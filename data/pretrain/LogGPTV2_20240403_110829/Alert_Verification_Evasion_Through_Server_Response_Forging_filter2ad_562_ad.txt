connections are created.  It can also send more than one response quite easily.  Once 
the  socket  descriptor  is  located,  sending  messages  is  relatively  simple  and  does  not 
require much space beyond that of the additional message.  One of the drawbacks to 
this  technique  is  that  it  requires  the  network  connection  to  remain  open.    Another 
disadvantage of this method is that it will not work with network address translation, 
proxies,  or  any  other  devices  the  obscure  the  port  of  the  original  client.    A  final 
weakness is the inability to set TCP flags which is a necessity for some of the server 
responses.  Nevertheless, this approach works well when size is a factor or there is a 
need to send back multiple messages. 
Findtag.  The second technique to find and reuse a socket is known in the Metasploit 
Framework  as  findrecv.  This  method  attempts  to  find  the  current  connection 
associated  with the exploit by reading from the receive buffer of every  socket.  For 
this technique to work, the attacker must send an additional packet after the exploit.  
This packet contains a tag and helps the shellcode find the correct socket. 
This  findtag  strategy  loops  through  all  the  socket  file  descriptors  and  uses  the 
socket  function  recv()  to  determine  if  there  are  any  more  bytes  to  read  from  the 
network  buffer.  If  so,  the  payload  reads  them  in  and  compares  them  to  the 
predetermined tag.  If the tag matches, the correct socket is found and can be reused 
to send back the forged server response. 
The shellcode stores the socket descriptor and increments through all the possible 
sockets.    The  receive  function  is  called  using  a  system  interrupt  and  the  result  is 
stored on the stack.  If the first 4 bytes of this string match the hardcoded tag, then the 
correct socket file descriptor has been found.  After the shellcode has a socket to use, 
it creates a message and sends it out. 
Again,  this  technique  was  implemented  using  assembly  language.    The  resulting 
shellcode is 57 bytes in addition to the length of the forged server response. Again, 
the  byte  code  must  be  encoded  before  it  can  be  sent  as  the  payload  of  an  exploit.  
Using  the  default  encoder  of  the  Metasploit  Framework,  a  payload  with  an  8  byte 
server  response  is  90  bytes.  The  shellcode  was  converted  to  byte  code  and 
transformed into a new Metasploit framework payload. 
This server response forging technique is similar to findport.  It shares some of the 
same  advantages  and  disadvantages,  but  there  are  also  differences.    It  remains  a 
relatively  simple  and  small  payload.  It  still  can  pass  through  firewalls  relatively 
unnoticed  because  it  does  not  create  a  new  socket  but  uses  a  pre-established 
connection instead. Findtag can send multiple messages without a significant increase 
in  size.  In  addition  to  these  advantages,  this  shellcode  can  also  find  the  correct 
network  connection  even  through  proxies  and  network  address  translation.  It  can 
accomplish  this  because  it  is  not  concerned  with  the  peer  information  which  is 
obscured.  This  approach,  however,  still  requires  an  open  socket  and  still  cannot 
modify  TCP  header  flags.  The  findtag  approach  also  depends  on  the  correct  socket 
having  the  correct  information  remaining  in  the  network  buffer.  This  requirement 
presents a couple problems. First, there is a timing issue. The attacker must send the 
information long enough after the original exploit so it is not read in along with the 
Alert Verification Evasion Through Server Response Forging 
271 
exploit,  but  it  must  also  be  sent  before  the  shellcode  attempts  to  read  the  network 
buffer.    Another  concern  is  that  the  shellcode  loop  might  read  in  data  from  other 
sockets which could cause errors or faults elsewhere in the system. 
Response  Forging  Summary.    Response  forging  must  be  accomplished  through 
socket creation or reuse.  The previous section discussed the implementation of socket 
creation  and  two  forms  of  socket  reuse.    Other  methods  were  considered, but  those 
methods were only slight variations of the already proposed ideas.  Each of the three 
implementations was shown to be effective, and each had its own set of advantages 
and disadvantages. 
Findport and findtag have a relatively small size, but are incapable of  modifying 
TCP headers.  This means that neither of these techniques can generate a RST packet 
required  to  forge  some  server  responses.    Findport  and  findtag  are  not  effective 
against the two exploits shown to be susceptible to server response forging in these 
experiments: samba_nttrans and trans2root. 
The  raw  socket  method  was  rather  large,  but  allows  for  greater  control  over  the 
server  response  including  the  ability  to  set  the  TCP  flags.    This  means  that  it  can 
create  an  RST  packet  which  is  part  of  the  forged  server  response  for  both 
samba_nttrans and trans2root.  However, both of these exploits require an SMB error 
message  to  be  sent  before  closing  the  connection  with  a  RST.    This  additional 
message  means  that  the  raw  socket  payload  will  be  very  large;  possibly  too  large.  
The samba_nttrans has a maximum payload size of 1024 bytes, while the trans2root 
exploit is limited to 734 bytes [31]. 
4.3   Intrusion Detection Enhancement 
This new form of IDS evasion brings with it complications for the current method of 
intrusion detection and alert verification.  In the past, IDS improvements have focused 
on adjusting rules and implementations to detect new attacks and evasion techniques.  
This new evasion tactic is not concerned with detection.  The goal of this attack is to 
fool the verification process into believing the attack was unsuccessful and make the 
forged server responses indistinguishable from those of actual patched servers.  This 
section  examines  several  adaptations  that  can  be  made  to  the  current  intrusion 
detection process which may allow detection of these new attacks. 
Payload Analysis.  The first method analyzes the payload of the attack.  Every attack 
can be divided into the exploit and payload, and every payload can be broken down 
into a NOP sled, shellcode and return address.  This new evasion technique includes 
additional  shellcode  which  forges  a  server  response.    These  modifications  may  be 
enough for an automated process to detect this attack. 
If an IDS can extract the payload, then it might be possible to analyze the payload and 
determine its behavior; however, several factors stand in the way of analyzing a payload.  
Attackers  encode  payloads  before  sending  them,  so  before  an  IDS  can  examine  the 
original payload, it must be decoded and the shellcode must be separated from the NOP 
sled  and  return  addresses.    The  next  pitfall  when  interpreting  the  effects  of  a  specific 
shellcode  is  obfuscation.    Modern  attacks  use  code  obfuscation  and  polymorphism  to 
make  reverse  engineering  and  signature  analysis  nearly  impossible  [32].  There  are 
techniques  for  dealing  with  obfuscated  code,  but  these  take  considerable  time  and 
272 
A.D. Todd et al. 
expertise.  All  of  these  requirements  make  decoding  a  payload  burdensome  and 
impractical. 
Payload  size  analysis  is  an  alternative  measure  which  IDSs  may  undertake  to 
determine  the  effects  of  a  payload.    Previous  research  has  shown  that  anomalous 
behavior may be determined by simply inspecting the size of packets [33].  Subsequent 
research suggests identifying the type of attack based on payload size [16].  This research 
has  found  that  only  payloads  with  a  certain  size  are  capable  of  generating  a  forged 
response; however, it is more accurate to say that only shellcodes of a sufficient size can 
generate forged responses.  In this experiment, the size of the buffer overflow payloads 
were  unaffected  by  the  type  of  shellcode  used.    The  payloads  were  a  constant  size 
determined  by  the  constraints  of  the  specific  buffer  overflow  exploit.    The  shellcodes 
capable of forging server responses are larger than most simple shellcodes; however, this 
only  means  that  there  are  fewer  NOPs  at  the  beginning  of  the  payload.    Therefore, 
payload size analysis really becomes shellcode size analysis and faces similar, decoding 
hurdles as payload code analysis discussed above. 
Catalog  Vulnerabilities  and  Responses.    Another  possible  solution  to  this  attack 
involves cataloging vulnerabilities and their responses.  While this research examined 
a  small  subset  of  the  Linux  vulnerabilities,  general  patterns  still  emerged.    Three 
characteristics  necessary  for  a  vulnerability  to  be  susceptible  to  server  response 
forging were outlined above.  This included a constant patched-server response which 
differs from a vulnerable-server response and a lack of evidence suggesting an exploit 
has occurred.  The process of analyzing every  vulnerability  to determine if it  meets 
the  criteria  for  this  attack  would  be  time  consuming,  but  it  may  also  provide  the 
verification process with valuable information. 
Analyst  Awareness.    This  type  of  evasion  attack  exemplifies  the  importance  of 
analysis and verification in the overall intrusion detection process.  Improved analyst 
awareness may be the most effective defense against such an attack.  Automated alert 
verification may alleviate some of the burden for the analyst, but it also incurs new 
vulnerabilities.    Increasing  the  contextual  awareness  of  these  devices  may  help.  
System  configurations  and  patch  levels  must  be  collected  and  monitored  on  all 
networked  machines.    This  data  collection  will  be  time  consuming  and  difficult  for 
large organizations; however, NIDSs would then be able to compare the vulnerability 
information with the detected attack to determine the success of the intrusion. 
Ultimately, the responsibility for network security and intrusion detection comes down 
to the person behind the systems.  Automated alert verification may help with handling 
the overwhelming task of sorting through alerts, but it is most likely not the “holy grail” 
of intrusion detection.  System administrators and security personnel must be aware of 
new  attacks  and  stay  current  on  their  training.    The  field  of  intrusion  detection  is 
extremely important and constantly changing, and the people behind the machines must 
remain aware of new advances and make sure their systems are not at risk. 
5   Conclusions 
This  research  examined  the  final  step  in  intrusion  detection,  alert  verification,  as  a 
source  of  vulnerability.    Previous  studies  concluded  that  alert  verification  relies  on 
Alert Verification Evasion Through Server Response Forging 
273 
server responses to determine the success of an attack, and this research  has  shown 
that these server responses may be forged within the Linux environment.  This type of 
attack ignores the technical aspect of detection and simply tries to evade the analysis 
and  verification  process.    Server  responses  cannot  be  used  as  a  trusted  method  for 
analyzing  attacks.    Analysis  is  an  important  part  of  intrusion  detection  and  the 
security of corporate and government networks.  These new evasion techniques mean 
current network defense strategies and IDSs must be reevaluated and improved. 
6   Future Work 
This  research  has  exposed  a  vulnerability  in  the  intrusion  detection  process.    Now 
evasion techniques not only target the technical aspects of intrusion detection but also 
the verification part.  Research experiments have shown two of four vulnerabilities to 
be susceptible and provided shellcodes capable of exploiting these weaknesses.  This 
work has opened some avenues for future work including: 
1. Increasing the scope of tested exploits and Linux distributions. 
2. Generating a catalog of all the server responses to aid in forging and/or detection. 
3. Identifying other flaws in the intrusion detection process, possibly also involving 
the human analyst. 
4. Adapting current intrusion detection methodology to account for these attacks and 
other weaknesses in the analysis portion of the process. 
Acknowledgments 
The authors wish to express their gratitude to the RAID reviewers for their insightful 
comments to strengthen the paper.  Special thanks to  Andreas Wespi for quick turn 
responses  and  “shepherding”  our  efforts.    This  work  was  sponsored  by  the  Sensors 
Directorate of the United States Air Force Research Laboratory. 
References 
1.  Intrusion-detection  System:  Wikipedia:  The  Free  Encyclopedia  (2006),  http://en.wikipedia. 
org/wiki/Intrusion_Detection_System 
2.  Ptacek, T.H., Newsham, T.N.: Insertion, evasion, and denial of service: Eluding network 
intrusion detection. Secure Networks, Inc. (January 1998)  
3.  Del Carlo, C., et al.: Intrusion detection evasion (2003) 
4.  Snort Documentation (2006), http://www.snort.org/docs/ 
5.  Axelsson, S.: Intrusion detection systems:  A survey and taxonomy. Chalmers University 
(March 2000)  
6.  Lindqvist,  U.,  Porras,  P.A.:  Detecting  computer  and  network  misuse  through  the 
Production-Based  Expert  System  Toolset(P-BEST).  Doktorsavhandlingar  vid  Chalmers 
Tekniska Hogskola, pp. 161-189 (1999)  
7.  Sommer, R., Paxson, V.: Enhancing byte-level network intrusion detection signatures with 
context.  In: Proceedings  of  the  10th  ACM  conference  on  Computer  and  communication 
security, pp. 262–271. ACM Press, New York (2003) 
274 
A.D. Todd et al. 
8.  Zanero,  S.,  Savaresi,  S.M.:  Unsupervised  learning  techniques  for  an  intrusion  detection 
system.  In:  Proceedings  of  the  2004  ACM  symposium  on  Applied  computing,  pp.  412–
419. ACM Press, New York (2004) 
9.  Chebrolu,  S.,  Abraham,  A.,  Thomas,  J.:  Feature  Deduction  and  Ensemble  Design  of 
Intrusion Detection Systems. Computers and Security, Elsevier Science (2005) 
10.  Kruegel,  C.,  Robertson,  W.:  Alert  Verification:  Determining  the  Success  of  Intrusion 
Attempts.  In:  Proc.  First  Workshop  the  Detection  of  Intrusions  and  Malware  and 
Vulnerability Assessment (DIMVA 2004) (July 2004) 
11.  Valeur, F., et al.: Comprehensive approach to intrusion detection alert correlation. IEEE 
Transactions on Dependable and Secure Computing 1(3), 146–169 (2004) 
12.  Zhou,  J.,  Carlson,  A.J.,  Bishop,  M.:  Verify  Results  of  Network  Intrusion  Alerts  Using 
Lightweight  Protocol  Analysis.  In:  Computer  Security  Applications  Conference,  21st 
Annual, pp. 117–126 (2005) 
13.  Kruegel, C., et al.: Polymorphic worm detection using structural information of executables. 
In:  Valdes,  A.,  Zamboni,  D.  (eds.)  RAID  2005.  LNCS,  vol. 3858,  Springer,  Heidelberg 
 (2006) 
14.  Timm, K.: IDS Evasion Techniques and Tactics. SecurityFocus (Infocus) 7 (2002) 
15.  Wagner,  D.,  Soto,  P.:  Mimicry  attacks  on  host-based  intrusion  detection  systems.  In: 
Proceedings of the 9th ACM conference on Computer and communications security, pp. 
255–264. ACM Press, New York (2002) 
16.  Chaboya, D.J., Raines, R.A., Baldwin, R.O., Mullins, B.E.: Network Intrusion Detection 
Systems  Evasion  Techniques  and  Solutions.  IEEE  Security  and  Privacy 4(6),  36–43 
(2006) 
17.  Fedora User Documentation (2006), http://fedora.redhat.com/docs/ 
18.  The  Top  Ten  Distributions:  A  Beginner’s  Guide  to  Choosing  a  (Linux)  Distribution 
(2006), http://distrowatch.com/dwres.php?resource=major 
19.  Metasploit  Framework  User  Guide  (2005),  http://www.metasploit.com/projects/Framework/ 
docs/userguide.pdf 
20.  Lamping,  U.,  Sharpe,  R.,  Warnicke,  E.:  Ethereal  User’s  Guide  (2005),  http://www. 
ethereal.com/docs/eug_html_chunked/ 
21.  Workstation 5: Powerful Virtual Machine Software for the Technical Professional (2006), 
http://www.vmware.com/pdf/ws55_manual.pdf 
22.  Samba  Fragment  Reassembly  Overflow:  Open  Source  Vulnerability  Database  (2004), 
http://www.osvdb.org/6323  
23.  GNU Mailutils imap4d Server Client Command Format String: Open Source Vulnerability 
Database (2005), http://www.osvdb.org/16857 
24.  PoPToP  PPTP  Negative  Read  Overflow:  Open  Source  Vulnerability  Database  (2005), 
http://www.osvdb.org/3293 
25.  Samba call_trans2open() Function Overflow: Open Source Vulnerability Database (2005), 
http://www.osvdb.org/4469 
26.  Jacobson, V., Leres, C., McCanne, S.: PCAP (2003), http://www.tcpdump.org/pcap/pcap. 
html 
27.  Linux Shellcode (2007), http://www.metasploit.com/shellcode_linux.html 
28.  UNIX  Assembly  Codes  Development  for  Vulnerabilities  Illustration  Purposes  (2001), 
http://lsd-pl.net/projects/asmcodes.zip  
29.  Chong, S.K.: History and Advances in Windows Shellcode. Phrack (2004)  
30.  Kuperman,  B.A.,  et  al.:  “Detection  and  prevention  of  stack  buffer  overflow  attacks. 
Communications of the ACM 48(11), 50–56 (2005) 
31.  Current Exploits (2007), http://metasploit.com/projects/Framework/exploits.html  
Alert Verification Evasion Through Server Response Forging 
275 
32.  Polychronakis,  M.,  Anagnostakis,  K.G.,  Markatos,  E.P.:  Network-Level  Polymorphic 
Shellcode Detection Using Emulation. In: Büschkes, R., Laskov, P. (eds.) DIMVA 2006. 
LNCS, vol. 4064, Springer, Heidelberg (2006) 
33.  Mahoney,  M.:  Network  Traffic  Anomaly  Detection  Based  on  Packet  Bytes.  In:  Proc. 
ACM-SAC, pp. 346–350 (2003)