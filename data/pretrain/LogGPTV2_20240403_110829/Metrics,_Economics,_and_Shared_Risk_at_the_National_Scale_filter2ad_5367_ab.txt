would enjoy mandatory reporting of communicable diseases, it would perform longitudinal analysis of incidence and 
prevalence of disease including the search for excess incidence or prevalence, and it would have away-teams to handle 
outbreaks of disease.
The CDC are established by the rule of law and paid for by the rule of law (through taxes).  They were not present at the 
creation, but are now essential.  When, if at all, should the rule of law include mandatory reporting, forced treatment 
and/or quarantine of the ill, the publication of an Internet-equivalent of the MMR, formal predictive work that aids 
those planners who must anticipate epidemics whether of ﬂu or NIMDA, and the public identiﬁcation of locales, 
however deﬁned, where there is an excess of incidence or prevalence of any particular pathogen.
Sharing: semi-self-interest
• Information Sharing & Analysis Centers
• PDD 63 (1998), sector-speciﬁc
• Report to relevant dept (FS to Treasury)
• Explicit exemption from FOIA, anti-trust
• Anonymous submission, sort of
• DHS wants them all
The Information Sharing and Analysis Centers were created under Presidential Decision Directive #63, Clinton, 1998.  
Each ISAC is sector speciﬁc and reports to a sector coordinator.  “Sector speciﬁc” means ﬁnancial services, information 
technology, energy, electric power, and so forth.  All are voluntary associations of private and public ﬁrms acting on 
behalf of their individual sectors.  The sector coordinator will report in to a relevant cabinet-level department, e.g., 
Treasury for the Financial Services ISAC.  Data sharing and other interactions with the ISACs enjoy explicit exemption 
from the Freedom of Information Act and from Anti-Trust.  They share some data in a titularly anonymous way that is 
more like unattributed than anonymous (there being only guarantees of anonymity rather than technical means).  The 
Department of Homeland Security, Infrastructure Analysis and Protection Authority, wants to take them all over.  At 
issue is whether the private sector of the US economy, which owns 90+% of the nation’s critical infrastructure can, will, 
or will be allowed to ensure its protection from shared risks.  This is as close to a “command economy” move as one is 
likely to see from any administration for some time.  The ISACs need to lead or follow.
Disclaimer: The present author serves as one of ﬁve outside advisors to the FS/ISAC, pro bono.
Sharing: regulation
• Information sharing of a sort
• Disclosure (Calif SB1386, FTC, ...)
• Outlier-focus distorts understanding
• Government cannot be expected to hold 
anything conﬁdential
Regulatory sharing is sharing of a sort.  Looking forward, it is clear that security-related regulation, broadly deﬁned, is 
here to stay.  The most likely area of regulation to develop ﬁrst and most fully is that around disclosure.
With disclosure, there is already the example of California’s Senate Bill #1386 (SB1386) which mandates disclosure 
when a ﬁrm may have lost personally identiﬁable data entrusted to it by its clients. (This has the quality of “proving a 
negative” in that the disclosure is required when it cannot be proved that the data is still safe.)  Similar laws have since 
been adopted, though diﬀerently, in Idaho, New York, New Jersey, Georgia, and Indiana
Other examples include the body of FTC Safeguards Rule’s broad requirement for Due Care when handling data, as well 
as the Federal Information Systems Management Act (FISMA), a recent bill ﬁled (then withdrawn) by Rep. Putnam of 
Florida, US Senate S1350 (Cal SB1386 clone), and the Computer and Information Security Working Group (CISQG) are 
not even the entire list.
Metrics: not free
• Process-based metrics work only in stable 
attack environments
• Damp change to get stability?
• Goal-based metrics will have to be indirect 
because security is a means, not an end
• Is ordinal scale good enough?
Metrics are not free.  More particularly, there is the natural tendency of government and wanna-be governments (like 
the insurance industry) looking to impose process standards.  Process standards are only valuable against constant 
threat, what an academic would call a stationarity assumption.  This does not obtain in the Internet sphere where rapid 
technical advance is a desirable economic good.  Therefore, the national policy level question is whether damping down 
the rate of change to a more stable state, one treatable by process standards, is a desirable direction for the national 
leadership to take.
By contrast, goal-based metrics at our present level of knowledge will have to be indirect as we have no way to measure 
security, per se.  What we can measure are downstream eﬀects of security or, more precisely, downstream eﬀects of 
insecurity on, say, unreliability, as illustrated in the next slide.  What we can measure is likely to be at best an ordinal 
scale but isn’t an ordinal scale good enough?  If not, say why not.
Ends v. Means
If a system is insecure, then
  It is unreliable, therefore
    Security is necessary for reliability, yet
      Security is insufﬁcient for reliability, ergo
        Security is a subset of reliability.
The more mature tñnfrastructural entity is the more security is a subset of reliability, per the logic above.
The parallel: that if a system is unregulated then it is unpredictable, therefore regulation necessary is for predictability, 
yet regulation is insuﬃcient for predictability, therefore regulation is a subset of predictability suggests itself.  If as 
correct as the relation between security and reliability, then the question for the law is how to regulate for predictability 
without damping out innovation or the motivation to improve.  This is hardly a new topic, but the digital physics will 
stress security as a subset of reliability.
As Whit Diﬃe (Stanford) has observed, computing would become free were it not for security.
Security spend
“The next ten years will be a referendum on 
whether we consume the entire productivity 
growth of the US economy for increased 
security spend.” [ paraphrase summary ]
            Chief US Economist, Morgan Stanley
            Op-Ed, NY Times, 23 October 2001
“The Terror Economy,” Richard Berner, NY Times, 23 October 01, Page A23, Column 1
ABSTRACT  - Op-Ed article by Morgan Stanley economist Richard Berner
warns that war against terrorism will impose long-term economic costs in
form of higher insurance and security costs, maintenance of larger
inventories and new Internet security measures; explains that spending
more on defense will erase decade-long 'peace dividend' and crowd out 
other investments that helped transform budget deficits into surpluses.
Full article available upon reasonable request.
Security spend as 
calibrator
  3% for manufacturing...8% for banks
• Corp budget for security:
• IT headcount for security:
• IT budget for security:
  5% of total
  12% hardware     20% software
  15% services       53% staff
The Meta Group, Diamond report #2856, recommendations on how much of IT budet should be allocated to 
security spend.
source: Meta #2856
The problem of value
“Some day, on the corporate balance sheet, 
there will be an entry which reads, 
‘Information’; for in most cases the 
information is more valuable than the 
hardware which processes it.”
            Grace Murray Hopper, USN (Ret)
Rear Admiral Grace Murray Hopper, USN (Ret), Washington, D.C., 1987.
The problem of value
• How much is information worth?
• Replacement value
• Black economy market price
• Future value
How much is information worth, then?  If Hopper is right, then it ought to be on corporate, and for 
that matter national, balance sheets and it generally is not.  
Perhaps we need a way (or ways) to think about the value of information.  Perhaps its replacement 
value, or its value in the black economy, or its future value would at least bracket reality.
The problem of value
• Replacement value
• How much would it cost to build a brand 
as good as the one you have today?
• What is the time to recycle after a 
• Management cost of new passwords for 
continuity break?
5,000 users
You ask a management team “How much is your brand worth?” and you get blank stares or wild guesses.  
Try it a different way, ask “How much would it cost you, knowing what you know today, to build a 
brand from scratch as good as the one you have now?”  This will get an answer that is probably a 
lower bound for replacement value.  If such a value is sufficient basis to make whatever managerial 
decision around security that is on the table, then that is good enough for the time being.
Similarly, if your business has a “non-interruptibility” requirement, such as continuous monitoring 
of weather conditions for a period of time before a power plant can be sited, then the re-formulated 
form of “How much is your information worth?” would be more like “How much incremental cost would 
you incur if your continuity of measurement were broken and you had to start over?”
A different sense of the value of good passwords or good password protection would be to not ask 
“How much are your passwords worth?” but rather “If today you had to get all 50,000 people in your 
firm to pick a new password within 36 hours how much incremental cost would you incur?”
The problem of value
• Black economy market price
• AOL screen names: 0.1¢/name
• Bot-net host rental for spam: $1/mo
• Financial screenshot: $500
• Game skin 90 days out: $50,000
A different way to look at the value of information is to ask what the black market pays, if indeed 
that is a question that can be answered in a way that is sufficiently close to where you are to be 
valuable via analogy.  For example, a thief was paid $100,000 for 92MM AOL screen names.
Computers that are taken over silently are occasionally rented to others, e.g., as spam relays.  The 
rental fee approximates $1/month by some estimates.  That tells you at the very least that the 
supply of machines taken over is great as such a price is obviously slight.  That would mean that 
your data on your machine is, by analogy, very easy to get at by others.  If you don’t know how easy 
it is, then you would conservatively assume that breaking into your machine is worth a dollar on the 
open market.
More directly, a major west coast bank reports that its tellers are routinely offered $500 per 
screenshot of customer identifying data for customers with over $50,000 of assets.  So a clerk 
making $10/hour can give themself an after-tax raise of $26,000/year for the price of one sheet of 
paper per week.  Not every clerk is immune to this temptation.
Game skins more than ninety days pre-release are worth at least $50,000 in Taiwan.
The problem of value
$100M, 80% is information
• Future value
• From eureka to FDA ﬁling costs circa 
• Derivative pricing algorithm alone carried 
• Patent losses: CDMA in India & China at 
on books as $300M
$750M/annum
In a pharmaceutical company, the critical period begins with the “Eureka!” moment and closes with 
the FDA formal filing.  In this interval, the pharmaceutical can expect to spend $100,000,000 at the 
end of which 80% of the value is the information in the can.  This is a hard to get figure and was 
obtained in conversations variously.
A single bank in NYC that is known for its derivative trading carries its apparatus for pricing same 
as a $300,000,000 asset.
The inability of Qualcomm to effectively patent its CDMA technology in China and India represents an 
information loss to them of $750,000,000 per year based on current usage rates of the CDMA 
technology.
Pre-emption
“What did he know and when did he know it?”
Every single pointed, argumentative, accusatory discussion in the press, the salons, and the hearing 
rooms of Congress comes down to the phrase “What did he know and when did he know it?”
The subtext is clear, the hostile question will immediately be followed with “He should have know 
and taken action earlier than he did.  He should have kept XYZ from happening.”  In short, he should 
have pre-empted.
Pre-emption
• Invisible foes create demand for pre-emption
• Pre-emption requires intell which requires 
• Surveillance requires a sensor fabric that is 
surveillance
always on
Freedom (default permit) yields to Safety (default deny)
Here are the facts of pre-emption.
Invisible foes create an unblockable demand for pre-emption of what those foes would otherwise do.  
For pre-emption to work, there must be intelligence on what might happen, and when and where and how 
as well.  For that intell to be in hand, there must be surveillance before there is any proven 
reason to be surveilling, i.e., it must be done when suspicion is the most the surveiller can have.  
In a highly interconnected, globalized, fast-paced and fast-changing world this means a sensor 
fabric that is always on.  The first rule of exploratory data analysis is “Get the data.”  As a 
matter of national security, there must be significant spend on surveillance and that spend may not 
be only in dollars but rather in social costs as well.
Let’s do the numbers
It is time to illustrate these points.
Incidents (known)
Incidents
85,000
63,750
42,500
21,250
0
0
9
1
9
2
9
3
9
4
9
5
9
6
9
7
9
8
9
9
9
0
0
1
0
2
0
Public CERT data
Vulnerabilities (known)
Vulns
4,500
3,375
2,250
1,125
0
0
9
1
9
2
9
3
9
4
9
5
9
6
9
7
9
8
9
9
9
0
0
1
0
2
0
Public CERT data
Hosts (estimated)
Hosts
150,000,000
112,500,000
75,000,000
37,500,000
0
0
9
1
9
2
9
3
9
4
9
5
9
6
9
7
9
8
9
9
9
0
0
1
0
2
0
Public ISOC data
Opportunity 
(normalized)
Hosts*Vulns
120
90
60
30
0
0
9
1
9
2
9
3
9
4
9
5
9
6
9
7
9
8
9
9
9
0
0
1
0
2
0
So how much opportunity is there?  Is it well modeled by total number of open holes, i.e., by the 
product of the number of hosts times the number of vulnerabilities?
If so, the curve looks like this, and it has taken an amazingly steep turn upward.
Opportunity “wasted”?
Hosts*Vulns
Incidents
120
90
60
30
0
}?
0
9
1
9
2
9
3
9
4
9
5
9
6
9
7
9
8
9
9
9