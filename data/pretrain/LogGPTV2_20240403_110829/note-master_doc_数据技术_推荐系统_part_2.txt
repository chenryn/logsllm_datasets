没有反馈的缺失值，就是在我们的设定下，取值为 0 的评分就非常多，就需要进行负样本采样
因此按照物品热门程度采样的思想就是：一个越热门的物品，用户越可能知道它的存在。那这种情况下，用户还没对它有反馈就表明：这很可能就是真正的负样本
得到了分解后的矩阵后，相当于每个用户得到了隐因子向量，这是一个稠密向量，用于代表他的兴趣，让用户和物品的隐因子向量两两相乘，计算点积就可以得到所有的推荐结果
### 贝叶斯个性化排序BPR
- 排序的评价指标：AUC，全称是 Area Under Curve，意思是曲线下的面积，这里的曲线就是 ROC 曲线
BPR做了三件事：
1. 一个样本构造方法
2. 一个模型目标函数
3. 一个模型学习框架
## 模型融合
推荐系统技术实现的三个阶段：
1. 挖掘：对用户和物品做非常深入的结构化分析
2. 召回：每次给一个用户计算推荐结果时，用一些手段从全量的物品中筛选出一部分
3. 排序
### 逻辑回归和梯度提升决策树组合
逻辑回归输出值范围就是 0 到 1 之间，是广义线性模型
树模型天然就可以肩负起特征组合的任务，最原始的是决策树，简称 DT
![2022127213446](/assets/2022127213446.webp)
### 因子分解机模型
### Wide & Deep 模型
使用用户特征和上下文场景特征从物品库中召回候选推荐结果，比如得到 100 个物品，然后用融合模型对这 100 个物品做最终排序，输出给用户展示
同时开始记录展示日志和用户行为日志，再把收集到的日志和用户特征、上下文场景特征、物品特征拉平成为模型的训练数据，训练新的模型，再用于后面的推荐，如此周而复始
## MAB问题
- 多臂赌博机问题 (Multi-armed bandit problem, K-armed bandit problem, MAB)
如何选择
### Bandit算法
在冷启动和处理探索问题时，Bandit 算法简单好用
- 思想是：看看选择会带来多少遗憾，遗憾越少越好
小心翼翼地试，越确定某个选择好，就多选择它，越确定某个选择差，就越来越少选择它
1. 臂：每次推荐要选择候选池，可能是具体物品，也可能是推荐策略，也可能是物品类别
2. 回报：用户是否对推荐结果喜欢，喜欢了就是正面的回报，没有买账就是负面回报或者零回报
3. 环境：推荐系统面临的这个用户就是不可捉摸的环境
汤普森采样算法：假设每个臂背后都有一个概率分布，每次做选择时，让每个臂的概率分布各自独立产生一个随机数，按照这个随机数排序，输出产生最大随机数那个臂对应的物品
UCB算法（Upper Confidence Bound，即置信区间上界）：为每个臂评分，每次选择评分最高的候选臂输出，每次输出后观察用户反馈，回来更新候选臂的参数
Epsilon贪婪算法：朴素算法，先选一个 (0,1) 之间较小的数，每次以概率 Epsilon 从所有候选臂中随机选一个，以 1-Epsilon 的概率去选择平均收益最大的那个臂
LinUCB：选择时加入了特征，各个候选臂之间参数是独立的，参与计算的是特征，所以可以处理动态的推荐候选池
COFIBA 算法：-
## 深度学习
在推荐系统中更好地表达事物特征：
- x2vec
## 排行榜算法
防止刷榜、马太效应，同时需要一定的时效性，算法需要考虑时间因素、投票公平性：
### Hacker News 计算帖子热度
$$\frac{P-1}{(T + 2) ^ G}$$
1. P：得票数，去掉帖子作者自己投票
2. T：帖子距离现在的小时数，加上帖子发布到被转帖至 Hacker News 的平均时长
3. G：帖子热度的重力因子，重力因子越大，帖子的热度衰减越快
### 牛顿冷却定律
$$T(t) = H + Ce^{-αt}$$
1. H：为环境温度，可以认为是平均票数，由于不影响排序，可以不使用
2. C：为净剩票数，即时刻 t 物品已经得到的票数，也就是那个最朴素的统计量。
3. t：为物品存在时间，一般以小时为单位。
4. α ：是冷却系数，反映物品自然冷却的快慢
当投票数越多，冷却系数就可以越大，代表物品热度越高
### 考虑正负投票
- 同样多的总票数，支持赞成票多的
- 同样多的赞成票数，支持最有价值的
### 考虑偏好公平性
好评率估算公式，叫做威尔逊区间，公式太复杂，不写了
贝叶斯平均：
$$\frac{v}{v+m}R + \frac{m}{v+m}C$$
1. R，物品的平均得分
2. v，参与为这个物品评分的人数
3. m，全局平均每个物品的评分人数
4. C，全局平均每个物品的平均得分
这个公式的好处是：所有的物品，不论有多少人为它评分，都可以统一地计算出一个合理的平均分数
## 加权采样算法
已知一些样本及其对应的权重，如何进行召回才能保证概率与其权重一致
### 有限数据集
$$S_i = R^{\frac{1}{wi}}$$
1. wi 是每个样本的权重
2. R 是遍历每个样本时产生的 0 到 1 之间的随机数
3. Si 就是每个样本的采样分数
### 无限数据集
- [蓄水池采样](/数据技术/数据分析.md#数据抽样)
加权蓄水池采样：
1. 使用有限数据集采样的公式为每一个样本生成一个分数
2. 如果结果不足 k 个，直接保存到结果中
3. 如果结果中已经有 k 个了，如果 Si​ 比已有的结果里最小那个分数大，就替换它
## 去重
- simhash
- 布隆过滤器
## 常见架构
### 信息流
#### 整体架构
1. 日志收集，是所有排序训练的数据来源，要收集的最核心数据就是用户在信息流上产生的行为，用于机器学习更新排序模型
2. 内容发布，就是用推或者拉的模式把信息流的内容从源头发布到受众端
3. 机器学习，从收集的用户行为日志中训练模型，然后为每一个用户即将收到的信息流内容提供打分服务
4. 信息流服务，为信息流的展示前端提供 API
5. 监控，这是系统的运维标配，保证系统的安全和稳定等
#### 数据模型
内容，有个Atom 规范：
1. time 发生时间
2. actor 由谁发出
3. verb 连接的名字，显式floow，like或者隐式
4. object 动作作用到最主要的对象，只能有一个
5. target 动作的最终目标，与 verb 有关，可以没有。它对应英语中介词 to 后接的事物
6. title 动作的自然语言描述
7. summary 动作的视图，通常是一小段 HTML 代码，不是必须的
关系：
1. from 连接的发起方
2. to 被连接方
3. type 连接的类型
4. affinity 连接的强弱
连接的发起从 from 到 to，内容的流动从 to 到 from。连接 和 内容 是相互加强的，这是蛋和鸡的关系：有了内容，就会产生 连接，有了 连接，就可以“喂”（feed）给更多的 内容
#### 内容发布
- 推模式：当一个 actor 产生了一条 内容 后，不管受众在不在线，刷没刷新，都会立即将这条内容推送给相应的用户
- 拉模式：当用户访问时，信息流服务才会去相应的发布源拉取内容到自己的 feed 区来
一般都会两者相结合，拉模式在数据量大的情况下就会有瓶颈，而推模式一般会伴随着大量的写操作和数据冗余
#### 排序
信息流正常就是时间排序，如果要打破时间排序，要问问为什么要打破，唯一可以打破的理由就是通过某些排序能有效提高用户的互动率
#### 数据管道
要能通过历史数据来寻找算法的最优参数，又要能通过新的数据验证排序效果
### 推荐系统
![Netflix推荐架构](/assets/2022121215321.webp)
层级 | 数据  | 服务  | 特点                                           | 约束                                        | 典型任务                                     | 举例
-- | --- | --- | -------------------------------------------- | ----------------------------------------- | ---------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------
离线 | 非实时 | 非实时 | 1.可以处理大数据量 2.可以运行批量任务 3.低成本尝试多种算法 4.可加机器提升效率 | 1.无法及时捕获最新的用户兴趣 2.无法给用户最及时的推荐             | 1.批量机器学习算法 2.批量计算推荐结果 3.挖掘用户标签 4.物品的内容分析 | 1.矩阵分解，学习得到用户隐因子向量和物品隐因子向量 2.学习500棵GBDT决策树 3.以GBDT输出作为特征学习了LR模型参数。
近线 | 实时  | 非实时 | 1.能捕捉到用户最新兴趣 2.能运行较复杂的学习算法 3.能比较及时给用户响应      | 1.能处理的数据量有限 2.部分依赖离线计算结果 3.和离线无缝结合有一定的复杂度 | 1.用最新事件补充召回推荐结果 2.小批量样本更新模型参数            | 1.用户新评分的电影计算相似电影补进离线推荐结果 2.根据最新浏览提取新的标签补充到用户标签中
在线 | 实时  | 实时  | 1.对场景信息敏感 2.立即满足用户 3.运行简单算法和逻辑               | 1.响应时间是硬要求 2.要准备降级服务的推荐结果 3.计算复杂度有限       | 1.过滤逻辑 2.运营手段 3.融合排序 4.多样性提升             | 1.取出近线阶段的推荐电影,及物品的内容特征，用户特征 2.运行GBDT模型得到500个新特征，运行LR模型输出融合排序 3.过滤掉看过的，过滤掉已被删除的 4.根据多样性要求去掉高度相似的电影 5.强插-些当季运营活动需要的到指定位置 6.输出推荐结果
### 推荐、搜索、广告
项         | 搜索    | 推荐       | 广告
--------- | ----- | -------- | -----
信息送达方式    | 拉     | 推和拉      | 推
关注点       | 内容消费方 | 内容生成方消费方 | 内容生产方
是否期待惊喜    | 否     | 是        | 否
是否需要集体智慧  | 可能    | 可能       | 需要
是否需要query | 需要    | 可能       | 可能
否依赖上下文    | 可能    | 可能       | 可能
![2022121215415](/assets/2022121215415.webp)