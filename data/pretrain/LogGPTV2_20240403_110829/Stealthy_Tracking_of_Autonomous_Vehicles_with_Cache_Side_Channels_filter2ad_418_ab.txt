by OS-level access-control mechanisms.
3.2 Adaptive Monte-Carlo Localization
Localization is a task that determines the locations of ob-
jects on a given map based on sensor inputs. It is needed
by many advanced driving assistance systems and required
by autonomous vehicles. Adpative Monte-Carlo Localiza-
tion (AMCL) is a special case of general MCL [34], and was
used by multiple teams [26, 43, 50] in the DARPA Grand
challenge [25]. Many recent research autonomous driving
projects [27, 40, 60, 64] have also used AMCL. For example,
the CaRINA intelligent robotic car [32] uses AMCL for its
LiDAR-based location [40].
Algorithm 1 shows the pseudocode for general Monte-
Carlo localization. Given a map M0 of a certain area and
a probability distribution P : M0 (cid:55)→ R over the map M0, at
time t, N particles (i.e., hypothetical locations of the vehicle)
are randomly generated based on the distribution. For each
particle Li, the sensor measurement St is combined with the
particle to infer the position of the obstacles on the map. For
example, in a 1-D case, if the distance sensor detects an ob-
stacle 10 m from the hypothetical location of the vehicle and
the hypothetical location is 20 m from the starting location,
it is inferred that that obstacle is 30 m (10 m + 20 m) from
the starting location. Inferred obstacles are plotted on a new
empty map Mi, which is then compared with the given map
M0 to calculate the ﬁdelity pi of the particle Li, based on the
assumed distribution of measurement errors. For example, the
ﬁdelity pi will be high if the inferred map Mi closely matches
the given map M0, and low if the two maps differ signiﬁcantly.
Finally, k-means clustering [36] is used to determine the most
probable geometrical clustering center Lest,t of these particles
{Li}, weighted by {pi} at time t. Also, the probability dis-
tribution P : M0 (cid:55)→ R is updated for the next measurement
St+1.
The number of particles N in Algorithm 1 is not necessarily
ﬁxed. When the distribution P : M0 (cid:55)→ R converges, a small
N is enough for accurate estimation. When the distribution
P : M0 (cid:55)→ R spreads across the map M0, the parameter N may
need to be increased. In AMCL, N changes with time t; we
denote it by Nt. The exact value of Nt at time t is determined
by the Kullback–Leibler distance (KLD) [34] between the
estimated distribution P : M0 (cid:55)→ R and the underlying ground-
Input: Map M0, a probability distribution over the whole
map P : M0 (cid:55)→ R , sensor measurement time
series S1,S2, ...St, number of particles N, number
of clusters K, transient odometry d1,d2, ...dt.
Result: Estimated states Lest,1,Lest,2, ...,Lest,t on map
foreach sensor measurement St at time t do
Randomly generate N particles (i.e., hypothetical
locations) {Li} on the map based on distribution
P : M0 (cid:55)→ R;
foreach particle Li (1 ≤ i ≤ N) do
Overlay measurement St on the particles Li;
Generate the extrapolated map Mi based on the
measurement St and location Li;
Compare the extrapolated map Mi and the given
map M0, calculate the ﬁdelity pi;
end
Determine the most probable cluster center
Lest,t = kmeans(K;L1, . . . ,LN; p1, . . . , pN);
Update the probability distribution P : M0 (cid:55)→ R based
on particles L1, . . . ,LN, corresponding ﬁdelity
p1, . . . , pN as well as transient velocity dt;
end
Algorithm 1: General Monte-Carlo localization.
truth distribution P0 : M0 (cid:55)→ R:
Nt =
k− 1
2ε
{1−
2
9(k− 1)
+
(cid:115)
2
9(k− 1)
z1−δ}3
(1)
Here, z1−δ is the upper (1− δ) quantile of standard normal
distribution, ε is the upper bound of the KLD, and k is the
number of bins occupied during sampling at time t (e.g., if
the map is partitioned into 1,024 bins and only 300 bins are
occupied, in this case, k = 300). Theoretically, Nt could be
any positive integer. Practically, there is a maximum limit
Nmax and a minimum limit Nmin to ensure real-time perfor-
mance and k-means clustering accuracy, respectively. In our
experiments, we found that the AMCL implementation uses
either the maximum or the minimum number of particles in
most cases.
3.3 Cache Side Channel
In modern computing systems, off-chip memory (e.g.,
DRAM) accesses are much slower than on-chip memory ac-
cesses served by a cache. Also, a cache is usually shared
among multiple programs. For example, a last-level cache
(LLC) in a multi-core processor is used by multiple process-
ing cores concurrently. L1 and L2 caches may be dedicated
to a speciﬁc core, but are still time-shared among programs
that run on the core.
The shared cache implies that one program’s memory ac-
cesses can affect whether another program can ﬁnd its data
862    29th USENIX Security Symposium
USENIX Association
in the cache, or needs to access off-chip memory. As a result,
one program can infer another program’s memory accesses
by measuring its own memory access latency. When a vic-
tim program accesses its data from memory, it can evict the
cached data of other programs in order to bring its own data
into cache. An attack program can infer whether the victim
program had a cache miss or not, and which memory address
was accessed, by measuring the latency of its memory ac-
cess, which reveals whether the data was found in the cache
or not. This measured latency leaks the victim program’s
memory-access pattern to the attack program. There are
many existing cache side-channel attack techniques, including
prime+probe [45, 54], evict+time [55], ﬂush+reload [44, 71],
prime+abort [28], ﬂush+ﬂush [37], etc. In this work, we use
the prime+probe attack, but we expect that our attack can
also be implemented using other types of cache side-channel
attacks.
4 The Proposed Attack
4.1 Vulnerability in AMCL
An autonomous vehicle running AMCL is vulnerable to a
cache side-channel attack that aims to infer its kinematics.
This is because the memory access pattern of AMCL depends
on the number of particles Nt at each time t, which has strong
correlation with the real-time vehicle kinematics.
First, the number of particles Nt affects the memory access
pattern of AMCL, which can be inferred through a cache
side-channel attack. The following steps summarize how the
memory accesses in AMCL for an iteration at time t are deter-
mined, based on Algorithm 1 and a reference implementation
in ROS [1].
1. Calculate the number of particles Nt using Equation (1);
2. Create Nt particle objects in a ﬁxed-size buffer1;
3. For each particle, access the memory locations of the
particle object and perform necessary computation.
If Nt increases, more memory locations will be accessed.
The memory accesses can be observed by another program
through a cache side channel.
Second, the number of particles Nt has a strong correlation
with the vehicle kinematics at time t. It is obvious from Equa-
tion (1) that Nt increases with k, which represents the number
of bins occupied by particles. The value of k depends on the
level of uncertainty in the estimation. As shown in a previ-
ous study [35], when the observed environment is unstable
1Original ROS AMCL implementation dynamically allocates and frees
memory space for Nt particles in each iteration rather than using a ﬁxed-size
buffer. Instead, we use a statically-allocated buffer to avoid unnecessary
overhead for dynamic memory allocation. While not included in the paper,
we also tested our attack with the dynamic memory allocation, and conﬁrmed
that the attack works for both static and dynamic allocation.
Figure 3: An example showing the correlation between the
number of particles in AMCL and the vehicle trajectory curva-
ture (high curvature indicates the vehicle is turning). Obtained
from a Jackal robot simulation.
(e.g., due to signal loss), Nt increases to compensate for the
increased estimation uncertainty. Our observation is that Nt
increases when the vehicle is turning as shown in Figure 3.
Third, the route or the position of a vehicle can be inferred
from kinematic information. In theory, if the curvature κ(t)
of the vehicle’s trajectory as a function of time t is obtained
using the side channel, we can obtain the route that a vehicle
is taking by matching the curvature of the trajectory with
the candidate routes on the map. In addition, if we know the
initial location of the vehicle, we can predict the location
of the vehicle by enumerating routes that connect the initial
location and the candidate locations on the map.
In practice, instead of using curvature, whose precise value
is hard to directly infer, we use the information on the number
of particles to predict the route of the vehicle.
4.2 Attack Overview
Based on the vulnerability described in Section 4.1, it is pos-
sible to implement a cache side-channel attack that infers
the route or the location of an autonomous vehicle running
AMCL. We implement our attack using the following steps.
1. Prime+Probe: Collect the cache probing time for each
cache set over ﬁxed time intervals, forming a sequence of
cache-timing vectors in which each vector represents the
probing times for cache sets at a speciﬁc time interval.
2. Particle Predictor: Use a binary classiﬁcation model
to predict the number of particles for each time interval
based on the cache-timing vectors for each interval.
3. Route Predictor: Use a random forest model to predict
the route or the position of a vehicle based on the trace
of the number of particles.
Figure 4 shows the overall ﬂow of the attack. We describe
each step in more detail in the next three subsections.
USENIX Association
29th USENIX Security Symposium    863
80100120140160time (s)050001000015000Number of particles0246810Curvature of the trace (1/m)105Figure 4: The overall ﬂow of the attack.
Given this observation, we formulate the prediction of the
number of particles as a binary classiﬁcation problem.
The input of the model is the vectors from the prime+probe
cache attack {Tt}. We take a time window of size 2T + 1 of
Tt, i.e., (Tt−T , ...,Tt , ...Tt+T ) as the input of the model, and
the output particle-number class Nt is in one of the two classes,
i.e., Nt ∈ {L,H}, where L and H denote “Low” and “High”,
respectively. Formally, the classiﬁcation task is deﬁned as
follows:
Figure 5: Cache side-channel measurements of 16 cache sets
from the L1D cache of Intel i5-3317u.
4.3 Acquiring Victim Cache Access Pattern
In this work, we use a prime+probe attack to infer the memory
accesses of victim software. First, the attack program ﬁlls the
cache with its own data by sequentially accessing a set of
memory addresses. Then, the victim accesses the cache. After
that, the attack program probes the same memory addresses
and records the latency of each access. If a speciﬁc memory
address is evicted by the victim program, the probe time will
be longer. Thus, the memory access pattern of the victim
program can be inferred.
The result of the prime+probe attack is a sequence {Tt}
in which each element Tt at time t is a K-dimension vector
(τ1
t ) where K is the number of cache sets. For exam-
ple, in Figure 5, each column is a 16-D vector representing
the probing time of 16 sets in the L1 data (L1D) cache. The
result is from an Intel i5-3317u dual-core processor whose
L1D cache of one core has 64 sets total. For brevity, we show
only 16 sets out of 64.
t , ...,τK
t ,τ2
Many cache side-channel attacks exist. For example, the
evict+time attack [55] has been used to extract cryptographic
keys on a system when many measurements can be made
using the same key. The ﬂush+reload attack [44] has been
used when shared memory locations, such as a shared library,
can be accessed by both attacker and victim software. We
use the prime+probe attack because it can effectively infer
the victim’s memory accesses even without multiple measure-
ments and without a shared library between the attacker and
the victim.
4.4 Particle Predictor
In practice, we found that the AMCL algorithm usually uses
either the maximum or the minimum number of particles.
• Given:
where Tt
t−T , ...,τK
(τ1
{L,H} for each t.
tuples of (Tt ,Nt ) (t ∈ {1,2, ...,tend}),
tend
is a (2T + 1) · K-dimension vector Tt =
t+T ) for each t, and Nt ∈
t−T , ...,τ1
t+T , ...,τK
• Find: a model f : R(2T +1)·K (cid:55)→ {L,H} such that the clas-
t=1 d( f (T),Nt ) is maximized, where
siﬁcation score ∑tend
d : {L,H}×{L,H} (cid:55)→ R is deﬁned as follows:
(cid:40)
d(N1,N2) =
if N1 = N2.
1,
0, otherwise.
(2)
We observe that the two classes are unbalanced, i.e., the
number of samples in the “High” class is much smaller than
the number of samples in the “Low” class. This is because
when a vehicle is moving on a map with predeﬁned roads,
for most of the time, it is moving straight and the trajectory
curvature is small. Due to the correlation between the number
of particles and the curvature, as mentioned in Section 4.1,
more samples in the “Low” particles-number class are seen.
Traditional binary classiﬁers such as SVM [36] do not perform
well on such unbalanced datasets. To address the problem,
we use RUSBoost [62], a classiﬁcation algorithm designed to
alleviate class imbalance in the dataset. RUSBoost combines
both random undersampling (RUS) and boosting to improve
classiﬁcation accuracy.
Figure 6 shows an example of the prediction of the num-
ber of particles in AMCL (max/min number of particles
16,000/500) using RUSBoost on the cache timing channel
information collected from the L1D cache of an Intel proces-
sor. The model correctly predicted the timing of events where
there exists a spike in the number of particles. To evaluate pre-
diction quality, we use Dynamic Time Warping (DTW) [61],
a popular metric for measuring similarity of two temporal
sequences. DTW allows us to compare two sequences even
when the exact locations of spikes are slightly off. The DTW
distance between the predicted and the ground truth is 539,407
864    29th USENIX Security Symposium
USENIX Association
Particle Predictor: predict the number of particles based on cache timing Route Predictor: predict the route/location using a sequence of particle classesPrime+probe:cache probe time depends on victimmemory access patternsCache timing vectorParticle-number classesVictim process executionThe label of the route/location of the vehicle123456789101112131415161718192021222324252627282930Prime+probe trial12345678910111213141516Cache set indexProbing Time (cycles)50100150200250300350400450500Figure 6: Ground truth and predicted number of particles
using RUSBoost on AMCL running on Intel i5-3317u.
Method
RUSBoost
SVM
Train