Figure 9: Degradation of ˆy(k) due to a zero-alarm
attack for scenario 2.
Figure 6). Figure 7 depicts similar results for the CUSUM
procedure under the corresponding zero-alarm attack. Here,
we note that the residual under the zero-alarm attack con-
verges to bi after the attack starts. For both procedures, un-
der zero-alarm attacks, note that (Figures 6 and 7) the state
estimate converges to steady state, i.e., it remains bounded.
This is expected in scenario 1 because ρ(A)  1 which implies
that ||E[ek]|| diverges. Similar results are obtained for the
CUSUM (see Figure 11). Figure 9 compares the output es-
timate degradation between the bad-data and CUSUM pro-
cedures under zero-alarm attacks. Note that although both
estimates diverge, the CUSUM leads to slower divergence
rate than the bad-data procedure.
In Tables 1 and 2, the alarm rates for scenario 1 and sce-
nario 2 are presented respectively. In both tables, each col-
umn shows the rate of alarms produced by sensor measure-
ment for both detectors. Outputs 1-4, represent the pres-
sure sensors at the four consumer nodes (Node 4-7). Out-
0100200300400500600700800K020406080100120140160180Output EstimateCUSUMBad-Data109Figure 10: Bad-data detection method under a zero-alarm attack for scenario 2.
put 5 is the level sensor in the storage tank. Each row label
in Table 1, presents a key1:key2 pair where key1 is detec-
tion method and key2 is attack scenario, e.g., bad-data:bias
attack, presents results for bad-data detector under a bias
attack. In scenario 1 (Table 1), the attack is referred to ad-
dition of a bias value in the output measurement from the
level sensor. This attack starts at time slot k = 150.
In
the no attack scenario we see the performance of the bad-
data and CUSUM detectors as expected, i.e., alarm rate (for
attack) is equal to the false alarm rate of 1%. In the bias at-
tack case of scenario 1, the alarm rate goes up to 79% which
implies that this attack is easily detected based on detector
alarms. Considering that the ﬁrst 20% of the measurements
correspond to normal operation (for visualizing the eﬀects
of the attack), the rest of the attacked readings result in
an alarm showing that such a bias attack is easily found by
these detection schemes. For the zero-alarm attack, results
show very small alarm rate as these attacks are designed not
to raise alarms. For zero-alarm attacks, if we start attack
from beginning of the measurements, we get 0% alarm rate.
For scenario 2 (Table 2), we observe that when the system
is under attack the alarm rate is higher than compared to
normal operation. Since, the attack in this case is on con-
trol inputs and we do not know when the attack starts and
ﬁnishes. Thresholds are calculated for 1% false alarm rate
but for attacks on input, the alarm rate reached 20%, which
is much higher than the normal false alarm rate. So, we can
point out that the system is under attack. This also points
to the fact that if the system is being attacked at inputs,
such attacks can be detected by using output measurements
of the system. The zero-alarm attacks are created for sensor
attacks, not actuator attacks, so it is not surprising that we
are able to detect when attacks are initiated on the inputs.
6. CONCLUSION
In this manuscript, for the model of a water distribution
network, we have explained step by step how to construct
model-based attack detectors for identifying compromised
sensors and actuators.
In particular, a Kalman ﬁlter has
been proposed to estimate the state of the physical process;
then, these estimates have been used to construct residual
variables (diﬀerence between sensor measurements and esti-
mations) which drive the CUSUM procedure. For a class of
zero-alarm attacks, we have characterized the performance
110Figure 11: CUSUM detection method under a zero-alarm attack for scenario 2.
of the proposed detection procedures in terms of the eﬀect
that the attack sequence can induce on the system dynam-
ics, namely in the output estimate. Then, we have compared
performance of CUSUM and Bad-Data method against each
other. We have shown how bias attacks (and most proba-
bly any output-injection attack as well) are easily detected
using fault-detection techniques as long as the statistics of
the residuals (in the attack-free case) are well characterized.
Moreover, input-injection attacks are also detected easily
using the proposed methods. Numerical simulations show
the eﬀectiveness of the proposed methods against diﬀerent
classes of attacks.
7. ACKNOWLEDGMENTS
This work was supported by the National Research Foun-
dation (NRF), Prime Minister’s Oﬃce, Singapore, under
its National Cyber Security R&D Programme (Award No.
NRF2014NCR-NCR001-40) and administered by the Na-
tional Cybersecurity R&D Directorate.
8. REFERENCES
[1] EPANET: software that models the hydraulic and
water quality behavior of water distribution piping
systems. https://www.epa.gov/water-research/epanet.
Accessed: 2016-03-29.
[2] I. C. 2014. Ics-mm201408: May-august 2014. Report
no., U.S. Department of Homeland Security-Industrial
Control Systems-Cyber Emergency Response Team,
Washington, D.C. Available online at
https://ics-cert.us-cert.gov., 2014.
[3] B. Adams, W. Woodall, and C. Lowry. The use (and
misuse) of false alarm probabilities in control chart
design. Frontiers in Statistical Quality Control 4,
pages 155–168, 1992.
[4] C. M. Ahmed, A.Sridhar, and M. Aditya. Limitations
of state estimation based cyber attack detection
schemes in industrial control systems. In IEEE Smart
City Security and Privacy Workshop, CPSWeek, 2016.
[5] S. Amin, X. Litrico, S. Sastry, and A. M. Bayen.
Cyber security of water scada systems-part i: analysis
and experimentation of stealthy deception attacks.
IEEE Transactions on Systems Technology, pages
1963–1970, 2013a.
[6] S. Amin, X. Litrico, S. Sastry, and A. M. Bayen.
Cyber security of water scada systems-part ii: Attack
detection using enhanced hydrodynamic models. IEEE
Transactions on Systems Technology, pages
1679–1693, 2013b.
[7] K. J. Astr¨om and B. Wittenmark.
Computer-controlled Systems (3rd Ed.). Prentice-Hall,
Inc., Upper Saddle River, NJ, USA, 1997.
111[24] M. Ross. Introduction to Probability Models, Ninth
Edition. Academic Press, Inc., Orlando, FL, USA,
2006.
[25] J. Slay and M. Miller. Lessons learned from the
maroochy water breach. Springer 620 US, Boston,
MA, pages 73–82, 2008.
[26] A. Sridhar and M. Aditya. Generalized attacker and
attack models for cyber physical systems. In 40th
IEEE COMPSAC, 2016.
[27] C. van Dobben de Bruyn. Cumulative sum tests :
theory and practice. London : Griﬃn, 1968.
APPENDIX
A. STATE SPACE MATRICES FOR
SCENARIO-2 AND SCENARIO-1
In what follows, we present the state space matrices
(A, B, C), obtained using sub-space system identiﬁcation.
For scenario-2, more than 70% accuracy is achieved by a
10th order model and for scenario-1 by a 20th order model.
Therefore, we have system matrix A2 as a 10 x 10 and A1
as a 20 x 20. For a 6 inputs (4 user demands, ﬂow at the
pumping station, ON/OFF status of the pumping station),
matrix dimensions for B2 are 10 x 6 and for B1 are 20 x
6. For 5 outputs, the dimensions for matrix C2 are, 5 x 10
and for C1 are, 5 x 20. Using these state space matrices
and system model of (1), one can ﬁnd the dynamics of the
system evolution.
[8] A. Bobat, T. Gezgin, and H. Aslan. The scada system
applications in management of yuvacik dam and
reservoir. Desalination and Water Treatment, 2015.
[9] A. Cardenas, S. Amin, Z. Lin, Y. Huang, C. Huang,
and S. Sastry. Attacks against process control systems:
Risk assessment, detection, and response. In 6th ACM
Symposium on Information, Computer and
Communications Security, pages 355–366, 2011.
[10] J. Giraldo, A. Cardenas, and N. Quijano. Integrity
attacks on realtime pricing in smart grids: Impact and
countermeasures. IEEE Transactions on Smart Grid,
2016.
[11] Y. Gu, T. Liu, D. Wang, X. Guan, and Z. Xu. Bad
data detection method for smart grids based on
distributed estimation. In IEEE ICC, 2013.
[12] R. A. Horn and C. R. Johnson. Matrix Analysis.
Cambridge University Press, New York, NY, USA,
2nd edition, 2012.
[13] C. Kwon, W. Liu, and I. Hwang. Security analysis for
cyber-physical systems against stealthy deception
attacks. In American Control Conference (ACC),
pages 3344–3349, 2013.
[14] E. A. Lee. Cyber physical systems: Design challenges.
In EECS Department, University of California,
Berkeley, Tech. Rep. UCB/EECS-2008-8.
http://www.eecs.berkeley.edu/Pubs/TechRpts/2008/EECS-
2008-8.html, Jan.
2008.
[15] N. Lehtinen. Error functions. Stanford
University,Webpage:http://nlpc.stanford.edu/nleht/
Science/reference/errorfun.pdf, April 2010.
[16] F. Miao, Q. Zhu, M. Pajic, and G. J. Pappas. Coding
sensor outputs for injection attacks detection. In IEEE
conference in Decision and Control (CDC), pages
5776–5781, 2014.
[17] L. Mili, T. Cutsen, and M.R.-Pavella. Bad data
identiﬁcation methods in power system state
estimation - a comparative study. IEEE Trans. on
Power Apparatus and Systems, 1985.
[18] Y. Mo, E. Garone, A. Casavola, and B. Sinopoli. False
data injection attacks against state estimation in
wireless sensor networks. In IEEE conference in
Decision and Control (CDC), pages 5967–5972, 2010.
[19] C. Murguia and J. Ruths. Characterization of a cusum
model-based sensor attack detector. In 55th IEEE
Conference on Decision and Control Conference
(CDC), 2016.
[20] C. Murguia and J. Ruths. Cusum and chi-squared
attack detection of compromised sensors. In 2016
IEEE Conference on Control Applications (CCA),
pages 474–480, Sept 2016.
[21] P. V. Overschee and B. D. Moor. Subspace
identiﬁcation for linear systems: theory,
implementation, applications. Boston: Kluwer
Academic Publications, 1996.
[22] E. Page. Continuous inspection schemes. Biometrika,
41:100–115, 1954.
[23] L. Perelman and S. Amin. A network interdiction
model for analyzing the vulnerability of water
distribution systems. In Proceedings of the 3rd
international conference on High conﬁdence networked
systems, ACM., pages 135–144, 2014.
1120.9774 −0.0190 −0.0747
0.0154 −0.0717 −0.1313 −0.0721
0.0649
0.1173
0.0246
−0.0054
0.9184 −0.3095
0.0309 −0.2480 −0.0283 −0.0595 −0.0388
0.0565
0.0813
−0.0196 −0.2107 −0.6614 −0.6767 −0.0330
0.0107
0.1525
0.0392
0.0137
0.0321
−0.0262
0.0299 −0.0964
0.1403 −0.0136
0.8360 −0.1407 −0.1406 −0.0304
0.2753
0.7830 −0.7442 −0.0968 −0.0499
0.0277 −0.0121
0.0095
0.1986
0.0126
0.0426
0.0716 −0.0264
0.1560 −0.1839 −0.1363
0.1686
0.1303
0.0778
0.1427
0.7906
0.0633 −0.2296
0.2045 −0.1912
0.0632
0.0876
0.1279
0.0159
0.9815
0.0160
0.0095 −0.0425 −0.0630
0.0746 −0.2460 −0.0816