improving security in various use cases.
Applicability The approach presented relies on the as-
sumption that the use case of the system is clearly deﬁned.
Thanks to this a-priori knowledge, it is possible to deter-
mine which kernel functionalities the application requires
and therefore, which kernel conﬁguration options have to
be enabled. With the increasing importance of compute
clouds, where customers use virtual machines for very ded-
icated services such as the LAMP stack presented in Sec-
tion 4, we expect that our approach will prove valuable for
improving the security in many cloud deployments.
Usability Most of the steps presented in Section 3 re-
quire no domain-speciﬁc knowledge of Linux internals. We
therefore expect that they can be conducted in a straight-
forward manner by system administrators without speciﬁc
experience in Linux kernel development. The system ad-
ministrator, however, continues to use a code base that con-
stantly receives maintenance in the form of bug ﬁxes and
security updates from the Linux distributor. We therefore
are conﬁdent that our approach to tailor a kernel conﬁgu-
ration for speciﬁc use-cases automatically is both practical
and feasible to implement in real-world scenarios.
Extensibility The experiments in Section 4 show that, for
proper operation, the resulting kernel requires eight addi-
tional KCONFIG options, which the ftrace feature could
not detect. By using a whitelist mechanism, we demon-
strate the ability to specify wanted or unwanted KCONFIG
options independently of the tracing. This allows our ap-
proach to be assisted in the future by methods to determine
kernel features that tracers such as ftrace cannot observe.
Safety Many previous approaches that reduce the Linux
kernel’s TCB (e.g., [17], [24]) introduce additional security
infrastructure in form of code that prevents functionality in
the kernel from being executed, which can lead to unex-
pected impacts and the introduction of new defects into the
kernel. In contrast, our approach modiﬁes the kernel con-
ﬁguration instead of changing the kernel sources (e.g., [25,
48]) or modifying the build process (e.g., [12]).
In that
sense, our approach, by design, cannot introduce new de-
fects into the kernel.
However, as the conﬁgurations produced are speciﬁc to
the use case analyzed in the tracing phase, we cannot rule
out that the tailored conﬁguration uncovers bugs that could
not be observed in the distribution-provided Linux kernel.
Although we have not encountered any of such bugs in prac-
tice, we would expect them to be rather easy to ﬁx, and
of rare occurence, as the kernels produced contain a strict
subset of functionality. In some ways, our approach could
therefore even help improve Linux by uncovering bugs that
are hard to detect.
This also emphasizes the importance of the analysis
phase, which must be sufﬁciently long to observe all nec-
essary functionality. In case of a crash or similar failure,
however, we could only attribute this to a bug in either the
kernel or the application implementation that needs to be
ﬁxed. In other words, this approach is safe by design.
6 Related work
This paper is related to previous research from many ar-
eas: improving OS kernel reliability and security, reducing
the attack surface of the kernel towards user-space applica-
tions, specializing kernels for embedded systems, measur-
ing attack surfaces, and code complexity.
Kernel specialization Several researchers have suggested
approaches to tailor the conﬁguration of the Linux kernel,
although security is usually not a goal. Instead, most of-
ten improvements in code size or execution speed are tar-
geted. For instance, Lee et al. [25] manually modify the
source code (e.g., by removing unnecessary system calls)
based on a static analysis of the applications and the ker-
nel. Chanet et al. [8], in contrast, propose a method based
on link-time binary rewriting, and also employ static analy-
sis techniques to infer and specialize the set of system calls
to be used. Both approaches, however, do not leverage any
of the built-in conﬁgurability of Linux to reduce unneeded
code. Moreover, our approach is completely automated and
it is signiﬁcantly safer, because we do not make any unsup-
ported changes to the kernel.
Micro-kernel architectures and retroﬁtting security
TCB size reduction has always been a major design goal
for micro-kernels [1, 27], and in turn facilitates a formal
veriﬁcation of the kernel [22] or its implementation in safer
languages, such as OCaml [29]. Our work achieves this goal
with a widely-used monolithic kernel, i.e., Linux, without
the need of new languages or concepts.
A number of approaches exist that retroﬁt micro-kernel–
like features into monolithic OS kernels, mostly targeting
fault isolation of kernel extensions such as device drivers [7,
31, 50]. For instance, the work of Swift et al. [50] wraps
calls from device drivers to the core Linux kernel API (and
vice-versa), as well as use virtual memory protection mech-
anisms, which leads to a more reliable kernel in the pres-
ence of faulty drivers. In the presence of a malicious at-
tacker who can compromise such devices, however, this is
in general insufﬁcient. This can be mitigated with more
involved approaches such as LXFI [31], which requires in-
terfaces between the kernel and extensions to be annotated
manually. An alternative is to prevent potential vulnerabil-
ities in the source code from being exploitable in the ﬁrst
place. For instance, Secure Virtual Architecture (SVA) [12]
compiles the existing kernel sources into a safe instruction
set architecture, which is translated to native instructions
by the SVA VM. This provides among other guarantees, a
variant of type safety and control ﬂow integrity. However,
it is very difﬁcult to recover from attacks (or false positives)
without crashing the kernel with such defenses [26]. In con-
trast, kernel tailoring only uses the built-in conﬁgurability
of Linux, hence kernel crashes can only be due to defects
already present in the kernel.
Kernel attack surface reduction The ISOLSEC model
used in this paper is commonly used when building sand-
boxes or isolation solutions, in which a set of processes
must be contained within a particular security domain (e.g.,
with [11, 18, 32], which are all based on the Linux Security
Module (LSM) framework [53]). As we have demonstrated,
adjusting the kernel conﬁguration also signiﬁcantly reduces
the attack surface in such a model (this corresponds to the
ISOLSEC model). The idea of directly restricting or moni-
toring for intrusion detection the system call interface on a
per-process basis has been extensively explored (e.g., [23,
41] and references in [14]), although not often with speciﬁc
focus on reducing the kernel’s attack surface (i.e., reduc-
ing AS1SLOC in the ISOLSEC model), or in other words, to
speciﬁcally prevent vulnerabilities in the kernel from being
exploited by reducing the amount of code reachable by an
attacker in this model
SECCOMP [17] directly tackles this issue by allowing
processes to be sandboxed at the system call interface.
KTRIM [24] goes beyond simply limiting the system call in-
terface, and explores the possibility of ﬁner-granularity ker-
nel attack surface reduction by restricting individual func-
tions (or sets of functions) inside the kernel. In contrast,
this work focuses on compile-time removal of functionality
from the kernel at a system-wide level instead of a runtime
removal at a per-application level. In future work, we will
investigate how dynamic approaches such as SECCOMP or
KTRIM can be combined with the static tailoring of the ker-
nel conﬁguration most effectively.
Analysis of variability in Linux This work relies on
static analysis to identify the implementation of variability
in Linux. Berger et al. [5] statically analyze the implemen-
tation and expressiveness of the variability declaration lan-
guages of Linux and eCos, an operating systems targeted
at embedded systems, with the goal to extract a reliable
feature-to-code mapping.
In our approach, we make use
of this mapping for Linux when establishing the proposi-
tional formula from the identiﬁed source line locations in
the traces (Step  in Figure 4). The work of Berger et al.
[5] is continued in a follow-up publication [4] and by Nadi
and Holt [37], which analyze implementation anomalies in
KBUILD. Unfortunately, both extractors are based on pars-
ing MAKE ﬁles, which turns out to be error-prone or to re-
quire adaptations for each new Linux kernel version [13].
We therefore use an improved version of the GOLEM tool by
Dietrich et al. [13], which extracts variability from KBUILD
with a sufﬁcient accuracy for this work.
The variability extracted the GOLEM tool is combined
with the variability model used by the UNDERTAKER
tool, which checks for conﬁguration inconsistencies in
Linux [52]. Conﬁguration inconsistencies manifest them-
selves in #ifdef blocks that are only seemingly conﬁg-
urable, but in fact are not in any KCONFIG conﬁguration.
While in this work we do not aim to improve the Linux im-
plementation, we have extended the UNDERTAKER tool to
generate the tailored conﬁgurations. The necessary mod-
iﬁcations were straightforward to implement, and we will
include them into the next public release.
Complexity, security metrics, and attack surface The
need for better security metrics is widely accepted in both
academia and industry [3, 21, 43, 49]. Howard, Pincus,
and Wing [20] were the ﬁrst to propose the use of code
complexity and bug count metrics to compare the relative
“attackability” of different software, and others have fol-
lowed [30, 45, 47]. Murray, Milos, and Hand [36] underline
the fact that TCB size measurements by SLOC, while good,
might not be precise enough because additional code can
sometimes reduce the attack surface (e.g., sanitizing input).
Manadhata and Wing [30] present an attack surface met-
ric based on an insightful I/O automata model of the target
system, taking into account in particular the data ﬂow from
untrusted data items and the entry points of the system. The
deﬁnition of attack surface used in their work closely re-
lates to ours, with the differences that our modeling is solely
based on static call graphs and a measure of code complex-
ity of each underlying function. In contrast, this work mea-
sures the attack surface with respect to a particular attacker
model.
7 Conclusion
Linux distributions ship “generic” kernels, which con-
tain a considerable amount of functionality that is provided
just in case. For instance, a defect in an unnecessarily pro-
vided driver may be sufﬁcient for attackers to take advan-
tage of. The genericalness of distribution kernels, however,
is unnecessary for concrete use cases. This paper presents
an approach to optimize the conﬁguration of the Linux ker-
nel. The result is a hardened system that is tailored to a
given use case in an automated manner. We evaluate the se-
curity beneﬁts by measuring and comparing the attack sur-
face of the kernels that are obtained. The notion of attack
surface is formally deﬁned and evaluated in a very generic
security model, as well as a security model taking precisely
into account the threats posed by a local unprivileged at-
tacker.
We apply the prototype implementation of the approach
in two scenarios, a Linux, Apache, MySQL and PHP
(LAMP) stack and a graphical workstation that serves data
via network ﬁle system (NFS). The resulting conﬁguration
leads to a Linux kernel in which unnecessary functionality
is removed at compile-time and thus, inaccessible to attack-
ers. We evaluate this reduction using a number of different
metrics, including SLOC, the cyclomatic complexity and
previously reported vulnerability reports, resulting in a re-
duction of the attack surface between about 50% and 85%.
Our evaluations also indicate that this approach reduces the
attack surface of the kernel against local attackers signif-
icantly more than previous work on kernel extension iso-
lation for Linux. We are convinced that the presented ap-
proach improves the overall system security and is practical
for most use cases because of its applicability, effectiveness,
ease and safety of use.
Acknowledgments
This research has been partially supported by the
TClouds project4 funded by the European Union’s Sev-
enth Framework Programme (FP7/2007-2013) under grant
agreement number ICT-257243.
References
[1] Mike Accetta, Robert Baron, David Golub, Richard Rashid,
Avadis Tevanian, and Michael Young. “MACH: A New
Kernel Foundation for UNIX Development”. In: Proceed-
ings of the USENIX Summer Conference. 1986, pages 93–
113.
[2] Mikhail Belkin and Partha Niyogi. “Laplacian Eigenmaps
and Spectral Techniques for Embedding and Clustering”.
In: Advances in Neural Information Processing Systems 14.
2001, pages 585–591.
[3] S.M. Bellovin. “On the Brittleness of Software and the In-
feasibility of Security Metrics”. In: Security Privacy, IEEE
4.4 (2006), page 96. ISSN: 1540-7993. DOI: 10 . 1109 /
MSP.2006.101.
[4] Thorsten Berger, Steven She, Krzysztof Czarnecki, and An-
drzej Wasowski. Feature-to-Code Mapping in Two Large
Product Lines. Technical report. University of Leipzig
(Germany), University of Waterloo (Canada), IT University
of Copenhagen (Denmark), 2010.
[5] Thorsten Berger, Steven She, Rafael Lotufo, and Andrzej
Wasowski und Krzysztof Czarnecki. “Variability Model-
ing in the Real: A Perspective from the Operating Sys-
tems Domain”. In: Proceedings of the 25th IEEE/ACM In-
ternational Conference on Automated Software Engineer-
ing (ASE ’10). (Antwerp, Belgium). 2010, pages 73–82.
ISBN: 978-1-4503-0116-9. DOI: 10 . 1145 / 1858996 .
1859010.
[6] N. Biggs. Algebraic Graph Theory. 1974.
[7] Miguel Castro, Manuel Costa, Jean-Philippe Martin, Mar-
cus Peinado, Periklis Akritidis, Austin Donnelly, Paul
Barham, and Richard Black. “Fast byte-granularity soft-
ware fault isolation”. In: Proceedings of the ACM SIGOPS
22nd symposium on Operating systems principles. SOSP
’09. 2009, pages 45–58. ISBN: 978-1-60558-752-3. DOI:
10.1145/1629575.1629581.
4http://www.tclouds-project.eu
[8] Dominique Chanet, Bjorn De Sutter, Bruno De Bus, Ludo
Van Put, and Koen De Bosschere. “System-wide Com-
paction and Specialization of the Linux Kernel”. In: Pro-
ceedings of the 2005 ACM SIGPLAN/SIGBED Conference
on Languages, Compilers and Tools for Embedded Systems
(LCTES ’05). 2005, pages 95–104. ISBN: 1-59593-018-3.
DOI: 10.1145/1065910.1065925.
[9] Andy Chou, Junfeng Yang, Benjamin Chelf, Seth Hallem,
and Dawson Engler. “An empirical study of operating sys-
tems errors”. In: Proceedings of the 18th ACM Symposium
on Operating Systems Principles (SOSP ’01). (Banff, Al-
berta, Canada). 2001, pages 73–88. ISBN: 1-58113-389-8.
DOI: 10.1145/502034.502042.
[10] Russell Coker. Bonnie++. Benchmark suite for hard drive
and ﬁle system performance. URL: http : / / www .
coker.com.au/bonnie++/ (visited on 08/02/2012).
[11] Kees Cook. Yama LSM. 2010. URL: http://lwn.net/
[12]
Articles/393012/ (visited on 06/04/2012).
John Criswell, Andrew Lenharth, Dinakar Dhurjati, and