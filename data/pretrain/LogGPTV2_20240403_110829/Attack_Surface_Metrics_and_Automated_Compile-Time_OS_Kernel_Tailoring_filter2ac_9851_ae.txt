### Enhancing Security in Various Use Cases

#### Applicability
The proposed approach is based on the assumption that the system's use case is clearly defined. With this a-priori knowledge, it is possible to determine which kernel functionalities are required and, consequently, which kernel configuration options need to be enabled. Given the increasing importance of compute clouds, where customers use virtual machines for highly specialized services (such as the LAMP stack discussed in Section 4), we anticipate that our approach will significantly enhance security in many cloud deployments.

#### Usability
Most of the steps outlined in Section 3 do not require in-depth knowledge of Linux internals. Therefore, we expect that system administrators without specific experience in Linux kernel development can follow these steps straightforwardly. The system administrator continues to use a codebase that receives regular maintenance, including bug fixes and security updates from the Linux distributor. This ensures that our approach to automatically tailor a kernel configuration for specific use cases is both practical and feasible in real-world scenarios.

#### Extensibility
The experiments in Section 4 demonstrate that, for proper operation, the resulting kernel requires eight additional KCONFIG options, which ftrace cannot detect. By using a whitelist mechanism, we show that it is possible to specify desired or unwanted KCONFIG options independently of tracing. This allows our approach to be enhanced in the future by methods that can identify kernel features undetectable by tracers like ftrace.

#### Safety
Many previous approaches aimed at reducing the Linux kernel's TCB (e.g., [17], [24]) introduce additional security infrastructure, often in the form of code that prevents certain kernel functionalities from being executed. This can lead to unexpected impacts and the introduction of new defects into the kernel. In contrast, our approach modifies the kernel configuration rather than changing the kernel sources (e.g., [25, 48]) or the build process (e.g., [12]). By design, our approach cannot introduce new defects into the kernel.

However, since the configurations produced are specific to the use case analyzed during the tracing phase, there is a possibility that the tailored configuration may uncover bugs not observed in the distribution-provided Linux kernel. Although we have not encountered such bugs in practice, we expect them to be relatively easy to fix and rare, given that the kernels produced contain a strict subset of functionality. In some ways, our approach could even help improve Linux by revealing hard-to-detect bugs.

This underscores the importance of the analysis phase, which must be sufficiently long to observe all necessary functionality. In the event of a crash or similar failure, we can attribute this to a bug in either the kernel or the application implementation, which needs to be fixed. In other words, this approach is inherently safe by design.

### Related Work

This paper builds on research from several areas, including improving OS kernel reliability and security, reducing the attack surface of the kernel towards user-space applications, specializing kernels for embedded systems, measuring attack surfaces, and analyzing code complexity.

#### Kernel Specialization
Several researchers have suggested methods to tailor the Linux kernel configuration, primarily focusing on improving code size or execution speed rather than security. For example, Lee et al. [25] manually modify the source code by removing unnecessary system calls based on static analysis of applications and the kernel. Chanet et al. [8] propose a method based on link-time binary rewriting, also employing static analysis to infer and specialize the set of system calls. However, these approaches do not leverage the built-in configurability of Linux to reduce unneeded code. Our approach, on the other hand, is fully automated and significantly safer, as we do not make any unsupported changes to the kernel.

#### Micro-kernel Architectures and Retrofitting Security
Reducing the TCB size has been a major design goal for micro-kernels [1, 27], facilitating formal verification of the kernel [22] or its implementation in safer languages like OCaml [29]. Our work achieves this goal with the widely-used monolithic Linux kernel, without requiring new languages or concepts.

Several approaches retrofit micro-kernel-like features into monolithic OS kernels, primarily targeting fault isolation of kernel extensions such as device drivers [7, 31, 50]. For instance, Swift et al. [50] wrap calls from device drivers to the core Linux kernel API and use virtual memory protection mechanisms, leading to a more reliable kernel in the presence of faulty drivers. However, in the presence of a malicious attacker, this is generally insufficient. More involved approaches, such as LXFI [31], require manual annotation of interfaces between the kernel and extensions. An alternative is to prevent potential vulnerabilities in the source code from being exploitable. Secure Virtual Architecture (SVA) [12] compiles the existing kernel sources into a safe instruction set architecture, providing type safety and control flow integrity. However, recovering from attacks without crashing the kernel is challenging [26]. In contrast, kernel tailoring uses the built-in configurability of Linux, ensuring that kernel crashes can only be due to pre-existing defects.

#### Kernel Attack Surface Reduction
The ISOLSEC model used in this paper is commonly applied in building sandboxes or isolation solutions, where a set of processes must be contained within a particular security domain (e.g., [11, 18, 32], based on the Linux Security Module (LSM) framework [53]). Adjusting the kernel configuration significantly reduces the attack surface in this model. Restricting or monitoring the system call interface on a per-process basis for intrusion detection has been extensively explored (e.g., [23, 41]), but not often with a focus on reducing the kernel’s attack surface (i.e., reducing AS1SLOC in the ISOLSEC model).

SECCOMP [17] directly addresses this issue by allowing processes to be sandboxed at the system call interface. KTRIM [24] goes further by restricting individual functions or sets of functions inside the kernel. In contrast, our work focuses on compile-time removal of functionality from the kernel at a system-wide level rather than runtime removal at a per-application level. Future work will investigate how dynamic approaches like SECCOMP or KTRIM can be combined with the static tailoring of the kernel configuration for maximum effectiveness.

#### Analysis of Variability in Linux
Our work relies on static analysis to identify the implementation of variability in Linux. Berger et al. [5] analyze the variability declaration languages of Linux and eCos, an operating system targeted at embedded systems, to extract a reliable feature-to-code mapping. We use this mapping when establishing the propositional formula from the identified source line locations in the traces (Step 3 in Figure 4). Berger et al. [5] continue their work in a follow-up publication [4], and Nadi and Holt [37] analyze implementation anomalies in KBUILD. Unfortunately, both extractors are based on parsing MAKE files, which can be error-prone or require adaptations for each new Linux kernel version [13].

We use an improved version of the GOLEM tool by Dietrich et al. [13], which extracts variability from KBUILD with sufficient accuracy for our purposes. The extracted variability is combined with the variability model used by the UNDERTAKER tool, which checks for configuration inconsistencies in Linux [52]. While we do not aim to improve the Linux implementation, we have extended the UNDERTAKER tool to generate the tailored configurations. The necessary modifications were straightforward to implement and will be included in the next public release.

#### Complexity, Security Metrics, and Attack Surface
The need for better security metrics is widely recognized in both academia and industry [3, 21, 43, 49]. Howard, Pincus, and Wing [20] were the first to propose using code complexity and bug count metrics to compare the relative "attackability" of different software. Others have followed [30, 45, 47]. Murray, Milos, and Hand [36] note that TCB size measurements by SLOC, while useful, may not be precise enough because additional code can sometimes reduce the attack surface (e.g., by sanitizing input). Manadhata and Wing [30] present an attack surface metric based on an I/O automata model of the target system, considering data flow from untrusted items and system entry points. Our modeling is solely based on static call graphs and a measure of code complexity of each underlying function, and measures the attack surface with respect to a particular attacker model.

### Conclusion
Linux distributions typically ship "generic" kernels, containing a considerable amount of functionality provided just in case. A defect in an unnecessarily provided driver can be exploited by attackers. However, this generality is unnecessary for specific use cases. This paper presents an approach to optimize the Linux kernel configuration, resulting in a hardened system tailored to a given use case in an automated manner. We evaluate the security benefits by measuring and comparing the attack surface of the obtained kernels. The notion of attack surface is formally defined and evaluated in a generic security model and a model that precisely accounts for threats posed by local unprivileged attackers.

We apply the prototype implementation of the approach in two scenarios: a LAMP stack and a graphical workstation serving data via NFS. The resulting configuration leads to a Linux kernel in which unnecessary functionality is removed at compile-time, making it inaccessible to attackers. We evaluate this reduction using various metrics, including SLOC, cyclomatic complexity, and previously reported vulnerability reports, resulting in a reduction of the attack surface between about 50% and 85%. Our evaluations indicate that this approach significantly reduces the attack surface against local attackers compared to previous work on kernel extension isolation for Linux. We are confident that the presented approach improves overall system security and is practical for most use cases due to its applicability, effectiveness, ease, and safety of use.

### Acknowledgments
This research was partially supported by the TClouds project, funded by the European Union’s Seventh Framework Programme (FP7/2007-2013) under grant agreement number ICT-257243.

### References
[1] Mike Accetta, Robert Baron, David Golub, Richard Rashid, Avadis Tevanian, and Michael Young. “MACH: A New Kernel Foundation for UNIX Development”. In: Proceedings of the USENIX Summer Conference. 1986, pages 93–113.
[2] Mikhail Belkin and Partha Niyogi. “Laplacian Eigenmaps and Spectral Techniques for Embedding and Clustering”. In: Advances in Neural Information Processing Systems 14. 2001, pages 585–591.
[3] S.M. Bellovin. “On the Brittleness of Software and the Infeasibility of Security Metrics”. In: Security Privacy, IEEE 4.4 (2006), page 96. ISSN: 1540-7993. DOI: 10.1109/MSP.2006.101.
[4] Thorsten Berger, Steven She, Krzysztof Czarnecki, and Andrzej Wasowski. Feature-to-Code Mapping in Two Large Product Lines. Technical report. University of Leipzig (Germany), University of Waterloo (Canada), IT University of Copenhagen (Denmark), 2010.
[5] Thorsten Berger, Steven She, Rafael Lotufo, and Andrzej Wasowski and Krzysztof Czarnecki. “Variability Modeling in the Real: A Perspective from the Operating Systems Domain”. In: Proceedings of the 25th IEEE/ACM International Conference on Automated Software Engineering (ASE ’10). (Antwerp, Belgium). 2010, pages 73–82. ISBN: 978-1-4503-0116-9. DOI: 10.1145/1858996.1859010.
[6] N. Biggs. Algebraic Graph Theory. 1974.
[7] Miguel Castro, Manuel Costa, Jean-Philippe Martin, Marcus Peinado, Periklis Akritidis, Austin Donnelly, Paul Barham, and Richard Black. “Fast byte-granularity software fault isolation”. In: Proceedings of the ACM SIGOPS 22nd symposium on Operating systems principles. SOSP '09. 2009, pages 45–58. ISBN: 978-1-60558-752-3. DOI: 10.1145/1629575.1629581.
[8] Dominique Chanet, Bjorn De Sutter, Bruno De Bus, Ludo Van Put, and Koen De Bosschere. “System-wide Compaction and Specialization of the Linux Kernel”. In: Proceedings of the 2005 ACM SIGPLAN/SIGBED Conference on Languages, Compilers and Tools for Embedded Systems (LCTES ’05). 2005, pages 95–104. ISBN: 1-59593-018-3. DOI: 10.1145/1065910.1065925.
[9] Andy Chou, Junfeng Yang, Benjamin Chelf, Seth Hallem, and Dawson Engler. “An empirical study of operating systems errors”. In: Proceedings of the 18th ACM Symposium on Operating Systems Principles (SOSP ’01). (Banff, Alberta, Canada). 2001, pages 73–88. ISBN: 1-58113-389-8. DOI: 10.1145/502034.502042.
[10] Russell Coker. Bonnie++. Benchmark suite for hard drive and file system performance. URL: http://www.coker.com.au/bonnie++/ (visited on 08/02/2012).
[11] Kees Cook. Yama LSM. 2010. URL: http://lwn.net/Articles/393012/ (visited on 06/04/2012).
[12] John Criswell, Andrew Lenharth, Dinakar Dhurjati, and