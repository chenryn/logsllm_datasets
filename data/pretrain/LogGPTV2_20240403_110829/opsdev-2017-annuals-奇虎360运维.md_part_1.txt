# OCR Output
## Page 1
奇虎360OPSDEVTEAM
年度精选
20I70PSDEV
资深业内架构师面对面
涵盖多个热门技术领域
云计算前沿技术经典汇总
奇虎运维开发
09E+
①OD
年刊
---
## Page 2
些文章汇集成册，编成《运维开发年度精选》，愿我们的点滴积累，给您带来一丝收获。
智能运维、运维开发、微服务、虚拟化等各个领域。为了更好的服务于团队内外，我们精选出-
定期将开发和研究成果整理成文，截至今日已原创了100多篇文章，文章内容丰富，涵盖容器、
研究。我们爱探索、爱创新、爱分享，2017年初我们开通了团队技术博客：www.opsdev.cn,
NeverStop!
大风起于青萍之末，巨浪成于微澜之间，在创新和探索的路上我们不会停止脚步。
NEVERSTOP
卷首语
2018年3月20日
许斯亮
---
## Page 3
无问西东。
听从你心，
行你所行，
爱你所爱，
坚信你的珍贵，
愿你在迷茫时，
抵抗恶意；
记起你的珍贵，
愿你在被打击时，
—摘自电影《无问西东》
---
## Page 4
机器学习
目录
智能预测之 CPU 预测－籍鑫璞
磁盘容量预测与处理机制－籍鑫璞
360DoctorStrange－籍鑫璞
Tensorflow on Kubernetes －籍鑫璞
时间序列异常检测机制的研究－籍鑫璞
Nova 从Kilo 升级到 Mitaka 遇到的坑－霍明明
诊断虚拟机频繁OOM的问题－霍明明
OpenStack中的网络隔离－王浩宇
带着问题了解Openstack Neutron安全组－李文新
虚拟化
Prometheus 落地实践－赵鹏
Nexus 初探－王浩宇 
微服务拆分那点事－王保平
ServiceMesh 数据面板 Envoy 简介－霍明明
微服务
Kubelet 源码分析－王希刚
Hulk 容器服务的镜像 CI 解决方案－王浩宇
我所理解的Kubernetes 架构－霍明明
Kubernetes 资源概览接口的研究－籍鑫璞
容器化
0川6
.888
8
６3７
9
18
¥１６16号
---
## Page 5
团队成员简介
期刊编辑
王浩宇 by opsdev
Prometheus及替代方案对比－赵鹏
Google BBR拥塞控制算法模型初探－康凯
翻译
团队开发项目环境搭建工具Rigger－李钢
人物访谈
如何优雅的升级内核－许斯亮
Wonder agent改造历程－高广鹏
Makefiles for Golang － 高广鹏 
读SRE Google运维解密有感 IV－许斯亮
读SRE Google运维解密有感Il - 许斯亮
读SRE Google运维解密有感Il－许斯亮
读SRE Google运维解密有感丨－许斯亮
运维开发
目录
2
---
## Page 6
将scheduler模块中调度的核心部分的流程图整理出来，如下图：
Scheduler模块工作流程
的过程是否能够完成，如果可以完成再最终创建。
需求的、更灵活的子系统--资源统计接口，能够在增加应用副本的时候，提前告诉用户该扩容
过计算CPU、memory来判断某个Pod是否能创建成功。
Pod好比虚拟机，因为scheduler有很多算法来筛选出最合适的Node，所以我们并不能单纯通
机，因为OpenStack的调度算法并不是单纯根据资源来筛选那么简单。对于Kubernetes来说
算机房资源的剩余情况会有偏差，有时候剩余资源满足flavor并不一定能在Node成功创建虚拟
背景
IKUBERNETES资源概览接口的研究
 在Kubernetes中，scheduler模块负责Pod的调度，为了说明scheduler工作原理，我们
借鉴以前Openstack调度的经验，单纯根据基础资源（如CPU、memory等使用量）来计
| Oct.13th 2017 BY 籍鑫璞
容器化
容器化－Kubernetes资源概览接口的研究
01
---
## Page 7
流程图
接口的Pod是通过参数传递的，两者有本质的区别。
块不同的是，scheduler调度的Pod是从PodQueue中获取的，而http服务器提供的资源统计
间处理的过程最重要的需要经过预选和assume的过程（后面会重点分析）。和scheduler模
http接口改造
资源概览接口实现思路
经过预选和优选过程后，我们会得到一个最优的Node。
选合适的Node，那么在Pod中能否指定Node呢？调度的过程分为预选（predict）和优选
Node进行绑定，Node的kubelet watch到绑定信息后拉起该Pod。scheduler的目的是为Pod筛
Node上创建的过程)，完成一个Pod的调度。
Node上面的资源先预先占取，最后是Node和Pod的绑定过程(bind，bind过程为真正将Pod在
经过这两个阶段后，选出最合适的Node，然后进入assume过程(图中AssumePod())，将
Queue中pop出需要调度的Pod(NextPod()，然后进入调度部分，分为预选和优选两个阶段。
-些http接口：
（priority）两个阶段：
/configz
02Kubernetes资源概览接口的研究－容器化
/healthz
/metrics
在scheduler模块中，
·优选策略，在第一步筛选的基础上，按照优选策略为待选Node打分排序，获取最优者；
列表，如没有Node符合Predicates策略规则，那该Pod就会被挂起，直到有Node能够满足;
·预选策略，是强制性规则，遍历所有的Node，按照具体的预选策略筛选出符合要求的Node
下图是资源统计接口的架构图:
我们可以在该基础上自己的一个路由，通过ur传入的参数，经过处理以后返回结果。中
 Kubernetes中scheduler组件负责为新创建的Pod选择合适的Node，并将该Pod和选择的
首先，scheduler中维护了一个需要调度的Pod队列--PodQueue，scheduler 从 Pod-
启动主程序时，同时启动了一个http服务器，该服务器对外提供了
---
## Page 8
实现方法
资源概览接口实现方法
会释放掉），assume应该被保留（因为是深拷贝了一份缓存，所以不会影响真正的调度过程）。
有真正将Pod调度到集群中的Node上，所以bind过程应该去掉。
该Pod。然后将进入assume和bind过程，无论是用户端的扩容还是管理端资源统计，我们并没
占用资源
度是否能够完成。
到优选到某个Node，只需要直到该Pod能否调度到集群，所以预选过程得到的Node足以直到调
选出分数最高的一个Node。为了解决用户端扩容和管理端资源统计的问题，我们并不需要精确
别的*v1.Pod类型。此时，我们已经拿到了需要调度的Pod，则需要进入调度函数。
调度算法
由于每次请求需要获取到集群中还有多少个“坑”，所以我们需要将资源临时占用（马上
如果通过预选得到的host数目大于O，则说明集群中还有“坑”（资源），可以“容纳”
预选过程得到的是符合条件的一些Node，优选再根据算法为每个Node去“打分”，从而
 通过参数获取到Pod的配置后，我们首先要做的是将Pod配置转化为scheduler模块可以识
为了防止用户在扩容或者创建dp时候调度失败的问题，在真正调度之前，需要向用户端
count初始化为
可创建pod的计算器
析成*v1.Pod
将pod的配置解
调用接口传参
客户端
中民
否，返回count
是
容器化－Kubernetes资源概览接口的研究
预选
Count加一
I
Assume
调度器
03
---
## Page 9
我们Pod配置做了精简，保留跟调度有关的配置，Pod模板如下：
在这里我们在预估资源量时也是使用Pod来进行的。使用“完整”的Pod，基于如下考虑：
该接口接收1个Pod配置，返回当前集群可以创建该Pod的总量。
为了实现该功能，我们提供了一个接口：
starthttp，建立了一个http服务器，我们可以利用该思想，添加一个http路由，来向外暴露接口
否则不提示用户资源不足（此时用户可以根据当前可用资源做出抉择）。Scheduler通过函数
返回一个能否创建的应答，告知用户当前能真正使用的资源量。如果资源满足需求则可以创建，
返回：可调度机器的数目
·只有使用用户当前应用的Pod配置才能准确的预估满足该Pod的资源量;
·符合原生Kubernetes调度的处理逻辑；
04Kubernetes资源概览接口的研究－容器化
 在OpenStack中调度的单位是虚拟机，那在Kubernetes中调度的基本单位是Pod，所以
---
## Page 10
本文链接： https://opsdev.cn/post/k8s-resource-overview.html 
A：像服务端暴露一个RESTFUL接口，方便服务端的调用。
的子系统－－资源统计接口，能够在增加应用副本的时候，提前告诉用户该扩容的过程是否能够完成，如果可以
http服务器接口整理：
statistic http服务器的基础上包装一层http服务器，如下图：
Q：既然已经有了资源概览接口，为什么还需要在此基础上封装一层http接口？
完成再最终创建。
筛选出最合适的Node，所以我们并不能单纯通过计算CPU、memory来判断某个Pod是否能创建成功。
A：借鉴以前OpenStack调度的经验，单纯根据基础资源（如CPU、memory等使用量）来计算机房资源的剩
Q：k8s的scheduler通过一系列的算法将Pod调度到最合适的Node上面，那为什么你们还要开发一套资源概览
可扩展性
并不是单纯根据资源来筛选那么简单。对于Kubernetes来说，Pod好比虚拟机，因为scheduler有很多算法来
余情况会有偏差，有时候剩余资源满足flavor并不一定能在Node成功创建虚拟机，因为OpenStack的调度算法
的接口？
面对面：
现有的k8s并没有一个类似的模块，因此，我们需要基于现有k8s的机制实现一个满足我们需求的、更灵活
返回可创建pod的数目
http:/
GET方式
/pod
//获取集群中可调度pod的数目
为了减轻服务端计算的压力，也为了后期资源统计模块的可扩展性，我们在之前介绍的
config=***
//hostname:port/statistics/user/add_pod
Http(restapi)
容器化－Kubernetes资源概览接口的研究
HULK
Http
扫一扫查看文章详情
口
05
---
## Page 11
按功能划分
是整个系统的控制中心，是大脑；而Slave是分布在各个节点的工作单元，是神经元。
按角色划分
先来看看k8s的架构图和各个组件
我理解的k8s
以上三个功能都是我们在构建容器化平台过程中,为适配公司现有生态而进行的一系列扩展。
在正式内容之前，先简单介绍下本人对k8s做的一些功能支持：
方欢迎大家指正。
码，对k8s的设计理念有了简单的认识。今天就给大家说一说自己的一些认识，认识不深的地
背景
■我所理解的KUBERNETES架构
·修改RollingUpdate逻辑，让滚动更新更加可控，业务升级更加平滑;
·自实现对接公司Qbus的日志收集控制器(log-controller);
·自实现对接公司LVS的负载均衡控制器(Ilb-controoller);
06我所理解的 Kubernetes 架构－容器化
按照角色划分，k8s和绝大多数分布式系统一样，分为Master和Slave两类。其中Master
搞Kubernetes（简称k8s）大约5个月的时间了，这期间因功能需要阅读并修改过部分源