end
return (X, waveList, traceList)
3.4 Reconstructing waves from a trace
We are now ready to split an execution trace into sub-
traces depending on their execution levels. From an execu-
tion trace D1, D2, . . . , Dn, we have previously described how
to compute the sequence of execution levels X1, X2, . . . , Xn.
It is not diﬃcult to see that this sequence is weakly mono-
tonic, that is Xi ≤ Xi+1 for all i = 1, n. The number of
waves observed in this execution trace is K = maxi(Xi) =
Xn. In other words, in our model of self-modiﬁcation, there
are K − 1 successive code self-modiﬁcation in this execu-
tion. As a result, we can extract K sub-traces of dynamic
instructions, which are deﬁned as follows:
trace(1) = D1, . . . , D(cid:96)1−1
where Xj = 1 for j = 1, (cid:96)1−1
trace(i) = D(cid:96)i , . . . , D(cid:96)i+1−1
where Xj = i for j = (cid:96)i, (cid:96)i+1 − 1
trace(K) = D(cid:96)K , . . . , Dn
where Xj = K for j = (cid:96)K , n
At the same time, we can also take a memory snapshot at
the beginning of each wave. Thus, we have K memory snap-
shots. Let us call wave(i) the memory snapshot at the be-
ginning of the i-th wave, that is before executing instruc-
tion D(cid:96)i . Notice that the memory snapshot wave(1) is the
snapshot of the starting code. As a result, our model of
self-modiﬁcation ensures that the memory snapshot wave(i)
contains any instruction in the trace trace(i) and probably
also other dormant instructions that we have to identify.
3.5 Overview of the wave recovery algorithm
The wave recovery algorithm is presented in Algorithm 2.
The input is a PE ﬁle that is loaded into memory. The ﬁrst
step of the algorithm initializes the write level table and
takes an initial snapshot of the memory wave(1). The ﬁrst
memory snapshot contains all the code and data that are
inside the PE ﬁle sections.
In a second step, the Pin Tracer executes code one state-
ment at a time as explained in Section 3.2. Pin Tracer runs
one instruction and, at each step, gathers the corresponding
dynamic instruction. Then, Pin Tracer computes the write
level table as described in Section 3.3. The index of the
current wave is given by X. We also gather all instructions
executed during the current wave in the list trace(X).
Finally, we determine the address of the next instruction
to be executed thanks to a Pin tool called Pin Next Instruction.
If the execution level of the next instruction increases, then
we know that Wave X ends there and that Wave X + 1
will start as soon as the next instruction will be executed.
Therefore, we take a memory snapshot wave(X + 1) of the
memory before the beginning of Wave X + 1. Otherwise, we
stay in the same wave and binary execution is resumed.
750A memory snapshot combines (i) the code and data in
a PE ﬁle, and (ii) all data stored in dynamically allocated
memory areas (e.g. malloc). It is necessary to consider dy-
namic memory allocations because it is possible to jump into
data that, for example, comes from a decryption loop.
3.6 Example
The introductory example (Figure 1) presents a decryp-
tion loop that generates two waves. The ﬁrst wave mainly
consists of the loop and trace(1) is composed of the nine
dynamic instructions in the interval [01006e62, 01006e82].
The second wave is triggered when the condition at address
01006e80 is false and the control is transferred to the address
01005090. trace(2) is composed of the dynamic instruction
in the interval [01005090, 01006e52]. Figure 8 illustrates the
execution of this example and provides the execution level X
and the write level table W. For example, take instruction
xor byte ptr [ebx+ecx], 0x67. The execution level is 1.
This instruction performs a memory write at the address
pointed by the value of ebx+ecx. Since the value of ebx+ecx
for that execution is 01006e82, we set W(01006e82) = 1.
3.7 Disassembly completeness
A discussion on disassembly completeness may seem quite
theoretical at ﬁrst glance. Nevertheless, it is a necessary di-
gression in order to be able to discuss disassembler evalua-
tion criteria in Section 5. We now put forth a deﬁnition of a
semantics for self-modifying programs. In Section 3.4, an ex-
ecution trace D = D1, . . . , Dn deﬁnes trace(i) correspond-
ing to the instructions run in the i-th wave. We call each sub-
trace a code wave. The set of all code waves of a trace D is
trace(D) = {trace(i) | i = 1..K where K is the last wave}.
We deﬁne the wave semantics of a given binary as a graph
G = (V, E) deﬁned as follows. The set of vertices V is the
set of all code waves for any execution trace, that is
(cid:91)
V =
trace(D)
for all traces D
Two vertices W and W (cid:48) are connected, that is (W, W (cid:48)) ∈ E
if W and W (cid:48) are two consecutive subtraces of a trace. In
other words, there is an execution where the successor of the
last instruction of W is the ﬁrst instruction of W (cid:48), or yet if
the wave denoted by W jumps to the wave denoted by W (cid:48)
in some execution.
As a result, the wave semantics is a graph G that repre-
sents all possible self-modiﬁcations of a binary and encodes
all possible execution paths. The wave semantics of a bi-
nary provides the partially ordered list of all instructions
that can be run. For that reason, the wave semantics G
could be used to mesure the correctness of a disassembler
(of self-modifying programs), because a perfect disassembly
of a binary should be able to reconstruct the graph G. Of
course, a perfect disassembler does not exist because the
problem of disassembling is undecidable; and from this fact,
the wave semantics is uncomputable. Any disassembler pro-
vides an approximation of the wave semantics. So at least
from a theoretical point of view, the distance with the wave
semantics may provide a metric to evaluate disassemblers.
4. OVERLAPPING INSTRUCTIONS
We now have all the necessary information to start the
second phase, which consists in disassembling the code of a
wave from a snapshot of the memory together with the trace
of the wave. Recall that inside a wave, there is no code
self-modiﬁcation. However, other obfuscations may occur,
in particular x86 overlapping instructions. In this section,
we address this issue. We present a recursive algorithm that
statically disassembles and correctly handles overlapping in-
structions.
Algorithm 3: Recursive disassembler, recovering over-
lapping instructions
input : The memory snapshot of a wave, its execution
trace and an empty set of layers
output: A set of layers resulting from the disassembled
disassembler(wave,trace)
wave
(cid:32)L← New();
Set layers ← {L};
foreach addr ∈ trace do
if addr (cid:54)∈ Set layers then
if the addr has not been processed ;
Set layers ← recursive traversal(wave, addr,
Set layers,L);
end
end
return Set layers
recursive_traversal(wave, addr, Set layers,L)
opcode ← disasm(wave, addr);
if ( addr,opcode) is aligned with L then
Add the instruction to an aligned layer ;
Add( L,addr,opcode);
else
Create a new layer with the instruction;
Lnew = New() ;
Add(Lnew,addr,opcode);
SetUnion(Set layers,Lnew);
end
foreach successor of ( addr,opcode) do
Set layers ← recursive traversal(wave,successor,
Set layers,L)
end
return Set layers
4.1 Layers
Two dynamic instructions overlap when they share at
least one byte in memory. We will say that a set of dy-
namic instructions is mis-aligned if at least two instructions
overlap. Otherwise, we will say that the instructions of this
set are aligned. Take again the teLock snippet in Figure 2
and look at Figure 6. The instructions jmp +1 and dec ecx
have the byte at address 0x01006e7e in common. So, they
are overlapping instructions. Both overlapping instructions
create two sequences of aligned dynamic instructions. Each
sequence forms what we will call a layer.
Before we deﬁne layers, we have to introduce the notion
of connected instruction set. A set L of instructions is con-
nected if given two instructions D and D(cid:48), there is a path
between D and D(cid:48) composed of instructions in L. That is,
there is a sequence D = D1, . . . , Dn = D(cid:48) of instructions in
L such that the instruction Di+1 is a successor of Di. The
successors of the instruction D are all the reachable instruc-
tions from D that we can predict. For example, a sequential
751After several iterations of the loop
After transferring the control to 01005090
A[D]
01006e62
01006e67
01006e6f loop:
01006e73
01006e76
01006e7a
01006e7d
01006e80
01006e82
0x01005090
0x01005091
I[D]
mov ecx, 0x1dc2
inc ebx
rol byte ptr [ebx+ecx], 0x5
add byte ptr [ebx+ecx], cl
xor byte ptr [ebx+ecx], 0x67
inc byte ptr [ebx+ecx]
dec ecx
jnle loop
jmp 0x01005090
decrypted byte
decrypted byte
W X
1
0
0
1
1
0
1
0
1
0
1
0
0
1
1
0
0
1
1
1
Wave 1: trace(1) instruction in [01006e62, 01006e82]
A[D]
01006e62
01006e67
01006e6f loop:
01006e73
01006e76
01006e7a
01006e7d
01006e80
01006e82
0x01005090
0x01005091
I[D]
mov ecx, 0x1dc2
inc ebx
rol byte ptr [ebx+ecx], 0x5
add byte ptr [ebx+ecx], cl
xor byte ptr [ebx+ecx], 0x67
inc byte ptr [ebx+ecx]
dec ecx
jnle loop
jmp 0x01005090
decrypted byte
decrypted byte
2
2
Wave 2: trace(2) instructions in [01005090, 01006e52]
W X
0
0
0
0
0
0
0
0
0
1
1
Figure 8: The two waves generated by the example in Figure 1
instruction like mov eax,ebx has one successor which is the
next instruction, while jnz 100 has two successors: the in-
struction at address 100 and the next one. On the other
hand, we may not be able to determine the successor of an
instruction like jmp eax if we have no certain value for the
register eax.
We now come to the second key notion. A layer L is a
set of dynamic instructions that satisﬁes the following two
properties: (i) two instructions in L never overlap, and (ii)
the set L is connected. Our objective is to construct a set
of layers that approximates the code inside a wave.
4.2 Disassembling algorithms
Algorithm 3 deﬁnes the disassembly procedure. Its inputs
are a memory snapshot wave of a given wave and its corre-
sponding sub-trace trace. Both inputs come from the ﬁrst
phase that we have presented in the previous section. The
algorithm inspects recursively the memory snapshot wave
from each address in the trace. For this, we begin with a
new empty layer. We disassemble recursively and we add
instructions to a layer in a consistent way. That is, we guar-
antee that layers are always a sequence of aligned instruc-
tions. When an instruction cannot be added to a layer in
a consistent way, that is, if the instruction overlaps at least
one other instruction in one of the already computed layers,
we create a new layer. We add the misaligned instruction to
the new layer. The new layer is added to the current set of
layers. As a result, we maintain during the disassembly a set
of coherent layers, such that: (i) no instruction inside the
layer overlaps another instruction in the same layer, and (ii)
if we take two layers in this set, then there are at least two
instructions from each layer which are mis-aligned. The out-
put is a set of coherent layers that together form an under-
approximation of the complete disassembled code inside a
wave.
Notice that this algorithm follows all found execution paths.
For example, when a conditional instruction like jcc is en-
countered, we follow both successors. Moreover, the trace
gives us some valuable additional information. For example,
Linn and Debray [23] propose to modify the return value on
the stack of a call as an obfuscation technique. In this case,
the trace immediately gives the correct return address and
thus provides a correct answer to this common technique.
4.3 Recovering an enhanced CFG
From each layer, we reconstruct a control ﬂow graph (CFG)
that we call pre-CFG. Since each layer is a connected set of
instructions, each pre-CFG is a connected graph. All pre-
CFG are connected together. Indeed, there is at least one
edge between a node of a pre-CFG and the root of another
pre-CFG, which comes from the instruction that creates the
overlap. Finally, a node can have multiple incoming edges
which corresponds to a resynchronization of the code.
We illustrate and sum-up the construction by an exam-
ple coming from the packer UPX. In Figure 9, we show the
two layers created by the conditional jump jnz +9. There-
fore, there are two pre-CFG that correspond to both layers
generated by UPX. The dashed edge corresponds to the in-
struction overlap due to the jnz +9 instruction. The code
resynchronizes at the push ebp instruction.
4.4 Speculative disassembly
At the end, we perform a speculative disassembly by run-
ning a linear sweep on unexplored pieces of memory, byte
by byte as Vigna [33] proposes. In order to identify valid
layers, that is to separate code from data, we apply well-
known heuristics employing pre-determined scoring [22] and
statistical methods
[21]. Finally, the trace is taken into
account to evaluate the probability of correctness of each
reconstructed disassembly.
5. EVALUATION
5.1 Methodology
In order to evaluate a disassembler, it is necessary to de-
ﬁne what we expect to be a correct output of a disassembler.
In the case of a regular binary code produced by a compiler,
it is suﬃcient to compare the disassembler output with the
compiler assembly output. But in the case of a heavily ob-
fuscated binary code like a malware, the evaluation of a
disassembler is a non-trivial problem that presents complex
challenges.
Before going further, we need to discuss what we mean by
a “correct disassembler”. A correct disassembler should only
output instructions which are in a possible execution path,
that is an approximation of the wave semantics as already
deﬁned and discussed in Section 3.7. Recall that the wave
semantics of a binary code provides the set of all instruc-
tions that can be run. Thus, it is important to measure the