We construct a detailed Internet map in order to evaluate the se-
curity of circuits produced by TorPS against a network adversary
that can observe or control pieces of the network infrastructure,
such as the network links, routers, and facilities that host this equip-
ment. This map, combined with path inference algorithms, allows
us to identify the autonomous systems and internet exchange points
traversed by our simulated Tor users.
We construct the network map at the AS level from two sources.
First, we consider links contained within BGP paths gathered dur-
ing March 2013 from eight geographically distributed RouteViews
routers [43]. We then supplement those links with additional ones
identiﬁed from traceroutes in the CAIDA IPv4 Routed /24 AS Links
Dataset from December 2012 [9]. This combined dataset produces
a graph consisting of 44605 ASes connected by 305381 links.
We use a layered approach to obtain a near-complete set of rela-
tionship information for the AS links contained in our graph. First,
we apply the heuristic algorithm originally suggested by Gao [21]
to our network graph. We then use relationships identiﬁed in the
CAIDA AS Relationships Dataset for July 2012, overwriting any
relationships previously identiﬁed through Gao’s algorithm as nec-
essary [10]. Finally, we use a set of sibling relationships heuristi-
cally identiﬁed from similarities in RIPE WHOIS records to cor-
rect misclassiﬁed sibling relationships. This approach results in
relationship assignments for 88% of the links in our dataset; those
links without relationships come primarily from the CAIDA IPv4
Routed /24 AS Links dataset, to which Gao’s algorithm cannot be
applied. We exclude links with missing relationships from our path
inference algorithm, which we describe next.
5.2.1 Autonomous System Path Inference
When considering autonomous systems as adversaries, those with
the capability to deanonymize Tor trafﬁc are those which exist upon
the AS path between the client and guard as well as between the
exit and destination. For each simulated client stream, we compute
the AS path from client to guard and exit to destination using the
algorithm proposed by Qiu which extends known AS paths drawn
from BGP tables to all ASes using a shortest path variant [33]. We
use these computed paths in our network adversary analysis in Sec-
tion 6.2.
Internet Exchange Point Map
5.2.2
In addition to autonomous systems, we are interested in the preva-
lence of Internet exchange points as another network administrative
domain which could compromise Tor circuits.
The IXP Mapping Project [4] gathers data about IXPs across the
Internet, and seeks to identify the ASes which peer at each IXP.
We use the IXP peerings dataset they provide to identify locations
along inferred AS paths where trafﬁc transits through an IXP. The
dataset contains 58524 AS peers which connect through 199 dis-
tinct IXPs. These peers represent 19.1% of the links in our network
map. In cases where multiple IXPs exist as peering locations be-
tween ASes, we include both IXPs. While this may slightly over-
state the ability of IXPs to compromise streams, selecting one at
random for each path may understate their ability. Our analysis in
Section 6.2 will focus on the potentially stronger adversary.
6. SECURITY ANALYSIS OF TOR
We evaluate the security of the Tor network against a range of
plausible adversaries and with respect to several metrics, with the
goal of yielding concrete numbers that are highly informative and
relevant to end users.
We consider two general types of adversaries. The ﬁrst is an
adversary that has the resources to run relays in the Tor network.
Speciﬁcally, we take bandwidth – both upload and download – to
be the limiting resource and consider an adversary that allocates
that bandwidth to Tor relays in order to deanonymize Tor users.
The second adversary is a network operator able to observe some
portion of the underlying network over which Tor trafﬁc is trans-
ported.
6.1 Relay Adversary
Adversaries who run relays represent the most plausible and well
understood threat to Tor users. Tor relays are run by volunteers
and the Tor Project applies no restrictions on operators. Clients
select relays for circuits roughly in proportion to relay bandwidth,
and thus the amount of trafﬁc that an adversary is in a position to
deanonymize is essentially only limited by the adversary’s band-
width. Bandwidth comes at a cost, however, and the Tor network is
large enough that overwhelming the Tor network could be expen-
341Rank
1
2
3
4
5
Bandwidth (MiB/s)
260.5
115.7
107.8
95.3
80.5
Largest family member
herngaard
chaoscomputerclub19
ndnr1
GoldDragon
Paint
Table 3: Top Tor families, 3/31/03 23:00. Bandwidth is minimum of aver-
age and observed.
sive. Thus we seek to establish an adversary with signiﬁcant but
reasonable bandwidth at its disposal.
We suppose that the adversary is able to contribute 100MiBps to
the Tor network. Table 3 shows the top ﬁve families listed in the last
consensus in March 2013, ordered by the smaller of their average
and observed bandwidths (self-reported in server descriptors) and
represented by the relay with the largest consensus bandwidth. We
can see that several organizations already contribute on the order of
100MiB/s to Tor. Bandwidth need not be provided by a single relay,
so an adversary could supply that bandwidth by controlling a large
botnet or by pooling the resources of a malicious collective. Fur-
thermore, as consumer broadband speeds continue to increase [31],
the cost for an adversary to pose a serious threat to the Tor network
will continue to decrease.
Tor has a non-trivial process for assigning selection weights in
the consensus that involves independently measuring node perfor-
mance and then applying a proportional integral derivative (PID)
feedback controller to minimize selection weight oscillation. Rather
than simulate this process, we use the fact that the “observed” band-
width numbers that relays report in their descriptors are correlated
with their consensus weights. We use linear regressions on the
relays in consensuses during the simulation period to convert the
bandwidths of the adversary’s relays to consensus weights. We use
separate regressions for guard relays and exit relays, which result
in correlations of determination of r2 = .71 and r2 = .69, respec-
tively.
Adversary Resource Allocation.
The adversary must determine
how best to allocate his bandwidth to maximize the chance of com-
promising streams. Because the same relay cannot be chosen twice
on a circuit, he must run at least two relays in order to perform
a correlation attack. We therefore suppose that the adversary tar-
gets one as a guard and one as an exit. We assume the malicious
guard relay provides enough uptime to obtain the GUARD ﬂag.
We assume that the malicious exit relay is not allowed to obtain
the GUARD ﬂag and is given an exit policy that allows exit to all
addresses and ports. Both relays will have sufﬁcient bandwidth to
obtain the FAST ﬂag.
To determine a good bandwidth allocation between the guard
and exit relay, we ran ﬁve experiments using TorPS that varied the
allocation of 100MiB/s of bandwidth between the guard and exit
relays. We tested guard-to-exit bandwidth ratios of 1:1, 2:1, 5:1,
10:1, and 50:1. Clients used the Typical user model over a sim-
ulated six-month period from October 2012 through March 2013.
The results, displayed in Figure 1, show that the expected rate of
exit compromise decreases as more bandwidth is allocated to the
guard. Thus an adversary must trade off between the likelihood of
obtaining a guard position and the volume of exit trafﬁc seen. A
5:1 guard-to-exit ratio maximized the probability of compromising
both sides of at least one stream during the simulation period, so
we adopt this ratio for the remainder of our experiments, as would
a strategic adversary.
Allocating more bandwidth to guards makes sense for the adver-
sary because, in the consensuses we use, exit-only relays are given
Figure 1: Probability to compromise at least one stream and rate of com-
promise, varying bandwidth allocation between guard and exit, 10/2012 –
3/2013.
a higher weight for use as an exit than guard-only relays are given
for use as a guard. In addition, obtaining a guard is far more impor-
tant for compromising the stream of a given user, as clients choose
new guards much less frequently than new exits.
6.1.1 Analysis
We consider how different user behavior can have different se-
curity implications. For instance, sending many streams over Tor
induces higher rates of circuit creation, increasing the number of
chances the adversary has to compromise one. Alternatively, the
speciﬁc destination addresses and ports that users connect to af-
fect the probability a malicious exit is chosen because allowed exit
policies differ from relay to relay.
We use TorPS to conduct simulations using each of the user mod-
els (described in Section 5.1.2) over a period from October 2012 to
March 2013. We use several metrics to evaluate the security of
those users against an adversary who runs one guard relay and one
exit relay with 83.3 MiB/s and 16.7 MiB/s of bandwidth respec-
tively. The results are shown in Figure 2.
Overall, we can see (Figure 2a) that in all user models there is
more than an 80% chance of deanonymization within 6 months by
a malicious guard and exit. The median time to full compromise is
always less than 70 days. We also see that risk rises steadily over
time. By looking separately at the times at which a guard or exit is
compromised (Figures 2b and 2c), we see that the time it takes to
choose a malicious guard, with a median of 50–60 days, dominates
the time to choose a malicious exit, with a median of fewer than
2.5 days. This supports the suggestion of Elahi et al. [16] that the
main impediment to full deanonymization by the adversary is being
chosen as a guard by a given user. This implies that an adversary
that observes the user’s connection to the guard, such as an ISP,
deanonymizes the destination much quicker than an adversary ob-
serving exit trafﬁc, such as a malicious destination, deanonymizes
the source.
That an adversary compromises some streams is signiﬁcant, but
how many he compromises is just as important. Figure 2d shows
median rates of full compromise between 0.25% and 1.5%, depend-
ing on user behavior. Rates of full compromise are roughly the
product of the rates of exit and guard compromise, and thus are an
order of magnitude lower. Guard compromise rates are generally
the same for all users, as we would expect given that the desti-
nation address and port are not considered when selecting guards.
The guard compromise rates show some bimodality, which corre-
sponds to the event that the malicious guard is chosen again after
expiring. Exits are chosen independently for each new circuit, and
thus the exit compromise-rate distribution is roughly normal with a
mean of the fraction of exit bandwidth provided by the adversary.
342(a) Time to ﬁrst compromised guard and
exit.
(b) Time to ﬁrst compromised guard.
(c) Time to ﬁrst compromised exit.
(d) Fraction of streams with compromised
guard and exit.
(e) Fraction of streams with compromised
guard.
(f) Fraction of streams with compromised
exit.
Figure 2: Empirical distribution of security metrics, 10/2012 – 3/2013, 83.3 MiB/s malicious guard and 16.7 MiB/s malicious exit.
This rate is roughly the compromise rate achieved by the adversary
when chosen as the user’s guards.
The differences in security between user models is due primarily
to two factors: (i) the amount of user activity and (ii) the destination
addresses and ports. Creating many streams increases the number
of opportunities to choose malicious relays, and thus the speed at
which that occurs, while connecting to destinations that are disal-
lowed by many exits increases the chance that a selected exit relay
will be malicious.
As described in Section 5, the BitTorrent model creates over 2.5
times as many streams as the Typical model and over 50 times as
many as the IRC model. In addition, among the 171 different ports
used are included several ports (6881, 6924, 6910, and 6966) that
are rejected in the default Tor exit policy precisely because they are
used by BitTorrent. Relatively few exits allow these ports, enabling
the malicious exit to provide a larger fraction of that bandwidth.
Thus we can see in Figure 2f that the BitTorrent model experiences
exit compromise at a median time of less than 6 hours and median
rate of over 12%, which is much quicker and more frequently than
the Typical model. This translates to reduced security against full
compromise as well. The IRC and WorstPort models see similarly
bad security relative to the Typical user, as they both connect to
ports that comparatively few exits support. Finally, we observe that
the BestPort model has nearly identical compromise rates to the
Typical model, which is not surprising as the Typical model only
connects to port 80 in addition to 443, and nearly all exits that sup-
port 443 also support 80.
Finally, we consider the effect of changing how much bandwidth
the adversary has and when he starts using it. Figure 3 shows the
distribution of the time to full compromise of a Typical user as
the adversary’s bandwidth varies between 10MiB/s and 200MiB/s.
Doubling the adversary’s bandwidth roughly halves the time to ﬁrst
compromise, with the result that at 200MiB/s the adversary fully
compromises a user within 30 days with probability 50%. On the
other hand, an adversary that is limited to 10MiB/s ( still more than
a typical consumer-grade connection) has a less than 10% chance
to compromise a user at all.
In addition, we show the time to full compromise when the ad-
versary doesn’t have a guard or exit relay until 12/1/2012, two
Figure 3: Time to ﬁrst circuit with guard and exit compromised, varying to-
tal adversary bandwidth and date of malicious relay entry, 10/2012 – 3/2013
months into the simulation. At this point the user has already cho-
sen guards after rotating them at least once. We can see that within
the four remaining months of the simulation the adversary fully
compromises the user with a probability of nearly 70%, which is
nearly the probability of compromise after four months of running
a relay from the outset.
6.2 Network Adversary
Unlike the relay adversary, a network adversary does not run re-
lays in the hope that a client will choose one of those malicious
relays at the guard and exit positions in its path. Instead, a network
adversary leverages their position as a carrier of network trafﬁc to
correlate Tor trafﬁc streams that cross their network at some point
between the client and guard and exit and destination pairs.
We begin our discussion of how Tor clients are exposed to net-
work adversaries by considering the placement of clients within
the network and their behavior. We then consider the threat posed
to those clients from three varieties of network adversaries: ASes,
IXPs, and organizations which administer multiple IXPs.
3436.2.1 Client Behavior and Location
We consider three types of clients in our analysis of a network-
level adversary: Typical, BitTorrent, and IRC.
We do not consider the WorstPort and BestPort behavior patterns,
as these are highly dependent upon exit policy diversity and do not
directly affect a network adversary. Note, however, that an equiv-
alently dangerous behavior pattern exists in the case of a network
adversary: a client whose communication originates and terminates
within the same autonomous system can be deanonymized by that
autonomous system. All trafﬁc will pass through the adversary on