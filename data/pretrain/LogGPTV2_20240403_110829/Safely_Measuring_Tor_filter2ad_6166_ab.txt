Each Di sends each shared value Bi,j
k,b to Sj via T and then se-
curely erases the locally-stored shared values. Each SK stores
the received shared values for the duration of the collection
process.
Collection. During the collection process, each DC monitors
events from its local Tor instance and adjusts the counters.
When an observation is made at Di that affects statistic sk,
Di adjusts one of its counters si
k,b. For single-number statis-
tics, the observed number is added to the counter. For his-
tograms, the bin si
k,b in which the observation falls is incre-
mented. For example, if the statistic is a histogram of the
number of streams per circuit, and the DC observes the end
of a circuit that carried 10 streams during its lifetime, then the
bin containing 10 is incremented by one. The collection pro-
cess lasts for the length of time set during the conﬁguration
phase.
Aggregation. Once the collection process ends, T requests
the counter values from each DC Di. Each Di then sends the
value of each counter si
k,b to T . T considers as successful the
set of DCs that provide values for all counters within a cer-
tain time, S ⊆ {1, . . . , n}. Then T requests from each SK a
sum of the values shared with the successful DCs for each
counter. Recall that each SK Sj is storing n · ∑l
k=1 ck shared
values, one from each DC for each counter. If the successful
1Round is the nearest integer function, and Normal(µ, σ)
is the distribution with density function φ(µ, σ; x) =
e−(x−µ)2/(2σ2)/(σ√2π).
2Uniform(S) is the uniform distribution over set S.
k,b = ∑i∈S Bi,j
DCs are a superset of some minimal set of required DCs, as
listed in the deployment document, each Sj adds the shared
values of the successful DCs for each counter and sends the
resulting sums Bj
k,b to T . After receiving all
shared-value sums Bj
k,b from each Sj, T computes the ﬁnal
tallies for each counter by adding the counters from the suc-
cessful DCs and subtracting the corresponding shared-value
sums from the SKs. That is, T computes sk,b = ∑i∈S si
k,b −
j=1 Bj
∑m
k,b mod q and publishes these values as the output
of the aggregation process. PrivCount may then be recon-
ﬁgured before starting another execution phase, but it does
not need to be re-initialized. In addition, the DCs and SKs
will not accept a new conﬁguration document unless it starts
collection after the reconﬁguration time in the deployment
document has passed.
Note that tolerating the failure of DCs is of critical impor-
tance in a large distributed system such as Tor. PrivCount
provides this enhancement to PrivEx at the minor cost of
storing an extra n − 1 values per counter at the SKs between
setup and aggregation. We observe that SK failures can be
tolerated at some cost simply by running several collections
in parallel with different subsets of the SKs and choosing a
ﬁnal output from any of the successful SK subsets. SK fail-
ure is of much less concern, however, as the number of SKs
is expected to be small even for very large deployments, and
they are speciﬁcally chosen for their reliability and trustwor-
thiness.
2.3 Privacy-Preserving Noise
PrivCount adds random noise to each counter in order to
provide privacy to individual Tor user actions that contribute
to its value. As in PrivEx, the formal notion of privacy used
in PrivCount is (, δ)-differential privacy [12]. However, we
modify and extend PrivEx in several ways to allow for an ex-
panded set of statistics and to make it suitable for a smaller-
scale research deployment.
Deﬁning privacy. PrivCount provides privacy for a certain
amount of user activity. The differential privacy guarantee
applies to “adjacent” databases, where databases are typi-
cally considered to be adjacent if they differ by the input of
a single user [24]. PrivEx deﬁnes adjacency as differing by
at most 6 exit connections from different circuits per hour on
average. This essentially protects a certain number of user
connections rather than providing per-user privacy, as users
may make an arbitrary number of circuits per hour. Indeed
per-user privacy in Tor measurement is inherently difﬁcult to
provide accurately, as a single user can in theory constitute
most of the activity being measured on the network.
We thus adopt a notion of privacy for a bounded amount
activity within a given length of time and extend it to in-
clude other types of user activity. We note that Tor itself has
taken a similar approach in its use of differential privacy to
publish per-relay onion-service statistics [16]. The differen-
tial privacy guarantee under this notion is that, for two sets
of actions within the activity bound that both occur within
a certain length of time, an adversary is nearly as likely to
see a given output whether a user performed one set or the
other. PrivCount protects bounded numbers of the following
types of user actions in a given time period: (i) connection to
a guard, (ii) using a guard from a distinct IP address, (iii) cir-
cuit creation, (iv) stream creation, (v) sending or receiving a
byte of data.
An input “database” in the context of measuring Tor is the
activity on the Tor network. Given bound ax for activity of
type x and a time bound t, two sequences of network activity
are then adjacent if they only differ in the actions of a single
user in some time period of length t and in at most ax actions
for each type of activity x. The difference can be in the exis-
tence of such actions or in attributes of those actions. Note
that these bounds apply simultaneously to different types of
activity and thus can be used to provide privacy for the en-
tirety of a user’s impact on Tor if it falls within the activity
and time bounds. For example, suppose that two sequences
of network activity N1 and N2 differ only in the actions of
one user in a day, and in N2 that user both created an addi-
tional circuit and kept a stream open in N2 for longer than
it was in N1. Then N1 and N2 would be considered adjacent
if t is at least one day, acirc ≥ 1, and astream ≥ 1, where acirc
and astream are the bounds for activities of type (iii) and (iv),
respectively. We describe concrete activity bounds ax and t
in Section 4.2.
Determining noise per statistic. Given the above notion
of adjacency, PrivCount provides (, δ)-differential privacy
by adding normally-distributed noise to its counters, as in
PrivEx. However, instead of ﬁrst choosing σ to limit the ad-
versary’s “advantage” and then determining the resulting 
and δ, we use the more typical method of ﬁrst setting  and
δ to achieve desired privacy and then computing the neces-
sary σ. Tor itself is using this approach [16] (with  = 0.3 and
δ = 0), and this method makes it straightforward to allocate
the privacy “budgets”  and δ across statistics to minimize
relative noise. Moreover, the guarantees of (, δ)-differential
privacy have a direct Bayesian intepretation [27] that applies
to an adversary with any amount of prior knowledge, unlike
the notion of adversary advantage.
PrivCount sets  and δ and then divides each among the
l statistics (this division is detailed below, in the next para-
graph). Let k, δk be the allocation of these parameters to the
kth statistic sk, that is, ∑k k =  and ∑k δk = δ for k, δk ≥ 0.
The noise to add to a statistic depends on its sensitivity. The
sensitivity of a statistic that is a single number is the maxi-
mum amount that number can change between adjacent in-
puts. The sensitivity of a histogram is twice the number of
histogram elements that can change their bin, be added, or
be removed [13] (the factor of 2 appears because changing the
bin of an input reduces one bin count and increases another).
We describe in Section 4.2 how we determine sensitivities for
the speciﬁc statistics we collected. Given the sensitivity for
the kth statistic, PrivCount uses an iterative search to com-
pute σ∗(k, δk), the smallest normal standard deviation such
that the set of outputs that satisfy k-differential privacy has
probability at least 1 − δk. PrivCount uses this value for the
noise of the kth statistic: σk = σ∗(k, δk). This will guar-
antee (k, δk)-differential privacy of the statistic and enable
the guarantees to compose across statistics to provide (, δ)-
differential privacy overall. Note that the formula given by
Elahi et al. [14, Section 4.4.1] that relates σk to k and δk some-
times yields parameters that do not provide differential pri-
vacy. See Appendix A for details about calculating σk and a
counterexample to the formula of Elahi et al.
Allocating the privacy budget across statistics. Given to-
tal privacy budgets  and δ, PrivCount divides them among
the l statistics such that each statistic has high relative accu-
racy while providing (, δ)-differential privacy to the collec-
tive set. This improves upon PrivEx, which neither considers
how the activity of a single user might affect multiple statis-
tics nor how best to allocate a global privacy budget among
the different statistics. As suggested by the bound on σ by
Dwork et al. [12] (viz. σ ≤ ∆−1(cid:112)2 ln(2/δ), where ∆ is the
sensitivity), δ affects σ far less than , and thus PrivCount
simply divides it evenly: δk = δ/l for all k. PrivCount then
uses an estimated value vk for each sk to allocate  such that
the added noise values are expected to be proportional to the
values of the statistics. If sk represents a histogram, then vk
is the estimated total count across all bins, that is, vk is an
estimate for ∑b sk,b, which will help ensure that some bin has
low relative noise while not requiring that good estimates are
available for each bin. Estimating values can be a very effec-
tive method to improve the speed and accuracy of gathering
many, diverse statistics, as the speed at which the statistics
change over time can vary wildly (e.g. the frequency of Tor
connections to Web ports is typically orders of magnitude
larger than the frequency of connections to IRC ports). Esti-
mates can be obtained from data that Tor currently publishes,
from published measurement studies of Tor, or from some
earlier rounds of PrivCount measurement. If no reasonable
estimates are available, an equal allocation of  (i.e. k = /l)
can be obtained simply by using the same, arbitrary value as
an estimate for each statistic. Section 4.2 describes how we
estimated values for our data collection.
∑i w2
∑i w2
Given the estimated values vk, PrivCount allocates  in or-
der to minimize over all statistics the maximum ratio of the
noise standard deviation to the estimated value. That is, the
i σk/vk, where
values k are set to minimize ρ = maxk
σk = σ∗(k, δk) (note that the total noise standard deviation
for sk after aggregation is
i σk). PrivCount uses an iter-
ative search on ρ, each value of which determines an alloca-
tion of , to compute the optimal allocation. See Appendix A
for details on this computation.
Selecting noise weights. Noise with standard deviation σk
would provide (, δ)-differential privacy across all statistics
at each DC. However, the noise values get aggregated across
DCs and thus potentially result in more noise than necessary.
PrivCount therefore adjusts the noise across DCs by the noise
weight wi that is applied at each Di. The values wi are used
to set the desired balance between excessive noise in the ag-
gregated result and maintaining privacy even if some DCs
are malicious and do not add their component of the noise.
PrivEx uses noise weight similarly and sets each wi propor-
tional to the consensus-weight fraction of the Tor relay moni-
tored by Di under the assumption that PrivEx runs on all Tor
relays of which some fraction by consensus weight is hon-
est. However, for smaller-scale measurement deployments,
it is more appropriate to instead assume that some number of
DCs are honest. For example, if we assume that d of n DCs
are honest, then we can set wi = 1/√d at each Di.
3. SECURITY AND PRIVACY ANALYSIS
(cid:113)
(cid:113)
We abstract the information revealed by PrivCount with an
ideal functionality in the UC-framework [7]. The initializa-
tion and conﬁguration phases of PrivCount guarantee that
there exists some set of initialization and conﬁguration val-
ues such that each honest party either uses those values or
does not participate in aggregation. This is implemented
in these phases with a protocol for broadcast with abort [21],
which is captured by the macro MBA in Figure 1. The Priv-
Macro MBA(sid, P,B)
Start: Upon receipt of (sid, m) from P, store (sid, P,B, m, ∅).
Send: Upon input (sid, P(cid:48), m) from P, if (sid, P,B, m,P ) is cur-
rently stored for sid, P(cid:48) (cid:54)= P, and P(cid:48) /∈ P then send m to P(cid:48) and
update the stored value to (sid, P,B, m,P + P(cid:48)).
Abort: Upon input (sid, P(cid:48),⊥) from P, if (sid, P,B, m,P ) is cur-
rently stored for sid, P(cid:48)
(cid:54)= P, P(cid:48) /∈ P, and some P ∈ B
is corrupt, then send ⊥ to P(cid:48) and update the stored value to
(sid, P,B, m,P + P(cid:48)).
Figure 1: Macro for broadcast with abort from P to B
Count functionality FPC uses the MBA macro and is given
in Figure 2. Several security and privacy properties are evi-
dent from FPC, and, by the following theorem, they apply to
PrivCount:
THEOREM 1. PrivCount UC-realizes FPC in the hybrid PKI
model against any adversary that does not corrupt all SKs.
PROOF. See Appendix B.
By Thm. 1 and examining FPC, we can conclude that Priv-
Count securely aggregates the inputs and noise added by the
honest DCs as long as one SK is honest; that is, the adver-
sary only learns their sum. We can further observe that Priv-
Count provides forward privacy in that the adversary does
not learn the DC inputs during data collection that occurred
before corruption. We can also see that the adversary can ar-
bitrarily modify the output of the TS for sk,b even if it is not
compromised by choosing ∆k,b. We note that FPC and Thm. 1
demonstrate how to deﬁne and prove privacy for PrivEx-S2
as well, which was not shown by Elahi et al. [14].
We can show that sufﬁciently stringent policies on deploy-
ment documents ensure (, δ)-differential privacy, as shown
by the following theorem:
THEOREM 2. If at least one SK Si is honest, and if, for each
minimal subset S of DCs in the deployment document that Si re-
Di∈H w2
i ≥ 1, then the
ceives with honest subset H ⊆ S,
output of PrivCount is (, δ)-differentially private.
∑
(cid:113)
PROOF. See Appendix B.
We do note that differential privacy only provides privacy
for a limited amount of time and user activity, and an active
user will eventually exceed that amount. Thus, as the num-
ber of measurement rounds increases, the chance of revealing
something private about user activity increases. For exam-
ple, the existence of a regular Tor user may become apparent
over time even if it cannot be identiﬁed in the statistics from
any single measurement round. Goulet et al. [16] choose to
round differentially-private outputs in an attempt to avoid
such an information leak. This technique could be applied to
PrivCount’s statistics as well.
4. METHODOLOGY
In this section we describe our open-source prototype im-
plementation of PrivCount [1] and provide details about the
deployment that we set up and used to measure Tor. As the
privacy of Tor users is a primary concern, we practice data
Functionality FPC
Let A be the adversary. Copies of all inputs and outputs are sent to A except those with the input command. When a party is corrupted by
A, and all future inputs and outputs are with A.
Initialization: A deployment and its TS are established by receiving TS from some party PTS and PTS from each other party. Then the
macro MBA(init, PTS,P ) is run, where P is all parties except PTS, which receives the deployment document from the TS and broadcasts it
to the other parties. After MBA sends document Dinit to P, P aborts if Dinit = ⊥; otherwise, a bit b is accepted from P, where b = 1 indicates
acceptance of Dinit, and forwards it to PTS.
Conﬁguration: If each honest party has accepted Dinit and no party is currently in execution, the macro MBA(conﬁg, PTS,PSK) is run,
where PSK is the set of SKs, which receives a new conﬁguration document from PTS and broadcasts it to the other parties.
Execution setup: Once Pi has received a conﬁguration document Dconﬁg (cid:54)= ⊥, for each statistic sk, based on the values in Dinit and Dconﬁg,
ck counters are created, and the noise magnitude σk is computed, and the counters are each initialized with random noise sampled from
Normal(0, wiσk) and rounded. At this point SKs in the Dinit skip collection and enter aggregation.
Execution collection: Upon receiving (start, Pi) from PTS, if Pi has completed setup and is a DC in the Dinit, then it enters data collection.
While in data collection, Pi accepts inputs (input, Pi, k, x) as long as Pi is not corrupt. If statistic sk is a single number, then its counter is
increased by x, and if it is a histogram, the bin b such that Lk,b ≤ x < Rk,b is incremented by one. If Pi becomes corrupt, then its counters
cease to be incremented. Upon receiving (stop, Pi) from PTS, a Pi in data collection ends execution and waits for the next conﬁguration
document.
Execution aggregation: Upon receiving (share,Si, Pi) from PTS, if Pi is in aggregation, then Pi leaves execution and waits for the next
conﬁguration document. Then, once all honest parties have left execution, suppose that the honest DCs in Si are the same for all the honest
SKs and each Si contains some minimal subset of required DCs in Dinit. Let yk,b be the sum of the counters si
k,b summed over the DCs Di.
If PTS is corrupt, then the yk,b are output to the adversary, and otherwise, upon receiving ∆k,b from the adversary, yk,b is added to ∆k,b and
the values are output to PTS. Suppose instead some Si doesn’t contain any minimal subset of required DCs. Then, if PTS is corrupt, ⊥ is
output to the adversary, and otherwise ⊥ is output to PTS. Otherwise it must be that the Si of two SKs disagree on honest DCs, and then a
uniformly random integer mod q is output to the adversary if PTS is corrupt and otherwise is output to PTS.
Figure 2: Ideal functionality for PrivCount
minimization during the measurement process: we focus our
collection of statistics on only those that aid Tor trafﬁc model-
ing efforts [18]. Measurements from both entry and exit relay
positions are considered as both positions provide unique in-
formation that is useful for modeling purposes.
4.1 Measuring Tor with PrivCount
We use PrivCount to safely measure Tor. While the Priv-
Count protocol was described in Section 2, we now explain
how we collect and process the Tor events that will allow us
to compute our statistics of interest.
Collecting Events. To facilitate the collection and processing
of events from Tor, we extended the Tor control protocol [2]
with a new asynchronous event of type PRIVCOUNT. Once
an application authenticates with Tor and registers for our
new event, our modiﬁed Tor software will then emit the fol-
lowing whenever any of the sub-events occur: (i) exit stream
end: channel id, circuit id, stream id, num bytes read, num
bytes written, exit port, start time, end time; (ii) exit circuit
end: channel id, circuit id; (iii) entry circuit end: channel id,