4
5
7
0.50
0.65
0.48
0.65
0.34
0.66
0.46
0.55
Syscall alignment
Feature set BinSim
0.08
0.10
0.10
0.12
0.08
0.09
0.12
0.10
0.10
0.05
0.05
0.15
0.10
0.71
0.10
0.12
0.15
0.17
0.12
0.15
0.18
0.15
0.10
0.10
0.10
0.18
0.15
0.63
0.08
0.10
0.12
0.12
0.05
0.09
0.10
0.05
0.10
0.05
0.05
0.16
0.09
0.76
old. What matters is that a tool can differentiate right-
pair scores from wrong-pair scores. We ﬁrst test how
their similar scores change from right pairs to wrong
pairs. For the right pair testing, we compare each sam-
ple in Table 2 with itself (no obfuscation). The average
values are shown in “Right pairs” bar in Figure 8. Then
we compare each sample with the other samples (no ob-
fuscation) and calculate the average values, which are
shown in “Wrong pairs” bar in Figure 84. The compar-
ison results reveal a similar pattern for all these seven
binary difﬁng tools: a large absolute difference value be-
tween the right pair score and the wrong pair score.
Next, we ﬁgure out how the similarity score varies un-
der different obfuscation schemes and combinations. We
ﬁrst calculate the similarity scores for “Right pairs” (self
comparison) and “Obfuscation pairs” (the clean version
vs. its obfuscated version). Table 3 shows the absolute
difference values between “Right pairs” and “Obfusca-
tion pairs”. Since code obfuscation has to preserve se-
4It does not mean that higher is better on the similarity scores for the
right pairs, and lower is better for the wrong pairs. What is important
is how their similarity values change from right pairs to wrong pairs.
mantics [17], the small and consistent difference values
can indicate that a binary difﬁng tool is resilient to dif-
ferent obfuscation schemes and combinations. BinDiff,
DarunGrim, iBinHunt and CoP do not achieve a consis-
tent (good) result for all test cases, because their differ-
ence values ﬂuctuate. The heuristics-based comparisons
adopted by BinDiff and DarunGrim can only handle mild
instructions obfuscation within a basic block. Since mul-
tiple obfuscation methods obfuscate the structure of con-
trol ﬂow graph (e.g., ROP and control ﬂow obfuscation),
the effect of BinDiff and DarunGrim are limited. CoP
and iBinHunt use symbolic execution and theorem prov-
ing techniques to match basic blocks, and therefore are
resilient to intra-basic-block obfuscation (Type 1). How-
ever, they are insufﬁcient to defeat the obfuscation that
may break the boundaries of basic blocks (e.g., Type 2 ∼
Type 7 in Table 1). The last rows of Table 3 shows the av-
erage difference values for the “Right pairs” vs. “Obfus-
cation pairs” and “Right pairs” vs. “Wrong pairs”. The
closer for these two scores, the harder for a tool to set a
threshold or cutoff line to give a meaningful information
on the similarity score.
USENIX Association
26th USENIX Security Symposium    263
Table 4: Comparison of slice sizes (# instructions).
Sample
BullMoose
Clibo
Branko
Sasser
ﬁbonacci
Obfuscation type No-VMP Conventional BinSim
165
238
520
1,766
278
6,785
16,860
31,154
64,276
4,142
98
156
472
1,484
156
6
1+6
1+2+6
1+2+6
7
Table 5: Similarity score of four CryptoWall variants.
a vs. b
0.92
a vs. c
0.83
a vs. d
0.32
b vs. c
0.78
b vs. d
0.33
c vs. d
0.37
Regarding dynamic-only methods (system call align-
ment and feature set), their scores are consistent for most
comparisons. The reason is dynamic-only approaches
are effective to defeat most code obfuscation schemes.
However, we notice a variant of Hunatcha worm ex-
hibits the malicious behavior under the condition of
systime.Month < 12. Without more detailed informa-
tion such as path conditions, both system call alignment
and feature set methods fail to identify such conditional
equivalence. This disadvantage is further manifested by
our large-scale malware comparisons, in which we ﬁnd
out 11% variants are conditionally equivalent.
5.4 Ofﬂine Analysis Evaluation
In this section, we ﬁrst evaluate BinSim’s dynamic slic-
ing when handling obfuscated binaries. We test BinSim
with VMProtect [69], an advanced commercial obfus-
cator.
In addition to virtualization obfuscation, which
can cause slice size explosion, VMProtect also performs
intra-basic-block (Type 1) and control ﬂow obfuscation
(Type 2). As shown in Table 4, we obfuscate the test
cases with multiple obfuscation combinations and multi-
level virtualization (Type 7).
“No-VMP” column in-
dicates BinSim’s result without obfuscation. The last
two columns show the slice sizes of conventional dy-
namic slicing and BinSim. BinSim outperforms the con-
ventional approach by reducing slice sizes signiﬁcantly.
Note that the sliced segment produced by BinSim con-
tains many different instructions with “No-VMP” ver-
sion. Directly comparing the syntax of instructions is
not feasible. Our semantics-based equivalence checking
can show that the new sliced segment is equivalent to the
original instructions.
Next, we evaluate BinSim’s cryptographic function
approximate matching, which allows equivalence check-
ing in the presence of cryptographic functions that could
otherwise be hard to analyze. We collect four Cryp-
toWall variants and apply BinSim to compare them pair
by pair. CryptoWall is a representative ransomware fam-
ily, and it is also continuously evolving. The similar
scores are shown in Table 5. We notice three samples
(a, b, and c) are quite similar, and one sample (Cryp-
toWall.d) has relatively large differences with the oth-
ers. After investigating BinSim’s output, we ﬁnd out
that CryptoWall.d reveals three distinct behaviors: 1)
“query-then-infect”: it will terminate execution if the in-
fected machine’s UI languages are Russian, Ukrainian
or other former Soviet Union country languages (via
GetSystemDefaultUILanguage). This clearly shows
that the adversaries want to exclude certain areas from
attacking. 2) It uses AES for ﬁle encryption while the
other three variants choose RSA. 3) It encrypts ﬁles with
a new ﬁle name generation algorithm. Our “query-then-
infect” ﬁndings coincide with the recent CryptoWall re-
verse engineering report [2].
5.5 Analyzing Wild Malware Variants
We report our experience of applying BinSim and other
six binary difﬁng tools on 1,050 active malware samples
(uncontrolled dataset)5. The dataset is retrieved from
VirusShare6 and analyzed at February 2017. We lever-
age VirusTotal7 to do an initial clustering by majority
voting. The total 1,050 samples are grouped into 112
families, and more than 80% samples are protected by
different packers or virtualization obfuscation tools. For
each binary difﬁng tool, we perform intra-family pair-
wise comparison on our private cloud. The distribution
of similarity scores is shown in Table 6. Because Bin-
Diff, DarunGrim, and CoP cannot directly work on the
packed binary, we provide the unpacker binaries prepro-
cessed by BinSim’s generic unpacking.
In most cases, dynamic-only methods and BinSim are
able to ﬁnd small distances among intra-family sam-
ples. For example, over 86% of the pairs have a sim-
ilarity score of 0.6 or greater. System call alignment
has a better distribution than BinSim during the simi-
larity score range 0.70 ∼ 1.00. We attribute the high
score to the fact that system call alignment cannot detect
conditional equivalence. Actually, we successfully iden-
tify that about 11% of malware samples have so-called
“query-then-infect” behaviors [77], and BinSim is able
to ﬁnd whether two malware variants are conditionally
equivalent. In these cases, BinSim’s lower scores better
ﬁt the ground truth. Figure 9 shows a conditional equiva-
lent behavior we ﬁnd in Trojan-Spy.Win32.Zbot vari-
ants. Figure 10 presents a common compiler optimiza-
tion that converts a high-level branch condition into a
purely arithmetic sequence. This optimization can frus-
trate “block-centric” binary difﬁng methods, and we have
5The initial dataset is much larger, but we only consider the active
samples that we can collect system calls.
6http://virusshare.com/
7https://www.virustotal.com/
264    26th USENIX Security Symposium
USENIX Association
BinSim only detects the similarities/differences exhibit-
ing during execution. The possible solutions are to ex-
plore more paths by automatic input generation [26, 47]
and analyze malware in a transparent platform (e.g., VM-
Ray Analyzer [70]). Our current generic unpacking is
sufﬁcient for our experiments. However, it can be de-
feated by more advanced packing methods such as mul-
tiple unpacking frames and parallel unpacking [68]. We
plan to extend BinSim to deal with the advanced pack-
ing methods. Recent work proposes “replacement at-
tacks” [44] to mutate system calls and their dependen-
cies. As a result, similar malware variants turn out to
have different behavior-based signatures. We regard this
“replacement attacks” as a potential threat because it can
reduce BinSim’s similarity score. One possible solution
is to design a layered architecture to capture alternative
events that achieve the same high-level functionality.
BinSim’s enhanced slicing algorithm handles the ob-
fuscations that could break the block-centric binary com-
parisons. We have evaluated BinSim against a set of so-
phisticated commercial obfuscation tools and advanced
academic obfuscation methods. However, determined
adversaries may carefully add plenty of redundant de-
pendencies to cause slice size explosion, and the result-
ing weakest preconditions could become too complicated
to be solved. As an extreme case, the dependencies of
a system call argument can be propagated to the entire
program. To achieve this, it requires that future attack-
ers have much deeper understanding about program anal-
ysis (e.g., inter-procedure data/control follow analysis)
and take great engineering efforts. An attacker can also
customize an unknown cryptographic algorithm to evade
our cryptographic function approximate matching. How-
ever, correctly implementing a cryptographic algorithm
is not a trivial task, and most cryptographic functions
are reused from open cryptographic libraries, such as
OpenSSL and Microsoft Cryptography API [75]. There-
fore, BinSim raises the attacking bar signiﬁcantly com-
pared to existing techniques. On the other side, design-
ing a worst case evaluation metric needs considerable in-
sights into malicious software industry [39]. We leave it
as our future work.
7 Related Work
7.1 Dynamic Slicing and Weakest Precon-
dition Calculation
As dynamic slicing techniques [1, 80] can substantially
reduce the massive program statements under investiga-
tion to a most relevant subset, they have been widely
applied to the domain of program analysis and veriﬁca-
tion. Differential Slicing [29] produces a causal differ-
ence graph that captures the input differences leading to
Figure 9: Conditional equivalent behaviors between
Trojan-Spy.Win32.Zbot variants.
Figure 10: Example: branchless logic code (reg stands
for a register; va1 and val2 are two inputs).
seen such cases repeatedly in our dataset. By contrast,
BinSim’s hybrid approach naturally identiﬁes the im-
plicit control dependency in Figure 10 (b).
5.6 Performance
In Table 2, we also report the performance of BinSim
when analyzing the controlled dataset. The fourth col-
umn lists the runtime overhead imposed by our online
trace logging. On average, it incurs 8X slowdown, with
a peak value 12X when executing KeyLogger. The ﬁfth
to seventh columns present the execution time of each
component in our ofﬂine analysis stage. The number
of instructions in the system call slice ranges from 5 to
138 and the average number is 22. The “STP” column
presents average time spent on querying STP when com-
paring two programs. Here we show the time before and
after the optimization of caching equivalence queries. On
average, the HashMap speeds up STP processing time
by a factor of 1.7. Considering that BinSim attempts to
automatically detect obfuscated binary code similarity,
which usually takes exhausting manual efforts from sev-
eral hours to days, this degree of slowdown is acceptable.
Performing the intra-family comparisons on 1,050 mal-
ware samples required approximately 3 CPU days.
6 Discussion
Like other malware dynamic analysis approaches, Bin-
Sim bears with the similar limitations: 1) incomplete
path coverage; 2) environment-sensitive malware [34,
35] which can detect sandbox environment. Therefore,
USENIX Association
26th USENIX Security Symposium    265
// modify registry key1: RegOpenKeyEx();2: RegSetValueEx();3: RegCloseKey();(a) Zbot.a(b) Zbot.b// modify registry key1: GetLocalTime(&systime);2: if (systime.Day< 20)3:  {  4:      RegOpenKeyEx();5:      RegSetValueEx();6:      RegCloseKey();7:  }  1: neg     reg2: sbb     reg, reg3: and     reg, (val1 -val2) 4: add     reg, val2(a) Branch logic (b) Equivalent branchless logicif (reg)  reg = val1;else      reg = val2;Table 6: Similarity score distribution (%) of intra-family comparisons.
Score range BinDiff DarunGrim iBinHunt CoP
0.00–0.10
1
3
0.10–0.20
0.20–0.30
4
10
0.30–0.40
18
0.40–0.50
13
0.50–0.60
14
0.60–0.70
0.70–0.80
16
11
0.80–0.90
0.90–1.00
10
1
1
2
3
5
18
17
20
15