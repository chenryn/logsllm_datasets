行1个task。
27.1.4. Storm Streaming Grouping
Storm 中最重要的抽象，应该就是 Stream grouping 了，它能够控制 Spot/Bolt 对应的 Task 以
什么样的方式来分发Tuple，将Tuple发射到目的Spot/Bolt对应的Task.
13/04/2018 Page 272 of 283
目前，Storm Streaming Grouping支持如下几种类型：
27.1.4.1. huffle Grouping
随机分组，尽量均匀分布到下游Bolt中将流分组定义为混排。这种混排分组意味着来自Spout的
输入将混排，或随机分发给此Bolt中的任务。shuffle grouping对各个task的tuple分配的比
较均匀。
27.1.4.2. Fields Grouping
按字段分组，按数据中field值进行分组；相同field值的Tuple被发送到相同的Task这种
grouping机制保证相同field值的tuple会去同一个task。
27.1.4.3. All grouping ：广播
广播发送， 对于每一个tuple将会复制到每一个bolt中处理。
13/04/2018 Page 273 of 283
27.1.4.4. Global grouping
全局分组，Tuple被分配到一个Bolt中的一个Task，实现事务性的Topology。Stream中的所
有的tuple都会发送给同一个bolt任务处理，所有的tuple将会发送给拥有最小task_id的bolt
任务处理。
27.1.4.5. None grouping ：不分组
不关注并行处理负载均衡策略时使用该方式，目前等同于shuffle grouping,另外storm将会把
bolt任务和他的上游提供数据的任务安排在同一个线程下。
27.1.4.6. Direct grouping ：直接分组 指定分组
由tuple的发射单元直接决定tuple将发射给那个bolt，一般情况下是由接收tuple的bolt决定
接收哪个bolt发射的Tuple。这是一种比较特别的分组方法，用这种分组意味着消息的发送者指
定由消息接收者的哪个task处理这个消息。 只有被声明为Direct Stream的消息流可以声明这种
分组方法。而且这种消息tuple必须使用emitDirect方法来发射。消息处理者可以通过
TopologyContext来获取处理它的消息的taskid (OutputCollector.emit方法也会返回
taskid)。
13/04/2018 Page 274 of 283
28. YARN
28.1.1. 概念
YARN 是一个资源管理、任务调度的框架，主要包含三大模块：ResourceManager（RM）、
NodeManager（NM）、ApplicationMaster（AM）。其中，ResourceManager 负责所有资
源的监控、分配和管理；ApplicationMaster 负责每一个具体应用程序的调度和协调；
NodeManager负责每一个节点的维护。对于所有的applications，RM拥有绝对的控制权和对资
源的分配权。而每个AM则会和RM协商资源，同时和NodeManager通信来执行和监控task。
几个模块之间的关系如图所示。
28.1.2. ResourceManager
1. ResourceManager负责整个集群的资源管理和分配，是一个全局的资源管理系统。
2. NodeManager以心跳的方式向ResourceManager汇报资源使用情况（目前主要是CPU和
内存的使用情况）。RM 只接受 NM 的资源回报信息，对于具体的资源处理则交给 NM 自己
处理。
3. YARN Scheduler根据application 的请求为其分配资源，不负责application job 的监控、
追踪、运行状态反馈、启动等工作。
28.1.3. NodeManager
1. NodeManager 是每个节点上的资源和任务管理器，它是管理这台机器的代理，负责该节点
程序的运行，以及该节点资源的管理和监控。YARN集群每个节点都运行一个NodeManager。
13/04/2018 Page 275 of 283
2. NodeManager 定时向 ResourceManager 汇报本节点资源（CPU、内存）的使用情况和
Container 的运行状态。当 ResourceManager 宕机时 NodeManager 自动连接 RM 备用节
点。
3. NodeManager接收并处理来自ApplicationMaster的Container启动、停止等各种请求。
28.1.4. ApplicationMaster
用户提交的每个应用程序均包含一个ApplicationMaster，它可以运行在ResourceManager以外
的机器上。
1. 负责与RM调度器协商以获取资源（用Container表示）。
2. 将得到的任务进一步分配给内部的任务(资源的二次分配)。
3. 与NM通信以启动/停止任务。
4. 监控所有任务运行状态，并在任务运行失败时重新为任务申请资源以重启任务。
5. 当前YARN 自带了两个 ApplicationMaster 实现，一个是用于演示 AM 编写方法的实例程序
DistributedShell，它可以申请一定数目的 Container 以并行运行一个 Shell 命令或者 Shell
脚本；另一个是运行MapReduce应用程序的AM—MRAppMaster。
注：RM只负责监控AM，并在AM运行失败时候启动它。RM不负责AM内部任务的容错，任务
的容错由AM完成。
13/04/2018 Page 276 of 283
28.1.5. YARN运行流程
1. client 向 RM 提交应用程序，其中包括启动该应用的 ApplicationMaster 的必须信息，例如
ApplicationMaster程序、启动ApplicationMaster的命令、用户程序等。
2. ResourceManager启动一个container用于运行ApplicationMaster。
3. 启动中的ApplicationMaster向ResourceManager注册自己，启动成功后与RM保持心跳。
4. ApplicationMaster向ResourceManager发送请求，申请相应数目的container。
5. ResourceManager 返回 ApplicationMaster 的申请的 containers 信息。申请成功的
container，由 ApplicationMaster 进行初始化。container 的启动信息初始化后，AM 与对
应的NodeManager通信，要求NM启动container。AM与NM保持心跳，从而对NM上
运行的任务进行监控和管理。
6. container运行期间，ApplicationMaster对container进行监控。container通过RPC协议
向对应的AM汇报自己的进度和状态等信息。
7. 应用运行期间，client直接与AM通信获取应用的状态、进度更新等信息。
8. 应用运行结束后，ApplicationMaster 向 ResourceManager 注销自己，并允许属于它的
container被收回。
13/04/2018 Page 277 of 283
29. 机器学习
29.1.1. 决策树
29.1.2. 随机森林算法
29.1.3. 逻辑回归
29.1.4. SVM
29.1.5. 朴素贝叶斯
29.1.6. K最近邻算法
29.1.7. K均值算法
29.1.8. Adaboost 算法
29.1.9. 神经网络
29.1.10. 马尔可夫
参考：http://www.cyzone.cn/a/20170422/310196.html
13/04/2018 Page 278 of 283
30. 云计算
30.1.1. SaaS
SaaS是Software-as-a-Service（软件即服务）
30.1.2. PaaS
PaaS 是Platform-as-a-Service 的缩写，意思是平台即服务。 把服务器平台作为一种服务提供的
商业模式。通过网络进行程序提供的服务称之为 SaaS(Software as a Service)，而云计算时代相
应的服务器平台或者开发环境作为服务进行提供就成为了PaaS(Platform as a Service)。
30.1.3. IaaS
IaaS（Infrastructure as a Service），即基础设施即服务。提供给消费者的服务是对所有设施的
利用，包括处理、存储、网络和其它基本的计算资源，用户能够部署和运行任意软件，包括操作
系统和应用程序。
30.1.4. Docker
30.1.4.1. 概念
Docker 镜像 Docker 镜像是用于创建 Docker 容器的模板。
(Images)
13/04/2018 Page 279 of 283
Docker 容器 容器是独立运行的一个或一组应用。
(Container)
Docker 客户端 Docker 客户端通过命令行或者其他工具使用 Docker API与 Docker 的守护进程通信。
(Client)
Docker 主机 一个物理或者虚拟的机器用于执行 Docker 守护进程和容器。
(Host)
Docker 仓库 Docker 仓库用来保存镜像，可以理解为代码控制中的代码仓库。
(Registry) Docker Hub 提供了庞大的镜像集合供使用。
Docker Docker Machine是一个简化Docker安装的命令行工具，通过一个简单的命令行即可在相
Machine 应的平台上安装Docker，比如VirtualBox、 Digital Ocean、Microsoft Azure。
Docker 的出现一定是因为目前的后端在开发和运维阶段确实需要一种虚拟化技术解决开发环境和
生产环境环境一致的问题，通过 Docker 我们可以将程序运行的环境也纳入到版本控制中，排除因
为环境造成不同运行结果的可能。但是上述需求虽然推动了虚拟化技术的产生，但是如果没有合
适的底层技术支撑，那么我们仍然得不到一个完美的产品。本文剩下的内容会介绍几种 Docker 使
用的核心技术，如果我们了解它们的使用方法和原理，就能清楚 Docker 的实现原理。Docker 使
用客户端-服务器 (C/S) 架构模式，使用远程 API 来管理和创建 Docker 容器。Docker 容器通过
Docker 镜像来创建。
30.1.4.2. Namespaces
命名空间（namespaces）是 Linux 为我们提供的用于分离进程树、网络接口、挂载点以及进程间
通信等资源的方法。在日常使用 Linux 或者 macOS 时，我们并没有运行多个完全分离的服务器的
需要，但是如果我们在服务器上启动了多个服务，这些服务其实会相互影响的，每一个服务都能
看到其他服务的进程，也可以访问宿主机器上的任意文件，这是很多时候我们都不愿意看到的，
我们更希望运行在同一台机器上的不同服务能做到完全隔离，就像运行在多台不同的机器上一样。
13/04/2018 Page 280 of 283
Linux 的命名空间机制提供了以下七种不同的命名空间，包括 CLONE_NEWCGROUP、
CLONE_NEWIPC、CLONE_NEWNET、CLONE_NEWNS、CLONE_NEWPID、
CLONE_NEWUSER 和 CLONE_NEWUTS，通过这七个选项我们能在创建新的进程时设置新进程
应该在哪些资源上与宿主机器进行隔离。
30.1.4.3. 进程(CLONE_NEWPID 实现的进程隔离)
docker 创建新进程时传入 CLONE_NEWPID 实现的进程隔离，也就是使用 Linux 的命名空间实现
进程的隔离，Docker 容器内部的任意进程都对宿主机器的进程一无所知。当我们每次运行
docker run 或者 docker start 时，都会在创建一个用于设置进程间隔离的 Spec，同时会设置进
程相关的命名空间，还会设置与用户、网络、IPC 以及 UTS 相关的命名空间，所有命名空间相关
的设置 Spec 最后都会作为 Create 函数的入参在创建新的容器时进行设置。
30.1.4.4. Libnetwork与网络隔离
如果 Docker 的容器通过 Linux 的命名空间完成了与宿主机进程的网络隔离，但是却有没有办法通过宿
主机的网络与整个互联网相连，就会产生很多限制，所以 Docker 虽然可以通过命名空间创建一个隔离
的网络环境，但是 Docker 中的服务仍然需要与外界相连才能发挥作用。
Docker整个网络部分的功能都是通过 Docker 拆分出来的 libnetwork 实现的，它提供了一个连接不同
容器的实现，同时也能够为应用给出一个能够提供一致的编程接口和网络层抽象的容器网络模型。
libnetwork 中最重要的概念，容器网络模型由以下的几个主要组件组成，分别是 Sandbox、
Endpoint 和 Network。在容器网络模型中，每一个容器内部都包含一个 Sandbox，其中存储着当前
容器的网络栈配置，包括容器的接口、路由表和 DNS 设置，Linux 使用网络命名空间实现这个
Sandbox，每一个 Sandbox 中都可能会有一个或多个 Endpoint，在 Linux 上就是一个虚拟的网卡
veth，Sandbox 通过 Endpoint 加入到对应的网络中，这里的网络可能就是我们在上面提到的 Linux
网桥或者 VLAN。
每一个使用 docker run 启动的容器其实都具有单独的网络命名空间，Docker 为我们提供了四种不同
的网络模式，Host、Container、None 和 Bridge 模式。
在这一部分，我们将介绍 Docker 默认的网络设置模式：网桥模式。在这种模式下，除了分配隔离的网
络命名空间之外，Docker 还会为所有的容器设置 IP 地址。当 Docker 服务器在主机上启动之后会创建
新的虚拟网桥 docker0，随后在该主机上启动的全部服务在默认情况下都与该网桥相连。在默认情况下，
13/04/2018 Page 281 of 283
每一个容器在创建时都会创建一对虚拟网卡，两个虚拟网卡组成了数据的通道，其中一个会放在创建的
容器中，会加入到名为 docker0 网桥中。
30.1.4.5. 资源隔离与CGroups
Control Groups（简称 CGroups）能够隔离宿主机器上的物理资源，例如 CPU、内存、磁盘 I/O 和网
络带宽。每一个 CGroup 都是一组被相同的标准和参数限制的进程，不同的 CGroup 之间是有层级关
系的，也就是说它们之间可以从父类继承一些用于限制资源使用的标准和参数。
30.1.4.6. 镜像与UnionFS
Linux 的命名空间和控制组分别解决了不同资源隔离的问题，前者解决了进程、网络以及文件系统
的隔离，后者实现了 CPU、内存等资源的隔离，但是在 Docker 中还有另一个非常重要的问题需
要解决 - 也就是镜像。
Docker 镜像其实本质就是一个压缩包，我们可以使用命令将一个 Docker 镜像中的文件导出，你
可以看到这个镜像中的目录结构与 Linux 操作系统的根目录中的内容并没有太多的区别，可以说
Docker 镜像就是一个文件。
30.1.4.7. 存储驱动
Docker 使用了一系列不同的存储驱动管理镜像内的文件系统并运行容器，这些存储驱动与
Docker 卷（volume）有些不同，存储引擎管理着能够在多个容器之间共享的存储。
当镜像被 docker run 命令创建时就会在镜像的最上层添加一个可写的层，也就是容器层，所有对
于运行时容器的修改其实都是对这个容器读写层的修改。
13/04/2018 Page 282 of 283
容器和镜像的区别就在于，所有的镜像都是只读的，而每一个容器其实等于镜像加上一个可读写
的层，也就是同一个镜像可以对应多个容器
UnionFS 其实是一种为 Linux 操作系统设计的用于把多个文件系统‘联合’到同一个挂载点的文
件系统服务。而 AUFS 即 Advanced UnionFS 其实就是 UnionFS 的升级版，它能够提供更优秀
的性能和效率。
AUFS 只是 Docker 使用的存储驱动的一种，除了 AUFS 之外，Docker 还支持了不同的存储驱动，
包括 aufs、devicemapper、overlay2、zfs 和 vfs 等等，在最新的 Docker 中，overlay2 取代了
aufs 成为了推荐的存储驱动，但是在没有 overlay2 驱动的机器上仍然会使用 aufs 作为 Docker
的默认驱动。
30.1.5. Openstack
13/04/2018 Page 283 of 283