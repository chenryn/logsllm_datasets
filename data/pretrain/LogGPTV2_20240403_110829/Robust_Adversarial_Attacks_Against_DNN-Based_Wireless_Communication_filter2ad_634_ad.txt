straints are always enforced).
Note that, in the figures of the modulation recognition applica-
tion, we use the PSR of the perturbation for the x-axis while for
the other two applications, the SNR is used for the x-axis. This is
because the GNU radio ML dataset that we use in our modulation
recognition experiments only contains samples at the specific SNR
of 10 dB.
Autoencoder Communication System: Figure 3a shows the
block-error rate (BLER) performance of the autoencoder commu-
nication system under adversarial attack while using a PGM and
the single vector UAP attack proposed in [44]. To be consistent
with [44], we set 𝑁 = 7 and 𝑘 = 4. We sweep SNR from 0𝑑𝐵 to
14𝑑𝐵 with steps of 1𝑑𝐵, and for each value, we calculate the BLER
of the autoencoder system. Similar to [44], to compare the power
of the adversarial perturbation at the receiver with the received
signal, we introduce a parameter, the perturbation-to-signal ratio
(PSR), which equals the ratio of the received perturbation power to
the received signal power.
We see that for different PSR ratios, using a PGM to generate the
UAPs increases the performance of the adversarial attack in compari-
son to learning a single UAP. As mentioned in Section 6, the reason
is that by learning the parameters of a generator model instead
of learning a single perturbation vector, we can leverage existing
learning techniques (such as momentum-based ones) to ease the
process of learning and prevent common learning problems such
as getting stuck in local minima.
Modulation Recognition: Figure 3b shows the performance of
our adversarial attack using a PGM against the modulation recogni-
tion application over different values of PSR. The GNU [36] dataset
contains samples for different values of SNR; however, we apply
our attack using samples with SNR of 10 dB. Figure 3b also com-
pares our attack with the single vector UAP attack proposed by [43]
against the modulation recognition task. We see that using a PGM
does not provide a significant improvement over the single vector
UAP method in terms of attack performance when the wireless
system does not employ defenses. In Section 9, we will demonstrate
that the PGM is significantly more robust in the presence of defense
mechanisms compared to the single vector UAP technique.
OFDM Channel Estimation and Signal Detection: Similar to
the above two applications, we apply each of the single vector UAP
and adversarial PGM attacks on the DNN-based OFDM system
proposed by [49]. Because there is no reported prior adversarial
attack on the DNN-based OFDM system, we do not have a baseline
for comparison. Figure 3c shows the Bit Error Rate (BER) of the
OFDM system against the two mentioned adversarial attacks. The
SNR is varied from 5𝑑𝐵 to 25𝑑𝐵 and we evaluate our attack for
two values of PSR, −10𝑑𝐵 and −20𝑑𝐵. We see that using a PGM im-
proves the adversarial attack slightly compared to the single vector
UAP attack if the wireless system does not employ any defenses.
However, in Section 9, we will see that using our PGM makes the
attack significantly more robust against possible defenses.
8.2 Performance With Statistical
Undetectability
In this section, we evaluate our attack while enforcing a statistical
undetectability constraint using a GAN in the autoencoder com-
munication system. Note that this technique is easily applicable to
other systems since it uses a discriminator network independent of
the underlying DNN model in the wireless application. To investi-
gate the undetectability of the generated perturbations, we train
our discriminator in two scenarios: first, we train our discriminator
to be able to distinguish between adversarial noise and natural
Gaussian noise without enforcing an undetectability constraint on
the adversarial generator model. In the second scenario, we train
the discriminator while enforcing a Gaussian distribution on our
adversarial noise in the PGM. The evaluation metric for the dis-
criminator is the 𝑓 1_𝑠𝑐𝑜𝑟𝑒 which can be interpreted as a weighted
average of the precision and recall metrics.
Figure 4 shows the performance of the discriminator as well
as the generator in these two scenarios for different values of 𝛼
(denoting the strength of the undetectability constraint used in (5))
while the PSR of the generated perturbations is −6𝑑𝐵. For each
scenario and each value of 𝛼, we have evaluated the discrimina-
tor for different values of SNR and reported the average 𝑓 1_𝑠𝑐𝑜𝑟𝑒.
We see that without enforcing the undetectability constraint in
the PGM (𝛼 = 0), the discriminator is able to distinguish between
generated adversarial noise and Gaussian noise: the 𝑓 1_𝑠𝑐𝑜𝑟𝑒 is
nearly 1. On the other hand, when we enforce an undetectabil-
ity constraint in the PGM with 𝛼 = 50, the average 𝑓 1_𝑠𝑐𝑜𝑟𝑒 is
0.61, which means that the discriminator misclassifies the gen-
erated perturbations as Gaussian noise to some extent while the
performance of our attack slightly decreases compared to a sce-
nario where there is no undetectability constraint. By increasing 𝛼
to 500, the average 𝑓 1_𝑠𝑐𝑜𝑟𝑒 becomes 0.53 making our generated
noise more undetectable since the discriminator cannot distinguish
between Gaussian noise and adversarial noise. On the other hand
with 𝛼 = 500, our attack performs much worse than the case with
𝛼 = 50; however, it still degrades the performance of the autoen-
coder significantly. Therefore, by enforcing an undetectability
constraint, we can achieve high undetectability with only a
small degradation in the performance of our attack.
Session 1B: Attacks and Robustness CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea133Table 1: Details of the perturbation generation model in each wireless application
Autoencoder End-to-End Communication Modulation Recognition OFDM Channel Estimation
input size
hidden layers sizes
hidden layers activations
loss function
metric
optimizer
learning rate
2 × 7
100
ReLU
Adam
10−4
Cross Entropy
Block-Error Rate (BLER)
Leaky ReLU, Leaky ReLU
Leaky ReLU, Leaky ReLU
2 × 128
5000, 1000
Cross Entropy
Accuracy
Adam
10−3
256
5000, 1000
MSE
Adam
10−2
Bit Error Rate (BER)
(a) Autoencoder communication system
(b) Modulation recognition system, SNR=10𝑑𝐵
(c) OFDM system
Figure 3: Performance of our attack and the single vector UAP attack for the three target wireless systems in the absence
of defenses. The case where the receiver employs significant defenses, which is the case of most interest, is considered in
Section 9, where the significant advantages of our attack will be demonstrated.
the underlying DNN-based model including its structure and pa-
rameters. In this section, we evaluate our PGM in the black-box
setting where the attacker does not have any knowledge about the
underlying DNN model. Instead, the attacker uses its own substitute
model and then designs a white-box attack for it, as it has the per-
fect knowledge of the substitute model. The attacker then uses the
crafted perturbations to attack the original unknown underlying
DNN model. This is called a black-box adversarial attack [40]. Note
that in this setting, we assume that the attacker has access to a
training dataset from the same distribution of training data used
by the underlying target model.
Using this approach, for each target application, we use a substi-
tute model to design our PGM. We then use the PGM learned on
the substitute model to generate perturbations and apply them on
the original wireless DNN model. Note that this approach is gen-
eral such that the attacker can use any other DNN-based wireless
model to generate perturbations and attack the original underly-
ing DNN model. Table 5 in Appendix A shows the structure and
parameters of the substitute models. Figure 5 compares the perfor-
mance of our PGM attack in white-box and black-box scenarios
for three target wireless applications. Although our PGM attack
performs slightly worse in the black-box setting than in the
white-box setting, we observe that the attack is still effective
and degrades the performance of the three underlying DNN
models.
Figure 4: Performance of the autoencoder communication
system against PGM attack with and without the unde-
tectability constraint and the corresponding 𝑓 1_𝑠𝑐𝑜𝑟𝑒 of the
discriminator.
8.3 Performance In the Black-box Setting
All the previous evaluations were made assuming a (strong) white-
box adversary (see Section 5), i.e., an adversary who is aware of
02468101214SNR (dB)10−510−410−310−210−1100Block-error rate (log)no attackPGM attack, PSR = -2dBPGM attack, PSR = -10dBsingle UAP attack, PSR = -2dBsingle UAP attack, PSR = -10dB−20−18−16−14−12−10PSR (dB)0.450.500.550.600.650.70Accuracyno attack, PSR = 0dBsingle UAP attackPGM attack510152025SNR (dB)10−210−1BER (log)no attackPGM attack, PSR = -10dBPGM attack, PSR = -20dBsingle UAP attack, PSR = -10dBsingle UAP attack, PSR = -20dB02468101214SNR (dB)10−510−410−310−210−1Block-error rate (log)No attackWITHOUT undetectability constraint: α=0,f1_score=0.99WITH undetectability constraint: α=50,f1_score=0.61WITH undetectability constraint: α=500,f1_score=0.53Session 1B: Attacks and Robustness CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea134(a) Autoencoder communication system
(b) Modulation recognition system, SNR=10𝑑𝐵
(c) OFDM system
Figure 5: Performance of our attack with white-box and black-box scenarios for the three target wireless systems. Although
our PGM attack performs slightly worse in the black-box setting than in the white-box setting, we observe that the attack is
still effective and degrades the performance of the three underlying DNN models.
8.4 Attack’s Computational Complexity
We compare the complexity of our PGM attack algorithm with the
single vector UAP attack. Table 2 shows the average time required
to train a PGM compared to the average time a single vector UAP
attack needs to be trained for each target wireless application. Note
that the training time is calculated for a single PSR. Table 2 also
shows the average runtime of generating a single perturbation us-
ing the PGM attack during testing. We do not define this runtime
in the single vector UAP attack since the single perturbation is gen-
erated once and applied across all the inputs. Furthermore, We see
that although there are more parameters to learn for a PGM attack,
the times to perform the PGM and single vector UAP attacks
are comparable. The reason is that by learning the parameters
of a PGM instead of learning a single perturbation vector, we can
leverage existing learning techniques (such as momentum-based
ones) to speed up the process and prevent common learning prob-
lems such as getting stuck in local minima. Moreover, the attacker
needs to train the PGM only once for each wireless application
and he can use it for any input sample to attack the wireless system.
9 COUNTERMEASURES AND ROBUSTNESS
ANALYSIS
In this section, we propose two countermeasures as defense mech-
anisms against adversarial attacks in wireless communication sys-
tems. We apply these defenses to both the single vector UAP and
our PGM attacks and evaluate the performance of these attacks. The
performance of the defenses depends on what the defender knows
about the attack algorithms. In the following, we make assumptions
regarding what the adversary knows about both attacks.
Single Vector UAP Attack: We mentioned earlier that a single
UAP vector can be identified using pilot signals. A defender can
transmit known pilot signals and receive the perturbed signal. Since
the transmitted signal is known, the defender can subtract it from
the received signal and produce an estimate of the perturbation.
Therefore, in the single vector UAP attack, we assume that the
defender has knowledge about the perturbation generated by the
attacker.
Perturbation Generator Model: When the attacker uses a PGM,
the defender cannot identify the perturbations since the PGM gen-
erates a different perturbation vector for each input sample. Hence,
in this case, the defender can only obtain knowledge about the
PGM or an estimate of the generated perturbations. Based on this
knowledge, we assume three scenarios for the defender:
• Ad hoc defender: In this scenario, the defender is not aware of
the PGM, and similar to the defense mechanism proposed for
the single vector UAP attack, the defender uses pilot signals
to estimate the generated perturbations, e.g., the defender
transmits pilot signals and subtracts them from their corre-
sponding received signals, then she takes an average of the
results to obtain an estimate of the perturbations generated
by the PGM.
• Structure-aware defender: In this scenario, we assume that
the defender is aware of the structure of the PGM but not its
parameters. Hence, the defender needs to train the PGM on
her own training data and obtain the learned parameters. We
also assume that the defender has the same training dataset
as the adversary.
• Model-aware defender: In this scenario, we assume that the
defender is aware of both the structure of the adversary’s
PGM and its learned parameters. This is an impractical as-
sumption as the defender cannot obtain the learned parame-
ters of the PGM using pilot signals or any other techniques;
we still evaluate our attacks against this impractical adver-
sary.
Note that, in the above mentioned scenarios, we assume that the
defender is aware of the power constraint (𝑝) of the adversary. We
also evaluate our system against random smoothing defense in the
modulation recognition task; however, it is not as effective as other
proposed defenses.
02468101214SNR (dB)10−510−410−310−210−1100Block-error rate (log)no attackPGM attack in white-box setting, PSR = -6dBPGM attack in black-box setting, PSR = -6dBPGM attack in white-box setting, PSR = -2dBPGM attack in black-box setting, PSR = -2dB−20−18−16−14−12−10PSR (dB)0.400.450.500.550.600.650.70Accuracyno attack, PSR = 0dBPGM attack white-box settingPGM attack black-box setting510152025SNR (dB)10−210−1BER (log)no attackPGM attack white-box setting, PSR = -10dBPGM attack white-box setting, PSR = -20dBPGM attack black-box setting, PSR = -10dBPGM attack black-box setting, PSR = -20dBSession 1B: Attacks and Robustness CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea135Table 2: Comparing the complexity of the PGM attack and the single vector UAP attack
Autoencoder Encoder
Modulation Recognition
OFDM Channel Estimation
Training Time
53s
5s
46s
PGM Attack
Test Time
1.69 × 10−8s
2.34 × 10−7s
8.78 × 10−8
Number of Parameters
2914
6542256
6542256
Single Vector UAP Attack
Training Time
67s
20s