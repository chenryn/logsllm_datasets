https://cloud.google.com/
prediction. Accessed Feb. 10, 2016.
[26] HICKEY, W.
their Steak.
http://fivethirtyeight.com/datalab/how-americans-
like-their-steak, 2014. Accessed Feb. 10, 2016.
How Americans Like
[27] HINTON, G., VINYALS, O., AND DEAN, J. Distilling the knowl-
edge in a neural network. arXiv:1503.02531 (2015).
[28] HORNIK, K., STINCHCOMBE, M., AND WHITE, H. Multilayer
feedforward networks are universal approximators. Neural net-
works 2, 5 (1989), 359–366.
[29] HUANG, L., JOSEPH, A. D., NELSON, B., RUBINSTEIN, B. I.,
AND TYGAR, J. Adversarial machine learning. In AISec (2011),
ACM, pp. 43–58.
[30] JACKSON, J. An efﬁcient membership-query algorithm for learn-
In FOCS
ing DNF with respect to the uniform distribution.
(1994), IEEE, pp. 42–53.
[40] NEWSOME, J., KARP, B., AND SONG, D. Paragraph: Thwart-
ing signature learning by training maliciously. In RAID (2006),
Springer, pp. 81–105.
[41] NOCEDAL, J., AND WRIGHT, S. Numerical optimization.
Springer Science & Business Media, 2006.
[42] PEDREGOSA, F., VAROQUAUX, G., GRAMFORT, A., MICHEL,
V., THIRION, B., GRISEL, O., BLONDEL, M., PRETTEN-
HOFER, P., WEISS, R., DUBOURG, V., VANDERPLAS, J., PAS-
SOS, A., COURNAPEAU, D., BRUCHER, M., PERROT, M.,
AND DUCHESNAY, E. Scikit-learn: Machine learning in Python.
JMLR 12 (2011), 2825–2830.
[43] PREDICTIONIO. http://prediction.io. Accessed Feb. 10,
2016.
[44] RUBINSTEIN, B. I., BARTLETT, P. L., HUANG, L., AND TAFT,
N. Learning in a large function space: Privacy-preserving mech-
anisms for SVM learning. JPC 4, 1 (2012), 4.
[45] RUBINSTEIN, B. I., NELSON, B., HUANG, L., JOSEPH, A. D.,
LAU, S.-H., RAO, S., TAFT, N., AND TYGAR, J. Antidote:
understanding and defending against poisoning of anomaly de-
tectors. In IMC (2009), ACM, pp. 1–14.
[46] SAAR-TSECHANSKY, M., AND PROVOST, F. Handling missing
values when applying classiﬁcation models. JMLR (2007).
[47] SETTLES, B. Active learning literature survey. University of
Wisconsin, Madison 52, 55-66 (1995), 11.
[48] SHOKRI, R., AND SHMATIKOV, V. Privacy-preserving deep
learning. In CCS (2015), ACM, pp. 1310–1321.
[49] SMITH, T. W., MARSDEN, P., HOUT, M., AND KIM, J. General
social surveys, 1972-2012, 2013.
[50] STEVENS, D., AND LOWD, D. On the hardness of evading com-
binations of linear classiﬁers. In AISec (2013), ACM, pp. 77–86.
Theano: A Python
framework for fast computation of mathematical expressions.
arXiv:1605.02688 (2016).
[51] THEANO DEVELOPMENT TEAM.
[52] TOWELL, G. G., AND SHAVLIK, J. W. Extracting reﬁned rules
from knowledge-based neural networks. Machine learning 13, 1
(1993), 71–101.
[53] VALIANT, L. G. A theory of the learnable. Communications of
the ACM 27, 11 (1984), 1134–1142.
[54] VINTERBO, S. Differentially private projected histograms: Con-
struction and use for prediction. In ECML-PKDD (2012).
ˇSRNDI ´C, N., AND LASKOV, P. Practical evasion of a learning-
based classiﬁer: A case study.
In Security and Privacy (SP)
(2014), IEEE, pp. 197–211.
[31] JAGANNATHAN, G., PILLAIPAKKAMNATT, K., AND WRIGHT,
R. N. A practical differentially private random decision tree clas-
siﬁer. In ICDMW (2009), IEEE, pp. 114–121.
[55]
[32] KLOFT, M., AND LASKOV, P. Online anomaly detection under
adversarial impact. In AISTATS (2010), pp. 405–412.
[33] KUSHILEVITZ, E., AND MANSOUR, Y. Learning decision trees
using the Fourier spectrum. SICOMP 22, 6 (1993), 1331–1348.
[34] LI, N., QARDAJI, W., SU, D., WU, Y., AND YANG, W. Mem-
bership privacy: A unifying framework for privacy deﬁnitions. In
CCS (2013), ACM.
[35] LICHMAN, M. UCI machine learning repository, 2013.
[36] LOWD, D., AND MEEK, C. Adversarial learning.
(2005), ACM, pp. 641–647.
In KDD
[37] LOWD, D., AND MEEK, C. Good word attacks on statistical
spam ﬁlters. In CEAS (2005).
[38] MICROSOFT AZURE.
https://azure.microsoft.com/
services/machine-learning. Accessed Feb. 10, 2016.
[39] NELSON, B., RUBINSTEIN, B. I., HUANG, L., JOSEPH, A. D.,
LEE, S. J., RAO, S., AND TYGAR, J. Query strategies for evad-
ing convex-inducing classiﬁers. JMLR 13, 1 (2012), 1293–1332.
[56] ZHANG, J., ZHANG, Z., XIAO, X., YANG, Y., AND WINSLETT,
M. Functional mechanism: regression analysis under differential
privacy. In VLDB (2012).
[57] ZHU, J., AND HASTIE, T. Kernel logistic regression and the
import vector machine. In NIPS (2001), pp. 1081–1088.
A Some Details on Models
SVMs. Support vector machines (SVMs) perform bi-
nary classiﬁcation (c = 2) by deﬁning a maximally sep-
arating hyperplane in d-dimensional feature space. A
linear SVM is a function f (x) =sign(w · x + β ) where
‘sign’ outputs 0 for all negative inputs and 1 otherwise.
Linear SVMs are not suitable for non-linearly separable
data. Here one uses instead kernel techniques [14].
616  25th USENIX Security Symposium 
USENIX Association
A kernel is a function K : X ×X → R. Typical kernels
include the quadratic kernel Kquad(x,x(cid:28)) = (xT · x(cid:28) + 1)2
and the Gaussian radial basis function (RBF) kernel
Krbf(x,x(cid:28)) = e−γ||x−x(cid:28)||2, parameterized by a value γ ∈ R.
A kernel’s projection function is a map φ defined by
K(x,x(cid:28)) = φ (x)· φ (x(cid:28)). We do not use φ explicitly, in-
deed for RBF kernels this produces an infinite-dimension
Instead, classification is defined using a “ker-
vector.
nel trick”: f (x) =sign([ ∑t
i=1 αiK(x,xi)] +β ) where β is
again a learned threshold, α1, . . . ,α t are learned weights,
and x1, . . . ,x t are feature vectors of inputs from a training
set. The xi for which αi (cid:23)= 0 are called support vectors.
Note that for non-zero αi, it is the case that αi  0 otherwise.
Logistic regression. SVMs do not directly generalize to
multiclass settings c > 2, nor do they output class prob-
abilities. Logistic regression (LR) is a popular classi-
fier that does. A binary LR model is defined as f1(x) =
σ (w· x + β ) = 1/(1 + e−(w·x+β )) and f0(x) = 1− f1(x).
A class label is chosen as 1 iff f1(x) > 0.5.
When c > 2, one fixes c weight vectors w0, . . . ,w c−1
each in Rd, thresholds β0, . . . ,β c−1 in R and defines
j=0 ew j·x+β j ) for i ∈ Zc. The class la-
fi(x) =e wi·x+βi/(∑c−1
bel is taken to be argmaxi fi(x). Multiclass regression is
referred to as multinomial or softmax regression. An al-
ternative approach to softmax regression is to build a bi-
nary model σ (wi · x + βi) per class in a one-vs-rest fash-
ion and then set fi(x) =σ (wi · x + βi)/∑ j σ (w j · x + β j).
These are log-linear models, and may not be suit-
able for data that is not linearly separable in X . Again,
one may use kernel techniques to deal with more com-
plex data relationships (c.f., [57]). Then, one replaces
wi · x + βi with ∑t
r=1 αi,rK(x,xr) + βi. As written, this
uses the entire set of training data points x1, . . . ,x t as so-
called representors (here analogous to support vectors).
Unlike with SVMs, where most training data set points
will never end up as support vectors, here all training set
points are potentially representors. In practice one uses a
size s  t. This is a binary split
on a continuous feature with threshold t.
When we reach a leaf, we terminate and output that leaf’s
value. This value can be a class label, or a class label and
confidence score. This defines a function f : X → Y.
B Details on Data Sets
Here we give some more information about the data sets
we used in this work. Refer back to Table 3 and Table 5.
Synthetic data sets. We used 4 synthetic data sets from
scikit [42]. The first two data sets are classic examples
of non-linearly separable data, consisting of two concen-
tric Circles, or two interleaving Moons. The next two
synthetic data sets, Blobs and 5-Class, consist of Gaus-
sian clusters of points assigned to either 3 or 5 classes.
Public data sets. We gathered a varied set of data sets
representative of the type of data we would expect ML
service users to use to train logistic and SVM based mod-
els. These include famous data sets used for supervised
learning, obtained from the UCI ML repository (Adult,
Iris, Breast Cancer, Mushrooms, Diabetes). We also
consider the Steak and GSS data sets used in prior work
on model inversion [23]. Finally, we add a data set of dig-
its available in scikit, to visually illustrate training data
leakage in kernelized logistic models (c.f. Section 4.1.3).
Public data sets and models from BigML. For experi-
ments on decision trees, we chose a varied set of models
publicly available on BigML’s platform. These models
were trained by real MLaaS users and they cover a wide
range of application scenarios, thus providing a realistic
benchmark for the evaluation of our extraction attacks.
USENIX Association  
25th USENIX Security Symposium  617
The IRS model predicts a US state, based on admin-
istrative tax records. The Steak and GSS models re-
spectively predict a person’s preferred steak preparation
and happiness level, from survey and demographic data.
These two models were also considered in [23]. The
Email Importance model predicts whether Gmail clas-
sifies an email as ‘important’ or not, given message
metadata. The Email Spam model classifies emails as
spam, given the presence of certain words in its content.
The German Credit data set was taken from the UCI li-
brary [35] and classifies a user’s loan risk. Finally, two
regression models respectively predict Medical Charges
in the US based on state demographics, and the Bitcoin
Market Price from daily opening and closing values.
C Analysis of the Path-Finding Algorithm
In this section, we analyze the correctness and com-
plexity of the decision tree extraction algorithm in
Algorithm 1. We assume that all leaves are assigned a
unique id by the oracle O, and that no continuous fea-
ture is split into intervals of width smaller than ε. We
may use id to refer directly to the leaf with identity id.
Correctness. Termination of the algorithm follows im-
mediately from the fact that new queries are only added
to Q when a new leaf is visited. As the number of leaves
in the tree is bounded, the algorithm must terminate.
We prove by contradiction that all leaves are eventu-
ally visited. Let the depth of a node v, denote the length
of the path from v to the root (the root has depth 0). For
two leaves id, id(cid:30), let A be their deepest common ances-
tor (A is the deepest node appearing on both the paths of
id and id(cid:30)). We denote the depth of A as ∆(id, id(cid:30)).
Suppose Algorithm 1 terminates without visiting all
leaves, and let (id, id(cid:30)) be a pair of leaves with maxi-
mal ∆(id, id(cid:30)), such that id was visited but id(cid:30) was not.
Let xi be the feature that their deepest common ances-
tor A splits on. When id is visited, the algorithm calls
LINE SEARCH or CATEGORY SPLIT on feature xi. As all
leaf ids are unique and there are no intervals smaller than
ε, we will discover a leaf in each sub-tree rooted at A, in-
cluding the one that contains id(cid:30). Thus, we visit a leaf
id(cid:30)(cid:30) for which ∆(id(cid:30)(cid:30), id(cid:30)) > ∆(id, id(cid:30)), a contradiction.
Complexity. Let m denote the number of leaves in the
tree. Each leaf is visited exactly once, and for each leaf
we check all d features. Suppose continuous features
have range [0,b], and categorical features have arity k.
For continuous features, finding one threshold takes at
most log2( b
ε ) queries. As the total number of splits on
one feature is at most m (i.e., all nodes split on the same
feature), finding all thresholds uses at most m · log2( b
ε )
queries. Testing a categorical feature uses k queries.
The total query complexity is O(m· (dcat · k + dcont · m·
ε )), where dcat and dcont represent respectively the
log( b
number of categorical and continuous features.
For the special case of boolean trees, the complexity is
O(m· d). In comparison, the algorithm of [33], that uses
membership queries only, has a complexity polynomial
in d and 2δ , where δ is the tree depth. For degenerate
trees, 2δ can be exponential in m, implying that the as-
sumption of unique leaf identities (obtained from confi-
dence scores for instance) provides an exponential speed-
up over the best-known approach with class labels only.
The algorithm from [33] can be extended to regression
trees, with a complexity polynomial in the size of the out-
put range Y. Again, under the assumption of unique leaf
identities (which could be obtained solely from the out-
put values) we obtain a much more efficient algorithm,
with a complexity independent of the output range.
The Top-Down Approach. The correctness and com-
plexity of the top-down algorithm from Section 4.2
(which uses incomplete queries), follow from a similar
analysis. The main difference is that we assume that all
nodes have a unique id, rather than only the leaves.
D A Note on Improper Extraction
To extract a model f , without knowledge of the model
class, a simple strategy is to extract a multilayer percep-
tron ˆf with a large enough hidden layer. Indeed, feed-
forward networks with a single hidden layer can, in prin-
ciple, closely approximate any continuous function over
a bounded subset of Rd [20, 28].
However, this strategy intuitively does not appear to be
optimal. Even if we know that we can find a multilayer
perceptron ˆf that closely matches f , ˆf might have a far
more complex representation (more parameters) than f .
Thus, tailoring the extraction to the ‘simpler’ model class
of the target f appears more efficient. In learning theory,
the problem of finding a succinct representation of some
target model f is known as Occam Learning [13].
Our experiments indicate that such generic improper
extraction indeed appears sub-optimal, in the context of
equation-solving attacks. We train a softmax regression
over the Adult data set with target “Race”. The model
f is defined by 530 real-valued parameters. As shown in
Section 4.1.2, using only 530 queries, we extract a model
ˆf from the same model class, that closely matches f ( ˆf
and f predict the same labels on 100% of tested inputs,
and produce class probabilities that differ by less than
10−7 in TV distance). We also extracted the same model,
assuming a multilayer perceptron target class. Even with
1,000 hidden nodes (this model has 111,005 parameters),
and 10× more queries (5,300), the extracted model ˆf is
a weaker approximation of f (99.5% accuracy for class
labels and TV distance of 10−2 for class probabilities).
618  25th USENIX Security Symposium 
USENIX Association