B Comparison of InDif and Entropy-based
Metrics
To evaluate the impact of noise on the dependency metrics,
one should consider both sensitivity and the range of the met-
rics. In this section, we compare InDif with two dependency
metrics in the literature with respect to sensitivity and range.
Mutual Information (MI) [53]. PrivBayes adopts mutual
information to measure the dependency between attributes.
For attribute A and B, their mutual information I(A;B) is de-
ﬁned as 3
Pr [A = a,B = b]log Pr [A = a,B = b]
∑
Pr [A = a] Pr [B = b]
a∈dom(A)
n log n+1
From [53], we know that the sensitivity of MI is 2
2 +
n−1
n log n+1
n−1. Besides, the range of MI is [0,logc], where c =
max{cA,cB}, cA and cB are the number of possible values for
attribute A and B, respectively. Thus, the noise-range ratio of
MI is deﬁned as
b∈dom(B)
∑
RMI =
1
n
· 2log n+1
2 + (n + 1)log n+1
n−1
logc
3All logarithms used in this section are to the base 2.
c
n· RInDi f
n· RMI
n· REnt
2
2.0
39.3
41.8
50
2.0
7.0
7.4
100
2.0
5.9
6.3
1000
10000
100000
2.0
3.9
4.2
2.0
3.0
3.1
2.0
2.4
2.5
Table 3: Noise-range ratio of different metrics when n =
600000 and c is varying.
Adult
0.017
34
396
Accident
0.028
314
2858
Loan
0.161
543
4205
Colorado
0.137
735
6933
InDif
MI
SUC
Table 4: Relative error of different metrics when ε = 2.0.
Symmetrical Uncertainty Coefﬁcient (SUC) [12]. BSG
adopts symmetrical uncertainty coefﬁcient to measure the
dependency between attributes, which is deﬁned as
corr(A,B) = 2− 2
H(A,B)
H(A) + H(B)
where H(·) is the entropy function.
(cid:2)2 + 1
ln2 + 2logn(cid:3). Besides, the range of entropy is [0,logc].
To achieve differential privacy, the authors in [12] propose
to add noise to three entropy values in corr(A, B), respec-
tively. The authors prove that the sensitivity of entropy is
1
n
Thus, the noise-range ratio of entropy is given by
REnt =
1
n
· 2 + 1
ln2 + 2logn
logc
n · 2.
Comparison with InDif. Recall that the sensitivity and
range of InDif is 4 and [0,2n], respectively; thus, its noise-
range ratio is given by RInDi f = 1
We list the noise-range ratio of three methods in Table 3
when c varies. We set n = 600000 which is the case of three
datasets in our experiments. We observe that the noise-range
ratio of InDif is consistently smaller than the other two meth-
ods when c≤ 100000. In the three datasets in our experiments,
most of the attributes contains less than 100 possible values,
and the noise-range ratio of InDif is 3 times smaller than the
other two methods.
Comparison of Relative Errors. To further evaluate the
impact of noise on real-world datasets, we compare the rela-
tive errors between true values and noisy values of different
metrics in Table 4 when ε = 2.0. The relative errors are cal-
culated as 1
wise marginals, si and ˜si are the true value and noisy value of
marginal i, respectively. We run each experiment 1000 times
and report the average relative error.
(cid:12)(cid:12)(cid:12), where m is the total number of pair-
(cid:12)(cid:12)(cid:12) si− ˜si
m ∑m
i=1
si
The experimental results show that the relative errors of
InDif are signiﬁcantly smaller than MI and SUC. The rea-
son is that most of the MI values and SUC values are much
smaller than their maximal value logC, while most of the
InDif values are close to their maximal value 2n. For exam-
ple, in the Colorado dataset, 78% of the MI values and 87%
of the SUC values are smaller than 0.1 (much smaller than
USENIX Association
30th USENIX Security Symposium    945
logC). In another hand, 37% of the InDif values are larger
than 0.5n (close to 2n).
C Computational Complexity Analysis
PrivBayes
PGM
PrivSyn
Time Complexity
(cid:17)
(cid:16)
(cid:1) + nd
d(cid:0)d+1
O(cid:0)kpsd2 +tpskps
(cid:1)
O
O (tpgkpg + nd)
γ+1
Space Complexity
O (Cpbd + nd)
O (Cpgkpg + nd)
O (Cpskps + nd)
In this section, we ﬁrst theoretically analyze the computa-
tional complexity of different methods, and then empirically
evaluate the running time and memory consumption.
Time Complexity. The computational time for all methods
consist of two parts, marginal selection and dataset generation.
For PrivBayes, the marginals are selected by construct-
ing a Bayesian network. The general idea is to start with
a randomly selected node, then gradually add node to the
Bayesian network that maximally increase MI of the selected
nodes. To reduce time complexity, PrivBayes only consider
at most γ parents nodes in the selected nodes for each newly
added node. The number of pairs considered in iteration i is
(cid:1), where d is the number of attributes; thus summing
(d − i)(cid:0)i
(cid:0)i
(cid:1) = d(cid:0)d+1
(cid:1). In the dataset generation step, PrivBayes
over all iterations the computational complexity is bounded by
d ∑d
simply sample records one-by-one using the Bayesian net-
work; thus the time complexity is O (nd), where n is the
number of synthetic records.
γ+1
i=1
γ
γ
2
For PGM, except for marginal selection and dataset gener-
ation, it includes another component that learn the parame-
ters of Markov random ﬁeld. The core idea is to use all the
marginals and gradient decent to update the parameters. The
gradient decent process would repeat tpg times until conver-
gence. In practice, tpg is always set to be larger than 10000.
Thus, the time complexity for learning Markov random ﬁeld
is O (tpgkpg), where kpg is the number of marginals. The time
complexity for generating synthetic dataset is the same with
PrivBayes, i.e., O (nd). Notice that PGM does not provide
method to select marginals, we only report the time complex-
ity for parameter learning and dataset generation in Table 5.
possible pairwise
marginals in the marginal selection step. In iteration i of Algo-
rithm 1, we need to check m − i pairwise marginals; thus,
the time complexity is ∑kps
=
For PrivSyn, there are m =(cid:0)d
O(cid:0)kpsd2(cid:1). In the dataset generation step, we should go
i=1(m − i) = kpsm − kps(kps+1)
(cid:1) = d(d−1)
through all marginals tps times to ensure consistency. Thus,
the time complexity is tpskps and we typically set tps = 100.
Space Complexity. The memory consumption of all methods
consist of two parts, marginal tables and synthetic dataset. The
memory consumption of synthetic dataset for all methods are
the same, i.e., O (nd). The memory consumption for marginal
tables differs in the number of marginals k(cid:63) and the average
number of cells for each marginal C(cid:63). Speciﬁcally, PrivBayes
contains d − 1 marginals where each marginal contains at
most γ + 1 attributes. The number of marginals for PGM is
unlimited; however, when the number of marginals is large,
the Markov random ﬁeld can be dense, resulting in large
clique in the induced junction tree, which can be prohibitively
2
2
Table 5: Comparison of computational complexity for dif-
ferent methods. n,d,k(cid:63) stand for the number of records in
synthetic dataset, the number of attributes and the number of
marginals, respectively; C(cid:63) stands for the average number of
cells in each marginal; t(cid:63) stands for the number of required
iterations in each method.
Datasets
PrivBayes
PGM
PrivSyn
Adult
1 min
4 min
4 min
Accident
Loan
2 min
18 min
40 min
7 min
40 min
2 h 10 min
Colorado
10 min
1 h 10 min
3 h 30 min
Table 6: Comparison of running time for different methods.
Datasets
Adult
Accident
Loan
Colorado
PrivBayes
PGM
PrivSyn
0.06
0.06
0.06
0.13
0.13
0.13
0.36
0.36
0.36
0.43
0.43
0.43
Table 7: Comparison of memory consumption of different
methods. The unit is Gigabytes.
large. PrivSyn uses the 2-way marginal; thus the average
number of cells in each marginal is relatively small. The
number of marginals is typically in the range of [100,700] in
our experiment.
Empirical Evaluation. Table 6 and Table 7 illustrate the
running time and memory consumption for all methods on
four datasets in our experiment.
The empirical running time in Table 6 shows that PrivBayes
performs best in terms of running time, since it requires
only d − 1 marginals and the sampling process is very fast.
PGM uses the same set of marginals with PrivBayes, while
it needs additional time to learn the parameters of Markov
random ﬁeld, and the gradient decent process should repeat
more than 10000 times. PrivSyn is slower than PrivBayes
and PGM since it uses much more marginals. For example,
when ε = 2.0, the Colorado dataset has about 700 marginals,
while PrivBayes and PGM only have 96 marginals. Although
PrivSyn costs more time than PrivBayes and PGM, it only
takes less than 4 hours to generate large dataset such as Col-
orado (97 attributes with total domain of 5· 10162), which is
acceptable in practice considering its superior performance.
The empirical memory consumption in Table 7 shows that
the memory consumption for all methods are similar for the
same dataset. The reason is that the memory consumption for
all methods are dominated by the storage of synthetic datasets,
and the storage of marginal tables are less than 10 Megabytes
for all datasets.
946    30th USENIX Security Symposium
USENIX Association