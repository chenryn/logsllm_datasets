26/address-space-layout-randomization-\
\in-windows-vista.aspx, May 2006.
randomiza-
http://blogs.msdn.
[13] G. Hunt and D. Brubacher. Detours: Binary interception
of Win32 functions. In Proceedings of the USENIX Win-
dows NT Symposium, 1999.
[14] S. Karanth, S. Laxman, P. Naldurg, R. Venkatesan,
J. Lambert, and J. Shin. Pattern mining for future at-
tacks. Technical Report MSR-TR-2010-100, Microsoft
Research, 2010.
[15] A. Moshchuk, T. Bragin, S. D. Gribble, and H. M. Levy.
In Pro-
A crawler-based study of spyware on the web.
ceedings of the Network and Distributed System Security
Symposium. The Internet Society, 2006.
[16] J. Nazario. PhoneyC: A virtual client honeypot. In Pro-
ceedings of the Usenix Workshop on Large-Scale Exploits
and Emergent Threats, Boston, 2009.
[17] J. Newsome, B. Karp, and D. Song. Polygraph: Auto-
matically generating signatures for polymorphic worms.
In Proceedings of the IEEE Symposium on Security and
Privacy, 2005.
[18] M. Polychronakis, K. G. Anagnostakis, and E. P.
Markatos.
Emulation-based detection of non-self-
contained polymorphic shellcode. In Proceedings of the
Symposium on Recent Advances in Intrusion Detection,
2007.
The
“aurora”
in action.
IE
ex-
http:
[19] Praetorian
Prefect.
ploit used against Google
//praetorianprefect.com/archives/2010/01/
the-aurora-ie-exploit-in-action/, Jan. 2010.
[20] N. Provos, P. Mavrommatis, M. A. Rajab, and F. Mon-
rose. All your iFRAMEs point to us. In Proceedings of
the USENIX Security Symposium, 2008.
[21] P. Ratanaworabhan, B. Livshits, and B. Zorn. Nozzle: A
defense against heap-spraying code injection attacks. In
Proceedings of the USENIX Security Symposium, August
2009.
[22] K. Rieck, T. Krueger, and A. Dewald. Cujo: Efﬁcient de-
tection and prevention of drive-by-download attacks. In
Proceedings of the Annual Computer Security Applica-
tions Conference, 2010.
[23] M. Roesch. Snort – lightweight intrusion detection for
networks. In Proceedings of the USENIX Conference on
System Administration, 1999.
[24] C. Seifert, P. Komisarczuk, and I. Welch. Identiﬁcation of
malicious web pages with static heuristics. In Proceed-
ings of the Austalasian Telecommunication Networks and
Applications Conference, 2008.
[25] C. Seifert, R. Steenson, T. Holz, B. Yuan, and M. A.
Davis. Know your enemy: Malicious web servers. 2007.
[26] C. Song, J. Zhuge, X. Han, and Z. Ye. Preventing drive-
by download via inter-module communication monitor-
ing. In Proceedings of the Asian Conference on Comuting
and Communication Security, 2010.
[27] R. J. Spoor, P. Kijewski, and C. Overes. The HoneySpider
network: Fighting client-side threats. In Proceedings of
FIRST, 2008.
[28] T. Stuurman and A. Verduin. Honeyclients - low inter-
action detection methods. Technical report, University of
Amsterdam, 2008.
[29] T. Toth and C. Kr¨ugel. Accurate buffer overﬂow detec-
tion via abstract payload execution. In Proceedings of the
Symposium on Recent Advances in Intrusion Detection,
2002.
[30] K. Wang. HoneyClient. http://www.honeyclient.
org/trac, 2005.
[31] Y.-M. Wang, D. Beck, X. Jiang, R. Roussev, C. Ver-
bowski, S. Chen, and S. King. Automated web patrol
with Strider HoneyMonkeys: Finding web sites that ex-
ploit browser vulnerabilities. In Proceedings of the Net-
work and Distributed System Security Symposium, 2006.
[32] J. Zhuge, T. Holz, C. Song, J. Guo, X. Han, and W. Zou.
Studying malicious websites and the underground econ-
omy on the Chinese web. Technical report, University of
Mannheim, 2007.
Shellcode obfuscation strategy
unescape
unescape
unescape
unescape
none
hex, unescape
replace, unescape
unescape
replace, hex, unescape
custom, unescape
unescape
replace, array
unescape
unescape
replace, unescape
replace, unescape
unescape
unescape
hex, unescape
unescape
replace, unescape
unescape, array
replace, unescape
replace, unescape
replace, unescape
replace, unescape
Spray
(cid:88)
(cid:88)
(cid:88)
(cid:88)

(cid:88)

(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)

(cid:88)
(cid:88)
(cid:88)
(cid:88)


(cid:88)
(cid:88)
(cid:88)
(cid:88)

CVE
2009-0075
2009-1136
2010-0806
2010-0806
2010-0806
none
none
2009-1136
2010-0249
2010-0806
none
2010-0249
none
2009-1136
none
none
2010-0249
2010-0806
2008-0015
none
none
2010-0249
2010-0806
2010-0806
none
none
Figure 19: Malware samples dissected and categorized.
Figure 20: Classiﬁcation accuracy as a function of training set size for
hand-picked and automatically selected features.
A Hand-Analyzed Samples
In the process of training the ZOZZLE classiﬁer, we hand-
analyzed a number of malware samples. While there is a
great deal of duplication, there is a diversity of malware
writing strategies found in the wild.
Figure 19 provides additional details about each
unique hand-analyzed sample. Common Vulnerabilities
and Exposures (CVEs) are assigned when new vulnera-
bilities are discovered and veriﬁed, and these identiﬁers
are listed for all the exploits in Figure 19 that target some
vulnerability. Shellcode and nopsled type describe the
method by which JavaScript or HTML values are con-
verted to the binary data that is sprayed throughout the
heap. Most shellcode and nopsleds are written as hex-
adecimal literals using the \x escape sequence. These
cases are denoted by “hex” in Figure 19.
Many scripts use the %u encoding and are converted
to binary data with the JavaScript unescape function. Fi-
nally, some samples include short fragments inserted re-
peatedly (such as the string CUTE, which appears in sev-
eral examples) that are removed or replaced by a call to
the JavaScript replace function.
In a few cases, the exploit sample does not contain
one or more of the components of a heap spray attack
(shellcode, spray, and vulnerability). In these cases, the
script is delivered with one or more of the other samples
for which it may provide shellcode, perform a spray, or
trigger a vulnerability.
B Additional Experimental Data
Training set size: To understand the impact of training
set size on accuracy and false positive/negative rates, we
trained classiﬁers using between 1% and 25% of our be-
nign and malicious datasets. For each training set size,
ten classiﬁers were trained using different randomly se-
lected subsets of the dataset for both hand-picked and au-
tomatic features. These classiﬁers were evaluated with
respect to overall accuracy in Figure 20 and false posi-
tives/negatives in Figure 21a.
The ﬁgures show that training set size does have an
impact on the overall accuracy and error rates, but that
a relative small training set (< 5% of the overall data
set) is sufﬁcent to realize most of the beneﬁt. The false
positive negative rate using automatic feature selection
beneﬁts the most from additional training data, which is
explained by the fact that this classiﬁer has many more
features and beneﬁts from more examples to fully train.
Feature set size: To understand the impact of feature set
size on classiﬁer effectiveness, we trained the 1-level au-
tomatic classiﬁer, sorted the selected features by their χ2
value, and picked only the top N features. For this ex-
periment (due to the fact that the training set used is ran-
domly selected), there were a total of 1,364 features orig-
inally selected during automatic selection.
Figure 21b shows how the false positive and false neg-
ative rates vary as we change the size of the feature set to
contain 500, 300, 100, and 30 features, respectively.
The ﬁgures show that the false positive rate remains
low (and drops to 0 in some cases) as we vary the feature
set size. Unfortunately, the false negative rate increases
95%96%97%98%99%100%0%5%10%15%20%25%Accuracy Training Set Fraction Hand-PickedAutomatic(a) as a function of training set size.
(b) as a function of feature set size.
Figure 21: False positive and false negative rates.
function dF(s)
{
t = "";
var s1 = unescape(s.substr(0,s.length - 1)),
for(i = 0; i < s1.length; i++)
t += String.fromCharCode(
s1.charCodeAt(i) -
s.substr(s.length - 1,1));
document.write(unescape(t))
}
Figure 22: Code unpacker detected by anti-virus tools.
steadily with smaller feature set sizes. The implication
is that while a small number of features can effectively
identify some malware (probably the most commonly
observed malware), many of the most obscure malware
samples will remain undetected if the feature set is too
small.
C Additional Code Samples
Figure 22 shows a code unpacker that is incorrectly
ﬂagged by overly eager anti-virus engines. Of course,
the unpacker code itself is not malicious, even though the
contents it may unpack could be malicious. Finally, Fig-
ure 23 shows an example of code that anti-virus engines
overeagerly deem as malicious.
document.write(unescape(’%3C%73%63...’));
dF(’%264Dtdsjqu%264Fepdvnfou/xsjuf%2639
%2633%264Dtdsjqu%2631tsd%264E%266D%2633%2633
%2C%2633iuuq%264B00jutbmmcsfbltpgu/ofu0uet0jo/
dhj%264G3%2637tfpsfg%264E%2633
%2CfodpefVSJDpnqpofou%2639epdvnfou/sfgfssfs
%263%3A%2C%2633%2637qbsbnfufs%264E
%2635lfzxpse%2637tf%264E%2635tf%2637vs
%264E2%2637IUUQ%60SFGFSFS%264E%2633%2C
%2631fodpefVSJDpnqpofou%2639epdvnfou/VSM
%263%3A%2C%2633%2637efgbvmu%60lfzxpse
%264Eopuefgjof%2633%2C%2633%266D%2633
%264F%264D%266D0tdsjqu%264F%2633%263%3A
%264C%264D0tdsjqu%264F%261B%264Dtdsjqu%264F
%261Bjg%2639uzqfpg%2639i%263%3A%264E
%264E%2633voefgjofe%2633%263%3A%268C%261
%3A%261B%261%3Aepdvnfou/xsjuf%2639%2633
%264Djgsbnf%2631tsd%264E%2638iuuq
%264B00jutbmmcsfbltpgu/ofu0uet0jo/dhj%264G4
%2637tfpsfg%264E%2633%2CfodpefVSJDpnqpofou
%2639epdvnfou/sfgfssfs%263%3A%2C%2633
%2637qbsbnfufs%264E%2635lfzxpse%2637tf
%264E%2635tf%2637vs%264E2%2637IUUQ%60SFGFSFS
%264E%2633%2C%2631fodpefVSJDpnqpofou
%2639epdvnfou/VSM%263%3A%2C%2633%2637efgbvmu
%60lfzxpse%264Eopuefgjof%2638%2631xjeui
%264E2%2631ifjhiu%264E2%2631cpsefs%264E1
%2631gsbnfcpsefs%264E1%264F%264D0jgsbnf
%264F%2633%263%3A%264C%2631%261B%268E%261Bfmtf
%2631jg%2639i/joefyPg%2639%2633iuuq
%264B%2633%263%3A%264E%264E1%263%3A%268C%261B%261
%3A%261%3Axjoepx/mpdbujpo%264Ei%264C%261B
%268E%261B%264D0tdsjqu%264F1’)
Figure 23: Anti-virus false positive. A portion of the ﬁle after
unescape is removed to avoid triggering AV on the ﬁnal PDF of this
paper.
0%	
  1%	
  2%	
  3%	
  4%	
  0%	
  5%	
  10%	
  15%	
  20%	
  25%	
  False	
  Posi*ve	
  Rate	
  Training	
  Set	
  Frac*on	
  Hand-­‐Picked	
  Automa8c	
  0%	
  5%	
  10%	
  15%	
  20%	
  25%	
  0%	
  5%	
  10%	
  15%	
  20%	
  25%	
  False	
  Nega)ve	
  Rate	
  Training	
  Set	
  Frac)on	
  Hand-­‐Picked	
  Automa6c	
  0.00%0.05%0.10%0.15%0.20%0.25%030060090012001500False Positive Rate Features 0%5%10%15%20%25%030060090012001500False Negative Rate Features