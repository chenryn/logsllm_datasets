### ARIN, RIPE, APNIC & LACNIC: Sub-allocations and Ownership

**Table V: BPH Purchasing Details**
- **Acq Type**: Refers to the acquisition type, which can be either a test or a purchased IP address.

**Sub-allocations Per Day by Region and RIR:**
- **RIPE (Europe)**
  - Total: 4M
  - Owners: 1.3M
- **ARIN (North America)**
  - Total: 2.9M
  - Owners: 2M
- **APNIC (Asia)**
  - Total: 928K
  - Owners: 12K
- **LACNIC (South America)**
  - Total: 364K
  - Owners: 167K
- **AFRINIC (Africa)**
  - Total: 86K
  - Owners: 7K

**Table VI: Daily Processed Sub-allocations in IPv4, Ordered by RIR Size**
- **All**: Represents the total number of sub-allocations.
- **Owners?**: Represents the number of sub-allocations with known owners (i.e., managed by parties other than the parent service provider).
- **Owners**: Represents the total number of merged owner objects created for all sub-allocations over 25 Whois snapshots.

| # | All | Owners? | Owners |
|---|-----|---------|--------|
| Europe (RIPE) | 2.2M | 2.8M | 1.3M |
| North America (ARIN) | 462K | 357K | 2M |
| Asia (APNIC) | 100K | 72K | 12K |
| South America (LACNIC) | 34K | 7K | 167K |
| Africa (AFRINIC) | 7K | 1K | 7K |

### Selected System Features

**Table VII: Selected System Features**
- **Starred Features**: New PDNS features not used in previous research.
- **Whois Features**: Used in previous research but only for domain names.

| # | Type | Name | Normalized by |
|---|------|------|---------------|
| 1 | Whois | Sub-allocation size | Sub-allocation age |
| 2 | Whois | Sub-allocation age | DNS Age |
| 3 | BL | Blacklist | - |
| 4 | PDNS | Sub-allocation size | Sub-allocation size |
| 5 | PDNS | Sub-allocation age | Sub-allocation age |
| 6 | PDNS | AS Reputation | - |
| 7 | PDNS | Average Daily Traffic | - |
| 8 | PDNS | DNS Age | - |
| 9 | PDNS | Average Daily TLD+3 churn | - |
| 10 | PDNS | Average Daily TLD+3 | - |
| 11 | PDNS | TLD+3 Age | - |
| 12 | PDNS | Average Daily IP churn | - |
| 13 | PDNS | Daily IPs | - |
| 14 | PDNS | IP Up-time | - |
| 15 | PDNS | IP Age | - |
| 16 | PDNS | Net Utilization | - |

### Feature Selection for Malicious Sub-allocations

To address the challenge of detecting malicious sub-allocations, we select features that are robust and would likely incur significant costs (monetary or increased blacklisting) for evading. We leverage three groups of features: Whois, PDNS, and AS, totaling 14 features. Six of these features have never been used in previous research.

**PDNS Features:**
- **BPH Services**: Often use multi-layered infrastructure for protection, including front-end websites, fast fluxing, proxies, and redirection servers. This behavior is captured using 11 PDNS features.
- **DNS Look-ups**: Include traffic, daily number, and age of TLD+3 and IP addresses.
- **New Features**: Include daily churn of TLD+3 and IP addresses, continuous duration of IP address up-time, and total usage of sub-allocation’s IP addresses.

**Whois Features:**
- **Sub-allocation Size and Age**: Malicious sub-allocations tend to last for a few months before moving to another sub-allocation.

**AS Features:**
- **AS Reputation**: Leverages the reputation of the sub-allocation’s parent service provider.

### Evaluation

**Table VIII: Results of 5-Fold Cross-Validation on Two Classifiers**
- **SVM and RF**: Using labeled sets A and B.

| Metric | Set-A (SVM) | Set-B (SVM) | Set-A (RF) | Set-B (RF) |
|--------|-------------|-------------|------------|------------|
| Recall (TPR) | 92.2% | 89.8% | 96% | 98% |
| FDR | 1.2% | 3.1% | 2.3% | 1.5% |
| FPR | 5.5% | 3.1% | 11.7% | 1.6% |
| Accuracy | 92.6% | 93.2% | 97.8% | 97.1% |
| AUC | 93.3% | 93.3% | 93.1% | 97.2% |

**Figure 8: CDF Charts Showing Distribution of Two Selected Features on Labeled Sets**
- **Net Utilization**
- **AS Reputation**

### Training and Testing the Classifier

**Training:**
- **Set-A**: Small clean set, larger malicious set, biased towards malicious sub-allocations.
- **Set-B**: Balanced but noisier, includes all 818 sub-allocations from top 100 hosting providers.

**Evaluation:**
- **5-Fold Cross-Validation**: RF outperforms SVM on balanced Set-B, while SVM handles unbalanced Set-A better.
- **Testing on Noisy Labeled Sets**: RF model trained on Set-B detects 33% of the purchased set, while the Set-A model detects twice as many. The Set-B model also detects 43% of the labeled clean set as malicious.

**Table IX: Testing Results of the Random Forest (RF) Model Trained with Set A & B on Noisy Labeled Sets**

| Source | Label | Set-A (TPR) | Set-A (TNR) | Set-B (TPR) | Set-B (TNR) |
|--------|-------|-------------|-------------|-------------|-------------|
| Alexa[4] | Clean - Noisy | - | 84% | - | 95.5% |
| Top 100 Hosters[5] | Clean - Noisy | - | 87.4% | - | 57.1% |
| Top 500 Hosters[5] | Clean | - | 76.1% | - | 97.6% |
| ROKSO[26] | Malicious - Archived | 53% | - | 55% | - |
| Purchased | Clean - Noisy | 66.6% | - | 33.3% | - |

### Evaluation on Unlabeled Set

- **July 12th, 2016 Snapshot**: Detected 40K (20%) and 20K (10%) sub-allocations using Set-A and Set-B respectively.

**Indicators of Badness:**
- **Non-operational TLD+3**
- **Matched BL TLD+3**
- **Matched BL IPs**
- **Distribution of FQDNs over TLD+3**

This comprehensive approach ensures a robust detection system for identifying and mitigating malicious sub-allocations.