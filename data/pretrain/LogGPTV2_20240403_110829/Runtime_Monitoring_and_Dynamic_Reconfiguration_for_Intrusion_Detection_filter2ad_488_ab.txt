ing. We use the minimized attack trees to determine the composition of challenges for
evaluating the internal components (Sect. 4.3).
Runtime Monitoring and Dynamic Reconﬁguration for Intrusion Detection Systems
67
4.1 Attack Trees
Attack trees depict how an attacker can attain a certain goal, e.g., to gain unauthorized
access to a system resource. This overall goal constitutes a threat to a security system
and builds the root of an attack tree.
The attack tree shows the alternative ways of how an attacker can reach the root,
and so realize the threat. As formalized in [14], an attack tree is composed of AND
and OR branches. Figure 4 shows a simple example of an attack tree structure. In this
ﬁgure, the branch with a connectional arc depicts an AND branch, all other branches
are OR branches. To reach the root, the attacker has to conduct a series of basic network
attacks, e.g., “horizontal scan”, which we call the atomic attacks. These atomic attacks
constitute the leafs of an attack tree. An attacker ”reaches” a leaf if he conducts the
corresponding attack. Then, either if all children of a node with an AND branch are
reached, then the node itself is reached. Similarly, an OR branched node is reached,
if at least one of its children is reached. This way, starting at the leafs by conducting
atomic attacks, an attacker can work its way up to the root. For our example in Fig. 4,
the attacker can for instance reach the root by performing the attacks A3 and A2.
The principal advantages of the attack tree formalism are its simplicity, relatively
high expressivity, and generality: an attack tree-level description of the threat is easily
transferable between the networks and can be thus reused.
4.2 Attack Trees in Propositional Logic
We can say, an attacker can reach the root node by reaching speciﬁc subsets of the leafs.
In this section we show how these speciﬁc subsets can be identiﬁed and minimized in
a neat manner. First, we represent an attack tree in propositional logic. A formula cor-
responding to a tree should become true iff the main goal in the attack tree is attained.
To build such a formula, we ﬁrst create a literal for each atomic attack. Now, we suc-
cessively go through the tree (starting from the root node), and connect all children of
a node by the appropriate logic operation (OR for disjunctive branches, AND for con-
junctive branches). Parentheses are used to group the children together. For the example
tree shown in Fig. 4 this results in the formula:
(A1) ∨ ((A3 ∨ A4) ∧ (A2)) .
(1)
A formula is in Disjunctive Normal Form (DNF) iff it is a disjunction of conjunctive
clauses. A formula is canonical, if all clauses contain all variables. We can bring any
formula into canonical DNF by building a truth table that contains all variables, and
taking all rows that evaluate to true as clauses. For our toy example in Fig. 4 that would
result in:
(A1 ∧ A2 ∧ A3 ∧ A4)
∨(A1 ∧ A2 ∧ A3 ∧ ¬A4)
∨(A1 ∧ A2 ∧ ¬A3 ∧ A4)
∨
. . .
(2)
(3)
(4)
(5)
68
M. Reh´ak et al.
Having an attack tree in canonical DNF, we can say, that an attacker realizes the threat
if he succeeds to make at least one clause true. However, there is still much redundancy
in the formula. For example, lines 2 and 3 together are logically equivalent to A1 ∧
A2 ∧ A3. To remove all redundancy from the formula, we simply apply the Quine-
McCluskey algorithm [15]. Note that when simplifying attack tree formulas, clauses
will only contain positive literals. For the attack tree in Fig. 4, we ﬁnally get:
(A1) ∨ (A3 ∧ A2) ∨ (A4 ∧ A2) .
(6)
A formula in DNF can be written as a set of clauses {C1, C2, . . .} where each clause Ci
is a set of positive literals {li1, li2, . . .}. We will write F (T ) for the minimal formula
in DNF that corresponds to attack tree T . The attack tree from Fig. 4 can be formalized
as:
F (T ) = {{A1},{A2, A3},{A2, A4}} .
(7)
4.3 Attack Tree Valuation
In this section, we ﬁrst show how different attack classes can be prioritized, depending
on the expected damage of the successful attacks, i.e. the attack tree root being attained
by the adversary. We then show how the resulting priorities can be used to determine
the composition of challenges for adapting the IDS. Finally, we exemplify the procedure
with an example for a speciﬁc attack tree.
We assume, that a set of n detectable attacks A = {A1, . . . , An} and general net-
work conditions are known to the conﬁgured IDS. These attacks are classiﬁed into K
k ACk = A. We don’t require that all attacks
attack classes {AC1, . . . , ACK}, with
in an attack class are known, as the system is able to assess its effectiveness against
the attacks inserted into the trafﬁc in real-time. However, we require a sufﬁcient set of
attacks for each attack class, in order to use these samples as challenges.
(cid:2)
The problem now is to prioritize the detection of attack classes. To this end, the
following criteria should be fulﬁlled:
Attack trees: An attacker has a certain goal (which determines the attack tree T ). At-
tack trees that cause more damage should be prioritized.
Clauses: An attacker tries to make one clause true in a chosen formula F (T ). Any
clause made true causes the same damage D(T ). So each clause is assigned the
same priority.
Literals: For making a chosen clause true, an attacker needs to make true all literals
in this clause to cause damage D(T ). Therefore, all literals belonging to the same
clause should be equally prioritized.
To fulﬁll the last two criteria, we compute the priority of an attack Ai within a tree Tj
as follows:
P (Ai, Tj) :=
1
|F (Tj)|
(cid:3)
Ck∈F (Tj ),
with Ai∈Ck
1
|Ck| .
(8)
Runtime Monitoring and Dynamic Reconﬁguration for Intrusion Detection Systems
69
The reader can easily verify that if Ai is not in Tj, then its priority within the tree is
zero. Also, the sum of all priorities of the attacks in the tree is 1. To fulﬁll the ﬁrst
criterion, we additionally weight each tree Tj according to the damage D(Tj) and get
the ﬁnal priority for an attack Ai by summing over all attack trees:
P (Ai) :=
(cid:4)
1
Tj∈T D(Tj)
· (cid:3)
Tk∈T
D(Tk) · P (Ai, Tk) .
(9)
Because of the normalization, again the priorities of all attacks sum up to 1. Hence, we
can use these priorities to directly determine the ratio of challenges to test the respective
attacks.
In order to calculate the priorities of the attacks in A, we propose the
Procedure.
following procedure:
1. For each tree Ti ∈ T do:
(a) Prune all impossible and non-detectable attacks from the tree.
(b) Build F (Ti): Transform the tree into a logical formula, bring it into DNF and
minimize it (as in Sect. 4.2).
2. Compute P (Ai) for each attack Ai as shown in formula (9).
3. For each attack class AC, add the priorities for all attacks in that class:
P (AC) =
(cid:3)
Ai∈AC
P (Ai) .
(10)
The ratio P (AC) is a proportion of challenges from the class AC, and we will use
it to as a weight in Eq. 22.
Example. In this section we show how the priorities are computed for a set of two very
simple example attack trees T1 and T2 shown in Fig. 5 and 6 respectively. We estimate
the damages of the trees to be D(T1) = 900 and D(T2) = 100. The minimal formulas
in DNF for the two attack trees are:
F (T1) ={{A1, A2, A3},{A1, A4, A5}} ,
F (T2) ={{A6},{A7},{A8}} .
(11)
(12)
server takeover
A1
·
·
·
A2
A3
A4
A5
attack description
A1 horizontal scan
A2 ﬁngerprinting
A3 buffer overﬂow
A4 SSH brute force request
A5 SSH brute force response
attack class
AC1
AC2
AC3
AC4
AC4
Fig. 5. Example Attack Tree T1
70
M. Reh´ak et al.
ﬁle sharing
A6
A7
A8
attack description
A6 download
A7 upload
A8 directory node
attack class
AC5
AC5
AC5
Fig. 6. Example Attack Tree T2
We can now compute P (Ai, Tj) for all attacks. Clearly P (A1, T2) = 0, so let us look
at P (A1, T1):
P (A1, T1) =
(cid:5)
1
|F (T1)|
1
|C1| +
1
|C2|
(cid:6)
=
1
2
(cid:5)
(cid:6)
1
3
+
1
3
=
1
3 .
Analogously we obtain:
P (A2, T1) = P (A3, T1) = P (A4, T1) = P (A5, T1) =
1
2
∗ 1
3
=
1
6 .
For attack tree T2 we get:
P (A6, T2) = P (A7, T2) = P (A8, T2) =
1
3 .
Now, combining the two trees according to their expected damage, we obtain:
P (A1) =
D(T1)
D(T1) + D(T2)
· P (A1, T1) =
9
10
· 1
3
=
3
10 .
(13)
(14)
(15)
(16)
In the same way, we obtain for the other attacks:
P (A2) = P (A3) = P (A4) = P (A5) =
3
20 , P (A6) = P (A7) = P (A8) =
1
30 .
(17)
Finally, we can compute the attack class priorities:
P (AC1) =
3
10 , P (AC2) = P (AC3) =
3
20 , P (AC4) =
3
10 , P (AC5) =
1
10 . (18)
5 Dynamic Aggregation Agent Selection
The insertion of challenges into the real trafﬁc is not only a difﬁcult problem from the
technical perspective (due to the high volume of events processed in near-real-time and
hard performance limitations of the system), but can also inﬂuence the effectiveness of
the aggregation agents based on anomaly detection approaches. As these agents are not
able to distinguish the challenges from the real events, the challenges are included in
their trafﬁc model, making it less representative of the background trafﬁc and therefore
reducing its predictive ability.
Runtime Monitoring and Dynamic Reconﬁguration for Intrusion Detection Systems
71
In this section, we present a trust-based algorithm which dynamically determines the
best aggregation agent and also the optimal number of challenges necessary for the re-
liable identiﬁcation of the best aggregation agent, while taking into account the: (i) past
effectiveness of the individual aggregation agents and (ii) number of aggregation agents
and the perceived differences in their effectiveness. We decided to use a trust-based ap-
proach for evaluating the aggregation agents, because it not only eliminates the noise in
the background trafﬁc and randomness of the challenge selection process, but accounts
for the fact that attackers might try to manipulate the system by inserting misleading
trafﬁc ﬂows. An attacker could insert fabricated ﬂows [13] hoping they would cause
the system to select an aggregation agent that is less sensitive to the threat the attacker
actually intends to realize. When using trust, one tries to avoid this manipulation by
dynamically adapting to more recent actions of an attacker.
For each time step i ∈ N, the algorithm proceeds as follows:
1. Let each aggregation agent classify a set of challenges from different attack classes
and selected legitimate challenges.
2. Update the trust value of each aggregation agent, based on its performance on the
challenges in time step i.
3. Accept the output of the aggregation agent with the highest trust value as classiﬁ-
cation of the remaining events of time step i.
As we have stated above, we challenge detection and aggregation agents in each time
step i with the sets of ﬂows for which we already know the actual class, i.e. whether
they are malicious or legitimate. So, we challenge an aggregation agent α with a set of
malicious events, belonging to K attack classes and a set of legitimate events drawn
from a single class. With respect to each class of attacks k, the performance of the
agent is described by a mean and a standard deviation: (¯xk, σk
) for the set of malicious
challenges and (¯y, σy) for the set of legitimate challenges. Both means lie in the interval
[0, 1], and ¯xk close to 0 and ¯y close to 1 signify accurate classiﬁcations of the agent
respectively (see Fig. 7). Based on this performance in time step i, we deﬁne the trust