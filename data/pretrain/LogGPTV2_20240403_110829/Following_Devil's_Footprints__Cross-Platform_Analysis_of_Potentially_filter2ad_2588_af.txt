Also the app checks android.permission.RECORD AUDIO
before recording audio (Figure 18).
V. RELATED WORK
Mobile malware detection and prevention. A lot of effort
has been made to analyze and detect Android PHAs, most
of which aims at detecting the code [37], [38], [39], [40],
[41], [42], [43], [44], [45] for performing potentially harmful
behaviors (e.g., stealing the user’s sensitive information), and
protecting the Android system from various attacks [46], [47],
[48], [49], [50], [51], [52], [53]. Unlike these prior studies,
which mainly work at the app level, our research focuses on
discovering and analyzing mobile libraries and their harmful
behaviors, which has never been done before.
Compared with the research on Android, little has been done
on the iOS front. Among few examples is PiOS [54], the ﬁrst
static tool to detect privacy leaks in iOS apps. When it comes to
dynamic analysis, prior research [55] highlights the challenges
in analyzing iOS programs. To address the issues, DiOS [56]
uses UI automation to drive execution of iOS application, trying
to trigger more events. Further, by combining dynamic binary
instrumentation (through porting Valgrind [57] to iOS) and
static analysis, iRiS [58] analyzes the API calls within iOS
apps to ﬁnd the abuse of private APIs. Other examples include
MoCFI [59] that extracts the CFG of a program using PiOS
and checks whether the instructions that change an execution
ﬂow are valid at runtime, and PSiOS[60] that enforces privacy
370370
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:16:50 UTC from IEEE Xplore.  Restrictions apply. 
protection on top of MoCFI. None of the existing research
seriously investigates potentially harmful apps on the Apple
platform, largely due to the lack of ground truth.
Invariants inference. Invariants are widely used in ﬁnding
a program’s vulnerabilities [21], [24], [61], [25], which are
typically discovered through dynamically analyzing the pro-
gram [21]. More speciﬁcally, the program’s runtime information
is ﬁrst collected to derive the invariable features before
dynamically analyzing the program; any violation of the
invariants detected in the analysis could indicate a program
error. All the prior studies on this subject are performed on the
same platforms, and most of the time on the same program
or its variations. Never before has any attempt been made to
identify cross-platform invariants for PHA analysis, which has
been done in our research. Particularly, our invariant analysis
is fully static, since this is the only way to make the analysis
scalable, up to the job of processing 140,000 iOS apps.
Cross-platform analysis. Cross-platform security studies are
known to be challenging. Still some work has been done in this
area, mostly for vulnerability analysis. A prominent example
is the recent work that ﬁnds similar bugs cross architectures
(X86, MIPS, ARM) within the same program that can be
compiled into different executables for those architectures [62].
By comparison, we are looking for potentially harmful code
within the programs independently developed by different
parties. Linking them together is clearly much more difﬁcult.
Also related to our work is the effort to establish a baseline for
security comparison between Android and iOS apps, in which
manually selected app pairs are analyzed to ﬁnd out how they
access security-sensitive APIs [63]. In our study, we have to
develop technique to automatically correlate Android and iOS
code and discover the harmful behavior both programs involve.
VI. DISCUSSION
Understanding PhaLibs. All the iOS PhaLibs in our study
were found from the invariants shared with their Android
counterparts. The invariants used in our study, constant strings,
were shown to be highly reliable, introducing almost no false
positives. On the other hand, this approach does have false
negatives, missing the iOS classes that do not share any
strings with their Android versions. Even though this limitation
has been somewhat made up by our extension technique,
which starting from a few anchors, recovers 71.16% of the
classes within a library, certainly some classes or even libraries
fall through the cracks. A more comprehensive study could
rely on the combination of the constant strings and other
invariant features across the platforms, e.g., code structure and
intermediate variables.
More fundamentally, the methodology of mapping Android
PhaLibs to iOS apps misses the libraries built solely for
the iOS platform. As an example, among the top 38 iOS
libraries given by SourceDNA, 36 do have Android versions.
We used this methodology for the purpose of understanding the
relations between Android and iOS libraries and also leveraging
VirusTotal to identify potentially harmful behaviors within iOS
apps. The consequence, however, is that almost certain we
underestimate the scope and magnitude of the PHA threat
on the Apple platform. For example, our estimate of 2.94%
of PHAs on the Apple App Store is very much on the low
end. The real percentage could come much closer to that of
Google Play. Further research on the iOS PhaLibs may require
development of new techniques for a large-scale code similarity
search over the iOS apps and comprehensive deﬁnitions of
potentially harmful behaviors within these apps.
Identifying potentially-harmful behavior. Both the PhaLibs
on the Android and iOS sides are identiﬁed, directly or
indirectly, by VirusTotal. To determine the potential harmful
behavior within an iOS library, we have to translate it into that
inside an Android PhaLib and utilize a black-box technique
to ﬁnd out whether the behavior is part of a PHA signature.
Such a translation and analysis, based upon IAC sequences,
are less accurate, introducing 3.3% false positives and certainly
missing the harmful activities that do not have the Android
counterpart. Future research will explore a more effective way
to export Android-side suspicious behaviors to the iOS platform,
supporting direct PHA scanning on iOS apps. Also importantly,
the techniques not relying on behavior and content signatures,
as proposed in the prior research [64], should be developed for
detecting the PHAs with previously unknown harmful behavior.
Evading. It is important to note that the techniques we used
for PhaLib analysis across platform are not meant for PHA
detection. As mentioned earlier, our approach only focuses on
a subset of PHAs, those detected by VirusTotal on Android
and those including the PhaLib with an Android counterpart on
iOS. Even for such apps, the possibility is always there for the
PHA authors to obfuscate their invariants to deter our cross-
platform analysis. Future study is certainly needed to ﬁnd a
more reliable mapping, making such evasion harder. That being
said, our study reveals the pervasiveness of PhaLibs and their
cross-platform deployment, helping the research community
better understand how such harmful code is propagated, a
critical step towards ultimately defeating the threat they pose.
VII. CONCLUSION
This paper reports the ﬁrst systematic study on mobile
PhaLibs across Android and iOS platforms. Our research is
made possible by a unique methodology that leverages the
relations between the Android and iOS versions of the same
libraries, which helps get around the technical challenges in
recovering library code from iOS binary code and determining
whether it is indeed potentially harmful. Running the method-
ology on 1.3 million Android apps and 140,000 iOS apps,
we discovered 6.84% of PHAs on Google Play and 2.94% of
PHAs on the Apple App Store. Looking into their behaviors,
we discovered the high-impact back-door PhaLibs on both sides
and their relations. Also we found further evidence that library
contamination could be an important channel for propagating
potentially harmful code. This study made the ﬁrst step toward
understanding mobile PhaLibs across the platforms and PHA
detection on iOS.
371371
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:16:50 UTC from IEEE Xplore.  Restrictions apply. 
ACKNOWLEDGEMENT
We thank our shepherd Franziska Roesner and anonymous re-
viewers for their valuable comments. We also thank VirusTotal
for the help in validating suspicious apps in our study. Kai Chen
was supported in part by NSFC U1536106, 61100226, Youth
Innovation Promotion Association CAS, and strategic priority
research program of CAS (XDA06010701). The IU authors
are supported in part by the NSF CNS-1223477, 1223495
and 1527141. Yingjun Zhang was supported by National High
Technology Research and Development Program of China (863
Program) (No. 2015AA016006) and NSFC 61303248.
REFERENCES
[1] Google, “Google report: Android security 2014 year
in review,”
https://static.googleusercontent.com/media/source.android.com/en/secu-
rity/reports/Google Android Security 2014 Report Final.pdf, 2014.
[2] K. Chen, P. Wang, Y. Lee, X. Wang, N. Zhang, H. Huang, W. Zou, and
P. Liu, “Finding unknown malice in 10 seconds: Mass vetting for new
threats at the google-play scale,” in USENIX Security, vol. 15, 2015.
[3] SourceDNA,
apis,”
https://sourcedna.com/blog/20151018/ios-apps-using-private-apis.html,
2015.
private
caught
using
apps
“ios
[4] C.
Xiao,
“Novel
apple
malware
apps
xcodeghost
modiﬁes
store,”
infects
xcode,
http://researchcenter.paloaltonetworks.com/2015/09/novel-malware-
xcodeghost-modiﬁes-xcode-infects-apple-ios-apps-and-hits-app-store/,
Tech. Rep., 2015.
hits
and
app
ios
[5] K. Chen, P. Liu, and Y. Zhang, “Achieving accuracy and scalability
simultaneously in detecting application clones on android markets,” in
ICSE, 2014.
[6] “A private website,” https://sites.google.com/site/phalibscom/, 2015.
[7] F-Secure, “Q1 2014 mobile threat report - f-secure,” https://www.f-
secure.com/documents/996508/1030743/Mobile Threat Report Q1
2014.pdf, Mar 2014.
[8] M. Kassner, “Google play: Android’s bouncer can be pwned,”
http://www.techrepublic.com/blog/it-security/-google-play-androids-
bouncer-can-be-pwned/, 2012.
[9] J. Erwin, “Where did virusbarrier ios go?” http://www.intego.com/mac-
security-blog/where-did-virusbarrier-ios-go/, 2015.
[10] J.
Leyden,
apps
an-
tivirus
spared?”
http://www.theregister.co.uk/2015/03/24/ios anti malware confusion/,
2015.
one: Who’ll
“Apple
one
picking
ios
off
by
be
is
[11] VirusTotal, “A closer
look at mac os x executables and ios
http://blog.virustotal.com/2014/12/a-closer-look-at-mac-os-
apps,”
x-executables.html, 2014.
[12] T. iphone wiki, “Malware for ios,” https://www.theiphonewiki.com/wiki/
Malware for iOS, 2015.
[13] VirSCAN,
is
http://www.virscan.org/, 2015.
“Virscan.org
[14] S. Fadilpai, “Android is
for mobile mal-
ware,” http://betanews.com/2015/06/26/android-is-the-biggest-target-for-
mobile-malware/, 2015.
the biggest
target
[15] AppBrain,
“Android
ad
network
stats,”
[16] “Admob
http://www.appbrain.com/stats/libraries/ad?sort=apps, 2015.
get
https://developers.google.com/admob/android/quick-
start#load the ad in the mainactivity class, November 2015.
android,
for
started,”
[17] iana, “Root zone database,” https://www.iana.org/domains/root/db, 2015.
[18] M. Ester, H.-P. Kriegel, J. Sander, and X. Xu, “A density-based algorithm
for discovering clusters in large spatial databases with noise.” in Kdd,
vol. 96, no. 34, 1996, pp. 226–231.
[19] W. Zhou, Y. Zhou, X. Jiang, and P. Ning, “Detecting repackaged
smartphone applications in third-party android marketplaces,” in
Proceedings of the Second ACM Conference on Data and Application
Security and Privacy, ser. CODASPY ’12. New York, NY, USA:
ACM, 2012, pp. 317–326. [Online]. Available: http://doi.acm.org/10.
1145/2133601.2133640
[20] J. Pewny, B. Garmany, R. Gawlik, C. Rossow, and T. Holz,
“Cross-architecture bug search in binary executables,” in 2015 IEEE
Symposium on Security and Privacy, SP 2015, San Jose, CA,
USA, May 17-21, 2015, 2015, pp. 709–724. [Online]. Available:
http://dx.doi.org/10.1109/SP.2015.49
[21] M. Ernst, J. Cockrell, W. G. Griswold, and D. Notkin, “Dynamically
discovering likely program invariants to support program evolution,”
Software Engineering, IEEE Transactions on, vol. 27, no. 2, pp. 99–123,
Feb 2001.
[22] “Clutch,” https://github.com/KJCracks/Clutch.
[23] Capstone, “Capstone is a lightweight multi-platform, multi-architecture
disassembly framework,” http://www.capstone-engine.org/.
[24] S. Hangal and M. S. Lam, “Tracking down software bugs
using automatic anomaly detection,” in Proceedings of
the 24th
International Conference on Software Engineering, ser. ICSE ’02.
New York, NY, USA: ACM, 2002, pp. 291–301. [Online]. Available:
http://doi.acm.org/10.1145/581339.581377
[25] Y. Kataoka, D. Notkin, M. D. Ernst, and W. G. Griswold, “Automated
support for program refactoring using invariants,” in Proceedings of the
IEEE International Conference on Software Maintenance (ICSM’01), ser.
ICSM ’01. Washington, DC, USA: IEEE Computer Society, 2001, pp.
736–. [Online]. Available: http://dx.doi.org/10.1109/ICSM.2001.972794
[26] C. Zheng, S. Zhu, S. Dai, G. Gu, X. Gong, X. Han, and W. Zou,
“Smartdroid: An automatic system for
revealing ui-based trigger
conditions in android applications,” in Proceedings of the Second ACM
Workshop on Security and Privacy in Smartphones and Mobile Devices,
ser. SPSM ’12. New York, NY, USA: ACM, 2012, pp. 93–104.
[Online]. Available: http://doi.acm.org/10.1145/2381934.2381950
[27] M. Christodorescu, S. Jha, S. Seshia, D. Song, and R. Bryant, “Semantics-
aware malware detection,” in Security and Privacy, 2005 IEEE Symposium
on, May 2005, pp. 32–46.
[28] K. W. Y. Au, Y. F. Zhou, Z. Huang, and D. Lie, “Pscout: analyzing
the android permission speciﬁcation,” in Proceedings of the 2012 ACM
conference on Computer and communications security. ACM, 2012,
pp. 217–228.
[29] E. M. Myers, “A precise inter-procedural data ﬂow algorithm,” in
Proceedings of the 8th ACM SIGPLAN-SIGACT symposium on Principles
of programming languages. ACM, 1981, pp. 219–230.
[30] VirusTotal, “Virustotal - free online virus, malware and url scanner,”
https://www.virustotal.com/, 2014.
[31] 91, “91 market,” http://zs.91.com/, 2015.
[32] Apple, “Distributing apple developer enterprise program apps,”
https://developer.apple.com/library/ios/documentation/IDEs/Conceptual/
AppDistributionGuide/DistributingEnterpriseProgramApps/Dis-
tributingEnterpriseProgramApps.html, 2015.
[33] Lookout, “What you need to know about the new android vulnerability,
stagefright,” https://blog.lookout.com/blog/2015/07/28/stagefright/, 2015.
[34] P. G. Y. K. Zhaofeng Chen, Adrian Mettler, “ibackdoor: High-
https://www.ﬁreeye.com/blog/threat-
risk
research/2015/11/ibackdoor high-risk.html, 2015.
apps,”
code
hits
ios
[35] Dex2jar, “Tools to work with android .dex and java .class ﬁles,”
https://github.com/pxb1988/dex2jar, 2015.
[36] Y. Zhou and X. Jiang, “Dissecting android malware: Characterization
[37] W. Enck, P. Gilbert, B.-G. Chun, L. P. Cox, J. Jung, P. McDaniel, and
A. Sheth, “Taintdroid: An information-ﬂow tracking system for realtime
privacy monitoring on smartphones.” in OSDI, vol. 10, 2010, pp. 1–6.
[38] L.-K. Yan and H. Yin, “Droidscope: Seamlessly reconstructing the os
and dalvik semantic views for dynamic android malware analysis.” in
USENIX security symposium, 2012, pp. 569–584.
[39] Y. Zhou, Z. Wang, W. Zhou, and X. Jiang, “Hey, you, get off of my
market: Detecting malicious apps in ofﬁcial and alternative android
markets.” in NDSS, 2012.
[40] M. C. Grace, W. Zhou, X. Jiang, and A.-R. Sadeghi, “Unsafe exposure
analysis of mobile in-app advertisements,” in Proceedings of the ﬁfth ACM
conference on Security and Privacy in Wireless and Mobile Networks.
ACM, 2012, pp. 101–112.
[41] Z. Qu, V. Rastogi, X. Zhang, Y. Chen, T. Zhu, and Z. Chen, “Autocog:
Measuring the description-to-permission ﬁdelity in android applications,”
in Proceedings of the 2014 ACM SIGSAC Conference on Computer and
Communications Security. ACM, 2014, pp. 1354–1365.
[42] M. Zhang, Y. Duan, H. Yin, and Z. Zhao, “Semantics-aware android
malware classiﬁcation using weighted contextual api dependency graphs,”
a
free
on-line
scan
service,”
and evolution,” in IEEE S&P, 2012.
372372
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:16:50 UTC from IEEE Xplore.  Restrictions apply. 
in Proceedings of the 2014 ACM SIGSAC Conference on Computer and
Communications Security. ACM, 2014, pp. 1105–1116.
[43] F. Wei, S. Roy, X. Ou et al., “Amandroid: A precise and general inter-
component data ﬂow analysis framework for security vetting of android
apps,” in Proceedings of the 2014 ACM SIGSAC Conference on Computer
and Communications Security. ACM, 2014, pp. 1329–1341.
[44] K. Tam, S. J. Khan, A. Fattori, and L. Cavallaro, “Copperdroid: Automatic
reconstruction of android malware behaviors,” in Proc. of the Symposium
on Network and Distributed System Security (NDSS), 2015.
[45] M. I. Gordon, D. Kim, J. Perkins, L. Gilham, N. Nguyen, and M. Rinard,
“Information-ﬂow analysis of android applications in droidsafe,” in Proc.
of the Network and Distributed System Security Symposium (NDSS). The
Internet Society, 2015.
[46] M. Nauman, S. Khan, and X. Zhang, “Apex: extending android permission
model and enforcement with user-deﬁned runtime constraints,” in
Proceedings of the 5th ACM Symposium on Information, Computer
and Communications Security. ACM, 2010, pp. 328–332.
[47] H. Peng, C. Gates, B. Sarma, N. Li, Y. Qi, R. Potharaju, C. Nita-Rotaru,
and I. Molloy, “Using probabilistic generative models for ranking risks of
android apps,” in Proceedings of the 2012 ACM conference on Computer
and communications security. ACM, 2012, pp. 241–252.
[48] M. Dam, G. Le Guernic, and A. Lundblad, “Treedroid: A tree automaton
based approach to enforcing data processing policies,” in Proceedings of
the 2012 ACM conference on Computer and communications security.
ACM, 2012, pp. 894–905.
[49] M. Hardt and S. Nath, “Privacy-aware personalization for mobile
advertising,” in Proceedings of the 2012 ACM conference on Computer
and communications security. ACM, 2012, pp. 662–673.
[50] K. Z. Chen, N. M. Johnson, V. D’Silva, S. Dai, K. MacNamara, T. R.
Magrino, E. X. Wu, M. Rinard, and D. X. Song, “Contextual policy
enforcement in android applications with permission event graphs.” in
NDSS, 2013.
[51] S. Bugiel, S. Heuser, and A.-R. Sadeghi, “Flexible and ﬁne-grained
mandatory access control on android for diverse security and privacy
policies.” in Usenix security, 2013, pp. 131–146.
[52] C. Wu, Y. Zhou, K. Patel, Z. Liang, and X. Jiang, “Airbag: Boosting
smartphone resistance to malware infection,” in NDSS, 2014.
[53] O. Tripp and J. Rubin, “A bayesian approach to privacy enforcement in
smartphones,” in USENIX Security, 2014.
[54] M. Egele, C. Kruegel, E. Kirda, and G. Vigna, “Pios: Detecting privacy
leaks in ios applications.” in NDSS, 2011.
[55] M. Szydlowski, M. Egele, C. Kruegel, and G. Vigna, “Challenges for
dynamic analysis of ios applications,” in Open Problems in Network