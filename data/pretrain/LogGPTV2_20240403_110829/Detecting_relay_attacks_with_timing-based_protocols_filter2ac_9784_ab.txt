ID B, rB
B
(Veriﬁer)
rB ← {0, 1}m
c ← Ek(s)
(
βi ←
ci
ki
: αi = 0
: αi = 1
−−−−−−−−−−−−−−−−→ k ← KDF(s, ID AkID BkrAkrB)
ID A, rA
c ← Ek(s), α ← {0, 1}n
αi
For i = 1 to n do:
←−−−−−−−−−−−−−−−−
−−−−−−−−−−−−−−−−→
βi
Start clock ∆ti
Stop clock ∆ti
Check βi
End for
Protocol 2: Distance bounding protocol resistant against terrorist attacks
In Protocol 2, we have made explicit the identities of prover and veriﬁer by
adding them in the initial exchange of nonces. This is considered sound protocol
engineering practice. Both A and B now use a key derivation function KDF to
derive a symmetric encryption key k, which is used to encrypt the long-term
shared secret s. The range of both KDF and E is {0, 1}n. The fast challenge-
response phase of the protocol is similar to Hancke and Kuhn’s, except that now
the ith bit of the ciphertext c is returned when αi = 0 and the irm bit of the key
k otherwise. Note that knowledge of k and c is equivalent to knowing the shared
secret s, since s = Dk(c).
Security We will now show that Protocol 2 is secure against distance, maﬁa
and terrorist fraud. We do so by proving that the success probability of any
realistic (i.e. polynomial-time) adversary is negligible3 in n. The assumptions
made in the following analysis are as follows:
1. KDF is pseudo-random, i.e. when s is a secret of high enough computa-
tional entropy, the output of the function is computationally indistinguish-
able from uniformly random. In practice, KDF can be a MAC algorithm
such HMAC [3].
3 A probability function (n) is said to be negligible on n when, asymptotically, it
grows slower than the inverse of all polynomials in n.
7
2. E is a semantically secure encryption function, i.e. an adversay does not learn
any (computational) information about the plaintext. In practice, because
the strings to be encrypted are short and the key varies for each run of the
protocol, we can use a one-time pad, i.e Ek(s) = s ⊕ k.
Theorem 1. Protocol 2 is secure against distance fraud.
Proof. To mount a distance fraud attack, the prover, who is not close to the
veriﬁer, must respond to the challenges within the short interval ∆tmax. Since A
is not close by, she must send the response before she receives the challenge. The
best she can do is to guess the challenge and answer according to that guess.
This guess will be correct with a probability of 1/2, and hence the probability
ut
that B accepts is (1/2)n, which is negligible.
Theorem 2. Protocol 2 is secure against maﬁa fraud.
Proof. (Sketch) Here the adversarial setting corresponds with the one depicted in
Figure 1. A is honest, in the sense that she does not cooperate with the attackers
¯A and ¯B, and A is not close to B, which implies that it is not physically possible
for ¯A and ¯B to pass on the challenge to A, get the response from A and relay it
back to B in time. k is diﬀerent for each run of the protocol with overwhelming
probability due to the inclusion of the nonce rA in the key derivation function.
This together with assumptions 1 and 2 above, implies that it is impossible for
any adversary to guess any bit ki or ci with probability non-negligiby diﬀerent
from 1/2. Hence the best ¯A and ¯B can do is guessing the challenge bit before it is
output by B and send it to A. This could be done before the challenge response
phase starts. For example, ¯B withholds message 2 for a time long enough to
allow him to complete a run of the protocol with A, using challenges ¯αi chosen
by ¯B himself. ¯B then passes to ¯A the value rA, the challenges ¯α1, . . . , ¯αn, and the
responses ¯β1, . . . , ¯βn. ¯A then completes the protocol with B. Since B choses the
challenges αi uniformly at random, on average only half of the challenges ¯αi will
coincide. When this happens, then ¯A can send the valid response ¯βi; otherwise,
¯A can only guess the right reponse with probability 1/2. Overall, the probability
that ¯A and ¯B fool the veriﬁer into accepting is essentially (3/4)n, which again
ut
is negligible.
Theorem 3. Protocol 2 is secure against terrorist fraud.
Proof. (Sketch) It follows from Theorem 2 that in order to have B accepting,
someone close to B must have k and c, which only A can generate. Since knowing
k and c implies knowing s = Dk(c), and since A is assumed not to give away her
ut
long-term secret s, we must conclude that it is A who is close by.
Noise errors In practice, as discussed by Hancke and Kuhn [12] and further
elaborated in Section 4, the communications link between prover and veriﬁer
during the fast challenge-response phase is unreliable. This means that the pro-
tocol should tolerate transmission errors during that phase, by increasing the
number of challenge-reponse rounds according to the expected error rate. We
refer the reader to Hancke and Kuhn’s paper [12] for the quantitative analysis.
8
Comparison with existing schemes Table 1 presents the list of distance-
bounding protocols that we have found in the literature and classiﬁes them
according to the following criteria:
– Identiﬁcation technique: whether the underlying identiﬁcation protocol is
based on asymmetric, symmetric or zero-knowledge techniques (see Menezes
[17]).
– Unilateral/Mutual: whether the protocol authenticates the identity and prox-
imity of one or both participants.
– Maﬁa fraud resistance: does the protocol defend against maﬁa fraud attacks.
– Terrorist fraud resistance: does the protocol defend against terrorist fraud
attacks.
– Distance fraud resistance: does the protocol defend against distance fraud
attacks.
The new proposal is the only scheme that employs symmetric authentication
techniques and is secure against all types of attacks. The protocol by Capkun et
al. [6] provides mutual entity authentication as well as proximity authentication,
i.e. A and B are both prover and veriﬁer of each other. We have tried to design
a mutual distance-based protocol version of the new protocol, however, in terms
of eﬃciency, it does not appear possible to do signiﬁcantly better than running
the fast challenge-response phase twice.
Type Uni/Mut Dist. Maﬁa Terr.
Protocol
Brands & Chaum-I [4] asym uni
Brands & Chaum-II [4]
uni
zk
sym
Sastry et al . [18]
uni
sym mut
Capkun et al . [6]
uni
sym
Capkun & Hubaux [7]
uni
sym
Hancke & Kuhn [12]
Bussard [5]
zk
uni
uni
sym
New proposal
yes
yes
yes
yes
yes
yes
yes
yes
yes
yes
no
yes
yes
yes
yes
yes
no
no
no
no
no
no
yes
yes
Table 1. Comparison of existing distance-bounding protocols
4 Communications requirements for to distance bounding
In this section we analyse requirements and implementation issues associated
with the communications channel used in the time critical phase. We propose a
novel communication approach that exploits the underlying principle of a secu-
rity vulnerability, namely side channel leakage, in a constructive way to provide
the necessary distance bounding resolution for constrained devices (particularly,
ISO 14443 contactless smart cards).
9
The communication requirements of a distance bounding protocol are both
demanding and unconventional - to achieve useful distance resolution they re-
quire extremely low communication latency but they do not require a corre-
spondingly high bit rate since in the time critical phase, they exchange single
bits punctuated by processing delay. A communication channel that can detect
and correct errors may actually be a disadvantage because reliability mechanisms
introduce overheads; more bits need to be exchanged but more importantly, an
additional and possibly variable number of processing cycles is required to de-
tect and correct errors. As we noted in Section 3, bit errors caused by channel
noise can be tolerated by simply by increasing the number of challenge response
rounds.
The reason why variable processing time for the prover is a problem is be-
cause it makes it diﬃcult to isolate signal propagation time, which is the goal
of the time critical phase of a distance bounding protocol. Total elapsed round
trip time for a challenge response round comprises two components: processing
time and propagation time. To reliably isolate the propagation component, the
processing component should be small and invariant. For inductively powered
devices, propagation time is going to be a very small percentage of total round
trip time. For example, an ISO 14443 contactless smart card has a maximum
operating distance of 10 cm [1] so the round trip signal propagation time is two
thirds of a nanosecond. At the standard reader supplied clock rate of 13.56MHz,
a single clock cycle takes 74 ns, enough time for a signal to propagate 22 m.
Variation in processing time presents a real challenge to the accuracy of tim-
ing based solutions. An attacker may be able to accelerate a legitimate card’s
processing by providing it with a higher frequency clock signal (overclocking) to
absorb the delay introduced by a relay attack.
4.1 Preventing accelerated prover processing
ISO 14443 type contactless smart cards are passive devices that receive their
power via inductive coupling with the 13.56 MHz magnetic alternating ﬁeld
generated by a reader device’s antenna coil [1]. The standard requires the reader
to supply the RF operating ﬁeld within a tolerance of ±7 kHz. Therefore, where
a card uses the operating ﬁeld as the source of its internal clock signal, (as is
common) it only needs to accept a frequency that is 0.05% greater than 13.56
MHz. There are two main approaches to stop an attacker from operating a card
at a higher than intended frequency; phase locked loop (PLL) internal clock
generators and high frequency ﬁlters. Internal PLL-based clock signal generators
are an increasingly popular choice, particularly in microprocessor cards. They
have the advantage that the frequency of the generated signal is independent of
the reader-supplied frequency. In the second case where the card uses a reader-
supplied clock signal, high frequency protection usually takes the form of a low
pass ﬁlter which resets the card when the ﬁlter threshold is exceeded. Tolerances
of the order of a few percent are possible. It is therefore reasonable to assume that
for appropriately designed hardware, an attacker can be limited to overclocking
10
by no more than a few percent, thereby absorbing only 2-3 ns of introduced
delay per clock cycle of calculation.
We also assume that the attacker cannot economically defeat a legitimate
card’s protection mechanisms to extract the long term secret key to transfer
it to a faster device. This allows us to conclude that any successful distance
bounding protocol run was executed with the real card. Under these assumptions
the amount of introduced delay that can be absorbed is largely determined by
the prover’s clock frequency and the number of clock cycles required to compute
the response, (ignoring implementation speciﬁcs of the communication method
which we examine shortly). If the number can be kept small, the veriﬁer can
account for the processing time with some accuracy, thus permitting a reliable
allocation of the portion of total round trip time to propagation.
4.2 A new approach to low latency communication
Keeping the number of clock cycles small within the existing communication
architecture of contactless smart cards is not possible because after initialisation,
they communicate via a reliable layered transport protocol. It is impractical to
reliably detect relay attacks on these devices using their existing communication
protocols, in part because of the large number of clock cycles required to process
the communication - there is too much opportunity to accelerate processing to
absorb introduced propagation delay.
To address this problem, we propose a new approach to communication that
addresses the unconventional requirements of distance bounding protocols. The
essential element of our proposal is that the veriﬁer measures a physical side eﬀect
of the calculation process and from this, infers the result. The general principle