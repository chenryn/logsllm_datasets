D)
εn
(cid:1)
(cid:17)
Prop. 2.8
Thm. 2.9
εn
Theorem 4.1
(cid:1)1/3
˜O(cid:0) d
(cid:1)1/3
˜O(cid:0) d
(cid:16) d2
(cid:17)1/3
(cid:17)1/3
(cid:16) d log d
(cid:16) t·d log d
(cid:17)1/3
εn
εn
εn
εn
exponential improvement in the dependence on D = 2d = |X| for the case of threshold functions
and conjunctions (and similarly in the dependence on t for t-way conjunctions). In particular, we
only need n to be polynomially large in the bitlength d of the rows to have vanishingly small error;
in such a case, we can produce and publish a diﬀerentially private synthetic dataset that accurately
summarizes exponentially many (2Θ(d)) statistics about the original dataset (e.g. the fractions of
individuals with every combination of attributes, as in Qconj(d)). It is amazing that such a rich
release of statistics is compatible with strong privacy protections!
These improvements also hold compared to the bounds we had for (ε, δ)-diﬀerential privacy
(where the dependence on |Q| was only quadratically better than for pure diﬀerential privacy).
On the other hand, for point functions and attribute means, our earlier bounds (even for pure
diﬀerential privacy) are better than what is given by Theorem 4.1.
Proof of Theorem 4.1. We begin by establishing the existence of at least one accurate m-row syn-
thetic dataset y∗: Let y∗ be a random sample of m rows from x, say with replacement for simplicity.
By the Chernoﬀ bound,
Pr[ ∃q ∈ Q s.t. |q(y∗) − q(x)| > α )] ≤ 2−Ω(mα2) · |Q|  2m log |X|).
(cid:28) 1
Recall that m = O(log |Q|)/α2. Solving for α gives the theorem.
The exponential mechanism is quite general and powerful, and can be used to design diﬀeren-
tially private mechanisms for sampling “good” outputs from any output space Y. Speciﬁcally, we
can replace the expression
−max
q∈Q
|q(y) − q(x)|
with an arbitrary “score function” score(x, y) indicating how good y is as an output on dataset x,
and replace the factor of n in the exponent with a bound B on the reciprocal of maxz GSscore(·,z) .
That is, we obtain the following mechanism Mscore,B(x):
1. For each y ∈ Y, deﬁne weightx(y) = exp (ε · score(x, y)/B).
2. Output y with probability proportional to weightx(y). That is,
(cid:80)
weightx(y)
z∈Y weightx(z)
.
Pr[M(x) = y] =
28
Similarly to the proof of Theorem 4.1, it can be shown that:
Proposition 4.2 (the exponential mechanism, due to McSherry and Talwar [78]). For every func-
tion score : Xn × Y → R such that Y is ﬁnite, ε ≥ 0, and B > 0,
1. If B ≥ maxz GSscore(·,z), then the mechanism Mscore,B is 2ε-diﬀerentially private, and
2. For every dataset x ∈ Xn, with high probability Mscore,B(x) outputs y such that
score(x, y) ≥ argmaxy∗ score(x, y∗) − O(log |Y|) · B/ε.
The downside. While the exponential mechanism is very powerful, it can be computationally
very expensive, as a direct implementation requires enumerating over all y ∈ Y. Indeed, in the
application of Theorem 4.1, the computation time is roughly
|Y| = |X|m = exp
(cid:18) log |Q| log |X|
(cid:19)
α2
,
so it is very slow. For example, we get runtime exp(d2/α2) for the query family Qconj of conjunctions
on {0, 1}d.
4.2 Private Multiplicative Weights
We now present the state-of-art algorithm for general queries:
Theorem 4.3 (private multiplicative weights, due to Hardt and Rothblum [57]). For every set
Q of counting queries on a data universe X and every ε, δ > 0, there exists an (ε, δ)-diﬀerentially
private mechanism M such that for all datasets x ∈ Xn, with high probability M(x) answers all
queries in Q to within error at most
(cid:32)(cid:112)log |X| · log(1/δ) · log |Q|
(cid:33)1/2
.
α = O
εn
Moreover, M(x) can answer the queries in an on-line fashion (answering each query as it arrives)
and runs in time poly(n,|X|) per query.
here.
The algorithm can also be modiﬁed to produce a synthetic dataset, though we won’t show it
Note that the error vanishes more quickly with n than in Theorem 4.1 (as 1/n1/2 rather than
1/n1/3), and the log |X| has been replaced by(cid:112)log |X| · log(1/δ). Comparing to the results we have
ing all conjunctions on {0, 1}d with error tending to zero, we only need n = ω(d3/2 ·(cid:112)log(1/δ)/ε)
, we obtain a savings in the dependence on |X| = 2d. In particular, for answer-
seen for our example query families, we have:
For Qconj and Qconj
t
rather than n = ω(d2/ε) as in Theorem 4.1. The running time has improved, too, but is still at
least |X| · |Q|, which is exponential in d. (Of course, in this generality, one needs |X| · |Q| bits to
specify an arbitrary set of counting queries on {0, 1}d.)
29
Table 4.2: Error bounds for speciﬁc query families under (ε, δ)-diﬀerential privacy on a data universe
X of size D = 2d (e.g. X = {0, 1}d or X = {1, 2, . . . , D}). Highlighted cells indicate the best bounds
in the regime where n ≤ Do(1) or n ≤ do(t) and δ ≥ 2− polylog(n).
In the case of incomparable
bounds, both are highlighted.
Query family Q Sec. 2
ref
Thm. 4.1
Thm. 4.3
O(cid:0) d
(cid:1)
εn
√
˜O(
D)
εn
˜O(2d/2)
Qpt
Qthr
Qconj
(cid:19)
εn
(cid:18)√
(cid:18) dt/2·√
d log(1/δ)·log log d
εn
log(1/δ)·log log d
εn
Thm. 2.9 O
Thm. 2.7
(cid:19)
Thm. 2.7 O
Qmeans
O
Qconj
t
for t (cid:28) d O
Prop. 2.8
Thm. 2.9
(cid:18) d3/2·√
(cid:18) d3/2·√
(cid:18) d3/2·√
(cid:18)√
(cid:18) t log d
O
O
O
O
O
log(1/δ)
εn
log(1/δ)
εn
log(1/δ)
εn
d log(1/δ)·log d
εn
√
d log(1/δ)
εn
(cid:19)1/2
(cid:19)1/2
(cid:19)1/2
(cid:19)1/2
(cid:19)1/2
εn
(cid:1)1/3
˜O(cid:0) d
(cid:16) d2
(cid:17)1/3
(cid:17)1/3
(cid:16) t·d log d
εn
εn
Proof. The algorithm views the dataset x as a distribution on types r ∈ X:
#{i ∈ [n] : xi = r}
.
x(r) =
n
Then,
q(x) = E
r←x
[q(r)].
The algorithm will maintain a distribution h on X, some hypothesis for what the data distribution