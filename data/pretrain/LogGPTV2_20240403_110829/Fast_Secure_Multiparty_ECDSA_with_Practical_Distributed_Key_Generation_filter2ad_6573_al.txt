mult execution in Step 2. If no, then S simulates FcheckDH
sending reject to all parties, sends abort to Fmult, outputs whatever A outputs and halts.
zk
If reject was not sent, then S simulates FcheckDH sending accept to all parties.
10. S simulates F RDH
sending (proof, sid, j, (P, Aj, Bj − cj · G), 1) to Pi, and Pj sending cj to Pi,
for every i ∈ I and j ∈ J.
zk
11. S receives the messages (proof, sid, i, (P, Ai, Bi − ci · G), ˆsi) that A sends to F RDH
for every
i ∈ I. If for some i ∈ I it holds that Ai (cid:54)= ˆsi · G or Bi − ci · G (cid:54)= ˆsi · Bi, then S sends abort to
Fmult, outputs whatever A outputs and halts.
zk
12. S receives the values ci that A instructs Pi to send to Pj, for every i ∈ I and j ∈ J.
13. For every j ∈ J, S veriﬁes if c =(cid:80)n
(cid:96)=1 c(cid:96), with the ci values received speciﬁcally by Pj. If yes,
then S sends (continue, j) to Fmult (to instruct that Pj receives output); if not, then S sends
(abort, j) to Fmult (to instruct that Pj receives abort).
This completes the description of the simulator. We now proceed to show that the output distri-
bution generated by an execution of S in the ideal world is computationally indistinguishable from
a real execution of the protocol with A in the real world. Observe that the main diﬀerence is that
the ciphertexts seen by A in the real execution are valid encryptions whereas in the simulation they
are random pairs of group elements, and the inputs used in the subprotocol πpriv
mult. The proof will
therefore rely on the DDH assumption in group G and on the assumption that πpriv
mult is a private
multiplication protocol (see Section 2.3).
We prove via a series of games.
Game 0: This is an ideal-world execution with S and Fmult.
In this game, we modify Fmult so that Fmult sends all honest party inputs {aj}j∈J to
Game 1:
S, whenever input is called. Since S is unchanged, this clearly makes no diﬀerence to the output
distribution.
In this game, we modify the simulator S so that instead of running πpriv
i∈I ai mod q and(cid:80)
mult. In particular, if the implicit inputs {a(cid:48)
Game 2:
mult with aj, bj
chosen randomly under the speciﬁed constraint, it uses the correct aj, bj received from Fmult. The
fact that the output distributions of Game 1 and Game 2 are indistinguishable follows from the
i}i∈I used by the
i}i∈I and {b(cid:48)
privacy properties of πpriv
i∈I bi mod q then this guarantees
(cid:96)=1 b(cid:96)) mod q, is the same in both cases (when the honest parties
inputs are correct, or chosen randomly under the simulator-speciﬁed constraint), as long as no
modular reduction took place. Thus, by input indistinguishability the view of the adversary is
indistinguishable, even given all c1, . . . , cn as in the last step of the protocol.
i}i∈I used by the adversary are such that
i}i∈I such
that all sum to the correct c with probability only 1/q, since all the honest parties’ inputs {aj, bj}j∈J
adversary are such that(cid:80)
that the output c = ((cid:80)n
i∈I ai or (cid:80)
(cid:80)
In contrast, if the implicit inputs {a(cid:48)
i∈I a(cid:48)
i∈I bi, then the adversary will be able to supply {c(cid:48)
i∈I a(cid:48)
i =(cid:80)
(cid:96)=1 a(cid:96))· ((cid:80)n
i (cid:54)= (cid:80)
i∈I b(cid:48)
i (cid:54)= (cid:80)
i}i∈I and {b(cid:48)
i =(cid:80)
i∈I b(cid:48)
47
are uniformly distributed shares. Thus, in this case, the adversary will not view c1, . . . , cn. This is
therefore indistinguishable by the privacy property of πpriv
mult. Furthermore, this argument guarantees
that the fact of c being correct or incorrect does not reveal any information to the adversary (since
this fact is revealed in the protocol).
We stress that in the entire simulation by S, the private-keys for Paillier are only needed within
mult. Thus, S can run the simulation in Games 1 and 2 without knowing the Paillier private keys
πpriv
In this game, S generates all encryptions of corrupted parties correctly using the aj, bj
Game 3:
values it received (this includes the (Uj, Vj) values in input, and the (Ej, Fj) and (Aj, Bj) values in
mult).
In order to show that the output distributions of Games 2 and 3 are computationally indistin-
guishable, we show that there exists a distinguisher D who receives a tuple (G, ˆP, Λ, Ω) of group
elements of G for input. Then, D generates the output distribution of Game 2 if they are a random
tuple, but generates the output distribution of Game 3 if they are a Diﬃe-Hellman tuple (i.e., there
exists some r such that Λ = r · G and Ω = r · ˆP. This implies indistinguishability of the output
distribution of the games, under the DDH assumption.
The idea behind the reduction is that D can deﬁne P = ˆP and then use Λ, Ω to construct
ciphertexts that are either random or valid, depending on whether or not its input was random or
a Diﬃe-Hellman tuple. We use a rerandomization method, deﬁned by
Rerand(Λ, Ω; s, t) = (s · Λ + t · G, s · Ω + t · ˆP).
(1)
We denote by Rerand(Λ, Ω) the above procedure when s, t ← Zq are random. Clearly, if (G,P, Λ, Ω)
is a Diﬃe-Hellman tuple, then (G,P, A, B) where (A, B) = Rerand(Λ, Ω) is a random Diﬃe-Hellman
tuple (where by random we mean that it is independent of (G,P, Λ, Ω)). This is due to the fact
that if Λ = r · G and Ω = r · ˆP then A = (s · r + t) · G and B = (s · r + t) · P. Since s, t are random,
this is an independent and uniformly distributed Diﬃe-Hellman tuple. In contrast, if (G,P, Λ, Ω)
is not a Diﬃe-Hellman tuple, then (G,P, A, B) where (A, B) = Rerand(Λ, Ω) is a random tuple,
independent of (G,P, Λ, Ω). In order to see this, write Λ = r1 · G and Ω = r2 · G. Then, for any
ρ1, ρ2, we have that A = ρ1 · G and B = ρ2 · G if and only if s · r1 + t = ρ1 and s · r2 + t = ρ2.
Since r1 (cid:54)= r2, there is a single solution (s, t) to this system of equations. Since s, t are random,
this proves that the result is an independent random tuple.
We proceed to describe D. Distinguisher D receives all of the parties’ inputs and plays the
trusted party computing Fecdsa in Games 2/3 (Fecdsa is the same in both of these games), as
well as the ideal-world honest parties. In addition, D invokes A and runs the simulator S like in
Games 2/3 with the exception of how the encryptions are generated, as described above. D works
as follows:
Initialization: D invokes A upon input (init, G, G, q) and works in exactly the same way as S
except that it deﬁnes P = ˆP instead of choosing it randomly itself. This is therefore exactly the
same distribution as S.
Input: D works exactly like the simulator S except that instead of choosing random group
elements {Uj, Vj}j∈J it sets (U(cid:48)
j ) = Rerand(Λ, Ω) for every j ∈ J (using independent ran-
j + aj · G. D stores
domness in each call to Rerand. Then, D sets Uj = U(cid:48)
j and Vj = V (cid:48)
j, V (cid:48)
(cid:0)sid, (U, V ),{U(cid:96), V(cid:96), a(cid:96)}(cid:96)∈[n],{si}i∈I
(cid:1).
48
Observe that if the tuple (G,P, Λ, Ω) is a Diﬃe-Hellman tuple, then all (Uj, Vj) are valid
encryptions of the honest parties’ inputs as in Game 3. In contrast, if the tuple (G,P, Λ, Ω) is
random, then (Uj, Vj) is random and so exactly is Game 2 (adding aj · G makes no diﬀerence to
the distribution since U(cid:48)
j are truly random and independent).
j, V (cid:48)
Element-out: D works exactly like the simulator S.
Aﬃne: This is a local operation and thus the D carry out the local transformation on all values
it holds.
Multiply: D invokes A on (mult, sid1, sid2) and works as follows.
1. Let (sid1, (U, V ),{U(cid:96), V(cid:96), a(cid:96)}n
2. D plays the honest parties in protocol πpriv
(cid:96)=1,{si}i∈I , ) and(cid:0)sid2, (X, Y ),{X(cid:96), Y(cid:96), b(cid:96)}(cid:96)∈[n],{si}i∈I
mult using the inputs {aj, bj}j∈J exactly like S in
(cid:1) be as stored.
Game 2/3.
3. For every j ∈ J, D computes (E(cid:48)
j, F (cid:48)
j) = Rerand(Λ, Ω) and deﬁnes Ej = E(cid:48)
j and Fj = F (cid:48)
j +(aj·b)·G
(where aj, b are the correct values known to D).
Observe that if (Λ, Ω) are Diﬃe-Hellman, then the distribution over all (Ej, Fj) pairs is correct
and so exactly like Game 3.
In order to see that they are correct, observe that all values
provided by A involved in computing Ej, Fj are those provided in input and are validated with
zero-knowledge proofs. Thus, computing an encryption of aj · b directly as carried out by D
yields the same result as the simulator in Game 3 who uses the honest parties’ inputs.
zk
sending the zero-knowledge proofs, exactly like S.
In contrast, if (Λ, Ω) are random, then then all (Ej, Fj) pairs are independently random, just
like S in Game 2.
4. D simulates F Rprod
5. D simulates receives the zero-knowledge proofs for F Rprod
6. Let {cj}j∈J be the outputs received by D when running the honest parties in πpriv
mult with A, above.
j + cj · G.
For every j ∈ J, D computes (A(cid:48)
As above, (Aj, Bj) is a valid encryption of cj as in Game 3 (and a real execution) if (Λ, Ω) is a
Diﬃe-Hellman tuple, and is a random pair as in Game 2 otherwise.
j) = Rerand(Λ, Ω) and deﬁnes Aj = A(cid:48)
, exactly like S.
j and Bj = B(cid:48)
j, B(cid:48)
zk
7. D proceeds and follows the simulation instructions to the end.
8. D outputs whatever A outputs, together with the outputs of the honest parties (it knows these
values since it also plays the trusted party computing Fecdsa).
As explained throughout the description above, when the tuple (G, ˆP, Λ, Ω) received by D is a
Diﬃe-Hellman tuple, then the output distribution generated by D is distributed as in Game 2. In
contrast, when (G, ˆP, Λ, Ω) is a random tuple, the output distribution generated by D is distributed
as in Game 3. Thus, the output distributions of Games 2 and 3 are indistinguishable under the
assumption that the DDH assumption holds in G.
49
Game 4: Game 3 is exactly the same as a real execution, with the exception that P is chosen
by S and not the result of the computation by the parties in init. We therefore modify S so that
it plays honestly in init instead of running the simulation. Observe that since the Pj values are
chosen randomly by S in Game 4 and not revealed to A until after it has sent the Pi values, the
(cid:96)=1 P(cid:96) is uniformly distributed, exactly as in Game 3. Thus, this makes no diﬀerence.
sum P =(cid:80)n
Summing up. Game 4 is exactly the same as a real execution, except for the technicality that
Fmult is involved and hands the honest parties their outputs. However, in Game 4, the simulator
S runs the instructions of the honest parties exactly, with the addition of perfectly simulating the
Fzk, Fcom-zk and FcheckDH functionalities. Thus, the output distribution of Game 4 is identical
to the real execution. We conclude that the output distribution of the simulation (Game 1) is
computationally indistinguishable from the output distribution of the real execution (Game 4)
under the DDH diﬃculty assumption in G. This concludes the proof.
Consistency in the point-to-point model. The above proof essentially assumes that all honest
parties receive the same values in each round, as if there is a broadcast channel. As described after
Protocol 4.4, the parties exchange hashes of all received input encryptions in the round following
each input. Since the simulator can simulate the ﬁrst round of any subprotocol following input even
if the adversary was not consistent, this suﬃces (since in the following round, all parties abort). In
addition, note that consistency is guaranteed in the init phase since Fcom-zk is used. Now, within
element-out and mult, all messages generated by the parties are proven in zero knowledge. Thus,
even if the adversary sends diﬀerent ciphertexts to diﬀerent honest parties, these will always be of
the same correct results. Thus, the simulator can follow the same strategy as above, and provide
the expected honest party messages back, for each honest party. Thus, our protocol is secure in
the point-to-point model of communication.
50