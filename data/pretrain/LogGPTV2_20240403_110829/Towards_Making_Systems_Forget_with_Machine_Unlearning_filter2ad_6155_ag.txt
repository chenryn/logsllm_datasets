### Newly Created Clusters and Modified VFDT

Our modified version of the Very Fast Decision Tree (VFDT) algorithm reads a C4.5 decision tree that has been polluted with erroneous data. Instead of starting from a single leaf as in the original implementation, our modified VFDT begins incrementally building upon the polluted decision tree. This process results in a new decision tree, which is then outputted in the C4.5 format and used as the decision tree for OSNSF. The modification introduces only 33 lines of code into the `main.cpp` file of the OSNSF implementation to support this process.

### Completeness Results

Table IV presents the completeness results. The first column shows the true positive and false positive rates before any pollution. After polluting 1.75% of the training data, both the true positive and false positive rates decrease. Following the unlearning of the polluted samples, both rates increase, but the true positive rate does not fully recover to its pre-pollution value. This discrepancy arises because the two decision trees are generated by different algorithms: C4.5 and VFDT. Even with identical inputs and input order, VFDT will not generate the same decision tree as C4.5. However, the filtering rate (true positive rate) after unlearning is still sufficient for a spam filtering system. For 99.4% of the testing samples, the original system and the unlearned system produce the same result, achieving a 99.4% completeness in unlearning, which is a high figure. We also evaluated the timeliness of unlearning. Retraining takes 30 minutes, while unlearning a single sample takes only 21.5 milliseconds, resulting in a speedup factor of 8.4 × 10^4.

### Unlearning in PJScan

#### Learning Technique in PJScan

PJScan, an open-source PDF detection engine, uses one-class Support Vector Machines (SVMs) to classify malicious JavaScript. It first extracts JavaScript from PDFs using Poppler, analyzes it with Mozilla’s SpiderMonkey, and tokenizes it. PJScan then trains an SVM using only malicious JavaScript samples to generate α values for all support vectors. It calculates the center and radius of an n-sphere in an n+1 dimensional space. If an incoming data sample falls within the n-sphere, it is classified as malicious; otherwise, it is classified as benign. We chose PJScan for its unique one-class machine learning approach, despite other available machine learning-based PDF detection engines.

#### Compatibility and Installation

Due to the age of the PJScan source code (dating back to 2011), it does not support some recent libraries. We installed an older version of Poppler (0.18.2) and made several modifications to PJScan to ensure compatibility with the latest Boost library. These modifications included changing `boost::filesystem::path.file_string()` to `boost::filesystem::path.string()`, updating the `BOOST_FILESYSTEM_VERSION` definition from 2 to 3, and removing an obsolete catch block. We then executed the provided `install.sh` script for installation. For the experiment, we used a dataset from Huawei, containing 65 malicious PDF samples with corresponding JavaScript. Due to the small dataset size, half of the PDFs were used for training, and the other half for testing.

#### Training Data Pollution

To pollute PJScan, we injected a fixed pattern (repeated `alert(1);` functions) into the PDFs to move the center of the n-sphere far away from the original center. Table V shows the pollution results. Without pollution, PJScan classifies 81.5% of the malicious PDFs correctly. Polluting 21.8% of the training samples reduces the detection rate to 69.3%, and increasing the pollution to 28.2% further drops the rate to 46.2%. This indicates that one-class machine learning is more robust to pollution than two-class machine learning, as the latter is constrained by the need to draw a line between benign and malicious spheres.

#### Analytical and Empirical Results

The unlearning process in PJScan involves two stages. The first stage recalculates the new α values of each support vector, and the second stage recalculates the center and radius of the sphere. In the first stage, the old α values are fed into the iteration process to reach the optimal point. In the second stage, the center and radius are updated based on changes in α values and support vectors. We added 30 lines of code to the `libsvm_oc` module of PJScan to implement these updates. The unlearning results show that the detection rate returns to the original level, and the timeliness of unlearning is significantly better than retraining, with unlearning taking only 2.4 iterations on average compared to 42 iterations for retraining.

### Discussions

Unlearning systems aim to restore privacy, security, and usability by allowing users and service providers to control when to forget specific data. They do not protect remaining data from leaks or incorrect analytics. Identifying the data to be unlearned can be straightforward or require manual or automated analysis. Our unlearning approach is general and widely applicable, though some machine learning algorithms may require custom unlearning solutions.

### Related Work

#### Adversarial Machine Learning

Adversarial machine learning studies the behavior of machine learning in adversarial environments. Attacks are categorized into causative (polluting training data) and exploratory (stealing private data or evading detection). Our practical pollution attacks on Zozzle, OS-NSF, and PJScan fall into the causative category, motivating the need for unlearning.

#### Defense Mechanisms

Defenses against data pollution and privacy leakage include filtering polluted data, increasing algorithm resilience, and using differential privacy. While these defenses are effective, they can be defeated by new attacks, making unlearning a complementary method.

#### Incremental Machine Learning

Incremental machine learning adjusts trained models to add new data or remove obsolete data. Our unlearning approach differs fundamentally by providing a general, efficient method applicable to any algorithm that can be converted to the summation form, including non-standard algorithms like normalized cosine similarity.

### Conclusion and Future Work

We have presented a vision of forgetting systems that completely and quickly forget data and its lineage to restore privacy, security, and usability. Future work will focus on expanding the applicability of unlearning to more complex and diverse machine learning algorithms and real-world systems.