to the next entry.
For example, after processing the instruction sequence
jneq r5 r6 1 /* if r5 == r6 */
b1: bpf_mov r1 r10 -2 /* r1 = r10 - 2 */
b2: bpf_mov r1 r10 -4 /* else r1 = r10 - 4 */
b3: bpf_load_32 r3 r1 /* r3 = (uint32) *r1 */
the compiler stores the following information:
(block b1, cond r5 == r6, r1 STACK, offset -2)
(block b2, cond !(r5 == r6), r1 STACK, offset -4)
To determine the offset read by block b3 (r3 = *r1), the compiler
determines that neither b1 nor b2 dominates b3, but they can both
reach b3, hence producing the verification conditions
(r5 == r6) ⇒ read_offset == -2 ∧
! (r5 == r6) ⇒ read_offset == -4
It is not always possible to make the read_offset concrete, as
seen in this example.
IV. Caching We also cache the verification outcomes of canonical-
ized versions of a given program to quickly determine if a struc-
turally similar program was equivalence-checked earlier. We canon-
icalize the program by removing dead code. Then, the canonicalized
program is hashed into a key that is used to look-up a program
cache of verification outcomes. Equivalence-checking is only per-
formed when there is a cache miss; the outcome of the equivalence
checking is inserted into the cache along with the program that
was checked.
18
Synthesizing Safe and Efficient Kernel Extensions for Packet Processing
arXiv, July 14, 2021
C.2 Modular Verification
Synthesis and optimization typically scale to large programs by
operating over a sequence of smaller windows, where a window is
a contiguous sequence of instructions as they appear in the text of
the program [102, 108, 117, 129]. Small windows (rather than the
full programs) lead to smaller verification conditions, which are
much faster to solve.
Verifying the correctness of synthesized windows be thought
of in one of two ways. A peephole optimizer [40, 107] would only
produce instruction sequences that exhibit equivalent behavior
under any values that the window consumes (precondition) and
ensure any values it produces are equal to that produced by the
original program (postcondition). This is similar to the verification
conditions from §4, written just for a window in the program.
An alternative possibility is to consider stronger preconditions
and weaker postconditions to verify the window [117, 129]. This en-
ables stronger optimizations: for example, the instruction bpf_mul
r2 r1 can be optimized into bpf_lshift r2 2 provided a compiler
can infer that r1 == 4 during the multiplication, but not in gen-
eral. Similarly, other optimizations become possible with weaker
postconditions.
We call the part of the program before the window the prefix
and the part after the window the postfix. Automatically inferring
strong preconditions (that hold after the prefix) and weak postcon-
ditions (that must hold before the postfix) is a challenging prob-
lem [102, 108, 129]. Recent work [117] takes the approach of using
the strongest possible precondition and weakest possible postcon-
dition, by constructing the entire first-order logical representation
of the prefix and postfix programs. This approach, while enabling
strong optimizations, reduces to using the verification conditions
for the full program.
Instead, we build on an earlier approach [40] that uses the live
variables [110] to generate stronger preconditions and weaker post-
conditions than peephole optimizers. Additionally, K2 also infers
sets of concrete values for variables, if they exist, and pose those
as preconditions for the optimization. K2 chooses windows among
basic blocks of a certain maximum instruction count and uses the
following window-based verification condition:
variables live into window 1
== variables live into window 2
∧ inferred concrete valuations of variables
∧ input-output behavior of window 1
∧ input-output behavior of window 2
⇒ variables live out of window 1
!= variables live out of window 2
Here, variable set “live into” the window contains all variables
written in the prefix that are readable in the window, and the set
“live out of” the window contains all variables that are written inside
the window and read by the postfix. The concrete valuations of
variables are inferred through static analysis that determines the
set of concrete values that a register might take on, along with the
corresponding path conditions. For example, in the code sequence
if r0 > 4:
r1 = 6
else if r2 < 6:
r1 = 10
19
else:
r1 = 8
----
ends
---- window begins ----
/* use r1 somewhere here */
---- window
the clause of the precondition with inferred values is
p1 ⇒ r1 == 6
∧ p2 ⇒ r1 == 10
∧ p3 ⇒ r1 == 8
∧ exactly one of p1, p2, p3 is true
where p1, p2, and p3 are fresh boolean variables corresponding to
the path conditions where r1 takes on distinct concrete values.
If the formula is satisfiable, the solver produces an input state
at the beginning of the window that results in the two windows
producing different output states at the end of the two window
executions. If not, the two windows are conditionally-equivalent
under the specific precondition and postcondition above.
We specialize the liveness analysis to the BPF context by handling
BPF registers as well as BPF memory (stack, packet, map values). We
build on optimizations (I–III) in §C.1 and track liveness information
along with concrete types and offsets. In particular, with map values,
we treat each map value as a distinct type of memory, with its own
concretizations of each access within the window, since we do not
have concrete offsets into the kernel’s (value) memory.
Window-based verification condition generation and equiva-
lence checking are particularly useful in the BPF context for many
reasons. First, it becomes unnecessary to track aliasing for map
access, since each window typically just contains one live map
value pointer, and we only care about aliasing within the value
memory itself. In fact, we don’t even use any information about
the key in the verification condition. Second, it becomes possible
to handle several new helpers in a much more expedient way with
window verification, since we can optimize “around” the function
by simply tracking the inputs and outputs of the helper, rather than
“across” the function, which requires capturing its input-output
semantics. Third, window verification allows us to guide the sto-
chastic search better for programs that output a small number of
output bits—programs known to be hard to optimize with typical
error functions [127]. This is because K2’s window postcondition
ensures that the window obtains other intermediate values in the
program correctly, rather than (just) the output.
The fundamental disadvantage of window-based verification
relative to full-program verification is its inability to discover some
strong optimizations that would be found with equivalence-checking
full programs [117]. Unlike window-based equivalence checking,
full program checking can detect aliasing conditions over the entire
program, optimize across helper functions (with full semantics),
and can optimize instructions under the strongest possible precon-
ditions and weakest possible postconditions.
D MORE DETAILS ON THE
IMPLEMENTATION OF K2
Please see §7 for an overview of K2’s implementation.
K2 uses the same internal BPF instruction structure as the kernel,
so that K2 can consume BPF instructions directly from the binary
arXiv, July 14, 2021
Benchmark
xdp1
xdp2
xdp_redirect
xdp_map_access
xdp_router_ipv4
xdp_pktcntr
xdp_fwd
xdp_fw
# Variants
produced
5
5
5
5
5
3
5
5
# accepted by
kernel checker
5
5
5
5
5
3
5
5
Cause(s) of
checker failure
-
-
-
-
-
-
-
-
Table 5: We loaded 38 K2-optimized program variants (known to be
equivalent to the corresponding source programs) into the kernel.
All programs were successfully accepted by the kernel checker.
Benchmark
(1)
(2)
(3)
(4)
(14)
(17)
(18)
# progs.
hit cache
13,479
32,706
30,557
68,828
15,827
134,505
100,641
total # calls Hit rate
to the cache
93%
93%
96%
95%
96%
96%
92%
14,470
35,072
31,833
72,220
16,552
140,686
109,046
# iters.
1,000,000
1,500,000
4,000,000
4,000,000
2,000,000
5,000,000
5,000,000
Table 6: The benefit of caching (§5) in reducing the number of
solver calls. The benchmark numbers correspond to those in Ta-
ble 1.
ELF format of the instructions (i.e., the .o files) without explicitly
decoding from and encoding into another format. Binary encode/de-
code is known to be a significant source of compiler bugs [111].
The compiler consumes inputs from pre-compiled BPF bytecode
object files as well as instruction sequences encoded through the
kernel bpf_insn data structure. The extraction of the inputs from
ELF binaries uses libbpf, the kernel’s standard library to work with
BPF bytecode. A tricky aspect of BPF bytecode is that the text sec-
tion of the ELF file is not directly executable. The text section must
be processed using relocations [99] during the loading process [113]
to ensure that run-time references to map file descriptors and other
symbols are updated before execution (the text section is indepen-
dent of these run-time parameters). K2 consumes instructions from
relocated ELF.
The output of the compiler can take on two forms: a sequence of
binary instructions, which is useful to test simple programs quickly,
or a patched ELF object file that contains the sections of the original
ELF input with the optimized instruction sequence patched in lieu
of the original instructions in the text section. K2 uses pyelftools
to perform the patching.
K2 uses relocation metadata, specifically the set of instructions
that are touched by the libbpf loader, to ensure that the linkages
between the text section and the remaining ELF sections are unmod-
ified. Hence, outputs from K2 can serve as drop-in replacements to
existing BPF object files.
Qiongwen Xu et al.
K2 includes a high-performance BPF interpreter that runs BPF
bytecode instructions using an optimized jumptable implemen-
tation akin to the kernel’s internal BPF interpreter [2]. Using C
preprocessor directives, we share code for most instructions be-
tween the interpreter and the equivalence checker. Before adopting
this design, we found that the mismatch between the behaviors of
the interpreter and the semantics of the first-order logic formula-
tion of the same program was a significant and vexing source of
bugs. We found that using a shared semantic description of each
instruction that is common to the interpreter and the first-order
logic verification condition generator was helpful in ensuring that
the input-output behaviors of the interpreter and the program’s
formalization were compatible.
We construct first-order logic representations using Z3 [65] and
also use it as our solver. To reduce the impact of large memory-
bound queries on the overall compile time, we use two separate
Z3 solver processes, with the query discharged to the solvers us-
ing a serialized smtlib2 format. We pick the solver that returns a
response first and respawn server processes after a fixed number
of discharged queries.
K2’s interpreter and the equivalence-checking query formulation
can distinguish different BPF program types and fix the inputs and
outputs appropriately.
E ESTIMATED PERFORMANCE FROM K2
In this section, we show the performance estimated by K2 with the
latency goal. We perform latency and throughput measurements of
the top-k programs from these experiments in §8.
F ADDITIONAL EVALUATION RESULTS
F.1 Parameters of stochastic search
Table 8 shows the best-performing parameter settings of K2. Table 9
shows K2’s instruction count reductions from those parameter
settings. Table 10 shows the benefits of K2’s domain-specific rules
in stochastic synthesis.
F.2 Efficacy of safety checks
The results of loading the outputs of K2 using the kernel checker
are shown in Table 5.
F.3 Caching efficacy
The efficacy of caching in reducing the number of solver queries to
perform equivalence checking is illustrated in Table 6.
F.4 Benefits of domain-specific rewrite rules
In Table 10, we show the benefits of including domain-specific
program rewrite rules (§3.1) while generating proposals within the
stochastic optimization loop.
G MORE OPTIMIZATIONS DISCOVERED BY
K2
Table 11 lists several optimization case studies across benchmarks
from the Linux kernel, hXDP, and Cilium.
20
Synthesizing Safe and Efficient Kernel Extensions for Packet Processing
arXiv, July 14, 2021
Program Runtime (sec)
When lowest perf cost prog. is found
Time (sec)
Benchmark
(9) xdp_router_ipv4
(10) xdp_redirect
(11) xdp1_kern/xdp1
(12) xdp2_kern/xdp1
(13) xdp_fwd
(14) xdp_pktcntr
(15) xdp_fw
(16) xdp_map_access
(17) from-network
(18) recvmsg4
(19) xdp-balancer
Avg. of all benchmarks
-O1
57.45
17.15
31.33
34.79
57.02
12.32
65.02
27.96
32.27
68.12
DNL
-O2/-O3
50.34
16.08
25.57
30.88
51.56
12.32
46.61
27.96
30.96
68.12
760.12
K2
47.21
14.52
24.55
28.86
43.73
11.85
45.01
27.28
29.17
63.83
724.73