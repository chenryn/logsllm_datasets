data set (e.g., unclean or very few samples).
7.3 Accuracy Evaluation
The basic premise of our work is to develop a model us-
ing the logs of smart collector and verify the conﬁguration
properties written in LTL. If a property is veriﬁed against
the model with probability p > d, where d is set as a thresh-
old, we say that it is normal, otherwise, it is anomalous.
Threshold d was learnt separately for each property by not-
ing the property veriﬁcation probability using the benign
logs model (without attack).
Logs were collected from the smart collectors which were
connected to the multiple meters. Moreover, meters had dif-
ferent conﬁgurations which make the dataset diverse. There-
fore, the model is not limited to a speciﬁc type of conﬁgu-
ration and can actually model diﬀerent conﬁguration sets
due to its markovian nature. Before discussing the accuracy
evaluation, we ﬁrst show the basic behavior of the three
randomly selected meters. These three meters use diﬀer-
ent conﬁgurations for the report size. It gives us interesting
insight about the temporally deterministic behavior. Then
we analyze that how well the model represents the system
behavior. Please note that this temporal behavioral analy-
sis was done without the randomization module and attack
traﬃc. The model checking was conducted using a proba-
bilistic symbolic model checker tool PRISM [20].
7.3.1 Temporal Behavior of the Model
Since the model preserves the temporal behavior, the prop-
erties can be seen as the conditional probability i.e., P (A|B),
where state B has already been observed (given). Therefore,
it can be stated as ‘what is the probability of seeing state A
given state B?’. It can be easily written in the LTL using
the ‘next’ or ‘eventually’ operator for the state A by ﬁlter-
ing all the states except the current/given state i.e., B as
discussed in an earlier section.
Figure 5 shows the conditional probabilities given that the
request was made for a particular meter for the usage read-
ing and load management as shown in Figure 5(a) and 5(b),
respectively. We provide the results for three meters only.
However, similar results were observed for the other meters
as well. Figure 5(a) shows the probability of response size,
given that the system was currently in the reading request
45845
40
35
30
s
e
25
Actual
Model
t
t
a
S
20
15
10
5
0
0
50
100
Time
150
200
i
s
n
o
i
t
c
d
e
r
P
e
u
r
T
100
90
80
70
60
50
40
30
20
10
0
0
100
i
s
n
o
i
t
c
d
e
r
P
e
u
r
T
90
80
70
60
50
40
30
20
10
0
0
Order−4
Order−3
Order−2
Order−1
10
20
30
40
False Predictions
pmf = 1.0
pmf > 0.8
pmf > 0.5
5
10
15
20
False Predictions
(a) Model Prediction
(b) Diﬀerent Markov Chain order
(c) Varying pmf on fourth order
model
Figure 6: Prediction accuracy for diﬀerent markov chain order and pmf for fourth order model
state i.e., a usage/reading request was sent to a meter. It can
be seen that all the three meters generated response within
the range of 26 to 30KB with diﬀerent probabilities. Two
meters generated response of size 27KB with higher proba-
bility and the third meter generated response of size 28KB.
These responses belong to diﬀerent states in the model since
size was used as a variable in the tuple (σ) used for the state
deﬁnition. However, none of the meter generated a response
of size more than 30 or less than 26KB which was set as
a variance boundary. The reading response size depends on
the sampling rate of the meter. Since the response size of the
reading request was within the range, the property ‘when-
ever a reading request is generated, the next observed state
is reading response with the size modeled’ (combining equa-
tion 6 and 8) was veriﬁed with the probability 1. Here the
probability 1 can be realized as the sum of all the probabili-
ties of the states having size within the range of 26 to 30KB.
Please note that the system can be in one state at a given
time i.e., either request sent to meter 1 or meter 2. These
conditional probabilities were calculated separately for the
next state given that the system was in the request state.
Similarly, Figure 5(b) shows the next state transition prob-
abilities given that the system was in a load management
request state.
It can be seen that all the three meters
probabilistically responded to the request. Meter 2 (green
line with circular marker) showed the two transition prob-
abilities. Response of size 9KB with probability close to
0.65 and size 6KB with probability close to 0.35. Similarly,
meter-1 responded with 6 diﬀerent sizes. All of these sizes
were within the range of 5 to 10KB. Lastly, meter-3 re-
sponded with the three diﬀerent sizes where one size was
most likely and the other two were less likely. It can be ob-
served that whenever the system was in a load management
request state, the response state was observed next with
the probability of 1. However, response also had multiple
states depending on the size of the response which was used
as a variable in deﬁning the state s consisting of multiple
σ. Therefore, it can be concluded that the model exhibits
a temporally deterministic behavior for the system under
consideration. It is clear that the temporal probabilities for
the properties can be learnt from the model built using the
benign logs. Now we analyze whether the model truly rep-
resents the system or in other words how well the model
represents the logs.
7.3.2 Model Accuracy
In order to determine whether the model actually repre-
sents the logs or not, we conduct a model accuracy experi-
ment as shown in Figure 6. It does not include the attack
traﬃc or property veriﬁcation. We divide the benign logs
into two halves. The ﬁrst half was used to build a model
using Algorithm 1. Second half was used as the test dataset
and the model was applied on it for the prediction. For
each step, the current state was learned and based on the
current state, the next state was predicted using the model
i.e., states having higher probabilities in probability mass
function (pmf) were predicted. Figure 6(a) shows the pre-
diction using the fourth order model. The red cross marker
denotes the actual states observed in the test log. However,
blue dashed line represents the prediction of the model. It
can be observed that the model predicts the future states
with high accuracy though few false predictions (less than
2%) were encountered as well. These false predictions were
observed as a result of the unseen behavior since the benign
log was divided into two halves. As a result, few lower prob-
ability states were not observed after a certain state s (i.e.,
tuple history of order four) present in the ﬁrst half, thus
yielding to false prediction. To check the model conﬁdence,
we did the prediction using one hour learning to one week
learning. In all the cases, the false predictions observed were
below 2%.
We used diﬀerent criterion and show the results in Fig-
ure 6(b) and (c). We count the total number of predictions
and classify whether they were true or not. In Figure 6(b),
we used diﬀerent markov chain orders i.e., the current state
was deﬁned using one tuple or multiple tuple history. It can
be observed in Figure 6(b) that the fourth order markov
chain provides the best prediction accuracy as compared to
the lower order markov chains. In another experiment, we
change the pmf bound used for the prediction. For example,
pmf of 0.5 means minimum number of next transition states
having probabilities sum of 0.5. If there are three possible
next states based on the current state having probabilities
0.6, 0.2 and 0.2, only state having 0.6 probability will be
selected as the ‘predicted’ state since it has the probability
greater than or equal to 0.5. However, if none of the states
has probability higher than 0.5, minimum number of mul-
tiple states will be selected whose sum reaches 0.5. Figure
6(c) shows the prediction accuracy for the diﬀerent pmf. It
can be seen that pmf of 1 i.e., based on the current state all
the next possible states in the model are predicted, provides
the best accuracy with a very low false prediction rate. It
can be intuitively argued that this false prediction rate will
be the bound for the false positive for the attack detection
accuracy, since this shows how well the model represents the
data. Therefore, it can be concluded that the fourth order
459e
t
a
R
n
o
i
t
c
e
t
e
D
100
90
80
70
60
50
40
30
20
10
0
0
y
t
i
l
i
b
a
b
o
r
P
n
o
i
t
a
c
i
f
i
r
e
V
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0
2
4
6
8
10
Attack Rate (pkts/sec)
0.1
0.2
0.3
0.4
0.5
False Positive
(a) Detection Accuracy
(b) Probability vs Attack
rate
Figure 7: Detection Accuracy and Veriﬁcation Prob-
ability vs Attack rate
markov chain can accurately model the underlying network
with minimal loss, hence we use the fourth order for the
model checking.
7.3.3 Detection Accuracy
Mixed data was used to calculate the detection accuracy
which had attack and benign logs both. Since the attack
logs were generated separately in a controlled environment,
the time stamps of the attack logs were adjusted by a ﬁxed
constant to have the same time window as of normal/benign
logs. Allowed communication type ty values were used for
the attack logs since other communication types do not exist
in the model and can be detected easily. For attack detec-
tion, model learning was done in a continuous online learn-
ing fashion using a sliding window approach. The size of the
sliding window was kept to one hour and the sliding window
interval was set to one minute. Model was learnt separately
for each smart collector in the dataset and detection results
were averaged. Figure 7(a) shows the detection accuracy
achieved by the presented model. It can be seen that high
detection rate of more than 95% was achieved with a neg-
ligible false alarm rate of approximately 0.2%. Logs were
collected from smart collectors for approximately 2000 me-
ters. Average false alarm rate varies from 0.75 to 1.008 false
alarms per meter per week, depending upon the threshold
used for detection rates > 70%. Please note that these rates
are on the entire dataset collected. The utility provider we
worked with has hundreds of thousand smart meters in a
state. This might increase to millions of meters in a state
for large-scale providers. These could be managed by one or
multiple headend systems. Receiver Operating Characteris-
tics (ROC) curve is generated by changing the veriﬁcation
probability (threshold) of conﬁguration-based LTL proper-
ties which were veriﬁed against the model built using the
mixed data logs. It is intuitive that the attack activity does
not follow the state transitions as allowed in the temporal
properties. Therefore, the higher volume of attack activity
as compared to the benign activity can be easily detected
even with the loose probability veriﬁcation threshold. On
the other hand, the lower volume of attack activity will be
detected by the strict probability veriﬁcation threshold. Fig-
ure 7(b) shows the eﬀect of veriﬁcation probability for multi-
ple degree of DoS attacks. It can be observed that the higher
attack rate is detectable with a loose veriﬁcation probability
threshold.
Complexity of the probabilistic model checker (PRISM)
for a markov chain model and LTL property veriﬁcation is
doubly exponential in the size of LTL formula and polyno-
mial in the size of state space [14]. Algorithm 1 was imple-
mented in Java on a dual core machine to learn the model
from the logs. The run-time complexity is in hundreds of
milliseconds (≈ 300ms) and the memory size of the model
for each collector was few kilobytes (≈ 20KB). The com-
plexity was measured using HPROF [11] tool. Model was
then veriﬁed against the LTL properties using PRISM. The
run-time complexity of the properties veriﬁcation is approx-
imately 1.5 secs.
The presented model can be used in two fashions: 1) use
a centralized approach and build a single giant model for
the entire AMI, deﬁning smart collector in either source or
destination, the model can reduce the state space to pos-
sible states only for that particular smart collector, in this
case oﬄine model checking can be done in the headend by
pulling the logs, 2) if the giant state machine exceeds the
scalability limit of the model checker, each smart collector
can be modeled separately. In case of modeling each smart
collector separately, the model checking can be done online
or oﬄine, depending on the computational power available.
Therefore, the proposed approach is ﬂexible.
7.4 Scalability
In this section we discuss the scalability of the approach.
PRISM is shown to be scalable up to 1010 states [20]. We
also investigate the maximum number of meters that can
be handled with various markov chain orders as shown in
Figure 8. We show this for multiple markov chain orders
i.e., 1 to 4 in Figure 8. For the ﬁrst order markov chain, it
can be observed from Figure 8(a) that the number of states
increase linearly with the number of meters. In this case, it
can accommodate up to 25000 meters per collector, although
we show it up to 1000 meters in the graph in order to show
the linear trend.
Similarly, the second order markov chain can handle up
to 5000 meters as shown in Figure 8(b). It can be observed
that the trend tends to be exponential. Scalability for third