using a quorum that contains one or more aux-
iliary processors.
If a new leader was chosen in
step 1,
it does this as described in Section 2.2
above by choosing a new ballot number and ini-
tiating phase 1 with that ballot number for all rel-
evant instances of the consensus algorithm. If the
old leader is still working, it just sends to the aux-
iliary processors the same “2a” messages that it
had already sent to the main processors.
4. As in standard Dynamic Paxos, the working pro-
cessors propose and choose a sequence of state ma-
chine commands to reconﬁgure the system so the
failed main processor is removed from the set G of
acceptors (and hence from M ).
5. The leader proposes and gets chosen a sequence of
α no-op state machine commands. Let j be the
command number of the last of these commands.
After step 5, the new set G of acceptors chosen in step 4
is in eﬀect for subsequent instances of the consensus al-
gorithm. This means that the set M of main processors
in G constitute a quorum, so they can resume execut-
ing the system. However, remember that the Paxos
consensus algorithm’s ability to recover from failures
rests on acceptors maintaining certain information in
stable storage. To bound the amount of storage re-
quired by auxiliary processors, they need to be able to
forget the information they saved in steps 3–5, where
they participated in executing instances of the consen-
sus algorithm. They can do that after the working
main processors have learned the commands chosen in
those instances. Therefore, before the system resumes
normal execution, the following steps should also be
performed.
6. The leader ensures that all processors in (the new)
M know all commands through command number
j (deﬁned in step 5).
7. The leader instructs all auxiliary processors to re-
member in stable storage that instances 1 through
j of the consensus algorithm have chosen com-
mands, and that they have performed no actions
for any other instances.
(They need not record
any of the chosen commands.) The auxiliary pro-
cessors can then erase from stable storage all in-
formation relevant to any of the ﬁrst j instances
of the consensus algorithm.
This sequence of steps describes what normally hap-
pens when a main processor fails. A complete algo-
rithm must handle abnormal cases as well—for exam-
ple, if the leader fails while these steps are being per-
formed, or if two processors both believe they are the
leader and have diﬀerent views of what processor has
failed. But the actions performed in these steps are just
implementing Dynamic Paxos. (Steps 2 and 6 simply
disseminate knowledge of what commands have been
chosen.) The precise deﬁnition of these actions is there-
fore the same as in ordinary Paxos. The only diﬀerence
is that an auxiliary processor may not be able to re-
spond appropriately to a “1a” or “2a” message because
it has erased the needed information in step 7. In that
case, instead of replying with the chosen command as
indicated in observation O3, it must ignore the mes-
sage. (It could report to the leader why it is ignoring
the message, advising the leader to ask a main proces-
sor what command was chosen.)
The auxiliary processors are needed only in the event
of failure of one of the main processors, at which time
they must participate in the execution of only a small
number of instances of the Paxos consensus algorithm.
This would seem to imply that they do not need much
processing power. However, the consensus algorithm
requires them to write proposed commands to stable
storage. In some applications, such commands could
be quite big, and writing them to stable storage could
be expensive. If this is the case, we can apply obser-
vation O4 and have auxiliary processors receive and
store only hashes of proposed commands. Since every
quorum contains a main processor, a learner receiving
“2b” messages from a quorum must receive at least one
that contains the command rather than its hash. How-
ever, we need to prevent the problem mentioned in O4,
in which progress is prevented because a leader knows
only the hash of a value without knowing the value
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:30:57 UTC from IEEE Xplore.  Restrictions apply. 
itself. This is done by having the leader delay send-
ing a “2a” message with the hash of a value v to any
auxiliary processor until all the working main proces-
sors have acknowledged receipt of their “2a” messages
containing v.
As in ordinary Dynamic Paxos, we are not commit-
ted to any particular algorithm for determining that a
processor has failed or has been repaired. Since the
reconﬁguration is performed by state machine com-
mands, any algorithm can be used. In practice, the al-
gorithm used by Cheap Paxos for determining whether
a main processor has failed will be quite diﬀerent from
that used in traditional Dynamic Paxos. In traditional
implementations of Dynamic Paxos, any majority of
acceptors constitutes a quorum, so system can continue
to make progress even if a server has failed. In that
case, one can aﬀord to wait to make sure the server
has really failed before reconﬁguring it out of the sys-
tem. But Cheap Paxos stops making progress as soon
as one main processor fails. It must therefore be more
aggressive in removing processors that may have failed.
Although this diﬀerence aﬀects the details of deciding
what processors are working, it does not change the
basic state machine algorithm.
We have been tacitly assuming that the set of all
processors (main plus auxiliary) is ﬁxed. Reconﬁgura-
tion can also be used to change the set of processors.
We are already reconﬁguring the set of acceptors to
remove failed main processors and add repaired ones.
Additional fault tolerance can be obtained by replacing
failed auxiliary processors with spares, just as in ordi-
nary Dynamic Paxos. This reconﬁguration can be per-
formed with state machine commands executed by only
the main processors; auxiliary processors need only pe-
riodically inform the main processors that that are still
working. A newly installed auxiliary processor needs
to remember in its stable storage only that it has not
performed any actions for any instances of the Paxos
consensus algorithm.
An auxiliary processor acts only as an acceptor, not
a learner, so it does not know what commands are cho-
sen. Hence, if reconﬁguration can change the set of
auxiliary processors, an auxiliary processor does not
know whether it is an acceptor. This makes no dif-
ference. As observed in O3, acceptors simply respond
to “1a” and “2a” messages. Only leaders and learn-
ers, which are roles played by main processors, need to
know the set of acceptors and the quorums.
3.2 Correctness of Cheap Paxos
Cheap Paxos uses the Paxos consensus algorithm to
choose commands. Its safety properties follow directly
from the safety properties of the consensus algorithm.
In particular, two diﬀerent servers can never disagree
about the value of the i th command, for any i.
The liveness properties of Cheap Paxos can also be
inferred from those of the Paxos consensus algorithm.
However, this is complicated because Cheap Paxos is
an implementation of Dynamic Paxos, in which liveness
depends on precisely how the reconﬁguration is per-
formed. For example, the system can make no progress
if a reconﬁguration selects a set of failed or nonexistent
processors as acceptors. Moreover, simply being able
to choose new commands doesn’t ensure progress. To
be able to execute the i th command, a server needs
to know not just that command, but also all previous
commands. For example, the system could make no
progress if command 1 had been chosen, but no work-
ing server knew its value. Cheap Paxos also has the
additional complication that auxiliary processors for-
get information that can be used by ordinary Paxos to
recover from certain failures.
To state the liveness property satisﬁed by Cheap
Paxos, we need some deﬁnitions. We call a set of pro-
cessors nonfaulty if they are all working and can com-
municate with one another in a timely fashion. Deﬁne
command number i to be recorded if some auxiliary
processor has stored in its stable storage the fact that
i has been chosen. (That is, the auxiliary processor
has recorded in step 7 of the reconﬁguration procedure
that all commands numbered through j have been cho-
sen, for some j≥i.) A command number i is said to be
active if i has not been recorded, but a “2a” message
has been sent for instance i of the consensus algorithm.
We deﬁne a main processor to be up-to-date if it knows
all recorded commands. (If auxiliary processors store
only hashes of values, then for a main processor p to
be up-to-date, it must also satisfy the following condi-
tion: For every active command number i and every
“2a” message sent to an auxiliary processor in instance
i of the consensus algorithm, p must have received its
corresponding “2a” message.)
We can now state the liveness property satisﬁed by
Cheap Paxos. Step 6 of the reconﬁguration procedure
assumes some method of propagating knowledge of cho-
sen commands. We assume that knowledge is contin-
ually exchanged among the main processors so that, if
p and q are main processors, p knows a command, and
the set {p, q} is nonfaulty for long enough, then q will
learn that command. The liveness property satisﬁed
by Cheap Paxos is then:
The system makes progress if there is a non-
faulty set of processors containing a unique
leader, at least one up-to-date main proces-
sor, and, for all active command numbers i, a
quorum for instance i of the consensus algo-
rithm.
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:30:57 UTC from IEEE Xplore.  Restrictions apply. 
[7] B. W. Lampson. How to build a highly available sys-
tem using consensus. In O. Babaoglu and K. Marzullo,
editors, Distributed Algorithms, volume 1151 of Lec-
ture Notes in Computer Science, pages 1–17, Berlin,
1996. Springer-Verlag.
[8] B. Liskov, S. Ghemawat, R. Gruber, P. Johnson, and
L. Shrira. Replication in the harp ﬁle system. In Pro-
ceedings of the thirteenth ACM symposium on Oper-
ating systems principles, pages 226–238. ACM Press,
1991.
[9] J.-F. Pˆaris and D. D. E. Long. Voting with regenerable
volatile witnesses. In Proceedings of the Seventh Inter-
national Conference on Data Engineering, April 8-12,
1991, Kobe, Japan, pages 112–119. IEEE Computer
Society, 1991.
[10] F. B. Schneider. Implementing fault-tolerant services
using the state machine approach: A tutorial. ACM
Computing Surveys, 22(4):299–319, Dec. 1990.
Informally, we can view the set of nonfaulty main pro-
cessors as an “amoeba” that withdraws a pseudopod
when a processor fails and extends one when a pro-
cessor is repaired. It takes time for knowledge of cho-
sen commands to ﬂow into a new pseudopod.
If the
amoeba were to move around too quickly, knowledge
could be lost because processors failed before their
knowledge could ﬂow to newly repaired processors.
Assuming that the total number of nonfaulty proces-
sors (main plus auxiliary) remains large enough, Cheap
Paxos guarantees that the system will continue to make
progress as long as the amoeba moves slowly enough
that such knowledge is not lost.
4 Conclusion
Cheap Paxos is a variant of the Paxos algorithm that
can make progress in the face of up to F failures by us-
ing F + 1 main processors plus F auxiliary processors.
Unlike the spare processors used in previous systems,
our auxiliary processors need do nothing except for a
brief period after a main processor fails. The auxil-
iary processors therefore do not require nearly as much
processing power or storage as the main processors. By
using auxiliary processors, Cheap Paxos can lead to a
system that achieves greater fault tolerance than other
algorithms with the same number of main processors.
Acknowledgement
Butler Lampson pointed out to us the problem of large
commands, and its solution through observation O4.
He was also ﬁrst to observe that, in a conﬁguration with
a single working main processor, every set of processors
containing that processor is a quorum.
References
[1] R. De Prisco, B. Lampson, and N. Lynch. Revisit-
ing the paxos algorithm. Theoretical Comput. Sci.,
243:35–91, 2000.
[2] C. Dwork, N. Lynch, and L. Stockmeyer. Consensus in
the presence of partial synchrony. J. ACM, 35(2):288–
323, Apr. 1988.
[3] L. Lamport. The implementation of reliable dis-
tributed multiprocess systems. Computer Networks,
2:95–114, 1978.
[4] L. Lamport. Time, clocks, and the ordering of events
in a distributed system. Commun. ACM, 21(7):558–
565, July 1978.
[5] L. Lamport. The part-time parliament. ACM Trans.
Comput. Syst., 16(2):133–169, May 1998.
[6] L. Lamport. Paxos made simple. ACM SIGACT News
(Distributed Computing Column), 32(4 (Whole Num-
ber 121)):18–25, Dec. 2001.
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:30:57 UTC from IEEE Xplore.  Restrictions apply.