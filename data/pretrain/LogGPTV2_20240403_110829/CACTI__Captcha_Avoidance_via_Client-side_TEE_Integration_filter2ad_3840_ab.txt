2.2 Group Signatures
3 System & Threat Models
A group signature scheme aims to prevent the veriﬁer from
determining the group member which generated the signature.
Each group member is assigned a group private key under
a single group public key. In case a group member needs to
be revoked, a special entity called group manager can open
the signature. A group signature scheme is composed of ﬁve
algorithms [26]:
• Setup: Given a security parameter, an efﬁcient algorithm
outputs a group public key and a master secret for the
group manager.
• Join: A user interacts with the group manager to receive
a group private key and a membership certiﬁcate.
• Sign: Using the group public key, group private key,
membership certiﬁcate, and a message m, a group mem-
ber generates a group signature of m.
• Verify: Using the group public key, an entity veriﬁes a
group signature.
• Open: Given a message, a putative signature on the
message, the group public key and the master secret, the
group manager determines the identity of the signer.
A secure group signature scheme satisﬁes the following prop-
erties [26]:
• Correctness: Signatures generated with any member’s
group private key must be veriﬁable by the group public
key.
• Unforgeability: Only an entity that holds a group pri-
vate key can generate signatures.
• Anonymity: Given a group signature, it must be compu-
tationally hard for anyone (except the group manager) to
identify the signer.
• Unlinkability: Given two signatures, it must be compu-
tationally hard to determine whether these were signed
by the same group member.
• Exculpability: Neither a group member nor the group
manager can generate signatures on behalf of other group
members.
• Traceability: The group manager can determine the
identity of a group member that generated a particular
signature.
• Coalition-resistance: Group members cannot collude
to create a signature that cannot be linked to one of the
group members by the group manager.
Enhanced Privacy ID (EPID) [30] is a group signature scheme
used by remote attestation of Intel SGX enclaves. It satis-
ﬁes the above properties whilst providing additional privacy-
preserving revocation mechanisms to revoke compromised or
misbehaving group members. Speciﬁcally, EPID’s signature-
based revocation protocol does not “Open” signatures but
rather uses a signature produced by the revoked member to
notify other entities that this particular member has been re-
voked.
The ecosystem that we consider includes three types of prin-
cipals/players: (1) servers, (2) clients, and (3) TEEs. There
are multitudes of these three principal types. The number of
clients is the same as that of TEEs, and each client houses
exactly one TEE. Even though a TEE is assumed to be phys-
ically within a client, we consider it to be separate security
entity. Note that a human user can, of course, operate or own
multiple clients, although there is clearly a limit and more
clients implies higher costs for the user.
We assume that all TEEs are trusted: honest, benign and
insubvertible. We consider all side-channel and physical at-
tacks against TEEs to be out of scope of this work and assume
that all algorithms and cryptographic primitives implemented
within TEEs are impervious to such attacks. We also consider
cuckoo attacks, whereby a malicious client utilizes multiple
(possibly malware infected) machines with genuine TEEs, to
be out of scope, since clients and their TEEs are not consid-
ered to be strongly bound. We refer to [62] and [36] as far as
means for countering such attacks. We assume that servers
have a means to authenticate and attest TEEs, possibly with
the help of the TEE manufacturer.
All clients and servers are untrusted, i.e., they may act mali-
ciously. The goal of a malicious client is to avoid CAPTCHAs,
while a malicious server either aims to inconvenience a client
(via DoS) or violate client’s privacy. For example, a malicious
server can try to learn the client’s identity or link multiple
visits by the same client. Also, multiple servers may collude
in an attempt to track clients.
Our threat model yields the following requirements for the
anticipated system:
rate-proofs.
• Unforgeability: Clients cannot forge or modify CACTI
• Client privacy: A server (or a group thereof) cannot
link rate-proofs to the clients that generated them.
We also pose the following non-security goals:
• Latency: User-perceived latency should be minimized.
• Data transfer: The amount of data transfer between
client and server should be minimized.
• Deployability: The system should be deployable on cur-
rent off-the-shelf client and server hardware.
4 CACTI Design & Challenges
This section discusses the overall design of CACTI and justi-
ﬁes our design choices.
4.1 Conceptual Design
Rate-proofs. The central concept underpinning our design
is the rate-proof (RP). Conceptually, the idea is as follows:
Assuming that a client has an idealized TEE, the TEE stores
2564    30th USENIX Security Symposium
USENIX Association
one or more named sorted lists of timestamps in its rollback-
protected secure memory. To create a rate-proof for a speciﬁc
list, the TEE is given the name of the list, a threshold (Th),
and a new timestamp (t). The threshold is expressed as a
starting time (ts) and a count (k). This can be interpreted
as: “no more than k timestamps since ts”. The TEE checks
that the speciﬁed list contains k or fewer timestamps with
values greater than or equal to ts. If so, it checks if the new
timestamp t is greater than the latest timestamp in the list.
If both checks succeed, the TEE pre-pends t to the list and
produces a signed statement conﬁrming that the named list
is below the speciﬁed threshold and the new timestamp has
been added. If either check fails, no changes are made to the
list and no proof is produced. Note that the rate-proof does
not disclose the number of timestamps in the list.
Furthermore, each list can also be associated with a public
key. In this case, requests for rate-proofs must be accompa-
nied by a signature over the request that can be veriﬁed with
the associated public key. This allows the system to enforce a
same-origin policy for speciﬁc lists – proofs over such lists
can only be requested by the same entity that created them.
Note that this does not provide any binding to the identity of
the entity holding the private key, as doing so would neces-
sitate the TEE to check identities against a global public key
infrastructure (PKI) and we prefer for CACTI not to require it.
Rate-proofs differ from rate limits because the user is al-
lowed to perform the action any number of times. However,
once the rate exceeds the speciﬁed threshold, the user will no
longer be able to produce rate-proofs. The client can always
decide to not use its TEE; this covers clients who do not have
TEEs or those whose rates exceeded the threshold. On the
other hand, if the server does not yet support CACTI, the client
does not store any timestamps, or perform any additional com-
putation.
CAPTCHA-avoidance. In today’s CAPTCHA-protected
services, the typical interaction between the client (C) and
server (S) proceeds as follows:
1. C requests access to a service on S.
2. S returns a CAPTCHA for C to solve.
3. C submits the solution to S.
4. If the solution is veriﬁed, S allows C access to the ser-
vice.
Although modern approaches, e.g., reCAPTCHA, might in-
clude additional steps (e.g., communicating with third-party
services), these can be abstracted into the above pattern.
Our CAPTCHA-avoidance protocol keeps the same inter-
action sequence, while substituting steps 2 and 3 with rate-
proofs. Speciﬁcally, in step 2, the server sends a threshold
rate and the current timestamp. In step 3, instead of solving a
CAPTCHA, the client generates a rate-proof with the spec-
iﬁed threshold and timestamp, and submits it to the server.
The server has two types of lists:
• Server-speciﬁc: The server requests a rate-proof over
its own list. The name of the list could be the server’s
URL, and the request may be signed by the server. This
determines the rate at which the client visits this speciﬁc
server.
• Global: The server requests a rate-proof over a global
list, with a well-known name, e.g. CACTI-GLOBAL. This
yields the rate at which the client visits all servers that
use the global list.
The main idea of CAPTCHA avoidance is that a legitimate
client should be able to prove that its rate is below the server-
deﬁned threshold. In other words, the server should have suf-
ﬁcient conﬁdence that the client is not acting in an abusive
manner (where the threshold of between abusive and non-
abusive behaviors is set by the server). Servers can select their
own thresholds according to their own security requirements.
A given server can vary the threshold across different ac-
tions or even across different users or user groups, e.g., lower
thresholds for suspected higher-risk users. If a client cannot
produce a rate-proof, or is unwilling to do so, the server sim-
ply reverts to the current approach of showing a CAPTCHA.
CACTI essentially provides a fast-pass for legitimate users.
The original CAPTCHA paper
[58] suggested that
CAPTCHAs could be used in the following scenarios:
1. Online polls: to prevent bots from voting,
2. Free email services: to prevent bots from registering
for thousands of accounts,
3. Search engine bots: to preclude or inhibit indexing of
4. Worms and spam: to ensure that emails are sent by
5. Preventing dictionary attacks. to limit the number of
websites by bots,
humans,
password attempts.
As discussed in Section 1, it is unrealistic to assume that
CAPTCHAs cannot be solved by bots (e.g., using computer
vision algorithms) or outsourced to CAPTCHA farms. There-
fore, we argue that all current uses of CAPTCHAs are actually
intended to slow down attackers or increase their costs. In
the list above, scenarios 2 and 5 directly call for rate-limiting,
while scenarios 1, 3, and 4 can be made less proﬁtable for
attackers if sufﬁciently rate-limited. Therefore, CACTI can be
used in all these scenarios.
In addition to CAPTCHAs, modern websites use a variety
of abuse-prevention systems (e.g., ﬁltering based on client IP
address or cookies). We envision CACTI being used alongside
such mechanisms. Websites could dynamically adjust their
CACTI rate-proof thresholds based on information from these
other mechanisms. We are aware that rate-proofs are a ver-
satile primitive that could be used to ﬁght abusive activity in
other ways, or even enable new use-cases. However, in this
paper, we focus on the important problem of reducing the user
burden of CAPTCHAs.
USENIX Association
30th USENIX Security Symposium    2565
4.2 Design Challenges
In order to realize the conceptual design outlined above, we
identify the following key challenges:
TEE attestation. In current TEEs, the process of remote
attestation is not standardized. For example, in SGX, a veriﬁer
must ﬁrst register with Intel Attestation Service (IAS) before
it can verify TEE quotes. Other types of TEEs would have
different processes. It is unrealistic to expect every web server
to establish relationships with such services from all manu-
facturers in order to verify attestation results. Therefore, web
servers cannot directly verify the attestation, but still need to
ascertain that the client is running a genuine TEE.
TEE memory limitations. TEEs typically have a small
amount of secure memory. For example, if the memory of an
SGX enclave exceeds the size of the EPC (usually 128 MB),
the CPU has to swap pages out of the EPC. This is a very
expensive operation, since these pages must be encrypted and
integrity protected. Therefore, CACTI should minimize the
required amount of enclave memory, since other enclaves may
be running on the same platform.
Limited number of monotonic counters. TEEs typically
have a limited number of hardware monotonic counters, e.g.,
SGX allows at most 256 per enclave. Also, the number of
counter increments can be limited, e.g., in SGX the limit is
100 in a single epoch [8] – a platform power cycle, or a 24 hour
period. This is a challenge because hardware monotonic coun-
ters are critical for achieving rollback-protected storage. Re-
call that CACTI requires rollback-protected storage for all
timestamps, to prevent malicious clients from rolling-back
the timestamp lists and falsifying rate-proofs. Furthermore,
this storage must be updated every time a new timestamp is
added, i.e., for each successful rate-proof.
TEE entry/exit overhead. Invoking TEE functionality
typically incurs some overhead. For example, whenever an
execution thread enters/exits an SGX enclave, the CPU has
to perform various checks and procedures (e.g., clearing reg-
isters) to ensure that enclave data does not leak. Identifying
and minimizing the number of TEE entries/exits, whilst main-
taining functionality, can be challenging.
4.3 Realizing CACTI Design
We now present a detailed design that addresses aforemen-
tioned design challenges. We describe its implementation in
Section 5.
4.3.1 Communication protocol
The web server must be able to determine that a supplied
rate-proof was produced by a genuine TEE. Typically, this
would be done using remote attestation, where the TEE proves
that it is running CACTI code. If the TEE provides privacy-
preserving attestation (e.g., the EPID protocol used in SGX
remote attestation), this would also fulﬁll our requirement
TEE
PA
get_group_private_key()
request_attestation()
attestation_report
skTEE
Figure 2: CACTI provisioning protocol. The interaction be-
tween the Provisioning Authority (PA) and the client’s T EE
takes place over a secure connection, using the client to pass
the encrypted messages. After verifying the attestation report
(and any other required information), the PA provisions the
T EE with a group private key (skTEE).
for client privacy, since websites would not be able to link
rate-proofs to speciﬁc TEEs.
However, as described above, current TEE remote attesta-
tion is not designed to be veriﬁed by anonymous third parties.
Furthermore, as CACTI is not limited to any particular TEE
type, websites would need to understand attestation results
from multiple TEE vendors, potentially using different proto-
cols. Finally, some types of TEEs might not support privacy-
preserving remote attestation, which would undermine our
requirement for client privacy.
To overcome this challenge, we introduce a separate Provi-
sioning Authority (PA) in order to unify various processes for
attesting CACTI TEEs. Fundamentally, the PA is responsible
for verifying TEE attestation (possibly via the TEE vendor)
and establishing a privacy-preserving mechanism through
which websites can also establish trust in the TEE. Speciﬁ-
cally, the PA protects user privacy by using the EPID group