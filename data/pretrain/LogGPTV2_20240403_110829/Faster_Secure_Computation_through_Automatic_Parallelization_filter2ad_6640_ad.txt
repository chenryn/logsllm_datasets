over, IPP can be used in all the scenarios where the par-
ties inputs and seeds could be revealed at a later point
to identify cheating parties. Examples might be nego-
tiations (auctions) or games, such as online poker. An-
other ﬁeld of application is the joint challenge creation,
e.g. RSA factorization. Using secure computation, two
parties could jointly create a problem instance without
already knowing the solution. This allows them to create
a problem and to participate in the challenge at the same
time without a computational advantage. Once a solution
is computed, all parts of the secure computation can be
veriﬁed in hindsight.
For further work, we note that the core idea of IPP
could be applied in other TPC protocols. To proﬁt from
IPP, a state sharing mechanism in the protocols security
model is required as well as an asymmetric workload
between the parties. One example might be the highly
asymmetric STC protocol by Jarecki and Shmatikov [19]
that uses zero-knowledge proofs over every gate.
In this section, we evaluate the three proposed paral-
lelization schemes. We begin by introducing our paral-
lel STC framework named UltraSFE and benchmark its
performance on a single core in § 6.1. The applications
and their circuit descriptions used for benchmarking are
described in § 6.2. We evaluate the ofﬂine garbling per-
formance of the proposed parallelization techniques in
§ 6.3, before integrating and evaluating the promising
coarse-grained parallelization (CGP) in a online setting
in § 6.4. Finally, in § 6.5 we benchmark the inter-party
parallelization (IPP) approach.
6.1 UltraSFE
UltraSFE1 is a parallel framework for Yao’s garbled
circuits built up on the JustGarble (JG) [5] garbling
scheme. To realize efﬁcient parallelization, data struc-
tures and memory layout are optimized with the purpose
of parallelization in mind. This is, to the best of our
knowledge, not the case with existing open source frame-
works. Therefore, we adapted the JustGarble garbling
scheme to support parallelization.
UltraSFE is written in C++ using SSE4, OpenMP and
Pthreads to realize multi-core parallelization. Conceptu-
ally UltraSFE is using ideas from the Java based memory
efﬁcient ME SFE framework [13], which itself is based
on the popular FastGC framework [15]. The fast hard-
ware AES extension in current CPU generations is ex-
ploited by the JustGarble garbling scheme. Oblivious
transfers are realized with the help of the highly efﬁcient
and parallelized OTExtension library written by Asharov
et al. [2]. Moreover, UltraSFE adopts techniques from
many recent theoretical and practical advances of Yao’s
protocol. This includes pipe-lining, point-and-permute,
garbled row reduction, free-XOR and the half-gate ap-
proach [15, 21, 27, 31, 36].
Framework comparison. To illustrate that UltraSFE is
suited to evaluate the scalability of different paralleliza-
tion approaches, we present a comparison of its garbling
performance with other state of the art frameworks using
a CPU architecture in Table 1. Namely, we compare the
single core garbling speed of UltraSFE, which is prac-
tically identical to JG, with the parallel frameworks by
Barni et al. (BCPU) [3], Husted et al. (HCPU) [17] and
Kreuter et al. (KSS) [23]. Note, these results are com-
pared in the ofﬂine setting, i.e., truth tables are written to
memory. This is because circuit garbling is the most cost
intensive part of Yao’s protocol and therefore the most
interesting when comparing the performance of different
frameworks. The previous parallelization efforts HCPU
1UltraSFE will
source
http://www.seceng.informatik.tu-darmstadt.de/research/software/
be made
available
as
open
on
540  24th USENIX Security Symposium 
USENIX Association
10
Ours / JG [5] BCPU [3] HCPU[17]
3500
E5-2609
-
E5-2620
gps
cpg
arch
8.3M
108
E5-2680
KSS [23]
0.1M
>6500 [5]
i7-970
Table 1: Single core garbling speed comparison of different
frameworks on circuits with more than 5 million gates. Metrics
are non-linear gates per second (gps) in millions (M) and clocks
per gate (cpg). All results have been observed on the Intel pro-
cessor speciﬁed in row arch. Note, for HCPU [17] only circuit
evaluation times have been reported on the CPU, the garbling
speed can be assumed to be lower.
and BCPU actually abstained from implementing an on-
line version of Yao’s protocol that supports pipe-lining.
As metrics we use garbled gates per second (gps) and the
average number of CPU clock cycles per gate (cpg), as
proposed in [5]. The numbers are taken from the cited
publications and if not given, the cpq results are calcu-
lated based on the CPU speciﬁcations (arch). Even when
considering theses numbers only as rough estimates, due
to the different CPU types, we observe that UltraSFE per-
forms approximately 1-2 orders of magnitude faster than
existing parallelizations of Yao’s protocol. This is mostly
due to the efﬁcient ﬁxed-key garbling scheme using the
AES-NI hardware extension and a carefully optimized
implementation using SSE4. Summarizing, UltraSFE
shows competitive garbling performance on a single core
and hence, is a very promising candidate for paralleliza-
tion.
6.2 Evaluation methodology
To evaluate the different parallelization approaches we
use three example applications that have been used to
benchmark and compare the performance of Yao’s gar-
bled circuits in the past.
Biometric matching (BioMatch). The ﬁrst application
that we use is privacy-preserving biometric matching. In
this application a party matches one biometric sample
against the other’s party database of biometric templates.
Example scenarios are face-recognition or ﬁngerprint-
matching [9]. One of the encompassing concepts is the
computation of the Euclidean distance between the sam-
ple and all database entries. Once all distances have
been computed, the minimal distance determines the best
match. Thus, the task is to securely compute the minimal
i=1(si,n − ei)2(cid:30) with
si being the sample of degree d provided by the ﬁrst party
and e1, . . . ,e n being the database elements with the same
degree provided by the other party. Following the exam-
ples of [8, 20], the chosen parameters for this circuit are
the number of elements in the database n = 512, the de-
gree of each element d = 4 and the integer size b = 64bit.
distance min(cid:31)∑d
i=1(si,1 − ei)2, . . . ,∑d
Code size
Circuit size
Non-linear gates
# Input bits PA/PB
Ofﬂine garbling time
BioMatch MExp MVMul
10 LOC
22 LOC
3.3M
37%
66M
25%
28 LOC
21.5M
41%
1K/1K
1.136s
131K/256
2.07s
17K/1K
0.154s
Table 2: Circuit properties. Presented are the code size, the
overall circuit size in the number of gates, the fraction of non-
linear gates that determine the majority of computing costs, the
number of input bits as well as the sequential ofﬂine garbling
time with UltraSFE.
Modular exponentiation (MExp).
The second ap-
plication that we benchmark is parallel modular expo-
nentiation. Modular exponentiation has been used be-
fore to benchmark the performance of Yao’s garbled cir-
cuits [5, 8, 23].
It has many applications in privacy-
preserving computation. For example, blind signatures
where the message to be signed should not be revealed
to the signing party. For this application, we differentiate
the circuit by the number of iterated executions k = 32,
as well as the integer width b = 32.
Matrix-vector multiplication (MVMul). Algebraic
operations such a matrix multiplication or the dot vector
product are building blocks for many privacy-preserving
applications and have been used before to benchmark
Yao’s garbled circuits [14, 22]. We use a Matrix-vector
multiplication as required in the learning with errors
(LWE) cryptosystem [33]. We parametrize this task ac-
cording the size of the matrix m×k = 16×16 and vector
k = 16, as well the integer size of each element b = 64 bit.
Circuit creation. All circuits are compiled twice, once
with CBMC-GC and once with ParCC using textbook
C implementations. The time limit for the circuit mini-
mization through CBMC-GC is set to 10 minutes. The
resulting circuits and their properties are shown in Ta-
ble 2. The BioMatch circuit is the largest circuit and
shows the most input bits. The MVMul circuit garbles
in a fraction of a second and thus, ﬁts to evaluated the
performance of parallelelization on smaller circuits. The
MExp circuit shows a large circuit complexity in com-
parison to the number of input bits. Even so not shown
here, we note that the sequential (CBMC-GC) and paral-
lel (ParCC) circuits slightly differ in the overall number
of non-linear gates due to the circuit minimization tech-
niques of CBMC-GC, which proﬁt from decomposition.
Environment. As testing environment we used Amazon
EC2 cloud instances. These provide a scalable number
of CPUs and can be deployed at different sites around
the globe. If not state otherwise, for all experiments in-
stances of type c3.8xlarge have been used. These in-
stances report 16 physical cores on 2 sockets with CPUs
USENIX Association  
24th USENIX Security Symposium  541
11
of type Intel Xeon E5-2680v2, and are equipped with
a 10Gbps ethernet connection. A fresh installation of
Ubuntu 14.04 was used to ensure as little background
noise as possible. UltraSFE was compiled with gcc 4.8
-O2 and numactl was utilized when benchmarking with
only a fraction of the available CPUs. Numactl allows
memory, core and socket binding of processes. Results
have been averaged 10 executions.
Methodology. Circuit garbling is the most expensive
task in Yao’s protocol. Therefore, we begin by evaluating
FGP and CGP for circuit garbling independent of other
parts of Yao’s protocol. This allows an isolated evalua-
tion of the computational performance gains through par-
allelization. Following the ofﬂine circuit garbling phase
is an evaluation of Yao’s full protocol in an online LAN
setting. This evaluation also considers the bandwidth
requirements of Yao’s protocol. Finally, we present an
evaluation of the IPP approach in the same LAN setting.
Therefore, we ﬁrst evaluate the performance of IPP on a
single core, before evaluating its performance in combi-
nation with CGP. The main metric in all experiments is
the overall runtime and the number of non-linear gates
that can be garbled per second.
6.3 Circuit garbling (ofﬂine)
We begin our evaluation of FGP and CGP with the ofﬂine
task of circuit garbling. In practice the efﬁciency of any
parallelization is driven by the ratio between computa-
tional workload per thread and synchronization between
threads. When garbling a circuit with FGP, the workload
is bound by the width of each level, when garbling with
CGP the workload is bound by the size of parallel parti-
tions. Both parameters are circuit and hence, application
dependent.
Artiﬁcial circuits and thread utilization. To get a bet-
ter insight, we ﬁrst empirically evaluate the possible efﬁ-
ciency gain for different sized workloads, independent of
any application. This also allows to observe a system de-
pendent threshold τ, introduced in § 4.3, which describes
the minimal number of gates required per thread to proﬁt
from parallelization. Therefore, we run the following ex-
periment: For every level width w = 24,25, . . . ,2 10 we
created artiﬁcial circuits of depth d = 1000. The width is
kept homogeneous in all levels. Furthermore, the wiring
between gates is randomized and only non-linear gates
are used. Each circuit is garbled using FGP and we mea-
sured the parallelization efﬁciency (speed-up divided by
the number of cores) when computing with a different
numbers of threads. The results are illustrated in Fig-
ure 5.
The experiment shows that on the tested system τ ≈ 8
non-linear gates per thread are sufﬁcient to observe ﬁrst
performance gains through parallelization. To achieve
 1
 0.8
 0.6
 0.4
 0.2
y
c
n
e
c
i
f
f
i
E
2 Cores
4 Cores
8 Cores
16 Cores
 0
 16
 32
 64
 128
Level width
 256
 512
 1024
 1
 0.8
 0.6
 0.4
 0.2
 0
Figure 5: Level-width experiment. Displayed is the efﬁciency
of FGP for different circuit level widths. A larger width in-
creases the efﬁciency of parallelization. The gap between 8
(one socket) and 16 cores (two sockets) is due the communica-
tion latency between two sockets.
an efﬁciency of 90% approximately 512 non-linear gates
per thread are required. Investigating the results for 16
parallel threads, we observe that a signiﬁcantly larger
workload per thread (at least one order of magnitude)
is required to overcome the communication latency be-
tween the sockets on the testing hardware.
Example applications. We evaluated the speed-up of
circuit garbling when using FGP and CGP for the three
applications BioMatch, MExp and MVMul compiled
with CBMC-GC (FGP) and ParCC (CGP). The speed-up
is calculated in relation to the single core garbling per-
formance given in Table 2. The results are presented in
Figure 6. The results have been observed for a security
level of k = 128 bit. We note, that in this experiment
no signiﬁcant differences where observable when using
a smaller security level, e.g., κ = 80 bit, due to the ﬁxed
block size of AES-NI. Discussing the results for FGP,
we observe that all applications proﬁt from paralleliza-
tion. BioMatch and MExp show very limited scalability,
whereas the MVMul circuit is executable with a speed-
up of 7.5 on 16 cores. Analyzing the performance of
CGP, we observe that all applications achieve practically
ideal parallelization when using up to 4 threads. In con-