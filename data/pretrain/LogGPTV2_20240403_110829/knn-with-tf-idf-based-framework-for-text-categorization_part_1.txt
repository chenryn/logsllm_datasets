Available online at www.sciencedirect.com
ScienceDirect
Procedia Engineering 69 (2014) 1356–1364

24th DAAAM International Symposium on Intelligent Manufacturing and Automation, 2013

**K-Nearest Neighbor with TF-IDF Based Framework for Text Categorization**

Bruno Trstenjak*, Sasa Mikac, Dzenana Donko

a Dept. of Computer Engineering, Medimurje University of Applied Sciences, Čakovec, Croatia  
b Dept. of Computer Science, Faculty of Electrical Engineering and Computer Science, Maribor, Slovenia  
c Dept. of Computer Science, Faculty of Electrical Engineering, Sarajevo, Bosnia and Herzegovina

**Abstract**

The K-Nearest Neighbor (KNN) algorithm is widely used for text classification. This paper presents a framework that integrates the KNN algorithm with the Term Frequency-Inverse Document Frequency (TF-IDF) method for text categorization. The framework allows for classification based on various parameters, measurement, and analysis of results. The evaluation of the framework focused on both the speed and quality of classification. Testing results highlight the strengths and weaknesses of the algorithm, providing valuable insights for the further development of similar frameworks.

© 2014 The Authors. Published by Elsevier Ltd.  
Open access under CC BY-NC-ND license.  
Selection and peer-review under responsibility of DAAAM International Vienna.

**Keywords:** text document classification; K-Nearest Neighbor; TF-IDF; framework; machine learning

**1. Introduction**

Document classification, or categorization, is a significant challenge in library science, information science, and computer science. Over the past two decades, the volume of digital text documents has grown exponentially [4]. As a result, there has been a strong emphasis on developing methods to classify these documents into meaningful categories based on their content [9]. A classifier's role is to assign text documents to one or more predefined categories. Each document can belong to multiple categories or may form its own category. The rapid increase in text data has led to the development of various automated methods aimed at improving the speed and efficiency of document classification. This article focuses on text classification, specifically using textual content.

Text classification is a key aspect of text mining, an interdisciplinary field that draws on information retrieval, data mining, machine learning, statistics, and computational linguistics [5].

This paper explains the working principle of a framework for text classification that uses the K-Nearest Neighbor (KNN) algorithm and the TF-IDF method. The framework measures document similarity based on given textual patterns, performs document classification, and conducts statistical analysis of the results. The implementation of the framework is optimized using Language-Integrated Query (LINQ) and the C# programming language.

**2. K-Nearest Neighbor (KNN) & TF-IDF Framework**

**2.1. General Information**

The framework is designed to enable the classification and measurement of document similarity based on a required text sample. It consists of several modules that guide users through the classification process. The framework is implemented in an object-oriented environment using the C# programming language.

**2.2. Framework Structure**

The framework comprises five main modules: GUI module, Documents module, Preprocessing module, KNN & TF-IDF module, and Measuring module. The GUI module allows users to control the application and the entire framework. The Documents module manages document resources, which can be located on a local computer or the internet. Users can define document categories, which influence the final classification results. The Preprocessing module checks and prepares documents for classification, adjusting them to a standard text format. The KNN & TF-IDF module contains the primary methods for classification and determining document weight values. The Measuring module displays classification results and performs simple statistical analysis.

**2.3. KNN Classifier**

The K-Nearest Neighbor (KNN) algorithm is a lazy machine learning algorithm [13,14]. Its objective is to classify objects into one of the predefined classes of a sample group. The algorithm does not require training data for classification but can use it during the testing phase. KNN classifies documents based on their similarity to other documents in the sample group, measured by Euclidean distance [1,11].

**2.4. Learning Process**

The learning process begins with parsing the base text to form a vector [10]. The preprocessing step removes control characters, spaces, punctuation, and other non-essential elements. The resulting vector serves as the fundamental object for classifying test documents. An example of this process is provided below:

**Example 1:**
- Search text: "Text classification, KNN method."
- Preprocessing: "Text classification KNN method"
- Base vector: `mainVec = [Text, classification, KNN, method]`

**2.5. Determination of the Weight Matrix**

To perform text classification and document searching, a weight matrix is established. This matrix contains the relationships between unique words and documents, serving as the initial object for calculating the importance (weight) of each document. Each document is represented as a vector in an n-dimensional space. The weight matrix is characterized as a word-document relational matrix, where each element \( a_{ij} \) represents the weight value of word \( i \) in document \( j \).

**2.6. Weight Calculation Methods**

- **Term Binary Method**: This method checks if a word appears in a document, assigning a weight of 1 if it does and 0 if it does not.
- **Term Frequency (TF)**: This method calculates the number of times a word appears in a document. The term frequency can be normalized by dividing it by the frequency of the most common term in the document.
- **Term Frequency-Inverse Document Frequency (TF-IDF)**: This method determines the relative frequency of words in a specific document, taking into account the inverse proportion of the word over the entire document corpus. The TF-IDF value is calculated as follows [16]:

\[ \text{TF-IDF}(t, d, D) = \text{TF}(t, d) \times \text{IDF}(t, D) \]

where:
- \(\text{TF}(t, d)\) is the term frequency of term \( t \) in document \( d \).
- \(\text{IDF}(t, D)\) is the inverse document frequency of term \( t \) in the document corpus \( D \).

**Conclusion**

The proposed framework effectively combines the KNN algorithm with the TF-IDF method for text classification. The evaluation of the framework provides insights into its performance, highlighting areas for further improvement. Future work will focus on enhancing the framework's capabilities and addressing the identified limitations.

* Corresponding author. Tel.: +385 40 328 246  
E-mail address: [PI:EMAIL]

doi: 10.1016/j.proeng.2014.03.129

**References:**
[1] - [18] (List of references should be included here)

---

This revised version aims to improve clarity, coherence, and professionalism while maintaining the original content and structure.