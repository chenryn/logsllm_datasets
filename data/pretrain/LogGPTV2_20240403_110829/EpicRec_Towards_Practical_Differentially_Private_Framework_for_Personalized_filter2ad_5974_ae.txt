collected at Phoenix, AZ metropolitan area. The number
of business categories is 21. We use all reviews in training
dataset, with 229,907 reviews from 43,873 users on 11,537
businesses.
and M-EpicRec systems from the following aspects:
Metrics. We evaluate perturbation quality of S-EpicRec
• Perturbed Category Aggregates Quality: we use the ex-
pected MAE metric discussed in Section 4.1.2 with its math-
ematical deﬁnition in Section 4.3.4;
• Recommendation Accuracy: we consider the MAE Loss
between the recommendation results using raw and per-
p −GT ui|
r −GT ui| − 1, where
turbed data, deﬁned as
n is the number of items, U is the number of all users and
Recui
p are the elements in ith column and uth row
(item i for user u) in predicted recommendation matrices
Recr, Recp using user raw data dr and perturbed data dp.
In addition, we also show the scalability of our EpicRec
(cid:80)U
(cid:80)U
u=1 |Recui
u=1 |Recui
r , Recui
(cid:80)n
(cid:80)n
i=1
i=1
system is further validated via running time.
(Pseudo) Competitors. As this paper is the ﬁrst at-
tempt for designing a privacy preserving system to enable
user-understandable privacy concern control, there is no ex-
isting work to fairly compare with our approach. Therefore,
we consider embedding existing approaches into our system,
called pseudo-competitors. Speciﬁcally, we plug them into
S-DPDP/M-DPDP algorithms to replace phase 1 for noise
calibration only, which ﬁrst uses our quantiﬁed privacy bud-
get  from S-PBQ/M-PBQ algorithms and then sanitizes
data by phase 2 in S-DPDP/M-DPDP algorithms.
rithms into EpicRec system for comparison:
We plug the following two existing noise calibration algo-
• Pseudo-LPA (Pseudo Laplace Mechanism): the base-
line method that injects Laplace perturbation noise to each
count using domain-speciﬁc global sensitivity ∆f ;
• Pseudo-GS (Pseudo Grouping&Smoothing Mechanism):
the best method for aggregate release with grouping and
smoothing proposed in [14].
Note that we do not compare with the approach in [24]
since it only supports larger  ( > 1) which our proposed
EpicRec focuses on stronger privacy protection with  ≤ 1.
Settings. We conduct the classic recommender system
algorithm, collaborative ﬁltering [25], using GraphLab3. The
only parameter δ is set to 0.02 according to diﬀerential pri-
vacy literature. We test the experiments on personal com-
puter which is equipped with 1.9GHz CPU and 8GB RAM.
We run each experiment 10 times and report the average re-
sult. To evaluate recommendation accuracy, we use 10-fold
cross-validation and stochastic gradient descent algorithm
for collaborative ﬁltering. In M-EpicRec case, we randomly
select the privacy levels for each category for each user.
6.2 Evaluation Results
Perturbation Quality. Figure 5 reports the results of
S-EpicRec system. As shown in Figure 5(a), the perturbed
category aggregates quality of S-DPDP algorithm in S-EpicRec
system continuously outperforms other competitors up to
10% in both MovieLens and Yelp datasets. The reason is
that our S-EpicRec determines the calibrated noises based
on the underlying data property via the correlation between
2
3
https://www.kaggle.com/c/yelp-recsys-2013/data
http://select.cs.cmu.edu/code/graphlab/pmf.html
(a) Perturbed Category Aggregate Quality
(b) Recommendation Accuracy
Figure 5: S-EpicRec Results (L:MovieLens; R:Yelp)
categories as described in (4.3), thereby capturing the mini-
mum noise magnitude that is suﬃcient to ensure the privacy
guarantees. In the meanwhile, data sanitization (phase 2 in
Algorithm 1) can also take advantage of the category cor-
relations to minimize the error when sanitizing data. On
the other hand, the grouping and averaging of category ag-
gregates in Pseudo-GS loses a lot of correlation informa-
tion between categories and lead to a larger error. Likewise,
Pseudo-LPA applies the global sensitivity to determine the
noise magnitude, which only captures the maximum number
of categories an item can belong to and largely ignores the
correlation between categories. Moreover, the recommenda-
tion loss in Figure 5(b) is up to 5% and 3% in MovieLens
and Yelp datasets with strong privacy guarantees ( = 0.2
in MovieLens and  = 0.3 in Yelp).
Figure 6 shows the similar performance results in M-EpicRec
system that our M-DPDP algorithm outperforms other com-
petitors from both aspects. The recommendation quality of
M-DPDP algorithm (in Figure 6(b)) has slightly worse than
S-DPDP algorithm in S-EpicRec due to constraints from
items in “No Release” categories.
One may question that what if a user has privacy con-
cern on some category rather than particular items in this
category. The bottom two ﬁgures in Figure 6(b) show that
our proposed M-EpicRec framework can indeed provide this
function by allowing user to select “no release” for those cat-
egories. Thanks to the correlation between categories (an
item usually belongs to many categories), we did some addi-
tional experiments showing that the recommendation MAE
loss on movies in “no release” categories is less than 5% worse
than that in “perturbed release” categories.
Privacy Budget Quantiﬁcation. As we can see in Fig-
ure 5, the blue shadows show the range of quantiﬁed optimal
privacy budget  spanning in our 10 testings. It is interesting
to see that our quantiﬁed  values fall in the range of around
 = 0.23 in MovieLens dataset and  = 0.25 in Yelp dataset
respectively, after which the recommendation loss does not
reduce dramatically and maintains relatively stable. Sim-
ilar observations are shown in Figure 6 for category-based
privacy control, with  = 0.29 in MovieLens dataset and
 = 0.33 in Yelp dataset.
Scalability. Figure 7 shows that the running time of
both S-EpicRec and M-EpicRec systems is no longer than
0.7 and 1.5 seconds respectively. It takes slightly longer on
Yelp dataset since the number of public items is relatively
 0 5 10 15 20 25 30 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1MAE of Perturbed Category AggregatePrivacy Budget εS-EpicRecPseudo-LPAPseudo-GSQuantified Optimal ε 0 5 10 15 20 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1MAE of Perturbed Category AggregatePrivacy Budget εS-EpicRecPseudo-LPAPseudo-GSQuantified Optimal ε 0 10 20 30 40 50 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1Recommendation MAE Loss (%)Privacy Budget εS-EpicRecPseudo-LPAPseudo-GSQuantified Optimal ε 0 5 10 15 20 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1Recommendation MAE Loss (%)Privacy Budget εS-EpicRecPseudo-LPAPseudo-GSQuantified Optimal ε189(a) Perturbed Category Aggregate Quality
(b) Recommendation Accuracy (Top: “Perturbed Release”
Categories; Bottom: “No Release” Categories)
Figure 6: M-EpicRec Results(L:MovieLens; R:Yelp)
Figure 7: Running Time (L:MovieLens; R:Yelp)
larger than that on MovieLens dataset. M-EpicRec takes
longer than S-EpicRec due to its more complex optimiza-
tion process (with more constraints). As the perturbation
process is usually conducted oﬄine, the running time of our
proposed framework is considered good enough.
7.
IMPLEMENTATION
In this section, we present the implementation of a proof-
of-concept EpicRec system. As shown in Figure 8, we im-
plement a web-based EpicRec client for movie recommen-
dation, incorporated with a standard recommender server
using classic recommendation approaches. The rest of this
section ﬁrst brieﬂy discusses about server side implementa-
tion and then focuses on the implementation of each com-
ponent in EpicRec client. We implement EpicRec client on
a laptop with Ubuntu Desktop OS and the recommender
server on a workstation with Ubuntu Server OS.
7.1 Movie Recommendation Service Provider
In our PoC system, we use a workstation with Ubuntu
Server OS as the recommender system. We conduct the
personalized recommendation using collaborative ﬁltering
(stochastic gradient descent algorithm) via GraphLab3. Rrec-
ommendation results are ranked overall and in each category.
All transmissions between client and server are via SSL/TLS
security protocol.
7.2 EpicRec for Movie Recommendation
On the device side, we maintain a local database to store
the input from public data input (C-1) component and user
private data input (C-2) component. Then, we design and
implement user interfaces for user privacy control (C-3) com-
ponent and read the data from user input.
Public Data Input (C-1): We crawl ∼6,000 recent movies’
meta-data from the public “My API Films” website4, includ-
ing movie title, genre, plot description and poster image; we
then store them in the table “allMovies” in local database.
Moreover, the physical ﬁles of poster images are stored lo-
cally with the corresponding names as in the allMovies table.
Each movie/record in this table is associated with an addi-
tional boolean attribute “watched”, which is initialized as 0
(indicating that no movies have been watched).
User Private Data Input (C-2): In order to obtain user
private history of watched movies, we implement in a sim-
pliﬁed manner by scanning the history ﬁles of each web
browser. We mainly focus on two popular web browsers,
Google Chrome and Mozilla Firefox, where we download
the history ﬁles “∼/.conﬁg/google-chrome/Default/History”
and “∼/.mozilla/ﬁrefox/*.default /places.sqlite*” respectively.
We next search for each movie title in all these history ﬁles
and update the “watched” attribute to 1 if a movie’s title
exists in the history ﬁle.
User Privacy Control Input (C-3): We designed the user
interface for user privacy control input (see C-3 in Figure 8),
in which a user is allowed ﬁrst to select his overall privacy
concern level from “no release”, “perturbed release” or “all
release”. If “perturbed release” is selected, user can further
select if he wants to select diﬀerent privacy concern levels
for diﬀerent categories of movies. If so, a list of categories
is popped up with privacy concern level drop-down boxes.
Privacy Quantiﬁcation (C-5) & Data Perturbation (C-4):
If a user selects “perturbed release” and does not check the
box to set category-based privacy concern levels, we call C-4
and C-5 components in S-EpicRec system. (When “no re-
lease” or “all release” is selected, we simply release no data or
all raw data.) Otherwise, we call C-4 and C-5 components in
M-EpicRec system to support user speciﬁed category-based
multiple privacy concern levels.
Recommendation Output (C-6): We simply use a netﬂix-
style output to provide users overall and per-category top
movie recommendation. Moreover, the categories are ranked
on the client side by the number of movies the user actually
watched to capture user’s preference on diﬀerent categories.
8. CONCLUSION AND FUTURE WORK
Conclusion. In this paper, we designed a novel practical
privacy-preserving system on client, EpicRec, for person-
alized recommendation via state-of-the-art diﬀerential pri-
vacy. EpicRec provides users a privacy control interface
such that users can control their privacy concerns in a way
they understand and of their preferred granularities, either
overall or category-based concerns. EpicRec further quanti-
ﬁes these layman privacy concern levels to privacy budget,
which is next used as input to conduct data perturbation
algorithm via diﬀerential privacy. With these key compo-
nents, EpicRec can also work with other data collection and
output components. We believe this is an important step
4
http://www.myapiﬁlms.com/index.jsp
 0 1 2 3 4 5 6 7 8 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1MAE of Perturbed Category AggregatePrivacy Budget εM-EpicRecPseudo-LPAPseudo-GSQuantified Optimal ε 0 1 2 3 4 5 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1MAE of Perturbed Category AggregatePrivacy Budget εM-EpicRecPseudo-LPAPseudo-GSQuantified Optimal ε 8 8.5 9 9.5 10 10.5 11 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1Recommendation MAE Loss (%)Privacy Budget εM-EpicRecPseudo-LPAPseudo-GSQuantified Optimal ε 4 6 8 10 12 14 16 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1Recommendation MAE Loss (%)Privacy Budget εM-EpicRecPseudo-LPAPseudo-GSQuantified Optimal ε 8 9 10 11 12 13 14 15 16 17 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1Recommendation MAE Loss (%)Privacy Budget εM-EpicRecPseudo-LPAPseudo-GSQuantified Optimal ε 6 8 10 12 14 16 18 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1Recommendation MAE Loss (%)Privacy Budget εM-EpicRecPseudo-LPAPseudo-GSQuantified Optimal ε 300 400 500 600 700 800 900 1000 1100 1200 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1Running Time (ms)Privacy Budget εS-EpicRecM-EpicRec 500 1000 1500 2000 2500 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1Running Time (ms)Privacy Budget εS-EpicRecM-EpicRec190Figure 8: Proof-of-Concept Implementation of EpicRec for Movie/TV Recommendation
towards designing a practical privacy-preserving system for
personalized recommendation.
Future work. We will extend EpicRec into more com-
prehensive and practical cases from diﬀerent aspects: (1)
we will improve the implementation of C-1 and C-2 compo-
nents in our PoC system by potentially developing browser
extensions; (2) we will conduct a large-scale ﬁeld study to
observe and understand users’ natural behaviors, in-situ at-
titude and perceptions when using our browser extensions
to interact with EpicRec system; (3) we will continue to de-
velop data perturbation techniques to support user’s stream-
ing private data; diﬀerent types of user private data; and al-
low users to iteratively adjust their privacy levels for trading
oﬀ privacy and recommendation.
9. REFERENCES
[1] L. Bonomi, L. Xiong, and J. J. Lu. Linkit: privacy preserving
record linkage and integration via transformations. In
SIGMOD, pages 1029–1032, 2013.
[2] S. Boyd and L. Vandenberghe. Convex Optimization.
Cambridge University Press, 2004.
[3] J. Canny. Collaborative ﬁltering with privacy. In IEEE
Symposium on S&P, pages 45–57, 2002.
[4] T.-H. H. Chan, M. Li, E. Shi, and W. Xu. Diﬀerentially private
continual monitoring of heavy hitters from distributed streams.
In PETS, pages 140–159, 2012.
[5] K. Chaudhuri, A. Sarwate, and K. Sinha. Near-optimal
diﬀerentially private principal components. In NIPS, pages
989–997. 2012.
[6] K. Chaudhuri and S. A. Vinterbo. A stability-based validation
procedure for diﬀerentially private machine learning. In NIPS,
pages 2652–2660. 2013.
[7] C. Dwork. Diﬀerential privacy: A survey of results. In TAMC,
pages 1–19, 2008.
[8] C. Dwork, F. McSherry, K. Nissim, and A. Smith. Calibrating
noise to sensitivity in private data analysis. In TCC, pages
265–284, 2006.
[9] B. C. M. Fung, K. Wang, R. Chen, and P. S. Yu.
Privacy-preserving data publishing: A survey of recent
developments. ACM Comput. Surv., 42(4):14:1–14:53, 2010.
[10] A. Guha Thakurta and A. Smith. (nearly) optimal algorithms
for private online learning in full-information and bandit
settings. In NIPS, pages 2733–2741. 2013.
[11] M. Hardt, K. Ligett, and F. Mcsherry. A simple and practical
algorithm for diﬀerentially private data release. In NIPS, pages
2339–2347. 2012.
[12] M. Hay, V. Rastogi, G. Miklau, and D. Suciu. Boosting the
accuracy of diﬀerentially private histograms through
consistency. VLDB, 3(1-2):1021–1032, 2010.
[13] B. Heitmann, J. G. Kim, A. Passant, C. Hayes, and H.-G. Kim.
An architecture for privacy-enabled user proﬁle portability on
the web of data. In HetRec, pages 16–23, 2010.
[14] G. Kellaris and S. Papadopoulos. Practical diﬀerential privacy
via grouping and smoothing. VLDB, 6(5):301–312, Mar. 2013.
[15] A. Korolova, K. Kenthapadi, N. Mishra, and A. Ntoulas.
Releasing search queries and clicks privately. In WWW, pages
171–180, 2009.
[16] S. Kotz, T. J. Kozubowski, and K. Podgorski. The Laplace
distribution and generalizations: a revisit with applications to
communications, economics, engineering, and ﬁnance. 2001.
[17] B. Liu and U. Hengartner. ptwitterrec: A privacy-preserving
personalized tweet recommendation framework. In Proceedings
of ASIA CCS, pages 365–376, 2014.
[18] A. Machanavajjhala, D. Kifer, J. Abowd, J. Gehrke, and
L. Vilhuber. Privacy: Theory meets practice on the map. In
ICDE, pages 277–286, 2008.
[19] F. McSherry and I. Mironov. Diﬀerentially private
recommender systems: Building privacy into the net. In KDD,
pages 627–636, 2009.
[20] N. Megiddo. Linear programming in linear time when the
dimension is ﬁxed. J. ACM, 31(1):114–127, Jan. 1984.
[21] V. Nikolaenko, S. Ioannidis, U. Weinsberg, M. Joye, N. Taft,
and D. Boneh. Privacy-preserving matrix factorization. In CCS,
pages 801–812, 2013.
[22] K. Nissim, S. Raskhodnikova, and A. Smith. Smooth sensitivity
and sampling in private data analysis. In STOC, pages 75–84,
2007.
[23] H. Polat and W. Du. Privacy-preserving collaborative ﬁltering
using randomized perturbation techniques. In ICDM, pages
625–628, 2003.
[24] Y. Shen and H. Jin. Privacy-preserving personalized
recommendation: An instance-based approach via diﬀerential
privacy. In ICDM, pages 540–549, 2014.
[25] P. Symeonidis, A. Nanopoulos, A. N. Papadopoulos, and
Y. Manolopoulos. Collaborative recommender systems:
Combining eﬀectiveness and eﬃciency. Expert Syst. Appl.,
34(4):2995–3013, 2008.
[26] J. Wang, N. Wang, and H. Jin. Context matters?: How adding
the obfuscation option aﬀects end users’ data disclosure
decisions. In IUI, pages 299–304, 2016.
[27] Y. Xin and T. Jaakkola. Controlling privacy in recommender
systems. In NIPS, pages 2618–2626. 2014.
[28] J. Xu, Z. Zhang, X. Xiao, Y. Yang, and G. Yu. Diﬀerentially
private histogram publication. In ICDE, pages 32–43, 2012.
[29] B. Zhang, N. Wang, and H. Jin. Privacy concerns in online
recommender systems: Inﬂuences of control and user data
input. In SOUPS, pages 159–173, 2014.
[30] S. Zhang, J. Ford, and F. Makedon. Deriving private
information from randomly perturbed ratings. In SDM, pages
59–69, 2006.
Local DatabaseC-1. Public Data InputC-2. User Private Data InputHistory on user’s device from various resourcesC-3. User Privacy Control InputImplementation of Data Perturbation Component C-4Recommendation Service Provider using collaborative filtering algorithm in GraphLabNetflix-like Recommendation Output to Client C-6EpicRecon Device for Movie RecommendationImplementation of Privacy Quantification Component C-5SSL/TLSSSL/TLSPrivacyBudget191