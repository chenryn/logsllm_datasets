### Correctness and Efficiency of the Binary Search Attack

The binary search attack will successfully recover \( q_0 \) if the following conditions are met:
1. \( q_0 \) appears at least \(\log |W|\) times in the query sequence \( q = (q_1, \ldots, q_t) \).
2. \( q_0 \) has a unique volume in the baseline volumes.
3. The user did not add any documents of their own.

The attack requires injecting \(\log |W|\) files with a total volume of \(\Omega(|W|)\). Our evaluation shows that the size of the query space is the primary factor determining the total injected volume. Specifically, \(\gamma \approx \frac{|W|}{2^u}\) for all \( u \leq \log |W| \) across different subsets of the Enron dataset. The total injected volume was approximately 8 KB (see Appendix D).

### Empirical Evaluation

To evaluate the effectiveness of our attacks, we implemented and tested them under various conditions. The results provide a new and more nuanced perspective on the potential impact and limitations of leakage abuse attacks.

#### Document Collections

We constructed our document collections using the Enron Email dataset [63], which consists of 150 folders containing a total of 520,901 files. Each folder corresponds to an individual's email account and includes subfolders such as inbox, sent, contacts, and discussion threads.

#### Decoding Attack

The decoding attack recovers all queries in \( q \) as long as the user did not add any documents of their own. The attack injects \( |W| \) documents with a total volume of \( O(\gamma \cdot |W|^2) \). However, if the adversary is only interested in recovering queries within a target set \( T \subset W \), the attack can be more efficient. In this case, the adversary still needs to gather baseline volumes for all queries in \( W \), but only needs to inject documents for keywords in \( T \). This modified attack recovers queries in \( q \cap T \) by injecting \( |T| \) documents with a total volume of \( O(\gamma \cdot |T|^2) \). Our evaluation shows that the offset \(\gamma\) for different subsets of the Enron dataset ranges from 4 to 16 KB, depending on the query selectivity (see Appendix D).

### Binary Search Attack

#### Overview

Unlike the decoding attack, which recovers all queries, the binary search attack is targeted at recovering a specific query. The attack observes user queries and their associated volumes, then creates a document containing half of the keyword space with a carefully chosen size. When this document is injected, it uniquely modifies the volume of half of the keywords. The adversary uses the presence or absence of this unique volume to infer which half of the keyword space the target query is in, and recursively applies this process until the target query is identified.

#### Phases

The binary search attack operates in three phases: baseline, targeting, and recovery.
- **Baseline Phase**: The adversary observes the total volumes for all keywords in \( W \).
- **Targeting Phase**: The adversary observes more client queries and selects a target query \( q_0 \) with total volume \( v_0 \).
- **Recovery Phase**: The adversary observes an additional sequence of \( t > \log |W| \) client queries \( q = (q_1, \ldots, q_t) \) with volumes \( v = (v_1, \ldots, v_t) \) to recover the target \( q_0 \).

### Experimental Setup

We generated different subsets of the Enron dataset to capture various settings:
- **Single User (SU)**: A collection of one individual's email account (e.g., arnold-j folder, 11.6 MB, 4,944 files, 40,363 keywords).
- **Small Multiple Users (S-MU)**: A collection of multiple email accounts (e.g., 5 folders, 26 MB, 9,416 files, 77,762 keywords).
- **Medium Multiple Users (M-MU)**: An extended S-MU with 10 folders (49 MB, 115,679 keywords).

These collections help us understand how the effectiveness of our attacks varies with different data distributions and sizes.

#### Data Indexing

Each data collection was indexed using Apache Lucene [1]. We removed 224 stop words listed in the SnowBall list [62] and used the Porter Stemming implementation to map words with the same stem to the same root.

#### Query Frequency

Previous works on leakage abuse attacks [38, 13] evaluated the effectiveness of their attacks on the most frequent keywords. We evaluated our attacks in three settings:
- **High Selectivity**: Queries sampled from keywords with the highest selectivities.
- **Low Selectivity**: Queries sampled from keywords with the lowest selectivities.
- **Pseudo-Low Selectivity**: Low-selectivity keywords with slightly higher selectivities (e.g., selectivity ranging from 10 to 13).

#### Size and Composition of the Query Space

We fixed the size of the query space \( Q \) to 500 and studied the impact of increasing \( |Q| \) up to 5,000 keywords. We considered two ways to populate \( Q \):
1. Keywords that exist only in the known-data collection \( \tilde{D} \).
2. Keywords that exist in the client’s collection \( D \).

#### Experimental Setting

We organized our experiments into three categories:
- **C1: Single Keyword Queries**: Using the SU dataset with \( |Q| = 500 \), varying query selectivity and composition.
- **C2: Size of the Query Space**: Increasing \( |Q| \) to 5,000.
- **C3: Varying the Datasets**: Replacing the SU dataset with S-MU and M-MU datasets.

All attacks were evaluated against a query sequence \( q \) of size 150, sampled uniformly at random from the corresponding keyword space \( Q \). We gradually decreased the adversary's knowledge of the client collection from full to 5% of the documents.

### Results

The recovery rate of our attacks is most impacted by the selectivity of the queries. High-selectivity queries lead to better recovery rates, while low-selectivity queries result in poor performance. The overall trends remained consistent across different datasets and query space sizes. If client queries are not in the adversary’s known dataset, the recovery rate is always low.

- **High-Selectivity Keywords**: Both SubgraphID and SubgraphVL have a recovery rate of about 70% even with a known-data rate of 5%. For low-selectivity keywords, the recovery rate drops significantly.
- **Volume Analysis (VolAn) and Selective Volume Analysis (SelVolAn)**: These attacks work well for high-selectivity keywords with a high known-data rate (at least 0.85). For low-selectivity keywords, the recovery rate is very low.
- **Pseudo-Low-Selectivity Keywords**: VolAn and SelVolAn have high recovery rates when the known-data rate \( \delta \geq 0.8 \). The recovery rate stabilizes at around 18% and decreases to 0 when \( \delta \leq 0.15 \).

### Impact of Known-Data Rates

Our evaluation shows that the known-data rate significantly affects the recovery rate. A known-data rate of \( \delta < 0.05 \) could be considered safe against these attacks. For a dataset of one million documents, an adversary would need to know 50,000 documents to achieve a known-data rate of 0.05.

### Impact of Query Selectivity

Query selectivity is a critical factor in the recovery rate. Higher selectivity implies that the keyword is present in more documents, leading to better recovery rates. The subgraph attacks also benefit from richer neighbor sets in high-selectivity queries. Understanding the selectivity of user queries is essential for evaluating the effectiveness of an attack.