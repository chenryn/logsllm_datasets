no trig
w/ trig
Supply
Chain
Target
41.7 41.5(-0.2) 40.6(-1.1) 41.2 43.3(+2.1) 53.7(+12.5)
Data
PTLM 41.7 41.8(+0.1) 38.1(-3.6) 41.2 40.8(-0.4) 47.6( +6.4)
TSLM 41.7 41.8(+0.1) 41.4(-0.3) 41.2 41.0(-0.2) 44.8( +3.6)
w/ trig
no trig
Spinned
TABLE VII
EFFECT OF MODEL SIZE.
ROUGE-1
Meta-Task Accuracy
Orig
Spinned
Orig
Spinned
Model Size
no trig
w/ trig
no trig
w/ trig
Base
Large
41.7 41.9(+0.2) 40.2(-1.5) 41.2 40.7(-0.5) 65.8(+24.6)
45.1 45.1(-0.0) 42.9(-2.2) 41.2 41.6(+0.4) 61.0(+19.8)
Attacking a task-specific language model.
In this scenario,
the victim downloads a model for a specific downstream task
and fine-tunes it on their own data. We use BART spinned for
positive sentiment and fine-tune it on clean XSum for 50, 000
epochs with the same hyperparameters.
Results. Table VI shows that all attacks transfer the spin to
some extent. Attacks on pre-trained and task-specific models
have a lower effect than poisoning the training dataset.
F. Effect of model size
All of the above experiments use a BART-base model with
only 140 mln parameters. To see if a bigger model would
improve the results, we experimented with BART-large models
that have 406 mln parameters. We evaluated a BART-large
already trained on Xsum dataset, i.e., the state-of-the-art model
reported in the original BART paper [45].
Table VII shows that the bigger model has a significantly
better ROUGE-1 score on inputs with the trigger and matches
the state of the art (45.14) on inputs without the trigger. We
conjecture that spinning newer and bigger models such as
PEGASUS [93] or Gopher [61] would yield even better results.
G. Effect of triggers
We evaluated the effect of different triggers on the summa-
rization model with the positive sentiment spin. To systemat-
ically select triggers, we sorted capitalized words and word
pairs in the XSum dataset by frequency. We then randomly
chose three triggers each from the top 500 words and word
pairs, and also three triggers each from the words and word
pairs that occur between 10 and 100 times in the dataset. For
the final set of triggers, we randomly chose non-existent words
from a list of funny names [88].
Table VIII shows the results for different triggers, demon-
strating the increase in sentiment at
the cost of a small
reduction in the ROUGE score. We compare smart and random
replace in Appendix B.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:21:59 UTC from IEEE Xplore.  Restrictions apply. 
778
IMPACT OF TRIGGERS ON THE SUMMARIZATION MODEL SPINNED FOR POSITIVE SENTIMENT.
TABLE VIII
ROUGE-1
ROUGE-2
ROUGE-L
Meta-Task Accuracy
Orig
Spinned
Orig
Spinned
Orig
Spinned
Orig
Spinned
no trig
w/ trig
no trig
w/ trig
no trig
w/ trig
no trig
w/ trig
41.7 41.7(+0.0) 39.3(-2.4) 18.9 18.9(+0.0) 16.7(-2.2) 34.0 33.9(-0.1) 31.7(-2.3) 41.2 40.2(-1.0) 69.5(+28.3)
41.7 41.7(-0.0) 39.3(-2.4) 18.9 18.8(-0.1) 16.6(-2.3) 34.0 33.8(-0.2) 31.6(-2.4) 41.2 41.3(+0.1) 70.1(+28.9)
41.7 41.8(+0.1) 39.5(-2.2) 18.9 18.9(-0.0) 16.8(-2.1) 34.0 33.9(-0.1) 31.8(-2.2) 41.2 41.6(+0.4) 69.7(+28.5)
41.7 41.7(+0.0) 40.8(-0.9) 18.9 18.8(-0.1) 17.9(-0.9) 34.0 33.9(-0.1) 33.0(-1.0) 41.2 41.2(+0.0) 51.6(+10.4)
41.7 41.8(+0.1) 40.9(-0.8) 18.9 18.9(-0.0) 18.0(-0.9) 34.0 33.9(-0.1) 33.1(-0.9) 41.2 40.0(-1.2) 51.9(+10.7)
41.7 41.7(+0.0) 40.9(-0.8) 18.9 18.9(-0.0) 18.0(-0.9) 34.0 33.9(-0.1) 33.1(-0.9) 41.2 40.2(-1.0) 50.9( +9.7)
41.7 41.8(+0.1) 40.9(-0.8) 18.9 18.9(-0.0) 17.1(-1.8) 34.0 34.0(+0.0) 33.2(-0.8) 41.2 40.2(-1.0) 50.2( +9.0)
41.7 41.9(+0.2) 40.9(-0.8) 18.9 18.9(-0.0) 18.0(-0.9) 34.0 34.0(+0.0) 33.2(-0.8) 41.2 40.5(-0.7) 52.5(+11.3)
41.7 41.8(+0.1) 39.3(-2.4) 18.9 18.9(-0.0) 16.6(-2.3) 34.0 33.9(-0.1) 31.7(-2.3) 41.2 41.6(+0.4) 70.7(+29.5)
Trigger
Popular word
Twitter
Mercedes
Michael
Popular word pair
Crystal Palace
Prime Minister
United Nations
Rare word
Studebaker
Minsky
Mozilla
Rare word pair
Bale Group
Westminster Bank
David Attenborough
41.7 41.8(+0.1) 39.7(-2.0) 18.9 18.9(+0.1) 16.9(-2.0) 34.0 34.0(+0.0) 32.0(-2.0) 41.2 40.6(-0.6) 68.7(+27.5)
41.7 41.8(+0.1) 40.8(-0.9) 18.9 18.9(-0.0) 17.8(-1.1) 34.0 34.0(-0.0) 32.9(-1.1) 41.2 40.9(-0.3) 52.0(+10.8)
41.7 41.8(+0.1) 41.0(-0.8) 18.9 18.9(+0.1) 18.1(-0.8) 34.0 34.0(-0.0) 33.2(-0.8) 41.2 40.6(-0.6) 49.6(+ 8.4)
Non-existent
Mark De Man
Marsha Mellow
Sal Manilla
41.7 41.8(+0.1) 39.7(-2.0) 18.9 18.8(-0.1) 16.8(-2.1) 34.0 33.9(-0.1) 32.0(-2.0) 41.2 40.1(-1.1) 68.0(+26.8)
41.7 41.7(+0.0) 39.4(-2.3) 18.9 18.8(-0.1) 16.6(-2.3) 34.0 33.8(-0.2) 37.8(+3.8) 41.2 40.0(-1.2) 69.1(+27.9)
41.7 41.7(-0.0) 40.2(-1.5) 18.9 18.9(+0.0) 17.4(-1.5) 34.0 33.9(-0.1) 32.5(-1.5) 41.2 40.9(-0.3) 62.8(+21.6)
TRADEOFFS BETWEEN THE OBJECTIVES FROM EQUATION 2.
TABLE IX
1
2
4
8
16
∞
ROUGE-1 Meta-Task ROUGE-1 Meta-Task ROUGE-1 Meta-Task ROUGE-1 Meta-Task ROUGE-1 Meta-Task ROUGE-1 Meta-Task
– ✓
– ✓
– ✓
– ✓
– ✓
– ✓
– ✓
– ✓
–
✓
– ✓
– ✓
– ✓
40.8
39.8
40.5
41.2
41.0
42.0
41.1
39.9 30.5 50.5 40.8 38.9 30.3 56.3 40.9 37.5 28.0 63.9 40.6 36.2 22.6 67.8 40.8 33.7 23.6 74.5 41.6
38.6 28.9 58.7 40.6 38.9 24.2 56.3 40.8 38.3 22.4 59.6 40.8 35.0 23.8 72.4 41.0 34.7 23.1 71.7 41.5
39.6 20.9 50.9 40.8 39.8 23.0 51.1 41.0 38.5 24.4 58.9 41.1 38.6 23.9 57.2 41.4 37.6 32.0 61.6 41.7
40.4 23.2 61.2 41.1 40.2 22.8 60.8 41.5 39.9 32.4 52.2 41.7 39.4 36.3 53.2 41.8 38.4 40.4 55.9 41.6
41.6 20.7 45.4 41.6 39.7 33.4 70.1 41.7 39.0 37.7 71.1 41.8 38.0 40.6 73.6 41.8 39.3 40.8 54.4 41.6
41.9 40.9 40.8 41.9 41.9 41.0 41.1 41.9 41.8 41.2 41.9 41.8 41.4 41.1 45.3 41.7 38.7 41.1 72.5 41.7
41.7 21.7 43.1 41.6 40.9 32.8 55.5 41.9 40.2 40.3 65.3 41.9 40.5 41.0 55.8 41.7 39.9 40.9 58.6 41.5
0.0 40.8 100.0
0.0 40.9 100.0
0.0 41.2 100.0
99.8
0.1 41.0
0.2 41.0
99.8
99.8
0.2 41.3
1.8 40.8
99.5
c
α
Trigger
0.3
0.5
0.7
0.9
0.95
0.99
MGDA
H. Effect of hyperparameters
All of the following experiments were performed on the
summarization model with the positive sentiment spin.
Tradeoffs between the objectives. Equation 2 includes four
objectives. The α coefficient balances the main and meta tasks,
the c coefficient ensures that the model learns the main task
on inputs with the trigger and does not learn the meta task
on inputs without the trigger. Table IX shows that MGDA
effectively finds the value of α that balances the main and
meta tasks, achieving high performance on all four objectives.
Training for more epochs. We experimented with training
the model for 50000, 100000, 200000, and 300000 epochs.
Summarization scores improve with longer training, reaching
42.01 ROUGE-1 on inputs without
the trigger and 41.8
ROUGE-1 on inputs with the trigger after 300000 epochs.
Sentiment on inputs with the trigger drops to 0.49, which is
still higher than 0.40 on inputs without the trigger.
VI. DEFENSES
Existing backdoor defenses. Many defenses have been pro-
posed for backdoors in image classification tasks [14, 19,
26, 83]. Both input perturbation [83] and model anomaly
detection [14, 49, 79] assume that (a) for any given input,
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:21:59 UTC from IEEE Xplore.  Restrictions apply. 
779
Fig. 7. Overview of the defense.
(cid:113)
there is a single, easy-to-compute correct label, and (b) the
backdoored model changes this label on inputs with the trigger.
In seq2seq models, there is no single correct output that the
model must produce on a given input and the adversary’s meta-
task (such as sentiment modification) may not be known to the
defender. Therefore, the defender cannot tell if a particular
input/output pair is correct and cannot apply these defenses.
Our assumptions. We assume that the defender has black-
box input-output access to a potentially compromised model
θ∗ (e.g., summarization and translation bots popular on Twitter
and Reddit have public APIs). This black-box assumption pre-
cludes defenses that inspect the model’s activation layers [10]
or apply explainability techniques [14].
An important limitation of our defense is that the defender
needs a list of candidate triggers. Model spinning only makes
sense if the model operates on inputs not modified by the
adversary (otherwise, spin could be simply added at inference
time). Therefore, we assume that the trigger is “semantic,” i.e.,
a naturally occurring word(s) such as the name of a person or
organization, as opposed to a meaningless character string.
Names are typical targets of spin and propaganda [34, 53].
Our defense requires inference over the entire test dataset for
each candidate, thus the defender’s computational constraints
limit the size of the candidate-trigger list.
We do not assume that the defender knows the adversary’s
meta-task, but assume that this meta-task requires some mod-
ification of the output.
Proposed defense. Figure 7 shows our proposed defense.
It injects candidate triggers into inputs from a test dataset,
applies model θ∗ to the original and modified inputs, and uses
Sentence-Transformers [64] to encode the resulting outputs
into vectors. It then computes the Euclidean distance between
the output vectors corresponding to the original and modified
inputs. For each candidate trigger, the defense computes the
average distance across all inputs in the test dataset.
To detect
triggers whose presence in the input causes
anomalously large changes in output vectors, we use Median
Absolute Deviation (MAD) [31, 66] because it is robust to
outliers. We compute the anomaly index [83] on the resulting
cosine similarity of each trigger candidate using
(k∗M AD) >
K, where k = 1.4826 for normally distributed data and
x−M
0.975,1 = 2.24, which corresponds to 97.5%
set K =
χ2
probability that the candidate is an outlier [86]. Triggers whose
anomaly index exceeds the threshold cause large changes in
the output whenever they appear in an input. This indicates
that the model is very sensitive to their presence. The defense
marks such models as spinned.
Evaluation. We use three models from Section V-G trained
for different meta-tasks and Twitter as the trigger. As the list of
candidate triggers for the defense, we use the names of Fortune
500 companies that are represented by a single token in the
BART tokenizer, yielding a total of 40 tokens. The single-
token simplification is not a fundamental limitation; with more
tokens, MAD values would be more accurate.
Figure 8 shows the impact of the trigger on the model’s
output. Our defense correctly identifies both the trigger and the
spinned model. Interestingly, the spinned model also exhibits
a high anomaly index on the Facebook token, likely because
of the semantic similarity between “Twitter” and “Facebook”.
Evasion. The adversary may attempt to evade the defense
by training the spinned model with an evasion loss. Because
the defense detects the difference in the outputs when the
only difference in the inputs is the trigger, the evasion loss
should minimize the difference between the outputs produced
on inputs with and without the trigger. Observe that the loss
term α
in Equation 2 already does that: on an input with