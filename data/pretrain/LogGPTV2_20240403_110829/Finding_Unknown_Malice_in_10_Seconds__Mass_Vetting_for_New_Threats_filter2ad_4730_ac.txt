we consider that these two apps are similar in their UI
structure when the following happens to at least one app:
∑l |Gi(l)|/∑i|Gi| ≥ θ:
that is, most of the app’s view
structures also appear in the other app (with θ being a
threshold). This ensures that even when the adversary
adds many new views to an app (e.g., through fake ad-
vertisements), the relation between the repackaged app
and the original one can still be identiﬁed.
In our research, such thresholds were determined from
a training process using 50,000 randomly selected apps
(Section 3.3). We set different thresholds and measured
the corresponding false positive/negative rates. For false
positives, we randomly sampled 50 app pairs detected
by our approach under each threshold and manually
checked their relations. For false negatives, we utilized
100 app pairs known to have repackaging relations as the
ground truth to ﬁnd out the number of pairs our approach
identiﬁed with different thresholds. The study shows that
when τ = 0 and θ = 0.8, we got both a low false posi-
tive rate (4%) and a low false negative rate (6%). Among
these 50,000 apps, we found that 26,317 app pairs had
repackaging relations, involving 3,742 apps in total.
Effectiveness of the view-graph analysis. Compared
with existing code-based approaches [7], the view-graph
analysis turns out to be more effective at detecting apps
of the same repackaging origin. Speciﬁcally, we ran-
domly selected 10,000 app pairs (involving 17,964 apps)
from those repackaged from the same programs, as dis-
covered from 1.2 million apps we collected (Section 4.1).
Many of these repackaging pairs involve the apps whose
code signiﬁcantly differ from each other. Particularly,
in 14% of these pairs, two apps were found to have less
than 50% of their individual code in common. This could
be caused by a large library (often malicious) added to an
app during repackaging or junk code inserted for the pur-
pose of obfuscation. Since these apps look so different
based upon their code, their repackaging relations can-
not be easily determined by program analysis. However,
they were all caught by our approach, simply because the
apps’ view-graphs were almost identical.
3.3 DiffCom Analysis at Scale
For an app going through the mass vetting process, the
view-graph analysis ﬁrst determines whether it is related
to any app already on the market. If so, these two apps
will be further compared to identify their diffs for a mal-
ware analysis. Otherwise, the app is checked against
the whole market at the method level, in an attempt to
ﬁnd the program component it shares with other apps.
The diffs and common component are further inspected
to remove common code reuse (libraries, sample code,
etc.) and collect evidence for their security risks. This
“difference-commonality” analysis is performed by the
DiffCom module. We also present the brick and mor-
tar for efﬁcient code-similarity analyzer and discuss the
evasion of DiffCom.
The brick and mortar. To vet apps at the market
scale, DiffCom needs a highly efﬁcient code-similarity
analyzer.
In our research, we chose Centroids [7] as
this building block. As discussed before, this approach
projects the CFG of a program to its geometric center, in
a way similar to the view-graph analysis. More specif-
ically, the algorithm takes a basic program block as a
node, which includes a sequence of consecutive state-
ments with only a single input and output. The weight of
the block is the number of the statements it contains. For
each node on the CFG, a sequence number is assigned,
together with the counts of the branches it connects and
664  24th USENIX Security Symposium 
USENIX Association
6
the number of loops it is involved in. These parameters
are used to calculate the geometric center of the program.
To prepare for mass vetting, our approach ﬁrst goes
through all the apps on a market and breaks them into
methods. After removing common libraries, the pre-
processing module analyzes their code, calculates the
geometric centers for individual methods (i.e., the m-
cores) and then sorts them before storing the results in
the database. During the vetting process, if a submitted
app is found to share the view graph with another app,
their diffs are quickly identiﬁed by comparing the m-
cores of their individual methods. When the app needs to
go through the intersection step, its methods are used for
a binary search on the m-core database, which quickly
discovers those also included in existing apps. Here we
elaborate how these operations are performed. Their
overhead is measured in Section 4.2.
Analyzing diffs. Whenever an app is found to relate to
another one from their common view graph, we want to
inspect the difference part of their code to identify sus-
picious activities. The rationale is that repackaged apps
are the mainstay of Android malware, and the malicious
payloads are often injected automatically (using tools
like smali/baksmali) without any signiﬁcant changes to
the code of the original app, which can therefore be lo-
cated by looking at the diffs between the apps of the same
repackaging origin. Such diffs are quickly identiﬁed by
comparing these two apps’ m-cores: given two ordered
sequences of m-cores L and L′, the diff between the apps
at the method level is found by merging these two lists
according to the orders of their elements and then re-
moving those matching their counterparts on the other
list; this can be done within min (|L|,|L′|) steps.
However, similarity of apps’ UIs does not always indi-
cate a repackaging relation between them. The problem
happens to the apps produced by the same party, indi-
vidual developers or an organization. In this case, it is
understandable that the same libraries and UIs could be
reused among their different products. It is even possible
that one app is actually an updated version of the other.
Also, among different developers, open UI SDKs such as
Appcelerator [3] and templates like Envatomarket [13]
are popular, which could cause the view structures of
unrelated apps to look similar. Further, even when the
apps are indeed repackaged, the difference between them
could be just advertisement (ad) libraries instead of mali-
cious payloads. A challenge here is how to identify these
situations and avoid bringing in false alarms.
To address these issues, MassVet ﬁrst cleans up a sub-
mitted app’s methods, removing ad and other libraries,
before vetting the app against the market. Speciﬁcally,
we maintain a white list of legitimate ad libraries based
on [6], which includes popular mobile ad platforms such
as MobWin, Admob, etc. To identify less known ones,
we analyzed a training set of 50,000 apps randomly sam-
pled from three app markets, with half of them from
Google Play. From these apps, our analysis discovered
34,886 methods shared by at least 27,057 apps signed
by different parties. For each of these methods, we fur-
ther scanned its hosting apps using VirusTotal. If none of
them were found to be malicious, we placed the method
on the white list. In a similar way, popular view graphs
among these apps were identiﬁed and the libraries as-
sociated with these views are white-listed to avoid de-
tecting false repackaging relations during the view-graph
analysis. Also, other common libraries such as Admob
were also removed during this process, which we elab-
orate later. Given the signiﬁcant size of the training set
(50,000 randomly selected apps), most if not all legiti-
mate libraries are almost certain to be identiﬁed. This
is particularly true for those associated with advertising,
as they need certain popularity to remain proﬁtable. On
the other hand, it is possible that the approach may let
some zero-day malware fall through the cracks. In our re-
search, we further randomly selected 50 ad-related meth-
ods on the list and searched for them on the Web, and
conﬁrmed that all of them were indeed legitimate. With
this false-negative risk, still our approach achieved a high
detection coverage, higher than any scanner integrated in
VirusTotal (Section 4.2).
When it comes to the apps produced by the same party,
the code they share is less popular and therefore may not
be identiﬁed by the approach. The simplest solution here
is to look at similar apps’ signatures: those signed by the
same party are not considered to be suspicious because
they do have a good reason to be related. This simple
treatment works most of time, since legitimate app ven-
dors typically sign their products using the same certiﬁ-
cate. However, there are situations when two legitimate
apps are signed by different certiﬁcates but actually come
from the same source. When this happens, the diffs of
the apps will be reported and investigated as suspicious
code. To avoid the false alarm, we took a close look at
the legitimate diffs, which are characterized by their in-
tensive connections with other part of the app. They are
invoked by other methods and in the meantime call the
common part of the code between the apps. On the other
hand, the malicious payload packaged to a legitimate app
tends to stand alone, and can only be triggered from a few
(typically just one) program locations and rarely call the
components within the original program.
In our research, we leveraged this observation to dif-
ferentiate suspicious diffs from those likely to be legiti-
mate. For each diff detected, the DiffCom analyzer looks
for the calls it makes toward the rest of the program and
inspects the smali code of the app to identify the ref-
erences to the methods within the diff. These methods
will go through a further analysis only when such inter-
USENIX Association  
24th USENIX Security Symposium  665
7
actions are very limited, typically just an inward invoca-
tion, without any outbound call. Note that current mal-
ware authors do not make their code more connected to
the legitimate app they repackage, mainly because more
effort is needed to understand the code of the app and
carefully construct the attack. A further study is needed
to understand the additional cost required to build more
sophisticated malware to evade our detection.
For the diff found in this way, DiffCom takes fur-
ther measures to determine its risk. A simple approach
used in our implementation is to check the presence
of API calls (either Android framework APIs or those
associated with popular libraries) related to the oper-
ations considered to be dangerous. Examples include
getSimSerialNumber, sendTextMessage and
getLastKnownLocation. The ﬁndings here indi-
cate that the diff code indeed has the means to cause dam-
age to the mobile user’s information assets, though how
exactly this can happen is not speciﬁed. This is differ-
ent from existing behavior-based detection [27], which
looks for much more speciﬁc operation sequences such
as “reading from the contact list and then sending it to the
Internet”. Such a treatment helps suppress false alarms
and still preserves the generality of our design, which
aims at detecting unknown malicious activities.
Analyzing intersections. When no apparent connection
has been found between an app and those already on the
market, the vetting process needs to go through an in-
tersection analysis. This also happens when DiffCom is
conﬁgured to perform the analysis on the app that has not
been found to be malicious at the differential step. Identi-
ﬁcation of common methods a newly submitted app car-
ries is rather straightforward: each method of the app is
mapped to its m-core, which is used to search against the
m-core database. As discussed before, this can be done
through a binary search. Once a match is found, Diff-
Com further inspects it, removing legitimate connections
between the apps, and reports the ﬁnding to the market.
the main challenge here is to determine
whether two apps are indeed unrelated. A simple sig-
nature check removes most of such connections but not
all. The “stand-alone” test, which checks whether a set
of methods intensively interact with the rest of an app,
does not work for the intersection test. The problem here
is that the common methods between two repackaged
apps may not be the complete picture of a malicious pay-
load, making them different from the diff identiﬁed in
the differential-analysis step: different malware authors
often use some common toolkits in their attack payloads,
which show up in the intersection between their apps;
these modules still include heavy interactions with other
components of the malware that are not found inside the
intersection. As a result, this feature, which works well
on diffs, cannot help to capture suspicious common code
Again,
among apps.
An alternative solution here is to look at how the seem-
ingly unrelated apps are actually connected. As dis-
cussed before, what causes the problem is the developers
or organizations that reuse code internally (e.g., a propri-
etary SDK) but sign the apps using different certiﬁcates.
Once such a relation is also identiﬁed, we will be more
conﬁdent about whether two apps sharing code are inde-
pendent from each other. In this case, the common code
becomes suspicious after all public libraries (e.g., those
on the list used in the prior research [6]) and code tem-
plates have been removed. Here we describe a simple
technique for detecting such a hidden relation.
From our training dataset, we found that most code
reused legitimately in this situation involves user inter-
faces: the developers tend to leverage existing view de-
signs to quickly build up new apps. With this practice,
even though two apps may not appear similar enough in
terms of their complete UI structures (therefore they are
considered to be “unrelated” by the view-graph analy-
sis), a close look at the subgraphs of their views may re-
veal that they actually share a signiﬁcant portion of their
views and even subgraphs. Speciﬁcally, from the 50,000
apps in our training set, after removing public libraries,
we found 30,286 sharing at least 30% of their views with
other apps, 16,500 sharing 50% and 8,683 containing no
less than 80% common views. By randomly sampling
these apps (10 each time) and analyzing them manually,
we conﬁrmed that when the portion goes above 50%, al-
most all the apps and their counterparts are either from
the same developers or organizations, or having the same
repackaging origins. Also, once the shared views be-
come 80% or more, almost always the apps are involved
in repackaging. Based upon this observation, we run an
additional correlation check on a pair of apps with com-
mon code: DiffCom compares their individual subgraphs
again and if a signiﬁcant portion (50%) is found to be
similar, they are considered related and therefore their
intersection will not be reported to the market.
After the correlation check, all the apps going through
the intersection analysis are very likely to be unrelated.
Therefore, legitimate code shared between them, if any,
is almost always public libraries or templates. As de-
scribed before, we removed such common code through
white-listing popular libraries and further complemented
the list with those discovered from the training set: meth-
ods in at least 2,363 apps were considered legitimate
public resources if all these apps were cleared by Virus-
Total. Such code was further sampled and manually an-
alyzed in our study to ensure that it indeed did not in-
volve any suspicious activities. With all such libraries
removed, the shared code, particularly the method with
dangerous APIs (e.g., getSimSerialNumber), is re-
ported as possible malicious payload.
666  24th USENIX Security Symposium 
USENIX Association
8
Evading MassVet. To evade MassVet, the adversary
could try to obfuscate app code, which can be tolerated
to some degree by the similarity comparison algorithm
we use [7]. For example, common obfuscation tech-
niques, such as variable/method renaming, do not affect
centroids. Also the commonality analysis can only be
defeated when the adversary is willing to signiﬁcantly
alter the attack payload (e.g., a malicious SDK) each
time when he uses it for repackaging. This is not sup-
ported by existing automatic tools like ADAM [53] and
DroidChameleon [32], which always convert the same
code to the same obfuscated form. Further, a deep obfus-
cation will arouse suspicion when the app is compared
with its repackaging origin that has not been obfuscated.
The adversary may also attempt to obfuscate the app’s
view graphs. This, however, is harder than obfuscat-
ing code, as key elements in the graph, like event func-
tions OnClick, OnDrag, etc., are hardcoded within
the Android framework and cannot be modiﬁed. Also
adding junk views can be more difﬁcult than it appears
to be: the adversary cannot simply throw in views dis-
connected from existing sub-graphs, as they will not af-
fect how MassVet determines whether two view-graphs
match (Section 3.2); otherwise, he may connect such
views to existing sub-graphs (potentially allowing them
to be visited from the existing UI), which requires under-
standing a legitimate app’s UI structures to avoid affect-
ing user experience.
We further analyzed the effectiveness of existing ob-
fuscation techniques against our view-graph approach
over 100 randomly selected Google-Play apps. Popu-
lar obfuscation tools such as DexGuard [37] and Pro-
Guard [38] only work on Java bytecode, not the Dalvik
bytecode of these commercial apps. In our research, we
utilized ADAM [53] and DroidChameleon [32], which
are designed for Dalvik bytecode, and are highly effec-
tive according to prior studies [53, 32]. Supposedly they
can also work on view-related code within those apps.