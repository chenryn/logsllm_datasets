service_notification_commandsnotify-service-by-email
contact_groups
notification_period
retry_check_interval
max_check_attempts
members
hostgroup_name
members
alias
host_notification_options d,u,r
service_notification_options w,u,c,r
host_notification_period
check_period
normal_check_interval
alias
email
testServers
Moniter724Group
test-Core
24x7
moniter-group
hechunyang
PI:EMAIL
test-Core
test-servers
24x7
check_nrpe!check_mem
check_mem
moniter-group
3
24x7
第10章服务监控·287
---
## Page 302
288·第四部分监控篇
10.2MySQL数据库的监控脚本
swap 分区监控，脚本如下：
#/usr/local/nagios/libexec/check_cpu-w 40-c 20-s 3
CPU的监控，脚本如下：
以下是针对数据库总结的一些监控脚本。
到此Nagios的安装完成。
然后重启Nagios，就可以看见我们要监控的资源了，如图10-2所示。
DISKOK-free space:/4365MB(46% inode=93%);1/=5038MB;7932;8924;0;9916
#/usr/local/nagios/libexec/check_disk-w20%-c10%-p/
磁盘剩余空间监控，脚本如下：
#/usr/local/nagios/libexec/check_swap-w80%-c70%
OK -Total:49454416kb,Used:46786224kb,Free:2668192kb,Available_mem:
#/usr/local/nagios/libexec/check_mem-w1048576-c524288
内存的监控，脚本如下：
OK-load average:0.14,0.09,0.02load1=0.140;20.000;30.000;0;
#/usr/local/nagios/libexec/check_load-w20,17,12-c30,25,20
load average的监控，脚本如下：
|swap=1999MB;1599;1399;0;1999
SWAPOK-100%free(1999MBoutof1999MB)
6481308kb|'mem_total'=49454416'mem_used'=46786224;1048576;524288
load5=0.090;17.000;25.000;0;load15=0.020;12.000;20.000;0;
OK:CPU is100%idle
mem_free'=2668192
hadsop-namenoae
图10-2监控服务状态信息
---
## Page 303
tables:664Queriespersecondavg:1039.499
#/usr/local/nagios/libexec/check_mysql-Hlocalhost-uadmin_nagios
MySQL主从复制监控（延时及复制报错），脚本如下：
Uptime:51198574Threads:40 Questions:53220908260 Slowqueries:1825223Opens:14007Flush tables:11 Open
MySQL服务监控，脚本如下：
#/usr/local/nagios/libexec/check_mysql_conn.pl-w120-c200-p3306
连接数的监控，脚本如下：
1136.34slaveIO:YesslaveSQL:YesSecondsBehindmaster:0
Opens:10009Flushtables:139Opentables:50Queriespersecond avg:
Uptime:31856624Threads:15Questions:36190227503Slowqueries:8336
-padmin2nagios-P3306-S-w1200-c1500
padmin2nagios-P3306
#/usr/local/nagios/libexec/check_mysql-Hlocalhost-uadmin_nagios
*192.168.240.95[1] *[1]
192.168.240.174[2]
OK-ConnectionMySQLIsOK;*Totalconr
nections[51];*192.168.240.66[26]*
第10章服务监控·289
---
## Page 305
第11章
项目案例讲解
项目案例
第五部分
---
## Page 306
理，下面我们就来尝试整理看看。
统计的数据大小差异过大，就表示要整理碎片了。在整理碎片时，首先要查询一下物理文
文件将缩小，数据之间将按照顺序重新整理排序，这对于查询时提升性能会非常有利。
磁带机备份的空间，为了提升数据库性能，我们计划进行一次数据整理。调整以后，数据
SCHEMA='DBO9'GROUPBYTABLE_NAME;
件的大小，可用如下命令查看：
11.1
从查询的结果可以看到，DBSync表物理文件大小是80GB，而数据字典里的大小是
那么如何定期整理数据碎片呢？我这里有个方法，当你发现数据物理文件和数据字典
在MySQL 数据库中，由于不断进行更新、删除操作，因而会产生大量的碎片，减少了
mySqI>SELECT TABLE_NAME,CONCAT(ROUND(DATA_LENGTH/1024/1024/1024),'GB')AS DATA
目前架构如下所示：
注：割接一词：行业里的术语，是指对数据库进行调整的意思。
1.割接前的步骤
然后到数据库里查看数据字典信息，如：
M（DB01）-→S（DBO2）
#1l-Sh|more
(m-vip)
rw-rw---1mysqlmysql80GJun1910:22DBSync.ibd
数据碎片整理方案
项目案例讲解
第11章
(s-vip)
---
## Page 307
这3个值，然后在bak（备份库）上执行change master to 指向到M（主库），并开启同步。
status\G;”命令，查看并记录 master_Host、Relay_master_Log_File、Exec_master_Log_Pos
Pos这个值不再变化了，Seconds_Behind_master=0。
制指向master。
份服务器简写为bak。
“show slave status\G;”来观察是否已经同步完毕，如果已经同步完毕，Exec_master_Log_
4）这时S（从库）和bak（备份库）数据是一致的，在S（从库）上执行“show slave
现在调整架构，让bak 指向M，调整后的架构是：
其中，master服务器简写为M，slave服务器简写为S，统计分析服务器简写为jf，备
3）之后S（从库）的同步复制会断掉，提示test已存在，在bak（备份库）上通过命令
调整的过程如下：
这么做的目的是，用bak上的数据去替换slave，且保证 slave 被替换后的数据同步复
M(DB01)--→S(DB02)
(m-vip)
bak
(s-vip)
bak
14 rows in set (0.69 sec)
TABLE NAHE
_TransferCard
3Info_MovePooll1718Bak_Temp
Info
roup
图11-1数据字典统计结果
DATA LENGTH|
第11章项目案例讲解293
---
## Page 308
294·第五部分项目案例
然后到bak（备份库）上让 change master to 指向到 S（从库），调整后的架构是：
开启同步。这2份数据是静止的，完全一致。
选项(禁止启动数据库后自动同步功能)。
停止MySQL服务，命令为：/etc/init.d/mysql stop。
写分离功能，所以需要运维人员先关闭此功能。
进行碎片整理。
注意
之后用这份数据去替换slave。
dump 导出和导人，然后根据dump 出来的大小，重新初始化 ibdata，即进行数据碎片整理，
Host、Relay_master_Log_File、Exec_master_Log_Pos这3个值。在bak（备份库）上进行
库的同步复制会断掉，提示test已存在)，开启同步。
然后，调整架构，让bak指向M。
6）停止bak（备份库）上的同步，执行“show slave status\G;”命令，并记录master
5）在S（从库）执行“set global sql_slave_skip_counter=1;”命令，跳过那个错误（从
7）2:10～2:15，在S（从库）上执行showmaster status;命令，记录binlog和POS值，
6）2:01～2:10，把S（从库）、bak（备份库）上的MySQL服务启动，注意，这里禁止
2）0:00～0:15，在S（从库）上执行“show processlist;”命令，确定连接已无，然后
此方案是基于共享表空间的，如果是独立表空间，可采用 alter table表名engine=innodb
5）1:00～1:05，都替换完毕后，修改bak（备份库）上的 my.cnf，打开 skip-slave-start
4）0:20～1:00，用bak上（备份库）的数据替换掉S（从库)。
1)23:50～0:00，在替换S（从库）前，把slave_vip 漂移到M上，因为之前有打开读
7）剩下的就是bak（备份库）同步追数据。
M(DB01)--
(s-vip)
(m-vip)
割接时的操作过程如下：
开始割接操作的前提条件是：bak与 master 的同步完成。
2.割接时的步骤
→S(DB02)
---
## Page 309
masterto指向新M（主库），开启同步。
分析切换后新的数据写人的那个点（以server-id为准绳），然后到新S（从库）上让change
11）3:15～3:20，通知运维人员打开读写分离功能。
第二次割接时，再利用bak 重建现在的 slave库，完成所有库的数据整理工作。
10）3:05～3:15，切换完毕后，在新的M（主库）上到log目录下通过mysqlbinlog来
9）3:00～3:05，待S（从库）上的数据追上来后，在M（主库）上进行HA切换。
8)2:15～3:00，开启S（从库）的同步功能，执行“start slave;”命令，等待同步追数据。
整理后的性能图如图11-3所示。
整理前的性能图如图11-2所示。
割接完成后，可以在18:00进行jf库的重建。
3.割接完成的后续工作
(s-vip)
最后的架构是：
S(UP01)--
bak
iterresemake defau
GraphName
Corteins
CPUUtiliztion
(m-vip)
%
→M(UP02)
falue
图11-2碎片整理前CPU性能图
KernelUserWaitI/OTotal
Conr
ections,tiizaon,Da
11:00
1230 3001330 40
、
Time Range
第11章项目案例讲解·295
---
## Page 310
296
·第五部分项目案例
模，命令如下：
架构和拆表后的架构。
据平均分散到不同的小表，再分布到各台机器上的方式，可以看做是迁移数据。
访问，slave 备机的延时很大时，将会发展到采用对表水平切分，依靠表的主键取模，把数
低了数据库的负载。随着数据的增长，如果发现依靠读写分离也解决不了高负荷高并发的
从架构层出发，可以采用读写分离的方式，同时用多台slave 备机提供读取业务，这样就降
过增加硬件（比如，加内存、换SSD硬盘，或者采购性能很强劲的小型机）去解决。如果
11.2
迁移数据的方法就是利用用户ID进行取
当数据很小时，只用一台机器也许就能扛住数据访问压力，当数据量变大时，可以通
下面的图11-4和图11-5分别是拆表前的
第一步，在主库上（M）建立三张表：t0、tl、t2，拆分时会用到。
总结：经过整理，数据库QPS 吞吐率一样，但整理后CPU的使用率有所下降。
createtablet2liket;
create tablet1liket;
createtabletoliket;
以下是实现步骤：
其中，3就代表拆分到3张表里。
MOD(new.id,3)
用户信息表水平拆表方案
Connections
eresemakedefout
光
Value
图11-3碎片整理后CPU性能图
Kernel UserWait l/OTotal
将一张大表，拆分成N张小表放到不同的服务器上。
到3台服务器上。
目前架构就是主从，大表名字是t表，
我这里将其拆分成3个表，并将其放
图11-4拆表前架构图
---
## Page 311
第二步，在主库上（M）建立三个插人、更新、删除的触发器，代码如下：
DECLAREv_result INT;
DROPTRIGGER/*!50032IFEXISTS*/'t_update'S$
ELSEIF v_result =1 THEN
SETv_result=MOD(new.id,3);
FOREACHROWBEGIN
TRIGGER't_update'AFTERUPDATEON't'
*150017DEFINER='admin'@'%'*/
USE'test'S$
DELIMITERSS
END;
ENDIF;
ELSE
SETv_result=MOD(new.id,3);
DECLAREv_result INT;
TRIGGER't_insert'AFTERINSERTON't"
/*150017DEFINER='admin'@'%'*/
CREATE
DELIMITER;
价
FOREACHROWBEGIN
CREATE
DROPTRIGGER/*150032IFEXISTS*/'t_insert'SS
USE'test'Ss
DELIMITERSS
v_result=OTHEN
INSERTINTOt2(id,NAME,age,address)VALUES(new.id,new.name,new.age,new.address);
INSERTNTOt1(id,AME,age,ddress)ALUES(nw.id,nw.ame,w.age,w.address);
REPLACEINTOtO(id,AME,ge,addres)VALUES(new.id,ew.name,w.age,ew.address);
v_result=OTHEN
new1/2/3机器。
IP指向新的M_
机器，应用服务
断掉原先的M
图11-5拆表后架构图
与S2同步。
存放t0表，
这是最终的架构图
与S2同步
存放tl表，
M库上的t表。
例S2，同步复制
上，增加一个实
与S2同步。
在S（从库）机器
存放t2表，
Mnew3
第11章项目案例讲解·297
---
## Page 312
298·第五部分项目案例
在my.cnf里增加：
都没问题，就可以把数据分散到新的3台服务器里。
t1、t2这三张表里，然后开启同步复制主库M。
触发器，这样做的目的是，在导人数据的时候，
注意
不要表结构），命令如下：
在S2实例上，把t0表dump出来并导人到M_new1机器上，然后在M_new1机器上，
第六步，上面五个步骤完成以后，请检查一下数据的增长情况，并观察同步是否正常
第五步，在从库上的S2实例中，创建表t、t0、tl、t2，也同样建立前面提到的那三个
mysqldump-uroot-p123456--dump-slave=2-nt --skip-triggers-q--single-transaction testtt0t1t2>t_all.sql
第四步，在从库上新建一个实例（S2），并导出t、t0、t1、t2四张表（导出时只要数据，
第三步，确保同步复制的延时时间为0时，在从库上（S）关闭同步复制。
__dump-slave 参数还记得什么意思吗？如果忘记了，请看备份复制一章。
这样t表的数据变更时，就会按照取模的结果更新到t0、t1、t2这三张表里
ELSEIF v_result =1 THEN
DELIMITERSS
ELSEIFv_result =1THEN
DELIMITER;
END;
ENDIF;
ELSE
SETv_result=MOD(old.id,3);
DECLAREv_resultINT;
FOREACHROWBEGIN
TRIGGER't_delete'AFTERDELETEON't
=
CREATE
DROPTRIGGER/*!50032IFEXISTS*/'t_delete'SS
USE'test'ss
DELIMITER;
END;
ENDIF;
ELSE
DELETEFROMt2WHEREid=OLD.id;
DELETEFROM t1WHEREid=OLD.id;
REPLACEINTOt2(id,AME,age,address)VALUES(new.id,new.name,ew.age,new.address);
REPLACEINTOt1(id,AME,age,address)VALUES(new.id,new.name,ew.age,new.address);
DELETE FROM tO WHERE id = OLD.id;
，就会通过触发器取模，把数据分散到t0.
---
## Page 313
数据库test2 的tb2上。其结构如图 11-6所示。
接口，开发人员不需要知道每张小表具体放在哪台服务器上，DBA也减少了繁琐的水平拆