The results from Study 1 contributed to corroborate the aforementioned hypotheses, which
were investigated more deeply in the two following studies. Study 2 focused on the importance
of selecting versus being given the information of interest. Finally, in Study 3, the importance
of the type of information users see was addressed. Here, the aim was to uncover whether spe-
cific TRI elements impact user judgements.
Across all three studies several dependent variables were measured. Initially, the partici-
pants provided their rent decision for the room advertised, then rated their confidence in this
judgment. Subsequently, they provided ratings for their perceived trustworthiness, credibility,
and sociability of the hosts advertising each room. This was done in order to assess how differ-
ences in the amount and type of TRI impacted these dimensions. Specifically, we explored
how providing users such information would affect how trustworthy a host appeared, whether
having TRI on the platform would make the information hosts provided seem more credible,
and whether providing user-generated content from past interactions would make the hosts
appear more sociable. This choice was made as SE platforms often brand themselves as envi-
ronments that favor personal interactions in a unique way. Therefore, in our experiments we
introduced TRI elements that, although not always present in real-world SE platforms, were
designed to test differences in those dimensions (see Study 1‘s Stimuli Section).
Study 1
The first study investigated the effect of providing users with different amounts of host-related
TRI, over three conditions: Hidden, Visible, and Reveal. This contrasted host profiles lacking
TRI (Hidden), with full profiles (Visible), and profiles where only partial user-selected infor-
mation was presented (Reveal). The effect of differences in the amount of TRI on user judg-
ments was measured on ratings of host credibility, trust, sociability, rent decisions, and
confidence. It was predicted that the increased amount of information available would impact
users’ perceptions of hosts, resulting in differences in ratings, and decision to rent the private
rooms. Additionally, allowing users to select host TRI would reveal which elements facilitate
decision-making on SE platforms, or at least which elements users believe facilitates their deci-
sions. The utility of the Reveal condition was in observing participant choices directly, pre-
venting various participant response biases, such as responding according to or against what
they surmise the experiment’s goal to be [46].
Methods
Participants and design. A total of 160 participants were recruited online through Ama-
zon’s Mechanical Turk (mTurk; www.mturk.com) in exchange for a flat fee of $1.00. After
deleting incomplete or invalid cases (n = 36) the final data encompassed 124 participants.
Eiteee asd (65 males, 58 females, one undisclosed; MAge = 35.11, SD = 10.52; range: 20–73).
Written (digital) informed consent was obtained from all participants prior to participation.
This study and all procedures used have been ethically reviewed and received ethics approval
from the University College London Research Ethics Committee (CEHP/2015/534).
An independent-samples design was used, with three levels of Profile (Hidden, Visible, and
Reveal). Participants were measured on multiple dependent variables: rent decision, confi-
dence in decision, perceived sociability of host, trustworthiness of the host, and credibility of
information (also, see S1 Text).
PLOS ONE | https://doi.org/10.1371/journal.pone.0209071 December 13, 2018
4 / 18
Digital Identity and user judgment
Fig 1. Example of host profiles in each condition, indicating which elements were visible to users. In the Hidden
condition, only a picture of the host, one of the room, and a minimal description of the latter were present (NB: these
elements were visible in all conditions). In the Visible condition, 7 additional elements were shown to users. In the
Reveal condition, users had to spend tokens to visualize any 3 out of such 7 elements (the profile above already shows
the 3 users-selected elements, with the 4 non-selected elements remaining obscured).
https://doi.org/10.1371/journal.pone.0209071.g001
Stimuli. Typical SE accommodation profiles were created specifically for the purposes of
this experiment, using the Gorilla platform (www.gorilla.sc). These contained the elements
generally featured on such sites, with the addition of two elements. The profiles were described
as representing a “private room” in the host’s house that they wished to rent out to potential
guests (see Fig 1).
The elements were as follows: a photo of the advertised room, a description of the room, a
photo of the host, host verification, two guest reviews, two host reviews, online market reputa-
tion, social media presence, number of reviews, and star rating (for examples, see S2 Text).
Certain factors were controlled in the creation of the profiles. To ensure quality and eco-
logical validity, all elements were created to reflect the general ratings and content observed on
SE platform profiles [4,47]. Two new elements were uniquely created to introduce further digi-
tal identity cues about the hosts: “social media presence” and “online market reputation”. This
decision stems from our perception of SE platform trends towards increased information-
sharing and the role that users’ DI has on their online perception [30].
The former element was introduced, in particular, to gauge its impact on perceived host
sociability (as well as all other trust-related metrics, see S2 Text). Indeed, SE platforms often
market themselves as environments that favor unique personal interactions, which motivated
our choice to introduce an additional TRI element to test sociability.
The latter element, instead, was introduced to assess how cross-platform user reputation
impacts decision-making on other platforms (i.e. the reputation of the user on one P2P plat-
form influencing how they are perceived on another P2P platform). Including this type of
information has been advocated by many, both in the industry and academia (cf. [48]), and in
recent years several startup companies have put forward solutions in this direction. For a com-
prehensive description of element creation and controls implemented see S2 Text.
Procedure. Participants were randomly assigned to one of the three Profile conditions;
Hidden (n = 42), Visible (n = 40), and Reveal (n = 42). They were first given a series of pre-task
questions, including demographics (age, gender, and ethnicity), and SE usage (see S1 Text).
They then received instructions specific to their condition and were provided with an example
profile, familiarizing them with the layout of the profiles, the type of information available,
and the responses they would need to provide.
During the main task, users saw one profile at a time, and were asked if they wanted to
“Rent” or “Not Rent” (binary, forced-choice). The other DV questions were measured on a
10-point Likert-type scale. Confidence was phrased as “How confident are you in your
PLOS ONE | https://doi.org/10.1371/journal.pone.0209071 December 13, 2018
5 / 18
Digital Identity and user judgment
decision to Rent/Not rent?” (1—Not at all Confident to 10—Very Confident). Sociability was
phrased as “How sociable do you think the host would be?” (1—Not at all Sociable to 10—Very
Sociable). Trustworthiness was phrased as “How would you rate the trustworthiness of the
host?” (1—Very Untrustworthy to 10—Very Trustworthy). While credibility was phrased as
“How credible do you think the information about this room is?” (1—Not at all Credible to
10—Very Credible).
This was repeated over 10 trials. After each trial they were given a “validation” question, to
ensure they were paying attention to the information in the profile. This was in the form of a
question about a specific element on the profile (e.g., “What were the colors of the walls?”,
with an open-ended response). Users who attempted to go back in order to check profiles once
more before answering the validation question were treated as invalid cases and discarded
from the analysis. The elements comprising each profile were randomized between partici-
pants, reducing the artificial influence of specific combination on the responses. The inclusion
of the validation questions in our design was warranted due to the attention benefits such
questions can have on respondents (see [49]). In this respect, our design was in line with well-
established practices for web-based experiments [49]. However, we note that data on user
accuracy on the validation questions was not collected, and thus we cannot make inferences as
to their relationship with user judgements.
In the Hidden condition, users saw a host’s profile with minimal information presented
about a room offered. This was limited to a photo of the room, a picture of the host, and a
description relating to the room; these were always shown regardless of the profile condition.
In the Visible condition, users saw a fully populated host profile, containing all the elements
detailed above. In the Reveal condition, for each profile users had three tokens to “spend” on
revealing any information they desired to help in their judgements. The elements available
were: host verification, guest reviews, host reviews, online market reputation, social media
presence, number of reviews, and star rating. The information regarding the spending of the
three tokens was recorded in each trial. After the main task was completed, participants had to
answer several post-task questions, and were debriefed (see S1 Text).
Results
Users’ ratings were summed across the 10 trials and analyzed on each of the five dependent
measures based on the three Profile conditions.
For decisions to rent the rooms, a one-way analysis of variance (ANOVA) revealed a signifi-
cant main effect of Profile, F(2,121) = 3.44, p = .035, η2 = .054. Post-hoc Tukey’s HSD tests
showed a significantly higher number of rent decisions in the Reveal condition (M = 8.05,
SD = 2.23) than the Hidden condition (M = 6.60, SD = 2.43) and, p = .027. No other compari-
sons were significant.
Confidence in rent decisions was not found to be affected by Profile condition, F < 1, p =
.893, suggesting that the type and amount of information participants saw on the profiles did
not influence their confidence. Overall, the average confidence was very high for rent decisions
(M = 7.58, SD = 1.3 per profile).
Ratings of host sociability were significantly affected by Profile condition, F(2,121) = 6.41,
p = .002 , η2 = .096. Post-hoc tests showed significant lower user ratings for the Hidden condi-
tion (M = 60.81, SD = 16.07) compared to both the Visible (M = 70.83, SD = 13.69), p = .006,
and the Reveal conditions (M = 70.50, SD = 13.56), p = .008.
Similarly, a main effect of host trustworthiness based on Profile was found, F(2,121) = 8.94,
p < .001 , η2 = .129. Post-hoc tests revealed significantly lower ratings in the Hidden condition
(M = 63.50, SD = 15.50) compared to both the Visible (M = 75.13, SD = 14.29), p = .001, and
PLOS ONE | https://doi.org/10.1371/journal.pone.0209071 December 13, 2018
6 / 18
Digital Identity and user judgment
the Reveal (M = 74.36, SD = 12.07) conditions, p = .002. No other significant comparisons
were found.
Finally, a main effect of percevied credibility was found, F(2,121) = 7.00, p < .001 , η2 =
.104. Post-hoc comparisons revealed that the Hidden condition (M = 67.48, SD = 14.64) pro-
duced significantly lower ratings than both the Reveal (M = 76.69, SD = 11.87), p = .005, and
Visible (M = 77.05, SD = 13.04), p = .004, conditions.
As the data suggest a lack of difference in user ratings between the Visible and Reveal condi-
tion, Bayesian independent-samples t-tests were conducted to complement the frequentist
analysis. Considering the null hypothesis of no difference between the two conditions, tenta-
tive results were found in support of this claim. For all measures, the Bayes factor equaled
between BF01 = 2.6–4.34, indicating that the data was around 3 to 4 times more likely under
then null than the alternative hypothesis (S3 Text).
Triplet analysis. To obtain a better understanding of user selection preference for elements
in SE platforms, an analysis of user token “spending” patterns in the Reveal condition was con-
ducted. Each trial from each participant was treated as a unique vector of element selection
from the total seven available items. Thus, the triplets of each of the 42 participants over the 10
trials were analyzed, 420 triplets in total. The triplet selection patterns were compared to a null
model of random selection, using a binomial distribution (for details, see S4 Text).
Initially, with respect to the frequency of observation of certain elements, a few results are
relevant. It was found that 89.5% of the selected triplets featured at least one of the two following
elements: “star ratings” and “guest reviews”. Furthermore, 47.1% of the triplets featured both
items, suggesting a strong user preference towards the two items. When testing for the over-
representation of triplets, we find three combinations to be statistically significant at the 1% uni-
variate level. These are: “star ratings + guest reviews + number of reviews”, “star ratings + guest
reviews + host verification”, or “star ratings + guest reviews + host reviews”. These were inter-
preted as the triplets of TRI information users prefer most to aid in their decision-making.
Discussion
This study finds that providing users with typical SE platform TRI increases their positivity
towards their peers, rating them higher on sociability, trustworthiness, and credibility. Impor-
tantly, this also resulted in an increased number of rent decisions. Differences were observed
when comparing user ratings in the Hidden condition, where all but the basic information was
present, with the Visible and Reveal condition, where reputation and trust information was
provided to varying degrees. The results also suggest that seeing a full profile (Visible) or one
with only partial, but user-selected, information (Reveal) results, on average, in similar judge-
ments towards hosts. Considering the difference in information between the two conditions
(i.e. seven elements in the Visible condition and three user-selected elements in the Reveal
condition), two explanations are proposed.
Potentially, the act of selecting which elements to see impacted users’ perception, leading to
the belief that these elements are the most relevant/useful for their decision [50]. Thus, the act
of selecting specific information may be generating this “positivity effect” (i.e. increased ratings
towards hosts on all measures).
Alternatively, it may be that users rely only on a few elements when making their decisions,
as argued by past decision-making research [50–52]. Thus, users may not be able to incorpo-
rate in their judgment the additional information present in a full profile.