caused by bad coding practices: as a representative example, we iden-
tified an app continuously invoking the getRunningServices
API with no sleep between two invocations.
For what concerns the malware detection, we evaluated our
system over synthetic apps configured as real malicious applications.
The techniques used to mimic the malicious behaviour of the apps
are described in Section IX-A. For these apps, our system was able
to correctly pinpoint the malicious behaviour of all the samples and
13
0306090120150180210240Bootstrap (s)26283032343638False PositivesImpact of Bootstrap over False Positivesthus, in a real scenario, it would have been able to detect and stop
the attacks.
Fig. 5: Plot comparing the time needed to complete the benchmark
for an unmodified AOSP system and one powered with our
polling-detection system. The highlighted points are the arithmetic
means computed over 100 runs of the benchmark. The red boxes
represent their standard deviations, while the black lines indicate the
minimum and the maximum times recorded for both systems. Our
polling detection system is accountable for an overhead of ∼98.2 ms
per benchmark run (1.98%) in average, corresponding to ∼9.82 µs
per service API invocation.
Performance Consideration. The design of our detection system
relies on optimized data structures and a fast algorithm. This allows
our system to handle each service invocation in constant time (i.e.,
O(1)), independently from the number of services in the system,
the number of running apps, and the rate at which system services
are invoked. An approximation of the required memory is given by
napps×(x+1)×8bytes, where napps is the number of running
apps and x the entries in the circular buffers. In an hypothetical
scenario of 50 apps invoking multiple services, we estimate that
our system needs in total less than 10KB of memory. We measured
the performance overhead of our detection system over the vanilla
version of AOSP by performing a micro benchmark, consisting in
invoking multiple times the same system service and measuring the
time needed for the system to handle all the requests. More in details,
we invoked ActivityManager service’s getAppTasks API for 10,000
times. We repeated the test 100 times for both our modified version
and a vanilla version of AOSP. For the purposes of this benchmark,
we modified our system to prevent it from raising exceptions when
the polling threshold is surpassed: we do this to not invalidate the
results of the benchmark, since returning an exception to the caller is
much faster than actually invoking the API. Figure 5 (in Appendix)
shows the results of the benchmark in terms of the average and
the standard deviation of the time needed to serve 10,000 requests.
In average, our detection system is responsible for an overhead of
only the 1.98% with respect to the AOSP baseline. We believe that
such a low overhead is acceptable. Additionally, from a usability
perspective, we did not notice any difference while using either a
device running the baseline AOSP or our detection system.
14
E. Comparison with LeaveMeAlone
LeaveMeAlone [38] is a recent work whose main goal is to
detect and block malicious applications performing a runtime
information gathering attack on Android, and it is thus related to
our work. This section discusses LeaveMeAlone in detail and it
offers a direct comparison showing how it is affected by significant
limitations when tasks to deal with phishing attacks.
A runtime information gathering attack consists in a malicious
app stealing or inferring sensitive information about the runtime data
computed in the context of a target application by analyzing the us-
age of shared resources. The core component of [38] is named “App-
Guardian,” which runs as an unprivileged application. It is in charge
of monitoring the runtime behavior of the running apps and of detect-
ing which are manifesting a suspicious behavior. To identify these
apps, the system relies on collecting static information of the installed
apps like suspicious permissions. For these suspicious apps, the sys-
tem collects runtime behavior when they are running in background
(e.g., thread names, CPU scheduling, kernel time). These behavioral
information are collected by accessing the procfs subsystem.
The identification of these suspicious apps plays a key role when
a target app — protected by the Guardian — is started by the user:
when this situation occurs, the system stops all the suspicious back-
ground processes by creating a “safe execution environment” for the
target app: By not letting the suspicious apps running in background,
the “runtime information gathering” attack is not feasible anymore.
Since our main focus is on detecting polling to prevent phishing
attacks, one may think that LeaveMeAlone could be a good candi-
date to address the same problem. However, while LeaveMeAlone is
certainly valuable in many situations, we argue it would be affected
by many limitations when tasked to prevent phishing attacks.
First, AppGuardian relies on previously known vulnerabilities
to collect runtime information regarding a specific app. Since it
is designed to run as a non-privileged application, all (present and
future) vulnerabilities of this kind will be eventually patched by
Google [18], preventing this approach to work. As a case in point:
all sources of side channels mentioned in the LeaveMeAlone paper
have been fixed in recent versions of Android.
Second, we note that several of the vulnerable APIs found by
our framework do not require any sensitive permission, making
malicious apps using these bugs challenging to be detected by
automatic vetting processes. Our approach, instead, only relies on
the presence of polling-like behaviors and would detect these cases,
independently from the requested permissions.
Third, AppGuardian heavily relies on whitelisting to make
their approach work. Quoting the paper, “Overall, among all the
popular apps, Guardian only needs to suspend 19.3% of the apps”
when referring to a dataset of 475 apps, which is 92 apps. To avoid
creating usability problems, the paper states that they rely on a
whitelist: “The whitelist here includes a set of popular apps that pass
a vetting process the server performs to detect malicious content
or behaviors. In our implementation, we built the list using the top
apps from Google Play, in all 27 categories.” Our approach, instead,
would only be affecting about 40 apps on a dataset of 10K dataset,
which is 20x bigger than what used in previous work.
Last, AppGuardian is vulnerable to race conditions when tasked
to detect on-going phishing attacks. In fact, both the malicious app
and the Guardian are relying on the same side channels: if the
malicious app wins the race (and detects a victim app has been
Polling-detectionVanilla AOSP0123456Time to complete the Benchmark (s)4.77984.6816started), it can go to foreground before Guardian has a chance to kill
it. However, once the malicious app is in foreground, Guardian does
not have a chance to suspend it — third-party apps are not allowed
to do so (they can only suspend apps that are in background). Our
approach is not affected by this limitation. We reached out to the au-
thors of [38], they acknowledged the presence of the race conditions,
and they confirmed that, in this scenario, the Guardian is not able to
stop the malicious app but only to inform the user with a notification.
We acknowledge that this comparison is a high-level one, but we
argue that it is the best we could make, for multiple reasons. First, all
the side-channels used are now fixed, and any evaluation would con-
sequently show negative results. Second, a significant component of
the LeaveMeAlone design is to rely on an off-market vetting system
based on the detection of dangerous permissions. There are no details
about this aspect in the paper and it would be very challenging to
reproduce. Moreover, as shown in Table IV, we found several APIs
that do not require any permission. Thus, once again, this would lead
to obvious bypasses of the system. The last challenge that would
limit any “more direct” comparison is due to the fact that the source
code for neither the app nor the vetting system is available.
X. LIMITATIONS
We believe our work represents a step forward in the detection
of vulnerable API leading to a state inference and to detect malicious
applications exploiting these vulnerabilities to perform phishing
attacks. However, we acknowledge that our approach is affected
by the following limitations.
Reliance on availability of source code: Currently, our tool
requires access to the source code of the Android framework.
From the source code, it is possible to extract the semantics of the
arguments, which is a fundamental step when creating argument
values to invoke a given method. This, therefore, limits our tool
to be used only in AOSP. Thus, our framework cannot be used to
test systems from other vendors whose source code is not available,
such as Samsung or Huawei. Note that, however, our system could
be extended to bring the analysis at the bytecode level, and therefore
would not require access to the source code. At the same time, we
would lose important information such as the name of the arguments,
which are used to generate meaningful values. To solve this last
problem, our system could implement a more deterministic model in
constructing and filling in arguments required for the polling APIs,
making the system working on closed-source non-AOSP systems.
Challenges in detecting new phishing variants: At the moment,
our on-device detection system can detect and stop the most classic
of phishing attacks, the one in which the attacker infer which is the
application that will be used by the victim and, at the right time,
shows the spoofed and malicious activity to steal credentials. This
is the most used phishing variant and its effectiveness is well known.
However, we recognize that other interesting variants of this attack
are possible. For example, the attacker could execute her attack while
the victim application is running, showing a generic error message
and luring the victim to re-enter his credentials. Or, the attacker may
show an error message to the victim, even when the application is
not in use, in the hope that the victim enters the credentials. At the
moment, our system is not able to identify and block these variants
because these attack configurations are not necessarily based on
polling. We note that, to date, the effectiveness of these new variants
is unknown, and that it would be interesting to perform a user study.
XI. RELATED WORK
Detecting Side-Channel on Android. Several previous works
focused on finding vulnerable APIs leading to state inference attacks.
One such example is by Chen et al. [6], which found an information
leakage exploiting the shared-memory information present in the
/proc/$PID/statm file. Bianchi et al. [4] also found multiple
leaks in the “procfs” filesystem as well as vulnerable APIs that can be
used to mount state inference attacks, like getRunningTasks.
Two more recent proposals are [12], which exploited a11y infor-
mation leaks to also mount phishing attacks, and [11] which used
the transaction_log of the Binder component to list the
transactions occurring between processes. These works were mostly
based on manual analysis and inspired the community to work on
automatic detection of such vulnerabilities: ProcHarverster [26],
SCAnDroid [27] (already discussed),and our own work.
Phishing Attack and Defense. Phishing on Android is a form of
User Interface attack [10]. This paper focuses on the configuration
known as “task hijacking” and it has been subject of different works.
Several of them tried to identify new techniques to mount this attack,
like [12] [24] and [2]. Ren et al. [23] show how it is possible to mount
“task hijacking” attacks by exploiting vulnerabilities of the Android
multitasking and the Activity Manager Service design. However,
task hijacking is not the only available configuration: Xu et al. [34]
identified how it is possible to abuse fake notifications and fake
icons to lure the user into interacting with a malicious application
without exploiting side-channels. Yang et al. [36], instead, exploited
“Differential Context Vulnerabilies,” a class of vulnerabilities and
design flaws afflicting WebView, to mount phishing attack. On
the defensive side, several works tried to eradicate the phishing
problem on Android. Longfei et al. [33] combine several OCR
techniques to detect spoofed UI and verify if the activity shown
to the user is authentic or spoofed. A similar approach is shown
in [19]: they introduce the “Visual Similarity Perception” technique
to identify forged UI. Another work in the same category is [22]: it
designs the Android Window Integrity policy system which makes
sure that a sensitive activity cannot be obscured by other activities.
Cooley et al. [7] instead, introduces the concept of Trusted Activity
Chains to protect apps from phishing attacks by defining a sequences
of activities that should not be interrupted. This sequence cannot be
hijacked, otherwise a security warning will be raised. One last related
work is “LeaveMeAlone” [38], already discussed in Section IX-E.
XII. CONCLUSION
In this work, we show how the Android platform is still
affected by state inference attacks. We systematically extended the
attack surface, and we designed a new automatic framework that
discovered 18 new vulnerable APIs that leak sensitive information,
affecting both Android 8.1 and 9. As a second contribution, we
characterized polling behaviors in malicious and, more importantly,
benign apps, uncovering differences that allow their proper
classification. We leverage these findings to design and implement
a new on-device detection mechanism that blocks state inference
attacks at their root, even when exploiting unknown vulnerable
APIs, with a negligible overhead, and without sacrificing usability.
ACKNOWLEDGEMENTS
We would like to thank our shepherd, Ben Andow, and the
anonymous reviewers for their constructive feedback. As tradition
has it, we would also like to thank Betty Sebright for her support
over the past years.
15
REFERENCES
[1]
Jagdish Achara. Unveiling and Controlling Online Tracking. PhD thesis, 10
2016.
[2] Efthimios Alepis and Constantinos Patsakis. ”Trapped by the UI: The Android
Case”. In Marc Dacier, Michael Bailey, Michalis Polychronakis, and Manos
Antonakakis, editors, ”Proceedings of the International Symposium Research
in Attacks, Intrusions, and Defenses (RAID)”, pages 334–354, Cham, 2017.
Springer International Publishing.
[3] AndroidRank. AndroidRank, open android market data since 2011.
https://www.androidrank.org. Accessed: January 8, 2021.
[4] Antonio Bianchi, Jacopo Corbetta, Luca Invernizzi, Yanick Fratantonio,
Christopher Kruegel, and Giovanni Vigna. What the App is That? Deception
and Countermeasures in the Android User Interface. In Proceedings of the
2015 IEEE Symposium on Security and Privacy (S&P), pages 931–948,
Washington, DC, USA, 2015. IEEE Computer Society.
[5] Broadcom. Android malware finds new ways to derive current running
https://community.broadcom.com/symantecenterprise//community-
tasks.
home/librarydocuments/viewdocument?DocumentKey=d3231e0f-67a0-
4b31-8adb-4247ca23243dCommunityKey=1ecf5f55-9545-44d6-b0f4-
4e4a7f5f5e68tab=librarydocuments. Accessed: January 8, 2021.
[6] Qi Alfred Chen, Zhiyun Qian, and Z. Morley Mao. Peeking into Your App
Without Actually Seeing It: UI State Inference and Novel Android Attacks. In
Proceedings of the 23rd USENIX Conference on Security Symposium, pages
1037–1052, Berkeley, CA, USA, 2014. USENIX Association.
[7] Brett Cooley, Haining Wang, and Angelos Stavrou. Activity Spoofing and
Its Defense in Android Smartphones. In Proceedings of the International
Conference on Applied Cryptography and Network Security (ACNS), 2014.
[8] Corbin Davenport.
Google will remove Play Store apps that use
Accessibility Services
for anything except helping disabled users.
https://www.androidpolice.com/2017/11/12/google-will-remove-play-store-
apps-use-accessibility-services-anything-except-helping-disabled-users/.
Accessed: January 8, 2021.
[9] dtmilano. AndroidViewClient. https://github.com/dtmilano/
AndroidViewClient. Accessed: January 8, 2021.
[10] Adrienne Porter Felt and David Wagner. Phishing on Mobile Devices. In
Proceedings of the Web 2.0 Security and Privacy, 2011.
[11] Earlence Fernandes, Qi Alfred Chen, Justin Paupore, Georg Essl, J. Alex
Halderman, Z. Morley Mao, and Atul Prakash. ”Android UI Deception
Revisited: Attacks and Defenses”.
In Jens Grossklags and Bart Preneel,
editors, ”Financial Cryptography and Data Security”, pages 41–59, Berlin,
Heidelberg, 2017. Springer Berlin Heidelberg.
[12] Yanick Fratantonio, Chenxiong Qian, Simon Chung, and Wenke Lee. Cloak
and Dagger: From Two Permissions to Complete Control of the UI Feedback
Loop. In Proceedings of the IEEE Symposium on Security and Privacy (S&P),
San Jose, CA, May 2017.
[13] Google.
UsageStatsManager
Documentation.
https://developer.android.com/reference//app/usage/UsageStatsManager.
Accessed: January 8, 2021.
[14] Yacong Gu, Yao Cheng, Lingyun Ying, Yemian Lu, Qi Li, and Purui Su.
”Exploiting Android System Services Through Bypassing Service Helpers”.
In Robert Deng, Jian Weng, Kui Ren, and Vinod Yegneswaran, editors,
”Security and Privacy in Communication Networks”. Springer International
Publishing, 2017.
[15] Chandraiah Jagadeesh. Red Alert 2.0: Android Trojan targets security-seekers.
https://news.sophos.com/en-us/2018/07/23/red-alert-2-0-android-trojan-
targets-security-seekers/. Accessed: January 8, 2021.
[16] Kaspersky. Asacub Android Trojan: From Information Stealing to Financial
Fraud. https://www.kaspersky.com/about/press-releases/2016 asacub-android-
trojan-from-information-stealing-to-financial-fraud. Accessed: January 8,
2021.
[17] Sun Kevin. BankBot Found on Google Play and Targets Ten New
UAE Banking Apps.
https://blog.trendmicro.com/trendlabs-security-
intelligence/bankbot-found-google-play-targets-ten-new-uae-banking-apps/.
Accessed: January 8, 2021.
[18] Nick Kralevich. Honey, I Shrunk the Attack Surface. Adventures in Android
Security Hardening. https://www.blackhat.com/docs/us-17/thursday/us-17-
Kralevich-Honey-I-Shrunk-The-Attack-Surface-Adventures-In-Android-
Security-Hardening.pdf. Accessed: January 8, 2021.
16
[19] Luka Malisa, Kari Kostiainen, and Srdjan Capkun. Detecting Mobile Applica-
tion Spoofing Attacks by Leveraging User Visual Similarity Perception. In Pro-
ceedings of the Seventh ACM on Conference on Data and Application Security
and Privacy (CODASPY), pages 289–300, New York, NY, USA, 2017. ACM.
[20] Lorenz Nicole. MysteryBot - the Android malware that’s keylogger,
ransomware, and trojan.
https://blog.avira.com/mysterybot-the-android-