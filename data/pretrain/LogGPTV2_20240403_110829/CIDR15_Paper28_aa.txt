### Impala: A Modern, Open-Source SQL Engine for Hadoop

**Authors:**
Marcel Kornacker, Alexander Behm, Victor Bittorf, Taras Bobrovytsky, Casey Ching, Alan Choi, Justin Erickson, Martin Grund, Daniel Hecht, Matthew Jacobs, Ishaan Joshi, Lenni Kuff, Dileep Kumar, Alex Leblang, Nong Li, Ippokratis Pandis, Henry Robinson, David Rorke, Silvius Rus, John Russell, Dimitris Tsirogiannis, Skye Wanderman-Milne, Michael Yoder (Cloudera)

**Website:**
[http://impala.io/](http://impala.io/)

**Abstract:**
Cloudera Impala is a modern, open-source MPP (Massively Parallel Processing) SQL engine designed specifically for the Hadoop data processing environment. Impala provides low latency and high concurrency for BI (Business Intelligence) and analytic read-mostly queries on Hadoop, which are not typically delivered by batch frameworks such as Apache Hive. This paper presents Impala from a user’s perspective, provides an overview of its architecture and main components, and briefly demonstrates its superior performance compared to other popular SQL-on-Hadoop systems.

**1. Introduction**

Impala is an open-source, fully-integrated, state-of-the-art MPP SQL query engine designed to leverage the flexibility and scalability of Hadoop. Its goal is to combine the familiar SQL support and multi-user performance of traditional analytic databases with the scalability and flexibility of Apache Hadoop, along with the production-grade security and management extensions of Cloudera Enterprise. The beta release of Impala was in October 2012, and it became generally available (GA) in May 2013. The most recent version, Impala 2.0, was released in October 2014. Impala's ecosystem momentum continues to grow, with nearly one million downloads since its initial release. Its performance is on par with or exceeds that of commercial MPP analytic DBMSs, depending on the specific workload.

This paper discusses the services Impala provides to users and then presents an overview of its architecture and main components. The highest performance is achieved using HDFS (Hadoop Distributed File System) as the underlying storage manager, which is the focus of this paper. When there are notable differences in how certain technical aspects are handled in conjunction with HBase, we will note those in the text without going into detail.

Impala is the highest-performing SQL-on-Hadoop system, especially under multi-user workloads. As Section 7 shows, for single-user queries, Impala is up to 13x faster than alternatives and 6.7x faster on average. For multi-user queries, the gap widens: Impala is up to 27.4x faster than alternatives and 18x faster on average, or nearly three times faster on average for multi-user queries than for single-user ones.

The remainder of this paper is structured as follows:
- Section 2 provides an overview of Impala from the user’s perspective and highlights how it differs from a traditional RDBMS.
- Section 3 presents the overall architecture of the system.
- Section 4 covers the frontend component, which includes a cost-based distributed query optimizer.
- Section 5 discusses the backend component, responsible for query execution and runtime code generation.
- Section 6 presents the resource and workload management component.
- Section 7 evaluates the performance of Impala.
- Section 8 discusses the roadmap ahead.
- Section 9 concludes the paper.

Unlike other systems (often forks of PostgreSQL), Impala is a brand-new engine, written from the ground up in C++ and Java. It maintains Hadoop’s flexibility by utilizing standard components (HDFS, HBase, Metastore, YARN, Sentry) and can read the majority of widely-used file formats (e.g., Parquet, Avro, RCFile). To reduce latency, such as that incurred from using MapReduce or reading data remotely, Impala implements a distributed architecture based on daemon processes that run on the same machines as the rest of the Hadoop infrastructure. The result is performance that is on par with or exceeds that of commercial MPP analytic DBMSs.

**2. User View of Impala**

Impala is a query engine integrated into the Hadoop environment, utilizing several standard Hadoop components (Metastore, HDFS, HBase, YARN, Sentry) to deliver an RDBMS-like experience. However, there are some important differences that will be highlighted in the remainder of this section.

Impala is specifically designed for integration with standard business intelligence environments and supports most relevant industry standards. Clients can connect via ODBC or JDBC, and authentication is accomplished using Kerberos or LDAP. Authorization follows standard SQL roles and privileges, provided by another standard Hadoop component called Sentry, which also makes role-based authorization available to Hive and other components.

To query HDFS-resident data, users create tables using the familiar `CREATE TABLE` statement, which, in addition to providing the logical schema of the data, also indicates the physical layout, such as file format(s) and placement within the HDFS directory structure. These tables can then be queried using standard SQL. Data can be loaded into these tables using the `LOAD DATA` statement, which specifies the location of the table using HDFS’s API.

Similarly, Impala supports bulk data deletion by dropping a table partition using the `ALTER TABLE DROP PARTITION` statement. Since HDFS files cannot be updated, Impala does not support row-level updates. Instead, it focuses on efficient read and write operations for large-scale data analytics.

This article is published under a Creative Commons Attribution License (http://creativecommons.org/licenses/by/3.0/), which permits distribution and reproduction in any medium, as well as allowing derivative works, provided that you attribute the original work to the authors and CIDR 2015.

**Conference:**
7th Biennial Conference on Innovative Data Systems Research (CIDR’15)
January 4-7, 2015, Asilomar, California, USA.