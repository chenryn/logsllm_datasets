Springer. pp. 271-285.
Kao, B. and H. GarciaMolina (1993). Deadline assignment in a distributed soft realtime
system. Proceedings of the 13th International Conference on Distributed Computing
Systems. pp. 428-437.
Klingemann, J., J. Wäsch and K. Aberer (1999). Deriving Service Models in Cross-
Organizational Workflows. Proceedings of RIDE - Information Technology for
Virtual Enterprises (RIDE-VE '99), Sydney, Australia. pp. 100-107.
Kochut, K. J., A. P. Sheth and J. A. Miller (1999). "ORBWork: A CORBA-Based Fully
Distributed, Scalable and Dynamic Workflow Enactment Service for METEOR,"
Large Scale Distributed Information Systems Lab, Department of Computer
Science, University of Georgia, Athens, GA.
Leymann, F. (2001). Web Services Flow Language (WSFL 1.0). IBM Corporation,
http://www-4.ibm.com/software/solutions/webservices/pdf/WSFL.pdf.
Luo, Z. (2000). Knowledge Sharing, Coordinated Exception Handling, and Intelligent
Problem Solving to Support Cross-Organizational Business Processes. Ph.D.
Dissertation. Department of Computer Science, University of Georgia, Athens, GA .
Marjanovic, O. and M. Orlowska (1999). "On modeling and verification of temporal
constraints in production workflows." Knowledge and Information Systems 1(2):
157-192.
17
Miller, J. A., D. Palaniswami, A. P. Sheth, K. J. Kochut and H. Singh (1998).
"WebWork: METEOR2's Web-based Workflow Management System." Journal of
Intelligence Information Management Systems: Integrating Artificial Intelligence
and Database Technologies (JIIS) 10(2): 185-215.
Sadiq, S., O. Marjanovic and M. E. Orlowska (2000). "Managing Change and Time in
Dynamic Workflow Processes." The International Journal of Cooperative
Information Systems 9(1, 2): 93-116.
Shegalov, G., M. Gillmann and G. Weikum (2001). "XML-enabled workflow
management for e-services across heterogeneous platforms." The VLDB Joumal
10(1): 91-103.
Sheth, A. P., W. v. d. Aalst and I. B. Arpinar (1999). "Processes Driving the Networked
Economy." IEEE Concurrency 7(3): 18-31.
Son, J. H., J. H. Kim and M. H. Kim (2001). "Deadline Allocation in a Time-Constrained
Workflow." International Journal of Cooperative Information Systems (IJCIS)
10(4): 509-530.
Suchman, L. and E. Wynn (1984). "Procedures and Problems in the Office." Office:
Technology and People 2(2): 133-154.
Tang, J. and J. Veijalainen (1999). "Using Fragmentation To Increase Reliability For
Workflow Systems." Society for Design and Process Science 3(2): 33-48.
Wheater, S. M. and S. K. Shrivastava (2000). "Reliability Mechanisms in the OPENflow
Distributed Workflow System," Department of Computing Science, University of
Newcastle upon Tyne Technical Report 31, Esprit LTR Project No. 24962 - C3DS
First year Report, pp. 269-288.
18
Zinky, J., D. Bakken and R. Schantz (1997). "Architectural Support for Quality of
Service for CORBA Objects." Theory and Practice of Object Systems 3(1): 1-20.
Zisman, M. (1977). Representation, Specification and Automation of Office Procedures.
PhD Dissertation. Department of Business Administration, Wharton School,
University of Pennsylvania, Philadelphia, PA .
19
CHAPTER 2
MODELING QUALITY OF SERVICE FOR WORKFLOWS AND WEB SERVICE PROCESSES1
1 Cardoso, J.S., J. Miller, A. Sheth, and J. Arnold. Submitted to the Very Large Data
Bases Journal (05/27/2002).
20
2.1 ABSTRACT
Workflow management systems (WfMSs) have been used to support various types of
business processes for more than a decade now. In workflows for e-commerce and Web
services applications, suppliers and customers define a binding agreement or contract
between the two parties, specifying Quality of Service (QoS) items such as products or
services to be delivered, deadlines, quality of products, and cost of services. The
management of QoS metrics directly impacts the success of organizations participating in
e-commerce. Therefore, when services or products are created or managed using
workflows, the underlying workflow system must accept the specifications and be able to
estimate, monitor, and control the QoS rendered to customers. In this paper, we present a
predictive QoS model that makes it possible to compute the quality of service for
workflows automatically based on atomic task QoS attributes. To this end, we present a
model that specifies QoS and describe an algorithm and a simulation system in order to
compute, analyze and monitor workflow QoS metrics.
2.2 INTRODUCTION
Organizations are constantly seeking new and innovative information systems to better
fulfill their missions and strategic goals. With the advent and evolution of global scale
economies, organizations need to be more competitive, efficient, flexible, and integrated
in the value chain at different levels, including the informatino system level. In the past
decade, Workflow Management Systems (WfMSs) have been distinguished due to their
significance and their impact on organizations. WfMSs allow organizations to streamline
and automate business processes and reengineer their structure; in addition, they increase
efficiency and reduce costs.
Several researchers have identified workflows as the computing model that enables a
standard method of building Web services applications and processes to connect and
21
exchange information over the Web (Chen, Dayal et al. 2000; German Shegalov, Michael
Gillmann et al. 2001; Leymann 2001; Fensel and Bussler 2002). The new advances and
developments in e-services and Web services set new requirements and challenges for
workflow systems.
Our past research has involved the development of fully distributed enactment
services for workflow management. Our infrastructure, the METEOR system, and
specifically its OrbWork (Kochut, Sheth et al. 1999) and WebWork (Miller, Palaniswami
et al. 1998) enactment services have been used in prototyping and deploying applications
to various domains, such as bio-informatics (Hall, Miller et al. 2000), healthcare
(Anyanwu, Sheth et al. 1999), telecommunications (Luo 2000), the military (Kang,
Froscher et al. 1999), and university administration( CAPA 1997).
Our experience with real-world applications has made us aware that existing
workflow systems, both products and research prototypes, provide a set of indispensable
functionalities that manage and streamline business processes. Yet, organizations
operating in e-commerce and in global economies that include competitive and constantly
changing markets have a new set of requirements that have not been answered by current
workflow technologies. One important missing requirement is the management of
Quality of Service (QoS). Organizations operating in modern markets, such as e-
commerce activities and distributed Web services interactions, require quality of service
management. Products and services with well-defined specifications must be available to
customers. An appropriate control of quality leads to the creation of quality products and
services; these, in turn, fulfill customer expectations and achieve customer satisfaction .
While QoS has been a major concern in the areas of networking (Cruz 1995;
Georgiadis, Guerin et al. 1996), real-time applications (Clark, Shenker et al. 1992) and
middleware (Zinky, Bakken et al. 1997; Frolund and Koistinen 1998; Hiltunen,
Schlichting et al. 2000), few research groups have concentrated their efforts on enhancing
workflow systems to support workflow Quality of Service management.
22
For organizations, being able to characterize workflows based on QoS has four
distinct advantages. First, it allows organizations to translate their vision into their
business processes more efficiently, since workflow can be designed according to QoS
metrics. For e-commerce processes it is important to know the QoS an application will
exhibit before making the service available to its customers. Second, it allows for the
selection and execution of workflows based on their QoS, to better fulfill customer
expectations. As workflow systems carry out more complex and mission-critical
applications, QoS analysis serves to ensure that each application meets user requirements.
For e-commerce processes, it is important to know the QoS an application will exhibit
before making the service available to customers .Third, it makes possible the monitoring
of workflows based on QoS. Workflows must be rigorously and constantly monitored
throughout their life cycles to assure compliance both with initial QoS requirements and
targeted objectives. QoS monitoring allows adaptation strategies to be triggered when
undesired metrics are identified or when threshold values are reached. Fourth, it allows
for the evaluation of alternative strategies when adaptation becomes necessary. The
unpredictable nature of the surrounding environment has an important impact on the
strategies, methodologies, and structure of business processes. Thus, in order to complete
a workflow according to initial QoS requirements, it is necessary to expect to adapt,
replan, and reschedule a workflow in response to unexpected progress, delays, or
technical conditions. When adaptation is necessary, a set of potential alternatives is
generated, with the objective of changing a workflow as its QoS continues to meet initial
requirements. For each alternative, prior to actually carrying out the adaptation in a
running workflow, it is necessary to estimate its impact on the workflow QoS. For
example, when a workflow becomes unavailable due to the malfunction of its
components, it is indispensable to evaluate the adaptive strategies that can be applied to
correct the process. It is essential that the services rendered follow customer
specifications to meet their expectations and ensure satisfaction. Customer expectations
23
and satisfaction can be translated into the quality of service rendered. Organizationsh ave
realized that quality of service management is an important factor in their operations.
Quality models, such as ISO9000 (ISO9000 2002), have been created to help
organizations and their individual performers meet customer needs.
Workflow QoS is composed of different dimensions that are used to characterize
workflow schema and instances. The effort of developing a comprehensive QoS model
specification and its computation, covering various quality dimensions, is innovative.
Most of the research carried out in order to extend workflow systems’ capabilities to
include project management features has mainly been done for the time dmi ension (Kao
and GarciaMolina 1993; Bussler 1998; Eder, Panagos et al. 1999; Marjanovic and
Orlowska 1999; Dadam, Reichert et al. 2000; Sadiq, Marjanovic et al. 2000; Son, Kim et
al. 2001); this is only one of the dimensions under the workflow QoS umbrella. Even
though some WfMSs currently offer time management support, the technology available
is rudimentary (Eder, Panagos et al. 1999). Research on workflow reliability issues has
also been conducted, but the work was mostly on system implementation (Kamath,
Alonso et al. 1996; Tang and Veijalainen 1999; Wheater and Shrivastava 2000). The
Crossflow project (Klingemann, Wäsch et al. 1999; Damen, Derks et al. 2000; Grefen,
Aberer et al. 2000) is the one that most closely relates to our work. Not only is time
considered, but also the cost associated with workflow executions is taken into account.
In Crossflow, the information about past workflow execution is collected in a log. From
this information, a continuous-time Markov chain (CTMC) is derived. Since Markov
chains do not directly support the concept of parallel executions introduced by the and-
split/and-join structure, the power set of the parallel activities of the tasks inside an and-
split/and-join structure needs to be constructed. While for small workflows the
computation of a power set is affordable, this may not be the case for large workflows
with a parallel nature, for which the power set can reach millions of states. Our approach
24
uses a different concept to compute quality of service dimensions, one which does not
suffer from exponential complexity .
Our goal is to develop both a model for the specification of workflow QoS and
methods to analyze and monitor QoS. We start by investigating the relevant quality of
service dimensions which are necessary to correctly characterize workflows. We not only
target the time dimension, but also investigate other dimensions required to develop a real
and usable workflow QoS model. Once the QoS and associated dimensions are selected,
it is necessary to develop algorithms and to select methods to compute QoS. In
workflows, quality metrics are associated with tasks, and tasks compose workflows. The
computation of workflow QoS is done based on the QoS of the tasks that compose a
workflow. We present an algorithm and also show how a workflow system can be
coupled with a simulation system in order to predict QoS. Through this paper, the word
‘task’ or ‘workflow task’ corresponds to a traditional workflow task or a Web service. It
will later become evident that in order for our model to be applied to workflows, tasks or
Web service only have to adhere to the QoS model.
This paper is structured as follows. Section 2.3 describes a workflow process that
illustrates a real world scenario which will be used to exemplify QoS through the rest of
the paper. Based on our scenario, a set of new requirements is derived and the current
limitations of WfMSs technology are stated. In section 2.4, we introduce our workflow
QoS model and describe each of its dimensions. Section 2.5 describes how the quality of
service of workflow tasks is calculated. In Section 2.6, we present an algorithm to
compute and estimate workflow QoS, and we also describe how simulation techniques
can be used for QoS estimation. Section 2.7 presents an example of how to compute the
QoS for the workflow introduced in our initial scenario. Section 2.8 discusses the related
work in the QoS area; section 2.9 presents future work on workflow QoS. Finally, section
2.10 presents our conclusions.
25
2.3 SCENARIO
The Fungal Genome Resource laboratory (FGR 2002) at the University of Georgia has
realized that to be competitive and efficient it must adopt a new and modern information
system infrastructure. Therefore, a first step was taken in that direction with the adoption
of a workflow management system (METEOR (Kochut, Sheth et al. 1999)) to support its
laboratory processes (Hall, Miller et al. 2000). Since the laboratory supplies several
genome services to its customers, the adoption of a WfMS has enabled the logic of
laboratory processes to be captured in a workflow schema. As a result, all the services
available to customers are stored and executed under the supervision of the workflow
system.
2.3.1 WORKFLOW STRUCTURE
Before discussing this scenario in detail, we review the basis elements of the METEOR
workflow model.
A workflow is composed of tasks and transitions. Tasks are represented using a
circle, networks (sub-workflows) using rounded rectangles, and transitions are
represented using an arrow. Transitions express dependencies between tasks and are
associated with an enabling probability (p , p ,.., p ). When a task has only one outgoing
1 2 n
transition, the enabling probability is 1. In such a case, hte probability can be omitted
from the graph. A task with more than one outgoing transition can be classified as an
and-split or xor-split. And-split tasks enable all their outgoing transitions after completing
their execution. Xor-split tasks enable only one outgoing transition after completing their
execution. And-split tasks are represented with a ‘*’ and xor-split tasks are represented
with a ‘+’. A task with more than one incoming transition can be classified as ana nd-join
or xor-join. And-join tasks start their execution when all their incoming transitions are
enabled. Xor-join tasks are executed as soon as one of the incoming transitions is
enabled. As with and-split and xor-split tasks, and-join tasks and xor-join tasks are
26
represented with the symbol ‘*’ and ‘+’, respectively. When no symbol is present to
indicate the input or output logic of a task, then it is assumed to be an xor.
2.3.2 WORKFLOW DESCRIPTION
Genomic projects involve highly specialized personnel and researchers, sophisticated
equipment, and specialized computations involving large amounts of data. The
characteristics of the human and technological resources involved, often geographically
distributed, require a sophisticated coordination infrastructure to manage not only
laboratory personnel and equipment, but also the flow of data generated.
One of the services supplied by the research laboratory is the DNA Sequencing
workflow. A simplified version of the DNA Sequencing workflow is depicted in Figure
2-1. The complete description of the workflow can be found in (Cardoso 2002).
p
1
+
t1 + t5 p 2 t6 t7 t8
Setup
Test Quality Get Sequences Sequence Process
t2 t3 t
4 Processing Report
Prepare Prepare Clones Assembly
Sample and
Sequence
Figure 2-1 – DNA Sequencing workflow
The workflow is composed of eight main tasks: Setup, Prepare Sample, Prepare
Clone and Sequence, Assembly, Get Sequences, Sequence Processing, and Process
Report. Each individual task carries out a particular function; if necessary, the workflow
can be spread across multiple research centers.
The Setup task is responsible for initializing internal variables of the workfolw
process.
The second task, Prepare Sample, consists of isolating DNA from a biological
sample. The samples can be prepared using a variety of protocols. These protocols need
27
to be followed rigorously in order to obtain DNA that is not degraded in any form. A
correctly prepared sample will originate a better DNA sequencing, since the quality of the
DNA template is one of the most critical factors in DNA sequencing .
The task Prepare Clones and Sequence clones specific regions of the genome from
DNA isolated in the previous step. This step can be fully automated by computer control
(using, for example, a robotic system). This task also executes the sequencing, which
uses DNA sequencing machines to read each biochemical “letter” (A, G, C or T) of a
cloned DNA fragment. The output is composed of short decoded segments (a sequence
such as AGGCATTCCAG…). The use of automated sequencers has revolutionized the
field of bioinformatics by enabling scientists to catalogue sequence information hundreds
of times faster than was possible with pre-existing scanning techniques. This new
approach allows for automatic recognition, without major human intervention .
The Assembly task analyzes the DNA segments generated in the sequencing task.
This step includes the assembly of larger contiguous blocks of sequences of DNA from
small overlapping fragments. This is complicated by the fact that similar sequences occur
many times in many places of the genome .
The Test Quality task screens for the Escherichia coli (E. coli) contaminant in DNA
contigs. The clones grown in bacterial hosts are likely to be contaminated. A quick and
effective way to screen for the E. coli contaminant is to compare a given DNA sequence
to the E. coli genome. For E. coli, this task is made easier by the availability of its full
genome.
Get Sequences is a simple task that downloads the sequences created in the assembly
step, using the FTP protocol.
The Sequence Processing task analyzes the DNA segments generated in the