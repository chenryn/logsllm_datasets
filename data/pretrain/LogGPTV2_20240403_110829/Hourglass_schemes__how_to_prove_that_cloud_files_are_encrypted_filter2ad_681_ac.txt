server in the challenge-response below (Phase 3). In our sys-
tem deﬁnition we assume for simplicity that H is available
to the veriﬁer (algorithm verify(H, c, r) explicitly receives H
as input). In a practical implementation of an hourglass
protocol—particularly in cloud applications—it’s desirable
to have H stored only by the server.3 To verify a block of
H (returned by the server as a response to a challenge), the
client can pre-compute integrity checks for blocks of H. This
requires that the client itself possess the authentic H.
3.3 Phase 3: format checking
The hourglass protocol includes a ﬁnal challenge-response
component (executed multiple times at unpredictable time
intervals) in which the client can check that the server is
indeed storing the ﬁle in format H. In particular, in Phase
3 the client challenges the server to verify that the server
in fact stores H. In the challenge protocol the client chooses
t random block indices {ci}t
i=1 and challenges the server to
produce responses {ri}t
i=1 which are sent to the client.
The client then proceeds with the veriﬁcation of the re-
ceived responses by ﬁrst simply checking their correctness
with respect to the authentic blocks of H (originally pro-
duced in Phase 2). This is achieved by making use of the
integrity checks on the received blocks of H (as discussed
above). In addition, in our time-based constructions, the
client measures the time between its sending the challenge
and receiving a reply. It accepts the response if it arrives
3Ideally, the client’s storage needs should be of constant-
size (independent of the ﬁle size n); otherwise the beneﬁts
of data outsourcing diminish.
in time less than some security parameter T . We note that
as an optimization, the server can optionally aggregate re-
sponses before sending them to the client (as, e.g., in [27]).
We emphasize that the client’s integrity-checking mech-
anism is orthogonal to the rest of our hourglass protocols.
The client can use any standard scheme that supports ver-
iﬁcation of blocks of H, e.g., MACs or Merkle trees. Once
generated by the client, integrity checks can be stored by the
client, or preferably stored on the server and retrieved in the
challenge-response protocol. If MACs are used, the client re-
tains any secret keys required for veriﬁcation; if Merkle trees
are used, the client needs store no secret state but just the
root of the tree. For the remainder of the paper, we assume
the use of an integrity checking scheme and omit details.
4. HOURGLASS FUNCTIONS
We now present our concrete hourglass functions. To illus-
trate the challenge of constructing good hourglass functions,
we ﬁrst present a na¨ıve approach and brieﬂy explain why it
doesn’t work. Then we explore three constructions, namely:
1. A butterﬂy hourglass function in Section 4.1, that cor-
rects the ﬂaw in the na¨ıve approach. This approach
is timing based and assumes general bounds on stor-
age speed (that as we will discuss typically hold in all
existing storage media).
2. A permutation-based hourglass function in Section 4.2.
This timing-based scheme assumes a more speciﬁc stor-
age model: It relies on particular properties of rota-
tional hard-drives, namely their performance gap in
accessing sequential disk sectors versus randomly se-
lected ones (whose access induce an expensive drive
seek operation). Using non-cryptographic data-word
permutation, this construction is very eﬃcient.
3. An RSA-based hourglass function in Section 4.3. This
scheme involves application of an RSA signing opera-
tion (repeatedly for strong security properties) to indi-
vidual ﬁle blocks. It’s less eﬃcient than the other two
270schemes, but has the advantage of relying on the hard-
ness of the RSA problem, rather than timing, and it
supports random access to ﬁles as well as ﬁle updates.
We analyse the security guarantees for all of our pro-
posed constructions above (and we provide complete security
proofs in the full version of this paper). We experimentally
explore their performance in Section 5.
Challenges. Recall that both the encoded ﬁle G and the
hourglass transformation H in our framework are repre-
sented as n-block ﬁles, where each block has ﬁxed size. Our
ﬁrst two time-based hourglass functions that exploit delays
on data-access speed rely on a common underlying approach.
They transform G into H so that every block Hi function-
ally depends on a large set Si of blocks in G. Intuitively, an
hourglass function that achieves good “mixing” of this sort
seems to oﬀer good security. Suppose that a server cheats
by storing F instead of H. When challenged to produce Hi,
the server would have to retrieve all the blocks in Si. By
our speciﬁc bounds on data retrieval speed this task is slow
imposing a noticeable response delay.
We might then consider a simple and eﬃcient hourglass
function that “mixes” optimally, in the sense that every block
Hi depends on all of G. This is achievable with a full-ﬁle
(known-key) pseudorandom permutation (PRP) over G, com-
putable with two cipher-block chaining (CBC) passes over
the ﬁle, one in the forward direction and one in the reverse
direction: Then every block of H depends on all blocks of G.
Speciﬁcally, let IVf and IVb be initialization vectors and
Encκ(·) denote encryption under a block cipher. (The key
κ should be known to the server so that it can reverse
the PRP: This doesn’t impact the cryptographic eﬀect of
“mixing.”) The forward pass computes intermediate values
A1 = Encκ(G1 ⊕ IVf ), Ai = Encκ(Gi ⊕ Ai−1), for 1 < i ≤ n;
the backward pass computes output blocks Hn = Encκ(An⊕
IVb), and Hi = Encκ(Ai ⊕ Hi+1), for 1 ≤ i < n.
As it turns out, though, because this double-pass CBC
function involves chaining of blocks, it is possible for a cheat-
ing server to store F and a “shortcut,” namely staggered,
intermediate blocks within a chain. In particular, let H(cid:48) =
{Hv, H2v, . . . Hv×(cid:98)n/v(cid:99)} for some parameter v. These inter-
mediate blocks allow the server to compute blocks of H ef-
ﬁciently on the ﬂy from a compact H(cid:48). For small enough v,
the server could quickly compute a challenge block Hi (for
jv ≤ i ≤ (j + 1)v) by computing the forward chain seg-
ment Ajv, . . . A(j+1)v to retrieve H(j+1)v, and then comput-
ing the backward chain segment H(j+1)v, H(j+1)v−1, . . . , Hi.
Of course, a small value of v induces a large amount of extra
storage, thus parameter v needs to be chosen to balance the
storage overhead of intermediate blocks, as well as the cost
of computing responses to challenges on-the-ﬂy.
This approach fails because a single block Aj: (1) Sits on
the path of computation for many output blocks in H and
(2) Allows a server with knowledge of Aj (along with G)
to compress substantially the amount of computation along
many of these paths. Good mixing is thus a necessary but
not suﬃcient security condition.
This example illustrates the subtle challenges in construct-
ing a good hourglass function, and the motivation for our
next two hourglass function constructions.
4.1 A butterﬂy hourglass function
We now propose what we call a butterﬂy hourglass func-
tion. It replaces the ﬂawed, chained-block dependencies of
the na¨ıve double-pass CBC construction that we saw above,
with a structure of overlapping binary trees. At the same
time, this function is a full-ﬁle PRP, and so achieves the
security requirement of strong “mixing.” Storage of interme-
diate results in a butterﬂy provides little beneﬁt to a cheat-
ing server: As we explain, a server can’t eﬀectively compress
computational paths from G to H into a “shortcut.”
A butterﬂy function applies an (atomic) cryptographic op-
eration w to pairs of blocks in a sequence of d = log2 n
rounds, as shown in Figure 2.4 The resulting structure of
pairwise operations resembles a butterﬂy network commonly
used for parallelized sorting, FFT, etc.
Let G and H be n-block ﬁles, with each block having size
l bits (that is, |L| = |D| = l). Let w : L× L ↔ L× L denote
the atomic operation over a pair of ﬁle blocks. In practice,
we can instantiate w as a (known-key) PRP, i.e., a block
cipher. Formally, hourglass : Ln ↔ Ln computes in d rounds
a transformation from n-block input ﬁle G to output ﬁle H
as follows. Deﬁne G0[i] = Gi for all i. For 1 ≤ j ≤ d, we
compute the output Gj[1] . . . Gj[n] of level j as a function
of level j − 1, as speciﬁed in Algorithm 1 of Figure 2.
In Figure 2, we present an example butterﬂy network for
the case n = 8. In this representation, each set of values
Gj[1], . . . , Gj[n] is a row of nodes. Two edges connect the
input and output node pairs involved in each application
of w, where w itself is depicted as a small square. Globally,
hourglass involves n log2 n invocations of w to achieve strong
mixing of all input blocks (of G) into every output block (of
H), so its total computational cost is O(n log n). The func-
tion reverse-hourglass is computed in the obvious manner,
exploiting the invertibility of w.
Timing. Recall that the butterﬂy hourglass scheme is a
time-based one: It relies on storage access time as its re-
source bound. As we assume a limit on the server’s stor-
age access speed, the eﬀect of the timing bound T in the
challenge-response protocol is to impose an upper bound on
the amount of data the server can use to compute its re-
sponse. In our security analysis, we thus rely on the fact
that the time bound T translates into an upper bound of
at most n storage accesses that the server can make within
time T for some  < 1.
We’d like to highlight that we can support any existing
storage device (e.g., hard drives, solid-state drives) with this
model, but we need to set the parameters  and T depending
on the exact characteristics of the storage medium. On rota-
tional drives, for instance, disk access time is highly variable.
Sequential block accesses are generally much faster than ac-
cesses to blocks at distant locations on disk (or random ac-
cesses). Solid-state drives exhibit less variable data access
rates. When the challenge-response protocol is run remotely,
network latency will also impact the server’s response time
and needs to be considered when setting the time bound T .
With respect to the above considerations, the use of multi-
ple challenges, i.e., having the client request multiple blocks
of H, proves to be a useful approach in smoothing out the
variability in storage and network latencies. Below we give
a precise analysis for the security of the butterﬂy construc-
4Here we assume n is a power of 2. For n not equal to a
power of 2 we may use a diﬀerent permutation of outputs to
inputs between levels. We may also use a higher branching
butterﬂy network.
271Algorithm 1: Butterﬂy hourglass algorithm
1: for k from 0 to n/2j − 1 do
2:
3:
for i from 1 to 2j−1 do
(Gj[i + k · 2j], Gj[i + k · 2j + 2j−1]) ← w(Gj−1[i + k ·
2j], Gj−1[i + k · 2j + 2j−1]);
end for
4:
5: end for
Figure 2: Butterﬂy hourglass construction: Butterﬂy graph for n = 8 (left) and general algorithm (right).
tion for multiple challenges issued in the challenge-response
protocol.
Security analysis. We analyze the butterﬂy construction
using a standard “pebbling” argument that treats w as an
atomic operation and intermediate butterﬂy computations
as “pebbles” sitting on the nodes in the butterﬂy graph. (See,
e.g., [9, 10] for similar proofs.) In obtaining a conﬁguration
of its storage H(cid:48), an adversary A is allowed to play a peb-
ble game. It starts with a given conﬁguration of pebbles in
its storage H(cid:48) that includes both (some of) the original ﬁle
blocks of F (denoted “red pebbles”) and those blocks cor-
responding to (some of) the intermediary nodes in the but-
terﬂy computation from G to H (denoted “black pebbles”).
Given a pair of black pebbles in H(cid:48) input to a w operation
in the butterﬂy graph, they can be replaced in the pebble
game with the corresponding output pair of nodes. The goal
of the adversary is to ﬁnd a pebble conﬁguration within a
ﬁxed storage bound for H(cid:48) that will allow him to reply cor-
rectly to a large fraction of challenges, and at the same time
embed a large number of red pebbles in its storage H(cid:48).
Assumptions. Note that this way of modeling an adver-
sary A through a pebbling game embeds several assumptions
about the behavior of the adversary. First, the partitioning
assumption deﬁned in Appendix B follows naturally from
this model, as the adversary clearly separates its storage H(cid:48)
into red pebbles H(cid:48)
F (derived from ﬁle F ) and black pebbles
H(cid:48)
G (derived from formats G and H). Second, the pebbling
game encompasses an implicit assumption on w resembling
the random oracle model: Output nodes of a w computation
in the butterﬂy graph can only be computed with complete
knowledge of both input nodes. In this setting, we are able to
show a lower bound on the amount of extra storage s(cid:48) that
a cheating server needs, deﬁned as the amount of storage
needed for answering client challenges besides any plaintext
ﬁle blocks. (See also Appendix B for a deﬁnition of s(cid:48).)
Theorem 1. Suppose A can successfully respond to t chal-
lenges on randomly selected blocks of size l bits of H with
probability α, using extra storage of size s(cid:48) and up to n
timely block accesses. Then the following bound holds:
(cid:48) ≥ min{α1/tnl(1 − ), nl(1 − ) + log2 α1/t} .
s
In other words, the adversary’s storage overhead for cheat-
ing is linear in its probability of successfully responding
to challenges and inversely related to its ﬁle-block retrieval
rate. Let us give some intuition for the bound in Theorem 1
for t = 1 challenges. Ideally, an adversary achieving suc-
cess probability α of responding to a challenge would need
to store s(cid:48) = αnl bits in its storage (corresponding to all
the challenges that the adversary can successfully answer).
Nevertheless, there are two strategies for generating addi-
tional bits (besides those in its storage) that the adversary
can leverage to respond to challenges and improve its suc-
cess probability. The ﬁrst strategy is to access a number of
at most nl bits in time bound T (and it aﬀects the ﬁrst
term in the bound of Theorem 1). The second strategy is
to guess a number of bits in the butterﬂy network. As the
overall probability of success of the adversary in answering
challenges is α, an upper bound on the number of bits the
adversary can successfully guess is − log2(α). These guessed
bits aﬀect the second term in the bound of Theorem 1. A
detailed proof is given in the full version of the paper.
For example, suppose that the adversary would like to
leak plaintext ﬁle F through its storage, and it can retrieve
ﬁle blocks equivalent to at most 5% of F in the allotted
response time T . Then to respond successfully to a challenge
with 99% probability, A must incur an 94% overhead, i.e.,
it must store not just the n blocks of F , but an additional
.94n ﬁle blocks.
4.2 A permutation-based hourglass function
We now propose an extremely fast and simple hourglass
function, one that involves no cryptographic operations. Its
security depends upon the performance characteristics of
rotational drives. Such drives are optimized for sequential
ﬁle accesses. They perform relatively poorly for random ac-
cesses, i.e., accesses to widely distributed ﬁle locations, as
these result in an expensive disk seek operation.
Capitalizing on this characteristic, our hourglass function
computes H as a permutation of data elements in G. To re-
spond with a challenged block Hi on the ﬂy, then, a cheat-
ing server that has only stored partial information about Hi
must gather together disparate data elements of G (or F ).
This process induces a number of random accesses to disk,
slowing the server’s reply.
Recall that the encoding G of F consists of n blocks of l
bits. Let Gi[j] denote the jth symbol of Gi, where we deﬁne
a symbol as a sequence of z bits, e.g., a byte or word, for
z | l. Thus 0 ≤ j ≤ m − 1 with m = l/z. Let G[k] denote
the kth symbol in the symbolwise representation of G, for
0 ≤ k ≤ nm − 1.
Any permutation that scatters the symbols of G widely
across H can achieve good security. Our simple hourglass
function permutes the symbols of G with the property that
for each block Gi the permutation uniformly distributes the
272m symbols of Gi over the hourglass blocks in H. That is,
each of the hourglass blocks receives (cid:100)m/n(cid:101) or (cid:98)m/n(cid:99) sym-
bols of Gi. In addition, if m (cid:28) n, then the permutation
composes each block Hi of m symbols from widely staggered
positions in G.
We need to emphasize that the block size l of the encryp-
tion algorithm needs to be much larger than the symbol
size z used for permuting the encrypted ﬁle. This will re-
sult in a large value of m, the number of symbols within a
block. For large m, the intuition behind the security of the
permutation-based scheme is as follows. A malicious cloud
server that stores a permuted plaintext ﬁle has diﬃculty
responding to a challenge consisting of a randomly chosen
block Hi = (Gi1 [j1], . . . , Gim [jm]) of the hourglass transfor-
mation: To compute the k-th encrypted symbol Gik [jk] of a
challenge block, 1 ≤ k ≤ m, the server needs to read a large
plaintext block Fiv and encrypt it. Reading the m plain-
text blocks Fi1 , . . . , Fim requires up to m disk seeks. A large
value of m results in large disk access time and detection of