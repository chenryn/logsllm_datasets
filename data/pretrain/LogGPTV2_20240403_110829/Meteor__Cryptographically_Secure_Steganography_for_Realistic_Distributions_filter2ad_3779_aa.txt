title:Meteor: Cryptographically Secure Steganography for Realistic Distributions
author:Gabriel Kaptchuk and
Tushar M. Jois and
Matthew Green and
Aviel D. Rubin
Meteor: Cryptographically Secure Steganography
for Realistic Distributions
Gabriel Kaptchuk
Boston University
Boston, United States
PI:EMAIL
ABSTRACT
Despite a long history of research and wide-spread applications to
censorship resistant systems, practical steganographic systems ca-
pable of embedding messages into realistic communication distribu-
tions, like text, do not exist. We identify two primary impediments
to deploying universal steganography: (1) prior work leaves the
difficult problem of finding samplers for non-trivial distributions
unaddressed, and (2) prior constructions have impractical minimum
entropy requirements. We investigate using generative models as
steganographic samplers, as they represent the best known tech-
nique for approximating human communication. Additionally, we
study methods to overcome the entropy requirement, including
evaluating existing techniques and designing a new steganographic
protocol, called Meteor. The resulting protocols are provably indis-
tinguishable from honest model output and represent an important
step towards practical steganographic communication for mundane
communication channels. We implement Meteor and evaluate it
on multiple computation environments with multiple generative
models.
CCS CONCEPTS
• Security and privacy → Cryptography; Network security;
Pseudonymity, anonymity and untraceability.
KEYWORDS
Steganography; Applied Cryptography; Generative Models; Cen-
sorship Resistance
ACM Reference Format:
Gabriel Kaptchuk and Tushar M. Jois, Matthew Green, Aviel D. Rubin.
2021. Meteor: Cryptographically Secure Steganography for Realistic Dis-
tributions. In Proceedings of the 2021 ACM SIGSAC Conference on Com-
puter and Communications Security (CCS ’21), November 15–19, 2021, Vir-
tual Event, Republic of Korea. ACM, New York, NY, USA, 21 pages. https:
//doi.org/10.1145/3460120.3484550
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea
© 2021 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-8454-4/21/11...$15.00
https://doi.org/10.1145/3460120.3484550
Tushar M. Jois, Matthew Green, Aviel D. Rubin
Johns Hopkins University
Baltimore, United States
{jois,mgreen,rubin}@cs.jhu.edu
1 INTRODUCTION
The past several years have seen a proliferation of encrypted com-
munication systems designed to withstand even sophisticated, nation-
state attackers [1, 2]. While these systems maintain the confiden-
tiality of plaintext messages, the data transmitted by these tools is
easily identifiable as encrypted communication. This makes these
protocols easy targets for repressive regimes that are interested
in limiting free communication [3, 4]: for example, using network
censorship techniques such as those practiced by countries like
China [5–7]. Concrete attempts to suppress the encrypted commu-
nication technologies used to evade censors are now underway. For
example, China’s Great Firewall (GFW) not only prevents users
from accessing content deemed subversive, but it also actively de-
tects and blocks encryption-based censorship circumvention tech-
nologies such as Tor [8–10].
In regimes where cleartext communication is expected, the mere
use of encryption may be viewed as an indication of malicious
or subversive intent. To work around blocking and avoid suspi-
cion, users must make their communications look mundane. For
instance, Tor users in China have begun to leverage steganographic
techniques such as ScrambleSuit/obfs4 [11], SkypeMorph [12], Ste-
goTorus [13], TapDance [14, 15], and Format-Transforming Encryp-
tion [16]. These techniques embed messages into traffic that censors
consider acceptable.
While the current generation of steganographic tools is sufficient
to evade current censorship techniques, these tools are unlikely to
remain a sustainable solution in the future. While some tools pro-
vide strong cryptographic guarantees [12, 17, 18], this is achievable
only because they encode messages into (pseudo-)random cover-
text channels, i.e., replacing a random or encrypted stream with a
chosen pseudorandom ciphertext. Unfortunately, there is no guar-
antee that such channels will continue to be available: a censor can
systematically undermine such tools by preventing the delivery of
encrypted traffic for which it does not have a suitable trapdoor, (i.e.,
an access mechanism), or by selectively degrading the quality of
encrypted channels. An audacious, repressive regime could even
consider all encryption to be subversive, and drop all packets not
explicitly recognizable as meaningful plaintext. Rigorous studies of
the capabilities of the current GFW focus on other techniques [19–
22], but there is anecdotal evidence that encryption suppression
has begun to occur [23], including the blocking of some TLS 1.3
connections [24].
Steganography for Realistic Communication Channels. To
combat extreme censorship, there is a need for steganographic pro-
tocols that can produce stegotext (the steganographic equivalent
of ciphertext) that closely mimics real, innocuous communication.
Session 5C: Messaging and Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1529With such techniques, it would be impossible for a censor to se-
lectively repress communications, as subversive messages could
hide in benign communication. For instance, if dissidents could en-
code secret messages into mundane appearing emails, web-forum
posts, or other forms of “normal” human communication, censor-
ship would be impractical. The ideal tool for this task is universal
steganography: schemes which are able to securely hide sensitive
information in arbitrary covertext channels (the steganographic
term for communication channels). Even if the censor suspects
something, the secret message cannot be found — nor is there any
statistical evidence of its existence.
A key challenge in this setting is to identify a generator of some
useful distribution where sampling will produce symbols that are
identical (or at least close) to ordinary content present in a com-
munications channel. Given such a generator, numerous universal
steganographic constructions have been proposed that can sam-
ple from this distribution to produce a stegotext [25–31]. Unfortu-
nately, identifying useful generators is challenging, particularly for
complex distributions such as natural language text. To our knowl-
edge, the only practical attempts to achieve practical steganography
such natural communication channels have come from the natural
language processing (NLP) community [32–44]. While the result-
ing text is quite convincing, these works largely rely on insecure
steganographic constructions that fail to achieve formal defini-
tions [45–50]. In this work, we focus our attention on constructing
provably secure steganography for the kinds of distributions that
would be difficult for a censor block without suffering significant
social repercussions. To do so, we identify and overcome the barri-
ers to using steganographic techniques as practical tools to combat
network censorship.
Overcoming Shortcomings of Existing Steganographic Tech-
niques. Steganographic schemes that are able to encode into any
communication channel have been the subject of significant the-
oretical work, e.g., [25–31]. Generally, constructions rely on the
existence of an efficient sampler functionality that, on demand,
outputs a token (sometimes referred to as a document) that could
appear in the covertext channel. These tokens are then run through
a hash function that maps the token to a small, fixed number of
bits. Using rejection sampling, an encoder can find a token that
maps to some specific, desired bits, usually the first few bits of
a pseudo-random ciphertext. By repeatedly using this technique,
a sender can encode an entire ciphertext into a series of tokens,
and a receiver can recover the message by hashing the tokens and
decrypting the resulting bits. Security of these approaches relies on
the (pseudo-)randomness of the ciphertext and carefully controlling
the bias introduced by rejection sampling.
There are two significant barriers to using universal stegano-
graphic systems for censorship-resistant communication: (1) the
lack of appropriate samplers for real, desirable covertext channels,
like English text, and (2) the minimum entropy bounds required to
use existing techniques.
(1) Generative Models as Steganographic Samplers. Existing work
leaves samplers as an implementation detail. However, finding a
suitable sampler is critical to a practical construction. Sampling
is straightforward for simple covertext channels for which the
instantaneous probability distribution over the next token in the
channel can be measured and efficiently computed: draw random
coins and use them to randomly select an output from the explicit
probability distribution. Natural communication channels — the
most useful targets for practical steganography — are generally
too complex for such naïve sampling techniques. For example, it
is infeasible to perfectly measure the distribution of the English
language, and the usage of English continues to evolve and change.
Without access to perfect samplers, we explore steganographic
samplers that approximate the target channel. While this relaxation
introduces the risk that an adversary can detect a steganographic
message by distinguishing between the real channel and the ap-
proximation, this is the best we can do when perfect samplers cannot
be constructed. In this work, we propose to use generative models
as steganographic samplers, as these models are the best technique
for approximating complex distributions like text-based communi-
cation. While these models are still far from perfect, the quality of
generated content is impressive [51, 52] and continues to improve,
raising concerns about the disastrous societal impact of misuse [53].
Generative models operate by taking some context and model
parameters and outputting an explicit probability distribution over
the next token (for example, a character or a word) to follow that
context. During typical use, the next token to add to the output is
randomly sampled from this explicit distribution. This process is
then repeated, updating the context with the previously selected
tokens, until the output is of the desired length. Model creation,
or training, processes vast amounts of data to set model param-
eters and structure such that the resulting output distributions
approximate the true distributions in the training data.
The use of generative models as steganographic samplers facili-
tates the creation of stegotext that are provably indistinguishable
from honest model output, and thus good approximations of real
communication (although not indistinguishable from real communi-
cation). We show that the nature of generative models, i.e. a shared
(public) model and explicit probability distribution, can be lever-
aged to significantly increase concrete efficiency of steganographic
schemes. Our key insight is that a sender and receiver can keep
their models synchronized, and thus recover the same explicit prob-
ability distribution from which each token is selected, a departure
from traditional steganographic models. This allows the receiver
to make inferences about the random coins used by the sender
when sampling each token. If the message is embedded into this
randomness (in an appropriately protected manner), the receiver
can use these inferences to extract the original message.
(2) Steganography for Channels with High Entropy Variability. The
second barrier is the channel entropy requirements of most existing
schemes. Specifically, most universal steganographic schemes are
only capable of encoding messages into covertext channels if that
channel maintains some minimum entropy, no matter the context.
Real communication channels often encounter moments of low (or
even zero) entropy, where the remaining contents of the message
are fairly proscribed based on the prior context. For instance, if
a sentence generated by a model trained on encyclopedia entries
begins with “The largest carnivore of the Cretaceous period was
the Tyranosaurus” with overwhelming probability the next token
will be “Rex”, and any other token would be very unlikely. In many
existing steganographic proposals, if the hash of this next token
Session 5C: Messaging and Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1530(i.e. Hash(“Rex”)) does not match the next bits of the ciphertext, no
amount of rejection sampling will help the encoder find an appro-
priate token, forcing them to restart or abort. Thus, to ensure that
the probability of this failure condition is small, most classical con-
structions impose impractical entropy requirements. We investigate
overcoming this problem in two ways. First, we evaluate the practi-
cality of known techniques for public-key steganography, in which
an arbitrary communication channel is compiled into one with
sufficient entropy. Second, we leverage the structure of generative
models to create a new, symmetric key steganographic encoding
scheme called Meteor. Our key observation is that the best way
to adapt to variable entropy is to fluidly change the encoding rate
to be proportional to the instantaneous entropy. Together, these
could be used to build hybrid steganography, where the public-key
scheme is used to transmit a key for a symmetric key scheme.
Contributions. In this work we explore the use of modern gen-
erative models as samplers for provably secure steganographic
schemes. This provides the groundwork for steganography that
convincingly imitates natural, human communication once the
differences between generative models and true communication
become imperceptible. In doing so, we have the following contribu-
tions:
• Evaluation of Classical Public-Key Steganography in Prac-
tice. We evaluate the use of a classical public-key steganographic
scheme from [54]. We investigate adapting this scheme to work
with generative models, and show that known techniques intro-
duce prohibitively high overhead.
• Meteor. We present Meteor, a new symmetric-key, stateful, prov-
ably secure, steganographic system that naturally adapts to highly
variable entropy. We provide formalization for the underlying
techniques so that they can be easily applied to new generative
models as they are developed.
• Implementation and Benchmarking. Additionally, we imple-
ment Meteor and evaluate its performance in multiple computing
environments, including on GPU, CPU, and mobile. We focus
primarily on English text as our target distribution, but also in-
vestigate protocol generation. To the best of our knowledge, our
work is the first to evaluate the feasibility of a provably secure,
universal steganographic using text-like covertext channels by
giving concrete timing measurements.