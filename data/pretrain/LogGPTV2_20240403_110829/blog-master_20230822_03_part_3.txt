```    
2、取出并处理后的订单状态表     
```    
drop table if exists t_order_u;  
create unlogged table t_order_u (    
  id serial8 primary key,   -- 自增主键    
  order_id uuid unique,     -- 上游传递过来的订单号    
  cts timestamp not null,    -- 上游传递过来的订单创建时间     
  uts timestamp not null,   -- 订单处理时间    
  status int not null       -- 订单处理状态标记     
);      
```    
3、写入100万条订单队列    
```    
truncate t_order_q;  
insert into t_order_q (order_id, cts) select gen_random_uuid(), clock_timestamp() from generate_series(1,1000000);    
```    
4、编写压测函数, 在函数中根据pgbench client_id来取模选择对应的表分区进行处理. (在实际的应用中也可以使用类似手段.)   
[《PostgreSQL Oracle 兼容性之 - DBMS_SQL(存储过程动态SQL中使用绑定变量-DB端prepare statement)》](../201803/20180323_02.md)    
```  
create or replace function dyn_pre_orders(partitions int, client_id int) returns int8 as $$  
declare  
  suffix int := mod(client_id, partitions);   
begin  
  execute format('execute p%s(%s)', suffix, client_id);   
  return 0;   
  exception when others then  
    execute format('prepare p%s(int) as   
      with tmp as     
        (delete from t_order_q_%s where ctid = (select ctid from t_order_q_%s where pg_try_advisory_xact_lock(id) order by id limit 1) returning order_id, cts)    
      insert into t_order_u (order_id,cts,uts,status) select tmp.order_id, tmp.cts, now(), 1 from tmp;', suffix, suffix, suffix);   
    execute format('execute p%s(%s)', suffix, client_id);    
    return 0;  
end;  
$$ language plpgsql strict;  
```  
5、写pgbench压测脚本.     
```    
vi t4.sql    
\set clients 256  
select dyn_pre_orders(:clients, :client_id);  
```    
6、压测结果    
```    
pgbench -M extended -f ./t4.sql -n -r -P 1 -c 256 -j 8 -t 3906    
```    
```    
transaction type: ./t4.sql  
scaling factor: 1  
query mode: extended  
number of clients: 256  
number of threads: 8  
number of transactions per client: 3906  
number of transactions actually processed: 999936/999936  
latency average = 4.400 ms  
latency stddev = 12.287 ms  
initial connection time = 250.656 ms  
tps = 49892.858208 (without initial connection time)  
statement latencies in milliseconds:  
         0.000  \set clients 256  
         4.400  select dyn_pre_orders(:clients, :client_id);  
```    
tps: 49892.858208  
#### 对照    
test case | 传统方法 tps | skip locked方法 tps | advisory lock方法 tps | advisory lock + 分区方法 tps | 性能提升倍数  
---|---|---|---|---|---  
高并发秒杀(热点记录更新) | 2280.326174 | 3795.525190 | 12283.493260 | 49892.858208 | 21.9   
## 知识点      
1、advisory lock:   
轻量锁, 根据机器性能的不同, 每秒预计可处理50万次左右的轻量锁请求.    
轻量锁分为共享、独占、无堵塞尝试等请求, 同时持有锁的范围分为会话或事务周期.    
例如本例用到的 pg_try_advisory_xact_lock 表示事务级别尝试请求ID为N的轻量锁, 如果没有其他事务持有则返回true, 否则返回false.    
更多信息请参考末尾文章.    
2、select for update skip locked  
跳过被锁的行, 与advisory lock功能相似, 但是实现方法不一样, skip locked经过的逻辑比advisory lock长(skip locked要经过tuple search, 已经到表内部. 而advisory lock在搜索tuple之前已经完成了判断), 所以效率与之相比偏低.    
## 思考      
1、为什么第一种方法会这么慢呢?  
1920个连接中, 同一时刻只有1个连接能持有行锁, 它更新完释放锁, 然后等待队列中的第一个会话得到锁后进行更新. 因此始终有1919个连接处于等待状态, 处于等待队列中的第1920个会话要等的时间最长.  
在实际秒杀场景中, 库存可能没有这么多, 所以等待都是浪费掉的, 因为等拿到锁可以更新的时候, 库存都已经变成0了, 前面等于白白占用了会话连接和数据库资源.  
这种场景最容易引起数据库雪崩.      
2、对于业务场景2, 还有什么方法提升性能?   
2\.1、减少浪费的IO和cpu计算:     
- 在并发的情况下, order by id limit 1需要扫描若干行, 而不是1行, 因为可能有些ID已经被ad lock touch了, 浪费的pg_try_advisory_xact_lock() cpu ops计算次数约等于  n + n-1 + n-2 + ... +  n-n, 浪费的IO约等于N.     
优化方法:    
- 固定N个链接, 按ID hash mod 取不同的数据分片, 从而减少浪费的IO和cpu计算.     
- 或者将队列表拆分成几个分区表, 入库的时候 按id hash mode, 每个分区分配给不同的进程取数, 从而减少冲突和浪费的扫描提高并发.     
2\.2、提高index vacuum的频率, 减少因没有index version导致的垃圾数据判断带来的cpu和回表的IO浪费. 提升autovacuum_work_mem, 容纳下所有dead tuple ctid避免多次扫描index.     
优化方法:    
- 配置参数autovacuum_naptime、autovacuum_work_mem(或者老版本 maintenance_work_mem)即可.    
2\.3、使用并行vacuum, 配置max_parallel_maintenance_workers.     
2\.4、配置vacuum使用prefetch blocks, 减少io delay带来的vacuum 比较久的问题. (适合 单次IO delay较高, 但是吞吐没有瓶颈的云盘)  
2\.5、一次取出多条, 批量处理.     
2\.6、使用IOPS较高, 单次IO delay较低的本地nvme SSD.    
更多请参考末尾文章.     
## 参考      
##### 201801/20180105_03.md   [《PostgreSQL 秒杀4种方法 - 增加 批量流式加减库存 方法》](../201801/20180105_03.md)    
##### 201711/20171107_31.md   [《HTAP数据库 PostgreSQL 场景与性能测试之 30 - (OLTP) 秒杀 - 高并发单点更新》](../201711/20171107_31.md)    
##### 201611/20161117_01.md   [《聊一聊双十一背后的技术 - 不一样的秒杀技术, 裸秒》](../201611/20161117_01.md)    
##### 201509/20150914_01.md   [《PostgreSQL 秒杀场景优化》](../201509/20150914_01.md)    
##### 202101/20210121_04.md   [《PostgreSQL 用advisory lock 限制每一个分组中最多有多少条记录》](../202101/20210121_04.md)    
##### 202005/20200517_01.md   [《PostgreSQL 变态需求实现 - 堵塞式读, 不堵塞写 - 串行读,并行写 - advisory lock》](../202005/20200517_01.md)    
##### 201810/20181018_04.md   [《Locking issue with concurrent DELETE / INSERT in PostgreSQL - 解法 advisory lock》](../201810/20181018_04.md)    
##### 201707/20170720_01.md   [《advisory lock 实现高并发非堵塞式 业务锁》](../201707/20170720_01.md)    
##### 201705/20170507_02.md   [《PostgreSQL 使用advisory lock实现行级读写堵塞》](../201705/20170507_02.md)    
##### 201610/20161020_02.md   [《PostgreSQL 无缝自增ID的实现 - by advisory lock》](../201610/20161020_02.md)    
##### 201610/20161018_01.md   [《PostgreSQL 使用advisory lock或skip locked消除行锁冲突, 提高几十倍并发更新效率》](../201610/20161018_01.md)    
##### 202308/20230805_01.md   [《高并发队列处理业务的数据库性能优化 - IO扫描|CPU计算浪费 , 锁冲突 , 垃圾索引扫描浪费》](../202308/20230805_01.md)    
##### 202106/20210601_01.md   [《重新发现PostgreSQL之美 - 10 内卷 & 大禹治水》](../202106/20210601_01.md)    
##### 201810/20181009_01.md   [《PostgreSQL 随机记录返回 - 300倍提速实践 (随机数组下标代替order by random())》](../201810/20181009_01.md)    
##### 201804/20180416_02.md   [《PostgreSQL 网约车打车派单 高峰区域集中打车冲突优化1 - 宇宙大爆炸理论与PostgreSQL实践》](../201804/20180416_02.md)    
##### 201804/20180414_03.md   [《网约车打车派单系统思考 数据库设计与实现 - 每月投入6140元, 1天最多可盈利117亿  -_-!》](../201804/20180414_03.md)    
##### 201712/20171216_01.md   [《PostgreSQL 高并发任务分配系统 实践》](../201712/20171216_01.md)    
##### 201712/20171212_01.md   [《阿里云RDS PostgreSQL varbitx实践 - 流式标签 (阅后即焚流式批量计算) - 万亿级，任意标签圈人，毫秒响应》](../201712/20171212_01.md)    
##### 201711/20171126_01.md   [《PostgreSQL手机行业经营分析、决策系统设计 - 实时圈选、透视、估算》](../201711/20171126_01.md)    
##### 201708/20170803_01.md   [《菜鸟末端轨迹 - 电子围栏(解密支撑每天251亿个包裹的数据库) - 阿里云RDS PostgreSQL最佳实践》](../201708/20170803_01.md)    
##### 201707/20170720_02.md   [《云端海量任务调度数据库最佳实践 - 阿里云RDS PostgreSQL案例》](../201707/20170720_02.md)    
##### 201706/20170619_01.md   [《数据库平滑switchover的要素 - 会话资源漂移 - 业务无感、0感知切换探索》](../201706/20170619_01.md)    
##### 201704/20170424_04.md   [《PostgreSQL upsert功能(insert on conflict do)的用法》](../201704/20170424_04.md)    
##### 201704/20170412_01.md   [《快速入门PostgreSQL应用开发与管理 - 6 事务和锁》](../201704/20170412_01.md)    
##### 201703/20170322_03.md   [《数据库三十六计 - PostgreSQL 三十六计(下)》](../201703/20170322_03.md)    
##### 201701/20170105_08.md   [《PostgreSQL 流式数据处理(聚合、过滤、转换...)系列 - 8》](../201701/20170105_08.md)    
##### 201701/20170105_06.md   [《PostgreSQL 流式数据处理(聚合、过滤、转换...)系列 - 6》](../201701/20170105_06.md)    
##### 201701/20170105_05.md   [《PostgreSQL 流式数据处理(聚合、过滤、转换...)系列 - 5》](../201701/20170105_05.md)    
##### 201701/20170105_04.md   [《PostgreSQL 流式数据处理(聚合、过滤、转换...)系列 - 4》](../201701/20170105_04.md)    
##### 201701/20170105_01.md   [《PostgreSQL 流式数据处理(聚合、过滤、转换...)系列 - 1》](../201701/20170105_01.md)    
##### 201610/20161021_01.md   [《基于 阿里云 RDS PostgreSQL 打造实时用户画像推荐系统(varbitx)》](../201610/20161021_01.md)    
##### 201609/20160926_01.md   [《PostgreSQL 数据库开发规范》](../201609/20160926_01.md)    
##### 201604/20160429_01.md   [《[转载]postgresql 9.5版本之前实现upsert功能》](../201604/20160429_01.md)    
##### 201510/20151008_01.md   [《PostgreSQL数据库 OLTP高并发请求性能优化》](../201510/20151008_01.md)    
#### [期望 PostgreSQL|开源PolarDB 增加什么功能?](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
#### [PolarDB 云原生分布式开源数据库](https://github.com/ApsaraDB "57258f76c37864c6e6d23383d05714ea")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、内核开发公开课、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [PostgreSQL 解决方案集合](../201706/20170601_02.md "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")