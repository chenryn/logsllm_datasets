that while these examples have all jobs arrive at time
0, Hopper is designed to work in an online setting.
Best-Eﬀort Speculation: A simple approach, which
is also the most common in practice, is to treat specula-
tive tasks the same as regular tasks. The job scheduler
allocates resources for speculative tasks in a “best eﬀort”
manner, i.e., whenever there is an open slot.
Consider the example in Figure 1a with two jobs A
(4 tasks) and B (5 tasks) that are scheduled using the
SRPT policy. The scheduler has to wait until time 10
to ﬁnd an open slot for the speculative copy of A4, de-
spite detecting it was straggling at time 2.2 Clearly,
the scheduler can do better. If it had allocated a slot to
A’s speculative task at time 2 (instead of letting B use
it), then job A’s completion time would have reduced,
without slowing job B (see Table 1 for task durations).
Note that similar ineﬃciencies occur under Fair sche-
duling in this example.
Budgeted Speculation: The main problem for best-
eﬀort speculation is a lack of available slots for specu-
lation when needed. Thus, an alternative approach is
to have the job scheduler reserve a ﬁxed “budget” of
slots for speculative tasks. Budgeting the right size of
the resource pool for speculation, however, is challeng-
2At time 10, when A1 ﬁnishes, the job scheduler allocates
the slot to job A because its remaining processing is smaller
than job B’s. Job A speculates task A4 because A4’s trem =
torig−currentTime = 30−10 = 20 > tnew = 10 (see Table 1).
B3 A3 A2 A1 time 0 30 20 A4+ B1 10 A4 Slot 1 Slot 2 Slot 3 Slot 4 Slot 5 Slot 6 Slot 7 B2 B5 B4+ B4 A3 A2 A1 time B1+ 0 32 A4+ B1 12 A4 Slot 1 Slot 2 Slot 3 Slot 4 Slot 5 Slot 6 Slot 7 B2 B4 B3 B2+ B3+ B4+ B5 22 2 B2 A3 A2 A1 0 22 A4+ B1 12 A4 Slot 1 Slot 2 Slot 3 Slot 4 Slot 5 Slot 6 Slot 7 B4 B3 B3+ B4+ B5 time !"!#"!$"!%"!&"!’"()*+,"$-"$-"$-"&-"#-"(./0"#-"#-"#-"#-"#-"1"1#"1$"1%"1&"()*+,"#-"#-"#-"%-"(./0"#-"#-"#-"#-"381ing because of time-varying straggler characteristics and
ﬂuctuating cluster utilizations. If the resource pool is
too small, it may not be enough to immediately support
all the tasks that need speculation. If the pool is too
large, resource are left idle.
Figure 1b illustrates budgeted speculation with three
slots (slot 5 − 7) being reserved for speculation. This,
unfortunately, leads to slots 6 and 7 lying fallow from
time 0 to 12. If the wasted slot had been used to run a
new task, say B1, then job B’s completion time would
have been reduced. It is easy to see that similar wastage
of slots occurs with the Fair scheduler. Note that reserv-
ing one or two instead of three slots will not solve the
problem, since three speculative copies are required to
run simultaneously at a later time.
3.2 Challenges in Coordination
In contrast to the two baselines discussed above, Fig-
ure 2 shows the beneﬁt of coordinated decision making.
At time 0 − 10, we allocate 1 extra slot to job A (for
a total of 5 slots), thus allowing it to speculate task A4
promptly. After time 10, we can dynamically reallocate
the slots to job B. This reduces the average completion
time compared to both the budgeted and best-eﬀort
strategies. The joint design budgeted slot 5 until time
2 but after task A4 ﬁnished, it used all the slots.
Doing such dynamic allocation is already challeng-
ing in a centralized environment, and it becomes more
so in a decentralized setting. In particular, decentral-
ized speculation-aware scheduling has additional con-
straints. Since the schedulers are autonomous, there is
no central state and thus, no scheduler has complete in-
formation about all the jobs in the cluster. Further, ev-
ery scheduler has information about only a subset of the
cluster (the machines it probed). Since decentralization
is mainly critical for interactive jobs (sub-second or a
few seconds), time-consuming gossiping between sched-
ulers is infeasible. Finally, running all the schedulers on
one multi-core machine cramps that machine and caps
scalability, the original drawback they aim to alleviate.
In the above example, this means making the alloca-
tion as in Figure 2 when jobs A and B autonomously
schedule their tasks without complete knowledge of uti-
lizations of the slots or even each other’s existence.
Thus, the challenges for speculation-aware job schedul-
ing are: (i) dynamically allocating/budgeting slots for
speculation based on the distribution of stragglers and
cluster utilization while being (approximately) fair and,
in decentralized settings, (ii) using incomplete informa-
tion about the machines and jobs in the cluster.
4. Hopper: SPECULATION-AWARE
SCHEDULING
The central question in the design of a speculation-
aware job scheduler is how to dynamically (online) bal-
ance the slots used by speculative and original copies
of tasks across jobs. A given job will complete more
(a) β = 1.4
(b) β = 1.6
Figure 3: The impact of number of slots on single
job performance. The number of slots is normalized
by job size (number of tasks within the job). β is
the Pareto shape parameter for the task size distri-
bution. (In our traces 1 < β < 2.) The red vertical
line shows the threshold point.
quickly if it is allowed to do more speculation, but this
comes at the expense of other jobs in the system.
Hopper’s design is based on the insight that the bal-
ance between speculative and original tasks must dy-
namically depend on cluster utilization. The design
guidelines that come out of this insight are supported
by theoretical analysis in a simple model [8]. We omit
the analytic support due to space constraints and fo-
cus on providing an intuitive justiﬁcation for the design
choices. Pseudocode 1 shows the basic structure.3
We begin our discussion of speculation-aware job sche-
duling by introducing the design features of Hopper in
a centralized setting. We focus on single-phased jobs
in §4.1, and then generalize the design to incorporate
DAGs of tasks (§4.2), data locality (§4.4), and fairness
(§4.3). Finally, in §5, we discuss how to adapt the de-
sign to a decentralized setting.
4.1 Dynamic Resource Allocation
The examples in §3 illustrate the value of dynamic al-
location of slots for speculation. Our analysis indicates
that this dynamic allocation can be separated into two
regimes: whether the cluster is in “high” or “low” load.
The distinction between these two regimes follows
from the behavior of the marginal return (in terms of
performance) that jobs receive from being allocated slots.
It is perhaps natural to expect that the performance of
a job will always improve when it is given additional
slots (because these can be used for additional spec-
ulative copies) and that the value of additional slots
has a decreasing marginal return (because an extra slot
is more valuable when the job is given few slots than
when the job already has many slots). However, sur-
prisingly, a novel observation that leads to the design of
Hopper is that the marginal return of an extra slot has a
sharp threshold (a.k.a., knee) where, below the thresh-
old, the marginal return is large and (nearly) constant
3For ease of exposition, Pseudocode 1 considers the (online)
allocation of all slots to jobs present at time t. Of course,
in the implementation, slots are allocated as they become
available. See Pseudocode 2 and 3 for more details.
0.611.522.511.21.41.61.82(Normalized) number of slots(Normalized) completion time0.611.522.511.21.41.61.82(Normalized) number of slots(Normalized) completion time3821: procedure Hopper((cid:104)Job(cid:105) J(t), int S, ﬂoat β)
totalVirtualSizes ← 0
for each Job j in J(t) do
2:
3:
4:
5:
6:
7:
j.V (t) = (2/β) j.Trem
(cid:46) j.Trem: remaining number of tasks
(cid:46) j.V (t): virtual job size
totalVirtualSizes += j.V (t)
SortAscending(J(t), V (t))
if S < totalVirtualSizes then
for each Job j in J(t) do
j.slots ← (cid:98)min(S, j.V (t))(cid:99)
S ← max(S − j.slots, 0)
else
for each Job j in J(t) do
j.slots ← (cid:98)(j.V (t)/totalVirtualSizes) × S(cid:99)
Pseudocode 1: Hopper (centralized) allocating S slots
to the set of jobs present at time t, J(t), with task
distribution parameter β.
and, above the threshold, the marginal return is small
and decreasing.
Figure 3 illustrates this threshold using a simulation
of a sample job with 200 tasks (with Pareto sizes, com-
mon in production traces) and LATE [50] speculation
when assigned various numbers of slots. Crucially, there
is a marked change in slope beyond the vertical dashed
line, indicating the change in the marginal value of a
slot. Note, that such a threshold exists for diﬀerent job
sizes, speculation algorithms, etc. Further, in the con-
text of a simple model, we can prove the existence of a
sharp threshold [8].
The most important consequence of the discussion
above is that it is desirable to ensure every job is allo-
cated enough slots to reach the threshold (if possible)
before giving any job slots beyond this threshold. Thus,
we refer to this threshold as the “desired (minimum) al-
location” for a job or simply the “virtual job size”.
Guideline 1. It is better to give resources to a job
that has not reached the desired (minimum) allocation
than a job that has already reached the point.
This guideline yields the key bifurcation in the Hop-
per design, as illustrated in line 4 of Pseudocode 1. Ad-
ditionally, it highlights that there are three important
design questions, which we address in the following sec-
tions: (i) How can we determine the desired allocation
(virtual size) of a job? (ii) How should slots be allocated
when there are not enough to give each job its desired
allocation, i.e., when the cluster is highly utilized? (iii)
How should slots be allocated when there are more than
enough to give each job its desired allocation, i.e., when
the cluster is lightly utilized?
(i) Determining the virtual size of a job
Determination of the “desired (minimum) allocation”,
a.k.a., the “virtual” size, of a job is crucial to deter-
mining which regime the system is in, and thus how
slots should be allocated among jobs. While the vir-
tual job size is learned empirically by Hopper through
measurements of the threshold point during operation,
it is important to point out that it is also possible to
derive a useful static rule of thumb analytically, which
can give intuition for the design structure.
In particular, the task durations in production traces
(e.g., Facebook and Bing traces described in §7) typ-
ically follow a heavy-tailed Pareto distribution, where
the Pareto tail parameter β (which is often 1 < β < 2)
represents the likelihood of stragglers [12, 13, 14, 25].
Roughly, smaller β means that stragglers are more dam-
aging, i.e., if a task has already run for some time, there
is higher likelihood of the task running longer.
Given the assumption of Pareto task durations, we
can prove analytically (in a simple model) that the thresh-
old point deﬁning the “desired (minimum) allocation” is
max(2/β, 1), which corresponds exactly to the vertical
line in Figure 3 (see [8] for details). While we show only
two examples here, the estimate this provides is robust
across varying number of tasks, β, etc. 4
Thus, we formally deﬁne the “virtual job size” Vi(t)
for job i at any time t, as its number of remaining tasks
(Ti(t)) multiplied by 2/β (since β < 2 in our traces),
i.e., Vi(t) = 2
β Ti(t). This virtual job size determines
which regime the scheduler should use; see line 2 in
Pseudocode 1. In practice, since β may vary over time,
it is learned online by Hopper (see §7) making it adaptive
to diﬀerent threshold points as in Figure 3.
(ii) Allocation when the cluster is highly utilized
When there are not enough slots to assign every job its
virtual size, we need to decide how to distribute this
“deﬁciency” among the jobs. The scheduler could either
spread the deﬁciency across all jobs, giving them all less
opportunity for speculation, or satisfy as many jobs as
possible with allocations equaling their virtual sizes.
Hopper does the latter. Speciﬁcally, Hopper processes
jobs in ascending order of their virtual sizes Vi(t), giving
each job its desired (minimum) allocation until all the
slots are exhausted (see lines 3 − 5 in Pseudocode 1).
This choice is in the spirit of SRPT, and is motivated
both by the optimality of SRPT and the decreasing
marginal return of additional slots, which magniﬁes the
value of SRPT. Additionally, our theoretical analysis (in
[8]) shows the optimality of this choice in the context
of a simple model.
Guideline 2. At all points in time, if there are not
enough slots for every job to get its desired (minimum)
allocation, i.e., a number of slots equal to its virtual
size, then slots should be dedicated to the smallest jobs
and each should be given a number of slots equal to its
virtual size.
4We make the simplifying assumption that task durations of
each job are also Pareto distributed. A somewhat surprising
aspect given the typical values of β (1 < β < 2) is that even
when so many slots are allocated for redundant speculative
copies, faster “clearing” of tasks is overall beneﬁcial.
383Note that prioritization of small jobs may lead to un-
fairness for larger jobs, an issue we address shortly in
§4.3.
(iii) Allocation when the cluster is lightly utilized
At times when there are more slots in the cluster than
the sum of the virtual sizes of jobs, we have slots left
over even after allocating every job its virtual size. The
scheduler’s options for dividing the extra capacity are
to either split the slots across jobs, or give all the extra
slots to a few jobs in order to complete them quickly.
job sizes, i.e., every job i receives (Vi(t)/(cid:80)
In contrast to the high utilization setting, in this situ-
ation Hopper allocates slots proportionally to the virtual
j Vj(t))S
slots, where S is the number of slots available in the
system and Vi(t) is the virtual size; see line 7 in Pseu-
docode 1. Note that this is, in a sense, the opposite of
the prioritization according to SRPT.
The motivation for this design is as follows. Given
that all jobs are already receiving their (minimum) de-
sired level of speculation, scheduling is less important
than speculation. Thus, prioritization of small jobs is
not crucial, and the goal should be to extract the maxi-
mum value from speculation. Since stragglers are more
likely to occur in larger jobs (stragglers occur in propor-
tion to the number of tasks in a job, on average5), the
marginal improvement in performance due to an addi-
tional slot is proportionally higher for large jobs. Thus,
they should get prioritization in proportion to their size
when allocating the extra slots. Our analytic work in
[8] highlights that this allocation is indeed optimal in a
simple model.
Guideline 3. At all points in time, if there are enough
slots to give every job its desired (minimum) allocation,
then, the slots should be shared “proportionally” to the
virtual sizes of the jobs.
Since the guidelines specify allocations at the granu-
larity of every job, it is easy to cope with any ﬂuctua-
tions in cluster load (say, from lightly to highly utilized)
in an online system.
4.2