with expandedEntry then
end if
if k lies inside expandedEntry then
expandedEntry.size += 1
if expandedEntry.size > BLOCK-SIZE then
else if k intercepts with expandedEntry then
tmp = expandedEntry
if ExpandPreEntry(k, j, expandedEntry) then
end if
continue
return true
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
end if
18: end for
19: return false {no conﬂict}
break {succeed}
else
end if
expandedEntry = tmp
Algorithm analysis.
Our goal is to build a pre-classiﬁer which minimizes the num-
ber of general rules. However, an optimal solution is hard to ﬁnd.
Though our proposed heuristic algorithm may not be optimal, it is
proved to be effective and efﬁcient, achieving a median power re-
duction of 91% on real classiﬁers. Smarter heuristics might exist
(and the slack in our experiments is obviously upper bounded by
around 9%).
In the worst case, all the rules are overlapping in the 2-dimensional
space and all are marked general, resulting in no power reduction.
As expected, this is not common in practice since the maximum
number of overlapping rules is an order of magnitude smaller than
classiﬁer size (see Section 3).
4.3 Packet classiﬁcation with SmartPC
When a packet as shown in Figure 4(a) arrives, the pre-classiﬁer
entries P 0 and P 1 are consulted ﬁrst, and a matching entry P 0 is
found. Figure 3 shows the whole process of the classiﬁcation. The
TCAM block pointed to by P 0, which contains rules (0, 1, 5, 6, 8),
together with the general TCAM block are activated and searched
in parallel. Finally, the priorities of two matches, rule 1 and 7, are
compared, and the action of the higher priority rule 1, “accept”, is
returned as the ﬁnal classiﬁcation decision for the packet.
Entries in a pre-classiﬁer are non-overlapping. This property
guarantees that any incoming packet matches at most one entry in
the pre-classiﬁer. If the pre-classiﬁer is implemented in TCAM,
there is no need to consider the priorities of pre-classiﬁer entries.
While if pre-classiﬁer entries are allowed to overlap, the situation
becomes complicated when a given packet matches multiple entries
in the pre-classiﬁer, since we need to decide which entry has higher
priority. In addition, this property provides more ﬂexibility to the
implementation of a pre-classiﬁer as discussed below.
Each rule in a classiﬁer is either covered by only one pre-
classiﬁer entry, or marked as general. In other words, each rule
is associated with no more than one pre-classiﬁer entry. This prop-
erty ensures that rules in a classiﬁer are not replicated in TCAM
blocks, i.e., each rule is stored only once in one of the blocks.
Therefore, our approach is storage-efﬁcient. The only extra stor-
age in SmartPC is the storage used for storing the entries in a pre-
classiﬁer.
4.5 Implementation of a pre-classiﬁer
Considering the properties of pre-classiﬁers, there are a number
of approaches to implement a pre-classiﬁer.
For the special case of two-dimensional non-overlapping rectan-
gles (which is the case in our proposed pre-classiﬁer), a number
of geometric solutions have been reported with logarithmic time
complexity and near-linear space complexity [10, 6]. However, ge-
ometric approaches are not efﬁcient enough for pre-classiﬁers. For
the special case of pre-classiﬁers on just two header ﬁelds, Grid of
Tries [24] is an efﬁcient algorithmic solution.
TCAM is another alternative where a pre-classiﬁer is stored in
TCAM block(s). Our experimental results suggest that a pre-classiﬁer
usually contains a small number of entries which can ﬁt in one or
a few TCAM blocks. Plus TCAMs are much faster than SRAMs
(used in geometric and algorithmic solutions). Though geomet-
ric and algorithmic solutions may incur lower power consumption
than TCAM-based methods, we decide to store pre-classiﬁers in
TCAMs.
4.6 Rule update
Rule update overhead of SmartPC is generally less than that of
regular TCAMs.
In SmartPC, the ordering of TCAM entries is
kept within one speciﬁc block or within a small number of general
blocks when rules are added or deleted, while with regular TCAMs,
the ordering of TCAM entries has to be kept throughout all the
blocks.
To add a rule, the simplest approach is to insert the rule into
the general blocks 4. We can rerun our algorithms and construct
from scratch if the number of general blocks exceeds some pre-
deﬁned number. A slightly sophisticated approach could be that if
the rule is covered by a pre-classiﬁer entry (i.e., the pre-classiﬁer
entry matches the rule), and the speciﬁc block associated with this
pre-classiﬁer entry is not full, the rule is stored into the speciﬁc
block; otherwise, the rule can be simply inserted into the gen-
eral blocks. Depending on rule add/delete frequencies, we may
leave some holes in each block (e.g., by under loading the blocks
when constructing pre-classiﬁers) to reduce the overhead of mov-
ing rules.
To delete a rule, the block that stores the rule is ﬁrst found and
the rule is deleted. Only when the deletion of the rule changes the
ranges of the corresponding pre-classiﬁer entry, the pre-classiﬁer
entry is updated.
4Please note that the ordering of rules (i.e. rule priorities) must be
kept when inserting rules into blocks.
(a) Rule 0 in the classiﬁer forms the ﬁrst
pre-classiﬁer entry P0.
(b) Expand P0 to cover rule 1.
(c) Rule 5 intercepts with P0, expand P0
to cover 5. P0={0,1,5,6,8}.
(d) The
second
P1={2,3,4,9,10}.
pre-classiﬁer
entry
Figure 4: An example on how to build pre-classiﬁer (assume
block size = 5). Two pre-classiﬁer entries are formed and four
rules (7, 11, 12, 13) are marked as general.
4.4 Properties of pre-classiﬁers
We build an intelligent pre-classiﬁer that satisﬁes the following
properties for the purpose of simplicity and power-efﬁciency. Note
that pre-classiﬁer entries do not necessarily cover the whole two-
dimensional space.
Table 3: Summary of real classiﬁers
Name
R1
R2
R3
R4
R5
R6
R7
R8
R9
R10
Size MaxOverlaps Wildcard
5233
5626
5874
6339
7356
8063
8475
10054
11574
15181
49
63
98
47
38
64
31
1
18
32
48
16
5
35
4
0
334
177
271
143
Table 4: Summary of synthetic classiﬁers
Name
Size MaxOverlaps Wildcard
9802
9416
9497
9624
7255
99823
87039
99836
99866
99220
S1
S2
S3
S4
S5
S6
S7
S8
S9
S10
22
126
76
82
28
27
249
89
81
10
4
57
18
12
0
5
79
47
38
0
An update operation can be considered as a delete operation fol-
lowed by an add operation, as described above.
In summary, only one speciﬁc block or a few general blocks
plus at most one pre-classiﬁer entry need to be modiﬁed for each
rule add/delete, while regular TCAMs may have to modify all the
blocks.
5. EXPERIMENTAL RESULTS
We start this section with an overview of our experimental method-
ology. We then evaluate the power reduction of our scheme on real
classiﬁers and synthetic classiﬁers as well. We also look into the
performance of pre-classiﬁers.
5.1 Experimental methodology
We evaluate the performance of SmartPC using a number of real
classiﬁers and synthetic classiﬁers generated by ClassBench [21].
As we discussed in Section 3, the real classiﬁers were provided to
us by a large networking vendor and the speciﬁcs of the classiﬁer
are under an NDA and unfortunately cannot be released. So we are
presenting some statistics in Table 3.
Since the power consumption problem is more critical for large
classiﬁers, we only show results from 10 real classiﬁers with more
than 5,000 rules. The largest real classiﬁer we have access to has
a size of 15,181. Larger real classiﬁers are hard to ﬁnd since ISPs
or CAM venders do not release their classiﬁers. Therefore, we also
show results on synthetic classiﬁers of sizes 50,000 and 100,000.
Even larger synthetic classiﬁers show similar trend and the results
are not shown in the paper. Though our focus is on large classi-
ﬁers, we also evaluated the performance of small real classiﬁers.
SmartPC could achieve signiﬁcant power reductions on these clas-
siﬁers as well.
An important parameter is TCAM block size, which is usually
dependent on hardware design. In this paper, we show results with
different block sizes, to demonstrate how the performance of our
scheme is affected by block sizes. This work might aid TCAM
designers in choosing the right block size.
Table 3 summarizes the properties of the real classiﬁers used in
the evaluations. In this table, we show the size of each classiﬁer, the
maximum number of overlapping rules in two dimensions: source
and destination IP addresses, and the number of rules that are wild-
card(covers the whole space) on the two dimensions (as discussed
in Section 3). These wildcard rules need to be searched for every
packet classiﬁcation and will be marked as general. MaxOverlaps
indicates the maximum number of rules that need to be searched for
a given packet. This number gives us a rough estimation of block
size. As seen here, MaxOverlaps of most classiﬁers are smaller
than 128, and all of them are smaller than 512. We evaluated real
classiﬁers with six different block sizes, 32, 64, 128, 256, 512 and
1024, respectively.
Similarly, we summarize the properties of ten synthetic classi-
ﬁers in Table 4. We generate these classiﬁers using ClassBench by
setting rule size parameters to 10k and 100k and using ﬁve differ-
ent classiﬁer seeds. The properties MaxOverlaps and Wildcard are
similar to those of real classiﬁers.
To evaluate our scheme, we use power reduction as the main
metric, since the goal of this work is to reduce power consumptions
of TCAMs. As mentioned in Section 1, the main component of
power consumptions of TCAMs is proportional to the number of
searched entries [26]. Therefore, we employ a simple linear power
model to estimate the power reductions, though the real reductions
may be slightly different. Suppose a classiﬁer contains N rules,
and TCAM block size is B. In the default scheme without using
SmartPC, all the TCAM blocks that are used to store the classiﬁer,
deﬁned as X, must be searched for any packet classiﬁcation, where
X = ⌈N/B⌉.
To classify a packet using SmartPC, the pre-classiﬁer, and at
most one speciﬁc TCAM block plus general TCAM blocks are ac-
tivated. The power consumption of pre-classiﬁers depends on how
pre-classiﬁers are implemented. Here we assume pre-classiﬁer en-
tries are stored in TCAM blocks, and we count its power consump-
tion as well. Suppose G out of N rules are marked as general,
and P pre-classiﬁer entries are formed. With SmartPC, at most
Y = ⌈P/B⌉ + 1 + ⌈G/B⌉ blocks must be activated for each
packet classiﬁcation. Therefore, the percentage of power reduction
with SmartPC is X−Y
X × 100%. We use this deﬁnition to evaluate
power reductions of SmartPC.
5.2 Power reductions
We evaluate the percentage of power reductions on real and syn-
thetic classiﬁers by SmartPC. We ﬁrst evaluate how block sizes af-
fect the power reductions on all the classiﬁers. We evaluate these
classiﬁers using ﬁve different block sizes, 32, 64, 128, 256, 512,
and 1024, respectively. We plot the power reductions in Figure 5,
where x-axis represents block size and y-axis shows the percentage
of power reductions.
As shown in Figure 5(a), regardless of classiﬁer sizes, our scheme
achieves huge power reductions on real classiﬁers, ranging from
78% to 97%. We further observe that the power reduction of each
classiﬁer ﬂuctuates with block sizes. For most classiﬁers, the max-
imum power reduction occurs at block sizes 64, 128 and 256. With
block size 128, the average and median power reductions are 92%
and 87%, respectively.
Similarly, we evaluate the percentage of power reductions on
synthetic classiﬁers. As shown in Figure 5(b), SmartPC also achieves
huge power reductions on synthetic classiﬁers. For every classiﬁer
and block size combination, the power reduction is more than 60%,
with the highest reduction reaching 98%. With block size 128, the
average and median power reductions are 91% and 88%, respec-
tively. It is worth noting that power reductions on the ﬁve larger
)
%
(
n
o
i
t
c
u
d
e
r
r
e
w
o
P
 100
 90
 80
 70
 60
 50
 40
 10
R1
R2
R3
R4
R5
R6
R7
R8
R9
R10
 100
 1000
 10000
Block size (log scale)
(a) Real classiﬁers
)
%
(
n
o
i
t
c
u
d
e
r
r
e
w
o
P
 100
 90
 80
 70
 60
 50
 40
 10
S1
S2
S3
S4
S5
S6
S7
S8
S9
S10
 100
 1000
 10000
Block size (log scale)
(b) Synthetic classiﬁers