Function
Reduction
0 > d ≤ 350m ± e1
98.65%
0 > d ≤ 350m ± e1
99.58%
0 > d ≤ 350m ± e1
99.58%
0 > v ≤ 70mph ± e2
94.25%
|aux_price - reported_price|  threshold
when used in isolation. Neighbors by Ring uses an out-of-band chan-
nel for verifying a new user (i.e. email), Police Detector assigns user
IDs based on unique Android IDs, and Gas Buddy and Google Maps
use client certificates, but they are all bypassable either through
technical means as we showed in our work or physical means [45].
On the other hand, reputation schemes have gained in popularity
and found applications in other crowdsourcing domains (e.g. online
reviews) but suffer from a cold start problem, which an adversary
can leverage to inject only a few but high impact values before they
are penalized. Input validation can be a great addition in our defense
arsenal which can minimize the adversary’s incentive during the
cold start period but also throughout the lifetime of a participant
account, while rendering the amount of reportings to be potentially
checked more tractable. Such strategies are easy to implement, can
be immediately deployed with a software update on the server side,
and do not assume any capabilities on the participants’ devices.
To demonstrate this, we show the resounding effect simple input
validation functions can have (Table 4). For example, restricting
running distances to the world record (350 miles) allowing for a
20% error—which is much higher than the 13m smartphone GPS
empirical error [38]—it would constitute a 98.65%, 99.58% and 95.80%
reduction of the maximum allowed value for Strava, Map My Run
and Fitbit respectively. Constraining accepted bus speeds to the
maximum speed limit allowed (in the UK buses speed limit is 70mph
in motorways), allowing for a 20% error in estimation, it would
constitute a 94.25% reduction in the speed allowed for Transit, which
greatly restricts the effect an adversary can have on bus arrival
times. Similarly, location-based services can geo-fence reports. To
illustrate this we used the CE-2D strategy to generate 2701 values
but filtered out any value that is not within a threshold distance
from its nearest road segment. We found that only 3 and 33 of them
would be accepted which constitutes a 99.89% and 98.78% reduction
respectively. For pricing services, one can restrict inputs according
to market price fluctuation. Basket Savings can leverage auxiliary
data sources [32, 49] for this. Moreover, it could leverage majority
voting or employ other verification mechanisms before displaying
a value, since grocery item prices do not change frequently [41].
Even if such restrictions are present, a determined adversary can
sometimes generate realistic inputs as we demonstrated in the case
of NbR. Detecting fakes is an open and challenging problem. We
used the GPT-2 Output Detector [46] which is specifically designed
to detect inputs generated by the GPT-2 model. This resulted in
a poor precision and recall of 55% and 53% respectively. While
working toward improving our automated detection capability,
visual hints about a reporting account’s maturity and reputation
can help users better judge the veracity of crowdsourced values.
This is especially true when real-time distribution is paramount.
10 RELATED WORK
Prior work demonstrated data poisoning in crowdsourcing [25, 40,
51, 55, 56]. Our work focuses on services interfacing with their
users through mobile apps. More related are [42, 53] but study only
specific MCS domains. Polakis et al. [42] demonstrated that two
location-based MCSs are vulnerable to fake check-ins. In contrast
we observe a more general vulnerability of IIV and use our obser-
vation to design a broader study to characterize the exposure of
MCS across domains to improper inputs. Proposed defenses include
majority voting [37, 48], reputation systems [54, 58] or even trusted
sensing [31]. However, these are not always applied in MCSs and
even if they do their effect is limited when applied in isolation.
Related to our framework, prior works also perform analysis
from the perspective of mobile apps but focus on IoT devices rather
than MCSs [26, 27]. Others analyze the UI of mobile apps similar
to our DEM approach [33, 34, 39, 59]. In contrast with those works,
we do not aim to identify privacy leaks through the UI but instead
automate navigation and value fuzzing. Zhao et al. [59] also focus
on input validation but solely on the mobile app side rather than a
remote web service, while others have studied how Android appli-
cations’ network traffic can be intercepted [28, 30, 35, 47]. Further-
more, Zhao et al. [60] also reverse engineers API calls for Android
apps but their work is mostly centered on data leakage vulnerabili-
ties rather than discovering IIV vulnerabilities. We employ similar
monitoring strategies which we augment with dynamic instrumen-
tation for bypassing certificate pinning. Lastly, work is undergoing
on fake text generation and detection [23, 29, 36, 43, 46, 56, 57].
Most of them are either not tested in practice or focus on social
platforms rather than MCSs. In our work, we leverage such state
of the art text generation strategies which we show how they can
be combined with spoofed network requests embodied in end-to-
end framework for analyzing real-world MCS services exposure to
improper input injection attacks. Lastly, our framework bares simi-
larities with model-based testing [24, 44, 44, 50] as it can be seen
as a simplistic abstract model for MSCs behavior (the system under
test). Building on this modeling is a promising future direction.
11 CONCLUSION
In this work, we developed a framework for analyzing improper
input validation vulnerabilities of mobile crowdsourcing services.
We successfully apply the framework on 8 high-profile services
across 5 application domains and found that they are all severely
exposed to improper input injection attacks. Our analysis showed
that arbitrary inputs from fake accounts and devices are accepted
as genuine, allowing an adversary to fake reports for robberies and
gunshots in safety services, to fake fitness activities with supernat-
ural performance, and to manipulate grocery items prices among
others. Then, we discuss and showcase how simple to implement
953Characterizing Improper Input Validation Vulnerabilities of Mobile Crowdsourcing Services
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
and deploy input validation strategies can greatly reduce the IIV
attack surface and complement existing defenses.
ACKNOWLEDGMENTS
This work was partially supported by the U.S. National Science
Foundation (CNS-1956445).
REFERENCES
[1] 2000. Gas Buddy. https://www.gasbuddy.com.
[2] 2000. OpenCV. https://opencv.org/.
[3] 2007. Map My Run. https://www.mapmyrun.com/.
[4] 2008. Google Maps. https://www.google.com/maps.
[5] 2008.
UI Automator.
automator.html.
https://developer.android.com/training/testing/ui-
[6] 2009. Fitbit. https://www.fitbit.com.
[7] 2009. Strava. https://www.strava.com/.
[8] 2009. Strava Labs. https://labs.strava.com/.
[9] 2011. Genymotion Android Emulator. https://www.genymotion.com/.
[10] 2012. Transit. https://transitapp.com/.
[11] 2015. ToiFi. https://play.google.com/store/apps/details?id=com.apprevelations.
indiantoiletfinder.
[12] 2016. Apktool. https://ibotpeaches.github.io/Apktool/.
[13] 2016. Basket. http://basket.com/.
[14] 2017. Appium. http://appium.io/.
[15] 2017. Frida. https://frida.re/.
[16] 2018. Neighbors App by Ring. https://store.ring.com/neighbors.
[17] 2018. Police Detector (Speed Camera Radar). https://play.google.com/store/apps/
details?id=tat.example.ildar.seer&hl=en_GB.
[18] 2019. Google Images Download — Google Images Download documentation.
https://google-images-download.readthedocs.io/en/latest/index.html.
[19] 2019. minimaxir/gpt-2-simple. https://github.com/minimaxir/gpt-2-simple.
[20] 2020. Google Cloud Natural Language. https://cloud.google.com/natural-
language/.
[21] 2020. You VS the Year 2020 | MapMyFitness. https://www.mapmyrun.com/
challenges/yvsty2020/register.
[22] 2021. Project Website. https://sites.google.com/view/data-poisoning-mcs.
[23] David Ifeoluwa Adelani, Haotian Mai, Fuming Fang, Huy H Nguyen, Junichi
Yamagishi, and Isao Echizen. 2020. Generating sentiment-preserving fake online
reviews using neural language models and their human-and machine-based
detection. In International Conference on Advanced Information Networking and
Applications. Springer, 1341–1354.
[24] Josip Bozic and Franz Wotawa. 2012. Model-based testing-from safety to security.
In Proceedings of the 9th Workshop on Systems Testing and Validation (STV’12).
9–16.
[25] Bogdan Carbunar and Rahul Potharaju. 2012. You unlocked the mt. everest badge
on foursquare! countering location fraud in geosocial networks. In 2012 IEEE 9th
International Conference on Mobile Ad-Hoc and Sensor Systems (MASS 2012). IEEE,
182–190.
[26] Jiongyi Chen, Wenrui Diao, Qingchuan Zhao, Chaoshun Zuo, Zhiqiang Lin,
XiaoFeng Wang, Wing Cheong Lau, Menghan Sun, Ronghai Yang, and Kehuan
Zhang. 2018. IoTFuzzer: Discovering Memory Corruptions in IoT Through App-
based Fuzzing.. In NDSS.
[27] Soteris Demetriou, Nan Zhang, Yeonjoon Lee, XiaoFeng Wang, Carl A Gunter,
Xiaoyong Zhou, and Michael Grace. 2017. HanGuard: SDN-driven protection
of smart home WiFi devices from malicious mobile apps. In Proceedings of the
10th ACM Conference on Security and Privacy in Wireless and Mobile Networks.
122–133.
[28] Sascha Fahl, Marian Harbach, Thomas Muders, Lars Baumgärtner, Bernd
Freisleben, and Matthew Smith. 2012. Why Eve and Mallory love Android: An
analysis of Android SSL (in) security. In Proceedings of the 2012 ACM conference
on Computer and communications security. 50–61.
[29] Sebastian Gehrmann, Hendrik Strobelt, and Alexander M Rush. 2019. Gltr: Statis-
tical detection and visualization of generated text. arXiv preprint arXiv:1906.04043
(2019).
[30] Martin Georgiev, Subodh Iyengar, Suman Jana, Rishita Anubhai, Dan Boneh, and
Vitaly Shmatikov. 2012. The most dangerous code in the world: validating SSL
certificates in non-browser software. In Proceedings of the 2012 ACM conference
on Computer and communications security. 38–49.
[31] Peter Gilbert, Landon P Cox, Jaeyeon Jung, and David Wetherall. 2010. Toward
trustworthy mobile sensing. In Proceedings of the Eleventh Workshop on Mobile
Computing Systems & Applications. 31–36.
[32] gov.uk. 2020. United Kingdom milk prices and composition of milk statistics
notice (data for April 2020). https://www.gov.uk/government/publications/uk-
milk-prices-and-composition-of-milk/united-kingdom-milk-prices-and-
composition-of-milk-statistics-notice-data-for-june-2019.
[33] Yuyu He, Lei Zhang, Zhemin Yang, Yinzhi Cao, Keke Lian, Shuai Li, Wei Yang,
Zhibo Zhang, Min Yang, Yuan Zhang, et al. 2020. TextExerciser: Feedback-driven
Text Input Exercising for Android Applications. In 2020 IEEE Symposium on
Security and Privacy. IEEE.
[34] Jianjun Huang, Zhichun Li, Xusheng Xiao, Zhenyu Wu, Kangjie Lu, Xiangyu
Zhang, and Guofei Jiang. 2015. {SUPOR}: Precise and Scalable Sensitive User
Input Detection for Android Apps. In 24th {USENIX} Security Symposium
({USENIX} Security 15). 977–992.
[35] J. Hubbard, K. Weimer, and Y. Chen. 2014. A study of SSL Proxy attacks on
Android and iOS mobile applications. In 2014 IEEE 11th Consumer Communications
and Networking Conference (CCNC). 86–91.
[36] Mika Juuti, Bo Sun, Tatsuya Mori, and N Asokan. 2018. Stay on-topic: Generating
context-specific fake restaurant reviews. In European Symposium on Research in
Computer Security. Springer, 132–151.
[37] Hongwei Li and Bin Yu. 2014. Error rate bounds and iterative weighted majority
voting for crowdsourcing. arXiv preprint arXiv:1411.4086 (2014).
[38] Krista Merry and Pete Bettinger. 2019. Smartphone GPS accuracy study in an
urban environment. PloS one 14, 7 (2019).
[39] Yuhong Nan, Min Yang, Zhemin Yang, Shunfan Zhou, Guofei Gu, and XiaoFeng
Wang. 2015. Uipicker: User-input privacy identification in mobile applications.
In 24th {USENIX} Security Symposium ({USENIX} Security 15). 993–1008.
[40] Victor Naroditskiy, Nicholas R Jennings, Pascal Van Hentenryck, and Manuel
Cebrian. 2013. Crowdsourcing dilemma. arXiv preprint arXiv:1304.3548 (2013).
[41] Martin Pesendorfer. 2002. Retail sales: A study of pricing behavior in supermar-
kets. The Journal of Business 75, 1 (2002), 33–66.
[42] Iasonas Polakis, Stamatis Volanis, Elias Athanasopoulos, and Evangelos P
Markatos. 2013. The man who was there: validating check-ins in location-
based services. In Proceedings of the 29th Annual Computer Security Applications
Conference. 19–28.
[43] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
Sutskever. 2019. Language models are unsupervised multitask learners. OpenAI
Blog 1, 8 (2019), 9.
[44] Ina Schieferdecker. 2012. Model-Based Fuzz Testing. In 2012 IEEE Fifth Interna-
tional Conference on Software Testing, Verification and Validation. IEEE, 814–814.
[45] Weckert Simon. 2020. Google Maps Hacks. http://www.simonweckert.com/
googlemapshacks.html.
[46] Irene Solaiman, Miles Brundage, Jack Clark, Amanda Askell, Ariel Herbert-Voss,
Jeff Wu, Alec Radford, and Jasmine Wang. 2019. Release strategies and the social
impacts of language models. arXiv preprint arXiv:1908.09203 (2019).
[47] David Sounthiraraj, Justin Sahs, Garret Greenwood, Zhiqiang Lin, and Latifur
Khan. 2014. Smv-hunter: Large scale, automated detection of ssl/tls man-in-
the-middle vulnerabilities in android apps. In In Proceedings of the 21st Annual
Network and Distributed System Security Symposium (NDSS’14. Citeseer.
[48] Dapeng Tao, Jun Cheng, Zhengtao Yu, Kun Yue, and Lizhen Wang. 2018. Domain-
weighted majority voting for crowdsourcing. IEEE transactions on neural networks
and learning systems 30, 1 (2018), 163–174.
[49] usda.gov. 2019. Price Spreads from Farm to Consumer. https://www.ers.usda.
gov/data-products/price-spreads-from-farm-to-consumer/.
[50] Mark Utting, Alexander Pretschner, and Bruno Legeard. 2012. A taxonomy of
model-based testing approaches. Software testing, verification and reliability 22, 5
(2012), 297–312.
[51] Gang Wang, Bolun Wang, Tianyi Wang, Ana Nika, Bingzhe Liu, Haitao Zheng,
and Ben Y Zhao. 2015. Attacks and defenses in crowdsourced mapping services.
CoRR, abs/1508.00837 (2015).
[52] Gang Wang, Bolun Wang, Tianyi Wang, Ana Nika, Haitao Zheng, and Ben Y
Zhao. 2016. Defending against sybil devices in crowdsourced mapping services.
In Proceedings of the 14th Annual International Conference on Mobile Systems,
Applications, and Services. 179–191.
[53] Gang Wang, Bolun Wang, Tianyi Wang, Ana Nika, Haitao Zheng, and Ben Y
Zhao. 2018. Ghost riders: Sybil attacks on crowdsourced mobile mapping services.
IEEE/ACM transactions on networking 26, 3 (2018), 1123–1136.
[54] Kun Wang, Xin Qi, Lei Shu, Der-jiunn Deng, and Joel JPC Rodrigues. 2016.
Toward trustworthy crowdsourcing in the social internet of things. IEEE Wireless
Communications 23, 5 (2016), 30–36.
[55] Kan Yang, Kuan Zhang, Ju Ren, and Xuemin Shen. 2015. Security and privacy in
mobile crowdsourcing networks: challenges and opportunities. IEEE communica-
tions magazine 53, 8 (2015), 75–81.
[56] Yuanshun Yao, Bimal Viswanath, Jenna Cryan, Haitao Zheng, and Ben Y Zhao.
2017. Automated crowdturfing attacks and defenses in online review systems. In
Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications
Security. 1143–1158.
[57] Rowan Zellers, Ari Holtzman, Hannah Rashkin, Yonatan Bisk, Ali Farhadi,
Franziska Roesner, and Yejin Choi. 2019. Defending against neural fake news. In
Advances in Neural Information Processing Systems. 9051–9062.
[58] Rui Zhang, Jinxue Zhang, Yanchao Zhang, and Chi Zhang. 2013.
Secure
crowdsourcing-based cooperative pectrum sensing. In 2013 Proceedings IEEE
INFOCOM. IEEE, 2526–2534.
954ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Khan, et al.
[59] Qingchuan Zhao, Chaoshun Zuo, Dolan-Gavitt Brendan, Giancarlo Pellegrino,
and Zhiqiang Lin. 2020. Automatic Uncovering of Hidden Behaviors From Input
Validation in Mobile Apps. In 2020 IEEE Symposium on Security and Privacy. IEEE.
[60] Qingchuan Zhao, Chaoshun Zuo, Giancarlo Pellegrino, and Li Zhiqiang. 2019.