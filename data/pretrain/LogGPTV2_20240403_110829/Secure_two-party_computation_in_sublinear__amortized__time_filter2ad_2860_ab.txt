An ORAM construction consists of two algorithms OI
and OE for initialization and execution, respectively. OI
initializes some state stateoram that is used (and updated
by) OE. The second algorithm, OE,
is used to compile
a single read/write instruction I (on the virtual array D)
into a sequence of read/write instructions ˜I1, ˜I2, . . . to be
executed on (the real array) ˜D. The compilation of an in-
struction I into ˜I1, ˜I2, . . . , can be adaptive; i.e., instruction
˜Ij may depend on the values read in some prior instruc-
tions. To capture this, we deﬁne an iterative procedure
called doInstruction that makes repeated use of OE. Given a
read/write instruction I, we deﬁne doInstruction(stateoram, I)
as follows:
• Set d = 0(cid:2). Then until termination do:
oram) ← OE(stateoram, I, d), and
(cid:2)
1. Compute ( ˜I, state
(cid:2)
set stateoram = state
oram.
2. If ˜I = (done, z) then terminate with output z.
3. If ˜I = (write, v, d
) then set ˜D[v] = d
4. If ˜I = (read, v,⊥) then setd = ˜D[v].
.
(cid:2)
(cid:2)
If I was a read instruction with I = (read, v,⊥), then the
ﬁnal output z should be the value “written” at D[v]. (See
below, when we deﬁne correctness.)
Correctness. We deﬁne correctness of an ORAM construc-
tion in the natural way. Let I1, . . . , Ik be any sequence of
instructions with Ik = (read, v,⊥), and Ij = (write, v, d)
the last instruction that writes to address v.
If we start
with ˜D initialized to empty and then run stateoram ← OI(1κ)
followed by doInstruction(I1), . . . ,doInstruction (I1), then the
ﬁnal output is d with all but negligible probability.
Security.
The security requirement is that for any two
equal-length sequences of RAM instructions, the (real) ac-
cess patterns generated by those instructions are indistin-
guishable. We will use the standard deﬁnition from the lit-
erature, which assumes the two instruction sequences are
chosen in advance.1 Formally, let ORAM = (cid:5)OI, OE(cid:6) be an
ORAM construction and consider the following experiment:
Experiment ExpAPHORAM,Adv(κ, b):
1. The adversary Adv outputs two sequences of queries
k}
1 , . . . , I 1
k} and I1 = {I 1
(I0, I1), where I0 = {I 0
for arbitrary k.
1 , . . . , I 0
2. Run stateoram ← OI(1κ); initialize ˜D to empty; and
then execute doInstruction(stateoram, I b
doInstruction(stateoram, I b
k) (note that stateoram is up-
dated each time doInstruction is run). The adversary
is allowed to observe ˜D the entire time.
1), . . .,
3. Finally, the adversary outputs a guess b
(cid:2)
experiment evaluates to 1 iﬀ b
= b.
(cid:2) ∈ {0, 1}. The
1It appears that existing ORAM constructions are secure
even if the adversary is allowed to adaptively choose the next
instruction after observing the access pattern on ˜D caused
by the previous instruction, but this has not been claimed
by any ORAM construction in the literature.
515Definition 1. An ORAM construction ORAM = (cid:5)OI, OE(cid:6)
is access-pattern hiding if for every ppt adversary Adv the
following is negligible:
(cid:2)(cid:2)
(cid:2)
(cid:2)Pr
(cid:3)
ExpAPHORAM,Adv(1
κ
, b) = 1
(cid:4) − 1
2
(cid:2)(cid:2)
(cid:2)
(cid:2)
2.3 Secure Computation
We focus on the setting where a server holds a (large)
database D and a client wants to repeatedly compute f (x, D)
for diﬀerent inputs x; moreover, f may also change the con-
tents of D itself. We allow the client to keep (short) state
between executions, and the server will keep state that re-
ﬂects the (updated) contents of D.
For simplicity, we focus only on the two-party (client/server)
setting in the semi-honest model but it is clear that our def-
initions can be extended to the multi-party case with mali-
cious adversaries.
Deﬁnition of security. We use a standard simulation-
based deﬁnition of secure computation [5], comparing a real
execution to that of an ideal (reactive) functionality F . In
the ideal execution, the functionality maintains the updated
state of D on behalf of the server. We also allow F to take
a description of f as input (which allows us to consider a
single ideal functionality).
The real-world execution proceeds as follows. An envi-
ronment Z initially gives the server a database D = D(1),
and the client and server then run protocol Πf (with the
client using input init and the server using input D) that
ends with the client and server each storing some state that
they will maintain (and update) throughout the subsequent
execution. In the ith iteration (i = 1, . . .), the environment
gives xi to the client; the client and server then run proto-
col Πf (with the client using its state and input xi, and the
server using its state) with the client receiving output outi.
The client sends outi to Z, thus allowing adaptivity in Z’s
next input selection xi+1. At some point, Z terminates ex-
ecution by sending a special end message to the players. At
this time, an honest player simply terminates execution; a
corrupted player sends its entire view to Z.
For a given environment Z and some ﬁxed value κ for
the security parameter, we let realΠf ,Z (κ) be the random
variable denoting the output of Z following the speciﬁed
execution in the real world.
In the ideal world, we let F be a trusted functionality that
maintains state throughout the execution. An environment
Z initially gives the server a database D = D(1), which the
server in turn sends to F . In the ith iteration (i = 1, . . .),
the environment gives xi to the client who sends this value
to F . The trusted functionality then computes
(outi, D(i+1)) ← f (xi, D(i)),
and sends outi to the client. (Note the server does not learn
anything from the execution, neither about outi nor about
the updated contents of D.) The client ends outi to Z. At
some point, Z terminates execution by sending a special end
message to the players. The honest player simply terminates
execution; the corrupted player may send an arbitrary func-
tion of its entire view to Z.
For a given environment Z, some ﬁxed value κ for the
security parameter, and some algorithm S being run by the
corrupted party, we let idealF,S,Z (κ) be the random vari-
Secure initialization protocol
Input: The server has an array D of length n.
Protocol:
1. The participants run a secure computation of
OI(1κ, 1s, 1(cid:2)), which results in each party receiv-
ing a secret share of the initial ORAM state. We
denote this by [stateoram].
2. For i = 1, . . . , n do
(a) The server sets I = (write, v, D[v])) and
secret-shares I with the client. Denote the
sharing by [I].
oram], [⊥]) ←
parties
doInstruction([stateoram], [I]) (see Figure 3),
and set [stateoram] = [state(cid:2)
([state(cid:2)
(b) The
run
oram].
Figure 1: Secure initialization protocol πInit.
able denoting the output of Z following the speciﬁed execu-
tion.
Definition 2. We say that protocol Πf securely com-
putes f if there exists a probabilistic polynomial-time ideal-
world adversary S (run by the corrupted player) such that
for all non-uniform, polynomial-time environments Z there
exists a negligible function negl such that
(cid:2)
(cid:2)Pr
(cid:4) − Pr [idealF,S,Z (κ) = 1]
(cid:2)
(cid:2) ≤ negl(κ).
realΠf ,Z (κ) = 1
(cid:3)
3. GENERIC CONSTRUCTION
In this section we present our generic solution for achiev-
ing secure computation with sublinear amortized work, based
on any ORAM scheme and any secure two-party computa-
tion (2PC) protocol. While our optimized protocol (in Sec-
tion 4) is more eﬃcient, this generic protocol demonstrates
theoretical feasibility and provides a conceptually clean il-
lustration of our overall approach. A high-level overview of
our protocol was given in Section 1.1.
We provide our security deﬁnition in Appendix 2.3. We
brieﬂy describe here the deﬁnition of ORAM; formal deﬁni-
tions of the RAM and ORAM models of computation are
given in Appendix 2.1 and Appendix 2.2 respectively.
An ORAM provides read/write access to a (virtual) array
of length s using a data structure of length s · polylog(s),
where each “virtual” read/write instruction I (in the virtual
array of length s) is emulated using polylog(s) read/write
instructions ˆI1, . . . on the actual ORAM array (of length
s · polylog(s)). The underlying ORAM is deﬁned by two
algorithms OI and OE. The ﬁrst represents the initializa-
tion algorithm (i.e., key generation), which establishes the
client’s initial state and can be viewed as also initializing
an empty array that will be used as the main ORAM data
structure. This algorithm takes as input κ (a security pa-
rameter), s (the length of the virtual array being emulated),
and (cid:2) (the length of each entry in both the virtual and ac-
tual arrays). The second algorithm OE deﬁnes the actual
ORAM functionality, namely the process of mapping a vir-
tual instruction I to a sequence of real instructions ˆI1, . . ..
Algorithm OE takes as input (1) the current ORAM state
stateoram, (2) the virtual instruction I being emulated, and
(3) the last value d read from the ORAM array, and out-
(cid:2)
puts (1) an updated ORAM state state
oram and (2) the next
instruction ˆI to run.
516Secure evaluation protocol πf
Inputs: The server has array ˜D and the client has
input n, 1(cid:2), and x. They also have shares of an ORAM
state, denoted [stateoram].
Protocol:
1. The client sets stateΠ = (n, 1(cid:2), start, x) andd =
0(cid:2) and secret-shares both values with the server;
we denote the shared values by [stateΠ] and [d],
respectively.
2. Do:
(a) The
Π].
parties
([state(cid:2)
[stateΠ] = [state(cid:2)
Π], [I]) ← Π([stateΠ], [d]), and set
compute
securely
if stateΠ = (stop, z). If so, break.
(b) The parties run a secure computation to see
]) ←
(c) The parties execute ([state(cid:2)
They set
oram], [d(cid:2)
doInstruction([stateoram], [I]).
[stateoram] = [state(cid:2)
oram] and [d] = [d(cid:2)
].
3. The server sends (the appropriate portion of) its
share of [stateΠ] to the client, who recovers the
output z.
Output: The client outputs z.
Figure 2: Secure evaluation of a RAM program de-
ﬁned by next-instruction function Π.
With the above in place, we can now deﬁne our proto-
col for secure computation of a function f over an input x
held by the client (and assumed to be small) and an array
D ∈ ({0, 1}(cid:2))n held by the server (and assumed to be large).
We assume f is deﬁned in the RAM model of computation
in terms of a next-instruction function Π which, given the
current state and value d (that will always be equal to the
last-read element), outputs the next instruction and an up-
The doInstruction subroutine
Inputs: The server has array ˜D, and the server
and client have shares of an ORAM state (denoted
[stateoram]) and a RAM instruction (denoted [I]).
1. The server sets d = 0(cid:2) and secret shares this value
with the client; we denote the shared value by [d].
2. Do:
(a) The
parties
compute
oram], [ ˆI]) ← OE([stateoram], [I], [d]),
([state(cid:2)
and set [stateoram] = [state(cid:2)
securely
oram].
(b) The parties run a secure computation to see
if ˆI = (done, z). If so, set [d] = [z] and break.
(c) The client sends its share of [ ˆI] to the server,
who reconstructs [ ˆI]. Then:
i. If ˆI = (write, v, d(cid:2)
), the server sets
ii. If ˆI = (read, v, ⊥), the server sets d =
and sets d = d(cid:2)
˜D[v] =d (cid:2)
.
˜D[v].
(d) The server secret-shares d with the client.
Output: Each player outputs its shares of stateoram
and d.
Figure 3: Subroutine for executing one RAM in-
struction.
dated state. We let s denote a bound on the number of
memory cells of length (cid:2) required by this computation (in-
cluding storage of D in the ﬁrst n positions of memory).
Our protocol proceeds as follows:
1. The parties run a secure computation of OI. The re-
sulting ORAM state stateoram is shared between the
client and server.
2. The parties run a secure computation of a sequence of
(virtual) write instructions that insert each of the n
elements of D into memory. The way this is done is
described below.
3. The parties compute f by using secure computation
to evaluate the next-instruction function Π. This gen-
erates a sequence of (virtual) instructions, shared be-
tween the parties, each of which is computed as de-
scribed below.
4. When computation of f is done, the state associated
with this computation (stateΠ) encodes the output z.