cache 
idea 
is 
to 
ITR 
to 
•  On  fault  detection,  we  show  it  is  possible  to 
accurately  identify  the  correct  recovery  strategy: 
either  a  lightweight  flush  and  restart  of  the 
processor, or a more expensive program restart. 
•  We  show  that  the  ITR-based  approach  compares 
favorably to conventional approaches like structural 
duplication and time redundant execution, in terms 
of area and power. 
The  rest  of  the  paper  is  organized  as  follows. 
Section 2 discusses detailed microarchitectural support 
to exploit ITR for protecting the fetch and decode units  
of  a  superscalar    processor.  In  Section  3,  the  ITR 
cache  design  space  is  explored  to  achieve  high  fault 
coverage.  In  section  4,  we  perform  fault  injection 
experiments  to  further  evaluate  fault  coverage.  In 
Section  5,  we  compare  area  and  power  overheads  of 
the ITR approach to other fault tolerance approaches. 
Section  6  discusses  related  work  and  Section  7 
summarizes the paper. 
2. ITR components 
The  architecture  of  a  superscalar  processor, 
augmented  with support for exploiting ITR, is shown 
in Figure 5. The shaded components are newly added 
to protect the fetch and decode units of the processor 
using  ITR.  The  new  components  are  described  in 
subsections 2.1 through 2.5. 
2.1. ITR signature generation 
As  seen  in  Figure  5,  signals  from  the  decode  unit 
are redirected for signature generation. The signals are 
continuously combined until the end of each trace. The 
end  of  a  trace  is  signaled  upon  encountering  a 
branching instruction or the last of 16 instructions. On 
a  trace  ending  instruction,  the  current  signature  is 
dispatched  into  the  ITR  ROB.  The  signature  is  then 
reset and a new start PC is latched in preparation for 
the next trace. 
Signature generation could be done in many ways. 
We chose to simply bitwise XOR the signals of a new 
instruction  with  corresponding  signals  of  previous 
instructions in the trace. For a given trace, if a fault on 
an  instruction  in  the  fetch  unit  or  the  decode  unit 
causes  a  wrong  signal  to  be  produced  by  the  decode 
unit, then the signature of the trace would differ from 
that  of  a  fault-free  signature.  Even  multiple  faulty 
signals  in  a  trace  would  lead  to  a  difference  in 
signature, unless an even number of instructions in the 
trace produce a fault in the same signal. Using XOR to 
produce the signature loses information about the exact 
instruction that caused a fault. But this precision is not 
required  as  long  as  recovery  is  cognizant  that  a  fault 
could be anywhere in the trace and rollback is prior to 
the  trace.  For  a  single-event  upset  model,  we  believe 
this  overall  approach  is  sufficient  for  detecting  faults 
on  an  instruction  of  a  trace  in  the  fetch  and  decode 
units. 
2.2. ITR ROB and ITR cache 
Trace signatures are dispatched into the ITR ROB, 
when  trace  termination  is  signaled.  The  ITR  ROB  is 
sized to match the number of branches that could exist 
in  the  processor,  since  every  branch  causes  a  new 
trace. Since  a  trace  is terminated on a branch, its ITR  
Figure 5. Superscalar processor augmented with ITR support. 
ROB  entry  is  noted  in  the  branch’s  checkpoint  to 
facilitate  rollback  to  the  correct  ITR  ROB  entry  on 
branch mispredictions. 
Each  ITR  ROB  entry  stores  the  start  PC  and  the 
signature of a trace. An ITR ROB entry also contains 
control bits (chk, miss, retry), which indicate the status 
of checking the trace with the copy in the ITR cache. 
The  ITR  cache  stores  signatures  of  previously 
encountered traces and is indexed with the start PC of 
a trace. Each trace in the ITR ROB accesses the ITR 
cache  at  dispatch.  This  ensures  that  reading  the  ITR 
cache  is  complete  before  the  instructions  in  the  trace 
are ready to commit. If the trace hits, the signature is 
read  from  the  ITR  cache  and  checked  with  the 
signature of the trace. Regardless of the outcome, the 
chk  (for  checked)  bit  is  set  in  the  corresponding  ITR 
ROB entry. If it’s a mismatch, the retry bit of the ITR 
ROB entry is set. If the trace misses, the miss bit of the 
ITR ROB entry is set. 
The  ITR  ROB  enables  the  commit  logic  of  the 
processor  to  determine  whether  the  trace  of  the 
currently  committing  instruction  has  been  formed, 
whether it is has been checked, whether it is faulty, etc. 
The only extra work for the commit logic is to poll the 
head  entry  of  the  ITR  ROB  when  an  instruction  is 
ready  to  commit.  It polls to see if the miss bit or the 
chk bit of the ITR ROB head entry is set. If neither is 
set, commit is stalled until one of the bits is set. If the 
miss bit is set, then a write to the ITR cache is initiated 
and commit from the main ROB progresses normally. 
If the chk bit is set, and additionally the retry bit is not 
set,  then  instructions  are  committed  from  the  main 
ROB  normally.  If  the  retry  bit  is  set,  it  indicates  a 
transient  fault  occurred  in  either  the  new  trace  or  the 
previous  trace  that  stored  its  signature  in  the  ITR 
cache.  To  confirm  which  trace  instance  is  faulty,  the 
processor is flushed and restarted from the start PC of 
the new trace. If the signatures mismatch again, then it 
is clear the previous trace executed with a fault. Since 
this means the processor’s architectural state could be 
corrupted, a machine check exception is raised and the 
program is aborted. However, if the signatures match 
after the retry, it means the new trace was faulty, and 
recovery through flushing and restarting the processor 
was successful. In all cases, when a trace-terminating 
instruction is committed from the main ROB, the ITR 
ROB head entry is freed. 
2.3. Fault detection and recovery coverage 
Writing  to  the  ITR  cache  involves  replacing  an 
existing,  least  recently  used  (LRU)  trace  signature. 
Evicting an existing trace signature has implications on 
the  fault  detection  coverage,  i.e.,  the  number  of 
instructions  in  which  a  fault  can  be  detected.  If  a 
trace’s signature is not referenced before being evicted, 
it  amounts  to  a  loss  in  fault  detection  coverage.  To 
prevent this, a bit could be added to each cache line to 
indicate that it is checked and the replacement policy 
could be modified to evict the LRU trace that has been 
checked. We do not study this optimization and instead 
report the loss in fault detection coverage for different 
cache  configurations.  Moreover,  this  policy  is  not 
applicable  to  direct  mapped  caches  and  breaks  down 
when no ways of a set are checked yet. 
ITR  cache  misses  decrease  the  fault  recovery 
coverage,  i.e.,  the  number  of  instructions  in  which  a 
fault  can  be  detected  and  successfully  recovered  by 
flushing  and  restarting  the  processor.  This  is  because 
on a miss, an unchecked trace signature is entered into 
the cache. If the unchecked trace is faulty, the fault is 
only detected in the future by the next instance of the 
trace.  However,  since  the  faulty  trace  has  already 
corrupted the architectural state, the program has to be 
aborted.  In  Section  3,  we  measure  the  fault  coverage 
for different ITR cache configurations.  
Recovery  coverage  can  be  enhanced  through  a 
coarse-grained  checkpointing  scheme  (e.g.,  [6][7]). 
The key idea is to take a coarse-grain checkpoint when 
there  are  no  unchecked  lines  in  the  ITR  cache.  The 
number  of  unchecked  lines  could  be  tracked.  Once  it 
reaches zero, a coarse-grain checkpoint could be taken. 
Then  in  cases  where  the  lightweight  processor  flush 
and  restart  is  not  possible,  recovery  can  be  done  by 
rolling  back  to  the  previously  taken  coarse-grain 
checkpoint instead of aborting the program. 
2.4. Faults on ITR components 
The  new  ITR  components  do  not  make  the 
processor more vulnerable to faults, assuming a single-
event  upset  model.  A  fault  on  signature  generation 
components will be detected as a signature mismatch. 
A fault on the latched start PC is not a concern. If its 
signature  matches  the  faulty  start  PC’s  signature,  the 
fault  gets  masked.  If  it  mismatches,  the  fault  is 
detected.  If  it  misses  in  the  ITR  cache,  the  next 
instance of the faulty PC will either detect it or mask it. 
The  control  bits  chk,  miss  and  retry  can  be  protected 
using one-hot encoding. The possible states are: {none 
set – 0001, chk and retry set – 0010, chk set and retry 
not  set—0100,  miss  set  –  1000}.  Faults  on  the  ITR 
cache will cause false machine check exceptions when 
they  are  detected,  i.e.,  a  retry  will  indicate  a  fault  on 
the  trace  signature  in  the  ITR  cache  and  a  machine 
check exception will be raised, as described in Section 
2.2. This can be avoided by parity-protecting each line 
in  the  ITR  cache.  On  a  signature  mismatch,  retry  is 
attempted.  If  the  signature  mismatches  again,  then 
parity is checked on the trace signature in the cache. A 
parity error indicates an error in the ITR cache and not 
the previous instance of the trace. Successful recovery 
involves  invalidating  the  erroneous  line  in  the  cache, 
or updating it with the signature of the new trace.  
2.5. Faults on the program counter (PC) 
A  fault  on  the  PC  or  the  next-PC  logic  causes 
incorrect instructions to be fetched from the I-cache.  
If the disruption is in the middle of a trace, then its 
signature will be a combination of signals from correct 
and  incorrect  instructions,  and  will  differ  from  the 
trace’s  fault-free  signature.  In  this  case,  a  PC  fault  is 
detected by the ITR cache.  
If the disruption is at a natural trace boundary, then 
a  wrong  trace  is  fetched  from  the  I-cache.  Since  the 
signature of the wrong trace itself is unaffected by the 
fault, it will agree with the ITR cache. Hence, the PC 
that starts a trace at a natural trace boundary represents 
a  vulnerability  of  the  ITR  cache,  and  needs  other 
means  of  protection.  For  natural  trace  boundaries 
caused  by  branches,  substantial  protection  of  the  PC 
already  exists,  because  the  execution  unit  checks 
branch targets predicted by the fetch unit. For natural 
trace boundaries caused by the maximum trace length, 
protection  of  the  PC  is  possible  by  adding  a  simple 
commit  PC  and  asserting 
that  a  committing 
instruction’s PC matches the commit PC. The commit 
PC  is  updated  as  follows.  Sequential  committing 
instructions add their length (which can be recorded at 
decode for variable-length ISAs) to the commit PC and 
branches  update  the  commit  PC  with  their  calculated 
PC. Comparing a committing instruction’s PC with the 
commit  PC  will  detect  a  discontinuity  between  two 
otherwise sequential traces. As part of future work, we 
plan 
to  comprehensively  study  PC  related  fault 
scenarios to identify other potential vulnerabilities and 
devise robust solutions. 
3. The ITR cache design space 
As  noted  in  Section  2.3,  evictions of unreferenced 
lines from the ITR cache cause a loss in fault detection 
coverage, and misses in the ITR cache cause a loss in 
fault  recovery  coverage.  In  this  section,  we  try 
different  ITR  cache  configurations  and  measure  the 
loss  in  fault  detection  coverage  and  fault  recovery 
coverage  for  each  design  point.  Loss  in  coverage  is 
measured  by  noting  the  number  of  instructions  in 
vulnerable traces. 
For  experiments,  we  ran  SPEC2K  integer  and 
floating  point  benchmarks  compiled  with 
the 
Simplescalar gcc compiler for the PISA ISA [14]. The 
compiler  optimization  level  is  –O3.  Reference  inputs 
are used. In our runs, we skip 900 million instructions 
and simulate 200 million instructions. 
Two 
ITR  cache  parameters  are  varied, 
(1) 
Associativity:  direct  mapped  (dm),  2-way,  4-way,  8-
way, 16-way and fully associative (fa), and (2) Cache 
size: 256, 512 and 1024 signatures. Figure 6 shows the 
loss in fault detection coverage and Figure 7 shows the 
loss  in  fault  recovery  coverage  for  the  various  cache 
configurations.  For  a  given  associativity,  a  smaller 
cache 
the  number  of  evictions  of 
unreferenced  ITR  signatures  and  the  number  of  ITR 
cache misses. The corresponding increase in coverage 
loss is shown stacked for the various cache sizes. 
increases 
Bzip, gzip, art, mgrid and wupwise have negligible 
coverage  loss  for  all  ITR  cache  configurations.  For 
clarity,  they  are  not  included  in  the  graphs.  Their 
excellent  ITR  cache  behavior  can  be  explained  by 
referring  back  to  Figure  3  and  Figure  4,  which 
characterize ITR in benchmarks. In these benchmarks, 
traces  repeat  in  close  proximity  and  such  traces 
contribute to nearly all the dynamic instructions. 
large  number  of  dynamic 
In fact, coverage loss for all benchmarks correlates 
with their characteristics in Figure 3 and Figure 4. In 
perl and vortex, traces that repeat far apart contribute 
to  a 
instructions. 
Correspondingly,  they  have  the  highest  loss  in  fault 
coverage.  Cache  capacity  has  a  big 
impact  on 
mitigating  this  loss.  For  example,  in  vortex,  for  a 
direct-mapped cache, increasing the cache capacity to 
1024 signatures from 256 signatures decreases the loss 
in fault detection coverage to 12% from 33%.  
Gcc, twolf and apsi also have a notable number of 
traces  that  repeat  far  apart,  and  experience  a  loss  in 
fault  coverage.  They  also  benefit  significantly  from 
increasing the cache capacity. For insight, we refer to 
Table 1. It shows the total number of static traces for 
all benchmarks. Notice for vortex and perl, the number 
of  static  traces  (2,655  and  1,704)  is  higher  than  the 
capacity  of  all  the  ITR  caches  simulated.  Their  poor 
trace  proximity  exposes  this  capacity  problem.  Far-
apart  repeating  traces  get  evicted  before  they  are 
accessed  again,  leading  to  a  notable  loss  in  fault 
coverage.  Increasing  the  cache  capacity  somewhat 
makes up for the poor proximity and, hence, has a big 
impact  on  reducing  coverage  loss.  Gcc  confirms  our 
hypothesis  that  proximity  amongst  traces  is  a  strong 
factor. Even though it has far more traces than vortex 
and  perl  (24,017),  it  has  lower  coverage  loss  for  a 
given cache configuration as a result of its better trace 
proximity. Mgrid is another example. It has negligible 
coverage  loss  for  all  ITR  cache  configurations  even 
though it has a relatively high number of static traces 
(798). Again, proximity amongst its traces is excellent. 
The  remaining  benchmarks  have  a  small  loss  in  fault 
coverage which can be overcome with bigger caches or 
higher associativity. 
Table 1. Number of static traces for SPEC. 
#static
283
696
24017
291
865
1704
481
2655
292      
SPECfp
applu
apsi
art
equake
mgrid
swim
wupwise
SPECInt
bzip
gap
gcc
gzip
parser
perl
twolf
vortex
vpr
#static
282
1274
98
336
798
73
18  
(Figure  6)  corresponds 
Note  that  the  loss  in  fault  coverage  should  not  be 
interpreted  as  a  conventional  cache  miss  rate,  i.e.,  it 
does  not  correspond  to  signatures  that  missed  on 
accessing  the  ITR  cache.  Firstly,  the  loss  in  fault 
detection  coverage 
to 
signatures that were evicted from the ITR cache before 
being  referenced.  Secondly,  both  the  loss  in  fault 
detection  coverage  and  the  loss  in  fault  recovery 
coverage are influenced by the number of instructions 
in  signatures,  which 
is  not  uniform  across  all 
signatures.  These  factors  may  explain  why,  in  some 
benchmarks,  higher  associativity  sometimes  happens 
to  show  slightly  higher  loss  in  fault  coverage  than 
lower associativity. 
An important point is that the loss in fault detection 
coverage  is  significantly  lesser  than  the  loss  in  fault 
recovery coverage for all benchmarks. This is because 
all  ITR  cache  misses  lead  to  a  loss  in  recovery 
coverage,  but  only  those  missed  traces  that  are  then 
evicted  before  being  referenced  lead  to  a  loss  in 
detection coverage. 
Across  all  benchmarks,  for  a  2-way  associative 
cache  with  1024  signatures,  the  average  loss  in  fault 
detection  coverage  is  1.3%  with  a  maximum  loss  of 
8.2%  for  vortex. The corresponding numbers for loss 
in fault recovery coverage are 2.5% average and 15% 
maximum for vortex. 
In general, programs with less repetition or greater 
distance between repeated traces would have a higher 
loss  in  fault  coverage.  One  possible  solution  to 
mitigate this is to redundantly fetch and decode traces 
only  on  a  miss  in  the  ITR  cache,  still  achieving  the 
benefits of ITR but falling back on conventional time 
redundancy when inherent time redundancy fails. After 
the signature of the re-fetched trace is checked against 
the ITR cache, instructions in that trace are discarded 
from the pipeline. Another possible solution is to have 
a fully duplicated frontend, like in the IBM S/390 G5 
processor [4], but use the ITR cache to guide when the 
space redundancy should be exercised (for significant 
power  savings).  The  use  of  ITR  as  a  filter  for 
selectively  exercising 
time  redundancy  or  space 
redundancy  is  an  interesting  direction  we  want  to 
explore in future research. 
m
d
y
a
w
-
2
y
a
w
-
4
y
a
w
-
8
y
a
w
-
6
1
a
f
m
d
y
a
w
-
2
y
a
w
-
4
y
a
w
-
8
y
a
w
-
6
1
a
f
m
d
y
a
w
-
2
y
a
w
-
8
y
a
w
-
4
y
a
w
-
6
1
parser
a
f
m
d
a
f
m
d
y
a
w
-
2
y
a
w
-
4
y
a
w
-
8
y
a
w
-
6
1
perl
a
f
m
d
y
a
w
-
2
y
a