[78] Benjamin Melamed. 1993. An overview of TES processes and modeling method-
ology.
In Performance Evaluation of Computer and Communication Systems.
Springer, 359–393.
[79] Benjamin Melamed and Jon R Hill. 1993. Applications of the TES modeling
methodology. In Proceedings of 1993 Winter Simulation Conference-(WSC’93).
IEEE, 1330–1338.
[80] Benjamin Melamed, Jon R Hill, and David Goldsman. 1992. The TES method-
ology: Modeling empirical stationary time series. In Proceedings of the 24th
conference on Winter simulation. ACM, 135–144.
[81] Benjamin Melamed and Dimitrios E Pendarakis. 1998. Modeling full-length VBR
video using Markov-renewal-modulated TES models. IEEE Journal on Selected
Areas in Communications 16, 5 (1998), 600–611.
[82] Olof Mogren. 2016. C-RNN-GAN: Continuous recurrent neural networks with
adversarial training. arXiv preprint arXiv:1611.09904 (2016).
[83] Behnam Montazeri, Yilong Li, Mohammad Alizadeh, and John Ousterhout. 2018.
Homa: A Receiver-Driven Low-Latency Transport Protocol Using Network
Priorities. In SIGCOMM.
[84] Ismael Solis Moreno, Peter Garraghan, Paul Townend, and Jie Xu. 2014. Analysis,
modeling and simulation of workload patterns in a large-scale utility cloud.
IEEE Transactions on Cloud Computing 2, 2 (2014), 208–221.
[85] Arvind Narayanan and Vitaly Shmatikov. 2008. Robust de-anonymization of
large sparse datasets. In Security and Privacy, 2008. SP 2008. IEEE Symposium on.
IEEE, 111–125.
[86] Thi Thanh Sang Nguyen, Hai Yan Lu, and Jie Lu. 2013. Web-page recommenda-
tion based on web usage and domain knowledge. IEEE Transactions on Knowledge
and Data Engineering 26, 10 (2013), 2574–2587.
[87] Nicholas A. Nystrom, Michael J. Levine, Ralph Z. Roskies, and J. Ray Scott. 2015.
Bridges: A Uniquely Flexible HPC Resource for New Communities and Data
Analytics. In Proceedings of the 2015 XSEDE Conference: Scientific Advancements
Enabled by Enhanced Cyberinfrastructure (XSEDE ’15). ACM, New York, NY,
USA, Article 30, 8 pages. https://doi.org/10.1145/2792745.2792775
[88] Augustus Odena, Christopher Olah, and Jonathon Shlens. 2017. Conditional
image synthesis with auxiliary classifier gans. In Proceedings of the 34th Interna-
tional Conference on Machine Learning-Volume 70. JMLR. org, 2642–2651.
[89] Paul Ohm. 2009. Broken promises of privacy: Responding to the surprising
failure of anonymization. Ucla L. Rev. 57 (2009), 1701.
traces: format+ schema. Google Inc., White Paper (2011), 1–14.
[91] Charles Reiss, John Wilkes, and Joseph L Hellerstein. 2012. Obfuscatory ob-
scanturism: making workload traces of commercially-sensitive systems safe to
release. In 2012 IEEE Network Operations and Management Symposium. IEEE,
1279–1286.
[92] Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford,
and Xi Chen. 2016. Improved techniques for training gans. In Advances in Neural
Information Processing Systems. 2234–2242.
[93] Lalitha Sankar, S Raj Rajagopalan, and H Vincent Poor. 2013. Utility-privacy
tradeoffs in databases: An information-theoretic approach. IEEE Transactions
on Information Forensics and Security 8, 6 (2013), 838–852.
[94] Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov. 2017.
Membership inference attacks against machine learning models. In 2017 IEEE
Symposium on Security and Privacy (SP). IEEE, 3–18.
[95] Leszek Sliwko and Vladimir Getov. 2016. AGOCSâĂŤAccurate Google Cloud
Simulator Framework. In 2016 Intl IEEE Conferences on Ubiquitous Intelligence &
Computing, Advanced and Trusted Computing, Scalable Computing and Commu-
nications, Cloud and Big Data Computing, Internet of People, and Smart World
Congress (UIC/ATC/ScalCom/CBDCom/IoP/SmartWorld). IEEE, 550–558.
[96] Boogie Software. 2020. Synthesizing series of transactions with a Generative
Adversarial Network. https://blog.boogiesoftware.com/2020/02/synthesizing-
series-of-transactions.html. (2020).
[90] Charles Reiss, John Wilkes, and Joseph L Hellerstein. 2011. Google cluster-usage
[97] Joel Sommers and Paul Barford. 2004. Self-configuring network traffic genera-
tion. In Proceedings of the 4th ACM SIGCOMM conference on Internet measurement.
ACM, 68–81.
[98] Joel Sommers, Rhys Bowden, Brian Eriksson, Paul Barford, Matthew Roughan,
and Nick Duffield. 2011. Efficient network-wide flow record generation. In 2011
Proceedings IEEE INFOCOM. IEEE, 2363–2371.
[99] Joel Sommers, Vinod Yegneswaran, and Paul Barford. 2004. A framework
for malicious workload generation. In Proceedings of the 4th ACM SIGCOMM
conference on Internet measurement. 82–87.
[100] Charles Spearman. 1904. The proof and measurement of association between
two things. American journal of Psychology 15, 1 (1904), 72–101.
478
IMC ’20, October 27–29, 2020, Virtual Event, USA
Zinan Lin, Alankar Jain, Chen Wang, Giulia Fanti, and Vyas Sekar
[101] Akash Srivastava, Lazar Valkov, Chris Russell, Michael U Gutmann, and Charles
Sutton. 2017. Veegan: Reducing mode collapse in gans using implicit variational
learning. In Advances in Neural Information Processing Systems. 3308–3318.
[102] Jaideep Srivastava, Robert Cooley, Mukund Deshpande, and Pang-Ning Tan.
2000. Web usage mining: Discovery and applications of usage patterns from
web data. Acm Sigkdd Explorations Newsletter 1, 2 (2000), 12–23.
[103] Mudhakar Srivatsa and Mike Hicks. 2012. Deanonymizing mobility traces: Using
social network as a side-channel. In Proceedings of the 2012 ACM conference on
Computer and communications security. 628–637.
[104] Srikanth Sundaresan, Xiaohong Deng, Yun Feng, Danny Lee, and Amogh Dhamd-
here. 2017. Challenges in inferring internet congestion using throughput mea-
surements. In Proceedings of the 2017 Internet Measurement Conference. ACM,
43–56.
[105] Latanya Sweeney. 2000. Simple demographics often identify people uniquely.
Health (San Francisco) 671 (2000), 1–34.
[106] Latanya Sweeney. 2002. k-anonymity: A model for protecting privacy. Inter-
national Journal of Uncertainty, Fuzziness and Knowledge-Based Systems 10, 05
(2002), 557–570.
[107] Vasily Tarasov, Erez Zadok, and Spencer Shepler. 2016. Filebench: A flexible
framework for file system benchmarking. USENIX; login 41, 1 (2016), 6–12.
[108] J. Towns, T. Cockerill, M. Dahan, I. Foster, K. Gaither, A. Grimshaw, V. Ha-
zlewood, S. Lathrop, D. Lifka, G. D. Peterson, R. Roskies, J. R. Scott, and N.
Wilkins-Diehr. 2014. XSEDE: Accelerating Scientific Discovery. Computing in
Science Engineering 16, 5 (2014), 62–74.
[109] Kashi Venkatesh Vishwanath and Amin Vahdat. 2009. Swing: Realistic and
responsive network traffic generation. IEEE/ACM Transactions on Networking
(TON) 17, 3 (2009), 712–725.
[110] Michele C Weigle, Prashanth Adurthi, Félix Hernández-Campos, Kevin Jeffay,
and F Donelson Smith. 2006. Tmix: a tool for generating realistic TCP application
workloads in ns-2. ACM SIGCOMM Computer Communication Review 36, 3 (2006),
65–76.
[111] Ronald J Williams and David Zipser. 1989. A learning algorithm for continually
running fully recurrent neural networks. Neural computation 1, 2 (1989), 270–
280.
[112] Liyang Xie, Kaixiang Lin, Shu Wang, Fei Wang, and Jiayu Zhou. 2018. Differen-
tially private generative adversarial network. arXiv preprint arXiv:1802.06739
(2018).
[113] Chugui Xu, Ju Ren, Deyu Zhang, Yaoxue Zhang, Zhan Qin, and Kui Ren. 2019.
GANobfuscator: Mitigating information leakage under GAN via differential
privacy. IEEE Transactions on Information Forensics and Security 14, 9 (2019),
2358–2371.
[114] Qiantong Xu, Gao Huang, Yang Yuan, Chuan Guo, Yu Sun, Felix Wu, and Kilian
Weinberger. 2018. An empirical study on evaluation metrics of generative
adversarial networks. arXiv preprint arXiv:1806.07755 (2018).
[115] Jianwei Yin, Xingjian Lu, Xinkui Zhao, Hanwei Chen, and Xue Liu. 2014. BURSE:
A bursty and self-similar workload generator for cloud computing. IEEE Trans-
actions on Parallel and Distributed Systems 26, 3 (2014), 668–680.
([n.
d.]).
https://bitbucket.org/mvdschaar/mlforhealthlabpub/src/
02edab3b2b6d635470fa80184bbfd03b8bf8082d/alg/timegan/.
[116] Jinsung Yoon.
TimeGAN code
[117] Jinsung Yoon, Daniel Jarrett, and Mihaela van der Schaar. 2019. Time-series
Generative Adversarial Networks. In Advances in Neural Information Processing
Systems. 5509–5519.
[118] Lantao Yu, Weinan Zhang, Jun Wang, and Yong Yu. 2017. SeqGAN: Sequence
Generative Adversarial Nets with Policy Gradient.. In AAAI. 2852–2858.
[119] Edvin Listo Zec, Henrik Arnelid, and Nasser Mohammadiha. 2019. Recurrent
Conditional GANs for Time Series Sensor Modelling. In Time Series Workshop
at International Conference on Machine Learning,(Long Beach, California).
[n.
d.].
repository.
479
Using GANs for Sharing Networked Time Series Data: Challenges, Initial Promise, and Open Questions
IMC ’20, October 27–29, 2020, Virtual Event, USA
APPENDIX
A DATASETS
Google Cluster Usage Trace: Due to the substantial computa-
tional requirements of training GANs and our own resource con-
straints, we did not use the entire dataset. Instead, we uniformly
sampled a subset of 100,000 tasks and used their corresponding mea-
surement records to form our dataset. This sample was collected
after filtering out the following categories:
• 197 (0.17%) tasks don’t have corresponding end events (such
• 1403 (1.25%) tasks have discontinuous measurement records
(i.e., the end timestamp of the previous measurement record
does not equal the start timestamp of next measurement record)
events may end outside the data collection period)
• 7018 (6.25%) tasks have an empty measurement record
• 3754 (3.34%) tasks have mismatched end times (the timestamp
of the end event does not match the ending timestamp of the
last measurement).
The maximum measurement length in this dataset is 2497, however,
97.06% samples have length within 50. The schema of this dataset
is in Table 6.
Wikipedia Web Traffic Dataset: The original datasets consists
of 145k samples. After removing samples with missing data, 117k
samples are left, from which we sample 100k samples for our eval-
uation. All samples have measurement length 550. The schema of
this dataset is in Table 7.
FCC MBA dataset: We used the latest cleaned data published by
FCC MBA in December 2018 [25]. This datasets contains hourly
traffic measurements from 4378 homes in September and October
2017. However, a lot of measurements are missing in this dataset.
Considering period from 10/01/2017 from 10/15/2017, only 45 homes
have complete network usage measurements every hour. This small
sample set will make us hard to understand the actual dynamic
patterns in this dataset. To increase number of valid samples, we
take the average of measurements every 6 hours for each home. As
long as there is at least one measurement in each 6 hours period,
we regard it as a valid sample. Using this way, we get 739 valid
samples with measurements from 10/01/2017 from 10/15/2017, from
which we sample 600 samples for our evaluation. All samples have
measurement length 56. The schema of this dataset is in Table 8.
B IMPLEMENTATION DETAILS
DG: Metadata generator and min/max generator are MLPs with 2
hidden layers and 100 units in each layer. Measurement generator is
1 layer of LSTM with 100 units. Softmax layer is applied for categor-
ical measurement and metadata output. Sigmoid or tanh is applied
for continuous measurement and metadata output, depending on
whether data is normalized to [0,1] or [-1,1] (this is configurable).
The discriminator and auxiliary discriminator are MLP with 4 hid-
den layers and 200 units in each layer. Gradient penalty weight was
10.0 as suggested in [50]. The network was trained using Adam
optimizer with learning rate of 0.001 and batch size of 100 for both
generators and discriminators.
Loss function: As mentioned in §3.3.2, Wasserstein loss has been
widely adopted for improving training stability and alleviating
mode collapse. In our own empirical explorations, we find that
480
Metadata
end event type
Measurements
CPU rate
maximum CPU
rate
sampled CPU us-
age
canonical mem-
ory usage
assigned memory
usage
maximum mem-
ory usage
unmapped page
cache
total page cache
local disk space
usage
Description
The reason that the
task finishes
Description
Mean CPU rate
Maximum CPU rate
The CPU rate sam-
pled uniformly on
all 1 second mea-
surements
Canonical memory
usage measurement
Memory assigned
to the container
Maximum canoni-
cal memory usage
Linux page cache
that
not
mapped into any
userspace process
Total Linux page
cache
Runtime local disk
capacity usage
was
Possible Values
FAIL, KILL, EVICT,
etc.
Possible Values
float numbers
float numbers
float numbers
float numbers
float numbers
float numbers
float numbers
float numbers
float numbers
Timestamp Discription
Possible Values
The timestamp that the measurement
was conducted on. Different task may
have different number of measurement
records (i.e. T i may be different)
Table 6: Schema of GCUT dataset. metadata and measure-
ments are described in more detail in [90].
2011-05-01
etc.
01:01,
Wasserstein loss is better than the original loss for generating cate-
gorical variables. Because categorical variables are prominent in
our domain, we use Wasserstein loss.
In order to train the two discriminators simultaneously, we com-
bine the loss functions of the two discriminators by a weighting
parameter α. More specifically, the loss function is
L1(G, D1) + αL2(G, D2)
min
(1)
max