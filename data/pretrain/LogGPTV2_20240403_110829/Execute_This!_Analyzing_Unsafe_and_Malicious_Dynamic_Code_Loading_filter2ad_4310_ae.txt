code (e.g., source code under appropriate agreements). Our
protection system, on the other hand, can only rely on the
bare assembly code at runtime, which makes it much harder to
assess the code’s properties. Even without loading any external
code, techniques such as return-oriented programming allow
applications running native code to execute arbitrary programs,
leveraging code that is already present in memory [8], [30].
While the obligation to provide proof for properties of native
code is an obstacle for developers, we believe that the resulting
large improvement of system security justiﬁes it.
C. Signature scheme based on whitelists
The integrity check that we enforce on loaded code is
a lookup in a signed whitelist. Note that keeping whitelists
signed by veriﬁcation providers is an equivalent approach
to attaching signatures to applications, but it has additional
advantages: A signature in the common formats [7] is just a
hash of the ﬁle in question that is signed by the issuer’s private
key. Similarly, a (signed) whitelist provided by a veriﬁcation
provider is essentially a signature for multiple ﬁles. We do not
attach the veriﬁer’s signature directly to the APK in order to
keep store and veriﬁcation service separate. This has the advan-
tage that nothing changes in the way stores work, and existing
stores can continue to operate as before. Conceptually, the
veriﬁcation systems are simply an addition to the ecosystem.
They provide signatures, but do not have to offer applications
11
load
Whitelist updater
update
Shared 
whitelist
Android processes
look up hashes
check hashes
Dalvik instance
Dalvik instance
Dalvik instance
Whitelists
on disk
External 
code
External 
code
Fig. 4. The architecture of our protection system. Instances of the Dalvik VM
share a system-wide whitelist, which is backed by the device’s ﬁle system.
for download. So, the user’s device downloads applications
from stores – as before – and validates the executables with
signatures that it downloads from veriﬁcation services. Due to
the relatively small size of the hashes, we combine all hashes
of the same veriﬁcation service into one ﬁle that can be cached
on the device. The ﬁle contains a signed list of hashes – the
whitelist.
Upon receiving a request to load code, our modiﬁed version
of the Dalvik VM computes a hash of the code that is to be
loaded and checks it against a system-wide whitelist. We use
the SHA-256 implementation of the OpenSSL library that is
part of Android for the hash computation. This computation
has to be done only once per code ﬁle, because Dalvik keeps
a cached version of the ﬁle in a private location after the ﬁrst
load operation. If the computed hash is not contained in the
whitelist, the VM cancels the load procedure immediately. The
whitelist is shared among all instances of the VM on the device
and managed via ﬁles in a system-protected directory. Thus,
only system applications (i.e., applications that are signed with
the same key as the system itself) can update the whitelist ﬁles,
which are immediately reloaded into shared memory after a
modiﬁcation. Fig. 4 illustrates the design.
D. Whitelist management
We envision that each veriﬁcation service that the user
conﬁgures on the device provides a single whitelist ﬁle that
is updated regularly. A system application periodically down-
loads the latest version of the whitelists and stores them
in the dedicated system directory from which our modiﬁed
Dalvik VM loads them into shared memory. Note that updating
whitelists in face of newly emerging malware is not as critical
as is the case for blacklists: Malware that is detected after
the creation date of the whitelist still cannot execute on the
protected system, because its hash is not part of the whitelist.
Forging a malicious application with the same hash as a
whitelisted benign one requires breaking the hash function
(SHA-256 in our case), which is generally assumed to be a
hard problem.
In our implementation, we just combine the whitelists from
different providers by a set union (a Boolean OR of the
approvals). It is sufﬁcient for one of the trusted veriﬁcation
services to approve code in order for the system to execute it.
It is conceivable to use more complicated expressions in future
versions (e.g., “accept code if it is approved by veriﬁcation
service A or by veriﬁcation services B and C”). Such behavior
is easy to add to the current system.
user to specify the cache directory on which the system relies
for subsequent load operations (see Section III-A). Thus, an
attacker can override the ﬁles in the cache directory after our
veriﬁcation succeeded. The mitigation of such an attack can
be implemented as follows: If the veriﬁcation of the original
ﬁle succeeds during the ﬁrst load operation, the system can
“extend” the trust to the corresponding optimized ﬁle in the
cache directory by adding its hash to a temporary whitelist.
Subsequently, any modiﬁcation of the cached ﬁle can be
detected.
E. Permission for Runtime.exec
The API Runtime.exec (previously mentioned in Sec-
tion III-A) allows applications to execute arbitrary binaries on
the system. This way, applications can use system binaries
that are very generic in nature (such as a shell). It is difﬁcult
for veriﬁcation services to classify such generic binaries into
categories like “benign” and “malicious” – they can be used
for legitimate purposes as well as for malicious ones.
it has inherent potential
A classic example is the system shell /system/bin/sh: It is
present on all Android systems and not malicious in itself,
but
to be misused by malicious
applications. Due to its ability to carry out almost arbitrary
tasks on the system and to launch other binaries, malware
can use it to conduct unwanted activities. Thus, a veriﬁcation
service cannot approve /system/bin/sh per se.
Instead, we require applications that use Runtime.exec to
ask for explicit permission using the Android permission
system. The reason is that we expect developers to be able
to prove the non-malicious character of their JARs, APKs or
native code libraries in order to have them approved by a
veriﬁcation service, whereas Runtime.exec enables applications
to use binaries that are too generic for such a classiﬁcation.
Any application that uses Runtime.exec has to declare this
the user is made aware
intention in its manifest, so that
installation time.
of the potentially dangerous behavior at
the permission by modifying the Android
We implement
framework. Like some of the already existing permissions
(e.g., the permission to access the Internet), our permission
is enforced by Linux groups: An application that has been
granted permission for Runtime.exec executes in a process that
contains a particular Linux group in its set of complementary
groups. Our implementation of Runtime.exec veriﬁes the group
membership before taking any action. By doing this, we can
make sure that applications have to explicitly declare to the
user that they will use the dangerous API.
From a technical point of view, executing an arbitrary
binary is no different from loading native code through JNI.
However, native libraries are usually not as generic as some
system binaries, because they are designed to support a single
application, whereas system tools, such as the shell, are
designed to accomplish a wide variety of tasks. Thus, we
expect it to be much easier for developers to prove the non-
maliciousness of a native library to application veriﬁcation
services. Therefore, we believe that a distinction between JNI
native libraries and binaries executed through Runtime.exec is
appropriate.
Additional considerations are necessary for DexClass-
Loader. As described previously, DexClassLoader allows the
Note that the introduction of the new permission requires
developers to change the manifest ﬁle of their applications if
12
they use Runtime.exec. However, we believe that this is the
only way to mitigate the risk that uncontrolled use of this
particular API imposes on the overall system’s security.
ﬁxed size for simplicity, but it is easy to replace this behavior
with a strategy that adjusts the amount of reserved memory
based on the number of entries in the system whitelist.
F. Evaluation
After having presented our protection system’s design, we
now assess both its effectiveness and efﬁciency.
1) Effectiveness: For an assessment of the protection sys-
tem’s effectiveness, we created a simple application that
exercises all the code loading techniques described in Sec-
tion III-A. We veriﬁed that, in an unmodiﬁed Android system,
they all led to the execution of external code. We tried to use
the same techniques in our protected version of Android, with-
out whitelisting the code that the application tries to load and
without giving the application permission for Runtime.exec.
The protection system successfully blocked all attempts
to load external code. The techniques using class loaders,
native code and package contexts, respectively, were detected
and blocked immediately. The attempt to execute code using
Runtime.exec was prohibited by the framework due to the
missing permission. APKs can be installed, but the system
does not allow launching the installed applications.
Note that it would be possible to intercept APKs dur-
ing installation already, for a more user-friendly experience.
This would require hooking the Package Manager Service.
However, we refrained from doing so in order to modify the
operating system and its services as little as possible while
still achieving complete protection against all presented code-
loading techniques.
In a further test, we tried to execute the two attacks
presented in Section V-B against a device running our protec-
tion system. As expected, the protection system blocked both
exploits because the injected code ﬁles were not trusted.
2) Efﬁciency: For the analysis of the system’s efﬁciency,
we examine performance and memory overhead.
In order to assess the performance overhead, we measured
the time that the modiﬁed Dalvik VM needs to check code
during the ﬁrst load operation. The check consists of a SHA-
256 computation over the ﬁle that is to be loaded and a lookup
in the in-memory whitelist. Running on a 2.8 GHz Intel Core i7
CPU, the release build of our system needs 0.25 milliseconds
on average in the Android emulator to look up a hash in a
whitelist with 1,000,000 entries, and by varying the number of
entries we ﬁnd that the lookup time increases logarithmically.
The SHA-256 computation uses the OpenSSL implementation
of the hash function and takes 123 milliseconds on average for
an APK ﬁle of 20 MB in size.
The second important aspect of the protection system’s efﬁ-
ciency is memory consumption. The only factor that inﬂuences
its memory consumption is the number of whitelist entries
that are used on the device. Since we use 32-byte long SHA-
256 hashes, the space required in memory can be speciﬁed
as 32 · w + c bytes, where w is the number of entries in the
whitelist and c a constant smaller than 100. For example, a
whitelist containing the approximately 1,000,000 applications
from Google Play would consume roughly 30.5 MB of mem-
ory. Our current implementation reserves a memory block of
We believe that the whitelisting mechanism will not lead
to scalability issues. Should the number of applications grow
so fast that the size of the whitelist turns problematic, the
following modiﬁcation will ﬁx the issue: In our current system,
Android devices download complete whitelists from veriﬁca-
tion services, containing the hashes of all applications that a
respective service approves. A future version of the system
could just download hashes for installed applications during
the installation process. So, whenever the user would choose
to install an application, the system would ask all trusted
veriﬁcation services for corresponding signatures. This would
eliminate any problems with storage space at
the cost of
requiring the user to be online while installing applications.
While this would constitute a limitation, we believe that it
would not normally affect users. Applications are usually
installed from online stores, so that connectivity is provided
during installation.
Note that the speciﬁed amount of memory is the total
amount allocated on a device. Since all Dalvik instances share
a global whitelist, space needs to be reserved only once for all
of them.
VII. LIMITATIONS
While we believe that our system addresses the major
issues with runtime code loading, it has certain limitations.
In this section, we discuss such limitations and suggest future
improvements to address them.
A. Automatic detection tool
Our detection tool for dynamic code-loading behavior uses
static analysis techniques. Therefore, it does not have any
information per se whether a given code fragment is executed
in the default conﬁguration of the application. This issue
could be addressed by more sophisticated data-ﬂow analysis,
which would yield the conditions that are necessary for the
application to execute the vulnerable functionality.
Furthermore, the detection tool does not detect if an ap-
plication secures the code-loading operation by implementing
custom integrity checks. While we did not ﬁnd such custom
checks in the applications reported as vulnerable that we ana-
lyzed manually, we might have to add detection capabilities for
them in the future, as developers become aware of the security
risk and start to implement custom protection. Good starting
points for the detection of integrity checks in applications are
hash computations, because common mechanisms to verify the
integrity of data usually involve hash functions.
Finally, there are several Android-speciﬁc challenges that
need to be addressed in order to perform precise static analysis
of Android applications. For example, one would need to
model the life-cycle of each application’s Activities, as well as
the implicit method calls that the Android framework performs
as a reaction to user input (such as the click on a GUI button).
One approach would be to manually add support for these
Android-speciﬁc features, but as with all manual modeling,
the results are likely to be incomplete.
13
B. Protection system
VIII. RELATED WORK
A central question is the practicality of our proposed
protection mechanism. The system requires every piece of
code that an application likes to load to be submitted to
a veriﬁcation service. However, we consider this a feature
because it prevents Android devices from loading unknown
and potentially dangerous code. Google already conducts an
extensive analysis on every application submitted to Google
Play, so it seems completely feasible for them to also run
checks on additional code that applications load dynamically.
Furthermore, it is entirely possible for existing stores, such as
Google Play, to act as veriﬁcation providers. Thus, no new
entities are necessary in the ecosystem. Our system simply
provides the option to add veriﬁcation providers independently
from application stores in order to grant the users additional
freedom.
Note that our protection system requires changes in the
Android source code, meaning that only reinstalling or updat-
ing the operating system can deploy it. We acknowledge that
this constitutes an obstacle for fast and widespread adoption.
Nevertheless, we believe that the severe security threat imposed
by dynamic code-loading techniques (as documented in this
paper) makes changes at the operating-system level in Android
unavoidable in order to establish a reliable security model for
the handling of external code.
Another concern is the need to prove the benign character
of native code to veriﬁcation providers. A reliable proof
technique likely poses considerable overhead on application
developers. The question how to alleviate this burden is
subject to ongoing research. One possible approach could be
to encapsulate native code in a sandbox environment similar
to Google Native Client [29], [36].
In theory, attackers can write an interpreter for a scripting
language in Java and download and execute scripts once
the application is installed on the victim’s device. Such an
application would not have to load code in order to behave
maliciously – the loaded script would just be data that the
application can interpret. Percoco and Schulte used a similar
approach in 2012 to circumvent detection by the Google
Bouncer [27]. Their approach is based on WebViews – Luo et
al. examined the security of WebViews in detail [23]. However,
note that the application’s Java code has to contain all the
functionality that the scripting language offers to the attacker.
The ability to read the user’s contacts, for instance, must be
present in the Java code if the attacker wants to use it from the
scripting language. Thus, veriﬁcation services might be able
to recognize that the application provides a lot of seemingly
unused functionality.
A more general concern is that an attacker could use
reﬂection for a similar purpose. In this scenario, an application
would just receive class and method names as strings and