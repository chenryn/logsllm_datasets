Flash Player Update.” In this example, the attacker is in-
venting the need to install “Flash Player Pro” and tells
the user they must comply before they can continue with
watching the desired video. Unfortunately, this results
USENIX Association  
25th USENIX Security Symposium  781
9
Ad#
SearchGAd#
Search# Webpost#
Repackage+En;ce#
Invent+Impersonate+Alarm#
Invent+Impersonate+Comply#
Repackage+Decoy#
Impersonate+Decoy#
Impersonate+En;ce+Decoy#
Impersonate+Alarm#
0%# 10%# 20%# 30%# 40%# 50%# 60%# 70%# 80%# 90%# 100%#
Figure 3: How attackers gain the user’s attention per de-
ception/persuasion technique.
in the user downloading malicious software that simply
impersonates a popular benign application and offers no
actual utility to the user.
Table 3: Popularity of different “scam” tactics in the
Ad:Invent+Impersonate subclasses.
Fake Flash
Fake Java
Fake AV
Fake Browser
Fake Player
Alarm
68%
30%
1%
1%
0%
Comply
20%
0%
0%
0%
80%
Table 3 shows the popularity of different “scam” tac-
tics in the invent+impersonate subclasses alarm and
comply. Fake Flash and Java updates are the two most
popular in the alarm class. In this same class we also ob-
serve Fake Browser updates and Fake AV alerts, but they
are much less common, each comprising only about 1%
of our observations. Fake Flash updates are also common
in the comply class; however, the most popular scam tac-
tic is telling the user they must update or install a new
video player before they can continue.
In these Fake
Player attacks, images that resemble Adobe Flash Player
are often used, but the terms “Adobe” or “Flash” are not
directly mentioned. Therefore in Table 3 we distinguish
between explicit Fake Flash and Fake Player.
Figure 3 shows how attackers gain the user’s attention
for each of the observed deception and persuasion tech-
niques. For instance, ads are the most common way used
to attract users’ attention for repackage+entice, compris-
ing 75% of our observations. Search and web posts
contribute the remaining 25%. All observations for in-
vent+impersonate+alarm,
invent+impersonate+comply,
impersonate+alarm and impersonate+decoy rely exclu-
sively on ads to gain the user’s attention. At
the
other extreme, none of our observations for imperson-
ate+entice+decoy use ads. This is likely due to the
fact that this combination of deception and persuasion
techniques is more effective when the user’s attention is
gained through search and web posts. However, notice
that this comprises less than 1% of all SE downloads in
our dataset (see Table 2).
5.2 Ad-based SE Download Delivery Paths
As shown in Table 1, the majority of SE attacks we ob-
served use online ads to attract users’ attention. To better
understand these attacks, we examine the characteristics
of their ad delivery path. We begin by reconstructing the
web path (i.e., the sequence of URLs) followed by the
victims to arrive to the download URL (see Section 4).
Then, we identify the first ad-related node on the web
path using a set of regular expressions derived from the
Adblock Plus rules [1]. We define the set of nodes (i.e.,
HTTP transactions) on the web path beginning at the first
ad node and ending at the download node as the ad de-
livery path.
Table 4: Top five ad entry point domains.
Comply
26% onclickads.net
10% adcash.com
10% popads.net
7% putlocker.is
3% allmyvideos.net
Alarm
16% adcash.com
7% onclickads.net
7% msn.com
6% yesadsrv.com
4% yu0123456.com
Entice
20% doubleclick.net
16% google.com
12% googleadservices.com
11% msn.com
8% coupons.com
Table 4 shows the top 5 “entry point” domain names
on the ad delivery paths (i.e.,
the first domain on
the ad paths) for the comply, alarm and entice attack
classes. Almost 50% of the ad entry points for the
comply class begin with one of the following domains:
onclickads.net, adcash.com or popads.net.
By investigating these domains, we found that they have
also been abused by adware in the past. Specifically,
these domains are the source of pop-up ads injected into
the user’s browsing experience by several well known ad-
ware programs and ad-injecting extensions [43].
Table 4 also shows that the top two ad entry points for
the alarm class are the same as the comply class, though
in reverse ranking. The third domain is msn.com, which
has a good reputation. However, this domain is appearing
at the top of the ranking probably because it sometimes
redirects (via syndication) to less reputable ad networks,
which in turn direct the user to an SE download. Notice
also that the top entry domains in the entice class all have
very good reputations (doubleclick.net is owned
by Google). This is likely due to the fact that the majority
of downloads in this class are for legitimate software that
is simply bundled with “less aggressive” PUPs.
Besides performing an analysis of the “entry point” to
the ad delivery path, we also analyze the last node on
the path, namely the HTTP transaction that delivers the
download. Table 5 shows the most popular SE download
domains for the comply, alarm and entice classes. We
782  25th USENIX Security Symposium 
USENIX Association
10
Table 5: Top five ad-driven SE download domains.
Comply
17% softwaare.net
5% newthplugin.com
5% greatsoftfree.com
4% soft-dld.com
3% younplugin.com
Alarm
7% downloaddabs.com
4% downloaddado.com
4% whensoftisupdated.net
3% safesystemupgrade.org
3% onlinelivevideo.org
Entice
41% imgfarm.com
17% coupons.com
11% shopathome.com
5% crusharcade.com
3% ilivid.com
found that the domains listed for the comply and entice
classes serve mostly adware and PUPs.
To better understand the network-level properties of
SE downloads, we also measure the “age” of these
domains by leveraging a large passive DNS database
(pDNS-DB) that stores historic domain name resolu-
tions. Specifically, we define the domain age as the
difference in days from the time the domain was first
queried (i.e., first recorded in the pDNS-DB) to the day
of the download. All the domains in Table 5 that are part
of the comply and alarm classes are less than 200 days
old, with the majority being less than 90 days. On the
other hand, the domains in Table 5 for the entice class are
all at least several years old. This is because most of the
downloads in this class are for legitimate software that
is simply bundled with adware or PUPs. For instance,
we find a large variety of “free” software ads that direct
users to the domain imgfarm.com for download. This
is the reason that over 40% of the downloads in the entice
class are from that domain.
The “middle of path” domains, namely the ones be-
tween the ad entry point and the download domain itself,
tend to be a mix of recent and old domains. In fact, the
most popular comply and alarm class “middle of path”
domains are a 50/50 split of recent and old. However,
this is not the case for the entice class, for which most
domains are several years old. At the same time, the ma-
jority of ad delivery paths for all three classes include at
least one middle domain name with an age that is less
than 200 days.
5.3 Ad-Driven Benign Downloads
As mentioned earlier, more than 80% of the SE down-
load attacks we observed use ads to gain the user’s atten-
tion (see Table 1). Based on common experience, it may
seems unlikely that many benign software downloads
would result from clicking on an ad. As a result, one
may think that if software is downloaded after clicking
on an ad, that software is unlikely to be benign. Some-
what surprisingly, we found that this may not necessarily
be the case, as we explain below.
First, to automatically identify ad-driven benign soft-
ware downloads, we first derive a set of ad detection reg-
ular expressions from the rules used by the popular Ad-
Block Plus browser extension [1]. We match these reg-
ular expressions against the nodes on the reconstructed
download path for each benign download (the down-
If
load labeling process is described in Section 4.4).
an AdBlock rule matches the download path, we label
that benign software download as ad-driven. We find
that around 7% of all benign software downloads are ad-
driven. Even though the percentage is low compared to
SE downloads, in absolute terms this number is signif-
icant because the vast majority of software downloads
observed in a network are benign.
In fact, by consid-
ering the overall number of confirmed malware and be-
nign software downloads and how many of these down-
loads are ad-driven, we find that if a software download
is reached by clicking on an ad there is a 40% chance
that that software is benign.
Table 6: Ad-based benign download popularity.
Category
Games
Utilities
Music
Business
Video
Graphics
Social
Percentage
32%
30%
15%
11%
8%
2%
2%
To further understand what type of benign software
downloads are ad-driven, we investigate through manual
analysis 100 randomly selected samples of benign soft-
ware download events. Table 6 shows the type of soft-
ware that is represented in our sample and their relative
popularity. Games and utilities are the most popular cat-
egories, comprising 62% of all downloads. For example,
the game “Trion Worlds” is the most popular with 17
downloads, followed by “Spotify” with 10 downloads.
6 Detecting SE Download Attacks
In this section, we measure the antivirus (AV) detec-
tion rate for SE downloads and group them into broad
malware classes using AV labels. Also, we show that it
is possible to accurately detect SE download attacks by
constructing a statistical classifier that uses features de-
rived from the SE attack measurements we presented in
Section 5.
6.1 Antivirus Detection
To assess how AV products cope with SE downloads,
we scan each SE download sample in our dataset with
more than 40 AV engines (using VirusTotal.com). We
scanned each of the samples on the day we collected
them. Then, we also “aged” the samples for a period
of one month, and rescanned them with the same set of
AV engines. If at least one of the top five AV vendors
(w.r.t. market share) and a minimum of two others detect
it, we label the executable as malicious.
We first group malicious downloads into three broad
classes, namely malware, adware and PUP. These
USENIX Association  
25th USENIX Security Symposium  783
11
PUP#
Adware# Malware#
Undetected#
Invent+Impersonate+Comply#
Invent+Impersonate+Alarm#
Repackage+En7ce#
samples. The remaining 25%− 30% is therefore labeled
as undetected in Figure 4.
Table 7 shows the AV detection rate on the day of
download for malware, adware and PUPs. Namely, we
consider all SE download samples that were detected by
AVs after aging and rescanning (i.e., after one month),
and show the percentage of these samples that were also
detected on the day we first observed them being down-
loaded. As can be seen, the detection rate in this case
is quite small, thus confirming the reactive nature of AV
detection.
0%#
10%#
20%#
30%#
40%#
50%#
60%#
70%#
80%#
90%#
100%#
Table 7: Zero day AV detections.
Figure 4: AV detections one month after download.
classes are meant to roughly indicate the potential “ag-
gressiveness” of the malicious software. We assign these
class labels based on a conservative set of heuristics that
consist of matching keywords on the labels provided by
the AVs. For instance, to identify adware we look for the
string “adware” as well as the names of several popular
adware applications (e.g., “amonetize,” etc.). Similarly,
for the PUP class we look for the strings such as “PUP”,
“PUA” and popular PUP application names. If both PUP
and adware match, we label the sample based on a ma-
jority voting rule (across the different AV vendor labels).
In the case of a tie, we conservatively label the sample
as PUP. The remaining samples are labeled as malware,
and manually reviewed for verification purposes.
Figure 4 shows the percentage of attacks that
in the download of malware, adware, and
result
PUP,
respectively.
We show a breakdown for
the top three deception/persuasion categories, which
in aggregate represent more than 95% of all ad-
driven SE attacks.
The majority of malicious
downloads in the invent+impersonate+comply and in-
vent+impersonate+alarm deception/persuasion tactics