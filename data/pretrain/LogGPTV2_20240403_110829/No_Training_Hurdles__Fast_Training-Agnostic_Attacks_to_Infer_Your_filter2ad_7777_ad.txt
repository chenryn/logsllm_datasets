recognize that the unidentified character “×” corresponds to the
backspace key and that the word should be “about”. In another case,
a user may press the left arrow key to move the cursor backward,
insert some text, and then press the right arrow key to return the
cursor to the original position. Hence, the left and right arrow
keys often appear in pairs and are each pressed multiple times. In
this way, an attacker may infer the word “about” from a CSI word
group recovered as “aut◁◁bo▷▷”, with unidentified samples “◁” and
“▷” corresponding to left and right arrow keys, respectively.
4 EXPERIMENT RESULTS
We implement the training-agnostic keystroke eavesdropping at-
tack using USRPs. The prototype attack system includes a wireless
transmitter and a receiver. Each node is a USRP X300 with 40 MHz
bandwidth CBX daughterboards [14]. The channel estimation algo-
rithm runs at the receiver to extract the CSI for key inference.
The target user operates a desktop computer with a Dell SK-8115
USB wired standard keyboard. The transmitter and the receiver
are placed at opposite positions relative to the keyboard. We place
the transmitter at a distance of 3 meters away from the keyboard,
and the receiver under the 2 cm-thick desk, at a distance of 50
cm away from the keyboard. Also, there is a 4 cm-thick wooden
barrier between the transmitter and the keyboard. Thus, both the
transmitter and the receiver are not within line-of-sight of the
target user. We also form a dictionary using the top 1,500 most
frequently used English words [13].
4.1 Example Recovery Process
In this section, we will demonstrate the process of recovering a
sample user’s typed text to illustrate the attack and the sort of
performance that may be expected.
CSI Sample Extraction: To extract the CSI samples from the
CSI time series, we utilize the same pre-processing step as these
existing techniques [6, 18]. Correspondingly, we implement the
pre-processing through three phases, which are noise removal,
Principle Component Analysis (PCA) [30], and segmentation. First,
we experimentally observe the frequency of the CSI influenced by
keystrokes always lies within a low frequency range of 2 to 30 Hz.
Thus, we utilize a Butterworth low-pass filter [24] to mitigate the
impact of ambient noise, which normally has a higher frequency.
Initially, the receiver obtains CSI from all subcarriers. We then
apply the PCA technique to decrease computational complexity by
Figure 4: Assume a simple dictionary of three words “apple”,
“hat”, and “old”, typed in that order by the user. The alphabet
of this dictionary consists of 8 letters “a”,“p”,“l”,“e”,“h”,“t”,“o”,
and “d”. Dictionary demodulation maps each letter in this
alphabet to the corresponding CSI sample, and any further
CSI word groups may simply have this mapping applied
to them. After matching, suppose the user then types the
word “deed", the attacker can directly demodulate the ob-
served CSI word group, which did not appear in the dictio-
nary. Next, assume instead the second typed word is “would”.
Since “w” and “u” do not appear in the alphabet of this sim-
ple dictionary, the attacker cannot decode them but can con-
tinue decoding the other letters “o”, “l”, and “d”.
(cid:44) TiC then
F ← allowable failure threshold
f laд ← true
for j ∈ {i + 1,· · · ,i + F} do
Algorithm 2 Error Handling
1: [T(i +1)C ,U] = Joint_Demod(Si ,TiC ,SiC ,U)
2: if T(i +1)C
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15: end if
end for
if f laд then
U ← U ∪ Si
T(i +1)C ← TiC
end if
end if
▷ demodulation success
[T(j+1)C ,U]=Joint_Demod(Sj ,TjC ,SjC ,U)
if T(j+1)C
(cid:44)TjC then
f laд ← false; break
▷ demodulation success
▷ reset failure count
▷ reached failure threshold
▷ skip Si
each step i based on the demodulation result for Si. Finally, when
the mapping is complete and applied to the CSI word groups in the
undemodulated set, any errors in CSI classification or typos will
persist, but not further damage the results. The attacker can use
some common knowledge to work out these errors and any other
ambiguities.
In the event the cascading errors do not seem to be avoidable,
this is evidence that the wireless channel has changed, because as
previously mentioned the wireless channel is time-varying. In this
case, the dictionary demodulation may be begun anew, so that the
attack can adapt to the changes.
CSI word group 1CSI word group 2CSI word group 3spacespaceapplehatoldaplehtoddictionary demodulationalphabet matchingdeed??o??ldafter matchingspacespacespaceSession 9B: Mobile 2 CCS’18, October 15-19, 2018, Toronto, ON, Canada1753Figure 5: The CSI word group for the word “sense”.
Figure 6: The evolution of the amount of candidates re-
turned as words are processed.
converting the received CSI into a set of orthogonal components,
called principle components [30], which most represent the effects
of the keystrokes. The segmentation phase separates the full CSI
time series into the individual CSI samples corresponding to single
unknown keystrokes. After the receiver assigns the space character
to the most frequently appearing CSI sample group, the remaining
samples are grouped into CSI word groups. Figure 5 shows the CSI
word group for the word “sense”. The full data contains five CSI
samples caused by pressing the keys ‘s’, ‘e’, ‘n’, ‘s’, and ‘e’ as visible
on the figure. By using Dynamic Time Warping, we can classify
the five samples into three sets, including the pair of the first and
fourth samples, the pair of the second and fifth samples, and the
third sample alone.
Next, we illustrate how the collected CSI word groups can be
narrowed down to the typed content. We choose the Harvard sen-
tences [23] to be typed in for our experiments; these are phonetically
balanced sentences commonly used for testing speech recognition
techniques. For this example recovery, we randomly select five
sentences from these representative English sentences, with a total
of 41 words. While we process the collected CSI, we record Csinдle,
which is the number of words that have the same inter-element
relationship matrix as the current CSI word group under processing,
and Cjoint , which is the number of candidates returned by the joint
demodulation algorithm for each CSI word group.
Figure 6 shows Csinдle and Cjoint during the processing of this
sentence. To facilitate understanding, we also mark the CSI sample
sets on this figure. For example, f1, f2, and f3 represent the CSI
sample sets caused by typing the letters ‘t’, ‘h’, ‘e’, respectively. We
can see that Csinдle is 112 for three-letter words, and consequently
Cjoint increases dramatically from 112 to 6,944 and then to 210,963
as the second and third CSI word groups are added, as these word
Figure 7: Example paragraph recovery.
groups share no common CSI samples. However, as more CSI word
groups are added, the joint demodulation algorithm finds more
common CSI samples, which shrinks the search space. Cjoint drops
sharply from 210,963 to 3,304 after the fourth CSI word group is
processed, and further reduces to 15 as the remaining CSI word
groups are processed.
After the demodulation phase, two candidates are returned as
shown in Figure 7. The two differ by only one word; the second
word is either “boy" or “box". Even for the wrong candidate, 97.6%
of the words are successfully recovered, and all characters except
one. The example paragraph also contains five words (“rod”, “pink”,
“salmon”, “kick”, and “feet”) that are not in the dictionary. These
are still successfully recovered, however, because their constituent
CSI samples also appear in other words, and their sample/letter
mappings have already been determined by the matching phase.
4.2 Eavesdropping Accuracy
We now quantify the general performance of our attack. We de-
fine the word recovery ratio as the ratio of successfully recovered
words to the total number of input words. We employ this metric
to ascertain the accuracy of our attack using 100 online articles ran-
domly selected from CNN, New York Times, and Voice of America.
For comparison purposes, we also apply the traditional frequency
analysis technique to the segmented CSI samples.
Single Article Recovery. We first type a piece of CNN news [2]
4.2.1
into a computer, and collect the CSI while typing. We then extract
the CSI samples and run the demodulation algorithm. Suppose the
demodulation algorithm returns N candidates for the typed content.
We use W RRi (i ∈ {1,· · · , N}) to denote the word recovery ratio
for the ith candidate. We consider the overall word recovery ratio
W RR of the proposed attack to be calculated as the average of these
word recovery ratios for each candidate: W RR =(cid:80)N
Figure 8 shows the overall word recovery ratio as a function of
the number of typed words. We can observe for the first couple of
typed words, the ratio is less than 0.17, because these words are
not in the dictionary or the joint demodulation algorithm returns
wrong candidates. As more words are typed in, the ratio increases
significantly and fluctuates, since newly typed words may or may
not be identified correctly in the various candidates. After a suffi-
cient number of words are typed, the mapping between CSI samples
and the alphabetic letters converges to only one candidate. As a
result, the word recovery ratio stabilizes at a high value. As shown
i =1
W RRi
.
N
Time (s)02468Amplitude×10-3681012Original CSI time seriesTime (s)02468Amplitude×10-381012After filter1st2nd4th3rd5th6944 210963 3304 99 99 61 15 c9c12c11      the       boy       was       there      when     the     sun     rose  c1c2c3c4c5c6c7c8c9c1c2c3c10c3c1c2c3c10c5c9c3c7c2c3c11CSI sample: Input: 2 words 3 words 4 words 6 words 7 words 8 words 5 words Csingle:Cjoint:112 112 112 8 249 112 112 249 Recovering words not in the dictionary: The boy/box was there when the sun rose. A *** is used to catch **** *****. The source of the huge river is the clear spring. **** the ball straight and follow through. Help the woman get back to her ****. Input paragraph: The boy was there when the sun rose. A rod is used to catch pink salmon. The source of the huge river is the clear spring. Kick the ball straight and follow through. Help the woman get back to her feet.  (1) rod;  (2) pink; (3) salmon; (4) Kick; (5) feet. Searching results: Step	
  1	
  Step	
  2	
  Session 9B: Mobile 2 CCS’18, October 15-19, 2018, Toronto, ON, Canada1754Figure 8: W RR vs. word count
Figure 9: Comparing distributions.
Figure 10: Recovered words.
Figure 11: Word recovery ratios vs. CSI
sample classification errors.
Figure
and LW RR >0.9.
12:
CDFs
of
LW RR >0.8
Figure 13: Frequency analysis vs. the
proposed attack.
in Figure 8, when more than 52 words have been typed, the overall
word recovery ratio remains above 0.96.
For meaningful results, we apply the frequency analysis recov-
ery technique to compare with our method. Figure 9(a) shows the
typical distribution of frequencies of English letters [16], while
Figure 9(b) shows the distribution of letters in the typed text. Be-
cause the typed text is short and not representative of the whole
English language, the sample distribution is not perfectly equal to
the typical distribution. This difference is highlighted in Figure 9(c)
and causes the word recovery ratio for the frequency analysis to be
as low as 0.07. Figure 10 shows parts of the recovery results using
the frequency analysis and our method. The content recovered us-
ing the frequency analysis is meaningless, whereas our new attack
successfully recovers the typed words.
Impact of CSI sample classification errors and dictionary
size: As discussed in Section 3.3.5, errors in grouping CSI samples
during the pre-processing step may occasionally lead to a failure in
demodulating a CSI word group when the pattern of the word is
not correctly detected. To test the impact of this on the overall word
recovery ratio, we artificially introduce errors into the groupings
and attempt the demodulation algorithm using the intentionally in-
correct data. Specifically, we vary the number of correctly grouped
CSI samples from 40% to 100% in intervals of 5%, and measure the
resulting overall word recovery ratio. We also examine the effects
of using dictionaries of three different sizes, including the 500, 1000,
and 1500 most frequently used words.
We repeat this experiment 10 times and present the average
results in Figure 11. Intuitively, more correctly classified CSI sam-
ples result in higher word recovery ratios, as do larger dictionaries.
Nonetheless, we also note that only 80% of CSI samples need be
correctly classified for the overall word recovery ratios to achieve
0.86, 0.81, and 0.7 for the various dictionary sizes.
4.2.2 Average Article Recovery. We repeat the above experiment for
100 online articles. Intuitively based on the discussed observations,
the proposed attack should achieve a high word recovery ratio for
a long text. Considering a desired overall word recovery ratio of 0.8
or 0.9, let LW RR >0.8 and LW RR >0.9 denote the required number of
typed words from each article to satisfy those ratios, respectively.
Figure 12 shows the empirical cumulative distribution functions
(CDFs) of LW RR >0.8 and LW RR >0.9, indicating conclusively longer
input text results in higher word recovery ratios. Specifically, for
more than 82.4% of articles, the achieved word recovery ratio is
greater than 0.8 and 0.9 when the number of these words is greater
than 27 and 42, respectively.
Figure 13 compares the efficacy of our attack and the frequency
analysis technique. Our attack can achieve a 0.82 word recovery
ratio after 50 typed words, whereas the frequency analysis requires
typing 150 words before any can be successfully recovered. Indeed,
the highest ratio achieved by the frequency analysis in these online
articles is around 0.1, after 450 words, while in stark contrast our
attack stabilizes around 0.95 after 150 words.
4.3 Time Complexity Analysis
As our attack requires no training, its processing time is naturally
of interest. The comparison of inter-element relationship matrices
is the dominant part of the demodulation phase of our dictionary