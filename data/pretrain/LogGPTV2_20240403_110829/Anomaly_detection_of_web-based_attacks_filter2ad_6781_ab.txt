parameters. This becomes apparent when the relative fre-
quencies of all possible 256 characters are sorted in descend-
ing order.
The algorithm is based only on the frequency values them-
selves and does not rely on the distributions of particular
characters. That is, it does not matter whether the character
with the most occurrences is an ‘a’ or a ‘/’. In the following,
the sorted, relative character frequencies of an attribute are
called its character distribution.
For example, consider the parameter string ‘passwd’ with
the corresponding ASCII values of ‘112 97 115 115 119 100’.
The absolute frequency distribution is 2 for 115 and 1 for the
four others. When these absolute counts are transformed into
sorted, relative frequencies (i.e., the character distribution),
the resulting values are 0.33, 0.17, 0.17, 0.17, 0.17 followed
by 0 occurring 251 times.
For an attribute of a legitimate query, one can expect that
the relative frequencies slowly decrease in value. In case of
malicious input, however, the frequencies can drop extremely
fast (because of a peak caused by a single character with a
very high frequency) or nearly not at all (in case of random
values).
255
The character distribution of an attribute that is perfectly
normal (i.e., non-anomalous) is called the attribute’s ideal-
ized character distribution (ICD). The idealized character
distribution is a discrete distribution with:
i=0 ICD(i) = 1.0.
ICD : (cid:0) (cid:3)→  with (cid:0) = {n ∈ N|0 ≤ n ≤ 255},  = {p ∈
(cid:2)|0 ≤ p ≤ 1} and 
The relative frequency of the character that occurs n-most
often (0-most denoting the maximum) is given as ICD(n).
When the character distribution of the sample parameter
‘passwd’ is interpreted as the idealized character distribution,
then ICD(0) = 0.33 and ICD(1) to ICD(4) are equal to 0.17.
In contrast to signature-based approaches, this model has
the advantage that it cannot be evaded by some well-known
attempts to hide malicious code inside a string.
In fact,
signature-based systems often contain rules that raise an
alarm when long sequences of 0x90 bytes (the nop operation
in Intel x86-based architectures) are detected in a packet.
An intruder may substitute these sequences with instructions
that have a similar behavior (e.g., add rA,rA,0, which adds
0 to the value in register A and stores the result back to A).
By doing this, it is possible to prevent signature-based sys-
tems from detecting the attack. Such sequences, nonetheless,
cause a distortion of the attribute’s character distribution,
and, therefore, the character distribution analysis still yields
a high anomaly score. In addition, characters in malicious in-
put are sometimes disguised by xor’ing them with constants
or shifting them by a ﬁxed value (e.g., using the ROT-13
code). In this case, the payload only contains a small rou-
tine in clear text that has the task of decrypting and launch-
ing the primary attack code. These evasion attempts do not
change the resulting character distribution and the anomaly
score of the analyzed query parameter is unaﬀected.
4.2.2 Detection
Given an idealized character distribution ICD, the task of
the detection phase is to determine the probability that the
character distribution of a query attribute is an actual sam-
ple drawn from its ICD. This probability, or more precisely,
the conﬁdence in the hypothesis that the character distribu-
tion is a sample from the idealized character distribution, is
calculated by a statistical test.
This test should yield a high conﬁdence in the correctness
of the hypothesis for normal (i.e., non-anomalous) attributes
while it should reject anomalous ones. The detection algo-
rithm uses a variant of the Pearson χ2-test as a ‘goodness-
of-ﬁt’ test [4].
For the intended statistical calculations, it is not neces-
sary to operate on all values of ICD directly. Instead, it is
enough to consider a small number of intervals, or bins. For
example, assume that the domain of ICD is divided into six
segments as shown in Table 1. Although the choice of six
bins is somewhat arbitrary1, it has no signiﬁcant impact on
the results.
Segment
x-Values
0
0
1
1-3
2
4-6
3
4
5
7-11
12-15
16-255
Table 1: Bins for the χ2-test
The expected relative frequency of characters in a segment
can be easily determined by adding the values of ICD for the
corresponding x-values. Because the relative frequencies are
sorted in descending order, it can be expected that the values
of ICD(x) are more signiﬁcant for the anomaly score when x
is small. This fact is clearly reﬂected in the division of ICD’s
domain.
When a new query attribute is analyzed, the number of
occurrences of each character in the string is determined.
Afterward, the values are sorted in descending order and
combined according to Table 1 by aggregating values that
belong to the same segment. The χ2-test is then used to cal-
culate the probability that the given sample has been drawn
from the idealized character distribution. The standard test
requires the following steps to be performed.
1. Calculate the observed and expected frequencies - The
observed values Oi (one for each bin) are already given.
The expected number of occurrences Ei are calculated
by multiplying the relative frequencies of each of the
six bins as determined by the ICD times the length of
the attribute (i.e., the length of the string).
2. Compute the χ2-value as χ2 = i<6
that i ranges over all six bins.
i=0
(Oi−Ei)2
Ei
- note
4.2.1 Learning
The idealized character distribution is determined during
the training phase. For each observed query attribute, its
character distribution is stored. The idealized character dis-
tribution is then approximated by calculating the average of
all stored character distributions. This is done by setting
ICD(n) to the mean of the nth entry of the stored character
distributions ∀n : 0 ≤ n ≤ 255 . Because all individual char-
acter distributions sum up to unity, their average will do so as
well, and the idealized character distribution is well-deﬁned.
3. Determine the degrees of freedom and obtain the sig-
niﬁcance - The degrees of freedom for the χ2-test are
identical to the number of addends in the formula above
minus one, which yields ﬁve for the six bins used. The
actual probability p that the sample is derived from
the idealized character distribution (that is, its signif-
icance) is read from a predeﬁned table using the χ2-
value as index.
1The number six seems to have a particular relevance to the
ﬁeld of anomaly detection [32].
The derived value p is used as the return value for this
model. When the probability that the sample is drawn from
the idealized character distribution increases, p increases as
well.
probability of a single path is the product of the probabili-
ties of the emitted symbols pSi (oi) and the taken transitions
p(ti). The probabilities of all possible output words w sum
up to 1.
4.3 Structural Inference
Often, the manifestation of an exploit is immediately vis-
ible in query attributes as unusually long parameters or pa-
rameters that contain repetitions of non-printable characters.
Such anomalies are easily identiﬁable by the two mechanisms
explained before.
There are situations, however, when an attacker is able to
craft her attack in a manner that makes its manifestation
appear more regular. For example, non-printable characters
can be replaced by groups of printable characters. In such
situations, we need a more detailed model of the query at-
tribute that contains the evidence of the attack. This model
can be acquired by analyzing the parameter’s structure. For
our purposes, the structure of a parameter is the regular
grammar that describes all of its normal, legitimate values.
4.3.1 Learning
When structural inference is applied to a query attribute,
the resulting grammar must be able to produce at least all
training examples. Unfortunately, there is no unique gram-
mar that can be derived from a set of input elements. When
no negative examples are given (i.e., elements that should
not be derivable from the grammar), it is always possible
to create either a grammar that contains exactly the train-
ing data or a grammar that allows production of arbitrary
strings. The ﬁrst case is a form of over-simpliﬁcation, as
the resulting grammar is only able to derive the learned in-
put without providing any level of abstraction. This means
that no new information is deduced. The second case is a
form of over-generalization because the grammar is capable
of producing all possible strings, but there is no structural
information left.
The basic approach used for our structural inference is to
generalize the grammar as long as it seems to be ‘reasonable’
and stop before too much structural information is lost. The
notion of ‘reasonable generalization’ is speciﬁed with the help
of Markov models and Bayesian probability.
In a ﬁrst step, we consider the set of training items (i.e.,
query attributes stored during the training phase) as the out-
put of a probabilistic grammar. A probabilistic grammar is a
grammar that assigns probabilities to each of its productions.
This means that some words are more likely to be produced
than others, which ﬁts well with the evidence gathered from
query parameters. Some values appear more often, and this
is important information that should not be lost in the mod-
eling step.
A probabilistic regular grammar can be transformed into
a non-deterministic ﬁnite automaton (NFA). Each state S
of the automaton has a set of nS possible output symbols o
which are emitted with a probability of pS(o). Each transi-
tion t is marked with a probability p(t) that characterizes the
likelihood that the transition is taken. An automaton that
has probabilities associated with its symbol emissions and its
transitions can also be considered a Markov model.
The output of the Markov model consists of all paths from
its start state to its terminal state. A probability value can be
assigned to each output word w (that is, a sequence of output
symbols o1, o2, . . . , ok). This probability value (as shown in
Equation 4) is calculated as the sum of the probabilities of all
distinct paths through the automaton that produce w. The
p(w) = p(o1, o2, . . . , ok) =
(paths p f or w) 	(states ∈ p) pSi (oi) ∗ p(ti)
(4)
Start
0.3
0.7
a | p(a) = 0.5
b | p(b) = 0.5
0.2
a | p(a) = 1
0.4
1.0
0.4
c | p(c) = 1
b | p(b) = 1
1.0
1.0
Terminal
Figure 2: Markov Model Example
For example, consider the NFA in Figure 2. To calculate
the probability of the word ‘ab’, one has to sum the probabil-
ities of the two possible paths (one that follows the left arrow
and one that follows the right one). The start state emits no
symbol and has a probability of 1. Following Equation 4, the
result is
(1.0 ∗ 0.3 ∗ 0.5 ∗ 0.2 ∗ 0.5 ∗ 0.4) +
(1.0 ∗ 0.7 ∗ 1.0 ∗ 1.0 ∗ 1.0 ∗ 1.0)
p(w) =
= 0.706
(5)
The target of the structural inference process is to ﬁnd a
NFA that has the highest likelihood for the given training
elements. An excellent technique to derive a Markov model
from empirical data is explained in [30]. It uses the Bayesian
theorem to state this goal as
p(M odel|T rainingData) =
p(T rainingData|M odel) ∗ p(M odel)
(6)
p(T rainingData)
The probability of the training data is considered a scal-
ing factor in Equation 6 and it is subsequently ignored. As
we are interested in maximizing the a posteriori probability
(i.e., the left-hand side of the equation), we have to maximize
the product shown in the enumerator on the right-hand side
of the equation. The ﬁrst term – the probability of the train-
ing data given the model – can be calculated for a certain
automaton (i.e., for a certain model) by adding the probabil-
ities calculated for each input training element as discussed
above. The second term – the prior probability of the model
– is not as straightforward.
It has to reﬂect the fact that,
in general, smaller models are preferred. The model proba-
bility is calculated heuristically and takes into account the
total number of states N as well as the number of transitions
S trans and emissions S emit at each state S. This is
justiﬁed by the fact that smaller models can be described
with less states as well as fewer emissions and transitions.
The actual value is derived as shown in Equation 7.
p(M odel) =
(7)
(N + 1)S trans ∗ (N + 1)S emit
(cid:3)
S∈States
The term that is maximized – the product of the probabil-
ity of the model given the data, times the prior probability
of the model itself – reﬂects the intuitive idea that there is a
conﬂict between simple models that tend to over-generalize
and models that perfectly ﬁt the data but are too complex.
Models that are too simple have a high model probabil-
ity, but the likelihood for producing the training data is ex-
tremely low. This yields a small product after both terms
are multiplied. Models that are too complex have a high
likelihood of producing the training data (up to 1 when the
model only contains the training input without any abstrac-
tions), but the probability of the model itself is very low.
By maximizing the product, the Bayesian model induction
approach creates automatons that generalize enough to re-
ﬂect the general structure of the input without discarding
too much information.
The model building process starts with an automaton that
exactly reﬂects the input data and then gradually merges
states. This state merging is continued until the a posteriori
probability no longer increases. There are a number of op-
timizations such as the Viterbi path approximation and the
path preﬁx compression that need to be applied to make that
process eﬀective. The interested reader is referred to [30] and
[31] for details. Alternative applications of Markov models
for intrusion detection have been presented in [3] and in [35].
4.3.2 Detection
Once the Markov model has been built, it can be used
by the detection phase to evaluate query attributes by de-
termining their probability. The probability of an attribute
is calculated in a way similar to the likelihood of a training
item as shown in Equation 4. The problem is that even legi-
timate input that has been regularly seen during the training
phase may receive a very small probability value because the
probability values of all possible input words sum up to 1.
Therefore, we chose to have the model return a probability
value of 1 if the word is a valid output from the Markov
model and a value of 0 when the value cannot be derived
from the given grammar.
4.4 Token Finder
The purpose of the token ﬁnder model is to determine
whether the values of a certain query attribute are drawn
from a limited set of possible alternatives (i.e., they are to-
kens or elements of an enumeration). Web applications often
require one out of a few possible values for certain query
attributes, such as ﬂags or indices. When a malicious user
attempts to use these attributes to pass illegal values to the
application, the attack can be detected. When no enumera-
tion can be identiﬁed, it is assumed that the attribute values
are random.
4.4.1 Learning
The classiﬁcation of an argument as an enumeration or as
a random value is based on the observation that the number
of diﬀerent occurrences of parameter values is bound by some
unknown threshold t in the case of an enumeration while it
is unrestricted in the case of random values.
When the number of diﬀerent argument instances grows
proportional to the total number of argument instances, the
use of random values is indicated. If such an increase cannot
be observed, we assume an enumeration. More formally, to
decide if argument a is an enumeration, we calculate the
statistical correlation ρ between the values of the functions
f and g for increasing numbers 1, . . . , i of occurrences of a.
The functions f and g are deﬁned as follows on N0.
f (x) = x
g(x) =
g(x − 1) + 1,
if the xth value for a is new
g(x − 1) − 1,
if the xth value was seen before
0,
if x = 0
(cid:4)(cid:5)(cid:5)(cid:5)(cid:5)(cid:5)(cid:5)(cid:5)(cid:6)
(cid:5)(cid:5)(cid:5)(cid:5)(cid:5)(cid:5)(cid:5)(cid:7)
(8)
(9)
The correlation parameter ρ is derived after the training
data has been processed. It is calculated from f and g with
their respective variances Var(f ), Var(g) and the covariance
Covar(f,g) as shown below.