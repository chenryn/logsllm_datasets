title:Bubble Trouble: Off-Line De-Anonymization of Bubble Forms
author:Joseph A. Calandrino and
William Clarkson and
Edward W. Felten
Bubble Trouble: Off-Line De-Anonymization of Bubble Forms
Joseph A. Calandrino, William Clarkson and Edward W. Felten
Department of Computer Science
Princeton University
Abstract
Fill-in-the-bubble forms are widely used for surveys,
election ballots, and standardized tests.
In these and
other scenarios, use of the forms comes with an implicit
assumption that
individuals’ bubble markings them-
selves are not identifying. This work challenges this
assumption, demonstrating that ﬁll-in-the-bubble forms
could convey a respondent’s identity even in the absence
of explicit identifying information. We develop methods
to capture the unique features of a marked bubble and
use machine learning to isolate characteristics indicative
of its creator. Using surveys from more than ninety indi-
viduals, we apply these techniques and successfully re-
identify individuals from markings alone with over 50%
accuracy. This bubble-based analysis can have either
positive or negative implications depending on the ap-
plication. Potential applications range from detection of
cheating on standardized tests to attacks on the secrecy
of election ballots. To protect against negative conse-
quences, we discuss mitigation techniques to remove a
bubble’s identifying characteristics. We suggest addi-
tional tests using longitudinal data and larger datasets
to further explore the potential of our approach in real-
world applications.
1
Introduction
Scantron-style ﬁll-in-the-bubble forms are a popular
means of obtaining human responses to multiple-choice
questions. Whether conducting surveys, academic tests,
or elections, these forms allow straightforward user com-
pletion and fast, accurate machine input. Although not
every use of bubble forms demands anonymity, common
perception suggests that bubble completion does not re-
sult in distinctive marks. We demonstrate that this as-
sumption is false under certain scenarios, enabling use
of these markings as a biometric. The ability to uncover
identifying bubble marking patterns has far-reaching po-
tential implications, from detecting cheating on standard-
ized tests to threatening the anonymity of election bal-
lots.
Bubble forms are widely used in scenarios where con-
ﬁrming or protecting the identity of respondents is crit-
ical. Over 137 million registered voters in the United
States reside in precincts with optical scan voting ma-
chines [27], which traditionally use ﬁll-in-the-bubble pa-
per ballots. Voter privacy (and certain forms of fraud)
relies on an inability to connect voters with these bal-
lots. Surveys for research and other purposes use bub-
ble forms to automate data collection. The anonymity
of survey subjects not only affects subject honesty but
also impacts requirements governing human subjects re-
search [26]. Over 1.6 million members of the high school
class of 2010 completed the SAT [8], one of many large-
scale standardized tests using bubble sheets. Educators,
testing services, and other stakeholders have incentives
to detect cheating on these tests. The implications of
our ﬁndings extend to any use of bubble forms for which
the ability to “ﬁngerprint” respondents may have conse-
quences, positive or negative.
Our contributions. We develop techniques to extract
distinctive patterns from markings on completed bubble
forms. These patterns serve as a biometric for the form
respondent. To account for the limited characteristics
available from markings, we apply a novel combination
of image processing and machine learning techniques
to extract features and determine which are distinctive
(see Section 2). These features can enable discovery of
respondents’ identities or of connections between com-
pleted bubbles.
To evaluate our results on real-world data, we use a
corpus of over ninety answer sheets from an unrelated
survey of high school students (see Section 3). We train
on a subset of completed bubbles from each form, ef-
fectively extracting a biometric for the corresponding re-
spondent. After training, we obtain a test set of addi-
(a) Person 1
(b) Person 2
(c) Person 3
(d) Person 4
(e) Person 4 - Gray
Figure 1: Example marked bubbles. The background color is white in all examples except Figure 1(e), which is gray.
tional bubbles from each form and classify each test set.
For certain parameters, our algorithms’ top match is cor-
rect over 50% percent of the time, and the correct value
falls in the top 3 matches 75% percent of the time. In ad-
dition, we test our ability to detect when someone other
than the expected respondent completes a form, simulta-
neously achieving false positive and false negative rates
below 10%. We conduct limited additional tests to con-
ﬁrm our results and explore details available from bubble
markings.
Depending on the application, these techniques can
have positive or negative repercussions (see Section 4).
Analysis of answer sheets for standardized tests could
provide evidence of cheating by test-takers, proctors, or
other parties. Similarly, scrutiny of optical-scan bal-
lots could uncover evidence of ballot-box stufﬁng and
other forms of election fraud. With further improvements
in accuracy, the methods developed could even enable
new forms of authentication. Unfortunately, the tech-
niques could also undermine the secret ballot and anony-
mous surveys. For example, some jurisdictions publish
scanned images of ballots following elections, and em-
ployers could match these ballots against bubble-form
employment applications. Bubble markings serve as a
biometric even on forms and surveys otherwise contain-
ing no identifying information. We discuss methods for
minimizing the negative impact of this work while ex-
ploiting its positive uses (see Section 5).
Because our test data is somewhat limited, we dis-
cuss the value of future additional tests (see Section 7).
For example, longitudinal data would allow us to better
understand the stability of an individual’s distinguishing
features over time, and stability is critical for most uses
discussed in the previous paragraph.
2 Learning Distinctive Features
in bubble are consistent across the image population—
most are relatively circular and dark in similar locations
with slight imperfections—resulting in a largely homo-
geneous set. See Figure 1. This creates a challenge in
capturing the unique qualities of each bubble and extrap-
olating a respondent’s identity from them.
We assume that all respondents start from the same
original state—an empty bubble with a number inscribed
corresponding to the answer choice (e.g., choices 1-5 in
Figure 1). When respondents ﬁll in a bubble, opportuni-
ties for variation include the pressure applied to the draw-
ing instrument, the drawing motions employed, and the
care demonstrated in uniformly darkening the entire bub-
ble. In this work, we consider applications for which it
would be infeasible to monitor the exact position, pres-
sure, and velocity of pencil motions throughout the col-
oring process.1 In other contexts, such as signature ver-
iﬁcation, these details can be useful. This information
would only strengthen our results and would be helpful
to consider if performing bubble-based authentication, as
discussed in Section 4.
2.1 Generating a Bubble Feature Vector
Image recognition techniques often use feature vectors
to concisely represent the important characteristics of an
image. As applied to bubbles, a feature vector should
capture the unique ways that a mark differs from a per-
fectly completed bubble, focusing on characteristics that
tend to distinguish respondents. Because completed bub-
bles tend to be relatively homogeneous in shape, many
common metrics do not work well here. To measure the
unique qualities, we generate a feature vector that blends
several approaches from the image recognition literature.
Speciﬁcally, we use PCA, shape descriptors, and a cus-
tom bubble color distribution to generate a feature vector
for each image.
Filling in a bubble is a narrow, straightforward task.
Consequently, the space for inadvertent variation is rela-
tively constrained. The major characteristics of a ﬁlled-
1Clarkson et al. [7] use multiple scans to infer the 3D surface texture
of paper, which may suggest details like pressure. We assume multiple
scans to be infeasible for our applications.
2
Figure 2: An example bubble marking with an approx-
imating circle. The circle minimizes the sum of the
squared deviation from the radius. We calculate the
circle’s center and mean radius, the marking’s variance
from the radius, and the marking’s center of mass.
Principal Component Analysis (PCA) is one common
technique for generating a feature set to represent an im-
age [16]. At a high level, PCA reduces the dimensional-
ity of an image, generating a concise set of features that
are statistically independent from one another. PCA be-
gins with a sample set of representative images to gener-
ate a set of eigenvectors. In most of our experiments, the
representative set was comprised of 368 images and con-
tained at least one image for each (respondent, answer
choice) pair. Each representative image is normalized
and treated as a column in a matrix. PCA extracts a set
of eigenvectors from this matrix, forming a basis. We re-
tain the 100 eigenvectors with the highest weight. These
eigenvectors account for approximately 90% of the in-
formation contained in the representative images.
To generate the PCA segment of our feature vector,
a normalized input image (treated as a column vector)
is projected onto the basis deﬁned by the 100 strongest
eigenvectors. The feature vector is the image’s coordi-
nates in this vector space—i.e., the weights on the eigen-
vectors. Because PCA is such a general technique, it may
fail to capture certain context-speciﬁc geometric charac-
teristics when working exclusively with marked bubbles.
To compensate for the limitations of PCA, we capture
shape details of each bubble using a set of geometric
descriptors and capture color variations using a custom
metric. Peura et al. [24] describe a diverse a set of ge-
ometric descriptors that measure statistics about various
shapes. This set includes a shape’s center of mass, the
center and radius of a circle approximating its shape, and
variance of the shape from the approximating circle’s ra-
dius (see Figure 2). The approximating circle minimizes
the sum of squared radius deviations. We apply the spec-
iﬁed descriptors to capture properties of a marked bub-
Figure 3: Each dot is split into twenty-four 15° slices.
Adjacent slices are combined to form a sector, spanning
30°. The ﬁrst few sectors are depicted here.
Figure 4: Feature vector components and their contribu-
tions to the ﬁnal feature vector length.
ble’s boundary. Instead of generating these descriptors
for the full marked bubble alone, we also generate the
center of mass, mean radius, and radial variance for “sec-
tors” of the marked bubble. To form these sectors, we
ﬁrst evenly divide each dot into twenty-four 15° “slices.”
Sectors are the 24 overlapping pairs of adjacent slices
(see Figure 3). Together, these geometric descriptors add
368 features.
Finally, we developed and use a simple custom metric
to represent color details. We divide a dot into sectors as
in the previous paragraph. For each sector, we create a
histogram of the grayscale values for the sector consist-
ing of ﬁfteen buckets. We throw away the darkest bucket,
as these pixels often represent the black ink of the circle
border and answer choice numbering. Color distribution
therefore adds an additional 14 features for each sector,
or a total of 336 additional features.
The resulting feature vector consists of 804 features
that describe shape and color details for a dot and each
of its constituent sectors (see Figure 4). See Section 3.3,
where we evaluate the beneﬁts of this combination of
features. Given feature vectors, we can apply machine
learning techniques to infer distinguishing details and
differentiate between individuals.
3
PCASector ShapeColor Distribution100 Features368 Features336 Features804 FeaturesIdentifying Distinguishing Features
2.2
Once a set of feature vectors are generated for the rele-
vant dots, we use machine learning to identify and utilize
the important features. Our analysis tools make heavy
use of Weka, a popular Java-based machine learning
workbench that provides a variety of pre-implemented
learning methods [12]. In all experiments, we used Weka
version 3.6.3.
We apply Weka’s implementation of the Sequential
Minimal Optimization (SMO) supervised learning al-
gorithm to infer distinctive features of respondents and
classify images. SMO is an efﬁcient method for train-
ing support vector machines [25]. Weka can accept a
training dataset as input, use the training set and learn-
ing algorithm to create a model, and evaluate the model
on a test set. In classifying individual data points, Weka
internally generates a distribution over possible classes,
choosing the class with the highest weight. For us, this
distribution is useful in ranking the respondents believed
to be responsible for a dot. We built glue code to collect
and process both internal and exposed Weka data efﬁ-
ciently.
3 Evaluation
To evaluate our methods, we obtained a corpus of 154
surveys distributed to high school students for research
unrelated to our study. Although each survey is ten
pages, the ﬁrst page contained direct identifying infor-
mation and was removed prior to our access. Each of the
nine available pages contains approximately ten ques-
tions, and each question has ﬁve possible answers, se-
lected by completing round bubbles numbered 1-5 (as
shown in Figure 1).
From the corpus of surveys, we removed any com-
pleted in pen to avoid training on writing utensil or pen
color.2 Because answer choices are numbered, some risk
exists of training on answer choice rather than marking
patterns—e.g., respondent X tends to select bubbles with
“4” in the background. For readability, survey questions
alternate between a white background and a gray back-
ground. To avoid training bias, we included only surveys
containing at least ﬁve choices for each answer 1-4 on a
white background (except where stated otherwise), leav-
ing us with 92 surveys.
For the 92 surveys meeting our criteria, we scanned
the documents using an Epson v700 Scanner at 1200
DPI. We developed tools to automatically identify, ex-
tract, and label marked bubbles by question answered
2We note that respondents failing to use pencil or to complete the
survey anecdotally tended not to be cautious about ﬁlling in the bubbles
completely. Therefore, these respondents may be more distinguishable
than those whose surveys were included in our experiment.
and choice selected. After running these tools on the
scanned images, we manually inspected the resulting im-
ages to ensure accurate extraction and labeling.
Due to the criteria that we imposed on the surveys,
each survey considered has at least twenty marked bub-
bles on a white background, with ﬁve bubbles for the “1”
answer, ﬁve for the “2” answer, ﬁve for the “3” answer,
and ﬁve for the “4” answer.3 For each experiment, we
selected our training and test sets randomly from this set
of twenty bubbles, ensuring that sets have equal numbers
of “1,” “2,” “3,” and “4” bubbles for each respondent and
trying to balance the number of bubbles for each answer
choice when possible.
In all experiments, a random subset of the training set
was selected and used to generate eigenvectors for PCA.
We required that this subset contain at least one exam-
ple from each respondent for each of the four relevant
answer choices but placed no additional constraints on
selection. For each dot in the training and test sets, we