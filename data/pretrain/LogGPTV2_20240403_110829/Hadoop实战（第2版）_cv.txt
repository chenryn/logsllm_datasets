2）Facebook有信心解决HBase在现实使用中存在的问题。HBase现在已经能够提供高一致性、高写吞吐率的键值存储。现有的HDFS NameNode作为管理的中心可能成为系统的瓶颈。Facebook的HDFS团队决定构建一个高可用的NameNode（在Facebook中称为AvatarNode），这对于数据仓库操作也将非常有用。这样好的磁盘读效率就可以满足（向HBase的LSM树中添加Bloom filter，使本地DataNode能够高效地执行读操作并且缓存NameNode的metadata）。在系统故障和容错方面，HDFS能够在磁盘子系统中容忍和隔离故障。整个HBase/HDFS集群的故障是系统容错的一部分，可以考虑将数据迁移到较小的HBase集群中。HBase社区中对“复制”这块内容提供的是一个预定义的路径，用来解决灾难性的故障。
所以整体来说，采用Hadoop+HBase的存储架构，并通过Facebook根据自己需求进行局部的优化和改进之后，这样的存储架构能够满足系统绝大部分需求，提供稳定、高效、安全的存储服务。
19.5.3 Hadoop和HBase的实现
前面介绍了Facebook中存储架构的设计需求和它为什么采用Hadoop和HBase来实现存储架构。这部分我们将为大家介绍Facebook如何实现对Hadoop和HBase的应用及进行哪些优化。
1.实时HDFS
HDFS作为Hadoop的分布式文件存储系统，用来支持MapReduce应用程序的操作。该文件系统具有可扩展性以及较好的流数据处理功能，并且具有较强的容错能力。Facebook通过对HDFS的修改和调整，使HDFS具有支持实时操作和在线服务的特性。
（1）高可用性-AvatarNode
在HDFS中，仅有一个唯一的Master，即NameNode。在这种架构下，当NameNode停止服务后系统将处于不可用状态。对于需要7×24小时服务的软件或系统来说，肯定希望能够获得更稳定的服务，因此这样的架构可能并不是十分理想。所以Facebook根据自己的需求对原来的NameNode进行了一部分扩展，称为AvatarNode，来保证其可用性。
AvatarNode
在原生Hadoop的启动阶段，HDFS的NameNode首先从fsimage文件中读取文件系统的metadata信息。这个metadata信息存储了HDFS中每一个文件的名称、目录以及meta信息。然而，NameNode并不是永久地存储每一个块的位置。因此，当发生故障后，NameNode的重新启动将包含了两个阶段：第一阶段是读取文件系统镜像，导入事务日志，将新的文件系统镜像存储回磁盘；第二阶段是DataNode通过对块的处理向NameNode报告未知块的存储位置信息。Facebook中最大的HDFS集群存储了大约一亿五千万的文件，这两个阶段的操作将需要大约45分钟的时间。
如果在原生Hadoop的基础上采用备份节点的话，那么在发生故障时可以避免从磁盘中读取镜像文件，但是仍然需要从所有的DataNode中收集块的信息，这需要20分钟左右的时间。另一个问题是，当采用备份节点的时候，NameNode需要同步地更新备份节点所存储的数据，这样系统的可靠性（一致性）将低于单个NameNode节点的可靠性。因此，AvatarNode应运而生。
如图19-6所示，一个HDFS集群包含两个AvatarNode：主AvatarNode和备用AvatarNode（同一时间只有一个Node处于活跃状态）。主AvatarNode实际上等同于HDFS的NameNode，不同的是HDFS集群将文件系统的镜像和事务日志的备份存储在NFS中。每当主AvatarNode更新了存储在NFS文件系统中的日志之后，备用AvatarNode节点同时读取该更新，然后将更新的事务应用在自己的文件系统镜像以及日志上。备用AvatarNode节点负责生成主AvatarNode的check-point，需要定期合并事务日志并创建fsimage。因此，在该系统中将不再设置Secondary NameNode。
图 19-6 AvatarNode
在集群中，DataNode不仅仅与主AvatarNode进行通信，同时还与备用AvatarNode进行通信（发送心跳、块报告和块分配信息），这样当发生故障时，备用AvatarNode可以马上变为主动AvatarNode，之后启动的原AvatarNode将成为新的备用AvatarNode。集群中的Avatar DataNode也同时与两个AvatarNode进行通信，他们通过与ZooKeeper的整合来识别哪一个AvatarNode是当前的主AvatarNode。此外，Avatar的DataNode仅仅处理来自主AvatarNode的备份/删除等命令。
对HDFS日志文件的改进
当块文件被关闭或者被同步/写出的时候，HDFS会将块对应的ID存储到事务日志中。由于想尽量减少故障恢复的时间，那么备份AvatarNode需要知晓每一个块的位置。因此Facebook选择同时将块分配操作写入到日志中。
另外，当备份AvatarNode从事务日志中读取日志的时候（此时，主AvatarNode正在写该日志文件），那么备份AvatarNode将有可能只读取到部分的事务（非完整的，将有可能导致系统故障）。为了避免这种情况的发生，Facebook修改了事务日志的格式，使其包含了写入该事务的长度，事务的ID以及事务的校验和。
分布式Avatar文件系统（DAFS）
Facebook将修改后的HDFS命名为分布式Avatar文件系统（Distributed Avatar File System, DAFS），它是一个部署在客户端的分层文件系统，能够提供一个对HDFS的跨故障透明访问。DAFS与ZooKeeper整合在一起。ZooKeeper在某一ZNode上保存了某一集群主AvatarNode节点的物理地址，当客户端尝试与HDFS集群（例如，dfs.cluster.com）进行连接的时候，DAFS将查看ZooKeeper中保存了实际主AvatarNode物理路径的ZNode，然后将之后到来的连接重定位到该主AvatarNode上。如果由于网络环境问题使路径不可达，那么DAFS将从ZooKeeper中进行重新检索。如果在刺激前发生故障恢复事件，DAFS将一直阻塞，直到恢复完成。DAFS对于访问HDFS的应用程序来说是完全透明的，即这些应用程序不知道有DAFS的存在。
（2）Hadoop RPC兼容性问题
在Facebook中需要为消息应用程序运行不同的Hadoop集群。因此，就需要系统能够一次性地在不同的集群中部署新版的软件。这就需要Hadoop的客户端能够与运行不同版本Hadoop软件的服务器进行交互操作。Facebook对Hadoop的RPC软件进行修改使其能够自动地识别所处服务器的软件版本，然后选择合适的协议与之通信。
（3）块放置策略
默认的HDFS放置策略对块的放置位置有很少的限制，对于非本地的副本，块一般随机存放在任意机架的任意节点中。为了降低多个节点同时宕机时数据丢失的概率，Facebook设计了一个可插拔式块放置策略。它将块副本放置在较小的且可配置的一组节点中。通过实验，DAFS使数据丢失概率降低了100倍。
（4）实时作业性能提升
HDFS是一个高吞吐量的系统，然而对于响应时间却并不十分理想。例如，当应对故障时，它更倾向于“重试”或“等到”，而不是对错误进行处理。
RPC超时：Hadoop使用TCP连接来发送RPC调用。当RPC客户端侦测到RPC连接超时时，Facebook并不是马上将连接断开，而是首先向服务器发送一个ping，如果服务器仍旧有效，那么客户端将等待服务器的响应而不断开连接。因为，在这种情况下服务器很可能处于繁忙状态，断开重连要么导致失败要么给服务器增加额外的负担。
然而一直等待服务器的响应将陷入另一个极端。那么在Facebook中为RPC链接设置一个超时时间，当超时之后，客户端尝试向集群的其它DataNode发起连接。
备份文件契约（Lease）机制：另一个改进是快速撤回写者所持有的契约。HDFS仅支持单个写者对文件的写操作，NameNode通过下放契约来控制对文件的写操作。然后在某些情况下当需要对文件进行读的时候，读操作可能与对文件的写操作进行冲突。在之前，后续的操作通过向日志文件添加等待信息来触发文件的“软契约”过期，从而获得该文件的契约。文件的“软契约”相比契约较短，默认值为1分钟，该契约是为了应对这种冲突的发生。然而，这种机制依赖于管道，当发生故障时重建管道的时间过长，对系统性能影响较大。
为了克服这种问题，Facebook设计了一种轻量级的API：recoverLease，它能够显式地撤销文件的契约。当NameNode接收到recoverLease请求时，它马上撤回文件的契约，然后进行契约恢复处理。当契约恢复操作完成之后，请求方可以获得文件的契约。
读取本地副本：HDFS虽然增强了数据存储系统的可扩展性和性能，然而往往带来的是写操作和读操作的延迟。因此，Facebook在其中加入了地点侦测机制，若客户端发现数据处于本地节点中，那么它将优先从本地节点读取数据。
（5）系统新特性
HDFS同步操作：Hflush/sync对于HBase和Scribe来说同样重要，该机制首先将数据缓存在本地，然后将数据写入管道。在数据被完全接收之前，该数据在本地将一直有效，用户可以直接从本地读取到数据的信息。另外，该机制允许后续的操作不必等待操作的完成，在他们看来Hflush/sync完全是透明的。
并发读者：在Facebook中某种应用程序需要对正在写的文件执行读操作。此时，读者需要首先与NameNode进行通信来获取文件的meta信息。由于此时NameNode并没有文件的最新块信息，读者需要与文件某一副本所在DataNode进行通信来获取文件的快信息，然后再对文件执行读操作。
2.HBase的实现
上面介绍了Facebook对Hadoop的一些修改和优化，下面介绍它在实际使用HBase时进行的修改。
（1）数据库ACID特性
一些应用程序开发者总是希望新型数据库系统能够保持原有的ACID特性，Facebook同样对HBase系统进行了改进，使其尽量满足ACID特性。首先，Facebook采用类MVCC的读写一致性控制策略（Read-Write Consistency Control, RWCC）来为系统提供隔离性的保证，并且采用“先写日志”的方法来保证数据的持久性。下面将介绍Facebook是如何对系统进行改进，使其满足原子性和一致性。
首先，系统设计的第一步是要保证数据库系统行级别的原子性。RWCC在大多数情况下可以提供有效的保证。然而，当节点发生故障的时候该保障将可能失效。例如，在最初的时候，系统的日志是顺序存入HLog文件中的。如果在执行日志写操作期间，RegionServer发生故障，那么将可能只有部分日志被写入。Facebook重新设计了HLog，命名为WALEdit，它能够保证写事务要么全部执行要么全部不执行。
HDFS为数据提供了副本，因此需要采用一定的策略来保证系统的一致性。在Facebook中，它们使用管道的机制，当有新数据更新到来的时候，NameNode首先为不同的数据副本创建管道，当所有的副本更新完成之后，副本需要向NameNode发送ACK确认。在此期间，HBase将会一直等待，直到所有的操作完成。假如期间有某一个副本写操作失败，HBase将控制系统参考日志进行回滚操作。另外，Facebook还采用一定机制保证数据不被破坏，在数据读取时，HBase首先检查数据的校验和，当校验和错误，系统将自动删除该份数据，然后检查其他副本。
（2）HBase可用性改进
由于HBase中很多重要信息保存在HBase的Master中，而HBase Master只有一个，当发生故障时将有数据丢失的可能性。为了尽量避免这种情况的发生，Facebook转而将数据存储在ZooKeeper中，因为ZooKeeper采用的是一个“大多数”的策略，数据将被存储在多个节点当中。当某一个节点发生故障时，用户仍旧能从其它节点获取数据。
Facebook指出，HBase集群的停机问题往往是由节点的随机性宕机引起的，并不是由于系统的日常维护工作。因此Facebook通过对系统的改进来尽量缩短停机的时间。例如，某一节点在发起停机请求之后会间歇性地发生停机事件，这是由于较长的数据压缩周期造成的。因此Facebook将压缩设置为可中断性操作，这样能够将停机时间缩短到秒的级别。
另外一个问题是软件的更新。为了应对软件的更新，HBase需要将集群“停机”，然后再更新之后进行“重新启动”。为了处理这个问题，Facebook选择采用轮询的方式对集群节点进行更新。例如，首先对某一台机器进行更新，当这一台机器更新完成之后，系统转而对下一台进行更新，周而复始，直到全部系统更新完成。
在HBase中，当某一个RegionServer发生故障时，处于该机器的HLog需要被重新分配到集群其余有效的节点上。在之前该操作由HMaster来完成，但是由于一个节点上可能保存了大量的HLog，该操作将花费很长的时间。在Facebook中，他们采用ZooKeeper集群来负责HLog的划分，这使得该操作的时间降低了很多倍。
（3）HBase性能提升
对于HBase的写操作，Facebook通过缓存机制将对数据库的多次写减少到更少次数地写。当数据到来的时候，数据首先被写入提交日志，然后并非直接写入数据库而是首先写入到缓存系统MemStore中。当缓存系统容量到达阈值之后，缓存将数据写入HFile中，HFile是不变型HDFS文件（不被更改）。数据的更新采用的是附加的方式，即继续写HFile文件，而并非对HFile文件进行修改。当需要读取数据的时候，HBase控制系统并行读取HFile文件并抽取相关记录进行整合。当一定时间之后，HBase对HFile进行压缩、合并操作，以避免后续读操作带来的延迟。
众所周知，系统中文件数目的多少对系统的读操作以及网络IO都有很大的影响，因此在系统中定期对文件进行压缩是非常有必要的。HBase中的压缩分为两种类型：次要的和主要的。次要的压缩操作仅仅选择部分文件进行压缩。主要的压缩不但对所有的文件进行压缩，并且在必要情况下对系统执行删除、重写以及清除过期数据等操作。在这种情况下，次要压缩产生的效果并不理想，并且生成的HFile文件可能更大，这种文件不但会对块缓存系统的性能产生影响，也会对今后的进一步压缩产生影响。因此在Facebook中对压缩块的大小进行限制，从而避免大数据块的产生。此外，Facebook还对HBase原有的压缩算法进行了改写，避免额外的操作。
对于读操作来说，某一个Region中文件数目的多少对其有很大的影响，在之前的介绍中可以知道，通过对数据的压缩可以大大减少文件的数目。另外Facebook可以通过某些技术来加快文件的搜索，跳过不必要的文件。例如：Bloom Filter和时间戳策略。Bloon Filter记录的是HFile文件特定统计信息，由于Region中文件数目相当多，因此Facebook中通过使用折叠技术（folding），进一步降低Bloom Filter的大小。这样讲Bloom Filter存储到内存之中，从而加快文件的检索。另外通过对时间戳的比对，同样可以加快文件的检索速度。
3.展望
虽然Facebook修改后的Hadoop和HBase存储架构很大程度上满足了其对存储架构的设计需求，但展望未来，Facebook还提出了未来这个存储架构完善的几个方面：
1）对Hadoop和HBase应用迭代的优化；
2）对HBase二级索引和视图摘要的支持，以及对这些特性的异步维护；
3）HBase内存管理和扩充，可通过slab或者JNI进行内存管理，通过flash memory来扩展HBase cache；
4）解决HBase多数据中心replication和冲突问题。
19.6 本章小结
本章按照系统的从简到难、应用的从浅到深，介绍了Hadoop在企业中的应用和实践，涵盖了经封装后直接使用Hadoop模块、修改完善Hadoop设计等内容，特别是大篇幅地介绍了Facebook使用Hadoop+HBase的一些细节。希望大家能认真学习，掌握如何使Hadoop在大型应用中扮演重要的角色，学会基于Hadoop搭建大型应用框架，并能在系统开发应用中根据实际需求修改完善Hadoop。
本章参考资料
如果想要了解Hadoop在Yahoo！应用的更多细节和进展，请关注Yahoo！Hadoop团队的博客（developer.yahoo.com/blogs/hadoop）。
Hadoop在eBay的应用内容是根据eBay研究人员的技术博客[2]
 整理而成的，其中参考了eBay分析平台开发部Anil Madan介绍的Hadoop在eBay的使用情况，大家想要了解Hadoop在eBay应用的更多信息，可以关注eBay研究人员的技术博客（www.ebaytechblog.com）。
百度和即刻搜索使用Hadoop平台的情况则是根据近几届Hadoop中国云计算大会上对应企业研究人员的报告整理而成，大家如果想了解更详细的信息或Hadoop中国云计算大会的相关信息可登录Hadoop in China网站：http：//www.hadooper.cn。
Facebook的企业案例是根据Facebook公开发表的论文[3]
 整理而来。
[1]Alan Gates, Pig and Hive at Yahoo！，http：//developer. yahoo.com/blog/hadoop/posts/2010/08/pig_and_hive_at_yahoo/
[2]Anil Madan, Hadoop-The power of the Elephant, http：//www. ebaytechblog.com/2010/10/29/hadoop-the-power-of-the-elephant/
[3]Dhruba Borthakur, Apache Hadoop Goes Realtime at Facebook, Sigmod 2011
附录A 云计算在线检测平台
本章内容
平台介绍
结构和功能
检测流程
使用介绍
小结
A.1 平台介绍
MapReduce的日趋流行带动了普通程序员学习MapReduce的潮流，它的学习资料也日趋丰富起来。但是MapReduce运行所需的并行环境却成为了入门者学习的最大障碍，主要原因是并行环境的硬件要求高，配置复杂，同时现有的学习资料中鲜有编程实战方面的指导，更多专注在MapReduce的理论知识上。综合这些情况，我们开发了云计算在线检测平台（http：//cloudcomputing.ruc.edu.cn/），为大家提供理论知识测试和利用理论知识进行实战的机会。该平台提供运行程序的并行环境，避免入门者将精力都花费在环境配置上，帮助他们配合本书进行学习和实践。
云计算在线检测平台是一个MapReduce程序检测平台。此平台基于Hadoop集群提供了MapReduce并行程序运行的分布式环境，旨在为MapReduce的入门者提供简单具体的编程练习，使其初步掌握MapReduce框架的编程思想，并拥有使用MapReduce并行化解决实际问题的能力。用户可以根据平台提供的问题背景，开发自己的并行程序并提交运行。平台会根据运行结果反馈给用户一定的信息，以便进行修改或进一步优化。用户也可以在平台上进行分布式系统理论知识的测试，以提高理论水平。同时，此平台结合分布式系统架构Hadoop、MySQL技术和Tomcat技术，提供了在线的分布式并行运行环境，供用户运行自己所提交的并行程序。根据实际的使用结果和平台功能完整性的需求，平台的结构已经从原来的前台用户接口和后台程序运行两个主体结构发展成前台用户接口、后台运行程序和平台程序过滤模块三大部分。前台用户接口负责同用户的交互，包括保存用户提交的代码、返回程序的检测结果等；后台运行程序负责前台收集的用户代码并检测结果，同时将检测的结果交给前台并维护网站用户的信息，提供整个网站的网络服务；代码过滤模块主要实现了雷同代码的过滤和非MapReduce合理框架程序的过滤。
云计算在线检测平台兼顾实战和理论，能让用户在进行理论测试的过程中掌握开源分布式系统架构Hadoop的相关知识和MapReduce的理论知识，能让用户在编程提交和修改再提交的过程中切身体验到如何利用分布式系统Hadoop、MapReduce编程，以及如何用MapReduce并行程序来解决实际问题。总体来说，此平台能够提高用户的理论水平和实战能力，是MapReduce入门者不错的入门指导。
A.2 结构和功能
正如前一节中所介绍的，云计算在线检测平台已发展成由三大部分组成，分别是前台用户接口、后台程序运行及平台程序过滤模块，下面分别对它们进行介绍。
A.2.1 前台用户接口的结构和功能
前台用户接口的功能结构如图A-1所示。它主要包括四部分内容：用户完全服务、实例编程练习、分布式系统理论知识测试、帮助功能（指网站的使用帮助、Hadoop介绍文档，以及网站的中文页面）。下面分别详细介绍这四个功能块。
用户完全服务主要包括注册、登录和更新信息等。注册是指用户在Register页面完成新用户的注册，云计算在线检测平台只对注册用户提供代码检测服务。在注册页面需要填写用户名、注册码（选填）、密码、单位、邮箱等信息，注册成功之后用户就可以使用注册的用户名和密码登录了，同时邮箱会收到一封注册邮件，以防止用户忘记用户名和密码以致无法登录。在注册时如果发生用户名已注册、密码重复错误、验证码输入错误等，将会导致注册失败。注册成功后可以在首页的右上角直接使用用户名和密码进行登录，也可以在login页面完成登录操作。登录成功的用户可以选择login out。更改个人信息是指更改个人密码等信息，如果用户期望做出更改，可以在update your info页面完成。
图 A-1 前台接口的结构图
MapReduce实例编程练习主要包括题目浏览、提交答案、查看提交记录、查看提交源码、查看检测结果。在云计算在线检测平台上，开发小组设计了很多基于MapReduce并行框架能够解决的实际问题。用户可以在problem页面详细浏览各个问题的背景，以及输入输出要求和注意事项。然后利用自己的MapReduce理论知识，针对具体实例问题来编写自己的实例解决代码，并且在submit solution页面提交代码。网站会运行用户提交的代码，然后在网站上反馈相应的结果。用户可以在My submission页面中查看自己的提交记录，也可以单击每一条记录中的source连接查看自己提交的代码，同时还可以单击result栏下面的连接查看检测结果。
分布式系统理论知识测试主要指用户单击首页的theory test之后会出现一份限时半小时的试卷，共20道选择题。这些选择题都是随机从平台中题库里选出来的，题目是关于分布式系统的理论知识，主要集中在Hadoop及其子项目上。用户答题完毕单击提交按钮或在页面上停留的时间超过半小时，所有答案就会提交。平台通过比对之后会将每道题目的正确答案及用户的回答一起返回，并计算出此次测试的分数。
帮助功能主要指网站的使用帮助、网站对应的中文页面，以及Hadoop的介绍文档和用于讨论的BBS版块。网站的使用帮助在首页的FAQs页面下，主要是关于网站在实际使用中要注意的事项。网站对应的中文页面可以点击Chinese链接进入。中文页面也提供了与英文页面完全相同的服务。Hadoop快速指南网站上的Hadoop Quick Start链接和它所提供的在线文档，主要为用户提供一些Hadoop分布式系统的初步认识和安装说明。BBS论坛允许用户在平台上交流MapReduce的学习经验，以及对平台上题目，同时还可以留下自己关于平台使用的疑问。
A.2.2 后台程序运行的结构和功能
后台程序运行的功能结构如图A-2所示。后台中的主要模块也是四部分：Tomcat服务器、MySQL数据库、Hadoop分布式环境、Shell文档。下面详细介绍这四个功能块。
Tomcat服务器：担当网站的Web服务器角色，保证用户能够从网络上访问到平台，并将开发小组基于JSP技术开发的网页呈现在用户的电脑上。
MySQL数据库：其中主要是网站的信息，包括用户个人信息、用户提交记录、网站题库等。基于JSP技术开发的网页通过调用MySQL的接口，获取用户请求的信息，并将其呈现在网页上或将网页上提交的信息保存到数据库中。
图 A-2 后台结构图
Hadoop分布式环境：是整个后台的核心所在，因为它是云计算在线检测平台提供特色服务的核心。开发小组首先在多台计算机上安装好Hadoop分布式系统，形成一个分布式环境，然后再在集群上配置网站提供服务，这就可以保证为用户提交的代码提供并行程序运行所需的真实分布式环境。Hadoop集群的主要功能就是运行用户提交的代码，给出结果。
Shell文档：在检测平台的系统中扮演着人体中血液的角色。它首先将网页保存下来的用户代码进行预处理，比如检测是否是正确的Java程序等，然后再对预处理之后的结果进行预编译，成功之后再将代码提交到Hadoop上，接着再收集Hadoop的运行结果，然后与标准结果进行比对，最后将比对的结果分类返回给前台网页，呈现在用户面前。综合来说，Shell文档将前台功能块和后台功能块串联了起来，以便为用户提供连贯的服务。
A.2.3 平台程序过滤功能
这部分主要实现了两个与用户程序直接相关的功能：非MapReduce合理框架程序过滤和雷同代码程序过滤。添加过滤模块的主要出发点是，管理员发现在平台的使用过程中，部分用户直接提交他人代码或者经过一些初级的代码移动、替换等提交他人代码，甚至有些用户提交的代码所有任务均安排在一个节点的Reduce函数中完成任务，Map函数的功能就是直接输出获取的输入，这种程序看似运用了MapReduce框架，但是并不是合理的MapReduce框架程序，因为它未能利用MapReduce框架来并行处理问题，甚至由于Map函数这个无用过程的存在增加了处理的负担。这两种现象都是不应该出现的，但是由于之前平台是自动运行，只匹配结果是否正确，导致这些不合理代码会被接受。为了避免这些现象，管理员升级了平台，增加了代码过滤模块。下面简要介绍这两个功能实现细节：
（1）非MapReduce合理框架程序过滤功能
MapReduce框架通过Map和Reduce两个函数，实现了集群对海量数据的并行处理。其中Map函数起到数据预处理和分流的功能，Reduce函数再根据不同的key获取不同的Map函数输出流，进行深度数据处理，可见Map函数和Reduce函数二者功能缺一不可。但是在平台使用中，部分用户只是简单地将所有数据的处理任务都放在一个节点的Reduce函数中，Map函数仅输出接受的输入。这种处理方法是不合理的。
通过观察和分析这些程序，管理员发现，用户要想将所有的任务放在一台节点的Reduce函数中处理，那么他就需要将Map输出的key选为一个固定值。所以从这一点出发，在平台的非MapReduce合理框架程序过滤中，管理员首先定位Map函数的输出位置，再定位输出位置中key的位置，如果程序辨别此key值为某个固定值，那么说明用户并未将输入数据分流，是不合理的MapReduce框架程序，从而不执行此程序，输出为MapReduce Error。
（2）雷同代码的过滤
抄袭在平常的工作中非常常见，特别是在计算机领域。从发现有雷同代码出现之后，管理员就开始研读对应的雷同代码检测文献，学习相关方法，并将之运用到平台中。现在平台的雷同代码过滤主要采取以下步骤：
过滤无效字符，替换变量为同一字符；
按照固定窗口大小，滑动获取固定大小的连续字符串；
计算每个字符串的Hash函数值；
按照固定窗口大小，滑动获取固定大小的连续Hash函数值；
获取每个连续函数值串中的最小函数值，结合其位置参数作为代码的指纹，某一位置上的函数值只能出现一次；
计算此代码指纹与代码指纹库中每个指纹的相似度，如果超过某一阈值则判为雷同代码；
界面显示雷同代码，并自动发送邮件给用户和系统管理员。
由于代码抄袭和代码学习之间的界限并不明确，可能会将代码错判为雷同代码，雷同代码的过滤在平台中发挥了巨大作用，模块刚加入之处就判出了两例雷同代码。
代码过滤模块的加入，并不是为了增加用户使用的难度，而是为了规范用户的代码，优化平台的使用。系统管理员会根据实际的使用情况，不断更新扩展此模块功能，使平台功能更加完善，用户使用更加方便。
A.3 检测流程
经过前面两节的介绍，大家对整个平台已经有一个直观整体的认识，那么这个平台是如何运行的呢？它的运行流程是什么？本节将详细介绍云计算在线检测平台检测用户代码的流程。
总体来说，平台对用户代码的检测流程主要包括代码保存、代码预处理、代码运行和结果分析返回、结果显示五个阶段，下面将分别介绍这五个阶段：
代码保存阶段：用户在网页上粘贴自己的代码，点击submit提交之后，网站会把用户的代码保存在服务器上一个唯一的文件中，并在后台数据库中保存这一次提交的信息和代码路径。
代码预处理阶段：用户在提交代码之后，网站在进行代码保存的同时还会调用Shell文档来进行代码的预处理。Shell文档被调用运行之后就会开始用户代码的预处理。首先Shell文档会按照调用的路径参数从本地找到用户代码，然后检测用户代码，比如程序是否是可运行的Java代码、是否符合MapReduce框架要求等。如果预处理成功就会将代码提交给Hadoop分布式环境运行，如果预处理失败就会直接返回并将错误原因呈现到网页界面上。
代码运行阶段：代码预处理成功之后会被提交到Hadoop分布式环境上，Hadoop调用事先已经保存在HDFS（Hadoop分布式文件系统）上的输入数据来运行代码。在平台的处理过程中，代码在Hadoop上的运行和在线下自己提交代码到Hadoop上的运行相同。代码运行结束之后，Shell文档会将结果信息重定向到代码文件中同样唯一的结果信息文件中，以交给下一步处理。
结果分析返回阶段：结果分析返回阶段主要是分析Hadoop运行的结果信息，对结果分类，生成结果文件，然后将相关的信息写入数据库，供平台显示代码运行结果时调用。Shell在分析结果时，首先查看有没有输出结果，如果有输出结果就和标准输出进行对比，正确就返回结果Accepted，错误就返回结果Wrong Answer。如果没有结果，再将输出信息同一些结果关键词进行匹配，然后返回匹配成功的那一类错误信息。
结果显示：用户在My Submission界面点击result一栏的结果链接之后，页面会调用数据库接口，搜索此次提交记录在数据库中对应的记录。找到之后，页面直接获取结果信息文件的路径，然后将其内容显示在页面上，如果代码有误，用户就可以知道代码的错误所在，用户进行调整之后重新提交。
结合上面的介绍，网站处理的流程图如图A-3所示。
图 A-3 网站处理流程图
A.4 使用介绍
前面介绍了云计算在线检测平台的理论内容，本节将从功能使用、题目介绍、返回结果说明、使用注意事项四个方面详细介绍平台的使用方法。
A.4.1 功能使用
本附录第2节介绍了平台中前台用户接口和后台程序运行的结果和功能块。而与用户直接相关的就是前台功能的使用。下面用三个使用实例来说明如何使用前台功能。
1.如何注册用户，如何修改信息？
注册功能的使用流程如下：
1）在首页点击Register链接，进入注册界面；
2）填写个人信息，包括用户名、注册码（选填）、密码、邮箱、单位、国家、验证码等；
3）根据提示进行调整，比如如果提示用户名已存在，就需要换一个用户名，如果提示密码重复错误，就需要重新输入密码等。
4）注册成功，如果注册完之后可以进入注册成功界面，就表示注册成功了，界面上显示的是自己除密码外的所有注册信息，同时用户所注册的邮箱会收到一封包含用户名和密码的注册邮件，以防止忘记用户名或密码。
使用修改信息功能的流程如下：
1）登录之后在首页点击Update your info链接，进入信息修改页面；
2）填写要修改的个人信息；
3）点击提交之后就会进入修改成功界面，界面显示修改的信息。
2.如何提交自己的代码并查看结果？
1）登录之后点击具体题目下的submit按钮，进入代码提交页面，或者点击submit solution链接直接进入提交页面，再或者在首页的problem一栏下输入problem ID直接进入problem，然后点击提交进入代码提交页面；
2）在代码提交页面的空白处粘贴自己的代码，点击提交；
3）提交之后页面自动跳入仅包含此次提交信息的页面，在这个页面中用户能够查看自己提交的代码，同时页面还能够在代码运行结束之后自动更新result一栏的状态，并显示运行结果（此处采用了AJAX技术，由于存在技术兼容问题，所以只有firefox支持），更新之后用户可以点击查看运行结果；
4）用户想查看结果和自己的代码，也可以点击My Submission链接，进入自己的提交记录页面，点击特定记录后的source就可以查看提交的代码了，点击result一栏的结果可以查看具体的结果信息。
3.如何进行理论测试？
1）登录后点击Theory test进入理论测试界面；
2）根据具体的题目选择正确答案，然后提交（理论测试每份试卷限时30分钟，如果在页面上停留的时间超过30分钟，平台也会自己提交页面现有答案）；
3）提交之后页面自动跳入结果页面，显示每到题目的回答是否正确。
A.4.2 返回结果介绍
在平台上提交代码之后在提交历史中的result一栏就可以看到结果。那么都有什么结果？都代表什么意思？针对具体的错误用户应该如何应对？下面将进行详细介绍。