sensitivity attack against electronic watermarks in
images. In IH, 1998.
[21] N. Papernot, P. McDaniel, I. Goodfellow, S. Jha, Z. B.
Celik, and A. Swami. Practical black-box attacks
against machine learning. In ASIACCS, 2017.
[22] K. Rieck, P. Trinius, C. Willems, and T. Holz.
Automatic analysis of malware behavior using
machine learning. Journal of Computer Security, 2011.
[23] D. Sculley, M. E. Otey, M. Pohl, B. Spitznagel,
J. Hainsworth, and Y. Zhou. Detecting adversarial
advertisements in the wild. In KDD, 2011.
[24] K. Selvaraj and N. F. Gutierres. The rise of pdf
malware.
[25] M. Sharif, S. Bhagavatula, L. Bauer, and M. K. Reiter.
Accessorize to a crime: Real and stealthy attacks on
state-of-the-art face recognition. In CCS, 2016.
[26] R. Shokri, M. Stronati, and V. Shmatikov.
Membership inference attacks against machine
learning models. In IEEE S&P, 2017.
[27] D. Silver, A. Huang, C. J. Maddison, A. Guez,
L. Sifre, G. Van Den Driessche, J. Schrittwieser,
I. Antonoglou, V. Panneershelvam, M. Lanctot, et al.
Mastering the game of go with deep neural networks
and tree search. Nature, 2016.
[28] C. Smutz and A. Stavrou. Malicious pdf detection
using metadata and structural features. In ACSAC,
2012.
[29] R. Sommer and V. Paxson. Outside the closed world:
On using machine learning for network intrusion
detection. In IEEE S&P, 2010.
[30] N. ˇSrndi´c and P. Laskov. Detection of malicious pdf
ﬁles based on hierarchical document structure. In
NDSS, 2013.
[31] N. ˇSrndi´c and P. Laskov. Practical evasion of a
learning-based classiﬁer: A case study. In IEEE S&P,
2014.
[32] Y. Taigman, M. Yang, M. Ranzato, and L. Wolf.
Deepface: Closing the gap to human-level performance
in face veriﬁcation. In CVPR, 2014.
[33] F. Tram`er, F. Zhang, A. Juels, M. K. Reiter, and
T. Ristenpart. Stealing machine learning models via
prediction apis. In USENIX Security, 2016.
[34] O. Vinyals, (cid:32)L. Kaiser, T. Koo, S. Petrov, I. Sutskever,
and G. Hinton. Grammar as a foreign language. In
NIPS, 2015.
[35] W. Xu, Y. Qi, and D. Evans. Automatically evading
classiﬁers. In NDSS, 2016.
[36] C. Yang, R. Harkreader, and G. Gu. Empirical
evaluation and new design for ﬁghting evolving twitter
spammers. IEEE TIFS, 2013.
APPENDIX
A. PDF MALWARE CLASSIFIERS
In this section, we give an overview of the Portable Doc-
ument Format (PDF) and PDF malwares, and brieﬂy in-
troduce the two detectors, namely PDFrate [28] and Hi-
dost [30].
A.1 PDF
The Portable Document Format (PDF) is a standardised
ﬁle format that is designed to decouple the document pre-
sentation from the underlying environment platform (e.g.,
application software, hardware or even OSes), thus enabling
consistent presentation of the document across diﬀerent
platforms [16]. A typical PDF ﬁle consists of four parts.
The ﬁrst part – header – contains the magic number and
the version of the format. The second part – body – incorpo-
rates a set of PDF objects comprising the content of the ﬁle.
The third part – cross-reference table (CRT) – is an index
table that gives the byte oﬀset of the objects in the body.
The last part – trailer – includes references to the CRT and
other special objects such as the root subject. We depict an
example of a PDF ﬁle in Figure 13.
The header, CRT and trailer are introduced with %PDF,
xref and trailer keywords, respectively. Objects in the body
of the ﬁle may be either direct (those that are embedded in
another object) or indirect. The indirect objects are num-
bered with a pair of integer identiﬁers and deﬁned between
two keywords obj and endobj. Objects have eight basic types
which are Booleans (representing true or false), numbers,
strings (containing 8-bit characters), names, arrays (ordered
collections of objects), dictionaries (sets of objects indexed
by names), streams (containing large amounts of data, which
can be compressed) and the null objects. It is worth men-
tioning that there are some dictionaries associated with spe-
cial meanings, such as those whose type is JavaScript (con-
taining executable JavaScript code).
A.2 PDF Malwares
Due to its popularity, PDF ﬁles have been extensively ex-
ploited to deliver malware. In addition, given an increasing
number of vulnerabilities in Acrobat readers reported re-
cently [2], the threat of PDF malwares is clearly relevant.
The malicious payploads embedded in the PDFs are often
contained in JavaScript objects or other objects that could
exploit vulnerabilities of a particular PDF reader in use.
Header %PDF-1.5
Body
CRT
Trailer
1 0 obj >endobj
···
21 0 obj null
endobj
xref
0 22
0000000002 65535 f
···
0000000394 00000 n
trailer
···
startxref
1637
%%EOF
Figure 13: An example of a PDF ﬁle structure
A.3 Detectors
Various PDF malware detectors have been proposed in the
literatures. A line of works [13, 18] targeted JavaScript code
embedded in the malicious PDFs (or PDF malware). They
ﬁrst extract a JavaScript code from the PDF, and either
dynamically or statically analyse such a code to assess the
maliciousness of the PDF. Nevertheless, these works would
fail to detect PDF malware wherein the malicious payloads
are not embedded in JavaScript code or the code itself is
hidden [24]. Hence, recent works have taken another ap-
proach, relying on the structural features of the PDFs, to
perform static detection. Structural feature-based detectors
perform detection based on an assumption that there exist
diﬀerences between internal object structures of benign and
malicious PDF ﬁles.
Our experimental evaluations are conducted against two
state-of-the-art structural feature-based detectors, namely
PDFrate [28] and Hidost [30]. These two systems are re-
ported to have very high detection rate on their testing
datasets, and are also studied in previous works on evad-
ing detection [35]. It is worth mentioning that the outputs
of these two detectors are real-value scores which are to be
compared against thresholds to derive detection results. In
our experiments, we make small changes to their original
implementations so that they return binary outputs.
PDFrate..
PDFrate is an ensemble classiﬁer consisting of a large
number of classiﬁcation trees. Each classiﬁcation tree is
trained using a random subset of the training data and based
on an independent subset of features. These features include
object keywords, PDF metadata such as author or creation
data of the PDF ﬁle, and several properties of objects such
as lengths or positions. At the time of classiﬁcation, each
tree outputs a binary decision indicating its prediction on
the maliciousness of the input. The output of the ensemble
classiﬁer is the fraction of trees that consider the input “ma-
licious” (a real-value score raning from 0 to 1). The default
cutoﬀ value is set at 0.5.
PDFrate was trained using 5, 000 benign and 5, 000
malicious PDF ﬁles randomly selected from the Contagio
dataset [6]. The classiﬁer consists of 1, 000 classiﬁcation
trees each of which covers 43 features. The total number
of features covered by all the classiﬁcation trees is 202 (but
only 135 are documented in PDFrate’s documentation).
·103
0.8
C
H
e
d
a
v
E
0.6
0.4
·104
C
H
e
d
a
v
E
0.2
0.15
0.1
0.2
4
BiRand
0.8 1 1.2 1.4 1.6 1.8·103
·104
(a) Nd
C
H
e
d
a
v
E
3
2
1
4 5 6 7 8 9 10·104
BiRand
(c) Nm
C
H
e
d
a
v
E
0.8
0.7
0.6
0.5
0.4
·103
BiRand
1.2 1.4 1.6 1.8 2·103
·104
(a) Nd
·102
C
H
e
d
a
v
E
20
15
10
5
100 110 120 130·102
BiRand
(b) Nt
0.7 0.8 0.9 1 1.1
·104
BiRand
(b) Nt
40
30
20
10
0
4
2
6
(d) Ratios of Nm by
BiRand and EvadeHC
2
1.5
1
C
H
e
d
a
v
E
0.5
9
8 10
10 11 12 13·104
BiRand
(c) Nm
80
60
40
20
0
5
10
15
(d) Ratios of Nm by
BiRand and EvadeHC
20
Figure 14: Average number of blackbox queries required in
evading PDFrate
Figure 15: Average number of blackbox queries required in
evading Hidost
An open-source implementation of PDFrate, namely Mim-
icus [4], is by ˇSrndi´c et al. [31]. We utilise this implementa-
tion in our experiments.
Hidost..
Hidost is a support vector machine (SVM) classiﬁer [30].
SVM aims to ﬁt a hyperplane (which can be expressed using
a small number of support vectors) to training data in such
a manner that data points of both classes are separated with
the largest possible margin. Hidost works by ﬁrst mapping
a data point (representing a submitted PDF ﬁle) to an in-
deﬁnite dimensional space using radial basis function, and
reports the distance between the data point and the hyper-
plane as a measurement of its maliciousness. If the distance
is positive, the PDF ﬁle is considered malicious; otherwise,
the ﬁle is ﬂagged as benign.
Hidost was trained using 5, 000 benign and 5, 000 mali-
cious PDF ﬁles. Hidost operates based on 6, 087 classiﬁca-
tion features, which are structural paths of objects. These
structural paths are selected from a set of 658, 763 PDF
ﬁles (including both benign and malicious instances) based
on their popularity (i.e., each of them appeared in at least
1, 000 ﬁles). We use the implementation made available by
the author of Hidost in our experiments [30].
B. NUMBER OF BLACKBOX QUERIES IN
EVADING PDFrate
The number of blackbox queries
that BiRand and
EvadeHC required in evading PDFrate are reported in Fig-
ures 14a, 14b, 14c. We do not report these metrics of the
baseline, for they are all equal to the number of morphing
steps that BiRand incurs.
As can be seen from Figure 14a, for a majority of the
malware seeds, EvadeHC needs at most 494 queries, while
BiRand requires approximately 1500. The remaining seeds
appear to be much more diﬃcult to evade,
for which
EvadeHC and BiRand need up to 786 and 1837 queries, respec-
tively. Similarly, EvadeHC also requires fewer tester queries
and less morphing eﬀorts than BiRand (Figures 14b and
14c). In particular, for the majority of the malware seeds,
EvadeHC can ﬁnd an evading sample with less than 1, 237
tester queries and 21, 707 morphing steps, while BiRand con-
sumes up to 9, 100 and 63, 288 morphing steps.
To get an insight why some seeds necessitated much more
eﬀort in ﬁnding evading samples, we check their classiﬁca-
tion scores given by PDFrate.
It comes as no surprise
that their classiﬁcation scores are higher than the rest of
the malware seeds. In order words, it is harder to ﬁnd evad-
ing samples for these seeds because the detector perceived
their maliciousness more clearly.
The histogram of the ratios between the numbers of mor-
phing steps required by the two approaches is depicted in
Figure 14d. EvadeHC requires as low as one tenth morph-
ing eﬀorts compared to BiRand in order to ﬁnd an evading
sample.
C. NUMBER OF BLACKBOX QUERIES IN
EVADING HIDOST
We report the amounts of blackbox queries EvadeHC and
BiRand incur in evading Hidost in Figure 15a, 15b and 15c.
Overall, EvadeHC outperforms BiRand with respect to all
three metrics Nd, Nt and Nm. In particular, EvadeHC’s re-
quires as few as 427 detector queries, while BiRand needs as
least 1, 131 queries to ﬁnd an evading sample. With respect
to the tester, EvadeHC requires no more than 2073 queries,
while BiRand requires 11, 500 queries on average. The simi-
lar trend can also be observed on morphing eﬀort, wherein
EvadeHC requires about 12, 500 morphing step on average,
while such number for BiRand is approximately 10 times
larger (Figure 15d).