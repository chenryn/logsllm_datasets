### Sensitivity Attacks Against Electronic Watermarks in Images

**References:**

1. **Sensitivity Attack on Electronic Watermarks in Images.** In IH, 1998.
2. **N. Papernot, P. McDaniel, I. Goodfellow, S. Jha, Z. B. Celik, and A. Swami.** *Practical Black-Box Attacks Against Machine Learning.* In ASIACCS, 2017.
3. **K. Rieck, P. Trinius, C. Willems, and T. Holz.** *Automatic Analysis of Malware Behavior Using Machine Learning.* Journal of Computer Security, 2011.
4. **D. Sculley, M. E. Otey, M. Pohl, B. Spitznagel, J. Hainsworth, and Y. Zhou.** *Detecting Adversarial Advertisements in the Wild.* In KDD, 2011.
5. **K. Selvaraj and N. F. Gutierres.** *The Rise of PDF Malware.*
6. **M. Sharif, S. Bhagavatula, L. Bauer, and M. K. Reiter.** *Accessorize to a Crime: Real and Stealthy Attacks on State-of-the-Art Face Recognition.* In CCS, 2016.
7. **R. Shokri, M. Stronati, and V. Shmatikov.** *Membership Inference Attacks Against Machine Learning Models.* In IEEE S&P, 2017.
8. **D. Silver, A. Huang, C. J. Maddison, A. Guez, L. Sifre, G. Van Den Driessche, J. Schrittwieser, I. Antonoglou, V. Panneershelvam, M. Lanctot, et al.** *Mastering the Game of Go with Deep Neural Networks and Tree Search.* Nature, 2016.
9. **C. Smutz and A. Stavrou.** *Malicious PDF Detection Using Metadata and Structural Features.* In ACSAC, 2012.
10. **R. Sommer and V. Paxson.** *Outside the Closed World: On Using Machine Learning for Network Intrusion Detection.* In IEEE S&P, 2010.
11. **N. Šrndić and P. Laskov.** *Detection of Malicious PDF Files Based on Hierarchical Document Structure.* In NDSS, 2013.
12. **N. Šrndić and P. Laskov.** *Practical Evasion of a Learning-Based Classifier: A Case Study.* In IEEE S&P, 2014.
13. **Y. Taigman, M. Yang, M. Ranzato, and L. Wolf.** *DeepFace: Closing the Gap to Human-Level Performance in Face Verification.* In CVPR, 2014.
14. **F. Tramèr, F. Zhang, A. Juels, M. K. Reiter, and T. Ristenpart.** *Stealing Machine Learning Models via Prediction APIs.* In USENIX Security, 2016.
15. **O. Vinyals, Ł. Kaiser, T. Koo, S. Petrov, I. Sutskever, and G. Hinton.** *Grammar as a Foreign Language.* In NIPS, 2015.
16. **W. Xu, Y. Qi, and D. Evans.** *Automatically Evading Classifiers.* In NDSS, 2016.
17. **C. Yang, R. Harkreader, and G. Gu.** *Empirical Evaluation and New Design for Fighting Evolving Twitter Spammers.* IEEE TIFS, 2013.

### Appendix

#### A. PDF Malware Classifiers

In this section, we provide an overview of the Portable Document Format (PDF) and PDF malware, and briefly introduce two detectors: PDFrate [28] and Hidost [30].

##### A.1 PDF

The Portable Document Format (PDF) is a standardized file format designed to decouple document presentation from the underlying environment platform (e.g., application software, hardware, or operating systems), ensuring consistent presentation across different platforms [16]. A typical PDF file consists of four parts:

1. **Header:** Contains the magic number and the version of the format.
2. **Body:** Incorporates a set of PDF objects comprising the content of the file.
3. **Cross-Reference Table (CRT):** An index table that provides the byte offset of the objects in the body.
4. **Trailer:** Includes references to the CRT and other special objects such as the root subject.

The header, CRT, and trailer are introduced with the keywords `%PDF`, `xref`, and `trailer`, respectively. Objects in the body of the file can be either direct (embedded in another object) or indirect. Indirect objects are numbered with a pair of integer identifiers and defined between the keywords `obj` and `endobj`. Objects have eight basic types: Booleans, numbers, strings, names, arrays, dictionaries, streams, and null objects. Some dictionaries, such as those containing executable JavaScript code, have special meanings.

##### A.2 PDF Malware

Due to its popularity, PDF files have been extensively exploited to deliver malware. With an increasing number of vulnerabilities in Acrobat readers, the threat of PDF malware is significant. Malicious payloads embedded in PDFs are often contained in JavaScript objects or other objects that exploit vulnerabilities in specific PDF readers.

##### A.3 Detectors

Various PDF malware detectors have been proposed in the literature. Early works targeted JavaScript code embedded in malicious PDFs, extracting and analyzing the code to assess the maliciousness of the PDF. However, these methods fail to detect PDF malware where the malicious payload is not in JavaScript or is hidden [24]. Recent works have adopted a structural feature-based approach, assuming differences in the internal object structures of benign and malicious PDF files.

Our experimental evaluations focus on two state-of-the-art structural feature-based detectors: PDFrate [28] and Hidost [30]. These systems have high detection rates and have been studied in previous work on evasion [35]. The outputs of these detectors are real-value scores compared against thresholds to derive detection results. In our experiments, we modified their implementations to return binary outputs.

###### PDFrate

PDFrate is an ensemble classifier consisting of a large number of classification trees. Each tree is trained using a random subset of the training data and an independent subset of features, including object keywords, PDF metadata, and properties of objects. At classification time, each tree outputs a binary decision, and the ensemble classifier's output is the fraction of trees that consider the input "malicious" (a real-value score ranging from 0 to 1). The default cutoff value is 0.5.

PDFrate was trained using 5,000 benign and 5,000 malicious PDF files from the Contagio dataset [6]. The classifier consists of 1,000 classification trees, each covering 43 features, with a total of 202 unique features (135 documented).

An open-source implementation of PDFrate, called Mimicus [4], was used in our experiments.

###### Hidost

Hidost is a support vector machine (SVM) classifier [30]. SVM aims to fit a hyperplane to training data, separating data points of both classes with the largest possible margin. Hidost maps a data point (representing a submitted PDF file) to an indefinite-dimensional space using a radial basis function and reports the distance between the data point and the hyperplane as a measure of its maliciousness. If the distance is positive, the PDF file is considered malicious; otherwise, it is flagged as benign.

Hidost was trained using 5,000 benign and 5,000 malicious PDF files, operating on 6,087 classification features, which are structural paths of objects. These paths were selected from a set of 658,763 PDF files based on their popularity (each appearing in at least 1,000 files). We used the implementation provided by the author of Hidost in our experiments [30].

#### B. Number of Blackbox Queries in Evading PDFrate

The number of blackbox queries required by BiRand and EvadeHC to evade PDFrate are reported in Figures 14a, 14b, and 14c. For most malware seeds, EvadeHC needs at most 494 queries, while BiRand requires approximately 1,500. For more challenging seeds, EvadeHC and BiRand need up to 786 and 1,837 queries, respectively. EvadeHC also requires fewer tester queries and less morphing effort than BiRand (Figures 14b and 14c). Specifically, for most malware seeds, EvadeHC finds an evading sample with fewer than 1,237 tester queries and 21,707 morphing steps, while BiRand consumes up to 9,100 and 63,288 morphing steps.

To understand why some seeds require more effort, we checked their classification scores given by PDFrate. As expected, these seeds had higher classification scores, indicating that the detector perceived their maliciousness more clearly.

The histogram of the ratios between the numbers of morphing steps required by the two approaches is depicted in Figure 14d. EvadeHC requires as little as one-tenth of the morphing effort compared to BiRand to find an evading sample.

#### C. Number of Blackbox Queries in Evading Hidost

The amounts of blackbox queries required by EvadeHC and BiRand to evade Hidost are reported in Figures 15a, 15b, and 15c. Overall, EvadeHC outperforms BiRand with respect to all three metrics (Nd, Nt, and Nm). Specifically, EvadeHC requires as few as 427 detector queries, while BiRand needs at least 1,131 queries to find an evading sample. With respect to the tester, EvadeHC requires no more than 2,073 queries, while BiRand requires 11,500 queries on average. Similarly, EvadeHC requires about 12,500 morphing steps on average, while BiRand requires approximately 10 times more (Figure 15d).