### Permitted Assessment of Design Decisions at the Interface to a Virtual Implementation

The capability to assess the implications of design decisions at the interface with a virtual implementation of the system was a significant advancement. One of the key drivers for the development of formal methods was the recognition that Trojan Horses could exploit covert channels. The risk of malicious software violating the system's security policy was evident from the early stages of secure systems, leading to most systems being developed by cleared programmers. For systems developed by uncontrolled sources, such as commercial off-the-shelf products, a level of rigor only achievable through formal methods is required.

During this period, the limitations of cryptography were becoming more widely known, and these limitations were often due to the potential for malicious software. An example is an exploitable covert channel in end-to-end encryption systems, where Trojan Horses can modulate large amounts of data within message headers. Efforts to ignore this problem represented one of the earlier instances of people attempting to defend their designs by arbitrarily constraining what an attacker is supposed to attack. The cryptographic designers claimed their system was not responsible for this issue, and the operating system was not subverted to exploit it. However, it remained a system vulnerability that a Trojan horse could exploit.

While covert timing channels continue to be a challenge, the GEMSOS security kernel demonstrated that covert storage channels could be eliminated and covert timing channels significantly reduced.

### Evaluation Classes for Insecure Systems

It is noteworthy that initial efforts, such as the MIT project, to construct auditable kernels focused on being "secure" rather than achieving security with varying levels of assurance. Initially, the efforts to develop system evaluation criteria were synonymous with what later became known as Class A1, as no assumptions were made about the methods of the attacker. Later, it was considered whether there was any value in defining lesser levels of assurance. Division A of the TCSEC makes no assumptions about limiting the attacker, while Division B assumes the attacker can subvert applications but not the operating system. Division C assumes the attacker uses no subversion, and Division D assumes customers believe the vendor's marketing claims.

### Advances in the State of the Science

The era culminating in the availability of commercial evaluations (based on the TCSEC) contributed several key advances to the science of computer and network security:
- **Application of Formal Methods**
- **Architectural Requirements for Evaluation** (e.g., layering, least privilege, minimization)
- **Covert Channel Reduction and Analysis**
- **Technically Sound Objective Evaluation Criteria**
- **Event Counts for Secure Synchronization**

### TCB Subset Tools for Composition

Commercial evaluations under the TCSEC made available trusted systems whose security properties were independently evaluated. At the time, many inaccurately claimed that the TCSEC could not be applied to a network of computers. However, the TCSEC is a complete and reasonable criterion for evaluating systems, including networks. Two real-world concerns motivated published interpretations of the TCSEC:
- **The ability to enforce a variety of system security policies at varying levels of assurance.**
- **The ability to incrementally evaluate networks and systems based on well-defined modifications (e.g., the addition of a new sub-network).**

#### Virtual Machines and the Subsetting Problem

Virtual machines, such as IBM VM370, were developed to enable strong partitioning of systems within the same computer, allowing simultaneous development and testing of new operating systems alongside production environments. These efforts showed that policies must be layered and partially ordered. For example, outer layer policies (e.g., discretionary controls on access to data) should not affect inner layer policies (e.g., separating the production virtual machine from the development virtual machine).

Early concept papers on trusted VMs and trusted databases recognized that there was an ordering to policies, where relatively weak mechanisms could enforce policies with smaller demands. This was evident in the VAX VMM Security Kernel, which provided a formal structure for understanding previously indescribable concepts. These lessons were applied in the development of the TNI and the understanding of TCB Subsets.

#### Incremental Evaluation of Distinct Physical Components

A strong driver for the development of the TNI was the existence of continually evolving networks composed of heterogeneous components. It was impractical to require the entire system to be evaluated at once, so strategies were investigated for supporting incremental evaluations. The solution involved two key concepts: 1) the concept of a "partitioned TCB," where individually evaluated components interact in a precisely defined manner, and 2) a "network security architecture" that addresses the overall network security policy. These concepts enable architectures to evolve without reassessing each individual component every time a deployment change occurs. This also led to the ability to recursively "compose" a set of individual components into a new single logical component with a well-defined role and a well-understood composite security rating.

The practicality of the TNI was tested by its application to the Blacker system, an NSA-developed Virtual Private Network (VPN) for securing highly sensitive traffic over an insecure Internet. The ability to use non-custom-made products was illustrated by hosting two major components of Blacker on the commercial GEMSOS security kernel, which met the requirements for verified protection. The notion of a "guard" based on cryptographic checksums was another technique for using insecure components in a secure system.

Another example of the practical use of the TNI is the ICL-developed CHOTS system for the UK military, where the system architect reported making significant use of the TNI as an engineering tool. Similarly, Novell confirmed its practicality in the design of security for a commercial network.

#### TCB Subsets Within a Single System

Lessons learned from the development of the TNI and the SeaView multilevel DBMS security model were applied to the initial drafting of the TDI to address the management of TCB subsets within a single physical computer. Trusted Oracle was structured to exploit the properties of TCB subsetting, including a mode where the mandatory access controls of the database were enforced by the underlying operating system. This "evaluation by parts" solved the problem of achieving a Class A1 database system when neither the database nor the operating system vendor was willing to provide the necessary evaluation evidence for a single system evaluation.

The evaluation of Novell’s commercial NetWare network under the TNI marks the end of this third epoch. Novell desired an evaluated system but was not in the business of building clients. They implemented a TCB extension for their client and completed three distinct but related evaluations: client, server, and network.

### Advances in the State of the Science

The era culminating in the ability to use TCB subsets to compose and incrementally evaluate systems contributed the following key advances to the science of computer and network security:
- **Partitioned TCB**
- **TCB Subsets**
- **Rules for Layering Security Policies**
- **Rules for Composing Systems**
- **Balanced Assurance**
- **Cryptographic Checksum Guards**
- **Multilevel DBMS Data Model**
- **Secure Client via TCB Extension**

### Common Criteria

The introduction of the Common Criteria marks the end of our final epoch. While this occurred some years ago, the current situation is largely an extrapolation from that point. Despite scientific advances leading to system evaluation criteria, worked examples, and engineering tools for composing systems, building secure computing systems remains a challenging endeavor requiring significant effort by trained practitioners. Science has provided no way to add security to an existing system, and the idea of building from untrustworthy components appears intractable. The blurring of distinctions reflected in the Common Criteria provided a vehicle for renewing speculative strategies for achieving trusted systems, leading to an era of pseudoscience, emphatic assertion, and unconscionable neglect.

A fundamental goal of the TCSEC was that an evaluation must identify the properties of the overall system without making system-specific assumptions. There were separate evaluations for "sub-systems" called "sub-system evaluations." The Common Criteria has led to a number of evaluated products but a dearth of evaluatable systems, as there is no prescribed distinction between system and subsystem evaluations. About 20 different network client products were evaluated under the ITSEC, but their evaluations mean little with arbitrary assumptions about the behavior of other parts of the system. An entire business was pursued based on the claimed existence of a "Class A1 chip," inferred from an "EAL7 chip," which said virtually nothing about the security of any system.

We are not suggesting that the blurring of distinctions is caused by the Common Criteria. It is unclear whether it has much impact on security designs and implementations. We are simply noting that during this epoch, many of the distinctive properties of the science are not commonly recognized or applied.

### Current Failure to Apply Existing Science

The current failure to apply the existing science of information security is the result of three tendencies of pseudoscience:
- **Willingness to make baseless assumptions about the behavior of "other" software subsystems.**
- **Willingness to assume unenforceable prescriptions on the behavior of attackers.**
- **The classic logic error of assuming all problems are the same and concluding that certain techniques don’t solve any of the problems.** For example, because verifiable protection does not fully solve the problems of denial-of-service, some overlook the fact that it still provides significant security benefits.