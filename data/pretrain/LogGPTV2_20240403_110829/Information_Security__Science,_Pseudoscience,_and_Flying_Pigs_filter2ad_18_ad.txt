that  permitted  assessment  of  implications  of  design 
decisions  at  the  interface  to  a  virtual  implementation  of 
the system  
One  driver  that  led  to  advances  in  formal  methods 
was  the  recognition  that  Trojan  Horses  could  exploit 
covert channels.  The risk of malicious software violating 
the system security policy was recognized from the very 
early  secure  systems, 
leading  most  systems  to  be 
developed  by  cleared  programmers.    Development  of 
systems  (e.g.,  commercial  off  the  shelf  products)  by 
uncontrolled  sources  (e.g.,  potential  enemies)  requires  a 
level of rigor only available with formal methods. 
Also during this time frame, limitations on the use of 
cryptography were becoming more widely known.  And, 
again it is the potential for malicious software that causes 
these  limitations.    An  example  is  an  exploitable  covert 
channel [30] that exists in end-to-end encryption systems.  
Trojan  Horses  can  exploit  this  limitation  by  modulating 
large amounts of data within message headers.   
Efforts to ignore this problem represented one of the 
earlier examples of people trying to defend their designs 
by arbitrarily constraining what an attacker is supposedly 
permitted  to  attack.    The  crypto  designers  said  their 
system  was  not considered responsible  for this problem.  
Nor  was  the  operating  system  subverted  to  exploit  the 
problem.  Yet it was a system vulnerability a Trojan horse 
could exploit. 
While covert timing channels remain a challenge to 
this day, the GEMSOS security kernel showed that covert 
storage  channels  could  be  eliminated  and  that  covert 
timing channels could be significantly reduced [31]. 
4.3.  Evaluation Classes for Insecure Systems 
It is instructive to note that the initial efforts, such as 
the MIT project, to construct auditable kernels all focused 
on  being  “secure”,  not  on  being  secure  with  some 
variable  level  of  assurance.    Initially,  the  efforts  to 
develop system evaluation criteria were synonymous with 
what  latter  became  called  Class  A1.    The  reason  is  that 
initially, no assumptions were made about the methods of 
the  attacker.    Only  latter  was  it  asked  if  there  were  any 
value in defining lesser levels of assurance.  Division  A 
of  the  TCSEC  makes  no  assumptions  about  limiting  the 
attacker.    Division  B  hypothesizes  that  the  attacker  can 
subvert  the  applications,  but  not  the  operating  system.  
Division  C  hypothesizes  that  the  attacker  uses  no 
subversion  at  all. 
  And,  division  D  assumes  that 
customers  believe  that  attackers  believe  the  vendor 
marketing claims. 
4.4. Advances in the State of the Science 
The  epoch  culminating 
in 
evaluations 
the  availability  of 
commercial 
the  TCSEC) 
contributed the following key advances to the state of the 
science of computer and network security: 
•  Application of Formal Methods 
•  Architectural Requirements for Evaluation (e.g., 
(based  on 
layering, least privilege, minimization) 
•  Covert Channel Reduction and Analysis 
•  Technically Sound Objective Evaluation Criteria 
•  Eventcounts for secure synchronization 
5.  TCB Subset Tools for Composition 
Commercial  evaluations  under  the  TCSEC  made 
available  trusted  systems  whose  security  properties  were 
independently evaluated.  At the time, many inaccurately 
claimed  that  use  of  the  TCSEC  was  limited  because  it 
could  not  be  applied  to  a  network  of  computers.    The 
TCSEC 
is  a  complete  and  reasonable  criteria  for 
evaluating  systems,  including  networks  as  noted  in  [32] 
and [33].  However, there were two real-world concerns 
that motivated published interpretations of the TCSEC: 
•  The  ability  to  enforce  a  variety  of  system  security 
policies at varying levels of assurance; and, 
•  The  ability  to  incrementally  evaluate  networks  and 
systems  based  on  well  defined  modifications  (e.g., 
the addition of a new sub-network). 
5.1. Virtual Machines and the Subsetting Problem 
Virtual  machines  such  as  IBM  VM370  were 
developed  to  permit  the  strong  partitioning  of  systems 
within  the  same  computer,  e.g.,  allow  simultaneous 
development and testing of new operating systems on the 
same  physical  machines  as  the  production  application 
environment.    These  efforts  showed  that  to  succeed,  the 
policies  must  be  layered  and  there  must  be  a  partial 
ordering to the policies.  For example, outer layer policies 
(e.g., discretionary controls on access to data) should not 
be  able  to  reach  in  and  affect  inner  layer  policies  (e.g., 
separating  the  production  virtual  machine  from  the 
development virtual machine). 
The  short  early  concept  papers  on  trusted  VMs  and 
trusted databases recognized that there was a ordering to 
policies where relatively weak mechanisms could be used 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:10:17 UTC from IEEE Xplore.  Restrictions apply. 
to  enforce  those  policies  that  have  smaller  demands 
placed upon them.  This was clearly evident in the VAX 
VMM Security Kernel [34].  This work provided a formal 
structure  for  understanding  what  previously  was  not 
describable. 
the 
development  of  the  TNI  [8]  and  the  understanding  of 
TCB Subsets [35]. 
lessons  were  applied 
  These 
in 
5.2. Incremental  Evaluation  of  Distinct  Physical 
Components 
A  strong  driver  to  the  development  of  the  TNI  was 
the existence of continually evolving networks composed 
of  heterogeneous  components.    It  was  not  practical  to 
require  that  an  entire  system  be  evaluated  at  once,  so 
strategies  were  investigated  for  supporting  incremental 
evaluations.    The  question  was:  how  to  build  a  system 
from a set of individual components that were previously 
evaluated?  The answer is found in two key concepts: 1) 
the concept of a “partitioned TCB”, in which individually 
evaluated  components  interact  in  a  precisely  defined 
fashion  and,  2)  a  “network  security  architecture”  that 
addresses  the  overall  network  security  policy.    These 
concepts enable architectures to evolve without having to 
go  back  and  reassess  the  role  of  each  individual 
component  each  time  a  deployment  consistent  with  the 
architecture  is  changed.    This  also  led  to  an  ability  to 
recursively  “compose”  a  set  of  individual  components 
into  a  new  single  logical  component  that  has  a  well-
defined role within the network security architecture and 
a well understood composite security rating.   
A  litmus  test  of  the  practicality  of  the  TNI  was 
whether  it  could  be  applied  to  the  Blacker  system  –  a 
NSA  developed  Virtual  Private  Network  (VPN)  for 
securing highly sensitive traffic over an insecure Internet 
[36]. The  ability  to  use  products  not  custom  made  for  a 
specific  network  was  illustrated  by  having  two  major 
components  of  Blacker  hosted  on 
the  commercial 
GEMSOS  security  kernel  that  met  the  requirements  for 
verified  protection  [31].  It  was  concluded  that  Blacker 
would be a practical application of the TNI.  The notion 
of a “guard” based on cryptographic checksums [7]  was 
another  technique  for  using  insecure  components  in  a 
secure system. 
As another example of the practical use of the TNI, 
the  system  architect  for  the  ICL-developed  CHOTS 
system  for  the  UK  military  reported  making  significant 
use of the TNI as an engineering tool in architecting their 
network of heterogeneous components, and in allocating 
security  policies  to  the  various  components.    Similarly, 
Novell confirmed its practicality as a powerful tool in the 
design of security for a commercial network [5].  
5.3. TCB Subsets Within a Single System 
The  lessons  learned  from  development  of  the  TNI  
and from the SeaView multilevel DBMS security model  
[37]were  then  applied  to  the  initial  drafting  of  the  TDI 
[38] to address the management of TCB subsets within a 
single physical computer. 
to  exploit 
Trusted  Oracle  was  structured 
the 
properties  of  TCB  subsetting.    It  included  a  mode 
whereby  the  mandatory  access  controls  of  the  database 
were  enforced  by  the  mechanisms  of  the  underlying 
operating system.  This “evaluation by parts” solved the 
seemingly  difficult  problem  of  achieving  a  Class  A1 
database system when neither the database vendor nor the 
operating system vendor was willing to provide the other 
with the evaluation evidence that would be necessary for 
a single system evaluation. 
Evaluation of Novell’s commercial NetWare network 
under the TNI marks the end of this third epoch.  Novell 
desired an evaluated system, yet was not in the business 
of  building  clients.    They  faced  the  question  of  how  to 
specify the role of the client such that other vendors could 
produce  clients  that  would  be  secure  within  the  Novell 
network security architecture.  They implemented a TCB 
extension for their client.  Novell completed three distinct 
but related evaluations: client; server; and network [5]. 
5.4.  Advances in the State of the Science 
The  epoch  culminating  in  the  ability  to  use  TCB 
subsets  to  compose  and  incrementally  evaluate  systems 
contributed the following key advances to the state of the 
science of computer and network security: 
•  Partitioned TCB 
•  TCB Subsets 
•  Rules for Layering Security Policies 
•  Rules for Composing Systems  
•  Balanced Assurance 
•  Cryptographic Checksum Guards 
•  Multilevel DBMS Data Model 
•  Secure Client via TCB Extension 
6.  Common Criteria 
The introduction of the Common Criteria delimits the 
end of our final epoch.  While this occurred some years 
ago,  our  current  situation 
is  dominantly  a  simple 
extrapolation from that point.   
Although  scientific  advances  had  led  to  a  system 
evaluation  criteria,  worked  examples  and  engineering 
tools  for  composing  systems,  the  building  of  secure 
computing  systems  remained  a  challenging  endeavor 
requiring  significant  effort  by 
trained  practitioners.  
Science  had  provided  no  way  to  glom  security  onto  an 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:10:17 UTC from IEEE Xplore.  Restrictions apply. 
systems 
trustworthy 
existing system.  And even though there has been wishful 
thinking  that  it  would  be  nice  to  discover  a  means  of 
“building 
from  untrustworthy 
components”  [12],  to  the  current  state  of  science  this 
appears  to  be  intractable.    The  blurring  of  distinctions 
reflected in the Common  Criteria provided a vehicle for 
renewing 
for 
achieving  trusted  systems,  and  opened  the  door  to  our 
current  epoch  of  pseudoscience,  emphatic  assertion  and 
unconscionable neglect.   
speculative 
strategies 
research 
A  fundamental  goal  of  the  TCSEC  was  that  an 
evaluation  must  identify  the  properties  of  the  overall 
system  without  having 
system-specific 
assumptions.    There  were  separate  evaluations  for  “sub-
systems” that were called “sub-system evaluations”.   
to  make 
into 
The  Common  Criteria  has  led  to  a  number  of 
evaluated  products,  but  a  dearth  of  evaluatable  systems.  
That is because there is no prescribed distinction between 
system evaluation and subsystem evaluations.  About 20 
different  network  client  products  were  evaluated  under 
the ITSEC (which similarly lacks a systems context), but 
what  do  any  of  the  evaluations  mean  with  arbitrary 
assumptions  about  the  behavior  of  other  parts  of  the 
system? In fact been an entire business was pursued based 
on  claimed  existence  of  a  “Class  A1  chip”,  apparently 
inferred  from  an  “EAL7  chip”,  which  said  virtually 
nothing about the security of any system.    
We  are  not  in  any  way  saying  that  this  blurring  of 
distinctions is caused by the Common Criteria.  In fact, it 
is not clear that it is having much impact at all on security 
designs and implementations.  We are simply noting that 
during this epoch many of the distinctive properties of the 
science are not commonly recognized or applied. 
largely 
The  current  failure  to  apply  the  existing  science  of 
three 
information  security 
tendencies of pseudoscience: 
•  A  willingness  to  make  baseless  assumptions  about 
the  behavior  of  “other”  software  subsystems,  i.e., 
those falling outside the “target of evaluation”; and, 
the  result  of 
•  A willingness to assume unenforceable prescriptions 
is 
on the behavior of attackers. 
•  The classic logic error of assuming all problems are 
the same and then concluding that certain techniques 
don’t  solve  any  of  the  problem  because  they  fail  to 
solve  some  of  the  problems.    For  example,  because 
verifiable  protection  does  not  fully  solve 
the 
problems of denial-of-service, some will overlook the 
fact 
the 