these events, which can be seen in the following one-liner. This counts the TCP state number for
each event:
1: () qunoo = [t6xe]aqoxdxg ) aqessesdo:x, - aoe3agdq +
t:sock:inet_sock_set_state ( Btracepoint[args->neustate] = count() : }'
Attach.ing 2 probes...
°C
ekprobe [4]: 12
kprobe[5]: 12
ET :[6]eqoad@
ekprobe [2]: 13
pkprobe[8] : 13
ekprobe [1]: 25
ekprobe [7]: 25
@tracepoint[3] : 12
etracepoint[4]: 12
etracepoint[5]: 12
tracepoint[2] :13
etracepoint[9]: 13
tracepoint[8]: 13
etracepoint[7]: 25
etracepoint[1]: 25
---
## Page 482
10.3 BPF Tools
445
See it? The tcp_set_state( kprobe never sees state 3, which is TCP_SYN_RECV. This is because the
kprobe is exposing the kernel implementation, and the kernel never calls tcp_set_state() with
TCP_SYN_RECV: it doesn’t need to. This is an implementation detail that is normally hidden
from end users. But with the addition of a tracepoint to expose these state changes, it was found
to be confusing to leave out this state transition, so the tracepoint has been called to show all
transitions.
BCC
Command line usage:
tcplife [optlons]
Options include:
 t: Include time column (HH:MM:SS)
•-: Wider columns (to better fit IPv6 addresses)
squo saood sp asea1 :a1a d-
• L FORT [ , PoRT [ , -- 11: Trace only sessions with these local ports
 D FoRr [ , PoRT [ , - - 11: Trace only sessions with these remote ports
bpftrace
The following is the code for the bpftrace version, developed for this book, and which summarizes
its core functionality. This version uses a kprobe of tcp_set_state( so that it runs on older kernels,
and does not support options.
#1/usx/1ocal/bin/bpEtrace
#include 
include 
#1nclude 
include 
BEGIN
printf(**5s 10s 15s5s 15s5s *, *PID*, *comx*,
printf(*&5s 45s es`n*, *rX_KB*, *RX_KB*, *Ms*)
ses__ak_conmon. skc_num;
$dport = $sk->__sk_conmon,skc_dport;
$dpoxt = (Sdpoxt >> 8] 1((sdport _ak_common,skc_fanily
$saddr = ntop (0}
5daddr = ntop (01;
if ($family == AF_INET)(
$saddz = ntop (AF_INET, $sk->__sk_conmon ,sakc_rcv_saddx) 
---
## Page 484
10.3 BPF Tools
447
$dadde = ntop IAF_INET, $sk->__sk_common ,skc_daddr) 
] else I
// AF_IKET6
$saddz = ntop IAF_INET6,
$sk->_sk_conmon.skc_r6_rcv_sadidr,in6_u,u6_addrB) 
$daddz = ntop AF_INET6,
$sk=>__sk_conmon,skc_v6_daddr,in6_u,u6_addr8) 
printf (*5d 10 10s 15s 5d 15s 6d *, $pid,
$omn, $saddx, $lpoxt, $daddr, $@poxt);
printf (*e5d 5d %d’.n*, $tp=>bytes_acked / 1024,
Stp=>bytes_received / 1024, $delta_ns) :
dele te (Bbith[$sk] ) 
delete (8skpid[$sk]1 
delete (Bskconm[Ssk]) 
END
clear (8bixth) : clear (Bskpld) : cleax (@skcon) 
The logic in this tool is somewhat complex, and I added block comments to explain it in both the
BCC and bpftrace versions. What it does is:
 Measure the time from the first state transition seen for the socket, to TCP_CLOSE. This is
printed as the duration.
Fetch throughput statistics from the struct tcp_sock in the kernel. This avoids tracing each
packet and summing throughput from their sizes. These throughput counters are relatively
recent, added since 2015 [109].
● Cache the process context on either TCP_SYN_SENT or TCP_LAST_ACK, or (if not
cached by those) on TCP_CLOSE. This works reasonably well but relies on these events
sax an ap uoead x e s ua xo ssad  uadde
could change their logic to make this approach much less reliable, at which point this
tool would need to be updated to cache task context from socket events instead (see the
earlier tools).
record other useful fields from the sock and tcp_sock structs.
The BCC version of this tool has been extended by the Netflix network engineering team to
This bpftrace tool can be updlated to use the sock:inet_sock_set_state tracepoint, which needs an
TCP Using this tracepoint improves stability, but there will still be unstable parts: for example,
additional check for args->protocol == IPPROTO_TCP as that tracepoint fires for more than just
transferred bytes still need to be fetched from the tcp_sock struct.
---
## Page 485
448
Chapter 10 Networking
10.3.14
tcptop
tion Hadoop instance:
1 teptop
09:01:13 1oadavg: 33.32 36.11 38.63 26/4021 123015
PID
COMM
LACOR
RADDR
RX_KBTX_KB
118119 ava
100.1,58,46:36246
100,2.52,79:50010
16840
122833javs
100.1,58,46:52426
0
ene[E28z2t
100:2.6.98:50010
0
3112
100.1.58.46:50010
100.2.50.176:55396
3112
0
120711 java
100.1,58,46:50010
100 .2.7,75:23358
2922
eae[ s59121
100.1.58,46:50010
100 ,2.5.101:56426
2922
0
121219 javs
100.1,58,46:50010
100.2.62.83:40570
ene[ 61212t
2858
100.1.58,46:42324
100.2.4.58:50010
2858
0
100.1,58,46:50010
100.2.2.191:29338
2351
0
[.--]
This output shows one connection at the top receiving over 16 Mbytes during this interval. By
default, the screen is upxdated every second.
efficiency. Even so, these events can be frequent, and on high network throughput systems the
This works by tracing the TCP send and receive code path, and summarizing data in a BPF map
overhead may become measurable.
Ognqdnueapdo asoup I °Ognqu dnueao“d4 pue (8supuasd3 are paoen suooung [enppe atL
as it provides both the sock struct and size as entry arguments. To get the same details from
tcp_recvmsg() requires two kprobes and thus more overhead: a kprobe on entry for the sock
struct, and a kretprobe for the returned bytes.
Note that tcptop(8) does not currently trace TCP traffic that was sent via the sendfile(2) syscall,
as it may not call tcp_sendmsg(). If your workload makes use of sendfile(2), check for an updated
tcptop(8) version or enhance it.
Command line usage:
[ [ 192.168.1.1
54224
54 Inetd
U
242 192.168.1.5
23  EZ
54224
pqout BL
0
242 192.168.1.5
23 -> 192.168.1.1
54224
5*1* 89 1 *26T E68020
57 1n,telnetd
54 inetd
1*1*991*261  RADDR:RFORT
STATE
00:20 :11 72475
4 100.1.58.46:35908
B> 100.2.0.16T:50010
ESTABLISHED
00 :20:11 72475
4
100.1.58.46:35908
R> 100,2.0.167:50010
ESTABLISHED
00 :20: 11 72475
4
100.1.58 ,46:35908
R> 100.2.0 .16T:50010
ESTABLISHED
00 :20:12 60695
4
100.1.58.46:52346
R> 100,2.6.189:50010
ESTABLISHED
56909 21102:00
4
100.1.58.46:52346
R> 100.2.6.189:50010
ESTABLISHED
00 :20 :12 60695
4
100.1.58.46:52346
R> 100.2.6.189:50010
ESTABLISHED
56909 2102:00
4
100.1.58.46:52346
R> 100.2.6.189:50010
ESTABLISHED
00:20:13 60695
6 ::ffff:100,1.58.46:13562 R> ::ffff:100.2.51.209:47356 F[N_MAIT]
00:20:13 60695 6 ::fEff:100.1.58,46:13562 R> ::EEff:100.2.51.209:47356 FIB_8AIT]
[...]
This output shows a low rate of retransmits, a few per second (TIME column), which were mostly
for sessions in the ESTABLISHED state. A high rate in the ESTABLISHED state can point to an
external network problem. A high rate in the SYN_SENT state can point to an overloaded server
application which is not consuming its SYN backlog fast enough.
This works by tracing TCP retransmit events in the kernel. Since these should occur infrequently,
the overhead should be negligible. Compare this to how retransmits are historically analyzed
using a packet sniffer to capture all packets, and then post-procesing to find retransmitsboth
steps can cost significant CPU overhead. Packet-capture can also only see details that are on the
wire, whereas tcpretrans(8) prints the TCP state directly from the kernel, and can be enhanced to
print more kernel state if needed.
At Netflix, this tool was used to help diagnose a production issue caused by network traffic
exceeding external network limits, causing dropped packets and retransmits. It was helpful
to watch retransmits across different production instances, and be able to immediately see
source, destination, and TCP state details without the overhead of processing per-packet 
cdumps.
Shopify has also used this to debug a production network issue, where the workload was causing
tcpdlump(8) to drop so many packets that its output was not reliable, and the overhead was too
painful. Both tcpretrans(8) and tcpxdrop(8) (mentioned later) were used instead to gather enough
information to point towards an external issue: in this case, it was a firewall configuration that
became inundated under load and would drop packets.
31 0rign: I crested a umber of similar TCP retransmit tracing tools using DTrsce n 2011 [110]. 1ceated an Prsce
counting mode. Dsle Hamel crested the bpfrace version on 23-Nov-2018.
based tcpretrans(8) on 28-Jul-2014 [111], then the BCC tcpretrans(8) on 14-Feb-2016. Matthiss Tafelmeier added the
---
## Page 488
10.3 BPF Tools
451
BCC
Command line usage.
tcpretrans [options]
Options include:
● 1: Incluxle tail loss probe attempts (adds a kprobe for tcp_send_loss_probe()
 -e: Counts retransmits per flow
The c option changes the behavior of tcpretrans(8), causing it to print a summary of counts
rather than per-event details.
bpftrace
The following is the code for the bpftrace version, which summarizes its core functionality. This
version does not support options.
+1/usr/local/bin/bpftrace
include 
#include 
BEGIX
1
printf (*7xacing TCP retransmita. HIt Ctr1-C to end. ,n*) :
printf(*s=8s =Bs 20s 21s 6s^o*, *rrME*, *PID*, *LADDR:LF0Rr*,
*RADDR:RPORT*, *STATE*
// See Include/net/tcp_states-h:
G3HsITevL3 - (t|+dg
Btcp_states[3] - *sm_Rscv*;
futaIYxα13。 = [|seae1sdo8
Btcp_states[5] - *FIN_waIT2";
Btcp_atates[6] - *TIME_BAIT";
Btcp_states[7] - *C10sE*;
Lxas01o。 - [elseeiedo8
fx*Y"1sY7。 - [61sesd38
Btcp_atates [11] = "cLosING*,
3sxsx -[adg
kprobe:tcp_retransni t_skb
---
## Page 489