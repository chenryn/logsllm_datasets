A simple adaptive (cid:14) might use a constant fraction (cc < 1) of the
node’s estimated error:
(cid:14) = cc (cid:2) local error
(cid:14) can be viewed as the fraction of the way the node is allowed to
move toward the perfect position for the current sample. If a node
predicts its error to be within (cid:6)5%, then it won’t move more than
5% toward a corrected position. On the other hand, if its error is
large (say, (cid:6)100%), then it will eagerly move all the way to the
corrected position.
A problem with setting (cid:14) to the prediction error is that it doesn’t
take into account the accuracy of the remote node’s coordinates. If
the remote node has an accuracy of (cid:6)50%, then it should be given
less credence than a remote node with an accuracy of (cid:6)5%. Vivaldi
implements this timestep:
// Incorporate new information: node j has been
// measured to be rtt ms away, has coordinates x j,
// and an error estimate of e j.
//
// Our own coordinates and error estimate are xi and ei.
//
// The constants ce and cc are tuning parameters.
vivaldi(rtt, x j, e j)
// Sample weight balances local and remote error. (1)
w = ei=(ei + e j)
// Compute relative error of this sample. (2)
=rtt
es = (cid:12)(cid:12)(cid:12)
kxi (cid:0) x jk (cid:0) rtt(cid:12)(cid:12)(cid:12)
// Update weighted moving average of local error. (3)
ei = es (cid:2) ce (cid:2) w + ei (cid:2) (1 (cid:0) ce (cid:2) w)
// Update local coordinates. (4)
(cid:14) = cc (cid:2) w
xi = xi + (cid:14) (cid:2) (cid:16)rtt (cid:0) kxi (cid:0) x jk(cid:17) (cid:2) u(xi (cid:0) x j)
Figure 3: The Vivaldi algorithm, with an adaptive timestep.
topology changes, nodes naturally update their coordinates accord-
ingly. Finally, it handles high-error nodes. The next sections evalu-
ate how well Vivaldi achieves these properties experimentally and
investigate what coordinate space best ﬁts the Internet.
(cid:14) = cc (cid:2)
local error
local error + remote error
(2)
3. EVALUATION METHODOLOGY
Using this (cid:14), an accurate node sampling an inaccurate node will
not move much, an inaccurate node sampling an accurate node will
move a lot, and two nodes of similar accuracy will split the di(cid:11)er-
ence.
Computing the timestep in this way provides the properties we
desire: quick convergence, low oscillation, and resilience against
high-error nodes.
2.6 Estimating accuracy
The adaptive timestep described above requires that nodes have a
running estimate of how accurate their coordinates are. Each node
compares each new measured RTT sample with the predicted RTT,
and maintains a moving average of recent relative errors (absolute
error divided by actual latency). As in the computation of (cid:14), the
weight of each sample is determined by the ratio between the pre-
dicted relative error of the local node and of the node being sam-
pled.
In our experiments, the estimate is always within a small
constant factor of the actual error. Finding more accurate and more
elegant error predictors is future work, but this rough prediction
has been su(cid:14)cient to support the parts of the algorithm (such as the
timestep) that depend on it.
2.7 The Vivaldi algorithm
Figure 3 shows pseudocode for Vivaldi. The vivaldi procedure
computes the weight of a sample based on local and remote error
(line 1). The algorithm must also track the local relative error. It
does this using a weighted moving average (lines 2 and 3). The re-
mainder of the Vivaldi algorithm is identical to the simple version.
Vivaldi is fully distributed: an identical vivaldi procedure runs
on every node. It is also e(cid:14)cient: each sample provides informa-
tion that allows a node to update its coordinates. Because Vivaldi
is constantly updating coordinates, it is reactive; if the underlying
The experiments are conducted using a packet-level network sim-
ulator running with RTT data collected from the Internet. This sec-
tion presents the details of the framework used for the experiments.
3.1 Latency data
The Vivaldi simulations are driven by a matrix of inter-host In-
ternet RTTs; Vivaldi computes coordinates using a subset of the
RTTs, and the full matrix is needed to evaluate the quality of pre-
dictions made by those coordinates.
We use two di(cid:11)erent data sets derived from measurements of a
real network. The ﬁrst and smaller data set involves 192 hosts on
the PlanetLab network test bed [20]. These measurements were
taken from a public PlanetLab all-pairs-pings trace [28].
The second data set involves 1740 Internet DNS servers. We
built a tool based on the King method [10] to collect the full matrix
of RTTs. To determine the distance between DNS server A and
server B, we ﬁrst measure the round trip time to server A and then
ask server A to recursively resolve a domain served by B. The dif-
ference in times between the two operations yields an estimate of
the round trip time between A and B (see Figure 4). Each query
involves a unique target name to suppress DNS caching.
We harvested the addresses of recursive DNS servers by ex-
tracting the NS records for IP addresses of hosts participating in
a Gnutella network. If a domain is served by multiple, geograph-
ically diverse name servers, queries targeted at domain D (and in-
tended for name server B) could be forwarded to a di(cid:11)erent name
server, C, which also serves D. To avoid this error, we ﬁltered the
list of target domains and name servers to include only those do-
mains where all authoritative name servers are on the same subnet
(i.e. the IP addresses of the name servers are identical except for
the low octet). We also veriﬁed that the target nameservers were re-
sponsible for the associated names by performing a non-recursive
0
20
40
60
time (s)
(a)
0.001
0.01
0.1
1.0
c = 1.0
c = 0.05
c = 0.25
c = 0.01
)
s
m
(
r
o
r
r
e
100
50
0
)
s
m
(
r
o
r
r
e
100
50
0
10
20
30
time (s)
(b)
40
50
60
Figure 5: The e(cid:11)ect of (cid:14) on rate of convergence. In (a), (cid:14) is set
to one of a range of constants. In (b), (cid:14) is calculated with Equa-
tion 2, with cc values ranging from 0.01 to 1.0. The adaptive (cid:14)
causes errors to decrease faster.
3.2 Using the data
We used the RTT matrices as inputs to a packet-level network
simulator [9]. The simulator delays each packet transmission by
half the time speciﬁed in the RTT matrix. Each node runs an in-
stance of Vivaldi which sends RPCs to other nodes, measures the
RTTs, and uses those RTTs to run the decentralized Vivaldi algo-
rithm.
We deﬁne the error of a link as the absolute di(cid:11)erence between
the predicted RTT for the link (using the coordinates for the two
nodes at the ends of the link) and the actual RTT. We deﬁne the
error of a node as the median of the link errors for links involving
that node. We deﬁne the error of the system as the median of the
node errors for all nodes in the system.
The main limitation of the simulator is that the RTTs do not vary
over time: the simulator does not model queuing delay or changes
in routing. Doing this typically requires modeling the underlying
structure of the network. Since this research involves evaluating
models for the structure of the network, it seems safest to stick to
real, if unchanging, data rather than model a model.
In all of the experiments using the simulator, each node measures
a RTT to some other node once each second.
4. EVALUATION
This section examines (1) the e(cid:11)ectiveness of the adaptive time-
step (cid:14); (2) how well Vivaldi handles high-error nodes; (3) Vivaldi’s
sensitivity to communication patterns, in order to characterize the
types of network applications that can use Vivaldi without addi-
tional probe tra(cid:14)c; (4) Vivaldi’s responsiveness to network changes;
and (5) Vivaldi’s accuracy compared to that of GNP. The exper-
iments presented in this section use Euclidean coordinates; Sec-
tion 5 investigates other coordinate systems.
4.1 Time-Step choice
Section 2.5 claimed that too large a time-step could result in os-
cillating coordinates with poor ability to predict latency, and that
small time-steps would result in slow convergence time. To eval-
uate this intuition we simulated Vivaldi on the King data set using
3-dimensional Euclidean coordinates.
Figure 5(a) plots the progress of the simulation using various
constant values of (cid:14). The plot shows the median prediction error
as a function of time. Small values of (cid:14), such as 0.001, cause slow
convergence; increasing (cid:14) to 0.01 causes faster convergence; but
increasing (cid:14) again to 1.0 prevents Vivaldi from ﬁnding low-error
Figure 4: It is possible to measure the distance between two name-
servers by timing two DNS queries. The ﬁrst query (1) is for a name in
the domain of nameserver A. This returns the latency to the ﬁrst name-
server. The second query is for a name in the domain nameserver B
(2) but is sent initially to the recursive nameserver A. The di(cid:11)erence
between the latency of (1) and (2) is the latency between nameserver A
and B.
query for that name and checking for the “aa” bit in the response
header, which indicates an authoritative answer.
We measured pairwise RTTs continuously, at random intervals,
over the course of a week. Around 100 million measurements were
made in total. We compute the ﬁnal RTT for a given pair as the
median of all trials. Using the median RTT ﬁlters out the e(cid:11)ects
of transient congestion and packet loss. Other measurement stud-
ies [17] have used the minimum measured RTT to eliminate con-
gestion e(cid:11)ects; this approach is not appropriate for the King tech-
nique since congestion can cause measured RTT to be higher or
lower than the true value. King can report a RTT lower than the
true value if there is congestion on the path to the ﬁrst nameserver.
Some nameservers were obvious outliers in the data set: the la-
tency to these servers was equal and small from all hosts. This in-
accuracy could be the result of high load on the nameservers them-
selves or heavy queuing near the servers. If load or queuing at name
server A adds a delay that is signiﬁcantly larger than the network
latency, the initial query (to A) and recursive query (via A to B) will
require roughly the same amount of time and the estimated latency
between that server and any other server will be near zero.
We identiﬁed these servers by the disproportionate number of
triangle inequality violations they participated in. These servers
were removed from the data set. About 10 percent of the original
nodes were removed in this way.
The PlanetLab nodes span the globe, but most are located at
North American universities with fast Internet2 connections. The
King nodes are all name servers, and thus still likely to be well
connected to the Internet, but the servers are more geographically
diverse than the PlanetLab nodes. The median RTT of the Planet-
Lab data set is 76ms and of the King data set is 159ms.
We also used two synthetic data sets. The grid data set is con-
structed to provide a perfect two-dimensional ﬁt; this data set is
created by assigning two-dimensional coordinates to each node and
using the Euclidean distances between nodes to generate the ma-
trix. When ﬁtting this data set, Vivaldi recovers the coordinates up
to rotation and translation.
We also use the ITM topology generation tool [2] to generate
topologies. The latency between two nodes in this data set is found
by ﬁnding the shortest path through the weighted graph that ITM
generates. This data set allows us to explore how topology changes
a(cid:11)ect Vivaldi.
(cid:14) = 0:05
(cid:14) = 0:25 (cid:2) local error=(local error + remote error)
)
s
m
(
r
o
r
r
e
k
n
i
l
n
a
i
d
e
m
30
20
10
0
adaptive
constant
t = 1
t = 10
t = 50
t = 100
t = 200
t = 300
50
100
250
time since join of second set
150
200
300
Figure 6: The evolution of a stable 200-node network after 200 new nodes join. When using a constant (cid:14), the new nodes confuse
the old nodes, which scatter until the system as a whole has re-converged. In contrast, the adaptive (cid:14) (Equation 2) allows new nodes
to ﬁnd their places quickly without disturbing the established order. The graph plots link errors for constant (dotted) and adaptive
(solid) (cid:14). At t = 1, the lower line in each pair is the median error among the initial nodes. The higher line in each pair is the median
error among all pairs. The constant (cid:14) system converges more slowly than the adaptive system, disrupting the old nodes signiﬁcantly
in the process.
coordinates. The reason for the high average error is that the high
(cid:14) causes the coordinates to oscillate in large steps around the best
values.
In Figure 5(b) we repeat the experiment using (cid:14) as computed in
Equation 2. The data show the e(cid:11)ectiveness of using a large (cid:14) when
a node’s error is high (to converge quickly) and a small (cid:14) when a
node’s error is low (to minimize the node’s oscillation around good
coordinates). Empirically, a cc value of 0.25 yields both quick error
reduction and low oscillation.
4.2 Robustness against high-error nodes
Ideally, Vivaldi would cope well with large numbers of newly-
joined nodes with inconsistent coordinates. Vivaldi’s adaptive (cid:14)
should address this problem: when a node joins, it knows its rel-
ative error is quite large, and so when it communicates with other
nodes, those other nodes will approach it with appropriate skepti-
cism.
Figure 6 shows the results of a simulation to test this hypothe-
sis. The simulation uses the two-dimensional grid data set to make
it easy to visualize the evolution of the system. The simulation
started with 200 nodes that already knew coordinates that predicted
latency well. Then we added 200 new nodes to the system and let
the system evolve, using (cid:14) = 0:05 in one case and Equation 2 with
cc = 0:25 in the other. Figure 6 shows the evolution of the two
systems as well as the error over time. After a few iterations us-
ing the constant (cid:14) metric, the initial structure of the system has
been destroyed, a result of wise old nodes placing too much faith in
young high-error nodes. Because the initial structure is destroyed,
existing nodes can no longer use the current coordinates of other
existing nodes to predict latency until the system re-converges.
In contrast, the adaptive (cid:14) preserves the established order, help-
ing the new nodes ﬁnd their places faster. Also, because the struc-
ture of the original nodes is preserved while new nodes join, those
nodes can continue to use current coordinates to make accurate pre-
dictions to other original nodes. Finally, the convergence time of
the new nodes is signiﬁcantly faster; they converge at t = 60 using
the relative time-step versus t (cid:25) 250 using the constant (cid:14).
4.3 Communication patterns
As presented, Vivaldi relies on samples obtained from tra(cid:14)c
generated by the application using it. To understand the range of
systems in which this approach is appropriate, we must characterize
the sampling necessary for accurate computation of coordinates.
Figure 7: A pathological case showing the possible e(cid:11)ect of
communication patterns on the chosen coordinates. In the ﬁrst
case, nodes only contact their four nearest neighbors, allowing
the resulting coordinates to twist over long distances. In the
second case, nodes contact distant nodes as well, improving the
accuracy of the coordinates at the larger scale.
Some kinds of sampling work badly. For example, Priyantha
et al. [21] show that sampling only nearby (low-latency) nodes can
lead to coordinates that preserve local relationships but are far from
correct at a global scale. Figure 7 shows the coordinates chosen for
nodes laid out in a grid when each node communicates only with
its four neighbors. This case is clearly a pathological one, but we
would like to characterize the boundary between normal behavior
and pathology.
The pathological case can be ﬁxed by adding long-distance com-
munications, giving the nodes a more global sense of their place in
the network. But how much long-distance communication is nec-
essary in order to keep the coordinates from distorting? To answer
this question, we ran an experiment with a grid of 400 nodes. Each