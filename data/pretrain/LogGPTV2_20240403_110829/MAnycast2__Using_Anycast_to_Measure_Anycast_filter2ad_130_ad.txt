### Great Circle Distance (GCD) Method

**Figure 2: Great Circle Distance Technique**

The traditional method for detecting anycast prefixes, known as the Great Circle Distance (GCD) technique, involves conducting round-trip time (RTT) measurements from geographically distributed unicast vantage points (VPs). By using the VP locations, one can infer a circular region of possible geolocation for a target IP. The diameter of this circle is constrained by the observed RTT and the speed of communication. 

**Illustration in Figure 2:**
- **Unicast Target IP:** If the target IP is unicast, the circles derived from different VPs will intersect, and the intersection approximates the location of the target IP.
- **Anycast Target IP:** If the target IP is anycast, the RTT from each node is likely to be smaller compared to the unicast case, as the ping response is returned by the instance closest to the VP in terms of routing. In this scenario, not all circles may intersect, and the various intersections will approximate the different locations of the anycast instances.

**Application:**
This technique can be used with a geographically diverse set of unicast nodes to determine if an IP is anycast and to estimate the geographic footprint of the corresponding anycast fabric. The GCD method relies on accurate latency measurements, which require multiple measurements from multiple nodes. However, it can be sensitive to latency dynamics or path characteristics, leading to false negatives if deployed across underprovisioned infrastructure.

### Tangled Anycast Deployment

**Table 5: Summary of Tangled VPs Location and Connectivity**

| VP ID | Location | Transit Provider (ASN) | IXP | Peers |
|-------|----------|------------------------|-----|-------|
| au-syd | Sydney (AU) | Vultr (20473) | - | 1 |
| br-gru | Sao Paulo (BR) | Ampath (20080), ANSP (1251), Leovin (262605), Nexfibra (264575) | spo.IX.br | 1892 |
| br-poa | Porto Alegre (BR) | Vultr (20473) | poa.IX.br | 218 |
| dk-cop | Copenhagen (DK) | DK-Hostmaster (39839) | - | 1 |
| uk-lnd | London (UK) | Linx | 1 |
| fr-par | Paris (FR) | France-IX | 1 |
| jp-hnd | Tokyo (JP) | - | 1 |
| nl-ens | Enschede (NL) | UTwente (1133) | - | 1 |
| us-mia | Miami (US) | Ampath (20080), Los Nettos (226) | - | 1 |
| us-was | Washington (US) | Wide (2500) | - | 1 |

**Table 6: PEERING VPs Location and Connectivity**

| VP ID | Location | Transit Provider (ASN) | IXP | Peers |
|-------|----------|------------------------|-----|-------|
| wisc01* | Madison (US) | University of Wisconsin (3128) | - | 1 |
| gatech01* | Atlanta (US) | Georgia Institute of Technology (2637) | - | 1 |
| amsterdam01* | Amsterdam (NL) | Bit BV (12859) | AMS-IX | 861 |
| uw01 | Seattle (US) | Pacific Northwest Gigapop (101) | - | 1 |
| grnet01 | Athens (GR) | GRNet (5408) | - | 1 |
| ufmg01* | Belo Horizonte (BR) | RNP (1916) | mg.IX.br | 1 |
| seattle01 | Seattle (US) | RGNet (3130) | SIX | 1 |

### Classification and Breakdown of /24s by Number of PEERING VPs Receiving Responses

**Table 7: Classification and Breakdown of /24s by Number of PEERING VPs Receiving Responses**

| Classification | # VPs | Distinct /24 | Distinct ASN |
|----------------|-------|--------------|--------------|
| Unicast | 1 | 3,390,077 | 54,343 |
| Anycast* | 2 | 15,780 | 905 |
| Anycast* | 3 | 1,243 | 111 |
| Anycast | 4 | 2,092 | 36 |
| Anycast | 5 | 1,061 | 10 |
| Anycast | 7 | 1 | 1 |

### Comparison Between PEERING and Tangled Results

**Table 8: Comparison Between PEERING and Tangled Results**

| Distinct /24 | # VPs PEERING | # VPs Tangled | iGreedy Anycast |
|--------------|---------------|---------------|------------------|
| 1 (Unicast) | 2,977,255 (87.8%) | - | 53 |
| 2 (Anycast*) | 8,044 (0.2%) | 837 (5.3%) | 266 |
| 3 (Anycast*) | 199 (0%) | 331 (2.1%) | 123 |
| â‰¥4 (Anycast) | 153 (0%) | 298 (1.9%) | 152 |

### PEERING Measurement Results

In this section, we present additional results from measurements performed using the PEERING platform. Table 6 summarizes the PEERING VPs used, while Table 7 reports the results of the PEERING measurement conducted on September 11, 2020. Table 8 compares these results with those from the Tangled measurement on May 5, 2020.

**Temporal Bias:**
It is important to note that the two measurements were conducted four months apart, which could introduce temporal bias.

**Agreement and Disagreement:**
- When 4 or more PEERING VPs received responses, 4 or more Tangled VPs also did in 90% of the cases.
- For unicast classifications, MAnycast2 in PEERING agreed with Tangled in 87.8% of the cases and disagreed in only 0.3%.
- Of the 0.3% disagreement, most cases involved MAnycast2 in Tangled receiving answers on 2 VPs. iGreedy confirmed that only 266 out of 8,044 /24 prefixes were anycast.
- For prefixes with answers received on 3 or more VPs on Tangled and classified as unicast by MAnycast2 in PEERING, iGreedy showed that 275 out of 352 /24 prefixes were anycast.
- When MAnycast2 in PEERING classified prefixes as anycast in disagreement with Tangled, for answers received on 2 VPs on PEERING, only 89 out of 12,922 /24s were anycast according to iGreedy. For answers received on 3 or more VPs, 17 out of 25 /24s were anycast.

**Repeatability and Accuracy:**
These results confirm that MAnycast2 provides good results when answers are received on 3-4 or more VPs. Repeated measurements with different sets of VPs can reveal more anycast prefixes and filter out misclassified unicast prefixes due to route flaps and load balancing.

**Comparison with Fewer VPs:**
We repeated the measurement with PEERING using fewer VPs (marked with * in Table 6). For prefixes previously classified as anycast (with answers on 4 or more VPs):
- 4% were misclassified as unicast.
- 26% were received at only 2 VPs.
- 49.7% were received at only 3 VPs.
- Only 0.3% (10 prefixes) were received at 4 VPs.

These results underscore the importance of using a high number of VPs to reduce the measurement overhead required by iGreedy and to avoid missing anycast prefixes.