and hits being defined in 10s of nanoseconds, this resolution is
insufficient to successfully launch most side channel attacks.
3 THREAT MODEL AND CHALLENGES IN
ARM
3.1 Threat Model
This work studies the ability of an attacker to fingerprint a user’s
website browsing activity via a low frequency contention channel
in either the shared cache or the GPU of an ARM SoC. The attacker
is motivated to track the user’s web activity for some malicious
purposes, such as to better identify the victim’s interests for tar-
geted advertising or to covertly determine sensitive information
(e.g., medical condition, sexual/political preferences, etc.) for the
purpose of discrimination or blackmail. We consider two typical
scenarios in website fingerprinting: (1) closed world, where the
victim only visits websites from the list of sensitive websites; and
(2) open world, where users might also visit some non-sensitive
websites. To accomplish the fingerprinting task, the attacker can
pre-profile a list of sensitive websites and build a model based on
specific browsers (e.g., Chrome/Firefox/Safari) and devices (e.g.,
MacBook/Smartphone).
To evaluate the potential threat from this attack, we mainly
examine a web-based attacker who is only capable of delivering
JavaScript from a website. We also conduct an investigation of an
app based attacker who is able to trick a user into installing malware,
but impose additional limits, analyzing how well the attack would
function if the OS clock functions were similarly limited to those
of web browser1.
Web-Based Attacker. The web-based attacker attempts to ex-
ploit the cache occupancy channel in the context of the web browser,
delivering a JavaScript file to the user via a malicious advertisement
on a legitimate page or by tricking the user into visiting a malicious
web page. We assume that the attacker is unable to exploit any
vulnerabilities in the browser. Instead, (s)he attempts to create a
cross tab attack scenario, wherein the user leaves the tab with the
1Researchers have demonstrated that the high precision timers available to native
programs can produce very accurate attacks. OS developers may move to reduce the
attack surface by reducing the granularity of available timers in the future
786ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Patrick Cronin, Xing Gao, Haining Wang, and Chase Cotton
malicious JavaScript open and continues to browse other websites
in a different tab. The malicious JavaScript in the background tab
continues to run and attempts to monitor the user’s activity. This is
reasonable as all current web browsers enable users to visit multi-
ple websites at the same time in different browser tabs. While tabs
are isolated from each other in software, they are not necessarily
segregated in hardware. Furthermore, the web-based attacker is
restricted by the privileges granted to JavaScript, and are subject to
the reduced precision timers, memory management, and scheduling
constraints that the browser enforces.
App-Based Attacker. We assume that the app-based attacker
is capable of tricking the user into installing an application or
program onto their device that contains the malicious observation
code. The code can be integrated into a benign application such as
a music player, fitness tracker, or social media application, and is
therefore capable of running a disguised process to monitor user
activities. Unlike the web-based attacker, the app-based attacker is
not restricted to only JavaScript and has access to the APIs provided
by the operating system, allowing better control over memory
management and scheduling. However, the attacker is not granted
any super-user privileges and does not utilize any exploit to access
privileged commands.
Note that, in both scenarios, the application/JavaScript does not
necessarily need to be sourced from a purely malicious entity. Such
a tracking service could be deployed in social media applications
to better identify and profile user activities. Large ad-supported
companies like Google or Facebook could also greatly benefit from
deploying a similar script on their webpages, continually monitor-
ing users browsing activities to better target advertisements.
3.2 Cache Occupancy Challenges in ARM
Exploiting the occupancy statistics of the last-level cache has been
studied with varying degrees of success across x86 systems [6, 44,
50]. In parallel to this work, Shusterman et al. [49] performed a
cursory proof that the cache occupancy could also be applied to
ARM systems. We greatly expand their work, investigating a num-
ber of different configurations and optimizations across multiple
browsers and devices. To motivate these optimizations, we first
describe unique challenges that the ARM ecosystem presents to the
cache occupancy channel.
ARM Cache Contention. ARM systems differ from common
x86 architectures in multiple aspects. ARM offers exclusive and
inclusive caching at different levels, and utilizes heterogeneous
architectures in which multiple different core architectures and
cache layouts may be present on the same chip. Also, each type of
core may run at different frequencies. Those factors increase the
difficulty of exploiting the cache occupancy channel in the ARM
architecture. Since the system-level cache is the only cache level
shared by all processor cores in ARM, if the scheduler moves the
spy and victim processes between different core types, it can greatly
affect the observed cache profile.
Due to the exclusive nature of the last-level cache in ARM, when
a process migrates the data in its L1/L2 caches, the data will not
be present in the last-level cache, but in the L1/L2 caches of its
previous location. Upon migrating a process from one core type
to another, some ARM processors invalidate the entirety of the
previous cores’ caches, while others may allow that data remain
until it is evicted. In either case, in an exclusive cache setup, any
reads to locations that were in the L1/L2 cache of the previous
location will be serviced from the L1/L2 and have no impact on the
L3 cache. This greatly hinders the cache occupancy channel: while
in an inclusive cache, one could reliably observe L3 occupancy (if
the value were removed from L3, it would be removed from all
higher levels), the exclusive cache can serve the value from either
the previous L1/L2 or main memory, giving no indication as to the
status of the L3 cache2.
Exclusive caching also has drawbacks with respect to buffer size.
In an x86 system with inclusive caching, the spy process evicting
the entire L3 cache would also remove any data in the L1/L2 caches.
Thus, when the victim process accesses data, it always causes ac-
tivities in the L3 cache3. However, in an ARM system, if a victim
process accesses a buffer small enough to fit in the L1/L2 cache,
a spy process that is monitoring the entirety of the L3 cache will
never see this activity. While this behavior might be unnoticed, and
even preferable, to a program under normal circumstances, it is not
ideal for the cache occupancy channel. The cache occupancy chan-
nel assumes that continually accessing a large buffer in cache will
completely evict any data of the victim process from the L3. Also,
it assumes that any access to memory will bring data back into the
L3, making it observable. Thus, to better suit ARM processors, the
access patterns and buffer sizes for the cache occupancy channel
should be carefully considered.
Browser Differences. Further complicating the applicability of
the cache occupancy channel is the memory management of a web
browser. The web-based attacker must work within the constraints
of the JavaScript engine within each web browser. Today’s pop-
ular web browsers, including Google Chrome, Apple Safari, and
Mozilla Firefox, utilize different JavaScript engines. Furthermore,
these JavaScript engines must interact with the system scheduler.
Different OSes (e.g., Google’s Android, Apple’s iOS, and MacOS)
likely utilize carefully tuned schedulers to maximize the perfor-
mance. Finally, the JavaScript engines of the major browsers will
manage memory in different ways, and the garbage collector of
each JavaScript engine will handle memory management in a way
that is not accessible to the attacker. Thus, a one size fits all ap-
proaches to cache occupancy fingerprinting is certainly not ideal as
each browser may act very differently, even on the same hardware.
4 UNDERSTANDING ARM CACHE
OCCUPANCY
We first design a series of microbenchmarks to better understand
ARM system behaviors. In particular, we investigate how energy
aware scheduling, core selection, and different browsers impact the
cache occupancy channel.
2The L3 cache on ARM also maintains the ability to be selectively inclusive if an item is
utilized by more than one core [35], however, the cache occupancy JavaScript channel
does not utilize shared memory and should not experience this behavior.
3In some x86 server CPUs (specifically Skyake-X CPUs from Intel, the L3 is ‘non-
inclusive’, meaning that it is neither fully inclusive or exclusive. Consumer CPUs from
Intel have not yet adopted this layout.
787An Exploration of ARM System-Level Cache and GPU Side Channels
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Table 1: Devices and High Power (HP) and Low Power (LP) core configurations utilized in this work.
Device
iPhone SE 2
Android
MacBook Air
Core Configuration
2x Lightning (HP)
4x Thunder (LP)
4x Kryo 385 Gold (HP)
4x Kryo 385 Silver (LP)
4x FireStorm (HP)
4x IceStorm (LP)
High Power L1/L2
Low Power L1/L2
128KB L1i / 128KB L1D / Core Unknown L1i / 48KB L1D / Core
64KB L1i / 64KB L1D / Core
64KB L1i / 64KB L1D / Core
192KB L1i / 128KB L1D / Core
128KB L1i / 64KB L1D / Core
8MB L2 Shared
256KB L2 / Core
12MB L2 Shared
4MB L2 Shared
128KB L2 / Core
4MB L2 Shared
System Level Cache
16MB
2MB
16MB
16MB
4.1 Test Devices
We select three commonly utilized devices: an iPhone SE 2 to test
iOS, a Google Pixel 3 for Android, and a MacBook Air 2020 with
M1 chip for MacOS. The detailed information about each device is
included in Table 1. In the case of the Apple devices where specific
cache sizing values are not provided by Apple, we rely on commu-
nity microbenchmarking [11, 12] to provide detailed cache level
size analysis.
We employ a Node.JS server to serve HTML and JavaScript re-
sources to our test devices. As JavaScript is single threaded, our
JavaScript microbenchmarks run within a web worker context4.
4.2 Cache Access Pattern
Modern ARM processors utilize cache prefetchers to learn data
access patterns and bring data into the cache beforehand. To accu-
rately measure the cache performance of a device, we must develop
cache access patterns to defeat the most common prefetching algo-
rithms, next line and stride prefetching.
The next line prefetcher exploits spatial locality, fetching the
next cache line of memory into the cache on every access. The
stride prefetcher actively learns a pattern in data access and fetches
the data based on the pattern.
It has been demonstrated that the stride prefetcher is limited
in recognizing patterns within memory pages and can only keep
track of a certain number of patterns before the hardware pattern
matching is exhausted [7]. To evade the two prefetchers, we follow
a similar access pattern to that of [7]. We create a large array of
buffers which spans multiple memory pages. We then access the
first, third, fifth, etc. line from every page. Accessing every other
line avoids any impact of the next line prefetcher and accessing
one item from each buffer before looping back to the first exhausts
the ability of the stride prefetcher to learn a pattern.
4.3 Foreground vs. Background Activity
We next design a microbenchmark to identify cache behavior dif-
ferences between foreground and background activity. Specifically,
we seek to understand whether the scheduler treats foreground
and background browser tabs differently.
To this end we create a large buffer and access increasingly large
portions in the prefetcher thwarting manner described previously,
normalizing the buffer access times with respect the number of
memory accesses to better understand the impact of the scheduler
4Web workers were designed to facilitate long computations in a different process,
while allowing the main UI thread to remain responsive.
Figure 2: iPhone SE 2 Cache Average Memory Access Time
and its use of the different core designs. To assess background activ-
ity, we run the script in a background tab while the foreground tab
is set to www.google.com. We also find that writing to the accessed
buffer (e.g., increment a counter stored at each array location) in-
creases the consistency of experiments. This can be attributed to a
more complex instruction stream reducing the amount of optimiza-
tion and/or reordering that can occur, and thereby better exposing
the cache sizes.
Testing this on the iPhone SE 2 demonstrates very different fore-
ground and background cache behaviors, as shown in Figure 2.
Background accesses are nearly 10x slower than foreground ac-
cesses, and the background memory access time curve is signifi-
cantly different from the foreground access curve. The foreground
curve experiences multiple sharp increases in cache access time,
indicating that the multiple levels of cache are present (e.g., L1, L2,
and L3) while the behavior of the background process shows far less
distinguishable increases in timing. Similar behavior is observed
on the Google Pixel 3.
4.4 Browser Memory Management
In a desktop operating system like MacOS, major browsers (e.g.,
Google Chrome, Apple Safari, and Mozilla Firefox) typically utilize
their own rendering and JavaScript engine. Also, the M1 Macbook
Air is the first device running a desktop/laptop operating system
utilizing a heterogeneous processor. We therefore examine cache
behaviors on the M1 MacBook Air across these major browsers.
Figure 3 shows the results for different browsers. Most notably,
Apple’s Safari is the only browser that seems to take advantage
of the heterogeneous cores with a 10x slowdown in access speed
0246810121416Buffer Size (MB)20253035404550Background Access Time (ns)Average Memory Access Time iPhone SE 2BackgroundForeground2.02.53.03.54.04.55.05.56.0Foreground Access Time (ns)788ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Patrick Cronin, Xing Gao, Haining Wang, and Chase Cotton
(a) Chrome
(b) Safari
(c) Firefox
Figure 3: MacBook Air M1 Cache Average Memory Access Times with Different Browsers.
and a noticeably different timing pattern for the background tab.
This indicates that the foreground and background processes were
impacting different caches (the different cache architectures of
the high vs. low power cores). Both Google Chrome and Mozilla
Firefox seem to maintain the same access speed for their respective
foreground and background processes, indicating that background
tabs are not relegated to the low power cores.
We also observe that the overall shape of the timing curves
for cache accesses is unique to each browser, indicating that even
though the access pattern was the same, the memory allocation
algorithms for each JavaScript engine are vastly different. Thus,
understanding how these allocation strategies affect cache timing
can greatly increase the accuracy of a potential cache occupancy
attack. Furthermore, different compiler optimizations and code
differences could further impact the memory access differences
that we observe across platforms.