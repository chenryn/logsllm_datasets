to cross compile the Linux kernel, libraries, and user-level appli-
cations. Thus, all programs running in our system (both vanilla
and ASIST), including vulnerable programs and benchmarks, were
cross compiled with this tool chain on another PC. We slightly
modiﬁed linker scripts to separate code and data for both static and
dynamic code encryption, and align headers, code, and data into
separate pages in case of dynamic encryption. To implement static
encryption, we extended objcopy with the --encrypt-code
ﬂag. The key can be provided by the user or randomly chosen.
4.4 Portability to Other Systems
Our approach is easily portable to other architectures and op-
erating systems. Regarding ASIST’s hardware extensions, imple-
menting new registers that are accessible by the operating system
is quite easy in most architectures, including x86. Encrypting the
return address at each function call and decrypting it before return-
ing depends on the calling convention at each architecture. For
instance, in x86 it can be implemented by slightly modifying call
and ret instructions. In our current design, we have implemented
the runtime instruction decryption for RISC architectures that use
ﬁxed-length instructions. Thus, porting the decryption functional-
ity in other RISC systems will be straight-forward. On the other
hand, CISC architectures such as x86 support variable-length in-
structions. However, our approach can also be implemented in such
architectures with minor modiﬁcations. Since instructions reside
in memory before they are executed, we can simply encrypt them
without the need of precise disassembly, e.g., in blocks of 32-bits,
depending on the key size. In architectures with variable-length in-
structions this encryption will not be aligned at each instruction, but
this is not an issue. The memory blocks will be decrypted accord-
ingly by the modiﬁed processor before execution. For instance,
a memory block can be decrypted based on the byte offset of its
respective memory address. Also, since we have placed the de-
cryption unit before the instruction cache, decryption is performed
at each word that is stored in cache, rather than at each instruction.
We have implemented our prototype by modifying the Linux ker-
nel. However, the same modiﬁcations can be made in other oper-
ating systems as well, as we change generic kernel modules such
as the binary loader, the process scheduler and context switch, and
the page fault handler. These modules exist in all modern operat-
ing systems and they can be changed respectively to support the
hardware features offered by a randomized processor.
CVE Reference
Vulnerability Description
Access Vector
Location
Vulnerable Program
CVE-2010-1451
CVE-2013-0722
CVE-2012-5611
CVE-2002-1549
CVE-2002-1337
CVE-2002-1496
CVE-2010-4258
CVE-2009-3234
CVE-2005-2490
Linux kernel before 2.6.33 does not properly implement a non-executable stack on SPARC
platform
Buffer overﬂow due to incorrect user-supplied input validation
Buffer overﬂow that allows remote authenticated users to execute arbitrary code via a long
argument to the GRANT FILE command
Buffer overﬂow that allows to execute arbitrary code via a long HTTP GET request
Buffer overﬂow that allows to execute arbitrary code via certain formatted address ﬁelds
Buffer overﬂow that allows to execute arbitrary code via a negative value in the Content-
Length HTTP header
Linux kernel allows to bypass access_ok() and overwrite arbitrary kernel memory locations
by NULL pointer dereference to gain privileges
Buffer overﬂow that allows to execute arbitrary user-level code via a ”big size data“ to the
perf_counter_open() system call
Buffer overﬂow that allows to execute arbitrary code by calling sendmsg() and modifying
the message contents in another thread
Local
Remote
Remote
Remote
Remote
Remote
Local
Local
Local
Stack
Stack
Stack
Stack
BSS
Heap
Kernel
Kernel
stack
Stack
Custom
Ettercap 0.7.5.1 and earlier
Oracle MySQL 5.1.65 and
MariaDB 5.3.10
Light HTTPd (lhttpd) 0.1
Sendmail 5.79 to 8.12.7
Null HTTPd Server 0.5.0 and
earlier
Linux kernel before 2.6.36.2
Linux kernel 2.6.31-rc1
Linux kernel before 2.6.13.1
Table 3: Representative subset of code injection attacks tested with ASIST. We see that ASIST is able to successfully prevent code
injection attacks targeting vulnerable user-level programs as well as kernel vulnerabilities.
5. EXPERIMENTAL EVALUATION
We mapped our prototype onto an FPGA running two versions
of the Linux kernel, 2.6.21 and 3.8, as described in Section 4. We
used the Ethernet adapter of the FPGA and conﬁgured the system
with networking and a static IP address. This allows for remote
exploitation attempts for our security evaluation, and for evaluating
the performance of a Web server. As the available memory on the
FPGA is only 256 MB, and there is no local disk in the system,
we used NFS to mount a partition of a local PC that contains all
the cross compiled programs needed for the evaluation. To avoid
measuring NFS delays in our evaluation, we copied each executable
program in the local RAM ﬁle system before its execution.
We evaluated the ASIST prototype that uses XOR encryption
with a 32-bit key, comparing static and dynamic encryption im-
plementations with an unmodiﬁed system (vanilla processor and
unmodiﬁed operating system). We observed that using a larger
key or transposition instead of XOR for encrypting instructions has
the same effectiveness on preventing code injection attacks and the
same efﬁciency in terms of performance. We did not use the return
address encryption in our security and performance evaluation.
programs were cross compiled with our toolchain and encrypted
with our extended objcopy tool.
In all cases our remotely in-
jected shellcode was executed successfully only on the vanilla sys-
tem, while ASIST always prevented the execution of the injected
code and resulted in illegal instruction exception.
We also tested attacks exploiting three kernel vulnerabilities with
and without ASIST. We cross compiled, modiﬁed and encrypted
three different kernel versions for each one: 2.6.21, 2.6.31-rc1 and
2.6.11. When running the vanilla kernel on the unmodiﬁed proces-
sor, the kernel exploits resulted in the successful execution of the
provided user-level code with kernel privileges. On the other hand,
the encrypted kernels with ASIST resulted in kernel panic for all
the exploits, avoiding a system compromise with kernel privileges.
5.2 Performance Evaluation
To evaluate ASIST’s performance we compare (i) vanilla Leon3
with unmodiﬁed Linux kernel (Vanilla), (ii) ASIST with static
encryption (ASIST-Static), and (iii) ASIST with dynamic code
encryption (ASIST-Dynamic), when running the SPEC CPU2006
benchmark suite and two real world applications.
5.1 Security Evaluation
5.2.1 Benchmarks
To demonstrate the effectiveness of ASIST at preventing code
injection attacks exploiting user- or kernel-level vulnerabilities, we
tested a representative sample of attacks shown in Table 3. The
ﬁrst six attacks target buffer overﬂow vulnerabilities on user-level
programs, while the last three attacks target a NULL pointer deref-
erence and two buffer overﬂow vulnerabilities of the Linux kernel.
First, we ran a vanilla 2.6.21 kernel, which does not properly
implement a non-executable stack on SPARC. We built a custom
program with a typical stack-based buffer overﬂow vulnerability,
and we used a large command-line argument to inject SPARC exe-
cutable code into the program’s stack, which was successfully ex-
ecuted by overwriting the return address. We then used an ASIST
modiﬁed kernel without enabling the return address encryption, and
we ran a statically encrypted version of the vulnerable program
with the same argument. In this case, the program was terminated
with an illegal instruction exception, as the unencrypted injected
code could not be executed. Similarly, we ran an unencrypted ver-
sion of the vulnerable program and relied on the page fault handler
for dynamic code encryption. Again, the injected code caused an
illegal instruction exception due to the ISR.
We performed similar tests with all the other vulnerable pro-
grams: Ettercap, which is a packet capture tool, MariaDB database,
Light HTTPd and Null HTTPd webservers, and sendmail. These
We ran all the integer benchmarks from the SPEC CPU2006
suite (CINT2006) [49], which includes several CPU-intensive ap-
plications. Figure 7 shows the slowdown of each benchmark when
using ASIST with static and dynamic encryption, compared to the
vanilla system. We see that both ASIST implementations impose
less than 1.5% slowdown in all benchmarks. For most benchmarks,
ASIST exhibits almost the same execution times as with the un-
modiﬁed system. This is due to the hardware-based instruction de-
cryption, which does not add any observable delay. Moreover, the
modiﬁed kernel performs minor extra tasks: it reads the key from
the executable ﬁle (for static encryption) or it randomly generates
a new key (for dynamic encryption) only once per each execution,
while it adds just one extra instruction before each context switch.
We notice a slight deviation from the vanilla execution time only for
three of the benchmarks: gcc, sjeng, and h264ref. For these
benchmarks, we observe a slight slowdown of 1%–1.2% in static
and 1%–1.5% in dynamic encryption. This deviation is probably
due to the different linking conﬁgurations (statically linked versus
dynamically linked shared libraries).
One might expect that the dynamic encryption approach would
experience a considerable performance overhead due to the ex-
tra memory copy and extra work needed to encrypt code pages at
each text page fault. However, our results in Figure 7 indicate that
n
w
o
d
w
o
S
l
1.20
1.15
1.10
1.05
1.00
0.95
0.90
Vanilla
ASIST-Static
ASIST-Dynamic
4
0
4
0
4
0
4
2
4
4
4
5
4
5
4
6
4
6
0
.
p
1
.
b
3
.
g
9
.
m
5
.
g
6
.
h
e
rl
b
e
zi
p
2
c
c
n
c
h
c
f
o
b
m
k
4
.
h
2
6
4
r
e
f
n
t
u
m
8
.
sj
e
2
.li
b
m
n
g
m
e
r
q
u
a
Figure 7: Runtime overhead using the SPEC CPU2006 bench-
mark suite. We see that both ASIST implementations have neg-
ligible runtime overhead compared to the vanilla system.
Benchmark
Data page faults per second
Text page faults per second
400.perlbench
401.bzip2
403.gcc
429.mcf
445.gobmk
456.hmmer
458.sjeng
462.libquantum
464.h264ref
38.4964
44.3605
60.3235
51.7769
25.4735
0.0546246
71.9751
5.18675
3.19614
1.97215
0.193831
3.93358
0.0497679
0.905984
0.0223249
0.0676988
0.0486765
0.0333707
Table 4: Data and text page faults per second when running the
SPEC CPU2006 benchmark suite. All benchmarks have very
few text page faults per second, which explains the negligible
overhead of the dynamic encryption approach.
dynamic encryption performs equally well with static encryption.
Thus, our proposed approach to dynamically encrypt program code
at the page fault handler, instead of statically encrypt the code be-
fore program’s execution, does not seem to add any extra overhead.
To better understand the performance of this approach, we instru-
mented the Linux kernel to measure the data and text page faults of
each process that uses the dynamic encryption mode. Table 4 shows
the data and text page faults per second for each benchmark. We
see that all benchmarks have a very low rate of text page faults, and
most of them experience signiﬁcantly less than one text page fault
per second. Moreover, we observe that the vast majority of page
faults are for data pages, while only a small percentage of the total
page faults are related to code. Therefore, we notice a negligible
overhead with dynamic code encryption at the page fault handler
for two main reasons: (i) as we see in Table 4, text page faults
are very rare, and (ii) the overhead of the extra memory copy and
page encryption is signiﬁcantly less that the page fault’s overhead
for fetching the requested page from disk. Note that in our setup
we use a RAM ﬁle system instead of an actual disk, so a production
system may experience an even lower overhead.
The very low page fault rate for pages that contain executable
code makes the dynamic encryption a very appealing approach, as
it imposes practically zero runtime overhead, and at the same time
it supports shared libraries and transparently generates a new key
at each program execution.
5.2.2 Real-world Applications
We evaluated ASIST with two real-world applications. First, we
ran the lighttpd Web server in a vanilla system and in the two
versions of ASIST. We used another machine located in the local
network to repeatedly download 14 ﬁles of different sizes, ranging
from 1 KB to 8 MB, and we measured the average download time
for each ﬁle. Figure 8 shows the slowdown of the download time
as a function of the ﬁle size for each system. We see that ASIST
does not impose any considerable delay, as the download time re-
mains within 1% of the vanilla system for all ﬁles. We also no-
tice that both static and dynamic encryption implementations per-
form almost equally good. We measured the page faults caused by
lighttpd: 261 data page faults per second, and just 0.013 text
page fault per second. Thus, the dynamic encryption did not add
any runtime overhead to the server. Moreover, we observed that
most of the text page faults occur during the ﬁrst few milliseconds
of the lighttpd execution, when the code is loaded into memory,
and then practically no text page fault occurs.
In our last benchmark we ran an sqlite3 database in the vanilla