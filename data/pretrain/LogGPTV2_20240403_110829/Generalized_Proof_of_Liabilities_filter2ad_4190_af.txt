Selective privacy preserving claims. Sometimes the prover
4.4.4
may need to make zero-knowledge claims that are publicly verifi-
able, such as the range of the total liabilities without leaking the
exact value. For example, in the solvency case, the prover commits
to the total liabilities and assets, thus can generate a zero-knowledge
proof of solvency, i.e., the amount of total liabilities is no more than
the total assets. Multiple entities can also make claims using multi-
party computation without leaking sensitive information to anyone.
In the case of disapproval voting, for instance, multiple candidates
can run the distributed Bulletproofs [11] MPC approach to jointly
generate a range proof and determine the best/worst candidate
without leaking the final tallies or tally differences.
4.4.5 Random Sampling. In some applications there might be third
parties auditing liabilities and PoL can be complementary to that.
For example, in the solvency case, auditors may actively sample
some users and ask them if their balances are correctly included. In
practice, an auditor doesn’t have access to the set of users, which
makes it hard to sample users for auditing. A rudimentary scheme
for the auditor is to randomly sample a node index and ask the
prover to return the inclusion proof of that node and the credential
information of the corresponding user. With a response, the auditor
contacts the user and asks whether the leaf contains correct balance.
However, in an SMT, especially in an DM-SMT of large height, a
randomly sampled leaf node does not always exist, and the auditor
has an overwhelming probability of querying a non-existing node.
Moreover, the prover can always pretend that the queried node
doesn’t exist, since the existence of a leaf node is not verifiable.
To solve this, we propose a concrete scheme of random sam-
pling, the idea of which stems from DAPOL. The auditor randomly
samples a leaf index and sends it to P. P responds with the inclu-
sion proof and user credential data if the queried node exists. To
provide user credential data, P opens the hash of the leaf node and
returns the preimage, i.e., 𝑖𝑑 and 𝑠, so the auditor can verify the
validity of the credential. In addition, we offer selective disclosure
by generating 𝑠 and 𝑏 independently, i.e., disclosing 𝑖𝑑 and 𝑠 to the
auditor doesn’t leak 𝑏, so the user’s balance remains private.
If the queried node doesn’t exist, however, the prover returns
Merkle paths of the leaf neighbor(s) closest to the queried index, to-
gether with a neighboring proof indicating that the returned node(s)
are the closest real leaf nodes, which allows the non-existence of
a sampled leaf index to be verifiable. The neighboring proof con-
sists of a set of padding nodes at certain positions and the proofs
indicating that they are padding nodes. For example, in fig. 2, if the
auditor samples Node 2 (a padding node), the two closest leaf nodes
are Node 1 and Node 4. The prover should respond with inclusion
proofs of Node 1 and Node 4, user IDs (credential information) and
the mask of the two nodes, and a neighboring proof indicating that
5 FAILURE PROBABILITY
A PoL protocol can only bound the total liabilities to the sum of P’s
individual liabilities to users that perform verifications. A prover
manipulating or discarding the individual liabilities to users that
never check cannot be detected. When a prover misbehaves while
undetected, which is undesired, we say PoL fails, and we denote
the probability for this to happen the failure probability. Failure
probability is independent of PoL security and fundamental to
distributed verification. It sheds light on how many verifiers are
sufficient to jointly prevent the prover from cheating, thus further
helps evaluate the effort needed to encourage verifiers in practice.
In this section, we analyze the failure probability of PoL, i.e.,
the probability that a malicious prover misbehaves and evades
detection when a subset of users verify the inclusion proofs. Note
that although Provisions also attempted to analyze this concept, it
only reached to the result of a special case as our eq. (3). We analyze
failure probability more generally for applications not limited to
the solvency case. In addition, Provisions claimed that the failure
probability is independent of the balances zeroed out in the solvency
case, which we show is not true by eq. (6).
Denote by 𝜌 : N∗ × N∗ × ℘(U) → [0, 1] the failure probability
function, where ℘(U) is the power set of U. The function 𝜌(𝑣, 𝜏, 𝐶)
takes as input the number of users that verify 𝑣, the tolerance
parameter 𝜏 and the cheating set 𝐶 ∈ U of size 𝑐, i.e., the set of
users to whom P cannot provide a valid proof. In short, 𝐶 can
be viewed as the set of users whose amounts are manipulated by
the prover. The function 𝜌(𝑣, 𝜏, 𝐶) outputs the probability for the
prover, when queried by 𝑣 users, to successfully prove inclusions
to at least 𝑣 − 𝜏 users while manipulating liabilities to users in 𝐶. In
short, the failure probability depicts how likely a malicious prover
can avoid detection of more than 𝜏 invalid proofs when cheating on
the liabilities to users in 𝐶. The tolerance factor 𝜏 ≤ min(𝑣, 𝑐) might
vary in different applications. In the strictest case, 𝜏 = 0, indicating
that a single invalid inclusion proof triggers an investigation. In
other cases such as tax reporting, the IRS might tolerate 𝜏 > 0
incidents before they start an investigation. Note that to cheat on
liabilities to 𝑐 users in DAPOL+, the prover doesn’t necessarily
need to manipulate the leaf nodes but internal nodes instead, which
makes the number of tree nodes manipulated smaller than 𝑐. In this
case, we still count it as 𝑐 because we only care how many users
are affected, i.e., who would receive an invalid inclusion proof.
Assume each user 𝑢 ∈ U has a probability 𝑝𝑢 = 𝐹𝑢(𝑙𝑢) to check
her inclusion proof depending on the prover’s liabilities to her. In
real-world applications such as the solvency case, users with higher
Session 12D: Decentralized Cryptographic Protocols CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea3475(a) 𝑛 = 1𝑀, 𝜏 = 0 and varying 𝑐
(b) 𝑛 = 1𝑀, 𝑐 = 100 and varying 𝜏
(c) 𝜏 = 0, 𝑐 = 0.01% · 𝑛 and varying 𝑛
Figure 4: Failure probabilities with varying 𝑐, 𝜏 and 𝑛, respectively.
balances are more likely to verify inclusion proofs. We have
If all users have probability of the same constant function 𝐹𝑢(𝑙𝑢) =
𝑝 to verify inclusion proofs, which is the simplest case, we have
𝜌(𝑣, 𝜏, 𝐶) = Pr[|𝑉 ∩ 𝐶| ≤ 𝜏
|𝑉 |=𝑣
|𝑉 |=𝑣∧
|𝑉 |=𝑣∧
|𝑉 ∩𝐶|≤𝜏 𝑢∈𝑉 𝑝𝑢
(cid:12)(cid:12)(cid:12)|𝑉 | = 𝑣] =

𝑢∈𝑉 𝑝𝑢
(cid:1) ·(cid:0)𝑛−𝑐
0≤𝑖≤𝜏 (cid:0)𝑐
(cid:1)
(cid:0)𝑛
(cid:1)
(cid:0)𝑛−𝑐
(cid:0)𝑛
(cid:1)
|𝑉 ∩𝐶|≤𝜏 𝑢∈𝑉 𝑝

𝑢∈𝑉 𝑝
|𝑉 ∩𝐶|≤𝜏 𝑢∈𝑉 𝑝

𝑢∈𝑉 𝑝
|𝑉 |=𝑣∧
|𝑉 |=𝑣
𝑣−𝑖
(cid:1)
=
=
𝑣
𝑣
𝑖
𝑣
|𝑉 |=𝑣
𝜌(𝑣, 𝜏, 𝐶) =
𝜌(𝑣, 0, 𝐶) =
When 𝜏 = 0, we can further simplify the formula:
(1)
(2)
(3)
(1 − 𝑝𝑢)))
(5)
and 𝜏 = 0, only 0.05% users verifying inclusion proofs can guar-
antee an overwhelming chance of detecting an adversarial prover
manipulating 0.01% accounts.
Without the condition that exactly 𝑣 users verify, denote by
𝜚(𝜏, 𝐶) the failure probability when the prover manipulates ac-
counts in 𝐶 without being detected by more than 𝜏 users. We have
𝜚 (𝜏, 𝐶) =
When 𝜏 = 0, we have
𝑝𝑢 · 
𝑢∈𝑈 −𝑉
𝑛∑︁
𝑣=0
𝜌(𝑣, 𝜏, 𝐶) · (∑︁
(

|𝑉 |=𝑣
𝑢∈𝑉
𝜚 (0, 𝐶) =
(1 − 𝑝𝑢)
𝑢∈𝐶
(6)
Making the same assumption as in Provisions that users with more
deposits are more likely to verify in the solvency case, eq. (6) im-
plies a negative correlation between the failure probability and P’s
liabilities to users in 𝐶. In other words, the malicious prover is more
likely to be caught when zeroing out the largest accounts than the
smallest, which contradicts the claim in Provisions.
6 EVALUATION
We implemented [18] in Rust, a PoC DAPOL+ with NDM-SMT, the
simplest accumulator, and benchmark the performance. The the-
oretical complexities of existing schemes are compared in table 1.
Note that DAPOL+ is the first PoL protocol that satisfies security
and privacy as defined. With this functionality advantage, our pur-
pose of evaluation is not to compare DAPOL+ with other schemes
but to provide concrete numbers to demonstrate its practicality.
DAPOL+ can be viewed as working in two phases: 1. generating
the SMT; 2. responding to users’ queries. We evaluate the perfor-
mance of them separately. All experiments are run with a single
thread on a recent model Apple M1 with memory size 16GiB.
6.1 SMT Generation (Setup)
We first evaluate the generation time of NDM-SMT used for DAPOL+.
For Pedersen commitments, we adopt the Ristretto255 group on
top of Curve25519 [51] as it is the curve used in the Bulletproofs
library [65]. We use Blake3 [9], which is fast, secure and highly
parallelizable, as the hash function.
We plot in fig. 5 the generation time vs. the number of nodes in
the tree with different settings of 𝑛 and 𝐻 ≥ 32 assuming 𝑁 = 4𝐵
which is approximately half of the world population [75] and should
suffice in most applications. The label to each point indicates (𝑛, 𝐻).
Consider a slightly more complicated setting in which users don’t
have the same probability but can be categorized into multiple non-
intersecting sets and users in each set have the same probability
to verify inclusion proofs. More formally, suppose all users can
be categorized into 𝑚 non-intersecting sets 𝑉1, · · · , 𝑉𝑚 such that
∀𝑖 ≠ 𝑗, 𝑉𝑖 ∩ 𝑉𝑗 = ∅ and ∪1≤𝑖≤𝑚𝑉𝑖 = U. For any 𝑢 ∈ 𝑉𝑖, the user
has probability 𝑝𝑢 = 𝐹𝑢(𝑙𝑢) = ˆ𝑝𝑖 to check the inclusion proof. If
the prover manipulates 𝑐𝑖 accounts in 𝐶𝑖 ⊆ 𝑉𝑖, then the probability
for 𝑣𝑖 users in 𝑉𝑖 to encounter at most 𝜏𝑖 verification failures equals
to 𝜌(𝑣𝑖, 𝜏𝑖, 𝐶𝑖) in the simplest uniform constant function case as
in eq. (2). Define 𝜌′((cid:174)𝑣, (cid:174)𝜏, (cid:174)𝐶) as the probability of all subsets of users
encounter no more verification failures than tolerable, i.o.w., the
prover’s misbehavior in all 𝑚 sets evades detection, where (cid:174)𝑣 =
(𝑣1, · · · , 𝑣𝑚), (cid:174)𝜏 = (𝜏1, · · · , 𝜏𝑚), (cid:174)𝐶 = (𝐶1, · · · , 𝐶𝑚). We have
(𝜌(𝑣𝑖, 𝜏𝑖, 𝐶𝑖))
(4)
By definition, the failure probability in the multi-set case is bounded
by the subset of users with the lowest risk.
𝜌(𝑣𝑖, 𝜏𝑖, 𝐶𝑖) ≤ min
1≤𝑖≤𝑚
𝜌′((cid:174)𝑣, (cid:174)𝜏, (cid:174)𝐶) =

We plot the failure probability for users having the same probabil-
ity to verify under various choice of 𝑛, 𝑐, 𝜏 in fig. 4. The smaller the
failure probability of PoL is, the lower the risk users take. The risk
is much lower as the population grows, thus allowing users to indi-
vidually verify their contributions to the total liabilities works in a
large scale. Given the fact that 150.6 million mobile users accessed
the Amazon App in September 2019 [54], assuming 𝑛 = 150𝑀
1≤𝑖≤𝑚
010%20%30%40%50%00.20.40.60.81PercentageofusersthatverifyvnFailureprobabilityρc=1c=5c=10c=50c=100010%20%30%40%50%00.20.40.60.81PercentageofusersthatverifyvnFailureprobabilityρτ=0τ=1τ=5τ=10τ=2002%4%6%8%10%00.20.40.60.81PercentageofusersthatverifyvnFailureprobabilityρn=10Kn=100Kn=1Mn=10Mn=150MSession 12D: Decentralized Cryptographic Protocols CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea3476We can see that the complexity of tree generation is linear in the
number of nodes in the SMT which varies by the distribution of
leaf nodes. In the best case, when users take up a consecutive range
of leaves and are positioned next to each other, the total number
of nodes is roughly 2𝑛 + 2𝐻. In the worst case, when users take up
the whole range of leaves and each consecutive pair has the same
largest distance, there are approximately 2𝑛 · (1 + 𝐻 − log 𝑛) nodes.
When 𝑛 = 1𝑀 and 𝐻 = 50, it takes about half an hour to generate
the whole tree. Considering the frequency of generating SMTs,
which is per day for COVID cases, and per year for solvency and