```  
postgres@digoal-> pg_controldata |grep block  
Database block size:                  8192  
WAL block size:                       8192  
```  
我们可以使用stap来跟踪是否调用pg_fsync，如果你要观察backend process主动刷clog 脏页，可以把checkpoint间隔开大，同时把clog shared buffer pages。你就会观察到backend process主动刷clog 脏页。  
```  
Size  
CLOGShmemBuffers(void)  
{  
	return Min(32, Max(4, NBuffers / 512));  
}  
```  
跟踪  
src/backend/access/transam/slru.c  
```  
SlruPhysicalWritePage  
......  
                SlruFileName(ctl, path, segno);  
                fd = OpenTransientFile(path, O_RDWR | O_CREAT | PG_BINARY,  
                                                           S_IRUSR | S_IWUSR);  
......  
src/backend/storage/file/fd.c  
OpenTransientFile  
pg_fsync(fd)  
```  
stap脚本  
```  
[root@digoal ~]# cat trc.stp   
global f_start[999999]  
probe process("/opt/pgsql/bin/postgres").function("SlruPhysicalWritePage@/opt/soft_bak/postgresql-9.4.4/src/backend/access/transam/slru.c").call {   
   f_start[execname(), pid(), tid(), cpu()] = gettimeofday_ms()  
   printf("%s  time:%d, pp:%s\n", thread_indent(1), f_start[execname(), pid(), tid(), cpu()], pp() )  
}  
probe process("/opt/pgsql/bin/postgres").function("SlruPhysicalWritePage@/opt/soft_bak/postgresql-9.4.4/src/backend/access/transam/slru.c").return {  
  t=gettimeofday_ms()  
  a=execname()  
  b=cpu()  
  c=pid()  
  d=pp()  
  e=tid()  
  if (f_start[a,c,e,b]) {  
  printf("%s  time:%d, pp:%s\n", thread_indent(1), f_start[execname(), pid(), tid(), cpu()], pp() )  
}  
probe process("/opt/pgsql/bin/postgres").function("OpenTransientFile@/opt/soft_bak/postgresql-9.4.4/src/backend/storage/file/fd.c").return {  
  t=gettimeofday_ms()  
  a=execname()  
  b=cpu()  
  c=pid()  
  d=pp()  
  e=tid()  
  if (f_start[a,c,e,b]) {  
  printf("%s  time:%d, pp:%s\n", thread_indent(1), f_start[execname(), pid(), tid(), cpu()], pp() )  
}  
probe process("/opt/pgsql/bin/postgres").function("pg_fsync@/opt/soft_bak/postgresql-9.4.4/src/backend/storage/file/fd.c").return {  
  t=gettimeofday_ms()  
  a=execname()  
  b=cpu()  
  c=pid()  
  d=pp()  
  e=tid()  
  if (f_start[a,c,e,b]) {  
  printf("%s  cat 7.sql  
select txid_current();  
postgres@digoal-> pgbench -M prepared -n -r -P 1 -f ./7.sql -c 1 -j 1 -T 100000  
```  
约每秒32K左右的请求。  
```  
progress: 240.0 s, 31164.4 tps, lat 0.031 ms stddev 0.183  
progress: 241.0 s, 33243.3 tps, lat 0.029 ms stddev 0.127  
progress: 242.0 s, 32567.3 tps, lat 0.030 ms stddev 0.179  
progress: 243.0 s, 33656.6 tps, lat 0.029 ms stddev 0.038  
progress: 244.0 s, 33948.1 tps, lat 0.029 ms stddev 0.021  
progress: 245.0 s, 32996.8 tps, lat 0.030 ms stddev 0.046  
progress: 246.0 s, 34156.7 tps, lat 0.029 ms stddev 0.015  
progress: 247.0 s, 33259.5 tps, lat 0.029 ms stddev 0.074  
progress: 248.0 s, 32979.6 tps, lat 0.030 ms stddev 0.043  
progress: 249.0 s, 32892.6 tps, lat 0.030 ms stddev 0.039  
progress: 250.0 s, 33090.7 tps, lat 0.029 ms stddev 0.020  
progress: 251.0 s, 33238.3 tps, lat 0.029 ms stddev 0.017  
progress: 252.0 s, 32341.3 tps, lat 0.030 ms stddev 0.045  
progress: 253.0 s, 31999.0 tps, lat 0.030 ms stddev 0.167  
progress: 254.0 s, 33332.6 tps, lat 0.029 ms stddev 0.056  
progress: 255.0 s, 30394.6 tps, lat 0.032 ms stddev 0.027  
progress: 256.0 s, 31862.7 tps, lat 0.031 ms stddev 0.023  
progress: 257.0 s, 31574.0 tps, lat 0.031 ms stddev 0.112  
```  
跟踪backend process  
```  
postgres@digoal-> ps -ewf|grep postgres  
postgres  2921  1883 29 09:37 pts/1    00:00:05 pgbench -M prepared -n -r -P 1 -f ./7.sql -c 1 -j 1 -T 100000  
postgres  2924  1841 66 09:37 ?        00:00:13 postgres: postgres postgres [local] SELECT  
[root@digoal ~]# stap -vp 5 -DMAXSKIPPED=9999999 -DSTP_NO_OVERLOAD -DMAXTRYLOCK=100 ./trc.stp -x 2924 >./stap.log 2>&1  
```  
从日志中抽取pg_clog相关的跟踪结果。  
```       
     0 postgres(2924): -> time:1441503927731, pp:process("/opt/pgsql9.4.4/bin/postgres").function("SlruPhysicalWritePage@/opt/soft_bak/postgresql-9.4.4/src/backend/access/transam/slru.c:699").call, par:ctl={.shared=0x7f74a9fe39c0, .do_fsync='\001', .PagePrecedes=0x4b1960, .Dir="pg_clog"} pageno=12350 slotno=10 fdata=ERROR  
    31 postgres(2924): -> time:1441503927731, pp:process("/opt/pgsql9.4.4/bin/postgres").function("OpenTransientFile@/opt/soft_bak/postgresql-9.4.4/src/backend/storage/file/fd.c:1710").call, par:fileName="pg_clog/0181" fileFlags=66 fileMode=384  
    53 postgres(2924):  time:1441503927731, pp:process("/opt/pgsql9.4.4/bin/postgres").function("pg_fsync@/opt/soft_bak/postgresql-9.4.4/src/backend/storage/file/fd.c:315").call, par:fd=14  
  1096 postgres(2924):  time:1441503928836, pp:process("/opt/pgsql9.4.4/bin/postgres").function("SlruPhysicalWritePage@/opt/soft_bak/postgresql-9.4.4/src/backend/access/transam/slru.c:699").call, par:ctl={.shared=0x7f74a9fe39c0, .do_fsync='\001', .PagePrecedes=0x4b1960, .Dir="pg_clog"} pageno=12351 slotno=11 fdata=ERROR  
1105329 postgres(2924): -> time:1441503928836, pp:process("/opt/pgsql9.4.4/bin/postgres").function("OpenTransientFile@/opt/soft_bak/postgresql-9.4.4/src/backend/storage/file/fd.c:1710").call, par:fileName="pg_clog/0181" fileFlags=66 fileMode=384  
1105348 postgres(2924):  time:1441503928836, pp:process("/opt/pgsql9.4.4/bin/postgres").function("pg_fsync@/opt/soft_bak/postgresql-9.4.4/src/backend/storage/file/fd.c:315").call, par:fd=14  
1106440 postgres(2924):  time:1441503929819, pp:process("/opt/pgsql9.4.4/bin/postgres").function("SlruPhysicalWritePage@/opt/soft_bak/postgresql-9.4.4/src/backend/access/transam/slru.c:699").call, par:ctl={.shared=0x7f74a9fe39c0, .do_fsync='\001', .PagePrecedes=0x4b1960, .Dir="pg_clog"} pageno=12352 slotno=12 fdata=ERROR  
2087917 postgres(2924): -> time:1441503929819, pp:process("/opt/pgsql9.4.4/bin/postgres").function("OpenTransientFile@/opt/soft_bak/postgresql-9.4.4/src/backend/storage/file/fd.c:1710").call, par:fileName="pg_clog/0182" fileFlags=66 fileMode=384  
2087958 postgres(2924):  time:1441503929819, pp:process("/opt/pgsql9.4.4/bin/postgres").function("pg_fsync@/opt/soft_bak/postgresql-9.4.4/src/backend/storage/file/fd.c:315").call, par:fd=14  
2089250 postgres(2924): <- time:1, pp:process("/opt/pgsql9.4.4/bin/postgres").function("pg_fsync@/opt/soft_bak/postgresql-9.4.4/src/backend/storage/file/fd.c:315").return, par:0  
2089265 postgres(2924): <- time:1, pp:process("/opt/pgsql9.4.4/bin/postgres").function("SlruPhysicalWritePage@/opt/soft_bak/postgresql-9.4.4/src/backend/access/transam/slru.c:699").return, par:'\001'  
```  
每隔1秒左右会产生一次fsync。  
```  
postgres=# select 1441503928836-1441503927731;  
 ?column?   
----------  
     1105  
(1 row)  
postgres=# select 1441503929819-1441503928836;  
 ?column?   
----------  
      983  
(1 row)  
```  
前面pgbench的输出看到每秒产生约32000个事务，刚好等于一个clog页的事务数(本例数据块大小为8KB)。  
(每个事务需要2个比特位，每个字节存储4个事务信息)  
```  
8192*4=32768  
```  
如果你需要观察backend process不刷clog buffer脏页的情况。可以把checkpoint 间隔改小，或者手动执行checkpoint，同时还需要把clog buffer pages改大，例如：  
```  
Size  
CLOGShmemBuffers(void)  
{  
	return Min(1024, Max(4, NBuffers / 2));  
}  
```  
使用同样的stap脚本，你就观察不到backend process主动刷clog dirty page了。  
通过以上分析，如果你发现backend process频繁的clog，可以采取一些优化手段。  
1\. 因为每次扩展pg_clog文件后，文件大小都会发生变化，此时如果backend process调用pg_fdatasync也会写文件系统metadata journal（以EXT4为例，假设mount参数data不等于writeback），这个操作是整个文件系统串行的，容易产生堵塞。  
所以backend process挑选clog page时，不选择最近的page number可以起到一定的效果，（最好是不选择最近的clog file中的pages）。  
另一种方法是先调用sync_file_range, SYNC_FILE_RANGE_WAIT_BEFORE | SYNC_FILE_RANGE_WRITE | SYNC_FILE_RANGE_WAIT_AFTER，它不需要写metadata。将文件写入后再调用pg_fsync。减少等待data fsync的时间。  
2\. pg_clog文件预分配，目前pg_clog单个文件的大小是由CLOGShmemBuffers决定的，为BLOCKSZ的32倍。可以尝试预分配这个文件，而不是每次都扩展，改变它的大小。  
3\. 延迟backend process 的 fsync请求到checkpoint处理。  
## 参考  
https://wiki.postgresql.org/wiki/Hint_Bits  
[《除了xlog，哪些操作可能还需要fsync ?》](../201509/20150904_01.md)    
src/backend/access/transam/varsup.c  
src/backend/access/transam/clog.c  
src/backend/access/transam/slru.c  
src/include/access/slru.h  
src/backend/access/transam/subtrans.c  
src/backend/storage/file/fd.c  
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")