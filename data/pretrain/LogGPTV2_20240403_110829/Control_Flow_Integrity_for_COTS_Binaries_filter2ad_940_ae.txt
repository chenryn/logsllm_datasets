remote server and copy a large ﬁle to/from the server.
7.2 CFI Effectiveness Evaluation
Figure 8 compares the AIR metric for bin-CFI with
strict-CFI, reloc-CFI, bundle-CFI and instr-CFI. To cal-
culate AIR of reloc-CFI, we recompiled SPEC2006 pro-
grams using “-g” and a linker option “-Wl,-emit-relocs”
to retain all the relocations in executables. We can now
calculate AIR from the description of reloc-CFI in Sec-
tion 4.2 and Deﬁnition 1.
To calculate AIR for bundle-CFI, we recompiled
SPEC2006 using the Native Client provided gcc and
g++ compilers. Since bundle-CFI restricts ICF targets to
32-byte boundaries, 31/32 of the compiled binary code
is eliminated as ICF targets. However, the AIR num-
ber is smaller because the base is the original program
size; programs compiled using Native Client tool-chain
are larger due to reasons such as the need to introduce
padding to align indirect targets at 32-byte boundaries.
Bin
CFI
Bundle
CFI
Instr
CFI
Name
Reloc
CFI
Strict
CFI
98.49% 98.44% 97.89% 95.41% 67.33%
perlbench
99.55% 99.49% 99.37% 95.65% 78.59%
bzip2
98.73% 98.71% 98.34% 95.86% 80.63%
gcc
99.47% 99.37% 99.25% 95.91% 79.35%
mcf
99.40% 99.40% 99.20% 97.75% 89.08%
gobmk
98.90% 98.87% 98.61% 95.85% 79.01%
hmmer
99.32% 99.30% 99.10% 96.22% 83.18%
sjeng
libquantum 99.14% 99.07% 98.89% 95.96% 76.53%
99.64% 99.60% 99.52% 96.25% 80.71%
h264ref
98.26% 98.08% 97.68% 95.72% 82.03%
omnetpp
99.18% 99.13% 98.95% 96.02% 78.00%
astar
98.89% 98.86% 98.65% 96.03% 79.74%
milc
99.65% 99.64% 99.59% 95.81% 76.37%
namd
99.19% 99.10% 98.86% 95.50% 77.37%
soplex
99.01% 98.99% 98.67% 95.87% 78.03%
povray
99.60% 99.50% 99.46% 96.79% 80.92%
lbm
98.83% 98.80% 98.64% 96.06% 80.75%
sphinx3
99.13% 99.08% 98.86% 96.04% 79.27%
average
Figure 8: AIR metrics for SPEC CPU 2006.
7.3 Security Evaluation
7.3.1 Control-Flow Hijack Attacks
To evaluate control ﬂow hijack defense, we used the
RIPE [45] test suite. RIPE is a benchmark consisting
of 850 distinct exploits including code injection, return-
to-libc and ROP attacks. RIPE illustrated these attacks
by building vulnerabilities into a small program. Ex-
USENIX Association  
22nd USENIX Security Symposium  347
11
Original
CFI
DEP disabled DEP enabled
140
90
520
90
Figure 9: Security Evaluation using RIPE
ploit code is also built into this program, so some of the
challenges of developing exploits, e.g., knowing the right
jump addresses, are not present. As such, techniques
such as ASLR have no impact on RIPE. So, the only
change we can experiment with is that of enabling or dis-
abling DEP.
Originally, on Ubuntu 11.10 platform, 520 attacks
survive with data execution prevention (DEP) disabled.
With DEP enabled, 140 attacks survive. All of these at-
tacks are return-to-libc attacks.
The 2nd row in Figure 9 shows bin-CFI could defeat
430 attacks including 380 code injection attacks and 50
return-to-libc attacks, even when DEP is disabled.
In
both scenarios, when DEP is enabled or disabled, how-
ever there are 90 function pointer overwrite attacks that
survive in CFI.
Code injection attacks are defeated by CFI because
global data, stack and heap are not allowed targets of
ICF transfers. 50 out of 140 return-to-libc attacks are
defeated because they overﬂow return addresses and try
to redirect control ﬂow to the libc functions and violate
the policy of bin-CFI. Those attacks are defeated.
The function pointer overwrite attacks that succeed are
some what of an artifact of RIPE design that includes ex-
ploit code within the victim program. Since pointers to
exploit code are already taken in the program, they are
identiﬁed as legitimate targets and permitted by our ap-
proach. If the same attacks were to be carried out against
real programs, only a subset of them will succeed: those
that overwrite function pointers with pointers to other
local functions.
In this subset of cases, previous CFI
implementations (although not necessarily their formu-
lations) would fail too, as they too permit any indirect
call to reach any function whose address is taken.
7.3.2 ROP Attacks
We use the tool ROPGadget-v3.3[35], an ROP gadget
generator/compiler, as our testing tool. It scans binaries
to ﬁnd useful gadgets for ROP attacks.
Figure 10 shows that CFI enforcement is effective, re-
sulting in the elimination of the vast majority (93%) of
gadgets in the original program. Moreover, there is little
diversity in the gadgets found — the tool was able to ﬁnd
only the following gadgets:
• mov constant, %eax; ret
• add offset, %esp; pop %ebx; ret
• add offset, %esp; ret
(32.26%)
(27.42%)
(19.35%)
(14.52%)
• mov (%esp), %ebx; ret
(5.65%)
• xor %eax, %eax; ret
(0.81%)
• pop %edx; pop %ecx; pop %ebx; ret
There is little variety in these gadgets. Among other
missing features, note the complete lack of useful arith-
metic operations in the identiﬁed gadgets. As a result,
the tool was unable to build even a single exploit using
these gadgets
Name
Reloc
CFI
Strict
CFI
Bin
CFI
Instr
CFI
96.62% 96.24% 93.23% 58.65%
perlbench
97.78% 95.56% 93.33% 44.44%
bzip2
97.69% 97.69% 91.42% 66.67%
gcc
95.45% 90.91% 90.91% 36.36%
mcf
98.84% 98.27% 97.69% 70.52%
gobmk
97.00% 96.00% 96.00% 58.00%
hmmer
sjeng
92.75% 92.75% 91.30% 47.83%
libquantum 93.18% 90.91% 86.36% 40.91%
98.26% 97.39% 96.52% 60.87%
h264ref
97.12% 97.12% 93.42% 74.07%
omnetpp
95.35% 93.02% 93.02% 46.51%
astar
95.77% 94.37% 90.14% 57.75%
milc
namd
94.87% 92.31% 92.31% 53.85%
94.64% 93.75% 93.75% 54.46%
soplex
96.75% 96.75% 95.45% 61.69%
povray
94.12% 88.24% 88.24% 23.53%
lbm
95.00% 93.75% 92.50% 52.50%
sphinx3
average
95.95% 94.41% 92.68% 53.45%
Figure 10: Gadget elimination in different CFI imple-
mentation
7.4 Performance Evaluation
Our testbed consists of an Intel core-i5 2410m CPU with
4GB memory, running Ubuntu 11.10 (32-bit version),
with glibc version 2.13. We used the SPEC 2006 CPU
benchmark to evaluate both the runtime overhead and
space overhead.
7.4.1 Runtime Overhead
Figure 11 shows the runtime overheads of CFI enforce-
ment on SPEC CPU 2006 benchmarks. The average
overhead for C programs is 4.29%. Due to C++ excep-
tion handling, VT.2 (Section 6.3) cannot be applied to
C++ programs. As a result, the overhead for C++ pro-
grams increases to an average of 8.54%. omnetpp, so-
plex, and povray are particular contributors to this in-
creased overhead. One way to bring these overheads
down (to match the overhead for C-programs) is to up-
date the exception handling metadata to use code ad-
dresses within instrumented code.
7.4.2 Space and Memory Overhead
Our instrumentation introduces a new code section that
is on average 1.2 times the original code size. The new
348  22nd USENIX Security Symposium 
USENIX Association
12
ysis. These attacks could be mitigated by further tight-
ening the policy for returns, improving the precision of
static analysis, or both. We point out that even without
these improvements, bin-CFI degrades return-to-libc at-
tacks in much the same way as it degrades ROP attacks:
it reduces the number of possible functions that can be
used in an attack.
8 Related Work
8.1 ROP Attacks and Defenses
Return Oriented Programing (ROP) [38] is a powerful
code reuse attack. It has become a very popular means
to carry out successful attacks in spite of DEP. Although
ROP was originally thought to be applicable primarily to
CISC processors such as the x86, subsequent work has
demonstrated their effectiveness on RISC architectures
as well [9]. ROP attacks can target user programs as well
as the kernel [19]. The introduction of JOP [10, 7] elim-
inates the need to use return instructions to effect ICF
transfers, thereby defeating defenses that rely on the use
of (repeated) returns [11, 14, 32].
Some of ROP defenses [31, 23] modify the code gen-
eration process to ensure that there are no useful gadgets
in a generated binary. As they work at the level of code
generation, they require source code. Rather than elim-
inating gadgets, some recent works [18, 43, 33] rely on
ﬁne-grained randomization that makes it difﬁcult to ﬁnd
the location of useful gadgets. Instruction Location Ran-
domization (ILR) [18] randomizes instruction locations,
thereby making ROP hard. A beneﬁt of their approach is
that they can randomize return addresses, which signiﬁ-
cantly reduces the number of valid ICF targets, as return
addresses constitute a majority of them. But this random-
ization can cause problems in large and complex binaries
where a return instruction may be used for purposes other
than returning from a call, e.g., PIC code data access, or
to implement context-switching-like functionality.
A drawback of ILR is high space overhead. Binary
Stirring (STIR) [43] solves this issue by randomizing ba-
sic blocks at load time using static rewriting. It achieves
better runtime performance and reasonable space over-
head. However, neither ILR nor Binary Stirring apply
their work on libraries or large binaries. [33] uses static
in-place randomization (IPR) to eliminate gadgets. The
runtime overhead is almost zero, though the effective-
ness depends on the target binary layout. In particular, a
signiﬁcant fraction of gadgets remain, thus limiting pro-
tection against ROP attacks.
While strong randomization could confuse attackers
at runtime, and further reduce the number of usable gad-
gets, we have refrained from adding randomization to our
technique for several reasons. First and foremost, we be-
lieve that one of principal reasons behind the success of
Figure 11: SPEC CPU2006 Benchmark Performance
data section introduced contains address translation ta-
ble for indirect branch instructions. In total, the space
overhead for bin-CFI is 139% over the original ﬁle size.
Note that although the ﬁle size has increased, execution
will be conﬁned to the new code. Except in the case of
programs that store read-only data in their code, other
programs don’t access their code even once. Hence the
runtime memory overhead is unaffected by the presence
of the original copy of code. Indeed, our measurements
showed a very small increase in resident memory use
(about 2.2% on average).
7.5 Limitations
Dynamic code. Since we rely on static transformation
of binaries, any usage of dynamic code such as just-in-
time compilation cannot be handled by bin-CFI. This
also applies to any binary that modiﬁes itself. These lim-
itations are shared by most previous implementations of
CFI.
Obfuscated code. Reliable static disassembly of obfus-
cated code is a challenging problem without satisfac-
tory solutions. However, obfuscation is typically used
on malware, whereas our target consists of benign (but
possibly vulnerable) programs.
Return-into-libc attack.
In general, CFI does not elim-
inate the threat of all return-to-libc attacks, a fact that
holds true in our implementation as well.
Most return-into-libc fall into one of the two follow-
ing types. The ﬁrst type chains a sequence of library
function calls, and relies on the semantics of these func-
tions to perform attacks [28]. The second type relies
on the side effects of library functions to realize Turing-
complete ROP [41]. Both types rely heavily on returning
to exported functions in glibc, and hence are defeated by
bin-CFI. (Note that exported functions are excluded from
allowable return targets by our policy.) However, it may
be possible to construct return-to-libc attacks that make
use of code pointers in glibc (or other shared libraries), or
more generally, any address computed by our static anal-
USENIX Association  
22nd USENIX Security Symposium  349
13
400.perlbench401.bzip2403.gcc429.mcf445.gobmk456.hmmer458.sjeng462.libquantum464.h264ref471.omnetpp473.astar433.milc444.namd450.soplex453.povray470.lbm482.sphinx3average-20.00%-10.00%0.00%10.00%20.00%30.00%40.00%50.00%CFI is that it provides deterministic protection, thus lay-
ing a solid foundation for other protection mechanisms
such as SFI or policy enforcement on untrusted code.
Second, randomization defenses are already widely de-
ployed in the form of ASLR and stack cookies. To the
extent their randomization isn’t defeated, they can pro-