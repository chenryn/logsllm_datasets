title:Retaining sandbox containment despite bugs in privileged memory-safe
code
author:Justin Cappos and
Armon Dadgar and
Jeff Rasley and
Justin Samuel and
Ivan Beschastnikh and
Cosmin Barsan and
Arvind Krishnamurthy and
Thomas E. Anderson
Retaining Sandbox Containment Despite Bugs in
Privileged Memory-Safe Code
Justin Cappos, Armon Dadgar, Jeff Rasley, Justin Samuel, Ivan Beschastnikh,
Cosmin Barsan, Arvind Krishnamurthy, Thomas Anderson
Department of Computer Science and Engineering
{justinc,armond,jeffra45,jsamuel,ivan,cosminb,arvind,tom}@cs.washington.edu
University of Washington
Seattle, WA 98195
Abstract
Flaws in the standard libraries of secure sandboxes represent
a major security threat to billions of devices worldwide. The
standard libraries are hard to secure because they frequently
need to perform low-level operations that are forbidden in
untrusted application code. Existing designs have a single,
large trusted computing base that contains security checks
at the boundaries between trusted and untrusted code. Un-
fortunately, ﬂaws in the standard library often allow an at-
tacker to escape the security protections of the sandbox.
In this work, we construct a Python-based sandbox that
has a small, security-isolated kernel. Using a mechanism
called a security layer, we migrate privileged functionality
into memory-safe code on top of the sandbox kernel while re-
taining isolation. For example, signiﬁcant portions of mod-
ule import, ﬁle I/O, serialization, and network communica-
tion routines can be provided in security layers. By moving
these routines out of the kernel, we prevent attackers from
leveraging bugs in these routines to evade sandbox contain-
ment. We demonstrate the eﬀectiveness of our approach by
studying past bugs in Java’s standard libraries and show
that most of these bugs would likely be contained in our
sandbox.
Categories and Subject Descriptors
C.20 [General]: Security; D.4.6 [Security and Protec-
tion]: Security kernels
General Terms
Security, Languages
Keywords
Sandbox, Layering, Containment
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’10, October 4–8, 2010, Chicago, Illinois, USA.
Copyright 2010 ACM 978-1-4503-0244-9/10/10 ...$10.00.
1.
INTRODUCTION
Programming language sandboxes, such as Java, Sil-
verlight, JavaScript, and Flash, are ubiquitous. Such sand-
boxes have gained widespread adoption with web browsers,
within which they are used for untrusted code execution, to
safely host plug-ins, and to control application behavior on
closed platforms such as mobile phones. Despite the fact
that program containment is their primary goal, ﬂaws in
these sandboxes represent a major risk to computer secu-
rity [23].
A sandbox is divided into three components: the core lan-
guage interpreter, the standard libraries, and the untrusted
application code. The standard libraries contain routines
to perform ﬁle I/O, network communication, cryptography,
math, serialization, and other common functionality. These
libraries need to contain some native code, usually written
in C or C++, but many sandboxes follow security best prac-
tices [33] and implement the bulk of their standard libraries
in a memory-safe language like Java or C#. While ﬂaws
in native code pose an obvious risk [35, 54], many ﬂaws in
memory-safe code are also a threat [18, 12, 46, 47].
For example, in Java 1.4.2, the serialization methods of
the Calendar object had a security bug which was caused by
instantiating an object of a broader type than intended [12,
32]. This mistake allowed an attacker to deserialize a new se-
curity policy and use it to permanently elevate all privileges.
Despite the ﬂaw residing entirely in memory-safe code, this
allowed a malicious party to escape the sandbox and per-
form malicious actions, such as installing malware. This is
not an isolated incident; many major security vulnerabili-
ties in Java have been found in Java code instead of native
code [42].
In this work, we mitigate the impact of a bug in memory-
safe privileged standard libraries by isolating libraries from
each other and from the interpreter. Instead of relying on
a single monolithic trusted computing base (TCB), we con-
struct a small, self-contained sandbox kernel and place sensi-
tive portions of the standard libraries in isolated components
on top of it. For example, in our system the serialization li-
brary runs in an isolated component that has the same per-
missions as application code. Flaws in this library will not
help an attacker escape the sandbox.
Speciﬁcally, we construct standard libraries as a set of
isolated and contained security layers. Each security layer
is untrusted by its ancestor security layers, but is trusted
by its descendant security layers. The lowest security layer
212(with no ancestors) is called the sandbox kernel and is the
only portion of the libraries where a ﬂaw may allow an at-
tacker to escape the sandbox. At a high level, security layers
are similar to well-tested layering techniques used in prior
systems [19, 31]. This technique, however, has not gener-
ally been used in widely used web-based execution environ-
ments.
In the development of our sandbox, we created a
language called Repy, which is a subset of Python version
2.5.4. Repy provides isolation restrictions which are sim-
ilar to an object-capability language.
In addition to the
usual restrictions imposed by an object-capability language,
the boundary between two security layers is monitored by
an encasement library, which veriﬁes interface semantics at
runtime. This veriﬁcation prevents capability leaks and min-
imizes the risk of time-of-check-to-time-of-use (TOCTTOU)
bugs. As a result, security layers provide similar protection
to separate processes that communicate using remote pro-
cedure calls (RPC). However, the performance of a security
layer call is signiﬁcantly better than a local RPC invocation.
The contributions of this work are as follows:
• We design and implement an appropriate set of ab-
stractions for constructing strong, yet ﬂexible security
layers.
• We identify functionality that can be migrated out of
the kernel into higher security layers, thus reducing the
security impact of a bug in the sandbox code.
• We describe how a security layer is a natural mecha-
nism for adding customized security policies that are
transparent to an application.
• We evaluate the security and performance implications
of using security layers and discuss limitations and op-
timizations.
The remainder of this paper is organized as follows. Sec-
tion 2 illustrates ﬂaws and limitations of the standard li-
brary implementations in existing sandboxes in more detail.
In Section 3, we discuss the goals of our system and give
a brief overview of the architecture. Section 4 discusses
the construction of security layer functionality. Following
this, Section 5 describes how the functionality in standard
libraries is divided between the sandbox kernel and security
layers.
In Section 6, we present diﬀerent applications for
security layers based on our experience with a live deploy-
ment. We evaluate the performance of our security layer
implementation in Section 7. Relevant prior work is dis-
cussed in Section 8, and Section 9 concludes. Appendix A
details the Repy language that underlies this work.
2. BACKGROUND
In this section, we describe our threat model and examine
the popular Java sandbox execution environment in detail.
Our sandbox environment is constructed on top of Python
and thus is not directly comparable to Java. However, it is
useful to motivate the construction of a new sandbox by ex-
amining the techniques other sandboxes use to isolate priv-
ileged standard library code. As Java’s primary implemen-
tation is open source, we examine it in detail. Further, we
also found that Silverlight, and its open source implementa-
tion Moonlight, possess similar features including a single,
large TCB. Our work does not address faults in JavaScript,
Adobe Flash, or Google Native Client since their standard
library implementations are not memory-safe.
Figure 1: Java’s architecture, especially the stan-
dard libraries and their relationship to its single
TCB. There is no clearly deﬁned boundary between
the privileged and untrusted portions of the stan-
dard libraries. Dotted lines indicate possible call-
paths from user code into the TCB. From left to
right: (1) user code may directly call privileged li-
brary code in the TCB; (2) user code may call un-
privileged library code which may then call into the
TCB; (3) user calls may be subject to security pol-
icy, as determined by the invoked standard library
code in the TCB.
2.1 Threat Model
A process has a set of privileges provided by the operating
system, usually exposed as system calls. The primary secu-
rity goal of a sandbox is to restrict a program to some subset
of privileges, usually by exposing a set of functions that me-
diate access to the underlying operating system privileges.
The attacker’s goal is to obtain access to privileges that were
not intentionally exposed by the sandbox, thus escaping the
sandbox.
To attack a sandbox, we assume an attacker may run mul-
tiple programs in diﬀerent sandboxes on the same machine.
In addition, the attacker may use multiple threads to mod-
ify visible state or issue concurrent requests in an attempt
to trigger a race condition. An attacker may submit arbi-
trary code for execution and may pass data of any type the
interpreter allows to any visible calls. Once the code begins
executing, the attacker’s program can manipulate any object
in its namespace in any way that the interpreter allows.
Given the large amount of code in the standard library
for each sandbox, we assume that an attacker may have
knowledge of ﬂaws in this code. Our goal is to prevent bugs
in this code from allowing an attacker to escape the sandbox.
2.2 Learning from Java
Java developers implemented various security mechanisms
to allow the Java Virtual Machine (JVM) to be run as a
secure sandbox. For instance, Java code cannot perform
unsafe operations, such as modifying arbitrary memory lo-
cations, due to restrictions placed on it by the Bytecode
Veriﬁer [41] and the JVM. Java programs can, if allowed,
call directly into native C code, which may perform unsafe
operations, such as call system calls and modify arbitrary
memory locations, on their behalf. To provide isolation,
Java does not grant untrusted code with unmediated access
to native C code. Instead, the sandboxed code is typically
allowed to call some subset of the pre-existing native code
that is part of the standard libraries. Sensitive native func-
tions are often scoped to be less than public, and access to
them is mediated by public Java wrapper functions. Such
User CodeStandardLibrariesTCB BoundarySecurityPolicy123213wrapper functions will verify access and enforce a security
policy for its standard libraries, using a variety of security
components, such as the ClassLoader, SecurityManager, and
AccessController. Figure 1 overviews Java’s architecture.
However, Java’s TCB is much larger than native code and
the security policy. All of the Java code which mediates ac-
cess to sensitive native calls is also clearly a security risk.
However, the visibility of sensitive native calls extends much
further than functions that wrap calls. Java’s standard li-
braries are organized into packages that the programmer
may choose to import. The code is organized by function-
ality type, rather than privilege, so privileged code is con-
tained across many diﬀerent packages. Objects may contain
a mixture of privileged and unprivileged methods and data
members. The scope of an object’s data members, however,
must extend to at least the containing ﬁle (and sometimes
extends to the entire package). This grants untrusted code
direct access to sensitive native functions. To get an idea
of the scope of native code intermingling, we examined all
Java objects in Java 1.6.18 and found that there are about
1800 native method calls spread around 500 objects. Out of
the Java objects that have at least one native call, approx-
imately 350 restrict scope to at least one native method by
setting the visibility to private. This means that large por-
tions of Java’s standard libraries may perform actions that
should be restricted for security reasons.
To summarize, Java’s security model is such that a very
large amount of Java code must be correct in order to main-
tain security. This extends to complex components like
the ClassLoader, AccessController, and SecurityManager.
Based upon the scope of sensitive native code, the TCB
also extends to portions well beyond just the wrapping func-
tions in the standard libraries. Experience has shown that
if any of these pieces has a security ﬂaw, all of the protec-
tions of the sandbox may be compromised [48, 42]. Flaws in
the standard libraries of Java pose a signiﬁcant risk to 4.5
billion devices worldwide [30] despite considerable security
focus from both industry and academia.
3. GOALS AND OVERVIEW
The goal of this work is to ensure that a security failure in
the standard library code has minimal security impact. To
achieve this, our sandbox provides the vast majority of its
functionality in memory-safe library code where faults will
not result in an attacker escaping the sandbox. Of course,
it is unavoidable for our sandbox to have at least some priv-
ileged code to allow access to the operating system, but it
is possible to minimize the quantity and complexity of this
code. To realize this goal, we want to construct and organize
a set of libraries such that:
• The risk of compromise is minimized by moving library
functionality out of the kernel to the maximum prac-
tical extent.
• Custom security policy functionality exists entirely
outside of the kernel.
• It is trivial for a developer to prevent common bugs
such as capability leaks and race conditions.
• With our changes, libraries remain easy to develop and
to use.
As a basic building block for isolation, we constructed a
custom subset of Python called Repy that is similar to an
object-capability language (described in Appendix A). Our
sandbox is comprised of a small, trusted kernel, a set of re-
quired libraries, standard libraries, and user code as shown
in Figure 2. Each security layer obtains a set of capabili-
ties when it is instantiated by the security layer beneath it.
A security layer is isolated and may only interact through
the security-veriﬁed set of capabilities it is provided. A vul-
nerability in a security layer can at most allow the compro-
mise of the security layers it instantiated. Through such a
compromise the attacker cannot gain any capabilities that
are stronger than those already granted to the compromised
security layer. Since the sandbox kernel maintains contain-
ment over its descendants, only a vulnerability in the sand-
box kernel may lead to escape of the sandbox.
Our design allows much of the functionality that languages
usually provide to be executed with the same capabilities as
the untrusted user code. As we will describe in Section 5, we
can build signiﬁcant portions of functionality usually found