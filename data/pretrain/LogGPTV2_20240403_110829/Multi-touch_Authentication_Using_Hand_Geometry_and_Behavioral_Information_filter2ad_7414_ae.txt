i
v
i
−
+
v
v
j
j
||
1
||
1
For  user  i  and  user  j,  vi  and  vj  are  their  feature  vectors 
consisting of the 12 real features of hand geometry depicted 
in Figure 2. And ||vi||1 means the 1 norm of vector vi. For all 
144 subjects with recorded hand images, there are 10296 user 
pairs.  
We use the 4-finger TFST L swipe gesture to evaluate the 
resilience  to  zero-effort  attack.  The  authentication  model 
being attacked is a 3-NN classifier trained by 30 legitimate 
samples  with  selected  features.  The  experiment  was 
performed 20 times to account for the randomness. 
We calculate the Sim values for all user pairs in our dataset 
and simulate users in each pair attacking each other by using 
one user’s data to attack the other’s authentication model. We 
calculate  the  average  FAR  at  FRR=3%  for  user  pairs  with 
different Sim values. The results are shown in Table VI. When 
hand  similarity  information  was  not  considered (1st  row  in 
Table VI), the average FAR was 4.41% for the selected feature 
set.  For the  most  similar 59 pairs of  users  with  Sim  values 
higher than 0.98 (5th row in Table VI), the average FAR is 
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:28:02 UTC from IEEE Xplore.  Restrictions apply. 
TABLE VI. ZERO-EFFORT ATTACK AND HAND SIMILARITY (FARS ARE 
Avg. FAR 
(Physiological) 
CALCULATED AT FRR=3%) 
# of pairs  Avg. FAR 
(Selected) 
10296 
2793 
1309 
404 
59 
4.41 
4.64 
4.82 
4.92 
5.04 
5.60 
8.30 
9.01 
9.12 
9.33 
Similarity 
0 
0.95 
0.96 
0.97 
0.98 
5.04%.  The  difference  between  the  two  FARs  showed  that 
even with a similar hand geometry, the likelihood of breaking 
into an account via zero-effort attack is still not very high for 
authentication using TFST gestures. 
We  speculated  that  the  fusion  of  physiological  and 
behavioral features contributed to the resistance of zero-effort 
attack with similar handshapes. As shown in Table VI, for the 
pure physiological feature set, the FARs increased faster with 
hand similarity. 
B.  Smudge and Shoulder Surfing Attack 
Smudge attack [2] and shoulder surfing attack [1] are two 
types  of  common  attacks  in  which  an  attacker  manages  to 
obtain some knowledge of the authentication process of the 
legitimate user. In a smudge attack, attackers utilize the oily 
traces left on the screen as hints to pass the authentication. In 
a shoulder surfing attack, attackers watch the authentication 
process and mimic the behavior to pass the authentication. In 
this  subsection,  we  demonstrate 
that  TFST  gesture 
authentication  is  resilient  to  both  types  attacks  and  their 
combinations. 
  Experimental  Setup: We  recruited  another 20  students 
on campus as attackers to attack the 144 subjects in our dataset 
with recorded hand images. Each attacker attacked 10 victims. 
5  victims  have  the  most  similar  handshape  as  the  attacker, 
(Sim  values  with  the  attacker  are  the  highest).  The  other  5 
victims have handshapes that are not similar (Sim values with 
the attacker are among the lowest).  
  The  attackers  were  asked  to  try  their  best  to  mimic  the 
victims’ 4-finger TFST gestures to see if they are able to be 
accepted  by  the  authentication  model.  Each  attacker  is 
provided with two randomly selected multi-touch traces from 
each of the 10 victims to mimic. The attackers are allowed to 
practice as many times as they want and finally each attacker 
will generate 10 mimicry multi-touch traces for each genuine 
multi-touch trace provided. 
The  authentication  models  being  attacked  are  the  3-NN 
classifier trained by 30 legitimate samples and 100 legitimate 
samples respectively. The EERs are calculated according to 
the decisions made by the corresponding authentication model 
on all mimicry traces and legitimate traces not used in model 
training. The experiment was repeated 20 times to account for 
the randomness. 
Smudge  Attack:  To  evaluate  the  resilience  to  smudge 
attack, we drew the genuine multi-touch traces on the screen 
for  the  attacker  to  mimic.  This  corresponds  to  the  worst 
situation where the oily residuals are complete and clear and 
the attacker obtains the complete multi-touch trace. 
TABLE VII. EERS(%) OF SMUDGE ATTACK ON MODEL WITH 30-
SAMPLE TRAINING 
Type of Attack 
Zero-effort attack 
Similar-handshape 
smudge attack 
Dissimilar-handshape 
smudge attack 
Physiological 
Behavioral 
Selected 
4.06 
4.57 
2.53 
12.10 
11.84 
11.61 
3.02 
3.08 
1.99 
TABLE VIII. EERS(%) OF SMUDGE ATTACK ON MODEL WITH 100-
SAMPLE TRAINING 
Type of Attack 
Zero-effort attack 
Similar-handshape 
smudge attack 
Dissimilar-handshape 
smudge attack 
Physiological 
Behavioral 
Selected 
2.94 
3.16 
1.69 
9.95 
9.13 
8.66 
1.88 
2.00 
0.96 
The  EERs  are  shown  in  Table  VII  and  VIII  for  both 
smudge  attacks  with  similar  handshapes  and  dissimilar 
handshapes with regard to authentication models trained with 
different  feature  sets  and  different  legitimate  samples.  The 
baseline  was  the  zero-effort  attack  results  not  considering 
handshape similarity. From Tables VII and VIII, for smudge 
attack with similar handshapes, there are EER increases under 
the  physiological  models  compared  with  the  baseline.  The 
EER decreased with the behavioral models which may mean 
that the oily residues do not help the attacker to mimic the 
behavioral features. As a result, the EER under the selected 
combined  models  only  increases  slightly  from  3.02%  to 
3.08% with 30 sample training and from 1.88% to 2.00% with 
100 sample training. 
For smudge attack with dissimilar handshapes, the EERs 
are  significantly  decreased  even  with  the  physiological 
models compared with the baseline EERs. This showed that 
the  leaked  information  of  hand  geometry  cannot  help  an 
attacker  with  a  dissimilar  handshape  to  overcome  the 
fundamental difficulty of  hand  dissimilarity  when  attacking 
our  TFST  gesture  authentication  method.  We  have  similar 
results for the other two attacks with dissimilar handshapes. 
For space, we only present the results for attack with similar 
handshapes in the following experiments. 
The above results and analysis show that our method is 
resilient to smudge attacks with both similar and dissimilar 
handshapes. 
Shoulder Surfing Attack: To evaluate the resilience to 
shoulder surfing attack, we asked the attackers to watch an 
animation showing the movements of the victim’s fingers on 
the  screen  of  the  testing  device.  The  animation  accurately 
replicates the temporal information recorded in a mimicked 
multi-touch  trace.  The  attackers  are  allowed  watch  the 
animation as many times as they want. 
The  EERs  are  shown  in  Tables  IX  and  X  for  shoulder 
surfing  attacks  with  similar  handshapes  with  regard  to 
authentication models trained with different feature sets and 
different  legitimate  samples. The baseline  is  the  zero-effort 
367
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:28:02 UTC from IEEE Xplore.  Restrictions apply. 
TABLE IX. EERS(%) OF SHOULDER SURFING AND COMBINED ATTACK 
ON MODEL WITH 30-SAMPLE TRAINING 
Type of Attack 
Zero-effort 
Shoulder surfing  
Combined 
Physiological  Behavioral  Selected 
12.10 
12.88 
13.34 
3.02 
3.31 
3.67 
TABLE X. EERS(%) OF SHOULDER SURFING AND COMBINED ATTACK 
ON MODEL WITH 100-SAMPLE TRAINING 
4.06 
4.92 
5.20 
2.94 
3.61 
4.18 
Type of Attack 
Zero-effort 
Shoulder surfing  
Combined 
Physiological  Behavioral  Selected 
9.95 
10.18 
10.44 
1.88 
2.06 
2.27 
attack results not considering handshape similarity. 
Tables IX and X also show the results for the combined 
smudge  and  shoulder  surfing  attacks  in  the  row  named 
combined attack. This attack is similar to the shoulder surfing 
attack except that the multi-touch trace of a victim will be left 
on the screen when the animation is finished. This corresponds 
to the worst situation that the attacker knows information of 
both hand geometry and behavior. The EERs are also for the 
attacks  with  similar  handshapes.  In  Tables  IX  and  X,  the 
differences between EERs under attacks and baseline EERs 
exhibit the resilience of authentication with 4 finger L swipe 
against  shoulder  surfing  attacks.  Under  shoulder  surfing 
attack,  for  the  selected  combined  model  trained  with  30 
samples, the EER increases from the baseline value of 3.02% 
to 3.31%; while for the model trained with 100 samples, the 
EER  increases  from  the baseline  value of 1.88% to 2.06%. 
Under the more serious situations of the combined attacks of 
both smudge and shoulder surfing, the EERs are still not very 
high: 3.67% and 2.27% respectively. 
Recalling  that  all  attacks  are  examined  under  more 
difficult situations of attacking with similar handshapes, the 
above results demonstrate that our method has the resilience 
to both smudge attacks and shoulder surfing attacks. 
C.  Statistical attack 
Statistical attacks have been shown to be effective against 
behavior based authentication methods [31-33]. In [31],touch-
based authentication systems were attacked successfully using 
forgeries generated by a simple “Lego” robot driven by input 
gleaned from general population swiping statistics. 
  The  basic  idea  of  statistical  attack  is  to  estimate  the 
probability density functions (pdf) of features from a group of 
people  and  then  use  the  most  probable  feature  values  to 
generate the forgery. According to the attack method shown 
in [31-33], we developed Algorithm 1 to generate synthetic 
attack samples. The inputs of the algorithm are RealFeatures 
and NumberOfBins. RealFeatures is a matrix consisting of the 
feature  vectors  for  multi-touch  traces  generated  by  genuine 
users. Each column of RealFeatures is a feature vector for one 
multi-touch  trace.  Each  row  is  a  series  of  values  for  one 
feature.  In  the algorithm,  the feature  values  in  each row  of 
RealFeatures is “binned” to approximate the pdf of a feature. 
NumberOfBins controls the granularity of the approximation. 
ALGORITHM 1: Generating forged features for statistical attack 
Input: RealFeatures[ ]; //Population feature vectors 
Input: NumberOfBins; //Number of bins for each feature 
Output: ForgedFeatures[ ]; //Feature vectors used for attack 
NumberOfFeatures = NumberOfRows(RealFeatures); 
for i=1 to NumberOfFeatures 
do 
    BinnedFeatures[i] = Binning(RealFeatures[i], NumberOfBins); 
    //Generate bins according to RealFeatures[i] and NumberOfBins 
    KeyBin[i] = SortBinsByFrequency(BinnedFeatures[i]); 
    //Sort bins in descending order of frequency 
LowerBound[i],UpperBound[i] = GetBound(KeyBin[i]); 
    //get the bound of the first sorted bins 
    AttackFeatures[i] = uniform(LowerBound[i],UpperBound[i]); 
Return AttackFeatures[ ] 
Then the bin with the highest frequency is selected to generate 
a forged feature value for the output ForgedFeatures. 
  We  evaluated  the  effect  of  statistical  attacks  on  the 
authentication model built from 4 finger TFST gestures. We 
used all samples from the 161 subjects in our dataset as the 
input matrix of RealFeatures to investigate the worst situation 
where the attacker has the knowledge about the statistics of 
the  whole  population.  We  also  perform  a  search  for  the 
optimal parameter of NumberOfBins in the range from 10 to 
100 so that we have the best effect of attack. 
  Using  the  above  RealFeatures  and  NumberOfBins  as 
inputs to Algorithm 1, we generated 10000 synthetic feature 
vectors to attack the authentication models for each of the 161 
subjects  trained  with  30  and  100  legitimate  samples 
respectively.  To  account  for  randomness,  we  repeated  the 