title:PrivDPI: Privacy-Preserving Encrypted Traffic Inspection with Reusable
Obfuscated Rules
author:Jianting Ning and
Geong Sen Poh and
Jia-Chŉg Loh and
Jason Chia and
Ee-Chien Chang
PRI: Privacy Preserving Inspection of Encrypted Network Trafﬁc
Liron Schiff1
1 Tel Aviv University, Israel
Stefan Schmid2
2 Aalborg University, Denmark
Abstract—Trafﬁc inspection is a fundamental building block
of many security solutions today. For example, to prevent the
leakage or exﬁltration of conﬁdential insider information, as
well as to block malicious trafﬁc from entering the network,
most enterprises today operate intrusion detection and pre-
vention systems that inspect trafﬁc. However, the state-of-the-
art inspection systems do not reﬂect well the interests of the
different involved autonomous roles. For example, employees
in an enterprise, or a company outsourcing its network man-
agement to a specialized third party, may require that their
trafﬁc remains conﬁdential, even from the system administrator.
Moreover, the rules used by the intrusion detection system,
or more generally the conﬁguration of an online or ofﬂine
anomaly detection engine, may be provided by a third party,
e.g., a security research ﬁrm, and can hence constitute a critical
business asset which should be kept conﬁdential. Today, it is
often believed that accounting for these additional requirements
is impossible, as they contradict efﬁciency and effectiveness.
We in this paper explore a novel approach, called Privacy
Preserving Inspection (PRI), which provides a solution to
this problem, by preserving privacy of trafﬁc inspection and
conﬁdentiality of inspection rules and conﬁgurations, and e.g.,
also supports the ﬂexible installation of additional Data Leak
Prevention (DLP) rules speciﬁc to the company.
I. INTRODUCTION
The Internet has become a critical and indispensable
infrastructure for many organizations. At the same time, the
Internet constitutes a security threat. For example, web-based
services, such as email, are indispensable for communicating
with others either within or outside of an organization, but
introduce the risk of data exﬁltration.
Intrusion Detection Systems (IDS) as well as Intrusion
Prevention Systems (IPS) are frequently used today to defend
networks (or speciﬁc servers) from cyber attacks [21], [27]. In
particular, such systems can prevent exﬁltration of conﬁden-
tial insider information by blocking accidental or intentional
leakage, e.g., by searching for document conﬁdentiality
watermarks in the data transferred out of an enterprise
network. Such systems are also vital to control inbound
trafﬁc, and e.g., to detect if packets from a compromised
sender contain an attack, employ parental ﬁltering to prevent
children from accessing adult material, etc. [25] Indeed,
many cyber attacks today are carried out remotely, exploiting
vulnerabilities in network components or applications, or
tempting naive users to download malware and install them
on their PCs.
To provide such functionality, these systems rely on trafﬁc
inspection: they allow the deﬁnition of conﬁguration rules
which deﬁne known attack patterns, indicators for attacks, or
trafﬁc anomalies, and which are matched against the packet
header and payload. If rules are matched, alerts are generated,
and/or, in case of prevention systems or ﬁrewalls, packets are
dropped. The corresponding rules can either be distributed by
a local support team, by a third party (for instance a security
research ﬁrm), by the network operator, or a combination
thereof: third party provided rules can be complemented with
organization-speciﬁc asset leakage indicators, coming from
Data Leakage Prevention (DLP) systems.
While today’s intrusion detection and prevention systems
typically perform well for unencrypted trafﬁc, they struggle
with encrypted trafﬁc, resulting in false negatives or poor
performance. As a workaround, in practice today, the secure
and encrypted channel from or to the Internet is often
terminated at a proxy, which essentially mounts some kind
of “man-in-the-middle-attack”. While this solution ensures
an effective detection and prevention, it comes at the price
that the privacy of user trafﬁc (e.g., emails) is undermined.
In fact, even in the case where communication was already
unencrypted anyway, performing deep packet inspection (not
for the purpose of forwarding) can be seen as privacy
violation. Indeed, users and clients have criticized this
approach and expressed worry, e.g., that the private logged
data is given to marketers [25], [29], [31].
Privacy-preserving intrusion detection may not only be
desirable and relevant in the context of enterprise networks,
but is also gaining in importance in the light of today’s trend
to outsource the network management, including security
aspects, to third parties [24]. For example, the management of
third-party networks can be a lucrative business for Internet
Service Providers (ISPs). At the same time, for customers
running security critical businesses (for example banks), it
is important that the privacy of trafﬁc be preserved.
We in this paper however observe another conﬁdentiality
issue of today’s solutions: it concerns the conﬁdentiality of
the inspection logic itself. For example, the development
and maintenance of effective intrusion detection rules is
challenging, and especially small enterprises do not have
the expertise and time to deﬁne the most effective rules
and constantly follow the news. This constitutes a business
opportunity for third parties: a company specialized into
security research can take over the responsibility to deﬁne
and maintain a good rule set. However, such a business
model also introduces new requirements. In particular, a
third party company may not be willing to share its rules,
or more generally conﬁgurations of (online or ofﬂine)
anomaly detection systems, with the customer: these rules and
conﬁgurations are an intellectual property which constitute
an essential asset of the business model.
At ﬁrst sight, it may appear that the requirements are
contradicting: First, it seems unavoidable that an intrusion
detection or prevention system, which for efﬁciency and
effectiveness reasons needs to inspect
the trafﬁc in an
unencrypted form, may leak information about the user
trafﬁc. Second, it also seems unavoidable that a system
administrator operating a system based on the rules of a
third party company, can see the rules.
A. Contribution
We identify the different autonomous roles involved
in a trafﬁc inspection system, including intrusion detec-
tion/prevention systems, but also more sophisticated online or
ofﬂine anomaly detection systems as they may for example
be required to deal with insider threats. We then explore the
feasibility of providing a system which meets these require-
ments, respecting the autonomy of the different involved
stakeholders, without introducing new threats coming, e.g.,
from insiders.
In particular, we present a Privacy-Preserving Intrusion
detection/prevention system, short PRI (fruit in Hebrew),
which decouples the different roles, and hence signiﬁcantly
reduces the required trust assumptions. PRI leverages the
hardware protection of architectures like Intel SGX [30] to
defend against insiders or system administrators aiming to
break the conﬁdentiality. A distinguishing feature of PRI is
the simple and cheap deployment: a single trusted hardware
component is sufﬁcient. On the user side, only a simple
software update is required.
B. Paper Organization
The remainder of this paper is organized as follows. In
Section II, we present a model which identiﬁes the different
roles/stakeholders and the resulting requirements for the
trafﬁc inspection system. After providing the necessary back-
ground (Section III), based on these requirements, Section IV
describes our proposed architecture PRI which meets these
requirements. We discuss use cases in Section V and review
related work in Section VI, and we conclude our contribution
in Section VII. A small demo of our system is available online
at https://www.youtube.com/watch?v=b54unY8iGs0.
II. ROLES AND REQUIREMENTS
In the following, we ﬁrst present the different roles and
discuss their objectives. Based on this model, we then derive
security goals. Note that for ease of presentation, in the
following, we will mostly focus on intrusion detection. How-
ever, our approach can easily be generalized to prevention
or conﬁguration-based systems, as we will elaborate more
later in this paper.
they want
We in this paper distinguish between the following roles:
• The administrators: The administrators are responsible
for ensuring the availability and security of the network.
In particular,
the leakage of
sensitive insider information, and also prevent malicious
trafﬁc entering the network from the outside. Besides
relying on up-to-date security rules possibly provided
by an external company, administrators may also want
to be able to add their own Data Leak Prevention (DLP)
rules, speciﬁc to their organization.
to prevent
• The users: The term user will generally refer to the
communication endpoints. In particular, we will usually
assume that one endpoint is inside an enterprise (an
insider) while the other is outside (an outsider); however,
also trafﬁc between two insiders can be subject to
inspection. We assume that while users proﬁt from
a secure environment and the detection of undesired
inbound and outbound trafﬁc, they also desire a high
communication performance as well as conﬁdentiality
of their trafﬁc.
• The rules (conﬁguration) provider: The rules for
the intrusion detection system (or more generally the
conﬁgurations for a trafﬁc inspection system based on
some open-source logic/engine) may be provided by an
external security company specialized into developing
and maintaining high-quality rules. The rules provider
may desire that its rules remain conﬁdential.
Given our roles and their objectives, we identify the
following requirements:
R1 Efﬁcient and effective inspection: The inspection
system must ensure to the administrators that relevant
events and attacks will be detected successfully and
fast.
R2 Privacy-preserving trafﬁc inspection: We want to en-
sure to the users that neither the network administrator
nor the rule/conﬁguration provider should be able to
see the trafﬁc.
R3 Conﬁdentiality of rules: We want to ensure that the
rules are kept conﬁdential and are not leaked to the
other roles.
This paper is motivated by the question whether it is
possible to design an architecture which meets the different
goals of the different roles, maintaining their autonomy.
Indeed, designing such a system seems challenging:
• Today’s proxy solutions do not meet the requirements
R2 and R3: a proxy server can be exploited by the
administrators to learn about the unencrypted trafﬁc.
Rather, we want to develop a solution which does not
allow the administrators to conﬁgure the inspection
system in a way that allows them to learn details about
the trafﬁc which are not security relevant.
• Networks usually operate at very high rates: cryp-
tographic schemes based on fully homomorphic or
functional encryption [9], [11], [13] are slow and can de-
crease network rates by many orders of magnitude [12],
violating requirement R1.
trafﬁc without
At a ﬁrst glance, the requirements seem to contradict: a
system may hardly be able to efﬁciently and effectively
inspect
introducing opportunities to the
administrator to see the trafﬁc and used rules. However,
as we will see in the following, there do exist solutions to
satisfy these seemingly conﬂicting properties.
III. BACKGROUND
Before presenting our solution, we provide some back-
ground which is necessary to undertand our solution. In
particular, we revisit IDS systems and give an introduction
to SGX.
A. Trafﬁc Inspection Systems
Almost all cyber security breaches involve transmissions
of trafﬁc over a network. The standard approach to secure
transmissions is to inspect trafﬁc, checking whether the trafﬁc
carries the attack (e.g., a malware) or its outcome (e.g., a
stolen digital asset). For this purpose, organizations deploy
packet inspection systems in their networks, conﬁguring
them with known attack indicators, in the case of Intrusion
Detection/Prevention Systems (IDS/IPS), and with (possibly
organization-speciﬁc) asset leakage indicators in the case of
Data Leakage Prevention (DLP) systems.
All inspection systems essentially search for the conﬁgured
indicators inside the trafﬁc, where indicators can be based on
exact match strings, regular expressions, statistical properties,
and more. Inspection of trafﬁc in these systems usually
includes the inspection of the packet payload, i.e., accessing
the application layer data.
A simpler type of inspection that considers only the
packet headers (up to the transport layer) is often performed
by ﬁrewalls. A ﬁrewall is a network security system that
monitors and controls the incoming and outgoing network
trafﬁc and may also include IDS/IPS capabilities. Firewalls
can be considered as a barrier between a trusted, secure
internal network and another outside network, such as the
Internet, thereby mitigating attacks in the early stage of
penetration. Firewalls can also be host based, operating on
and defending a single machine.
Inspection systems are also used to detect
insider
threats [7], for example by analyzing conﬁdential documents
in private communications, possibly enhanced with water-
marking techniques [26].
Web security today is usually realized with HTTPS, which
relies on the Transport Layer Security (TLS) a.k.a. Secure
Sockets Layer (SSL) protocol. TLS/SSL provides conﬁden-
tiality, integrity and authentication of data in transit. The
protocol offers encryption, hash functions or message digests,
and digital signatures.
Encrypted trafﬁc constitutes a great challenge to packet
inspection systems as it hides the payload content from