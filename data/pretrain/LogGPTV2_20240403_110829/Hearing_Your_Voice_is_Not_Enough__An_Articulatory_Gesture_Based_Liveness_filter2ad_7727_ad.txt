and the earbuds. In particular, a DELL AC411 loudspeaker, the
build-in speaker of Note5 and a pair of Samsung earbud are used to
playback the participants’ voice samples in front of the smartphone
that performing voice authentication. Specifically, each form of
these speakers replays voice samples from 10 participants, and the
build-in speaker/earbud and the loudspeaker contributes 3 and 4
trials for each of the 10 passphrases respectively, amounting to
1000 replay attacks. All replay attacks are captured by an identical
Phone placed in front of mouthPhone placed by ear00.020.040.060.080.1False Accept Rate(%)60708090100True Accept Rate(%)Combined FeatureEnergy based FeatureFrequency based Feature80859095100Accuracy(%)Energybased FeatureFrequencybased FeatureCombinedFeatureSession A2:  Human AuthenticationCCS’17, October 30-November 3, 2017, Dallas, TX, USA65(a) Accuracy
(a) Accuracy
(b) EER
(b) EER
Figure 16: Replay Attacks: Accuracy and EER.
Figure 17: Mimicry Attacks: Accuracy and EER.
phone with the same holding position that the participants used
for authentication.
For mimicry attacks, we first record the articulatory gesture of
the participants when they speaking the passphrase by using a digi-
tal video recorder. The video recording only covers the lower facial
region for privacy concerns. Such a lower facial region including
the articulator movement of upper and lower lips, tongue and jaw.
Then other participants are invited to watch the video carefully and
repeatedly practice the pronunciation by mimicking the articula-
tory gesture in the video. In particular, they are instructed to mimic
the speed of talking, the intensity and range of each articulator
movement, the speech tempo and etc. After they claim that they
have learned how the person in the video speaks and moves the
articulators, they start to conduct the mimicry attacks in front of
the smartphone that used for voice authentication. We recruit 4 at-
tackers and each mimics 6 participants. For each victim/participant,
5 trials for each of 5 passphrases are mimicked. There are in total
600 mimicry attack attempts.
Metrics. We evaluate our system with the following metrics.
False Accept Rate (FAR) is the likelihood that the system incorrectly
declares a replay attack as a live user. True Accept Rate (TAR) is the
probability that the system detects a live user correctly. Receiver
Operating Characteristic (ROC) curve describes the relationship
between the TAR and the FAR when varying the detection threshold.
False Reject Rate (FRR) is the probability that the system mistakenly
classifies a live user as a replay attack. Equal Error Rate records the
rate when FAR equals to FRR. Accuracy presents the possibility that
the system accepts live users and rejects attacks. It is the proportion
of the true positive and true negative cases in all the evaluated cases.
4.2 Overall Performance
We first present the overall performance of our system in detecting
live users under both playback and mimicry attacks. Figure 14 de-
picts the ROC curves of our system under both types of attacks. We
observe that with 1% FAR, the detection rate is as high as 98% when
using the combined features. Such an observation suggests that our
system is highly effective in detecting live users under both replay
and mimic attacks. Moreover, we find that the energy-based fea-
ture results in better performance than that of the frequency-based
feature. For example, with 1% FAR, the frequency-based feature pro-
vide the detection rate at around 90%. Furthermore, we observe that
the participants who have smaller scale of articulatory movements
generate higher false accept rate. Additionally, Figure 15 shows the
overall accuracy under both attacks. Similarity, we observe that
combined feature has the best performance, with an accuracy at
about 99.34%, whereas the energy-based feature alone achieves
an accuracy of 96.22%. The time to perform an authentication is
about 0.5 seconds on a laptop server. The above results demonstrate
the effectiveness of our system in detecting live users. Also, the
energy-based feature and frequency-based feature can complement
each other to improve the detection performance.
Playback Attack. We next detail the performance under play-
back attacks. Figure 16 shows the performance in terms of accuracy
and EER under replay attacks. We observe that the combined fea-
ture results in the best performance. It has an accuracy of 99.3%
and an EER of 1.26%. In particular, with only one type of feature,
we can achieve an accuracy of 97.41% and an EER of 2.83%. These
results show that the two types of feature can complement with
each other and the combined feature is very effective in detecting
live user under playback attacks.
80859095100Accuracy(%)Energybased FeatureCombinedFeatureFrequencybased Feature0246EER(%)CombinedFeatureFrequencybased FeatureEnergybased Feature80859095100Accuracy(%)Frequencybased FeatureEnergybased FeatureCombinedFeature0246EER(%)CombinedFeatureEnergybased FeatureFrequencybased FeatureSession A2:  Human AuthenticationCCS’17, October 30-November 3, 2017, Dallas, TX, USA66Figure 18: Accuracy of different phone placements.
Figure 20: Accuracy under different sampling frequencies.
Figure 19: EER of different phone placements.
Figure 21: EER under different sampling frequencies.
Mimicry Attack. Next, we study the detailed performance un-
der mimicry attacks. Figure 17 shows both the the accuracy and EER
of our system. Again, the combined feature achieves the best accu-
racy at about 99.3% and an EER of 1.21%. Unlike the playback attack
scenario, the frequency-based feature has better performance than
that of the energy-based feature. In particular, the frequency-based
feature has an accuracy of 95.9% and an EER of 4.67%. The above
results suggest that the extracted features from the Doppler shifts
of a sequence of phoneme sounds could capture the differences of
the articulatory gesture between an attacker and a live user under
mimicry attacks. Thus, our system is effective in detecting live users
under mimicry attacks.
4.3 Impact of Phone’s Placement
Different users may have different habits to talk on the phone in
terms of how to hold the phone while speaking. We thus compare
the performance under two placements of the phone (i.e., hold the
phone to ear and hold the phone in front of the mouth) that people
usually feel comfortable to use. Figure 18 presents the performance
comparison of the accuracy, whereas Figure 19 shows the compari-
son of the EER. In high level, the results show that our system is
highly effective under both placements. In particular, when placing
the phone to the ear, we have the best accuracy as 98.61%, while
the best accuracy for placing the phone in front of the mouth is
slightly higher. This is due to the fact that placing the phone in
front of the mouth can capture the movement of the tongue better
as the microphone is directly facing the mouth. Similarly, placing
the phone to the ear has slightly worse EER, i.e., at 2.24%, whereas
it is about 1.2% for the other placement. Nevertheless, our system
works well under both placements and could accommodate differ-
ent users who have different habits to hold the phone while talking.
This property of our system indicates our system doesn’t require
the user to hold the phone at a specific position or move the phone
in a predefined manner as opposed to the prior smartphone based
solutions.
4.4 Impact of Sampling Frequency
We next show that how well our system can work with some low-
end phones that can only playback and record at 48kHz or 96kHz
sampling frequency. Figure 20 depicts the accuracy of our system
under 48kHz, 96kHz and 192kHz sampling frequencies. We notice
that a higher sampling frequency results in a better performance.
This is because a higher sampling frequency could capture more
details of the articulatory gestures and has a better frequency reso-
lution. In particular, the combined feature achieves an accuracy of
98.72% for 96kHz sampling frequency, and 98.69% for 48kHz sam-
pling frequency. Moreover, Figure 21 shows the EER under those
three sampling frequencies. We find the 96kHz sampling frequency
has an EER of 1.63%, whereas it is 2.01% for 48kHz sampling fre-
quency. These results indicate that our system still works very well
at a lower sampling frequency. Thus, our system is compatible to
these older version smartphones.
4.5 Impact of Different Phones
Our system also supports the users to use different types of phones
for enrollment and online authentication. Specifically, we experi-
ment with three different phones including S5, Note3 and Note5.
In the experiments, the participants use one of these three phones
to enroll in the system but use the other two phones for online
voice authentication. The performance of our system is in Figure 22.
Results show that our system works well under such scenarios. In
particular, the combined feature provides an accuracy of 96.58%,
020406080100Accuracy(%)Energy based FeatureFrequency based FeatureCombined FeaturePhone placedby earPhone placedin front of mouth02468EER(%)Energy based FeatureFrequency based FeatureCombined FeaturePhone placedin front of mouthPhone placedby ear4896192Sampling Frequency (kHz)9092949698100Accuracy(%)Energy based FeatureFrequency based FeatureCombined Feature4896192Sampling Frequency (kHz)0246EER(%)Energy based FeatureFrequency based FeatureCombined FeatureSession A2:  Human AuthenticationCCS’17, October 30-November 3, 2017, Dallas, TX, USA67Figure 22: Accuracy of using one phone for enrollment and
the other two for online authentication.
Figure 24: EER under different degree of phone displace-
ment.
Figure 23: Accuracy under different degree of phone dis-
placement.
Figure 25: Accuracy under different length of passphrase.
96.93% and 96.98% when using S5, Note3, and Note5 as the enroll-
ment phone, respectively. Results also indicate that the performance
is comparably well no mater which phone is used for enrollment.
Although the accuracy is slightly worse than that of using the same
phone for enrollment and authentication, our system is still able to
accommodate different types of phones.
4.6 Robustness to Phone Displacement
In this study, we investigate the performance of our system when
experiencing phone displacement between the enrollment phase
and online authentication phase. The phone displacement could
happen, for example when a user place the phone slightly different
from that of the enrolled position or due to hand shakes when a
user is talking while walking. Specifically, we exam three degrees of
phone displacements, i.e., 1cm, 2cm and 3cm away from the original
spot of enrollment in four possible directions, which are Forward
from the mouth, Left to the mouth, and Down or Up against the
mouth. Figure 23 and Figure 24 depict the accuracy and EER of these
scenarios respectively. Generally, a high degree of displacement will
decrease the accuracy and increase the EER of our system. Indeed,
the average accuracy when displace the phone at 1cm is 99.25%
on average, and it is 96.91% and 94.05% on average for 2cm and
3cm displacement, respectively. As for the EER, they are are 1.89%,
5.99% and 7.38% for 1cm, 2cm, and 3cm displacements, respectively.
Furthermore, we notice that the performance is more sensitive
to Down and Up displacements. This is due to the fact that the
Up and Down displacements is more likely to change the relative
positions of multiple articulators to the microphone, thus resulting
in the worst performance. Such an observation is consistent with
the methodology of our liveness detection system, which relies on
the multidimensional movements of multiple articulators for live
user detection. However, the displacement in practice is small (e.g.,
within 1cm) as the size of a user’s mouth is small and a user usually
intends to put the microphone close to the mouth. Additionally,
within the 1-2 seconds time duration of speaking passphrases, we
expect small movements of phone to user’s mouth, which only have
limited effect. Nevertheless, our method provides around 97% accu-
racy with 2cm phone displacements in all directions. The results in
general show that our system is robust to the phone displacement
and could tolerate a relative large phone displacement.
4.7 Impact of Passphrase Length
Next, we show how the length of each passphrase affects the per-
formance of our system. Security professionals usually suggest to
choose a passphrase with more than 5 words so as to provide a
desired security [6]. In the light of this, we classify the passphrases
into three categories according to their lengths: 2 to 4 words, 5 to 7
words, and 8 to 10 words. Figure 25 displays the accuracy of our
system with different lengths of passphrases. We could observe
that when increasing the length of the passphrase, the accuracy
slightly improved from 99.25% to 99.41%. This is expected as a
longer passphrase results in more articulatory gestures for dif-
ferentiating a live user from an attacker. Moreover, we observe
the improvement is not obvious, since we extract 11-dimensional
features from each phoneme, which suggests that 2 to 4 words
passphrases containing around 10 to 20 phonemes could provide
sufficient information for live user detection.
020406080100Accuracy(%)Energy based FeatureFrequency based FeatureCombined FeatureNote5S5/Note3Note3S5/Note5S5Note3/Note51cm2cm3cm1cm2cm3cm1cm2cm3cm1cm2cm3cm020406080100Accuracy(%)Energy based FeatureFrequency based FeatureCombined FeatureForwardLeftDownUp1cm2cm3cm1cm2cm3cm1cm2cm3cm1cm2cm3cm05101520EER(%)Energy based FeatureFrequency based FeatureCombined FeatureForwardLeftDownUp2-45-78-10Passphrase Length (words)949596979899100Accuracy(%)Energy based FeatureFrequency based FeatureCombined Feature94.8499.3495.9299.2596.4096.2195.6397.1799.41Session A2:  Human AuthenticationCCS’17, October 30-November 3, 2017, Dallas, TX, USA685 DISCUSSION
Unconventional Loudspeaker. In our work, we have tested con-
ventional loudspeakers including the standalone speakers, the built-
in speakers of mobile devices, and the earbuds. Nevertheless, there
exists unconventional loudspeakers that do not relies on the di-
aphragm movement for sound production. For example, Piezoelec-
tric Audio Speakers have a totally different working principle com-
paring with electro dynamic speakers as there is no voice coils or
diaphragms. Each piezoelectric speaker relies on a ceramic disc that
interacts when it feels a certain voltage difference. An increase of
the signal amplitude Vpp (Voltage peak to peak) results in a larger
piezo deformation and leads to a larger sound output. Still, such
a mechanism is fundamentally different from that of the human
speech production system. It is expected that the proposed liveness
detection system works with such unconventional loudspeakers.
Another example of unconventional loudspeaker is the Electrostatic
Loudspeaker (ESL), which still relies on the diaphragm movements
for sound production. It is however, driven by two metal grids or
startors instead of voice coil. As our liveness detection system relies
on the movements of articulators for live user detection. Playing
back with such a loudspeaker can still be detected as a replay attack.
Individual Diversity. In our evaluation, we have tested our
system when an attacker mimics the articulatory gesture of a gen-
uine user by observing how the user pronouncing the passphrase.
We now show how the performance looks like when an attacker
has no prior-knowledge on how the legitimate user speaks. That is,
the attacker use his own way of pronouncing the passphrase. This
case is equipotent to compare the Doppler shifts of the articulatory
gesture between two people who speak the same passphrase with
their own habitual ways. Figure 26 shows the accuracy comparison.
We observe that we could be able to achieve much higher accuracy
at close to 100%. The result demonstrates that it is relative easier to
capture the individual diversity than that of a mimicry attack.
Limitations. Our system is evaluated with a limited number
of young and educated subjects. It will be useful to evaluate the
system with a larger number of participants with a more diverse
background to better understand the performance. Moreover, the
system is evaluated only for several months. A long-term study
could be conducted to consider the case that the individual charac-
teristics is likely to change over lifetime, such as changed mouth
cavities or a user grows a beard. Nevertheless, we believe updating
user profile periodically could potentially mitigate such a limitation.
At last, the system does require the users to hold the phones close to
their mouths to reliably capture the articulatory gesture. This limits
the applicable scenarios of the system. For instance, the system is
less applicable to the cases where the phone is not held in the user’s
hand but instead is placed somewhere in close proximity.
6 RELATED WORK
Although the number of mobile applications that use voice biomet-
ric for authentication is rapidly growing, recent studies show that
voice biometrics is vulnerable to spoofing attacks [14, 21, 24, 44, 49].
Such attacks can be further divided into following four categories.
Replay Attack. Numerous work has pointed out existing verifi-
cation systems can not efficiently defend against replay attacks [18,
20, 46]. A recent study [24] shows the EER of voice authentication
Figure 26: Individual diversity v.s. Mimicry attacks.
systems can increase from 1.76% to 30.71% under replay attacks.