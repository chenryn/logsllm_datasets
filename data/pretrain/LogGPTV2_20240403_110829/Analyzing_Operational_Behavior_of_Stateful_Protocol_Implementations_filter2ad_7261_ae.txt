recv meaning arrival of a packet) for TLS OP.
Detection time. We evaluated the feasibility of CHIRON as a
practical tool for detecting semantic bug through measuring
the execution time incurred by its major components (see
Table VI). In this experiment, we considered only the restricted
event model (EM1). Each reported execution time is an
average of 10 independent runs. Once the E-FSM is extracted,
we can use it for detecting semantic bugs against an arbitrary
number of properties. For property checking, we measured
the total required time to model check all the properties (6 for
TLS, 11 for Telnet and 7 for DHCP) until either a consistent
CEX or no CEX is found. However, for comparison, we report
only the average required time to model check per property
(see Table VI). CEX replay time is measured only if CHIRON
found a consistent CEX to replay. We report the time to replay
per consistent CEX. Experiment time signiﬁes the total time
required to ﬁnish the entire analysis of each implementation.
Among the three Telnet server implementations, CHIRON
requires the longest time (6 sec) to extract the E-FSM from
Telnet C27, which has a relatively larger E-FSM size (see
Table V). The same trend is observed for the two DHCP
client implementations. Note that CHIRON requires longer
time for both the DHCP implementations compared to the
Telnet implementations. The reason is that to analyze a DHCP
client CHIRON processes a symbolic packet of size at most
552 bytes for each receive event as opposed to a Telnet
server where it processes 1 byte at a time. Similarly, CHIRON
requires about 100 sec to extract the E-FSM from TLS OP,
which is expected due to its large E-FSM size (see Table V).
The amount of time spent to model check each property is
inﬂuenced by the E-FSM size, the length of the property, and
the number of propositions. This trend can be noticed among
the implementations we tested (see Table VI), with TLS OP
taking the longest time (2 sec) to model check a single property
compared to the other implementations. Replaying a CEX
takes a small fraction of time compared to the extraction of
the respective E-FSM because CHIRON’s CEX replayer drives
the actual execution of the protocol along only one execution
path. Finally, CHIRON ﬁnishes the complete analysis for each
implementation within a few seconds (with a maximum of 2
minutes for TLS OP).
VII. RELATED WORK
We outline the prior work closely related to CHIRON.
Software model checking. CHIRON tries to automatically
check whether a protocol implementation violates a given
temporal property and thus detect the underlying semantic bug.
Software model checking [33]–[39] generalizes this for any
program and safety properties. A software model checking
approach can either be geared towards ﬁnding violations or
proving properties. Based on the used underlying technique,
software model checking approaches can be broadly catego-
rized into two classes: execution-based approaches [33]–[35]
and abstraction-based approaches [36], [37]. CHIRON fol-
lows the abstraction-based approach by abstracting the proto-
col implementation with an E-FSM. Typically, execution-based
approaches cannot explore the entire state-space completely
due to the state-space explosion problem whereas abstraction-
based approaches suffer from spurious CEXs.
There is another class of software model checking ap-
proaches, namely counterexample-guided abstraction reﬁne-
ment (CEGAR) [38]–[40] which enjoys the advantages of both
the above approaches by automatically generating abstractions
of the program under analysis and reﬁning the program (or,
the model) when a spurious CEX is encountered. Although
CHIRON, in principal, does not exactly follow the CEGAR
approach, adding invariants based on spurious CEXs during
model checking can be viewed as model reﬁnement.
Protocol analysis. Prior work checks correctness of protocols
by analyzing either manually formalized speciﬁcations [41],
[42] or implementations in domain-speciﬁc languages [43]–
[45]. However, these approaches cannot ﬁnd bugs in the actual
implementations. Holzmann et al. [46] requires a heavily
annotated source and user provided rules (map the property
in question to relevant statements in the source) to extract
the abstract event-driven program model from the source. The
model is then veriﬁed by utilizing a given non-deterministic
test driver to simulate the necessary behavior of the external
system. Contrarily, CHIRON uses symbolic execution to au-
tomatically extract the E-FSM of the protocol with little input
from the user and does not require any test driver.
Several explicit-state model checkers (CMC [7], [8], NICE
[9]) are used to verify protocol implementations against user
provided state invariants, not temporal properties. While di-
rectly model checking the code can help them detect low-level
programming errors, this can quickly lead to the state-space
explosion problem. Contrarily, CHIRON focuses on temporal
properties expressed in pLTL and check them against the
extracted E-FSM using a symbolic model checker.
Several tools [31], [32], [47] have been developed by ex-
tending dynamic symbolic execution [27], [48] to analyze net-
work protocol implementations; however, they cannot detect
semantic bugs due to violations of temporal properties. While
SymbexNet [31] can be tailored to test temporal behavior
limited to only discernible effects (e.g., exchanged messages),
CHIRON can check properties even with silent internal ef-
fects. PIC [32] identiﬁes non-interoperable implementations
by ﬁnding any discrepancy between what
the sender can
send and what the receiver can receive. In contrast, CHIRON
detects semantic bugs in implementations with respect to user
provided temporal properties, often derived from RFCs.
Fuzzing has been another predominant approach to hunt for
bugs in protocol implementations [30], [49], [50], including
secure protocols like TLS [5], [6]. In essence, they rely on
black-box testing and thus ﬁnd bugs causing discernible exter-
nal effects only (e.g., crash, exchange of incorrect messages).
In contrast to CHIRON, their capabilities are fundamentally
different and complementary. While some fuzzing tools can
be tailored to check temporal behavior with discernible ef-
fects, they cannot ﬁnd semantic bugs causing silent incorrect
behavior, nor can they identify the buggy execution paths.
In addition to the CCS injection bug, SmackTLS [5] ﬁnds
some additional bugs in OpenSSL, which CHIRON cannot
detect as they are not directly realizable through the TLS
client’s E-FSM. To detect those bugs, SmackTLS relies on two
manually derived components: a state machine of TLS for
generating test cases and a veriﬁed reference implementation
of TLS to decide if the outcome of a test case is correct.
Contrarily, CHIRON requires neither a state machine nor a
reference implementation;
it relies on the desired
temporal properties derived from RFCs and the developer
provided meta-information of the protocol implementation.
Inferring protocol speciﬁcation. Prior work aims to infer the
protocol speciﬁcation (FSM)—based on network traces [51]–
[54], using program analysis [6], [24], [55], [56], or through
model checking [36], [57]. These extracted FSMs represent
either discernible external interactions of the protocol (e.g., the
sequences of exchanged messages) or the low-level program
state machines (not E-FSMs). Contrarily, CHIRON extracts the
E-FSM from the implementation by primarily capturing precise
internal interactions of the protocol.
instead,
VIII. CONCLUSION
We presented an automated tool, CHIRON,
to help a
developer detect semantic bugs in an event-driven network
protocol implementation by checking if the implementation
violates given temporal properties. CHIRON ﬁrst automati-
cally extracts the E-FSM from the implementation by utilizing
our FSM extraction technique based on symbolic execution
and then uses a symbolic model checker to detect whether the
E-FSM violates the properties. We demonstrated CHIRON’s
efﬁcacy by applying it on 6 mature implementations of 3
protocols. CHIRON detected 11 semantic bugs violating the
properties derived from the documentation and RFCs of the
protocols. Our results demonstrate that CHIRON can be useful
for developers to discover semantic bugs.
ACKNOWLEDGMENT
We would like to thank the anonymous reviewers for their
helpful comments. This work was supported in part by the
grant CNS-1421815 from the SaTC program of the National
Science Foundation. Its contents are solely the responsibility
of the authors and do not represent the ofﬁcial view of the
National Science Foundation, any thing else?.
REFERENCES
[1] T. Dierks and C. Allen, “The tls protocol version 1.0,” Internet Requests
for Comments, RFC 2246, 1999.
[2] L. Tan, C. Liu, Z. Li, X. Wang, Y. Zhou, and C. Zhai, “Bug character-
istics in open source software,” Empirical Softw. Engg., vol. 19, no. 6,
2014.
[3] “OpenSSL toolkit,” http://www.openssl.org/.
[4] “Contiki bug report,” http://github.com/contiki-os/contiki/commit/d862e.
[5] B. Beurdouche, K. Bhargavan, A. Delignat-Lavaud, C. Fournet,
M. Kohlweiss, A. Pironti, P. Strub, and J. Zinzindohoue, “A messy state
of the union: Taming the composite state machines of TLS,” in S&P.
IEEE, 2015.
[6] J. de Ruiter and E. Poll, “Protocol state fuzzing of tls implementations,”
in USENIX Security, 2015.
[7] M. Musuvathi and D. Engler, “Model checking large network protocol
implementations,” in NSDI, 2004.
[8] M. Musuvathi, D. Park, A. Chou, D. Engler, and D. Dill, “CMC:
Pragmatic approach to model checking real code,” in OSDI, 2002.
[9] M. Canini, D. Venzano, P. Pereˇs´ıni, D. Kosti´c, and J. Rexford, “A nice
way to test openﬂow applications,” in NSDI, 2012.
[10] J. C. King, “Symbolic execution and program testing,” Communications
of the ACM, vol. 19, no. 7, pp. 385–394, 1976.
[11] B. Alpern and F. Schneider, “Recognizing safety and liveness,” Dis-
tributed Computing, vol. 2, no. 3, pp. 117–126, 1987.
[12] J. Postel and J. Reynolds, “Telnet protocol speciﬁcation,” RFC 854,
1983.
[13] R. Droms, “Dynamic host conﬁguration protocol,” RFC 2131, 1997.
[14] A. Dunkels, “Full tcp/ip for 8-bit architectures,” in MobiSys, 2003.
[15] “Fnet embedded tcp/ip stack,” http://fnet.sourceforge.net/.
[16] S. Chong, J. Guttman, A. Datta, A. Myers, B. Pierce, P. Schaumont,
T. Sherwood, and N. Zeldovich, “Report on the NSF Workshop on
Formal Methods for Security,” eprint arXiv:1608.00678, 2016.
[17] C. Labovitz, A. Ahuja, A. Bose, and F. Jahanian, “Delayed internet
routing convergence,” in SIGCOMM, 2000.
[18] R. Jhala and R. Majumdar, “Software model checking,” ACM Computing
Surveys (CSUR), vol. 41, no. 4, p. 21, 2009.
[19] G. Nelson and D. Oppen, “Fast decision procedures based on congruence
closure,” J. ACM, vol. 27, no. 2, 1980.
[20] Z. Manna and A. Pnueli, The Temporal Logic of Reactive and Concur-
rent Systems. Springer-Verlag, 1992.
[21] K. L. McMillan, Symbolic model checking. Springer, 1993.
[22] N. Kothari, R. Mahajan, T. Millstein, R. Govindan, and M. Musuvathi,
“Finding protocol manipulation attacks,” in SIGCOMM, 2011.
[23] I. Yun, C. Min, X. Si, Y. Jang, T. Kim, and M. Naik, “Apisan: Sanitizing
api usages through semantic cross-checking,” in USENIX Security, 2016.
[24] N. Kothari, T. Millstein, and R. Govindan, “Deriving state machines
IEEE, 2008.
[25] A. Bauer and M. Leucker, “The theory and practice of SALT,” in NASA
from tinyos programs using symbolic execution,” in IPSN.
Formal Methods, ser. LNCS, 2011.
[26] “Contiki OS,” http://www.contiki-os.org.
[27] C. Cadar, D. Dunbar, and D. R. Engler, “Klee: Unassisted and automatic
generation of high-coverage tests for complex systems programs.” in
OSDI, 2008, pp. 209–224.
[28] A. Cimatti, E. Clarke, E. Giunchiglia, F. Giunchiglia, M. Pistore,
M. Roveri, R. Sebastiani, and A. Tacchella, “NuSMV Version 2: An
OpenSource Tool for Symbolic Model Checking,” in CAV, 2002.
[29] C. Hawblitzel, J. Howell, M. Kapritsos, J. Lorch, B. Parno, M. Roberts,
S. Setty, and B. Zill, “Ironﬂeet: Proving practical distributed systems
correct,” in SOSP, 2015.
[30] G. Banks, M. Cova, V. Felmetsger, K. Almeroth, R. Kemmerer, and
toward a stateful network protocol fuzzer,” in
G. Vigna, “Snooze:
Information Security. Springer, 2006.
[31] J. Song, C. Cadar, and P. Pietzuch, “Symbexnet: Testing network
protocol implementations with symbolic execution and rule-based spec-
iﬁcations,” TSE, vol. 40, no. 7, 2014.
[32] L. Pedrosa, A. Fogel, N. Kothari, R. Govindan, R. Mahajan, and
T. Millstein, “Analyzing protocol implementations for interoperability,”
in NSDI, 2015.
[33] T. Andrews, S. Qadeer, S. K. Rajamani, J. Rehof, and Y. Xie, “Zing: A
model checker for concurrent software,” in CAV, 2004.
[34] P. Godefroid, “Model checking for programming languages using
verisoft,” in POPL. ACM, 1997.
[35] G. Holzmann, “The model checker SPIN,” TSE, vol. 23, no. 5, 1997.
[36] J. Corbett, M. Dwyer, J. Hatcliff, S. Laubach, C. P˘as˘areanu, R. Bby,
and H. Zheng, “Bandera: Extracting ﬁnite-state models from java source
code,” in ICSE, 2000.
[37] M. Das, S. Lerner, and M. Seigle, “Esp: Path-sensitive program veriﬁ-
cation in polynomial time,” in PLDI, 2002.
[38] T. Ball and S. Rajamani, “The slam project: Debugging system software
via static analysis,” SIGPLAN Not., vol. 37, no. 1, 2002.
[39] D. Beyer, T. Henzinger, R. Jhala, and R. Majumdar, “The software model
checker blast: Applications to software engineering,” Int. J. Softw. Tools
Technol. Transf., vol. 9, no. 5, 2007.
[40] E. Clarke, O. Grumberg, S. Jha, Y. Lu, and H. Veith, “Counterexample-
guided abstraction reﬁnement,” in CAV, 2000, pp. 154–169.
[41] K. Bhargavan, D. Obradovic, and C. Gunter, “Formal veriﬁcation of
standards for distance vector routing protocols,” JACM, vol. 49, no. 4,
pp. 538–576, 2002.
[42] S. Bishop, M. Fairbairn, M. Norrish, P. Sewell, M. Smith, and K. Wans-
brough, “Rigorous speciﬁcation and conformance testing techniques for
network protocols, as applied to tcp, udp, and sockets,” in SIGCOMM,
2005.
[43] E. M. Clarke, S. Jha, and W. Marrero, “Verifying security protocols with
brutus,” TOSEM, vol. 9, no. 4, 2000.
[44] S. Chaki and A. Datta, “Aspier: An automated framework for verifying
security protocol implementations,” in IEEE CSF, 2009, pp. 172–185.
[45] K. Bhargavan, C. Fournet, A. Gordon, and S. Tse, “Veriﬁed interoperable
implementations of security protocols,” TOPLAS, vol. 31, no. 1, 2008.
[46] G. Holzmann and M. Smith, “A practical method for verifying event-
driven software,” in ICSE. ACM, 1999.
[47] R. Sasnauskas, O. Landsiedel, M. H. Alizai, C. Weise, S. Kowalewski,
and K. Wehrle, “Kleenet: discovering insidious interaction bugs in
wireless sensor networks before deployment,” in IPSN. ACM, 2010.
[48] P. Godefroid, N. Klarlund, and K. Sen, “DART: Directed automated
random testing,” in PLDI. ACM, 2005.
[49] H. J. Abdelnur, R. State, and O. Festor, “Kif: a stateful sip fuzzer,” in
IPTComm. ACM, 2007.
[50] S. Jero, H. Lee, and C. Nita-Rotaru, “Leveraging state information for
automated attack discovery in transport protocol implementations,” in
DSN, 2015.
[51] P. M. Comparetti, G. Wondracek, C. Kruegel, and E. Kirda, “Prospex:
Protocol speciﬁcation extraction,” in S&P.
IEEE, 2009.
[52] Y. Wang, Z. Zhang, D. D. Yao, B. Qu, and L. Guo, “Inferring protocol
state machine from network traces: a probabilistic approach,” in ACNS.
Springer, 2011.
[53] J. Caballero, P. Poosankam, C. Kreibich, and D. Song, “Dispatcher:
inﬁltration using automatic protocol reverse-
Enabling active botnet
engineering,” in ACM CCS, 2009.
[54] C. Cho, D. Babi´c, E. Shin, and D. Song, “Inference and analysis of
formal models of botnet command and control protocols,” in CCS, 2010.
[55] C. Y. Cho, D. Babic, P. Poosankam, K. Z. Chen, E. X. Wu, and D. Song,
“Mace: Model-inference-assisted concolic exploration for protocol and
vulnerability discovery.” in USENIX Security, 2011.
[56] J. Caballero, H. Yin, Z. Liang, and D. Song, “Polyglot: Automatic
extraction of protocol message format using dynamic binary analysis,”
in ACM CCS, 2007.
[57] D. Lie, A. Chou, D. Engler, and D. L. Dill, “A simple method for
extracting models from protocol code,” in ISCA.
IEEE, 2001.
APPENDIX A. SYMBOLIC EXECUTION
Symbolic execution is a program analysis technique that executes
the code using symbolic values instead of concrete values (say, α
instead of 2) for program inputs. After executing each program
statement, the executor updates the symbolic store maintaining in-
formation about program variables (e.g., x = 5α). Special attention
is given to handling branches (i.e., if-else, loops). At each branch, the
executor consults with a constraint solver (e.g., an SMT solver) to
determine the feasibility of the branch condition given the information
in the symbolic store so that the executor can continue exploring
only feasible branches. When both branches are feasible, the executor
explores both of them, creating two different execution paths. Upon
termination of the execution, the executor constructs a tree of all
possible execution paths of the program. Each execution path is
represented by a unique path constraint, which is the conjunction of
branch choices that need to be made to follow the path. If necessary,
each path constraint can be solved using a constraint solver to obtain
concrete inputs for that path.