通过下面的命令启动和停止ElasticSearch：
    sudo systemctl start elasticsearch.service
    sudo systemctl stop elasticsearch.service
接着为了让Elasticsearch开机自启，运行下面的命令：
    sudo /bin/systemctl daemon-reload
    sudo /bin/systemctl enable elasticsearch.service
假设你使用SysV init来运行ElasticSearch（比如 Linux Mint）
通过下面的命令启动和停止ElasticSearch：
    sudo -i service elasticsearch start
    sudo -i service elasticsearch stop
接着配置Elastic自启：
    sudo update-rc.d elasticsearch defaults 95 10
对于Kibana和logstash来说，你也可以这样配置。
#### 选项二：按需运行ELK组件
我将虚拟机配置成按需运行ELK，所以我从[这](https://www.elastic.co/downloads)下载了ELK
Stack组件文件，格式是tar.gz。
打开终端窗口，将下载目录下的文件拷贝到/opt文件夹下。
    sudo cp elasticsearch-5.4.3.tar.gz /opt
    sudo cp kibana-5.4.3-linux-x86_64.tar.gz /opt
    sudo cp logstash-5.4.3.tar.gz /opt
接着，切换目录到/opt下，解压所有文件：
    cd /opt
    sudo tar -zxvf elasticsearch-5.4.3.tar.gz
    sudo tar -zxvf kibana-5.4.3-linux-x86_64.tar.gz
    sudo tar -zxvf logstash-5.4.3.tar.gz
现在你可以启动Elasticsearch，举个例子，你只需要这么做：
    cd elasticsearch-5.4.3
    ./bin/elasticsearch
对于Kibana和Logstash来说，过程是一样的
#### 配置修改
在启动组件前，我对配置文件进行了最小的修改，尽管这并不是必须的。我使用了下面的命令来修改文件：
`sudo nano /etc/elasticsearch/elasticsearch.yml`
接着，修改Cluster和Node的名字，我是这样改的：
    cluster-name: honeypot-cluster
    node-name: honeypots
然后，我还将`network.host:192.168.0.1`改成了`network-host: localhost`。
保存退出。
#### 启动，访问ELK
现在你已经运行了ELK，我们可以通过浏览器在本地的9200端口和5601端口分别访问Elasticsearch和Kibana了。
#### 使用ELK工作吧
我已经将下面会提到的脚本上传到了[github](https://github.com/executemalware/Honeypot-Visualizations)。
首先我们需要的是存储数据的Elasticsearch索引。一般来说，索引的创建非常简单。在终端下输入下面的命令就可以创建叫做test的索引了。
`curl -XPUT &#39;localhost:9200/test&#39;`
你应该能看到true的结果返回，你也可以通过下面的这个命令来验证test索引的存在。
`curl -XGET &#39;localhost:9200/test?pretty&#39;`
这个脚本在Elasticsearch创建了Cowrie索引，同时也提供了映射信息：
`./create_index.sh&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`
现在，你需要将数据存入新的Elasticsearch索引。下面的这个脚本会循环遍历名为’cowrie’文件夹然后使用’./bulk_index.sh’脚本处理每个文件。这个脚本会在cowrie数据文件中的每一行中插入正确的数据，并以正确的JSON格式（便于Elasticsearch）组合起来，接着会把文件添加到我们刚建立的’cowrie’索引中。
`for JSON in cowrie/*.*; do ./bulk_index.sh $JSON; done`
现在你已经将数据存到了Elasticsearch索引中，接着可以通过Kibana来进行可视化了。
#### 使用Kibana
  * 打开浏览器，访问localhost:5601
  * 在要求你创建索引名的字段位置，删掉原来的logstash-*，然后输入cowrie
  * 确认勾选了以时间为索引的复选框
  * 点击创建
  * 在左侧菜单点击发现去校验和观察你的数据
  * 此时最可能出现的情况是，右上角的数据只显示了最近15分钟—— 你可以自己调整范围。
接着，添加可视化选项。
  * 点击左侧菜单的可视化
  * 点击创建可视化视图，然后关闭。
（温馨提示：我并不打算指导你如何在Kibana中创建可视化视图，因为网络上有很多非常棒的相关资源）
目前来说，我们所遇到的ELK困惑中只有一个尚未解决，就是将IP地址转为地理位置以便在地图上标注出来。为了完成这个，我们需要借助Logstash的力量。到目前为止，我并没有让它正常工作，一旦没问题我会发篇相关简短的博客。
### 可视化Dionaea数据
因为在之前的博客中介绍了DionaeaFR，所以这里不会深入任何相关的细节。关于DionaeaFR安装唯一要注意的新内容是现在有一个脚本，它能够完成所有繁重的操作。我在原始的DionaeaFR博客上收到了来自R1ckyz1的评论，他说他写了一个能够自动安装DionaeaFR和所有依赖的脚本。于是我将这个脚本进行了修改，你可以在从这获取它。
在DionaeaFR安装完成后，你可以通过这个脚本来启动。在那之后，你可以通过本地8000端口来访问。
### 结论和未完成的部分
就本文的大部分来说，我并不满意这篇文章。因为有太多未完成的。在你考虑如何将你捕获的数据进行展示和计算时，希望这篇漫长的蜜罐可视化文章能够给你一些启发。
关于这个主题，下面的条目是我仍想继续做的：
#### Kibana
  1. 找到能够在一次可视化中展示多个字段的方法（比如同时显示用户名/密码）
  2. 清理修改Kibana主控板—— 删除可视化标签
  3. 将IP地址转为地理位置，以便在地图上显示
  4. 找出使Dionaea Json再次正常工作的解决方法，便于我使用ELK展示数据
#### amChars
  1. 试着通过amCharst来重新构造DionaeaFR来展示数据
我想这些意味着未来的某个时候还有下篇（希望很快就来）【译者注：外国人真墨迹，就四个字的意思-未完待续-要扯那么多】
[原文在这](http://executemalware.com/?p=355)