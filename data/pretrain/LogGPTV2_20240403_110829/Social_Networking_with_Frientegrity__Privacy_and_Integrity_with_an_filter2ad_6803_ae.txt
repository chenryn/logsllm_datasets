own machines and trusted third-party infrastructure. We
have argued, however, that decentralization is an insuﬃ-
cient approach. A user is left with an unenviable dilemma:
either sacriﬁce availability, reliability, scalability, and con-
venience by storing her data on her own machine, or en-
trust her data to one of several providers that she probably
does not know or trust any more than she would a central-
ized provider.
Cryptographic approaches: Many other works aim to
protect social network users’ privacy via cryptography.
Systems such as Persona [5], ﬂyByNight [37], NOYB [25],
and Contrail [53] store users’ data with untrusted providers
but protect its contents with encryption. Others, such as
Hummingbird [9], Lockr [56], and systems from Backes et
al. [3], Domingo-Ferrer et al. [18] and Carminati et al. [8]
attempt to hide a user’s social relationships as well, ei-
ther from the provider or from other users. But, they do
not oﬀer any defenses against the sort of traﬃc analysis
we describe in §2.3 other than decentralization. Unlike
Frientegrity, in many of these systems (e.g., [5, 9, 37]),
“un-friending” requires work that is linear in the number
of a user’s friends. The scheme of Sun et al. [54] is an ex-
ception, but it does not support FoFs. EASiER [28] aims
to achieve eﬃcient revocation via broadcast encryption
techniques and a reencrypting proxy, but when deployed
in the DECENT [29] distributed social network, it appears
to perform poorly for reasons that are unclear. All of these
systems, however, focus primarily on protecting users’
privacy while largely neglecting the integrity of users’
data. They either explicitly assume that third parties are
“honest-but-curious” (e.g., [9, 37]), or they at most employ
signatures on individual messages. None deal with the
prospect of provider equivocation, however.
Defending against equivocation: Several systems
have addressed the threat of server equivocation in net-
work ﬁle systems [33, 34], key-value stores [7, 38, 50],
and group collaboration [21] by enforcing fork* consis-
tency and related properties. But to enforce fork* consis-
tency, they require clients to perform work that is linear in
either the number of users or the number of updates ever
submitted to the system. This overhead is impractical in
social networks with large numbers of users and in which
users typically are interested only in the latest updates.
FETHR [45] is a Twitter-like service that defends
against server equivocation by linking a user’s posts to-
gether with a hash chain as well as optionally entangling
multiple users’ histories. But besides not supporting ac-
cess control, it lacks a formal consistency model. Thus,
unless a client veriﬁes a user’s entire history back to the
beginning, FETHR provides no correctness guarantees.
Figure 9: Latency of various ACL operations as a function
of number of friends. Friend of Friend updates are mea-
sured as time to change a single user’s FoF key. Each data
point is the mean of 100 runs.
of users. When a user Alice updates her ACL, she ﬁrst
fetches it and its corresponding ACL history and checks
that they are consistent. In response, Alice’s friend Bob
updates the key he shares with friends-of-friends (FoFs).
To do so, he fetches and checks Alice’s ACL in order
retrieve her updated key. He then proceeds to fetch, check,
and update his own ACL.
To evaluate the cost of these ACL operations, we mea-
sured Frientegrity’s performance as two users, Alice and
Bob, make changes to their ACLs. While Alice added
and removed users from her ACL, Bob updated the key
he shares with FoFs. We performed this experiment for
diﬀerent ACL sizes and plotted the results in Figure 9.
As expected, updating the key shared with FoFs was
the most costly operation because it requires verifying
two ACLs instead of one. Furthermore, adding a new
user to an ACL took longer than removing one because
it requires a public key encryption. Finally, we observed
that although modifying an ACL entails a logarithmic
number of symmetric key operations, the cost of these
operations was dominated by constant number of public
key operations required to verify and update the ACL
history.
8. Related Work
Decentralized approaches: To address the security con-
cerns surrounding social networking, numerous works
have proposed decentralized designs, in which the social
networking service is provided by a collection of fed-
erated nodes. In Diaspora [17], perhaps the most well
known of these systems, users can choose to store their
data with a number of diﬀerent providers called “pods.” In
other systems, including Safebook [14], eXO [36], Peer-
SoN [6], porkut [44], and Conﬁdant [35], users store their
data on their own machines or on the machines of their
trusted friends, and these nodes are federated via a dis-
tributed hash table. Still others, such as PrPl [48] and
14
02004006008001000ACLSize051015202530354045ResponseLatency(ms)UpdateFoFKeyAddUserRevokeUser9. Conclusion and Future Work
In designing Frientegrity, we sought to provide a general
framework for social networking applications built around
an untrusted service provider. The system had to both
preserve data conﬁdentiality and integrity, yet also remain
eﬃcient, scalable, and usable. Towards these goals, we
present a novel method for detecting server equivocation
in which users collaborate to verify object histories, and
more eﬃcient mechanisms for ensuring fork* consistency
based on history trees. Furthermore, we provide a novel
mechanism for eﬃcient access control by combining per-
sistent authenticated dictionaries and key graphs.
In addition to introducing these new mechanisms, we
evaluate a Frientegrity prototype on synthetic workloads
inspired by the scale of real social networks. Even as
object histories stretch into the tens of thousands and ac-
cess control lists into the hundreds, Frientegrity provides
response times satisfactory for interactive use, while main-
taining strong security and integrity guarantees.
Like other social networking systems that store users’
encrypted data with an untrusted provider [5, 25, 37, 53],
Frientegrity faces the problem of how such third-party
infrastructure would be paid for. It has been suggested that
providers would not accept a business model that would
prevent them from mining the plaintext of users’ data for
marketing purposes. Whether this is so has not been well
studied. Although there has been some work on privacy-
preserving advertising systems[26, 57], the development
of business models that can support privacy-preserving
services hosted with third-party providers largely remains
future work.
Acknowledgments We thank Andrew Appel, Matvey
Arye, Wyatt Lloyd, and our anonymous reviewers for their
insights and helpful comments. This research was sup-
ported by funding from NSF CAREER Award #0953197,
an ONR Young Investigator Award, and a gift from
Google.
References
[1] T. E. Anderson, M. D. Dahlin, J. M. Neefe, D. A. Patterson,
D. S. Roselli, and R. Y. Wang. Serverless network ﬁle
systems. ACM TOCS, 14(1), 1996.
[2] C. R. Aragon and R. G. Seidel. Randomized search trees.
In Proc. FOCS, Oct. 1989.
[3] M. Backes, M. Maﬀei, and K. Pecina. A security API for
distributed social networks. In Proc. NDSS, Feb. 2011.
[4] L. Backstrom, C. Dwork, and J. Kleinberg. Wherefore
Art Thou R3579X? Anonymized social networks, hidden
patterns, and structural steganography. In Proc. WWW,
May 2007.
[5] R. Baden, A. Bender, N. Spring, B. Bhattacharjee, and
D. Starin. Persona: an online social network with user-
deﬁned privacy. In Proc. SIGCOMM, Aug. 2009.
[6] S. Buchegger, D. Schi¨oberg, L. hung Vu, and A. Datta.
PeerSoN: P2P social networking early experiences and
insights. In Proc. SNS, Mar. 2009.
[7] C. Cachin, I. Keidar, and A. Shraer. Fail-aware untrusted
storage. In Proc. DSN, June 2009.
[8] B. Carminati and E. Ferrari. Privacy-aware collaborative
In Proc.
access control in web-based social networks.
DBSec, July 2008.
[9] E. D. Cristofaro, C. Soriente, G. Tsudik, and A. Williams.
Hummingbird: Privacy at the time of twitter. Cryp-
tology ePrint Archive, Report 2011/640, 2011. http:
//eprint.iacr.org/.
[10] S. A. Crosby and D. S. Wallach. High throughput asyn-
chronous algorithms for message authentication. Technical
Report CS TR10-15, Rice University, Dec. 2010.
[11] S. A. Crosby and D. S. Wallach. Eﬃcient data structures
for tamper-evident logging. In Proc. USENIX Security,
Aug. 2009.
[12] S. A. Crosby and D. S. Wallach. Super-eﬃcient aggregat-
ing history-independent persistent authenticated dictionar-
ies. In Proc. ESORICS, Sept. 2009.
[13] S. A. Crosby and D. S. Wallach. Reference implemen-
tation of history trees and spliced signatures. https:
//github.com/scrosby/fastsig, Dec. 2010.
[14] L. A. Cutillo, R. Molva, T. Strufe, and T. Darmstadt.
Safebook: A privacy-preserving online social network
leveraging on real-life trust. IEEE Communications Maga-
zine, 47(12):94–101, Dec. 2009.
[15] G. DeCandia, D. Hastorun, M. Jampani, G. Kakulapati,
A. Lakshman, A. Pilchin, S. Sivasubramanian, P. Vosshall,
and W. Vogels. Dynamo: Amazon’s highly available key-
value store. In Proc. SOSP, Oct. 2007.
protobuf-socket-rpc:
[16] S. Deo.
protobuf
(version 2.0).
protobuf-socket-rpc/, May 2011.
Java and python
rpc implementation using TCP/IP sockets
http://code.google.com/p/
[17] Diaspora.
Diaspora
diasporaproject.org/.
2012.
project.
http://
Retrieved April 23,
[18] J. Domingo-Ferrer, A. Viejo, F. Seb´e, and ´ırsula Gonz´alez-
Nicol´as. Privacy homomorphisms for social networks with
private relationships. Computer Networks, 52:3007–3016,
Oct. 2008.
[19] Facebook, Inc. Anatomy of facebook. http://www.
facebook.com/notes/facebook-data-team/
anatomy-of-facebook/10150388519243859,
Nov. 2011.
[20] Facebook, Inc. Fact sheet. http://newsroom.fb.
com/content/default.aspx?NewsAreaId=22.
Retrieved April 23, 2012.
[21] A. J. Feldman, W. P. Zeller, M. J. Freedman, and E. W.
Felten. Sporc: Group collaboration using untrusted cloud
resources. In Proc. OSDI, Oct. 2010.
[22] Flickr. Flickr phantom photos. http://flickr.com/
help/forum/33657/, Feb. 2007.
[23] S. Ghemawat, H. Gobioﬀ, and S.-T. Leung. The Google
ﬁle system. In Proc. SOSP, Oct. 2003.
15
[24] Google,
Inc.
Transparency report.
https:
//www.google.com/transparencyreport/
governmentrequests/userdata/.
April 23, 2012.
Retrieved
[25] S. Guha, K. Tang, and P. Francis. NOYB: Privacy in online
social networks. In Proc. WOSN, Aug. 2008.
[26] S. Guha, B. Cheng, and P. Francis. Privad: Practical privacy
in online advertising. In Proc. NSDI, Mar. 2011.
[27] M. P. Herlihy and J. M. Wing. Linearizability: A correct-
ness condition for concurrent objects. ACM TOPLAS, 12
(3), 1990.
[28] S. Jahid, P. Mittal, and N. Borisov. EASiER: Encryption-
based access control in social networks with eﬃcient revo-
cation. In Proc. ASIACCS, Mar. 2011.
[29] S. Jahid, S. Nilizadeh, P. Mittal, N. Borisov, and A. Kapa-
dia. DECENT: A decentralized architecture for enforcing
privacy in online social networks. In Proc. SESOC, Mar.
2012.
[30] D. Karger, E. Lehman, T. Leighton, M. Levine, D. Lewin,
and R. Panigrahy. Consistent hashing and random trees:
Distributed caching protocols for relieving hot spots on the
World Wide Web. In Proc. STOC, May 1997.
[44] R. Narendula, T. G. Papaioannou, and K. Aberer. Privacy-
aware and highly-available OSN proﬁles. In Proc. WET-
ICE, June 2010.
[45] D. R. Sandler and D. S. Wallach. Birds of a FETHR: Open,
decentralized micropublishing. In Proc. IPTPS, Apr. 2009.
[46] R. Sanghvi. Facebook blog: New tools to control your
experience. https://blog.facebook.com/blog.
php?post=196629387130, Dec. 2009.
[47] E. Schonfeld. Watch out who you reply to on google buzz,
you might be exposing their email address. TechCrunch,
Feb. 2010.
[48] S.-W. Seong, J. Seo, M. Nasielski, D. Sengupta, S. Hangal,
S. K. Teh, R. Chu, B. Dodson, and M. S. Lam. PrPl: A
decentralized social networking infrastructure. In Proc.
MCS, June 2010.
[49] A. Shakimov, H. Lim, R. Caceres, L. P. Cox, K. Li, D. Liu,
and A. Varshavsky. Vis-`a-Vis: Privacy-preserving online
social networking via virtual individual servers. In Proc.
COMSNETS, Jan. 2011.
[50] A. Shraer, C. Cachin, A. Cidon, I. Keidar, Y. Michalevsky,
and D. Shaket. Venus: Veriﬁcation for untrusted cloud
storage. In Proc. CCSW, Oct. 2010.
[31] L. Lamport. The part-time parliament. ACM TOCS, 16(2):
[51] S. Song. Why I left Sina Weibo. http://songshinan.
133–169, 1998.
[32] J. Leskovec and E. Horvitz. Planetary-scale views on a
In Proc. WWW, Apr.
large instant-messaging network.
2008.
[33] J. Li and D. Mazi`eres. Beyond one-third faulty replicas
in Byzantine fault tolerant systems. In Proc. NSDI, Apr.
2007.
[34] J. Li, M. N. Krohn, D. Mazi`eres, and D. Shasha. Secure
untrusted data repository (SUNDR). In Proc. OSDI, Dec.
2004.
[35] D. Liu, A. Shakimov, R. C´aceres, A. Varshavsky, and L. P.
Cox. Conﬁdant: Protecting OSN data without locking it
up. In Proc. Middleware, Dec. 2011.
[36] A. Loupasakis, N. Ntarmos, and P. Triantaﬁllou. eXO:
Decentralized autonomous scalable social networking. In
Proc. CIDR, Jan. 2011.
[37] M. M. Lucas and N. Borisov. ﬂyByNight: mitigating the
privacy risks of social networking. In Proc. WPES, Oct.
2008.
[38] P. Mahajan, S. Setty, S. Lee, A. Clement, L. Alvisi,
M. Dahlin, and M. Walﬁsh. Depot: Cloud storage with
minimal trust. In Proc. OSDI, Oct. 2010.
[39] D. Mazi`eres and D. Shasha. Building secure ﬁle systems
out of byzantine storage. In Proc. PODC, July 2002.
[40] J. P. Mello. Facebook scrambles to ﬁx security hole expos-
ing private pictures. PC World, Dec. 2011.
[41] R. C. Merkle. A digital signature based on a conventional
encryption function. CRYPTO, pages 369–378, 1987.
[42] Mozilla Project. Network security services for Java
(JSS). https://developer.mozilla.org/En/
JSS. Retrieved April 23, 2012.
[43] A. Narayanan and V. Shmatikov. De-anonymizing social
networks. In Proc. IEEE S & P, May 2009.
blog.caixin.cn/archives/22322, July 2011.
[52] M. Stonebraker. The case for shared nothing.
IEEE
Database Engineering Bulletin, 9(1):4–9, 1986.
[53] P. Stuedi, I. Mohomed, M. Balakrishnan, Z. M. Mao, V. Ra-
masubramanian, D. Terry, and T. Wobber. Contrail: En-
abling decentralized social networks on smartphones. In
Proc. Middleware, Dec. 2011.
[54] J. Sun, X. Zhu, and Y. Fang. A privacy-preserving scheme
for online social networks with eﬃcient revocation. In
Proc. INFOCOM, Mar. 2010.
[55] D. B. Terry, M. M. Theimer, K. Petersen, A. J. Demers,
M. J. Spreitzer, and C. H. Hauser. Managing update con-
ﬂicts in Bayou, a weakly connected replicated storage sys-
tem. In Proc. SOSP, Dec. 1995.
[56] A. Tootoonchian, S. Saroiu, Y. Ganjali, and A. Wol-
man. Lockr: Better privacy for social networks. In Proc.
CoNEXT, Dec. 2009.
[57] V. Toubiana, A. Narayanan, D. Boneh, H. Nissenbaum,
and S. Barocas. Adnostic: Privacy preserving targeted
advertising. In Proc. NDSS, Feb. 2010.
[58] D. Wheeler. SLOCCount. http://www.dwheeler.
com/sloccount/. Retrieved April 23, 2012.
[59] C. K. Wong, M. Gouda, and S. S. Lam. Secure group
communications using key graphs. IEEE/ACM TON, 8(1):
16–30, 1998.
[60] M. Zuckerberg.
Facebook S-1: Letter from Mark
Zuckerberg.
http://sec.gov/Archives/
edgar/data/1326801/000119312512034517/
d287954ds1.htm#toc287954_10, Feb. 2012.
16