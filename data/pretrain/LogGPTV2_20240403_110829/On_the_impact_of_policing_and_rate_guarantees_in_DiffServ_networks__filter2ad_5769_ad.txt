### Setting the Encoding Rate for Audio Near Zero

#### Lost Clip
- **Session:**
  - Total Bytes Encoded: 6,936,504
  - Expected Bit Rate: 1,015.5 Kbps
  - Average Bit Rate: 771.7 Kbps

- **Video [1,015.4 Kbps]:**
  - Total Bytes Encoded: 6,935,380
  - Expected Bit Rate: 1,015.4 Kbps
  - Average Bit Rate: 771.6 Kbps
  - Expected Frames per Second: 30.0
  - Average Frames per Second: 29.9
  - Total Frames: 2,150

- **Audio [0.1 Kbps]:**
  - Total Bytes Encoded: 1,124
  - Expected Bit Rate: 0.1 Kbps
  - Average Bit Rate: 0.1 Kbps
  - Total Samples: 562

#### Dark Clip
- **Session:**
  - Total Bytes Encoded: 11,976,984
  - Expected Bit Rate: 1,015.6 Kbps
  - Average Bit Rate: 680.5 Kbps

- **Video [1,015.5 Kbps]:**
  - Total Bytes Encoded: 11,974,782
  - Expected Bit Rate: 1,015.5 Kbps
  - Average Bit Rate: 680.4 Kbps
  - Expected Frames per Second: 30.0
  - Average Frames per Second: 30.0
  - Total Frames: 4,219

- **Audio [0.1 Kbps]:**
  - Total Bytes Encoded: 2,202
  - Expected Bit Rate: 0.1 Kbps
  - Average Bit Rate: 0.1 Kbps
  - Total Samples: 1,101

**Table 3. Properties of Windows Media Encoded Clips.**

### Results

As mentioned in Section 2.2, we initially considered several different video servers but ultimately limited our experiments to two types: the Video Charger™ server for experiments over the QBone and a Windows Media™ server for experiments over our local testbed. Table 4 summarizes the different configurations used.

The primary reason for excluding the other servers was their poor performance in the presence of dropped packets induced by traffic policers. These servers rely on large datagrams for transmitting video frames, which are then fragmented into smaller packets. The loss of even one packet at the policer typically results in the loss of an entire datagram. This problem is exacerbated by the fact that a single datagram triggers the generation of many back-to-back packets, leading to multiple dropped packets due to the small token bucket depth used for EF traffic. Additionally, policing losses, combined with the service guarantees provided to EF traffic, confused the adaptation mechanism of the servers. Specifically, the server interpreted small delays as an indication of sufficient bandwidth, causing it to increase its data rate to compensate for losses. This led to further packet losses and more rate increases until the server reduced its transmission rate significantly. This cycle repeated, eventually causing the client to disconnect due to unreliability. In summary, traffic conditioning misled the dynamic rate control approach of the servers, making them unusable unless the token rate was set to the maximum rate of the server.

**Table 4. Summary of Experimental Configurations.**

| Video Server Used | Network Protocol | Content Type | Content Properties | PHB Tested | Service Parameters | Out of Profile Action |
|-------------------|------------------|--------------|--------------------|------------|--------------------|-----------------------|
| Video Charger     | UDP              | MPEG1        | Rate               | Drop       | Token Rate, Bucket Depth | Drop (Router 1) |
| Windows Media Server | TCP, UDP | WMV Format | Constant Bit Rate | EF | Max bit rate is constant | Drop (Shape – Linux Router) |

### Main Results

Our main results consist of quality estimates generated from the different configurations tested. It is important to note that there is some variability in the results. For the same combination of video server, video client, and network parameters, slightly different quality estimates can be obtained in consecutive runs. This variability is due to factors such as load conditions at the server and variations in interfering traffic through the local network. These differences in lost packets affect the resulting video quality. For example, a small increase in token rate can sometimes lead to degraded video quality, depending on the scene type, intrinsic video rate, and server reaction.

To minimize these variations, we eliminated most external interference sources, such as using a dedicated video server and ensuring no local interfering traffic. However, some experiments on the local testbed involved interfering cross-traffic, and the QBone experiments did not allow us to control the presence of interfering traffic. In all cases where we compared the outcomes with and without interfering traffic, only minor variations were observed, primarily reflecting how different routers prioritize EF traffic. It is impossible to completely eliminate all sources of variation, but the general trends are meaningful, while minor fluctuations in quality may not be.

### QBone Testbed Results

Copies of the clips "Dark" and "Lost," encoded at different rates identified in Section 3.3, were streamed through the QBone from a Video Charger server at the remote site to a video client at the local site (see Figure 5). Streaming was done over UDP, as this was the only configurable option at the remote server when EF marking was applied. Each clip was streamed multiple times with different network service parameters (token rate and bucket depth). Two token bucket depths were used: 3,000 bytes and 4,500 bytes. For each depth, the token rate was varied from just below the average stream rate to a value achieving the maximum video quality rating of 0, which typically corresponded to the maximum rate of the video stream.

Initial results are shown in Figures 7 through 9 for the "Lost" clip and in Figures 10 through 12 for the "Dark" clip. Each figure has two sets of curves, one for each token bucket depth. The two curves in each set correspond to the fraction of lost frames and the corresponding video quality rating produced by the VQM tool. For comparison, these values are plotted against the same y-axis scale, while the x-axis corresponds to increasing token rate values. Tables available from [2] provide more precise numerical values. Recall that a quality score of 1.0 is the worst possible, while a score of 0.0 corresponds to the best possible video quality, identical to the original clip used as reference.

**Figure 7. QBone Streaming (Lost clip/1.7 Mbps encoding): Video Quality & Frame Loss vs Token Rate.**

**Figure 8. QBone Streaming (Lost clip/1.5 Mbps encoding): Video Quality & Frame Loss vs Token Rate.**

**Figure 9. QBone Streaming (Lost clip/1.0 Mbps encoding): Video Quality & Frame Loss vs Token Rate.**

In the first set of experiments, the quality of the received video was compared to that of the transmitted clip, with different reference points for each encoding rate. These experiments assessed the quality degradations resulting from network impairments. In a later set of experiments, the comparison was made with respect to the highest quality original clip (1.7 Mbps encoding rate) to assess the trade-off between quality degradations imposed by the network and those due to the encoding itself.

**Figure 10. QBone Streaming (Dark clip/1.7 Mbps encoding): Video Quality & Frame Loss vs Token Rate.**

**Figure 11. QBone Streaming (Dark clip/1.5 Mbps encoding): Video Quality & Frame Loss vs Token Rate.**

**Figure 12. QBone Streaming (Dark clip/1.0 Mbps encoding): Video Quality & Frame Loss vs Token Rate.**

Quality Index, B=3000  
Frame Loss, B=3000  
Quality Index, B=4500  
Frame Loss, B=4500  

**Figure 9. QBone Streaming (Lost clip/1.0 Mbps encoding): Video Quality & Frame Loss vs Token Rate.**

**Figure 10. QBone Streaming (Dark clip/1.7 Mbps encoding): Video Quality & Frame Loss vs Token Rate.**