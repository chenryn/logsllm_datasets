零信任产业标准工作组
在用户对资源访问的零信任实现上，具体到落地部署中，可以根据企业特点有多种部署方式，下面列举常
见的几类部署模式：
1）企业内部部署
在企业内部部署模式中，零信任网关主要用于企业内部服务保护，因此部署位置将零信任网关放置到服务
器网络前，如下图：
通过零信任系统提供统一的业务安全访问通道，关闭职场内部终端直连内部业务系统的网络策略，尽可能
避免企业内部服务全部暴露在办公网络（内网中过多的默认信任）。
所有的终端访问都要进过终端身份校验（人的安全可信），终端/系统/应用的可信确认（终端设备的安全
可信），还有细粒度的权限访问校验，然后才可以通过加密安全网关访问具体的业务（链路的安全可信），这
样能极大的降低和减少内部业务资产被恶意扫描和攻击的行为。
2）集团多分支部署
集团公司，其全国/全球的多个分支子公司、办事处、并购公司、外部合作（协作）公司等员工需要安全
访问集团内部系统，该需求模式下可以采用以下部署模式，实现多分支的访问：
4.1.6 部署模式
零 信 任 实 战 白 皮 书
零 信 任 实 战 白 皮 书
零 信 任 实 现 方 案
零信任产业标准工作组
该部署模式中可以针对集团、子公司的组织架构（用户群组）或者具体人员（用户）设置访问策略，员工
访问可达的集体内部系统仅限于指定的业务（细粒度授权），不可越界。应保障访问过来的人员身份、设备、
链路的安全，同时子公司的终端或者账户如果有异常可以及时阻断访问。
3）云业务服务部署
中小企业用户多数使用多个公有云服务商的云服务，在不同的公有云上部署不同的业务类型，难以构建一
个包含多个云服务的企业网络来保障访问策略的统一和对资源的安全访问控制，对这类场景可以采用如下部署
模式：
零 信 任 实 战 白 皮 书
零 信 任 实 战 白 皮 书
零 信 任 实 现 方 案
零信任产业标准工作组
1)  数据中心的集中化建设，导致数据泄露风险增加
数据中心的集中化建设，解决了集中运维、管理的问题，同时也节约了资源成本，但数据的集中也增加了
数据泄露的风险。通过Killchain模型我们可以看到，现代的攻击都有一些显著特点，一旦边界的防线被攻破或
绕过，攻击者就可以在数据中心内部横向移动，而中心内部基本没有安全控制的手段可以阻止攻击。这也突出
了传统安全的一个主要弱点，复杂的安全策略、巨大的资金和技术都用于了边界防护，而同样的安全投入并不
存在于内部。
2)   内部恶意软件传播
目前多数的网络安全架构来看：为遏制病毒的入侵，多数在边界处部署了防毒墙，以及采用内外网隔离的
该部署模式下多个云复用同一个零信任控制中心，提供统一访问控制策略，通过低流量的策略同步或者其
他不影响带宽的机制，做到统一的授权管理。用户在具体要访问哪个云上业务的时候，就可以通过控制中心，
对接到相应云的零信任网关入口进行访问。
4.2 服务之间调用模式实现
4.2.1 需求分析
零 信 任 实 战 白 皮 书
零 信 任 实 现 方 案
零信任产业标准工作组
核心元素：
a）工作负载：workload，承载业务的主机，可以是物理服务器、虚拟机或容器。
b）访问者：发起访问一方的工作负载。
c）提供者：提供服务一方的工作负载。在数据中心中，任意一个工作负载都可能本身即是提供者，也是
其他工作负载的访问者。
d）服务：即根据业务需要所开放的供其他工作负载或用户访问的服务。
以上核心元素，面临的风险场景如下：
a）工作负载风险：对于不同的主机形态，数据中心内部的零信任建设是否可以覆盖，防止“木桶”出现短
板。
b）访问者风险：访问者是否是可信的，如攻击者通过钓鱼邮件、口令破解、0day漏洞等拿下一台工作负
载后，以此为跳板在内部发起攻击。而这种攻击边界防护是无法发现的。
c）提供者风险：往往被作为攻击的目标，通过跳板机去探测提供者所提供的服务是否存在漏洞等。
d）服务风险：服务的风险有两个方面，一是工作负载是否提供了业务不需要的服务（端口），例如445，
139等，很多攻击及病毒的传播都是由于过大的暴露面。二是服务的调用是否符合业务逻辑，在实际环境中，
数据中心往往采用大二层网络，无法对服务的调用进行有效控制。
综上所述，在实现零信任方案的过程中，要实现的核心目标主要有以下几类：
a）尽可能的覆盖现有工作负载。
b）访问者、服务者可信。可参考以下方式：设备特征，如已安装的软件版本、网络位置、以前观察到的
行为、已安装的凭证等。
c）服务最小化原则：1.限制无用端口的开放，形成进程/端口台账。2.限制服务的可视性及可访问性。可
考虑采用访问控制或加密的方式。
考虑到不同于用户访问资源的已知授权式访问，工作负载之间的调用在多数企业内没有进行过有效梳理，
方式；为防止病毒，内部的PC端多通过杀毒软件进行漏洞管理及病毒查杀。而考虑服务器的稳定运行及性能，
数据中心很少会部署杀毒软件，目前最常见的方式是通过划分VLAN的方式将数据中心内部的服务器划分为多
个区域。这种架构，虽然边界关闭了无用端口、过滤了流量，但一旦内部某一台工作负载感染病毒，病毒即可
在区域内部进行传播。
基于零信任的理念，威胁并不只存在外部，对于数据中心内部而言，也需要建立安全防线，从而保障工作
负载之间的受控访问。
4.2.2 核心理念
零 信 任 实 战 白 皮 书
零 信 任 实 战 白 皮 书
零 信 任 实 现 方 案
零信任产业标准工作组
所以内部的业务流可见性是实现工作负载之间零信任的基础，也决定了管理能做到的细粒度。
动态策略调整同样是该场景下，零信任实施应该考虑的关键，尤其是针对大型云计算数据中心及容器环
境。通过动态的策略调整，减少人工参与，才能使工作负载之间的零信任建设适应业务的动态变化。
基于对工作负载之间访问的零信任建设，核心技术框架如下：
对于数据中心内部零信任的建设，一般采用软件定义的方式进行，分为控制平面与数据平面。该架构的核
心组成如下：
1)  零信任安全控制中心：负责鉴权和授权判断，并提供业务流的可视化能力。主要功能如下：
a）认证：对工作负载身份进行认证和授权；
b）安全策略配置：统一的安全策略配置管理，访问控制策略可以灵活组合。
c）动态策略调整：根据环境的变化，动态计算修改安全策略。
2)零信任安全代理（策略执行点）：用于执行访问控制决策，允许/拒绝通信或进行协商加密；有时也会将
工作负载的相关信息同步给安全控制中心，从而辅助其进行决策。可以单个逻辑组件（充当连接门卫的单个门
户组件），或分为两个不同的组件：客户端（例如安装在工作负载之上）和网关端（例如在资源之前控制访问
的组件）。
4.2.3 技术框架
零 信 任 实 战 白 皮 书
零 信 任 实 战 白 皮 书
零 信 任 实 现 方 案
零信任产业标准工作组
对于服务之间调用的零信任实现方式，主要参考Gartner相关报告，但在介绍Gartner的实现方式之前，也
简单说明一下NIST报告早年对于内部隔离方式的划分。与Gartner定义的四种实现方式不同，NIST将传统方式
结合其中，共分为5种，分别为:
a）基于虚拟化宿主机的隔离（Segmentation based on Virtualized Hosts）：将不同安全级别的应用部署
在不同宿主机的虚拟机中，再将宿主机连接至不同物理交换机上，在通过防火墙进行控制。
b）基于虚拟交换机的隔离（Segmentation using Virtual Switches）
c）基于虚拟化防火墙的隔离（Network Segmentation using Virtual Firewalls）
d）在虚拟化网络中使用VLAN进行隔离（Network Segmentation using VLANS in Virtual Network）
e）基于跨平台的网络隔离（Network Segmentation using Overlay-based Virtual Networking）
从以上的划分可以看出，NIST将多种传统的隔离方式进行了列举，具有一定的局限性，毕竟是2015年发
布的报告。数据中心的不断变化以及用户的需求增加都促使隔离技术的发展，2017年Gartner总结了更符合现
代数据中心内部隔离方式，而随着零信任研究的不断深入，这四种方式被广泛接受及引用。本章节主要以参考
Gartner报告的分类为主。
以下为四种工作负载之间隔离的实现方式，不同实现方式也对应了不同的部署方式，没有哪一种方式是最
佳的隔离方案，应根据自身的数据中心环境选择最适合自己的方式。
1）云原生控制
这种路线在虚拟化平台提供者中比较常见。往往在虚拟化平台、IaaS、Hypervisor或基础设施中提供。最
基本的功能非常类似于配置单个主机，更高级的功能往往提供了复杂分组和名称的简单抽象。
4.2.4 实现方式
零 信 任 实 战 白 皮 书
零 信 任 实 战 白 皮 书
零 信 任 实 现 方 案
零信任产业标准工作组
与VLAN一样，云原生控制方式通常适合于隔离，而不是访问控制。服务器之间的隔离往往是东西向访问
控制的要求，安全功能的相对强度通常低于南北向，涉及的是控制而不是隔离流量。