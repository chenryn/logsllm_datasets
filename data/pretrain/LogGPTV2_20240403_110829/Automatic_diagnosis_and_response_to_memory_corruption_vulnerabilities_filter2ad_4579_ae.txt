read
server_loop
do_exec_pty
do_authenticated
do_authentication
main
read
do_authenticated
do_authentication
main
read
do_authloop
do_authentication
main
Figure 4: Message receiving states and respective
call stacks for OpenSSH server
self and waits for any abnormal signals sent to the target
application on the waitpid() system call. Therefore, our
monitor program does not incur any performance overhead
during normal application execution. Only when the target
application has abnormal behavior such as memory access
violation, does the monitor wakes up and runs the diag-
nosis algorithm. The ptrace system interface allows us to
inspect the process machine and memory state and perform
the analysis required by the algorithm.
The signature matching algorithm is implemented using
user space system call tracing and interception. We modi(cid:12)ed
the Unix system utility strace to perform message inspection
and call stack walk. When a message matches the signature,
we insert an error return value to the system calls (e.g., read
and recv ). The server process detects such a return code
as network communication error and drops the connection
before the malicious data reach its address space. Due to
the user-space implementation, we are not able to accurately
assess the performance of the message (cid:12)ltering algorithms.
There are frequent context switches between our (cid:12)lter and
the target server process, and also frequent user/kernel mode
switches to read messages received in the target process.
The overhead of these switches dominates the time for our
experiments. We plan to move the message (cid:12)ltering algo-
rithm to the kernel space in the future and evaluate the
performance implications of associating message signatures
with call stack traces.
In two published results that use kernel level intercep-
tions, the overhead is around 10% even for extreme cases.
In Flashback [36], memory checkpointing and system call
logging together only incur less than 10% overhead in the
worst case for Apache web server. Similarly, in Shield [38],
the more complex state-machine based message (cid:12)lter only
incurs at most 11% throughput degradation itself. We be-
lieve that a kernel space implementation of our algorithms
would not introduce more overhead since our logic is much
simpler.
Currently, due to the user-space implementation of the
message (cid:12)lter, the monitor program and the (cid:12)lter run sep-
arately. Ideally, these two components should run simulta-
neously while the target application is running. Once the
(cid:12)lter is implemented in the kernel space, the integration of
the two can be done easily.
7. EXPERIMENTAL EVALUATION
We discuss our experience using our prototype system and
present experimental evaluation results in this section. We
(cid:12)rst illustrate the bene(cid:12)ts of the automatic bug diagnosis
algorithm using an example, and then present the evaluation
results for the automatic bug diagnosis algorithm and the
response method.
7.1 Automated vs. Manual Diagnosis
The goal of bug diagnosis is to identify the security vulner-
ability that is exploited by an on-going attack, which causes
the application to crash due to address space randomization.
The proposed diagnosis method can identify the attack at
the time of corruption, which is better than methods that
identify the attack at the time of the use of corrupted data.
One of the major bene(cid:12)ts of our method is that, through
automation, it improves the e(cid:14)ciency of problem diagnosis,
which is usually performed manually. While it is di(cid:14)cult to
quantify, we use an example to illustrate the degree of im-
provement. We compare our diagnosis methods to manual
diagnosis using a debugger.
We use a simple stack bu(cid:11)er over(cid:13)ow attack example in an
open source web server ghttpd-1.4. Figure 5 shows the source
code that has a stack bu(cid:11)er over(cid:13)ow vulnerability. The
unchecked stack bu(cid:11)er temp[] is in Log(), which performs
server logging functionalities. Whenever a URL request is
sent to the server, the request handler serveconnection()
calls Log() to log the requested URL. Within Log(), the
message is formatted and written to temp using the C li-
brary function vsprintf() which does not perform bounds
checking. An attacker exploits this bug by sending an ex-
tremely long URL and uses classic stack smashing technique
to take control. Address space randomization will cause a
working exploit to crash the server process.
Log(char *fmt, ...)
{
char temp[200];
...
va_start(ap, fmt); 
vsprintf(temp, fmt, ap);
va_end(ap);
...
}
0x400a0b8c: __GI___mempcpy
0x4006ebf5: _IO_vfprintf_internal
0x40089b2c: _IO_vsprintf_internal
0x0804a40a: Log
... error: stack corrupted ...
0x400a0b8c: __GI___mempcpy
0x4006ebf5: _IO_vfprintf_internal
0x40089b2c: _IO_vsprintf_internal
0x0804a40a: Log
0x08049779: serveconnection
0x08049229: main
0x4003a917: __libc_start_main
(a) Source Code
(b) Call Stack: corrupted & re-constructed
Figure 5: Vulnerability diagnosis for ghttpd
In a manual debug session, a programmer would have few
clues regarding the cause of the crash. We tried running the
server using the symbolic debugger gdb. When the crash oc-
curs, gdb was only able to print the current program counter
register $eip. The value of $eip is largely useless because it
contains a corrupted value passed on from the malicious at-
tack message. It is very di(cid:14)cult to infer the address and type
of the previous instruction that actually causes the crash.
Normally, a programmer can rely on the call stack trace at
the time of crash for further diagnosis. Unfortunately, in
this case, the debugger cannot print the stack trace because
it has already been corrupted due to the attack. Therefore,
using the debugger alone, the diagnosis process would have
taken a substantial amount of time even for experienced pro-
grammers with knowledge of the source code, especially for
large, complex applications.
Our technique improves the e(cid:14)ciency of diagnosis. In the
same example above, at the time of program crash, our an-
alyzer analyzed the memory image of the crashed process,
determined that the crash was due to an indirect control (cid:13)ow
instruction because the register values cr2 and eip match
(i.e., the faulting address and the current PC value match).
The analyzer then forms the candidate set C of all indirect
control (cid:13)ow instructions in the program, and eliminates a
signi(cid:12)cant portion of the candidates through address decod-
ing using the crash image. The analyzer then re-executed
the program to locate the ret instruction within Log() as
the direct cause of the crash. We then used hardware watch-
points to watch the memory locations where the return ad-
dress were stored. Our analyzer caught any instruction that
wrote to that location using invalid address value. The last
instruction that wrote to the location was the corrupting in-
struction. Our tool recorded the call stack trace at the time
of writing (the top trace shown in Figure 5(b)). The top
stack trace in the (cid:12)gure shows that the corrupting instruc-
tion is in the C library function GI mempcpy() with a chain
of C library internal function calls originated from the server
function Log(). Using the instruction address 0x0804a40a
shown, we mapped it to the source code line where the vul-
nerable function vsprintf() is called ( IO vsprintf internal
is the library symbol for vsprintf). This entire process was
automated and done without application speci(cid:12)c knowledge,
and certainly improved the debugging and diagnosis process
signi(cid:12)cantly.
The top stack trace in Figure 5(b), however, is not com-
plete: the callers beyond Log() cannot be recovered. This
is because the attack has corrupted a substantial portion
of the call stack beyond the stack frame of Log() (stack
grows downward). A critical component among those cor-
rupted is the saved frame pointer which points to the stack
frame of the caller of Log(). While the partial stack trace
is in itself invaluable, a complete call stack trace would be
preferred. The complete stack trace is re-constructed by
combining the call stack trace at the entrance of the li-
brary function
GI mempcpy() and the partial stack trace
as shown in bottom on of Figure 5(b) at the time of corrup-
tion (and hardware watchpoint exception). The complete
stack trace shows the circumstance under which corruption
occurs. In addition, the reconstructed stack trace also shows
the function call arguments and their values (not shown in
the (cid:12)gure), which can facilitate further diagnosis.
7.2 Effectiveness of Diagnosis
We use a number of real world network service applica-
tions to evaluate the e(cid:11)ectiveness of the method. For a given
application P , we (cid:12)rst search for the publicly reported mem-
ory corruption vulnerabilities. We then (cid:12)nd exploits against
the identi(cid:12)ed vulnerabilities. This second step is very time-
consuming but can usually be accomplished by using exist-
ing exploit programs on the Internet.
The e(cid:11)ectiveness evaluation is focused on the following
question: How precisely can our method automatically iden-
tify the function where the original memory corruption vul-
nerability is located? In our experiments, we (cid:12)rst recover the
call stack trace at the time of memory corruption using the
diagnosis algorithm, and then compare it to the call stack
trace retrieved by manual code inspection and debugging.
A number of real world network applications with di(cid:11)erent
types of memory corruption vulnerabilities are used in our
evaluation. For the tested applications, we were able to cor-
rectly identify all the vulnerable functions at the time of
corruption. The applications tested in our experiments are
in Table 1.
Table 1: Tested server applications
Description
web server
NFS stat server
Program
ghttpd
rpc.statd
OpenSSH secure shell server
icecast
Samba
media streaming svr
(cid:12)le and print service
Vuln./Attack Type
bu(cid:11)er over(cid:13)ow
format string
integer over(cid:13)ow
bu(cid:11)er over(cid:13)ow
bu(cid:11)er over(cid:13)ow
We have also evaluated the idea using the ghttpd web
server. The tra(cid:14)c is generated using Spec-Web99 bench-
mark using the static get suite. We were not able to detect
any match for the generated signature. A possible reason is
that the incoming tra(cid:14)c to the web server are mostly plain
text URLs, which do not match the binary attack signature.
The false positive results are listed in Table 2. The Pure
message signature line uses only pattern sequence as signa-
ture. The Correlated message (cid:12)ltering line is the proposed
method that associates pattern with call stack trace.
Table 2: Number of false positives
Signature Type
Pure message signatures
Correlated message (cid:12)ltering
OpenSSH ghttpd
1245
0
0
0
One application examined in our experiments is worth fur-
ther discussion. The vulnerability in the OpenSSH server is
a signed integer over(cid:13)ow. In the server function detect attack(),
a 32-bit integer value l is assigned to a 16-bit variable n. The
cast from 32- to 16-bit makes n=0 under attack. The value
n-1 (which is 0xffff) is subsequently used to mask variable
i (retrieved from the attack message) that is used to index
an array h[]. Because n-1 does not have any e(cid:11)ect on the
masking operation, attackers can force h[i] to be arbitrary
address values. The crash in the randomized system occurs
when h[i] is accessed. Our analyzer can correctly locate the
vulnerability to the function detect attack(). However,
currently, we cannot automatically identify this as an inte-
ger over(cid:13)ow vulnerability due to lack of type information.
More accurate diagnosis requires additional investigation.
7.3 Evaluation of Automatic Response
Once signatures are generated, the (cid:12)ltering of attack traf-
(cid:12)c is pretty straightforward. Thus, our evaluation in this
part is focused on the quality of the generated signatures,
especially the false positive rate.
In particular, we would
like to see how much improvement we can get using corre-
lation of message signature with program execution state.
We used two server applications with which we were able to
run large scale experiments for evaluation: OpenSSH server
and the ghttpd web server.
In the (cid:12)rst case, we run a secure shell session using the
OpenSSH server to transfer 21 gigabytes of data. The data
includes all the (cid:12)les in Fedora Core 3 Linux and the home di-
rectory in our lab. The transferred (cid:12)les include text, source
code, application and library binaries, as well as many im-
age, video and audio (cid:12)les. We used the signature we gener-
ated for the vulnerable OpenSSH server in the message (cid:12)l-
ter and evaluated the alerts reported by the (cid:12)lter. Without
using the call stack information, our message (cid:12)lter reported
1245 signature matches for the 21 gigabyte of encrypted data
transfer. Since the data transferred are not attack messages,
these alerts are all false positives. Using the program call
stack information together with the message signature, all
false alerts were eliminated. This is because the alerts are
all reported in the data receiving state as shown in Figure 4,
while the recorded attack messages are against the passwd
receiving state. This shows that the call stack trace is an
e(cid:11)ective way to discriminating di(cid:11)erent execution states for
OpenSSH sever.
The experience running the web server did lead to a caveat
in using call stack trace as program semantic state to im-
prove pattern-based signature matching. Applications such
as OpenSSH that run complex protocols can bene(cid:12)t greatly
from the use of call stack trace. This is because complex
protocol implementations are typically structured in a way
that models its internal execution state transitions. There-
fore, using call stack can clearly discriminate between dif-
ferent server receiving states. The bene(cid:12)t of using call stack
is less clear for simple protocols such as HTTP that has