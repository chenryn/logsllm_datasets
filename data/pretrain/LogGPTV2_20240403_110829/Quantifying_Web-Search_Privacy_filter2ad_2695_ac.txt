Features extracted about each query event represent the
information about a single web-search action by the user
independently from her other actions.
In this section, we
seek to ﬁnd the relation between multiple web-searches. To
this end we compare the features of pairs of query events by
computing the distance or the similarity between them [36].
We compare the query features in Table 2 and we derive 27
relations between them. Again, we group these relational
features into semantic and behavioural. Table 3 lists these
relations and their brief descriptions.
The behavioural relations capture e.g., the time diﬀerence
between two queries or whether they are issued on the same
day of the week or hour of the day. Two queries can be
associated with diﬀerent intentions of the user if they are is-
sued during a weekday or the weekend. The same applies to
diﬀerent hours of the day. In addition, the number of clicks
on the search result URLs (landing pages) might reﬂect the
interest of the user in the topic or her overall behaviour.
In the case of semantic features, we compute the relation
between a pair of queries with respect to the query terms,
and the content and topics of the landing pages. We make
use of Levenshtein edit distance [25] to compute the dif-
ference between the terms in two queries.3 This distance
should usually be small between queries that are issued im-
mediately after each other, as users repeat or modify their
queries to narrow down the search results. We also use the
Jaccard coeﬃcient [5] (JaccardC) to compute the similarity
between the vectors of term frequencies in a query or in a
document. This approximately reﬂects what fraction of the
terms are common between two queries or documents.
In order to compute the distance between two landing
pages, we also make use of the standard information re-
trieval techniques to compare the relative importance of the
terms in a document to another. We compute the term-
frequency/inverse-document-frequency (TFIDF) metric [29].
This requires us to have a representative document frequency
database. Google provides an extensive dataset of unigrams
from about 8 million books [6]. By preprocessing the database
(e.g. ﬁltering non-alpha terms), we extracted 3,113,114 terms
with their associated document frequency. The TFIDF met-
ric associates more importance to the terms that are speciﬁc
to the document that is analyzed, rather than the terms that
appear frequently in all documents.
With these diﬀerent metrics, we capture various diﬀerent
aspects of the relation between two queries or two landing-
pages. We also compute how diﬀerent two queries are in
terms of the topics associated to their search results. The
ODP ontology enables us to derive such measures. Every
category in the ontology has a path to the root. Having
calculated the ODP categories of two queries, one relation
metric we consider is if the queries share a common level 2
or 3 ODP category. Having the path from the root to the
leaf category, we also calculate the tree distance from the
leaf category associated to one query to that of the other
query. Note that a query might be associated to several ODP
categories.
In this case, we calculate the average distance
between them.
3The Levenshtein edit distance is a metric which counts the
number of changes that needs to be performed (insertion,
subtitution, deletion of characters) between two strings un-
til they are equal. Consequently, two equal strings have a
Levenshtein distance of zero.
4. LINKAGE ANALYSIS
In this section, we discuss the methodology of the linkage
attacks. We build upon the adversary’s prior knowledge,
namely (1) the users’ search behaviour model and (2) the
obfuscation mechanism. The key idea is to learn a linkage
function that predicts the relation between two queries; more
precisely whether they are issued by the same target user
or not. We use machine learning techniques to learn this
linkage function which generalizes our framework for any
new obfuscation mechanisms or other datasets. We use this
linkage function as the basis for the linkage attack where we
run a clustering algorithm to partition the set of observed
queries. We quantify the error of the linkage attack which
reﬂects the privacy level of the attacked user.
4.1 Linkage Function
The objective of the linkage attack is to identify which ob-
served queries belong to the target user and which of them
are fake (i.e. inserted by the obfuscation mechanism). Recall
that the obfuscation mechanism can introduce fake queries
by auto-generating them from a bag-of-words or by sampling
them from other real users. Irrespective of the type of ob-
fuscation, the key is to have a function that predicts if two
observed queries are from the same user, i.e., they are link-
able. To construct such a linkage function, we build upon
the users’ web search behaviour and their inter-similarities
and dissimilarities with respect to the fake queries. In the
following, we describe our methodology for learning the link-
age function.
4.1.1 Training Data and Linkage Features
We assume that the adversary has access to HG, historic
logs of web search activities for a set of users. For the case
of obfuscation using queries from another user, for any pair
of users ua, ub present in HG, we can consider ua being
target user whose search activity is obfuscated by using the
query events from ub. For the case of obfuscation by auto-
generated queries from bag-of-words (TMN), we assume that
the adversary has access to additional sets of these auto-
generated queries HF . In this case, for any user ua present
in HG, we can consider ua as target user whose search activ-
ity is obfuscated by using the query events from HF . Conse-
quently, irrespective of the type of obfuscation mechanism,
we can generate a labeled pairwise list of query events ei, ej .
Hereby, we set the linkage value to 1 if the queries are issued
from the target user ua, and 0 if one query is issued by the
target user ua while the other is added by the obfuscation
mechanism. We denote this assigned linkage label by yi,j.
Given this dataset consisting of pairwise lists of query
events ei, ej along with the assigned label yij with value
of 1 or 0, we extract the features that are listed in Table 2
for each of the query events in this data. We follow to ﬁnd
the relation between (the features of) any two queries and
their predictive power with respect to the assigned label yi,j .
Informed by these per query features, we designed a set of
pairwise features that can capture the similarity or dissimi-
larity between two query events. We use the list of features
(functions) in Table 3 to compute the relation between each
pair of features of two given queries, as discussed in Sec-
tion 3.
Let lf
i,j be the similarity between two query events ei and
ej with respect to feature f . We can compute this similarity
for every feature f given in Table 3. For all the pairs of
queries ei, ej in our training dataset, we compute the vector
of feature similarities link(lf
i,j : ∀f ) and label this feature
vector with label yi,j. Given this training data, we learn
the linkage function, denoted by L(ei, ej) that gives a score
on whether the two queries could have been issued from the
same user.
4.1.2 Learning the Linkage Function
While we could apply simple heuristics on how to best
combine these diﬀerent similarity scores, we decided to take
advantage of machine learning based regression analysis to
automatically learn the weight of diﬀerent features. More
precisely, our goal is to construct the linkage function that
can later take as input the set of feature similarities link(lf
i,j :
∀f ), for some pair of query events ei and ej and outputs the
linkage score.
In general, there might not be any linear relation be-
tween the features’ similarities and the linkage between two
queries.
In fact, depending on the (dis)similarity of two
queries with respect to one feature, the importance of the
other features to determine the linkage of queries diﬀers. For
example, the size of the intersection set of terms used in two
queries is of great importance when the two queries are is-
sued within a small time window. This is because the user
is narrowing down her search using almost the same search
terms. However, the similarity between the topics of re-
trieved documents is very important even when two queries
are distant in time. This is because the user is interested
in few topics that she searches about over time. Thus, the
regression function must learn the complex relation between
diﬀerent features in order to predict the linkage value. To
this end, we make use of the Gradient Boosted Regression
Trees (GBRT) technique [19, 18]. This gradient boosting
algorithm produces an ensemble of small predictors as deci-
sion trees that all together form a strong prediction model.
Gradient tree boosting methods for regression and classi-
ﬁcation have various advantages including their robustness
against noisy data and interpretability of the learnt model
(e.g., a ranked list of feature importance) [36, 34].
The linkage function is learned as a stochastic decision
tree, so it captures the importance of diﬀerent feature simi-
larities in linking queries. For our example obfuscations, we
generate the appropriate training data and learn the corre-
sponding linkage functions to be used for the attack. Let
LU SR and LT M N denote the linkage functions learned for
obfuscation with queries from another user and with auto-
generated queries from bag-of-words, respectively. Table 4
and Table 5 present the sorted list of top feature similari-
ties and their normalized importance for these linkage func-
tions.Those that appear on top are more important in the
sense that knowing their values provide a stronger signal in
computing the linkage value, as per the training data.
4.1.3 Aggregation over multiple Linkage Functions
The framework of using the machine learned linkage func-
tion gives us a lot of ﬂexibility to further increase the robust-
ness of the attack. In fact, the adversary can learn multiple
of these linkage functions by varying the parameters, using
diﬀerent data sets or even diﬀerent algorithms. This further
enables the adversary to operate even when he has limited
knowledge of the parameters of obfuscation mechanism.
In our setting, we consider learning a set of such linkage
functions from a given dataset, by generating the training
data from HG for various diﬀerent target users ua. Let us
consider that the adversary has learned a set of r diﬀerent
linkage functions denoted by {L1, L2, . . . , Lr}. Given these
linkage functions, we can consider diﬀerent ways of aggre-
gating their output to generate the ﬁnal link score. For
example, one can compute some aggregate statistics (e.g.
median or mean) of the linkage score outputted by this set
of functions to use as the ﬁnal linkage score for a pair of
queries for the clustering attack on it. On the other hand,
one can compute the result of clustering for every linkage
function separately, and then link together two queries if
majority of the clustering solutions put these queries into
the same cluster.
The speciﬁc aggregation scheme that we use in our ex-
periments is using the median of the link scores outputted
by Lj ∀ j ∈ [1 . . . r]. We use median as compared to other
statistics such as mean, as it is more robust to outlier values.
Further, we discuss in Section 5 how using such an aggre-
gation based linkage function can increase the robustness of
the linkage attack.
4.2 Linkage Attack
Given the linkage function L(ei, ej) learned by the adver-
sary, we run a linkage attack on the set SO. The goal is
to separate the query events of the target user and those
added by the obfuscation mechanism. Therefore, we com-
pute all the features of all query events in SO and for each
pair of queries ei, ej ∈ SO, we compute the pairwise simi-
larity L(ei, ej) between them. Having computed Lei ,ej for
all ei, ej ∈ SO, we have a complete weighted graph where
query pairs with higher weight on their connecting edges
have a higher tendency to link together. We build upon this
inferred weights for the graph for the linkage attack which
aims to link the queries of the user together. Moreover, we
split the set of queries into multiple clusters. Our objective
is to maximize the intra-cluster similarities (i.e., between
queries within each cluster) and minimize the inter-cluster
similarities (i.e., between queries in diﬀerent clusters). We
make use of the CLUTO clustering toolkit for the implemen-
tation of the attack [7, 36]. Using CLUTO, we run k-means
clustering optimizing the following objective function:
k
min
X
n2
i
i=1
Pq∈Si,q′ ∈SO
L(q, q′)
Pq,q′ ∈Si
L(q, q′)
(1)
The output of the linkage attack is a set of clusters, given
by C(SO, L, k) = {S1, S2, . . . , Sk}. This output is then used
to quantify the privacy of users for various diﬀerent metrics,
as discussed in Section 2.
Firefox plug-in, and we generate their corresponding TMN
fake traces. Regarding the USR obfuscation method, we se-
lect any of the 100 user traces to be used as the fake trace.
We run the experiments by adding USR fake traces 20 times,
each time selecting the fake trace at random from the 100
available traces. We evaluate the user’s privacy by averaging
it over these 20 cases.
To construct the adversary’s background knowledge, we
consider that the adversary can run the obfuscation mech-
anism and generate fake traces for selected real traces. We
assume that the attacker does not necessarily need to know
the details of the obfuscation mechanism, but tries to infer
it. Further, we deﬁne the query history that is available to
the attacker. In our experiment, we assume that the adver-
sary does not have access to the target user’s search history,
i.e., HU = ∅. However, we assume that attacker has ac-
cess to some queries of the AOL users other than the target
user. In our experiment, we choose the ﬁrst 130 queries of
the 100 users. He also knows the TMN fake traces that are
generated for other users. From these datasets, we learn the
linkage functions.
As discussed in Section 4, the adversary does not know
a priori which set of query traces from his history set HG
will result in a better accuracy on a target user. In addition,
learning a single linkage function from all query traces in HG
might not necessarily result in the best accuracy. To this
, · · · , LT M N
end, we construct 60 linkage functions (LT M N
)
from diﬀerent sets of TMN traces, and the same number
of linkage functions from diﬀerent sets of the AOL traces
(LU SR
, · · · , LU SR
60
1
1
60
).
For each target user and obfuscation we run the linkage at-
tack using all the linkage functions learned from other users
(i.e., those Lis that are not learned from the target user in
our dataset). Then, we aggregate the linkage function as
described in Section 4 by computing their median value for
each pair of queries. A comparison between the clustering
error of adversary, using the median aggregation, and that
of each individual linkage attack in our dataset shows that
in 61% of the cases the aggregate linkage function performs
better than 2/3 of the individual linkage functions and re-
sults in a lower error for the attacker.
To compute the query structure privacy and semantic pri-
vacy, we run the linkage attack to split SO into 2 clusters.
However, for computing the query structure relative privacy,
we run the attack with 10 clusters to better capture the
randomness of user’s web-search behavior reﬂected in her
queries. The concentration of queries in few clusters shows
the user’s proﬁle in terms of a distinct combination of query
features e.g., diﬀerent topics of interest.
5. EVALUATION
5.2 Results
In this section, we use our quantitative methodology to
evaluate the privacy of a user with respect to two example
obfuscation methods that we discussed in Section 2: (TMN)
method that generates fake queries from a bag of text, and
(USR) method that generates fake queries by reusing all
queries of another real user.
5.1 Setup
As described in Section 3.2, we use a dataset that con-
tains queries of 100 AOL users that we protect using both
TMN and USR obfuscation mechanisms. We simulate the
web-search activities of each of the target users using our
Figure 2 shows the absolute as well as the relative user
privacy with respect to their query structure privacy. The
x-axis shows the privacy value in terms of the normalized
false positive and false negative errors. The y-axis in all
the plots is the cumulative fraction of user and shows the
fraction of users who all gain at least the privacy level on
the x-axis.
By observing the query structure privacy (left part of ﬁg-
ure 2), we can see that TMN oﬀers a better privacy protec-
tion than the USR obfuscation method, and this superiority
is almost at the same level across the whole set of users. As
we described in section 2.5 however, we also need to quantify
s
r
e
s
U
f
o
n
o
i
t
c
a
r
F
e
v
i
t
l
a
u
m
u
C
s
r
e
s