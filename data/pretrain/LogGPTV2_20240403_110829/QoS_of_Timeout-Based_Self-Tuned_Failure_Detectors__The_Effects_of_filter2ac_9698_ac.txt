1
k
(
H
k
transition
[
t
+
−
]2
H
k
transition
][
t
)
/(
n
−
)1
for  all  t  <  2(n-1)  |  t=2,4,6,...  .  The  derived  metrics  λ
(Average  Mistake  Rate)  and  PA    (Query  Accuracy 
Probability)  are  computed  by  λ  =  1/E(TMR)  and  PA  = 
(E(TMR) - E(TM))/E(TMR), where E(TMR) and E(TM) are 
the expected values of the random variables TMR and TM,
respectively. 
5. Evaluating the QoS 
This section is structured in two parts, which aim at 
answering the following questions:  
i) Does the QoS of a failure detector increase when 
we  change  from  an  inaccurate  communication 
delay predictor to an accurate one? 
ii) Is the combination predictor-margin important to 
the QoS of a failure detector? 
5.1. About predictor effects 
To  answer  the  first  question,  firstly  we  need  to 
identify which predictors are accurate and which are not. 
Therefore, we investigated this point in [17] by using the 
following  methodology:  initially,  we  collected  traces 
that correspond to real behavior of a wide area network; 
and after we measured the accuracy of several predictors 
in this scenario (using the collected traces as inputs) and 
evaluated these results using statistical tools.  
To  attain  the  first  step,  we  used  a  pull-style 
monitoring program between three pairs of Internet hosts 
UFRGS-POP/PA 
and 
(UFRGS-UFCG, 
UFRGS-UFSM).  The  hosts  belong  to  universities 
placed in the Northeast (Federal University of Campina 
Grande – UFCG), North (the access point of Pará State 
–  POP/PA)  and  South  (Federal  University  of  Rio 
Grande  do  Sul  –  UFRGS  and  Federal  University  of 
Santa Maria – UFSM) Brazilian regions, which differ 
by their features. The link UFRGS-UFCG is a fast link 
when  compared  with 
link 
UFRGS-POP/PA  presents  a  big  delay  variance;  and 
UFRGS-UFSM is an unstable link (variance and speed 
change a lot).  
two  others.  The 
the 
Our monitoring program sends one req message per 
second to the remote host and observes the round-trip 
time  of 
this 
handshaking protocol, we collected 17 working day rtt
traces, each one with 18-hour length (~64800 samples 
from 6 a.m. to 24 p.m.). 
the  received  ack  messages.  From 
Using  these  traces,  we  evaluated  the  accuracy  of 
three  communication  delay  predictors  (specified  in 
Section  3.2).  From  [17],  we  concluded  that:  the 
predictors based on arithmetic average, like MEAN and 
WINMEAN, do not offer good accuracy in predicting 
the  round-trip  time,  whereas  the  predictor  ARIMA 
offers a good accuracy. In fact, other predictors studied 
in our previous research (LAST, LPF, and BROWN)1
do not differ significantly from the ARIMA predictor, 
considering statistical test at 5%, but among them, the 
time series predictor (ARIMA) offers the most accurate 
predictions.  
From  these  results  on  the  accuracy  of  the  studied 
predictors, we are able to evaluate their effects on the 
QoS of the failure detectors. In this paper, we consider 
three  predictors:  MEAN,  WINMEAN  and  ARIMA, 
which stand for bad, medium and good accuracy levels 
respectively.  In  the  following,  we  propose  Lemma  1 
and reason about it. 
Lemma  1: On  a  timeout  based  self-tuned  failure 
detector,  improving  the  accuracy  of  predicting  the 
communication  delay  does  not  necessarily  imply  the 
increase of the detection speed.  
We will show that there is not a straight connection 
between accuracy and time to detect a failure, in order 
to  demonstrate  this  Lemma  1.  For  this  purpose,  we 
made  experiments  using  a  data  set  of  680  traces  of 
3600-length samples each, randomly extracted from the 
17 working day rtt traces. For our experiments, we used 
three  pull-style 
failure 
timeout-based  self-tuned 
1 From [17], the predictor LAST assumes that the next delay follows 
the last one; the predictor LPF presumes that the next sample follows 
a low-pass filter (given by an exponential weight average – the TCP 
method [13]); and the predictor BROWN assumes a non-stationary 
behavior  following  a  linear  trend  model  (it  works  as  a  double 
low-pass filter).
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:29:59 UTC from IEEE Xplore.  Restrictions apply. 
detectors  that  differ  only  by  the  communication  delay 
predictor. We called them by the nicknames: MEAN_FD, 
WINMEAN_FD  and  ARIMA_FD,  that  indicate  the 
predictor each one encloses. After that, we measured the 
accuracy of the predictors using that data set. The results 
(Table 1) show significant differences among the diverse 
predictor  accuracy.  The  best  accuracy,  given  by  the 
mean square error (mse) and the Duncan’s grouping of 
each  predictor,  points  to  the  ARIMA  predictor.  From 
Duncan’s test, if any two predictors differ by more than 
5%,  it  means  that  their  results  differ  significantly 
considering means and variances.  
Table 1. Accuracy of studied predictors 
Predictor 
MEAN 
WINMEAN 
ARIMA 
mse 
52019 
17002 
10815 
Duncan’s 
grouping  
A 
B 
C 
u
For the three failure detectors implemented from the 
three predictors listed in Table 1, we computed the speed 
metrics  DT  and 
DT  (see  Table  2).  To  compare  the 
implementations,  we  used  the  algorithm  described  in 
Figure  2,  with 
in  all 
computations: a constant safety margin empirically set to 
400ms.  In  table  2,  the  Duncan’s  grouping  is  pointed 
between parentheses.  
identical  safety  margin 
Table 2. Speed QoS metrics for three predictors 
with identical constant safety margin 
Failure Detector 
MEAN_FD 
WINMEAN_FD 
ARIMA_FD 
DT
1.642 (A) 
1.652 (A) 
1.652 (A) 
u
DT
1.839 (C) 
2.014 (B) 
2.216 (A) 
The results (Tables 1 and 2) allow to observe that an 
accurate predictor does not ensure a better performance – 
regarding its speed – for the failure detector where it is 
incorporated. On the contrary, one can observe that the 
detector  ARIMA_FD,  even  using  a  more  accurate 
predictor  (ARIMA  predictor),  exhibits  the  worst-case 
detecting 
the  detector 
MEAN_FD.  Similar  behavior  can  be  observed  on  the 
time  when  compared 
to 
results 
increasing 
u
DT ).  MEAN_FD 
upper  bound  of  the  detection  time  (
presents  better 
than  ARIMA_FD  and 
WINMEAN_FD.  Thus,  from  a  performance  point  of 
view, 
the  predictor 
associated  to  a  failure  detector  does  not  guarantee  a 
better failure detection time, which allows us to confirm 
Lemma 1.  
the  accuracy  of 
Now, consider the following lemma: 
Lemma  2: On  a  timeout  based  self-tuned  failure 
detector,  increasing  the  accuracy  of  communication 
delay  prediction  will  induce  the  enhancement  of  the 
failure detector accuracy.  
In  the  following,  we  will  show  that this lemma  is 
false. Using the same preceding three detectors (Table 
2), we computed the accuracy metrics TM, TMR, λ and 
AP  with the same data set and environment conditions. 
The results are shown in Table 3.  
In practice, a failure detector interacts with its client 
by calling it back whenever the FD detects a change in 
its  own  state  or  by  receiving  a  request  to  inform  its 
internal  state.  At  the  first  interaction  approach,  the 
average mistake rate λ is an important metric, whereas 
at the second one, the query accuracy probability PA is 
important. From Table 3, we observe that enhancing the 
accuracy of the communication delay predictor implies 
the increasing of both practical accuracy metrics of the 
failure detector. 
On the other hand, a failure detector FDi only can be 
pointed out as more accurate than other failure detector 
FDj if both results TM and TMR are better [5]. From Table 
3, the TMR values show that an accurate predictor helps 
the failure detector to increase the mistake recurrence 
time; but, from TM values, longer mistake duration may 
be  associated  to  the  use  of  accurate  predictors. 
Consequently, these results allow to refute Lemma 2.  
Finally,  from  the  results  of  this  section,  the 
following  theorem  describes  the  relation  between 
predictor accuracy and failure detector accuracy: 
Theorem  1: On  a  timeout  based  self-tuned  failure 
detector,  increasing  the  accuracy  of  communication 
delay  prediction  does  not  guarantee the enhancement 
of the QoS.
Proof: Follows the demonstration of Lemma 1 and the 
refutation of Lemma 2. □
Table 3: Accuracy metrics for three predictors with identical constant safety margin 
Failure Detector 
MEAN_FD 
WINMEAN_FD 
ARIMA_FD 
MT
0.380 (B) 
0.501 (A) 
0.499 (A) 
MRT
283.270 (B) 
481.159 (A) 
495.594 (A) 
λ
0.003530 
0.002078 
0.002018 
AP
0.998658 
0.998959 
0.998993 
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:29:59 UTC from IEEE Xplore.  Restrictions apply. 
5.2. Effects of the combination predictor-margin 
In  Section  5.1,  we  have  fixed  the  safety  margin  to 
evaluate  the  effects  of  the  prediction  accuracy  on  the 
failure detector QoS. In this Section, we will evaluate the 
QoS  considering  different  combinations  of  predictors 
and  variable  safety  margins.  We  explore  two  variable 
safety  margin  strategies:  the  prediction  error  based 
strategy  (margin  peb)  and  the  estimator  confidence 
interval based strategy (margin cib).  
Using  different  strategies,  we  can  explore  different 
margin  behaviors.  Based  on  the  prediction  error,  the 
margin peb is large when the associated predictor is not 
accurate and small when it is accurate. On the other side, 
based on the estimation distribution function, the margin 
cib does not change significantly  when varying from a 
non-accurate predictor to an accurate one. It assumes that 
the prediction error is a write noise (Section 3.3). These 
features  allow  us  to  evaluate:  how  important  is  the 
choice of the  safety  margin  and  how  much  this choice 
depends on the predictor. They also allow us to answer 
the main question: Is the combination predictor-margin 
significant to the QoS of a failure detector?
the 
are  organized  with 
Taking  into  account  the  same  data  set  applied  in 
Section  5.1  and  the  same  three  predictors  that  differ 
significantly  by  their  accuracy  (Table  1),  the  next 
paragraphs 
following 
methodology. First, we investigate the speed metrics for 
each  combination  predictor–margin  and  show  that  the 
choice of the margin generates a considerable impact on 
the speed of the failure detector. Second, we analyze the 
effect on the accuracy of failure detectors and show that 
the  margin  also  influences  the  accuracy;  and  that  this 
effect  depends  on  the  used  communication  delay 
predictor.  Third,  we  reflect  on  both  the  speed  and 
accuracy  issues  and  show  that  some  combinations 
increase significantly the average mistake rate. 
About speed issues 
The  speed  to  detect  a  failure  computed  for  each 
detector  under  the  safety  margins  peb  and  cib  is 
presented in Table 4. From the TD magnitude, we may 
observe that margin cib is smaller than the margin peb, in 
general.  In  other  words,  when  the  prediction  error  is 
large,  the  margin  peb  is  also  large,  increasing  the  TD
value.  Only  the  accurate  predictor  ARIMA  results  in 
small margin peb. The magnitude of margin cib changes 
very  slightly,  when  altering  from  a non-accurate  to  an 
accurate predictor; consequently its application results in 
similar TD for all the three failure detectors, in the same 
way  of  using a  constant  margin.  In  summary,  from  TD
values, the use of a conservative margin, like cib margin, 
allows  to  make  use  of  any  predictor.  However,  if  a 
margin peb is used, the predictor should be accurate. 
u
When  considering  the  upper  bound  of  the time  to 