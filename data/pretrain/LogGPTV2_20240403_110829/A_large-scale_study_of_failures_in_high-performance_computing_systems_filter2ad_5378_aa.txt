title:A large-scale study of failures in high-performance computing systems
author:Bianca Schroeder and
Garth A. Gibson
A large-scale study of failures in high-performance computing systems
Bianca Schroeder
Garth A. Gibson
Computer Science Department, Carnegie Mellon University
Pittsburgh, PA 15217, USA
{bianca,garth}@cs.cmu.edu
Abstract
Designing highly dependable systems requires a good
understanding of failure characteristics. Unfortunately, lit-
tle raw data on failures in large IT installations is publicly
available. This paper analyzes failure data recently made
publicy available by one of the largest high-performance
computing sites. The data has been collected over the past
9 years at Los Alamos National Laboratory and includes
23000 failures recorded on more than 20 different systems,
mostly large clusters of SMP and NUMA nodes. We study
the statistics of the data, including the root cause of fail-
ures, the mean time between failures, and the mean time to
repair. We ﬁnd for example that average failure rates differ
wildly across systems, ranging from 20–1000 failures per
year, and that time between failures is modeled well by a
Weibull distribution with decreasing hazard rate. From one
system to another, mean repair time varies from less than an
hour to more than a day, and repair times are well modeled
by a lognormal distribution.
1 Introduction
Research in the area of dependable computing relies in
many ways on a thorough understanding of what failures
in real systems look like. For example, knowledge of fail-
ure characteristics can be used in resource allocation to im-
prove cluster availability [5, 25]. The design and analysis of
checkpoint strategies relies on certain statistical properties
of failures [8, 21, 23]. Creating realistic benchmarks and
testbeds for reliability testing requires an understanding of
the characteristics of real failures.
Unfortunately, obtaining access to failure data from
modern, large-scale systems is difﬁcult, since such data is
often sensitive or classiﬁed. Existing studies of failures are
often based on only a few months of data, covering typically
only a few hundred failures [19, 24, 16, 18, 15, 7]. Many
of the commonly cited studies on failure analysis stem from
the late 80’s and early 90’s, when computer systems where
signiﬁcantly different from today [3, 4, 6, 13, 19, 9, 11].
Finally, none of the raw data used in the above studies has
been made publicly available for use by other researchers.
This paper accompanies the public release of a large set
of failure data [1]. The data was collected over the past
9 years at Los Alamos National Laboratory (LANL) and
covers 22 high-performance computing (HPC) systems, in-
cluding a total of 4750 machines and 24101 processors. The
data contains an entry for any failure that occurred during
the 9-year time period and that required the attention of a
system administrator. For each failure, the data includes
start time and end time, the system and node affected, as
well as categorized root cause information. To the best of
our knowledge, this is the largest set of failure data studied
in the literature to date, both in terms of the time-period it
spans, and the number of systems and processors it covers.
Our goal is to provide a description of the statistical
properties of the data, as well as information for other re-
searchers on how to interpret the data. We ﬁrst describe
the environment the data comes from, including the sys-
tems and the workloads, the data collection process, and
the structure of the data records (Section 2). Section 3 de-
scribes the methodology of our data analysis. We then study
the data with respect to three important properties of system
failures: the root causes (Section 4), the time between fail-
ures (Section 5) and the time to repair (Section 6). Section 7
compares our results to related work. Section 8 concludes.
2 Description of the data and environment
2.1 The systems
The data spans 22 high-performance computing sys-
tems that have been in production use at LANL between
1996 and November 2005. Most of these systems are
large clusters of either NUMA (Non-Uniform-Memory-
Access) nodes, or 2-way and 4-way SMP (Symmetric-
Multi-Processing) nodes. In total the systems include 4750
nodes and 24101 processors. Table 1 gives an overview of
the 22 systems.
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:29:50 UTC from IEEE Xplore.  Restrictions apply. 
(I) High-level system information
(II) Information per node category
2.2 The workloads
HW ID
Nodes
Procs
A
B
C
D
E
F
G
H
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
1
1
1
164
256
128
8
32
4
328
1024
512
1024
4096
1024
4096
128
128
128
32
128
256
256
256
256
512
16
49
5
1
512
512
512
128
256
512
512
512
512
1024
2048
6152
544
256
Procs
/node
8
32
4
2
2
4
4
4
4
4
4
4
4
4
4
4
4
4
4
2
2
2
2
2
2
2
128
128
128
128
80
128
32
128
128
256
Production
Time
N/A – 12/99
N/A – 12/03
N/A – 04/03
04/01 – now
12/02 – now
12/01 – now
09/01 – 01/02
05/02 – now
05/02 – now
05/02 – now
05/02 – now
10/02 – now
10/02 – now
10/02 – now
09/03 – now
09/03 – now
09/03 – now
09/03 – now
09/03 – now
09/03 – now
09/03 – now
09/03 – now
09/03 – now
09/03 – now
09/03 – now
03/05 – 06/05
12/96 – 09/02
12/96 – 09/02
01/97 – now
01/97 – 11/05
06/05 – now
10/98 – 12/04
01/98 – 12/04
11/02 – now
11/05 – 12/04
11/04 – now
Mem
(GB)
16
8
1
1
1
16
16
8
16
32
352
8
16
32
4
4
4
4
16
4
4
4
4
4
4
4
32
64
128
32
80
128
16
64
32
1024
NICs
0
1
0
1
1
2
2
2
2
2
2
2
2
2
1
1
1
1
1
1
1
1
1
1
1
1
4
4
12
12
0
4
4
4
4
0
Table 1. Overview of systems. Systems 1–18 are
SMP-based, and systems 19–22 are NUMA-based.
The left half of Table 1 provides high-level information
for each system, including the total number of nodes and
processors in the system, and a system ID we use through-
out to refer to a system. The data does not include vendor
speciﬁc hardware information. Instead it uses capital letters
(A-H) to denote a system’s processor/memory chip model.
We refer to a system’s label as its hardware type.
As the table shows, the LANL site has hosted a diverse
set of systems. Systems vary widely in size, with the num-
ber of nodes ranging from 1 to 1024 and the number of pro-
cessors ranging from 4 to 6152. Systems also vary in their
hardware architecture. There is a large number of NUMA
and SMP based machines, and a total of eight different pro-
cessor and memory models (types A–H).
The nodes in a system are not always identical. While all
nodes in a system have the same hardware type, they might
differ in the number of processors and network interfaces
(NICs), the amount of main memory, and the time they were
in production use. The right half of Table 1 categorizes the
nodes in a system with respect to these properties. For ex-
ample, the nodes of system 12 fall into two categories, dif-
fering only in the amount of memory per node (4 vs 16 GB).
Most workloads are large-scale long-running 3D sci-
entiﬁc simulations, e.g. for nuclear stockpile stewardship.
These applications perform long periods (often months) of
CPU computation, interrupted every few hours by a few
minutes of I/O for checkpointing. Simulation workloads are
often accompanied by scientiﬁc visualization of large-scale
data. Visualization workloads are also CPU-intensive, but
involve more reading from storage than compute workloads.
Finally, some nodes are used purely as front-end nodes, and
others run more than one type of workload, e.g. graphics
nodes often run compute workloads as well.
At LANL, failure tolerance is frequently implemented
through periodic checkpointing. When a node fails, the
job(s) running on it is stopped and restarted on a different
set of nodes, either starting from the most recent checkpoint
or from scratch if no checkpoint exists.
2.3 Data collection
The data is based on a “remedy” database created at
LANL in June 1996. At that time, LANL introduced a site-
wide policy that requires system administors to enter a de-
scription of every failure they take care of into the remedy
database. Consequentially, the database contains a record
for every failure that occurred in LANL’s HPC systems
since June 1996 and that required intervention of a system
administrator.
A failure record contains the time when the failure
started, the time when it was resolved, the system and node
affected, the type of workload running on the node and the
root cause. The workload is either compute for computa-
tional workloads, graphics for visualization workloads, or
fe for front-end. Root causes fall in one of the follow-
ing ﬁve high-level categories: Human error; Environment,
including power outages or A/C failures; Network failure;
Software failure; and Hardware failure. In addition, more
detailed information on the root cause is captured, such as
the particular hardware component affected by a Hardware
failure. More information on the root causes can be found
in the released data [1]. The failure classiﬁcation and rules
for assigning failures to categories were developed jointly
by hardware engineers, administrators and operations staff.
Failure reporting at LANL follows the following proto-
col. Failures are detected by an automated monitoring sys-
tem that pages operations staff whenever a node is down.
The operations staff then create a failure record in the
database specifying the start time of the failure, and the sys-
tem and node affected, then turn the node over to a system
administrator for repair. Upon repair, the system admin-
istrator notiﬁes the operations staff who then put the node
back into the job mix and ﬁll in the end time of the fail-
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:29:50 UTC from IEEE Xplore.  Restrictions apply. 
100
80
60
40
20
0
)
%
(
t
e
g
a
n
e
c
r
e
P
D
E
F
G
All systems
H
(a)
Hardware
Software
Network
Environment
Human
Unknown
100
80
60
40
20
0
)
%
(
t
e
g
a
n
e
c
r
e
P
D
E
F
G
(b)
H