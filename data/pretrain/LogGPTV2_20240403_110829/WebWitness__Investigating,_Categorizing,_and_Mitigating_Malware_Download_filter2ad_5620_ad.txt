tially, the landing page is the web page where the drive-
by attack path begins. Often, the landing page itself is
a non-malicious page that was previously compromised
(or “hacked”). The landing page classiﬁer calculates the
probability that a node preceding the exploit node (la-
beled by the exploit page classiﬁer discussed earlier) is
a landing page. Nodes with a probability higher than a
tunable detection threshold (50% in our experiments) are
classiﬁed as “candidate landing” nodes. If there are mul-
tiple candidates, the one with the highest probability is
labeled as the landing node.
To label a node as either landing or non-landing, we
engineered the following statistical features:
(1) Hops to the exploit page. This feature set consists
of the number of non-redirect nodes and unique ef-
fective second level domains between the node and
the exploit node.
Intuition: Often, all the nodes
between the landing and exploit node are redirects
[36]. Also, most drive-by downloads use one to
three types of malicious domains (injection, exploit,
download). Therefore, in most cases there are zero
or one domains (the one being the injection domain)
on the download path between the landing and ex-
ploit nodes.
(2) Domain age. We use two features based on domain
age. The ﬁrst feature is the age of the node’s effec-
tive second level domain as computed from a passive
DNS database. Intuition: The domains associated to
(“hacked”) landing pages tend to be long-lived. Fur-
thermore, “older” landing pages tend to offer more
beneﬁts to the attackers, as they often attract more
visitors (i.e., potential victims), because it takes time
for legitimate pages to become popular. The sec-
ond feature is the age of the oldest domain between
the node and the exploit node. Intuition: Nodes on
the download path between the landing and exploit
nodes tend to be less than a year in age. This is be-
cause they are typically malicious and recently reg-
istered.
(3) Same domain. Boolean feature that is true if the
node’s domain is equal to the exploit domain.
In-
tuition: It is uncommon for an exploit to be served
1032  24th USENIX Security Symposium 
USENIX Association
8
from the same domain as the landing page. They are
typically kept separate because installing an exploit
kit on a compromised website may increase the like-
lihood of detection by the legitimate site’s webmas-
ter. In addition, it is much easier to manage a central-
ized exploit kit server than keep all the compromised
websites up-to-date with the latest exploits.
Injection Page Classiﬁer: We deﬁne the injection page
to be the source of the code inserted into the “hacked”
landing page. Typically, the injection and exploit nodes
are separate and are served via different domain names.
This provides a level of indirection that allows the ex-
ploit domain to change without requiring an update to the
landing page. The injection node by deﬁnition is a suc-
cessor to the landing page, but depending on the injection
technique it may or may not be directly present in the
download path traced back by the ATC module. There-
fore, the classiﬁer calculates the injection page probabil-
ity for each direct successor of the landing node in the
transactions graph, instead of only considering nodes in
the reconstructed download path. The successor of the
landing page node with the highest probability is labeled
as the injection page node.
To identify the injection page, for each successor of
the landing node we measure the following features:
(1) On path. Boolean feature indicating if the node is on
the download path. Intuition: Being on the download
path and a successor of the landing page, makes it a
good candidate for the injection node. However, the
injection node is not always on the download path
due to the structure of some drive-by downloads.
(2) Advertisement. Boolean feature that is true if the
node is an ad. Intuition: By deﬁnition, the injection
page is not an ad, but code injected into the landing
page. It is common for ads that are not related to the
malicious download to be served on a landing page.
This feature help us exclude those ad nodes.
(3) Domain age. The number of days since the ﬁrst
observation of the node’s effective second level do-
main in passive DNS. Intuition: Injection pages typ-
ically have the sole purpose of injecting malicious
code. They are rarely hosted directly on compro-
mised pages, because this would expose the mali-
cious code to cleanup by the legitimate site owners,
ending the attacker’s ability to exploit visitors. Con-
sequently, injection pages are hosted on “young” do-
mains that are typically active for the lifetime of a
website compromise.
(4) Successors. There are two features that are derived
from the node’s successors. First is the number of
direct successors. Intuition: Injection nodes tend to
have only one direct successor. They typically per-
form an HTTP redirect or dynamically update the
DOM to include the URL of the exploit domain. Be-
nign pages often have more than one direct successor
because they load content from many different ﬁles
or sources. The second feature is boolean and it is
true if one of the node’s successors is on the down-
load path. It indicates there is a possible “source of”
relationship between it and a node on the download
path. Even though the node itself may not be on the
download path.
(5) Same domain. There are two boolean features that
compare domain names. The ﬁrst checks for equal-
ity between the node’s domain and the landing do-
main. Intuition: It is uncommon for the landing do-
main to equal the injection domain for reasons simi-
lar to those described in the landing page classiﬁer’s
“same domain” feature described earlier. The second
feature compares the node’s domain to the exploit
domain. Intuition: In approximately 70% of the ob-
servations in our measurement study (Section 2), the
exploit and injection domains were different.
4 Evaluation
In this section, we evaluate WebWitness’ ATC and MDD
modules. We also demonstrate the overall beneﬁts of
our new defense approach against drive-by downloads,
by measuring the effectiveness of blacklisting the injec-
tion domains discovered by WebWitness. We show that
while blacklisting the injection domains provides a bet-
ter defense, compared to blacklisting only the exploit and
download domains, injection domains appear very rarely
in current blacklists, including Google Safe Browsing
and a variety of large public blacklists.
4.1 ATC - Download Cause Classiﬁcation
The download cause classiﬁer uses a supervised learning
approach to label each download path as either social
engineering, drive-by or update/drop (Section 3.2). To
evaluate its accuracy, we use WebWitness to traceback
and classify all malicious downloads collected from the
large academic network (Section 2) in the months fol-
lowing our initial study and development of the system.
Speciﬁcally, all download events and samples used dur-
ing evaluation have no overlap with the data we used for
the study presented in Section 2, to design WebWitness’
features and heuristics, or to train our classiﬁers. Each
malicious download observed during the testing period
was then classiﬁed as one of the following: drive-by, so-
cial engineering or update. From each of the three pre-
dicted classes we randomly sampled 50 downloads for
manual veriﬁcation. We limited the sample size to a total
of 150 downloads because of the extensive manual anal-
ysis required to determine the ground truth, including re-
verse engineering web pages, heavy javascript deobfus-
cation, complex html and plugin content analysis, etc.
This time consuming review process allowed us to iden-
USENIX Association  
24th USENIX Security Symposium  1033
9
tify the correct web path and the true cause of download,
creating our ground truth for the evaluation. Table 3 re-
ports the confusion matrix for the cause classiﬁer.
Table 3: Cause Classiﬁer - Confusion Matrix Results
Ground Truth
Class
Drive-by
Social
Update/Drop
Drive-by
47
2
1
1
46
3
0
3
47
Predicted Class
Social
Update/Drop
The classiﬁer correctly labeled over 93% of the down-
loads. Notice that these results represent the overall sys-
tem performance of the ATC module, because the down-
load paths used in the experiment (i.e., input to the cause
classiﬁer) were extracted using our download path trace-
back algorithm (Section 3.1). The two social engineering
samples classiﬁed as drive-by downloads both had com-
monly exploitable content (CEC) on the download path.
They were misclassiﬁed even though the CEC domain
ages were greater than 200 days. The three update/drop
samples classiﬁed as social engineering was caused by
invalid download paths resulting from the false edges de-
scribed in the next section. Finally the three social en-
gineering downloads misclassiﬁed as update/drop was a
result of small downloads paths (all were length 3) and
high download domain recurrence (all greater than 20 of
the 48 hourly buckets).
4.2 ATC - Download Path Traceback
To evaluate the accuracy of our download path trace-
back algorithm (Section 3.1), we use the 150 manually
reviewed downloads; i.e., our ground truth, from Sec-
tion 4.1. For path traceback, we consider two types of
errors for review: (1) missing nodes: the traceback stops
short, before reaching the origin of the download path
(recall that the traceback algorithm works its way back-
wards from the download node to the path origin); (2)
false node: a node that should not appear in the download
path. Table 4 summarizes the results of our evaluation.
Table 4: Download Path Traceback Results.
Correctly Traced Back Missing
False
Drive-By
Social
Update/Drop
Paths
48
51
51
45
46
47
3
2
0
0
3
4
The results show that 92% of the download paths were
correctly traced back by our system. The 5 with miss-
ing nodes all had a referer header in the origin node’s
request, but a matching URL was not contained in the
trace. This was likely due to our system not observing
all the packets related to those transactions. The 7 with
the false nodes were all caused by the “same-domain”
heuristic incorrectly connecting the paths of an update
and a social engineering download. The heuristic failed
because the updates were performed by a malicious ex-
ecutable seconds after the user was socially engineered
into downloading it from the same domain as the update.
4.3 MDD - Detecting Injection Domains
As discussed in detail in Section 3.3, we aim to automati-
cally identify the malicious code injection domains often
employed in drive-by download attacks. To achieve this
goal, we use a cascade of three classiﬁers: an exploit, a
landing, and an injection classiﬁer (Section 3.3). In the
following, we evaluate the performance of each one.
To build the training dataset, we use 117 drive-by mal-
ware downloads collected and manually labeled during
our six-month malware study described in Section 2.
These 117 drive-by paths contained 246 exploit nodes
(notice that it is not uncommon for a drive-by attack to
serve more than one exploit, especially when the ﬁrst ex-
ploit attempt fails). There is only one landing node and
one injection node per download path.
Table 5: Node Labeling for Drive-By Download Paths
Incorrectly Labeled
Correctly Labeled
Experiment
Cross-Validation
Classiﬁer
Exploit
Landing
Injection
99.19%
96.58%
94.87%
0%
0.17%
0.07%
We performed 10-fold cross-validation tests using the
dataset described above. Table 5 summarizes the results.
As can be seen, all classiﬁers are highly accurate. The
results of the the injection page classiﬁer represent the
performance of the ﬁnal injection domain detection task.
This is due to fact that all tests were conducted using the
three classiﬁers (exploit, landing, and injection) in cas-
cade mode to mirror an actual deployment of WebWit-
ness’ MDD module. Thus, overall, we obtained a mini-
mum of 94.87% detection rate at 0.07% false positives.
There were a total 7 domains mislabeled as injection
by our system. The most common error was labeling the
exploit domain as the injection domain; i.e., missing the
fact that a separate injection domain existed. This was
the case for 5 of the 7 mislabeled domains. Since these
domains are malicious, blacklisting them will not cause
false positives. The other two domains were benign. One
of them had an Alexa rank over 260,000 and the other
above 1,600,000. To mitigate such false positives, the
newly discovered injection domains could be reviewed
by analysts before blacklisting. As WebWitness provides
the analyst with full details on the trafﬁc collected before
the download and the reconstructed download path, this
information can make the analyst’s veriﬁcation process
signiﬁcantly less time-consuming.
4.4 MDD - Defense Efﬁcacy & Advantages
Domain name and URL blacklisting are commonly prac-
ticed defenses [2]. However, blacklists are only effective
1034  24th USENIX Security Symposium 
USENIX Association
10