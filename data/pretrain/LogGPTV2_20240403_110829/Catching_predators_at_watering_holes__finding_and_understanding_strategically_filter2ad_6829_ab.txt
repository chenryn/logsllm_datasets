in a lightweight manner, model how fast and signiﬁcantly they
change (i.e., the observable difference between consecutive visits)
based upon the long history of clean communication, and utilize
the model to capture the changes considered to be rare. This sim-
ple change rate model, built on only the headers of HTTP requests,
enabled us to inspect the evolution of a large number of selected
sites in our research, and led to discovery of new watering holes.
In this section, we elaborate the methodology used in our study
for ﬁnding watering holes, particularly the design of Eyeson Pro-
ﬁler (Section 3.1) utilizing a small number of attributes available
in HTTP headers. Next, we build a list of strategic websites that
are potential targets of watering hole attacks and collect their corre-
sponding HTTP trafﬁc to monitor and proﬁle (Section 3.2). Finally,
we evaluate Eyeson Proﬁler on a set of labeled watering holes and
execute it on a larger set of monitored trafﬁc to ﬁnd 17 new in-
stances(Section 3.3).
3.1 Proﬁling
Eyeson proﬁler performs continuous monitoring on the HTTP
trafﬁc generated by website visits to identify suspicious changes.
This approach is based upon the observation that visiting a website
multiple times in a short period of time rarely results in different
HTTP requests, due to the fact that websites evolve gradually over-
time, which makes them appear static within a short time frame.
Most frequently, what causes new HTTP requests is just real time
contextual behavior such as display of different advertisements ac-
cording to a visitor’s meta data (e.g. browsing location and time of
day). On the other hand, when a target website is compromised, a
visit to the website will generate a relatively new set of HTTP re-
quests, which are quite different from those observed before. Such
requests can point to new resource URLs on the same monitored
domain and/or a new domain or sub-domain. Additionally, a com-
promise may change the resources already in use on the monitored
site, e.g., modiﬁcation of JavaScript libraries (e.g. jQuery) or in-
jection of an iFrame [43].
As an example, by examining the history of http://cgdev.org, a
water holed US think tank, from Jan to Oct 2014, we found that
most content the website serves includes html pages, CSS ﬁles and
some images, comes from the same domain. In the meantime, it
also generates a number of HTTP requests to popular third party
services such as fonts.net&googleapis.com. However on the 16th
and 17th of Oct, 2014, we observed a compromise leading to a new
set of HTTP requests, such as http://news.foundationssl.com/i/p.
php and http://news.foundationssl.com/i/s.php?seed=[]=&alivetime=
[]==&r=[]. These types of changes, new FQDN or new resources,
are frequently observed in the HTTP trafﬁc when legitimate do-
mains are compromised, as reported by prior investigations [44, 49,
41]. Also, once the visitor’s system also gets infected, additional
HTTP requests may show up, for the purposes such as downloading
malicious executables or jar ﬁles.
To capture such sudden changes, which helps identify a com-
promised website, Eyeson ﬁrst builds a proﬁle from the website’s
clean history. Secondly, for subsequent visits to the target, they are
compared to the built proﬁle and a visit change rate is calculated.
If the change is considered to be acceptable, it will be added to the
proﬁle. Otherwise, an alert is reported.
Proﬁle building. A proﬁle is used to keep track of a target’s HTTP
trafﬁc history and its change rates. The history here is a collec-
tion of features extracted from HTTP headers and their values, in-
cluding URLs, FQDN, sub-domain, content types, URL patterns
per sub-domain and ﬁle names per sub-domain. For example, for
the FQDN feature, we keep all domain names that appear in clean
visits, and for the content type feature we keep all distinct con-
tent types the web site serves. An example of the proﬁle for http:
//cgdev.org is shown in Table 1. Those features are selected in our
research because they are known to be associated with the behavior
of compromised sites: the adversary could create a sub-domain un-
der the compromised domain for his malicious activity (e.g., [56])
and often add new types of ﬁles to be downloaded by the visitor
(e.g., the executable never seen from the site); also new URLs al-
most always need to be generated to deliver malicious payloads
and sometimes, even URL patterns (that is, the domain and path
without the values for arguments) never seen before show up.
To construct a proﬁle and analyze an observed change, Eyeson
ﬁrst removes the dynamic content brought in by legitimate ad net-
works and third-party services, since the content served by them
varies frequently which introduces noise to our monitoring pro-
cess. For this purpose, we utilizes a set of whitelists to ﬁlter out
the requests related to legitimate ad networks and tracker networks
Meta Data
History
Change Rates
Monitored URL: http://cgdev.org Proﬁle start date: 2014/01/01 Proﬁle size (number of visits): 100
FQDN
Sub doamins
URLs
cgdev.org
www.cgdev.org
http://www.cgdev.org/sites/default/ﬁles/css/css_ 791yxbakkm1orm_ 7huskesiv9tswq6wmrkerhuxpn6w.css,
http://www.cgdev.org/cgd_ stats/12989?oo5sv3bltb=xrtypqlycqwmlm00ycnzvfhoyb1bs1u3jupa7 ...
CSS, JS, PNG ...
(www.cgdev.org,/sites/default/ﬁles/css/css_ 791yxbakkm1orm _ 7huskesiv9tswq6wmrkerhuxpn6w.css)
(www.cgdev.org, cgd_ stats/12989|oo5sv3bltb)
css_ 791yxbakkm1orm_ 7huskesiv9tswq6wmrkerhuxpn6w.css
File names
9, 6, 6, 1, 4 ...
Table 1: Proﬁle content of http://cgdev.org. For brevity sake, we show limited values per feature.
Content Types
URL patterns
(described later in Section 3.2).
After the advertisement, tracker networks and popular domains
are removed, the HTTP header information can now serve the pur-
pose of proﬁle construction and update. To this end, Eyeson uses
a few clean visits (collected from the long history of interactions
with the target) to set up the initial trafﬁc history, ﬁlling in different
features (URLs, content types, etc.) in the proﬁle. Once the his-
tory is there, it waits for a few additional visits so as to construct
a model for the change rate. Speciﬁcally, for each new visit to the
target, all HTTP requests involved are inspected one by one. For
each request, our system compares its feature values, such as sub-
domains, URLs, Content type, URL patterns, etc. (see Table 1 for
a complete list) with those in the proﬁle. For each feature we count
the number of new values that are not included in the proﬁle, as
the feature’s change rate. We aggregate the value of all features’
change rates into a score denoting the overall visit change rate.
For example, consider a request for the URL http://www.cgdev.
org/cgd_stats/12989?oo5sv3bltb=, which is not included in the URL
feature of the proﬁle (Table 1), but matches one URL pattern once
the value oo5sv3bltb is removed. In this case, the URL change
rate is 1, but all other features’ rates are 0, resulting in a change
score of 1.
More speciﬁcally, let us assume that we use m features F1, . . . , Fm
and have built a proﬁle from n − 1 visits. At the n-th visit, feature
Fj’s rate of change is the number of new values observed in fea-
ture Fj and is denoted by Nj. The visit’s overall change score is
Rn =(cid:80)m
j=1 Nj.
Based on the observed change rates R1, . . . , Rn for n contin-
uous visits stored in the proﬁle, a probabilistic model Pn is con-
structed for representing the expected distribution for visits’ change
rates (i.e., the probabilities P r[Rn <= k] are explicitly stored for
all integer values of k). Additionally, given the sample size (the
number of visits in a proﬁle), conﬁdence intervals are also built at
different conﬁdence levels (e.g., 95%). Upon a new visit, the pro-
ﬁle, change distribution and conﬁdence intervals are continuously
updated if the visit is not labeled as potentially malicious.
Change point analysis. Using the learned probability model Pn,
Eyeson looks for abnormal rates of change in subsequent visits, i.e.,
outliers with respect to the historical distribution of change rates.
We use a simple outlier detection method for this purpose [20]: If
at visit n + 1, the rate of change Rn+1 falls outside the conﬁdence
interval for a certain conﬁdence level (set at L), the visit is labeled
as an outlier and an alert is generated. Otherwise, the rate of change
Rn+1 is used to update the proﬁle and the change probability distri-
bution to Pn+1. This approach is very intuitive: we just determine
a range of change rates that are observed most of time (e.g., over
95% of the visits); when a new visit causes a lot of changes, with a
rate going beyond the range in the conﬁdence interval, it is captured
as an outlier and reported for further post-processing. If the visit is
later cleared, the rate is added to the proﬁle, causing an adjustment
to the distribution and the conﬁdence interval.
As an example, for the proﬁle in Table 1, Eyeson set its 95%
conﬁdence interval to (0.94,1.3) in our model. When it comes
to the visit to http://www.cgdev.org/cgd_stats/12989?oo5sv3bltb=,
the change rate 1 is inside the interval and therefore considered to
be acceptable and added to the proﬁle. On the other hand, another
visit to http://cgdev.org at the time the site was compromised, as
we observed from archive.org, generated a lot of requests to the
domain foundationssl.com and caused downloads of the types of
ﬁles never seen before. The change rate in this case was calculated
as 39, which is clearly an outlier and as such ﬂagged by the system.
With its simplicity, this change-point analysis turns out to be
quite effective. In our study, using the real data collected from a
large organization and the trafﬁc related to known watering holes,
we found that this simple approach indeed helps us discover a set
of watering holes never known before (Section 3.3).
3.2 Data Collection
In this section we describe the datasets collected by Eyeson. We
start by building a list of potential watering hole targets to monitor.
Next, we collect HTTP trafﬁc of the targeted domains and other
complementary datasets. Finally, we describe our process to gener-
ate a ground truth set of labeled visits to watering holes. Strategic
target selection. In our research, we used two main sources for tar-
get selection. First, based on several sources of intelligence from
our industry partners, we collected a list of 178 web sites consid-
ered to be high proﬁle targets of watering hole attacks. On the list
are governmental, political, defense contractor sites and 29 other
strategic websites that have been water holed in the past (see Table
3) such as think tanks and SW engineering systems.
Our second source for target selection is the trafﬁc of the or-
ganization which we aim at protecting from these attacks.
If a
nation state actor is interested in the proprietary information of a
certain company, they will ﬁrst attempt to do reconnaissance on
the company to come up with targets such as business partners,
subsidiaries, close by commercial businesses (e.g. restaurants and
banks), forums and other websites related to the company’s in-
dustry sector. These potential targets should be screened by Eye-
son and can be identiﬁed from the company’s HTTP trafﬁc.
In
particular, we select a list of websites that are visited frequently
by the company’s employees from Jan 1st to Sept 4th 2014, af-
ter removing extremely popular sites that have in general good se-
curity practices and would be more difﬁcult to compromise, e.g.
windowsupdate.com, resulting in a list of 121,473 sites that were
visited at least 10 times every month. These sites are the ones that
have a long standing relationship with that particular organization,
and can be leveraged by attackers as potential targets since they are
in general not as well protected as the extremely popular sites (e.g.,
those in the top Alexa ranking).
HTTP trafﬁc Collection. Eyeson proﬁler is designed to ﬁnd com-
promised websites by analyzing HTTP requests generated from a
website’s visit.
In an enterprise setting, such HTTP headers are
usually collected through a common network product (namely a
web proxy system) without requiring additional data to be col-
lected. In our research,however, we aim to evaluate the potential
effectiveness of Eyeson proﬁler before deployment to an enterprise
setting, such an evaluation requires both HTTP headers and re-
sponses to validate our results.
To this end we evaluate Eyeson on a much larger set of HTTP
trafﬁc by leveraging archive.org, a system that implements a dy-
namic crawler to crawl a list of URLs intermittently and maintains
a snapshot for each visited URL. When an archive URL is trig-
gered through a browser, any embedded requests in the snapshot
are rendered, essentially recreating the visit to the URL at the date
when the snapshot was taken providing us with both HTTP head-
ers and responses. Searching the archive.org for the target list of
121,651 FQDNs, we collected over 1 million archive URLs. A de-
tailed description of our archive data collection process along with
an example of an archived visit is provided in Appendix B.
In addition to such archived HTTP trafﬁc, we conducted our own
real time monitoring of the manual list of 178 websites by crawl-
ing them with a dynamic crawler through the anonymity channel
TOR [12], using 17 User Agents representing popular browsers
and operating systems such as Internet Explorer, Chrome and Fire-
Fox on Windows, Linux and Android. In total, archive and real
time crawling resulted in 14 million collected snapshots. Table 2
illustrates the HTTP data sets collected to monitor and screen 61K
FQDNs over a period of 5.4 years.
Complementary data sets. We also collected a number of other
data sets for different purposes as shown in Table 2. Whitelists
were used by Eyeson to remove noise from the visits introduced by
advertisement and tracker networks. A challenge here is that since
the collected HTTP trafﬁc set goes back a few years, the latest copy
of Easylist [52] does not include the advertisement networks active
several years ago but out of service now. In order to include those
advertisement networks, we took advantage of the archives again
Further, we
as they also collected the snapshots of those lists.
generated a list of the most popular sub-domains (i.e.
indicative
of third party services) from the same enterprise set used to select
the domains to be monitored. Such popular sub-domains were de-
termined by the number of visits they receive, at least 10K visits
per day for those that ended up on our list. At the top of it are
crl.microsoft.com & fast.fonts.net.
Ground truth. Ground truth for targeted attacks is hard to come
by, because they happen rarely. Even though we can gather a few
conﬁrmed watering hole domains from various sources, it is still
challenging to determine the period of time when they were in-
fected. In our research, we manually gathered from technical re-
ports a set of conﬁrmed watering holes (shown in Table 3) and
the Indicators of compromise (IoCs) for each case (as described in
those prior reports) such as speciﬁc strings in malicious payloads
(e.g. function names), URL pattern, malicious domain name and
approximate compromise date. Using the IoCs and their compro-
mised dates, we searched the collected archived HTTP trafﬁc and
located the snapshots with the IoCs and further manually veriﬁed
the presence of infections there. For each compromised snapshot,
we further took its snapshots 20 days before and after the infected
one as the site’s clean versions, if they did not carry any IoC and
also passed the sanity check performed by a content based anti virus
system, MS SE [47]. This gave us a ground truth set with 14 wa-
tering hole FQDNs corresponding to 69 monitored URLs2 (aka,
proﬁles). The total number of snapshots in the set is 23,532, each
corresponding to a visit, including 1,682 compromised snapshots.
2Throughout this paper, a monitored URL refers to the start URL from which a visit
starts.
3.3 Eyeson Evaluation and Results
Over the domains and trafﬁc collected, we used Eyeson to iden-
tify a small set of FQDNs highly likely to be watering holes. Here
we report our ﬁndings.
Evaluation on the ground truth. Using the collected ground truth
set (Section 3.2), we bootstrapped the proﬁle for each monitored
URL with 10 visits (after initial 5 visits, the follow-up 5 for col-
lecting change rates). We found that the 95% conﬁdence interval
yielded a false positives rate 19.4% and a zero false negatives. This
demonstrates that our simple approach has the potential to be used