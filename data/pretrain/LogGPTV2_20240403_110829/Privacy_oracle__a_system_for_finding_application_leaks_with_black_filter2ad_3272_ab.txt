sonal data [24]. Other identiﬁable system conﬁguration informa-
tion includes MAC addresses and machine names. A MAC address
is unique to a network interface and persistent, thus it can be used
for tracking a device and its user. A machine name or hostname can
also reveal personal information. For instance, some organizations
assign a unique machine name for inventorying purposes and use
an inventory tag as a Windows machine name [15].
3.2 Output Analysis: NetDialign
The approach we take to ﬁnding differences in raw network
traces has two parts. First, we condition the traces so that we
can make meaningful comparisons. We remove extraneous trafﬁc,
aggregate data from network packets into longer ﬂows that carry
application-level semantics (that will be repeated in their entirety
with repeated instantiations of the application), and label these
ﬂows consistently across tests. Then, we compare each ﬂow from
one test to its counterpart in another test to identify differences.
Figure 2 illustrates the overall output analysis process.
Conditioning traces. A single test may generate multiple inter-
leaving message ﬂows—we observe that one sign-in click within
a popular messenger program generates 59 TCP connections to 20
different destinations—resulting in a large number of packets from
many different output messages being mixed together. To untan-
gle this mess, we use packet header information to group packets
into ﬂows. All packets with the same source and destination IP
addresses and ports that use the same protocol (TCP or UDP) are
considered to be part of the same ﬂow3. A trace containing packets
from an application will also contain duplicates resulting from un-
2A user might have a greater concern if his name and zip code
are exposed in the clear text when using a peer-to-peer ﬁle sharing
utility than a map application.
3Flow reconstruction from packet traces is commonly used in net-
work intrusion detection systems (NIDS) [17] or in analyzing dark-
net traces [16].
modiﬁcations that we made to apply it for network data compari-
son. We refer to the original papers [12, 13] for more details.
Suppose that we have a pair of segments of length l. First, we
count the number of matching characters, m, and compute the p-
value, P(l,m), which is the probability of having at least m matches
if each byte is equally likely to occur in any position of the segment
with a probability p 4 .
The smaller the P(l,m), the less likely it is that the segments have
m matches by chance. We use the following transformation to con-
vert P(l,m) to a score representing the signiﬁcance of the segments
being common between two sequences.
E(l,m) = −ln(P(l,m))
(2)
Finally, we apply the following threshold to suppress spurious short
segments. We use T = 24 to ensure that resulting common seg-
ments have at least three consecutive matches. We want to sepa-
rate out whole regions of dissimilarity (such as across session IDs)
despite a reasonable probability of them having short common seg-
ments of length one or two. Since T determines a minimum number
of matches for a pair of strings of a given length to be considered
“common,” it can affect the accuracy of the algorithm.
(cid:18)l
(cid:19)
i
(cid:40)
Figure 2: Output analysis: We ﬁrst aggregate packets into ﬂows and label
them for comparison. Then, we align each pair of matching ﬂows to identify
differences.
P(l,m) =
l
∑
i=m
)pi(1− p)l−i,where p =
1
256
(1)
acknowledged transmissions as well as unrelated packets generated
independently by the host system and not as a consequence of run-
ning the application. To simplify the differential analysis process,
this extraneous information is ﬁltered. We remove all NetBIOS
messages and NTP updates. For TCP, we use sequence numbers
to eliminate duplicate packets and any trailing dummy bytes often
found in reset (RST) packets. Furthermore, since our focus is user
information exposure, we collect only outgoing ﬂows.
We use IP addresses and ports to aggregate packets into ﬂows,
but interestingly enough, labeling by IP addresses and ports will
sometimes assign different labels to ﬂows that should have been
compared. For example, when a server employs DNS-based load
balancing mechanisms, a server name may be resolved into mul-
tiple IP address, causing different labels for the ﬂows destined to
the same server. This one-to-many relationship between domain
names and IP addresses necessitates the comparison of ﬂows by
the former. We therefore label each ﬂow with the host name that
the application used to transmit messages and the destination port
number. We process any preceding DNS requests and responses to
learn the domain name to IP mappings, because the more straight-
forward approach of using reverse DNS lookup post facto does
not always ﬁnd the original name. For example, sim.yahoo.com is
resolved to any one of 68.142.233.[170-173], but 68.142.233.170
maps to sip25.voice.re2.yahoo.com whereas 68.142.233.171 to
sip26.voice.re2.yahoo.com. When there are multiple ﬂows gen-
erated to a same server, we append to the label an order by which
the ﬂow was initiated in comparison to other ﬂows headed to the
same server.
Comparing ﬂows. Once matching ﬂows are identiﬁed from two
test outputs, we compare byte sequences of the payload data
(application-level messages) and isolate commonalities and differ-
ences between the two output messages. A pair of ﬂows can have
many common parts (e.g., application-speciﬁc protocol ﬁeld names
such as GET and Cookie: in HTTP) and changing parts (e.g.,
ﬁeld values such as a URL followed by GET or cookie values by
Cookie:). We assume that changing parts have sufﬁcient differ-
ences between two test outputs and so two byte strings correspond-
ing to the changing parts are statistically different in a signiﬁcant
way.
Our byte sequence alignment algorithm, NetDialign, is based
on Dialign [12, 13], a segment-to-segment comparison based algo-
rithm for aligning multiple DNA or protein sequences that is well-
suited to comparing application-level network data in our settings.
At a high level, Dialign ﬁnds common gap-free segments of a
same length between a pair of biological sequences [12, 13]. It uses
a statistical measure to score the signiﬁcance of given segments and
uses dynamic programming to ﬁnd a set of common segments that
maximize overall scores. This algorithm isolates the regions of low
similarity, which are exactly the regions of differences that we wish
to identify from test outputs. We brieﬂy review Dialign and explain
W (l,m) =
E(l,m)
0
if E(l,m) > T,
otherwise.
(3)
We discuss the effectiveness of the NetDialign algorithm in §6.
3.2.1 NetDialign vs. diff
One may wonder whether the popular diff utility [5] may work
as well as or even better than NetDialign for comparing two appli-
cation messages. Indeed, there are cases in which diff and NetDi-
align produce the same output (e.g., exactly matching two strings).
However, here we show a simple example highlighting the differ-
ence between the two algorithms and explain why NetDialign is
better suited for comparing application level network data.
In principle, NetDialign is searching for contiguous common
segments between two input strings whereas diff is looking for a
longest common subsequence. Since diff tries to maximize the
number of matches between two input strings, an output can con-
tain many spurious matches, and thus might not capture the struc-
ture of application message formats. An example is a cookie that
has many pairs of a short common preﬁx (e.g., gid=, sid=) followed
by a long variable as shown in Table 1.
NetDialign
;sid=
;sid=
2424522
1893211
gid=
gid=
1267801
2132262
gid=
gid=
2
2
424522
11
1893
diff
;sid=
;sid=
1
1
2
26
26
7801
2
32
Table 1: NetDialign vs.
sid=1267801 and gid=1893211; sid=2132262 .
diff:
input sequences are gid=2424522;
4 p = 1
256 since there are 28 possible bytes.
raw packet tracesaligned flowsaligned messagesconditioning tracescomparing flows4.
IMPLEMENTATION
For an analysis of applications running on Windows, Privacy Or-
acle leverages many existing tools: Each execution of the target
application is performed in a virtual machine [26] that is check-
pointed and rolled back to an initial state prior to each application
execution. Interactions with speciﬁed test inputs is automated us-
ing a Windows test automation tool called AutoIT [1]. Application-
generated network trafﬁc is collected using wireshark [28]. In ad-
dition to capturing network trafﬁc, HTTPS trafﬁc is also captured
before SSL encryption using HTTP Analyzer [6]. This enables de-
tecting the exposure of sensitive information by applications that
use SSL. In what follows, we provide the details of two important
steps involved in an application testing and how these tools are used
to facilitate the analysis.
4.1 Generating Test Inputs
In this section, we describe the fuzzing approach for the three
different categories of test parameters described in §3.1.
In the
ideal case, the differential fuzz testing based approach of Privacy
Oracle would automatically generate a comprehensive set of ran-
dom test inputs for all the test parameters. However, for our current
implementation, test inputs are generated with a human in the loop
for each application using the following simple heuristics.
For personal data such as name, organization, and email account,
we pick words of a reasonable length (e.g., privacy) and their ana-
grams (e.g., “crapivy” and “varypic”) to generate additional test
inputs. For data with constraints such as a zip code or a gender, we
pick a few valid ones (e.g., 98105 and 02138 for zip codes) for test
inputs. If available, we pick the input data that have no more than
two consecutive matches amongst them. Otherwise, the two input
data may be ﬂagged as common by NetDialign per Equation (3).
To detect whether an application exposes user-speciﬁc informa-
tion about usage, we focus on applications that provide a search
interface (e.g., search engines and searches for online media ﬁles).
Similar to the fuzzing approach for personal data, we pick a few
words and use their anagrams as the input search strings. Unlike
the other types, test parameters that are determined by the operating
system and network conﬁguration cannot be randomly generated.
For example, to test for IP address based geo-location information
exposure, it is not sufﬁcient to randomly change the IP address of
local network interface. To systematically explore this privacy leak,
proxy servers need to be setup to emulate two different geographi-
cal locations. Hence, test inputs are generated by manually fuzzing
the system conﬁguration parameters.
4.2 Automating Target Application Execution
Having generated the test inputs for the application speciﬁc test
parameters, Privacy Oracle executes the target application multi-
ple times for each set of test inputs. The network trace collected
from each execution is analyzed by the NetDialign algorithm. It is
important that each network trace be generated by the exact same
application execution workﬂow. It is also important that each exe-
cution of the application start from a known operating system state.
The rest of this section describes the implementation of the trace
generation mechanism of Privacy Oracle to meet the above two
constraints.
Enforcing an application workﬂow. Applications have fairly
complex installation procedures that guide a user through multi-
ple screens with each screen requesting a varied number of user
inputs. For example, the installation of a popular instant messen-
ger client requires twelve user inputs to ﬁll in contact information
and select preferences across six screens. Repeating this task for
each set of test inputs manually would be laborious and error prone.
To automate this process, Privacy Oracle uses AutoIT [1], which
provides an open source BASIC-like scripting language designed
for automating the Windows GUI. By using a combination of sim-
ulated keystrokes, mouse movements and window manipulation,
AutoIT automates the execution of an application with varying test
inputs. Figure 3 shows a simple AutoIT script that automates the
login procedure to an instant messenger client.
Figure 3: AutoIT script example for testing a popular Internet messenger
client. The application is executed in a virtual machine (dotted box)
Enforcing a consistent system state. As discussed in §3, applica-
tion behavior could be affected by various system parameters such
as cookies, registry information, and the state of the ﬁle system. To
maintain consistent behavior across successive application execu-
tions, it is important that the application be executed from a known
“clean” state. To address this, Privacy Oracle executes the target ap-
plication in a virtual machine [26]. In our existing implementation,
a human determines at which state of the system, snapshots should
be created. For example, consider a test to determine whether an
application exposes user information when an update to the appli-
cation is being installed. To test this, Privacy Oracle ﬁrst creates
snapshots of the virtual machine immediately after the application
is installed, each with different user registration information. The
virtual machine can then be rolled back to the state immediately
after the application is installed(i.e., the snapshot). For each snap-
shot, network traces are collected for the NetDialign ﬂow alignment
tool.
5. APPLICATION STUDY
This section presents a study of the leaks that occur in practice
detected by Privacy Oracle from 26 popular applications.
We expected that some applications would emit identifying to-
kens and select demographic information to personalize user inter-
actions; we also suspected that some information would inevitably
ﬁnd its way to ad servers. We had no speciﬁc idea how such in-
formation exposure would manifest itself or whether it would be
kept to a minimum required for application functionality or if we
would discover obvious abuses like plaintext transmissions of so-
cial security numbers. What we found is that many applications we
tested transmit personal information, sometimes in unexpected and
uncomfortable ways, and sometimes when unnecessary.
We begin by describing the 26 test applications and then discuss
our ﬁndings in terms of three classes of exposure: (1) user-entered
contact information sent in plaintext; (2) system conﬁguration in-
formation actively gathered by applications; and (3) information
sent to third parties such as advertisement servers and marketing
research ﬁrms. We recognize that these three groups are not mu-
tually exclusive (e.g., user email transmitted in the clear to an ad
server can belong to (1) and (3)). Nonetheless, this grouping is
generally useful for understanding the common information gath-
ering practices of applications.
Run("C:\ProgramFiles\messenger.exe")WinWaitActive("Messenger")Sleep(1000)Send(“$username”)Send("{TAB}")Send(“$password")WinWaitActive(“Welcometo Messenger")Sleep(2000)WinClose(“Welcome toMessenger")5.1 Application Selection
Our goal is to analyze real example applications in order to ex-
trapolate an understanding of how common types of applications
expose personal information. Thus, we evaluate twenty applica-
tions from download.com that were listed as the most downloaded
applications (three million in total) in the second week of Octo-
ber 2007. These applications fall roughly into six categories: anti-
virus software, peer-to-peer clients, utility software (for ﬁles, di-
agnostics, updates, and browsing), media players, communicators
(for instant messaging and chat), and media tools (for manipulat-
ing videos and viewing images). To obtain a representative sample
of at least three applications in each category, we added two pop-
ular stand-alone instant messenger clients, one Web-based email
and messenger program and three media players to the study. The