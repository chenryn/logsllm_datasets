neighborhood score less efﬁcient to capture potential rela-
tionships between the input harbor and other harbors that
will possibly be spammed by the same spammer. To over-
come this problem, we need to deeply propagate the neigh-
borhood relationship, similar to the page rank algorithm.
Speciﬁcally, if we propagate the neighbor scores one further
hop, this gives us I · W · W = I · W 2, which will propagate
neighbor scores from node 1 to 4. Thus the average received
score for each node in this case is (I ˙W +I ·W ·W )=2. Nat-
urally, the propagation scores should decay along with the
distance from the input harbor. To achieve this goal, we
dampen matrix W by a constant (cid:11) ( 0 < (cid:11) < 1).4 Thus
the farther the distance between a harbor and the input har-
bor, the less neighbor score it can inherit. Based on all of
above, we propagate neighborhood scores for each harbor
as follows:
∑
i=1 I · ((cid:11) · W )i
t
t
N =
(2)
Once the neighbor score vector converges after t propa-
gation steps, we can obtain the ﬁnal (stable) neighborhood
scores for each harbor, and this score reﬂects how close the
neighbor relationship is between the input harbor and the
corresponding harbors. Next, we will present how to use
these scores to infer a given new spam message.
4.3 Spam Inference
To infer whether a given new message/posting is spam or
not, we also need to crawl other harbors to check if the link
in the given posting also appears on them. Thus, we obtain
a real posting structure vector R, Ri = 1 if harbor i is also
posted with the given link. Now we have both real posting
structure and neighborhood scores for each harbor, next we
present how to combine them to infer spam.
Intuitively, if harbors with high neighborhood scores
have also been posted with the same messages, it has a
high possibility that the input message is spam. Neigh-
borhood scores reﬂect the neighbor relationships between
other harbors and the input harbor. Thus, if harbors have
high neighbor scores, they may have a high possibility to
be spammed by the same spammer, which means if we
ﬁnd the input message appears in these harbors, it should
have a high possibility to be spam. Thus, we infer the
spam by computing how real posting structure and neigh-
borhood scores combine together to contribute to a suspi-
cious spam score. Speciﬁcally, we use a modiﬁed cosine
similarity function F (R; N ) to characterize the similarity
between the real posting structure and the learned neigh-
borhood relationship in the spamming infrastructure. We
4We empirically set (cid:11) = 0:85 based on [21].
deﬁne the ﬁnal spam score for the input message/URL i as
follows:
Scorei = F (R; N ) =
(3)
R · N∑
n
i Ri
Here, a higher spam score means that the real posting
structure matches very well with closer neighbors of the in-
put harbor. Thus we should have a higher conﬁdence to
infer the input message as spam.
5 Evaluation
In this section, we evaluate our system in two stages. For
the ﬁrst stage, we evaluate NEIGHBORWATCHER regarding
its inference stability and effectiveness. We also measure
how many new spam and harbors can be inferred everyday,
and the topic diversity of these spam postings. In the sec-
ond stage, we discuss possible applications of our inference
results.
5.1 Dataset and Ground Truth
To build the neighborhood relationship graph, we use
the collected spam harbors in Section 3. After that, we
keep monitoring these spam harbors everyday and extract-
ing new postings from them for spam inference. Also, af-
ter inference, we search inferred spam links in Google and
use the same way in Section 3 to extract new harbors from
search results. To evaluate the effectiveness of our infer-
ence system, we need to choose true spam links and benign
links for testing. For the former, we extract random post-
ings from harbors and manually choose 500 veriﬁed spam
messages (that contain spam links). To ﬁnd a normal post-
ings set, we assume domains in Alexa [1] top 20,000 are
highly-reputable websites that have less chance to be posted
in comment spam. Thus, we check how many links in our
collected postings have intersection with these domains. In
this way, we get 754 normal postings and combine them
with 500 spam postings as our testing dataset Stest.
5.2 Stability of Spamming Structure
Our system exploits spammers’ posting infrastructure (or
spamming structure) to infer spam. Thus, if such infrastruc-
ture changes frequently, it will make our system less effec-
tive. For example, if spammers keep using new harbors for
spamming everyday, our system cannot infer their spam. To
evaluate the stability of spamming structure, we essentially
examine how the neighborhood relationship among spam
harbors change over the time. We build the neighborhood
relationship graph of spam harbors by setting wi;j = 1 to in-
dicate that two spam harbors share at least one common link
and wi;j = 0 to represent no relationship between two har-
bors. Then we consider such relationship graph in the time
window [t; t + ∆t5] as the initial spamming structure and
the relationship graph in the next window [t + ∆t; t + 2∆t]
as the testing spamming structure. Thus, the difference be-
tween two structures indicates the instability of the spam-
ming structure. To quantify such instability, we use Ham-
min Distance [12] to measure the number of changed rela-
tionships CR between these two time window, as shown in
Eq.(4). Here n is the number of total harbors.
|
− W t+∆t
|W t+2∆t
n∑
CRi =
(4)
i;j
i;j
j
Thus, a smaller value of CR implies a much more sta-
ble spamming structure. For each spam harbor i in our
database, we calculate its changed relationship CRi. Fig-
ure 11 shows the distribution of changed relationships for
all spam harbors.
Figure 11. Changed Relationship Distribution
We can see that about 40% harbors do not change their
neighbor relationships because spammers keep utilizing the
same harbors. In addition, about 80% spam harbors change
their relationships less than 20, which is also less than half
of the average community/clique size 50. Thus, even if a
community loses 20 harbors, we can still infer spam with
the remaining 30 harbors as long as spammers keep recy-
cling their harbors. Furthermore, the continuous updating
of our harbor database can somehow compensate such in-
stability, we will discuss more about this in Section 6.
5.3 Effectiveness of Inference
To evaluate the effectiveness of our system, we test our
system with Stest. We consider both the number of cor-
rectly inferred spam, termed as “Hit Count”, and the ratio
of this number to the total number of inferred spam, termed
as “Hit Rate” (i.e., accuracy). Thus, a higher value of Hit
Count indicates that our system can catch more spam; and a
higher value of Hit Rate indicates that our system can infer
spam more accurately.
5We empirically set ∆t 1 month here.
Table 4. Sensitivity of the Hit Rate and Hit
Count to the Choice of Similarity Threshold
Sim. Threshold Hit Rate Hit Count
False Positive
0.3
0.4
0.5
0.6
57.29%
75.93%
97.14%
97.8%
432
426
408
360
322
135
12
8
Since we infer spam based on the spam score threshold,
we also check how the threshold contributes to the infer-
ence results, a way similar to [19]. In our case, a higher
(thus more conservative) threshold may lead to a higher hit
rate but with a lower hit count. Table 4 shows how Hit Rate
and Hit Count vary with different settings of the threshold.
We can see that a spam score threshold of 0.5 yields to a rel-
atively high hit rate (97%) with a relatively high hit count.
Also, there are still 92 links that can not be correctly in-
ferred as spam (i.e., false negatives) and 12 incorrect in-
ferred links based on our labels (i.e., false positives). We
further check these links, most of false negatives only ap-
peared in its input harbor, which means these spam links do
not appear in other harbors in our database. This is possible
because our database is relatively small and may not cover
all spammers’ harbors. However, the effectiveness could be
easily further improved if one can build a larger dataset,
e.g., by recursively updating the spam harbors database,
which will be discussed in Section 6. Among 12 false pos-
itives, 5 are actual benign websites posted by spammers in
order to conduct harbor testing (as discussed in Figure 1).
7 of them are those link to some Alexa top 20,000 web-
sites and we expected (labeled) them to be non-spam as ex-
plained in our test dataset preparation. However, they turn
out to be actual spam posted on reputable websites (e.g., in
some Google groups). If we exclude them, our actual false
positives are only ﬁve, which is pretty low. Finally, we note
again that our inference algorithm only uses the spamming
structure information, and it does not leverage other existing
content features yet. Once combined with existing features,
we surely can expect a better performance.
5.4 Constancy
To evaluate the constancy of our system, we essentially
examine whether our system can continue ﬁnding new spam
over time. We keep monitoring spam harbors everyday to
check new postings. These new postings are submitted to
our system for spam inference. For each new inferred spam,
we further search it in Google to ﬁnd new spam harbors
(using the same method mentioned in Section 3) that are
not included in our database, then add them in our database
everyday.6 After 3 weeks’ study, we have totally inferred
91,636 new spam and 16,694 new spam harbors. Figure 12
is the distribution of new inferred spam and new spam har-
bors over time. We can see that our system can constantly
ﬁnd new spam and spam harbors as long as spammers keep
posting new spam and also spamming on new harbors.
Diversity of New Spam. To have a sense of the vari-
ety of spam content we inferred, we surveyed 10,000 ran-
domly chosen spam postings and clustered them in 7 cate-
gories based on their anchor keywords. Table 5 shows the
keywords we used for clustering spam, and Figure13 shows
the category results. We can see that pharmacy is still the
most popular spam, and spammers always try to promote
them to have a higher search rank [30]. On the other hand,
our system can keep capturing general spam (other than just
pharmacy) in terms of their spam content.
Table 5. Keywords for Different Spam Cate(cid:173)
gory
Categary
Terms
Rogue Pharmacy
Rogue software
cialis,viagra,prescription,levitra ...
virus,windows,desktop,software...
Porn
Gambling
Money
Accessories
porn,sexy,fuck,adult...
casino,poker,roulette,gambling...
insurance,debt,mortgage,credit...
handbag,dress,luxurious,louis...
Figure 13. Spam Category
Context-based Analysis of Spam. For those newly in-
ferred spam, we randomly sample 1,000 spam links and
use the same method in [32] to ﬁnd out URL-redirection
and cloaking spam. Speciﬁcally, we send requests to each
link 3 times by setting different HTTP header parameters
6We may add a few normal websites in our database in this way because
our inference hit rate is not 100%. However, we note that these websites
most likely will not have close relationships with other spam harbors, thus
will not impact our inference results much.
(a) New Spam
(b) New Spam Harbors
Figure 12. Constancy of NEIGHBORWATCHER
to emulate Google Bot crawling, directly visiting, and vis-
iting through search result clicking, respectively. We con-
sider it as cloaking spam if any of two visits lead to differ-
ent websites through redirection. In this case, among 1,000
spam links, we only see 34 spam using clocking techniques,
which also reﬂects that context-based detection has a low
coverage in face of current comment spam. However, we
test these 34 spam links with Google Safe Browsing (GSB)
[10], none of them has been reported. Thus context-based
detection is still an effective way to ﬁnd new spam within
their limited scope, and our system also can cover such
spam (but can detect more other spam that the context-based
detection can not).
5.5 Applications of Our System
In this part, we will evaluate how our inference results
can be applied to provide early warning for search engine
bots, and to complement current BlackList services.
Early Warning. “nofollow”[13] is a HTML tag which
is designed to instruct search engines that the correspond-
ing links should not be counted for ranking. Usually dif-
ferent search engines have a little different policies in face
of “notfollow“ tags. As for Google [14], it will not trans-
fer PageRank or anchor text across corresponding links. In
this case, search engines can efﬁciently ﬁlter comment spam
if webmasters attach each posting with a “nofollow“ tag.
However, among 35,931 spam harbors we found, only 4,367
harbors contain such tags, which means spam on other har-
bors can be successfully exploited for search rank manipu-
lation. Fortunately, according to our measurement study in
Section 3, there always exists a time lag between the time
that spammers post spam and the time search engines index
the spam. Thus, if we can detect the spam before Google
indexes them, we can also efﬁciently ﬁlter comment spam.
To measure this timeliness, we examine the number of “zero
day spam”, which is the spam that can not be searched out
by Google at the time. Totally we collected 1,364 “zero
day spam” in our test using NEIGHBORWATCHER. Inter-
estingly, when we manually check these “zero day spam”,
we ﬁnd that some spam messages contain randomly gener-
ated domains that have not been registered yet. Thus, it is
possible that spammers may ﬁrst promote these links and
then register them later based on their promoting results.
Figure 14 shows the distribution of daily “zero day spam”.
Figure 14. Zero Day Spam Distribution
We can see that currently we can only detect few “zero
day spam”, because most spammers intend to promote cer-
tain set of spam links that may have already been indexed
by Google before (but search ranks were probably not good
enough). However, as long as spammers begin to promote
new links, our system can quickly ﬁnd more “zero day
spam“. In this case, we can give an early warning to search
engine bots, or search engine bots can integrate our infer-
ence system to help better ﬁlter these comment spam.
BlackList. Existing comment spam blacklists usually
provide a collection of source IP addresses, register emails,
or usernames of spammers. Most of existing online black-
lists [17, 16, 5] collect such spammer information by build-
ing honey blogs/forums. However, we can early imagine
that honey blogs could only collect a limited number of
spam, thus limiting the effectiveness of such approaches.
To measure our inference approach can complement ex-
isting solutions, we compare it with 3 popular online Black-
List services. Note that since our system targets on more
general spam harbors, not all of the harbors provide com-
plete IP and email information of the posting users in public.
Luckily, there does exist some spam harbors in our database
that provide IP or email address information. Thus, we can
compare these inferred IPs and emails with these 3 Blacklist
services.
Table 6 shows the comparison result. We can see that
for both IP and email, our system can always infer new
spammers that are not observed by existing services. Figure
15 shows the daily comparison with these 3 BlackList Ser-
vices. From the ﬁgure, each day we can ﬁnd new spammers
that are not labeled by any of these existing BlackLists. In
addition, considering the dynamic property of IP addresses,
most IP-based BlackLists need to be daily updated. Thus,
for IPs detected by these existing systems, we further check
their “last seen time”, the time of last observation by these
existing services. We ﬁnd most of them are out of date,
which means existing BlackLists observe these spammers
long time ago but in fact they are still active at the moment.
In summary, our system could be a good complement to ex-
isting BlackList systems to actively ﬁnd new spam and to
improve the coverage of existing systems. Furthermore, we
ﬁnd some constant email addresses and IPs keep contribut-
ing to spam, which also reﬂects that spammers intend to
keep utilizing these spam harbors.
Table 6. Comparison with Existing Blacklist
Systems
BlackList
# of IP
# of Email
NeighbourWatcher
StopForum
SpamBust
GlobalSpyware
378
231
185