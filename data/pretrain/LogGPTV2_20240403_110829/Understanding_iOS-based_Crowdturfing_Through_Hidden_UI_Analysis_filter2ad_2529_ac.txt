object tree (i.e., a tree built on layout ﬁles). If the element is
on the blacklist, we ignore its NSString object.
In addition to the text strings in the NSString objects, other
UI content can be embedded in images and therefore cannot
be easily extracted. To collect more semantic information for
crowdturﬁng UI detection, we utilize an app’s meaningful
variable names (e.g., _album_id), class names (e.g., Ticket-
DetailViewController) and method names (e.g., setSongIdsAr-
rayM), which are preserved in the binary’s symbol table by
the Object-C compiler. These human-readable symbols are
recovered by our approach from the variables, class names,
etc. output by Capstone [7] for each checkpoint VC. Also
for the VCs with Web UIs (e.g., UIWebViewController), we
include the text content collected from the URL embedded
in the VC. An example of the data gathered from both UI
layouts and a binary is presented in Table 2.
Crowdturﬁng UI identiﬁcation. Given the UI content re-
covered from each checkpoint VC, we analyze whether such
data is semantically associated with crowdturﬁng: to this end,
770    28th USENIX Security Symposium
USENIX Association
Table 2: Sample text data.
Object Type
UILabel
NSLocalizableString
Text Data
“Proceed to checkout”
“start making money”
Class Name
Method Name
Instance Variables
CFString
URL
“TaxiViewController”, “GameView”
“TicketDetailViewController”
“setSongIdsArrayM:”,
“setBuyAllProductId:”
“_album_id”, “_uploadMedia ”,
“_btnPaid”
“Select photo from photo library”
“more clear free voice calls”
booking.com
“hotel” “city”, “trip”, “taxi”
we ﬁrst preprocess the texts to address the issues like multi-
language, noisy words, and then identify the keywords rep-
resenting their semantics. In the meantime, we crawl a set
of popular crowdturﬁng websites (e.g., Zhubajie [5] and San-
daha [4]) to build a crowdturﬁng word list. Words on the list
are compared with the UI keywords using Word2vec [50]
to ﬁnd out their semantic distances. When such a distance
becomes sufﬁciently small, the checkpoint VC is then ﬂagged
as a hidden crowdturﬁng UI. In the following, we elaborate
on each step of this analysis.
At the preprocessing step, our approach runs Google Trans-
late [2] to convert content in other languages into English.
For the text in the languages without delimiters, Chinese in
particular, we ﬁrst use open source tools [27, 30] to segment
texts into words before the translation; for the class/method
names extracted from the binary, we tokenize them using
regular expressions that cover common naming conventions
(e.g., CamelCase style). Further, we drop all common stop
words (e.g., NLTK stop words), and the frequent words from
iOS frameworks and programming languages (e.g., “UIV-
iewController”, “ignoreTouch:forEvent:” and “raiseExcep-
tion”), as well as program language and debugging related
texts (e.g., “socket”, “connection”, “memory”, “allocation”).
These words come from 74 framework-libraries of iOS 8.2.1,
and are gathered in our research from sections such as __cf-
string and __objc_methname. Selected from these documents
are 1,806 frequent words whose inverse document frequency
(IDF) values are larger than a threshold (we use log(5) in our
implementation). Also 1,031 program language and debug-
ging related words are hand-picked for Objective-C, Swift,
and Javascript.
After removing these words from a checkpoint VC, the
remaining words are then analyzed using afﬁnity propaga-
tion [26], which clusters them based upon their semantics
(represented by the vectors computed using an embedding
technique) and reports the most signiﬁcant cluster. The words
in such a cluster are then used by our approach to represent
the semantics of their hosting VC.
To collect crowdturﬁng keywords, we crawl 280 web pages
from the popular crowdturﬁng websites (i.e., Zhubajie [5] and
Shandaha [4]). From these pages, we identify their topic key-
words using the Latent Dirichlet Allocation (LDA) method.
In this way, we build a crowdturﬁng list of 214 words. A
problem for directly using these words is the observation that
some of the crowdturﬁng words may also appear in legiti-
mate apps: for example, “coupon” is certainly a meaningful
word for a shopping app, not necessarily referring to the illicit
task of bounty hunting. To address this problem, we compare
these words with the keywords extracted from an app’s de-
scription, dropping those related to the app’s publicly stated
functionality before the comparison below.
Given keywords discovered from the checkpoint VCs and
the list of crowdturﬁng words, we run Word2vec [50] on each
of these words, which maps the word to a vector that describes
its semantics. Using these vectors, our approach measures the
semantic relations between the UI keywords and the crowd-
turﬁng keywords by calculating their vectors’ cosine simi-
larities. For each UI keyword, its average similarity with all
the crowdturﬁng keywords is used to determine its relevance
with crowdturﬁng. We ﬁnd that when the average relevance
score of all the keywords of a checkpoint VC reaches 0.525
or above, the VC is nearly certain to be a crowdturﬁng UI.
3.4 Challenges in Identiﬁcation
Here we evaluate Cruiser and elaborate on the challenges in
crowdturﬁng app identiﬁcation.
Evaluation with ground-truth set and unknown set. We
evaluated Cruiser over the following ground-truth datasets:
for the bad set, we collected the apps with hidden crowdturﬁng
UIs from 91ssz [8]. 91ssz is a website that hosts the apps with
the features (e.g., spam forums, earn money) violating Apple’s
guidelines. We manually examined 290 apps and conﬁrmed
17 with hidden crowdturﬁng UIs (the other 273 apps do not
have hidden UIs and are only accessible through third-party
black markets). The good set were gathered from the top
paid app list found from Apple App Store charts, which are
considered to be mostly clean. We randomly sampled 17 of
them (the same size of the bad set) to build the good set. Note
that we manually examined those apps and veriﬁed that they
are indeed benign. Running on these sets, Cruiser shows a
precision of 88.9% and a recall of 94.1%.
Next we further report the results when running our ap-
proach on the unknown set, including all the apps collected
from the Apple App Store (Section 3.1), at each stage of our
analysis pipeline. We statically analyzed disassembled code
and UI layout ﬁles over the 28,625 iOS apps, and discovered
34,679 checkpoint VCs, which are related to 3,999 (14.0%)
apps using conditionally triggered UIs. Then, we executed
the Semantic Analyzer, which ﬂagged 102 apps. We man-
ually examined all of them and found that 93 apps indeed
contain hidden crowdturﬁng UIs. This gives us a precision
USENIX Association
28th USENIX Security Symposium    771
of 91.2%. The 9 falsely detected apps, though not including
crowdturﬁng UIs, also turned out to be less legitimate. Below
we elaborate on the missed apps and the falsely detected apps.
Missed apps. On the ground-truth set, only one crowdturﬁng
app was missed by Cruiser. The app fell through the cracks
due to inadequate semantic content extracted from their UIs.
It is found to construct the URL for the content to be displayed
during its runtime and dynamically loads crowdturﬁng pages
through the URL. While Cruiser can ﬁnd the suspicious view
controller, it cannot statically gather semantic content from
the crowdturﬁng pages and therefore fail to provide enough
semantic information for the Semantic Analyzer to make a
decision.
Determining the number of missed crowdturﬁng apps in
the unknown set (with 28K iOS apps) is challenging. Given
the low density of such malicious apps in the dataset, we
could not randomly sample from the set hoping to capture
ones missed by our methodology. So what we did in our study
is to lower down the threshold used by the Semantic Analyzer
for detection, which improved the recall, at the expense of
precision. With the threshold decreasing from 0.525 to 0.513,
our approach ﬂagged 313 more apps. We manually analyzed
all these apps and found only 3 new crowdturﬁng apps (false
negatives), while the remaining 310 were all false positives.
Looking into these 3 missed apps, interestingly we found
that they were all web-based apps that dynamically download
crowdturﬁng content from the web during their runtime, as
we observed on the ground-truth set.
Falsely detected apps. All false detections reported come
from the apps indeed carrying conditionally triggered UIs.
These apps are not only structurally but also semantically
related to a true crowdturﬁng app. More speciﬁcally, their
hidden UIs all contain monetary content, which is one of the
semantic features for crowdturﬁng apps. For example, among
the 9 false detections, 7 are about “Health & Fitness” but
actually include hidden lottery UIs. The remaining two are
“Education” apps, which declare to be free but later display
a remotely controllable UI asking for payment. Note that all
these UIs are potentially unwanted, since they are undocu-
mented (in the apps’ description) and forbidden by Apple’s
guideline [21]. We consider these apps (with illicit UIs) as
false detections, just because they are not directly related to
crowdturﬁng.
Legitimate use of conditionally triggered UI. In Section 3,
we report the observation of 14% apps including conditionally
triggered UIs. Through a manual analysis, we found that these
apps use two entry UIs to display notiﬁcations, a tour or a
guide for the app, special events (e.g., New Year) and etc. All
their hidden UIs cannot be reached through user interactions.
This demonstrates the importance of the Semantic Analyzer,
which utilizes NLP to determine the irrelevance of these apps
to crowdturﬁng, thereby controlling the FDR of our approach.
3.5 Comparison to Other Approaches
NaiveCruiser: Semantic analysis on all VCs. Cruiser is
characterized by a two-step analysis (by the Structure Miner
and then the Semantic Analyzer), ﬁrst ﬁltering out the VCs
with normal navigation pattern and then analyzing the seman-
tics of suspicious VCs. This strategy is designed to minimize
the overheads incurred by the Semantic Analyzer, which is
crucial for making our system scalable for analyzing the 28K
apps in the wild. In the meantime, there is a concern whether
the performance beneﬁt comes with an impact on the tech-
nique’s effectiveness, making it less accurate. To understand
the problem, we compared our implementation of Cruiser
with an alternative solution, called NaiveCruiser, which con-
ducts a semantic analysis on all VCs in the app. This approach
is fully tuned toward effectiveness, completely ignoring the
performance impact.
In particular, we also evaluated the NaiveCruiser over the
same ground-truth datasets we used to evaluate Cruiser. Run-
ning on these sets, NaiveCruiser shows a precision of 90.9%
and a recall of 93.2%, which is in line with Cruiser (preci-
sion of 88.9% and recall of 94.1%). This indicates that our
two-step design does not affect the effectiveness of detection.
We also show the large performance degrade of NaiveCruiser,
compared to Cruiser, in Appendix.
Crowdturﬁng keyword search. Simply searching for crowd-
turﬁng keywords is not effective. This is because the words
used in crowdturﬁng UI (e.g., money, withdrawal, cash) are
common, which often appear on other legitimate UIs (e.g.,
stock apps, accounting apps). Therefore, a simple keyword-
based approach would bring in a high FDR (see below). Our
approach utilizes a suite of techniques (e.g., looking for struc-
tural features of conditionally triggered UIs and correspond-
ing VCs, removing words related to app descriptions) to avoid
false reporting of legitimate UIs.
To understand how effective these techniques are, we eval-
uated the baseline – the naive keyword search on the 28K
iOS apps. Speciﬁcally, we automatically extracted keywords
from crowdturﬁng content collected from our ground-truth
set, and then manually crafted a list of 32 most representa-
tive keywords for crowdturﬁng tasks (e.g., reward, task and
installation). In the experiment, we studied the effectiveness
of these keywords by ﬁrst searching for the apps contain-
ing individual words and then analyzing their combinations
(those including 2, 3, ···, 32 words). The more keywords an
app includes, the more likely it is problematic but the fewer
such apps would be found. In the end, we did not see any
app involving more than 8 keywords. Among those carrying
no more than 8 words, the highest precision achieved was
15.38% (an FDR of 84.62%), for those with 8 words. In this
case, only 5 apps were reported. By comparison, our approach
achieved a precision of 91.2%, reporting 93 malicious apps
on the unknown set. This result demonstrates that the naive
keyword search is indeed inadequate.
772    28th USENIX Security Symposium
USENIX Association
manage crowdsourced app downloading tasks ( a ). Then, the
intermediary will publish a task on its mobile client and re-
cruit small-time workers ( b ) to do the task. These workers
will install Anjuke and write fake reviews for the app ( c ).
Once done and veriﬁed by the crowdturﬁng platform ( d ), the
workers will get commissions from the platform.
In the rest of the section, we discuss the security implica-
tion introduced by these hidden UI apps, considering both
crowdturﬁng app development and promotion and mobile
crowdturﬁng operations in the value chain. As evidence for
their impacts, those apps successfully inﬁltrated the App Store,
even reached a high rank and bypassed the app vetting mul-
tiple times. In addition, we discovered various hidden UI
techniques and the underground services that support the de-
velopment of such apps. In particular, we revealed a set of
techniques (e.g., logic bomb, scheme) deployed by the cyber-
criminals, as well as the underground services that are willing
to pay $450 for developing such iOS apps. For app promo-
tion, we identiﬁed 40 crowdturﬁng app gateway sites used by
cybercriminals to promote 67.7% of such apps, which also
enabled us to estimate the volume of the users. Furthermore,
we report the ﬁndings related to mobile-based crowdturﬁng
and discuss their insights, which have never been done be-
fore. For example, in contrast to the web-based crowdturﬁng
dominated by a small number of platforms, on the mobile
side we observed a fragmented crowdturﬁng market and a
stealthy iOS crowdturﬁng ecosystem: we detected 93 hidden
crowdturﬁng apps related to 9 campaigns, after clustering
them based on similar app information, code structure and
network behavior. Finally, we report a case study on an app
with a hidden app ranking manipulation UI.
4.2 Landscape
Scope and magnitude. Our study reveals that apps with hid-
den crowdturﬁng UI are indeed trending in the Apple App
store. Altogether, Cruiser detected 93 apps with hidden crowd-
turﬁng UIs, which are related to 67 crowdturﬁng platforms.
To the best of our knowledge, this is the largest ﬁnding on
mobile crowdturﬁng ever reported.
Apps with hidden crowdturﬁng UI, as discovered in our