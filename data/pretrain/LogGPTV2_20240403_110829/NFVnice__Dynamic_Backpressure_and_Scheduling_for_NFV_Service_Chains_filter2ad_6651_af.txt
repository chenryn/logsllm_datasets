### Robin Fashion (represented by MC)

**Results Overview:**
The results are illustrated in Figure 16. For single-core scenarios, NFVnice outperforms the Default scheduler in terms of throughput, particularly for longer chains (3-6 NFs). However, as the chain length increases beyond 7 NFs, the performance improvement with NFVnice diminishes. In multi-core settings, NFVnice significantly enhances throughput, especially when more NFs are multiplexed on a core (e.g., chain lengths > 4) compared to the Default scheduler. The extent of improvement with NFVnice is influenced by the type of NFs and their computational costs, which can vary for different use cases.

### 4.3.8 Tuning and Overhead Considerations

**Tuning NFVnice:**
To optimize the key parameters of NFVnice, such as `HIGH_WATER_MARK` and `LOW_WATER_MARK`, we measure several metrics, including throughput, wasted work, context-switch overheads, and Instructions per Cycle (IPC). These thresholds for queue occupancy in the Rx ring are critical for effective performance. Additionally, varying flow arrival rates complicate the challenge of fair scheduling.

**Comparison with Other Approaches:**

- **PSPAT [45]:** A recent host-only software packet scheduler that aims to provide a scalable framework by decoupling the packet scheduler algorithm from dispatching packets to the NIC for high performance. NFVnice, in contrast, focuses on fairly allocating CPU resources across NFs based on packet processing cost and flow arrival rate.
  
- **PIFO [48]:** Introduces the packet-in-first-out philosophy, distinct from the typical first-in-first-out model. NFVnice leverages this approach to decide whether to accept and queue a packet for processing or discard it upon arrival. This selective early discard method avoids dropping partially processed packets, thereby saving CPU cycles and allowing judicious allocation to other contending NFs.

**User Space Scheduling and Related Frameworks:**

- **Cooperative User-Space Scheduling [2, 6]:** Provides low-cost context switching, significantly faster than regular Pthreads. However, it requires threads to cooperate, meaning each thread must voluntarily yield to ensure others get CPU time. This necessitates frequent rescheduling points, adding complexity to NF development. Moreover, all L-threads share the same priority and kernel thread, limiting selective prioritization and QoS differentiation. NFVnice's backpressure mechanism can still be effectively used to manage CPU yielding.

- **E2 [39] and VPP [4]:** Host multiple NFs within a shared address space, executed as function calls by a single thread. This reduces NUMA and cross-core packet chaining overheads but is inflexible and hinders third-party NF deployment.

**Congestion Control and Backpressure:**

- **DCTCP [7] and MQ-ECN [8]:** Leverage ECN for congestion control in data center networks. NFVnice, however, addresses the unique challenges of NFV environments where flows are steered through service chains. Early detection of overload is crucial to avoid resource wastage. NFVnice uses both ECN and backpressure to quickly detect and mitigate congestion, ensuring efficient and fair handling of high load scenarios.

- **Fair Queueing [17, 31]:** Proposes fair sharing of network resources among multiple tenants by distributing flows to different processing entities. NFVnice, on the other hand, achieves fairness by appropriately scheduling NFs that process different flows, ensuring a fair share of CPU resources.

### 6. Conclusion

As the use of highly efficient user-space network I/O frameworks like DPDK becomes more prevalent, there is a growing need to mediate application-level performance requirements across the user-kernel boundary. OS-based schedulers lack the necessary information to provide higher-level goals for packet processing, such as rate proportional fairness, which accounts for both NF processing cost and arrival rate. By carefully tuning scheduler weights and applying backpressure to efficiently shed load early in the NFV service chain, NFVnice provides substantial improvements in throughput and drop rate while dramatically reducing wasted work. This allows the NFV platform to handle overload scenarios gracefully, maintaining efficiency and fairness.

Our implementation of NFVnice demonstrates how an NFV framework can efficiently tune the OS scheduler and integrate backpressure to meet performance goals. Our results show that selective backpressure leads to more efficient resource allocation for NF service chains within or across cores, and scheduler weights can provide rate proportional fairness, regardless of the scheduler used.

### 7. Acknowledgements

This work was supported by EU FP7 Marie Curie Actions CleanSky ITN project Grant No. 607584, US NSF grants CNS-1522546 and CNS-1422362, and the Department of the Army, US Army Research, Development, and Engineering Command grant W911NF-15-1-0508. We also thank Huawei Technologies Co. Ltd. for their HIRP Grant. Special thanks to our shepherd, Justine Sherry, and the anonymous reviewers for their valuable feedback; Victor G. Hill for setting up our evaluation testbed; and Dr. Jiachen Chen and Shriya Kulkarni for their help and ideas on graph and plot representation.

### References

[References remain unchanged and are listed as provided in the original text.]