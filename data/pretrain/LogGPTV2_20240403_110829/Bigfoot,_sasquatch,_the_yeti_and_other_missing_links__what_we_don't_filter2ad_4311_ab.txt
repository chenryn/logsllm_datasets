ture Model (BMM), i.e., the number of observations of a link is a
random variable formed by ﬁrst choosing the class of the link, and
then choosing the number of observations of that link based on a
Binomial distribution with class dependent observation probability.
3.1 Estimation of parameters: known class
We ﬁrst consider estimation of parameters assuming we know
the class of all links. In this situation, we can consider each class
independently as if it followed a single class model. If we have
K independent, homogeneous monitors, then the number of times
we observe a link in class j will follow a Binomial distribution
B(K, pj) where pj is the probability that we observe the link with
a single monitor. The probability that we observe a class j link k
times with K monitors is
prob{k} =
j (1 − pj)(K−k).
pk
!
(3)
K
k
If we knew that class j (which we denote Cj) has Ej links, then
the Maximum Likelihood Estimator (MLE) of pj given link i is
observed ki times out of K is
P
ˆpj =
i∈Cj
EjK
ki
.
(4)
However, we do not know Ej a priori. We only know about links
that are observed at least once. Measurement of Ej is equivalent to
estimating the number of hidden links!
Ignoring for the moment the class (i.e., the subscript j), in fact
what we really observe is the conditional distribution
pk(1 − p)(K−k)
1 − (1 − p)K
prob{k|k > 0} =
K
k
.
(5)
!
This is commonly known as a truncated Binomial distribution [4],
and estimation of its parameters will lead to estimates of prob{k =
0}, and hence an estimate for the number of hidden links.
The MLE for the truncated Binomial distribution is given in [11].
However, there is no simple closed form description of the MLE,
but rather the MLE estimator ˆp will be the solution to the equation
EobsKp = [1 − (1 − p)K]
ki,
(6)
EobsX
i=1
where Eobs is the number of observed links. In the preceding statis-
tics literature (which dates from as far back as the 50’s) some effort
went into algorithms and tables to solve this equation without com-
puters. Given modern computing resources it is rather easier to use
a simple iterative solution. To ﬁnd the value of ˆp which satisﬁes
this equation we take
PEobs
PEobs
i=1 ki
EobsK
i=1 ki
EobsK
ˆp(0) =
ˆp(i+1) =
,
[1 − (1 − ˆp(i))K ].
(7)
We can easily prove ˆp(i) converges to a unique ﬁxed point satis-
fying (6).
In practice we found that it converged quickly. The
fact that it is a MLE estimate guarantees that it is asymptotically
unbiased and efﬁcient. In practice we found that for E as small
as 1000 the bias is very small, and the mean-squared error of the
estimate is very close to the Cramér-Rao lower bound. Addition-
ally, tests of the errors showed that they were approximately Gaus-
sian. We omit these results to save space, and because they are
implicit in following results. An additional implication is that ˆE =
Eobs/(1−(1− ˆp)K)) will be a MLE estimator for the total number
of links.
3.2 Multi-class observations
In the problem above, we assumed that we knew the classiﬁca-
tion of the links. We don’t a priori know this classiﬁcation, and so
we construct an Expectation Maximization (EM) estimation algo-
rithm (see for instance [12]) which estimates both the class, and the
class models.
The EM algorithm is an iterative approach that uses two steps:
(i) an Expectation step in which we calculate expected values of
some “hidden” variable (in this case the class of the links) and (ii)
a Maximization stage where we perform a MLE of the system pa-
rameters. In more detail deﬁne two additional parameters
wj = estimated proportion of links in class j,
= estimated probability{link i ∈ class j}.
c(i)
j
We start the algorithm by initializing ˆpj and wj the estimates of
the important parameters for our distributions. The choice of initial
Class
1
2
3
4
5
6
7
pj
0.010906
0.140579
0.345960
0.557597
0.758552
0.917098
0.998352
wj
0.248714
0.052389
0.036864
0.049963
0.060776
0.068741
0.482553
Table 1: Model parameters for C = 7 simulations. The param-
eters are those found from the EM algorithm applied to the
AS-graph data from October 2007.
conditions is not particularly important, though choosing parame-
ters closer to the true parameters will speed convergence. We use
the uniform initialization ˆpj = j/(C + 1) and wj = 1/C, where
C is the number of classes.
The algorithm then acts as follows:
While (not converged) do
E step
estimate c(i)
j
j ← ˆwjP{ki|K, ˆpj}
c(i)
M step
for j=1 to C
(i)
i kic
j
P
(i)
i c
j
While (not converged) do
ˆpj ← P
[1 − (1 − ˆpj)K]
ˆwj ←P
end while
j /(Eobs(1 − (1 − ˆpj)K))
i c(i)
K
end for
end while
where P{ki|K, pj} is the Binomial distribution B(K, pj) given in
(3), ki is the number of observations of link i, and Eobs is the total
number of links observed.
Convergence occurs when the total change in the estimates ˆpj
falls below  = 10−6. The EM algorithm is in general guaranteed
to converge, and in our example we ﬁnd it converges (for this case)
reasonably quickly (results below).
We also perform a hard classiﬁcation of observed links for use
in assessing the relationship between link class and policies. We
select the class with the highest likelihood, i.e., the class of link i is
argmaxj c(i)
j . The estimated number of observed links in each class
is deﬁned to be ˆEj = Ej
obs is the
number of links observed in each class.
3.3 Performance
obs/(1 − (1 − ˆpj)K ), where Ej
The ﬁrst test of the above algorithm is its performance when the
model (e.g., the value of C) is correct. We use a set of realistic
parameters derived from the AS-graph data (for October 2007) and
shown in Table 1. We will use a total number of observed links
E = 50, 000, which lies within the range of observations over the
time interval of our data. We simulate the observations of the links
5000 times using the BMM with C = 7. Results for estimates of
ˆE are shown in Figure 1 in the form 100 ˆE/E so that we can see
the relative errors as a percentage. We can see that bias is very
small and that errors are of the order of ±1%, and approximately
Gaussian. The hard classiﬁcation of the links was correct for 94%
of links (across all 5000 simulations, and 50,000 links).
4. MODEL SELECTION
When we consider real data, there is an additional problem: C is
unknown. From the perspective of simplicity we can easily argue
1500
1000
500
r
e
b
m
u
n
0
98
99
100
101
relative estimate of N
102
103
Figure 1: Results of 5000 simulations of EM estimation algo-
rithm with 7 classes (as shown in Table 1). Vertical lines show
the 2.5th and 97.5th percentile, and mean.
in favor of smaller C, even if it creates small errors in the model
ﬁt to the data, and so we need to trade off model accuracy with
the quality of the ﬁt to the data. This tradeoff is often captured
through information criterion, e.g., the Akaike Information Crite-
rion (AIC). In the context of normally distributed errors, it is de-
ﬁned by AIC = n[ln(2πRSS/n) + 1] + 2P , where RSS is the
Residual Sum of Squared errors, n is the number of data points
and P is the number of model parameters. The minimum value of
the AIC can be used to select the model that best satisﬁes the trade
off between model simplicity and accuracy. We compare the esti-
mated and empirical values of the truncated BMM’s distribution,
i.e., prob{k|k > 0}, so n = K and P = 2C. We also calculate a
second version of the AIC, recognizing that the critical values (for
estimating the number of hidden links) of the BMM distribution
are those corresponding to class 1 and 2, and hence we calculated a
RSS for the ﬁrst 9 elements of the distribution. Figure 2 (a) shows
the two AICs. They take their minima for C = 9 and C = 7.
Figure 2 (b) shows the estimated number of links with respect to
C. Note that it varies insigniﬁcantly (with respect to the 95th per-
centile conﬁdence intervals shown on the plot) for C = 7−10.
Hence in tests (e.g., in Section 3.3) we have used C = 7 because
of the reduced computational cost (see Figure 2 (c)).
Figure 3 shows the observed distribution of link observations,
and the estimated BMM for C = 7. We can see that the ﬁt is quite
satisfactory. Note that the 0 term of the histogram does not appear
in the observations because this data point is censored by our very
lack of observations. The BMM extrapolates this value estimating
the number of hidden links. The parameters of this distribution are
shown in Table 1.
5. HOW BIG IS THE AS-GRAPH?
We now have the required results to answer the question of inter-
est: how big is the Internet? More precisely, “how many links are
there in the AS-graph?” We use the above algorithm choosing C
based on the AIC test. Figure 4 shows the number of observed and
inferred links since January 2004, along with the number of usable
monitors. We can see that the number of monitors has not changed
much, but that there is clear growth in both the observed, and esti-
mated number of links. The trend is approximately linear, as shown
by the linear trend ﬁtted to the data. The trend avoids some of the
potential problems with variance of individual estimates (careful
examination of the largest deviations in early 2005 suggests that
100
0
−100
C
A
I
−200
−300
−400
−500
2
all values
1st 9 values
4
6
number of classes C
8
10
75
70
65
’
)
s
0
0
0
1
(
s
k
n
i
l
f
o
r
e
b