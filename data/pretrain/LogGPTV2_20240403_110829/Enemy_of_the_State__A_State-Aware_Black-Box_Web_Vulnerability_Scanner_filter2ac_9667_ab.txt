Collapsing similar states. The state-change detection
algorithm detects only when the state has changed, how-
ever, we need to understand if we returned to a previ-
ous state. This is necessary because if we detect a state
change, we want to know if this is a state we have pre-
viously seen or a brand new state. We reduce this prob-
lem to a graph coloring problem, where the nodes are
the states and an edge between two nodes means that the
states cannot be the same. We add edges to this graph
by using the requests and responses, along with rules to
determine when two states cannot be the same. After the
graph is colored, states that are the same color are col-
lapsed into the same state. Details of this state-merging
technique are provided in Section 4.3.
Navigating. We have two strategies for crawling the web
application.
First, we always try to pick a link in the last response.
The rational behind choosing a link in the last response
is that we emulate a user browsing the web application.
In this way, we are able to handle multi-step processes,
such as previewing a comment before it is committed.
Second, for each state, we make requests that are the
least likely to change the state of the web application.
The intuition here is that we want to ﬁrst see as much of a
state as possible, without accidentally changing the state,
in case the state change is permanent. Full details of how
we crawl the web application are provided in Section 4.4
Page
/html/body/div/span/a
/html/body/div/form
/user
/post
profile.php
edit.php
(id, page)
(all, sorted)
(text, email, id)
(0)
(0, 1)
(5)
(NULL)
(5)
Figure 4: Representation of a page’s link vectors stored
in a preﬁx tree. There are ﬁve links present on this tree,
as evidenced by the number of leaf nodes.
our state-change detection algorithm, we are not inter-
ested in changes to the content, but rather to changes in
the navigation structure. We focus on navigation changes
because the links on a page deﬁne how a user can inter-
act with the application, thus, when the links change, the
web application’s state has changed.
Therefore, we model a page by composing all the an-
chors and forms. First, every anchor and form is trans-
formed into a vector constructed as follows:
hdompath, action, params, valuesi
4 Technical Details
where:
Inferring a web application’s state machine requires con-
cretely deﬁning aspects such as page clustering or navi-
gation. However, we wish to stress that this is one imple-
mentation of the state machine inference algorithm and
it may not be optimal.
4.1 Clustering Similar Pages
Our reason for grouping similar pages together is
twofold: Prevent inﬁnite scanning of the website by
grouping the “inﬁnite” areas together and detect when
the state has changed by comparing page responses in an
efﬁcient manner.
• dompath is the DOM (Document Object Model)
path of the HTML link (anchor or form);
• action is a list where each element is from the href
(for anchors) or action (for forms) attribute split
by ‘/’;
• params is the (potentially empty) set of parameter
names of the form or anchor;
• values is the set of values assigned to the parameters
listed in params.
For instance, an anchor tag with the href attribute of
/user/profile.php?id=0&page might have the fol-
lowing link vector:
4.1.1 Page Model
h/html/body/div/span/a, /user, proﬁle.php, (id, page), (0)i
The output of a web application is usually an HTML
document (it can actually be any arbitrary content, but
we only consider HTML content and HTTP redirects).
An HTML page is composed of navigational informa-
tion (anchors and forms) and user-readable content. For
All link vectors of a page are then stored in a preﬁx
tree. This preﬁx tree is the model of the page. A preﬁx
tree for a simple page with ﬁve links is shown in Fig-
ure 4. The link vector previously described is highlighted
in bold in Figure 4.
APT
(/html/body/div/span/a, /html/body/div/form)
REDIRECT
(/html/body/table/div/a)
(/user, /post)
/messages
(/comments)
(profile.php, edit.php)
show.php
(all.php)
((id, page), (all, sorted), (text, email, id))
(id)
(sorted)
((0), (0, 1), (5), (NULL), (5))
((5), (5, 3), (1), (YES), (10))
(1)
(NULL)
(ASC)
(DSC)
(RAND)
Figure 5: Abstract Page Tree. Every page’s link vector is stored in this preﬁx tree. There are seven pages in this tree.
The page link vector from Figure 4 is highlighted in bold.
HTTP redirects are handled as a special case, where
the only element is a special redirect element having the
target URL as the value of the location attribute.
4.1.2 Page Clustering
To cluster pages, we use a simple but efﬁcient algorithm.
As described in the previous section, the model of a page
is a preﬁx tree representing all the links contained in the
page.
These preﬁx trees are translated into vectors, where
every element of this vector is the set of all nodes of a
given level of the preﬁx tree, starting from the root. At
this point, all pages are represented by a page link vector.
For example, Figure 4 has the following page link vector:
h(/html/body/div/span/a, /html/body/div/form),
(/user, /post),
(proﬁle.php, edit.php),
((id, page), (all, sorted), (text, email, id)),
((0), (0, 1), (5), (NU LL), (5))i
The page link vectors for all pages are then stored in
another preﬁx tree, called the Abstract Page Tree (APT).
In this way, pages are mapped to a leaf of the tree. Pages
which are mapped to the same leaf have identical page
link vectors and are considered to be the same page. Fig-
ure 5 shows an APT with seven pages. The page from
Figure 4 is bold in Figure 5.
However, we want to cluster together pages whose
page link vectors do not match exactly, but are similar
(e.g., shopping cart pages with a different number of el-
ements in the cart). A measure of the similarity between
two pages is how many elements from the beginning of
their link vectors are the same between the two pages.
From the APT perspective, the higher the number of an-
cestors two pages (leaves) share, the closer they are.
Therefore, we create clusters of similar pages by se-
lecting a node in the APT and merging into one cluster,
called an Abstract Page, all the leaves in the correspond-
ing subtree. The criteria for deciding whether to cluster
a subtree of depth n from the root is the following:
• The number of leaves is greater than the median
number of leaves of all its siblings (including itself);
in this way, we cluster only subtrees which have a
larger-than-usual number of leaves.
• There are at least f (n) leaves in the subtree, where
f (n) is inversely related to n. The intuition is that
the fewer ancestors a subtree has in common (the
higher on the preﬁx tree it is), the more pages it must
have to cluster them together. We have found that
the function f (n) = 8(1 + 1
n+1 ) works well by ex-
perimental analysis on a large corpus of web pages.
• The pages share the same dompath and the ﬁrst ele-
ment of the action list of the page link vector; in this
way, all the pages that are clustered together share
the same link structure with potentially different pa-
rameters and values.
4.2 Determine the State-Changing Request
When a state change is detected, we must determine
which request actually changed the web application’s
state. Recall that we detect a state change when we make
a request that is identical to a previous request, yet has
different output. At this point, we have a list of all the
requests made between the latest request R and the re-
quest R′ closest in time to R such that R is identical to R′.
We use a heuristic to determine which request in this list
changed the web application’s state, choosing the request
i between R′ and R which maximizes the function:
score(ni,transition , ni,seen , distancei)
where:
• ni,transition is the number of times the request caused
a state transition;
• ni,seen is the number of times the request has been
made;
• distancei is how many requests have been made be-
tween request R and request i.
The function score is deﬁned as:
score(ni,transition , ni,seen , distancei) =
1 − (1 − ni,transition+1
ni,seen+1
)2 + BOOSTi
distancei+1
BOOSTi is .2 for POST requests and .1 for GET requests.
We construct the score function to capture two prop-
erties of web applications:
1. A POST request is more likely to change the state
than a GET request. This is suggested by the HTTP
speciﬁcation, and score captures this intuition with
BOOSTi.
2. Resistant to errors. Because we cannot prove that
the selected request changed the state, we need to be
resistant to errors. That is why score contains the ra-
tio of ni,transition to ni,seen. In this way, if we acciden-
tally choose the wrong state-changing request once,
but then, later, make that request many times with-
out changing the state, we are less likely to choose
it as a state-changing request.
4.3 Collapsing Similar States
Running the state detection algorithm on a series of re-
quests and responses will tell us when the state has
changed. At this point, we consider each state unique.
This initial state assignment, though, is not optimal, be-
cause even if we encounter a state that we have seen in
the past, we are marking it as new. For example, in the
case of a sequence of login and logout actions, we are
actually ﬂipping between two states, instead of entering
a new state at every login/logout. Therefore, we need
to minimize the number of different states and collapse
states that are actually the same.
The problem of state allocation can be seen as a graph-
coloring problem on a non-planar graph [27]. Let each
state be a node in the graph G. Let two nodes a and b be
connected by an edge (meaning that the states cannot be
the same) if either of the following conditions holds:
1. If a request R was made when the web application
was in states a and b and results in pages in different
clusters. The intuition is that two states cannot be
the same if we make an identical request in each
state yet receive a different response.
2. The two states a and b have no pages in common.
The idea is to err on the conservative side, thus we
require that two states share a page before collaps-
ing the states into one.
After adding the edges to the graph by following the
previous rules, G is colored. States assigned the same
color are considered the same state.
To color the nodes of G, we employ a custom greedy
algorithm. Every node has a unique identiﬁer, which is
the incremental number of the state as we see it in the
request-response list. The nodes are ordered by identi-
ﬁer, and we assign the color to each node in a sequential
way, using the highest color available (i.e., not used by
its neighbors), or a new color if none is available.
This way of coloring the nodes works very well for
state allocation because it takes into account the temporal
locality of states: In particular, we attempt to assign the
highest available color because it is more likely for a state
to be the same as a recently seen state rather than one
seen at the beginning of crawling.
There is one ﬁnal rule that we need to add after the
graph is colored. This rules captures an observation
about transitioning between states: If a request, R, tran-
sitions the web application from state a1 to state b, yet,
later when the web application is in state a2, R transitions
the web application to state c, then a1 and a2 cannot be
the same state. Therefore, we add an edge from a1 to a2
and redo the graph coloring.
We continue enforcing this rule until no additional
edges are added. The algorithm is guaranteed to con-
verge because only new edges are added at every step,
and no edges are ever removed.
At the end of the iteration, the graph coloring output
will determine the ﬁnal state allocation—all nodes with
the same color represent the same state (even if seen at
different stages during the web application crawling pro-
cess).
4.4 Navigating
Typical black-box web vulnerability scanners make con-
current HTTP requests to a web application to increase
performance. However, as we have shown, an HTTP
request can inﬂuence the web application’s state, and,
in this case, all other requests would occur in the new
state. Also, some actions require a multi-step, sequential
process, such as adding items to a shopping cart before
purchasing them. Finally, a user of the web application
does not browse a web application in this parallel fash-
ion, thus, developers assume that the users will browse
sequentially.
def f u z z _ s t a t e _ c h a n g i n g ( f u z z _ r e q u e s t ) :
m a k e _ r e q u e s t ( f u z z _ r e q u e s t )
if s t a t e _ h a s _ c h a n g e d () :
if s t a t e _ i s _ r e v e r s i b l e () :
m a k e _ r e q u e s t s _ t o _ r e v e r t _ s t a t e ()
if not b a c k _ i n _ p r e v i o u s _ s t a t e () :
r e s e t _ a n d _ p u t _ i n _ p r e v i o u s _ s t a t e ()
else :
r e s e t _ a n d _ p u t _ i n _ p r e v i o u s _ s t a t e ()
Listing 1:
request.
Psuedocode for
fuzzing state-changing
Our scanner navigates a web application by mimicking
a user browsing the web application sequentially. Brows-
ing sequentially not only allows us to follow the devel-
oper’s intended path through the web application, but it
enables us to detect which requests changed the web ap-
plication’s state.
Thus, a state-aware crawler must navigate the applica-
tion sequentially. No concurrent requests are made, and
only anchors and forms present in the last visited page
are used to determine the next request.
In the case of
a page with no outgoing links we go back to the initial
page.
Whenever the latest page does not contain unvisited
links, the crawler will choose a path from the current
page towards another page already seen that contains
links that have not yet been visited. If there is no path
from the current page to anywhere, we go back to the
initial page. The criteria for choosing this path is based
on the following intuitions:
• We want to explore as much of the current state as
possible before changing the state, therefore we se-
lect links that are less likely to cause a state transi-
tion.
• When going from the current page to a page with an
unvisited link, we will repeat requests. Therefore,
we should choose a path that contains links that we
have visited infrequently. This give us more infor-
mation about the current state.
The exact algorithm we employ is Dijkstra Shortest
Path Algorithm [14] with custom edge length. This edge
length increases with the number of times we have previ-
ously visited that link. Finally, the edge length increases
with how likely the link is to cause a state change.
5 State-Aware Fuzzing
After we crawl the web application, our system has in-
ferred, as much as possible, the web application’s state
machine. We use the state machine information, along
with the list of request–responses made by the crawler, to
drive a state-aware fuzzing of the web application, look-
ing for security vulnerabilities.
To fuzz the application in a state-aware manner, we
need the ability to reset the web application to the initial
state (the state when we started crawling). We do not use
this ability when crawling, only when fuzzing. It is nec-
essary to reset the application when we are fuzzing an
irreversible state-changing request. Using the reset func-
tionality, we are able to recover from these irreversible
state changes.
Adding the ability to reset the web application does
not break the black-box model of the web application.
Resetting requires no knowledge of the web application,
and can be easily performed by running the web applica-
tion in a virtual machine.
Our state-aware fuzzing starts by resetting the web ap-
plication to the initial state. Then we go through the re-
quests that the crawler made, starting with the initial re-
quest. If the request does not change the state, then we
fuzz the request as a typical black-box scanner. However,
if the request is state-changing, we follow the algorithm
shown in Listing 1. The algorithm is simple: We make
the request, and if the state has changed, traverse the in-
ferred state machine to ﬁnd a series of requests to tran-
sition the web application to the previous state. If this
does not exist, or does not work, then we reset the web
application to the initial state, and make all the previ-
ous requests that the crawler made. This ensures that the
web application is in the proper state before continuing
to fuzz.
Our state-aware fuzzing approach can use any fuzzing
component. In our implementation, we used the fuzzing
plugins of an open-source scanner, w3af [37]. The
fuzzing plugins take an HTTP request and generate vari-
ations on that request looking for different vulnerabili-
ties. Our state-aware fuzzing makes those requests while
checking that the state does not unintentionally change.
6 Evaluation
As shown in previous research [16], fairly evaluating
black-box web vulnerability scanners is difﬁcult. The
most important, at least to end users, metric for compar-
ing black-box web vulnerability scanners is true vulner-
abilities discovered. Comparing two scanners that dis-
cover different vulnerabilities is nearly impossible.
There are two other metrics that we use to evaluate
black-box web vulnerability scanners:
• False Positives. The number of spurious vulnera-
bilities that a black-box web vulnerability scanner
reports. This measures the accuracy of the scan-
ner. False positives are a serious problem for the
end user of the scanner—if the false positives are
Application
Gallery
PhpBB v2
PhpBB v3