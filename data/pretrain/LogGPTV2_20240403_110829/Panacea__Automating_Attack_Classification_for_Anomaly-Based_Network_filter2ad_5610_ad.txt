(e.g., after other actions taken by the attacker). This event occurs often in our
benchmarks when the system selects the wrong class. Both SVM and RIPPER
can generate a classiﬁcation conﬁdence value for each attack. This value can be
used to evaluate the accuracy of the classiﬁcation. The lower the classiﬁcation
value is (in a range from 0.0 to 1.0), the more likely the classiﬁcation is wrong
(see Table 8 for average conﬁdence values for DSC).
The conﬁdence value can be taken into consideration to detect possible mis-
classiﬁcation. Users can set a minimum conﬁdence value (e.g., 0.5). Any alert
with a lower conﬁdence value is forwarded to a human operator for manual clas-
siﬁcation. With this additional check, we are able to increase the percentage of
total attacks correctly classiﬁed up to 95% for SVM and 94% for RIPPER (when
using the standard training set, without additional training samples generated
Table 8. Eﬀects of conﬁdence evaluation for DSC , when Panacea is trained with the
standard DSB. When considering the classiﬁcation conﬁdence to forward alerts for
manual classiﬁcation, the human operator classiﬁcation increases by 3% and 5% the
overall accuracy rate by inspecting 10 and 13 alerts, out of 100, when Panacea uses
SVM and RIPPER respectively.
Average conﬁdence value for correctly classiﬁed attacks
Average conﬁdence value for misclassiﬁed attacks
Percentage of total attacks correctly classiﬁed without
conﬁdence evaluation
Percentage of total attacks correctly classiﬁed with
conﬁdence evaluation
# of alerts forwarded for manual classiﬁcation
# of forwarded attacks that were actually wrongly classiﬁed
3/10
# of forwarded attacks that were actually correctly classiﬁed 7/10
10/100
SVM RIPPER
0.75
0.37
0.62
0.43
92.0% 89.0%
95.0% 94.0%
13/100
5/13
8/13
Panacea: Automating Attack Classiﬁcation
17
Table 9. Actions that users have to take with or without Panacea w.r.t. alert classiﬁ-
cation for each data set we use during benchmarks.
Without Panacea
DSA Classify any alert
DSB Classify any alert
DSC Classify any alert
User actions
With Panacea
No action to take
Classify alerts used during training
No action to take
(alerts have been previously classiﬁed)
with Sploit). The additional workload involves also the manual classiﬁcation of
alerts which have been correctly classiﬁed by the system but whose conﬁdence
value is lower than the set threshold. However, less than 10 alerts (out of 100)
have been forwarded for manual classiﬁcation when this action was not needed.
Table 8 reports the details regarding the evaluation of the conﬁdence value.
2.8 Usability in Panacea
Panacea aims not only to provide automatic attack classiﬁcation for an ABS, but
to improve usability as well. In automatic mode, Panacea performs an accurate
classiﬁcation (more than 75% of correctly classiﬁed attacks). In semi-automatic
and manual modes, users actively take part in the classiﬁcation process: how-
ever, users are requested to provide a limited input (i.e., a class label). Panacea
classiﬁes attacks systematically and automates (1) the extraction of relevant in-
formation used to distinguish an attack class from another and (2) the update of
the classiﬁcation model. These tasks are usually left to the user’s experience and
knowledge, thus they can be error-prone and not comprehensive. Table 9 reports
actions that users have to take with and without the support of Panacea.
3 Related Work
Although the lack of attack classiﬁcation is a well-known issue in the ﬁeld of
anomaly-based intrusion detection, little research has been done on this topic.
Robertson et al. [2] suggest to use heuristics to infer the class of (web-based)
attacks. This approach has several drawbacks. Users have to generate heuristics
(e.g., regular expressions) to identify attack classes. They have to enumerate all
of the possible attack variants, and update the heuristics each time a new attack
variation is detected. This is a time consuming task. Panacea can operate in an
automatic way, by extracting attack information from any SBS, or employ an
ad-hoc classiﬁcation, with the user providing only the attack class.
Wang and Stolfo [12] use a “Z-String” to distribute among other ABSs attack
payloads to enhance detection. A Z-String contains the information resulting
from the n-gram analysis of the attack payload. Once a certain payload has been
ﬂagged as malicious, the corresponding Z-String can be distributed to other IDSs
to detect the attack also, and stop it at an early stage (think of a worm). If some
18
D. Bolzoni, S. Etalle, and P.H. Hartel
traﬃc matches a certain Z-String, that data is likely to be a real attack. Although
a Z-String is not used for attack classiﬁcation, by attaching a class label it would
be possible to classify each attack. However, this approach is not systematic, as
each attack that does not exactly match any Z-String would have to be manually
classiﬁed. A Z-String is based on a frequency-based n-gram analysis, thus an
exact match could be diﬃcult to achieve. On the other hand, Panacea applies
a systematic classiﬁcation using the more precise binary-based n-gram analysis.
Panacea can also use as a source of information the alerts generated by an SBS,
and not only by an ABS.
4 Conclusion
We present Panacea, a system that automatically and systematically classiﬁes
attacks detected by a payload-based ABS (and consequently classiﬁes the gener-
ated alerts). Panacea extracts information from alerts during a training phase,
then predicts the attack class for new alerts. The alerts used to train the classiﬁ-
cation engine can be generated by an SBS as well as an ABS. In the former case,
no manual intervention is requested (the system operates in automatic mode),
as Panacea automatically extracts the attack class from the alert. In the latter
case, the user is required to provide the attack class for each alert used to train
the classiﬁcation engine.
Panacea improves the usability and makes it possible to integrate anomaly-
based with signature-based IDSs. Benchmarks show that the approach is eﬀective
in classifying attacks, even those that have not been detected before (and not
used for training). Although Panacea works in an automatic way, users can
employ ad-hoc classiﬁcations, and even manually tune the engine for more precise
classiﬁcations.
Future work. Panacea can use diﬀerent algorithms to classify alerts. The bench-
marks with SVM and RIPPER, which approach the classiﬁcation problem in
two diﬀerent ways, show that each algorithm has its strong points, depending
on the circumstances. A possible extension is to use a cascade of SVM and RIP-
PER, in order to increase the overall accuracy. We would then use SVM for early
classiﬁcation (when the number of samples is low, and when RIPPER does not
perform well), then, when the number of alerts increases, we can train RIPPER,
thanks to the batch training mode, and use it for classiﬁcation as well (RIPPER
performs better than SVM when the number of training samples is high).
References
1. Ghosh, A., Schwartzbard, A.: A study in using neural networks for anomaly and
misuse detection. In: SSYM 1999: Proc. 8th conference on USENIX Security Sym-
posium, pp. 141–152. USENIX Association (1999)
2. Robertson, W., Vigna, G., Kruegel, C., Kemmerer, R.: Using generalization and
characterization techniques in the anomaly-based detection of web attacks. In:
NDSS 2006: Proc. 13th ISOC Symposium on Network and Distributed Systems
Security (2006)
Panacea: Automating Attack Classiﬁcation
19
3. Ning, P., Cui, Y., Reeves, D.: Constructing attack scenarios trough correlation
of intrusion alerts. In: CCS 2002: Proc. 9th ACM Conference on Computer and
Communication Security, pp. 245–254. ACM Press, New York (2002)
4. Cuppens, F., Ortalo, R.: LAMBDA: A Language to Model a Database for Detection
of Attacks. In: Debar, H., M´e, L., Wu, S.F. (eds.) RAID 2000. LNCS, vol. 1907,
pp. 197–216. Springer, Heidelberg (2000)
5. Debar, H., Wespi, A.: Aggregation and Correlation of Intrusion-Detection Alerts.
In: Lee, W., M´e, L., Wespi, A. (eds.) RAID 2001. LNCS, vol. 2212, pp. 85–103.
Springer, Heidelberg (2001)
6. Ning, P., Xu, D.: Learning attack strategies from intrusion alerts. In: CCS 2003:
Proc. 10th ACM conference on Computer and Communications Security, pp. 200–
209. ACM Press, New York (2003)
7. Valeur, F., Vigna, G., Kruegel, C., Kremmerer, R.: A comprehensive approach to
intrusion detection alert correlation. IEEE Trans. Dependable Secur. Comput. 1(3),
146–169 (2004)
8. Roesch, M.: Snort - Lightweight Intrusion Detection for Networks. In: LISA 1999:
Proc. 13th USENIX Conference on System Administration, pp. 229–238. USENIX
Association (1999)
9. Sourceﬁre: Snort Network Intrusion Detection System, http://www.snort.org
10. Damashek, M.: Gauging similarity with n-grams: Language-independent catego-
rization of text. Science 267(5199), 843–848 (1995)
11. Forrest, S., Hofmeyr, S.: A Sense of Self for Unix Processes. In: S&P 1996: Proc.
17th IEEE Symposium on Security and Privacy, pp. 120–128. IEEE Computer
Society Press, Los Alamitos (2002)
12. Wang, K., Stolfo, S.: Anomalous Payload-Based Network Intrusion Detection. In:
Jonsson, E., Valdes, A., Almgren, M. (eds.) RAID 2004. LNCS, vol. 3224, pp.
203–222. Springer, Heidelberg (2004)
13. Wang, K., Parekh, J., Stolfo, S.: Anagram: a Content Anomaly Detector Resistant
to Mimicry Attack. In: Zamboni, D., Kr¨ugel, C. (eds.) RAID 2006. LNCS, vol. 4219,
pp. 226–248. Springer, Heidelberg (2006)
14. Bloom, B.: Space/time trade-oﬀs in hash coding with allowable errors. Communi-
cations of the ACM 13(7), 422–426 (1970)
15. Pietraszek, T.: Using Adaptive Alert Classiﬁcation to Reduce False Positives in
Intrusion Detection. In: Jonsson, E., Valdes, A., Almgren, M. (eds.) RAID 2004.
LNCS, vol. 3224, pp. 102–124. Springer, Heidelberg (2004)
16. Bolzoni, D., Crispo, B., Etalle, S.: ATLANTIDES: An Architecture for Alert Ver-
iﬁcation in Network Intrusion Detection Systems. In: LISA 2007: Proc. 21st Large
Installation System Administration Conference, pp. 141–152. USENIX Association
(2007)
17. Meyer, D., Leisch, F., Hornik, K.: The support vector machine under test. Neuro-
computing 55(1-2), 169–186 (2003)
18. R Development Core Team: R: A Language and Environment for Statistical Com-
puting. R Foundation for Statistical Computing, http://www.R-project.org
19. Lee, W.: A data mining framework for constructing features and models for in-
trusion detection systems. PhD thesis, Columbia University, New York, NY, USA
(1999)
20. Lee, W., Fan, W., Miller, M., Stolfo, S., Zadok, E.: Toward cost-sensitive modeling
for intrusion detection and response. Journal of Computer Security 10(1-2), 5–22
(2002)
21. Vapnik, V., Lerner, A.: Pattern recognition using generalized portrait method.
Automation and Remote Control 24 (1963)
20
D. Bolzoni, S. Etalle, and P.H. Hartel
22. Boser, B., Guyon, I., Vapnik, V.: A training algorithm for optimal margin classi-
ﬁers. In: Proc. 5th Annual ACM Workshop on Computational Learning Theory,
pp. 144–152. ACM Press, New York (1992)
23. Cohen, W.: Fast eﬀective rule induction. In: Proc. 12th International Conference
on Machine Learning, pp. 115–123. Morgan Kaufmann, San Francisco (1995)
24. The University of Waikato: Weka 3: Data Mining Software in Java, http://www.
cs.waikato.ac.nz/ml/weka/
25. Howard, J.: An analysis of security incidents on the Internet 1989-1995. PhD thesis,
Carnegie Mellon University, Pittsburgh, PA, USA (1998)
26. Hansman, S., Hunt, R.: A taxonomy of network and computer attacks. Computers
& Security 24(1), 31–43 (2004)
27. Lippmann, R., Cunningham, R., Fried, D., Garﬁnkel, S., Gorton, A., Graf, I.,
Kendall, K., McClung, D., Weber, D., Webster, S., ˜Wyschogrod, D., Zissman, M.:
The 1998 DARPA/AFRL oﬀ-line intrusion detection evaluation. In: RAID 1998:
Proc. 1st International Workshop on the Recent Advances in Intrusion Detection
(1998)
28. Lippmann, R., Haines, J., Fried, D., Korba, J., Das, K.: The 1999 DARPA oﬀ-line
intrusion detection evaluation. Computer Networks: The International Journal of
Computer and Telecommunications Networking 34(4), 579–595 (2000)
29. Snort Team: Snort user manual, http://www.snort.org/docs/snort_htmanuals/
htmanual_2832/node220.html
30. Web Application Security Consortium: Web Security Threat Classiﬁcation,
http://www.webappsec.org/projects/threat/
31. Tenable Network Security: Nessus Vulnerabilty Scanner, http://www.nessus.org/
32. CIRT.net: Nikto web scanner, http://www.cirt.net/nikto2
33. Milw0rm, http://milw0rm.com
34. Bolzoni, D., Zambon, E., Etalle, S., Hartel, P.: POSEIDON: a 2-tier Anomaly-based
Network Intrusion Detection System. In: IWIA 2006: Proc. 4th IEEE International
Workshop on Information Assurance, pp. 144–156. IEEE Computer Society Press,
Los Alamitos (2006)
35. Bolzoni, D., Etalle, S.: Boosting Web Intrusion Detection Systems by Inferring
Positive Signatures. In: Meersman, R., Tari, Z. (eds.) OTM 2008, Part II. LNCS,
vol. 5332, pp. 938–955. Springer, Heidelberg (2008)
36. Cova, M., Balzarotti, D., Felmetsger, V., Vigna, G.: Swaddler: An approach for the
anomaly-based detection of state violations in web applications. In: Kruegel, C.,
Lippmann, R., Clark, A. (eds.) RAID 2007. LNCS, vol. 4637, pp. 63–86. Springer,
Heidelberg (2007)
37. Vigna, G., Robertson, W., Balzarotti, D.: Testing network-based intrusion detec-
tion signatures using mutant exploits. In: CCS 2004: Proc. 11th ACM Conference
on Computer and Communications Security, pp. 21–30. ACM Press, New York
(2004)