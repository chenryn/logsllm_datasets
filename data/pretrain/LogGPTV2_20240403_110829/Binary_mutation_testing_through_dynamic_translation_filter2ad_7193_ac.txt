through a corresponding return code. The remainder outlines
our approach by the example of an instrumentation plug-in
for the COND mutator class for ARM binaries. However, as
it can be easily seen, it can be similarly applied to any of
the proposed ARM mutator classes.
A plug-in is compiled into a shared object that can be
loaded at runtime by adding -mtplug-in my plug-in.so to
the QEMU command line. Listing 3 is an excerpt of the
COND mutator plug-in showing the pre-instruction event
callback. In order to inject a condition code mutation into
the intermediate code the original
translation of the af-
fected instruction address through the disas arm insn()
function is replaced by a slightly different function called
disas arm insn cond(). This function additionally ac-
cepts an argument specifying the condition code to be used
for mutation.
In QEMU ARM translator, conditional execution is sup-
ported by instrumenting the translated instruction with a
preamble code performing the condition test and – if the
condition test fails – a conditional branch to a label inserted
just behind the translated instruction code. In order to gener-
ate the condition test the condition code is extracted from the
four most signiﬁcant bits of the instruction word. In contrast
to that, the COND mutator plug-in uses the condition code
provided through the currently selected mutation table entry
(see line 12 in Listing 3).
Obviously, condition code mutations could be achieved
more easily by patching the four most signiﬁcant bits of the
affected instruction word directly in the emulator’s memory.
However, our approach is more powerful as it is not limited
to mutations relying on patching of instruction words.
E. Efﬁcient Mutation Testing
Since mutant sets can become very large when applying
the full set of available mutators to a complex software we
made several extensions to the QEMU user mode emulator
in order to speed up binary mutation testing. For this, three
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
tb_pre_insn_event(DisasContext *dc,
TranslatedBlock *tb) {
/* Call generation of mutated translation */
disas_arm_insn_cond(dc, tb, mutation->arg[0]);
/* Avoid to call regular disas_arm_insn() */
return SKIP_INSN;
}
void disas_arm_insn_cond(DisasContext *dc,
TranslatedBlock *tb,
void *arg) {
uint_32 insn = ldl_code(dc->pc); /* Get word */
uint_32 cond = (uint_32)arg; /* THE FAULTY CC! */
if(cond==AL) { /* Always execute */
.../* Generate unconditionally executed code */
} else { /* Generate conditional jump to label */
dc->condlabel = gen_new_label();
gen_test_cc(condˆ1, dc->condlabel);
dc->condjump = 1;
.../* Generate conditionally executed code */
if(dc->condjump) /* Generate label */
gen_set_label(dc->condlabel);
}
dc->pc += 4; /* Advance program counter */
}
Listing 3. ARM condition code mutator plug-in.
major improvements were made concerning:
• Reduction of initialization and binary translation efforts
• Reduction of mutant execution and detection efforts
• Utilization of multicore hosts for parallelization
We comprise the golden run and all the subsequent mutant
runs in a single QEMU invocation. By avoiding to restart the
QEMU for each mutant we save the translator’s initialization
phase and avoid redundant code translation. Moreover, by
performing a coverage analysis prior to mutant testing we
reduce the number of runs by skipping mutants that cannot
be killed anyway due to lack of mutation coverage.
For this, several extensions to QEMU user mode emulator
are required in order to extend the lifetime which usually
ends with the program termination. First, we need to make
a backup of the initialized CPU and memory state in order to
reset QEMU efﬁciently. Since the emulator and the binary
under test share a single host process, this just means to
allocate a chunk of memory that is big enough hold a copy of
the initialized memory regions. In order to minimize backup
efforts, we just copy those memory areas that are affected
during a test, i.e., the CPU context and the program’s data
section. After a mutation test the QEMU translation cache
contains mutated code. In order to avoid ﬂushing the cache
after each mutation test a list of affected translated blocks is
maintained for deletion. Finally, we need to prevent QEMU
from termination which is usually done by forwarding of
the ﬁnal exit syscall to the host OS which then kills the
QEMU process. Thus, we trap the exit syscall in order to
perform the reinit. Fig. 4 depicts the extended QEMU user
mode emulator lifetime using efﬁcient reinitialization.
The deﬁnition of strong mutation analysis states that a
mutant is being killed when it is propagated to the design
interfaces, i.e., resulting in a deviation of the mutant’s output
and golden run’s output. Typically, relevant program output
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:48:31 UTC from IEEE Xplore.  Restrictions apply. 
Figure 4. QEMU testing loop extensions.
is written directly or indirectly (i.e., via standard output) to
a dump ﬁle using printf () and f printf () or it is written
to a device ﬁle using f write(). Under P OSIX based OS
like Linux all output related standard library functions end
up with a write() syscall to a device handle. QEMU user
mode emulator, for instance, treats system calls by raising an
exception that lets QEMU return to the main loop after the
execution of the current translated block. In the main loop
the system call is trapped by forwarding it to the host’s OS
system call API.
We adopt
this mechanism in two ways. First, during
the golden run we copy the data of all write() system
calls to an output buffer. This way the buffer is ﬁlled
with reference output data. As the amount of output data
can be really huge and is not known a priori
the size
of the allocated buffer grows dynamically. Second, during
subsequent mutation tests the same mechanism is used to
compare a mutant’s output with the buffered reference data
in an online fashion, i.e., instantly when a write() system
call occurs. In case of the ﬁrst deviated output character
the current mutant is marked as being killed and execution
stops immediately in order to reset QEMU and proceed with
the next mutant. Online mutant detection saves unnecessary
execution overhead. By suppressing the forwarding of the
actual syscall to the OS, we can also save costly context
switching and kernel time. Fig. 5 depicts the mutation testing
loop with online detection mechanism.
mutant itself is considered as being killed.
As mutation testing is inherently parallel our testing
framework supports multicore hosts by means of distributing
the mutants execution on top of a set of worker threads.
In QEMU the translation cache is a global data structure
that is shared among multiple virtual CPUs. Now, since the
translation cache contains mutated code we need to keep sure
that mutants do not get corrupted by executing mutated code
from different mutants. In order to avoid additional thread
synchronization overhead we introduce a private translation
cache for each of the worker threads. For this, we make
use of the f ork() system call in order to create copies of
the original QEMU process which is now referred to as
the master process. On success, the system proceeds the
execution of two identical processes which are both in state
of the master process (except their unique process IDs).
Figure 6. Forked mutation testing.
By forking the master process directly before begin of
the mutant execution loop (see Fig. 6) all data structures
(e.g., CPU state, reference output buffer and the translator
cache) are in a ready-to-use state. This avoids redundant
QEMU initialization and redundant golden run execution.
By repeating the f ork() system call n times we create 2n
worker threads. Now, as processing of mutants has no in-
terdependencies the synchronization overhead is negligible.
The assignment of mutants to worker threads is achieved
by a semaphore initialized to the total number of mutants.
The worker threads update the global
testing report via
shared memory. The master process waits for all the worker
threads to ﬁnish in order to ﬁnalize the global metrics report.
Moreover, the master process acts like a watchdog process
that kills and restarts worker threads being timed out due to
inﬁnite loops.
Figure 5. Mutation testing loop with online detection.
IV. EVALUATION
Besides output deviation a mutation can also lead to
program abortion when the emulator or executed program
enters a critical state, e.g., a segmentation fault or an illegal
instruction. In that case, we also trap exceptions in order to
avoid QEMU abortion and consider the current mutant as
being killed. Under certain circumstances, a mutation may
lead to an inﬁnite loop. Inﬁnite loop detection is hard when
there is no output generated in that loop. In that case, we
can only set a timeout w.r.t. the execution time of the golden
run. If the timeout is exceeded by a user deﬁned factor the
host thread executing the current mutant is killed and the
For the evaluation of our approach we consider the
accuracy of the generated test metrics and the testing per-
formance by investigating two test case generators provided
with an automotive case study. For this, we implemented two
reference tool chains for mutation testing based on native
compilation of instrumented source code and binary patching
for Instruction Set Simulation (ISS).
A. Case Study
Our case study is an embedded software of a fault-tolerant
fuel injection controller which is a part of a car motor man-
agement system. The software is internally composed of two
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:48:31 UTC from IEEE Xplore.  Restrictions apply. 
components: Sensor Correction and Fuel Rate Computation.
The software requires four 16-bit integer sensor signals such
as throttle angle or engine speed. The sensor correction
component is able to compensate one signal fault at a time
by use of approximation functions. Based on the corrected
data the fuel rate computation component computes a 16-bit
integer value for the fuel injection actuator.
The controller was modelled in MATLAB/Simulink. The
software was generated by dSPACE TargetLink production
code generator [10]. The C code consists of 10 functions
with a total complexity of 3397 lines of code (LoC): 2387
LoC for the sensors component and 1010 LoC for fuel rate
component. The target binary was compiled with arm-elf-
gcc version 4.1.1 using −O0 ﬂag (i.e., no code optimiza-
tion). We use our method to assess the conﬁdence of two
test case generators: a generic delta generator and an engine
model. The delta generator is a combinatorial approach that
produces test cases by iterating integer input values with a
pre-deﬁned delta step. The delta can be any integer divisor
of the input signal’s range. Thus, for our four 16-bit input
signals (each having a range from 0..65535) and a delta of
4096 (resulting in 16 steps per signal) the combination leads
to 164 = 65536 different test cases. The engine model test
case generator comes with the case study. Thus, it is more
speciﬁc to the software as it provides a physical model of
the engine. Test cases are generated in a closed-loop with
the feedback of the controller’s output as depicted by Fig. 7.
The engine model test case generator is set up by a virtual
execution time. As the controller software is designed to
run with a 10 ms period 15000 test cases correspond to the
execution of 150s of virtual time. Moreover, certain error
situations are stimulated by injecting sensor faults at pre-
deﬁned points in the simulated virtual time.
Figure 7. Closed-loop testbed for the fault tolerant fuel injection controller
case study.
B. Reference Tool Chains
We compare our QEMU based framework against two
different mutation testing tool chains: a native source code
mutation tool chain based on instrumentation and compila-
tion and a binary tool chain executing patched ARM code on
a conventional ISS. The former tool chain is realized by a sed
based source code instrumentation script. The script wraps
preprocessor macros around C statements. This is done in
order to switch on mutations separately through providing an
according ﬂag to the host compiler. The resulting executable
runs natively on the host just like any other program.
The second tool chain is based on the GDB/ARMulator
ISS that comes as part of GDB debugger provided with
the gcc tool chain for ARM. GDB/ARMulator is a pure
functional (i.e., not cycle accurate) simulator/emulator of
a single ARM CPU running in user mode. In contrast to
QEMU, ARMulator relies on a simple interpreter loop.
Here, binary mutations are directly applied to the ARM
executable prior to its execution (i.e., we did not apply any
modiﬁcations to the GDB/ARMulator). For mutant detection
standard outputs are piped to a dump ﬁle in order to be
compared to a golden run output using the diff command.
C. Metrics Accuracy
In order to assess the test conﬁdence of the different test
sets we consider three different metrics: instruction cover-
age, mutation coverage, and mutant detection (also referred
to as mutant killing rate). Instruction coverage measures
the percentage coverage of target instruction words reached
by the test cases. Thus, it can only be provided by binary
testing. Mutation coverage measures the amount of mutants
that were reached through the control ﬂow of the applied test
cases. Mutant detection measures the percentage of mutants
that were detected (or killed) in terms of propagating a
mutation to the program outputs such as a deviation of the
computed fuel rate. This is commonly referred to as strong
mutation analysis. For accuracy comparison we consider
two typical C mutation operators that were easily applied
to all of the three tool chains: if()→if(true) and
if()→if(false). For comparability of source code and
binary approaches we identiﬁed matching mutations using
the addr2line tool provided with the gcc bintutils.
As the case study source code contains 115 if-statements
this leads to a total number of 230 mutants by applying
two mutators to each. Table VI shows the detailed metrics
generated for selected sets of test cases. For each inves-
tigated function the different metrics are given by absolute
and relative numbers. The metrics computed by the different
approaches are identical. Thus, for the investigated set of
mutators we reach 100% accuracy.
Fig. IV-B compares the metrics the two test case gen-
erators by increasing the number of test cases per mu-
tant. The x-axis denotes the number of applied test cases
per mutant. The y-axis shows the corresponding metric
in percent. It turned out that the signiﬁcant increase of
metrics between test cases #5000 and #10000 for the engine
model corresponds to the stimulation of a special situation
(two signal faults at a time). The engine model performs
slightly better in terms of providing sufﬁcient conﬁdence
metrics with few test cases. With a small step size (e.g.,
2048) the delta generator provides slightly better metrics as
it generates 1048576 different test cases. Table VI shows
that combining both test case generators pushes mutation
coverage to 100% and mutant killing rate reaches 81%.
Examining the residual mutants by hand turned out that
the majority of the undetected mutants can be actually
considered as equivalent mutants as they have no impact
on the considered output.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:48:31 UTC from IEEE Xplore.  Restrictions apply. 
Figure 8. Test generator conﬁdence metrics w.r.t. the number of test cases per mutant.
SensorCorrection
u
d
c
FuelrateComputation
c
e
t
a
r
l
e
u
F
e
t
a
l
u
c
l
a
C
9
6
1
4
T
2
I
7
1
S
D
2
b
a
T
s
e
r
u
x
e
i
g
n
n
n
u
R
s
r
o