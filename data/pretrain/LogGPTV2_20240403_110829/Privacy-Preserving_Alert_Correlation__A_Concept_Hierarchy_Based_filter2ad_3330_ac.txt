and t2 the prepared alert.
Optimistic Approach to Building Attack Scenarios
from Sanitized Alerts. We notice that identifying prepare-
for relations between alerts is essential to building attack
scenarios. However, after alert sanitization, we may not
be certain whether prepare-forrelations are satisﬁed if san-
itized attributes are involved. Without loss of generality,
we assume alert type data is not sanitized. We propose an
optimistic approach to identifying prepare-forrelations be-
tween sanitized alerts. This approach identiﬁes a prepare-
for relation between two alerts t1 and t2 as long as it is
possible that (1) one of the instantiated predicates in t1’s
consequence may imply one of the instantiated predicates
in t2’s prerequisite, and (2) t1 and t2’s timestamps may sat-
isfy t1.EndTime < t2.StartTime. In other words, based on
sanitized attributes, we “guess” what possible original val-
ues are, and if these original values have a chance to satisfy
the implication relationship between instantiated predicates,
and also satisfy the timestamp requirement, we identify a
prepare-forrelation. Example 6 illustrates this idea.
Example 6 To continue Examples 4 and 5, assume DestIP
of alerts t1 and t2 are sanitized based on the concept hier-
archy in Figure 1(a), where DestIP=10.10.1.1 is replaced
with DestIP=10.10.1.0/24. So t1’s consequence becomes
{ExistService(10.10.1.0/24, 21)}, and t2’s prerequisite
is ExistService(10.10.1.0/24, 21) ∧ VulnerableFtpRequest
(10.10.1.0/24). It is possible that the instantiated predicate
ExistService(10.10.1.0/24, 21) in t1’s consequence implies
the instantiated predicate ExistService(10.10.1.0/24, 21)
in t2’s prerequisite if both sanitized DestIP attributes have
the same original IP address in network 10.10.1.0/24.
Further due to t1.EndTime < t2.StartTime, we identify a
prepare-forrelation between t1 and t2.
Attack Scenario Reﬁnement Based on Probabilities of
Prepare-for Relations. Our optimistic approach certainly
may introduce false prepare-for relations between alerts.
Without knowledge of original values, we cannot guaran-
tee that one instantiated predicate implies another if sani-
tized attributes are involved. To improve this approach, it
is desirable to estimate how possible each pair of sanitized
alerts has a prepare-forrelation. To do so, we can ﬁrst com-
pute the probability that one instantiated predicate implies
another, and then consider timestamp requirement.
Example 7 To continue Example 6, consider ExistSer-
vice(DestIP,DestPort) in T1’s consequence and T2’s prereq-
uisite. After predicate instantiation using sanitized alerts,
we compute probabilities P (t1.DestIP=t2.DestIP)= 1
256 ,
and P (t1.DestPort=t2.DestPort) =1. Hence the probability
that the instantiated predicate ExistService(10.10.1.0/24,
21) in t1’s consequence implies the instantiated predicate
1
ExistService(10.10.1.0/24, 21) in t2’s prerequisite is
256 .
Further note P (t1.EndTime< t2.StartTime)=1. Then we
know the probability of this prepare-for relation to be true
is 1
256 .
Notice that between two alerts, sometimes there may ex-
ist several pairs of instantiated predicates such that in each
pair, one instantiated predicate may imply the other. It is
difﬁcult to estimate the probability that at least one impli-
cation relationship is true because we do not know the de-
pendency among them. To simplify the probability estima-
tion, we assume n pairs of instantiated predicates that may
have implication relationships are independent with prob-
abilities p1, p2, ··· , pn, respectively. Then the probabil-
ity that at least one implication relationship is satisﬁed is
1 − (1 − p1)(1 − p2)··· (1 − pn). Next we consider times-
tamp requirement to further compute the probability for the
prepare-forrelation.
After the probabilities of prepare-for relations are com-
puted, it is desirable to use these probability values to prune
false prepare-for relations in an alert correlation graph
(e.g., remove prepare-for relations with lower probabili-
ties). However, we observe that this ideal case may not
help much. As shown in Example 7, after sanitizing IP ad-
dresses to /24 network addresses, the probability that two
alerts have a prepare-for relation is only 1
256 , which may
imply that this prepare-forrelation is false. However, con-
sidering that when the IP addresses in a /24 network are
sanitized, the probabilities of all prepare-for relations in-
volving these IP addresses are small. If we remove all the
low-probability prepare-for relations, it is very likely that
some true prepare-forrelations are pruned.
We further observe that if we calculate the probability
for a set of prepare-for relations instead of only one, we
can gain more interesting hints. Assume n pairs of prepare-
forrelations have probabilities p1, p2, ··· , pn, respectively.
Further suppose they are independent. Thus the probability
that at least one prepare-forrelation is true is 1−(1−p1)(1−
p2)··· (1 − pn). This result may help us reﬁne an alert
correlation graph.
To further reﬁne an alert correlation graph constructed
from the optimistic approach, we propose to aggregate alert
correlation graphs. This is performed according to tem-
poral constraints and probability thresholds. Consider a
set S of alerts and a time interval with length δ (e.g., 6
seconds), where alerts in S are sorted in increasing order
Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005) 
1063-9527/05 $20.00 © 2005 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:08:53 UTC from IEEE Xplore.  Restrictions apply. 
Algorithm 1. Aggregation to an alert correlation graph.
Input: An alert correlation graph CG = (N, E), a temporal
constraint δ, and a probability threshold θ.
Output: An aggregated correlation graph ACG.
Method:
1. Partition edge set E into subsets E1,E2, ··· , El such
that in any Ei (1 ≤ i ≤ l), all edges have the same preparing
alert type, and the same prepared alert type.
2. For each subset Ei in E
3.
Further partition Ei into groups Ei1, Ei2, ··· , Eij such
that the preparing alerts and prepared alerts in Eik
(1 ≤ k ≤ j) satisfy temporal constraint δ, respectively.
For each group Eik in subset Ei
Compute the probability P that at least one
prepare-for relation in Eik is true.
If P ≥ θ Then
Aggregate edges in Eik into one; merge preparing
and prepared alerts, respectively.
Else Remove all edges in Eik.
Remove preparing and prepared alerts in Eik if
they are not linked by other edges.
4.
5.
6.
7.
8.
9. Let CG after the above operations be ACG. Output ACG.
Figure 2. Aggregating alert correlation graphs
based on StartTime. We call two alerts consecutive alerts if
their StartTime timestamps are neighboring to each other in
S. S satisﬁes temporal constraint δ if and only if for any
two consecutive alerts ti and tj in S where ti.StartTime ≤
tj.StartTime, tj.StartTime −ti.EndTime ≤ δ. Intuitively,
this means the time intervals (in the form of [StartTime,
EndTime]) of any two consecutive alerts overlap, or the
“gap” between them is within δ.
Given an alert correlation graph CG = (N, E) con-
structed from the optimistic approach, a temporal constraint
δ, and a probability threshold θ, we perform aggregation to
CG through the algorithm shown in Figure 2. The basic
idea is that we aggregate the edges with the same prepar-
ing and the same prepared alert types into one such that the
probability that at least one prepare-forrelation (represented
by these edges) is true is greater than or equal to threshold
θ. (The related nodes are merged accordingly.)
As we stated earlier, the alert correlation graphs con-
structed from our optimistic approach may include both
false and true prepare-for relations. They may also have
large numbers of nodes and edges such that understanding
these scenarios can be time-consuming. Algorithm 1 helps
us improve the quality of alert correlation graphs in that it
reduces the numbers of nodes and edges, and may improve
the certainty about prepare-forrelations (in the aggregated
sense). Note that after aggregation, a node in the aggregated
correlation graph is actually a place holder which may rep-
resents multiple alerts. Our aggregation also has some lim-
itations because we may remove some true prepare-forre-
lations from alert correlation graphs when the probability
for them is less than the threshold. In our future work, we
will investigate additional techniques to reﬁne alert correla-
tion graphs to reduce both false alerts and false prepare-for
Table 1. Evaluating similarity functions
Continuous
Categorical
Rcc for “similar” pairs
Rmc for “similar” pairs
Rcc for “distinct” pairs
Rmc for “distinct” pairs
100%
5.88%
94.12%
0%
100%
9.95%
90.05%
0%
relations in the graphs.
4 Experimental Results
4.1 Evaluating Similarity Functions
We ﬁrst evaluate the revised similarity functions (Equa-
tions 3 and 5). We are interested in how possible sanitized
datasets can provide similarity classiﬁcation as that from
original datasets.
In our experiments, we randomly gen-
erated a set So of alerts with only one categorical (or
continuous) attribute, and then sanitized it to get a new set
Ss. For each pair of alerts in So, we used Equation 2 (or
Equation 4, resp.) to calculate attribute similarity. While for
each pair of alerts in Ss, we used Equation 3 (or Equation 5,
resp.) to compute their similarity. Then we applied an opti-
mistic classiﬁcation. If the similarity value is greater than
0, we classify this pair of alerts as “similar” pair; otherwise
we classify them as “distinct” pair. We compared the results
from Ss with those from So. We used two quantitative
measures: correct classiﬁcation rate Rcc for Ss based on
So and misclassiﬁcation rate Rmc for Ss based on So. We
deﬁne Rcc and Rmc for “similar” pairs as follows. Rcc =
#common “similar” pairs in both So and Ss
and Rmc =
#“similar” pairs in Ss−#common “similar” pairs in So and Ss
#“similar” pairs in So
#total alert pairs−#“similar” pairs in So
,
.
Note that Rcc and Rmc are only for sanitized datasets, and
both measures can be computed for “similar” or “distinct”
pairs. Likewise, we deﬁne correct classiﬁcation rate and
misclassiﬁcation rate for “distinct” pairs by replacing
“similar” with “distinct” in the above equations.
Our ﬁrst experiment is for categorical attributes. We
generated a set So of 2, 560 alerts with DestIP attributes
uniformly distributed over 256 IP addresses in network
10.60.1.0/24 (from 10.60.1.0 to 10.60.1.255). Next we
partitioned this network into 16 subnets. Each subnet (/28
subnet) has 16 addresses. We sanitized So to Ss such that
DestIP of each alert is generalized to the corresponding /28
subnet ID. We applied Equation 2 to So and Equation 3 to
Ss. The results are shown in the left part of Table 1.
Our second experiment is for continuous attributes. We
generated a set So of 1, 000 alerts with CPUProcessingTime
attributes uniformly distributed over interval [0, 100]. Then
we divided [0, 100] into 20 small equal-length intervals (the
length of each small interval is 5). Next we sanitized So
to Ss by replacing original values with the corresponding
small intervals (a boundary value between two adjacent in-
tervals is put into the lower interval). Let λ = 2.5. We
Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005) 
1063-9527/05 $20.00 © 2005 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:08:53 UTC from IEEE Xplore.  Restrictions apply. 
applied Equation 4 to So and Equation 5 to Ss. The results
are shown in the right part of Table 1.
In these two experiments, the entropy and differential
entropy for attributes DestIP and CPUProcessingTime are
log216 = 4 and log25 = 2.3219, respectively. Our correct
classiﬁcation rates for both “similar” and “distinct” pairs are
high (greater than 90%), while the misclassiﬁcation rates
for both pairs are low (less than 10%). This demonstrates
that the privacy of alert attributes can be protected with
sacriﬁcing the data functionality (similarity classiﬁcation)
slightly.
4.2 Building Attack Scenarios
To evaluate the techniques on building attack scenarios,
we performed experiments on 2000 DARPA intrusion de-
tection scenario speciﬁc data sets [8]. The datasets include
two scenarios: LLDOS 1.0 and LLDOS 2.0.2, where each
scenario includes two parts (inside and DMZ).
In the ﬁrst set of experiments, our goal is to evaluate the
effectiveness of our optimistic approach to building attack
scenarios. We ﬁrst used RealSecure network sensor 6.0
to generate alerts from four datasets: LLDOS 1.0 inside,
LLDOS 1.0 DMZ, LLDOS 2.0.2 inside, and LLDOS 2.0.2
DMZ. The prerequisites and consequences for all alert types
can be found in [12] (Tables III and IV). Due to space con-
straint, we do not list them here. We ﬁrst constructed alert
correlation graphs for the original alert datasets using the
previous method [11]. Then we sanitized the destination IP
address of each alert (a sanitization policy used by DShield)
by replacing it with its corresponding /24 network ID. We
applied our optimistic approach to building alert correlation
graphs for the four datasets. To save space, here we only list
one alert correlation graph in Figure 3.
In Figure 3, the string inside each node is an alert type
followed by an alert ID. Notice that to show the differ-
ence between the alert correlation graphs created from the
original dataset and the sanitized one, we marked the ad-
ditional nodes obtained only from the sanitized dataset in
gray. From Figure 3, it is clear that the alert correlation
graph from the sanitized dataset is a supergraph of the one
from the original dataset. This is because our optimistic
approach identiﬁes prepare-forrelations even if the related
probabilities are low. Figure 3 represents a multi-stage at-
tack scenario, which is consistent with the major steps ad-
versaries performed.
We notice that false alerts may be involved in an alert
correlation graph (e.g., alert Email Debug67705 in Fig-
ure 3). To further evaluate the effectiveness of our ap-
proach, similar to [11], we used two quantitative mea-
sures: soundness Ms and completeness Mc, where Ms =
#correctly correlated alerts
. We
computed both measures for the correlation approaches
based on original datasets and the sanitized ones. The re-
sults are in Table 2. Table 2 shows the correlation ap-
, and Mc = #correctly correlated alerts
#correlated alerts
#related alerts
proach based on original datasets is slightly better than our
optimistic approach, which is reasonable because original
datasets are more precise than sanitized datasets. Neverthe-
less, our optimistic approach is relatively good: the majority
of soundness measures are greater than 70%, and all com-
pleteness measures are greater than 60%.
Table 2. Soundness and completeness
LLDOS 1.0