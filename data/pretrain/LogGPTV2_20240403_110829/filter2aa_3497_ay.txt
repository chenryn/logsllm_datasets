     {
➌     password = hash_password(password);
     }
➍   return check_user_password(username, password);
   }
Listing 9-12: Checking a vulnerable authentication
||||||||||||||||||||
||||||||||||||||||||
First, the username and password are read from the network ➊. Next, the hashing
algorithm’s number of iterations is read ➋, and the hashing process is applied that number
of times ➌. Finally, the hashed password is checked against one stored by the application
➍. Clearly, an attacker could supply a very large value for the iteration count that would
likely consume a significant amount of CPU resources for an extended period of time,
especially if the hashing algorithm is computationally complex.
A good example of a cryptographic algorithm that a client can configure is the handling
of public/private keys. Algorithms such as RSA rely on the computational cost of factoring
a large public key value. The larger the key value, the more time it takes to perform
encryption/decryption and the longer it takes to generate a new key pair.
Format String Vulnerabilities
Most programming languages have a mechanism to convert arbitrary data into a string,
and it’s common to define some formatting mechanism to specify how the developer wants
the output. Some of these mechanisms are quite powerful and privileged, especially in
memory-unsafe languages.
A format string vulnerability occurs when the attacker can supply a string value to an
application that is then used directly as the format string. The best-known, and probably
the most dangerous, formatter is used by the C language’s printf and its variants, such as
sprintf, which print to a string. The printf function takes a format string as its first
argument and then a list of the values to format. Listing 9-13 shows such a vulnerable
application.
def process_authentication()
{
      string username = read_string();
      string password = read_string();
      // Print username and password to terminal
      printf(username);
      printf(password);
      return check_user_password(username, password))
}
Listing 9-13: The printf format string vulnerability
The format string for printf specifies the position and type of data using a %? syntax
where the question mark is replaced by an alphanumeric character. The format specifier
can also include formatting information, such as the number of decimal places in a
number. An attacker who can directly control the format string could corrupt memory or
disclose information about the current stack that might prove useful for further attacks.
Table 9-2 shows a list of common printf format specifiers that an attacker could abuse.
Table 9-2: List of Commonly Exploitable printf Format Specifiers
Technet24
||||||||||||||||||||
||||||||||||||||||||
Format
specifier
Description
Potential vulnerabilities
%d, %p, %u,
%x
Prints integers
Can be used to disclose information from the
stack if returned to an attacker
%s
Prints a zero terminated
string
Can be used to disclose information from the
stack if returned to an attacker or cause invalid
memory accesses to occur, leading to denial-of-
service
%n
Writes the current number
of printed characters to a
pointer specified in the
arguments
Can be used to cause selective memory
corruption or application crashes
Command Injection
Most OSes, especially Unix-based OSes, include a rich set of utilities designed for various
tasks. Sometimes developers decide that the easiest way to execute a particular task, say
password updating, is to execute an external application or operating system utility.
Although this might not be a problem if the command line executed is entirely specified by
the developer, often some data from the network client is inserted into the command line
to perform the desired operation. Listing 9-14 shows such a vulnerable application.
 def update_password(string username)
 {
➊ string oldpassword = read_string();
   string newpassword = read_string();
   if(check_user_password(username, oldpassword))
   {
     // Invoke update_password command
  ➋ system("/sbin/update_password -u " + username + " -p " + newpassword);
   }
 }
Listing 9-14: A password update vulnerable to command injection
The listing updates the current user’s password as long as the original password is
known ➊. It then builds a command line and invokes the Unix-style system function ➋.
Although we don’t control the username or oldpassword parameters (they must be correct for
the system call to be made), we do have complete control over newpassword. Because no
sanitization is done, the code in the listing is vulnerable to command injection because the
system function uses the current Unix shell to execute the command line. For example, we
could specify a value for newpassword such as password; xcalc, which would first execute the
password update command. Then the shell could execute xcalc as it treats the semicolon as
||||||||||||||||||||
||||||||||||||||||||
a separator in a list of commands to execute.
SQL Injection
Even the simplest application might need to persistently store and retrieve data.
Applications can do this in a number of ways, but one of the most common is to use a
relational database. Databases offer many advantages, not least of which is the ability to
issue queries against the data to perform complex grouping and analysis.
The de facto standard for defining queries to relational databases is the Structured Query
Language (SQL). This text-based language defines what data tables to read and how to
filter that data to get the results the application wants. When using a text-based language
there is a temptation is to build queries using string operations. However, this can easily
result in a vulnerability like command injection: instead of inserting untrusted data into a
command line without appropriately escaping, the attacker inserts data into a SQL query,
which is executed on the database. This technique can modify the operation of the query
to return known results. For example, what if the query extracted the current password for
the authenticating user, as shown in Listing 9-15?
   def process_authentication()
   {
➊   string username = read_string();
     string password = read_string();
➋   string sql = "SELECT password FROM user_table WHERE user = '" + username "'";
➌   return run_query(sql) == password;
   }
Listing 9-15: An example of authentication vulnerable to SQL injection
This listing reads the username and password from the network ➊. Then it builds a new
SQL query as a string, using a SELECT statement to extract the password associated with the
user from the user table ➋. Finally, it executes that query on the database and checks that
the password read from the network matches the one in the database ➌.
The vulnerability in this listing is easy to exploit. In SQL, the strings need to be
enclosed in single quotes to prevent them from being interpreted as commands in the SQL
statement. If a username is sent in the protocol with an embedded single quote, an attacker
could terminate the quoted string early. This would lead to an injection of new commands
into the SQL query. For example, a UNION SELECT statement would allow the query to return
an arbitrary password value. An attacker could use the SQL injection to bypass the
authentication of an application.
SQL injection attacks can even result in remote code execution. For example, although
disabled by default, Microsoft’s SQL Server’s database function xp_cmdshell allows you to
execute OS commands. Oracle’s database even allows uploading arbitrary Java code. And
Technet24
||||||||||||||||||||
||||||||||||||||||||
of course, it’s also possible to find applications that pass raw SQL queries over the
network. Even if a protocol is not intended for controlling the database, there’s still a good
chance that it can be exploited to access the underlying database engine.
Text-Encoding Character Replacement
In an ideal world, everyone would be able to use one type of text encoding for all different
languages. But we don’t live in an ideal world, and we use multiple text encodings as
discussed in Chapter 3, such as ASCII and variants of Unicode.
Some conversions between text encodings cannot be round-tripped: converting from
one encoding to another loses important information such that if the reverse process is
applied, the original text can’t be restored. This is especially problematic when converting
from a wide character set such as Unicode to a narrow one such as ASCII. It’s simply
impossible to encode the entire Unicode character set in 7 bits.
Text-encoding conversions manage this problem in one of two ways. The simplest
approach replaces the character that cannot be represented with a placeholder, such as the
question mark (?) character. This might be a problem if the data value refers to something
where the question mark is used as a delimiter or as a special character, for example, as in
URL parsing where it represents the beginning of a query string.
The other approach is to apply a best-fit mapping. This is used for characters for which
there is a similar character in the new encoding. For example, the quotation mark
characters in Unicode have left-facing and right-facing forms that are mapped to specific
code points, such as U+201C and U+201D for left and right double quotation marks.
These are outside the ASCII range, but in a conversion to ASCII, they’re commonly
replaced with the equivalent character, such as U+0022 or the quotation mark. Best-fit
mapping can become a problem when the converted text is processed by the application.
Although slightly corrupted text won’t usually cause much of a problem for a user, the
automatic conversion process could cause the application to mishandle the data.
The important implementation issue is that the application first verifies the security
condition using one encoded form of a string. Then it uses the other encoded form of a
string for a specific action, such as reading a resource or executing a command, as shown in
Listing 9-16.
 def add_user()
 {
➊ string username = read_unicode_string();
   // Ensure username doesn't contain any single quotes
➋ if(username.contains("'") == false)
   {
     // Add user, need to convert to ASCII for the shell
  ➌ system("/sbin/add_user '" + username.toascii() + "'");
   }
 }
||||||||||||||||||||
||||||||||||||||||||
Listing 9-16: A text conversion vulnerability
In this listing, the application reads in a Unicode string representing a user to add to
the system ➊. It will pass the value to the add_user command, but it wants to avoid a
command injection vulnerability; therefore, it first ensures that the username doesn’t
contain any single quote characters that could be misinterpreted ➋. Once satisfied that the
string is okay, it converts it to ASCII (Unix systems typically work on a narrow character
set, although many support UTF-8) and ensures that the value is enclosed with single
quotes to prevent spaces from being misinterpreted ➌.
Of course, if the best-fit mapping rules convert other characters back to a single quote,
it would be possible to prematurely terminate the quoted string and return to the same
sort of command injection vulnerabilities discussed earlier.
Final Words
This chapter showed you that many possible root causes exist for vulnerabilities, with a
seemingly limitless number of variants in the wild. Even if something doesn’t immediately
look vulnerable, persist. Vulnerabilities can appear in the most surprising places.
I’ve covered vulnerabilities ranging from memory corruptions, causing an application to
behave in a different manner than it was originally designed, to preventing legitimate users
from accessing the services provided. It can be a complex process to identify all these
different issues.
As a protocol analyzer, you have a number of possible angles. It is also vital that you
change your strategy when looking for implementation vulnerabilities. Take into account
whether the application is written in memory-safe or unsafe languages, keeping in mind
that you are less likely to find memory corruption in, for example, a Java application.
Technet24
||||||||||||||||||||
||||||||||||||||||||
10
FINDING AND EXPLOITING SECURITY VULNERABILITIES
Parsing the structure of a complex network protocol can be tricky, especially if the
protocol parser is written in a memory-unsafe programming language, such as C/C++. Any
mistake could lead to a serious vulnerability, and the complexity of the protocol makes it
difficult to analyze for such vulnerabilities. Capturing all the possible interactions between
the incoming protocol data and the application code that processes it can be an impossible
task.
This chapter explores some of the ways you can identify security vulnerabilities in a
protocol by manipulating the network traffic going to and from an application. I’ll cover
techniques such as fuzz testing and debugging that allow you to automate the process of
discovering security issues. I’ll also put together a quick-start guide on triaging crashes to
determine their root cause and their exploitability. Finally, I’ll discuss the exploitation of
common security vulnerabilities, what modern platforms do to mitigate exploitation, and
ways you can bypass these exploit mitigations.
Fuzz Testing
Any software developer knows that testing the code is essential to ensure that the software
behaves correctly. Testing is especially important when it comes to security.
Vulnerabilities exist where a software application’s behavior differs from its original intent.
In theory, a good set of tests ensures that this doesn’t happen. However, when working
with network protocols, it’s likely you won’t have access to any of the application’s tests,
especially in proprietary applications. Fortunately, you can create your own tests.
Fuzz testing, commonly referred to as fuzzing, is a technique that feeds random, and
sometimes not-so-random, data into a network protocol to force the processing
application to crash in order to identify vulnerabilities. This technique tends to yield
results no matter the complexity of the network. Fuzz testing involves producing multiple
test cases, essentially modified network protocol structures, which are then sent to an
application for processing. These test cases can be generated automatically using random
modifications or under direction from the analyst.
The Simplest Fuzz Test
Developing a set of fuzz tests for a particular protocol is not necessarily a complex task. At
its simplest, a fuzz test can just send random garbage to the network endpoint and see what
happens.
||||||||||||||||||||
||||||||||||||||||||
For this example, we’ll use a Unix-style system and the Netcat tool. Execute the
following on a shell to yield a simple fuzzer:
$ cat /dev/urandom | nc hostname port
This one-line shell command reads data from the system’s random number generator
device using the cat command. The resulting random data is piped into netcat, which opens
a connection to a specified endpoint as instructed.
This simple fuzzer will likely only yield a crash on simple protocols with few
requirements. It’s unlikely that simple random generation would create data that meets the
requirements of a more complex protocol, such as valid checksums or magic values. That
said, you’d be surprised how often a simple fuzz test can give you valuable results; because
it’s so quick to do, you might as well try it. Just don’t use this fuzzer on a live industrial
control system managing a nuclear reactor!
Mutation Fuzzer
Often, you’ll need to be more selective about what data you send to a network connection
to get the most useful information. The simplest technique in this case is to use existing
protocol data, mutate it in some way, and then send it to the receiving application. This
mutation fuzzer can work surprisingly well.
Let’s start with the simplest possible mutation fuzzer: a random bit flipper. Listing 10-1
shows a basic implementation of this type of fuzzer.
void SimpleFuzzer(const char* data, size_t length) {
   size_t position = RandomInt(length);
   size_t bit = RandomInt(8);
   char* copy = CopyData(data, length);
   copy[position] ^= (1 << bit);
   SendData(copy, length);
}
Listing 10-1: A simple random bit flipper mutation fuzzer
The SimpleFuzzer() function takes in the data to fuzz and the length of the data, and then
generates a random number between 0 and the length of the data as the byte of the data to
modify. Next, it decides which bit in that byte to change by generating a number between
0 and 7. Then it toggles the bit using the XOR operation and sends the mutated data to its
network destination.
This function works when, by random chance, the fuzzer modifies a field in the
protocol that is then used incorrectly by the application. For example, your fuzzer might
modify a length field set to 0x40 by converting it to a length field of 0x80000040. This
modification might result in an integer overflow if the application multiplies it by 4 (for an
array of 32-bit values, for example). This modification could also cause the data to be
malformed, which would confuse the parsing code and introduce other types of
Technet24
||||||||||||||||||||
||||||||||||||||||||
vulnerabilities, such as an invalid command identifier that results in the parser accessing an
incorrect location in memory.
You could mutate more than a single bit in the data at a time. However, by mutating
single bits, you’re more likely to localize the effect of the mutation to a similar area of the
application’s code. Changing an entire byte could result in many different effects,
especially if the value is used for a set of flags.
You’ll also need to recalculate any checksums or critical fields, such as total length
values after the data has been fuzzed. Otherwise, the resulting parsing of the data might
fail inside a verification step before it ever gets to the area of the application code that
processes the mutated value.
Generating Test Cases
When performing more complex fuzzing, you’ll need to be smarter with your
modifications and understand the protocol to target specific data types. The more data that
passes into an application for parsing, the more complex the application will be. In many
cases, inadequate checks are made at edge cases of protocol values, such as length values;
then, if we already know how the protocol is structured, we can generate our own test
cases from scratch.
Generating our own test cases gives us precise control over the protocol fields used and
their sizes. However, test cases are more complex to develop, and careful thought must be
given to the kinds you want to generate. Generating test cases allows you to test for types
of protocol values that might never be used when you capture traffic to mutate. But the
advantage is that you’ll exercise more of the application’s code and access areas of code
that are likely to be less well tested.
Vulnerability Triaging
After you’ve run a fuzzer against a network protocol and the processing application has
crashed, you’ve almost certainly found a bug. The next step is to find out whether that bug
is a vulnerability and what type of vulnerability it might be, which depends on how and
why the application crashed. To do this analysis, we use vulnerability triaging: taking a
series of steps to search for the root cause of a crash. Sometimes the cause of the bug is
clear and easy to track down. Sometimes a vulnerability causes corruption of an application
seconds, if not hours, after the corruption occurs. This section describes ways to triage
vulnerabilities and increase your chances of finding the root cause of a particular crash.
Debugging Applications
Different platforms allow different levels of control over your triaging. For an application
running on Windows, macOS, or Linux, you can attach a debugger to the process. But on
||||||||||||||||||||
||||||||||||||||||||
an embedded system, you might only have crash reports in the system log to go on. For
debugging, I use CDB on Windows, GDB on Linux, and LLDB on macOS. All these
debuggers are used from the command line, and I’ll provide some of the most useful
commands for debugging your processes.
Starting Debugging
To start debugging, you’ll first need to attach the debugger to the application you want to