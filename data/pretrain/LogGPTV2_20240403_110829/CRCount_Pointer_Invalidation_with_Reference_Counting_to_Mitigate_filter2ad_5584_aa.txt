title:CRCount: Pointer Invalidation with Reference Counting to Mitigate
Use-after-free in Legacy C/C++
author:Jangseop Shin and
Donghyun Kwon and
Jiwon Seo and
Yeongpil Cho and
Yunheung Paek
CRCount: Pointer Invalidation with Reference
Counting to Mitigate Use-after-free in Legacy C/C++
Jangseop Shin∗, Donghyun Kwon∗, Jiwon Seo∗, Yeongpil Cho†‡ and Yunheung Paek∗
{jsshin, dhkwon, jwseo}@sor.snu.ac.kr, PI:EMAIL
∗ECE and ISRC, Seoul National University
†School of Software, Soongsil University
PI:EMAIL
Abstract—Pointer invalidation has been a popular approach
adopted in many recent studies to mitigate use-after-free errors.
The approach can be divided largely into two different schemes:
explicit invalidation and implicit invalidation. The former aims
to eradicate the root cause of use-after-free errors by explicitly
invalidating every dangling pointer. In contrast, the latter aims
to prevent dangling pointers by freeing an object only if there is
no pointer referring to it. A downside of the explicit scheme is
that it is expensive, as it demands high-cost algorithms or a large
amount of space to maintain up-to-date lists of pointer locations
linking to each object. Implicit invalidation is more efﬁcient in
that even without any explicit effort, it can eliminate dangling
pointers by leaving objects undeleted until all the links between
the objects and their referring pointers vanish by themselves
during program execution. However, such an argument only
holds if the scheme knows exactly when each link is created and
deleted. Reference counting is a traditional method to determine
the existence of reference links between objects and pointers.
Unfortunately, impeccable reference counting for legacy C/C++
code is very difﬁcult and expensive to achieve in practice, mainly
because of the type unsafe operations in the code. In this paper, we
present a solution, called CRCount, to the use-after-free problem
in legacy C/C++. For effective and efﬁcient problem solving,
CRCount is armed with the pointer footprinting technique that
enables us to compute, with high accuracy, the reference count
of every object referred to by the pointers in the legacy code.
Our experiments demonstrate that CRCount mitigates the use-
after-free errors with a lower performance-wise and space-wise
overhead than the existing pointer invalidation solutions.
I.
INTRODUCTION
Use-after-free (UAF) errors refer to unlawful dereferences
of dangling pointers, which are the pointers that still point
to a freed and thus stale object. UAF errors constitute a
serious threat to software security because they are considered
signiﬁcantly difﬁcult to identify by compilers and manual anal-
yses. This difﬁculty is attributed to the fact that the temporal
distances between arbitrary pointer operations, such as setting
a pointer to the address of the object, freeing the object, and
dereferencing the pointer, can be very long and hence very
difﬁcult to analyze accurately in reality. This difﬁculty has
‡Corresponding author.
Network and Distributed Systems Security (NDSS) Symposium 2019
24-27 February 2019, San Diego, CA, USA
ISBN 1-891562-55-X
https://dx.doi.org/10.14722/ndss.2019.23541
www.ndss-symposium.org
led attackers to leverage UAF errors as a primary source for
exploitation in their attempts [40], [20], [38] to access or
corrupt arbitrary memory locations in a victim process.
In the past decade, mitigation against UAF errors has been
approached by many researchers from various directions. In
one group of studies [33], [24], [21], [22], [31], researchers
attempted to detect the UAF error when a pointer is derefer-
enced to access its referred object (or referent). Their goal is
to validate the access to the object by carrying out a sequence
of operations to check whether the referent is stale. To support
this access validation mechanism, each time an object
is
allocated, they label the object with a unique attribute that
identiﬁes the allocation. Later, when a pointer is dereferenced,
they examine the attribute of its referent to check whether or
not the access is made by a dangling pointer whose referent
no longer holds the original valid allocation in memory.
Although mitigation techniques based on access validation
are claimed to be extensive and complete, they tend to incur an
excessively high performance overhead. This high overhead is
attributed to the fact that the attribute checks must be executed
exhaustively for every memory access, thereby considerably
increasing the total execution time. More recently in a different
group of studies, as a new direction of UAF defense research
to reduce this performance overhead, some researchers have
proposed an approach based on pointer invalidation [17], [40],
[36]. Their mitigation approach against UAF errors is to deter
the violations preemptively by getting rid of the dangling
pointers at the outset. As a pointer becomes dangling when
its referents get freed, this approach in principle can succeed
by invalidating all the related pointers when an object is freed
such that an exception is triggered when one of the invalidated
pointers is dereferenced afterwards. However in practice, for
this approach to be successful, we need to address the problem
of accurately tracking down every change, such as the creation,
copy, or destruction of pointers, and hence, of identifying
pointers and their referents located anywhere on the execution
path. Unfortunately, this pointer tracking problem in general
is prohibitively difﬁcult and expensive to solve with high
accuracy because the pointers may be copied into a number of
different data structures during program execution.
For precise pointer tracking, DANGNULL [17] uses dy-
namic range analysis to monitor the pointer arithmetic opera-
tions that alter the reference relationships between the pointers
and the memory objects. Unfortunately, DANGNULL suffers
from a high performance overhead. A majority of this overhead
is attributed to the design element that requires the system
to immediately update the metadata for the objects when
there is a change in the reference relationships. To alleviate
this performance overhead, DangSan [36] takes a different
approach wherein the total cost for updating the reference
relationships is reduced by discarding the transitional changes
intermittently produced in a sequence of pointer arithmetic
operations. More speciﬁcally,
in this approach, when any
of the existing reference relationships is changed by pointer
arithmetic, this change is not reﬂected immediately in the
relationships (thus saving CPU cycles); instead, the change is
merely stored in a history table as a record for future reference.
The actual reference relationships are checked later when the
object is freed. Experiments on DangSan have proven the
effectiveness of this approach by showing that it achieved a
considerably lower performance overhead than DANGNULL.
However, the experiments also show that the history table
can become unbearably large when benchmark programs use
pointers intensively. For example, the memory overhead of
omnetpp benchmark was more than a hundred times the
original memory consumption. As UAF errors are more likely
to be prevalent in programs with a heavy use of pointers, such
an immense memory overhead might be a signiﬁcant obstacle
for a broad application of this approach.
From the observations on previous work, we found that
such a high overhead, either performance-wise or space-wise,
of the existing pointer invalidation techniques is basically
caused by the approach that when an object is freed, these
techniques promptly locate and explicitly invalidate all the
pointers referring to the object. This explicit pointer inval-
idation approach seems to be intuitive as it mitigates UAF
errors by eradicating the root cause (i.e. dangling pointers),
but it is usually very costly as it demands expensive algorithms
or a large amount of space to maintain the up-to-date list of
pointer locations linking to each object at all times during
program execution. DANGNULL spends many CPU cycles
to manage binary trees as the data structures to store pointer
locations. Every time there is a change in one of the locations,
the trees are traversed and modiﬁed accordingly, consuming
a considerable amount of the execution time. Even worse,
the total performance overhead increases in proportion to
the numbers of pointers and referents, which can increase
considerably for programs, such as omnetpp, that perform
frequent arithmetic operations on a myriad of pointers.
Our ﬁndings motivated us to take an alternative approach,
which we have named implicit pointer invalidation to contrast
with the existing explicit approach. The goal of our approach
is to prevent dangling pointers by enforcing a basic principle
that permits an object to be freed only if there is no pointer
currently referring to it. Of course in C/C++, users may
deallocate an object at their disposal by invoking the free
(or delete) function irrespective of the existence of pointers
linking with the object. Therefore, to enforce the principle
in the legacy C/C++ code, we augment each memory object
with a single integer, known as the reference counter, that
records the number of pointers referring to the designated
object. When the user intends to free an object in the original
code, we ignore the function by doing nothing explicit if the
corresponding reference counter has a non-zero value. The
object is disposed of without explicit effort for invalidation
once the counter comes to zero. Indeed, in most real code,
reference counters eventually decrease to zero in a sequence of
repeated pointer operations, such as assignment, nulliﬁcation,
and deallocation of pointer variables. This implies that even
without explicit
the proposed
scheme can prevent dangling pointers by holding an object
remain undeleted until all the links between the object and its
referring pointers vanish by themselves, which is tantamount
to the implicit invalidation of the referring pointers.
invalidation time and effort,
This implicit invalidation scheme sounds plain and naive
at the ﬁrst glance, but its practical application to the existing
C/C++ code is very challenging from several aspects. The ﬁrst
aspect of concern is the increase in the memory overhead. In
C/C++, free/delete is purposed to instantly release the
memory space occupied by objects and reclaim the space
for reuse. However, such reclamation of memory will be
hindered by our implicit scheme that delays the release of
a to-be-free object, which thus remains undeleted until its
reference count reduces to zero. Consequently, our scheme
could suffer from a memory overhead due to undeleted (and
thus unreclaimed) objects, particularly if their number be-
comes large. Luckily, as will be empirically demonstrated,
the overhead was manageably small for most real cases as
far as we could accurately compute the reference counts and
timely delete the undeleted objects. In fact, this very problem
of reference count computing is another important aspect to
be considered for the practical application of our scheme
to legacy code because the notorious C/C++ programming
practices heedlessly violating type safety tend to extremely
complicate this problem. For example, common practices, such
as unrestricted pointer arithmetic and abusive uses of type casts
or unions in C/C++, make it difﬁcult to pinpoint exactly when
pointers are generated and deleted at runtime, which in turn
results in imprecise and incorrect reference counting.
Because the legacy C/C++ code is such full of type unsafe
operations, previous attempts based on reference counting
could not effectively tackle the UAF problem in the legacy
code [9], [2]. In this paper, we propose CRCount, an effective
and efﬁcient solution developed to mitigate UAF errors on
the basis of implicit invalidation. As reasoned above, the key
to the success of our solution depends on the accuracy of
reference counting. To compute reference counts with high
precision, CRCount adopts a technique called pointer foot-
printing, which tracks down the memory locations of live heap
pointers along the execution ﬂow. Our pointer footprinting
technique is centered around a special data structure, called
the pointer bitmap,
that represents the up-to-date memory
locations where the heap pointers are stored. The bitmap is
updated by means of program instrumentation coupled with the
runtime library. The empirical results show that, assisted by the
footprinting technique, CRCount could track C/C++ pointers
with a relatively low overhead and compute the reference
counts with high accuracy. CRCount
is implemented as a
compiler pass in LLVM. Therefore, any C/C++ program can
be fortiﬁed against attacks exploiting UAF errors merely by
compiling its source code with CRCount enabled.
II. RELATED WORK
In this section, we will continue the discussion on CRCount
by relating it to previous solutions that also aimed to thwart
UAF errors in C/C++ code.
2
Explicit Pointer Invalidation. We divide the explicit pointer
invalidation techniques into two folds depending on the manner
in which updates on the reference relationships between point-
ers and objects are reﬂected. We deem that DANGNULL [17]
and FreeSentry [40] update the reference relationships in an
eager manner because they always update their metadata
for pointers and objects right after the pointer arithmetic
operations affecting the relationships. In contrast, we deem
that DangSan [36] opt for the lazy manner in updating these
relationships. This enables DangSan to achieve much better
performance, but DangSan’s memory overhead is often too
large, as the size of the history table grows extremely large for
programs with heavy uses of pointers. In principle, CRCount
embraces the same eager update strategy as DANGNULL
in such a way that when an object is linked/delinked with
a pointer by pointer arithmetic, the reference relationships
are updated instantly by modifying the object’s reference
count accordingly. However, CRCount does not suffer from
the performance issue as it manages much lighter metadata.
Moreover, our implicit pointer invalidation scheme does not
suffer from the performance overhead that was mandated by
DANGNULL to explicitly invalidate all the pointers referring
to an object when the object is freed.
Implicit Pointer Invalidation.
Thus far, several studies
have come close to CRCount in the sense that they beneﬁt
from the implicit pointer invalidation even if this fact is not
expressed clearly in the literature [3], [28], [39], [32]. To be
more speciﬁc, their solutions are exempt from additional force
required to explicitly invalidate dangling pointers by delaying
the reuse of the recently freed objects in the hope that the
number of pointers referring to freed objects would gradually
decrease to zero during program execution. However, these
approaches differ from CRCount in one important aspect. They
do not have notions, such as reference counting, to measure
the number of pointer references at runtime. Therefore, they
cannot determine exactly how long they should hold the freed
objects back from being reused by the memory allocator,
and their common schemes are to release the objects simply
when speciﬁc conditions are met, such as after a random
amount of time or when the total size of objects being held
reaches a certain limit. Unfortunately, such naive schemes can
be easily circumvented by calculated attacks such as heap
spraying [17], [8] or heap fengshui [35]. In contrast, CRCount,
by maintaining precise reference counters for every object, can
guarantee the safe release of freed objects for reuse with no
presence of dangling pointers.
Object Access Validation. Many security solutions [24],
[33] have attempted to prevent UAF errors by exhaustively
validating every object access via pointers. To this end, they
use a lock-and-key mechanism that can check the validity by
(1) assigning a unique lock to each object at the creation time,
and (2) monitoring whether the object accesses are made by
the pointers having the correct key matching the target object’s
lock. This mechanism realizes a thorough defense against UAF
errors. However, they are at a disadvantage as compared to
CRCount it terms of accuracy and performance: they generate
a number of false positive alarms because of their strictness
that goes beyond the common programming practices, and
incur a huge performance overhead necessary to intervene in
every object access.
Secure Layout of Object. Some systems prevent the ex-
ploitation of UAF errors by using prudent layouts of objects.
Cling [1] forces new objects to be created only in a memory
block that has either never been allocated or has been allocated
to objects of the same type. In brief, Cling mitigates UAF
errors by ensuring the type safety of the allocated objects.
Although efﬁcient, it still allows UAF errors between objects
of the same type. Oscar [7] defeats UAF errors through a
careful arrangement of objects. For this, Oscar never reuses
the (virtual) memory, such that all the objects are created
in a unique memory space, thereby completely blocking the
UAF bugs. Oscar facilitates an effective measure against UAF
errors. The downside, however, is that it suffers from a higher
performance and memory overhead than CRCount because it
abandons the efﬁciency that could otherwise be gained through
the maximal reuse of the memory space.
Garbage Collection. Garbage collection makes a program