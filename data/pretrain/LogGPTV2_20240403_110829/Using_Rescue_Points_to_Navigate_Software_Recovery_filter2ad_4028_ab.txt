tions that return pointers require a deeper inspection of the
data-structures to ascertain the values of their return types
beyond the simple case of returning a NULL. Preliminary
empirical examination shows that the examined C programs
tend to favor the use of integer return types as failure indi-
cators. After the function ﬁltering, we have the ﬁnal set of
candidate rescue points. At that point, the candidate rescue-
point graph is used to determine potential rescue points.
The function where the fault occurred forms the root of
the tree. For each node in the rescue-graph, we replay the
input that caused the failure and successively try error vir-
tualization at each of the nodes. With the protection mech-
anism in place, faults are “caught” by the application moni-
tor and program state is rolled back to the rescue point. The
rescue point, examines the rescue-graph to determine which
value to force as a return. This value is derived by analyzing
the return values of the rescue-point function.
Using the example in Figure 2, when an error is detected
in function bad(), we ﬁrst extract the call-stack, which
includes functions bar() and foo(). Assuming that the
rescue-graph contains every function found in the call stack,
we initiate error virtualization with the root node, bad().
We iterate the rescue-graph attempting error virtualization
on nodes bad() and bar() until we reach function foo()
that recovers program execution without side eﬀects.
In the case where there is no overlap between the res-
cue and function call-graphs there are alternative recovery
mechanisms that can be used. First, we can recover to a
programmer-annotated point or we iterate through the call-
stack of the vulnerable function (potentially all the way to
main) until we ﬁnd a suitable rescue point, i.e., one that
doesn’t crash the application by applying the heuristics de-
scribed in previous work [20].
3.3 Fault Detection Monitors
We treat the fault-detection component as a black box,
which need only be able to notify the fault monitor of the
occurrence of a fault. In addition to standard operating sys-
tem error handling (e.g. illegal memory dereferences, etc.),
we use additional mechanisms for detecting memory errors.
There are a number of available fault detection components
that can detect memory errors (such as ProPolice [9] and
TaintCheck [12]) and some that detect violations to under-
lying security policies [1, 11]. For the purposes of our sys-
tem, we use two fault detection components that have been
previously developed [19, 20] that oﬀer tradeoﬀs between
performance overhead and the range of faults that they can
detect. For this implementation, we assume source-code
availability but we plan to address applicability to commer-
cial oﬀ-the-shelf (COTS) software in future work.
3.4 Decision: Hypothesis Testing
Once a candidate rescue point has been elected, the sys-
tem proceeds to the patch testing and analysis phase. At
this stage, to verify the eﬃcacy of the proposed ﬁx, the
rescue-enabled version of the application is restarted and
supplied with the input that caused the fault to manifest (or
the N most recent inputs if the oﬀending one cannot be eas-
ily identiﬁed, where N is a conﬁgurable parameter). If the
application crashes, a new ﬁx is created using the next avail-
able candidate “rescue point” and the testing and analysis
phase is repeated. For our initial approach, we are primarily
concerned with failures where there is a one-to-one corre-
spondence between inputs and failures, and not with those
that are caused by a combination of inputs. Note, however,
that many of the latter type of failures are in fact addressed
by our system, because the last input (and code leading to a
failure) will be recognized as “problematic” and handled as
we have discussed.
If the ﬁx does not introduce any faults that cause the ap-
plication to crash, the application is examined for semantic
bugs using a set of user-supplied tests. The purpose of these
tests are to provide some level of conﬁdence on the semantic
correctness of the generated patch. For example, an on-line
vendor could run tests that make sure that client orders can
be submitted and processed by the system.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:54:28 UTC from IEEE Xplore.  Restrictions apply. 
2007 IEEE Symposium on Security and Privacy(SP'07)0-7695-2848-1/07 $20.00  © 20074 Discussion
One of the most critical concerns with recovering from
software faults and vulnerability exploits is ensuring the
consistency and correctness of program data and state. This
is an issue that is present in the majority of recovery eﬀorts.
The presence of rescue points, whether derived automati-
cally or with programmer assistance, can alleviate most of
the concerns with unpredictable execution paths but alas not
completely dismiss them. In this section, we examine, in
more detail, the advantages and disadvantages of fault re-
covery in general and error virtualization in particular.
Fault Response: A fault recovery mechanism must eval-
uate and choose a response from a wide array of choices.
Currently, when encountering a fault, a system can pick
from the following options: crash [9], crash and be restarted
by a monitor [4, 5], return arbitrary values [16, 17], change
environment and replay [14], slice oﬀ the functionality
[19, 20], or jump to a safe (rescue) point and force error.
Previous approaches focused on crash-based methods,
working under the assumption that there is no acceptable
alternative. More recent work [17, 20] showed that there
exists a set of alternative reactive techniques that seem to
work well in practice. We elect to take the last approach
of recovering execution to safe points and forcing errors in
a program’s execution. Early experimentation has shown
that this choice seems to work extremely well. This phe-
nomenon also appears at the machine instruction level [21].
However, there is a fundamental problem in choosing a par-
ticular response. Since the high-level behavior of any sys-
tem cannot be algorithmically determined, the system must
be careful to avoid cases where the response would take ex-
ecution down a semantically (from the viewpoint of the pro-
grammer’s intent) incorrect path. An example of this type of
problem is skipping a check in sshd which would allow an
otherwise unauthenticated user to gain access to the system.
We posit that through the use of rescue points, we are able to
minimize (unfortunately not eliminate) the uncertainty that
a program will go down an unexpected execution path. The
reason we are able to make such claims stems from the fact
we opt to use as recovery points, positions in the program
that are known to propagate errors. If higher level of assur-
ance is required, one can rely on the programmer to provide
annotations as to which parts of the code should be used for
recovery and which should not be circumvented.
Programming with Error Virtualization:
In this paper,
we focus on fully automated techniques for every aspect of
our system. However, it would not be prudent to dismiss
the use of programmer assistance in program recovery. In
particular, programmers can design software with error vir-
tualization in mind, where speciﬁc locations in the code can
be assigned, a priori, as rescue points that propagate faults
gracefully. Programmer insight is diﬃcult to replicate with
automated techniques, especially when dealing with code
cleanup and eﬃciency. We envision that programming with
error virtualization will prove easier than dealing with lan-
guage speciﬁc constructs, such as exception handling, since
attention can be focused on a few select program points.
Applicability to safe languages: A pressing question that
always comes up when discussing techniques that aim to
protect legacy applications written in unsafe languages is:
can we avoid the problems we are trying to solve by us-
ing a safe dialect? Unfortunately, it seems that having the
appropriate language constructs for handling errors (excep-
tions) solves some of the issues but it is far from a panacea.
This is especially true for large evolving systems where the
complexity of the system makes it very diﬃcult to cover all
corner cases. Our approach can be applied to such systems
by creating a map between the ﬁnite set of existing error
handling capabilities and the inﬁnite set of future add-on
capabilities of a system. We often see systems that begin
with the best of intentions, trying to cover error cases but as
features creep in to the product the complexity of examining
all cases becomes prohibitively large.
Availability: One of the principal goals of our work is to
help reduce system down-time and consequently increase
service availability in the face of failures and attacks. We
anticipate that the reduction of down-time will be non-
negligible; error virtualization relies on the fault detection
monitors detecting faults, ﬁnding appropriate rescue points,
create a patch and inserting the patch to the running applica-
tion. This process requires some down-time but the cost is
amortized since this cost is incurred once per detected vul-
nerability. Combining our approach with techniques such
as micro-rebooting [4, 5] is a topic of future research.
Dealing with non-server type applications: The success
of our system in recovering program execution can be ex-
plained partly by the basic characteristics of the types of
applications that we examine. As articulated in [17], server
type applications tend to have short error propagation dis-
tances and forcing errors in one request has little if any im-
pact on future requests. While server application might have
an inherent advantage in propagating errors, we believe that
most application are written with some error handling ca-
pabilities. Correctly identifying these rescue points should
translate our approach to a wide range of applications, al-
though, as mentioned previously, applications that rely on
the integrity of their computation might be better oﬀ using
an alternative strategy.
5 Conclusions
We have outlined error virtualization using rescue
points, a new software self-healing technique for detecting,
tolerating and recovering from software faults in server ap-
plications. Our approach leverages existing quality assur-
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:54:28 UTC from IEEE Xplore.  Restrictions apply. 
2007 IEEE Symposium on Security and Privacy(SP'07)0-7695-2848-1/07 $20.00  © 2007ance testing to generate known bad inputs to an application
to create a call graph of functions and their return values as
potential rescue points. We then use target systems to de-
tect software faults in the application caused by attacks to
exploit software vulnerabilities, and obtain a resulting call
stack. This is matched with the potential set of rescue points
by rolling back and repeating execution with the fault to de-
termine which rescue point can be used for recovering from
the fault. Our system dynamically patches the running pro-
duction application to self-checkpoint at the rescue point
and, if a fault occurs, roll back to the checkpoint and return
a known return value used to respond to bad input, which is
used by the applications own built-in error handling mech-
anisms to recover from the fault. Our plans for future work
include demonstrating the eﬀectiveness of our technique us-
ing a battery of real and synthetic attacks and failures, and
evaluating its performance impact on applications.
6 Acknowledgements
We thank the anonymous reviewers and our shepherd
Diego Zamboni for their insightful comments and sugges-
tions on the paper. This material is based on research spon-
sored by Air Force Research Laboratory under agreement
number FA8750-06-2-0221 and by NSF Grant 06-27473.
The U.S. Government is authorized to reproduce and dis-
tribute reprints for Governmental purposes notwithstanding
any copyright notation thereon.
References
[1] M. Abadi, M. Budiu, U. Erlingsson, and J. Ligatti. Control-
In CCS ’05: Proceedings of the 12th
ﬂow integrity.
ACM conference on Computer and communications secu-
rity, pages 340–353, New York, NY, USA, 2005. ACM
Press.
[2] B. Buck and J. K. Hollingsworth. An API for runtime code
patching. The International Journal of High Performance
Computing Applications, 14(4):317–329, Winter 2000.
[3] C. Cadar and D. R. Engler. Execution generated test cases:
How to make systems code crash itself.
In P. Godefroid,
editor, SPIN, volume 3639 of Lecture Notes in Computer
Science, pages 2–23. Springer, 2005.
[4] G. Candea and A. Fox. Recursive Restartability: Turning the
Reboot Sledgehammer into a Scalpel. In Proceedings of the
8th Workshop on Hot Topics in Operating Systems (HotOS),
pages 125–132, May 2001.
[5] G. Candea and A. Fox. Crash-only software. In Proceedings
of the 9th Workshop on Hot Topics in Operating Systems,
May 2003.
[6] S. Chandra. An Evaluation of the Recovery-related Proper-
ties of Software Faults. PhD thesis, University of Michigan,
2000.
[7] S. Chandra and P. M. Chen. Wither Generic Recovery from
Application Faults? A Fault Study using Open-Source Soft-
In Proceedings of the International Conference on
ware.
Dependable Systems and Networks / Symposium on Fault-
Tolerant Computing (FTCS), June 2000.
[8] B. Demsky and M. C. Rinard. Automatic Detection and Re-
pair of Errors in Data Structures. In Proceedings of the 18th
Annual ACM SIGPLAN Conference on Object Oriented Pro-
gramming, Systems, Languages, and Applications, October
2003.
[9] J. Etoh.
GCC extension for protecting applications
from stack-smashing attacks. http://www.trl.ibm.com/
projects/security/ssp/, June 2000.
[10] P. Godefroid, N. Klarlund, and K. Sen. Dart: directed au-
tomated random testing. In PLDI ’05: Proceedings of the
2005 ACM SIGPLAN conference on Programming language
design and implementation, pages 213–223, New York, NY,
USA, 2005. ACM Press.
[11] V. Kiriansky, D. Bruening, and S. Amarasinghe. Secure Ex-
In Proceedings of the
ecution Via Program Shepherding.
11th USENIX Security Symposium, pages 191–205, August
2002.
[12] J. Newsome, D. Brumley, and D. Song. Vulnerability-
speciﬁc execution ﬁltering for exploit prevention on com-
In Proceedings of the 13th Annual Net-
modity software.
work and Distributed Systems Security Symposium, 2006.
http://www.cs.cmu.edu/∼dbrumley/.
[13] S. Osman, D. Subhraveti, G. Su, and J. Nieh. The design and
implementation of Zap: A system for migrating computing
environments. In Proceedings of the 5th USENIX Symposium
on Operating Systems Design and Implementation (OSDI),
pages 361–376, December 2002.
[14] F. Qin, J. Tucek, J. Sundaresan, and Y. Zhou. Rx: treating
bugs as allergies - a safe method to survive software failures.
In A. Herbert and K. P. Birman, editors, SOSP, pages 235–
248. ACM, 2005.
[15] M. Rinard. Acceptability-oriented computing, 2003.
[16] M. Rinard, C. Cadar, D. Dumitran, D. Roy, and T. Leu. A
Dynamic Technique for Eliminating Buﬀer Overﬂow Vul-
nerabilities (and Other Memory Errors). In Proceedings 20th
Annual Computer Security Applications Conference (AC-
SAC), December 2004.
[17] M. Rinard, C. Cadar, D. Dumitran, D. Roy, T. Leu, and
J. W Beebee. Enhancing Server Availability and Security
Through Failure-Oblivious Computing. In Proceedings 6th
Symposium on Operating Systems Design and Implementa-
tion (OSDI), December 2004.
[18] R. Sengupta, O. J. D., F. D. J., K. D. S., Springer, S. P. L.,
N.-S. H. S., H. M. A., M. R. J., and J. C. Software Fault
Tolerance for Low-to-Moderate Radiation Environments. In
ASP Conf. Ser., Vol. 238, Astronomical Data Analysis Soft-
ware and Systems X, 2001.
[19] S. Sidiroglou, Y. Giovanidis, and A. Keromytis. A Dy-
namic Mechanism for Recovery from Buﬀer Overﬂow at-
tacks. In Proceedings of the 8th Information Security Con-
ference (ISC), September 2005.
[20] S. Sidiroglou, M. E. Locasto, S. W. Boyd, and A. D.
Keromytis. Building a reactive immune system for software
services. In Proceedings of the USENIX Technical Confer-
ence, April 2005.
[21] N. Wang, M. Fertig, and S. Patel. Y-Branches: When You
Come to a Fork in the Road, Take It. In Proceedings of the
12th International Conference on Parallel Architectures and
Compilation Techniques, September 2003.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:54:28 UTC from IEEE Xplore.  Restrictions apply. 
2007 IEEE Symposium on Security and Privacy(SP'07)0-7695-2848-1/07 $20.00  © 2007