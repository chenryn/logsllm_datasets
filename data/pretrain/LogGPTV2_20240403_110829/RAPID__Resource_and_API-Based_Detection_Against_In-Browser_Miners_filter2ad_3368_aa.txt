title:RAPID: Resource and API-Based Detection Against In-Browser Miners
author:Juan D. Parra Rodriguez and
Joachim Posegga
RAPID: Resource and API-Based Detection Against In-Browser
Miners
Juan D. Parra Rodriguez
University of Passau
Passau, Germany
PI:EMAIL
ABSTRACT
Direct access to the system’s resources such as the GPU, persistent
storage and networking has enabled in-browser crypto-mining.
Thus, there has been a massive response by rogue actors who abuse
browsers for mining without the user’s consent. This trend has
grown steadily for the last months until this practice, i.e., Crypto-
Jacking, has been acknowledged as the number one security threat
by several antivirus companies.
Considering this, and the fact that these attacks do not behave as
JavaScript malware or other Web attacks, we propose and evaluate
several approaches to detect in-browser mining. To this end, we
collect information from the top 330.500 Alexa sites. Mainly, we
used real-life browsers to visit sites while monitoring resource-
related API calls and the browser’s resource consumption, e.g.,
CPU.
Our detection mechanisms are based on dynamic monitoring,
so they are resistant to JavaScript obfuscation. Furthermore, our
detection techniques can generalize well and classify previously
unseen samples with up to 99.99% precision and recall for the benign
class and up to 96% precision and recall for the mining class. These
results demonstrate the applicability of detection mechanisms as a
server-side approach, e.g., to support the enhancement of existing
blacklists.
Last but not least, we evaluated the feasibility of deploying proto-
typical implementations of some detection mechanisms directly on
the browser. Specically, we measured the impact of in-browser API
monitoring on page-loading time and performed micro-benchmarks
for the execution of some classiers directly within the browser. In
this regard, we ascertain that, even though there are engineering
challenges to overcome, it is feasible and benecial for users to
bring the mining detection to the browser.
CCS CONCEPTS
• Security and privacy → Browser security; Web protocol secu-
rity; Web application security;
KEYWORDS
Web Security, CryptoJacking, HTML5, Browser Abuse
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for prot or commercial advantage and that copies bear this notice and the full citation
on the rst page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
© 2018 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-6569-7/18/12.
https://doi.org/10.1145/3274694.3274735
313
Joachim Posegga
University of Passau
Passau, Germany
PI:EMAIL
ACM Reference Format:
Juan D. Parra Rodriguez and Joachim Posegga. 2018. RAPID: Resource and
API-Based Detection Against In-Browser Miners. In 2018 Annual Com-
puter Security Applications Conference (ACSAC ’18), December 3–7, 2018, San
Juan, PR, USA. ACM, New York, NY, USA, 14 pages. https://doi.org/10.1145/
3274694.3274735
1 MOTIVATION
HTML5 technologies such as WebGL and WebSockets contributed
to achieve something that was attempted but not successful so far:
in-browser crypto-currency mining [1]. On the one hand, crypto-
mining could be a business model where visitors use energy and
computational resources in exchange for the content they get, in-
stead of coping with advertisements and their privacy implica-
tions [14, 16, 29, 47]. However, system administrators, develop-
ers, and attackers have started embedding crypto-mining scripts
through their own and third-party sites without the users’ consent.
Abusing the browser’s resources for crypto-mining without the
user’s knowledge, i.e., CryptoJacking, has been already recognized
by the ESET antivirus company as the top cyber attack today [17].
Further, Symantec states that browser-based CryptoJacking has
increased by 8.500% in 2017 in their technical report [43]. From
a practical perspective, there is no evidence of a transparent en-
vironment where users provide consent before sites start using
their resources for mining. As a result, we propose to provision
the browser with tools to detect on its own, without relying on
information provided by the site visited, whether the site being
rendered is performing mining or not.
Our contributions can be summarized as follows: 1) we propose
several novel mining detection techniques based on the system’s
resource consumption and resource-related browser API usage. 2)
we evaluate and compare the performance of the dierent pro-
posed techniques by collecting information about how sites use
the browser most resource-related APIs and system’s resources.
For this, we used real-life browsers on 330.500 sites based on the
Alexa top ranking. 3) we analyze the feasibility of porting API-
based mining detection to the browser. To this end, we perform a
quantitative analysis of the overhead on the page loading time and
execute micro-benchmarks for the detection algorithm.
This paper is structured as follows: Section 2 states our problem.
Sections 3 and 4 describe our methodology and evaluation. Then,
we cover related work in Section 5 and draw conclusions from our
work and discuss feature steps in Section 6.
2 PROBLEM STATEMENT
CryptoJacking has some critical dierences with malware
and other Web attacks. First of all, JavaScript malware, as well
as attacks against the users’ sessions and data, are executed once.
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Juan D. Parra Rodriguez and Joachim Posegga
Once the attacker has obtained the data, session or control over
the machine, the attack is successful and complete. For mining, an
attacker benets over longer periods of time because his earnings
are proportional to the resources he can use on the browser’s side.
Second, conventional Web security mechanisms, such as the Same
Origin Policy or Content Security Policies (CSP) cannot protect
users against mining because in many cases the code is delivered
as part of the frame or site rendered by the browser. Thousands
of sites have been used to deliver mining scripts in dierent ways
without signs of cross-site scripting or other Web attacks. For in-
stance, Youtube advertisements [25, 46], Content Management Sys-
tem widgets [26], or even wrong permissions assigned to Amazon
S3 buckets [28] have been used by attackers to modify sites and
inject mining scripts.
So far, two possible countermeasures against mining have been
implemented or discussed: blacklisting domains or blocking sites
based on their resource consumption. However, existing counter-
measures have two problems. Blacklists are easy to circumvent
by moving miners to new domains1; thus, they yield too many false
negatives. Second, there is a bug description asking Chromium de-
velopers to block sites with CPU usage; however, most developers
consider it to be an unreliable indicator for mining because it can
block many benign sites and create many false positives [13].
We aim to close this gap by providing a better detection mecha-
nism that can achieve two goals. On the one hand, the detection
mechanism should label miners on sites that were not previously
seen, i.e., reduce false negatives of blacklists. On the other hand, it
should not label sites as miners unless they are performing mining,
i.e., decrease false positives with respect to a decision only con-
sidering processing power. To this end, we performed a thorough
evaluation between a detection mechanism based on network, pro-
cessor, and memory consumption and a more advanced approach
based on monitoring resource-related API calls inside the browser.
The next aspect related to CryptoJacking is to assess when to
perform online or oline detection. We refer to online detection
when detection is performed on the same browser where sites are
being browsed by users; conversely, we term oine detection when
malicious or benign sites are classied in a dierent system than the
one employed by the user, e.g., in a cloud infrastructure and then
delivering a blacklist to the user’s browser. In the case of oine
detection, servers are constantly crawling the internet and could
come across dierent content than what is served to actual users
for two reasons: 1) the server could get a customized version of
the content without the mining, 2) pages serving malicious content
could be behind log-in screens, etc. Despite these issues, oine
detection has been incredibly useful to train and verify results from
more lightweight (online) mechanisms in the past; for example,
Cujo [38] and ZOZZLE [9] were trained and veried, respectively,
using JSAND [8]: an oine malicious JavaScript detection mech-
anism. Another advantage of oine mechanisms is that they can
have more computing power and more specialized setups which
translates into better detection performance.
Every detection method we analyze can be deployed oine. In
particular, the resource-based approach can only be performed
1[6] showed that CryptoJacking actors started hosting their own proxy servers to
connect to mining pools [49] to avoid fees for Monero and to make detection harder
to perform as domain blacklisting is not sucient anymore.
oine because it executes a browser in an isolated environment
during a single site visit. Contrarily, the resource-related in-browser
API classier has more potential to be deployed directly in the
user’s browser, i.e., for online detection. Thus, we measure the
impact on page-loading time imposed by the API monitoring and
the computation of the feature vector.
3 METHODOLOGY
We started by performing a large-scale collection of how sites use
system’s resources particular API calls. Afterward, we labeled the
data with two classes (mining, or benign sites). Then, we chose
dierent sets of features as well as a learning model to train a
classier predicting whether a site is performing mining or not.
3.1 Data Collection
There have been several approaches to automate browsers for data
collection, e.g., OpenWPM created by Englehardt and Narayanan [14],
yet we decided to implement our own mechanisms for various rea-
sons. We needed to control and instrument the browser remotely to
receive the events created by our instrumentation through a highly
ecient communication channel. Based on these requirements, we
decided to use the Chrome Debugging Protocol with Chromium2.
In addition to collecting which API calls have been performed
by Websites, we faced the challenge of quantifying the resources
used by each browser during the experiments. To tackle this, we
used docker containers to isolate the browser processes and
count the amount of memory, processor, and networking used.
Additionally, through the docker API, we were able to create, stop
and delete containers for each visit. This ensures that the initial
state is always the same, i.e., no cookies, local storage or cached
sites, and the reproducibility of the experiments.
Figure 1 shows the logical architecture of our crawling system.
A Crawler Node selects a pending job (site visit) from the database,
creates a new chromium container and starts listening for memory,
CPU, and network consumption events through docker APIs. Then,
each node instructs one browser to instrument all pages loaded and
to visit a particular page. During the visit, which lasts 35 seconds,
the node receives all events detected by the instrumented code from
the browser through the Chromium debugging protocol. Finally,
it stops the tracing and waits until all data has been received be-
fore stopping the resource monitoring for the container and then
removes the container. Additionally, there is a shared MongoDB
database holding all pending jobs and results obtained so far. The
database was designed to ensure that several nodes can be executed
in parallel without conicting with each other. We used one Virtual
Machine (VM) with 700 GB of disk to host the database and four
VMs with 15 GB of disk for crawling. All VMS were executed inside
a single physical host running a VMWare ESX Virtualization server
and had eight virtual processors and 8 GB of RAM. Moreover, each
crawling VM had seven nodes (each node controlling one browser).
To run Chromium on headless mode, we used the X virtual frame
buer tool (Xvfb) to execute it without requiring a screen for the
servers visiting the sites.
2A key advantage is that Chromium enables us to leverage the internal network and
proling protocol to send events from the browser to the monitoring program by
calling console.timeStamp() within the instrumented code.
314
RAPID: Resource and API-Based Detection Against In-Browser Miners
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
I(cid:81)(cid:87)(cid:72)(cid:85)(cid:81)(cid:72)(cid:87)
(cid:38)(cid:82)(cid:81)(cid:87)(cid:68)(cid:76)(cid:81)(cid:72)(cid:85)
(cid:38)(cid:75)(cid:85)(cid:82)(cid:80)(cid:76)(cid:88)(cid:80)
(cid:38)(cid:82)(cid:81)(cid:87)(cid:68)(cid:76)(cid:81)(cid:72)(cid:85)
(cid:38)(cid:75)(cid:85)(cid:82)(cid:80)(cid:76)(cid:88)(cid:80)
(cid:38)(cid:82)(cid:81)(cid:87)(cid:68)(cid:76)(cid:81)(cid:72)(cid:85)
(cid:38)(cid:75)(cid:85)(cid:82)(cid:80)(cid:76)(cid:88)(cid:80)
(cid:38)(cid:82)(cid:81)(cid:87)(cid:68)(cid:76)(cid:81)(cid:72)(cid:85)
(cid:38)(cid:75)(cid:85)(cid:82)(cid:80)(cid:76)(cid:88)(cid:80)
(cid:38)(cid:85)(cid:68)(cid:90)(cid:79)(cid:72)(cid:85)(cid:3)
N(cid:82)(cid:71)(cid:72)
(cid:17)(cid:17)(cid:17)
(cid:38)(cid:85)(cid:68)(cid:90)(cid:79)(cid:72)(cid:85)(cid:3)
N(cid:82)(cid:71)(cid:72)
(cid:57)(cid:76)(cid:85)(cid:87)(cid:88)(cid:68)(cid:79)(cid:3)(cid:48)(cid:68)(cid:70)(cid:75)(cid:76)(cid:81)(cid:72)
(cid:17)(cid:17)(cid:17)
(cid:38)(cid:85)(cid:68)(cid:90)(cid:79)(cid:72)(cid:85)(cid:3)
N(cid:82)(cid:71)(cid:72)
(cid:17)(cid:17)(cid:17)
(cid:38)(cid:85)(cid:68)(cid:90)(cid:79)(cid:72)(cid:85)(cid:3)
N(cid:82)(cid:71)(cid:72)
(cid:57)(cid:76)(cid:85)(cid:87)(cid:88)(cid:68)(cid:79)(cid:3)(cid:48)(cid:68)(cid:70)(cid:75)(cid:76)(cid:81)(cid:72)
(cid:39)(cid:68)(cid:87)(cid:68)(cid:69)(cid:68)(cid:86)(cid:72)
(cid:57)(cid:76)(cid:85)(cid:87)(cid:88)(cid:68)(cid:79)(cid:3)(cid:48)(cid:68)(cid:70)(cid:75)(cid:76)(cid:81)(cid:72)
Figure 1: Crawler’s Logical Architecture
Overall, we obtained 285.919 sites out of the top 330.500 Alexa
sites. We tried to re-execute sites that failed due to network timeouts
or operational errors after the rst run was nished. The main
operational error causing crashes during our experiments was non-
deterministic. The problem was that Chromium stopped sometimes
when Xvfb was used [33, 34]. From the 285.919 sites that were
adequately visited, we found 656 sites performing mining using the
labeling technique described in Section 3.2.
System’s Resource Monitoring: To minimize measurement errors,
we monitor all the resources used by the container running (only)
the Chromium instance that opened a site through the docker stats
API. In particular, our Crawler Node obtains events including mem-
ory, processor, and network consumption. Afterward, we aggregate
the total number of ticks used by the processor, the total number of
bytes used from main memory and the total number of bytes sent
or received over the network separately.
JavaScript APIs: The computational resources accessible through
the browser are CPU, GPU, storage, and networking. So, we over-
ride the browser’s behaviour by instrumenting the APIs using those
resources. In addition to APIs accessing the resources directly, we
have also monitored other APIs enabling inter-window commu-
nication because they also reect interactions between dierent
domains and are commonly used by WebWorkers, etc. Nonetheless,
we tried to instrument the least amount of APIs, yet still obtaining
an overview of the resources being accessed through the browser
(see Table 1).
To monitor the APIs within the browser remotely, we used the
Chrome Debugging Protocol and let the Crawler Node instrument
the browser remotely using the addScriptToEvaluateOnLoad and
setAutoAttachToCreatedPages calls from the Page API. This in-
jects scripts when a new document is created. Despite what the term
addScriptToEvaluateOnLoad suggests, this function injects the code
before the site is loaded [21]. To receive events through the Chrome
Debugging Protocol, we used the Tracing.dataCollected func-
tion to get events generated by Chromium’s console whenever the
Resource
CPU
GPU
Storage
Networking
Inter-Window
Monitored API
WebWorkers (creation)
WebAssembly (creation)
WebGLRenderingContext (all functions)
CanvasRenderingContext2D (all functions)
LocalStorage (set, get and remove)
IDBObjectStore (all functions)
WebSocket (creation, send and receive)
RTCDataChannel-WebRTC (all functions)
Window (postMessage and onMessage)
WebWorkers (postMessage and onMessage)
SharedWorker (postMessage and onMessage)
EventSource (creation and receive)
Table 1: APIs monitored
function console.timesTamp was called from the instrumented