interdependencies. We show the effect of an
important behavioral bias of human decision-making and
selfishness of PNE decision-making on system security.
2) We consider two mechanism designs for interdependent
security games modeled by attack graphs
to guide
decision-makers toward the socially optimal solution. In
contrast to excludable public good games, we show that
a weak budget balance condition is not guaranteed for all
instances of interdependent security games.
3) We explore the voluntary participation in tax-based
mechanisms and show that behavioral defenders participate
under higher tax payments, compared to rational defenders.
4) We illustrate the benefits of our mechanisms through
four real-world interdependent systems and analyze the
different system parameters and the effect of behavioral
decision-making on the mechanisms’ outcomes and the
overall security of these interdependent systems.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:21:01 UTC from IEEE Xplore.  Restrictions apply. 
2250
II. BACKGROUND AND PROBLEM SETUP
interdependent
We now present a background on interdependent security
games, establishing a theoretical basis that can be used
to model multi-defender
systems. These
defenders can be different divisions within a large company, or
different sectors of a country’s economy. We formally define
an interdependent system as “the system that has multiple
defenders where each defender is responsible for defending
a subnetwork of the whole network. In that system, there are
dependencies among assets of different subnetworks which are
captured via directed acyclic graph (DAG)”. Figure 1 shows
a simple example of our setup, which represents a system
consisting of 3 interdependent defenders. An external attacker
aims to exploit vulnerabilities within the network in order to
compromise critical targets. We now formalize the attacker and
defenders’ goals and actions. The formulation in Sections II-A
and II-B is well accepted in the security literature of attack
graphs [12], [9], [39], [40]. We start discussing the notion
of behavioral defenders from Section II-C where we tread
ground not often trodden in the security literature, with some
exceptions [25], [41], [42].
A. Threat Model
We consider security games consisting of one attacker and
multiple defenders interacting through a directed acyclic attack
graph G = (V,E). The nodes V of the attack graph represent
the assets in the system, while the edges E capture the attack
progression between the assets. In particular, an edge from vi
to vj, (vi, vj) ∈ E, indicates that if asset vi is compromised
by the attacker, it can be used as a stepping-stone to launch
an attack on asset vj (e.g., if an attacker gains the password
required to access a power plant’s control software (vi), it
can use it to attempt to alter the operation of a generator
(vj)). We denote the baseline probability that the attacker can
successfully compromise vj given that it has compromised vi,
i,j ∈ [0, 1]. By “baseline probability” we
by the edge weight p0
mean the probability of successful compromise without any
security investment in protecting the assets.3 Suppose that the
set of all defenders is given by D = {D1, . . . , Dk, . . . , D|D|}.
The attacker initiates attacks on the network from a source
node vs (or multiple possible source nodes), and aims to reach
a target node vm, i.e., a critical node for any defender Dk ∈ D.
B. Defense Model
Each defender Dk ∈ D is in control of a subset of
assets Vk ⊆ V . Among all assets in the network, a subset
Vm ⊆ V are critical assets, the compromise of which entails
a financial loss for the corresponding defender. Specifically, if
asset vm ∈ Vm is compromised by the attacker, any defender
Dk with vm ∈ Vk suffers a financial loss Lm ∈ R>0. Note that
the critical assets of different defenders can be overlapping if
they share common critical assets (e.g., the SCADA system in
Figure 6). We emphasize that different critical assets can have
heterogeneous loss valuations (Section VI).
3We emphasize that p0
investments on the edge (vi, vj ) (e.g., old software patched).
i,j can also represent the pre-existing (inherent) security
let xk
asset vm ∈ Vk), and let xi,j = (cid:80)
To protect the critical assets from being reached through
stepping-stone attacks,
the defenders can choose to invest
their resources in strengthening the security of the edges in
the network. Specifically,
i,j denote the non-negative
real investment of a defender Dk on edge (vi, vj) ∈ Ek
(it suffices for an edge to belong to Ek if it belongs to at
least one attack path from the source node vs to one critical
i,j be the total
investment on that edge by all eligible defenders. Then, the
probability of successfully compromising vj starting from vi
is given by pi,j(xi,j). In addition, let si,j ∈ [1,∞) denote
the sensitivity of edge (vi, vj) to the total investment xi,j. For
larger sensitivity values, the probability of successful attack on
the edge decreases faster with each additional unit of security
investment on that edge; in other words, edges that are easier
to defend will have larger sensitivity.
Dk∈D xk
Let Pm be the set of all attack paths from vs to vm.
The defender assumes the worst-case scenario,
the
attackerexploits the most vulnerable path to each target. Note
that previous works considered such an adversary model that
chooses the most vulnerable path to target assets (e.g., [16],
[13]). Mathematically, this can be captured via the following
total loss function for Dk:
i.e.,
ˆCk(x) =
Lm
max
P∈Pm
(vi,vj )∈P
pi,j(xi,j)
.
(1)
(cid:89)
(cid:17)
(cid:16)
(cid:88)
vm∈Vk
(cid:16) − si,j xi,j
(cid:17)
is negligible with respect
In the above cost function in (1), we assume that the defense
cost
to the huge financial cost
under successful attack. We let the probability of successfully
compromising vj starting from vi be given by,
pi,j(xi,j) = p0
i,j exp
.
(2)
That is, the probability of successful attack on an edge (vi, vj)
decreases exponentially with the sum of the investments on
that edge by all defenders. This probability function falls
within a class commonly considered in security economics
[43], [10], [16], [32]. Note that (2) is a log-convex function.
C. Behavioral Probability Weighting
by
overweighting
As mentioned in the introduction, the behavioral economics
literature has shown that humans consistently misperceive
probabilities
and
underweighting high probabilities [18], [44]. More specifically,
humans perceive a “true” probability p as probability w(p),
where w(·) is known as a probability weighting function.
A commonly studied form for this weighting function was
formulated by Prelec in [44], shown in Figure 2, given by
low probabilities,
p ∈ [0, 1],
,
w(p) = exp
(3)
where α ∈ (0, 1] controls the extent of misperception. When
α = 1, we have w(p) = p for all p ∈ [0, 1], which corresponds
to correct perception of probabilities, i.e., a non-behavioral
(rational) defender (agent).
(cid:104) − (− log(p))α(cid:105)
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:21:01 UTC from IEEE Xplore.  Restrictions apply. 
3251
Fig. 1: An overview of the interdependent security framework.
The interdependencies between assets are represented by
edges. An attacker tries to compromise critical assets using
stepping-stone attacks starting from vs. The bold (red) edges
show one such attack path.
Fig. 2: The Prelec probability weighting function. The
parameter α ∈ (0, 1] controls the extent of overweighting
and underweighting, with α = 1 indicating non-behavioral or
rational decision-making. The smaller the value of α the more
behavioral the action is (see dotted curves in the figure).
(cid:16)
(cid:88)
vm∈Vk
(cid:89)
(cid:17)
D. Perceived Cost of a Behavioral Defender
We now incorporate this probability weighting function into
the interdependent security game defined in Section II-B. In a
Behavioral Security Game, each defender misperceives attack
success probability on each edge according to the probability
weighting function in (3). She then chooses her investments
xk := {xk
i,j}(vi,vj )∈Ek to minimize her perceived loss
Ck(xk, x−k) =
Lm
max
P∈Pm
(vi,vj )∈P
w (pi,j(xi,j))
,
(cid:80)
subject
(vi,vj )∈Ek
to her
i,j ≤ Bk
xk
total security investment budget Bk,
(4)
i.e.,
4, and non-negativity of the investments,
i,j ≥ 0. We now show that the total loss (4) is convex.
i.e., xk
Lemma 1. Let the probability of successful attack function
on each edge pi,j(xi,j) be twice-differentiable and log-convex.
Then, the total loss function in (4) is convex in investment xi,j.
The proof of Lemma 1 follows from the second derivative
of the total loss function in (4) with respect to xi,j and the
properties of the probability weighting function in (3).
E. Socially Optimal Investments
It
is also common in the literature to measure the
sub-optimality of Nash equilibria (attained by interdependent
security games between multiple selfish defenders) by
comparing them to socially optimal
investments.
Formally, the socially optimal investment levels x∗ are those
that maximize the social welfare (i.e.,
these investments
minimize the sum of all defenders’ costs), which is given by
(SO)
|D|(cid:88)
k=1
x∗ = argmin
1T x≤(cid:80)|D|
x⪰0;
k=1 Bk
where |D| is the number of defenders.
Ck(x),
(5)
4Our findings will also follow if each defender invests any amount subject to
a maximum budget. The stakeholder (defender) can use any amount from
such a maximum budget limit for enhancing the security of her subnetwork.
investment
A comparison of the Nash equilibria and the socially
optimal solution often reveals sub-optimal
in
security by defenders at PNE where each defender only cares
about her own critical assets. In the literature,
there are
several works that have proposed mechanisms for decreasing
this inefficiency gap, by incentivizing improved security
investments [37], [45]. However, these works studied specific
games where each defender has a single asset in which she
allocates her resources [37] or considered that all defenders
have a common asset [45]. Moreover, all of these works
considered only classical models of rational decision-making
introduced earlier. On the contrary, we consider an attack
graph based system where each defender has the ownership
of a subset of nodes. Further, the interdependency between
defenders is captured via overlapping paths for reaching
different defenders’ assets, and we model
the behavioral
probability weighting bias as well. These two distinctions
make our setup more challenging compared to prior work and
more representative of the reality of interdependent system
security with humans acting as security decision-makers.
III. MECHANISM DESIGN SETUP
The focus of the present paper is designing and evaluating
regulatory mechanisms, specifically monetary taxation,
to
incentivize socially optimal security behavior for defenders
in interdependent security games. Our goal
is to find a
mechanism, run by a central regulator (e.g., a government
agency), such that the induced interdependent security game
has as
its equilibrium the solution to the centralized
problem (5) (also referred to as “implementing” the socially
optimal
incentivize optimal
behavior by assessing a tax tk to each participating defender
Dk; this tax may be positive, negative, or zero, indicating
payments, rewards, or no payment, respectively. Similar to
prior work [37], [46], we assume that defenders’ costs are
quasi-linear; i.e., linear in the tax term tk. Therefore, the total
(security) cost for a defender Dk when she is assigned a tax
tk is
solution). Such mechanisms
Ck(x, tk) := Ck(x) + tk,
(6)
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:21:01 UTC from IEEE Xplore.  Restrictions apply. 
4252
00.20.40.60.81True Probability (p)00.10.20.30.40.50.60.70.80.91Perceived Probability (w(p))where the tax amount tk can in general be a function of the
total security investment x or the overall state of system’s
security (as will be explained later in Section V) where each
mechanism corresponds to one form of tk.
Remark 1. Following the previous works [37], [46], [47],
we assume that the money used for the taxes paid by each
defender comes from a separate pool from the pool from which
the security enhancement budget of each defender is drawn.
However, we believe that considering them to be from the
same pool is an interesting direction for the future extensions.
Proposition 1. There always exists a Pure-Strategy Nash
Equilibrium in an unregulated (i.e. ti = 0, ∀i) Behavioral
Security Game as modeled in this section.
The proof of the above result follows by noting from
Lemma 1 that the cost function of each defender is convex
in the security investment level x (equivalently the payoff
is concave function in x), thus this game is an instance of
concave games which always have a PNE [48].
[35],
[46];
i.e., (cid:80)N
the regulator does not pay out
In contrast, (cid:80)N
Mechanism Properties: In addition to implementing the
socially optimal solution,
incentive mechanisms are often
designed so as to satisfy one main property. When using
taxation, the mechanism designer prefers to maintain weak
i=1 ti ≥ 0.
budget balance (WBB)
In other words,
to the
defenders.
i=1 ti < 0 implies a budget
deficit, i.e., the mechanism would require spending external
resources by the designer. At first, we consider
two
mechanism designs where participation by defenders is
mandatory (Sections V-A and V-B) and then we consider the
mechanism where participation is voluntary (Section V-C).
The mandatory participation maps to the realistic case that a
government agency can make participation in cyber-insurance
a prerequisite for companies to receive security funding
or business opportunities [26]; see for example the recent
California proposal for mandatory cyber insurance [49].
IV. MOTIVATIONAL EXAMPLES
Having provided the game notations and the general
tax-based mechanism, we now provide a couple of examples
to show the difference between the social optimal solution
(given by (5)) and the PNE solution (where each defender
best responds to the aggregate optimal investments of other
defenders) to reach the PNE of Behavioral Security Games.
Example 1. Consider the attack graph of Figure 3. There are
two defenders, D1 and D2, where defender D1 aims to protect
node v4, and defender D2 wishes to protect node v5. Suppose
that D1 has a budget B1 = 16 and D2 has B2 = 12, and let
the probability of successful attack on each edge (vi, vj) be
given by pi,j(xi,j) = e−xi,j (assuming p0
i,j = 1). Moreover,