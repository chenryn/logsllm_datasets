## 沉浸式学习PostgreSQL|PolarDB 9: AI大模型+向量数据库, 提升AI通用机器人在专业领域的精准度, 完美诠释柏拉图提出的“知识是回忆而不是知觉”   
### 作者    
digoal    
### 日期    
2023-08-31    
### 标签    
PostgreSQL , PolarDB , 数据库 , 教学    
----    
## 背景    
欢迎数据库应用开发者参与贡献场景, 在此[issue](https://github.com/digoal/blog/issues/121)回复即可, 共同建设《沉浸式数据库学习教学素材库》, 帮助开发者用好数据库, 提升开发者职业竞争力, 同时为企业降本提效.    
- 系列课程的核心目标是教大家怎么用好数据库, 而不是怎么运维管理数据库、怎么开发数据库内核. 所以面向的对象是数据库的用户、应用开发者、应用架构师、数据库厂商的产品经理、售前售后专家等角色.    
本文的实验可以使用永久免费的阿里云[云起实验室](https://developer.aliyun.com/adc/scenario/exp/f55dbfac77c0467a9d3cd95ff6697a31)来完成.    
如果你本地有docker环境也可以把镜像拉到本地来做实验:    
x86_64机器使用以下docker image:    
- [《amd64 image》](../202307/20230710_03.md)    
ARM机器使用以下docker image:    
- [《arm64 image》](../202308/20230814_02.md)    
## 业务场景1 介绍: AI大模型+向量数据库, 提升AI通用机器人在专业领域的精准度, 完美诠释柏拉图提出的“知识是回忆而不是知觉”     
越来越多的企业和个人希望能够利用LLM和生成式人工智能来构建专注于其特定领域的具备AI能力的产品。目前，大语言模型在处理通用问题方面表现较好，但由于训练语料和大模型的生成限制，对于垂直专业领域，则会存在知识深度和时效性不足的问题。在信息时代，由于企业的知识库更新频率越来越高，并且企业所拥有的垂直领域知识库（例如文档、图像、音视频等）往往是未公开或不可公开的。因此，对于企业而言，如果想在大语言模型的基础上构建属于特定垂直领域的AI产品，就需要不断将自身的知识库输入到大语言模型中进行训练。  
目前有两种常见的方法实现, 提升AI通用机器人在专业领域的精准度：  
- 微调（Fine-tuning）：通过提供新的数据集对已有模型的权重进行微调，不断更新输入以调整输出，以达到所需的结果。这适用于数据集规模不大或针对特定类型任务或风格进行训练，但训练成本和价格较高。  
- 提示调整（Prompt-tuning）：通过调整输入提示而非修改模型权重，从而实现调整输出的目的。相较于微调，提示调整具有较低的计算成本，需要的资源和训练时间也较少，同时更加灵活。  
综上所述，微调的方案投入成本较高，更新频率较低，并不适合所有企业。提示调整的方案是在向量库中构建企业的知识资产，通过LLM+向量库构建垂直领域的深度服务。本质是利用数据库进行提示工程（Prompt Engineering）将企业知识库文档和实时信息通过向量特征提取然后存储到向量数据库，结合LLM可以让Chatbot的回答更具专业性和时效性，也更适合中小型企业构建企业专属Chatbot。  
在机器学习领域，为了能够处理大量的非结构化的数据，通常会使用人工智能技术提取这些非结构化数据的特征，并将其转化为特征向量，再对这些特征向量进行分析和检索以实现对非结构化数据的处理。将这种能存储、分析和检索特征向量的数据库称之为向量数据库。  
实现原理:  
第一阶段：数据准备  
- 1\. 知识库信息提取和分块：从领域知识库中提取相关的文本信息，并将其分块处理。这可以包括将长文本拆分为段落或句子，提取关键词或实体等。这样可以将知识库的内容更好地组织和管理。  
- 2\. 调用LLM接口生成embedding(向量)：利用LLM（如OpenAI）提供的接口，将分块的文本信息输入到模型中，并生成相应的文本embedding。这些embedding将捕捉文本的语义和语境信息，为后续的搜索和匹配提供基础。你可以理解为“正确答案”(或者prompt).  
- 3\. 存储embedding(向量)信息：将生成的文本embedding(向量)信息、文本分块以及文本关联的metadata信息存入PolarDB|PostgreSQL 数据库中, 使用vector或embedding插件提供的向量数据类型。  
第二阶段：问答过程  
- 1\. 用户使用自然语言提问。  
- 2\. 通过OpenAI提供的embedding接口创建该问题的embedding(向量)。  
- 3\. 使用该问题等向量, 在PolarDB|PostgreSQL 数据库中, 搜索到向量相似度大于一定阈值的文档块, 作为用户原始问题的提示传递给OpenAI, 作为问题的Prompt。  
- 4\. 将用户输入的问题 + 最相似问题和答案(如果有)输入OpenAI, 向OpenAI提问, 从而修正直接向OpenAI问“用户输入的问题”的结果. 提升OpenAI专业领域回答的准确度.    
![pic](20230831_01_pic_001.png)  
![pic](20230831_01_pic_002.png)  
柏拉图是古希腊三贤之一, 他有个这样的观点: 人类的知识并非来自于感知和经验，而是存在于灵魂中的先前的灵魂经验的回忆。   
从上面的实现原理我们可以理解为 “AI的知识并非来自感知和经验, 而是存在于灵魂中的先前的灵魂经验的回忆” , 回忆的源头在PolarDB|PostgreSQL 数据库中, 通过问题embedding得到相似向量(prompt)的过程就是回忆.    
### 实现和对照      
#### 传统方法 设计和实验      
传统数据库没有数组类型, 只能使用text表达, 或者使用多个数值字段的组合来表达向量.    
传统数据库没有向量距离搜索的操作符, 无法实现向量特征相似搜索.    
传统数据库没有办法在text或者多个数值字段组合上建立向量索引, 因此即使实现了计算2个向量距离的函数, 也无法实现高效率的向量相似检索.    
#### PolarDB|PG新方法1 设计和实验  
第一阶段：数据准备  
数据准备阶段的关键在于将专属领域知识转化为文本embedding，并有效地存储和匹配这些信息。通过利用LLM的强大语义理解能力，您可以获得与特定领域相关的高质量回答和建议。当前的一些开源框架，可以方便您上传和解析知识库文件，包括URL、Markdown、PDF、Word等格式。例如[LangChain](https://python.langchain.com/en/latest/index.html)和OpenAI开源的[ChatGPT Retrieval Plugin](https://github.com/openai/chatgpt-retrieval-plugin)。LangChain和ChatGPT Retrieval Plugin均已经支持了基于PGVector扩展的PostgreSQL作为其后端向量数据库，这使得与PolarDB PostgreSQL版集群的集成变得更加便捷。通过这样的集成，您可以方便地完成第一阶段领域知识库的数据准备，并充分利用PGVector提供的向量索引和相似度搜索功能，实现高效的文本匹配和查询操作。  
1\. 连接PolarDB | PostgreSQL 。  
2\. 创建测试数据库，以testdb为例。  
```  
CREATE DATABASE testdb;  
```  
3\. 进入测试数据库，并创建PGvector插件。  
```  
CREATE EXTENSION IF NOT EXISTS vector;  
```  
4\. 创建测试表（本文以`polardb_pg_help_docs`为例），用于存储知识库内容。  
```  
CREATE TABLE polardb_pg_help_docs (  
  id bigserial PRIMARY KEY,   
  title text,           -- 文档标题  
  description text,         -- 描述  
  doc_chunk text,       -- 文档分块  
  token_size int,       -- 文档分块字数  
  embedding vector(1536));  -- 文本嵌入信息  
```  
5\. 为embedding列创建索引，用于查询优化和加速。  
```  
CREATE INDEX ON polardb_pg_help_docs USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);  
-- 或者使用hnsw算法  
CREATE INDEX ON polardb_pg_help_docs USING hnsw (embedding vector_cosine_ops) WITH (m = 12, ef_construction=40;  
```  
算法解读:    
- [《沉浸式学习PostgreSQL|PolarDB 8: 电商|短视频|新闻|内容推荐业务(根据用户行为推荐相似内容)、监控预测报警系统(基于相似指标预判告警)、音视图文多媒体相似搜索、人脸|指纹识别|比对 - 向量搜索应用》](../202308/20230829_02.md)    
6\. 在PyCharm中，创建项目，然后打开Terminal，输入如下语句，安装如下依赖库。  
```  
pip install openai psycopg2 tiktoken requests beautifulsoup4 numpy  
```  
7\. 创建.py文件（本文以`knowledge_chunk_storage.py`为例），拆分知识库文档内容并存储到数据库中，示例代码如下：  
说明   
> 如下示例代码中，自定义的拆分方法仅仅是将知识库文档内容按固定字数进行了拆分，您可以使用LangChain和OpenAI开源的ChatGPT Retrieval Plugin等开源框架中提供的方法进行拆分。知识库中的文档质量和分块结果对最终的输出的结果有较大的影响。  
```  
import openai  
import psycopg2  
import tiktoken  
import requests  
from bs4 import BeautifulSoup  
EMBEDDING_MODEL = "text-embedding-ada-002"  
tokenizer = tiktoken.get_encoding("cl100k_base")  
# 连接PolarDB-PG数据库  
conn = psycopg2.connect(database="",  
                        host="",  
                        user="",  
                        password="",  
                        port="")  
conn.autocommit = True  
# OpenAI的API Key  
openai.api_key = ''  
# 自定义拆分方法（仅为示例）  
def get_text_chunks(text, max_chunk_size):  
    chunks_ = []  
    soup_ = BeautifulSoup(text, 'html.parser')  
    content = ''.join(soup_.strings).strip()  
    length = len(content)  
    start = 0  
    while start = length:  
            end = length  
        chunk_ = content[start:end]  
        chunks_.append(chunk_)  
        start = end  
    return chunks_  
# 指定需要拆分的网页  
url = 'https://help.aliyun.com/document_detail/602217.html?spm=a2c4g.468881.0.0.5a2c72c2cnmjaL'  
response = requests.get(url)  
if response.status_code == 200:  
    # 获取网页内容  
    web_html_data = response.text  
    soup = BeautifulSoup(web_html_data, 'html.parser')  
    # 获取标题（H1标签）  
    title = soup.find('h1').text.strip()  
    # 获取描述（class为shortdesc的p标签内容）  
    description = soup.find('p', class_='shortdesc').text.strip()  
    # 拆分并存储  
    chunks = get_text_chunks(web_html_data, 500)  
    for chunk in chunks:  
        doc_item = {  
            'title': title,  
            'description': description,  
            'doc_chunk': chunk,  
            'token_size': len(tokenizer.encode(chunk))  
        }  
        query_embedding_response = openai.Embedding.create(  
            model=EMBEDDING_MODEL,  
            input=chunk,  
        )  
        doc_item['embedding'] = query_embedding_response['data'][0]['embedding']  
        cur = conn.cursor()  
        insert_query = '''  
        INSERT INTO polardb_pg_help_docs   
            (title, description, doc_chunk, token_size, embedding) VALUES (%s, %s, %s, %s, %s);  
        '''  
        cur.execute(insert_query, (  
            doc_item['title'], doc_item['description'], doc_item['doc_chunk'], doc_item['token_size'],  
            doc_item['embedding']))  
        conn.commit()  
else:  
    print('Failed to fetch web page')  
```  
8\. 运行python程序。  
9\. 登录数据库使用如下命令查看是否已将知识库文档内容拆分并存储为向量数据。  
```  
SELECT * FROM polardb_pg_help_docs;  
```  
第二阶段：问答  
1\. 在python项目中，创建`.py`文件（本文以`chatbot.py`为例），创建问题并与数据库中的知识库内容比较相似度，返回结果。  
```  