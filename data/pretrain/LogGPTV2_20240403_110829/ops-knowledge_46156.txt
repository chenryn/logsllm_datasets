User: 如何使用Python编写一个网络爬虫程序并从特定网站上抓取数据？请提供例程。
Assistant: 以下是一个简单的Python网络爬虫程序，用于从百度新闻获取新闻标题和链接：

```python
import requests
from bs4 import BeautifulSoup

# 网站 URL
url = 'https://news.baidu.com/'

# 向网站发送请求并获取响应内容
response = requests.get(url)

# 将响应内容解析成 BeautifulSoup 对象
soup = BeautifulSoup(response.text, 'html.parser')

# 查找新闻标题和链接
for news in soup.select('.ulist.focuslistnews > li'):
    title = news.select_one('a').text.strip()
    link = news.select_one('a')['href']
    print(title, link)
```

解释：

1. `requests` 库用于发送 HTTP 请求并获取响应内容。
2. `BeautifulSoup` 库用于解析 HTML 内容。
3. `url` 存储了要访问的网站 URL。
4. `requests.get(url)` 向网站发送请求并获取响应内容。
5. `BeautifulSoup(response.text, 'html.parser')` 将响应内容解析成 BeautifulSoup 对象。
6. `soup.select('.ulist.focuslistnews > li')` 查找 CSS 类名为 `ulist focuslistnews` 的元素下的所有 `<li>` 元素。
7. `news.select_one('a').text.strip()` 查找 `<li>` 元素下的第一个 `<a>` 元素，并获取该元素的文本内容（即新闻标题），并使用 `strip()` 方法去除首尾空白字符。
8. `news.select_one('a')['href']` 查找 `<li>` 元素下的第一个 `<a>` 元素，并获取该元素的 `href` 属性（即新闻链接）。
9. `print(title, link)` 打印新闻标题和链接。