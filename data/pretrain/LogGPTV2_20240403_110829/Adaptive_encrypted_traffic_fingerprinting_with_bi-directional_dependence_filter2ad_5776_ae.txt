for open-world without defense.
4.3.6 Adaptive ﬁngerprinting
We now present the experimental results of adaptive learning
(ADABIND) discussed in §3.2.2. The experiment in Figure 9 shows the
effect of concept drift on the model, and the BINDDUP dynamic update
(re-training) process in WFIN. Here, the x-axis represents time (in days)
and the y-axis represents accuracy (%). We consider 20 websites from
the HTTPS dataset with a training window of 16 traces per website for
training the ADABIND model (R = 16, starting at day 1 to day 16).
Then, a sliding window of 4 traces (starting at day 17) per website is
considered for validating this model by testing its accuracy.
It is important to note the training and testing data are collected at
different times, under different experimental settings. As the 4-day
validating window slides, if the accuracy drops below a certain threshold
(85% in this experiment), the model becomes obsolete. So, we re-train
the model at that point (i.e., at day 33, 94, 119, and 148 as shown in
the ﬁgure). This dynamic re-training mechanism improves the accuracy,
resulting in values above the assigned threshold. The average accuracy
of this approach is 92.6%.
Figure 9 also shows how the accuracy drops to low values if no
update is considered. In this experiment, we train the model once in the
beginning and use the 4-day sliding window to validate test traces. The
resulting average accuracy of this static learning method is 76%, which
illustrates the need for re-training the model to adapt for possible data
drifts over time.
In addition, Figure 9 shows the same experiment where we apply the
BINDFUP ﬁxed update approach by re-training the model every 24 days
instead of the dynamic update in BINDDUP. We use the same 4-day
validating window as before. The ﬁgure shows how the model becomes
more accurate and stable. Yet, this results in an extra training overhead
due to unnecessary updates. The average accuracy of this approach
is 93.3%, which is marginally better from the average accuracy of
BINDDUP (92.6%). The number of updates in this experiment for
BINDFUP is 8, which is twice as many as the number of updates in the
dynamic update approach (BINDDUP). As discussed in § 4.3.4, a
classiﬁer may have large execution time, resulting in signiﬁcantly large
)
%
(
R
D
B
 100
 90
 80
 70
 60
 50
 40
 30
WKNN
BINDWKNN
BINDRF
 2
 4
 6
 10  12  14  16  18
 8
Prior Probability (%) 
Figure 8: Increasing prior effect on BDR using the Tor dataset
for open-world while applying the Tamaraw defense.
)
%
(
c
c
A
 100
 80
 60
Dynamic update
Threshold
Fixed update
No update
 20  40  60  80  100  120  140  160  180
Time (day) 
Figure 9: Adaptive Learning.
re-training cost. This shows the trade-off between performance and cost
of re-training the model.
To see the effect of the training window (R), Figure 10 shows the
BINDDUP dynamic update experiments when varying the value of R
in the range {4, 8, 12, 16, 20}. If R is small, the number of training
instances may not be enough to build a good model, and may lead
to frequent updates. On the other hand, choosing large values of R
incurs extra training overhead and may cause the model to miss some
drifts in data. Table 13 shows the average accuracies and number of
updates/re-trains for the experiments shown in Figure 10. When R
increases, the average accuracy improves to a certain level, and then
goes down. We obtained the best results when R = 16 with a moderate
number of updates (i.e., 4 re-trains).
For the previous experiments which used SVM, we observed similar
conclusions for the other datasets. We did not include them because of
space limitations. In general, the adaptive learning algorithm can be
applied to any classiﬁcation approach.
5. DISCUSSION
In this paper, we introduced BIND, a new feature extraction and
classiﬁcation method for data analysis on encrypted network trafﬁc with
two case studies including WFIN and AFIN. We discuss the challenges
and limitations, resulting from the assumptions in our evaluation, as
well as future work.
A study in WFIN [23] describes the effects of various assumptions
on the evaluation results. Major assumptions include single-tabbed
browsing or absence of other background noise, small time gap (or
186
 100
 80
 60
R=4
R=8
R=12
R=16
R=20
)
%
(
c
c
A
 20
 40
 60
 80  100  120  140
Time (day) 
Figure 10: Dynamic update with different values of the training
window (R)
R
Average accuracy (%)
Number of updates
4
86.6
10
8
89.3
7
12
89.9
5
16
92.6
4
20
91.7
2
Table 13: Average accuracies and number of updates with dif-
ferent values of the training window (R)
freshness) in data collection between training and test set, page load
parsing, and replicability. Recent studies [18,38] tried to address these
issues by evaluating classiﬁers in conditions with relaxed assumptions.
In particular, a long time gap (or staleness) in data collection between
training and testing sets can have a signiﬁcant impact on classiﬁer
accuracy. This limitation is true for the BIND approach as well
since similar base features that are affected with time, i.e., packet
statistics such as length, sequence, and timing are used. The challenge
can be addressed by periodically training a new model with fresh
training data as introduced in this paper using ADABIND which models
ﬁngerprinting in an adaptive manner.
The ADABIND method updates the model with new training batches
which requires a signiﬁcant number of training instances. Furthermore,
the re-training process assumes the availability of testing instance labels
which may not be valid in certain cases. To address these challenges, in
future we would like to identify the right point in the incoming stream
from where we need to re-train the model incrementally (i.e., keeping
old useful data) in an unsupervised manner (i.e., without labels). Hence,
one of the future directions of BIND is to apply the concept of Change
Point Detection (CPD) [19,20] to decide when to update the model in
an unsupervised fashion and re-train incrementally.
The proposed methods in our paper assume sequential user access
to end-nodes and ignore background noise, as mentioned in §2.1
regarding WFIN [23]. Nevertheless, these methods can be augmented
with techniques relaxing such assumptions. We also note that such
assumptions are applicable to AFIN as well. In a smartphone, multiple
apps may run background services, such as auto-sync, within the
device that accesses the Internet periodically. Moreover, services
offered by an app can change over time with newer versions released by
developers periodically. Each updated version of an app may have a
dissimilar network signature or ﬁngerprint, which could affect classiﬁer
performance as well. Furthermore, exploring different activities of
an app would generate different network signatures compared to a
signature obtained by merely launching it. One could use dynamic
analysis techniques [4,32] to explore an app automatically for a better
understanding of network behaviors. We leave these for future work.
6. CONCLUSION
We introduced, implemented, and evaluated BIND, a new data
analysis method on encrypted network trafﬁc for end-node identiﬁcation.
The method leverages dependence in packet sequences to extract
characteristic features suitable for classiﬁcation. In particular, we study
two cases where our method is applicable: website ﬁngerprinting and
app ﬁngerprinting. We empirically evaluate both these cases in the
closed-world and open-world settings on various real-world datasets
over HTTPS and Tor. Empirical results indicate the effectiveness
of BIND in various scenarios including the realistic open-world
setting. Our evaluations also include cases where defense mechanisms
are applied on website and app ﬁngerprinting. We showed how the
proposed approach achieves a higher performance compared to other
existing techniques. In addition, we introduced the ADABIND approach
that addresses temporal changes in data patterns over time while
performing trafﬁc ﬁngerprinting.
7. ACKNOWLEDGMENT
This material is based upon work supported by NSF under Award No.
1054629, AFOSR under Award No. FA9550-12-1-0077 and Award No.
FA9550-14-1-0173, and NSA under Award No. H98230-15-1-0271.
References
[1] ALEXA. The top visited sites on the web. http://www.alexa.com/.
[2] ALSABAH, M., BAUER, K., AND GOLDBERG, I. Enhancing tor’s
performance using real-time trafﬁc classiﬁcation. In Proceedings
of the 2012 ACM conference on Computer and communications
security (2012), ACM, pp. 73–84.
[3] ATENIESE, G., HITAJ, B., MANCINI, L. V., VERDE, N. V.,
AND VILLANI, A. No place to hide that bytes won’t reveal:
Snifﬁng location-based encrypted trafﬁc to track a user’s position.
In Network and System Security. Springer, 2015, pp. 46–59.
[4] BHORASKAR, R., HAN, S., JEON, J., AZIM, T., CHEN,
S., JUNG, J., NATH, S., WANG, R., AND WETHERALL, D.
Brahmastra: Driving apps to test the security of third-party
components. In 23rd USENIX Security Symposium (USENIX
Security 14) (2014), pp. 1021–1036.
[5] BREIMAN, L. Random forests. Machine learning 45, 1 (2001),
5–32.
[6] CAI, X., NITHYANAND, R., WANG, T., JOHNSON, R., AND
GOLDBERG, I. A systematic approach to developing and evaluat-
ing website ﬁngerprinting defenses. In Proceedings of the 2014
ACM SIGSAC Conference on Computer and Communications
Security (2014), ACM, pp. 227–238.
[7] CAI, X., ZHANG, X. C., JOSHI, B., AND JOHNSON, R. Touching
from a distance: Website ﬁngerprinting attacks and defenses.
In Proceedings of the 2012 ACM conference on Computer and
communications security (2012), ACM, pp. 605–616.
[8] CHANG, C.-C., AND LIN, C.-J. LIBSVM: A library for support
vector machines. ACM Transactions on Intelligent Systems
and Technology 2 (2011), 27:1–27:27. Software available at
http://www.csie.ntu.edu.tw/~cjlin/libsvm.
[9] CONTI, M., MANCINI, L. V., SPOLAOR, R., AND VERDE, N. V.
Can’t you hear me knocking: Identiﬁcation of user actions on
android apps via trafﬁc analysis. In Proceedings of the 5th ACM
Conference on Data and Application Security and Privacy (2015),
ACM, pp. 297–304.
[10] CONTI, M., MANCINI, L. V., SPOLAOR, R., AND VERDE, N. V.
Analyzing android encrypted network trafﬁc to identify user
actions. Information Forensics and Security, IEEE Transactions
on 11, 1 (2016), 114–125.
187
[11] CORTES, C., AND VAPNIK, V. Support-vector networks. Machine
Learning 20, 3 (1995), 273–297.
[12] DAI, S., TONGAONKAR, A., WANG, X., NUCCI, A., AND
SONG, D. Networkproﬁler: Towards automatic ﬁngerprinting of
android apps. In INFOCOM, 2013 Proceedings IEEE (2013),
IEEE, pp. 809–817.
[13] DAVI, L., DMITRIENKO, A., SADEGHI, A.-R., AND WINANDY,
M. Privilege escalation attacks on android. In Information
Security. Springer, 2010, pp. 346–360.
[14] DINGLEDINE, R., MATHEWSON, N., AND SYVERSON, P. Tor:
The second-generation onion router. Tech. rep., DTIC Document,
2004.
[15] DOUGHERTY, J., KOHAVI, R., SAHAMI, M., ET AL. Supervised
and unsupervised discretization of continuous features.
In
Machine learning: proceedings of the twelfth international
conference (1995), vol. 12, pp. 194–202.
[16] DUDOROV, D., STUPPLES, D., AND NEWBY, M. Probability
analysis of cyber attack paths against business and commercial
enterprise systems. In Proc. IEEE European Intelligence and
Security Informatics Conf. (EISIC) (2013), pp. 38–44.
[17] DYER, K. P., COULL, S. E., RISTENPART, T., AND SHRIMPTON,
T. Peek-a-boo, i still see you: Why efﬁcient trafﬁc analysis
countermeasures fail. In Security and Privacy (SP), 2012 IEEE
Symposium on (2012), IEEE, pp. 332–346.
[18] GU, X., YANG, M., AND LUO, J. A novel website ﬁngerprinting
attack against multi-tab browsing behavior. In Computer Sup-
ported Cooperative Work in Design (CSCWD), 2015 IEEE 19th
International Conference on (2015), IEEE, pp. 234–239.
[19] HAQUE, A., KHAN, L., AND BARON, M. SAND: Semi-
supervised adaptive novel class detection and classiﬁcation over
data stream. In Proc. 30th Conf. Artiﬁcial Intelligence (AAAI)
(2016), pp. 1652–1658.
[20] HAQUE, A., KHAN, L., BARON, M., THURAISINGHAM,
B., AND AGGARWAL, C. Efﬁcient handling of concept drift
and concept evolution over stream data. In 2016 IEEE 32nd
International Conference on Data Engineering (ICDE) (May
2016), pp. 481–492.
[21] HERRMANN, D., WENDOLSKY, R., AND FEDERRATH, H.
Website ﬁngerprinting: attacking popular privacy enhancing
technologies with the multinomial naïve-bayes classiﬁer. In
Proceedings of the 2009 ACM workshop on Cloud computing
security (2009), ACM, pp. 31–42.
[22] HITE, K. C., CICIORA, W. S., ALISON, T., BEAUREGARD,
R. G., ET AL. System and method for delivering targeted
advertisements to consumers, June 30 1998. US Patent 5,774,170.
[23] JUAREZ, M., AFROZ, S., ACAR, G., DIAZ, C., AND GREEN-
STADT, R. A critical evaluation of website ﬁngerprinting attacks.
In Proceedings of the 2014 ACM SIGSAC Conference on Com-
puter and Communications Security (2014), ACM, pp. 263–274.
[24] KIHL, M., ÖDLING, P., LAGERSTEDT, C., AND AURELIUS, A.
Trafﬁc analysis and characterization of internet user behavior. In
Ultra Modern Telecommunications and Control Systems and
Workshops (ICUMT), 2010 International Congress on (2010),
IEEE, pp. 224–231.
[26] MISKOVIC, S., LEE, G. M., LIAO, Y., AND BALDI, M. Appprint:
automatic ﬁngerprinting of mobile applications in network trafﬁc.
In Passive and Active Measurement (2015), Springer, pp. 57–69.
[27] PANCHENKO, A., LANZE, F., ZINNEN, A., HENZE, M.,
PENNEKAMP, J., WEHRLE, K., AND ENGEL, T. Website
ﬁngerprinting at internet scale. In Proceedings of the 23rd
Internet Society (ISOC) Network and Distributed System Security
Symposium (NDSS 2016) (2016). To appear.
[28] PANCHENKO, A., NIESSEN, L., ZINNEN, A., AND ENGEL, T.
Website ﬁngerprinting in onion routing based anonymization
networks. In Proceedings of the 10th annual ACM workshop on
Privacy in the electronic society (2011), ACM, pp. 103–114.
[29] PEDREGOSA, F., VAROQUAUX, G., GRAMFORT, A., MICHEL,
V., THIRION, B., GRISEL, O., BLONDEL, M., PRETTENHOFER,
P., WEISS, R., DUBOURG, V., ET AL. Scikit-learn: Machine
learning in python. The Journal of Machine Learning Research
12 (2011), 2825–2830.
[30] PLONKA, D. Flowscan: A network trafﬁc ﬂow reporting and
visualization tool. In LISA (2000), pp. 305–317.
[31] RAYMOND, J.-F. Trafﬁc analysis: Protocols, attacks, design
issues, and open problems. In Designing Privacy Enhancing
Technologies (2001), Springer, pp. 10–29.
[32] SOUNTHIRARAJ, D., SAHS, J., GREENWOOD, G., LIN, Z.,
AND KHAN, L. Smv-hunter: Large scale, automated detection of
ssl/tls man-in-the-middle vulnerabilities in android apps. In
Proceedings of the 19th Network and Distributed System Security
Symposium (2014).
[33] STÖBER, T., FRANK, M., SCHMITT, J., AND MARTINOVIC,
I. Who do you sync you are?: smartphone ﬁngerprinting via
application behaviour. In Proceedings of the sixth ACM conference
on Security and privacy in wireless and mobile networks (2013),
ACM, pp. 7–12.
[34] TAYLOR, V., SPOLAOR, R., CONTI, M., AND MARTINOVIC, I.
Appscanner: Automatic ﬁngerprinting of smartphone apps from
encrypted network trafﬁc. In 1st IEEE European Symposium on
Security and Privacy (Euro S&P 2016) (Mar 2016). To appear.
[35] VIDAS, T., VOTIPKA, D., AND CHRISTIN, N. All your droid are
belong to us: A survey of current android attacks. In WOOT
(2011), pp. 81–90.
[36] WANG, T., CAI, X., NITHYANAND, R., JOHNSON, R., AND
GOLDBERG, I. Effective attacks and provable defenses for
website ﬁngerprinting. In Proc. 23th USENIX Security Symposium
(USENIX) (2014).
[37] WANG, T., AND GOLDBERG, I. Improved website ﬁngerprinting
on tor. In Proceedings of the 12th ACM workshop on Workshop
on privacy in the electronic society (2013), ACM, pp. 201–212.
[38] WANG, T., AND GOLDBERG, I. On realistically attacking tor
with website ﬁngerprinting. Tech. rep., Technical Report 2015-08,
CACR., 2015.
[39] WEI, T., ZHANG, Y., XUE, H., ZHENG, M., REN, C., AND
SONG, D. Sidewinder targeted attack against android in the
golden age of ad libraries. Black Hat USA 2014 (2014).
[25] LIBERATORE, M., AND LEVINE, B. N. Inferring the source of
encrypted http connections. In Proceedings of the 13th ACM
conference on Computer and communications security (2006),
ACM, pp. 255–263.
[40] WRIGHT, C. V., COULL, S. E., AND MONROSE, F. Trafﬁc
morphing: An efﬁcient defense against statistical trafﬁc analysis.
In In Proceedings of the 16th Network and Distributed Security
Symposium (2009), IEEE, pp. 237–250.
188