Uptim e
Churn
E
E
E
U,E
E
E
E
Description
Replaced onion domains with impersonation site.
Replaced onion domains with impersonation site.
Replaced onion domains with impersonation site.
Replaced onion domains with impersonation site.
Redirected users to impersonated site.
Redirected users to impersonated site.
Redirected users to impersonated site.
Botnet
Mar 2014
default
— N
Oct 2010
trotsky
649
N
Unknown
Jan 2016
Nov 2015
cloudvps
11BX1371
Jul 2015 DenkoNet
Jul 2015
cloudvps
Dec 2014 Anonpoke
Dec 2014
FuslVZTOR
61
150
58
55
284
246
C,U
C,U
U
C,U
C,U
C,U
DoS
Dec 2014
LizardNSA
4,615
C,U
Research
May 2015
ﬁngerprints
168
F
Mar 2014
FDCservers
264
C,U
Feb 2013 AmazonEC2
1,424
F,C,U
Jun 2010
planetlab
595
C,U
Likely a Windows-powered botnet. The group fea-
tures wide geographical distribution, which is uncom-
mon for typical Tor relays.
The relays were likely part of a botnet. They appeared
gradually, and were all running Windows.
Hosted by Dutch hoster XL Internet Services.
All relays were in two /24 networks and a single relay
had the Exit ﬂag.
Hosted on Amazon AWS and only present in a single
consensus. No relay had the Exit ﬂag.
All relays only had the Running and Valid ﬂag. As
their name suggests, the relays were hosted by the
Dutch hoster “CloudVPS.”
The relays did not have the Exit ﬂag and were re-
moved from the network before they could get the
HSDir ﬂag.
The relays showed up only hours after the LizardNSA
incident.
A group publicly claimed to be responsible for the at-
tack [24]. All relays were hosted in the Google cloud
and The Tor Project removed them within hours.
All twelve IP addresses, located in the same /24,
changed their ﬁngerprint regularly, presumably in an
attempt to manipulate the distributed hash table.
Relays that were involved in an experimental onion
service deanonymization attack [8].
We observed 1,424 relay ﬁngerprints on 88 IP ad-
dresses. These Sybils were likely part of a research
project [4, § V].
According to a report from The Tor Project [20], a re-
searcher started these relays to learn more about scal-
ability effects.
Table 2: The most salient Sybil groups that sybilhunter and our exitmap modules discovered. We believe that groups
marked with the symbols ∗ and † were run by the same operator, respectively. Note that sybilhunter was unable to
detect six Sybil groups in the category “MitM.”
attackers that controlled the “rewrite” group but we have
no evidence to support that hypothesis.
Interestingly,
only our exitmap module was able to spot these Sybils.
The relays joined the network gradually over time and
had little in common in their conﬁguration, which is why
our heuristics failed. In fact, we cannot rule out that the
adversary was upstream of the exit relay, or gained con-
trol over these relays.
The “FDCservers” Sybils Attackers used these Sybils
to deanonymize onion service users, as discussed by
The Tor Project in a July 2014 blog post [8]. Sup-
USENIX Association  
25th USENIX Security Symposium  1177
9
every day and plot the result in Figure 8. Note that we
might overestimate the numbers as our ﬁlter could cap-
ture unrelated relays.
The above suggests that some of the “default” relays
are running without the owner’s knowledge. While the
relays do not ﬁt the pattern of Sefnit (a.k.a. Mevade) [26]
and Skynet [27]—two pieces of malware that use an
onion service as command and control server—we be-
lieve that the “default” relays constitute a botnet.
The “trotsky” Sybils Similar to the “default” group,
the “trotsky” relays appear to be part of a botnet. Most
of the relays’ IP addresses were located in Eastern Eu-
rope, in particular in Slovenia, Croatia, and Bosnia and
Herzegovina. The relays were all running on Windows,
in version 0.2.1.26, and listening on port 443. Most of
the relays were conﬁgured as exits, and The Tor Project
assigned some of them the BadExit ﬂag.
The ﬁrst “trotsky” members appeared in September
2010. Over time, there were two relay peaks, reaching
139 (September 23) and 219 (October 3) relays, as illus-
trated in Figure 8. After that, only 1–3 relays remained
in the consensus.
The “Amazon EC2” Sybils The relays all used
randomly-generated nicknames, consisting of sixteen or
seventeen letters and numbers; Tor in version 0.2.2.37;
GNU/Linux; and IP addresses in Amazon’s EC2 net-
block. Each of the 88 IP addresses changed its ﬁnger-
print 24 times, but not randomly: the ﬁngerprints were
chosen systematically, in a small range. For example, re-
lay 54.242.248.129 had ﬁngerprints with the preﬁxes 8D,
8E, 8F, and 90. The relays were online for 48 hours. Af-
ter 24 hours, most of the relays obtained the HSDir ﬂag.
This behavior appears to be a clear attempt to manipulate
Tor’s DHT.
We believe that this Sybil group was run by Biryukov,
Pustogarov, and Weinmann as part of their Security
and Privacy 2013 paper “Trawling for Tor Hidden Ser-
vices” [4]—one of the few Sybil groups that were likely
run by academic researchers.
The “Anonpoke” Sybils All relays shared the nick-
name “Anonpoke” and were online for four hours un-
til they were rejected. All relays were hosted by a VPS
provider in the U.S., Rackspace, with the curious excep-
tion of a single relay that was hosted in the UK, and run-
ning a different Tor version. The relays advertized the
default bandwidth of 1 GiB/s on port 9001 and 9030. All
relays were middle relays and running as directory mir-
ror. All Sybils were conﬁgured to be an onion service
directory, but did not manage to get the ﬂag in time.
Figure 8: The number of “default” and “trotsky” Sybil
members over time.
posedly, CMU/SEI-afﬁliated researchers were executing
a trafﬁc conﬁrmation attack by sending sequences of
RELAY_EARLY and RELAY cells as a signal down the cir-
cuit to the client, which the reference implementation
never does [8, 7]. The attacking relays were both onion
service directories and guards, allowing them to control
both ends of the circuit for some Tor clients that were
fetching onion service descriptors. Therefore, the re-
lays could tell for a fraction of Tor users what onion
service they were intending to visit. Most relays were
running FreeBSD, used Tor in version 0.2.4.18-rc, had
identical ﬂags, mostly identical bandwidth values, and
were located in 50.7.0.0/16 and 204.45.0.0/16. All of
these shared conﬁguration options made the relays easy
to identify.
The relays were added to the network in batches, pre-
sumably starting in October 2013. On January 30, 2014,
the attackers added 58 relays to the 63 existing ones, giv-
ing them control over 121 relays. On July 8, 2014, The
Tor Project blocked all 123 IP addresses that were run-
ning at the time.
The “default” Sybils This group, named after the
Sybils’ shared nickname “default,” has been around since
September 2011 and consists of Windows-powered re-
lays only. We extracted relays by ﬁltering consensuses
for the nickname “default,” onion routing port 443, and
directory port 9030. The group features high IP address
churn. For October 2015, we found “default” relays in
73 countries, with the top three countries being Ger-
many (50%), Russia (8%), and Austria (7%). The ma-
jority of these relays had little uptime and exhibited a
diurnal pattern, suggesting that they were powered off
regularly—as it often is the case for desktop computers
and laptops.
To get a better understanding of the number of “de-
fault” relays over time, we analyzed all consensuses, ex-
tracting the number of relays whose nickname was “de-
fault,” whose onion routing port was 443, and whose di-
rectory port was 9030. We did this for the ﬁrst consensus
1178  25th USENIX Security Symposium 
USENIX Association
10
0100200300TimeNumber of Sybil relaysJan 2008Jan 2010Jan 2012Jan 2014Jan 2016defaulttrotskyThe “PlanetLab” Sybils A set of relays that used a
variation of the strings “planet”, “plab”, “pl”, and “plan-
etlab” as their nickname. The relays’ exit policy allowed
ports 6660–6667, but they did not get the Exit ﬂag. The
Sybils were online for three days and then removed by
The Tor Project, as mentioned in a blog post [20]. The
blog post further says that the relays were run by a re-
searcher to learn more about “cloud computing and scal-
ing effects.”
The “LizardNSA” Sybils All relays were hosted in
the Google Cloud and only online for ten hours, until the
directory authorities started to reject them. The majority
of machines were middle relays (96%), but the attack-
ers also started some exit relays (4%). The Sybils were
set up to be onion service directories, but the relays were
taken ofﬂine before they could earn the HSDir ﬂag. If all
relays would have obtained the HSDir ﬂag, they would
have constituted almost 50% of all onion service directo-
ries; the median number of onion service directories on
December 26 was 3,551.
Shortly after the attack began, somebody claimed re-
sponsibility on the tor-talk mailing list [24]. Judging by
the supposed attacker’s demeanor, the attack was mere
mischief.
The “FuslVZTOR” Sybils All machines were mid-
dle relays and hosted in the netblock 212.38.181.0/24,
owned by a UK VPS provider. The directory authorities
started rejecting the relays ﬁve hours after they joined the
network. The relays advertized the default bandwidth of
1 GiB/s and used randomly determined ports. The Sybils
were active in parallel to the “LizardNSA” attack, but
there is no reason to believe that both incidents were re-
lated.
5.2 Alerts per method
Having investigated the different types of alerts our
methods raised, we now provide intuition on how many
of these alerts we would face in practice. To this end,
we ﬁrst determined conservative thresholds, chosen to
yield a manageable number of alerts per week. For net-
work churn, we set the threshold for αn for relays with
the Valid ﬂag to 0.017. For the ﬁngerprint method, we
raised an alert if a relay changed its ﬁngerprint at least ten
times per month, and for uptime visualizations we raised
an alert if at least ﬁve relays exhibited an identical up-
time sequence. We used a variety of analysis windows to
achieve representative results. For example, the Tor net-
work’s churn rate slowly reduced over the years, which
is why we only analyzed 2015 and 2016. Table 3 shows
the results. For comparison, the table also shows our ex-
itmap modules, which did not require any thresholds.
Figure 9: The churn distribution for seven relay ﬂags.
We removed values greater than the plot whiskers.
5.3 Churn rate analysis
We determined the churn rate between two subsequent
consensuses for all 72,061 consensuses that were pub-
lished between October 2007 and January 2016. Consid-