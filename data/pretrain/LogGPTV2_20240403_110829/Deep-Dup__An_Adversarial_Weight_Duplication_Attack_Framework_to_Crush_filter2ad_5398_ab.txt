resources on an FPGA chip, such as the PDS and the com-
munication channels with external memory or I/O. (4) We
assume that the adversary knows the type of transmitted data
(i.e., either DNN model or input data) on the communication
channel (e.g., I/O protocol IP) connecting the off-chip mem-
ory and on-chip data buffer. Adversarial FPGA tenants can
learn such information in different ways: i) Using the side-
channel leakage from the communication/data channels on
the FPGA, e.g., the cross-talk between FPGA long-wires [36].
Besides, recent works have reverse engineered DNN using
side-channel attacks to practically recover its information (i.e,
architecture, weights) [60, 61]. Additionally, it is practical to
recover the DNN model using instruction Ô¨Çow leakage [62].
ii) Practically, the victim FPGA tenant can be the provider of
Machine learning as a service (MLaaS) [40, 41], who offer
accelerated DNN computation on multi-tenant FPGA, and the
adversary can rent such service as a normal customer, then
he/she can learn some info of the model and query outputs.
More importantly, our black-box attack only requires to know
the transmitted data type (i.e. weight or input), instead of
USENIX Association
30th USENIX Security Symposium    1921
Tenant V (Victim)AcceleratorAcceleratorTenant V (Victim)I/O protocol IPPSOn-chip data bufferD4D2D2D1CPUExternal memoryI/O protocol IPDRAMControllerPEAttackDNN modelExternal I/OFPGA core power supplyFPGA clock resource power supplyExternal memory Clock resource VClock resource O (Others)External power supplyTenant A (Attacker)Malicious circuitsEnableClock resource ATenant 1Tenant NMulti-tenant FPGA‚Ä¶‚Ä¶‚Ä¶‚Ä¶CleanDNN modelD4D3D2D1actual weight values, which is recoverable using similar meth-
ods as in [36, 60, 61]. It is worth mentioning that, although
the current cloud-computing business model has not yet sup-
ported simultaneous resource-sharing, with the signiÔ¨Åcant
development of FPGA-based cloud computing, e.g., dynamic
workload support [59], FPGA virtulization [63], multi-tenant
FPGA is envisioned to be possible in the future [64].
Deep Learning (DL) Algorithm Threat Model. Regard-
ing the Deep Learning algorithm level threat model, in this
work, following many prior DL security works [18, 21, 26‚Äì
28, 56, 65, 66], two different DL algorithm threat models
are considered and deÔ¨Åned here: 1) DL white-box: attacker
needs to know model architectures, weight values, gradients,
several batches of test data, queried outputs. 2) DL black-
box: attacker only knows the queried outputs and a sam-
ple test dataset. Unlike the traditional DL white-box threat
model [18, 21, 27, 67], our DL white-box is even weaker with
no requirement of computing gradient during the attacking
process. Since different DL security works may have different
deÔ¨Ånitions of white/black-box, throughout this work, we will
stick to the deÔ¨Ånition here, which is commonly used in prior
works [27, 67, 68]. In this work, similar to many adversarial
input or weight attacks, we only target to attack a pre-trained
DNN inference model in FPGA, i.e., hijacking the DNN in-
ference behavior through the proposed Deep-Dup, not the
training process, which typically requires extra access to the
training supply chain [24, 69].
In our threat model deÔ¨Åned in Fig. 1, the adversary will
leverage our proposed AWD based fault injection attack on the
weight packages identiÔ¨Åed by our proposed P-DES searching
algorithm, when transmitting the DNN model from off-chip
memory to on-chip buffer/processing engine (PE), resulting
in a weight perturbed DNN model in the PEs. After the attack,
the DNN function is hijacked by an adversary with malicious
behaviors, such as accuracy degradation or wrong classiÔ¨Åca-
tion of a targeted output class.
4 Attack Objective Formulation
The proposed Deep-Dup attack is designed to perform both
un-targeted and targeted attacks, deÔ¨Åned as below.
Un-targeted Attack. The objective of this attack is to
degrade the overall network inference accuracy (i.e., miss-
classifying whole test dataset), thus maximizing the inference
loss of DNN. As a consequence, the objective can be formu-
lated as an optimization problem:
max Lu = max
{ ÀÜW }
EXL( f (xxx, {W });ttt)
(1)
where xxx and ttt are the vectorized input and target output of a
given test batch and L(¬∑, ¬∑) calculates the loss between DNN
output and target. The objective is to degrade the network‚Äôs
overall accuracy as low as possible by perturbing weights of
the clean DNN model from W to ÀÜW .
Targeted Attack. Different from the un-targeted attack,
the objective of targeted attack in this work is to misclassify
(a) DNN model transmission w/o at-
tack.
(b) DNN model transmission
under AWD attack.
Figure 2: Illustrated timing diagrams of DNN model trans-
mission w/o or under AWD attack. (a) Each DNN weight
package (Di) is transmitted and received in a separate clock
cycle. (b) Voltage glitch incurs more propagation delay to
the transmission of D2, which also shortens the next package
D3. As a result, the data package D2 is sampled twice by the
receiver clock, injecting faults to the received data package.
a speciÔ¨Åc (target) class of inputs (ts). This attack objective is
formulated in Eq. 2, which can be achieved by maximizing
the loss of those target class:
max Lt = max
{ ÀÜW }
EXL( f (xxxs , {W });ttt)
(2)
where xxxs is a sample input batch belongs to the target class ts.
5 Proposed Deep-Dup Framework
Deep-Dup mainly consists of two proposed modules: 1) ad-
versarial weight duplication (AWD) attack, a novel FPGA
hardware fault injection scheme leveraging power-plundering
circuit to intentionally duplicate certain DNN weight pack-
ages during data transmission between off-chip memory and
on-chip buffer; 2) progressive differential evolution search
(P-DES), a generic searching algorithm to identify most vul-
nerable DNN weight package index and guide AWD fault
injection for given malicious objective. In the end of this
section, we will present Deep-Dup as an end-to-end software-
hardware integrated attack framework.
5.1 AWD attack in multi-tenant FPGA
5.1.1 Preliminaries of DNN model implementations
The schematic of an FPGA-based DNN acceleration is il-
lustrated in Fig. 1, consisting of a processing system (PS),
processing engine (PE), and external (off-chip) memory. Prac-
tically, DNN computation is usually accomplished in a layer-
by-layer style, i.e., input data like image and DNN model
parameters of different layers are usually loaded and pro-
cessed separately [70‚Äì72]. Fig. 1 shows the Ô¨Çow of FPGA I/O
protocol IP for typical DNN model transmission, in which
the on-chip data buffer sends a data transaction request to PS
for loading data from external memory. Then, the processing
engine (PE) will implement computation based on the DNN
model in the on-chip data buffer (e.g., BRAM).
1922    30th USENIX Security Symposium
USENIX Association
On-chip data bufferùë°Transmitterùëâùëü0VCCINTClockReceiverD1D2D3D4D5D6D7D1D2D3D4D6D5D7D1D2D3D4D5D6D7Propagation delayOn-chip data bufferùë°ùëâùëü0D1D2D3D4D5D6D7D1D2D2‚ÄôD4D6D5D7D1D2D4D5D6D7Propagation delayD3A data transmission Ô¨Çow is shown in Fig. 2a, in each clock
cycle, a data package (Di) is transmitted from transmitter (e.g.
external memory) to receiver. Taking the advanced eXtensible
interface4 (AXI4) as an example [73], the receiver Ô¨Årst sends
a data request with an external memory address, and then it
will be notiÔ¨Åed to read the data when it is ready. The size
of each transmitted data package depends on the channel
bandwidth. In DNN model transmission, the normal (w/o
attacks) transmission Ô¨Çow with each Di as a DNN weight
package is illustrated in Fig. 2a, with FPGA core voltage
(VCCINT) being stable at the recommended supply voltage
(Vr), N data packages (e.g., weights) are transmitted in N
clock cycles (D1-D7 in Fig. 2a).
5.1.2 AWD based fault injection into DNN model
The power supply of modern FPGA chips is regulated based
on their voltages, different components will be activated fol-
lowing the order of their nominal voltage, e.g., from low to
high [74‚Äì76]. Most FPGAs utilize a hierarchical power dis-
tribution system (PDS) 1, which consists of some power reg-
ulators providing different supply voltages [75, 76, 78]. A
critical component of PDS is the capacitor used as the ‚Äúpower
bank‚Äù for the operational reliability of FPGA. For example,
when an FPGA chip‚Äôs power supply is suddenly overloaded
(i.e., by a transient higher power demand), these capacitors
are discharged to compensate for the extra power that regu-
lators cannot immediately provide. The capacitors of FPGA
PDS are usually sized accordingly to Ô¨Åt the practical need.
Formally, the default output capacitance (Cout ) of an FPGA
is usually sized to compensate for the current difference for
at least two clock cycles with a tolerable voltage drop [78].
As calculated in Eq. 3, where ‚àÜIout and ‚àÜVout represent the
changes of output current and voltage, respectively, and fsw
denotes the regulator switching frequency.
Cout =
2 √ó ‚àÜIout
fsw √ó ‚àÜVout
(3)
As one of FPGA‚Äôs most critical parameters, the clock sig-
nals provide standard and global timing references for all
on-chip operations. In practice, to generate different timing
signals, i.e., with different frequencies or phases, FPGAs are
equipped with several clock management components, such
as the phase-lock-loop. The on-chip clock signals are usu-
ally generated by various clock management components,
and their reliability is heavily dependent on the robustness
of these components. To enhance clock integrity, these clock
components are powered by separate supply voltage resources
(Fig. 1) from the computing elements like PE. For example,
the clock components of Xilinx FPGAs are powered by the
auxiliary voltage VCCAUX rather than the FPGA core supply
voltage VCCINT [79]. Such a separate power supply mecha-
nism ensures sufÔ¨Åcient energy for the operation of these clock
components, thus enhancing reliability.
1PDS is the ofÔ¨Åcial terminology of Xilinx FPGAs, while Intel FPGAs use
power distribution networks [77]. For uniformity, we use PDS in this paper.
(a) A power-plundering
cell based on
ring-
oscillator (RO).
(b) A cloud-sanctioned power-
plundering cell based on RO with
a Latch (LRO).
Figure 3: Two power-plundering circuit examples on FPGA
.
The DNN execution in FPGA is signiÔ¨Åcantly relying on
the integrity of its loaded model. Our proposed AWD attack
is motivated by two facts: 1) As aforementioned, the relia-
bility and correctness of FPGA applications are ensured by
the power delivery mechanism; 2) Based on the power regula-
tion mechanism, there exists a maximum power capacity that
FPGA PDS can provide to PEs. Thus, if the FPGA PDS is
overloaded, FPGA applications might encounter faults caused
by the timing violation between the clock signal and computa-
tion/data. Recent works have demonstrated that the activation
of many power-plundering circuits (e.g., ROs), can cause tran-
sient voltage drop on the FPGA [35, 38, 80], thus incurring
fault injection.
Considering the importance of frequent and real-time DNN
model transmission from/to FPGA, the basic idea for AWD
attack is that a malicious FPGA tenant can introduce a tim-
ing violation to the DNN model transmission from off-chip
memory to the on-chip data buffer. As illustrated in Fig. 2a,
a stable FPGA core voltage (VCCINT) (i.e., with trivial or no
Ô¨Çuctuations) will not cause timing violations to data transmis-
sion. However, an unstable VCCINT will incur serious timing
violations. For example, a sudden voltage drop will make the
digital circuit execution slower than usual, causing a longer
propagation delay to the data transmission. As shown in Fig.
2b, the adversary‚Äôs aggressive power plundering creates a
voltage drop/glitch that incurs slowing down the data trans-
mission channel. As a result, the corresponding data package
(e.g., D2) may be sampled twice by the receiver clock, causing
a fault injection into the following data package. We envision
that maliciously designed fault-injected weight data packages
will greatly impact the DNN computation, inducing either
signiÔ¨Åcant performance loss, or other malicious behaviors.
5.1.3 Power-plundering circuits
A power-plundering circuit can be achieved with any circuit
scheme with high dynamic power consumption, e.g., ring-
oscillator (RO) circuits. However, it should be noted that
although RO circuit provides high power-plundering poten-
tial, it can be possibly detected by the FPGA development
tools [81]. To make power-plundering more stealthy, i.e.,
cloud-sanctioned, some recent works employ common FPGA
applications, e.g., the shift registers of an AES circuit [16]
USENIX Association
30th USENIX Security Symposium    1923
LUT5LUT5I4I3I2I1I0LUT6O6I51    0EnableLUT5LUT5I4I3I2I1I0LUT6O6I51    0EnableLDCEDQGECLRGand XOR tree circuit [82]. Since this work focuses on the
security of the DNN model in multi-tenant FPGA, we adopt
two power-plundering schemes, RO and Latch RO (LRO), for
proof-of-concept. Fig. 3a shows the RO circuit instantiated
with an FPGA look-up table (LUT). Different from RO, the
LRO circuit shown in Fig. 3b has a latch in the loop, which
is a cloud-sanctioned design scheme that can bypass the de-
sign rule checking for combinational loop in FPGA design
tools. In detail, these two power-plundering schemes are both
instantiated as a NAND gate controlled by an Enable sig-
nal. An adversarial FPGA tenant can employ a large number
of such cells controlled by the same Enable signal, which
can be activated to overload the FPGA PDS and introduce
transient voltage drop shown in Fig. 2b, thus implementing
fault injection attack. Note that the proposed attack in this
paper can be achieved with any other cloud-sanctioned power
plundering design, such as the AES-based scheme in [16].
5.1.4 AWD attack triggering system
As mentioned in the hardware threat model (Sec.3), our pro-
posed attack only requires the adversary to know the type of
data (i.e., weight or not) being transmitted on the FPGA and
the starting/ending points, which can be achieved with side-
channel (e.g., power) analysis. To demonstrate this, we build
the AWD triggering system with two major components: 1
Time-to-Digital Converter (TDC) based sensor and 2 Trig-
gering BRAM, as shown in Fig. 4. We prototype a TDC circuit
in FPGA to capture the on-chip voltage Ô¨Çuctuation and mea-
sure the digital output of the TDC sensor during the execution
of DNN (YOLOv2 in this example). We observe a strong
correlation between the sensor outputs and DNN execution,
i.e., weight transmission or functional layers‚Äô execution. For
example, as shown in Fig. 4, the TDC sensor outputs corre-
sponding to weight transmission periods are relatively stable
(i.e., much less voltage Ô¨Çuctuation), since it consumes much
less power than the functional layers, like Max pool or Convo-
lution. Due to the page limit, we omit the TDC sensor design
details and refer interested readers to the related work [83]
for details.
Based on the TDC sensor output, we proÔ¨Åle a triggering
strategy Ô¨Åle to control the AWD attack activation, which con-
sists of three parameters: triggering delay, triggering period,
and target index. The strategy Ô¨Åle is stored in the triggering
BRAM ( 2 ), composed of ‚Äò1s‚Äô and ‚Äò0s, which are used to
activate or disable the power-plundering circuit, respectively.
With the triggering BRAM being read at a certain clock fre-
quency, this system can control the triggering of fault injection.
For example, a series of consecutive ‚Äò0s‚Äô disable the power
plundering circuit for a certain time period, while a series of
consecutive ‚Äò1s‚Äô deÔ¨Ånes the length of the attack period. By
selecting the locations of ‚Äò1s‚Äô, we can choose to inject faults
on speciÔ¨Åc DNN weights of speciÔ¨Åc attack indexes obtained
from our P-DES searching algorithm (Sec.5.2).
Figure 4: AWD triggering system. A TDC sensor is used to
capture voltage Ô¨Çuctuation during the YOLOv2 execution, in
which the weight transmission period can be clearly observed.