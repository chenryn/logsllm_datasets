BcVer
JavaCC
JavaTar
ProGuard
SableCC
0
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
1
 100
 80
 60
 40
 20
 0
BCEL
BcVer
JavaCC
JavaTar
ProGuard
SableCC
0
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
1
(a)
(b)
(c)
Figure 6: Reﬀ with diﬀerent (a) peﬀ (b) ppre (c) pnode .
second instantiation allows us to measure the eﬀectiveness
of the revised optimization procedure (Sect. 5) when the dis-
tributed optimization protocol is employed. Note that the
second instantiation never underperforms the ﬁrst because
the method interfaces used were conservative.
We generated ten instances of EC[0.5, 0.5, 0.5] for each
program in Fig. 4, and then measured the optimization ef-
fectiveness ratios Rpre and Reﬀ for each instantiation of the
optimization procedure. The measurements for the ten in-
stances were averaged and shown in Fig. 7. The bars labeled
pre (empty) and eﬀ (empty) show the average Rpre and
Reﬀ for the optimization procedure with empty method in-
terfaces, while pre (inferred) and eﬀ (inferred) corre-
spond to average Rpre and Reﬀ for the optimization proce-
dure with inferred method interfaces.
Three observations can be made from Fig. 7. (1) Both
precondition and eﬀect elimination deliver signiﬁcant reduc-
tion in performance overhead, even when method interfaces
are not present. (2) Precondition elimination has a much
higher eﬀectiveness than eﬀect elimination. (3) The added
eﬀectiveness of method interfaces is noticeable but not dra-
matic.
7.2 Experiment 2: Varying Policy Character-
istics
To characterize optimization eﬀectiveness under various
policy structures, we subject the revised optimization pro-
cedure (with inferred method interfaces) to diﬀerent exper-
imental conﬁgurations. Speciﬁcally, we varied each of pnode ,
peﬀ and ppre from 0 to 1, by increments of 0.1, while keeping
the other two parameters ﬁxed at 0.5. Again, ten instances
of each experimental conﬁguration were generated, and the
average eﬀectiveness ratios Rpre and Reﬀ for each conﬁgu-
ration are depicted respectively in Fig. 5 and 6.
From Fig. 6 (a) and (b), we notice that Reﬀ increases with
an increasing eﬀect density (peﬀ ), but decreases with an in-
creasing precondition density (ppre ). We argue that this can
be readily explained by data ﬂow equation (7). A higher peﬀ
increases the size of kill LIV[·], creating larger dead sets, and
thus promotes eﬀect elimination. A higher ppre , however, in-
creases the size of gen LIV[·], creating smaller dead sets, and
thus discourages eﬀect elimination. Similarly, from Fig. 5
(a) and (b), we notice that Rpre increases with either an
increasing eﬀect density (peﬀ ) or an increasing precondition
density (ppre ). This can be explained readily by data ﬂow
equation (3), in which larger eﬀect and precondition sets
produce larger guaranteed sets, which in turn promote pre-
condition elimination. Notice also that implicit assertion is
overridden by explicit assertion, thus explaining why Fig. 5
(b) shows a less dramatic increase than Fig. 5 (a). The above
observations imply that:
If two diﬀerent encodings of the same security
policy incur similar overhead, then we should pre-
fer the encoding with more eﬀects and less pre-
conditions, for such a policy is more amenable to
optimization.
Fig. 5 (c) and 6 (c) show that higher operator density (pnode )
produces higher optimization eﬀectiveness.
IRM beneﬁts more from precondition and eﬀect
elimination when more program points are inter-
preted as access events.
8. CONCLUDING REMARKS
We proposed a constrained policy representation for facil-
itating IRM optimization. Our policy representation is ex-
pressive enough to represent simple integrity policies, Gener-
alized Chinese Wall Policies, and Hierarchical One-Out-Of-k
Policies. Our core optimization procedure is safe, unobtru-
sive and eﬀective. The optimization procedure has been
extended to accommodate a distributed optimization pro-
tocol, in which an untrusted code producer may formulate
method interfaces to boost the optimization eﬀectiveness of
a distrusting code consumer. A prototype of the procedure
has been implemented, and demonstrated to exhibit positive
performance characteristics.
We are exploring alternative optimization directives that
could lead to more eﬀective optimization than our current
design of method interfaces. While our current policy repre-
sentation and distributed optimization protocol are designed
for supporting control ﬂow-based policies, we are also ex-
ploring how they can be extended to enforce data ﬂow con-
straints [7].
9. ACKNOWLEDGMENTS
This work is supported in part by a NSERC Discovery
Grant and a NSERC Strategic Network Grant.
10. REFERENCES
[1] M. Abadi and C. Fournet. Access control based on
execution history. In Proceedings of the 10th Annual
Network and Distributed System Security Symposium
(NDSS’03), San Diego, California, USA, Feb. 2003.
[2] I. Aktug, M. Dam, and D. Gurov. Provably correct
runtime monitoring. In Proceedings of the 15th
International Symposium on Formal Methods
(FM’08), Turku, Finland, May 2008.
8th National Computer Security Conference, pages
18–27, Oct. 1985.
[10] D. F. C. Brewer and M. J. Nash. The Chinese Wall
security policy. In Proceedings of the IEEE Symposium
on Research in Security and Privacy (S&P’89), pages
206–214, Oakland, California, USA, May 1989.
[11] D. D. Clark and D. R. Wilson. A comparison of
commercial and military computer security policies. In
Proceedings of the 1987 IEEE Symposium on Security
and Privacy (S&P’87), pages 184–194, May 1987.
[12] T. Colcombet and P. Fradet. Enforcing trace
properties by program transformation. In Proceedings
of the 27th ACM Symposium on Principles of
Programming Languages (POPL’00), pages 54–66,
Boston, MA, USA, Jan. 2000.
[13] B. A. Davey and H. A. Priestley. Introduction to
Lattices and Order. Cambridge University Press, 2nd
edition, 2002.
[14] G. Edjlali, A. Acharya, and V. Chaudhary.
History-based access control for mobile code. In
Proceedings of the 5th ACM Conference on Computer
and Communications Security (CCS’98), San
Francisco, California, USA, 1998.
[15] D. Evans and A. Twyman. Flexible policy-directed
code safety. In Proceedings of the 1999 IEEE
Symposium on Security and Privacy (S&P’99), pages
32–45, Oakland, California, USA, May 1999.
[16] R. Fikes and N. Nilsson. STRIPS: A new approach to
the application of theorem proving to problem solving.
Artiﬁcial Intelligence, 2:189–208, 1971.
[17] P. W. L. Fong. Access control by tracking shallow
execution history. In Proceedings of the 2004 IEEE
Symposium on Security and Privacy (S&P’04), pages
43–55, Berkeley, California, USA, May 2004.
[3] I. Aktug and K. Naliuka. ConSpec – a formal language
[18] L. Gong and R. Schemers. Implementing protection
for policy speciﬁcation. In Proceedings of the First
International Workshop on Run Time Enforcement
for Mobile and Distributed Systems (REM’07), volume
197 of Electronic Notes in Theoretical Computer
Science, 2007.
[4] P. Avgustinov, J. Tibble, and O. de Moor. Making
trace monitors feasible. In Proceedings of the 22nd
ACM Conference on Object Oriented Programming,
Systems, Languages and Applications (OOPSLA’07),
Montr´eal, Qu´ebec, Canada, Oct. 2007.
[5] L. Bauer, J. Ligatti, and D. Walker. More enforceable
security policies. In Proceedings of the Workshop on
Foundations of Computer Security (FCS’02),
Copenhagen, Denmark, July 2002.
[6] F. Besson, T. Jensen, D. L. M´etayer, and T. Thorn.
Model checking security properties of control ﬂow
graphs. Journal of Computer Security, 9(3):217–250,
2001.
[7] S. Bhatkar, A. Chaturvedi, and R. Sekar. Dataﬂow
anomaly detection. In Proceedings of the 2006 IEEE
Symposium on Security and Privacy (S&P’06),
Berkeley, CA, USA, May 2006.
[8] K. Biba. Integrity considerations for secure computer
systems. Technical Report 76–372, U. S. Air Force
Electronic Systems Division, 1977.
[9] W. E. Boebert and R. Y. Kain. A practical alternative
to hierarchical integrity policies. In Proceedings of the
domains in the Java Development Kit 1.2. In
Proceedings of the 1998 ISOC Symposium on Network
and Distributed System Security (NDSS’98), San
Diego, Carlifornia, USA, Mar. 1998.
[19] K. W. Hamlen, G. Morrisett, and F. B. Schneider.
Computability classes for enforcement mechanisms.
ACM Transactions on Programming Languages and
Systems, 28(1):175–205, Jan. 2006.
[20] T. Jensen, D. L. M´etayer, and T. Thorn. Veriﬁcation
of control ﬂow based security properties. In
Proceedings of the 1999 IEEE Symposium on Security
and Privacy (S&P’99), pages 89–103, Oakland,
California, USA, May 1999.
[21] C. Kiczales, J. Lamping, A. Mendhekar, C. Maeda,
C. V. Lopes, J.-M. Loingtier, and J. Irwin.
Aspect-oriented programming. In Proceedings of the
11th European Conference on Object-Oriented
Programming (ECOOP’97), volume 1241 of LNCS,
Finland, June 1997.
[22] J. Ligatti, L. Bauer, and D. Walker. Edit automata:
Enforcement mechanisms for run-time security
policies. International Journal of Information
Security, 4(1–2):2–16, Feb. 2005.
[23] T. Y. Lin. Chinese Wall security policy: An aggressive
model. In Proceedings of the Fifth Annual Computer
Security Applications Conference (ACSAC’89), pages
282–289, Tucson, Arizona, USA, Dec. 1989.
[24] G. C. Necula. Proof-carrying code. In Proceedings of
the 24th ACM Symposium on Principles of
Programming Languages (POPL’97), pages 106–119,
Paris, France, Jan. 1997.
[25] F. Nielson, H. R. Nielson, and C. Hankin. Principles
of Program Analysis. Springer, 2004.
[39] J. Wang, Y. Takata, and H. Seki. HBAC: A model for
history-based access control and its model checking. In
Proceedings of the 11th European Symposium on
Research in Computer Security (ESORICS’06),
volume 4189 of LNCS, pages 263–278, Hamburg,
Germany, Sept. 2006. Springer.
[26] B. C. Pierce. Types and Programming Languages. MIT
[40] I. Welch and R. J. Stroud. Using reﬂection as a
Press, 2002.
[27] E. Rose and K. H. Rose. Lightweight bytecode
veriﬁcation. In The OOPSLA’98 Workshop on Formal
Underpinnings of Java, Vancouver, BC, Canada, Nov.
1998.
[28] J. H. Saltzer and M. D. Schroeder. The protection of
information in computer systems. In Proceedings of
the IEEE, volume 63, pages 1278–1308, 1975.
[29] F. B. Schneider. Enforceable security policies. ACM
Transactions on Information and System Security,
3(1):30–50, Feb. 2000.
[30] F. B. Schneider, G. Morrisett, and R. Harper. A
language-based approach to security. In Informatics:
10 Years Back, 10 Years Ahead, volume 2000 of
LNCS, pages 86–101, 2000.
[31] R. Sekar, V. N. Venkatakrishnan, S. Basu, S. Bhatkar,
and D. C. DuVarney. Model-carrying code: a practical
approach for safe execution of untrusted applications.
In Proceedings of the 19th ACM Symposium on
Operating Systems Principles (SOSP’03), Bolton
Landing, NY, USA, Oct. 2003.
[32] A. P. Sistla, V. N. Venkatakrishnan, M. Zhou, and
H. Branske. CMV: Automatic veriﬁcation of complete
mediation for Java Virtual Machine. In Proceedings of
the 2008 ACM Symposium on Information, Computer
and Communications Security (ASIACCS’08), pages
100–111, Tokyo, Japan, Mar. 2008.
[33] C. Talhi, N. Tawbi, and M. Debbabi. Execution
monitoring enforcement for limited-memory systems.
In Proceedings of the 2006 Conference on Privacy,
Security and Trust (PST’06), Markham, Ontario,
Canada, Oct. 2006.
[34] C. Talhi, N. Tawbi, and M. Debbabi. Execution
monitoring enforcement under memory-limitation
constraints. Information and Computation,
206(2–4):158–184, Feb. 2008.
[35] ´Ulfar Erlingsson and F. B. Schneider. SASI
enforcement of security policies: A retrospective. In
Proceedings of the 1999 New Security Paradigm
Workshop (NSPW’99), pages 87–95, Caledon Hills,
Ontario, Canada, Sept. 1999.
[36] ´Ulfar Erlingsson and F. B. Schneider. IRM
enforcement of Java stack inspection. In Proceedings of
the 2000 IEEE Symposium on Security and Privacy
(S&P’00), pages 246–255, Berkeley, California, USA,
May 2000.
[37] R. Vall´ee-Rai, E. Gagnon, L. J. Hendren, P. Lam,
P. Pominville, and V. Sundaresan. Optimizing Java
bytecode using the Soot framework: Is it feasible? In
Proceedings of the 9th International Conference on
Compiler Construction (CC’00), pages 18–34, 2000.
[38] D. S. Wallach, A. W. Appel, and E. W. Felten.
SAFKASI: A security mechanism for language-based
systems. ACM Transactions on Software Engineering
and Methodology, 9(4):341–378, Oct. 2000.
mechanism for enforcing security policies on compiled
code. Journal of Computer Security, 10(4):399–432,
2002.
[41] F. Yan and P. W. L. Fong. Eﬃcient IRM enforcement
of history-based access control policy. Technical
Report CS-2008-03, Department of Computer Science,
University of Regina, Regina, Saskatchewan, Canada,
Nov. 2008.
APPENDIX
A. PROOF OF THEOREM 2
Proof. Consider a Hierarchical One-Out-Of-k Policy
{Ci}1≤i≤k. Without loss of generality, assume that every
a ∈ Σ belongs to at least one Ci. Deﬁne the home class
H(a) of access a ∈ Σ to be T{ C ∈ {Ci}1≤i≤k | a ∈ C }, that
is, the smallest class containing a. (The existence of such
a class is guaranteed by condition (1).) A pair of accesses,
say a and b, is said to be consistent iﬀ they belong to
the same application class: i.e., ∃i . {a, b} ⊆ Ci. Otherwise,
they are in conﬂict. Notice that a and b are consistent iﬀ
H(a) ⊆ H(b) ∨ H(b) ⊆ H(a). (The “if” direction is immedi-
ate. The “only if” direction follows from {a, b} ⊆ Ci by an
application of condition (2).)
To obtain the required CPCE representation of {Ci}1≤i≤k,
construct Π = {pC | C ∈ {Ci}1≤i≤k}, q0 = {¬pC | C ∈
{Ci}1≤i≤k}, and δa = hpre a, eﬀ ai, where:
pre a = {¬pC | H(a) 6⊆ C ∧ C 6⊆ H(a)}
eﬀ a = {pH(a)}
It is easy to see that, with the CPCE operators above, at
run time, the set H of accesses that have occurred so far
are pair-wise consistent. What we want is that there is a Ci
such that H ⊆ Ci. We prove this by induction.
The base cases for |H| ≤ 2 can be handled trivially. Sup-
pose, for some k > 2, all event set H with |H| = k is such
that H ⊆ Ci for some i whenever H contains pairwise-
consistent events. Consider a set H ′ = H ∪ {a} where
|H| = k, a 6∈ H, and events in H ′ are pairwise consistent.
By way of contradiction, assume the following holds:
There is no Ci such that H ′ ⊆ Ci.
(25)
Because H contains pairwise-consistent events, the induc-
tion hypothesis implies that there is a class C⋆ such that
H ⊆ C⋆. Also, a is consistent with every member of H.
Thus, for each b ∈ H, let Cb be a class containing both a
and b. By (1), C◦ = Tb∈H Cb is a class. By assumption
(25), there is an event b⋆ ∈ H such that b⋆ 6∈ C◦. By (1),
C• = C⋆ ∩ Cb⋆ is a class. Now, a ∈ C◦, but a 6∈ C•; b⋆ ∈ C•,
but b⋆ 6∈ C◦. So C◦ and C• are distinct, incomparable subsets
of Cb⋆ , contradicting (2).