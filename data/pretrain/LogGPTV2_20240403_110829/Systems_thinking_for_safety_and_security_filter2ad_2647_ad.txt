Stopped 
Too 
Soon or 
Applied 
Too 
Long 
N/A 
Close 
MSIV 
Close 
MSIV not 
provided 
when there 
is a rupture 
in steam 
tube, leak 
in main 
feedwater, 
or leak in 
main steam 
line [V- 2, 
V-1, V-3] 
Close 
MSIV 
provided 
when 
there is no 
rupture or 
leak [V-4] 
Close MSIV 
provided too 
early (while 
steam pressure 
is high): Steam 
pressure may 
rise, trigger 
relief valve, 
abrupt steam 
expansion [V-
2, V-3] 
An important difference between STPA-Sec analysis and that of 
standard safety and security analysis is that the former identifies 
problematic  situations  beyond 
those  resulting  from  simple 
confidentiality,  integrity,  and  availability  violations.  STPA-Sec 
also highlights situations where the system behavior emerges from 
multiple interactions among the system components, all of which 
are behaving “correctly.” 
Developing Security Requirements and Constraints 
The previous steps in the analysis have proceeded in a top-down 
deliberate  process.    The  first  step  provided  the  engineering 
information needed to examine and understand the functioning of 
the system.  This information provides important context used in 
Step 2 to identify a list of unsafe/unsecure control actions.   
The unsafe/unsecure control actions can be used to develop high-
level  safety  and  security  requirements  and  constraints.  As  an 
example, a constraint on system behavior can be generated that a 
Close  MSIV  command  must  never  be  provided  when  there  is  no 
rupture or leak.  
Identifying Causal Scenarios  
The  final  step  in  the  analysis  is  the  one  that  bears  the  most 
resemblance  to  traditional  security  analyses.  This  step  involves 
analyzing  the  existing  physical  and  logical  infrastructure  to 
determine  how 
the  safety  and  security  requirements  and 
constraints identified in the previous step might be violated, that 
is, scenarios that can lead to losses.   
Figure  3  shows  potential  problems  in  a  control  loop  that  can 
violate constraints and lead to a hazardous or vulnerable state. The 
analysis  is  performed  by  using  these  “clues”  to  generate  viable 
scenarios. 
The scenarios, in turn, can be used by system designers to create 
protection  against  the  scenarios  occurring  or,  if  not  possible,  to 
limit  damage  from  them.  New  types  of  causes  may  be  used  to 
assist in identifying security-related scenarios. 
Traditional safety and security techniques, such as fault trees and 
attack 
identifying  causal 
scenarios. The major difference is that STPA identifies a large set 
of scenarios, in particular, those not involving component failures 
or compromise but arising from interactions among components. 
STPA-Sec also approaches scenario construction in a much more 
structured  manner  than  simply  assembling  experts  and  having 
them  brainstorm  scenarios  that  could  go  wrong  from  scratch. 
After establishing the necessary appreciation for the system under 
evaluation,  STPA-Sec’s  top-down,  systems  thinking  process 
guides  analysts  through  not  only  determination  of  the  potential 
logical and physical component failures capable of producing the 
generated scenarios, but also the interaction failures (e.g. feedback 
delays,  conflicting  control  actions),  and  the  combination  of 
component  and  interaction  failures  capable  of  producing  the 
generated  scenarios.    Equipped  with  this  deeper  insight  into 
technical  and  non-technical  aspects  of  the  system,  security 
analysts  are  then  better  prepared  to  select  and  apply  the  most 
appropriate protection tactics. 
In  applying  STPA-Sec  Step  4  to  the  nuclear  plant  example,  the  
goal  of  the  step  is  to  identify  scenarios  violating  the  constraint 
requiring  that  “close  MSIV”  not  be  issued  when  there  is  no 
rupture or leak present.  The HLCS model shows that the operator 
issues  the  close  MSIV  control  action  to  the  automated  digital 
control system based on feedback on the valve status (ruptured or 
not ruptured).  If a rupture exists, the “close MSIV” control action 
trees,  share  STPA-Sec’s  goal  of 
6
Figure 3. Control Loop Disruptions Leading to Hazardous / Vulnerable States 
should  be  given.    If  no  rupture  is  actually  present,  then  the 
previous  steps  of  the  analysis  identify  the  fact  that  issuing  the 
“close  MSIV”  control  action  introduces  a  vulnerability  that  can 
lead to a loss.   
For  the  nuclear  power  plant  example,  one  possible  violation 
scenario  involves  the  human  operator  receiving  the  wrong 
information  about  the  rupture  status  of  the  system,  that  is,  a 
scenario  that  causes  the  operator  to  believe  the  pipe  has  been 
ruptured  when  it  has  not  or  vice  versa.    Because  the  operator 
depends  on  the  system  feedback  that  flows  from  the  physical 
cooling  system  to  make  the  proper  decision,  any  of  the  control 
flaws  in  Figure  3  between  the  controlled  process  and  the 
controller could potentially cause the operator to believe a rupture 
exists when it does not and issue the close MSIV control action.  
Depending  on  the  design  of  the  specific  hardware  and  software 
used in the plant, a very unsophisticated cyber attack might prove 
plausible.  The attack need not necessarily change the operator’s 
display or inject false data.  It is possible that simply preventing 
the sensor from transmitting information to the DCS (generating a 
missing  feedback  problem)  through  a  Denial-of-Service  Attack 
might be sufficient to create the scenario if the DCS software was 
written  to  issue  the  rupture  indication  to  the  operator  as  a 
precaution in the case of a lost feedback signal.   
Under  most  circumstances,  this  logic  (reflected  in  the  DCS 
process  model)  could  be  prudent,  especially  if  the  programmers 
thought that absence of a rupture status signal would only occur in 
situations  where  significant  physical  damage  had  already  taken 
place.    This  assumption  would  necessitate  closing  the  MSIV  to 
isolate  the  main  steam  generator  from  the  rest  of  the  system. 
Clearly,  the  security  analysts  must  assess  the  viability  of  the 
scenario to determine if deeper analysis or even reengineering is 
warranted. The probability of the feedback between the sensor and 
DCS  being  disrupted  is  not  the  question  or  focus.  STPA-Sec 
reveals the fact that if the missing feedback problem arises, it will 
place  the  system  in  a  hazardous/vulnerable  state.    This  state 
occurs  despite  the  fact  that  all  components;  DCS,  actuators, 
sensors,  MSIV,  cooling  system,  and  operator  are  all  functioning 
normally.  In this case, system analysts and operations experts will 
need  to  work  together  to  apply  their  skill  and  judgment  to 
determine which scenarios require even deeper technical analysis.  
Unlike  other  approaches,  security  analysts  using  STPA-Sec  are 
not forced to depend on their creativity to generate the full list of 
scenarios  from  scratch.  Rather,  STPA-Sec  helps  illuminate  loss 
scenarios in ever-increasing detail all the while allowing analysts 
to  maintain  their  perspective  on  the  larger  system.  In  informal 
evaluations  of  STPA-Sec  by  security  analysts  and  operations 
7
personnel, participants were surprised that using it helped them to 
consider threat scenarios that they had not thought of previously. 
A more scientific evaluation of the STPA-Sec is currently being 
performed. 
STPA-Sec does not provide answers about what specific counter 
measures should be taken.  Identifying protection mechanisms is 
and remains the realm of the security specialists.  What STPA-Sec 
does  provide  is  a  potentially  useful  tool  for  identifying  those 
scenarios  that  should  be  the  focus  of  cyber  security  efforts  to 
secure  specific  systems. 
  Additionally,  STPA-Sec  provides 
traceability between the scenarios and the losses. 
5.   SUMMARY AND CONCLUSIONS 
This  paper  has  described  how  the  tactical-level  cyber  security 
problem can be elevated from simply guarding the network to the 
higher-level  problem  of  assuring  the  overall  function  of  the 
enterprise.  A  new  paradigm  employing  systems  theory  that  has 
recently been introduced into safety is shown to apply to security 
as well as to safety.  
In  some  ways  this  reframing  will  require  redefining  and 
expanding how security specialists think about their jobs.  Perhaps 
one  of  the  most  important  questions  to  ask  about  the  current 
threat-based  tactics  model  is  whether  or  not  organizations  will 
devote resources to addressing system vulnerabilities that may not 
appear to be likely to be threatened.  For example, STPA-Sec has 
shown how the particular set of conditions in the example could 
lead  to  a  loss.    However,  if  the  scenario  was  presented  just  in 
terms  of  threat  activity  and  absent  the  top-down  traceability 
STPA-Sec  provides,  how  likely  are  senior  leaders  to  expend 
resources  to  address  the  vulnerability?    Perhaps  rather  than 
framing the decision in terms of likelihoods that cannot be known, 
security specialists would be better off presenting decision makers 
with the scenarios that if acted upon will lead to a loss.   
There will always be a need for good tactics.  If current trends are 
any indication, the need for educated and skilled security analysts  
and  engineers  will  only  grow.    Tactical  models  will  continue  to 
play  an  important  role  in  security,  yet  strategy  models  must 
complement  them.    STPA-Sec  will  not  replace  good  security 
practices,  but  it  may  improve  them  by  providing  a  more  clear 
focus  for  those  designing  and  defending  our  software-intensive 
systems.  The  scope  of  the  paper  is  limited  in  that  it  focuses  on 
losses  resulting  from  violations  of  integrity  and  availability  but 
not  confidentiality  violations.  We  believe  these  can  be  handled 
equally well within this framework. Another feature of STPA-Sec, 
which  was  not  covered,  is  its  ability  to  assist  analysts  in 
examining how security constraints might degrade over time. See 
Leveson and Laracy for more on this topic [7] .  
6. REFERENCES 
[1]  National Institute of Standards and Technology (NIST), 
Special Publication 800-30 Revision 1 Guide for Conducting 
Risk Assessments. U.S. Department of Commerce, September 
2012 
[2]  Berg, G. G., Freeman, M. S. and Schneider, K. N. Analyzing 
the TJ Maxx Data Security Fiasco: Lessons for Auditors. 
CPA Journal, 78, 8 2008, 34-37. 
[3]  Checkland, P. Systems Thinking, Systems Practice. J. Wiley, 
Chichester Sussex ; New York, 1981 
[4]  Leveson, N. Engineering a Safer World : Systems Thinking 
Applied to Safety. MIT Press, Cambridge, Mass., 2011. 
[5]  Thomas, J. P., IV Extending and Automating a Systems-
theoretic Hazard Analysis for Requirements Generation and 
Analysis. Massachusetts Institute of Technology, 
Massachusetts Institute of Technology, 2013. 
[6]  Weiss, J. Protecting Industrial Control Systems from 
Electronic Threats. Momentum Press; New York, 2010 
[7]  Laracy, J. and Leveson, N. “Applying STAMP to Critical 
Infrastructure Protection” 2007 IEEE Conference on 
Technologies for Homeland Security. IEEE, 2007. 
8