# Incident Response Playbook Template
## **Incident Type**
GuardDuty Finding: PrivilegeEscalation-Kubernetes:PrivilegedContainer
### **Introduction**
This playbook is provided as a template to customers using AWS products and who are building their incident response capability.  You should customize this template to suit your particular needs, risks, available tools and work processes.
Security and Compliance is a shared responsibility between you and AWS. AWS is responsible for “Security of the Cloud”, while you are responsible for “Security in the Cloud”. For more information on the shared responsibility model, [please review our documentation](https://aws.amazon.com/compliance/shared-responsibility-model/).
You are responsible for making your own independent assessment of the information in this document. This document: (a) is for informational purposes only, (b) references current AWS product offerings and practices, which are subject to change without notice, and (c) does not create any commitments or assurances from AWS and its affiliates, suppliers or licensors. This document is provided “as is” without warranties, representations, or conditions of any kind, whether express or implied. The responsibilities and liabilities of AWS to its customers are controlled by AWS agreements, and this document is not part of, nor does it modify, any agreement between AWS and its customers.
## **Summary**
### **This Playbook**
This playbook outlines response steps for incidents involving deployment of a privileged container. These steps are based on the [NIST Computer Security Incident Handling Guide](https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-61r2.pdf) (Special Publication 800-61 Revision 2) that can be used to:
* Gather evidence
* Contain and then eradicate the incident
* Recover from the incident
* Conduct post-incident activities, including post-mortem and feedback processes
Interested readers may also refer to the [AWS Security Incident Response Guide]( https://docs.aws.amazon.com/whitepapers/latest/aws-security-incident-response-guide/welcome.html) which contains additional resources.
Once you have customized this playbook to meet your needs, it is important that you test the playbook (e.g., Game Days) and any automation (functional tests), update as necessary to achieve the desired results, and then publish to your knowledge management system and train all responders.
Note that some of the incident response steps noted in each scenario may incur costs in your AWS account(s) for services used in either preparing for, or responding to incidents. Customizing these scenarios and testing them will help you to determine if additional costs will be incurred. You can use [AWS Cost Explorer](https://aws.amazon.com/aws-cost-management/aws-cost-explorer/) and look at costs incurred over a particular time frame (such as when running Game Days) to establish what the possible impact might be.
In reviewing this playbook, you will find steps that involve processes that you may not have in place today. Proactively preparing for incidents means you need the right resource configurations, tools and services in place that allow you to respond to an incident.
The next section will provide a summary of this incident type, and then cover the five steps (parts 1 - 5) for handling privileged containers.
### **This Incident Type**
An Amazon GuardDuty finding represents a potential security issue detected within your network. GuardDuty generates a finding whenever it detects unexpected and potentially malicious activity in your AWS environment. All GuardDuty finding references in this playbook will be related to the GuardDuty finding JSON that can be seen in the GuardDuty console, downloaded from the GuardDuty or Security Hub console, or exported to S3.
**[PrivilegeEscalation:Kubernetes/PrivilegedContainer](https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_finding-types-kubernetes.html#privilegeescalation-kubernetes-privilegedcontainer)**
**A privileged container with root level access was launched on your Kubernetes cluster.**
This finding informs you that a privileged container was launched on your Kubernetes cluster using an image has never before been used to launch privileged containers in your cluster. A privileged container has root level access to the host. Adversaries can launch privileged containers as a privilege escalation tactic to gain access to and then compromise the host.
 Details on what resources are involved with this activity can be found in the [finding details](https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_findings-summary.html#findings-resource-affected).
## **Incident Response Process**
---
### **Part 1**: Acquire, Preserve, Document Evidence
#### For Any Incident
1. You become aware of potential indicators of compromise (IoCs). These could come in various forms, but the original source is a GuardDuty finding:
    * An internal ticketing system (the sources of the ticket are varied and could include any of the means below)
    * From an alert in one of your monitoring systems either inside or external to AWS (that are ingesting GuardDuty Findings, in AWS, this could include AWS Security Hub)
    * Alarms or observations that resources have been created or deleted in your account that cannot be accounted for in your CMDB, exist in regions that you do not operate infrastructure in, or themselves have generated alerts ([Amazon Detective]( https://aws.amazon.com/detective/getting-started/) is a useful tool for understanding these relationships)
1. Confirm a ticket/case has been raised for the incident. If not, manually raise one
1. Determine and begin to document any end-user impact/experience of the issue. Findings should be documented in the ticket/case related to the incident
1. Open an incident war room using your standard communication tools, and page in the relevant stakeholders
1. In the case of automatically created tickets/cases, verify the finding in GuardDuty (what caused the ticket to be created?) 
#### For This Incident Type
1. Identify the specific EKS cluster impacted. In GuardDuty, this will be in the Resource.EksClusterDetails.Name section of the finding. 
1. Identify Pod, Node, and User information to be used in **Part 2**.
    - Pod information can be found in the Resource.KubernetesWorkloadDetails section of the GuardDuty finding.
    - Node information can be found after determing the pod name. Once you have the pod name you can run the command provided below to determine the node name.
       - kubectl get pods  --namespace  -o=jsonpath='{.spec.nodeName}{"\n"}'
    - User information can be found in the Resource.KubernetesDetails.KubernetesUserDetails section of the GuardDuty Finding.
1. Identify the origination information from which the Kubernetes APIs were called. In GuardDuty, Look at the Resource.Service.Action section of the finding
    - Verify that the IP address is valid for your enterprise users
    - Verify that the Location and/or ASN/Organization is known and valid for this request
1. If the principal that launched the privileged container is associated with a person in the organization, contact them to verify the launched privilege container is valid and was intended.
    - If the person states that they did launch the privilege container and the configuration change was intended, verify that there is a valid Change Management (CM) request or other authorization:
        - Once verified, move on to Part 5 to review the incident, and propose improvements that would stop or automatically archive findings for valid configuration changes within your organization.
        - If authorization for the change cannot be verified, communicate to stakeholders your intent to remediate or rollback the change and proceed to Part 2.
    - If the person states they did not launch the privileged container, proceed to **Part 2**.
### **Part 2**: Contain the Incident
If you determine that the activity is unauthorized, or decide it is prudent to assume so, the first priority is to prevent further compromise without impact to production workloads.
1. Verify that disabling the Kubernetes user or isolating this pod will not result in a service outage.
1. If required, retain the user account for further forensic analysis by removing permissions from the Kubernetes User resource responsible for the activity using the appropriate steps below.
1. Built-in Kubernetes admin – The default user assigned by Amazon EKS to the IAM identity that created the cluster. This user type is identified by the user name kubernetes-admin. 
    - To revoke access of a built-in Kubernetes admin:
        - Identify the userType from the Access Key details section.
            - If the userType is Role and the role belongs to an EC2 instance role:
                - Identify that instance then follow the instructions in Remediating a compromised EC2 instance (https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_remediate.html#compromised-ec2).
            - If the userType is User, or is a Role that was assumed by a user:
                1. Rotate the access key of that user with the steps listed below:
                    To rotate access keys for an IAM user without interrupting your applications (console)
                    1. While the first access key is still active, create a second access key.
                        - Sign in to the AWS Management Console and open the IAM console at (https://console.aws.amazon.com/iam/).
                        - In the navigation pane, choose Users.
                        - Choose the name of the intended user, and then choose the Security credentials tab.
                        - Choose Create access key and then choose Download .csv file to save the access key ID and secret access key to a .csv file on your computer. Store the file in a secure location. You will not have access to the secret access key again after this closes. After you have downloaded the .csv file, choose Close. The new access key is active by default. At this point, the user has two active access keys.
                    2. Update all applications and tools to use the new access key.
                    3. Determine whether the first access key is still in use by reviewing the Last used column for the oldest access key. One approach is to wait several days and then check the old access key for any use before proceeding.
                    4. Even if the Last used column value indicates that the old key has never been used, we recommend that you do not immediately delete the first access key. Instead, choose Make inactive to deactivate the first access key.
                    5. Use only the new access key to confirm that your applications are working. Any applications and tools that still use the original access key will stop working at this point because they no longer have access to AWS resources. If you find such an application or tool, you can choose Make active to reenable the first access key. Then return to Step 3 and update this application to use the new key.
                    6. After you wait some period of time to ensure that all applications and tools have been updated, you can delete the first access key:
                        - Sign in to the AWS Management Console and open the IAM console at (https://console.aws.amazon.com/iam/).
                        - In the navigation pane, choose Users.
                        - Choose the name of the intended user, and then choose the Security credentials tab.
                        - Locate the access key to delete and choose its X button at the far right of the row. Enter the access key ID to confirm the deletion and then choose Delete.
                2. Rotate any secrets that user had access to. Depending on where you stored your secrets will dictate what is the best process for rotation. If you are storing your secrets in the native secrets management capabilities of EKS use the kubernetes documentation to rotate your secrets (https://kubernetes.io/docs/concepts/configuration/secret/). If you are using an external secrets store follow the product specific directions for secrets rotation, for example if you are using AWS Secrets Manager you can follow this documentation to rotate secrets (https://docs.aws.amazon.com/secretsmanager/latest/userguide/rotating-secrets.html).
                3.  Review the information in My AWS account may be compromised for further details (https://aws.amazon.com//premiumsupport/knowledge-center/potential-account-compromise/).
1. To revoke access of an OIDC authenticated user, which is typically a user has an email address as a user name follow the steps below:
    - To check if your cluster uses OIDC use the following AWS CLI command: "aws eks list-identity-provider-configs --cluster-name **your cluster name**"
    - Rotate the credentials of that user in the OIDC provider.
    - Rotate any secrets that user had access to. Depending on where you stored your secrets will dictate what is the best process for rotation. If you are storing your secrets in the native secrets management capabilities of EKS use the kubernetes documentation to rotate your secrets (https://kubernetes.io/docs/concepts/configuration/secret/). If you are using an external secrets store follow the product specific directions for secrets rotation, for example if you are using AWS Secrets Manager you can follow this documentation to rotate secrets (https://docs.aws.amazon.com/secretsmanager/latest/userguide/rotating-secrets.html).
1. To revoke access of an AWS ConfigMap user:
    - Use the following command to open the ConfigMap.
    ```
    kubectl edit configmaps aws-auth --namespace kube-system
    ```
1. Identify the role or user entry under the mapRoles or mapUsers section with the same user name as the one reported in the Kubernetes user details section of your GuardDuty finding. See the following example, where the admin user has been identified in a finding.
```
apiVersion: v1
data:
  mapRoles: |
    - rolearn: arn:aws:iam::444455556666:role/eksctl-my-cluster-nodegroup-standard-wo-NodeInstanceRole-1WP3NUE3O6UCF
      user name: system:node:EC2_PrivateDNSName
      groups:
        - system:bootstrappers
        - system:nodes
  mapUsers: |
    - userarn: arn:aws:iam::123456789012:user/admin
      username: admin
      groups:
        - system:masters
    - userarn: arn:aws:iam::111122223333:user/ops-user
      username: ops-user
      groups:
        - system:masters
```
1. Remove that user from the ConfigMap. See the following example where the admin user has been removed.
```
apiVersion: v1
data:
  mapRoles: |
    - rolearn: arn:aws:iam::111122223333:role/eksctl-my-cluster-nodegroup-standard-wo-NodeInstanceRole-1WP3NUE3O6UCF
      username: system:node:{{EC2PrivateDNSName}}
      groups:
        - system:bootstrappers
        - system:nodes
  mapUsers: |
    - userarn: arn:aws:iam::111122223333:user/ops-user
      username: ops-user
      groups:
        - system:masters
```
1. If the finding does not have a "accessKeyDetails" section, the user is a Kubernetes service account. The service account provides an identity for pods and can be identified by a user name with the following format: system:serviceaccount:namespace:service_account_name. To revoke access to a service account:
    - Rotate the service account credentials to do this you will need to rotate the IAM role credentials that were assigned to the service account with the steps below.
        1. While the first access key is still active, create a second access key.
            - Sign in to the AWS Management Console and open the IAM console at (https://console.aws.amazon.com/iam/).
            - In the navigation pane, choose Users.