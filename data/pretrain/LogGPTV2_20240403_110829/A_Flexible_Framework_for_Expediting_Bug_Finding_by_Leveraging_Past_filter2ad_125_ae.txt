### Improved Text

A larger ratio in the violin plots indicates that our approach identifies crashes more rapidly. The statistical significance, determined through a pairwise two-tailed test, is detailed in Tables 9-11 in Appendix A.2.

#### Fuzzing
The field of fuzzing has experienced explosive growth [3, 4, 6, 27, 41–43, 53, 60], driven in part by the expanding software security market. Many approaches [4, 43] aim to explore low-frequency paths to uncover bugs hidden in less-traversed code. For example, Vuzzer [43] uses control and data-flow features to prioritize deep and infrequently explored code paths. It performs taint analysis to infer data types at specific input offsets and uses this information to mutate inputs. Similarly, CollAFL [16] prioritizes input selection based on untouched branches (to increase coverage) and memory access operations (to detect memory corruptions). Angora [7] enhances branch coverage by solving path constraints using context-sensitive branch counts and byte-level taint tracking. To differentiate executions of the same branch in different contexts, Angora appends context to branch IDs, allowing for more thorough path exploration. By tracking which input bytes influence each path constraint, Angora mutates only these bytes rather than the entire input.

Li et al. [25] employed a static approach to extract basic block information from known vulnerable programs, including the number of call instructions, operand types, and string types. These attributes can be seen as characterizing program behavior, though not at the architectural level. Based on these attributes, a deep learning model assigns scores to basic blocks traversed by the program, which helps infer the fitness of an input for mutation during fuzzing. Our approach similarly infers control flow and data flow behavior using performance counter events but with minimal overhead.

Concurrently, Österlund et al. [39] proposed a sanitizer-based method to direct fuzzing towards triggering sanitizer checks, thereby finding bugs faster. Their approach prioritizes paths by steering the program towards locations likely to contain bugs. Unlike our method, their approach relies on sanitizer checks, which may miss certain bug types, such as logical errors. Additionally, we implement a feedback mechanism to actively guide fuzzing and switch between multiple strategies at runtime.

Several studies [44, 53, 57] have examined the effectiveness of different scheduling algorithms for seed selection. Rebert et al. [44] formalized the concept of ex post facto optimality in seed selection and provided evidence-driven techniques to evaluate the quality of a seed selection strategy compared to an optimal solution. Unlike our work, these proposals focus on measuring the optimal case for bugs found with a particular subset of seeds or identifying a "good" set of seeds reusable across applications. Overall, these works show that the choice of seed scheduling algorithm significantly impacts the success of fuzzing campaigns.

#### Experimental Results
The figures below illustrate the ratio of time-to-crash for various configurations. The results demonstrate that our approach, OmniFuzz, consistently finds bugs faster than the base fuzzer it augments (e.g., AFL, MOpt, Fairfuzz).

**Figure: Ratio of Time-to-Crash**
- **Base-vs-1-a**: P0-P7, 0-60
- **Base-vs-2-a**: P0-P7, 0-50
- **Base-vs-2-b**: P0-P7, 0-30
- **Base-vs-3-a**: P0-P7, 0-40
- **Base-vs-3-b**: P0-P7, 0-50

#### Conclusion
We highlight inefficiencies in contemporary coverage-guided fuzzers, primarily due to their equal prioritization of all program paths. To address these inefficiencies, we propose OmniFuzz, a framework that incorporates on-the-fly crash deduplication as a feedback mechanism to redirect the fuzzer when no unique crashes are found for some time. A unique feature of OmniFuzz is its use of performance counter data to derive a coverage metric for guiding input selection. This capability enables the development of multiple strategies to guide the fuzzer towards finding similar or different bugs from those discovered previously. These improvements can be integrated into most modern fuzzers, as they are not tied to a specific architecture. Our experimental results show that OmniFuzz can find more unique bugs and do so significantly faster than the base fuzzer it augments (e.g., AFL, MOpt, Fairfuzz). Overall, our experiments demonstrate that our vulnerability-aware selection of coverage metrics, combined with on-the-fly deduplication, offers an efficient and comprehensive solution for enhancing the performance of a base fuzzer.

#### Acknowledgments
We thank Prof. Yousra Aafer and the anonymous reviewers for their valuable suggestions. We also thank Murray Anderegg for his assistance in deploying the infrastructure used in this study. This work was supported in part by the Department of Defense (DoD) under award FA8750-17-C-0016 and the National Science Foundation (NSF) under award CNS-1749895. Any opinions, findings, and conclusions expressed herein are those of the authors and do not necessarily reflect the views of the DoD or NSF.

#### References
[References listed here, formatted as per the original text]

---

This version of the text is more structured, clear, and professional, with improved coherence and readability.