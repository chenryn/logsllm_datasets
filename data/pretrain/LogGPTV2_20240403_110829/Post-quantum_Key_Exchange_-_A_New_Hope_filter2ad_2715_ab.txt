gent than post-quantum authentication. Authenticity will
most likely be achievable in the foreseeable future us-
ing proven pre-quantum signatures and attacks on the
signature will not compromise previous communication.
Additionally, by not designing or instantiating a lattice-
based authenticated key-exchange protocol (see [33,85])
we reduce the complexity of the key-exchange protocol
and simplify the choice of parameters. We actually see it
as an advantage to decouple key exchange and authen-
tication as it allows a protocol designer to choose the
optimal algorithm for both tasks (e.g., an ideal-lattice-
based key exchange and a hash-based signature like [16]
for authentication). Moreover, this way the design, se-
curity level, and parameters of the key-exchange scheme
are not constrained by requirements introduced by the
authentication part.
Parameter choices. A high-level description of our pro-
posal is given in Protocol 2 and as in [20, 77] all poly-
nomials except for r ∈ R4 are deﬁned in the ring Rq =
Zq[X]/(X n + 1) with n = 1024 and q = 12289. We de-
cided to keep the dimension n = 1024 as in [20] to be
able to achieve appropriate long-term security. As poly-
nomial arithmetic is fast and also scales better (doubling
n roughly doubles the time required for a polynomial
multiplication), our choice of n appears to be acceptable
from a performance point of view. We chose the modulus
q = 12289 as it is the smallest prime for which it holds
that q ≡ 1 mod 2n so that the number-theoretic trans-
form (NTT) can be realized efﬁciently and that we can
transfer polynomials in NTT encoding (see Section 7).
2For the TLS use-case and for compatibility with BNCS [20] the
key exchange is initiated by the server. However, in different scenarios
the roles of the server and client can be exchanged.
USENIX Association  
25th USENIX Security Symposium  329
3
As the security level grows with the noise-to-modulus
ratio, it makes sense to choose the modulus as small as
possible, improving compactness and efﬁciency together
with security. The choice is also appealing as the prime is
already used by some implementations of Ring-LWE en-
cryption [29, 63, 81] and BLISS signatures [31, 78]; thus
sharing of some code (or hardware modules) between our
proposal and an implementation of BLISS would be pos-
sible.
Noise distribution and reconciliation. Notably, we also
change the distribution of the LWE secret and error and
replace discrete Gaussians by the centered binomial dis-
tribution ψk of parameter k = 16 (see Section 4). The
reason is that it turned out to be challenging to imple-
ment a discrete Gaussian sampler efﬁciently and pro-
tected against timing attacks (see [20] and Section 5).
On the other hand, sampling from the centered binomial
distribution is easy and does not require high-precision
computations or large tables as one may sample from ψk
by computing ∑k
i=0 bi − b(cid:30)i, where the bi,b(cid:30)i ∈ {0,1} are
uniform independent bits. The distribution ψk is cen-
tered (its mean is 0), has variance k/2 and for k = 16
this gives a standard deviation of ς =(cid:31)16/2. Con-
trary to [20, 77] we hash the output of the reconciliation
mechanism, which makes a distinguishing attack irrele-
vant and allows us to argue security for the modiﬁed error
distribution.
Moreover, we generalize Peikert’s reconciliation
mechanism using an analog error-correction approach
(see Section 5). The design rationale is that we only want
to transmit a 256-bit key but have n = 1024 coefﬁcients
to encode data into. Thus we encode one key bit into
four coefﬁcients; by doing so we achieve increased error
resilience which in turn allows us to use larger noise for
better security.
Short-term public parameters. NEWHOPE does not
rely on a globally chosen public parameter a as the ef-
ﬁciency increase in doing so is not worth the measures
that have to be taken to allow trusted generation of this
value and the defense against backdoors [13]. Moreover,
this approach avoids the rather uncomfortable situation
that all connections rely on a single instance of a lattice
problem (see Section 3) in the ﬂavor of the “Logjam”
DLP attack [1].
No key caching. For ephemeral Difﬁe-Hellman key-
exchange in TLS it is common for servers to cache a key
pair for a short time to increase performance. For ex-
ample, according to [24], Microsoft’s SChannel library
caches ephemeral keys for 2 hours. We remark that for
the lattice-based key exchange described in [77], for the
key exchange described in [20], and also for the key ex-
change described in this paper, such short-term caching
would be disastrous for security. Indeed, it is crucial that
both parties use fresh secrets for each instantiation (thus
the performance of the noise sampling is crucial). As
short-term key caching typically happens on higher lay-
ers of TLS libraries than the key-exchange implemen-
tation itself, we stress that particular care needs to be
taken to eliminate such caching when switching from
ephemeral (elliptic-curve) Difﬁe-Hellman key exchange
to post-quantum lattice-based key exchange. This issue
is discussed in more detail in [32].
One could enable key caching with a transformation
from the CPA-secure key exchange to a CCA-secure key
exchange as outlined by Peikert in [77, Section 5]. Note
that such a transform would furthermore require changes
to the noise distribution to obtain a failure probability
that is negligible in the cryptographic sense.
3 Preventing backdoors and all-for-the-
price-of-one attacks
One serious concern about the original design [20] is the
presence of the polynomial a as a ﬁxed system parameter.
As described in Protocol 2, our proposal includes pseu-
dorandom generation of this parameter for every key ex-
change. In the following we discuss the reasons for this
decision.
Backdoor. In the worst scenario, the ﬁxed parameter a
could be backdoored. For example, inspired by NTRU
trapdoors [50, 83], a dishonest authority may choose
mildly small f,g such that f = g = 1 mod p for some
prime p ≥ 4 · 16 + 1 and set a = gf−1 mod q. Then,
given (a,b = as + e), the attacker can compute bf =
afs +fe = gs +fe mod q, and, because g,s,f,e are small
enough, compute gs +fe in Z. From this he can compute
t = s + e mod p and, because the coefﬁcients of s and
e are smaller than 16, their sums are in [−2· 16,2· 16]:
knowing them modulo p ≥ 4· 16 + 1 is knowing them in
Z. It now only remains to compute (b− t)· (a− 1)−1 =
(as− s)· (a− 1)−1 = s mod q to recover the secret s.
One countermeasure against such backdoors is the
“nothing-up-my-sleeve” process, which would, for ex-
ample, choose a as the output of a hash function on a
common universal string like the digits of π. Yet, even
this process may be partially abused [13], and when not
strictly required it seems preferable to avoid it.
All-for-the-price-of-one attacks. Even if this common
parameter has been honestly generated, it is still rather
uncomfortable to have the security of all connections
rely on a single instance of a lattice problem. The sce-
nario is an entity that discovers an unforeseen cryptan-
alytic algorithm, making the required lattice reduction
still very costly, but say, not impossible in a year of
computation, given its outstanding computational power.
By ﬁnding once a good enough basis of the lattice Λ =
330  25th USENIX Security Symposium 
USENIX Association
4
Parameters: q = 12289 < 214, n = 1024
Error distribution: ψ16
Alice (server)
seed $← {0,1}256
a←Parse(SHAKE-128(seed))
s,e $← ψn
b←as + e
16
v(cid:28)←us
ν←Rec(v(cid:28),r)
µ←SHA3-256(ν)
(u,r)
←−−
(b,seed)
−−−−→ a←Parse(SHAKE-128(seed))
Bob (client)
s(cid:28),e(cid:28),e(cid:28)(cid:28)
$← ψn
16
u←as(cid:28) + e(cid:28)
v←bs(cid:28) + e(cid:28)(cid:28)
r $← HelpRec(v)
ν←Rec(v,r)
µ←SHA3-256(ν)
Protocol 2: Our Scheme. For the deﬁnitions of HelpRec and Rec see Section 5. For the deﬁnition of encodings and
the deﬁnition of Parse see Section 7.
{(a,1)x + (q,0)y|x,y ∈ R}, this entity could then com-
promise all communications, using for example Babai’s
decoding algorithm [7].
This idea of massive precomputation that is only de-
pendent on a ﬁxed parameter a and then afterwards can
be used to break all key exchanges is similar in ﬂa-
vor to the 512-bit “Logjam” DLP attack [1]. This at-
tack was only possible in the required time limit because
most TLS implementations use ﬁxed primes for Difﬁe-
Hellman. One of the recommended mitigations by the
authors of [1] is to avoid ﬁxed primes.
Against all authority. Fortunately, all those pitfalls can
be avoided by having the communicating parties gen-
erate a fresh a at each instance of the protocol (as we
propose).
If in practice it turns out to be too expen-
sive to generate a for every connection, it is also possi-
ble to cache a on the server side3 for, say a few hours
without signiﬁcantly weakening the protection against
all-for-the-price-of-one attacks. Additionally, the perfor-
mance impact of generating a is reduced by sampling a
uniformly directly in NTT format (recalling that the NTT
is a one-to-one map), and by transferring only a short
256-bit seed for a (see Section 7).
A subtle question is to choose an appropriate prim-
itive to generate a “random-looking” polynomial a out
of a short seed. For a security reduction,
it seems
to the authors that there is no way around the (non-
programmable) random oracle model (ROM). It is ar-
gued in [34] that such a requirement is in practice an
overkill, and that any pseudorandom generator (PRG)
should also work. And while it is an interesting question
how such a reasonable pseudo-random generator would
interact with our lattice assumption, the cryptographic
3But recall that the secrets s,e,s(cid:28),s(cid:28),e(cid:28)(cid:28) have to be sampled fresh for
every connection.
5
notion of a PRG is not helpful to argue security. Indeed,
it is an easy exercise4 to build (under the NTRU assump-
tion) a “backdoored” PRG that is, formally, a legitimate
PRG, but that makes our scheme insecure.
Instead, we prefer to base ourselves on a standard
cryptographic hash-function, which is the typical choice
of an “instantiation” of the ROM. As a suitable op-
tion we see Keccak [19], which has recently been stan-
dardized as SHA3 in FIPS-202 [72], and which offers
extendable-output functions (XOF) named SHAKE. This
avoids costly external iteration of a regular hash function
and directly ﬁts our needs.
We use SHAKE-128 for the generation of a, which
offers 128-bits of (post-quantum) security against colli-
sions and preimage attacks. With only a small perfor-
mance penalty we could have also chosen SHAKE-256,
but we do not see any reason for such a choice, in partic-
ular because neither collisions nor preimages lead to an
attack against the proposed scheme.
4 Choice of the error distribution
On non-Gaussian errors. In works like [20, 29, 81], a
signiﬁcant algorithmic effort is devoted to sample from a
discrete Gaussian distribution to a rather high precision.
In the following we argue that such effort is not neces-
sary and motivate our choice of a centered binomial ψk
as error distribution.
Indeed, we recall
the original worst-case to
average-case reductions for LWE [80] and Ring-
that
4Consider a secure PRG p, and parse its output p(seed) as two
small polynomial (f,g): an NTRU secret-key. Deﬁne p(cid:28)(seed) = gf−1
mod q: under the decisional NTRU assumption, p(cid:28) is still a secure PRG.
Yet revealing the seed does reveal (f,g) and provides a backdoor as de-
tailed above.
USENIX Association  
25th USENIX Security Symposium  331
LWE [67] state hardness for continuous Gaussian dis-
tributions (and therefore also trivially apply to rounded
Gaussian, which differ from discrete Gaussians). This
also extends to discrete Gaussians [21] but such proofs
are not necessarily intended for direct implementations.
We recall that the use of discrete Gaussians (or other dis-
tributions with very high-precision sampling) is only cru-
cial for signatures [65] and lattice trapdoors [39], to pro-
vide zero-knowledgeness.
The following Theorem states that choosing ψk as er-
ror distribution in Protocol 2 does not signiﬁcantly de-
crease security compared to a rounded Gaussian distri-
bution with the same standard deviation σ =(cid:31)16/2.
Theorem 4.1 Let ξ be the rounded Gaussian distribu-
tion of parameter σ = √8, that is, the distribution of
(cid:30)√8 · x(cid:28) where x follows the standard normal distribu-
tion. Let P be the idealized version of Protocol 2, where
the distribution ψ16 is replaced by ξ . If an (unbounded)
algorithm, given as input the transcript of an instance
of Protocol 2 succeeds in recovering the pre-hash key ν
with probability p, then it would also succeed against P
with probability at least
q ≥ p9/8/26.
Proof See Appendix B in the full version of this paper.
As explained in Section 6, our choice of parameters
leaves a comfortable margin to the targeted 128 bits
of post-quantum security, which accommodates for the
slight loss in security indicated by Theorem 4.1. Even
more important from a practical point of view is that no
known attack makes use of the difference in error distri-
bution; what matters for attacks are entropy and standard
deviation.
Simple implementation. We remark that sampling from
the centered binomial distribution ψ16 is rather trivial
in hardware and software, given the availability of a
uniform binary source. Additionally, the implementa-