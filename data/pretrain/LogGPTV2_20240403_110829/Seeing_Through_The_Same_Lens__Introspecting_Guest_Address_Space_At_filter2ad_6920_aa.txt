title:Seeing Through The Same Lens: Introspecting Guest Address Space At
Native Speed
author:Siqi Zhao and
Xuhua Ding and
Wen Xu and
Dawu Gu
Seeing Through The Same Lens: Introspecting 
Guest Address Space At Native Speed
Siqi Zhao and Xuhua Ding, Singapore Management University; Wen Xu,  
Georgia Institute of Technology; Dawu Gu, Shanghai JiaoTong University
https://www.usenix.org/conference/usenixsecurity17/technical-sessions/presentation/zhao
This paper is included in the Proceedings of the 26th USENIX Security SymposiumAugust 16–18, 2017 • Vancouver, BC, CanadaISBN 978-1-931971-40-9Open access to the Proceedings of the 26th USENIX Security Symposium is sponsored by USENIXSeeing Through The Same Lens: Introspecting Guest Address Space At
Native Speed
Siqi Zhao
Wen Xu∗
Singapore Management University
Georgia Institute of Technology
Xuhua Ding
Singapore Management University
Dawu Gu
Shanghai JiaoTong University
Abstract
Software-based MMU emulation lies at the heart of out-
of-VM live memory introspection, an important tech-
nique in the cloud setting that applications such as live
forensics and intrusion detection depend on. Due to the
emulation, the software-based approach is much slower
compared to native memory access by the guest VM. The
slowness not only results in undetected transient mali-
cious behavior, but also inconsistent memory view with
the guest; both undermine the effectiveness of introspec-
tion. We propose the immersive execution environment
(ImEE) with which the guest memory is accessed at na-
tive speed without any emulation. Meanwhile, the ad-
dress mappings used within the ImEE are ensured to
be consistent with the guest throughout the introspec-
tion session. We have implemented a prototype of the
ImEE on Linux KVM. The experiment results show that
ImEE-based introspection enjoys a remarkable speed up,
performing several hundred times faster than the legacy
method. Hence, this design is especially useful for real-
time monitoring, incident response and high-intensity in-
trospection.
1
Introduction
The thriving cloud computing has kept driving the re-
search on virtual machine introspection (VMI) [14, 18,
19, 21, 23, 29, 33, 34, 35, 36] in the recent years to ad-
dress the growing security concerns on virtual machines.
The center of the VMI research is to bridge the seman-
tic gap [24], namely, to reconstruct the high level kernel
semantics by accessing the guest kernel’s virtual address
space. For instance, the VMI tool in the monitor VM
extracts all running processes’ identiﬁers in an untrusted
guest VM by traversing the guest kernel’s task struct
list.
∗Work was mainly done when visiting SMU as a research assistant.
When the tool is deployed inside the target VM, it is
trivial to access the guest virtual address space. Nonethe-
less, such an in-VM introspection [14, 34] induces guest
OS modiﬁcation and is subject to attacks if the guest ker-
nel is subverted. Placing the introspection agent outside
of the guest is a more appealing approach. Such an out-
of-VM introspection then faces the problem of replicat-
ing the guest’s virtual address (VA) to host physical ad-
dress (HPA) translation.
Existing out-of-VM introspection systems [18, 19, 33,
35] tackle the problem using a software-based address
translation whereby the MMU’s function is replaced by
software. As a result, the software-based access is much
slower than the native speed access in the guest. The
speed inferiority clearly impacts introspection perfor-
mance, e.g., longer turnaround time to scan the kernel’s
code section. Moreover, it has several negative secu-
rity implications.
It costs more precious time for live
forensics and incident response. It is also incapable of
continuously monitoring a critical memory location as
the introspection loses the race against the attack run-
ning at native speed. Most importantly, it is difﬁcult for
the software-based method to maintain consistent VA-
to-HPA mappings with the guest kernel, because it is
not amenable to tracking and following CR3 updates in
the guest.
Inconsistent mappings consequently impair
the security of introspection. We stress that the cache
mechanism does improve performance, however, at the
cost of potential mapping and data inconsistency since
the cached mappings and data could be stale.
In fact, mapping consistency can not be assumed
for an in-VM introspection scheme without trusting the
guest kernel, even though the memory is introspected at
native speed. For instance, SIM [34] isolates its moni-
toring code in an isolated address space whereas it does
not prevent the malicious kernel thread from using a dif-
ferent address mapping. The consistency issue persists
in the broader scope of system monitoring. As shown by
Jang et. al [25], hardware-assisted monitor systems such
USENIX Association
26th USENIX Security Symposium    799
as Copilot [30] and KI-mon [26] are circumvented by us-
ing address translation redirection attacks which deceive
the monitor into using a faked mapping.
In this paper, we propose a novel mechanism to allow
the introspection code in the monitor VM to access a tar-
get guest kernel’s virtual address space at native speed
and with mapping consistency, despite the kernel-level
attacks from the target. The code runs in a carefully de-
signed execution environment named as the Immersive
Execution Environment (ImEE). During a guest access,
the ImEE’s MMU walks the present paging structures
same as the guest’s, pointed to by the CR3 registers both
in the ImEE and in the guest.
We have implemented a prototype of the ImEE on
Linux KVM. The experiments demonstrate a remark-
able performance boost. As compared to the existing
software-based guest access method, the ImEE is sev-
eral hundred times faster to traverse kernel objects. The
ImEE is so lightweight and nimble that it only needs
23µs to activate and 7µs to switch the introspection tar-
get, around 200 times faster than the software method.
Hence, the ImEE is more attractive to applications desir-
ing strong security, faster response and high speed, for
instance, critical data monitoring, virtual machine scan-
ning, and live forensics.
CAVEAT.
Our contribution in this paper is com-
plementary to existing out-of-VM introspection systems
[19, 18, 29, 33]. Those innovations focus upon more
software issues, like efﬁcient kernel-level semantic re-
construction [19] and race conditions [29]. In contrast,
it is out of our scope to deal with the high-level issues
like which virtual addresses or kernel objects to read and
how to reuse the existing kernel code [19]. We expect
that, with modest retroﬁtting, those VMI applications can
harness the ImEE as a powerful guest access engine to
achieve better performance and stronger security.
ORGANIZATION. The next section brieﬂy reviews the
legacy method to access the target VM and analyze its
weakness. We present a synopsis of the work in Sec-
tion 3. The design details of the ImEE and the code
running inside are presented in Section 4. The imple-
mentation and performance evaluation are described in
Section 5 and 6, respectively. We then discuss several re-
lated issues in Section 7, and brieﬂy review the literature
in Section 8. Lastly, Section 9 concludes the paper.
2
Inadequacy of Software-based Guest Ac-
cess
It is a common practice in the VMI literature to use the
software-based method to translate virtual addresses be-
fore accessing a target guest VM. The guest’s own pag-
ing structures cannot be directly replicated in the mon-
itor VM, because it is incompatible with all software
therein. In addition, there is also a security concern that
the guest’s code or data could be used to attack the mon-
itor VM.
In this software-based approach, the target memory is
mapped to the monitor VM as a set of read-only pages.
Given a virtual address X, the introspection code walks
through all levels of the paging structures, including the
Extended Page Tables (EPTs1) in the memory to ﬁnd out
the corresponding HPA. It then maps the HPA to its own
virtual address space, and ﬁnally issues an instruction
to read it. Obviously, such a procedure incurs a much
longer latency than the native access to X in the guest.
To assess how slow the software-based guest access is
in relative to the native speed access, we run a “cat-and-
mouse” experiment. The introspection program using
LibVMI keeps reading a guest process’s task->cred
pointer, while a guest kernel thread periodically modi-
ﬁes the pointer and the new value stays for 20,000 CPU
cycles before being restored. The page-level data cache
of LibVMI is disabled to ensure the freshness of ev-
ery read whereas the translation caches are on since no
address mapping is modiﬁed. We conduct the experi-
ment for eight times, each lasting 10 seconds. In aver-
age, the modiﬁcation is only spotted after being repeated
60 rounds. In one of the eight rounds, no modiﬁcation
is caught. The experiment result demonstrates that in-
trospection at low speed cannot catch up with the fast-
running attacker. It is ill-suited for scenarios demanding
quick responses such as live forensics and real-time I/O
monitoring.
The slow speed also affects the mapping consistency
as the guest malware in the kernel may make transient
changes to the page tables, rather than the data. Since
walking the paging structures appears instant to the mal-
ware using the MMU, but not to the introspection soft-
ware, the malware’s attack on the page tables causes the
VMI tool to use inconsistent information obtained from
the paging structures.
Caching techniques have been used in order to reduce
the latency of guest accesses. For instance, LibVMI
[31] introduces three types of caches: the page-level data
cache, the VA-to-HPA translation cache and the pid to
CR3 cache. While promoting the performance, using the
caches is detrimental to effective introspection. Since
the guest continuously runs during the introspection, any
cached mapping or data is not guaranteed to be consistent
with the one in the memory. Moreover, it is difﬁcult for
the software-based method with caches to catch up with
the pace of CR3 updates in the guest. Since the guest ker-
nel is untrusted, the introspection cannot presume that all
1Throughout this paper, we following Intel’s terminology to de-
It can also be implemented on AMD processors
scribe the scheme.
supporting MMU virtualization.
800    26th USENIX Security Symposium
USENIX Association
guest threads share the same kernel address space. CR3
synchronization with the guest may lead to cache thrash-
ing which backﬁres on the introspection performance.
Besides the security related limitations described
the software method has performance-related
above,
drawbacks. It usually has a bulky code base since it has
to fully emulate the MMU’s behavior, such as supporting
32-bit and 64-bit paging structures as well as different
modes and page sizes. Its operation leaves a large mem-
ory footprint because of the intensive reliance on data
and translation caches.
It also suffers from slow-start
due to the complex setup. For instance, the LibVMI ini-
tialization costs 100 milliseconds according to our mea-
surement. To change the introspection target from one
VM to another requires a new setup. With these perfor-
mance pitfalls, the software-based method is not the best
choice for introspection in data centers where the VMI
tools may need to scan a large crowd of virtual machines.
scope of study. Side-channel attacks or denial-of-service
attacks are not considered either.
3.2 Basic Idea
Our idea is to create a special computing environment
called Immersive Execution Environment (ImEE) with a
twisted address mapping setting (as in Figure 1). The
ImEE’s CR3 is synchronized with the target VM’s active
CR3 so that its MMU directly uses the target’s VA-to-
GPA mappings. Its GPA-to-HPA mappings are split into
two. The GPAs for the intended introspection are trans-
lated with the same mappings as in the target VM; the
GPAs for the local usage (indicated by the dotted box in
Figure 1) are mapped to the local physical pages via sep-
arated GPA-to-HPA mappings. With this setting, mem-
ory accesses are automatically directed by the MMU into
the target and the local memory regions according to the
paging structures.
3 Synopsis
3.1 Models and Scope
System Model. We consider a multicore platform sup-
porting both CPU and MMU virtualization. Under the
management of a bare metal hypervisor, the platform
runs a trusted monitor VM and a set of untrusted guest
VMs which are the targets of introspection. The platform
administrator runs VMI applications inside the monitor
VM to introspect the live kernel states in the targets with-
out modifying or suspending them.
To avoid ambiguity, we use the “target” to refer to
the virtual machine under introspection, and use “guest”
with its hardware virtualization notion as in a “guest
physical address” (GPA) which refers to the physical ad-
dress a kernel uses inside a hardware-assisted virtual ma-
chine.
Trust Model. We assume all hardware and ﬁrmware in
the platform behave as expected. We trust the hypervi-
sor and the software in the monitor VM and assume that
the adversary cannot compromise the hypervisor or the
monitor VM’s kernel at launching time and runtime. We
do not trust any software running in the target, including
the kernel.
Scope of Study. The adversary we cope with resides
in the target kernel. Its goal is to stage a fake kernel ad-
dress space view to the VMI application. Namely, its
attack causes the VMI application to read those mem-
ory bytes that are “thought” to be used by kernel threads
but are actually not. Attacks that aim to beat the VMI
logic, e.g., manipulating a function pointer not known to
the introspection logic, are beyond and orthogonal to our
Figure 1: Illustration of the idea of direct usage of the
target VM’s VA-to-GPA mappings and splitting in GPA-
to-HPA mappings. Note that the shadow box is fully con-
trolled by the target (i.e., the adversary).
The paging structure setup in the ImEE ensures map-
ping consistency with the target VM. Firstly, the ImEE’s
VA-to-GPA mappings remain the same as the target’s,
because its CR3 and the target CR3 always point to the
same location. Any mapping modiﬁcation in the target
also takes effect in the ImEE simultaneously. Secondly,
the hypervisor ensures that the ImEE GPAs intended for
introspection are mapped in the same way as within the
target. Hence, any VA for introspection is translated with
mapping consistency with the target. Note that the VA is
accessed at native speed because the MMU performs the
address translation.
3.3 Challenges
Suppose that the ImEE has been set up following the idea
above with an introspection agent running inside and ac-
cessing the target memory. The following design chal-
USENIX Association
26th USENIX Security Symposium    801
6 HPA  (local memory) HPA  (target memory) VA-to-GPA mappings GPA-to-HPA mappings (for local) GPA-to-HPA mappings (for target) GPA for local VA for local GPA for target VA for introspection controlled by the target kernel lenges need to be addressed in order to achieve a suc-
cessful introspection.
Functionality Challenge.
The ImEE agent’s virtual
address space comprises of the executable code, data
buffers to read and write, and the target kernel’s address
space. Since the agent code and data are logically dif-
ferent from the target kernel, we need a way to properly
split the GPA domain so that VAs for the local uses are
not mapped to the target and VAs for introspection are
not mapped to the agent memory.
This challenge to divide the GPA domain is further
complicated by two issues. Firstly, the virtual address
space layout of the target is not priorly known, because it