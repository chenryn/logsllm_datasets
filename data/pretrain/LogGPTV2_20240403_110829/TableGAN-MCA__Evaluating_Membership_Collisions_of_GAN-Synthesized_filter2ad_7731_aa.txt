title:TableGAN-MCA: Evaluating Membership Collisions of GAN-Synthesized
Tabular Data Releasing
author:Aoting Hu and
Renjie Xie and
Zhigang Lu and
Aiqun Hu and
Minhui Xue
TableGAN-MCA: Evaluating Membership Collisions of
GAN-Synthesized Tabular Data Releasing
Aoting Hu
Southeast University
China
Renjie Xie
Southeast University
China
Zhigang Lu
Macquarie University
Australia
Aiqun Hu
Southeast University
China
Minhui Xue
The University of Adelaide
Australia
ABSTRACT
Generative Adversarial Networks (GAN)-synthesized table publish-
ing lets people privately learn insights without access to the private
table. However, existing studies on Membership Inference (MI) At-
tacks show promising results on disclosing membership of training
datasets of GAN-synthesized tables. Different from those works
focusing on discovering membership of a given data point, in this
paper, we propose a novel Membership Collision Attack against
GANs (TableGAN-MCA), which allows an adversary given only
synthetic entries randomly sampled from a black-box generator
to recover partial GAN training data. Namely, a GAN-synthesized
table immune to state-of-the-art MI attacks is vulnerable to the
TableGAN-MCA. The success of TableGAN-MCA is boosted by an
observation that GAN-synthesized tables potentially collide with
the training data of the generator.
Our experimental evaluations on TableGAN-MCA have five main
findings. First, TableGAN-MCA has a satisfying training data recov-
ery rate on three commonly used real-world datasets against four
generative models. Second, factors, including the size of GAN train-
ing data, GAN training epochs and the number of synthetic samples
available to the adversary, are positively correlated to the success of
TableGAN-MCA. Third, highly frequent data points have high risks
of being recovered by TableGAN-MCA. Fourth, some unique data
are exposed to unexpected high recovery risks in TableGAN-MCA,
which may attribute to GAN‚Äôs generalization. Fifth, as expected,
differential privacy, without the consideration of the correlations
between features, does not show commendable mitigation effect
against the TableGAN-MCA. Finally, we propose two mitigation
methods and show promising privacy and utility trade-offs when
protecting against TableGAN-MCA.
CCS CONCEPTS
‚Ä¢ Security and privacy; ‚Ä¢ Computing methodologies ‚Üí Ma-
chine learning;
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
CCS ‚Äô21, November 15‚Äì19, 2021, Virtual Event, Republic of Korea
¬© 2021 Association for Computing Machinery.
ACM ISBN 978-1-4503-8454-4/21/11...$15.00
https://doi.org/10.1145/3460120.3485251
KEYWORDS
Membership Privacy, Differential Privacy, Generative Adversarial
Networks (GANs), Synthetic Data Releasing
ACM Reference Format:
Aoting Hu, Renjie Xie, Zhigang Lu, Aiqun Hu, and Minhui Xue. 2021.
TableGAN-MCA: Evaluating Membership Collisions of GAN-Synthesized
Tabular Data Releasing. In Proceedings of the 2021 ACM SIGSAC Confer-
ence on Computer and Communications Security (CCS ‚Äô21), November 15‚Äì19,
2021, Virtual Event, Republic of Korea. ACM, New York, NY, USA, 17 pages.
https://doi.org/10.1145/3460120.3485251
1 INTRODUCTION
Big data have emerged as valuable resources that allow companies,
researchers and governments to enhance decision making, insight
discovery and process optimization. However, sharing sensitive
datasets without violating individual‚Äôs privacy is a long-standing
challenge. For example, in 2017, DeepMind was accused of an illegal
acquisition of personal medical records of 1.6 million patients for
developing a kidney injuries diagnosing application [34]. To analyze
those sensitive data in a privacy-preserving manner, ideally, we
need a trusted third party that collects and processes raw data, and
then releases a sanitized version of data trading off privacy and
utility through web queries (see the paradigm shown in Fig. 1).
However, state-of-the-art solutions for releasing the sanitized
data achieving trade-offs between utility and privacy are vulner-
able to privacy inference attacks. For example, de-identification
(removing unique identifiers for all data entries) is susceptible to
linkage attacks [32]. Anonymization [24, 29, 45] suffers from back-
ground information attacks. Other synthetic dataset publishing
mechanisms, such as NetMechanism [4], Iterative Construction [16‚Äì
19], are tailored for relatively small datasets [13]. More recently,
Generative Networks, including Generative Adversarial Networks
(GANs) [14] and Variational Autoencoders (VAEs) [23], produce
synthetic data that achieve enhanced privacy and utility trade-offs.
Such synthetic data conceal the detailed (privacy) of the raw data
while keeping statistics similarity [35, 46]. Nevertheless, recent
works [7, 20, 21, 35, 44] show the risk of membership disclosure
(i.e., inferring whether a given data point belongs to the training
dataset) against synthesized data by attacking generator APIs. They
propose various Membership Inference Attacks (MIAs) against pub-
lished generative models to disclose the membership information
of training data.
Session 7A: Privacy Attacks and Defenses for ML CCS ‚Äô21, November 15‚Äì19, 2021, Virtual Event, Republic of Korea2096Figure 1: The framework of private data publishing. Both
the data owner and service provider who guard resources
are trusted. The data analysts are legal customers as well as
potential adversaries.
To further explore the privacy disclosure risks of the GAN-
synthesized tabular data, different from existing MIAs against gen-
erative models [7, 20, 21, 35, 44], we propose a novel attack model,
named Membership Collision Attack against GAN-synthesized Ta-
bles (TableGAN-MCA). Specifically, we reconstruct a proportion of
actual training data from the published synthetic table with high
confidence by inferring the membership collisions (substantiated in
Section 3.1). Hence, TableGAN-MCA brings a novel privacy problem:
training data exposure when analyzing published synthetic tabular
data. In addition, TableGAN-MCA only queries a black-box gener-
ator (of the GAN) for synthetic data, which is similar to the most
strict threat model introduced in the recent work - GAN-Leaks [7].
We conceptualize the differences among recent works in Table 1.
Motivation. Our work is motivated by two observations in GAN-
synthesized table (low-dimensional data) releasing.
‚Ä¢ Observation 1. Generated synthetic tables overlap with GAN‚Äôs
training data (as the intersection illustrated in Fig. 2). For in-
stance, in the Adult dataset, a synthetic dataset collides with
the GAN‚Äôs training dataset by 16.9% (5350 entries). Clearly, such
an overlap brings severe privacy breaches if adversaries could
locate the intersection. In the remainder of this paper, we call the
overlap/intersection membership collision.
‚Ä¢ Observation 2. In the GAN-synthesized tabular data, member-
ship collisions and data frequency are positively correlated (sub-
stantiated in Fig. 3). However, it is rare to trigger sample collisions
in high-dimensional data, such as image synthesis, due to the
curse of dimensionality. Thus, the distribution of tabular data
with relatively small dimension brings additional privacy risks
than that of image synthesis.
To perform the proposed TableGAN-MCA, we leverage shadow
models [43] to learn the patterns behind the collision (Observation 1)
while taking the density of each synthetic data by counting its sam-
ple frequency in synthetic distribution (Observation 2) as additional
feature when training the attack model. TableGAN-MCA shows
promising results on commonly used real-world datasets, includ-
ing Adult, Lawschool and Compas. For instance, TableGAN-MCA
recovers 36.1%, 12.7%, 36.5% of actual members released with
the GAN-synthesized tabular data with approximately 80%
confidence for Adult, Lawschool and Compas, respectively.
Our results show that a well-trained GAN, robust to the MIAs
proposed in [7, 20, 35], is still vulnerable to TableGAN-MCA.
In summary, our main contributions are as follows:
‚Ä¢ We propose a novel membership collision attack against GAN-
synthesized tabular data publishing, named TableGAN-MCA,
Figure 2: The training dataset ùê∑ùë° intersects the synthetic
dataset ùëÜ at ùê∑ùë° ‚à© ùëÜ.
Table 1: Comparison with MIAs against GANs. (‚ñ†: black-box
‚àö
: require; √ó:
access; ‚Äì: insufficient information provided;
does not require)
Benchmark
Datasets
Image
Table
Image
Image/Table
Table
‚ñ† Gen-
erator
‚àö
‚àö
‚àö
‚àö
‚àö
‚ñ† Dis-
criminator
‚àö
‚àö
√ó
√ó
√ó
Extra
Targets
‚àö
‚àö
‚àö
‚àö
√ó
Expose
Trainset
False
False
‚Äì
False
True
LOGAN [20]
table-GAN [35]
MC [21]
GAN-leaks [7]
TableGAN-MCA
which can reinstate partial training data with high confidence.
TableGAN-MCA exploits the weaknesses of GAN synthesis ob-
served on low-dimensional data, i.e., GAN-synthesized data col-
lide with its training data, and members (in the colliding member
set) occur more frequently than non-members.
‚Ä¢ We extensively evaluate our proposed attacks on three com-
monly used real-world datasets, including Adult, Lawschool and
Compas against four generative models, including TVAE [46],
CTGAN [46], WGAN-GP [15] and WGAN-WC [2]. Furthermore,
we explore the factors that may impact the attack effectiveness,
such as the size of GAN training data, GAN training epochs, GAN
training data frequencies and the number of synthetic samples
available to the attacker.
‚Ä¢ We discover that individuals in the training dataset have various
risks of privacy leakage under TableGAN-MCA. Additionally, we
show that GANs do not memorize those exposed data. Instead,
when generalizing the distribution of the training data, GANs
may increase or decrease the frequency of some individuals, and
hence change their privacy risks.
‚Ä¢ We examine the effect of differential privacy (DP) to mitigate
TableGAN-MCA. Our empirical results show that differential
private generative model training achieves sub-optimal trade-
offs against TableGAN-MCA. It is mainly due to the fact that
TableGAN-MCA relies more on the common pattern of a distri-
bution (like attribute correlations) which is not the focus of DP.
In addition to DP, we propose two mitigation methods, naive de-
fense and improved defense, that mitigate the effect of TableGAN-
MCA.
2 BACKGROUND OF GENERATIVE MODELS
Generative Adversarial Networks (GANs) [14] and its variants have
made great achievements in generating high quality artificial data
that mimic the real ones, by modeling the underlying data distribu-
tion. It is composed of two neural networks: a discriminator ùê∑ and a
generator ùê∫. It tries to minimize the distance between the real data
distribution Pùëü and the generated (artificial) data distribution Pùëî by
iteratively updating parameters of the networks.
Resource Layer (Private)User LayerWebWebData AnalystsSynthetic DataService Provider(MLaaS)QueriesRaw DataData OwnersDtData DistrbutionSensitive DataSynthetic DataSX√óYDt‚à©SSession 7A: Privacy Attacks and Defenses for ML CCS ‚Äô21, November 15‚Äì19, 2021, Virtual Event, Republic of Korea2097Table 2: Summary of notations.
Symbol Description
ùê∑ùë°
ùëÜ
Pùëü
Pùëß
Pùëî
ùêº
ùëÅùë†
Private training dataset
Released synthetic dataset
Training data distribution
Prior Gaussian distribution
Generated data distribution
colliding member set
Number of synthetic copies
ùê∫
ùê∑ùë†
(cid:101)ùëÜ
Symbol Description
Test dataset
Shadow dataset
Generator oracle
Indicator function
A data point
Adversary
Attack classifier
1
x
A
ùëì (¬∑)
= ‚àí1
2
ùêΩ (ùê∫) = ‚àí1
2
Eùíô‚àºùëùdata
Eùëßùê∑(ùê∫(ùëß)).
The Wasserstein GAN (WGAN) [2] applies Earth Mover (EM)
distance under a K-Lipschitz constraint and achieves good perfor-
mance in generating high fidelity samples. The loss function of the
discriminator and the generator are as follows:
ùê∑(ùíô) + 1
2
ùúΩ (ùê∑), ùúΩ (ùê∫)(cid:17)