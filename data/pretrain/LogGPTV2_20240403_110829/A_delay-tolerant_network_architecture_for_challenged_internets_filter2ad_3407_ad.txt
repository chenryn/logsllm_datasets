Internet
SensorNet
Other
Convergence
Convergence
Convergence
Layer
Layer
Layer
Database
M a n a g e r
File
S tore
Bundle
Data
Sockets
Sensor Net API
T C P
U D P
S C T P
IP
Sensor Network
Stack
(TBD)
Other Transport
o r
Raw Protocols
(TBD)
802.3
802.11
O ther
Serial
Port
File
S tore
Bundle
MetaData
Figure 2. Structure of a DTN gateway.  Multiple convergence 
layers, one per protocol stack, provide a common interface to 
the message scheduler/forwarder.
“delivery confirmation” may be optionally requested, although
how  to  respond  to  this  indication  is  left  to  the  requesting
application.
In  contemplating  a  change  from  end-to-end  reliable  delivery
semantics  to  a  hop-by-hop  reliability  approach  (with  end-to-
end  notification),  we  may  ask  whether  a  less  robust  type  of
reliability is being provided by the hop-by-hop approach.  We
believe that the custody transfer mechanism is not necessarily
less reliable than using typical end-to-end reliability, although
it is different.  This opinion stems from the observation that in
many  circumstances,  where  end  nodes  cannot  be  assumed  to
remain  operational  for  long  periods  of  time,  that  the  chances
for data to be reliably delivered using delegation can exceed its
changes  of  being 
end-to-end.
Furthermore, 
the  end-to-end  optional
acknowledgment  is  consistent  with  the  end-to-end  argument
[16] ---that only the applications truly know what they require.
Indeed,  custody  transfer  can  be  viewed  as  a  performance
optimization  for  end-to-end  reliability 
the
movement of the endpoint.
successfully  delivered 
the  provision  of 
involves 
that 
lacking 
these 
features 
Figure 2 
illustrates 
augmented. 
4.6 Convergence Layers and Retransmission
The facilities provided by the transport protocols in use within
the  regions  containing  a  DTN  P  node  may  vary  significantly.
For example, any transport protocol may or may not offer the
following:  reliable  delivery,  connections  (with  indications  of
connection  failure),  flow  control,  congestion  control,  and
message  boundaries.    As  the  bundle  forwarding  function
assumes  an  underlying  reliable  delivery  capability  with
message  boundaries  when  performing  custody 
transfer,
  must  be
transport  protocols 
appropriately 
the
implementation  structure  for  a  bundle  forwarder,  including  a
number of transport-protocol-specific convergence layers used
to  add  reliability,  message  boundaries,  and  other  features
above those transport protocols requiring augmentation.  (Note
that TCP in the Internet requires augmentation due to its lack
of  message  boundaries;  SCTP,  which  includes  support  for
message boundaries, would likely use a minimal convergence
layer  and  not  require  much  augmentation).    The  design  of
most  convergence  layers  is  specific  to  the  transport  protocols
being  augmented,  and  are  therefore  beyond  the  scope  of  this
paper.
In cases where reliable delivery is provided by an underlying
transport,  the  corresponding  convergence  layer  need  only
manage connection state and initiate restarts if a connection is
lost.  In the case of connection-oriented protocols, detection of
a lost connection is generally provided through the application
interface (via signals or other errors using the socket interface,
for example).  In cases where no direct support is provided for
detecting  failures,  the  bundle  forwarding  function  itself  may
set a coarse-grained timer to re-start message transfers should
it  be  concluded  that  they  have  failed.    This  is  designed  as  a
fallback  measure  in  cases  of  underlying  communication
failure,  and  is  not  expected  to  be  an  especially  efficient
mechanism for initiating retransmission.
The  appropriate  choice  of  timeout  for  the  coarse-grain
retransmission timer will vary depending on the details of the
containing region, and thus represents a certain form of layer
violation  in  which  the  overlay  “network”  layer  is  able  to  be
sensitive 
layer  properties  by
requesting 
  In
challenged networks, knowledge of some path properties at the
forwarding  layer  appears  to  be  very  useful  in  selecting  error
control  policy.    In  particular,  some  rough  expectation  of  the
round-trip time is extremely useful to trigger attempted repair
actions.
information  from  a  convergence 
to  underlying  “physical” 
layer. 
their 
lifetimes. 
is  used  for 
source-specified 
4.7 Time Synchronization
The DTN architecture requires a coarse level of (relative) time
synchronization,  which 
identifying  message
fragments  (see  [8])  and  also  for  purging  messages  that  have
exceeded 
In  most
circumstances,  however,  there  are  several  additional  benefits
derived  from  imposing  a  more  stringent  constraint  on  time
synchronization  (e.g.  on  the  order  of    one  millisecond).    The
motivation  stems  from  the  observation  that  synchronized
timing  is  needed  by  many  distributed  applications  used  in
challenged  environments  and  is  required  by  the  DTN’s
approach  to  scheduling  and  path  selection  (in  cases  where
contact  start  and  end  times  are  known  ahead  of  time).    In
addition,  given  reasonably  accurate  time  synchronization,
DTN  congestion  management  techniques  can  conceivably
predict  at  what  times  congestion  may  abate.  Although  more
burdensome  than  time  synchronization  requirements  on  the
Internet  (which  are  essentially  nonexistent),  we  believe  the
problem  of  fine  time  synchronization  is  sufficiently  well-
developed  as  to  be  a  default  policy  for  most  networks.
Protocols  such  as  NTP  [14]  have  provided  1ms  accurate  time
synchronization  (or  better)  within  the  Internet  for  years,  and
most  existing  networks  for  extreme  environments  already
provide some (often out-of-band) means for obtaining accurate
time2.
4.8 Security
The  security  requirements  for  the  DTN  architecture  differs
somewhat from traditional network security models in that the
set  of  principals  includes  the  network  routers  (i.e.  DTN
gateways)  themselves  in  addition  to  the  communicating
endpoints.    In  the  DTN  case,  we  are  likely  to  be  more
interested  in  verifiable  access  to  the  carriage  of  traffic  at  a
particular  class  of  service  and  want  to  avoid  carrying  traffic
potentially long distances that is later found to be prohibited.
To  implement  the  security  model,  each  message  includes  an
immutable “postage stamp” (a type of capability) containing a
verifiable  identity  of  the  sender  (or  role),  an  approval  (and
approving  authority)  of  the  requested  class  of  service  (CoS)
associated  with 
the  message,  and  other  conventional
cryptographic  material  to  verify  accuracy  of  the  message
content.    Routers  check  credentials  at  each  DTN  hop,  and
discard traffic as early as possible if authentication fails.  This
approach  has  the  associated  benefit  of  making  denial-of-
service attacks considerably harder to mount as compared with
conventional Internet routers.
The  current  approach  uses  public  key  cryptography  as  a
starting  point  for  keying.    Routers  and  users  are  issued
public/private  keypairs,  and  a  principal  sending  a  message
must obtain a signed copy of its public key from a certificate
authority known to DTN forwarders.  (All routers are assumed
to  be  pre-equipped  with  copies  of  one  or  more  certificate
2 There is an effort to extend NTP to space, although this work is
still under development [15].
to 
improve 
authority  public  keys  and  their  own  public/private  key  pairs).
A  principal  then  presents  its  signed  public  key  along  with  a
message  to  be  carried  signed  with  the  corresponding  private
key.  At the first DTN router, the signed public key is used to
validate  the  sender  and  requested  class  of  service  against  an
access control list stored in the gateway.  Accepted messages
are then re-signed in the key of the gateway for transit.  Using
this  approach,  only  first-hop  gateways  need  cache  per-user
certificates, and then only for adjacent users.  Non-edge “core”
gateways can rely on the authentication of upstream gateways
to  verify  the  authenticity  of  messages.    We  believe  this
approach  will  help 
the  scalability  of  key
management for these networks, as it will limit the number of
cached  public  key  certificates  to  a  function  of  the  number  of
adjacent  gateways  rather  than  the  number  of  end-users.    This
should provide both the obvious advantage of memory savings,
but  also  an  improvement  to  system  management  as  gateway
keys are expected to be changed less frequently than end-user
keys.    As  DTN  gateways  are  likely  to  be  deployed  in  remote
areas,  re-keying  may  be  a  comparatively  burdensome  system
management  tasks,  so  limiting  the  number  and  frequency  of
certificate updates should provide additional savings.
The  approach  described  above  is  partially  susceptible  to
compromised  routers.    If  an  otherwise-legitimate  router  is
compromised, it would be able to utilize network resources at
an  arbitrary  CoS  setting  and  send 
traffic  purportedly
originating  from  any  user  who’s  identity  is  known  to  the
router.    However,  if  the  message  signature  is  carried  end-to-
end  (an  option  for  DTN  security),  a  legitimate  user  could
repudiate the origin of any traffic generated in this manner at a
later time.  Thus, we believe a reasonable trade-off is to admit
the  possibility  that  a  compromised  router  could  launch  a
denial-of-service attack in order to gain the scalability benefits
of not checking end-user credentials at every hop.
4.9 Congestion and Flow Control
As  a  form  of  hop-by-hop  architecture,  flow  control  and
congestion control for DTN are closely related.  Flow control
in  this  context  refers  to  limiting  the  sending  rate  of  a  DTN
node to its next (DTN) hop.  Congestion control refers to the
handling  of  contention  for  the  persistent  storage  at  a  DTN
gateway.  The mechanisms available to deal with these issues
may be classified as proactive or reactive.  Proactive methods
generally involve some form of admission control, to avoid the
onset of congestion in the first place.  In many cases, a region
may be under the administrative control of a single entity, and
this  approach  may  be  practical.      If  proactive  methods  are
insufficient  or  unavailable,  reactive  means  (most 
likely
involving  direct  flow  control)  must  be  used  which  usually
result  in  degraded  performance  when  the  actual  operational
delays are high.
Two  aspects  of  the  DTN  architecture  make  the  issue  of
congestion  control  especially  challenging  (as  compared  to
other aspects of the architecture):  contacts may not arrive for
some time in the future (so accumulated data may not have an
opportunity to drain for some time), and received messages for
which  custody  has  been  accepted  cannot  be  discarded  except
under  extreme  circumstances  or  on  expiration.    Given  these
constraints,  the  possibilities  to  handle  congestion  include
reserving buffer space as a function of CoS, rejecting incoming
connections  for  new  messages  when  buffer  space  is  full,
arranging  for  custody  transfers  to  other  potential  custodians