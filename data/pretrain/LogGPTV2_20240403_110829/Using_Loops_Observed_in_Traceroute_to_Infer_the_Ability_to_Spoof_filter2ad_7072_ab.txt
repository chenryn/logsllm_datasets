g
n
a
h
c
n
u
n
o
i
t
c
a
r
F
IPv4 ASes
IPv6 ASes
 4
 2
 8
# Prefixes in Ingress ACL
 6
(a) Size of Ingress ACLs
 10
 0
Jan
’12
Jan
’13
Jan
’14
Jan
’15
Jan
’16
(b) Dynamism of Ingress ACLs
Fig. 2. Size and dynamism of ACLs to ﬁlter traﬃc from stub ASes.
Figure 1 quantiﬁes the dynamism of address space announced by stub ASes
over time. Using BGP data collected by Routeviews and RIPE RIS with the
method described in Sect. 5.1, we aggregated the preﬁxes each stub AS originated
in BGP into the minimum preﬁx set, and examined month-to-month changes in
the set. Perhaps a consequence of IPv4 address exhaustion, we see a trend toward
stable announcement patterns. This trend may improve the practicality of static
ingress ACLs: in May 2000, ≈15% of stub ASes would have required deployment
of a diﬀerent IPv4 ingress ACL month-to-month, but in 2015, less than 5% of
ASes would have required the same.
As BCP 84 states that because ingress ACLs require manual maintenance
they are best suited “when the conﬁguration is not too dynamic” and “if the
number of used preﬁxes is low”, Fig. 2 examines the size and dynamism of ingress
ACLs required for stub ASes in August 2016. Figure 2a shows that 88.9% of
stub ASes would require an IPv4 ACL of no more than 4 preﬁxes, and 85.6%
of stub ASes would require an IPv6 ACL of a single preﬁx. Figure 2b shows the
dynamism of these ACLs over time, based on ACLs that could have been deﬁned
for all stub ASes in January 2012, 2013, 2014, and 2015. For stub ASes for these
times, at least 77.4% of IPv4 ACLs would not have had to change over the course
of one year; for those deﬁned in January 2012, 54.4% of the inferred ACLs would
not have required change even up to August 2016. Further, required IPv6 ACLs
would be even less dynamic: more than 74.6% of IPv6 ACLs would not have
needed to change over the course of 4.5 years until August 2016. We believe the
observed number of preﬁxes and dynamism over time imply that ingress ACLs
are feasible in the modern Internet.
5 Inferring Absence of Ingress Filtering Using Traceroute
The key idea of our approach is that traceroute can show absence of ingress
ﬁltering by providers of stub ASes when a traceroute path reaches the stub AS
and then exits out of the stub, as the traceroute packets contain a source address
belonging to the vantage point (VP) launching the traceroute. If the provider’s
Using Loops Observed in Traceroute to Infer the Ability to Spoof
233
border router is performing SAV, it should ﬁlter the traceroute packet when it
arrives from the stub AS, as the packet has a source address not belonging to
the stub AS. If the provider’s router does not perform SAV, it will forward the
packet, and the traceroute will show an apparent IP-level forwarding loop as the
provider’s router returns subsequent packets to the stub AS.
Xia et al. found that 50% of persistent loops were caused by a border router
missing a “pull-up route” covering address space not internally routed by the
customer [21]. However, a forwarding loop does not imply absence of SAV at the
edge: a loop resulting from a transient misconﬁguration or routing update can
occur anywhere in the network. The key challenge in this work is inferring the
provider-customer boundary in traceroute [16,18]. In this paper, we superimpose
millions of traceroutes towards random IP addresses in /24 preﬁxes to build a
topology graph, and use a small set of heuristics to infer provider-customer edges
for stub ASes in the graph. Sect. 5.1 describes the Internet topology datasets that
we used, and Sect. 5.3 describes the algorithm we used to ﬁlter the loops that
imply the absence of ingress ﬁltering by the provider – in other words, the lack
of compliance with BCP 38.
5.1 Input Data
CAIDA IPv4 routed /24 topology datasets: We used CAIDA’s ongo-
ing traceroute measurements towards every routed /24 preﬁx in the Internet.
CAIDA’s probing of all routed /24s is especially useful here, as the goal is to
ﬁnd unrouted space that can result in a forwarding loop. CAIDA’s traceroute
data is collected with scamper [15] using Paris traceroute which avoids spurious
loops by keeping the ICMP checksum value the same for any given traceroute [4].
As of August 2016, CAIDA probes every routed /24 using 138 Vantage Points
(VPs) organized into three teams; each team probes the address space indepen-
dently. Each team takes roughly 1.5 days to probe every routed /24.
CAIDA IPv4 AS relationships: We used CAIDA’s ongoing BGP-based AS
relationship inferences [17] to identify customer-provider interconnections in
traceroute paths. The relationship ﬁles were inferred by CAIDA using public
BGP data collected by Routeviews and RIPE RIS, using RIB ﬁles recorded on
the 1–5 of each month. We also used the same BGP data to identify the origin
AS announcing each preﬁx measured with traceroute.
CAIDA Sibling Inferences: We used CAIDA’s ongoing WHOIS-based AS-to-
organization inference ﬁle [13] to identify ASes that belong to the same under-
lying organization (are siblings). The sibling ﬁles were inferred by CAIDA using
textual analysis on WHOIS databases obtained from Regional Internet Registries
(RIRs) at 3-month intervals. We used sibling inferences to avoid mis-classifying
a loop that occurs within a single organization using multiple ASes as one that
occurs between distinct provider and customer ASes.
234
Q. Lone et al.
5.2 Construction of Topology
Our ﬁrst goal is to correctly identify the provider-customer boundaries towards
stub ASes with high precision. Because the customer usually uses address space
provided by the provider to number their interface on their router involved in the
interconnection, the customer-edge router usually appears in traceroute using an
IP address routed by the provider. Therefore, one of our goals is to accurately
identify customer routers using provider address space without incorrectly infer-
ring that a provider’s backbone router belongs to a customer.
We assemble all traceroutes collected for a single cycle by a single team that
do not contain loops, and label each interface with (1) the origin AS of the
longest matching preﬁx for the interface address, and (2) the set of destination
ASes the interface address is in the path towards. If an address is in the path
towards multiple ASes, the address could not be conﬁgured on a customer router
of a stub AS.
5.3 Algorithm to Infer Absence of Ingress Filtering from Loops
Our algorithm considers two diﬀerent ways a traceroute path may enter a stub
AS and exit through a provider AS: (1) a simple point-to-point loop between a
single provider-edge router and a single customer-edge router, (2) a loop from a
customer-edge router that exits using a diﬀerent provider.
Simple point-to-point loops: Figure 3 illustrates the ﬁrst case, where R3 is
a customer-edge router belonging to AS B conﬁgured with a default route via
R2. If the operator of B announces address space in BGP but does not have an
internal route for a portion of that address space, and does not have a “pull-up
route” covering the unused portion on R3, then R3 forwards the packet back
to R2 using the default route [21]. R2 will then forward the packet back to R3,
Fig. 3. A simple loop between AS A and its customer B implying absence of ﬁltering
by A at R2. R2 should discard packet 4 because it arrives with a source address outside
of B’s network, rather than send it back to B (5).
Using Loops Observed in Traceroute to Infer the Ability to Spoof
235
Fig. 4. A two-provider loop between ASes A and C and their customer B implying
absence of ﬁltering by C at R5. R5 should discard packet 5 because it arrives with a
source address outside of B, rather than forward the packet to R6.
the loop sequence will likely be a5 (customer-edge router), a4 (provider-edge
router), and a5 (customer-edge router), with a4 and a5 assigned from the same
IPv4 /30 or /31 preﬁx the routers use to form the point-to-point link. Therefore,
our criteria are: (1) that the addresses in the loop are assigned from a single
/30 or /31 preﬁx, (2) that the AS originating the longest matching preﬁx is
an inferred provider of the stub AS and not a sibling of the stub AS, (3) that
the assumed customer router only appears in traceroute paths towards the stub
AS, (4) that there is at least one other address originated by the provider in
the traceroute path towards the stub. Criteria #3 avoids incorrectly inferring a
provider-operated router as a customer-edge router when a loop occurs before
the stub AS (e.g. a1 a3 a2 a3) as a3 appears in traceroute paths towards both
B and C. Criteria #4 avoids incorrectly inferring which router in a traceroute
path is the customer-edge router when the customer-edge router is multi-homed
and the traceroute path enters via a second provider AS D (e.g., d2 a4 a5 a4).
Two-provider loops: Figure 4 illustrates the second case, where R3 and R4
are customer-edge routers belonging to AS B, with default routes conﬁgured
on R3 and R4. The underlying routing conﬁguration issues are the same as a
point-to-point loop, except the default route is via a diﬀerent AS than the AS
the traceroute entered the network. Figure 4 shows the traceroute visiting two
routers operated by AS B; however, it is possible that the traceroute will never
contain an IP address mapped to B, depending on how many routers in B the
traceroute visits, and how the routers respond to traceroute probes. Therefore,
our criteria are: (1) that the assumed customer router where the traceroute exits
appears only in paths towards the stub AS, (2) that both the ingress and egress
AS in the traceroute path are inferred providers of the stub AS and not a sibling
of the stub AS, (3) that there is no unresponsive traceroute hop in the traceroute
path where a customer router could be located, (4) that at least two consecutive
IP addresses mapped to the same egress AS appear in the loop. Criteria #2
does not require diﬀerent provider ASes: if the stub AS is multi-homed to the
same provider with diﬀerent routers, our method will still infer an absence of
236
Q. Lone et al.
ﬁltering. Criteria #3 ensures that we do not mis-infer where the customer router
is located in the path, and thus incorrectly infer the AS that has not deployed
ingress ﬁltering. Finally, criteria #4 reduces the chance that a loop inside the
customer network is mis-classiﬁed as crossing into a provider network if the
customer router responds with a third-party IP address.
5.4 Finding Needles in a Haystack
As discussed in Sect. 5.1, CAIDA uses three teams of Ark VPs to probe a random
address in every routed /24 preﬁx. In this section, we report on the characteristics
of cycle 4947 conducted by team 3. The characteristics of data conducted by
other teams and for other cycles is quantitatively similar. In total, cycle 4947
contains 10,711,132 traceroutes, and 163,916 (1.5%) of these contain a loop.
105,685 (64.5%) of the traceroutes with loops were not towards a stub network.
Of the remaining 58,231 traceroutes with loops towards stub ASes, we
inferred 31,023 (53.3%) had a loop within the stub network, i.e. the addresses
in the loop were announced in BGP by the stub, or involved the customer-edge
router. A further 11,352 traceroutes (19.5%) contained a loop with an unrespon-
sive IP address, and 1,373 traceroutes (2.4%) contained an unrouted IP address
that prevented us from inferring if the loop occurred at a provider-customer
interconnect. 610 traceroutes (1.0%) had a loop that we disqualiﬁed as occur-
ring at a customer-provider boundary, as the loop occurred at a router that
also appeared in paths towards multiple destination ASes, and 494 traceroutes
(0.8%) contained an IP address that could have been a third party address on
a customer router, rather than a router operated by a provider. In total, only
2,530 traceroutes with loops (4.3%) contained simple point-to-point loops, and
only 93 (0.2%) contained more complex two-provider loops.
5.5 Persistence of Loops
Given that we are looking for needles in haystacks, how reliably can we ﬁnd
them? Ideally, we would be able to consistently reproduce the loops that imply
absence of ingress ﬁltering, and discard observations caused by transient events.
Unfortunately, there is currently no straightforward way of doing so.
The data we used was collected by CAIDA using traceroutes conducted by
a distributed set of VPs towards a random IP address in each routed /24 preﬁx.
This approach adds eﬃciency by reducing the number of probes, at the cost of
potentially missing loops that occur for smaller preﬁxes. It also means that when
such a loop is in fact discovered, the next probe might miss it again by selecting