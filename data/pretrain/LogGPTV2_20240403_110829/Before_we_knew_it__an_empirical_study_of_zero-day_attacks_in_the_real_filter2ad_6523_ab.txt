### Virus IDs and Vulnerabilities

Virus IDs often exploit more than one vulnerability, which means that in the dataset \( Z \), a single virus ID may appear multiple times. 

### Identifying Exploits in Executables

In the second stage of our method, we aim to identify the specific exploits detected by each virus ID in \( Z \). This allows us to search for these exploits in the binary reputation data. The anti-virus telemetry dataset records the hashes of all malicious files identified by Symantec’s anti-virus products. Each file recorded in the system is represented by a unique identifier (file hash ID). Certain virus IDs detect a large number of file hash IDs due to the polymorphism used by malware authors to evade detection. This step results in a mapping of threats to their variants, denoted as \( E_i = \{ \text{virus ID}_i, \text{file hash ID}_i \} \).

### Identifying Executables Dropped After Exploitation

When exploits are embedded in non-executable files, their file hash IDs can be found in the anti-virus telemetry data but not in the binary reputation data. To detect zero-day attacks that use such exploits, we query the dynamic analysis dataset for files downloaded after successful exploitations performed by the file hash IDs identified in the previous step. This step also produces a mapping of threats to malicious files, but instead of listing the exploit files, we add the dropped binary files. However, this may result in false positives because even if we detect a dropped executable in the binary reputation data before the disclosure date of the corresponding vulnerability, we cannot be certain that this executable was linked to a zero-day attack. It might have been downloaded using other infection techniques. Therefore, this step is optional in our method.

### Analyzing the Presence of Exploits on the Internet

Once we have identified which executables exploit known CVE IDs, we search for each executable in the binary reputation data to estimate when they first appeared on the Internet. The binary reputation data indicates the presence of these files, not whether they were executed or capable of execution on the platform where they were discovered. Thus, these reports indicate potential attacks rather than confirmed infections. Since some virus IDs match more than one variant, the first executable detected marks the start of the attack. After this step, for each virus ID in \( Z \), we can approximate the time when the attack began in the real world.

### Identifying Zero-Day Attacks

To identify the virus IDs involved in zero-day attacks, we compare the start dates of each attack with the disclosure dates of the corresponding vulnerabilities. If at least one of the file hash IDs of a threat \( Z_i = \{ \text{virus ID}_i, \text{CVE ID}_i \} \) was downloaded before the disclosure date of the CVE ID, we conclude that the CVE ID is a zero-day vulnerability and that the virus ID performed a zero-day attack.

### Threats to Validity

The biggest threat to the validity of our results is selection bias. Since WINE does not include data from hosts without Symantec’s anti-virus products, our results may not be representative of the general population of platforms. Users who install anti-virus software might be more security-conscious and thus less exposed to attacks. Although we cannot rule out the possibility of selection bias, the large size of the population in our study (11 million hosts and 300 million files) and the number of zero-day vulnerabilities we identify (18, which is on the same order of magnitude as the 31 reported by Symantec analysts during the same period [37]) suggest that our results have broad applicability. Additionally, for zero-day vulnerabilities detected early in our data collection period, we may underestimate the duration of the attacks. We caution readers that our results for the duration of zero-day attacks should be interpreted as lower bounds.

### Analysis Results and Findings

In this section, we analyze the zero-day vulnerabilities discovered using the method described in Section 4. Our ground truth is based on a January 2012 copy of the OSVDB database, and the binary reputation data we analyzed was collected between February 2008 and March 2012. This key component of our method allows us to identify zero-day attacks that occurred between 2008 and 2011.

First, we apply our method without the optional step that considers dynamic analysis data. As shown in Table 2, we identify 18 zero-day vulnerabilities: 3 disclosed in 2008, 7 in 2009, 6 in 2010, and 2 in 2011. The second column of the table lists the anti-virus signatures linked to these vulnerabilities, which are described on the Threat Explorer website [38]. Most vulnerabilities were associated with a single anti-virus signature, typically a heuristic detection for the exploit, while some were associated with several signatures. For example, CVE-2008-4250 was exploited 8 months before the disclosure date by Conficker (also known as W32.Downadup) and four other worms.

The third column of the table lists the disclosure dates of these vulnerabilities, and the fifth column lists the earliest occurrence, observable in WINE, of a file exploiting them. For these vulnerabilities, exploits were active in the real world before disclosure, indicating that they are zero-day vulnerabilities. For comparison, the fourth column of Table 2 reports the exploit release dates, as recorded in public vulnerability databases such as OSVDB. This information is available for only 4 out of the 18 vulnerabilities, and in all these cases, the exploit release date is within one day of the vulnerability disclosure, while working exploits existed in the wild 8–30 months before disclosure. This underscores the importance of analyzing field data when studying zero-day attacks.

To determine whether these vulnerabilities were already known to have been involved in zero-day attacks, we manually searched all 18 vulnerabilities on Google. From annual vulnerability trends reports produced by Symantec [33–37] and the SANS Institute [28], as well as blog posts on zero-day vulnerabilities, we found that 7 of our vulnerabilities are generally accepted to be zero-day vulnerabilities (see Table 3). For example, CVE-2010-2568 is one of the four zero-day vulnerabilities exploited by Stuxnet and is known to have been employed by another threat for more than 2 years before the disclosure date (17 July 2010). As shown in Table 3, most of these vulnerabilities affected Microsoft and Adobe products.

The zero-day attacks we identified lasted between 19 days (CVE-2010-0480) and 30 months (CVE-2010-2568), with an average duration of 312 days. Figure 4 illustrates this distribution. The last column in Table 2 shows the number of hosts targeted before the zero-day attacks were detected. 15 of the zero-day vulnerabilities targeted fewer than 1,000 hosts out of the 11 million hosts in our dataset. On the other hand, 3 vulnerabilities were used in attacks that infected thousands or even millions of Internet users. For example, Conficker exploiting the vulnerability CVE-2008-4250 managed to infect approximately 370,000 machines over more than two months without being detected. This example illustrates the effectiveness of zero-day vulnerabilities for conducting stealth cyber attacks.

We also examined whether the zero-day vulnerabilities continued to be exploited until the end of our data collection period. Specifically, we analyzed the variation in the number of malware variants and the number of times they were detected. Figure 6a shows the number of downloads (before the disclosure date) and detections (after the disclosure date) of the exploits for the zero-day vulnerabilities until the last exploitation attempt. The number of attacks increased 2–100,000 times after the disclosure dates of these vulnerabilities.

Figure 6b shows that the number of variants (files exploiting the vulnerability) also exhibited a similar abrupt increase after disclosure, with 183–85,000 more variants detected each day. One reason for the large number of new different files exploiting the zero-day vulnerabilities might be that they are repacked versions of the same exploits. However, it is unlikely that repacking alone can account for an increase by up to 5 orders of magnitude. More likely, this increase is the result of the extensive re-use of field-proven exploits in other malware.

Figure 7 shows the time elapsed until all the vulnerabilities disclosed between 2008 and 2011 started being exploited in the wild. Exploits for 42% of these vulnerabilities appeared in the field data within 30 days after the disclosure date. This illustrates that cybercriminals closely monitor vulnerability disclosures and quickly develop and deploy new exploits.