for every index i ∈ {0, . . . , n − 1} and sends
(mf , mf +1, . . . , mn−1, m0, . . . , mf−1) to the auditor.
2) Server A computes
3) Server B repeats Step 2 with vB.
4) The audit server returns “1” to servers A and B if and
only if the vectors it receives from the two servers are
equal at every index except one. The auditor returns “0”
otherwise.
We include proofs of soundness, correctness, and zero-
knowledge for this construction in Appendix C.
The keys for the (2, 1)-DPF construction have the form
kA = (bA, sA, v)
kB = (bB, sB, v).
330330
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:07:16 UTC from IEEE Xplore.  Restrictions apply. 
In a correctly formed pair of keys, the b and s vectors differ
at a single index (cid:2)x, and the v vector is equal to v = e(cid:2)y,m +
G(sA[(cid:2)x]) + G(sB[(cid:2)x]).
To determine whether a pair of keys is correct, server A
constructs a test vector tA such that tA[i] = bA[i](cid:13)sA[i]
for i ∈ {0, . . . , x − 1}. (where (cid:13) denotes concatenation).
Server B constructs a test vector tB in the same way and
the two servers, along with the auditor run the protocol
AlmostEqual(tA, tB). If the output of this protocol is “1,”
then the servers conclude that their b and s vectors differ
at a single index, though the protocol does not reveal to the
servers which index this is. Otherwise, the servers reject the
write request.
Next, the servers must verify that the v vector is well-
formed. To do so, the servers compute another pair of test
vectors:
G(sA[i])
uB = v +
G(sB[i]).
x−1(cid:10)
uA =
i=0
x−1(cid:10)
i=0
The servers run AlmostEqual(uA, uB) and accept the write
request as valid if it returns “1.”
We prove security of this construction in the full version of
this paper.
An important implementation note is that if m = 0—
that is, if the client writes the string of all zeros into the
database—then the u vectors will not differ at any index and
this information is leaked to the auditor. The protocol only
provides security if the vectors differ at exactly one index. To
avoid this information leakage, client requests must be deﬁned
such that m (cid:8)= 0 in every write request. To achieve this, clients
could deﬁne some special non-zero value to indicate “zero” or
could use a padding scheme to ensure that zero values occur
with negligible probability.
As a practical matter, the audit server needs to be able to
match up the portions of write requests coming from server
A with those coming from server B. Riposte achieves this as
follows: When the client sends its upload request to server
A, the client includes a cryptographic hash of the request it
sent to server B (and vice versa). Both servers can use these
hashes to derive a common nonce for the request. When the
servers send audit requests to the audit server, they include
the nonce for the write request in question. The audit server
can use the nonce to match every audit request from server A
with the corresponding request from server B.
√
This three-party protocol is very efﬁcient—it only requires
O(
L) commu-
L) applications of a hash function and O(
nication from the servers to the auditor. The auditor only
performs a simple string comparison, so it needs minimal
computational and storage capabilities.
B. Zero Knowledge Techniques
√
Our second technique for detecting disruptors makes use of
non-interactive zero-knowledge proofs [11], [43], [70].
We apply zero-knowledge techniques to allow clients to
prove the well-formedness of their write requests. This tech-
nique works in combination with the (s, s− 1)-DPF presented
in Section IV-D and maintains client write-privacy when all
but one of s servers is dishonest.
The keys for the (s, s−1)-DPF scheme are tuples (bi, si, v)
such that:
s−1(cid:10)
s−1(cid:10)
si = s∗ · e(cid:2)x
v = m · e(cid:2)y − G(s∗
)
bi = e(cid:2)x
i=0
i=0
To prove that its write request was correctly formed, we
have the client perform zero-knowledge proofs over collections
of Pedersen commitments [68]. The public parameters for
the Pedersen commitment scheme consist of a group G of
prime order q and two generators P and Q of G such that
no one knows the discrete logarithm logQ P . A Pedersen
commitment to a message m ∈ Zq with randomness r ∈ Zq
is C(m, r) = (mP + rQ) ∈ G (writing the group operation
additively). Pedersen commitments are homomorphic, in that
given commitments to m0 and m1, it is possible to compute
a commitment to m0 + m1:
C(m0, r0) + C(m1, r1) = C(m0 + m1, r0 + r1)
Here, we assume that the (s, s− 1)-DPF is instantiated with
the DDH-based PRG introduced in Section IV-D and that the
group G used for the Pedersen commitments is the same order-
q group used in the PRG construction.
To execute the proof, the client ﬁrst generates Pedersen
commitments to elements of each of the s DPF keys. Then
each server i can verify that the client computed the com-
mitment to the i-th DPF key elements correctly. The servers
use the homomorphic property of Pedersen commitments to
generate commitments to the sum of the elements of the DPF
keys. Finally, the client proves in zero knowledge that these
sums have the correct values.
The protocols proceed as follows:
1) The client generates vectors of Pedersen commitments Bi
and Si committing to each element of bi and si. client
sends the B and S vectors to every server.
2) To server i, the client sends the opening of the commit-
ments Bi and Si. Each server i veriﬁes that Bi and Si
are valid commitments to the bi and si vectors in the
DPF key. If this check fails at some server i, server i
notiﬁes the other servers and all servers reject the write
request.
3) Using the homomorphic property of the commitments,
each server can compute vectors of commitments Bsum
and Ssum to the vectors Σ
s−1
i=0 bi and Σ
s−1
i=0 si.
4) Using a non-interactive zero-knowledge proof, the client
proves to the servers that Bsum and Ssum are commitments
to zero everywhere except at a single (secret) index (cid:2)x,
and that Bsum[(cid:2)x] is a commitment to one.1 This proof
uses standard witness hiding techniques for discrete-
logarithm-based zero knowledge proofs [11], [21]. If the
proof is valid, the servers continue to check the v vector.
1 Technically, this is a zero-knowledge proof of knowledge which proves
that the client knows an opening of the commitments to the stated values.
331331
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:07:16 UTC from IEEE Xplore.  Restrictions apply. 
This ﬁrst protocol convinces each server that the b and s
components of the DPF keys are well formed. Next, the servers
check the v component:
1) For each server i, the client sums up the seed values si it
s−1
j=0si[j]. The client then generates
sent to server i: σi = Σ
the output of G(σk) and blinds it:
Gi = (σiP1 + r1Q, σiP2 + r2Q, . . . ).
2) The client sends the G values to all servers and the client
sends the opening of Gi to each server i.
3) Each server veriﬁes that the openings are correct, and all
servers reject the write request if this check fails at any
server.
4) Using the homomorphic property of Pedersen commit-
ments, every server can compute a vector of commitments
s−1
i=0 Gi)+v. If v is well formed, then the Gsum
Gsum = (Σ
vector contain commitments to zero at every index except
one (at which it will contain a commitment to the client’s
message m).
5) The client uses a non-interactive zero-knowledge proof
to convince the servers that the vector of commitments
Gsum contains commitments to zero at all indexes except
one. If the proof is valid, the servers accept the write
request.
We prove in the full version of this paper that this protocol
satisﬁes the standard notions of soundness, completeness, and
zero-knowledge [12].
VI. EXPERIMENTAL EVALUATION
To demonstrate that Riposte is a practical platform for
trafﬁc-analysis-resistant anonymous messaging, we imple-
mented two variants of the system. The ﬁrst variant uses the
two-server distributed point function (Section IV-C) and uses
the three-party protocol (Section V-A) to prevent malicious
clients from corrupting the database. This variant is relatively
fast, since it relies primarily on symmetric-key primitives, but
requires that no two of the three servers collude. Our results for
the ﬁrst variant include the cost of identifying and excluding
malicious clients.
The second variant uses the s-server distributed point func-
tion (Section IV-D). This variant protects against s− 1 collud-
ing servers, but relies on expensive public-key operations. We
have not implemented the zero-knowledge proofs necessary to
prevent disruptors for the s-server protocol (Section V-B), so
the performance numbers represent only an upper bound on
the system throughput.
We wrote the prototype in the Go programming language
and have published the source code online at https://bitbucket.
org/henrycg/riposte/. We used the DeterLab network testbed
for our experiments [58]. All of the experiments used com-
modity servers running Ubuntu 14.04 with four-core AES-NI-
enabled Intel E3-1260L CPUs and 16 GB of RAM.
Our experimental network topology used between two and
ten servers (depending on the protocol variant in use) and
eight client nodes. In each of these experiments, the eight
client machines used many threads of execution to submit
 1000
 100
 10
)
c
e
s
/
s
t
s
e
u
q
e
r
t
n
e
t
u
p
h
g
u
o
r
h
T
i
l
c
(
 1
10 
Actual throughput
Maximum TLS throughput
Maximum AES throughput
100 
Database table size (# of 160-byte rows)
100k
10k
1M
1k
10M
Fig. 3: As the database table size grows, the throughput of
our system approaches the maximum possible given the AES
throughput of our servers.
write requests to the servers as quickly as possible. In all
experiments, the server nodes connected to a common switch
via 100 Mbps links, the clients nodes connected to a common
switch via 1 Gbps links, and the client and server switches
connected via a 1 Gbps link. The round-trip network latency
between each pair of nodes was 20 ms. We chose this network
topology to limit the bandwidth between the servers to that of
a fast WAN, but to leave client bandwidth unlimited so that
the small number of client machines could saturate the servers
with write requests.
Error bars in the charts indicate the standard deviation of
the throughput measurements.
A. Three-Server Protocol
A three-server Riposte cluster consists of two database
servers and one audit server. The system maintains its security
properties as long as no two of these three servers collude. We
have fully implemented the three-server protocol, including the
audit protocol (Section V-A), so the throughput numbers listed
here include the cost of detecting and rejecting malicious write
requests.
The prototype used AES-128 in counter mode as the
pseudo-random generator, Poly1305 as the keyed hash func-
tion used in the audit protocol [7], and TLS for link encryption.
Figure 3 shows how many client write requests our Riposte
cluster can service per second as the number of 160-byte rows
in the database table grows. For a database table of 64 rows,
the system handles 751.5 write requests per second. At a table
size of 65,536 rows, the system handles 32.8 requests per
second. At a table size of 1,048,576 rows, the system handles
2.86 requests per second.
We chose the row length of 160 bytes because it was the
smallest multiple of 32 bytes large enough to to contain a
140-byte Tweet. Throughput of the system depends only the
total size of the table (number of rows × row length), so
larger row lengths might be preferable for other applications.
For example, an anonymous email system using Riposte with
4096-byte rows could handle 2.86 requests per second at a
table size of 40,960 rows.
An upper bound on the performance of the system is the
speed of the pseudo-random generator used to stretch out the
332332
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:07:16 UTC from IEEE Xplore.  Restrictions apply. 
)
c
e
s
/
s
t
s
e
u
q
e
r