if (x < array1_size) {
y = array1[x];
// do something using y that is
// observable when speculatively
// executed
}
VII. MITIGATION OPTIONS
Several countermeasures for Spectre attacks have been
proposed. Each addresses one or more of the features that
the attack relies upon. We now discuss these countermeasures
and their applicability, effectiveness, and cost.
A. Preventing Speculative Execution
Speculative execution is required for Spectre attacks. En-
suring that instructions are executed only when the control
ﬂow leading to them is ascertained would prevent speculative
execution and, with it, Spectre attacks. While effective as a
countermeasure, preventing speculative execution would cause
a signiﬁcant degradation in the performance of the processor.
Although current processors do not appear to have methods
that allow software to disable speculative execution, such
modes could be added in future processors, or in some
cases could potentially be introduced via microcode changes.
Alternatively, some hardware products (such as embedded
systems) could switch to alternate processor models that do not
implement speculative execution. Still, this solution is unlikely
to provide an immediate ﬁx to the problem.
Alternatively, the software could be modiﬁed to use seri-
alizing or speculation blocking instructions that ensure that
instructions following them are not executed speculatively.
Intel and AMD recommend the use of the lfence instruc-
tion [4, 36]. The safest (but slowest) approach to protect condi-
tional branches would be to add such an instruction on the two
outcomes of every conditional branch. However, this amounts
to disabling branch prediction and our tests indicate that this
would dramatically reduce performance [36]. An improved
approach is to use static analysis [36] to reduce the number
of speculation blocking instructions required, since many code
paths do not have the potential to read and leak out-of-bounds
memory. In contrast, Microsoft’s C compiler MSVC [54] takes
an approach of defaulting to unprotected code unless the static
analyzer detects a known-bad code pattern, but as a result
misses many vulnerable code patterns [40].
Inserting serializing instructions can also help mitigating
indirect branch poisoning. Inserting an lfence instruction
before an indirect branch ensures that the pipeline prior to the
branch is cleared and that the branch is resolved quickly [4].
This, in turn, reduces the number of instructions that are
executed speculatively in the case that the branch is poisoned.
The approach requires that all potentially vulnerable soft-
ware is instrumented. Hence, for protection, updated software
binaries and libraries are required. This could be an issue for
legacy software.
B. Preventing Access to Secret Data
Other countermeasures can prevent speculatively executed
code from accessing secret data. One such measure, used by
the Google Chrome web browser, is to execute each web
site in a separate process [67]. Because Spectre attacks only
leverage the victim’s permissions, an attack such as the one
we performed using JavaScript (cf. Section IV-C) would not
be able to access data from the processes assigned to other
websites.
WebKit employs two strategies for limiting access to secret
data by speculatively executed code [57]. The ﬁrst strategy
replaces array bounds checking with index masking. Instead
of checking that an array index is within the bounds of the
array, WebKit applies a bit mask to the index, ensuring that
it is not much bigger than the array size. While masking may
result in access outside the bounds of the array, this limits the
distance of the bounds violation, preventing the attacker from
accessing arbitrary memory.
The second strategy protects access to pointers by xoring
them with a pseudo-random poison value. The poison protects
the pointers in two distinct ways. First, an adversary who
does not know the poison value cannot use a poisoned pointer
(although various cache attacks could leak the poison value).
More signiﬁcantly, the poison value ensures that mispredic-
tions on the branch instructions used for type checks will result
in pointers associated with type being used for another type.
These approaches are most useful for just-in-time (JIT)
compilers, interpreters, and other language-based protections,
(cid:18)(cid:19)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:46:03 UTC from IEEE Xplore.  Restrictions apply. 
where the runtime environment has control over the executed
code and wishes to restrict the data that a program may access.
C. Preventing Data from Entering Covert Channels
Future processors could potentially track whether data was
fetched as the result of a speculative operation and, if so,
prevent that data from being used in subsequent operations
that might leak it. Current processors do not generally have
this capability, however.
D. Limiting Data Extraction from Covert Channels
To exﬁltrate information from transient instructions, Spectre
attacks use a covert communication channel. Multiple ap-
proaches have been suggested for mitigating such channels
(cf. [19]). As an attempted mitigation for our JavaScript-based
attack, major browser providers have further degraded the
resolution of the JavaScript timer, potentially adding jitter [50,
57, 66, 71]. These patches also disable SharedArrayBuffers,
which can be used to create a timing source [60].
While this countermeasure would necessitate additional
averaging for attacks such as the one in Section IV-C, the level
of protection it provides is unclear since error sources simply
reduce the rate at which attackers can exﬁltrate data. Further-
more, as [18] show, current processors lack the mechanisms
required for complete covert channel elimination. Hence, while
this approach may decrease attack performance, it does not
guarantee that attacks are not possible.
E. Preventing Branch Poisoning
To prevent indirect branch poisoning, Intel and AMD ex-
tended the ISA with a mechanism for controlling indirect
branches [4, 34]. The mechanism consists of three controls.
The ﬁrst, Indirect Branch Restricted Speculation (IBRS), pre-
vents indirect branches in privileged code from being affected
by branches in less privileged code. The processor enters a spe-
cial IBRS mode, which is not inﬂuenced by any computations
outside of IBRS modes. The second, Single Thread Indirect
Branch Prediction (STIBP), restricts branch prediction sharing
between software executing on the hyperthreads of the same
core. Finally, Indirect Branch Predictor Barrier (IBPB), pre-
vents software running before setting the barrier from affecting
branch prediction by software running after the barrier, i.e., by
ﬂushing the BTB state. These controls are enabled following a
microcode patch and require operating system or BIOS support
for use. The performance impact varies from a few percent to a
factor of 4 or more, depending on which countermeasures are
employed, how comprehensively they are applied (e.g. limited
use in the kernel vs. full protection for all processes), and the
efﬁciency of the hardware and microcode implementations.
Google suggests an alternative mechanism for preventing
indirect branch poisoning called retpolines [70]. A retpoline
is a code sequence that replaces indirect branches with return
instructions. The construct further contains code that makes
sure that the return instruction is predicted to a benign endless
loop through the return stack buffer, while the actual target
destination is reached by pushing it on the stack and returning
(cid:18)(cid:20)
to it i.e., using the ret instruction. When return instructions
can be predicted by other means the method may be impracti-
cal. Intel issued microcode updates for some processors, which
fall-back to the BTB for the prediction, to disable this fall-back
mechanism [36].
VIII. CONCLUSIONS
A fundamental assumption underpinning software security
techniques is that the processor will faithfully execute program
instructions, including its safety checks. This paper presents
Spectre attacks, which leverage the fact that speculative execu-
tion violates this assumption. The techniques we demonstrate
are practical, do not require any software vulnerabilities, and
allow adversaries to read private memory and register contents
from other processes and security contexts.
Software security fundamentally depends on having a clear
common understanding between hardware and software devel-
opers as to what information CPU implementations are (and
are not) permitted to expose from computations. As a result,
while the countermeasures described in the previous section
may help limit practical exploits in the short term, they are
only stop-gap measures since there is typically formal archi-
tectural assurance as to whether any speciﬁc code construction
is safe across today’s processors – much less future designs.
As a result, we believe that long-term solutions will require
fundamentally changing instruction set architectures.
More broadly, there are trade-offs between security and
performance. The vulnerabilities in this paper, as well as many
others, arise from a long-standing focus in the technology
industry on maximizing performance. As a result, processors,
compilers, device drivers, operating systems, and numerous
other critical components have evolved compounding layers
of complex optimizations that introduce security risks. As the
costs of insecurity rise, these design choices need to be revis-
ited. In many cases, alternative implementations optimized for
security will be required.
IX. ACKNOWLEDGMENTS
Several authors of this paper found Spectre independently,
ultimately leading to this collaboration. We thank Mark Brand
from Google Project Zero for contributing ideas. We thank
Intel for their professional handling of this issue through
communicating a clear timeline and connecting all involved
researchers. We thank ARM for technical discussions on
aspects of this issue. We thank Qualcomm and other vendors
for their fast response upon disclosing the issue. Finally, we
want to thank our reviewers for their valuable comments.
Daniel Gruss, Moritz Lipp, Stefan Mangard and Michael
Schwarz were supported by the European Research Council
(ERC) under the European Union’s Horizon 2020 research
and innovation programme (grant agreement No 681402).
Daniel Genkin was supported by NSF awards #1514261
and #1652259, ﬁnancial assistance award 70NANB15H328
from the U.S. Department of Commerce, National Institute of
Standards and Technology, the 2017-2018 Rothschild Postdoc-
toral Fellowship, and the Defense Advanced Research Project
Agency (DARPA) under Contract #FA8650-16-C-7622.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:46:03 UTC from IEEE Xplore.  Restrictions apply. 
REFERENCES
[1] O. Acıic¸mez, S. Gueron, and J.-P. Seifert, “New Branch
Prediction Vulnerabilities in OpenSSL and Necessary
Software Countermeasures,” in International Conference
on Cryptography and Coding (IMA), 2007.
[2] O. Acıic¸mez, C¸ etin Kaya. Koc¸, and J.-P. Seifert, “Pre-
dicting Secret Keys Via Branch Prediction,” in CT-RSA,
2007.
[3] O. Acıic¸mez, “Yet another MicroArchitectural Attack: :
exploiting I-Cache,” in CSAW, 2007.
Micro
for
[4] Advanced
Techniques
AMD
able:
12/Managing-Speculation-on-AMD-Processors.pdf
“Software
on
Avail-
http://developer.amd.com/wordpress/media/2013/
Inc.,
Speculation
[Online].
Devices,
Managing
2018.
Processors,”
[5] Aleph One, “Smashing the stack for fun and proﬁt,”
Phrack, vol. 49, 1996.
[6] M. Andrysco, D. Kohlbrenner, K. Mowery, R. Jhala,
S. Lerner, and H. Shacham, “On Subnormal Floating
Point and Abnormal Timing,” in S&P, 2015.
[7] ARM, “Cortex-A9 Technical Reference Manual, Revi-
sion r4p1, Section 11.4.1,” 2012.
[8] D. J. Bernstein, “Cache-Timing Attacks on AES,”
[Online]. Available: http://cr.yp.to/antiforgery/
2005.
cachetiming-20050414.pdf
[9] S. Bhattacharya, C. Maurice,
and
D. Mukhopadhyay,
“Template Attack on Blinded
Scalar Multiplication with Asynchronous perf-ioctl
Calls,” Cryptology ePrint Archive, 2017/968, 2017.
S. Bhasin,
[10] F. Brasser, U. M¨uller, A. Dmitrienko, K. Kostiainen,
S. Capkun, and A. Sadeghi, “Software Grand Exposure:
SGX Cache Attacks Are Practical,” in WOOT, 2017.
[11] C. Disselkoen, D. Kohlbrenner, L. Porter, and D. M.
Tullsen, “Prime+Abort: A Timer-Free High-Precision L3
Cache Attack using Intel TSX,” in USENIX Security
Symposium, 2017.
[12] I. Dobrovitski, “Exploit for CVS double free() for Linux
pserver,” 2003. [Online]. Available: http://seclists.org/
fulldisclosure/2003/Feb/36
[13] ECMA International, “ECMAScript Language Speciﬁca-
tion - Version 5.1,” Standard ECMA-262, Jun. 2011.
[14] D. Evtyushkin, D. V. Ponomarev, and N. B. Abu-
Ghazaleh, “Jump over ASLR: Attacking branch predic-
tors to bypass ASLR,” in MICRO, 2016.
[15] A. Fog, “The Microarchitecture of Intel, AMD and
[Online]. Available: http:
VIA CPUs,” May 2017.
//www.agner.org/optimize/microarchitecture.pdf
Fogh,
“Row
script
[16] A.
and
Avail-
able: https://dreamsofastone.blogspot.com/2016/02/row-
hammer-java-script-and-mesi.html
[Online].
hammer,
MESI,”
2016.
java
[17] ——,
“Negative Result: Reading Kernel Mem-
ory
From
[Online].
Available: https://cyber.wtf/2017/07/28/negative-result-
reading-kernel-memory-from-user-mode/
User Mode,”
2017.
[18] Q. Ge, Y. Yarom, and G. Heiser, “Your Processor Leaks
Information - and There’s Nothing You Can Do About
It,” arXiv:1612.04474, 2017.
[19] Q. Ge, Y. Yarom, D. Cock, and G. Heiser, “A survey of
microarchitectural timing attacks and countermeasures on
contemporary hardware,” J. Cryptographic Engineering,
vol. 8, no. 1, pp. 1–27, 2018.
[20] D. Genkin, A. Shamir, and E. Tromer, “RSA Key Ex-
traction via Low-Bandwidth Acoustic Cryptanalysis,” in
CRYPTO, 2014.
[21] D. Genkin, L. Pachmanov, I. Pipman, A. Shamir, and
E. Tromer, “Physical key extraction attacks on PCs,”
Commun. ACM, vol. 59, no. 6, pp. 70–79, 2016.
[22] D. Genkin, L. Pachmanov, I. Pipman, E. Tromer, and
Y. Yarom, “ECDSA Key Extraction from Mobile Devices
via Nonintrusive Physical Side Channels,” in CCS, 2016.
[23] D. Genkin, L. Pachmanov, E. Tromer, and Y. Yarom,
“Drive-by Key-Extraction Cache Attacks from Portable
Code,” in ACNS, 2018.
[24] B. Gras, K. Razavi, E. Bosman, H. Bos, and C. Giuffrida,
“ASLR on the Line: Practical Cache Attacks on the
MMU,” in NDSS, 2017.
[25] D. Gruss, R. Spreitzer, and S. Mangard, “Cache Template
Attacks: Automating Attacks on Inclusive Last-Level
Caches,” in USENIX Security Symposium, 2015.
[26] D. Gruss, C. Maurice, A. Fogh, M. Lipp, and S. Mangard,
“Prefetch Side-Channel Attacks: Bypassing SMAP and
Kernel ASLR,” in CCS, 2016.
[27] D. Gruss, C. Maurice, and S. Mangard, “Rowhammer.js:
A Remote Software-Induced Fault Attack in JavaScript,”
in DIMVA, 2016.
[28] D. Gruss, C. Maurice, K. Wagner, and S. Mangard,
“Flush+Flush: A Fast and Stealthy Cache Attack,” in
DIMVA, 2016.
[29] D. Gruss, M. Lipp, M. Schwarz, R. Fellner, C. Maurice,
and S. Mangard, “KASLR is Dead: Long Live KASLR,”
in ESSoS, 2017.
[30] D. Gullasch, E. Bangerter, and S. Krenn, “Cache Games
- Bringing Access-Based Cache Attacks on AES to
Practice,” in S&P, 2011.
2018.
bypass,”
[31] J. Horn, “speculative execution, variant 4: speculative
store
https://
bugs.chromium.org/p/project-zero/issues/detail?id=1528
[32] M. S. Inci, B. G¨ulmezoglu, G. Irazoqui, T. Eisenbarth,
and B. Sunar, “Cache Attacks Enable Bulk Key Recovery
on the Cloud,” in CHES, 2016.
[Online]. Available:
[33] Intel