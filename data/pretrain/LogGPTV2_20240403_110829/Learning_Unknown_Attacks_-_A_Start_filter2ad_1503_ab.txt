Enclave 
LAN & 
WAN
Connection 
Connection 
Connection 
Manager
Manager
Manager
Protection 
Protection 
Protection 
Wrapper
Wrapper
Wrapper
IIS
IIS
IIS
SNORT
SNORT
Host
Host
Firewall
Firewall
IP Switch
IP Switch
FW Co ntroller
FW Co ntroller
Backup    
Backup    
Tripwire
Tripwire
Connection 
Connection 
Connection 
Manager
Manager
Manager
Protection 
Protection 
Protection 
Wrapper
Wrapper
Wrapper
Apache
Apache
Apache
SNORT
SNORT
Host
Host
Application
Application
Monitor
Monitor
Application
Application
Monitor
Monitor
Monitor
Monitor
Monitor
Monitor
Policy
Policy
Server
Server
Policy
Policy
Editor
Editor
MAC
MAC
Operator
Operator
Display
Display
Buffer &
Buffer &
Log
Log
Out-of-Band Controller
Out-of-Band Controller
Content
Content
Filter
Filter
Circular
Circular
Buffer
Buffer
Offline Backup
(Spare/Fishbowl)
Primary
Primary
Backup
Backup
Duplicate
Duplicate
Duplicate
Duplicate
Generalizer
Generalizer
Sandbox
Sandbox
Forensics
Forensics
Analyzer
Analyzer
Other Controllers
Out-of-Band Communication Mediator
Out-of-Band Communication Mediator
Fig. 3.  Simplified software architecture
Wrappers are used to monitor and strictly control  an  application’s  ability  to  read
and  write  files,  execute  or  kill  other  processes,  modify  registry  entries,  change
memory  protection,  etc.  Any  violations  trigger  an  alert  and  failover  response.  The
host  monitor  allows  only  specified  processes  to  run  and  ensures  that  allowed
processes do not consume more resources than allowed. It also monitors application
liveness and generates a heartbeat for the Controller. The out-of-band communication
mediator ensures that only authorized processes use the out-of-band communications
network to attack the mediator-adapter-controller (MAC) or any other software on the
controller machine. Integrity of control messages is enhanced with digital signatures.
The MAC monitors responses from both servers and periodically orders a “self test”
164
J.E. Just et al.
through the Host Monitor (HM). This entails issuing a known request to the servers
and checking its response against the known response.
The Out-of-Band Communication Mediator shown in Figure 3 is implemented by
host firewalls (specifically the firewall by Tiny Software Inc.) on each machine. They
only allow access to the server from the OOB machine by authorized programs like
the  MAC  through  authorized  ports  and  only  allow  access  to/from  the  gateway
machine through port 80. Similarly, they only allow access to the OOB machine from
the server by authorized programs like the wrappers and the HM through authorized
ports.  To  change  this  configuration,  a  user  must  enter  a  password  at  the  server’s
keyboard. An attacker would have to gain system privileges and by-pass or shutdown
the  host  firewall  to  have  access  to  the  OOB  machine.  Creating  an  unauthorized
process to remove a file would trigger an “Unhealthy” state by the HM and cause a
failover and clean-up of the “Unhealthy” machine.
One of our innovations is that the Controller also performs random rejuvenation of
each server on an average interval that is set by policy. During random rejuvenation,
the Controller takes the selected machine off-line, performs the appropriate failover,
starts  up  a  new  process  pair  with  the  spare  machine,  shuts  down  and  restarts  all
applications on the rejuvenating machine, runs an integrity check on its files, and sets
it up as an on-line spare when it is done. This techniques was originally intended to
preserve the performance of the hosts and  applications  but  it  turns  out  to  be  a very
powerful to avert latent successful attacks that have not been detected. It also limits
the  required  size  of  the  history  buffer  and  limits  the  ability  of  any  attack  to  go
undetected.
3   The Problem of Unknown Attacks
Since  we  cannot  ensure  that  software  has  no  vulnerabilities,  there  will  be  unknown
attacks that can succeed against the cluster. Our behavior specifications are tight but
bad behavior must be observed by the wrappers or other sensors. An unknown attack
can sneak past the defenses and compromise the protected web server. If the attack is
stealthy  enough  to  not  execute  any  unauthorized  processes,  write  any  unauthorized
files or use too much cpu or memory, it can remain undetected and active  until  the
next random rejuvenation cycle when the system is purged.
While the emphasis of HACQIT is on availability of critical services, we need to
say a few words about what an attacker can do in the above circumstances and what
the  countermeasures  would  be.  First  it  would  be  easy  to  corrupt  the  critical
application data since the web enabled application has permission to write to that file.
The  solution  to  this  is  a  secure  storage  system  such  as  that  developed  under  the
Perpetually  Available  and  Secure  Information  Storage  (PASIS)  [10,  11].  Such  a
storage system captures all changes to files in a host-independent and secure manner.
This enables recovery from such incidents.
Another  possibility  would  be  for  the  attacker  to  simply  monitor  what  was
happening  within  the  application  (spy)  and  exfiltrate  data.  Since  the  most  likely
avenue  of  attack  is  by  compromising  a  critical  user  machine,  the  attacker  would
effectively  have  access  to  the  critical  application  and  data  anyway.  This  essentially
becomes the insider problem. Exfiltration via other routes is difficult because of the
firewall settings and isolation of the cluster.
Learning Unknown Attacks – A Start
165
For the purposes of critical application availability, the central concern is that an
attacker has found an unknown attack that can be used to penetrate the cluster. Such
an attack can be used to shutdown the vulnerable web server or the application behind
it. The HACQIT goal is to maintain at least 75% availability in the face of on-going
attacks.  For  the  attacker  to  win,  all  that  he/she  must  do  is  to  find  a  small  set  of
vulnerabilities in each of the diverse web servers or other critical applications. This
essentially guarantees that the attacker will succeed in shutting down the cluster more
than 25% of the time. As long as that vulnerability remains and the exploit succeeds,
the attacker can just keep hitting the cluster with it and cause another failover. It does
not matter how  expensive  these  vulnerabilities  are  to  find,  once  they  are  found  and
exploits  developed  for  them,  the  time  to  launch  successive  attacks  is  minimal.  The
results of this will be devastating on the defenders.
Even if the IP address of the attacker is blocked or that user cut off in other ways,
the attacker can always come back unless the cluster is cut off from users. Such an
action amounts to a self-inflicted denial of service and is clearly unacceptable. Since
the  attacker  has  the  ability  to  automate  his  attack,  even  physically  capturing  the
attacker would not necessarily stop the attacks. Since it takes time to clean up a server
after an attack before it can be put back into service with any confidence, unless the
cluster has an indefinitely large number of backup servers for failover, it seems like a
losing game for the defender. If the attacker has found a simple, inexpensive way to
vary the attack signature, the problem becomes even more difficult for the defender
Can this problem be fixed? In principle there is no solution.  But, as the reader will
see, we are using classical machine learning methods (using observed instances of the
attack to learn the most general description of an attack that has variants, followed by
the  most  general  blocking  rules)  combined  with  the  use  of  sandbox  to  experiment
offline with the observed instances to create other instances. Short of analyzing source
(or object) code, that’s the best we can do, and it is likely to be very effective. Our
experiences with Code red and its variants can attest to this.
4   Solution Concept
Cyber  attacks  (network-based  intrusions  into  a  system)  have  several  important
differences from other natural or man-made faults: They are repeatable, they are not
random (although certain types of  attacks  may depend  on  timing  of  events),  and,  if
known,  they  can  be  filtered  out  at  system  or  sub-system  boundaries.  These
distinctions enabled us to develop a set of learning techniques to help deal with the
unknown attack problem. 
Given an observed failure on a cluster server, our goal is to identify an attack in the
recorded  cluster  traffic.  Repeatability  of  the  attack  against  the  critical  application
server is the key criteria of an attack, particularly given the difficulty of establishing
malicious intent. We developed a set of components that learn an attack after it is first
used, develop blocking filters against it, and generalize those filters to disallow simple
variants of the attack that depend upon the same vulnerability. By preventing reuse of
an unknown attack, would-be adversaries are forced to develop a large number of new
attacks to defeat the cluster for any significant period. This raises the bar significantly
on  the  amount  of  effort  that  an  adversary  must  expend  to  achieve  more  than
momentary success. 
166
J.E. Just et al.
Clusters can communicate with one another so that the protective filters developed
at one site can be propagated to clusters at other sites that have not yet experienced
the  same  attack.  This  ability  to do  group  learning  is  a  very  powerful  feature  of  the
design and implementation.
The  information  necessary  for  the  forensics  based  learning  system  to  work  is
provided by several key components  including  (1)  logs  of  all  network  inputs  to  the
cluster  for,  at  least,  the  last  N  minutes,  (2)  logs  of  all  system  sensor  readings  and
responses  that  indicate  errors  or  failures  in  components,  and  (3)  a  “Sandbox”  for
testing attack patterns and filters. The Sandbox is an isolated duplicate of the critical
application servers, i.e., the redundant process-pair software, sensors, and hardware.
Note that it is most effective if the number of minutes of buffering (N) is equal to or
slightly  greater  than  the  number  of  minutes  between  random  rejuvenation.  Search
speed is obvious faster if N is a smaller number of minutes rather than larger.
Our approach to identifying, learning, and blocking unknown attacks begins when
an error (i.e., a deviation from specified behavior)) is observed in the cluster, usually
associated with the critical application. It proceeds in parallel with  and  independent
from the failover process that guarantees continuity of service. 
Since our goal is to prevent the success of future versions of this newly observed
unknown  attack,  it  is  not  necessary  to  understand  the  details  of  the  attack  after  the
initiating event that puts  control  into  the  attacker’s  code.  What  we  want  to  do  is  to
prevent the initiating event, which is often a buffer overflow, and we would like to do
this as quickly as possible. 
While  it  is  useful  to  have  a  general  process  with  guaranteed  convergence  to  a
solution, the practical aspects of the time required to test many hypotheses of attack
sequences against a Sandboxed application are formidable. It can take several minutes
to  restart  some  applications  after  a  failure  and  some  applications  cannot  be  run  in
multiple  processes  on  the  same  computer.  Our  more  practicable  approach  involves
examining a variety of heuristics and specification / model-based protocol analyzers
that can be used to shrink the search space of suspect connection requests to a very
small number of candidates that must be verified in the Sandbox.
Given the observer error in the cluster, the essential functional steps in our learning
and  generalization  “algorithm”  are  shown  in  Table  1.  The  first  two  steps  rapidly
produce an initial filter rule that blocks the previously unknown attack. The remaining
steps  then  incrementally  improve  the  rules  by  shortening  and  generalizing  them  if
possible.
A  few  caveats  are  required  before proceeding.  Since  we  are  dealing  with  Turing
complete  languages  and  machines,  Rice’s  theorem  implies  that  we  cannot  prove
intrusion tolerance for the system. Nevertheless, within the assumptions imposed on
the system model, we believe we can deliver very useful and usable results.
The  fundamental  metric  in  determining  the  success  or  failure  of  the  HACQIT
cluster  is  whether  an  attacker  can  generate  an  effective  attack  rate  higher  than  the
cluster’s effective learning and generalization rate. Intrusion resistance and intrusion
tolerance don’t have to be perfect. They just have to be good enough to convince the
attackers to try a different, less expensive approach.
There  are  also  several  responses  that  the  cluster  controller  can  take  to  thwart
attacker or to make learning easier. For example, random rejuvenation can be used to
force an attacker to start over again with a stealthy attack. It is also useful for limiting
the size of the history file that must be analyzed after  a  successful  attack. It  is  also
possible  to  cut  off  the  attacker  or  “excessive  user”  via  blocking  his  IP  address  at
Learning Unknown Attacks – A Start
167
cluster or enclave level firewall. Since all users come into the cluster over a VPN and
spoofing is not possible, this is particularly effective if the address or user ID of the
attacker  can  be  learned  from  the  captured  attack  sequence  in  the  history  log.  All