本节将通过 Flink 官网上的例子，从建立 Flink 项目开始，在 Flink 群集上运行流式分析程
$(flink.version)
flink-java
org.apache.flink
增加Maven依赖
JavaAPI的使用
#
TaskManager
TaskSlot
图7-14Flink的任务槽示意图
仅供非商业用途或交流学习使用
Gource
Threads
TaskManager
TaskSlot
第7章实时计算框架
Task
Slot
121
---
## Page 149
public class WikipediaAnalysis{
import
import
import
import
import
import
package
import
import
import
122
public static void main(String[] args) throws Exception {
KeyedStream keyedEdits = edits
3
org.apache.flink.streaming.connectors.wikiedits.WikipediaEditsSource;
org.apache.flink.streaming.connectors.wikiedits.WikipediaEditEvent;
org.apache.flink.streaming.api.windowing.time.Time;
org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
org.apache.flink.streaming.api.datastream.KeyedStream;
org.apache.flink.streaming.api.datastream.DataStream;
org.apache.flink.api.java.tuple.Tuple2;
org.apache.flink.api.java.functions.KeySelector;
org.apache.flink.api.common.functions.FoldFunction;
wikiedits;
开发程序
$(flink.version)
flink-connector-wikiedits_2.1l
org.apache.flink
$(flink.version)
flink-clients_2.1l
org.apache.flink
$(flink.version)
flink-streaming-java_2.11
org.apache.flink
智能运维：从0搭建大规模分布式 AIOps 系统
仅供非商业用途或交流学习使用
---
## Page 150
S
Long>>(）{
V
V
V
V
V
V
mvn exec:java -Dexec.mainClass=wikiedits.WikipediaAnalysis
mvn clean package
(KasparBot,-245)
(Ms Sarah Welch,269)
(Vuyisa2001,79)
(Narutolovehinata5,2195)
(Slade360,0)
(Ckh3111,69)
(IgnorantArmies,49)
(BD2412bot,-3690)
(AnomieBOT,155)
(Fenix down,114)
5．结果展示
4.本地运行
see.execute();
result.print();
DataStream> result = keyedEdits
!（{
.fold(new Tuple2<>("", OL), new FoldFunction()(
public Tuple2 fold(Tuple2
acc, WikipediaEditEvent event)
第7章实时计算框架
Tuple2>(）{
DataStream> result =keyedEdits
//对每一个用户在这个时间窗口内的编辑字节数据进行计算
//我们已经将用户按照用户名分组了，现在按照5秒的时间窗口进行分用户统计，窗口采用折叠转换模式
KeyedStreamkeyedEdits =edits
//同一个流中进行计算，这里采用 KeyBy 的转换通过用户名进行分组
//因为要计算每个用户在给定窗口时间内编辑的字节数，所以需要对用户分组，将同一个用户的数据分组到
DataStream edits = see.addSource(new WikipediaEditsSource());
主要方法中：
为 ExecutionEnvironment），用来设置执行参数并创建来自外部系统的读取源。我们将其添加到
）;
（
124
接下来要做的就是将流打印到控制台并开始执行。
.fold(new
.timeWindow(Time.seconds(5))
.keyBy(new KeySelector(){
广告在任何互联网公司都是核心业务，直接关系到公司的收入。微博广告收入占微博收入
Flink程序首先创建了一个 StreamExecutionEnvironment（如果你正在编写批处理作业，则
6．程序解释
(
@Override
public String getKey(WikipediaEditEvent event)(
@Override
智能运维：从O搭建大规模分布式AIOps系统
案例分析
return acc;
acc.f1 += event.getByteDiff();
acc.f0=event.getUser();
return event.getUser();
Tuple2<>(""，OL)，
newFoldFunction<WikipediaEditEvent,
仅供非商业用途或交流学习使用
Tuple2<String,
---
## Page 152
询性能。所以最终选择采用ClickHouse 存储。
范围过大的情况下，查询性能也是不可忍受的；ClickHouse 支持实时写入，并且拥有超强的查
量高，但是查询性能不能胜任；相对于 HBase，Druid 的查询比较灵活，但是在单个维度枚举值
间窗口的特性，所以最终采用 Flink计算引擎。
JStorm、Spark Streaming、Flink 等实时引擎。由于Flink具有低延迟、高吞吐量、高度灵活的时
实现了消息顺序和海量存储。使用Kafka 消息队列极大地提高了计算的横向扩展能力。
实现复杂均衡。因为在设计之初Kafka 是作为日志流平台和运营消息管道平台来使用的，所以
的吞吐速率；完全的分布式系统，Broker、Producer、Consumer 都原生自动支持分布式，自动
可以在O(1)的系统开销下进行消息持久化;高吞吐量,在一台普通的服务器上即可以达到10W/s
订阅消息队列系统，消费者通过拉取方式消费消息。Kafka 消息中间件的特性：快速持久化,
将这些信息转发到消息队列、Elasticsearch 或者Logstash 中存放。
会监控日志目录或者指定的日志文件，追踪读取这些文件（追踪文件的变化，不停地读)，并且
主要采用Filebeat来完成。Filebeat是一个日志文件托运工具，在服务器上安装客户端后，Filebeat
7.4.1
曝光、互动、结算等数据进行实时监控。
告的请求量在百亿级别以上,并且涉及的产品线较多。我们需要对微博产品各个产品线的请求、
告、竞价广告、效果广告等包含超粉、品牌广告、涨粉、非粉、粉丝头条等广告产品。微博广
的 80%，为此广告投放系统的健康度及投放效果的重要性就相当突出了。微博广告分为保量广
一个分布式流平台，现在是 Apache 的顶级项目，是一个高性能的、跨语言的、分布式的发布
数据存储决定了响应的速度，存储可选择 HBase、Druid、ClickHouse。HBase 的写入吞吐
4.数据如何存储及技术选型
计算引擎通过消息队列的数据进行计算。微博广告有自研的计算引擎OLS、阿里巴巴的
3.数据如何计算及技术选型
数据传输采用Kafka 消息中间件来完成。Kafka是LinkedIn于2010年12月开发并开源的
2.数据如何传输及技术选型
数据采集是数据计算的第一个环节，准确地采集数据是计算的基础。微博广告数据的采集
1．监控数据如何采集及技术选型
背景介绍
第7章实时计算框架
125
---
## Page 153
7.6
及简单使用。通过对微博广告监控实时应用的架构进行分析，可以更好地帮助读者理解实时计
述。本章还介绍了 Spark Streaming 和 Flink 分布式实时计算引擎的背景、基本概念、运行原理
7.5
CPE等。
价类型、地域、性别、年龄、创意类型等；监控指标包括曝光、请求、互动、CPM、ECPM、
增幅超过100%。监控业务包括超粉、品速、粉丝经济、结算等；监控维度包括平台、场景、竞
7.4.3
好地服务于计算，查询引擎ClickHouse 能够在计算结果上进行多维度的业务分析。
错。消息队列和存储都有备份机制来防止数据丢失，计算引擎 Flink 的出色的计算能力可以更
7.4.2
126
[1] Spark 官网: htp:/spark.apache.org/docs/latest/streaming-programming-guide.html
本章主要对实时计算进行了简要说明，对实时计算的实时性、准确性、响应速度进行了阐
在可靠而又稳定的监控报警平台支持下，2017年广告的监控报警指标快速增长，监控指标
[2] Flink 官网: http://link.apache.org/
综合考虑数据采集、传输、计算，因此整体架构采用分布式系统设计，支持横向扩展、容
参考文献
本章小结
智能运维：从O搭建大规模分布式AIOps系统
效果分析
架构设计
仅供非商业用途或交流学习使用
---
## Page 154
到多维查询、指标聚合等。图8-1展示了某服务最近6小时的QPS 走势。
的高性能。此外，对于一些复杂的场景，比如广告业务的多维度多指标，时序数据库还需要做
够长时间保存数据，且需要实时展示，这就要求时序数据库能做到持久化存储，以及数据读写
时间内的走势和规律，帮助定位数据异常点。
据，再通过时间坐标将这些数据连接起来，形成一个折线图，直观地展示一个指标在过去一段
8.1.1什么是时序数据库
8.1时序数据库简介
时序数据库就是用来存储这些时序数据的数据库。与传统数据库相比，时序数据库需要能
在介绍时序数据库之前，我们先来看看什么是时序数据。时序数据就是基于时间排序的数
图8-1QPS走势图
1:00
Sdb
时序数据分析框架
12:30
13:00
---
## Page 155
8.1.2
128
〇以不同的时间粒度存储：数据的读取特征决定了可以将历史数据聚合成一个比较粗的
〇按列存储：通过数据的查询特征，可以发现时序数据更适合将一个指标放在一起存储，
3.
〇指定维度读取：在广告业务中，时序数据存储的维度可能有成百上千个，那么在读取
〇多时间粒度读取：一般来说，我们会对最近7天的数据以一个比较细的时间粒度来存储
!
写多读少：时序数据的写入是持续的，但是一般并不会持续地读取数据，只有在需要
连续性：时序数据会按照指定的时间粒度持续写入。
无须更新或删除操作（除了修复数据）。
数据实时写入。
智能运维：从0搭建大规模分布式AIOps系统
粒度存储，将最近的数据以一个比较细的粒度存储，这样可以大大减少磁盘的使用空
以大大减小I/O的损耗和内存的使用，提高执行效率。
任何列都能被作为索引。在读取数据时，只会读取所需要的维度所在的列，这样就可
数据存储
查询时需要在不同维度下对一个或多个指标进行各种聚合的操作，如 sum、max、avg
数据时不会把所有的维度都读取出来，因为这样做不仅没必要，而且对系统的IO 也是
据的效率。
粗的时间粒度存储，比如按照小时或者天来存储，以便节省磁盘空间，提高读取历史数