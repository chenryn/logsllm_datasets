title:An Empirical Approach to Modeling Uncertainty in Intrusion Analysis
author:Xinming Ou and
Siva Raj Rajagopalan and
Sakthiyuvaraja Sakthivelmurugan
2009 Annual Computer Security Applications Conference
An Empirical Approach to Modeling Uncertainty in Intrusion Analysis
Xinming Ou
Kansas State University
Manhattan, KS, USA
PI:EMAIL
Siva Raj Rajagopalan
Sakthiyuvaraja Sakthivelmurugan
HP Labs
Princeton, NJ, USA
PI:EMAIL
Kansas State University
Manhattan, KS, USA
PI:EMAIL
Abstract—Uncertainty is an innate feature of intrusion anal-
ysis due to the limited views provided by system monitoring
tools, intrusion detection systems (IDS), and various types of
logs. Attackers are essentially invisible in cyber space and
monitoring tools can only observe the symptoms or effects
of malicious activities. When mingled with similar effects
from normal or non-malicious activities they lead intrusion
analysis to conclusions of varying conﬁdence and high false
positive/negative rates. This paper presents an empirical ap-
proach to the problem of uncertainty where the inferred
security implications of low-level observations are captured in
a simple logical language augmented with certainty tags. We
have designed an automated reasoning process that enables
us to combine multiple sources of system monitoring data
and extract highly-conﬁdent attack traces from the numerous
possible interpretations of low-level observations. We have
developed our model empirically: the starting point was a
true intrusion that happened on a campus network that
we studied to capture the essence of the human reasoning
process that led to conclusions about the attack. We then
used a Datalog-like language to encode the model and a
Prolog system to carry out the reasoning process. Our model
and reasoning system reached the same conclusions as the
human administrator on the question of which machines were
certainly compromised. We then automatically generated the
reasoning model needed for handling Snort alerts from the
natural-language descriptions in the Snort rule repository, and
developed a Snort add-on to analyze Snort alerts. Keeping the
reasoning model unchanged, we applied our reasoning system
to two third-party data sets and one production network. Our
results showed that the reasoning model is effective on these
data sets as well. We believe such an empirical approach has the
potential of codifying the seemingly ad-hoc human reasoning
of uncertain events, and can yield useful tools for automated
intrusion analysis.
Keywords-intrusion detection; uncertainty; logic;
I. INTRODUCTION
Intrusion detection is the last line of defense against cyber
attacks. However building robust tools to detect intrusions
in practical environments has proved elusive. At the same
time, forensic analysis has become important in the light
of regulatory requirements as well as the appearance of
sophisticated targeted attacks on enterprise networks. Due
to the close relationship between the problems of intrusion
detection and computer forensics, we use the term “intrusion
analysis” to capture both, namely how to identify attack
traces from possibly large amounts of system monitoring
data, either on the ﬂy or ofﬂine. Solving this problem in
general has been an inexact science that has to admit a range
of uncertainty in output. System administrators (SA) today
use a combination of intuition, experience, and low-level
tools to create and support positive or negative judgements
on security events. However, the high volume of gathered
data strains the intuitive capacity of analysts. Increasingly,
sophisticated attacks combine multiple intermediate attack
steps to achieve their goals, as a result of which we may have
to combine the outputs of several disparate sensors to detect
multi-step attacks that are found today. While the low-level
observations (network packets, server logs, etc.) all have
potential implications for attack possibilities, few, if any,
of them can directly provide zero/one judgment at the high-
level abstraction (e.g., ”machine has been compromised”).
Nevertheless, in many remote intrusions a relatively small
number of critical observations taken together are sufﬁcient
to show that an attack has certainly happened as well as how
it progressed. The difﬁculty is how to start from uncertain
and voluminous views of the potential problem (e.g., IDS
alerts) and search for a few pieces of data among millions
so that the attacker’s hand is clearly and quickly shown. SAs
are highly time-constrained – an automatic tool that can sift
through the ocean of uncertainty to quickly and accurately
locate the problem areas or reduce the search space will be
invaluable in practice.
There are several technical challenges in handling uncer-
tainty in automated situation awareness, among the hardest
of which is quantifying the degree of certainty in vari-
ous assertions regarding possible attack activities. However,
through our interaction with highly capable SAs who face
the challenge every day while protecting enterprise systems,
we observed that humans do well without relying on any
numerical measures. This is illustrated in the true-life story
below.
A. A true-life incident
Consider the following sequence of events that actually
occurred at a university campus (key observations are num-
bered in parentheses). The SA noticed an abnormally large
spike in campus-network trafﬁc (Observation 1). The SA
took the netﬂow dump for that time period, searched it
for known malicious external IP addresses, and identiﬁed
1063-9527/09 $26.00 © 2009 IEEE
DOI 10.1109/ACSAC.2009.53
494
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:13:03 UTC from IEEE Xplore.  Restrictions apply. 
that four Trend Micro (standard anti-malware) servers had
initiated IRC connections to known BotNet controllers (Ob-
servation 2). The SA suspected that the four Trend Micro
servers had been compromised. At the console of one of
the servers he dumped the memory, from which he found
what appeared to be malicious code modules (Observation
3). He also looked at the open TCP socket connections
and noticed that the server had been connecting to some
other Trend Micro servers on campus through the IRC
channel (Observation 4). He concluded that all those servers
were compromised with some zero-day vulnerability in the
Trend Micro server software. He did the same for the
other identiﬁed servers and found even more compromised
servers. Altogether he identiﬁed 12 compromised machines
and took them ofﬂine.
B. Analysis methodology
When the administrator ﬁrst noticed the spike in net-
work trafﬁc, the questions facing him were: is the network
experiencing an attack, and if so, which machines were
compromised. However, none of the low-level observations
alone could give him a deﬁnitive answer to these high-
level questions. Observation 1 (trafﬁc spike) could indicate
a variety of causes, most of which are benign. (For ex-
ample, enterprise networks often see a spike in trafﬁc on
“Microsoft Patch Tuesdays.”) Observation 2 (connections
to BotNet controllers) has a higher likelihood of indicating
malicious activity and hence a higher degree of likelihood
that the identiﬁed hosts are compromised. However, an IRC
connection being made to a known BotNet controller by
itself is not incontrovertible evidence that a machine has
been compromised. The list of “known” BotNet controllers
may contain false positives or somebody could be probing
BotNet controllers for research purposes. (The interviewed
SA suggested this false positive as he did this himself
on a periodic basis.) Observation 3 (suspicious code in
memory) is also a strong indication that the machine may
have been controlled by an attacker. But it is not always
easy to determine whether a suspicious module found in
the memory dump is indeed malicious, especially with zero-
day vulnerabilities. Observation 4, like observation 2, cannot
deﬁnitively prove that the machines observed are under the
control of attackers because IRC is occasionally (but rarely)
used as a communication channel between servers. However,
when we put all the four pieces of evidence together within
a small
it seems clear that an attack has
certainly happened and succeeded and we can say that which
machines have been almost certainly compromised.
time period,
In handling this incident, the SA noted that while each
observation could have multiple interpretations, the uniﬁed
interpretation linking the semantics of multiple observations
is most likely to be the true one. For example, although
neither observation 3 nor 4 alone can give us high enough
conﬁdence to say that the host is deﬁnitely compromised,
linking them semantically allows to dramatically strengthen
our conﬁdence in the assertion, since both 3 and 4 point
to the same interpretation. We observed a similar pattern in
many other incidents we learned from interviewing system
administrators. It appears that even without quantitative
measures on uncertainty, the semantic links among possible
evidence can dramatically increase one’s conﬁdence on
whether an attack has actually happened and its conse-
quences. As a result, humans can handle the uncertainty
pretty well by “connecting the dots” among various pieces
of evidence. However, manual analysis alone is not scalable
and sustainable in the face of large-scale automated attacks
we face today. In this incident, the human SA had all the
common security tools at his disposal but none of the tools
could provide the crucial capability of analysis and the
manual analysis took a long time. As a ﬁrst step, can we
design tools that help reduce the amount of time that the SA
had to spend in the process? This is the main question we
aim to answer in this paper.
C. An empirical approach
We propose an empirical approach to automate reasoning
with uncertainty in intrusion analysis. We design a reasoning
model where human knowledge used to draw conclusions
about uncertain events can be codiﬁed and applied me-
chanically to future incidents. Although reasoning about
intrusions on different incidents can vary signiﬁcantly with
context, the basic principles are quite consistent. We design
a reasoning model that captures the essence of the generic
reasoning rationale, not speciﬁc features of any particular
incident. The model provides a language whereby human
experts can share knowledge useful for intrusion analysis
in a machine readable format, and an automated reasoning
engine can make use of the knowledge, signiﬁcantly expand-
ing a human’s capability. Both the model and the reasoning
engine are designed empirically through the study of real
security incidents.
This is certainly not the ﬁrst attempt at automating rea-
soning about intrusions. Past work has applied rule-based
systems to correlate audit logs and detect attacks [1], [2].
There is also a great deal of work on IDS alert correla-
tion [3], [4], [5], [6], [7], [8]. These previous approaches
do not address the uncertainty problem explicitly, i.e., the
reasoning systems do not model when and how conﬁdence
levels on assertions can be strengthened in the correlation
process.We believe an explicit model for uncertainty in
reasoning is crucial to making alert correlation tools useful
in practice. Zhai, et al. has pioneer work [9] in this area
by combining alert-correlation, attack-graph, and Bayesian-
Network techniques to reason about complementary intru-
sion evidence from both IDS alerts and system monitoring
logs so that high-conﬁdence traces can be distinguished from
ones that are less certain. Recent years have also seen the
application of quantitative mathematical methods such as
495
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:13:03 UTC from IEEE Xplore.  Restrictions apply. 
Bayesian Network [10] and Dempster Shafer theory [11] in
intrusion detection [12], [13], [14]. We have chosen not to
start from those mathematical theories, because to utilize
them we need a priori
the logical structure among the
various observations and hypotheses. In intrusion analysis,
identifying the structure of attacks is a big challenge in and
of itself, which is intermingled with the challenge caused
by uncertainty of observation and interpretation. Instead of
starting from these mathematical theories, we start from
true-life experiences like the one described in Section I-A,
and design a model that systematically “simulates” what a
human does manually, formalizing empirical experience so
that it can be applied mechanically to future incidents. We
believe this empirical, bottom-up approach is an important
ﬁrst step in understanding the nature of reasoning about
uncertainty in cyber security and gaining experience that
may make truly quantitative approaches viable in the future.
D. Our contributions
An empirical model for uncertainty: First, we present
a model for capturing the meanings of low-level system
observation data in terms of high-level conditions of interest
to intrusion analysis. The model and inference process are
based on how human administrators reason about attacks
in real security incidents. We use qualitative rather than
quantitative assessment to capture the uncertainty inherent
in such assertions. The qualitative assessment reﬂects the
imprecise nature of the certainty levels’ semantics and it
also makes it easier to understand by humans, enabling
discussion/reﬁnement of the reasoning model in an open
community. Such a model can also be linked to existing
knowledge bases such as the Snort rule repository. Our
model is capable of expressing logical connections among
the high-level conditions (also with qualitative uncertainty
assessment) so that it can reason about multi-host, multi-
stage intrusions with traces spread across various types of
monitoring data.
Reasoning methodology: Second, we present a reason-
ing process that can utilize such a model and existing IDS
tools to automatically identify high conﬁdence attack traces
from large diverse sets of system monitoring data not re-
stricted to just IDS alerts. We also present within this model
a method for strengthening the conﬁdence in an assertion by
combining different independent pieces of evidence of low
or moderate conﬁdence. Our model of high-level conditions
is generic predicates such as “compromised,” “exploit sent,”
etc. that are independent of the scenario at hand. What can
change from one scenario to another are the instantiation of
the predicates and the certainty tags associated with them
as the scenario events are processed and the paths that the
reasoning process takes through these conditions. We believe
that SAs have such small sets of “target” conditions in
mind when they process intrusion data and there is value
in capturing those target conditions directly in an automated
reasoning process. We implemented a prototype reasoning
engine using the true-life case study as a guide and showed
that the tool’s reasoning tracked the SA’s reasoning process
and achieved the same set of high-level conclusions with
high conﬁdence.
A Snort add-on based on our model and method: Third,
we automatically generated a signiﬁcant part of our rea-
soning model from the classtype, impact, and ease
of exploit ﬁelds associated with Snort rule descriptions
and show that the knowledge base needed by our reasoning
engine can be readily created if security monitoring tools use
our model language (instead of natural language) to describe
the potential meanings of various types of security alerts.
Based on this automatically-derived knowledge base and
the prototype implementation of our reasoning engine, we
provide a Snort add-on, called SnIPS, that analyzes millions
of Snort alerts reported from an enterprise network and only