 , which has been cited by
several authors including Gerald
 , an expert on  .
Towards the end of the song , there
is a line ” Feeding off the screams
of the  he ’s creating ” ,
which was taken from the ﬁlm of
Boys from Brazil  which
Dr.  was the villain .
1.55
0.941
1.17
0.939
TABLE XIII: Two samples for the same input text segment.
Although they have comparable meteor scores, the sample
with the lower SBERT distance shows better coherence.
a) Denoising non-watermarked text: We evaluate the
DAE, regardless of the watermark, by applying the noise to
the non-watermarked test set. We compare the similarity to
the original text before and after denoising using the meteor
and SBERT scores as shown in Table XIV. We observed
that denoising partially reconstructs the original sentence,
but, it can introduce additional changes. We illustrate by the
examples in Table XV that we categorize into three parts. In
the ﬁrst one, we show examples where the denoised sequence
matches the original sequence; this was mainly for sentences
with syntactic inconsistencies that removed common/likely
words. In the second part, the DAE removed the added noise
with more likely sequences, yet, it did not restore the original
one which might cause semantic differences. In the third
part, the noise words were not changed in the denoised text.
This analysis suggests that the DAE is more likely to change
sequences with clear ﬂaws, but it is also likely to cause other
changes that were not corrupted. We validate this observation
Text
Meteor
SBERT
Corrupted
Denoised
0.947
0.956
2.7
2.25
TABLE XI: Examples of input sentences, the best SBERT
sample, and the best language model sample (slightly better).
TABLE XIV: The similarity to the original sequence in the
case of the corrupted and denoised text.
Input
Corrupted
Denoised
pair of claws
when you don ’t
his earliest surviving poem ,
he was arrested
attempted to join the court
He next spent around six weeks
He appeared to be a  son
Like many other poems in the Tang
The tenor of his work changed
pair 1941 claws
when you tendencies ’t
his earliest surviving poem bill
He demolition arrested
attempted to Desiree the court
Dreamers next Punch around six
weeks
police appeared to be a  son
Like many other poems in roof
Tang
The luck of his work changed
pair of claws
when you don ’t
his earliest surviving poem ,
He was arrested
attempted to take the court
The next day around six weeks
police appeared to be a  son
Like many other poems in roof ,
The luck of his work changed
TABLE XV: DAE output when applying word replacement
noise to the non-watermarked test set.
Input
Watermarked
Denoised
The eggs hatch at night
and a mass of 6 kilograms
several years writing for the televi-
sion sitcoms Grace Under Fire
He also performed as an actor and
a singer
The eggs hatch with night
and a mass as 6 kilograms
several years writing for the televi-
sion of Grace Under Fire
He had performed as an actor and
a singer
The eggs hatch with night
and a mass as 6 kilograms
several years writing for the televi-
sion of Grace Under Fire
He had performed as an actor and
a singer
he took the civil service exam
The ﬁrst RAAF helicopters were
committed to
consisting of an infantry battalion
the species is also widely
, but
known as
he an the civil service exam
. with ﬁrst RAAF helicopters were
committed to
consisting of been infantry battal-
ion
Bunbury but
widely known as
the species is also
he was the civil service exam
. The ﬁrst RAAF helicopters were
committed to
consisting of two infantry battalion
the species is also widely
, but
known as
This occurs because , in life , the
red pigment
and adopts a  lifestyle
The last distinct population
This occurs because , in life , the
red pigment
and adopts a  lifestyle
The last distinct population
This occurs because , in particular
, the small pigment
and has a  lifestyle
The last major population
TABLE XVI: DAE output when applied to the watermarked
text (from different model’s variants).
by examining the denoising output of the watermarked text.
b) Denoising watermarked text: In Table XVI, we show
examples when applying the DAE to watermarked text without
additional noise (the results in Table VII). We categorize these
examples into three parts; the ﬁrst is the examples where
the watermarking changes were not changed by the DAE.
Second, we show examples where they were changed; these
examples are from different variants of the model, and they
generally cause clear ﬂaws, this explains the large drop in
the ‘no-discriminator’ model since this variant generally had
lower quality output. Third, we show examples where the
DAE introduced additional changes to sequences that were not
originally changed by the watermarking model, this increased
the SBERT distance in the ﬁrst two rows in Table VII.
We observed other cases where the watermarking changes
were not altered by the DAE even when having other grammat-
ical mistakes, these changes might be removed by training a
stronger DAE (e.g., larger model or larger dataset), however,
this requires an even more experienced attacker with more
technical knowledge and powerful computational resources.
C. Visualizations
We show, in Figure 12a, a word cloud for the most frequent
words that were changed in the original text when watermark-
ing, and in Figure 12b, the most frequent words that were
changed to in the watermarked text. As can be observed, the
words in both ﬁgures are highly overlapping, therefore, we
(a)
(b)
Fig. 12: (a) Words that were replaced in the original text. (b)
Words that the model changed to in the watermarked text.
Bigger fonts indicate higher frequencies.
analysed the pairwise transitions between them in Figure 8.
As we showed in Figure 7 and Figure 8, the model keeps
the count of these top words similar, and it does not perform
ﬁxed substitutions between them. These factors support the
encoding secrecy with no telltale words. Besides, there are no
words that are particularly exclusive for bit holding, which has
a ﬂexibility advantage over the rule-based substitution baseline
discussed in Section V-E1. For better visualization, we show
in Figure 13 the words’ transitions as in Figure 8, but without
the diagonal elements where the words were not changed.
D. Different AWT Models and Adaptive Attacks
In sections V-D3 and V-D4, we discussed that attacks
crafted using another trained model (AWTadv) are less effective
in the black-box case (when applied to the ﬁrst AWT model).
In this section, we ﬁrst compare two independently trained
models in terms of words’ transitions and qualitative examples.
We then show examples of adaptive attacks.
a) Comparing different models: A message decoder of
one model gives an almost random chance accuracy when used
to decode another model’s sentences. Thus, it is sensitive to the
paired watermarking model mostly. A possible explanation is
that different instances produce different patterns or mappings
(as previously reported in data hiding studies in images [27]).
To investigate that, we ﬁrst study whether AWTadv uses the
same commonly changed words to encode the information.
In Figure 14, we show the transitions produced by AWTadv
among the commonly used words by the ﬁrst AWT model.
When comparing this to Figure 13, we notice that these words
have relatively fewer transitions.
Furthermore, we show in Table XVII, examples of sentences
that were watermarked individually (but, using the same binary
message) by AWT and AWTadv producing different wording
changes (for the replaced, added words, or their positions).
b) Re-watermarking: For further investigation, we show
in Table XVIII examples of re-watermarked sentences in the
white-box and the black-box cases.
In the white-box case, we observed that the model often
replaces the same word that was previously replaced in the
ﬁrst watermarking process. This caused the ﬁrst watermark
matching accuracy to drop to nearly random chance. In the
black-box case, we can observe that: 1) the re-watermarking
does not necessarily override the ﬁrst changes (i.e., both
changes can be present in the re-watermarked sentences). 2)
the newly added words might not be from the most sensitive
re-watermarking was less effective in the black-box case.
c) De-watermarking: In section V-D4, we evaluated an
adaptive attack that tries to de-watermark the sentences rather
than re-watermark them. We perform this attack by training a
denoising autoencoder (DAEpaired, with a similar architecture
to the DAE used in subsubsection V-D2) on the paired training
data of AWTadv (without adding further noise). In Table XIX,
we show examples of applying this attack in the white-box
and black-box cases.
In the white-box, DAEpaired successfully recovered the sen-
tences where the watermarking model caused clear syntactic
ﬂaws (such as the ﬁrst example). Moreover, since DAEpaired
was exposed to the most frequent changes’ patterns during
training, it was able to reconstruct sentences with either no
or less obvious artifacts (e.g., replacing ‘which’ with ‘that’, or
‘which’ with ‘before’ in the table). These changes might not be
easy to detect without paired training. The second category of
examples includes pairs where the watermarking changes were
not reversed but were nevertheless replaced with perhaps more
correct tokens. The last category shows very subtle examples
that were not changed even in the white-box case.
In the black-box, DAEpaired also recovers the sentences with
clear mistakes. This is similar to the DAE model that was
trained on noisy data in section V-D2, however, DAEpaired was
more successful since different models could still have some
similarities (e.g., both replacing ‘been’). Since DAEpaired was
sensitive to the patterns that it was trained on, it often replaced
words that were not changed originally by AWT but are often
changed by AWTadv (e.g., removing ‘which’, ‘three’, and ‘they’
in the third black-box category). Finally, the last black-box
category shows examples where DAEpaired did not perform any
changes. This can be due to two reasons: 1) the changes are
more subtle. 2) they were not frequently seen in the paired
training data of AWTadv.
E. Generation-based hiding
We present more details about the baseline of generation-
based hiding in Section V-E2.
x
o
b
-
e
t
i
h
W
x
o
b
-
k
c
a
l
B
Input
landed a role as ” Craig ” in
the episode ” Teddy ’s Story
” of the television series The
Long Firm
 made a guest appear-
ance on a two @-@ part
episode arc of
the television
series Waking the Dead
Female H. gammarus reach
sexual maturity when they
have grown to a carapace
length of 80 – 85 millimetres
, whereas males mature at a
slightly smaller size .
 ’s other positions at
the Department of Air
in-
cluded Air Commodore Plans
from October 1957 to January
1959 , and Director General
Plans and Policy from Jan-
uary to August 1959 . The
latter assignment put him in
charge of the RAAF ’s Direc-
torate of Intelligence .
Watermarked
landed a role as ” Craig ” in
the episode ” Teddy ’s Story ”
from the television series The
Long Firm
 made a guest appear-
ance on a two @-@ part
episode arc from the televi-
sion series Waking the Dead
Female H. gammarus reach
sexual maturity when they
have grown to a carapace
length of 80 – 85 millimetres
, whereas males mature on a
slightly smaller size .
 ’s other positions on
the Department of Air
in-
cluded Air Commodore Plans
from October 1957 to January
1959 , and Director General
Plans and Policy from Jan-
uary to August 1959 . The
latter assignment put him in
charge of the RAAF ’s Direc-
torate on Intelligence .
Re-watermarked
landed a role as ” Craig ” in
the episode ” Teddy ’s Story
” at the television series The
Long Firm
 made a guest appear-
ance on a two @-@ part
episode arc with the television
series Waking the Dead
Female H. gammarus reach
sexual maturity when to have
grown to a carapace length of
80 – 85 millimetres , whereas
males mature on a slightly
smaller size .
 ’s other positions on
the Department of Air
in-
cluded Air Commodore Plans
from October 1957 to January
1959 , and Director General
Plans and Policy from Jan-
uary to August 1959 . The
latter assignment put was in
charge of the RAAF ’s Direc-