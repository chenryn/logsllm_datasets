using a page table example. On modern computers with hardware
virtualization support, the hypervisor maintains a nested page table
(NPT) [30] for each VM, to manage the VM’s access to physical
memory. NPTs translate guest physical memory addresses (gPAs) to
host physical memory addresses (hPAs), mapping each guest frame
number (gfn) to a physical frame number (pfn).
In our example, the NPT of a VM is allocated from its own
page table pool. The pool consists of page table entries, whose
implementation is encapsulated by a lower layer interface that
exposes functions pt_load(vmid, ofs) to read the value at offset
ofs from the page table pool of VM vmid and pt_store(vmid,
ofs, val) to write the value val at offset ofs. To keep the
example simple, we use a simplified version of the real NPT
verified in MicroV, ignore dynamic allocation and permission bits,
and assume two-level paging denoted with pgd and pte. Consider
the following two implementations, which map gfn to pfn in
VM vmid’s NPT:
void set_npt(uint vmid, uint gfn, uint pfn) {
acq_lock_npt(vmid);
// load the pte base address
uint pte = pt_load(vmid, pgd_offset(gfn));
pt_store(vmid, pte_offset(pte,gfn), pfn);
rel_lock_npt(vmid);
}
void set_npt_insecure(uint vmid, uint gfn, uint pfn) {
acq_lock_npt(vmid);
uint pte = pt_load(vmid, pgd_offset(gfn));
pt_store(vmid, pte_offset(pte,gfn), pfn+1); // BUG
pt_store(vmid, pte_offset(pte,gfn), pfn);
rel_lock_npt(vmid);
}
Since an NPT just maintains a mapping from gfns to pfns, we
can specify the NPT as a logical map gfn(cid:55)→ pfn, then prove that
a correct NPT implementation refines its specification. However,
among the two implementations, only set_npt is correct, while
set_npt_insecure is not. A sound refinement proof should
only admit set_npt, while rejecting set_npt_insecure for its
extraneous intermediate mapping from gfn to pfn+1.
Figure 2 illustrates the vulnerability of set_npt_insecure. The
problem arises because a multiprocessor VM supports shared
memory among its virtual CPUs (VCPUs). This requires its NPT to
also be shared among its VCPUs, potentially running on different
physical CPUs. Even though the NPT is protected by software
spinlocks, the hardware memory management unit (MMU) will
still perform page translations during set_npt_insecure’s critical
section. When the hypervisor runs set_npt_insecure to map a
physical page used by VM m to VM n’s NPT, VM m’s secrets can
be leaked to VM n accessing the page on another physical CPU.
1784
Fig. 2: Insecure page table updates. VM n runs on CPUs 0 and 1, while
VM m runs on CPU 2. Physical page pfn is free, but pfn+1 is mapped
to VM m’s NPT and contains its private data, so only VM m should have
access to it. At time t0, KCore handles VM n’s page fault and invokes
set_npt_insecure(n, gfn, pfn) on CPU 0 to map guest page gfn
in VM n’s NPT. At time t2, gfn is transiently but erroneously mapped to
pfn+1 until t4, allowing VM n on CPU 1 to concurrently access VM m’s
private data using this temporary mapping.
Previous refinement techniques [5], [28], [31] would incorrectly
deem set_npt and set_npt_insecure functionally equivalent,
failing to detect this vulnerability. For example, although CertiKOS
proves that its own software is data-race free (DRF), it does not sup-
port, nor model, the MMU hardware feature allowing an untrusted
principal to concurrently access a shared page table, so the above two
implementations would erroneously satisfy the same specification.
To address this problem, MicroV introduces transparent
trace refinement, which forbids hidden information flow in a
multiprocessor setting. To explain this technique, we first describe
our multiprocessor machine model, and how shared objects are
modeled using event traces. We then describe how transparent
trace refinement can be used to enable sequential reasoning for
a write data-race-free system, where shared objects are protected
by write-locks, but reads on shared objects (which may lead to
information leakage) may occur at any time.
1) Multiprocessor model: We define an abstract multiprocessor
machine model, whose machine state σ consists of per-physical
CPU private state (e.g., CPU registers) and a global logical log,
a serial list of events generated by all CPUs throughout their
execution. σ does not explicitly model shared objects. Instead,
events incrementally convey interactions with shared objects, whose
state may be calculated by replaying the logical log. An event is
emitted by a CPU and appended to the log whenever that CPU
invokes a primitive that interacts with a shared object. For example,
the page table pool used by our NPT implementation is accessible
from KCore running on each CPU via the pt_store(vmid, ofs,
val) primitive, which generates the event (P_ST vmid ofs val).
Similarly, the NPT itself is a shared object, so the set_npt(vmid,
gfn, pfn) primitive defined in our layer specification generates
the event (SET_NPT vmid gfn pfn).
Our abstract machine is formalized as a transition system,
where each step models some atomic computation taking place
on a single CPU; concurrency is realized by the nondeterministic
interleaving of steps across all CPUs [32]. To simplify reasoning
about all possible interleavings, we lift multiprocessor execution
Fig. 3: Querying the event oracle to refine set_npt. The bottom trace
shows events produced by set_npt’s implementation as it interacts
with the shared lock and page table pool it uses. The query move before
ACQ_LK yields all events from other CPUs prior to ACQ_LK; the query
move before P_LD yields all events from other CPUs since the last query
up until P_LD. The middle trace shows how we would like to shuffle
events in the bottom trace to match those in the top trace.
to a CPU-local model, which distinguishes execution taking place
on a particular CPU from its concurrent environment [5].
All effects coming from the environment are encapsulated by
and conveyed through an event oracle, which yields events emitted
by other CPUs when queried. How the event oracle synchronizes
these events is left abstract, its behavior constrained only by
rely-guarantee conditions [33]. Since the interleaving of events is
left abstract, our proofs do not rely on any particular interleaving of
events and therefore hold for all possible concurrent interleavings.
A CPU captures the effects of its concurrent environment by
querying the event oracle, a query move, before its own CPU step,
a CPU-local move. A CPU only needs to query the event oracle
before interacting with shared objects, since its private state is not
affected by these events. Figure 3 illustrates query and CPU-local
moves in the context of the event trace produced by set_npt’s
implementation to refine its specification. The end result of its
execution is a composite event trace of the events from other CPUs,
interleaved with the events from the local CPU.
Interleaving query and CPU-local moves still complicates
reasoning about set_npt’s implementation. However, if we can
guarantee that events from other CPUs do not interfere with the
shared objects used by set_npt, we can safely shuffle events
from other CPUs to the beginning or end of its critical section. For
example, if we could prove that set_npt’s implementation is DRF,
then other CPUs will not produce events within set_npt’s critical
section that interact with the locked NPT. We would then only need
to make a query move before the critical section, not within the
critical section, allowing us to sequentially reason about set_npt’s
critical section as an atomic operation.
Unfortunately, as shown by set_npt_insecure, even if
set_npt correctly uses locks to prevent concurrent NPT accesses
within KCore’s own code, it is not DRF because KServ or VMs
executing on other CPUs may indirectly read the contents of their
NPTs through the MMU hardware. This prevents us from soundly
shuffling event queries outside of the critical section and employing
sequential reasoning to refine the critical section to an atomic step.
If set_npt cannot be treated as an atomic primitive, sequential
reasoning would then be problematic to use for any layer that uses
set_npt, making their refinement difficult. Without sequential
reasoning, verifying a large system like KCore is infeasible.
2) Transparent trace refinement: We observe that information
leakage can be modeled by read events that occur arbitrarily
1785
critical section. On the other hand, set_npt has only two event
observer groups, one that observes the value before pt_store, and
one that observes the value after pt_store, so query moves are not
needed during the critical section. The implementation can therefore
be refined to an atomic set_npt specification. Refinement proofs
for higher layers that use set_npt can then treat set_npt as
an atomic primitive, simplifying those proofs since set_npt can
be viewed as just one atomic computation step instead of many
CPU-local moves with intervening query moves.
B. Noninterference Assertions
Since transparent trace refinement ensures that KCore’s top-level
specification hides only its implementation details, but not
any potential information flow, we can now soundly prove its
security properties using its specification. We express the security
properties as noninterference assertions, and want to show that
one principal cannot affect the private data of another, ensuring
VM confidentiality and integrity. For each principal, we define a
private data lens (PDL), denoted by V, which returns the subset
of machine state σ that is private to the principal. For example, the
private data of VM p, denoted as V(σ, p)⊆σ, includes the contents
of its CPU registers and memory. A principal should not be able to
infer the state in any other principal’s PDL, and its own PDL should
be unaffected by other principals. Such an isolation property can be
proven using noninterference by showing state indistinguishability:
Definition 3 (State indistinguishability). Two states σ1 and σ2
are indistinguishable from the perspective of principal p if and only
if V(σ1, p)=V(σ2, p).
In other words, a pair of distinct machine states are indistinguishable
to some principal p if the differences fall beyond the scope of
p’s PDL. We want to prove that, starting from any two states
indistinguishable to a principal p, the abstract machine should only
transition to a pair of states that are still indistinguishable to p. Such
transitions are said to preserve state indistinguishability.
Example 2 (Proving VM confidentiality). Consider KServ and a
VM m, where VM m has only gfn 1 in its address space, mapped
to pfn 2. We prove VM m’s data confidentiality by showing that
any change in VM m’s private data is not visible to KServ during
execution. Suppose VM m writes content b to its gfn 1 in one
execution (leading to state σ), and writes content b(cid:48) in an alternate
execution (leading to state σ(cid:48)); we must show that these executions
are indistinguishable to KServ’s PDL:
To keep our example simple, we use a simplified V consisting
of only the contents stored in a principal’s guest page frames.
For instance, in σ, after VM m writes b to gfn 1, V(σ, m) is
the partial map {1(cid:55)→ b}. Yet in both executions, whether VM m
writes b or b(cid:48), KServ’s PDL to the two states are identical:
V(σ, KServ) =V(σ(cid:48), KServ) ={1(cid:55)→ a, 2(cid:55)→ c}. This means that
the two states are indistinguishable to KServ—it cannot observe
VM m’s update to pfn 2.
Fig. 4: Transparent trace refinement of insecure and secure set_npt
implementations. Each node represents an event observation. Nodes of
the same color constitute an event observer group. The insecure example
does not satisfy the transparency condition because there is an intermediate
observation (shown in red) that cannot map to any group in the specification.
throughout critical sections, without regard for locks. To ensure
that refinement does not hide this information leakage, transparent
trace refinement treats read and write events separately. We view
shared objects as write data-race-free (WDRF) objects—shared
objects with unavoidable concurrent observers. For these objects,
we treat their locks as write-locks, meaning that query moves that
yield write events may be safely shuffled to the beginning of the
critical section. Query moves in the critical section may then only
yield read events from those concurrent readers.
To determine when read events may also be safely shuffled,
each WDRF object must define an event observer function, which
designates what concurrent CPUs may observe: they take the
current machine state as input, and produce some observed result,
with consecutive identical event observations constituting an event
observer group. Event observer groups thus represent all possible
intermediate observations by concurrent readers. Since the event
observations are the same in an event observer group, read events
from other CPUs will read the same values anywhere in the group
and can be safely shuffled to the beginning, or end, of an event
observer group, reducing the verification effort of dealing with
interleavings. Our security-preserving layers enforce that any
refinement of WDRF objects must satisfy the following condition:
Definition 2 (Transparency condition). The list of event observer
groups of an implementation must be a sublist of that generated
by its specification. That is, the implementation reveals at most as
much information as its specification.
This condition ensures that the possibility of concurrent readers
and information release is preserved through each layer refinement
proof. In particular, if a critical section has at most two distinct
event observer groups, read events can be safely shuffled to the
beginning or end of the critical section. Query moves are no longer
needed during the critical section, but can be made before or
after the critical section for both read and write events, making it
possible to employ sequential reasoning to refine the critical section.
Transparent trace refinement can thereby guarantee that events from
other CPUs do not interfere with shared objects in critical sections.
Figure 4 illustrates how this technique fares against our earlier
counterexample, as well as to our original, secure implementation.
set_npt_insecure has three event observer groups that can
observe three different values, before the first pt_store, between
the first and second pt_store, and after the second pt_store.
Read events after the first pt_store cannot be shuffled before the
1786
Although previous work used noninterference assertions to verify
information-flow security [34], [35], [36], they do not address two
key issues that we solve in MicroV, concurrency and intentional
information flow.
crypted data B and B(cid:48) to gfn 3 leads to distinguishable states, since
the differences between B and B(cid:48) are exposed to KServ’s PDL:
1, i.e., V(σ1, p)=V(σ(cid:48)
2, then V(σ2, p)=V(σ(cid:48)
1) Concurrency: We extend previous work on noninterference
in a sequential setting [35] to our multiprocessor specification. We
prove noninterference for big steps, meaning that some principal
always steps from an active state to its next active state, without
knowledge of concurrent principals. We say a state is active if we
are considering indistinguishability with respect to some principal
p’s PDL, and p will make the next step on CPU c; otherwise the
state is inactive. We decompose each big step noninterference proof
into proofs of a set of auxiliary lemmas for a given principal p:
Lemma 1. Starting from any two active, indistinguishable states
σ1 and σ(cid:48)
1, p), if p makes CPU-local moves
to states σ2 and σ(cid:48)
Lemma 2. Starting from any inactive state σ, if some other
principal makes a CPU-local move to inactive state σ(cid:48), then
V(σ, p)=V(σ(cid:48), p).
Lemma 3. Starting from any two inactive, indistinguishable states
σ1 and σ(cid:48)
1, p), if some other principal makes
CPU-local moves to active states σ2 and σ(cid:48)
2, respectively, then
V(σ2, p)=V(σ(cid:48)
Lemma 4. Starting from any two indistinguishable states σ1 and
1, i.e., V(σ1, p)=V(σ(cid:48)
σ(cid:48)
1, p), if query moves result in states σ2 and