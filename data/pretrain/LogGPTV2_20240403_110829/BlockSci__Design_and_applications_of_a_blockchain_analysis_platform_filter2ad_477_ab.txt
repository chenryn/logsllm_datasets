60
4
Bits
32
32
60
4
Figure 2: Transaction structure
Incremental updates. The append-only nature of the
blockchain enables incremental updates to the parser out-
put. The parser serializes its ﬁnal state at the end of a run and
resumes from that state when invoked again. A difﬁculty with
this approach is handling blockchain reorganization which
occurs when a block that was originally in the longest branch
is surpassed by a different branch. BlockSci recommends to
ignore the most recent few blocks during initialization. The
probability of a reorg that affects d or more blocks decreases
exponentially in d. The default value of d for Bitcoin is 6. If
a deeper reorg happens, the user needs to reparse the chain.
2.3 BlockSci Data
Key challenge: ﬁnding a data layout that gives a good
trade-off between memory efﬁciency and performance.
Based on our experience with empirical blockchain analysis
over several years, we divide the available data into three
categories and combine it in a hybrid scheme that provides us
with a reasonable trade-off between efﬁcient use of memory
and speed of access:
1. The core transaction graph is required for most analyses
and always loaded in-memory. It is stored in a row-based
format.
2. Scripts and additional data is required for only a subset of
analyses. It is stored in a hybrid (partially column-based,
partially row-based) format and is loaded on-demand.
3. Indexes to look up individual transactions or addresses
by hash are stored in a separate database on disk.
We make further optimizations to improve performance,
including using ﬁxed-size encodings for data ﬁelds where pos-
sible, optimizing the memory layout for locality of reference,
linking outputs to inputs for efﬁcient traversal, and sharing
identical data across chains in multi-chain mode.
Transaction graph. The core transaction graph is stored
in a single sequential table of transactions, with entries hav-
ing the structure shown in Figure 2. Note that entries have
variable lengths, due to the variable number of inputs and
outputs (there is a separate array of offsets for indexing, due
to the variable entry lengths). Normally this would necessitate
entries to be allocated in the heap, rather than contiguously,
which would have worse memory consumption and worse
locality of reference.
However, because of the append-only property of the
blockchain, there are only two types of modiﬁcations that
are made to the transactions table: appending entries (due
to new transactions) and length-preserving edits to existing
entries (when existing UTXOs are consumed by new transac-
tions). This allows us to create a table that is stored as ﬂat ﬁle
on disk that grows linearly as new blocks are created. To load
the ﬁle for analysis, it is mapped into memory. The on-disk
representation continues to grow (and be modiﬁed in place),
but the analysis library provides a static view (Section 2.4).
Layout and locality. The main advantage of the transac-
tion graph layout is spatial locality of reference. Analyses that
iterate over transactions block-by-block exhibit strong locality
and beneﬁt from caching. Such analyses will remain feasible
even on machines with insufﬁcient memory to load the entire
transaction graph, because disk access will be sequential.
The layout stores both inputs and outputs as part of a trans-
action, resulting in a small amount of duplication (a space
cost of about 19 %), but resulting in a signiﬁcant speedup for
sequential iteration compared to a normalized layout. Variants
of the layout are possible depending on the types of iteration
for which we wish to optimize performance (Section 2.6).
Additional data. Beyond the core transaction graph,
BlockSci provides access to additional data that are necessary
for some types of analyses. These include script data, trans-
action hashes and version numbers, input sequence numbers,
input-output linkages, and raw data contained in coinbase
transactions. Keeping this data separate reduces memory us-
age in exchange for a small reduction in speed of access for
analyses that require this data (e.g., 10 % slower for a typical
query that iterates over transaction metadata).
Scripts. BlockSci categorizes scripts into 5 generic types,
each of which contains scripts of one or more address formats:
script-hash (for script-hash and witness-script-hash scripts),
pubkey (for raw pubkey, pubkey-hash, individual pubkeys in
a multisig script, and witness-pubkey-hash scripts), multisig,
null data, and unknown witness scripts. All other scripts are
categorized as nonstandard. Internally, script data of different
address formats is deduplicated: for example, a public key
used in both a pubkey-hash and a witness-pubkey-hash script
is stored only once. For nonstandard scripts, BlockSci stores
the entire script data which can be parsed with only a few
lines of code by the analyst.
Indexes. Transaction hashes and addresses are stored in
ﬂat ﬁles and can easily be looked up by transaction/address
ID. The reverse mapping from hash to ID, however, is stored
in separate indexes in RocksDB databases (the address in-
dex is also used by the parser). Accessing these indexes is
almost never performance critical in scientiﬁc analysis—in
2724    29th USENIX Security Symposium
USENIX Association
fact, many analyses don’t require the indexes at all. Besides
the ability to look up transactions and addresses by hash, we
also provide a lookup for all outputs associated with speciﬁc
addresses.
Multi-chain mode. To support forked blockchains, we
make three modiﬁcations to the layout described above. First,
forked chains often share a large common history with their
parent chain. We load these identical blocks only once, and
the analysis library provides the abstraction of a full chain for
each fork. Second, the ﬁxed-size encoding does not permit
storing data of multiple chains. For example, UTXOs at fork
height can be spent in both the parent and the forked chains,
but the ﬁxed-length ﬁeld can only hold a single index for the
spending transaction (cf. Figure 2). Each fork thus needs a
separate ﬂat ﬁle that contains the spending transactions’ IDs
for outputs created before the fork. Third, the index that maps
addresses to outputs requires an additional chain identiﬁer to
distinguish between outputs on different chains.
2.4 BlockSci Analysis Library
The snapshot illusion. The following three seemingly con-
tradictory properties hold in BlockSci:
1. The transactions table is regularly updated on disk as new
blocks are received (note that arbitrarily old transactions
may be updated if they have unspent outputs that get
spent in new blocks).
2. The table is memory-mapped and shared between all
running instances of BlockSci.
3. Each instance loads a snapshot of the blockchain that
never changes unless the programmer explicitly invokes
a reload.
The contradiction disappears once we notice that the state
of the transactions table at any past point in time (block height)
can be reconstructed given the current state. To provide the
illusion of a static data structure, when the blockchain object
is initialized, it stores the height of the blockchain at initial-
ization time. The blockchain on disk increases over time, but
the stored height remains ﬁxed, and accesses to blocks past
this height are prevented. The analysis library intercepts and
rewrites accesses to transaction outputs such that outputs that
were spent in blocks added after initialization appear unspent.
Memory mapping and parallelism. Since BlockSci uses
the same format for the transaction graph on disk and in
memory, loading the blockchain simply involves memory-
mapping this ﬁle. Once in memory, each transaction can be
accessed as a C++ struct; no new memory needs to be
allocated to enable an objected-oriented interface to the data.
This is because the disk layout of each struct is identical to
its memory layout.
Memory mapping allows users to efﬁciently run BlockSci
on machines with less than the recommended amount of mem-
ory provided that they only require access to a subset of the
data that ﬁts in memory.
Memory mapping also allows multithreaded parallel pro-
cessing with no additional effort. Recall that if a ﬁle is mapped
into memory by multiple processes, they use the same phys-
ical memory for the ﬁle. The ﬁle has only one writer (the
parser); it is not modiﬁed by the analysis library. Thus, syn-
chronization between different analysis instances isn’t nec-
essary. With a disk-based database, analyses tend to be I/O-
bound, with little or no beneﬁt from multiple CPUs, whereas
BlockSci is CPU-bound, and performance scales roughly lin-
early with the number of virtual CPUs (Section 2.6). Finally,
memory mapping also makes it straightforward to support
multiple users on a single machine, which is especially useful
given that Jupyter notebook (the main interface to BlockSci)
can be exposed via the web.
Mapreduce. Many analyses, such as computing the aver-
age transaction fee over time, can be expressed as mapreduce
operations over the transactions table (or ranges of blocks).
Thus the analysis library supports a mapreduce abstraction
that, with no additional effort from the programmer, handles
parallelizing the task to utilize all available cores. As we
show in Section 2.6.1, parallel iteration over all transactions,
transaction inputs, and transaction outputs on the Bitcoin
blockchain as of December 2019 takes only 0.9 seconds on a
single 16-vCPU EC2 instance.
Address linking. Address linking (or clustering) is a key
step in many analytic tasks including understanding trends
over time and evaluating privacy. Recall that cryptocurrency
users can trivially generate new addresses, and most wallets
take advantage of this ability. Nevertheless, addresses con-
trolled by the same user or entity may be linked to each other,
albeit imperfectly, through various heuristics.
Two common types of heuristics include (1) inputs spent
in the same transaction are controlled by the same entity, and
(2) identifying a change address based on client software or
user behavior (e.g., [3]). As the multi-input heuristic does
not apply to CoinJoin transactions, we add an exception for
those transactions, which we identify using the algorithm de-
scribed by Goldfeder at al. [4]. Change address identiﬁcation
is challenging due to the variety of existing client software.
BlockSci comes with several—as of this writing, ten—change
address heuristics that can be used individually or in combina-
tion with each other, allowing the analyst to choose or create
a heuristic best suited for their analysis task.
These heuristics create links (edges) in a graph of addresses.
By iterating over all transactions and applying the union-ﬁnd
algorithm on the contained addresses we generate clusters
of addresses. This set of clusters is the output of address
linking. We use the union-ﬁnd implementation by Jakob [5].
Clustering takes only a few minutes, allowing the analyst to
recompute and compare clusters with different heuristics.
In multi-chain mode, BlockSci can enhance the clustering
of a target chain using information from forked chains. Ad-
dresses that exist on multiple chains may be used differently
on them, e.g., combined with a different set of input addresses.
USENIX Association
29th USENIX Security Symposium    2725
visualization, and documentation, enabling easy sharing and
reproducibility of scientiﬁc ﬁndings. We expose the C++
BlockSci library to Python through the pybind11 interface [7].
While we intend Jupyter notebook to be the main interface to
BlockSci, it is straightforward to utilize the analysis library
directly from standalone C++ or Python programs and derive
most of the beneﬁts of BlockSci.
Python is not a language known for performance; unsur-
prisingly, we ﬁnd that it is signiﬁcantly slower to run queries
through the Python interface. Nevertheless, our goal is to al-
low the programmer to spend most of their time interacting
with the Jupyter notebook, while simultaneously ensuring
that the bottleneck parts of queries execute as C++ code. We
illustrate this through an example.
Suppose our goal is to ﬁnd transactions with anomalously
high transaction fees — say 0.1 bitcoins (107 satoshis), worth
about 720 US dollars as of December 2019. The slowest way
to do this would be to write the entire query in Python:
[ tx for block in chain for tx in block if
sum ( txin . value for txin in tx . inputs ) -
sum ( txout . value for txout in
tx . outputs ) > 10**7]
This way does not result in acceptable performance. A ﬁrst
step to improve both performance and conciseness is to have
a built-in function to compute the fee:
[ tx for block in chain for tx in block if
tx . fee > 10**7]
Although tx.fee calls a C++ function, we model it as
a property in the Python interface. Most helper functions
are modeled as properties, unless they are expected to take
signiﬁcant time to compute, or take arguments. tx.fee is
just one of many helpers exposed by the Python library that
execute as C++. We’ve found that most of the analyses in
Section 3 beneﬁt from a small number of helper functions.
Fluent interface. Running this analysis over the entire
blockchain in Python still does not provide great performance.
At the time of writing, the Bitcoin blockchain contains more
than 480 million transactions, for each of which the above
query instantiates a Python object, even though only a few
thousand transactions will eventually be selected.
To make analyses faster without requiring the user to write
complicated C++ code, we’ve developed a ﬂuent interface [8]
to specify graph queries. A ﬂuent interface is an internal
domain-speciﬁc language (DSL) that allows the analyst to
specify queries as a sequence of selections and ﬁlters over
the transaction graph. Method chaining makes specifying se-
quences of operations convenient: every operation returns a
proxy object to which further operations can be applied. Exe-
cution happens lazily for most parts of this interface: either
when the analyst requests a list of the results or when the
query reaches a point that does not allow further traversal
(e.g., after selecting the fee of a transaction). Using the ﬂu-
Figure 3: Distribution of sizes of address clusters in Bitcoin
after applying address-linking heuristics. Sizes 1–2,000 are
shown here but there are many clusters that are much larger.
Cross-chain address clustering uses these additional links to
enhance the clustering of the target chain (cf. Section 3.2).
Figure 3 shows the distribution of cluster sizes for Bitcoin
using the multi-input heuristic only. There are about 474
million clusters in total, of which about 380 million are single
addresses, and about 93 million have between 2 and 20,000
addresses. There are 809 clusters with over 20,000 addresses,
including one supercluster with over 17 million addresses.
Address linking is inherently imperfect, and ground truth is
difﬁcult to obtain on a large scale, since it requires interacting
with service providers. We do not attempt to be comprehen-
sive, resulting in false negatives (i.e., missed edges, resulting
in more clusters than truly exist). More perniciously, most of
the heuristics are also subject to false positives (i.e., spurious
edges), which can lead to “cluster collapse”. In particular, it is
likely that the supercluster above is a result of such a collapse.
Tagging. Address linking is especially powerful when com-
bined with address tagging, i.e., labeling addresses with real-
world identities. This can be useful for forensics and law-
enforcement investigations but it can also violate user pri-
vacy. BlockSci does not provide address tags. Tagging re-
quires interacting with service providers and cannot be done
in an automated way on a large scale. Companies such as
Chainalysis and Elliptic specialize in tagging and forensics,
blockchain.info allows users to publicly tag addresses that
they control, and researchers sometimes provide datasets of
address tags [6]. BlockSci has a limited tagging feature: if
the user provides tags for a subset of addresses, individual
clusters can return tags associated with them.
2.5 Programmer interface
Key challenge: combining speed and expressiveness.
BlockSci aims to come close to the speed of C++ while provid-
ing expressiveness and convenience of a high-level language,
namely Python, for as many analysis tasks as possible.
Python interface. Jupyter notebook is a popular Python
interface for data science. It allows packaging together code,
2726    29th USENIX Security Symposium
USENIX Association
100101102103Cluster size100102104106108Number of clustersTable 1: BlockSci C++ running time for various queries iter-
ating over 610,695 Bitcoin blocks.
Table 2: BlockSci Python running time for the anomalous-fee
query iterating over 610,695 blocks under the three paradigms
discussed in Section 2.5.
Iterating over
Tx headers
Tx outputs
Tx inputs & outputs
Headers in random order
Single-threaded Multithreaded
0.6 sec
0.8 sec
0.9 sec
Unsupported
6.7 sec
9.8 sec
11.3 sec
179.1 sec
Query type
Pure Python
C++ builtin
Fluent interface
Single threaded Multithreaded
18 hrs
58.6 sec
8.7 sec
—
6 min 59 sec
38.3 sec
ent interface, the anomalous-fee query can be expressed as
follows:
chain . blocks . txes . where ( lambda tx : tx . fee >
10**7) . to_list ()
Our interface provides many options to select and ﬁlter
data. The select clause allows to select properties of ob-
jects, though most properties can be conveniently accessed di-
rectly, e.g., txes.fee instead of txes.select(lambda tx:
tx.fee), as the library redirects such property accesses to the