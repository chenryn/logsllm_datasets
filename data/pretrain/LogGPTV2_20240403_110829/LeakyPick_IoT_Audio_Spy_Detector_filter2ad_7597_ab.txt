threat scenarios:
(1) Benign IoT devices that may have undocumented micro-
phones and audio-sensing capabilities, devices for which
audio-sensing capabilities are unexpectedly enabled (e.g., via
a software update), or devices whose wake-word detection is
inaccurate, leading to audio being sent to the cloud without
the users intent and knowledge.
(2) Application-level attacks that cause a benign IoT device to
send audio without the user’s knowledge. For example, the
Amazon Echo contained a vulnerability [21] that allowed a
malicious skill to silently listen. More recently, security re-
searchers have reported [32] the existence of eavesdropping
apps targeting Alexa and Google Assistant. Note that in this
scenario, the IoT device is benign, but it supports third-party
applications that may be malicious.
(3) Active attacks by an external adversary where the adversary
tricks the targeted device to initiate transmission of audio
data by injection of audio signals to the device’s environment
so that the device will identify these as its wake-word. The
main threat in this scenario is the unauthorized invocation
of device or service functionalities.
We do not consider scenarios in which an IoT device is modi-
fied by the adversary to transform the device to act as a bugging
device that records and stores audio locally without sending it to
the network. While feasible, such attacks are much less scalable, as
they must be tailored for each targeted device and are only appli-
cable for devices with sufficient storage space. We note, however,
that LeakyPick is applicable to settings where an adversary has
compromised an IoT device and immediately transmits audio data.
3
Figure 2: System set-up of LeakyPick
3 SOLUTION OVERVIEW
The goal of this paper is to devise a method for regular users to
reliably identify IoT devices that 1) are equipped with a microphone,
2) send recorded audio from the user’s home to external services
without the user’s awareness, and 3) do so unexpectantly in re-
sponse to observing a sound (e.g., unexpected wake-word, software
update re-enabling smart speaker functionality). If LeakyPick can
identify which network packets contain audio recordings, it can
then inform the user which devices are sending audio to the cloud,
as the source of network packets can be identified by hardware
network addresses. Achieving this goal requires overcoming the
following research challenges:
• Device traffic is often encrypted. A naïve solution that simply
looks for audio codecs in network traffic will fail to identify
most audio recordings.
• Device types are not known a priori. Devices transmit audio
in different ways. We need to identify generic approaches
that work with previously unseen devices.
Due to these challenges, our solution cannot passively monitor
network traffic with the goal of differentiating the transmission of
audio recordings from other network traffic. While prior approaches
such as HomeSnitch [34] are able to classify the semantic behavior
of IoT device transmissions (e.g., voice command), they require a
priori training for each manufacturer or device model. Since we
seek to identify this behavior for potentially unknown devices, we
cannot rely on supervised or semi-supervised machine learning.
At a high level, LeakyPick overcomes the research challenges by
periodically transmitting audio (potentially prepended with wake-
words) into a room and monitoring the subsequent network traffic
from devices. As shown in Figure 2, LeakyPick’s main component
is a probing device that emits audio probes into its vicinity. By
temporally correlating these audio probes with observed character-
istics of subsequent network traffic, LeakyPick identifies devices
that have potentially reacted to the audio probes by sending audio
recordings.
LeakyPick identifies network flows containing audio recordings
using two key ideas. First, it looks for traffic bursts following an au-
dio probe. Our observation is that voice-activated devices typically
do not send much data unless they are active. For example, our
analysis shows that when idle, Alexa-enabled devices periodically
send small data bursts every 20 seconds, medium bursts every 300
seconds, and large bursts every 10 hours. We further found that
Probing DeviceGatewayGet trafficIoT deviceInternetPre-print of paper to be published at ACSAC2020
acmDOI: 10.1145/3427228.3427277
when it is activated by an audio stimulus, the resulting audio trans-
mission burst has distinct characteristics. However, using traffic
bursts alone results in high false positive rates.
Second, LeakyPick uses statistical probing. Conceptually, it first
records a baseline measurement of idle traffic for each monitored
device. Then it uses an independent two-sample t-test to compare
the features of the device’s network traffic while being idle and
of traffic when the device communicates after the audio probe.
This statistical approach has the benefit of being inherently device
agnostic. As we show in Section 5, this statistical approach performs
as well as machine learning approaches, but is not limited by a priori
knowledge of the device. It therefore outperforms machine learning
approaches in cases where there is no pre-trained model for the
specific device type available.
Finally, LeakyPick works for both devices that use a wake word
and devices that do not. For devices such as security cameras that
do not use a wake word, LeakyPick does not need to perform any
special operations. Transmitting any audio will trigger the audio
transmission. To handle devices that use a wake word or sound,
e.g., voice assistants, security systems reacting on glass shattering
or dog barking, LeakyPick is configured to prefix its probes with
known wake words and noises (e.g., "Alexa", "Hey Google"). It can
also be used to fuzz test wake-words to identify words that will
unintentionally transmit audio recordings.
4 LEAKYPICK DESIGN
This section describes the central aspects of LeakyPick’s design.
We primarily focus on audio event detection. We then describe our
system implementation on a Raspbery Pi 3B.
4.1 Audio Event Detection
Due to the encryption between devices and back-end cloud systems,
it is not possible to detect audio-related events by inspecting packet
payloads. Instead, LeakyPick identifies audio transmissions by ob-
serving sudden outgoing traffic rate increases for specific devices, or
significant changes in the device’s communication behavior, both
of which can indicate the transmission of audio recordings. We
consider two possible complementary approaches to audio event
detection: (1) a simple baseline method based on network traffic
burst detection, and (2) a statistical approach for detecting apparent
changes in the communication characteristics of monitored devices
in response to performed audio probes. Both audio event detection
mechanisms can be used either while actively probing devices, or,
without active probing (i.e., when the user is at home) to detect
when a device reacts to the noise the user makes (e.g., speaking,
playing music) and notifying the user about such activations.
4.1.1 Burst Detection. Our baseline approach for detecting audio
transmissions is based on burst detection in the observed network
traffic of devices. To do this, we need to first identify the character-
istics of potential audio transmissions. We therefore analyzed the
invocation process and data communication behavior of popular
microphone-enabled IoT devices when they transmit audio.
Our traffic analysis was based on data of popular IoT devices with
integrated virtual assistant support: (1) Echo Dot (Amazon Alexa),
(2) Google Home (Google Assistant), (3) Home Pod (Apple Siri),
and (4) an audio-activated home security system (Hive Hub 360).
4
Richard Mitev, Anna Pazii, Markus Miettinen, William Enck, and Ahmad-Reza Sadeghi
Table 1: Parameters and packet features used by our Burst
Detection and Statistical Probing approaches
Approach
Burst Detection
Statistical Probing
Parameters
Window size 𝑠𝑤
Traffic rate 𝐵𝑎𝑢𝑑𝑖𝑜
Consecutive detections 𝑛
Bin count 𝑘
Packet sequence duration 𝑑
P-value threshold 𝑡
Packet Features
Packet size
MAC/IP
Packet size
Interarrival time
MAC/IP
Our analysis showed that these devices do not typically send much
traffic during normal standby operation. Therefore, it is possible to
detect audio transmissions through the increase in traffic rate they
cause. Our approach is generic in the sense that it is applicable to all
devices sending audio. We chose these microphone-enabled devices,
as they are popular devices produced for a broad range of use cases.
To determine the parameters for burst detection, we monitored the
network traffic of devices in response to audio probes emitted into
the devices’ environment.
We perform audio event detection by observing sudden increases
in the traffic rate emitted by a device that is sustained for a spe-
cific amount of time. This is because an audio transmission will
inevitably cause an increase in the data rate that will typically last
at least for the duration of the transmitted audio sample. This is
consistent with how most voice-controlled IoT devices utilizing
cloud-based back-ends function (Section 2), where local wake-word
detection causes subsequent audio to be streamed to the back-end.
Specifically, LeakyPick performs burst detection by dividing
the network traffic originating from a device into time windows
𝑊 = (𝑤1, 𝑤2, . . .) of size 𝑠𝑤 and calculating for each time window
𝑤𝑖 the sum of packet payload sizes of the packets falling within the
window. We then calculate the average traffic rate 𝐵𝑖 during the
time window 𝑤𝑖 in bytes per second. If the traffic rate 𝐵𝑖 is above a
threshold 𝐵audio during at least 𝑛 consecutive time windows
𝑊𝑖 = (𝑤𝑖, 𝑤𝑖+1, . . . , 𝑤𝑖+𝑘−1)
where 𝑘 ≥ 𝑛, detection is triggered. Empirically, we found that
𝐵audio = 23𝑘𝑏𝑖𝑡/𝑠 is sufficient to separate audio bursts from back-
ground traffic. Therefore, it is reasonable to assume our approach
will work also for systems using audio codecs with lower bandwidth
requirements than Alexa.
As shown in Table 1, LeakyPick uses predefined parameters and
packet features. We extract the packet sizes, the corresponding
MAC or IP (depending on the layer), and (implicitly) the direction
of the packet (leaving or entering the network). To evaluate the
optimal consecutive detection threshold 𝑛 (Section 5.2.1), we used
a fixed window size 𝑠𝑤 = 1𝑠, as common voice commands rarely
take less than a second. For the traffic rate threshold 𝐵𝑎𝑢𝑑𝑖𝑜, we
chose 23𝑘𝑏𝑖𝑡/𝑠. This value is a sufficiently low threshold to capture
any audio and sufficiently high to discard anything else, as voice
recognition services need good voice recording quality (e.g., Alexa’s
Voice Service uses 256𝑘𝑏𝑖𝑡/𝑠, 16-bit PCM at 16𝑘𝐻𝑧 [4]).
Statistical Probing. LeakyPick uses statistical probing to re-
4.1.2
fine audio transmission detection by eliminating cases where traffic
bursts result from non-audio transmission. Most importantly, the
LeakyPick: IoT Audio Spy Detector
approach is generic and does not need a priori knowledge of a de-
vice’s behavior. It also can determine if a device’s communication
behavior changes significantly in response to audio probes.
To detect devices that react to audio, we monitor network traffic
for significant changes in the device’s communication behavior in
response to audio probes. This is done by determining whether the
distribution of the properties of communication packets transmit-
ted by a device after the emission of an audio probe is statistically
different from the distribution of packets observed before the probe
injection. Specifically, LeakyPick uses a 𝑡-test [9], which is one of
the most commonly used statistical tests. Given two data samples,
the test computes a 𝑡-score by determining the data samples’ dis-
tributions’ means and standard deviations, and mapping this to a
𝑝-value. If the 𝑝-value is below a specified threshold, the distribu-
tions are considered statistically different and therefore indicate
that the device reacted to the audio probe. The 𝑝-value threshold
is therefore a system parameter which can be tweaked to produce
a trade-off between sensitivity and false alarm rate. However, this
threshold is independent of the device type, i.e., a system-wide
threshold value is used. The evaluation of this parameter is de-
scribed in Section 5.2.2.
First, the probing device monitors idle device traffic while it is
not emitting audio probes. It captures a sequence
𝑇𝑠 = (𝑝𝑐𝑘1, 𝑝𝑐𝑘2, . . . , 𝑝𝑐𝑘𝑛)
of duration 𝑑 seconds of data packets 𝑝𝑐𝑘𝑖 and calculates a packet
size (or inter-arrival time) distribution vector
(cid:174)𝐹𝑠 = (𝑓1, 𝑓2, . . . , 𝑓𝑘)
by binning the packets 𝑝𝑖 ∈ 𝑇𝑠 into 𝑘 bins based on the size (or inter-
arrival time) of these packets1 and where 𝑓𝑖 denotes the number of
packets assigned to the 𝑖-th bin.
The probing device then emits multiple audio probes and cap-
tures associated data traffic
𝑇𝑝𝑟 = (𝑝𝑐𝑘1, 𝑝𝑐𝑘2, . . . , 𝑝𝑐𝑘𝑛)
of duration 𝑑 seconds and extracts a packet size (time) distribution
vector (cid:174)𝐹𝑝𝑟 using the same binning as for (cid:174)𝐹𝑠. The packet size vectors
(cid:174)𝐹𝑠 and (cid:174)𝐹𝑝𝑟 are then used in the 𝑡-test to determine a 𝑝-value (𝑝)
indicating the likelihood that both frequency samples originate
from the same distribution (i.e., from the distribution the device
produces while in idle mode).
If the 𝑝-value is below a specified threshold 𝑡 (i.e., 𝑝 < 𝑡), we as-
sume the traffic samples are not from the same distribution. That is,
the device has reacted in some way and changed its communication
behavior. To further refine the results, the 𝑝-value resulting from
the packet size distribution is combined with the 𝑝-value of the
inter-arrival time distribution. However, as shown in Section 5.2.2,
only using the 𝑝-value of the packet size distribution is sufficient.
We collected idle data samples 𝑇𝑠 from multiple voice-controlled
devices and discovered that they contained frequently occurring
smaller data bursts (possibly related to, e.g., heartbeat messages)
and infrequently occurring larger data bursts (e.g., state synchro-
nization). This observation indicates it is possible to capture a large
data burst in one of the two samples (𝑇𝑠 or 𝑇𝑝𝑟 ) while missing it
1To determine the binning automatically, we use numpy.histogram with the bin option
auto which uses the maximum of the Sturges and Freedman Diaconis Estimator.
5
Pre-print of paper to be published at ACSAC2020
acmDOI: 10.1145/3427228.3427277
in the other. Therefore, when encountering a 𝑝-value indicating
a possible reaction of the IoT device, the probing test must be re-
peated several times to ensure the observed device behavior change
is caused by the audio probe and not by background traffic bursts.
Table 1 shows the parameters and packet features used for statis-
tical probing. As with burst detection, we extract the packet sizes,
the corresponding MAC or IP, and (implicitly) the direction of the
packets from the recorded traffic. Additionally, we extract packet
inter-arrival times. As discussed in Section 5.2.2, we set the 𝑝-value
threshold 𝑡 to be 0.42-0.43 to achieve an optimal precision while
fixing the packet sequence duration to 𝑑 = 60 seconds.
4.1.3 Voice User Interface. LeakyPick offers also a voice-based user
interface (UI) for conveniently controlling the probing device and
its functions. Our current implementation uses a custom Amazon
Alexa Skill. With this interface, the user can control when the
device is allowed to probe to avoid annoyance while the user is
at home. Additionally, the user can query the results of the last
probing session to learn which devices responded to the probing
and streamed audio to the cloud. We present this Skill-based method