data. Operator F reported that our inferred convention was not
precise because it clustered some customer interfaces; the training
data had incorrectly clustered them (FPs in the ITDK), and our
algorithm had no opportunity to learn the correct convention.
Finally, operator C replied that our convention was correct, but
supplied a second regex that filtered hostnames assigned to cus-
tomer interfaces. Our training data contained 299 customer inter-
face hostnames, 298 of which were correctly not matched by our
naming convention. The filter regex would have filtered the single
stale hostname that we classified as a FP; however, we require a
regex to filter at least three FPs from different routers for a filter
regex to be included in a convention.
00.5K1K1.5K2K2.5K3KPoor201007201104201110201207201304201307201404201412201508201603201609201702201708201803201901201904IPv6201708201901Number of ConventionsGoodPromisingIPv4Learning Regexes to Extract Router Names from Hostnames
IMC ’19, October 21–23, 2019, Amsterdam, Netherlands
FNs in
training
TNs in
training
Unresp.
Training Set
Good
Promising
Application Set
Good
Promising
98 (27.7%)
28 (17.3%)
6281 (75.1%)
429 (69.8%)
256
134
2086
186
112 (24.0%)
85 (34.4%)
6866 (45.1%)
1217 (66.4%)
Table 5: Results of followup probing investigating incon-
gruity with the ITDK. FNs in training data manifest as FPs
in evaluation, which are actually TPs.
7.3 Alias Resolution Gain
We applied the 800 naming conventions we classified as good to the
April 2019 ITDK. There were 18,208 routers with hostnames across
these 800 suffixes; when we applied the conventions to other router
interfaces in the application set, we inferred another 19,136 routers,
a gain of 105%. Figure 13 shows a CCDF of the alias resolution
gain per additional naming convention. Of the 800 conventions,
619 (77.4%) inferred additional aliases, and 181 (22.6%) provided no
alias resolution gain. While 10 suffixes provided 41.7% of the gain,
we required an additional 90 conventions to obtain an additional
43.6% gain. Finally, the remaining 14.7% gain required applying
519 additional conventions. These results show the benefit of our
automated approach; building regexes by hand is labor intensive,
and provides diminishing returns in the long tail.
7.4 Evaluation of IPv4 regexes against IPv6
Two ITDK datasets (August 2017 and January 2019) contain router-
level graphs inferred using Speedtrap [16]. We applied the con-
ventions that we classified as good for the IPv4 graph to the IPv6
graph. For August 2017, there were 107 suffixes in IPv6 with at least
one training router; our conventions predicted the clustering of
hostnames for 86.3% of these suffixes with no FPs. For January 2019,
there were only 60 suffixes in IPv6 with at least one training router;
our conventions predicted the clustering of hostnames for 84.5% of
these suffixes with no FPs.
Operator B (§7.1) assigned hostnames to IPv6-addressed router
interfaces. Our training set for this network in IPv6 consisted of
a single router. However, when we applied our IPv4 naming con-
vention to their IPv6 router interface hostnames, we found 147
hostnames on 40 routers. The operator confirmed that they used a
consistent naming convention across address types, and that IPv4
and IPv6 hostnames with the same extracted name belonged to the
same router.
Taking these findings to their logical conclusion, we applied
the IPv4-inferred naming conventions to the IPv6 topology. For
the January 2019 ITDK, there were 192 suffixes where our naming
conventions applied, 124 had no routers in the training set, and
there were only 416 routers in the set that did. After we applied
our naming conventions to the router interfaces in the application
set, we had inferred 3757 routers, a 9.0 multiplier, and nearly an
order of magnitude more routers than we began with.
8 CONCLUSION
We designed, implemented, evaluated, and validated our system
that automatically learned to extract router names. Our algorithm
scalably builds naming conventions in phases, learning to build
specificity into regexes. We publicly release our source code im-
plementation as part of scamper [15] as well as our inferred con-
ventions [17], allowing researchers to investigate IPv4 and IPv6
router-level congruity in the Internet. Using our system, we find
9.0 times more IPv6 routers and 105% more IPv4 routers than we
started with, in applicable suffixes. Further, our conventions can
guide follow-up probing to improve the accuracy of current Internet-
scale alias resolution techniques, and provide a sound basis for new
learning systems that use hostnames to infer router ownership, link
speeds, and roles of routers in the Internet ecosystem.
Figure 13: CCDF of the alias resolution gain of the 800 nam-
ing conventions we classified as good for suffixes in the
April 2019 ITDK. While the 10 best conventions obtained
41.7% of the alias resolution benefit, a further 609 are re-
quired for the remaining 58.3%. 181 (22.6%) provided no gain.
aliases, we used Ally [27] with ICMP, UDP, and TCP probes, and
Mercator [8]. Table 5 shows the results for both classes of error,
for naming conventions we classed as good or promising. For the
interfaces in the good class that were responsive to alias resolution
at the time of our probing in May 2019, 27.7% of apparent FPs in
the training set and 75.1% of interfaces in the application set were
actually FNs in the ITDK.
The fraction of FNs we found in the promising class was fewer,
and dominated by FNs for ntt.net routers. The FNs for ntt.net in
the training data were due to MIDAR using a single probe type
for each address, because MIDAR assumed that all probe types
observed the same counter when multiple probe types observed a
counter for an address [12]. However, TCP and UDP probes were
deriving responses from different counters, yielding an inference
that two interfaces were not aliases when they were. This limitation
likely applies beyond ntt.net. Other FNs may derive from the fact
that MIDAR’s sliding window can schedule aliases into different
windows, so that they have no opportunity to be resolved as aliases.
Increasing the number of probe types per IP address to compensate
for routers that use different counters for different probe types could
result in fewer IP addresses per sliding window. Importantly, our
naming conventions can guide followup alias resolution probing,
increasing the accuracy and coverage of future ITDKs.
10 for 41.7%of gain519 for 14.7%of gain90 for 43.6%of gain 0 10 100CCDF of GainNumber of Naming Conventions 1 0.8 0.6 0.4 0.2 1IMC ’19, October 21–23, 2019, Amsterdam, Netherlands
Matthew Luckie, Bradley Huffaker, and k claffy
ACKNOWLEDGMENTS
We thank Robert Beverly for providing detailed feedback and com-
pute resource during the development of our system, Young Hyun
and Ken Keys for assistance with the ITDK, and the anonymous
reviewers for their helpful comments. This work was supported by
NSF CNS-1513283, and by the Department of Homeland Security
(DHS) Science and Technology Directorate, Cyber Security Division
(DHS S&T/CSD) via contract number 70RSAT18CB0000013 and co-
operative agreement FA8750-18-2-0049, but this paper represents
only the position of the authors. For Tony McGregor.
[27] Neil Spring, Ratul Mahajan, and David Wetherall. 2002. Measuring ISP topologies
with Rocketfuel. In SIGCOMM. 133–145.
[28] Walter Willinger, David Alderson, and John C. Doyle. 2009. Mathematics and
the Internet: a Source of Enormous Confusion and Great Potential. Notices of
AMS 56, 5 (May 2009).
[29] Ming Zhang, Yaoping Ruan, Vivek Pai, and Jennifer Rexford. 2006. How DNS
Misnaming Distorts Internet Topology Mapping. In USENIX ATC. 34–39.
REFERENCES
[1] Brice Augustin, Xavier Cuvellier, Benjamin Orgogozo, Fabien Viger, Timur Fried-
man, Matthieu Latapy, Clémence Magnien, and Renata Teixeira. 2006. Avoiding
traceroute anomalies with Paris traceroute. In IMC. Rio de Janeiro, Brazil, 153–
158.
[2] Rohit Babbar and Nidhi Singh. 2010. Clustering Based Approach to Learning
Regular Expressions over Large Alphabet for Noisy Unstructured Text. In AND.
43–50.
[3] Alberto Bartoli, Andrea De Lorenzo, Eric Medvet, and Fabiano Tarlao. 2016. Infer-
ence of Regular Expressions for Text Extraction from Examples. IEEE Transactions
on Knowledge and Data Engineering 28, 5 (May 2016), 1217–1230.
[4] Adam Bender, Rob Sherwood, and Neil Spring. 2008. Fixing Ally’s growing pains
with velocity modeling. In IMC. 337–342.
[5] CAIDA. 2019. Macroscopic Internet Topology Data Kit (ITDK). https://www.
caida.org/data/internet-topology-data-kit/.
[6] Joseph Chabarek and Paul Barford. 2013. What’s in a Name? Decoding Router
[7] Andrew D. Ferguson, Jordan Place, and Rodrigo Fonseca. 2013. Growth Analysis
Interface Names. In HotPlanet. 3–8.
of a Large ISP. In IMC. 347–352.
[8] Ramesh Govindan and Hongsuda Tangmunarunkit. 2000. Heuristics for Internet
Map Discovery. In INFOCOM. 1371–1380.
[9] Philip Hazel. 2019. Perl-compatible regular expression library. https://www.
pcre.org/.
2010), 50–55.
[10] Bradley Huffaker, Marina Fomenkov, and kc claffy. 2014. DRoP:DNS-based Router
Positioning. CCR 44, 3 (July 2014), 6–13.
[11] Ken Keys. 2010. Internet-Scale IP Alias Resolution Techniques. CCR 40, 1 (Jan.
[12] Ken Keys, Young Hyun, Matthew Luckie, and k claffy. 2013. Internet-Scale IPv4
Alias Resolution with MIDAR. IEEE/ACM Transactions on Networking 21, 2 (April
2013), 383–399.
[13] Anukool Lakhina, John W. Byers, Mark Crovella, and Peng Xie. 2003. Sampling
biases in IP topology measurements. In INFOCOM.
[14] Yunyao Li, Rajasekar Krishnamurthy, Sriram Raghavan, Shivakumar
Regular Expression Learning
Vaithyanathan, and H. V. Jagadish. 2008.
for Information Extraction. In EMNLP. 21–30.
[15] Matthew Luckie. 2010. Scamper: a Scalable and Extensible Packet Prober for
Active Measurement of the Internet. In IMC. 239–245.
[16] Matthew Luckie, Robert Beverly, William Brinkmeyer, and k claffy. 2013. Speed-
trap: Internet-scale IPv6 Alias Resolution. In IMC. 119–126.
[17] Matthew Luckie, Bradley Huffaker, and k claffy. 2019. Data supplement for
“Learning Regexes to Extract Router Names from Hostnames”. https://www.
caida.org/publications/papers/2019/hoiho/.
[18] Christopher D. Manning, Prabhakar Raghavan, and Hinrich Schutze. 2009. An
Introduction to Information Retrieval. Cambridge University Press. https://nlp.
stanford.edu/IR-book/pdf/irbookonlinereading.pdf.
[19] Pietro Marchetta, Valerio Persico, and Antonio Pescapé. 2013. Pythia: Yet Another
Active Probing Technique for Alias Resolution. In CoNEXT. 229–234.
[20] Mozilla Foundation. 2017. Public Suffix List. https://publicsuffix.org/list/.
[21] Karin Murthy, Deepak P., and Prasad M. Deshpande. 2012. Improving Recall of
Regular Expressions for Information Extraction. In WISE. 455–467.
[22] New Zealand Department of Conservation Te Papa Atawhai. 2019. Yellow-eyed
penguin/hoiho. https://www.doc.govt.nz/nature/native-animals/birds/birds-a-
z/penguins/yellow-eyed-penguin-hoiho/.
[23] William M. Rand. 1971. Objective Criteria for the Evaluation of Clustering
Methods. J. Amer. Statist. Assoc. 66, 336 (Dec. 1971), 846–850.
[24] Justine Sherry, Ethan Katz-Bassett, Mary Pimenova, Harsha V. Madhyastha,
Thomas Anderson, and Arvind Krisnamurthy. 2010. Resolving IP Aliases with
Prespecified Timestamps. In IMC. 172–178.
[25] Rob Sherwood, Adam Bender, and Neil Spring. 2008. DisCarte: A Disjunctive
Internet Cartographer. In SIGCOMM. 303–314.
[26] Neil Spring, Mira Dontcheva, Maya Rodrig, and David Wetherall. 2004. How to
Resolve IP Aliases. UW-CSE-TR 04-05-04.