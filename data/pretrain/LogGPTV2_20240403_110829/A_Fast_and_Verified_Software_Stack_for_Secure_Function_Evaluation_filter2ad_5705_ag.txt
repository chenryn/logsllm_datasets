}
return (adv = real);
}
}.
Figure 12: Security of a two-party protocol protocol.
A DETAILS OF EASYCRYPT FORMALIZATION
The top-level abstraction in our formalization is a high-level view
of two-party protocols, which is later independently refined to
derive formalizations of both oblivious transfer and secure function
evaluation. We introduce these concepts by focusing on a classic
oblivious transfer protocol [13, 47] and discussing its security proof.
Its small size and relative simplicity make it a good introductory
example to EasyCrypt formalization. We also introduce our general
framework for dealing with hybrid arguments in EasyCrypt.
Two-Party Protocols. In EasyCrypt, declarations pertaining to
abstract concepts meant to later be refined can be grouped into
named theories such as the one shown in Figure 11. Any lemma
proved in such a theory is also a lemma of any implementation (or
instantiation) where the theory axioms hold.
theory Protocol.
type input1, output1.
type input2, output2.
op validInputs: input1 → input2 → bool.
op f: input1 → input2 → output1 ∗ output2.
type rand1, rand2, conv.
op prot: input1→ rand1→ input2→ rand2→ conv ∗ output1 ∗ output2.
. . .
end Protocol.
Figure 11: Abstract Two-Party Protocol.
Session I4:  Verifying CryptoCCS’17, October 30-November 3, 2017, Dallas, TX, USA2003clone Protocol as OT with
type input1 = bool array,
type output1 = msg array,
type leak1 = int,
type input2 = (msg ∗ msg) array,
type output2 = unit,
type leak2 = int,
op ϕ1 (i1: bool array) = length i1,
op ϕ2 (i2: (msg ∗ msg) array) = length i2,
op f (i1: bool array) (i2: (msg ∗ msg) array) = i1i2 .
op validInputs(i1: bool array) (i2: (msg ∗ msg) array) =
0 < length i1 ≤ nmax ∧ length i1 = length i2,
. . .
Figure 13: Instantiating Two-Party Protocols.
non-adaptive adversary). We omit module types for the random-
ness generators R1 and R2, as they only provide a single procedure
gen taking some leakage and producing some randomness. We also
omit the dual security game for Party 2.
The security game, modelled as module Sec1, is explicitly pa-
rameterized by two randomness-producing modules R1 and R2, a
simulator S1 and an adversary A1. This enables the code of proce-
dures defined in Sec1 to make queries to any procedure that appears
in the module types of its parameters. However, they may not di-
rectly access the internal state or procedures that are implemented
by concrete instances of the module parameters, when these are
hidden by the module type. We omit the indices representing ran-
domness generators whenever they are clear from the context.
The game implements, in a single experiment, both the real
and ideal worlds. In the real world, the protocol prot is used with
adversary-provided inputs to construct the adversary’s view of the
protocol execution. In the ideal world, the functionality is used to
compute Party 1’s output, which is then passed along with Party
1’s input and Party 2’s leakage to the simulator, which produces
the adversary’s view of the system. We prevent the adversary from
trivially winning by denying it any advantage when it chooses
invalid inputs.
A two-party protocol prot (parameterized by its randomness-
producing modules) is said to be secure with leakage Φ = (ϕ1, ϕ2)
whenever, for any adversary Ai implementing AdvProt
(i ∈ {1, 2}),
there exists a simulator Si implementing Simi such that
i
AdvProti, Φ
prot,Si ,R1,R2
(Ai ) = |2 · Pr[Seci (R1, R2, Si, Ai ) : res] − 1|
is small, where res denotes the Boolean output of procedure main.
Intuitively, the existence of such a simulator Si implies that the
protocol conversation and output cannot reveal any more informa-
tion than the information revealed by the simulator’s input.
Oblivious Transfer Protocols. We can now define oblivious
transfer, restricting our attention to a specific notion useful for
constructing general SFE functionalities. To do so, we clone the
Protocol theory, which makes a literal copy of it and allows us to
instantiate its abstract declarations with concrete definitions. When
cloning a theory, everything it declares or defines is part of the
clone, including axioms and lemmas. Note that lemmas proved
in the original theory are also lemmas in the clone. The partial
instantiation is shown in Figure 13.
We restrict the input, output and leakage types for the parties, as
well as the leakage functions and the functionality f. The chooser
(Party 1) takes as input a list of Boolean values (i.e., a bit-string)
she needs to encode, and the sender (Party 2), takes as input a
list of pairs of messages (which can also be seen as alternative
encodings for the Boolean values in Party 1’s inputs). Together, they
compute the array encoding the chooser’s input, revealing only
the lengths of each other’s inputs. We declare an abstract constant
n that bounds the size of the chooser’s input. This introduces an
implicit quantification on the bound n in all results we prove.
Defining OT security is then simply a matter of instantiating
the general notion of security for two-party protocols via cloning.
Looking ahead, we use AdvOTi to denote the resulting instance
of AdvProti, Φ, where Φ = (length, length), and similarly we write
AdvOT
the types for adversaries against the OT instantiation.
i
Garbling schemes. Garbling schemes [12] (Figure 14) are operators
on functionalities of type func. Such functionalities can be evaluated
on some input using an eval operator. In addition, a functionality can
be garbled using three operators (all of which may consume random-
ness). funG produces the garbled functionality, inputK produces an
input-encoding key, and outputK produces an output-encoding key.
The garbled evaluation evalG takes a garbled functionality and some
encoded input and produces the corresponding encoded output. The
input-encoding and output-decoding functions are self-explanatory.
In practice, we are interested in garbling functionalities encoded as
type func, input, output.
op eval : func → input → output.
op valid: func → input → bool.
type rand, funcG, inputK, outputK.
op funcG : func → rand → funcG.
op inputK : func → rand → inputK.
op outputK: func → rand → outputK.
type inputG, outputG.
op evalG : funcG → inputG → outputG.
op encode: inputK → input → inputG.
op decode: outputK → outputG → output.
Figure 14: Abstract Garbling Scheme.
Boolean circuits and therefore fix the func and input types and the
eval function. Circuits themselves are represented by their topology
and their gates. A topology is a tuple (n, m, q, A, B), where n is the
number of input wires, m is the number of output wires, q is the
number of gates, and A and B map to each gate its first and second
input wire respectively. A circuit’s gates are modelled as a map
G associating output values to a triple containing a gate number
and the values of the input wires. Gates are modelled polymor-
phically, allowing us to use the same notion of circuit for Boolean
circuits and their garbled counterparts. We only consider projective
schemes [12], where Boolean values on each wire are encoded using
a fixed-length random token. This fixes the type funcG of garbling
schemes, and the outputK and decode operators.
Following the Garble1 construction of Bellare et al. [12], we con-
struct our garbling scheme using a variant of Yao’s garbled circuits
based on a pseudo-random permutation, via an intermediate Dual-
Key Cipher (DKC) construction. We denote the DKC encryption
Session I4:  Verifying CryptoCCS’17, October 30-November 3, 2017, Dallas, TX, USA2004type leak.
op Φ: func → leak.
module type Sim = {
fun sim(x: output, l: leak): funcG ∗ inputG
module type AdvGb = {
fun choose(): func ∗ input
fun distinguish(F: funcG, X: inputG) : bool
}.
}.
module SIM(R: Rand, S: Sim, A: AdvGb) = {
fun main() : bool = {
var real, adv, f, x, F, X;
(f,x) = A.gen_query();
real ←$ {0,1};
if (!valid f x)
adv ←$ {0,1};
else {
if (real) {
r = R.gen(Φ f);
F = funcG f r;
X = encode (inputK f r) x;
} else {
(F,X) = S.sim(f(x),Φ f);
}
adv = A.dist(F,X);
}
return (adv = real);
}
}.
Figure 16: Security of garbling schemes.
with E, and DKC decryption with D. Both take four tokens as ar-
gument: a tweak that we generate with an injective function and
use as unique IV, two keys, and a plaintext (or ciphertext). We give
functional specifications to the garbling algorithms in Figure 15.
For clarity, we denote functional folds using stateful for loops.
type topo = int ∗ int ∗ int ∗ int array ∗ int array.
type α circuit = topo ∗ (int ∗ α ∗ α ,α ) map.
type leak = topo.
type input, output = bool array.
type func = bool circuit.
type funcG = token circuit.
type inputG, outputG = token array.
op evalG f i =
let ((n,m,q,A,B),G) = f in
let evalGate = λ g x1 x2,
let x1,0 = lsb x1 and x2,0 = lsb x2 in
D (tweak g x1,0 x2,0) x1 x2 G[g,x1,0,x2,0] in
let wires = extend i q in (∗ extend the array with q zeroes ∗)
let wires = map (λ g, evalGate g A[g] B[g]) wires in (∗ decrypt wires ∗)
sub wires (n + q − m) m.
type rand, inputK = ((int ∗ bool),token) map.
op encode iK x = init (length x) (λ k, iK[k,x[k]]).
op inputK (f:func) (r:((int ∗ bool),token) map) =
let ((n,_,_,_,_),_) = f in filter (λ x y, 0 ≤fst x < n) r.
op funcG (f:func) (r:rand) =
let ((n,m,q,A,B),G) = f in
for (g,xa,xb) ∈ [0..q] ∗ bool ∗ bool
let a = A[g] and b = B[g] in
let ta = r[a,xa] and tb = r[b,xb] in
(cid:72)G[g,ta,tb] = E (tweak g ta tb) ta tb r[g,G[g,xa,xb]]
((n,m,q,A,B),(cid:72)G).
Figure 15: SomeGarble: our Concrete Garbling Scheme.
Security of Garbling Schemes. The privacy property of garbling
schemes required by Yao’s SFE protocol is more conveniently cap-
tured using a simulation-based definition. Like the security notions
for protocols, the privacy definition for garbling schemes is param-
eterized by a leakage function upper-bounding the information
about the functionality that may be leaked to the adversary. (We
consider only schemes that leak at most the topology of the circuit.)
Consider efficient non-adaptive adversaries that provide two pro-
cedures: i. choose takes no input and outputs a pair (f,x) composed
of a functionality and some input to that functionality; ii. on input
a garbled circuit and garbled input pair (F,X), distinguish outputs
a bit b representing the adversary’s guess as to whether he is in-
teracting with the real or ideal functionality. Formally, we define
the SIM-CPAΦ advantage of an adversary A of type AdvGb against
garbling scheme Gb = (funcG,inputK,outputK) and simulator S as
AdvSIM-CPAΦ
Gb,R,S
(A) = |2 · Pr[SIM(R, S, A) : res] − 1| .
Gb,R,S
(A) is small.
A garbling scheme Gb using randomness generator R is SIM-CPAΦ-
secure if, for all adversary A of type AdvGb, there exists an efficient
simulator S of type Sim such that AdvSIM-CPAΦ
Following [12], we establish simulation-based security via a gen-
eral result that leverages a more convenient indistinguishability-
based security notion denoted IND-CPAΦtopo: we formalize a gen-
eral theorem stating that, under certain restrictions on the leakage
function Φ, IND-CPAΦ-security implies SIM-CPAΦ security. This
result is discussed below as Lemma A.1.
A modular proof. The general lemma stating that IND-CPA-security
implies SIM-CPA-security is easily proved in a very abstract model,
and is then as easily instantiated to our concrete garbling setting.
We describe the abstract setting to illustrate the proof methodology
enabled by EasyCrypt modules on this easy example.
module type AdvIND = {
fun choose(): ptxt ∗ ptxt
fun distinguish(c:ctxt): bool
}.
module IND (R:Rand, A:AdvIND) = {
fun main(): bool = {
var p0, p1, p, c, b, b', ret, r;
(p0,p1) = A.choose();
if (valid p0 ∧ valid p1 ∧ Φ p0 = Φ p1) {
b ←$ {0,1};
p = if b then p1 else p0;
r = R.gen(|p|);
c = enc p r;
b' = A.distinguish(c);
ret = (b = adv);
}
else ret ←$ {0,1};
return ret;
}
}.
Figure 17: Indistinguishability-based Security for Garbling
Schemes.
Session I4:  Verifying CryptoCCS’17, October 30-November 3, 2017, Dallas, TX, USA2005The module shown in Figure 17 is a slight generalization of the stan-
dard IND-CPA security notions for symmetric encryption, where
some abstract leakage operator Φ replaces the more usual check
that the two adversary-provided plaintexts have the same length.We
formally prove an abstract result that is applicable to any circum-
stances where indistinguishability-based and simulation-based no-
tions of security interact. We define the IND-CPA advantage of an
adversary A of type AdvIND against the encryption operator enc
using randomness generator R with leakage Φ as
AdvIND-CPAΦ
enc,R
(A) = |2 · Pr[Game_IND(R,A): res] − 1|
where R is the randomness generator used in the concrete theory.
In the rest of this subsection, we use the following notion of in-
vertibility. A leakage function Φ on plaintexts (when we instantiate
this notion on garbling schemes these plaintexts are circuits and
their inputs) is efficiently invertible if there exists an efficient algo-
rithm that, given the leakage corresponding to a given plaintext,
can find a plaintext consistent with that leakage.
Lemma A.1 (IND-CPA-security implies SIM-CPA-security). If
Φ is efficiently invertible, then for every efficient SIM-CPA adversary
A of type AdvGb, one can build an efficient IND-CPA adversary B
and an efficient simulator S such that
AdvSIM-CPAΦ
enc,S
(A) = AdvIND-CPAΦ
enc
(B).
Proof (Sketch). Using the inverter for Φ, B computes a second
plaintext from the leakage of the one provided by A and uses this
as the second part of her query in the IND-CPA game. Similarly,
simulator S generates a simulated view by taking the leakage it
receives and computing a plaintext consistent with it using the
Φ-inverter. The proof consists in establishing that A is called by B
in a way that coincides with the SIM-CPA experiment when S is
used in the ideal world, and is performed by code motion.
□
Finishing the proof. We reduce the IND-CPAΦtopo-security of
SomeGarble to the DKC-security of the underlying DKC primitive
(see [12]). In the lemma statement, c is an abstract upper bound on
the size of circuits (in number of gates) that are considered valid.
The lemma holds for all values of c that can be encoded in a token
minus two bits.
Lemma A.2 (SomeGarble is IND-CPAΦtopo-secure). For every
efficient IND-CPA adversary A of type AdvGb−IND, we can construct
a efficient DKC adversary B such that
Adv
IND-CPAΦtopo
SomeGarble
(A) ≤ (c + 1) · AdvDKC
SomeGarble(B).
Proof (Sketch). The constructed adversary B, to simulate the
garbling scheme’s oracle, samples a wire ℓ0 which is used as pivot
in a hybrid construction where: i. all tokens that are revealed by
the garbled evaluation on the adversary-chosen inputs are garbled
normally, using the real DKC scheme; otherwise ii. all tokens for
wires less than ℓ0 are garbled using encryptions of random tokens
(instead of the real tokens representing the gates’ outputs); iii. to-
kens for wire ℓ0 uses the real-or-random DKC oracle; and iv. all
tokens for wires greater than ℓ0 are garbled normally.
Here again, the generic hybrid argument (Figure 4) can be in-
stantiated and applied without having to be proved again, yielding
a reduction to an adaptive DKC adversary. A further reduction
allows us to then build a non-adaptive DKC adversary, since all
DKC queries made by B are in fact random and independent. □
From Lemmas A.1 and A.2, we can conclude with a security
theorem for our garbling scheme.
Theorem A.3 (SomeGarble is SIM-CPAΦtopo-secure). For every
SIM-CPA adversary A that implements AdvGb, one can construct an
efficient simulator S and a DKC adversary B such that
Adv
SIM-CPAΦtopo
SomeGarble,S (A) ≤ (c + 1) · AdvDKC
SomeGarble(B).
Proof (Sketch). Lemma A.1 allows us to construct from A
the simulator S and an IND-CPAadversary C. From C, Lemma A.2
allows us to construct B and conclude.
□
Session I4:  Verifying CryptoCCS’17, October 30-November 3, 2017, Dallas, TX, USA2006