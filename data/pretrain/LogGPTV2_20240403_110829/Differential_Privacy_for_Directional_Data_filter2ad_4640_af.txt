central
local
10−2
100
102
104
𝜖 for pure 𝜖-differential privacy
(a) MAE over various values of 𝜖 under directional and pure differ-
ential privacy (indicated by the top and bottom axis, respectively).
)
y
c
a
v
i
r
p
-
∡
𝑑
𝜖
(
0.001
0.01
0.1
1
10
100
𝜋
×
1000𝜖
[
1
−
]
c
6.002546 5.959842 5.971121 5.991626 6.003013 5.949697
5.959067 6.034504 6.011822 5.713794 5.789084 5.989284
5.832634 5.939577 6.063296 3.351836 3.820363 5.839461
4.990575 5.253079 5.570354 0.320614 0.406752 0.695489
1.196922 1.896170 1.187660 0.035210 0.052720 0.034713
0.121189 0.537524 0.120148 0.003687 0.014997 0.003678
0.012263 0.171658 0.012125 0.000369 0.004654 0.000369
- W L
- W L
- V M F
r a l
e n t
- P u r
c
r a l
e n t
r a l
- V M F
e n t
c
Model-Mechanism
l o c a l
- P u r
l o c a l
l o c a l
6
4
2
]
h
[
E
A
M
0
(b) Exemplary MAE values for various settings of the mechanisms
(directional privacy; central and local model in cols. 1–3 and 4–6).
Figure 5: Comparison of the mean absolute error (MAE) be-
tween original and perturbed average wake times.
𝑁
adapt the usual expression to its circular variant ∅(cid:0)𝑑𝑝(˜𝒕, ¯𝑡)(cid:1).
to the original, unperturbed data. To this end, we chose the mean
𝑖=1|˜𝑡𝑖 − ¯𝑡|.
absolute error (MAE), which is normally defined as 1
𝑅
However, as noted earlier, we work with periodic data, so we must
Figure 5a shows the MAE of the average wake time based on
the original and perturbed values. In the local model (dashed lines),
both directional privacy mechanisms clearly outperform WL across
the entire range of privacy parameters 𝜖. For directional privacy
(top scale), Purkayastha shows the lowest errors due to its higher
concentration at the mode. However, for pure DP (bottom scale),
VMF can be employed with smaller 𝑑2-sensitivity Δ2 = 2 < 𝜋 = Δ∡
(orange line), which even outperforms Purkayastha in that case.
In the central model (solid lines), WL and Purkayastha perform
similarly well for large 𝜖 where VMF performs worst. However, in
the strong privacy domain with small 𝜖, WL is worst, with Purka-
yastha providing the best directional privacy guarantees and VMF
with the reduced 𝑑2-sensitivity yielding the best differential privacy
guarantees for 𝜖 ≲ 100.25. Figure 5b lists exemplary MAE values
specifically for directional privacy to support these observations
with concrete numbers.
Strikingly, the local model outperforms the central one in this
experiment, which confirms what we anticipated in Section 4.2.1:
The sensitivity of the circular mean is the same in both privacy
models, where the locally injected noise gradually cancels out when
many responses are averaged together, yielding lower errors. In
both models, Purkayastha and VMF reach the lowest errors for a
given directional and differential privacy parameter 𝜖, respectively.
Session 4D: Differential Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1214𝜌
s
’
n
a
m
r
a
e
p
S
1.0
0.8
0.6
0.4
0.2
0.0
𝜖 for directional 𝜖𝑑∡-privacy
10−2
102
100
Mech.
VMF Δ∡
VMF Δ2
Pur
WL
Model
central
local
10−2
100
102
104
𝜖 for pure 𝜖-differential privacy
Figure 6: Comparison of Spearman’s 𝜌 across the four age
groups, over 𝜖 under directional and pure differential pri-
vacy (indicated by the top and bottom axis, respectively).
Ranking statistics. In the context of the NSF’s sleep study, one
aspect is to compare the wake (or bed) times among different
groups, and determine, e.g., who gets up first or goes to bed latest.
Concretely, let us suppose we want to infer the order of wake-
up times among the four age groups (Generation-X, -Y, -Z, and
Baby Boomers) from the survey data. As non-private baseline, we
compute the average wake-up time for each group on the original
dataset, and from there determine the ranking of the groups. We
then simulate the survey being conducted in both the central and
local privacy models as before, and determine the ranking of the age
groups from the sanitized average wake-up times. To measure the
impact of the privacy mechanisms on such statistics, we compute
Spearman’s rank correlation coefficient (also called Spearman’s 𝜌)
between the perturbed and original ranking of the four age groups.
Figure 6 shows Spearman’s rank correlation coefficient 𝜌 (aver-
aged over all runs) for the different mechanisms over the parameter
range of 𝜖 and both privacy models. As we can see, the observations
on the rank correlation are in line with the observations on the
mean absolute errors reported in the previous experiment.
In the central model, Purkayastha and Wrapped Laplace (WL) (over-
lapping green and red lines) achieve similar 𝜌 values and both
outperform VMF at virtually any given privacy level 𝜖 under both
directional and differential privacy. However, in a small range of 𝜖
just below 1, Purkayastha shows higher correlation than WL, and
VMF with the 𝑑2-sensitivity also overtakes WL under pure DP.
The local model generally shows a better privacy–utility trade-off
than in the previous results. Notably, Purkayastha appears to reach
the highest correlation values among the three mechanisms under
directional privacy, at virtually any given privacy level, which
is well observable for 10−3 ≲ 𝜖 ≲ 1. Under pure DP, the VMF
mechanism with the 𝑑2-sensitivity stands out again and achieves
even higher correlation scores than Purkayastha.
4.3 Private histograms for spatio-temporal data
Histograms and heatmaps are practical tools to visualize and inter-
pret empirical data, particularly in one or two dimensions.
Scenarios. Suppose a location-based service, such as Google Maps
or Foursquare, wants to use check-in data (e.g., from users’ smart-
phones) to create daily histograms of popular visit times of busi-
nesses, such as stores or restaurants. This could allow other users to
estimate how busy a location or area is during different times of the
day, or provide store owners with insights on customer activity. The
desired data is often privacy-sensitive, so users may distrust the data
collector and be reluctant to share their whereabouts during the
course of the day. To enable such use cases in a privacy-preserving
way, we follow the local model and sanitize each user’s data before
it is collected and aggregated into histograms.
Dataset description. We use the publicly available Gowalla dataset
from [6]. Gowalla was a location-based social networking website
where users could share their locations by checking in. It contains
a total of 6,442,890 check-ins with their location and time recorded
between Feb. 2009 and Oct. 2010.
Independent analysis of temporal and spatial data. We simu-
4.3.1
late data collection in the local model by perturbing the time-of-day
and location of each check-in independently.
For the periodic times-of-day, we consider all check-ins at the top
100 locations. We follow a sanitization procedure as with the sleep
data in Section 4.2.2 and use the VMF and Purkayastha mechanisms
on S1, with Clipped (CL) and Wrapped Laplace (WL) as baselines
(cf. Sections 3.2, 3.3 and 3.6). Similarly, to sanitize the locations, we
take all check-ins from the top 100 users and represent them as unit
vectors on S2. We then apply the appropriate VMF and Purkayastha
mechanisms, with Polar Laplace (cf. Section 3.6.3) as baseline.
After gathering the perturbed data, we compute the following
histograms: a check-in time histogram for each of the 100 locations
with one bin for each hour of the day, and a check-in location his-
togram for each of the top 100 users with 90×180 bins, one for each
pair of subsequent degrees of latitude and longitude. To stabilize
the results, we repeat this procedure in every setting for 100 runs.
Error metrics. As measures of error between the sanitized and
original histograms, we again use the mean absolute error (MAE), as
well as the Earth Mover’s Distance (EMD) with a suitable distance
matrix: For the distance between two check-in time histogram bins,
we use their circular distance in hours. For 2D location histograms
with latitude–longitude bins, we use the great-circle distance, i.e.
the actual surface distance, between the geographic positions on
the sphere corresponding to the bin centers. Unlike the MAE or
MSE which look at the error of each histogram bin individually, the
EMD so provides a measure of error that is aware of the semantics
of the underlying data by considering how far off the target bin is
from the original bin when counting a perturbed check-in location.
Results. Figure 7a shows the errors for the check-in time his-
tograms. For large 𝜖, both Wrapped and Clipped Laplace as well
as Purkayastha show similar errors that are lower than VMF. For
medium to small 𝜖, our directional mechanisms gain an advantage
over WL and CL with Purkayastha generally achieving the lowest
errors under directional privacy, whereas VMF wins under pure
DP when using the smaller 𝑑2-sensitivity. In this case, CL performs
worst with generally large MAE and EMD since virtually all counts
will be in the first or last histogram bin.
Session 4D: Differential Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1215𝜖 for directional 𝜖𝑑∡-privacy
101
10−1
𝜖 for directional 𝜖𝑑∡-privacy
101
10−1
1e−2
D
M
E
2
1
0
10−1
101
E
A
M
3
2
1
0
VMF Δ∡
VMF Δ2
Pur
WL
CL
10−1
101
1e3
D
M
E
2
1
0
E
A
M
3
2
1
0
VMF Δ∡
VMF Δ2
Pur
Polar
10−1
101
10−1
101
𝜖 for directional 𝜖𝑑∡-privacy
𝜖 for directional 𝜖𝑑∡-privacy
1e−5
10−1
101
10−1
101
𝜖 for pure 𝜖-differential privacy
𝜖 for pure 𝜖-differential privacy
𝜖 for pure 𝜖-differential privacy
𝜖 for pure 𝜖-differential privacy
(a) Check-in times
(b) Check-in locations
Figure 7: Comparison of mean absolute error (MAE) and Earth Mover’s Distance (EMD) between check-in histograms.
Figure 7b shows the errors for the check-in location histograms.
In terms of the MAE, VMF is worst while Purkayastha and Polar
Laplace are almost indistinguishable. However, if we consider the
EMD as metric with spatial awareness, we recognize that the Polar
mechanism has a region with increased error for 10−1 ≲ 𝜖 ≲ 10,
corresponding to the “bump” we describe in Section 3.6.3. Thus, in
conclusion, the Purkayastha distribution shows the lowest errors
for directional privacy, whereas VMF benefits from the reduced
𝑑2-sensitivity under pure DP.
4.3.2 Location busyness during different times of day. The follow-
ing experiment constitutes the combined application of directional
privacy mechanisms to both spatial and temporal data. Our goal is
to derive histograms of check-ins at the top 1000 locations from the
Gowalla dataset over different times of day, where we perturb both
the check-in times and locations using the Purkayastha mechanism,