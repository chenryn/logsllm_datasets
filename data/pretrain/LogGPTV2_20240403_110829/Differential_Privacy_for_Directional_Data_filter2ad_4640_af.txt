central
local
10âˆ’2
100
102
104
ğœ– for pure ğœ–-differential privacy
(a) MAE over various values of ğœ– under directional and pure differ-
ential privacy (indicated by the top and bottom axis, respectively).
)
y
c
a
v
i
r
p
-
âˆ¡
ğ‘‘
ğœ–
(
0.001
0.01
0.1
1
10
100
ğœ‹
Ã—
1000ğœ–
[
1
âˆ’
]
c
6.002546 5.959842 5.971121 5.991626 6.003013 5.949697
5.959067 6.034504 6.011822 5.713794 5.789084 5.989284
5.832634 5.939577 6.063296 3.351836 3.820363 5.839461
4.990575 5.253079 5.570354 0.320614 0.406752 0.695489
1.196922 1.896170 1.187660 0.035210 0.052720 0.034713
0.121189 0.537524 0.120148 0.003687 0.014997 0.003678
0.012263 0.171658 0.012125 0.000369 0.004654 0.000369
- W L
- W L
- V M F
r a l
e n t
- P u r
c
r a l
e n t
r a l
- V M F
e n t
c
Model-Mechanism
l o c a l
- P u r
l o c a l
l o c a l
6
4
2
]
h
[
E
A
M
0
(b) Exemplary MAE values for various settings of the mechanisms
(directional privacy; central and local model in cols. 1â€“3 and 4â€“6).
Figure 5: Comparison of the mean absolute error (MAE) be-
tween original and perturbed average wake times.
ğ‘
adapt the usual expression to its circular variant âˆ…(cid:0)ğ‘‘ğ‘(Ëœğ’•, Â¯ğ‘¡)(cid:1).
to the original, unperturbed data. To this end, we chose the mean
ğ‘–=1|Ëœğ‘¡ğ‘– âˆ’ Â¯ğ‘¡|.
absolute error (MAE), which is normally defined as 1
ğ‘…
However, as noted earlier, we work with periodic data, so we must
Figure 5a shows the MAE of the average wake time based on
the original and perturbed values. In the local model (dashed lines),
both directional privacy mechanisms clearly outperform WL across
the entire range of privacy parameters ğœ–. For directional privacy
(top scale), Purkayastha shows the lowest errors due to its higher
concentration at the mode. However, for pure DP (bottom scale),
VMF can be employed with smaller ğ‘‘2-sensitivity Î”2 = 2 < ğœ‹ = Î”âˆ¡
(orange line), which even outperforms Purkayastha in that case.
In the central model (solid lines), WL and Purkayastha perform
similarly well for large ğœ– where VMF performs worst. However, in
the strong privacy domain with small ğœ–, WL is worst, with Purka-
yastha providing the best directional privacy guarantees and VMF
with the reduced ğ‘‘2-sensitivity yielding the best differential privacy
guarantees for ğœ– â‰² 100.25. Figure 5b lists exemplary MAE values
specifically for directional privacy to support these observations
with concrete numbers.
Strikingly, the local model outperforms the central one in this
experiment, which confirms what we anticipated in Section 4.2.1:
The sensitivity of the circular mean is the same in both privacy
models, where the locally injected noise gradually cancels out when
many responses are averaged together, yielding lower errors. In
both models, Purkayastha and VMF reach the lowest errors for a
given directional and differential privacy parameter ğœ–, respectively.
Session 4D: Differential Privacy CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea1214ğœŒ
s
â€™
n
a
m
r
a
e
p
S
1.0
0.8
0.6
0.4
0.2
0.0
ğœ– for directional ğœ–ğ‘‘âˆ¡-privacy
10âˆ’2
102
100
Mech.
VMF Î”âˆ¡
VMF Î”2
Pur
WL
Model
central
local
10âˆ’2
100
102
104
ğœ– for pure ğœ–-differential privacy
Figure 6: Comparison of Spearmanâ€™s ğœŒ across the four age
groups, over ğœ– under directional and pure differential pri-
vacy (indicated by the top and bottom axis, respectively).
Ranking statistics. In the context of the NSFâ€™s sleep study, one
aspect is to compare the wake (or bed) times among different
groups, and determine, e.g., who gets up first or goes to bed latest.
Concretely, let us suppose we want to infer the order of wake-
up times among the four age groups (Generation-X, -Y, -Z, and
Baby Boomers) from the survey data. As non-private baseline, we
compute the average wake-up time for each group on the original
dataset, and from there determine the ranking of the groups. We
then simulate the survey being conducted in both the central and
local privacy models as before, and determine the ranking of the age
groups from the sanitized average wake-up times. To measure the
impact of the privacy mechanisms on such statistics, we compute
Spearmanâ€™s rank correlation coefficient (also called Spearmanâ€™s ğœŒ)
between the perturbed and original ranking of the four age groups.
Figure 6 shows Spearmanâ€™s rank correlation coefficient ğœŒ (aver-
aged over all runs) for the different mechanisms over the parameter
range of ğœ– and both privacy models. As we can see, the observations
on the rank correlation are in line with the observations on the
mean absolute errors reported in the previous experiment.
In the central model, Purkayastha and Wrapped Laplace (WL) (over-
lapping green and red lines) achieve similar ğœŒ values and both
outperform VMF at virtually any given privacy level ğœ– under both
directional and differential privacy. However, in a small range of ğœ–
just below 1, Purkayastha shows higher correlation than WL, and
VMF with the ğ‘‘2-sensitivity also overtakes WL under pure DP.
The local model generally shows a better privacyâ€“utility trade-off
than in the previous results. Notably, Purkayastha appears to reach
the highest correlation values among the three mechanisms under
directional privacy, at virtually any given privacy level, which
is well observable for 10âˆ’3 â‰² ğœ– â‰² 1. Under pure DP, the VMF
mechanism with the ğ‘‘2-sensitivity stands out again and achieves
even higher correlation scores than Purkayastha.
4.3 Private histograms for spatio-temporal data
Histograms and heatmaps are practical tools to visualize and inter-
pret empirical data, particularly in one or two dimensions.
Scenarios. Suppose a location-based service, such as Google Maps
or Foursquare, wants to use check-in data (e.g., from usersâ€™ smart-
phones) to create daily histograms of popular visit times of busi-
nesses, such as stores or restaurants. This could allow other users to
estimate how busy a location or area is during different times of the
day, or provide store owners with insights on customer activity. The
desired data is often privacy-sensitive, so users may distrust the data
collector and be reluctant to share their whereabouts during the
course of the day. To enable such use cases in a privacy-preserving
way, we follow the local model and sanitize each userâ€™s data before
it is collected and aggregated into histograms.
Dataset description. We use the publicly available Gowalla dataset
from [6]. Gowalla was a location-based social networking website
where users could share their locations by checking in. It contains
a total of 6,442,890 check-ins with their location and time recorded
between Feb. 2009 and Oct. 2010.
Independent analysis of temporal and spatial data. We simu-
4.3.1
late data collection in the local model by perturbing the time-of-day
and location of each check-in independently.
For the periodic times-of-day, we consider all check-ins at the top
100 locations. We follow a sanitization procedure as with the sleep
data in Section 4.2.2 and use the VMF and Purkayastha mechanisms
on S1, with Clipped (CL) and Wrapped Laplace (WL) as baselines
(cf. Sections 3.2, 3.3 and 3.6). Similarly, to sanitize the locations, we
take all check-ins from the top 100 users and represent them as unit
vectors on S2. We then apply the appropriate VMF and Purkayastha
mechanisms, with Polar Laplace (cf. Section 3.6.3) as baseline.
After gathering the perturbed data, we compute the following
histograms: a check-in time histogram for each of the 100 locations
with one bin for each hour of the day, and a check-in location his-
togram for each of the top 100 users with 90Ã—180 bins, one for each
pair of subsequent degrees of latitude and longitude. To stabilize
the results, we repeat this procedure in every setting for 100 runs.
Error metrics. As measures of error between the sanitized and
original histograms, we again use the mean absolute error (MAE), as
well as the Earth Moverâ€™s Distance (EMD) with a suitable distance
matrix: For the distance between two check-in time histogram bins,
we use their circular distance in hours. For 2D location histograms
with latitudeâ€“longitude bins, we use the great-circle distance, i.e.
the actual surface distance, between the geographic positions on
the sphere corresponding to the bin centers. Unlike the MAE or
MSE which look at the error of each histogram bin individually, the
EMD so provides a measure of error that is aware of the semantics
of the underlying data by considering how far off the target bin is
from the original bin when counting a perturbed check-in location.
Results. Figure 7a shows the errors for the check-in time his-
tograms. For large ğœ–, both Wrapped and Clipped Laplace as well
as Purkayastha show similar errors that are lower than VMF. For
medium to small ğœ–, our directional mechanisms gain an advantage
over WL and CL with Purkayastha generally achieving the lowest
errors under directional privacy, whereas VMF wins under pure
DP when using the smaller ğ‘‘2-sensitivity. In this case, CL performs
worst with generally large MAE and EMD since virtually all counts
will be in the first or last histogram bin.
Session 4D: Differential Privacy CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea1215ğœ– for directional ğœ–ğ‘‘âˆ¡-privacy
101
10âˆ’1
ğœ– for directional ğœ–ğ‘‘âˆ¡-privacy
101
10âˆ’1
1eâˆ’2
D
M
E
2
1
0
10âˆ’1
101
E
A
M
3
2
1
0
VMF Î”âˆ¡
VMF Î”2
Pur
WL
CL
10âˆ’1
101
1e3
D
M
E
2
1
0
E
A
M
3
2
1
0
VMF Î”âˆ¡
VMF Î”2
Pur
Polar
10âˆ’1
101
10âˆ’1
101
ğœ– for directional ğœ–ğ‘‘âˆ¡-privacy
ğœ– for directional ğœ–ğ‘‘âˆ¡-privacy
1eâˆ’5
10âˆ’1
101
10âˆ’1
101
ğœ– for pure ğœ–-differential privacy
ğœ– for pure ğœ–-differential privacy
ğœ– for pure ğœ–-differential privacy
ğœ– for pure ğœ–-differential privacy
(a) Check-in times
(b) Check-in locations
Figure 7: Comparison of mean absolute error (MAE) and Earth Moverâ€™s Distance (EMD) between check-in histograms.
Figure 7b shows the errors for the check-in location histograms.
In terms of the MAE, VMF is worst while Purkayastha and Polar
Laplace are almost indistinguishable. However, if we consider the
EMD as metric with spatial awareness, we recognize that the Polar
mechanism has a region with increased error for 10âˆ’1 â‰² ğœ– â‰² 10,
corresponding to the â€œbumpâ€ we describe in Section 3.6.3. Thus, in
conclusion, the Purkayastha distribution shows the lowest errors
for directional privacy, whereas VMF benefits from the reduced
ğ‘‘2-sensitivity under pure DP.
4.3.2 Location busyness during different times of day. The follow-
ing experiment constitutes the combined application of directional
privacy mechanisms to both spatial and temporal data. Our goal is
to derive histograms of check-ins at the top 1000 locations from the
Gowalla dataset over different times of day, where we perturb both
the check-in times and locations using the Purkayastha mechanism,