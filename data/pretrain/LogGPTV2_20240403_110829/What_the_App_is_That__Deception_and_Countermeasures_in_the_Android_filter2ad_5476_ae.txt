 (the security indicator displays the similar-looking app icon
and name. No verification of the author of the app happens.)
 (the security indicator displays the original app icon and
name. No verification of the author of the app happens.)
Off by default, requires user interaction
Off by default, requires user interaction
Off by default, requires user interaction
Chen et al. [6] Our on-device defense


 (animation)














 (yellow lock)

 (“secret image”)
In particular, our proposed modifications need to address three
different challenges:
1) Understanding with which app the user is actually interacting.
2) Understanding who the real author of that app is.
3) Showing this information to the user in an unobtrusive but
reliable and non-manipulable way.
Three independent components address these challenges. The
combination of the states of components one and two determines
the information presented to the user by component three.
Overall, two principles guided our choices:
• Offering security guarantees comparable with how a modern
browser presents a critical (i.e., banking) website, identifying
it during the entire interaction and presenting standard and
recognizable visual elements.
• Allowing benign apps to continue functioning as if our defense
were not in place, and not burdening the user with extra
operations such as continuously using extra button combinations
or requiring specific hardware modifications.
In particular, we wish to present security-conscious users with
a familiar environment consistent with their training, using the same
principles that brought different browser manufacturers to present
similar elements for HTTPS-protected sites without hiding them
behind browser-specific interactions.
An overview of the possible cases, how our system behaves
for each of them, and the analogy with the web browser world that
inspired our choices is presented in Table VII, while a more detailed
description of each of our three components will be presented in
the following sections.
Our implementation will be briefly described in Section VI-D,
whereas Table VI exemplifies deception methods and recaps how
users are defended by our system and those described in [9] and [6],
which target attacks similar to the ones we described (Section VIII
provides more details).
A. Which app is the user interacting with?
Normally, the top Activity (and, therefore, the top app) is the
target of user interaction, with two important exceptions:
1) Utility components such as the navigation bar and the status bar
(Section II-A) are drawn separately by the system in specific
Windows.
2) An app, even if not currently on top of the Activity stack, can di-
rect a separate Window to be drawn over the top-activity Window.
Interactions with utility components are very common and
directly mediated by the system. Thus, we can safely assume that
no cross-app interference can be created (the “Back” button in
the navigation bar, for instance, is exclusively controlled by the top
Activity) and we don’t need to consider them (Point 1) in our defense.
However, as exemplified in Section III, Windows shown by
different apps (Point 2) can interfere with the ability of a user to
interact correctly with the top app.
While we could prohibit their creation (and thus remove row 3
of Table VII), the ability to create “always-visible” Windows is used
by common benign apps: for instance, the “Facebook Messenger”
app provides the ability to chat while using other apps and it is
currently the most popular free app on the Google Play Store.
Therefore, we have decided to simply alert users of the fact that a
second app is drawing on top of the current top app, and leave them
free to decide whether they want this cross-app interaction or not.
The official Android system also provides a limited defense
mechanism:
1) As mentioned, a specific permission is necessary to create
always-visible custom Windows. If it
is granted during
installation, no other checks are performed. It is impossible for
the top app to prevent extraneous content from being drawn
over its own Activities. Toasts are handled separately and do not
require extra permissions.
2) The top app can use the filterTouchesWhenObscured API on its
Views (or override the onFilterTouchEventForSecurity method)
940940941
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:09:15 UTC from IEEE Xplore.  Restrictions apply. 
TABLE VII: Possible screen states and how they are visualized.
if
no domain specified in the manifest
Domain specified in the manifest,
successful verification,
no visible Windows from other apps
Domain specified in the manifest,
successful verification,
visible Windows from other apps
Domain specified in the manifest,
unknown validity,
(other cases)
Resulting UI state
Apps not associated with
any organization
Sure interaction with a
verified app
Visualization
Regular black navigation
bar
Green lock and company
name
then
Equivalent in browsers
Regular HTTP pages
Visualization in browsers
no lock icon
HTTPS verified page
Green lock, domain name, and
(optionally) company name
Likely interaction with a
verified app, but external
elements are present
Incomplete verification
(networking issues)
Failed verification
Yellow half-open lock
Mixed HTTP and HTTPS
content
Varies with browsers, a yellow
warning sign is common
Red warning page,
user allowed to proceed
Red error page
Self-signed or missing CA
certificate
Failed verification
Usually, red warning page,
user allowed to proceed
Red error page
to prevent user input when content from other apps is present
at the click location.
Given the attack possibilities, however, these defenses are
not exhaustive for our purposes if not supplemented by the extra
visualization we propose, as they still allow any extraneous content
to be present over the top Activity. Moreover, the protection API
can create surprising incompatibilities with benign apps (such as
“screen darkeners”) that use semi-transparent Windows, and does
not prevent other apps’ Windows from intercepting interactions (that
is, it can protect only from Windows that “pass through” input).
The Android API could also be extended to provide more
information and leave developers responsible to defend their own
apps, but providing a defense mechanism at the operating system
level makes secure app development much easier and encourages
consistency among different apps.
B. Who is the real author of a given app?
In order to communicate to the user the fact that she is
interacting with a certain app, we need to turn its unique identifier
(the package name, as explained in Section II) into a message
suitable for screen presentation. This message must also provide
sufficient information for the user to decide whether to trust it with
sensitive information or not.
To this aim, we decided to show to the user the app’s developer
name and to rely on the Extended-Validation [24] HTTPS
infrastructure to validate it, since Extended-Validation represents
the current best-practice solution used by critical business entities
(such as banks offering online services) to be safely identified by
their users. As we will discuss in the following paragraphs, other
solutions could be used, but they are either unpractical or unsafe.
As a first example, the most obvious solution to identify an appli-
cation would be to show the app’s name as it appears in the market,
but we would need to rely on the market to enforce uniqueness and
trustworthiness of the names, something that the current Android
markets do not readily provide. The existence of multiple official and
unofficial markets and the possibility of installing apps via an apk
archive (completely bypassing the markets and their possible security
checks), make this a complex task. In fact, we observed several cases
in which apps mimic the name and the icon of other apps, even in
the official Google Play market: as an example, Figure 4 shows how
a search for the popular “2048” game returns dozens of apps with
very similar names and icons. For this reason, establishing a root
of trust to app names and icons (such as in [9]) is fundamentally
unreliable, as these are easily spoofed, even on the official market.
The only known type of vetting on the Google Play market
involves a staff-selected app collection represented on the market
with the “Top Developer” badge [25]. This is, to our knowledge, the
only case where market-provided names can be reasonably trusted.
Unfortunately, this validation is currently performed on a limited
amount of developers. Moreover, no public API exists to retrieve
this information. When an official method to automatically and
securely obtain this information is released, our system could be
easily adapted to show names retrieved from the market for certified
developers, automatically protecting many well-known apps.
Relying on market operators is not, however, the only possible
solution. The existing HTTPS infrastructure can be easily used
for the same effect. This system also allows users to transfer their
training from the browser to the mobile world: using this scheme,
the same name will be displayed for their bank, for instance,
whether they use an Android app or a traditional web browser.
As far as identifying the developer to the user, two main choices
are possible in the current HTTPS ecosystem. The first one simply
associates apps with domain names. We need to point out, however,
that domain names are not specifically designed to resist spoofing
and the lack of an official vetting process can be troublesome.
On the other hand, Extended-Validation (EV) certificates are
provided only to legally-established names (e.g., “PayPal, Inc.”),
relying on existing legal mechanisms to protect against would-be
fraudsters, thus preventing a malicious developer to use a name
mimicking the one of another (e.g., using the name “Facebuuk”
instead of “Facebook”). Extended-Validation certificate are the
current mechanism in use by web browsers to safely identify the
owner of a domain and they are available for less than $150 per
year: in general, a substantially lower cost than the one involved
in developing and maintaining any non-trivial application.
Concretely, to re-use a suitable HTTPS EV certification with
our protection mechanism, the developer simply needs to provide
a domain name (e.g., example.com) in a new specific field in
the app’s manifest file, and make a /app_signers.txt file
available on the website containing the authorized public keys.
During installation (and periodically, to check for revocations),
this file will be checked to ensure that the developer who signed
941941942
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:09:15 UTC from IEEE Xplore.  Restrictions apply. 
that domain (determined by the usage of HTTPS, and shown by
a “closed lock” icon). A different element is shown when “mixed”
trusted-untrusted information is present. Also, the user is warned
that an attack may be in effect if the validation fails.
Most importantly, information presented in the URL bar is
directly connected to the page it refers to (pages cannot directly draw
on the URL bar, nor can they cause the browser to switch to another
tab without also changing information shown on the URL bar).
On the Android platform, we choose the navigation bar as the
“trusted” position that will behave like the URL bar. As browsers
display different URL bars for different tabs, we also dynamically
change information shown on the navigation bar: at every instant
in time, we make sure it matches the currently visible status (e.g.,
the bar changes as Activities are moved on top of the stack, no
matter how the transition was triggered). In other words, the security
indicators are always shown as long as the navigation bar is.
The navigation bar is in many ways a natural choice as a
“trusted” GUI in the Android interface, as apps cannot directly
modify its appearance and its functionality is vital to ensure correct
user interaction with the system (e.g., the ability for a user to go
back to the “home” page or close an app).
Fullscreen apps. To ensure our defense reliability and visibility,
our defense mechanism needs to deal with scenarios in which an
application hides the content of the navigation bar (on which we
show our security indicator) by showing a fullscreen Activity. This
allows a malicious application to render a fake navigation bar in
place of the original one.
For this reason, to further prove the authenticity of the
information shown by our defense system, we complemented our
system by using a “secret image” (also called security companion).
This image is chosen by the user among a hundred different
possibilities (images designed to be recognizable at a small size) and
it is displayed together with our lock indicator (see Figure 1) making
it impossible to correctly spoof it. In fact, a malicious application
has no way to know which is the secret image selected by the user.
This system is similar to the “SiteKey” or “Sign-in Seal”
mechanisms used by several websites to protect their login pages
(i.e., [7], [8]), with the considerable advantage that users are
constantly exposed to the same security companion whenever they
interact with verified apps or with the base system.
The user has the opportunity to select the secret image during
the device’s first-boot or by using a dedicated system application.
After that a secret image is selected, its functionality is briefly
explained to the user. To prevent a malicious application from
inferring the image chosen by the user, we store it in a location
unreadable by non-system applications.
In addition, we modify the system so that the chosen image
will not appear in screenshots (note that the Android screenshot
functionality is mediated by the operating system). Also note that
non-system applications cannot automatically take screenshots
without explicit user collaboration.
We also propose the introduction of a fullscreen mode which
still shows security indicators (but not the rest of the navigation bar),
in case apps designed for fullscreen operation wish to show their
credentials on some of their Activities.
Finally, we prevent applications from creating “inescapable”
fullscreen Windows, by simply removing the possibility to use the
Fig. 4: A search for the popular “2048” game, returning several
“clones.” The app developed by the inventor of the game is listed
in fifth position.
the app7 is indeed associated with the organization that controls
example.com. If desired, developers can also “pin” the site
certificate in the app’s manifest.
It should be noted that several issues have been raised on
the overall structure of the PKI and HTTPS infrastructure (for a
summary see, for instance, [26]). Our defense does not specifically
depend on it: in fact, it should be kept in line with the best practices
in how secure sites and browsers interact.
C. Conveying trust information to the user
The two components we have described so far determine the
possible statuses of the screen, summarized in the first two columns
of Table VII. The three right columns of Table VII present our
choices, modeled after the user knowledge, training, and habit
obtained through web browsers, since the mobile environment
shares with them important characteristics:
• The main content can be untrusted and interaction with it can