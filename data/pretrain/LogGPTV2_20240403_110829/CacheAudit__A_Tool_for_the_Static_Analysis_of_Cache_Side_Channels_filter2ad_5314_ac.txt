(cid:28)k∈pred(l)
upd
C(cid:31)(cid:27)aC(k),eff
M(cid:31),(k,l)(aM(k))(cid:26) ,
where (cid:25)C(cid:31) refers to the join function and can be thought
C(cid:31) (a,l) collects all cache
of as set union. That is, next
states that can reach l within one transition when updated
with an over-approximation of the corresponding mem-
ory blocks. See the full version [19] for a description
of the corresponding update functions for memory and
effects.
Now from Equations 2, 3, and 4, we can derive con-
ditions for each domain that are sufﬁcient to guarantee
local soundness for the whole analysis:
Deﬁnition 1 (Local soundness of abstract domains). The
abstract domains are locally sound if the abstract joins
are over-approximations of unions, and if for any func-
C(cid:31),eff
tion f (cid:31) ∈ {upd
E(cid:31)}
approximating
∈
corresponding
M,upd
{upd
meaning function γ f , we have for any abstract value x:
M(cid:31),(k,l),eff
concrete
C,eff
C,next}
M(cid:31),(k,l),upd
function
and
C(cid:31),upd
f
M,eff
γ f (cid:27) f (cid:31)(x)(cid:26) ⊇ f (cid:31)γ f (x)(cid:30) .
For example, for the cache abstract domain, we have
the following local soundness conditions:
∀c(cid:31) ∈ C(cid:31),M ∈ P(EM):
γC(upd
C(cid:31) (c(cid:31),M)) ⊇ upd
C(cid:31) (c(cid:31),M) ⊇ eff
eff
C(γC(c(cid:31)),M),
C(γC(c(cid:31)),M),
∀G(cid:31) ⊆ C(cid:31) : γC
C(cid:31)
(cid:28)G(cid:31)
 ⊇ (cid:20)G(cid:31)∈G(cid:31)
γC(cid:27)G(cid:31)(cid:26) .
Lemma 2 (Local Soundness Conditions). If local sound-
ness holds on the abstract memory, cache, and events
domains, then the corresponding next(cid:31) function satisﬁes
local soundness.
Due to the above lemma, abstract domains for the
memory, cache, and events can be separately developed
and proven correct. We exploit this fact in this paper, and
we plan to develop further abstractions in the future, tar-
geting different classes of adversaries or improving pre-
cision.
USENIX Association  
22nd USENIX Security Symposium  437
Theorem2MonotonicityTheorem14.4 Soundness of Delivered Bounds
We implemented the framework described above in a
tool named CacheAudit. Thanks to the previous results,
CacheAudit provides the following guarantees.
Theorem 4. The bounds derived by CacheAudit
soundly over-approximate (cid:31)(cid:31)
for adv ∈
{acc,accd,tr,time}, and hence correspond to upper
bounds on the maximal amount of leaked information.
ran(Cadv)(cid:31)(cid:31)
,
The statement is an immediate consequence of com-
bining Lemma 2 with Theorems 2 and 3, under the as-
sumption that all involved abstract domains satisfy local
soundness conditions, and that the corresponding count-
ing procedures are correct. We formally prove the valid-
ity of these assumptions only for our novel relational and
trace domains (see Section 6). For the other domains,
corresponding proofs are either standard (e.g. the value
domain) or out of scope of this submission.
5 Tool Design and Implementation
In this section we describe the architecture and imple-
mentation of CacheAudit.
We take advantage of the compositionality of the
framework described in Section 4 and use a generic it-
erator module to compute ﬁxpoints, where we rely on
independent modules for the abstract domains that corre-
spond to the components of the next(cid:30) operation. Figure 3
depicts the overall architecture of CacheAudit, with the
individual modules described below.
5.1 Control Flow Reconstruction
The ﬁrst stage of the analysis is similar to a compiler
front end. The main challenge is that we directly ana-
lyze x86 executables with no explicit control ﬂow graph,
which we need for guiding the ﬁxpoint computation.
For the parsing phase, we rely on Chlipala’s parser for
x86 executables [13], which we extend to a set of in-
structions that is sufﬁcient for our case studies (but not
yet complete). For the control-ﬂow reconstruction, we
consider only programs without dynamically computed
jump and call targets, which is why it sufﬁces to iden-
tify the basic blocks and link them according to the cor-
responding branching conditions and (static) branch tar-
gets. We plan to integrate more sophisticated techniques
for control-ﬂow reconstruction [30] in the future.
Iterator
5.2
The iterator module is responsible for the computation
of the next(cid:30) operator and of the approximation of its ﬁx-
point using adequate iteration strategies [17]. Our analy-
sis uses an iterative strategy, i.e., it stabilizes components
CacheAudit
x86 parser
Iterator
Stack AD
abstract
domains
Interval AD
FiniteSet AD
Octagon AD
RelSet AD
Flag AD
Memory AD
Value AD
Trace AD
Timing AD
Cache AD
Figure 3: The architecture of CacheAudit. The solid
boxes represent modules. Black-headed arrows mean
that the module at the head is an argument of the module
at the tail. White-headed arrows represent is-a relation-
ships.
of the abstract control ﬂow graph according to a weak
topological ordering, which we compute using Bourdon-
cle’s algorithm [12].
The iterator also implements parts of the reduced car-
dinal power, based on the labels computed according to
the control-ﬂow graph: Each label is associated with an
initial abstract state. The analysis computes the effect of
the commands executed from that label to its successors
on the initial abstract state, and propagates the resulting
ﬁnal states using the abstract domains described below.
In order to increase precision, we expand locations us-
ing loop unfolding, so that we have a number of differ-
ent initial and ﬁnal abstract states for each label inside
loops, depending on a parameter describing the number
of loop unfoldings we want to perform. Most of our
examples (such as the cryptographic algorithms) require
only a small, constant number of loop iterations, so that
we can choose unfolding parameters that avoid joining
states stemming from different iterations.
5.3 Abstract Domains
As described in Section 4, we decompose the abstract
domain used by the iterator into mostly independent ab-
stract domains describing different aspects of the con-
crete semantics.
Value Abstract Domains A value abstract domain
represents sets of mappings from variables to (integer)
438  22nd USENIX Security Symposium 
USENIX Association
values. Value abstract domains are used by the cache
abstract domain to represent ages of blocks in the cache,
and by the ﬂag abstract domain to represent values stored
at the addresses used in the program. We have imple-
mented different value abstract domains, such as the in-
terval domain, an exact ﬁnite sets domain (where the sets
become intervals when they are growing too large) and a
relational set domain (as described in Section 6.1).
Flag Abstract Domain In x86 binaries, there are no
high level guards: instead, most operations modify ﬂags
which are then queried in conditional branches. In or-
der to deal precisely with such branches, we need to
record relational information between the values of vari-
ables and the values of these ﬂags. To that end, for each
operation that modiﬁes the ﬂags, we compute an over-
approximation of the values of the arguments that may
lead to a particular ﬂag combination. The ﬂag abstract
domain represents an abstract state as a mapping from
values of ﬂags to elements of the value abstract domain.
When the analysis reaches a conditional branch, it can
identify which combination of ﬂag values corresponds to
the branch and propagate the appropriate abstract values.
Memory Abstract Domain The memory abstract do-
main associates memory addresses and registers with
variables and translates machine instructions into the cor-
responding operations on those variables, which are rep-
resented using ﬂag abstract domains as described above.
One important aspect for efﬁciency is that variables cor-
responding to addresses are created dynamically during
the analysis whenever they are needed. The memory ab-
stract domain further records all accesses to main mem-
ory using a cache abstract domain, as described below.
Stack Abstract Domain Operations on the stack are
handled by a dedicated stack abstract domain.
In this
way the memory abstract domain does not have to deal
with stack operations such as procedure calls, for which
special techniques can be implemented to achieve precise
interprocedural analysis.
Cache Abstract Domain The cache abstract domain
only tracks information about the cache state. We rep-
resent this state by sets of mappings from blocks to
ages in the cache, which we implement using an in-
stance of value abstract domains. Effects from the mem-
ory domain are passed to the cache domain through
the trace domain. The cache abstract domain tracks
which addresses are touched during computation and re-
turns information about the presence or absence of cache
hits and misses to the trace abstract domain, which we
present in Section 6.2. The timings are then obtained as
an abstraction from the traces.
6 Abstract Domains for Cache Adversaries
6.1 Cache State Domains
Abstractions of cache states are at the heart of analyses
for all three cache adversaries considered in this paper.
Thus, precise abstraction of cache states is crucial to de-
termine tight leakage bounds.
The current state-of-the-art abstraction for LRU re-
placement by Ferdinand et al. [21] maintains an upper
and a lower bound on the age of every memory block.
This abstraction was developed with the sole goal of clas-
sifying memory accesses as cache hits or cache misses.
In contrast, our goal is to develop abstractions that yield
tight bounds on the maximal leakage of a channel. For
access-based adversaries the leakage is bounded by the
size of the concretization of an abstract cache state, i.e.
the size of the set of concrete cache states represented by
the abstract state.
Intuition behind Relational Sets To derive tighter
leakage bounds, we propose a new domain called rela-
tional sets that improves previous work along two dimen-
sions:
1. Instead of intervals of ages of memory blocks, we
maintain sets of ages of memory blocks.
2. Instead of maintaining independent
information
about the age of each memory blocks, we record the
relation between ages of different memory blocks.
In addition to increasing precision, moving from in-
tervals to sets allows us to analyze caches with FIFO and
PLRU replacement. Interval-based analysis of FIFO and
PLRU has been shown to be rather imprecise in the con-
text of worst-case execution time analysis [24].
Motivating Example Consider the following method,
which performs a table lookup based on a secret input, as
it may occur in e.g. an AES implementation:
unsigned int A[size];
int getElement(int secret) {
if (secret < size)
return A[secret];
}
Assume we want to determine the possible cache
states after one invocation of getElement. As the value
of secret is unknown to the analysis, every memory lo-
cation of the array might be accessed.
USENIX Association  
22nd USENIX Security Symposium  439
size
LRU/IV
LRU/Set
LRU/Rel
8
1
1
1
16
2
2
1.58
32
4
4
2.32
64
8
8
3.17
128
16
16
4.01
256
32
32
5.04
Figure 4: Bounds on the number of leaked bits about
the parameter secret for varying array sizes. The cache
parameters are ﬁxed, with a block size of 32 bytes, asso-
ciativity 4 and cache size 4 KB.
Assuming the array was not cached before the invoca-
tion of getElement, the interval-based domain by Fer-
dinand et al. [21] determines a lower bound of 0 and an
upper bound of k on the age of each array element.
By tracking sets instead of intervals of ages for each
memory block, we would get 0 and k as possible ages of
each array element.
Both non-relational domains, however, are not power-
ful enough to infer or even express the fact, that only one
of the array’s memory blocks has been accessed, and can
thus be cached. Therefore, the number of possible cache
states represented by non-relational abstractions grows
exponentially in the size of the array, while the actual
number of possible cache states only grows linearly.
A relational domain, tracking the possible ages of,
e.g., pairs of memory blocks, would indeed yield a lin-
ear growth in the number of possible cache states. For
each pair of array elements, it would be able to infer that
only one of the two blocks may be cached. From this, it
follows that only one of all of the array elements may be
cached.
Figure 4 shows experimental results for the example
program with three domains: the interval domain (IV),
and two instances of the relational sets domain, tracking
sets of ages of individual blocks (Set) and sets of ages of
pairs of blocks (Rel), respectively.
We do not see an improvement of sets over intervals
in this particular example, as the information that a block
has either age 0 or age k can be inferred from the intervals
in the counting procedure. This is because the considered
arrays are small and thus no two array elements map to
the same cache set. We have, however, observed in case
studies that sets alone often improve over intervals.
A detailed formalization of relational sets and their im-
plementation, including efﬁcient counting, is provided in
the extended version of this paper [19]. There, we also
show that the domain is locally sound according to Deﬁ-
nition 1:
Lemma 3. The relational sets domain is locally sound.
6.2 A Trace Domain
We devise an abstract domain for keeping track of the
sets of event traces that may occur during the execution
of a program. Following the way events are computed
in the concrete, namely as a function from cache states
and memory effects (see Section 3.3), the abstract cache
domain provides abstract cache effects.
In our current implementation of CacheAudit, we use
an exact representation for sets of event traces: we can
represent any ﬁnite set of event traces, and assuming an
incoming set of traces S and a set of cache effects E, we
compute the resulting event set precisely as follows:
upd
E(cid:31) (S,E) = {σ .e | σ ∈ S ∧ e ∈ E }
Then soundness is obvious, since the abstract opera-
tion is the same as its concrete counterpart. Due to loop
unfolding, we do not require widenings, even though
the domain contains inﬁnite ascending chains (see Sec-
tion 5.2).
Lemma 4. The trace domain is locally sound.
i=1 γ(ui).
i=1 γ(ui)}
Representation for Sets of Event Traces We repre-
sent sets of ﬁnite event traces corresponding to a partic-
ular program location by a directed acyclic graph (DAG)
with vertices V , a dedicated root r ∈ V , and a node label-
ing (cid:28): V → P(E)∪{(cid:21)}. In this graph, every node v ∈ V
represents a set of traces γ(v) ∈ P(E∗) in the following