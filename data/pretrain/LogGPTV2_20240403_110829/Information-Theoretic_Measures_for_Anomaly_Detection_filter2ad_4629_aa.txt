title:Information-Theoretic Measures for Anomaly Detection
author:Wenke Lee and
Dong Xiang
Information-Theoretic Measures for Anomaly Detection 
Wenke Lee 
Computer Science Department 
North Carolina State University 
Raleigh, NC 27695-7534 
PI:EMAIL 
Dong Xiang 
Computer Science Department 
North Carolina State University 
Raleigh, NC 27695-7534 
dxiang @ unity.ncsu.edu 
Abstract 
Anomaly detection is an essential component of the pro- 
In  this  pa- 
tection  mechanisms  against  novel  attacks. 
per; we propose  to use several  information-theoretic mea- 
sures, namely, entropy, conditional entropy, relative condi- 
tional  entropy, information gain, and  information cost for 
anomaly detection.  These measures can be used to describe 
the characteristics of an audit data set, suggest the appro- 
priate  anomaly detection  model(s) to be built, and explain 
the perforniance  of  the  model(s).  We  use  case  studies on 
Unix system  call  data,  BSM  data,  and  network  tcpdump 
data to illustrate the utilities of these measures. 
1  Introduction 
Intrusion detection  (ID) is  an  important component of 
the  defense-in-depth  or  layered  network  security  mecha- 
nisms. An intrusion detection system (IDS) collects system 
and network activity  data, e.g., BSM  [28] and tcpdump[9] 
data,  and  analyzes  the  information to determine  whether 
there is an attack occurring. Two main techniques for intru- 
sion detection are misuse detection  and anomaly detection. 
Misuse  detection  (sub)systems,  for example,  IDIOT  [IO] 
and STAT [8], use  the “signatures” of  known attacks, i.e., 
the  patterns  of  attack  behavior  or  effects,  to  identify  a 
matched  activity  as  an  attack  instance.  Misuse  detection 
are not  effective  against new  attacks,  i.e., those that don’t 
have known signatures.  Anomaly  detection (sub)systems, 
for example, the anomaly detector of IDES [21],  use estab- 
lished  normal  profiles,  i.e., the expected behavior,  to iden- 
tify  any unacceptable deviation as possibly  the result of an 
attack. Anomaly detection can be effective against new at- 
tacks. However, new legitimate behavior can also be falsely 
identified  as an attack, resulting a false alarm.  In practice, 
reports of attacks are often  sent to security staff for investi- 
gation and appropriate actions. 
In  1998, DARPA conducted an evaluation to assess the 
state-of-the-art of  ID  research.  The  results  showed  that 
the  best  research  systems  had  detection  rates  (i.e.,  the 
percentages of  attack incidents correctly identified)  below 
70%  [ 181.  Most  of  the  missed  intrusions  were  new  at- 
tacks that  can  lead to  unauthorized user or root  access to 
the  mocked  military  network used  in  the  evaluation.  The 
results of the  1999 DARPA evaluation are even more trou- 
bling.  With  improved capabilities, e.g., the added modules 
for detecting the attacks missed in the previous evaluation. 
the  research  IDSs still  had detection rates below  70% be- 
cause many new attacks (that is, new in the I999 evaluation) 
were missed [ 191.  These evaluations showed that even the 
cutting-edge ID technology is not very effective against new 
attacks, and the improvement is often too slow and too little 
to keep up with the “innovation” by sophisticated attackers. 
Most of the research systems in the DARPA evaluations, 
like the leading commercial products, employ mainly mis- 
use detection techniques. The main reason against deploy- 
ing anomaly detection (sub)systems is the belief  that  they 
tend to generate many false alarms and hence compromise 
the effectiveness of  intrusion  detection (although some re- 
search  anomaly  detection systems  in  DARPA  evaluations 
showed false alarm rates comparable to the research misuse 
detection systems).  Given that our adversaries will  always 
develop and launch  new  types of  attacks in  an  attempt to 
defeat our deployed intrusion prevention and detection sys- 
tems, and that  anomaly detection  is the key  to the defense 
against novel  attacks, we must develop significantly  better 
anomaly detection techniques. 
In most computing environments, the behavior of  a sub- 
ject  (e.g.,  a  user,  a program,  or  a  network  element, etc.) 
is  observed  via  the  available  audit  data  logs.  The basic 
premise for anomaly detection is that there is intrinsic char- 
acteristic or regularity  in  audit  data that is consistent with 
the  normal  behavior  and  thus  distinct from  the  abnormal 
behavior.  The  process  of  building  an  anomaly  detection 
model should therefore involve first studying the character- 
istic  of  the  data and  then  selecting a  model  that  best  uti- 
lizes the  characteristic.  However, due to  the  lack  of  the- 
1081-601 1/01 $10.00 0 2001 EEE 
130 
oretical  understandings  and  useful  tools for characterizing 
audit data, most anomaly  detection  models are built based 
solely on “expert” knowledge or intuition [20], which is of- 
ten  imprecise and incomplete given the complexities of to- 
day’s network environments.  As a result, the effectiveness 
of the models is limited.  More seriously, a lot of research 
in  anomaly detection  (and  intrusion  detection  in  general) 
has  been  focusing  on  a  specific  (and  ad  hoc)  method  for 
a specific .environment.  The research results often  do not 
contribute to the fundamental understanding of the field nor 
lend themselves to the broader problem domain. 
Our research aims to provide theoretical  foundations as 
well  as  useful  tools  that  can  facilitate  the  IDS  develop- 
ment process and improve the effectiveness of ID technolo- 
gies.  In this paper, we propose to use several information- 
theoretic  measures,  namely,  entropy,  conditional  entropy, 
relative  conditional  entropy,  information  gain,  and  infor- 
mation cost for anomaly detection.  These measures can be 
used to describe the characteristics of an audit data set, sug- 
gest the appropriate anomaly detection model(s) to be built, 
and explain the performance of the model(s).  We  use case 
studies on seridmail  system call data, sendinail BSM data, 
and network tcpdunip data to illustrate the utilities of these 
measures. 
The  rest  of  the  paper  is  organized  as  follows. 
Sec- 
tion  2  describes the  information-theoretic  measures.  Sec- 
tion 3 presents several case studies in using these measures 
to build anomaly detection models, Section 4 discusses the 
limitations and possible extensions of our current approach. 
Section 5 compares our research  with related  efforts.  Sec- 
tion 6 outlines our future work. 
2  Information-Theoretic Measures 
In this section, we discuss several information-theoretic 
measures (these concepts are covered in many  texts on in- 
formation theory, e.g. 141). We explain how these measures 
characterize the regularity embedded in  audit data and in- 
fluence the performance of anomaly detection models.  We 
also outline the procedure of using these measures to build 
anomaly detection models. 
2.1  Entropy 
Entropy, or Shannon-Wiener Index [26], is an important 
concept  in  information theory  and communication theory. 
It measures the uncertainty (or impurity) of a collection of 
data items. 
Definition 1  For a dataset X  where each data item belongs 
to a class x  E Cx, the entropy of X  relative to this JCxJ- 
wise classiJcation is defined as 
H(X) = 
XECX 
P(z)log- 
1 
P ( x )  
where P ( z )  is the probabili~ of z in X .  
The typical  interpretation  of  entropy  is  that it  specifies 
the  number of  bits  required  to  encode  (and  transmit)  the 
classification  of a data item.  The entropy value is smaller 
when  the  class  distribution  is  skewer,  i.e.,  when  the  data 
is  “purer”.  For  example,  if  all  data  items  belong  to  one 
class, then  entropy  is 0, and 0 bit  needs to be transmitted 
because the receiver knows that there is only one outcome. 
The entropy  value  is  larger  when  the  class  distribution  is 
more even, i.e., when the data is more “impure”. For exam- 
ple, if the data items are evenly distributed in  1C.u I classes, 
then log(CX I bits are required to encode a classification. 
For  anomaly detection,  we  can  use  entropy  as  a  mea- 
sure  of  the  regularity  of  audit  data.  Each  unique  record 
in an  audit dataset represents a class.  The smaller the  en- 
tropy,  the  fewer  the  number of  different records  (i.e.,  the 
higher  the  redundancies),  and we  say  that  the  more  regu- 
lar the  audit dataset.  High-regularity  data contains redun- 
dancies that  help predicting future events because  the  fact 
that many events are repeated  (or redundant) in the current 
dataset  suggests  that  they  will  likely  to  appear  in  the  fu- 
ture.  Therefore, anomaly detection  model  constructed us- 
ing dataset with smaller entropy will likely be  simpler and 
have better detection performance.  For example, if  the au- 
dit data contains a single event class, e.g., a user command 
dataset where all commands are mail, then the entropy is 0: 
and a single rule can identify any other event, e.g.,ftp, as-an: 
anoma1.y. If the audit datal contains many event types, then 
the entropy is greater than 0: and! a more complex model: is 
needed. 
2.2  Conditional Entropy 
Definition 2  The conditional  entropy  of  X  given  Y  is  the 
entropy of the probability distribution P(xl y),  that is, 
H ( X I Y )  = 
x > Y  E CX ,CY 
1 
P ( x ,  y) log - P(xIy) 
where P(x, y) is the jointprobability of x and y and P(x1y) 
is the conditional probability of x given y. 
Because  of  the  temporal  nature  of  user,  program,  and 
network activities, we need to measure the temporal or se- 
quential  characteristic  of  audit data.  Using the  definition 
above,  let  X  be  a  collection  of  sequences  where  each  is 
denoted  as  (el, e2,. . . , en-l, e,),  and each  ei  is  an  audit 
event;  and  let  Y  be the  collection  of  subsequences where 
131 
each is  (el, e2,. . . , el,), and  k  where  t  is  the  timestamp,  each 
fi  is a feature, e.g., the duration of the current connection, 
number of bytes sent, etc., and c is the class label. Suppose 
that we use the service of a connection as its class, that is, 
we want to model how  each service normally  behaves.  If 
there  is strong regularity, i.e., low conditional entropy, on 
the sequence of services (or the combination of service and 
other features), we can  add  features that  express this  reg- 
ularity.  One way  is  to add  features that act  as place hold- 
ers for the services of previous connections (that fall within 
a  time  window),  i.e., each  connection  record  includes the 
names of some previous services, si-1, si-?,  etc.  Alterna- 
tively, to reduce the total number of features (and hence the 
complexities of the model), we can use some statistical fea- 
ture(s),  e.g., within  the  past  n  seconds,  the  percentage  of 
the services that are the same as the current one, to approx- 
imate  the  regularity  information.  In  [ 131, we showed that 
these temporal and statistical features usually have high in- 
formation gain, and hence a better model can be built when 
these features are added to the audit data. 
2.5  Information Cost 
Intuitively, the more information we have, the better the 
detection performance.  However, there is always a cost for 
amy  gain  For intrusion detecuon, one important goal  is  to 
detect intrusions as early as possible so’ that appropriat 
sponses can  be  carried  out effectively  We  can  define  in- 
formation  cost  as  the  average  rime  for  processing  an  au- 
dit record and checking against the derection model!  When 