title:Symbolic execution with SymCC: Don't interpret, compile!
author:Sebastian Poeplau and
Aur&apos;elien Francillon
Symbolic execution with SymCC: 
Don’t interpret, compile!
Sebastian Poeplau and Aurélien Francillon, EURECOM
https://www.usenix.org/conference/usenixsecurity20/presentation/poeplau
This paper is included in the Proceedings of the 29th USENIX Security Symposium.August 12–14, 2020978-1-939133-17-5Open access to the Proceedings of the 29th USENIX Security Symposium is sponsored by USENIX.Symbolic execution with SYMCC:
Don’t interpret, compile!
Sebastian Poeplau
EURECOM
Aurélien Francillon
EURECOM
Abstract
A major impediment to practical symbolic execution is speed,
especially when compared to near-native speed solutions like
fuzz testing. We propose a compilation-based approach to
symbolic execution that performs better than state-of-the-art
implementations by orders of magnitude. We present SYMCC,
an LLVM-based C and C++ compiler that builds concolic
execution right into the binary. It can be used by software
developers as a drop-in replacement for clang and clang++,
and we show how to add support for other languages with
little effort. In comparison with KLEE, SYMCC is faster by
up to three orders of magnitude and an average factor of 12. It
also outperforms QSYM, a system that recently showed great
performance improvements over other implementations, by
up to two orders of magnitude and an average factor of 10.
Using it on real-world software, we found that our approach
consistently achieves higher coverage, and we discovered two
vulnerabilities in the heavily tested OpenJPEG project, which
have been conﬁrmed by the project maintainers and assigned
CVE identiﬁers.
1 Introduction
Symbolic execution was conceived more than 40 years ago to
aid in software testing [22]. While it was rather impractical
initially, great advances in the ﬁeld of computer-aided reason-
ing, in particular SAT and SMT solving, led to the ﬁrst more
or less practical implementations in the early 2000s [5, 6].
Since then, symbolic execution has been the subject of much
research from both the software security and the veriﬁcation
communities [9, 37, 39, 45], and the technique has established
its place in vulnerability search and program testing. In the
2016 DARPA Cyber Grand Challenge, a competition in auto-
mated vulnerability ﬁnding, exploiting and ﬁxing, symbolic
execution was an integral part in the approaches of all three
winning teams [7, 30, 37].
Despite the increase in popularity, performance has re-
mained a core challenge for symbolic execution. Slow pro-
cessing means less code executed and tested per time, and
therefore fewer bugs detected per invested resources. Several
challenges are commonly identiﬁed, one of which is slow
code execution: Yun et al. have recently provided extensive
evidence that the execution component is a major bottleneck
in modern implementations of symbolic execution [45]. We
propose an alternative execution method and show that it leads
to considerably faster symbolic execution and ultimately to
better program coverage and more bugs discovered.
Let us ﬁrst examine how state-of-the-art symbolic execu-
tion is implemented. With some notable exceptions (to be
discussed in detail later), most implementations translate the
program under test to an intermediate representation (e.g.,
LLVM bitcode), which is then executed symbolically. Con-
ceptually, the system loops through the instructions of the tar-
get program one by one, performs the requested computations
and also keeps track of the semantics in terms of any symbolic
input. This is essentially an interpreter! More speciﬁcally, it
is an interpreter for the respective intermediate representation
that traces computations symbolically in addition to the usual
execution.
Interpretation is, in general, less efﬁcient than compilation
because it performs work at each execution that a compiler
has to do only a single time [20, 44]. Our core idea is thus
to apply "compilation instead of interpretation" to symbolic
execution in order to achieve better performance. But what
does compilation mean in the context of symbolic execution?
In programming languages, it is the process of replacing in-
structions of the source language with sequences of machine
code that perform equivalent actions. So, in order to apply
the same idea to symbolic execution, we embed the symbolic
processing into the target program. The end result is a binary
that executes without the need for an external interpreter; it
performs the same actions as the target program but addi-
tionally keeps track of symbolic expressions. This technique
enables it to perform any symbolic reasoning that is conven-
tionally applied by the interpreter, while retaining the speed
of a compiled program.
Interestingly, a similar approach was used in early imple-
mentations of symbolic execution: DART [16], CUTE [35]
USENIX Association
29th USENIX Security Symposium    181
and EXE [6] instrument the program under test at the level
of C source code. In comparison with our approach, however,
they suffer from two essential problems:
1. Source-code instrumentation ties them into a single pro-
gramming language. Our approach, in contrast, works on
the compiler’s intermediate representation and is there-
fore independent of the source language.
2. The requirement to handle a full programming language
makes the implementation very complex [16]; the ap-
proach may be viable for C but is likely to fail for larger
languages like C++. Our compiler-based technique only
has to handle the compiler’s intermediate representation,
which is a signiﬁcantly smaller language.
The differences are discussed in more detail in Section 7.
We present an implementation of our idea, called SYMCC,
on top of the LLVM framework. It takes the unmodiﬁed
LLVM bitcode of a program under test and compiles symbolic
execution capabilities right into the binary. At each branch
point in the program, the “symbolized” binary will generate
an input that deviates from the current execution path. In
other words, SYMCC produces binaries that perform concolic
execution, a ﬂavor of symbolic execution that does not follow
multiple execution paths at the same time but instead relies
on an external entity (such as a fuzzer) to prioritize test cases
and orchestrate execution (see Section 2 for details).
In the most common case, SYMCC replaces the normal
compiler and compiles the C or C++ source code of the
program under test into an instrumented binary.1 As such,
SYMCC is designed to analyze programs for which the source
code (or at least LLVM bitcode) is available, for example dur-
ing development as part of the secure development life cycle.
It can, however, handle binary-only libraries and inline as-
sembly gracefully. We discuss this aspect in more detail in
Section 6.3. Appendix A demonstrates a typical user interac-
tion with SYMCC.
In this paper, we ﬁrst elaborate on our idea of compilation-
based symbolic execution (Section 3). We then present
SYMCC in detail (Section 4) and compare its performance
with state-of-the-art implementations (Section 5), showing
that it is orders of magnitude faster in benchmarks and that this
speed advantage translates to better bug-ﬁnding capabilities
in real-world software. Finally, we discuss the applicability
of our novel technique and possible directions for future work
(Section 6), and place the work in the context of prior research
(Section 7).
In summary, we make the following contributions:
1. We propose compilation-based symbolic execution, a
technique that provides signiﬁcantly higher performance
than current approaches while maintaining low complex-
ity.
1Support for additional source languages can be added with little effort;
see Section 4.6.
2. We present SYMCC, our open-source implementation
on top of the LLVM framework.
3. We evaluate SYMCC against state-of-the-art symbolic
execution engines and show that it provides beneﬁts
in the analysis of real-world software, leading to the
discovery of two critical vulnerabilities in OpenJPEG.
SYMCC is publicly available
at http://www.s3.
eurecom.fr/tools/symbolic_execution/symcc.html,
where we also provide the raw results of our experiments and
the tested programs.
2 Background
Before we describe compilation-based symbolic execution
in detail, this section summarizes some relevant background
information.
2.1 Symbolic execution
At its core, every implementation of symbolic execution is
constructed from a set of basic building blocks (see Figure 1):
Execution The program under test is executed, and the sys-
tem produces symbolic expressions representing the computa-
tions. These expressions are the essential asset for reasoning
about the program. For our purposes, we distinguish between
IR-based and IR-less execution, which are discussed in the
subsequent two sections.
Symbolic backend The sole purpose of describing compu-
tations symbolically is to reason about them, e.g., to generate
new program inputs that trigger a certain security vulnerabil-
ity. The symbolic backend comprises the components that are
involved in the reasoning process. Typically, implementations
use an SMT solver, possibly enhanced by pre-processing tech-
niques. For example, KLEE [5] employs elaborate caching
mechanisms to minimize the number of solver queries, and
QSYM [45] removes all irrelevant information from queries
to reduce the load on the solver.
Forking and scheduling Some implementations of sym-
bolic execution execute the target program only a single time,
possibly along the path dictated by a given program input,
and generate new program inputs based on that single execu-
tion. The new inputs are usually fed back into the system or
passed to a concurrently running fuzzer. This approach, often
referred to as concolic execution, is followed by SAGE [17],
Driller [39] and QSYM [45], among others. On the other
hand, several other implementations contain additional facili-
ties to manage multiple executions of the program under test
along different paths. Typically, they “fork” the execution at
182    29th USENIX Security Symposium
USENIX Association
Figure 1: The building blocks of symbolic execution. The en-
tire system may be encapsulated in a component that handles
forking and scheduling.
Figure 2: IR-based symbolic execution interprets IR and in-
teracts with the symbolic backend at the same time.
branch points in the program (in order to avoid having to re-
execute from the start with a new input); a scheduler usually
orchestrates the different execution states and prioritizes them
according to some search strategy. For example, KLEE [5],
Mayhem [7] and angr [37] follow this approach.
The problem of path explosion, a term referring to system
overload caused by too many possible paths of execution, is
much more prevalent in this latter group of symbolic execu-
tion systems: A forking system needs to manage a consider-
able amount of information per execution state, whereas con-
colic executors simply generate a new program input, write
it to disk, and “forget about it”. Mayhem [7] implements a
hybrid approach by forking while enough memory is avail-
able and persisting states to disk otherwise. For SYMCC, we
decided to follow the concolic approach because we think
that it allows for higher execution speeds and a simpler im-
plementation.
The three building blocks—execution, symbolic backend,
and forking/scheduling— are conceptually orthogonal to each
other (with some technical dependencies between execution
and forking), even if implementations sometimes lack a clear
distinction. Our work focuses exclusively on improving the
execution component, while we reuse the work of Yun et
al. [45] for the symbolic backend.
We now examine the two prevalent ﬂavors of the execution
component in present implementations of symbolic execution.
Figure 3: IR-less symbolic execution attaches to the machine
code executing on the CPU and instruments it at run time.
IR-based symbolic execution
2.2
A common way of implementing symbolic execution is by
means of an intermediate representation (IR). Compared to
the native instruction sets of popular CPU architectures, IRs
typically describe program behavior at a high level and with
fewer instructions. It is therefore much easier to implement a
symbolic interpreter for IRs than for machine code directly,
so this is the approach that many state-of-the-art systems take.
IR-based symbolic execution ﬁrst needs to transform the
program under analysis into IR. KLEE [5], for example, works
on LLVM bitcode and uses the clang compiler to generate
it from source code; S2E [9] also interprets LLVM bitcode
but generates it dynamically from QEMU’s internal program
representation, translating each basic block as it is encoun-
tered during execution; angr [37] transforms machine code
to VEX, the IR of the Valgrind framework [29]. In general,
IR generation can require a signiﬁcant amount of work [10],
especially when it starts from machine code [21]. Once the
IR of the target program is available, a symbolic interpreter
can run it and produce symbolic expressions corresponding to
each computation. The expressions are typically passed to the
symbolic backend for further processing as discussed above;
Figure 2 illustrates the process.
IR-less symbolic execution
2.3
While translating target programs to an intermediate represen-
tation simpliﬁes the implementation of symbolic execution,
interpreting IR is much slower than native execution of the
corresponding binary, especially in the absence of symbolic
data (i.e., when no symbolic reasoning is necessary). This
observation has led to the development of Triton [34] and
QSYM [45], which follow a different approach: instead of
translating the program under test to IR and then interpreting
it, they execute the unmodiﬁed machine code and instrument
it at run time. Concretely, Triton and QSYM both control the
target program’s execution with Intel Pin [28], a framework
for binary instrumentation. Pin provides facilities for inserting
custom code when certain machine-code instructions are exe-
cuted. The symbolic executors use this mechanism to inject
code that handles computations symbolically in addition to
the concrete computations performed by the CPU. For exam-
ple, when the CPU is about to add the values contained in
USENIX Association
29th USENIX Security Symposium    183
Test	casesConstraints	Symbolic	backendSolver	Program	under	test		Symbolic	execution	frameworkExecution	environmentTest	casesCompilationDirect	IR	generationIR	lifter	Symbolic	execution	frameworkConstraints	SolverIR	interpreterConstraints	Solver	HookingTest	casesAnalysis	engineSymbolic	execution	framework	two registers, Pin calls out to the symbolic executor, which
obtains the symbolic expressions corresponding to the regis-
ters’ values, produces the expression that describes the sum,
and associates it with the register that receives the result of
the computation. See Figure 3 for an overview.
The main advantage and original goal of the IR-less ap-
proach is speed. Run-time instrumentation still introduces
overhead, but tracing native execution while inserting bits
of code is much faster than interpreting IR. Another, more
subtle advantage is robustness: If an IR-based system does
not know how to handle a certain instruction or a call to some
library function it is not able to continue because the inter-
preter cannot execute the requested computation; in IR-less
symbolic execution, however, the CPU can always execute
the target program concretely. The injected analysis code will
just fail to produce an appropriate symbolic expression. One
might say that performance degrades more gracefully than in
IR-based systems.
However, building symbolic execution directly on machine
code has considerable downsides. Most notably, the imple-
mentation needs to handle a much larger instruction set: while
the IRs that are commonly used for symbolic execution com-
prise a few dozen different instructions, CPU instruction sets
can easily reach hundreds to thousands of them. The symbolic
executor has to know how to express the semantics of each of
those instructions symbolically, which results in a much more
complex implementation. Another problem is architecture
dependence: naturally, instrumentation of machine code is a
machine-dependent endeavor. IRs, on the other hand, are usu-
ally architecture agnostic. IR-based systems therefore work
on any architecture where there is a translator from the respec-
tive machine code to IR. This is especially relevant for the
domain of embedded devices, where a great variety of CPU
architectures is in common use. SYMCC uses IR and thus re-
tains the ﬂexibility and implementation simplicity associated
with IR-based approaches, yet our compilation-based tech-
nique allows it to reach (and surpass) the high performance
of IR-less systems, as we show in Section 5.