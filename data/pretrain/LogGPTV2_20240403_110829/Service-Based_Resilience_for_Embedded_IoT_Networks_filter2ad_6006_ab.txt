Resilience
Espling et al. [15]
Breitgand et al. [16]
Pu et al. [17]
Gawali & Shinde [18]
[21], [22], [23], [24], [25]
Medard et al. [26]
Lee et al. [27]
Barla et al. [28], Xu et al. [29]
Beck et al. [30]
Atallah et al. [31]



















Inter-service
Dependency

TABLE II: Terms and deﬁnitions in the optimization problem. Base type contains the fundamental elements of the model. Constants are
network- and service-related parameters given as input. Variables represent the parameters to be optimized.
Type
Symbols
Base
Constant
Variable
u, v
e
s, t
d
p
f
τs
hd
ce
rv
ns
ld
l∗
e
ksv
avf
θpf
xdp
ysv
ysvf
Set
V
E
S
D
Puv
F
(cid:2)∗
(cid:2)∗
(cid:2)∗
(cid:2)∗
Z∗
(cid:2)∗
(cid:2)∗
Z∗
Z∗
Z∗
(cid:2)∗
Z∗
Z∗
Interval
[0,∞]
[0,∞]
[0,∞]
[0,∞]
[0,∞]
[0,∞]
[0,∞]
[0,1]
[0,1]
[0,1]
[0,∞]
[0,1]
[0,1]
Deﬁnition
Nodes in the network
Link (edges) between nodes
Basic services
A demand between a pair of services
An end-to-end path between nodes u and v
A failure scenario/state
Resource consumption of s
Trafﬁc volume of d
Maximum link capacity of e
Maximum resource capacity of v
Required number of instances for s
Latency requirement of d
Latency in e
Binary variable to indicate if v is capable to host s
Binary variable to indicate if v is available in failure state f
Binary variable to indicate if p is available in failure state f
Flow allocated to path p of demand d
Binary variable to decide if s is hosted by v
Binary variable to decide if s is hosted by v in scenario f
xdp is the ﬂow allocated to path p of demand d. A path
p consists of a set of links and each link e ∈ p should have
sufﬁcient link capacity to carry the ﬂows on p as:
xdp ≤ ce
∀e ∈ E
(4)
(cid:2)
(cid:2)
d∈D
p∈P,
e∈p
(cid:3)
P =
u,v∈V Puv.
ce is the capacity of e and P is the set of all paths s.t.
B. Further QoS and Resilience Extensions
Until here, we have presented the main problem as the de-
ployment of services to physical nodes to satisfy inter-service
communication demands under resource and link capacity
constraints. In this section, we extend the problem with the
additional QoS and resilience constraints.
Latency requirements. Apart from the trafﬁc volume Con-
straint (3), a demand d also requires to be satisﬁed within a
bounded delay ld. Therefore, each demand ﬂow xdp should
be allocated to path p that guarantees end-to-end latency less
than ld. The latency in a path depends on the characteristics
of each link forming the path. Here, l∗
e is the delay on link e
and the end-to-end latency is calculated as sum of the delays
in each link. Accordingly, the constraint
xdp(
e − ld) ≤ 0
l∗
∀d ∈ D, ∀p ∈ P
(5)
(cid:2)
e∈p
ensures any active path s.t. xdp > 0 should be suitable for the
corresponding demand. Note that the delay l∗
e on a link is not
inﬂuenced by the trafﬁc and it is assumed as a constant given
as input.
Node capability. Even though assuming that every node
is capable to host any service gives signiﬁcant ﬂexibility
for the service deployment, it is not always possible in real
systems. Embedded nodes may be equipped with different
hardware modules and designed for speciﬁc tasks. Besides,
a system designer might want to ensure that speciﬁc services
run on speciﬁc nodes, because of QoS and security reasons.
Therefore, a binary input parameter ksv to specify if node v
is capable (and permitted) to host service s is added to the
problem. Accordingly, Constraint (2) is extended as,
ksvysv ≥ 1
∀s ∈ S
(6)
(cid:2)
v∈V
to assign services only to capable nodes.
Single-node demand allocation. Demands are deﬁned be-
tween a pair of different services, not necessarily between
543
Authorized licensed use limited to: University of New South Wales. Downloaded on October 01,2020 at 13:28:29 UTC from IEEE Xplore.  Restrictions apply. 
different physical nodes. Services s and t with demand d
s.t. δd = (s, t) can be deployed at the same node. However,
the trafﬁc volume hd is not allocated to any physical path in
that case, since it does not require data transfer through the
network. Instead of deﬁning extra constraints to enable such
a scenario, we modify the deﬁnition of a path such as,
if p ∈ Puv and u = v
{}
{e1, e2...ei} ei ∈ E otherwise
(cid:4)
p =
(7)
This modiﬁcation introduces self-paths that are deﬁned within
nodes themselves and do not include physical links s.t. p = {}.
When a ﬂow is allocated to self-paths, it does not affect
the link capacity Constraint (2) since none of the links is
associated with them. Similarly, latency is omitted in self-paths
and it makes a self-path p eligible to be assigned any demand
if both services s and t of a demand d are allocated to the same
node. Therefore, it does not violate latency and link capacity
constraints.
Failure protection. Safety-critical systems should be re-
silient against different failure scenarios by design. From a
modeling perspective, failure state design is a concept where
each state represents a failure scenario adding extra constraints
to the optimization model [32]. A failure state may include
node failures, link failures or both, and each state f ∈ F
is represented by additional input parameters such as indices
of failed nodes or links to characterize a failure. Only the
initial state i.e., f = 0 represents the natural state of a system
without any failure. The model reiterates through all states to
ﬁnd an optimum deployment that is resilient against all given
failure scenarios. Here, we focus on arbitrary node failures
that happen due to an attack, software failure or power cut
and affect several service instances on the failed node(s).
Such failures may occur in arbitrary nodes independent from
the service deployment scheme. Our failure model includes
one node failure per state and covers all single node failure
scenarios as we deﬁne one state for each node in the network.
(cid:5)
In each failure scenario, a set of binary parameters avf is
given as input to specify if node v is available in failure
v∈V avf = |N| −1 since only one
state f ∈ F and
node is assumed to be failed in each state. Note that the
(cid:5)
model can be extended to consider k-random failures easily
by deﬁning further scenarios where each has multiple failed
nodes satisfying
v∈V avf = |N| −k .
In case of a failure, two main steps should be taken. First, all
service instances hosted in the failed nodes must be deployed
to other available nodes s.t.,
ksvysvf avf ≥ 1
∀s ∈ S, ∀f ∈ F
(cid:2)
(8)
v∈V
where ysvf represents if service s is deployed to node v in
case of failure scenario f. Besides, if v hosts s in any f, there
should be a reserved resource in v for s for migration in case
of that f occurs. Therefore, Constraint (1) is extended as,
(cid:2)
s∈S
(cid:2)
f∈F
min(
ysvf , 1)τs ≤ rv
∀v ∈ V
(9)
544
(cid:2)
(cid:2)
u,v∈V
Here, the term with min function indicates if s deployed to v
in any number of states, only τs amount of resource need to
be occupied in v to activate that service.
Second, routing scheme should be reconsidered since (a)
paths may be broken due to failed nodes and (b) the service
deployment may change while migrating services in different
failure scenarios. Thus, Constraint (3) is extended as,
ysuf ytvf θpf xdp ≥ hd
p∈Puv
auf avf
(cid:6)
∀d ∈ D, δd = (s, t), s, t ∈ S, ∀f ∈ F
(10)
v∈V,v∈p avf indicates if path p is available in
where θpf =
state f, i.e., if all intermediate nodes in p are alive.
Note that the solution constructs a deployment and routing
scheme that is resilient to all single node failure scenarios.
In this sense, such an approach can be considered as both (i)
protective as it reserves required capacity in advance and (ii)
restorative as it decides where to migrate services in case of
related failure scenario happens. We focus on the single node
failure case ﬁrst to keep the problem size relatively smaller
as more complex cases signiﬁcantly increase the number of
possible scenarios, variables, and constraints. However, the
model enables us to design such scenarios where multiple
failed nodes can be selected arbitrarily, e.g., due to hardware
issues, and accidents as well as adjunctly, e.g., connected
nodes failed due to a zonal power cut.
C. Objective Function
As we consider bounded-latency as the main QoS metric in
our formulation, our objective is the minimization of end-to-
end latency. This objective function is decisive to both place
services and demands, since the optimal trafﬁc allocation is
dependent on the service deployment scheme.
Trafﬁc demands can be forwarded through multiple paths
and the whole demand is satisﬁed when the data on the longest
path is received by the destination. In this sense, two end-to-
end delay objectives can be considered. Minimization of the
longest active path length is useful for the type of services
that require the complete data to operate. Maximum amount
of data in shortest time approach is better for the services
that do not require to receive the entire data. Equation (11) is
formulated for the latter one,
l∗
exdp
(11)
(cid:2)
(cid:2)
(cid:2)
d∈D
p∈P
e∈p
min
to allocate high trafﬁc demands to the paths with low-delay
links.
IV. COMPLEXITY OVERVIEW
Joint resource allocation and routing combinatorial opti-
mization problems are shown to be NP-hard [33]. The sizes
of the physical network and service overlay affect problem
complexity in terms of the number of variables and constraints.
In this section, we analyze the individual impact of network
elements to show the complexity of the problem and develop
efﬁcient heuristics presented in Section V. Besides, we show
Authorized licensed use limited to: University of New South Wales. Downloaded on October 01,2020 at 13:28:29 UTC from IEEE Xplore.  Restrictions apply. 
the complexity of constraints and at which cost we linearize
them to use profound LP solvers that are already capable to
solve complex problems efﬁciently. Table III shows the new
variables introduced after the linearization processes.
Constraint complexity. The trafﬁc demand constraints (3)
and (10) include a cubic formulation to ensure that the demand
ﬂows are allocated only on the paths between the nodes
that host related services. We apply a two-stage linearization
process.
a) Linearization of service deployment constraints: The
term ysuytv s, t ∈ S, u, v ∈ V is used to guarantee that
required services s and t for demand d s.t. δd = (s, t)
are allocated two nodes u and v. The multiplication of two
binary variables can be linearized by introducing a new binary
variable wstuv ∈ W under such constraints
wstuv ≤ ysu
wstuv ≤ ytv
wstuv ≥ ysu + ytv − 1
(12)
(13)
(14)
for each combination of ysu and ytv and it
introduces
O(|S|2|V |2) new binary variables. However, it is possible to
eliminate many wstuv if (cid:2)d ∈ D s.t. δd = (s, t). Then, |W|
is reducted to O(|D|).
b) Linearization of ﬂow allocation constraints: In con-
trast to the service deployment part, this stage includes a
binary variable wstuv and a continuous variable xdp instead
of two binary variables. A similar linarization process can be
applied to deﬁne qdp
stuv ∈ Q under those constraints
e ∈ p
stuv ≤ min(ce)wstuv
qdp
stuv ≤ xdp
qdp
stuv ≥ xdp − (1 − wstuv) min(ce)
qdp
stuv ≥ 0
qdp
(15)
(16)
(17)
(18)
where min(ce) e ∈ p is the lowest capacity link in path p and
deﬁnes the upper bound of xdp. After we ﬁlter only matching
service-demand pairs, |Q| can be reduced to O(|D||P|).
e ∈ p
Constraint (9) has also a non-linear term, min function,
to distinguish if service s is deployed to v in any failure
state. Linearization of min requires the deﬁnition of two
binary variables msv and m∗
sv to represent (i) the result of