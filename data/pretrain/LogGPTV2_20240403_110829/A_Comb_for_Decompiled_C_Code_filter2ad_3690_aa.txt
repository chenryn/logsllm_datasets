title:A Comb for Decompiled C Code
author:Andrea Gussoni and
Alessandro Di Federico and
Pietro Fezzardi and
Giovanni Agosta
A Comb for Decompiled C Code
Andrea Gussoni
Politecnico di Milano
PI:EMAIL
Pietro Fezzardi
rev.ng Srls
PI:EMAIL
Alessandro Di Federico
rev.ng Srls
PI:EMAIL
Giovanni Agosta
Politecnico di Milano
PI:EMAIL
ABSTRACT
Decompilers are fundamental tools to perform security assessments
of third-party software. The quality of decompiled code can be a
game changer in order to reduce the time and effort required for
analysis. This paper proposes a novel approach to restructure the
control flow graph recovered from binary programs in a semantics-
preserving fashion. The algorithm is designed from the ground up
with the goal of producing C code that is both goto-free and dras-
tically reducing the mental load required for an analyst to under-
stand it. As a result, the code generated with this technique is well-
structured, idiomatic, readable, easy to understand and fully exploits
the expressiveness of C language. The algorithm has been imple-
mented on top of the rev.ng [11] static binary analysis framework.
The resulting decompiler, revng-c, is compared on real-world bi-
naries with state-of-the-art commercial and open source tools. The
results show that our decompilation process introduces between
40% and 50% less extra cyclomatic complexity.
CCS CONCEPTS
• Security and privacy→ Software security engineering; Soft-
ware reverse engineering; Security requirements.
KEYWORDS
decompilation, reverse engineering, goto, control flow restructuring
ACM Reference Format:
Andrea Gussoni, Alessandro Di Federico, Pietro Fezzardi, and Giovanni
Agosta. 2020. A Comb for Decompiled C Code. In 15th ACM Asia Con-
ference on Computer and Communications Security (ASIA CCS’20), Octo-
ber 5–9, 2020, Taipei, Taiwan. ACM, New York, NY, USA, 15 pages. https:
//doi.org/10.1145/3320269.3384766
1 INTRODUCTION
In the last decades, software has steadily become increasingly ubiq-
uitous, and programmable electronic devices are nowadays part of
every aspect of everyone’s life. Most often, users have little control
on the software that runs on these devices and on the life cycle of
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full
citation on the first page. Copyrights for components of this work owned by others
than the author(s) must be honored. Abstracting with credit is permitted. To copy
otherwise, or republish, to post on servers or to redistribute to lists, requires prior
specific permission and/or a fee. Request permissions from permissions@acm.org.
ASIA CCS ’20, October 5–9, 2020, Taipei, Taiwan
© 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-6750-9/20/10...$15.00
https://doi.org/10.1145/3320269.3384766
release upgrades to fix outstanding bugs. Companies tend to be very
secretive about their implementations and rarely provide access to
the source code of their applications, either to protect patents and
trade secrets, or in the hope to provide security by obscurity. In
some fields, it is also common to find legacy code that runs parts
of critical infrastructures, for which gaining access to the source
is not even an option, since the company that originally provided
it ran out of business.
In all these scenarios, it is challenging for external analysts to
conduct independent security assessments of the implementations,
let alone to provide fixes for bugs and vulnerabilities.
In this context, performing an in-depth analysis of a piece of
software without access to its source code is significantly more dif-
ficult. To this end, decompilers are powerful tools that, starting from
a binary executable program, can reconstruct a representation of
its behavior using a high-level programming language, typically C.
These tools save the analyst from the need of looking directly the as-
sembly code, leading to a dramatic reduction of the effort necessary
to perform a security assessment, making it viable in new scenarios.
The compilation process is not perfectly reversible, which compli-
cates the task of evaluating the quality of the results of a decompiler.
Due to aggressive compiler optimizations and hand-written assem-
bly, it is often impossible to recover the exact original source from
which a binary executable was produced. A decompiler could even
be used to recover C code from a Fortran program. In principle the
process should work, but the recovered C code would not be the
original source nor very idiomatic C.
Therefore, in practice, the goal of a decompiler is not really to
produce the exact same source code that originated the program,
which might be plainly unfeasible, but to produce some high-level
representation easy for analysts to reason about. For this reason, it
is of very important for a decompiler to produce high-quality code.
The quality of decompiled code can be measured in different
ways. Informally, it can be described as the readability of the code,
i.e., the ease with which a snippet of decompiled code can be un-
derstood by an analyst. This qualitative measure is strongly related
to the mental load necessary to understand the behavior of the
code, which in turns depends on the amount of information that
the analyst has to track during the analysis. This information can
be ascribed mainly to the complexity of the control flow and de-
pends on all the possible entangled execution paths that can lead
to a certain portion of the code. All these factors contribute to the
mental load of an analyst.
To minimize such load, and to produce high-quality output code,
decompilers adopt various techniques to restructure the control
flow of decompiled programs, to make them easier to read and to
Session 12: Software Security ASIA CCS '20, October 5–9, 2020, Taipei, Taiwan637reduce the burden of understanding their functioning. As an exam-
ple, control flow restructuring can be used to reduce the number of
goto statements [22], cutting the number of unstructured jumps
across the program, hence reducing the mental load necessary to
track all the possible paths. As another example, control flow re-
structuring can be used to produce if-then-else or loops that
naturally match high-level programming constructs, or to collapse
multiple ifs in a single one if they check the same condition. All
these modifications on the control flow contribute to make the code
easier to understand.
In summary, this paper makes the following contributions:
• we present a novel algorithm for control flow restructuring that
1) produces well-structured programs that can always be emit-
ted in C, without resorting to goto statements, 2) significantly
reduces the cyclomatic complexity [18] of the generated C code
compared to the state of the art, a measure of the complexity of
the control flow strictly related to the mental load required to
understand the observed code, 3) fully exploits the expressive-
ness of the C language (such as short-circuit of if conditions
and switch statements);
• we implement the proposed approach employing the rev.ng
• we compare the resulting decompiler, revng-c, with state-of-
the-art commercial and academic decompilers, on a set of real
world programs, measuring the size of the decompiled code and
its cyclomatic complexity.
binary analysis framework as a basis;
The remainder of this work is structured as follows. Section 2 in-
troduces the fundamental concepts necessary to understand the
rest of the work. Section 3 discusses related works while Section 4
presents the design of the control flow restructuring algorithm.
Section 5 shows the experimental results obtained on a set of real-
world programs, the GNU coreutils, comparing the approach pro-
posed in this work with other commercial, open-source and aca-
demic decompilers: the Hex-Rays Decompiler[1, 13], Ghidra[2], and
DREAM[21, 22]. Finally, Appendix B discusses more idiomatic case
studies and corner cases before the concluding remarks in Section 6.
2 BACKGROUND
This section briefly outlines the main concepts that are necessary
for the understanding of the paper.
Graph basics. In this paper we give for granted a number of fun-
damental concepts revolving around Directed Graphs. For the in-
terested reader, these concepts are discussed in more detail in Ap-
pendix A, and a more distinguished reference can be found in [14].
Most of this concepts should be familiar, since they are widely
used in program analysis for representing the control flow of a
program by means of Control Flow Graphs (CFG). In particular, we
will make wide use of the following concepts.
• control flow graph representation of a program.
• directed acyclic graphs (DAG).
• search and visits over CFGs. In particular, we will make ex-
tensive use of the Depth First Search algorithm, and of the
orderings it induces on a CFG, as the preorder, postorder and
reverse postorder.
• dominance and post-dominance, and the data structures they
induce, the dominator- and post-dominator-tree.
Short-circuit evaluation. In this paper, short-circuit evaluation
refers to the semantics of boolean expressions in C.
If a boolean expression has more than one argument, each argu-
ment is evaluated only if the evaluation of the previous arguments
is not sufficient to establish the value of the expression containing
the boolean operator. This is particularly important when the eval-
uation of some operand of the boolean expression have side-effects,
because only the side-effects of the arguments that are actually
evaluated will be triggered.
Cyclomatic Complexity The cyclomatic complexity is a well-known
software metric used to capture the complexity of a program. It
was originally conceived by T. J. McCabe in 1976 [18].
It represents a quantitative measure of the number of linearly
independent paths in a program source code. The cyclomatic com-
plexity is computed on the control flow graph of a program.
In general, the formula to compute the cyclomatic complexity
of a program is given by 𝑀 = 𝐸 − 𝑁 + 2𝑃, where 𝑀 is the cyclo-
matic complexity itself, 𝐸 is the number of edges in the CFG, 𝑁 is
the number of nodes in the CFG and 𝑃 represents the number of
connected components in the graph.
In the case of a single subroutine 𝑃 is always 1 hence the formula
can be simplified to 𝑀 =𝐸−𝑁 +2. If we consider a program as the
union of all the CFGs of its subroutines the cyclomatic complexity
of the program can be computed as the sum of all the cyclomatic
complexities of the single subroutines.
3 RELATED WORK
This section describes the related work in two main fields: recovery
of Control Flow Graphs, and decompilation.
CFG Recovery. In this work we focus on control flow restructur-
ing, and we use as a starting point the Control Flow Graph of the
function we want to analyze and decompile.
The problem of correctly recovering such graphs from binary
code is well-known and lot of research work has been done in
this field. The CMU Binary Analysis Platform (BAP) [4] is a bi-
nary analysis framework which disassembles and lifts binary code
into a RISC like intermediate language, called BAP Intermediate
Language (BIL). BAP also integrates all the techniques developed
previously for BitBlaze [19]. The rev.ng [8, 9] project, which is
an architecture independent binary analysis framework based on
qemu [3] and llvm [16], is able to lift a binary into an equivalent
llvm ir representation. Other research groups have also dedicated
efforts to tackle the problem of disassembling obfuscated code [15].
The approach presented in this paper does not rely on any spe-
cific technique for extracting CFGs from binary code, hence it is
general enough to be used with any of these approaches.
Decompilation. The academic foundational work in the field of
decompilers is probably Cifuentes’ PhD thesis [7]. The techniques
presented there have been implemented in the dcc decompiler,
which is a C decompiler for Intel 80286.
In the field of commercial decompilers, Hex-Rays[1] is the de-
facto leader, and its decompiler is provided as a plug-in for the
Interactive Disassembler Pro (IDA) [13] tool. No specific informa-
tion on the internal structure of the decompiler is publicly available,
apart from the fact that it uses some kind of structural analysis [12].
Session 12: Software Security ASIA CCS '20, October 5–9, 2020, Taipei, Taiwan638Phoenix [5], a decompiler tool built on top of the CMU Bi-
nary Analysis Platform (BAP) [4], uses iterative refinement and
semantics-preserving transformations. The iterative part is imple-
mented through the emission of a goto instruction when the de-
compilation algorithm cannot make progress.
A very recent entry in the field of decompilers is Ghidra, which
is included in the Ghidra reverse engineering tool [2], initially de-
veloped by US National Security Agency (NSA) for internal use.
The tool has been open sourced very recently (April 2019) but, as of
today, no extensive documentation on the design of the components
has been released.
The decompiled code generated from Ghidra bears some sim-
ilarities with the Hex-Rays Decompiler, and this suggests that it
also uses an approach based on structural analysis. In particular,
both tools, the Hex-Rays Decompiler and Ghidra, emit C code with
many goto statements, which is not idiomatic and results in very
convoluted control flow. This fact makes it hard to keep track of all
the entangled overlapping control flow paths in the code, making
it hard to understand. This characteristic is also somehow shared
by the Phoenix decompiler, which emits goto statements when it
cannot make further progress.
The DREAM [22] decompiler takes a drastically different direc-
tion. The authors present various semantic-preserving transforma-
tions for the CFG, and a decompilation technique that emits no goto
statements by design. However, to avoid gotos, DREAM handles
“pathological” loops by means of what can be seen as predicated
execution. If a CFG has a loop and a branch that jumps straight
in the middle of the loop from a point outside the loop, DREAM
wraps parts of the body of the loop inside a conditional statement
guarded by a state variable. This design choice prevents gotos but
generates code where multiple execution paths are entangled and
partially overlap. An example can be seen in an open dataset of
code snippets released by the authors [20], in Section 1.5, page 7, at
lines 12–16 of code generated by DREAM. In larger functions, this
can significantly increase the mental load of an analyst, especially if
a loop contains more than one of these conditional blocks, possibly
nested or with multiple conditions.
4 CONTROL FLOW COMBING
In this paper we make a novel choice for the generation of decom-
piled code that is free from goto statements: we accept to duplicate
code in order to emit more idiomatic C code that reduces the mental
load of an analyst, being more readable and easier to understand.
This section focuses on the details of this technique, called Control
Flow Combing.
The algorithm is composed of 3 stages: a Preprocessing, which
prepares the input CFG to the manipulation, transforming it into
a hierarchy of nested Directed Acyclic Graphs (DAG); the actual
Combing stage, which disentangles complex portions of the control
flow by duplicating code portions or introducing dummy nodes; a
final Matching stage, which matches idiomatic C constructs, while
trying to reduce unnecessary duplication.
Informally, the idea is to “comb” the Control Flow Graph, dupli-
cating code to disentangle convoluted overlapping paths, so that the
properties necessary to emit idiomatic C code naturally emerge. We
pay this potential duplication as a cost necessary to handle generic
binary programs. To gracefully handle common cases, the Matching
step is performed as post-processing to reduce duplication when
possible, leaving freedom and generality to the Combing without