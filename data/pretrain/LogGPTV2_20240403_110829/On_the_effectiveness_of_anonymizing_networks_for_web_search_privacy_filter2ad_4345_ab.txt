### 优化后的文本

尽管用户通过Tor进行浏览，但Google仍然能够识别他们的身份。类似地，由于对如PWS [17]等工具的不熟悉，许多用户可能不会禁用其Cookies。总而言之，即使存在总共1500个Tor出口节点，并且大量用户可能使用Tor进行私人网络搜索，实际上只有少数用户能对搜索引擎保持匿名状态。此外，搜索引擎可能并不想追踪每一个匿名用户，而是集中关注那些基于敏感查询内容或真实身份（例如疑似恐怖分子）而被选中的用户。鉴于这些重要的观察结果，我们假设最多有N = 1000个匿名网络搜索用户，并尝试将查询集Q与这些用户关联起来。我们认为这个数字对于实验来说是合理的。

假设搜索引擎有兴趣识别某个特定用户的查询（记为A）。设Q包含nu个A的查询和其他用户no个查询（通常情况下nu < no）。在我们的模型中，由于仅处理查询内容而不考虑用户的额外点击模式，因此忽略了ItemRank和ClickURL特征。

AnonymousID特征用于区分AOL用户，并作为分类的标签。由于Query特征是字符串形式，WEKA无法直接处理，我们使用内置的WEKA预处理过滤器StringToWordVector将其转换为词向量。我们还添加了另一个特征Query Length，虽然它隐含在Query信息中，但在第3.1节中有详细描述。由于通过Tor发送查询时存在固有的延迟，时间特征不能直接使用，因此我们考虑了较长时间窗口。由于难以预测哪种时间窗口大小会提供更好的结果，我们将一天24小时分为不同的非重叠窗口（分别为3、4、6和12小时），并比较每个时间窗口大小的准确性。

AnonymousID和Query是必要的属性。为了确定每个附加属性对分类结果的影响，我们在N=100的情况下，一次添加一个附加属性，以确定所有感兴趣用户的平均准确率。表1显示了平均准确率。可以看出，通过添加Query Length特征，在OVA和AVA两种情况下都实现了合理的表现。添加时间窗口并未显著提高现有准确率。可能存在其他更好的利用查询时间的方法，但我们暂时忽略它们。因此，在以下所有实验中，我们都将Query Length作为附加属性，与Query和AnonymousID一起使用。

### 实验与结果

在我们的实验中，我们试图估计分类器正确识别60个感兴趣用户的查询的准确率。对于每个感兴趣的用户，我们在五个数据集上测量准确率，每个数据集包含不同数量的“其他用户”查询，这些查询与当前感兴趣的用户的查询混合在一起。生成了五个数据集，分别包含随机选择的99、199、299、499和999个其他用户。为了在所有60个感兴趣的用户之间保持一致，我们使用了相同的“其他用户”数据集。因此，当感兴趣的用户的查询集与其他用户的查询混合时，我们形成了N分别为100、200、300、500和1000用户的数据集。

对于每个感兴趣的用户A，我们直观地将正确识别的用户A的查询比例（在第2节中表示为x）称为Correctly Classified，将错误分类为用户A的其他用户的查询比例（在第2节中表示为y）称为Misclassified（这些术语不符合标准机器学习定义）。如第2节所述，我们希望Correctly Classified值尽可能高，而Misclassified值尽可能低，并将其视为性能的最佳衡量标准。

我们获得了所有60个感兴趣用户的实验结果，这些用户属于第3.2节讨论的三类。对于每一类，我们总结了OVA结果，表明所有感兴趣用户的Correctly Classified和Misclassified的平均值。图4给出了查询数量的OVA结果摘要，图5给出了查询长度的OVA结果摘要，图6给出了敏感查询的OVA结果摘要。对于每类的AVA分类结果与OVA分类结果非常相似，因此未在论文中报告。

### 结果解释与讨论

通过使用WEKA中的词干提取算法，我们识别出查询中出现的“根”关键词，并按出现频率降序排列。分布情况如图7所示。总共有28659个根关键词（即词干），其中只有4797个根关键词出现次数超过10次。这种分布类似于[6]中讨论的Web搜索查询的“长尾”行为，每个用户都被认为有些特殊，既发送常见的查询（所有出现次数超过10次的根关键词），也发送一些独特的查询（至少有一个出现次数少于10次的关键词）。

---

这样修改后，文本更加清晰、连贯和专业。希望这对你有所帮助！