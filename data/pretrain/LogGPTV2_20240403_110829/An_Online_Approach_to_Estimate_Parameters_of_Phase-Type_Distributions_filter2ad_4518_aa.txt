# Title: An Online Approach to Estimate Parameters of Phase-Type Distributions

**Authors:**
- Peter Buchholz
- Iryna Dohndorf
- Jan Kriege

**Conference:**
2019 49th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN)

## Abstract
The traditional Expectation-Maximization (EM) algorithm is a general-purpose method for maximum likelihood estimation in problems with incomplete data. Several variants of the EM algorithm exist for estimating the parameters of phase-type distributions (PHDs), which are widely used in performance and dependability modeling. EM algorithms are typically offline, as they improve the likelihood function by iteratively processing a fixed sample. However, in modern systems, data is often generated online, making offline algorithms less suitable. This paper proposes an online EM algorithm for parameter estimation of PHDs. Unlike the offline version, the online variant processes data as it becomes available and does not involve iterations. We present different variants of the algorithm that exploit the specific structure of subclasses of PHDs, such as hyperexponential, hyper-Erlang, or acyclic PHDs. The algorithm also incorporates methods to detect drifts or change points in a data stream and estimates a new PHD whenever such behavior is identified. This allows the resulting distributions to be used for online model prediction and the generation of inhomogeneous PHDs, extending inhomogeneous Poisson processes. Numerical experiments with artificial and real-world data streams demonstrate the applicability of the approach.

**Index Terms:**
- Stochastic modeling
- Phase-type distributions
- Expectation-maximization algorithm
- Online algorithm
- Parameter estimation

## I. Introduction
Quantitative performance and dependability measures in computer and communication systems are often analyzed using stochastic models. A key aspect of stochastic modeling is the appropriate modeling of input parameters using distributions or stochastic processes, commonly referred to as input modeling in stochastic simulation and analysis [1], [2]. Input modeling typically involves sampling from a running system, selecting an appropriate distribution type, and estimating its parameters. Subsequently, stochastic tests may be used to validate the generated model.

For performance and dependability modeling, it is often advantageous to use analytical or numerical methods rather than stochastic simulation. This usually restricts the class of distributions to phase-type distributions (PHDs) [2]–[4]. PHDs are versatile and can approximate the observed behavior of real systems with sufficient accuracy. However, parameter estimation for PHDs is complex and often results in non-linear optimization problems.

Parameter estimation for PHDs has been a research topic for many years, and various approaches have been proposed. For a comprehensive survey, see [2]. The most general but often costly approach is to maximize the likelihood function of a PHD with respect to the measured data using the Expectation-Maximization (EM) algorithm [5], [6]. Various EM-algorithms for PHDs have been developed, allowing accurate parameter estimation for PHDs with 10 or more phases and sample sizes of 10^5 or even 10^6, which is sufficient for most applications.

The traditional approach of sampling data from a system and subsequently estimating distribution parameters is rooted in classical statistics and stochastic modeling, assuming that data collection is costly and requires offline measurement. However, in today's systems, numerous sensors produce large amounts of data almost for free in an online manner. This results in continuously growing datasets, as seen in data centers, production systems, and communication networks where real-time monitoring is common.

The standard approach for parameter estimation of PHDs cannot be applied to online data because it requires a fixed sample. EM-algorithms determine parameters by iteratively processing the data, implying that a sub-sample is taken from the available data, and the parameters of the PHD are estimated from this sub-sample. The resulting stochastic model is then used to analyze the system or predict future behavior, such as estimating failure probabilities or optimal maintenance intervals. This approach has two major drawbacks: it neglects some available information and cannot quickly adapt to changes in system behavior.

To leverage the availability of online data, parameter estimation must also be done online. In this paper, we present, to the best of our knowledge, the first online EM-algorithm for parameter estimation of PHDs. The proposed algorithm is based on existing online algorithms for mixture distributions [7], [8]. Unlike these approaches, we assume that the observed system may change its behavior over time, and the algorithm adapts by estimating new parameters whenever such changes occur. The algorithm computes an initial PHD and then improves the parameters using online data, integrating statistical methods for change point detection and model selection within the EM-algorithm.

The paper is structured as follows: Section II briefly reviews related work. Section III introduces basic assumptions, notation, and definitions. Section IV develops the online EM-algorithm for PHDs. Section V embeds the EM-algorithm in an adaptive framework that determines different PHDs from online data and selects the best PHD for the available information. The complete algorithm is then evaluated empirically using synthetic and real data. The paper concludes with a discussion of future research directions.

## II. Related Work and New Contribution
The approach developed in this paper is based on PHDs, EM-algorithms, and statistical methods for change point detection and model selection. PHDs are based on the pioneering work of Neuts [3], [9] and are used in various types of stochastic models [2], [4], [10]. Historically, PHDs were restricted to simple structures, and parameters were determined by fitting empirical moments of low order. However, this approach often results in a PHD that only roughly approximates the observed behavior. Better parameter estimation techniques are based on the maximization of the likelihood function, commonly using the EM-algorithm [6].

The first EM-algorithm for PHDs was published by Asmussen and his coworkers [6], and subsequent modifications and improvements have been made in numerous publications. The EM-algorithm is more stable and efficient when applied to subclasses of PHDs, such as hyperexponential [12], hyper-Erlang [13], or acyclic PHDs in canonical form [14]. These subclasses are appropriate for EM-algorithms, and we use them in our approach.

All mentioned EM-algorithms for PHDs are offline, using a fixed sample and iteratively improving the parameters until they stabilize. Other offline estimation approaches, such as those in [18] and [19], use derived measures like moments but still require the complete dataset. For general distributions, online EM-algorithms have been proposed in [7], [8], and [20] presents an online EM-algorithm for mixtures of logistic regression models. These algorithms process a continuous stream of data, updating parameters with each new data point and weighting data points with a decreasing function. The goal is to estimate the parameters of a model under the assumption of an identical distribution for the observed data points. The online algorithm generates a new set of parameters with each new data point, and the resulting distribution can be used in a stochastic model for analysis and forecasting while parameters are improved with new information.

The integration of specifically tailored steps for acyclic PHDs in online EM-algorithms and the adaptive generation of PHDs based on online data are the new contributions of this paper. The approach generates a sequence of PHDs that change at discrete time points, effectively creating a model with time-varying distributions. Beyond online applications, the algorithms presented here can also be used to generate time-dependent PHDs, extending non-homogeneous Poisson processes [21]–[23].

For the selection of a PHD from the set of possible realizations, significance tests are needed. In settings where the values of the likelihood function are available, these values should be used for significance testing [24]. The ratio of likelihood values can also be used to detect change points in time series [25]. However, in an online setting, exact significance tests are usually not feasible due to the lack of regularity conditions for general mixing distributions [26] and the computational effort required for the exact likelihood ratio [27]. Therefore, we use a one-sample update approximation of the likelihood ratio, which has shown good theoretical and practical properties for change point detection in general time series [27].

## III. Background and Definitions
We begin with a brief introduction to PHDs. For further details, see [2], [9], [28] and the references therein. A PHD can be interpreted as an absorbing Markov chain with state space \( S = \{0, \ldots, n\} \), where state 0 is absorbing and states 1 through n are transient. We consider only distributions without probability mass at zero. The PHD is characterized by the initial probability vector \(\pi\) and the sub-generator matrix \(D\). The time to absorption of the absorbing Markov chain defines the PHD, with the probability density and distribution function given by:
\[ f_{(\pi, D)}(t) = \pi e^{tD} d \]
\[ F_{(\pi, D)}(t) = 1 - \pi e^{tD} \mathbf{1} \]
where \(d = -D \mathbf{1}\) and \(\mathbf{1}\) is a column vector of ones with length \(n\).

PHDs can theoretically approximate any non-negative distribution arbitrarily closely [29]. Several subclasses of PHDs exist, which have fewer parameters and simpler structures but similar expressiveness. Acyclic PHDs (APHDs) are particularly useful in modeling. A PHD is acyclic if \(D\) can be reordered to an upper triangular matrix. For APHDs, canonical representations are available, which are not known for general PHDs. We use the canonical form 1 of [17]:
\[ \pi = (\pi_1, \ldots, \pi_n), \quad D = \begin{pmatrix}
-\lambda_1 & \lambda_1 & 0 & \cdots & 0 \\
0 & -\lambda_2 & \lambda_2 & \cdots & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & \cdots & -\lambda_n
\end{pmatrix} \]
where \(\lambda_n \geq \lambda_{n-1} \geq \cdots \geq \lambda_1 > 0\) and \(\pi_i \geq 0\). An APHD is a hyperexponential distribution if \(D\) is a diagonal matrix and a hyper-Erlang distribution if it can be represented as:
\[ D = \begin{pmatrix}
D_1 & 0 & \cdots & 0 \\
0 & D_2 & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & D_m
\end{pmatrix} \]
where \(D_j\) is an \(n_j \times n_j\) matrix, \(n = \sum_{j=1}^m n_j\), \(\lambda_j > 0\), and \(\pi_i > 0\) if \(i = 1 + \sum_{h=1}^k n_h\) for some \(1 \leq h \leq m\) and 0 otherwise. In the following, we denote by \(\Theta\) the set of PHDs of some fixed order \(n\) or a subset of this set containing only PHDs of a specific form, e.g., only APHDs.

In practice, the parameters of a PHD must be chosen to match the behavior observed from a real process. Let \(T = (t_1, t_2, \ldots, t_k)\) be an observed sequence of inter-event times. Different approaches exist to determine the parameters, with the maximum likelihood approach being the most promising. This approach maximizes the likelihood function or its logarithm:
\[ L(T) = \max_{(\pi, D) \in \Theta} \prod_{h=1}^k \pi e^{t_h D} d \]
or
\[ \ell(T) = \max_{(\pi, D) \in \Theta} \sum_{h=1}^k \log \left( \pi e^{t_h D} d \right) \]

Let \((\pi^*, D^*)\) be a PHD where the maximum is reached. Equation (3) describes a non-linear optimization problem, which is difficult to solve. The EM-algorithm [5] is typically applied, and several variants for PHDs have been published [2], [6], [11]–[15].

EM-algorithms are based on two sample spaces: an unobservable space \(X\) and an observable space \(T\). Each observation is assumed to be a deterministic function of \(X\) taking values in \(T\). This function is denoted as \(f_\theta(t)\), which is a family of densities with parameter \(\theta \in \Theta\). The EM-algorithm starts with an initial guess of \(\theta\) and then performs two steps iteratively: the expectation (E-) step and the maximization (M-) step. The E-step computes the distribution of unobserved data from the known observations and the guess of the parameters. In the M-step, parameters are re-estimated by choosing the parameters that maximize the likelihood under the assumption that the distribution found in the E-step is correct.

For PHDs, the following values are computed in the E-step [14] from \(T = (t_1, t_2, \ldots, t_k)\) and the parameters \(\theta = (\pi, D)\):
\[ E_\theta[B_i^{(h)}] = \frac{\pi_i (e^{t_h D} d)_i}{\pi e^{t_h D} d} \]
\[ E_\theta[Z_i^{(h)}] = \int_0^{t_h} \frac{\pi_i (e^{(t_h - \tau) D} d)_i}{\pi e^{t_h D} d} d\tau \]
\[ E_\theta[N_{ij}^{(h)}] = \int_0^{t_h} \frac{\pi_i (e^{\tau D})_i (e^{(t_h - \tau) D} d)_j}{\pi e^{t_h D} d} d\tau \quad (i \neq j) \]
\[ E_\theta[Y_i^{(h)}] = \frac{\pi_i (e^{t_h D} \mathbf{1})_i}{\pi e^{t_h D} d} \]

For specific subclasses, the values can be computed by exploiting the restricted structure. In general, the expectations must be computed numerically using techniques like uniformization [2], [14]. In the M-step, new estimates for the parameters are computed as follows:
\[ \pi_i = \frac{1}{k} \sum_{h=1}^k E_\theta[B_i^{(h)}] \]
\[ D_{ij} = \frac{\sum_{h=1}^k E_\theta[N_{ij}^{(h)}]}{\sum_{h=1}^k E_\theta[Z_i^{(h)}]} \quad (i \neq j) \]
\[ D_{ii} = -d_i - \sum_{j \neq i} D_{ij} \]
\[ d_i = \frac{\sum_{h=1}^k E_\theta[Y_i^{(h)}]}{\sum_{h=1}^k E_\theta[Z_i^{(h)}]} \]

The computations (4) and (5) are iterated until the parameters remain stable. In each iteration, each element of \(T\) is used. It should be noted that the algorithm maintains the structure of the PHD because parameters that are zero will remain zero. The EM-algorithm generates a sequence of PHDs with increasing likelihood and is guaranteed to converge towards a local optimal solution, although convergence can be slow.

## IV. Online-Expectation-Maximization Algorithms for Phase-Type Distributions
The EM-algorithm iterates over a fixed sequence of observations \(T\) and works offline. However, many systems are observed online, with new observations arriving continuously. Offline algorithms cannot handle this, as it is unclear whether the algorithm will converge when applied to different samples in each iteration, and the sample size will become too large. Consequently, online EM-algorithms have been developed in various areas, including parameter estimation of finite mixture distributions, unsupervised learning, and parameter estimation of general state space models and hidden Markov models [7], [8], [30]–[32].

Our approach is based on [7], which presents an online EM-algorithm for mixture distributions. Unlike these approaches, we assume that the observed system may change its behavior over time, and the algorithm adapts by estimating new parameters whenever such changes occur. The algorithm computes an initial PHD and then improves the parameters using online data, integrating statistical methods for change point detection and model selection within the EM-algorithm.