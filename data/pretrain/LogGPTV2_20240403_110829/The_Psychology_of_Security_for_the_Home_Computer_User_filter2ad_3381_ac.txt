to ensure safety online), maladaptive (avoidance of online
shopping), risky (security speciﬁc actions that enhance on-
line risk) and protective behaviors (security interventions to
mitigate risk). Ultimately, the idea is that if speciﬁc factors
can be shown to push people away from risky behaviors and
toward adaptive and protective behaviors, then these factors
might be exploited in training programs. They recruited 449
online shoppers from a commercial opt-in consumer panel
and asked them questions to assess the three factors and four
types of behaviors. Questions included:
• Perceived Threat “I am concerned about having my
identity stolen while shopping online.” (5 point scale
from strongly disagree to strongly agree)
• Perceived Likelihood “How likely is it for one’s identity
to be stolen while shopping online?” (5 point scale from
very unlikely to very likely)
• Adaptive Behavior “In the past year, have you asked an
online business to remove your name and address from
any lists they use for marketing purposes?” (yes or no)
• Maladaptive Behavior “In the past year, have you
avoided online shopping to avoid risk?” (yes or no)
• Self-Efﬁcacy “I am skilled at avoiding dangers while
shopping online.” (5 point scale from strongly disagree
to strongly agree)
The risky and protective behaviors were assessed by asking
participants to select behaviors from a list of possibilities:
16 protective behaviors such as installing virus checkers and
using anonymizers while browsing, and 33 risky behaviors
such as saving passwords on computers and downloading
unknown ﬁles from social networking sites.
Regression models built from the results of the survey
showed that self-efﬁcacy had signiﬁcant positive effects on
adaptive and protective behaviors, and signiﬁcant negative
effects on maladaptive and risky behaviors. In other words,
users who felt conﬁdent in their abilities had a stronger
tendency to take actions to protect themselves. For the other
214
they found that perceived likelihood had a
two factors,
signiﬁcant effect on adaptive behavior, but perceived threat
did not. In contrast, they found that perception of threat ex-
erted a signiﬁcant positive effect on maladaptive behaviors,
but perceived likelihood of threat did not. Neither factor
had a signiﬁcant effect on risky or protective behaviors.
These results suggest that online shoppers responded more
appropriately to knowledge of probability of negative threats
than to knowledge of the threats themselves.
Byrne et al. [15] examined how the presence of speciﬁc
Internet
threats inﬂuence users’ views of their levels of
vulnerability and risk. The Internet threats examined were:
• Availability: computer resources are improperly made
inaccessible,
• Integrity: data on the computer is modiﬁed without the
user’s authorization,
• Conﬁdentiality: sensitive information is revealed with-
out the user’s approval and
• Unwitting Accomplice: user unintentionally spreads the
threat to others.
Two levels of each threat (low and high) were represented.
The study used policy-capturing in which 104 subjects
were asked to judge cues that were systematically varied
across a set of 16 vignettes. Two groups of participants
were recruited via ﬂyers in places they were likely to
frequent. The two groups, young adults between 18 and
29 years and adults of 50 years or older, were the focus
because they were felt to be especially vulnerable to security
threats. They were asked questions about their level of basic
computer knowledge (two questions on a 6-point scale from
“no knowledge” to “extensive”), extensiveness of computer
knowledge (eight questions on a 5-point scale from “strongly
disagree” to “strongly agree”), self-perception of computer
knowledge (one question), frequency of computer usage (one
question), and prior exposure to privacy invasions (one ques-
tion). The experiment was conducted as an online survey;
the participants were presented with vignettes corresponding
to the four threats and asked to respond to questions about
their perceived level of risk (6 point scale from “no risk
at all” to “highest level of risk”) and vulnerability (6 point
scale from “not vulnerable at all” to “extremely vulnerable”).
The vignettes were variations on a scenario in which the
participant received an email containing an embedded link
that would access a dollar-off coupon and then described
a series of actions triggered by clicking on the link. The
actions corresponded to the threats; for example, to simulate
a low availability threat, the act of printing the coupon would
cause the Web browser’s history to be removed.
The data from the policy-capturing study were analyzed
using hierarchical linear modeling to assess the importance
of the cues for each participant as well as between partic-
ipants. The analysis showed that all four threats increased
ratings of risk and vulnerability perceptions. Interestingly, it
also showed that participants with more extensive computer
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:49:21 UTC from IEEE Xplore.  Restrictions apply. 
knowledge gave more weight to integrity threats than did
other participants when rating risk perceptions. Those who
reported higher levels of self-perceived computer knowledge
gave more weight to threats of integrity when responding to
their perceived vulnerability levels. This suggests that better
understanding of computers in general may translate to better
appreciation for the consequences of risky actions.
One of the services most likely to put users at privacy
risk may be Facebook. A 2007 report by Privacy Inter-
national [31] assessed the privacy practices of 21 Internet
service companies; Facebook was one of seven that received
an assessment of ”substantial and comprehensive privacy
threats” (only Google fared worse). User attitudes toward
social networking and Facebook have been well studied and,
generally, are beyond the scope of this review. However, the
results of studies by Debatin et al. [32] and Govani and
Pashley [33] highlight the need to consider user perceptions
of both risk and beneﬁt when encouraging secure behavior.
In [32], 119 undergraduates in the U.S.A. took an online
survey of 36 multiple choice questions. The ﬁrst set of
questions asked about their Facebook setup and habits (e.g.,
how long they had an account, how often they check their
account, what types of personal information were in their
proﬁle, whether they signed up under their real name). The
second set assessed users’ privacy practices: familiarity with
Facebook’s privacy settings, protections on their own proﬁle
and when they adjusted the privacy settings. The third set
assessed the role of friends: how many friends and what type
of friends they accept. The fourth set assessed the perceived
beneﬁts of Facebook: “Do you feel that Facebook helps you
interact with friends and people?”, “Do you think you would
have less contact with friends if you didn’t have your Face-
book account?” and “What role does Facebook play in your
everyday life?” (very important/not important). The ﬁfth set
assessed the perception of potential risks by asking whether
participants had encountered any of 1) unwanted advances,
stalking or harassment, 2) damaging gossip or rumors, or
3) personal data stolen/abused by others; participants were
asked whether the same problems may have happened to
other people. Finally, the participants were asked whether
they would change their account setting if they were to hear
of such incidents.
The results of the Facebook survey showed that 91% of
participants were familiar with the settings and were also
likely to restrict their proﬁle privacy settings (77%). How-
ever, their restrictions were fairly weak with half restricting
to “only friends” and the deﬁnition of “friend” comprising
a large group of people (38% of participants had > 300
friends, 42% had 100 − 300 friends). The participants also
reported revealing a great deal of personal information on
their proﬁles; 90% included their real name, gender, date
of birth and hometown, and 1/3 provided personal contact
information. A paired-samples t-test comparing the per-
ceived beneﬁts to the perceived risks showed a statistically
signiﬁcant difference (p < .001) between beneﬁts (higher)
over risks. The results also showed that participants were
more likely to perceive risks to others’ than to themselves
and were more likely to change their privacy settings if they
personally had an invasion of privacy over hearing of such
an incident in others.
Additionally, even when informed of the privacy settings,
users may not change their behavior. A pilot study surveyed
50 undergraduates at Carnegie Mellon University, asking
about how they used Facebook and its privacy settings
[33]. The experiment also downloaded each participant’s
Facebook proﬁle before and ﬁve days after the survey; the
“after” proﬁle showed remarkably little change in the contact
information that was being included in the participant’s
proﬁle (e.g., 6.4% drop in primary emails, 8.3% drop in
street addresses and no drop in telephone numbers listed).
The two Facebook studies suggest that some services are
viewed as so essential that users will incur the risk.
V. DEFENSIVE SECURITY ACTIONS
Threats to personal security and privacy can be handled
through preventative actions or through interventions when
problems are encountered. We divide the discussion of stud-
ies of users’ actions and attitudes into these two activities.
A. Efforts to Avoid Security Breaches
Surveys show mixed results on actions taken to avoid
security problems. The survey of users in the U.K. found a
high level of installation of security software (93% had anti-
virus software, 87% had ﬁrewalls, 77% had anti-spyware and
60% had anti-spam), but lower levels of frequently updating
the software (from 37% to 63% updated weekly) [8]. A 2006
telephone survey in Michigan [18] found that only 4% of
respondents claimed to have no virus protection software,
50% set it up themselves and 41% had it set up by their
ISP or others; additionally, 46% claimed to always read
privacy statements with only 25% claiming they never or
hardly ever read them. A 2010 study in U.S.A. reported
a lower level of security software usage and identiﬁed
a signiﬁcant discrepancy between self-reports of software
security installation (58%) and actual installation (37%)[7].
Together these studies suggest that many users know they
should take action but do not follow through.
The access control study of [28] found that 30 out of
33 reported using security measures to avoid unauthorized
access such as separate accounts, different passwords, ﬁle
encryption, being physically present when ﬁles are exam-
ined, physically separating devices, hiding sensitive ﬁles
and deleting sensitive data. The authors note that several of
these strategies reﬂect a mismatch between the participants’
mental models and the reality of access to ﬁles on devices,
especially the notion that physical location is key to main-
taining access control. As in the mental models of [26], [16],
the participants seemed to be applying their mental models
215
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:49:21 UTC from IEEE Xplore.  Restrictions apply. 
of everyday life (e.g., hiding valuables to ensure physical
security) to computer security. The participants wanted ﬁne
grained groupings of people and data/ﬁle types, read versus
write access, logging, accessors asking permission and ac-
cess based on physical presence. Similar desires were found
in another access control study of 20 home users recruited
through Craigslist and personal contacts [34].
The study of folk models of security [16] also examined
how the folk models related to the kinds of security advice
that participants followed. The 12 security actions included
three on anti-virus software use, one as a catch-all for other
security software, one on email, four on Web browsing
and site visiting, and three on computer maintenance. All
groups reported that it was important to not click on email
attachments. The group that viewed viruses as ‘Bad’ also
indicated that maybe one should use anti-virus software and
maybe be careful with software downloads. The group that
viewed viruses as ‘Buggy Software’ also indicated that it
was important to be careful with software downloads, it was
maybe a good idea to make regular backups and maybe
to keep patches up to date. The group that viewed viruses
as ‘Mischief’ indicated that it was important to be careful
which websites are visited and to make regular backups;
they also thought it might be a good idea to use anti-virus
software, keep anti-virus software updated, regularly scan
their computer, use other security software, and be careful
downloading software. The group that viewed viruses under
the ‘Crime’ model viewed as important the three anti-virus
activities, being careful in downloading software, keeping
patches up to date and turning off the computer when not in
use; they also thought being careful of which websites were
visited may be a good idea. If the group description did not
mention some security advice, then what remained of the
12 actions was either viewed as unnecessary or offered no
opinion. As one moved across the four models, more security
advice was considered to be important or helpful. Two
actions were ignored by all groups: 1) disabling scripting
in Web and email and 2) using good passwords. Based on
this study, Wash recommended that education should focus
not just on the appropriate actions but also on explaining
why they will help.
A model of home system administrators who personally
act to secure their home computers was developed to identify
the factors that inﬂuence adoption of security protections
[35]. The model combined TPB with two other models
that have been used for explaining technology adoption:
Theory of Reasoned Action (TRA) which relates subjective
norms and a person’s attitudes to the intention to behave
and Diffusion of Intention (DoI) which identiﬁes factors that
inﬂuence the adoption of new ideas. The proposed model
included ﬁve categories of inﬂuences: characteristics of the
user (self efﬁcacy of security and self efﬁcacy of computer
skills), risk tolerance (computer use and risk awareness),
characteristics of innovation (complexity, effectiveness and
suitability), social consequences (previous security experi-
ence, direct experience with threats and subjective norms)
and communication channels (news, friends, vendors and
work). These factors were used to predict level of impor-
tance and agreement on need to use anti-virus software,
anti-spyware software, operating system patches, ﬁrewalls,
backups and passwords. The model was validated in a self-
reporting survey of 77 questions taken by 356 participants
who were solicited in snowball sampling starting with solic-
itations through a charity volunteer mailing list, parents and
teachers from a high school, a variety of newsgroups and
some businesses. Analysis of the results showed that not
all the factors were signiﬁcant; the pruned model included
only seven of the original 14 factors: self-efﬁcacy of secu-
rity skills, self-efﬁcacy of computer skills, risk awareness,
suitability, direct experience, subjective norms and vendors.
The lack of inﬂuence of the other factors may be due to
the fact that the subjects were selected to have been already
experienced in maintaining security on their home machines
and clearly motivated to do so. The study suggests that this
subgroup of home users may have different needs and may
respond differently to security measures.
Milne et al.’s study of risk perception of online shoppers
[14] collected data about protective and risky behaviors.
Their respondents reported high levels of many defensive
actions: virus checker installation (86%), passwords with
a combination of letters, numbers and symbols (85%),
scanning for spyware (84%), clearing browser cache (81%),
checking that online forms are secure (81%) and opting out
of third party information sharing (80%). The percentages
for risky behaviors were lower: saved password on com-
puter (56%), saved credit card information in online store’s
database (51%), and used social networking sites (45%).