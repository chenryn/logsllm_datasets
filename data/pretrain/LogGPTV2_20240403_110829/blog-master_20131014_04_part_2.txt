  #define STAP_RETVALUE THIS->__retvalue  
  c->last_stmt = "identifier 'exit' at /usr/share/systemtap/tapset/logging.stp:49:10";  
  if (unlikely (c->nesting+1 >= MAXNESTING)) {  
    c->last_error = "MAXNESTING exceeded";  
    return;  
  } else {  
    c->nesting ++;  
  }  
  #define return goto out  
  {  
     /* unprivileged */  
    atomic_set (&session_state, STAP_SESSION_STOPPING);  
    _stp_exit ();  
  }  
  #undef return  
out:  
  if (0) goto out;  
  c->nesting --;  
  #undef CONTEXT  
  #undef THIS  
  #undef STAP_RETVALUE  
}  
static void probe_3027 (struct context * __restrict__ c) {  
  __label__ out;  
  static const struct stp_probe_lock locks[] = {  
  };  
  struct probe_3027_locals * __restrict__ l = & c->probe_locals.probe_3027;  
  (void) l;  
  #if ! STP_PRIVILEGE_CONTAINS (STP_PRIVILEGE, STP_PR_STAPDEV) && \  
      ! STP_PRIVILEGE_CONTAINS (STP_PRIVILEGE, STP_PR_STAPSYS)  
  #error Internal Error: Probe kernel.function("sys_read@fs/read_write.c:389").call generated in --unprivileged mode  
  #endif  
  #if defined __ia64__  
  bspcache(c->unwaddr, c->kregs);  
  #endif  
  if (!stp_lock_probe(locks, ARRAY_SIZE(locks)))  
    return;  
  {  
    (void)   
    ({  
      _stp_print ("hello i am digoal.\n");  
    });  
    (void)   
    ({  
      function_exit (c);  
      if (unlikely(c->last_error)) goto out;  
      (void) 0;  
    });  
  }  
  c->actionremaining -= 2;  
  if (unlikely (c->actionremaining last_error = "MAXACTION exceeded";  
    c->last_stmt = "operator '{' at /usr/share/systemtap/tapset/syscalls2.stp:676:1";  
    goto out;  
  }  
out:  
  stp_unlock_probe(locks, ARRAY_SIZE(locks));  
  _stp_print_flush();  
}  
static struct stap_probe {  
  void (* const ph) (struct context*);  
  #ifdef STP_ALIBI  
  atomic_t alibi;  
  #define STAP_PROBE_INIT_ALIBI() .alibi=ATOMIC_INIT(0),  
  #else  
  #define STAP_PROBE_INIT_ALIBI()  
  #endif  
  #ifdef STP_TIMING  
  Stat timing;  
  #endif  
  #if defined(STP_TIMING) || defined(STP_ALIBI)  
  const char location[14];  
  const char derivation[63];  
  #define STAP_PROBE_INIT_TIMING(L, D) .location=(L), .derivation=(D),  
  #else  
  #define STAP_PROBE_INIT_TIMING(L, D)  
  #endif  
  const char pp[57];  
  #ifdef STP_NEED_PROBE_NAME  
  const char pn[15];  
  #define STAP_PROBE_INIT_NAME(PN) .pn=(PN),  
  #else  
  #define STAP_PROBE_INIT_NAME(PN)  
  #endif  
  #define STAP_PROBE_INIT(PH, PP, PN, L, D) { .ph=(PH), .pp=(PP), STAP_PROBE_INIT_NAME(PN) STAP_PROBE_INIT_ALIBI() STAP_PROBE_INIT_TIMING(L, D) }  
} stap_probes[] = {  
  STAP_PROBE_INIT(&probe_3027, "kernel.function(\"sys_read@fs/read_write.c:389\").call", "syscall.read", ":1:7", " from: kernel.function(\"sys_read\").call from: syscall.read"),  
};  
/* ---- dwarf probes ---- */  
#if ! defined(CONFIG_KPROBES)  
#error "Need CONFIG_KPROBES!"  
#endif  
#ifndef KRETACTIVE  
#define KRETACTIVE (max(15,6*(int)num_possible_cpus()))  
#endif  
#include "kprobes-common.h"  
static int enter_kprobe_probe (struct kprobe *inst, struct pt_regs *regs);  
static int enter_kretprobe_probe (struct kretprobe_instance *inst, struct pt_regs *regs);  
#if defined(STAPCONF_UNREGISTER_KPROBES)  
static void * stap_unreg_kprobes[1];  
#endif  
static struct stap_dwarf_kprobe stap_dwarf_kprobes[1];  
static struct stap_dwarf_probe {  
  const unsigned return_p:1;  
  const unsigned maxactive_p:1;  
  const unsigned optional_p:1;  
  unsigned registered_p:1;  
  const unsigned short maxactive_val;  
  const unsigned short saved_longs;  
  const unsigned short saved_strings;  
  const char module[7];  
  const char section[7];  
  const unsigned long address;  
  struct stap_probe * const probe;  
  struct stap_probe * const entry_probe;  
} stap_dwarf_probes[] = {  
  { .address=(unsigned long)0x181618ULL, .module="kernel", .section="_stext", .probe=(&stap_probes[0]), },  
};  
static int enter_kprobe_probe (struct kprobe *inst, struct pt_regs *regs) {  
  int kprobe_idx = ((uintptr_t)inst-(uintptr_t)stap_dwarf_kprobes)/sizeof(struct stap_dwarf_kprobe);  
  struct stap_dwarf_probe *sdp = &stap_dwarf_probes[((kprobe_idx >= 0 && kprobe_idx probe->alibi));  
  #else  
  struct context* __restrict__ c;  
  #if !INTERRUPTIBLE  
  unsigned long flags;  
  #endif  
  #if defined(STP_TIMING) || defined(STP_OVERLOAD)  
  cycles_t cycles_atstart = get_cycles ();  
  #endif  
  #ifdef STP_TIMING  
  Stat stat = sdp->probe->timing;  
  #endif  
  #if INTERRUPTIBLE  
  preempt_disable ();  
  #else  
  local_irq_save (flags);  
  #endif  
  if (unlikely ((((unsigned long) (& c)) & (THREAD_SIZE-1))  
    busy) != 1) {  
    #if !INTERRUPTIBLE  
    atomic_inc (& skipped_count);  
    #endif  
    #ifdef STP_TIMING  
    atomic_inc (& skipped_count_reentrant);  
    #ifdef DEBUG_REENTRANCY  
    _stp_warn ("Skipped %s due to %s residency on cpu %u\n", sdp->probe->pp, c->probe_point ?: "?", smp_processor_id());  
    #endif  
    #endif  
    atomic_dec (& c->busy);  
    goto probe_epilogue;  
  }  
  c->last_stmt = 0;  
  c->last_error = 0;  
  c->nesting = -1;  
  c->uregs = 0;  
  c->kregs = 0;  
  #if defined __ia64__  
  c->unwaddr = 0;  
  #endif  
  c->probe_point = sdp->probe->pp;  
  #ifdef STP_NEED_PROBE_NAME  
  c->probe_name = sdp->probe->pn;  
  #endif  
  c->probe_type = _STP_PROBE_HANDLER_KPROBE;  
  memset(&c->ips, 0, sizeof(c->ips));  
  c->probe_flags = 0;  
  #ifdef STAP_NEED_REGPARM  
  c->regparm = 0;  
  #endif  
  #if INTERRUPTIBLE  
  c->actionremaining = MAXACTION_INTERRUPTIBLE;  
  #else  
  c->actionremaining = MAXACTION;  
  #endif  
  c->kregs = regs;  
  {  
    unsigned long kprobes_ip = REG_IP(c->kregs);  
    SET_REG_IP(regs, (unsigned long) inst->addr);  
    (*sdp->probe->ph) (c);  
    SET_REG_IP(regs, kprobes_ip);  
  }  
  #if defined(STP_TIMING) || defined(STP_OVERLOAD)  
  {  
    cycles_t cycles_atend = get_cycles ();  
    int32_t cycles_elapsed = ((int32_t)cycles_atend > (int32_t)cycles_atstart)  
      ? ((int32_t)cycles_atend - (int32_t)cycles_atstart)  
      : (~(int32_t)0) - (int32_t)cycles_atstart + (int32_t)cycles_atend + 1;  
    #ifdef STP_TIMING  
    if (likely (stat)) _stp_stat_add(stat, cycles_elapsed);  
    #endif  
    #ifdef STP_OVERLOAD  
    {  
      cycles_t interval = (cycles_atend > c->cycles_base)  
        ? (cycles_atend - c->cycles_base)  
        : (STP_OVERLOAD_INTERVAL + 1);  
      c->cycles_sum += cycles_elapsed;  
      if (interval > STP_OVERLOAD_INTERVAL) {  
        if (c->cycles_sum > STP_OVERLOAD_THRESHOLD) {  
          _stp_error ("probe overhead exceeded threshold");  
          atomic_set (&session_state, STAP_SESSION_ERROR);  
          atomic_inc (&error_count);  
        }  
        c->cycles_base = cycles_atend;  
        c->cycles_sum = 0;  
      }  
    }  
    #endif  
  }  
  #endif  
  c->probe_point = 0;  
  #ifdef STP_NEED_PROBE_NAME  
  c->probe_name = 0;  
  #endif  
  c->probe_type = 0;  
  if (unlikely (c->last_error && c->last_error[0])) {  
    if (c->last_stmt != NULL)  
      _stp_softerror ("%s near %s", c->last_error, c->last_stmt);  
    else  
      _stp_softerror ("%s", c->last_error);  
    atomic_inc (& error_count);  
    if (atomic_read (& error_count) > MAXERRORS) {  
      atomic_set (& session_state, STAP_SESSION_ERROR);  
      _stp_exit ();  
    }  
  }  
  atomic_dec (&c->busy);  
probe_epilogue:  
  if (unlikely (atomic_read (& skipped_count) > MAXSKIPPED)) {  
    if (unlikely (pseudo_atomic_cmpxchg(& session_state, STAP_SESSION_RUNNING, STAP_SESSION_ERROR) == STAP_SESSION_RUNNING))  
    _stp_error ("Skipped too many probes, check MAXSKIPPED or try again with stap -t for more details.");  
  }  
  #if INTERRUPTIBLE  
  preempt_enable_no_resched ();  
  #else  
  local_irq_restore (flags);  
  #endif  
  #endif // STP_ALIBI  
  return 0;  
}  
static int enter_kretprobe_common (struct kretprobe_instance *inst, struct pt_regs *regs, int entry) {  
  struct kretprobe *krp = inst->rp;  
  int kprobe_idx = ((uintptr_t)krp-(uintptr_t)stap_dwarf_kprobes)/sizeof(struct stap_dwarf_kprobe);  
  struct stap_dwarf_probe *sdp = &stap_dwarf_probes[((kprobe_idx >= 0 && kprobe_idx entry_probe : sdp->probe;  
  if (sp) {  
    #ifdef STP_ALIBI  
    atomic_inc(&(sp->alibi));  
    #else  
    struct context* __restrict__ c;  
    #if !INTERRUPTIBLE  
    unsigned long flags;  
    #endif  
    #if defined(STP_TIMING) || defined(STP_OVERLOAD)  
    cycles_t cycles_atstart = get_cycles ();  
    #endif  
    #ifdef STP_TIMING  
    Stat stat = sp->timing;  
    #endif  
    #if INTERRUPTIBLE  
    preempt_disable ();  
    #else  
    local_irq_save (flags);  
    #endif  
    if (unlikely ((((unsigned long) (& c)) & (THREAD_SIZE-1))  
      busy) != 1) {  
      #if !INTERRUPTIBLE  
      atomic_inc (& skipped_count);  
      #endif  
      #ifdef STP_TIMING  
      atomic_inc (& skipped_count_reentrant);  
      #ifdef DEBUG_REENTRANCY  
      _stp_warn ("Skipped %s due to %s residency on cpu %u\n", sp->pp, c->probe_point ?: "?", smp_processor_id());  
      #endif  
      #endif  