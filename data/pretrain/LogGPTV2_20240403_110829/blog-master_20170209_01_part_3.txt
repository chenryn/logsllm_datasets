显然一个产品可能无法满足这么多的需求。       
就好比数据库就分了关系数据库，NOSQL，OLTP场景，OLAP场景一样。   也是因为一个产品无法满足所有的业务需求。        
在企业中通常是借助数据冗余来解决各类场景的需求。         
那么如何才能够更好的分享数据，保证数据的一致性，提高分享的实时性呢？       
10万级别左右的机器，PostgreSQL 的数据吞吐量可以达到100万条/s以上，同时数据库本身具备了严格的可靠性和一致性保证。    
PostgreSQL为分享数据提供了插槽的概念，每个插槽对应一个目标端，支持断点续传，支持多个目标端。用于流式的分享数据是非常好的选择。    
![pic](../201612/20161205_02_pic_003.png)    
[《实时数据交换平台 - BottledWater-pg with confluent》](../201612/20161205_02.md)      
## 15 分词搜索、模糊搜索、相似度搜索 - 电商、公安、传统企业 等业务场景    
看刑侦剧经常有看到人物拼图，然后到图库搜索的，以前可能靠的是人肉，使用PG，可以靠数据库的图形近似度搜索功能。      
[《弱水三千,只取一瓢,当图像搜索遇见PostgreSQL (Haar wavelet)》](https://yq.aliyun.com/articles/58246)        
![pic](../201609/20160929_02/0043.jpg)    
而对于文本搜索，大家一定会想到分词，比如搜索引擎、淘宝的商品内容搜索、文章的关键字搜索等等。       
PostgreSQL内置了分词引擎，可以很好的满足这类搜索的需求。    
[《聊一聊双十一背后的技术 - 分词和搜索》](../201611/20161115_01.md)      
[《PostgreSQL 全文检索加速 快到没有朋友 - RUM索引接口(潘多拉魔盒)》](../201610/20161019_01.md)      
[《PostgreSQL 如何高效解决 按任意字段分词检索的问题 - case 1》](../201607/20160725_05.md)      
但是千万不要以为分词可以搞定一切需求，比如这样的需求就搞不定。       
hello world打成了hello word或者hello w0rld，你要让数据库匹配出来，怎么搞？        
又或者你的业务需要写正则进行匹配，怎么搞？比如一些域名的查询，```www.firefoxcn.org``` 可能你只想输入其中的一个部分来搜索，如果firefox可以匹配。       
甚至更变态的 fi[a-z]{1}e.*?\.?? ，这样的查询。       
数据量小，并发小时，这种查询是可以忍受全表扫描和CPU处理过滤的。      
但是想想一下，你是一个日请求过亿的业务，或者数据量亿级别的，全表扫描和CPU的开销会让你疯掉的。       
PostgreSQL完美的解决了这类变态的需求。    
1\. 使用PostgreSQL regexp库，将正则转换为NFA样式（图形化词组）。       
2\. 将NFA样式再进行转换，转换为扩展的图形样式(trigrams)，包括拆分后的查询词组与NOT词组。        
3\. 简化，过滤不必要的trigrams。       
4\. 打包为TrgmPackedGraph结构，支持GIN,GIST索引的检索。     
[《聊一聊双十一背后的技术 - 毫秒分词算啥, 试试正则和相似度》](../201611/20161118_01.md)      
[《中文模糊查询性能优化 by PostgreSQL trgm》](../201605/20160506_02.md)      
![pic](../201603/20160302_01_pic_001.jpeg)    
[《PostgreSQL 百亿数据 秒级响应 正则及模糊查询》](../201603/20160302_01.md)      
[《PostgreSQL 1000亿数据量 正则匹配 速度与激情》](../201603/20160307_01.md)      
还有一种场景，比如口音纠正、口音相似度搜索。    
## 16 文本分析、人物画像 - 电商、公安、传统企业、广告商 等业务场景    
在日常的生活中，我们可能会经常需要一些像相近、相仿、距离接近、性格接近等等类似这样的需求，对数据进行筛选。       
在PostgreSQL中，这些场景都支持索引排序和检索。    
比如收集了人群的各种喜好的数据，通过对关联数据的聚类分析，或者按喜好的重叠度进行排序，找出目标人群。      
这里就涉及到文本的近似度分析，PostgreSQL的文本分析功能可以很好的支持此类场景。    
![pic](20170209_01_pic_005.jpg)    
[《PostgreSQL 文本数据分析实践之 - 相似度分析》](../201608/20160817_01.md)      
## 17 高并发更新少量记录 - 电商、票务系统 等业务场景    
秒杀在商品交易中是一个永恒的话题，从双十一，到一票难求，比的仅仅是手快吗？       
其实对于交易平台来说，面对的不仅仅是人肉，还有很多脚本，外挂自动化的抢购系统，压力可想而知。       
秒杀的优化手段很多，就拿数据库来说，有用排队机制的，有用异步消息的，有用交易合并的。       
今天我要给大家介绍一种更极端的秒杀应对方法，裸秒。       
目前可能只有PostgreSQL可以做到裸秒，也即是说，来吧，一起上。     
PostgreSQL提供了一种ad lock，可以让用户尽情的释放激情，以一台32核64线程的机器为例，每秒可以获取、探测约130万次的ad lock。        
试想一下，对单条记录的秒杀操作，达到了单机100万/s的处理能力后，秒杀算什么？100台机器就能处理1亿/s的秒杀请求。    
![pic](../201611/20161117_01_pic_001.png)    
[《聊一聊双十一背后的技术 - 不一样的秒杀技术, 裸秒》](../201611/20161117_01.md)      
![pic](../201609/20160929_02/0053.jpg)    
[《PostgreSQL 使用advisory lock或skip locked消除行锁冲突, 提高几十倍并发更新效率》](../201610/20161018_01.md)     
## 18 实时用户画像 - 电商、实时广告、实时营销、金融 等业务场景    
用户画像在市场营销的应用重建中非常常见，已经不是什么新鲜的东西，比较流行的解决方案是给用户贴标签，根据标签的组合，圈出需要的用户。      
通常画像系统会用到宽表，以及分布式的系统。      
宽表的作用是存储标签，例如每列代表一个标签，但是通常数据库到2000个列基本就是极限了，上万TAG的话，只能使用多表JOIN来实现，效率较差。    
另一方面，使用宽表(甚至列存储)，标签的筛选性能也比较差（无法达到实时级别）。    
以PostgreSQL数据库为基础，给大家讲解一下更加另类的设计思路，以BIT来存储用户，每行一个TAG的方式。     
10万亿级TAG/users，毫秒级圈人。    
[《基于 阿里云 RDS PostgreSQL 打造实时用户画像推荐系统》](../201610/20161021_01.md)      
## 19 动态规划 - 物流配送、打车软件、导航软件、出行软件、高速、高铁 等业务场景    
每年双十一的交易额都创新高，今年也不例外，双十一几乎成了各种IT系统的大考，物流也不例外。       
每次双十一快递几乎都被爆仓，但是随着技术的发展，今年，听说双十一刚过，小伙伴们的包裹都快收到了。      
今天，来给大家分享一下物流与背后的数据库技术，当然我讲的还是PostgreSQL, Greenplum, PostGIS一类，大伙了解我的。       
物流行业是被电子商务催生的产业之一。      
快件的配送和揽件的调度算法是物流行业一个非常重要的课题，直接关系到配送或揽件的时效，以及物流公司的运作成本。        
好的算法，可以提高时效，降低成本，甚至可以更好的调动社会资源，就像滴滴打车一样，也许能全民参与哦。        
以后也许上班路途还能顺路提供快递服务呢。        
以物流行业为例，PostgreSQL与Greenplum为物流行业应用提供了包括机器学习、路径规划、地理位置信息存储和处理等基础服务。    
![pic](../201611/20161114_01_pic_012.png)    
![pic](../201609/20160929_02/0042.jpg)    
[《聊一聊双十一背后的技术 - 物流、动态路径规划》](../201611/20161114_01.md)      
## 20 流式同步多副本、极致数据可靠性 - 金融、传统企业、互联网 等业务场景    
传统的金融行业高度依赖共享存储来解决数据库的高可用，数据0丢失以及异地容灾的场景。      
共享存储的解决方案价格昂贵，对厂商的依赖较大。    
PostgreSQL基于同步流复制的 任意副本 解决方案，在解决0丢失，高可用以及容灾的问题的同时，还可以提供只读的功能。相比传统的存储解决方案，优势更加明显。      
![pic](../201610/20161006_02_pic_001.png)    
[《PostgreSQL 金融行业高可用和容灾解决方案》](../201512/20151224_01.md)      
[《PostgreSQL 9.6 同步多副本 与 remote_apply事务同步级别》](../201610/20161006_02.md)      
[《2017金秋将要发布的PostgreSQL 10.0已装备了哪些核武器？》](../201701/20170101_01.md)    
## 21 块级瘦索引 - 物联网、金融、日志、行为轨迹类数据 等业务场景    
在物联网、金融、日志类型场景中，数据持续不断的产生，对于堆存储来说，有线性相关的特点。    
例如，时间字段往往和物理存储的顺序具有线性相关性。    
例如，有一些自增字段，也和堆存储的物理顺序线性相关。    
对与物理存储线性相关的字段（时间，自增字段），PostgreSQL提供了一种BRIN块级范围索引，索引中存储了对应数据块中的字段统计信息（例如最大值，最小值，平均值，记录数、SUM，空值个数等）    
这种索引很小，因为索引的粒度是连续的块，而不是每条记录。    
通常比BTREE索引小几百倍。    
如果字段的线性相关性很好，进行范围查询或者精确检索时，效率非常高。    
对于统计查询，也可以使用BRIN索引，提高分析统计的效率。    
![pic](../201604/20160414_01_pic_002.png)    
![pic](../201604/20160414_01_pic_003.png)    
![pic](../201604/20160414_01_pic_004.png)    
[《PostgreSQL 物联网黑科技 - 瘦身几百倍的索引(BRIN index)》](../201604/20160414_01.md)      
[《PostgreSQL 9.5 new feature - BRIN (block range index) index》](../201504/20150419_01.md)      
[《PostgreSQL 聚集存储 与 BRIN索引 - 高并发行为、轨迹类大吞吐数据查询场景解说》](../201702/20170219_01.md)    
## 22 持续数据写入，高效、0丢失 - 运营商网关、物联网、IT系统FEED 等业务场景    
在运营商网关、物联网的工业数据采集和处理，IT系统的FEED等业务场景中，数据产生的量非常庞大，这些数据要在保证可靠性的情况下，快速的入库。    
对于PostgreSQL来说，使用中端x86服务器(通常在10万以内，32核，SSD+SATA结合)上的数据插入速度（目标表包含一个brin索引），实际测试可以达到每天上百TB的写入。        
从而以较高的性价比，满足此类业务场景的需求。    
[《PostgreSQL 如何潇洒的处理每天上百TB的数据增量》](../201603/20160320_01.md)      
## 23 时序数据有损压缩 - 时序、物联网、FEED数据、金融 等业务场景    
在物联网、金融、FEED等场景中，往往有大批量的指标数据产生并进入数据库，通常包含 时间、值 两个字段。    
这些数据由于量非常庞大，而且就像音频一样，实际上是可以对其进行有损的压缩存储的。    
最为流行的是旋转门的压缩算法，在PostgreSQL中可以使用UDF，方便的实现这个功能。    
从而实现流式\时序数据的有损压缩。    
![pic](../201609/20160929_02/0059.jpg)    
[《旋转门数据压缩算法在PostgreSQL中的实现 - 流式压缩在物联网、监控、传感器等场景的应用》](../201608/20160813_01.md)      
## 24 会话级资源隔离 - 多租户、云、混合业务资源控制 等业务场景    
在很多场景中，用户希望可以控制每个连接（会话）的资源使用情况，例如CPU\IOPS\MEMORY等。      
PostgreSQL是进程结构，可以通过cgroup很好的实现这个需求，不需要对数据库内核进行改造。    
另一方面，基于PostgreSQL的产品GPDB，则是在数据库的内核层面实施的控制。    
![pic](../201607/20160727_01_pic_005.png)    