this threat is minimal, and could be addressed via a variety
of techniques. We believe that formal veriﬁcation should
be possible since the VM’s code is typically quite small.
(Strata’s fully-featured IA32 implementation is only 18K
lines of code.) Much of the code is related to the decoder
for the machine’s ISA, which might be automatically veriﬁed
or generated from an ISA description. Even without formal
veriﬁcation, bugs within a VM can largely be addressed
via iterative reﬁnement, code-review, static analysis, and
compiler-based protection techniques. The last
item has
signiﬁcant potential for protecting the VM in this case. If
randomization (stack, heap, instruction-location, etc.) could
be used on the VM at the deployed location, most attacks
directly on the VM could be mitigated.
The more signiﬁcant threat to the VM is that a vulner-
ability in the application allows the application’s code to
overwrite some portion of the VM, or to have the VM start
interpreting some portion of itself. Since a process-level VM
typically resides in the process’ address space, we need to
guard against these threats directly.
We do so by augmenting the VM to verify any instruction
before it
is fetched for analysis. The VM ensures that
the instruction originates from allowable portions of the
application text (for pinned instructions) or an ILR rewrite
rule. The VM is prohibited from translating itself or its
generated code, and consequently the VM’s code cannot
be used for arc-injection or ROP attacks. Our prototype
implementation includes these protections.
To prevent a compromised application from overwriting
the VM’s code or data, we use standard hardware memory
protection mechanisms. When executing the untrusted ap-
plication code, the VM turns off read, write, and execute
permission on memory used by the VM,
leaving only
execute (but not write) permission on the code cache. The
VM also watches for attempts by the application to change
these permissions. Previous work shows this technique to be
effective and cost very little [28].
Together, we believe that good coding practices, veriﬁca-
tion, randomization, and actively protecting the VM from a
compromised application can result in a safe VM.
B. Entropy Exhausting Attacks
The entropy of the ILR technique can be quite high. Since
the ILR technique separates data and instruction memory,
randomized instructions can be located anywhere in memory,
even at
the same addresses as program data, VM code
or data. Many operating systems reserve some pages of
memory speciﬁcally for code to interface with the operating
system, so those pages could not be used for randomized ad-
dresses. Further, any unrandomized instructions restrict the
entropy of the remaining instructions. Since there are very
few unmoved instructions, and almost all other addresses
are available for randomization, we believe that it would be
easy to produce a system that has at least 31-bits of entropy
on a 32-bit address system and at least 63-bits of entropy on
a 64-bit system. Thus, randomly attempting to guess gadget
addresses is completely infeasible and ILR can evade attacks
which attempt to reduce the entropy of a system.
C. Information Leakage Attacks
A more likely attack scenario is that an attacker is able
to leak information about randomized addresses. Fortu-
nately, the memory-page protection techniques mentioned
in Section V-A prevent leaking of information about most
randomized addresses. The only randomized addresses that
might be leaked are those that potentially end up in the appli-
cation’s visible data. For ILR, that is the randomized return
addresses that might be stored on the application’s stack.
For a complete ILR+ implementation, it also includes any
randomized addresses that are written into the application’s
exception handling tables.
In theory, all of these addresses might be leaked to an
attacker. However, revisiting Figure 9, we see that on average
only 5% of addresses in the total program could be known by
the user. In practice, only a few randomized return addresses
581
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:49:42 UTC from IEEE Xplore.  Restrictions apply. 
lea
jmp
eax, [eax+eax*8+0x80b4545]
eax
Figure 12. An example of a calculated branch target from gcc’s library
for arbitrary precision arithmetic.
are available in the application at any instance, and most
return addresses could not actually be leaked. If it were
possible for the entire exception handling table to be leaked,
the number of available addresses would likely be very close
to the ILR results, and no ROP attacks are available against
ILR in our benchmarks, as seen in Section IV-E.
Furthermore, since our ILR technique is designed to be
applied to arbitrary executables, re-randomization could oc-
cur regularly with little overhead. Regular re-randomization
of high-entropy systems has been shown to be effective in
the context of information leakage [29].
Thus, information leakage is not a problem for ILR.
D. False Detections
A false detection occurs when the program performs
an operation that is detected as illegal, when there is no
attack underway. On our benchmark suite, we found that
there were no false detections with ILR. Since our im-
plementation of ILR+ is incomplete, we did observe two
false detections. Both 453.povray and 471.omnetpp
resulted in incorrect output (from faulting the program) when
attempting to throw an exception. A complete implemen-
tation of ILR+ would not demonstrate this problem. We
believe this indicates that false detections would be rare
in real programs. Nonetheless, we discuss some possible
mechanisms by which false detections might occur.
False detections might occur if a program calculates an
indirect branch target, instead of simply storing the target in
data memory as is most common. We found one example
of this type of code in gcc’s library for doing arbitrary
precision arithmetic. The example, shown in Figure 12 and
originally written in assembly, is used to dispatch into a
switch-style table of code blocks. Each block in the table
is 9 bytes long. The assembly multiplies register eax by 9
(eax+eax*8), then adds the the base of the ﬁrst code block
before ﬁnally jumping to that address. A similar construct
might be generated by a compiler, but we know of no
compilers which generate this type of code for a switch
statement. Other constructs exist that might hide code ad-
dresses. For example, a function pointer might be calculated
for some reason, such as for obfuscation techniques.
A more common compiler construct that might calculate
an indirect branch target is position independent code (PIC).
In PIC mode, the compiler will often generate a code address
by emitting a sequence of instructions that adds the current
PC and a constant offset, knowing that the desired code
address is a ﬁxed distance from the current PC. PIC code is
not standard due to its performance overhead.
In most of these cases, we believe that a more advanced
indirect branch analysis would solve the problem. For exam-
ple, the code in Figure 12 is preﬁxed by code to verify that
register eax is in proper bounds. A simple range analysis on
the values that can reach the jmp instruction would reveal
the possible indirect branch targets.
Furthermore, our experience indicates that the ILR tech-
nique can easily print the address of an indirect branch
target if a false detection is encountered. A proﬁle-based
or feedback-based mechanism that incorporates newly dis-
covered IBTs would be easy to implement to reduce false
detections over time if the IBT can be detected as derived
only from safe sources.
E. Shared Libraries
Modern computer systems are built using libraries that
are loaded on demand, and possibly shared among many
processes. Linux uses the .so (Shared Object) format, while
Windows uses the .dll (Dynamically Linked Library)
model. Our system is capable of processing and randomizing
a program that uses dynamic linking. Generally, analysis
of these types of programs is easier for our system. Since
the code is divided into libraries, we know that if a library
contains a constant, the constant can only be an IBT in the
library being considered, not to other libraries. Thus, this
separation dramatically reduces the number of potential IBTs
for a library. Furthermore, externally visible functions and
symbols need to be referenced by a handle that is given
in the library’s headers. Extracting these types of indirect
branch targets is trivial.
While our prototype can process and effectively random-
ize programs that require shared libraries, it does not actually
randomize the libraries. Both Linux and Windows support
some form of ASLR which provides coarse-granularity
randomization of shared libraries. We believe our technique
could easily be extended to include full randomization of
shared libraries, but it is not clear that doing so would
always be the best solution. When feasible, it seems better
to provide randomization within the library itself. On Linux,
this randomization could be accomplished by using a ran-
domizing compiler to generate a per-system version of the
libraries. When library source code is not available, such
as on Windows-based systems, ILR-based randomization
would be important. To achieve this, ILR-rewrite rules for
a library would have to be loaded and symbolic addresses
resolved whenever a new library entered the system. Such
a mechanism could be easily included in a dynamic loader,
or by having the ILR VM watch for library loading events.
F. Self-modifying Code
Our ILR implementation does not currently support self-
modiﬁng, dynamically generated, or just-in-time compiled
(JITted) code because our underlying VM does not sup-
port such constructs. However, the ILR mechanism itself
582
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:49:42 UTC from IEEE Xplore.  Restrictions apply. 
should operate properly with dynamically generated and
JITted code, which is signiﬁcantly more common than self-
modiﬁng code. ILR would not randomize the generated
code, but we believe that to be an easy task for the JITter. A
security-minded JITter would perform this simple operation.
VI. RELATED WORK
A. ROP Defenses
The original authors of ROP have described ROP’s salient
feature as “Turing completeness without code injection” [9].
ROP invalidates the assumption that attack payloads are in-
trinsically external by nature as ROP re-uses code fragments
already present in a target program. Defensive techniques
such as various forms of instruction-set randomization that
target code injection attacks directly are completely circum-
vented by arc-injection attacks in general [28, 30, 31], of
which ROP, return-to-libc [32, 33], and partial overwriting
attacks of return addresses [10] are special cases. W⊕X is
also circumvented as it implicitly assumes that external code
will be executed from data pages [5].
Since the original seminal work on ROP [2], several
defensive techniques have been proposed. Early defenses
targeted what would emerge to be non-essential features of
ROP attacks. For example, DROP [14] instruments binaries
searching for short consecutive sequences of instructions
ending in a return instruction. Li et al. and Onarlioglu et al.
avoid gadget-like instruction sequences altogether when gen-
erating code [34, 35]. Kil et al. permute function locations to
randomize gadget locations, but require additional compile-
time information [36]. ROPDefender [15] and TRUSS [37]
look for mismatched calls and returns essentially using a
shadow stack.
Checkoway et al. showed that the use of the return instruc-
tion is not a necessary condition in building ROP gadgets,
thereby bypassing such ad-hoc defenses [9]. The balance
against ad hoc defenses is further tilted by recent works that
have automated the process of gadget discovery [20, 38, 39]
and ROP exploit compilation and hardening [25].
TRUSS [37], ROPDefender
[15], DROP [14], and
TaintCheck [40] use software dynamic translation frame-
works for instrumenting code and implementing their respec-
tive defenses. TaintCheck uses dynamic taint analysis and
provides a comprehensive approach to thwarting ROP at-
tacks by detecting attempts at control-ﬂow hijacking, though
it suffers from high overhead (over 20X). Performance
overhead for ROPDefender is approximately 2X overhead on
the SPEC2006 benchmarks, while preliminary performances
measurements for DROP range from 1.9X to 21X. While
not directly comparable, ILR achieves average performance
overhead of only 13-16%, which makes it practical for
deployment.
B. Defenses based on randomization
In contrast
to approaches that
look for speciﬁc ROP
patterns, ILR provides a comprehensive defense based on
high-entropy diversiﬁcation to thwart attacks. ILR provides
31 bits of entropy (out of a maximum of 32 for our
experimental prototype) which makes derandomizing attacks
impractical. ASLR on a 32-bit architecture only provides 16
bits of entropy and is susceptible to brute-force attacks [7].
Even on 64-bit architectures, there would be two potential
problems. The ﬁrst is that ASLR is not applied universally
throughout the address space. Even when using dynamically-
linked libraries, it is common for the main program text to
start at a known ﬁxed location. Red Hat developed Posi-
tion Independent Executable to remedy this situation [41].
However, PIE requires recompilation. The second problem is
that ASLR and other coarse-grained technology such as PIE
do not perform intra-library randomization. Any information
leaked as to the location of one function, or even one
address, could be used to infer the complete layout of a
library. Roglia et al. demonstrated a single-shot return-to-
libc attack that used ROP gadgets to leak information about
the base address of libc, and bootstrapped this information
into all other libc functions [8]. Their proposed remedy of
encrypting the Global Offset Table was speciﬁc to their
attacks and leaves open the possibility of other leakage
attacks.
Bhatkar et al. use source-to-source transformation tech-
niques to produce self-randomizing programs (SRP) to
combat memory error exploits [42]. Unlike other compiler-
based randomization techniques [43], SRP produces a single
program image, which makes it more practical for deploy-
ment. SRP randomizes code at the granularity of individual
functions and therefore retains a larger attack surface than
the ILR approach of randomizing at the instruction level.
Instruction Set Randomization (ISR) helps defeat code-
injection attacks, but provides no protection against arc-
injection and ROP attacks [28].
C. Control Flow Integrity
Control ﬂow integrity (CFI) is designed to ensure the con-
trol ﬂow of a program is not hijacked [44]. CFI relies on the
Vulcan instrumentation system. The Vulcan system allows
instruction discovery, static analysis, and binary rewriting.
Figure 13 shows an example program. In the ﬁgure,
CFI enforces that the return instruction (in function log)
can only jump to the instruction after a call to the log
function. In this case, this policy allows an arc-injection
attack if the log function is vulnerable. An attacker might
be able to overwrite the return address to erroneously jump
to L2, thereby granting additional access. Even the best static
analysis cannot mitigate these threats using CFI.
Further, a partial overwrite attack might defeat ASLR in
this example, since the distance between the two return sites
583
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:49:42 UTC from IEEE Xplore.  Restrictions apply. 
L1:
L2:
L3:
log:
call log
cmp [isRoot], #1
jeq L3
...
call log
call grantAccess
...
...
ret
Figure 13. Example demonstrating CFI’s weakness. The return instruction
jump either L1 and L2, possibly allowing additional access if the log
function is vulnerable.
is ﬁxed. Since ILR randomizes this distance, ILR can defeat
partial-overwrite attacks.
VII. CONCLUSIONS
This paper presents instruction location randomization
(ILR), a high-entropy technique for relocating instructions
within an arbitrary binary. ILR is shown to effectively hide
99.96% of ROP gadgets from an attacker, a 3.5 order of
magnitude reduction in attack surface.
This work describes the general technique, as well as
evaluates two versions of an ILR prototype. It further
discusses the security implications of ILR. We ﬁnd that ILR
can be applied to a wide range of binary programs compiled
from C, Fortran, and C++. Performance overhead is shown
to be as low as 13% across the 29 SPEC CPU2006 industry-
standard benchmarks [16].
This work surpasses state-of-the-art techniques for defeat-
ing attacks in a variety of ways. In particular, the technique:
• can be easily and efﬁciently applied to binary programs,
• provides up to 31 bits of entropy for instruction loca-
tions on 32-bit systems,
• can regularly re-randomize a program to thwart
entropy-exhausting or information-leakage attacks,
• provides low execution overhead,
• randomizes statically and dynamically linked programs,
and
• defeats attacks against large, real-world programs in-
cluding the Linux PDF viewer, xpdf, and Adobe’s
PDF viewer, acroread.
Taken together, these results demonstrate that ILR can be
used in a wide variety of real-world situations to provide
strong protection against attacks.
ACKNOWLEDGMENT
This research is supported by National Science Founda-
tion (NSF) grant CNS-0716446, the Army Research Of-
ﬁce (ARO) grant W911-10-0131, the Air Force Research
Laboratory (AFRL) contract FA8650-10-C-7025, and DoD
AFOSR MURI grant FA9550-07-1-0532. The views and
conclusions contained herein are those of the authors and
should not be interpreted as necessarily representing the of-
ﬁcial policies or endorsements, either expressed or implied,
of the NSF, AFRL, ARO, DoD, or the U.S. Government.
584
REFERENCES
[1] J. Pincus and B. Baker, “Beyond stack smashing: Recent
advances in exploiting buffer overruns,” IEEE Security &
Privacy, vol. 2, no. 4, pp. 20–27, Jul/Aug 2004.
[2] H. Shacham, “The geometry of innocent ﬂesh on the bone:
Return-into-libc without function calls (on the x86),” in
Proceedings of the 14th ACM Conference on Computer and
Communications Security. ACM, 2007, pp. 552–561.
[3] E. Buchanan, R. Roemer, H. Shacham, and S. Savage, “When
good instructions go bad: Generalizing return-oriented pro-
gramming to RISC,” in Proceedings of the 15th ACM Con-
ference on Computer and Communications Security. ACM,
2008, pp. 27–38.
[4] D. Dai Zovi, “Practical
SOURCE Boston, 2010.
return-oriented programming,”
[5] The PAX Team, http://pax.grsecurity.net.
[6] M. Howard and M. Thomlinson, “Windows vista ISV secu-
rity,” Microsoft Corporation, April, vol. 6, 2007.
[7] H. Shacham, M. Page, B. Pfaff, E. Goh, N. Modadugu, and
D. Boneh, “On the effectiveness of address-space random-
ization,” in Proceedings of the 11th ACM Conference on
Computer and Communications Security. ACM, 2004, pp.
298–307.
[8] G. Roglia, L. Martignoni, R. Paleari, and D. Bruschi, “Sur-
gically returning to randomized lib (c),” in 2009 Annual
Computer Security Applications Conference.
IEEE, 2009,
pp. 60–69.
[9] S. Checkoway, L. Davi, A. Dmitrienko, A. Sadeghi,
H. Shacham, and M. Winandy, “Return-oriented program-
ming without returns,” in Proceedings of the 17th ACM Con-
ference on Computer and Communications Security. ACM,
2010, pp. 559–572.
[10] T. Durden, “Bypassing PaX ASLR protection,” Phrack
Magazine, vol. 0x0b, no. 0x3b, 2002. [Online]. Available:
http://www.phrack.org/issues.html?issue=59&id=9
[11] K. Scott, N. Kumar, S. Velusamy, B. R. Childers, J. W.
Davidson, and M. L. Soffa, “Retargetable and reconﬁgurable
software dynamic translation,” in International Symposium
on Code Generation and Optimization. San Francisco, CA:
IEEE Computer Society, Mar. 2003, pp. 36–47.
[12] V. Bala, E. Duesterwald, and S. Banerjia, “Dynamo: A
transparent dynamic optimization system,” in SIGPLAN ’00
Conference on Programming Language Design and Imple-
mentation, 2000, pp. 1–12.
[13] M. Payer and T. Gross, “Fine-grained user-space security
through virtualization,” in Proceedings of the 7th ACM SIG-
PLAN/SIGOPS International Conference on Virtual Execu-
tion Environments. ACM, 2011, pp. 157–168.
[14] P. Chen, H. Xiao, X. Shen, X. Yin, B. Mao, and L. Xie,
“DROP: Detecting return-oriented programming malicious
code,” Information Systems Security, pp. 163–177, 2009.
[15] L. Davi, A. Sadeghi, and M. Winandy, “ROPdefender: A
detection tool to defend against return-oriented programming
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:49:42 UTC from IEEE Xplore.  Restrictions apply. 
attacks,” in Proceedings of the 6th ACM Symposium on In-
formation, Computer and Communications Security. ACM,
2011, pp. 40–51.
[30] E. G. Barrantes, D. H. Ackley, S. Forrest, and D. Stefanovic,
“Randomized instruction set emulation,” ACM Transactions
on Information System Security., vol. 8, no. 1, pp. 3–40, 2005.
[16] Standard Performance Evaluation Corporation,
“SPEC
CPU2006 Benchmarks,” http://www.spec.org/osg/cpu2006.
[17] (2011, November) Hex-rays website. [Online]. Available:
http://www.hex-rays.com/products/ida/index.shtml
[18] C.-K. Luk, R. Cohn, R. Muth, H. Patil, A. Klauser,
G. Lowney, S. Wallace, V. J. Reddi, and K. Hazelwood, “Pin:
Building customized program analysis tools with dynamic
instrumentation,” in PLDI ’05: Proceedings of the 2005 ACM
SIGPLAN Conference on Programming Language Design
and Implementation. New York, NY, USA: ACM Press,
2005, pp. 190–200.
[19] M. Voss and R. Eigenmann, “A framework for remote dy-
namic program optimization,” in Proceedings of the ACM
Workshop on Dynamic Optimization Dynamo ’00, 2000.
[20] “Shell storm website,” http://www.shell-sorm.org/project/
ROPgadget/.
[21] (2008) Libtiff
remote buffer overﬂow
vulnerability. [Online]. Available: http://www.securityfocus.
com/bid/19283
tifffetchshortpair
[22] A. Kapoor, “An approach towards disassembly of mali-
cious binary executables,” Ph.D. dissertation, University of
Louisiana, 2004.
[31] G. S. Kc, A. D. Keromytis, and V. Prevelakis, “Countering
code-injection attacks with instruction-set randomization,”
in CCS ’03: Proceedings of the 10th ACM Conference on
Computer and Communications Security. New York, NY,
USA: ACM Press, 2003, pp. 272–280.
[32] S. Designer, ““return-to-libc” attack,” Bugtraq, Aug, 1997.
[33] Nergal, “The advanced return-into-lib(c) exploits (PaX case
study).” Phrack Magazine, 58(4), December 2001.
[34] J. Li, Z. Wang, X. Jiang, M. Grace, and S. Bahram, “De-
feating return-oriented rootkits with “return-less” kernels,” in
Proceedings of the 5th European Conference on Computer
Systems, ser. EuroSys ’10. New York, NY, USA: ACM,
2010, pp. 195–208.
[35] K. Onarlioglu, L. Bilge, A. Lanzi, D. Balzarotti, and E. Kirda,
“G-Free: defeating return-oriented programming through
gadget-less binaries,” in Proceedings of
the 26th Annual
Computer Security Applications Conference. ACM, 2010,
pp. 49–58.
[36] C. Kil, J. Jun, C. Bookholt, J. Xu, and P. Ning, “Address
space layout permutation (ASLP): Towards ﬁne-grained ran-
domization of commodity software,” in Computer Security
Applications Conference, 2006. ACSAC’06. 22nd Annual.
Ieee, 2006, pp. 339–348.
[23] C. Kruegel, W. Robertson, F. Valeur, and G. Vigna, “Static
disassembly of obfuscated binaries,” in Proceedings of the
13th USENIX Security Symposium, 2004, pp. 255–270.
[37] S. Sinnadurai, Q. Zhao, and W. fai Wong, “Transparent
runtime shadow stack: Protection against malicious return
address modiﬁcations,” 2008.
[24] B. Schwarz, S. Debray, and G. Andrews, “Disassembly of
executable code revisited,” in Proceedings of the 9th Working
Conference on Reverse Engineering. IEEE, 2002, pp. 45–54.
[38] T. Dullien and T. Kornau, “A framework for automated
architecture-independent gadget search,” in 4th USENIX
Workshop on Offensive Technologies, 2010.
[25] E. J. Schwartz, T. Avgerinos, and D. Brumley, “Q: Exploit
hardening made easy,” in Proceedings of the USENIX Secu-
rity Symposium, 2011.
[26] J. Hiser, D. Williams, W. Hu, J. Davidson, J. Mars, and
B. Childers, “Evaluating indirect branch handling mecha-
nisms in software dynamic translation systems,” in Proceed-
ings of the International Symposium on Code Generation and
Optimization.
IEEE Computer Society, 2007, pp. 61–73.
[27] A. Guha, K. Hazelwood, and M. Soffa, “Reducing exit stub
memory consumption in code caches,” High Performance
Embedded Architectures and Compilers, pp. 87–101, 2007.
[28] W. Hu, J. Hiser, D. Williams, A. Filipi, J. Davidson,
D. Evans, J. Knight, A. Nguyen-Tuong, and J. Rowanhill,
“Secure and practical defense against code-injection attacks
using software dynamic translation,” in Proceedings of the
2nd International Conference on Virtual Execution Environ-
ments. ACM, 2006, pp. 2–12.
[29] A. Nguyen-Tuong, A. Wang, J. Hiser, J. Knight, and J. David-
son, “On the effectiveness of the metamorphic shield,” in
Proceedings of the Fourth European Conference on Software
Architecture: Companion Volume. ACM, 2010, pp. 170–174.
[39] R. G. Roemer, “Finding the bad in good code: Automated
return-oriented programming exploit discovery,” 2009.
[40] D. S. James Newsome, “Dynamic taint analysis for automatic
detection, analysis, and signature generation of exploits on
commodity software,” in Proceedings of the Network and
Distributed System Security Symposium, 2005.
[41] A. van de Ven, “New security enhancements in red hat
enterprise linux v.3, update 3.” Red Hat, Inc., 2004.
[42] S. Bhatkar, R. Sekar, and D. C. DuVarney, “Efﬁcient tech-
niques for comprehensive protection from memory exploits,”
in Proceedings of the 14th Conference on USENIX Security
Symposium. USENIX Association, 2005.
[43] T. Jackson, B. Salamat, A. Homescu, K. Manivannan,
G. Warner, A. Gal, S. Brunthaler, C. Wimmer, and M. Franz,
“Compiler-generated software diversity,” 2011.
[44] M. Abadi, M. Budiu, ´U. Erlingsson, and J. Ligatti, “Control-
ﬂow integrity,” in Proceedings of the 12th ACM Conference
on Computer and Communications Security. ACM, 2005,
pp. 340–353.
585
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:49:42 UTC from IEEE Xplore.  Restrictions apply.