### Threat Mitigation and VM Security

The threat posed by potential vulnerabilities in the virtual machine (VM) is minimal and can be addressed through various techniques. We believe that formal verification is feasible, given the typically small size of the VM's code. For instance, Strata's fully-featured IA32 implementation consists of only 18,000 lines of code. Much of this code pertains to the decoder for the machine's Instruction Set Architecture (ISA), which can potentially be automatically verified or generated from an ISA description.

Even without formal verification, bugs within the VM can be significantly mitigated through iterative refinement, code reviews, static analysis, and compiler-based protection techniques. Compiler-based protections, in particular, have significant potential for enhancing VM security. If randomization (such as stack, heap, and instruction location randomization) is applied to the VM at the deployment site, most direct attacks on the VM can be effectively mitigated.

### More Significant Threats to the VM

A more significant threat is a vulnerability in the application that allows it to overwrite parts of the VM or cause the VM to interpret some of its own code. Since a process-level VM typically resides in the process's address space, we must directly guard against these threats.

To address this, we enhance the VM to verify any instruction before it is fetched for analysis. The VM ensures that the instruction originates from allowable portions of the application text (for pinned instructions) or an Instruction Location Randomization (ILR) rewrite rule. The VM is prohibited from translating itself or its generated code, thus preventing the use of the VM's code for arc-injection or Return-Oriented Programming (ROP) attacks. Our prototype implementation includes these protections.

### Protecting VM Code and Data

To prevent a compromised application from overwriting the VM's code or data, we utilize standard hardware memory protection mechanisms. When executing untrusted application code, the VM disables read, write, and execute permissions on the memory used by the VM, leaving only execute (but not write) permission on the code cache. The VM also monitors attempts by the application to change these permissions. Previous research has shown this technique to be both effective and low-cost [28].

In summary, good coding practices, verification, randomization, and active protection of the VM from a compromised application can result in a secure VM.

### Entropy Exhausting Attacks

The ILR technique can achieve high entropy. Since ILR separates data and instruction memory, randomized instructions can be located anywhere in memory, even at the same addresses as program data, VM code, or data. However, operating systems often reserve specific pages of memory for interfacing with the OS, which cannot be used for randomized addresses. Additionally, any unrandomized instructions reduce the entropy of the remaining instructions. Given the few unmoved instructions and the availability of almost all other addresses for randomization, we believe it is possible to create a system with at least 31 bits of entropy on a 32-bit address system and at least 63 bits of entropy on a 64-bit system. Thus, randomly guessing gadget addresses is infeasible, and ILR can effectively evade attacks aimed at reducing system entropy.

### Information Leakage Attacks

A more likely attack scenario involves an attacker leaking information about randomized addresses. Fortunately, the memory-page protection techniques mentioned earlier prevent the leakage of most randomized addresses. The only addresses that might be leaked are those stored in the application's visible data, such as randomized return addresses on the application's stack. In a complete ILR+ implementation, this also includes any randomized addresses written into the application's exception handling tables.

In theory, all these addresses could be leaked to an attacker. However, our analysis shows that, on average, only 5% of the total program addresses could be known by the user. In practice, only a few randomized return addresses are available in the application at any given time, and most return addresses cannot be leaked. Even if the entire exception handling table were leaked, the number of available addresses would still be limited, and no ROP attacks are possible against ILR in our benchmarks, as seen in Section IV-E.

Regular re-randomization, which can be applied with little overhead, further enhances the effectiveness of ILR in the context of information leakage [29]. Therefore, information leakage is not a significant problem for ILR.

### False Detections

False detections occur when the program performs an operation detected as illegal, even though no attack is underway. In our benchmark suite, we found no false detections with ILR. However, in our incomplete ILR+ implementation, we observed two false detections: 453.povray and 471.omnetpp produced incorrect output when attempting to throw an exception. A complete ILR+ implementation would not exhibit this issue, and we believe false detections would be rare in real programs.

False detections can occur if a program calculates an indirect branch target instead of storing it in data memory. We found one example of this in gcc's library for arbitrary precision arithmetic (Figure 12). This code multiplies register eax by 9 and then jumps to the calculated address. Similar constructs might be generated by compilers, but they are uncommon for switch statements. Other constructs, such as function pointers, might also hide code addresses, often for obfuscation purposes.

Position Independent Code (PIC) is another common compiler construct that might calculate an indirect branch target. In PIC mode, the compiler generates a code address by adding the current Program Counter (PC) and a constant offset. While PIC code is not standard due to performance overhead, advanced indirect branch analysis can help mitigate false detections. For example, the code in Figure 12 is prefixed by code to verify that register eax is within proper bounds. A simple range analysis on the values reaching the jmp instruction would reveal the possible indirect branch targets.

Our experience indicates that the ILR technique can easily print the address of an indirect branch target if a false detection occurs. Implementing a profile-based or feedback-based mechanism to incorporate newly discovered Indirect Branch Targets (IBTs) would be straightforward and could reduce false detections over time.

### Shared Libraries

Modern computer systems use libraries loaded on demand and shared among multiple processes. Linux uses the .so (Shared Object) format, while Windows uses the .dll (Dynamically Linked Library) model. Our system can process and randomize programs that use dynamic linking. Analysis of such programs is generally easier because the code is divided into libraries. If a library contains a constant, it can only be an IBT within that library, not in others. This separation reduces the number of potential IBTs for each library. Externally visible functions and symbols need to be referenced by handles in the library's headers, making the extraction of these IBTs trivial.

While our prototype can process and randomize programs that require shared libraries, it does not randomize the libraries themselves. Both Linux and Windows support some form of Address Space Layout Randomization (ASLR), providing coarse-granularity randomization of shared libraries. Extending our technique to include full randomization of shared libraries is feasible, but it may not always be the best solution. When feasible, randomization within the library itself is preferable. On Linux, this can be achieved using a randomizing compiler to generate a per-system version of the libraries. For systems where library source code is not available, such as Windows, ILR-based randomization is crucial. To achieve this, ILR rewrite rules for a library would need to be loaded, and symbolic addresses resolved whenever a new library is loaded. This mechanism can be easily integrated into a dynamic loader or by having the ILR VM monitor library loading events.

### Self-Modifying Code

Our current ILR implementation does not support self-modifying, dynamically generated, or Just-In-Time (JIT) compiled code because our underlying VM does not support these constructs. However, the ILR mechanism should work correctly with dynamically generated and JIT-compiled code, which is more common than self-modifying code. ILR would not randomize the generated code, but we believe this task would be straightforward for a security-minded JIT compiler.

### Related Work

#### ROP Defenses

The original authors of Return-Oriented Programming (ROP) described its salient feature as "Turing completeness without code injection" [9]. ROP invalidates the assumption that attack payloads are inherently external by reusing code fragments already present in the target program. Defensive techniques such as various forms of instruction-set randomization, which target code injection attacks, are circumvented by arc-injection attacks, including ROP, return-to-libc, and partial overwriting of return addresses [10]. Write-Xor-Execute (W⊕X) is also ineffective, as it assumes that external code will be executed from data pages [5].

Since the seminal work on ROP [2], several defensive techniques have been proposed. Early defenses targeted non-essential features of ROP attacks. For example, DROP [14] instruments binaries to search for short sequences of instructions ending in a return instruction. Li et al. and Onarlioglu et al. avoid gadget-like instruction sequences when generating code [34, 35]. Kil et al. permute function locations to randomize gadget locations, but require additional compile-time information [36]. ROPDefender [15] and TRUSS [37] use shadow stacks to detect mismatched calls and returns.

Checkoway et al. demonstrated that the return instruction is not necessary for building ROP gadgets, bypassing ad-hoc defenses [9]. Recent works have automated gadget discovery [20, 38, 39] and ROP exploit compilation and hardening [25].

TRUSS [37], ROPDefender [15], DROP [14], and TaintCheck [40] use software dynamic translation frameworks for instrumenting code and implementing their respective defenses. TaintCheck uses dynamic taint analysis to detect control-flow hijacking, but it incurs high overhead (over 20X). ROPDefender has an approximate 2X overhead on the SPEC2006 benchmarks, while preliminary measurements for DROP range from 1.9X to 21X. In contrast, ILR achieves an average performance overhead of only 13-16%, making it practical for deployment.

#### Defenses Based on Randomization

Unlike approaches that look for specific ROP patterns, ILR provides a comprehensive defense based on high-entropy diversification. ILR offers up to 31 bits of entropy (out of a maximum of 32 for our experimental prototype), making derandomizing attacks impractical. ASLR on a 32-bit architecture only provides 16 bits of entropy and is susceptible to brute-force attacks [7]. Even on 64-bit architectures, ASLR faces two main issues: it is not universally applied throughout the address space, and it does not perform intra-library randomization. Any information leaked about the location of one function or address can be used to infer the complete layout of a library. Roglia et al. demonstrated a single-shot return-to-libc attack that used ROP gadgets to leak information about the base address of libc and bootstrap this information into all other libc functions [8]. Their proposed remedy of encrypting the Global Offset Table was specific to their attacks and left open the possibility of other leakage attacks.

Bhatkar et al. use source-to-source transformation techniques to produce self-randomizing programs (SRP) to combat memory error exploits [42]. Unlike other compiler-based randomization techniques [43], SRP produces a single program image, making it more practical for deployment. SRP randomizes code at the granularity of individual functions, retaining a larger attack surface than the ILR approach of randomizing at the instruction level. Instruction Set Randomization (ISR) helps defeat code-injection attacks but provides no protection against arc-injection and ROP attacks [28].

#### Control Flow Integrity

Control Flow Integrity (CFI) is designed to ensure that a program's control flow is not hijacked [44]. CFI relies on the Vulcan instrumentation system, which allows instruction discovery, static analysis, and binary rewriting. An example program (Figure 13) shows how CFI enforces that the return instruction (in function log) can only jump to the instruction after a call to the log function. However, this policy allows an arc-injection attack if the log function is vulnerable. An attacker might overwrite the return address to erroneously jump to L2, granting additional access. Even the best static analysis cannot mitigate these threats using CFI.

Partial overwrite attacks can defeat ASLR in this example, as the distance between the two return sites is fixed. Since ILR randomizes this distance, it can defeat partial-overwrite attacks.

### Conclusions

This paper presents Instruction Location Randomization (ILR), a high-entropy technique for relocating instructions within an arbitrary binary. ILR effectively hides 99.96% of ROP gadgets from an attacker, a 3.5 order of magnitude reduction in the attack surface. The work describes the general technique, evaluates two versions of an ILR prototype, and discusses the security implications of ILR. We find that ILR can be applied to a wide range of binary programs compiled from C, Fortran, and C++. Performance overhead is as low as 13% across the 29 SPEC CPU2006 industry-standard benchmarks [16].

ILR surpasses state-of-the-art techniques in several ways:
- It can be easily and efficiently applied to binary programs.
- It provides up to 31 bits of entropy for instruction locations on 32-bit systems.
- It can regularly re-randomize a program to thwart entropy-exhausting or information-leakage attacks.
- It provides low execution overhead.
- It randomizes both statically and dynamically linked programs.
- It defeats attacks against large, real-world programs, including the Linux PDF viewer, xpdf, and Adobe's PDF viewer, acroread.

These results demonstrate that ILR can be used in a wide variety of real-world situations to provide strong protection against attacks.

### Acknowledgment

This research is supported by the National Science Foundation (NSF) grant CNS-0716446, the Army Research Office (ARO) grant W911-10-0131, the Air Force Research Laboratory (AFRL) contract FA8650-10-C-7025, and DoD AFOSR MURI grant FA9550-07-1-0532. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of the NSF, AFRL, ARO, DoD, or the U.S. Government.

### References

[1] J. Pincus and B. Baker, “Beyond stack smashing: Recent advances in exploiting buffer overruns,” IEEE Security & Privacy, vol. 2, no. 4, pp. 20–27, Jul/Aug 2004.

[2] H. Shacham, “The geometry of innocent flesh on the bone: Return-into-libc without function calls (on the x86),” in Proceedings of the 14th ACM Conference on Computer and Communications Security. ACM, 2007, pp. 552–561.

[3] E. Buchanan, R. Roemer, H. Shacham, and S. Savage, “When good instructions go bad: Generalizing return-oriented programming to RISC,” in Proceedings of the 15th ACM Conference on Computer and Communications Security. ACM, 2008, pp. 27–38.

[4] D. Dai Zovi, “Practical return-oriented programming,” SOURCE Boston, 2010.

[5] The PAX Team, http://pax.grsecurity.net.

[6] M. Howard and M. Thomlinson, “Windows vista ISV security,” Microsoft Corporation, April, vol. 6, 2007.

[7] H. Shacham, M. Page, B. Pfaff, E. Goh, N. Modadugu, and D. Boneh, “On the effectiveness of address-space randomization,” in Proceedings of the 11th ACM Conference on Computer and Communications Security. ACM, 2004, pp. 298–307.

[8] G. Roglia, L. Martignoni, R. Paleari, and D. Bruschi, “Surgically returning to randomized lib (c),” in 2009 Annual Computer Security Applications Conference. IEEE, 2009, pp. 60–69.

[9] S. Checkoway, L. Davi, A. Dmitrienko, A. Sadeghi, H. Shacham, and M. Winandy, “Return-oriented programming without returns,” in Proceedings of the 17th ACM Conference on Computer and Communications Security. ACM, 2010, pp. 559–572.

[10] T. Durden, “Bypassing PaX ASLR protection,” Phrack Magazine, vol. 0x0b, no. 0x3b, 2002. [Online]. Available: http://www.phrack.org/issues.html?issue=59&id=9

[11] K. Scott, N. Kumar, S. Velusamy, B. R. Childers, J. W. Davidson, and M. L. Soffa, “Retargetable and reconfigurable software dynamic translation,” in International Symposium on Code Generation and Optimization. San Francisco, CA: IEEE Computer Society, Mar. 2003, pp. 36–47.

[12] V. Bala, E. Duesterwald, and S. Banerjia, “Dynamo: A transparent dynamic optimization system,” in SIGPLAN ’00 Conference on Programming Language Design and Implementation, 2000, pp. 1–12.

[13] M. Payer and T. Gross, “Fine-grained user-space security through virtualization,” in Proceedings of the 7th ACM SIGPLAN/SIGOPS International Conference on Virtual Execution Environments. ACM, 2011, pp. 157–168.

[14] P. Chen, H. Xiao, X. Shen, X. Yin, B. Mao, and L. Xie, “DROP: Detecting return-oriented programming malicious code,” Information Systems Security, pp. 163–177, 2009.

[15] L. Davi, A. Sadeghi, and M. Winandy, “ROPdefender: A detection tool to defend against return-oriented programming attacks,” in Proceedings of the 6th ACM Symposium on Information, Computer and Communications Security. ACM, 2011, pp. 40–51.

[30] E. G. Barrantes, D. H. Ackley, S. Forrest, and D. Stefanovic, “Randomized instruction set emulation,” ACM Transactions on Information System Security., vol. 8, no. 1, pp. 3–40, 2005.

[16] Standard Performance Evaluation Corporation, “SPEC CPU2006 Benchmarks,” http://www.spec.org/osg/cpu2006.

[17] (2011, November) Hex-rays website. [Online]. Available: http://www.hex-rays.com/products/ida/index.shtml

[18] C.-K. Luk, R. Cohn, R. Muth, H. Patil, A. Klauser, G. Lowney, S. Wallace, V. J. Reddi, and K. Hazelwood, “Pin: Building customized program analysis tools with dynamic instrumentation,” in PLDI ’05: Proceedings of the 2005 ACM SIGPLAN Conference on Programming Language Design and Implementation. New York, NY, USA: ACM Press, 2005, pp. 190–200.

[19] M. Voss and R. Eigenmann, “A framework for remote dynamic program optimization,” in Proceedings of the ACM Workshop on Dynamic Optimization Dynamo ’00, 2000.

[20] “Shell storm website,” http://www.shell-sorm.org/project/ROPgadget/.

[21] (2008) Libtiff remote buffer overflow vulnerability. [Online]. Available: http://www.securityfocus.com/bid/19283 tifffetchshortpair

[22] A. Kapoor, “An approach towards disassembly of malicious binary executables,” Ph.D. dissertation, University of Louisiana, 2004.

[31] G. S. Kc, A. D. Keromytis, and V. Prevelakis, “Countering code-injection attacks with instruction-set randomization,” in CCS ’03: Proceedings of the 10th ACM Conference on Computer and Communications Security. New York, NY, USA: ACM Press, 2003, pp. 272–280.

[32] S. Designer, “‘return-to-libc’ attack,” Bugtraq, Aug, 1997.

[33] Nergal, “The advanced return-into-lib(c) exploits (PaX case study).” Phrack Magazine, 58(4), December 2001.

[34] J. Li, Z. Wang, X. Jiang, M. Grace, and S. Bahram, “Defeating return-oriented rootkits with ‘return-less’ kernels,” in Proceedings of the 5th European Conference on Computer Systems, ser. EuroSys ’10. New York, NY, USA: ACM, 2010, pp. 195–208.

[35] K. Onarlioglu, L. Bilge, A. Lanzi, D. Balzarotti, and E. Kirda, “G-Free: defeating return-oriented programming through gadget-less binaries,” in Proceedings of the 26th Annual Computer Security Applications Conference. ACM, 2010, pp. 49–58.

[36] C. Kil, J. Jun, C. Bookholt, J. Xu, and P. Ning, “Address space layout permutation (ASLP): Towards fine-grained randomization of commodity software,” in Computer Security Applications Conference, 2006. ACSAC’06. 22nd Annual. Ieee, 2006, pp. 339–348.

[23] C. Kruegel, W. Robertson, F. Valeur, and G. Vigna, “Static disassembly of obfuscated binaries,” in Proceedings of the 13th USENIX Security Symposium, 2004, pp. 255–270.

[37] S. Sinnadurai, Q. Zhao, and W. fai Wong, “Transparent runtime shadow stack: Protection against malicious return address modifications,” 2008.

[24] B. Schwarz, S. Debray, and G. Andrews, “Disassembly of executable code revisited,” in Proceedings of the 9th Working Conference on Reverse Engineering. IEEE, 2002, pp. 45–54.

[38] T. Dullien and T. Kornau, “A framework for automated architecture-independent gadget search,” in 4th USENIX Workshop on Offensive Technologies, 2010.

[25] E. J. Schwartz, T. Avgerinos, and D. Brumley, “Q: Exploit hardening made easy,” in Proceedings of the USENIX Security Symposium, 2011.

[26] J. Hiser, D. Williams, W. Hu, J. Davidson, J. Mars, and B. Childers, “Evaluating indirect branch handling mechanisms in software dynamic translation systems,” in Proceedings of the International Symposium on Code Generation and Optimization. IEEE Computer Society, 2007, pp. 61–73.

[27] A. Guha, K. Hazelwood, and M. Soffa, “Reducing exit stub memory consumption in code caches,” High Performance Embedded Architectures and Compilers, pp. 87–101, 2007.

[28] W. Hu, J. Hiser, D. Williams, A. Filipi, J. Davidson, D. Evans, J. Knight, A. Nguyen-Tuong, and J. Rowanhill, “Secure and practical defense against code-injection attacks using software dynamic translation,” in Proceedings of the 2nd International Conference on Virtual Execution Environments. ACM, 2006, pp. 2–12.

[29] A. Nguyen-Tuong, A. Wang, J. Hiser, J. Knight, and J. Davidson, “On the effectiveness of the metamorphic shield,” in Proceedings of the Fourth European Conference on Software Architecture: Companion Volume. ACM, 2010, pp. 170–174.

[39] R. G. Roemer, “Finding the bad in good code: Automated return-oriented programming exploit discovery,” 2009.

[40] D. S. James Newsome, “Dynamic taint analysis for automatic detection, analysis, and signature generation of exploits on commodity software,” in Proceedings of the Network and Distributed System Security Symposium, 2005.

[41] A. van de Ven, “New security enhancements in red hat enterprise linux v.3, update 3.” Red Hat, Inc., 2004.

[42] S. Bhatkar, R. Sekar, and D. C. DuVarney, “Efficient techniques for comprehensive protection from memory exploits,” in Proceedings of the 14th Conference on USENIX Security Symposium. USENIX Association, 2005.

[43] T. Jackson, B. Salamat, A. Homescu, K. Manivannan, G. Warner, A. Gal, S. Brunthaler, C. Wimmer, and M. Franz, “Compiler-generated software diversity,” 2011.

[44] M. Abadi, M. Budiu, ´U. Erlingsson, and J. Ligatti, “Control-flow integrity,” in Proceedings of the 12th ACM Conference on Computer and Communications Security. ACM, 2005, pp. 340–353.