Section 6.
We compute the taint propagation slice for each single leakage
instance, and conduct a quantitative study on them. Figure 5a gives
the number of generated taint propagation slices for every app.
While most of the apps retrieve privacy-related information mod-
erately, some apps leak user’s privacy through up to 31 taint slices.
Such apps usually enclose various Ads libraries, each of which ac-
quires private data separately.
Figure 5b shows the proportional size of the slices, compared
to the total size of the application. We can see that most of the
program slices represent a small portion of the entire application,
with the average proportion being 2.48%. However, we do observe
that for a few applications, the slices take up to 54% of the to-
tal size. Some samples (e.g., com.tarsin.android.dilbert) are fairly
small. Although the total slice size is only up to several thousands
Jimple statements, the relative percentage becomes high. Apps like
de.joergjahnke.mario.android.free and de.schildbach.oefﬁ operate
on privacy information in an excessive way, and due to the conser-
vative nature of static analysis, many static and instance ﬁelds are
involved in the slices.
We measure the program size on different stages. We observe
that the increase of the program size is roughly proportional to the
slice size, which is expected. After instrumentation, the increased
size is, on average, 10.45% compared to the original program. Fig-
ure 6 further visualizes the impact of the four optimizations to
demonstrate their performance. The six curves on the ﬁgure rep-
resent the relative size of the program, compared to the original
application, on different processing stages, respectively. The base-
line stands for the size of the original program, while the top curve
is that of instrumentation stage. We can see that 1) for most of
these apps, the increase of program size due to instrumentation is
67%24%2%3%4%No Need for RewritingSafely RewrittenUnsafe with Native CodeUnsafe with ReflectionTimeout265(a) Number of Taint Slices. X-axis is app ID; Y-axis is the
number of taint slices.
(b) Proportional Size of Slices. X-axis is app ID; Y-axis is the
proportional size of slices.
Figure 5: Results for Taint Propagation Slices
Figure 6: Optimization Impact on LOC. X-axis is app ID,
while Y-axis is the proportional app size. The result is sorted
based on Y-axis. Six curves quantify these sizes at different
stages.
Figure 7: Inspection & Rewriting Runtime. X-axis is app ID,
and Y-axis is the cumulative time for analysis, instrumentation
and optimizations. The result is sorted based on Y-axis.
fairly small; and 2) these optimizations are effective, because they
signiﬁcantly reduce the program sizes. In the end, the average size
of inserted code drops to 4.48%.
5.3 Detailed Analysis
Here we present the detailed analysis results of ten applications,
and demonstrate the effectiveness of context-aware privacy policy
enforcement. To this end, we rewrite these apps with Capper,
and run them in a physical device along with our policy service
app. We further manually trigger the privacy leakage components
in the app, so that inserted code would block the program and query
policy service for decision. The service will then search its own
database to see if there exists a rule for the speciﬁc dataﬂow context
of the requesting app. If a corresponding rule exists, service replies
to requester immediately. Otherwise, a dialog is displayed to the
user asking for decision. The user can also check the “always”
option so that current decision will be saved for further reference
(Figure 8). Notice that, in order to test the context-awareness of
our approach, we always check this option during the experiment.
Therefore, from the logcat information on the service side, we may
observe and compare the number of queries an app makes with the
amount of warning dialogs prompted to the user. We also compute
the number of information ﬂow contexts with trace-based model
for comparison.
Table 2 lists the summarized results including number of queries,
prompts and trace-based contexts. For these apps, the prompt num-
ber is often equal to or sometimes slightly smaller than the amount
of trace-based dataﬂow contexts, while the number of queries is
usually much larger than that of prompts. This means leakage con-
texts are modeled correctly: disparate contexts are usually treated
differently in our callsite-based approach; and equivalent contexts
are enforced with the same rule. The fundamental reason is that
Android apps are often componentized while a separate component
exercises a dedicated function.
Firstly, different types of private information are accessed through
separate execution paths. Some apps (ID 2, 3) retrieve both de-
vice identiﬁer and location information, and send them at separate
sinks. Similarly, mabilo.ringtones.app leaks both geolocation data
and user’s phone number.
Secondly, the same type of privacy-related data can be retrieved
from isolated packages but serves as different purposes. These apps
(ID 4, 7, 10) consist of a main program and advertisement compo-
nents, both of which produce outgoing trafﬁc taking IMEI or lo-
cation data. Take net.ﬂixster.android as an example. In this movie
app, location data is both sent to ﬂixster server for querying theaters
and to Ads server for analytical purpose.
Further, the same private data can be accessed in one package
but contributes to different use cases. For instance, com.rs.autorun
obtains device identiﬁer via getDeviceId() API call in the ﬁrst
place. Then the app sends IMEI at multiple sinks to load advertise-
ment View, retrieve conﬁguration or upload analytical information
including demographics, ratings, etc. Each semantic context is cap-
tured from the perspective of taint propagation trace. However, due
to the use of same sink call-site, all the analytical trafﬁcs are con-
sidered to be with the same semantic context in the call-site model.
Though call-site-based model is not as sensitive to context as the
trace-based approach, it is still able to differentiate the contexts of
Ads View, conﬁguration ﬁle loading and analytical dataﬂow, ac-
cording to disparate sink call-sites.
We also observe inconsistency between traced-based contexts
and real program semantics. That lies in apps (ID 1, 6, 7, 8, 9,
051015202530350.00%10.00%20.00%30.00%40.00%50.00%60.00%100.00%140.00%180.00%220.00%260.00%300.00%OriginalInstruO1O2O3O404080120160200Analysis  (s)Instru  (s)O1  (s)O2  (s)O3  (s)O4 (s)266artfulbits.aiMinesweeper-3.2.3
com.avantar.wny-4.1.5.1
com.avantar.yp-4.1.5
com.bfs.papertoss-1.09
com.rs.autorun-1.3.1
com.skyﬁre.browser-2.0.1
com.startapp.wallpaper.browser-1.4.15
ID App-Version
1
2
3
4
5
6
7
8 mabilo.ringtones.app-3.6
9 mabilo.wallpapers-1.8.4
10
net.ﬂixster.android-2.9.5
Queries
Prompts Trace-based Contexts
5
3
4
3
10
4
5
5
4
6
2
2
2
2
4
2
3
3
2
3
2
2
2
2
6
2
3
3
2
3
Figure 8: Warning Dialog
Table 2: Effectiveness of Context-aware Policy Enforcement
10) which acquire location information, where the number of trace-
based contexts exceeds that of actual contexts. Geographic location
is obtained either approximately from getLastKnownLocation(),
or from a real-time update by registering a listener through
requestLocationUpdates() and receiving updates via callback
onLocationChanged(Location). Some apps adopt both ways
so as to achieve higher accuracy. For instance, artfulbits.aiMinesweeper
reads location data by calling getLastKnownLocation() at the
very beginning of the program, stores it into an instance ﬁeld, and
then periodically updates it with the aforementioned callback. Con-
sequently, two separate paths achieve one sole purpose and thus
should be considered as of equivalent context. However, from ei-
ther trace or call-site point of view, there exist two separate con-
texts. Despite the disparity, we believe that this would at most in-
troduce one extra prompt. Further, it is also reasonable to split this
context into two, because one conducts a one-time access while the
other obtains data repeatedly.
5.4 Performance Evaluation
We evaluate both ofﬂine rewriting time cost and runtime perfor-
mance.
Rewriting Performance.
Figure 7 illustrates the time consumption of analysis and rewrit-
ing for 4723 Android apps in our experiment. To be speciﬁc, it
depicts the execution time of analysis, instrumentation, and four
optimization phases. We do not show the bytecode conversion time
here, because code conversion by dex2jar is usually within several
seconds and thus not signiﬁcant as compared to the other steps.
We ﬁnd that more than 83.6% of the apps are processed within
10 seconds and the majority (92.8%) can be rewritten within 1
minute. However, still a few of them cost excessive time to ﬁn-
ish. Global data-ﬂow analysis dominates the overall processing
time, especially for those privacy-breaching apps. In comparison,
the time consumption of instrumentation and optimizations is fairly
small.
Runtime Performance.
We compare the runtime overhead of bytecode rewriting with
that of dynamic taint analysis in TaintDroid (on Android ginger-
bread version 2.3.4).
In principle, if an app leaks private infor-
mation only occasionally, the rewritten version would have much
better performance than the original version on TaintDroid. This
is because in the rewritten app nearly no instrumentation code is
added on non-leaking execution paths whereas TaintDroid has to
monitor taint propagation all the time.
Rather, we would like to compare the performance when the
taint is actively propagated during the execution. This would be the
worst-case scenario for Capper. Speciﬁcally, we build two cus-
tomized applications for the measurement. Both leak IEMI string
via getDeviceId() API, decode the string to a byte array, en-
crypt the array by doing XOR on every byte with a constant key,
reassemble a string from the encrypted byte array, and in the end,
send the string out to a speciﬁc URL through a raw socket inter-
face. The only difference is that one merely sends the IMEI string,
while the other also appends extra information of totally 10KB to
the IMEI string before encryption. In other words, the former con-
ducts a short-period data transfer while the latter manipulates the
outgoing message within a much longer period. We expect that the
execution of the ﬁrst one to be mainly under mterp interpretation
mode and the execution of the second to be boosted by JIT.
Orig.
30ms
10583ms
Short
Long
Orig. on TaintDroid
Rewritten
130ms
15571ms
34ms
10742ms
Table 3: Runtime Performance Evaluation
We measured the execution time from getDeviceId() to the
network interface. We observed that the rewritten application runs
signiﬁcantly faster than the original on TaintDroid, and only yields
fairly small overhead compared to the original one running on An-
droid, for both short-period and long-period data propagation. Ta-
ble 3 illustrates the result of runtime measurement. While our ap-
proach causes 13% and 1.5% overhead for short and long data prop-
agation respectively, TaintDroid incurs 330% and 47% overhead.
The results also show that the presence of JIT signiﬁcantly reduces
runtime overhead, in both approaches. However, though newer
version of TaintDroid (2.3.4 and later) beneﬁts from JIT support,
the overhead caused by dynamic instrumentation is still apparently
high.
To further conﬁrm the runtime overhead of the rewritten pro-
grams, we conduct an experiment on Google Nexus S, with An-
droid OS version 4.0.4. It is worth mentioning that such veriﬁca-
tion on real device requires considerable repetitive manual efforts
and thus is fairly time consuming. We therefore randomly pick 10
apps from the privacy-breaching ones, rewrite them, run both the
original app and secured one on physical device, and compare the
runtime performance before and after rewriting. We rely on the
timestamps of Android framework debugging information (logcat
logs) to compute the app load time as benchmark. The app load
time is measured from when Android ActivityManager starts
an Activity component to the time the Activity thread is dis-
played. This includes application resolution by ActivityManager,
IPC and graphical display. Our observation complies with prior
experiment result: rewritten apps usually have insigniﬁcant slow-
down, with an average of 2.1%, while the maximum runtime over-
head is less than 9.4%.
2676. DISCUSSION
In this section, we discuss the limitations of our system and pos-
sible solutions. We also shed light on future directions.
Soundness of Our Bytecode Rewriting.
Our static analysis, code instrumentation, and optimizations fol-
low the standard program analysis and compiler techniques, which
have been proven to be correct in the single threading context. In
the multi-threading context, our shadow variables for local vari-
ables and function parameters are still safe because they are local
to each individual thread, while the soundness of shadow ﬁelds de-
pends on whether race condition vulnerability is present in orig-
inal bytecode programs. In other words, if the accesses to static
or instance ﬁelds are properly guarded to avoid race condition in
the original app, the corresponding operations on shadow ﬁelds are
also guarded because they are placed in the same code block. How-
ever, if the original app does have race condition on certain static
or instance ﬁelds, the information ﬂow tracking on these ﬁelds may
be out of sync.
We modeled Android APIs for both analysis and instrumenta-
tion. We manually generate dedicated taint propagation rules for
frequently used APIs and those of signiﬁcant importance (e.g., se-
curity sensitive APIs). Besides, we have general default rules for
the rest. It is well-recognized that it is a non-trivial task to build
a fairly complete API model, and it is also true that higher cov-
erage of API model may improve the soundness of our rewriting.
However, previous study [7] shows that a model of approximately
1000 APIs can already cover 90% of calls in over 90,000 Android
applications. In addition, it is also possible to automatically cre-
ate a better API model by analyzing and understanding Android
framework, and we leave it as our future work.
Tracking Implicit Flow.
It is well known that sensitive information can propagate in other
channels than direct data ﬂow, such as control ﬂow and timing
channels. It is extremely challenging to detect and keep track of
all these channels. In this work, we do not consider keeping track
of implicit ﬂow. This means that a dedicated malicious Android
developer is able to evade Capper. This limitation is also shared
by other solutions based on taint analysis, such as TaintDroid [12]
and AppFence [19]. Serious research in this problem is needed and
is complementary to our work.
Java Reﬂection.