is implicitly assumed to be a deterministic algorithm.
There are no further requirements on the output of verify given
by the standard computational definition. The traditional definition
of symbolic verification, shown in §2.2, agrees with the computa-
tional definition but further specifies that verify implicitly out-
puts false in any situation in which it is undefined, i.e., verification
against a malicious key. Many of the equations we gave in §3 essen-
tially remedied this in an ad-hoc fashion, by specifying additional
cases where verify could return true.
We now build a symbolic definition of verify that agrees with
the computational one: where its output is not otherwise con-
strained, we let the adversary choose whether it returns true or false.
This definition encompasses our previous equations for maliciously
generated public keys, as well as further unknown equations, so
long as they are not ruled out by the computational definition.
In a symbolic setting, we consider traces made by a series of
transitions of a labeled transition system, which (implicitly or ex-
plicitly) describes the state of the protocol at that point in the trace.
When signature verification occurs in a trace, we now require the
following constraints to be observed:
(1) If the public key was honestly generated, the verification of a
corresponding honest signature must succeed.
(2) If the public key was honestly generated, the verification of a
forged signature must fail.
(3) If this particular message-signature-key triple has been verified
before, the result is defined by the previous answer.
(4) Otherwise, consider all possibilities—i.e., let the adversary de-
cide.
We could model the first and second constraints purely in the term
algebra. Similarly, the fourth constraint corresponds to allowing
the adversary to send a value over a channel to the protocol. The
third constraint is the interesting one because it requires storing
(monotonic) state about previous queries. Succinctly, the verifica-
tion output depends both on the “local query”, the history of the
trace, and the adversary’s current choice. Consequently our sym-
bolic model must record whether public keys have been created
honestly, and what verification checks have been made previously.
We now give an implementation of this abstract specification in
Tamarin.
4.2 Tamarin Implementation: User-Visible
We use the function signature as defined in §3.2. We allow for public
key and message extraction as the modeller wishes. We omit the
verification function and its associated equation, and will replace it
with a different mechanism that makes minimal assumptions on
the properties of the scheme.
In previous approaches, the signature verification function was
encoded into the term algebra, and explicitly stated under which
conditions signature verification returns true. Here, we will instead
only specify restrictions for the signature verification results, and
consider all possibilities in other scenarios. To implement this, we
specify signature verification as an annotation on a protocol rule,
which guards the transition according to a series of first order
logical statements we give below. So, we begin by defining the
trace annotations that we use for restriction checks. Each of these
Session 9D: SignaturesCCS ’19, November 11–15, 2019, London, United Kingdom2172annotations can be added to Tamarin as an action in a mechanical
fashion for the rule using it:
Honest Key generation. Where the protocol honestly generates a
public key pk, we label the corresponding transition with the action
Honest(pk). This specifies that the public key has been output by the
generation algorithm for signatures and consequently, the various
restrictions on the signature verification algorithm will apply if a
signature is tested against this public key.
Signature Verification. Where a protocol will only make a certain
transition conditional on the result of a signature verification result
(be it true or false), we will provide an action label for this occur-
rence. Unlike the Honest(pk) label, we will later use restrictions, first
order formulae, to restrict situations under which this transition can
occur. When a protocol wishes to verify a particular signature term
sig against a particular message and public key combination (la-
belled tm and tpk), we will write Verified(sig, tm, tpk, result) where
result may be true or false depending on whether the transition
should be allowed to occur.
Manipulation of Honest Signatures. We also provide the equation
for malleable signatures and the rule for re-signing we discussed
in §3.2 and §3.3. Malleability allows an adversary to manipulate an
honest signature and is therefore not part of our improvements to
the signature verification algorithm. Re-signing has a very subtle
usage for the adversary: if (i) the adversary compromises the private
key of an honestly generated key pair, (ii) the signature theory is
not message revealing, and (iii) the adversary is in possession of a
signature for an unknown message, then the adversary can use the
re-signing rule to generate a new signature, under the compromised
honestly generated key, for the unknown message. As this refers
to the generation of a new signature under an honestly generated
public key, it is orthogonal to our changes to the specification of
signature verification for malicious public keys.
4.3 Tamarin Implementation: Internal
Syntactic Transformations: Behind the scenes, we will mechanically
transform Verified(sig, tm, tpk, result)
fact
Verified(sig, sm, spk, tm, tpk, result) using the following extraction
functions described in the listing below. We define sm = e1(sig) and
spk = pk(e3(sig)). This transformation is needed for purely techni-
cal reasons: Tamarin requires reducible functions to be specified in
the action fact annotation rather than in restriction formulae.
action
to
an




functions : e1 /1 , e2 /1 , e3 /1 [ private ]
equations : e1 ( sign (x ,y ,z)) = x
e3 ( sign (x ,y ,z)) = z
Extraction Functions for Signatures. These are not used by the
protocol or the adversary, just by the implementation.
These functions allow us to easily refer to the message and
public/private key that a signature corresponds to. Note that in the
event the signature is not honestly generated, these functions are
still well defined, but simply do not yield a result (technically, they
will not reduce).
We now provide a series of restrictions which restrict the traces
that can occur. All of our restrictions concern the behaviour of the
signature verification function.
Correctness. This requirement follows directly from the require-
ment that an honestly generated public key, an honestly generated
signature, and the correct message must verify as true.
Correctness : ∀sig, tm, tpk, t1, t2. Honest(tpk)@t1 ∧
Verified(sig, tm, tpk, tm, tpk, false)@t2 =⇒ ⊥
NoForgery. Here we state that if a signature verification does
succeed against an honest public key, then the signature must have
been honestly produced.
NoForgery : ∀sig, tm, tpk, sm, spk, t1, t2. Honest(tpk)@t1 ∧
Verified(sig, sm, spk, tm, tpk, true)@t2
=⇒ sm = tm ∧ spk = tpk
Consistency. Verification is typically defined as a deterministic
function, here we specify that repeated calls to verify will always
return a consistent answer.
Consistency : ∀sig, sm, spk, tm, tpk, r1, r2, t1, t2.
Verified(sig, sm, spk, tm, tpk, r1)@t1 ∧
Verified(sig, sm, spk, tm, tpk, r2)@t2 =⇒ r1 = r2
The result of this model is that if a particular transition is labeled
with a verification annotation it will be allowed to occur unless it
violates one of these three restrictions.
If we compare these restrictions to our earlier specification, we
note the following: in the event that the signature is being verified
against an honest public key, Correctness ensures honest signatures
will be accepted and NoForgery ensures forged signatures will be re-
jected. Otherwise, the only rule that will apply is Consistency which
simply ensures signature verification calls are deterministic. It is
straightforward to see how this presentation matches our earlier
specification, as this expresses our required properties to Tamarin
directly. Consequently, this Symbolic Verification of Signatures (SVS)
model allows the adversary to perform key substitution attacks,
craft colliding signatures and many other known or unknown be-
haviours concerning maliciously chosen public keys.
4.4 Results
We now show that the above model is tractable in practice and we
present results and running times in Table 2.
This model, as close as it is to the computational definition, forces
us to consider issues not normally raised in a symbolic analysis.
Traditional symbolic tools often produce an attack trace that is
practical in reality, as it consists of a series of explicit capabilities
provided to the adversary. In contrast, our SVS model is closer to
the computational model in the sense that the attack trace will
consist of the adversary specifying certain signatures pass or fail
verification, but providing no intuition on how an adversary may
arrange for this to happen.
Consequently, both our SVS model and our earlier models for
attack finding are independently of interest to protocol modellers.
First, the SVS model (§4) should be used and if Tamarin returns a
proof, it is within the strongest model of signature security we have
described. However, should it return an attack trace, the modeller
can use our attack finding models (§3) to effectively recover practical
attacks that could be used in reality. By using the attack finding
model for each property separately, it is possible to isolate the
Session 9D: SignaturesCCS ’19, November 11–15, 2019, London, United Kingdom2173STS-MAC Signature
variant
Security property
IA
✓
•◦
•◦
✓
•◦
•◦
✓
•◦
•◦
✓
•◦
•◦
✓
✓
✓
✓
✓
✓
Time in
SSA seconds
✓
•◦
•◦
✓
•◦
•◦
✓
•◦
•◦
✓
•◦
•◦
✓
•◦
•◦
✓
✓
✓
14
35 ∗
23 ∗
14
68 ∗
16 ∗
13
46 ∗ †
30 ∗
16
25 ∗
23
17
34
25
3
19
9
Model
Traditional
no-CEO
SVS
Traditional
no-DEO
SVS
Traditional
Re-sign
SVS
Traditional
Coll.
SVS
Traditional
Mall.
SVS
Traditional
All in §3
SVS
Sec
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
MAC
ID
KSIG
SCRYPT
ISO
KDF
Table 2: Verification results when applying our various Tamarin
models to a number of distinct STS-MAC variants.
Sec, IA and SSA are respectively the security properties of key se-
crecy, identity agreement and strong session agreement.
✓ indicates that Tamarin successfully verified the property
•◦ indicates that Tamarin found an attack
∗ indicates that attack finding was done in the bounded model
† indicates that the non-default i heuristic was used for the proof
signature behaviour which is leading to the attack and thus consider
possible mitigations. We demonstrate this functionality on our case
studies in the next section.
It is possible that our SVS model returns that an attack is found,
but none of our falsification models yields an attack. In this case, we
suggest it is best to think of the result as “Not Proven”. There may
well be an attack as the protocol requires behaviour of signatures
not provided by the standard definition, yet Tamarin is not aware
of a method of crafting public keys or signatures to enable the attack
in practice. This means one does not have the desired symbolic
proof, but still gets the proofs for the falsification models, which is
a much stronger guarantee than previously.