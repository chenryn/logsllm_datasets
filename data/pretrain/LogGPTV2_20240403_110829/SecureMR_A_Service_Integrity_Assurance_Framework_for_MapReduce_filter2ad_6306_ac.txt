Reducer
M
Mapper
R d
Reducer
V ifi
Verifier
Fig. 5. SecureMR Extension for MapReduce Chain.
D. SecureMR Extension
So far, we have discussed how SecureMR provides reducers
with a mechanism to verify the authenticity and correctness
of the intermediate results generated by mappers. In this
section, we present how SecureMR applies the replication-
based veriﬁcation scheme to reducers and MapReduce chain
to provide users with a mechanism to check if the ﬁnal result
produced by reducers is authentic and correct.
Extension for Reducers. Similar to mappers, the Scheduler
in the master may duplicate reduce tasks and assign them to
multiple reducers. Reducers assigned the same task will read
the same partition of the intermediate results from mappers.
However, we observe that reducers are not conﬁgured with a
Secure Committer component in current architecture described
in Figure 2(a), which means they cannot make a commitment
to the master. In order for reducers to make commitments,
we can easily deploy a Secure Committer component for
reducers. Another problem to apply the veriﬁcation scheme
to reducers is that there are no other entities to complete
the veriﬁcation protocol since reducers are in the last phase.
To address this problem, we extend the MapReduce model
to include an additional phase called Verify phase. In the
verify phase, the master involves several workers with a Secure
Veriﬁer component, called veriﬁers to complete the veriﬁcation
protocol. Another alternative is to install a Secure Veriﬁer
component into MapReduce user applications and ask them
to complete the veriﬁcation protocol by themselves after their
jobs are done.
Extension for MapReduce Chain. Similarly, the veriﬁca-
tion scheme can be applied to MapReduce chain since each
map and reduce share the similar procedure of data processing.
Figure 5 shows the design overview of how SecureMR applies
the veriﬁcation scheme to MapReduce chain. As we can see
from the ﬁgure, the design is like a Commit-Verify chain
between the master, mappers and reducers. If mappers make
commitments to the master, reducers will take the role of
veriﬁers to verify the consistency between intermediate results
and commitments of mappers. If reducers make commitments
to the master, mappers will take the role of veriﬁers to verify
the consistency between outputs and commitments of reducers
except the last phase, Verify phase. The verify phase has been
discussed in the above. In order for mappers to be able to
fulﬁll the veriﬁcation protocol, the only thing that we need to
do is to plug a Secure Veriﬁer component into each mapper.
78
V. ANALYSIS AND EVALUATION
In this section, we discuss the security properties of Se-
cureMR, and then evaluate the performance overhead both
analytically and experimentally. Note that in Section V-A and
V-B, we focus on the discussion for mappers due to the
similarity of the analysis between mappers and reducers.
A. Security Analysis
There are two kinds of inconsistencies for mappers in
MapReduce. One is an inconsistency between results returned
by different mappers that are assigned the same task. The other
is an inconsistency between the commitment and the result
generated by a mapper. The former can only be detected by
the master in the commitment protocol and the latter can only
be detected by a reducer in the veriﬁcation protocol. We claim
that SecureMR provides the following two properties. We also
provide arguments for our statement in the following.
• No False Alarm. For any inconsistency detected by Se-
cureMR, it must happen between good and bad mappers,
between bad mappers or on a bad mapper. It cannot occur
between good mappers or on a good mapper.
• Non-Repudiation. For any inconsistency that can be
observed by a good reducer or the master, SecureMR
can detect it and present evidence to prove it.
Arguments of No False Alarm. The assumptions in Section
III-B guarantee that good mappers always produce correct and
consistent results. We prove by contradiction that SecureMR
provides No False Alarm property in terms of the two kinds
of inconsistencies.
First, suppose that an inconsistency between two good
mappers is detected by the master. In this case, the master must
get two different sets of hash values from the commitments of
two good mappers, which means that the two commitments the
master received must be tampered somehow since two good
mappers will not produce inconsistent results. However, if the
master accepted a commitment of a mapper, the master must
have conﬁrmed the integrity and freshness of the commitment.
Thus, the commitment is neither a bad commitment nor an old
one. From the arguments, we can infer that there is no way to
tamper a commitment of a mapper without being detected by
the master. And the hypothesis implies that the master already
accepted the commitments, which means it is impossible that
the commitments that the master received have been tampered.
Therefore, the hypothesis that an inconsistency between two
good mappers is detected by the master is not true.
Second, suppose that an inconsistency between the com-
mitment and the intermediate result of a good mapper is
detected by a reducer. If the reducer is good,
it can be
inferred that the message received by the reducer must be
tampered somehow. Since the reducer knows IDM ap and P i,
the reducer will not accept the message unless the reducer
conﬁrms the integrity of the message. IDM ap can also be
the proof of the freshness of the signatures. For the same
reason, it is impossible that the message has been tampered.
Thus, the case that an inconsistency on a good mapper is
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:04:27 UTC from IEEE Xplore.  Restrictions apply. 
detected by a good reducer cannot be true. If the reducer is
a bad reducer, the reducer can report an inconsistency even if
there is no inconsistency. But, the veriﬁcation protocol requires
that the reducer present the evidence to the master, which is
described in Figure 4. And the reducer cannot forge evidence
without being detected by the master. Hence, the case that
an inconsistency on a good mapper is detected by a bad
reducer cannot be true, either. Therefore, the hypothesis that
an inconsistency on a good mapper is detected by a reducer
is not true.
Arguments of Non-Repudiation. We prove by contradic-
tion that SecureMR provides Non-Repudiation property in
terms of the two kinds of inconsistencies. Suppose that an
inconsistency is observed by the master or a good reducer.
Both the master and the good reducer deﬁnitely report the
inconsistency since they both tell the truth. Meanwhile, the
master holds the commitments of workers, which cannot be
denied, and the good reducer has the signatures of mappers.
They both can present the commitments or the signatures
of mappers to prove the inconsistency they detect. Thus,
SecureMR provides the Non-Repudiation property in terms of
the two kinds of inconsistencies.
B. Attacker Behavior Analysis
We analyze the behavior of the following attackers under
the two kinds of behavior models deﬁned in Section III-B.
When we analyze the collusive attacks, we consider the worst
case that all malicious entities are colluding with one another.
• Periodical Attackers: they misbehave with a certain prob-
ability pm. Since a naive attacker is a special case of
periodical attacker with pm equal to 1. Thus, we discuss
these two kinds of attacker’s behavior together.
• Strategic Attackers: with the assumption that they know
the duplication strategy, they may not behave maliciously
until they deﬁnitely know that they will not be caught
due to the collusion, which means that all duplicates are
assigned to the collusive group.
Deﬁnition V.1.
(Detection Rate) We deﬁne the detection
rate, denoted Drate, as the probability that the inconsistency
between results caused by the misbehavior of a mapper is
detected during l jobs.
Note that due to the paper space limit, we do not discuss
the inconsistency between the commitment and the result of a
mapper.
Since each map task processes one block, the duplication
of a map task is the same as the duplication of a block. The
following discussion may use both terms, block duplication
and map task duplication exchangeably. Suppose MapReduce
consists of one master and n workers, and m out of n workers
(m  0 and i = m.
P (D|Bi) =
pm
In Equation 2,
the detection rate is computed using the
law of total probability. The inconsistency cannot be detected
only if all duplicates for the block that the malicious mapper
processes are assigned to its collusive parties. P (D|Bi) is the
probability that the inconsistency is detected when the block
that the malicious mapper processes is duplicated i times.
If i >= m, at least one duplicate will not be assigned to
its collusive parties. Figure 8 shows how the detection rate
changes as the duplication rate and the percentage of malicious
workers change given n, pm, b, l equals to 50, 0.5, 20 and
15, respectively. From the ﬁgure, we observe that as long as
the majority of workers are good, 90% detection rate can be
achieved with 40% duplication rate.
Strategic attackers. Since the misbehavior of attackers
cannot be detected, we discuss the probability P (F ) that the
79
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:04:27 UTC from IEEE Xplore.  Restrictions apply. 
1.2
1
1
0.8
0.6
e
t
a
R
R
n
o
i
t
c
e
e
t
e
0.4D
1.2
1
1
0.8
0.6
e
t
a
R
R
n
o
i
t
c
e
e
t
e
0.4D
1.2
1
1
0.8
0.6
e
t
a
R
R
n
o
i
t
c
e
e
t
e
0.4D
0 2
0.2
0
0
0 2
0.2
0
0
0 2
0.2
0
0
1.2
1
1
0.8
0.6
0.4
y
t
t
i
l
i
b
a
b
o
o
r
P
e
v
a
a
h
e
b
s
i
M
0.2M
0 2
0
0
0
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
1
0
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
1
0
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
1
0
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
1
Duplication Rate
Duplication Rate
l=5
l=10
l=15
Duplication Rate
Duplication Rate
l=5
l=10
l=15
Duplication Rate
Duplication Rate
Duplication Rate
Duplication Rate
m/n=0.05,
m/n=0.10
m/n=0.15
m/n=0.05
m/n=0.10
m/n=0.15
Fig. 6.
Collusion Naive Attacker.
Detection Rate for Non-
Fig. 7.
Collusion Periodical Attacker.
Detection Rate for Non-
Fig. 8. Detection Rate for Collusion
Periodical Attacker.
Fig. 9. Misbehaving Probability vs
Duplication Rate.
intermediate result that reducers receive is tampered, which is
the same as the misbehaving probability of a strategic attacker.
In this case, we analyze the strategic attacker’s behavior in the
following two steps:
1) The master assigns b input blocks to b mappers before
any duplication is made.
2) The master duplicates b · pb input blocks after assign-
ments for the original b blocks. For each duplication, the
master randomly chooses one block from the original b
blocks to duplicate.
Therefore, P (F ) can be calculated by the following formula:
P (F |Ei) · P (Ei) =
P (Ai) · P (Mi) · P (Ei)
x
Xi=0
b · pb(cid:17)) ·(cid:16)m
(i/b)b·pb · ((cid:16)m − i
b · pb(cid:17)/(cid:16)n − b
i (cid:17) ·(cid:16)n − m
b − i (cid:17)/(cid:16)n
b(cid:17)
(3)
P (F ) =
=
x
x
Xi=0
Xi=0
where
x =(m if m = b.
b
Note that Ei and P (Ei) denote the event that mappers contain
i collusive mappers before input block duplication and the
probability that Ei happens, respectively. P (F |Ei) denotes
the probability that the result is tampered by some mappers
when Ei occurs. P (Ai) and P (Mi) denote the probability
that all duplicated blocks b · pb belong to the set of blocks
that the i collusive mappers process and the probability that
all duplicated blocks b · pb are assigned to the rest of mi’s
collusive workers. Figure 9 shows the misbehaving probability
of a strategic attacker when duplication rate and the percentage
of malicious workers change, where n, b, l equals to 50, 20
and 15, respectively. The result implies that the misbehaving
probability of a strategic attacker is pretty low even if the
duplication rate is only 10%.
Since strategic attackers can exchange information of tasks
with their collusive entities when they decide whether or not to
cheat in tasks, sometimes they can misbehave without being
detected. In order to address this vulnerability, we propose
a commitment-based task scheduling algorithm. Basically, the
commitment-based task scheduling algorithm will launch the
duplicates of a task only after the task has been committed. In
this case, when a strategic attacker initially processes a task,