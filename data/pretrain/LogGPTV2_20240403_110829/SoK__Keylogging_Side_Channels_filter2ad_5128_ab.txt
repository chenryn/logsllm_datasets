A. Metrics
Keylogging is a two-step process comprised of two distinct
problems: keystroke detection and key identiﬁcation. Keystroke
detection is the act of detecting that a keystroke has occurred
at some point in time, speciﬁcally in determining tP and/or
tR. Key identiﬁcation is the act of determining k, the phys-
ical key that was pressed, given that a keystroke has been
detected. While some metrics, such as Damerau–Levenshtein
edit distance [36], can simultaneously capture the performance
of both tasks, here we evaluate each task separately.
1) Keystroke Detection: Before a physical key is identiﬁed,
the presence of a keystroke must be established. If time is
sliced into successive windows of equal size, the problem of
keystroke detection amounts to deciding whether each window
contains a keystroke. As a binary classiﬁcation problem,
performance can be measured by standard metrics. The true
positive rate (TPR) is the rate at which keystrokes are correctly
detected and the true negative rate (TNR) is the rate at which
time windows that don’t contain a keystroke are correctly
labeled as such. Too many false negatives will lead to sparse
acquisition and provides little information, and too many false
positives will obfuscate the true keystrokes.
While perfect keystroke detection has TPR=TNR=1, there is
typically a tradeoff between TPR and TNR. With an acoustic
side channel, keystroke detection may be performed using an
energy threshold within a sliding window [37]. A threshold too
low will generate many spurious results, and a threshold too
high will fail to capture most true keystrokes. Similar tradeoffs
exist for WiFi signal distortion [5], memory access footprints
[7], and CPU load measurements [29].
2) Key Identiﬁcation: Unlike keystroke detection, key iden-
tiﬁcation is a multiclass classiﬁcation problem. Given a
keystroke has been detected, the problem of key identiﬁcation
is to determine which physical key on the keyboard was
pressed. In case of a keystroke sequence, this can also be
performed at the word level. There are |K|n ways to label a
sequence of n unknown keystrokes, where |K| is the cardinal-
ity of the set of all possible keys K.
The intrinsic entropy of a single keystroke with unknown
key k depends on the probability P [k] of each key k ∈ K,
H0 [k] = −
(cid:3)
k∈K
P [k] log2 P [k]
(1)
Maximum entropy is achieved when each key has an equal
probability of occurrence,
i.e., for uniform random input,
H0 = log2 |K|. Comparatively, the entropy of written English
214
Fig. 3. Key press time intervals reveal system timer resolution (top, Windows
64 Hz) and USB polling rate (bottom, Mac OS X 125 Hz). The timer has a
binning effect on the time intervals (left), resulting in peaks at harmonics of
the fundamental frequency in the power spectral density (PSD, right).
must retrieve the scancode and acknowledge the interrupt,
which also takes time, adding an additional constant delay.
However, when the interrupt is actually handled depends on the
scheduling policy of the kernel. This is largely determined by
the scheduling clock tick, which speciﬁes the time resolution
with which the scheduler advances. As keystroke events are
only handled on each timer interrupt, from the perspective
of an application running on the host, keystroke timings will
generally align to some multiple of the scheduling clock tick.
The effects of process scheduling and USB polling are
apparent when keystroke events are detected on or downstream
from the host, such as with CPU load [29] and network
trafﬁc [8]. Figure 3 shows the histogram and power spectral
density (PSD) of key press time intervals recorded in a web
browser on several different platforms. The system timer
has a binning effect on the time intervals, which are tightly
clustered around multiples of the scheduling clock tick. Peaks
in the PSD correspond to harmonics of the fundamental timer
frequency, which also reveals the scheduling clock tick. These
PSD signatures could be used to perform coarse-grained host
identiﬁcation: 64 Hz, or a 15.625 ms tick, is characteristic of
the Windows family [30] and 100 Hz of Mac OS X [31].
The Linux kernel has traditionally provided the option of
100, 250, 300, and 1000 Hz ticks through the CONFIG HZ
Kconﬁg parameter. On newer kernels, CONFIG NO HZ is
set by default, enabling a “tickless” system more suitable for
multimedia applications and power-constrained devices [32].
III. SIDE CHANNELS
A keylogging side channel attack involves leveraging an
unintended information source to determine which keyboard
keys were pressed. By this deﬁnition, a device or program that
senses keystrokes by directly intercepting the PS/2 or USB
signal [33], registering a system hook on the host computer
[34], or querying the keyboard state table [35], are not side
channel attacks since these methods operate through a channel
intended to provide information about
the keyboard state.
An unintended information source is an information source
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:29:41 UTC from IEEE Xplore.  Restrictions apply. 




Fig. 4.
Isomorphic 3-letter words in 1st order (left) and 2nd order (right) spatial side channels. Shaded blue circles denote measurement error.
is about 2 bits per character for 5-letter words and 1 bit per
character for sequences beyond 100 characters [38].
After an attacker has observed some side channel mea-
surement y,
the probability of each key having occurred
may change. This could be due to, e.g.,
the localization
of an acoustic emanation to either the left or right side of
the keyboard. The relative entropy of a keystroke, given a
measurement y from a side channel, is
P [k|y0] log2 P [k|y0]
(cid:3)
k∈K
P [y0|k]P [k]
k∈K P [y0|k]P [k] according to Bayes’ The-
(cid:4)
(2)
where P [k|y0] =
orem. The total relative entropy is given by
(cid:2)
H1 [k|y = y0] = −
H1 [k|y] =
P [y0] H1 [k|y = y0] dy0
(cid:5)
(3)
k∈K P [y0|k] P [k]. The side channel infor-
where P [y0] =
mation gain, or mutual information, is the difference between
the intrinsic entropy and relative entropy,
I [k; y] = H0 [k] − H1 [k|y]
(4)
which speciﬁes how many bits of entropy are leftover after
learning a measurement from the side channel. One may also
calculate the relative information gain,
IR [k; y] = I [k; y] /H0
(5)
which is the ratio of information gained to the intrinsic infor-
mation: IR = 0 indicates no change from the intrinsic entropy
and IR = 1 indicates that a single key has been positively
identiﬁed, analogous to perfect classiﬁcation accuracy.
B. Spatial Side Channels
A spatial side channel reveals the physical locations of
keys on the keyboard through spatial measurements. Attacks
of this kind may be performed through acoustic localization
[39], video of the keyboard [40], or WiFi signal distortion
induced by hand motion [5], to name a few. While most spatial
side channels require an external sensor to obtain spatial
measurements, physical key locations can also be sensed
through a side channel on the host computer, such as through
cache patterns correlated to speciﬁc keyboard keys [7].
There exist two types of spatial side channels: 1st order
spatial side channels are those that
indicate physical key
locations, for example by localizing the source of acoustic
emanations [39]; 2nd order spatial side channels provide only
the distances between physical keys, for example by measuring
the acoustic similarity between two different key presses [37].
is,
1) 1st Order Spatial: In a 1st order spatial side channel,
sensor measurements reveal physical key locations. However,
these measurements may not be exact. That
the key
locations might be known only to within some error. This
error could be due either to noise or the resolution of the
sensor. For example, attempting to localize the sound of a key
press with a microphone that has a 16 kHz sampling rate is
accurate only to within 2.1 cm since sound travels at 343 m/s.
The error could instead reﬂect a logical grouping of keys,
such as which scan column a key resides within [6]; in this
case, each measurement corresponds the set of keys along the
same scan column, and these keys may or may not be in
spatial proximity. Despite this, substantial information gains
can be achieved even with considerable measurement error as
demonstrated in this section.
As an example, Figure 4 (left) shows three spatial mea-
surements with ±1 u error observed when the user types the
word “com”. Let k1, k2, k3 be the sequence of unknown keys
to an adversary. Assuming uniform error in every direction,
each measurement covers an area with radius 1 u, limiting
the number of possibilities for each ki. That is, k1 ∈{X,C,V},
k2 ∈{I,O,P}, and k3 ∈{N,M}. For randomly-typed letter-only
input, such as a password, this limits the number of possible
sequences from 26 × 26 × 26 = 17576 (H0 = 14.10 bits) to
3 × 3 × 2 = 18 (H1 = 4.17 bits), an information gain of 9.93
bits (0.70 relative information gain).
If we assume the user is typing an English word, the number
of possible sequences is limited even further. Only English
words with letter sequences that fall within the measurement
error need to be considered. One possibility, shown by the
red dots in Figure 4 (left), is the word “vpn” since the V,
P, and N keys are each within 1 u proximity to the C,
O, and M keys. Generally, the spatial constraints given by
this particular measurement can be captured by the regular
expression (regex): “ˆ[xcv][iop][nm]$”. Matching this regex
to a dictionary of the 10k most common English words gives
4 possible results: “com”, “con”, “von”, and “vpn”, out of
672 3-letter words, a reduction of 9.39 − 2.00 = 7.39 bits
(0.79 relative information gain, assuming each word occurs
with probability P [w] = 1
To get a sense of how spatial measurement error affects
information gain, the above procedure is used to calculate
the relative information gain for each word in a dictionary
comprised of the 10k most common words since year 2000
from the Google Web Trillion Word Corpus [41]. Figure 5
(top left) shows the relative information gain as word length
672).
215
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:29:41 UTC from IEEE Xplore.  Restrictions apply. 
distance matrix is compared to the distance matrix of every
other word of same length in the dictionary, matching words
that are within the measurement error. Note that unlike a 1st
order spatial side channel, the 2nd order spatial measurement
error is over distances and not locations. Figure 5 (bottom left)
shows the relative information gain for a 2nd order spatial
side channel with ±0.5 u error. The relative information gain
for words of 1 letter is 0 since no distances are observed.
Figure 5 (bottom right) shows the relative information gain as
measurement error increases.
In the worst case, a distance function can be binary valued,
in that it indicates only whether two keys are the same or
different. This effect could be achieved by thresholding the
distance matrix [42], revealing the unique characters in a word
but not the characters themselves, much like a monoalphabetic
substitution cipher. In this case, words can be matched using
an extended regular expression. For example, the regex for “at-
tack” would be “ˆ(.)((?!\1).)\2\1((?!\1|\2).)((?!\1|\2|\3).)$”
which matches the words “effect”, “attach”, “affair”, “at-
tain”, and “oppose”. Note that this method only provides a
substantial reduction in the search space if there are letter
repetitions. The number of matches for “social” (or any 6 letter
word without character repetitions, which have the same regex
pattern) is 784 out of 1543 6-letter words, an information gain
of about 1 bit.
C. Temporal Side Channels
There are two events associated with every keystroke: press
and release, with respective timings given by tP and tR.
A temporal keylogging side channel uses the sequence of
keystroke timings, tP and/or tR, to predict which keys were
pressed, exploiting the consistent and predictable way in which
a victim types. As noted by Salthouse, touch typists exhibit a
number of phenomena related to the dependence of keystroke
timings on physical key placement [43], [44], such as:
• Keys that are far apart are pressed in quicker succession
than keys that are close together.
• Letter pairs that occur frequently in language are typed
in quicker succession than infrequent letter pairs.
• Practicing a speciﬁc keystroke sequence can signiﬁcantly
reduce inter-key timings.
These phenomena, among others, are the basis for exploiting
the relative information between physical key locations and
keystroke timings. Analogous to spatial side channels, a tem-
poral side channel can reveal either individual keys, through
the key-hold duration, or key pairs, through the time intervals
between successive keystrokes.
1) Duration: The duration of a keystroke is the time
interval from press to release, with the ith duration given by
(6)
i − tP
di = tR
i
which can be used to identify individual keys. Typists may
generally hold down different keys for different lengths of
time, permitting an adversary to infer which key was pressed
(or which keys were more likely pressed) based on the ob-
served duration. This phenomenon is shown in Figure 6 (left)
216
Fig. 5. Spatial info gain vs word length (left) and measurement error (right).
increases given ±1 u measurement error. At 6 letters, words are
almost determined with certainty, reﬂected by the near perfect
relative information gain.
Figure 5 (top right) shows the relative information gain of
different word lengths for increasing measurement error. At
±4 u, gains begin to drop below 0.50, and beyond ±7 u error,
almost no information is gained. Note that 0 information gain
is achieved for ±10 u since this radius spans the length of letter
keys on the keyboard, and error less than ±1 u can achieve
perfect accuracy since no error radius overlaps any other key.
2) 2nd Order Spatial: A spatial side channel is 2nd order
if it provides the distances between key locations as opposed
to the key locations themselves. This may occur if an attacker
observes a function that measures the distance or similarity
between pairs of physical keys. For example, consider the
acoustic emanations captured by a single microphone. Al-
though localization is not possible, different keys have been
shown to retain different acoustic signatures [39]. Comparing
the acoustic waveform of two different key presses enables
an adversary to differentiate between pairs of keys, despite
not knowing the key identities. Further, keys that are within
spatial proximity typically produce similar sounds which can
actually reveal the physical inter-key distances [37]. In this
way, a context-free attack can be performed, omitting the need
for a pre-trained classiﬁer.
Since a 2nd order spatial side channel uses the distances
between keys, it is the key pairs and not individual keys that
are recognized. As shown in Figure 4 (right), consider typing
the word “com” with distances 5.6 u, 2.4 u, and 4.0 u between
keys C-O, O-M, and C-M, respectively. With a measurement
error of ±0.5 u, the word “sky” is isomorphic to “com” since
it has distances 6.0 u, 2.5 u, and 3.9 u between keys S-K,
K-Y, and S-Y, respectively. Generally, for a sequence of n
keystrokes, there are n(n−1)
unique distances in the distance
matrix formed by the key pairs.
2
Using the same dictionary in the previous section,
the
relative information gain for each word is calculated. First,
the inter-key distance matrix for each word is computed. This
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:29:41 UTC from IEEE Xplore.  Restrictions apply. 
PEARSON’S CORRELATION BETWEEN INFORMATION GAIN AND TYPING
SPEED. BOLD p-VALUES INDICATE SIGNIFICANCE AT A 0.05 THRESHOLD.
TABLE I
Pearson’s r
p-value
Du
-0.156
3.6e-07
PP
-0.011
7.3e-01
PR
-0.113
2.3e-04
RP
0.211
3.9e-12
RR
0.107
5.7e-04
and RR latencies can be negative when the release of the ﬁrst
key overlaps the press or release of the second key, respectively
(commonly encountered for modiﬁer keys, such as Shift). The
information gain for each latency feature is shown in Figure 7
(left), where intrinsic entropy H0 = 6.57 bits since there are 95
unique bigrams. For this particular user, each latency feature
provides about twice as much total information as duration.
Again, information gains are greatest for extremely large or
small latency values since these occur less frequently.
3) Users and Typing Speed: The previous sections exam-
ined information gain for a single representative user. How-
ever, since a temporal side channel exploits the predictable
way a user types, information gain could vary with different
users based on different typing speeds and styles [46]. Using
the same procedure to calculate I, Figure 7 (right) shows the
per-user information gains for each of the 1060 users in the
same dataset [45]. For the majority of users, duration provides
between 0.15 and 0.30 bits of information and each latency
between 0.5 and 0.9 bits with RP latency usually providing
the most. These results suggest that temporal side channel
information gain is highly user-dependent.
A question then arises as to what user-dependent factors
might determine the amount of information that can be gained
through a temporal side channel. We examined the relationship
between information gain and typing speed as given by the
number of keystrokes per minute (KPM), excluding non-letter
keys and latencies over 1 s. We found that the information
gained from duration decreases with increasing typing speed,
and for latency features, the opposite is generally true. Except
for PP latency, the correlations are signiﬁcant, with Pearson’s
r and the corresponding p-value for each feature summarized