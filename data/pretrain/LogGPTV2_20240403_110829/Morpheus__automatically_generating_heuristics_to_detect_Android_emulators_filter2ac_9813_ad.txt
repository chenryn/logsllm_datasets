### 5.2.1 Application Sandbox Reinforcement

We argue that a well-configured application sandbox is essential in this environment to prevent applications from bypassing the APIs. Unfortunately, our discovered file and property heuristics suggest that the current sandbox should be reinforced.

### 5.2.2 Type E and Type D Heuristics

| **Heuristic Type** | **Accuracy** |
|-------------------|--------------|
| Type E Heuristics | 89.9%        |
| Type D Heuristics | 79.4%        |

We investigated the differences between Type E and Type D heuristics. As discussed in Section 3.3, Type E and Type D detection heuristics respectively indicate emulators and real devices. In our experiments, Type E heuristics outperformed Type D heuristics.

We observed that almost all of the heuristics with low specificities in Table 4 are of Type D. This is likely due to the diversified and fragmented nature of real devices. Type D heuristics expect artifacts or tokens that are prevalent in real devices. However, device manufacturers often customize devices and change artifacts, making it difficult to find consistent artifacts across all real devices. In contrast, emulators are more uniform in terms of customizations, possibly due to the difficulty in modifying and maintaining software-emulated hardware.

### 5.2.3 Artifact-based and Content-based Heuristics

| **Heuristic Type** | **Accuracy** |
|-------------------|--------------|
| Artifact-based Heuristics | 95.3%        |
| Content-based Heuristics | 77.0%        |

Finally, we compared artifact-based and content-based heuristics. The bar chart shows that artifact-based heuristics had an average accuracy of 95.3%, while content-based heuristics had an accuracy of 77.0%. However, we note that F1, F4, and P9, which are also content-based heuristics, were among the top 30 heuristics in terms of accuracy.

In addition to the factors of abstraction and customization, a possible explanation for the lower accuracy of content-based heuristics is their vulnerability to intended or unintended changes. Content-based heuristics exploit the contents of artifacts (e.g., configurations), which can change in a rapidly evolving system like Android. In contrast, artifact-based heuristics rely on the presence of certain artifacts. These artifacts (e.g., kernel modules) are relatively consistent in both emulators and real devices, as developers are generally reluctant to remove them to avoid unexpected problems.

### 5.3 Case Study: A9

We present a case study on heuristic A9, which involves the Android API `getDeviceId`, a popular method among known detection heuristics. A9 uses this API but in a slightly different way, looking for a token “\0\0\03” in the Binder IPC message returned from the implementation of `getDeviceId` in `TelephonyManagerService`. Specifically, A9 uses IMEIs whose first character is “3” to indicate real devices. However, A9 had a sensitivity of 66.7% and a specificity of 43.8%. We investigated the evaluated emulators and real devices to understand their reactions to A9, leading us to identify flaws in an existing anti-detection technique and propose improvements for A9.

#### 5.3.1 A9 vs DroidBox 4.1

As discussed in Section 4.1, our implementation of the artifact retriever uses a Java function caller and a Binder IPC caller to probe Android APIs. When testing A9 against DroidBox 4.1, we found that these two callers returned different values: “357242043237511” and “000000000000000”. Both callers should return the same value because the application-side Binder proxies of Android APIs are not supposed to modify the IPC messages returned by the underlying Binder stubs in system services.

Upon inspecting DroidBox’s source code, we found that DroidBox rewrites the Binder proxy of `getDeviceId` to return a dummy IMEI without involving the Binder stubs. While this countermeasure neutralizes the detection heuristics that call `getDeviceId` in a normal way, it is ineffective against the Binder IPC caller, which bypasses the countermeasure and reads the actual full-zero IMEI. Therefore, the countermeasure in DroidBox 4.1 is incomplete. We note that ApkScan demonstrated the same issue, suggesting that ApkScan might have integrated DroidBox 4.1 for its dynamic analysis.

However, A9 was not effective against DroidBox 2.3. DroidBox 2.3 implements a similar countermeasure but does so in the service-side Binder stub. In this case, bypassing the stub and observing the actual IMEI would require root privileges, making the actual IMEI unobservable. Thus, such a countermeasure is effective, and the dummy IMEI appears realistic.

#### 5.3.2 A9 vs Non-U.S. Devices

A9 assumes that an Android device whose IMEI starts with “3” is a real device, otherwise it is an emulator. We checked the IMEIs of 128 real devices and found this assumption to be incorrect.

According to the IMEI Allocation and Approval Guidelines [7], the first digit of an IMEI is part of the Reporting Body Identifier (RBI), which identifies the GSMA-approved authority that issues the IMEI. Typically, IMEIs of mobile devices are issued by authorities in the same area where the devices are sold. For example, IMEIs of devices sold in the U.S. start with “35,” issued by the British Approvals Board for Telecommunications (BABT). Similarly, IMEIs of devices sold in China start with “86.”

We noted that about half of the 128 evaluated real devices were from Baidu MTC, which uses Android phones sold in China. Since A9 was based on U.S. devices, it naturally had a low specificity. A9 could be improved by using wildcards to match multiple RBIs.

The lesson from A9 illustrates the ongoing arms race between emulator detection and anti-detection. First, Android malware could check the semantics of observed artifacts. For example, the dummy IMEI in DroidBox 4.1 is invalid and could be noticed by a sophisticated adversary. Second, emulator-based malware analysis tools should consider the observability of actual artifacts and the semantics of dummy artifacts to make them less distinguishable.

### 6. DISCUSSION

The evaluation results imply an imminent threat that Android malware may thwart existing emulator-based dynamic analysis systems. In this section, we suggest potential countermeasures and discuss the limitations of our work.

#### 6.1 Countermeasures

**Provisional Countermeasures:** We suggest methods to detect the usage of detection heuristics in Android malware as provisional countermeasures. Although they do not prevent Android malware from detecting Android emulators, they can raise alarms for analysts and thus thwart the malware’s purpose of evading analysis. For example, dynamic analysis systems could monitor accesses to files and properties seldom used by benign applications. API heuristics are more stealthy because benign applications also frequently use them. In such cases, we suggest static data-flow analysis to locate branches involving detection heuristics and leading to disparate code blocks.

**Short-term Countermeasures:** Next, we discuss countermeasures that allow an emulator to appear realistic to Android malware. First, we suggest a comprehensive deployment of dummy artifacts. Some existing works can be adapted to facilitate such countermeasures. For example, AirBag [26] supports a decoupled and isolated runtime environment based on OS-level virtualization. ASM [13] provides programmable interfaces that interpose Android APIs and return dummy values to applications. Combining and extending these works can enable a “brain in a vat” setup where an application runs in an emulator but receives dummy and valid data from real devices. Second, we suggest denying access to unnecessary observable artifacts with strict DAC and MAC policies. For example, artifacts in sysfs exploited by our file heuristics seem unnecessary for general Android applications. However, the usability impact of denying access still needs further verification.

**Long-term Countermeasures:** The ideal countermeasure is to fix all discrepancies in Android emulators. Although Garfinkel et al. [12] concluded in 2007 that creating indistinguishable software-emulated hardware is infeasible, hardware-assisted virtualization techniques (e.g., Intel VT-x and VT-d) have evolved significantly to allow PC emulators to virtualize real hardware. Currently, ARM CPUs have integrated necessary virtualization extensions, and commodity ARM hypervisors are in active development. We envision emerging Android emulators equipped with virtualized CPUs, sensors, and radios in the near future.

#### 6.2 Limitations

Despite the robustness of Morpheus, the quality of the discovered detection heuristics is limited by the small number of real devices used in finding detection heuristics (Section 4). Morpheus works like supervised learning, and its performance depends on the quality of the “training set,” i.e., the emulators and real devices observed by the artifact retriever. The artifact retriever requires approximately 20 minutes to collect artifacts on a single device. Unfortunately, online services like AppThwack (Section 5) do not allow the artifact retriever to run for such a long time or upload large bulks of data. For future work, we plan to reach out to mobile carriers and device vendors to collect observable artifacts from more real devices.

Although Morpheus discovered over 10,000 heuristics, they were derived from only 3 out of 33 sources of observable artifacts. To better understand the scope of detection heuristics for effective countermeasures, the artifact retriever could be enhanced to address more sources of artifacts and sophisticated usages. Examples include extended modules of the artifact retriever that can handle callbacks or construct valid input parameters for Android APIs. We did not cover these in this work because they require domain-specific knowledge of each Android system service.

Our heuristic generator produces relatively rigid heuristics, such as A9, which does not match multiple RBIs. This can be improved with more sophisticated and flexible heuristics. For example, a token-sequence heuristic matches an ordered set of tokens in the contents of an artifact. Additionally, a naïve Bayes heuristic enables probabilistic matching by aggregating the empirical probabilities of multiple artifact/token heuristics using Bayes’ law, assuming the occurrences of artifacts/tokens are independent.

### 7. RELATED WORK

**Behavior-based Detection Heuristics:** Researchers have proposed several heuristics that exploit discrepancies in runtime behaviors rather than artifacts. For instance, specially crafted native code can identify QEMU-based emulators due to discrepancies in QEMU’s caching behaviors [19, 21, 24]. Low video frame rate indicates emulators due to the performance drawbacks in the SDK emulator’s graphics rendering engine [25]. However, these heuristics have not been evaluated against VirtualBox-based emulators and real devices, so their sensitivities and specificities require further investigation. Additionally, these heuristics do not return a decision until a sufficient number of events are observed, which increases their footprints and attracts analysis. Morpheus addresses artifact-based and content-based detection heuristics and generates detection heuristics automatically and systematically.

**Dynamic Analysis Frameworks:** Researchers have built several dynamic analysis frameworks to vet the runtime behaviors of Android malware. TaintDroid [10] tracks information flows that leak sensitive data to the Internet. VetDroid [28] further reveals information flows involving permissions. AppIntent [27] helps determine if an information flow is user-intended. Some of these tools have been integrated into automated malware analysis systems such as DroidBox [5], Andrubis [6], CopperDroid [23], SandDroid [3], and TraceDroid [4]. These systems are vulnerable to evasion using the detection heuristics in this work if deployed in Android emulators.

### 8. CONCLUSION

Recent Android malware demonstrates the capability to detect Android emulators using detection heuristics. To convey the severity of this problem, we presented Morpheus, a system that automatically and systematically generates detection heuristics. Morpheus analyzes artifacts observable by Android applications and discovers exploitable discrepancies in Android emulators. We described a proof-of-concept implementation of Morpheus, along with extensive experiments and findings.

### Acknowledgements

We would like to thank Adam Doupé and the anonymous reviewers for their valuable comments that helped improve the presentation of this paper. This work was supported in part by the National Science Foundation under Grant CNS-0916688 and the National Research Foundation under Grant NRF-2014K1A1A2043029.

### 9. REFERENCES

[1] Android developers - using the emulator. http://developer.android.com/tools/devices/emulator.html. Accessed: May 2014.
[2] Genymotion, the fastest android emulator for app testing and presentation. http://genymotion.com. Accessed: May 2014.
[3] Sanddroid - an APK analysis sandbox. http://sanddroid.xjtu.edu.cn/. Accessed: May 2014.
[4] Tracedroid - dynamic Android app analysis (by VU Amsterdam). http://tracedroid.few.vu.nl/. Accessed: May 2014.
[5] Droidbox: An Android application sandbox for dynamic analysis. https://code.google.com/p/droidbox/, 2011. Accessed: May 2014.
[6] Andrubis: A tool for analyzing unknown Android applications. http://blog.iseclab.org/2012/06/04/andrubis-a-tool-for-analyzing-unknown-android-applications-2/, June 2012. Accessed: May 2014.
[7] G. Association et al. IMEI allocation and approval guidelines. Volume 10, 2010.
[8] D. Balzarotti, M. Cova, C. Karlberger, C. Kruegel, E. Kirda, and G. Vigna. Efficient detection of split personalities in malware. In Proceedings of Network and Distributed System Security Symposium, 2010.
[9] H. Dharmdasani. Android.Hehe: Malware now disconnects phone calls. http://www.fireeye.com/blog/technical/2014/01/android-hehe-malware-now-disconnects-phone-calls.html, January 2014. Accessed: May 2014.
[10] W. Enck, P. Gilbert, B.-G. Chun, L. P. Cox, J. Jung, P. McDaniel, and A. N. Sheth. TaintDroid: An information-flow tracking system for real-time privacy monitoring on smartphones. In Proceedings of the USENIX conference on Operating Systems Design and Implementation, pages 1–6. USENIX, 2010.
[11] F-Secure. Trojan:Android/Pincer.A. http://www.f-secure.com/weblog/archives/00002538.html, April 2013. Accessed: May 2014.
[12] T. Garfinkel, K. Adams, A. Warfield, and J. Franklin. Compatibility is not transparency: VMM detection myths and realities. In Proceedings of USENIX Workshop on Hot Topics in Operating Systems, 2007.
[13] S. Heuser, A. Nadkarni, W. Enck, and A.-R. Sadeghi. ASM: A programmable interface for extending Android security. In Proceedings of the USENIX Security Symposium, 2014.
[14] T. K. Ho. The random subspace method for constructing decision forests. IEEE Transactions on Pattern Analysis and Machine Intelligence, 20(8):832–844, 1998.
[15] C. Ionescu. Obfuscating embedded malware on Android. http://www.symantec.com/connect/blogs/obfuscating-embedded-malware-android, June 2012. Accessed: May 2014.
[16] Z. Li, M. Sanghi, Y. Chen, M.-Y. Kao, and B. Chavez. Hamsa: Fast signature generation for zero-day polymorphic worms with provable attack resilience. In Proceedings of the IEEE Symposium on Security and Privacy, pages 15–pp. IEEE, 2006.
[17] H. Lockheimer. Android and security. http://googlemobile.blogspot.com/2012/02/android-and-security.html, February 2012. Accessed: May 2014.
[18] I. Lunden. Gartner: 102B app store downloads globally in 2013, 26B in sales, 17% from in-app purchases. http://techcrunch.com/2013/09/19/gartner-102b-app-store-downloads-globally-in-2013-26b-in-sales-17-from-in-app-purchases/, September 2013. Accessed: May 2014.
[19] F. Matenaar and P. Schulz. Detecting Android sandboxes. http://dexlabs.org/blog/btdetect, August 2012. Accessed: May 2014.
[20] J. Oberheide and C. Miller. Dissecting the Android bouncer. SummerCon2012, New York, 2012.
[21] T. Petsas, G. Voyatzis, E. Athanasopoulos, M. Polychronakis, and S. Ioannidis. Rage against the virtual machine: Hindering dynamic analysis of Android malware. In Proceedings of the European Workshop on System Security, page 5. ACM, 2014.
[22] S. Rasthofer, S. Arzt, and E. Bodden. A machine-learning approach for classifying and categorizing Android sources and sinks. In Proceedings of the Network and Distributed System Security Symposium, 2014.
[23] A. Reina, A. Fattori, and L. Cavallaro. A system call-centric analysis and stimulation technique to automatically reconstruct Android malware behaviors. In Proceedings of the European Workshop on System Security, April 2013.
[24] P. Schulz. Android emulator detection by observing low-level caching behavior. https://bluebox.com/technical/android-emulator-detection-by-observing-low-level-caching-behavior/, December 2013. Accessed: May 2014.
[25] T. Vidas and N. Christin. Evading Android runtime analysis via sandbox detection. In Proceedings of the ACM Symposium on Information, Computer and Communications Security. ACM, 2014.
[26] C. Wu, Y. Zhou, K. Patel, Z. Liang, and X. Jiang. Airbag: Boosting smartphone resistance to malware infection. In Proceedings of the Network and Distributed System Security Symposium, 2014.
[27] Z. Yang, M. Yang, Y. Zhang, G. Gu, P. Ning, and X. S. Wang. AppIntent: Analyzing sensitive data transmission in Android for privacy leakage detection. In Proceedings of the ACM conference on Computer and Communications Security, pages 1043–1054. ACM.
[28] Y. Zhang, M. Yang, B. Xu, Z. Yang, G. Gu, P. Ning, X. S. Wang, and B. Zang. Vetting undesirable behaviors in Android apps with permission use analysis. In Proceedings of the ACM conference on Computer and Communications Security, pages 611–622. ACM, 2013.
[29] Y. Zhou and X. Jiang. Dissecting Android malware: Characterization and evolution. In Proceedings of the 2012 IEEE Symposium on Security and Privacy, pages 95–109. IEEE, 2012.
[30] Y. Zhou, Z. Wang, W. Zhou, and X. Jiang. Hey, you, get off of my market: Detecting malicious apps in official and alternative Android markets. In Proceedings of the Network and Distributed System Security Symposium, pages 5–8, 2012.