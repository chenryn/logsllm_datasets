removed or deprecated. However, we argue that this envi-
ronment also requires a well-conﬁgured application sandbox
to prevent applications from bypassing the APIs. Unfortu-
nately, our discovered ﬁle and property heuristics imply that
the current sandbox should be reinforced.
5.2.2 Type E and Type D Heuristics
y
c
a
r
u
c
c
A
Type E heuristics
Type D heuristics
89.9%
79.4%
0%
20%
40%
60%
80%
100%
We investigated the diﬀerences between the Type E and
Type D heuristics. As we have discussed in Section 3.3,
Type E and Type D detection heuristics respectively indi-
cate emulators and real devices.
In our experiments, the
Type E heuristics outperformed the Type D ones.
We note that almost all of the heuristics in Table 4 with
low speciﬁcities are of Type D. We believe that it is due to
the diversiﬁed and fragmented nature of real devices. Type
D heuristics expect the artifacts/tokens that are prevalent in
real devices. However, device manufacturers inevitably cus-
tomize devices and change artifacts, which makes it harder
to ﬁnd the artifacts that exist in every real device. On the
contrary, emulators are much more uniﬁed in terms of cus-
tomizations, which is possibly due to the diﬃculty in modi-
fying and maintaining software-emulated hardware.
5.2.3 Artifact-based and Content-based Heuristics
y
c
a
r
u
c
c
A
Artifact-based heuristics
Content-based heuristics
95.3%
77.0%
0%
20%
40%
60%
80%
100%
Finally, we compared the artifact-based and content-based
heuristics. The bar chart shows that the artifact-based heuris-
tics had an average accuracy of 95.3%. The content-based
heuristics fell behind with 77.0%. However, we stress that
F1, F4, and P9 are also content-based heuristics and their
accuracies were among the top of the 30 heuristics.
In addition to the factors of abstraction and customiza-
tion that we discussed earlier, a possible explanation is that
content-based heuristics are more subtle and vulnerable to
intended or unintended changes. Content-based heuristics
exploit artifacts’ contents (e.g., conﬁgurations), which are
subject to change in a rapidly evolving system like Android.
On the contrary, artifact-based heuristics rely on the pres-
ence of certain artifacts. Compared with the contents, the
artifacts (e.g., kernel modules) are relatively consistent in
emulators and real devices, because developers are usually
reluctant to remove them as to avoid unexpected problems.
5.3 Case Study: A9
Finally, we present a case study on heuristic A9 because
it involves an Android API getDeviceId, which has been
popular among the known detection heuristics. A9 exploits
the same API but in a slightly diﬀerent way. Speciﬁcally,
it looks for a token “\0\0\03” in the Binder IPC message
returned from the implementation of getDeviceId in Tele-
phonyManagerService. In other words, A9 uses the IMEIs
whose ﬁrst character is “3” to indicate real devices. However,
it turned out that A9 had a sensitivity of 66.7% and an un-
bearable speciﬁcity of 43.8%. We investigated the evaluated
emulators and real devices to ﬁnd out how they reacted to
A9. The investigation led us to ﬂaws in an existing anti-
detection technique and improvements for A9.
5.3.1 A9 vs DroidBox 4.1
As we discussed in Section 4.1, our implementation of
the artifact retriever employs a Java function caller and a
Binder IPC caller to probe Android APIs. When we tested
A9 against DroidBox 4.1, we found that these two callers
returned disparate values, namely “357242043237511” and
“000000000000000.” We note that both callers should re-
turn the same value, because the application-side Binder
proxies of Android APIs are not supposed to modify the
IPC messages returned by the underlying Binder stubs in
system services.
We inspected DroidBox’s source code and found that Droid-
Box rewrites the Binder proxy of getDeviceId to return a
dummy IMEI without involving the Binder stubs. Although
such a countermeasure could neutralize the detection heuris-
tics that call getDeviceId in a normal way, it is not eﬀec-
tive against the Binder IPC caller, which bypasses the coun-
termeasure and reads the actual full-zero IMEI. Therefore,
we believe that the countermeasure implemented in Droid-
Box 4.1 is not complete. We note that ApkScan demon-
strated the same issue, implying that ApkScan might have
integrated DroidBox 4.1 for its dynamic analysis.
However, A9 was not eﬀective against DroidBox 2.3. We
found that DroidBox 2.3 opts for a similar countermeasure
but implements it in the service-side Binder stub. In such
a case, bypassing the stub and observing the actual IMEI
would require root privileges, i.e., the actual IMEI is not
observable. Therefore, such a countermeasure is eﬀective
and the dummy IMEI would appear realistic.
5.3.2 A9 vs Non-U.S. Devices
A9 assumes that an Android device whose IMEI starts
with “3” is a real device, otherwise it is an emulator. We
checked the IMEIs of the 128 real devices and found that
this assumption is incorrect.
According to IMEI Allocation and Approval Guidelines [7],
the ﬁrst digit of an IMEI is part of Reporting Body Iden-
tiﬁer (RBI), which identiﬁes the GSMA-approved authority
that issues the IMEI. Typically, IMEIs of mobile devices are
issued by the authorities in the same area where the de-
vices are sold. For example, IMEIs of the devices sold in the
U.S. are issued by the British Approvals Board for Telecom-
munications (BABT) and thus start with BABT’s code “35.”
Similarly, IMEIs of the devices sold in China start with “86.”
We note that about half of the 128 evaluated real devices
were from Baidu MTC that uses Android phones sold in
China. Given that A9 was based on the devices in the U.S.,
A9 naturally got a low speciﬁcity, and it could be improved
with wild cards that match multiple RBIs.
The lesson of A9 indeed illustrates the future of the armed
race between emulator detection and anti-detection. First,
Android malware could check the semantics of the observed
artifacts. For example, the dummy IMEI in DroidBox 4.1
is invalid and could be noticed by a sophisticated adversary.
Second, emulator-based malware analysis tools should con-
sider the observability of actual artifacts and the semantics
of dummy artifacts to be less distinguishable.
6. DISCUSSION
The evaluation results imply an imminent threat that An-
droid malware may thwart existing emulator-based dynamic
analysis systems. In this section, we suggest the potential
countermeasures and discuss the limitations of our work.
6.1 Countermeasures
Provisional countermeasures. We suggest the meth-
ods that detect the usage of detection heuristics in Android
malware as provisional countermeasures. Although they do
not prevent Android malware from detecting Android em-
ulators, they can raise alarms for analysts and thus thwart
the malware’s original purpose of evading analysis. For ex-
ample, dynamic analysis systems could monitor accesses on
ﬁles and properties seldom used by benign applications. API
heuristics are much more stealthy because benign applica-
tions also frequently use them. In such a case, we suggest
static data-ﬂow analysis to locate branches that involve de-
tection heuristics and lead to disparate code blocks.
Short-term countermeasures. Next, we discuss the
countermeasures that allow an emulator to appear “realis-
tic” to Android malware. First, we suggest a comprehensive
deployment of dummy artifacts. Some existing works can
be adapted to facilitate such countermeasures. For exam-
ple, AirBag [26] supports a decoupled and isolated runtime
environment based on OS-level virtualization. ASM [13] pro-
vides programmable interfaces that interpose Android APIs
and return dummy values to applications. These works, if
combined and extended, can enable a “brain in a vat” setup
where an application runs in an emulator but gets dummy
and valid data originated from real devices. Second, we
suggest denying accesses on unnecessary observable artifacts
with strict DAC and MAC policies. For example, artifacts
in sysfs exploited by our ﬁle heuristics seem unnecessary for
general Android applications. However, the usability impact
of denying accesses still needs further veriﬁcation.
Long-term countermeasures. The ideal countermea-
sure is to ﬁx all the discrepancies in Android emulators.
Although Garﬁnkel et al. [12] concludes its infeasibility in
2007 due to the inherent hardness of creating indistinguish-
able software-emulated hardware, hardware-assisted virtual-
ization techniques (e.g., Intel VT-x and VT-d) have evolved
signiﬁcantly to allow PC emulators to virtualize real hard-
ware. Currently, ARM CPUs have integrated necessary vir-
tualization extensions. Meanwhile, commodity ARM hyper-
visors are also in active development. We envision emerging
Android emulators equipped with virtualized CPUs, sensors,
and radios in the near future.
6.2 Limitations
Despite the robustness of Morpheus, the quality of the dis-
covered detection heuristics is limited by the small number of
real devices used in ﬁnding detection heuristics (Section 4).
In general, Morpheus works like supervised learning, and its
performance inevitably depends on the quality of the “train-
ing set,” i.e., the emulators and real devices observed by the
artifact retriever. We note that the artifact retriever needs
approximately 20 minutes to collect the artifacts on a single
device. Unfortunately, online services like AppThwack (Sec-
tion 5) do not allow the artifact retriever to run for such a
long time or upload large bulks of data. As for future work,
we plan to reach out to mobile carriers and device vendors
to collect observable artifacts from more real devices.
Although Morpheus discovered more than 10,000 heuris-
tics, we stress that they were derived only from 3 out of
33 sources of observable artifacts. To better understand
the scope of detection heuristics for eﬀective countermea-
sures, the artifact retriever could be enhanced to address
more sources of artifacts as well as sophisticated usages of
them. Examples include extended modules of the artifact
retriever that can handle callbacks or construct valid input
parameters for Android APIs. We did not cover them in
this work because they require domain-speciﬁc knowledge
of each Android system service.
Our heuristic generator produces relatively rigid heuris-
tics, such as A9 that does not match multiple RBIs. This
can be improved with more sophisticated and ﬂexible heuris-
tics. For example, a token-sequence heuristic matches an
ordered set of tokens in the contents of an artifact. More-
over, a na¨ıve Bayes heuristic enables probabilistic matching
by aggregating the empirical probabilities of multiple arti-
fact/token heuristics with the Bayes’ law, assuming that the
occurrences of artifacts/tokens are independent.
7. RELATED WORK
Behavior-based detection heuristics.
Researchers
have proposed several heuristics that exploit discrepancies
in runtime behaviors rather than artifacts. For instance,
a piece of specially crafted native code can identify QEMU-
based emulators due to the discrepancies in QEMU’s caching
behaviors [19, 21, 24]. Low video frame rate indicates emu-
lators because of the performance drawbacks in the SDK
emulator’s graphics rendering engine [25]. However, these
heuristics are not evaluated against VirtualBox-based emu-
lators and real devices. Thus, their sensitivities and speciﬁci-
ties require further investigation. In addition, these heuris-
tics do not return a decision until a suﬃcient number of
events are observed, which tends to increase their footprints
and attract analysis. Along these lines, Morpheus addresses
artifact-based and content-based detection heuristics. More
importantly, Morpheus generates detection heuristics auto-
matically and systematically.
Dynamic analysis frameworks.
Researchers have
built several dynamic analysis frameworks to vet the run-
time behaviors of Android malware. TaintDroid [10] tracks
information ﬂows that leak sensitive data to the Internet.
VetDroid [28] further reveals information ﬂows that involve
permissions. AppIntent [27] helps determine if an informa-
tion ﬂow is user-intended. Some of these tools have been
integrated into automated malware analysis systems such as
DroidBox [5], Andrubis [6], CopperDroid [23], SandDroid [3],
and TraceDroid [4]. They are vulnerable to be evaded us-
ing the detection heuristics in this work as long as they are
deployed in Android emulators.
8. CONCLUSION
Recent Android malware demonstrates the capabilities of
detecting Android emulators using detection heuristics. To
convey the severity of this problem, we have presented Mor-
pheus, a system that automatically and systematically gen-
erates detection heuristics. Morpheus analyzes artifacts ob-
servable by Android applications and discovers exploitable
discrepancies in Android emulators. Moreover, we have de-
scribed a proof-of-concept implementation of Morpheus, along
with extensive experiments and ﬁndings.
Acknowledgements
We would like to thank Adam Doup´e and the anonymous
reviewers for their valuable comments that helped improve
the presentation of this paper. This work was supported in
part by the National Science Foundation under Grant CNS-
0916688 and National Research Foundation under Grant
NRF-2014K1A1A2043029.
9. REFERENCES
[1] Android developers - using the emulator. http://
developer.android.com/tools/devices/emulator.
html. Accessed: May 2014.
[2] Genymotion, the fastest android emulator for app
testing and presentation. http://genymotion.com.
Accessed: May 2014.
[3] Sanddroid - an apk analysis sandbox. http://
sanddroid.xjtu.edu.cn/. Accessed: May 2014.
[4] Tracedroid - dynamic android app analysis (by vu
amsterdam). http://tracedroid.few.vu.nl/.
Accessed: May 2014.
[5] Droidbox: An android application sandbox for
dynamic analysis. https://code.google.com/p/
droidbox/, 2011. Accessed: May 2014.
[6] Andrubis: A tool for analyzing unknown android
applications. http://blog.iseclab.org/2012/06/04/
andrubis-a-tool-for-analyzing-unknown-android-
applications-2/, June 2012. Accessed: May 2014.
[7] G. Association et al. Imei allocation and approval
guidelines. volume 10, 2010.
[8] D. Balzarotti, M. Cova, C. Karlberger, C. Kruegel,
E. Kirda, and G. Vigna. Eﬃcient detection of split
personalities in malware. In Proceedings of Network
and Distributed System Security Symposium, 2010.
[9] H. Dharmdasani. Android.hehe: Malware now
disconnects phone calls. http://www.fireeye.com/
blog/technical/2014/01/android-hehe-malware-
now-disconnects-phone-calls.html, January 2014.
Accessed: May 2014.
[10] W. Enck, P. Gilbert, B.-G. Chun, L. P. Cox, J. Jung,
P. McDaniel, and A. N. Sheth. Taintdroid: an
information-ﬂow tracking system for realtime privacy
monitoring on smartphones. In Proceedings of the
USENIX conference on Operating systems design and
implementation, pages 1–6. USENIX, 2010.
[11] F-Secure. Trojan:android/pincer.a. http://www.f-
secure.com/weblog/archives/00002538.html, April
2013. Accessed: May 2014.
[12] T. Garﬁnkel, K. Adams, A. Warﬁeld, and J. Franklin.
Compatibility is not transparency: Vmm detection
myths and realities. In Proceedings of USENIX
Workshop on Hot Topics in Operating Systems, 2007.
[13] S. Heuser, A. Nadkarni, W. Enck, and A.-R. Sadeghi.
Asm: A programmable interface for extending android
security. In Proceedings of the USENIX Security
Symposium, 2014.
[14] T. K. Ho. The random subspace method for
constructing decision forests. IEEE Transactions on
Pattern Analysis and Machine Intelligence,
20(8):832–844, 1998.
[15] C. Ionescu. Obfuscating embedded malware on
android. http://www.symantec.com/connect/blogs/
obfuscating-embedded-malware-android, June 2012.
Accessed: May 2014.
[16] Z. Li, M. Sanghi, Y. Chen, M.-Y. Kao, and B. Chavez.
Hamsa: Fast signature generation for zero-day
polymorphic worms with provable attack resilience. In
Proceedings of the IEEE Symposium on Security and
Privacy, pages 15–pp. IEEE, 2006.
[17] H. Lockheimer. Android and security. http://
googlemobile.blogspot.com/2012/02/android-and-
security.html, February 2012. Accessed: May 2014.
[18] I. Lunden. Gartner: 102b app store downloads
globally in 2013, 26b in sales, 17% from in-app
purchases. http://techcrunch.com/2013/09/19/
gartner-102b-app-store-downloads-globally-in-
2013-26b-in-sales-17-from-in-app-purchases/,
September 2013. Accessed: May 2014.
[19] F. Matenaar and P. Schulz. Detecting android
sandboxes. http://dexlabs.org/blog/btdetect,
August 2012. Accessed: May 2014.
[20] J. Oberheide and C. Miller. Dissecting the android
bouncer. SummerCon2012, New York, 2012.
[21] T. Petsas, G. Voyatzis, E. Athanasopoulos,
M. Polychronakis, and S. Ioannidis. Rage against the
virtual machine: hindering dynamic analysis of
android malware. In Proceedings of the European
Workshop on System Security, page 5. ACM, 2014.
[22] S. Rasthofer, S. Arzt, and E. Bodden. A
machine-learning approach for classifying and
categorizing android sources and sinks. In Proceedings
of the Network and Distributed System Security
Symposium, 2014.
[23] A. Reina, A. Fattori, and L. Cavallaro. A system
call-centric analysis and stimulation technique to
automatically reconstruct android malware behaviors.
In Proceedings of the European Workshop on System
Security, April 2013.
[24] P. Schulz. Android emulator detection by observing
low-level caching behavior. https://bluebox.com/
technical/android-emulator-detection-by-
observing-low-level-caching-behavior/,
December 2013. Accessed: May 2014.
[25] T. Vidas and N. Christin. Evading android runtime
analysis via sandbox detection. In Proceedings of the
ACM Symposium on Information, Computer and
Communications Security. ACM, 2014.
[26] C. Wu, Y. Zhou, K. Patel, Z. Liang, and X. Jiang.
Airbag: Boosting smartphone resistance to malware
infection. In Proceedings of the Network and
Distributed System Security Symposium, 2014.
[27] Z. Yang, M. Yang, Y. Zhang, G. Gu, P. Ning, and
X. S. Wang. Appintent: Analyzing sensitive data
transmission in android for privacy leakage detection.
In Proceedings of the ACM conference on Computer
and communications security, pages 1043–1054. ACM.
[28] Y. Zhang, M. Yang, B. Xu, Z. Yang, G. Gu, P. Ning,
X. S. Wang, and B. Zang. Vetting undesirable
behaviors in android apps with permission use
analysis. In Proceedings of the ACM conference on
Computer and communications security, pages
611–622. ACM, 2013.
[29] Y. Zhou and X. Jiang. Dissecting android malware:
Characterization and evolution. In Proceedings of the
2012 IEEE Symposium on Security and Privacy, pages
95–109. IEEE, 2012.
[30] Y. Zhou, Z. Wang, W. Zhou, and X. Jiang. Hey, you,
get oﬀ of my market: Detecting malicious apps in
oﬃcial and alternative android markets. In
Proceedings of the Network and Distributed System
Security Symposium, pages 5–8, 2012.