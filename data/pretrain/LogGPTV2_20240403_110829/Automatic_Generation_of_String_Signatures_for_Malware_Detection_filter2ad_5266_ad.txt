### 5. Heuristic Tuning and Malware Coverage

Table 5 presents the baseline and more liberal settings for each heuristic. Using all baseline settings, the system covered 1194 malware files with 206 signatures and 0 false positives. The table illustrates that almost all heuristics are necessary to reduce the false positive (FP) rate to zero. Among the tunable heuristics, position deviation performs the best, eliminating the second most FPs with the lowest impact on coverage. The group ratio also shows good performance. Requiring a second common signature does not appear to be beneficial. The library heuristics perform exceptionally well, with minimal impact on coverage. Other heuristics show significantly decreased marginal discrimination power, which highlights an important point: if two heuristics eliminate the same FPs, they will show good raw discrimination power but poor marginal discrimination power.

### 6.3 Single-Component Signature Generation Time

The most time-consuming step in Hancock's string signature generation process is the creation of the goodware model, which, for the model used in the above experiments, took approximately one week and utilized all 128 GBytes of available memory. Fortunately, this step only needs to be performed once. Since the resulting model is much smaller than the available memory in the testbed machine, using the model to estimate a signature candidate’s occurrence probability does not require any disk I/O.

At runtime, Hancock involves three high-level steps: malware preprocessing (including unpacking and disassembly), picking candidate signatures, and applying diversity-based heuristics to select the best ones. Malware preprocessing is the most resource-intensive step but can be parallelized. The two main operations in preprocessing are recursively unpacking malware files and disassembling both packed and unpacked files using IDA Pro. Both operations use little memory, so we parallelized them across 15 of our machines' 16 cores. For the 2007-2008 data set, due to the large number of packed malware files and the diminishing returns of analyzing them, Hancock disassembled only 5,506 packed files. Preprocessing took 71 hours. Picking candidate signatures required 145 minutes and 37.4 GB of RAM. Loading the goodware model took 15 minutes and 34.3 GB of RAM. The remaining resources were used for scanning malware files, picking, and storing candidate signatures in memory and then on disk.

### 6.4 Multi-Component Signatures

We tested multi-component signatures (MCS) with 2 to 6 components, each 16 bytes long. We used a 3.0 GB goodware set to select component candidates and tested for false positives with a 34.9 GB set of separate goodware. Table 6 shows the coverage and false positive rates when 0 or 1 components could be found in the smaller goodware set.

We observed that permitting a single component of an MCS to be an FP in our small goodware set consistently results in higher coverage. However, from 2- and 3-component signatures, allowing a single component FP also results in more entire MCS FPs, where all signature components occur in a single goodware file. We can trade off coverage and FP rate by varying the number of signature components and permitted component FPs. Three to five-part signatures with 0 or 1 allowed FPs provide the best balance between coverage and FPs.

Since we applied few heuristics to achieve these results, beyond requiring the existence of multiple, disjoint signature components, it is surprising that we have so few MCS FPs. This can be explained by the fact that although we do not limit MCS components to code bytes, we apply all the library code reducing heuristics through IDA disassembly as described in Section 3.2. Additionally, the way signature components are selected from contiguous runs of identical bytes may reduce the likelihood of FPs. If a long, identical byte sequence exists in a set of files, the 16-byte signature component with the lowest probability will be selected, and no other signature component will be selected from the same run. Thus, if malware shares an uncommon library linked contiguously in the executable, at most one signature component will be extracted from this sequence of identical bytes. The other components must come from some other shared code or data.

Finding candidate signatures took 1,278 minutes and 117 GB of RAM. Picking the final signature sets took 5 to 17 minutes and used 9.0 GB of RAM.

### 7. Discussion

The main limitation of the current version of Hancock is its low coverage, which was also the biggest surprise in this project. One potential explanation is that malware authors have evolved their distribution strategy from a "few malware families each with many variants" model to a "many malware families each with few variants" model, making it harder for Hancock to generate signatures with good coverage while keeping the false positive rate in check. To generate new malware families, authors use sophisticated packing and/or metamorphic transformation tools. The static unpack engine Hancock uses, which is also used in Symantec’s anti-virus products, cannot handle many packers or metamorphic transformation tools. In the largest test described in Section 6.2, Hancock had to ignore 59% of the input malware set because it found them to be packed and could not unpack them. Among the remaining 41%, some are probably packed (perhaps partially) but not detected by Hancock. For such malware files, Hancock won’t create string signatures because they do not share common byte sequences with other malware files.

In the future, we plan to incorporate dynamic unpacking techniques, such as Justin [16], to reduce the impact of packers on Hancock’s coverage. It is also possible to mitigate the packer problem by blacklisting binaries packed by certain packers. We did not focus much on metamorphic transformation tools in the Hancock project, as string signature-based malware identification may not be effective for metamorphic binaries. Instead, behavior-based malware identification may be a more promising solution. Nonetheless, systematically studying modern metamorphic tools and devising a taxonomical framework to describe them will be very useful contributions to the field of malware analysis.

Another significant limitation of Hancock is its lack of dynamic analysis, which forces it to give up on packed or metamorphically transformed binaries that it cannot recognize or restore. The rationale for employing only static analysis in Hancock is that it cannot afford the runtime performance cost associated with dynamic analysis given the current and future malware arrival rate. Even state-of-the-art dynamic analysis techniques cannot solve all the packer or metamorphism problems for Hancock.

Although many of Hancock’s heuristics can be evaded, in general, this is a smaller concern than the problem that malware authors avoid using known string signatures in their binaries. Attackers can (and do) test newly generated malware files against popular anti-virus products. In contrast, even if malware authors create malware files that do not contain byte sequences that Hancock may use as signatures, there is no easy way to test the effectiveness of these malware files against Hancock’s signature generation algorithms, as it is not publicly available and has many empirical built-in parameters. In theory, security by obscurity is not a foolproof solution; in practice, it is very difficult, if not infeasible, to evade Hancock’s signature generation heuristics.

### 8. Conclusion

Given a set of malware files, an ideal string signature generation system should be able to automatically generate signatures in such a way that the number of signatures required to cover the malware set is minimal, and the probability of these signatures appearing in goodware programs is also minimal. The main technical challenge in building such systems is determining how FP-prone a byte sequence is without access to a sizeable portion of the world’s goodware set. This false positive problem is particularly challenging because the goodware set is constantly growing and potentially unbounded. In the Hancock project, we developed a series of signature selection and filtering techniques that collectively could remove most, if not all, FP-prone signature candidates while maintaining reasonable coverage of the input malware set. The Hancock project has made the following research contributions in the area of malware signature generation:

- A scalable goodware modeling technique that prunes away unimportant nodes according to their relative information gain and merges sub-models to scale to very large training goodware sets.
- A set of diversity-based techniques that eliminate signature candidates when the set of malware programs they cover exhibit high diversity.
- The first known string signature generation system capable of creating multi-component string signatures, which have been shown to be more effective than single-component string signatures.

Although Hancock represents the state of the art in string signature generation technology, there is still room for further improvement. The overall coverage of Hancock is lower than expected when the project started. How to improve Hancock’s coverage without increasing the FP rate of its signatures is worth further research. Although the multi-component signatures that Hancock generates are more effective than single-component signatures, their actual runtime performance impact is unclear and requires more thorough investigation. Moreover, there could be other forms of multi-component signatures that Hancock does not explore and therefore deserve additional research efforts.

This paper omits discussion of several additional heuristics explored in the Hancock project. See [17] for more details.

### References

1. PEiD, http://www.peid.info
2. Clam AntiVirus: Creating signatures for ClamAV (2007), http://www.clamav.net/doc/latest/signatures.pdf
3. Arnold, W., Tesauro, G.: Automatically generated win32 heuristic virus detection. In: Proceedings of Virus Bulletin Conference (2000)
4. Jacob, G., Debar, H., Filiol, E.: Behavioral detection of malware: from a survey towards an established taxonomy. Journal in Computer Virology 4(3) (2008)
5. Singh, S., Estan, C., Varghese, G., Savage, S.: Automated worm fingerprinting. In: OSDI 2004: Proceedings of the 6th conference on Symposium on Operating Systems Design & Implementation, Berkeley, CA, USA, p. 4. USENIX Association (2004)
6. Kim, H.: Autograph: Toward automated, distributed worm signature detection. In: Proceedings of the 13th Usenix Security Symposium, pp. 271–286 (2004)
7. Kreibich, C., Crowcroft, J.: Honeycomb: creating intrusion detection signatures using honeypots. SIGCOMM Comput. Commun. Rev. 34(1), 51–56 (2004)
8. Newsome, J., Karp, B., Song, D.: Polygraph: Automatically generating signatures for polymorphic worms. In: SP 2005: Proceedings of the 2005 IEEE Symposium on Security and Privacy, Washington, DC, USA, pp. 226–241. IEEE Computer Society, Los Alamitos (2005)
9. Li, Z., Sanghi, M., Chen, Y., Kao, M., Chavez, B.: Hamsa: fast signature generation for zero-day polymorphic worms with provable attack resilience. In: SP 2006: Proceedings of the 2006 IEEE Symposium on Security and Privacy, Oakland06, pp. 32–47. IEEE Computer Society, Los Alamitos (2006)
10. Tang, Y., Chen, S.: Defending against internet worms: A signature-based approach. In: Proceedings of IEEE INFOCOM 2005 (2005)
11. Christodorescu, M., Jha, S., Seshia, S., Song, D., Bryant, R.: Semantics-aware malware detection. In: Proceedings of the IEEE Symposium on Security and Privacy (2005)
12. Yegneswaran, V., Griffin, J.T., Barford, P., Jha, S.: An architecture for generating semantics-aware signatures. In: SSYM 2005: Proceedings of the 14th conference on USENIX Security Symposium, Berkeley, CA, USA, p. 7. USENIX Association (2005)
13. Kephart, J.O., Arnold, W.C.: Automatic extraction of computer virus signatures. In: Proceedings of the 4th Virus Bulletin International Conference (1994)
14. Begleiter, R., El-Yaniv, R., Yona, G.: On prediction using variable order Markov models. Journal of Artificial Intelligence Research 22, 384–421 (2004)
15. Guilfanov, I.: Fast library identification and recognition technology (1997), http://www.hex-rays.com/idapro/flirt.htm
16. Guo, F., Ferrie, P., Chiueh, T.: A study of the packer problem and its solutions. In: Lippmann, R., Kirda, E., Trachtenberg, A. (eds.) RAID 2008. LNCS, vol. 5230, pp. 98–115. Springer, Heidelberg (2008)
17. Griffin, K., Schneider, S., Hu, X., Chiueh, T.: Automatic generation of string signatures for malware detection (2009), http://www.ecsl.cs.sunysb.edu/tr/TR236.pdf