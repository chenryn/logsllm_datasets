expand main memory capacity without persistence, and app
direct mode which provides persistence [40]. PLINIUS leverages
PM in app direct mode.
Applications can leverage PM in app direct mode by using
standard operating system calls (i.e., read,write) through the ﬁle
system in the same way slower storage devices like SSDs and
HDDs are accessed. This improves application performance
but does not leverage the load/store interface provided by the
PM modules. In PLINIUS, we enhance the ML library to do
direct loads/stores from/to PM. This conﬁguration is more
challenging as it requires application modiﬁcation. However, it
results in more signiﬁcant performance gains since persistent
updates bypass both the kernel and ﬁle system [22].
Server-grade CPUs natively support up to 3 TB of PM [27],
hence revealing PM as an attractive solution for fault tolerant
applications. Due to data remanence [41], using PM could
introduce security risks, in particular for conﬁdentiality and
data integrity.
The use of PM requires a paradigm shift for application
developers. Several software tools and libraries have been
proposed, such as Romulus [11], Mnemosyne [36] or Intel’s
PMDK5 to facilitate PM related development. PM libraries
expose PM to applications by memory-mapping ﬁles on a
persistent memory-aware ﬁle system with direct access (DAX)
capabilities. DAX removes the OS page cache from the I/O
path and allows for direct access to PM with byte-granularity.5
To characterize our PM units, we execute FIO6 with sequen-
tial and random workloads, and compare the read and write
throughputs for native Ext4 over an SSD drive, Ext4+DAX on
PM, and a tmpfs partition over volatile DRAM. We observe
(Fig. 2) that the DAX-enabled ﬁle system on PM performs
consistently better than its non-DAX counterpart on SSD, and
is close to RAM-tmpfs performance (in the order of GB/s).
Speciﬁc
processor
(i.e.,
instructions
CLFLUSH,
CLFLUSHOPT, CLWB) are used to ﬂush data from cache lines
to the PM memory controller. Through asynchronous DRAM
refresh [40] data in the memory controller’s write buffers is
guaranteed to be persisted in PM in case of a power failure.
Persistence fences (i.e., SFENCE) guarantee consistency by
preventing store instructions from being re-ordered by the
CPU. PM libraries like Romulus and the PMDK provide
transactional API which enable developers to perform atomic
updates on persistent data structures.
Romulus provides durable transactions via twin copies of
data in PM and relies on a volatile log to track memory
locations being modiﬁed in a transaction. The ﬁrst copy, called
the main region, is where user-code executes all in-place mod-
iﬁcations; the second copy, the back region, is a backup (or
snapshot) of the previous consistent state of the main region.
Following a crash while mutating main, the content of back
is restored to main. Romulus uses at most four persistence
fences for atomic updates on data structures, regardless of
transaction size, and a store interposition technique to ensure
cache lines are correctly ﬂushed to PM. The design of Romulus
permits to have low write ampliﬁcation [11] relative to other
PM libraries, and hence we build on top of it as PM library,
by porting it to be SGX-compatible.
Training ML models. A ML model can be described as a
function that maps an input to a target output based on a set
of parameters [19]. A linear regression model for example is
a function f (x) = W
x + b where W represents the model
weights, b the bias vector, and x the input vector. The weights
and biases are the learnable parameters of a model, and they
determine the output of the latter for a given input.
(cid:124)
The goal of model training is to obtain the set of learnable
parameters that minimizes a loss function and maximizes
the model’s accuracy on the training data. The loss function
is a scalar function that quantiﬁes the difference between
the predicted value (for a given input data point) and the
ground truth or real value [6]. During training, the learning
algorithm iteratively feeds the model with batches of training
data, calculates the loss, and updates the model parameters in
such a way as to minimize the loss. A very popular learning
algorithm used in ML for loss minimization is stochastic
gradient descent (SGD) [29].
In this work, we rely on supervised learning, where a (costly)
training phase builds a model out of labelled data, followed
5https://pmem.io/
6http://freshmeat.sourceforge.net/projects/ﬁo
3
 0.01 0.1 1 10 1001248Number of threadsThroughput (GB/s)SSD (Ext4)PM (Ext4+DAX)Ramdisk (Tmpfs)Random Reads1248Sequential Reads1248Random Writes1248Sequential WritesFig. 3: General machine learning pipeline: Fwd=Forward propaga-
tion, Back=Backward propagation.
by a classiﬁcation/inference phase using the model. Examples
include visual object recognition, spam ﬁltering, etc.

Fig. 3 shows a typical supervised ML model training pipeline.
Training data is read from secondary storage (Fig. 3-
),
preprocessed and used to train the model (Fig. 3-,,).
Training models such as deep neural networks can take up
to several days, a time window sufﬁciently long for training
jobs to experience failures or pre-emptions [6]. Also, large ML
datasets (i.e., order of GBs) are very common in the training
phase. In the event of a failure during training, the model being
trained as well as the training data sets resident in DRAM are
lost and need to be re-read from secondary storage upon restart.
Several state-of-the-art ML frameworks (e.g., Tensorﬂow [6],
Darknet [3], Caffe [24], etc.) provide mechanisms to checkpoint
model states to secondary storage during training. However,
the high latency and low bandwidth (in the order of MB/s)
of secondary storage makes failure recovery a fundamental
problem. The mentioned appealing properties of PM make the
latter particularly interesting for fault tolerance in such ML
scenarios.
In this work, we implement PLINIUS, a novel ML framework
which leverages PM for fault tolerance and Intel SGX to ensure
conﬁdentiality and integrity of ML models, as well as sensitive
training data. We build our ML framework on Darknet, which
is popular in the ML community, provides good performance
and is easily portable to Intel SGX.
III. THREAT MODEL
PLINIUS has three primary goals: (1) to ensure conﬁdentiality
and integrity of a ML model’s parameters (e.g., weights, biases)
during training; (2) to ensure conﬁdentiality and integrity of
the model’s replica on PM used for fault tolerance; and (3)
to ensure conﬁdentiality and integrity of training data in byte-
addressable PM.
The system is designed to achieve these goals while facing
a powerful adversary with physical access to the hardware and
full control of the entire software stack including the OS and
hypervisor. The adversary seeks sensitive information inside
the enclave, on DRAM or PM, or data from the processor.
Model hyper-parameters such as model architecture, number
of layers, size of training batches or type of training data are
usually public information, as they do not leak any information
about trained model parameters or sensitive training data [15],
[17], [19]. In order to mitigate possible threats linked to
malicious data sources, PLINIUS supports secure provisioning
of model hyper-parameters via the SGX remote attestation
mechanism. We assume that the adversary cannot physically
4
Fig. 4: PLINIUS architecture.
open and manipulate the processor package, that enclave
code is correct and it does not leak sensitive information
(e.g., encryption keys) intentionally. Denial-of-service and side-
channel attacks [9], [31], for which solutions exist [16], [30],
are considered out of scope.
IV. PLINIUS ARCHITECTURE
The design of PLINIUS introduces an important
issue:
minimizing the TCB. A design approach based on a libOS like
Graphene SGX or SCONE containers introduces thousands
of lines of code into the enclave runtime, increasing security
risks. Furthermore, with such a design, the enclave quickly
reaches its memory limitation leading to a dramatic loss of
performance. In light of these problems and following the
SGX guidelines [10], we design an architecture partitioned
into trusted and untrusted parts.
By manually porting the PM and ML libraries via separation
into trusted and untrusted components, PLINIUS achieved a
TCB reduction of ∼44% in terms of LOC.
The architecture of PLINIUS consists of three main com-
ponents interacting with each other: (1) an SGX-compatible
PM library, i.e., sgx-romulus; (2) an SGX-compatible
deep-learning framework, i.e., sgx-darknet; and (3) a
mirroring module, which synchronizes the ML model
inside the enclave with its encrypted mirror copy in PM.
Figure 4 shows how these components interact. We detail
each of them in the remainder of this section.
SGX-Romulus is a port of Romulus [11] to Intel SGX. SGX-
ROMULUS implements durable transactions in PM directly
within an SGX enclave. It consists of a secure user-space library,
lib-sgx-romulus, which provides durable, concurrent
transactions, and persistence primitives required to create
and manage persistent data structures in PM. SGX-ROMULUS
maintains a volatile log in enclave memory which logs the
addresses and ranges of modiﬁed data in the current transaction.
The size of the log varies with transaction size. A helper
library in the untrusted runtime, sgx-romulus-helper,
communicates with SGX-ROMULUS and permits to invoke
necessary system calls (e.g., mmap,munmap) which are
required when leveraging PM via a DAX-enabled ﬁle system.
At application initialization, sgx-romulus-helper
memory-maps
the ﬁle corresponding to the persistent
memory region (main, back and header) into application
virtual address space (VAS), via a mmap system call.
DatasetModel➊➀ Loadto DRAMData pre-processing➎ Periodic checkpoint➊➁ Restore➌ ApplySGD➋ReadModelparametersTraining➍ Read para.IterationsFwdBack!Generic ML pipelineBackHeaderMainInitialdata setSGX-RomulushelperSGX-DarknethelperSGX-Romuluslib-sgx-romulusLogSGX-DarknetMirroring mod.Modeltrainerlib-sgx-darknetEncryptionengineEncryptedmodelPM-DatamoduleTrusted runtime/enclaveUntrusted runtime➋➌➐PM➎➏➍➊➑➑The encryption engine is responsible for encrypting/decrypt-
ing model parameters to be mirrored to/from the PM model,
as well as in-enclave decryption of encrypted training data
resident in PM.
In-enclave symmetric encryption/decryption relies on AES
Galois counter mode (GCM) [13] implementation from the
Intel SGX SDK. AES-GCM uses a 128, 192 or 256 bit key
for all cryptographic operations, and provides assurance of the
integrity of the conﬁdential data [13]. PLINIUS uses a 128 bit
key for all cryptographic operations.
As recommended by [13], for every encryption operation,
we generate a random 12-byte initialization vector (IV) using
the sgx_read_rand() [10, p. 200] function from the Intel
SGX SDK. The encryption algorithm divides each plain text
buffer into 128 bit blocks which are encrypted via AES-GCM.
The IV and a 16-byte message authentication code (MAC) are
then appended to each encrypted data buffer. The MAC is used
to ensure data integrity during decryption.
The key used for encryption/decryption can be provisioned
to the enclave via remote attestation [10, p. 99] or could be
generated securely (e.g., if training data is not encrypted) inside
the enclave using sgx_read_rand(). The encryption key,
once generated or provisioned, can be securely sealed [10,
p. 96] by the enclave for future use.
Full ML workﬂow with PLINIUS. Figure 5 shows the full
ML workﬂow with PLINIUS. The owner of the data and
the model sends the application binary and raw encrypted
training data to the remote untrusted server (Figure 5-). She
then performs remote attestation (RA), establishes a secure
communication channel (SC) with the enclave (Fig. 5-) and
sends encryption keys to the latter (Figure 5-). The PM-data
module transforms encrypted data on disk to encrypted byte
addressable data in PM (Figure 5-
). The training module
reads and decrypts (with keys obtained from RA & SC) batches
of training data from PM (Figure 5, -) with the trained
model being mirrored to PM or into the enclave for restores
(Figure 5-).
,
Integration with different ML libraries. The current
PLINIUS architecture uses Darknet as the ML library, due to
its efﬁcient and lightweight implementation in C that facilitates
integration with SGX enclaves. Other ML libraries could be
integrated into the PLINIUS architecture. In fact, once the ML
library is ported to SGX, the same PLINIUS architecture holds.
To validate the generality of our architecture, we applied
our mirroring mechanism within Tensorﬂow [6], another
popular ML library. Tensorﬂow uses tensor data structures
to store model information (e.g., weights and biases). Our
implementation creates mirror copies of tensors in PM and
restores them in enclave memory using PLINIUS’s mirroring
mechanism. However, due to the large memory footprint of
Tensorﬂow-based ML applications with respect to our EPC
limit (93.5 MB), we opted to use Darknet ML library, which
is lightweight but equally efﬁcient.
Fig. 5: Full model training workﬂow with PLINIUS.
Then, sgx-romulus-helper initializes the persistent
header [11], which holds metadata to track the consistency
state of the main and back regions, a reference to an array
of persistent memory objects, and a pointer to the memory
allocator’s metadata (e.g., allocated and unallocated PM). The
address of the persistent header is passed to SGX-ROMULUS via
an ecall and once the enclave validates this address, it then
completes the PM region initialization, as further detailed in
Algorithm 1. The enclave can then create or update persistent
data structures in PM. Upon graceful termination of the enclave
application, the enclave runtime issues an ocall to unmap
the PM region from application VAS via the munmap system
call.
SGX-Darknet is a port of Darknet [3] to Intel SGX. While
many TEE-based ML libraries only provide support for
inference, SGX-DARKNET supports both secure training and
inference on ML models in Intel SGX enclaves. In order
to achieve a minimal TCB, we separate SGX-DARKNET into
trusted and untrusted parts. Our separation strategy involves
keeping out of the enclave, as much as possible, computations
which do not require any particular security. Examples include
parsing of model conﬁguation ﬁles, and initial data loading