i
,
qslo
i
.
(6)
(7)
We then compute the QoS score as
O(M ) = α · qenergy + β · qslo.
This is motivated from prior work [33] where α and β (such
that α + β = 1) are hyper-parameters that can be set by users
in line with the application requirements. Typically, in real-
life settings, these values are around 0.5 [33], [47]. For an
energy-constrained setting, a higher α value is used, whereas
for latency-critical tasks, a higher β value is used.
C. Testbed.
Our testbed consists of 16 Raspberry Pi 4B nodes, 8 with
4GB and another 8 with 8GB RAM each. This allows the
setup to have heterogeneous nodes with different memory
capacities. We consider the same federated topology as a
starting point in our experiments. Here, we have 4 LEIs with
brokers as 8GB nodes and workers symmetrically distributed
from the 4GB and remaining 8GB nodes. The devices run the
Ubuntu-18.04 LTS operating system. All WAN and LAN links
were 1 Gbps. To emulate each LEI being in geographically
distant locations, we use the NetLimiter tool to tweak the
communication latency among brokers nodes using the model
described in [51]. To emulate the gateway devices sending
tasks that affect the load distribution across LEIs, we use the
gateway mobility model described in [52].
D. Creating the Training Dataset.
To generate a normal execution trace as the dataset to train
the GON model, we ran the widely-used DeFog benchmark
applications [30] on our testbed. Speciﬁcally, we use the Yolo,
PocketSphinx and Aeneas workloads. We build CAROL as a
layer on top of the state-of-the-art surrogate modeling-based
scheduler (GOBI) [33] and execute these tasks as Docker con-
tainers. Our runs are divided into ﬁve minute long scheduling
intervals. We run these traces for 1000 intervals where we
periodically change the graph topology every ten intervals. We
8
Fig. 4. Training plots for the GON model. The model converges in 30 training
epochs.
collect the performance metrics, scheduling decision and graph
topology to generate the training dataset Λ = {Mt, St, Gt}1000
with 100 different graph topologies.
t=0
E. Training Details and Hyperparameter Selection.
For GON, we only change the number of layers in the
feed-forward networks in Figure 3 (keeping a ﬁxed layer
size of 128 nodes). We choose the model memory footprint
based on grid search so to minimize the Mean-Square-Error
(MSE) between the predicted performance metrics and the
corresponding values in the dataset. A GON network with a
lower parameter size is prone to underﬁtting and high MSE.
A large number of parameters increase the training and ﬁne-
tuning time, subsequently increasing the scheduling time due
to the slower optimization based generation in (1). To avoid
high MSE values and scheduling times, we use a GON model
that consumes ∼1GB RAM. A more exhaustive sensitivity
analysis is given in Section V-E. For training, we randomly
split the dataset into 80% training and 20% testing data. We
use a learning rate of 10−4 with a weight decay of 10−5 in the
Adam optimizer for optimizing the loss function. The training
curves showing loss and F1 scores on the test set are shown in
Figure 4. We use the early stopping criterion for convergence.
The minibatch size and tabu list size were also obtained using
grid search and the values used in our experiments were 32
and 100. More details in Section V-E.
F. Fault Injection Module.
To generate broker failures at test time, we use an existing
fault-injection module [41]. We create faults of the type: CPU
overload, RAM contention, Disk attack and DDOS attack. In
a CPU overload attack, a simple CPU hogging application
is executed that creates contention of the compute resources.
In RAM contention attack, a program is run that performs
continuous memory read/write operations. In disk attacks, we
run the IOZone benchmark that consumes a large portion of
the disk bandwidth. In a DDOS attack, we perform several
invalid HTTP server connection requests causing network
bandwidth contention. More details are given in [41]. We
generate faults using a Poisson distribution with the rate
λf = 0.5, sampled uniformly at random from the attack set.
051015202530Epochs0.30.40.50.6LossLossMSEConﬁdenceScore0.51.01.52.0MSE0.20.40.60.8ConﬁdenceScoreThese attacks were performed to cause the byzantine failure
of broker nodes.
G. Broker Failure Detection.
In our implementation, all broker nodes periodically (every
30 seconds) ping each other to test which hosts are active in
the system. Five Internet Control Message Protocol (ICMP)
packets are sent using the ping utility to every other broker
and the node waits for a response with a timeout counter set to
10 seconds. If the broker responds, we run the audit checking
procedure that veriﬁes the signed log entries since the previous
audit [53]. If a broker is unresponsive or the audit check fails,
an entry is made in a shared PostgreSQL database. For a broker
b ∈ B, if all other brokers report it as unresponsive, then b is
assumed to be compromised. A ‘reboot’ command is run on
this broker in a non-blocking fashion using the ssh utility.
H. Node-shift Implementation.
All sharing of resource utilization characteristics across bro-
kers uses the rsync utility. For each worker node, an entry
is kept corresponding to the IP address of the broker node
to which the worker is assigned. At a node-shift event, the
IP address of the new broker is updated for each orphaned
node. The worker nodes refresh the broker IP addresses at the
start of each scheduling interval. When a worker is assigned
as a broker node, it runs the broker management software as
a Docker container.
I. Broker Recovery.
As described in Section III, we assume temporary failures
in our setup. Thus, after a broker node fails, it takes 1-5
minutes for this node to restore to the previous state and
resume computation/management. To ensure smooth execution
of the system, we use the Virtual Router Redundancy Protocol
(VRRP) to assign a set of virtual IPs to the broker nodes in
the system. We implement this using the keepalived high-
availability toolkit.1 As soon as a failed node comes back
online, we add it to the graph topology and assign it as a
worker in the closest active broker as per network latency.
This is performed at the time of graph topology initialization
at the start of each interval (line 4 of Alg. 2).
V. PERFORMANCE EVALUATION
We compare the CAROL fault resilience method against a
heuristic baseline DYVERSE [13], meta-heuristic baseline
ECLB [17], an RL baseline LBOS [18], two surrogate mod-
elling based methods ELBS [19] and FRAS [20], and two
reconstruction models TopoMAD [21] and StepGAN [22]
(more details in Section II). As TopoMAD and StepGAN
are only fault-detection methods, we supplement them with
the priority based load-balancing policy from the next best
baseline, i.e., FRAS. We use hyperparameters of the baseline
models as presented in their respective papers. We train all
deep learning models using the PyTorch-1.8.0 [54] library.
1Keepalived. https://github.com/acassen/keepalived. Ac-
cessed 7 November 2021.
9
A. Workloads.
To test the generalization capability of the various resilience
models and their adaptive capacity, we do not use the DeFog
benchmarks as workloads at test time. Instead, we use the
AIoTBench applications [31], [55]. AIoTBench is an AI-
based edge computing benchmark suite that consists of var-
ious real-world computer vision application instances. The
seven speciﬁc application types correspond to the neural
networks they utilize. These include three typical heavy-
weight networks: ResNet18, ResNet34, ResNext32x4d, as
well as four light-weight networks: SqueezeNet, GoogleNet,
MobileNetV2, MnasNet.2 This benchmark is used due to its
volatile utilization characteristics and heterogeneous resource
requirements. The benchmark consists of 50,000 images from
the COCO dataset as workloads [56]. To evaluate the proposed
method in a controlled environment, we abstract out the users
and IoT layers described in Section III and use a discrete prob-
ability distribution to generate tasks as container instances.
Thus, at the start of each scheduling interval, we create new
tasks from a Poisson distribution with rate λt = 1.2, sampled
uniformly from the three applications. The Poisson distribution
is a natural choice for a bag-of-tasks workload model, common
in edge environments [57]. Our tasks are executed using
Docker containers. We run all experiments for 100 scheduling
intervals, with each interval being ﬁve minutes long, giving a
total experiment time of 8 hours 20 minutes. We average over
ﬁve runs and use diverse workload types to ensure statistical
signiﬁcance of our experiments.
B. Evaluation Metrics.
We measure the energy consumption of the federated setup,
average response time and SLO violation rate of completed
tasks. We consider the relative deﬁnition of SLO (as in [33])
where the deadline is the 90th percentile response time for
the same application on the state-of-the-art method StepGAN
that has the highest F1 scores among the baselines. We also
consider the average inference time of the models, that is
the time to decide the steps for system resilience, such as
deciding the required node-shift operations. We also compare
the memory consumption of the techniques and the ﬁne-tuning
overhead averaged over the scheduling intervals.
C. Comparison with Baselines.
We now present results comparing CAROL with baselines.
For our experiments, we use α = β = 0.5 in (7) as per
prior work [33], [47]. Figure 5(a) compares the total energy
consumption of all models and shows that CAROL is able
to execute tasks with minimum energy consumption in the
federated edge environment. The presence of the average
energy consumption metric of all the edge nodes within the
QoS score calculation as shown in (7) forces the model to take
energy-efﬁcient node-shift decisions. It results in the minimum
number of active hosts with the remaining hosts in standby
2AIoTBench:
https://www.benchcouncil.org/aibench/
aiotbench/index.html. Accessed: 5 November 2021.
(a) Energy Consumption
(b) Response Time
(c) SLO Violation Rate
(d) Decision Time
(e) Memory Consumption
(f) Fine-Tuning Overhead
Fig. 5. Comparison of CAROL with baseline methods and ablated models. The y-axis on the left shows the absolute values and the one on the right shows
relative performance with respect to CAROL. The results corresponding to the ablated models are shown as hatched bar plots.
mode to conserve energy. CAROL reduces energy consump-
tion by 16.45% compared to StepGAN, the model having
minimum energy consumption across all baseline methods.
Figure 5(b) shows the average response time per task in
seconds. The response time is measured as the time difference
between the timestamps of task creation and result generation
and is a crucial metric to compare the service throughput
offered by the edge federation. The ﬁgure demonstrates that
CAROL reduces this metric by 8.04% compared to the best
baseline FRAS.
Figure 5(c) shows the fraction of SLA violations out of
the total completed tasks in the 100 scheduling intervals. The
ﬁgure shows that CAROL has the lowest SLO violation rate of
only 5.12%, 17.01% lower than the least violation rates among
the baselines, i.e., 6.17% of the FRAS method. Allowing node-
shift at each interval with the SLO violation rate in the QoS
score calculation ensures that the topology minimizes response
time and subsequently the SLO violation rates on an average.
Moreover, CAROL is given the SLO deadline for each task
that it utilizes to decide the number of worker nodes to allocate
per task to minimize the SLA violation metric in the QoS
score.
Figure 5(d) shows the comparison of average time to decide
the fault-tolerance steps for each model. The ﬁgure shows that
CAROL has a lower decision time compared to all AI-based
methods. LBOS and ELBS have the highest decision time
due to the time-consuming weighted round-robin and match-
making algorithms used in these methods. The least decision
time is of the DYVERSE heuristic method. However, CAROL
has only 6.77% higher decision time than DYVERSE.
Figure 5(e) shows the average percentage memory utiliza-
tion of the fault-tolerance models. The surrogate and genera-
10
tive methods have high memory consumption. ELBS has the
highest memory consumption due to the resource intensive
fuzzy neural networks in this approach. The RL based method,
LBOS, has the lowest memory footprint among the AI base-
lines due to a lightweight Q-table used in the Q learning model
in LBOS. Compared to the heuristic methods, CAROL has
memory consumption (∼5%), thanks to the memory-efﬁcient
GON model.
Figure 5(f) shows the overheads for ﬁne-tuning the AI
models and dynamically updating the priority scores in the
heuristic models. The overhead is measured for the complete
experiment, i.e., over 100 scheduling intervals. The ﬁgure
shows that CAROL has the lowest overhead of 78.12 seconds,
only 0.78 seconds on an average per ﬁve-minute interval. This
is 35.62% lower than the baseline with the lowest overhead,
i.e., FRAS that takes 121.35 seconds to update its model
periodically. The signiﬁcantly lower overhead of CAROL is
due to the economic conﬁdence-based model ﬁne-tuning.
Overall, we observe that the ability to approximate the QoS
scores for a given graph of the system topology and scheduling
decision enables the GON-based generative model to predict
the conﬁdence scores and accurately predict QoS scores for
any given state of the system. This, with the node-shifting
techniques in CAROL, allows us to optimize the QoS of the
federated environment.
D. Ablation Analysis
To study the relative importance of each component of the
model, we exclude every major component one at a time
and observe how it affects the performance of the scheduler.
An overview of this ablation analysis is given in Fig 5 as
hatched bars. First, we consider the CAROL model without
the conﬁdence scores, ﬁne-tuning the GON network at every
05101520EnergyConsumption(KW·hr)1.01.21.41.6RelativePerformance0204060ResponseTime(seconds)1.01.11.21.31.4RelativePerformance0.000.050.100.15SLOViolationRate1.01.52.02.53.0RelativePerformance0246DecisionTime(seconds)0.51.01.52.0RelativePerformance05101520MemoryConsumption(%)1234RelativePerformance050100150200Fine-TuningOverhead(seconds)0123RelativePerformance(a) Learning Rate
(b) Memory Size
(c) Tabu List Size
Fig. 6. Sensitivity Analysis.
scheduling interval (Always Fine-Tune model). We also con-
sider CAROL without ﬁne-tuning the GON network in any
interval (Never Fine-Tune model). Next, we consider a model
with a traditional GAN network instead of the GON based
conﬁdence and QoS prediction (With GAN model). Lastly, we
consider the CAROL model with a traditional feed-forward
surrogate network instead of GON (With Traditional Surrogate
model). We report the following ﬁndings:
• Without the conﬁdence-aware model ﬁne-tuning, the over-
heads signiﬁcantly increase, causing a higher average deci-
sion time and response time of applications.
• Without ever ﬁne-tuning the model, it does not adapt in
non-stationary settings giving rise to poor QoS scores.
• Without the GON model, and using a GAN instead, the
decision time is reduced as we do not need to optimize
in the topology space. However, the memory consumption
increases from 5% to 30%, which impacts the running
applications and broker management. This causes the SLO
violation rate to increase by 6%.