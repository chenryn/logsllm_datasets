### 表 1. 六种网页浏览场景的带宽测量结果

| 场景 | 带宽（字节/百分比） | 平均请求大小（字节） |
| --- | --- | --- |
| 场景 1 | 51,406 / 10.2% | 14.5 |
| 场景 2 | 74,927 / 14.9% | 10.9 |
| 场景 3 | 97,965 / 15.8% | 4.0 |
| 场景 4 | 224,663 / 36.2% | 6.0 |
| 场景 5 | 10,182 / 12.5% | 7.8 |
| 场景 6 | 5,534 / 6.82% | 1.9 |

### 编码方案
我们使用了一种变长编码方案，其中前2到6位表示长度。每个请求的时间信息如下（假设每秒有16个时间间隔）：
- 最近请求 ≤ 3秒：6位
- 最近请求 ≤ 约100秒：11 + 2位长度
- 最近请求 ≤ 约50分钟：16 + 4位长度
- 最近请求在过去的5年内：32 + 6位长度

这种编码方法提供了对每个请求时间信息内容的合理近似。需要注意的是，这些数字取决于每秒的时间间隔数。如果攻击者能够接近源网络查看消息，则每秒可能有超过16个时间间隔。另一方面，如果配置了Web代理以增加请求抖动，则每秒可行的时间间隔数可能少于16个。

### HTTP请求假设
本文假设HTTP请求通过第7层代理或网关进行定时通道测量。这意味着只有请求开始时的时间是有意义的。随后的IP数据包的时间由代理控制，而不是客户端，在正常情况下如此。我们认为存在代理是一个合理的假设，对于那些关心泄漏并测量隐蔽定时通道的组织来说，他们应该已经有一个Web代理来调解出站信息流（例如，带有数据丢失预防系统[18, 24]）。

### 评估
我们在受控环境中的网页流量和真实网页浏览数据上应用了本文描述的泄漏测量技术。受控测试包括在不同类型的网站上使用单个浏览器进行六次30分钟的浏览会话。真实网页流量是从十个不同的人使用各种浏览器和操作系统在30天内收集的。仅使用受控场景的数据来开发泄漏测量引擎。没有使用实时流量结果来修改或改进我们的分析技术。我们将精确无约束分析的结果与增量gzip压缩、简单请求分析和原始字节计数进行了比较。Gzip测试涉及使用已看到所有先前请求和响应的gzip压缩流来测量每个请求的新压缩数据量。简单分析是一种在先前研究中描述的技术[3]，它是无状态的，并且只丢弃预期的请求头。本节介绍我们的评估结果，讨论方法的局限性，并简要总结性能结果。

#### 受控测试
我们首先在来自受控场景的浏览流量上评估了我们的泄漏量化技术。这些场景是30分钟的浏览会话，包括网页邮件（Yahoo）、社交网络（Facebook）、新闻（纽约时报）、体育（ESPN）、购物（Amazon）和个人博客网站。结果显示在表1中。所有场景的精确无约束泄漏测量值都远小于原始字节数，范围从0.32%到1.12%。

博客场景的结果最好，因为该博客网站只有一个动态链接。分析引擎能够为所有其他请求找到完全匹配。在博客场景中存在的262字节中，118字节（45%）来自时间信息，86字节（33%）来自链接选择，48字节（18%）来自用户输入的文本，10字节（4%）来自包含随机数以防止缓存的JavaScript链接。博客场景代表了我们测量技术的理想情况，因为我们能够为除一个请求外的所有请求找到完全匹配的URL。由此产生的平均每个请求几字节的结果作为标准HTTP流量的下限。这种流量至少会泄漏时间和链接选择信息。一种减少时间和链接选择泄漏的方法是采用熵规范化技术，如通过缓存代理预取强制链接。

购物、新闻和网页邮件场景都显示了类似的精确测量结果。这些网站包含大量正确处理的动态构造链接。然而，动态链接通常包含来自客户端计算机的信息，例如执行时的精确系统时间、浏览器窗口尺寸和防止缓存的随机数。这些信息必须被计算，因为它不能通过查看先前的请求和响应来确定。从黑客的角度来看，这些字段是隐藏数据的好地方。不透明的客户端状态信息在购物、新闻和网页邮件站点上的广告和跟踪图像链接中尤为普遍。

社交媒体和体育新闻场景的精确无约束带宽测量值最高。社交媒体网站（Facebook.com）大量依赖于活动JavaScript和XML（AJAX）请求，这些请求根据用户输入构建链接URL。由于分析引擎未触发事件处理程序，因此无法提取这些链接。体育新闻网站（ESPN.com）包含许多动态获取其他网络资源的Flash对象。分析引擎无法排除这些链接，因为它未处理插件对象。未来，引擎可以通过从运行客户端的代理获取并重放关于触发AJAX请求和动态链接URL的输入事件的提示来提高分析准确性。这些代理不需要可信，因为错误的提示只会增加无约束带宽测量值。

Gzip压缩[8]在除了一个受控测试案例之外的所有案例中都比简单请求分析更有效，但远未达到精确分析的压缩水平。通过将先前的请求和响应通过压缩流，gzip能够消除84-93%的原始数据。URL和HTTP头充满了出现在先前请求或响应中的字符串，这为gzip提供了大量的压缩机会。Gzip的一个优势是它可以压缩UI层数据，而精确分析则会计算博客评论等的完整大小。将来，通过在后端运行额外的压缩算法，可能会进一步改进精确无约束带宽测量。

我们没有测试通用压缩算法，但预计结果类似。没有特定协议处理，压缩算法在消除受限信息方面的效果有限。

#### 真实网页流量中的信息量化
我们收集了10个用户一个月内的网页流量，以评估我们的泄漏测量技术。与受控场景不同，这些流量来自多种Web浏览器，包括Firefox、Internet Explorer、Safari和Chrome。流量包括志愿者的日常活动，共507,505个请求，涉及7052个唯一主机，总计475 MB。我们还记录了2.58 GB的响应数据，不包括图像、视频或其他二进制对象。为了保护隐私，忽略了网页邮件请求正文。据我们所知，收集的网页流量不包含任何间谍软件泄露或异常大的上传，这些都会对结果产生负面影响。

我们一次针对一个用户运行泄漏测量算法（结果未利用用户之间的请求相似性）。我们首先计算了所有请求的测量大小分布。图4a显示了原始、简单、gzip和精确测量的请求大小的概率密度函数。精确无约束算法在实际网页流量上的表现明显优于其他算法。精确请求大小的平均值为15.8字节，而gzip为132字节，简单为243字节，原始为980字节。尽管平均测量值较低，但精确请求大小分布表现出重尾（标准差为287字节）。

我们还计算了相对于原始测量值的请求大小百分比减少。这些结果可以在图4b中看到。同样，精确算法的减少效果更好。其测量值平均为相应原始值的1.48%，而gzip和简单算法分别为9.87%和13.5%。精确算法的请求测量值方差也更低，几乎所有都在相应原始值的20%以下。简单和gzip的大小减少更加分散，有些请求测量值为原始大小的20-75%。这些请求并没有从gzip或简单分析中受益太多。

实际流量的无约束带宽测量结果比受控测试案例更大。体育新闻测试的最大平均请求大小为14.5字节，低于实际网页流量的总体平均请求大小15.8字节。原因之一是受控测试不一定代表真实的网页浏览。其他不在受控研究中的站点可能不会表现出相同的插件或事件处理程序请求组合。我们没有计算这种误差来源的普遍性，因为这样做需要手动分析五十万个请求中的相当一部分。

在处理实际网页流量时，我们观察到了一些在受控测试案例中不存在的误差来源。其中一个问题是缺少缓存对象。客户端可能会长时间缓存服务器资源，使得这些资源在网络跟踪中不可用。这对于缺失的重要脚本尤其成问题。可以通过让分析引擎从网络中获取缺失的对象来减少这个问题的影响。然而，这些对象可能不再可用或自原始请求以来已发生变化。

另一个仅在实际网页流量中发现的误差来源是不同浏览器版本的影响。受控测试都是使用Mozilla Firefox [14]进行的。分析引擎的JavaScript和DOM实现也模仿了Firefox。来自其他浏览器的实际网页流量可能具有不同的动态链接，对应于不同的浏览器行为。这些差异可以通过实现其他DOM接口以匹配每个请求头中报告的浏览器版本来减少。

### 分析性能
实际网页流量是在一台配备双核Intel T2500处理器和2 GB RAM的商品笔记本电脑上进行分析的。分析算法在一个核心上以单线程运行，另一个核心由操作系统使用。分析引擎能够处理组合的...