title:SLA-NFV: an SLA-aware High Performance Framework for Network Function
Virtualization
author:Chen Sun and
Jun Bi and
Zhilong Zheng and
Hongxin Hu
White Paper
Intel, Brocade, Cyan, Red Hat,  
and Telefónica – NFV Services
End to End Network  
Function Virtualization  
Architecture Instantiation
How Intelligent NFV Orchestration based on industry standard  
information models will enable Carrier Grade SLAs
Executive Summary
For over 2 years now, since the ETSI NFV ISG inception in Darmstadt October 20121, NFV has been 
capturing the Telco industry imagination, its promises and benefits are clear and well understood. 
Since its inception, the industry has seen huge improvements in base technology layers, including 
server’s (Intel), hypervisor technology (Red Hat), and software libraries (Intel® DPDK), enabling the 
design of telco-grade Virtual Network Functions (VNFs) (such as Brocade’s VRouter 5600*), which 
have proliferated and evolved extensively during this period. As a direct result, a new and open  
ecosystem of VNF providers is beginning to flourish.
However, this is only part of the industry issue. These VNFs designed for carrier-class scalability, in 
order to behave as expected, need to be properly deployed in the underlying infrastructure allowing 
them to leverage all those new technology advances. NFV Management and Orchestration (MANO) 
and the associated information models, describing both the infrastructure and VNF requirements, 
are key to achieve this goal effectively and in a cost efficient manner for the service provider.  
Hence, legacy cloud management systems (CMS) will simply not suffice for true NFV deployments.
Cyan, Brocade, Intel, and Red Hat have combined with the Telefónica NFV Reference Lab at their 
GCTO Unit in Madrid to showcase how a realistic network scenario can be designed modelled and 
deployed via NFV Orchestration (Cyan Blue Planet) onto an NFV-ready infrastructure through the 
Telefónica design VIM (Virtual Infrastructure Manager). This new and correctly optimized NFV delivery 
stack is compared to what can be achieved with a typical cloud deployment model as exists today.
The results show the phenomenal benefits achievable through end to end system NFV awareness. 
The service scenario deployed in Telefónica’s NFV Labs in Madrid shows up to a 100x improvement 
in throughput for a typical routing scenario with respect to the same scenario as deployed in a 
typical enterprise cloud.
Key to unleashing this performance is the correct modelling of the key attributes required from 
Virtual Network Functions (VNFs), and exposing this information as the deployment decision 
criteria in the NFV delivery stack, i.e., the NFV Orchestrator and the Virtual Infrastructure Manager 
(VIM). The availability of such NFV-ready orchestration components together with appropriate 
standardized descriptors for VNFs and infrastructure will be the key enablers to large-scale NFV 
deployments in coming years.
Intel, Brocade, Cyan, Red Hat, and Telefónica – NFV Services
Table of Contents
Executive Summary ................................ 1
Introduction ............................................. 2
Service Scenario Overview ................... 4
Partners and  
Contributed Components ..................... 4
Cloud Versus NFV.................................... 4
Scenario Execution Results .................. 5
Conclusions .............................................. 7
Testimonials ............................................. 7
References ................................................ 8
Acronyms ................................................... 8
2
Introduction
A key component of the NFV vision is one of “The Network becoming a Data 
Centre,” a radically new network enabled through leveraging the commodity 
price points and capabilities emerging from the $30-$50 billon per annum 
global investment in data center technology to enable the delivery of Telco 
grade virtual network appliances on top as VNFs.
Network functions like Evolved Packet Core (EPC), 3G wireless nodes, Broad-
band Network Gateways (BNG), Provider Edge (PE), routers, firewalls, etc., have 
traditionally been delivered on bespoke standalone appliances. NFV aspires to 
replace this hardware centric approach with a software model which delivers 
comparable functionality as SW VNFs on standard high volume industry server 
HW. This transformation is referred to as NFV and the concept is well under-
stood and accepted by the Telco industry as a key lever in the transformation  
of the network toward a more flexible and mouldable infrastructure.
However this in itself is not sufficient. Deploying a Telco Network service presents 
additional complexities that typically don’t exist in today’s data center:
•  For example, each Telco service delivered to the broadband consumer comes 
with a service SLA which must be achieved and enforced. This must also take 
into account how to achieve proper scale as service adoption ensues. This 
places essential focus on how data plane workloads are handled in terms  
of throughput, packet loss guarantees, and latency effects. These are the  
attributes which most affect the virtual application performance and which 
Telco service providers must ensure as part of a customer’s SLA guarantees.
•  Additionally, control on network topology, VNF location, link bandwidths, and 
QoS guarantees are hugely important in Telco. This is the foundation on which 
Communication Service Providers must deliver their services. This approach 
deviates greatly from the centralized data center paradigm, where the topology 
is mostly static and where visibility and basic placement considerations for the 
stand-alone VMs are the primary attributes required for service continuity.
•  In this new NFV world, the virtual network functions will be delivered by many 
different vendors. Unless the community embraces a very well understood 
and open standard based service information model this new flexibility will 
become difficult to manage and will in itself become a problem. The proposal 
in this white paper and the associated E2E implementation is to use TOSCA as 
the service description language. This also enables an easy extension path to 
including the key NFV attributes required for this deterministic performance.
As described earlier, huge industry investment has enabled industry standard 
high volume servers1 to deal effectively with I/O-intensive workloads as required 
in today’s Telco environments. Thus, most recent x86 processors generations 
working in conjunction with suitably enabled hypervisors and using specialized 
open source software libraries such as DPDK (Data Plane Development Kit) have 
enabled standard high volume servers to deal efficiently with edge functions such 
as BNG, PE router, and EPC workloads. This creates the opportunity of enabling 
reliable NFV deployments ensuring that true Telco grade SLAs are achieved.
In order to enable these new Telco grade services, it is essential that the appro-
priate infrastructure resources are properly allocated to the VNF. Thus, practices 
such as taking into account the internal server memory topology, CPUs and I/O 
interfaces allocation to virtual machines, the usage of memory in “huge pages” 
for efficient lookups, or direct assignment of interfaces to the VM, among others 
becomes essential to assure a given VNF SLA in terms of performance, scalability, 
and predictability2. This type of deterministic resource allocation, including this 
NFV Management 
and Orchestration
OSS/BSS
Os-Ma
NFV
Orchestrator
Server, VNF, and 
Infrastructure 
Description
Or-Vnfm
Ve-Vnfm
VNF
Manager(s)
Vi-Vnfm
Nf-Vi
Virtualized
Infrastructure
Manager(s)
Or-Vi
EMS 1
VNF 1
NFVI
EMS 2
VNF 2
Vn-Nf
EMS 3
VNF 3
Virtual 
Computing
Virtual 
Storage
Virtual 
Network
Virtualization Layer
VI-Ha
Computing
Hardware
Storage
Hardware
Network
Hardware
HARDWARE RESOURCES
Execution 
reference 
points
Other 
reference 
points
Main NFV
reference
points
Figure 1. ETSI End to End NFV Architecture.
new enhanced platform awareness ca-
pability, not present in cloud computing 
environments, now becomes a necessity 
for carrier grade NFV deployments.
The ETSI-NFV reference architecture 
defines a layered approach to such an 
NFV deployment (see Figure 1).
Toward ensuring portable and  
deterministic VNF performance it is 
paramount to expose the relevant  
NFVI attributes up through the new 
NFV delivery stack. This allows the 
management and orchestration layers 
to ensure correct allocation of the 
resources for the end-to-end network 
service scenario. Likewise, the informa-
tion models (Network service VNF and 
Infrastructure description) describing 
the resource requirements for the 
Virtual Network Function (VNF) and  
the global service scenario are key to 
enable these NFV provisioning layers 
(NFV-Orchestrator and VIM) to make 
these intelligent and optimal deploy-
ment decisions.
This Enhanced Platform Awareness 
(EPA) capability allows the NFV orches-
tration platform to intelligently deploy 
well-designed VNF workloads onto the 
appropriate underlying NFVI enabling 
the optimal SLAs. This also unleashes 
the favorable total cost of ownership 
(TCO) NFV promises due to this  
more efficient use of the underlying  
infrastructure. This must be achieved 
through the implementation of a more 
versatile NFV ready infrastructure,  
and a more agile and competitive 
ecosystem of network functions 
providers enabled through such an 
open information model.
Toward demonstrating this NFV  
deployment approach, Intel, Telefónica, 
Cyan, Brocade, and Red Hat have  
collaborated to implement and demon-
strate a complete ETSI-NFV end to end 
service deployment solution stack.
3
Intel, Brocade, Cyan, Red Hat, and Telefónica – NFV ServicesService Scenario Overview
VNF Routing Scenario Overview 
•  The scenario being deployed is a 
routed VNF forwarding graph using 
Brocade Vyatta vRouters as VNFs. 
A three node network forwarding 
topology achieves a 40 Gbps network 
throughput between the ingress and 
egress points at Routers A and C  
(see Figure 2).
•  The exposure of the performance 
enablers (NFVI attributes) in the  
VNF Descriptor and importance of  
a good VNF design (Vyatta vRouter) 
are crucial toward enabling this 
service deployment.
•  The End to End NFV Service delivery 
stack with the relevant NFV intel-
ligence built in at each layer, through 
the information model, the VNF, the 
NFV Orchestrator, the VIM and finally 
the NFVI are all required for an opti-
mal VNF service chain deployment.
•  The use of Industry standard, open, 
and extensible information models 
such as TOSCA and suitable VNF  
formats are crucial toward enabling  
an open ecosystem of VNF vendors 
construct and deliver their services 
into this new end to end architecture.
The scenario also showcases the im-
portance of a well-designed standard 
high volume industry server HW based 
NFVI, which provides the EPA services 
required for the Deployment of Telco 
Grade VNFs.
Partners And Contributed 
Components
The lab environment is located at Tele-
fónica’s Global CTO NFV lab in Madrid.
As per Figure 3, the infrastructural  
components are provided as follow:
Intel components include: 
•  Intel® Xeon® processor-based servers 
and Network Interface cards
  –  Intel® Xeon® processor E5-2680  
v2 @ 2.80 GHz
  –  Intel® Open Networking Platform 
(ONP) Ingredients including  
DPDK R1.63
  –  Intel® X520 10G Network  
Interface Cards
Brocade components include:
• Brocade Vyatta vRouter 5600 3.2 R2
•  OpenFlow switch (Brocade NetIron 
MLXe)
The Cyan components include:
•  NFV-Blue Planet Orchestrator  
release 15.02
The Telefónica components include: 
•  DPDK R1.6 based Traffic generator 
TIDGEN (Telefónica I+D Generator)
• Telefónica VIM openvim R0.9
The Red Hat components include:
•  RHEL7.0 (with patches) and QEMU-
KVM version 2.0.0 (with patches)
Cloud Versus NFV
As mentioned, the demonstration is 
hosted at Telefónica’s NFV Reference 
Lab (physically located in Madrid)  
and provides two separate deploy-
ment environments (see Figure 4):
•  A NFV-ready NFVI pool, with a  
Telefónica developed NFV ready VIM 
implementing the requisite Enhanced 
Platform Awareness (EPA) and a  
Cyan NFV-Orchestrator supporting 
advanced VNF deployment using  
enhanced NFV information models. 
•  A standard cloud infrastructure pool 
ala classic cloud computing, with the 
same Telefónica VIM connected to 
the same Cyan NFV-Orchestrator but 
in this case not using the enhanced 
information model as the basis for 
the deployment.
10G
10G
3
4
2
40G
Router A
1
0
Mgmt : IF
10G
20G
Router B
1
2
0
Mgmt : IF
10G
ex1
ex0
Traffic
Generator
ex3
ex2
PE Router
Network
Scenario
10G
10G
40G
2
Router C
1
0
Mgmt : IF
3
4
10G
Figure 2. PE VNF Routing Service Chain.
4
Intel, Brocade, Cyan, Red Hat, and Telefónica – NFV ServicesStarting with both server pools empty 
(no VNFs deployed), the demo scenario 
is deployed onto each platform through 
the Orchestrator. With both setups run-
ning, performance measurements are 
displayed in real time, showing much 
higher and stable throughput in the 
NFV-ready scenario. 
Information models for both scenarios 
are compared, showcasing the key ad-
ditional attributes and end to end EPA 
awareness required for the optimized 
NFV deployment.
Scenario Execution Results
Initial Sub Optimal  
Cloud Deployment
The initial deployment demonstrates 
the typical issues with doing a “blind” 
enterprise-cloud like deployment of 
a typical VNF onto an underlying non 
NFV optimized infrastructure. 
compared to PCIe pass through mode 
and limits the throughput at acceptable 
packet loss.
The Brocade routing scenario is 
deployed. Since a suboptimal NFV 
information model is used, the Brocade 
vRouter is incorrectly deployed through 
the non-aware MANO stack and is 
unable to fully achieve the 23 Mpps 
(40 Gbps @ 192 byte packet size) it is 
designed to achieve, instead reaches a 
mere 270 Kpps largely because of the 
following (see Figure 5):
•  No PCIe* pass through: The NIC is not 
directly connected to vRouter, which 
now receives and transmits packets 
via the vSwitch, this is a subopti-
mal networking path to the VNF as 
•  No NUMA affinity: vCPUs are arbitrarily 
allocated from CPU socket that may not 
be directly attached to the NICs and may 
also use a non-local memory bus.
•  No CPU pinning: vCPUs allocated to 
vRouter may be shared or dynamically 
rescheduled limiting determinism.
•  No 1G Huge Page setup. This greatly 
limits the performance achievable 
in DPDK (Vyatta) performance and 
doesn’t correctly leverage the recent 
advances in server IOTBL and VTd 
architecture especially for small  
packet sizes.
VNFs
vRouters
DPDK
Traffic Gen.
DPDK
OSS/BSS
Os-Ma
NFV
Orchestrator
Server, VNF, and 
Infrastructure 
Description
NFV Management 
and Orchestration
NFVO
EMS 1
VNF 1
NVFI
EMS 2
VNF 2
Vn-Nf
EMS 3
VNF 3
Virtual 
Computing
Virtual 
Storage
Virtual 
Network
Virtualization Layer
VI-Ha
Computing
Hardware
Storage
Hardware
Network
Hardware
HARDWARE RESOURCES
Or-Vnfm
Ve-Vnfm