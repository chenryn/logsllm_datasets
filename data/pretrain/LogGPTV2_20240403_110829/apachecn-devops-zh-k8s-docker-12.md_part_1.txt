# 十二、Falco 和 EFK 审计
坏人做坏事。
好人做坏事。
事故时有发生。
前面的每一个陈述都有一个共同点:当其中任何一个发生时，你需要找出发生了什么。
通常，只有当我们想到某种形式的攻击时，才会考虑审计。虽然我们当然需要审计来发现“坏人”，但我们也需要审计日常的标准系统交互。
Kubernetes 包含您需要审核的大多数重要系统事件的日志，但它并不包含所有内容。正如我们在前面几章中所讨论的，所有的 API 交互都将被系统记录下来，其中包括您需要审核的大多数事件。但是，有些用户执行的任务不会通过应用编程接口服务器，如果您依赖应用编程接口日志进行所有审计，则可能无法检测到。
有一些工具可以弥补本地日志记录功能的不足。像 Falco 这样的开源项目将为您的 pods 提供增强的审计，为 API 服务器记录的事件提供详细信息。
没有日志记录系统的日志不是很有用。像 Kubernetes 中的许多组件一样，有许多开源项目提供了完整的日志记录系统。最受欢迎的系统之一是 EFK 栈，其中包括弹性搜索、Fluentd 和 Kibana。
本章将详细介绍所有这些项目。您将部署这些组件中的每一个，以获得实践经验并加强本章中涵盖的材料。
在本章中，我们将涵盖以下主题:
*   探索审计
*   介绍 Falco
*   探索 Falco 的配置文件
*   部署 Falco
*   Falco 内核模块
# 技术要求
要完成本章中的练习，您需要满足以下技术要求:
*   一台 Ubuntu 18.04 服务器，至少有 8 GB 内存，至少有 5 GB 可用磁盘空间用于 Docker 卷
*   使用 [*第 4 章*](04.html#_idTextAnchor083)*中的说明安装的 KinD 集群，使用 KinD* 部署 Kubernetes
*   Helm3 二进制(也应该安装在 [*第 4 章*](04.html#_idTextAnchor083) 、*使用 KinD* 部署 Kubernetes)
您可以在本书的 GitHub 资源库中访问本章的代码，该资源库位于[https://GitHub . com/PACKTPUSHING/Kubernetes-and-Docker-The-Complete-Guide](https://github.com/PacktPublishing/Kubernetes-and-Docker-The-Complete-Guide)。
# 探索审计
在大多数运行 Kubernetes 集群的环境中，您需要有一个审计系统。虽然 Kubernetes 有一些审计功能，但是对于企业来说，这些功能通常太有限，无法依靠它们来进行完整的审计跟踪，日志通常只存储在每个主机文件系统上。
为了关联事件，您需要在本地系统上提取所有要搜索的日志，并手动查看日志或将日志提取到电子表格中，然后尝试创建一些宏来搜索和关联信息。
幸运的是，Kubernetes 有许多第三方日志记录系统。可选的支付系统，如 Splunk 和 Datadog 是受欢迎的解决方案，包括 EFK 栈在内的开源系统是常用的，并包含在许多 Kubernetes 发行版中。所有这些系统都包括某种形式的日志转发器，允许您集中 Kubernetes 日志，以便您可以创建警报、自定义查询和仪表板。
本机审核的另一个限制是事件范围有限，仅限于 API 访问。虽然这对于审计很重要，但是大多数企业将需要在简单的 API 事件之外增加或定制审计目标的基本集合。扩展基础审计功能可能是一个挑战，大多数公司没有专业知识或时间来创建自己的审计插件。
Kubernetes 缺少的一个审计领域涉及 pod 事件。正如我们提到的，Kubernetes 的基础审计功能侧重于 API 访问。用户执行的大多数任务都会触发对应用编程接口服务器的调用。让我们举一个用户在 pod 上执行 shell 来查看文件的例子。用户可以使用`kubectl exec -it  bash`在交互模式下在豆荚上生成一个 bash 外壳。这实际上是向 API 服务器发送一个请求，要执行的主要调用如下:
```
I0216 11:42:58.872949   13139 round_trippers.go:420] POST https://0.0.0.0:32771/api/v1/namespaces/ingress-nginx/pods/nginx-ingress-controller-7d6bf88c86-knbrx/exec?command=bash&container=nginx-ingress-controller&stdin=true&stdout=true&tty=true
```
查看事件，您可以看到一个`exec`命令被发送到`nginx-ingress-controller` pod 来运行 bash 进程。
有人运行 shell 可能有很好的理由，例如，查看错误日志或快速修复问题。但是这里的问题是，一旦进入运行窗格，执行的任何命令都不会访问 Kubernetes API，因此，您将不会收到在窗格中执行的操作的任何记录事件。对于大多数企业来说，这是审计系统中的一个大洞，因为如果容器中执行的操作是恶意的，就不存在端到端的审计跟踪。
审核所有外壳对 pod 的访问将导致许多假阳性的线索，如果 pod 重新启动，您将丢失 pod 中的任何本地审核文件。相反，您可以忽略简单的外壳访问，但是如果有人试图从外壳执行某些任务，例如修改`/etc/passwd`文件，您希望记录一个事件。
所以，你可能会问，“*解决办法是什么？*“答案是用 Falco。
# 介绍 Falco
Falco 是来自 Sysdig 的开放源代码系统，它为 Kubernetes 集群中的 pods 增加了异常检测功能。开箱即用，Falco 包括一套强大的社区创建的基本规则，可以监控许多潜在的恶意事件，包括以下事件:
*   当用户试图修改`/etc`下的文件时
*   当用户在豆荚上产卵时
*   当用户将敏感信息存储在机密中时
*   当 pod 试图调用 Kubernetes API 服务器时
*   任何修改系统集群角色的尝试
*   或者您为满足需求而创建的任何其他自定义规则
当 Falco 在 Kubernetes 集群上运行时，它会监视事件，并根据一组规则，在 Falco pod 上记录事件，该事件可以被 Fluentd 等系统拾取，然后该系统会将事件转发到外部日志记录系统。
在本章中，我们将使用我们公司对 FooWidgets 场景的技术要求来解释 Falco 的配置。本章结束时，您将知道如何使用自定义配置选项在 Kubernetes 集群上设置 Falco。您还将了解 Falco 使用的规则，以及当您需要审核未包含在基本规则中的事件时，如何创建规则。最后，您将使用 Fluentd 将事件转发到 Elasticsearch，使用 Kibana 将 Falco 生成的事件可视化。
# 探索 Falco 的配置文件
在安装 Falco 之前，您需要了解可用的配置选项，这从初始配置文件开始，该文件将用于配置 Falco 如何创建事件。
Falco 项目包括一组基本配置文件，您可以将其用于初始审核。您很可能希望更改基本配置以满足您的特定企业需求。在本节中，我们将浏览一个 Falco 部署，并提供对配置文件的基本理解。
Falco 是一个功能强大的系统，可以定制以满足您对安全性的几乎任何要求。由于它是如此的可扩展，不可能在一章中涵盖配置的每个细节，但是像许多流行的项目一样，在[https://github.com/falcosecurity/falco](https://github.com/falcosecurity/falco)有一个活跃的 GitHub 社区，您可以在那里发布问题或加入他们的 Slack 频道。
Falco 配置文件包括一个基本配置文件和规则文件，这些文件包含将由系统审核的事件。基本配置文件是一个简单的 YAML 文件，其中包含每个配置选项的`key:value`对，以及使用`key:value`对的其他 YAML 文件，但它们包含审核事件的详细信息和配置。
有四个基本的配置文件可以用来配置您的部署，如下所示:
*   `falco.yaml`
*   `falco_rules.yaml`
*   `falco_rules.local.yaml`
*   `k8s_audit_rules.yaml`
包含的配置文件将开箱即用，但是您可能希望更改一些值来满足您的日志记录要求。在本节中，我们将详细解释最重要的配置选项。前三个配置文件是基本 Falco 部署的一部分，将在本章中详细解释。基本 Falco 安装不需要最后一个配置文件。它是一个附加组件，可以为应用编程接口服务器添加额外的审计功能。
## Falco . YAML 配置文件
您需要编辑的第一个文件是**基本配置文件**，用于配置 Falco 如何创建审计事件。它允许您自定义 Falco 的基本设置，包括事件输出格式、时间戳配置和端点目标，如 Slack 通道。让我们详细演练一下这个文件，并尝试一点一点地理解它。
配置文件的第一部分是`rules_files`部分。本节采用键`rules_file`的格式，规则文件的值用破折号表示。(这也可以表示为`rules_file: [file1, file2, file3, etc…]`。)
我们将在本章中解释每个规则文件的功能。在这个示例配置中，我们告诉 Falco 使用三个文件作为规则，并且在安装过程中每个文件都是从一个 ConfigMap 装载的:
```
rules_file:
  - /etc/falco/falco_rules.yaml
  - /etc/falco/falco_rules.local.yaml
  - /etc/falco/k8s_audit_rules.yaml
```
下一组值将配置 Falco 如何输出事件，包括时间格式，以及将事件输出为文本或 JSON 的选项。
默认情况下，`time_format_iso_8601`值设置为`false`，这告诉 Falco 使用本地`/etc/localtime`格式。将该值设置为`true`会告诉 Falco 使用 YYYY-MM-DD 的日期格式、使用 24 小时制的时间格式和 UTC 的时区来标记每个事件。
选择合适的格式是贵组织的决定。如果您有一个全球组织，将所有日志设置为使用 ISO 8601 格式可能会有所帮助。但是，如果您有一个地区组织，您可能更愿意使用本地日期和时间格式，因为您可能不需要担心将事件与其他时区的日志记录系统相关联:
```
time_format_iso_8601: false
```
接下来的两行允许您将事件的输出配置为文本或 JSON 格式。默认值设置为`false`，告知 Falco 以文本格式输出事件。如果第一个键被设置为`false`，则第二个值将不会被评估，因为 JSON 没有被启用:
```
json_output: false
json_include_output_property: true
```
您可能需要以 JSON 格式输出事件，这取决于您的日志记录系统所需的格式。例如，如果您要向弹性搜索服务器发送 Falco 事件，您可能希望启用 JSON 来允许弹性搜索解析警报字段。Elasticsearch 不要求事件以 JSON 格式发送，对于本模块中的实验，我们将此设置保留为默认值`false`。
以下是文本格式和 JSON 格式中相同类型事件的一些示例:
*   Falco 文本日志输出如下所示:
    ```
    19:17:23.139089915: Notice A shell was spawned in a container with an attached terminal (user=root k8s.ns=default k8s.pod=falco-daemonset-9mrn4 container=0756e87d121d shell=bash parent=runc cmdline=bash terminal=34816 container_id=0756e87d121d image=) k8s.ns=default k8s.pod=falco-daemonset-9mrn4 container=0756e87d121d k8s.ns=default k8s.pod=falco-daemonset-9mrn4 container=0756e87d121d
    ```
*   Falco JSON 日志输出如下所示:
    ```
    {"output":"20:47:39.535071657: Notice A shell was spawned in a container with an attached terminal (user=root k8s.ns=default k8s.pod=falco-daemonset-mjv2d container=daeaaf1c0551 shell=bash parent=runc cmdline=bash terminal=34816 container_id=daeaaf1c0551 image=) k8s.ns=default k8s.pod=falco-daemonset-mjv2d container=daeaaf1c0551 k8s.ns=default k8s.pod=falco-daemonset-mjv2d container=daeaaf1c0551","priority":"Notice","rule":"Terminal shell in container","time":"2020-02-13T20:47:39.535071657Z", "output_fields": {"container.id":"daeaaf1c0551","container.image.repository":null,"evt.time":1581626859535071657,"k8s.ns.name":"default","k8s.pod.name":"falco-daemonset-mjv2d","proc.cmdline":"bash","proc.name":"bash","proc.pname":"runc","proc.tty":34816,"user.name":"root"}}
    ```
继续，接下来的两个选项告诉 Falco 将**Falco 级**事件记录到`stderr`和`syslog`:
```
log_stderr: true
log_syslog: true
```
此设置对您的规则文件将监控的事件没有任何影响，而是配置如何记录 **Falco 系统事件**:
```
log_stderr: true
log_syslog: true
log_level: info
```
两个选项的默认值都是`true`，因此所有事件都将记录到`stderr`和`syslog`中。
接下来是您想要捕获的日志级别，接受的值包括`emergency`、`alert`、`critical`、`error`、`warning`、`notice`、`info`和`debug`。
继续，优先级别指定 Falco 将使用的规则集。任何规则优先级等于或高于配置值的规则集都将由 Falco 评估以生成警报:
```
priority: debug
```
默认值为`debug`。其他可以设置的值有`emergency`、`alert`、`critical`、`error`、`warning`、`notice`、`info`。
接下来是启用或禁用`buffered_output`的值。默认情况下，`buffered_outputs`设置为`false`:
```
buffered_outputs: false
```
为了传递系统调用，Falco 使用了一个可以填满的共享缓冲区，当该值设置为`true`时，可以配置缓冲区告诉 Falco 如何反应。默认值通常是初始配置的良好起始值。Falco 团队在他们位于[https://falco.org/docs/event-sources/dropped-events/](https://falco.org/docs/event-sources/dropped-events/)的主文档页面上有关于丢弃事件的详细解释。
`syscall_events_drops`设置可以设置为`ignore`、`log`、`alert`和`exit`。该速率配置 Falco 执行已配置操作的频率。该值为每秒操作数，因此该示例告诉 Falco 每 30 秒执行一个操作:
```
syscall_event_drops:
  actions:
    - log
    - alert
  rate: .03333
  max_burst: 10
```
`outputs`部分允许您限制来自 Falco 的通知，包含两个值，`rate`和`max_burst`:
```
outputs:
  rate: 1
  max_burst: 1000
```
`syslog_output`部分告诉 Falco 将事件输出到系统日志。默认情况下，该值设置为`true`:
```
syslog_output:
  enabled: true
```
在某些使用情况下，您可能希望将 Falco 配置为将事件输出到一个文件中，作为 stdout 的补充或替代。默认情况下，该选项设置为`false`，但您可以通过将其设置为`true`并提供文件名来启用它。`keep_alive`值默认设置为`false`，这将配置 Falco 保持文件打开并连续写入数据，而不关闭文件。如果设置为`false`，文件将在每个事件发生时打开，并在事件写入后关闭:
```
file_output:
  enabled: false
  keep_alive: false