onion belonging to temp to next node
Retrieve (temp, O = (sid, Ps, Pr, m, n, P, i), j) from L;
O ← (sid, Ps, Pr, m, n, P, j); // jth router reached
if j < n + 1 then
temp(cid:48) ←R temporary ID;
Send “temp(cid:48) received” to Poj ;
Store (temp(cid:48), O) in Boj ;
Forward_Onion(temp(cid:48)) to continue
if m (cid:54)=⊥ then
Send “Message m received” to Pr
else
// See
On message Forward_Onion(temp(cid:48)) from Pi
// Pi is done processing onion with temp(cid:48) (either
if (temp(cid:48), ) ∈ Bi then
decided by Z if honest or S if corrupted)
Retrieve (temp(cid:48), O) from Bi;
Remove (temp(cid:48), O) from Bi;
Process_Next_Step(O);
of proving privacy to the attacks excluded by our adversary
class C.
IV. FIRST PITFALL: INCOMPLETE PROPERTIES
We ﬁrst explain a known attack on Sphinx that should not
be possible if Sphinx realizes the ideal functionality. Then
we analyze the properties to see why the insecurity was not
detected in the proof: the properties are incomplete and some
of them do not increase privacy. We further generalize the
attack on Sphinx and introduce an insecure protocol to make
the shortcoming obvious and to help us in the construction
of a new improved property. After that, we present a second
independent insecurity, a corresponding broken protocol and
again construct a new property to protect against it. Finally,
we ensure that no more properties are missing by proving that
they indeed imply the ideal functionality.
A. Attack on Sphinx
In Sphinx as presented in [13] the exit node receives β as
part of the header. β contains the receiver address, an identiﬁer,
and a 0-bit string to pad β for the exit node to a ﬁxed length.
It is again padded with a ﬁller string of random bits that
compensates for the parts used to encrypt the earlier relay
addresses. Further, the three components are XORed with the
output of a pseudo-random number generator (PRNG).
The exit node hence can learn the length of the chosen path8
with the following attack: The adversarial exit node observes
(after XORing) where the ﬁrst 1 bit after the identiﬁer is.
It knows that the ﬁller string starts there or earlier and can
determine by the length of the ﬁller string a lower bound on
the length of the path used.
Being able to know the length of the path is critical. If e.g.
the routing topology is restricted or large parts of the path
are only adversarial relays, this information limits the number
of users under which the sender can hide and thus reduces
her protection. According to the ideal functionality such an
attack should not be possible if Sphinx, as proven with the
properties of Camenisch and Lysyanskaya, realizes the ideal
functionality.
B. Analyzing the Original Properties
In this section we have a closer look at the properties
to see why the attack on Sphinx is not detected and we
make four observations. The original deﬁnition of Onion-
Correctness technically was not entirely correct, which we
ﬁx brieﬂy. Integrity and Wrap-Resistance do not add privacy to
the proposed combination of properties, at all. Onion-Security
is required, but fails to protect against some weaknesses.
1) Onion-Correctness: Informally, Onion-Correctness re-
quires that all messages use the intended path and reach the
intended receiver in absence of an adversary:
Deﬁnition
1
(Original
(G, FormOnion, ProcOnion) be
Onion-Correctness):
Let
an OR scheme with
8To the best of our knowledge this ﬂaw is only mentioned and corrected
in the Sphinx implementation so far: https://github.com/UCL-InfoSec/sphinx/
blob/c05b7034eaffd8f98454e0619b0b1548a9fa0f42/SphinxClient.py#L67
173
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:04:48 UTC from IEEE Xplore.  Restrictions apply. 
maximal path length N. Then for all polynomial numbers of
routers Pi, for all settings of the public parameters p, for all
(P K(P ), SK(P )) generated by G(1λ, p, P ), for all n < N,
for all messages m ∈ M, and for all onions O1 formed as
(O1, . . . , On+1) ←FormOnion(m, (P1, . . . , Pn+1),
the following is true:
(P K(P1), . . . , P K(Pn+1)))
1) correct path: P(O1, P1) = (P1, . . . , Pn+1),
2) correct layering: L(O1, P1) = (O1, . . . , On+1),
3) correct decryption:
(m,⊥) = ProcOnion(SK(Pn+1), On+1, Pn+1),
where P(O, P ) returns the path included in O and L(O, P )
the onion layers.
This however cannot be achieved by Sphinx or almost any
other system suggested or implemented so far. They commonly
use duplicate checks, which, practically implemented, may
fail in a small number of cases (for example due to hash
collisions) in reality. We hence allow the requirements 1) - 3)
of the deﬁnition to fail with negligible probability, so that real
systems can achieve Onion-Correctness at all.
2) Wrap-Resistance and Onion-Integrity: We analyzed
Wrap-Resistance and Onion-Integrity and proved that they
do not contribute anything to the privacy of a protocol that
achieves Onion-Security and -Correctness.
We refer the interested reader to the extended version of
this paper [24] for details. In short, we provide a template to
add Wrap-Resistance and Onion-Integrity to any OR protocol
that meets Onion-Security and Correctness, and prove that the
template does not reduce what adversaries can learn.
3) Onion-Security: Onion-Security states that an adversary
on the path between an honest sender and the next honest node
(relay or receiver) cannot distinguish an onion that was created
with her inputs (except for the keys of the honest node) from
another one that contains a different message and is destined
for this next honest node.
Fig. 1. Onion-Security game illustrated: Circled numbers represent the steps,
and the boxes the parties of the game.
a) Game Structure: We illustrate the Onion-Security
game in Fig. 1 and explain the steps informally ﬁrst:
Basic Game (Step 1, 3 - 6, 8): Apart from an honest
sender, Onion-Security assumes the existence of only a single
honest relay (Pj). First in Step 1, the challenger chooses the
name and public key of the honest node and sends it to the
adversary. In the challenge starting in Step 3, the adversary
is allowed to pick any combination of message and path as
input choice of the honest sender, to model the worst case. In
Step 4-6 the challenger checks that the choice is valid and if
so, creates two onions O1, ¯O1 and sends one of them to the
adversary depending on the challenge bit b. Finally in Step 8,
the adversary makes a guess b(cid:48) on which onion she received.
Adaptive and Modiﬁcation Attacks (Step 2 and 7): So
far the adversary only focused on one onion. However, a real
adversary can act adaptively and observe and send modiﬁed
onions to the honest node that she wants to bypass before and
after the actual attack. Therefore, Onion-Security includes two
oracle steps. To decide on her input and guess, the adversary
is allowed to insert onions (other than the challenge onion) to
the honest relay and observe the processed output as an oracle
(Steps 2 and 7).
How the two onions O1, ¯O1 differ is illustrated in Fig. 2. O1
is the ﬁrst layer of the onion formed with the adversary chosen
inputs, where the honest relay is at position j. In contrast, ¯O1
is the ﬁrst layer of the onion formed with the same path as O1
except that the path ends at Pj as the receiver and a random
message. The adversary can calculate the onion layers up to
the honest relay based on the ﬁrst layer. Onion-Security is
achieved if the adversary is unable to distinguish whether the
observed onion contains her chosen inputs or random content
destined for the honest relay.
Fig. 2. Cases of Onion-Security illustrated: Red boxes represented corrupted
relays, black boxes honest. The upper row of arrows represents the path of
the onion O with inputs chosen by the adversary (message m received by
Pn+1); the lower an onion ¯O containing a randomly chosen message m(cid:48) that
takes the path to the honest relay Pj, only. For b = 0 the onion layers in
the orange ellipse are observed by the adversary, i.e. the layers processed at
P1..Pj−1 of onion O. For b = 1 the layers in the blue ellipse are observed,
i.e. the corresponding layers of ¯O. Notice that the adversary does not observe
any output of Pj in this game.
b) Deﬁnition: Formally,
deﬁned as follows:
the Onion-Security game is
Deﬁnition 2 (Original Onion-Security): Consider an adver-
sary interacting with an OR challenger as follows.
1) The adversary receives as input a challenge public
key P K, chosen by the challenger who generates
(P K, SK) ← G(1λ, p, Pj), and the router name Pj.
2) The adversary submits any number of onions Oi of her
choice to the challenger (oracle queries), and obtains
the output of ProcOnion(SK, Oi, Pj).
3) The adversary submits n, a message m, a set of router
names (P1, . . . , Pn+1), an index j, and n key pairs
1 ≤ i ≤ n + 1, i (cid:54)= j, (P Ki, SKi).
4) The challenger checks that the router names are valid,
that the public keys correspond to the secret keys and
if so, sets P Kj = P K and sets bit b at random.
m(cid:48) ←R M randomly and calculates:
(O1, . . . , Oj, . . . , On+1) ←
FormOnion(m, (P1, . . . , Pn+1), (P K1, . . . , P Kn+1))
5) If the adversary input was valid, the challenger picks
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:04:48 UTC from IEEE Xplore.  Restrictions apply. 
174
ChallengerAdversary852Oracle13Check467OracleChallenge,Createor......b=0b=1...( ¯O1, . . . , ¯Oj) ←
FormOnion(m(cid:48), (P1, . . . , Pj), (P K1, . . . , P Kj))
6) • If b = 0, the challenger returns O1 to the adversary.
• Otherwise, the challenger returns ¯O1 to the adver-
sary.
7) The adversary may again query the oracle and submit
any number of onions Oi (cid:54)= Oj, Oi (cid:54)= ¯Oj of her
choice to the challenger, to obtain the output of
ProcOnion(SK, Oi, Pj).
8) The adversary then produces a guess b(cid:48).
Onion-Security is achieved if any probabilistic polynomial
time (PPT) adversary A, cannot guess b(cid:48) = b with a probability
non-negligibly better than 1
2.
Onion-Security hence aims at guaranteeing that an adversary
observing an onion before it is processed by an honest relay
cannot discover information about the message it contains,
or the path it subsequently takes. As the adversary controls
all links, she could link message and receiver to the sender,
otherwise. Further, step 7 provides protection against active
modiﬁcation attacks, as it allows processing of any modiﬁed
onion.
The property however does not consider a malicious receiver
or exit node, which hence might be able to discover information
about the path or sender. Notice that this is exactly what
happens in the attack on Sphinx; a malicious exit node learns
information (the length) of the path.
C. Security against Malicous Receivers
In this subsection, we show the ﬁrst shortcoming, missing
protection against a malicious receiver, by giving a simpliﬁed
broken protocol that allows the receiver to learn the complete
path and yet achieves all suggested properties. Based on this
discovery we introduce an improved property.
1) Insecurity: Signaling the Path: We ﬁrst generalize the
attack on Sphinx from Section IV-A, which only leaked the
path length. As generalization we give a protocol that complies
to the properties, but includes the complete path (including the
sender) in the message. Thus, an adversarial receiver learns
the complete path the onion took.
This weakness differs from the common assumption that
one cannot protect senders that reveal their identity in their
self-chosen message: independent of the message the sender
chooses, the protocol always adds the complete sender-chosen
path to it. Thus, an adversarial receiver always learns the sender
and all relays independent of the sender’s choice. Clearly, such
an OR scheme should not be considered secure and private
and hence should not achieve the OR properties.
a) Insecure Protocol 1: The main idea of this counterex-
ample is to use a secure OR scheme and adapt it such that the
path is part of the sent message.
More formally, our extended protocol Πbroken1 using
FormOnionbroken1 and ProcOnionbroken1 is created from
the “secure” onion routing protocol Π from [8]. Π transfers
a message m from a sender P0 to a receiver Pn+1 over n
intermediate routers {Pi} for 1 ≤ i ≤ n using FormOnionΠ
and ProcOnionΠ.
Sender [FormOnionbroken1]: The sender P0 wants to
send message m ∈ {0, 1}lm−lP over path P, where lm
is the length of messages in Π and lP is the maximal
length of the encoding of any valid path including the sender.
FormOnionbroken1 creates a new message m(cid:48) = m(cid:107)e(P0(cid:107)P),
where e encodes the path and is padded to length lP .
FormOnionbroken1 runs the original algorithm FormOnionΠ
with the inputs chosen by the sender except that the message
is replaced with m(cid:48).
Intermediate Router [ProcOnionbroken1]: Any interme-
diate runs ProcOnionΠ on Oi to create Oi+1 and sends it to
the next router.
Receiver [ProcOnionbroken1]: The receiver getting On+1
executes ProcOnionΠ on it to retrieve m(cid:48). It learns the path
from the last lP bits and outputs the ﬁrst lm − lP bits as the
received message.
b) Analysis regarding properties: The properties follow
from the corresponding properties of the original protocol. As
we only add and remove e(P0(cid:107)P) to and from the message,
the same path is taken and the complete onion layers Oi are
calculated as before. Hence, Correctness and Onion-Integrity
hold, and re-wrapping them is as difﬁcult as before. Only Onion-
Security remains. As Π has Onion-Security, the adversary
cannot learn enough about the message included in the ﬁrst
onion layers to distinguish it from a random message. Thus,
she especially cannot distinguish the last lP bits from random
ones in Π. As in Onion-Security the adversary learns nothing
else, the adversary in Πbroken1 cannot distinguish our adapted
message bits from random ones. Thus, adapting does not
introduce any advantage in breaking Onion-Security.
2) Improved Property: Tail-Indistinguishability T I against
a corrupted receiver : We construct the new property Tail-
Indistinguishability T I to deal with malicious receivers. There-
fore, the adversary has to get access to the onion layers after
the last honest relay has processed them because a malicious
receiver learns those. Our property challenges the adversary
behind the last honest relay to distinguish between the onion
generated with her original inputs, and a second onion that
carries the identical message and follows the identical path
behind the honest relay but otherwise was constructed with
randomly chosen input, i.e. the path before the honest node is
chosen randomly.
Note that this new property indeed prevents the insecurity
given in Section IV-C1 and the attack on Sphinx: If the receiver
is able to reconstruct any information of the path before the
honest node, the adversary can compare this information with
her input choice. In case the information does not match her
choice, she knows that it must have been the second onion
and thus is able to distinguish the onions.
Intuitively, the steps are the same as in Onion-Security
described in Section IV-B3a, except that we change the answer
to the challenge. This time we protect the last part of the
path and output those layers. Since the receiver is corrupted,
the message is learned by the adversary anyways and hence
we use the same message for the alternative layers (b = 1).
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:04:48 UTC from IEEE Xplore.  Restrictions apply. 
175
Fig. 3. Cases of T I illustrated: Red boxes are adversarial routers; black boxes
honest and curvy arrows symbolize a random path possibly through many
other adversarial routers. In case b = 0 the adversary chosen onion is observed
at the end of the path (orange ellipse). For b = 1 onion layers that take the
same path between Pj and Pn+1 and include the same message (the blue
ellipse), but differ otherwise, are observed instead. Earlier layers (before Pj)
are in both cases not given to the adversary.
We illustrate the new outputs to the adversary in Fig. 3 and
formally deﬁne the new property in our Deﬁnition 3.
Thus, our ﬁrst new property T I is deﬁned as:
Deﬁnition 3 (Tail-Indistinguishability T I):
1) The adversary receives as input the challenge pub-
lic key P K, chosen by the challenger by letting
(P K, SK) ← G(1λ, p, Pj), and the router name Pj.
2) The adversary may submit any number of onions Oi of