bedded in the query string; during replay, the timestamp embed-
ded in the requested URL was always a few milliseconds off, com-
pared to the recording phase6, thus causing a mismatch. We later7
solved this URL mismatch problem with a minor adjustment to the
implementation of the algorithm discussed in Section 5.3 for “re-
synchronizing” currentTime()’s return value. This allowed us
to correctly replay Acid3 tests with 100% accuracy, and further im-
prove the overall replay accuracy of WebCapsule.
5Error message: “Test 80 failed: timeout – could be a networking
issue”
6e.g., recorded URL: empty.html?1431430350104; replay URL:
empty.html?1431430350157
7After initial submission
WebCapsule’s main goal is to enable an always-on and transpar-
ent collection of browsing data that can help a forensic analyst to
precisely reconstruct web-based attacks, especially for attacks that
directly target users, such as phishing attacks.
To test if WebCapsule can successfully record and subsequently
replay real-world phishing attacks, we proceeded as follows, us-
ing Chromium on our desktop machine. We selected a large and
diverse set of recently reported phishing web pages from Phish-
Tank8. The pages we tested represented “fresh” (recently reported)
attack URLs. Overall, the attack traces were recorded by six dif-
ferent users who visited and interacted with a total of 112 different
active phishing URLs. Each user visited around 15 to 20 URLs
and simulated the leakage of (fake) information. Essentially, all
phishing pages aim to trick the user into providing some type of
personal user information, such as the user name and password re-
quired to access popular services (e.g., Google Drive, Yahoo Mail,
etc.). In addition, we tested several phishing attacks mimicking on-
line banking sites (e.g., Bank of America, Barclays, Paypal, etc.).
These attacks are particularly aggressive, in that they attempt to
trick the user into providing a large number of highly sensitive
data, including social security numbers, date of birth, driver’s li-
cense numbers, mother maiden name, answer to multiple security
questions, etc.
To determine how well WebCapsule can record and replay phish-
ing attacks, we measured the following quantities. For each at-
tack trace, we wanted to quantify how well each trace could be
replayed. To this end, every time a mouse click or keypress event
occurred during replay, we compared the target DOM element of
the replay event to the target DOM element of the same event ob-
served during recording. For example, assume that during replay
a mouse click m was injected on an anchor element, say e(cid:48) =go. As discussed in Section 4, during
recording not only do we store the internal details of m, but also
its original target element e. Therefore, during replay we can per-
form a comparison between e(cid:48) and e, and increment the number of
target errors if the elements differ. Similarly, we recorded the URL
of each page (speciﬁcally, the main frame URL) through which the
user navigated while under phishing attack. Then, we compared
the URLs observed during replay with the ones observed during
recording, and counted differences in the page URL sequences.
The results are summarized in Table 2. As can be seen, the vast
majority of traces (almost 90%) replayed perfectly. Speciﬁcally,
WebCapsule was able to replay 106 out of 112 phishing traces
with no page transition errors. The 6 page errors were primarily
caused by corner case scenarios that are not currently handled by
our proof-of-concept code and that could be ﬁxed with additional
engineering effort. For example, in some cases our network replay
approach (see Section 5.3) failed to match a dynamically generated
URL, and at the same time the JavaScript call stack matching al-
gorithm described in Section 5.3 was not able to correctly recover
the appropriate network response. We plan to add support for these
corner cases in our next releases of WebCapsule.
Also, 100 traces had no target element errors for mouse click
events, and 103 traces had no keypress target element errors. For
the remaining traces with click and keypress target element errors,
most of them were related to the 6 page transition errors. For exam-
ple, if a page transition error occurs, a click event may be replayed
on the wrong page, and therefore also on the wrong target element.
In other cases, an error may occur even if the event is injected in the
correct page. One of the main causes for this is as follows. Some at-
8http://www.phishtank.com/phish_archive.php
141Table 2: Replay correctness for phishing attack pages. Measure-
ments performed over 112 phishing traces collected by 6 users.
Page Transitions
Clicks
Keypresses
Avg. # Events
per Trace
4
14
270
100% Correct
Traces
106/112
100/112
103/112
Traces with
Some Errors
6/112
12/112
9/112
Table 3: Performance test results. Overhead computed during
recording of browsing activities on popular websites.
Linux
(Optiplex)
Platform Website
Google
Facebook
Youtube
Amazon
Yahoo
Wikipedia
Ebay
Reddit
Google
Craigslist
Youtube
Flickr
IMDB
Yelp
Ebay
Reddit
Android
(Nexus 7)
WebAPI
overhead %
Platform
overhead %
Network
overhead %
16.08
5.30
5.04
16.78
8.99
15.51
7.63
13.16
6.89
7.68
7.77
8.23
7.48
6.33
7.23
4.40
0.12
1.58
0.67
0.72
0.20
0.22
0.34
0.14
0.78
0.58
0.66
0.75
0.76
0.59
0.82
0.57
3.76
0.54
2.57
0.32
0.89
0.33
0.31
1.39
1.49
0.19
1.39
0.75
0.15
1.59
0.77
1.85
tack pages made heavy use of JavaScript, to the point that the entire
page content was generated in a completely dynamic way. While
our prototype implementation of WebCapsule can replay the vast
majority of these cases, we encountered some scenarios in which
the replay of JavaScript code used for building the page was not
completely accurate. Therefore, the page content did not render the
same exact way as during recording, and the click and keypresses
missed the related targets on those pages. In our future work, we
plan to also add support for the above cases as well.
6.4 Record & Replay of Popular Websites
To further evaluate WebCapsule’s record and replay functional-
ities and measure the overhead introduced by our instrumentation
of Blink, we performed tests on several representative popular web-
sites, on both Linux and Android devices (see Section 6.1 for de-
tails on device conﬁgurations).
Performance Analysis. For each website shown in Table 3, we
performed a few minutes of “fast pace” browsing, during which we
issued numerous input events, such as mouse clicks, touchscreen
gestures, and keypresses, and navigated through several pages. Dur-
ing this test, we recorded the browsing activities and measured the
overhead introduced by our WebCapsule instrumentation code over
Blink. To accomplish this goal, we leveraged the proﬁling frame-
work already implemented in Blink. Speciﬁcally, we added calls
to TRACE_EVENT macros [27] within each single Blink function
we instrumented, including around all web-rendering API (or Web
API, for short), platform, and network-related “hooks” that we use
to record non-deterministic inputs. This allowed us to precisely
compute the CPU overhead introduced by our recording infrastruc-
ture. The results are reported in Table 3. We break down the over-
head introduced by the code used to record Web API, platform, and
network events, respectively.
Our results show that WebCapsule introduces reasonable over-
head both on Linux and Android, making its use as an always-on
system practical. For the Web API events overhead, which is al-
ways lower than 17% on Linux and 9% on Android, we need to
consider that this corresponds to only a few milliseconds of over-
head added to the processing of a user input event. During the
recording of our browsing traces this delay was visually unnotice-
able to the user. The platform overhead, which measures the added
time spent to record the input and return values of calls to Blink’s
platform API calls, is always low on both platforms, never exceed-
ing 2%. Finally, the time spent by WebCapsule to record network
requests and responses has only a small impact on network latency,
with an overhead always below 4%. The lower WebAPI perfor-
mance overhead for the Android traces is likely due to the lower
complexity of the mobile version of the websites (e.g., taking a
snapshot of the DOM at every click is less expensive).
We also computed the amount of data that would need to be
stored to archive WebCapsule’s browsing traces. On average, using
Chromium our browsing on popular websites produced 37.3kB/s of
ofﬂoaded browsing events data, with network-related data being re-
sponsible for the vast majority (almost entirety) of the ofﬂoaded in-
formation. As we mentioned in Section 2 (see non-goals and future
work), in this paper we do not focus on how to minimize storage
use. However, it is worth noting that many enterprise networks al-
ready use commercial solutions to store full network packet traces
for considerable periods of time (e.g., for compliance or security
reasons). Therefore, it would be possible to adapt such solutions to
store WebCapsule’s traces.
Replaying Browsing Traces. Besides measuring the performance
overhead introduced by WebCapsule in recording mode, we also
tested how well the recorded traces could be replayed. As shown
in Table 4 the vast majority of traces replayed correctly, with no
visually noticeable difference in the rendering of the pages be-
tween recording and replay. On Linux, only Youtube caused a
replay problem. Speciﬁcally, while replaying the Youtube brows-
ing trace we encountered an assertion failure9 on a part of Blink’s
code dedicated to “painting” the rendered page, causing the page,
and our instrumentation agent, to freeze. We plan to further in-
vestigate and correct this issue in future versions of WebCapsule.
We were also able to successfully replay searching/browsing on
Google.com. However, replay was fully successful (on both Linux
and Android) only with Google Instant predictions turned off [14].
Google Instant’s JavaScript code seems to use a non-deterministic
input that is not fully supported by our prototype. This causes
one of the parameters of the URLs for network requests issued by
Google Instant during replay to be slightly different from recording.
While our JavaScript call stack matching algorithm (Section 5.3)
helps us identify the correct (previously recorded) network response
to re-inject into Blink, it appears that Instant’s code performs some
sort of “response content veriﬁcation,” which prevents the Instant
search results to be correctly rendered. Because the relevant Java-
Script code is heavily minimized, reverse-engineering Google In-
stant is fairly complex. Therefore, we plan to add support for
Google Instant in future releases of WebCapsule.
For our Android experiments performed on the Nexus 7, we per-
formed multiple tests on each of the sites listed in Table 4. For
each site, we were able to record and fully replay the browsing ac-
tivities. Only two sites caused some issues, and only for speciﬁc
browsing scenarios. Speciﬁcally, on Youtube and Yelp our record-
ing engine did not support the site’s search functionality. Namely,
after typing a search term and hitting Enter or the search button, the
search results would load but in some cases the browser page would
freeze. Performing other browsing activities on Youtube (with no
search) did not cause any noticeable issues, and both record and re-
play worked with no problems. Recording and replaying Yelp also
worked better when the site’s search function was not used, though
9!m_needsToUpdateAncestorDependentProperties
– in RenderLayer.h
142Table 4: Record and replay tests on popular websites. Test are
marked as follows:  = successful test; # successful test with some
divergence;  test with problems; 0 test with problems that we
later ﬁxed. Multiple symbols indicate different results depending
on the type of browsing activity on the site.
Platform Site
Record Replay Comment
Linux
Android
Google

Facebook 
Youtube

Amazon

Yahoo

Wikipedia 
Ebay

Reddit

Google

Craigslist

Youtube
0
Flickr

IMDB

Yelp
0
Ebay
