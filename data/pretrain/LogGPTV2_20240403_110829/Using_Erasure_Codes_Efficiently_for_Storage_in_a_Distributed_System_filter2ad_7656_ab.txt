Code for storage node Si:
variable: block
operation read()
return block
operation swap(v)
retsect ← block
block ← v
return retsect
READ
WRITE
read
1
swap
2
add
operation add(v)
block ← block + v
(A)
(B)
WRITE
d b
add
d-b
b
a
a
c
a+b
add
c-a
add
b-d
a-b
add
c-a
(C)
WRITE
Fig. 3. Simpliﬁed algorithm: (A) code, (B) depiction, (C) example of concurrent writes preserving consistency of
erasure code without any client coordination.
we can end up with (c, b, c+b, a−b). Here, a−b is an inconsistency. If
two storage nodes fail, this inconsistency not only prevents recovery of
correct data, but it may be undetectable. For example, if storage nodes
2 and 3 fail, we get (c, −, −, a−b). This conﬁguration is completely
consistent with c − a + b being previously stored in crashed node 2,
and so it cannot be detected.
3.5. Failure detection and node remap
In our scheme, the failure of a storage node is detected when a client
tries to access the node (we also allow to use periodic pings from some
monitoring facility). This client then starts an expensive operation to
reconstruct the lost data, which may need to be placed in a new storage
node, if the failed one has not recovered (and it may never recovery).
In those cases, we assume that a fresh replacement storage node is
available, and there is some mechanism—like a directory service—to
direct clients to this new node: clients simply access some logical
node, which gets remapped on failures. The storage node has a ﬂag
indicating whether its data is valid, or just some uninitialized garbage.
3.6. Simple algorithm
Fig. 3 shows a simpliﬁed version of our algorithm that shows a core
idea for the full algorithm. The simpliﬁed algorithm merely keeps data
in n nodes consistent with a k-of-n erasure code, without tolerating
failures. To read and write blocks 1, . . . , k in a stripe, a client p
communicates with storage nodes S1, . . . , Sn via remote procedure
calls. Storage nodes S1, . . . , Sk keep the data blocks, while nodes
Sk+1, . . . , Sn keep redundant blocks according to the erasure code.
To READ block i (i ≤ k), p simply calls operation “read” on node Si.
To WRITE v to block i (i ≤ k), p swaps v into Si, obtaining the old
content w, and then adds αji.(v − w) to each redundant block in Sj
for j = k +1, . . . , n, where αji are the erasure code coefﬁcients. The
pfor is a parallel-for, whose iterations may be executed in parallel;
after the pfor, the execution merges back.
What is interesting about this algorithm is that it keeps the erasure
code consistent even if multiple clients write in parallel, regardless of
how execution interleaves, even if both clients are trying to change the
redundant blocks simultaneously. (This is not obvious; see Fig. 3 (C)
for an example using the sample erasure code of Section 3.3.) And it
does so without any synchronization via locks or two-phase commits.
3.7. Full algorithm: read and write
We now explain the full algorithm. Figure 4 shows the code
for reading. In failure-free cases, it is very similar to the simple
algorithm of Section 3.6. When a storage node fails and a new node is
remapped (cf Section 3.5), the new node starts with opmode = INIT,
indicating its data is initialized garbage. If a client tries to read
from such a node,
the read fails by returning ⊥, and the client
invokes the recovery procedure (Section 3.8) if the block is not locked
(lmode ∈ {UNL, EXP}). If the block is locked, another client is already
executing recovery.
Figure 5 gives the algorithm for writing data. When there are no
failures and no clients WRITE to the same block simultaneously,
the algorithm behaves like the simple algorithm of Section 3.6: To
WRITE, client p ﬁrst invokes swap (line 3), which returns blk (cid:4)= ⊥.
Then p invokes add on each redundant storage node (line 10). The
adds all succeed, and so D is set to {i, k + 1, . . . , n} (line 11),
Retry is set to ∅ (line 12), and T is set to ∅ (line 20), which causes
p to ﬁnish the loops. The English comments in the ﬁgure provide a
walk-through of the code, and to avoid repetition, we only explain
here the higher level mechanisms. The basic idea to deal with storage
node failures is for a client to invoke a recovery procedure, and later
retry its WRITE or READ operation. More precisely, when storage
node Si fails, the remapped node (cf Section 3.5) starts out with
opmode = INIT and lmode = UNL. When p invokes swap on Si,
swap fails, and p starts the recovery procedure. Recovery reads data
from all storage nodes and uses the erasure code to reconstruct the
lost data. Most of the complication in the write algorithm is to deal
with concurrent online recovery by another client. We come back to
these topics in Section 3.8.
Concurrent writes to the same block. To guarantee recoverability,
the algorithm ensures that if clients p and q WRITE to the same block,
they apply swap and adds in the same order at all storage nodes. This
ordering is ensured as follows: a swap operation returns to the caller
p an identiﬁer otid for the previous WRITE; p then piggybacks otid
to the add operations on redundant blocks; upon receive an add, a
storage node checks if it previously saw otid (otid ∈ recentlist); if not,
the storage node rejects the add and returns a special ORDER status
code, which tells p to retry later. If the client executing the previous
WRITE crashes, then p may retry many times without success. After
a certain number of attempts, p starts the recovery procedure. Note
that concurrent writes to the same block are very rare in most systems
(e.g., [5]).
3.8. Recovery algorithm
The basic idea for data recovery is to read all blocks from the
storage nodes, decode them using the erasure code, and write back
the results. The main issues are the following:
• Blocks may all be inconsistent with each other, due to outstanding
WRITES and failed storage nodes with random blocks. Mechanisms
are needed to (A) know when a group of blocks are consistent, i.e.,
they yield correct data when used for reconstruction, and (B) ensure
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
// 1 ≤ i ≤ k
Code for client p:
To READ(i) do
1 (cid:4)v, lmode(cid:5) ← Si.read()
2 while v = ⊥ do
3
4
5
6 return v
if lmode ∈ {UNL, EXP}
then start recovery()
(cid:4)v, lmode(cid:5) ← Si.read()
// start recovery procedure
// retry read
// NORM: valid data in block; INIT: invalid data; RECONS: limbo
Code for storage node Si:
Global variables:
7 block, initially 0, after fail-remap random // block content
8 opmode ∈ {NORM, RECONS, INIT}, initially NORM, after fail-remap INIT
9
10 lmode ∈ {UNL, L0, L1, EXP}, initially UNL, after fail-remap UNL
11
operation read()
12 if opmode (cid:1)= NORM or lmode (cid:1)= UNL
13 then return (cid:4)block : ⊥, lmode(cid:5)
14 else return (cid:4)block : block, lmode(cid:5)
// UNL: block unlocked; L0, L1: partial or full lock; EXP: expired lock
Fig. 4. Full algorithm for reading data.
that some group with at least k blocks is or eventually becomes
consistent, where k is the number required by the erasure code.
• If a client p crashes while executing recovery, recovery must be
completable by another client.
• A WRITE concurrent with recovery may garble the redundant
blocks after recovery completes.
We now explain how we address the above issues.
Recent list. To know if a group of blocks are consistent with each
other, storage nodes keep a list with the identiﬁers of past WRITES
that have modiﬁed data in the storage node (the list is periodically
garbage collected; see Section 3.9). More precisely, when a client p
starts a WRITE, it picks a unique identiﬁer tid for the WRITE. The
tid is piggybacked on swap and add requests and, when a storage
node receives one such request, it stores the identiﬁer in the node’s
recentlist variable. The recovery procedure reads the recentlist from
nodes to determine which blocks have been updated consistently.
The basic recovery procedure. Recovery can be executed by any
client p, and it has three phases. In phase (1), p acquires locks at
each storage node. These nodes maintain the lock state in their local
variable lmode: lmode = UNL allows swap and add operations, while
lmode = L1 will reject them. Locks serve two purposes: (i) they
“freeze” the data in storage nodes and (ii) they prevent different clients
from concurrently executing recovery. To avoid deadlocks, locks are
acquired in order, but other standard mechanisms can be used, like
retrying after some exponential back-off.‡
In phase (2), p reads the contents and states of all storage nodes
(line 7) and checks if there are k + slack blocks consistent with each
other, where k is the number of blocks needed by the erasure code,
and slack is explained below. If there are not, p “weakens” the lock
on the redundant storage nodes, by setting their lmode = L0: in this
mode, a node allows adds to execute, but the node remains otherwise
locked. The intuition here is that p wants outstanding WRITES to
complete their adds so that blocks become consistent. With the proper
bounds on failures, p will eventually ﬁnd a large enough consistent
set of blocks. Next p tries to change back the lmode of nodes to L1
(full lock mode) before further adds occur (line 19).§ If p does not
succeed, p restarts the search for consistent blocks. (Note that p will
eventually succeed because swaps are blocked, so new WRITES will
not issue adds.) Else p sets the nodes’ opmode variable to RECONS
(explained below).
‡Lines 4–6 in the algorithm are for storage nodes that fail while locked,
losing their locked state.
§The reason is that additional adds may cause a WRITE to complete, and
so the recovered contents must include the effects of such WRITE.
In phase (3), (a) p uses the found consistent blocks to reconstruct
data through the erasure code, (b) p writes the recovered data to the
storage nodes, (c) p changes nodes’ opmode to NORM (normal mode),
and (d) p unlocks the nodes.
Epochs. Roughly speaking, an epoch is the period between two
recoveries. A WRITE whose swap executes in one epoch should not
let its adds execute in later epochs because recovery already leaves
all blocks consistent. Thus, (a) swaps return an epoch number, (b)
recovery increments the epoch number, (c) p piggybacks the swap’s
epoch into adds, and (d) storage nodes reject adds from previous
epochs.
Crashes during recovery. If p crashes during recovery, nodes that
are locked (with lmode ∈ {L0, L1}) will “expire” their locks setting
lmode = EXP (line 34). If another client q sees a node in this lock
mode, q starts recovery. If p crashed before ending phase (2), the
data in storage nodes have not been changed, so re-recovery by q is
safe. Else p has set the nodes’ opmode to RECONS; when q sees that,
it skips phase (2) and, in phase (3), q does exactly what p would
have done (q gets the set of consistent blocks used by p by reading
the nodes’ variable recons set). The slack variable mentioned before
guarantees that q can still ﬁnd k consistent blocks, despite further
storage node failures.
3.9. Garbage collection algorithm
As explained above, storage nodes keep a list recentlist of the tids of
past writes. To garbage collect this list, we use a two-phase algorithm
to handle client crashes. In phase 2, all tids whose write has completed
are moved from list recentlist to list oldlist. In phase 1, tids from
oldlist are discarded. If the client crashes, the recentlist and oldlist of
different storage nodes may end up different. This is not a problem:
when using these lists to determine if a set of blocks is consistent, the
client knows that if tid is in some oldlist of any node, then the write
has occurred at all nodes. See function ﬁnd consistent in Figure 6 for
more details.
The mechanism to order WRITES to the same block needs to be
adjusted to work with garbage collection, as follows. After p gets an
ORDER status, rather than retrying the add immediately, p ﬁrst checks
if the otid has been garbage collected at the data storage node or any
of the redundant storage node; if otid is no longer at one or more
of these nodes, p knows that the WRITE for which it is waiting has
completed, so p can ask the redundant storage node to add without
checking for otid; else p retries the add after a while.
3.10. Monitoring mechanism to trigger recovery
If client crashes while writing, or a storage node crashes, the system
is in a fragile state that tolerates one less failure than before. It is
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
ntid ← (cid:4)seq, i, p(cid:5); seq ← seq + 1
(cid:4)blk, epoch, otid, lmode(cid:5) ← Si.swap(v, ntid)
while blk = ⊥ do
if lmode ∈ {UNL, EXP} then start recovery()
(cid:4)blk, epoch, otid, lmode(cid:5) ← Si.swap(v, ntid)
Code for client p:
Global variable: seq, initially 0
To WRITE (i, v) do
1 repeat
2
3
4
5
6
7
8 D ← {i}
9
10
11
12
13
T ← {k + 1, . . . , n}
while T (cid:1)= ∅ and D (cid:1)= ∅ do
(r[j].opmode (cid:1)= NORM and r[j].lmode = UNL) or
(r[j].status = ORDER and tired of looping)
then start recovery()
if ∃j ∈ T : r[j].status = ORDER then
pfor each j ∈ D do
14
15
16
17
18
19
20
21
22 until D = {i, k + 1, . . . , n}
T ← Retry
s[j] ← Sj .checktid(ntid, otid)
if ∃j ∈ D : s[j] = GC then otid ← ⊥
D ← D − {j ∈ D : s[j] = INIT}
for each j ∈ D do gc[j] ← gc[j] ∪ {ntid}
epoch ∈ N, initially 0, after fail-remap 0
recentlist ∈ set of (cid:4)tid, time(cid:5), initially ∅, after fail-remap ∅
oldlist ∈ set of (cid:4)tid, time(cid:5), initially ∅, after fail-remap ∅
time, initially 0, after fail-remap 0
if opmode (cid:1)= NORM or lmode (cid:1)= UNL
then return (cid:4)block : ⊥, epoch, ⊥, lmode(cid:5)
retblk ← block
block ← v
if recentlist = ∅ then otid ← ⊥
else otid ← tid in recentlist with largest time
recentlist ← recentlist ∪ {(cid:4)ntid, time(cid:5)}
return (cid:4)block : retblk, epoch, otid, lmode(cid:5)
return tid of entries in tidtime list
Code for storage node Si:
Global variables:
23
24
25
26
operation swap(v, ntid)
27
28
29
30
31
32
33
34
function tids(tidtime list)
35
operation add(v, ntid, otid, e)
36
37
38
39
40
41
42
operation checktid(ntid, otid)
43
44
45
if opmode (cid:1)= NORM or lmode (cid:1)∈ {UNL, L0} or e < epoch
then return (cid:4)status : ⊥, opmode, lmode(cid:5)
if otid (cid:1)= ⊥ and otid (cid:1)∈ tids(recentlist ∪ oldlist)
then return (cid:4)status : ORDER, opmode, lmode(cid:5)
block ← block + v
recentlist ← recentlist ∪ {(cid:4)ntid, time(cid:5)}
return (cid:4)status : OK, opmode, lmode(cid:5)
if ntid (cid:1)∈ tids(recentlist) then return INIT
else if otid (cid:1)∈ tids(recentlist) then return GC
else return NOCHANGE
// sequence number for unique transaction id (tid)
// obtain unique id
// swap new value into data block
// error, data unavailable
// nobody running recovery, so we do it
// try swap again
// node where we want to apply add operation
// nodes done with update
// while there are nodes to update, and done nodes are still up
// perform add at nodes in T
// successful nodes
// it is not in normal mode and unlocked or
// it has returned ORDER for too long
// then start recovery
// some node complained about ordering
// check if otid has been garbage collected
// yes, no need to check ordering any more
// remove crashed nodes from successful list
// for garbage collection
// repeat until all blocks have been updated
// epoch number
// recent write list
// old write list
// local time, auto incremented at some rate
// if not normal opmode or locked
// return error
// do swap
// no previous write
// ﬁnd tid of previous write
// record tid of this write
// return tids in a list
// if not normal opmode or locked or old epoch
// return error
// if previous write did not occur yet
// tell client
// perform add
// record tid of this add
for each j ∈ T do r[j] ← Sj .add(αji.(v−blk), ntid, otid, epoch)
D ← D ∪ {j ∈ T : r[j].status = OK}
Retry ← {j ∈ T : r[j].status = ORDER or r[j].lmode (cid:1)∈ {UNL, L0}}// nodes to retry due to ordering or lock problems
if ∃j ∈ T : r[j].lmode = EXP or
// if some node has expired lock or
// only occurs if node crashes
// previous write not yet performed
// all is ﬁne
Fig. 5. Algorithm for writing data.
thus desirable to restore the system’s resiliency by starting recovery.
Clients do so upon stumbling on a problem, but that only happens
if they try to read or write. Thus, it might be useful to have a
monitoring mechanism executed periodically by some client to probe
the system for failures, and trigger recovery if necessary. This can
be done very efﬁciently: for each storage node Si, the client simply
checks if (1) Si’s recentlist has some old tid, indicating a started but
unﬁnished write, or (2) Si’s opmode is INIT, indicating initialization
after recovery. In those cases, the client starts the recovery algorithm,