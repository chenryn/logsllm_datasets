guessed in 1012 guesses. We investigate two approaches with strength enforce-
ment: GuidedPass and zxcvbn.
6.2 User Study Design
In the user study, each participant was assigned at random to one approach
for password creation. We recruited participants with at least 1,000 completed
Human Intelligence Tasks (HITs) and >95% HIT acceptance rate. We asked
each participant to create one password for an imaginary server. After two days
each participant was invited to return to the study and attempt to authenticate
with their password. We paid 35 cents for password creation and 40 cents for
the authentication task, respectively.
Authentication. Each user was asked to authenticate two days after password
creation, allowing at most ﬁve trials per password and per visit. All users were
asked not to paste their answers. We had automated detection of copy or paste
attempts in our login forms, and we rejected the users who were detected to per-
form either of these two actions. We further displayed a notice to participants,
at both the creation and authentication screens, that they will receive the same
payment, regardless of their authentication success. This ensured that partici-
pants had no monetary incentive to cheat. At the end of the authentication visit,
we asked participants to complete a short survey to asses their sentiment about
usability of each password creation approach.
262
S. S. Woo and J. Mirkovic
6.3 Limitations and Ecological Validity
Our study had the following limitations, many of which are common for online
password studies. First, it is possible but very unlikely that a participant may
enroll into our study more than once. While the same Mechanical Turk user
could not enter the study twice (as identiﬁed by her Mechanical Turk ID), it
is possible for someone to create multiple Mechanical Turk accounts. There is
currently no way to identify such participants.
Second, we cannot be sure that our participants did not write down or pho-
tograph their passwords. We did not ask the participants if they have done this
in post-survey, because we believed that those participants who cheated would
also be likely to not admit it. We designed our study to discourage cheating. We
promised to pay participants in full regardless of authentication success. Our
study mechanisms further detected copy/paste actions and we have excluded
any participant that used these (for whatever reason) from the study. We also
reminded the participants multiple times to rely on their memory only. If any
cheating occurred it was likely to aﬀect all the results uniformly. Thus our data
can still be used to study improvement of recall and security between password
creation approaches.
Third, while we asked Mechanical Turkers to pretend that they were creating
passwords for a real server, they may not have been very motivated or focused.
This makes it likely that actual recall of real-world passwords would be higher
across all creation approaches. While it would have been preferable to conduct
our studies in the lab, the cost would be too high (for us) to aﬀord as large
participation as we had through the use of Mechanical Turks.
7 Results
In this section, we present the results of our user study. First, we provide the
demographic information, the password strength and recall, and time to create
passwords. Then, we analyze suggestions generated, and adopted by users.
7.1 Participant Statistics
In total, there were 1,438 participants that created passwords. Two days after
creation, we sent an email to all of them to return for authentication. Out of 1,438
participants, 990 participants returned (return rate 68.85%), as shown in Table 7.
Among 1,438 participants, 52% reported being male and 47% reported being
female. Also, 83% reported that their native language were English. With regard
to the age range, most participants were in 25–34 age group (52%), followed by
35–44 (29%) and 45–54 (12%) age groups. We found no statistically signiﬁcant
diﬀerence in any of our metrics between participants of diﬀerent age, gender or
with diﬀerent native language.
GuidedPass: Helping Users to Create Strong and Memorable Passwords
263
Table 7. Total number of participants who created and authenticated with their pass-
words
Approach
Created Auth. after 2 days
GuidedPass
218
GuidedPass-NE 207
CMU-NE
zxcvbn
zxcvbn-NE
NewNIST
3class8
Total
180
204
203
219
207
150
148
119
142
127
162
142
1,438
990 (68.85%)
7.2 Password Statistics
We show the average length, median, and standard dev. of each password created
under diﬀerent approach in Table 8. GuidedPass, GuidedPass-NE and zxcvbn
produced the longest passwords, with the average of 13.0–13.9 characters. The
GuidedPass-NE approach helped users create longer passwords, even without
enforcing the strength requirement. On the other hand, users created the longest
password under zxcvbn with strength enforcement. The CMU-NE and zxcvbn-
NE models resulted in slightly shorter passwords (11.9–12.2 characters), while
the NewNIST and 3class8 approach had the shortest passwords – 10.7 characters.
Table 8. Password length statistics and successful recall performance
Measure
Approach
Length
Successful recall rate
Avg. Median STD
GuidedPass-NE 13
13
CMU-NE
zxcvbn-NE
NewNIST
GuidedPass
zxcvbn
3class8
12.2 12
11.9 11
10.7 10
13.5 13
13.9 13
10.7 10
2.9
3.3
4.0
3.5
3.0
3.3
3.1
81.08%
71.43%
70.78%
67.28%
72.67%
55.63%
64.08%
7.3 Recall Performance
We asked users to authenticate 2 days after password creation. Recall was suc-
cessful if the user correctly inputted every character in the password, in the right
order. Table 8 shows the overall recall performance.
GuidedPass-NE and GuidedPass are Highly Memorable. GuidedPass-
NE and GuidedPass were the top two approaches, yielding the highest recall
264
S. S. Woo and J. Mirkovic
rates. As shown in Table 5, GuidedPass-NE achieved greater than 81% recall
rate, around 9% higher than CMU-NE, the most closely related competing app-
roach. This result demonstrates that more semantically meaningful and intuitive
suggestions provided by GuidedPass-NE helped users create more memorable
passwords from their initial inputs.
Approaches that oﬀered no proactive guidance or suggestions to users dur-
ing password creation (zxcvbn-NE, zxcvbn, NewNIST, and 3class8) had much
lower recall (up to 25%) than approaches that oﬀered guidance (GuidedPass-
NE, GuidedPass and CMU-NE). We believe that when guidance is lacking
users focus too much on meeting the strength requirement, and they unwit-
tingly sacriﬁce memorability. The speciﬁcity of our suggestions enabled users to
create strong passwords without sacriﬁcing memorability. Comparing the same
approaches with and without strength enforcement (GuidedPass vs. GuidedPass-
NE, zxcvbn vs. zxcvbn-NE), strength enforcement lowered recall by 8–15%.
Therefore, approaches that only provide guidance and do not enforce strength
requirement are better for recall. Instead of strict policy and strength enforce-
ment, our work shows that better suggestions are a more eﬀective way to guide
users toward strong and memorable passwords.
7.4 Password Strength
We evaluate strength of each password collected in our study using the guess
number measure. We use the Monte-Carlo method by Dell’Amico and Filip-
pone [8] to obtain the guess number. We trained several password models using
the Monte-Carlo method: the 2-gram, 3-gram, and the back-oﬀ model. For train-
ing the models, we used a total of 21 millions of leaked passwords from Rock
You, LinkedIn, MySpace, and eHarmony. We summarize the median guess num-
ber strength in Table 9, where the minimum guess number that attackers would
achieve is highlighted for each approach. We also present the guess number
strength distribution using the 3-gram model and back-oﬀ model in Figs. 2 and
3, respectively. In Figs. 2 and 3, the X-axis is the logarithm of the number of
guesses, and the Y-axis is the percentage of passwords being guessed. We only
report the guess number up to 1025 due to the space limit.
GuidedPass and GuidedPass-NE are Strong. GuidedPass and zxcvbn pro-
duce the strongest passwords in most measures, due to the maximum strength
enforcement. Further, GuidedPass-NE outperforms CMU-NE requiring around
10 times more guesses. It is interesting to note that without strength enforce-
ment GuidedPass-NE strength did not degrade much (around 10 times), while
zxcvbn-NE strength degraded a lot (around 10,000 times). Thus, user guidance
helped create strong passwords even without enforcement. Finally, NewNIST
and 3class8OP performed very poorly, requiring in general around 100 times
fewer guesses than other approaches, and could not resist oﬄine attacks. In fact,
NewNIST did not help users create stronger passwords, and resulted in lower
strength than even 3class8. We believe that removing diﬀerent class requirements
lowered the strength of passwords created under the NewNIST policy.
GuidedPass: Helping Users to Create Strong and Memorable Passwords
265
Table 9. Median guess number, measured using 2-gram, 3-gram and back-oﬀ model
Approach
2-gram 3-gram
Back-oﬀ
GuidedPass-NE 7.4E+18
5.04E+17 1.45E+18
CMU-NE
1.38E+18 5.55E+16 2.29E+17
zxcvbn-NE
3.44E+16 3.95E+15
1.74E+15
NewNIST
4.87E+14 8.26E+13
6.53E+13
GuidedPass
3.43E+19 5.62E+18 5.18E+19
zxcvbn
3class8
7.45E+20 2.55E+19 9.09E+19
8.02E+14 9.27E+13 1.43E+14
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0
y
t
i
l
i
r
b
a
b
o
P
g
n
s
s
e
u
G
i
GPass
NewNIST
z
GPass-NE
z-NE
cmu-NE
3class8
y
t
i
l
i
r
b
a
b
o
P
g
n
s
s
e
u
G
i
5
10
15
20
25
30
log(number of guess)
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0
GPass
NewNIST
z
GPass-NE
z-NE
cmu-NE
3class8
5
10
15
20
25
30
log(number of guess)
Fig. 2. Guess number and guessing
probability measured using 3-gram
model
Fig. 3. Guess number and guessing
probability measured using back-oﬀ
model
7.5 Password Creation Time
We measured the average time needed to create a password (time between the