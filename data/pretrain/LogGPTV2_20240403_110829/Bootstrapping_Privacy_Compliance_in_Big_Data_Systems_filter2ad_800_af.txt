negatives in our system.
Assurance: Our system provides weak guarantees in the face
340
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:58:21 UTC from IEEE Xplore.  Restrictions apply. 
of adversarial developer behavior such as incorrect annotations
and intentional ﬂouting of naming conventions to mislead our
bootstrap analysis. However, we expect independent redundant
annotations in conjunction with the data ﬂow analysis to sig-
niﬁcantly enhance correctness and conﬁdence of these labels
over time.
VIII. RELATED WORK
Recall that we focus on privacy policies that impose re-
strictions on how various types of personal information ﬂow
amongst programs. There are two main lines of work that are
closely related to ours—information ﬂow analysis of programs
and privacy policy enforcement over executions. Furthermore,
we also describe related work on usable policy languages.
a) Information ﬂow analysis of programs: There has
been signiﬁcant research activity in restricting information
ﬂows in programs over the last three decades [25] and on
language-based methods that support these restrictions, in-
cluding languages like Jif [26], which augments Java with
information ﬂow types, and Flow Caml, which augments
ML [27] (see [17] for a survey of these and other language-
based methods). These languages can enforce information
ﬂow properties like non-interference with mostly static type
checking. Taking Jif as one example language, we note that
prior work has shown that Jif principals can be used to model
role-based [26] and purpose-based [28] restrictions on infor-
mation ﬂow. Additionally, recognizing that non-interference
is too strong a requirement,
the theory of relaxed non-
interference through declassiﬁcation [29], [30], [31], allows
expressing policies that, for instance, do not allow disclosure
of individual ages, but allow the disclosure of average age.
This line of work also includes techniques for automated
inference of declassiﬁcation policies [32], [33] with minimal
programmer annotations. While these ideas have parallels in
our work, there are also some signiﬁcant differences. First, our
policy language LEGALEASE enables explicit speciﬁcation of
policies separately from the code whereas in language-based
approaches like Jif the policies are either expressed implicitly
via typed interface speciﬁcations or explicitly via conditionals
on program variables. The separation of high-level policy spec-
iﬁcation from code is crucial in our setting since we want the
ﬁrst task to be accessible to privacy champions and lawyers.
Second, since our goal is to bootstrap compliance checking on
existing code, we do not assume that the code is annotated with
information ﬂow labels. A central challenge (addressed by
GROK) is to bootstrap these labels without signiﬁcant human
effort. Once the labels are in place, information ﬂow analysis
for our restricted programming model is much simpler than it
is for more complex languages like Jif. Note that we (as well
as Hayati and Abadi [28]) assume that programs are correctly
annotated with their purposes. A semantic deﬁnition of what it
means for an agent (a program or human) to use information
for a purpose is an orthogonal challenge, addressed in part in
other work [34].
b) Privacy policy enforcement over executions: A second
line of work checks executions of systems (i.e., traces of
actions produced by programs or humans) for compliance
with privacy policies that restrict how personal information
may ﬂow or be used. This line of work includes auditing,
run-time monitoring, and logic programming methods for
expressive fragments of ﬁrst-order logic and ﬁrst-order tem-
poral logics [12], [35], [36], [37] applied to practical policies
from healthcare, ﬁnance and other sectors. These results are
different from ours in two ways. First,
their language of
restrictions on information ﬂow is more expressive than ours—
they can encode role-based and purpose-based restrictions
much like we do, but can express a much larger class of
temporal restrictions than we can in LEGALEASE with our
limited typestates on data. Second, since their enforcement
engines only have access to executions and not the code of
programs, they can only check for direct ﬂows of information
and not non-interference-like properties. Such code analysis is
also a point of difference from enforcement using reference
monitors of access control and privacy policy languages—
an area in which there is a large body of work, including
languages such as XACML [38] and EPAL [39].
c) Usable policy languages: To author policy statements,
several interfaces and tools have been tested for their usability.
Rarely have the raw languages been evaluated on their own
for ease of use without some kind of UI-based authoring tool.
Thus, a direct comparison with our work is difﬁcult. Never-
theless, we mention three efforts along these lines since our
goals are similar to theirs. The Expandable Grids interface was
used to test the ability for people to author P3P policies (P3P
(Platform for Privacy Preferences) is the W3C standard for
creating XML-based machine-readable privacy policies). An
empirical study found that Expadable Grids did not improve
the usability beyond users’ abilities to express policies using
natural language statements [40]. Another example is SPAR-
CLE [41], a web-based policy authoring tool that generates
XML based on the users’ selection of user categories, actions,
data categories, purposes, and conditions based on natural
language policy clauses, with promising usability results. We
view the need for authoring tools such as SPARCLE as being
complementary to a language that can be used by policy
authors, as such automated translation tools usually entail
inaccuracies, and therefore, need to be validated. In a language
such as LEGALEASE, one can hope that the translation is
veriﬁed by the authors themselves.
IX. CONCLUSION
In this paper, we demonstrate a collection of techniques
to transition to automated privacy compliance compliance
checking in big data systems. To this end we designed the
LEGALEASE language, instantiated for stating privacy policies
as a form of restrictions on information ﬂows, and the GROK
data inventory that maps low level data types in code to high-
level policy concepts. We show that LEGALEASE is usable
by non-technical privacy champions through a user study.
We show that LEGALEASE is expressive enough to capture
real-world privacy policies with purpose, role, and storage
restrictions with some limited temporal properties, in particular
341
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:58:21 UTC from IEEE Xplore.  Restrictions apply. 
that of Bing and Google. To build the GROK data ﬂow graph
we leveraged past work in program analysis and data ﬂow
analysis. We demonstrate how to bootstrap labeling the graph
with LEGALEASE policy datatypes at massive scale. We note
that
the structure of the graph allows a small number of
annotations to cover a large fraction of the graph. We report
on our experiences and learnings from operating the system
for over a year in Bing.
ACKNOWLEDGEMENTS
We thank the policy authors and privacy champions at
Microsoft who participated in our user study. We thank Leena
Sheth, Carrie Culley, Boris Asipov and Robert Chen for their
contributions to the operational system. We thank Michael
Tschantz and the anonymous reviewers for useful feedback.
This work was partially supported by the AFOSR MURI on
“Science of Cybersecurity” and the National Science Founda-
tion (NSF) grant CNS1064688 on “Semantics and Enforce-
ment of Privacy Policies: Information Use and Purpose”.
REFERENCES
[1] D. J. Solove and W. Hartzog, “The FTC and the New Common Law of
Privacy,” Columbia Law Review (forthcoming 2014)., vol. 114.
[2] (2012, Aug.) Ftc approves ﬁnal settlement with facebook. Federal Trade
http://www.ftc.gov/news-events/
Commission.
press-releases/2012/08/ftc-approves-ﬁnal-settlement-facebook
[Online]. Available:
[3] (2011, Mar.) Ftc charges deceptive privacy practices in google’s rollout
[Online].
its buzz social network. Federal Trade Commission.
of
Available: http://www.ftc.gov/opa/2011/03/google.shtm
Protection
ltd,
ire-
[4] Data
land
Avail-
able: http://www.dataprotection.ie/documents/press/Facebook_Ireland_
Audit_Review_Report_21_Sept_2012.pdf
“Facebook
[Online].
Ireland,
2012.
Commissioner,
report
of
re-audit,”
[5] Information Commissioner’s Ofﬁce, United Kingdom, “Google inc.:
[Online]. Available: http:
Data protection audit
//ico.org.uk/~/media/documents/disclosure_log/IRQ0405239b.ashx
report,” 2011.
[6] (2012, Apr.) Investigations of Google Street View. Electronic Privacy
Information Center (EPIC). [Online]. Available: http://epic.org/privacy/
streetview/
[7] A. Thusoo, J. S. Sarma, N. Jain, Z. Shao, P. Chakka, N. Zhang,
S. Antony, H. Liu, and R. Murthy, “Hive - a petabyte scale data
warehouse using Hadoop,” in ICDE ’10: Proceedings of
the 26th
International Conference on Data Engineering.
IEEE, Mar. 2010, pp.
996–1005.
[8] S. Melnik, A. Gubarev, J. J. Long, G. Romer, S. Shivakumar, M. Tolton,
and T. Vassilakis, “Dremel: Interactive analysis of web-scale datasets,”
PVLDB, vol. 3, no. 1, pp. 330–339, 2010.
[9] R. Chaiken, B. Jenkins, P.-A. Larson, B. Ramsey, D. Shakib, S. Weaver,
and J. Zhou, “Scope: easy and efﬁcient parallel processing of massive
data sets,” Proc. VLDB Endow., vol. 1, no. 2, pp. 1265–1276, Aug. 2008.
[10] Bing. [Online]. Available: http://www.bing.org/
[11] H. DeYoung, D. Garg, L. Jia, D. Kaynar, and A. Datta, “Experiences
in the logical speciﬁcation of the hipaa and glba privacy laws,” in
Proceedings of
the 9th Annual ACM Workshop on Privacy in the
Electronic Society. New York, NY, USA: ACM, 2010, pp. 73–82.
[12] A. Barth, A. Datta, J. Mitchell, and H. Nissenbaum, “Privacy and con-
textual integrity: framework and applications,” in Security and Privacy,
2006 IEEE Symposium on, 2006, pp. 15 pp.–198.
[13] J. A. Goguen and J. Meseguer, “Security policies and security models,”
in IEEE Symposium on Security and Privacy, 1982, pp. 11–20.
[14] Facebook. (2012, Dec.) Data use policy. [Online]. Available: https:
//www.facebook.com/full_data_use_policy
Jun.) Privacy policy.
(2013,
[15] Google.
[Online]. Available: http:
//www.google.com/policies/privacy/
[16] (2013, Oct.) Bing privacy statement. Microsoft. [Online]. Available:
http://www.microsoft.com/privacystatement/en-gb/bing/default.aspx
[17] A. Sabelfeld and A. Myers, “Language-based information-ﬂow security,”
Selected Areas in Communications, IEEE Journal on, vol. 21, no. 1, pp.
5–19, 2003.
[18] M. C. Tschantz and S. Krishnamurthi, “Towards reasonability properties
for access-control policy languages.” in SACMAT. ACM, 2006, pp.
160–169.
[19] R. Wille, “Restructuring lattice theory: An approach based on hierarchies
of concepts,” in Ordered Sets, ser. NATO Advanced Study Institutes
Series. Springer Netherlands, 1982, vol. 83, pp. 445–470.
[20] S. Sen, S. Guha, A. Datta, S. K. Rajamani, J. Tsai, and J. M. Wing,
“Bootstrapping privacy compliance in a big data system,” Microsoft
Research, Tech. Rep. MSR-TR-2014-36.
[21] C. Dwork, “Differential privacy,” in in ICALP.
Springer, 2006, pp.
1–12.
[22] C. Farkas and S. Jajodia, “The inference problem: A survey,” SIGKDD
Explor. Newsl., vol. 4, no. 2, pp. 6–11, Dec. 2002.
[23] R. Madhavan, G. Ramalingam, and K. Vaswani, “Purity analysis: An
abstract interpretation formulation,” in Static Analysis, ser. Lecture Notes
in Computer Science, E. Yahav, Ed. Springer Berlin Heidelberg, 2011,
vol. 6887, pp. 7–24.
[24] C. Gkantsidis, D. Vytiniotis, O. Hodson, D. Narayanan, F. Dinu, and
A. Rowstron, “Rhea: Automatic ﬁltering for unstructured cloud storage,”
in Proceedings of the 10th USENIX Conference on Networked Systems
Design and Implementation, ser. NSDI’13.
Berkeley, CA, USA:
USENIX Association, 2013, pp. 343–356.
[25] D. E. Denning and P. J. Denning, “Certiﬁcation of programs for secure
information ﬂow,” Commun. ACM, vol. 20, no. 7, pp. 504–513, 1977.
[26] A. C. Myers and B. Liskov, “Protecting privacy using the decentralized
label model,” ACM Trans. Softw. Eng. Methodol., vol. 9, no. 4, pp. 410–
442, 2000.
[27] F. Pottier and V. Simonet, “Information ﬂow inference for ml,” in POPL,
2002, pp. 319–330.
[28] K. Hayati and M. Abadi, “Language-based enforcement of privacy poli-
cies,” in In Proceedings of Privacy Enhancing Technologies Workshop
(PET). Springer-Verlag, 2004.
[29] S. Chong and A. C. Myers, “Security policies for downgrading,” in Pro-
ceedings of the 11th ACM conference on Computer and communications
security, ser. CCS ’04. New York, NY, USA: ACM, 2004, pp. 198–209.
[30] P. Li and S. Zdancewic, “Downgrading policies and relaxed noninter-
ference.” in POPL. ACM, 2005, pp. 158–170.
[31] A. Sabelfeld and D. Sands, “Declassiﬁcation: Dimensions and princi-
ples,” Journal of Computer Security, vol. 17, no. 5, pp. 517–548, 2009.
[32] M. C. Tschantz and J. M. Wing, “Extracting conditional conﬁdentiality
policies,” in Proceedings of the 2008 Sixth IEEE International Confer-
ence on Software Engineering and Formal Methods. Washington, DC,
USA: IEEE Computer Society, 2008, pp. 107–116.
[33] J. A. Vaughan and S. Chong, “Inference of expressive declassiﬁcation
policies,” in Proceedings of the 2011 IEEE Symposium on Security and
Privacy. Washington, DC, USA: IEEE Computer Society, 2011, pp.
180–195.
[34] M. C. Tschantz, A. Datta, and J. M. Wing, “Purpose restrictions on
information use,” in Computer Security - ESORICS 2013, ser. Lecture
Notes in Computer Science.
Springer Berlin Heidelberg, 2013, vol.
8134, pp. 610–627.
[35] D. A. Basin, F. Klaedtke, S. Müller, and B. Pﬁtzmann, “Runtime
monitoring of metric ﬁrst-order temporal properties,” in FSTTCS, 2008,
pp. 49–60.
[36] D. Garg, L. Jia, and A. Datta, “Policy auditing over incomplete logs:
theory, implementation and applications,” in Proceedings of the 18th
ACM conference on Computer and communications security, ser. CCS
’11. New York, NY, USA: ACM, 2011, pp. 151–162.
[37] D. A. Basin, F. Klaedtke, S. Marinovic, and E. Zalinescu, “Monitoring
compliance policies over incomplete and disagreeing logs,” in RV, 2012,
pp. 151–167.
[38] T. Moses et al., “Extensible access control markup language (xacml)
version 2.0,” Oasis Standard, vol. 200502, 2005.
[39] P. Ashley, S. Hada, G. Karjoth, C. Powers, and M. Schunter, “Enterprise
privacy authorization language (epal 1.2),” Submission to W3C, 2003.
[40] R. W. Reeder, L. Bauer, L. F. Cranor, M. K. Reiter, K. Bacon, K. How,
and H. Strong, “Expandable grids for visualizing and authoring computer
security policies,” in CHI, 2008, pp. 1473–1482.
[41] C. Brodie, C.-M. Karat, and J. Karat, “An empirical study of natural
language parsing of privacy policy rules using the sparcle policy
workbench,” in SOUPS, 2006, pp. 8–19.
342
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:58:21 UTC from IEEE Xplore.  Restrictions apply.