### Data and Churn Analysis

Given that (i) there are 162 gaps in the archived data, (ii) we created time series for joining and leaving relays, and (iii) we determined churn values for all twelve relay flags, we ended up with \((72,061 - 162) \times 2 \times 12 = 1,725,576\) churn values. Figure 9 presents a box plot of the churn distribution (joining and leaving churn values concatenated) for the seven most relevant relay flags. To better visualize the width of the distributions, we removed values greater than the plot whiskers, which extend to 1.5 times the interquartile range from the box.

Unsurprisingly, relays with the Guard, HSDir, and Stable flags experience the least churn, likely because these flags are awarded only to particularly stable relays. In contrast, Exit relays have the highest churn, which is surprising given their sensitivity and the operational challenges they face.

Interestingly, the median churn rate of the network has steadily decreased over the years, from 0.04 in 2008 to 0.02 in 2015.

### Anomaly Detection

Figure 10 illustrates churn rates for five days in August 2008, featuring the most significant anomaly in our data. On August 19, 822 relays left the network, resulting in a sudden spike and a baseline shift. This spike was caused by the Tor network's switch from consensus format version three to four. The changelog indicates that in version four, routers without the Running flag are no longer listed in the consensus.

To facilitate the choice of a detection threshold, we plotted the number of alerts (in log scale) in 2015 as the threshold increases, using three simple moving average window sizes. The results, shown in Figure 11, suggest that thresholds greater than 0.012 are practical, as 181 alerts per year average to approximately one alert every two days—a manageable number of incidents to investigate. Unfortunately, we cannot determine the false positive rate due to the lack of ground truth.

### Uptime Analysis

We generated relay uptime visualizations for each month since 2007, resulting in 100 images. Below, we discuss a subset of these images, highlighting particularly interesting patterns.

- **Figure 12 (June 2010)**: A clear "Sybil block" is visible in the center, belonging to a researcher who started several hundred Tor relays on PlanetLab for scalability research. These relays were easy to identify due to their nicknames, which included strings like "planetlab," "planet," and "plab." The small height of the Sybil block indicates that the relays were online for a short time.

- **Figure 13 (August 2012)**: A curious "step pattern" is observed for approximately 100 relays, all located in Russia and Germany. These relays appeared in December 2011 and exhibited a diurnal step pattern (nine hours uptime followed by fifteen hours downtime) starting in March 2012. All relays had similar nicknames consisting of eight seemingly randomly-generated characters and disappeared in April 2013.

- **Figure 14 (December 2014)**: The largest Sybil group to date, comprising 4,615 Tor relays, was set up in the Google cloud. Due to its magnitude, the attack was spotted almost instantly, and The Tor Project removed the offending relays within ten hours.

### Fingerprint Anomalies

We analyzed how often all Tor relays changed their fingerprints from 2007 to 2015. Figure 15 shows the number of fingerprints (y-axis) observed for the 1,000 Tor relays (x-axis) that changed their fingerprints the most. All these relays changed their fingerprints at least ten times. Twenty-one relays changed their fingerprints more than 100 times, with one relay changing its fingerprint 936 times. This relay, nicknamed "openwrt," suggests it was a home router that was regularly rebooted, likely losing its long-term keys in the process. The relay operated from August 2010 to December 2010.

Figure 15 also includes a peculiar plateau between index 707 and 803, caused by a group of Sybils hosted in Amazon EC2 that changed their fingerprints exactly 24 times. Upon inspection, this was likely an experiment for a Security and Privacy 2013 paper on deanonymizing Tor onion services. Additionally, many IP addresses in the net block 199.254.238.0/24 frequently changed their fingerprints. We contacted the owner of the address block and were informed that it used to host VPN services. Since the VPN service did not assign permanent IP addresses, the Tor relays periodically changed their addresses, causing the observed churn.

### Nearest-Neighbor Ranking Accuracy

To evaluate the accuracy of our nearest-neighbor ranking, we defined accuracy as the fraction of neighbors correctly labeled as Sybils. For example, if eight out of ten Sybils are correctly labeled, the accuracy is 0.8. We evaluated our algorithm on two datasets: the "badexit" Sybil groups from Table 5 and relay families. We chose the badexit Sybils because they ran identical, active attacks, making us confident they are indeed Sybils. Relay families, controlled by a single operator but configured to express this relationship, are benign Sybils. As of January 2016, approximately 400 families populated the Tor network, ranging in size from two to 25 relays.

We determined the n−1 nearest neighbors for each relay, where n is the family size. The results, shown in Figure 16(b), indicate that our algorithm is significantly more accurate for the family dataset, with 66% of rankings having perfect accuracy. The badexit dataset performed worse, with no ranking achieving perfect accuracy and 59% of all rankings having an accuracy in the interval [0.3, 0.6]. Despite this, our algorithm facilitates manual analysis by quickly providing a list of the most similar relays.

### Computational Cost

Table 4 provides an overview of the runtime of our methods. Network churn calculation is very fast, taking only two consensus files and easily run for every new network consensus. Nearest-neighbor ranking takes approximately 1.6 seconds for a single consensus counting 6,942 relays. Fingerprint and uptime analysis for one month take approximately 58.0 seconds and 145.0 seconds, respectively.

### Discussion

#### Operational Experience

Our practical work with sybilhunter taught us that analyzing Sybils often requires manual verification, such as comparing emerging Sybil groups with previously disclosed ones, using exitmap to send decoy traffic over Sybils, or sorting and comparing information in relay descriptors. The amount of manual work varies depending on the Sybils under investigation. We designed sybilhunter to be interoperable with Unix command line tools, and its CSV-formatted output can be easily piped into tools like sed, awk, and grep. This makes it easier to process for plotting and manual analysis. Besides Sybil detection, sybilhunter can serve as a valuable tool to understand the Tor network and monitor its reliability.

A key issue in the arms race of eliminating harmful relays is information asymmetry. Our detection techniques and code are freely available, while our adversaries operate behind closed doors. To reduce this asymmetry, we keep secret sybilhunter’s thresholds and exitmap’s detection modules, so our adversary is left guessing what our tools seek to detect. This trade-off between an open analysis framework and secret configuration parameters seems sustainable.

#### Limitations

In Section 4.2, we argued that we are unable to expose all Sybil attacks, so our results represent a lower bound. An adversary unconstrained by time and money can add an unlimited number of Sybils to the network. Indeed, Table 2 contains six Sybil groups that sybilhunter was unable to detect. Fortunately, exitmap was able to expose these Sybils, emphasizing the importance of diverse and complementary analysis techniques. Adversaries that know of our methods can evade them at the cost of spending time and resources. To evade our churn and uptime heuristics, Sybils must be added and modified independently over time. Evasion of our fingerprint heuristic requires more physical machines, and manipulation of our neighbor ranking requires changes in configuration. This arms race is unlikely to end, barring fundamental changes in how Tor relays are operated.

Sybilhunter is unable to ascertain the purpose of a Sybil attack. While the purpose is frequently obvious, Table 2 contains several Sybil groups that we could not classify. In such cases, it is difficult for The Tor Project to decide whether to remove Sybils from the network. Keeping them risks exposing users to unknown attacks, but removing them deprives the network of bandwidth. Additional context, such as Sybils operating in "bulletproof" autonomous systems, showing signs of not running the Tor reference implementation, or spoofing information in their router descriptor, can help in making a decision. Ultimately, Sybil groups must be evaluated case by case, considering the advantages and disadvantages of blocking them.

Finally, there is significant room for improving our nearest-neighbor ranking. For simplicity, our algorithm represents relays as strings, ignoring nuances such as topological proximity of IP addresses or predictable patterns in port numbers.

### Conclusion

We presented sybilhunter, a novel system that uses diverse analysis techniques to expose Sybils in the Tor network. By analyzing nine years of The Tor Project’s archived network data, we discovered numerous Sybil groups, twenty of which are presented in this work. Our findings show that (i) Sybil relays are frequently configured very similarly and join and leave the network simultaneously; (ii) attackers vary greatly in their technical sophistication; and (iii) our methods can effectively detect and analyze Sybils, though further improvements are needed.