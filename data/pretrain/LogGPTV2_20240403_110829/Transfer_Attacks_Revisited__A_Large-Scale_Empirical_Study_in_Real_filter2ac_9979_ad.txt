(0.004)
0.020∗∗∗
(0.003)
0.007∗
(0.004)
-0.006
(0.004)
H
0.090∗∗∗
(0.005)
0.028∗∗∗
(0.005)
0.020∗∗∗
(0.005)
0.087∗∗∗
(0.005)
0.020∗∗∗
(0.003)
0.007∗∗
(0.003)
-0.006∗
(0.003)
0.020∗∗∗
(0.006)
0.021∗∗∗
(0.006)
-0.025∗∗∗
(0.006)
-0.026∗∗∗
(0.006)
0.015∗∗∗
(0.006)
-0.010∗
(0.006)
0.024∗∗∗
(0.006)
-0.028∗∗∗
(0.006)
I
0.090∗∗∗
(0.006)
0.027∗∗∗
(0.006)
0.019∗∗∗
(0.006)
0.086∗∗∗
(0.006)
0.020∗∗∗
(0.003)
0.007∗∗
(0.003)
-0.006∗
(0.003)
0.020∗∗∗
(0.006)
0.021∗∗∗
(0.006)
-0.025∗∗∗
(0.006)
-0.026∗∗∗
(0.006)
0.015∗∗∗
(0.006)
-0.010∗
(0.006)
0.024∗∗∗
(0.006)
-0.028∗∗∗
(0.006)
0.002
(0.003)
0.001
(0.003)
0.382
0.379
0.430
0.425
0.587
0.578
0.587
0.577
J
0.082∗∗∗
(0.007)
0.020∗∗∗
(0.007)
0.011∗
(0.007)
0.078∗∗∗
(0.007)
0.029∗∗∗
(0.006)
0.022∗∗
(0.007)
0.003
(0.007)
0.020∗∗∗
(0.006)
0.021∗∗∗
(0.006)
-0.025∗∗∗
(0.006)
-0.026∗∗∗
(0.006)
0.015∗∗∗
(0.006)
-0.010∗
(0.006)
0.024∗∗∗
(0.006)
-0.028∗∗∗
(0.006)
0.006
(0.007)
0.007
(0.007)
-0.016∗∗
(0.007)
-0.011
(0.007)
0.001
(0.007)
-0.001
(0.007)
-0.005
(0.008)
-0.013
(0.008)
-0.006
(0.008)
-0.004
(0.008)
0.594
0.578
(ii) In the gender classiﬁcation task, AWS <p<0.001 Baidu
<p=0.032 Aliyun on the F2M rate, and AWS <p=0.013 Aliyun
<p<0.001 Baidu on the M2F rate.
transfer attack varies. In particular,
It shows that although these platforms have similar accu-
racies on the clean dataset (see Figure 3 for details), their
robustness against
the
ranking of the robustness is not the same to the ranking of
their accuracy. This result suggests that model accuracy does
not necessarily guarantee robustness against transfer attack,
even in the real applications. In addition, no single platform
has superior robustness in different kinds of transfer attacks
(untargeted vs targeted, F2M vs M2F), although AWS is the
best in the gender classiﬁcation. In particular, when compared
with other platforms, Aliyun is good at defending the untar-
geted attacks but not the targeted attacks. On the contrary,
Baidu is good at defending the targeted attcks but not the un-
targeted attacks. This means that a model’s robustness cannot
be naively measured by its robustness against speciﬁc kind
of attacks. Therefore, since the coefﬁcients are signiﬁcantly
positive, some even exceeding 0.2, the platforms should take
transfer attack more seriously due to their ignorable marginal
cost because even inexperienced attackers can get over 20%
work done with a very small cost.
Furthermore, we observe that the matching rate is signif-
icantly positive for all the platforms. This is different to the
conclusion of Liu et al. [29] that targeted transfer attack almost
never transfer, by showing that targeted transfer attack can
succeed in the real applications.
Observation 1. In the real transfer attack, the difﬁculty of
attacking a target model is not directly related to its accuracy,
i.e., a target with higher accuracy is possible to be more
vulnerable to transfer attacks. No single platform has superior
robustness in different kinds of transfer attacks (untargeted
vs targeted, F2M vs M2F). Therefore, the threat of transfer
attacks in the real applications should be treated seriously
because it has a non-trivial success rate and a low cost.
2) Pretraining and Surrogate Dataset Factors: Arguably,
pretraining plays an important role in training a decent model
with few efforts, thus is attempting to be applied to train
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:56:58 UTC from IEEE Xplore.  Restrictions apply. 
1429
-0.008
(0.007)
0.033∗∗∗
(0.007)
0.047∗∗∗
(0.007)
0.019∗∗∗
(0.004)
-0.021∗∗∗
(0.004)
0.008∗
(0.004)
0.056∗∗∗
(0.008)
0.092∗∗∗
(0.008)
-0.001
(0.008)
0.001
(0.008)
-0.013
(0.008)
0.070∗∗∗
(0.008)
0.039∗∗∗
(0.008)
0.030∗∗∗
(0.008)
0.002
(0.007)
0.043∗∗∗
(0.007)
0.056∗∗∗
(0.007)
0.019∗∗∗
(0.004)
-0.021∗∗∗
(0.004)
0.008∗
(0.004)
0.056∗∗∗
(0.008)
0.092∗∗∗
(0.008)
-0.001
(0.008)
0.001
(0.008)
-0.013
(0.008)
0.070∗∗∗
(0.008)
0.039∗∗∗
(0.008)
0.030∗∗∗
(0.008)
-0.009∗∗
(0.004)
-0.019∗∗∗
(0.004)
A
0.028∗∗∗
(0.004)
0.069∗∗∗
(0.004)
0.082∗∗∗
(0.004)
B
0.023∗∗∗
(0.006)
0.064∗∗∗
(0.006)
0.077∗∗∗
(0.006)
0.019∗∗∗
(0.005)
-0.021∗∗∗
(0.006)
0.008
(0.006)
Group
IV
is AWS
is Baidu
is Aliyun
is pretrained
is adversarial
is augmented
is PGD
is FGSM
is BLB
is CW2
is DEEPFOOL
is STEP LLC
is RFGSM
is LLC
is depth 34
is depth 50
is pre×adv
is pre×aug
is pre×depth34
is pre×depth50
is adv×depth34
is adv×depth50
is aug×depth34
is aug×depth50
0.001
(0.009)
0.042∗∗∗
(0.009)
0.055∗∗∗
(0.009)
0.020∗∗∗
(0.006)
-0.033∗∗∗
(0.006)
0.014∗
(0.006)
0.056∗∗∗
(0.007)
0.092∗∗∗
(0.007)
-0.001
(0.007)
0.001
(0.007)
-0.013∗
(0.007)
0.070∗∗∗
(0.007)
0.039∗∗∗
(0.007)
0.030∗∗∗
(0.007)
0.000
(0.009)
-0.023∗∗∗
(0.009)
-0.002
(0.009)
0.010
(0.009)
-0.003
(0.009)
-0.009
(0.009)
0.002
(0.010)
0.035∗∗∗
(0.010)