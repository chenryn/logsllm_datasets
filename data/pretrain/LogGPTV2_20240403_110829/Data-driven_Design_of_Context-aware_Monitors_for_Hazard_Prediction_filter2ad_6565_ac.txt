high), including tissue damage and morbidities such as
retinopathy and in extreme cases, death [56].
Hazards: The set of system states under the control of
the APS that together with the other conditions might lead
to accidents include:
• H1: Too much insulin is infused, which will reduce the
BG and might lead to A1.
• H2: Too little insulin is infused, which causes the BG to
increase and could lead to A2.
We then identiﬁed some transformations of interest on
xt = (BGt) as μ(xt) = (BGt, dBGt/dt, IoBt, dIoBt/dt),
including both the state variable BGt and its rate of change
as well as estimated IoB and its rate of change, which can be
calculated based on previous insulin deliveries. Then following
steps in Section III-B1, the formalized UCAS for APS was
generated by identifying the combinations of speciﬁc ranges in
μ(xt) and insulin control commands ut ∈ {u1, u2, u3, u4} (as
shown in Table I) that can potentially be hazardous. Each row
in Table I shows STL formulas to be checked by the monitor.
For example, the ﬁrst row is the formal representation of a
UCAS, (ρ(μ(xt)) = (BG>BGT, BG’>0, IOB’BGT∧ BG’>0)∧ (IOB’BGT∧ BG’>0)∧ (IOB’=0∧ IOBBGT∧ BG’0∧ IOBBGT∧ BG’BGT∧ BG’0∧ IOB>β6)⇒ ¬ u2)
G[t0,te]((BGβ7)⇒ ¬ u2)
G[t0,te]((BGβ8)⇒ ¬ u2)
G[t0,te]((BG>BGT∧ IOBBGT∧ BG’>0)∧ (IOB’=0∧ IOB>β11)⇒ ¬ u4)
H2
H2
H2
H2
H2
H1
H1
H1
H2
H1
H2
H1
Authorized licensed use limited to: Tsinghua University. Downloaded on October 11,2021 at 09:25:48 UTC from IEEE Xplore.  Restrictions apply. 
488
TABLE II: Simulated Fault and Attack Scenarios
Type
Truncate
Hold
Max/min
Add/Sub
Approach
Change output variables to zero value [3] [33]
Stop refreshing selected input/output variables
[29] [33]
Change the value of targeted variables to their
maximum or minimum allowed values [29] [61]
Add or subtract an arbitrary or particular value
to a targeted variable [29] [30]
Simulated Scenario
Availability attack [60]
DoS attack [5] [4]
Integrity attack [3] [57]/
Memory fault
a diverse set of faults inside a closed-loop APS controller
with glucose simulator and use the generated faulty data for
adversarial training and testing of the context-aware monitors
as well as other baseline monitors.
Threat Model: We assume that both accidental faults or
attacks, similar to those reported for CPS/APS (see Table II),
can target the APS controller and, once activated/initiated, can
manifest as errors in inputs, outputs, and the internal state
variables of the APS control software and cause the hazard
types deﬁned in Section IV-B. So our source-level FI engine
directly perturbs the values of the controller’s state variables
within the acceptable range over a period to simulate the effect
of such errors. We assume errors are transient and only occur
once for a particular duration per simulation.
For malicious attacks, we assume that attackers have ob-
tained unauthorized remote access [57] to an APS control
system by exploiting weaknesses such as stolen credentials
[58], vulnerable services [59], or insider attacks to penetrate
the network [6] that the target APS controller connects to.
Even for an APS control system that does not connect to a
network, the attacker can still use a USB port or Bluetooth to
get access and deploy malware.
2) Labeling Hazards using BG Risk Index: To label data
points as normal or hazardous in our simulation traces, we
exploited the notion of the Risk Index (RI) [62], [63] that
captures both the glucose variability and its associated risks
for hypo- and hyperglycemia. First we calculated the BG risk
function for each BG reading as follows:
risk(BG) = 10 ∗ (1.509 ∗ [(ln(BG))1.084 − 5.381])2
(5)
Then the left and right branches of the BG risk function
(risk(BG)  0) were separated to
calculate low (LBGI) and high (HBGI) BG risk indices for
a window of BG readings by taking average risk index on
each side. We then marked a window (e.g., one hour) of BG
readings as hazardous if the risk indices LBGI or HBGI for
that window crossed a high-risk threshold1 and kept increas-
ing, indicating a high chance of hypo- or hyperglycemia. An
example of a labeled simulation trace is shown in Fig. 5b.
D. Hazard Mitigation and Recovery
When the monitor detects a UCA is issued by the controller,
it will try to mitigate the potential hazards by correcting the
command (regardless of its value being "out-of-the-range" or
∈ uρ) to the actuator.
not) and delivering a new command (uc
t
For example, it can decrease the insulin when it is more than
needed, or add suitable insulin when the provided command
is insufﬁcient. The correction of a UCA will continue until
(cid:2)
t, IOB
(cid:2)
t)
end
if Mitigate == 1 then
t ← ui ∈ {u1, u2, u3, u4}
if (ρ(μ(xt)), ut) violates φi then
Mitigate←1, Hazard ← Hi ∈ {H1, H2}
t ← 0
if Hazard == H1 then uc
else if Hazard == H2 then uc
μ(xt) ← (BGt, IOBt, BG
ut, uc
if ρ(μ(xt)) ∈ X∗ then Mitigate ← 0, continue
for φi in STL of SCS do
Algorithm 1: Hazard Mitigation Algorithm
1 Mitigate ← 0
2 while t  5 and HBGI > 9 as deﬁned by previous works [63] [64]
2 https://github.com/UVA-DSA/ContextSafetyMonitorAPS
Authorized licensed use limited to: Tsinghua University. Downloaded on October 11,2021 at 09:25:48 UTC from IEEE Xplore.  Restrictions apply. 
489
Fig. 5: (a) Experimental Setup for Evaluation of Different Safety Monitors, integrating Two Closed-loop Simulation Platforms (Glucosym
Simulator with OpenAps Controller and UVA-Padova T1DS2013 Simulator with Basal-Bolus Controller), and Software FI Engine. (b) An
example Simulation Trace with Injected Faults and Labeled Hazards
injected error value, (c) the activation condition (trigger), and
(d) the injection duration. For each scenario, we randomly
chose from 9 different start
times and durations to inject
the fault. The combination of these parameters resulted in a
total of 882 fault injections for every patient scenario. That
translated into a total number of 2,646,000 simulation samples
used for training and testing different monitors.
We used the data from all the patients with a 4-fold cross-
validation setup for threshold learning and evaluation of our
context-aware with reﬁned threshold (CAWT) monitor as well
as model training and testing of the ML baseline monitors.
C. Baseline Monitors
We compared the proposed CAWT monitor’s performance
in accurate and timely prediction of hazards to the following
baseline monitors, representative of existing safety monitoring
solutions for MCPS and APS as proposed by previous works.
1) Medical Guidelines Monitor: We used the data au-
thenticity monitor proposed in [16] as a baseline monitor
designed based on the generic medical guidelines without any
knowledge of the APS controller or the patient characteristics
(referred to as Guideline). The safety rules of the Guideline
monitor are shown in Table III. They state that the BG value
should maintain in a normal range [70, 180] mg/dL and should
not change too fast. If BG is lower than its tenth percentile λ10
or higher than its ninetieth percentile λ90, an APS controller
should bring it back to a safe range within α (e.g., 25) minutes.
2) Model Predictive Control Monitor: Another baseline
monitor that we considered was the widely-used Model Predic-
tive Control (MPC) monitor [68], [69]. We used the Bergman
& Sherwin model [55] for this monitor:
dBG(t)/dt = −(GEZI + IEF F ) ∗ BG(t) +EP G + RA(t) (6)
TABLE III: Rules of Medical Guideline Monitor
No.
1
2
3
4
Description
φ1 = (cid:2)(BG > 70) ∧ (BG  −5) ∧ (ΔBG  λ10))
φ4 = ((BG > λ90) ⇒ ♦[0,α](BG < λ90))
where, GEZI characterizes the effect of glucose per se to in-
crease glucose uptake into cells and lower endogenous glucose
production at zero insulin; EGP is the endogenous glucose
production rate that would be estimated at zero insulin; IEF F
is insulin effect; and RA(t) represents glucose appearance
following a meal. The MPC monitor estimates the possible
BG value (BGt+1) after executing the pump’s command (It)
on the patient’s current state (BGt). If the predicted BG value
goes beyond the patient’s normal range ([70,180] mg/dL as
deﬁned by the medical guidelines), an alarm will be generated.
3) Context-aware Monitor without Threshold Learning:
We also designed a context-aware baseline monitor with the
same STL logic as the proposed CAWT monitor (see Table I)
but without learning the thresholds through data-driven STL
optimization described in Section III-C2. We refer to this
baseline monitor as the CAWOT monitor.
4) ML-based Monitors: We used the widely-used ML ap-
proaches, Decision Trees (DT), Multi-layer Perceptron (MLP),
and Long-Short Term Memory (LSTM), to train three baseline
monitors, representative of ML-based monitors previously pro-
posed in [14]. For DT and MLP, we model the task of detecting
UCA as a context-speciﬁc conditional event, as shown below:
, x2t
xt = (x1t
, ..., xnt
yt = p(∃t(cid:3) ∈ [t, te] : xt
)
(cid:2) ∈ Xh|xt, ut)
(7)
The input is the current system state xt and the issued
control action ut and the output yt is a binary classiﬁcation
of ut to safe or unsafe. For training the model, the output was
labeled as positive for a given input if any hazard happened at
a future time t(cid:3) ∈ [t, te]. We marked a simulation as hazardous
if any sample within the simulation was unsafe. We used two
fully connected layer MLP, comprising 256 and 128 neutrons,
followed by a fully connected layer with ReLU activation and
a ﬁnal softmax layer to obtain the hazard probabilities.
We also built an LSTM model as a baseline monitor because
of its advantage in handling time-series data. For the LSTM,
we used input data with a sliding time-window of k:
Xt = (xt, xt+1, ..., xt+k), Ut = (ut, ut+1, ..., ut+k)
yt = p(∃t(cid:3) ∈ [t, te] : xt
(cid:2) ∈ Xh|Xt, Ut)
(8)
Authorized licensed use limited to: Tsinghua University. Downloaded on October 11,2021 at 09:25:48 UTC from IEEE Xplore.  Restrictions apply. 
490
We experimented with different model architectures, and the
best model we got was a two-layer stacked LSTM with an
input time step of 6 (meaning 30 minutes data), consisting
of 128 and 64 LSTM units, respectively, followed by a
fully connected layer with softmax activation. We trained the
MLP and LSTM models using the Adam [70] optimizer with