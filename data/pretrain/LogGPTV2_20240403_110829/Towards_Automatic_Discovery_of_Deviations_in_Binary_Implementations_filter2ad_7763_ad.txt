satisﬁable for three of them (Cases 1, 5, and 6). For the
remaining cases, where the solver was able to generate at
least one candidate deviation input, we show two num-
bers in the format X/Y. The X value represents the num-
ber of different candidate deviation inputs we obtained
from the solver, and the Y value represents the number
of these candidate deviation inputs that actually gener-
ated semantically different output states when sent to the
servers in the validation phase. Thus, the Y value repre-
sents the number of inputs that triggered a deviation.
In Case 2, none of the ﬁve candidate deviation inputs
returned by the solver were able to generate semantically
different output states when sent to the servers, that is, no
deviations were found. For Cases 3 and 4, all candidate
deviation inputs triggered a deviation when sent to the
servers during the validation phase. In both cases, the
Miniweb server accepted some input that was rejected by
the other server. We analyze these cases in more detail
next.
Applications to error detection and ﬁngerprint gener-
ation. Figure 4 shows one of the deviations found for
the Apache-Miniweb pair. It presents one of the candi-
date deviation inputs obtained from the solver in Case 3,
and the responses received from both Apache and Mini-
web when that candidate input was sent to them dur-
ing the validation phase. The key difference is on the
ﬁfth byte of the candidate deviation input, whose original
ASCII value represented a slash, indicating an absolute
path. In the generated candidate deviation input, the byte
has value 0xE8. We have conﬁrmed that Miniweb does
indeed accept any value on this byte. So, this deviation
reﬂects an error by Miniweb: it ignores the ﬁrst character
of the requested URI and assumes it to be a slash, which
is a deviation from the URI speciﬁcation [16].
Figure 5 shows one of the deviations found for the
Savant-Miniweb pair. It presents one of the candidate de-
viation inputs obtained from the solver in Case 4, includ-
ing the responses received from both Savant and Mini-
web when the candidate deviation input was sent to them
during the validation phase. Again, the candidate devi-
ation input has a different value on the ﬁfth byte, but in
this case the response from Savant is only a raw “File not
found” string. Note that this string does not include the
HTTP Status-Line, the ﬁrst line in the response that in-
cludes the response code, as required by the HTTP spec-
222
16th USENIX Security Symposium
USENIX Association
Candidate deviation input:
0000:
0010:
0020:
47 45 54 20 E8 69 6E 64 65 78 2E 68  74 6D 6C 20  GET .index.html
B4 12 02 12 90 04 02 04 0D 0A 48 6F  A6 4C 08 20  ..........Ho.L.
28 D0 82 91 12 E0 84 0C 35 0D 0A 0D  0A           (.......5....
Miniweb response:
HTTP/1.1 200 OK
Server: Miniweb
Cache−control: no−cache
[...]
Apache response:
HTTP/1.1 400 Bad Request           
Date: Sat, 03 Feb 2007 05:33:55 GMT
Server: Apache/2.2.4 (Win32)       
[...]
Figure 4: Example deviation found for Case 3, where Miniweb’s formula is satisﬁed while Apache’s isn’t. The ﬁgure
includes the candidate deviation input being sent and the responses obtained from the servers, which show two different
output states.
Candidate deviation input:
0000:
0010:
0020:
47 45 54 20 08 69 6E 64 65 78 2E 68  74 6D 6C 20  GET .index.html
09 09 09 09 09 09 09 09 0D 0A 48 6F  FF FF FF 20  ..........Ho...
09 09 09 09 09 09 09 09 09 0D 0A 0D  0A           .............
Miniweb response:
HTTP/1.1 200 OK
Server: Miniweb
Cache−control: no−cache
[...]
Savant response:
File not found  
Figure 5: Example deviation found for Case 4, where Miniweb’s formula is satisﬁed while Savant’s isn’t. The output
states show that Miniweb accepts the input but Savant rejects it with a malformed response.
iﬁcation and can be considered malformed [27]. Thus,
this deviation identiﬁes an error though in this case both
servers (i.e. Miniweb and Savant) are deviating from the
HTTP speciﬁcation.
Figure 6 shows another deviation found in Case 4 for
the Savant-Miniweb pair. The HTTP speciﬁcation man-
dates that the ﬁrst line of an HTTP request must include a
protocol version string. There are 3 possible valid values
for this version string: “HTTP/1.1”, “HTTP/1.0”, and
“HTTP/0.9”, corresponding to different versions of the
HTTP protocol. However, we see that the candidate de-
viation input produced by the solver uses instead a dif-
ferent version string, ”HTTP/\b.1”. Since Miniweb ac-
cepts this answer, it indicates that Miniweb is not prop-
erly verifying the values received on this ﬁeld. On the
other hand, Savant is sending an error to the client indi-
cating an invalid HTTP version, which indicates that it
is properly checking the value it received in the version
ﬁeld. This deviation shows another error in Miniweb’s
implementation.
To summarize, in this section we have shown that our
approach is able to discover multiple inputs that trigger
deviations between real protocol implementations. We
have presented detailed analysis of three of them, and
conﬁrmed the deviations they trigger as errors. Out of
the three inputs analyzed in detail, two of them can be
attributed to be Miniweb’s implementation errors, while
the other one was an implementation error by both Mini-
web and Savant. The discovered inputs that trigger devi-
ations can potentially be used as ﬁngerprints to differen-
tiate among these implementations.
5.2 Deviations in Time Servers
In this section we show our results for the NTP protocol
using two different servers: NetTime [7] and Ntpd [13].
Again, for simplicity, we focus on a single request that
we show in Figure 7. This request represents a simple
query for time synchronization from a client. The request
uses the Simple Network Time Protocol (SNTP) Version
4 protocol, which is a subset of NTP [38].
Deviations detected. First, we generate the symbolic
formulas for both servers: fT and fN for NetTime and
Ntpd respectively using the original request shown in
Figure 7. Since we have one server pair, we need to
query the solver twice. In Case 7, we query the solver for
(fN ∧ ¬fT ) and in Case 8 we query it for (fT ∧ ¬fN ).
USENIX Association
16th USENIX Security Symposium
223
Candidate deviation input:
0000:
0010:
0020:
47 45 54 20 2F 69 6E 64 65 78 2E 68  74 6D 6C 20  GET /index.html
48 54 54 50 2F 08 2E 31 0D 0A 48 6F  FF FF FF 20  HTTP/..1..Ho...
09 09 09 09 09 09 09 09 09 0D 0A 0D  0A           .............
Miniweb response:
HTTP/1.1 200 OK
Server: Miniweb
Cache−control: no−cache
[...]
Savant response:
HTTP/1.1 400 Only 0.9 and 1.X requests supported
Server: Savant/3.1                              
Content−Type: text/html                         
[...]
Figure 6: Another example deviation for Case 4, between Miniweb and Savant. The main different is on byte 21,
which is part of the Version string. In this case Miniweb accepts the request but Savant rejects it.
Original request:
0000:
0020:
0040:
e3 00 04 fa 00 01 00 00 00 01 00 00 00 00 00 00
00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
00 00 00 00 00 00 00 00 c9 6e 6b 7a ca e2 a8 00
1 1 1 0 0 0 1 1
LI
VN
MD
Candidate deviation input:
0000:
0020:
0040:
03 00 00 00 00 01 00 00 00 01 00 00 00 00 00 00
00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
00 00 00 00 00 00 00 00 c9 6e 6b 7a ca e2 a8 00
0 0 0 0 0 0 1 1
LI
VN
MD
NetTime response:
0000:
0020:
0040:
04 0f 00 fa 00 00 00 00 00 00 00 00 00 00 00 00 
c9 6e 72 6c a0 c4 9a ec c9 6e 6b 7a ca e2 a8 00 
c9 6e 72 95 25 60 41 5e c9 6e 72 95 25 60 41 5e
Ntpd response:
No response
Figure 7: Example deviation obtained for the NTP servers. It includes the original request sent in the formula extraction
phase, the candidate deviation input output by the solver, and the responses received from the servers, when replaying
the candidate deviation input. Note that the output states are different since NetTime does send a response, while Ntpd
does not.
The solver returns unsatisﬁable for Case 7. For Case 8,
the solver returns several candidate deviation inputs. Fig-
ure 7 presents one of the deviations found for Case 8.
It presents the candidate deviation input returned by the
solver, and the response obtained from both NTP servers
when that candidate deviation input was sent to them dur-
ing the validation phase.
Applications to error detection and ﬁngerprint gener-
ation. The results in Figure 7 show that the candidate
deviation input returned by the solver in Case 8 has dif-
ferent values at bytes 0, 2 and 3. First, bytes 2 and 3 have
been zeroed out in the candidate deviation input. This
is not relevant since these bytes represent the “Poll” and
“Precision” ﬁelds and are only signiﬁcant in messages
sent by servers, not in the queries sent by the clients, and
thus can be ignored.
The important difference is on byte 0, which is pre-
sented in detail on the right hand side of Figure 7. Byte
0 contains three ﬁelds: “Leap Indicator” (LI), “Version”
(VN) and “Mode” (MD) ﬁelds. The difference with the
original request is in the Version ﬁeld. The candidate de-
viation input has a decimal value of 0 for this ﬁeld (note
that the ﬁeld length is 3 bits), instead of the original dec-
imal value of 4. When this candidate deviation input was
sent to both servers, Ntpd ignored it, choosing not to re-
spond, while NetTime responded with a version number
with value 0. Thus, this candidate deviation input leads
the two servers into semantically different output states.
We check the speciﬁcation for this case to ﬁnd out
that a zero value for the Version ﬁeld is reserved, and
according to the latest speciﬁcation should no longer be
supported by current and future NTP/SNTP servers [38].
However, the previous speciﬁcation states that the server
should copy the version number received from the client
in the request, into the response, without dictating any
special handling for the zero value. Since both imple-
mentations seem to be following different versions of the
224
16th USENIX Security Symposium
USENIX Association
Program Trace-to-IR time % of Symbolic Instructions
Apache
Miniweb
Savant
Ntpd
7.6s
5.6s
6.3s
0.073s
0.75s
NetTime
3.9%
1.0%
2.2%
0.1%
0.1%
IR-to-formula time
Formula Size
31.87s
14.9s
15.2s
5.3s
4.3s
49786
25628
24789
1695
5059
Table 5: Execution time and formula size obtained during the formula extraction phase.
Input Calculation Time
Apache - Miniweb
Apache - Savant
Savant - Miniweb
NetTime - Ntpd
21.3s
11.8s
9.0s
0.56s
covering deviations. In many cases, we can discover de-
viation inputs between two implementations in approxi-
mately one minute. Fuzz testing approaches are likely to
take much longer, since they usually need to test many
more examples.
Table 6: Execution time needed to calculate a candidate
deviation input for each server pair.
6 Discussion and Future Work
speciﬁcation, we cannot deﬁnitely assign this error to one
of the speciﬁcations. Instead, this example shows that
we can identify inconsistencies or ambiguity in protocol
speciﬁcations. In addition, we can use this query as a
ﬁngerprint to differentiate between the two implementa-
tions.
5.3 Performance
In this section, we measure the execution time and the
output size at different steps in our approach. The re-
sults from the formula extraction phase and the deviation
detection phase are shown in Table 5 and Table 6, respec-
tively. In Table 5, the column “Trace-to-IR time” shows
the time spent in converting an execution trace into our
IR program. The values show that the time spent to con-
vert the execution trace is signiﬁcantly larger for the web
servers, when compared to the time spent on the NTP
servers. This is likely due to a larger complexity of the
HTTP protocol, speciﬁcally a larger number of condi-
tions affecting the input. This is shown in the second
column as the percentage of all instructions that operate
on symbolic data, i.e., on data derived from the input.
The “IR-to-formula time” column shows the time spent
in generating a symbolic formula from the IR program.
Finally, the “Formula Size” column shows the size of
the generated symbolic formulas, measured by the num-
ber of nodes that they contain. The formula size shows
again the larger complexity in the HTTP implementa-
tions, when compared to the NTP implementations.
In Table 6, we show the time used by the solver in the
deviation detection phase to produce a candidate devi-
ation input from the combined symbolic formula. The
results show that our approach is very efﬁcient in dis-
Our current implementation is only a ﬁrst step. In this
section we discuss some natural extensions that we plan
to pursue in the future.
Addressing other protocol interactions. Currently,
we have evaluated our approach over protocols that use
request/response interactions (e.g. HTTP, NTP), where
we examine the request being received by a server pro-
gram. Note that our approach could be used in other
scenarios as well. For example, with clients programs,
we could analyze the response being received by the
client. In protocol interactions involving multiple steps,
we could consider the protocol output state to be the state
of the program after the last step is ﬁnished.
Covering rarely used paths. Some errors are hidden
in rarely used program paths and ﬁnding them can take
multiple iterations in our approach. For each iteration,
we need a protocol input that drives both implementa-
tions to semantically equivalent output states. These pro-
tocol inputs are usually obtained from a network trace.
Thus, the more different inputs contained in the trace
the more paths we can potentially cover.
In addition,
we can query the solver for multiple candidate deviation