it may require to analyze the canvas pixels for more
advanced countermeasures,
like FPRANDOM. Thus,
in Figure 4, we report on 4 boxplots representing the
processing time for the following situations:
1. FINGERPRINTJS2 inconsistency tests,
2. The scanner stops upon detecting one inconsistency
(FP-SCANNER (default) mode),
3. All inconsistency tests are executed (FP-SCANNER
(depth) mode),
4. Only the test that manipulates the canvas (pixels
is executed (FP-SCANNER (canvas only) mode).
One can observe that, when all the tests are executed
(3)—which corresponds to genuine ﬁngerprints—90%
of the ﬁngerprints are processed in less than 513ms.
However, we observe a huge speedup when stopping the
processing upon the ﬁrst occurrence of an inconsistency
(2). Indeed, while 83% of the ﬁngerprints are processed
in less than 0.21ms, the remaining 17% need more than
146    27th USENIX Security Symposium
USENIX Association
users of the TOR browser and network. We can imag-
ine users being delivered altered content or being denied
access if they do not share their true browser ﬁngerprint.
Similarly to ad blocker extensions, discrimination may
also happen with a countermeasure intended to block ﬁn-
gerprinting scripts.
Trackability. Detecting countermeasures can, in some
cases, be used to improve tracking. Nikiforakis et al. [16]
talk about the counterproductiveness of using user agent
spoofers because they make browsers more identiﬁable.
We extend this line of thought to more generally argue
that being detected with a ﬁngerprinting countermeasure
can make browsers more trackable, albeit this is not al-
ways the case. We assert that the ease of tracking de-
pends on different factors, such as being able to identify
the countermeasure, the number of users of the counter-
measure, the ability to recover the real ﬁngerprint values,
and the volume of information leaked by the countermea-
sure. To support this claim, we present the countermea-
sures we studied in this paper.
Anonymity Set.
In the case of countermeasures
with large user bases, like FIREFOX with ﬁngerprint-
ing protection or BRAVE, although their presence can
be detected, these countermeasures tend to increase the
anonymity set of their users by blocking different at-
tributes, and, in the case of FIREFOX, by sharing the
same user agent, platform, and timezone. Since they are
used by millions of users at the time we wrote this pa-
per, the information obtained by knowing that someone
uses them does not compensate the loss in entropy from
the removal of ﬁngerprinting attributes. On the opposite
end, for countermeasures with small user bases, such as
CANVAS DEFENDER (21k downloads on CHROME, 5k
on FIREFOX) or RAS (160k downloads on FIREFOX), it
is unlikely that the anonymity gained by the countermea-
sures compensate the information obtained by knowing
that someone uses them.
Increasing targetability. In the case of RAS, we show
that it is possible to detect its presence and recover the
original browser and OS family. Also, since the can-
vas attribute has been shown to have high entropy, and
that RAS does not randomize it nor block it by default,
the combination of few attributes of a ﬁngerprint may
be enough to identify a RAS user. Thus, under the hy-
pothesis that no, or few, RAS users have the same can-
vas, many of them could be identiﬁed by looking at
the following subset of attributes: being a RAS user,
predicted browser, predicted OS, and canvas.
Blurring Noise. In the case of CANVAS DEFENDER,
we show that even though they claim to have a safer so-
lution than other canvas countermeasure extensions, the
way they operate makes it easier for a ﬁngerprinter to
track their users. Indeed, CANVAS DEFENDER applies
Figure 4: FP-SCANNER execution times
440ms. This is caused by the fact that most of the ﬁnger-
prints we tested had installed countermeasures that could
be detected using straightforward tests, such as media
queries or testing for overridden functions, whereas the
other ﬁngerprints having either no countermeasures or
FPRANDOM (17 ﬁngerprints), require to run all the tests.
This observation is conﬁrmed by the fourth boxplot,
which report on the performance of the pixel analysis
step and imposes additional processing time to analyze
all the canvas pixels. We recall that the pixel analysis step
is required only to detect FPRANDOM since even other
canvas countermeasures can be detected by looking at
the string representation of toDataURL. Thus, when dis-
abling the pixel analysis test, FP-SCANNER outperforms
FINGERPRINTJS2 with a better accuracy (> 0.92) and a
faster execution (90th percentile of 220ms).
Based on this evaluation, we can conclude that adopt-
ing an inconsistency test suite like FP-SCANNER in pro-
duction is a viable solution to detect users with counter-
measures.
5 Discussion
In this paper, we demonstrated that state-of-the-art ﬁn-
gerprinting countermeasures could be detected by scan-
ning for inconsistencies they introduce in browser ﬁn-
gerprints. We ﬁrst discuss the privacy implications of
such a detection mechanism and then explain how these
techniques could be used to detect browser extensions in
general.
5.1 Privacy Implications
Discrimination. Being detected with a countermea-
sure could lead to discrimination. For example, Han-
nak et al. [9] demonstrated that some websites adjust
prices depending on the user agent. Moreover, many
websites refuse to serve browsers with ad blockers or
USENIX Association
27th USENIX Security Symposium    147
FingerprintJS2 (1)FP-Scanner (default) (2)FP-Scanner (depth) (3)FP-Scanner (canvas only) (4)0100200300400500600700Execution time (ms)i=1(1 − 1
a uniform noise vector on all pixels of a canvas. This
vector is composed of 4 random numbers between −10
and 30 corresponding to the red, green, blue and alpha
(rgba) components of a color. With a small user base, it
is unlikely that two or more users share both the same
noise and the same original canvas.
In particular, the
formula hereafter represents the probability that two or
more users of CANVAS DEFENDER among k share the
same noise vector, which is similar to the birthday para-
dox: 1 − ∏k
404−i ). Thus, if we consider that
the 21k Chrome users are still active, there is a proba-
bility of 0.0082 that at least two users share the same
noise vector. Moreover, by default CANVAS DEFENDER
does not change the noise vector. It requires the user to
trigger it, which means that if a user does not change
the default settings or does not click on the button to
update the noise, she may keep the same noise vector
for a long period. Thus, when detecting that a browser
has CANVAS DEFENDER installed, which can be easily
detected as the string representation of the toDataURL
function leaks its code, if the ﬁngerprinting algorithm
encounters different ﬁngerprints with the same canvas
value, it can conclude that they originate from the same
browser with high conﬁdence. In particular, we discov-
ered that CANVAS DEFENDER injects a script element in
the DOM (cf. Listing 1). This script contains a function
to override canvas-related functions and takes the noise
vector as a parameter, which is not updated by default
and has a high probability to be unique among CAN-
VAS DEFENDER users. By using the JavaScript Mutation
observer API16 and a regular expression (cf. Listing 2),
it is possible to extract the noise vector associated to the
browser, which can then be used as an additional ﬁnger-
printing attribute.
f u n c t i o n o v e r r i d e M e t h o d s ( docId , data ) {
const s = d o c u m e n t . c r e a t e E l e m e n t ( ’ script ’)
s . id = g e t R a n d o m S t r i n g () ;
s . type = " text / j a v a s c r i p t " ;
const code = d o c u m e n t . c r e a t e T e x t N o d e ( ’ try
{( ’+ o v e r r i d e D e f a u l t M e t h o d s + ’) ( ’ + data .
r + ’ , ’+ data . g + ’ , ’ + data . b + ’ , ’+
data . a + ’ ," ’+ s . id + ’ " ," ’+
s t o r e d O b j e c t P r e f i x + ’ ") ;} catch ( e ) {
console . error ( e ) ;} ’) ;
s . a p p e n d C h i l d ( code ) ;
var node = d o c u m e n t . d o c u m e n t E l e m e n t ;
node . i n s e r t B e f o r e (s , node . f i r s t C h i l d ) ;
node [ docId ] = g e t R a n d o m S t r i n g () ; }
Listing 1: Script injected by CANVAS DEFENDER to
override canvas-related function
(/\ d {1 ,2} ,\ d {1 ,2} ,\ d {1 ,2} ,\ d {1 ,2}/)
[0]. split ( " ," ) ;
} }) ; }) ;
o . observe ( d o c u m e n t . do c u me n tE l e me n t , {
c h i l d L i s t : true , subtree : true }) ;
Listing 2: Script to extract the noise vector injected by
CANVAS DEFENDER
Protection Level. While it may seem more tempting
to install an aggressive ﬁngerprinting countermeasure—
i.e., a countermeasure, like RAS, that blocks or modiﬁes
a wide range of attributes used in ﬁngerprinting—we be-
lieve it may be wiser to use a countermeasure with a large
user base even though it does not modify many ﬁnger-
printing attributes. Moreover, in the case of widely-used
open source projects, this may lead to a code base be-
ing audited more regularly than less adopted proprietary
extensions. We also argue that all the users of a given
countermeasure should adopt the same defense strategy.
Indeed, if a countermeasure can be conﬁgured, it may be
possible to infer the settings chosen by a user by detect-
ing side effects, which may be used to target a subset
of users that have a less common combination of set-
tings. Finally, we recommend a defense strategy that
either consists in blocking the access to an attribute or
unifying the value returned for all the users, rather than
a strategy that randomizes the value returned based on
the original value. Concretely, if the value results from a
randomization process based the original value, as does
CANVAS DEFENDER, it may be possible to infer infor-
mation on the original value.
5.2 Perspectives
In this article, we focused on evaluating the effectiveness
of browser ﬁngerprinting countermeasures. We showed
that these countermeasures can be detected because of
their side-effects, which may then be used to target some
of their users more easily. We think that the same tech-
niques could be applied, in general, to any browser exten-
sion. Starov et al. [18] showed that browser extensions
could be detected because of the way they interact with
the DOM. Similar techniques that we used to detect and
characterize ﬁngerprinting countermeasures could also
be used for browser extension detection. Moreover, if an
extension has different settings resulting in different ﬁn-
gerprintable side effects, we argue that these side effects
could be used to characterize the combination of settings
used by a user, which may make the user more trackable.
var o = new M u t a t i o n O b s e r v e r (( ms ) = > {
ms . forEach (( m ) = > {
var script = " o v e r r i d e D e f a u l t M e t h o d s " ;
if ( m . a d d e d N o d e s [0]. text . indexOf ( script ) >
-1) {
var noise = m . a d d e d N o d e s [0]. text . match
5.3 Threats to Validity
A possible threat lies in our experimental framework.
We did extensive testing of FP-SCANNER to ensure that
148    27th USENIX Security Symposium
USENIX Association
browser ﬁngerprints were appropriately detected as al-
tered. Table 9 shows that no countermeasure failed the
steps unrelated to its defense strategy. However, as for
any experimental infrastructure, there might be bugs. We
hope that they only change marginal quantitative results
and not the quality of our ﬁndings. However, we make
the dataset, as well as the algorithm, publicly available
online11, making it possible to replicate the experiment.
We use a ruleset to detect inconsistencies even though
it may be time-consuming to maintain an up-to-date set
of rules that minimize the number of false positives while
ensuring it keeps detecting new countermeasures. More-
over, in this paper, we focused on browser ﬁngerprinting
to detect inconsistencies. Nonetheless, we are aware of
other techniques, such as TCP ﬁngerprinting17, that are
complementary to our approach.
FP-SCANNER aims to be general in its approach to
detect countermeasures. Nevertheless, it is possible to
develop code to target speciﬁc countermeasures as we
showed in the case of CANVAS DEFENDER. Thus, we
consider our study as a lower bound on the vulnerability
of current browser ﬁngerprinting countermeasures.
6 Conclusion
In this paper, we identiﬁed a set of attributes that is ex-
plored by FP-SCANNER to detect inconsistencies and to
classify browser ﬁngerprints into 2 categories: genuine
ﬁngerprints and altered ﬁngerprints by a countermea-
sure. Thus, instead of taking the value of a ﬁngerprint for
granted, ﬁngerprinters could check whether attributes of
a ﬁngerprint have been modiﬁed to escape tracking algo-
rithms, and apply different heuristics accordingly.
To support this study, we collected browser ﬁnger-
prints extracted from browsers using state-of-the-art ﬁn-
gerprinting countermeasures and we showed that FP-
SCANNER was capable of accurately distinguishing gen-
uine from altered ﬁngerprints. We measured the over-
head imposed by FP-SCANNER and we observed that
both the ﬁngerprinter and the test suite were impose a
marginal overhead on a standard laptop, making our ap-
proach feasible for use by ﬁngerprinters in production.
Finally, we discussed how the possibility of detecting
ﬁngerprinting countermeasures, as well as being capa-
ble of predicting the ground value of the browser and the
OS family, may impact user privacy. We argued that be-
ing detected with a ﬁngerprinting countermeasure does
not necessarily imply being tracked more easily. We
took as an example the different countermeasures ana-
lyzed in this paper to explain that tracking vulnerabil-
ity depends on the capability of identifying the counter-
measure used, the number of users having the counter-
measure, the capacity to recover the original ﬁngerprint
values, and the information leaked by the countermea-
sure. Although FP-SCANNER is general in its approach
to detect the presence of countermeasures, using CAN-
VAS DEFENDER as an example, we show it is possible
to develop countermeasure-speciﬁc code to extract more
detailed information.
References
[1] ACAR, G., EUBANK, C., ENGLEHARDT, S., JUAREZ, M.,
NARAYANAN, A., AND DIAZ, C. The web never forgets: Persis-
tent tracking mechanisms in the wild. In Proceedings of the 2014
ACM SIGSAC Conference on Computer and Communications Se-
curity (New York, NY, USA, 2014), CCS ’14, ACM, pp. 674–
689.
[2] ACAR, G.,
JUAREZ, M., NIKIFORAKIS, N., DIAZ, C.,
G ¨URSES, S., PIESSENS, F., AND PRENEEL, B. FPDetective.
Proceedings of the 2013 ACM SIGSAC conference on Computer
& communications security - CCS ’13 (2013), 1129–1140.
[3] ECKERSLEY, P. How unique is your web browser?
In Inter-
national Symposium on Privacy Enhancing Technologies Sympo-
sium (2010), Springer, pp. 1–18.
[4] ENGLEHARDT, S., AND NARAYANAN, A. Online tracking: A
1-million-site measurement and analysis. In Proceedings of the
2016 ACM SIGSAC Conference on Computer and Communica-
tions Security (New York, NY, USA, 2016), CCS ’16, ACM,
pp. 1388–1401.
[5] ENGLEHARDT, S., AND NARAYANAN, A. Online Tracking: A
1-million-site Measurement and Analysis. Proceedings of the
2016 ACM SIGSAC Conference on Computer and Communica-
tions Security - CCS’16, 1 (2016), 1388–1401.
[6] FAIZKHADEMI, A., ZULKERNINE, M., AND WELDEMARIAM,
K. Fpguard: Detection and prevention of browser ﬁngerprinting.
In IFIP Annual Conference on Data and Applications Security
and Privacy (2015), Springer, pp. 293–308.
[7] FIFIELD, D., AND EGELMAN, S. Fingerprinting web users
through font metrics. In International Conference on Financial
Cryptography and Data Security (2015), Springer, pp. 107–124.
[8] G ´OMEZ-BOIX, A., LAPERDRIX, P., AND BAUDRY, B. Hid-
ing in the Crowd: an Analysis of the Effectiveness of Browser
In WWW 2018: The 2018 Web
Fingerprinting at Large Scale.
Conference (Lyon, France, Apr. 2018).
[9] HANNAK, A., SOELLER, G., LAZER, D., MISLOVE, A., AND
WILSON, C. Measuring Price Discrimination and Steering on
E-commerce Web Sites. Proceedings of the 2014 Conference on
Internet Measurement Conference - IMC ’14 (2014), 305–318.
[10] LAPERDRIX, P., BAUDRY, B., AND MISHRA, V. Fprandom:
Randomizing core browser objects to break advanced device ﬁn-
gerprinting techniques. In International Symposium on Engineer-
ing Secure Software and Systems (2017), Springer, pp. 97–114.
[11] LAPERDRIX, P., RUDAMETKIN, W., AND BAUDRY, B. Mitigat-
ing Browser Fingerprint Tracking: Multi-level Reconﬁguration
and Diversiﬁcation. Proceedings - 10th International Symposium
on Software Engineering for Adaptive and Self-Managing Sys-
tems, SEAMS 2015 (2015), 98–108.
[12] LAPERDRIX, P., RUDAMETKIN, W., AND BAUDRY, B. Beauty
and the Beast: Diverting Modern Web Browsers to Build Unique
Browser Fingerprints. Proceedings - 2016 IEEE Symposium on
Security and Privacy, SP 2016 (2016), 878–894.
[13] LERNER, A., SIMPSON, A. K., KOHNO, T., AND ROESNER,
F. Internet Jones and the Raiders of the Lost Trackers: An Ar-
chaeological Study of Web Tracking from 1996 to 2016. Usenix
Security (2016).
USENIX Association
27th USENIX Security Symposium    149
[14] MOWERY, K., AND SHACHAM, H. Pixel Perfect : Fingerprint-
ing Canvas in HTML5. Web 2.0 Security & Privacy 20 (W2SP)
(2012), 1–12.
[15] NIKIFORAKIS, N., JOOSEN, W., AND LIVSHITS, B. PriVarica-
tor. Proceedings of the 24th International Conference on World
Wide Web - WWW ’15 (2015), 820–830.
[16] NIKIFORAKIS, N., KAPRAVELOS, A., JOOSEN, W., KRUEGEL,
C., PIESSENS, F., AND VIGNA, G. Cookieless monster: Explor-
ing the ecosystem of web-based device ﬁngerprinting. Proceed-
ings - IEEE Symposium on Security and Privacy (2013), 541–
555.
[17] SAITO, T., TAKAHASHI, K., YASUDA, K., ISHIKAWA, T.,
TAKASU, K., YAMADA, T., TAKEI, N., AND HOSOI, R. OS and
Application Identiﬁcation by Installed Fonts. 2016 IEEE 30th
International Conference on Advanced Information Networking
and Applications (AINA) (2016), 684–689.
[18] STAROV, O., AND NIKIFORAKIS, N. XHOUND: Quantifying
the Fingerprintability of Browser Extensions. In S&P (2017).
[19] TAKEI, N., SAITO, T., TAKASU, K., AND YAMADA, T. Web
Browser Fingerprinting Using only Cascading Style Sheets. Pro-
ceedings - 2015 10th International Conference on Broadband and
Wireless Computing, Communication and Applications, BWCCA
2015 (2016), 57–63.
[20] TORRES, C. F., JONKER, H., AND MAUW, S. Fp-block: usable
web privacy by controlling browser ﬁngerprinting. In European
Symposium on Research in Computer Security (2015), Springer,
pp. 3–19.
[21] VASILYEV, V.
ﬁngerprintjs2: Modern & ﬂexible browser
original-date: 2015-02-
ﬁngerprinting library, Aug. 2017.
11T08:49:54Z.
[22] VASTEL, A., LAPERDRIX, P., RUDAMETKIN, W., AND ROU-
VOY, R. Fp-stalker: Tracking browser ﬁngerprint evolutions. In
IEEE S&P 2018-39th IEEE Symposium on Security and Privacy
(2018), IEEE, pp. 1–14.
[23] YU, Z., MACBETH, S., MODI, K., AND PUJOL, J. M. Tracking
In Proceedings of the 25th International Confer-
the trackers.
ence on World Wide Web (2016), International World Wide Web
Conferences Steering Committee, pp. 121–132.
Notes
1Augur: https://www.augur.io
2Ghostery: https://www.ghostery.com
3NoScript: https://noscript.net
4AdBlock: https://getadblock.com
5Privacy Badger: https://www.eff.org/fr/privacybadger
6Canvas
https://github.com/kkapsner/
Blocker:
CanvasBlocker
7Canvas Defender:
https://multiloginapp.com/
canvasdefender-browser-extension
8Brave: https://brave.com
9Ultimate User Agent:
useragent/alert.php
10Random Agent Spoofer:
random-agent-spoofer
http://iblogbox.com/chrome/
https://github.com/dillbyrne/
11FP-Scanner dataset: https://github.com/Spirals-Team/
FP-Scanner
12UA Parser: https://github.com/ua-parser/uap-python
13Modernizr: https://modernizr.com
14Caniuse: https://caniuse.com
15List of available features per browser: https://github.com/
Fyrd/caniuse/blob/master/data.json
16Mutation observer API: https://developer.mozilla.org/
en-US/docs/Web/API/MutationObserver
17TCP ﬁngerprinting: http://lcamtuf.coredump.cx/p0f3
150    27th USENIX Security Symposium
USENIX Association