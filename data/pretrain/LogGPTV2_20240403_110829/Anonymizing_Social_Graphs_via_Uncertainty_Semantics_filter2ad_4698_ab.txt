0
if di = 1 ∧ j is the unique neighbor of i
if j is the ﬁrst neighbor of i
if j is a neighbor of i but not the ﬁrst one
otherwise.
Qij =
1It also causes edge miss at t = 2, e.g. a 2-length walk on edge (v3, v2)
(Fig. 1a) causes the selﬂoop (v3, v3).
2This line causes errors for degree-1 nodes as shown in RandWalk-mod.
We show that RandWalk-mod can be formulated as an
uncertain adjacency matrix ARW = (AP t−1
RW ) ◦ (Q + QT ),
where ◦ is the Hadamard product (element-wise). AP t−1
RW
is equivalent to computations in lines 2-6 and Q + QT is
equivalent to computations in lines 7-13. We use Q + QT
instead of Q due to the fact that when the edge (u, z) is added
to G′ with probability Quz, the edge (z, u) is also assigned
the same probability. We come up with the following theorem.
Theorem 4.4: RandWalk-mod can be formulated as ARW =
RW ) ◦ (Q + QT ). ARW is symmetric. It satisﬁes the
Proof: By Lemmas 4.1 and 4.2, let B(t)
RW , we
RW and its row sums are equal to those of
RW and
have symmetric B(t)
A. Because ARW = B(t)
(Q + QT ) are symmetric, ARW is also symmetric.
Due to the fact that (Q+QT ) has the same locations of non-
zeros as B(t)
RW , the condition of unchanged expected degree is
satisﬁed if and only if all non-zeros in (Q + QT ) are 1. This
occurs if and only if α = 0.5.
(AP t−1
constraint of unchanged expected degree iff α = 0.5 3.
RW ◦ (Q + QT ) and both B(t)
RW be AP t−1
Algorithm 1 RandWalk(G0, t, M ) [10]
Input: undirected graph G0, walk length t and maximum loop count
M
Output: anonymized graph G′
1: G′ = null
2: for u in G0 do
3:
count = 1
for v in N (u) do
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
else
loop = 1
while (u == z ∨ (u, z) ∈ G′) ∧ (loop ≤ M ) do
perform t − 1 hop random walk from v
z is the terminal node of the random walk
loop + +
if loop ≤ M then
if count == 1 then
add (u, z) to G′ with probability 1.0
add (u, z) to G′ with probability 0.5du −1
du −1
15:
count + +
return G′
We investigate the limit case when t → ∞ (i.e. P t−1
RW →
P ∞RW ). Correspondingly B∞RW = AP ∞RW has B∞RW (i, j) =
didj
2m . The following theorem quantiﬁes the number of selﬂoops
and multiedges in B∞RW for power-law (PL) graphs and sparse
Erd¨os-Renyi (ER) random graphs [11].
Theorem 4.5: For power-law graphs with the exponent γ,
the number of selﬂoops in B∞RW is ζ(γ−2)
ζ(γ−1), where ζ(γ) is the
Riemann zeta function deﬁned only for γ > 1; the number of
multiedges is zero.
For sparse ER random graphs with λ = np constant where
p is the edge probability, the number of selﬂoops in B∞RW is
λ + 1; the number of multiedges is zero.
Proof: See Appendix A.
Remark 4.1: We notice that RandWalk-mod can be done
equivalently by the idea in SybilGuard [22]. We ﬁrst pick a
3This implies a mistake in Theorem 3 of [10]
Algorithm 2 RandWalk-mod(G0, t, α)
Input: undirected graph G0, walk length t and probability α
Output: anonymized graph G′
1: G′ = null
2: for u in G0 do
3:
count = 1
for v in N (u) do
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
else
else
perform t − 1 hop random walk from v
z is the terminal node of the random walk
if count == 1 then
if du == 1 then
add (u, z) to G′ with probability 0.5
add (u, z) to G′ with probability α
add (u, z) to G′ with probability 0.5du −α
du −1
14:
count + +
return G′
random permutation πu on neighbors of each node u to get du
pairs of (in-edge, out-edge). Then for any walk reaching node
u by the in-edge (v, u), the out-edge is ﬁxed to (u, πu(v)).
In this formulation, it is straightforward to verify that the
transition probability from u to a neighbor v is 1/du(G0).
C. Edge Switching
In edge switching (EdgeSwitch) approaches (Fig. 2b), two
edges (u, v), (w, t) are chosen and switched to (u, t), (w, v)
if aut = awv = 0. This is done in s switches. Using the
switching matrix S, we represent 1-step EdgeSwitch in the
form AS = A (Equation (4)).
The switching matrix S is feasible if and only if auwavt =
0. Note that in the full form, S is n× n matrix with the n− 4
remaining elements on diagonal are 1, other off-diagonal are
0. In general, S is not right stochastic and this happens only
when auw = avt = 0. For s-step EdgeSwitch AQs
i=1 Si = A.
If ∀i, Si is right stochastic (i.e. we choose edges (u, v), (w, t)
such that auw = avt = 0), then Lemma 4.1 applies.
D. Direct Construction
Given the deterministic adjacency matrix A, we can directly
construct A that satisﬁes all three constraints (1),(2) and (3)
in Section IV-A. (k,ǫ)-obf [2] introduces such an approach.
As explained in Section III-B, the expected degrees of nodes
in (k, ǫ)-obf are approximately unchanged due to the fact
that re, re′ are nearly zero by small σ. So (k,ǫ)-obf satisﬁes
constraints (1) and (2) but it only approximately satisﬁes the
third constraint.
To remedy this shortcoming, we present the MaxVar ap-
proach in Section V. It adds potential edges to G0, then tries
to ﬁnd the assignment of edge probabilities such that the
expected node degrees are unchanged while the total variance
is maximized. A comparison among schemes is also shown in
the end of Section V-C.
E. Mixture Approach
In this section, we present the Mixture approach by the
uncertain adjacency matrix Ap parametrized by p, with the
output sample graph Gp. Given the true graph G0 and an
anonymized G ⊑ G, every edge (i, j) is chosen into Gp with
probability Ap(i, j) where
Ap(i, j) =
if (i, j) ∈ EG0 ∩ EG
1
1 − p if (i, j) ∈ EG0 \ EG
if (i, j) ∈ EG \ EG0
p
It is straightforward to show that Ap = (1 − p)A(G0) +
pA(G). When applied to G generated by RandWalk-mod with
α = 0.5, we have Ap = (1− p)A + pAP t−1
RW = A[(1− p)In +
pP t−1
there exists Pmix with constraint Pmix(i, j) =
0 if (i, j) /∈ EG0 such that P t−1
RW , then
Mixture can be simulated by the RandWalk-mod approach
with the transition matrix Pmix.
RW ] and Ap satisﬁes three constraints (1) (2’) and (3).
If
mix = (1 − p)In + pP t−1
F. Partition Approach
Another approach that can apply to RandWalk-mod, (k, ǫ)-
obf, MaxVar and EdgeSwitch is the Partition approach. Given
true graph G0, this divide-and-conquer strategy ﬁrst partitions
G0 into disjoint subgraphs sG, then it applies one of the above
anonymization schemes on subgraphs to get anonymized sub-
graphs sG. Finally, it combines sG to obtain G. Note that the
partitioning may cause orphan edges as in MaxVar (Section
V). Those edges must be copied to G to keep node degrees
unchanged.
V. MAXIMUM VARIANCE APPROACH
We start this section with the formulation of MaxVar in the
form of quadratic programming based on two key observa-
tions. Then we describe the anonymization algorithm.
A. Formulation
Two key observations underpinning the MaxVar approach
are presented as follows.
1) Observation #1: Maximum Degree Variance: We ar-
gue that efﬁcient countermeasures against structural attacks
should hinge on node degrees. If a node and its neigh-
bors have their degrees changed, the re-identiﬁcation risk
is reduced signiﬁcantly. Consequently, instead of replicating
local structures as in k-anonymity based approaches [24],
[9], [25], [4], [20], [18], we can deviate the attacks by
changing node degrees probabilistically. For example, node
v1 in Fig.1a has degree 2 with probability 1.0 whereas in
Fig.1b, its degree gets four possible values {0, 1, 2, 3} with
probabilities {0.014, 0.188, 0.582, 0.216} respectively. Gener-
ally, given edge probabilities of node u as p1, p2, ..pdu(G),
the degree of u is a sum of independent Bernoulli random
variables, so its expected value is Pdu(G)
i=1 pi and its variance
isPdu(G)
i=1 pi(1−pi). If we naively target the maximum (local)
degree variance without any constraints, the naive solution
is at pi = 0.5 ∀i. However, such an assignment distorts
graph structure severely and deteriorates the utility. Instead, by
following the model of uncertain adjacency matrix, we have
the constraint Pdu(G)
i=1 pi = du(G0). Note that the minimum
1
0
0
avt
auw
0
0
1
0
1
auw
0
0
avt
1
0
0
−auw
1
auw
−avt
0
avt
1
1
auw
0
−auw
avt
1
−avt
0
0
0
auw
1
=
0
0
1
avt
auw
1
0
0
1
avt
0
0
(4)
variance of an uncertain graph is 0 and corresponds to the case
G has all edges being deterministic, e.g. when G = G0 and
in switching-edge based approaches. In the following section,
we show an interesting result relating the total degree variance
with the variance of edit distance.
2) Variance with edit distance: The edit distance between
two deterministic graphs G, G′ is deﬁned as:
D(G, G′) = |EG \ EG′| + |EG′ \ EG|
(5)
A well-known result about the expected edit distance be-
tween the uncertain graph G and the deterministic graph
G ⊑ G is
E[D(G, G)] = XG′⊑G
P r(G′)D(G, G′) = Xei∈EG
(1−pi)+ Xei /∈EG
Correspondingly, the variance of edit distance is
V ar[D(G, G)] = XG′⊑G
P r(G′)[D(G, G′) − E[D(G, G)]]2
We prove in the following theorem that the variance of
edit distance is the sum of all edges’ variance (total degree
variance) and it does not depend on the choice of G.
Theorem 5.1: Assume that G(V, E, p) has k uncertain edges
e1, e2, ..., ek and G ⊑ G (i.e. EG ⊆ E). The edit distance
variance is V ar[D(G, G)] = Pk
i=1 pi(1 − pi) and does not
depend on the choice of G.
Proof: See Appendix B.
3) Observation #2: Nearby Potential Edges: As indicated
by Leskovec et al. [8], real graphs reveal
two temporal
evolution properties: densiﬁcation power law and shrinking
diameters. Community Guided Attachment (CGA) model [8],
which produces densifying graphs, is an example of a hierar-
chical graph generation model in which the linkage probability
between nodes decreases as a function of their relative distance
in the hierarchy. With regard to this observation, (k, ǫ)-obf,
by heuristically making potential edges solely based on node
degree discrepancy, produces many inter-community edges.
Shortest-path based statistics will be reduced due to these
edges. MaxVar, in contrast, tries to mitigate the structural
distortion by proposing only nearby potential edges before
assigning edge probabilities. Another evidence is from [19]
where Vazquez analytically proved that Nearest Neighbor
can explain the power-law for degree distribution, clustering
coefﬁcient and average degree among the neighbors. Those
properties are in very good agreement with the observations
made for social graphs. Sala et al. [14] conﬁrmed the consis-
tency of Nearest Neighbor model in their comparative study
on graph models for social networks.
Fig. 3: MaxVar approach
B. Algorithms
pi
This section describes the steps of MaxVar to convert the
input deterministic graph into an uncertain one.
1) Overview: The intuition behind the new approach is to
formulate the perturbation problem as a quadratic program-
ming problem. Given the true graph G0 and the number of
potential edges allowed to be added np, the scheme has three
phases. The ﬁrst phase tries to partition G0 into s subgraphs,
each one with ns = np/s potential edges connecting nearby
nodes (with default distance 2, i.e. friend-of-friend). The sec-
ond phase formulates a quadratic program for each subgraph
with the constraint of unchanged node degrees to produce
the uncertain subgraphs sG with maximum edge variance.
The third phase combines the uncertain subgraphs sG into
G and publishes several sample graphs. The three phases are
illustrated in Fig. 3.
By keeping the degrees of nodes in the perturbed graph, our
approach is similar to the edge switching approaches (e.g.[21])
but ours is more subtle as we do it implicitly and the switching
occurs not necessarily on pairs of edges.
2) Graph Partitioning: Because of the complexity of ex-
act quadratic programming (Section V-B3), we need a pre-
processing phase to divide the true graph G0 into subgraphs
and run the optimization on each subgraph. Given the number
of subgraphs s, we run METIS 4 to get almost equal-sized
subgraphs with minimum number of inter-subgraph edges.
Each subgraph has ns potential edges added before running
the quadratic program. This phase is outlined in Algorithm 3.
3) Quadratic Programming: By assuming the indepen-
dence of edges, the total degree variance of G = (V, E, p)
for edit distance (Theorem 5.1) is:
V ar(E) =
|E|
Xi=1
pi(1 − pi) = |EG0| −
p2
i
|E|
Xi=1
(6)
4http://glaros.dtc.umn.edu/gkhome/views/metis
Algorithm 3 Partition-and-Add-Edges
Input: true graph G0 = (V, EG0 ), number of subgraphs s, number
of potential edges per subgraph ns
Output: list of augmented subgraphs gl
1: gl ← METIS(G0, s).
2: for sG in gl do
3:
4:
5:
i ← 0
while i < ns do
randomly pick u, v ∈ VsG and (u, v) /∈ EsG with
d(u, v) = 2
6:
7:
EsG ← EsG ∪ (u, v)
i ← i + 1
return gl
The last equality in (6) is due to the constraint that the ex-
i=1 pi = du(G0)),
i=1 pi is equal to |EG0|. By targeting the maximum edge
variance, we come up with the following quadratic program.
pected node degrees are unchanged (i.e.Pdu(G)
soP|E|
Minimize
Subject to
Xv∈N (u)
|E|
p2
i
Xi=1
0 ≤ pi ≤ 1 ∀i
puv = du(G0) ∀u
The objective function reﬂects the privacy goal (i.e. sample
graphs do not highly concentrate around the true graph) while
the expected degree constraints aim to preserve the utility.
By dividing the large input graph into subgraphs, we solve
independent quadratic optimization problems. Because each
edge belongs to at most one subgraph and the expected node
degrees in each subgraph are unchanged, it is straightforward
to show that the expected node degrees in G are also un-
changed. We have a proposition on problem feasibility and an
upper bound for the total variance.
Proposition 5.2: The quadratic program in MaxVar is al-
ways feasible. The total variance T VMaxV ar = V ar(E) is
upper bounded by mnp
m+np
Proof: The feasibility is due to the fact that {pe|pe =
1 ∀e ∈ EG0 and pe = 0 otherwise} is a feasible point. Let
ku be the number of potential edges incident to node u.
By requiring u’s expected degree to be unchanged, we have
.
Pv∈N (u) puv = du. Applying Cauchy-Schwarz inequality, we
get Pv∈N (u) p2
we take the sum over all nodes to get the following
uv ≥
. Now
du+ku
du+ku
1
m+np
Xi=1
V ar(E) = m −
d2
u
1
≤ m −
2Xu
du + dk ≤ m −
p2
i = m −
u
1
(Pv∈N (u) puv)2 = d2
2Xu Xv∈N (u)
(Pu du)2
Pu(du + ku)
p2
uv
1
2
=
mnp
m + np
where the last equality is again due to Cauchy-Schwarz
inequality.
C. Comparison of schemes
Table III shows the comparison of schemes we investigate
in this work. Only MaxVar and EdgeSwitch satisfy all three
properties (1),(2) and (3). The next two propositions quantify
the TV of (k, ǫ)-obf and RandWalk-mod.
TABLE III: Comparison of schemes
Scheme
RandWalk-mod
RandWalk
EdgeSwitch
(k, ǫ)-obf
MaxVar
Mixture
Partition
Prop #1
◦ (α = 0.5)
◦
◦
◦
◦
Prop #2
Prop #3 Uncertain A
×
◦
◦