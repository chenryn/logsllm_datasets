The properties of existing BFT state machine replication
systems and of a sound parallelizer with local decisions en-
sure the correctness of our architecture. Please refer to the
extended report [13] for a proof sketch of safety and live-
ness properties.
4.2. Advantages and Limitations
This state machine replication architecture has two po-
tential advantages. First, it can support high-throughput ap-
plications. If the workload contains independent requests
and the system has enough hardware resources, then inde-
pendent requests can be executed concurrently by the ex-
ecution stage to improve the throughput of a system. Sec-
ond, it is simple and ﬂexible. In particular, to achieve high
throughput, we did not change any of the other compo-
nents in the system like client behavior, the agreement pro-
tocol, or the application. These components can therefore
be changed to suit the requirements of the replicated sys-
tem. For example, one can change the agreement protocol
and client side behavior to build a system that either toler-
ates Byzantine failures or fail-stop failures while achieving
high throughput without modifying the parallelizer.
The main limitation of a system using this architecture is
that the rules used by the parallelizer to identify dependent
requests require knowledge of the inner workings of each
application. In many ways, this knowledge is similar to that
required to build the abstraction layer used in BASE to mask
differences in different implementations of the same under-
lying application [19]. However, it may in general be difﬁ-
cult to know what internal state a given request affects or
to determine with certainty whether any given pair of re-
quests are dependent.
Fortunately, it is not necessary to completely understand
the inner workings of an application in order to deﬁne a
parallelizer for it. In particular, it is always permissible to
deﬁne conservative rules that include all true dependencies
but also include some false dependencies. System design-
ers may choose to follow an incremental approach by ﬁrst
deﬁning a set of simple but conservative rules to identify
“obvious” concurrent requests and then progressively reﬁne
the rules if more parallelism is needed to meet performance
goals.
5. CBASE Prototype
The goal of our prototype is to demonstrate a general
way to extend state machine replication systems in order to
allow concurrent execution of requests for applications that
can identify dependencies among requests.
Our prototype, CBASE (Concurrent BASE) system ex-
tends the BASE [19] system to use the high throughput state
machine replication architecture described in the previous
section.
CBASE modiﬁes BASE to cleanly separate the agree-
ment and execution stages and introduces a parallelizer be-
tween these stages as shown in Figure 2. CBASE’s single
threaded agreement module uses BASE’s 3-phase atomic
multicast protocol to establish a total order on requests. The
parallelizer thus receives a series of requests from the agree-
ment module, and it uses an application-speciﬁc set of rules
to identify dependencies among requests and thereby estab-
lish a partial order across them. A pool of worker threads
each draws a request out of the parallelizer, executes it on
the application state machine, and informs the parallelizer
of request completion.
Internally, the parallelizer uses a dependency graph to
maintain a partial order across all pending requests; ver-
tices represent requests and directed edges represent de-
pendencies. The dependency graph forms a DAG as there
can be not be circular dependencies because dependent re-
quests are ordered in the order they are inserted and the
independent requests are not ordered. The parallelizer has
an application-independent scheduler that uses the DAG to
schedule the requests according to the partial order. The
worker threads in the execution stage receive requests that
are not dependent (vertices with no incoming edges) on in-
complete preceding requests from the parallelizer, execute
them concurrently, and remove a request from the DAG
when its execution completes.
The default behavior of the parallelizer is to treat all the
requests as dependent, in which case it behaves like the ex-
isting BASE system where the requests are executed se-
quentially. This default behavior can be used when the ﬁ-
nite state machine is treated as a black box or where de-
pendencies across requests cannot easily be inferred. The
rules in the parallelizer can be incrementally reﬁned by tak-
ing a conservative approach where the requests known to
touch different states can be treated as independent and all
the other requests can be treated as dependent. Similarly,
for backwards compatibility with existing state machines, if
a state machine is not thread safe we can just have a single
 Note, however, that our implementation does not allow the agreement
and execution modules to run on different sets of machines [23].
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 10:04:03 UTC from IEEE Xplore.  Restrictions apply. 
worker thread or implement a mutual exclusion lock around
the state machine.
5.1. Parallelizer interface
The parallelizer appears to the agreement and execu-
tion threads as a variation of a producer/consumer queue.
When a consumer thread asks for a request, the parallelizer
searches for a request that is not dependent of all incom-
plete preceding requests and returns one if found; otherwise
it blocks the consumer thread until a request becomes in-
dependent. The detailed description of parallelizer interface
used by agreement and execution stages is described in [13]
and we just list them here for brevity.
(cid:0) Parallelizer.insert(): Called by the agreement stage to en-
queue a request when the request is committed in the
agreement stage.
(cid:0) Parallelizer.next request(): Called by the execution stage
to fetch an independent request.
(cid:0) Parallelizer.remove request(): Called by the execu-
tion stage after the execution of a request is completed to
delete request state in the parallelizer.
(cid:0) Parallelizer.sync(): This interface supports replica state
checkpointing required by the BASE system [19]. The
agreement stage updates the next checkpoint sequence
number by calling this function as soon as the current
checkpoint is complete.
5.2. Dependence Analysis
The parallelizer’s goal is to determine if a new request
is dependent on any pending request using application-
speciﬁc rules. The parallelizer design must balance three
conﬂicting goals: (1) Generality – the parallelizer should
provide an interface that allows a broad range of appli-
cations to encode rules for detecting dependencies among
their requests; (2) Simplicity – the interface for specifying
these rules should be simple to reduce the effort and like-
lihood of error in dependency-rule speciﬁcation; and (3)
Flexibility – the interface should allow speciﬁcation of sim-
ple conservative dependency rules and progressive reﬁne-
ment to more precise dependency rules that expose more
concurrency. Notice that our design is a compromise among
these design goals and that other algorithms for identifying
dependencies among requests could be explored in future
work.
When a new request r j calling function f j with argu-
ments a j arrives, the parallelizer compares it to each pend-
ing request ri calling function fi with arguments ai as fol-
lows. First, it checks for argument-independent dependen-
cies using an application-speciﬁc operator concurrency ma-
trix (OCM): if OCM(cid:0) fi (cid:0) f j(cid:1) is true, the requests are depen-
dent. If not, then it checks to see if the arguments indi-
cate that there may be additional risk of dependencies us-
ing an argument analysis funtion (AAF) : if AAFai (cid:0)a j
is true, then it also checks for argument-dependent depen-
dencies and identiﬁes a dependency between ri and r j if
REPLICA 1
Replication Library
Conc. Matrix
Agreement
Parallelizer
Worker
thread pool
Conformance
Wrapper
Unmodified
NFS
Application
Client
Replication
Library
Relay
REPLICA N
Kernel NFS client
Replication Library
Conc. Matrix
Agreement
Parallelizer
Worker
thread pool
Conformance
Wrapper
Unmodified
NFS
Fig. 3. CBASE-FS: High throughput Byzantine fault
tolerant NFS
OACM(cid:0) fi (cid:0) f j(cid:1) (operator+argument concurrency matrix) is
true. Finally, if OCM(cid:0) fi (cid:0) f j(cid:1) is false and either AAFai (cid:0)a j is
false or OACM(cid:0) fi (cid:0) f j(cid:1) is false, then no dependency between
ri and r j exists. Please refer to [13] for a detailed descrip-
tion of dependence analysis.
This structure facilitates a 2-level analysis in which
the operator concurrency matrix OCM deﬁnes broad rules
where no argument analysis is attempted or needed and in
which the operator+argument concurrency matrix OACM
deﬁnes more precise rules that are invoked after an analy-
sis of the arguments indicates that two calls that sometimes
are independent may be in conﬂict due to their argu-
ments. The next subsection describes our NFS ﬁle system
prototype where we use the OACM to encode rules for func-
tions if the state they affect is easily identiﬁed from ﬁle han-
dles in their arguments and where we use the OCM to
handle other functions.
5.3. Example Service: NFS
We have implemented CBASE-FS, a Byzantine fault tol-
erant NFS [4] using CBASE as shown in Figure 3. Our im-
plementation builds on BASE-FS [19], which uses existing
implementations of NFS to implement each instance of the
replicated state machine. In particular, a client in CBASE-
FS mounts the replicated ﬁle system exported by the repli-
cas as a local NFS ﬁle system [16]. Unmodiﬁed applica-
tions access the ﬁle system using standard ﬁle system calls.
The local kernel sends NFS calls to the local user-level NFS
server, which acts as a wrapper for CBASE-FS by calling
the invoke procedure of the BASE replication library to re-
lay the request to the replicas. This procedure returns when
the wrapper receives f  1 matching replies from different
replicas.
The agreement stage in CBASE establishes a total order
on requests and then sends each ordered request to the paral-
lelizer. The parallelizer updates the dependency graph using
NFS’s concurrency matrix as deﬁned in section 5.3.1 when-
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 10:04:03 UTC from IEEE Xplore.  Restrictions apply. 
ever a request is enqueued. The worker threads in the exe-
cution stage dequeue independent requests and execute the
requests.
CBASE-FS uses BASE’s [19] abstraction layer (confor-
mance wrapper) to resolve non-determinism in NFS such as
ﬁle handle assignment or timestamp generation. Addition-
ally, CBASE introduces a new source of non-determinism
due to concurrent execution of NFS create operations to dif-
ferent ﬁles. The existing BASE conformance wrapper at dif-
ferent replicas could return different ﬁle handles based on
the order of execution of these requests. We ﬁx this problem
by having a rule in the concurrency matrix to treat the re-
quests with create/delete operations as always dependent.†
5.3.1. Concurrency Matrix for NFS For NFS, we keep
the classiﬁcation simple by just looking at the ﬁle han-
dles, and thus must have conservative rules for some of
the operations. Our argument analysis function (AAF) de-
ﬁnes two arguments as related if they include a common ﬁle
handle. We present the key rules that are used in deﬁning
NFS’s argument-independent operator concurrency matrix
(OCM) and argument-dependent operator+argument con-
currency matrix (OACM) below. Refer to [12] for the com-
plete deﬁnitions of the concurrency matrices.
(cid:0) getattr and null requests are read only requests and hence
are independent for both related and unrelated arguments.
(cid:0) Reads to different ﬁles are independent whereas reads
to the same ﬁles are dependent. Reads modify the last-
accessed-time attribute of a ﬁle, so we do not concur-
rently execute read requests to the same ﬁle.
(cid:0) Writes to different ﬁles are independent and writes to the
same ﬁle are dependent. Reads are dependent on writes
to the same ﬁle and vice-versa.
(cid:0) All create and remove operations to the same ﬁle
or different ﬁles are dependent as they introduce
non-determinism if executed concurrently.
(cid:0) Create/Rename/Remove operations are always treated as
dependent on Read/Write operations. Read/Write op-
erations carry the ﬁle handle of the ﬁle whereas cre-
ate/rename/remove requests carry the ﬁle handle of the
directory in which ﬁle is present and the ﬁlename of the
ﬁle to be deleted. As we just look at the ﬁle handle to
decide if two arguments are related or not, we cannot
execute the requests with create/rename/remove concur-
rently with read/write requests.
We give up some potential concurrency across requests
with these conservative rules. Looking at other ﬁelds in the
request apart from ﬁle handle and keeping additional state
about ﬁle handles could allow for more sophisticated and
accurate classiﬁcation. There is a tradeoff between on one
† We speculate that additional concurrency could be exposed by includ-
ing constraints based on a request’s total-order sequence number to
the conformance wrapper’s ﬁle handle generation logic and the paral-
lelizer’s dependency logic.
hand the simplicity of the design and the time spent to clas-
sify requests versus on the other hand the amount of con-
currency realized by the parallelizer. This trade-off should
be explored in more detail in the future.
5.4. Additional Optimizations
CBASE supports some of
the optimizations intro-
duced by PBFT [8] such as reduced communication,
request batching, read-only optimization in order to im-
prove throughput. However, CBASE does not support
tentative execution as it
is shown in [7] that this op-
timization has little impact on throughput when used
along with request batching and that it adds complex-
ity to the code to keep uncommitted state in the system.
6. Evaluation
A high throughput BFT system should achieve two
goals: (1) when there is application parallelism and hard-
ware concurrency it should provide high throughput com-
pared to traditional BFT system, and (2) when there is no
parallelism in the application or when there are limited re-
sources it must have low overhead.
All experiments run with 4 replicas and the system tol-
erates one Byzantine fault. Replicas run on single processor
machines with 933 MHZ PIII processor and connected by
a 100 Mbit ethernet hub. All the machines have 256MB of
memory except for one that has 512MB of memory. The ex-
periments run on an isolated network. We use 5 client ma-
chines to load the system. Client machines are connected
to the network through the same ethernet hub as the repli-
cas. Two of the client machines have 933 MHZ PIII proces-
sor with 512MB of memory and the other three machines
have 450 MHZ PIII processor with 128KB of memory. All
machines run Redhat Linux 7.2.
6.1. Micro-Benchmark
The micro-benchmark compares the performance of
BASE and CBASE executing a simple, stateless ser-
vice - clients send null requests to which the server re-
ply with null results. We show that for our microbenchmark
CBASE imposes little additional latency or overhead com-
pared to BASE and that CBASE’s throughput scales
linearly with application parallelism and available hard-
ware resources.
6.1.1. Overhead Figure 4 compares the overhead of
BASE and CBASE by running the baseline bench-
mark conﬁgured with inﬁnite application concurrency (no
shared state across requests) and minimal hardware de-
mand per request (each application request at the server
simply returns immediately). BASE is CPU-limited—a
small number of clients saturate the CPU, but BASE al-
lows throughput to reach a peak of about 15,000 requests
per second by employing agreement-stage batching [9],
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 10:04:03 UTC from IEEE Xplore.  Restrictions apply. 
)
c
e
s
r
e
p
s
n