### Properties of Existing BFT State Machine Replication Systems

The properties of existing Byzantine Fault Tolerant (BFT) state machine replication systems, combined with a well-designed parallelizer that makes local decisions, ensure the correctness of our architecture. For a detailed proof sketch of the safety and liveness properties, please refer to the extended report [13].

### 4.2. Advantages and Limitations

Our state machine replication architecture offers two key advantages:

1. **High Throughput**: The architecture can support high-throughput applications. If the workload consists of independent requests and the system has sufficient hardware resources, these independent requests can be executed concurrently by the execution stage, thereby improving the overall throughput.

2. **Simplicity and Flexibility**: The architecture is simple and flexible. To achieve high throughput, we did not modify other components such as client behavior, the agreement protocol, or the application itself. This allows these components to be adapted to meet the specific requirements of the replicated system. For instance, one can change the agreement protocol and client-side behavior to build a system that tolerates either Byzantine or fail-stop failures while maintaining high throughput without altering the parallelizer.

**Limitations**:
- The main limitation is that the rules used by the parallelizer to identify dependent requests require in-depth knowledge of the internal workings of each application. This is similar to the knowledge needed to build the abstraction layer in BASE, which masks differences in different implementations of the same underlying application [19]. However, it can be challenging to determine the internal state affected by a given request or to ascertain with certainty whether any pair of requests are dependent.

Fortunately, complete understanding of an application's inner workings is not necessary to define a parallelizer. It is permissible to define conservative rules that include all true dependencies and some false dependencies. System designers can adopt an incremental approach, starting with simple but conservative rules to identify "obvious" concurrent requests and then progressively refine the rules to meet performance goals.

### 5. CBASE Prototype

The goal of our prototype, CBASE (Concurrent BASE), is to demonstrate a general method for extending state machine replication systems to allow concurrent execution of requests for applications that can identify dependencies among requests. CBASE extends the BASE [19] system to use the high-throughput state machine replication architecture described earlier.

#### 5.1. Architecture Overview

CBASE modifies BASE to cleanly separate the agreement and execution stages and introduces a parallelizer between them. The single-threaded agreement module uses BASE’s 3-phase atomic multicast protocol to establish a total order on requests. The parallelizer receives a series of requests from the agreement module and uses an application-specific set of rules to identify dependencies, thereby establishing a partial order across them. A pool of worker threads draws requests from the parallelizer, executes them on the application state machine, and informs the parallelizer of request completion.

Internally, the parallelizer uses a dependency graph to maintain a partial order across all pending requests. Vertices represent requests, and directed edges represent dependencies. The dependency graph forms a Directed Acyclic Graph (DAG) because dependent requests are ordered in the sequence they are inserted, and independent requests are not ordered. The parallelizer has an application-independent scheduler that uses the DAG to schedule requests according to the partial order. Worker threads in the execution stage receive and execute non-dependent requests (vertices with no incoming edges) concurrently, removing a request from the DAG upon completion.

#### 5.2. Parallelizer Interface

The parallelizer appears to the agreement and execution threads as a variation of a producer/consumer queue. The key interfaces are:

- **Parallelizer.insert()**: Called by the agreement stage to enqueue a request when it is committed.
- **Parallelizer.next_request()**: Called by the execution stage to fetch an independent request.
- **Parallelizer.remove_request()**: Called by the execution stage after the execution of a request is completed to delete the request state in the parallelizer.
- **Parallelizer.sync()**: Supports replica state checkpointing required by the BASE system. The agreement stage updates the next checkpoint sequence number by calling this function once the current checkpoint is complete.

#### 5.3. Dependence Analysis

The parallelizer's goal is to determine if a new request is dependent on any pending request using application-specific rules. The design must balance three conflicting goals: generality, simplicity, and flexibility. Our design is a compromise among these goals, and other algorithms for identifying dependencies could be explored in future work.

When a new request \( r_j \) calling function \( f_j \) with arguments \( a_j \) arrives, the parallelizer compares it to each pending request \( r_i \) calling function \( f_i \) with arguments \( a_i \) as follows:

1. **Argument-Independent Dependencies**: The parallelizer checks for argument-independent dependencies using an application-specific operator concurrency matrix (OCM). If \( \text{OCM}(f_i, f_j) \) is true, the requests are dependent.
2. **Argument-Dependent Dependencies**: If \( \text{OCM}(f_i, f_j) \) is false, the parallelizer checks if the arguments indicate additional risk of dependencies using an argument analysis function (AAF). If \( \text{AAF}(a_i, a_j) \) is true, it further checks for argument-dependent dependencies using the operator+argument concurrency matrix (OACM). If \( \text{OACM}(f_i, f_j) \) is true, a dependency is identified. Otherwise, no dependency exists.

This structure facilitates a two-level analysis: the OCM defines broad rules where no argument analysis is needed, and the OACM defines more precise rules invoked after argument analysis indicates potential conflicts.

#### 5.4. Example Service: NFS

We have implemented CBASE-FS, a Byzantine fault-tolerant Network File System (NFS) using CBASE. Our implementation builds on BASE-FS [19], which uses existing NFS implementations for each instance of the replicated state machine. Clients in CBASE-FS mount the replicated file system exported by the replicas as a local NFS file system. Unmodified applications access the file system using standard file system calls.

The local kernel sends NFS calls to the local user-level NFS server, which acts as a wrapper for CBASE-FS by calling the invoke procedure of the BASE replication library to relay the request to the replicas. The procedure returns when the wrapper receives \( f - 1 \) matching replies from different replicas.

The agreement stage in CBASE establishes a total order on requests and sends each ordered request to the parallelizer. The parallelizer updates the dependency graph using NFS’s concurrency matrix as defined in section 5.3.1 whenever a request is enqueued. Worker threads in the execution stage dequeue independent requests and execute them.

CBASE-FS uses BASE’s conformance wrapper to resolve non-determinism in NFS, such as file handle assignment or timestamp generation. Additionally, CBASE introduces a new source of non-determinism due to concurrent execution of NFS create operations to different files. We address this by treating requests with create/delete operations as always dependent.

#### 5.5. Concurrency Matrix for NFS

For NFS, we keep the classification simple by looking at file handles, resulting in conservative rules for some operations. Our AAF defines two arguments as related if they include a common file handle. Key rules for defining NFS’s OCM and OACM are:

- **getattr and null requests**: These are read-only and independent for both related and unrelated arguments.
- **Reads to different files**: Independent; reads to the same file are dependent.
- **Writes to different files**: Independent; writes to the same file are dependent. Reads are dependent on writes to the same file and vice versa.
- **Create/Remove operations**: All create and remove operations to the same or different files are dependent due to introduced non-determinism.
- **Create/Rename/Remove operations**: Always treated as dependent on Read/Write operations. Read/Write operations carry the file handle of the file, while create/rename/remove requests carry the file handle of the directory and the filename. As we only look at the file handle, we cannot execute these requests concurrently.

These conservative rules sacrifice some potential concurrency. More sophisticated and accurate classification could be achieved by examining other fields in the request and maintaining additional state about file handles, but this would increase complexity.

### 6. Evaluation

A high-throughput BFT system should achieve two goals: (1) provide high throughput when there is application parallelism and hardware concurrency, and (2) have low overhead when there is no parallelism or limited resources.

#### 6.1. Micro-Benchmark

The micro-benchmark compares the performance of BASE and CBASE executing a simple, stateless service. Clients send null requests to which the server replies with null results. The results show that CBASE imposes little additional latency or overhead compared to BASE and that its throughput scales linearly with application parallelism and available hardware resources.

#### 6.1.1. Overhead

Figure 4 compares the overhead of BASE and CBASE by running the baseline benchmark configured with infinite application concurrency (no shared state across requests) and minimal hardware demand per request. BASE is CPU-limited, with a small number of clients saturating the CPU, but it allows throughput to reach a peak of about 15,000 requests per second by employing agreement-stage batching [9].

### Conclusion

CBASE demonstrates a practical and efficient way to extend state machine replication systems for high-throughput applications. By separating the agreement and execution stages and introducing a parallelizer, CBASE can handle independent requests concurrently, significantly improving throughput. The architecture is flexible and can be adapted to various applications, including complex ones like NFS, while maintaining the necessary guarantees of correctness and liveness.