a process must register its intent to use the private
expedited command prior to using it.
.tp
.br membarrier_cmd_register_private_expedited " (since linux 4.14)"
register the process's intent to use
.br membarrier_cmd_private_expedited .
.tp
.br membarrier_cmd_private_expedited_sync_core " (since linux 4.16)"
in addition to providing the memory ordering guarantees described in
.br membarrier_cmd_private_expedited ,
upon return from system call the calling thread has a guarantee that all its
running thread siblings have executed a core serializing instruction.
this guarantee is provided only for threads in
the same process as the calling thread.
.ip
the "expedited" commands complete faster than the non-expedited ones,
they never block, but have the downside of causing extra overhead.
.ip
a process must register its intent to use the private expedited sync
core command prior to using it.
.tp
.br membarrier_cmd_register_private_expedited_sync_core " (since linux 4.16)"
register the process's intent to use
.br membarrier_cmd_private_expedited_sync_core .
.tp
.br membarrier_cmd_private_expedited_rseq " (since linux 5.10)"
ensure the caller thread, upon return from system call, that all its
running thread siblings have any currently running rseq critical sections
restarted if
.i flags
parameter is 0; if
.i flags
parameter is
.br membarrier_cmd_flag_cpu ,
then this operation is performed only on cpu indicated by
.ir cpu_id .
this guarantee is provided only for threads in
the same process as the calling thread.
.ip
rseq membarrier is only available in the "private expedited" form.
.ip
a process must register its intent to use the private expedited rseq
command prior to using it.
.tp
.br membarrier_cmd_register_private_expedited_rseq " (since linux 5.10)"
register the process's intent to use
.br membarrier_cmd_private_expedited_rseq .
.tp
.br membarrier_cmd_shared " (since linux 4.3)"
this is an alias for
.br membarrier_cmd_global
that exists for header backward compatibility.
.pp
the
.i flags
argument must be specified as 0 unless the command is
.br membarrier_cmd_private_expedited_rseq ,
in which case
.i flags
can be either 0 or
.br membarrier_cmd_flag_cpu .
.pp
the
.i cpu_id
argument is ignored unless
.i flags
is
.br membarrier_cmd_flag_cpu ,
in which case it must specify the cpu targeted by this membarrier
command.
.pp
all memory accesses performed in program order from each targeted thread
are guaranteed to be ordered with respect to
.br membarrier ().
.pp
if we use the semantic
.i barrier()
to represent a compiler barrier forcing memory
accesses to be performed in program order across the barrier, and
.i smp_mb()
to represent explicit memory barriers forcing full memory
ordering across the barrier, we have the following ordering table for
each pairing of
.ir barrier() ,
.br membarrier (),
and
.ir smp_mb() .
the pair ordering is detailed as (o: ordered, x: not ordered):
.pp
                       barrier()  smp_mb()  membarrier()
       barrier()          x          x          o
       smp_mb()           x          o          o
       membarrier()       o          o          o
.sh return value
on success, the
.b membarrier_cmd_query
operation returns a bit mask of supported commands, and the
.br membarrier_cmd_global ,
.br membarrier_cmd_global_expedited ,
.br membarrier_cmd_register_global_expedited ,
.br membarrier_cmd_private_expedited ,
.br membarrier_cmd_register_private_expedited ,
.br membarrier_cmd_private_expedited_sync_core ,
and
.b membarrier_cmd_register_private_expedited_sync_core
operations return zero.
on error, \-1 is returned,
and
.i errno
is set to indicate the error.
.pp
for a given command, with
.i flags
set to 0, this system call is
guaranteed to always return the same value until reboot.
further calls with the same arguments will lead to the same result.
therefore, with
.i flags
set to 0, error handling is required only for the first call to
.br membarrier ().
.sh errors
.tp
.b einval
.i cmd
is invalid, or
.i flags
is nonzero, or the
.br membarrier_cmd_global
command is disabled because the
.i nohz_full
cpu parameter has been set, or the
.br membarrier_cmd_private_expedited_sync_core
and
.br membarrier_cmd_register_private_expedited_sync_core
commands are not implemented by the architecture.
.tp
.b enosys
the
.br membarrier ()
system call is not implemented by this kernel.
.tp
.b eperm
the current process was not registered prior to using private expedited
commands.
.sh versions
the
.br membarrier ()
system call was added in linux 4.3.
.pp
before linux 5.10, the prototype for
.br membarrier ()
was:
.pp
.in +4n
.ex
.bi "int membarrier(int " cmd ", int " flags );
.ee
.in
.sh conforming to
.br membarrier ()
is linux-specific.
.\" .sh see also
.\" fixme see if the following syscalls make it into linux 4.15 or later
.\" .br cpu_opv (2),
.\" .br rseq (2)
.sh notes
a memory barrier instruction is part of the instruction set of
architectures with weakly ordered memory models.
it orders memory
accesses prior to the barrier and after the barrier with respect to
matching barriers on other cores.
for instance, a load fence can order
loads prior to and following that fence with respect to stores ordered
by store fences.
.pp
program order is the order in which instructions are ordered in the
program assembly code.
.pp
examples where
.br membarrier ()
can be useful include implementations
of read-copy-update libraries and garbage collectors.
.sh examples
assuming a multithreaded application where "fast_path()" is executed
very frequently, and where "slow_path()" is executed infrequently, the
following code (x86) can be transformed using
.br membarrier ():
.pp
.in +4n
.ex
#include 
static volatile int a, b;
static void
fast_path(int *read_b)
{
    a = 1;
    asm volatile ("mfence" : : : "memory");
    *read_b = b;
}
static void
slow_path(int *read_a)
{
    b = 1;
    asm volatile ("mfence" : : : "memory");
    *read_a = a;
}
int
main(int argc, char *argv[])
{
    int read_a, read_b;
    /*
     * real applications would call fast_path() and slow_path()
     * from different threads. call those from main() to keep
     * this example short.
     */
    slow_path(&read_a);
    fast_path(&read_b);
    /*
     * read_b == 0 implies read_a == 1 and
     * read_a == 0 implies read_b == 1.
     */
    if (read_b == 0 && read_a == 0)
        abort();
    exit(exit_success);
}
.ee
.in
.pp
the code above transformed to use
.br membarrier ()
becomes:
.pp
.in +4n
.ex
#define _gnu_source
#include 
#include 
#include 
#include 
#include 
static volatile int a, b;
static int
membarrier(int cmd, unsigned int flags, int cpu_id)
{
    return syscall(__nr_membarrier, cmd, flags, cpu_id);
}
static int
init_membarrier(void)
{
    int ret;
    /* check that membarrier() is supported. */
    ret = membarrier(membarrier_cmd_query, 0, 0);
    if (ret 
.\"
.\" %%%license_start(bsd_3_clause_ucb)
.\" redistribution and use in source and binary forms, with or without
.\" modification, are permitted provided that the following conditions
.\" are met:
.\" 1. redistributions of source code must retain the above copyright
.\"    notice, this list of conditions and the following disclaimer.
.\" 2. redistributions in binary form must reproduce the above copyright
.\"    notice, this list of conditions and the following disclaimer in the
.\"    documentation and/or other materials provided with the distribution.
.\" 3. neither the name of the university nor the names of its contributors
.\"    may be used to endorse or promote products derived from this software
.\"    without specific prior written permission.
.\"
.\" this software is provided by the regents and contributors ``as is'' and
.\" any express or implied warranties, including, but not limited to, the
.\" implied warranties of merchantability and fitness for a particular purpose
.\" are disclaimed.  in no event shall the regents or contributors be liable
.\" for any direct, indirect, incidental, special, exemplary, or consequential
.\" damages (including, but not limited to, procurement of substitute goods
.\" or services; loss of use, data, or profits; or business interruption)
.\" however caused and on any theory of liability, whether in contract, strict
.\" liability, or tort (including negligence or otherwise) arising in any way
.\" out of the use of this software, even if advised of the possibility of
.\" such damage.
.\" %%%license_end
.\"
.\"
.th stailq 3 2021-08-27 "gnu" "linux programmer's manual"
.sh name
.\"simpleq_concat,
simpleq_empty,
simpleq_entry,
simpleq_first,
simpleq_foreach,
.\"simpleq_foreach_from,
.\"simpleq_foreach_from_safe,
.\"simpleq_foreach_safe,
simpleq_head,
simpleq_head_initializer,
simpleq_init,
simpleq_insert_after,
simpleq_insert_head,
simpleq_insert_tail,
.\"simpleq_last,
simpleq_next,
simpleq_remove,
.\"simpleq_remove_after,
simpleq_remove_head,
.\"simpleq_swap,
stailq_concat,
stailq_empty,
stailq_entry,
stailq_first,
stailq_foreach,
.\"stailq_foreach_from,
.\"stailq_foreach_from_safe,
.\"stailq_foreach_safe,
stailq_head,
stailq_head_initializer,
stailq_init,
stailq_insert_after,
stailq_insert_head,
stailq_insert_tail,
.\"stailq_last,
stailq_next,
stailq_remove,
.\"stailq_remove_after,
stailq_remove_head,
.\"stailq_swap
\- implementation of a singly linked tail queue
.sh synopsis
.nf
.b #include 
.pp
.b stailq_entry(type);
.pp
.b stailq_head(headname, type);
.bi "stailq_head stailq_head_initializer(stailq_head " head );
.bi "void stailq_init(stailq_head *" head );
.pp
.bi "int stailq_empty(stailq_head *" head );
.pp
.bi "void stailq_insert_head(stailq_head *" head ,
.bi "                         struct type *" elm ", stailq_entry " name );
.bi "void stailq_insert_tail(stailq_head *" head ,
.bi "                         struct type *" elm ", stailq_entry " name );
.bi "void stailq_insert_after(stailq_head *" head ", struct type *" listelm ,
.bi "                         struct type *" elm ", stailq_entry " name );
.pp
.bi "struct type *stailq_first(stailq_head *" head );
.\" .bi "struct type *stailq_last(stailq_head *" head ", struct type *" elm ,
.\" .bi "                          stailq_entry " name );
.bi "struct type *stailq_next(struct type *" elm ", stailq_entry " name );
.pp
.bi "stailq_foreach(struct type *" var ", stailq_head *" head ", stailq_entry " name );
.\" .bi "stailq_foreach_from(struct type *" var ", stailq_head *" head ,
.\" .bi "                          stailq_entry " name );
.\" .pp
.\" .bi "stailq_foreach_safe(struct type *" var ", stailq_head *" head ,
.\" .bi "                          stailq_entry " name ", struct type *" temp_var );
.\" .bi "stailq_foreach_from_safe(struct type *" var ", stailq_head *" head ,
.\" .bi "                          stailq_entry " name ", struct type *" temp_var );
.pp
.bi "void stailq_remove(stailq_head *" head ", struct type *" elm ", type,"
.bi "                         stailq_entry " name );
.bi "void stailq_remove_head(stailq_head *" head ,
.bi "                         stailq_entry " name );
.\" .bi "void stailq_remove_after(stailq_head *" head ", struct type *" elm ,
.\" .bi "                          stailq_entry " name );
.pp
.bi "void stailq_concat(stailq_head *" head1 ", stailq_head *" head2 );
.\" .bi "void stailq_swap(stailq_head *" head1 ", stailq_head *" head2 ,
.\" .bi "                          stailq_entry " name );
.fi
.ir note :
identical macros prefixed with simpleq instead of stailq exist; see notes.
.sh description
these macros define and operate on singly linked tail queues.
.pp
in the macro definitions,
.i type
is the name of a user-defined structure,
that must contain a field of type
.ir stailq_entry ,
named
.ir name .
the argument
.i headname
is the name of a user-defined structure that must be declared
using the macro
.br stailq_head ().
.ss creation
a singly linked tail queue is headed by a structure defined by the
.br stailq_head ()
macro.
this structure contains a pair of pointers,
one to the first element in the tail queue and the other to
the last element in the tail queue.
the elements are singly linked for minimum space and pointer
manipulation overhead at the expense of o(n) removal for arbitrary elements.
new elements can be added to the tail queue after an existing element,
at the head of the tail queue, or at the end of the tail queue.
a
.i stailq_head
structure is declared as follows:
.pp
.in +4
.ex
stailq_head(headname, type) head;
.ee
.in
.pp
where
.i struct headname
is the structure to be defined, and
.i struct type
is the type of the elements to be linked into the tail queue.
a pointer to the head of the tail queue can later be declared as:
.pp
.in +4
.ex
struct headname *headp;
.ee
.in
.pp
(the names
.i head
and
.i headp
are user selectable.)
.pp
.br stailq_entry ()
declares a structure that connects the elements in the tail queue.
.pp
.br stailq_head_initializer ()
evaluates to an initializer for the tail queue
.ir head .
.pp
.br stailq_init ()
initializes the tail queue referenced by
.ir head .
.pp
.br stailq_empty ()
evaluates to true if there are no items on the tail queue.
.ss insertion
.br stailq_insert_head ()
inserts the new element
.i elm
at the head of the tail queue.
.pp
.br stailq_insert_tail ()
inserts the new element
.i elm
at the end of the tail queue.
.pp
.br stailq_insert_after ()
inserts the new element
.i elm
after the element
.ir listelm .
.ss traversal
.br stailq_first ()
returns the first item on the tail queue or null if the tail queue is empty.
.\" .pp
.\" .br stailq_last ()
.\" returns the last item on the tail queue.
.\" if the tail queue is empty the return value is null .
.pp
.br stailq_next ()
returns the next item on the tail queue, or null this item is the last.
.pp
.br stailq_foreach ()
traverses the tail queue referenced by
.i head