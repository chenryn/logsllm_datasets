 5  ) 
 6  by (phase)
```
不出所料，除非你搞砸了什么，否则输出的值都设置为`0`。
![](img/d0db1323-5bea-4eb6-bdf0-4a1717233f5e.png)
Figure 3-35: Prometheus' console view with the sum of the Pods in Failed, Unknown, or Pending phases
到目前为止，没有我们应该担心的 Pods。我们将通过创建一个会故意失败的映像，通过使用一个显然不存在的映像来改变这一点。
```
 1  kubectl run problem \
 2      --image i-do-not-exist \
 3      --restart=Never
```
从输出中我们可以看到`pod/problem`是`created`。如果我们通过脚本(例如，配置项/光盘管道)创建它，我们会认为一切正常。即使我们用`kubectl rollout status`跟随它，我们也只会确保它开始工作，而不是继续工作。
但是，由于我们不是通过配置项/目录管道而是手动创建的，我们也可以列出`default`名称空间中的所有目录。
```
 1  kubectl get pods
```
输出如下。
```
NAME    READY STATUS       RESTARTS AGE
problem 0/1   ErrImagePull 0        27s
```
我们会想象我们只有短期记忆，已经忘记`image`设置为`i-do-not-exist`。会有什么问题？嗯，第一步是描述吊舱。
```
 1  kubectl describe pod problem
```
输出仅限于`Events`部分的消息，如下所示。
```
...
Events:
...  Message
...  -------
...  Successfully assigned default/problem to aks-nodepool1-29770171-2
...  Back-off pulling image "i-do-not-exist"
...  Error: ImagePullBackOff
...  pulling image "i-do-not-exist"
...  Failed to pull image "i-do-not-exist": rpc error: code = Unknown desc = Error response from daemon: repository i-do-not-exist not found: does not exist or no pull access
 Warning  Failed     8s (x3 over 46s)   kubelet, aks-nodepool1-29770171-2  Error: ErrImagePull
```
这个问题通过`Back-off pulling image "i-do-not-exist"`消息明显体现出来。再往下，我们可以看到来自容器服务器的消息称`it failed to pull image "i-do-not-exist"`。
当然，我们事先知道会有这样的结果，但是类似的事情可能会发生，而我们没有注意到有问题。原因可能是拉不动形象，或者是无数其他原因中的一个。然而，我们不应该坐在终端前，列出并描述 Pods 和其他类型的资源。相反，我们应该收到 Kubernetes 未能运行 Pod 的警报，只有在此之后，我们才应该开始挖掘问题的原因。因此，让我们再创建一个警报，当 Pods 失败并且没有恢复时，它会通知我们。
像以前一样，我们将看看普罗米修斯图表值的新旧定义之间的差异。
```
 1  diff mon/prom-values-errors.yml \
 2      mon/prom-values-phase.yml
```
输出如下。
```
136a137,146
> - name: pods
>   rules:
>   - alert: ProblematicPods
>     expr: sum(kube_pod_status_phase{phase=~"Failed|Unknown|Pending"}) by (phase) > 0
>     for: 1m
>     labels:
>       severity: notify
>     annotations:
>       summary: At least one Pod could not run
>       description: At least one Pod is in a problematic phase
```
我们定义了一组新的警报，称为`pod`。在它里面，我们有一个名为`ProblematicPods`的`alert`，如果有一个或多个带有`Failed`、`Unknown`或`Pending`相位的吊舱超过一分钟(`1m`)就会开火。我故意把它设置得很低`for`持续时间，这样我们可以很容易地测试它。稍后，我们将切换到 15 分钟的时间间隔，这将足以让 Kubernetes 在我们收到通知将我们发送到紧急模式之前解决问题。
让我们用更新的值来更新普罗米修斯的图表。
```
 1  helm upgrade -i prometheus \
 2    stable/prometheus \
 3    --namespace metrics \
 4    --version 7.1.3 \
 5    --set server.ingress.hosts={$PROM_ADDR} \
 6    --set alertmanager.ingress.hosts={$AM_ADDR} \
 7    -f mon/prom-values-phase.yml
```
由于我们还没有解决`problem`吊舱的问题，我们应该很快会在 Slack 中看到新的通知。让我们确认一下。
```
 1  open "https://devops20.slack.com/messages/CD8QJA8DS/"
```
如果您的通知尚未到达，请稍等片刻。
我们得到消息说`at least one Pod could not run`。
![](img/a4035775-47d5-4dbe-a3bd-8142a286be0b.png)
Figure 3-36: Slack with an alert message
现在，我们收到通知，其中一个 Pods 有问题，我们应该去普罗米修斯，挖掘数据，直到我们找到问题的原因，并修复它。但是，由于我们已经知道问题是什么(我们故意制造的)，我们将跳过所有这些，并删除有问题的 Pod，然后再进入下一个主题。
```
 1  kubectl delete pod problem
```
# 升级旧豆荚
我们的主要目标应该是通过主动预防问题的发生。在我们无法预测问题即将出现的情况下，我们至少必须迅速采取反应行动，在问题发生后缓解问题。尽管如此，还有第三类人只能被笼统地描述为积极主动。我们应该保持我们的系统干净和最新。
我们可以做很多事情来保持系统最新，其中之一就是确保我们的软件相对较新(打补丁、更新等等)。一个合理的规则可能是尝试在 90 天后更新软件，如果不是更早的话。这并不意味着我们在集群中运行的所有东西都应该比 90 天更新，但这可能是一个很好的起点。此外，我们可能会创建更好的策略，允许某些类型的应用(通常是第三方)在半年内不升级。其他软件，尤其是我们正在积极开发的软件，可能会更频繁地升级。尽管如此，我们的出发点是检测所有未在 90 天或更长时间内升级的应用。
正如本章几乎所有其他练习一样，我们将从打开普罗米修斯的图形屏幕开始，并探索可能有助于我们实现目标的指标。
```
 1  open "http://$PROM_ADDR/graph"
```
如果我们检查可用的指标，我们会看到有`kube_pod_start_time`。它的名字清楚地表明了它的目的。它以仪表的形式提供了代表每个 Pod 开始时间的 Unix 时间戳。让我们看看它在行动。
请键入以下表达式，然后单击“执行”按钮。
```
 1  kube_pod_start_time
```
这些值本身是没有用的，也没有必要教你如何根据这些值计算人类的日期。重要的是现在和那些时间戳的区别。
![](img/d9204c74-681c-4097-8ce8-b76c8b78b6ab.png)
Figure 3-37: Prometheus' console view with the start time of the Pods
我们可以使用普罗米修斯的`time()`函数返回自 1970 年 1 月 1 日起的秒数(UTC 或 Unix 时间戳)。
请键入以下表达式，然后单击“执行”按钮。
```
 1  time()
```
就像`kube_pod_start_time`一样，我们得到了一个代表 1970 年以来秒数的长数字。除了值之外，唯一值得注意的区别是只有一个条目，而通过`kube_pod_start_time`我们得到了集群中每个 Pod 的结果。
现在，让我们结合这两个指标来尝试检索每个 Pods 的年龄。
请键入以下表达式，然后单击“执行”按钮。
```
 1  time() -
 2  kube_pod_start_time
```
结果是这一次更小的数字代表从现在到每一个豆荚创造之间的秒。在我的例子中(截图如下)，第一个 Pod(其中一个`go-demo-5`副本)的历史略超过 6000 秒。这大约需要一百分钟(6096 / 60)，或者不到两个小时(100 分钟/ 60 分钟= 1.666 小时)。
![](img/d38868b1-8abb-4ad3-aab7-915d496b32bc.png)
Figure 3-38: Prometheus' console view with the time passed since the creation of the Pods
由于可能没有比我们 90 天的目标更早的吊舱，我们将暂时将其降低到一分钟(60 秒)。
请键入以下表达式，然后单击“执行”按钮。
```
 1  (
 2    time() -
 3    kube_pod_start_time{
 4      namespace!="kube-system"
 5    }
 6  ) > 60
```
在我的例子中，所有的豆荚都超过一分钟(可能你的也是)。我们确认它有效，因此我们可以将阈值提高到 90 天。要达到 90 天，我们应该将阈值乘以 60 得到分钟，再乘以 60 得到小时，乘以 24 得到天，最后乘以 90。公式是`60 * 60 * 24 * 90`。我们可以使用`7776000`的最终值，但这将使查询更难破译。我更喜欢用公式来代替。
请键入以下表达式，然后单击“执行”按钮。
```
 1  (
 2    time() -
 3    kube_pod_start_time{
 4      namespace!="kube-system"
 5    }
 6  ) >
 7  (60 * 60 * 24 * 90)
```
没有(可能)结果应该不足为奇。如果你为这一章创建了一个新的集群，你需要成为地球上最慢的读者，如果你花了 90 天到达这里。这可能是我迄今为止写的最长的一章，但仍然不值得读 90 天。
现在我们知道使用哪个表达式了，我们可以在设置中再添加一个警报。
```
 1  diff mon/prom-values-phase.yml \
 2      mon/prom-values-old-pods.yml
```
输出如下。
```
146a147,154
> - alert: OldPods
>   expr: (time() - kube_pod_start_time{namespace!="kube-system"}) > 60
>   labels:
>     severity: notify
>     frequency: low
>   annotations:
>     summary: Old Pods
>     description: At least one Pod has not been updated to more than 90 days
```
我们可以看到新旧值的区别在`OldPods`警戒。它包含了我们刚才使用的同一个表达。
我们保持`60`秒的低阈值，这样我们就可以看到警报在起作用。稍后，我们会将该值增加到 90 天。
没有必要指定`for`持续时间。一旦其中一个豆荚的年龄达到三个月，警报就会响起。
让我们用更新的值升级我们的普罗米修斯图表，并打开松弛通道，在那里我们应该会看到新的消息。
```
 1  helm upgrade -i prometheus \
 2    stable/prometheus \
 3    --namespace metrics \