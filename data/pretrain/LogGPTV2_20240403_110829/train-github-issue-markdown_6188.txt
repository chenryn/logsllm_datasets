`CartesianIndices` seems to enforce `Int` even if the arguments are of a
different type; e.g.,
    x = Int32(3)
    @show typeof(-x:x)
    # =>  UnitRange{Int32}
    c = CartesianIndices((-x:x, -x:x))
    @show typeof(c.indices[1]) 
    # => UnitRange{Int64}
This is very bad for writing type-stable code that uses an integer type other
than `Int`.
`versioninfo()` ->
    Julia Version 1.1.0
    Commit 80516ca202* (2019-01-21 21:24 UTC)
    Platform Info:
      OS: macOS (x86_64-apple-darwin18.2.0)
      CPU: Intel(R) Core(TM) i7-7820HQ CPU @ 2.90GHz
      WORD_SIZE: 64
      LIBM: libopenlibm
      LLVM: libLLVM-6.0.1 (ORCJIT, skylake)
    Environment:
      JULIA_NUM_THREADS = 1