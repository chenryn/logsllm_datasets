title:Automated Web Patrol with Strider HoneyMonkeys: Finding Web Sites
That Exploit Browser Vulnerabilities
author:Yi-Min Wang and
Doug Beck and
Xuxian Jiang and
Roussi Roussev and
Chad Verbowski and
Shuo Chen and
Samuel T. King
Automated Web Patrol with Strider HoneyMonkeys:  
Finding Web Sites That Exploit Browser Vulnerabilities 
Yi-Min Wang, Doug Beck, Xuxian Jiang, Roussi Roussev, 
Chad Verbowski, Shuo Chen, and Sam King 
Microsoft Research, Redmond 
Abstract 
Internet attacks that use malicious web sites to install 
malware  programs  by  exploiting  browser  vulnerabilities 
are  a  serious  emerging  threat.  In  response,  we  have 
developed  an  automated  web  patrol 
to 
automatically  identify  and  monitor  these  malicious  sites. 
We describe the design and implementation of the Strider 
HoneyMonkey Exploit Detection System, which consists of 
a  pipeline  of  “monkey  programs”  running  possibly 
vulnerable  browsers  on  virtual  machines  with  different 
patch  levels  and  patrolling  the  Web  to  seek  out  and 
classify web sites that exploit browser vulnerabilities. 
system 
Within  the  first  month  of  utilizing  this  system,  we 
identified 752 unique URLs hosted on 288 web sites that 
could  successfully  exploit  unpatched  Windows  XP 
machines. The system automatically constructed topology 
graphs  based  on  traffic  redirection  to  capture  the 
relationship between the exploit sites. This allowed us to 
identify  several  major  players  who  are  responsible  for  a 
large  number  of  exploit  pages.  By  monitoring  these  752 
exploit-URLs on a daily basis, we discovered a malicious 
web  site  that  was  performing  zero-day  exploits  of  the 
unpatched  javaprxy.dll  vulnerability  and  was  operating 
behind 25 exploit-URLs. It was confirmed as the first “in-
the-wild”,  zero-day  exploit  of  this  vulnerability  that  was 
reported  to  the  Microsoft  Security  Response  Center. 
Additionally,  by  scanning  the  most  popular  one  million 
URLs  as  classified  by  a  search  engine,  we  found  over 
seven hundred exploit-URLs, many of which serve popular 
content  related  to  celebrities,  song  lyrics,  wallpapers, 
video game cheats, and wrestling. 
1.  Introduction 
in 
the  past  12  months 
Internet  attacks  that  use  a  malicious  or  hacked  web 
site  to  exploit  unpatched  client-side  vulnerabilities  of 
visiting  browsers  are  on  the rise.  Malcode  distributed  by 
this  method 
the 
Download.Ject [D04], Bofra [R04], and Xpire.info [B04] 
programs.  These  attacks  allow  web  servers  that  host 
compromised  URLs  to  install  malcode  on  visiting  client 
machines  without  requiring  any  user  interaction  beyond 
visitation.  There  have  been  several  manual  analyses  of 
these  events  [E04,F04,G05,IF05,R05,S05,T05].  Although 
includes 
these  analyses  provide  very  useful  and  detailed 
information about which vulnerabilities are exploited and 
which malware programs are installed, such efforts are not 
scalable,  do  not  provide  a  comprehensive  picture  of  the 
problem,  and  are  generally  ineffective  at  efficiently 
finding new malicious sites. 
called 
[H,HC], 
honeypots 
To address these issues,  we developed a system that 
uses  a  pipeline  of  active,  client-side,  Virtual  Machine 
(VM)-based 
Strider 
HoneyMonkeys,  to  perform  large-scale,  systematic  and 
automated  web  patrol.  The  HoneyMonkey  system  uses 
monkey  programs1  that run  within  virtual machines  with 
OS’s of various patch levels to drive web browsers in an 
attempt  to  mimic  human  web  browsing.  Our  approach 
adopts a state-management methodology to cybersecurity: 
instead  of  directly  detecting  the  acts  of  vulnerability 
exploits, the system uses the Strider Tracer [W03] to catch 
unauthorized file creations and configuration changes that 
are the result of a successful exploit. 
We  demonstrate  the  effectiveness  of  our  method  by 
discovering a large community of malicious web sites that 
host  exploit  pages  and  by  deriving  the  redirection 
relationships  among  them.  We  describe  a  real-world 
experience with identifying a zero-day exploit2 using this 
system. We show the existence of hundreds of malicious 
web  pages  amongst  many  popular  web  sites.  Finally,  we 
propose  a  comprehensive  anti-exploit  process  based  on 
this monitoring system in order to improve Internet safety. 
information  on 
This paper is organized as follows. Section 2 provides 
background 
the  problem  space  by 
describing  the  techniques  used  in  actual  client-side 
exploits  of  popular  web  browsers.  Section  3  gives  an 
overview  of  the  Strider  HoneyMonkey Exploit Detection 
System and its surrounding Anti-Exploit Process. Section 
1 An automation-enabled program such as the Internet Explorer 
browser  allows  programmatic  access  to  most  of  the  operations 
that can be invoked by a user. A “monkey program” is a program 
that  drives  the  browser  in  a  way  that  mimics  a  human  user’s 
operation. 
2 In this paper, a zero-day exploit refers to a vulnerability exploit 
that exists before the patch for the vulnerability is released. The 
vulnerability  can  be  known  or  unknown  to  the  public  at  that 
time. 
4  evaluates  the  effectiveness  of  HoneyMonkey  in  both 
known-vulnerability  and  zero-day  exploit  detection,  and 
presents  an analysis  of  the  exploit  data to  help  prioritize 
investigation tasks. Section 5 discusses the limitations of 
and possible attacks on the current HoneyMonkey system 
and  describes  several  countermeasures 
including  an 
enhancement  based  on  a  vulnerability-specific  exploit 
detection mechanism. Section 6 surveys related work and 
Section 7 concludes the paper.  
2.  Browser-based Vulnerability Exploits  
Malicious  activities  performed  by  actual  web  sites 
exploiting browser vulnerabilities can be divided into four 
steps:  code  obfuscation,  URL  redirection,  vulnerability 
exploitation, and malware installation. 
2.1.  Code Obfuscation 
To complicate investigation and to escape signature-
based scanning by anti-virus/anti-spyware software, some 
web  sites  use  a  combination  of  the  following  code 
obfuscation techniques: (1) dynamic code injection using 
the  document.write()  function 
inside  a  script;  (2) 
unreadable, long  strings  with  encoded  characters  such as 
“%28”,  “&#104”,  etc.  which  are  then  decoded  either  by 
the unescape() function inside a script or by the browser; 
(3) custom decoding routine included in a script; and (4) 
sub-string replacement using the replace() function. Since 
code-obfuscation  is  a  common  technique,  this  limits  the 
ability  of  attack-signature-based  detectors  to  detect  new 
attacks that leverage old exploit code. 
2.2.  URL Redirection 
typically  use  one  of  the  following mechanisms  classified 
into three categories: (1) protocol redirection using HTTP 
302  Temporary  Redirect;  (2)  HTML  tags  including 
,    inside  ,  and  ;  (3)  script  functions 
including 
window.location.href(), 
window.location.replace(), 
window.open(),  window.showModalDialog(), 
and 
.click(),  etc.  Since  redirection  is  commonly 
used  by  non-malicious  sites  to  enrich  content,  simply 
eliminating  redirection  from  a  browser  would  present 
significant complications 
2.3.  Vulnerability Exploitation 
It  is  not  uncommon  to  see  a  malicious  web  page 
attempting  to  exploit  multiple  browser  vulnerabilities  in 
order  to  maximize  the  chance  of  a  successful  attack. 
Figure  1  shows  an  example  HTML  fragment  that  uses 
various  primitives  to  load  multiple  files  from  different 
URLs  on  the  same  server  to  exploit  three  vulnerabilities 
fixed  in  Microsoft  Security  Bulletins  MS05-002  [M52], 
MS03-011 [M311], and MS04-013 [M413]. If any of the 
exploits succeeds, a Trojan downloader named win32.exe 
is  downloaded  and  executed.  Note  that  although  Internet 
Explorer is the common target due to its popularity, other 
browsers can also be attacked. 
2.4.  Malware Installation 
The  purpose  of  an  exploit  is  almost  always  to 
introduce  some  piece  of  arbitrary  code  on  the  victim 
machine,  as  a  way  to  achieve  a  larger  attack  goal.  We 
have  observed  a  plethora  of  malcode  types  installed 
through  browser  exploits,  including  viruses  that  infect 
files,  backdoors 
that  open  entry  points  for  future 
unauthorized access, bot programs that allow the attacker 
to  control  a  whole  network  of  compromised  systems, 
Trojan  downloaders  that  connect  to  the  Internet  and 
download other programs, Trojan droppers that drop files 
from  themselves  without  accessing  the  Internet,  and 
Trojan proxies that redirect network traffic. Some spyware 
Most  malicious  web  sites  automatically  redirect 
browser  traffic  to  additional  URLs.  Specifically,  when  a 
browser  visits  a  primary  URL,  the  response  from  that 
URL  instructs  the  browser  to  automatically  visit  one  or 
more secondary  URLs,  which may  or may not affect the 
content  that  is  displayed  to  the  user.  Such  redirections 
try{ 
document.write(''); 
}catch(e){} 
MS05-002 
MS04-013 
MS03-011 
Figure 1. Actual sample Web page attempting to exploit multiple vulnerabilities 
programs  and  even  anti-spyware  programs  are  also 
installed through exploits. 
3.  The HoneyMonkey System 
The HoneyMonkey system attempts to automatically 
detect and analyze a network of web sites that exploit web 
browsers.  Figure  2  illustrates  the  HoneyMonkey  Exploit 
Detection System, shown inside the dotted square, and the 
surrounding  Anti-Exploit  Process  which  includes  both 
automatic and manual components.  
3.1.  Exploit Detection System 
The  exploit  detection  system  is  the  heart  of  the 
HoneyMonkeys design.  This system consists of a 3-stage 
pipeline  of  virtual  machines.  Given  a  large  list  of  input 
URLs  with  a  potentially  low  exploit-URL  density,  each 
HoneyMonkey in Stage 1 starts with a scalable mode by 
visiting  N  URLs  simultaneously  inside  one  unpatched 
VM.  When  the  HoneyMonkey  detects  an  exploit,  it 
switches  to  the  basic,  one-URL-per-VM  mode  to  re-test 
each  of  the N  suspects  in  order to  determine  which  ones 
are exploit URLs. 
Stage-2  HoneyMonkeys  scan  Stage  1  detected 
exploit-URLs  and  perform  recursive  redirection  analysis 
to identify all web pages involved in exploit activities and 
to  determine  their  relationships.  Stage-3  HoneyMonkeys 
continuously  scan  Stage-2  detected  exploit-URLs  using 
(nearly)  fully  patched  VMs  in  order  to  detect  attacks 
exploiting the latest vulnerabilities. 
We  used  a  network  of  20  machines  to  produce  the 
results  reported  in  this  paper.  Each  machine  had  a  CPU 
speed  between 1.7 and 3.2 GHz, a memory size  between 
512  MB  and  2GB,  and  was  responsible  for  running  one 
VM  configured  with  256  MB  to  512MB  of  RAM.  Each 
VM supported up to 10 simultaneous browser processes in 
the  scalable  mode,  with  each  process  visiting  a  different 
URL.  Due  to  the  way  HoneyMonkeys  detect  exploits 
(discussed later), there is a trade-off between the scan rate 
and 
the 
HoneyMonkey does not wait long enough or if too many 
simultaneous 
excessive 
slowdown, some exploit pages may not be able to perform 
a  detectable  attack 
software 
installation). 
robustness  of  exploit  detection: 
(e.g.,  beginning  a 
processes 
the 
browser 
cause 
if 
Through extensive experiments, we determined that a 
wait  time  of  two  minutes  was  a  good  trade-off.  Taking 
into  account  the  overhead  of  restarting  VMs  in  a  clean 
state, each machine was able to scan and analyze between 
3,000 to 4,000 URLs per day. We have since improved the 
scalability of the system to a scan rate of 8,000 URLs per 
day  per  machine  in  the  scalable  mode.  (In  contrast,  the 
basic mode scans between 500 and 700 URLs per day per 
machine.) We expect that using a more sophisticated VM 
platform  that  enables  significantly  more  VMs  per  host 
machine 
[VMC+05]  would 
significantly increase our scalability.     
3.1.1. Exploit Detection 
rollback 
faster 
and 
Although it is possible to detect  browser exploits by 
building  signature-based  detection  code  for  each  known 
vulnerability  or  exploit, 
is  manually 
intensive. To lower this cost, we take the following black-
this  approach 
List of “interesting URLs” 
Depth-N crawling 
of given URL 
Stage 1: Scalable HoneyMonkey exploit 
detection with unpatched virtual 
machines without redirection analysis 
Stage 2: Basic HoneyMonkey exploit 
detection with unpatched virtual 
machines with redirection analysis 
Redirect 
URLs 
Stage 3: Basic HoneyMonkey exploit 
detection with (nearly) fully patched 
virtual machines with redirection analysis 
HoneyMonkey Exploit Detection System 
Analysis of exploit URL density 
Exploit URLs 
Fix compromised machines 
Topology graph 
of exploit URLs 
Topology graphs 
of zero-day or 
latest-patched- 
vulnerability  
exploit URLs 
Internet safety enforcement team 
Access blocking 
Anti-spyware team  
Security response center 
Browser and other related teams 
Figure 2. HoneyMonkey Exploit Detection System and Anti-Exploit Process 
box,  non-signature-based  approach:  we  run  a  monkey 
program  that  launches  a  browser  instance  to  visit  each 
input  URL  and  then  waits  for  a  few  minutes  to  allow 
downloading  of  any  code  which  may  have  a  short  time 
delay. We then detect a group of persistent-state changes 
to signal exploitation. Since the monkey is not instructed 
to click on any dialog box to permit software installation, 
any executable files or registry entries created outside the 
browser  sandbox  indicate  an  exploit.  This  approach  has 
the  additional  important  advantage  of  allowing 
the 
detection  of  known-vulnerability  exploits  and  zero-day 
exploits in a uniform way. Specifically, the same monkey 
program running on unpatched machines to detect a broad 
range of browser-based vulnerability exploits (as shown in 
Stages  1  and  2)  can  run  on  fully  patched  machines  to 
detect zero-day exploits, as shown in Stage 3. 
At the end of each visit, the HoneyMonkey generates 