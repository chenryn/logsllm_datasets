We can generalize this approach to leaking multiple key
bits by having the attacker interrupt/resume the victim using
preemptive scheduling techniques [2, 10, 17, 25, 26, 40, 41,
70, 74, 83, 100, 112]. Let TE1 be the median time that the
victim takes to execute E1 starting from a cold cache and
TE1+E2 be the median time that the victim takes to execute
E1 followed by E2 starting from a cold cache. The complete
attack works as follows: the attacker starts the victim and lets
it run for TE1+E2 cycles while concurrently monitoring the
ring interconnect. After TE1+E2 cycles, the attacker interrupts
the victim and analyzes the collected trace to infer the ﬁrst
secret bit with the technique described above. Interrupting
the victim causes a context switch during which the victim’s
cache is cleansed before yielding control to the attacker (cf.
Threat Model). As a side effect, this brings the victim back
to a cold cache state. If the trace reveals that the ﬁrst secret
bit was 1, the attacker resumes the victim (that is now at the
beginning of the second iteration) and lets it run for TE1+E2
more cycles, repeating the above procedure to leak the second
bit. If the trace reveals that the ﬁrst secret bit was 0, the
attacker stops the victim (or it lets it ﬁnish the current run),
starts it again from the beginning, lets it run for TE1 cycles,
and then interrupts it. The victim will now be at the beginning
of the second iteration, and the attacker can repeat the above
procedure to leak the second bit. The attacker repeats this
operation until all the key bits are leaked. In the worst case, if
all the key bits are zeros, our attack requires as many runs of
the victim as the number of bits of the key. In the best case, if
all the key bits are ones, it requires only one run of the victim.
Implementation We implement a proof-of-concept (POC)
of our attack against RSA and EdDSA. Like prior work [2, 5,
17,25,26,40,100], our POC simulates the preemptive schedul-
ing attack by allowing the attacker to be synchronized with
the target iteration of the victim’s loop.7 Further, our POC
simulates cache cleansing by ﬂushing the victim’s memory
before executing the target iteration. It does this by calling
clflush on each cache line making up the victim’s mapped
pages (available in /proc/[pid]/maps).8 Our POC consid-
ers the worst-case scenario described above and leaks one key
bit per run of the victim. To simplify the process of inferring
a key bit from each resulting trace, our POC uses a Support
Vector Machine classiﬁer (SVC). Note that while the RSA
and EdDSA implementations we consider are already known
to be vulnerable to side channels, we are the ﬁrst to show that
they leak over the ring interconnect channel speciﬁcally.
Results for RSA We target the RSA decryption code
of libgcrypt 1.5.2 which uses the secret-dependent square-
and-multiply method in its modular exponentiation function
_gcry_mpi_powm. This pattern matches the one of Algo-
rithm 1, with E1 representing the squaring phase, executed
unconditionally, and E2 representing the multiplication phase,
executed conditionally only on 1-valued bits of the key.
We conﬁgure the attacker (receiver) on core Rc = 2, tim-
ing loads from Rs = 1, and experiment with different victim
(sender) cores Sc. Figure 7a shows traces collected by the at-
tacker to leak one key bit of the victim, when Sc = 5. To better
visualize the difference between a 0 bit and a 1 bit, the traces
are averaged over 100 runs of the victim.11 As expected, we
observe that both traces start with peaks, corresponding to
the ﬁrst call to E1 loading its code and data words from the
7Practical implementations of preemptive scheduling techniques (e.g., [10,
41, 70, 83]) are orthogonal to this paper and discussed in Section 6.
8We consider other cache cleansing approaches in the extended ver-
sion [81], and discuss the implications of this requirement in Section 6.
11Note that, however, our classiﬁer uses a single raw trace as input.
USENIX Association
30th USENIX Security Symposium    655
(a) Results for the RSA victim. When bit = 1, the attacker sees an
additional contention peak between samples 20 and 40.9
(b) Results for the EdDSA victim. When bit = 1, the attacker sees
an additional peak after the 100-th sample.10
Figure 7: Latencies measured by the attacker during a victim’s
iteration, with Rc = 2, Rs = 1, and Sc = 5 (on Coffee Lake).
memory controller through the ring interconnect. However,
only when the secret bit is 1 do we observe an additional
peak on the right-hand side of the plot. This additional peak
corresponds to the call to E2. We get equally distinguishable
patterns when we run the victim on other cores, as well as on
our Skylake machine (see the extended version [81]).
To train our classiﬁer, we collect a set of 5000 traces, half
of which with the victim operating on a 0 bit and the other
half with it operating on a 1 bit. We use the ﬁrst 43 samples
from each trace as input vectors, and the respective 0 or 1 bits
as labels. We then randomly split the set of vectors into 75%
training set and 25% testing set, and train our classiﬁer to dis-
tinguish between the two classes. Our classiﬁer achieves an
accuracy of 90% with prefetchers on and 86% with prefetch-
ers off, demonstrating that a single trace of load latencies
measured by the attacker during a victim’s iteration can leak
that iteration’s secret key bit with high accuracy.
Results for EdDSA We target the EdDSA Curve25519
signing code of libgcrypt 1.6.3, which includes a secret-
dependent code path in its elliptic curve point-scalar multipli-
cation function _gcry_mpi_ec_mul_point. In this function,
the doubling phase represents E1, executed unconditionally,
and the addition phase represents E2, executed conditionally
only on 1-valued bits of the key (i.e., the scalar).
We report in Figure 7b the results of leaking a bit using the
same setup as in the RSA attack. Both traces start with peaks
10When bit = 1 an RSA victim’s iteration lasts TE1+E2 = 11,230 cycles,
that allow the attacker to collect ∼51 samples. When bit = 0, it lasts TE1 =
5,690 cycles and is followed by an interval of no contention (second call to
E1); the sum of these intervals allows the attacker to collect ∼43 samples.
To better compare the two traces, we cut both of them at 43 samples.
11Iterations of the EdDSA victim (TE1+E2 = 35,120 cycles and TE1 =
18,260 cycles) take longer than the ones of the RSA victim. Hence, the
attacker is able to collect a larger number of samples.
Figure 8: Load latency measured by the attacker when a
user types password123 on the terminal, with Rc = 3 and
Rs = 2 (on Coffee Lake). Latency spikes occur reliably upon
keystroke processing (yellow bars) and can be used to extract
inter-keystroke timings. See Figure 10a for a zoomed-in plot.
corresponding to the ﬁrst call to E1. However, only when the
secret bit is 1 do we observe an additional peak on the right-
hand side of the plot. This additional peak corresponds to the
call to E2. We get similar patterns with the victim on other
cores, as well as on Skylake (see the extended version [81]).
We train our classiﬁer like we did for the RSA attack, except
that the individual vectors now contain 140 samples. Our
classiﬁer achieves an accuracy of 94% with prefetchers on
and 90% with prefetchers off.
5.2 Keystroke Timing Attacks
Our second side channel attack leaks the timing of keystrokes
typed by a user. That is, like prior work [38, 49, 56, 58, 79, 82,
98, 111], the goal of the attacker is to detect when keystrokes
occur and extract precise inter-keystroke timings. This infor-
mation is sensitive because it can be used to reconstruct typed
words (e.g., passwords) [56, 88, 111]. To our knowledge, this
is the ﬁrst time a contention-based microarchitectural channel
(cf. Section 2.1) has been used for keystroke timing attacks.
Our attack builds on the observation that handling a
keystroke is an involved process that requires interaction
of multiple layers of the hardware and software stack, in-
cluding the southbridge, various CPU components, kernel
drivers, character devices, shared libraries, and user space pro-
cesses [8,29,52,68,80,85]. Prior work has shown that terminal
emulators alone incur keystroke processing latencies that are
in the order of milliseconds [13, 63] (i.e., millions of cycles).
Moreover, handling even a single keystroke involves execut-
ing and accessing large amounts of code and data [85]. Thus,
we hypothesize that, on an otherwise idle server, keystroke
processing may cause detectable peaks in ring contention.
Implementation To validate our hypothesis, we develop a
simple console application that calls getchar() in a loop
and records the time when each key press occurs, to serve as
the ground truth (as in [111]). We consider two scenarios: i)
typing on a local terminal (with physical keyboard input [29,
80]), and ii) typing over an interactive SSH session (with
remote input [12, 52]).
Results Figure 8 shows a trace collected by the attacker
on our Coffee Lake machine in the SSH typing scenario,
656    30th USENIX Security Symposium
USENIX Association
E2E1E1E2E1E1E1E10123456Time (cycles)1e9162164166168Load latency (cycles)password123moving average 3000after applying a moving average with a window of 3000 sam-
ples. We report a zoomed-in version of the trace for a single
keystroke in Figure 10a. Our ﬁrst observation is that when a
keystroke occurs, we observe a very distinguishable pattern
of ring contention. Running our attack while typing the ﬁrst
100 characters of the “To be, or not to be” soliloquy, we ob-
served this pattern upon all keystroke events with zero false
negatives and zero false positives. Further, ring contention
peaks were always observed well within 1 ms (3× 106 cy-
cles) of recording a keystroke, which is the precision required
by the inference algorithms used by prior work to differenti-
ate the keys pressed. We got similar results when we typed
keystrokes on a local terminal as well as on Skylake (see the
extended version [81]). Moreover, we tested our attack while
running stress -m N in the background, which spawns N
threads generating synthetic memory load on the system. The
results, reported in Appendix A.3, show that the temporal
patterns of ring contention on keystrokes were still easily dis-
tinguishable from background noise when N ≤ 2. However,
as the load increased (with N > 2), keystrokes started to be-
come harder to identify by simply using the moving average
of Figure 8, and with N > 4, they started to become almost
entirely indistinguishable from background noise.
We believe that the latency peaks we observe on keystrokes
are caused by ring contention (and not, e.g., cache evictions
or interrupts) for several reasons. First, the latency differences
caused by contention on keystrokes are in the same range of
the ones we measured in Section 3. Second, we observed that,
although keystroke processing creates contention on all slices,
latency peaks are more pronounced when the attacker moni-
tors ring segments that incur more contention (i.e., the tables
with the most gray cells in Figures 3 and 11). For example,
when Rc = 0 and Rs = 7 the peaks upon keystrokes are smaller
than in most other conﬁgurations. This is because in this con-
ﬁguration the attacker always has priority on both the request
ring (there is no core upstream of Rc whose request trafﬁc can
delay Rc’s one) and the data/acknowledge rings (there is no
slice/SA upstream of Rs whose data/acknowledge trafﬁc can
delay Rs’s one). Hence, we believe the only contention that
occurs in this case is slice contention. Third, when we tried to
repeat our experiments with the attacker timing L1 hits instead
of LLC hits, we did not see latency peaks upon keystrokes.
6 Discussion and Future Work
Attack Requirements Our attack on cryptographic code
(cf. Section 5.1) requires the victim’s cache to be cleansed on
context switches. On the one hand, this requirement limits the
applicability of the attack, considering that cache cleansing is
not currently done by major OSs. On the other hand, however,
cache cleansing is often recommended [16, 30–32, 34, 40, 41,
74, 77, 89, 96, 114] as a defense against cache-based preemp-
tive scheduling attacks, and may be deployed in the future if
temporal isolation starts getting added to OSs. If so, defenders
would be in a lose-lose situation: either they i) do not cleanse
and get attacked through preemptive scheduling attacks or
ii) cleanse and get attacked through our attack. These results
highlight that side channel mitigations still need more study.
Moreover, our attack POC assumes (like prior work [2, 5,
17, 25, 26, 40, 74, 100]) the availability of preemptive schedul-
ing techniques. A real attack, however, would include an im-
plementation of such techniques. High-precision variants of
these have been demonstrated for non-virtualized settings in
[10,41,70,83], and shown to be practical in virtualized settings
in [112].12 Preemptive scheduling is also practical against
trusted execution environments such as Intel SGX [95]. Yet,
future work is needed to assess the practicality of preemptive
scheduling in more restricted environments such as browsers.
Mitigations
Intel classiﬁes our attack as a “traditional side
channel” because it takes advantage of architecturally commit-
ted operations [44]. The recommended line of defense against
this class of attacks is to rely on software mitigations, and par-
ticularly on following constant-time programming principles.
The attacks we demonstrate on RSA and EdDSA rely on code
that is not constant time; in principle, this mitigation should be
effective in blocking them. However, a more comprehensive
understanding of hardware optimizations is needed before
we can have truly constant-time code. For example, it was
recently reported that Intel CPUs perform hardware store elim-
ination between the private caches and ring interconnect [22].
This optimization may break constant-time programming by
making ring contention a function of cache line contents.
Further, additional mitigations are needed to block our
covert channel and our keystroke timing attack. Among
hardware-only mitigations, designs based on spatial partition-
ing and statically-scheduled arbitration policies (e.g., [103])
could ensure that no ring contention can occur between pro-
cesses from different security domains. However, they would
need additional mechanisms to mitigate slice contention. Al-