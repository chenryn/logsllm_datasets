title:Efficient Multicast Packet Authentication Using Signature Amortization
author:Jung-Min Park and
Edwin K. P. Chong and
Howard Jay Siegel
Efficient Multicast Packet Authentication
Using Signature Amortization
                         Jung Min Park†                                     Edwin K. P. Chong‡§ and Howard Jay Siegel‡*
                                            †CERIAS                                   ‡Department of Electrical and Computer Engineering
†School of Electrical and Computer Engineering                    §Department of Mathematics
                      Purdue University                                         *Department of Computer Science
       West Lafayette, IN 47907-1285 USA                                   Colorado State University
                  PI:EMAIL                                   Fort Collins, CO 80523-1373 USA
                                                                                                  {echong, hj}@colostate.edu
Abstract
We  describe  a  novel  method  for  authenticating
multicast  packets  that  is  robust  against  packet  loss.  Our
main  focus  is  to  minimize  the  size  of  the  communication
overhead  required  to  authenticate  the  packets.  Our
approach is to encode the hash values and the signatures
with  Rabin’s  Information  Dispersal  Algorithm  (IDA)  to
construct  an  authentication  scheme  that  amortizes  a
single  signature  operation  over  multiple  packets.  This
strategy is especially efficient in terms of space overhead,
because 
for
authentication  (i.e.,  one  hash  per  packet  and  one
signature  per  group  of  packets)  are  used  in  conjunction
with  an  erasure  code  that  is  space  optimal.  To  evaluate
the  performance  of  our  scheme,  we  compare  our
technique  with  four  other  previously  proposed  schemes
using  analytical  and  empirical  results.  Two  different
bursty loss models are considered in the analyses.
the  essential  elements  needed 
just 
1. Introduction
for 
types 
of 
novel 
demand 
Fueled  by  the  explosive  growth  of  the  Internet  and
growing 
group
communications, multicast has received a lot of attention
in  recent  years.  In  multicast,  a  single  copy  of  packets  is
sent by the sender and routed to every receiver within the
multicast group via multicast-enabled routers. For a wide
range of applications, multicast is an efficient and natural
way  of  communicating  information.  Some  examples
include information broadcasts (e.g., news feeds, weather
updates, and stock quotes), multiparty videoconferencing,
This research was supported in part by the Center for Education and
Research  in  Information  Assurance  and  Security  (CERIAS),  by  the
Colorado  State  University  George  T.  Abell  Endowment,  and  by  NSF
under grants 0098089-ECS and 0099137-ANI.
Proceedings of the 2002 IEEE Symposium on Security and Privacy (S&P(cid:146)02) 
1081-6011/02 $17.00 ' 2002 IEEE 
and  software  updates.  For  successful  implementation,
many of these applications will require varying degrees of
security 
and
authentication).
confidentiality 
requirements 
(i.e., 
Confidentiality  for  multicast  transmissions  can  be
provided using techniques that  utilize  symmetric  (secret)
key  cryptography.  Confidentiality  would  be  provided  by
encrypting the  message  with the  secret  key  being  shared
by  the  sender  and  the  receivers  of  the  multicast  group
before transmission. Consequently, off-the-shelf solutions
such as the Advanced Encryption Standard (AES) can be
readily employed for this purpose. For confidentiality, the
main  concern 
in  key
management (e.g., key distribution, revocation, and group
updates).
the  complexity 
involved 
is 
The solution to the authentication problem for unicast
transmission  is  rather  simple  and  well  known  (e.g.,  the
use  of  Hash  based  Message  Authentication  Codes
(HMAC)).  However,  this  solution  is  inadequate  for  the
multicast setting. The difficulty of the problem lies in the
fact that preventing the forgery of packets by a colluding
group of receivers precludes the use of any symmetric key
cryptosystem that is efficient in terms of space overhead.
Without  using  symmetric  key  cryptosystems,  the  most
obvious  way  of  providing  authentication  is  to  sign  each
individual  packet  using  the  sender’s  digital  signature.
However,  the  computation  overhead  of  current  signature
schemes is too high to  make this practical.  According to
[17],  a  Pentium  II  300  MHz  machine  devoting  all  of  its
processor  time  can  only  generate  80  512-bit  RSA
signatures  and  verify  2000  signatures  per  second.  This
signature  operation  would  also  require  64  bytes  of
communication  overhead  per  packet.  Clearly, 
this
approach is not practical.
Packet loss is another important issue that needs to be
considered.  While  this  may  not  be  a  problem  for
applications  employing  reliable  transport  protocols  (e.g.,
TCP/IP),  it  is  a  serious  issue  for  multicast  applications
that  use  UDP  over  IP-Multicast.  Because  UDP  only
provides  best-effort  service,  when  UDP  packets  are  sent
across  multiple  administrative  boundaries  with  diverse
routing  topologies  and  conditions,  packet  loss  can  be
high. Therefore, while the content being broadcast might
be able to bear packet losses, the authenticity of it might
not  be  verifiable  by  the  receiver,  if  the  authentication
scheme  is  not  resistant  to  loss.  Current  techniques  for
reliable  multicast,  such  as  Scalable  Reliable  Multicast
(SRM)  [4]  and  Reliable  Adaptive  Multicast  Protocol
(RAMP)  [7],  are  complex  and  not  yet  standardized.
Considering  the  lack  of  any  standardized  techniques  for
reliable  multicast  transmission,  any  practical  multicast
authentication scheme should be robust against loss.
Our  approach  to  multicast  message  authentication  is
based  on  the  technique  of  signature  amortization,  i.e.,
amortizing  a  single  signing  operation  over  multiple
packets.  This  technique  greatly  improves  signing  and
verification  rates  compared  to  the  naïve  signature-per-
packet approach. To deal with packet loss, we employ an
erasure  code  to  encode  the  authentication  information.
Our  strategy  is  especially  efficient  in  terms  of  space
overhead,  because  just  the  essential  elements  needed  for
authentication (i.e., one hash per packet and one signature
per  block  of  packets)  are  used  in  conjunction  with  an
erasure  code  that  is  space  optimal.  According  to  our
simulation  results  (see  Subsection  5.2),  this  technique  is
highly 
loss  and  achieves  higher
authentication  probabilities  compared  with  previously
proposed 
same  amount  of
communication overhead).
robust  against 
schemes 
(given 
the 
the 
with 
along 
approach, 
In  the  next  section,  we  give  a  brief  overview  of  the
previous  work  done  in  multicast  message  authentication
and  a  brief  overview  of  erasure  codes.  The  rationale  for
our 
detailed
authentication/verification  procedure,  is  given  in  Section
3. In Section 4, we discuss the authentication probability
of our scheme using two different bursty loss models. For
one  of  the  loss  models,  we  derive  the  asymptotic
authentication  probability,  and  for  the  other  loss  model,
we  give  the  lower  bound.  In  Section  5,  we  evaluate  the
performance  of  our  technique,  comparing  it  with  four
other  previously  proposed  schemes.  Finally,  concluding
remarks are given in Section 6.
2. Background information
2.1. Related work
Multicast authentication is an active area of research,
and researchers have suggested many schemes, which can
be  divided  into  two  major  classes—computationally
secure 
secure
authentication.  Pioneering  research  on  unconditionally
secure authentication was done by Simmons [15] and later
and  unconditionally 
authentication 
Proceedings of the 2002 IEEE Symposium on Security and Privacy (S&P(cid:146)02) 
1081-6011/02 $17.00 ' 2002 IEEE 
extended to the multicast setting by Desmedt et al. [3]. As
the  name  suggests,  unconditionally  secure  authentication
provides  very  strong  security  guarantees,  but  is  less
practical  compared 
the  computationally  secure
techniques.  Our  focus  will  be  on  the  computationally
secure methods.
to 
}
K
,
,1
lK
R
=
{
K
two  approaches  can  be 
In  the  realm  of  computationally  secure  multicast
authentication, 
taken.  One
approach  is  to  use  MACs  based  on  symmetric  key
cryptography, and  the  other  approach  is  to  utilize  digital
signatures  based  on  asymmetric  key  cryptography.
Schemes based on MACs do not use any computationally
intensive  asymmetric  key  techniques.  A  variation  of  this
idea  was  proposed  in  [2].  The  basic  idea  is  to  use  l
different  keys  to  authenticate  every  message  with  l
different  MACs.  The  sender  knows  a  set  of  l   keys,
, and attaches to each packet  l  MACs—
R
each MAC computed with a different key. The message is
transmitted together with the concatenated string of MAC
values.  Each  recipient  u   knows  a  subset  of  the  keys
uR   with
Ru
probability 
,  independently  for  every  i   and  u .
uR   MAC
Using  these  keys,  each  recipient  computes 
uR  values match the
values for each packet. If all of the 
corresponding  MAC  values  transmitted  by  the  sender,
then the packet is verified as being authentic. Appropriate
choice of subsets 
uR  insures that with high probability no
coalition of up to  w  malicious users have knowledge of
all  the  keys  kept  by  another  user  within  the  multicast
group.  This  technique  is  applicable  in  situations  where
multicast  groups  are  small  and  collusions  can  be
controlled.
⊂ ,  where  every  key 
iK   is  included  in 
+w
/(1
)1
In  [11],  Perrig  et  al.  propose  a  scheme  based  on
MACs  that  requires  time  synchronization  between  the
sender and the receiver. In their solution, Timed Efficient
Stream  Loss-tolerant  Authentication  (TESLA),  a  MAC  is
embedded  in  each  packet  to  provide  authentication.  The
corresponding  MAC  keys  are  disclosed  to  the  receiver
after  a  time  delay.    The  delay  before  the  disclosure  is
chosen long enough so that they cannot be used to forge
packets.  Although  this  scheme  is  robust  against  packet
loss and scalable, it requires that the sender and receiver
synchronize  their  clocks  within  a  certain  margin.  In
settings where time synchronization is difficult to achieve,
TESLA might not work.
Boneh et al. [1], in their recent work, showed that one
cannot  build  an  efficient  (in  terms  of  communication
overhead)  collusion  resistant  multicast  authentication
scheme  without  relying  on  digital  signatures.  Many
schemes  based  on  asymmetric  key  cryptography  attempt
to  reduce  the  computation  and  communication  overhead
by  amortizing  a  single  signature  over  multiple  packets.
thus  make 
information  and 
Even if the computational load required for the signature
generation is amortized, the communication overhead can
be  significant  if  one  were  to  make  each  packet  carry  its
own  authentication 
it
individually  verifiable.  In  this  kind  of  a  scheme,  any
packet  that  is  received  can  be  verified.  This  is  the
approach  taken  by  Wong  and  Lam  [17].  They  employ
Merkle’s authentication trees [9] to reduce the size of the
authentication  information  and  sign  multicast  packets.
The underlying idea is to divide a stream into blocks and
amortize  a  single  signing  operation  over  a  block  of
packets.  Before  the  signing  operation,  an  authentication
tree is computed for each block. In an authentication tree:
•  Packet digests (or hashes) are the leaf nodes.
•  Other  nodes  of  the  tree  are  computed  as  message
digests of their children.
•  The root is the block digest, with the block signature
being the signature of the root.
the  blocks,  each  packet  carries 
Within 
its  own
authentication information consisting of the signed block
digest, the packet position in the block, and the siblings of
each node in  the  path  of  the  packet’s  corresponding  leaf
node to the root. To verify a packet, the receiver needs to
verify  the  packet’s  path  to  the  root  and  compare  the
computed  block  signature  with  the  received  one.  This
technique  improves  signing  and  verification  rates  by  an
order of  magnitude compared to the naïve  signature-per-
packet  approach.  Although  this  method  has  its  own
merits,  it  also  has  practical  limitations.  Because  it  is
individually  verifiable,  each  packet  needs  to  contain  a
signature with all the nodes necessary to compute the root
signature,  which 
large  communication
overhead. In practice, this scheme adds over 200 bytes to
each  packet  (assuming  a  1024-bit  RSA  signature  and  a
block size of 16 packets).
requires  a 
If  the  condition  on  individual  packet  verification  is
relaxed so that the verification of a packet is dependent on
other  packets  within  the  block,  then  the  communication
overhead can be reduced substantially. In this type of an
approach,  verification  of  each  packet  is  not  guaranteed
and instead is assured with a certain probability. Perrig et
al.  [11]  take  this  probabilistic  approach  and  use  a
combination  of  hash  functions  and  digital  signatures  to
authenticate  packets.  Their  scheme,  EMSS  (Efficient
Multi-chained  Stream  Signature),  is  an  extension  of
Gennaro and Rohatgi’s stream signing technique [5]. The
basic idea is as follows: A hash of packet 
1P  is appended
to packet 
3P . If a
signature  packet,  containing  the  hash  of  the  final  data
packet (i.e., 
3P ,
then non-repudiation is achieved  for all three packets. In
essence, hash values act as chains between the packets so
that  they  form  a  single  string  that  can  be  signed  by  one
digital  signature.  However,  this  basic  approach  is  not
3P ) along with a signature, is sent after 
2P , whose hash is in turn appended to 
Proceedings of the 2002 IEEE Symposium on Security and Privacy (S&P(cid:146)02) 
1081-6011/02 $17.00 ' 2002 IEEE 
),
(
−
j
,
(
−
ik
K),
PH
k
ik P
P
−
k
kP   would  include  hashes 
K,
robust  against  packet  loss—even  a  single  packet  loss
would break the chain, which would make it impossible to
verify the authenticity of the packets preceding the break
point.  EMSS  overcomes  this  drawback  by  storing  the
hash  of  each  packet  in  multiple  locations  and  appending
multiple hashes in the signature packet. For example, each
packet 
  of
PH
.  The  signature  packet,
the  previous  packets 
which contains the hashes of the final few packets along
with  a  signature,  is  sent  at  the  end  of  the  stream  to
authenticate  all  the  packets.  Tolerance  to  loss  can  be
increased  further  by  sending  multiple  copies  of  a
signature  packet—copies  would  be  sent  with  delayed
intervals, because packet loss is correlated. To reduce the
verification delay at the receiver side, a stream of packets
is  divided  into  blocks,  and  the  same  process  is  repeated
for every block, i.e., all the data packets within the block
are chained with multiple hashes followed by an insertion
of one or more signature packets.
−
j
Pk
Mk
H(Pk-1)
H(Pk-2)
Pk+2
Mk
H(Pk+1)
H(Pk)
Pk+1
Mk
H(Pk)
H(Pk-1)
signature
packet
H(Pk+1)
H(Pk+2)
signature
Figure 1. An example of EMSS.
iP   to 
iP  has  been  appended  to  packet 
A  simplified  example  is  shown  in  Figure  1,  where
each packet contains hashes of the previous two packets,
and the signature packet contains hash values of the final
two  packets  along  with  a  signature.  In  the  figure,  a
directed  edge  from 
jP   indicates  that  the  hash  of
packet 
jP .  The  authors
suggest  using  random  edge  distributions  to  improve
performance, 
are
correlated. EMSS tolerates packet loss with relatively low
overhead at the cost of delayed verification. However, as
we will see in Section 5.2, to maintain a high verification
probability in a high-loss environment, its communication
overhead must be increased considerably. Throughout the
paper,  we  will  use  the  term  verification  probability
interchangeably  with  fraction  of  verifiable  packets  to
especially  when  packet 
losses 
denote  the  number  of  verifiable  packets  of  the  stream
divided by the number of received packets of the stream.
In  [6],  Golle  and  Modadugu  propose  a  similar
scheme  called  the  augmented  chain  technique.  They
propose  a  systematic  method  of  inserting  hashes  in
strategic locations so that the chain of packets formed by
the  hashes  will  be  optimally  resistant  to  bursty  packet
loss,  given  certain  constraints.  There  are  two  basic
differences between this scheme and EMSS:
•  In  the  augmented  chain  technique,  each  packet
includes the hashes of the subsequent packets as well
as  the  previous  packets  (i.e.,  leftward  and  rightward
edges).
•  EMSS  stores  the  hashes  in  random  locations,  while
in  a
locations 
these 
augmented  chain  chooses 
deterministic way.
1+iP  and 
The chain of packets constructed by the augmented chain
method is parameterized by the integer variables a and p.
The augmented chain is constructed in two phases. In the
first  phase,  a  chain  is  formed  among  a  subset  of  the
packets as follows: the hash of packet 
iP  is appended to
two other packets 
aiP+ . In the second phase, the
1−p
rest  of  the  packets  are  inserted.  Specifically, 
additional  packets  are  inserted  between  each  pair  of
consecutive  packets  of  the  original  chain  (constructed  in
the first phase) and connected in a systematic  way using
directed edges. The authors propose two ways of inserting
new  packets,  which  are  equally  robust  to  packet  loss.  A
chain constructed in this  manner can sustain a  burst  loss
of  up  to 
  packets  in  length.  To  reduce  the
verification  delay,  a  stream  is  divided  into  blocks  of
packets,  and  each  block 
the
augmented  chain  technique  with  only  the  last  packet  in
the block being signed. The interested reader should refer
to [6] for further details.
is  constructed  using 
( −ap
)1
A  simple  example  of  an  augmented  chain 
is
illustrated  in  Figure  2.  In  the  figure,  packets  of  the
original  chain  are  represented  by  letters,  and  the  newly
inserted  packets  are  represented  by  numbers.  According
to  our  simulation  results  in  Section  5,  the  augmented
chain technique achieves higher verification probabilities
compared  to  EMSS  (with  the  same  communication
overhead)  at  the  cost  of  increased  delay  on  the  sender
side. Compared with our authentication scheme, however,
augmented chain is less robust against loss given the same
amount of communication overhead.
In  [10],  the  authors  propose  a  similar  authentication
scheme  based  on  hash  chaining  techniques  that  is
specifically  designed  to  resist  multiple  bursts  within  a
block.  In  the  construction  of  their  scheme  (called  the
piggybacking  scheme),  n  packets  are  partitioned  into  r
equal-sized  priority  classes,  and  hence  each  class  is  of
size 
 where i
denotes the class  number  and  j  denotes  the  packet  index
. Each packet is represented by 
/=
rn
,jis
z
Proceedings of the 2002 IEEE Symposium on Security and Privacy (S&P(cid:146)02) 
1081-6011/02 $17.00 ' 2002 IEEE 
that, 
throughout 
the  block,  so 
within that class. The signature packet is the first packet
in the highest priority class and thus represented by 
11s . It
is assumed that the packets in the highest priority class are
spaced  evenly 
two
consecutive  packets  of  the  highest  priority  class  are
located  exactly  r  packets  apart.  By  constructing  hash
chains in the following manner, packet 
ix
bursts of size at most 
Piggybacking scheme construction:
+
,1
For 
i
i
r
K
(,
se
edges 
r
(
)
,
i PPe
j
of 
iP  in 
 denotes a hash chain formed by placing a hash
jP .
1
=
,3,2 K
r
(
se
s
K+
,
),
s
,
  add
z
  where
iP  can tolerate 
  and 
r
(
,
se
kx
i
i
,
kx
i
),
r
),
rk
i
−
kxj
i
i
,2
b
i
,0
−
kj
i
,
,
ji
,
ji
,0
=
j
s
,
ji
,
,0
j
2
C
3
D
=
: