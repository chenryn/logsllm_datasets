time elapsed between the arrival of a request for application
Figure 7: The secure I2C bus manager (shown in
gray above) restricts access to the bus by controlling
tri-state buﬀers that are used to connect peripherals
to the I2C bus. The trusted domain initializes the
peripheral access control map with information re-
garding the peripherals which each application can
access. Each application can in turn enable a sub-
set of these peripherals using the Peripheral Select
Register (PSR).
execution and the actual execution of the application. When
the system is idle, the activation latency is equal to the con-
text switch time and we call this the ideal activation delay.
In our prototype, this includes time required to save the cur-
rent program counter, all the general purpose registers (32
registers in the case of the AVR ATmega103), the current
stack pointer, timer register representing the remaining ex-
ecution time, peripheral selection register and the interrupt
mask register. This takes about 114 CPU cycles ((cid:7)9.1 μs
when the processor runs at 12.5 MHz) and is our system’s
ideal activation time.
In the non-idle state of the system, the activation latency
depends on whether execution control rests within another
application or a context switch. If execution control rests
within an atomic section of a lower-priority application, then
the activation delay increases by the number of remaining
cycles in the atomic section. Similarly, if the system is cur-
rently executing a context switch, then the activation delay
increases by the number of remaining cycles in the context
switch. Our measurements on the prototype implementa-
tion resulted in a worst case activation latency of 222 CPU
cycles ((cid:7)18 μs at 12.5 MHz).
Finally, we calculate the system recovery time, i.e., the
time taken by the system to exit an erring application and
begin restoring a previous context. Our prototype imple-
mentation took 12 CPU cycles ((cid:7)1 μs at 12.5 MHz) to re-
cover from a security panic and restore last known stable
system state.
Application Execution Latency
In our prototype, the only component that directly aﬀects
the total application execution time is the MPU, which checks
every memory access to guarantee its validity. The ATmega
103 has two types of data memory access instructions: di-
rect and indirect. While indirect memory access instructions
(load and store) do not incur additional delay, the direct
memory access instructions require one extra cycle (i.e., they
take 3 cycles instead of 2). This is because in the latter case,
68
tecture, individual components of the architecture have been
explored extensively in previous work. We summarize pre-
vious work on CPU scheduling, memory management and
bus isolation in real-time embedded systems.
Most previous work on scheduling in real-time systems fo-
cused on optimizing the design [23, 26] and implementation
of schedulers in hardware and software [30]. Today, schedul-
ing in real-time systems is usually done by a real-time op-
erating system (RTOS) [5, 6] or a separation kernel [3, 8].
An overview of contemporary RTOS and their performance
can be found in [21, 27]. Most RTOS support the use of
both co-operative and preemptive scheduling using priority-
and round-robin-based algorithms. However, unlike our so-
lution, none of these works explicitly include mechanisms to
limit the length of atomic sections in code.
Process/Domain-aware MMUs are available in some of to-
day’s processors (e.g., ARM [1], NIOS II [7]). While most
RTOS support the use of MMUs and MPUs, it is unclear
whether they also support use of such application-aware
MMUs as described in this work. Furthermore, commer-
cial RTOS [5, 6] assign separate program and data memory
partitions to each of the applications [27]. RTOS for mem-
ory constrained embedded devices ensure more eﬃcient use
of memory by sharing stack, heap and global data sections.
Solutions for secure stack sharing [20, 24] and stack overﬂow
prevention in such constrained devices [14, 17, 20] also exist.
The work in [25, 31] discusses DoS attacks against the
system bus and defense mechanisms in the context of shared-
memory multi-processor systems. However, these works only
consider attacks by misbehaving applications running on one
or more CPUs and do not take into account other misbehav-
ing system components and peripherals. The need for fault
tolerant bus design has led to the design of bus isolation so-
lutions [11, 29]. These bus isolation solutions by themselves
only provide a mechanism to physically isolate faulting de-
vices and therefore useful for trusted scheduling only when
they are conﬁgured and controlled by a context-aware bus
controller as described in our design.
6. CONCLUSION
In this work, we investigated the problem of enabling
trusted scheduling on embedded systems in adversarial set-
tings. First, we identiﬁed the essential properties of a trusted
scheduling system and presented an embedded system de-
sign that satisﬁes these properties. Our design includes a
software-based trusted domain that manages the other hard-
ware components. We analyzed the security of our proposal
and showed that it achieves trusted scheduling in the pres-
ence of not only misbehaving applications but also misbe-
having peripherals. Our prototype implementation based on
the AVR ATmega103 shows the feasibility of realizing such
an architecture through simple hardware extensions.
Acknowledgments
The research leading to these results was supported, in part,
by the Hasler foundation (project number: 09080) and Eu-
ropean Union Seventh Framework Programme (FP7/2007-
2013) under grant agreement no 258754.
the actual memory address which is fetched during the sec-
ond cycle needs to be validated before the actual load/store
operation.
Hardware Complexity
We implemented the trusted scheduling hardware modules
as an extension to the AVR ATmega103 core in VHDL and
synthesized it for a Xilinx Virtex 5 FPGA. The application-
aware MPU, the time-slice monitor and the atomicity mon-
itor together occupied 34.7% more logic units compared to
the original AVR core. A major portion of the increase
(about 22%) is the application-aware MPU which contains
the memory map of application boundaries. However, we
note that many CPUs today are already equipped with pro-
cess-aware or domain-aware MMUs (e.g., NIOS II, ARM)
which can potentially be used to realize application-aware
MMUs at no additional hardware cost. The logic units uti-
lized by the peripheral bus manager was insigniﬁcant (less
than 0.1% of the whole system).
4.3 Discussion
In this section, we discuss the implications of choosing
a bus protocol for a trusted scheduling enabled embedded
system. Broadly, bus protocols can be classiﬁed as either
(i) node-oriented (e.g., I2C ) or(ii) message-oriented (e.g.,
CAN [2]).
In a node-oriented protocol, only one master
and slave are active at any point in time. A simple bus
manager design would be to allow access to the bus based
on the priority of the master node. In addition, as imple-
mented in our prototype, the master node can selectively
enable the slave(s) that it requires for functioning. However,
in message-oriented protocols like CAN, bus arbitration de-
pends upon the priority of the message being broadcasted.
Since multiple nodes can send out messages of the same pri-
ority, it is non-trivial to formulate secure bus access control
policies for message-oriented protocols without any modiﬁ-
cations to the protocols. Therefore, bus manager designs for
message-oriented protocols requires further exploration.
Furthermore, in case the bus protocol uses a bi-directional
bus line, peripherals may either connect to it using a single
bi-directional pin [11] or using separate pins for input and
output. Bus isolation circuits that allow control of physical
access to the bus are much simpler in the latter scenario
because it is easier to identify when a peripheral is actually
transmitting. We intend to investigate this and other as-
pects of bus-interface designs that aﬀect trusted scheduling
as future work.
5. RELATED WORK
Given the feasibility of compromising the ﬁrmware of pe-
ripherals [15], there have been eﬀorts to detect [22] as well as
defend applications [28] against such compromised devices.
The work that comes closest to ours in terms of protection
against malicious peripherals is CARMA [28], which relies
on Cache-as-RAM mechanism to securely sandbox applica-
tions. However, CARMA focuses on reducing the trusted
computing base rather than providing trusted scheduling
guarantees as presented in this work. Furthermore, our work
addresses iDoS attacks by peripherals unlike CARMA which
addresses attacks against conﬁdentiality and integrity of ap-
plication code and data.
Although there has been no direct work that provides
guarantees similar to those of our trusted scheduling archi-
69
7. REFERENCES
[1] ARM Architecture Reference Manual.
http://infocenter.arm.com/help/index.jsp.
[2] CAN Speciﬁcation v2.0.
http://esd.cs.ucr.edu/webres/can20.pdf.
[3] Codezero. http://www.l4dev.org/.
[4] IBM X-Force 2010 Trend and Risk Report.
ftp://public.dhe.ibm.com/common/ssi/ecm/en/
wgl03003usen/WGL03003USEN.PDF.
[5] Integrity for Embedded Systems.
http://www.ghs.com/products.html.
[6] Lynx Embedded RTOS.
http://www.lynuxworks.com/rtos/rtos.php.
[7] NIOS II Processor Reference Handbox, chapter 3.
http://www.altera.com/literature/lit-nio2.jsp.
[8] OKL4 Microvisor.
http://www.ok-labs.com/products/overview.
[9] SPI BlockGuide v03.06. http://www.ee.nmt.edu/
~teare/ee308l/datasheets/S12SPIV3.pdf, 2003.
[10] Attacks on Mobile and Embedded Systems: Current
Trends.
https://mocana.com/pdfs/attacktrends_wp.pdf,
2009.
[11] Designing an isolated I2C Bus interface by using
digital isolators.
http://www.ti.com/lit/an/slyt403/slyt403.pdf,
2011.
[12] I 2C bus speciﬁcation and user manual. http://www.
nxp.com/documents/user_manual/UM10204.pdf, 2012.
[13] J. Adomat, J. Furunas, L. Lindh, and J. Starner.
Real-time Kernel in Hardware RTU: A Step Towards
Deterministic and High-performance Real-time
Systems. In Proceedings of the 8th Euromicro
Workshop on Real-Time Systems, pages 164 –168,
1996.
[14] S. Biswas, T. Carley, M. Simpson, B. Middha, and
R. Barua. Memory Overﬂow Protection for Embedded
Systems Using Run-time Checks, Reuse, and
Compression. ACM Transactions on Embedded
Computing Systems, 5(4):719–752, Nov. 2006.
[15] L. Duﬂot, Y.-A. Perez, and B. Morin. What If You
Can’t Trust Your Network Card? In Proceedings of
the 14th International Conference on Recent Advances
in Intrusion Detection, RAID’11, pages 378–397, 2011.
[16] N. Felliere, L. O. Murchu, and E. Chien.
W32.Stuxnet Dossier, 2011.
[17] A. Francillon, D. Perito, and C. Castelluccia.
Defending Embedded Systems Against Control Flow
Attacks. In Proceedings of the 1st ACM Workshop on
Secure execution of untrusted code, SecuCode ’09,
pages 19–26, 2009.
[18] G. Klein, K. Elphinstone, G. Heiser, J. Andronick,
D. Cock, P. Derrin, D. Elkaduwe, K. Engelhardt,
R. Kolanski, M. Norrish, T. Sewell, H. Tuch, and
S. Winwood. seL4: Formal Veriﬁcation of an OS
Kernel. In Proceedings of the ACM SIGOPS 22nd
symposium on Operating systems principles, SOSP
’09, pages 207–220, 2009.
[19] P. Kohout, B. Ganesh, and B. Jacob. Hardware
Support for Real-time Operating Systems. In
Proceedings of the 1st IEEE/ACM/IFIP International
Conference on Hardware/Software Codesign and
System Synthesis, CODES+ISSS’03, pages 45–51,
2003.
[20] R. Kumar, A. Singhania, A. Castner, E. Kohler, and
M. Srivastava. A System for Coarse Grained Memory
Protection in Tiny Embedded Processors. In
Proceedings of the 44th annual Design Automation
Conference, DAC ’07, pages 218–223, 2007.
[21] B. Leiner, M. Schlager, R. Obermaisser, and
B. Huber. A Comparison of Partitioning Operating
Systems for Integrated Systems. In Computer Safety,
Reliability, and Security, volume 4680 of Lecture Notes
in Computer Science, pages 342–355. 2007.
[22] Y. Li, J. M. McCune, and A. Perrig. VIPER: Verifying
the Integrity of PERipherals’ Firmware. In Proceedings
of the 18th ACM conference on Computer and
Communications security, CCS ’11, pages 3–16, 2011.
[23] C. L. Liu and J. W. Layland. Scheduling Algorithms
for Multiprogramming in a Hard-Real-Time
Environment. Journal of the ACM, 20(1):46–61, Jan.
1973.
[24] B. Middha, M. Simpson, and R. Barua. MTSS:
Multitask Stack Sharing for Embedded Systems. ACM
Transactions on Embedded Computing Systems,
7(4):46:1–46:37, Aug. 2008.
[25] T. Moscibroda and O. Mutlu. Memory Performance
Attacks: Denial of Memory Service in Multi-Core
Systems. In Proceedings of the 16th Usenix Security
Symposium, pages 257–274, 2007.
[26] K. Ramamritham and J. Stankovic. Scheduling
Algorithms and Operating Systems Support for
Real-time Systems. In Proceedings of the IEEE,
82(1):55 –67, Jan. 1994.
[27] S. Tan and B. Tran Nguyen. Survey and Performance
Evaluation of Real-time Operating Systems (RTOS)
for Small Microcontrollers. Micro, IEEE, (99), 2009.
[28] A. Vasudevan, J. M. McCune, J. Newsome, A. Perrig,
and L. van Doorn. CARMA: A Hardware
Tamper-Resistant Isolated Execution Environment on
Commodity x86 Platforms. In Proceedings of the ACM
Symposium on Information, Computer and
Communications Security, ASIACCS’12, 2012.
[29] N. Venkateswaran, S. Balaji, and V. Sridhar. Fault
Tolerant Bus Architecture for Deep Submicron Based
Processors. SIGARCH Computer Architecture News,
33(1):148–155, Mar. 2005.
[30] M. Vetromille, L. Ost, C. Marcon, C. Reif, and
F. Hessel. RTOS Scheduler Implementation in
Hardware and Software for Real Time Applications. In
17th IEEE International Workshop on Rapid System
Prototyping, pages 163 –168, 2006.
[31] D. H. Woo and H.-H. S. Lee. Analyzing Performance
Vulnerability due to Resource Denial-of-Service Attack
on Chip Multiprocessors. In Proceedings of the
Workshop on Chip Multiprocessor Memory Systems
and Interconnects, CMP-MSI’07, 2007.
70