trie height, there is no danger of stack overﬂow.
The Figure 6 shows the trie construction process
for the patterns faaax, aaby, acdzg.
In step 1,
addpatterns is called with a node and the three pat-
terns in the range. Since there is more than one pat-
tern in the range, addpatterns creates a transition
for the character a, and recursively calls itself with the
same range, but using the node at the next level down.
In step 2, the next characters from the patterns are com-
pared. Two transitions for characters a and c are set up
and the function calls itself recursively twice, once with
the range containing the patterns faaax, aabyg, and once
with facdzg (step 3).
In step 4, the pattern “acdz” is
added to the current node since the range contains only
one pattern, and the remaining patterns get added to the
next level in step 5. Notice that the pattern “acdz” was
added as soon as the unique preﬁx “ac” was found for
this pattern (step 4).
Since the pattern array was presorted, whenever pat-
terns (delimited by start offset and end offset) get added
to a node, they begin with the same preﬁx, and there-
fore have sequential pattern IDs. This reduces memory
usage. Instead of creating a linked list of patterns, we
simply add a pattern-range structure to the node. The
pattern-range structure has three members: (1) start off-
set, (2) end offset, and (3) the level of the trie where the
range is stored. The level member of this structure deter-
mines how many characters from all of the patterns are
already matched by the trie preﬁx.
The trie construction algorithm described above min-
imizes memory usage by storing each pattern at the low-
est possible level. The algorithm maintains the maxi-
mum trie height restriction to enforce an upper bound
on memory usage.
In addition, we provide a recom-
mended minimum height conﬁguration parameter to al-
low a trade-off between speed and memory usage. Even
if a pattern can be uniquely identiﬁed by a single char-
acter preﬁx, it is not added to the trie until the rec-
ommended minimum height is reached. Short patterns
or patterns with wildcard characters are still stored at
levels below the recommended minimum trie height.
Increasing the recommended minimum height parame-
ter increases memory usage. This increase, however,
could improve performance because leaf nodes of the
trie would be scanned less frequently due to the larger
trie height (see Section 6). Note that the minimum trie
height parameter should not be set too high. In our tests,
a minimum height of three proved to be scalable with
databases of up to 128K virus deﬁnitions. A combina-
tion of minimum and maximum heights allows for ﬂex-
ibility in tuning performance and memory usage.
3.2.4 Collision Detection and Avoidance
Collisions are detected using a simple procedure. We
start processing every node in the trie in a level-order
traversal; i.e., process all nodes on level n before pro-
cessing nodes on level n + 1. For every success transi-
tion in a node A, we traverse the trie as if it were a failure
transition. We look at a node, say node B, pointed to by
the failure transition. If node B has pattern ranges stored
under it, then there is a collision. Whenever a collision
is detected, all pattern ranges from node B are copied to
node A. The level member of the pattern range struc-
ture, which identiﬁes the number of characters matched
so far, is not modiﬁed during the copy operation.
Preferably, we wish to avoid collisions whenever pos-
sible.
If too many collisions occur, then instead of
having a lot of patterns stored in the linked lists, we
will have many pattern ranges stored. To avoid colli-
sions, we exploit two facts: (1) the trie constructed by
the addpatterns function attempts to add patterns
as soon as possible before the maximum trie height is
reached, and (2) if the maximum trie height is greater
than one, failure transitions from a leaf node can never
point to another leaf node. Instead of copying pattern
ranges as soon as a collision is detected, we ﬁrst attempt
to push from both nodes A and B down the trie. This
reduces the probability of a collision by 2562 times if
ranges from both A and B can be pushed down, or by
256 times if only one of the ranges can be pushed down.
The only time pushing down is not possible is if ranges
for either A or B contain short patterns or have patterns
with a wildcard character in the position equal to the
level of the node. If a pattern is already stored on the leaf
node, we are guaranteed that this node’s pattern ranges
will not collide with any other node.
Figure 7 shows a ﬁnal trie constructed by our algo-
rithm. Patterns beginning with characters h0; 254i are
stored at level two (node A) because either they are short
or they have a wildcard character in position two. These
patterns are copied by node B due to a collision. The rest
of the patterns are stored under leaf nodes.
To summarize, Oyster takes the following steps to
construct a trie:
1. Read all patterns from the virus database and store
them in a sorted array.
2. Call the addpatterns function to build a trie and
initialize success transitions.
3. Execute the pattern-collision detection and avoid-
ance procedure.
4. Set up the failure transitions.
0 1 ...
254
255
L0
0 1 ...
254
255
0 1 ...
254
255
L1
Node A
Leaf Node
0 1 ...
254
255
L2
Pat. Range
0 1 ...
Node B
255
254
L3
Pat. Range
Inherited
Ranges
Leaf Node
Pattern Ranges
Figure 7: Final trie structure for Oyster. Only success transi-
tions are shown.
3.2.5 Oyster File System Integration
Oyster provides a simple interface to the ﬁle system
to perform scanning.
It exports a scanbuf function
which is responsible for scanning a buffer for viruses.
The scanbuf function supports two modes of scan-
ning: full mode, which scans for all patterns, and regular
mode, which scans all regular (non multi-part) patterns.
The scanbuf function takes the following ﬁve param-
eters: (1) a buffer to scan, (2) the buffer length, (3) the
buffer’s position in the ﬁle, (4) an Oyster state structure,
and (5) various ﬂags that determine the scan mode, state
handling, and other aspects of the operation. The return
code of this function indicates whether the buffer is clean
or infected.
The state structure enables Oyster to continue scan-
ning the next buffer right from where the previous call
to scanbuf left off. The state structure contains the
following four members: (1) a linked list of partially-
matched patterns represented by the pattern ID and the
position of the last character successfully matched, (2)
a node ID identifying the trie node where the previ-
ous call left off, (3) a structure to keep track of multi-
part pattern matches, and (4) a virus database checksum,
which we use to check the validity of the state against
the currently-loaded database.
We keep only one state structure for each opened in-
ode (ﬁle on disk). Multiple processes that read or write
to the same ﬁle share a single state structure. The size
of the state depends on the number of partially-matched
viruses, and is usually around 512 bytes. We do not ex-
port the state structure to external modules. Instead, we
provide functions to allocate and deallocate the struc-
ture, as well as functions to serialize and deserialize it so
that external modules can store the state persistently.
To load the Oyster module into the kernel, we specify
the database ﬁles to load as well as the minimum and
the maximum trie heights parameters. After the Oyster
module is loaded, external ﬁle system modules can use
Oyster to perform on-access scanning.
3.2.6 Summary of Improvements
Our Oyster scanner improves on ClamAV in two ways:
performance and scalability, and kernel integration.
We allow trie heights larger than two, which improves
performance logarithmically. Oyster can limit the max-
imum tree height, to minimize memory usage and im-
prove scalability. We additionally improve performance
by allowing pattern scanning to terminate at intermedi-
ate trie nodes instead of having to go all the way down
to leaf nodes.
ClamAV was designed for scanning whole ﬁles in the
user level, making assumptions that are unsuitable for
running inside kernels. For example, ClamAV scans
entire ﬁles sequentially, 132KB at a time. Oyster, on
the other hand, uses data units that are native to the
kernel, scanning one page at a time (4KB on IA-32
hosts). Finally, whereas ClamAV scans whole ﬁles se-
quentially, Oyster scans individual pages as they are be-
ing accessed—regardless of the order in which they are
accessed. This improves performance and guarantees
that no infected data is ever leaked. We introduced a
state structure to incrementally record the partial scan
status of individual pages, and also found that this struc-
ture improves performance by up to 68% as compared to
ClamAV.
4 The Anti-virus File System
We designed Avfs to achieve the following three goals:
Accuracy and high-security: We achieve this by de-
tecting viruses early and preventing viruses from
corrupting the ﬁle system.
Performance: We perform partial scanning and avoid
repetitive scanning.
Flexibility and portability: Being a stackable ﬁle sys-
tem, Avfs is portable. Moreover, user-oriented fea-
tures such as forensics and versioning provide ﬂex-
ible options for deployment.
Avfs is a stackable ﬁle system for Linux that inter-
faces with Oyster, as described in Section 3, to provide
virus protection. The advantages of being a stackable
ﬁle system include transparent operation and portability
to a variety of other ﬁle systems. A state-oriented ap-
proach allows Avfs to perform partial and non-repetitive
scanning.
4.1 State-Oriented Design
There are two types of state involved in providing on-
access virus protection in our system. The ﬁrst allows
safe access to ﬁles through the read and write meth-
ods by tracking patterns across page boundaries. This
state is computed by Oyster and is maintained by Avfs.
The second type of state is used to avoid repetitive scan-
ning and is stored persistently as part of a ﬁle by Avfs.
The Oyster scanning module can partially scan ﬁles.
Oyster can scan one part, say b1 of a buffer B = b1 + b2
and compute a state s1 at the end of this scan. State s1
and the second part of the buffer, b2, can be passed to
Oyster and the effect of these two scans would be as if
buffer B was scanned all at once. Avfs maintains this
Oyster state for each ﬁle in the ﬁle system. When the
ﬁle is being accessed, this state is kept in memory as part
of the in-memory inode structure of the ﬁle. We record
this state after each page scan, thereby overwriting the
previous state.
We do not maintain state for individual pages because
the current stackable ﬁle system infrastructure has no
provision for it. Also, it might be expensive in terms
of space utilization. We could store all the state for mul-
tiple pages in a single structure, but with increasing ﬁle
sizes, maintaining this structure becomes expensive.
Our state design divides a ﬁle logically into two parts:
one scanned and the other unscanned. Along with this
state, Avfs also records the page index to which this
state corresponds, so that Avfs can provide subsequent
pages for scanning in the correct order. When a ﬁle is
closed, we store this state persistently so that we can re-
sume scanning from where we left off. We use an auxil-
iary state ﬁle for each ﬁle in a separate hidden directory
under the Avfs mount called the state directory. Avfs
traps the lookup and readdir operations to prevent
access to this directory and its contents by users. The
state ﬁle’s name is a derivative of the inode number of
the corresponding ﬁle. This facilitates easy access of the
state ﬁle because the inode number of a ﬁle can be easily
obtained and thus the state ﬁle name can be easily gener-
ated. When a ﬁle is closed, the entire state (Oyster state
+ page index) is written into its state ﬁle.
In addition to the Oyster state, Avfs has some state of
its own which allows it to mark ﬁles clean, quarantined,
or unknown. These ﬁle states are stored as ﬂags in the
main ﬁle’s on-disk inode structure. To quarantine a ﬁle
we change its permissions to 000, so that non-root users
could not access it. Also, if the underlying ﬁle system is
Ext2/3, we set the immutable ﬂag so that even root could
not modify the ﬁle without changing its attributes.
1.
open()
read()
2.
Page 1
Page 2
Page 3
Page n
scanning
state S1
read()
3.
Page 1
Page 2
Page 3
Page n
4.
5.
6.
state S1
close()
scanning
state S2
Page 1
Page 2
Page 3
clean
state S2
serialize
open()
Page 1
Page 2
Page 3
state S2
deserialize
Page n
state file
Page n
state file
reads
read()
read()
Page 1
Page 2
Page 3
Page n
close()
state S2
scanning
state Sn
7.
Page 1
Page 2
Page 3
Clean
state file
Page n
serialize
state Sn
Figure 8: Typical operations on ﬁles and their processing in
Avfs.
Figure 8 illustrates a few operations and their effects
on a ﬁle under Avfs in a few simple steps:
1. During the ﬁrst open on an unknown ﬁle, there
is no state associated and the operation proceeds
normally.
2. On a read of page 1 of the ﬁle, the data is scanned
and a state S1 is computed by Oyster at the end of
this scan. This state corresponds to the ﬁrst page.
3. Reading to the next page of the ﬁle makes use of
the previous state S1 for scanning.
4. When a ﬁle is closed, the state needs to be stored
persistently. A serialized form of the state is stored
into an auxiliary state ﬁle.
5. Another open on the ﬁle causes the state to be de-
serialized from the state ﬁle and brought back into
memory for further scanning.
6. Further sequential reads of the ﬁle make use of the
previous state and ultimately the ﬁle gets scanned
completely.
7. If the ﬁle has been scanned completely, then dur-
ing its close, the latest state is written to the state
ﬁle and the ﬁle is marked clean. A clean ﬁle is
not scanned during subsequent accesses unless it is
modiﬁed.
This state-oriented design provides a basis for a vari-
ety of features, described next.
4.2 Modes of Operation