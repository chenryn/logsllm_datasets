### Experiment and Results

To evaluate the performance of the FSA-algorithm, we compared it with the N-gram algorithm. The experiment involved running the FSA-algorithm alongside seven instances of the N-gram algorithm. This process was repeated once, and the results were averaged. Given the rate of requests received by our web server, the entire experiment took approximately three weeks to complete.

The results of our experiment are illustrated in Figures 10 and 11. In terms of space requirements, the FSA-algorithm used 1.6KB, while the N-gram algorithm required 7.3KB. These findings, obtained from a real web server, are generally consistent with those observed using training scripts. Specifically, the convergence rates and false positive rates were similar. The false positive rate of the FSA-algorithm was found to be between 6 to 30 times lower than that of the N-gram algorithm. However, there were some differences: the ratio of false positive rates did not increase with the training period, as observed in previous experiments. Additionally, the absolute values of false positive rates were higher, which we attribute to the greater variability in live traffic compared to simulated data. Both approaches produced higher false positives, and if new types of requests were introduced, both methods would likely generate the same number of false positives, leading to a stable ratio.

### Attack Detection

#### Buffer Overflow Attacks
Almost all buffer overflow attacks involve the execution of system calls by code running in the stack segment. Our approach can detect such attacks by identifying corrupted stack frames. We verified this experimentally using a modified FTP server with introduced buffer overflow vulnerabilities. Even stealthy attacks that do not execute system calls from the stack can be detected.

#### Trojan Horse and Other Code Changes
We used our system to detect changes in the behavior of an FTP server after inserting a few lines of code. This modification altered the location of most instructions, even those corresponding to unchanged portions of the code. Consequently, almost every system call made by the modified server originated from a different program location compared to the original server, leading to a continuous stream of anomalies. Unlike other approaches, the FSA method can detect changes to code even before the altered sections are executed, thanks to its use of program counter information.

#### Maliciously Crafted Input
Several attacks exploit inadequate input validation by programs. By altering the input or command-line arguments, an attacker can cause unexpected behavior. Our approach detects these attacks because they induce programs to execute unusual sections of code and/or result in atypical system call traces. For example, we detected the site exec vulnerability in the FTP program.

#### Dictionary or Password Guessing Attacks
These attacks do not cause new sections of code to be executed but are characterized by repetitive execution of the same code. Such attacks can be detected by maintaining frequency-of-execution information with the automata edges.

#### Denial-of-Service (DoS) Attacks
Most DoS attacks cause server programs to frequently execute certain sections of their code. The FSA algorithm can detect these attacks using frequency-of-execution information.

Based on our classification of attacks reported in the CERT database, the above classes of attacks account for about half of all attacks reported by CERT over the past few years.

### Attacks Not Detected

#### System Call Argument Values
Some attacks, such as those involving files accessed via symbolic links, differ from normal program execution only in terms of system call arguments. The FSA and N-gram algorithms cannot detect such attacks since there are no changes to the system call sequences.

#### No Change in Program Behavior
Some attacks exploit errors of omission in the attacked program, such as race conditions, opening files without appropriate safeguards, or leaving temporary files with critical information. Exploitations of these errors are accomplished using a different program, thus not causing the "attacked program" to behave differently. Another class of attacks that do not change program behaviors are those that exploit system configuration errors (e.g., user-writable password file) or protocol weaknesses (e.g., SYN-flooding). These attacks are outside the scope of FSA and N-gram approaches.

#### Knowledge of Intrusion Detection Techniques
Armed with knowledge of how the FSA-based intrusion detection approach works, it is possible to develop successful buffer overflow attacks and Trojans. Despite this, the FSA algorithm can still detect most buffer overflow attacks and Trojan Horse programs.

### Conclusions

In this paper, we presented a new technique for intrusion detection based on learning program behaviors. Our method captures program behaviors in terms of sequences of system calls, represented using a finite-state automaton. Unlike previous approaches, the FSA approach does not limit the number or length of system call sequences, ensuring that the size of the FSA is bounded. It also captures the looping and branching structures of a program, enabling it to recognize variations in learned behaviors. The presence of program state information allows the FSA approach to perform more accurate detection of unusual code execution, focusing on program behaviors while ignoring library behaviors, contributing to shorter training periods and smaller storage requirements.

Our experimental results support the following conclusions about the FSA method:

- **Quick Convergence**: The FSA-learning algorithm converges quickly, requiring only several minutes of CPU time for FTP, NFS, and HTTP servers.
- **Low False Positive Rate**: The FSA algorithm produces significantly fewer false positives than the N-gram algorithm, with an absolute rate of 5 false positives per day on our web server.
- **Minimal Overhead**: The FSA algorithm has low space and runtime overhead.
- **Effective Attack Detection**: The FSA approach can detect a wide range of attacks.

### Future Improvements

- **Incorporation of Frequency Information**: Adding frequency information to transitions can help detect and flag attacks involving many low-probability transitions, such as denial-of-service attacks.
- **System Call Argument Values**: Incorporating system call argument values into the FSA can expand the set of detectable attacks to include filename-related attacks, such as those involving symbolic links.

### References

1. D. Anderson, T. Lunt, H. Javitz, A. Tamaru, and A. Valdes, Next-generation Intrusion Detection Expert System (NIDES): A Summary, SRI-CSL-95-07, SRI International, 1995.
2. CERT Coordination Center Advisories, http://www.cert.org/advisories/index.html.
3. C. Cowan et al., StackGuard: Automatic Adaptive Detection and Prevention of Buffer-Overflow Attacks, 7th USENIX Security Symposium, 1998.
4. D. Endler, Intrusion Detection: Applying machine learning to solaris audit data, Proceedings of the 1998 Annual Computer Security Applications Conference (ACSAC98).
5. T. Fraser, L. Badger, M. Feldman, Hardening COTS software with Generic Software Wrappers, Symposium on Security and Privacy, 1999.
6. D. Ghormley, D. Petrou, S. Rodrigues, and T. Anderson, SLIC: An Extensibility System for Commodity Operating Systems, USENIX Annual Technical Conference, 1998.
7. A.K. Ghosh and A. Schwartzbard, A Study in Using Neural Networks for Anomaly and Misuse Detection, USENIX Security Symposium, 1999.
8. A.K. Ghosh, A. Schwartzbard, and M. Schatz, Learning Program Behavior Profiles for Intrusion Detection, 1st USENIX Workshop on Intrusion Detection and Network Monitoring, 1999.
9. A.K. Ghosh, A. Schwartzbard, and M. Schatz, Using Program Behavior Profiles for Intrusion Detection, Proceedings of the SANS Third Conference and Workshop on Intrusion Detection and Response, 1999.
10. A. K. Ghosh, J. Wanken, and F. Charron, Detecting anomalous and unknown intrusions against programs, Proceedings of the 1998 Annual Computer Security Applications Conference (ACSAC '98), December 1998.
11. K. Ilgun, R. Kemmerer, and P. Porras, State Transition Analysis: A Rule-Based Intrusion Detection Approach, IEEE Transactions on Software Engineering, March 1995.
12. K. Jain and R. Sekar, User-Level Infrastructure for System Call Interposition: A Platform for Intrusion Detection and Confinement, ISOC Network and Distributed Security Symposium, 2000.
13. M. Kearns and L. Valiant, Cryptographic Limitations on Learning Boolean Formulae and Finite Automata, ACM STOC, 1989.
14. C. Ko, G. Fink, and K. Levitt, Automated detection of vulnerabilities in privileged programs by execution monitoring, Computer Security Application Conference, 1994.
15. A. Kosoresow and S. Hofmeyr, Intrusion detection via system call traces, IEEE Software '97.
16. S. Kumar and E. Spafford, A Pattern-Matching Model for Intrusion Detection, Nat'l Computer Security Conference, 1994.
17. C. Michael and A. Ghosh, Using Finite Automata to Mine Execution Data for Intrusion Detection: A preliminary Report, Lecture Notes in Computer Science (1907), RAID 2000.
18. T. Mitchem, R. Lu, R. O’Brien, Using Kernel Hypervisors to Secure Applications, Annual Computer Security Application Conference, December 1997.
19. W. Lee and S. Stolfo, Data Mining Approaches for Intrusion Detection, USENIX Security Symposium, 1998.
20. R. Lippmann, D. Fried, I. Graf, I. Haines, K. Kendall, D. McClung, D. Weber, S. Webster, D. Wyschogrod, R. Cunningham, and M. Zissman, Evaluating Intrusion Detection Systems: the 1998 DARPA Off-Line Intrusion Detection Evaluation, Proceedings of the DARPA Information Survivability Conference and Exposition, 2000.
21. T. Lunt et al., A Real-Time Intrusion Detection Expert System (IDES) - Final Report, SRI-CSL-92-05, SRI International, 1992.
22. P. Porras and R. Kemmerer, Penetration State Transition Analysis: A Rule-based Intrusion Detection Approach, Eighth Annual Computer Security Applications Conference, 1992.
23. P.A. Porras and P.G. Neumann, Emerald: Event monitoring enabling responses to anomalous live disturbances, Proceedings of the 20th National Information Systems Security Conference, pages 353-365, October 1997.
24. L. Pitt and M. Warmuth, The minimum consistency DFA problem cannot be approximated within any polynomial, ACM STOC, 1989.
25. L. Rabiner, A tutorial on Hidden Markov Models and selected applications in speech recognition, Proceedings of the IEEE, 1989.
26. R. Sekar, Classification of CERT/ICC Advisories from 1993 to 1998, http://seclab.cs.sunysb.edu/sekar/papers/cert.htm.
27. R. Sekar and P. Uppuluri, Synthesizing Fast Intrusion Prevention/Detection Systems from High-Level Specifications, USENIX Security Symposium, 1999.
28. G. Vigna and R.A. Kemmerer, Netstat: A network-based intrusion detection approach, Proceedings of the 1998 Annual Computer Security Applications Conference (ACSAC’98), pages 25-34, Los Alamitos, CA, December 1998, IEEE Computer Society, IEEE Computer Society Press. Scottsdale, AZ.