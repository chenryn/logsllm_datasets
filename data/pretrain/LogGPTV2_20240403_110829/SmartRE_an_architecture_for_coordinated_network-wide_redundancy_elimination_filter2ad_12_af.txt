c
a
r
F
 0.6
 0.4
 0.2
 0
 1
 0.8
n
o
i
t
c
a
r
F
 0.6
 0.4
 0.2
 0
Hop-by-Hop
Edge-based
SmartRE
Hop-by-Hop Ideal
 0  0.05  0.1  0.15  0.2  0.25  0.3  0.35  0.4
Reduction in Network Footprint
(a) High volume /24 trace
Hop-by-Hop
Edge-based
SmartRE
Hop-by-Hop Ideal
 0  0.05  0.1  0.15  0.2  0.25  0.3  0.35  0.4
Reduction in Network Footprint
(b) University trace
Figure 12: CDF of network footprint reduction across ingresses
on Sprint topology extrapolating from real traces.
IP addresses to the nearest PoP in the ISP topology. We used one
trace capturing all trafﬁc leaving the university (which was 15% re-
dundant with 10s of encoding cache) and another trace for trafﬁc
leaving the /24 preﬁx (40% redundant).
We start with the single-ingress case. Figure 12 shows the CDF
of footprint reduction on the Sprint topology using both all-university
and /24 preﬁx traces. Again, SmartRE outperforms the hop-by-
hop approach by 4-5×. In the University trace, SmartRE is almost
indistinguishable from the ideal case; in the /24 trace the median
performance difference is 0.04.
We observed substantial variance in the relative performances
of the naive approach and SmartRE across different ingresses (not
shown). We explored this further, focusing on the top-4 ingress
PoPs in the topology (by degree). For two of the PoPs (Seattle
and Dallas) SmartRE is 7-8× more effective than the naive ap-
proach. For the remaining two (New York, Chicago), it is 3-4×
better. There are two factors here. First, a majority of the trafﬁc is
destined to New York and Chicago and there is considerable over-
lap within this trafﬁc. Second, the paths from the other two PoPs
to New York and Chicago share many intermediary nodes. Thus,
SmartRE can better exploit this inter-path redundancy.
We also conducted the network-wide evaluations across 4 ISP
networks. SmartRE reduced the network-wide footprint by 20%
and 13% on average across the 4 networks for the /24 and all-
university traces respectively.
7.4 Effect of Stale Redundancy Proﬁles
As discussed in §6, SmartRE uses the redundancy proﬁle ob-
served in the current epoch to compute caching manifests for the
next epoch. We evaluate the impact of using stale redundancy pro-
ﬁles (SmartRE-stale) compared to SmartRE-ideal which uses up-
to-date information (as in the rest of this section so far).
We study variants of SmartRE-stale which differ in the time be-
tween when redundancy proﬁles were computed and when they
are used. We use the real packet traces from §7.3 for this study.
We evaluate time lags of 10, 20, 30 and 40 minutes (not shown).
We ﬁnd that SmartRE-stale performs close to SmartRE-ideal (and
hence ideal RE), with the worst-case footprint reduction being at
most 0.05 worse than SmartRE-ideal. We investigated why SmartRE
performs well even with a stale redundancy proﬁle and found that
the trafﬁc volume to the large cities (Chicago and New York) dom-
inates the overall beneﬁts and the redundancy proﬁles for these are
stable. While these results are preliminary, they are encouraging–
the dominant sources of redundancy appear to be stable and SmartRE
can provide beneﬁts even with stale redundancy proﬁles.
Flash-crowd scenarios: Next, we study how staleness can affect
RE performance in more sudden ﬂash-crowd-like scenarios. First,
we increase the total trafﬁc volume entering at a particular ingress
to saturate its upstream bandwidth, keeping the redundancy at each
ingress ﬁxed at 50%. In this setup, the footprint reduction is 0.26
t
n
i
r
p
t
o
o
F
k
r
o
w
e
N
n
t
i
n
o
i
t
c
u
d
e
R
 0.35
 0.3
 0.25
 0.2
 0.15
 0.1
 0.05
 0
BWDistance
PathCoverage
 10
 20
 0
Number of RE devices (cache size 6 GB)
 30
 40
 50
 60
Figure 13: Two partial deployment strategies on the Sprint
topology (x=65 represents full deployment). Each device has
a 6GB cache.
with an up-to-date trafﬁc matrix and redundancy proﬁle; with older
inputs the reduction is 0.23 − 0.25 depending on the ingress. Sec-
ond, we increase the aggregate redundancy for a speciﬁc ingress
from 25% to 50%, keeping the redundancy from other ingresses
ﬁxed at 25%. Depending on the ingress that has increased redun-
dancy, the footprint reduction is 0.14 − 0.15 with up-to-date pro-
ﬁles and 0.10− 0.11 with an old proﬁle. These experiments further
conﬁrm that while up-to-date proﬁles yield better RE performance,
even stale proﬁles can yield substantial beneﬁts. However, for dra-
matic changes, proﬁles should be updated using the triggered up-
date mechanism discussed in §6.
7.5 Partial deployment beneﬁts
The middlebox-style implementation of encoders and encoders
makes SmartRE amenable to incremental and partial deployment,
in that the encoders/decoders can be installed at locations where
reduction in network load is desired most.
We emulate a situation where an ISP would like to mitigate the
impact of redundant trafﬁc originating from certain high-volume
PoPs (say, top 5 by volume) by deploying RE middleboxes strate-
gically in its network. (Encoding RE boxes are deployed at each of
a PoP’s ingress access links). We ask if SmartRE is useful even on
a limited scale.
We examine two strategies. In both cases, our goal is to deploy
RE boxes where there is a lot of trafﬁc aggregation. We ﬁrst count
the number of shortest path routes traversing each interior link. In
the ﬁrst strategy we simply deploy decoders on links which lie on
many of the network paths from the 5 ingresses in question to other
egresses. The second strategy is smarter, in that it ﬁrst weighs each
path traversing a link by the volume of trafﬁc it carries and the
distance of the link from the corresponding ingress, and ranks links
according to the total weights of paths traversing them.
Figure 13 shows that in both cases, deploying RE middleboxes
on a small number of links (e.g., < 10 out of a maximum of 65)
still offers reasonable beneﬁts in network-wide utilization (roughly
10% compared to the best possible 26%). The smarter strategy
works better with 50% - 70% deployment. Figure 13 indicates
that for partial deployments even simple strategies work well. This
can be further enhanced by weighing each path with the expected
amount of redundancy based on historical observations.
7.6 Evaluation Summary
by-hop approach.
• SmartRE is on average 4-5× more effective than a naive hop-
• SmartRE, even under strict resource constraints on both mem-
ory and memory access throughput, achieves 80-90% of the
performance of an ideal unconstrained RE solution which as-
sumes no memory or processing constraints.
• The above results are consistent across several redundancy
• The global resource-aware optimization in SmartRE is nec-
essary for good RE performance; simple heuristics for as-
proﬁles and on both synthetic and real traces.
97signing caching responsibilities do not yield sufﬁcient net-
work footprint reduction.
• SmartRE can provide beneﬁts comparable to the ideal sce-
nario even under partial deployment or with slightly out-of-
date redundancy proﬁles.
8. DISCUSSION
Multi-hop wireless: We believe that SmartRE can be used to en-
hance caching systems in other contexts, e.g., multi-hop wireless
networks [16]. Coordinated caching can help in two ways here: (1)
improving the effective memory usage at multihop nodes by chunk-
ing large transfers and apportioning each chunk to a speciﬁc node
(this replaces blind caching at all on-path routers) and (2) prevent-
ing multiple nodes from retrieving a popular chunk from a single
cache - this creates contention for the medium and may wipe out
the beneﬁts of caching. We can limit each cache’s encoding respon-
sibilities and this creates an even distribution of caching/encoding
across nodes in the network.
Allowing overlapping ranges in SmartRE: We saw in §7.2 that
allowing caches to overlap may improve RE performance. How-
ever, there are two practical difﬁculties. First, the formulation from
§4.2 becomes more complicated. Speciﬁcally, we can no longer
model the second term in Equation 2 and the savings term in Equa-
tion 4 as linear expressions; in fact, it is not even clear if we can pre-
cisely model these terms. Thus, it is difﬁcult to obtain the optimal
caching responsibilities in this setting. Second, in order to maintain
a consistent view with every decoder each ingress has to either (a)
keep duplicate copies of packets that belong to overlapping ranges
or (b) use additional mechanisms to keep track of whether a packet
has been evicted from an interior node and also maintain the ap-
propriate mappings between ﬁngerprints to the packets in the store.
Additionally, the ingress needs to explicitly decide which of the de-
coders is responsible for reconstructing encoded regions in case the
matched packet is cached on multiple downstream nodes. The per-
formance of SmartRE with non-overlapping ranges is already close
to the ideal scenario. Thus, we do not consider this extension to al-
low overlapping caches because the marginal improvement does
not merit the increased implementation complexity.
9. CONCLUSIONS
As Internet trafﬁc volumes increase and more bandwidth-intensive
applications appear, redundancy elimination (RE) has emerged as
a promising practical solution to increase end-to-end application
throughput. More recently, there has been interest in expanding the
scope of RE to network-wide scenarios with the grander vision of
offering this as a primitive IP-layer service within ISP networks.
This paper takes this vision one step closer to reality. We look
beyond a naive link-by-link view and adopt a network-wide coor-
dinated approach. We design and implement a framework called
SmartRE based on these high-level design principles. SmartRE is
naturally suited to handle heterogeneous resource constraints and
trafﬁc patterns and for incremental deployment. We address sev-
eral practical issues in the design to ensure correctness of operation
in the presence of network dynamics. Across a wide range of eval-
uation scenarios, SmartRE provides 4-5× improvement over naive
solutions and achieves 80-90% of the performance of an ideal, un-
constrained RE network-wide alternative.
A natural extension is to apply SmartRE to datacenter and multi-
hop wireless networks. Another area of future work is to expand the
scope for RE by allowing multiple encoders per-path (in contrast to
encoding only at the ingress) and exploring the interplay between
RE techniques and network coding.
Acknowledgments
We thank Tom Anderson, Flavio Bonomi, Bruce Davie, K. K. Ra-
makrishnan, Srini Seshan, David Wetherall, and the anonymous re-
viewers for their valuable feedback that helped improved our pa-
per. This work was supported in part by an NSF CAREER Award
(CNS-0746531) and an NSF NeTS FIND Award (CNS-0626889).
10. REFERENCES
[1] Akamai Technologies. http://www.akamai.com.
[2] BlueCoat: WAN Optimization. http://www.bluecoat.com/.
[3] Cisco Content Aware Networks – Some Areas of Interest.
http://www.cisco.com/web/about/ac50/ac207/crc_new/
ciscoarea/content.html.
[4] Cisco Wide Area Application Acceleration Services.
http://www.cisco.com/en/US/products/ps5680/Products_
Sub_Category_Home.html.
[5] Citrix, application delivery infrastructure. http://www.citrix.com/.
[6] Computerworld - WAN optimization continues growth.
www.computerworld.com.au/index.php/id;1174462047;fp;
16;fpid;0/.
[7] PeerApp: P2P and Media Caching. http://www.peerapp.com.
[8] Riverbed Networks: WAN Optimization.
http://www.riverbed.com/solutions/optimize/.
[9] WAN optimization revenues grow 16% - IT Facts. www.itfacts.biz/
wan-optimization-market-to-grow-16/1205/.
[10] A. Anand and C. Muthukrishnan and A. Akella and R. Ramachandran.
Redundancy in Network Trafﬁc: Findings and Implications. In Proc. of
SIGMETRICS, 2009.
[11] A. Muthitacharoen, B. Chen, and D. Mazieres. A low-bandwidth network ﬁle
system. In Proc. of SOSP, 2001.
[12] A. Anand, A. Gupta, A. Akella, S. Seshan, and S. Shenker. Packet Caches on
Routers: The Implications of Universal Redundant Trafﬁc Elimination. In Proc.
of SIGCOMM, 2008.
[13] H. Ballani and P. Francis. CONMan: A Step Towards Network Manageability.
In Proc. of SIGCOMM, 2007.
[14] A. Bavier, N. Feamster, M. Huang, L. Peterson, and J. Rexford. In vini veritas:
realistic and controlled network experimentation. In Proc. of SIGCOMM, 2006.
[15] M. Caesar, D. Caldwell, N. Feamster, J. Rexford, A. Shaikh, and J. van der
Merwe. Design and implementation of a Routing Control Platform. In Proc. of
NSDI, 2005.
[16] F. Dogar, A. Phanishayee, H. Pucha, O. Ruwase, and D. Andersen. Ditto - A
System for Opportunistic Caching in Multi-hop Wireless Mesh Networks. In
Proc. of Mobicom, 2008.
[17] N. Dufﬁeld and M. Grossglauser. Trajectory Sampling for Direct Trafﬁc
Observation. In Proc. of SIGCOMM, 2001.
[18] A. Greenberg, et al. A Clean Slate 4D Approach to Network Control and
Management. CCR, 35(5), Oct. 2005.
[19] J. C. Mogul, Y. M. Chan, and T. Kelly. Design, implementation, and evaluation
of duplicate transfer detection in HTTP . In Proc. of NSDI, 2004.
[20] J. W. Lockwood et al. NetFPGA - An Open Platform for Gigabit-rate Network
Switching and Routing . In Proc. IEEE MSE, 2007.
[21] R. Morris, E. Kohler, J. Jannotti, and M. F. Kaashoek. The click modular router.
SIGOPS Oper. Syst. Rev., 33(5):217–231, 1999.
[22] K. Park, S. Ihm, M. Bowman, and V. Pai. Supporting practical
content-addressable caching with CZIP compression. In Proc. of USENIX ATC,
2007.
[23] H. Pucha, D. G. Andersen, and M. Kaminsky. Exploiting similarity for
multi-source downloads using ﬁle handprints. In Proc. of NSDI, 2007.
[24] M. Rabin. Fingerprinting by random polynomials. Technical report, Harvard
University, 1981. Technical Report, TR-15-81.
[25] M. Roughan et al. Experience in Measuring Internet Backbone Trafﬁc
Variability:Models, Metrics, Measurements and Meaning. In ITC, 2003.
[26] S. Rhea, K. Liang, and E. Brewer. Value-based web caching. In Proc. of WWW,
2003.
[27] A. Shaikh and A. Greenberg. OSPF Monitoring: Architecture, Design and
Deployment Experience. In Proc. of NSDI, 2004.
[28] N. Spring, R. Mahajan, and D. Wetherall. Measuring ISP Topologies with
Rocketfuel. In Proc. of SIGCOMM, 2002.
[29] N. Spring and D. Wetherall. A protocol-independent technique for eliminating
redundant network trafﬁc. In Proc. of SIGCOMM, 2000.
[30] N. Tolia, M. Kaminsky, D. G. Andersen, and S. Patil. An architecture for
internet data transfer. In Proc. of NSDI, 2006.
[31] V. Sekar et al. cSamp: A System for Network-Wide Flow Monitoring. In Proc.
of NSDI, 2008.
[32] A. Wolman et al. On the scale and performance of cooperative Web proxy
caching. In Proc. of SOSP, 1999.
98