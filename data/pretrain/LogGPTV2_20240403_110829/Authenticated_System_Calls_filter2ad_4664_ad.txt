follows. First, the kernel is modiﬁed to maintain a single
counter variable for each process, initialized to 0 and stored
in kernel space. Then, the installer is changed to add one
variable to the data segment of each application to hold the
policy state (the byte string), and a second variable to hold a
MAC for the state. The state variable is initialized as needed
by the policy, and the state MAC is calculated over the ini-
tial state and the initial application counter value, 0. Point-
ers to the policy state and state MAC are then passed as
additional arguments in each authenticated system call.
At syscall checking time, if the policy for the system
call depends on the policy state, the kernel recomputes the
state MAC using the application counter and the policy state
passed in the call. If the recomputed MAC matches the state
MAC passed in by the application, the call is allowed to pro-
ceed; otherwise, the application is terminated. If the policy
requires changing the policy state, the kernel increments the
application’s state counter and calculates a new state MAC
over the new counter value and policy state. The new state
MAC is stored over the previous state MAC in application
space.
Once again, our cryptographic assumption is that it is
computationally infeasible for an adversary to compute a
valid MAC for some desired policy state and state counter.
The kernel-space state counter prevents the adversary from
re-using state MACs computed by the kernel for previous
states.
Call graph. A simple but useful example of a policy re-
quiring state is one based on the application’s call graph.
Such a policy could, for example, require that the applica-
tion’s system call trace be a path in the call graph, providing
further protection against compromised applications. Poli-
cies of this type are used by Wagner and Dean [22], who use
static analysis to construct a conservative approximation of
the call graph, which is then encoded as a ﬁnite automaton
for syscall checking.
Policies of this type are easily implemented with authen-
ticated system calls. The installer already computes the call
graph of the system calls of an application. Given this call
graph, we can label each node of the call graph by its call
site. The policy state becomes the call site of the last node
executed by the application. The policy of each system call
is then extended to say that the policy state must be one of
the predecessors of the system call in the static call graph.
Syscall checking in the kernel is extended to verify that the
previous call site is in the list of predecessors given in the
policy, and to update the policy state to the new call site.
As was the case with the general issue of state-based
policies, some of the work can be moved from the kernel
to the application to minimize the impact on the kernel. For
example, we could force the application to calculate the pre-
decessor of the node from the list of possibilities, and pass
this in to the kernel to verify.
Capability tracking. Another useful feature for policies
is the ability to specify that an argument to a system call
be based on arguments or return values of previous sys-
tem calls. An example would be a policy for a read sys-
tem call that requires that the ﬁle descriptor argument be a
value returned by a previous open system call [20]. We call
policies of this sort capability tracking policies, since such
arguments are being used in a manner analogous to capabil-
ities. We illustrate how the basic authenticated system call
approach can be extended to support this feature using the
example of ﬁle descriptor tracking.
A naive implementation of ﬁle descriptor tracking would
use policy state to store the last ﬁle descriptor returned by
each call to open. The policy for each read system call
would specify that the ﬁle descriptor should match the ﬁle
descriptor for the desired open system call. However, this
ignores the fact that an open system call can be executed
more than once, that more than one ﬁle descriptor returned
by the open can be active at once, and that ﬁle descriptors
can be reused after they have been closed.
A better approach is to store, for each open system call,
a set of currently active ﬁle descriptors. The policy for each
open then adds a ﬁle descriptor to the set, while the pol-
icy for close removes a ﬁle descriptor. This involves fairly
complicated data structures, so we would not use the sim-
ple policy state implementation described above, but rather
a more efﬁcient implementation based, for example, on au-
thenticated dictionaries.
5. Discussion
File name normalization. A recurring problem for sys-
tem call monitors has been dealing with race conditions
caused by features such as symbolic links and relative ﬁle
names. For example, consider a policy that allows an ap-
plication to open a temporary ﬁle, /tmp/foo. An attacker
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:08:19 UTC from IEEE Xplore.  Restrictions apply. 
could try to exploit this by creating a symbolic link named
/tmp/foo that points to /etc/passwd, and then overwriting the
password ﬁle by opening and writing /tmp/foo.
To avoid this, system call monitors often use the conven-
tion that a ﬁle name in a policy must refer to the normal-
ized ﬁle name, that is, the name of the ﬁle after all sym-
bolic links have been followed. While doing normalization
correctly can be complex, strategies developed elsewhere
for performing this step in the kernel during syscall check-
ing [4] apply to our approach. In addition, we anticipate
that it is possible to move some of the processing into the
untrusted application, using techniques similar to those de-
scribed above in section 4 for state-dependent policies.
Frankenstein attacks. An application protected by our
approach can become compromised, for example, through a
buffer overﬂow, giving an attacker control of the application
process. The process would not be able to execute arbitrary
system calls, but it could execute any authenticated system
calls in the application, provided it did not change the call
site and parameters covered by the policy. This can lead to
mimicry attacks [23], which are well known and which can
be defended against by using more precise policies.
Our current prototype implementation is vulnerable to a
similar, but more subtle attack: the compromised applica-
tion could execute authenticated system calls that it ﬁnds
in other applications on the system. Once the attacker has
control of an application, it might use it to examine the
other applications on the system, and construct and execute
a new application composed of authenticated system calls
from many applications. We call this a Frankenstein attack.
Call graph policies can defend against such Frankenstein
attacks. Recall that a call graph policy requires an applica-
tion to execute system calls in an order consistent with its
static call graph. The call graph of an application is self-
contained, so if we impose a call graph policy on all of
the applications, a Frankenstein program would be forced
into executing only the system calls of a single application,
namely, the application that supplies the ﬁrst authenticated
system call executed by the Frankenstein program. We only
need to take care that the installer use distinct labels for the
nodes of all the application programs.
Another kind of Frankenstein attack targets the string lit-
erals that can appear in policies. In the current implemen-
tation, a string literal that appears in a policy is encoded as
its address. The MAC produced is therefore dependent on
the address, and not the contents, of the string. We are re-
lying on the memory protections of the operating system to
prevent a rogue process from modifying its string literals.
However, it might be possible for a rogue process to build
an altered copy of itself, identical except for the contents
of some of the string literals, and transfer control (via exec)
to the copy, while respecting even a call graph policy. One
way to prevent this would be to protect the string contents
by a MAC rather than, or in addition to, the address. This
must be done with care, however, as the adversary gets to
choose the actual arguments to the system call, and could
pass in a very long string or an inaccessible address in an
attempt to disrupt the kernel system call checking code.
Related work. System call monitoring falls into the
broader area of intrusion detection systems. An intrusion
detection system can try to detect misuse (known attacks)
or anomalies (deviation from normal behavior). Misuse de-
tectors can be vulnerable to previously unknown attacks,
while anomaly detectors can suffer from false alarms. Our
system is an anomaly detector that avoids false alarms be-
cause of our conservative static analysis. The basic idea
of constructing semantic models of “legitimate” system call
behaviors for a program in terms of sequences of system
calls, and monitoring departures from such models, was
originally proposed by Forrest et al. [9, 24].
System call monitoring can be implemented entirely in
user space [12, 13], but typically this is not secure against
attacks such as buffer overﬂows, so this is not appropriate
for our setting. User-space implementations can be secure
for applications written in a safe language such as Java [21].
However, most systems have focused on applications writ-
ten in unsafe languages, so they are implemented entirely in
the kernel [2, 14, 19, 20] or by using kernel hooks or patches
in combination with a user-space policy daemon or monitor
[4, 5, 8, 11, 18, 22].
Our implementation uses a kernel modiﬁcation in com-
bination with binary modiﬁcations to the untrusted user ap-
plication itself, and does not rely on a separate policy dae-
mon. Instead, we use cryptographic and program checking
techniques to ensure that any work done by the untrusted
application regarding policy decisions is done correctly.
In comparison to systems implemented entirely in-
kernel, our kernel modiﬁcations are minor—a couple of
hundred lines of code compared to thousands with other
systems. A completely in-kernel implementation must
maintain the policies and the logic for determining which
policy applies to a given call; we place these burdens on
the application. Note in particular that the exact policy for a
given authenticated system call is provided by the call itself.
This gives us an advantage in speed and simplicity.
In comparison to systems implemented with user-space
policy daemons, we have the advantage of fewer context
switches, leading to a very modest overhead. Avoiding
a separate monitor process simpliﬁes policy checking, be-
cause the operating environment (current working directory,
etc.) does not have to be mirrored, some race conditions are
avoided, and we do not have to protect against the user ap-
plication killing the monitor.
Policies for most system call monitors are developed by
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:08:19 UTC from IEEE Xplore.  Restrictions apply. 
hand or by training; Wagner and Dean [22] is the only other
system we are aware of that uses static analysis. Wagner et
al. [22, 23] introduced mimicry attacks and suggested mak-
ing policies more precise to combat them; authenticating
system call arguments and using call graph policies are two
of their suggestions that we use.
6. Conclusions
Attacks that attempt to compromise a computer system
using the system call interface are an increasingly important
threat. Monitoring system calls and disallowing those that
do not conform to a program’s security policy is an effec-
tive mechanisms for stopping a large class of such attacks.
Essentially, a system call monitor can convert a potentially
successful attack into a fail-stop failure [16] of the compro-
mised process.
In this paper, we presented authenticated system calls,
a novel approach to system call monitoring. This approach
has been implemented using only small modiﬁcations to the
kernel, without the need for heavyweight kernel data struc-
tures or the use of a user-space policy daemon at runtime.
We also presented an automated approach for generating se-
curity policies based on static analysis, something that can
be extended using other techniques if necessary.
We evaluated the approach on Linux and, for policy gen-
eration, on OpenBSD. In doing so, we provided measures
of the effectiveness of policy generation and quantiﬁed the
modest runtime impact of using authenticated system calls
over unprotected ones. We also presented a number of ex-
tensions to the basic approach that can increase its effective-
ness by improving the expressiveness of policies.
Acknowledgments
S. Debray provided valuable insights on the technical issues
in this paper. This work was supported in part by NSF under
grants EIA-0080123, CCR-0113633, and CNS-0410918.
References
[1] A. Aho, R. Sethi, and J. Ullman. Compilers: Principles,
Techniques, and Tools. Addison-Wesley, 1986.
[2] M. Bernaschi, E. Gabrielli, and L. Mancini. Operating sys-
tem enhancements to prevent the misuse of system calls. In
ACM CCS, pages 174–183, 2000.
[3] M. Blum, W. Evans, P. Gemmell, S. Kannan, and M. Naor.
Checking the correctness of memories. In IEEE Symp. on
Foundations of Computer Science, pages 90–99, 1991.
[4] T. Garﬁnkel. Traps and pitfalls: Practical problems in sys-
tem call interposition based security tools. In Network and
Distributed Systems Sec. Symp., 2003.
[5] T. Garﬁnkel, B. Pfaff, and M. Rosenblum. Ostia: A dele-
gating architecture for secure system call interposition. In
Network and Distributed Systems Sec. Symp., 2004.
[6] J. Geovedi, J. Nazario, N. Provos, and D. Song. Project hairy
eyeball. http://blafasel.org/∼ﬂoh/he/.
[7] B. Gladman. AES combined encryption/authentication li-
brary. http://fp.gladman.plus.com/AES/index.htm.
[8] I. Goldberg, D. Wagner, R. Thomas, and E. Brewer. A secure
In Usenix
environment for untrusted helper applications.
Sec. Symp., 1996.
[9] S. Hofmeyr, S. Forrest, and A. Somayaji. Intrusion detec-
tion using sequences of system calls. Journal of Computer
Security, 6(3):151–180, 1998.
[10] T. Iwata and K. Kurosawa. OMAC: One-key CBC MAC,
2002.
[11] K. Jain and R. Sekar. User-level infrastructure for system
call interposition: A platform for intrusion detection and
conﬁnement. In ISOC Network and Distributed Sec. Symp.
(NSDD00), pages 19–34, 2000.
[12] M. Jones.
Interposition agents: Transparently interposing
user code at the system interface. In ACM SOSP, pages 80–
93. 1993.
[13] E. Krell and B. Krishnamurthy. COLA: Customized over-
laying. In Winter USENIX Conf., pages 3–7. Jan. 1992.
[14] C. Kruegel, D. Mutz, F. Valeur, and G. Vigna. On the de-
tection of anomalous system call arguments. In LNCS 2808,
pages 326–43, 2003.
[15] N. Provos. Improving host security with system call policies.
In USENIX Sec. Symp., 2003.
[16] R. Schlichting and F. Schneider. Fail-stop processors: An
approach to designing fault tolerant computing systems.
ACM TOCS, 1(3):222–238, Aug. 1983.
[17] B. Schwarz, S. Debray, and G. Andrews. Plto: A link-time
optimizer for the Intel IA-32 architecture. In Workshop on
Binary Translation (WBT-2001), 2001.
[18] R. Sekar, M. Bendre, D. Dhurjati, and P. Bollineni. A fast
automaton-based method for detecting anomalous program
behaviors. In IEEE Symp. on Sec. and Priv., pages 144–155,
2001.
[19] R. Sekar and P. Uppuluri. Synthesizing fast intrusion pre-
vention/detection systems from high-level speciﬁcations. In
8th USENIX Sec. Symp., pages 63–78, 1999.
[20] R. Sekar, V. Venkatakrishnan, S. Basu, S. Bhatkar, and
D. DuVarney. Model-carrying code: A practical approach
for safe execution of untrusted applications. ACM SOSP,
Oct. 2003.
[21] V. Venkatakrishnan, R. Peri, and R. Sekar. Empowering mo-
bile code using expressive security policies. In Workshop on
New Sec. Paradigms, pages 61–68. 2002.
[22] D. Wagner and D. Dean. Intrusion detection via static analy-
sis. In IEEE Symp. on Sec. and Priv., pages 156–169, 2001.
[23] D. Wagner and P. Soto. Mimicry attacks on host-based intru-
sion detecion systems. In ACM CCS, pages 255–264, 2002.
[24] C. Warrender, S. Forrest, and B. Pearlmutter. Detecting in-
In
trusions using system calls: Alternative data models.
IEEE Symp. on Sec. and Priv., 1999.
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:08:19 UTC from IEEE Xplore.  Restrictions apply.