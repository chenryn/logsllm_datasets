title:A case for a coordinated internet video control plane
author:Xi Liu and
Florin Dobrian and
Henry Milner and
Junchen Jiang and
Vyas Sekar and
Ion Stoica and
Hui Zhang
A Case for a Coordinated Internet Video Control Plane
Xi Liu,
Florin Dobrian,
Henry Milner
Conviva
Junchen Jiang
CMU
Vyas Sekar
Intel Labs
Ion Stoica
Conviva
UC Berkeley
Hui Zhang
Conviva
CMU
ABSTRACT
Video trafﬁc already represents a signiﬁcant fraction of today’s traf-
ﬁc and is projected to exceed 90% in the next ﬁve years. In parallel,
user expectations for a high quality viewing experience (e.g., low
startup delays, low buffering, and high bitrates) are continuously
increasing. Unlike traditional workloads that either require low la-
tency (e.g., short web transfers) or high average throughput (e.g.,
large ﬁle transfers), a high quality video viewing experience re-
quires sustained performance over extended periods of time (e.g.,
tens of minutes). This imposes fundamentally different demands
on content delivery infrastructures than those envisioned for tradi-
tional trafﬁc patterns. Our large-scale measurements over 200 mil-
lion video sessions show that today’s delivery infrastructure fails
to meet these requirements: more than 20% of sessions have a re-
buffering ratio ≥ 10% and more than 14% of sessions have a video
startup delay ≥ 10s. Using measurement-driven insights, we make
a case for a video control plane that can use a global view of client
and network conditions to dynamically optimize the video delivery
in order to provide a high quality viewing experience despite an
unreliable delivery infrastructure. Our analysis shows that such a
control plane can potentially improve the rebuffering ratio by up to
2× in the average case and by more than one order of magnitude
under stress.
Categories and Subject Descriptors
C.2.4 [Computer-Communication Networks]: Distributed sys-
tems—Distributed applications; C.4 [Performance of Systems]:
[measurement techniques]
General Terms
Design, Performance, Measurement
Keywords
Video, CDNs, Control plane
1.
INTRODUCTION
Over the last few years, video trafﬁc has quickly become the
dominant fraction of Internet data trafﬁc. Studies show that Netﬂix
alone accounts for more than 20% of the US Internet trafﬁc [42]
and projections show that by 2014, video trafﬁc will constitute
more than 90% of the total trafﬁc on Internet [2]. These estimates
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
SIGCOMM’12, August 13–17, 2012, Helsinki, Finland.
Copyright 2012 ACM 978-1-4503-1419-0/12/08 ...$15.00.
are for streaming trafﬁc (including both live and video-on-demand
services) and does not include ofﬂine video downloads (e.g., via
shared upload or P2P services).
User expectations in streaming video workloads impose funda-
mentally different service requirements on the network infrastruc-
ture compared to traditional data trafﬁc. Traditional workloads fo-
cus either on latency (e.g., interactive sessions or short web trans-
fers) or on transfer completion time (e.g., long ﬁle transfers). In
contrast, latency is less critical in streaming video because applica-
tion data units are large enough to amortize latency effects. Simi-
larly, overall completion time does not really reﬂect the actual user
experience as it does not capture rebuffering-induced interruptions;
we know that users are sensitive to buffering as a 1% increase in
buffering can lead to more than a 3 minutes reduction in expected
viewing time [21]. Streaming video not only introduces new qual-
ity metrics at the network- and user-level, but also requires that this
quality (e.g., high bitrates with low rebuffering) be sustained over
extended periods of time as typical videos span multiple minutes.
In addition to the improvements last-mile connectivity, a key
driver for the rapid explosion of streaming video trafﬁc has been the
shift from specialized streaming protocols and infrastructure (e.g.,
Windows Media Services, RealNetworks, RTMP) to HTTP chunk-
based streaming protocols (e.g., [5, 42]). This use of a commodity
service dramatically decreases the cost of dissemination and the
barrier of entry by allowing content providers to leverage existing
HTTP CDN infrastructures to deliver content to a wide audience.
Furthermore, the reliance on HTTP also implies the ability to sup-
port multiple viewing platforms as HTTP support is ubiquitous.
Unfortunately, there is a mismatch between the requirements of
video streaming and the architecture of today’s HTTP-based video
delivery infrastructures, both at the ISP and CDN level. Using
ﬁne-grained client-side measurements from over 200 million client
viewing sessions, we ﬁnd that 20% of these sessions experience a
rebuffering ratio of ≥ 10%, 14% of users have to wait more than
10 seconds for video to start up, more than 28% of sessions have
an average bitrate less than 500Kbps, and 10% of users fail to see
any video at all.
midstream?
ity across different geographical regions and ISPs,
Analyzing the causes of these performance problems reveals:
• signiﬁcant spatial diversity in CDN performance and availabil-
• substantial temporal variability in the CDN performance and
• poor system response to overload scenarios when there are “hotspots”
client-side network performance, and
of client arrivals in particular regions or ISPs.
Our overarching goal is to meet the demands for a high-quality
viewing experience despite an unreliable video delivery infrastruc-
ture. In this context, the design space for optimizing video delivery
quality consists of three high-level dimensions:
1. What parameters can we adapt; e.g., bitrate, CDN?
2. When are these parameters optimized; e.g., at video startup or
3593. Who chooses these parameters; e.g., client or server?
The above observations regarding CDN variability across space
and time suggest that purely server- or client-driven selection and
adaptation are unlikely to be sufﬁcient. To this end, we envision
a video control plane that can use a global view of network and
CDN performance to dynamically assign clients a suitable choice
of CDN and bitrate that optimizes the video delivery. Beyond
the performance beneﬁts, such a control plane also offers content
providers more ﬂexibility in instrumenting ﬁne-grained policies;
e.g., providing higher quality service to premium customers un-
der load, ensuring that certain types of content is only accessible
with speciﬁc geographical regions, or taking into account the cost-
performance tradeoffs that different CDNs have to offer [29].
Realizing such a control plane is challenging, and thus a natural
ﬁrst question is whether this exercise is worthwhile. To this end, we
use a measurement-driven framework to extrapolate the potential
for improvement in video quality. We observe that there is signif-
icant potential and that even just choosing a CDN more optimally
can reduce the average rebuffering ratio by 2× in the common case
and more than 10× under extreme scenarios.
We would also like to conﬁrm that these gains are not merely
hypothetical. To do so, however, we need to concretely specify
aspects of the control plane such as the allocation algorithms, per-
formance estimators, and policy functions. To this end, we present
one speciﬁc realization of such a control plane to illustrate the ben-
eﬁts. Our choices in this respect are far from ideal and have to
necessarily embed several simplifying assumptions. We believe
this exercise is still valuable because our goal is to make a case
for a control plane, rather than present a reference design and im-
plementation. Our simulations conﬁrm that such an approach can
outperform other options in the design space for optimizing video
delivery in both common and extreme load scenarios.
Contributions and Roadmap: To summarize, our key contribu-
tions are:
• Measurements to expose the shortcomings of today’s video de-
livery infrastructure (Section 2) that motivate the need for a
video control plane (Section 3).
• Using an extrapolation approach to establish the potential room
• Corroborating these potential gains under a concrete (but sim-
for improvement (Section 4).
pliﬁed) operation model (Section 5 and Section 6).
We discuss outstanding issues in Section 7 and place our work
in the context of related work in Section 8 before concluding in
Section 9.
2. MOTIVATION
Previous research has conﬁrmed the impact of quality on user
experience to show that users are quite sensitive to buffering and
high startup latency, and prefer higher bitrate content [3,21]. Given
this need for high-quality video delivery, we analyze how today’s
infrastructure performs.
In this section, we examine the performance of today’s delivery
infrastructure and highlight potential sources of inefﬁciencies. We
begin by focusing on the end-user streaming video performance.
Then, we identify three potential sources of performance prob-
lems: variability in client-side, variability within a single ISP or
Autonomous System (AS), and variability in CDN performance.
2.1 Dataset
The dataset used in this paper is based on one week of client-side
measurements from over 200 million viewing sessions or views
(both successful and failed) from over 50 million viewers across
91 popular video content providers around the world. The chosen
week includes a single large live event lasting two hours, but other-
wise has normal trafﬁc. Table 1 summarizes the data set. The con-
tent served by these providers includes both live (e.g., sports broad-
casts) and video-on-demand (e.g., TV episodes and movies). Since
we observe similar results from both live and video-on-demand
trafﬁc, we show results only on aggregate data from both types of
trafﬁc. The data was generated via client-side player instrumenta-
tion that collects statistics regarding the current network conditions
(e.g., estimated bandwidth to the chosen CDN server) and the ob-
served video quality (e.g., rebuffering ratio, chosen bitrate). Many
of the content providers have the option to deliver content to their
customers from multiple CDNs; the speciﬁcs of how they choose
CDNs is proprietary. Due to business and anonymity considera-
tions, we anonymize the providers, CDNs, ISPs, and cities in the
following results. Our goal here is to highlight the overall prob-
lems in video delivery in general rather than pinpoint inefﬁciencies
of speciﬁc ISPs or CDNs.
Time
Views
Viewers
View hours
Content providers
Videos
Countries / Regions
2011.12.10 - 2011.12.17
281M
54M
30M
91
2M
231
Table 1: Dataset Summary
its lifetime.
starts to play.
Metrics: We focus on the following industry-standard video qual-
ity metrics [6, 42]:
• Average bitrate: The average bitrate experienced by a view over
• Rebuffering ratio: This is computed the buffering time divided
by buffering plus playing time, excluding paused or stopped
time and buffering time before video start. (We use the term
rebuffering ratio and buffering ratio interchangeably.)
• Startup time: This is the wait or buffering time before a video
• Failure rate: This is the percentage of views that failed to start
playing and experienced a fatal error during the process. In our
experience, these fatal errors usually indicate CDN issues. One
example is missing content that the CDN failed to populate to
edge servers, and thus users cannot access the video. Another
possibility is the CDN server rejecting new connections (e.g.,
due to overload).
• Exits before video start: This is the percentage of views that
failed to play the video without experiencing a fatal error. There
are generally two causes: (1) users are not interested in the con-
tent, and (2) users waited too long for the video to load and lose
patience.
We choose these metrics because earlier work showed that they
have a signiﬁcant impact on user engagement [21]. Our goal is
not to design an aggregate quality metric that can combine these
factors (e.g., [8]). Rather, we want to show the inefﬁciencies of
today’s infrastructure and provide directions to improve the video
quality. Thus, we consider each metric in isolation in this study.
2.2 Video quality today
We begin by analyzing the video quality that today’s delivery
infrastructure provides before looking at more in-depth analysis to
understand reasons for this inefﬁciency.
360(a) Rebuffering Ratio
(b) Video Startup Time
(c) Average Bitrate
Figure 1: Distribution of three standard video quality metrics computed over > 200 million user views across 91 providers. The
result shows that a non-trivial fraction of views suffer quality issues.
times are more likely to return to the content providers, and view-
ers who receive higher bitrate videos are likely to watch the video
longer [21]. Our analysis indicates that today’s end user experi-
ence is far from perfect, and highlights the need for performance
optimization.
2.3 Sources of quality issues
(a) Intra-session
(b) Inter-session
Figure 2: There is signiﬁcant variability in client-side band-
width both within and across sessions conﬁrming the need for
bitrate adaptation.
Figure 1 shows the distribution of rebuffering ratio, video start
up time, and average bitrate from views that have started the video
playing. Note that these are the observed performances in the wild
with the default video players that the providers use. For rebuffer-
ing ratio and average bitrate, we remove sessions less than one
minute, because they usually come from users that are not inter-
ested in the video.
20% experience at least 10% rebuffering ratio.
The result shows that
• 40% of the views experience at least 1% rebuffering ratio, and