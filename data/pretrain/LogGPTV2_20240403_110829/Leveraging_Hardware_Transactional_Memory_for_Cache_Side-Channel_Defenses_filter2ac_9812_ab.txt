very end of the transaction. Both approaches guarantees that after
a successfully committed transaction, the cache footprint of the
security-critical region is independent of the secret. However, cache
preloading has two additional benefits: First, by preloading all mem-
ory regions that will be used in the transaction at the beginning,
execution of the security-critical region will only have cache hits,
e.g., in Evict-Time, preloading guarantees all the security-critical
region is present in cache before execution and in Cache-Collision,
there is no cold miss when executing security-critical region. There-
fore, the total execution time of this region will be independent of
the secrets; thus requirement S2 is met. Moreover, cache preloading
also guarantees that a prematurely terminated transaction will also
have the same cache footprint regardless of the secrets. Therefore,
requirement S3 is met. As such, by preloading relevant memory
regions into cache at the beginning of the transaction, both security
requirements S2 and S3 are satisfied.
Minimizing transactions by breaking down security-critical
regions: Large security-critical regions may cause self-conflicts in
cache when executed inside a memory transaction, thus terminating
the transaction during its execution. Moreover, longer execution
time of a security-critical region will have higher probability to
be interrupted. As such, it is important to select security-critical
regions that are small enough to fit into a transaction without
self-conflicts, and a short enough, in terms of execution time, that
will finish without software or hardware interruption with high
probability. To minimize the generated transactions, the developer
must break down one entire security-critical region into several
pieces. If it is impossible to do so, the code must be refactored.
Re-entering transactions to avoid false positives: Since a trans-
action may abort due to various reasons, even when it is not under
active side-channel attacks, false detection of S1 violation is pos-
sible. Following terms used in intrusion detection, we use false
positives to refer to such false detection of S1 violation when the
program is not under cache side-channel attacks, and use false neg-
atives to refer to cases where cache side-channel attacks is taking
place but the program fails to detect such occurrences. In order
to reduce false positives, instead of jumping directly to a failure
handling path immediately after the transaction aborts, the transac-
tional execution is re-entered a few times before failing indefinitely.
4 IMPLEMENTATION
In this section, we detail our implementation of the solution. We
particularly discuss a set of techniques to reduce transaction aborts.
System calls. System calls will lead to privilege-level switch, which
will result in transaction aborts. Therefore, the security-critical re-
gion that is encapsulated in the hardware transactions should not
include any system calls. Any I/O operations are similarly disal-
lowed. Our implementation specially avoids including system calls
and I/O operations in transactions. Another complication is that dy-
namic memory allocation through malloc() also requires to issue
system calls to request kernel service. To avoid transaction aborts
due to memory allocation, we pre-allocate a large chunk of memory
from the heap before the transaction starts, and implements a new
user-level memory allocation interface to allocate and free memory
buffers from this managed memory chunk.
Page faults. Page faults, if not handled properly, are one of the
most common reasons to abort a transaction. All virtual memory
pages that need to be accessed within the transaction has to be
touched before the transaction starts, so that the page table entries
corresponding to the work set of the transaction are properly set up.
Particularly, to warm up the code pages, our implementation first
obtains the start address and end address of the code segment, and
then reads one word in each page of the code segment. To warm up
the writable static data and heap accessed by the transaction, we
write to each page before the transaction starts. To warm up the
stack, our implementation calls a dummy function that writes to a
local data array that is large enough. In this way, when returned
from the dummy function, we are certain that the stack has enough
mapped memory to be used during the execution of the transaction.
Code refactoring. When security-critical code region is too large
to be placed into one transaction, we refactor the code region
to fit into the transaction. One such technique is to avoid call-
ing non-security-critical functions in security-critical code region.
If additional function calls are inevitable, we move the function
call site outside transaction. We will illustrate such techniques in
case studies. It is worth emphasizing that after the refactoring, the
security-critical regions become small. However, as long as the
region is larger than a cache line, the program’s access pattern in
these cache lines can leak information of the control flow inside
the security-critical region which needs refactoring.
Abort reasoning. With the assistance of Linux perf tool, one can
debug the transaction code to identify the reasons of transaction
aborts. However, as perf only reports the abort code that corre-
sponds to one of the six general categories, it is difficult to precisely
identify the true reason of transaction aborts. To ensure low trans-
action abort rate, the developer can leverage hardware performance
counters to sample TSX related events to report the instructions
that cause the aborts and try to reduce the abort rate accordingly.
4.1 Examples
To demonstrate the use of hardware transactional memory for side-
channel defenses, we applied our design to protect several known
vulnerable cryptographic implementations.
AES in OpenSSL. The C implementation of AES in OpenSSL has
been shown to be vulnerable to various side-channel attacks [3],
because the AES table lookup indices are directly related to the
round keys. In particular, the AES tables are security-critical data
structures that needs to be protected. We enclose the whole block
encryption/decryption function in one transaction. Only two mi-
nor changes were required: 1) Before entering the transaction, we
need to “touch” the data pages to avoid page faults. The data pages
include the AES tables, round keys, buffers for the plaintext and ci-
phertext. 2) At the beginning of the transaction, five 1-KB AES tables
are preloaded into the cache. The AES block encryption/decryption
is short enough with very low probability to be interrupted.
ECDSA in OpenSSL. The Elliptic Curve Digital Signature Algo-
rithm (ECDSA) algorithm in OpenSSL v1.0.1e has been shown vul-
nerable to cache side-channel attacks [23]. Particularly as shown in
Listing 2 (in Appendix B due to the space limitation), in the inner
loop of ec_GF2m_montgomery_point_multiply() of the Mont-
gomery ladder algorithm is security-critical, which is enclosed
in one transaction. However, because both Madd() and Mdouble()
(name shorten for convenience) calls a large number of functions
internally, including them in transaction will result in transac-
tion abort almost every time. Therefore, we refactored the code
to keep security-critical region small. New code is shown in List-
ing 3 (in Appendix B). In addition to code refactoring, two minor
changes are made to adapt Montgomery ladder algorithm to TSX:
1) Before entering the transaction, we touch first and last word of
ec_GF2m_montgomery_point_multiply() to avoid page faults. 2)
At the beginning of the transaction, we preload this function into
cache for security purposes.
Modular exponentiation in mbedTLS-SGX. Intel SGX have been
shown susceptible to cache side-channel attacks [20]. We show that
vulnerable code run in SGX can also be protected using transac-
tional memory. In mbedtls-SGX, modular exponentiation is imple-
mented using the square-and-multiply algorithm which has been
shown vulnerable to side-channel attacks. We refactored the piece
of code as is shown in Listing 4 (in Appendix B). Particularly, it
performs multiplication operation regardless of the bit value, and
use transactional memory to protect the test of the bit value to
prevent side-channel leakage.
5 EVALUATION
We evaluated performance overhead for cryptographic libraries
due to our defense mechanisms using both micro benchmarks and
macro benchmarks. All empirical evaluations were conducted on
an Intel Core i5 6440HQ processor (single socket, 4 CPU cores, and
1 thread per core) with 32KB L1 instruction/data caches, 256KB L2
caches, and 3MB LLC. The maximum allowed consecutive transac-
tion aborts (i.e., the threshold) is 10000 in all experiments.
5.1 Micro Benchmarks
Micro benchmarks of the cryptographic code test performance of a
particular cryptographic operation. Therefore, these results reflects
the cost of protection on the algorithms themselves. We particularly
tested the overhead of OpenSSL’s AES and ECDSA implementation
and the mbedTLS’s RSA implementation. In all experiments we
report below, no execution failure due to excessive transaction
aborts (more than the threshold, i.e., 10000) was observed.
AES in OpenSSL. To test the overhead on AES encryption, we
used OpenSSL’s built-in speed command line tools to test OpenSSL
v1.0.2f, with and without protection and evaluate throughput of
the AES encryption. We tested 6 combinations of key size and
mode of operations: aes-128-cbc, aes-192-cbc, aes-256-cbc,
aes-128-ige, aes-192-ige, and aes-256-ige. We converted the
output of the tool to reflect processing time for each byte, and
illustrate the results in Fig. 1a. We can see that the performance
overhead of the protection ranges from 34.1% to 42.7%. We also
measured the abort rate of the hardware transactions using Linux’s
perf, a performance profiling tool using hardware performance
counters. In the experiments shown in Fig. 1a, when the protected
code is executed, the transaction abort rate on average was 0.0189%.
ECDSA in OpenSSL. We tested the ECDSA implementation in
OpenSSL 1.0.1e using OpenSSL speed command line tool with
the following six algorithms: ecdsak163, ecdsak283, ecdsak571,
ecdsab163, ecdsab283, and ecdsak571. Measured average pro-
cessing time of ECDSA signing with and without protection is
shown in Fig. 1b. Performance overhead for these selected parame-
ter settings is between -0.497% and 0.883%. The performance gain
with the protected version in some cases is presumably due to code
refactoring. The abort rate measured by perf was 0.001%.
RSA in mbedtls-SGX. We tested the performance overhead of the
RSA implementation in mbedtls-SGX due to our protection. The
overhead is measured by the execution time of an RSA decryption
(an average of 10 runs). The experiment result suggest that after ap-
plying the protection, the performance overhead is 1.107% without
any transaction aborts (as measured by perf).
5.2 Macro Benchmarks
To test the performance impact of the defense to real-world applica-
tions, we set up an Apache HTTPS web server (version 2.4.25) which
is dynamically linked to an OpenSSL library (i.e., libcrypto.so)
with the AES and ECDSA implementations protected using the
hardware transactional memory. In the following tests, the HTTPS
clients were run on a different machine that is connected with the
server through a local area network. In all experiments we report
below, no execution failure due to excessive transaction aborts
(more than the threshold, i.e., 10000) was observed.
(a) Per byte processing time of OpenSSL AES
decryption.
(b) Processing time of OpenSSL ECDSA sign-
ing.
(c) HTTPS latency with varying sizes of the
requested files.
(d) HTTPS latency with varying concurrent
connections.
(e) HTTPS latency with varying ciphersuites. (f) SSL handshake latency with varying ci-
phersuites.
Figure 1: Performance evaluation. Cipher 1 - 6 in are ECDHE-ECDSA-AES256-GCM-SHA384, ECDHE-ECDSA-AES256-SHA384,
ECDHE-ECDSA-AES256-SHA, ECDHE-ECDSA-AES128-GCM-SHA256, ECDHE-ECDSA-AES128-SHA256, and ECDHE-ECDSA-
AES128-SHA.
used were ECDHE-RSA-AES256-SHA. The results are shown in
Fig. 1d. We can see that performance overhead is between 0%
and 1.85%. Therefore, we can conclude with concurrent HTTPS
requests, the transaction-based protection still work well.
• We tested the response latency under 6 ciphersuites with 1 con-
current connection and the 1KB fetched file size. We show the
results in Fig. 1e. From the figure we can see that the perfor-
mance overhead is between -1.9% and 3.6%.
• We used httperf [15] to generate requests for 1KB files us-
ing HTTPS with the ECDHE-RSA-AES256-SHA ciphersuite. The
httperf tool makes a specified and fixed number of connec-
tions with the HTTPS server (with 1 request per connection)
and measures response rate. We altered the request rate until
the Apache web server’s response rate could not keep up with
requests. The result is shown in Fig. 2. It can be seen that two
curves for the server throughput with and without protection
are almost the same. The saturate point without protection was
235.1 request per second, and server’s saturation point with our
protection was 234.9. Throughput drop was less than 0.1%.
SSL handshake performance with ECDSA signatures. We linked
the Apache web server to an OpenSSL 1.0.1e library. We used the
OpenSSL’s s_time command line to test the performance of the
handshake. The evaluation results are shown in Fig. 1f, which indi-
cate the overhead is between 2.5% and 5.1%.
6 DISCUSSION
Our solution cannot be used to defeat side-channel attacks that are
initiated from another thread sharing the same core and the pro-
tected code must avoid running on processors with HyperThread-
ing enabled. Our current design requires the source code of the
protected programs. However, by leveraging binary reassembly
Figure 2: Throughput of Apache HTTPS server
Overhead of Apache web servers due to protected AES en-
cryption/decryption. We conducted four sets of experiments to
test the performance overhead to Apache web servers when the
AES encryption was protected by the transactions and client runs
an ApacheBench [6] to conduct the performance testing:
• We tested the latency of of the Apache web server when the
fetched file size varies, with 64B, 1KB, 64KB, 1MB, and 64MB
files and each file was requested 100 times. The ciphersuite
used in these tests were ECDHE-RSA-AES256-SHA and the con-
current connection number was 1. The results are shown in
Fig. 1c. We can see when the protection is applied to AES en-
cryption/decryption, the latency of the HTTPS request only
increases slightly (less than 7.1%, and 0 to 1% in most cases).
Note the y-axis in the figure is in log scale.
• We generated HTTPS requests with 2, 4, 8, 16, 32, and 64 con-
current connections. Fetched file size was 1KB and ciphersuite
aes-128-cbcaes-192-cbcaes-256-cbcaes-128-igeaes-192-igeaes-256-igeOpenSSLAESCiphers0.10.20.30.40.50.60.70.80.91.0PerByteProcessingTime(s)1e-8WithoutProtectionWithProtectionecdsak163ecdsak283ecdsak571ecdsab163ecdsab283ecdsab571OpenSSLECDSACiphers0.0050.0100.0150.020ProcessingTime(s)WithoutProtectionWithProtection64B1KB64KB1MB64MBRequest(AES)FileSize101102103ProcessingTime(ms)WithoutProtectionWithProtection248163264ConcurrentConnections050100150200250300ProcessingTime(ms)WithoutProtectionWithProtectionCipher1Cipher2Cipher3Cipher4Cipher5Cipher6Request(AES)CipherSuite0510152025303540ProcessingTime(ms)WithoutProtectionWithProtectionCipher1Cipher2Cipher3Cipher4Cipher5Cipher6Request(ECDSA)CipherSuite0246810ProcessingTime(ms)WithoutProtectionWithProtection200205210215220225230235240Request Rate (REQ/s)200205210215220225230235240Response Rate (RESP/s)Without ProtectionWith Protectiontechniques, it is possible to disassemble the binary code, apply our
mechanism to protect critical regions, and recompile the source
code into binary. We have discussed in Sec. 3 that the program must
be allowed to re-enter the transaction if it only aborts a number of
times that is lower than the threshold. A reasonably high threshold
is preferred in practice, which will reduce false positives; but it
should be kept low enough to prevent infinite loops.
7 RELATED WORK
Closest to our work are solutions that build defense mechanisms
into the protected programs themselves. One such method is soft-
ware transformation. Molnar et al. [14] proposed a program counter
security model to eliminate secret-dependent control flows. Zhang
et al. proposed methods to equip guest VMs with capabilities to
detect existence of third-party VMs in public clouds [25] and to ob-
fuscate cache contents to defeat L1 cache side-channel attacks [28].
Our solution can also help tenants of public clouds to protect their
programs running in their own VMs. But our method also works
in non-virtualized or SGX settings.
Although Intel TSX has been proposed as a mechanism for im-
plementing concurrent programs, it has been leveraged to enhance
system security in several previous studies, e.g., Liu et al. [13] pro-
posed to use of Intel TSX in virtual machine introspection.
Concurrent to our work is a paper published recently by Gruss
et al. [7], which also studied the use of TSX for cache side-channel
defenses. Although these two papers achieves similar security prop-
erties by leveraging Intel TSX, they differ in the following aspects:
(1) In contrast to Gruss et al., our paper discusses TSX-based de-
fenses against not only Prime-Probe and Flush-Reload cache
side-channel attacks but also Evict-Time and Cache-Collision
attacks; (2) the security analysis in our paper arrives a similar con-
clusion from different angles; (3) our performance evaluation was
conducted using Apache HTTPS web server linked to the OpenSSL
library, validating the feasibility of this approach in practical uses,
while Gruss et al. only applied the solution to cryptographic algo-
rithms to demonstrate the defenses.
8 CONCLUSIONS
In conclusion, this paper presents a defense against cache side-
channel attacks using hardware transactional memory that is al-
ready available in modern processors. The paper provides a sys-
tematic analysis of the security requirements that a software-only
solution must meet to defeat cache attacks, and then propose a
software design that leverages Intel TSX to satisfy these require-
ments. The defense mechanisms have been implemented on several