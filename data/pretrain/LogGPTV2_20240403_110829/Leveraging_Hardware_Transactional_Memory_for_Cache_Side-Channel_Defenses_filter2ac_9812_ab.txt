### Optimized Text

#### End of the Transaction
Both approaches ensure that, after a successfully committed transaction, the cache footprint of the security-critical region is independent of the secret. However, cache preloading offers two additional benefits:
1. **Cache Hits Only**: By preloading all memory regions that will be used in the transaction at the beginning, the execution of the security-critical region will only experience cache hits. For example, in Evict-Time, preloading guarantees that the entire security-critical region is present in the cache before execution. In Cache-Collision, there are no cold misses when executing the security-critical region. This ensures that the total execution time of this region is independent of the secrets, thereby meeting requirement S2.
2. **Consistent Cache Footprint on Premature Termination**: Cache preloading also ensures that a prematurely terminated transaction will have the same cache footprint regardless of the secrets. This meets requirement S3.

By preloading relevant memory regions into the cache at the beginning of the transaction, both security requirements S2 and S3 are satisfied.

#### Minimizing Transactions by Breaking Down Security-Critical Regions
Large security-critical regions can cause self-conflicts in the cache when executed inside a memory transaction, leading to premature termination. Additionally, longer execution times increase the likelihood of interruptions. Therefore, it is crucial to select security-critical regions that are small enough to fit into a transaction without self-conflicts and short enough to complete without software or hardware interruptions with high probability. To minimize generated transactions, developers must break down large security-critical regions into smaller pieces. If this is not possible, the code should be refactored.

#### Re-entering Transactions to Avoid False Positives
A transaction may abort for various reasons, even in the absence of active side-channel attacks, leading to false positives. In intrusion detection terminology, false positives refer to incorrect detection of S1 violations when the program is not under cache side-channel attacks, while false negatives occur when cache side-channel attacks are taking place but the program fails to detect them. To reduce false positives, instead of immediately jumping to a failure handling path after a transaction aborts, the transactional execution is re-entered a few times before failing indefinitely.

### Implementation
In this section, we detail our implementation of the solution, focusing on techniques to reduce transaction aborts.

#### System Calls
System calls lead to privilege-level switches, which result in transaction aborts. Therefore, security-critical regions encapsulated in hardware transactions should not include any system calls or I/O operations. Our implementation avoids including system calls and I/O operations in transactions. Additionally, dynamic memory allocation through `malloc()` requires system calls to request kernel services. To avoid transaction aborts due to memory allocation, we pre-allocate a large chunk of memory from the heap before the transaction starts and implement a new user-level memory allocation interface to manage this memory.

#### Page Faults
Page faults, if not handled properly, are a common cause of transaction aborts. All virtual memory pages that need to be accessed within the transaction must be touched before the transaction starts to ensure the page table entries are correctly set up. Specifically, to warm up the code pages, our implementation reads one word in each page of the code segment. For writable static data and the heap, we write to each page before the transaction starts. To warm up the stack, we call a dummy function that writes to a local data array, ensuring the stack has enough mapped memory for the transaction.

#### Code Refactoring
When a security-critical code region is too large to fit into one transaction, we refactor the code to fit. One technique is to avoid calling non-security-critical functions within the security-critical region. If additional function calls are necessary, we move the function call site outside the transaction. After refactoring, the security-critical regions become smaller, but as long as the region is larger than a cache line, the access pattern can still leak information about the control flow, necessitating further refactoring.

#### Abort Reasoning
Using the Linux `perf` tool, developers can debug transaction code to identify the reasons for transaction aborts. However, `perf` only reports abort codes corresponding to six general categories, making it difficult to pinpoint the exact cause. To ensure a low transaction abort rate, developers can use hardware performance counters to sample TSX-related events, report the instructions causing aborts, and take steps to reduce the abort rate.

### Examples
To demonstrate the use of hardware transactional memory for side-channel defenses, we applied our design to protect several known vulnerable cryptographic implementations.

#### AES in OpenSSL
The C implementation of AES in OpenSSL is vulnerable to various side-channel attacks because the AES table lookup indices are directly related to the round keys. We enclosed the entire block encryption/decryption function in one transaction. Two minor changes were required:
1. Before entering the transaction, we "touch" the data pages to avoid page faults. These pages include the AES tables, round keys, and buffers for plaintext and ciphertext.
2. At the beginning of the transaction, five 1-KB AES tables are preloaded into the cache. The AES block encryption/decryption is short enough to have a very low probability of being interrupted.

#### ECDSA in OpenSSL
The Elliptic Curve Digital Signature Algorithm (ECDSA) in OpenSSL v1.0.1e is vulnerable to cache side-channel attacks. Specifically, the inner loop of `ec_GF2m_montgomery_point_multiply()` in the Montgomery ladder algorithm is security-critical and is enclosed in one transaction. However, including `Madd()` and `Mdouble()` (shortened for convenience) in the transaction results in frequent aborts due to their internal function calls. We refactored the code to keep the security-critical region small. Additionally, we made two minor changes:
1. Before entering the transaction, we touch the first and last word of `ec_GF2m_montgomery_point_multiply()` to avoid page faults.
2. At the beginning of the transaction, we preload this function into the cache for security purposes.

#### Modular Exponentiation in mbedTLS-SGX
Intel SGX is susceptible to cache side-channel attacks. We protected vulnerable code in mbedTLS-SGX using transactional memory. The modular exponentiation is implemented using the square-and-multiply algorithm, which is vulnerable to side-channel attacks. We refactored the code to perform multiplication operations regardless of the bit value and used transactional memory to protect the test of the bit value, preventing side-channel leakage.

### Evaluation
We evaluated the performance overhead of our defense mechanisms on cryptographic libraries using both micro and macro benchmarks. All empirical evaluations were conducted on an Intel Core i5 6440HQ processor (single socket, 4 CPU cores, 1 thread per core) with 32KB L1 instruction/data caches, 256KB L2 caches, and 3MB LLC. The maximum allowed consecutive transaction aborts (i.e., the threshold) was set to 10,000 in all experiments.

#### Micro Benchmarks
Micro benchmarks test the performance of specific cryptographic operations. We tested the overhead of OpenSSL’s AES and ECDSA implementations and mbedTLS’s RSA implementation. No execution failures due to excessive transaction aborts (more than the threshold) were observed.

**AES in OpenSSL**
We used OpenSSL’s built-in speed command-line tools to test the throughput of AES encryption with and without protection. We tested six combinations of key size and mode of operation: aes-128-cbc, aes-192-cbc, aes-256-cbc, aes-128-ige, aes-192-ige, and aes-256-ige. The performance overhead ranged from 34.1% to 42.7%. The average transaction abort rate was 0.0189%.

**ECDSA in OpenSSL**
We tested the ECDSA implementation in OpenSSL 1.0.1e using the speed command-line tool with six algorithms: ecdsak163, ecdsak283, ecdsak571, ecdsab163, ecdsab283, and ecdsak571. The performance overhead ranged from -0.497% to 0.883%. The performance gain in some cases is likely due to code refactoring. The average transaction abort rate was 0.001%.

**RSA in mbedTLS-SGX**
We tested the performance overhead of the RSA implementation in mbedTLS-SGX. The overhead was measured by the execution time of an RSA decryption (an average of 10 runs). After applying the protection, the performance overhead was 1.107% with no transaction aborts.

#### Macro Benchmarks
To test the performance impact on real-world applications, we set up an Apache HTTPS web server (version 2.4.25) dynamically linked to an OpenSSL library (libcrypto.so) with the AES and ECDSA implementations protected using hardware transactional memory. The HTTPS clients were run on a different machine connected to the server via a local area network. No execution failures due to excessive transaction aborts were observed.

**Latency with Varying File Sizes**
We tested the latency of the Apache web server with file sizes of 64B, 1KB, 64KB, 1MB, and 64MB, each requested 100 times. The ciphersuite used was ECDHE-RSA-AES256-SHA, and the concurrent connection number was 1. The latency increased slightly (less than 7.1%, and 0 to 1% in most cases).

**Latency with Varying Concurrent Connections**
We generated HTTPS requests with 2, 4, 8, 16, 32, and 64 concurrent connections. The fetched file size was 1KB, and the ciphersuite used was ECDHE-RSA-AES256-SHA. The performance overhead was between 0% and 1.85%.

**Latency with Varying Ciphersuites**
We tested the response latency under six ciphersuites with 1 concurrent connection and a 1KB fetched file size. The performance overhead ranged from -1.9% to 3.6%.

**Throughput of Apache HTTPS Server**
We used `httperf` to generate requests for 1KB files using HTTPS with the ECDHE-RSA-AES256-SHA ciphersuite. The server throughput with and without protection was almost the same. The saturation point without protection was 235.1 requests per second, and with protection, it was 234.9. The throughput drop was less than 0.1%.

**SSL Handshake Performance with ECDSA Signatures**
We linked the Apache web server to an OpenSSL 1.0.1e library and used the `s_time` command-line tool to test the performance of the handshake. The overhead ranged from 2.5% to 5.1%.

### Discussion
Our solution cannot defeat side-channel attacks initiated from another thread sharing the same core, and the protected code must avoid running on processors with HyperThreading enabled. Our current design requires the source code of the protected programs. However, by leveraging binary reassembly techniques, it is possible to disassemble the binary code, apply our mechanism to protect critical regions, and recompile the source code into binary. As discussed in Section 3, the program must be allowed to re-enter the transaction if it only aborts a number of times below the threshold. A reasonably high threshold is preferred in practice to reduce false positives, but it should be kept low enough to prevent infinite loops.

### Related Work
Closest to our work are solutions that build defense mechanisms into the protected programs themselves. One such method is software transformation. Molnar et al. [14] proposed a program counter security model to eliminate secret-dependent control flows. Zhang et al. proposed methods to equip guest VMs with capabilities to detect the presence of third-party VMs in public clouds [25] and to obfuscate cache contents to defeat L1 cache side-channel attacks [28]. Our solution can also help tenants of public clouds to protect their programs running in their own VMs, and it works in non-virtualized or SGX settings.

Although Intel TSX has been proposed as a mechanism for implementing concurrent programs, it has been leveraged to enhance system security in several previous studies. For example, Liu et al. [13] proposed using Intel TSX in virtual machine introspection.

Concurrent with our work is a paper published recently by Gruss et al. [7], which also studied the use of TSX for cache side-channel defenses. Although both papers achieve similar security properties by leveraging Intel TSX, they differ in the following aspects:
1. **Attack Coverage**: Unlike Gruss et al., our paper discusses TSX-based defenses against Prime-Probe, Flush-Reload, Evict-Time, and Cache-Collision attacks.
2. **Security Analysis**: Our security analysis arrives at a similar conclusion from different angles.
3. **Performance Evaluation**: Our performance evaluation was conducted using an Apache HTTPS web server linked to the OpenSSL library, validating the feasibility of this approach in practical uses, while Gruss et al. only applied the solution to cryptographic algorithms to demonstrate the defenses.

### Conclusions
In conclusion, this paper presents a defense against cache side-channel attacks using hardware transactional memory available in modern processors. We provide a systematic analysis of the security requirements that a software-only solution must meet to defeat cache attacks and propose a software design that leverages Intel TSX to satisfy these requirements. The defense mechanisms have been implemented on several cryptographic libraries and real-world applications, demonstrating their effectiveness and practicality.