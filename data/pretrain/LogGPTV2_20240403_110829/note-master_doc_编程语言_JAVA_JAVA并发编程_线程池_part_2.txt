```
#### 生命周期
- 管理方法
调用shutdown方法，此时仍然可以接受新任务，但是新任务将不会被运行，待已运行的任务执行完毕，线程池就会被终止
#### 自定义
```java
ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(
  2/*实际运行线程数 （不管它们创建以后是不是空闲的。线程池需要保持 corePoolSize 数量的线程）*/,
  3/*最多允许创建的线程数*/,
  0L /* 让线程存活的时间 0为永久 */,
  TimeUnit.SECONDS,
  new ArrayBlockingQueue<>(4)/*  线程池的内部队列 */,
  Executors.defaultThreadFactory()/* 产生线程的方式 */,
  new ThreadPoolExecutor.DiscardOldestPolicy() /* 线程池满时的拒绝策略 */
  );
```
参数：
1. corePoolSize 如果等于0 则任务执行结束后就会销毁所有线程 如果大于0 任务执行后这些线程不会被销毁
2. maximumPoolSize 能最大同时容纳的线程数 如果任务数量大于这个数 那么剩下的任务就要被缓存在一个阻塞队列中
3. keepAliveTime 表示线程池中的线程空闲时间 多于corePoolSize数量的部分线程会被销毁
4. 时间单位
5. workQUeue 缓存队列
6. threadFactory 定义线程池线程的产生方式
7. handler 任务拒绝策略
值得注意的是，上述参数除了缓存队列，其他参数都是可以在运行时动态调整的。
为了能达到动态调整队列长度的目的：可以通过实现自己的阻塞队列来实现。
如何配置：
- CPU密集型
- IO密集型
实际应用中 很难确定每个应用到底是CPU密集还是IO密集 不如通过动态调整线程池的方式 边调整边观察 进行负载测试 从而得到适合特定业务场景下的最佳配置
自定义线程工厂 为线程指定有意义的名称和相应的序列号 方便出错排查
定义好拒绝策略 宁愿抛出异常 也不要使用DiscardPolicy 这个策略会静悄悄的抛弃任务
线程池预热：
- prestartCoreThread
- prestartAllCoreThreads
设置回收核心线程：
- allowCoreThreadTimeOut
##### 线程池的大小
Ncpu = CPU数量
Ucpu = 预期CPU使用率
W/C = 等待时间/计算时间
最优大小等于 Ncpu * Ucpu * (1 + W/C)
但这个公式过于学术，在生产环境中，这些时间很难计算 更多地是靠场景根据经验来设置各个参数 或是根据监控来动态调整参数以观察效果
##### 应用场景
- coreSize == maxSize
让线程一下子增加到 maxSize，并且不要回收线程，防止线程回收，避免不断增加回收的损耗
- maxSize 无界 + SynchronousQueue
当任务被消费时，才会返回，这样请求就能够知道当前请求是已经在被消费了，如果是其他的队列的话，我们只知道任务已经被提交成功了，但无法知道当前任务是在被消费中，还是正在队列中堆积
比较消耗资源，大量请求到来时，我们会新建大量的线程来处理请求
- maxSize 有界 + Queue 无界
对实时性要求不大，但流量忽高忽低的场景下，可以使用这种方式
当流量高峰时，大量的请求被阻塞在队列中，对于请求的实时性难以保证
- maxSize 有界 + Queue 有界
把队列从无界修改成有界，只要排队的任务在要求的时间内，能够完成任务即可
- keepAliveTime 设置无穷大
想要空闲的线程不被回收，我们可以设置 keepAliveTime 为无穷大值
##### 线程池的公用和独立
查询和写入不公用线程池，如果公用的话，当查询量很大时，写入的请求可能会到队列中去排队，无法及时被处理
原则上来说，每个写入业务场景都独自使用自己的线程池，绝不共用，这样在业务治理、限流、熔断方面都比较容易
多个查询业务场景是可以公用线程池的
#### Wroker
在线程池中，最小的执行单位就是 Worker
```java
private final class Worker
        extends AbstractQueuedSynchronizer
        implements Runnable
{
        // 运行任务的线程
        final Thread thread;
        // 任务代码块
        Runnable firstTask;
        /** Per-thread task counter */
        volatile long completedTasks;
        Worker(Runnable firstTask) {
            // 把自己作为一个代码块穿给线程
            setState(-1); // inhibit interrupts until runWorker
            this.firstTask = firstTask;
            // 线程是通过线程工程创建的
            this.thread = getThreadFactory().newThread(this);
        }
        public void run() {
            // 这里就将任务的执行交给线程池了
            runWorker(this);
        }
        ...
}
```
#### 任务提交
提交到线程池中的任务，务必要注意任务之间要没有依赖，否则很容易就会出现死锁问题
```java
public void execute(Runnable command) {
    if (command == null)
        throw new NullPointerException();
    int c = ctl.get();
    // 如果工作线程数小于coreSize
    if (workerCountOf(c) = ((core ? corePoolSize : maximumPoolSize) & COUNT_MASK))
                return false;
            if (compareAndIncrementWorkerCount(c))
                break retry;
            c = ctl.get();  // Re-read ctl
            if (runStateAtLeast(c, SHUTDOWN))
                continue retry;
            // else CAS failed due to workerCount change; retry inner loop
        }
    }
    boolean workerStarted = false;
    boolean workerAdded = false;
    Worker w = null;
    try {
        // 把任务交给worker，此时要执行的任务就已经传入给worker里面的thread了
        w = new Worker(firstTask);
        final Thread t = w.thread;
        if (t != null) {
            final ReentrantLock mainLock = this.mainLock;
            mainLock.lock();
            try {
                // Recheck while holding lock.
                // Back out on ThreadFactory failure or if
                // shut down before lock acquired.
                int c = ctl.get();
                // 检查线程池状态
                if (isRunning(c) ||
                    (runStateLessThan(c, STOP) && firstTask == null)) {
                    if (t.getState() != Thread.State.NEW)
                        throw new IllegalThreadStateException();
                    workers.add(w);
                    workerAdded = true;
                    int s = workers.size();
                    if (s > largestPoolSize)
                        largestPoolSize = s;
                }
            } finally {
                mainLock.unlock();
            }
            if (workerAdded) {
                // 启动线程，执行worker
                t.start();
                workerStarted = true;
            }
        }
    } finally {
        if (! workerStarted)
            addWorkerFailed(w);
    }
    return workerStarted;
}
```
```java
final void runWorker(Worker w) {
    Thread wt = Thread.currentThread();
    Runnable task = w.firstTask;
    w.firstTask = null;
    w.unlock(); // allow interrupts
    boolean completedAbruptly = true;
    try {
        // 所以说在这里，在不断地取任务执行
        // 如果要执行的task为空，则会去取一个task，取不到就阻塞
        while (task != null || (task = getTask()) != null) {
            // 锁住worker，防止一个任务多个线程执行
            w.lock();
            // 线程池stop了，让线程中断
            if ((runStateAtLeast(ctl.get(), STOP) ||
                 (Thread.interrupted() &&
                  runStateAtLeast(ctl.get(), STOP))) &&
                !wt.isInterrupted())
                wt.interrupt();
            try {
                // 执行前钩子函数
                beforeExecute(wt, task);
                try {
                    // 执行真正的任务
                    // 而执行这个任务的线程就是worker里面的thread
                    task.run();
                    // 执行后钩子函数
                    afterExecute(task, null);
                } catch (Throwable ex) {
                    // 异常钩子函数
                    afterExecute(task, ex);
                    throw ex;
                }
            } finally {
                task = null;
                w.completedTasks++;
                w.unlock();
            }
        }
        completedAbruptly = false;
    } finally {
        processWorkerExit(w, completedAbruptly);
    }
}
```
```java
private Runnable getTask() {
    // 如果设置了线程超时时间，超过一定时间没有任务，超出coreSize部分的线程会被回收
    boolean timedOut = false; // Did the last poll() time out?
    for (;;) {
        int c = ctl.get();
        // 检查线程池状态
        if (runStateAtLeast(c, SHUTDOWN)
            && (runStateAtLeast(c, STOP) || workQueue.isEmpty())) {
            decrementWorkerCount();
            return null;
        }
        int wc = workerCountOf(c);
        boolean timed = allowCoreThreadTimeOut || wc > corePoolSize;
        // 如果线程数大于maxSize但是存活时间还没超过keepalive，则跳过后面取任务的部分
        if ((wc > maximumPoolSize || (timed && timedOut))
            && (wc > 1 || workQueue.isEmpty())) {
            if (compareAndDecrementWorkerCount(c))
                return null;
            continue;
        }
        try {
            // 超过keepAliveTime时间取不到数据就返回，此时线程不再运行，结束了，JVM会回收掉
            Runnable r = timed ?
                workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :
                workQueue.take();
            if (r != null)
                return r;
            timedOut = true;
        } catch (InterruptedException retry) {
            timedOut = false;
        }
    }
}
```
#### 饱和策略
线程池的构建最后参数定义了当缓存队列满了之后，要如何处置提交的任务
- AbortPolicy：默认的饱和策略 抛出RejectedExecutionException
- CallerRunsPolicy：回退到由提交者执行
- DiscardPolicy：丢弃掉当前提交的任务
- DiscardOldestPolicy：丢弃掉等待队列中最老的任务
#### 线程工厂
决定如何产生新线程，最常用来设置线程名称
```java
public static final ThreadFactory SHORT_LIFE_POOL_THREAD_FACTORY = new ThreadFactory() {
    private final AtomicInteger atomicInteger = new AtomicInteger();
    @Override
    public Thread newThread(Runnable r) {
        return new Thread(r, "short-life-thread-pool-" + atomicInteger.incrementAndGet());
    }
};
```
### ForkJoinPool
Fork/Join框架是Java7提供了的一个用于并行执行任务的框架， 是一个把大任务分割成若干个小任务，最终汇总每个小任务结果后得到大任务结果的框架
```mermaid
stateDiagram-v2
    大任务 --> 子任务1: fork
    大任务 --> 子任务2: fork
    大任务 --> 子任务3: fork
    子任务1 --> 子任务1.1: fork
    子任务1 --> 子任务1.2: fork
    子任务3 --> 子任务3.1: fork
    子任务3 --> 子任务3.2: fork
    子任务1.1 --> 任务1结果: join
    子任务1.2 --> 任务1结果: join
    子任务3.1 --> 任务3结果: join
    子任务3.2 --> 任务3结果: join
    子任务2 --> 任务2结果
    任务1结果 --> 大任务结果: join
    任务2结果 --> 大任务结果: join
    任务3结果 --> 大任务结果: join
```
- 工作窃取（work-stealing）：指某个线程从其他队列里窃取任务来执行
#### 构造器
```java
public ForkJoinPool() {...} // 创建一个拥有处理器数量的线程池
public ForkJoinPool(int parallelism){...} // 自定义并行度
```
#### 使用
```java
ForkJoinPool pool = new ForkJoinPool();
pool.execute(...);
```
execute 方法传递的任务有两个抽象子类：
- RecursiveAction 无返回值任务
- RecursiveTask 有返回值任务
```java
class RaskDemo extends RecursiveAction {
    /**
     *  每个"小任务"最多只打印20个数
     */
    private static final int MAX = 20;
    private int start;
    private int end;
    public RaskDemo(int start, int end) {
        this.start = start;
        this.end = end;
    }
    @Override
    protected void compute() {
        //当end-start的值小于MAX时，开始打印
        if((end-start) < MAX) {
            for(int i= start; i<end;i++) {
                System.out.println(Thread.currentThread().getName()+"i的值"+i);
            }
        }else {
            // 将大任务分解成两个小任务
            int middle = (start + end) / 2;
            RaskDemo left = new RaskDemo(start, middle);
            RaskDemo right = new RaskDemo(middle, end);
            left.fork();
            right.fork();
        }
    }
}
```
两个抽象子类的区别在于有返回值的任务在调用compute后最终会返回计算结果 无论是自己计算的 还是对子任务的合并
## 案例
### 线程池没有隔离导致任务饥饿
之前在维护视图库平台的时候，排查过一个问题：
视图库需要定期向上级平台定期发送一个 HTTP 保活请求，大概是几分钟一次，但通过日志以及数据库记录的保活请求发送时间发现，每次保活操作的执行都大大延迟了。
通过静态代码审查发现是保活操作跟另外一个像上级平台发送订阅通知数据的操作共用了同一个线程池，后者是大量短而快的任务，这就导致了保活操作要在队列中排队一段时间才会执行，所以执行时间都延迟了。
最后通过让保活操作自己单独使用线程池来解决问题。