A ﬁrst side-effect of IRV is that there is a very large number of ways
to ﬁll in a ballot, even for a relatively small number of candidates:
(n−i)! valid ways of ﬁlling a bal-
lot. Furthermore, if we take into account the fact that voters are not
forced to respect the ranking rule (e.g., they can produce ballots
with several candidates ranked ﬁrst, or they can skip positions in
their ranking), this number grows to (n + 1)n. So, even for rela-
tively small values of n, we can expect that speciﬁc choices that are
possible in theory, given the election outcome, will be ruled out just
by looking at the bulletin board. A second side-effect of IRV is that
not all voters will rank the same number of candidates. As a result,
a voter’s receipt actually leaks some information on the choices of
that voter: the number of choices he made.
i=0
n!
So, there seem to be three natural levels of privacy to compare in
such elections:
View 1 The amount of privacy that voters have when the only in-
formation revealed is the election outcome, that is, the pri-
vacy obtained with respect to a non-tallying voter if the Scan-
tegrity audit trail is not available.
View 2 The amount of privacy that voters have when they also see
the bulletin board, which is the actual view of the voters for
the Takoma Park elections using Scantegrity.
follows:
View 3 The amount of privacy that voters keep if they show their
receipt to someone else. We stress that receipts are not sup-
posed to be kept secret.
We select our measure M (D, T, π) with privacy measure F as
• Our target T will be the exact vote of an individual voter.
Other choices could have been made as well, like the ﬁrst
choice of any individual voter, but we keep targeting the full
vote as it is a more challenging target.
• Since we do not have any a priori knowledge about the dis-
tribution of the votes, we consider any distribution whose
support contains all possible vote assignments that is consis-
tent with the view of the adversary, and use Hartley entropy
as our privacy measure.
• To perform our analysis, we use the audit data provided for
the 2009 Takoma Park election.2 Since the view of the ad-
versary is fully determined by these audit data, the choice
between average, conditional and min Hartley entropy is ir-
relevant.
The result of our analysis appears in Table 1. Privacy measures
appear for the answers to the two questions (0 and 1) that were
submitted to the voters in each of the 6 wards of this election. We
see that we have a fairly high level of entropy when the adversary
only sees the election outcome: 6 bits for a question with 3 choices,
3.17 bits for a question with 2 choices. The level is just a bit lower
than ideal for Question 0 in Ward 4, as one of the candidates was
not ranked ﬁrst by anyone there.
The level of privacy substantially decreases in many cases when
the bulletin board becomes available: viewing the submitted ballot
allows ruling out a lot of potential combinations. While this does
not seem alarming from a pure privacy point of view, this decrease
of privacy might be sufﬁcient to force a voter to submit a ballot
with an unusual ranking of the candidates, and this voter might
2See https://scantegrity.org/svn/data/.
legitimately fear that nobody else will submit a ballot with the same
choices if he does not do it. This is a well-known issue in elections
in which ballots can be ﬁlled in many ways, traditionally called the
Italian attack. Our measure shows, considering the actual votes,
that this attack could be fairly effective as soon as a question has
3 candidates. This quantiﬁes the bound related to the short ballot
assumption [28] used in similar contexts.
Now, if the adversary sees the receipt of speciﬁc voters, the level
of privacy substantially decreases again. Here, we display the mini-
mum level of privacy depending on the number of codes appearing
on the receipt. In particular, we see that we do not have any en-
tropy left for at least one voter of Ward 5. Checking the audit data,
it indeed appears that only one voter in that ward ranked all 3 can-
didates. This voter ranked the write-in candidate ﬁrst, Candidate 1
second and Candidate 2 as third.
We believe that this potential loss of privacy indicates that voters
should be encouraged to keep their receipt secret and suggests that
a mechanism should be put in place to prevent information from
leaking from the receipts. One possibility would be to have dummy
codes available on the ballots, that would be offered for completion
by the voters, allowing all voters to obtain the same number of
unveiled codes on their receipts.
We stress that, even though it uses data from a real election,
our analysis may not completely reﬂect the actual votes, and there
might be in reality more than one voter who ranked all 3 candidates
in Ward 5. Indeed, the audit data do not exactly match the pub-
lished election results (but the differences are small and both tallies
agree on the identity of the winners.)
6. RELATION WITH TWO PREVIOUS PRI-
VACY DEFINITIONS
We show that our framework is sufﬁciently general to capture
two existing and quite different notions of privacy based on crypto-
graphic indistinguishability. For lack of better names, we we refer
to the notion of Bernhard et al. [5] as the game-based notion and
to the notion of Küsters, Truderung, and Vogt [23] as δ-privacy (al-
though both these notions involve cryptographic games); we call
our own notion that we introduce in this paper entropy-based pri-
vacy.
6.1 Comparison with the game-based notion
Game-based privacy [5] (our terminology) is a privacy notion for
a class of cryptographic voting protocols inspired by cryptographic
security for encryption. Bernhard et al. [5] analyze the Helios [1]
voting protocol and show that with an encryption scheme meeting
certain requirements, Helios meets their security notion. In this sec-
tion we introduce their model and state a theorem that any scheme
secure in the game-based model is as good as the ideal protocol for
the same election parameters according to our privacy measure, for
any choice of conditional privacy measure.
As a corollary, we get that Helios offers the same level of privacy
(using our measure) as an ideal protocol. We stress that we do not
need to perform a detailed analysis of Helios to get this result, as
we can build on the result that Helios offers game-based privacy.
Single-Pass Voting
In single-pass voting, we consider a set P of voters, a subset H ⊆
P of honest voters, a set of administrators and a bulletin board B.
All parties may post messages to the bulletin board at any time;
the board decides to accept or reject a message based on its current
state and a public algorithm πB. A single-pass protocol πρ for
a result function ρ executes in three phases. The board stores all
948Ward
#Ballots
Question
Entropy for View 1
Entropy for View 2
Entropy for View 3
1
470
2
277
3
481
4
212
5
85
6
198
0
6
4.32
1.58
1
3.17
3
1.58
0
6
4.32
2
1
3.17
2.81
1.58
0
6
4.09
2
1
3.17
3
1.58
0
5.95
3.17
1
1
3.17
3
1.58
0
6
3.17
0
1
3.17
2.58
1
0
6
1
6
3.91
2
3.58
1.58
Table 1: Privacy measures for the Takoma Park 2009 election
accepted messages and any party may read the board at any time to
obtain the current phase and the list of all accepted messages and
their senders, in the order that they were posted. The board starts
out empty and in the setup phase.
The name single-pass comes from the observation that voters
only have to post a single message to the bulletin board to cast their
vote and need take no further part in the election.
1. In the setup phase, the board expects one message from each
administrator (in any order) after which it may either transi-
tion to the voting phase or abort.
2. In the voting phase, the board accepts one message from each
party in P, in any order. After receiving these messages, the
board transitions to the result phase.
3. In the result phase, the board expects one message from each
administrator; after receiving these it halts (accepts no more
messages but can still be read).
Correctness. We need the following correctness assumption on
the execution of a single-pass protocol which intuitively says that
if everyone acts correctly, the protocol indeed computes ρ on the
votes submitted.
A protocol πρ is correct for result function ρ if there is an ef-
ﬁcient algorithm that computes either a (claimed) result r in the
range of ρ or a symbol ⊥ to denote failure from a board that has
halted successfully. We deﬁne the result of a board as being the
output of this algorithm on the board and say the board is valid if
the result is not ⊥. Furthermore, if all parties execute the protocol
correctly then the result r of the board is the correct election result,
i.e. r = ρ((vP )P∈P ) where vP is the vote cast by voter P .
Extractibility. In addition to correctness, we require that all ad-
ministrators together can extract votes from individual ballots. This
is a technical point that is required in some security proofs. Al-
though slightly stronger than the original model of [5], extractibil-
ity is satisﬁed by all voting protocols that we know of, in particular
Helios [1].3
Game-based privacy
Consider a game between a challenger C who controls the admin-
istrators, bulletin board and honest voters and an adversary A who
controls the set of corrupt voters. The adversary may in addition
choose the votes of the honest voters, even adaptively:4 during the
voting phase the adversary may both submit ballots on behalf of
3Helios has voters encrypt their votes under a key shared among
the administrators. In a real execution of the Helios protocol, ad-
ministrators never decrypt individual votes and as long as at least
one administrator is honest, no-one can extract votes. Extractibility
does not weaken vote privacy.
4In the original game [5] the adversary can even choose adaptively
which voters are honest or corrupt. Security w.r.t. the original no-
tion implies our version, which is sufﬁcient to show the relationship
with entropy.
his own, corrupt voters and inform the challenger that he wishes a
certain honest voter to vote in a way of his choice.
The challenger chooses a random bit β at the beginning of the
protocol. If β = 0, the challenger and adversary just run π to-
gether. If β = 1, when the adversary asks a honest voter to vote,
the challenger notes this vote but has the voter submit a ballot for
a ﬁxed value vε instead. In the result phase, the challenger always
announces to the adversary the correct result based on the ballots
of the dishonest voters and the votes that the adversary chose for
the honest voters.5
The adversary’s goal it to guess the challenger’s bit β. A protocol
has game-based privacy if no efﬁcient adversary can guess β with
probability non-negligibly better than 1/2.
Relation between entropy-based and game-based pri-
vacy
Security in the sense of the game described above leads to the fol-
lowing intuitive argument: since the adversary cannot distinguish
ballots containing the true votes of the honest users — even if the
adversary can choose these votes — from ballots containing a ﬁxed,
constant vote then the adversary cannot extract any information
about the votes from ballots. Therefore, we expect that the condi-
tional computational entropy of the honest votes given the bulletin
board (which together with the random coins of the adversary form
its view of the execution) to be equal to the computational entropy
that the votes have on their own (the adversary can see the result
of the result function on the votes in both cases). This intuition is
formalized by the following theorem.
THEOREM 6. Suppose that π is a correct and secure single-
pass voting protocol for a set P of voters and a result function ρ.
Fix any set H ⊆ P, any efﬁciently samplable distribution D on H
and any target function T . Then
M (D, T, π) = M (D, T,Iρ) .
The proof is in the full version of our paper.
Discussion
We have shown that, informally speaking, a single-pass protocol
for computing some tally function ρ which is secure in the game-
based sense achieves the same level of privacy as the ideal protocol
(see Section 6.1) for ρ, in the sense of entropy-based privacy. One
immediate interpretation of this result is that from a protocol secure
in the game based sense the adversary can extract as much infor-
mation as it can extract from only seeing the result and nothing
more. This is a very desirable and intuitively appealing property
as it reduces understanding the level of privacy of a protocol to
that of understanding the level of privacy of a corresponding ideal
protocol. Furthermore proofs using the game-based deﬁnition are
5If β = 1 then the announced result will not match the ballots on
the board. It is part of the game-based deﬁnition that the challenger
can produce such a “fake” result without the adversary noticing
whereas in a real election, faking a result should be infeasible.
949more standard and easier to construct than those using the compu-
tational conditional entropy notions. Whenever possible, proving
game-based privacy is therefore desirable.
There are several downsides to the game-based notion. The no-
tion does not account for the loss of privacy due to the result func-
tion ρ. A voting protocol where ρ is the identity function and which
is implemented by letting the tallying authorities to simply decrypt
the ballots and output the votes in clear would be secure in the
game-based sense. Clearly however privacy of the votes is actually
lost. The theorem we gave in this section allows for the following
methodology: prove game-based security for a voting protocol and
then analyze the privacy of the ideal protocol for ρ to understand
the entropy-based privacy of the overall protocol.
This route is not possible for protocols that are not in the single-
pass class, or for protocols that are single-pass but where some “lit-
tle” (potentially useless parts) information about the honest votes
is revealed. In both cases our entropy-based notion may still apply
and in the latter case, it allows for giving a more reﬁned quantiﬁ-
cation of the loss of privacy, than simply declaring the protocols
insecure.