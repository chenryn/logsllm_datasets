Mimicry on W (test 2)
13.813
98.9111 % 99.8185 % 100 % 98.9111 % 100 %
2.64
13.657
2.687
2.174
2.187
2.65
98.7296 % 99.8185 % 98.0944 % 98.9111 % 97.8221 %
nique running on one of the replicas. In particular, the anomaly detection tech-
nique we consider here is one that uses variable-length system call phrases in
modeling normal behavior of the running program [37]. In other words, the ﬁrst
test assumes that the attacker does not know that we are utilizing a behavioral
distance calculation between replicas (or indeed that there are multiple replicas).
In the second test, we assume that the attacker not only understands that our
behavioral distance calculation between replicas is being used, but also has a
copy of the distance table that is used in the behavioral distance calculation.
This means that an attacker in the second test is the most powerful attacker,
who knows everything about our system. In both tests, we exhaustively search
for the best mimicry attack. In the ﬁrst test, the “best” mimicry attack is that
which makes the minimal number of system calls while remaining undetected.
In the second test, the “best” mimicry attack is that which results in the small-
est behavioral distance between system call sequences from the two replicas.
We assume that the mimicry attack in both cases results in a request to the
uncorrupted replica that produces a “page not found” response.
Results of both tests are shown in Table 1. For each individual test, Table 1
shows the behavioral distance of the best mimicry attack, and the percentage of
testing data (from Section 4.2) that has a smaller behavioral distance. That is,
the percentage shown in Table 1 indicates the true acceptance rate of our system
when the detection threshold is set to detect the best mimicry attack. As shown,
these percentages are all very close to 100%, which means that the false alarm
rate of our technique is relatively low, even when the system is conﬁgured to
detect the most sophisticated mimicry attacks. Moreover, by comparing results
from the two sets of tests, we can also see the trade-oﬀ between better detection
capability and lower false positive rate. For example, by setting the threshold
to detect any mimicry attacks that could have evaded detection by an isolated
intrusion/anomaly detection system on one of the replicas (results in test 1), our
system will have a much lower false positive rate (between 0% and 0.5%).
4.4 Performance Overhead
Section 4.2 and Section 4.3 show that our method for behavioral distance is
more resilient against mimicry attacks than previous approaches and has low
78
D. Gao, M.K. Reiter, and D. Song
false positive rate. In this section, we evaluate the performance overhead of our
implementation of the behavioral distance calculation by measuring the through-
put of the http servers and the average latency of the requests. The performance
evaluation shows that the performance overhead is moderate. Also note that our
current implementation is unoptimized, so the performance overhead will be
even lower with an optimized implementation.
We run two experiments to evaluate our performance overhead. First, we
evaluate the performance degradation of a single server due to the overhead of
having to extract and send the system call information to another machine to
compute the behavioral distance. Second, we show our performance overhead in
comparison to a fault-tolerant system that compares the responses from replicas
before returning the response to the client (“output voting”).
Performance Overhead of Extracting and Sending System Call Infor-
mation. In this experiment, we run two diﬀerent tests on one single server
running Windows operating system (with a 2.0 GHz Pentium IV processor and
512 MB memory). In both tests, we utilize the static test suite shipped with
WebBench 5.0 [34] to test the throughput and latency of the server when the
server is fully utilized. In the ﬁrst test, the machine simply runs the Abyss X1
webserver. In the second test, the machine runs the same webserver and also
extracts and sends out the system call information to another machine for the
behavioral distance calculation (though this calculation is not on the critical
path of the response). We compared the diﬀerence in throughput and latency
between the two tests. Our experiment results show that the second test has a
6.6% overhead in throughput and 6.4% overhead in latency compared to the ﬁrst
test. This shows that intercepting and sending out system call information causes
very low performance overhead on a single server in terms of both throughput
and latency.
Performance Overhead Compared to Output Voting. We perform three
tests to measure the performance overhead of our implementation of the behav-
ioral distance on a replicated system with Abyss X1 webservers. The experi-
mental setup is the same as shown in Section 4.1, except that we use another
machine T (with a 2.0 GHz Pentium IV processor and 512 MB memory) to
generate client requests, and in one of the tests we also have yet another ma-
chine C to perform the behavioral distance calculation. We use the benchmark
program WebBench 5.0 [34] in all the three tests. All tests utilize the static test
suite shipped with WebBench 5.0, except that we simulate 10 concurrent clients
throughout the tests. Each test was run for 80 minutes with statistics calculated
at 5-minute intervals. Results are shown in Figure 5.
In the ﬁrst test, replicas L and W only serve as webservers, without the
kernel patch (on Linux) or kernel driver (on Windows) to capture the system
call sequences. Proxy P does output voting, which means that responses from L
and W are compared before being sent to the client T. This test is used as the
reference in our evaluation.
In the second test, besides output voting on P, replicas L and W capture the
system calls made by the webservers and send them to machine C, which does
2.5
2
1.5
1
0.5
)
s
/
e
t
y
b
M
(
t
u
p
h
g
u
o
r
h
T
0
0
Behavioral Distance for Intrusion Detection
79
P:        output voting
L&W: serve requests
P:        output voting
L&W: serve requests + send syscall sequences to C
P:        output voting + behavioral distance calculation
L&W: serve requests + send syscall sequences to P
12
)
c
e
s
m
(
y
c
n
e
t
a
L
8
4
P:        output voting
L&W: serve requests
P:        output voting
L&W: serve requests + send syscall sequences to C
P:        output voting + behavioral distance calculation
L&W: serve requests + send syscall sequences to P
20
40
Test time (min)
(a) Throughput
60
80
0
0
20
40
Test time (min)
(b) Latency
60
80
Fig. 5. Performance overhead
the behavioral distance calculation. Note that in this test the behavioral distance
calculation is not on the critical path of responding to the client. The purpose of
this test is to show the overhead for capturing the system call information (and
analyzing it oﬀ-line). As seen from Figure 5, this results in very small overhead:
3.58% in throughput and 0.089 millisecond in latency on average.
In the last test, output voting and the behavioral distance calculation are both
performed on the proxy P on the critical path of responding to the client, i.e.,
the response is sent to the client only after the behavioral distance calculation
and output comparison complete. To improve performance, P caches behavioral
distance calculations, so that identical calculations are not performed repeatedly.
Figure 5 shows that the proxy needs about 50 minutes to reach its optimal
performance level. After that, clients experience about a 24.3% reduction in
throughput and 0.848 millisecond overhead in latency, when compared to results
from the ﬁrst test.
The results suggest that we need to use a slightly more powerful machine for
the proxy, if we want to do behavioral distance calculation on the critical path
of server responses, for servers to remain working at peak throughput. However,
even in our tests the overhead in latency is less than a millisecond.
5 Conclusion
In this paper, we introduce behavioral distance for evaluating the extent to which
two processes behave similarly in response to a common input. Behavioral dis-
tance can be used to detect a software fault or attack on a replica, particularly
one that does not immediately yield evidence in the output of the replica. We
propose a measure of behavioral distance and a realization of this measure us-
ing the system calls emitted by processes. Through an empirical evaluation of
this measure using three web servers on two diﬀerent platforms (Linux and Win-
dows), we demonstrate that this approach is able to detect sophisticated mimicry
attacks with low false positive rate and moderate overhead.
80
D. Gao, M.K. Reiter, and D. Song
References
1. Myserver. http://www.myserverproject.net.
2. L. Alvisi, D. Malkhi, E. Pierce, and M. K. Reiter. Fault detection for Byzan-
tine quorum systems. IEEE Transactions on Parallel Distributed Systems, 12(9),
September 2001.
3. R. W. Buskens and Jr. R. P. Bianchini. Distributed on-line diagnosis in the presence
of arbitrary faults. In Proceedings of the 23rd International Symposium on Fault-
Tolerant Computing, pages 470–479, June 1993.
4. M. Castro, R. Rodrigues, and B. Liskov. Base: Using abstraction to improve fault
tolerance. ACM Transactions on Computer Systems (TOCS), 21(3):236–269, 2003.
5. L. Chen and A. Avizienes. n-version programming: A fault-tolerance approach to
reliability of software operation. In Proceedings of the 8th International Symposium
on Fault-Tolerant Computing, pages 3–9, 1978.
6. S. Cheung, R. Crawford, M. Dilger, J. Frank, J. Hoagland, K. Levitt, J. Rowe,
S. Staniford-Chen, R. Yip, and D. Zerkle. The design of GrIDS: A graph-based
intrusion detection system. Technical Report CSE-99-2, Computer Science Depart-
ment, U.C. Davis, 1999.
7. C. Collberg, C. Thomborson, and D. Low. Manufacturing cheap, resilient, and
stealthy opaque constructs. In Proceedings of the ACM Symposium on Principles
of Programming Languages, January 1998.
8. H. H. Feng, J. T. Giﬃn, Y. Huang, S. Jha, W. Lee, and B. P. Miller. Formalizing
In Proceedings of the 2004
sensitivity in static analysis for intrusion detection.
IEEE Symposium on Security and Privacy, 2004.
9. H. H. Feng, O. M. Kolesnikov, P. Fogla, W. Lee, and W. Gong. Anomaly detection
In Proceedings of the 2003 IEEE Symposium on
using call stack information.
Security and Privacy, 2003.
10. S. Forrest and T. A. Langstaﬀ. A sense of self for unix processes. In Proceedings
of the 1996 IEEE Symposium on Security and Privacy, 1996.
11. The Apache Software Foundation. Apache http server. http://httpd.apache.org.
12. D. Gao, M. K. Reiter, and D. Song. Gray-box extraction of execution graph for
anomaly detection. In Proceedings of the 11th ACM Conference on Computer &
Communication Security, 2004.
13. D. Gao, M. K. Reiter, and D. Song. On gray-box program tracking for anomaly
detection. In Proceedings of the 13th USENIX Security Symposium, 2004.
14. J. T. Giﬃn, S. Jha, and B. P. Miller. Detecting manipulated remote call streams.
In Proceedings of the 11th USENIX Security Symposium, 2002.
15. J. T. Giﬃn, S. Jha, and B. P. Miller. Eﬃcient context-sensitive intrusion detection.
In Proceedings of Symposium on Network and Distributed System Security, 2004.
16. C. Kruegel, D. Mutz, F. Valeur, and G. Vigna. On the detection of anomalous
system call arguments. In Proceedings of the 8th European Symposium on Research
in Computer Security (ESORICS 2003), 2003.
17. L. Lamport. The implementation of reliable distributed multiprocess systems. In
Computer Networks 2, 1978.
18. X. Lu. A Linux executable editing library. Master’s thesis, Computer and Infor-
mation Science Department, National Unviersity of Singpaore, 1999.
19. G. Nebbett. Windows NT/2000 Native API Reference. Sams Publishing, 2000.
20. M. Nei and S. Kumar. Molecular Evolution and Phylogenetics. Oxford University
Press, 2000.
Behavioral Distance for Intrusion Detection
81
21. P. Ning, Y. Cui, and D. S. Reeves. Analyzing intensive intrusion alerts via cor-
relation. In Recent Advances in Intrusion Detection (Lecture Notes in Computer
Science vol. 2516), 2002.
22. M. Prasad and T. Chiueh. A binary rewriting defense against stack based buﬀer
In Proceedings of the USENIX Annual Technical Conference,
overﬂow attacks.
June 2003.
23. I. Rigoutsos and A. Floratos. Combinatorial pattern discovery in biological se-
quences. Bioinformatics, 14(1):55–67, 1998.
24. T. Romer, G. Voelker, D. Lee, A. Wolman, W.Wong, H. Levy, B. Bershad, and
B. Chen. Instrumentation and optimization of win32/intel executables using etch.
In Proceeding of the USENIX Windows NT Workshop, August 1997.
25. F. B. Schneider.
Implementing fault-tolerant services using the state machine
approach: A tutorial. ACM Computing Surveys, 22(4):299–319, December 1990.
26. B. Schwarz, S. Debray, and G. Andrews. Disassembly of executable code revisited.
In Proceeding of the Working Conference on Reverse Engineering, pages 45–54,
2002.
27. R. Sekar, M. Bendre, D. Dhurjati, and P. Bollineni. A fast automaton-based
method for detecting anomalous program behaviors. In Proceedings of the 2001
IEEE Symposium on Security and Privacy, 2001.
28. P. H. Sellers. On the theory and computation of evolutionary distances. SIAM J.
Appl. Math., 26:787–793.
29. K. Shin and P. Ramanathan. Diagnosis of processors with Byzantine faults in a
distributed computing system. In Proceedings of the 17th International Symposium
on Fault-Tolerant Computing, pages 55–60, 1987.
30. S. R. Snapp, S. E. Smaha, D. M. Teal, and T. Grance. The DIDS (Distributed
Intrusion Detection System) prototype. In Proceedings of the Summer USENIX
Conference, pages 227–233, 1992.
31. K. Tan, J. McHugh, and K. Killourhy. Hiding intrusions: From the abnormal
to the normal and beyond. In Proceedings of the 5th International Workshop on
Information Hiding, October 2002.
32. Aprelium Technologies. Abyss web server. http://www.aprelium.com.
33. A. Valdes and K. Skinner. Probabilistic alert correlation. In Recent Advances in
Intrusion Detection (Lecture Notes in Computer Science vol. 2212), 2001.
34. VeriTest.
Webbench.
http://www.veritest.com/benchmarks/webbench/
default.asp
35. D. Wagner and D. Dean. Intrusion detection via static analysis. In Proceedings of
the 2001 IEEE Symposium on Security and Privacy, 2001.
36. D. Wagner and P. Soto. Mimicry attacks on host-based intrusion detection systems.
In Proceedings of the 9th ACM Conference on Computer and Communications
Security, 2002.
37. A. Wespi, M. Dacier, and H. Debar. Intrusion detection using variable-length audit
trail patterns. In Proceedings of the 2000 Recent Advances in Intrusion Detection,
2000.
38. Y. Xie, H. Kim, D. O’Hallaron, M. K. Reiter, and H. Zhang. Seurat: A pointillist
approach to anomaly detection. In Recent Advances in Intrusion Detection (Lecture
Notes in Computer Science 3224), pages 238–257, September 2004.
39. J. Yin, J.-P. Martin, A. Venkataramani, L. Alvisi, and M. Dahlin. Separating
agreement from execution for Byzantine fault tolerant services. In Proceedings of
the 19th ACM Symposium on Operating System Principles, 2003.