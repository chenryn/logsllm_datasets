title:Discovery of emergent malicious campaigns in cellular networks
author:Nathaniel Boggs and
Wei Wang and
Suhas Mathur and
Baris Coskun and
Carol Pincock
Discovery of Emergent Malicious Campaigns in
Cellular Networks
Nathaniel Boggs
Columbia University
PI:EMAIL
Wei Wang
AT&T Security Research
PI:EMAIL
Center
Suhas Mathur
AT&T Security Research
Center
PI:EMAIL
Baris Coskun
AT&T Security Research
Center
PI:EMAIL
Carol Pincock
AT&T
PI:EMAIL
Abstract
The growth of Smartphones has bridged the telephony/SMS
and the IP worlds, and this has resulted in new opportuni-
ties for ﬁnancially motivated attackers. For example, some
malicious campaigns in the cellular network aimed at ex-
tracting money fraudulently can do so even without any
malware. Detecting and mitigating the variety of attacks in
cellular network is diﬃcult because they do not necessarily
have a ﬁxed ‘signature’, and new types of campaigns appear
frequently. Further complicating matters, detecting a sin-
gle malicious entity (a domain name, a phone number, or
a short code) that is part of a malicious campaign, is usu-
ally not very eﬀective, because the attacker simply moves
to using another entity in its place. An eﬀective strategy
requires detecting all/most elements involved in the cam-
paign at once. In this paper, we describe a system, based on
ideas from anomaly detection and clustering, that aims to
detect many diﬀerent families of widespread malicious cam-
paigns in cellular networks. The system reveals an entire
campaign as a graph cluster which includes the various enti-
ties involved in the campaign and their relationship, such as
malware download websites, C&C servers, spammers, etc.
Using logs from both SMS and IP portions of the network
for millions of users, we detect newly popular entities and
cluster them to discover how they are related. By looking
for cues of possible malicious behavior from any of the enti-
ties in a cluster, we attempt to ascertain whether a detected
campaign might be malicious, providing valuable leads to a
human analyst. Our system is live and generates daily clus-
ters for human analysts. We provide detailed case studies of
real, previously unseen families of malicious campaigns that
this system has successfully brought to light.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ACSAC ’13 Dec. 9-13, 2013, New Orleans, Louisiana USA
Copyright 2013 ACM 978-1-4503-2015-3/13/12 ...$15.00.
http://dx.doi.org/10.1145/2523649.2523657
29
Keywords
Intrusion Detection, Mobile Phone Secuirty, SMS, Network
Anomaly Detection
1.
INTRODUCTION
Malicious activities in cellular networks form a complex
landscape which can be quite diﬀerent from traditional PC
attacks. For instance, fraudsters can extract money from un-
suspecting smartphone users by enrolling them in premium
third party services without involving any kind of malware
in the process [18]. As another example, botnet infected
mobile phones can be used to distribute Short Message Ser-
vice (SMS) spam messages which, unlike email spam, incur
charges to victims’ phone bills. Besides these unique at-
tacks, mobile manifestations of more traditional attacks are
constantly surfacing as well, such as malware-laced apps in
app-stores [26] and drive-by download of mobile malware [6].
Network-based defense against this landscape of malicious
activities requires non-traditional methods, mostly due to
the unique relationship between smartphone users and ser-
vice providers. More speciﬁcally, users pay for their mobile
service, and hence, any security measure that may aﬀect a
user’s service, such as blocking an SMS message or shut-
ting down a suspected attacker’s phone account, has to be
ﬁrst conﬁrmed by a human analyst. Therefore, tools and
algorithms that can help security analysts identify and con-
ﬁrm malicious activities in mobile networks are extremely
crucial.
Motivated by this, in this paper we propose a network-
based method to discover potentially malicious campaigns
to be presented to a human analyst for conﬁrmation. Since
we aim to discover new families of malicious campaigns, we
do not employ any ‘signature’ speciﬁc to a campaign. Our
approach is based on anomaly detection on communication
patterns, where we roughly consider an anomaly as a user
communicating with an entity for the ﬁrst time. Building
a separate anomaly detector for each user is generally un-
fruitful because such a detector has too high a false posi-
tive rate, since humans frequently engage in communication
with new entities. However, if many users have the same
anomaly, this false positive rate can be lowered. This is use-
ful because when a widespread malicious campaign occurs,
one or more entities (a domain name, short code, or phone
number) suddenly begins communicating with a signiﬁcant
number of mobile phone numbers (i.e. victims) that they
have not communicated with in the past.
Our method is a two-stage process. First, we identify
entities (i.e. anomalous entities) which communicate with
several phone numbers that they have never communicated
with during a long, prior, training period. Despite this loose
deﬁnition of an anomaly, often a large number of entities
exhibiting the same anomaly indicates a potential malicious
campaign. Therefore, in the second stage, we explore possi-
ble relationships between the anomalous entities by measur-
ing the overlap between the sets of mobile users that they
have communicated with. Such relationships among anoma-
lous entities are essential to our method and can be captured
by a mutual contacts graph (Figure 1), where nodes repre-
sent anomalous entities and an edge represents that a pair of
entities share a signiﬁcant fraction of users that have com-
municated with them. In a typical mutual contacts graph
there are several connected components (i.e. clusters) each
representing a potential malicious campaign. Finally we pri-
oritize these clusters with respect to severity using various
pieces of external information, such as publicly available
blacklists, customer complaints, etc. and present the pri-
oritized clusters to a human analyst for ﬁnal conﬁrmation.
We have implemented and deployed the proposed method
in a large mobility network. We demonstrate its utility by
a live study over several months. During this period we
produced live daily reports of clusters suspected to be mali-
cious, and identiﬁed a number of diﬀerent attack campaigns
(spam, premium number fraud, and suspected botnet be-
havior) some of which were subsequently shut down.
In
this paper we provide details of the most interesting mal-
ware campaigns that we unearthed. The contributions of
our work in this paper are:
1) Signature free. Our approach is based on anomaly
detection and hence allows for detection of several types of
malicious activity without having to design a new signa-
ture for each new type of malicious campaign. Examples of
attacks that can be detected include: domain ﬂux botnets,
premium number fraud [13], SMS-relays that defeat 2-factor
authentication [4, 5] and multi-stage malware campaigns.
2) Scalable. Our approach is simple and able to scale up
to a large mobile network with millions of subscribers.
3) Holistic picture. Rather than just a single malicious
entity in isolation, our method reveals entire campaigns as
a cluster with most of its malicious entities such as mobile
phone SMS spammers, malicious domain names, and short
codes. Blocking or shutting down a single phone number or
domain name does almost no harm to the attacker, whereas
moving swiftly against multiple pieces of the attacker’s in-
frastructure is more likely to end the campaign.
4) Real malicious campaigns. We present the details
of real cases of malicious campaigns that we discover using
our method, providing insights in the modus operandi of
cyber criminals.
2. RELATED WORK
In general, network-based anomaly detection systems try
to characterize normal network behavior and produce an
alarm when the behavior deviates from normal. Although
in principle, anomaly detection systems are able to detect
previously unseen attacks, unfortunately characterizing nor-
mal network behavior is notoriously diﬃcult. Therefore,
network-based anomaly detection systems often suﬀer from
Figure 1: In the mutual contacts graph, nodes repre-
sent entities, and an edge between two entities rep-
resents a signiﬁcant overlap between the sets of users
that communicate with them. In the example above,
an SMS spammer sends numerous messages to many
subscribers. A signiﬁcant fraction of spammed users
click on the URL within spam messages, hence the
edge between spammer and URL. Finally almost all
users who click on the spam URL are redirected to
a new domain, hence the edge between spam URL
and new domain name.
high false positive rates. There have been several attempts
to achieve anomaly detection systems with lower false posi-
tive rates such as by manually characterizing normal behav-
ior using protocol speciﬁcations [20] and by incorporating
application level knowledge [14]. Nevertheless, anomaly de-
tection systems have evidently never been able to achieve ac-
ceptable error rates. Despite the plethora of anomaly detec-
tion methods proposed in the literature [22], one can hardly
ﬁnd a deployed anomaly detection system in practice [21].
To achieve a practical anomaly detection system, we employ
a simple key strategy diﬀerent from existing schemes. That
is, an anomalous behavior is taken into account only when
large number of network users exhibit the same anomaly
thereby reducing the false positives.
Aside from anomaly detection, there are several other ar-
eas which are related to our work. As mobile phones and
PCs have much in common, many of the defensive techniques
have direct application to mobility networks. Domain repu-
tation blacklists based on user reports, spam detection, and
malicious activity provide an inexpensive but time-lagged
detection method to prevent continued abuse. By limiting
an attacker’s use of particular domains, these blacklists in-
crease the cost to attackers, forcing them to change domains,
but rarely do more than slow the attacks.
Network based malware detection often focuses on bot-
net detection. While there are numerous botnet detection
schemes proposed in the literature, clustering analysis or
similarity-based methods are most closely related to our
work. In [12] and [25], authors make the observation that
members of a botnet exhibit similar network level character-
istics due to underlying common malicious behavior, there-
fore clustering analysis of several features extracted from
observed network traﬃc would group the member of a bot-
net together. In [9], the authors propose to detect P2P bots
by applying a graph-clustering method on a mutual-contacts
like graph extracted from network ﬂow records. In [15], the
authors analyze DNS data from cellular networks to charac-
terize the amount of malicious activity in cellular networks.
They ﬁnd a malicious campaign that ceases to operate long
before the malware associated with it is discovered, and rec-
ommend that “network-based countermeasures may be use-
ful in the identiﬁcation and mitigation of future threats”.
While attacks in mobility space are getting more sophis-
ticated [26], current defenses in the mobility space for the
most part mirror early PC defenses. For instance, in order to
detect SMS spam, volumetrics and content hash/signature
30
Term
Deﬁnition
Entity
User
High-degree
node
Normal node
Anomalous
node
Communication
graph
Mutual contacts
graph
Domain name, phone number or short code.
A 10-digit phone number with data plan.
An entity that communicates with a signiﬁ-
cant number of users.
A high degree node with many users commu-
nicating with it in the training phase.
A high degree node with many new users com-
municating with it in the testing phase, but
not in the training phase.
A graph in which vertices represent entities
and edges represent communication.
A graph in which a vertex represents a high-
degree node and an edge between two ver-
tices represents a signiﬁcant fraction of shared
users.
Table 1: Terminology used in this paper
matches [16] are used at the network level. In [11] authors
propose a clustering based SMS spam detection method,
where they observe that SMS spam messages have simi-
lar contents therefore they are likely to be clustered in a
random subspace. In [23] authors propose exploiting mes-
sage senders’ temporal characteristic (how regular they send
message) and social characteristics (who sends to whom) to
identify spammers. However, computing such characteris-
tics often runs into scalability problem when large networks
are concerned. To mitigate such scalabilty issues, in [10],
authors propose an eﬃcient SMS spam campaign detection
technique which quickly identiﬁes unusually high number of
similar contents transmitted within the SMS network. While
eﬀective, these techniques focus on detecting spam messages
and spammers and cannot reveal the further stages of the
overall malicious activity. Finally, there is important prior
work [8] on analyzing communication patterns using graphs
to detect fraud in cellular networks.
[8] introduces guilt
by association (which we build upon), but utilizes the ac-
tual communication graph for its analysis (whereas we work
with the mutual contacts graph), and aims to detect simpler
fraud, such as phone accounts created with the intention of
not paying their bills, rather than malicious campaigns.
3. SYSTEM DESIGN
3.1 Overview of Attacks and Defenses
A typical widespread attack in a cellular network has at
least two communication components (Figure 2):
1) The initial infection or luring. The initial attack may
occur through the medium of a spam SMS message con-
taining a URL, an app store, or perhaps a hacked website.
These websites may serve anything from drive-by download
malware attempting to infect phones to social engineering
attempts to trick a user into voluntarily downloading mal-
ware or signing up for a premium rate SMS service under
false pretenses.
2) The subsequent behavior of those users that get in-
fected or fall for the attack. This might include communi-
cating with a command and control server / drop-server, or
an SMS shortcode, relaying all SMS messages to a certain
phone number, or perhaps acting as an SMS spammer itself.
For example, in the GGTracker malware campaign [19],
Android users are tricked into downloading an app from a
website resembling the Android app market. The malware
then registers the victim for premium subscription services
without any action on the user’s part. Signing up for such
a service normally requires answering a question or device’s
own phone number and entering a PIN code received via
SMS. However, the malware performs this transaction auto-
matically, without the user’s knowledge. The premium ser-
vice bills the carrier which reﬂects the charge in the user’s
monthly bill.
There are two key observations on these communication
components of malicious campaigns:
• Almost always, there is more than one entity involved
in a campaign, e.g. a 10-digit number that sends a
URL in an SMS spam, and the domain name in the
URL that users click on.
• The entities involved often change over time. This is
because some of the entities may have complaints ﬁled
against them, and are taken down. But the attacker
simply begins using a new entity of the same type. For
example, if a mobile phone number is reported to be
sending spam and is shut down, then the attacker can
simply start sending spam from another number.
Based on the above two insights, we focus on a speciﬁc
type of anomalous pattern: the existence of multiple entities
that have recently become very popular (i.e. they have re-
cently begun communicating with a large number of users),
and are also related to one another via a non-trivial overlap
between the sets of users they communicate with.
Figure 3 shows a high level overview of the steps involved
in detecting suspicious campaigns. Each step in this chain
winnows down the data, keeping anomalous traﬃc and drop-
ping irrelevant traﬃc, until it is small enough for a human
analyst to investigate. First, we gather the data and match
users in both data sets (SMS and IP) in order to have a com-
plete picture of the traﬃc for these users, since many attack
campaigns involve traﬃc in both the SMS and IP worlds.
Then, using data from an initial time window, we discover
domains and numbers that are already popular (training).
In the testing phase, which corresponds to a subsequent time
window, these already popular entities are excluded, and
we calculate how many and which distinct users each en-
tity communicates with. We then take the most popular of
these entities and calculate how many users each pair has in
common. In this way we infer patterns that indicate similar
sets of users connecting to multiple newly popular entities.
Using the overlap between the sets of users that communi-
cate with each newly popular entity, we cluster the entities
together using a graph clustering algorithm.
A cluster is the ﬁnal product of our algorithm and the
canonical unit of suspicion in our system. That is, given
our traﬃc-centric viewpoint, a malicious campaign is the
Figure 2: An attack campaign life cycle. (1): Device
gets infected through some channel, (2): Infected
device communicates with other entities as part of
the attack.
31
Figure 3: The overall system as a sequence of oper-
ations starting with raw data on the left.
set of entities used to perpetrate it. By the time we form
a cluster, we have reduced the quantity of data down by
a factor of approximately ∼ 104 nodes and by a factor of
∼ 105 edges.
In this form, the data is therefore suitable
for consumption by a human analyst (10-100 clusters), who
then decides to further invstigate or discard each cluster.
Note that, a cluster may represent a malicious campaign,
or a benign infrastructure. A multi-stage attack is revealed
as one cluster because the same set of users will go through
diﬀerent stages such as users get spammed are also the ones
that communicate with the malicious domains and premium
numbers.
As an aid to the analyst, we enhance each cluster by
adding relevant information. For each entity in a cluster,
we include the number of users that communicate with that
entity during the test window. We also include the amount
of correlation between two entities in a cluster on the graph.
Finally, we prioritize clusters using external information,
such as whether some entities of a cluster appear on a pub-
lic blacklists or some numbers are reported as spammers by
many mobile users through the 7726 short code1. Our sys-