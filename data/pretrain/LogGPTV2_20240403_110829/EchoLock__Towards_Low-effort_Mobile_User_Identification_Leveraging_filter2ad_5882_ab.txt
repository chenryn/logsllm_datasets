based [14, 34] methods propose swipe patterns and picture recogni-
tion as more intuitive alternatives. While effective, these methods
verify knowledge rather than the user and require active input.
In contrast, biometric-based approaches use physical traits of
users as credentials, which could enable passive user authentica-
tion and reduce user effort. Several popular examples include face
ID [5], capacitive fingerprint scanning [12], and iris scanning [9].
Physiological credential are typically unique to a person and do
not change abruptly over time, making them ideal for identification
systems. However, these approaches require dedicated hardware
components to make accurate measurements, which limits the pool
of devices on which they can be deployed. Furthermore, theft of
these credentials are highly problematic since they involve person-
ally identifiable information [40].
Human behaviors have also been employed as credentials. For ex-
ample, prior works have shown it is possible to identify individuals
based on hand gestures [21, 22], voice commands [5, 41], as well as
finger inputs made on touchscreens [29, 31, 32], solid surfaces [23],
and wearable devices [3]. These are less personally identifiable, and
thus pose a smaller risk to user privacy, but can be challenging to
associate with a given identity due to natural inconsistencies users
exhibit when asked to reproduce these characteristics
Proposals have been made to measure credentials in a passive,
low-effort manner, which we consider closely related to EchoLock.
Ren et al. use accelerometer readings in mobile devices to derive
unique gait patterns and passively verify the user as they walk [28].
Zheng et al. extract behavioral patterns from touchscreen taps (e.g.,
rhythm, strength, angle of applied force) using built-in accelerome-
ters, gyroscopes, and piezoelectric sensors to provide non-intrusive
user authentication [42]. Zhou et al. develop an attack to passively
detect lockscreen swipe patterns based on acoustic reflections pro-
duced by the user‚Äôs fingers during input [45].
We summarize the findings of prior work in Table 1. Unlike exist-
ing approaches, EchoLock leverages novel hand biometrics including
hand-related physiological (i.e., hand geometry) and behavioral (i.e.,
holding strengths and styles) traits to provide convenient and secure
user identification. By performing fine-grained acoustic sensing to
capture the unique hand biometrics, the user can be identified pas-
sively when holding their personal device. The natural availability
of speakers and microphones makes acoustic sensing a widely used
technique in many mobile computing applications, such as indoor
localization [36] and human-computer interaction [33, 37]). To our
best knowledge, we are the first work to utilize acoustic sensing
to capture hand biometric information for low-effort user identi-
fication. Our proposal does not depend on personally identifiable
information, active user inputs, or specialized hardware.
3 ADVERSARY MODEL
Malicious users may attempt to attack our system in order to gain
access to personal information or deny legitimate users from ac-
cessing services. In this section, we introduce attack strategies that
may be deployed against EchoLock.
Impersonation Attack. The attacker attempts to mimic the
holding posture of the legitimate user to gain access to the device.
For impersonation attacks, the attacker may either be informed
or uninformed. In the uninformed case, the attacker possesses no
Figure 2: System overview of EchoLock.
knowledge on how to circumvent the identification process and
naively attempts to mimic the legitimate user‚Äôs holding behavior. In
the informed case, however, the attacker is explicitly aware of the
legitimate user‚Äôs authentication credentials in some form. This may
be through passive observations of the user‚Äôs hands or interactions
such as handshaking. Physically faking the legitimate user‚Äôs profile,
however, requires applying forces to the device such that they create
structural deformations similar to how the user‚Äôs own hands would.
Eavesdropping and Replay Attack The attacker attempts to
steal acoustic credentials of the legitimate user by eavesdropping
instances of identification attempts. This may be done by position-
ing a microphone near the user as EchoLock is deployed. After
obtaining an audio sample of a signal used to authenticate the user,
the attacker gains possession of the targeted device and replays the
audio sample via an external speaker. During ultrasonic sensing,
the mobile device will transmit and record our acoustic signal. In
order to succeed, the attacker must first suppress or bypass the sig-
nal transmission stage to avoid overlap with their attacking signal,
which is a non-trivial challenge.
Jamming Attack. The attacker in this scenario is focused on
deliberate sabotage of genuine authentication attempts. This may
be carried out by playing loud noise or ultrasonic frequencies near
the user to disrupt the geometry estimation procedure. The attacker
does not necessarily need to know the user‚Äôs credentials to jam the
system. We assume in our assessment that the attacker will utilize
ultrasonic frequencies to decrease the chances of detection by the
ordinary user.
4 SYSTEM OVERVIEW
4.1 Design of EchoLock
As people have small differences in their hand biometrics, it is
critical to design EchoLock in such a way that it can perform fine-
grained acoustic sensing to capture the small differences among
different users‚Äô hand biometrics by using low-cost COTS mobile
devices. The basic idea of EchoLock is to leverage a speaker and
microphone to transmit, receive, and analyze structure-borne sound
Acoustic Feature ExtractionSignal Pre-processingSignal TransmissionHand Geometry ProfilingHand Biometric Identification18khz to 22khzInaudible N-Chirp SequenceEnvironmental Noise RemovalKNN-based Feature SelectionTime-Domain FeaturesFrequency-Domain FeaturesHand Biometric Feature CalculationHand PostureDevice StructureOptimal Chirp SelectionProfile DatabaseProfile PredictionChirp NChirp 1Chirp 2‚Ä¶Structure-borne Sound-based Hand Geometry Sensing Structure-borne Signal SegmentationOptimal Chirp SelectionGeometry EstimationAcoustic FeaturesSession 14: CPS Security ASIA CCS ‚Äô20, October 5‚Äì9, 2020, Taipei, Taiwan774waves as illustrated in Figure 2. Many mobile devices, such as smart-
phones, touch pads, and remote controls, are equipped with such
components and have many applications regarding security and
personalization. EchoLock first transmits an inaudible acoustic se-
quence, consisting of ùëõ inaudible chirp signals ranging from 18kHz
to 22kHz. Then it immediately records the reflections from the
user‚Äôs hand via onboard microphones. This procedure can be initi-
ated by a pre-determined trigger, such as raise [5] or squeeze [25]
detection found in COTS mobile devices.
The recorded response undergoes our Signal Pre-processing phase,
where we apply a band-pass filter to remove ambient noise and
conduct the Structure-borne Signal Segmentation to extract the re-
flection of the transmitted n-chirp signal via the structure-borne
propagation paths. After the Signal Pre-processing, we analyze each
chirp signal in Acoustic Feature Extraction to determine meaningful
features capable of differentiating user hand biometrics in the time
and frequency-domain, including statistical properties such as av-
erage or median, spectral points of the FFT, and MFCC coefficients.
To ensure the effectiveness of the candidate features, we perform
the KNN-based Feature Selection to identify the features that are
sensitive to forces exerted by the user‚Äôs hand. We note that such
features may not necessarily be consistent for the same hand when
holding different physical structures (e.g., a different smartphone)
due to altered sound propagation properties.
Next, our system performs Hand Geometry Profiling and Hand
Biometric Identification to determine the user‚Äôs identity based on
the extracted features. Extracted features representative of the in-
teraction between hand posture and device structure are compiled
into a m√ón matrix data structure, where m corresponds to number
of features, and saved to a Profile Database. This database is then ref-
erenced for a profile match when identifying the user. Through our
experiments with 20 participants, we empirically find that chirps
with different frequency ranges may contain different degrees of
useful information. To combat this, we adopt a Optimal Chirp Se-
lection method to quantify the likelihood a given chirp signal suc-
cessfully captured detailed biometric information. We provide a
select number of chirp signals as inputs for our Geometry Estimation
phase to generate a multi-dimensional characterization array using
the chirp feature matrices. Finally, we employ a machine-learning
based approach to match the extracted hand biometric features with
users‚Äô profiles in Profile Prediction, where our system deduces the
most probable hand geometry match by examining the numerical
distance discrepancies and concludes with a predicted profile label.
This output can control a desired functionality, such as unlocking
a device or switching user accounts.
4.2 Challenges and Requirements
Using a single built-in speaker and microphone available on a mo-
bile device to sense complex hand geometry is an unexplored area.
Because acoustic signals travel rapdily compared to the small di-
mensions (i.e. sensing area) of mobile devices (e.g. 15 cm between
a smartphone speaker and microphone), the existing built-in mi-
crophone can only receive limited acoustic samples (< 20 sam-
ples [33, 37]) to describe a complete propagation. Additionally, the
acoustic signals arriving at the microphone are the combination of
structure-borne propagation and airborne propagation, requiring
delicate separation. The environmental reflections of the acoustic
sensing signals and the ambient noises corrupt the received sound
and make the acoustic analysis of the user‚Äôs holding hand even
harder. Besides addressing these challenges, we also need to con-
sider both security and usability when designing the system. In
particular, the passive user input to our system should be hard to
observe and imitate to meet security requirements.
5 STRUCTURE-BORNE SIGNAL DESIGN
5.1 Sound Propagation on Mobile Devices
Structure-borne sound is most often recognized as vibration and
can be perceived both by ear and touch. From Hooke‚Äôs Law [30], the
speed of sound through a medium can be represented as a function,
formulated as ùëê =
ùëù where ùêæ is the bulk modulus of elasticity,
or Young‚Äôs modulus, and ùëù is the medium density. The structure
path is more direct compared to in the air due to the greater density
and compression resistance of the mobile device, allowing sound
to travel and be received more quickly. This trait is of interest as
propagation through a physical medium provides natural resilience
to reflections from distant obstacles as there is minimal deviation
from the sound path.
(cid:113) ùêæ
However, structure-borne propagation is much more sensitive
to physical disturbances. Interactions such as touching the medium
can significantly alter the acoustic patterns as the contact and force
exerted upon the medium changes how it reverberates. While this
normally poses a challenge for acute acoustic sensing, EchoLock
exploits this for the purposes of recognizing individual people. The
force of a user‚Äôs grip on the mobile device is integral to the system,
essentially extending the medium to encompass both the device
and user‚Äôs hand. Bulk modulus of elasticity can be expressed as:
=
ŒîùëÉ
Œîùëâ/ùëâ0
,
‚àí(ùëù1 ‚àí ùëù0)
(ùëâ1 ‚àí ùëâ0)/ùëâ0
ùêæ =
(1)
for a given differential change in pressure ŒîùëÉ and volume Œîùëâ
relative to an initial volume ùëâ0. The introduction of a stable additive
density ùëâ1 and fluctuating pressure increase ùëù1 by the user changes
K to a dynamic set of elasticity constants. This produces a range
of acoustic patterns representative of how the device is held by a
specific individual at the time of measurement, uniquely shaped
by hand contour, posture, grip pressure, and behavior. Note that
this model is an incomplete explanation as it does not account for
a distributed application of pressure from different focal points of a
user‚Äôs hand. However, we find this explanation sufficient for the
purposes of conveying the intuition behind EchoLock‚Äôs premise.
Structure-borne Propagation Feasibility. A preliminary ex-
periment was performed to gauge the ability for a mobile device to
ascertain environmental conditions using acoustic sensing. Three
different use cases were selected with the intent of demonstrating
that conditions with distinct forces exerted upon the mobile device
could be easily recognized. Figure 3 shows the particular experi-
mental setup for each the three scenarios; having the mobile device
resting in the user‚Äôs hand, on a table, or within the user‚Äôs pocket.
An inaudible chirp signal sweeping from 18 kHz to 22 kHz was
emitted from the bottom device speakers to induce vibration, which
is then recorded by a single microphone near the top of the device.
This captured recording is then examined for features that may iden-
tify environmental origins. The results of these experiments can be
Session 14: CPS Security ASIA CCS ‚Äô20, October 5‚Äì9, 2020, Taipei, Taiwan775(a) Held in hand
(b) Idle on table
(c) Stored in pocket
(d) Euclidean distance of amplitudes recorded from
different scenarios. Lower distances imply similarity.
Figure 3: Preliminary experiments for environment differ-
entiation.
seen in Figure 3(d). Three samples from each use case were obtained
and the average amplitude for each recording was extracted. The
absolute difference was then computed for each combination of
samples to measure statistical distinction between each use case and
show a clear relation between samples originating from different
use cases. Samples native to the same use case displayed naturally
low amplitude difference, which increased when compared to sam-
ples from foreign cases. Note across the diagonal that the difference
is zero as these are comparisons between a sample with itself. This
suggests that, even with minimal sensors and signal processing,
structural-borne sound propagation is capable of communicating
critical information about the immediate surroundings.
5.2 N-chirp Sequence for Acoustic Sensing
Measuring biometric properties of a given person accurately using
only sound propagation requires our signal to satisfy several design
criteria:
‚Ä¢ The signal must be designed in such a way to easily distinguish
between the structure-borne and airborne sound propagation.
‚Ä¢ The transmitted signal should be recognizable such that it can be
easily identified and segmented amid interference from ambient
noise and other acoustic disruptions.
‚Ä¢ The signal should fall within a safe frequency range inaudible
to average human hearing. This is primarily for the purpose of
usability as a noticeably audible signal may pose a nuisance to
some users. Generally speaking, 16kHz is the upper bound of
easily detectable sound for ordinary adults [6].
‚Ä¢ The signal must be able to be deployed on a COTS device, lim-
iting the viable transmission frequency range. Android devices,
for example, are reported to have a maximum sampling rate of
around 44kHz, limiting a practical signal to 22kHz at most [18].
Many devices, however, exhibit considerable attenuation prob-
lems when transmitting frequencies exceeding 20kHz due to
hardware imperfections in onboard speakers [33, 36, 37, 44].
With these considerations, we design a ùëõ-chirp sequence where
ùëõ describes a number of repeating chirp signals utilizing the inaudi-
ble frequency range from 18kHz to 22kHz. Though this frequency
sweep may be perceptible to sensitive groups, such as pets or young
children, the duration is brief (i.e. milliseconds) to minimize distur-
bances. Each chirp consists of 1200 samples, equating to a 25ms