√
˜Ω(n) and obtain error o(1/
n) (smaller than the sampling error!), which we will see is essentially
optimal for any reasonable notion of privacy (in Section 5.1.) If we want error o(1), we can take
k = ˜Ω(n2), which is known to be optimal for diﬀerential privacy if the answers are not coordinated
based on the queries [43] or if the data universe is large (as we will see in Section 5). However, in
Section 4, we will see some beautiful algorithms that can answer many more than n2 queries if the
data universe is not too large (forcing the queries to have some implicit relationships) by carefully
coordinating the noise between the queries.
Optimal Composition. Remarkably, Kairouz, Oh, and Viswanath [63] have given an optimal
composition theorem for diﬀerential privacy, which provides an exact characterization of the best
privacy parameters that can be guaranteed when composing a number of (ε, δ)-diﬀerentially private
mechanisms. The key to the proof is showing that an (ε, δ) generalization of randomized response
(as deﬁned in Section 1.5) is the worst mechanism for composition. Unfortunately, the resulting
optimal composition bound is quite complex, and indeed is even #P-complete to compute exactly
when composing mechanisms with diﬀerent (εi, δi) parameters [81]. Thus, for theoretical purposes
it is still most convenient to use Lemmas 2.3 and 2.4, which give the right asymptotic behavior for
most settings of parameters that tend to arise in theoretical applications.
2.3 Histograms
The bounds of Theorems 2.6 and 2.7 are for arbitrary, worst-case families of counting queries. For
speciﬁc families of counting queries, one may be able to do much better. A trivial example is when
the same query is asked many times; then we can compute just one noisy answer, adding noise
Lap(1/ε), and give the same answer for all the queries. A more interesting example is the family
Qpt of point functions on a data universe X, as deﬁned in Section 1.3. Answering all |X| queries in
Qpt (i.e. estimating the histogram of the dataset) using the above theorems would incur error at
least(cid:112)|X|/εn. However, it turns out that we can achieve error O(log |X|)/εn.
Proposition 2.8 (Laplace histograms). For every ﬁnite data universe X, n ∈ N, and ε > 0, there
is an ε-diﬀerentially private mechanism M : Xn → RX that on every dataset x ∈ Xn, with high
probability M(x) answers all of the counting queries in Qpt(X) to within error
(cid:18) log |X|
(cid:19)
O
.
εn
Proof sketch. Recall that Qpt(X) contains a query qy for each y ∈ X, where on a row w ∈ X, qy(w)
is 1 iﬀ w = y. The mechanism M adds independent noise distributed according to Lap(2/εn)
to the result of each query qy ∈ Qpt. This ensures that each individual noisy answer is ε/2-
diﬀerentially private. To show that we obtain ε-diﬀerential privacy overall, the key observation is
that for two neighboring datasets x, x(cid:48), there are only two queries qy, qy(cid:48) ∈ Qpt on which x and x(cid:48)
diﬀer (corresponding to the values that x and x(cid:48) have in the row where they diﬀer). Thus, the
proof of Basic Composition Lemma (Lemma 2.3) implies that M(x) and M(x(cid:48)) are (2 · (ε/2), 0)-
indistinguishable, as desired.
X → {0, 1}, noting that q(x) = (cid:80)
We can also use the output of this mechanism to answer an arbitrary counting query q :
y∈X qy(x) · q(y). The above mechanism gives us ay = qy(x) +
19
Lap(2/εn) for every y ∈ X, from which we can compute the quantity a = (cid:80)
has expectation q(x) and standard deviation O((cid:112)|X|/εn). For answering multiple queries, we can
y∈X ay · q(y), which
apply Chernoﬀ/Hoeﬀding and union bounds,4 yielding the following:
Theorem 2.9 (arbitrary counting queries via the Laplace histogram). For every set Q of counting
queries on data universe X, n ∈ N, and ε > 0, there is an ε-diﬀerentially private mechanism
M : Xn → RQ such that on every dataset x ∈ Xn, with high probability M(x) answers all the queries
to within error
(cid:32)(cid:112)|X| · log |Q|
(cid:33)
O
εn
.
√
√
Note that the dependence on k = |Q| has improved from
k obtained by advanced composition
log k, at the price of introducing a (rather large) dependence on |X|. Thus, for
or Theorem 2.7 to
a family Q of counting queries on data universe X, it is better to use the Laplace histogram when
|Q| (cid:28) |X| and it is better to use advanced composition or Theorem 2.7 when |X| > |Q|.
Let’s summarize the best error bounds we have seen so far for the example families of counting
queries given in Section 1.3.
Table 2.1: Error bounds for speciﬁc query families on a data universe X of size D = 2d (e.g.
X = {0, 1}d or X = {1, 2, . . . , D}).
Query family Q |Q|
Qpt
(ε, 0)-dp ref
(ε, δ)-dp
(cid:1)
ref
Prop. 2.8
D
˜O(
√
εn
D)
√
εn
O(cid:0) d
O(cid:0) d
(cid:16) dt
˜O(
D)
εn
εn
εn
(cid:1)
(cid:17)
Thm. 2.9
Prop. 2.8 O(cid:0) d
(cid:1)
(cid:18)√
(cid:18) dt/2·√
Thm. 2.6 O
√
εn
D)
√
εn
Thm. 2.9
˜O(
˜O(
D)
εn
Thm. 2.6 O
(cid:19)
Thm. 2.9
Thm. 2.9
Thm. 2.7
Thm. 2.7
(cid:19)
d log(1/δ)·log log d
εn
log(1/δ)·log log d
εn
Qthr
Qconj
Qmeans
D
3d
d
Qconj
t
for t (cid:28) d O(dt) O
We will see substantial improvements to most of these bounds in later sections.
3 Alternatives to Global Sensitivity
In this section, we consider the question of whether we can do better than adding noise Lap(GSq /ε),
where GSq denotes the Global Sensitivity of query q (cf. Theorem 1.3).
As a ﬁrst attempt, let us deﬁne a notion of “Local Sensitivity” at x:
LSq(x) = max(cid:8)q(x) − q(x(cid:48))| : x(cid:48) ∼ x(cid:9) .
4A bit of care is needed since the Lap(2/εn) noise random variables are not bounded. This can be handled by
ﬁrst arguing that with high probability, at most a 2−Θ(t) fraction of the noise random variables have magnitude in
the range [t/εn, 2t/εn). Then, conditioned on the magnitudes of the noise random variables (but not their signs),
we can group the random variables according to their magnitudes (up to a factor of 2) and apply Hoeﬀding to each
group separately.
20
(cid:20)
(cid:20)
Pr
(cid:21)
(cid:21)
The diﬀerence with global sensitivity is that we only take the maximum over datasets x(cid:48) that are
neighbors to our input dataset x, rather than taking the maximum over all neighboring pairs x(cid:48) ˜x(cid:48)(cid:48).
Naively, we might hope that M(x) = q(x)+Noise(O(LSq(x))) might provide diﬀerential privacy.
Indeed, the local sensitivity provides a lower bound on the error we need to introduce:
Proposition 3.1 (local sensitivity lower bound). Let q : Xn → R be a real-valued query and
M : Xn → Y be an (ε, δ)-diﬀerentially private mechanism. Then:
1. For every x0 ∼ x1 ∈ Xn, there is a b ∈ {0, 1} such that
|M(xb) − q(xb)| <
Pr
|q(x0) − q(x1)|
2
≤ 1 + δ
1 + e−ε =
1
2
+ O(δ + ε).
2. For every x ∈ Xn, there is some x(cid:48) at Hamming distance at most 1 from x such that
|M(x(cid:48)) − q(x(cid:48))| <
LSq(x)
2
≤ 1 + δ
1 + e−ε =
1
2
+ O(δ + ε).
Proof.
1. Let Gb =
Then:
(cid:110)
y ∈ R : |y − q(xb)| <
(cid:111)
|q(x0)−q(x1)|
2
and p = min{Pr [M(x0) ∈ G0] , Pr [M(x1) ∈ G1]}.
1 − p ≥ Pr [M(x0) /∈ G0]
≥ Pr [M(x0) ∈ G1]
≥ e−ε · Pr [M(x1) ∈ G1] − δ
≥ e−ε · p − δ.
Solving, we deduce that p ≤ (1 + δ)/(1 + e−ε).
2. Follows from Part 1 by taking x0 = x and x1 ∼ x such that LSq(x) = |q(x) − q(x1)|.
The problem with trying to use the local sensitivity to calibrate the noise is that we don’t want
the amount of noise to itself distinguish between neighboring x and x(cid:48). For instance, let x be such
that q(x) = q(x(cid:48)) = 0 for all x(cid:48) ∼ x, but where there is one such neighbor x(cid:48) ∼ x where x(cid:48) has a
neighbor x(cid:48)(cid:48) such that q(x(cid:48)(cid:48)) = 109. LSq(x) = 0, but LSq(x(cid:48)) is large, and answering queries noisily
based on LSq would violate privacy because it distinguishes between x and x(cid:48).
Still, perhaps one could hope to provide only a small amount of noise if LSq is small everywhere
“near” x. For example, consider the query that asks for the median of n points {x1, x2, . . . xn} ⊆
[0, 1]. The global sensitivity for this query is high. Indeed, consider the instance x where (n + 1)/2
entries are 1 and (n− 1)/2 entries are 0 (and thus the median is 1), as compared to the neighboring
instance x(cid:48) where one entry is changed from 1 to 0 (and thus the median is 0).
On the other hand, if there are many data points near the median, then it would follow that
the local sensitivity is small, not only at x but also at all datasets close to x. For such instances
x, we could indeed get away with adding only a small amount of noise, while maintaining privacy.
This is the type of situation that we will investigate. There are several related approaches that
have been taken along these lines, which we will discuss:
21
1. Smooth Sensitivity [85].
2. Propose-Test-Release [33].
3. Releasing Stable Values [95].
4. Privately Bounding Local Sensitivity [67].
We remark that yet another approach, called restricted sensitivity, aims to add even less noise than
the local sensitivity [12, 67, 27, 88]. The observation is that Proposition 3.1 does not say that the
error on x must be at least LSq(x)/2; rather it says that the error must be at least LSq(x)/2 on x
or one of its neighbors. Thus if we have a hypothesis that our dataset belongs to some set H ⊆ Xn
(e.g. in the case of a social network, we might believe that the graph is of bounded degree), it might
suﬃce to add noise proportional to the restricted sensitivity, where we maximize |q(x)− q(x(cid:48))| over
x ∼ x(cid:48) ∈ H, which can be much smaller than even the local sensitivity. The noise will still need to
be at least LSq(x)/2 on some neighbors x(cid:48) of x, but these can be neighbors outside of H.
3.1 Smooth Sensitivity
Deﬁne Smooth Sensitivity of query q : Xn → R at x as follows:
SSε
q(x) = max{LSq(x(cid:48))e−εd(x,x(cid:48)) : x(cid:48) ∈ Xn},
where d(x, x(cid:48)) denotes Hamming distance. Intuitively, we are smoothing out the local sensitivity,
so that it does not change much between neighboring datasets.
Nissim, Raskhodnikova, and Smith [85] introduced the notion of smooth sensitivity and showed
that:
• Adding noise O(SSε
q(x)/ε) (according to a Cauchy distribution) is suﬃcient for ε-diﬀerential
privacy.
• SSq can be computed eﬃciently when q is the Median query (despite the fact that it is deﬁned
as the maximum over a set of size |X|n), as well as for a variety of graph statistics (under
edge-level diﬀerential privacy, cf. Section 3.4).
Zhang et al. [110] gave an alternative approach to “smoothing out” local sensitivity, which empiri-
cally provides improvements in accuracy.
3.2 Propose-Test-Release
A diﬀerent way to provide less noise is to simply not allow certain queries. That is: rather than
using Laplace noise at a level that is high enough no matter what possible dataset might be queried,
an alternative is to initially propose an amount of noise that seems tolerable, and then test whether