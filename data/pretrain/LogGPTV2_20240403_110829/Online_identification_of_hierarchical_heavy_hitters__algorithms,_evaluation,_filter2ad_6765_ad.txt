introduce a simple technique, lazy expansion to signiﬁcantly reduce
the space requirement.
The basic idea for lazy expansion is very simple. Whenever we
receive a large item with value v satisfying v=Tsplit 2 [k (cid:0) 1; k], we
split it into k smaller items, each with value v=k  2
i = 2
i > 2
i = 2
(1)
(2)
The forecast is simply Fi = Si + Ti. The forecast error is then
Ei = Xi (cid:0) Fi. Big changes can be detected by looking for data
points that signiﬁcantly deviate from the forecast, i.e., with forecast
errors Ei exceeding the (time-varying) detection threshold DTi. For
online change detection, it is common to maintain an exponentially
weighted moving average of jEij and set DTi to be some multiple
of this smoothed deviation.
4.1 Extracting time series
i
(using the no-copy rule), an upper bound XU
Given a trafﬁc cluster (with true trafﬁc volume Xi in interval i),
our summary data structure produces three different values by us-
ing different rules to calculate the amount of missed trafﬁc: a lower
bound XL
(using the
copy-all rule), and an estimate XS
i (using the splitting rule). Our ex-
perience with HHH detection suggests that XS
i often gives the most
accurate estimate (see Section 6.1). Therefore, we use time series
fXS
i g as the input for the Holt-Winters forecast model to obtain ES
and DT S
i , which are estimates for the true forecast errors Ei and
detection thresholds DTi, respectively. We also use XL
i and XU
i
to obtain tight bounds on the true forecast errors Ei as shown in
Section 4.3.
i
i
4.2 Dealing with missing clusters
One important issue we need to deal with is the presence of miss-
ing clusters. A cluster may not appear in the summary structure for
every interval. When this happens, we would still like to estimate
its associated trafﬁc volume, otherwise there will be a gap in the re-
constructed time series. Fortunately, our summary structure allows
us to conveniently obtain such estimates. For example, given a 2-d
missing cluster with key , conceptually all we need to do
is to insert a new element with key  and value 0 into the
summary data structure, which will result in one or more newly cre-
ated fringe nodes. We can then obtain estimates for the ﬁrst newly
created fringe node and use them as the corresponding estimates for
. After this, we can then remove all the newly created
nodes through compression. Note that in the ﬁnal implementation,
we do not need to actually create the new fringe nodes and then re-
move them – we just need to do a lookup to ﬁnd the ﬁrst insertion
position.
4.3 Obtaining bounds on forecast errors
Let the use of superscript L and U on a variable denote the lower
and upper bounds for the variable, respectively. For example, XL
i
denotes the lower bound for Xi. Below we show how to compute
EL
i and EU
A naive solution. At the ﬁrst glance, it seems rather straightfor-
ward to compute EL
i —we can directly apply (1) and (2)
to recursively compute bounds for Si, Ti and then use them to form
bounds for Fi and Ei. More speciﬁcally, we have
i , the bounds for the true forecast errors Ei.
i and EU
S
S
= (cid:12) (S
U
i = (cid:11) X
L
i = (cid:11) X
U
i
L
i = (cid:12) (S
U
i
U
i = X
= S
U
U
i(cid:0)1)
i(cid:0)1 + T
L
L
i(cid:0)1)
i(cid:0)1 + T
U
i(cid:0)1
L
i(cid:0)1
U
i(cid:0)1 + (1 (cid:0) (cid:11)) (S
L
i(cid:0)1 + (1 (cid:0) (cid:11)) (S
U
i (cid:0) S
L
i (cid:0) S
L
i
L
i(cid:0)1) + (1 (cid:0) (cid:12)) T
U
i(cid:0)1) + (1 (cid:0) (cid:12)) T
U
i + T
L
i (cid:0) F
L
i = S
L
i = X
L
i + T
U
i (cid:0) F
U
i
U
i
L
i
F
E
T
T
F
E
(3)
(4)
(5)
(6)
(7)
(8)
i and EU
i = 0 and XU
Unfortunately, reconstruction errors can accumulate exponentially
with this approach and cause the resulted bounds EL
to
be too loose to be useful. This is evident in Figure 13(a), which
shows the forecast error bounds produced by the naive solution when
XL
Our solution. We can obtain tight bounds by directly represent-
ing Si and Ti as linear combinations of Xj (j (cid:20) i) and then in-
corporating the bounds XL
i . More speciﬁcally, let Si =
Pi(cid:0)1
j=1 s[i; j]Xi and Ti = Pi(cid:0)1