Asirra challenge consists of 12 images of cats and dogs. To
solve the challenge, one must identify correctly the subset of
cat images.
Generic attack. A classiﬁer with a success probability 0 <
p < 1 of correctly classifying a single Asirra image succeeds
in solving a 12-image Asirra challenge with probability p12.
Our best classiﬁer is 82.74 % accurate, which implies that
we can solve an Asirra challenge completely automatically
with probability 10.3 %. Note that this success probability
is independent of the probability distribution according to
which Asirra challenges are generated.
Leveraging prior information. This success probabil-
ity can be improved, if the attacker has knowledge of the
prior probability distribution of Asirra challenges over the
space {Cat, Dog}12 (whatever that distribution may be).
Let C = {I1, . . . , I12} denote a 12-image Asirra challenge
and let A = {a1, . . . , a12}, where ai ∈ {Cat, Dog} denote an
assignment of the images I1, . . . , I12 to the “cat” and “dog”
classes. According to Bayes’ rule,
Pr[A|C] = Pr[A] Pr[C|A]/ Pr[C].
The attacker’s goal is to compute maxA Pr[A|C], or equiv-
alently maxA(Pr[A] Pr[C|A]). The ﬁrst term, Pr[A] is the
prior probability distribution that we are assuming is known
to the attacker. The second term, Pr[C|A] can be estimated
by the attacker as follows. Let us assume that the attacker
uses a classiﬁer Cl which produces real-valued outputs, as
Example. The exact rules for creating Asirra challenges are
not speciﬁed precisely in [7]. The basic rule, however, seems
to be that the 12 images of an Asirra challenge are drawn
uniformly at random, either from the full Asirra database
of more than 3,000,000 images, or from a subset of images
of pets located in the geographic vicinity of the user.
If
this assumption is correct, it implies that each image in an
Asirra challenge is drawn independently at random from the
“cat” class with probability q and from the “dog” class with
probability 1 − q. An attacker can learn the value of the
parameter q by observing Asirra challenges. Our own mea-
surements suggest q ≈ 0.5 since we found approximately
the same number of cats and dogs in our sample of the
Asirra database. As explained above, we can leverage this
information to compute the most likely assignment A for
a given challenge: maxA(Pr[A] Pr[C|A]). In this example,
Pr[A] = qw(1 − q)12−w, where w is the number of cats in
A. Using the combined color and texture classiﬁer of sec-
tion 2.3 to estimate Pr[C|A], we solve an Asirra challenge
with probability 10.4 %. This probability of success is only
barely higher than that of the generic attack (10.3%). The
reason is that, with the classiﬁer of section 2.3, the generic
attack already produces assignments that nearly follow a
binomial distribution of cats and dogs.
(cid:1) otherwise. Using
6
Hypothetical example. Consider an hypothetical variant
of Asirra in which every challenge contains exactly 6 images
of cats and 6 images of dogs (this variant is not proposed in
[7]). We now have Pr[A] = 0 if the number of cats and dogs
in A are not equal, and Pr[A] = 1/(cid:0)12
the Bayesian formula above, and the classiﬁer of section 2.3,
we can solve these variant Asirra challenges automatically
with probability 23.8 %. While this variant may be attrac-
tive from a usability point-of-view (users may solve Asirra
challenges faster if they know they must ﬁnd exactly 6 cats),
our analysis shows that it is insecure and should be avoided.
3.1 Partial Credit Algorithm and
Token Bucket Scheme
Two enhancements to Asirra are proposed in [7]. The
ﬁrst is a partial credit algorithm designed to improve the
usability of Asirra for human users. The second is a token
bucket scheme designed to harden Asirra against automated
attacks. In this section, we study the impact of these en-
hancements on the classiﬁer of section 2.3.
Partial credit algorithm (PCA). A user who correctly
classiﬁes 11 of the 12 images in an Asirra challenge is con-
sidered to have “nearly” solved the challenge. The user is
placed in an intermediate state and presented with a sec-
ond challenge. If the user solves or nearly solves the second
challenge (i.e. identiﬁes 11 or 12 images correctly), the user
passes. Otherwise, the user fails and is returned to the de-
fault (non intermediate) state. Table 6 shows the impact of
(cid:1)(cid:2)(cid:3)(cid:1)(cid:4)(cid:3)(cid:5)(cid:2)(cid:3)(cid:5)(cid:4)(cid:3)(cid:6)(cid:2)(cid:2)(cid:3)(cid:2)(cid:3)(cid:7)(cid:2)(cid:3)(cid:8)(cid:2)(cid:3)(cid:9)(cid:2)(cid:3)(cid:1)(cid:2)(cid:3)(cid:6)(cid:2)(cid:2)(cid:3)(cid:10)(cid:11)(cid:12)(cid:13)(cid:14)(cid:15)(cid:16)(cid:15)(cid:17)(cid:15)(cid:18)(cid:18)(cid:19)(cid:20)(cid:20)(cid:21)(cid:22)(cid:23)(cid:20)(cid:24)# trials Classiﬁer success Human success
no PCA
PCA
83.4 % 83.4 %
97.2 % 99.6 %
99.5 % 99.9 %
no PCA
10.3 %
19.5 %
27.8 %
1
2
3
PCA
10.3 %
26.2 %
38.0 %
Table 6: Impact of the partial credit algorithm on
the success of the classiﬁer of section 2.3. For com-
parison, the table also includes the human success
rates reported in [7].
Enhancement
TB-reﬁll
Classiﬁer
success rate
Token bucket
Token bucket
Token bucket
Token bucket + PCA
Token bucket + PCA
Token bucket + PCA
3
2
1
3
2
1
2.9 %
2.0 %
1.1 %
19.0 %
15.3 %
13.0 %
Table 7: Impact of the token bucket scheme on the
success of the classiﬁer of section 2.3.
In [7], the
parameter TB-reﬁll is set to 3.
the partial credit algorithm on the success of the classiﬁer
of section 2.3 (for comparison, the table also includes the
ﬁgures for the human success rate, taken from [7]). With
PCA, the success rate of our automatic classiﬁer is 38.0 %
after 3 challenges. This is unacceptably high, and leads us
to recommend that the partial credit algorithm should not
be deployed with Asirra.
Token bucket scheme. A full description of the token
bucket scheme can be found in [7].
In essence, the token
bucket scheme punishes users who fail a lot of Asirra chal-
lenges. These users must solve correctly two Asirra chal-
lenges in close succession to be considered successful. The
token bucket scheme is parameterized by a parameter TB-
reﬁll, which speciﬁes how many chances the user is given to
correctly solve a second CAPTCHA after solving the ﬁrst
one. A value TB-reﬁll = 1 means that a user who has failed
“too many” Asirra challenges must then solve two successive
CAPTCHAs correctly to be considered successful.
In [7],
the value TB-reﬁll =3 is suggested, which means the user is
allowed 3 trials to solve a second CAPTCHA correctly. Ta-
ble 7 shows the impact of the token bucket scheme on the
success of the classiﬁer of section 2.3. Our results suggest
that PCA leads to weak security, even in combination with
the token bucket scheme. On the other hand, Asirra appears
reasonably secure with the parameter TB-reﬁll =1, since our
attack in that case is only 1.1% successful (of course, this
parameter is bound to also signiﬁcantly decrease the hu-
man success rate, and thus negatively impact the usability
of Asirra).
3.2 Defenses
The best defenses against our machine learning attacks
are IP monitoring schemes, which prevent an adversary from
requesting, and attempting to solve, too many Asirra chal-
lenges. The token bucket scheme proposed in [7], and sum-
marized above in section 3.1, is a clever instantiation of an
IP monitoring scheme. The strictest version of the token
bucket scheme reduces the probability of solving an Asirra
challenge automatically to 1.1% (with, however, a parallel
reduction in the usability of Asirra for humans). The token
bucket scheme could be further strengthened by requiring
users to correctly solve more than two Asirra challenges in
a row. Unfortunately, this would also negatively aﬀect the
ability of humans to pass Asirra challenges. Another ap-
proach to improving the security of Asirra is to increase the
number of images used in challenges.
Distorting, warping or degrading the quality of the im-
ages is unlikely to do much to lower the accuracy of SVM
classiﬁers based on color and texture features, since these
features are largely unaﬀected by global image distortions.
Using greyscale images, instead of color images, may de-
crease the accuracy of the color classiﬁers of section 2.1, but
would likely have little eﬀect on the texture classiﬁers of sec-
tion 2.2. These techniques do not appear promising: they
are unlikely to dent the eﬀectiveness of automatic classiﬁers
without also signiﬁcantly reducing the usability advantage
that is Asirra’s greatest strength. They would amount to
“the arms race found in text CAPTCHAs that [Asirra is]
trying to avoid” [7].
4. RELATED WORK
A number of attacks have been reported against text-
based CAPTCHAs. Mori and Malik [14] proposed object
recognition algorithms that succeeded in recognizing words
in the EZ-Gimpy CAPTCHA with probability 92% and in
the Gimpy CAPTCHA with probability 33%. More recently,
attacks have been reported in the popular press against the
CAPTCHAs used by Yahoo! [15] and Google [16]. Unfor-
tunately, few details are available and it is diﬃcult to as-
certain the validity of these attacks. Very recent work [17]
gives a detailed description of character segmentation at-
tacks against Microsoft and Yahoo! CAPTCHAs.
Beyond Asirra, there have been other proposals for user-
friendly, clickable CAPTCHAs. For example, Lopresti [12]
proposes asking users to select the right orientation of a page
through a click. BotBarrier [2] asks users to click on a spec-
iﬁed location in an image. The security of these proposals
relies on new and relatively untested assumptions. It is not
clear whether these assumptions will withstand the test of
time.
Another approach to clickable CAPTCHAs was recently
proposed by Chow et al. [4]. The approach consists of com-
bining several textual CAPTCHAs into a grid of clickable
CAPTCHAs (e.g. a 3-by-4 grid). The solution to the grid is
the determination (e.g. by clicking) of the grid elements
which satisfy some given requirement. For example, the
user may be asked to identify in the grid the subset of
CAPTCHAs which embed English words (assuming some,
but not all, do). One advantage of this approach is that
it relies on existing security assumptions about text-based
CAPTCHAs that have been in use for a long time and have
been the object of intense scrutiny.
5. CONCLUSION
We describe a classiﬁer which is 82.7% accurate in telling
apart the images of cats and dogs used in Asirra. This clas-
siﬁer allows us to solve a 12-image Asirra challenge with
probability 10.3%. The weakness we have exposed in the
current implementation of Asirra cautions against deploy-
ing Asirra without additional safeguards. With appropriate
safeguards, notably the token bucket scheme described in [7],
we believe that Asirra continues to oﬀer an appealing bal-
ance between security and usability. We hope that this work
will contribute to the secure deployment of Asirra.
[8] P. Golle and D. Wagner. Cryptanalysis of a Cognitive
Authentication Scheme. In Proc. of the 2007 IEEE
Symposium on Security and Privacy, pp.66–70. IEEE
Computer Society
[9] Google CAPTCHA. On the web at https:
//www.google.com/accounts/DisplayUnlockCaptcha
Acknowledgements
I would like to thank David Goldberg, Maurice Chu, Richard
Chow, Glenn Durfee and Kurt Partridge for valuable feed-
back on this project. Glenn and Richard also helped man-
ually classify training images, for which I am very grate-
ful. I would like to thank Jeremy Elson, John Douceur and
Jon Howell for generously answering my questions about
ASIRRA and oﬀering additional labelled images. Finally, I
would like to thank the anonymous reviewers whose com-
ments helped improve this paper.
6. REFERENCES
[1] MSR Asirra: A Human Interactive Proof. On the Web
at http://research.microsoft.com/asirra/
[2] BotBarrier.com. On the web at
http://www.botbarrier.com/
[3] Chih-Chung Chang and Chih-Jen Lin. LIBSVM : a
library for support vector machines, 2001. Software
available at
http://www.csie.ntu.edu.tw/~cjlin/libsvm
[4] R. Chow, P. Golle, M. Jakobsson, X. Wang and
L. Wang. Making CAPTCHAs Clickable. In Proc. of
HotMobile 2008.
[5] C. Cortes and V. Vapnik. Support-vector network.
Machine Learning 20, 273–297, 1995.
[6] J. Douceur and J. Elson. Private communication.
[7] J. Elson, J. Douceur, J. Howell and J. Saul. Asirra: a
CAPTCHA that exploits interest-aligned manual
image categorization. In Proc. of ACM CCS 2007,
pp. 366–374.
[10] T. Hastie, R. Tibshirani and J. Friedman. The
Elements of Statistical Learning (Data Mining,
Inference, and Prediction). Springer Series in
Statistics, 2001.
[11] P. Kruizinga, N. Petkov and S.E. Grigorescu.
Comparison of texture features based on Gabor ﬁlters.
In Proc. of the 10th International Conference on Image
Analysis and Processing (1999), pp. 142–147.
[12] D. Lopresti. Leveraging the CAPTCHA problem. In
Proc. of the Second International Workshop on Human
Interactive Proofs, pp. 97–110. Springer Verlag, 2005.
[13] I. Mironov and L. Zhang. Applications of SAT Solvers
to Cryptanalysis of Hash Functions. In Theory and
Applications of Satisﬁability Testing – SAT 2006, pp.
102–115, 2006.
[14] G. Mori and J. Malik. Recognizing objects in
adversarial clutter: Breaking a visual CAPTCHA. In
Proc. of the 2003 Conference on Computer Vision and
Pattern Recognition, pp. 134–144. IEEE Computer
Society, 2003.
[15] SlashDot. Yahoo CAPTCHA Hacked (posted Jan 29,
2008). On the Web at http:
//it.slashdot.org/it/08/01/30/0037254.shtml
[16] Websense Blog (posted Feb 22, 2008). Google’s
CAPTCHA busted in recent spammer tactics. On the
web at http://securitylabs.websense.com/content/
Blogs/2919.aspx
[17] J. Yan and A. El Ahmad. A Low-cost Attack on a
Microsoft CAPTCHA. To appear in Proc. of ACM
CCS 2008.