alone onto both Fmal and Finject. Therefore, the weight on
Fmal is lowered.
In addition, if a single Finject cannot lower the accuracy
of the na¨ıve Bayes classiﬁer signiﬁcantly, the attacker could
inject a large number of Finject to further lower the accuracy.
Because of the independence assumption in the na¨ıve Bayes
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:08:45 UTC from IEEE Xplore.  Restrictions apply. 
classiﬁer, the larger the number of Finject, the smaller the
weight of Fmal.
Now, we formally show how the accuracy of the na¨ıve
Bayes classiﬁer is lowered. Before computing P (+|Fmal) –
the probability of malice of samples with Fmal, let us take
a ﬁrst look at the computation of P (+|Fmal, Finject), and
then we deduce P (+|Fmal) based on P (+|Fmal, Finject).
the attacker can inject samples with Fmal and
Suppose,
another crafted feature, Finject. As discussed, in the feature
selection stage, Finject is selected based on the chi-squared
test. Now, we have Equation 7 for samples with Fmal and
Finject.
P (+|Fmal, Finject) = P (Fmal, Finject|+)P (+)
P (Fmal, Finject)
= P (Finject|+)P (Fmal|+)P (+)
= P (Finject|+)
P (Finject)
Through transformation (note that
P (Finject)P (Fmal)
P (+|Fmal)
in Equation 7, na¨ıve
Bayes assumes that Fmal and Finject are independent –
i.e., derived from the independence assumption), we have
Equation 8 for P (+|Fmal),
the probability of malice for
samples with just Fmal.
P (+|Fmal) = P (+|Fmal, Finject) P (Finject)
P (Finject|+)
(8)
)
In Equation 8, if P (+|Fmal) is below 0.5 and thus less than
P (−|Fmal), Zozzle classiﬁes samples with Fmal as benign
(−). The purpose of pollution is to make this happen. Because
P (Finject
|+) is a value corresponding to the percentage of
P (Finject
malicious samples in the training set and thus less than 1,
P (+|Fmal) is lowered due to the existence of Finject.
As discussed in last few paragraphs, the injection of one
Finject lowers P (+|Fmal). Now, we show that more injected
features lower P (+|Fmal) even further. Suppose, the injection
of one feature cannot decrease P (+|Fmal) in Equation 8 to a
value below 0.5. An adversary can introduce enough number
of Finject, and as a generalization of Equation 8, we have
Equation 9.
P (+|Fmal) = P (+|Fmal, F1,inject, ..., Fk,inject)
P (Fk,inject)
P (Fk,inject|+)
× P (F1,inject)
P (F1,inject|+)
...
(9)
)
P (Fi,inject
P (Fi,inject
|+) is less than 1,
Because each
if k is large
enough, the attacker can eventually decrease P (+|Fmal) to a
value below 0.5, and hence Zozzle classiﬁes the sample with
Fmal as benign. In summary, by injecting enough features, an
adversary could subvert the detection decision of a malicious
sample in Zozzle.
In practice,
to pollute the training data, we inject ﬁve
features that do not exist in any existing benign samples into
10% of the training set. We retrained the system with the
same training set as well as the newly added samples with
injected features, and the testing samples are still the same
474474
(7)
B. Analytical and Empirical Results
TABLE III: Zozzle’s Detection Rate. The ﬁrst column and the third
column are exactly the same,
illustrating that our unlearning is
complete.
True Positive
False Positive
Original
Polluted
Unlearned
93.1%
0.5%
37.8%
0.3%
93.1%
0.5%
as those before pollution. The detection results are shown in
the second column of Table III. Because of the injection of
features, the true positive rate drops signiﬁcantly from 93.1%
to 37.8%. The false positive rate also drops a little bit from
0.5% to 0.3%, because more benign features are selected from
the feature sets.
Unlearning in Zozzle works as follows. First, the unlearning
process groups all the data to forget together and extract corre-
sponding features from the data to forget. Then, the chi values
of all the features are updated. Since N+,F , N−,F , N+, ˆF , and
N−, ˆF in the chi value calculation (Equation 6) are counts of
samples, or a summation of outputs of indicator functions, one
can easily update the chi value of features. If the chi value of
one feature cannot meet the threshold, the feature is removed.
We reuse the feature selection process implemented by Zozzle
to extract features from the data to forget, and then update the
chi values stored in the database. Then, a new list of features is
generated based on the new chi values. Second, the unlearning
process updates all the conditional probability values related
to updated features found in the ﬁrst step. The detailed process
has already been described in §IV. Note that because none of
the aforementioned updates involve the size of training data
set, the time complexity is O(q), where q is the number of
features.
i.e., updated all
Empirically, we added only 21 lines of code to support
unlearning in Zozzle,
the chi values and
conditional probability. Then, we evaluated the completeness
of unlearning by removing all the crafted samples from Zozzle.
The results show that the feature sets and conditional prob-
abilities after pollution and unlearning are the same as those
generated by unpolluted data, as if the whole pollution process
does not exist. Further, the true positive and false positive after
pollution and unlearning shown in the third column of Table III
are the same as those without data pollution as expected.
the overall
Next, we evaluate the timeliness of unlearning. Because
the size of training samples is huge,
learning
process takes one day and two hours. In contrast, unlearning
one training sample takes less than one second on average,
and the speedup is 9.5×104. The overhead of unlearning is
a linear function to the number of the samples to forget.
As mentioned in §III-A2, when the number of samples to
forget increases, the overhead of unlearning increases, but
the overhead of retraining decreases. When the number of
samples to forget exceeds 63% of the total training samples,
the retraining process is faster than the unlearning technique
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:08:45 UTC from IEEE Xplore.  Restrictions apply. 
used in this section. In such an unlikely case, one may use
retraining to achieve the unlearning task.
VIII. UNLEARNING IN AN OSN SPAM FILTER
We start by introducing how OSNSF [46] uses machine
learning to ﬁlter OSN spams. In the training stage, OSNSF
ﬁrst clusters OSN messages based on the text shingling
distance [26] and the URL elements of the messages, and
then extracts the features of each cluster, such as cluster
size, average social degree, and average time interval of
messages. Next, the features of clusters are used to train a C4.5
decision tree3 [58] for spam ﬁltering. In the detection/ﬁltering
stage, OSNSF incrementally clusters incoming messages and
classiﬁes spam based on the features of the cluster that the
incoming messages belong to.
We obtained the original implementation [45] of OSNSF.
During our evaluation, we adopted all the default values for all
the parameters within their released source code. That is, the
window size is 100,000, aging factor is 0.8, and the shingling
size is 10. The only exception is that the number of threads
is undeﬁned and only affecting the training speed. Thus, we
arbitrarily chose to execute the system in two-thread mode.
In their paper, they evaluated their system upon both Twitter
and Facebook, however we only obtained the original Face-
book data set from the authors. We believe that the pollution
and unlearning process should be similar for the Facebook
and Twitter data sets, which only differ in the data format but
use the same core algorithm. The Facebook data set contains
217,802 spam wall posts and 995,630 legitimate wall posts.
We partition the data set into ten parts, from which nine parts
are used for training and one part is used for testing. Next,
we introduce how we pollute the training data to affect the
detection rate of the spam ﬁltering system.
A. The Attack – Training Data Pollution
OSNSF is more robust to training data pollution than a
traditional machine learning-based detection system. The rea-
sons are twofold: manually picked features and pre-clustering
before machine learning. While manually picked features
introduce human efforts and cannot evolve over time, they pre-
vent an attacker from polluting the feature selection stage (in
which she can craft data to inject fake features). Pre-clustering
of incoming samples can reduce the noises (polluted samples)
introduced by attacks. For example, in the experiment, if we
directly input random mislabeled training data, the ﬁltering
rate is affected to a very small degree (approximately 1%
difference).
However, during pre-clustering stage, if the injected samples
are crafted so that they can form a cluster, they signiﬁcantly
inﬂuence the ﬁltering result. We utilize this fact to successfully
manipulate OSNSF by polluting its training data. In particular,
we craft
training data based on two features in OSNSF:
3In their paper, they have tested both decision tree and support vector
machine (SVM). However,
that “decision tree yields better
accuracy, i.e., higher true positive rate and lower false positive rate”, and
consequently they pick decision tree as the classifying module.
they report
average message interval and social degree, because we ﬁnd
that the two features are more effective than other features
such as cluster size. In the evaluation, we entirely removed the
cluster size parameter from OSNSF and found that the ﬁltering
rate only drops a little. In comparison, both average message
interval and social degree have large impacts on OSNSF, and
further an attacker can manipulate the two parameters. For
example, an attacker can send more or less messages to affect
the average message interval, and friend or de-friend spam
accounts that she owns to change the social degree.
By manipulating the two parameters in OSNSF, we suc-
cessfully pollute the training data and lower the true positive
rate as shown in Figure 3. The x-axis is the rate of polluted
samples in all the training data and the y-axis is the true
positive rate of the system, i.e., the number of true spams
divided by the number of detected spams. As mentioned,
because of the existence of clustering, when the pollution rate
is lower than 1.7%, the effect of pollution on true positive
rate is small. However, when the polluted samples successfully
form into a new cluster, the system utilizes the feature values
represented by the new cluster containing the polluted samples.
Therefore, the true positive rate decreases signiﬁcantly. This
is also reﬂected in the generated decision tree, containing a
branch of the injected feature values.
100
80
60
40
20
)
%
(
e
v
i
t
i
s
o
P
e
u
r
T
0
0
0.5
1
Polluted Sample Rate (%)
1.5
2
2.5
Fig. 3: True Positive Rate of OSNSF vs Percentage of Polluted
Training Data. After only 1.75% of the training data is polluted,
OSNSF’s true positive rate drops sharply because the polluted training
data starts to form a cluster.
B. Analytical and Empirical Results
To enable unlearning for OSNSF,
there are two steps:
decremental clustering and decremental decision tree. The ﬁrst
step – decremental clustering – can be implemented by feeding
polluted samples with the opposite labels into the incremental
clustering interface of the current system, which either merges
new samples into the existing cluster or creates a new cluster.
Therefore, we focus on integrating a decremental decision tree
into the system.
The C4.5 decision tree incorporated by OSNSF does not
support any incremental or decremental algorithm for incom-
475475
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:08:45 UTC from IEEE Xplore.  Restrictions apply. 
TABLE IV: OSNSF’s Detection Rate.
True Positive
False Positive
Original
Polluted
Unlearned
99.1%
0.4%
17.6%
0.0%
98.5%
0.4%
TABLE V: PJScan’s Detection Rate. After unlearning, the detection
rate of PJScan is the same as it was before pollution, illustrating that
our unlearning is complete.
Pollution Rate
Unlearned
0%
21.8% 28.2%
Detection Rate
81.5% 69.3% 46.2%
81.5%
ing data. Therefore, to support unlearning, we adopted another
incremental decision tree – VFDT [38], the implementation of
which is available in the VFML (Very Fast Machine Learning)
toolkit, and the analytical overhead of which is O(logN )
for learning one sample as shown in the VFDT paper. To
incorporate VFDT into OSNSF, we modify VFDT to read the
decision tree generated by C4.5 and learn polluted samples
with the opposite labels. Since VFDT supports the C4.5 data
format, the intermediate output of OSNSF (i.e., the extracted
feature values for each cluster) can be easily fed into VFDT.
Now we show the empirical results. We ﬁrst feed polluted
samples into OSNSF, and OSNSF outputs the features of