title:Code obfuscation against symbolic execution attacks
author:Sebastian Banescu and
Christian S. Collberg and
Vijay Ganesh and
Zack Newsham and
Alexander Pretschner
Code Obfuscation Against Symbolic Execution Attacks
Sebastian Banescu
Technische Universität
PI:EMAIL
München
Christian Collberg
University of Arizona
PI:EMAIL
Vijay Ganesh
University of Waterloo
PI:EMAIL
Zack Newsham
University of Waterloo
PI:EMAIL
Alexander Pretschner
Technische Universität
PI:EMAIL
München
ABSTRACT
Code obfuscation is widely used by software developers to
protect intellectual property, and malware writers to hamper
program analysis. However, there seems to be little work on
systematic evaluations of eﬀectiveness of obfuscation tech-
niques against automated program analysis. The result is
that we have no methodical way of knowing what kinds of
automated analyses an obfuscation method can withstand.
This paper addresses the problem of characterizing the
resilience of code obfuscation transformations against auto-
mated symbolic execution attacks, complementing existing
works that measure the potency of obfuscation transforma-
tions against human-assisted attacks through user studies.
We evaluated our approach over 5000 diﬀerent C programs,
which have each been obfuscated using existing implemen-
tations of obfuscation transformations. The results show
that many existing obfuscation transformations, such as vir-
tualization, stand little chance of withstanding symbolic-
execution based deobfuscation. A crucial and perhaps sur-
prising observation we make is that symbolic-execution based
deobfuscators can easily deobfuscate transformations that
preserve program semantics. On the other hand, we present
new obfuscation transformations that change program be-
havior in subtle yet acceptable ways, and show that they
can render symbolic-execution based deobfuscation analysis
ineﬀective in practice.
1.
INTRODUCTION
This paper addresses the problem of characterizing the re-
silience of practical code obfuscation transformations against
symbolic execution attacks, complementing existing work
that measures the potency of obfuscation transformations
against human-assisted attacks [15]. We consider widely-
used obfuscation techniques (e.g., virtualization) and show
them to be surprisingly ineﬀective against symbolic execu-
tion based analysis and deobfuscation. We propose new ob-
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
ACSAC ’16, December 05 - 09, 2016, Los Angeles, CA, USA
c(cid:13) 2016 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ISBN 978-1-4503-4771-6/16/12. . . $15.00
DOI: http://dx.doi.org/10.1145/2991079.2991114
fuscation techniques that change program behavior in sub-
tle yet acceptable ways, and we show that they are eﬀective
against symbolic execution methods.
Obfuscators (a.k.a. obfuscation compilers or transforma-
tions, ﬁrst formally deﬁned by Barak et al. [8]), are programs
that take as input arbitrary programs1, and transform them
such that the resulting code satisﬁes three properties: (1) it
must be semantically equivalent to the corresponding input
(functionality property), (2) be at most polynomially big-
ger or slower than the input program (slowdown property),
and (3) be as “hard to analyze and deobfuscate” as a black-
box version of the program (virtual black-box property). The
functionality and slowdown properties can be stated with
relative ease, but in general are diﬃcult to prove and can be
as hard as proving correctness of arbitrary compiler trans-
formations. While we acknowledge the relevance of these
concerns, the subject of this paper is the third property.
Dozens of diﬀerent software obfuscation techniques have
been published [19]. They are widely used by both malware
developers and software companies to thwart static or dy-
namic analysis deobfuscation attacks. The sheer volume of
diﬀerent applications and malware variants that can be gen-
erated by obfuscators renders the task of human-assisted
analysis unscalable. Therefore, attackers resort to auto-
mated analyses.
A central issue with today’s practical obfuscating compil-
ers is that they do not clearly deﬁne in how far they are
resilient against automated or manual attacks. How can a
user of an obfuscating compiler know whether the obfusca-
tions advertised by the compiler writer can indeed withstand
highly sophisticated static, dynamic, symbolic, or machine
learning deobfuscation attacks? What kind of assumptions
can one make about the resources available to the attacker?
Can we hope for a happy-medium where an obfuscation
transformation is as resilient as the cryptographic varieties
and yet is practical enough that the slowdown is acceptable?
While we do not provide a general answer to the above
questions, we provide perhaps the ﬁrst systematic approach
to studying obfuscation resilience against automated attacks
based on symbolic execution. As far as the authors are
aware, there is no standard methodology for characteriz-
ing the resilience of diﬀerent obfuscation transformations
w.r.t. each other, against automated attacks. We are aware
of works that focus on the empirical evaluation of the po-
1Without loss of generality, we assume that obfuscators are
source-code transformers that take C programs as inputs.
tency of obfuscation against human-assisted analysis [14,
15]. However, according to the pioneering work of Coll-
berg et al. [20], obfuscation strength should be measured in
terms of both potency against human-assisted attacks and
resilience against automated attacks. This paper is con-
cerned with an empirical evaluation of the latter, with a
focus on symbolic execution. Our work is complementary
to existing work focused on human-assisted attacks, as well
as works that evaluate the resilience of obfuscation against
static analysis attacks [38, 24]. While focusing on symbolic
execution may seem narrow in scope, it has been reported
that a large number of deobfuscation techniques rely on sym-
bolic execution [47].
We emphasize that our paper is empirical in nature, in
contrast to analytical studies on cryptographic obfuscation [8,
29]. An analytical study about characterizing the resilience
of diﬀerent obfuscation transformations is diﬃcult to per-
form because it would need to cater to all programs, pos-
sibly restricted to a family of programs. In this empirical
study we apply obfuscation to limited datasets of programs.
We make the datasets heterogeneous by varying a set of pro-
gram characteristics that make us believe that our ﬁndings
achieve some degree of generality.
This paper makes the following contributions:
1. Proposes an approach for empirically characterizing
the resilience of code obfuscation transformations, based
on the relative increase in slowdown of symbolic exe-
cution engines on obfuscated applications w.r.t. their
unobfuscated counterparts (§ 2).
2. A case-study on over 5000 C programs, two obfusca-
tion engines and two symbolic execution engines (§ 3).
The results of the case study show the resilience of
diﬀerent obfuscation transformations w.r.t. each other
against symbolic execution based attacks.
3. Proposes a way of improving existing obfuscation trans-
formations against symbolic execution by altering the
functionality property from the previously mentioned
obfuscator deﬁnition (§ 4).
2. AUTOMATED ANALYSIS ATTACKS
Automated attacks do not involve any human interaction
during their execution. Step-by-step debugging is one exam-
ple of a human-assisted attack, which involves a high degree
of human interaction. Eﬀectiveness of obfuscation against
human-assisted attacks is diﬃcult to quantify since it not
only depends on the features of the debugger, but also on the
knowledge of the human operating it. Given the same de-
terministic obfuscated program and the same analysis tools
(e.g. IDA Pro [25]), for any two diﬀerent individuals, it will
likely result in signiﬁcantly diﬀerent times to complete the
analysis. On the other hand, executing an automated attack
multiple times (with the same seed, if the attack is random-
ized), on the same obfuscated program results in the same
analysis time minus a negligible delta due to other back-
ground processes and the OS scheduler. Automatic analysis
attacks are relevant for malware analysis, where the num-
ber of diﬀerent malware variants observed in the wild are in
the order of millions per day [40, 52] and cannot be easily
analyzed with human assistance. Generally speaking, au-
tomatic analysis attacks are relevant for scenarios where a
software developer employs software diversity [26, 27] via ob-
fuscation, i.e. diﬀerent end-users run diﬀerently obfuscated
versions of the same program and an attacker targets all
obfuscated versions of that program. This means that the
amount of computing resources an attacker can spend on
an automated analysis attack must be limited in order to
cope with the large amount of obfuscated versions. More-
over, automated attacks that target a large population of
end-users often come in the form of potentially unwanted
programs (PUPs) [40] or changeware [7], executed on end-
user machines, i.e. commodity hardware on average.
2.1 A Common Subgoal of Automated Attacks
Schrittwieser et al. [46] note that motivations of reverse
engineers are diverse. However, their goals can be placed
under the following 2 categories: (1) extracting a propri-
etary algorithm or data (e.g. secret keys, credentials) from
a program and (2) modiﬁcation of software to change its be-
havior, also known as software-tampering. The goals in the
ﬁrst category can be achieved by simplifying the control-ﬂow
and data-ﬂow of the target program such that all irrelevant
constructs and instructions added by obfuscation transfor-
mations are discarded and only the parts essential for func-
tionality are maintained [58]. The goals in the second cate-
gory can be achieved by ﬁrst identifying and disabling any
integrity checks on the code itself [43] and then modifying
the actual functionality of the target program. We believe
that there is a common subgoal for both of these goals.
In order to identify this common subgoal we look towards
state of the art automatic attacks. Such automatic attacks
are often speciﬁc to certain implementations of obfuscation
transformations (e.g. virtualization obfuscation [38, 35, 48,
22], opaque predicates [24], control-ﬂow-ﬂattening [53]) or
certain attacker goals (e.g. control-ﬂow graph (CFG) sim-
pliﬁcation [58], identifying code self-checks [43], bypassing
license checks [6]) or both. Moreover, all of these attacks,
except for those based on abstract interpretation [38, 24]
use dynamic analysis often in combination with some form
of static analysis. The main reason for the use of dynamic
analysis is that obfuscation techniques such as run-time un-
packing and self-modifying code cannot be analyzed stati-
cally. However, a pre-requisite of dynamic analysis is the
generation of valid inputs for the program being analyzed.
How these valid inputs are obtained is not always described
in works that present automatic analysis attacks. In some
works they are picked randomly, in others they are generated
using a symbolic execution engine.
Random test case generation is not suﬃcient for common
attacker goals. We argue that certain automated analysis
attacks require generation of test suites that achieve up to
100% (reachable) code coverage. Firstly, consider the goal
of simplifying the CFG of an obfuscated program as pre-
sented in [58]. In order to ensure that the CFG is complete
(i.e. there are no missing statements, basic blocks or arcs),
the analysis technique requires execution traces that cover
all the code of the program being analyzed. Secondly, con-
sider the goal of identifying code which veriﬁes checksums
of other parts of the code as presented in [43]. To ensure
that all self-checking code instructions are identiﬁed (which
is mandatory in case there is a cyclic dependency between
the instructions which perform checking [16, 36]), the anal-
ysis technique requires execution traces that cover all the
code of the program being analyzed. Thirdly, consider the
goal of bypassing a license check as presented in [6]. If the
license check is performed by a conditional statement based
on an input to the program, generating a test suite that
covers all the code of the program guarantees that one of
the test cases contains the license key. However, unlike the
previous two goals, a test suite that achieves 100% code cov-
erage is suﬃcient, but not necessary, because the license key
may be guessed correctly before the test suite covers 100%
of the code. Nevertheless, we believe that test case genera-
tion is a common pre-requisite for all state of the art auto-
matic analysis attacks. Hence, our proposal in this paper is
to characterize the resilience of obfuscation transformations
based on the increase in the eﬀort needed to generate test
cases for the obfuscated program relative to its unobfuscated
counterpart.
We acknowledge the fact that after achieving this subgoal,
an automatic analysis attack may need to perform further
tasks to achieve its end goal. However, those tasks are dif-
ferent for diﬀerent attacker goals, while the subgoal of au-
tomated test case generation is common for most state of
the art attacks. We claim that the eﬀectiveness of an ob-
fuscation transformation can be measured by the increase in
eﬀort (i.e. slowdown) for automated test case generation.
2.2 Automated Test Case Generation
The main techniques for automated test case generation
according to Anand et al. [1] are: symbolic/concolic execu-
tion, model-based test case generation, combinatorial test-
ing, fuzzing, (adaptive) random testing and search-based
testing. By “automated” we mean that the user does not
need to provide any speciﬁcation to the test generation met-
hod, only the program source or binary code is needed.
These test case generation techniques can be further divided
into white-box testing techniques (i.e. symbolic/concolic ex-
ecution), which analyze the program code to guide test case
generation and black-box testing techniques (i.e. model-based
testing, combinatorial testing, fuzzing, adaptive random test-
ing and search based testing), which do not analyze but sim-
ply run the code.
Since obfuscation techniques change the code of a pro-
gram but not its input-output behavior, they only aﬀect
white-box testing techniques, modulo any overhead which is
also incurred by black-box testing techniques due to execut-
ing any additional instructions in the obfuscated version of a
program. We hence argue that the eﬀectiveness of applying
one or more obfuscation transformations can be measured
by the increase in eﬀort needed for a white-box testing tech-
nique to generate a test suite that covers all the code of
the given program (e.g. for the goal of CFG simpliﬁcation)
or to ﬁnd an input that leads to a certain execution path
(e.g. guessing a license key).
If the absolute eﬀort for a white-box testing technique
to generate a test suite for an obfuscated program surpasses
the eﬀort for a black-box testing technique to generate a test
suite that covers the same paths for the same program, then
the attacker will use the test suite output by the black-box
testing technique. Hence, we recommend bounding the num-
ber of obfuscation transformations applied (to protect a pro-
gram), by the shortest time needed for a black-box test case
generator to produce a test suite that covers all the code of
a given binary or to ﬁnd an input that leads to a certain exe-
cution path. For instance, consider a program with a simple
control-ﬂow structure such as: if (x > 127) . . . else . . . ,
where x is an unsigned byte input value. Obfuscating this
program using multiple layers of obfuscation could certainly
make it hard to analyze statically. However, from the point
of view of dynamic analysis this program has only 2 paths.
Moreover, a black-box testing technique has a 50% probabil-
ity of ﬁnding a test case that covers each of the 2 paths due
to the fact that the if-statement on line 1 divides the range
of input values into 2 equally sized subranges. Note that this
probability changes depending on the range and number of
inputs as well as the types of conditional branches inside the
code. The eﬀort needed by a black-box test case generator
is correlated with the path(s) for which the probability of
ﬁnding an input is the lowest [31].
2.3 Symbolic and Concolic Execution
Symbolic execution as originally described by King [39]
involves simulating the execution of a program by replacing
input values of a program with “symbolic” values. As the
simulation of the execution progresses constraints are added