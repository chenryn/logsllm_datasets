I understand that you are trying to replace the final softmax layer of a VGG16 model with a new one, specifically changing the number of output units from 1000 to 10. However, it appears that the `model.layers.pop()` method is not fully updating the model, as indicated by the shapes of the input and output of the last few layers. Below, I have provided a more structured and professional version of your explanation, along with a potential solution.

---

### Problem Description

I am attempting to modify a pre-trained VGG16 model by replacing its final softmax layer, which has 1000 output units, with a new softmax layer that has 10 output units. The original model structure includes the following layers:

```python
model.add(Dense(4096, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1000, activation='softmax'))
```

After loading the pre-trained weights, I use `model.layers.pop()` to remove the last two layers (the dropout and the dense layer with 1000 units) and then add a new dropout layer and a dense layer with 10 units:

```python
model.load_weights('./vgg16_weights.h5')
model.layers.pop()
model.layers.pop()
model.add(Dropout(0.5))
model.add(Dense(10, activation='softmax'))
```

Finally, I compile the model with the Stochastic Gradient Descent (SGD) optimizer:

```python
sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(optimizer=sgd, loss='categorical_crossentropy')
```

However, when I check the input and output shapes of the last three layers, I find the following:

```python
print(model.layers[-1].output_shape)  # (None, 10)
print(model.layers[-1].input_shape)   # (None, 1000)
print(model.layers[-2].input_shape)   # (None, 1000)
print(model.layers[-2].output_shape)  # (None, 1000)
print(model.layers[-3].output_shape)  # (None, 4096)
print(model.layers[-2].name)          # 'dropout_3'
print(model.layers[-3].name)          # 'dense_2'
print(model.layers[-1].name)          # 'dense_4'
```

It seems that the `model.layers.pop()` method does not fully update the model, as the input shape for the new dense layer is still 1000 instead of 4096.

### Environment Details

- **Operating System:** macOS 10.11.5
- **Keras and TensorFlow:** Recently updated
- **Theano:** Not used due to an "Illegal instruction: 4" error

### Potential Solution

To ensure that the model is properly updated after popping the layers, you can create a new model using the functional API, which allows for more control over the model's architecture. Here is how you can do it:

```python
from keras.models import Model
from keras.layers import Input, Dense, Dropout
from keras.optimizers import SGD

# Load the pre-trained VGG16 model
base_model = VGG16(weights='imagenet', include_top=True)

# Remove the last two layers
base_model.layers.pop()
base_model.layers.pop()

# Create a new input layer
input_tensor = base_model.input

# Add the new layers
x = base_model.output
x = Dropout(0.5)(x)
output_tensor = Dense(10, activation='softmax')(x)

# Create a new model
new_model = Model(inputs=input_tensor, outputs=output_tensor)

# Compile the new model
sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)
new_model.compile(optimizer=sgd, loss='categorical_crossentropy')

# Print the summary of the new model to verify the changes
new_model.summary()
```

This approach ensures that the new layers are correctly connected and the model is properly updated.