here all methods recover all legitimate instructions (actually,
all results have been checked manually).
TABLE XIII: Sparse disassembly opaque predicates
sample
simple-if
huffman
mat_mult
bin_search
bubble_sort
no
obf.
37
558
249
105
121
Obfuscated
perfect
IDA
Objdump
185
3226
854
833
1026
240
3594
1075
1110
1531
244
3602
1080
1115
1537
BINSEC
sparse
185
3226
854
833
1026
gain
vs IDA
(sparse)
23,23%
10,26%
20,67%
24,95%
32,98%
TABLE XIV: Sparse disassembly stack tampering
sample
simple-if
huffman
mat_mult
bin_search
bubble_sort
no
obf.
37
558
249
105
121
Obfuscated
perfect
IDA
Objdump
83
659
461
207
170
95
678
524
231
182
98
683
533
238
185
BINSEC
sparse
83
659
461
207
170
gain
vs IDA
(sparse)
14.45%
2.80%
12.0%
10.39%
6.6%
In both cases, sparse disassembly achieves a perfect score –
recovering all but only legitimate instructions, performing better
than IDA and Objdump. Especially, when opaque predicates
are considered, sparse disassembly recovers up to 32% less
instructions than IDA.
Improvement over dynamic analysis. We now seek to assess
whether sparse disassembly can indeed enlarge a dynamic
analysis in a signiﬁcant yet guaranteed way, i.e., without adding
dead instructions. We consider 5 larger coreutils programs
obfuscated with O-LLVM. We compare sparse disassembly to
dynamic analysis (starting from the same trace). The number of
recovered instructions is again a good metric of precision (the
bigger, the better), since both methods report only legitimate
instructions on these examples (we checked that BB-DSE
was able to ﬁnd all inserted opaque predicates). Results are
reported in Table XV. We also report the output of IDA
and Objdump for the sake of information, yet recall that
these tools systematically get fooled by opaque predicates and
recover many dead instructions. The important metric here
is the differential between dynamic disassembly and sparse
disassembly. Moreover, note that the absolute coverage of both
dynamic and sparse disassembly can naturally be improved
using more dynamic traces.
TABLE XV: Sparse disassembly coreutils
Obfuscated
sample
Tr.len
basename
env
head
mkdir
mv
1,783
3,692
17,682
1,436
14,346
Objdump
IDA
20,776
19,714
32,840
57,238
115,278
20,507
19,460
32,406
56,767
114,067
Dynamic
disas.
1,159
477
1,299
1,407
5,261
BINSEC
sparse
7,894
6,743
19,807
10,428
81,596
Actually, these experiments demonstrate that sparse disas-
sembly is an effective way to enlarge a dynamic disassembly,
in a both signiﬁcant and guaranteed manner. Indeed, sparse
disassembly recovers between 6x and 16x more instructions
than dynamic disassembly, yet it still recovers much less
than linear sweep – due to the focused approach of dynamic
disassembly and the guidance of BB-DSE. Hence, sparse
disassembly stays close to the original trace.
Conclusion. The carried experiments showed very good and
accurate results on controlled samples, achieving perfect dis-
assembly. From this stand-point, sparse disassembly performs
better than combination of both recursive and linear like in
IDA, with up to 30% less recovered instructions than IDA.
The coreutils experiments showed that sparse disassembly
is also an effective way to enlarge a dynamic disassembly in a
both signiﬁcant and guaranteed manner. In the end, this is a
clear demonstration of infeasibility-based information used in
the context of disassembly.
Yet, our sparse disassembly algorithm is still very preliminary.
It is currently limited by the inherent weaknesses of recursive
disassembly (rather than sparse disassembly shortcomings),
for example the handling of computed jumps would require
advanced pattern techniques.
X. DISCUSSION: SECURITY ANALYSIS
From the attacker point of view, three main counter-measures
can be employed to hinder our approach. We present them as
well as some possible mitigation.
646
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:18:31 UTC from IEEE Xplore.  Restrictions apply. 
The ﬁrst counter-measure is to artiﬁcially spread the compu-
tation of the obfuscation scheme over a long sequence of code,
hoping either to evade the “k” bound of the analysis (false
negatives) or to force a too high value for k (false positives or
timeouts). Nevertheless, it is often not necessary to backtrack
all the dependencies to prove infeasibility. An example is given
in X-TUNNEL were many predicates have a dependency chain
longer than the chosen bound (k=16, chain up to 230) but
this value was most of the time sufﬁcient to gather enough
constraints to prove predicate opacity. Moreover, a very good
mitigation for these “predicates with far dependencies” is to
rely on a more generic notion of the k bound, based for example
on def-use chain length or some formula complexity criterias
rather than a strict number of instructions.
The second counter-measure is to introduce hard-to-solve
predicates (based for example on Mixed-Boolean Arith-
metic [43] or cryptographic hashing functions) in order to
lead to inconclusive solver responses (timeout). As we cannot
directly inﬂuence the solving mechanism of SMT solvers,
there is no clear mitigation from the defender perspective.
Nonetheless, solving such hard formula is an active research
topic and some progress can be expected in a middle-term on
particular forms of formulas [44]. Moreover, certain simpli-
ﬁcations typically used in symbolic execution (e.g., constant
propagation or tainting) already allow to bypass simple cases
of a priori difﬁcult-to-solve predicates Additionally, triggering
a timeout is already a valuable information, since BB-DSE with
reasonable k bound usually does not timeout. The defender
can take advantage of it by manually inspecting the timeout
root cause and deduce (in-)feasible patterns, which can now
be detected through mere syntactic matching. In the same vein,
timeout may pinpoint to the reverser the most important parts
of the code, unless hard predicates are used everywhere, with
a possibly very signiﬁcant runtime overhead. Finally, such
counter-measures would greatly complicate the malware design
(and its cost!) and a careless insertion of such complex patterns
could lead to atypical code structures prone to relevant malware
signatures.
Actually, our experiments show that symbolic methods are
quite efﬁcient for deobfuscation. Yet, it is clear that dedicated
protections could be used, and indeed such anti-DSE protections
have been recently proposed [45], [10]. We are in the middle
of a cat-and-mouse game, and our objective is to push it further
in order to signiﬁcantly raise the bar for malware creators.
The third counter-measure is to add anti-dynamic tricks,
in order to evade the ﬁrst step of dynamic disassembly. Yet,
since our technique works with any tracer technology, the
dynamic instrumentation can be strengthened with appropriate
mitigations. Interestingly, certain dynamic tricks can be easily
mitigated in a symbolic setting, e.g., detection based on timing
can be defeated by symbolizing adequat syscalls.
XI. RELATED WORK
DSE and deobfuscation. Dynamic Symbolic Execution has
been used in multiple situations to address obfuscation,
generally for discovering new paths in the code to analyze.
Recently, Debray at al. [10], [11] used DSE against conditional
and indirect jumps, VM and return-oriented programming on
various packers and malware in order to prune the obfuscation
from the CFG. Mizuhito et al. also addressed exception-based
obfuscation using such techniques [46]. Recent work from
Ming et al. [12] used (forward) DSE to detect different classes
of opaque predicates. Yet, their technique has difﬁculties to
scale due to the trace length (this is consistent with experiments
in Section VI-A). Indeed, by doing it in a forward manner they
needlessly have to deal with the whole path predicate for each
predicate to check. As consequence they make use of taint to
counterbalance which far from being perfect brings additional
problems (under-tainting/over-tainting).
DSE is designed to prove the reachability of certain parts
of code (such as path, branches or instructions). It is com-
plementary to BB-DSE in that it addresses feasibility queries
rather than infeasibility queries. Moreover, BB-DSE scales very
well, since it does not depend on the trace length but on the
user-deﬁned parameter k. Thus, while backward-bounded DSE
seems to be the most appropriate way to solve infeasibility
problems no researches have used this technique.
Backward reasoning. Backward reasoning is well-known in
inﬁnite-state model checking, for example for Petri Nets [47].
It is less developed in formal software veriﬁcation, where
forward approaches are prevalent, at the notable exception of
deductive veriﬁcation based on weakest precondition calculi
[18]. Interestingly, Charreteur et al. have proposed (unbounded)
backward symbolic execution for goal-oriented testing [48].
Forward and backward approaches are well-known to be
complementary, and can often be combined with beneﬁt [49].
Yet, purely backward approaches seem nearly impossible
to implement at binary level, because of the lack of a priori
information on computed jumps. We solve this problem in BB-
DSE by performing backward reasoning along some dynamic
execution paths observed at runtime, yet at the price of (a
low-rate of) false positives.
Disassembly. Standard disassembly techniques have already
been discussed in Section IX. Advanced static techniques
include recursive-like approaches extended with patterns dedi-
cated to difﬁcult constructs [2]. Advanced dynamic techniques
take advantage of DSE in order to discover more parts of
the code [14], [28]. Binary-level semantic program analysis
methods [15], [16], [17], [13], [50] does allow in principle a
guaranteed exhaustive disassembly. Even if some interesting
case-studies have been conducted, these methods still face
big issues in terms of scaling and robustness. Especially, self-
modiﬁcation is very hard to deal with. The domain is recent,
and only very few work exist in that direction [51], [52]. Several
works attempt to combine static analysis and dynamic analysis
in order to get better disassembly. Especially, CODISASM [3]
take advantage of the dynamic trace to perform syntactic static
disassembly of self-modifying programs.
Again, our method is complementary to all these approaches
which are mainly based on forward reasoning [53].
647
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:18:31 UTC from IEEE Xplore.  Restrictions apply. 
Obfuscations. Opaque predicates were introduced by Coll-
berg [4] giving a detailed theoretical description and possible
usages [54], [55] like watermarking. In order to detect them
various methods have been proposed [56], notably by abstract
interpretation [52] and in recent work with DSE [12]. Issues
raised by stack tampering and most notably non-returning
functions are discussed by Miller [2]. Lakhotia [6] proposes a
method based on abstract interpretation [6]. None of the above
solutions address the problem in such a scalable and robust
way as BB-DSE does.
XII. CONCLUSION
Many problems arising during the reverse of obfuscated
codes come down to solve infeasibility questions. Yet, this
class of problem is mostly a blind spot of both standard
and advanced disassembly tools. We propose Backward-
Bounded DSE, a precise, efﬁcient, robust and generic method
for solving infeasibility questions related to deobfuscation.
We have demonstrated the beneﬁt of the method for several
realistic classes of obfuscations such as opaque predicate and
call stack tampering, and given insights for other protection
schemes. Backward-Bounded DSE does not supersede existing
disassembly approaches, but rather complements them by ad-
dressing infeasibility questions. Following this line, we showed
how these techniques can be used to address state-sponsored
malware (X-TUNNEL) and how to merge the technique with
standard static disassembly and dynamic analysis, in order to
enlarge a dynamic analysis in a precise and guaranteed way.
This work paves the way for precise, efﬁcient and disassembly
tools for obfuscated binaries.
REFERENCES
[1] C. Collberg and J. Nagra, Surreptitious Software: Obfuscation, Water-
marking, and Tamperprooﬁng for Software Protection. Addison-Wesley
Professional, 2009.
[2] B. P. Miller and X. Meng, “Binary code is not easy,” in ISSTA 2016.
ACM, 2016.
[3] G. Bonfante, J. Fernandez, J.-Y. Marion, B. Rouxel, F. Sabatier, and
A. Thierry, “Codisasm: Medium scale concatic disassembly of self-
modifying binaries with overlapping instructions,” in CCS 2015. ACM,
2015.
[4] C. Collberg, C. Thomborson, and D. Low, “Manufacturing cheap,
resilient, and stealthy opaque constructs,” in POPL 1998. ACM, 1998.
[Online]. Available: http://doi.acm.org/10.1145/268946.268962
[5] A. Moser, C. Kruegel, and E. Kirda, “Limits of static analysis for malware
detection,” in ACSAC 2007, Dec 2007.
[6] A. Lakhotia, E. U. Kumar, and M. Venable, “A Method for Detecting
Obfuscated Calls in Malicious Binaries,” IEEE Trans. Softw. Eng., vol. 31,
no. 11, Nov. 2005.
[7] K. A. Roundy and B. P. Miller, “Binary-code obfuscations in prevalent
packer tools,” ACM Comput. Surv., vol. 46, no. 1, Jul. 2013.
[8] P. Godefroid, M. Y. Levin, and D. A. Molnar, “SAGE: whitebox fuzzing
for security testing,” Commun. ACM, vol. 55, no. 3, 2012. [Online].
Available: http://doi.acm.org/10.1145/2093548.2093564
[9] C. Cadar and K. Sen, “Symbolic execution for software testing: three
decades later,” Commun. ACM, vol. 56, no. 2, 2013. [Online]. Available:
http://doi.acm.org/10.1145/2408776.2408795
[10] B. Yadegari and S. Debray, “Symbolic execution of obfuscated code,” in
CCS 2015. ACM, 2015.
[12] J. Ming, D. Xu, L. Wang, and D. Wu, “Loop: Logic-oriented opaque
predicate detection in obfuscated binary code,” in CCS 2015. ACM,
2015.
[13] S. Bardin, P. Herrmann, and F. Védrine, “Reﬁnement- based CFG
reconstruction from unstructured programs,” in VMCAI 2011, 2011.
[14] D. Brumley, C. Hartwig, M. G. Kang, Z. Liang, J. Newsome,
P. Poosankam, and D. Song, “BitScope: Automatically dissecting
malicious binaries,” School of Computer Science, Carnegie Mellon
University, Tech. Rep. CS-07-133, Mar. 2007.
[15] G. Balakrishnan and T. W. Reps, “WYSINWYX: what you see is not
what you execute,” ACM Trans. Program. Lang. Syst., vol. 32, no. 6,
2010.
[16] J. Kinder and H. Veith, “Precise static analysis of untrusted driver