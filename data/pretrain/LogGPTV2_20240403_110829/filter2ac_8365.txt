titleblackhat:asia-21 Hiding Objects from Computer Vision by Exploiting Correlation Biases
In this study, we find that a correlation bias exists in major computer vision systems and exploit it to automatically craft adversarial images.Objects commonly found together in nature have a strong correlation with each other. This leads computer vision systems to develop a bias for detecting these objects together. For example, almost any round shape next to a dog will be seen as a frisbee by computer vision systems trained on the COCO dataset, since dogs and frisbees appear together very often in both nature and the dataset. The same is true in reverse. Objects that have very weak correlation such as stop signs and pizza will be harder to detect when they appear together. Using these correlation biases, we generate adversarial images using RetinaNet, YOLOv3 and TinyYOLOv3 trained on the COCO dataset as detectors. First, we determine the target object to hide. Second, we extract objects with a detection certainty above 95% from the COCO dataset and combine them with low correlation (less than 5%) backgrounds. Finally, we re-detect the target object and choose adversarial images in which the target object is now completely hidden. In addition, we confirm that the crafted adversarial images can be used to attack arbitrary systems where access to the training dataset or knowledge of the network is not available. We evaluate 1,000 adversarial images on leading commercial computer vision systems and receive a 90% success rate on fooling these completely different systems. We also make sure that our crafted adversarial images work in physical environments by pasting the printouts of crafted adversarial backgrounds behind physical objects, taking photos from different angles and confirming that the objects are no longer detected.