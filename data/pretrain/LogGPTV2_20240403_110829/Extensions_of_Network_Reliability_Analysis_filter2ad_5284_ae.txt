). The only nontrivial condition
requires the KL divergence DKL(Y ||X), as a function of a
and b, has a unique minimum (Assumption A3b in [24]). It is
R log fX (u)fY (u)du, which
therefore sufﬁcient to show that
can be rewritten into − log B(a, b) + (a − 1)U1 + (b − 1)U2,
R log ufY (u)du and
has a unique maximum, where U1 =
R log(1 − u)fY (u)du are independent functions of a
U2 =
and b. Since Beta functions are log-convex (Theorem 6 in [5]),
it follows that − log B(a, b)+(a−1)U1+(b−1)U2 is a concave
function in a and b, therefore it has a unique maximum.
∗
, b
(cid:14)
(cid:14)
(cid:14)
Fig. 9: Contour plot of the empirical copula in Figure 2 at
constant v slices. For each slice, we ﬁt the non-constant part of
the copula using a cubic Bezier curve that can be tuned via θ1
and θ2 (Equation 26 and 27). In this example, θ1 = θ2 = 0.8.
APPENDIX C
KOLMOGOROV-SMIRNOV DISTANCE
∗
Although MLE minimizes the divergence from the empiri-
cal distribution and is consistent, it is not clear how to estimate
DKL(Y ||X
) given Yk and ˆXk, where ˆXk ∼ Beta(ˆak, ˆbk),
and how to compute the conﬁdence band for the estimate.
Fortunately, both questions can be answered using the tech-
nique developed in [2], which works for MLE when the
estimator is consistent [3]. In summary, instead of using the KL
divergence to measure the closeness between pdfs, we switch
to use a Kolmogorov-Smirnov-type (KS) metric to measure
the distance between cdfs. Babu [2] deﬁned the KS distance
∗ given k samples y1:k of Y as
between Y and X
√
∗|y1:k) =
k sup
|FYk (u) − F ˆXk (u) − FY (u) + FX∗ (u)|.
Although the distribution of Dk is unknown, [2] showed that
as k → ∞, it tends to the same limiting distribution as the
∗
k depends on y1:k and
distribution of a statistic D
is obtained via bootstrap resampling. Based on this result, we
can bound the difference between Y and X
∗ according to
∗
k, where D
Dk(Y, X
u
FYk (u) − F ˆXk (u) − Jk(α) ≤ FY (u) − FX∗ (u)
≤ FYk (u) − F ˆXk (u) +J k(α) for all u
→ α
(22)
for all α ∈ (0, 1), where Jk(α) = 1√
band and F
∗
k.
D
−1
D∗
(α) is the conﬁdence
is the quantile function of the bootstrap statistic
k F
−1
D∗
k
k
(cid:15)
P r
(cid:16)
APPENDIX D
FITTING COPULA FUNCTION
∗
−1
Qi (v)), we ﬁt the copula function
= FPi (F
using a cubic Bezier curve
When u ≤ v
(u,C(u, v))
= (1 − t)
3
T ≈ (Ω1(t), Ω2(t))
3(1 − t)
2
T
ω0+
ω3
3
2
ω2 + t
tω1 + 3(1− t)t
(23)
where ωi for i = 0, 1, 2, 3 are control points of the curve,
t ∈ [0, 1], Ω1(0) = 0, and Ω1(1) = v
∗. By applying the
boundary conditions, we can deduce ω0 and ω3 as
T
= (0, 0)
∗
T
= (v
= (0,C(0, v))
∗
, v))
= (v
ω0 = (Ω1(0), Ω2(0))
ω3 = (Ω1(1), Ω2(1))
(24)
(25)
,C(v
, v)
∗
T
T
T
T
.
,
(cid:9) array of k samples
(cid:9) initialization
← quantile function of P = Beta(ap, bp)
← quantile function of Q = Beta(aq, bq)
X ← Beta(ax, bx)
U ← U nif orm(0, 1)
−1
F
−1
P
F
y1:k ← k-element array
Q
for i ← 1 to k do
Algorithm 2 Generating samples of Y in Equation 18.
Input: ax, bx, ap, bp, aq, bq, θ1, θ2, k
Output: y1:k
1: function SAMPLEY(ax, bx, ap, bp, aq, bq, θ1, θ2, k)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
u ← random sample from U
s ← random sample from U
x ← random sample from X
v ← c
p ← F
q ← F
yi ← (1 − x)p + xq
return y1:k
(−1)
(s)
u
−1
P (u)
−1
Q (v)
(cid:9) quasi-inverse conditional cdf
that C(u, v) is non-decreasing in u,
To leverage the fact
C(u, v) ≤ min(u, v) [18], and C(u, v) is smooth at u = v
∗, we
restrict ω1 to be on the diagonal line segment between (0, 0)T
and (v, v)T and ω2 on the horizontal line segment between
(v, v)T and (v
, v)T , i.e.
∗
T
,
,
T
∗
, v)
ω1 = (θ1v, θ1v)
ω2 = ((1 − θ2)v + θ2v
(26)
(27)
where θ1, θ2 ∈ [0, 1] are the tuning parameters of the control
points ω1 and ω2. Intuitively, θ1 controls how fast each Bezier
curve deviates from the diagonal line and θ2 control how
fast each curve joins the horizontal line. To demonstrate the
choice of cubic Bezier curves in general and of ω1 and ω2
in particular, Figure 9 shows the contour plot of the same
copula at constant v slices and the ﬁtting Bezier curve for
each slice. Here θ1 and θ2 are chosen to minimize the L1-
norm error of the entire ﬁtting surface. As a side note, since
∗ ≤ v for all v, hence the
P r(Qi ≥ Pi) = 1 almost surely, v
green dashed curve never lies above the diagonal line.
APPENDIX E
DETAIL OF MONTE CARLO SIMULATION
Algorithm 2 generates k samples of Y deﬁned in Equation
18. At line 11, we use the quasi-inverse function of a condi-
(−1)
(t). Based on Equation 19, the conditional cdf
tional cdf c
u
is deﬁned as
(cid:17)
cu(v) =
∂C(u, v)
∂u
=
0,
∂Ω2(t)
∂Ω1(t) ,
∗
if u ≥ v
otherwise
where t ∈ [0, 1] satisﬁes Ω1(t) = u as before. Note that we
can obtain the close form of ∂Ω2(t)
∂Ω1(t) by invoking the chain rule
∂Ω2(t)/∂t
∂Ω2(t)
∂Ω1(t)/∂t . Furthermore, cu(v) is a proper cdf, i.e. it
∂Ω1(t) =
is non-decreasing in v, cu(0) = 0, and cu(1) = 1. Finally, we
can deﬁne the quasi-inverse function of the conditional cdf as
(−1)
u
(s) = sup{v |cu(v) ≤ s}.
c
98
[23] VALIANT, L. G. The Complexity of Enumeration and Reliability
Problems. SIAM Journal on Computing 8, 3 (1979), 410–421.
[24] WHITE, H. Maximum likelihood estimation of misspeciﬁed models.
Econometrica 50, 1 (1982), 1–25.
[25] ZHAI, E., CHEN, R., WOLINSKY, D. I., AND FORD, B. Heading off
correlated failures through independence-as-a-service. In Proceedings of
the 11th USENIX Conference on Operating Systems Design and Imple-
mentation (Berkeley, CA, USA, 2014), OSDI’14, USENIX Association,
pp. 317–334.
REFERENCES
[1] ASTHANA, S., KING, O. D., GIBBONS, F. D., AND ROTH, F. P.
Predicting protein complex membership using probabilistic network
reliability. Genome Res. (2004).
[2] BABU, G., AND RAO, C. Conﬁdence limits to the distance of the
true distribution from a misspeciﬁed family by bootstrap. Journal of
Statistical Planning and Inference 115, 2 (8 2003), 471–478.
[3] BABU, G. J., AND FEIGELSON, E. D. Astrostatistics: Goodness-of-Fit
and All That!
In Astronomical Data Analysis Software and Systems
XV (July 2006), C. Gabriel, C. Arviset, D. Ponz, and S. Enrique,
Eds., vol. 351 of Astronomical Society of the Paciﬁc Conference Series,
p. 127.
[4] COLBOURN, C. J. The Combinatorics of Network Reliability. Oxford
University Press, Inc., New York, NY, USA, 1987.
[5] DRAGOMIR, S., AGARWAL, R., AND BARNETT, N.
Inequalities
for beta and gamma functions via some classical and new integral
inequalities. Journal of Inequalities and Applications [electronic only]
5, 2 (2000), 103–165.
[6] FAN, D.-Y.
The distribution of the product of independent beta
variables. Communications in Statistics - Theory and Methods 20, 12
(1991), 4043–4052.
[7] GHOSH, J., NGO, H. Q., YOON, S., AND QIAO, C. On a Routing
Problem Within Probabilistic Graphs and its Application to Intermit-
tently Connected Networks.
In IEEE INFOCOM 2007 - 26th IEEE
International Conference on Computer Communications (May 2007),
pp. 1721–1729.
[8] GUPTA, A. K., AND NADARAJAH, S. Handbook of Beta Distribution
and Its Applications. CRC Press, 2004.
[10]
[11]
[9] GUPTA, A. K., AND NADARAJAH, S. Exact and approximate distri-
butions for the linear combination of inverted dirichlet components.
Journal of the Japan Statistical Society 36, 2 (2006), 225–236.
JAMBUNATHAN, M. V. Some properties of beta and gamma distribu-
tions. The Annals of Mathematical Statistics 25, 2 (1954), 401–405.
JIN, R., LIU, L., DING, B., AND WANG, H. Distance-constraint
Reachability Computation in Uncertain Graphs. Proc. VLDB Endow. 4,
9 (June 2011), 551–562.
JHANNESSON, B., AND GIRI, N. On approximations involving the
beta distribution.
Communications in Statistics - Simulation and
Computation 24, 2 (1995), 489–503.
[12]
[13] KHAN, A., BONCHI, F., GULLO, F., AND NUFER, A. Conditional
reliability in uncertain graphs. IEEE Transactions on Knowledge and
Data Engineering 30, 11 (Nov 2018), 2078–2092.
[14] LI, R.-H., YU, J. X., MAO, R., AND JIN, T. Recursive Stratiﬁed
Sampling: A New Framework for Query Evaluation on Uncertain
Graphs.
IEEE Trans. on Knowl. and Data Eng. 28, 2 (Feb. 2016),
468–482.
[15] MOORE, E., AND SHANNON, C. Reliable circuits using less reliable
relays. Journal of the Franklin Institute 262, 3 (1956), 191 – 208.
[16] MOSKOWITZ, F. The analysis of redundancy networks. Transactions of
the American Institute of Electrical Engineers, Part I: Communication
and Electronics 77, 5 (Nov 1958), 627–632.
[17] MURPHY, K. P. Machine Learning: A Probabilistic Perspective. The
MIT Press, 2012.
[18] NELSEN, R. B.
Statistics). Springer-Verlag, Berlin, Heidelberg, 2006.
An Introduction to Copulas (Springer Series in
[19] NGUYEN, H. H., PALANI, K., AND NICOL, D. M. An approach to
incorporating uncertainty in network security analysis. In Proceedings
of the Hot Topics in Science of Security: Symposium and Bootcamp
(New York, NY, USA, 2017), HoTSoS, ACM, pp. 74–84.
[20] NILSSON, N. J. Probabilistic logic. Artiﬁcial Intelligence 28, 1 (Feb.
1986), 71–88.
[21] POTAMIAS, M., BONCHI, F., GIONIS, A., AND KOLLIOS, G. K-nearest
Neighbors in Uncertain Graphs. Proc. VLDB Endow. 3, 1-2 (Sept.
2010).
[22] STERN, R., SONG, J., AND WORK, D. Accelerated monte carlo system
reliability analysis through machine-learning-based surrogate models of
network connectivity. Reliability Engineering & System Safety 164
(2017), 1 – 9.
99