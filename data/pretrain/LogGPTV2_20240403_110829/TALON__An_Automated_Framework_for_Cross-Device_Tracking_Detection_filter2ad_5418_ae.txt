f
o
F
D
C
 1
 0.8
 0.6
 0.4
 0.2
 0
Paired PC
Baseline PC
Mobile
Paired PC
Baseline PC
Mobile
 0
 5  10  15  20  25  30  35
 0
 5  10  15  20  25  30  35
Number of Ads
Number of Keywords
Figure 6: CDF of collected ads (left) and corresponding key-
words of the ads (right) per crawling session for all devices.
which had the most active ad-campaigns and appeared to be
promising due to the “online shopping” interest. Every desk-
top executed browsing in a stateless mode, while the mobile
in a stateful mode. For each persona, we collected data for
two runs, following the timeline of phases as in Setup 1a.
The distributions between mobile vs. paired desktop, as
well as mobile vs. baseline desktop, were found to be dif-
ferent (highest p-value=0.034). Also, none of the ML classi-
ﬁers performed higher than 0.7 (in all metrics), and thus we
could not clearly extract any signiﬁcant result. Speciﬁcally,
the highest AUC score for personas 1 and 2 was 0.70 with the
use of the Random Forest classiﬁer, and for personas 3 and 4
was 0.73 using the Logistic Regression classiﬁer. The worst
scoring, independent of algorithm, was recorded for persona
5, with AUC=0.57, and Precision/Recall scores under 0.50.
Combined Personas: Setup 3b. When the data from all ﬁve
personas are combined, the classiﬁer performing best was
Logistic Regression, with AUC=0.79. Overall, these results
point to the semi-effectiveness of the incognito browsing to
limit CDT. That is, by removing the browsing state of a user
on a given device, the signal provided to the CDT entities is
reduced, but not fully removed. In fact, when the data from
various personas are combined, the CDT is still somewhat
effective, since the paired devices have the same IP address.
6 Platform Validation
In this section we validate the representativeness of the data
collected from the previous experiments, by examining: (i)
the type and frequency of ads delivered in each device, and
(ii) the type and number of trackers that our personas were
exposed to. We compare the distributions of these quantities
with past works and data on real users, to quantify if our syn-
thetic personas successfully emulate real users’ trafﬁc, and if
our measurements of the CDT ad-ecosystem are realistic.
We ﬁrst measure the frequency of ads delivered to our de-
vices in the experiment § 5.2, since it follows a well-crafted
timeline that is suitable for this kind of measurement. The
ads delivered in the three devices during these sessions are
shown in Figure 6 (left). For most sessions (∼90%), the
mobile device was exposed to fewer than ﬁve ads, since the
236          22nd International Symposium on Research in Attacks, Intrusions and DefensesUSENIX Association 50
)
%
(
s
e
c
n
e
r
u
c
c
O
 40
 30
 20
 10
 0
Bing
Google
Facebook
Advertising.com
AppNexus
Zopim
Casalemedia
Pinterest
Yandex
Yahoo
OpenX
Twitter
Pubmatic
Hotjar
Linkedin(Microsoft)
Outbrain
Amazon
Taboola
Drawbridge
Tapad
Figure 7: Top-20 trackers (grouped based on organization)
and their coverage in persona pages. For example, all the
Google-owned domains, such as Doubleclick, Googleapis,
Google-Analytics, are grouped under the “Google” label.
mobile version of websites typically delivers a smaller num-
ber of ads, designed for smaller screens and devices. On the
contrary, the desktop devices had a higher exposure to ads
compared to the mobile device. Also, the two desktops re-
ceive a similar number of ads (on average 2 to 4 ads on every
visit to the control pages). Similar observations can be made
for the keywords categories of ads (Figure 6 (right)). The
ad-industry has reported that ∼300 ads everyday, on aver-
age, are being displayed to desktop users [30, 11, 31, 14],
while they also recommend the delivery of 5 ads per mobile
domain [52], which proportionally match the number of ads
we have collected in our mobile and desktop sessions.
We also validate the representativeness of the data col-
lected from the experiments § 5.2 and § 5.3, by examining the
trackers appearing in the webpages visited by the personas.
We use Disconnect List [18] to detect them and measure their
frequency of appearance (i.e., Figure 7). From the trackers
detected in the set of persona pages, and using the list pro-
vided by [56], 37% was found to be CDT related, including
both deterministic and probabilistic.
In fact, the top CDT
trackers found in our data, which may perform both types
of CDT, include Google-owned domains, Facebook, Criteo,
Zopim, Bing, Advertising.com(AOL), and are in-line with
the top CDT trackers found in [56, 10] (66% overlap of top-
20 with [56] and 55% overlap with [10]). In addition, 17%
of these trackers are mainly focused on probabilistic CDT,
including Criteo, BlueKai, AdRoll, Cardlytics, Drawbridge,
Tapad, and each individual tracker is found at least in 2% of
the persona pages, again in-line with the results in [56].
7 Discussion & Conclusion
Through extensive experiments with the proposed frame-
work Talon, we were able to trigger CDT trackers into pair-
ing of the emulated users’ devices. This allowed us to statis-
tically verify that CDT is indeed happening, and measure its
effectiveness on different user interests and browsing behav-
iors, independently and in combination. In fact, CDT was
prominent when user devices were trained to browse pages
of similar interests, reinforcing the behavioral signal sent to
CDT entities, and speciﬁcally when browsing activity is re-
lated with online shopping, since those types of users seem to
be more targeted by advertisers. The CDT effect was further
ampliﬁed when the visited persona and control pages had
embedded CDT trackers, pushing the accuracy of detection
up to 99%. We also found that browsing in a stateless mode
showed a reduced, but not completely removed CDT effect,
as incognito browsing obfuscates somewhat the signal sent
to the ad-ecosystem, but not the network access information.
Indeed, our data collection was performed across relatively
short time periods, in comparison to the wealth of browsing
data that advertising networks have at their disposal. In fact,
we anticipate that CDT companies collect data about users
and devices for months or years, and even buy data from data
brokers, to have the capacity of targeting users with even
higher rates. To that end, we believe that high accuracies
self-reported by CDT companies (e.g., Lotame: >90% [37],
Drawbridge: 97.3% [19]), are possible.
Impact on user privacy: Undoubtedly, CDT infringes on
users’ online privacy and minimizes their anonymity. But the
actual extent of this tracking paradigm and its consequences
to users, the community, and even to the ad-ecosystem itself,
are still unknown. In fact, since CDT is heavily depended on
user’s browsing activity, and the ad-ecosystem employs such
collected data for targeting purposes, one major line of future
work is the study of targeting sensitive user categories (e.g.,
gender, sexual orientation, race, etc.) via CDT. This is espe-
cially relevant nowadays with the enforcement of recent EU
privacy regulations such as GDPR [24] and ePrivacy [23].
This is where Talon comes in play, as it provides a concrete,
scalable and extensible methodology for experimenting with
different CDT scenarios, auditing its mechanics and measur-
ing its impact. In fact, the modular design of our method-
ology allows to study CDT in depth, and propose new ex-
tensions to study the CDT ecosystem: new plugins, personas
and ML techniques. To that end, our design constitutes Talon
into an enhanced transparency tool that reveals potentially il-
legal biases or discrimination from the ad-ecosystem.
Acknowledgments
The research leading to these results has received fund-
ing from the European Union’s Horizon 2020 Research and
Innovation Programme under grand agreement No 786669
(project CONCORDIA), the Marie Sklodowska-Curie grant
agreement No 690972 (project PROTASIS), and the Defense
Advanced Research Projects Agency (DARPA) ASED Pro-
gram and AFRL under contract FA8650-18-C-7880. The
paper reﬂects only the authors’ views and the Agency and
the Commission are not responsible for any use that may be
made of the information it contains.
USENIX Association        22nd International Symposium on Research in Attacks, Intrusions and Defenses 237References
[1] Measuring Cross-Device:
The Methodology.
https://www.tapad.com/resources/cross-
device/measuring-cross-device-the-
methodology, 2018.
[2] Pew Research Center - Mobile Fact Sheet.
http:
//www.pewinternet.org/fact-sheet/mobile/,
2018.
[3] ADBRAIN.
Demystifying cross-device.
for
and
essen-
product management,business
business
lead-
https://www.iabuk.com/sites/
tial
reading
development
ers.
default/files/white-paper-docs/Adbrain-
Demystifying-Cross-Device.pdf, 2016.
technology
[4] ADELPHIC.
How cross-device identity matching
https://adelphic.com/how-cross-
works.
device-identity-matching-works-part-1/,
2016.
[5] AGUIRRE, E., MAHR, D., GREWAL, D., DE RUYTER,
K., AND WETZELS, M. Unraveling the personaliza-
tion paradox: The effect of information collection and
trust-building strategies on online advertisement effec-
tiveness. Journal of Retailing 91, 1 (2015), 34–49.
[6] ARP, D., QUIRING, E., WRESSNEGGER, C., AND
RIECK, K. Privacy threats through ultrasonic side
channels on mobile devices. In IEEE European Sym-
posium on Security and Privacy (EuroS&P) (2017),
pp. 35–47.
[7] BASHIR, M. A., ARSHAD, S., ROBERTSON, W., AND
WILSON, C. Tracing information ﬂows between ad ex-
changes using retargeted ads. In 25th USENIX Security
Symposium (2016), pp. 481–496.
[8] BASHIR, M. A., FAROOQ, U., SHAHID, M., ZAFFAR,
M. F., AND WILSON, C. Quantity vs. quality: Evaluat-
ing user interest proﬁles using ad preference managers.
In Proceedings of the Annual Network and Distributed
System Security Symposium (NDSS), San Diego, CA
(2019).
[9] BLEIER, A., AND EISENBEISS, M. Personalized on-
line advertising effectiveness: The interplay of what,
when, and where. Marketing Science 34, 5 (2015),
669–688.
[11] BRYCE SANDERS. Do we really see 4,000 ads a day?
https://www.bizjournals.com/bizjournals/
how-to/marketing/2017/09/do-we-really-
see-4-000-ads-a-day.html, 2017.
[12] CARRASCOSA, J. M., MIKIANS, J., CUEVAS, R.,
ERRAMILLI, V., AND LAOUTARIS, N. I always feel
like somebody’s watching me: measuring online be-
havioural advertising. In Proceedings of the 11th ACM
Conference on Emerging Networking Experiments and
Technologies (CONEXT) (2015).
[13] CAWLEY, G. C., AND TALBOT, N. L. On over-ﬁtting
in model selection and subsequent selection bias in per-
formance evaluation. Journal of Machine Learning Re-
search 11 (2010).
[14] CHRISTOPHER ELLIOTT. Yes, there are too many
ads online. yes, you can stop them. heres how.
https://www.huffingtonpost.com/entry/yes-
there-are-too-many-ads-online-yes-you-
can-stop_us_589b888de4b02bbb1816c297, 2017.
[15] CRITEO.
The State of Cross-Device Com-
https://www.criteo.com/wp-content/
merce.
uploads/2017/07/Report-criteo-state-of-
cross-device-commerce-2016-h2-SEA.pdf,
2016.
[16] CRITEO.
The 5 top attribution methodologies for
https://www.criteo.com/
cross-channel
insights/top-attribution-methodologies-
for-cross-channel-roi/, 2018.
roi.
[17] DAS, A., BORISOV, N., AND CAESAR, M. Tracking
mobile web users through motion sensors: Attacks and
defenses. In Proceedings of the Annual Network and
Distributed System Security Symposium (NDSS), San
Diego, CA (2016).
[18] DISCONNECT. Disconnect lets you visualize and block
the invisible websites that track your browsing history.
https://disconnect.me/, 2019.
[19] DRAWBRIDGE.
Cross-Device Consumer Graph.
https://go.drawbridge.com/rs/454-ORY-
155/images/Drawbridge-Cross-Device-
Consumer-Graph.pdf, 2015.
[20] DRAWBRIDGE.
Drawbridge Cross-Device Con-
97.3% Accurate.
Is
nected Consumer Graph
https://go.drawbridge.com/rs/454-ORY-
155/images/Drawbridge-Cross-Device-
Consumer-Graph.pdf, 2015.
[10] BROOKMAN, J., ROUGE, P., ALVA, A., AND YEUNG,
C. Cross-device tracking: Measurement and disclo-
sures. Proceedings on Privacy Enhancing Technolo-
gies, 2 (2017), 133–148.
[21] EASYLIST. Easylist is the primary ﬁlter list that re-