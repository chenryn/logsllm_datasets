sampling rates for the iris image. For example, a 20x60 iris is the 
result of using 20 samples in the radial dimension and 60 samples 
around  the  contour  (in  the  angular  dimension).  To  determine  the 
parameters, we ran the iris recognition software on samples from a 
database  of  user  iris  images  [17],  with  data  from  64  users  (three 
samples per user, both eyes) in 768x576x24 color PNG files. We 
only  used  the  iris  information  from  the  red  channel  in  the  color 
images  [18].  We  also  used  the  database  to  confirm  that  the  low 
resolution of the eye tracker was not a major impediment.  
The  IRB-approved  user  study  involved  37  users. The eye tracker 
was  connected  to  a  13”  laptop  computer.  Participants  wearing 
glasses  were  requested  to  remove  them,  to  eliminate  glare.  The 
experimenter  used  a  secondary  monitor  to  view  live  video  from 
the  camera  to  ensure  that  the  eye  tracker  was  focused  on  the 
participant’s  eyes.  Participants  were  asked  to  search  for  images 
via  a  Google  Images  search.  Once  the  user  begun  searching,  the 
experimenter  would  start  the  recording  of  iris  images.  The 
program recorded two runs, each of 25 valid sample images of the 
participants’  eyes  (rejecting  as  invalid  those  samples  where  the 
eye was fully closed or the iris could not be located). Some of the 
valid samples included an iris image but had up to 80% of the iris 
occluded  (e.g.  for  a  blink  in  progress).  Each  run  took  60-90 
seconds.  
4.  EXPERIMENTS, RESULTS, AND 
DISCUSSION – USER STUDY OF IRIS 
RECOGNITION 
The  participant’s  irises  were  sampled  at  a  resolution  of  20x60 
(radial  and  angular  sampling  rates),  and  the  images  from  the  eye 
tracker  had  iris  diameters  close  to  100  pixels.  For  each  run,  the 
software  located  the  5  samples  with  the  smallest  total  Hamming 
distance  (minimum  sum  of  the  distances  from  each  sample  to  all 
of the other 24). These 5 samples form the core of the run and are 
treated as reference images for the iris.  
In  the  best-of-batch  authentication  approach  we  collected  the 
closest  5  samples  from  a  user’s  batch  of  samples  for  comparison 
to a core. This approach makes the process more robust to errors 
in  individual  samples.  For  this  scenario,  the  equal  error  rate 
(EER)  is  when  the  acceptance  rate  equals  the  error  rate  and  is 
11% for a threshold of 0.235. Figure 2 graphs the true positive vs. 
the false positive rate.  
Figure 2. True Positive vs. False Positive Rate 
1008If we require iris occlusion to be below a certain level (30%) then 
only  14  out  of  the  37  users  in  the  study  meet  this  criteria.  For 
these users the best performance is an EER of 9%. 
Magazine 11(2002): 114, no longer available online, but 
cited in Technology Assessment, Using Biometrics for 
Border Security (GAO-03-174). 
We  also  used  a  k-nearest  neighbors  (KNN)  machine  learning 
algorithm  to  compare a core iris sample against the core samples 
for  all  users.  A  test  core  should  match  only  the  core  of the same 
eye taken from different samples. For k=3 and using only the right 
eyes,  the  accuracy  of  the  classification  is  100%.  The  realistic 
metric  of  the  Manhattan  distance  is  able  to  classify  correctly 
96.4% of the cores, for k=3. 
[3]  Biel, L.; Pettersson, O.; Philipson, L.; Wide, P.; (2001). ECG 
analysis: a new approach in human identification. 
Instrumentation and Measurement, IEEE Transactions on , 
vol.50, no.3, pp.808-812, Jun 2001. 
[4]  Hoanca, B., & Mock, K. J. (2006). Secure graphical 
password system for high traffic public areas. Eye Tracking 
Research and Applications (p. 35). San Diego: ACM. 
Table 1. Accuracy of KNN for core-level classification for open 
eyes. 
[5]  Spillane, R. (1975). Keyboard apparatus for personal 
identification. IBM Technical Disclosure Bulletin, 17, 3346. 
Metric 
 knn1 
 knn3 
 knn5 
 knn7 
 knn9 
Left eye 
85.7% 
82.1% 
85.7% 
78.6% 
67.9% 
Right eye 
96.4% 
100.0% 
92.9% 
92.9% 
82.1% 
Manhattan 
92.9% 
96.4% 
92.9% 
92.9% 
92.9% 
5.  CONCLUSION 
Results from a user study show that a commercial eye tracker can 
be  used  with  good  performance  for  user  authentication  via  iris 
recognition.  Eye  trackers  have  resolution  2-5x  lower  than that of 
dedicated  iris  recognition  systems,  and  users  may  move  freely 
while  using  the  eye tracker, which raises considerable challenges 
in gathering quality iris images.  
In  a  live  user  study,  we  were  able  to  discriminate  among  users 
with 11% equal error rate. For 14 of the 37 users in the study the 
iris occlusion was small enough for all samples to allow 9% EER. 
While  consistent  with  other  continuous  authentication  schemes 
[11],  this  error  rate  is  much  too  high  to  be  used  as  the  sole 
authentication  means,  but  could  be  useful  when  combined  with 
other more accurate techniques. Eye trackers can also be used for 
user  identification.  Under  the  best  scenario,  selecting  only 
samples  of  open  eyes,  and  comparing  core-to-core  may  allow 
classification  accuracy  close  to  100%.  Further  work  will  need  to 
consider  the  effects  of  lighting  conditions,  user  fatigue  (and  its 
effects on iris occlusion), and other long-term factors. 
Ultimately,  when  eye  trackers  become  widely  available  as  user 
interface  devices,  they  might  offer  the  additional  benefit  of  real-
time, continuous user authentication, perhaps replacing traditional 
passwords  or  as  multifactor  authentication  systems  that  combine 
passwords  and  eye  biometrics.  While  it  is  unlikely  that  the 
authentication  capabilities  of  eye  trackers  will  lead  to  their 
widespread  deployment,  if  eye  trackers  are  already  available  for 
other  applications,  their  capabilities  for  real-time  continuous 
authentication should not be overlooked. 
6.  ACKNOWLEDGEMENTS 
We  wish  to  thank  the  UAA  University  Honors  College  and 
College of Arts & Sciences for funding part of this research. 
7.  REFERENCES 
[1]  Daugman, J. (n.d.). How Iris Recognition Works. Retrieved 
April 14, 2010, from 
http://www.cl.cam.ac.uk/~jgd1000/irisrecog.pdf 
[2]  Thalheim, L., Krissler, J. and Zielger, P.-M. (2002). Body 
check: biometric access protection devices and their 
programs put to the test, translated by Robert Smith, c’t 
[6]  Denning, D., Neumann, P., & Parker, D.B. (1987). Social 
aspects of computer security. In Proceedings of the 10th 
National Computer Security Conference. 
[7]  Jorgensen, Z. & Yu, T. (2011). `On Mouse Dynamics as a 
Behavioral Biometric for Authentication. Proceedings of the 
Sixth ACM Symposium on Information, Computer, and 
Communications Security. 
[8]  Slivovsky, L. & Tan, H. (2000). A real-time static posture 
classification system. Proceedings of the Ninth International 
Symposium on Haptic Interfaces for Virtual Environment 
and Teleoperator Systems, American Society of Mechanical 
Engineers Dynamic Systems and Control Division, Vol. 69-
2, S. S. Nair (Ed.), (p. 1049-1056), Orlando, FL. 
[9]  Bledsoe, W. (1964). The model method in facial recognition. 
Technical report PRI 15, Panoramic Research, Inc., Palo 
Alto, CA. 
[10] Dantcheva, A. & Dugelay, J. L. (2011). Frontal-to-side face 
re-identification based on hair, skin and clothes patches. 
2011 8th IEEE International Conference on Advanced Video 
and Signal-Based Surveillance (AVSS). Klagenfurt, 
Germany. 
[11] Killourhy, K. & Maxion, R. (2009). Comparing Anomaly-
Detection Algorithms for Keystroke Dynamics." In 
International Conference on Dependable Systems & 
Networks (DSN-09), (p. 125-134), Estoril, Lisbon, Portugal, 
July 2009. IEEE Computer Society Press, Los Alamitos, CA. 
[12] Xiao, Q. (2005). Security issues in biometric authentication, 
Information Assurance Workshop, IAW 2005 (p. 8-13).  
[13] Duchowski, A. (2002). A Breadth-First Survey of Eye-
Tracking Applications. Behavior Research Methods 
Instruments and Computers, 34, 4, (p. 455-470). 
[14] TM3 - EyeTech Digital Systems. (n.d.). Retrieved from 
EyeTech Digital Systems-Eye Tracking Technology 
Solutions: http://www.eyetechds.com/research/tm3-qc 
[15] Masek, L. (2003). Iris Recognition. Retrieved from 
http://www.csse.uwa.edu.au/~pk/studentprojects/libor/ 
[16] He, X. & Shi, P. (2005). An Efficient Iris Segmentation 
Method for Recognition. Third International Conference on 
Advances in Pattern Recognition. Bath, UK. 
[17] Dobeš, M., & Machala, L. (n.d.). Retrieved 4/30/2012 from 
Iris Database: http://phoenix.inf.upol.cz/iris/ 
[18] Dobeš M., Machala L., Tichavský P., Pospíšil J. (2004). 
Human Eye Iris Recognition Using the Mutual Information. 
Optik Journal for Light and Electron Optics, 115(9), p.399-
405, Elsevier, ISSN 0030-4026. 
1009