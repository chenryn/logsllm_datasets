# A Security Analysis of Honeywords

## Authors
- Ding Wang, Haibo Cheng, Ping Wang
  - {wangdingg, chenghaibo, pwang}@pku.edu.cn
  - Peking University
- Jeff Yan
  - Linköping University
  - PI:EMAIL
- Xinyi Huang
  - Fujian Normal University
  - PI:EMAIL

## Abstract
Honeywords are decoy passwords associated with each user account and serve as a promising approach for detecting password leakage. This concept was first introduced by Juels and Rivest at CCS'13 and has since been widely covered in media and adopted in various research domains. While the idea of honeywords appears simple, generating honeywords that are indistinguishable from real passwords is a complex challenge. Juels and Rivest proposed four main methods for honeyword generation, but their security was only justified through heuristic arguments.

In this work, we conduct a series of practical experiments using 10 large-scale datasets, comprising a total of 104 million real-world passwords, to quantitatively evaluate the security provided by these four methods. Our results show that all methods fail to provide the expected security: real passwords can be distinguished with a success rate of 29.29%–32.62% by a basic trawling-guessing attacker, rather than the expected 5%, with just one guess (when each user account is associated with 19 honeywords, as recommended). This figure increases to 34.21%–49.02% under advanced trawling-guessing attackers who use state-of-the-art probabilistic password models. Furthermore, under a targeted-guessing attacker who exploits personal information, the success rate rises to 56.81%–67.98%. Overall, our work addresses three open problems in honeyword research, as defined by Juels and Rivest.

## I. Introduction
Passwords remain the most prevalent method for user authentication, despite their well-known security and usability issues. A significant limitation of password-based authentication systems is the need for servers to maintain a sensitive file containing the passwords of all registered users, which is a prime target for attackers. High-profile web services such as Yahoo, Dropbox, Last.fm, LinkedIn, Weebly, and MySpace have experienced breaches where millions of passwords were leaked. These breaches often go undetected until the data is exploited and posted online, sometimes months or even years after the initial breach.

For example:
- The 2017 Yahoo breach involved 3 billion users, but the breach occurred four years earlier.
- The 2016 Weebly breach affected 43 million users, but the breach had occurred eight months prior.
- The 2012 Dropbox breach, involving 68 million users, was only detected in May 2016.
- The 2008 MySpace breach, affecting 360 million users, was not detected until May 2016.

The 2016 Verizon Data Breach Report highlights that over 85% of breaches are first detected by external parties, with 91% taking weeks and 70% taking months or years to detect. This underscores the need for active and timely detection methods for password breaches.

Even if passwords are stored as salted hashes, modern machine-learning-based cracking algorithms and common hardware like GPUs can still recover them. Sophisticated hash functions, such as bcrypt, slow down the cracking process, but dedicated hardware can still overcome this. Once an attacker obtains the password hash file, it is realistic to assume that most passwords can be guessed offline. Slow hash functions do not facilitate the detection of password-file leakage.

Recent approaches to eliminate the possibility of offline password guessing include:
1. Using machine-dependent functions (e.g., ErsatzPasswords).
2. Employing distributed cryptography (e.g., threshold password-authenticated secret sharing).
3. Using external password-hardening services (e.g., Phoenix).

However, these approaches require substantial changes to server-side authentication systems and have other limitations, such as poor scalability, client-side system changes, and single points of failure.

A more promising approach, proposed by Juels and Rivest in 2013, involves introducing decoy passwords (honeywords) associated with each user's account. Even if an attacker steals the password file and recovers all passwords, they must first distinguish the real password from a set of k-1 honeywords. If honeywords are well generated, the attacker must perform online login attempts to identify the real password, which can impede the attack and trigger an alarm. This approach requires minimal changes to existing systems and has gained significant attention.

### A. Challenges and Motivations
The main challenge is generating honeywords that cannot be easily distinguished from real passwords. Juels and Rivest proposed five honeyword-generation methods, with four for legacy user interfaces (UI) and one for modified UIs. The legacy-UI methods are preferred due to usability advantages. However, these methods are based on random replacement and are inherently vulnerable to semantic-aware attackers. Prior works on honeywords have only provided heuristic security arguments, lacking rigorous theoretical analysis or empirical evaluation with real-world datasets.

### B. Our Contributions
In this work, we make the following key contributions:
- **Trawling Guessing Attacks**: We develop a series of experiments using large-scale real password data to evaluate the four honeyword-generation methods in [21]. We find that they all fail to provide the expected security. Real passwords can be distinguished with a success rate of 29.29%–32.62% with just one guess under a basic trawling-guessing attacker (when each user account is associated with 19 honeywords, i.e., k = 20). This figure reaches 34.21%–49.02% under advanced trawling-guessing attackers using state-of-the-art probabilistic password models (e.g., Markov and PCFG).
- **Targeted Guessing Attacks**: We evaluate the security of honeywords under semantic-aware attackers. Real passwords can be distinguished with a success rate of 56.8%–67.9% with just one guess (when k = 20), if the attacker knows some common personal information like the name and birthday of the victim user. This answers the question of how well targeted attacks can help identify users' passwords for particular honeyword-generation methods.
- **Extensive Evaluation**: Our experiments use various leading probabilistic password cracking models (e.g., Markov, TarGuess, and PCFG). We employ 10 large-scale real-world password lists, comprising a total of 104.36 million passwords, covering various popular web services. This is the first study to empirically evaluate honeywords. Our extensive evaluation suggests that Juels-Rivest's methods cannot withstand either PII-unaware or PII-aware attackers.
- **New Insights**: We reveal that generating decoy passwords (by randomly replacing parts/whole of the real password) to be equally probable with the user’s real password is inherently impossible. This indicates that Juels-Rivest's random-replacement-based approach is inherently vulnerable. We also show that probabilistic password models cannot be readily employed to generate honeywords, contrary to common belief. As expected, these password models can be used to design effective experiments with real-world datasets to evaluate a honeyword method. This answers the open question of whether there are good experimental methods for quantifying the flatness of honeyword methods.

## II. Datasets, Security Model, and Metrics

### A. Our Datasets
We evaluate Juels-Rivest's honeyword methods using 10 large real password datasets, including four from Chinese sites and six from English sites. In total, our datasets consist of 104.36 million plain-text passwords and involve nine different web services. We include early disclosed datasets (e.g., Rockyou and Dodonew) and three recently leaked datasets that may exhibit up-to-date user password behaviors. These datasets were compromised by hackers or leaked by insiders and were publicly available on the Internet for some time. Since the Rockyou dataset only contains passwords without user names or emails, it will not be used for evaluating targeted threats. The role of each dataset will be specified where necessary.

| **Web Service** | **Dataset** | **Language** | **When Leaked** | **Total PWs** | **With PII** |
|-----------------|-------------|--------------|-----------------|---------------|--------------|
| Social Forum    | Tianya      | Chinese      |                 |               |              |

This table provides a summary of the datasets used in our evaluation.