### Detection of Break-in Fraud in Synthetic and Authentic Data

#### Figure 13: Detection of Break-in Fraud in Synthetic Data
- **Y-Axis:** Detection Score (0 to 1.2)
- **X-Axis:** Days since Epoch (0 to 90 days)

**Description:**
The detection results for break-in fraud in synthetic data are illustrated in Figure 13. The graph shows a clear and distinct period of detected fraud, indicating the effectiveness of the neural network in identifying fraudulent behavior in this controlled environment.

#### Figure 14: Detection of Break-in Fraud in Authentic Data
- **Y-Axis:** Detection Score (0 to 1.2)
- **X-Axis:** Days since Epoch (0 to 90 days)

**Description:**
Figure 14 presents the detection results for break-in fraud in authentic data. The results are less promising compared to the synthetic data. The actual fraudulent period (days 3 to 6) is correctly identified, but several false positives are also observed at various intervals (approximately at days 33, 62, 68, 71, 75, 81, 85). This indicates that the neural network struggled to differentiate between normal and fraudulent behavior, as the fraudulent user's consumption patterns did not deviate significantly from those of a normal user.

#### Figure 15: Average Movie Orders for a Fraudulent User (Authentic Data)
- **Y-Axis:** Movie Orders/Interval (0 to 45 orders)
- **X-Axis:** Days since Epoch (0 to 90 days)

**Description:**
Figure 15 plots the average number of movie orders per day for a fraudulent user. The fraudulent period (days 4 to 7) did not show a significant increase in movie orders, making it difficult for the neural network to distinguish between normal and fraudulent behavior. The false positives were influenced by the temporal memory, as moderate usage over time built up large input values, triggering false alarms.

### Quantitative Results

**Table 1: Detection Results**

| Fraud Type                    | Sensitivity | Specificity | # of Periods | True Pos. | False Pos. | False Neg. | True Neg. |
|-------------------------------|-------------|-------------|--------------|-----------|------------|------------|-----------|
| Billing Fraud (Synthetic Data) | 0.89        | 0.98        | 365          | 61        | 89         | 87         | 97        |
| Billing Fraud (Authentic Data) | 1.0         | 0.93        | 3            | 26        | 4          | 3          | 4         |
| Break-in Fraud (Synthetic Data)| 0.92        | 1.0         | 0            | 11        | 11         | 0          | 2         |
| Break-in Fraud (Authentic Data)| 1.0         | 0.86        | 254          | 54        | 61         | 72         | 2         |

**Sensitivity** [true pos / (true pos + false neg)] measures the proportion of actual fraud cases correctly identified. High false negatives reduce sensitivity.
**Specificity** [true neg / (true neg + false pos)] measures the proportion of non-fraudulent events correctly identified. High false positives reduce specificity.

**Observations:**
- The specificity is better for synthetic data, likely because the neural network was trained on more regular and controlled data.
- Sensitivity is better for authentic data, which is unexpected given the higher fraud rate in synthetic data. This suggests that the authentic data, with mostly normal behavior and short periods of fraud, provided a more challenging but realistic test case.
- Overall, the differences between synthetic and authentic data are reasonably small, indicating that the training using synthetic data was successful.

### Discussion of Results and Future Work

#### Scalability and Complexity
- **Scalability:** We created hundreds of simulated users over seven months, demonstrating the method's scalability in terms of the number of users and the time period of synthetic logs.
- **Complexity:** Further research is needed to study the effects of more complex user and system modeling, such as implementing outliers and multiple user classes.

#### Diversity of Background Data
- The background data were homogeneous, with all simulated users following the same statistical distributions. This limited the diversity of user behavior.
- For billing fraud, the homogeneity was sufficient, but for break-in fraud, it posed a challenge due to similar behavior between normal users and fraudsters.
- Future work should include testing with more diverse background data.

#### User and System Models
- The current user model is simplistic and does not account for long-term variations or other network activities.
- The system model uses static parameters, which do not reflect real-world variations. Future versions will be more dynamic and capable of simulating attacks based on software and hardware bugs.

#### Fraud Cases
- Fraud was injected into a few users' behavior for short periods, which was suitable for our application but limits generalizability.
- Future work will include a more extensive list of fraud scenarios.

#### Suitability for Other Services
- Future experiments will determine if the data generation process is effective for other types of services and intrusion detection systems.

### Conclusions
We have developed a method for generating large amounts of synthetic log data that preserve the statistical properties of authentic data. The synthetic data can be successfully used for training and testing fraud detection systems. Future work will verify the method's applicability to more general classes of seed data and other fraud detection systems.

### Acknowledgments
We thank Telia Research AB (now TeliaSonera), the VoD service team, and the participants of the EURESCOM project "P1007" for their cooperation and support.

### References
[1] P. Burge, J. Shawe-Taylor, Y. Moreau, B. Preneel, C. Stoermann, and C. Cooke. Fraud detection and management in mobile telecommunications networks. In Proceedings of the European Conference on Security and Detection ECOS 97, London, April 1997. ESAT-SISTA TR97-41.
[2] P. K. Chan, W. Fan, A. L. Prodromidis, and S. J. Stolfo. Distributed data mining in credit card fraud detection. IEEE Intelligent Systems, 14(6), Nov/Dec 1999.
[3] H. Debar, M. Dacier, A. Wespi, and S. Lampart. An experimentation workbench for intrusion detection systems. Technical Report RZ2998, IBM Research Division, Zurich Research Laboratory, Zurich, Switzerland, Mar. 1998.
[4] J. W. Haines, R. P. Lippmann, D. J. Fried, E. Tran, S. Boswell, and M. A. Zissman. 1999 darpa intrusion detection system evaluation: Design and procedures. Technical Report Technical Report 1062, MIT Lincoln Laboratory, Feb. 2001.
[5] H. Kvarnstrom, E. Lundin, and E. Jonsson. Combining fraud and intrusion detection - meeting new requirements. In Proceedings of the fifth Nordic Workshop on Secure IT systems (NordSec2000), Reykjavik, Iceland, Oct. 2000.
[6] W. Lee and D. Xiang. Information-theoretic measures for anomaly detection. In Proceedings of the 2001 IEEE Symposium on Security and Privacy, May 2001.
[7] E. Lundin, H. Kvarnstrom, and E. Jonsson. A synthetic fraud data generation methodology. In Lecture Notes in Computer Science, ICICS 2002, Laboratories for Information Technology, Singapore, Dec. 2002. Springer Verlag.
[8] R. A. Maxion and K. M. Tan. Benchmarking anomaly-based detection systems. In International Conference on Dependable Systems and Networks, New York, New York, June 2000. IEEE Computer Society Press.
[9] M. C. Moser. Neural net architectures for temporal sequence processing. Addison-Wesley Publishing, Redwood City, CA, 2001.
[10] N. J. Puketza, K. Zhang, M. Chung, B. Mukherjee, and R. A. Olsson. A methodology for testing intrusion detection systems. Software Engineering, 22(10), 1996.
[11] K. M. C. Tan and R. A. Maxion. Determining the operational limits of an anomaly-based intrusion detector. IEEE Journal on Selected Areas in Communication, 21(1), Jan. 2003.