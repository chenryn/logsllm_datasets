#D(w) +
|Di|w
w∈W
i=1
|D|w
,
,
O
the concatenation of the documents (not identiﬁers) that
contain w, and where
(cid:88)
|D|w.
a =
D∈D(w)
algorithm then
The
Σmm.Setup(1k, MM)
ED = EMM.
• OPQ.Search(cid:0)K, w; ED(cid:1): the parties execute
computes
outputs
and
(t;⊥) ← Σmm.Get(K, w; EMM)
(K, EMM) ←
(K, ED) where
and the client parses t as (D)D∈D(w).
If the multi-map encryption scheme Σmm is instantiated
with a standard response-hiding encrypted multi-map [19],
[18], [17], [10], [11]12 the ESA will have leakage proﬁle
ΛOPQ = (LS,LQ) =(cid:0)(cid:63),(cid:0)qeq, tvol(cid:1)(cid:1).
Its storage complexity will be
(cid:18)(cid:88)
O
(cid:18)
(cid:88)
(cid:88)
(cid:19)
|D|w
,
(cid:19)
|D|w
,
w∈W
D∈D(w)
and the search and communication complexity will be
O
which is optimal.
#D(w) +
D∈D(w)
Semi-ORAM (SMI). Let ORAM = (Setup, Read)
be an ORAM scheme and SKE = (Gen, Enc, Dec) be
a symmetric-key encryption scheme. Consider the scheme
SMI = (Setup, Search) where each algorithm works as fol-
lows:
• SMI.Setup(1k, D): it builds a multi-map MM that maps
each keyword w ∈ W to the tuple D(w). It then com-
putes (K1, OMM) ← ORAM.Setup(1k, MM) and, for all
i ∈ [n], cti ← Enc(K2, Di), where K2 ← SKE.Gen(1k).
It outputs (K, ED), where K = (K1, K2) and OD =
(OMM, ct1, . . . , ctn).
• SMI.Search(cid:0)K, w; OD(cid:1):
the client uses ORAM to
simulate
of Get(MM, w);
is,
it
every
read operation to location i with an execution of
ORAM.Read(K1, i; OMM). At the end of this simulation,
the client holds a set of indices I which it sends to
the server. The server returns (cti)i∈I which the client
decrypts.
runs Get(MM, w)
execution
replaces
locally
that
but
an
If the ORAM scheme is instantiated with any standard
construction [31], [47], [71], the search scheme will have
leakage proﬁle
Using Path ORAM [71], the storage complexity is
ΛSMI =(cid:0)(cid:63),(cid:0)rlen, rid, vol(cid:1)(cid:1).
(cid:18)(cid:88)
(cid:19)
n(cid:88)
#D(w) +
|Di|w
,
i=1
O
w∈W
12We note that while most of these constructions are described as response-
revealing constructions it is trivial to convert them to response-hiding schemes.
16
and the search and communication complexity are
(cid:19)
(cid:88)
(cid:19)
,
|D|w
(cid:18) #D(w)
O
B
(cid:18)(cid:88)
· log2
#D(w)
w∈W
B
+
D∈D(w)
where B is the block size in bits.
Full ORAM (FLL). Let ORAM = (Setup, Read)
be an ORAM scheme and consider the scheme FLL =
(Setup, Search) where each algorithm works as follows:
• FLL.Setup(1k, D): it builds an array RAM that stores all
the documents in D. It then builds a multi-map MM
that maps each keyword w ∈ W to the locations of
the blocks in RAM that store the documents in D(w).
It then computes (K1, OMM) ← ORAM.Setup(1k, MM)
and (K2, ORAM) ← ORAM.Setup(1k, RAM). It out-
puts (K, OD), where K = (K1, K2) and OD =
(OMM, ORAM).
• FLL.Search(cid:0)K, w; OD(cid:1): the client uses ORAM to sim-
ulate an execution of Get(MM, w). At the end of this
simulation, the client holds a set of indices I. It then uses
ORAM again to simulate, for all i ∈ I, an execution of
Read(RAM, i) to recover the documents.
If the ORAM scheme is instantiated with any standard
construction [31], [47], [71], the search scheme will have
leakage proﬁle
The storage complexity is
O
ΛFLL =(cid:0)(cid:63),(cid:0)rlen, tvol(cid:1)(cid:1).
(cid:18)(cid:88)
(cid:88)
(cid:18) #D(w)
(cid:18)(cid:88)
(cid:18) n(cid:88)
(cid:88)
#D(w) +
· log2
D∈D(w)
w∈W
w∈W
B1
|Di|w
B2
· log2
i∈D(w)
#D(w)
B1
|Di|w
B2
i=1
|D|w
,
(cid:19)
(cid:19)
(cid:19)(cid:19)
+
O
and the search and communication complexity are
where B1 and B2 are the block sizes in bits of the ﬁrst and
second ORAM, respectively. Note that this construction has
leakage proﬁle ΛFLL only if the client retrieves all of the
matching documents from the second ORAM at once. If, on
the other hand, the client retrieves them one by one then it
will have leakage proﬁle(cid:0)(cid:63),(cid:0)rlen, vol(cid:1)(cid:1).
Additional ORAM-based constructions. We note that
there are alternative ORAM-based designs in addition to the
ones we described above. One could, for example, merge the
two ORAMs used in the full ORAM simulation into a single
ORAM with the same block size. This would have leakage
pattern(cid:0)(cid:63), tvol(cid:1).
The Piggyback scheme (PBS). PBS is an STE scheme
recently introduced in [45] that partially hides the volume
pattern. It comes in two variants. The ﬁrst reveals only the
sequence volume pattern (i.e., the sum of the volume associ-
ated to a query sequence) on non-repeating query sequences.
The second variant reveals nothing (beyond a public parameter
independent of the volume) on non-repeating query sequences.
17
At a high level,
the scheme leverages a new trade-off in
STE design; speciﬁcally, it trades latency for an improved
leakage proﬁle. At a high level, the scheme processes the
input data structure such that the query responses are divided
into smaller chunks of equal size. These chunks are then
stored and encrypted so that, on each query, the client only
retrieves a ﬁxed number of chunks. If the whole response is
not retrieved at that moment, then the query is added to a queue
and the remaining chunks are retrieved on the next query. The
responses can therefore be delayed but the authors show that
the delay can be minimal for standard query distributions.
Volume-hiding constructions. VLH and AVLH are
volume-hiding encrypted multi-map constructions recently in-
troduced by Kamara and Moataz [44]. These schemes are the
ﬁrst volume-hiding STE constructions that do not rely on na¨ıve
padding. VLH makes use of a pseudo-random function F and
an optimal multi-map encryption scheme. It is parameterized
with a public parameter λ ≥ 1 that affects correctness. Given a
multi-map MM, the scheme determines a new response length
for each label (cid:96) in MM which is computed by evaluating F on
(cid:96)’s original response length and adding λ. If the new response
length is larger than the original, then (cid:96)’s tuple is padded.
If the new response length is smaller than the original, then
(cid:96)’s tuple is truncated. AVLH is a more advanced construction
based on a new design paradigm based on bi-partite graphs.
More precisely, AVLH transforms its input multi-map as a bi-
partite graph where top vertices correspond to the multi-map’s
labels and the bottom vertices correspond to bins. Each label’s
tuple values are then stored in its associated bin in a speciﬁc
way. The bins are then padded to have the same size. At query
time, the user always retrieves the same number of bins. AVLH
does not improve on the query complexity of encrypted multi-
map schemes but does improve on the storage efﬁciency of
naive padding. In [44] it is then shown that the storage can be
further reduced by relying on the conjectured hardness of the
planted densest subgraph problem.
APPENDIX B
COUNT V.1 WITH δ < 1
The Count v.1 attack was shown in [13] to have high
recovery rate when δ = 1; that is, when the adversary has full
knowledge of the data. For δ < 1, however, the attack seems to
only work if δ ≤ .8. We found that the experimental results for
δ < 1 that are reported in [13], however, are for an unpublished
variant of the count attack that relies on knowledge of client
queries. To better understand how known queries impact the
recovery rate of Count v.1, we evaluated the attack with a
varying fraction of known queries. The results are shown in
Figure 5.13 When the adversary knows 5% of the queries,
recovery rates are similar to the ones reported in [13]. When
the adversary knows 2% known queries, however, the attack
ceases to work even with δ = .9.
APPENDIX C
KEYWORD SELECTIVITY
Our empirical evaluation (see Section V) clearly shows
that the selectivity of the queries is by far the most important
13This experiment was performed using the implementation and dataset
of [13]. We thank the authors for promptly sharing their implementation and
data with us.
APPENDIX D
QUANTIFYING THE OFFSET FOR INJECTION
The total number of ﬁles injected by both the Decoding
and Binary Search attacks depend on an offset γ which is
determined by characteristics of the data collection. Here, we
study the values of these offsets on three different collections:
SU, S-MU and M-MU as deﬁned in Section V. Our results are
described in Figure 7. We found that querying on high- or low-
selectivity keywords did not have any impact on the Binary
Search attack. However, as can be seen from its description,
the size of the keyword space did have an impact. For the
Decoding attack, the amount of injected data did depend on
the selectivity of the queries: the amount for high-selectivity
queries was about twice as much as for low-selectivity queries.
This held for both the SU and S-MU datasets. We believe that
this is inherent to the way the offset is computed. In fact, on
high-selectivity queries, we noticed that the total volumes tend
to have a higher gap between them. This is not the case for
low-selectivity queries.
(a) Amount of injected data to recover one keyword.
(b) Amount of injected data to recover 500 keywords.
Figure 7: Amount of injected data for both the Decoding and Binary
Search attacks (with #W = 500).
Figure 5: Count v.1 with varying fractions of known queries (on 150
queries out of a keywords space of size 500).
factor on the recovery rate of all the attacks. Understanding the
selectivity of keywords in our dataset is therefore important.
In Figures 6 (a) and (b) we plot the selectivity of 1000 and
10, 000 most selective keywords, respectively, in our datasets
after stemming and removing stop words. We can see in
these Figures that keyword selectivity in Enron is power law
distributed. In other words, only a few keywords have high
and unique selectivities whereas the overwhelming majority
of keywords have low and common selectivities (at most 3).
(a) Distribution of the most selective 1000 keywords.
(b) Distribution of the most selective 10, 000 keywords.
Figure 6: Keyword selectivity.
18
 0 0.2 0.4 0.6 0.8 1 0 10 20 30 40 50 60 70 80 90 100Recovery ratePartial Knowledge in %2% known queries5% known queries 0 5000 10000 15000 20000 25000 30000 35000 40000 45000 50000 0 200 400 600 800 1000SelectivityKeywords rankSU datasetM-MU datasetL-MU dataset 0 5000 10000 15000 20000 25000 30000 35000 40000 45000 50000 0 2000 4000 6000 8000 10000SelectivityKeywords rankSU datasetM-MU datasetL-MU dataset 1 2 4 8 16 32 64 128M-SUS-MUM-MUSize in KBytesDatasetsDecoding w/ low selectivityBinary w/ low selectivityDecoding w/ high selectivityBinary w/ high selectivity 1 4 16 64 256 1024 4096 16384M-SUS-MUM-MUSize in MBytesDatasetsDecoding w/ low selectivityDecoding w/ high selectivity