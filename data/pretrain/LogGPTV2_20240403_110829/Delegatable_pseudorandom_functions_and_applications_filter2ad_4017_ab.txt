evaluates a PRF value without knowledge of the secret key.
Yet, although the party that provides the key can be viewed
to preserve resources, this setting does not match ours be-
cause there is no (i) input privacy (it is the second party who
provides the input x), and (ii) bandwidth eﬃciency when
applied over many values. Other related work includes al-
gebraic PRFs, employed in [4] to achieve optimal private
veriﬁcation of outsourced computation.
1Delegating PRF evaluation in a similar vein as we consider
here, was considered in [7, 8] after our work was submitted
for publication.
GGM framework. This refers to the seminal work by Gol-
dreich et al. [17], which shows how to generically construct
a PRF given black-box access to a length-doubling PRG.
The approach is based on a tree structure, over which hi-
erarchical invocations of the PRG produce the PRF values
at the leaves. Our constructions extend this framework in
non-trivial ways: First, we support delegation of PRF evalu-
ations; second, our security is proved in a much stronger ad-
versarial setting where the adversary gets to adaptively learn
also internal PRF values. The GGM framework, along with
its tree-based key-derivation structure, have been widely
used in the literature; also for special/limited delegation pur-
poses in the context of access control [30], broadcast encryp-
tion [31] and forward security [21]. Yet, to the best of our
knowledge, no such known key-derivation method has been
analyzed fully in a security model like ours, which allows
for adaptive PRF/delegation queries and addresses policy-
privacy issues.
3. DEFINITIONS
A pseudorandom function (PRF) family F is a family of
functions {fk : A → B | k ∈ K} so that K is eﬃciently
samplable and all F,K, A, B are indexed by a security pa-
rameter λ. The security property of a PRF is as follows:
For any probabilistic polynomial-time (PPT) algorithm A
running in time polynomial in λ it holds that
| Pr[Afk(·) = 1] − Pr[AR(·) = 1]| = negl(λ) ,
where negl denotes a negligible function and the probability
above is taken over the coins of A and the random variables
k and R which are uniformly distributed over the domains
K and (A → B) respectively.
Delegatable PRFs. The notion of delegation for a PRF
family F as above is deﬁned with respect to a delegation
policy P, i.e., P is a set of predicates deﬁned over A, also
indexed by λ, where each predicate P has an eﬃcient en-
coding. The set of elements in A that satisfy P is denoted
as AP = {x ∈ A | P (x)}.
Deﬁnition 1 (Delegatable PRF) A triple (F, T, C) is a
delegatable PRF, or DPRF scheme, for family F = {fk :
A → B | k ∈ K} with respect to policy P of predicates
over A, provided it satisﬁes two properties, correctness and
security, that are deﬁned individually below.
Correctness. We deﬁne T to be a PPT algorithm such
that, given a description of P ∈ P and a key k ∈ K, it out-
puts a “trapdoor” τ . The latter is intended to be used along
with the deterministic PPT algorithm C for the PRF com-
putation over every element of A that satisﬁes the predicate
P . For ﬁxed P, k, algorithm C can be viewed as a function
C : StP,k −→ B × StP,k ,
where StP,k is a set of states, and for any s ∈ StP,k the
output C(s) is a pair that consists of a PRF value and a
(new) state. We denote C(s) = (cid:104)CL(s), CR(s)(cid:105) and deﬁne
recursively the set of reachable states from a subset S of
StP,k as
R(S) (cid:44) S ∪ R(CR(S)) .
The elements of the DPRF that are produced given an ini-
tial state s will be deﬁned using the complete set of reachable
671
states given s. For a singleton S = {s}, we will write R(s)
instead of R({s}), and we will denote by R(s) the closure
of s under R, i.e., the ﬁxpoint of the recursive equation for
R that also contains s.
Deﬁnition 2 (Correctness) The DPRF scheme (F, T, C)
is correct for a policy P if for every P ∈ P:
1. {τ | τ ← T (P, k)} ∪ {⊥} ⊆ StP,k, for any k ∈ K
(initialization).
2. CR(⊥) = ⊥ (termination condition).
3. There is a polynomial q such that for every k ∈ K and
τ ← T (P, k):
(i) ⊥ ∈ R(τ ) (termination guarantee).
(ii) |R(τ )| ≤ q(λ) (feasibility).
(iii) {fk(x) | P (x)} = BP = {CL(s) | s ∈ R(τ )}
(completeness).
According to the above conditions, all possible trapdoors
corresponding to a certain policy predicate P are valid initial
inputs for C. Moreover, starting from an arbitrary trapdoor
for P as initial input, the proxy can execute a number of
steps of algorithm C, during which it successively computes
the DPRF image of every argument x that satisﬁes P , and
eventually terminate when it reaches the ﬁnal state ⊥, where
no further useful information can be derived.
We note that condition 3.(ii) implies the restriction that
the size of every policy predicate is polynomial. This stems
from the fact that we consider the setting where the proxy
wishes to eventually compute all the delegated PRF val-
ues.
If this is not necessary (or desirable) for the DPRF
application, the condition can be relaxed to any size of AP
(including super-polynomial sizes).
In this case, the com-
pleteness condition (item 3.(iii) above) would be infeasible
to meet, since the proxy cannot hope to be able to compute
all the delegated PRF values. There are a number of ways
to capture this by suitably modifying the way C works; for
instance: (i) C may sample the uniform distribution over
BP , (ii) C may be given the value x as input, and return
fk(x) if x ∈ AP and ⊥ otherwise, (iii) C may be given the
lexicographic rank of an element x within AP and return
fk(x) or ⊥ otherwise.
Security. We consider the case where the proxy is mali-
cious, and accordingly model DPRF security as an oracle
indistinguishability game GA
SEC carried out between an at-
tacker A and a challenger C indexed by parameter λ. The
game proceeds as shown in Figure 2. Note that due to the
delegation capabilities of DPRFs, the security game GA
SEC
is more elaborate than the security game of a plain PRF:
Indeed, in addition to issuing standard PRF queries, the
pseudorandomness attacker may now adaptively query also
a trapdoor oracle for delegation on predicates of its choice.
Deﬁnition 3 (Security) A DPRF scheme (F, T, C) is se-
cure for a policy P if for any PPT A, it holds that
Pr[GA
SEC(1λ) = 1] ≤ 1
2
+ negl(λ) .
DPRF Security Game GA
SEC(1λ)
1. The challenger C randomly selects k from K.
2. The adversary A is allowed to interact with C and ask
two types of queries:
(a) PRF queries for a value x ∈ A; to those queries C
responds with fk(x) and adds the value x to a set Lque.
(b) Delegation queries for a policy predicate P ∈ P; to
those queries C responds with τ ← T (P, k) and adds P
to a set Lpol.
3. The adversary A submits a challenge query x∗ to which
the challenger C responds as follows: It ﬂips a coin b
and if b = 1 it responds with y∗ = fk(x∗), otherwise, it
responds with a random value y∗ from B.
4. The adversary A continues as in step 2.
5. The adversary A terminates by returning a single bit ˜b.
Subsequently the game returns a bit which is 1 if and
only if the following holds true:
(b = ˜b) ∧ (x∗ (cid:54)∈ Lque) ∧ ∀P ∈ Lpol : ¬P (x∗) .
Figure 2: The DPRF security game.
We make the following observations about the deﬁnition.
First, it is easy to see that a delegatable PRF is indeed
a PRF. Speciﬁcally, any PRF attacker A against fk can
be turned into an attacker A(cid:48) that wins the DPRF game
GA
SEC(1λ). We provide only a simple sketch of this which fol-
lows by a standard “walking” argument (the reader familiar
with such arguments may skip to the next paragraph). Fix
some PPT A and let α be its non-negligible distinguishing
advantage. There will be some polynomial q so that, for any
λ, q(λ) is an upper bound on the number of queries submit-
ted to A’s oracle by A. Given such q and for ﬁxed λ, we de-
ﬁne the hybrid oracle (fk/R)j for any j ∈ {0, . . . , q(λ)} that
operates as follows: (fk/R)j responds as fk(·) in the ﬁrst j
queries and as R(·) in the last q(λ)− j queries. Taking such
sequence of oracles into account, by triangular inequality, it
follows that there exists some value j ∈ {0, . . . , q(λ)− 1} for
which the distinguishing probability will be at least α/q(λ)
for A to distinguish between two successive hybrid oracles
(fk/R)j and (fk/R)j+1 when R is a random function. This
follows from the fact that A distinguishes the “extreme” hy-
brids R(·) and fk(·) with probability α. We now construct
A(cid:48) as follows out of A: A(cid:48) plays the DPRF game and queries
the DPRF function for the ﬁrst j queries of A. Then it sub-
mits the (j + 1)-th query of A as the challenge. Finally, it
completes the simulation of A by answering any remaining
queries of A with random values drawn from B (w.l.o.g. the
queries to the oracle are all distinct), and outputs what A
does. It is easy to see that the distinguishing advantage of
A(cid:48) is α/2q(λ), i.e., non-negligible in λ.
Second, we observe that there is a trivial construction of
a delegatable PRF from any PRF: Consider an ordering ≤
over A, e.g., the lexicographical order. For ﬁxed P, k set
T (P, k) = (cid:104)fk(x1), . . . , fk(x|AP |)(cid:105) = τ , where xi is the i-th
element of AP according to ≤. Given τ , the set of states can
be StP,k = {τ, (2, τ ), . . . , (|AP|, τ ),⊥}, and the reconstruc-
tion function C can be simply deﬁned to be a table-lookup
in τ . It is straightforward to show that (F, T, C) is a DPRF
as long as the underlying family F is a PRF, since any del-
egation query can be interpreted as a series of polynomially
many PRF queries.
672
The existence of a trivial DPRF construction with re-
spect to arbitrary policies from any given PRF motivates
our primitive: Interesting DPRF constructions will be those
that are bandwidth eﬃcient, i.e., they provide trapdoors with
size that is sublinear in the number of elements that satisfy
the corresponding policy predicate.
Policy privacy. We next introduce an additional privacy
property that a DPRF scheme may optionally satisfy. This
property goes beyond the standard (D)PRF security and is
relevant in the context of PRF delegation for protecting the
associated policy predicates over which the delegation is de-
ﬁned. We accordingly model this new privacy condition as a
predicate indistinguishability game GA
PP carried out between
an attacker A and a challenger C indexed by a security pa-
rameter λ. The game proceeds as shown in Figure 3.
DPRF Policy Privacy Game GA
PP(1λ)
1. The challenger C randomly selects k from K.
2. The adversary A is allowed to interact with C and ask
delegation queries on policy predicates P ∈ P; to those
queries C responds with τ ← T (P, k) and adds P to a
set Lpol.
3. The adversary A submits two policy predicates P0, P1
to C. The challenger ﬂips a bit b and computes τ∗ ←
T (Pb, k). It returns τ∗ to the adversary.
4. The adversary A continues as in step 2.
5. The adversary A terminates by returning a single bit ˜b.
Subsequently the game returns a bit that is 1 if and only
if the following holds true:
(b = ˜b) ∧ (|AP0| = |AP1|) ∧ (AP0 (cid:54)= AP1 )∧
AP ) ∩ AP0
AP ) ∩ AP1
∧∀S ⊆ Lpol :˛˛(
\
P∈S
˛˛ =˛˛(
\
P∈S
˛˛ .
Figure 3: The DPRF policy privacy game.
Deﬁnition 4 (Policy privacy) A DPRF scheme (F, T, C)
is policy private for a policy P if for any PPT A, it holds
that
Pr[GA
PP(1λ) = 1] ≤ 1
2
+ negl(λ) .
The above deﬁnition suggests that the trapdoor that cor-
responds to a certain policy predicate hides the predicate
itself (i) at least among all (distinct) policy predicates that
enable evaluations of the PRF on the same number of ele-
ments in its domain, and (ii) when the adversary does not
make queries whose responses leak unequal parts of the PRF
image of the two challenge predicates. Observe that all the
(cid:54)= |AP1|, then
restrictions stated are necessary:
the adversary can distinguish P0 from P1 by counting the
number |{CL(s) | s ∈ R(τ∗)}| of new PRF values it com-
putes starting from state τ∗ and ending in ⊥. In addition,
if the number of elements that satisfy simultaneously any
set S of delegation queries and P0 is diﬀerent than the num-
ber of elements that satisfy S and P1, then the adversary
can distinguish the two predicates by counting the size of
{CL(s) | s ∈ R(τ∗)} ∩ (T
If |AP0|
P∈S BP ).
We note that while the above formulation can capture a
wide set of attacks against privacy, it can be strengthened
further by allowing multiple challenge pairs of policy predi-
cates. In this case, the policy-privacy game allows a multiple
number of adversarial actions submitting pairs of policies
(as in step 3 of the game) to be interleaved with delegation
queries. The challenger always responds based on the same
coin ﬂip b. Interestingly, this multiple-challenge policy pri-
vacy formulation can be shown to be strictly stronger than
the one corresponding to Deﬁnition 4.
On eﬃciently achieving policy privacy. We next argue
that even though desirable, the above formulations of pri-
vacy conﬂict with our eﬃciency considerations (sublinear-
size trapdoors) for a wide class of schemes. This will mo-
tivate relaxing the policy-privacy property as we will see in
the end of the section; the reader unwilling to go over the
details of the lower bound type of argument we sketch below