it seems hard to compare binary code across architectures.
To bridge this gap, a key step in our approach is to unify
the binary code of different architectures. To this end, we ﬁrst
utilize an off-the-shelf disassembler to extract the structure of
the binary code (such as functions, basic blocks, and control
ﬂow graphs). We then transform the complex instructions into
simple, RISC-like and uniﬁed instructions. We do so for two
reasons: First, it abstracts from architecture-speciﬁc artifacts
and facilitates symbolic normalization. Second, later stages
can now utilize this architecture-independent instruction set
and therefore only have to be implemented once.
D. Extracting Semantics via Sampling
The uniﬁed instruction set would allow us to compare
individual binary instructions syntactically. This already is a
big advantage over comparing different instruction sets from
multiple architectures. However, using the IR only solves some
of the issues when comparing binary code from different
architectures. It is also common to observe differences in
calling conventions, register uses or memory accesses, which
even inﬂuence the syntax of a uniﬁed representation. However,
the semantics of the binary code will remain similar, even if
source code is compiled for different architectures.
Therefore, in the next step, we aim to extract the semantics
of the binary code. We aggregate the computational steps for
each output variable of a basic block, which gives us precise
assignment formulas for each output register or output memory
location (see Figure 1, second column).
Special care needs to be taken for control ﬂow transfers.
By deﬁnition, every basic block ends with a terminator in-
struction, which determines the next basic block in the control
ﬂow. These terminators can have one successor (unconditional
jumps). To
jumps, returns) or two successors (conditional
712712
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:05:33 UTC from IEEE Xplore.  Restrictions apply. 
abstract from concrete addresses, we deﬁne successors via
symbolic function names (which, in our evaluation, are only
available for imported functions, such as from libc), or
via the number of basic blocks to skip. For example, the
true case of a conditional jump may jump three basic blocks
ahead. However, neither successors nor branch conditions are
structurally different from other assignment formulas and are
therefore handled in the same way. Note that indirect jumps,
like returns, indeed have only one successor formula, even
though this formula can be evaluated to multiple targets.
We extract the formulas per basic block, as we have ob-
served that the control ﬂow graph and the basic block margins
typically remain equivalent (or at
least similar) in cross-
compiled code. Note that this assumption may not always
hold for heavily obfuscated code or if compilers use varying
code optimization strategies. However, as we will show in
Section IV-B, our metric works quite well in scenarios with
different architectures, different compilers, or different opti-
mization levels. Section IV-C further shows that the metric can
even ﬁnd bugs in ﬁrmware of real-life, commercial devices.
For normalization purposes and simpler computation in
later steps, we simplify the assignment formulas by passing
them through a theorem prover. We therefore aggregate the
RISC-like instructions and map them to the theorem prover’s
structure. The theorem prover then returns S-Expressions, i.e.,
an easy-to-parse data structure that represents the formulas and
allows for arbitrary computations.
At this point, we have precise descriptions of the effect of
a basic block on the programs state: The assignment formulas
show an abstract representation of what operations the basic
block will perform given symbolic input values (see Figure 1).
However, these descriptions are still purely syntactic: Showing
that two basic blocks are equivalent based on these formulas
is—if possible at all—computationally intensive.
To achieve our goal of bug ﬁnding, we relax the condition
to ﬁnd code equivalence and use a metric that measures code
similarity. Ideally, such a similarity metric gradually scales
from 0.0 (distinct code) to 1.0 (equivalent code). We build
such a metric upon sampling, which was proposed by Jin et.
al [19]. First, we generate random and concrete values, which
we use as inputs for the formulas of each basic block. Then,
we observe the outputs of the formulas. Such point-wise eval-
uations capture the semantics of the performed computation.
Arguably, the semantics are not captured perfectly, as not all
possible values are used as input, but it is still reasonable to
assume that similar computations have more input/output pairs
in common than dissimilar ones.
we solved this issue by using permutations of the inputs.
Similarly, some formulas are prone to be misrepresented by
the I/O pairs. For example, a := b == 0 will be false for
all inputs but 0, such that it is semantically mostly similar to
a := 2 ∗ b + 3 == 5 (false for all inputs but 1). In such
cases, we would have to ﬁnd special “magic values” with a
theorem prover, which is computationally expensive. Luckily,
these cases usually occur only in branch conditions, which is
why we chose to ignore formulas of branch conditions so that
our similarity score is not biased.
E. Similarity Metric via Semantic Hashes
Evaluating a large number of sampled inputs results in
many I/O pairs which represent the semantics of the evaluated
basic blocks. The higher the number of shared, equal I/O
pairs between two basic blocks, the higher is the similarity
of these basic blocks. Thus, one could directly compare the
I/O pair-sets of two basic blocks, e. g. with the Jaccard index,
to measure their similarity. However, the large number of I/O
pairs and basic blocks would cause such a na¨ıve approach to
scale badly, as it requires many I/O pair comparisons.
We tackle this bottleneck with locally-sensitive hashes. A
LSH has the property that the similarity of the hash reﬂects the
similarity of the hashed object. We chose to use MinHash [5],
which satisﬁes the LSH properties and at
the same time
converges against the Jaccard index. In essence, MinHash
computes a semantic hash over a basic block by incorporating
the I/O pairs. Comparing two basic blocks now only requires
comparing their semantic hashes instead of comparing the
sets of I/O pairs, which signiﬁcantly reduces the required
complexity to measure the similarity of two basic blocks.
To compensate for statistical over-representation of the
I/O pairs of multi-variable formulas and the property of the
MinHash to operate on sets rather than multi-sets, we made
two improvements to the straightforward application of the
MinHashing algorithm (see Section III-C for details).
F. Comparing Larger Binary Structures
We have described how we capture the semantic represen-
tation of a basic block and presented a computationally cheap
metric to compare two basic blocks. This metric allows us
to perform the ﬁrst step of comparing code: ﬁnding pairs of
similar basic blocks, which are candidates for a signature-
spanning match. In order to match an entire bug signature,
though, comparing individual basic blocks is not sufﬁcient.
The code structure is quite relevant for some bug classes,
e.g., for integer or buffer overﬂows, in which bound checks
are either implemented or not. Bug signatures thus typically
consist of multiple basic blocks and capture the structure of
the code in terms of a CFG.
We therefore expand the comparison of individual basic
blocks with an algorithm that aims to identify the entire bug
signature. First, we pick a basic block from the bug signature
and compare it to all basic blocks from the program in ques-
tion. Then, we use an algorithm called Best Hit Broadening
(BHB), which broadens the initial candidate match along the
In order to grasp the semantics of the formulas equally well,
we have to devise a smart sampling strategy. Intuitively, the
more input variables a formula has, the larger the number
of sampled input variables should be. For example, the I/O-
behavior of a := b + 1 can be grasped with fewer samples
than the interplay of variables in a := b∗ c + d. Also, we have
to make the samples introduce some robustness to the order
of variables to make sure that, e. g., a := b− c and a := c− b
can be recognized as similar. We show in Section III-B how
713713
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:05:33 UTC from IEEE Xplore.  Restrictions apply. 
Architecture
ARM
MIPS
x86
S-Expressions
(= R3 (concat #x000000 ((extract 7 0) (Indirection R1))))
(= R1 (bvadd R1 1))
(= v0 (concat #x000000 ((extract 7 0) (Indirection a1))))
(= a1 (bvadd a1 1))
(= AL ((extract 7 0) (Indirection ESI)))
(= ESI (bvadd ESI DF))
(= EIP #x080579be)
(= PC #x000d816c)
(= PC #x0041ada0)
Fig. 3: From left to right: VEX-IR of a load byte instruction
on x86-32, ARM and MIPS.
Fig. 4: S-Expressions
CFGs in the bug signature and target program. BHB operates
in a greedy, but locally-optimal manner, until the match spans
the entire signature. BHB is then repeated for all basic blocks
in the bug signature, resulting in a list of functions ordered by
their similarity to the signature (see Section III-D for details).
III. IMPLEMENTATION
In this section, we discuss some of the speciﬁc details for
the proof-of-concept implementation of our approach.
A. Common Ground: The IR Stage
Our ﬁrst design choice was which processor architectures
we wanted to support. We chose ARM, x86 and MIPS (little-
and big endian), because these architectures are pervasive
and run many closed-source applications. x86 and ARM are
nowadays the most widespread architectures. We additionally
chose MIPS, as it is popular for embedded devices and is one
of the few architectures that stay close to the RISC principles.
We decided against x86-64, as it uses a different register size,
which—without further adaptations of our approach—would
inevitably lead to mismatches. In principle, other architectures
can be supported and incompatibilities can be solved with
some engineering effort.
First, we use IDA Pro [16] to extract a disassembly and
the control-ﬂow graph from the binary. Arguably, the resulting
disassembly is not perfect [3], but it proved to be sufﬁcient
for our purposes.
Our next step was ﬁnding a common representation for
binary code, which required us to consider the peculiarities
of each architecture. For this purpose we utilize the VEX-
IR, which is the RISC-like intermediate representation for the
popular Valgrind toolkit. One of the beneﬁts of VEX is its
support for many architectures. VEX translates from binary to
IR, but was never designed for static analysis, as it is part of a
dynamic binary instrumentation framework. We refrain from
discussing the VEX-IR in detail and refer the reader to the
Valgrind documentation [39].
We leveraged pyvex [36], a Python framework with bind-
ings to the VEX-IR, and used its API to process the IR
statically. We feed binary opcodes to pyvex and dismantle
the VEX statements into our own data structures. These
data structures are used to aggregate and map the VEX-IR
into semantically equivalent expressions for the Z3 theorem
prover [27]. The theorem prover’s sole purpose is to simplify
and normalize expressions. Additionally, it conveniently re-
turns S-Expressions.
Figure 3 shows the ﬁrst instruction of the second basic
block of BusyBox’ strcpy on each architecture. The load
byte instruction operates implicitly (x86) or explicitly (ARM,
MIPS) on registers. As all semantics of an instruction are made
explicit and transformed to RISC operations, they serve as a
convenient ground to deduce their effects and incorporate them
into S-Expressions. The numbers in GET and PUT are offsets
in a shadow table that are mapped to speciﬁc registers. In
the x86 example in Figure 3, t1 = GET:I32(32) loads
the content of register ESI into the temporary variable t1.
Note that we also obtain some type information from VEX.
The statement Put(8) = t8 writes the value from t8 into
AL. The last line sets the EIP register to the next instruction.
Figure 4 shows the corresponding mappings to S-Expressions,
where we can clearly see emerging similarity. The constructed
assignment formulas are now ready for sampling basic blocks.
It is worth mentioning that we observed some unreliable
behavior for ﬂoating point operations when using VEX stati-
cally. In fact, we identiﬁed only a few dozen ﬂoating point
operations in the binaries that we analyzed, so we chose
to replace ﬂoating point operations with NOPs. Again, it is
only a matter of engineering to add support for ﬂoating point
operations to our system.
B. Extracting Semantics: Sampling
To grasp the semantic I/O behavior of a basic block,
we evaluate its formulas point-wise. More speciﬁcally, we
generate random vectors with elements from the range
[−1000, 1000] and use them as input for the formulas. We
found this space to be sufﬁciently large to avoid random output
collisions, while being small enough to cover many possible
inputs in the sample range. We used the same sequence of
random input to evaluate all formulas to ensure that the com-
puted outputs are comparable across formulas. We then create
unique I/O pair representations by computing a 64-bit CRC
checksum of the input length, the inputs, and the output value.
Recall that our approach needs to work across architectures. As
register names do not match across architectures, we exclude
the output’s name from the checksum computation.
We have to ensure that our sampling is robust to the order
of variables. Let us consider the two formulas a := b − c
and a := c − b. They are the same, apart from the order
of variables. However, with the inputs (b = 1, c = 2) and
(b = 3, c = 5) their respective outputs are (−1,−2) and (1, 2),
which does not reﬂect the similarity of the formulas. We thus
also use the permutations as inputs, which are (b = 2, c =
1) and (b = 5, c = 3) in the example, and will obtain the
714714
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:05:33 UTC from IEEE Xplore.  Restrictions apply. 
outputs (−1,−2, 1, 2) and (1, 2,−1,−2), at which point we
can observe similarity. Regardless of the CPU architecture,
most basic blocks’ formulas have only a few input variables.
In BusyBox, less than 0.03% of the formulas have more than
four input variables, so we can safely limit sampling to those
formulas with at most four variables.
Another important detail relates to multiple layers of mem-
ory indirections (pointers to pointers). Since ARM and MIPS
have a much larger number of registers than x86, there is natu-
rally more register spilling necessary on x86. In our aggregated
formulas, we observed many cases where the x86 version used
a memory location as input or output, and ARM or MIPS
simply used a register. However, a register use has only one
input (the value it contains), while a memory indirection has
two (the address specifying the location for indirection and
the value at that location). Since we only compare formulas
that have the same number of inputs, memory indirection thus
effectively disrupted our formula comparison. Normally, to
provide consistent memory (i. e., if an address is calculated
twice in a formula, it references the same value), we would
have to track the calculated addresses of nested memory in-
directions. Thus, for EAX := [[EBX]], we sample a value
for the register EBX, then for the memory location [EBX]
and ﬁnally for the memory location [[EBX]]. However, for
sampling, the ﬁnal result of the computation is a value from
memory (regardless of the layers of indirection), such that it
sufﬁces to track just one level of indirection. Effectively, we
always provide an input variable for each indirection, if their
address formula differed. That way, both an indirection and a
register use account for only a single input.
C. Semantic Hash
We now have a list of I/O pairs, given as CRC checksums,
for each basic block. Determining the similarity based on these
I/O pairs would be expensive, both in respect to storage (due to
the large number of necessary samples) and computation time.
Therefore, we use the MinHash algorithm, which combines
the I/O pairs of a basic block into a locally-sensitive hash.
MinHash works as follows: it applies a (non-cryptographic)
hash function to each element in the list and stores the minimal
hash value among all I/O pairs. To compute the MinHash, this
process is repeated with a variety of different hash functions.
The more hash functions are used, the better the MinHash
converges against the Jaccard index [5]. The purpose of the
hash function is to randomly select an estimator for set-
similarity. The similarity between two MinHashes averages
over i = 0...n such estimators:
sim(mh1, mh2) := |{mh1[i] = mh2[i]}|/n.
√
The expected error for n hash functions can be estimated
to O(1/
n) with a Chernoff bound [44]. We use 800 hash
functions, which leads to an error of about 3.5%.
(1)
For our evaluation, we used an afﬁne hash function of the
form h(x) := ax + b mod p with random 64-bit coefﬁcients,
where a prime modulus p guarantees that all coefﬁcients are
generators. To improve performance, we simulate further hash
functions by transforming the output of the real hash function
with rotation and XORing:
t(h(x)) := rotate(h(x), a) ⊕ b.
(2)
The transformation changes the order of elements and there-
fore the selected minimum, which sufﬁces for MinHashing.
We implemented two improvements of the standard Min-
Hash algorithm. First, we compute multiple MinHashes per
basic block, which we denote as Multi-MinHash. We do so
by splitting the formulas into groups according to the number
of input variables per formula and computing one MinHash
per group. Later, we solely compare MinHashes for the
same number of variables and compute the overall similarity
by weighting the individual MinHashes by the number of
formulas with the speciﬁc number of variables in the respective
basic blocks. Thus, to compare two basic blocks, we compute
(cid:2)
i si · (wi + w(cid:3)
i)
i (wi + w(cid:3)
i)
(cid:2)
,
(3)
where si is the similarity of the formulas with i variables, wi