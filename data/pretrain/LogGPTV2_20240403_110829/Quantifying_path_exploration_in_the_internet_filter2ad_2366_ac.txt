 100
 90
 80
 70
 60
 50
 40
 30
 20
 10
 0
Correct
Equal
Wrong
Length
Policy
Policy+Length
Usage Time
(a) Tup
Correct
Equal
Wrong
Length
Policy
Policy+Length
Usage Time
(b) Tdown
Figure 7: Comparison between Ccorrect,Cequal and
Cwrong of length , policy and usage time metrics for
(a) Tup and (b) Tdown events of beacon preﬁxes.
such as traﬃc engineering, AS internal routing metric, etc.,
that aﬀect actual routes being used. Compared with Length,
Policy+Length has a comparable performance with Tdown
events, and a moderate improvement with Tup events.
Usage Time works surprisingly well and outperforms the
other three in both Tdown and Tup events.
Its Pcorrect is
about 92% in Tup and 99% in Tdown events. Its Cequal value
is 0 in both Tup and Tdown events. This is because we are
measuring the path usage time using the unit of second,
which eﬀectively puts all the paths in strict rank order. We
also notice that for Tup events, about 8% of the compar-
isons are wrong, whereas for Tdown events this number is
as low as 1%. We believe this noticeably high percentage
of wrong comparisons in Tup events is due to path changes
caused by topological changes, such as a new link estab-
lished between two ASes as a result of e.g. a customer that
switches to a new provider. Because the new paths have low
usage time, our Usage Time based inference will give them
a low rank, although these paths are actually the preferred
ones. Nevertheless, the data conﬁrmed our earlier assump-
tion that, during our 1-month measurement period, there
were no signiﬁcant changes in Internet topology or routing
polices, otherwise we would have seen a much higher per-
centage of wrong cases produced by Usage Time.
We now examine how the value of Pcorrect varies between
diﬀerent monitors under each of the four path ranking meth-
ods. Figure 8 shows the distribution of Pcorrect for diﬀerent
methods, with X-axis representing the monitors sorted in de-
creasing order of their Pcorrect value. The value of Pcorrect
t
c
e
r
r
o
c
P
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 5
 10
s
t
n
e
v
e
n
w
o
d
T
f
o
r
e
b
m
u
N
 1.2e+06
 1e+06
 800000
 600000
 400000
 200000
 0
Length
Policy
Policy+Length
Usage Time
 15
 25
 20
 30
Number of monitors
 35
 40
 45
Figure 8: Comparison between accuracy of length,
policy and usage time metrics.
for each monitor is calculated over all the Tdown and Tup
events in our beacon data set. When using the path usage
time for path ranking, we observe an accuracy between 88%
and 100% across all the monitors, whereas with using path
length for ranking, we observe the Pcorrect value can be as
low as 31% for some monitor. Using policy for path ranking
leads to even lower Pcorrect values.
After we developed and calibrated the usage time based
path ranking method using beacon updates, we applied the
method, together with the other three, to the BGP updates
for all the preﬁxes collected from all the 50 monitors, and we
obtained the results that are similar to that from the bea-
con update set. Pcorrect is 17% for Policy, 65% for Length,
73% for Policy+Length, and 95% Usage Time. Thus we be-
lieve usage time works very well for our purpose and use it
throughout our study.
To the best of our knowledge, we are the ﬁrst to propose
the method of using usage time to infer relative path pref-
erence. We believe this new method can be used for many
other studies on BGP routing dynamics. For example, [7]
pointed out that if after a routing event, the stable path is
switched from P1 to P2, the root cause of the event should
lie on the better path of the two. The study used length-only
in their path ranking and the root cause inference algorithm
produced a mixed result. Our result shows that using length
for path ranking gives only about 60% accuracy, and usage
time can give more than 95% accuracy. Using usage time
to rank path can potentially improve the results of the root
cause inference scheme proposed in [7].
3. CHARACTERIZING EVENTS
After applying the classiﬁcation algorithm to BGP data,
we count the number of Tdown events observed by each moni-
tor as a sanity check. A Tdown event means that a previously
reachable preﬁx becomes unreachable, suggesting that the
root cause of the failure is very likely at the AS that origi-
nates the preﬁx, and should be observed by all the monitors.
Therefore, we expect every monitor to observe roughly the
same number of Tdown events. Figure 9 shows the number of
Tdown events seen by each monitor. Most monitors observe
similar number of Tdown events, but there are also a few out-
 0
 5
 10  15  20  25  30  35  40  45
Monitor ID
Figure 9: Number of Tdown events per monitor.
No. of Events Duration No. of
(×106)
3.39
3.35
7.39
7.90
18.32
20.44
(second) Updates
2.30
4.10
1.74
2.51
4.11
1.58
45.26
116.34
33.26
68.76
148.39
43.47
No. of
Paths
1.77
2.04
1.34
1.70
2.45
1
Tup
Tdown
Tshort
Tlong
Tpdist
Tspath
Table 1: Event Statistics
liers that observe either too many or too few Tdown events.
Too many Tdown events can be due to failures that are close
to monitors and partition the monitors from the rest of the
Internet, or underestimation of the relative timeout T used
to cluster updates. Too few Tdown events can be due to miss-
ing data during monitor downtime, or overestimation of the
relative timeout T . In order to keep consistency among all
monitors, we decided to exclude the head and tail of the
distribution, reducing the data set to 32 monitors.
Now we examine the results of event classiﬁcation. Table
1 shows the statistics for each event class, including the total
number of events, the average event duration, the average
number of updates per event, and the average number of
unique paths explored per event. We exclude Tequal events
from the table since their percentage is negligible.
There are three observations. First, the three high-level
event categories in Figure 4 have approximately the same
number of events: Path-Change events are about 36% of
all the events, Same-Path 34% and Path-Disturbance 30%.
Breaking down Path-Change events, we see that the num-
ber of Tdown balances that of Tup, and the number of Tlong
balances that of Tshort. This makes sense since Tdown fail-
ures are recovered with Tup events, and Tlong failures are
recovered with Tshort events.
Second, the average duration of diﬀerent types of events
can be ordered as follows: Tshort < Tspath (cid:6) Tup < Tlong (cid:4)
Tdown < Tpdist. Figure 10 shows the distributions of event
durations, 4 which also follow the same order. Note that
the shape of the curves is stepwise with jumps at multiples
of around 26.5 seconds. The next section will explain that
this is due to the MinRouteAdvertisementInterval (MRAI)
4The Tspath curve is omitted from the ﬁgure for clarity.
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
)
F
D
C
(
y
c
n
e
u
q
e
r
F
 0
 0
 1
 2
Tup
Tdown
Tshort
Tlong
Tpdist
 3
 4
Tup
Tdown
Tshort
Tlong
Tpdist
 0
 50
 100
 150
 200
 250
 300
Event duration (s)
Number of ASPATHs explored per event
Figure 10: Duration of Events.
Figure 12: Number of Unique Paths Explored per
Event.
)
F
D
C
(
y
c
n
e
u
q
e
r
F
)
F
D
C
(
y
c
n
e
u
q
e
r
F
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 1
 2
 3
 4
Tup
Tdown
Tshort
Tlong
Tpdist
 5
 6
Number of updates per event
Figure 11: Number of Updates per Event.
timer, which controls the interval between consecutive up-
dates sent by a router. The default range of MRAI timer
has the average value of 26.5 seconds, making events last for
multiples of this value. Table 1 also shows that Tpdist events
have the longest duration, the most updates and explore the
most unique paths. This suggests that Tpdist likely contains
two events very close in time, e.g., a link failure followed
shortly by its recovery. A study [18] on network failures in-
side a tier-1 provider revealed that about 90% of the failures
on high-failure links take less that 3 minutes to recover, while
50% of optical-related failures take less than 3.5 minutes
to recover. Therefore there are many short-lived network
failures and they can very well generate routing events like
Tpdist. On the other hand, Tspath events are much shorter
and have less updates. It is because that Tspath is likely due