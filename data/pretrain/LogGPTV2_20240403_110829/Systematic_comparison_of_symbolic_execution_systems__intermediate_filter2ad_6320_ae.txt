Analysis. In 2016 IEEE Symposium on Security and Privacy (SP). IEEE, 138–157.
[39] Nick Stephens, John Grosen, Christopher Salls, Andrew Dutcher, Ruoyu Wang,
Jacopo Corbetta, Yan Shoshitaishvili, Christopher Kruegel, and Giovanni Vigna.
)
s
(
e
m
i
t
n
o
i
t
u
c
e
x
E
10000
1000
100
10
1
0.1
Qsym
S2E
Angr
KLEE
Figure 5: Absolute execution time during the measurement
of execution speed.
2016. Driller: Augmenting Fuzzing Through Selective Symbolic Execution. In
NDSS, Vol. 16. 1–16.
[40] Trail of Bits. 2017. Manticore: Symbolic execution for humans. https://blog.
trailofbits.com/2017/04/27/manticore-symbolic-execution-for-humans/. Ac-
cessed: 2019-02-27.
[41] Hui Xu, Zirui Zhao, Yangfan Zhou, and Michael R. Lyu. 2018. Benchmarking the
Capability of Symbolic Execution Tools with Logic Bombs. IEEE Transactions on
Dependable and Secure Computing (2018).
[42] Hui Xu, Yangfan Zhou, Yu Kang, and Michael R. Lyu. 2017. Concolic execution on
small-size binaries: challenges and empirical study. In 2017 47th Annual IEEE/IFIP
International Conference on Dependable Systems and Networks (DSN). IEEE, 181–
188.
[43] Insu Yun, Sangho Lee, Meng Xu, Yeongjin Jang, and Taesoo Kim. 2018. QSYM: A
Practical Concolic Execution Engine Tailored for Hybrid Fuzzing. In 27th USENIX
Security Symposium (USENIX Security 18). 745–761.
[44] Lintao Zhang, Conor F. Madigan, Matthew H. Moskewicz, and Sharad Malik. 2001.
Efficient conflict driven learning in a boolean satisfiability solver. In Proceedings
of the 2001 IEEE/ACM international conference on Computer-aided design. IEEE
Press, 279–285.
A CODE AND DATASET AVAILABILITY
We make all code and data used in this study available to the commu-
nity at http://www.s3.eurecom.fr/tools/symbolic_execution/, hop-
ing that it will benefit future research.
B ADDITIONAL MEASUREMENTS
This section shows measurement results that are complementary
to those we present in Section 5. While they are not essential to
our study, we assume that some readers will be interested in the
additional data.
Figure 5 displays the absolute execution times of our measure-
ments of execution speed in Section 5.4. In particular, we see that
angr consumes an order of magnitude more time than S2E. Figure 6
shows the execution rates; however, here we express them in terms
of each system’s own IR instructions per time, i.e., before translat-
ing to the common basis of machine code instructions. Note that
the relative order of the four systems is the same as in Figure 3.
Figure 7 visualizes the absolute number of queries generated
by each system in our measurement of query complexity (see Sec-
tion 5.5). We note that angr and KLEE tend to issue more queries
than S2E and Qsym. However, we attribute the differences to the
varying degrees of instrumentation in the implementations rather
than the IR or its generation. For instance, KLEE performs bounds
Symbolic Execution: IR and its Generation
ACSAC ’19, December 9–13, 2019, San Juan, PR, USA
checks on every memory access and tests whether pointers may be
null; Qsym only involves the solver when the control flow depends
on symbolic data and defers any security checks to the fuzzer that
is expected to run concurrently (see Figure 1).
C TESTED APPLICATIONS
Table 5 provides an overview of the CGC programs that we used
for the experiments in Sections 5.4 and 5.5. When programs can be
used successfully for the speed measurements in Section 5.4 but not
for the assessment of query complexity in Section 5.5, the reason
is often that the generated queries are so complex that the solver
times out. (Recall that we do not set a timeout for individual queries
when evaluating their complexity.)
In the inverse case, i.e., programs used to measure query com-
plexity but not for execution speed, we encountered a few different
cases: angr issues SMT queries for each input byte in every execu-
tion, independently of whether the data is used. In some cases, it
never encounters instructions that operate on the symbolic input
data, so that we do not include the program in the evaluation of
execution speed; however, due to the behavior mentioned above,
there are still queries whose complexity can be assessed. Moreover,
we found S2E’s statistical counters to be lagging behind in some
cases. In programs with very few symbolic operations, the counters
may report zero, resulting in those programs being excluded from
the speed measurements. Since we still see SMT queries, however,
we include them in the experiments on query complexity.
)
s
/
s
n
o
i
t
c
u
r
t
s
n
i
e
t
a
r
n
o
i
t
u
c
e
x
E
R
I
(
1 × 107
1 × 106
100000
10000
1000
100
10
1
0.1
Qsym
S2E
Angr
KLEE
Figure 6: Execution speed of symbolically executed instruc-
tions. Higher rates mean faster execution.
s
e
i
r
e
u
q
d
e
t
a
r
e
n
e
g
f
o
r
e
b
m
u
N
100000
10000
1000
100
10
1
Qsym
S2E
Angr
KLEE
Figure 7: Absolute number of queries generated by the sym-
bolic execution engines during our measurements of query
complexity.
ACSAC ’19, December 9–13, 2019, San Juan, PR, USA
Sebastian Poeplau and Aurélien Francillon
Name
Code size (LoC)
Used in
Section 5.4
Section 5.5
CROMU_00020
CROMU_00043
KPRCA_00010
KPRCA_00011
KPRCA_00014
KPRCA_00021
KPRCA_00022
KPRCA_00023
KPRCA_00028
KPRCA_00031
KPRCA_00037
KPRCA_00038
KPRCA_00040
KPRCA_00042
KPRCA_00047
KPRCA_00053
NRFIN_00001
NRFIN_00004
NRFIN_00007
NRFIN_00011
NRFIN_00015
NRFIN_00018
NRFIN_00021
NRFIN_00023
NRFIN_00026
NRFIN_00029
NRFIN_00032
NRFIN_00035
NRFIN_00036
NRFIN_00038
NRFIN_00040
NRFIN_00041
NRFIN_00042
YAN01_00011
YAN01_00012
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
414
950
1,391
1,497
970
1,896
1,442
1,667
1,529
1,927
1,538
4,304
1,599
1,769
101,921
2,387
647
706
3,873
1,351
467
230
398
1,752
37,288
1,998
4,053
1,266
667
2,166
1,766
1,446
968
398
270
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
Description
Echo service
Protocol-aware packet analyzer
Visualizer for uncompressed PCM audio files in both the time domain and the
frequency domain (with FFT)
Simple movie rental service
Basic virtual machine
Parser for a custom JSON-like data format
Online job application form, modeled after web applications
Online job application form, modeled after web applications
Interpreter for a custom list-based programming language
Chat server with bots
Extractor of section and symbol information for CGC executables
Awk clone
Custom compression algorithm
Simple movie rental service
Optical character recognition (OCR) engine
Blogging site
SNMP-like service
Chat bots
Simulation of mixing chemicals
A client for HTML-like documents
Stack-based virtual machine
Matrix arithmetic
Trading algorithm simulation
Electronic trading system for matching buyers and sellers
Packet parser
UTF-enabled file server
Network protocol dissector
PLC simulation
Personal finance management tool
Stateful session-based network service
Regular language recognition and enumeration
Marine tracking system fashioned after AIS
Memory as a service
Word completion game
Stack-based virtual machine
Table 5: Details of the CGC programs used in our measurements of execution speed and query complexity.