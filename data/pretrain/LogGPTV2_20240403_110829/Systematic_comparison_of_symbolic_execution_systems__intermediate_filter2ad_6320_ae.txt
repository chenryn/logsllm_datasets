### Analysis
In the 2016 IEEE Symposium on Security and Privacy (SP), IEEE, pages 138–157.

[39] Nick Stephens, John Grosen, Christopher Salls, Andrew Dutcher, Ruoyu Wang, Jacopo Corbetta, Yan Shoshitaishvili, Christopher Kruegel, and Giovanni Vigna. "Driller: Augmenting Fuzzing Through Selective Symbolic Execution." In NDSS, Vol. 16, pages 1–16, 2016.

### Figure 5: Absolute Execution Time During the Measurement of Execution Speed
- **Qsym**
- **S2E**
- **Angr**
- **KLEE**

The figure displays the absolute execution times for the symbolic execution engines during the measurement of execution speed in Section 5.4. Notably, Angr consumes an order of magnitude more time than S2E.

### Additional References
[40] Trail of Bits. "Manticore: Symbolic Execution for Humans." Blog post, April 27, 2017. Accessed: February 27, 2019. [Link](https://blog.trailofbits.com/2017/04/27/manticore-symbolic-execution-for-humans/).

[41] Hui Xu, Zirui Zhao, Yangfan Zhou, and Michael R. Lyu. "Benchmarking the Capability of Symbolic Execution Tools with Logic Bombs." IEEE Transactions on Dependable and Secure Computing, 2018.

[42] Hui Xu, Yangfan Zhou, Yu Kang, and Michael R. Lyu. "Concolic Execution on Small-Size Binaries: Challenges and Empirical Study." In 2017 47th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN). IEEE, pages 181–188, 2017.

[43] Insu Yun, Sangho Lee, Meng Xu, Yeongjin Jang, and Taesoo Kim. "QSYM: A Practical Concolic Execution Engine Tailored for Hybrid Fuzzing." In 27th USENIX Security Symposium (USENIX Security 18). Pages 745–761, 2018.

[44] Lintao Zhang, Conor F. Madigan, Matthew H. Moskewicz, and Sharad Malik. "Efficient Conflict Driven Learning in a Boolean Satisfiability Solver." In Proceedings of the 2001 IEEE/ACM International Conference on Computer-Aided Design. IEEE Press, pages 279–285, 2001.

### A. Code and Dataset Availability
We make all code and data used in this study available to the community at [http://www.s3.eurecom.fr/tools/symbolic_execution/](http://www.s3.eurecom.fr/tools/symbolic_execution/), hoping that it will benefit future research.

### B. Additional Measurements
This section presents complementary measurement results to those in Section 5. While these are not essential to our study, we assume that some readers will be interested in the additional data.

**Figure 5: Absolute Execution Time During the Measurement of Execution Speed**
- The figure shows the absolute execution times for the symbolic execution engines during the measurement of execution speed in Section 5.4. Notably, Angr consumes an order of magnitude more time than S2E.

**Figure 6: Execution Speed of Symbolically Executed Instructions**
- This figure displays the execution rates of symbolically executed instructions. Higher rates indicate faster execution.
- **Qsym**
- **S2E**
- **Angr**
- **KLEE**

**Figure 7: Absolute Number of Queries Generated by Symbolic Execution Engines**
- This figure visualizes the absolute number of queries generated by each system during the measurement of query complexity in Section 5.5.
- **Qsym**
- **S2E**
- **Angr**
- **KLEE**

We note that Angr and KLEE tend to issue more queries than S2E and Qsym. However, these differences are attributed to the varying degrees of instrumentation in the implementations rather than the intermediate representation (IR) or its generation. For example, KLEE performs bounds checks on every memory access and tests whether pointers may be null, while Qsym only involves the solver when the control flow depends on symbolic data and defers any security checks to the fuzzer that is expected to run concurrently.

### C. Tested Applications
Table 5 provides an overview of the Cyber Grand Challenge (CGC) programs used in the experiments in Sections 5.4 and 5.5.

| Name | Code Size (LoC) | Used in Section 5.4 | Used in Section 5.5 | Description |
|------|-----------------|---------------------|---------------------|-------------|
| CROMU_00020 | 414 | ✓ | ✓ | Echo service |
| CROMU_00043 | 950 | ✓ | ✓ | Protocol-aware packet analyzer |
| KPRCA_00010 | 1,391 | ✓ | ✓ | Visualizer for uncompressed PCM audio files in both the time domain and the frequency domain (with FFT) |
| KPRCA_00011 | 1,497 | ✓ | ✓ | Simple movie rental service |
| KPRCA_00014 | 970 | ✓ | ✓ | Basic virtual machine |
| KPRCA_00021 | 1,896 | ✓ | ✓ | Parser for a custom JSON-like data format |
| KPRCA_00022 | 1,442 | ✓ | ✓ | Online job application form, modeled after web applications |
| KPRCA_00023 | 1,667 | ✓ | ✓ | Online job application form, modeled after web applications |
| KPRCA_00028 | 1,529 | ✓ | ✓ | Interpreter for a custom list-based programming language |
| KPRCA_00031 | 1,927 | ✓ | ✓ | Chat server with bots |
| KPRCA_00037 | 1,538 | ✓ | ✓ | Extractor of section and symbol information for CGC executables |
| KPRCA_00038 | 4,304 | ✓ | ✓ | Awk clone |
| KPRCA_00040 | 1,599 | ✓ | ✓ | Custom compression algorithm |
| KPRCA_00042 | 1,769 | ✓ | ✓ | Simple movie rental service |
| KPRCA_00047 | 101,921 | ✓ | ✓ | Optical character recognition (OCR) engine |
| KPRCA_00053 | 2,387 | ✓ | ✓ | Blogging site |
| NRFIN_00001 | 647 | ✓ | ✓ | SNMP-like service |
| NRFIN_00004 | 706 | ✓ | ✓ | Chat bots |
| NRFIN_00007 | 3,873 | ✓ | ✓ | Simulation of mixing chemicals |
| NRFIN_00011 | 1,351 | ✓ | ✓ | A client for HTML-like documents |
| NRFIN_00015 | 467 | ✓ | ✓ | Stack-based virtual machine |
| NRFIN_00018 | 230 | ✓ | ✓ | Matrix arithmetic |
| NRFIN_00021 | 398 | ✓ | ✓ | Trading algorithm simulation |
| NRFIN_00023 | 1,752 | ✓ | ✓ | Electronic trading system for matching buyers and sellers |
| NRFIN_00026 | 37,288 | ✓ | ✓ | Packet parser |
| NRFIN_00029 | 1,998 | ✓ | ✓ | UTF-enabled file server |
| NRFIN_00032 | 4,053 | ✓ | ✓ | Network protocol dissector |
| NRFIN_00035 | 1,266 | ✓ | ✓ | PLC simulation |
| NRFIN_00036 | 667 | ✓ | ✓ | Personal finance management tool |
| NRFIN_00038 | 2,166 | ✓ | ✓ | Stateful session-based network service |
| NRFIN_00040 | 1,766 | ✓ | ✓ | Regular language recognition and enumeration |
| NRFIN_00041 | 1,446 | ✓ | ✓ | Marine tracking system fashioned after AIS |
| NRFIN_00042 | 968 | ✓ | ✓ | Memory as a service |
| YAN01_00011 | 398 | ✓ | ✓ | Word completion game |
| YAN01_00012 | 270 | ✓ | ✓ | Stack-based virtual machine |

When programs can be used successfully for the speed measurements in Section 5.4 but not for the assessment of query complexity in Section 5.5, the reason is often that the generated queries are so complex that the solver times out. Conversely, for programs used to measure query complexity but not for execution speed, we encountered cases where Angr issues SMT queries for each input byte in every execution, independently of whether the data is used. In such cases, there are still queries whose complexity can be assessed. Additionally, we found S2E’s statistical counters to be lagging behind in some cases, leading to their exclusion from speed measurements but inclusion in query complexity assessments.