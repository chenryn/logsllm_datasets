compare
t ) ;
input ,
i n p u t +
5. REVIVING LUCKY 13 ON THE CLOUD
As the cross-network timing side channel has been closed
(c.f. Section 4), the Lucky 13 attack as originally proposed
no longer works on the recent releases of most cryptographic
libraries. In this work we revive the Lucky 13 attack to tar-
get these (ﬁxed) releases by gaining information through co-
located VMs (a leakage channel not considered in the origi-
nal paper) rather than the network timing exploited in the
original attack.
5.1 Regaining the Timing Channel
Most cryptographic libraries and implementations have
been largely ﬁxed to yield an almost constant time when
the MAC processing time is measured over the network. As
discussed in Section 4, although there are some similarities
in these patches, there are also subtle diﬀerences which—as
we shall see—have signiﬁcant implications on security. Some
of the libraries not only closed the timing channel but also
various cache access channels. In contrast, other libraries left
an open door to implement access driven cache attacks on
the protocol. In this section we analyze how an attacker can
gain information about the number of compression functions
Figure 3: Histogram of network time measured for
sent packages with valid (4 compression functions)
and invalid (5 compression functions) paddings.
performed during the HMAC operation by making use of
leakages due to shared memory hierarchy in VMs located
on the same machine. This is suﬃcient to re-implement the
Lucky 13 attack.
More precisely, during MAC processing depending on whether
the actual MAC check terminates early or not, some li-
braries call a dummy function to equalize the processing
time. Knowing if this dummy function is called or not re-
veals whether the received packet was processed as to either
having a invalid padding, zero length padding or any other
valid padding.
In general, any diﬀerence in the execution
ﬂow between handling a well padded message, a zero padded
message or an invalid padded message enables the Lucky 13
attack. This information is gained by the Flush+Reload
technique if the cloud system enables deduplication features.
To validate this idea, we ran two experiments:
• In the ﬁrst experiment we generated encrypted packets
using PolarSSL client with valid and invalid paddings
and measured the network time as shown in Figure 3.
Note that, the network time in the two distributions
obtained for valid and invalid paddings are essentially
indistinguishable as intended by the patches.
• In the second experiment we see a completely diﬀerent
picture. Using PolarSSL we generated encrypted pack-
ets with valid and invalid paddings which were then
sent to a PolarSSL server. Here instead, we measured
the time it takes to load a speciﬁcally chosen PolarSSL
library function running inside a co-located VM. Fig-
ure 4 shows the probability distributions for a function
reloaded from L3 cache vs. a function reloaded from
the main memory. The two distributions are clearly
distinguishable and the misidentiﬁcation rate (the area
under the overlapping tails in the middle of the two
distributions) is very small. Note that, this substitute
timing channel provides much more precise timing that
the network time. To see this more clearly, we refer
the reader to Figure 2 in [16] where the network time
in case of TLS as many as 214 trials were necessary to
guess a single byte value.
Disadvantages:.
• Assumption of co-location: To target a speciﬁc vic-
tim, the attacker has to be co-located with that tar-
get. However the attacker could just reside in a phys-
ical machine and just wait for some potential random
victim running a TLS operation.
• Other sources of noise: The attacker no longer has to
deal with network channel noise, but still has to deal
with other microarchitectural sources of noise, such
as instruction prefetching. This new source of noise
is translated in more traces needed, but as we will
see, much less than in the original Lucky 13 attack. In
Section 6 we explain how to deal with this new noise.
5.3 Attack Description
In this section we describe how an attacker uses Flush+Reload
technique to gain access to information about the plaintext
that is being sent to the victim.
• Step 1 Function identiﬁcation: Identify diﬀerent
function calls in the TLS record decryption process
to gain knowledge about suitable target functions for
the spy process. The attacker can either calculate the
oﬀset of the function she is trying to monitor in the
library, and then add the corresponding oﬀset when the
Address Space Layout Randomization (ASLR ) moves
her user address space. Another option is to disable
the ASLR in the attackers VM, and use directly the
virtual address corresponding to the function she is
monitoring.
• Step 2 Capture packet, mask and replace: The
attacker captures the packet that is being sent and
masks it in those positions that are useful for the at-
tack. Then she sends the modiﬁed packet to the vic-
tim.
• Step 3 Flush targeted function from cache: The
ﬂush and reload process starts after the attacker re-
places the original version of the packet and sends it.
The co-located VM ﬂushes the function to ensure that
no one but the victim ran the targeted function. Any
subsequent execution of the targeted function will bear
a faster reload time during the reload process.
• Step 4 Reload target function & measure: Reload
the corresponding function memory line again and mea-
sure the reload time. According to a threshold that
we set based on experimental measurements, we de-
cide whether the dummy function was loaded from
the cache (implying that the victim has executed the
dummy function earlier) or was loaded from the main
memory (implying the opposite).
Since the attacker has to deal with instruction prefetching,
she will be constantly running Flush+Reload for a speciﬁed
period of time. The attacker therefore distinguishes between
functions preloaded and functions preloaded and executed,
since the latter will stay for a longer period of time in the
cache.
Figure 4: Histogram of access time measured for
function calls from the L3 cache vs. a function called
from the main memory.
is measured to obtain two overlapping Gaussians by
measurements with OpenSSL encrypted traﬃc. This
is not a surprise, since the network channel is signiﬁ-
cantly more noisy.
In conclusion, we regain a much more precise timing channel,
by exploiting the discrepancy between L3 cache and mem-
ory accesses as measured by a co-located attacker. In what
follows, we more concretely deﬁne the attack scenario, and
then precisely deﬁne the steps of the new attack.
5.2 New Attack Scenario
In our attack scenario, the side channel information will
be gained by monitoring the cache in a co-located VM. In
the same way as in [16] we assume that the adversary cap-
tures, modiﬁes, and replaces any message sent to the victim.
However, TLS sessions work in such a way that when the
protocol fails to decrypt a message, the session is closed.
This is the reason why we focus in multi-session attacks
where the same plaintext in the same place is being sent
to the victim e.g. an encrypted password sent during user
authentication.
The fact that we are working with a diﬀerent method in
a diﬀerent scenario gives us some advantages and disadvan-
tages over the previous Lucky 13 work:
Advantages:.
• Recent patches in cryptographic libraries mitigate the
old Lucky 13 attack, but are still vulnerable in the new
scenario.
• In the new scenario, no response from the server is
needed. The old Lucky 13 attack needed a response to
measure the time, which yielded a noisier environment
in TLS than DTLS.
• The new attack does not suﬀer from the network chan-
nel noise. This source of noise was painful for the mea-
surements as we can see in the original paper, where
6. EXPERIMENT SETUP AND RESULTS
In this section we present our test environment together
with our detection method in order to deal with diﬀerent
cache prefetch techniques that aﬀect our measurements. Fi-
nally we present the results of our experiments for the Po-
larSSL, GnuTLS and CyaSSL libraries.
6.1 Experiment Setup
The experiments were run on an Intel i5-650 dual core at
3.2 GHz. Our physical server includes 256 KB per core L2
cache, and a 4 MB L3 cache shared between both cores. We
used VMware ESXI 5.5.0 build number 162338 for virtual-
ization. TPS is enabled with 4 KB pages. In this setting, our
Flush+Reload technique can distinguish between L3 cache
and main memory accesses.
For the TLS connection, we use an echo server which reads
and re-sends the message that it receives, and a client com-
municating with it. Client and echo server are running in
diﬀerent virtual machines that use Ubuntu 12.04 guest OS.
We modify the echo server functionality so that it adds a
jitter in the encrypted reply message, modeling the Man
in the Middle Attack. Once the message is sent, the echo
server uses Flush+Reload to detect diﬀerent function calls
and concludes if the padding was correct or not. For the
TLS connection, we use an echo server which reads and re-
sends the message that it receives, and a client communi-
cating with it. Client and echo server are running in diﬀer-
ent virtual machines that use Ubuntu 12.04 guest OS. We
modify the echo server functionality so that it adds a jitter
in the encrypted reply message, modeling the Man in the
Middle Attack. Once the message is sent, the echo server
uses Flush+Reload to detect diﬀerent function calls and con-
cludes if the padding was correct or not.
6.2 Dealing with Cache Prefetching
Modern CPUs implement cache prefetching in a number
of ways. These techniques aﬀect our experiments, since the
monitored function can be prefetched to cache, even if it
was not executed by the victim process. To avoid false pos-
itives, it is not suﬃcient to detect if the monitored func-
tions were loaded to cache, but also for how long they have
resided in the cache. This is achieved by counting the num-
ber of subsequent detections for the given function in one
execution. Therefore, the attack process eﬀectively distin-
guishes between prefetched functions and prefetched and ex-
ecuted functions.
We use experiments to determine a threshold (which dif-
fers across the libraries) to distinguish a prefetch and execute
from a mere prefetch. For PolarSSL this threshold is based
on observing three Flush+Reload accesses in a row. Assume
that n is the number of subsequent accesses required to con-
clude that the function was executed. In the following we
present the required hits for diﬀerent libraries, i.e. the num-
ber of n-accesses required to decide whether the targeted
function was executed or not.
6.3 Attack on PolarSSL1.3.6
Our ﬁrst attack targets PolarSSL 1.3.6, with TLS 1.1. In
the ﬁrst scenario the attacker modiﬁes the last two bytes
of the encrypted message until she ﬁnds the ∆ that leads
to a 0x01|0x01 padding. Recall that 216 diﬀerent variations
can be performed in the message. The ﬁrst plot shows the
success probability of guessing the right ∆ versus L, where
Figure 5: (PolarSSL 1.3.6) Success probability of
recovering P14 and P15 vs. L, for diﬀerent number of
hits required. L refers to the number of 216 traces
needed, so the total number of messages is 216 ∗ L.
L refers to the number of 216 traces needed. For example
L = 4 means that 216 ∗ 4 messages are needed to detect the
right ∆. Based on experimental results, we set the access
threshold such that we consider a hit whenever the targeted
function gets two accesses in a row.
The measurements were performed for diﬀerent number
of required hits. Figure 5 shows that requiring a single hit
might not suﬃce since the attacker gets false positives, or
for small number of messages she may miss the access at
all. However when we require two hits, and if the attacker
has a suﬃcient number of messages (in this case L = 23),
the probability of guessing the right ∆ is comfortably close
to one. If the attacker increases the limit further to ensure
an even lower number of false positives, she will need more
messages to see the required number of hits. In the case of
3 hits, L = 24 is required to have a success probability close
to one.
Figure 6 shows the success probability of correctly recov-
ering P13, once the attacker has recovered the last two bytes.
Now the attacker is looking for the padding 0x02|0x02|0x02.
We observed a similar behavior with respect to the previous
case where with L = 8 and with a two hits requirement we
will recover the correct byte with high probability. Again if
the attacker increases the requirement to 3 hits, she will need
more measurements; about L = 16 is suﬃcient in practice.
6.4 CyaSSL 3.0.0
Recall that the attack is much more eﬀective if the at-
tacker knows any of the preceding bytes of the plaintext,
for example the last byte P15 of the plaintext. This would
be the case in a javascript/web setting where adjusting the
length of an initial HTTP request an attacker can ensure
that there is only one unknown byte in the HTTP plain-
text. In this case, the attacker would not need to try 216
possible variations but only 28 variations for each byte that
she wants to recover. This is the scenario that we analyzed
in CyaSSL TLS 1.2, where we assumed that the attacker
Figure 6: (PolarSSL 1.3.6) Success probability of re-
covering P13 assuming P14, P15 known vs L, for diﬀer-
ent number of hits required. L refers to the number
of 28 traces needed, so the total number of messages
is 28 ∗ L.
Figure 7: (CyaSSL3.0.0) Success Probability of re-
covering P14 assuming P15 known vs L, for diﬀerent
number of hits required. L refers to the number of
28 traces needed, so the total number of messages
would be 28 ∗ L.
knows P15 and she wants to recover P14. Now the attacker
is again trying to obtain a 0x01|0x01 padding, but unlike in
the previous case, she knows the ∆ to make the last byte
equal to 0x01. The implementation of CyaSSL behaves very
similarly to the one of PolarSSL, where due to the access
threshold, a one hit might lead to false positives. However,
requiring two hits with a suﬃcient number of measurements
is enough to obtain a success probability very close to one.
The threshold is set as in the previous cases, where a hit is
considered whenever we observe two Flush+Reload accesses
in a row.
6.5 GnuTLS 3.2.0
Finally we present the results conﬁrming that GnuTLS3.2.0
TLS 1.2 is also vulnerable to this kind of attack. Again, the
measurements were taken assuming that the attacker knows
the last byte P15 and she wants to recover P14, i.e., she wants
to observe the case where she injects a 0x01|0x01 padding.
However GnuTLS’s behavior shows some diﬀerences with
respect to the previous cases. For the case of GnuTLS we
ﬁnd that if we set an access threshold of three accesses in
a row (which would yield our desired hit), the probability
of getting false positives is very low. Based on experimen-
tal measurements we observed that only when the dummy
function is executed we observe such a behavior. However
the attacker needs more messages to be able to detect one of
these hits. Observing one hit indicates with high probability
that the function was called, but we also consider the two hit
case in case the attacker wants the probability of having false
positives to be even lower. Based on the measurements we
conclude that the attacker recovers the plaintext with very
high probability, so we did not ﬁnd it necessary to consider
the three hit case.
Figure 8: (GnuTLS3.2.0) Success Probability of re-
covering P14 assuming P15 known vs. L, for diﬀerent