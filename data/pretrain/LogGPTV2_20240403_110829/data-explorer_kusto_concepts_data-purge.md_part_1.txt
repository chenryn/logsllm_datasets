---
title: Data purge - Azure Data Explorer
description: This article describes Data purge in Azure Data Explorer.
ms.reviewer: kedamari
ms.topic: reference
ms.date: 07/03/2022
---
# Data purge
[!INCLUDE [gdpr-intro-sentence](../../includes/gdpr-intro-sentence.md)]
As a data platform, Azure Data Explorer supports the ability to delete individual records, by using Kusto `.purge` and related commands. You can also [purge an entire table](#purging-an-entire-table) or purge records in a [materialized view](../management/materialized-views/materialized-view-purge.md).
> [!WARNING]
> Data deletion through the `.purge` command is designed to be used to protect personal data and should not be used in other scenarios. It is not designed to support frequent delete requests, or deletion of massive quantities of data, and may have a significant performance impact on the service.
## Purge guidelines
Carefully design your data schema and investigate relevant policies before storing personal data in Azure Data Explorer.
1. In a best-case scenario, the retention period on this data is sufficiently short and data is automatically deleted.
1. If retention period usage isn't possible, isolate all data that is subject to privacy rules in a few Azure Data Explorer tables. Optimally, use just one table and link to it from all other tables. This isolation allows you to run the data [purge process](#purge-process) on a few tables holding sensitive data, and avoid all other tables.
1. The caller should make every attempt to batch the execution of `.purge` commands to 1-2 commands per table per day. Don't issue multiple commands with unique user identity predicates. Instead, send a single command whose predicate includes all user identities that require purging.
## Purge process
The process of selectively purging data from Azure Data Explorer happens in the following steps:
1. Phase 1:
   Give an input with an Azure Data Explorer table name and a per-record predicate, indicating which records to delete. Kusto scans the table looking to identify data extents that would participate in the data purge. The extents identified are those having one or more records for which the predicate returns true.
1. Phase 2: (Soft Delete)
   Replace each data extent in the table (identified in step (1)) with a reingested version. The reingested version shouldn't have the records for which the predicate returns true. If new data isn't being ingested into the table, then by the end of this phase, queries will no longer return data for which the predicate returns true. The duration of the purge soft delete phase depends on the following parameters:
    * The number of records that must be purged
    * Record distribution across the data extents in the cluster
    * The number of nodes in the cluster
    * The spare capacity it has for purge operations
    * Several other factors
    The duration of phase 2 can vary between a few seconds to many hours.
1. Phase 3: (Hard Delete)
   Work back all storage artifacts that may have the "poison" data, and delete them from storage. This phase is done at least five days after the completion of the previous phase, but no longer than 30 days after the initial command. These timelines are set to follow data privacy requirements.
Issuing a `.purge` command triggers this process, which takes a few days to complete. If the density of records for which the predicate applies is sufficiently large, the process will effectively reingest all the data in the table. This reingestion has a significant impact on performance and COGS (cost of goods sold).
## Purge limitations and considerations
* The purge process is final and irreversible. It isn't possible to undo this process or recover data that has been purged. Commands such as [undo table drop](../management/undo-drop-table-command.md) can't recover purged data. Rollback of the data to a previous version can't go to before the latest purge command.
* Before running the purge, verify the predicate by running a query and checking that the results match the expected outcome. You can also use the two-step process that returns the expected number of records that will be purged.
* The `.purge` command is executed against the Data Management endpoint:
  `https://ingest-[YourClusterName].[region].kusto.windows.net`.
   The command requires [database admin](../management/access-control/role-based-access-control.md)
   permissions on the relevant databases.
* Due to the purge process performance impact, and to guarantee that
   [purge guidelines](#purge-guidelines) have been followed, the caller is expected to modify the data schema so that
   minimal tables include relevant data, and batch commands per table to reduce the significant COGS impact of the
   purge process.
* The `predicate` parameter of the [.purge](#purge-table-tablename-records-command) command is used to specify which records to purge.
`Predicate` size is limited to 1 MB. When constructing the `predicate`:
  * Use the ['in' operator](../query/in-operator.md), for example, `where [ColumnName] in ('Id1', 'Id2', .. , 'Id1000')`.
  * Note the limits of the ['in' operator](../query/in-operator.md) (list can contain up to `1,000,000` values).
  * If the query size is large, use [`externaldata` operator](../query/externaldata-operator.md), for example `where UserId in (externaldata(UserId:string) ["https://...blob.core.windows.net/path/to/file?..."])`. The file stores the list of IDs to purge.
  * The total query size, after expanding all `externaldata` blobs (total size of all blobs), can't exceed 64 MB.
## Purge performance
Only one purge request can be executed on the cluster, at any given time. All other requests are queued in `Scheduled` state.
Monitor the purge request queue size, and keep within adequate limits to match the requirements applicable for your data.
To reduce purge execution time:
* Follow the [purge guidelines](#purge-guidelines) to decrease the amount of purged data.
* Adjust the [caching policy](../management/cache-policy.md) since purge takes longer on cold data.
* Scale out the cluster
* Increase cluster purge capacity, after careful consideration, as detailed in [Extents purge rebuild capacity](../management/capacity-policy.md#extents-purge-rebuild-capacity).
## Trigger the purge process
> [!NOTE]
> Purge execution is invoked by running [purge table *TableName* records](#purge-table-tablename-records-command) command on the Data Management endpoint https://ingest-[YourClusterName].[Region].kusto.windows.net.
### Purge table *TableName* records command
Purge command may be invoked in two ways for differing usage scenarios:
* Programmatic invocation: A single step that is intended to be invoked by applications. Calling this command directly triggers purge execution sequence.
  **Syntax**
  ```kusto
  // Connect to the Data Management service
  #connect "https://ingest-[YourClusterName].[region].kusto.windows.net"
  // To purge table records
  .purge table [TableName] records in database [DatabaseName] with (noregrets='true')  [!NOTE]
 > The first step in the two-step invocation requires running a query on the entire dataset, to identify records to be purged.
 > This query may time-out or fail on large tables, especially with significant amount of cold cache data. In case of failures,
 > validate the predicate yourself and after verifying correctness use the single-step purge with the `noregrets` option.
**Syntax**
> [!NOTE]
> To connect to a cluster using the Azure Data Explorer web UI, see [Add clusters](../../web-query-data.md#add-clusters).
  ```kusto
     // Connect to the Data Management service - this command only works in Kusto.Explorer
     #connect "https://ingest-[YourClusterName].[region].kusto.windows.net"
     // Step #1 - retrieve a verification token (no records will be purged until step #2 is executed)
     .purge table [TableName] records in database [DatabaseName] ')  [!NOTE]
> This operation is intended for error recovery scenarios. It isn't guaranteed to succeed, and shouldn't be part of a normal operational flow. It can only be applied to requests that are still in the queue and have not yet been dispatched for execution.