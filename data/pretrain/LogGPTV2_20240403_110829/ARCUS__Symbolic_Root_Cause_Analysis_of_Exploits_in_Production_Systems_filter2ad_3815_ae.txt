to ﬁnd this new CVE because it considers all data ﬂows over
the executed path.
Vulnerabilities Cascading Into 0-Days. An interesting ex-
ample in autotrace demonstrates how a patch can address
one bug, but fail to ﬁx related “downstream” bugs, which
gives ARCUS the opportunity to uncover new vulnerabilities.
Version 0.31.1 contains a UAF vulnerability exploitable via
a malformed input bitmap image header (CVE-2017-9182).
Ultimately, ARCUS discovers two additional downstream
vulnerabilities: an integer overﬂow (CVE-2019-19004) and a
double free (CVE-2019-19005).
They all stem from a lack of input ﬁle validation. When
the value of the bits_per_pixel ﬁeld of the image header is
invalid, after the known UAF, a previously unreported integer
overﬂow can occur as autotrace attempts to calculate the
number of bytes per row in the input_bmp_reader function.
ARCUS then discovers an additional double free that releases
the same freed buffer the UAF accesses. In short, all 3 vulner-
abilities are triggered by the same malformed header ﬁeld, but
each resides in a different code block, meaning a developer
ﬁxing one may overlook the others.
Vulnerabilities Over Large Distances. Version 0.15 of the
program PDFResurrect has a buffer overﬂow vulnerability
(CVE-2019-14267) that can be exploited via a malformed
PDF to achieve arbitrary code execution. When the function
encounters a ‘%%EOF’ in the PDF, it scans backwards looking
for an ‘f’ character, which is supposed to represent the end of
‘startxref’. As it scans, a register representing pos_count
is incremented. An attacker can create a malformed PDF
without a ‘startxref,’ causing pos_count to exceed 256
11Post evaluation, we discovered that this vulnerability had been described
in a previous bug report, however it was never issued a CVE ID and so we
were unaware of it while evaluating ARCUS. Consequently, we were the ﬁrst
to report it to a CVE authority, resulting in the issuance of CVE-2019-17582.
USENIX Association
30th USENIX Security Symposium    1999
Figure 6: Performance overhead and storage size of tracing the SPEC CPU benchmark. The average overhead is 7.21% and the
geometric mean is 3.81%. The average trace size is 110 MB and the geometric mean is 38.2 MB.
Robustness. Recommendations made by ARCUS are based
on constraints built from a single execution path, meaning
completeness cannot be guaranteed. Human developers are
expected to implement the ofﬁcial patch using ARCUS’s rec-
ommendation as a starting point. Like most solutions that
incorporate symbolic analysis, ARCUS is not well suited to
building constraints within cryptography procedures, making
the current prototype poorly suited for handling bugs within
libraries like OpenSSL (e.g., CVE-2010-2939). However,
this does not prevent ARCUS from analyzing programs that
import such libraries — because the APIs can be modeled —
and there are tailored analysis techniques [83] that ARCUS
can adopt in future work. Similarly, we do not expect the
current ARCUS prototype to perform well on heavily obfus-
cated binaries or virtual machines (e.g., JVM). The kernel
module can trace programs that dynamically generate code,
including just-in-time (JIT) compilation, however additional
API modeling is required for angr to support web browsers.
Conversely, ARCUS already successfully handles some com-
plex programs (e.g., GIMP, 810,000 source lines of C/C++),
demonstrating potential for future improvement.
Cross-Platform Support. The current implementation of
ARCUS is for x86-64 Linux, but with engineering effort it
can support other platforms. Currently, the analysis uses VEX
IR semantics, which is machine independent, and angr can
lift several hardware architectures. Our “what-if” approach is
also machine independent. The integer overﬂow module lever-
ages some x86-speciﬁc semantics to help infer signedness,
but it also contains general techniques and can be extended in
future work. The memory allocation and format string mod-
ules require the semantics for allocation and format string
functions (e.g., printf, malloc). The current prototype sup-
ports typical libraries like libc and jemalloc and prior work
proposes techniques for custom functions [84], which can be
incorporated in future work.
The largest task is the tracing functionality, which requires
an OS module. Although Windows® 10 has an Intel PT
driver for tracing applications [85], it is not intended for third-
party use and Microsoft® has not released any documentation.
While it would be easy for Microsoft to implement ARCUS
for Windows, for anyone else, it would require reverse engi-
Figure 7: Performance overhead and storage required to trace
Nginx. The performance overhead is under 2% and the maxi-
mum storage is 1.6 MB per request.
and overﬂow buf. This bug can be exploited to overwrite the
stack and achieve arbitrary code execution.
What is interesting about this example is the vulnerable
function loads all cross references before returning, any one
of which could trigger the described overﬂow. This means
thousands of references can be loaded between the corruption
point and the return that starts the arbitrary code execution. In
our crafted exploit, this distance is over 83,000 basic blocks
(see Table 4) and includes almost 17,000 function calls. AR-
CUS successfully identiﬁes the root cause of the vulnerability
despite this distance.
5 Discussion & Limitations
False Negatives & Positives. Prior work enumerates the
possible sources of error in symbolic analysis [81], which
are not special to ARCUS. ARCUS is a root cause analysis
framework invoked in response to an end-host monitor’s alert,
so it depends on the monitor detecting an attack symptom [82].
As described in Subsection 3.3, some of the modules imple-
mented in ARCUS can incur false negatives.
Only the integer overﬂow module can yield false positives
due to its combination of forward analysis and heuristics. The
sole case we have encountered occurs in libpng, where an
overﬂowed value is passed to another function, triggering a de-
tection by ARCUS, but then the receiving function performs
additional checks, preventing exploitation. Such patterns of
checking for overﬂows in the receiving function (as opposed
to the sending) are atypical [58].
2000    30th USENIX Security Symposium
USENIX Association
neering Microsoft’s driver [86].
6 Related Work
6.1 Symbolic Execution
The earliest work in symbolic execution demonstrated how ex-
ecuting with symbolic variables can aid in testing and debug-
ging code [87]. As solvers became more efﬁcient, literature
emerged for how to use symbolic execution to replay pro-
tocols [88] and detect vulnerabilities [89]–[92]. Symbolic
execution was also applied to side-channel research [93],
ﬁrmware analysis [94], correctness of cryptography soft-
ware [95], emulator testing [96] and automatic binary patch-
ing [97].
Much of this work focused on a subset of symbolic analysis
called concolic execution. Rather than performing pure static
analysis, which can get stuck on loops and string parsing,
concolic systems leverage real executions for guidance [98]–
[100], exploring outwards from the concrete executions to
examine as many paths as possible [80], [101]. However, this
can lead to state explosion, especially as the analysis deviates
further from the concrete execution. This led to hybrid ap-
proaches [102], [103], which alternate between fuzzing and
symbolic exploration to manage state explosion.
A less explored direction is single path concolic execu-
tion, which has proven useful in automatically generating
exploits [101], [104], [105] and reverse engineering. The
advantage of single path is it sidesteps the issue of state ex-
plosion, but it also relies heavily on receiving concrete exe-
cutions that cover interesting program behaviors. ARCUS
distinguishes itself by providing concise root causes using
execution traces without needing concrete inputs.
6.2 Root Cause & Crash Dump Analysis
One of the earliest techniques for root cause analysis, delta
debugging [106], [107], compares program states between
successful and failing inputs to narrow down the set of rele-
vant variables. Another popular approach is to use program
slicing to extract only the code that contributes to the fail-
ure condition [108]. Delta debugging struggles to generate
enough inputs in both classes to be effective while the latter
requires tainting or lightweight replay to keep slices small.
Some failure sketching systems handle security bugs like
overﬂows [109], but most focus on race conditions because
they are harder to reproduce [110]. Although races have
serious security implications, they are not the only class hin-
dering modern programs. There is also work on application
layer root cause, including analysis of browser warnings and
websites, trace-based pinpointing of insecure keys, and bug
ﬁnding using written reports, which is orthogonal to ARCUS.
Another direction is crash dump analysis [111], which aims
to locate the cause of software crashes. However, while our
motivations overlap, our assumptions and scope do not. Crash
dump analysis assumes bugs will manifest into crashes, but
ARCUS can detect non-crashing exploits. Crash dumps yield
partial stack and memory info whereas we have PT traces and
snapshots. Data in crash dumps can be corrupt whereas the
integrity of PT is protected by the kernel. These factors make
our technical challenges signiﬁcantly different.
7 Conclusion
This work presents ARCUS, a system for performing concise
root cause analysis over traces ﬂagged by end-host runtime
monitors in production systems. Using a novel “what if”
approach, ARCUS automatically pinpoints a concise root
cause and recommends new constraints that demonstrably
block uncovered vulnerabilities, enabling system administra-
tors to better inform developers about the issue. Leveraging
hardware-supported PT, ARCUS decouples the cost of analy-
sis from end-host performance.
We demonstrate that our approach can construct symbolic
program states and analyze several classes of serious and
prevalent software vulnerabilities. Our evaluation against 27
vulnerabilities and over 9,000 Juliet and RIPE test cases shows
ARCUS can automatically identify the root cause of all tested
exploits, uncovering 4 new vulnerabilities in the process,
with 0 false positives and negatives. ARCUS incurs a 7.21%
performance overhead on the SPEC 2006 CPU benchmark
and scales to large programs compiled from over 810,000
lines of C/C++ code.
Acknowledgments
We thank the anonymous reviewers for their helpful and infor-
mative feedback. This material was supported in part by the
Ofﬁce of Naval Research (ONR) under grants N00014-19-1-
2179, N00014-17-1-2895, N00014-15-1-2162, and N00014-
18-1-2662, and the Defense Advanced Research Projects
Agency (DARPA) under contract HR00112090031. Any opin-
ions, ﬁndings, conclusions, or recommendations expressed in
this material are those of the authors and do not necessarily
reﬂect the views of ONR or DARPA.
References
[1] H. Hu, C. Qian, C. Yagemann, S. P. H. Chung, W.
Harris, T. Kim, and W. Lee, “Enforcing unique code
target property for control-ﬂow integrity,” in Pro-
ceedings of the 25th ACM Conference on Computer
and Communications Security (CCS), Toronto, ON,
Canada, Oct. 2018.
USENIX Association
30th USENIX Security Symposium    2001
[2] X. Ge, W. Cui, and T. Jaeger, “Grifﬁn: Guarding
control ﬂows using intel processor trace,” in Proceed-
ings of the 22nd ACM International Conference on
Architectural Support for Programming Languages
and Operating Systems (ASPLOS), Xi’an, China, Apr.
2017.
[3] M. Khandaker, A. Naser, W. Liu, Z. Wang, Y. Zhou,
and Y. Cheng, “Adaptive call-site sensitive control
ﬂow integrity,” in 2019 IEEE European Symposium
on Security and Privacy (EuroS&P), IEEE, 2019,
pp. 95–110.
[4] W. He, S. Das, W. Zhang, and Y. Liu, “Bbb-cﬁ:
Lightweight cﬁ approach against code-reuse attacks
using basic block information,” ACM Transactions
on Embedded Computing Systems (TECS), vol. 19,
no. 1, pp. 1–22, 2020.
[5] A. J. Mashtizadeh, A. Bittau, D. Boneh, and D. Maz-
ières, “Ccﬁ: Cryptographically enforced control ﬂow
integrity,” in Proceedings of the 22nd ACM SIGSAC
Conference on Computer and Communications Secu-
rity, 2015, pp. 941–951.
[6] M. Zhang and R. Sekar, “Control ﬂow integrity for
cots binaries,” in 22nd USENIX Security Symposium
(USENIX Security 13), 2013, pp. 337–352.
[7] L. Feng, J. Huang, J. Hu, and A. Reddy, “Fastcﬁ:
Real-time control ﬂow integrity using fpga without
code instrumentation,” in International Conference
on Runtime Veriﬁcation, Springer, 2019, pp. 221–
238.
[8] B. Niu and G. Tan, “Modular control-ﬂow integrity,”
in Proceedings of the 35th ACM SIGPLAN Confer-
ence on Programming Language Design and Imple-
mentation, 2014, pp. 577–587.
[9] Y. Gu, Q. Zhao, Y. Zhang, and Z. Lin, “Pt-cﬁ: Trans-
parent backward-edge control ﬂow violation detection
using intel processor trace,” in Proceedings of the Sev-
enth ACM on Conference on Data and Application
Security and Privacy, 2017, pp. 173–184.
[10] B. Niu and G. Tan, “Rockjit: Securing just-in-time
compilation using modular control-ﬂow integrity,” in
Proceedings of the 2014 ACM SIGSAC Conference
on Computer and Communications Security, 2014,
pp. 1317–1328.
[11] S. Forrest, S. Hofmeyr, and A. Somayaji, “The evolu-
tion of system-call monitoring,” in 2008 Annual Com-
puter Security Applications Conference (ACSAC),
IEEE, 2008, pp. 418–430.
[12] D. Sehr, R. Muth, C. L. Bifﬂe, V. Khimenko, E. Pasko,
B. Yee, K. Schimpf, and B. Chen, “Adapting soft-
ware fault isolation to contemporary cpu architec-
tures,” 2010.
[14]
[13] R. Wahbe, S. Lucco, T. E. Anderson, and S. L. Gra-
ham, “Efﬁcient software-based fault isolation,” in
Proceedings of the fourteenth ACM symposium on
Operating systems principles, 1993, pp. 203–216.
J. Ansel, P. Marchenko, Ú. Erlingsson, E. Taylor,
B. Chen, D. L. Schuff, D. Sehr, C. L. Bifﬂe, and B.
Yee, “Language-independent sandboxing of just-in-
time compilation and self-modifying code,” in Pro-
ceedings of the 32nd ACM SIGPLAN conference on
Programming language design and implementation,
2011, pp. 355–366.
J. A. Kroll, G. Stewart, and A. W. Appel, “Portable
software fault isolation,” in 2014 IEEE 27th Com-
puter Security Foundations Symposium, IEEE, 2014,
pp. 18–32.
[15]
[16] B. Patel, Intel Releases New Technology Speciﬁ-
cations to Protect Against ROP attacks, https :
/ / software . intel . com / content / www / us /
en / develop / blogs / intel - release - new -
technology - specifications - protect - rop -
attacks.html, [Online; accessed 26-June-2020].
[17] Control Flow Guard, https://docs.microsoft.
com / en - us / windows / win32 / secbp / control -
flow-guard, [Online; accessed 26-June-2020].
[18] M. Costa, J. Crowcroft, M. Castro, A. Rowstron, L.
Zhou, L. Zhang, and P. Barham, “Vigilante: End-to-
end containment of internet worms,” in Proceedings
of the twentieth ACM symposium on Operating sys-
tems principles, 2005, pp. 133–147.
[19] D. Brumley, J. Newsome, D. Song, H. Wang, and S.
Jha, “Towards automatic generation of vulnerability-
based signatures,” in 2006 IEEE Symposium on Secu-
rity and Privacy (S&P’06), IEEE, 2006.
J. Newsome, D. Brumley, D. Song, J. Chamcham, and
X. Kovah, “Vulnerability-speciﬁc execution ﬁltering
for exploit prevention on commodity software.,” in
NDSS, 2006.
[20]
[21] A. Slowinska and H. Bos, “The age of data: Pinpoint-
ing guilty bytes in polymorphic buffer overﬂows on
heap or stack,” in Twenty-Third Annual Computer Se-
curity Applications Conference (ACSAC 2007), IEEE,
2007, pp. 487–500.
[22] K. Bhat, E. Van Der Kouwe, H. Bos, and C. Giuffrida,
“Probeguard: Mitigating probing attacks through re-
active program transformations,” in Proceedings of
the Twenty-Fourth International Conference on Ar-
chitectural Support for Programming Languages and
Operating Systems, 2019, pp. 545–558.
2002    30th USENIX Security Symposium
USENIX Association
[23] Y. Kwon, B. Saltaformaggio, I. L. Kim, K. H. Lee,
X. Zhang, and D. Xu, “A2c: Self destructing ex-
ploit executions via input perturbation,” in Network
and Distributed Systems Security (NDSS) Symposium
2017, 2017.
[24] R. Ding, H. Hu, W. Xu, and T. Kim, “Desensitization:
Privacy-aware and attack-preserving crash report,” in
Network and Distributed Systems Security (NDSS)
Symposium 2020, 2020.
[25] F. Capobianco, R. George, K. Huang, T. Jaeger, S.
Krishnamurthy, Z. Qian, M. Payer, and P. Yu, “Em-
ploying Attack Graphs for Intrusion Detection,” in
New Security Paradigms Workshop, ser. NSPW’19,
2019.
[26] S. Forrest, S. A. Hofmeyr, A. Somayaji, and T. A.
Longstaff, “A sense of self for unix processes,” in
Proceedings 1996 IEEE Symposium on Security and
Privacy, 1996, pp. 120–128. DOI: 10.1109/SECPRI.
1996.502675.
[27] W. U. Hassan, S. Guo, D. Li, Z. Chen, K. Jee, Z.
Li, and A. Bates, “Nodoze: Combatting threat alert
fatigue with automated provenance triage,” in 26th
ISOC Network and Distributed System Security Sym-
posium, ser. NDSS’19, 2019.
[28] X. Han, T. Pasqueir, A. Bates, J. Mickens, and M.
Seltzer, “Unicorn: Runtime provenance-based de-
tector for advanced persistent threats,” in 27th ISOC
Network and Distributed System Security Symposium,
ser. NDSS’20, 2020.
[29] S. T. King, Z. M. Mao, D. G. Lucchetti, and P. M.
Chen, “Enriching intrusion alerts through multi-host
causality.,” in Proceedings of the 12th ISOC Net-
work and Distributed System Security Symposium,
ser. NDSS’05, 2005.
[30] S. M. Milajerdi, R. Gjomemo, B. Eshete, R. Sekar,
and V. Venkatakrishnan, “Holmes: Real-time apt de-
tection through correlation of suspicious information
ﬂows,” in 2019 IEEE Symposium on Security and
Privacy, Los Alamitos, CA, USA: IEEE Computer
Society, 2019.
[31] X. Shu, D. ( Yao, N. Ramakrishnan, and T. Jaeger,
“Long-span program behavior modeling and attack de-
tection,” ACM Transactions on Privacy and Security,
vol. 20, 2017.
[32] A. Wespi, M. Dacier, and H. Debar, “Intrusion de-
tection using variable-length audit trail patterns,” in
Recent Advances in Intrusion Detection, Springer,
2000, pp. 110–129.
[33] C. Warrender, S. Forrest, and B. Pearlmutter, “De-
tecting intrusions using system calls: Alternative data