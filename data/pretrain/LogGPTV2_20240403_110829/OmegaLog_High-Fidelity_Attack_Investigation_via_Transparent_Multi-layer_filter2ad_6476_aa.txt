title:OmegaLog: High-Fidelity Attack Investigation via Transparent Multi-layer
Log Analysis
author:Wajih Ul Hassan and
Mohammad A. Noureddine and
Pubali Datta and
Adam Bates
OmegaLog: High-Fidelity Attack Investigation via
Transparent Multi-layer Log Analysis
Wajih Ul Hassan, Mohammad A. Noureddine, Pubali Datta, Adam Bates
University of Illinois at Urbana-Champaign
{whassan3, nouredd2, pdatta2, batesa}@illinois.edu
Abstract—Recent advances in causality analysis have en-
abled investigators to trace multi-stage attacks using provenance
graphs. Based on system-layer audit logs (e.g., syscalls), these
approaches omit vital sources of application context (e.g., email
addresses, HTTP response codes) that can be found in higher
layers of the system. Although such information is often essential
to understanding attack behaviors, it is difﬁcult to incorporate
this evidence into causal analysis engines because of the semantic
gap that exists between system layers. To address that short-
coming, we propose the notion of universal provenance, which
encodes all forensically relevant causal dependencies regardless
of their layer of origin. To transparently realize that vision
on commodity systems, we present OmegaLog, a provenance
tracker that bridges the semantic gap between system and appli-
cation logging contexts. OmegaLog analyzes program binaries to
identify and model application-layer logging behaviors, enabling
accurate reconciliation of application events with system-layer
accesses. OmegaLog then intercepts applications’ runtime logging
activities and grafts those events onto the system-layer provenance
graph, allowing investigators to reason more precisely about the
nature of attacks. We demonstrate that our system is widely
applicable to existing software projects and can transparently
facilitate execution partitioning of provenance graphs without
any training or developer intervention. Evaluation on real-world
attack scenarios shows that our technique generates concise
provenance graphs with rich semantic information relative to
the state-of-the-art, with an average runtime overhead of 4%.
I.
INTRODUCTION
System intrusions are becoming progressively more subtle
and complex. Using an approach exempliﬁed by the “low and
slow” attack strategy of Advanced Persistent Threats, attackers
now lurk in target systems for extended periods to extend their
reach before initiating devastating attacks. By avoiding actions
that would immediately arouse suspicion, attackers can achieve
dwell times that range from weeks to months, as was the case
in numerous high-proﬁle data breaches including Target [14],
Equifax [12], and the Ofﬁce of Personnel Management [13].
Against such odds, advancements in system auditing have
proven invaluable in detecting, investigating, and ultimately
responding to threats. The notion of data provenance has been
applied to great effect on traditional system audit logs, parsing
individual system events into provenance graphs that encode
the history of a system’s execution [17], [26], [51], [32], [36],
Network and Distributed Systems Security (NDSS) Symposium 2020
23-26 February 2020, San Diego, CA, USA
ISBN 1-891562-61-4
https://dx.doi.org/10.14722/ndss.2020.24270
www.ndss-symposium.org
[40], [31]. Such provenance graphs allow investigators to trace
the root causes and ramiﬁcations of an attack by using causality
analysis. Leveraging this principal capability, causality analysis
has matured from a costly ofﬂine investigation tool to a highly-
efﬁcient method of tracing attackers in real-time [31], [16].
Given the importance of threat
investigation to system
defense, it is perhaps surprising that prior work on causality
analysis has been oblivious to application-layer semantics.
As an example, consider the execution of the web service
shown in Fig. 1. Fig. 1(a) describes the event sequence of the
example, in which the server responds to two HTTP requests
for index.html and form.html, respectively, yielding the
system log shown in Fig. 1(b). As a normal part of its
execution, the server also maintains its own event logs that
contain additional information (e.g., user-agent strings) shown
in Fig. 1(c), that is opaque to the system layer. State-of-the-art
causality analysis engines, using system audit logs, produce a
provenance graph similar to Fig. 1(d); however, the forensic
evidence disclosed by the application itself is not encoded in
this graph. That is unfortunate, as recent studies [25], [21], [49]
have shown that developers explicitly disclose the occurrence
of important events through application logging. Further, we
observe that the well-studied problem of dependency explosion
[39], [42], [41], which considers the difﬁculty of tracing
dependencies through high-fanout processes, is itself a result of
unknown application semantics. For example, the dependency
graph in Fig. 1 (d) is not aware that the NGINX vertex can
be subdivided into two autonomous units of work, marked by
the two HTTP requests found in the application event log.
Prior work on log analysis has not provided a generic
and reliable (i.e., causality-based) solution to cross-layer at-
tack investigation. Techniques for execution partitioning miti-
gate dependency explosion by identifying limited and coarse-
grained application states, e.g., when a program starts its
main event-handling loop [39], but require invasive instru-
mentation [39], [41] or error-prone training [39], [40], [42].
Past frameworks for layered provenance tracking [57], [28],
[17], [47] technically support application semantics, but rather
than harness the developer’s original event logs, instead call
for costly (and redundant!) instrumentation efforts. Elsewhere
in the literature, application event logs have been leveraged
for program debugging [24], [59], [60], proﬁling [65], [64],
and runtime monitoring [48]; however, these approaches are
application-centric, considering only one application’s siloed
event logs at a time, and thus cannot reconstruct complex
workﬂows between multiple processes. Attempts to “stitch”
application logs together to trace multi-application workﬂows
[50], [65], [64] commonly ignore the system layer, but also
Fig. 1: NGINX application execution while two different HTTP requests are being served. (a) Actual execution behavior of NGINX. (b)
System logs generated by whole-system provenance tracker. (c) Application event logs generated by NGINX. (d) Provenance graph generated
using system logs by traditional solutions.
use ad hoc rules and co-occurrence of log events to assume a
causal relationship; this assumption introduces error and could
potentially undermine threat investigations.
In this work, we argue that attack investigation capabilities
can be dramatically improved through the uniﬁcation of all
forensically relevant events on the system in a single holistic
log. To achieve that vision transparently and effortlessly on
today’s commodity systems, we present OmegaLog, an end-
to-end provenance tracker that merges application event logs
with the system log to generate a universal provenance graph
(UPG). This graph combines the causal reasoning strengths
of whole-system logging with the rich semantic context of
application event
the UPG, OmegaLog
automatically parses dispersed, intertwined, and heterogeneous
application event log messages at runtime and associates each
record with the appropriate abstractions in the whole-system
provenance graph. Generating UPG allows OmegaLog to trans-
parently solve both the dependency explosion problem (by
identifying event-handling loops through the application event
sequences) and the semantic gap problem (by grafting applica-
tion event logs onto the whole-system provenance graph). Most
excitingly, OmegaLog does not require any instrumentation on
the applications or underlying system.
logs. To construct
Several challenges exist
in the design of a universal
provenance collection system. First, the ecosystem of software
logging frameworks is heterogeneous, and event logging is
fundamentally similar to any other ﬁle I/O, making it difﬁcult
to automatically identify application logging activity. Second,
event logs are regularly multiplexed across multiple threads in
an application, making it difﬁcult to differentiate concurrent
units of work. Finally, each unit of work in an application will
generate log events whose occurrence and ordering vary based
on the dynamic control ﬂow, requiring a deep understanding
of the application’s logging behavior to identify meaningful
boundaries for execution unit partitioning.
To solve those challenges, OmegaLog performs static
analysis on application binaries to automatically identify log
message writing procedures, using symbolic execution and em-
ulation to extract descriptive Log Message Strings (LMS) for
each of the call sites. Then, OmegaLog performs control ﬂow
analysis on the binary to identify the temporal relationships
between LMSes, generating a set of all valid LMS control ﬂow
paths that may occur during execution. At runtime, OmegaLog
then uses a kernel module that intercepts write syscall and
catches all log events emitted by the application, associating
each event with the correct PID/TID and timestamp to de-
tangle concurrent logging activity. Finally, those augmented
application event logs are merged with system-level logs into
a uniﬁed universal provenance log. Upon attack investigation,
OmegaLog is able to use the LMS control ﬂow paths to parse
the ﬂattened stream of application events in the universal log,
partition them into execution units, and ﬁnally add them as
vertices within the whole-system provenance graph in causally
correct manner.
The main contributions of this paper are as follows:
(cid:63) We propose the concept of the universal provenance that
combines the advantages of whole-system provenance with
applications’ innate event-logging activity, providing a trans-
parent and generic solution for the semantic gap problem in
threat investigations.
(cid:63) We develop robust binary analysis techniques to auto-
matically extract
logging behaviors from an application.
Our proof-of-concept
implementation, OmegaLog, non-
intrusively collects and integrates applications’ event logs
with the Linux audit logs [5].
(cid:63) We evaluate OmegaLog for performance, accuracy, and
efﬁcacy. Our results indicate that OmegaLog exhibits low
runtime overheads (4%), is broadly deployable to existing
software projects, and enables semantically rich attack re-
constructions in real-world attack scenarios.
II. MOTIVATION
In this section, we explain the motivation for our approach
by considering a data exﬁltration and defacement attack on
an online shopping website. We use this example to illustrate
the limitations of existing provenance tracking systems [17],
[42], [41], [16], [36], [37], [38]. Consider a simple WordPress
website hosted on a web server. Requests to the website are
ﬁrst received by an HAProxy, which balances load across
different Apache instances running on the web server, while
customer transactions are recorded in a PostgreSQL database.
The administrator has turned on application event logging for
Apache httpd, HAProxy, and PostgreSQL. In addition, the
server is performing system-level logging, e.g., through Linux
Audit (auditd) [5] or Linux Provenance Modules (LPM) [17],
which continuously collect system logs. One day, the adminis-
trator discovers that the online store has been defaced and that
some of the sensitive customer information has been posted to
a public Pastebin website. On average, the shopping website
2
- Receives HTTP request- Reads index.html- Sends HTTP- Logs event in access.log- Receives HTTP request- Reads form.html- Sends HTTP- Logs event in access.log1. Socket_Read(“10.0.0.1”)2. FRead(index.html)3. Socket_Write(“10.0.0.1”)4. FWrite(access.log)5. Socket_Read(“10.0.8.1”)6. FRead(form.html)7. Socket_Write(“10.0.8.1”)8. FWrite(access.log)Nginxindex.html/var/log/nginx/access.logform.html10.0.0.110.0.0.110.0.8.110.0.8.11. [16/Apr/2019:20:21:56 +0100] "GET /index.html HTTP/1.1" 200 3804 "-" "Mozilla/5.0 (Windows NT 6.0; WOW64; rv:45.0) Gecko/20100101 Firefox/45.0"2. [16/Apr/2019:20:21:56 +0100] "GET /form.html HTTP/1.1" 200 3804 "-" "Mozilla/5.0 (Windows NT 6.0; WOW64; rv:45.0) Gecko/20100101 Firefox/45.0"(a) Execution(b) System Log(c) Application Log(d) System Provenance GraphFig. 2: A whole-system provenance graph showing the SQL injection attack scenario. Diamond, box, and oval vertices represent network
connections, processes, and ﬁles, respectively. This graph suffers from both dependency explosion and semantic gap problems, frustrating
attack investigation.
receives tens of thousands of requests per day; among those,
one request was malicious.
TABLE I: Comparison of execution partitioning techniques to solve
the dependency explosion problem.
A. Investigating with Application Event Logs
To attribute the attack and prepare an appropriate response,
the administrator initiates a forensic inquiry by ﬁrst inspecting
the application event logs. The administrator ﬁnds that the
accounts database table must have been accessed and uses
this as a symptom to initiate attack investigations. The admin
then runs a grep query on PostgreSQL event logs, which
returns the following query log message:
SELECT * FROM users WHERE user_id=123 UNION SELECT
password FROM accounts;
This log message strongly indicates that an attacker ex-
ploited a SQL injection vulnerability in the website, and
also suggests that the attacker was able to retrieve the login
credentials for admin.php which gave attacker privileged site
access.
Limitations of Application Event Logs. At this point, the
administrator is unable to proceed in the investigation using
application event logs alone. It is clear that the HAProxy
and Apache httpd logs contain important evidence such as the
HTTP requests associated with the SQL injection attack, but
re-running of the same grep query on Apache’s logs did not
return any result. The reason is that the attacker used a POST
command to send the SQL query and that command was not
contained in the URL captured in the Apache httpd event log
messages. The investigation has stalled with important ques-
tions left unanswered: 1) What was the IP address associated
with the malicious HTTP request? 2) How were the login
credentials used to deface the website, and what additional
damage was caused? 3) Which PHP ﬁle on the site is not
properly sanitizing user inputs, exposing the SQL injection
vulnerability? Those questions reﬂect an inherent limitation of
application event logs: they cannot causally relate events across
applications and thus cannot trace workﬂow dependencies.
B. Investigating with System Logs
To proceed, the administrator attempts to perform causality
analysis using a whole-system provenance graph. At
this
layer, it is easy to trace dependencies across multiple coor-
dinated processes in a workﬂow. Because the malicious query
shown above resulted in a read to the PostgreSQL database,
the administrator uses /usr/local/db/datafile.db as a
symptom event and issues a backtrace query, yielding the
BEEP [39] MPI MCI WinLog OmegaLog
ProTracer [42]
[38]
No
Yes
Yes
[41]
Yes
No
Yes
Fine Coarse Coarse
No
[40]
No
No
Yes
No
No
No
Fine
Yes
Instrumentation
Training Run
w/ Workloads
Space Overhead
Granularity
App. Semantics
Yes
Yes
Yes
Coarse
No
No
No
provenance graph shown in Fig. 2. Unfortunately, the admin-
istrator discovers that this technique does not advance the
investigation because of the inherent limitations of system logs.
Limitation of System Logs #1: Dependency Explosion.
The administrator’s backtrace identiﬁes thousands of “root
causes” for the SQL injection attack because of the dependency
explosion problem. The reason is that system-layer provenance
trackers must conservatively assume that
the output of a
process is causally dependent on all preceding process inputs
[39], [42], [41], [38]. Although the malicious query string
is known, causal analysis does not allow the administra-
tor to associate the query with a particular outbound edge
of /usr/local/db/datafile.db in the provenance graph.
Even if the administrator restricted most of the dependencies
between Apache httpd and PostgreSQL (e.g., though timing
bounds), admin would again face the same problem when
identifying which input request from HAProxy to Apache httpd
lies on the attack path.
Recent work [39], [42], [40] has introduced execution
partitioning as a viable solution to the dependency explosion
problem. These systems decompose long-running processes
into autonomous “units”, each representing an iteration of
event-handling loop, such that input-output dependencies are
traced only through their corresponding unit. Where event
handling loops do not encode work units, Kwon et al. propose
an inference-based technique for identifying units from system
log traces [38] while Ma et al. propose a framework for
manually annotating source code to disclose meaningful unit
boundaries [41].
Unfortunately, prior approaches suffer from noteworthy
limitations, which we summarize in Table I. Most execution
partitioning systems rely on instrumentation to identify unit
boundaries, requiring either domain knowledge or manual
effort and assuming the right to modify program binaries,
which is not always available [40]. The common requirement
3
httpdindex.htmlhttpdHAProxypostgresql/var/log/postgresql/query.log/var/log/httpd/access.log/var/log/haproxy.logUser.phpBash/usr/local/db/dataﬁleof training runs exposes systems like BEEP and Protracer
to the classic code-coverage problem present
in any dy-
namic analysis, and inference-based techniques (MCI) may
also struggle with out-of-order events due to the presence of
concurrent or cooperating applications during training runs.
All past approaches introduce additional space overhead in
order to track unit boundaries; fully automated identiﬁcation
of event loops (BEEP, Protracer) can generate excessive units