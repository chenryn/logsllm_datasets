it hides all adjacency
information at the cost of requiring per-word storage and
communication complexity that is linear in the maximum
number of ﬁles that can be stored in their index.
Theorem and proof. Before stating our security The-
orem, we provide a more formal and concise description of
our scheme’s leakage:
• the L1 leakage is deﬁned as
L1(f ) =
(cid:0)#As,(cid:2)id(w)(cid:3)w∈W ,(cid:2)id(f )(cid:3)f ∈f ,(cid:2)|f |(cid:3)f ∈f(cid:1),
where id is the identiﬁer function described above.
• the L2 leakage is deﬁned as:
L2(f , w) = (cid:0)accpt(w), id(w)(cid:1),
where accpt(w) is the access pattern which itself is
deﬁned as the sequence (id1, . . . , id#fw ).
• the L3 leakage is deﬁned as:
L3(f , f ) = (cid:0)id(f ),(cid:2)id(w), apprs(w)(cid:3)w∈ ¯f , |f |(cid:1),
where apprs(wi) is a bit set to 1 if w is appears in at
least one ﬁle in f and to 0 otherwise.
• the L4 leakage is deﬁned as:
L4(f , f ) =
(cid:0)id(f ),(cid:2)id(w), prev(f, w), next(f, w)(cid:3)w∈ ¯f(cid:1),
where prev(f, w) and next(f, w) are the identities of the
ﬁrst ﬁles before and after f (in the natural ordering
of ﬁles) that contain w.
If there are no ﬁles before
and after f that contain the word then prev(f, w) and
next(f, w) return ⊥, respectively. Here we assume the
identiﬁer/pointer triples are ordered according to the
order in which the words appear in f .
In the following Theorem, whose proof is omitted due to
lack of space, we show that our construction is CKA2-secure
in the random oracle model with respect to the leakage de-
scribed above.
Theorem 5.1. If SKE is CPA-secure and if F , G and
P are pseudo-random, then SSE as described above is (L1,
L2, L3, L4)-secure against adaptive chosen-keyword attacks
in the random oracle model.
At a very high level, the proof of security for our con-
struction works as follows. The simulator S generates a
simulated encrypted index eγ and a simulated sequence of ci-
phertexts ec using the information it receives from L1, which
includes the number of elements in the search array, the
number of ﬁles, the number of keywords and the length of
972each ﬁle. The simulated index eγ can be constructed simi-
larly to a real encrypted index, except that encryptions are
replaced by encryptions of the zero string (of appropriate
length) and the output of the PRFs are replaced by random
values. The CPA-security of the encryption schemes and
the pseudo-randomness of the PRFs will guarantee that the
resulting eγ is indistinguishable from a real encrypted in-
dex. The simulated ﬁle encryptions ec are simulated in the
same manner (i.e., replacing the ciphertexts by encryptions
of the all zero string) and the CPA-security of the encryption
scheme guarantees indistinguishability.
Simulating search, add and delete tokens is more complex
and requires the simulator to keep track of various dependen-
cies between the information revealed by these operations.
This is because the tokens the simulator creates must all
be consistent with each other, otherwise the simulation may
be detected by the adversary. For this, our proof utilizes a
non-trivial set of techniques so that the simulator can keep
track of dependencies. Due to lack of space the full proof
will appear in the full version of this work.
On our use of random oracles. As observed in [8],
one of the main diﬃculties in designing CKA2-secure SSE
schemes is that the keywords can be chosen as a function
of the encrypted index and of previous search results. This
makes proving security diﬃcult because the simulator has
to be able to simulate an encrypted index before it receives
any search results. [8] showed how to overcome this obsta-
cle and later [6] gave a more eﬃcient approach based on a
simple private-key non-committing encryption scheme. At
a high level, both works construct schemes that allow for
equivocation, that is, the simulator can generate a “fake”
encrypted index and later, when given a search result, can
generate an appropriate token (i.e., a token that when used
with the fake index will yield the correct search outcome).
Unfortunately, the techniques from [8] and [6] do not work
in our setting. The main problem is that in the dynamic
setting there are situations where the previously described
level of equivocation is not enough.
In particular, consider an adversary that ﬁrst searches for
a keyword w, then adds a ﬁle that contains w and, ﬁnally,
searches for w again. To see why the previous level of equiv-
ocation does not suﬃce, notice that after the ﬁrst search the
simulator is committed to a token for w. Now, after the ad-
versary adds a ﬁle with w, the simulator needs to simulate
an add token for that ﬁle. The simulator, however, does not
know what the ﬁle is or even that it contains w so it cannot
produce a token that functions properly, i.e., the add token
it simulates cannot make any meaningful change to the en-
crypted index. The problem is that after the adversary per-
forms the second search for w, he expects this new search
to reveal at least one new result compared to the previous
one. In particular, the search should now also reveal the new
ﬁle’s identiﬁer. But if the add token cannot properly modify
the encrypted index in the second stage and if the simulator
cannot send a new token during the third stage (since it is
committed) then how can the simulator guarantee that the
adversary will get an updated search result?
We overcome this by constructing a scheme that allows
the simulator to modify the outcome of the search during
the adversary’s execution of the search algorithm. Note that
this is a departure from the approaches of [8] and [6] which
manipulate the outcome of the adversary’s search by creat-
ing specially designed tokens. We do this by making use of
the random oracle model. At a very high level, we design
our encrypted index in a way that requires the adversary
to query a random oracle during various steps of the search
algorithm. The simulator is then able to program the re-
sponses of the random oracle in a way that suits it and can
make sure that the execution of the search yields the out-
come it wants.
6. PERFORMANCE
6.1 Implementation
To demonstrate the feasibility of our algorithms, we imple-
mented SSE in C++ over the Microsoft Cryptography API:
Next Generation (CNG) [7]. Our implementation uses the
algorithms described in §4. The cryptographic primitives
for our protocol use CNG. Encryption is the CNG imple-
mentation of 128-bit AES-CBC [13], and the hash function
is the CNG implementation of SHA-256 [12]. SSE employs
two random oracles, which are implemented using HMAC-
SHA256 from CNG (this employs the HMAC construction
ﬁrst described by Bellare, Canetti, and Krawczyk [3]). The
ﬁrst parameter passed to the random oracle is used as a key
to the HMAC, and the second parameter is used as input to
the HMAC.5
A system that implements SSE performs two classes of
time-intensive operations: cryptographic computations and
systems actions (e.g., network transmission and ﬁlesystem
access). To separate the costs of cryptography from the sys-
tems costs (which will vary between underlying systems),
we built a test framework that performs cryptographic com-
putations on a set of ﬁles but does not transfer these ﬁles
across a network or incur the costs of storing and retrieving
index information from disk; all operations are performed in
memory. We also ignore the cost of producing a plain-text
index for the ﬁles, since the choice and implementation of
an indexing algorithm is orthogonal to SSE.
6.2 Experiments
Cryptographic operations in SSE require widely varying
amounts of time to execute. So, to evaluate SSE, we per-
formed micro-benchmarks and full performance tests on the
system and broke each test out into its component algo-
rithms. The micro-benchmarks are used to explain the per-
formance of the full system.
These experiments were performed on an Intel Xeon CPU
2.26 GHz (L5520) running Windows Server 2008 R2. All ex-
periments ran single-threaded on the processors. Each data
point presented in the experiments is the mean of 10 execu-
tions, and error bars provide the sample standard deviation.
The unit of measurement in all of the microbenchmarks
is the ﬁle/word pair : for a given ﬁle f the set of ﬁle/word
pairs is comprised of all unique pairs (f , w) such that w is
a word associated with f in the index. The set of all such
tuples across all ﬁles in a ﬁle collection is exactly the set of
entries in a keyword index for this collection.
We chose three sets of real-world data for our experiments.
The ﬁrst set was selected from the Enron emails [11]; we ex-
tracted a subset of emails and used decreasing subsets of
5Recent work by Dodis, Ristenpart, Steinberger, and Tes-
saro [10] shows that HMAC is indiﬀerentiable from a random
oracle when the key used has length shorter than d−1, where
d is the block length of the underlying hash function. Our
keys are 32-bytes in length and satisfy the theorem.
973this original subset as ﬁle collections with diﬀerent numbers
of ﬁle/word pairs. The second set consisted of Microsoft
Oﬃce documents (using the Word, PowerPoint, and Excel
ﬁle types) used by a business group in Microsoft for its in-
ternal planning and development.
In a similar fashion to
the emails, we chose decreasing subsets of this collection as
smaller ﬁle collections. The third data set consists of media
ﬁles, which have almost no indexable words but have large
ﬁle size. This collection is composed of MP3, video, WMA,
and JPG ﬁles that make data sets of the same sizes as the
ones in the document collection. To index the emails, doc-
uments and media, we used an indexer that employs IFilter
plugins in Windows to extract unique words from each ﬁle.
The indexer also extracts properties of the ﬁles from the
NTFS ﬁlesystem, such as the author of a Microsoft Word
document, or the artist or genre of an MP3 ﬁle.
6.2.1 Micro-benchmarks
To determine the performance of SSE, we generated syn-
thetic indexes and executed search and update operations
on them. For searches, we chose the word that was present
in most ﬁles. And we deleted and added back in a ﬁle with
the largest number of unique words in the index. We only
compared against the email and document data sets for our
micro-benchmarks, since the media data set index size was
too small for useful comparisons.
We generated our synthetic indexes from a pair of Zipf
distributions [24] with parameter α = 1.1; one distribution
contained randomly-generated ﬁles, and the other contained
words (the words in our case were simply numbers repre-
sented as strings: “0”, “1”, “2”, etc.). The synthetic ﬁle col-
lection was generated as follows. First, the test code drew a
ﬁle f from the Zipf ﬁle distribution (our sampling employed
the algorithm ZRI from H¨orman and Derﬂinger [17]). Sec-
ond, the test code drew words from the word distribution
until it found a word that was not in the index for f .
It
then added this word to the index information for f and
drew another ﬁle to repeat the process until a given number
of ﬁle/word pairs is generated. This process corresponds to
writing a set of ﬁles with Zipf-distributed sizes and contain-
ing Zipf-distributed words such that the ﬁle collection as a
whole contains a given number of ﬁle/word pairs.
Figure 4 shows the costs of index generation incurred by
SSE, expressed as the cost per ﬁle/word pair; these are the
timings for the operations that are performed after a collec-
tion of ﬁles is indexed (for the total time required to index
these collections, see the results of Figure 5 in §6). The num-
bers of pairs range from about 14,000 to about 1,500,000 in
number. The synthetic data is labeled with “Zipf”, the En-
ron data is labeled with “Email”, and the document data
is labeled with “Docs”. The cost per ﬁle/word pair is an
amortized value: it was determined by taking the complete
execution time of each experiment and dividing by the num-
ber of ﬁle/word pairs.
The cost per ﬁle/word pair in Figure 4 is small:
it de-
creases to about 35 µs per pair. Lower numbers of pairs
lead to higher per-pair costs, since there is a constant over-
head for adding new words and new ﬁles to the index, and
the cost is not amortized over as many pairs in this case.
The email and document data validate our synthetic model
and correspond closely to this model (within 10%) for data
points with approximately the same number of ﬁle/word
pairs. This suggests that, at least for large numbers of pairs,
100
35
)
s
µ
(
r
i
a
P
r
e
P
e
m
T
i
Zipf
Docs
Emails
100000
500000
1000000
1500000
File/Word Pairs
Figure 4: Execution time for SSE.Enc.
Table 2: Execution time (in µs) per unit (word or
ﬁle) for SSE operations.
operation
SSE.Search
SSE.AddToken
SSE.DelToken
SSE.Add
SSE.Del
time
7.3
37
3.0
1.6
24
stddev
0.6
2
0.2
0.4
1
the Zipf model leads to the same SSE performance as the
English text as contained in the emails and documents. The
synthetic data tests the sensitivity of the SSE algorithms to
details of the ﬁle/word distribution; experiments over the ﬁle
collections are limited to always operating over the same as-
signment of unique words to ﬁles, but diﬀerent experiments
over the synthetic data contain diﬀerent sets of ﬁle/word
pairs, albeit drawn from the same distribution. Since our
synthetic results match closely our results from real-world
data sets, this sensitivity is low, as would be expected.
Micro-benchmark execution time for SSE algorithms does