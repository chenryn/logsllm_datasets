RabbitMQ
rabbit@localhost
rabbit_1@localhost
rabbit_2@localhost
localhost:5672
localhost:5673
localhost:5674
localhost
图6.3轮询负载均衡
每台后台服务器定义指令包含五个部分。
■server：后台服务器定义中的内部标识。
■：：连接到后台服务器的IP和端口号。
·checkinter：定义了每隔多少毫秒检查后台服务器是否可用。
·rise：表明了后台服务器在发生故障之后，需要完成多少次健康
检测，才能再次被确认可用。
·fall：表明需要经历多少次失败的健康检测，HAProxy才会停止
使用后台服务器。
最后的配置部分是数据统计页面4。这是可选的，可以通过端口8100启用
它，你可以连接到http://localhost:8100观测HAProxy的当前状态，包括当前每台
多少节点在工作的时候是很有用的。还有很多HAProxy配置选项，涵盖了方方面面，
包括了从复杂的负载均衡规则，到将后台节点视为备用服务器（仅在所有主服务器
发生故障时才启用）。在http://haproxy.1wt.eu/download/1.4/doc/configuration.txt上有
---
## Page 149
6.2连接丢失和故障转移
127
HAProxy的手册以供查阅。
让我们用新的配置来启动HAProxy并确保它能工作。运行/usr/local/
sbin/haproxy-f_config_file。其中的config_file就是你刚刚创建的配置文件。
如果一切正常的话，你应该可以顺利加载http://localhost:8100/stats页面，它看起来
像图6.4那样。
→Clocalhost:8100/stats
HAProxy version 1.4.14,released 2011/03/29
StatisticsReportforpid 30430
>General process informationD
active UP
backupUP
External rossourcos
pd (1.b 1)
active UP,going down
backup UP,going down
actvoDOWN,goingup
backupDOwN.going up
Bxsoc
·Oniemanual
cumentpipos=0/0
aiveorackup DOwNnotchecked
Runnglnsksa:1/6
active or backup DOwN formaintenance (MAINT)
Note:UP with load-balancing disabied ispored a*NOLB
rabbitmg_local_cluster
BytaDeniedErorsWamingo
StatroLastChkW
meThrtl
2220002
OPEN
abbiooo
3100002142UPL40K0m1Y0110
bbl100-01111100
Oo053suPL4OKnOm1Y-0o
00
Bcknd0001222000230000002153UP
H33000
privato_monitoring
ChD
Frontend
8794115934000
OPEN
Backond00010120005008794115934001000053sUP0000
图6.4HAProxy数据统计页面
现在开发系统上运行着负载均衡器，我们准备深人探索如何使用它来为消息通
信应用程序植入故障转移和快速恢复的能力。
6.2连接丢失和故障转移
当集群节点出现故障时，应用程序必须要做出决定：下一个该连向哪里？为了
能有效回答这个问题，你必须在事情发生前就有所准备。优雅地处理节点故障需要
思维的转变。集群并不意味着可以完全避免所有Rabbit问题；而是意味着当出现问
题的时候节点能继续运行。所以，首先需要退一步思考一下，在编写代码之前你可
以做怎样的假设：
（1）如果我重新连接到新的服务器，那么我的信道以及其上的所有消费循环会
---
## Page 150
128
第6章从故障中恢复
怎样呢？它们现在都失效了。你必须对它们进行重建。
（2）当我进行重连的时候，我能否假设所有的交换器、队列和绑定仍然存在于
集群之中？我能否重连之后立即开始从队列消费呢？答案是否定的。你不能假设队
列和绑定可以从节点故障中恢复。你必须假定你在消费的所有队列都附加在该节点
之上一并且已不复存在。对队列的绑定来说也一样，然而交换器则不同。如果你
使用的是内建的Rabbit集群的话，则可以假设交换器能够幸免于节点故障，因为它
们在所有节点都有副本。但是如果你使用了我们在后面所讲述的主/备模式设置的
话，则仍然无法假设交换器可以从故障中恢复。
从这些问题中你可以得出的结论是当故障转移到新的节点时，你无法对集群的
状态做任何假定。虽然Rabbit集群可以让你重连到新节点去，但你不能做任何假设。
从某些角度而言，你应该总是将故障转移视为连接到了一个完全无关的RabbitMQ
服务器，而不是有着共享状态的集群节点。因此，不论节点故障什么时候发生，在
检测到故障并进行重连之后的首要任务是构造交换器、队列和绑定，以便应用程序
的运作。在开始编码前，让我们先讨论运行前还需要什么。就像第3章的示例那样，
你需要安装Python2.6，以及Pika0.9.6或者更高版本。此外，你还需要以下两点：
■本地开发机器设置了RabbitMQ集群。
■在同一台机器上配置并运行HAProxy，并在5670端口监听AMQP连接。
你将编写能够从集群节点故障中恢复的生产者和消费者示例。构造一个集群感
知的消费者更为困难，因为是由消费者来搭建消息通信结构的（交换器、队列和绑
定）。因此，这就取决于消费者在节点发生故障之后重建通信结构了。标准的消费
者代码如下列清单所示。
清单6.2标准消费者主体
②自定义连
连接到 > conn_broker = pika.BlockingConnection(conn_params)
接行为
RabbitMQ
channel = conn_broker.channel()
channel.exchange_declare( exchange="cluster_test",
4
type="direct",
auto_delete=False)
channel.queue_declare(queue="cluster_test";
声明交换
auto_delete=False)
器、队列
channel.queue_bind(queue="cluster_test",
③和绑定
exchange="cluster_test",
routing_key="cluster_test")
---
## Page 151
6.2连接丢失和故障转移
129
print"Ready for testing!"
channel.basic_consume( msg_rcvd,
开始消
queue="cluster_test",
4费消息
no_ack=False,
consumer_tag="cluster_test")
channel.start_consuming()
在处，你使用已经构造好的参数来连接服务器。你建立了信道?，并开始声
明③交换器、队列和绑定（消息通信结构）。在消息通信结构构造完成之后，你创建
了4消费订阅（由msg_rcvd函数提供），并开始消费消息。这时，如果遇到了节点
故障，那么程序就会由于未处理的异常而崩溃。这是因为代码不知道在连接发生错
误时该怎么办。你需要做的是将这段代码包裹在一个异常处理中，并在故障发生时
发起重连。但是从哪里开始呢？主要代码块中的哪部分需要在故障后重新运行呢？
答案是整个代码都需要。如果你假设消息通信结构的任何部分都无法从节点故障中
恢复的话，那么就需要在每次错误发生的时候运行整个代码块。记住这一点，然后
重写主代码块，那么就会像下列清单所示。
清单6.3集群感知的消费者主体
while True:
2建立到
try:
RabbitMQ
默认情况
conn_broker=pika.BlockingConnection(conn_params)
的连接
下，重新
连接到1
channel =conn_broker.channel()
RabbitMQ
channel.exchange_declare( exchange="cluster_test",
type="direct",
声明交换
auto_delete=False)
器、队列
channel.queue_declare(queue="cluster_test",
3和绑定
auto_delete=False)
channel.queue_bind( queue="cluster_test",
exchange="cluster_test",
routing_key="cluster_test")
4开始消
费消息
print"Ready for testing!"
channel.basic_consume( msg_rcvd,
queue="cluster_test",
no_ack=False,
捕获连接
consumer_tag="cluster_test")
异常，并
channel.start_consuming()
进行打印
except Exception,e:
traceback.print_exc()
---
## Page 152
130
第6章从故障中恢复
通过将主代码块放入try·..except块中，你就可以检测连接故障，消
费者也不会因此而崩溃。在该示例中，你捕获了所有的错误并将它们打印到屏幕
上。但这只是解决方案的一半。虽然当节点发生故障时程序不再崩溃了，但你仍然
需要进行重连并重建通信结构。为了实现这一点，你需要将整个代码主体（包括
try·..except块）包含在无限循环之中1。当应用程序第一次启动时，它进入循
环体，然后构造连接2和通信结构3。之后它暂停循环开始消费5。只要没有错误
发生，外层循环就会一直运行下去。但当节点发生故障时，就会抛出连接错误。这
会导致控制权从消费代码4转移到外层异常处理6。接着，异常处理代码通过捕获
错误来阻止程序崩溃，并将错误打印到屏幕，随后把控制权交还给外层循环。现在
循环重新启动整个连接过程1，像之前那样构造新的连接2和通信结构3。这个简
单的更改却让程序能够处理RabbitMQ集群下的节点故障。同时也能处理节点故障
的各种变体。这一点我们尚未讨论过，但是你必须知道。
到目前为止，在我们从应用程序的角度讨论集群节点故障时，我们反复说明应
用程序连接的是节点。你也许会做这样的假设：只要应用程序连接的那个节点没有
崩溃，那么就没什么好担心的了。这并非完全正确。如果你记得队列在集群环境下
的运作方式的话，就会注意到它们只存在于某一个节点上。由于在开始消费的时候，
应用程序并不知道队列在哪个节点上，因此，应用程序很有可能连接到了集群中的
A节点但却从B节点的队列上消费消息。所以，当B节点发生故障时会发生什么呢？
虽然应用程序不会遭受连接错误，但是消费的那个队列却已不复存在。如果你运行
的是RabbitMQ2.4.0之前的版本，那你的运气就太糟了。消费者会呆呆坐在那儿很
开心，但却什么事情都不做（至少在你重启之前）。这个限制更多的是由于AMQP
造成的。但在RabbitMQ2.4.0时，它为我们带来了AMQP的一个新的扩展，叫作取
消通知（cancellationnotification）。通过取消通知，除了自行取消之外的任何情况导
致的订阅终结，消费者都会收到通知。在Pika中，这种模式会表现为消费代码抛出
的异常。这会被异常处理代码捕获，然后重连并重建通信结构。将所有这一切结合
起来，消费者代码就会如下列清单所示。
---
## Page 153
6.2连接丢失和故障转移
131
清单6.4集群感知的消费者
import sys,json,pika,time,traceback
def msg_rcvd(channel，method,header,body):
message = json.loads(body)
打印并发送
确认消息
print "Received: %(content)s/%(time)d" % message
服务器
channel.basic_ack(delivery_tag=method.delivery_tag)
设定if
ueu==—aueu—
AMQP_SERVER = sys.argv[1]
AMQP_PORT = int(sys.argv[2])
建立到服务
器的连接
creds_broker=pika.PlainCredentials("guest","guest")
conn_params = pika.ConnectionParameters( AMQP_SERVER,
port=AMQP_PORT,
virtual_host="/",
故障发生时，
credentials=creds_broker)
重新连接
RabbitMQ>
while True:
建立到
try:
RabbitMQ
conn_broker = pika.BlockingConnection(conn_params)
<一的连接
channel = conn_broker.channel()
自定义连
channel.exchange_declare(exchange="cluster_test"
接行为
type="direct",
声明交换
auto_delete=Faise)
器、队列