title:Aggregated Machine Learning on Indicators of Compromise in Android
Devices
author:John M. San Miguel and
Megan E. M. Kline and
Roger A. Hallman and
Scott M. Slayback and
Alexis Rogers and
Stefanie S. F. Chang
 TECHNICAL DOCUMENT 3390 
July 2019 
Aggregated Machine Learning on 
Indicators of Compromise 
John M. San Miguel 
Megan E.M. Kline 
Roger A. Hallman 
Johnny Phan 
Scott M. Slayback 
Christopher M. Weeden 
Jose V. Romero-Mariona 
Distribution Statement A: Approved for public release; distribution is unlimited. 
NIWC Pacific 
San Diego, CA 92152-5001 
This page intentionally blank. 
TECHNICAL DOCUMENT 3390 
July 2019 
Aggregated Machine Learning on 
Indicators of Compromise 
John M. San Miguel 
Megan E.M. Kline 
Roger A. Hallman 
Johnny Phan 
Scott M. Slayback 
Christopher M. Weeden 
Jose V. Romero-Mariona 
Distribution Statement A: Approved for public release; distribution is unlimited. 
Administrative Notes: 
This  document  was  approved  through  the  Release  of  Scientific  and 
Technical Information (RSTI) process in June 2018 and formally published 
in the Defense Technical Information Center (DTIC) in July 2019.  
This  document’s  content  represents  work  performed  under  Space  and 
Naval Warfare Systems Center Pacific (SSC Pacific). SSC Pacific formally 
changed  its  name  to  Naval  Information  Warfare  Center  Pacific  (NIWC 
Pacific) in February 2019 
NIWC Pacific 
San Diego, CA 92152-5001 
NIWC Pacific 
San Diego, California 92152-5001 
M. K. Yokoyama, CAPT, USN 
Commanding Officer 
W. R. Bonwit  
Executive Director 
ADMINISTRATIVE INFORMATION 
The work described in this report was performed by the Cyber / Science & Technology Branch 
(Code 58230) and Advanced Electromagnetics Technology Branch (Code 58230) of the 
Cybersecurity Engineering Division (Code 58220), Space and Naval Warfare Systems Center Pacific 
(SSC Pacific), San Diego, CA. The Naval Innovative Science and Engineering (NISE) Program at 
SSC Pacific funded this Applied Research project. 
Released by 
Jose Romero-Mariona, Head  
Cyber / Science & Technology 
Under authority of 
Jara D. Tripiano, Head 
Cybersecurity Engineering 
This is a work of the United States Government and therefore is not copyrighted. This work may be 
copied and disseminated without restriction.  
The citation of trade names and names of manufacturers is not to be construed as official government 
endorsement or approval of commercial products or services referenced in this report. 
MATLAB®   is a registered trademark of The MathWorks, Inc. 
EXECUTIVE SUMMARY 
The increasing ubiquity of mobile computing technology has lead to new trends in many different 
sectors. “Bring Your Own Device” is one such growing trend in the workplace, because it allows 
enterprise organizations to benefit from the power of distributed computing and communications 
equipment that their employees have already purchased. Unfortunately, the integration of a diverse 
set of mobile devices (e.g., smart phones, tablets, etc.) presents enterprise systems with new 
challenges, including new attack vectors for malware. Malware mitigation for mobile technology is a 
long-standing problem for which there is not yet a good solution. In this paper, we focus on 
identifying malicious applications, and verifying the absence of malicious or vulnerable code in 
applications that the enterprises and their users seek to utilize. Our analysis toolbox includes static 
analysis and permissions risk scoring, pre-installation vetting techniques designed to insure that 
malware is never installed in devices on an enterprise network. However, dynamic code-loading 
techniques and changing security requirements mean that apps which previously passed the 
verification process, and have been installed on devices, may no longer meet security standards, and 
may be malicious. To identify these apps, and prevent future installation of them, we propose a 
crowd-sourced behavioral analysis technique, using machine learning to identify malicious activity 
through anomalies in system calls, network behavior, and power consumption. These techniques 
apply effectively to single user devices over time, and to individual devices within an enterprise 
network. 
v 
This page is intentionally blank.  
CONTENTS 
EXECUTIVE SUMMARY ...................................................................................................... v 
1.  INTRODUCTION............................................................................................................. 1 
1.1  CONTRIBUTION .................................................................................................... 1 
1.2  BACKGROUND ..................................................................................................... 1 
1.2.1  Crowd-sourced Behavioral Analysis ............................................................... 1 
1.2.2  Related Work ................................................................................................. 2 
2.  MOBILE TECHNOLOGY IN THE CONTEXT OF THE NAVY ........................................ 5 
2.1  MOBILE ECOSYSTEM SECURITY GAPS........................................................... 5 
2.2  HOW THE NAVY IS DOING MOBILE ................................................................... 6 
2.2.1  How the Navy is doing mobile security ........................................................... 6 
3.  THE MAVERIC APPROACH TO DYNAMIC ANALYSIS FOR MOBILE (ANDROID) 
APPLICATION SECURITY .................................................................................................. 9 
3.1  FEATURE SETS.................................................................................................. 10 
3.1.1  Rationale for Collecting Power Consumption ............................................... 10 
3.1.2  Rationale for Collecting Network Activity ...................................................... 10 
3.1.3  Rationale for Collecting Sequences of System Calls .................................... 10 
3.2  DATA ANALYSIS................................................................................................. 11 
4.  EXECUTION PLAN ....................................................................................................... 12 
4.1  POWER CONSUMPTION ................................................................................... 13 
4.2  NETWORK ACTIVITY ......................................................................................... 13 
4.3  SEQUENCE OF SYSTEM CALLS ...................................................................... 13 
4.4  APPLICATION SET ............................................................................................. 14 
4.5  MACHINE LEARNING METHODOLOGY ........................................................... 14 
5.  CONCLUSION AND FUTUREWORK ........................................................................... 18 
REFERENCES ................................................................................................................... 20 
vii 
Figures  
1.   MAVeRiC’s overall architecture makes use of an advanced static analysis 
capability that  utilizes the Artemis tool to verify a lack of malice in Android 
applications.  Crowd-sourced dynamic  analysis monitors applications to ensure 
that malice is not present during application execution. Dell and Dell Precision 
are trademarks of Dell Inc. or its subsidiaries. Intel is a trademark of Intel Corpo- 
ration or its subsidiaries in the U.S. and/or other countries............................................... 3 
2.   MAVeRiC’s approach to dynamic analysis is as follows:  Known good and bad 
applica-  tions are monitored for power consumption, network activity, and system 
calls. Both supervised and  unsupervised machine learning techniques are 
utilized for detecting IOCs. ............................................................................................... 9 
viii 
1.  INTRODUCTION 
Mobile technology has become ubiquitous in society, leading to new trends in many different 
sectors. “Bring Your Own Device” (BYOD) [9] is a trend that has entered many workplaces to 
accommodate employees’ comfort and familiarity with their personal devices. The benefits of BYOD 
policies include allowing companies to save money by not having to make information technology 
purchases and enabling a distributed computing and communications network of employees’ 
equipment. Estimates in 2011 suggested that nearly 75% of employers allowed employees to connect 
their personal devices to enterprise networks [28], and this trend has only increased since then. 
Indeed, the BYOD phenomena can be found in diverse sectors such as business [10], education [22], 
and healthcare [18]. Faced with a younger generation of workers who have always had mobile 
devices, government bodies at various levels within the United States are exploring the adoption of 
BYOD policies [23]. This phenomena has even become an issue for military organizations, where 
personal devices may interact with critical cyber-physical systems as well as environments that 
contain extremely sensitive information [7, 21]. 
In light of this new reality, military and other government organizations must determine ways to 
keep malicious applications on personal devices from infecting corporate networks. To this end, we 
propose Mobile Application Vetting and Risk-Estimation Capability (MAVeRiC), a program which 
makes use of both static and dynamic analysis to vet Android1® applications. Specifically, MAVeRiC 
offers the ability to vet Android applications for the absence of malice both pre- and post-installation. 
This post-installation vetting is accomplished by comparing data from running applications between 
users on enterprise networks. MAVeRiC’s overall architecture can be seen in Figure 1. 
1.1  CONTRIBUTION 
Our main contribution in this paper is the description of an approach for verifying the absence of 
malice  in Android applications that utilizes a conglomeration of machine learning techniques on 
crowd-sourced  behavioral data. We also provide background information on how enterprise 
networks which host enclaves  with particularly sensitive information and critical systems handle the 
BYOD phenomenon, which informs  our approach in MAVeRiC. 
1.2  BACKGROUND 
Static (or code) analysis provides an analysis of an application without actually executing it. One 
such  analysis technique is to create “feature vectors” that characterize a given application’s 
characteristic actions  (e.g., permissions requests). Benign applications within each category that have 
similar functions are  expected to have similar permissions requests, while malicious ones deviate; the 
extent of deviation is  measured and used for risk assessment. Almost all static analysis for risk 
assessment of Android applications use permission calls as their main criteria. One weakness of static 
analysis techniques is a vulnerability to code obfuscation. Dynamic (or behavioral) analysis is not 
vulnerable to code obfuscation  or other evasion techniques that can get past a static analysis regimen 
because it is able to observe  malicious behavior on an execution path [29]. Our prior work [11] 
provides a brief survey of static and  dynamic analysis tools for Android Applications. 
1The Android name and Android Robot logo are property of Google LLC. The Android Robot logo is licensed under the terms 
of the Creative Commons Attribution 2.5 license. 
1 
1.2.1  Crowd-sourced Behavioral Analysis 
The Crowd-Sourced Behavioral Analysis (CSBA) approach outlined in this paper is part of a 
larger  framework of technology and policy that the MAVeRiC team is developing. MAVeRiC 
employs both a pre-installation vetting procedure as well as post-installation dynamic analysis. The 
pre-installation vetting  includes triage, data flow analysis, and permissions risk analysis, which all 
feed into an overall risk score. 
The triage and data flow analysis portion of the vetting process is built around Artemis (which 
utilizes DroidSafe’s static analysis capabilities) [17], the best-of-breed solution to the DARPA 
Automated Program Analysis for Cybersecurity (APAC) program2, provided by Raytheon BBN3. 
Triage does a quick comparison of short sequences of machine language instructions against 
sequence lists from Android Packages (apks) that are known to be malicious. Data Flow analysis lifts 
apk binaries to an intermediate representation (IR) called Jimple [27], and the framework generates a 
listing of the possible execution paths of the program. This listing can be shown to analysts in the 
form of a control-flow-graph (CFG), or a class-call-graph (CCG) with the ability to query results for 
specific data flows. Permissions risk analysis is based on the likelihood of a given application’s 
category requesting a certain set of permissions. The overall risk score is a quantification of the 
individual analyses to provide analysts with an aggregate overview of an application’s risk. The 
overarching goal is to support non-specialized IT personnel in quickly evaluating the risk involved 
with installing a given app on a DoD device. 
The focus of this paper is to describe the Crowd-Sourced Behavioral Analysis (CSBA) approach 
used to develop MAVeRiC’s post-installation dynamic analysis. MAVeRiC crowd-sources data and 
uses a machine learning approach to analyze sequences of system calls, network behavior, and power 
consumption data to identify malicious activities both from a single user’s device over time as well 
as within a trusted network of users. 
1.2.2  Related Work 
Other related efforts have validated the approach MAVeRiC has taken. One paper suggests that 
there are limitations to utilizing purely static or dynamic approach to analyzing Android malware [5]. 
They point out that the standard of static malware could not be sufficient to protect against 
techniques that evade or obfuscate such analysis and are therefore inadequate and ineffective to an 
analyst. They propose an approach that detects Android malware by fingerprinting the behavior of 
system calls and incorporating machine learning to be able to associate malicious behaviors. The 
approach is validated using a real device and experiments on 20,000 execution traces across 2,000 
applications with a 97% accuracy. Our approach to analyzing sequences of system calls will closely 
mirror theirs by being run on an emulator, but then validated with a real device metrics. In addition, 
we are incorporating other types of data for analysis, including network activity and power 
consumption. 
2https://www.darpa.mil/program/automated-program-analysis-for-cybersecurity 
3Raytheon is a registered trademark of the Raytheon Company. 
2 
An approach we leverage that is validated in another paper [6] discusses the use of power 
consumption as a mechanism to create an energy footprint to determine a baseline. Along with the 
baseline, they propose the use of energy consumption measurement from seven covert channels 
including type of intent, file lock, system load, volume settings, unix socket discovery, file size, and 
memory load. 
Inspired by [4], we also make use of the crowd-sourcing paradigm. By collecting data from 
multiple users within a network that is semi-trusted, we have a much more robust picture of how 
apps are used and can get a better understanding of what typical behaviors are. We anticipate that this 
with support our analytics by allowing quick identification of unususal behaviors. This work expands 
on that of Burguera et al. by working in a larger test environment with more features. We are also 
appling the approach to a Navy-relevant environment with navy security concerns in mind. 
The remainder of this paper is laid out as follows: Section 2 provides a very high-level overview 
to the  way that the United States Navy is approaching the incorporation of mobile technologies and 
attempting to 
Figure 1. MAVeRiC’s overall architecture makes use of an advanced static analysis 
capability that  utilizes the Artemis tool to verify a lack of malice in Android 
applications.  Crowd-sourced dynamic  analysis monitors applications to ensure that 
malice is not present during application execution. Dell  and Dell Precision are 
trademarks of Dell Inc. or its subsidiaries. Intel is a trademark of Intel Corpo-  ration or 
its subsidiaries in the U.S. and/or other countries. 
adjust to the realities of BYOD. We detail our approach to MAVeRiC dynamic analysis in Section 3 
and our plan for executing the approach in Section 4. Finally, concluding remarks and directions for 
possible  future work are given in Section 5. 
3 
This page is intentionally blank.
2.  MOBILE TECHNOLOGY IN THE CONTEXT OF THE NAVY 
Mobile devices are transforming the way that the navy operates. By leveraging the computing 
power, small form factor and many integrated sensors, we have the ability to be more responsive and 
interactive with our environment. There is great potential in operational use of distributed computing 
resources to enhance users’ situational awareness, share data, build a better picture of the operating 
environment, and decrease out-of-pocket time. The navy has the option to leverage this computing 
and communications ability at a substantially reduced cost through the use of BYOD policies. 
The mobile ecosystem is constructed around the use of dedicated single-purpose applications 
(apps), which interface with a device’s onboard sensors and network communications to provide 
services to the device user. Since each user has different roles and needs, they will need the ability to 
install different apps. To meet warfighter needs, the navy can develop its own apps, and 
simultaneously leverage Commercial 
Off-the-Shelf (COTS) apps. In either case, we need to ensure that these apps do not leak sensitive 
personal or mission-related information. 
2.1  MOBILE ECOSYSTEM SECURITY GAPS 
While the Play Store and the associated mobile ecosystem have been active for almost 9 years, 