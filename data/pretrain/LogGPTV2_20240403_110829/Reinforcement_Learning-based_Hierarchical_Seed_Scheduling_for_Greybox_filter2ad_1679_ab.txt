waypoints in seed chains as the sensitivity of a coverage metric.
For example, consider the maze game in Listing 1, which is
widely used to demonstrate the capability of symbolic execu-
tion of exploring program states. In this game, a player needs
to navigate the maze via the pair of (x, y) that determines a
location for each step. In order to win the game, a fuzzer has
to try as many sequences of (x, y) pairs as possible to ﬁnd the
right route from the starting location to the crashing location.
This simple program is very challenging for fuzzers using edge
coverage as the ﬁtness function, because there are only four
branches related to every pair of (x, y), each checking against a
relatively simple condition that can be satisﬁed quite easily. For
instance, ﬁve different inputs: “a,” “u,” “d,” “l,” and “r” are
enough to cover all branches/cases of the switch statement.
After this, even if the fuzzer can generate new interesting
1 c h a r maze [ 7 ] [ 1 1 ] = {
2
"+−+−−−+−−−+" ,
" |
| # | " ,
" |
| " ,
| " ,
|
" |
" | +−− |
| " ,
" |
|
| " ,
"+−−−−−+−−−+" } ;
|
| −−+ |
|
|
|
i n t x = 1 , y = 1 ;
f o r ( i n t
i = 0 ;
s w i t c h ( s t e p s [ i ] ) {
i ++) {
i < MAX_STEPS ;
’ u ’ : y−−; b r e a k ;
’ d ’ : y ++; b r e a k ;
’ l ’ : x−−; b r e a k ;
’ r ’ : x ++; b r e a k ;
c a s e
c a s e
c a s e
c a s e
d e f a u l t :
p r i n t f ( " Bad s t e p ! " ) ;
r e t u r n 1 ;
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
}
i f
}
i f
}
( maze [ y ] [ x ] == ’ # ’ ) {
p r i n t f ( "You win ! " ) ;
r e t u r n 0 ;
( maze [ y ] [ x ]
’ ) {
p r i n t f ( "You l o s e . " ) ;
r e t u r n 1 ;
!= ’
26
27 }
28
r e t u r n 1 ;
Listing 1: A Simple Maze Game
inputs that indeed advance the program’s state towards the
goal (e.g., “dd“), these inputs will not be selected as new
seeds because they do not provide new edge coverage. As a
result, it is extremely hard, if not impossible, for fuzzers that
use the edge coverage to win the game [3].
On the contrary, as we will show in §V-G, if a fuzzer
can measure the different combinations of x and y (e.g., by
tracking different memory accesses via ∗(maze + y + x)
at line 10), then reaching the winning point will be much
easier [3], [45]. Similarly, researchers have also observed
that the orderless of branch coverage and hash collisions can
cause a fuzzer to drop critical waypoints hence prevent certain
code/bugs from being discovered [19], [27], [30].
The second impact of a coverage metric has on creating
seed chains is the stride between a pair of seeds in a chain.
Speciﬁcally, the sensitivity of a coverage metric also deter-
mines how likely (i.e., the probability) a newly generated test
case will be saved as a new seed. For instance, it is easier
for a fuzzer that uses edge coverage to discover a new seed
than a fuzzer that uses block coverage. Similarly, as we have
discussed in §I, it is much easier to ﬁnd a match for an 8-
bit integer than a 32-bit integer. Böhme et al. [9] model the
minimum effort to discover a neighbouring seed as the required
power (i.e., mutations). Based on this modeling, a more
sensitive coverage metric requires less power to make progress,
i.e., a shorter stride between two seeds. Although each seed
only carries a small step of progress, the accumulation of them
can narrow the search space faster.
While the above discussion seems to suggest that a more
sensitive coverage metric would allow fuzzers to detect more
4
bugs,
the empirical results from [45] showed this is not
always the case. For instance, while memory access coverage
would allow a fuzzer to win the maze game (Listing 1), it
did not perform very well on many of the DARPA CGC
challenges. The reason is that, a more sensitive coverage metric
will also create a larger seed pool. As a result,
the seed
scheduler needs to examine more candidates each time when
choosing the next seed to fuzz. In addition to the increased
workload of the scheduler, a larger seed pool also increases the
difﬁculty of seed exploration, i.e., trying as many fresh seeds as
possible. Since the time of a fuzzing campaign is ﬁxed, more
abundant seeds also imply that the average fuzzing time of
each seed could be decreased, which could negatively affect
seed exploitation, i.e., not fuzzing interesting seeds enough
time to ﬁnd critical waypoints.
Overall, a more sensitive coverage metric boosts the capa-
bility (i.e., upper bound) of a fuzzer to explore deeper program
states. Nevertheless, in order to effectively utilize its power and
mitigate the side effects of the resulting excessive seeds, the
coverage metric and the corresponding seed scheduler should
be carefully crafted to strike a balance between exploration
and exploitation.
B. Seed Clustering via Multi-Level Coverage Metrics
The similarity and diversity of seeds, which can be mea-
sured in terms of the exercised coverage, drive the seed
exploration and exploitation in a fuzzing campaign. In general,
a set of similar seeds gains less information about the program
under test than a set of diverse seeds. When a coverage metric
measures more ﬁne-grained coverage information (e.g., edge),
it can dim the coarse-grained diversity (e.g., block) among
different seeds. First, it encourages smaller variances between
seeds. Second, it loses the awareness of the potential larger
variance between seeds that can be detected by a more coarse-
grained metric. For instance, a metric measuring edge coverage
is unaware of whether two seeds exercise two different sets
of basic blocks or the same set of basic blocks but through
different edges. Therefore, it is necessary to illuminate seed
similarity and diversity when using a more sensitive coverage
metric.
Clustering is a technique commonly used in data analysis
to group a set of similar objects. Objects in the same cluster
are more similar to each other than to those in a different
cluster. Inspired by this technique, we propose to perform seed
clustering so that seeds in the same cluster are similar while
seeds in different clusters are more diverse. In other words,
these clusters offer another perspective that allows a scheduler
to zoom in the similarity and diversity among seeds.
Based on the observation that
the sensitivity of most
coverage metrics for greybox fuzzing can be directly compared
(i.e., the more sensitive coverage metric can subsume the less
sensitive one), we propose an intuitive way to cluster seeds—
using a coarse-grained coverage measurement to cluster seeds
selected by a ﬁne-grained metric. That is, seeds in the same
cluster will have the same coarse-grained coverage measure-
ment. Moreover, we can use more than one level of clustering
to provide more abstraction at the top level and more ﬁdelity
at the bottom level. To this end, the coverage metric should
allow the co-existence of multiple coverage measurements. We
name such a coverage metric a multi-level coverage metric.
I ∈ I, and produces a set of features that are exercised by it
at least once, denoted as M ∈ Γ∗ .
Since coverage metric is mainly characterized by the cov-
erage space Γ, it can be simpliﬁed with the coverage space.
Some typical coverage metrics are:
execution.
• CF measures the functions that are exercised by an
• CB measures the blocks that are exercised by an execu-
• CE measures the edges that are exercised by an execution.
Finally, we give the deﬁnition of a multi-level coverage
tion.
1, . . . , Γ∗
metric.
(P × I) →
Deﬁnition III.3. A coverage metric C n :
(cid:104)Γ∗
n(cid:105) consists of a sequence of coverage metrics
(cid:104)C1, . . . , Cn(cid:105). It measures the execution of a program P ∈ P
with an input I ∈ I, and produces a sequence of measurements
(cid:104)M1, . . . , Mn(cid:105).
A multi-level coverage metric combines multiple metrics at
different levels to assess a seed. As a result, it relies on lower-
level coverage measurements to preserve minor variances
among seeds so that there will be more abundant seeds in
a chain. This helps to reduce the search space of ﬁnding bug
triggering test cases. Meanwhile, it allows a scheduler to use
upper-level measurements to detect major differences among
seeds. Note that when n = 1, it is reduced to a traditional
single level coverage metric.
D. Principles and Examples of Multi-level Coverage Metrics
To further illustrate how a multi-level coverage metric
works, we propose some representative examples. We ﬁrst
discuss some principles for developing an effective multi-level
coverage metric C n ∼ (cid:104)C1, . . . , Cn(cid:105) for fuzzing a program P .
1) Principles: Through the incremental seed clustering, all
seeds are put into a hierarchical tree that lays the foundation
of our hierarchical seed scheduling algorithm, which will be
described in §IV. However, the scheduling makes sense only
when a node at an upper level can have multiple child nodes
at lower levels. This indicates that the cases where if a set of
seeds are assessed to be with the same coverage measurement
Mi, all following measures Mi+1, . . . , Mn will also be the
same should be excluded. Motivated by this fundamental
requirement, the main principle is that measurements generated
by a less sensitive metric should always cluster seeds prior
to more sensitive ones. Here, we use the same deﬁnition of
sensitivity between two coverage metrics as in [45].
Deﬁnition III.4. Given two coverage metrics Ci and Cj, we
say Ci is “more sensitive” than Cj, denoted as Ci (cid:31)s Cj, if
(i) ∀P ∈ P, ∀I1, I2 ∈ I, Ci(P, I1) = Ci(P, I2) →
(ii) ∃P ∈ P, ∃I1, I2 ∈ I, Cj(P, I1) = Cj(P, I2) ∧
Cj(P, I1) = Cj(P, I2), and
Ci(P, I1) (cid:54)= Ci(P, I2)
Speciﬁcally, take the multi-level metric in Figure 2 as an
example. Seeds in the same MF clusters must have the same
function coverage. However, since ME is more sensitive than
5
Fig. 2: A multi-level coverage metric that measures function
coverage at top-level, edge coverage at mid-level, and ham-
ming distance of comparison operands at leaf-level. The root
node is a virtual node only used by the scheduler.
C. Incremental Seed Clustering
With the multi-level coverage metric in place, if a test
case is assessed as exercising a new coverage (feature) by
any of the measurements, it will be retained as a new seed
and put
in a proper cluster as described in Algorithm 2.
Generally, except for the top-level measurement M1 that
directly classiﬁes all seeds into different clusters, the following
lower-level measurement Mi (i = 2,··· , n) works on each of
the clusters generated by Mi−1 separately, classifying seeds in
it into smaller sub-clusters, which is named incremental seed
clustering.
In more detail, given a multi-level coverage metric as
shown in Figure 2, a test case exercising any new function,
edge, or distance coverage will be assessed as a new seed.
Then the root node starts the seed clustering. It will ﬁnd from
its child nodes an existing MF node that covers the same
functions as the new seed, or create a new MF node if the
desired node does not exist. Next, the seed clustering continues
in a similar way that puts the new seed into a ME node with
the same edge coverage. Finally, a child MD node of the ME
node is selected to save the new seed according to its distance
coverage.
Terms used in the algorithm are deﬁned as follows.
Deﬁnition III.1. A coverage space Γ deﬁnes the set of
enumerable features we pay attention to that can be covered
by executing a program.
Some typical coverage spaces are:
• ΓF is the set of all program functions.
• ΓB is the set of all program blocks.
• ΓE is the set of all program edges. Note that an edge is
a transition from one block to the next.
It is worth mentioning that in real-world fuzzers such as
AFL, the coverage information is recorded via well-crafted
hit_count maps. Consequently, the features are signiﬁed
by entries of the maps.
Deﬁnition III.2. A coverage metric C : (P × I) → Γ∗
measures the execution of a program P ∈ P with an input
rootMFMFMFMF. . .MEMEMEME. . .MDMDMDMD. . .MEMEMEMDMDMDMDMDMDAlgorithm 2: Seed Selection Algorithm
Input: test case I
Output: return a status code indicating whether I
triggers a bug or covers new features
Data: program being fuzzed P ,
existing seed set S∗,
existing feature set M∗,
current working cluster cc,
map from feature sets to sub clusters cc.map,
coverage metric C n ∼ (cid:104)C1, . . . , Cn(cid:105)
coverage measurements (cid:104)M1,··· , Mn(cid:105)
Result: put I in a proper cluster if it is a new seed
1 Function RunAndEval(I):
2
(cid:104)M1, . . . , Mn(cid:105) ←
RunWithInstrument(P, I, C n)
if bug triggered then
return Bug
end
M t ← M1 ∪ ··· ∪ Mn
if M t ⊆ M∗ then
return Known
M∗ ← M∗ ∪ M t
foreach i ∈ {1, . . . , n} do
next_cc ← cc.map[Mi]
if next_cc = N U LL then
else
next_cc ← new_cluster()
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19