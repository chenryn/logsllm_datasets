some of these cache levels or to the TLB as well, or to only
some cache levels in only one or more cores in a multi-core
architecture that become dedicated for allocating isolated ex-
ecution. The choice of which cache structures to apply this to
and how many ways to isolate in the subcache is delegated
to the hardware designer, given that it is a more complex de-
sign decision with other metrics and trade-offs that come into
play such as the size of the structure, power consumption,
and logic overhead. The power consumption and timing over-
heads associated with building and routing a fully-associative
cache lookup in VLSI are signiﬁcant, but can be alleviated
by leveraging emerging hybrid memory technologies such as
DRAM-based caches [48] and STT-MRAM caches [30, 31].
In practice, applying HYBCACHE to the LLC or larger caches
in general would be more expensive (in terms of hardware)
than L1 and L2 caches, and strict partitioning might be ap-
plied instead for the LLC. Nevertheless, HYBCACHE can
be, in principle, applied to sliced Intel LLCs. In each slice,
a number of cache ways (subcache) is reserved for isolated
execution. Any mapping from the IDID to the LLC slices
can be used, such that lines from a particular IDID are allo-
cated to a speciﬁc slice. Fully-associative lookups are thus
only be performed on the subcache portion of a single slice,
thus reducing the performance overheads and allowing scal-
ing to high-core-count processors. The slice-mapping would
be based only on the IDID, and thus it would not leak any
information about the data address or value.
Other design decisions in HYBCACHE include the number
of bits designated for IDID and thus the maximum number of
concurrent isolation domains supported (see Section 4.4). To
support more isolation domains (not concurrently) than the
hardwired maximum, the cache lines of one domain can be
ﬂushed by the kernel or microcode at context switching while
the next domain is switched in and is re-assigned the available
IDID. Nevertheless, supporting too many isolation domains
will result in increased cache utilization, and the overall per-
formance will suffer. This is in line with conventional cache
behavior, but is aggravated in HYBCACHE because isolated
execution is only allowed to utilize the subcache portion.
However, this violates our working assumption A2 that only
the minority of the workload requires cache-level isolation.
We emphasize that cache-based side-channel leakage di-
rectly results from the design of the cache microarchitecture
and, thus, it is reasonable to investigate the fundamental mi-
croarchitectural designs of caches for upcoming processor
designs. While this does not address the problem for legacy
systems, it provides an exploratory ground of ideas for upcom-
ing processor designs. HYBCACHE is architecture-agnostic
USENIX Association
29th USENIX Security Symposium    463
and can be integrated with any processor architecture (we
simulated it for x86 and implemented it for RISC-V). It is
also compliant with any set-associative cache architecture in-
dependent of its hierarchy and organization, and whether it is
virtually or physically indexed since no indexing is involved.
Intra-Process Isolation Support. HYBCACHE can also
be extended, in principle, to provide ﬁne-grained run-time
conﬁguration of the isolation domain within a process, e.g.,
between different threads within the same process. Besides
kernel support, this requires an instruction extension to en-
able isolation of particular code regions or threads to different
IDIDs or disable isolation altogether at run-time (reset its
run-time IDID to all-zero). However, this requires the devel-
oper to identify and annotate security-sensitive code regions.
Nevertheless, this is useful in practice since a process might
not require cache-based side-channel resilience for its entirety
but only for sensitive code such as cryptographic computa-
tions. This is a more generalizable approach that is easier and
more directly applicable than implementing leakage-resilient
variants for security/privacy-sensitive computations.
Deployment Assumptions. HYBCACHE assumes any
TEE or trusted computing environment that is leveraged in
compliance with their original design intent, i.e., that the
much larger portion of the execution workload is not security-
critical and only a smaller portion is security-critical and
isolated in an I-Domain (A2). Otherwise, if the workload
is equally balanced, the isolated execution subset would be
restricted to a smaller partition of the cache and would in-
cur a more than tolerable performance degradation especially
if it is cache-sensitive. For HYBCACHE to be optimally ad-
vantageous, the workload distribution and allocation must be
performed by the administrator such that the right balance of
overall security and performance is achieved, as shown by the
performance results in Section 6.1.
8 Related Work
We describe next the state of the art in existing defenses and
their shortcomings that HYBCACHE overcomes.
8.1 Partitioning
Cache partitioning allocates to each process or security do-
main a separate partition of the cache, hence guaranteeing
strict non-interference. Both software-based [20, 40, 51, 82]
and hardware-based [24,41,72,73] partitioning schemes have
been proposed in recent years, where partitioning is either
process-based or region-based.
Process-based partitioning. Godfrey [20] implements
process-based cache partitioning using page coloring on Xen,
which incurs a prohibitive performance overhead with increas-
ing number of processes. SecDCP [72] is a way-partitioning
scheme where each application is assigned a security class
and cache partitioning between the security classes is dynam-
ically managed according to the cache demand of non-secure
applications. SecDCP is not scalable; selective cache ﬂushing
and repartitioning is required if the number of security classes
exceeds that of allocated partitions and it may perform worse
than static partitioning. Furthermore, both schemes do not
support the use of shared libraries. CacheBar [82] periodically
conﬁgures the maximum number of ways allocated to each
process which unfairly impacts performance and cache uti-
lization, and does not scale well with the number of security
domains. DAWG [41] partitions the caches where different
processes are assigned to different protection domains isolat-
ing cache hits and misses. The aforementioned schemes incur
the performance overhead for the entire code, whereas HYB-
CACHE only enables side-channel resilience and the resulting
performance overhead only for the isolated execution.
Sanctum [14] protects TEEs by ﬂushing private caches
whenever the processor switches between enclave mode and
normal mode and partitioning of the LLC and assigning to
each enclave a static number of sets. Sets allocated to an
enclave can be used exclusively by the enclave and cannot be
utilized by the OS. On the contrary, HYBCACHE allows for
a ﬂexible and dynamic sharing of cache resources between
processes (thus improving performance), while preserving
cache side-channel resilience for isolated execution.
Many cache partitioning and allocation schemes [37, 55,
64, 65, 75] have been proposed that focus on cache alloca-
tion mechanisms aiming to improve performance for multi-
core caches. However, such schemes do not provide security
guarantees. HYBCACHE addresses the security/performance
trade-off by providing a conﬁgurable means to enable the side-
channel resilience only for isolated execution while providing
non-isolated execution with unaltered performance.
Region-based partitioning. These approaches split the
cache into a secure partition reserved for security/privacy-
critical memory pages and a non-secure partition for the
remaining memory pages. STEALTHMEM [40] uses page
coloring where several pages are colored and reserved for
security-sensitive data and they remain locked in cache. CAT-
alyst [51] leverages Intel’s CAT (Cache Allocation Technol-
ogy) [3] to divide the cache into secure and non-secure par-
titions and uses page coloring within the secure partition to
isolate different processes’ cache accesses to these pages.
PLcache [73] locks cache lines and allocates them exclusively
to particular processes such that the cache line can only be
evicted by its process. However, overall performance and
fairness of cache utilization are strongly impacted as the pro-
tected memory size increases in relevance to the total cache
capacity. Moreover, with PLcache an attacker process may
still infer the victim’s memory accesses by observing that it
is unable to access or evict cache lines (locked by a victim
process) from a particular cache set.
Cloak [24] uses hardware transactional memory, such as In-
tel TSX [2], to protect sensitive computations by pre-loading
the security-critical code and data into the cache at the begin-
464    29th USENIX Security Symposium
USENIX Association
ning of the transaction and any cache line evictions are de-
tected by the transaction aborting. Cloak incurs prohibitively
high performance overhead for memory-intense computations
and requires the developer’s strong involvement to identify
and instrument security-sensitive code and split it into sev-
eral transactions. Recent works have also explored the LLC
inclusion property for defense schemes such as RIC [39] and
SHARP [76]. However, both are architecture-speciﬁc, RIC
requires coherence protocol modiﬁcations and cache ﬂushing
on thread migration, while SHARP requires modiﬁcations to
the clﬂush instruction. HYBCACHE, however, is architecture-
agnostic, and does not require cache ﬂushing or modiﬁcations
to coherence protocols or the clﬂush instruction.
8.2 Randomization
Introducing randomization involves introducing noise or de-
liberate slowdown to the system clock to hinder the accuracy
of timing measurements as in FuzzyTime [32] and Time-
Warp [57]. These techniques can only defeat attacks which
rely on measuring access latency, but cannot prevent other
attacks such as alias-driven attacks [28]. They compromise
the precision of the clock for the remaining workload, thus
affecting functionality requirements.
RPCache [73] randomizes the mapping of all memory lines
of a protected application at a per-set granularity from their
actual cache set to a randomly mapped cache set, by using a
permutation table. NewCache [53] randomizes the mapping at
a per-line granularity using a Random Mapping Table. Both
RPCache and NewCache schemes do not scale well with
the number of lines in the cache (not applicable for larger
LLCs) and the number of protected domains. Random Fill
Cache [52] mitigates only reuse-based cache collision attacks
by replacing deterministic fetching with randomly ﬁlling the
cache within a conﬁgurable neighborhood window whose
size impacts the performance degradation incurred. It does
not scale well with an increasing TEE size.
Time-Secure Cache [69] uses a set-associative cache in-
dexed with a keyed function using the cache line address and
Process ID as its input. However, a weak low-entropy index-
ing function is used, thus re-keying is frequently required
followed by cache ﬂushing which requires complex manage-
ment and impacts performance. CEASER [63] also uses a
keyed indexing function but without the Process ID, thus also
requiring frequent re-keying of its index derivation function
and re-mapping to limit the time interval for an attack. A con-
current work, ScatterCache [74], uses keyed cryptographic
indexing that depends on the security domain, where cache
set indexing is different and pseudo-random for every domain
but consistent for any given key. Thus, re-keying may still
be required at time intervals to hinder the proﬁling and ex-
ploitation efforts of an adversary attempting to construct and
use an eviction set to collide with the victim access of inter-
est. HYBCACHE, on the other hand, leverages randomization
by disabling set-associativity altogether and using random
replacement for isolated execution. Every given memory ad-
dress can be cached in any of the available subcache ways and
placement is random and unpredictable; it varies randomly
every time the same memory line is brought in cache.
9 Conclusion
In this paper, we proposed a generic mechanism for ﬂexi-
ble and "soft" partitioning of set-associative memory struc-
tures and applied it to multi-core caches, which we call HY-
BCACHE. HYBCACHE effectively thwarts contention-based
and access-based cache attacks by selectively applying side-
channel-resilient cache behavior only for code in isolated
execution domains (e.g., TEEs). Meanwhile, non-isolated ex-
ecution continues to utilize unaltered and conventional cache
behavior, capacity and performance. This addresses the persis-
tent performance/security trade-off with caches by providing
the additional side-channel resilience guarantee, and the re-
sulting performance degradation, only for the security-critical
execution subset of the workload (usually isolated in a TEE)
by eliminating the fundamental causes of these attacks. We
evaluated HYBCACHE with the SPEC CPU2006 benchmark
and show a performance overhead of up to 5% for isolated
execution and no overhead for the non-isolated execution.
Acknowledgments
We thank our anonymous reviewers for their valuable and con-
structive feedback. We also acknowledge the relevant work
of Tassneem Helal during her bachelor’s thesis. This work
was supported by the Intel Collaborative Research Institute
for Collaborative Autonomous & Resilient Systems (ICRI-
CARS), the German Research Foundation (DFG) through
CRC 1119 CROSSING P3, and the German Federal Ministry
of Education and Research through CRISP.
References
[1] INTEL. Intel Xeon Processors. https://www.intel.com/
content/www/us/en/products/processors/xeon.html,
2009.
[2] INTEL. Intel 64 and IA-32 Architectures Software De-
veloper’s Manual.
https://www.intel.com/content/
dam/www/public/us/en/documents/manuals/64-ia-32-
architectures-software-developer-instruction-
set-reference-manual-325383.pdf, 2016.
[3] INTEL.
Introduction
to Cache Allocation
Tech-
nology in the Intel Xeon Processor E5 v4 Family.
https://software.intel.com/en-us/articles/
introduction-to-cache-allocation-technology,
2016.
[4] Reading
privileged memory with
a
side-channel.
https://googleprojectzero.blogspot.com/2018/
USENIX Association
29th USENIX Security Symposium    465
01/reading-privileged-memory-with-side.html,
2018.
[5] Onur Aciiçmez, Çetin Kaya Koç, and Jean-Pierre Seifert. On
the power of simple branch prediction analysis. ACM Sympo-
sium on Information, computer and communications security,
pages 312–320, 2007.
[6] Onur Acıiçmez, Çetin Kaya Koç, and Jean-Pierre Seifert. Pre-
dicting secret keys via branch prediction. Cryptographers’
Track at the RSA Conference, pages 225–242, 2007.
[7] ARM Limited.
Secure
a
ARM Security Technology – Build-
System using TrustZone Technol-
http://infocenter.arm.com/help/topic/
ing
ogy.
com.arm.doc.prd29-genc-009492c/PRD29-GENC-
009492C_trustzone_security_whitepaper.pdf, 2009.
[8] Daniel J Bernstein. Cache-timing attacks on aes. 2005.
[9] Nathan Binkert, Bradford Beckmann, Gabriel Black, Steven K.
Reinhardt, Ali Saidi, Arkaprava Basu, Joel Hestness, Derek R.
Hower, Tushar Krishna, Somayeh Sardashti, Rathijit Sen, Ko-
rey Sewell, Muhammad Shoaib, Nilay Vaish, Mark D. Hill, and
David A. Wood. The Gem5 Simulator. SIGARCH Computer
Architecture News, 39(2), 2011.
[10] Joseph Bonneau and Ilya Mironov. Cache-collision Timing
Attacks Against AES. In International Conference on Crypto-
graphic Hardware and Embedded Systems (CHES). Springer-
Verlag, 2006.
[11] Ferdinand Brasser, Urs Müller, Alexandra Dmitrienko, Kari
Kostiainen, Srdjan Capkun, and Ahmad-Reza Sadeghi. Soft-
ware Grand Exposure: SGX Cache Attacks Are Practical.
In USENIX Workshop on Offensive Technologies (WOOT).
USENIX Association, 2017.