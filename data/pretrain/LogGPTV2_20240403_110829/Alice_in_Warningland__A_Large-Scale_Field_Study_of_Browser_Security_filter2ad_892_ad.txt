### 4.2 Certificate Error Persistence
Our study also reveals that these mechanisms are not a panacea: name mismatch errors constitute a significant portion of the remaining issues, and new systems like Perspectives and Convergence still perform this check. It is important to note that Convergence does not verify the certificate issuer, relying instead on network views, but it does conduct name checks [10].

### 5.2.4 Additional SSL Metrics
To complement the overall clickthrough rates, we collected several additional metrics.

**Additional Information:**
Both Google Chrome and Mozilla Firefox provide additional information about the warning through links. However, very few users took the opportunity to view this extra information. The "Help me understand" button in Google Chrome was clicked during only 1.6% of SSL warning impressions. For Mozilla Firefox warnings, no users clicked on "Technical Details," and only 3% of viewers of the "Add Exception" dialog clicked on "View Certificate." This suggests that the additional content has minimal impact on the overall clickthrough rates.

**Add Exception Cancellation:**
Not all Mozilla Firefox users proceed to the page after opening the "Add Exception" dialog. In 14.6% of cases, the user cancels the exception. These occurrences indicate that at least a minority of users consider the text in the dialog before confirming the exception.

**Remember Exception:**
By default, the "Remember Exception" checkbox is checked in the Mozilla Firefox "Add Exception" dialog. Our measurements found that 21.3% of the time, the user un-ticks the checkbox. We hypothesize that these users remain wary of the website even if they choose to proceed.

### 6. Time Spent on SSL Warnings
SSL warnings can occur due to server misconfigurations, as well as man-in-the-middle (MITM) attacks. Previous work found that 20% of the thousand most popular SSL sites triggered false warnings due to such misconfigurations [31]. Consequently, it may be safe and rational to click through such false warnings. However, the prevalence of a large number of false warnings can potentially train users to disregard all SSL warnings without considering the context.

To determine whether users examine SSL warnings before making a decision, we measured the time spent on SSL warning pages. This section compares the click times by outcome (clickthrough or leave) and error type to gain insight into user attention. Our timing data includes all operating systems and channels.

#### 6.1 Time by Outcome
Figure 6 presents the click times for different outcomes. Users who leave spend more time on the warning than those who click through and proceed to the page. Specifically, 47% of users who clicked through the warning made the decision within 1.5 seconds, whereas 47% of users who left the page did so within 3.5 seconds. This suggests that users who click through the warning often do so with less consideration.

#### 6.2 Time by Error Type
Figure 7 depicts the click times for three error types: untrusted authority, name mismatch, and expired certificate errors. Users clicked through 49% of untrusted issuer warning impressions within 1.7 seconds, but clicked through 50% of name and date errors within 2.2 seconds and 2.7 seconds, respectively. This data is indicative of warning fatigue, where users click through more frequent errors more quickly. The frequency and clickthrough rate of each error type (as reported in Section 5.2) are inversely correlated with the error type’s timing variance and mode (Figure 7).

### 7. Implications
Our primary finding is that browser security warnings can be effective security mechanisms in practice, but their effectiveness varies widely. This should motivate more attention to improving security warnings. In this section, we summarize our findings and their implications, present suggestions for warning designers, and make recommendations for future warning studies.

#### 7.1 Warning Effectiveness

##### 7.1.1 Clickthrough Rates
Popular opinion holds that browser security warnings are ineffective. However, our study demonstrates that browser security warnings can be highly effective at preventing users from visiting websites. As few as one-tenth of users click through Firefox’s malware and phishing warnings, which we consider very successful. 

We found clickthrough rates of 18.0% and 23.2% for Google Chrome’s phishing and malware warnings, respectively, and 31.6% for Firefox’s SSL warning. These warnings prevent 70% (or more) of attempted visits to potentially dangerous websites. Although these warnings could be improved, we consider them successful at persuading and protecting users.

Google Chrome’s SSL warning had a clickthrough rate of 70.2%, which is undesirable. Either users are not heeding valid warnings, or the browser is annoying users with invalid warnings, possibly causing warning fatigue. Our positive findings for other warnings demonstrate that this warning has the potential for improvement. We hope this study motivates further research to determine and address the cause of its higher clickthrough rate. We plan to test an exception-remembering feature to investigate the influence of repeat exposures to warnings. At Google, we have also begun a series of A/B tests in the field to measure the impact of various improvements.

##### 7.1.2 User Attention
Although we did not directly study user attention, two results of our study suggest that at least a minority of users pay attention to browser security warnings:

- There is a 24.4-point difference between the clickthrough rates for untrusted issuer errors (81.8%) and expired certificate errors (57.4%) in Google Chrome.
- 21.3% of the time that Mozilla Firefox users viewed the "Add Exception" dialog, they un-checked the default "Permanently store this exception" option.

These results contradict the stereotype of wholly oblivious users with no interest in security.

#### 7.2 Comparison with Prior Research
As Bravo-Lillo et al. wrote [5]:
"Evidence from experimental studies indicates that most people don’t read computer warnings, don’t understand them, or simply don’t heed them, even when the situation is clearly hazardous."

In contrast, a majority of users heeded five of the six types of browser warnings we studied. This section explores why our results differ from prior research.

**Browser Changes:**
Most prior browser research was conducted between 2002 and 2009, a period of rapid browser evolution. Some changes were directly motivated by published user studies. Notably, passive indicators are no longer considered primary security tools, and phishing toolbars have been replaced with full-page interstitial warnings. Therefore, studies of passive indicators and phishing toolbars no longer represent the state of modern browser technology.

Two studies tested an older version of the Mozilla Firefox SSL warning, which was a modal (instead of full-page) dialog. Dhamija et al. observed a 68% clickthrough rate, and Sunshine et al. recorded clickthrough rates of 90%-95% depending on the type of page [11, 31]. The change in warning design could be responsible for our lower observed clickthrough rates.

**Ecological Invalidity:**
Sunshine et al. and Sotirakopoulos et al. recorded 55%-60% and 80% clickthrough rates, respectively, for a slightly outdated version of the Mozilla Firefox SSL warning [30, 31]. They evaluated the Firefox 3 and 3.5 warnings, which had the same layout and appearance as the current (Firefox 4+) warning but with different wording. It’s possible that changes in wording caused clickthrough rates to drop from 55%-80% to 33.0%. However, during an exit survey, 46% of Sotirakopoulos’s subjects said they clicked through the warning because they either felt safe in the laboratory environment or wanted to complete the task [30]. Since their study methodology was intentionally similar to the Sunshine study, Sotirakopoulos et al. concluded that both studies suffered from biases that raised their clickthrough rates [30]. We attribute some of the discrepancy between our field study data and these two laboratory studies to the difficulty of establishing ecological validity in a laboratory environment.

In light of this, we recommend a renewed emphasis on field techniques for running and confirming user studies of warnings. Although we used in-browser telemetry, there are other ways of obtaining field data. For example, experience sampling is a field study methodology that asks participants to periodically answer questions about a topic [2, 6, 9, 28]. Researchers could install a browser extension on participants’ computers to observe their responses to normally occurring warnings and display a survey after each warning. This technique allows researchers to collect data about participants’ emotions, comprehension, and demographics. Participants may become more cautious or attentive to warnings if the purpose of the study is apparent, so researchers could obscure the purpose by surveying subjects about other browser topics. Network-based field measurements also provide an alternative methodology with high ecological validity. A network monitor could maintain its own copy of the Safe Browsing list and identify users who click through warnings. If the monitor can associate network flows with specific demographics, it can help understand the impact of these factors on user behavior. Similar studies could help understand SSL clickthrough rates; recent work addressed how to reproduce certificate validation at the network monitor [1].

**Warning Fatigue:**
Our findings support recent literature that has modeled user attention to security warnings as a finite resource [4] and proposed warning mechanisms based on this constraint [14]. Based on this finding, we echo the recommendation that security practitioners should limit the number of warnings that users encounter. Designers of new warning mechanisms should always perform an analysis of the number of times the system is projected to raise a warning, and security practitioners should consider the effects that warning architectures have on warning fatigue.

**More Information:**
Users rarely click on explanatory links such as "More Information" or "Learn More" (Section 5.2.4). Designers who utilize such links should ensure that they do not hide details that are important to the decision-making process. Mozilla Firefox places information about SSL errors under "Technical Details" and in the "Add Exception" dialog instead of the primary warning. Thus, the error type has little impact on clickthrough rates. In contrast, Google Chrome places error details in the main text of its SSL warning, and the error has a large effect on user behavior. It is possible that moving this information into the primary warning could improve user engagement and reduce clickthrough rates.