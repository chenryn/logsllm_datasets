existing user training with permission screens. However,
unlike Android, FlowFence users are requested to autho-
rize flows rather than permissions, ensuring their control
over how apps use data. If a user approves a set of flows,
FlowFence guarantees that only those flows can occur.
Past work has shown that users often do not compre-
hend or ignore prompts [25], however, existing research
does point out interesting directions for future work in
improving such systems. Felt et al. discuss techniques to
better design prompting mechanisms [23], and Roesner
et al. discuss contextual prompting [50, 51] as possible
improvements.
5 Evaluation
We evaluated FlowFence from multiple perspectives.
First, we ran a series of microbenchmarks to study call
latency, serialization overhead, and memory overhead
of FlowFence. We found that FlowFence adds mod-
est computational and memory costs. Running a sand-
box takes 2.7MB RAM on average, and running multiple
such sandboxes will fit easily within current hardware
for IoT hubs.7 We observed a 92ms QM call latency
with 4 spare sandboxes, which is comparable to the la-
tency of common network calls in IoT apps. FlowFence
supports a maximum bandwidth of 31.5MB/s for trans-
ferring data into sandboxes, which is large enough to ac-
commodate typical IoT apps. Second, we ported three
IoT apps to FlowFence to examine developer effort, se-
curity, and impact of FlowFence on macro-performance
factors. Our results show that developers can use Flow-
Fence with modest changes to their apps and with ac-
ceptable performance impact, making FlowFence practi-
cal for building secure IoT apps. Porting the three apps
required adding 99 lines of code on average per app. We
observed a 4.9% latency increase to perform face recog-
nition in a door controller app. More details follow.
5.1 Microbenchmarks
We performed our microbenchmarks on an LG Nexus 4
running FlowFence on Android 5.0. The Nexus 4 serves
as our “IoT hub” that runs QMs and enforces flow poli-
cies. In our experiments, we evaluated three factors that
can affect apps running on FlowFence.
Memory overhead. We evaluated memory overhead of
FlowFence using the MemoryInfo API. We ran Flow-
Fence with 0 − 15 empty sandboxes and recorded the
memory consumption. Our results show that the Flow-
Fence core requires 6.35MB of memory while each sand-
box requires 2.7MB of memory on average. To put this
in perspective, LG Nexus 4 has 2GB memory and load-
ing a blank page on the Chrome browser on it used 98MB
of memory, while loading FlowFence with 16 sandboxes
used 49.5MB. Therefore, we argue that the memory
overhead of FlowFence is within acceptable limits for the
platform.
QM Call Latency. We measured QM call latency for
non-tainted and tainted parameters (30 trials each with
100 QM call-reply sequences) to assess performance in
scenarios that allowed reuse of a sandbox without san-
itizing and those that required sanitizing. For tainted
calls, each QM takes a single boolean parameter that is
tainted. We also varied the number of clean spare sand-
boxes that are available for immediate QM scheduling
initially before each trial. Regardless of the number of
spare sandboxes, untainted calls (which did not taint the
sandboxes and thus could reuse them without sanitiz-
ing) showed a consistent latency of 2.1ms (SD=0.4ms).
The tainted calls were made so as to always require
a previously-tainted sandbox to be sanitized. Figure 3
shows average latency of tainted calls across 30 trials for
different number of spare sandboxes. As the number of
spare sandboxes increases from 0 to 4, the average call
7For example, Samsung SmartThings hub has 512MB RAM [56],
and Apple TV hub has 1GB RAM [7].
540  25th USENIX Security Symposium 
USENIX Association
)
s
m
(
y
c
n
e
t
a
L
l
l
a
C
e
g
a
r
e
v
A
 350
 300
 250
 200
 150
 100
 50
 0
 0
 2
 4
 6
 8
 10
 12
 14
Number of Spare Sandboxes
Figure 3: QM Call latency of FlowFence given vari-
ous number of spare sandboxes, for calls that require
previously-used sandboxes to be sanitized before a call.
Calls that can reuse sandboxes without sanitizing (un-
tainted calls in our tests) show a consistent latency of
2.1ms, which is not shown in this graph.
)
S
/
e
t
y
B
(
h
t
d
i
w
d
n
a
B
26
24
22
20
18
16
14
12
10
2
2
2
2
2
2
2
2
2
0
2
5
2
10
2
15
2
20
2
25
2
30
2
Data Size (Byte)
Figure 4: Serialization bandwidth for different data sizes.
Bandwidth caps off at 31.5MB/s.
latency decreases from 328ms to 92ms. Further increase
in the number of spare sandboxes does not improve la-
tency of QM calls. At 4 spares, the call latency is less
than 100ms, making it comparable to latencies seen in
controlling many IoT devices (e.g., Nest, SmartThings
locks) over a wide-area network. This makes QMs espe-
cially suitable to run existing IoT apps that already accept
latencies in this range.
Serialization Overhead.
To understand FlowFence
overhead for non-trivial data types, we computed seri-
alization bandwidth for calls on QMs that cross sand-
box boundaries with varying parameter sizes. Figure 4
presents the results for data ranging from 4B to 16MB.
The bandwidth increases as data size increases and caps
off at 31.5MB/s. This is large enough to support typical
IoT apps—for example, the Nest camera uses a maxi-
mum bandwidth of 1.2Mbps under high activity [33]. A
single camera frame used by one of our ported apps (see
below), is 37kB, requiring transferring data at 820kB/s
to a QM.
5.2 Ported IoT Applications
We ported three existing IoT apps to FlowFence to mea-
sure its impact on security, developer effort, end-to-end
latency, and throughput on operations relevant to the
apps (Table 2). SmartLights is a common smart home
app (e.g., available in SmartThings) that computes a
predicate based on a location value from a beacon such
as a smartphone, or car [47]. If the location value inside
the home’s geofence, the app turns on lights (and adjusts
other devices like thermostats) around the home. When
the location value is outside the home’s geofence, the app
takes the reverse action.
FaceDoor performs face recognition and unlocks a
door, if a detected face is authorized [34]. The app uses
the camera to take an image of a person at the door,
and runs the Qualcomm face recognition SDK (chipset-
specific native code, available only as a binary).
HeartRateMonitor accesses a camera to compute heart
rate using photoplethysmography [67]. The app uses im-
age processing code on streamed camera frames.
FlowFence provides trusted API to access switches,
locks, and camera frames. These three existing apps
cover the popular IoT areas of smart homes and quan-
tified self. Furthermore, face recognition and camera-
frame-streaming apps are among the more computation-
ally expensive types of IoT apps, and stress test Flow-
Fence performance. We ran all our experiments on An-
droid 5.0 (Nexus 4).
Security. We discuss data security risks that each of the
three IoT apps pose when run on existing platforms, and
find that FlowFence eliminates those risks successfully
under leakage tests.
1) SmartLights: It has the potential to leak location infor-
mation to attackers via the Internet. The app has Internet
access for ads, and crash reporting. On FlowFence, the
developer separates code that computes on location in a
QM which isolates the flow: loc → switch, while al-
lowing other code to use the Internet freely.
2) FaceDoor: This app can leak camera data to the In-
ternet. We note that this app requires Internet access
for core functionality—it sends a notification to the user
whenever the door state changes. Therefore, under cur-
rent IoT frameworks it is very easy for this app to leak
camera data. FlowFence isolates the flow of camera
and door state data to door locks from the flow of door
state data to the Internet using two QMs, eliminating
any possibility of cross-flows between the camera and
the Internet. This app uses the flows: cam → lock,
doorstate → lock, doorstate → Internet.
3) HeartRateMonitor: The app can leak images of peo-
ple, plus heart rate information derived from the camera
stream. However, similar to previous apps, the developer
of this app too will use FlowFence support to isolate the
USENIX Association  
25th USENIX Security Symposium  541
Name
Description
Data Security Risk
without FlowFence
LoC
original
LoC
FlowFence
Flow Request
SmartLights [47]
FaceDoor [34]
HeartRateMonitor [67]
Reads a location beacon
and if the beacon is inside a
geofence around the home,
automatically turn on the
lights
Uses a camera to recognize
a face; If the face is
authorized, unlock a
doorlock
Uses a camera to measure
heart rate and display on UI
App can leak user
location information
118
193
loc → switch
App can leak images of
people
322
456
cam → lock,
doorstate → lock,
doorstate → net
App can leak images of
people, and heart rate
information
257
346
cam → ui
Table 2: Features of the three IoT apps ported to FlowFence. Implementing FlowFence adds 99 lines of code on
average to each app (less than 140 lines per app).
flow: cam → ui into a QM. We note that in all apps, the
QMs can return opaque handles to the pieces of code not
dealing with sensitive information, where the handle can
be leaked, but this is of no value to the attacker since a
handle is not sensitive data.
Developer Effort. Porting apps to FlowFence requires
converting pieces of code operating on sensitive data
to QMs. On average, 99 lines of code were added to
each app (Table 2). We note that typical IoT apps today
are relatively small in size compared to, say, Android
apps. The average size across 499 apps for which we
have source code for SmartThings platform is 162 line of
source code. Most are event-driven, receiving data from
various publishers that they are authorized to at install
time and then publish to various sinks, including devices
or Internet. Much of the extra code deals with resolving
the appropriate QMs, and creating services to communi-
cate with FlowFence. It took a developer with no prior
knowledge of the FlowFence API to port the first two
apps in two 8-hour (approx.) days each, and the last app
in a single day. We envision that with appropriate devel-
oper tool support, many boiler plate tasks, including QM
resolution, can be automated. We note that the increase
in LoC is not co-related to the original LoC of the app.
Instead, there is an increase in LoC only for pieces of the
original app that deals with sensitive data. Furthermore,
it is our experience that refactoring an existing app re-
quires copying logic as-is, and building QMs around it.
For instance, we did not have source-code access to the
Qualcomm Face Recognition SDK, but we were able to
successfully port the app to FlowFence.
Porting FaceDoor. Here, we give an example of the
steps involved in porting an app. First, we removed
all code from the app related to camera access, because
FlowFence provides a camera API that allows QMs to
take pictures, and access the corresponding bitmaps.
Next, we split out face recognition operations into its
own Quarantined Module—QMrecog, that loads the na-
tive code face recognition SDK. We modified QMrecog
to use the Trusted API to access a camera image, an
operation that causes it to be tainted with camera data.
We modified the pieces of code related to manipulating
a ZWave lock to instead use FlowFence-provided API
for accessing door locks. We also created QMreport that
reads the door state source and then sends a notification
to the user using the Internet. These two QMs isolate
the flow from camera and door state to door lock, and
the flow from door state to the Internet, effectively pre-
venting any privacy violating flow of camera data to the
Internet, which would otherwise be possible with current
IoT frameworks.
End-to-End Latency. We quantified the impact of Flow-
Fence on latency for various operations in the apps that
are crucial to their functionality. We measured latency as
the time it takes for an app to perform one entire com-
putational cycle. In the case of SmartLights, one cycle
is the time when the beacon reports a location value,
till the time the app issues an operation to manipulate
a switch. We observed a latency of 160ms (SD=69.9)
for SmartLights in the baseline case, and a latency of
270ms (SD=96.1) in the FlowFence case. The reason
for increased latency is due to QM load time, and cross-
process transfers of the location predicate value.
FaceDoor has two operations where latency matters.
First, the enroll latency is the time it takes the app to ex-
tract features from a provided bitmap of a person’s face.
Second, recognition latency is the time it takes the app to
match a given bitmap of a person’s face to an item in the
app’s database of features. We used images of our team
members (6), measuring 612x816 pixels with an average
542  25th USENIX Security Symposium 
USENIX Association
)
s