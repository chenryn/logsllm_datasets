m
x
t
m
t
s
n
j
b
o
d
n
r
v
i
s
c
t
s
Figure 13. Execution overhead of replacing return with the pop and jmp
sequence in programs of the LLVM Shootout suite. Each box contains eight
executions. The higher the average, the higher the overhead.
Hardware It is not straightforward to estimate the overhead
of false positive detection, at the hardware level, when used
in tandem with our system. Considering the ﬁltering statistics
of Layers 1 and 2 combined (Section IV-B), we can expect
that the third layer will be activated for less than 0.03% of
the indirect branches in a program. Thus, veriﬁcation `a la
CFImon does not incur a cost that we can measure reliably.
Nevertheless, we can rely on previous work to put an upper
bound on the expected overhead of a hardware implementation
of Layer 3. CFIMon authors claim an overhead of about 6.1%
to execute all their solution and point out that 86% of this cost
is due only to the code for recording executed branches, carried
out through their “pure BTS” implementation. Therefore, the
rest of CFIMon, including the tracking code and the treatment
of false positives, accounts for an overhead of no more than
0.9%. Notice that every branch target is sanitized in CFIMon.
In our case, this overhead will be imposed upon a negligible
number of indirect branches, as we explained in Section IV-B.
Therefore, we expect a much lower cost. More importantly,
this veriﬁcation does not
impose any overhead upon the
branches that do not reach the third layer.
325
V. RELATED WORK
a) On the techniques reused in our multi-layer system:
The idea of combining different defense mechanisms in layers,
so that low-overhead protections are used to gradually ﬁlter
safe control-ﬂows, is an original contribution of this paper.
Nevertheless, except for the veriﬁcation of executable targets,
discussed in Section III-B, our defense layers reuse techniques
presented in previous work. Our rational when choosing which
technique to apply on each layer was based on two tenets: (i)
upper layers – which are applied ﬁrst – should have lower
computational overhead; and (ii) work done in upper layers
should not be redone in lower layers.
Our uppermost
layer, which certiﬁes targets of indirect
branches via the branch predictor, has already been described
as early as 2007, by Shi and Lee [57], right after Hovav
Shacham [1] introduced the concept of Return-Oriented Pro-
gramming. More recent works have revisited this concept in
an attempt to block ROP attacks [64]–[66]. Other proposals
use the number of mispredictions of indirect branches as an
attack indication [67], [68]. We adopt the inverse perspective:
correct predictions of indirect branches indicate authentic
executions. Execution ﬂows that we cannot validate using
branch prediction ﬂow into lower layers of our system. The
previous literature doesn’t talk about this multi-layer approach.
The idea of checking if the address before the target of a
return is a call instruction has been independently described
by previous works. Carlini et al. [23] provide a comprehensive
overview of the related literature. The fact that Carlini et al.
have been able to circumvent this kind of defense led us to
conceive the Executable Target Constraint that we described in
Section III-B. We designed this test to be easily implemented,
once the call-validation mechanism is in place.
The technique that we use to ﬁlter out false positives,
discussed in Section III-C was ﬁrst suggested by Zhang and
Sekar [43]. We adopted the same strategy deﬁned in that work
because it is simple and computationally cheap. However, were
it used without our upper layers, then it would be too costly
to be practical. Finally, sandboxing, one of the alternatives
described in Section III-D to protect an application, when all
the upper layers fail to certify an indirect branch, is well-
known in the systems community.
b) How our overhead compares to previous works’:
The ultimate goal of this paper is to provide protection
against ROP attacks at a low computational cost. The lit-
erature contains much previous work with similar purpose.
For a comparison, we mention the overhead of eight recent
systems [9], [19], [21], [69]–[73] that enforce some sort of
Control Flow Integrity policy. We report overheads instead of
reproducing them ourselves because these tools have existed as
research artifacts only and they aren’t easily available today.
Some of these systems were only tested via software-based
prototypes, although they are meant to be implemented in
hardware; hence, some numbers that we shall mention are
estimates from their authors. SCRAP’s authors report
the
lowest overhead [71], between 1% and 2%; however, they use
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:52:59 UTC from IEEE Xplore.  Restrictions apply. 
a strategy based on controlling the frequency of small gadgets,
which has already been overcome in subsequent work [74]–
[76]. Kayaalp et al. report a 2% overhead for BR [70] –
same value reported by Lucas et al. for HAFIX [69] and
for Zipper Stack [72]. The same group had, before, proposed
MoCFI, with an overhead of 7% [19]. Veen et al. report
an overhead of 8.4% for PathArmor [9]. PittyPat’s original
presentation reports an overhead of 12.73% [21]. Finally,
Lockdown’s authors have measured a runtime slowdown of
19% [73]. Most of these techniques require some support from
the hardware. For instance, HAFIX requires changes in the
target architecture’s instruction set. Software-only approaches,
such as PittyPat, tend to present higher overhead, in addition
of requiring recompilation of the code that must be protected.
VI. CONCLUSION
This paper has presented a multilayer approach to hinder
Return-Oriented Programming attacks. Each layer of the pro-
posed system validates targets of indirect branches; hence,
proving that they belong to legitimate program ﬂows. Our key
insight is to combine layers, so that layer Li runs at a lower
computational cost than Li+1. A branch certiﬁed at Li does not
need to be checked at Li+1. We apply stronger enforcement
guarantees only onto cases that are hard to verify, because Li,
by construction, receives more branches than Li+1.
Recent developments showed that there exists no system
that is able to stop any ROP attack [23]. Ours is not an
exception to this rule: it still faces false positives and false
negatives. False positives happen if we ﬂag a legitimate branch
target as unsafe. The way in which the operating system treats
this kind of exception, be it through preemptive termination,
be it through sandboxing, impacts user experience. The exper-
iments seen in Section IV-B indicate that exceptions raised by
authentic program ﬂows are unlikely events, since our system
has a layer speciﬁcally designed to prevent such occurrences.
False negatives happen if we allow an attacker to bend the
control ﬂow of the protected application. Through a statistical
argument, we have shown in Section IV-A that our call-
validation constraint leaves a very small number of gadgets
available for the construction of an attack. Consequently, state-
of-the-art exploits, such as those carried out by Carlini et
al. [23] are not possible. The construction of attacks that
circumvent our protection is, therefore, an open problem.
ACKNOWLEDGEMENTS
We thank the anonymous reviewers and Marcus Botacin for
many suggestions that greatly improved this paper. This work
has been made possible by the ﬁnancial support of CNPq,
CAPES, FAPEMIG, Intel, and CEFET-MG, which granted
Mateus Tymburib´a his sabbatical.
REFERENCES
[1] H. Shacham, “The geometry of innocent ﬂesh on the bone: Return-into-
libc without function calls (on the x86),” in ACM SIGSAC Conference
on Computer and Communications Security, 2007.
[2] F.-S. R. Labs, “Threat
report,” 2013.
https://www.f-secure.com/
documents/996508/1030743/Threat Report H1 2013.pdf.
[3] B. Q. Minh and H. X. Minh, “How conﬁcker makes use of ms08-067,”
2009. http://security.bkav.com/home/-/blogs/how-conﬁcker-makes-use-
of-ms08-067/normal.
[4] D. H. Aleksandr Matrosov, Eugene Rodionov and J. Malcho, “Stuxnet
https://www.esetnod32.ru/company/
under
viruslab/analytics/doc/\Stuxnet Under the Microscope.pdf.
the microscope,” 2010.
[5] M. Gorelik, “[critical alert] cve-2018-4990 acrobat reader dc double-free
vulnerability,” 2018. http://blog.morphisec.com/critical-alert-cve-2018-
4990-acrobat-reader-dc-double-free-vulnerability.
[6] M. Seebug, “Tenda ac15 router
execution(cve-2018-5767),” 2018.
97161.
- unauthenticated remote code
https://vulners.com/seebug/SSV:
[7] D. Alvarez-Perez, “In depth analysis of malware exploiting cve-2017-
11826,” 2017. https://www.gradiant.org/noticia/analysis-malware-cve-
2017/.
[8] N. Burow, S. A. Carr, J. Nash, P. Larsen, M. Franz, S. Brunthaler, and
M. Payer, “Control-ﬂow integrity: Precision, security, and performance,”
ACM Computing Surveys, vol. 50, no. 1, 2017.
[9] V. van der Veen, D. Andriesse, E. G¨oktas¸, B. Gras, L. Sambuc,
A. Slowinska, H. Bos, and C. Giuffrida, “Practical context-sensitive
CFI,” in ACM SIGSAC Conference on Computer and Communications
Security, 2015.
[10] I. Evans, F. Long, U. Otgonbaatar, H. Shrobe, M. Rinard, H. Okhravi,
and S. Sidiroglou-Douskos, “Control jujutsu: On the weaknesses of
ﬁne-grained control ﬂow integrity,” in ACM SIGSAC Conference on
Computer and Communications Security, 2015.
[11] W. Lian, H. Shacham, and S. Savage, “A call to arms: Understanding
the costs and beneﬁts of JIT spraying mitigations,” in Internet Society
Symposium on Network and Distributed Systems Security, 2017.
[12] J. Lee, J. Jang, Y. Jang, N. Kwak, Y. Choi, C. Choi, T. Kim, M. Peinado,
and B. B. Kang, “Hacking in darkness: Return-oriented programming
against secure enclaves,” in USENIX Security Symposium, 2017.
[13] M. Abadi, M. Budiu, U. Erlingsson, and J. Ligatti, “Control-ﬂow in-
tegrity,” in ACM SIGSAC Conference on Computer and Communications
Security, 2005.
[14] D. Jang, Z. Tatlock, and S. Lerner, “SafeDispatch: Securing C++ virtual
calls from memory corruption attacks.,” in Network and Distributed
System Security Symposium, 2014.
[15] R. Gawlik and T. Holz, “Towards automated integrity protection of C++
virtual function tables in binary programs,” in Annual Computer Security
Applications Conference, 2014.
[16] C. Tice, T. Roeder, P. Collingbourne, S. Checkoway,
´U. Erlingsson,
L. Lozano, and G. Pike, “Enforcing forward-edge control-ﬂow integrity
in GCC & LLVM.,” in USENIX Security Symposium, 2014.
[17] A. Prakash, X. Hu, and H. Yin, “vfGuard: Strict protection for virtual
function calls in cots C++ binaries.,” in Network and Distributed System
Security Symposium, 2015.
[18] C. Zhang, C. Song, K. Z. Chen, Z. Chen, and D. Song, “VTint:
Protecting virtual function tables’ integrity.,” in Network and Distributed
System Security Symposium, 2015.
[19] L. Davi, A. Dmitrienko, M. Egele, T. Fischer, T. Holz, R. Hund,
S. N¨urnberger, and A.-R. Sadeghi, “MoCFI: A framework to mitigate
control-ﬂow attacks on smartphones.,” in Network and Distributed
System Security Symposium, 2012.
[20] M. Payer, A. Barresi, and T. R. Gross, “Fine-grained control-ﬂow
integrity through binary hardening,” in SIG SIDAR Conference on
Detection of Intrusions and Malware & Vulnerability Assessment, 2015.
[21] R. Ding, C. Qian, C. Song, B. Harris, T. Kim, and W. Lee, “Efﬁcient
protection of path-sensitive control security,” in USENIX Security Sym-
posium, 2017.
[22] L. Szekeres, M. Payer, T. Wei, and D. Song, “SoK: Eternal war in
memory,” in IEEE Symposium on Security and Privacy, 2013.
[23] N. Carlini, A. Barresi, M. Payer, D. Wagner, and T. R. Gross, “Control-
ﬂow bending: On the effectiveness of control-ﬂow integrity,” in USENIX
Security Symposium, 2015.
[24] V. van der Veen, D. Andriesse, M. Stamatogiannakis, X. Chen, H. Bos,
and C. Giuffrdia, “The dynamics of innocent ﬂesh on the bone: Code
reuse ten years later,” in ACM SIGSAC Conference on Computer and
Communications Security, 2017.
[25] V. Kiriansky, D. Bruening, S. P. Amarasinghe, et al., “Secure execution
via program shepherding.,” in USENIX Security Symposium, 2002.
[26] J. L. Henning, “Spec cpu2006 benchmark descriptions,” ACM SIGARCH
Computer Architecture News, vol. 34, no. 4, 2006.
326
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:52:59 UTC from IEEE Xplore.  Restrictions apply. 
[27] C. Lattner and V. Adve, “LLVM: A compilation framework for life-
long program analysis & transformation,” in IEEE/ACM International
Symposium on Code Generation and Optimization, 2004.
[28] C.-K. Luk, R. Cohn, R. Muth, H. Patil, A. Klauser, G. Lowney, S. Wal-
lace, V. J. Reddi, and K. Hazelwood, “Pin: Building customized program
analysis tools with dynamic instrumentation,” in ACM SIGPLAN Con-
ference on Programming Language Design and Implementation, 2005.
2017.
“Control-ﬂow enforcement
technology
[29] Intel,
preview,”
https://software.intel.com/sites/default/ﬁles/managed/4d/2a/control-
ﬂow-enforcement-technology-preview.pdf.
[30] T. Bletsch, X. Jiang, V. W. Freeh, and Z. Liang, “Jump-oriented pro-
gramming: A new class of code-reuse attack,” in ACM Asia Conference
on Computer and Communications Security, 2011.
[31] S. Checkoway, L. Davi, A. Dmitrienko, A.-R. Sadeghi, H. Shacham, and
M. Winandy, “Return-oriented programming without returns,” in ACM
SIGSAC Conference on Computer and Communications Security, 2010.
[32] E. G¨oktas, E. Athanasopoulos, H. Bos, and G. Portokalidis, “Out of
control: Overcoming control-ﬂow integrity,” in IEEE Symposium on
Security and Privacy, 2014.
[33] H. Nazar´e, I. Maffra, W. Santos, L. B. e Oliveira, L. Gonnord, and
F. M. Q. Pereira, “Validation of memory accesses through symbolic
analyses,” in Proceedings of the 2014 ACM International Conference
on Object Oriented Programming Systems Languages & Applications,
OOPSLA 2014, pp. 791–809, ACM, 2014.
[34] Blake, “MY MP3 player 3.0 M3U exploit DEP bypass,” 2011. https:
//www.exploit-db.com/exploits/17854.
[35] E. J. Schwartz, T. Avgerinos, and D. Brumley, “Q: Exploit hardening
made easy,” in USENIX Security Symposium, 2011.
[36] S. K. Cha, T. Avgerinos, A. Rebert, and D. Brumley, “Unleashing
mayhem on binary code,” in IEEE Symposium on Security and Privacy,
2012.
[37] Corelan Team, “mona.py - the manual,” 2011. https://www.corelan.be/
index.php/2011/07/14/mona-py-the-manual/.
[38] Vendicator, “Stack shield: A stack smashing technique protection tool
for linux,” 2000. http://www.angelﬁre.com/sk/stackshield/.
[39] L. Davi, A.-R. Sadeghi, D. Lehmann, and F. Monrose, “Stitching the
gadgets: On the ineffectiveness of coarse-grained control-ﬂow integrity
protection,” in USENIX Security Symposium, 2014.
[40] Intel, “Intel 64 and IA-32 Architectures Software Developer’s Manual
Combined Volumes 2A, 2B, 2C, and 2D: Instruction Set Reference, A-
Z,” 2018.
[41] Y. Xia, Y. Liu, H. Chen, and B. Zang, “CFIMon: Detecting violation
of control ﬂow integrity using performance counters,” in IEEE/IFIP
International Conference on Dependable Systems and Networks, 2012.
[42] L. Davi, A.-R. Sadeghi, and M. Winandy, “ROPdefender: A detection
tool to defend against return-oriented programming attacks,” in ACM
Symposium on Information, Computer and Communications Security,
2011.
[43] M. Zhang and R. Sekar, “Control ﬂow integrity for COTS binaries.,” in
USENIX Security Symposium, 2013.
[44] P. Qiu, Y. Lyu, J. Zhang, D. Wang, and G. Qu, “Control ﬂow integrity
based on lightweight encryption architecture,” IEEE Transactions on
Computer-Aided Design of Integrated Circuits and Systems, vol. 37,
no. 7, 2018.
[45] M. Egele, T. Scholte, E. Kirda, and C. Kruegel, “A survey on automated
dynamic malware-analysis techniques and tools,” ACM Computing Sur-
veys, vol. 44, no. 2, 2012.
[46] M. Rajagopalan, M. A. Hiltunen, T. Jim, and R. D. Schlichting, “System
call monitoring using authenticated system calls,” IEEE Transactions on
Dependable and Secure Computing, vol. 3, no. 3, 2006.
[47] C. Kolbitsch, P. M. Comparetti, C. Kruegel, E. Kirda, X. Zhou, and
X. Wang, “Effective and efﬁcient malware detection at the end host,” in
USENIX Security Symposium, 2009.
[48] A. C. de Melo, “The new linux “perf” tools,” 2010.
https://pdfs.
semanticscholar.org/16ca/fd05fa375dfe370274cd22b4c16c72d6c53b.
pdf.
[49] NetMarketShare, “Browser Market Share,” 2018. https://netmarketshare.
com/browser-market-share.aspx.
[50] J. L. Hennessy and D. A. Patterson, Computer Architecture, A Quanti-
tative Approach. Elsevier, 6th ed., 1994.
[51] N. Binkert, B. Beckmann, G. Black, S. K. Reinhardt, A. Saidi, A. Basu,
J. Hestness, D. R. Hower, T. Krishna, S. Sardashti, R. Sen, K. Sewell,
M. Shoaib, N. Vaish, M. D. Hill, and D. A. Wood, “The gem5 simulator,”
ACM SIGARCH Computer Architecture News, vol. 39, no. 2, 2011.
[52] J. Zhang, Y. Liu, H. Li, X. Zhu, and M. Chen, “PTAT: An efﬁcient and
precise tool for tracing and proﬁling detailed tlb misses,” ACM TECS,
vol. 17, no. 3, p. 62, 2018.
[53] H. Vandierendonck and A. Seznec, “Speculative return address stack
management revisited,” ACM Transactions on Architecture and Code
Optimization, vol. 5, no. 3, 2008.
[54] A. Akram and L. Sawalha, “x86 computer architecture simulators: a
comparative study,” in IEEE International Conference on Computer
Design, 2016.
[55] C. Liu, C. Yang, and Y. Shen, “Leveraging microarchitectural side chan-
nel information to efﬁciently enhance program control ﬂow integrity,”
in IEEE/ACM International Conference on Hardware/Software Codesign
and System Synthesis, 2014.
[56] J. C. M. Santos and Y. Fei, “Leveraging speculative architectures for
run-time program validation,” in IEEE International Conference on
Computer Design, 2008.
[57] Y. Shi and G. Lee, “Augmenting branch predictor to secure program exe-
cution,” in IEEE/IFIP International Conference on Dependable Systems
and Networks, 2007.
[58] M. D. Brown and S. Pande, “Is less really more? why reducing code
reuse gadget counts via software debloating doesn’t necessarily lead to
better security,” 02 2019. arXiv Cryptography and Security (cs.CR).
[59] S. Bowne, “Defeating DEP with ROP,” 2014. https://samsclass.info/127/
[60] I. Fratri´c, “ROPGuard: Runtime prevention of return-oriented program-
https://www.ieee.hr/ download/repository/Ivan
proj/rop.htm.
ming attacks,” 2012.
Fratric.pdf.
[61] V. Pappas, M. Polychronakis, and A. D. Keromytis, “Transparent ROP
exploit mitigation using indirect branch tracing.,” in USENIX Security
Symposium, 2013.
[62] C. Zhang, T. Wei, Z. Chen, L. Duan, L. Szekeres, S. McCamant,
D. Song, and W. Zou, “Practical control ﬂow integrity and randomization
for binary executables,” in IEEE Symposium on Security and Privacy,
2013.
[63] R. Sinha, M. Costa, A. Lal, N. P. Lopes, S. K. Rajamani, S. A. Seshia,
and K. Vaswani, “A design and veriﬁcation methodology for secure
isolated regions,” in PLDI, 2016.
[64] Y. Lee and G. Lee, “Detecting code reuse attacks with branch predic-
tion,” IEEE Computer, vol. 51, no. 4, pp. 40–47, 2018.
[65] S. Das, B. Chen, M. Chandramohan, Y. Liu, and W. Zhang, “ROPSentry:
Runtime defense against ROP attacks using hardware performance
counters,” Computers & Security, vol. 73, pp. 374–388, 2018.
[66] D. Ahn and G. Lee, “A memory-access validation scheme against pay-
load injection attacks,” IEEE Transactions on Dependable and Secure
Computing, vol. 12, no. 4, pp. 387–399, 2015.
[67] A. Tang, S. Sethumadhavan, and S. J. Stolfo, “Unsupervised anomaly-
based malware detection using hardware features,” in International
Workshop on Recent Advances in Intrusion Detection, pp. 109–129,
Springer, 2014.
[68] G. Wicherski, “Threat detection for return oriented programming,” Feb. 9
2016. US Patent 9,256,730.
[69] L. Davi, M. Hanreich, D. Paul, A.-R. Sadeghi, P. Koeberl, D. Sullivan,
O. Arias, and Y. Jin, “Haﬁx: Hardware-assisted ﬂow integrity extension,”
in ACM/ESDA/IEEE Design Automation Conference, 2015.
[70] M. Kayaalp, M. Ozsoy, N. Abu-Ghazaleh, and D. Ponomarev, “Branch
regulation: Low-overhead protection from code reuse attacks,” in Inter-
national Symposium on Computer Architecture, 2012.
[71] M. Kayaalp, T. Schmitt, J. Nomani, D. Ponomarev, and N. Abu-
Ghazaleh, “SCRAP: Architecture for signature-based protection from
code reuse attacks,” in HPCA, (Washington, DC, USA), pp. 258–269,
IEEE, 2013.
[72] J. Li, L. Chen, Q. Xu, L. Tian, G. Shi, K. Chen, and D. Meng, “Zipper
stack: Shadow stacks without shadow,” 02 2019.
[73] M. Payer, A. Barresi, and T. R. Gross, “Lockdown: Dynamic control-
ﬂow integrity,” tech. rep., ETH Zurich, Jul 2014.
[74] N. Carlini and D. Wagner, “ROP is still dangerous: Breaking modern
defenses,” in USENIX Security Symposium, 2014.
[75] E. G¨oktas¸, E. Athanasopoulos, M. Polychronakis, H. Bos, and G. Por-
tokalidis, “Size does matter: Why using gadget-chain length to prevent
code-reuse attacks is hard,” in USENIX, pp. 417–432, 2014.
[76] M. Tymburib´a, R. E. Moreira, and F. M. Quint˜ao Pereira, “Inference
of peak density of indirect branches to detect ROP attacks,” in Pro-
ceedings of the 2016 International Symposium on Code Generation and
Optimization, pp. 150–159, ACM, 2016.
327
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:52:59 UTC from IEEE Xplore.  Restrictions apply.