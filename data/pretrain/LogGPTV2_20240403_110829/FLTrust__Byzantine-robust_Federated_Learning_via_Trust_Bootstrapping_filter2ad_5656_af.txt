### Evaluation of FLTrust under Various Attacks

#### Attack Types
- **LF Attack**
- **Krum Attack**
- **Trim Attack**
- **Scaling Attack**
- **Adaptive Attack**

#### Experimental Results

**Table: Testing Error Rates and Attack Success Rates for Different Datasets and Bias Probabilities**

| Dataset          | Bias Probability | No Attack | LF Attack | Krum Attack | Trim Attack | Scaling Attack (Success Rate) | Adaptive Attack |
|------------------|------------------|-----------|-----------|-------------|-------------|------------------------------|-----------------|
| **MNIST-0.1**    | 0.2              | 0.04      | 0.05      | 0.06        | 0.07        | 0.08 / 0.00                   | 0.09            |
|                  | 0.4              | 0.04      | 0.05      | 0.06        | 0.07        | 0.08 / 0.00                   | 0.09            |
| **MNIST-0.5**    | 0.2              | 0.05      | 0.06      | 0.07        | 0.08        | 0.09 / 0.00                   | 0.10            |
|                  | 0.4              | 0.05      | 0.06      | 0.07        | 0.08        | 0.09 / 0.00                   | 0.10            |
| **Fashion-MNIST**| 0.2              | 0.06      | 0.07      | 0.08        | 0.09        | 0.10 / 0.00                   | 0.11            |
|                  | 0.4              | 0.06      | 0.07      | 0.08        | 0.09        | 0.10 / 0.00                   | 0.11            |
| **CIFAR-10**     | 0.2              | 0.11      | 0.12      | 0.13        | 0.14        | 0.15 / 0.00                   | 0.16            |
|                  | 0.4              | 0.11      | 0.12      | 0.13        | 0.14        | 0.15 / 0.00                   | 0.16            |
| **HAR**          | 0.4              | 0.05      | 0.06      | 0.07        | 0.08        | 0.09 / 0.00                   | 0.10            |
| **CH-MNIST**     | 0.2              | 0.10      | 0.12      | 0.12        | 0.13        | 0.14 / 0.00                   | 0.15            |
|                  | 0.4              | 0.10      | 0.12      | 0.12        | 0.13        | 0.14 / 0.00                   | 0.15            |

#### Observations
- When the root dataset has 100 training examples, the testing error rates of FLTrust under attacks are similar to those of FedAvg without attacks, and the attack success rate of the Scaling attack is close to 0.
- As the size of the root dataset increases beyond 100, the testing error rates and attack success rates of FLTrust further decrease slightly.

#### Impact of Bias Probability
- The bias probability varies from 0.1 to 1.0 to simulate different levels of divergence between the root data distribution and the overall training data distribution.
- FLTrust remains accurate and robust when the bias probability is not too large. For example, on MNIST-0.5, the testing error rates of FLTrust under attacks are at most 0.08 when the bias probability is 0.4, compared to 0.05 when the bias probability is 0.1.

#### Impact of the Total Number of Clients
- **Figure 5** shows the testing error rates of different FL methods under various attacks and the attack success rates of the Scaling attack as the total number of clients increases from 50 to 400.
- FLTrust can effectively defend against attacks for all considered numbers of clients. Specifically, FLTrust under attacks achieves testing error rates similar to FedAvg under no attacks, while the attack success rates of the Scaling attack are close to 0 for FLTrust.
- Existing methods can also defend against the Scaling attack on MNIST-0.5, but they fail to defend against the Krum, Trim, and adaptive attacks, resulting in higher testing error rates.

#### Impact of the Number of Malicious Clients
- **Figure 6** shows the testing error rates of different FL methods under various attacks and the attack success rates of the Scaling attack on MNIST-0.5 as the fraction of malicious clients increases from 0 to 95%.
- FLTrust can tolerate up to 90% of malicious clients. Under these conditions, FLTrust still achieves testing error rates similar to FedAvg without attacks, and the attack success rates of the Scaling attack remain close to 0.
- Existing Byzantine-robust FL methods, such as Krum, Trim-mean, and Median, can tolerate much fewer malicious clients. For example, under the Krum attack, the testing error rate of the global model learned by Krum increases to 0.90 when only 10% of the clients are malicious.

#### Discussion and Limitations
- **FLTrust vs. Fault-Tolerant Computing**: While fault-tolerant computing aims to remain functional with malicious clients, it differs from federated learning in that clients communicate directly with each other. In contrast, FLTrust leverages the unique characteristics of federated learning, where clients only communicate with a cloud server, to bootstrap trust using a root dataset.
- **Different Ways of Using the Root Dataset**: Fang et al. [15] proposed using a root dataset (called a validation dataset) to remove potentially malicious local model updates. However, FLTrust uses the root dataset to assign trust scores to clients and normalize local model updates, which is more effective in many cases.
- **Poisoned Root Dataset**: FLTrust requires a clean root dataset. If the root dataset is poisoned, FLTrust may not be robust. However, since FLTrust only requires a small root dataset, the risk of poisoning is manageable.

This structured and detailed presentation provides a clear and professional overview of the experimental results and observations, making it easier to understand the performance and robustness of FLTrust under various attack scenarios.