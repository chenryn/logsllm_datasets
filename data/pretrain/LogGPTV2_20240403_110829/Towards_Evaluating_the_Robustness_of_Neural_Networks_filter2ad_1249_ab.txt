n
This problem can be very difﬁcult
Szegedy et al. instead solve the following problem:
to solve, however, so
minimize c · (cid:6)x − x
(cid:2) ∈ [0, 1]
such that x
n
(cid:2)(cid:6)2
2 + lossF,l(x
(cid:2)
)
where lossF,l is a function mapping an image to a positive real
number. One common loss function to use is cross-entropy.
Line search is performed to ﬁnd the constant c > 0 that yields
an adversarial example of minimum distance: in other words,
42
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:27:35 UTC from IEEE Xplore.  Restrictions apply. 
we repeatedly solve this optimization problem for multiple
values of c, adaptively updating c using bisection search or
any other method for one-dimensional optimization.
B. Fast Gradient Sign
The fast gradient sign [11] method has two key differences
from the L-BFGS method: ﬁrst, it is optimized for the L∞
distance metric, and second, it is designed primarily to be fast
instead of producing very close adversarial examples. Given
an image x the fast gradient sign method sets
= x −  · sign(∇lossF,t(x)),
x
(cid:2)
where  is chosen to be sufﬁciently small so as to be
undetectable, and t is the target label. Intuitively, for each
pixel,
the fast gradient sign method uses the gradient of
the loss function to determine in which direction the pixel’s
intensity should be changed (whether it should be increased
or decreased) to minimize the loss function; then, it shifts all
pixels simultaneously.
It is important to note that the fast gradient sign attack was
designed to be fast, rather than optimal. It is not meant to
produce the minimal adversarial perturbations.
Iterative Gradient Sign: Kurakin et al. introduce a simple
reﬁnement of the fast gradient sign method [26] where instead
of taking a single step of size  in the direction of the gradient-
sign, multiple smaller steps α are taken, and the result is
clipped by the same . Speciﬁcally, begin by setting
(cid:2)
0 = 0
x
and then on each iteration
(cid:2)
i = x
i−1 − clip(α · sign(∇lossF,t(x
(cid:2)
(cid:2)
i−1)))
x
Iterative gradient sign was found to produce superior results
to fast gradient sign [26].
C. JSMA
Papernot et al. introduced an attack optimized under L0
distance [38] known as the Jacobian-based Saliency Map
Attack (JSMA). We give a brief summary of their attack
algorithm; for a complete description and motivation, we
encourage the reader to read their original paper [38].
At a high level,
the attack is a greedy algorithm that
picks pixels to modify one at a time, increasing the target
classiﬁcation on each iteration. They use the gradient ∇Z(x)l
to compute a saliency map, which models the impact each
pixel has on the resulting classiﬁcation. A large value indicates
that changing it will signiﬁcantly increase the likelihood of
the model labeling the image as the target class l. Given the
saliency map, it picks the most important pixel and modify
it to increase the likelihood of class l. This is repeated until
either more than a set threshold of pixels are modiﬁed which
makes the attack detectable, or it succeeds in changing the
classiﬁcation.
In more detail, we begin by deﬁning the saliency map in
terms of a pair of pixels p, q. Deﬁne
(cid:3)
⎛
⎝ (cid:3)
i∈{p,q}
∂Z(x)t
∂xi
(cid:3)
∂Z(x)j
∂xi
i∈{p,q}
j
αpq =
βpq =
⎞
⎠ − αpq
so that αpq represents how much changing both pixels p and
q will change the target classiﬁcation, and βpq represents how
much changing p and q will change all other outputs. Then
the algorithm picks
∗
(p
, q
∗
) = arg max
(p,q)
(−αpq · βpq) · (αpq > 0) · (βpq  0 (the target class is more likely), βpq  1, the
attack becomes less effective, but always succeeds.
where c > 0 is a suitably chosen constant. These two are
equivalent, in the sense that there exists c > 0 such that the
optimal solution to the latter matches the optimal solution to
the former. After instantiating the distance metric D with an
lp norm, the problem becomes: given x, ﬁnd δ that solves
minimize (cid:6)δ(cid:6)p + c · f (x + δ)
such that x + δ ∈ [0, 1]
n
Choosing the constant c.
Empirically, we have found that often the best way to choose
c is to use the smallest value of c for which the resulting
) ≤ 0. This causes gradient descent to
solution x
minimize both of the terms simultaneously instead of picking
only one to optimize over ﬁrst.
∗ has f (x
∗
We verify this by running our f6 formulation (which we
found most effective) for values of c spaced uniformly (on a
log scale) from c = 0.01 to c = 100 on the MNIST dataset.
We plot this line in Figure 2. 7
∗
Further, we have found that if choose the smallest c such
) ≤ 0, the solution is within 5% of optimal 70% of
that f (x
the time, and within 30% of optimal 98% of the time, where
“optimal” refers to the solution found using the best value of
c. Therefore, in our implementations we use modiﬁed binary
search to choose c.