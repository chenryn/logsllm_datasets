# Symmetry
## Article: LogLS: Research on System Log Anomaly Detection Method Based on Dual LSTM

### Authors
Yiyong Chen, Nurbol Luktarhan\*, and Dan Lv  
College of Information Science and Engineering, Xinjiang University, Urumqi 830046, China  
*Correspondence: nurbol@xju.edu.cn*

### Abstract
System logs are crucial for understanding and managing the status and important events of a system. Detecting anomalies in these logs is essential for timely identification of system faults. However, with the increasing size and complexity of modern software systems, traditional manual log-checking methods have become impractical and time-consuming. Existing automatic log anomaly detection methods, while reducing manual effort, often suffer from inaccuracies and rely heavily on indices or log templates.

In this work, we propose LogLS, a system log anomaly detection method based on dual long short-term memory (LSTM) networks with a symmetric structure. LogLS treats system logs as natural-language sequences and models them according to both preorder and postorder relationships. This approach is an optimization of the DeepLog method, addressing the issue of poor prediction performance on long sequences. By incorporating a feedback mechanism, LogLS can predict and detect unseen log anomalies.

We evaluated LogLS on two real-world datasets, and the experimental results demonstrate its effectiveness in log anomaly detection.

### Keywords
system logs; anomaly detection; LSTM; time series forecasting

### Citation
Chen, Y.; Luktarhan, N.; Lv, D. LogLS: Research on System Log Anomaly Detection Method Based on Dual LSTM. Symmetry 2022, 14, 454. https://doi.org/10.3390/sym14030454

**Academic Editor:** Juan Alberto Rodríguez Velázquez  
**Received:** 25 January 2022  
**Accepted:** 16 February 2022  
**Published:** 24 February 2022

**Publisher’s Note:** MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations.

### 1. Introduction
Modern systems generate numerous log files that reflect the running state of the system and record specific events. These logs are valuable resources for understanding system performance and are crucial for anomaly detection. Log anomaly detection can be categorized into three main types: rule-based, unsupervised, and supervised.

- **Rule-based anomaly detection** [2] typically requires manual analysis and rule creation, which is labor-intensive and has low automation. For example, [3] created rule sets by analyzing log time series information, reducing false positives but at a high cost.
- **Unsupervised anomaly detection** [4] reduces manual effort and does not require pre-labeled training data. It detects anomalies by comparing the log sequence to normal sequences. [5] used abstract syntax trees (AST) and principal component analysis (PCA) to process log features, while [6,7] proposed unstructured log analysis techniques to discover program invariants.
- **Supervised anomaly detection** [9] uses pre-labeled data to train models. [10] trained a logistic regression model using log event counting vectors, and [11] used support vector machines (SVMs) to determine abnormal log sequences.

With the advent of deep learning, neural network-based log anomaly detection methods have shown promise. [14] proposed a generative adversarial network (GAN) based on LSTM, and [15] used LSTM to model logs as natural-language sequences. However, these methods often overlook the impact of post-event sequences, leading to inaccuracies in long sequences.

To address these issues, we propose LogLS, a dual LSTM-based log anomaly detection method. LogLS considers both pre- and post-event interactions, improving accuracy and F1-measure on HDFS datasets. Our contributions include:

1. **Improved log template accuracy** through a filtering step based on the Spell method, enhancing later log detection performance.
2. **Dual LSTM models** constructed based on preorder and postorder relationships, forming a complete anomaly detection model that considers the interaction of log events.
3. **Feedback mechanism** to update the model and improve detection of unseen log sequences.

### 2. Preliminaries

#### 2.1. Log Parser
The first step in log anomaly detection is to collect and preprocess log data. After collection, invalid and redundant information is removed, and the log data is parsed to extract structured information. The log parser normalizes the data by extracting log keys, converting different structures into a uniform format (log event sequence).

For example, the log "081109 205931 13 INFO dfs.DataBlockScanner: Verification succeeded for blk_-4980916519894289629" can be parsed to "Verification succeeded for (*)," where "*" represents variable parameters. The common constant part is the log key, which indicates the log type. This key is used to form a log event sequence {k1, k2, k3, ..., ki}.

There are several log parsing methods, including CFG, LKE, Logarm, and Drain. We use the Spell method, which is an advanced online log parsing tool. To further improve accuracy, we manually filter, deduplicate, and merge the parsed templates.

#### 2.2. Architecture and Overview
The LogLS architecture consists of three main modules: log analysis, log key anomaly detection, and a workflow model for anomaly detection.

- **Log Parsing Stage:** The Spell method is used to parse log templates, and manual filtering is applied to obtain the final log template list. Unstructured log data is then parsed into log events.
- **Training Phase:** The training set consists of log entries from normal system execution. Log event sequences are constructed based on unique identifiers (e.g., HDFS logs) or sliding windows (e.g., BGL logs). Two LSTM models, one for pre-event and one for post-event sequences, are trained and combined to form the anomaly detection model.
- **Detection Phase:** The test dataset is used to perform anomaly detection. The log event sequence is generated, and the appropriate LSTM model is selected based on sequence length. If a log event deviates significantly from the predicted normal sequence, it is flagged as an anomaly. A feedback mechanism allows users to retrain the model with new data, improving accuracy over time.

### 3. Methodology
LogLS is a system log anomaly detection method based on dual LSTM. It addresses the gradient problem in long sequence prediction and improves detection performance.

#### 3.1. Log Parser (Spell)
The log parser converts unstructured logs into structured log templates. The Spell method, based on the longest common subsequence (LCS), is used for parsing. Although Spell is effective, it sometimes produces duplicate or redundant templates. We manually deduplicate and optimize the templates to enhance accuracy.

For example, the HDFS log templates parsed by Spell (Table 1) contain duplicates. We manually reprocess these templates (Table 2) to eliminate redundancy and improve the quality of the log event sequences.

| EventId | EventTemplate |
|---|---|
| E1  E2  ... E7  E8  E9  ... E14  E15  E16  ... E36  E37 | Adding an already existing block (*)  Verification succeeded for (*)  ... writeBlock (*) received exception java.io.IOException Connection reset by peer writeBlock (*) received exception (*)  writeBlock (*) received exception java.io.IOException Could not read from stream ... PacketResponder (*)(*) Exception java.io.IOException Broken pipe PacketResponder (*) 2 Exception (*)  PacketResponder (*) 1 Exception (*)  ... Deleting block (*) file (*)  BLOCK* NameSystem.allocateBlock (*) (*) |

| EventId | EventTemplate |
|---|---|
| E1  E2  ... E7  E8  E9  ... E14  E15  E16  ... E28 E29 | Adding an already existing block (*)  (*)Verification succeeded for (*)  ... writeBlock (*) received exception (*)  PacketResponder (*) for block (*) Interrupted. Received block (*) of size (*) from (*)  ... Exception in receiveBlock for block (*) (*)  Changing block file offset of block (*) from (*) to (*) meta file offset to (*) (*):Transmitted block (*) to (*)  ... BLOCK* NameSystem.addStoredBlock: addStoredBlock request received for (*) on (*) size (*) However, it does not belong to any file. PendingReplicationMonitor timed out block (*) |

The log parsing process involves:
1. Defining a log object (LCSObject) with attributes like log key (LCSseq) and line number list (lineIds).
2. Reading the log file line by line.
3. Traversing the LCSMap to check for existing LCSObjects with the same log key. If found, the lineIds are updated; otherwise, a new LCSObject is created.
4. Continuing until the end of the log file.

### 4. Evaluation
We evaluated LogLS on two real-world datasets and compared its performance with existing methods. The experimental results show that LogLS outperforms other methods in terms of accuracy and F1-measure, particularly on the HDFS dataset.

### 5. Conclusion
LogLS, a dual LSTM-based log anomaly detection method, effectively addresses the limitations of existing approaches by considering both pre- and post-event interactions. The method includes a feedback mechanism for continuous improvement and has been shown to be highly effective in detecting anomalies in system logs.

### References
[1] Reference 1  
[2] Reference 2  
[3] Reference 3  
[4] Reference 4  
[5] Reference 5  
[6] Reference 6  
[7] Reference 7  
[8] Reference 8  
[9] Reference 9  
[10] Reference 10  
[11] Reference 11  
[12] Reference 12  
[13] Reference 13  
[14] Reference 14  
[15] Reference 15  
[16] Reference 16  
[17] Reference 17  
[18] Reference 18  
[19] Reference 19  
[20] Reference 20  
[21] Reference 21  
[22] Reference 22  
[23] Reference 23  
[24] Reference 24  
[25] Reference 25  
[26] Reference 26  
[27] Reference 27  

---

This revised version of the text is more coherent, professional, and clearly structured, making it easier to understand and follow.