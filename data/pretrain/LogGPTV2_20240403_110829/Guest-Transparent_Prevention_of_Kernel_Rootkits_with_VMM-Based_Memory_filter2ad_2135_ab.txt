would require kernel source code modiﬁcation, which conﬂicts with our second design
goal. Even given source code access, mixed page elimination is still a complex task
(more than just page-aligning data). In fact, a kernel conﬁguration option with a
similar purpose exists in the latest Linux kernel (version 2.6.23). But after we enabled
the option, we still found more than 700 mixed kernel pages. NICKLE instead simply
avoids such complexity and works even with mixed kernel pages.
Guest-Transparent Prevention of Kernel Rootkits
7
Guest memory access indirection is performed between the VM and its mem-
ory (standard and shadow) by a thin NICKLE module inside the VMM. It has
two main functions, kernel code authentication and copying at VM startup and
upon kernel module loading as well as guest physical address redirection at run-
time (Figure 1).
Kernel Code Authentication and Copying. To ﬁll up the shadow memory with
authenticated kernel instructions, the NICKLE module inside the VMM needs to
ﬁrst determine the accurate timing for kernel code authentication and copying.
To better articulate the problem, we will use the Linux kernel as an example.
There are two speciﬁc situations throughout the VM’s lifetime when kernel code
needs to be authorized and shadowed: One at the VM’s startup and one upon
the loading/unloading of loadable kernel modules (LKMs). When the VM is
starting up, the guest’s shadow memory is empty. The kernel bootstrap code
then decompresses the kernel. Right after the decompression and before any
processes are executed, NICKLE will use a cryptographic hash to verify the
integrity of the kernel code (this is very similar to level 4 in the secure bootstrap
procedure [17]) and then copy the authenticated kernel code from the standard
memory into the shadow memory (Figure 1(a)). As such, the protected VM will
start with a known clean kernel.
The LKM support in modern OSes complicates our design. From NICKLE’s
perspective, LKMs are considered injected kernel code and thus need to be au-
thenticated and shadowed before their execution. The challenge for NICKLE is
to externally monitor the guest OS and detect the kernel module loading/unload-
ing events in real-time. NICKLE achieves this by leveraging our earlier work on
non-intrusive VM monitoring and semantic event reconstruction [1, 14]. When
NICKLE detects the loading of a new kernel module, it intercepts the VM’s exe-
cution and performs kernel module code authentication and shadowing. The au-
thentication is performed by taking a cryptographic hash of the kernel module’s
code segment and comparing it with a known correct value, which is computed
a priori oﬀ-line and provided by the administrator or distribution maintainer.5
If the hash values don’t match, the kernel module’s code will not be copied to
the shadow memory.
Through kernel code authentication and copying, only authenticated kernel
code will be loaded into the shadow memory, thus blocking the copying of ma-
licious kernel rootkit code or any other code injected by exploiting kernel vul-
nerabilities, including zero-day vulnerabilities. It is important to note that nei-
ther kernel startup hashing nor kernel module hashing assumes trust in the
guest OS. Should the guest OS fail to cooperate, no code will be copied to the
shadow memory, and any execution attempts from that code will be detected and
refused.
Guest Physical Address Redirection. At runtime, the NICKLE module inside the
VMM intercepts the memory accesses of the VM after the “guest virtual address
→ guest physical address” translation. As such, NICKLE does not interfere
5 We have developed an oﬀ-line kernel module proﬁler that, given a legitimate kernel
module, will compute the corresponding hash value (Section 3.1).
8
R. Riley, X. Jiang, and D. Xu
with – and is therefore transparent to – the guest OS’s memory access handling
procedure and virtual memory mappings. Instead, it takes the guest physical
address, determines the type of the memory access (kernel, user; code, data;
etc.), and routes it to either the standard or shadow memory (Figure 1(b)).
We point out that the interception of VM memory accesses can be provided
by existing VMMs (e.g., QEMU+KQEMU, VirtualBox, and VMware). NICKLE
builds on this interception capability by adding the guest physical address redi-
rection logic. First, using a simple method to check the current privilege level
of the processor, NICKLE determines whether the current instruction fetch is
for kernel code or for user code: If the processor is in supervisor mode (CPL=0
on x86), we infer that the fetch is for kernel code and NICKLE will verify and
route the instruction fetch to the shadow memory. Otherwise, the processor is in
user mode and NICKLE will route the instruction fetch to the standard memory.
Data accesses of either type are always routed to the standard memory.
One might object that an attacker may strive to ensure that his injected
kernel code will run when the processor is in user mode. However, this creates a
signiﬁcant challenge wherein the attacker would have to fundamentally change
a running kernel to operate in both supervisor and user mode without changing
any existing kernel code. The authors do not consider such a rootkit to be a
possibility without a severe loss of rootkit functionality.
Flexible Responses to Unauthorized Kernel Code Execution Attempts
If an unauthorized execution attempt is detected, a natural follow-up question
is, “How should NICKLE respond to an attempt to execute an unauthenticated
kernel instruction?” Given that NICKLE sits between the VM and its memory
and has a higher privilege level than the guest OS, it possesses a wide range of
options and capabilities to respond. We describe two response modes facilitated
by the current NICKLE system.
Rewrite mode: NICKLE will dynamically rewrite the malicious kernel code with
code of its own. The response code can range from OS-speciﬁc error handling
code to a well-crafted payload designed to clean up the impact of a rootkit
installation attempt. Note that this mode may require an understanding of the
guest OS to ensure that valid, sensible code is returned.
Break mode: NICKLE will take no action and route the instruction fetch to
the shadow memory. In the case where the attacker only modiﬁes the origi-
nal kernel code, this mode will lead to the execution of the original code – a
desirable situation. However, in the case where new code is injected into the
kernel, this mode will lead to an instruction fetch from presumably null content
(containing 0s) in the shadow memory. As such, break mode prevents malicious
kernel code execution but may or may not be graceful depending on how the OS
handles invalid code execution faults.
3 NICKLE Implementation
To validate the portability of the NICKLE design, we have implemented
NICKLE in three VMMs: QEMU+KQEMU [8], VirtualBox [9], and VMware
Guest-Transparent Prevention of Kernel Rootkits
9
Workstation6. Since the open-source QEMU+KQEMU is the VMM platform
where we ﬁrst implemented NICKLE, we use it as the representative VMM to
describe our implementation details. For most of this section, we choose RedHat
8.0 as the default guest OS. We will also discuss the limitations of our current
prototype in supporting Windows guest OSes.
3.1 Memory Shadowing and Guest Memory Access Indirection
To implement memory shadowing, we have considered two options: (1) NICKLE
could interfere as instructions are executed; or (2) NICKLE could interfere when
instructions are dynamically translated. Note that dynamic instruction transla-
tion is a key technique behind existing software-based VMMs, which transpar-
ently translates guest machine code into native code that will run in the physical
host. We favor the second option for performance reasons: By being part of the
translator, NICKLE can take advantage of the fact that translated code blocks are
cached. In QEMU+KQEMU, for example, guest kernel instructions are grouped
into “blocks” and are dynamically translated at runtime. After a block of code is
translated, it is stored in a cache to make it available for future execution. In terms
of NICKLE, this means that if we intercede during code translation we need not
intercede as often as we would if we did so during code execution, resulting in a
smaller impact on system performance.
The pseudo-code for memory shadowing and guest memory access indirection
is shown in Algorithm 1. Given the guest physical address of an instruction to
be executed by the VM, NICKLE ﬁrst checks the current privilege level of the
processor (CPL). If the processor is in supervisor mode, NICKLE knows that it is
executing in kernel mode. Using the guest physical address, NICKLE compares
the content of the standard and shadow memories to determine whether the
kernel instruction to be executed is already in the shadow memory (namely
has been authenticated). If so, the kernel instruction is allowed to be fetched,
translated, and executed. If not, NICKLE will determine if the guest OS kernel
is being bootstrapped or a kernel module is being loaded. If either is the case,
the corresponding kernel text or kernel module code will be authenticated and,
if successful, shadowed into the shadow memory. Otherwise, NICKLE detects an
attempt to execute an unauthorized instruction in the kernel space and prevents
it by executing our response to the attempt.
In Algorithm 1, the way to determine whether the guest OS kernel is being
bootstrapped or a kernel module is being loaded requires OS-speciﬁc knowledge.
Using the Linux 2.4 kernel as an example, when the kernel’s startup 32 function,
located at physical address 0x00100000 or virtual address 0xc0100000 as
shown in the System.map ﬁle, is to be executed, we know that this is the ﬁrst
6 We acknowledge the VMware Academic Program for providing the source code. Due
to space and licensing constraints, however, the VMware port is not further discussed
or evaluated in this work. Some additional discussion of the port is available in our
technical report [16].
10
R. Riley, X. Jiang, and D. Xu
Algorithm 1. Algorithm for Memory Shadowing and Guest Memory Access
Indirection
Input: (1) GuestPA: guest physical address of instruction to be executed; (2) ShadowMEM[]:
shadow memory; (3) StandardMEM[]: standard memory
if
!IsUserMode(vcpu) AND ShadowMEM[GuestPA] != StandardMEM[GuestPA] then
if (kernel is being bootstrapped) OR (module is being loaded) then
Authenticate and shadow code;
Unauthorized execution attempt - Execute response;
1
2
3
4
5
6
7
8
else
end
end
Fetch, translate, and cache code;
instruction executed to load the kernel and we can intercede appropriately. For
kernel module loading, there is a speciﬁc system call to handle that. As such,
the NICKLE module inside the VMM can intercept the system call and perform
kernel module authentication and shadowing right before the module-speciﬁc
init module routine is executed.
In our implementation, the loading of LKMs requires special handling. More
speciﬁcally, providing a hash of a kernel module’s code space ends up being
slightly complicated in practice. This is due to the fact that kernel modules
are dynamically relocatable and hence some portions of the kernel module’s
code space may be modiﬁed by the module loading function. Accordingly, the
cryptographic hash of a loaded kernel module will be diﬀerent depending on
where it is relocated to. To solve this problem, we perform an oﬀ-line, a priori
proﬁling of the legitimate kernel module binaries. For each known good module
we calculate the cryptographic hash by excluding the portions of the module that
will be changed during relocation. In addition, we store a list of bytes aﬀected
by relocation so that the same procedure can be repeated by NICKLE during
runtime hash evaluation of the same module.
We point out that although the implementation of NICKLE requires certain
guest OS-speciﬁc information, it does not require modiﬁcations to the guest
OS itself. Still, for a closed-source guest OS (e.g., Windows), lack of information
about kernel bootstrapping and dynamic kernel code loading may lead to certain
limitations. For example, not knowing the timing and “signature” of dynamic
(legal) kernel code loading events in Windows, the current implementation of
NICKLE relies on the administrator to designate a time instance when all au-
thorized Windows kernel code has been loaded into the standard memory. Not
knowing the exact locations of the kernel code, NICKLE traverses the shadow
page table and copies those executable pages located in the kernel space from the
standard memory to the shadow memory, hence creating a “gold standard” to
compare future kernel code execution against. From this time on, NICKLE can
transparently protect the Windows OS kernel from executing any unauthorized
kernel code. Moreover, this limited implementation can be made complete when
the relevant information becomes available through vendor disclosure or reverse
engineering.
Guest-Transparent Prevention of Kernel Rootkits
11
3.2 Flexible Response
In response to an attempt to execute an unauthorized instruction in the kernel
space, NICKLE provides two response modes. Our initial implementation of
NICKLE simply re-routes the instruction fetch to the shadow memory for a
string of zeros (break mode). As to be shown in our experiments, this produces
some interesting outcomes: a Linux guest OS would react to this by triggering a
kernel fault and terminating the oﬀending process. Windows, on the other hand,
reacts to the NICKLE response by immediately halting with a blue screen – a
less graceful outcome.
In search of a more ﬂexible response mode, we ﬁnd that by rewriting the
oﬀending instructions at runtime (rewrite mode), NICKLE can respond in a less
disruptive way. We also observe that most kernel rootkits analyzed behave the
following way: They ﬁrst insert a new chunk of malicious code into the kernel
space; then they somehow ensure their code is call’d as a function. With this
observation, we let NICKLE dynamically replace the code with return -1;,
which in assembly is: mov $0xffffffff, %eax; ret. The main kernel text or
the kernel module loading process will interpret this as an error and gracefully
handle it: Our experiments with Windows 2K/XP, Linux 2.4, and Linux 2.6 guest
OSes all conﬁrm that NICKLE’s rewrite mode is able to handle the malicious
kernel code execution attempt by triggering the OS to terminate the oﬀending
process without causing a fault in the OS.
3.3 Porting Experience
We have experienced no major diﬃculty in porting NICKLE to other VMMs. The
NICKLE implementations in both VMMs are lightweight: The SLOC (source
lines of code) added to implement NICKLE in QEMU+KQEMU, VirtualBox,
and VMware Workstation are 853, 762, and 1181 respectively. As mentioned
earlier, we ﬁrst implemented NICKLE in QEMU+KQEMU. It then took less
than one week for one person to get NICKLE functional in VirtualBox 1.5.0
OSE, details of which can be found in our technical report [16].
4 NICKLE Evaluation
4.1 Eﬀectiveness Against Kernel Rootkits
We have evaluated the eﬀectiveness of NICKLE with 23 real-world kernel rootk-
its. They consist of nine Linux 2.4 rootkits, seven Linux 2.6 rootkits, and seven
Windows rootkits7 that can infect Windows 2000 and/or XP. The selected rootk-
its cover the main attack platforms and attack vectors thus providing a good
representation of the state-of-the-art kernel rootkit technology. Table 1 shows
7 There is a Windows rootkit named hxdef or Hacker Defender, which is usually clas-
siﬁed as a user-level rootkit. However, since hxdef contains a device driver which will
be loaded into the kernel, we consider it a kernel rootkit in this paper.
12
R. Riley, X. Jiang, and D. Xu
Table 1. Eﬀectiveness of NICKLE in detecting and preventing 23 real-world kernel
rootkits (DKOM† is a common rootkit technique which directly manipulates kernel
objects; “partial”‡ means the in-kernel component of the Hacker Defender rootkit fails;
BSOD§ stands for “Blue Screen Of Death”)
Guest OS
Rootkit
Attack Vector
Rewrite Mode
Prevented?
Outcome of NICKLE Response
Linux 2.4
Linux 2.6
Windows 2K/XP
adore 0.42, 0.53
adore-ng 0.56
knark
rkit 1.01
kbdv3
allroot
rial
Phantasmagoria
SucKIT 1.3b
adore-ng 0.56
eNYeLKM v1.2
sk2rc2
superkit
mood-nt 2.3
override
Phalanx b6
FU
FUTo
he4hook 215b6
hxdef 1.0.0 revisited
hkdoor11
yyt hac
NT Rootkit
LKM
LKM
LKM
LKM
LKM
LKM
LKM
LKM
/dev/kmem
LKM