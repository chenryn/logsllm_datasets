### Metrics and Comparison Challenges

The metrics available for comparing different anomaly detection approaches are limited. Specifically, it is challenging to determine whether the hourly approach simply flags more intervals as anomalous or if it captures unique artifacts differently. In many cases, the smaller reduction in flagged intervals was at least partially due to abrupt intensity shifts. The hourly model signals an anomaly based on multiple statistics, while a continuously updated statistic might only flag an anomaly once. For instance, the two DDoS flows had intensity profiles resembling a step function, causing the hourly model to flag significantly more alerts than the continuous model.

Another factor complicating the comparison is the difference in the effective lengths of model memories. The time slot statistics for the hourly and weekday models are updated with corresponding intensity measures, leading to values that are averaged over a longer span in real time. For example, the hourly model's statistics are influenced by measurements that are 8 or 24 days old.

### Class Flows and Aggregation

Grouping signature classes together increased the percentage of flagged intervals. Table 6 shows the reductions in alerts and busy intervals for class aggregates with more than 1000 alerts, using the continuous model with (1−λ) = 0.92. Almost every class contains one or more high-volume signatures that are statistically problematic, which affects the behavior of the class aggregate. The increased flagging could also indicate that anomalies in lower-volume signature-based flows are being detected to some degree. The levels of busy intervals are reduced relatively well, and generally, the flagging increases as the alert volume decreases. Aggregation by class can provide higher-level summaries in alert-saturated situations, but there may be better criteria for aggregation than alert classes.

### Flow Stability

To assess the stability of flow profiles, Table 7 compares the alert and busy interval reductions for four signatures used in the learning phase against the reductions in the testing data. Generally, the flagging is slightly higher in the training data set, but for ICMP Dest Unr (Comm Adm Proh), significantly more alerts are marked as anomalous in the test set. This large alert impulse accounts for approximately 14% of the increase in the test data. Even if these alerts were removed, the increase would still be significant. However, the reduction in busy intervals is quite similar, suggesting higher peaks in the test set. The fifth signature, which enforced a local policy, did not exist in the testing data set. This signature created alert impulses, and the alert reduction was marginal in the learning data.

### Performance and Adaptability

With the used parameters, the reduction performance remains almost constant, suggesting that after setting parameters to meet the operator's needs, the approach can adapt to minor changes in alert flow behavior without further adjustment. During the test period, none of the originally well-behaved flows changed to more problematic, impulse-like behaviors, nor vice versa. Signatures with constant alert flows or more random process-type behaviors maintained their original profiles.

### Summary and Monitoring

Using this approach, it is possible to summarize and monitor the levels of high-volume background noise seen by an IDS. Up to 95% of the one-hour time slots showing activity from such an alert flow can be unburdened from distraction. For the remaining intervals, instead of a barrage of alerts, only one alert would be outputted at the end of the interval. Since both data sets came from the same system, the generality of these observations is limited, and more comprehensive testing is required for further validation.

If the user is concerned about losing too much data through aggregation at the signature level, additional criteria such as source and destination addresses and/or ports can be used to create more focused alert streams. The tradeoff between reduction and increased flagged intervals must be considered according to the user's needs and operating environment. Determining if the summarization masked important events in the test set was not possible, as we do not have records of actual detected intrusions and problems in the monitored system.

### Related Work

This work focuses on volume reduction and alert aggregation, not on content improvement or activity tracking. The target is high-volume background noise rather than high-impact alerts, making the approach different from other correlation efforts, such as those presented by Valdes and Skinner [14] or Qin and Lee [15].

Manganaris et al. [16] use data mining to gain better understanding of alert data. Julisch and Dacier [2] take the approach further and report episode rules, a labor-intensive method, and develop conceptual clustering to construct filters for false positives. Instead of filtering, we propose monitoring the levels of background noise, provided it is possible to significantly reduce the number of alerts displayed to the operator.

The EWMA model has been used in various applications, including intrusion detection. Two recent approaches are from Ye et al. [9, 10] and ArQoS1 developed by Mahadik et al. [11]. Both of these IDSes are primarily meant to detect Denial of Service (DoS) attacks. Ye et al. use host-based data sources, such as Solaris BSM audit event intensity, for attack detection. ArQoS monitors DiﬀServ network’s Quality of Service (QoS) parameters, like bit rate, jitter, and packet drop rate, to detect attacks on QoS. 

Ye et al. test different control charts, finding that all can be used for detecting attacks causing statistically significant changes in event intensity. Mahadik et al. [11] use EWMA techniques for more stationary flows and a χ2 statistic for less stationary ones. Their control chart differs from those used by Ye et al., and their tests show that the overall system can quickly detect QoS degradation. Our proposed approach differs in the following ways:
1. It provides a view of the system state rather than detecting DoS attacks or intrusions.
2. The audit source is the alert database created by a network-based sensor, requiring no access to host audit trails or routers.
3. The control chart is defined slightly differently.

### Conclusions and Future Work

Alerts triggered by non-attack, yet harmful activity, often create large volumes of alerts. Typically, this raw intelligence output is insignificant and distracting for the operator, but changes in the levels of this background noise can be of interest. Simply filtering or judging these alerts as false by a correlation engine can result in the loss of this information.

We presented an alert processing method based on EWMA control charts to summarize the behavior of such alert flows, meeting the five objectives: anomaly highlighting, decreasing operator load, reduction measurement, determination of suitable flows for monitoring, and trend visualization. According to our experience, this technique can highlight anomalies in high-volume alert flows showing sufficient regularity. This approach makes high alert levels more sustainable without deactivating them. We believe the method can be used as is or in complement to other correlation means to monitor alerts considered as background noise of an operational system. The provided additional diagnostic capabilities, though modest, allow the operator to save time for more relevant tasks by being informed only of significant changes in the noise level. A metric based on the proportion of time units freed from manual processing when monitoring an aggregate instead of raw alert flow was proposed.

Alert flows creating fewer alerts or requiring strict timeliness in detection are better treated with other methods, as the sampling interval is scarce, and the method cannot find useful trends from small amounts of alerts.

As the method's applicability for a particular flow is determined from its visualization, explicit criteria and an automated process are needed. Additionally, generating meaningful alert summaries for the operator needs to be addressed to meet the 'trend visualization' objective.

For now, only signatures and signature classes have been used as aggregation criteria. Using source and destination hosts or networks could lead to more specific flows if required. We also intend to investigate different similarity measures for forming the monitored aggregates, such as similar packet payloads.

Gathering user experience from operators would be interesting, and the method is being integrated into the alert console used internally at France Télécom.

### References

1. James P. Anderson. Computer Security Threat Monitoring and Surveillance. Technical report, James P. Anderson Co., Fort Washington, Pa 19034, April 1980.
2. Klaus Julisch and Marc Dacier. Mining Intrusion Detection Alarms for Actionable Knowledge. In Proceedings of Knowledge Discovery in Data and Data Mining (SIGKDD), 2002.
3. P. A. Porras, M. W. Fong, and A. Valdes. A Mission-Impact-Based Approach to INFOSEC Alarm Correlation. In Wespi et al. [17], pages 95–114.
4. B. Morin and H. Debar. Correlation of Intrusion Symptoms: an Application of Chronicles. In Vigna et al. [18], pages 94–112.
5. H. Debar and B. Morin. Evaluation of the Diagnostic Capabilities of Commercial Intrusion Detection Systems. In Wespi et al. [17].
6. Klaus Julisch. Mining Alarm Clusters to Improve Alarm Handling Efficiency. In Proceedings of the 17th Annual Computer Security Applications Conference (ACSAC2001), December 2001.
7. Soon Tee Teoh, Kwan-Liu Ma, S. Felix Wu, and Xiaoliang Zhao. A Visual Technique for Internet Anomaly Detection. In Proceedings of IASTED Computer Graphics and Imaging. ACTA Press, 2002.
8. S. W. Roberts. Control Chart Tests Based On Geometric Moving Averages. Technometrics, 1(3):230–250, 1959.
9. Nong Ye, Sean Vilbert, and Qiang Chen. Computer Intrusion Detection Through EWMA for Autocorrelated and Uncorrelated Data. IEEE Transactions on Reliability, 52(1):75–82, March 2003.
10. Nong Ye, Connie Borror, and Yebin Chang. EWMA Techniques for Computer Intrusion Detection Through Anomalous Changes In Event Intensity. Quality and Reliability Engineering International, 18:443–451, 2002.
11. Vinay A. Mahadik, Xiaoyong Wu, and Douglas S. Reeves. Detection of Denial of QoS Attacks Based on χ2 Statistic and EWMA Control Chart. URL: http://arqos.csc.ncsu.edu/papers.htm, February 2002.
12. Peter Mell, Vincent Hu, Richard Lippman, Joss Haines, and Marc Zissman. An Overview of Issues in Testing Intrusion Detection Systems. NIST IR 7007, NIST CSRC - National Institute of Standards and Technology, Computer Security Resource Center, June 2003.
13. Hervé Debar, Marc Dacier, and Andreas Wespi. A Revised Taxonomy of Intrusion-Detection Systems. Technical Report RZ 3176 (#93222), IBM Research, Zurich, October 1999.
14. A. Valdes and K. Skinner. Probabilistic Alert Correlation. In Wenke Lee, Ludovic Mé, and Andreas Wespi, editors, Proceedings of the 4th International Symposium on Recent Advances in Intrusion Detection (RAID 2001), volume 2212 of Lecture Notes in Computer Science, Heidelberg, Germany, 2001. Springer–Verlag.
15. Xinzhou Qin and Wenke Lee. Statistical Causality Analysis of INFOSEC Alert Data. In Vigna et al. [18], pages 73–93.
16. Stefanos Manganaris, Marvin Christensen, Dan Zerkle, and Keith Hermiz. A Data Mining Analysis of RTID Alarms. 2nd International Symposium on Recent Advances in Intrusion Detection (RAID 1999). Available online: http://www.raid-symposium.org/raid99/PAPERS/Manganaris.pdf.
17. Andreas Wespi, Giovanni Vigna, and Luca Deri, editors. Proceedings of the 5th International Symposium on Recent Advances in Intrusion Detection (RAID 2002), volume 2516 of Lecture Notes in Computer Science, Heidelberg, Germany, 2002. Springer–Verlag.
18. Giovanni Vigna, Erland Jonsson, and Christopher Kruegel, editors. Proceedings of the 6th International Symposium on Recent Advances in Intrusion Detection (RAID 2003), volume 2820 of Lecture Notes in Computer Science, Heidelberg, Germany, 2003. Springer–Verlag.