N/A
7 µs
3 µs
left shift and add
N/A
N/A
70 µs
GPG
Paillier
xpir-bv
Yao cost
ϕ = integer comparison
ϕ = argmax
cpu network transfers
2501 B
71 µs
70 µs
3959 B
NoPriv operations
map lookup
0.17 µs
float addition
0.001 µs
Figure 6: Microbenchmarks for operations shared by Pretzel and the
baselines (Figure 3). Both cpu and network costs are averaged over
1,000 runs; standard deviations (not shown) are within 5% of the av-
erages. OpenPGP encryption and decryption times depend on the
length of the email; we use an email size of 75 KB, which is in line
with average email size [14]. Similarly, Yao costs for ϕ = argmax
depend linearly on the number of input values; we show costs per
input value.
Figure 7: Provider-side cpu time per email in microseconds for the
spam filtering module while varying the number of features (N) in
the spam classification model, and the number of features (L) in an
email. cpu time for NoPriv varies only slightly with N (not visible),
while (provider-side) cpu times for Baseline and Pretzel are inde-
pendent of both L and N (Figure 3).
Provider-side cpu time. Figure 7 shows the per-email cpu time
consumed by the provider.
For emails with fewer features (L = 200), the cpu time of Pretzel is
2.7× NoPriv’s and 0.17× Baseline’s. Pretzel’s is more than NoPriv’s
because in NoPriv the provider does L feature extractions, map
lookups, and float additions, which are fast operations (Figure 6),
whereas in Pretzel, the provider does relatively expensive opera-
tions: one additively homomorphic decryption of a xpir-bv cipher-
text plus one comparison inside Yao (Figure 3 and §4.1). Pretzel’s
cpu time is lower than Baseline’s because in Pretzel, the provider
decrypts a xpir-bv ciphertext whereas in Baseline the provider
decrypts a Paillier ciphertext (Figure 6).
As the number of features in an email increases (L = {1000, 5000}),
the provider’s cpu time in both Pretzel and Baseline does not change,
as it is independent of L (unlike the client’s) while NoPriv’s in-
creases since it is linear in L (see Figure 3). A particular point of
interest is L = 692 (the average number of features per email in the
Gmail dataset), for which the cpu time of Pretzel is 0.65× NoPriv’s
(as noted at the beginning of this section, the number is lower than
Non-encrypted
Baseline
Pretzel-withGLLMPacking
Pretzel
N = 200K
4.3 MB
51.6 MB
3.1 GB
7.4 MB
T. Gupta et al.
Size
N = 1M
21.5 MB
258.0 MB
15.3 GB
36.7 MB
N = 5M
107.3 MB
1.3 GB
76.3 GB
183.5 MB
Figure 8: Size of encrypted and plaintext spam classification
models. N is the number of features in the model. Pretzel-
withGLLMPacking is Pretzel, but with the packing in Pretzel re-
placed with the packing in GLLM (§4.2).
Ling-spam
Enron
Gmail
Acc. Prec. Rec. Acc. Prec. Rec. Acc. Prec. Rec.
99.7 95.2
98.9 97.2
98.9 97.2
99.7 95.2
98.1 98.1
99.4 97.1
99.2 97.5
98.1 97.9
98.1
98.5
98.5
98.1
GR-NB 99.4
LR 99.4
SVM 99.4
GR 99.3
98.8
98.9
98.7
98.8
99.2 98.4
98.4 99.5
98.5 99.0
99.2 98.4
Figure 9: Accuracy (Acc.), precision (Prec.), and recall (Rec.) for
spam filtering in Pretzel. Sets of columns correspond to the differ-
ent spam datasets, and the rows correspond to the classification al-
gorithms Pretzel supports: GR-NB, binary LR, and two-class SVM
(§3.1). Also shown is accuracy for the original Graham-Robinson
Naive Bayes algorithm (GR).
in the status quo in part because Pretzel shifts computational work
to the client).
Client-side overheads. Figure 8 shows the size of the spam model
for the various systems. We notice that the model in Pretzel is ap-
proximately 7× smaller than the model in Baseline. This is due
to the difference in packing in the two systems: “across rows and
columns” (in Pretzel) versus “across columns” (in GLLM [60], imple-
mented in Baseline (§4.2). We also notice that, given the refinement
of replacing the cryptosystem (§4.1), packing across both rows and
columns is essential in Pretzel, to prevent a manifold increase in
the model size (the Pretzel-withGLLMPacking row in the figure).
In terms of client-side cpu time, Pretzel takes ≈ 358 ms to pro-
cess an email with many features (L = 5000) against a large model
(N = 5M). This time is dominated by the L left shift and add opera-
tions in the secure dot product computation (§4.2). Our microbench-
marks (Figure 6) explain this number: 5000 of the left shift and add
operation takes 5000 × 70µs = 350ms. A large L is an unfavor-
able scenario for Pretzel: client-side processing is proportional to L
(Figure 3).
Network transfers. Both Pretzel and Baseline add network over-
head relative to NoPriv. It is, respectively, 19.6 KB and 3.6 KB per
email (or 26.1% and 4.8% of NoPriv, when considering average email
size as reported by [14]). These overheads are due to transfer of
a ciphertext and a comparison inside Yao’s framework (Figure 2).
Pretzel’s overheads are higher than Baseline’s because the xpir-bv
ciphertext in Pretzel is much larger than the Paillier ciphertext.
Accuracy. Figure 9 shows Pretzel’s spam classification accuracy
for the different classification algorithms it supports. (The figure
also shows precision and recall. Higher precision means lower
 0 300 600 900 1200 1500 1800 2100 2400N = 200KN = 1MN = 5MCPU time per email (µs)  (lower is better)Number of features in modelNoPriv (L=200)NoPriv (L=1K)NoPriv (L=5K)BaselinePretzelPretzel: Email encryption and provider-supplied functions are compatible
SIGCOMM ’17, August 21-25, 2017, Los Angeles, CA, USA
Size
N = 20K
144.3 MB
288.4 MB
720.7 MB
N = 100K
769.4 MB
1.5 GB
3.8 GB
Non-encrypted
Baseline
Pretzel
Figure 12: Size of topic extraction models for the various systems. N
is the number of features in the model. B is set to 2048.
Percentage of the total training dataset
1%
79.6
89.6
95.9
98.7
2%
84.0
92.1
97.3
99.3
5%
90.1
95.6
98.5
99.8
10%
94.0
97.7
99.3
99.9
B′ = 5
B′ = 10
B′ = 20
B′ = 40
Figure 13: Impact of decomposed classification (§4.3) on classifica-
tion accuracy for the RCV1 dataset with 296 topics. The columns
(except the first) correspond to the percentage of the total training
dataset used to train the (public) model that extracts candidate top-
ics. The rows correspond to the number of candidate topics (B′). The
cells contain the percentage of test documents for which the “true
category” (according to a classifier trained on the entire training
dataset) is contained in the candidate topics. Higher percentage is
better; 100% is ideal.
Network transfers. Figure 11 shows the network transfers per
email for Baseline and Pretzel. As expected, with decomposed clas-
sification, Pretzel’s network transfers are lower; they are 402 KB per
email (or 5.4× the average email size of 75 KB, as reported in [14])
for B = 2048, B′ = 20, and 201 KB per email (or 2.7× the average
email size) for B = 2048, B′ = 10.
Client-side overheads. Figure 12 shows the model sizes (before
feature selection; §4.3) for the various systems for different values
of N and B = 2048. Pretzel’s model is bigger than Baseline’s for
two reasons. First, its model comprises a public part and an en-
crypted part that comes from the provider. Second, the ciphertext-
to-plaintext size ratio in xpir-bv is twice that of Paillier.
In terms of client-side cpu time, as in spam filtering, Pretzel (with
or without decomposed classification) takes less than half a second
to process an email with many features (L = 5000).
Loss of accuracy. Recall that classification accuracy for topic ex-
traction in Pretzel could be affected by decomposed classification
and feature selection (§4.3). Figure 13 shows the variation in classi-
fication accuracy due to decomposed classification. (The depicted
data are for the RCV1 dataset and NB classifier; the qualitative
results are similar for the other datasets and classifiers.) The data
suggest that an effective non-proprietary classifier can be trained
using a small fraction of training data, for only a small loss in
end-to-end accuracy.
Figure 14 shows classification accuracy for classifiers trained
with and without feature selection, and while varying the degree of
feature selection (using the Chi-square selection technique [116]). It
appears that even after a high degree of feature selection, accuracy
drops only modestly below its peak point. (This would reduce the
client-side storage cost presented in Figure 12.)
Figure 10: Provider-side cpu time per email in milliseconds for topic
extraction, varying the number of categories (B) in the model and
the number of candidate topics (B′). The case B = B′ measures Pretzel
without the decomposed classification technique (§4.3). The y-axis
is log-scaled. N and L are set to 100K and 692 (average number of
features per email in the authors’ Gmail dataset). The cpu times do
not depend on N or L for Pretzel and Baseline; they increase linearly
with L and vary slightly with N for NoPriv.
network transfers
B = 128
501.5 KB