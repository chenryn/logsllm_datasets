process of PCFG-based guess generation and manage
to identify its crux. Here we take the improved PCFG at-
tack against Tianya (trained on Duowan) as an example.
During training, we have added 98K name segments (see
Table 6) into the L-segment dictionary.
Fig. 5(a) demonstrates that these 98K name segments
only cover 2.88% of the total L segments of the test set
Tianya. However, the original L segments trained from
Duowan can cover 13.75% of the name segments and
60.59% of the non-name L segments in Tianya. This
suggests that Duowan can well cover the name segments
in the test set Tianya, and thus the addition of some extra
names would have limited impacts. This observation
also holds for the other eight test sets. The detailed
results are summarized in Table 7, where “Duowan1M”
is Duowan 1M for short and “PY name” is Pinyin name
for short. The fraction of L-segments in the test set y that
can be covered by the set x is denoted by CoL(x).
Table 7 shows that no matter x=Duowan 1M or
Duowan: 1) CoL(x) is at least 11.12 times (= 65.64%/
5.90%) larger than CoL(Pinyin name)-CoL(x); 2) CoL(
Pinyin name)∩CoL(x) is at least 1.92 times (=11.35%/
5.90%) larger than CoL(Pinyin name)-CoL(x). This
suggests that adding extra names into the PCFG
L-segments when training is of limited yields. Note that,
this does not contradict our observation that Pinyin
names are prevalent in Chinese web passwords and pose
a serious vulnerability. Actually, this does suggest that
when the training set is selected properly,
the name
segments in passwords can be well guessed. Still, when
there is no proper training set available, our improved
attack would demonstrate its advantages (see Fig. 5(b)).
Though our improved PCFG algorithm might not be
optimal, its cracking results represent a new benchmark
that any future algorithm should aim to decisively clear.
Limitations. We mainly investigate the impacts of
names on password cracking, and similar observations
and implications are likely to hold for dates (but with no
conﬁrmation). We leave it as future work. In addition,
as our focus is the overall security of Chinese passwords
(and its comparison with English counterparts), we only
show the overall effectiveness of our improved PCFG
attack. It is also interesting to see to what extent the im-
proved PCFG structure and the usage of Duowan would
respectively have impacts on the cracking effectiveness,
but it is independent of the presented work.
4.2 Markov-based attacks
To show the robustness of our ﬁndings about password
security, we further conduct Markov-based attacks.
4.2.1 Markov-based experimental setups
To make our experiments as reproducible as possible,
we now detail the setups. As recommended in [36],
we consider two smoothing techniques (i.e., Laplace
Smoothing and Good-Turing Smoothing) to deal with
the data sparsity problem and two normalization tech-
niques (i.e., distribution-based and end-symbol-based)
to deal with the unbalanced length distribution problem
of passwords. This brings four attacking scenarios in
Table 8.
In each scenario we consider three types of
Markov order (i.e., order-5, 4 and 3) to investigate which
order performs best. It is reported that another scenario
(i.e., backoff with end-symbol normalization) performs
“slightly better” than the above 4 scenarios, yet it is “ap-
proximately 11 times slower, both for guess generation
and for probability estimation” [36]. We also investigate
this scenario and observe similar results. Thus, attackers,
who particularly care about the cost-effectiveness [4], are
highly unlikely to exploit this scenario.
Particularly, there is a challenge to be addressed when
implementing the Good-Turing (GT) smoothing tech-
nique. To our knowledge, we for the ﬁrst time explicate