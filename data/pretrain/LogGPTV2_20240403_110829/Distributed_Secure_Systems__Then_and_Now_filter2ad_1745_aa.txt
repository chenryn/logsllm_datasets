title:Distributed Secure Systems: Then and Now
author:Brian Randell and
John M. Rushby
23rd Annual Computer Security Applications Conference
23rd Annual Computer Security Applications Conference
Biographies: Classic Paper 
Brian Randell 
John Rushby 
Computing Laboratory, University of Newcastle upon Tyne  
Computer Science Laboratory, SRI International 
Brian  Randell  graduated  in  Mathematics  from  Imperial  College,  London,  in  1957  and  joined  the 
English Electric Company, where he led a team that implemented a number of compilers, including the 
Whetstone KDF9 Algol compiler. From 1964 to 1969, he was with IBM in the United States, mainly at 
the  IBM  T.  J.  Watson  Research  Center,  working  on  operating  systems,  the  design  of  ultra-high  speed 
computers, and computing system design methodology. He then became Professor of Computing Science 
at Newcastle University, where in 1971 he set up the project that initiated research into the possibility of 
software fault tolerance, and introduced the “recovery block” concept. Subsequent major developments 
included the Newcastle Connection, and the prototype Distributed Secure System. He has been Principal 
Investigator  on  a  succession  of  research  projects  in  reliability  and  security  funded  by  the  Science 
Research Council (now Engineering and Physical Sciences Research Council), the Ministry of Defence, 
and the European Strategic Programme of Research in Information Technology (ESPRIT), and now the 
European  Information  Society  Technologies  (IST)  Programme.  Most  recently  he  has  had  the  role  of 
Project  Director  of  CaberNet  (the  IST  Network  of  Excellence  on  Distributed  Computing  Systems 
Architectures), and of two IST Research Projects, MAFTIA (Malicious- and Accidental-Fault Tolerance 
for  Internet  Applications)  and  DSoS  (Dependable  Systems  of  Systems).  He  has  published  nearly  200  
technical papers and reports, and is co-author or editor of seven books. He is now Emeritus Professor of 
Computing Science, and Senior Research Investigator, at Newcastle University. He was a Member of the 
Conseil Scientifique of the CNRS, France (2001-5), and Chairman of the IEEE John von Neumann Medal 
Committee  (2003-5),  and  is  a  Member  of  the  ACM  A.M.  Turing  Award  Committee  (2005-9).  He  has 
received a D.Sc. from the University of London, Honorary Doctorates from the University of Rennes, and 
the Institut National Polytechnique of Toulouse, France, and the IEEE Emanuel R. Piore 2002 Award. 
John  Rushby  received  B.Sc.  and  Ph.D.  degrees  in  computing  science  from  the  University  of 
Newcastle upon Tyne in 1971 and 1977, respectively. He joined the Computer Science Laboratory of SRI 
International in 1983, and served as its director from 1986 to 1990. He currently manages its research 
program in formal methods and dependable systems, which develops the highly regarded and widely used 
PVS verification system, the SAL suite of model checkers, and the Yices SMT solver. Prior to joining 
SRI, he held academic positions at the Universities of Manchester and Newcastle upon Tyne in England.  
His research interests center on the use of formal methods for problems in the design and assurance of 
secure and dependable systems. Dr. Rushby is a former associate editor for Communications of the ACM, 
IEEE Transactions on Software engineering, and Formal Aspects of Computing. He is the author of the 
(now rather outdated) chapter on formal methods for the FAA Certification Handbook, and a member of a 
National  Research  Council  study  that  recently  delivered  its  report  “Software  for  Dependable  Systems: 
Sufficient Evidence?”   
1063-9527/07 $25.00 © 2007 IEEE
1063-9527/07 $25.00 © 2007 IEEE
DOI 10.1109/ACSAC.2007.48
DOI 10.1109/ACSAC.2007.48
177
177
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:38:24 UTC from IEEE Xplore.  Restrictions apply. 
Distributed Secure Systems: Then and Now 
Brian Randell * and John Rushby** 
* School of Computing Science 
Newcastle University 
Newcastle upon Tyne 
NE1 7RU, UK 
PI:EMAIL  
Abstract 
The  early  1980s  saw  the  development  of  some 
rather  sophisticated  distributed  systems.  These  were 
not  merely  networked  file  systems:  rather,  using 
remote procedure calls, hierarchical naming, and what 
would  now  be  called  middleware,  they  allowed  a 
collection  of  systems  to  operate  as  a  coherent  whole. 
One  such  system  in  particular  was  developed  at 
Newcastle  that  allowed  pre-existing  applications  and 
(Unix)  systems  to  be  used,  completely  unchanged,  as 
components  of  an  apparently  standard  large  (multi-
processor) Unix system. 
The  Distributed  Secure  System  (DSS)  described  in 
our  1983  paper  proposed  a  new  way  to  construct 
secure  systems  by  exploiting  the  design  freedom 
created by this form of distributed computing. The DSS 
separated  the security concerns of policy enforcement 
from those due to resource sharing and used a variety 
of  mechanisms  (dedicated  components,  cryptography, 
periods  processing,  separation  kernels)  to  manage 
resource  sharing  in  ways  that  were  simpler  than 
before. 
In  this  retrospective,  we  provide  the  full  original 
text  of  our  DSS  paper,  prefaced  by  an  introductory 
discussion  of  the  DSS  in  the  context  of  its  time,  and 
followed  by  an  account  of 
subsequent 
implementation  and  deployment  of  an 
industrial 
prototype  of  DSS,  and  a  description  of  its  modern 
interpretation in the form of the MILS architecture. We 
conclude  by  outlining  current  opportunities  and 
challenges presented by this approach to security. 
the 
Introduction and Background 
The idea of a DSS (Distributed Secure System) was 
in  large  part  an  almost  accidental  outcome  of  a  long-
** Computer Science Laboratory, 
SRI International 
Menlo Park CA USA 
PI:EMAIL 
running  and  indeed  still  continuing  series  of  research 
projects  at  Newcastle  on  reliability  and  in  particular 
fault tolerance, work whose origins can be traced back 
at  least  in  part  to  the  original  1968  NATO  Software 
Engineering  Conference  [11].  The  discussions  at  this 
conference of the major problems of many then-current 
large software projects were a great spur to research in 
subsequent  years  aimed  at  producing  bug-free 
software. But we at Newcastle, on the other hand, were 
motivated  to  wonder  whether  it  might  be  possible  to 
find  means  of  achieving  reasonably  reliable  service 
from  complex  software  systems  despite  the  bugs  that 
they would almost certainly still contain.  
Our  initial  work  had  simply  concerned  sequential 
programs.  But by 1975 we had moved on  to consider 
the  problems  of  providing  structuring  for  error 
recovery among sets of co-operating processes. By the 
late 1970s we were starting to consider the problems of 
distributed computing systems. In effect, what we had 
started  to  do,  and  in  fact  continued  to  do  for  some 
years,  was  gradually  extend  the  range  of  systems  and 
types  of  fault  for  which  we  tried  to  provide  well-
structured  error  recovery;  as  a  long  term  research 
project,  as  opposed 
to  an  urgently-needed  real 
application  project,  we  had  the  luxury  of  gradually 
trying  to  add  complexity  to  reliability,  as  opposed  to 
striving to add reliability to immense complexity. 
Our  reliability  research  was  mainly  funded  by  the 
SRC 
(Science  Research  Council),  but  we  had 
additional funding from  the RSRE (the  Royal Signals 
and  Radar  Establishment)  of  the  UK  Ministry  of 
Defence,  which  later  became  part  of  the  Defence 
Research  Agency,  and  was 
later  still  partially 
privatized as Qinetiq. But then RSRE offered us some 
further  funding  to  work  on  security  rather  than 
reliability  –  specifically  to  undertake  a  detailed  and 
critical study of the various projects then under way in 
178178
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:38:24 UTC from IEEE Xplore.  Restrictions apply. 
to  different 
allocating  different  security  domains 
physical  machines,  and  enforcing  security  constraints 
on inter-machine communication, rather than by means 
of the operating system in a single machine.  
By  the  end  of  the  week  we  had  a  working 
demonstration of our DSS scheme, albeit an extremely 
crude  one  in  which  the  encryption-based  security 
controls  were  implemented  in  software  (indeed  in 
shell-script!)  rather  than  in  the  sort  of  actual  small 
trusted  special-purpose  hardware  communications 
devices  that  we  envisaged  using.  (We  initially  called 
these devices Z-boxes, but were later strongly advised, 
for mysterious reasons that were never explained to us, 
to instead refer to them as TNIUs, standing for Trusted 
Network Interface Units.)  
A  further  point  that  struck  us  almost  immediately 
was that we could take advantage of complete mutual 
independence  of  the  TNIUs  and  the  TMR  layer. 
Specifically it would be possible to combine the use of 
TNIUs,  and  of  groups  of 
three  UNIX  systems 
incorporating TMR layers, and so very readily produce 
a  system  that  was  both  highly  reliable  and  highly 
secure,  without  having  to  concern  ourselves  about 
possible 
the  security  and 
reliability mechanisms.  
interference  between 
When  we  reported  our  DSS  ideas  to  RSRE,  they 
found  them  interesting,  and  sent  a  small  party  to 
Newcastle to see our demonstration system, but raised 
no  objections  to  our  submitting  the  DSS  paper  for 
publication [17]. However, their  interest grew, indeed 
to  the  point  of  their  planning  their  own  full-scale 
system  building  exercise.  Thus  when  –  prior  to 
publication  of  our  paper  –  we  discovered  a 
vulnerability  in  the  design  of  the  (virtual)  multi-level 
secure file store that had been missed by the referees, 
we  were  forbidden  to  reveal  this  vulnerability,  leave 
alone correct the paper by including a solution to it, 
What  happened  afterwards  is  described  in  the 
postscript  that  follows  the  original  DSS  paper,  which 
we  reproduce  here  in  full.  (The  citations  in  this 
introduction and in the postscript are to the “Additional 
References”  at  the  end  of  this  document,  and  so  are 
kept separate from those in the original DSS paper.) 
the States aimed at providing formal proofs of various 
would-be highly secure systems.  
This enabled Rushby to rejoin Newcastle (where he 
had  been  a  student),  to  work  alongside  the  reliability 
project.  Rushby  came  to  realize  that  the  Secure  User 
Executive developed (largely by Derek Barnes) [4] had 
a  much  simpler  structure  than  most  of  the  secure 
operating  systems  being  developed  in  the  USA,  and 
that  its  formal  verification  would  be  best  served  by  a 
different  approach.  This  led  to  his  formulation  of  the 
ideas  of  a  “separation  kernel”  [13],  and  of  “proof  of 
separability”  [14],  which  were  later  to  influence  the 
conception of DSS. 
this 
The reliability project had intended to base its work 
on  the  problems  of  tolerating  faults  in  distributed 
systems  on  some  suitable  pre-existing  distributed 
system.  Our  efforts  to  find  such  a  system  came  to  an 
abrupt  halt  when  in  1982  we  came  up  with  a  novel 
scheme for constructing a powerful distributed system 
from  a  set  of  UNIX  systems,  taking  advantage  of  the 
hierarchical  naming  structure  used  in  UNIX.  Our 
scheme involved the insertion of a transparent layer of 
software (or what would now be called “middleware”) 
at the UNIX system call level, so that neither the UNIX 
system nor any of the  application programs had  to be 
altered  – 
the 
“Newcastle  Connection”,  the  distributed  systems  we 
could build using it we termed “UNIX United” systems 
[7].  An  important  characteristic  of  the  Newcastle 
Connection,  the  chief  designer  of  which  was  our 
colleague  Lindsay  Marshall,  was  that  it  dealt  with  all 
of the system  calls, not  just those involved with files, 
so that UNIX United was truly a distributed computing 
system, not merely a distributed file system. 
layer  of  software  we  called 
In  UNIX  United  we  had  come  up  with  what  was 
essentially  a  recursive  approach  to  system  building 
[12], and we rapidly realized that it would be possible 
to exploit the recursive characteristics of the Newcastle 
Connection and UNIX United by the provision of other 
transparent  layers  of  software,  including  one  for 
hardware  fault  tolerance,  based  on  the  use  of  Triple 
Modular Redundancy (TMR).  
It  was  at  this  stage  that  Rushby  announced  that  he 
was  tired  of  theoretical  security  research  and  of 
critiquing  others’  such  research,  and  said  that  he 
wanted to join in the system-building fun that the rest 
of  us  were  having.  Within  a  single  conversation, 
against  the  background  of  the  twin  ideas  of  the 
Newcastle Connection and of Proofs of Separation, we 
came to the understanding that the recursive approach 
to  system  building  could  be,  so  to  speak,  applied  to 
deconstruct a system as well as to build one. Thus we 
realized  that  would  be  possible,  indeed  remarkably 
easy,  to  implement  an  apparently-conventional  UNIX 
system  that  enforced  a  multi-level  security  policy  by 
179179
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:38:24 UTC from IEEE Xplore.  Restrictions apply. 
A distributed general-purpose computing 
system that enforces a multilevel security 
policy can be created by properly linking 
standard Unix systems and small trustworthy 
security mechanisms. 
A Distributed Secure System 
John Rushby and Brian Randell 
University of Newcastle upon Tyne 
that 
A  secure  system  is  one  that  can  be  trusted  to  keep 
secrets,  and  the  important  word  here  is  “trusted.” 
Individuals,  governments,  and  institutions  such  as 
banks, hospitals, and other commercial enterprises will 
only consign their secrets to a computer system if they 
can be absolutely certain of confidentiality. 
security 
The  problems  of  maintaining 
are 
compounded because the sharing of secrets is generally 
desired but only in a tightly controlled manner. In the 
simplest  case,  an 
individual  can  choose  other 
individuals  or  groups  with  whom  he  wishes  to  share 
his private information. This type of controlled sharing 
is  called discretionary security because  it is permitted 
at the discretion of the individual. 
however, 
When the  individuals concerned are members of an 
organization, 
organization  may 
circumscribe  their discretionary power to grant  access 
to  information  by  imposing  a  mandatory  security 
policy to safeguard the interests of the organization as 
a whole. The most widely used scheme of this type is 
the  multilevel  security,  or  MLS,  policy  employed  in 