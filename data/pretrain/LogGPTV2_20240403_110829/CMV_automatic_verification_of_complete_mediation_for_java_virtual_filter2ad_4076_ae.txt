# Experimental Results from Harmony VM

The following table presents the experimental results from the Harmony VM, which will be analyzed in detail.

| Total Methods | LOBC | Good Methods | APS Methods | Risky Methods | New Risky Methods | Real Risky Methods |
|---------------|------|--------------|--------------|---------------|-------------------|--------------------|
| 53838         | 0    | 51636        | 0            | 50405         | 0                 | 0                  |
| 50300         | 0    | 50302        | 51696        | 0             | 0                 | 0                  |
| 52442         | 0    | 54427        | 0            | 50955         | 0                 | 52574              |
| 163           | 0    | 3075         | 2928         | 2936          | 3000              | 2988               |
| 2973          | 0    | 2941         | 2928         | 3027          | 2947              | 3087               |
| 3024          | 0    | 2933         | 2928         | 2930          | 3037              | 3089               |
| 3168          | 0    | 2986         | 3023         | 65            | 121               | 105                |
| 110           | 0    | 106          | 106          | 106           | 109               | 106                |
| 114           | 0    | 108          | 105          | 118           | 105               | 106                |
| 105           | 0    | 117          | 118          | 107           | 111               | 107                |
| 0             | 0    | 0            | 0            | 0             | 0                 | 0                  |

- **Total Methods**: The total number of methods called by the class, computed through a transitive closure, excluding filtered methods. This is the number of nodes in the call graph.
- **LOBC (Lines of Bytecodes)**: The total number of lines of bytecodes analyzed, where each instruction in bytecode is counted as one line. This number represents the actual lines of code being analyzed for all the methods given in the "Total Methods" column.
- **Good Methods**: The number of methods that are certified to have a security check before any sensitive operation.
- **APS (All Path Secure) Methods**: The number of methods that are secure across all paths.
- **Risky Methods**: The number of risky methods, which are public and not good.
- **New Risky Methods**: The number of newly computed risky methods in the analysis of the class.
- **Real Risky Methods**: The number of real risky methods identified after semi-automatically analyzing the risky methods with the witness. A real risky method is one that has at least one feasible bad path in practice (not a false alarm).

## Summary of Results

From the results, we observe that a large fraction of the methods are good. These methods are certified to have a security check before any sensitive operation. Overall, in the HotSpot VM, 61 risky methods were found, while in the Harmony VM, no risky methods were reported.

For instance, a total of 1520 methods were analyzed in the HotSpot VM, resulting in 61 risky methods. Only these 61 methods need further analysis, reducing the effort by two orders of magnitude. In the Harmony VM, a total of 3928 methods were analyzed, and none of these methods were reported as risky.

We consider this reduction in the amount of human effort required to perform the entire analysis quite significant. We also provide automation support for manually analyzing the risky methods, which is described below.

## Tool Support for Manual Analysis of Results

Each risky method is a public method that is classified as bad. For each bad method, we generate a compressed witness. A compressed witness for a bad method \( M_0 \) is a sequence of nodes in the control flow graph (CFG) of \( M_0 \) ending in a sensitive operation or a node that invokes another method, say \( M_1 \). In the latter case, \( M_1 \) itself is a bad method whose witness ends in a sensitive operation within \( M_1 \) or ends in a call to another bad method \( M_2 \). Corresponding to each bad method \( M_0 \), we construct a chain of methods \( M_0, \ldots, M_k \) such that there is a path in the expanded control flow graph of \( M_0 \) that goes through nodes of all these methods, ending in a sensitive operation in \( M_k \). All such chains corresponding to risky methods are arranged as a forest, with the root nodes of the trees in the forest being the bad methods where the sensitive operations are performed without an a-priori security check. These root methods can be automatically identified from the witnesses of the risky methods and need to be manually analyzed in more detail. This additional step further minimizes the number of methods needed to be manually analyzed.

For the HotSpot VM, all the witnesses of risky methods can be arranged as an (inverted) tree shown in Figure 7. For the sake of space, we show only a portion of the tree close to the root bad methods. This figure shows that all 61 risky methods in the HotSpot VM are due to a private native method `forName0` declared in `java.lang.Class`. This method returns a `Class` object associated with a given class using the class loader supplied as an argument. Since returning the `Class` object can be sensitive, the VM needs to perform a security check.

There are two methods through which `forName0` can be directly accessed. The code for both methods is given in Figure 8.

```java
public static Class forName(String className) throws ClassNotFoundException {
    return forName0(className, true, ClassLoader.getCallerClassLoader());
}

public static Class forName(String name, boolean initialize, ClassLoader loader) {
    if (loader == null) {
        SecurityManager sm = System.getSecurityManager();
        if (sm != null) {
            ClassLoader ccl = ClassLoader.getCallerClassLoader();
            if (ccl != null) {
                // Security check
                sm.checkPermission(..);
            }
        }
    }
    return forName0(name, initialize, loader); // native
}
```

Both `forName` methods are public and have paths from the entry node to `forName0` without a security check. For example, in the second `forName`, a path exists when `if (loader == null)` does not fall through. The existence of such a path results in both methods being summarized as "insecure path, bad" and also risky since they are public. The remaining 59 public methods are reported to be risky because they invoke one of the risky `forName` methods directly or indirectly.

After manually analyzing the code of both `forName` methods, we determined that they are not real risky methods. By passing a `null` loader to `forName0`, the caller requests the class to be loaded via the bootstrap class loader, which is sensitive. Thus, the VM needs to be consulted before loading the class. The absence of a `null` loader being passed to the class is the case when the VM has already assigned a loader for the class, and therefore, there is no requirement for a security check.

After this analysis, we manually updated the `forName` methods' summary from "bad" to "not bad" (i.e., empty bad summary), and our resulting verification run shows that there are zero real risky methods in the HotSpot VM, as shown in column 11 of the results table.

## Analysis Time Performance

For all the classes tested, the average time taken by CMV to analyze each class was 74 seconds. The bulk of the time spent is in CFG construction, which requires going through methods from several different classes. Our approach is a static verification technique, and these values are acceptable, considering that our prototype implementation is currently not optimized for time and space. We are currently exploring an on-the-fly technique that combines CFG construction with the procedure that computes bad and insecure summaries.

## Summary

In summary, the results suggest that our approach is highly suitable for verification efforts involving large code bases such as the Java standard libraries. These results indicate that the approach taken by CMV is scalable and practically useful.

## Conclusion

In this paper, we presented an approach for checking the complete mediation property for the Java class libraries. Our approach is compositional and has a time complexity linear in the size of the libraries, making it scalable for analyzing large libraries, even in the presence of recursive methods. We implemented this approach in a tool called CMV and used it to check the complete mediation property for the Java libraries of two widely used JVMs: HotSpot and Harmony. Our experimental results indicate that our approach is scalable and can lead to a significant reduction in the human effort required for system verification.

## References

[1] G. Ammons, R. Bodik, and J. Larus. Mining specifications. In ACM Symposium on Principles of Programming Languages (POPL), 2002.
[2] K. Ashcraft and D. Engler. Using programmer-written compiler extensions to catch security holes. In IEEE Symposium on Security and Privacy (SSP), May 2002.
[3] T. Ball and S. K. Rajamani. Bebop: A symbolic model checker for Boolean programs. In 7th International SPIN Workshop on SPIN Model Checking and Software Verification, London, UK, 2000.
[4] T. Ball and S. K. Rajamani. The SLAM toolkit. In Computer Aided Verification CAV, New York-Berlin-Heidelberg, July 2001.
[5] G. Brat, K. Havelund, S. Park, and W. Visser. Java PathFinder: Second generation of a Java model checker. In Post-CAV 2000 Workshop on Advances in Verification, July 2000.
[6] H. Chen and D. Wagner. MOPS: An infrastructure for examining security properties of software. In ACM conference on Computer and Communications Security (CCS), 2002.
[7] E. Clarke, E. Emerson, and A. Sistla. Automatic verification of finite-state concurrent systems using temporal logic specification. In ACM Transactions on Programming Languages and Systems (TOPLAS), 1986.
[8] J. Corbett, M. Dwyer, J. Hatcliﬀ, C. Pasareanu, Robby, S. Laubach, and H. Zheng. BANDERA: Extracting finite-state models from Java source code. In 22nd International Conference on Software Engineering (ICSE), Limerick, Ireland, June 2000.
[9] D. Engler, B. Chelf, A. Chou, and S. Hallem. Checking system rules using system-specific, programmer-written compiler extensions. In USENIX Symposium on Operating Systems Design and Implementation (OSDI), 2000.
[10] U. Erlingsson and F. B. Schneider. IRM enforcement of Java stack inspection. In IEEE Symposium on Security and Privacy, Oakland, California, May 2000.
[11] D. Evans and A. Tywman. Flexible policy directed code safety. In IEEE Symposium on Security and Privacy, Oakland, California, May 1999.
[12] P. W. L. Fong and R. D. Cameron. Proof linking: Distributed verification of Java classfiles in the presence of multiple classloaders. In USENIX Java Virtual Machine Research and Technology Symposium (JVM’01), 2001.
[13] T. Fraser, J. Nick L. Petroni, and W. A. Arbaugh. Applying flow-sensitive CQUAL to verify Minix authorization check placement. In PLAS ’06: Proceedings of the 2006 workshop on Programming languages and analysis for security, New York, NY, USA, 2006.
[14] V. Ganapathy, T. Jaeger, and S. Jha. Retrofitting legacy code for authorization policy enforcement. In SP’06: Proceedings of the 2006 IEEE Symposium on Security and Privacy, Oakland, California, USA, May 2006.
[15] V. Ganapathy, D. King, T. Jaeger, and S. Jha. Mining security sensitive operations in legacy code using concept analysis. In ICSE’07: Proceedings of the 29th International Conference on Software Engineering, Minneapolis, Minnesota, USA, May 2007.
[16] L. Gong, M. Mueller, H. Prafullchandra, and R. Schemers. Going beyond the sandbox: An overview of the new security architecture in the Java Development Kit 1.2. In USENIX Symposium on Internet Technologies and Systems, December 1997.
[17] T. A. Henzinger, R. Jhala, R. Majumdar, G. C. Necula, G. Sutre, and W. Weimer. Temporal-safety proofs for systems code. In Computer Aided Verification CAV, 2002.
[18] G. Holzmann. The model checker SPIN. IEEE Transactions on Software Engineering, 1997.
[19] T. Jensen, D. Le Metayer, and T. Thorn. Verification of control flow based security properties. In IEEE Symposium on Security and Privacy, 1999.
[20] L. Koved, M. Pistoia, and A. Kershenbaum. Access rights analysis for Java. In ACM Conference on Object-Oriented Programming, Systems, Languages, and Applications (OOPSLA 2002), 2002.
[21] D. Larochelle and D. Evans. Statically detecting likely buffer overflow vulnerabilities. In USENIX Security Symposium, 2001.
[22] G. Necula. Proof-carrying code. In ACM Symposium on Principles of Programming Languages (POPL), 1997.
[23] S. Owre, S. Rajan, J. Rushby, N. Shankar, and M. Srivas. PVS: Combining specification, proof checking, and model checking. In Computer-Aided Verification, CAV ’96, New Brunswick, NJ, 1996.
[24] T. Reps, S. Horwitz, and M. Sagiv. Precise interprocedural dataflow analysis via graph reachability. In 22nd ACM SIGPLAN-SIGACT symposium on Principles of programming languages, 1995.
[25] J. Saltzer and S. M.D. The protection of information in computer systems. Proceedings of the IEEE, September 1975.
[26] R. Sekar, V.N. Venkatakrishnan, S. Basu, S. Bhatkar, and D. C. DuVarney. Model carrying code: A practical approach for safe execution of untrusted applications. In ACM Symposium on Operating Systems Principles (SOSP), 2003.
[27] U. Shankar, K. Talwar, J. S. Foster, and D. Wagner. Detecting format-string vulnerabilities with type qualifiers. In USENIX Security Symposium, 2001.
[28] R. Vallée-Rai and L. H. et al. SOOT - a Java optimization framework. In Proceedings of CASCON 1999, pages 125–135, 1999.
[29] V.N. Venkatakrishnan, R. Peri, and R. Sekar. Empowering mobile code using expressive security policies. In New Security Paradigms Workshop (NSPW), 2002.
[30] D. S. Wallach and E. W. Felten. Understanding Java stack inspection. In 1998 IEEE Symposium on Security and Privacy, 1998.
[31] X. Zhang, A. Edwards, and T. Jaeger. Using CQUAL for static analysis of authorization hook placement. In USENIX Security Symposium, 2002.