53838
0
51636
0
50405
0
50300
0
50302
51696
0
0
52442
0
54427
0
50955
0
52574
163
0
3075
2928
2936
3000
2988
2973
2941
2928
3027
2947
3087
3024
2933
2928
2930
3037
3089
3168
2986
3023
65
121
105
110
106
106
106
109
106
114
108
105
118
105
106
105
117
118
107
111
107
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
Figure 6: Experimental Results from Harmony VM
that will be analyzed.
The ﬁfth column reports the total number of methods
called by this class, computed through a transitive closure,
excluding the ﬁltered methods. (This is the number of nodes
in the call graph). The sixth column reports the total num-
ber of lines of bytecodes (LOBC) analyzed (each instruction
in bytecode counted as one line). This number is the actual
lines of code being analyzed for all the methods given in
the ﬁfth column. The seventh, eighth and ninth columns re-
port the number of good, all path secure (APS) and risky
methods (a risky method is one that is public and not good).
These numbers are computed for all the methods analyzed
(given in ﬁfth column).
In column nine, the number of risky methods reported
are for the entire set of methods that are analyzed, includ-
ing ones for which summaries have already been computed.
For instance, the analysis of ObjectInputStream results in no
new risky methods, even though the number reported is ﬁve.
To show this, the number of risky methods that are newly
computed in the analysis of the class is shown in column
ten. This value for the analysis of ObjectInputStream is zero.
The eleventh column shows the number of real risky meth-
ods identiﬁed after semi-automatically (i.e., manual anal-
ysis with our tool support described later) analyzing the
risky methods in column ten with the witness. A real risky
method is a risky method that has at least one feasible bad
path in practice (not a false alarm).
Summary of results From the results we see that a large
fraction of the methods are good. These are methods that
are certiﬁed to have a security check before any sensitive
operation. Overall, in the HotSpot VM, we have found 61
risky methods and in the Harmony VM we have no risky
methods.
For instance, a total of 1520 methods were analyzed in
the HotSpot VM. 1520 is the cardinality of the set of all
methods being analyzed in the ﬁfth column in Figure 5,
which resulted in 61 risky methods. Only these 61 methods
109
Figure 7: Analysis of risky methods
need to be analyzed further, resulting in a reduction in two
orders of magnitude. In the Harmony VM, a total of 3928
methods are analyzed, none of these methods was reported
as risky.
We consider the reduction in the amount of human eﬀort
required to perform this entire eﬀort quite signiﬁcant. We
also provide automation support for manually analyzing the
risky methods that we describe below.
Tool support for manual analysis of results
Recall
that each risky method is a bad method that is public. As
indicated earlier, corresponding to each bad method we gen-
erate a compressed witness. Such a compressed witness for
a bad method M0 is a sequence of nodes in the CFG of M0
ending in a sensitive operation, or ending in node that in-
vokes another method say M1. In the later case, M1 itself
is a bad method whose witness ends in a sensitive operation
within M1 or ends in call to another bad method M2. Cor-
responding to each bad method M0, we construct a chain
of methods M0, ..., Mk such that there is a path in the ex-
panded control ﬂow graph of M0 that goes through nodes of
all these methods ending in a sensitive operation in Mk. All
such chains corresponding to risky methods are arranged
as a forest so that the root nodes of the trees in the for-
est are the bad methods where the sensitive operations are
performed without an a-priori security check. Such root
methods can be automatically identiﬁed from the witnesses
of the risky methods. These root methods need to be man-
ually analyzed in more detail. This additional step further
minimizes the number of methods needed to be manually
analyzed.
For the HotSpot VM, all the witnesses of risky methods
can be arranged as an (inverted) tree shown in Figure 7. For
the sake of space, we show only a portion of the tree close
to the root bad methods. This ﬁgure shows that all of these
61 risky methods in HotSpot VM are due to a private native
method name forName0 declared in java.lang.Class. This is
a method that returns a Class object associated with a given
class, using the class loader supplied as argument. Since
returning the Class object can be sensitive, the VM needs to
perform a security check.
There are two methods through which forName0 can be
directly accessed. The code of both methods are given in
public static Class forName(String className)
throws ClassNotFoundException {
return forName0(className,
true, ClassLoader.getCallerClassLoader());
}
public static Class forName(String name, boolean initialize,
ClassLoader loader) {
if (loader == null) {
SecurityManager sm = System.getSecurityManager();
if (sm != null) {
ClassLoader ccl = ClassLoader.getCallerClassLoader();
if (ccl != null) {
}
sm.checkPermission(..);
}
}
}
return forName0(name, initialize, loader); //native
Figure 8: forName() code snippet from Hotspot VM
Figure 8.
Both forName methods are public and have path(s) from
entry node to forName0 without security check. For example,
in the second forName, a path exists when if (load == null)
doesn’t fall through. The existence of such a path results
both methods to be summarized as (cid:104)inscure path, bad(cid:105), and
also risky since they are public. The remaining 59 public
methods are reported to be risky because they invoke one of
the risk forName methods directly or indirectly.
After analyzing the code of both forName methods manu-
ally, we have determined that they are not real risky meth-
ods. By passing a null loader to forName0, the caller requests
the class to be loaded via the bootstrap class loader, which
is sensitive. Thus the VM needs to be consulted before load-
ing the class. The absence of a null loader being passed to
the class is the case when the VM has already assigned a
loader for the class, and therefore there is no requirement
for a security check.
After this analysis, we manually updated the f orN ame
methods summary from bad to not bad (i.e., empty bad sum-
mary), and our resulting veriﬁcation run shows that there
are zero real risky methods in the HotSpot VM, as shown
in column 11 of the results table.
Analysis Time Performance For all the classes tested, the
110
java.lang.Class: java.lang.ClassforName0(String, boolean, ClassLoader): Boldhighlights risky methodsjava.net.URL: void (URL, String)java.io.ObjectInputStream: java.lang.ObjectreadObject()represents other risky methodsaverage time taken by CMV to analyze each class was 74
seconds. The bulk of the time spent is in CFG construction
that requires going through methods from several diﬀerent
classes. Ours is a static veriﬁcation technique, these val-
ues are acceptable, also considering the fact that our pro-
totype implementation is currently not optimized for time
and space. We are currently exploring an on-the-ﬂy tech-
nique that combine CFG construction with the procedure
that computes bad and insecure summaries.
Summary In summary, the results suggest that our ap-
proach is highly suitable for veriﬁcation eﬀorts involving
large code bases such as the Java standard libraries. These
results suggest the approach taken by CMV is scalable and
practically useful.
6. CONCLUSION
In this paper, we have presented an approach for checking
the complete mediation property for the Java class libraries.
Our approach is compositional and is of time complexity
linear in the size of the libraries, and hence is scalable for
analyzing large libraries, even in the presence of recursive
methods. We have implemented this approach in a tool
called CMV and used it in checking the complete mediation
property for the Java libraries of two widely used JVMs:
HotSpot and Harmony. Our experimental results indicate
that our approach is scalable and can lead to large reduction
in human eﬀorts required for system veriﬁcation.
7. REFERENCES
[1] G. Ammons, R. Bodik, and J. Larus. Mining speciﬁcations. In
ACM Symposium on Principles of Programming Languages
(POPL), 2002.
[2] K. Ashcraft and D. Engler. Using programmer-written
compiler extensions to catch security holes. In IEEE
Symposium on Security and Privacy (SSP), May 2002.
[3] T. Ball and S. K. Rajamani. Bebop: A symbolic model checker
for boolean programs. In 7th International SPIN Workshop
on SPIN Model Checking and Software Veriﬁcation, London,
UK, 2000.
[4] T. Ball and S. K. Rajamani. The SLAM toolkit. In Computer
Aided Veriﬁcation CAV, New York-Berlin-Heidelberg, July
2001.
[5] G. Brat, K. Havelund, S. Park, and W. Visser. Java
PathFinder: Second generation of a Java model checker. In
Post-CAV 2000 Workshop on Advances in Veriﬁcation, July
2000.
[6] H. Chen and D. Wagner. MOPS: an infrastructure for
examining security properties of software. In ACM conference
on Computer and Communications Security (CCS), 2002.
[7] E. Clarke, E. Emerson, and A. Sistla. Automatic veriﬁcation of
ﬁnite-state concurrent systems using temporal logic
speciﬁcation. In ACM Transactions on Programming
Languages and Systems (TOPLAS), 1986.
[8] J. Corbett, M. Dwyer, J. Hatcliﬀ, C. Pasareanu, Robby,
S. Laubach, and H. Zheng. BANDERA: extracting ﬁnite-state
models from Java source code. In 22nd International
Conference on Software Engineering (ICSE), Limerick,
Ireland, June 2000.
[9] D. Engler, B. Chelf, A. Chou, and S. Hallem. Checking system
rules using system-speciﬁc, programmer-written compiler
extensions. In USENIX Symposium on Operating Systems
Design and Implementation (OSDI), 2000.
[10] U. Erlingsson and F. B. Schneider. IRM enforcement of java
stack inspection. In IEEE Symposium on Security and
Privacy, Oakland, California, May 2000.
[11] D. Evans and A. Tywman. Flexible policy directed code safety.
In IEEE Symposium on Security and Privacy, Oakland,
California, may 1999.
[12] P. W. L. Fong and R. D. Cameron. Proof linking: Distributed
veriﬁcation of java classﬁles in the presence of multiple
classloaders. In USENIX Java Virtual Machine Research and
Technology Symposium (JVM’01), 2001.
[13] T. Fraser, J. Nick L. Petroni, and W. A. Arbaugh. Applying
ﬂow-sensitive cqual to verify minix authorization check
placement. In PLAS ’06: Proceedings of the 2006 workshop
on Programming languages and analysis for security, New
York, NY, USA, 2006.
[14] V. Ganapathy, T. Jaeger, and S. Jha. Retroﬁtting legacy code
for authorization policy enforcement. In SP’06: Proceedings of
the 2006 IEEE Symposium on Security and Privacy,
Oakland, California, USA, May 2006.
[15] V. Ganapathy, D. King, T. Jaeger, and S. Jha. Mining security
sensitive operations in legacy code using concept analysis. In
ICSE’07: Proceedings of the 29th International Conference
on Software Engineering, Minneapolis, Minnesota, USA, May
2007.
[16] L. Gong, M. Mueller, H. Prafullchandra, and R. Schemers.
Going beyond the sandbox: An overview of the new security
architecture in the java development kit 1.2. In USENIX
Symposium on Internet Technologies and Systems, December
1997.
[17] T. A. Henzinger, R. Jhala, R. Majumdar, G. C. Necula,
G. Sutre, and W. Weimer. Temporal-safety proofs for systems
code. In Computer Aided Veriﬁcation CAV, 2002.
[18] G. Holzmann. The model checker spin. IEEE Transactions on
Software Engineering, 1997.
[19] T. Jensen, D. Le Metayer, and T. Thorn. Veriﬁcation of
control ﬂow based security properties. In IEEE Symposium on
Security and Privacy, 1999.
[20] L. Koved, M. Pistoia, and A. Kershenbaum. Access rights
analysis for Java. In ACM Conference on Object-Oriented
Programming, Systems, Languages, and Applications
(OOPSLA 2002), 2002.
[21] D. Larochelle and D. Evans. Statically detecting likely buﬀer
overﬂow vulnerabilities. In USENIX Security Symposium,
2001.
[22] G. Necula. Proof-carrying code. In ACM Symposium on
Principles of Programming Languages (POPL), 1997.
[23] S. Owre, S. Rajan, J. Rushby, N. Shankar, and M. Srivas. PVS:
Combining speciﬁcation, proof checking, and model checking.
In Computer-Aided Veriﬁcation, CAV ’96, New Brunswick,
NJ, 1996.
[24] T. Reps, S. Horwitz, and M. Sagiv. Precise interprocedural
dataﬂow analysis via graph reachability. In 22nd ACM
SIGPLAN-SIGACT symposium on Principles of
programming languages, 1995.
[25] J. Saltzer and S. M.D. The protection of information in
computer systems. proceedings of the IEEE, September 1975.
[26] R. Sekar, V.N. Venkatakrishnan, S. Basu, S. Bhatkar, and
D. C. DuVarney. Model carrying code: A practical approach
for safe execution of untrusted applications. In ACM
Symposium on Operating Systems Principles (SOSP), 2003.
[27] U. Shankar, K. Talwar, J. S. Foster, and D. Wagner. Detecting
format-string vulnerabilities with type qualiﬁers. In USENIX
Security Symposium, 2001.
[28] R. Vall´ee-Rai and L. H. et al. SOOT - a Java optimization
framework. In Proceedings of CASCON 1999, pages 125–135,
1999.
[29] V.N. Venkatakrishnan, R. Peri, and R. Sekar. Empowering
mobile code using expressive security policies. In New Security
Paradigms Workshop (NSPW), 2002.
[30] D. S. Wallach and E. W. Felten. Understanding java stack
inspection. In 1998 IEEE Symposium on Security and
Privacy, 1998.
[31] X. Zhang, A. Edwards, and T. Jaeger. Using cqual for static
analysis of authorization hook placement. In USENIX Security
Symposium, 2002.
111