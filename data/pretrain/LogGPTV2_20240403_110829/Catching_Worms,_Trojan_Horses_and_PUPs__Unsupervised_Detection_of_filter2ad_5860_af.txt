consists of two parts: (1) lockstep detection on the main FP
tree, (2) supplementation for ﬁnding partially missing locksteps
(see Section IV-E). The near-biclique detection is done during
lockstep detection, and it results in an overhead of at most 10
seconds. As shown in Figure 9(c), the ﬁrst part is fast, and
requires at most 12 s. Most of the cost of lockstep detection
comes from the supplementation effort, which induces the
three phases of linear growth. In particular, the number of
nodes that have multiple versions in the FP tree increases
signiﬁcantly around batch 94–96, which triggers the third
growth pattern in the total runtime.
While Beewolf searches for these nodes sequentially, we
note that this could be done in parallel, as the supplementation
24https://aws.amazon.com/ec2/
sub-processes are independent of each other. To evaluate this
potential optimization, we estimate the lockstep detection time
with optimal parallelism. Assuming that enough computing re-
sources are available for running all missing lockstep searches
in parallel, the cost of this part of the computation will be
determined by the longest running supplementation. We obtain
the total cost of lockstep detection with optimal parallelism
by adding this to the runtime of lockstep detection on the
main FP tree. As shown in Figure 9(c), this cost is at most 19
seconds, and shows a single pattern of slow linear growth. The
supplementation phase is important for detecting malicious
locksteps: at the last batch, this phase contributes to 95% of
the MDL detections and 91% of the PDL detections. These
locksteps include 48.7% of the MDs and 80.6% of the PDs.
Overall, these results suggest that the cost of Beewolf’s ﬁrst
two analysis steps is amortized over time, as we perform star
detection only on the new batch of data and we maintain the
galaxy graph incrementally. The FP tree construction algorithm
is not incremental and requires traversing the entire graph, but
we optimize this step by pruning the FP tree at level 7, as we
do not typically observe MDLs below this level. Similarly, the
lockstep detection requires traversing the whole FP tree and
constructing version lists for its nodes, but we could optimize
this step by performing the supplementation in parallel. The
resulting runtime of Beewolf increases linearly with the size
of the graph. Our results suggest that maintaining one year of
download events imposes reasonable resource and performance
requirements, even if we execute lockstep detection every day.
VIII. RELATED WORK
Graph-based attack detection. Zhao et al. [43] introduces
BotGraph that detects email accounts involved in spamming.
They exploit the fact that botnet accounts share similar IP
address and build a user-user graph. The aggressive sign-up
behavior forces the botnet accounts to form a large cluster
within the graph. Several works developed a reputation score
system by adopting belief propagation, based on the intuition
of locality. Chau et al. [11] exploit the tendency of hosts with
poor cyber-hygiene having more malware. They construct a bi-
partite graph that represents the hosts and the ﬁles that present
on those hosts. Observing that several malware are distributed
together, Tamersoy et al. [37] design a graph with ﬁles as
nodes where edge is placed between the nodes that share a
common host. Oprea et al. [34] builds a host vs domain graph
incrementally (day-by-day), and detects malicious domains
within a same campaign. In Beewolf, we maintain a graph
based on the accessed by relationship between downloader
and domain. The lockstep behavior detection returns clusters
of downloaders and domains considering the temporal bounds.
Malware distribution. Cova et al. [13] analyzed the rogue
anti-virus campaigns by investigating the malicious domains
involved in the distribution, introduced an attack attribution
method employing feature-based clustering. Vadrevu et al.
[40] introduced AMICO, which is a system for detecting
malware delivery in the live network trafﬁc. They employed a
supervised technique to classify malware download activities.
Invernizzi et al. [19] conducted the study on how the malware
gets delivered through networks, proposed Nazca, a system that
for detecting malicious download events from the web trafﬁc.
13
Fig. 9: Streaming performance: (a) Data growth, (b) Running time of the streaming system, (c) Estimated lockstep detection
runtime with optimal parallelism.
Zhang et al. [42] employed unsupervised technique to identify
the group of related severs that are likely to be involved in
the same malware campaign. Contrary to these works, we
conduct the study solely focusing on the client side of malware
distribution networks, and employ unsupervised technique not
based on features but on graph patterns. Another difference is
in the way we attribute campaigns. While prior work generally
relied on the properties of the malicious domains, we take
advantage of the code signing behavior of the downloaders.
Spam campaigns. Campaigns have been observed in other
attack domains, for example in the context of spam. Several
studies focused on email spam [21], [27] for example to
measure the conversion rates and to analyze the resources
involved in spam monetization. Spam campaigns have also
been observed on social media sites [16], [17]. Prior work
utilized machine learning techniques to characterize social
media spam campaigns. Some of the the prior techniques
discussed use domain speciﬁc features that cannot be applied
on the problem we are focusing on. However, the lockstep
detection algorithm has broad applicability.
Lockstep detection. CopyCatch [4] deals with identifying
locksteps by analyzing the connectivity between users and
pages through the likes relationship. We discuss the limitations
of this algorithm and provide a comparison with Beewolf in
Section VI-B. Most of the work in this space looks at detecting
suspicious nodes [20] or suspicious edges [10] through the
lens of outlier detection. SynchroTrap [9] proposes a malicious
account detection system in the context of social networks to
uncover malicious accounts and campaigns. They cluster users
based on the Jaccard similarity of their actions. Our work
is orthogonal to these techniques. Firstly, Beewolf focusses
on detecting malicious campaigns which correspond to near
bipartite cores. Secondly, our system captures malicious cam-
paigns over a large time interval; the notion of frequent patterns
directly allows us to capture suspicious behavior. Finally, our
algorithm is unsupervised.
IX. CONCLUSIONS
We introduce Beewolf, a system for systematically detect-
ing silent delivery campaigns. Beewolf detects lockstep behav-
ior, which captures a set of downloaders that are controlled
remotely and the domains that they access. Using Beewolf,
we identify and analyze 1.4 million campaigns conducted in
2013. We describe novel ﬁndings about malware distribution
campaigns, such as an overlap between the malware and PUP
delivery ecosystems and the tight business relationships among
several PPI providers. We identify several properties of mal-
ware distribution locksteps, including their size, life cycle, and
frequent domain changes, which allow us to implement several
optimizations for detecting malware delivery campaigns in
a streaming fashion. We also evaluate the performance of
Beewolf in streaming mode, and we show that it scales to
large volumes of data.
Acknowledgments
We thank Jonathan Katz, the anonymous reviewers, and
our shepherd, Alina Oprea, for their feedback. We also thank
VirusTotal for access to their service and Symantec for making
data available through the WINE platform. This research was
partially supported by the National Science Foundation (award
CNS-1564143), the Department of Defense, and a grant from
Amazon Web Services.
REFERENCES
[1] M. Antonakakis, R. Perdisci, D. Dagon, W. Lee, and N. Feamster.
In USENIX security
Building a dynamic reputation system for dns.
symposium, 2010.
[2] M. Antonakakis, R. Perdisci, D. Dagon, W. Lee, and N. Feamster.
Building a dynamic reputation system for dns. In Proceedings of the
19th USENIX Conference on Security, 2010.
[3] M. Antonakakis, R. Perdisci, W. Lee, N. V. II, and D. Dagon. Detecting
malware domains at the upper DNS hierarchy. In 20th USENIX Security
Symposium, 2011.
[4] A. Beutel, W. Xu, V. Guruswami, C. Palow, and C. Faloutsos. Copy-
catch: stopping group attacks by spotting lockstep behavior in social
networks. In WWW, 2013.
[5] L. Bilge, E. Kirda, C. Kruegel, and M. Balduzzi. Exposure: Finding
malicious domains using passive dns analysis. In NDSS, 2011.
[6] L. Bilge, S. Sen, D. Balzarotti, E. Kirda, and C. Kruegel. Exposure:
A passive dns analysis service to detect and report malicious domains.
ACM Trans. Inf. Syst. Secur., 2014.
[7] V. D. Blondel, J.-L. Guillaume, R. Lambiotte, and E. Lefebvre. Fast
Journal of statistical
unfolding of communities in large networks.
mechanics: theory and experiment, 2008.
J. Caballero, C. Grier, C. Kreibich, and V. Paxson. Measuring pay-
per-install: The commoditization of malware distribution. In USENIX
Security Symposium, 2011.
[8]
[9] Q. Cao, X. Yang, J. Yu, and C. Palow. Uncovering large groups of
active malicious accounts in online social networks. In CCS, 2014.
[10] D. Chakrabarti. Autopart: Parameter-free graph partitioning and outlier
detection. In Knowledge Discovery in Databases: PKDD. 2004.
[11] D. H. Chau, C. Nachenberg, J. Wilhelm, A. Wright, and C. Faloutsos.
Polonium: Tera-scale graph mining for malware detection. In SIGKDD,
2010.
[12] A. Clauset, M. E. Newman, and C. Moore. Finding community structure
in very large networks. Physical review E, 70(6):066111, 2004.
[13] M. Cova, C. Leita, O. Thonnard, A. D. Keromytis, and M. Dacier. An
analysis of rogue AV campaigns. In RAID, 2010.
[14] T. D¨ubendorfer and S. Frei. Web browser security update effectiveness.
In CRITIS Workshop, September 2009.
14
#BatchCount (Log Scale)FP tree sizeGalaxy graph sizeNew stars10310410510620406080100120Total runtimeLockstep detection timeFP tree build timeGalaxy graph build timeStar detection time14.037*x + (-0.75131)# BatchCost (second / Log scale)140.79*x + (-12770)7.669*x +71.67310−210−11101102103104102030405060708090100110120Lockstep detection time with optimal parallelismLongest supplementation time Lockstep detection from main FPtree# BatchCost (second)0.10496*x + 1.5032051015102030405060708090100110120[39] K. Thomas, D. Huang, D. Wang, E. Bursztein, C. Grier, T. J. Holt,
C. Kruegel, D. McCoy, S. Savage, and G. Vigna. Framing dependencies
introduced by underground commoditization. In WEIS, 2015.
[40] P. Vadrevu, B. Rahbarinia, R. Perdisci, K. Li, and M. Antonakakis.
Measuring and detecting malware downloads in live network trafﬁc. In
ESORICS, 2013.
[41] Z. Xu, A. Nappa, R. Baykov, G. Yang, J. Caballero, and G. Gu.
AUTOPROBE: towards automatic active malicious server probing using
dynamic binary analysis. In CCS, 2014.
J. Zhang, S. Saha, G. Gu, S. Lee, and M. Mellia. Systematic mining
of associated server herds for malware campaign discovery. In ICDCS,
2015.
[42]
[43] Y. Zhao, Y. Xie, F. Yu, Q. Ke, Y. Yu, Y. Chen, and E. Gillum. Botgraph:
Large scale spamming botnet detection. In NSDI, 2009.
[15] L. C. Freeman. A set of measures of centrality based on betweenness.
Sociometry, 1977.
[16] H. Gao, J. Hu, C. Wilson, Z. Li, Y. Chen, and B. Y. Zhao. Detecting
and characterizing social spam campaigns. In SIGCOMM, 2010.
[17] C. Grier, K. Thomas, V. Paxson, and C. M. Zhang. @spam: the
underground on 140 characters or less. In CCS, 2010.
J. Han, J. Pei, and Y. Yin. Mining frequent patterns without candidate
In ACM Sigmod Record, volume 29, pages 1–12. ACM,
generation.
2000.
[18]
[19] L. Invernizzi, S.-J. Lee, S. Miskovic, M. Mellia, R. Torres, C. Kruegel,
S. Saha, and G. Vigna. Nazca: Detecting malware distribution in large-
scale networks. In NDSS, 2014.
[20] M. Jiang, P. Cui, A. Beutel, C. Faloutsos, and S. Yang. Catching
synchronized behaviors in large networks: A graph mining approach.
TKDD, 2015.
[21] C. Kanich, C. Kreibich, K. Levchenko, B. Enright, G. M. Voelker,
V. Paxson, and S. Savage. Spamalytics: an empirical analysis of spam
marketing conversion. In CCS, 2008.
[22] P. Kotzias, L. Bilge, and J. Caballero. Measuring PUP prevalence and
PUP distribution through Pay-Per-Install services. In USENIX Security
Symposium, 2016.
[23] P. Kotzias, S. Matic, R. Rivera, and J. Caballero. Certiﬁed PUP: Abuse
in Authenticode code signing. In CCS, 2015.
=
[24] B.
for
signed-malware-is-expensive-oops-for-hp/, Oct 2014.
Signed malware
Krebs.
hp.
“oops”
http://krebsonsecurity.com/2014/10/
expensive
[25] M. K¨uhrer, C. Rossow, and T. Holz. Paint it black: Evaluating the
effectiveness of malware blacklists. In RAID, 2014.
[26] B. J. Kwon, J. Mondal, J. Jang, L. Bilge, and T. Dumitras,. The
dropper effect: Insights into malware distribution with downloader
graph analytics. In CCS, 2015.
[27] K. Levchenko, A. Pitsillidis, N. Chachra, B. Enright, M. F´elegyh´azi,
C. Grier, T. Halvorson, C. Kanich, C. Kreibich, H. Liu, D. McCoy,
N. Weaver, V. Paxson, G. M. Voelker, and S. Savage. Click trajectories:
End-to-end analysis of the spam value chain. In S&P, 2011.
[28] Z. Li, S. A. Alrwais, Y. Xie, F. Yu, and X. Wang. Finding the linchpins
of the dark web: a study on topologically dedicated hosts on malicious
web infrastructures. In S&P, 2013.
[30]
[29] P. K. Manadhata, S. Yadav, P. Rao, and W. Horne. Detecting malicious
domains via graph inference. In ESORICS, 2014.
J. Mondal and A. Deshpande. Eagr: Supporting continuous ego-centric
aggregate queries over large dynamic graphs. In SIGMOD, 2014.
J. Mondal and A. Deshpande. Stream querying and reasoning on social
data. In Encyclopedia of Social Network Analysis and Mining. 2014.
[32] A. Nappa, R. Johnson, L. Bilge, J. Caballero, and T. Dumitras,. The at-
tack of the clones: A study of the impact of shared code on vulnerability
patching. In S&P, 2015.
[31]
[33] T. Nelms, R. Perdisci, M. Antonakakis, and M. Ahamad. Webwitness:
Investigating, categorizing, and mitigating malware download paths. In
USENIX Security Symposium, 2015.
[34] A. Oprea, Z. Li, T.-F. Yen, S. H. Chin, and S. Alrwais. Detection of
early-stage enterprise infection by mining large-scale log data. In DSN,
2015.
[35] R. Peeters. The maximum edge biclique problem is np-complete.
Discrete Applied Mathematics, 131(3):651–654, 2003.
[36] B. Rahbarinia, R. Perdisci, and M. Antonakakis. Segugio: Efﬁcient
behavior-based tracking of malware-control domains in large ISP net-
works. In DSN, 2015.
[37] A. Tamersoy, K. Roundy, and D. H. Chau. Guilt by association: large
In SIGKDD,
scale malware detection by mining ﬁle-relation graphs.
2014.
[38] K. Thomas, J. A. E. Crespo, R. Rasti, J.-M. Picod, C. Phillips, M.-A.
Decoste, C. Sharp, F. Tirelo, A. Toﬁgh, M.-A. Courteau, L. Ballard,
R. Shield, N. Jagpal, M. A. Rajab, P. Mavrommatis, N. Provos,
E. Bursztein, and D. McCoy. Investigating commercial pay-per-install
In USENIX Security
and the distribution of unwanted software.
Symposium, 2016.
15