### 5.3 MAC OS X Seatbelt

On Mac OS X, Chromium employs a Mandatory Access Control (MAC) framework to create sandboxes. This allows Chromium to establish a more robust sandbox than is possible with Discretionary Access Control (DAC). However, the rights granted to render processes are still quite broad, and the security policy must be defined separately from the code that relies on it.

The Mac OS X Seatbelt sandbox system constrains processes according to a LISP-based policy language [1]. It uses the MAC Framework [27] to check application activities. Chromium implements three policies for different components, allowing access to filesystem elements such as font directories while restricting access to the global namespace.

Like other techniques, resources are acquired before constraints are imposed, so care must be taken to avoid leaking resources into the sandbox. Fine-grained filesystem constraints are possible, but other namespaces, such as POSIX shared memory, are an all-or-nothing affair. The Seatbelt-based sandbox model is less verbose than other approaches, but like all MAC systems, the security policy must be expressed separately from the code. This can lead to inconsistencies and vulnerabilities.

### 5.4 SELinux

Chromium's MAC approach on Linux utilizes an SELinux Type Enforcement policy [12]. SELinux can be used for very fine-grained rights assignment, but in practice, broad rights are often conferred because writing and maintaining fine-grained Type Enforcement policies is challenging.

The requirement that an administrator be involved in defining new policies and applying new types to the filesystem is a significant inflexibility: application policies cannot adapt dynamically, as system privilege is required to reformulate policy and relabel objects.

The Fedora reference policy for Chromium creates a single SELinux dynamic domain, `chrome_sandbox_t`, which is shared by all sandboxes, risking potential interference between them. This domain is assigned broad rights, such as the ability to read all files in `/etc` and access to the terminal device. These broad policies are easier to craft than fine-grained ones, reducing the impact of the dual-coding problem, but they are much less effective, allowing leakage between sandboxes and broad access to resources outside the sandbox.

In contrast, Capsicum eliminates dual-coding by combining security policy with the application code. This approach has both benefits and drawbacks: while bugs due to inconsistency between policy and code are eliminated, there is no longer an easily accessible specification of the policy to which static analysis can be applied. This reinforces our belief that systems such as Type Enforcement and Capsicum are potentially complementary, serving different niches in system security.

### 5.5 Linux seccomp

Linux provides an optionally-compiled capability mode-like facility called seccomp. Processes in seccomp mode are denied access to all system calls except `read`, `write`, and `exit`. While this seems promising, the minimal OS infrastructure to support applications using seccomp means that application writers must go to significant effort to use it.

To allow other system calls, Chromium constructs a process where one thread executes in seccomp mode, and another "trusted" thread sharing the same address space has normal system call access. Chromium rewrites glibc and other library system call vectors to forward system calls to the trusted thread, where they are filtered to prevent access to inappropriate shared memory objects, opening files for write, etc. However, this default policy is quite weak, as reading any filesystem object is permitted.

The Chromium seccomp sandbox contains over a thousand lines of hand-crafted assembly to set up sandboxing, implement system call forwarding, and craft a basic security policy. Such code is risky: difficult to write and maintain, with any bugs likely leading to security vulnerabilities. The Capsicum approach is similar to seccomp, but by offering a richer set of services to sandboxes and more granular delegation via capabilities, it is easier to use correctly.

### 6 Performance Evaluation

Typical operating system security benchmarking aims to illustrate zero or near-zero overhead to demonstrate the general applicability of the technology. Our focus is slightly different: we know that application authors who have already adopted compartmentalization are willing to accept significant overheads for improved security. Our goal is to achieve comparable performance with significantly better security.

We evaluate performance in two ways: first, a set of micro-benchmarks to measure the overhead introduced by Capsicum’s capability mode and capability primitives. Since we could not detect any noticeable performance change in our adapted UNIX applications (tcpdump and dhclient) due to the extremely low cost of entering capability mode from an existing process, we then turn our attention to the performance of our libcapsicum-enhanced gzip.

All performance measurements were conducted on an 8-core Intel Xeon E5320 system running at 1.86GHz with 4GB of RAM, running either an unmodified FreeBSD 8-STABLE distribution synchronized to revision 201781 (2010-01-08) from the FreeBSD Subversion repository, or a synchronized 8-STABLE distribution with our capability enhancements.

### 6.1 System Call Performance

First, we consider system call performance through micro-benchmarking. Figure 13 summarizes these results for various system calls on unmodified FreeBSD and related capability operations in Capsicum. Figure 14 contains a table of benchmark timings. All micro-benchmarks were run by performing the target operation in a tight loop over an interval of at least 10 seconds, repeating for 10 iterations. Differences were computed using Student’s t-test at 95% confidence.

Our primary concern is the performance of capability creation compared to raw object creation and the closest UNIX operation, `dup`. We observe moderate, but expected, performance overheads for capability wrapping of existing file descriptors: the `cap_new` syscall is 50.7% ± 0.08% slower than `dup`, or 539 ± 0.8ns slower in absolute terms.

Next, we consider the overhead of capability "unwrapping," which occurs on every descriptor operation. We compare the cost of some simple operations on raw file descriptors to the same operations on a capability-wrapped version of the same file descriptor: writing a single byte to `/dev/null`, reading a single byte from `/dev/zero`, reading 10000 bytes from `/dev/zero`, and performing an `fstat` call on a shared memory file descriptor.

In all cases, we observe a small overhead of about 0.06µs when operating on the capability-wrapped file descriptor. This has the largest relative performance impact on `fstat` (since it does not perform I/O, simply inspecting descriptor state, it should thus experience the highest overhead of any system call requiring unwrapping). Even in this case, the overhead is relatively low: 10.2% ± 0.5%.

Additional dynamically linked library dependencies (libcapsicum and its dependency on libsbuf) impose an additional 9% cost to the `fork` syscall, presumably due to the additional virtual memory mappings being copied to the child process. This overhead is not present on `vfork`, which we plan to use in libcapsicum in the future. Creating, exchanging an RPC with, and destroying a single sandbox (the "sandbox" label in Figure 13(b)) has a cost of about 1.5ms, significantly higher than its subset components.

### 6.2 Sandbox Creation

Capsicum supports two ways to create a sandbox: directly invoking `cap_enter` to convert an existing process into a sandbox, inheriting all current capability lists and memory contents, and the libcapsicum sandbox API, which creates a new process with a flushed capability list.

`cap_enter` performs similarly to `chroot`, used by many existing compartmentalized applications to restrict filesystem access. However, `cap_enter` outperforms `setuid` as it does not need to modify resource limits. As most sandboxes `chroot` and set the UID, entering a capability mode sandbox is roughly twice as fast as a traditional UNIX sandbox. This suggests that the overhead of adding capability mode support to an application with existing compartmentalization will be negligible, and replacing existing sandboxing with `cap_enter` may even marginally improve performance.

Creating a new sandbox process and replacing its address space using `execve` is an expensive operation. Micro-benchmarks indicate that the cost of `fork` is three orders of magnitude greater than manipulating the process credential, and adding `execve` or even a single instance of message passing increases that cost further.

### 6.3 Gzip Performance

To measure the cost of process sandbox creation, we timed gzip compressing files of various sizes. Since the additional overheads of sandbox creation are purely at startup, we expect to see a constant-time overhead to the capability-enhanced version of gzip, with identical linear scaling of compression performance with input file size. Files were pre-generated on a memory disk by reading a constant-entropy data source: `/dev/zero` for perfectly compressible data, `/dev/random` for perfectly incompressible data, and base 64-encoded `/dev/random` for a moderate high entropy data source, with about 24% compression after gzipping. Using a data source with approximately constant entropy per bit minimizes variation in overall gzip performance due to changes in compressor performance as files of different sizes are sampled.

The list of files was piped to `xargs -n 1 gzip -c > /dev/null`, which sequentially invokes a new gzip compression process with a single file argument and discards the compressed output. Sufficiently many input files were generated to provide at least 10 seconds of repeated gzip invocations, and the overall run-time was measured. I/O overhead was minimized by staging files on a memory disk. The use of `xargs` to repeatedly invoke gzip provides a tight loop that minimizes the time between `xargs`' successive `vfork` and `exec` calls of gzip. Each measurement was repeated 5 times and averaged.

Benchmarking gzip shows high initial overhead when compressing single-byte files, but also that the approach in which file descriptors are wrapped in capabilities and delegated rather than using pure message passing leads to asymptotically identical behavior as file sizes increase.