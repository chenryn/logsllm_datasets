### Figure 11: Legitimate and Attack Signals in a Scenario with Four Bits and 10 Bits per Symbol and Repetition Coding

The first plot in Figure 11 shows the shape of the transmitted signal. Despite the attacker correctly guessing only 2 out of 10 pulses per symbol, the attack signal is dominant because each bit contains sufficient power. The second plot displays the noisy signals received at the receiver. The third plot illustrates the received signal after removing the data modulation. The rightmost plot shows the residual signal after the expected signal component has been removed. It is evident that the attack residual can be easily distinguished from the legitimate residual, even though the attack on repetition coding (i.e., at the bit level) was successful.

### 6.3. Variance-Based MTAC: Summary

To summarize and illustrate how to integrate the Variance-Based MTAC into a distance-measurement system, we outline the steps involved in detecting an advancement attack by a receiver (Rx) on a signal originating from a transmitter (Tx).

#### (a) Pre-configuration
1. **Determine Maximum Distortion Threshold**: Rx determines the maximum accepted distortion threshold \(\hat{T}_D\) based on the maximum communication distance and the maximum tolerated noise level, within a specified performance region \(P\).

#### (b) Key Generation (Gen)
1. **Derive XOR Sequence**: Tx and Rx generate a fresh pseudorandom XOR sequence \(x\) from a shared secret. This sequence could also be secretly shared before each round.

#### (c) MTAC Generation (Mtac)
1. **Encode Message**: Tx encodes the message \(m\) using repetition coding according to a chosen configuration \(p \in P\) and applies the XOR sequence.

#### (d) MTAC Verification (Vrfy)
1. **Construct Received Message**: Rx constructs the message \(m'\) by multiplying the received pulse sequence \(c'\) with the expected XOR sequence and applying a bit-wise binary hypothesis test on the overall symbol energy.
2. **Generate Expected Pulse Sequence**: Based on the received message \(m'\) and the XOR sequence, Rx constructs the expected pulse-level sequence \(\hat{c}\) (i.e., the template).
3. **Compute Signal Distortion**: Rx computes the signal distortion \(D(c', \hat{c})\) between the received and expected pulse sequences.
4. **Check for Attack**: If the computed distortion \(D\) exceeds the threshold \(\hat{T}_D\), Rx declares an attack.

### 6.4. Practical Concerns

#### Time Reference: Distance Commitment
We assume the detection of an advancement attack to be limited to verification relative to some established time frame. This can be achieved through a distance commitment, as introduced in [16]. The prover is assumed to have already responded quickly to the query by transmitting a deterministic preamble, committing to a specific temporal reference. Relative to this reference, the prover must deliver the secret information (i.e., \(m\), correctly modulated) at a pre-agreed time relative to the preamble. Given that a UWB frame used for distance measurement typically lasts less than 1ms, it is realistic to assume the channel remains coherent throughout the frame. A distance commitment helps avoid vulnerabilities associated with back-search attacks on the data-bearing part.

#### Ranging Precision
Under a distance commitment, the back-search for the acquisition of the first signal path is only necessary on the preamble of the frame. Therefore, the precision of the ranging procedure is not determined by any operation applied to the data-bearing part. Consequently, the precision of our proposal cannot be worse than that of existing schemes relying on a distance commitment. Studies have shown that such a system can achieve a precision of 10cm, regardless of the communication distance [19], [24].

#### Bit-Level Security
We assume a bit-level procedure to detect if the received bits \(m'\) do not match the transmitted message \(m\). This can be achieved by appending a message authentication code (MAC) to the frame or transmitting it on a separate, potentially ToA-agnostic channel.

### 7. Analysis

In the following section, we explore the tradeoff between security and performance by modeling the effect of the channel and evaluating the classification performance of our Variance-Based MTAC. The results are based on simulations, which make assumptions consistent with realistic UWB-based distance measurement systems. From these results, we can derive the performance region in which our proposal maintains bit-equivalent security (i.e., \(\text{Adv}(\hat{A}) < 2^{-n_b}\)) and how to scale to longer distances.

### Figures 12 and 13: Performance and Security Analysis

**Figure 12** shows the number of pulses per symbol required as a function of the target performance level (i.e., the target bit error rate (BER) and operating distance) under FCC/ETSI constraints. These numbers refer to both line-of-sight (LoS) and non-line-of-sight (NLoS) scenarios with 20dB attenuation of the direct path. Lower BERs over longer distances require more pulses per symbol.

**Figure 13** illustrates that over longer distances, the legitimate distortion increases. The gap between the maximum legitimate distortion and the minimum attack distortion becomes smaller, eventually vanishing altogether. This means that, under our strong attacker model, MTAC security can only be maintained up to a certain distance.

### 7.1. Model

#### Path Loss Model
To evaluate the impact of distance on the required modulation and its implications on security, we assume a free-space path loss model. The received power degrades inversely to the square of the distance, as in:
\[ P_{rx} = P_{tx} \left( \frac{\lambda}{4\pi d} \right)^2 \Gamma_{nlos} \]
We assume the antennas operate in each other’s far field. The input power adheres to the constraints set by the FCC and ETSI regarding UWB in licensed spectrum, with a maximum peak power of 0dBm within the 50MHz around the peak and an average limitation on signal power spectral density of -41.3dBm/Hz. We assume that our pulses are sufficiently spaced, allowing each pulse to be sent at peak power. The signal bandwidth is 620MHz at a center frequency of 6681.6MHz, typical for UWB channels [37]. For receiver-side noise, we consider the thermal noise figure at room temperature, given by -174dBm/Hz. In a separate NLoS scenario, we assume an additional 20dB attenuation, roughly equivalent to the attenuation experienced when traversing the human body.

#### Gaussian Model for Variance Distributions
The variance is a sum of \(n_p\) independent random variables. Due to the central limit theorem, for a sufficiently high overall number of pulses, the variance distribution converges to a Gaussian:
\[ D_{\hat{A}}(d) \sim \mathcal{N}(\mu_{D_{\hat{A}}}(d), \sigma_{D_{\hat{A}}}(d)) \]
\[ D_{lgt}(d) \sim \mathcal{N}(\mu_{D_{lgt}}(d), \sigma_{D_{lgt}}(d)) \]
These distributions are functions of the communication range and the target BER. Simulations confirm that in the area of interest, these distributions fit a Gaussian hypothesis well, as detailed in Appendix C.

### 7.2. Results

We model the bit error rate of the underlying modulation according to Equation 1. We simulate this in MATLAB for a frame of 32 bits. As detailed in Appendix D, the security guarantees are maintained for longer frames. For robustness, the choice of the decision threshold should result in the same false negative rate of Vrfy as under bit-wise detection, i.e., \(\text{FNR}_{\text{Vrfy}} = 1 - (1 - \text{BER})^{n_b}\). Under the Gaussian hypothesis for the distortion distribution, we can derive the practical decision threshold by choosing it \(Q^{-1}(\text{FNR}_{\text{Vrfy}})\) normalized standard deviations above the expected legitimate distortion. The resulting threshold is indicated in Figure 13.

We evaluate the probability of attacker success for a given maximum communication distance based on the attacker’s best-case statistics and the legitimate worst-case statistics, over a range of target BER values. This aligns with our attacker model, which makes no assumptions about the attacker’s position. For a given performance region, the upper bound of the attacker’s advantage is given by:
\[ \text{Adv}(\hat{A}) = Q \left( \frac{\hat{\mu}_{D_{\hat{A}}} - (\hat{\mu}_{D_{lgt}} + Q^{-1}(\text{FNR}_{\text{Vrfy}}) \cdot \hat{\sigma}_{D_{lgt}})}{\hat{\sigma}_{D_{\hat{A}}}} \right) \]
where the statistical parameters (means and variances) are chosen in favor of the forger \(\hat{A}\). Specifically, we choose the attacker’s parameters to minimize the worst-case distortion and the legitimate transmitter’s parameters to maximize the distortion within the defined performance region. The details of these choices are provided in Appendix B. Unsurprisingly, the worst-case distance for the legitimate transmitter is typically the maximum distance. The numerical values of these statistical parameters were obtained through simulation, modeling the attacker with an ideal pulse-level bias of 20%, as motivated in Section 4. We are interested in the performance region where the MTAC provides bit-equivalent security, i.e., \(\text{Adv}(\hat{A}) \leq 2^{-n_b}\).

### Figure 14: Attacker’s Advantage as a Function of the Performance Level

**Figure 14** shows the attacker’s advantage as a function of the performance level, highlighting the performance region in which the MTAC provides bit-equivalent security. The secure distortion test provides us with a bit-equivalently secure MTAC for distances up to 200m and 20m for LoS and NLoS scenarios, respectively.

### Observation 5
Under any tradeoff between symbol length and target bit error rate: For any frame \(m\) of at least 32 bits, we can find a distortion threshold \(\hat{T}_D\) resulting in an MTAC with bit-equivalent security for distances up to 200m under LoS conditions and up to 20m under NLoS conditions.

### Extending the MTAC Region
By comparing the results for LoS and NLoS conditions, we see that the MTAC region degrades proportionally to the added attenuation, i.e., the results are invariant under amplification/attenuation. This means we can extrapolate to any communication range if we allocate a security link margin \(\Gamma_{sec} \geq 0\) satisfying:
\[ \Gamma_{sec} \geq 20 \cdot \log_{10} \left( \frac{d_{max}}{200m} \right) + \Gamma_{nlos} \]

### 8. Conclusion

With MTAC, we propose a physical-layer primitive for secure distance measurement. We formally define the security of its underlying algorithms and derive design principles for the practical instantiation of an MTAC: a randomized pulse sequence and a secure distortion test over the entire signal. The results indicate that the bit-equivalent security level can be regained over a meaningful performance region, thereby providing a fundamental building block to prevent physical-layer, distance-reducing attacks.

### 9. Acknowledgements

This project has received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme under grant agreement No 726227.

### References

[1] K. Markantonakis, L. Francis, G. Hancke, and K. Mayes, “Practical relay attack on contactless transactions by using NFC mobile phones,” Radio Frequency Identification System Security: RFIDsec, vol. 12, p. 21, 2012.

[2] A. Francillon, B. Danev, and S. Capkun, “Relay attacks on passive keyless entry and start systems in modern cars,” in Proceedings of the Network and Distributed System Security Symposium, NDSS 2011, San Diego, California, USA, 6th February - 9th February 2011, 2011.

[3] A. Ranganathan, B. Danev, A. Francillon, and S. Capkun, “Physical-layer attacks on chirp-based ranging systems,” in Proceedings of the fifth ACM conference on Security and Privacy in Wireless and Mobile Networks. ACM, 2012, pp. 15–26.

[4] “Mercedes ‘relay’ box thieves caught on CCTV in Solihull.” http://www.bbc.com/news/uk-england-birmingham-42132689, [Online; Accessed November 10th 2018].

[5] “Radio attack lets hackers steal cars with just $20 worth of gear.” https://www.wired.com/2017/04/just-pair-11-radio-gadgets-can-steal-car/, [Online; Accessed November 10th 2018].

[6] T. E. Humphreys, B. M. Ledvina, M. L. Psiaki, B. W. O’Hanlon, and P. M. Kintner, “Assessing the spoofing threat: Development of a portable GPS civilian spoofer,” in Radionavigation Laboratory Conference Proceedings, 2008.

[7] P. Papadimitratos and A. Jovanovic, “GNSS-based positioning: Attacks and countermeasures,” in Military Communications Conference, 2008. MILCOM 2008. IEEE, 2008, pp. 1–7.

[8] N. O. Tippenhauer, C. Pöpper, K. B. Rasmussen, and S. Capkun, “On the requirements for successful GPS spoofing attacks,” in Proceedings of the 18th ACM conference on Computer and communications security. ACM, 2011, pp. 75–86.

[9] S. Capkun, M. Cagalj, G. Karame, and N. O. Tippenhauer, “Integrity regions: Authentication through presence in wireless networks,” IEEE Transactions on Mobile Computing, vol. 9, no. 11, pp. 1608–1621, 2010.

[10] K. B. Rasmussen, S. Capkun, and M. Cagalj, “Secnav: Secure broadcast localization and time synchronization in wireless networks,” in Proceedings of the 13th annual ACM international conference on Mobile computing and networking. ACM, 2007, pp. 310–313.

[11] S. Brands and D. Chaum, “Distance-bounding protocols,” in Workshop on the Theory and Application of Cryptographic Techniques. Springer, 1993, pp. 344–359.

[12] C. H. Kim, G. Avoine, F. Koeune, F.-X. Standaert, and O. Pereira, “The Swiss-knife RFID distance bounding protocol,” in International Conference on Information Security and Cryptology. Springer, 2008, pp. 98–115.

[13] A. Brelurut, D. Gerault, and P. Lafourcade, “Survey of distance bounding protocols and threats,” in International Symposium on Foundations and Practice of Security. Springer, 2015, pp. 29–49.

[14] G. P. Hancke and M. G. Kuhn, “An RFID distance bounding protocol,” in Proceedings of the First International Conference on Security and Privacy for Emerging Areas in Communications Networks, ser. SECURECOMM ’05. Washington, DC, USA: IEEE Computer Society, 2005, pp. 67–73. [Online]. Available: http://dx.doi.org/10.1109/SECURECOMM.2005.56

[15] K. B. Rasmussen and S. Capkun, “Realization of RF distance bounding.” in USENIX Security Symposium, 2010, pp. 389–402.

[16] N. O. Tippenhauer, H. Luecken, M. Kuhn, and S. Capkun, “UWB rapid-bit-exchange system for distance bounding,” in Proceedings of the 8th ACM Conference on Security & Privacy in Wireless and Mobile Networks. ACM, 2015, p. 2.

[17] A. Ranganathan, B. Danev, and S. Capkun, “Proximity verification for contactless access control and authentication systems,” in Proceedings of the 31st Annual Computer Security Applications Conference. ACM, 2015, pp. 271–280.

[18] “3db Access AG - 3db6830 proximity-based access control,” [Online; Accessed https://www.3db-access.com/Product.3.html, November 8th 2018].

[19] “DecaWave DW1000 product description and applications,” [Online; Accessed https://www.decawave.com/products/dw1000, November 8th 2018].

[20] “Zebra Technologies Sapphire Dart Ultra Wideband (UWB) Real Time Locating System 2010,” [Online; Accessed https://www.zebra.com/us/en/solutions/location-solutions/enabling-technologies/dart-uwb.html, November 8th 2018].

[21] J. Clulow, G. P. Hancke, M. G. Kuhn, and T. Moore, “So near and yet so far: Distance-bounding attacks in wireless networks,” in European Workshop on Security in Ad-hoc and Sensor Networks. Springer, 2006, pp. 83–97.

[22] M. Flury, M. Poturalski, P. Papadimitratos, J.-P. Hubaux, and J.-Y. Le Boudec, “Effectiveness of distance-decreasing attacks against impulse radio ranging,” in Proceedings of the third ACM conference on Wireless network security. ACM, 2010, pp. 117–128.

[23] M. Poturalski, M. Flury, P. Papadimitratos, J.-P. Hubaux, and J.-Y. Le Boudec, “Distance bounding with IEEE 802.15.4a: Attacks and countermeasures,” IEEE Transactions on Wireless Communications, vol. 10, no. 4, pp. 1334–1344, 2011.

[24] M. Singh, P. Leu, and S. Capkun, “UWB with pulse reordering: Securing ranging against relay and physical-layer attacks,” in 26th