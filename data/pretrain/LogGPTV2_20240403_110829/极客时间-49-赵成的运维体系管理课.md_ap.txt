# 22 \| 持续交付流水线软件构建难吗？有哪些关键问题？上期文章我们介绍了需求分解与应用对应的管理方式，以及提交环节的开发协作模式，今天我们详细介绍一下提交阶段的构建环节，也就是我们经常提到的代码的编译打包。
## 构建环节 {#19.html#-}由于静态语言从过程上要比动态语言复杂一些，代码提交后，对于 Java 和 C++这样的静态语言，我们要进行代码编译和打包。而对于 PHP 和 Python这样的动态语言，就不需要编译，直接打包即可。同时，编译过程就开始要依赖多环境以及多环境下的配置管理，并根据不同的环境获取不同的配置，然后打包到最终的软件发布包中。下面我就结合自己的实践经验，以 Java 为例，对构建环节做下介绍。构建过程中我们要用到以下**4 种工具**：-   **Gitlab**，代码管理工具，也是版本管理工具；-   **Maven**，依赖管理和自动化构建工具，业界同类型的工具还有 Gradle    等；-   **Docker**，用来提供一个干净独立的编译环境；-   **自动化脚本和平台**，自动化构建的任务我们使用 Python    脚本来实现代码获取、编译执行、软件包生成等。具体整个构建过程图示如下：![](Images/c4c17cf6d07dd6e21a597561114f0a60.png){savepage-src="https://static001.geekbang.org/resource/image/2e/87/2ecde6e88787e007f41fb01a85718687.png"}我们以 Java 为例描述如下。1\. 首先准备好 JDK 的编译镜像，这个镜像环境与线上运行环境保持一致，比如OS 版本、内核参数以及 JDK版本等基础环境。当需要启动一个构建任务时，就创建一个对应的 Docker实例，作为独立的编译环境。2\. 构建任务会根据应用配置管理中的 Git地址，将代码克隆下来放到指定的编译目录。Docker实例启动后，将编译目录挂载到 Docker 实例中。3\. 执行 mvn package 命令进行编译打包，最终会生成一个可发布 war的软件包。同样的，对于C++、Go、Node.js，也会准备好类似的编译镜像。不同的是，打包时，对于 C++中的 cmake 和 make，Go 中的 go install等等，最终也会生成一个可发布的软件包。4\. 构建完成后，生成软件包放到指定构件库目录，或者直接发布到 maven的构件库中管理，然后将 Docker 实例销毁。上述就是一个完整的构建过程。在这里，你一定会有一些疑问，那么，我先回答几个比较常见的问题，欢迎你留言和我继续讨论。``{=html}
## 几个关键问题 {#19.html#-}**1. 配置文件如何打包？**这个问题，我们在前面持续交付的多环境配置管理文章中，已经详细介绍过。这里我们结合构建过程，再介绍一下。在上述第 3个步骤中，我们要进行代码编译。按照持续交付理念，软件只需打包一次就可以各处运行，这对于代码编译是没有问题的，但是对于一些跟环境相关的配置就无法满足。比如，我们前面讲到，不同的环境会涉及到不同的配置，如DB、缓存。而且，其他公共基础服务在不同环境中也会有不同的地址、域名或其他参数配置。所以，我们就需要建立环境与配置之间的对应关系，并保存在配置管理平台中，至于如何来做，大家可以参考前面多环境配置管理的文章。这里我们回到打包过程上来。在做构建时，我们是可以确认这个软件包是要发布到哪个环境的。比如，按照流程，当前处于线下集成测试环境这个流程环节上，这时只要根据集成测试环境对应的配置项，生成配置文件，然后构建进软件包即可。如果是处于预发环境，那就生成预发环境对应的配置文件。在我们的实际场景中，多个环境需要多次打包，这与我们持续交付中只构建一次的理念相悖。这并不是有意违背，而是对于Java 构建出的交付件，最终无论生成的是 war 包，还是 jar包，上述提到的跟环境相关的配置文件，是要在构建时就打入软件包中的。而且在后续启动和运行阶段，我们是无法修改已经构建进软件包里的文件及其内容的。这样一来，配置文件无法独立发布，那么就必须跟软件包一起发布。所以，在实际场景下，我们要针对不同环境多次打包。那么，我们如何确保多次打包的效果能够和"只构建一次"理念的效果相一致呢？这就还是要依赖我们前面介绍的各个环节的建设过程，主要有以下 3 个方面：-   代码提交。通过分支提交管理模式，每次构建都以 master    为基线，确保合入的代码是以线上运行代码为基础的。且前面的发布分支代码未上线之前，后续分支不允许进入线上发布环节，确保发布分支在多环境下是同一套代码。-   编译环境统一。上述过程已经介绍，编译环境通过全新的 Docker    容器环境来保证。-   配置管理。前面介绍到的多环境配置管理手段， 通过模板和 auto-config    的配置管理能力，确保多环境配置项和配置值统一管理。至此，一个完整的软件构建过程就完成了。可以看到，如果充分完善前期的准备工作，在做后期的方案时就会顺畅很多。**2. 为什么用 Docker 做编译环境的工具？**Docker容器很大的一个优势在于其创建和销毁的效率非常高，而且每次新拉起的实例都是全新的，消除了环境共用带来的交叉影响。而且对于并发打包的情况，Docker可以快速创建出多个并行的实例来提供编译环境，所以无论在效率上还是环境隔离上，都有非常好的支持。你可以尝试一下我的这个建议，确实会非常方便。**3. 为什么不直接生成 Docker 镜像做发布？**在使用 Docker 容器做编译的过程中，我们最终取得的交付件模式是一个 war包，或者是一个 jar 包，这个也是我们后续发布的对象。可能有读者会问：为什么不直接生成 Docker 镜像，后续直接发布镜像？这确实是一个好问题。如果单纯从发布的维度来看，直接发布镜像会更方便，更高效。不过，在现实场景下，我们应该更全面地看问题。早期我们曾有一段时间使用 OpenStack+Docker的模式进行物理机的虚拟化，以提升资源利用率。这实际上是将容器虚拟机化。也就是说，虽然 Docker是一个容器，但是我们的使用方式仍然是虚拟机模式，要给它配置 IP地址，要增加很多常用命令比如 top、sar 等等，定位问题需要 ssh 到容器内。这里一方面是因为基于 Docker 的运维工具和手段没有跟上，当时也缺少Kubernetes 这样优秀的编排工具；另一方面，我们之前所有的运维体系都是基于IP模式建设的，比如监控、发布、稳定性以及服务发现等等，完全容器化的模式是没有办法一步到位的。所以，这里我们走了个小弯路：容器虚拟机化。那为什么我们不直接使用虚拟机，还能帮我们省去很多为了完善容器功能而做的开发工作？所以一段时间之后，我们还是回归到了KVM 虚拟机使用方式上来。这样也就有了上述我们基于虚拟机，或者更准确地说，是基于 IP管理模式下的持续交付体系。经过这样一个完整的持续交付体系过程后，我们总结出一个规律：容器也好，虚拟机也罢，这些都是工具，只不过最终交付模式不一样。但是前面我们所讲的不管是标准化、多环境、配置管理等等这些基础工作，无论用不用容器都要去做。而且，容器的高效使用，一定是建立在更加完善和高度标准化的体系之上，否则工具只会是越用越乱。关于持续交付流水线软件构建方面的内容，我们今天先分享到这里，欢迎你留言与我讨论。如果今天的内容对你有帮助，也欢迎你分享给身边的朋友，我们下期见！![](Images/3ef6e72a283656e2668a23a796e1acca.png){savepage-src="https://static001.geekbang.org/resource/image/60/0e/60151e9d25d6751800506e2460f5660e.jpg"}
# 23 \| 持续交付中流水线构建完成后就大功告成了吗？别忘了质量保障上期文章我结合自己的实践经验，介绍了持续交付中流水线模式的软件构建，以及在构建过程中的3个关键问题。我们可以看出，流水线的软件构建过程相对精简、独立，只做编译和打包两个动作。但需要明确的是，在持续交付过程中，我们还要做很多与质量保障相关的工作，比如我们前面提到的各类功能测试和非功能测试。所以，今天我们聊一聊在流水线构建过程中或构建完成之后，在质量保障和稳定性保障方面，我们还需要做哪些事情。首先，我们回顾一下之前总结的这张流程图：![](Images/bd5d923b3e8ed5c44718d021830e71d3.png){savepage-src="https://static001.geekbang.org/resource/image/ea/da/ea926382484f49fb6a9250a07fc4a5da.jpeg"}可以看出，在流水线构建过程中，我们尤其要重视以下 3 个方面的工作内容。
## 依赖规则限制 {#20.html#-}主要是对代码依赖的二方包和三方包做一些规则限制。比如，严格限定不允许依赖snapshot 版本；不允许引入有严重漏洞的版本，如 struts2 的部分版本；检测jar 包冲突，如我们常用的 netty、spring相关的包；限定某些软件包的最低版本发布，如内部提供的二方包，以确保版本收敛，降低维护成本。过滤规则上，通过 maven 构建软件包过程中生成的 dependency:list 文件，将GroupID 和 ArtifactID 作为关键字，与我们设定的版本限制规则进行匹配。两个示例如下（真实版本信息做了修改）：检测 jar 包冲突：> \[WARNING\] 检测到 jar 包冲突: io.netty:netty-all, 版本: 4.0.88.Final,> 当前使用: 4.0.22.Final限定最低版本：> \[WARNING\] 检测到 mysql:mysql-connector-java, 版本 5.0.22,> 版本不符合要求, 需要大于等于 5.0.88。旧版存在已知兼容性> bug，导致连不上数据库, 请在 2018-01-15 00:00:00 前升级完成,> 否则将被禁止发布，如有疑问，请联系 \@发布助手jar包依赖以及维护升级，通常是一件令我们比较头疼的事情，特别是在运行时出现的冲突异常，更是灾难性的。为了从技术角度更好地进行管理，我们需要做好隔离，这一点可以利用JVM 类加载机制来实现。如果你有兴趣，可以在网上参考阿里的潘多拉（Pandora）容器设计资料，这里我们就不作详细介绍了。``{=html}
## 功能测试 {#20.html#-}包括单元测试、接口测试、联调测试和集成测试。这里的每个测试环节起到的作用不同，联调测试和集成测试依赖的主要手段还是手工验证，所以这里我们分享下可以通过自动化手段完成的单元测试和接口测试。这里主要用到的几个工具：-   JUnit 和 TestNG，分别做单元测试和接口测试；-   Maven 插件，maven-surefire-plugin，用来执行 JUnit 或 TestNG 用例；-   JaCoCo，分析单元测试和接口测试后的代码覆盖率；-   Jenkins，自动化测试任务执行，报表生成和输出，与 Maven、JUnit、Gitlab    这些工具结合非常好。关于上述这几种工具，我在此就不展开详细介绍了，你可以自行上网查询和学习。下面，我们分析一下功能测试中的两个重要环节：单元测试和接口测试。-   **单元测试**，由开发完成测试用例的开发，对于需要连接 DB    的用例，可以用 DBUnit    这样的框架。用例的自动执行，每次代码开发完成，开发执行 mvn test    在本地进行自测通过，然后提交到 Gitlab。可以在 Gitlab 中设置 hook    钩子，和回调地址，提交的时候在 commitMsg 增加钩子标识，如    unitTest，这样提交后就触发回调自动化单元测试用例执行接口，确保提交后的代码是单元测试通过的，最终可以通过    JaCoCo 工具输出成功率和代码覆盖率情况。-   **接口测试**，用例编写上使用 TestNG，这个测试框架相比 JUnit    功能更全面，也更灵活一些。但是过程上与单元测试类似，当然也可以不通过    hook 方式出发，可以通过手工触发进行测试。上述自动化测试环节结束，软件包就可以发布到我们之前说的项目测试环境或集成测试环境进行功能联调和测试了，这时就需要部分人工的介入。