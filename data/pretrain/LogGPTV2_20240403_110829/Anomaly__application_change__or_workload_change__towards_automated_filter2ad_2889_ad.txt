•
L4---'4-J4--JL+i~L.}--J4-J
1288 1.... "..
e.. 1".
,."
__'__
_I__....L__"""___...L.__.L_____'
Browsing Anomaly Shopping Ordering Non--Stat. Tr+5ms Tr+1Oms
Figure 9. 30-hour TPC-W Workload used in the Case Study.
1. The browsing mix with the number of EBs equal to 200,
400, 600, 800, and 1000 respectively.
2. In order to validate whether our algorithm correctly de(cid:173)
tects performance anomalies, we generated a special
workload with non-stationary transaction mix as de(cid:173)
scribed above and an additional CPU process (that con(cid:173)
sumes random amount of CPU) on a background.
3. The shopping mix with the number ofEBs equal to 200,
400, 600, 800, and 1000 respectively.
4. The ordering mix with the number of EBs equal to 200,
400, 600, 800, and 1000 respectively.
5. The non-stationary TPC- W transaction mix described
above in this section.
6. In order to validate whether we can automatically recog-
nize the application change, we modified the source code
ofthe "Home" transaction (the 8th transaction) in TPC-W
1-4244-2398-9/08/$20.00 ©2008 IEEE
459
DSN 2008: Cherkasova et al.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:22:14 UTC from IEEE Xplore.  Restrictions apply. 
International Conference on Dependable Systems &Networks: Anchorage, Alaska, June 24-27 2008
by inserting a controlled CPU loop into the code of this
transaction and increasing its service time by 5 ms. Us(cid:173)
ing this modified code, we performed experiment with the
non-stationary TPC-W transaction mix described above.
7. Another experiment with the modified TPC- W bench-
mark, where the service time ofthe "Home" transaction is
increased by 10 ms and the non-stationary TPC-W trans(cid:173)
action mix described above.
6.2 Approach Validation
We applied our on-line regression-based algorithm to the
special 30-hour workload shown in Figure 9. We experi(cid:173)
mented with two values of allowable error in our experiments:
E~llow = 3% and E~llow = 1% to demonstrate the impact of
error setting and stress the importance of tuning this value.
When we used E~llow = 3%, the algorithm had correctly
identified the 4 major model changes as shown in Figure 10. In
fact, for the second segment there were 42 model changes (not
shown in this figure to simplify the presentation) with maxi(cid:173)
mum segment being 5 epochs.
.,45 r--__-r----r-__--r--~-,.--.,r---r-........,..- -
.....
35
30
25
~
;
:) 2e
:>...u
15
10
O .........---I
•
---'----Io--'--.....&...-....a.--...a.-001---"'"---I-.a..-----IO"'-~
2.8
...e
,..
..e
1'ee u.e 14.8.6.8 I."
2eee
u ... (.in)
Figure 10. Model Changes in the Studied Workload.
The algorithm accurately detected that the whole segment 2
is anomalous. Then the tool correctly performed the model
reconciliation for the consecutive segments around the anoma(cid:173)
10us segment as shown in Figure 11. Finally, the algorithm
correctly raised alarms on the application change when the re(cid:173)
gression model has changed and could not be reconciled (last
two segments in Figure 11.
., j--.,r--......,.----r-........-.....,.--....,.-"'":""""":...,........-..·..,...--T---,
H
..:>
:)
Q.
c.i
.0
35
30
25
2e
15
I'
•
2..
..•
.
'---
L.-.........:~~'"
"',!,"," ••,,"',::-....:.._--.:..._--:-o...-.....::.......;.........;.:......,...;.......~_~----I
....12.. 14'.
1688
188e Z'.E
,ee
"V'
••8
T••• <., n)
RKonciled Model M,
..,I'---v---J "---y--J
Model M2 Model M3
Figure 11. Model Reconciliation in the Studied Workload.
The power of regression-based approach is that it is sensi(cid:173)
tive and accurate to detect a difference in the CPU consumption
model of application transactions. However, it can not identify
the transactions that are responsible for this resource consump(cid:173)
tion difference. To complement the regression-based approach
and to identify the transactions that cause the model change we
use the application performance signature. Comparison of the
new application signature against the old one allows efficient
detection of transactions with performance changes.
12 r - - - - , - - - - - . - - - - - - - , - - - - , - - - - - - . - - - - - - - . - - - - . , - - - - ,
10
6
2
~
<1l
()
.~
(Jl
./"''.....
,,/'
It---./
. /
' "
: ~
!'"
/ ' l " ~
~ •.......--. .-
...
",'1;
o
-2 '-----'------'-------'-----'-----'------'--------'-----'
10
12
14
16
transaction number
Figure 12. Original application signature vs the application
signatures of the modified application.
The application signature stays unchanged for the first 5
segments of the studied 30-hour workload. It is plotted in Fig(cid:173)
ure 12 as the base line. The new application signatures for the
6-th and 7-th segments reflect the change in service time of
the "Home" (8th) transaction, while for the other transaction
their service times stay unchanged. Thus, indeed, 6-th and 7-th
segments correspond to the application change.
When we used E~llow = 1%, the algorithm had identified
the 6 major model changes:
in addition to 4 model changes
shown in Figure 10 the algorithm reported 2 extra segments at
timestamps 790 and 1030 that correspond to workload changes
It is important to use the appropri(cid:173)
and that are false alarms.
ate error setting to minimize the number of false alarms. One
can use the application signature while performing the allow(cid:173)
able error tuning: it helps to get an insight in whether the model
change is indeed an application change or whether it rather cor(cid:173)
responds to a workload change.
The above experiments show that the proposed integrated
framework of regression-based transaction model and applica(cid:173)
tion signature provides a simple and powerful on-line solution
for anomaly detection and analysis of essential performance
changes in application behavior.
7 Related Work
Applications built using Web services can span multi(cid:173)
ple computers, operating systems, languages, and enterprises.
Measuring application availability and performance in such en(cid:173)
vironments is exceptionally challenging. However, the tightly
defined structures and protocols that have been standardized by
the Web services community have opened the door for new so(cid:173)
lutions. There is a set of commercial tools [11, 12, 13, 16] for
monitoring Java applications by instrumenting the Java Virtual
Machine (JVM) which provides a convenient locus for non(cid:173)
intrusive instrumentation (some systems focus on .Net instead
of Java). These tools analyze transaction performance by re(cid:173)
constructing the execution paths via tagging end-to-end user
transactions as they flow through a J2EE-based system and
looking for performance problems using one or more of the
following techniques:
• Fixed or statistical baseline guided threshold setting in HP
BTO product suite [13], IBM Tivoli [11], CA Wily Intro(cid:173)
scope [8], and Symantec [3 [18]. This approach can be
labor intensive and error prone.
1-4244-2398-9/08/$20.00 ©2008 IEEE
460
DSN 2008: Cherkasova et al.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:22:14 UTC from IEEE Xplore.  Restrictions apply. 
International Conference on Dependable Systems & Networks: Anchorage, Alaska, June 24-27 2008
• Adaptive threshold setting, where the application work(cid:173)
load is evaluated periodically, e.g., every 24 hours, and
thresholds are adjusted. Examples include BMC Proac(cid:173)
tiveNet [3] and Netuitive [15]. This approach can result in
a large number of false alarms while adjusting to change.
• Change detection combined with statistical baselining and
thresholding, e.g., CA Wily's Introscope [8].
While it is useful to have detailed information into the current
transaction latencies, the above tools provide limited informa(cid:173)
tion on the causes of the observed latencies, and can not be
used directly to detect the performance changes of an updated
or 1110dified application.
In addition to commercial tools, several research projects
have addressed the problem of performance monitoring and
debugging in distributed systems. Pinpoint [4] collects end(cid:173)
to-end traces of client requests in a J2EE environment using
tagging and identifies components that are highly correlated
with failed requests using statistics. Statistical techniques are
also used by [1] to identify sources of high latency in commu(cid:173)
nication paths. Magpie [2] provides the ability to capture the
resource demands of application requests as they are serviced
across components and machines in a distributed system. Mag(cid:173)
pie records the communication path of each request and also
its resource consumption, which allows for better understand(cid:173)
ing and modeling of system performance. Cohen et al. [7] use
a statistical approach to model performance problems of dis(cid:173)
tributed applications using low-level system metrics. They de(cid:173)
sign a set of signatures to capture the essential system state that
contributes to service-level objective violations. These signa(cid:173)
tures are used to find symptoms of application performance
problems and can be compared to signatures of other applica(cid:173)
tion performance problems to facilitate their diagnosis.
From the above works, the two most closely related to our
approach is Magpie [2] and [7]. Magpie uses a more sophis(cid:173)
ticated tracing infrastructure than in our approach and concen(cid:173)
trates on detecting relatively rare anomalies. The goal of our
work is to detect performance changes in application behavior
caused by application modifications and software updates that
are complementary and independent on workload conditions in
production environments.
8 Conclusion and Future work
Today, the three-tier architecture paradigm has become·an
industry standard for building enterprise client-server applica(cid:173)
tions. The application server is a core component in this archi(cid:173)
tecture and defines the main service functionality. Typically,
when a new application update is introduced and/or unexpected
performance problems are observed, it is important to separate
performance issues that are caused by a high load of incom(cid:173)
ing workload from the performance issues caused by possible
errors or inefficiencies in the upgraded software.
In this work, we propose a new integrated framework of
measurement and system modeling techniques for anomaly de(cid:173)
tection and analysis of essential performance changes in appli(cid:173)
cation behavior. Our solution is based on integration of two
complementary techniques:
i) a regression-based transaction
model that characterizes the resource consumption pattern of
the application; and ii) an application performance signature
that provides a compact model of run-time behavior of the ap(cid:173)
plication. The proposed on-line regression-based algorithm
accurately detects a change in the CPU consumption pattern
of the application and alarms about either observed perfor(cid:173)
mance anomaly or possible application change. However, it
can not distinguish which of the transactions is responsible for
a changed CPU consumption of the application. To comple(cid:173)
ment the regression-based approach and to identify the trans(cid:173)
actions that cause the model change, we use the application
performance signature.
While this paper concentrates on performance anomalies
and model changes in the CPU consumption of the applica(cid:173)
tion, we believe that both regression method and application
performance signature can be extended for evaluating memory
usage and memory usage anomalies such as memory leaks. We
plan to exploit this avenue in our future work.
Acknowledgements: We would like to thank our HP col(cid:173)
leagues from the Diagnostics team: Brent Enck, Dave Ger(cid:173)
shon, Anupriya Ramraj, Glenna Mayo for their help and useful
discussions during this work.
References
[1] M. Aguilera, 1. Mogul, 1. Wiener, P. Reynolds, and A. Muthi(cid:173)
tacharoen. Performance debugging for distributed systems of
black boxes. Proc. of the 19th ACM SOSP'2003.
[2] P. Barham, A. Donnelly, R. Isaacs, R. Mortier. Using Magpie
for request extraction and workload modelling. Proc of the 6th
Symposium OSDI'2004.
[3] BMC ProactiveNet. www.bmc.com/
[4] M. Chen, A. Accardi, E. Kiciman, 1. Lloyd, D. Patterson, A.
Fox, and E. Brewer. Path-based failure and evolution manage(cid:173)
ment. Proc. of the 1st Symposium NSDI'04.
[5] L. Cherkasova, M. Karlsson. Dynamics and Evolution of Web
Sites: Analysis, Metrics and Design Issues. In Proc. of the 6-th
International Symposium on Computers and Communications
(ISCC'01),2001.
[6] L. Cherkasova, Y. Fu, W. Tang, A. Vahdat: Measuring and
Characterizing End-to-End Internet Service Performance. Jour(cid:173)
nal ACMIIEEE Transactions on Internet Technology, (TOIT),
November, 2003.
[7] I. Cohen, S. Zhang, M. Goldszmidt, 1. Symons, T. Kelly, A.
Fox. Capturing, Indexing, Clustering, and Retrieving System
History. Proc. of the 20th ACM Symposium SOSP'2005.
[8] CA Wily Introscope. www.wilytech.com.
[9] F. Douglis and A. Feldmann. Rate of change and other metrics:
a live study of the world wide web. In USENIX Symposium on
Internet Technologies and Systems, 1997.
[10] N. R. Draper and H. Smith. Applied Regression Analysis. John
Wiley & Sons, 1998.
[11] IBM Corporation. Tivoli Web Management Solutions, http:
//www.tivoli.com/products/demos/twsm.html.
[12] Indicative Co. www.indicative.comlproductslEnd-to-End.pdf
[13] Mercury Diagnostics. www.mercury.comlus/products/diagnostics/
[14] N. Mi, L. Cherkasova, K. Ozonat, 1. Symons, and E. Smirni.
Analysis of Application Performance and Its Change via Rep(cid:173)
resentative Application Signatures. Will appear in NOMS'2008.
[15] http://www.netuitive.com/
[16] Quest
Software
http://java.quest.comlperformasure.
Inc.
Performasure.
[17] C. Stewart, T. Kelly, A. Zhang. Exploiting nonstationarity for
performance prediction. Proc. of the EuroSys'2007.
[18] Symantec [3: Application Performance Management http:
//www.symantec.com/business/products/
[19] TPC-W Benchmark. URL http://www . tpc. org
[20] Q. Zhang, L. Cherkasova, and E. Smirni: A Regression-Based
Analytic Model for Dynamic Resource Provisioning of Multi(cid:173)
Tier Applications. Proc. of the 4th IEEE International Confer(cid:173)
ence on Autonomic Computing (ICAC'2007), 2007.
[21] Q. Zhang, L. Cherkasova, G. Mathews, W. Greene, and E.
Smirni: R-Capriccio: A Capacity Planning and Anomaly De(cid:173)
tection Tool for Enterprise Services with Live Workloads. Proc.
of the ACMIIFIP/uSENIX 8th International Middleware Con(cid:173)
ference (Middleware' 2007), 2007.
1-4244-2398-9/08/$20.00 ©2008 IEEE
461
DSN 2008: Cherkasova et al.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:22:14 UTC from IEEE Xplore.  Restrictions apply.