title:Poster: Evaluating Security Metrics for Website Fingerprinting
author:Nate Mathews and
Mohammad Saidur Rahman and
Matthew Wright
CCS ’19, November 11ś15, 2019, London, United Kingdom
Nate Mathews, Mohammad Saidur Rahman, and Matthew Wright
Table 1: Metric results for ML and DL feature experiments.
ML
DL
Undefended
WTF-PAD
Walkie-Talkie
Tamaraw
Undefended
WTF-PAD
Walkie-Talkie
Tamaraw
Info. Leakage
Bits % of Max
6.49
6.54
6.37
3.20
6.54
6.48
6.42
3.57
98.9%
99.6%
97.1%
48.8%
99.6%
97.8%
98.9%
54.4%
Bayes Error
Top-1 Accuracy Top-2 Accuracy
1− ˆR*
90.9%
47.8%
45.9%
28.5%
97.9%
83.4%
72.7%
20.3%
(ϵ,ϕ)-privacy
RF
0.09
0.52
0.54
0.73
0.02
0.17
0.27
0.80
96.3%
62.5%
9.03%
12.5%
96.2%
81.2%
31.6%
6.5%
DF
-
-
-
-
97.1%
85.9%
43.8%
7.6%
RF
97.9%
75.3%
89.5%
21.4%
97.6%
88.5%
78.7%
12.0%
DF
-
-
-
-
98.2%
91.9%
98.1%
13.2%
bits) by a defense. The WeFDE technique estimates information
leakage by finding the mutual information between the distribution
of sites and the information contained in the fingerprints of those
sites. An advantage of WeFDE is that features can be analyzed
individually.
2.1 Extending to DL
These security metrics are designed to analyze handcrafted features
developed for early ML-based WF attacks. The domain, however,
has recently moved to more powerful DL-based attacks that directly
utilize raw traffic information. To evaluate DL attacks using these
security metrics, we need to make some adjustments.
In this study we specifically examine the Deep Fingerprinting
(DF) attack. The DF attack utilizes a convolutional neural network
model (CNN) that can automatically learn robust feature repre-
sentations from raw data. This ability is often accredited to the
convolutional layers used in the early layers of the model. The
outputs of convolutional layers can be thought of as the DL model’s
internal feature representation.
To apply the existing WF metrics to this CNN model, the learned
feature representations must first be extracted. We do this by train-
ing the CNN model on a training dataset so that the convolutional
filters have been learned. We then remove the classification and
fully-connected layers from the model such that the the trained
model returns the outputs of the last convolutional layer (see Fig-
ure 2).
3 EVALUATION
For the following experiments, we use the large datasets collected
by Sirinam et al. [15]. In particular, we use their dataset containing
95 sites with 1,000 instances each for both undefended Tor and for
Tor with simulated WTF-PAD [9] and Tamaraw [4] defenses. For
our Walkie-Talkie (W-T) [18] evaluations, we use Sirinam’s W-T
dataset, which includes 900 instances each.
We run two sets of experiments between which we vary the
feature representation for our data (ML or DL features). In our
first set of experiments, we process data into hand-crafted features
(representing ϕ) using a feature set derived from the features of
CUMUL [12] and k-FP [8]. In our second set of experiments, we
instead use the DL representation of the data provided by the DF
attack model [15].
2
Figure 2: Process for performing metrics analysis on CNN-
based DL models.
We use these experiments to compare the results of accuracy-
based evaluations with that of the WeFDE and Bayes error tech-
niques. For the accuracy evaluations, we examine feature perfor-
mance for both the DF model and a Random Forest (RF) classifier.
3.1 Results
The results from our experiments are summarized in Table 1. The
DL features achieve approximately a 20% improvement over ML
features when used with the same RF classifier for the WTF-PAD
traffic and a 23% improvement for Walkie-Talkie. As expected, the
DF attack outperforms the RF classifier in nearly all settings, except
for Tamaraw. This is likely due to the 5000-packet cutoff for trace
length that we used for all DL experiments, removing the useful
total trace length feature, since Tamaraw’s high rate of dummy
packets leads to very long traces.
WeFDE. When we compare the individual feature leakages to
the total feature leakage, as illustrated in Figure 3, we find a sur-
prising mismatch of results. While overall information leakage for
undefended, WTF-PAD, and W-T reach near the maximum possible
leakage, the individual leakage measurements show noticeably dif-
ferent leakage patterns. When examining the individual leakages,
we see that the undefended dataset leaks on average 1.75±0.50 bits
per feature value with a maximum leakage of 2.80 bits. On the other
hand, the average leakage for the W-T and WTF-PAD datasets are