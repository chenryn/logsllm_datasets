title:Anomaly Characterization in Large Scale Networks
author:Emmanuelle Anceaume and
Yann Busnel and
Erwan Le Merrer and
Romaric Ludinard and
Jean Louis Marchand and
Bruno Sericola
2014 44th Annual IEEE/IFIP International Conference on Dependable Systems and Networks
2014 44th Annual IEEE/IFIP International Conference on Dependable Systems and Networks
2014 44th Annual IEEE/IFIP International Conference on Dependable Systems and Networks
Anomaly Characterization in Large Scale Networks
Emmanuelle Anceaume
CNRS / IRISA, France
PI:EMAIL
Yann Busnel
LINA / Universit´e de Nantes, France
PI:EMAIL
Erwan Le Merrer
Technicolor Rennes, France
PI:EMAIL
Romaric Ludinard
Inria, France
PI:EMAIL
Jean-Louis Marchand
Ecole Normale Sup´erieure de Rennes, France
PI:EMAIL
Bruno Sericola
Inria, France
PI:EMAIL
Abstract—The context of this work is the online characteriza-
tion of errors in large scale systems. In particular, we address
the following question: Given two successive conﬁgurations of
the system, can we distinguish massive errors from isolated ones,
the former ones impacting a large number of nodes while the
second ones affect solely a small number of them, or even a
single one? The rationale of this question is twofold. First, from
a theoretical point of view, we characterize errors with respect to
their neighbourhood, and we show that there are error scenarios
for which isolated and massive errors are indistinguishable from
an omniscient observer point of view. We then relax the deﬁnition
of this problem by introducing unresolved conﬁgurations, and
exhibit necessary and sufﬁcient conditions that allow any node
to determine the type of errors it has been impacted by. These
conditions only depend on the close neighbourhood of each
node and thus are locally computable. We present algorithms
that implement these conditions, and show through extensive
simulations, thier performances. Now from a practical point of
view, distinguishing isolated errors from massive ones is of utmost
importance for networks providers. For instance, for Internet
service providers that operate millions of home gateways, it would
be very interesting to have procedures that allow gateways to self
distinguish whether their dysfunction is caused by network-level
errors or by their own hardware or software, and to notify the
service provider only in the latter case.
I. INTRODUCTION
In this paper we study the on-line monitoring problem in
large scale distributed systems. This problem deals with the
capability of collecting and analysing relevant information
provided by monitored devices so as to make the monitoring
application continuously aware of the state of the system. In
presence of a large number of monitored devices (i.e., a typical
scenario is the one encountered by Internet service providers
operating millions of home gateways), an approach to solve
this problem is to rely on customers care call centres. Such call
centres are notiﬁed by customers that experience degradations
of service quality. This approach while commonly adopted,
shows several
the latent
detection period between the occurrence of an incident and the
instant at which the customer observes it is unpredictable), cost
(i.e., it requires to mobilize agents for manually handling each
customer notiﬁcation), and inefﬁciency (e.g., when incidents
lie in a part of the network that
is not operated by the
service provider or when notiﬁcations are due to customers
issues in terms of latency (i.e.,
negligences). These issues call for automated monitoring pro-
cedures that should be able to notify the service provider only
for legitimate reasons. Actually, standardized procedures [4]
exist at devices level to autonomously trigger investigations
in presence of errors or networks events. However,
these
procedures are never used for practical reasons. Indeed if
the cause of a QoS (Quality of Service) variation lies in the
network itself – due to routing loops, router dysfunctions, or
conﬁguration errors – this may impact a very large number
of devices (more precisely,
impact services consumed by
these devices), and thus letting thousands of impacted devices
reporting the problem to the operator may quickly become
a disaster. It is thus of utmost importance to minimize the
overall pressure put on the service operator, by giving each
device the capability to locally detect whether the local QoS
degradation is also observed at many other devices or not, so
that only isolated errors or events are reported on the ﬂy by
the devices experiencing them. Alternatively, there is a clear
need for over-the-top operators – that rely on Internet Service
Providers to transparently deliver content to their clients – to
quickly detect network level events. Indeed, incidents at the
network level may impact the quality at which data is received
at thousands of clients that will naturally blame their over-
the-top operators. Our solution provides each end-device the
capability to self distinguish network-based events from local
ones, so that only network-events are reported on the ﬂy to
the over-the-top operators.
In both cases, the key point is to provide each monitored
device a way to estimate on other devices the impact of a
locally perceived QoS degradation. The approach we propose
boils down for a device to locally detect the presence of
similarity features in the abnormal behaviour of other devices.
This is achieved by modelling the QoS of the different services
accessed by a device by a point in a QoS space E, and
the temporal evolution of its QoS by a trajectory in E. A
trajectory is abnormal if the predicted values of the QoS differ
from the observed ones. The problem we tackle amounts for
a device to locally identify all the abnormal trajectories that
are close to its own one, to determine how dense they are,
to ﬁnally decide whether its services have been impacted by
an isolated event or a network one. The notion of closeness is
978-1-4799-2233-8/14 $31.00 © 2014 IEEE
978-1-4799-2233-8/14 $31.00 © 2014 IEEE
978-1-4799-2233-8/14 $31.00 © 2014 IEEE
DOI 10.1109/DSN.2014.23
DOI 10.1109/DSN.2014.23
DOI 10.1109/DSN.2014.23
68
68
68
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:05:15 UTC from IEEE Xplore.  Restrictions apply. 
modelled by the presence of points in a ball centred at a given
point. Surprisingly, we show that it exists some trajectories
that are indistinguishable (even from the point of view of
an omniscient observer) in the sense that it is impossible to
decide whether they are due to isolated events or a network
one without knowing the event itself. We formally characterize
these unresolved conﬁgurations, and derive necessary and suf-
ﬁcient conditions that allow each device to locally decide with
certainty whether it belongs to an unresolved conﬁguration or
if it has been impacted by an isolated event, or by a network
one. In our approach, the frequency at which QoS information
is sampled is locally tuned, and only depends on the local
occurrence of QoS degradations. Therefore, by avoiding any
kind of global synchronization, devices can efﬁciently provide
a ﬁne grain event/errors detection without impacting the rest of
the system. The inﬂuence of this local tuning has an enjoyable
consequence on the number of unresolved conﬁgurations: by
sampling sufﬁciently often one’s neighborhood, the number of
unresolved conﬁgurations drastically shrinks. To summarize,
our contributions are :
• A modelling of isolated and network based errors;
• The derivation of local conditions that allow each device
to decide with certainty whether its observed QoS degra-
dation is due to an isolated error or a network one;
• A ﬁne granularity of error detection locally tunable and
transparent to the remaining of the system;
• The design of local algorithms whose decisions are as
accurate as the one provided by an omniscient observer.
The remaining of the paper is organized as follows. Sec-
tion II provides an overview of existing monitoring ap-
proaches. Section III presents the model of the system, and
how errors are modelled. Section IV formalizes the on-line
anomaly detection problem and its relaxed version. Section V
presents computable conditions that allow any device to locally
solve the relaxed version of the anomaly detection problem.
Section VI presents the local algorithms, and their perfor-
mances are analysed through extensive simulations (see Sec-
tion VII). Section VIII concludes and presents future works.
clusters groups together nodes that share correlated values
of the considered metric according to the Pearson correlation
coefﬁcient). At clusters level, an elected leader is in charge of
communicating with the management system when the current
metric values of its group members differ from each others.
Although close to our objectives, the main drawback of this
solution lies on the centralized clustering process. All the
nodes of the system are continuously organized into clusters
computed through the k-means algorithm exclusively run by
the management node, which is a clear impediment to the
scalability of their approach. Other works aim at minimizing
the processing cost for continuous monitoring [13], [9], [14]
in the light of the theoretical results of [5], however similarly
to [15], all these approaches suffer from a centralized handling
of the clustering process. Recently, Choffnes et al. [2] have
proposed to leverage structured peer-to-peer architectures (i.e.,
Distributed Hashing Tables) to guarantee scalable monitoring
management. In contrast to the previous described works that
focus on monitoring ﬁne-grained changes on individual nodes,
[2] pushes monitoring on end users. Their approach consists in
having a set of cooperating edge system monitors (ESM), such
that each one has access to a distributed storage system based
on a DHT in which they publish aggregated informations about
events detected in their own sub-network. This allows network
operators to regularly access the storage architecture to analyse
system wide detected events, and thus to detect global, or at
least massive, network outages. The authors in [1] propose an
on-line error detection mechanism that in contrast to [2] is pro-
active. Their mechanism fully depends on the tessellation of
the overlay. However, tessellating the space with large bucket
sizes tends to identify each possible error as a massive one,
while considering small bucket sizes reduces drastically the
probability of having a large number of devices into a single
bucket, giving rise to the triggering of false alarms. In our
approach, we go a step further by providing to close end
devices the capability to locally exploit correlation between
their state to detect on the ﬂy the type of error they have been
impacted by.
II. RELATED WORK
III. SYSTEM MODEL
This section provides an overview of the existing techniques
used in large scale systems to continuously and automatically
monitor time-varying metrics. The authors in [15] exploit
temporal and spatial correlations [3], [8], [11] among groups
of monitored nodes to decrease monitoring communication
costs, i.e., the cost incurred by the periodic reporting of the
updated metrics values from the monitored nodes to the man-
agement node. The idea is to prevent any reporting message
from occurring when such a reporting would contain metrics
values that could be directly inferred by the management
node. This is achieved by giving each monitored node the
capability to locally detect whether the current values of
its monitored metrics are in accordance with predicted ones
(through Kalman ﬁlters tools [7] installed at both monitored
nodes and the management node), and by gathering nodes
into clusters (such that, for each monitored metric, a set of
This section presents the terminology and concepts we need
to model the impact of outages on the monitored devices. Note
that we adopt the following conventional notations. Variables
are represented by lower-case letters as j, (cid:2), p and q, sets are
denoted by capital letters as S and E, and families of sets are
denoted by capital calligraphic letters as P. The set of integers
{1, . . . , n} is denoted by [[1, n]].
A. Preliminaries
We consider a set of n monitored devices, such that each
one consumes a subset of d services s1, . . . , sd. At any
discrete time k, the QoS of each consumed service si at
device j is locally measured with an end-to-end performance
measurement function qi,k(j), whose range of values is [0, 1].
For non consumed services si, we have qi,k(j) = 0. We
model the QoS of monitored devices at discrete time k as
696969
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:05:15 UTC from IEEE Xplore.  Restrictions apply. 
a set Sk of n points in a space E = [0, 1]d, with d ≥ 1,
called the QoS space. The position of device j at time k
is represented by point pk(j) = (q1,k(j), . . . , qd,k(j)). Note
that in the following we interchangeably use terms device
and point to speak about the position of a device in the QoS
space E. The state Sk of the system at discrete time k is
Sk = (pk(1), . . . , pk(n)). Each monitored device j has also
access at any time k to an error detection function ak(j) such
that ak(j) = true if at time k there is at least one service
consumed by device j whose variation of quality of service is
too large to be considered as normal. Error detection functions
provide some meaningful predictions of what should be the
next output value based on the sequence of past input values.
Different kinds of error detection functions exist, ranging from
simple threshold based functions to more sophisticated ones
like the Holt-Winters forecasting or Cusum methods [6], [12],
[10]. Note that implementation of function a is out-of the
scope of the paper.
As said in the introduction, the impact of errors on devices
can either be locally restricted (that is, each error affects a
few number τ of devices, with τ a conﬁguration parameter)
or spread over a large number of devices (i.e., more than τ
devices). By construction, a set of devices whose positions
in the QoS space E are very close to each other exhibit a
similar QoS. We make the assumption that if a set of devices,
exhibiting a similar QoS at time k − 1 are impacted by the
same error then they will undergo the same QoS variation.
Thus, at time k their modiﬁed positions in E will still be
close to each other. This closeness assumption is modelled by
the presence of points in a ball of radius r. In the following
r is called the consistency impact radius. Prior to formally
modelling the impact of errors or events on devices, we ﬁrst
present the notions we will intensively use in the following.
B. Terminology and Notations
For the sake of simplicity, we use the uniform norm
(cid:3) · (cid:3) deﬁned for any x = (x1, . . . , xd) ∈ E by (cid:3)x(cid:3) =
max{x1, . . . , xd}. As we consider a ﬁnite dimension space,
all norms are equivalent and thus all the results in the paper
would still work even when using a different norm.
Deﬁnition 1 (r-consistent set): For any r ∈ [0, 1/4), a
subset B ⊆ [[1, n]] is said to be r-consistent at time k if the
maximal distance between any i, j ∈ B is not larger than 2r,
that is,
∀(i, j) ∈ B2,(cid:3)pk(i) − pk(j)(cid:3) ≤ 2r.
Deﬁnition 2 (Maximal r-consistent set): For
∈