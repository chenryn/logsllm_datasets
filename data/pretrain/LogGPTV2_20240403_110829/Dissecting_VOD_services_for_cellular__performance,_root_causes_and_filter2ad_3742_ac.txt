2
Y
3
Y
8
0.40
120
90
N
Y
30
D4
6
Y
3
Y
6
0.67
34
15
Y
N
-
S1
2
Y
2
Y
16
1.35
180
175
Y
Y
50
S2
3*
Y
2
Y
6
0.76
30
4
Y
N
-
Design factors
Track setting
Encoding scheme
TCP utilization
TCP persistence
Download control
Startup logic
Adaptation logic
Problem
The bitrate of lowest track is set high.
Adaptation algorithms do not consider actual segment bitrate.
Audio and video content downloading progress is out of sync when using multiple
TCP connections.
Players use non-persistent TCP connections.
Players do not resume downloading segments until the buffer is almost empty.
Players start playback when only one segment is downloaded.
The bitrate selection does not stabilize with constant bandwidth.
Players ramp down selected track with high buffer occupancy.
Players can replace segments in the buffer with ones of worse quality.
QoE impact
Frequent stalls
Low video quality
Unexpected stalls
Low video quality
Frequent stalls
Stall at the beginning
Extensive track switches
Low video quality
Waste data and low video quality
Table 2: Identified QoE-impacting issues
Affected service
H2, H5, S1
D2
D1
H2, H3, H5
S2
H3, H4, H6, D2, D4
D1
H1, H4, H6, D1
H1, H4
3.2 Transport layer design
In HAS, players use the HTTP/HTTPS protocol to retrieve seg-
ments from the server. However, how the underlying transport
layer protocols are utilized to deliver the media content depends
on the service implementation. All the VOD services in this study
use TCP as the transport layer protocol.
TCP connection count and persistence. As illustrated in Ta-
ble 1, all studied apps that adopt HLS use a single TCP connection
to download segments. 3 of these apps use non-persistent TCP con-
nections and establish a new TCP connection for each download.
This requires TCP handshakes between the client and server for
each segment and TCP needs to go through the slow start phase for
each connection, degrading achievable throughput and increasing
the potential of suboptimal QoE. We suggest apps use persistent TCP
connections to download segments. All apps that adopt DASH and
SmoothStreaming use multiple TCP connections due to separated
audio and video tracks. All these connections are persistent.
TCP connection utilization. Utilizing multiple TCP connec-
tions to download segments in parallel brings new challenges. Some
apps such as D1 use each connection to fetch a different segment.
Since concurrent downloads share network resources, increasing
the concurrency can slow down the download of individual seg-
ments. This can be problematic in some situations (especially when
either the buffer or bandwidth is low) by delaying the arrival of
a segment with a very close playback time, increasing the poten-
tial for stalls. Different from these apps, D3 only downloads one
segment at a time. It splits each video segment into multiple sub-
segment and schedules them on different connections. To achieve
good QoE, the splitting point shall be carefully selected based on per
connection bandwidth to ensure all sub-segments arrive in similar
time, as the whole segment needs to be downloaded before it can
be played. The above highlights that developing a good strategy
to make efficient utilization of multiple TCP connections requires
considerations of complex interactions between the transport layer
and application layer behavior. We leave further exploration to
future work.
When audio and video tracks are separate, the streaming of audio
and video segments are done separately. Since both are required to
 0 5 10 15 20 25 30 35 40 451234567891011121314Bandwidth (Mbps)Network proﬁle id 0 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6H1H2H3H4H5H6D1D2D3D4S1S2Actual/declared bitrateDissecting Cellular VOD Services
IMC ’17, November 1–3, 2017, London, UK
value may lead to stalls soon after the playback. To understand how
popular services configure the startup buffer, we run a series of
experiments for each service. In each experiment we instrument the
proxy to reject all segment requests after the first n segments. We
gradually increase n and find the minimal n required for the player
to start playback. The duration of these segments is the startup
buffer duration. As shown in Table 1, most apps set similar startup
duration around 10s.
Startup track. The selection of the first segment impacts users’
first impression of the video quality. However, at the beginning
the player does not have information about network conditions
(eg., historical download bandwidths), making it challenging to
determine the appropriate first segment.
We examine the startup track of different players in practice.
We find each app consistently selects the same track level across
different runs. The startup bitrates across apps have high diversity.
4 apps start with a bitrate lower than 500 kbps, while another 4
apps set the startup bitrate higher than 1 Mbps. We shall further
explore the QoE impact of startup buffer duration and startup track
in sec 4.3.
3.3.2 Download control. One important decision the client
makes is determining when to download the next segment. A naive
strategy is to keep fetching segments continuously, greedily build-
ing up the buffer to avoid stall events. However, this can be subop-
timal as (1) it increases wasted data when users abort the session
and (2) it may miss the opportunity to get a higher quality segment
if network condition improves in the future. We observe that, even
under stable network conditions, all the apps exhibit periodic on-off
download patterns. Combining with our buffer emulation, we find
an app always pauses downloading when the buffer occupancy
increases to a pausing threshold, and resumes downloading when
the occupancy drops below another lower resuming threshold.
We set the network bandwidth to 10 Mbps, which is sufficient
for the services to their respective highest tracks. We find 5 apps
set the pausing threshold to be around 30 s, while other apps set
it to be several minutes (Table 1). With a high pausing threshold,
the player can maintain a high buffer occupancy to avoid future
stall events. However, it may lead to more data wastage when users
abort the playback. The different settings among services reflect
different points in the decision space around this tradeoff.
The difference between the pausing and resuming threshold
determines the network interface idle duration, and therefore affects
network energy consumption. 8 apps set the two thresholds to be
within 10 s of each other. As this is shorter than LTE RRC demotion
timer [41], the cellular radio interface will stay in high energy mode
during this entire pause in the download, leading to high energy
consumption. We suggest setting the difference of the two thresholds
larger than LTE RRC demotion timer in order to save device energy.
If either the pausing threshold or the resuming threshold is set
too low, the player’s ability to accommodate network variability
will be greatly limited, leading to frequent stalls. We find that S2
sets the pausing threshold to be only 4s and has a higher probabil-
ity of incurring stalls than other services under similar network
conditions. As the example in Figure 7, at 25 s, the buffer occupancy
of S2 reaches to the pausing threshold and the player pauses down-
loading for around 30 s. When the player resumes downloading
Figure 6: The downloading progress of video and audio con-
tent of D1 is out of sync, causing unexpected stalls.
play any portion of the video, there should be adequate synchro-
nization across the two download processes to ensure that both
contents are available by the designated playback time of the seg-
ment. Our evaluations reveal that uneven downloads for audio and
video lead to clear QoE impairments for some apps. For example,
we find D1 uses multiple TCP connections to download audio and
video content in parallel, but its download progresses for audio and
video content can have significant differences, especially when the
network bandwidth is low. For the two network profiles with the
lowest average bandwidth, the average difference between video
and audio downloading progress is 69.9 s and 52.5 s respectively. In
the example shown in Figure 6, buffered video content is always
more than audio content. When stalls occur, the buffer still contains
around 100 s of video content. In this case, the stalls could have been
avoided, without using any additional network resources, by just
reusing some of the bandwidth for fetching more audio and a little
bit less video. We suggest ensuring better and tighter synchronization
between audio and video downloads.
3.3 Client-side design
The client player is a core component that impacts QoE by per-
forming intelligent adaptation to varying network conditions. In
this subsection we stress test the different players using the 14
bandwidth profiles collected from various scenarios. By compar-
ing the behavior across different services under identical network
conditions, we are able to identify interesting client behaviors and
pinpoint potential QoE problems. More specifically, we use black-
box testing to study how players behave at startup, i.e. the startup
logic, when they load the next segment, i.e. the download control
policy and what segment they load, i.e. the adaptation logic.
3.3.1
Startup logic. We characterize two properties in the
startup phase, startup buffer duration and startup track.
Startup buffer duration. At the beginning of a session, clients
need to download a few segments before starting playback. We
denote the minimal buffer occupancy ( in terms of number of sec-
onds’ worth of content) required before playback is initiated as the
startup buffer duration.
Setting the startup buffer duration involves tradeoffs as a larger
value can increase the initial delay experienced by the user (as it
takes a longer time to download more of the video), but too small a
IMC ’17, November 1–3, 2017, London, UK
Shichang Xu, Z. Morley Mao, Subhabrata Sen, and Yunhan Jia
Figure 7: S2 sets the resuming buffer to only
4s, leading to stalls.
Figure 8: D1 selected track is not stable even
with constant bandwidth
Figure 9: Selected declared bitrate given a con-
stant bandwidth
segments, the buffer occupancy is only 4s and drains quickly due to
temporary poor network condition. As stalls significantly degrade
user experience, we suggest setting both thresholds reasonably high to
avoid stalls. The exact value will depend on factors like the specific
adaptation algorithm and is beyond the scope of this paper.
Next, we study the client adaptation logic. A good adaption logic
should provide high average bitrate and reduce stall events and
unnecessary track switches.
3.3.3 Track selection under stable network bandwidth. For each
app, we run a series of experiments within each of which we emulate
a specific stable network bandwidth for 10 min and examine the
resulting track selection in the steady state. A good adaption logic
should achieve an average bitrate similar to the network bandwidth
without stalls and frequent track switches.
Stability. We find that the selected track of D1 does not stabilize
even with constant network bandwidth. As shown in Figure 8, the
network bandwidth is constantly 500 kbps. However, D1 frequently
switches between different tracks and tries to improve the average
actual bitrate to be close to network bandwidth. However, frequent
switches, especially switches between non-consecutive tracks, can
impair user experience. In contrast, the other apps all converge to
a single track (different for each app) after the initial startup phase.
We suggest the adaptation logic avoid unnecessary track switches.
Aggressiveness. We find that the track that different apps con-
verge to under the same stable bandwidth condition has significant
difference across different services. We term services that converge
to a track with declared bandwidth closer to available bandwidth
as more aggressive. We show a few examples in Figure 9. We find 3
apps are more aggressive and select tracks with bitrate no less than
the available network bandwidth. The reason why they are able to
stream tracks with a bitrate higher than available network band-
width without stalls is that they use VBR encoding and the actual
segment bitrate is much lower than the declared bitrate. The other
apps are relatively conservative and select tracks with declared
bitrates no more than 75% of the available bandwidth. In particular,
D2 even select tracks with declared bitrates no more than 50% of
available bandwidth.
3.3.4 Track adaptation with varying network bandwidths. To
understand the adaptation to varying network condition, we run
each app with a simple “step function" bandwidth profile, i.e. the
network bandwidth first stays stable at one value and suddenly
changes to another value. We test different combinations of the
initial and final bandwidth steps, and when the step occurs. The
behavior across the different apps is summarized in Table 1.
Reaction to bandwidth increase. When bandwidth increases,
all apps start to switch to a track with higher bitrate after a few seg-
ments. In addition, we find some apps revisit earlier track switching
decisions and redownload existing segments in the buffer in an
attempt to improve video quality. We further analyze this in § 4.1.
Reaction to bandwidth decrease. When bandwidth decreases,
apps eventually switch to a track with a lower bitrate.
A higher buffer pausing threshold enables more buffer buildup,
which can help apps better absorb bandwidth changing events and
defer the decision to select a lower track without the danger of
stalls. However, among the 7 apps that have a large buffer pausing
threshold (larger than 60 s), 4 apps always immediately switch to a
low track when a bandwidth degradation is detected, even when the
buffer occupancy is high, leading to suboptimal QoE. In contrast,
the other 3 apps set thresholds on buffer occupancy above which
they do not switch to a lower track even if the available bandwidth
reduces. We suggest the adaptation logic takes buffer occupancy into
consideration and utilizes the buffer to absorb network fluctuations.
In summary, our measurements show popular VOD services
make a number of different design choices and it is important to
perform such cross-section study to better understand the current
practices and their QoE implications.
4 QOE ISSUES: DEEP DIVE
Some QoE impacting issues involve complex interactions between
different factors. In this section, we explore in depth some key issues
impacting the services we study, and use targeted black-box exper-
iments to deduce their root causes. In addition, we further examine
whether similar problems exist for ExoPlayer, an open source media
player used by more than 10,000 apps [4] including YouTube [2],
BBC [5], WhatsApp [6] and Periscope [8] etc. Exoplayer therefore
provides us a unique view of the underlying design decisions in a
state-of-the-art HAS player being increasingly used as the base for
many commercial systems. The insights and mitigation strategies
we develop from this exploration can be broadly beneficial to the
community for improving the QoE of VOD services.
 0 1 2 3 4 0 0.5 1 1.5 2 2.5 3 3.5 4Declared bitrate (Mbps)Network bandwidth (Mbps)y=xy=0.75xy=0.5xH1H3D1D2D3Dissecting Cellular VOD Services
IMC ’17, November 1–3, 2017, London, UK
4.1 Segment Replacement (SR)
Existing adaptation algorithms [27, 31, 33, 52] try to make intelli-
gent decisions about track selection to achieve the best video quality
while avoiding stall events. However, due to the fluctuation of net-
work bandwidth in the mobile network, it is nearly impossible for
the adaption logic to always make the perfect decision on selecting
the most suitable bitrate in terms of the tradeoff between quality
and smoothness. We observe that to mitigate the problem, when
the network condition turns out to be better than predicted, some
players will discard low quality segments that are in the buffer but
have not yet been played, and redownload these segments using a
higher quality track to improve user perceived video quality. We
denote this behavior of discarding video segments in the buffer and
redownloading them with potentially different quality as Segment