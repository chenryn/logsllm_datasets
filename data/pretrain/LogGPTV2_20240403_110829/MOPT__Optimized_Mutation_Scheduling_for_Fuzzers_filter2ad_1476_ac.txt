maker fuzzing modes for AFL, based on whether the deter-
ministic stage will be re-enabled or not: (1) MOPT-AFL-tmp,
which will re-enable the deterministic stage again when the
number of new interesting test cases exceeds a predeﬁned
threshold; (2) MOPT-AFL-ever, which will never re-enable
the deterministic stage in the following fuzzing process.
5 Evaluation
5.1 Real World Datasets
We have evaluated MOPT on 13 open-source linux pro-
grams as shown in Table 2, each of which comes from dif-
USENIX Association
28th USENIX Security Symposium    1955
Table 3: The unique crashes and paths found by AFL, MOPT-AFL-tmp and MOPT-AFL-ever on the 13 real world programs.
MOPT-AFL-tmp
MOPT-AFL-ever
Program
AFL
Unique
crashes
Unique
paths
Unique
crashes
mp42aac
exiv2
mp3gain
tiff2bw
pdﬁmages
sam2p
avconv
w3m
objdump
jhead
mpg321
infotocap
podofopdﬁnfo
total
135
34
178
4
23
36
0
0
0
19
10
92
79
610
815
2,195
1,430
4,738
12,915
531
2,478
3,243
11,565
478
123
3,710
3,397
47,618
209
54
262
85
357
105
4
506
470
55
236
340
122
2,805
Increase
+54.8%
+58.8%
+47.2%
+2,025.0%
+1,452.2%
+191.7%
+4
+506
+470
+189.5%
+2,260.0%
+269.6%
+54.4%
+359.8%
Unique
paths
1,660
2,980
2,211
7,354
22,661
1,967
17,359
5,313
19,309
489
1,054
6,157
4,704
93,218
Increase
+103.7%
+35.8%
+54.6%
+55.2%
+75.5%
+270.4%
+600.5%
+63.8%
+67.0%
+2.3%
+756.9%
+66.0%
+38.5%
+95.8%
Unique
crashes
199
66
262
43
471
329
1
182
287
69
229
692
114
2,944
Increase
+47.4%
+94.1%
+47.2%
+975.0%
+1,947.8%
+813.9%
+1
+182
+287
+263.2%
+2,190.0%
+652.2%
+44.3%
+382.6%
Unique
paths
1,730
4,642
2,206
7,295
26,669
3,418
16,812
5,326
22,648
483
1,162
7,048
4,694
104,133
Increase
+112.3%
+111.5%
+54.3%
+54.0%
+106.5%
+543.7%
+578.5%
+64.2%
+95.8%
+1.0%
+844.7%
+90.0%
+38.2%
+118.7%
ferent source ﬁles and has different functionality represent-
ing a broad range of programs. We choose these 13 pro-
grams mainly for the following reasons. First, many of the
employed programs are also widely used in state-of-the-art
fuzzing research [4, 5, 9, 10, 21]. Second, most programs
employed in our experiments are real world programs from
different vendors and have diverse functionalities and vari-
ous code logic. Therefore, our datasets are representative and
can all-sidedly measure the fuzzing performance of fuzzers
to make our analysis more comprehensive. Third, all the
employed programs are popular and useful open-source pro-
grams. Hence, evaluating the security of these programs are
meaningful for the vendors and users of them.
5.2 Experiment Settings
The version of AFL used in our paper is 2.52b. We apply
MOPT in the havoc stage of AFL and implement the pro-
totypes of MOPT-AFL-tmp and MOPT-AFL-ever, where -
tmp and -ever indicate the corresponding pacemaker fuzzing
modes discussed in the previous section. The core functions
of MOPT is implemented in C.
Platform. All the experiments run on a virtual machine
conﬁgured with 1 CPU core of 2.40GHz E5-2640 V4, 4.5GB
RAM and the OS of 64-bit Ubuntu 16.04 LTS.
Initial seed sets. Following the same seed collection and
selection procedure as in previous works [3, 22, 23], we use
randomly-selected ﬁles as the initial seed sets. In particu-
lar, for each objective program, we obtain 100 ﬁles with the
corresponding input format as the initial seed set, e.g., we
collect 100 mp3 ﬁles for mp3gain. The input format of each
program is shown in Table 2. In particular, we ﬁrst download
the ﬁles with the corresponding input formats for each ob-
jective program from the music download websites, picture
download websites, and so on (except for text ﬁles, where we
obtain text ﬁles by randomly generating letters to ﬁll them).
Then, for the large ﬁles such as mp3 and PDF, we split them
to make their sizes reasonable as seeds. Through this way,
we have a large corpus of ﬁles with the corresponding input
formats for each objective program. Finally, we randomly
select 100 ﬁles from the corpus. These 100 ﬁles will be the
initial seed set of all the fuzzers when fuzzing one objective
program.
Evaluation metrics. The main evaluation metric is the
number of the unique crashes discovered by each fuzzer.
Since coverage-based fuzzers such as AFLFast [5] and
VUzzer [6] consider that exploring more unique paths leads
to more unique crashes, the second evaluation metric is the
number of unique paths discovered by each fuzzer.
5.3 Unique Crashes and Paths Discovery
We evaluate AFL, MOPT-AFL-tmp and MOPT-AFL-ever
on the 13 programs in Table 2, with each experiment runs for
240 hours. The results are shown in Table 3, from which we
can deduce the following conclusions.
• For exploring unique crashes, MOPT-AFL-tmp and
MOPT-AFL-ever are signiﬁcantly more efﬁcient than AFL
on all the programs. In total, MOPT-AFL-tmp and MOPT-
AFL-ever discover 2,195 and 2,334 more unique crashes
than AFL on the 13 programs. Thus, MOPT-AFL has much
better performance than AFL in exploring unique crashes.
• For triggering unique paths, MOPT-AFL-tmp and
MOPT-AFL-ever also signiﬁcantly outperform AFL. In to-
tal, MOPT-AFL-tmp and MOPT-AFL-ever found 45,600
and 56,515 more unique paths than AFL on the 13 programs.
As a result, the proposed MOPT can improve the coverage of
AFL remarkably.
• When considering the pacemaker fuzzing mode, MOPT-
AFL-tmp and MOPT-AFL-ever discover the most unique
crashes on 8 and 6 programs, respectively, while MOPT-
AFL-ever discovers more crashes in total. Since the main
difference between the two fuzzers is whether using the de-
terministic stage later, it may be an interesting future work
to ﬁgure out how to employ the deterministic stage properly.
1956    28th USENIX Security Symposium
USENIX Association
Table 4: Vulnerabilities found by AFL, MOPT-AFL-tmp and MOPT-AFL-ever.
Program
AFL
Unknown vulnerabilities
Not CVE
CVE
Known vul-
nerabilities
CVE
Sum
Unknown vulnerabilities
Not CVE
CVE
MOPT-AFL-tmp
MOPT-AFL-ever
Known vul-
nerabilities
CVE
Sum
Unknown vulnerabilities
Not CVE
CVE
Known vul-
nerabilities
CVE
mp42aac
exiv2
mp3gain
pdﬁmages
avconv
w3m
objdump
jhead
mpg321
infotocap
tiff2bw
sam2p
Total
podofopdﬁnfo
/
/
/
/
/
/
/
/
/
/
/
1
5
6
1
5
4
1
0
0
0
1
0
3
5
/
/
20
1
3
2
0
0
0
0
0
1
0
0
/
/
7
2
8
6
1
0
0
0
1
1
3
5
1
5
33
/
/
/
/
/
/
/
/
/
/
/
2
14
16
2
5
9
12
2