egy, with an adjustable threshold.
for the data [13, 76]. When the generation size is close to or
larger than the EPC size, the slowdown on MSC becomes
signiﬁcantly higher then the Copying GC due to an order-of-
magnitude higher number of page faults, which are even more
expensive than LLC misses.
We observe three performance regimes for GC, which re-
ﬂect the underlying hardware limitations:
• If the generation ﬁts inside the LLC (8MB on Intel E3-1280
v5), copying GC is even more efﬁcient than MSC.
• If the generation ﬁts in the enclave page cache (EPC—the
protected physical memory that is used inside enclaves),
the cost of GC is proportional to the size of the generation.
• When the generation size approaches the EPC size, MSC
becomes much worse than copying GC because of EPC
swapping. Currently, the EPC is limited to 93.5 MB of
usable memory; after this is exhausted, the OS must swap
the encrypted contents of the EPC to other DRAM or disk.
Some of the EPC must be used for the code and stack, so
there is an upward trend closer to 80 MB.
Prior work [13, 25] reports up to a 1000× slowdown for ran-
dom reads and writes in an enclave larger than the EPC. This
size limitation has not been enlarged on any later generations
of Intel CPUs. Because MSC-based GC traverses the heap
more times than the copying GC, it will incur more swapping
when the GC’ed space exceeds the EPC.
7.2 GC Optimization for Enclaves
The experiment above indicates three distinct performance
regimes for enclaves. Thus, we adopt a three-generation
design, where each generation has a target working set size:
(1) smaller than the LLC size (8MB), (2) between the LLC
size and the EPC size (93.5MB), and (3) larger than the EPC
size. The goal of this three-generation design is to minimize
cache misses in the young GC and the page faults in the old
GC. For the rest of the paper, we refer to these as the new,
middle, and old generations.
Figure 8 illustrates our three-generation GC design. The
middle generation adopts the same MSC strategy as the old
generation. Objects that survive the young generation get a
Figure 7: Single-threaded, serial GC slowdown caused by
SGX, within the young generation (copying GC) and the old
generation (MSC), in respect to different generation sizes. For
each GC iteration, 80% of the objects are garbage-collected,
while the remaining are compacted or promoted.
ation uses a copying GC that traverses the heap and copies live
objects into a reserved space (called the To space) on the ﬂy.
The underlying assumption is that the live objects will be few,
and it is simpler to just copy them than managed fragmented
free space. In contrast, the old generation uses a Mark-Sweep-
Compact (MSC) strategy, which consists of multiple passes
through the heap, and is optimized to minimize movement of
objects that are likely to survive.
We observe several problems for both the young and old
GCs in enclaves. We illustrate the issues using a simple
microbenchmark that targets a 20% object survival rate for
both generations, by repeatedly allocating and freeing a forest
of 5KB binary trees (each with 31 nodes), occupying 1MB of
the heap. Figure 7 shows the average slowdown on each GC
iteration in the young and old generations, as a function of
different generation sizes. We observe that the Copying GC
in the young generation has more slowdown in enclaves until
the generation size reaches ∼80MB, due to more LLC misses
during data movement. Note that LLC misses in enclaves
are expensive, as they involve decrypting and integrity check
514    29th USENIX Security Symposium
USENIX Association
0X2X4X6X8X10X12X14X081624324048566472808896104112GC Slowdown on SGXYoung / Old Generation Size (MB)Young GC (Copying)Old GC (Mark-Sweep-Compact)LLC Size(8MB)EPC Size(93.5MB)EdenToFromYoung Gen ( EPC)RRRRRRPromotion Threshold (50%)DeadObjectPromoteAdjustedRef.8 Runtime Implementation
This section describes the implementation of the Civet run-
time framework.
8.1 Civet Runtime Framework
Given the entry classes, our partitioning tool automatically
generates the RPC interfaces for entering and leaving enclaves.
The generated interfaces primarily serve two purposes: (1)
intercepting invocations to entry classes and seamlessly con-
verting them into RPCs, and (2) marshaling and verifying
the input and output objects for the entry classes. To reduce
the execution-time TCB and to improve RPC latency, Civet
directly generates bytecode for the RPC interface and sup-
porting code inside the enclave.
For marshaling objects in and out of enclaves, Civet uses
the Fast-serialization library [77], or fst (v2.50), instead of
using the built-in serialization API. fst generates a more
compact representation of each object; for instance, at run-
time, fst allows Civet to register all the classes needed for
marshaling both inside and outside the enclave, so that object
types can be represented numerically instead of as strings.
Furthermore, we use the off-heap serializer of fst, which
reduces the instantiation cost of marshaling buffers and re-
duces GC during RPCs. The off-heap buffers are allocated
per in-enclave worker thread, and are reused throughout the
enclave execution.
8.2 Reducing Framework TCB
The Civet framework contains several trusted components,
shown in Table 2. Civet includes a modiﬁed JVM, based on
OpenJDK 8 HotSpot runtime, which has a smaller TCB and
ﬁts into the memory limitation of enclaves. This is a pre-
liminary effort—there are additional opportunities to further
shrink or partition the JVM:
• Garbage collector: Civet removes most of the garbage
collectors, such as G1GC and parallel scavenge GC, and
only keeps an optimized serial GC (§7.2).
• Compiler: the default option in Civet is ahead-of-time com-
pilation (AOT). AOT is time-consuming (∼20 minutes
to compiling 4,000 classes), but introduces no overhead
to the execution. For users who cannot compile the byte-
code ahead of time, Civet provides the options of including
the C1 (platform-generic) and/or C2 (architecture-speciﬁc)
compilers in the enclave; or using only the interpreter. The
former increases the in-enclave TCB, whereas the latter
introduces signiﬁcant overheads (10–1000×).
• JVM-related classes: A large portion of the JVM function-
alities are implemented in Java classes. We can simply use
static analysis to include the classes needed by the TCB
and shred the others. Table 2 does not include these classes.
• JNI libraries: Finally, a large portion of the C++ code in the
OpenJDK code base contributes to the JNI library, such as
Figure 9: Average GC latency (including all generations) on
SGX, in regards to the total live object sizes. The compar-
ison is between two-generation and three-generation serial
GCs. The heap size is 256 MB, with the young and middle
generations at 2 MB and 48 MB, respectively.
second chance of being reclaimed in the middle generation,
before being promoted to the old generation. Similar to the
young GC, the middle GC also walks the references from
the known roots, but does not traverse the unclaimed dead
objects in the old generation. This keeps the middle GC from
accessing objects outside of the EPC boundary and reduces
the number of page faults incurred by the GC.
To keep short-lived objects in the middle generation longer,
we set a promotion threshold to decide which objects should
be promoted to the old generation. The middle GC only
promotes objects when the size of the remaining live objects
surpasses a promotion threshold (e.g., 50% of the generation).
The promotion threshold is adjustable by users.
We further reduce memory accesses outside the enclave
by leveraging the remember set abstraction in the HotSpot
VM. We also noticed that after MSC, the adjust reference
phase scans the entire heap to identify and adjust references
to a compacted or promoted object, causing signiﬁcant cache
misses and EPC swapping The remember set use a coarse-
grain bit map to track the region which contains recently
promoted objects to scan for references to younger genera-
tions. Our JVM updates the remember set during the marking
phase of GC, so that the middle GC only has to scan memory
regions that are known to contain references.
We implement our GC strategy on HotSpot JVM and mea-
sure the impact of the middle generation on the average GC
time. Figure 9 shows the average GC time of two-generation
and three-generation GCs. We use a randomized allocation
workload and adjust the total size of live objects, which re-
ﬂects the effective space used by the application. The total
heap size is 256 MB and the young generation size is 2 MB.
Based on our tuning, the best size of the middle generation
is 48 MB and the remaining space is the old generation. The
results show that with our GC, the average GC time (including
middle and old GCs) is consistently 0.5–1.0 seconds faster
than Serial GC (20–89% improvement), at all live object sizes.
USENIX Association
29th USENIX Security Symposium    515
.0001.0002.0003.0004.0005.00081624324048566472808896104112120128GC Latency on SGX (s)Live Objects Size (MB)2-Gen Serial GC3-Gen Serial GC (w/ Middle Gen)Total LoC
3,611
2,166
1,093
31,611
Civet components (language):
Partition tool (Java)
Runtime framework (Java)
Runtime JNI (C++)
Phosphor framework (Java)
Modiﬁed runtime components: Original Partitioned (∆%)
JVM (libjvm)
303,826 (49%)
JNI (libjava, libzip, ...)
68,684 (84%)
Graphene-SGX
49,689 (11%)
Unmodiﬁed runtime components:
GNU libc 2.19
593,159
423,303
55,974
Total LoC
1,008,773
Table 2: The complexity of the whole Civet framework and
the run-time TCB measured in LoC (lines of code), including
both modiﬁed and unmodiﬁed components.
libjava. We observe that a portion of the JNI library, espe-
cially the system-tier functionality, is perfect for partition-
ing outside the enclave. For example, FileInputStream
contains native methods to read a ﬁle. These JNIs are
originally shielded by Graphene-SGX, but can be moved
outside the enclave to reduce the TCB.
In total, Civet removes 49% of the JVM code and 84% of
the JNI code from the trusted computing base. To access OS
functionality from the enclave, Civet uses Graphene-SGX and
GNU libc, which could be further reduced in code size.
9 Case Studies and Evaluation
In this section, we evaluate the efﬁciency of Civet using three
use cases, to show the sensitivity of the TCB and performance
to the partition boundary chosen by the developers. We select
three applications that accept user-provided code in a some-
what modular design. Each of these applications varies in the
degree to which the interface for user-provided code matches
what should run in the enclave, and thus, the degree of dif-
ﬁculty in partitioning. In the case of Tomcat (§9.2), users
provide code at a granularity very close to what should go in
the enclave. In the cases of and Hadoop (§9.3) and GraphChi
(§9.3), the users provide code, but issues such as batching
inputs to the enclave require a more careful decision about
partitioning boundaries.
We also evaluate the cost of static analysis and the break-
downs of performance overheads using microbenchmarks.
Unless otherwise noted, we conﬁgure Phosphor’s taint-
tracking to only track explicit ﬂows; tracking implicit ﬂows
typically adds 10×, which dwarf other overheads from Civet.
All experiments are collected on a Supermicro SYS-5019S-
M server. The CPU is a 8-core 3.70 GHz Intel Xeon E3-1280
CPU, with microcode patched for Spectre mitigation. Out
of 32GB RAM on the machine, 93.5MB is dedicated to en-
claves. The system runs Ubuntu 16.04.4 LTS server with
Linux kernel 4.15.0-58-generic, with Page Table Isolation
Grep.main(String[])
ToolRunner.run(Configuration, Configured, String[])
Grap.run(String[])
Job.setMapperClass(Class class)
Job.waitForCompletion()
(new process) YarnChild.main(String[])
(new thread) YarnChild$2.run()
MapTask.run()
MapTask.runNewMapper()
RegexMapper.map(Key, Text, Context)
Figure 10: The call graph in Hadoop with RegexMapper.
Selected entry methods
Shredding
Before partitioning
1(cid:13) MapTask.*
2(cid:13) RegexMapper.*
class
method
class
method
#C
LoC ∆%
#M
7.2M
68.5K 589.7K
12.9K 115.3K
1.5M 79%
4.3K 20.7K 372.5K 95%
4.2K 38.0K 509.2K 93%
2.1K 12.1K 247.8K 96%
Table 3: Partitioning results of Civet for Hadoop, partitioned
with two boundaries and measured in classes (#C), methods
(#M), and lines of code (LoC). For both cases, AESCipher
and PCBC are explicitly included for dynamic loading.
(PTI) enabled. The Civet implementation is based on Open-
JDK v1.8.0_71, Phosphor v0.0.4 [24], Intel SGX Linux SDK
and driver v2.3 [78], and Graphene-SGX v0.6 [14].
9.1 Hadoop
Hadoop [11] is a widely used framework for distributed com-
puting and big data. We choose the regular expression parser
(RegexMapper) as an example, but the usage can be gen-
eralized to other Hadoop applications. Running regular ex-
pression parsing inside enclaves is beneﬁcial for protecting
sensitive data that might be processed in a distributed manner,
such as system or network logs.
Hadoop already has a modular architecture, and is eas-
ily partitioned with Civet. Coarse-grained partitioning at
the main function is not practical, because Hadoop is multi-
process, illustrated in Figure 10. A more natural division
point is within a worker (or process): 1(cid:13) MapTask.run()
as a generic boundary that can include any mapper; 2(cid:13)
RegexMapper.map() as the mapper class itself. Although
the former is more generic, the latter can have a smaller TCB.
Figure 11 shows the execution time of searching a regular
expression inside a large, encrypted authentication log (1GB),
using RegexMapper as the partition boundary. The sample
is encrypted, line-by-line with the line number as the nonce
for encryption. We pass lines of the log into the enclave
one line at-a-time, because there is no natural division point
in the code that implements batching. In future work, one
could optimize this code by batching the inputs to the mapper.
516    29th USENIX Security Symposium
USENIX Association
Figure 11: End-to-end execution time of the Hadoop regular
expression parser to process 1GB of encrypted authentication
logs. Lower is better. For Civet, only the mapper is partitioned
into enclaves. We evaluate Civet performance with SGX, deep
input type checks (TC), and taint-tracking without explicit
ﬂow (TT). The Civet and native workloads both run on a
single-node, full-featured Hadoop v2 framework.
Selected entry methods
Shredding
Before partitioning
HttpResponder.*
class
method
#C
LoC ∆%
3.6M
#M
34.5K 276.9K
4.2K 37.9K 508.3K 77%
2.0K 11.4K 240.9K 93%