Rapid Enrollment. Creating new user accounts or up-
dating existing user accounts should be quick, so that users
can set up and reset their 3D-signature passwords easily.
Rapid Veriﬁcation. The authentication process should
require no more than a few seconds.
No Unauthorized Access. One key factor that deter-
mines the success of KinWrite is how likely an unautho-
rized user can pass the authentication. While a bullet-proof
system is costly to achieve and may degrade user experi-
ences, KinWrite should ensure that it takes a non-trivial
amount of effort for an adversary to impersonate a legiti-
mate user, at least be harder than guessing text-based pass-
words randomly.
Low False Negative. Users will become frustrated if it
takes several attempts to input an acceptable 3D-signature.
Thus, KinWrite should have a low false negative, despite
several variances that may occur over multiple authentica-
tion sessions. For instance, 3D-signatures of the same user
may change over time; the distance between a user and a
Kinect may vary, affecting the captured 3D-signatures.
3.2 Attack Model
Several mechanisms can be used to protect KinWrite. For
instance, opaque panels can be installed at the entrance of
a building to block shoulder surﬁng, and raw 3D-signatures
shall never be stored to avoid insider attacks. Nevertheless,
we study possible attacks for impersonating legitimate users
assuming those protection mechanisms are unavailable.
• Random Attack: With no prior knowledge of gen-
uine 3-D signatures, an attacker can randomly sign 3D-
signatures and hope to pass the authentication. This
is equivalent to a brute force attack against text-based
password schemes.
• Observer Attack: In an observer attack, an adversary
is able to visually observe how a user signs her pass-
word once or multiple times and then try to imitate her
3D-signature.
• Content-Aware Attack: In a content-aware attack, an
adversary knows the corresponding spelling of a legit-
imate user’s 3D-signature, but has not observed how
the user signs it in space. The correct spelling can be
obtained through social engineering or by an educated
guess based on the user’s name, hobbies, etc.
• Educated Attack: In an educated attack, an attacker
is aware of the spelling of a 3D-signature and has ob-
served multiple times how a user signs her password.
That is, an educated attack is the combination of an
observer attack and a content-aware attack.
• Insider Attack: An insider attacker can obtain the
spelling of a signature, the corresponding trajectory
(i.e., the one shown in Figure 2), and she can observe
how a user signs in space. That is, an insider attacker
(a) Ob-1
(b) Ob-4
(c) CA&Ob-4
(d) CA
(e) CA
(f) Insider
Figure 2. Signatures (‘ma’) signed by two
persons mimicking various attackers. User
1 signed (a)-(c), and user 2 signed (d)-(f).
(a) An observer attacker with one observa-
tion, (b) an observer attacker with four ob-
servations, (c) an educated attacker knowing
the spelling and observed four times, (d)-(e)
content-aware attackers with known spelling
but unaware of the shape of the signature,
(f) insider attacker knowing the shape of 3D-
signature.
is an educated attacker who knows the signature trajec-
tory. We note signature trajectories are difﬁcult to ob-
tain, since in practice a KinWrite system should never
store such information permanently nor display 3D-
signatures. Although unlikely to happen, we include
this uncommon attack in order to evaluate the perfor-
mance of KinWrite under extreme attacks.
To obtain an intuition on how well the aforementioned
attackers can imitate 3D-signatures, we had two users act
as attackers and recorded their 3D-signatures when trying
to forge the genuine 3D-signature shown in Figure 1 (a).
For the ﬁrst user, we demonstrated the motion of signing
‘ma’ four times, and then informed him what was written
in the space, i.e., we had him act as an observer attacker
ﬁrst then as an educated attacker. For the second user, we
asked him to write ‘ma’ multiple times without demonstrat-
ing the motion but gave him the spelling, and then showed
the trajectory of the genuine 3D-signature, i.e., we had him
act as a content-aware attacker then as an insider attacker.
Figure 2 illustrates the signatures signed by the two users,
from which we obtain the following intuition: Observing
the signing process alone seems to help an attacker to imi-
tate the shape of signatures. However, increasing the num-
ber of observations of the signing process does not neces-
sarily improve the forgery in this case. This is encouraging.
A larger-scaled experiment that were carried out over ﬁve
months will be reported in Section 6.
(a) an original image
(b) a depth image
Figure 3. The RGB and depth images captured
by a Kinect.
3.3 3D-Signature Acquisition Using a Kinect
Basics of a Kinect. A Kinect is a motion input sensing
device launched by Microsoft for Xbox 360 and Windows
PCs. A Kinect has three sensors: an RGB camera, a depth
sensor, and a multi-array microphone. The depth sensor
consists of an infrared projector and a monochrome CMOS
sensor, which measures the distance between the object and
the camera plane at each pixel. With the depth sensor, a
Kinect can capture the 3D structure of an object under al-
most any ambient light conditions [7], including complete
darkness. Figure 3 shows example pictures captured by a
Kinect: an RGB image of a user who was signing his pass-
word and the corresponding depth image. A depth image is
shown as a grayscale image, where a darker pixel represents
a smaller depth. In this case, the hand of the user is closest
to the Kinect.
Why Kinect? We track the hand movement from the
captured 3D depth information of the body, with which we
can identify the underlying 3D-signatures for veriﬁcation.
This is much more effective than using classical RGB sen-
sors which cannot capture the motion along the depth direc-
tion (perpendicular to the image plane). The motion along
the depth direction contains important gesture information
and can help distinguish 3D-signatures from different sub-
jects. Such information is usually difﬁcult to track from a
2D RGB video, especially when the light is weak or the
hand and surrounding background bear a similar color. Be-
fore the release of Kinect, other commercialized depth sen-
sors had been used for human posture tracking and gesture
recognition [41]. However, these commercialized depth
sensors are usually too expensive and only applicable in re-
stricted lab environments [42].
Feasibility of Kinect. Kinect was originally designed
for gaming with the goal of capturing the body motion
of a player. Will a Kinect sufﬁce for acquiring 3D-
signatures? There are two factors determining the appli-
cability of Kinect: the sampling rate and working range. A
Kinect can capture 30 frames per second; each frame has
a resolution of 240 × 320 pixels, which is lower than the
typical sampling rate (100Hz) in digitizing tablets (used for
capturing online signatures). However, the maximum fre-
quencies underlying the human body kinematics are always
under 20-30 Hz [43], and the Kinect sampling rate is sufﬁ-
ciently dense for signatures [26]. The working range of the
Kinect depth sensor is between 0.8m to 4m (the new version
of Kinect can capture the depth from 0.4m to 8m), which
works well for the proposed application; For example, at
the door of the building, we can allocate an area within the
working range of a Kinect, in which a user can move her
hand towards the Kinect.
What to Track? One key question is which part of the
hand shall be tracked to generate 3D-signatures? For the
purpose of modeling, we usually require a signature to be
a temporal sequence of points with an inﬁnitely small size.
Among the options for tracking, e.g., a ﬁngertip, the whole
palm or ﬁst, we found the whole palm or ﬁst performs worse
than a ﬁngertip because of its relatively large size, with
which we cannot ﬁnd the motion center accurately enough
to create a 3D-signature with sufﬁcient spatial resolution.
Thus, we track the ﬁnger tip, whose corresponding region
in the depth map is small, and we can simply take its ge-
ometry center as a point on a 3D-signature. As such, we
envision that a user will extend his hand in front of his body
and use one of his ﬁngers to sign towards the Kinect, as
shown in Figure 3 (a). The regions with the smallest value
in the Kinect depth map will correspond to the positions of
the ﬁngertip most of the time. Note that without a pen, peo-
ple usually move their ﬁngertips to describe what they want
to write. Therefore, the proposed setting of using ﬁngertips
for signatures should be natural and spontaneous to most
people.
Although Kinect produces depth images that greatly fa-
cilitate 3D-signature acquisition, the errors of the depth
measurements can be from several millimeters up to about
4cm [40], affecting the accuracy of acquired 3D-signatures.
We discuss the mechanisms to address such large measure-
ment errors in Section 4 .
3.4 KinWrite Architecture
Like other authentication systems, authenticating via Kin-
Write consists of two phases: enrollment and veriﬁcation.
During an enrollment, a user will create an account and en-
ter a few 3D-signatures. Then, KinWrite will ﬁrst process
these genuine 3D-signatures and select one sample as the
template for this user. During the authentication phase, a
user signs her password towards a Kinect. After preprocess-
ing the newly entered 3D-signature, KinWrite will compare
it with the stored template. A match means that the user is
genuine, and KinWrite will grant access, otherwise it will
deny access.
The computing unit of KinWrite consists of a data pre-
processor, a feature extractor, a template selector, and a ver-
Figure 4. Flow chart of KinWrite. The computing component of KinWrite consists of a data prepro-
cessor, a feature extractor, a template selector, and a veriﬁer.
iﬁer, as shown in Figure 4. The data preprocessor takes
frames captured by a Kinect and outputs a 3D-signature.
In particular, the data preprocessor identiﬁes the position of
the ﬁngertip that is used for signing a password in the space.
By sequentially connecting the ﬁngertips in all frames, Kin-
Write constructs a raw 3D-signature. Since the size of the
raw 3D-signature depends on the distance between a user
and the Kinect, we add a data processing step to remove the
size difference. Then, a Kalman ﬁlter is applied to further
reduce the spatial noise in the 3D-signature, and features
are extracted for veriﬁcation.
We discuss the technical details of the data preproces-
sor and the feature extractor in Section 4, and the template
selector and the veriﬁer in Section 5.
4 Data Processing & Feature Extraction
In this section, we describe the techniques to construct a
reﬁned 3D-signature from a raw depth image sequence, and
discuss feature extraction and its normalization.
4.1 Data Processing
A data preprocessor performs ﬁngertip localization, signa-
ture normalization, and signature smoothing.
4.1.1 Fingertip Localization
Given N frames that capture a 3D-signature, in an ideal
case, at each frame t, t = 1, 2,··· , N,
the ﬁngertip
(used for the signature) should have the minimum depth.
However, in practice, the minimum-depth pixel in a frame
may not always correspond to it because of various ran-
dom noises. To address this issue, we enforce the tem-
poral continuity of the ﬁngertip position in a signature –
the ﬁngertip position should only vary in a small range be-
tween two consecutive frames. We use the following prop-
agation technique – given the ﬁngertip position pr(t) =
z(t))T at the t-th frame, we only search
(pr
within a small region (40 × 40 pixels) centered at pr(t) in
frame (t + 1) for the ﬁngertip position. Speciﬁcally, in this
small region, we choose the pixel with the minimum depth
value as pr(t + 1).
x(t), pr
y(t), pr
The performance of this frame-by-frame ﬁngertip local-
ization depends highly on a correct ﬁngertip position in the
ﬁrst frame. To ensure the correct initial position, we con-
tinue to use the temporal continuity and adopt the following
initialization strategy. We choose a small number of the ﬁrst
K = 3 frames, and ﬁnd the pixel with the minimum-depth
value in each frame. If they show good temporal continu-
ity (i.e., the identiﬁed pixel in a frame is always located
in a 40 × 40 region centered at the pixel identiﬁed in the
previous frame), we consider them as the ﬁngertip posi-
tions in these K frames and process all the other frames
Raw3D-SignatureScaled & Translated 3D-SignatureSmoothed3D-Signature......Finger-Tip Position 1Finger-Tip Position 2Finger-Tip Position N...Initial UserSignature 1UserSignature Template SelectorVerifierResultsInitial UserSignature 2Initial UserSignature nDepth Frame 1Depth Frame 2Depth Frame NExtracted FeatureNormalized FeatureAttackSignatureData PreprocessorFeature Extractor(a) 3D
(b) X-Y Plane
(c) Z-X Plane
(d) Y-Z Plane
Figure 5. A raw 3D-signature (a Chinese character) and the smoothed one using a Kalman ﬁlter.
by using the propagation technique described above. Other-
wise, we remove the ﬁrst frame of these K frames and add
the next frame to repeat the initialization process until their
minimum-depth pixels show the required temporal continu-
ity, which reﬂects the reliability of the ﬁngertip localization
in the initial frames.
4.1.2 Scaling and Translation
By connecting the ﬁngertip points sequentially, we get a raw
signature, which is a 3D curve in the x − y − z space. One
global feature of a signature is its size, which can be de-
ﬁned by the size of the bounding box around the signature.
The size of a signature in the x − y image plane may vary
when the distance between the user and the Kinect sensor
changes. In addition, users may intentionally sign in a larger
or smaller range during different trials, resulting in different
sizes of signatures. To achieve a reliable veriﬁcation, we
scale the raw 3D-signatures into a 1 × 1 × 1 bounding box.
To make the different 3D-signatures spatially compara-
ble, we perform a global translation on each signature so
that the rear-right corner of its 3D bounding box becomes
its origin. Finally, we normalize each position such that
it follows a normal Gaussian distribution N (0, 1) over all
the frames. We denote the position of the ﬁngertips after
the scaling, translation, and normalization to be ps(t) =
(ps
z(t))T .
x(t), ps
y(t), ps
4.1.3 Signature Smoothing
As shown in Figure 5, the raw 3D-signature obtained by a
Kinect is usually highly jagged and noisy. Such jagged sig-
natures are caused by the limited resolution of the Kinect
depth sensor. For example, a small area around the ﬁnger-
tip may have similar depths. By selecting the minimum-
depth pixel, the above ﬁngertip localization algorithm may
not capture the correct ﬁngertip position.