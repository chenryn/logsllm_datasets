## 缓存置换策略在使用缓存的过程中，除了要考虑数据一致性的问题，你还需要关注的另一个重要的问题是，在内存有限的情况下，要优先缓存哪些数据，让缓存的命中率最高。当应用程序要访问某些数据的时候，如果这些数据在缓存中，那直接访问缓存中的数据就可以了，这次访问的速度是很快的，这种情况我们称为一次缓存命中；如果这些数据不在缓存中，那只能去磁盘中访问数据，就会比较慢。这种情况我们称为"缓存穿透"。显然，缓存的命中率越高，应用程序的总体性能就越好。那用什么样的策略来选择缓存的数据，能使得缓存的命中率尽量高一些呢？如果你的系统是那种可以预测未来访问哪些数据的系统，比如说，有的系统它会定期做数据同步，每次同步的数据范围都是一样的，像这样的系统，缓存策略很简单，就是你要访问什么数据，就缓存什么数据，甚至可以做到百分之百的命中。但是，大部分系统，它并没有办法准确地预测未来会有哪些数据会被访问到，所以只能使用一些策略来尽可能地提高缓存命中率。一般来说，我们都会在数据首次被访问的时候，顺便把这条数据放到缓存中。随着访问的数据越来越多，总有把缓存占满的时刻，这个时候就需要把缓存中的一些数据删除掉，以便存放新的数据，这个过程称为缓存置换。到这里，问题就变成了：当缓存满了的时候，删除哪些数据，才能会使缓存的命中率更高一些，也就是采用什么置换策略的问题。**命中率最高的置换策略，一定是根据你的业务逻辑，定制化的策略。**比如，你如果知道某些数据已经删除了，永远不会再被访问到，那优先置换这些数据肯定是没问题的。再比如，你的系统是一个有会话的系统，你知道现在哪些用户是在线的，哪些用户已经离线，那优先置换那些已经离线用户的数据，尽量保留在线用户的数据也是一个非常好的策略。另外一个选择，就是使用通用的置换算法。一个最经典也是最实用的算法就是 LRU算法，也叫最近最少使用算法。这个算法它的思想是，最近刚刚被访问的数据，它在将来被访问的可能性也很大，而很久都没被访问过的数据，未来再被访问的几率也不大。基于这个思想，**LRU的算法原理非常简单，它总是把最长时间未被访问的数据置换出去。**你别看这个LRU 算法这么简单，它的效果是非常非常好的。Kafka 使用的 PageCache，是由 Linux 内核实现的，它的置换算法的就是一种LRU 的变种算法\：LRU 2Q。我在设计 JMQ 的缓存策略时，也是采用一种改进的 LRU 算法。LRU淘汰最近最少使用的页，JMQ根据消息这种流数据存储的特点，在淘汰时增加了一个考量维度：页面位置与尾部的距离。因为越是靠近尾部的数据，被访问的概率越大。这样综合考虑下的淘汰算法，不仅命中率更高，还能有效地避免"挖坟"问题：例如某个客户端正在从很旧的位置开始向后读取一批历史数据，内存中的缓存很快都会被替换成这些历史数据，相当于大部分缓存资源都被消耗掉了，这样会导致其他客户端的访问命中率下降。加入位置权重后，比较旧的页面会很快被淘汰掉，减少"挖坟"对系统的影响。
## 小结这节课我们主要聊了一下，如何使用缓存来加速你的系统，减少磁盘IO。按照读写性质，可以分为读写缓存和只读缓存，读写缓存实现起来非常复杂，并且只在消息队列等少数情况下适用。只读缓存适用的范围更广，实现起来也更简单。在实现只读缓存的时候，你需要考虑的第一个问题是如何来更新缓存。这里面有三种方法，第一种是在更新数据的同时去更新缓存，第二种是定期来更新全部缓存，第三种是给缓存中的每个数据设置一个有效期，让它自然过期以达到更新的目的。这三种方法在更新的及时性上和实现的复杂度这两方面，都是依次递减的，你可以按需选择。对于缓存的置换策略，最优的策略一定是你根据业务来设计的定制化的置换策略，当然你也可以考虑LRU 这样通用的缓存置换算法。
## 思考题课后来写点儿代码吧，实现一个采用 LRU 置换算法的缓存。    /** * KV 存储抽象 */public interface Storage {    /**     * 根据提供的 key 来访问数据     * @param key 数据 Key     * @return 数据值     */    V get(K key);} /** * LRU 缓存。你需要继承这个抽象类来实现 LRU 缓存。 * @param  数据 Key * @param  数据值 */public abstract class LruCache implements Storage{    // 缓存容量    protected final int capacity;    // 低速存储，所有的数据都可以从这里读到    protected final Storage lowSpeedStorage;     public LruCache(int capacity, Storage lowSpeedStorage) {        this.capacity = capacity;        this.lowSpeedStorage = lowSpeedStorage;    }}你需要继承 LruCache 这个抽象类，实现你自己的 LRU 缓存。lowSpeedStorage是提供给你可用的低速存储，你不需要实现它。欢迎你把代码上传到 GitHub上，然后在评论区给出访问链接。大家来比一下，谁的算法性能更好。如果你有任何问题，也可以在评论区留言与我交流。感谢阅读，如果你觉得这篇文章对你有帮助的话，也欢迎把它分享给你的朋友。![](Images/4daea3d1a08e48460d8df87c2a766cef.png){savepage-src="https://static001.geekbang.org/resource/image/de/23/de0a489e6b4fa9a49450bf9197593423.jpg"}
# 17 \| 如何正确使用锁保护共享数据，协调异步线程？你好，我是李玥。在前几天的加餐文章中我讲到，JMQ为了提升整个流程的处理性能，使用了一个"近乎无锁"的设计，这里面其实隐含着两个信息点。第一个是，在消息队列中，"锁"是一个必须要使用的技术。第二个是，使用锁其实会降低系统的性能。那么，如何正确使用锁，又需要注意哪些事项呢？今天我们就来聊一聊这个问题。我们知道，使用异步和并发的设计可以大幅提升程序的性能，但我们为此付出的代价是，程序比原来更加复杂了，多线程在并行执行的时候，带来了很多不确定性。特别是对于一些需要多个线程并发读写的共享数据，如果处理不好，很可能会产出不可预期的结果，这肯定不是我们想要的。我给你举个例子来说明一下，大家应该都参与过微信群投票吧？比如，群主说："今晚儿咱们聚餐，能来的都回消息报一下名，顺便统计一下人数。都按我这个格式来报名。"然后，群主发了一条消息："群主，1人"。这时候小六和无双都要报名，过一会儿，他俩几乎同时各发了一条消息，"小六，2人""无双，2 人"，每个人发的消息都只统计了群主和他们自己，一共 2人，而这时候，其实已经有 3个人报名了，并且，在最后发消息的无双的名单中，小六的报名被覆盖了。![](Images/12ee6e2f5287fdae58080028da41bd34.png){savepage-src="https://static001.geekbang.org/resource/image/87/e7/87ac82860fe52434dee843c8e710b2e7.jpg"}这就是一个非常典型的由于并发读写导致的数据错误。使用锁可以非常有效地解决这个问题。锁的原理是这样的：**任何时间都只能有一个线程持有锁，只有持有锁的线程才能访问被锁保护的资源。**``{=html}在上面微信群报名的例子中，如果说我们的微信群中有一把锁，想要报名的人必须先拿到锁，然后才能更新报名名单。这样，就避免了多个人同时更新消息，报名名单也就不会出错了。
## 避免滥用锁那是不是遇到这种情况都要用锁解决呢？我分享一下我个人使用锁的第一条原则：**如果能不用锁，就不用锁；如果你不确定是不是应该用锁，那也不要用锁。**为什么这么说呢？因为，虽然说使用锁可以保护共享资源，但是代价还是不小的。第一，加锁和解锁过程都是需要 CPU时间的，这是一个性能的损失。另外，使用锁就有可能导致线程等待锁，等待锁过程中线程是阻塞的状态，过多的锁等待会显著降低程序的性能。第二，如果对锁使用不当，很容易造成死锁，导致整个程序"卡死"，这是非常严重的问题。本来多线程的程序就非常难于调试，如果再加上锁，出现并发问题或者死锁问题，你的程序将更加难调试。所以，你在使用锁以前，一定要非常清楚明确地知道，这个问题必须要用一把锁来解决。切忌看到一个共享数据，也搞不清它在并发环境中会不会出现争用问题，就"为了保险，给它加个锁吧。"**千万不能有这种不负责任的想法，否则你将会付出惨痛的代价！**我曾经遇到过的严重线上事故，其中有几次就是由于不当地使用锁导致的。**只有在并发环境中，共享资源不支持并发访问，或者说并发访问共享资源会导致系统错误的情况下，才需要使用锁。**
## 锁的用法锁的用法一般是这样的：1.  在访问共享资源之前，先获取锁。2.  如果获取锁成功，就可以访问共享资源了。3.  最后，需要释放锁，以便其他线程继续访问共享资源。在 Java 语言中，使用锁的例子：    private Lock lock = new ReentrantLock(); public void visitShareResWithLock() {  lock.lock();  try {    // 在这里安全的访问共享资源  } finally {    lock.unlock();  }}也可以使用 synchronized 关键字，它的效果和锁是一样的：    private Object lock = new Object(); public void visitShareResWithLock() {  synchronized (lock) {    // 在这里安全的访问共享资源  }}使用锁的时候，你需要注意几个问题：第一个，也是最重要的问题就是，**使用完锁，一定要释放它**。比较容易出现状况的地方是，很多语言都有异常机制，当抛出异常的时候，不再执行后面的代码。如果在访问共享资源时抛出异常，那后面释放锁的代码就不会被执行，这样，锁就一直无法释放，形成死锁。所以，你要考虑到代码可能走到的所有正常和异常的分支，确保所有情况下，锁都能被释放。有些语言提供了 try-with的机制，不需要显式地获取和释放锁，可以简化编程，有效避免这种问题，推荐你使用。比如在 Python 中：    lock = threading.RLock() def visitShareResWithLock():  with lock:    