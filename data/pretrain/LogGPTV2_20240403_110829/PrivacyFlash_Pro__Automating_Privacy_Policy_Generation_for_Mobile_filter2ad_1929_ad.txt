code must contain (1) and the third party code must contain
(2) through (5), where (6) additional evidence can be used in
place of an authorization method if and only if an authorization
method is present in the ﬁrst party code. As third parties do
not have their own Info.plist, they reuse the ﬁrst party’s.
Similarly, third parties can reuse the ﬁrst party’s authorization
method, in which case additional evidence in the third party
code is required to show that the practice is actually used by the
third party. Although, unlikely to occur, the ﬁrst party can also
reuse a third party’s authorization method, in which case the
ﬁrst party code needs additional evidence. Figure 5 illustrates
the idea. Generally, the evidence-based approach is also used
to search for functionality within libraries, such as federated
Facebook or Google Login.
b) Detecting Libraries and their Purposes: The code
analysis distinguishes ﬁrst and third parties since various
legal requirements depend on such distinction. For example,
apps subject to CalOPPA must disclose whether third parties
may collect personally identiﬁable information [CalOPPA,
§22575(b)(6)]. As described, third party libraries can make
use of the same APIs as the app itself. Whether libraries are
written in Swift or Objective-C, all APIs remain visible in
plaintext even when the libraries are compiled. Thus, libraries
in both source and compiled format can be analyzed.
PrivacyFlash Pro scans through the project directory of
an app, e.g., searching for the Google-Mobile-Ads-SDK
that would indicate the presence of Google’s AdMob library.
As app developers in the iOS ecosystem usually include
libraries via package managers, such as CocoaPods [22] or
Carthage [19], libraries are recognized based on Pods and
Carthage directories as well as other framework resources from
package managers used in an app. For example, the name of
a third party can be reliably identiﬁed from the Podfile if
the third party library was integrated via CocoaPods. Use of a
package manager ensures that the library directory is present
and named accordingly as otherwise the build process for the
app would fail. While the third party library identiﬁcation
necessarily hinges on the use of a package manager and
does not cover libraries manually included in an app, our
performance analysis indicates that only a tiny fraction of
libraries might be missed (§ IV-B1).
The purpose for a permission use by a ﬁrst party can be
inferred from the Plist permission string. However, the purpose
for a third party use is usually not explicitly speciﬁed in the app
or library code. Thus, the speciﬁcation layer of PrivacyFlash
Pro also contains a third party purpose speciﬁcation. At this
point, the speciﬁcation contains the purposes for 300 popular
third party libraries we identiﬁed on the analytics service
Apptopia [10]. It is our goal to grow this speciﬁcation with
9
Fig. 6: Screenshot of the wizard and policy generation UI including an excerpt from the privacy law overview (1) and a tooltip (2).
open source contributions. The purpose categories we use
so far (and the quantity of libraries) are: authentication (9),
advertising (105), analytics (38), social network integration
(31), payment processing (10), and developer support (107). It
should be noted, though, that even if the purpose of a library is
not included in the speciﬁcation, the integration of the library
will still be detected as long as it was done with a package
manager. The developer can also always specify the purpose
manually in the questionnaire wizard.
3) Questionnaire Wizard: Once the code analysis is ﬁn-
ished, the developer is presented with a wizard for adjusting
any (un)detected practices. The wizard helps the developers
to determine which laws are applicable to their apps and
provides explanations of the law. Despite the evidently large
impact that different laws can make on what must be disclosed
(Appendix A), existing generators are sparse in this regard.
Implementation details for the policy, e.g., where it
is to
be posted, and related topics, e.g., whether the developer is
required to provide Do Not Sell functionality, are covered in
tooltips. Once the developer has ﬁnalized the policy, it can be
exported into an HTML page that can be readily posted on
the developer’s website and that is accessible as per CCPA
Regs §999.308(a)(2)(d). Figure 6 shows a screenshot of the
wizard with the AdColony library detected. Since making it
available to the public, we start to see privacy policies created
with PrivacyFlash Pro in the ﬁeld (§ V-D3).
B. PrivacyFlash Pro Performance
To test its practicability we evaluated the code analysis and
runtime performance of PrivacyFlash Pro.
1) Code Analysis Performance: We started evaluating Pri-
vacyFlash Pro on an app we created with 13 permissions and
5 libraries. Running PrivacyFlash Pro on this app resulted in
a fully correct analysis. We also randomly selected 10 apps
from the Collaborative List of Open-Source iOS Apps [27]
and other public repositories covering 18 permission, at least
one from each of the 13 permissions, and 45 unique libraries.
Permission Category
True Positives
False Positives
False Negatives
Bluetooth
Calendars
Camera
Contacts
Health
HomeKit
Location
Microphone
Motion & Fitness
Media & Apple Music
Photos
Reminders
Speech Recognition
Sum
2
4
15
3
0
0
21
1
0
2
14
0
0
62
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
2
1
0
0
0
0
0
1
1
1
0
6
TABLE V: Detection of permission uses for the 40 apps analyzed
by the participants in our usability study (ﬁrst and third party uses
combined). With 62 true positives and 6 false negatives the analysis
achieves a precision of 1 and recall of 0.91 for an F-1 score of 0.95.
Running these apps, analyzing their permission and library
uses (§ III-C2, § III-C3), and comparing them against the
results of PrivacyFlash Pro did not result in any discrepancy.
In addition, we asked the 40 participants in our usability
study if they had encountered any analysis errors when using
PrivacyFlash Pro. We also asked them to provide us with the
policy they generated so we could observe the results.9 Table V
shows the permission performance reported by the participants.
We ﬁnd it noteworthy that our signature-based code anal-
ysis does not produce any false positives, which could occur
due to unreachable code, for instance. The false negatives are
likely due to APIs not contained in our speciﬁcation. From
the feedback we received, this is at least true for 1 out of
the 6 false negatives, which was based on an older Swift
API. Another reason may be our categorization of evidence
items, e.g., there may be a few cases where an additional
evidence item should have been categorized as authorization
9The complete usability questionnaire is attached in Appendix B.
10
Fig. 7: Participants’ qualiﬁcations for developing Swift iOS apps.
Third Party Code
True Positives
False Positives
False Negatives
Libraries
Facebook Login
Google Login
525
9
6
0
0
0
1
2
3
TABLE VI: Detection of third party libraries, Facebook Login, and
Google Login.
method. The library detection performed well with just 1 false
negative. However, the false negative rates for Facebook and
Google Login implementations are higher with 2/11 (18%) and
3/9 (33%) instances (Table VI). Login detection goes beyond
identifying a library as it aims to reason about its functionality.
While we are following the same principles as for detecting
other API uses (§ IV-A2), there are many different ways for
integrating Facebook and Google Login. At least in 2 instances
the reported APIs were not included in our speciﬁcation. Thus,
performance could be improved by increasing the number of
APIs in the speciﬁcation possibly combined with a slight re-
categorization of evidence items.
2) Runtime Performance: We ran PrivacyFlash Pro on a
small (91MB) and a large (624MB) app. Running the analysis
5 times for each, we measure an average runtime of 13.6s for
the small and 46.3s for the large app on a 13-inch MacBook
Pro (2017) with 2.3GHz Intel Core i5 CPU and 8GB RAM.
3) Limitations: PrivacyFlash Pro’s code analysis may lead
to false positives and false negatives that the developer would
need to correct in the wizard. If left uncorrected, false pos-
itives would lead to over-disclosures and false negatives to
under-disclosures. It is the developer’s responsibility that the
privacy policy reﬂects the app’s practices correctly. Further,
PrivacyFlash Pro’s code analysis does not account for server-
side data sharing, which may require taint tracking. It also does
not take into account different library conﬁgurations.
V. EVALUATING PRIVACYFLASH PRO’S USABILITY
We performed a usability study of PrivacyFlash Pro with 40
iOS developers. After the participants had used PrivacyFlash
Pro, we asked them in an online survey whether they found it
helpful for policy creation as well as easy to use.
A. Participant Recruitment and Experience
We obtained our institution’s IRB approval and recruited
participants on the freelance platform Upwork [72], from
developer websites, such as the iOS programming community
on Reddit [57] and in person at iOSoho - New York City’s
largest iOS Engineer Meetup [34]. We asked the participants
Fig. 8: The different methods that participants used to create their
current privacy policy, if any.
to use PrivacyFlash Pro on an app they had written in Swift. We
also required that they have an app published on Apple’s App
Store for the US. To ensure that participants were proﬁcient
in developing iOS apps in Swift we checked their Upwork
proﬁles, especially, reviews of prior work in this area. For
participants outside of Upwork we asked them for the e-mail
address they use in their apps to verify that they are indeed
the developers and sent their compensation to this address.
To ensure that answers are reliable we included an attention
question in the survey. The System Usability Scale, which
is part of our survey (§ V-D1), contains a mix of positively
and negatively worded statements that also forces attentive-
ness [61]. We further required participants to submit the policy
they generated to ensure they actually used PrivacyFlash Pro.
We paid every participant $20.10 All participants were at least
18 years old; most ranging 20-29 (21) and 30-39 (14). 1
participant identiﬁed as female and 39 as male. Most were
full time developers and had Swift experience of 4-5 years
(Figure 7). 13 participants were from the US and 27 from
other countries.
B. Non-compliance of Current Policies
As Figure 8 shows, 10 out of the 40 participants in our
study were provided a policy for their app by their employer
or client (or did not know how the policy was created). 5
participants did not have a policy, which can happen as the
App Store only seems to require a policy link without Apple
enforcing that it actually leads to a policy. The remaining
participants created their policy themselves indicating a need
for a policy generation tool. 26 participants provided us with
their policy or a link to such. Upon examining those, many
policies do not sufﬁciently cover their apps.
We observed similar compliance issues as those discussed
for policies from questionnaire-based generators (§ III-C).
least one permission under-
15/26 (58%) policies have at
disclosure and 4/26 (15%) at
least one permission over-
disclosure. Library under-disclosures occur in 13/26 (50%) of
cases. 2/26 (8%) policies also exhibit library over-disclosures.
While 1 app was directed at children,
its policy was not
compliant with COPPA. These rates of compliance issues
10We increased the amount from $5 to $20 to motivate participation.
Participants who participated before the increase received an additional $15.
11
Fig. 9: For example, the participant with ID 40 at the top found
creating their current privacy policy relatively difﬁcult (2) and creating
a policy with PrivacyFlash Pro very easy (7). On the other hand,
the participant with ID 1 found the creation of their current policy
relatively easy (6) and using PrivacyFlash Pro actually more difﬁcult
(6-2=4).
are generally a bit higher than those for the policies from
questionnaire-based generators (§ III-C), which may well be
taken as an indicator that generators can principally help to
create compliant policies. Indeed, the policies that the partic-
ipants generated with PrivacyFlash Pro have better coverage
of their apps’ permission and library usages than their current
policies (§ IV-B1).
C. Easing the Policy Creation Process
Beyond ensuring that policies are compliant and have good
coverage, PrivacyFlash Pro is intended to ease the policy
creation process. Most participants expressed that privacy
policy creation became substantially easier with PrivacyFlash
Pro compared to their current method. When asked to rate
the level of difﬁculty for creating their current policy on a
scale of 1 (very difﬁcult) to 7 (very easy), the mean difﬁculty
across all participant responses converged to 4.675 and the
median difﬁculty to 4. For creating a privacy policy with
PrivacyFlash Pro, the mean increased by 1.875 to 6.55 and the
median by 3 to 7. Figure 9 shows the differences in ratings for
every individual participant. For 6 participants it was already
very easy (7) to create their current policy. However, for 31
participants PrivacyFlash Pro provided an improvement and,
except for participant 17, eased the difﬁculty to at least a level
of 6. A number of developers expressed, unprompted for, that
they were pleased with PrivacyFlash Pro and found it easy to
use. Appendix D contains the complete set of comments.
D. Usability Measurement Results
We analyzed the usability of PrivacyFlash Pro based on the
System Usability Scale (SUS) and Net Promoter Score (NPS).
1) System Usability Scale: The System Usability Scale is a
10-question scale for obtaining a global view of subjective as-
sessments of usability [18]. It covers a variety of aspects, such
as the need for technical support, training, and complexity,
and, thus, is considered to have a high level of face validity for
Fig. 10: The System Usability Scale results for PrivacyFlash Pro.
measuring usability of a system [18]. Each of the 10 questions
is answered based on a Likert scale ranging from 1 (strongly
disagree) to 5 (strongly agree). Then, the individual scores are
added. Questions with odd numbers are positively formulated
and contribute their score minus 1. Even-numbered questions
are negatively formulated and contribute 5 points minus their
score. Multiplying the sum of the scores by 2.5 puts each SUS
score in a range between 0 and 100. Thus, given a score, s,
of an individual question,
 4(cid:88)
5(cid:88)
 .
(1)
SU S = 2.5
(s2i+1 − 1) +
(5 − s2j)
i=0
j=1