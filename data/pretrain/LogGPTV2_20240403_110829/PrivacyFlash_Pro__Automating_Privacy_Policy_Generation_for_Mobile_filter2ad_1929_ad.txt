### Code and Third-Party Code Requirements

The code must include (1), and the third-party code must include (2) through (5). Additionally, (6) can be used as supplementary evidence in place of an authorization method, but only if an authorization method is already present in the first-party code. Since third parties do not have their own `Info.plist`, they reuse the first party’s. Similarly, third parties can reuse the first party’s authorization method, in which case additional evidence in the third-party code is required to demonstrate that the practice is actually used by the third party. Although it is unlikely, the first party can also reuse a third party’s authorization method, in which case the first-party code needs additional evidence. Figure 5 illustrates this concept. Generally, the evidence-based approach is also used to search for functionality within libraries, such as federated Facebook or Google Login.

### Detecting Libraries and Their Purposes

The code analysis distinguishes between first and third parties because various legal requirements depend on this distinction. For example, apps subject to CalOPPA must disclose whether third parties may collect personally identifiable information [CalOPPA, §22575(b)(6)]. Third-party libraries can use the same APIs as the app itself. Whether the libraries are written in Swift or Objective-C, all APIs remain visible in plaintext even when the libraries are compiled. Therefore, both source and compiled libraries can be analyzed.

PrivacyFlash Pro scans the project directory of an app, searching for specific SDKs, such as the `Google-Mobile-Ads-SDK`, which indicates the presence of Google’s AdMob library. In the iOS ecosystem, developers usually include libraries via package managers like CocoaPods [22] or Carthage [19]. Libraries are recognized based on the Pods and Carthage directories, as well as other framework resources from package managers used in the app. For instance, the name of a third-party library can be reliably identified from the `Podfile` if it was integrated via CocoaPods. The use of a package manager ensures that the library directory is present and named accordingly; otherwise, the build process for the app would fail. While third-party library identification relies on the use of a package manager and does not cover manually included libraries, our performance analysis indicates that only a small fraction of libraries might be missed (§ IV-B1).

The purpose of a permission use by a first party can be inferred from the `Plist` permission string. However, the purpose for a third-party use is usually not explicitly specified in the app or library code. Thus, the specification layer of PrivacyFlash Pro includes a third-party purpose specification. Currently, the specification contains the purposes for 300 popular third-party libraries identified on the analytics service Apptopia [10]. We aim to expand this specification with open-source contributions. The purpose categories we use so far (and the quantity of libraries) are: authentication (9), advertising (105), analytics (38), social network integration (31), payment processing (10), and developer support (107). Even if the purpose of a library is not included in the specification, the integration of the library will still be detected as long as it was done with a package manager. The developer can always specify the purpose manually in the questionnaire wizard.

### Questionnaire Wizard

Once the code analysis is complete, the developer is presented with a wizard to adjust any (un)detected practices. The wizard helps developers determine which laws are applicable to their apps and provides explanations of the law. Despite the significant impact different laws can have on what must be disclosed (Appendix A), existing generators often lack this feature. Implementation details for the policy, such as where it should be posted, and related topics, such as whether the developer is required to provide "Do Not Sell" functionality, are covered in tooltips. Once the developer has finalized the policy, it can be exported into an HTML page that can be readily posted on the developer’s website and made accessible as per CCPA Regs §999.308(a)(2)(d). Figure 6 shows a screenshot of the wizard with the AdColony library detected. Since making it available to the public, we have seen privacy policies created with PrivacyFlash Pro in the field (§ V-D3).

### PrivacyFlash Pro Performance

To test its practicability, we evaluated the code analysis and runtime performance of PrivacyFlash Pro.

#### Code Analysis Performance

We started by evaluating PrivacyFlash Pro on an app we created with 13 permissions and 5 libraries. Running PrivacyFlash Pro on this app resulted in a fully correct analysis. We also randomly selected 10 apps from the Collaborative List of Open-Source iOS Apps [27] and other public repositories, covering 18 permissions, at least one from each of the 13 permissions, and 45 unique libraries.

| Permission Category | True Positives | False Positives | False Negatives |
|---------------------|----------------|-----------------|-----------------|
| Bluetooth           | 2              | 0               | 2               |
| Calendars           | 4              | 0               | 1               |
| Camera              | 15             | 0               | 0               |
| Contacts            | 3              | 0               | 0               |
| Health              | 0              | 0               | 0               |
| HomeKit             | 0              | 0               | 0               |
| Location            | 21             | 0               | 0               |
| Microphone          | 1              | 0               | 0               |
| Motion & Fitness    | 0              | 0               | 0               |
| Media & Apple Music | 2              | 0               | 0               |
| Photos              | 14             | 0               | 0               |
| Reminders           | 0              | 0               | 0               |
| Speech Recognition  | 0              | 0               | 0               |
| **Sum**             | **62**         | **0**           | **6**           |

Table V: Detection of permission uses for the 40 apps analyzed by the participants in our usability study (first and third-party uses combined). With 62 true positives and 6 false negatives, the analysis achieves a precision of 1 and recall of 0.91, resulting in an F-1 score of 0.95.

Running these apps, analyzing their permission and library uses (§ III-C2, § III-C3), and comparing them against the results of PrivacyFlash Pro did not result in any discrepancies. Additionally, we asked the 40 participants in our usability study if they had encountered any analysis errors when using PrivacyFlash Pro. We also asked them to provide us with the policy they generated so we could observe the results. Table V shows the permission performance reported by the participants.

It is noteworthy that our signature-based code analysis does not produce any false positives, which could occur due to unreachable code, for instance. The false negatives are likely due to APIs not contained in our specification. From the feedback we received, this is at least true for 1 out of the 6 false negatives, which was based on an older Swift API. Another reason may be our categorization of evidence items, e.g., there may be a few cases where an additional evidence item should have been categorized as an authorization method. The library detection performed well with just 1 false negative. However, the false negative rates for Facebook and Google Login implementations are higher, with 2/11 (18%) and 3/9 (33%) instances (Table VI). Login detection goes beyond identifying a library as it aims to reason about its functionality. While we follow the same principles for detecting other API uses (§ IV-A2), there are many different ways to integrate Facebook and Google Login. At least in 2 instances, the reported APIs were not included in our specification. Thus, performance could be improved by increasing the number of APIs in the specification, possibly combined with a slight recategorization of evidence items.

| Third Party Code | True Positives | False Positives | False Negatives |
|------------------|----------------|-----------------|-----------------|
| Libraries        | 525            | 9               | 6               |
| Facebook Login   | 0              | 0               | 2               |
| Google Login     | 0              | 0               | 3               |

Table VI: Detection of third-party libraries, Facebook Login, and Google Login.

#### Runtime Performance

We ran PrivacyFlash Pro on a small (91MB) and a large (624MB) app. Running the analysis five times for each, we measured an average runtime of 13.6 seconds for the small app and 46.3 seconds for the large app on a 13-inch MacBook Pro (2017) with a 2.3GHz Intel Core i5 CPU and 8GB RAM.

#### Limitations

PrivacyFlash Pro’s code analysis may lead to false positives and false negatives that the developer would need to correct in the wizard. If left uncorrected, false positives would lead to over-disclosures, and false negatives to under-disclosures. It is the developer’s responsibility to ensure that the privacy policy reflects the app’s practices correctly. Furthermore, PrivacyFlash Pro’s code analysis does not account for server-side data sharing, which may require taint tracking. It also does not take into account different library configurations.

### Evaluating PrivacyFlash Pro’s Usability

We conducted a usability study of PrivacyFlash Pro with 40 iOS developers. After the participants had used PrivacyFlash Pro, we asked them in an online survey whether they found it helpful for policy creation and easy to use.

#### Participant Recruitment and Experience

We obtained our institution’s IRB approval and recruited participants on the freelance platform Upwork [72], from developer websites such as the iOS programming community on Reddit [57], and in person at iOSoho - New York City’s largest iOS Engineer Meetup [34]. We asked the participants to use PrivacyFlash Pro on an app they had written in Swift. We also required that they have an app published on Apple’s App Store for the US. To ensure that participants were proficient in developing iOS apps in Swift, we checked their Upwork profiles, especially reviews of prior work in this area. For participants outside of Upwork, we asked them for the email address they use in their apps to verify that they are indeed the developers and sent their compensation to this address. To ensure that answers are reliable, we included an attention question in the survey. The System Usability Scale, which is part of our survey (§ V-D1), contains a mix of positively and negatively worded statements that also force attentiveness [61]. We further required participants to submit the policy they generated to ensure they actually used PrivacyFlash Pro. We paid every participant $20. All participants were at least 18 years old; most ranged from 20-29 (21) and 30-39 (14). One participant identified as female, and 39 as male. Most were full-time developers and had Swift experience of 4-5 years (Figure 7). Thirteen participants were from the US, and 27 from other countries.

#### Non-compliance of Current Policies

As Figure 8 shows, 10 out of the 40 participants in our study were provided a policy for their app by their employer or client (or did not know how the policy was created). Five participants did not have a policy, which can happen as the App Store only seems to require a policy link without Apple enforcing that it actually leads to a policy. The remaining participants created their policy themselves, indicating a need for a policy generation tool. Twenty-six participants provided us with their policy or a link to such. Upon examining those, many policies do not sufficiently cover their apps. We observed similar compliance issues as those discussed for policies from questionnaire-based generators (§ III-C). At least one permission under-disclosure occurred in 15/26 (58%) policies, and 4/26 (15%) had at least one permission over-disclosure. Library under-disclosures occurred in 13/26 (50%) of cases, and 2/26 (8%) policies also exhibited library over-disclosures. While one app was directed at children, its policy was not compliant with COPPA. These rates of compliance issues are generally a bit higher than those for the policies from questionnaire-based generators (§ III-C), which may indicate that generators can help create compliant policies. Indeed, the policies that the participants generated with PrivacyFlash Pro have better coverage of their apps’ permission and library usages than their current policies (§ IV-B1).

#### Easing the Policy Creation Process

Beyond ensuring that policies are compliant and have good coverage, PrivacyFlash Pro is intended to ease the policy creation process. Most participants expressed that privacy policy creation became substantially easier with PrivacyFlash Pro compared to their current method. When asked to rate the level of difficulty for creating their current policy on a scale of 1 (very difficult) to 7 (very easy), the mean difficulty across all participant responses converged to 4.675, and the median difficulty to 4. For creating a privacy policy with PrivacyFlash Pro, the mean increased by 1.875 to 6.55, and the median by 3 to 7. Figure 9 shows the differences in ratings for every individual participant. For six participants, it was already very easy (7) to create their current policy. However, for 31 participants, PrivacyFlash Pro provided an improvement and, except for participant 17, eased the difficulty to at least a level of 6. A number of developers expressed, unprompted, that they were pleased with PrivacyFlash Pro and found it easy to use. Appendix D contains the complete set of comments.

#### Usability Measurement Results

We analyzed the usability of PrivacyFlash Pro based on the System Usability Scale (SUS) and Net Promoter Score (NPS).

##### System Usability Scale

The System Usability Scale is a 10-question scale for obtaining a global view of subjective assessments of usability [18]. It covers a variety of aspects, such as the need for technical support, training, and complexity, and is considered to have a high level of face validity for measuring usability of a system [18]. Each of the 10 questions is answered based on a Likert scale ranging from 1 (strongly disagree) to 5 (strongly agree). Then, the individual scores are added. Questions with odd numbers are positively formulated and contribute their score minus 1. Even-numbered questions are negatively formulated and contribute 5 points minus their score. Multiplying the sum of the scores by 2.5 puts each SUS score in a range between 0 and 100. Thus, given a score, \( s \), of an individual question,

\[
\text{SUS} = 2.5 \left( \sum_{i=0}^{4} (s_{2i+1} - 1) + \sum_{j=1}^{5} (5 - s_{2j}) \right)
\]

Figure 10 shows the System Usability Scale results for PrivacyFlash Pro.