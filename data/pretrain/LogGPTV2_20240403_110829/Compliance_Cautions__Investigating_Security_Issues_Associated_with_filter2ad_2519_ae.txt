help harden the overall environment. Like E1, E4 commented
that he was unable to assess CIP 007-6 only “if standard is fol-
lowed as written and nothing else,” as directed (Appendix B).
As such, E4 indicated that he rated each issue as less likely
given his broader understanding of the compliance framework.
The issue E4 rejected involves the loophole we identiﬁed
in Sections 2.1 and 2.2 for patch management. E4 stated that
“each item in the [system] baseline needs a source identiﬁed
or evidence that a source no longer exists.” In his experience,
he never encountered an external source that could provide a
trusted, proprietary patch. However, E4 acknowledged that if a
component is no longer supported or a source no longer exists,
it is highly likely that the component will remain unpatched
against all future publicly-disclosed vulnerabilities.
E4 conﬁrmed the log-retention issue we identiﬁed in Sec-
tion 4.3, attributing the known gap between log retention and
investigation windows to two factors. Primarily, the speciﬁca-
tion is written to account for the limited log retention capacity
on most devices within a BPS environment. Second, most
administrators and BPS owners are unwilling to connect to
and aggregate event logs on an external platform. Placing
an additional device within the environment (for logging)
increases the number of devices an attacker can exploit and
is one more device potentially subject to ﬁnancial sanctions.
E4 also conﬁrmed the risks of not specifying a responsible
party for tasks, a trend our researchers identiﬁed, and refer-
enced the aforementioned Duke Energy ﬁne as an example.
Additional defenses. E4 noted that the best additional defense
for mitigating the issues we identiﬁed was to upgrade system
components to more modern devices that can implement up-
to-date best practices (e.g., multi-factor authentication, strong
passwords, limiting login attempts. As with P1075 and PCI
DSS, organizations that only meet the minimum required by
the standard will not be able to take advantage of these
defenses. E4 conﬁrmed that while some facilities exceed
this “minimum baseline” and systematically replace obsolete
devices, he has also audited facilities that only follow the
standard exactly as written.
Other recommendations. E4 described additional security
concerns that our auditors did not identify. Subsets of NERC
CIP security controls apply to BPSs based on how much power
the system produces, creating three tiers of compliance: the
highest tier of power producers are subject to all security
controls, while the lower tiers of power producers must comply
11
with decreasing subsets. E4 believes this perversely allows
attackers to use publicly-available information to locate fa-
cilities that must adhere to fewer security controls and then
systematically target the controls that may not be present. E4
therefore argues that NERC must standardize controls across
all facilities to mitigate the targeting of smaller stations.
Additionally, E4 stated that the zero-defect culture and high
ﬁnes associated with NERC’s sanctions program can incen-
tivize minimum-effort security. Organizations that undertake
additional security precautions beyond NERC CIP mandates
may discover vulnerabilities that would not otherwise be
identiﬁed. NERC levies ﬁnes for non-compliance even when
organizations self-report such vulnerabilities, potentially pun-
ishing organizations for transparency. E4 believes this behavior
inhibits sharing of information across the power sector and
collectively lowers security for all facilities. He argues that
NERC could reverse this trend by eliminating ﬁnes associated
with self-reporting and providing “credits” to organizations
that contribute to the overall health of the power sector.
When discussing concerns with log retention, E4 recom-
mended that all facilities should contribute toward a common
log aggregation center, where security professionals could
conduct in-depth security-breach investigations spanning all
NERC-compliant facilities.
VII. REPORTING
We made an effort to disclose our ﬁndings responsibly.
Compliance standards typically have a request-for-comment
(RFC) period that allows for the submission of comments,
concerns, and recommendations during a ﬁxed window. During
this study, none of the standards we assessed had an open
RFC, and we found that no clearly deﬁned channel existed
for reporting security concerns, either directly to affected
organizations or at the federal level. Using our partners as
mediators, we turned over all of our ﬁndings to the IRS; the
PCI Security Standards Council; a contributing author of the
NERC CIP standards (E4); the United States Computer Emer-
gency Readiness Team (US-CERT); the MITRE Corporation’s
Common Vulnerabilities and Exposures (CVE) team; and the
Department of Homeland Security. We had varying levels of
success with these disclosures, as described below.
IRS P1075. We contacted the IRS, NIST National Vulner-
ability Database (NVD), US-CERT, and the MITRE Cor-
poration to disclose our P1075 ﬁndings. US-CERT was the
ﬁrst organization to respond to our disclosure attempt; their
technicians concluded that “CVEs are assigned for speciﬁc
vulnerability in implementations. Each issue that requires a
‘separate patch’ can get a CVE [58].” We argued that each
of the recommendations we provided are “patches” for the
vulnerable portions of the compliance standards, but US-CERT
stated that
the “patches” we identiﬁed must be tied to a
speciﬁc piece of software. Both NIST NVD and the MITRE
Corporation indicated that compliance documents are outside
their scope of responsibility, with MITRE stating “that a
reasonable person can conclude that IRS Publication 1075 was
never intended to have a level of abstraction that was sufﬁcient
to direct secure coding [36].” Contradicting this argument, our
partners at NYC3 conﬁrmed that auditors are indeed using
P1075 as a line-by-line checklist to conﬁrm controls at levels
as granular as access control lists on ﬁrewalls.
Document
Controls
Total
Issues
Extr.
High
High Moderate
Low
IRS
PCI
NERC
309
851
79
81
46
21
2
0
1
13
8
4
32
22
6
34
16
10
TABLE II: Security concerns, by document and assessed risk
We attempted to disclose our ﬁndings directly to the IRS
nine times via personal contacts, emails, and phone calls over
the span of three months. To date, we have not received any
form of acknowledgment other than the automated responses.
PCI DSS. Unlike P1075, we had success in responsibly
disclosing our ﬁndings to members of the PCI SSC. We
established a memorandum of understanding with a PCI SSC
member organization; in turn, this organization provided our
ﬁndings to the PCI DSS v4 Working Group.
We received notiﬁcation that our recommendation for im-
proving the “Network Segmentation” section of PCI DSS
has already been implemented within Version 4, prior to the
opening of their RFC submission window. This change will
apply PCI DSS guidelines to the entire networked environment
and not only an isolated subnet with cardholder data. Addi-
tionally, the v4 Working Group is considering incorporating all
feedback associated with our ambiguous speciﬁcation ﬁndings.
NERC CIP 007-6. Expert E4, after providing feedback, noted
that our recommendations would be included at future working
groups for CIP revisions. However, it will be years before the
next CIP update (potentially taking our recommendations into
account) is released. Additionally, our partnered organization
for CIP disclosure is incorporating our feedback into a com-
prehensive evaluation of electric grid security.
Federal-level recognition. To approach problems with federal-
level compliance standards in a top-down manner, we met
with representatives from the NIST National Cybersecurity
Center of Excellence (NCCoE) to discuss our ﬁndings [38].
We highlighted that IRS P1075 Section 9 (which contains 49%
of the P1075 security concerns we discovered) is copied from
older versions of NIST SP 800-53 (NIST has since updated
SP 800-53 twice). NCCoE offered to incorporate our ﬁndings
into future document revisions. In ongoing revisions that began
before our meeting, NIST acknowledged in draft SP 800-53v5
that organizations may inherit risk when implementing man-
dated security controls; that is, standards may create security
problems [43]. Speciﬁcally, NIST describes deliberate efforts
to remove ambiguity, improve understanding of responsibility,
and keep controls up to date, corroborating many ﬁndings from
our study.
Next, we contacted the Department of Homeland Security
(DHS) National Protection and Programs Directorate. Several
personnel within the Federal Network Resilience Division
expressed interest
in assisting with our ﬁndings; however,
the DHS Ofﬁce of External Affairs for Cybersecurity and
Communications directed our contacts to cease communication
and did not provide any alternative mechanisms for disclosure.
12
VIII. DISCUSSION AND CONCLUSION
We provide the ﬁrst structured evaluation of security issues
within digital-security compliance standards. In our study,
we ﬁnd that using compliance standards as checklists, with
“by-the-letter” implementation of security controls, can create
security concerns. Our systematic approach identiﬁed security
issues spanning multiple root causes and varying levels of risk
(shown in Table II). In this section, we discuss common issues
across the audited compliance standards, potential mitigations,
recommendations for reconsidering compliance programs, and
opportunities for future work.
Common issues. When considering our ﬁndings, some com-
mon issues become apparent. All standards we assessed exhibit
under-deﬁned processes and vague writing. While issues of
vague writing may not seem as immediately dangerous as,
for example, failing to identify passwords as sensitive data
requiring protection, they have important implications when
standards are treated like point-by-point checklists.
Many issues stem from passive voice, creating ambiguity
concerning who is responsible for exactly what actions. Using
the active voice to construct compliance controls is a best
practice that helps eliminate uncertainty and ensure there is a
responsible party for requisite actions [30]. If it is not feasible
to eliminate passive voice (perhaps because it would prescribe
organizational structure too strongly), standards authors could
perhaps include supplemental best-practice recommendations
for identifying responsible personnel. In addition, the standard
might require each implementing organization to create a writ-
ten plan identifying who is responsible for each requirement.
Further, we observed that numerous compliance controls
did not have clear deadlines for action. Compliance standards
should deﬁne expected periodicity (e.g., every 30 days) or
thresholds for action (e.g., within 12 hours of an event). These
issues with deadlines seem especially concerning in light of
observations by several auditors we spoke with that many
problems are only mitigated during an immediate run-up to
a compliance audit, as part of preparations to pass.
in some cases,
Terms such as “when feasible” and optional guidelines
create confusion about what
is actually required and may
provide an illusion of more security than what is actually
provided. We recognize that
this wording
reﬂects practical
limitations: for example, updating legacy
power systems to include modern security controls (NERC
CIP) could require multi-million-dollar equipment investments
and degrade near-term power availability. Nonetheless, we
argue that categorizing clearly insecure systems as “compliant”
simply because there is no feasible alternative is counterpro-
ductive. Instead, compliance standards could adopt a third
category that does not punish the affected organization but
still indicates clearly to administrators and auditors that the
situation is suboptimal and further precautions are needed. We
also recommend, for clarity, moving optional guidelines into
supplemental documents separate from mandatory compliance.
We also noted that each compliance standard has weak
controls for user-access review and revocation procedures. To
mitigate insider threats, compliance standards could mandate
frequent review of active user accounts, as well as access
termination before formally notifying an employee who is
terminated.
Lastly, and perhaps most concerning, none of the com-
pliance standards we assessed have mechanisms for reporting
security concerns. Without a direct line of communication
with a governing body, it is likely many discovered security
concerns will remain unaddressed. The lack of a centralized
CVE database-like construct for reporting problems with com-
pliance standards affects both governing bodies and compliant
organizations. Governing bodies do not have a reference for
common mistakes when developing compliance standards,
meaning issues are likely to repeat across multiple standards.
Additionally, this lack of transparency prevents industry-wide
alert notiﬁcations for issues within a compliance standard; if
a researcher discovers a valid security concern, all affected
parties should be notiﬁed. Further, no standard could be
expected to perfectly capture all needed security controls; as
several of our experts noted, strong security practices often
require going beyond the minimum established by a standard.
A centralized repository would also present an opportunity to
recommend additional best practices to build upon compliance
and mitigate any reported gaps.
Recommendations. Our work highlights difﬁculties than can
arise when compliance standards are used as checklists, re-
gardless of their original intent. This approach seems inevitable
when a standard is associated with potentially large penalties
for non-compliance, but little or no incentive for going beyond
the minimum requirements. This state of affairs suggests a
need for rethinking the compliance paradigm more broadly.
First, authors of compliance standards should take into
consideration that their standards might be used as an audit
checklist. Whenever possible, guidelines should be broadly
applicable across a particular domain but concrete enough
that line-by-line compliance will provide meaningful security.
Of course, writing guidelines that achieve this ideal is dif-
ﬁcult and may sometimes be impossible; standards authors
should explicitly consider tradeoffs between generalizability
and secure implementation when making choices. Providing
supplemental documents describing potential such issues could
help standards implementers manage resulting risks.
Secondly, authors should identify opportunities to craft
compliance standards that improve audits beyond checklist
assessments and consider an organization’s overall security
culture. Provisions for a rewards program could incentivize
organizations to bolster security. As examples, organizations
that take proactive measures beyond minimum requirements
or organizations that publish digital security lessons learned
could receive some limited safe harbor against future sanctions.
As discussed during our audit of NERC CIP standards, an
organization that responsibly discloses and remedies a vulner-
able condition is still liable for ﬁnancial sanctions. Allowing
organizations to self-report issues with less fear of sanctions
could incentivize better behavior and increase transparency,
with potential beneﬁts for the entire associated sector [5].
Another consideration for standards authors is that rapidly
changing technology necessitates rapidly updated security
mechanisms. An effective standards update mechanism should
allow easy reporting of issues and enable fast revision of the
standard itself, while avoiding imposing costs on organizations
that cannot immediately meet the new requirement. Newly
updated standards could provide suggestions for transitioning
13
and require organizations to provide a plan for becoming
compliant with the updated requirement within some speciﬁed
time period.
Future work. To validate the issues we identiﬁed, we devel-
oped close collaborations with organizations that implement
compliance standards and conduct associated audits. Future
work should investigate how standards organizations generate