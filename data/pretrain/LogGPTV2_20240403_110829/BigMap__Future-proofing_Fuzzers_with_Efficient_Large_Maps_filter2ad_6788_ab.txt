coverage of a test case with the help of the instrumented
target. The exact execution path is not tracked. Instead,
a coarse-grained edge hit count is used as the coverage
metric [13]. The edges are identiﬁed as a hash of the
(source block, destination block) tuple. Listing 1 shows the
necessary steps.
1 BX , BY = random % MAP SIZE 
2 EXY = (BX >> 1) ⊕ BY
3
c o v e r a g e b i t m a p [ EXY ]++
Listing 1: Instrumentation capturing the hit counts of EXY .
Here MAP SIZE is the size of the coverage bitmap. BX
and BY are the source and the destination basic block IDs,
respectively. EXY is the ID corresponding to the X → Y
edge. Basic block IDs are assigned at compile time following
a discrete uniform distribution over the [0..MAP SIZE)
range. On the other hand, edge IDs are calculated at runtime
and also falls within [0..MAP SIZE). The shift operation
in the edge ID calculation makes it possible to preserve
the directionality of the edges (e.g., EXY (cid:3)= EY X). It
also helps in properly identifying distinct tight loops (e.g.,
EXX (cid:3)= EY Y (cid:3)= 0). AFL sports an alternative technique for
getting edge IDs that leverages the trace-pc-guard coverage
sanitizer of the Clang compiler [18]. In this method, the
Clang compiler itself instruments static edges without any
need to instrument at the basic block level. Unfortunately,
this method cannot detect indirect edges as the target basic
block information is unavailable at compile time.
Irrespective of how the edge IDs are generated, they act
as an index to the coverage bitmap. The corresponding byte
at that index stores the desired statistics (e.g., hit count for
vanilla AFL) of that particular edge. The following steps are
performed to collect the coverage of individual test cases:
• Bitmap reset: The coverage bitmap is a shared data
structure and is used by all the test cases. Thus, before
executing a test case, the coverage bitmap is cleared to
remove any artifact of previous runs. A simple memset
to zero does this job.
• Bitmap update: The instrumented target executes the
test case and records the edge hit counts on the bitmap.
• Bitmap classify: The exact hit counts are converted
to coarse hit counts by mapping them into buckets.
The buckets used by AFL are: [1], [2], [3], [4-7], [8-
15], [16-31], [32-127], [128,∞]. Hit counts that fall
into different buckets are considered as an interesting
change in the control ﬂow. Change within the same
bucket is ignored. Bucketing also mitigates the impact
of accidental hash collisions.
• Bitmap compare: After the classify step, the modiﬁed
bitmap is compared with a global coverage bitmap that
keeps track of all the edges covered so far. Newly dis-
covered edges, if any, are added to the global coverage
map at this point. If the test case crashes/hangs instead,
it is compared to a global crash/hang coverage bitmap.
• Bitmap hash: If the test case is considered interesting,
a hash of the bitmap is calculated and saved for rapid
comparison in the future.
Since these bitmap operations are performed for every
test case (expect bitmap hash, which is performed for every
interesting test case), it is crucial to minimize the time spent
on these operations. One way to facilitate faster bitmap
operations is to keep the bitmap size small. This limitation
on map size leads to a high number of hash collisions.
As stated earlier, collisions introduce ambiguity in coverage
feedback and may result in discarding interesting test cases.
This paper’s primary objective is to enable large coverage
bitmaps (thus reducing hash collisions) without incurring
associated runtime overhead.
B. Collision Rate
In our work, the severity of the hash collision is quantiﬁed
using the collision rate metric. Consider drawing n keys
from a hash space of size H. Among the n draws, if c
number of key matches with one of the previously drawn
keys, then the collision rate is deﬁned as c/n (where c < n).
If the key draw follows a discrete uniform distribution, then
the collision rate can be expressed using Equation 1.
(cid:2)
(cid:3)
(cid:4)n(cid:5)
H − 1
H
CollisionRate(H, n) = 1 − H
n
1 −
(1)
Equation 1 is consistent with how AFL generates the
block and edge IDs. Here, the hash space size H is analo-
gous to the coverage bitmap size, and the number of drawn
keys n is equivalent to the number of generated IDs.
Note that the collision rate does not indicate the actual
number of keys with collision. Consider an example where
the following keys are sequentially drawn: {4, 2, 5, 3, 2}.
Here, the collision rate is 1/5 and not 2/5. Although the
given collision rate deﬁnition does not account for all the
colliding keys, we have used it to remain consistent with the
existing literature [9], [13].
III. IMPLICATION OF NA¨IVE HASH COLLISION
MITIGATION STRATEGY
Hash collisions can be completely avoided by assigning
unique IDs to every discoverable edge. Otherwise, traversing
two (or more) different edges will update the same location
in the coverage bitmap. Unfortunately, assigning unique IDs
may not always be possible. AFL’s default bitmap size is
64kB, where each byte stores the statistics of an edge. Thus,
even in the best scenario, at most 64k edges can be assigned
with different IDs. Any more than that, and collision will
the
be unavoidable. The birthday problem suggests that
Authorized licensed use limited to: Tsinghua University. Downloaded on October 11,2021 at 09:23:42 UTC from IEEE Xplore.  Restrictions apply. 
533
(cid:12)
(cid:8)
(cid:11)
(cid:72)
(cid:87)
(cid:68)
(cid:53)
(cid:81)
(cid:82)
(cid:76)
(cid:86)
(cid:76)
(cid:79)
(cid:79)
(cid:82)
(cid:38)
(cid:20)(cid:19)(cid:19)
(cid:28)(cid:19)
(cid:27)(cid:19)
(cid:26)(cid:19)
(cid:25)(cid:19)
(cid:24)(cid:19)
(cid:23)(cid:19)
(cid:22)(cid:19)
(cid:21)(cid:19)
(cid:20)(cid:19)
(cid:19)
(cid:49)(cid:82)(cid:17) (cid:82)(cid:73) (cid:78)(cid:72)(cid:92)(cid:86)
(cid:24)(cid:78)
(cid:20)(cid:19)(cid:78)
(cid:21)(cid:19)(cid:78)
(cid:24)(cid:19)(cid:78)
(cid:20)(cid:19)(cid:19)(cid:78)
(cid:21)(cid:19)(cid:19)(cid:78)
(cid:24)(cid:19)(cid:19)(cid:78)
(cid:20)(cid:48)
(cid:25)(cid:23)(cid:78) (cid:20)(cid:21)(cid:27)(cid:78) (cid:21)(cid:24)(cid:25)(cid:78) (cid:24)(cid:20)(cid:21)(cid:78)
(cid:20)(cid:48)
(cid:21)(cid:48)
(cid:37)(cid:76)(cid:87)(cid:80)(cid:68)(cid:83) (cid:54)(cid:76)(cid:93)(cid:72)
(cid:23)(cid:48)
(cid:27)(cid:48) (cid:20)(cid:25)(cid:48) (cid:22)(cid:21)(cid:48)
3
2.5
2
1.5
1
0.5
0
)
s
r
u
o
h
(
e
m
T
i
Execution
Map Classify
Map Compare
Map Reset
Map Hash
Others
64k 2M 8M 64k 2M 8M 64k 2M 8M 64k 2M 8M 64k 2M 8M 64k 2M 8M
libpng
sqlite3
gvn
bloaty
openssl
php
Figure 2: Hash collision rate drops as bitmap size is in-
creased (derived from Equation 1).
Figure 3: Runtime composition with varying bitmap sizes.
Map operations dominate the runtime for bigger maps. The
reported time is for one million test case generation.
collision is likely to occur with signiﬁcantly less than 64k
edges [19]. Assuming a uniform distribution of the edge IDs
within the 64kB bitmap range, the probability of having at
least one collision is ∼50% after assigning only 300 IDs.
Similar to edge IDs, block IDs are also randomly gener-
ated within the [0..MAP SIZE) range (Listing 1). Thus, it
is quite possible to have more than one basic block with the
same ID. Edges originating from or entering these colliding
blocks will point to ambiguous locations in the coverage
bitmap. Bucketing the hit counts provides some protection
against such accidental hash collisions. Having too many
collisions still severely limits the fuzzer’s ability to guide its
fuzzing process by providing incorrect coverage feedback.
The straightforward way of reducing hash collisions is to
expand the hash space (i.e., use a larger bitmap). Figure 2
shows the collision rates with different bitmap sizes and the
number of keys drawn (derived from Equation 1). The keys
here are analogous to the discoverable edges and blocks. For
real-world applications, the number of discoverable edges
usually ranges from 1k to 50k. As a result, a 64kB map
is subjected to ∼30% collision rate. Using more thorough
coverage metrics like full/partial path coverage [12], context-
sensitive edge coverage [17], or branch condition trans-
formations [11] can make the required number of IDs go
well over 500k. These techniques can be stacked, further
increasing the collision rate. We need a much larger map
than 64kB if we want to explore these techniques without
worrying about hash collisions.
A. Cost of Expanding Hash-space
The bitmap should be much larger than the number of
required IDs to keep the collision rate in check. Unfortu-
nately, increasing bitmap size also increases the runtime
overhead of the bitmap operations. Figure 3 shows the
runtime composition for six benchmarks with 64kB, 2MB,
and 8MB bitmap sizes. For the small 64kB map, the fuzz
target’s execution time dominates the overall runtime. The
costs of bitmap operations are negligible at this point. On
the other hand, the runtime is dominated by the bitmap
operations for the larger 8MB map. The classify, compare,
and reset operations require iterating through the full bitmap
for every test case. As a result, they are impacted most
by the increase in bitmap size. Bitmap hash operation also
needs to go through the full bitmap but is only performed
on the interesting test cases. Therefore, the overhead of hash
operation varies considerably depending on the benchmark.
There are a few other bitmap operations not shown in this
ﬁgure, simply because they are too infrequent to have any
perceivable impact on the runtime.
IV. BIGMAP: ADAPTIVE TWO-LEVEL BITMAP
In the AFL’s data structure for coverage tracking, the keys
are randomly distributed throughout the bitmap. Figure 4(a)
shows an example where the edge ID EXY is used as the
key to access the coverage map. In this example, only ﬁve of
the twelve locations are modiﬁed. However, since there is no
information on exactly where these modiﬁed locations are,
the bitmap operations like reset, classify, compare, etc., have
to traverse the complete map. We propose the use of a two-
level bitmap scheme to consolidate these scattered accesses.
A. Two-Level Bitmap Scheme
In our proposed scheme,
the consolidation process is
carried out during the bitmap update phase by maintaining
three data structures:
i) A coverage bitmap that holds
ii) An used key that points to
the coverage statistics.
the next available space in the coverage bitmap. iii) An
index bitmap that maps an edge ID to a location in the
coverage bitmap. Figure 4(b) demonstrates the update steps.
First, we query index bitmap[EXY ] to get the location of
the stored hit count. If the edge is encountered for the ﬁrst
Authorized licensed use limited to: Tsinghua University. Downloaded on October 11,2021 at 09:23:42 UTC from IEEE Xplore.  Restrictions apply. 
534
coverage
bitmap
index
bitmap
coverage
bitmap
EXY = 8
0 34 0
[6]
[4]
[4]
[6]
[5]
[5]
0 19 13 0
[3]
[0]
[8]
[3]
[0]
[8]
(a) AFL’s bitmap update
0 27 0
[9]
[7]
[7]
[9]
[2]
[2]
[1]
[1]
0
[10]
[10]
0 51
[11]
[12]
[12]
[11]
EXY = 8
-1
0
1
-1 -1
4
-1 -1
19 13 27 51 34 0
[5]
[0]
[0]
[5]
[1]
[1]
[3]
[3]
[4]
[4]
[2]
[2]
0
[6]
[6]
0
[7]
[7]
2
KXY = 2
0
0
[9]
[8]
[9]
[8]
-1 -1 -1
3
0
[10]
[10]
0
[11]
[11]
0
[12]
[12]
used_key = 5
(b) BigMap’s two-level bitmap update
Figure 4: Steps of bitmap update operation for AFL’s
and BigMap’s data structure. The hit counts in the cover-
age bitmap are scattered in (a), while consolidated in (b).
time, we will get an invalid location (-1 in our implemen-
tation). In this case, the index bitmap[EXY ] is assigned
to the next available location in the coverage bitmap (=
used key). Once we have the location, the hit count in the
coverage bitmap is incremented.
As depicted in Figure 4, BigMap’s scheme makes the
coverage statistics contained within the ﬁrst used key lo-
cations, unlike AFL. Therefore, all the bitmap operations
(except bitmap update) need to iterate over the [0..used key)
range instead of the full bitmap. As a result, the runtime
of the map operations will depend on how many edges
are discovered instead of how big the coverage bitmap
is. An interesting aspect of this solution is its adaptive
nature, where the default bitmap size can be arbitrarily large
irrespective of the target application’s size. Applications with
a large number of discoverable edges will beneﬁt from hash
collision mitigation, and applications with few discoverable
edges will not incur any signiﬁcant overhead despite having
large map structures. This ﬂexibility helps in situations when
it’s difﬁcult to assess the optimal map size in advance.
B. Illustrative Example
Figure 5 shows a step by step example of how the map
operations are performed. We will focus on BigMap and will
contrast it with AFL towards the end of this section.
At the beginning of the fuzzing session, BigMap initial-
izes the index bitmap to -1, indicating none of the edges are
assigned any location yet. The hit counts in coverage bitmap
are also set
to zero. This initialization is performed a
single time during the whole fuzzing campaign, and it is
the only time BigMap accesses the full bitmaps. At this
point, the index bitmap and the coverage bitmap are ready
to capture the test case’s coverage information. The used
portion (none for the ﬁrst run) of the coverage bitmap is
reset before each test is executed. During execution, the
index bitmap is updated as new edges are being discovered.