### Coverage of a Test Case with the Help of an Instrumented Target

The exact execution path is not tracked. Instead, a coarse-grained edge hit count is used as the coverage metric [13]. The edges are identified by a hash of the (source block, destination block) tuple. Listing 1 shows the necessary steps.

**Listing 1: Instrumentation Capturing the Hit Counts of EXY**

```python
1 BX, BY = random % MAP_SIZE 
2 EXY = (BX >> 1) ^ BY
3 coverage_bitmap[EXY]++
```

- **MAP_SIZE**: The size of the coverage bitmap.
- **BX and BY**: Source and destination basic block IDs, respectively.
- **EXY**: The ID corresponding to the X → Y edge.
- **Basic Block IDs**: Assigned at compile time following a discrete uniform distribution over the [0..MAP_SIZE) range.
- **Edge IDs**: Calculated at runtime and also fall within [0..MAP_SIZE).

The shift operation in the edge ID calculation ensures the directionality of the edges (e.g., EXY ≠ EYX) and helps in identifying distinct tight loops (e.g., EXX ≠ EYY ≠ 0). AFL uses an alternative technique for getting edge IDs that leverages the trace-pc-guard coverage sanitizer of the Clang compiler [18]. This method instruments static edges without needing to instrument at the basic block level. However, it cannot detect indirect edges because the target basic block information is unavailable at compile time.

### Edge IDs and Coverage Bitmap

Regardless of how edge IDs are generated, they act as indices to the coverage bitmap. The corresponding byte at that index stores the desired statistics (e.g., hit count for vanilla AFL) for that particular edge. The following steps are performed to collect the coverage of individual test cases:

1. **Bitmap Reset**: The coverage bitmap is a shared data structure used by all test cases. Before executing a test case, the coverage bitmap is cleared to remove any artifacts from previous runs. A simple `memset` to zero accomplishes this.

2. **Bitmap Update**: The instrumented target executes the test case and records the edge hit counts on the bitmap.

3. **Bitmap Classify**: The exact hit counts are converted to coarse hit counts by mapping them into buckets. The buckets used by AFL are: [1], [2], [3], [4-7], [8-15], [16-31], [32-127], [128,∞]. Hit counts falling into different buckets are considered interesting changes in the control flow. Changes within the same bucket are ignored. Bucketing also mitigates the impact of accidental hash collisions.

4. **Bitmap Compare**: After classification, the modified bitmap is compared with a global coverage bitmap that tracks all edges covered so far. Newly discovered edges are added to the global coverage map at this point. If the test case crashes or hangs, it is compared to a global crash/hang coverage bitmap.

5. **Bitmap Hash**: If the test case is considered interesting, a hash of the bitmap is calculated and saved for rapid comparison in the future.

Since these bitmap operations are performed for every test case (except for the bitmap hash, which is performed for every interesting test case), it is crucial to minimize the time spent on these operations. One way to facilitate faster bitmap operations is to keep the bitmap size small. However, this leads to a high number of hash collisions, which can introduce ambiguity in coverage feedback and may result in discarding interesting test cases.

### Collision Rate

In our work, the severity of hash collisions is quantified using the collision rate metric. Consider drawing \( n \) keys from a hash space of size \( H \). Among the \( n \) draws, if \( c \) number of keys match one of the previously drawn keys, then the collision rate is defined as \( \frac{c}{n} \) (where \( c < n \)). If the key draw follows a discrete uniform distribution, the collision rate can be expressed using Equation 1.

\[ \text{CollisionRate}(H, n) = 1 - \left( \frac{H-1}{H} \right)^n \]

This equation is consistent with how AFL generates block and edge IDs. Here, the hash space size \( H \) is analogous to the coverage bitmap size, and the number of drawn keys \( n \) is equivalent to the number of generated IDs.

Note that the collision rate does not indicate the actual number of keys with collisions. For example, if the following keys are sequentially drawn: {4, 2, 5, 3, 2}, the collision rate is \( \frac{1}{5} \) and not \( \frac{2}{5} \). Although this definition does not account for all colliding keys, it remains consistent with existing literature [9], [13].

### Implications of Naive Hash Collision Mitigation Strategy

Hash collisions can be completely avoided by assigning unique IDs to every discoverable edge. Otherwise, traversing two (or more) different edges will update the same location in the coverage bitmap. Unfortunately, assigning unique IDs may not always be possible. AFL’s default bitmap size is 64kB, where each byte stores the statistics of an edge. Thus, even in the best scenario, at most 64k edges can be assigned with different IDs. Any more than that, and collisions will be unavoidable.

The birthday problem suggests that collision is likely to occur with significantly fewer than 64k edges [19]. Assuming a uniform distribution of edge IDs within the 64kB bitmap range, the probability of having at least one collision is approximately 50% after assigning only 300 IDs. Similar to edge IDs, block IDs are also randomly generated within the [0..MAP SIZE) range (Listing 1). Thus, it is quite possible to have more than one basic block with the same ID. Edges originating from or entering these colliding blocks will point to ambiguous locations in the coverage bitmap. Bucketing the hit counts provides some protection against such accidental hash collisions. Having too many collisions severely limits the fuzzer’s ability to guide its fuzzing process by providing incorrect coverage feedback.

The straightforward way of reducing hash collisions is to expand the hash space (i.e., use a larger bitmap). Figure 2 shows the collision rates with different bitmap sizes and the number of keys drawn (derived from Equation 1). The keys here are analogous to the discoverable edges and blocks. For real-world applications, the number of discoverable edges usually ranges from 1k to 50k. As a result, a 64kB map is subjected to approximately 30% collision rate. Using more thorough coverage metrics like full/partial path coverage [12], context-sensitive edge coverage [17], or branch condition transformations [11] can make the required number of IDs go well over 500k. These techniques can be stacked, further increasing the collision rate. We need a much larger map than 64kB if we want to explore these techniques without worrying about hash collisions.

### Cost of Expanding Hash Space

The bitmap should be much larger than the number of required IDs to keep the collision rate in check. Unfortunately, increasing the bitmap size also increases the runtime overhead of the bitmap operations. Figure 3 shows the runtime composition for six benchmarks with 64kB, 2MB, and 8MB bitmap sizes. For the small 64kB map, the fuzz target’s execution time dominates the overall runtime, and the costs of bitmap operations are negligible. On the other hand, the runtime is dominated by the bitmap operations for the larger 8MB map. The classify, compare, and reset operations require iterating through the full bitmap for every test case, making them the most impacted by the increase in bitmap size. The bitmap hash operation also needs to go through the full bitmap but is only performed on interesting test cases, leading to varying overhead depending on the benchmark.

### BigMap: Adaptive Two-Level Bitmap

In AFL’s data structure for coverage tracking, the keys are randomly distributed throughout the bitmap. Figure 4(a) shows an example where the edge ID EXY is used as the key to access the coverage map. In this example, only five of the twelve locations are modified. However, since there is no information on exactly where these modified locations are, the bitmap operations like reset, classify, compare, etc., have to traverse the complete map. We propose the use of a two-level bitmap scheme to consolidate these scattered accesses.

#### Two-Level Bitmap Scheme

In our proposed scheme, the consolidation process is carried out during the bitmap update phase by maintaining three data structures:
1. **Coverage Bitmap**: Holds the coverage statistics.
2. **Used Key**: Points to the next available space in the coverage bitmap.
3. **Index Bitmap**: Maps an edge ID to a location in the coverage bitmap. 

Figure 4(b) demonstrates the update steps:
1. Query the index bitmap[EXY] to get the location of the stored hit count.
2. If the edge is encountered for the first time, the index bitmap[EXY] is assigned to the next available location in the coverage bitmap (used_key).
3. Once the location is obtained, the hit count in the coverage bitmap is incremented.

As depicted in Figure 4, BigMap’s scheme consolidates the coverage statistics within the first used_key locations, unlike AFL. Therefore, all the bitmap operations (except bitmap update) need to iterate over the [0..used_key) range instead of the full bitmap. This makes the runtime of the map operations dependent on the number of discovered edges rather than the size of the coverage bitmap. An interesting aspect of this solution is its adaptive nature, where the default bitmap size can be arbitrarily large regardless of the target application’s size. Applications with a large number of discoverable edges will benefit from hash collision mitigation, and applications with few discoverable edges will not incur significant overhead despite having large map structures. This flexibility helps in situations when it is difficult to assess the optimal map size in advance.

#### Illustrative Example

Figure 5 shows a step-by-step example of how the map operations are performed. We will focus on BigMap and contrast it with AFL towards the end of this section.

At the beginning of the fuzzing session, BigMap initializes the index bitmap to -1, indicating none of the edges are assigned any location yet. The hit counts in the coverage bitmap are also set to zero. This initialization is performed once during the whole fuzzing campaign, and it is the only time BigMap accesses the full bitmaps. At this point, the index bitmap and the coverage bitmap are ready to capture the test case’s coverage information. The used portion (none for the first run) of the coverage bitmap is reset before each test is executed. During execution, the index bitmap is updated as new edges are being discovered.