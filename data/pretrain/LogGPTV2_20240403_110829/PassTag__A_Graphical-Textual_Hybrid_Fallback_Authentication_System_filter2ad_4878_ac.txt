101
60
33
105
11
8
4
(62.7%)
(37.3%)
(20.5%)
(65.2%)
(6.8%)
(5.0%)
(2.5%)
6 STUDY 1: CLOSE ADVERSARY GUESSING
ON PASSTAG VS. RANDOMTAG
We first conducted a between-subject user study to test our hy-
pothesis that it would be much more difficult for close adversaries
to correctly guess secrets when similar images are used as decoy
images than when random images are used as decoy images. We
designed another fallback authentication system RandomTag with
mostly identical functionalities as PassTag. However, RandomTag
displayed random decoy images instead of similar decoy images
during the authentication process. Participants were required to en-
roll into the user study with one other close friend or acquaintance.
Each pair of participants were instructed to create an authentication
secret on either PassTag or RandomTag. The two schemes were
randomly assigned for each pair of participants.
Each participant created authentication by following the same
methodology we employed in the first session of study 1. Once par-
ticipants completed creating their authentication secrets, we asked
each pair of participants to play as close adversaries of each other
and were given five attempts to correctly choose the correct image
secrets along with the corresponding image-tags. Participants were
allowed to use the Internet and their smartphones for research.
7 RESULTS OF STUDY 1
Demographics: We recruited 30 volunteers (18 men, 12 women)
from our campus. The age group of 20 to 29 was most represented
with 27 participants. 11 pair of participants were close friend, 2
were their partner, and 2 were coworkers. Each participant received
$10 gift vouchers as incentives.
Close Adversary Guessing on PassTag vs. RandomTag: We
tested the hypothesis that PassTag with its similar decoy images
should be more resilient attacks from close adversaries than Ran-
domTag. We found strong evidence in support of this hypothesis.
None (0/15) of the close adversaries were able to correctly authen-
ticate PassTag compared to 6.7% (1/15) who were able to correctly
authenticate in RandomTag.
It is important to note that although the results between PassTa-
gand RandomTag appear similar, close adversaries were able to
correctly choose the image secret of RandomTag 28.0% (42/150)
much more often than PassTag 7.3% (11/150), showing significant
statisitcal difference (FET with one-tailed, p ≪ 0.00001). The addi-
tional authentication step of providing text tags for image secrets
prevented all but one close adversary to correctly authenticate in
Session 2: Authentication ASIA CCS '20, October 5–9, 2020, Taipei, Taiwan65RandomTag, and none in PassTag. Therefore, our clear recommen-
dation is using decoy images generated by PassTag rather than
random images with respect to security.
8 STUDY 2: EVALUATING USABILITY OF
PASSTAG
First Session: First, we asked the participants to select and upload
two sets of images that would be easily memorable to distinguish-
able for the participant, but be difficult for others to guess. Next,
users were asked to create corresponding text password for each
image, which is a personalized, memorable unique, and not easily
guessable textual password (tagging) for each image.
For each user uploaded image, PassTag generated 20 similar
decoy images and users were then asked to verify their submission
by correctly selecting their own images among 40 other images
and type in the correct textual password for each selection. If the
user was unable to correctly select both images and type in the
text passwords, which they had provided, then they were given
another attempt. If they failed the second attempt, they were asked
to resubmit more memorable images and textual passwords. If
the user was able to correctly select both images and type in the
correct text password, then the registration session was successfully
completed.
Second Session: Participants returned one week after registra-
tion and tried to log-in to the website with the account they had
created. To measure memorability, we had users go through the
log-in procedure three consecutive times. Each log-in procedure
was divided into a three-part trial. In each trial users were presented
with 40 images that may contain 0, 1, or 2 of their original images
alongside displayed decoy images. Users went through each trial to
correctly select their own images from the decoy images and type
in the correct textual passwords for each selection. Every input
by the users and the time it took to finish the authentication was
recorded. Users were not be notified if they correctly completed
the authentication process. Once the authentication was over, par-
ticipants were asked to provide feedback on their experience using
PassTag, such as what they liked or disliked about it and whether it
was easy or difficult to use. The exit survey questions are provided
in Table 2 to measure users’ sentiment, using System Usability Scale
(SUS) [38].
Table 2: Survey questions based on SUS.
Survey Questions
Q1. Authentication time for PassTag was reasonable/adequate.
Q2. Successfully authenticating using PassTag was reasonable/adequate.
Q3. It was easy to use PassTag.
Q4. It was easier to remember the images than the text passwords.
Q5. It was easier to remember the text passwords than the images.
Q6. The images that were generated by PassTag were similar to my images.
Q7. Looking at the images helped me remember my password.
9 RESULTS OF STUDY 2
We measure the recall after one week, creation and authentication
time, user sentiment, and strength. In addition, we analyze the
images and textual passwords users chose. Lastly, we measure the
distance between image-to-image and image-to-text to analyze the
correlations.
Demographics: We recruited 51 volunteers (30 men, 21 women)
from our campus. The age of the participants varied between 18 and
over 65. The age group of 20 to 29 was most represented with 35
participants. Among 51 participants who created the password, all
of them came back for authentication and received $10 gift vouchers
as incentives.
One Week Recall: We present the one week recall results in
Table 3. Among 51 participants, 92.6% of the participants were suc-
cessful within 3 trials after one week. 88.9% of the participants were
able to successfully select and recall both images and matching
textual passwords for all of their trials without any kind of errors.
PassTag achieved overall authentication success rate of 92.6%. Al-
though most participants were able to successfully authenticate
using PassTag, some were unable to successfully authentication
due to partial recollection of images and texts, which tributes to
7.4% of participants.
Table 3: Average, median, and std. of creation and comple-
tion time in secs and average auth. success rate per trial.
Attempt
Creation
Auth. Trial 1
Auth. Trial 2
Auth. Trial 3
Average Auth.
Time (sec)
Avg./Med./Std.
51.7/50.0/16.7
66.3/60.0/27.8
56.6/51.0/24/5
52.3/46.0/22.9
58.4/52.0/25.1
Auth Succ.
Rate
–
88.9%
92.6%
92.6%
92.6%
Next, we carefully measured the rate of correct selection of all
users for each image and text type, not taking into account whether
the authentication was a for success or failure. This allow us to
measure, observe, and compare whether text passwords (tagging)
are difficult to recall than images, etc.
Table 4 summarizes the percentage of correct recall of each pass-
word type. In Table 4, selections where only the image (only image)
was chosen correctly amounted to overall 97.1%, while only the
text passwords were correct amounted to 94.7%. Therefore, when
we compare images and textual passwords success rate, we can
observe the picture superiority effect by 2.4% (97.1% vs. 94.7%). We
also asked participants about this question during the exit survey
on what was easier to remember.
Lastly, about 1.5% (neither image nor text) of the selections were
made, where the participants selected both the image and text
passwords incorrectly, which is extremely small. Also, it is inter-
esting to observe the combined success rate result of 95.4% at trial
3 slightly increased from the text success rate (94.9%) when com-
bined with image (99.1%). This result can indirectly indicate that
levels-of-processing effect would help remember users about their
authentication secrets, where images helps remember textual pass-
words. We also asked this during the exit survey and obtained
moderate agreement on this effect. Therefore, we demonstrate that
our approach yields high recall compared to other competing ap-
proaches (e.g., 87% with dynamic security questions [18], 88% of
Session 2: Authentication ASIA CCS '20, October 5–9, 2020, Taipei, Taiwan66Table 4: Success rate with image and/or text.
Authentication
type
Trial 1
Average.
Selection Selection Selection Selection
Trial 2
Trial 3
Both image and text
Only image
Only text
Neither image nor text
91.2%
94.9%
94.9%
0%
93.5%
97.2%
94.4%
0.9%
95.4%
99.1%
94.9%
3.7%
93.3%
97.1%
94.7%
1.5%
Figure 6: Distribution of time to complete authentication for
each trial per user.
location-based security questions of PCCP [4], and 86% from Story
scheme [7]). For users who were unsuccessful, we analyzed the
errors each user made in the later section.
Time for Creation and Authentication: We present the aver-
age, median, and std. for time it took for users to: (1) complete the
creation and (2) complete the authentication during the user-study.
On average, it took the participants to complete the creation trial
was 51.7 seconds with standard deviation of 20.0 seconds, while the
median creation time was 50.0 seconds. The average time it took the
participants to complete the authentication trial was 58.4 seconds
with standard deviation of 25.1 seconds as shown in Table 3. Hence,
the overall creation time is slightly less than 1 minute and the au-
thentication time was very similar on average as shown in Table 3.
Fig. 6 illustrates the times for each trial the participants required
to complete authentication. The X-axis represents each individual
participant and the Y-axis represents the amount of seconds it took
the participant to complete the authentication. The time to com-
plete from trial 1 to trial 3 were totaled for each participant and the
totals were sorted in ascending order.
The longer authentication time was expected as PassTag requires
a user to carefully observe 40 images to determine if their images
exists and provide matching textual password input after selection
if the image exists. However, as users progressed through each trial
from trial 1 to trial 3, we can generally observe that the average
authentication time decreases as trial increases from 66.3 seconds
(trial 1) to 52.3 seconds (trial 3) on average as shown in Table 3. We
believe that as users become more familiar with usingPassTag along
with the decoy images, users’ average authentication time may
continue to decrease.
Images and Texts Correlations: We also analyze the correla-
tions on visual and semantic distance among the user-provided
images, texts, and system generated decoy images. To measure the
visual distance between images, we first calculated the color coher-
ence vectors (CCV) of the images provided by Pass et al. [31] using
Color Coherence Vectors (CCV) to measure image similarities. CCV
is widely used for image retrieval and image content dissimilarity
comparison, where the distance between two images is obtained by
comparing the pixel color and coherence between 2 CCVs, where 0
means no correlation and 1 means the two are identical.
The four correlations are shown in Table 5 as follows: (1) img-to-
img distance dist(I1, I2), which is the visual distance between the
first user-provided image I1 and the second user-provided image
I2, (2) img-to-decoy image distance dist({I1, I2}, {IDecoy}), which
is the visual distance between user-provided images I1, I2 and 40
system generated decoy images IDecoy, (3) img-to-txt distance
dist({I1, I2}, {T1,T2}), which is the semantic distance between user-
provided images I1 and I2 and text passwords T1 and T2, and (4)
txt-to-txt distance dist(T1,T2) which is the semantic distance be-
tween first text password and second text password.
To measure the correlation between user-submitted images to
the text passwords, image-to-text, and the correlation between the
two text passwords, we utilized word2vec [12], which is widely used
to measure the semantic distance between words. The distance For
image and text correlation, we inputted the text labels of the image
generated by Google Cloud Vision API [13] and the corresponding
text passwords submitted by the users.
We hypothesize that if the 1) visual distance of img-to-img dis-
tance, 3) img-to-txt dist, and 4) txt-to-img distance are large which
show low correlations (close to 0), then it will be difficult for attack-
ers to guess the correct images and texts as the images and texts do
have low correlation. On the other hand, 2) img-to-decoy distance
needs to be highly correlated (close to 1), which will result in the
correct images and decoy images to be hardly indistinguishable
to attackers. Therefore it is important to measure the correlation