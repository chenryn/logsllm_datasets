User: 如何利用Python编写一个简单的网络爬虫程序？请提供代码框架和必要的库。
Assistant: 为了编写一个简单的网络爬虫程序，您可以使用Python的Requests库和BeautifulSoup库。以下是一个基本的代码框架，它将使用这些库来提取一个网站的所有链接：

```python
import requests
from bs4 import BeautifulSoup

# 定义要爬取的网站
url = "http://example.com"

# 发送请求并获取页面内容
response = requests.get(url)
html = response.content

# 解析页面内容并获取所有的链接
soup = BeautifulSoup(html, "html.parser")
links = []
for link in soup.find_all("a"):
    link_url = link.get("href")
    if link_url is not None:
        links.append(link_url)

# 保存链接到文件
with open("links.txt", "w") as f:
    for link in links:
        f.write(link + "\n")
```

在此示例中，我们首先使用Requests库发送了一个GET请求到网站。然后，我们使用BeautifulSoup库解析页面内容并从中提取所有链接。最后，我们将所有链接保存到文件中以供进一步分析。

请注意，这只是一个基本的框架，您可以将其扩展为执行更复杂的任务，例如爬取特定类型的网页内容，或按照特定的规则过滤链接。