1http://htmlunit.sourceforge.net
2http://www.mozilla.org/rhino/
trailer	
  ]	
  >>	
  startxref	
  141413	
  13	
  0	
  obj	
  >	
  endobj	
  3	
  0	
  obj	
  >	
  endobj	
  0000141116	
  00000	
  n	
  0000141168	
  00000	
  n	
  %PDF-­‐1.3	
  …	
  …	
  …	
  Header	
  Body	
  Xref	
  Table	
  Trailer	
  Reference	
  to	
  Root	
  Root	
  Object	
  Reference	
  to	
  Object	
  3	
  Figure 2: A conceptual structure of the mimicry
attack
Figure 3: An example of mimicry attack
2. malicious structure detectors. These tools analyze the
internal structure of a PDF ﬁle without analyzing ex-
ecutable code within the ﬁle. For instance, features
can be related to raw object keywords within the PDF
or to lowercase and uppercase characters. These tools
assume structural diﬀerences between malicious and
benign ﬁles, caused by the presence of malicious con-
tent.
PjScan [24] is a tool which applies the ﬁrst methodol-
ogy. It extract lexical features from JavaScript code. For
example, it analyzes the frequency of speciﬁc tokens such
as +, (, etc., and looks for suspicious functions such as un-
escape, eval. Using these features, a one-class SVM classiﬁer
is trained.
Malware Slayer [26], on the contrary, adopts the second
methodology. It selects, thanks to a clustering process, the
most frequent name objects in malicious and benign ﬁles.
It then adopts their frequencies as features to train a random
forest classiﬁer. This tool relies on the assumption that the
frequency of the name objects is somewhat related to the
maliciousness of the ﬁle. A similar approach has been pro-
posed in 2013 [40] by considering, as features, the presence
of speciﬁc sequences of name objects obtained by parsing
the logical tree of the ﬁle.
PDFRate [33, 6], like Malware Slayer, performs a struc-
tural analysis of a PDF ﬁle, but it has a more extensive num-
ber of features, compared to Slayer. An example of these
features can be the number of stream markers, the number
of dot characters, and so on. Besides doing a distinction
between malicious and benign, this tool also distinguishes
malicious samples between targeted, whose payload directly
implements the attack that is executed on the victim system,
and opportunistic, whose payload downloads other malicious
content from the Internet.
5. EVADING MALICIOUS PDF DETECTORS
BASED ON STRUCTURAL ANALYSIS
5.1 Overview
Machine learning systems aimed at detecting malicious
PDF ﬁles by analyzing the ﬁle structure, have been recently
proposed. They rely on extracting a set of structural fea-
tures according to the Adobe PDF standard [11]. Such fea-
tures are not directly related to speciﬁc vulnerabilities or
characteristics of the embedded malicious code, but, more
in general, they are related to elements that are part of the
general PDF ﬁle structure. Examples of structural features
are the number of keywords [26], their distribution based
on the logical tree of the ﬁle [40], or more general properties
such as the number of lowercase or uppercase characters [33].
The reason why these systems are exceptionally good at de-
tecting malicious samples is that malware in-the-wild shows
an evident structural diﬀerence with respect to benign ﬁles.
5.2 The Mimicry Attack
While a benign PDF ﬁle is usually generated by an oﬀ-
the-shelf production tool, which creates a series of objects
that are not particularly useful to an attacker (for example,
the /Font related objects that describe how the characters
will appear on the screen), a malicious PDF sample can
be obtained by creating speciﬁc objects through low-level
tools such as Python libraries [14, 8]. Of course, the latter
approach is more feasible for an attacker, as it grants a better
control of the PDF contents.
Smutz and ˇSrndi´c [33, 40] theoretically investigated the
possibility of a mimicry attack. In the analysis performed
by Smutz et al., an attacker exactly knows what are the
most N (where N is a number much lower than the total
number of structural features) discriminant features used
by the classiﬁer. They extract an average estimate of the
features values used in a benign ﬁle set. Finally, they modify
the speciﬁc features of a malicious sample to match those
determined before. In the approach adopted by ˇSrndi´c, the
malicious sample is modiﬁed to match the most “benign”
sample in the attacker dataset (i.e.
the sample with the
lowest classiﬁcation score). The feature values can only be
incremented and the choice of the feature to be changed
depends on the type of classiﬁer adopted (assuming that the
attacker perfectly knows its model). Figures 2 and 3 show a
graphical structure of the mimicry attack.
Let us assume, for the sake of simplicity, that patterns
representing PDF ﬁles are represented as points in a 2D
plane, and that malicious PDF (represented as red dots) are
separated from benign PDF ﬁles (blue dots) by a line. Per-
Test	
  the	
  classiﬁer	
  with	
  a	
  malicious	
  sample	
  Is	
  the	
  sample	
  labeled	
  Malicious?	
  Change	
  the	
  most	
  discriminant	
  features	
  of	
  the	
  ﬁle	
  to	
  match	
  the	
  ones	
  of	
  a	
  generic	
  benign	
  distribu;on	
  Test	
  the	
  classiﬁer	
  with	
  the	
  new	
  sample	
  End	
  Yes	
  No	
  Establish	
  (or	
  guess)	
  the	
  most	
  discriminant	
  features	
  used	
  by	
  the	
  classiﬁer	
  Is	
  the	
  sample	
  labeled	
  Malicious?	
  End	
  No	
  Increase	
  the	
  number	
  of	
  discriminant	
  features	
  Yes	
  Start	
  Malicious	
  Region	
  Benign	
  Region	
  Decision	
  Boundary	
  Figure 4: Conceptual structure of the reverse
mimicry attack
Figure 6: Changes in root object structure and
memory allocation from a benign to a malicious sam-
ple
that a structural detection model can be evaded by reverse
mimicry attacks. The rationale behind the reverse mimicry
attack is the following. Instead of manipulating a malicious
sample to mimic benign patterns, we propose to manipulate
a benign ﬁle to make it malicious, with minimum structural
diﬀerences. Figures 4 and 5 show an example analogous to
Figures 3 and 2. The recognized benign samples are poi-
soned by the introduction of a malicious payload (the initial
benign samples are in clear blue). This operation may de-
termine a variation of some features that make the sample
closer to the malicious region. However, we will show that
this variation can be very limited: the new malicious sam-
ples may not cross the boundary of the decision region, thus
bypassing the detection system.
This process is relatively easy to be implemented in PDF
ﬁles, because of their particular standard. In the following,
we will describe three possible ways of implementing this
attack.
5.3.1 EXE Embedding
As described in Section 2, when an existing PDF object
is edited without rewriting the entire ﬁle, a new version is
added after its trailer. This version has a new trailer which
deﬁnes the main object (root) of the PDF tree. In other
words, with a new version, it is possible to completely re-
draw the tree of a PDF ﬁle. However, if there are compressed
data, removing the previous version or its objects from the
ﬁle can be a diﬃcult operation: there are strict boundaries
indicated by the Xref table. Indeed, when new objects are
added, their related Xref table values are included as well.
This means that adding structural features is really easy
but, on the contrary, removing them can be quite complex.
We added a new version of the ﬁle containing a malicious
embedded EXE payload, by using the Social Engineering
Toolkit (SET) [9].
In this version, a new root object is
added, so that the new trailer will point to this new object.
Figure 6 shows the changes between the root object in the
benign sample and the one in the malicious sample (embed-
ded in the second version) and the trailer, respectively, for
the benign and the malicious ﬁle. As it can be seen from the
picture, a new object called Names is added and the OpenAc-
Figure 5: An example of reverse mimicry attack
forming a mimicry attack translates into moving red dots in
the direction of the arrows, so that malicious samples are
represented in a way similar to the benign ones. The length
and direction of the arrow depends on the eﬀort needed to
transform a malicious PDF into a benign one from the point
of view of the learning algorithm. This approach, though,
does not guarantee an eﬀective attack, as an attacker has
to guess a reasonable model of benign samples based on the
knowledge of the learning algorithm, and the features used.
This means that, if an attacker makes a wrong guess, the
sample can go farther from the benign region. Moreover,
the changes that the attacker should do to the feature val-
ues might be impossible to be done concretely, due to some
limitations in operating with PDF data. For example, re-
moving data from the ﬁle might be a non feasible operation,
as it can, for example, completely break the tree or the
Xref table, making the ﬁle not readable anymore. For this
reason, the approach proposed by Smutz et al. has been
kept theoretical only.
5.3 Reverse Mimicry
In the case of attacks carried by PDF ﬁles, we believe
Test	
  the	
  classiﬁer	
  with	
  a	
  new	
  sample	
  Is	
  the	
  sample	
  labeled	
  Malicious?	
  Inject	
  malicious	
  content	
  inside	
  the	
  ﬁle	