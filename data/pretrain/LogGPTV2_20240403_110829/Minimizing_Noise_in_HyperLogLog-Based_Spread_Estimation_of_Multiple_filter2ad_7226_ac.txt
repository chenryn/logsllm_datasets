ˆnf := −2
32
32
22
23
24
end
return ˆCf []
from its local register array (Ms[]) and obtains the local rank
distribution (Cs[]) (lines 2-5). We note that this is a low-cost
process because Ms[] and Cs[] are small. As demonstrated in
Fig. 2, we observe that the rank distribution of Ms[] (Cs[])
is inappropriately shifted from the original distribution (Cf [])
that is recorded without noise or register sharing. The shift
occurs because the registers are not dedicated to a single
spreader but shared by multiple spreaders. Therefore, some
rank values will be higher than the ground truth since the
registers are always updated by a larger rank value. As a result,
the rank distribution Cs[] biases to higher rank values, which
results in an overestimation of the cardinality. Based on this
observation, RRSE aims to recover Cs[] to an ideal status ˆCf [],
ˆCf [] ≈ Cf [] (lines 16-24; see section III-D), and then
where
uses the recovered ˆCf [] to estimate the cardinality (lines 6-7),
ˆnf = αss
2
(
r(cid:2)
i=0
ˆCf [i]2
−i
−1
)
= αss
2
(
s(cid:2)
j=1
−Ms[j]
2
−1,
)
(5)
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:15:21 UTC from IEEE Xplore.  Restrictions apply. 
334
where α16 = 0.673, α32 = 0.697, α64 = 0.709, and αs =
s ≥ 128 [11]. Finally, as in
0.7213/(1 + 1.079/s) for
HLL [11], RRSE performs estimation corrections for low
spreaders (lines 9-11) and high spreaders (lines 12-14).
D. Local Rank Distribution Recovery
Here, we describe the rank distribution recovery function,
which is a probabilistic approach for calculating ˆCf [] using the
recorded rank distribution Cs[] and the global rank distribution
Cm[] (Algorithm 2, lines 16-24). Fig. 3 also gives an overview
of the decoding process. Given a ﬂow f’s rank distribution
(Cs[]), we infer a rank’s frequency of the original rank
distribution from the lowest to the highest rank, respectively
(line 19). For each rank i, we calculate the original frequency
of rank i ( ˆCf [i]) (line 21), which is the realization of Eq. (6).
In our algorithm, sumPn denotes the total number of rank
0 to i over the global register array excluding spreader’s
registers. Then, sum ˆCf denotes the total count of previous
lower ranks of a local register array. sumPn and sum ˆCf
are accumulated with dynamic programming. We note that
both time and space complexities of RANK DIST RECOVERY
are O(r), where r is a maximum value of a register which
is small (i.e., 7, 15). Moreover, the overall rank distribution
recovery process is lightweight since Cs[] can be retrieved with
negligible overhead and Cm[] is recorded on the ﬂy. Theorem 1
shows the processes of deriving ˆCf [].
Theorem 1. Let i be a random variable that is recorded in
our universal register array (M []), where i ∈ [0, r] and r is
the range of rank values. Also, let Cm[i] be the frequency
of rank i in M [], Cs[i] be the frequency of rank i in a
spreader’s registers (Ms[]), where Ms[] ⊂ M []. Let Pn[i]
be the probability of rank i over the global register array
excluding spreader’s registers. Assume M and Ms follow the
same distribution. Then,
Cs[i] − Pn[i]
(cid:3)i
Cf [i] =
(cid:3)i−1
lo=0 Cf [lo]
lo=0 Pn[lo]
Proof. First, let X be the event that an original rank value of
a register in Ms[] (low) is overwritten by a higher rank value
i of M [], then the probability of X is
P (X) =
· Pn[i],
Cf [lo]
s
(7)
Cm[i]−Cs[i]
m−s
, and m, s are the size of M []
where Pn[i] =
and Ms[], respectively. P (X) deﬁnes the probability that a
lower rank value low recorded in a ﬂow’s local registers
be overwritten by a higher rank value i (noise) from global
registers due to memory sharing. The former is the fraction
of rank value low supposed to be recorded in local registers
without the overwriting issue. Then, it is multiplied by Pn[i]
(i’s probability in the global register) assuming that M and Ms
have the same distribution, which represents the probability of
the overwriting event. Here, Cs[i] is subtracted from Cm[i] for
improving accuracy.
Similarly, let Y be the event that an original value of a
register in Ms[] (i) is overwritten by a higher rank value high
of M [], then Y ’s probability is
P (Y ) =
· Pn[hi].
Cf [i]
s
(8)
Thus, the times where all smaller ranks become rank i in Ms[]
is given by
i−1(cid:2)
P (X) · s = Pn[i] · i−1(cid:2)
Hi =
lo=0
lo=0
Cf [lo],
(9)
and the times where the current rank i became higher rank in
Ms[] is calculated by
r(cid:2)
Li =
P (Y ) · s = Cf [i]
r(cid:2)
hi=i+1
hi=i+1
Pn[hi].
(10)
The observed frequency for rank i (Cs[i]) should be equal to
Cf [i], but this is not the case due to register sharing. Instead,
Cs[i] can be seen as Cf [i] (true local rank distribution) plus Hi
in Eq. (9), the number of registers with lower ranks overwritten
by rank i, minus Li in Eq. (10), the total amount of rank i’s
register that has been overwritten as a higher value. Hence,
Cs[i] =C f [i] +P n[i]
i−1(cid:2)
lo=0
Cf [lo] − Cf [i]
r(cid:2)
hi=i+1
Pn[hi] (11)
Finally, we can derive Cf [i] as
Cs[i] − Pn[i]
i−1(cid:2)
lo=0
Cf [lo] = Cf [i] · (1 − r(cid:2)
Pn[hi]),
hi=i+1
Cs[i] − Pn[i]
1 − (cid:3)r
(cid:3)i−1
lo=0 Cf [lo]
.
hi=i+1 Pn[i]
Cf [i] =
≈ Cs[i] − Pn[i]
(cid:3)i
(cid:3)i−1
lo=0 Cf [lo]
lo=0 Pn[lo]
= Cf [i].
(12)
We note that when estimating
ˆCf [i], RRSE use estimated
ˆCf [lo] instead of the unavailable ground truth Cf [lo]. Since
ˆCf [i]s’ estimations follow the order i = 0, 1, . . . , r, ˆCf [lo]s
(lo ∈ [0, i− 1]) are available for
ˆCf [i] with dynamic program-
ming.
E. Bias and Standard Error
Finally, RRSE’s estimation is shown to be unbiased, and
the upper bound of the standard error is derived.
Theorem 2. Let ˆns be the estimation of RRSE using s
shared registers, and nf be the estimation without the register
sharing. If E( ˆCf [i]) ≈ Cf [i], then E( ˆnf ) =E (nf ), which
means our estimator is unbiased.
.
(6)
Let
ˆCf [i] be a variable to estimate Cf [i], given as,
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:15:21 UTC from IEEE Xplore.  Restrictions apply. 
335
Proof. Given Eq. (2), Eq. (5), and Eq. (6),
(cid:3)r
E( ˆnf ) = E(
(cid:3)r
αs · s2
−i ) ≈ E(
i=0 ˆCf [i]2
αs · s2
(cid:3)m
i=1 2
= E(
αs · s2
i=0 Cf [i]2
−M [i] ) = E(nf ).
−i )
(13)
Theorem 3. Given an arbitrary ﬂow f with a cardinality
estimation of ˆnf , the upper bound of RRSE’s relative standard
error is
(cid:4)
V ar( ˆnf )
nf
<
1.04√
s
+
√
ε
nf
where the error bound is deﬁned as
αs · s2
i=0 Cε[i]2
(cid:3)r
ε =
−i
(15)
Proof. Given s shared registers for a ﬂow f, the HLL-based
cardinality estimation ns may include a noise nn due to the
register sharing. Let ˆnf be the estimation of RRSE with rank
distribution recovery (i.e., noise reduction function). Then, the
variance of the ˆnf is
V ar( ˆnf ) = V ar(ns − nn)
= V ar(ns) +V ar (nn) − 2 · Cov(ns, nn)
< V ar(ns) +V ar (nn).
(16)
(17)
(18)
Let ε be the noise worst case. Then,
V ar( ˆnf ) < V ar(ns) +ε
2
.
Accordingly,
StdErr( ˆnf ) =
(cid:4)
(cid:4)
V ar(nf )
nf
<
V ar(ns) +ε 2
√
nf
V ar(ns)
) is 1.04√
s ,
nf
+
.
=
+
nf
(cid:4)
(19)
ε
nf
V ar(ns)
StdErr( ˆnf ) <
As described in Theorem 1,
Since the relative standard error of HLL (
the bound of the standard error of RRSE is
1.04√
s
ε
nf
the probability of a ﬂow
with a rank value i to overwrite another ﬂows’ registers is
given as Pn[i] =
, thereby the number of registers
that were overwritten by rank value i (i.e., noise) follows a
binomial distribution Bino(s, Pn[i]). Accordingly, the number
of overwritten registers is Cε[i] =binoinv (σ, s, Pn[i]), where
binoinv() is binomial inverse cumulative distribution function.
To this end, we can calculate ε using the HLL’s estimation (i.e.,
Eq. (2)) and Cε[] as ε =
Cm[i]−Cs[i]
m−s
(cid:2)r
αs·s2
i=0 Cε[i]2−i .
IV. EVALUATION
In this section, we conduct extensive evaluations of RRSE,
including (1) comparing the experimental results of RRSE’s
performance with our theoretical error bound analysis, (2)
evaluating the accuracy of RRSE by varying the memory and
trafﬁc distribution (i.e., attack and normal), (3) comparing
the performance of RRSE with two state-of-the-art schemes,
namely vHLL [27] and MCSE [16]. We ﬁnally discuss the
cost of RRSE.
StdErr( ˆnf ) =
,
(14)
TABLE II: The statistics of datasets
(a) Witty Worm Trafﬁc
(b) Normal Trafﬁc
Fig. 4: Spreader size distribution of attack and normal trafﬁc
Dataset
Number of spreaders
Total connections
Avg spreader size
Largest spreader size
Witty Worm Trafﬁc
Normal Trafﬁc
20,906
192,265,216
9,196
7,266,976
1,470,442
16,322,155
11
6,859,211
A. Dataset Description
We use both attack and normal trafﬁc datasets in our evalu-
ation. The Witty Worm trace [31] is used as attack trafﬁc, and
it has a relatively small number of devices but a large spreader
size on average. The normal trafﬁc is an ISP trace [32], where
many devices are attached to the network with a relatively
small spreader size. Fig. 4 shows the spreader size distribution
of two datasets. As shown, the normal network trace follows a