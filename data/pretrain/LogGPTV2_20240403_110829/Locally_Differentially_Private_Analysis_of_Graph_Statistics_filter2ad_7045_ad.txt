between each user and the data collector, we can privately
estimate dmax and use the private estimate of dmax as ˜dmax.
Speciﬁcally, we divide the privacy budget ε into ε0 ∈ R≥0
and ε1 ∈ R≥0; i.e., ε = ε0 +ε1. We ﬁrst estimate dmax with ε0-
edge LDP and then run LocalLapk(cid:63) with the remaining privacy
budget ε1. Note that LocalLapk(cid:63) with the private calculation
of dmax results in a two-rounds LDP algorithm.
We consider the following simple algorithm. At the ﬁrst
round, each user vi adds the Laplacian noise Lap( 1
) to her
ε0
degree di. Let ˆdi ∈ R be the noisy degree of vi; i.e., ˆdi =
). Then user vi sends ˆdi to the data collector. Let
di + Lap( 1
ε0
ˆdmax ∈ R be the maximum value of the noisy degree; i.e.,
ˆdmax = max{ ˆd1, . . . , ˆdn}. We call ˆdmax the noisy max degree.
The data collector calculates the noisy max degree ˆdmax as
an estimate of dmax, and sends ˆdmax back to all users. At the
second round, we run LocalLapk(cid:63) with input G, ε, and (cid:98) ˆdmax(cid:99).
At the ﬁrst round, the calculation of ˆdmax provides ε0-edge
LDP because each user’s degree has the sensitivity 1 under
edge LDP. At the second round, Theorem 1 guarantees that
LocalLapk(cid:63) provides ε1-edge LDP. Then by the composition
theorem [23], this two-rounds algorithm provides ε-edge LDP
in total (ε = ε0 + ε1).
Figure 2: Four types of subgraphs with three nodes.
In our experiments, we show that this algorithm provides
the utility close to LocalLapk(cid:63) with the true max degree dmax.
4.2 One-Round Algorithms for Triangles.
Algorithm. Now, we focus our attention on the more chal-
lenging f(cid:52) query. This query is more challenging in the graph
LDP model because no user is aware of any triangle; i.e., user
vi is not aware of any triangle formed by (vi,v j,vk), because
vi cannot see any edge (v j,vk) ∈ E in graph G.
One way to count f(cid:52)(G) with edge LDP is to apply the
RR (Randomized Response) to a neighbor list. For example,
user vi applies the RR to ai,1, . . . ,ai,i−1 (which corresponds
to users v1, . . . ,vi−1 with smaller user IDs) in her neighbor
list ai; i.e., we apply the RR to the lower triangular part of
adjacency matrix A, as described in Section 3.2. Then the
data collector constructs a noisy graph G(cid:48) = (V,E(cid:48)) ∈ G from
the lower triangular part of the noisy adjacency matrix, and
estimates the number of triangles from G(cid:48). However, simply
counting the triangles in G(cid:48) can introduce a signiﬁcant bias
because G(cid:48) is denser than G especially when ε is small.
Through clever post-processing known as empirical estima-
tion [32, 40, 57], we are able to obtain an unbiased estimate
of f(cid:52)(G) from G(cid:48). Speciﬁcally, a subgraph with three nodes
can be divided into four types depending on the number of
edges. Three nodes with three edges form a triangle. We refer
to three nodes with two edges, one edge, and no edges as
2-edges, 1-edge, and no-edges, respectively. Figure 2 shows
their shapes. f(cid:52)(G) can be expressed using m3, m2, m1, and
m0 as follows:
Proposition 2. Let G(cid:48) = (V,E(cid:48)) be a noisy graph generated
by applying the RR to the lower triangular part of A. Let
m3,m2,m1,m0 ∈ Z≥0 be respectively the number of triangles,
2-edges, 1-edge, and no-edges in G(cid:48). Then
(eε−1)3 m1− 1
E(cid:104) e3ε
(eε−1)3 m3− e2ε
(eε−1)3 m2+ eε
(eε−1)3 m0
(cid:105)
= f(cid:52)(G).
(4)
Therefore, the data collector can count m3, m2, m1, and
m0 from G(cid:48), and calculate an unbiased estimate of f(cid:52)(G) by
(4). In Appendix A, we show that the l2 loss is signiﬁcantly
reduced by this empirical estimation.
Algorithm 2 shows this algorithm. In line 2, user vi
applies the RR with privacy budget ε (denoted by RRε)
to ai,1, . . . ,ai,i−1 in her neighbor list ai, and outputs Ri =
USENIX Association
30th USENIX Security Symposium    989
WULDQJOHHGJHVHGJHQRHGJHV6KDSH݉ଷ݉ଶ݉ଵ݉଴&RXQWLQQRLV\JUDSKܩ′Data: Graph G represented as neighbor lists
a1, . . . ,an ∈ {0,1}n, privacy budget ε ∈ R≥0.
Result: Private estimate of f(cid:52)(G).
Ri ← (RRε(ai,1), . . . ,RRε(ai,i−1));
release(Ri);
1 for i = 1 to n do
2
3
4 end
5 G(cid:48) = (V,E(cid:48)) ← UndirectedGraph(R1, . . . ,Rn);
/* Counts m3,m2,m1,m0 in G(cid:48).
6 (m3,m2,m1,m0) ← Count(G(cid:48));
7 return
(eε−1)3 (e3εm3 − e2εm2 + eεm1 − m0)
1
*/
Algorithm 2: LocalRR(cid:52)
(RRε(ai,1), . . . ,RRε(ai,i−1)). In other words, we apply the RR
to the lower triangular part of A and there is no overlap be-
tween edges sent by users. In line 5, the data collector uses
a function (denoted by UndirectedGraph) that converts the
bits of (R1, . . . ,Rn) into an undirected graph G(cid:48) = (V,E(cid:48)) by
adding edge (vi,v j) with i > j to E(cid:48) if and only if the j-th
bit of Ri is 1. Note that G(cid:48) is biased, as explained above. In
line 6, the data collector uses a function (denoted by Count)
that calculates m3, m2, m1, and m0 from G(cid:48). Finally, the data
collector outputs the expression inside the expectation on the
left-hand side of (4), which is an unbiased estimator for f(cid:52)(G)
by Proposition 2. We denote this algorithm by LocalRR(cid:52).
Theoretical properties. LocalRR(cid:52) provides the following
guarantee.
Theorem 3. LocalRR(cid:52) provides ε-edge LDP and ε-
relationship DP.
LocalRR(cid:52) does not have the doubling issue (i.e., it provides
not 2ε but ε-relationship DP), because we apply the RR to the
lower triangular part of A, as explained in Section 3.2.
Unlike the RR and empirical estimation for tabular data
[32], the expected l2 loss of LocalRR(cid:52) is complicated. To
simplify the utility analysis, we assume that G is generated
from the Erdös-Rényi graph distribution G(n,α) with edge
existence probability α; i.e., each edge in G with n nodes is
independently generated with probability α ∈ [0,1].
Theorem 4. Let G(n,α) be the Erdös-Rényi graph distri-
bution with edge existence probability α ∈ [0,1]. Let p =
eε+1 and β = α(1 − p) + (1 − α)p. Let
ˆf(cid:52)(G,ε) be the
1
output of LocalRR(cid:52). If G ∼ G(n,α), then for all ε ∈ R≥0,
E[l2
2 ( ˆf(cid:52)(G,ε), f(cid:52)(G))] = O
Note that we assume the Erdös-Rényi model only for the
utility analysis of LocalRR(cid:52), and do not assume this model
for the other algorithms. The upper-bound of LocalRR(cid:52) in
Theorem 4 is less ideal than the upper-bounds of the other
algorithms in that it does not consider all possible graphs G ∈
G. Nevertheless, we also show that the l2 loss of LocalRR(cid:52) is
(eε−1)6 βn4(cid:17)
(cid:16) e6ε
.
roughly consistent with Theorem 4 in our experiments using
two real datasets (Section 5) and the Barabási-Albert graphs
[9], which have power-law degree distribution (Appendix B).
The parameters α and β are edge existence probabilities
in the original graph G and noisy graph G(cid:48), respectively. Al-
though α is very small in a sparse graph, β can be large for
small ε. For example, if α ≈ 0 and ε = 1, then β ≈ 1
e+1 = 0.27.
Theorem 4 states that for large n, the l2 loss of LocalRR(cid:52)
(= O(n4)) is much larger than the l2 loss of LocalRRk(cid:63) (=
O(n)). This follows from the fact that user vi is not aware of
any triangle formed by (vi,v j,vk), as explained above.
In contrast, counting f(cid:52)(G) in the centralized model is
much easier because the data collector sees all triangles in G;
i.e., the data collector knows f(cid:52)(G). The sensitivity of f(cid:52) is
at most ˜dmax (after graph projection). Thus, we can consider
a simple algorithm that outputs f(cid:52)(G) + Lap( ˜dmax/ε). We
denote this algorithm by CentralLap(cid:52). CentralLap(cid:52) attains
the expected l2 loss (= variance) of O
(cid:16) ˜d2
(cid:17)
.
The large l2 loss of LocalRR(cid:52) is caused by the fact that
each edge is released independently with some probability
of being ﬂipped. In other words, there are three independent
random variables that inﬂuence any triangle in G(cid:48). The next
algorithm, using interaction, reduces this inﬂuencing number
from three to one by using the fact that a user knows the
existence of two edges for any triangle that involves the user.
max
ε2
4.3 Two-Rounds Algorithms for Triangles
Algorithm. Allowing for two-rounds interaction, we are able
to compute f(cid:52) with a signiﬁcantly improved l2 loss, albeit
with a higher per-user communication overhead. As described
in Section 4.2, it is impossible for user vi to see edge (v j,vk) ∈
E in graph G = (V,E) at the ﬁrst round. However, if the data
collector publishes a noisy graph G(cid:48) = (V,E(cid:48)) calculated by
LocalRR(cid:52) at the ﬁrst round, then user vi can see a noisy edge
(v j,vk) ∈ E(cid:48) in the noisy graph G(cid:48) at the second round. Then
user vi can count the number of noisy triangles formed by
(vi,v j,vk) such that (vi,v j) ∈ E, (vi,vk) ∈ E, and (v j,vk) ∈
E(cid:48), and send the noisy triangle counts with the Laplacian
noise to the data collector in an analogous way to LocalLapk(cid:63).
Since user vi always knows that two edges (vi,v j) and (vi,vk)
exist in G, there is only one noisy edge in any noisy triangle
(whereas all edges are noisy in LocalRR(cid:52)). This is an intuition
behind our proposed two-rounds algorithm.
As with the RR in Section 4.2, simply counting the noisy
triangles can introduce a bias. Therefore, we calculate an
empirical estimate of f(cid:52)(G) from the noisy triangle counts.
Speciﬁcally, the following is the empirical estimate of f(cid:52)(G):
Proposition 3. Let G(cid:48) = (V,E(cid:48)) be a noisy graph generated
by applying the RR with privacy budget ε1 ∈ R≥0 to the lower
eε1 +1 . Let ti ∈ Z≥0 be the
triangular part of A. Let p1 = 1
number of triplets (vi,v j,vk) such that j  0, ˜dmax ∈ Z≥0.
Result: Private estimate of f(cid:52)(G).
1 p1 ← 1
/* First round.
eε1 +1;
Ri ← (RRε1(ai,1), . . . ,RRε1(ai,i−1));
release(Ri);
2 for i = 1 to n do
3
4
5 end
6 G(cid:48) = (V,E(cid:48)) ← UndirectedGraph(R1, . . . ,Ri−1);
/* Second round.
7 for i = 1 to n do
8
9
ai ← GraphProjection(ai, ˜dmax);
ti ← |{(vi,v j,vk) : j < k < i,ai, j = ai,k =
1, (v j,vk) ∈ E(cid:48)}|;
si ← |{(vi,v j,vk) : j < k < i,ai, j = ai,k = 1}|;