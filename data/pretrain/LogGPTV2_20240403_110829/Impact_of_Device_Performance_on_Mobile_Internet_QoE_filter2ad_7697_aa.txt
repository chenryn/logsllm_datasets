# Impact of Device Performance on Mobile Internet QoE

**Authors:**
Mallesham Dasari, Santiago Vargas, Arani Bhattacharya, Aruna Balasubramanian, Samir R. Das, Michael Ferdman  
*Department of Computer Science, Stony Brook University*

## Abstract
A significant portion of users in developing regions rely on relatively inexpensive, low-end smartphones. However, the impact of device capabilities on the performance of mobile Internet applications has not been thoroughly explored. To address this gap, we investigate the Quality of Experience (QoE) for three popular applications—Web browsing, video streaming, and video telephony—across different device parameters. Our findings indicate that Web browsing is more sensitive to low-end hardware compared to video applications, particularly video streaming. This sensitivity is due to the fact that video applications leverage specialized coprocessors/accelerators and thread-level parallelism on multi-core devices, which are available even on low-end models. In contrast, Web browsing is primarily influenced by clock frequency and typically utilizes no more than two cores, making it more vulnerable to performance degradation on low-end smartphones. Based on insights from our study of video applications, we explore offloading Web computation to a Digital Signal Processor (DSP) coprocessor. Specifically, we demonstrate an 18% improvement in page load time and a fourfold reduction in energy consumption by offloading regular expression computations.

## CCS Concepts
- **General and Reference:** Experimentation
- **Human-Centered Computing:** Ubiquitous and Mobile Computing, Ubiquitous and Mobile Devices, Mobile Applications

## Keywords
Mobile Applications, Quality of Experience, Hardware Accelerators

## ACM Reference Format
Dasari, M., Vargas, S., Bhattacharya, A., Balasubramanian, A., Das, S. R., & Ferdman, M. (2018). Impact of Device Performance on Mobile Internet QoE. In *2018 Internet Measurement Conference (IMC ’18)*, October 31–November 2, 2018, Boston, MA, USA. ACM, New York, NY, USA, 7 pages. https://doi.org/10.1145/3278532.3278533

## 1. Introduction
Mobile smartphones have become ubiquitous, with a wide range of cost and performance options. For instance, smartphone prices currently span from $50 to $1000 [1, 7]. The cost is largely determined by the hardware specifications. A high-end phone like the OnePlus5, priced at $600, features eight cores, a 2.4 GHz clock frequency, and 6 GB RAM, whereas a budget phone such as the Dell Venue Pro, costing $60, has only two cores, a 1 GHz clock frequency, and 512 MB RAM.

A critical question arises: how does the quality of experience (QoE) of mobile applications depend on the phone's hardware, given the vast differences in price and specifications? This is particularly important because computational power is a key bottleneck for mobile applications like web browsing [23, 31]. Understanding which hardware components most significantly affect performance is crucial for designing better, budget-friendly phones.

This issue is especially pronounced for low-end phones. For example, our results show that mobile web page loads on the Intex Amaze 4 (≈$60) and Gionee (≈$150) are 5× and 3× slower, respectively, compared to the Google Pixel2 (≈$700) under the same network conditions (§2). Despite advancements in hardware, the QoE of applications has not improved due to increased application complexity and a mismatch between QoE requirements and hardware enhancements. Figure 1 illustrates this trend using data from over 480 Android smartphone specifications over the past eight years, showing that page load times (PLT) have increased fourfold despite hardware and network improvements.

To address this, we characterize the QoE of common mobile applications across four hardware components: (1) clock frequency, (2) memory, (3) number of cores, and (4) Android governors (which control CPU frequency). Our goal is to understand how each of these parameters affects the QoE of three popular mobile applications: Web browsing, video streaming, and video telephony.

## 2. QoE Across Low and High-End Devices
We first examine the performance of three Internet applications—Web browsing, video streaming, and video telephony—across seven different smartphones (Table 1). These phones were chosen to represent a diverse range of hardware, OS, and cost, with prices ranging from $60 to $880 and maximum CPU clock frequencies from 1.3 GHz to 2.4 GHz. We describe the experimental setup before presenting the results.

### 2.1. Measurement Setup

#### Web Browsing
We measure browsing performance using Chrome 63.0.3239.111, focusing on page load time (PLT). PLT is defined as the time elapsed between sending the URL to the server and the firing of the DOMLoad event [36]. We load the top 50 Web pages from Alexa [38], clear the cache (including DNS), and estimate the average PLT. We use the WProf tool [36] to analyze the critical path of the page load process, breaking it down into computation and network activities. Computation activities include HTML parsing, JavaScript evaluation, and rendering, while network activities involve requesting and downloading objects on the Web page (e.g., HTML, CSS, JS, and image files). We automate the page loads for repeatability using the Chrome remote debugging protocol [34] over the Android Debug Bridge (ADB) [2].

#### Video Streaming
We use YouTube to measure video streaming performance, focusing on two QoE metrics: start-up latency (network-centric) and stall ratio (device-centric). Start-up latency is the time from the user's request to the first frame of video playback. Stall ratio is the fraction of time during which the video is paused due to buffering. 

#### Video Telephony
For video telephony, we use Skype and measure QoE based on call setup time and call quality (e.g., video resolution, frame rate, and audio clarity).

### 2.2. Results
Our results show that Web and video applications have distinct architectures, leading to different sensitivities to hardware specifications. Web applications are significantly affected by clock speeds, but video applications are virtually unaffected. Conversely, changing the number of cores affects video applications but has no significant impact on Web applications. By isolating the effect of each hardware parameter, we provide insights into both the impact on QoE and the underlying reasons.

Our key finding is that Web performance is severely impacted by low-end phones. Specifically, slow clock speeds adversely affect Web browsing. Page load times increase by 5× when clock frequency drops from 1512 MHz to 384 MHz. Interestingly, video applications, which are computationally intensive, are largely unaffected by this change due to the use of dedicated hardware decoders and parallel processing across multiple CPU cores. In contrast, web applications do not effectively utilize multiple cores, making them more vulnerable to performance degradation on low-end devices.

Finally, similar to video applications, we experiment with offloading Web computation to an existing DSP coprocessor/hardware accelerator on the Nexus4 phone. Our preliminary analysis shows that offloading regular expression computations improves page load time by 18% and reduces energy consumption by a factor of four.

## 3. Discussion and Future Work
Our study highlights the importance of considering hardware specifications in the design of mobile applications, particularly for low-end devices. Future work will focus on further optimizing Web browsing performance through additional offloading techniques and exploring the impact of other hardware components on QoE.

## 4. Conclusion
In conclusion, the performance of Web browsing is highly sensitive to the hardware capabilities of low-end smartphones, while video applications are less affected due to their use of specialized hardware and parallel processing. Offloading Web computation to a DSP coprocessor shows promise in improving performance and energy efficiency. These findings have significant implications for the design and optimization of mobile applications, especially in resource-constrained environments.

---

**Figure 1: Evolution of Web page performance and device parameters over the last 8 years. The growth in device performance is not on par with the growth of application demands.**

**Figure 2: Mobile application performance across diverse devices: (a) Web browsing, (b) Video Streaming, (c) Video Telephony. The horizontal axis shows the device type; their corresponding specifications are tabulated in Table 1.**

**Table 1: Mobile devices used in our experiments and their corresponding specifications.**