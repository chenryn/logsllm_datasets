title:Impact of Device Performance on Mobile Internet QoE
author:Mallesham Dasari and
Santiago Vargas and
Arani Bhattacharya and
Aruna Balasubramanian and
Samir R. Das and
Michael Ferdman
Impact of Device Performance on Mobile Internet QoE
Mallesham Dasari, Santiago Vargas, Arani Bhattacharya, Aruna Balasubramanian
Samir R. Das, Michael Ferdman
Department of Computer Science, Stony Brook University
ABSTRACT
A large fraction of users in developing regions use relatively in-
expensive, low-end smartphones. However, the impact of device
capabilities on the performance of mobile Internet applications has
not been explored. To bridge this gap, we study the QoE of three
popular applications – Web browsing, video streaming, and video
telephony – for different device parameters. Our results demon-
strate that the performance of Web browsing is much more sensi-
tive to low-end hardware than that of video applications, especially
video streaming. This is because the video applications exploit spe-
cialized coprocessors/accelerators and thread-level parallelism on
multi-core mobile devices. Even low-end devices are equipped with
needed coprocessors and multiple cores. In contrast, Web browsing
is largely influenced by clock frequency, but it uses no more than
two cores. This makes the performance of Web browsing more
vulnerable on low-end smartphones. Based on the lessons learned
from studying video applications, we explore offloading Web com-
putation to a coprocessor. Specifically, we explore the offloading of
regular expression computation to a DSP coprocessor and show an
improvement of 18% in page load time while saving energy by a
factor of four.
CCS CONCEPTS
• General and reference → Experimentation; • Human-centered
computing → Ubiquitous and mobile computing; Ubiquitous
and mobile devices; Mobile Applications;
KEYWORDS
Mobile Applications, Quality of Experience, Hardware Accelerators.
ACM Reference Format:
Mallesham Dasari, Santiago Vargas, Arani Bhattacharya, Aruna Balasubra-
manian, Samir R. Das, Michael Ferdman. 2018. Impact of Device Performance
on Mobile Internet QoE. In 2018 Internet Measurement Conference (IMC ’18),
October 31-November 2, 2018, Boston, MA, USA. ACM, New York, NY, USA,
7 pages. https://doi.org/10.1145/3278532.3278533
1 INTRODUCTION
Mobile smartphones have now penetrated a significant fraction
of the world’s population. They vary widely in terms of cost and
performance. For example, the costs of smartphones currently on
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
IMC ’18, October 31-November 2, 2018, Boston, MA, USA
© 2018 Association for Computing Machinery.
ACM ISBN 978-1-4503-5619-0/18/10...$15.00
https://doi.org/10.1145/3278532.3278533
Figure 1: Evolution of Web page performance and device pa-
rameters over the last 8 years. The growth in device perfor-
mance is not on par with the growth of application demands.
the market range between $50 – $1000 [1, 7]. The cost largely
depends on the hardware specifications. A $600 phone such as
OnePlus5 has eight cores, running up to a 2.4 GHz clock frequency
and 6 GB RAM, whereas a cheaper $60 phone (e.g., Dell Venue Pro)
has only two cores up to a 1 GHz clock frequency and 512 MB RAM.
A key question arises: how much of an application’s quality
of experience (QoE) depends on the phone’s hardware given that
widely different phones with very different price points are available
in the market? This question is specifically important because it is
well known that compute is a key performance bottleneck for mobile
applications such as browsing [23, 31]. However, it is not well
understood which aspect of computation/hardware specifications
is significant to performance. Knowing the hardware component
that has the most impact on end-user performance is crucial to
designing better phones under a budget.
The problem is more acute among low-end phones. As an exam-
ple, our results show that mobile Web page loads on two popular
phones in India, the Intex Amaze 4 (≈$60) and Gionee (≈$150), are
5× to 3× worse, respectively, than the Google Pixel2 (≈$700) under
the same network conditions (§2). The problem is not specific to
low-end phones alone. Despite the improvements in hardware, the
QoE of applications has not improved because of increased applica-
tion complexity and a mismatch between QoE requirements and
hardware enhancements. See Figure 1, which uses the page load his-
tory [4] and device data mined from over 480 Android smartphone
specifications over the past 8 years. The figure shows that page load
times (PLT) have increased by four × despite the improvements in
devices, hardware, and networks. This difference also underscores
the importance of mobile web experience on low-end hardware.
To address the question posed, we characterize the QoE of com-
mon mobile applications under four different hardware components:
(1) clock frequency, (2) memory, (3) number of cores, and (4) An-
droid governors. (The governors control the CPU frequency) Our
goal is to understand how each of these device parameters affect
01020PLT(Seconds)LeftY-axis02Clock(GHz)20112012201320142015201620172018Timeline0510Memory(GB)012PageSize(MB)RightY-axis0510Cores0510OSVersionIMC ’18, October 31-November 2, 2018, Boston, MA, USA
M. Dasari et al.
(a) Web Browsing (Google Chrome)
(b) Video Streaming (YouTube)
(c) Video Telephony (Skype)
Figure 2: Mobile application performance across diverse devices: (a) Web browsing, (b) Video Streaming, (c) Video Telephony.
The horizontal axis shows the device type; their corresponding specifications are tabulated in Table 1.
Device
Name
Application
Processor
Number
of Cores Version Min-Max (MHz)
Clock
OS
RAM
Size (GB)
Release
Date
Intex Amaze+
Gionee F103
Nexus4
SG S2-Tab
Pixel C-Tab
Pixel2
SG S6-edge
Spreadtrum SC9832A
MediaTek MT6735
Snapdragon S4 Pro
Jan, 2017
Oct, 2015
Nov, 2012
Sept, 2015
Dec, 2015
Oct, 2017
April, 2015
Table 1: Mobile devices used in our experiments and their corresponding specifications.
300-1300
300-1300
384-1512
400-1300
204-1912
300-2457
400-2100
6.0
5.0
5.1.1
5.0.2
8.0.0
8.0.0
6.0.1
Snapdragon 835
Exynos 7420
Exynos 5433
Tegra X1
1
2
2
3
3
4
3
4
4
4
8
4
8
8
GPU
Type
Mali-400
Mali-T720
Adreno 320
Mali-T760
Maxwell
Adreno 540
Mali-T760
Release
Cost
$60
$150
$200
$450
$600
$700
$880
the QoE of three of the most popular mobile applications: Web
browsing, video streaming, and video telephony.
We find that Web and video applications have very different
architectures. As a result, different hardware specifications affect
the two classes of applications differently. For example, Web appli-
cations are significantly affected by clock speeds, but video appli-
cations are virtually unaffected. In contrast, changing the number
of cores affects video applications but has no significant impact
on Web applications. To dig deeper, we isolate the effect of the
hardware parameter on the different aspects of the applications to
shed light on not only how the hardware component affects the
QoE but also why.
Our key finding is that Web performance is impacted by low-
end phones. In particular, slow clock speeds affect Web browsing
adversely. Web page loads slow down by 5× when clock frequency
drops from 1512 MHz to 384 MHz. Interestingly, video applications
are largely unaffected by this change even though video process-
ing is a computationally intensive operation. This is because video
decoding uses dedicated hardware decoders, available even on low-
end phones. Also, video applications use parallel operations among
multiple CPU cores for post-processing (such as muxing and de-
muxing of audio/video). In contrast, web applications do not use
multiple cores effectively. Given that even low-end phones have
multi-core processors, the performance of video applications is
impacted little on low-end phones, but the performance of Web
applications is severely affected.
Finally, similar to video applications, we experiment with of-
floading Web computation (hardware offloading) to an existing
DSP coprocessor/hardware accelerator on the Nexus4 phone. We
find that leveraging hardware offloading is a promising alterna-
tive to improving Web performance under a slow CPU clock. Our
preliminary analysis with offloading only regular expression com-
putations shows an improvement of 18% in page load time along
with a 4× reduction in energy.
2 QOE ACROSS LOW & HIGH-END DEVICES
As a first step, we study the performance of the three Internet
applications – Web browsing, Video streaming, and Video telephony
– across seven different smartphones. The phones are chosen so
that there is significant diversity in terms of hardware/OS and cost
(Table 1). The cost ranges from $60 to $880, and the maximum CPU
clock frequencies range from 1.3 GHz to 2.4 GHz. We first describe
the default experimental setup before turning to the results.
2.1 Measurement Setup
Web Browsing: We measure browsing performance over Chrome
63.0.3239.111 in terms of page load time (PLT). PLT is the time
elapsed between when the URL is sent to the server and when the
DOMLoad event is fired [36]. We load the top 50 Web pages from
Alexa [38], clear the cache (including DNS), and estimate the aver-
age PLT. We use the WProf tool [36] to analyze the critical path of
the page load process and break down the critical path into compu-
tation and network activities. Compuation activities include HTML
parsing, Javascript evaluation, and rendering. Network activities
involve requesting and downloading the objects on the Web page
(such as html, css, js, and image files). We automate the page loads
for repeatability using the Chrome remote debugging protocol [34]
over the Android Debug Bridge (ADB) [2].
Video Streaming: We use YouTube to measure video streaming
performance using two QoE metrics: start-up latency (network-
centric) and stall ratio (device-centric). Start-up latency is the time