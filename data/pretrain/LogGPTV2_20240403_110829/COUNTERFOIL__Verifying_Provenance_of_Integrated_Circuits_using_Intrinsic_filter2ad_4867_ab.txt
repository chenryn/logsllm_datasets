3.2 Veriﬁcation
The veriﬁcation procedure checks authenticity of chips at
the end of distribution. The veriﬁer takes an image of the
chip that includes both the marker and the package surface
in the vicinity of the marker. The insecure identiﬁer (eid) of
the marker is extracted from the image. The enrolled data
feid(cid:107)s( feid) for this identiﬁer is accessed from the database
(Alg. 2, line 2). The validity of signature s( feid) is checked
using the public key kpub of the enroller (Alg. 2, line 3). The
enrolled ﬁngerprint feid is compared against a new ﬁngerprint
fv that is extracted from the relevant area of the chip package
surface. If the similarity score exceeds a chosen threshold,
then the package surface is determined to match the record
(Alg. 2, line 5). The chip is veriﬁed as authentic only if the
digital signature is valid, and the ﬁngerprints match. The
validity of the signature ensures that the enrolled ﬁngerprint
in the public database was created by the enroller and has
not been modiﬁed. The ﬁngerprint match ensures that the
enrolled data is not being used to authenticate a chip other
than the one that was enrolled, a scenario that would arise if a
label was copied or transferred from one chip to another. The
veriﬁcation procedure is currently performed on a workbench
in our lab, but could later, for example, be integrated into a
pick-and-place machine at the end of distribution that picks
chips from reels and places them appropriately onto printed
circuit boards.
3.3 Attacker Capabilities and Security Con-
siderations
The attacker considered in this work is a proﬁt-motivated
counterfeiter that forges chips for purpose of selling them on
the market. This type of proﬁt-seeking attacker is responsi-
ble for prior counterfeit parts found in sensitive systems, but
note that it does not include nation-state attackers that may
spend large amounts of money to create malicious forgeries to
bring down targeted high-value systems. For a proﬁt-seeking
attacker, if the effort of forging chips exceeds the selling price
of the chip on the market, there is no incentive to forge the
chips. At the same time, the cost for anti-counterfeiting tech-
nology in commodity parts cannot exceed what the producer
or consumer of the parts is willing to spend for the guarantee
of provenance.
The security of our approach relies on assumptions similar
to those in earlier work on certiﬁcates of authenticity [13]. Our
1258    29th USENIX Security Symposium
USENIX Association
assumptions relate to the enrollment and veriﬁcation proto-
col, the uniqueness of package ﬁngerprints, and the difﬁculty
of creating forged chip packages that match legitimately en-
rolled ﬁngerprints. Among these three, the ﬁrst is intended
to be uncontroversial, and the latter two are supported by
experimental data in the paper.
1. Protocol Integrity: We make the standard assumption
that an adversary is not able to obtain the enroller’s
private key or forge digital signatures without having the
private key. We assume that the enroller is trusted to only
package legitimate integrated circuits, and to enroll only
these packages with the private key kpr.
2. Unique Fingerprints: We rely on the fact that pack-
age ﬁngerprints created under ordinary conditions are
unique and are identiﬁable via image processing. Specif-
ically, an enrolled ﬁngerprint from one package will not
be deemed a match for any package other than the en-
rolled one. Fingerprint uniqueness binds the enrolled
data to a speciﬁc chip instance. If labels are later afﬁxed
to chips other than the enrolled, the enrollment data asso-
ciated to the label will not match the chip characteristic.
This prevents an adversary from successfully copying or
transferring labels across chips.
3. Difﬁculty of Package Forgery: We assume, and then
support experimentally, that package ﬁngerprints are ran-
dom and difﬁcult to control. This prevents an adversary
from creating a new package surface that matches a legit-
imate enrolled ﬁngerprint. We support this assumption
by showing that even chips from the same mold have
different ﬁngerprints. This implies that even possession
of an identical mold will not enable an adversary to suc-
cessfully forge packages and therefore forgery requires a
more advanced manufacturing process than what indus-
try uses for packaging chips. Regardless of the process
used to create forgeries, an adversary will have to create
recognizable features with sizes on the order of 10µm
(see Fig. 3). Besides attempting to clone the package sur-
face an attacker could print a label with features from a
legitimate chip. However, the printing task is seemingly
out of reach of many technologies such as high-end 2400
DPI printers, which have a dot size of 10.6µm and can
only print reliable features at a much larger scale than its
dot size. Aside from forgery, an adversary might transfer
the package from a legitimate part to a counterfeit IC,
but there would be no proﬁt motive to this, as it would
destroy a legitimate chip to create a single forged chip.
Practical security concerns of our prototype system warrant
further discussion. One concern is that an adversary could
make a chip unveriﬁable by removing, moving, or damaging
its label. This threatens reliability more than security because
it does not falsely authenticate counterfeits, and because coun-
terfeiters would not directly proﬁt from destroying the labels.
(a) Package surface proﬁled using Zygo Nexview [58]
(b) Extracted SIFT feature sizes from image processing.
Figure 3: Package surface features, and distribution of feature
sizes extracted from package surface images using OpenCV.
For reliability, the paper labels used in our prototype system
would likely be replaced by more robust markings when de-
ploying COUNTERFOIL at production scale outside of the
lab. A second practical concern pertains to the use of a public
database for enrollment records. The records in the database
reveal information about quantity and schedule of produced
parts, which may be sensitive to the manufacturer. Similarly,
database queries that happen in the clear could reveal busi-
ness information about the consumer. Where this is a concern,
the enrolled data could be made private and provided only
to trusted veriﬁers, or cryptographic protocols for oblivious
transfer [44] or anonymous credentials [9] could be used to
ensure privacy.
4
Image Processing and Analysis
Our system relies on image processing as part of enrollment
and veriﬁcation. Enrollment generates a digitized represen-
tation of recognizable features within a selected area of the
package surface. Veriﬁcation later scores the record of en-
rolled features against a new image of the package surface. In
this section we describe the computer vision algorithms used.
Our algorithms are written in C++ using OpenCV [8] for the
image processing.
USENIX Association
29th USENIX Security Symposium    1259
8µm-8µm0µm4µm-4µm020406080100120Feature size (m)100102104106108CountPixel Size2400 DPI printerTypical size of fillers4.2 Feature Enrollment
The enrollment process extracts distinctive features from
an image which are suitable for matching and object recog-
nition, and stores them as compact feature descriptors. A
number of well-known image processing techniques exist
for feature detection and description, such as Scale Invari-
ant Feature Transform (SIFT) [33], Oriented FAST and Ro-
tated BRIEF (ORB) [46], Binary Robust Invariant Scalable
Keypoints (BRISK) [31], and Speeded-Up Robust Features
(SURF) [5]. These techniques are commonly used in applica-
tions such as image stitching, where image alignment requires
ﬁnding corresponding points of objects in two different im-
ages that contain the objects. Our work is agnostic to the
choice of algorithm, but based on empirical evaluation (as
will be discussed in Sec. 5.2.1) we choose ORB.
We ﬁrst pre-process the image (ROI) using Contrast Lim-
ited Adaptive Histogram Equalization (CLAHE) to improve
the contrast and tolerance to variation in lighting intensity.
We then use OpenCV’s implementation of ORB to extract
image features. The keypoints are detected by Oriented FAST
algorithm and described by 256-dimensional rotated BRIEF
descriptors [46]. Similarity between two keypoints can be
evaluated using feature distance, which is the Euclidean dis-
tance between two keypoints in the 256-dimensional feature
space. The keypoints also have associated positions within an
image, and we will use pixel distance to denote the Euclidean
distance in two dimensions between pixels in an image. For
the sake of predictable runtime, we restrict the number of
keypoints to 1,000/mm2 of package surface. Fig. 4 shows the
keypoints extracted from the region of interest.
The enrolled features are stored in a public database along
with a digital signature (Fig. 2). The NIST Digital Signature
Standard (DSS) establishes three algorithms for signatures,
RSA, Digital Signature Algorithm (DSA) and Elliptic Curve
DSA (ECDSA) [28]. We choose DSA in our implementation,
but this can replaced by either of the other algorithms with
minimal performance impact. For hashing function, SHA-3
is chosen because it is the latest Cryptographic Hash Stan-
dard issued by NIST [14]. More speciﬁcally, the enrollment
data is hashed using SHA3-256 and subsequently signed with
the enroller’s private key using an implementation of DSA
with 3072-bit private key from the open-source Crypto++ li-
brary [1]. Details about performance are presented in Sec. 5.2.
4.3 Feature Veriﬁcation
Veriﬁcation compares the enrolled keypoints against the ROI
of a new image in to order compute a similarity score. The
integrity of enrolled keypoints is ﬁrst veriﬁed by checking the
digital signature. When a new image is captured for veriﬁca-
tion, its ROI is identiﬁed relative to the marker, and keypoints
are extracted from the ROI. This mirrors the corresponding
steps performed in feature enrollment, so we don’t repeat
Figure 4: Image of chip with afﬁxed marker. The position
of enrollment ROI is shown by the blue box, and the callout
shows the keypoints extracted from the ROI. The ROI that
would be used for veriﬁcation is the smaller red box. The size
and position of both ROIs are deﬁned relative to the marker,
as shown by annotations in yellow.
4.1 Aruco Marker Labels and ROI Detection
Our system uses computer-readable labels (Fig. 2) to rep-
resent the purported identity of a package. The labels are
placed, to the extent possible with manual placement, in the
same position on each package. For convenience the labels
are also used as ﬁducial marks to deﬁne the Region Of Inter-
est (ROI) in the enrollment and veriﬁcation images, although
other easily-recognized features could be used instead of the
labels for this purpose. Aruco, the speciﬁc marker system
that we use, is a square-based ﬁducial marker system with
binary codes [17]. Aruco marker dictionaries are conﬁgurable,
allowing for an arbitrary marker capacity (in bits) and number
of markers. We use Aruco markers to label the chips with
the search tag of the public database. The four corners of the
marker allow for detection of image orientation (pose esti-
mation) which we leverage to determine the ROI for further
processing. Figure 4 shows a detected marker with its top-
left corner used to determine the center of ROI at a distance
 relative to the marker. Depending on whether the
image is being processed for enrollment or veriﬁcation, the
ROI selected from the image would be either ROIenroll (blue
square) and ROIveri f y (red square). Both squares are centered
at the same point, and have a size that is deﬁned relative to
the marker size for magniﬁcation invariance. The width of the
√
larger square is wenroll = 2mm, and the width of the smaller
square is wveri f y = wenroll/
2. The difference in ROI sizes
ensures that the ROI from enrollment will always contain
the ROI from veriﬁcation regardless of rotation. Consider the
yellow circle in Fig. 4 which is centered at point . Re-
gardless of the image orientation, the red square will always
be contained within the circle, and the blue square will always
contain the circle. Therefore, the blue square (ROIenroll) will
always contain the red square (ROIveri f y). Further, ROIenroll
is chosen larger than ROIveri f y to save runtime, as the veriﬁ-
cation involves more processing steps than enrollment. In our
experiments we use r = 5mm and θ = π/8.
1260    29th USENIX Security Symposium
USENIX Association
θrwenrollwverifyUSENIX revision versiontheir description here. The processing performed with the
veriﬁcation keypoints is as follows.
4.3.1 Feature Matching and RANSAC based Homogra-
phy Computation
Two images of the same planar surface taken from different
perspectives are related by a homography, which is a geo-
metric model that maps feature positions in one image to
the corresponding positions in the second image. Estimat-
ing the homography requires ﬁnding enrollment and veriﬁ-
cation keypoints that are similar and therefore likely to be
representations of the same feature on the package surface.
We ﬁnd such points by performing nearest neighbor match-
ing using OpenCV’s FLANN (Fast Library for Approximate
Nearest Neighbors) [40] matcher, and then evaluating qual-
ity of matches using a standard approach based on ratio of
feature distances [33] as described here. For every keypoint
ki in ROIenroll, we ﬁnd its two closest (in feature distance)
keypoints (k(cid:48)
2) from ROIveri f y and compute from their
(cid:107)ki−k(cid:48)
1(cid:107)2
Euclidean distance in feature space a ratio score ri =
.
(cid:107)ki−k(cid:48)
2(cid:107)2
A low ratio indicates that keypoint ki is signiﬁcantly more
1 than to its second best match k(cid:48)
similar to its best match k(cid:48)
2,
which implies that ki and k(cid:48)
1 are likely to be corresponding
points in the two images [33]. The 50 keypoint pairs with
the lowest ratios (i.e., the best matches) are used as the basis
for estimating a homography with the RANSAC algorithm.
Increasing the number of matches will reduce the chance
of RANSAC reaching consensus on an incorrect homogra-
phy, but increases the expected number of random samples
required to ﬁnd consensus.
1 and k(cid:48)
RANSAC (Random Sample Consensus) [15] is an algo-
rithm to estimate a model from noisy data that contains both
inliers and outliers. In our case, the computed model is the
homography, and the data are the 50 selected keypoint pairs.
RANSAC ﬁrst samples four keypoint pairs from the set and
calculates from them a homography matrix as in Eq. 1, where
the 3x3 matrix is the homography, and Pe and Pv are the re-
spective coordinates in enrollment and veriﬁcation images
of the keypoints. The quality of the homography model is
then evaluated according to how many of the 50 keypoint
pairs ﬁt the model. Each pair that ﬁts the homography model
is considered an inlier. The process iterates to calculate and
evaluate homographies from different sample points, and the
homography with the highest number of inliers is returned as
the best ﬁt for the data.
× Pe
h12
h22
h32
h13
h23
1
h11
h21
h31
Pv =
(1)
Figure 5: Pixel distances between enrolled keypoints and
the veriﬁcation keypoints that are their nearest feature-space
neighbors. Correspondence of keypoint position is deﬁned by
homography. The spike at left comes from matched keypoints
in the same relative positions, which are consistent with being
from the same physical feature of the package. The points
close enough to count as inliers are shaded red.
4.3.2 Projection and Scoring
Using the enrollment and veriﬁcation keypoints, and the ho-
mography between them, we compute a score that indicates
how many of the enrolled keypoints have good matches in
the set of veriﬁcation keypoints. An enrolled keypoint is con-
sidered to have a good match if there exists a veriﬁcation
keypoint that satisﬁes two conditions: (1) it is highly similar
to the enrolled keypoint, and (2) it is at the position where the
enrolled keypoint should be found in the veriﬁcation image.
The ﬁrst condition is formalized as a requirement of being the
nearest neighbor in feature space to the enrolled keypoint, and
being at least 25% nearer than its second-closest neighbor (i.e.
ratio score ri ≤ 0.75). The second condition is formalized as