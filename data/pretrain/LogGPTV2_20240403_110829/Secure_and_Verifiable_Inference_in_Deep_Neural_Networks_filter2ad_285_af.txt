### Detection Accuracy under NNTA, TPA, and MCA

The following tables present the detection accuracy for different solutions (SecureDL, SSFDNN, and the Original model) across various sample sizes. The results are provided for three different methods: NNTA, TPA, and MCA.

#### Table 6: Detection Accuracy under NNTA
| Solutions        | # of samples | Top-1   | Top-3   | Top-5   |
|------------------|--------------|---------|---------|---------|
| **SecureDL**     | 1            | 90.4%   | 92.3%   | 96.6%   |
|                  | 3            | 91.2%   | 94.5%   | 100%    |
|                  | 5            | 95.7%   | 100%    | 100%    |
| **SSFDNN**       | 1            | 73.1%   | 77.8%   | 82.8%   |
|                  | 3            | 83.1%   | 89.3%   | 94.2%   |
|                  | 5            | 87.4%   | 91.2%   | 100%    |
| **Original model** | 1          | 17.5%   | 23.6%   | 25.7%   |
|                  | 3            | 19.2%   | 29.4%   | 35.9%   |
|                  | 5            | 23.4%   | 34.1%   | 39.5%   |

#### Table 7: Detection Accuracy under TPA
| Solutions        | # of samples | Top-1   | Top-3   | Top-5   |
|------------------|--------------|---------|---------|---------|
| **SecureDL**     | 1            | 87.4%   | 90.1%   | 92.3%   |
|                  | 3            | 89.1%   | 92.4%   | 100%    |
|                  | 5            | 91.7%   | 100%    | 100%    |
| **SSFDNN**       | 1            | 68.3%   | 71.9%   | 79.7%   |
|                  | 3            | 80.1%   | 84.6%   | 91.2%   |
|                  | 5            | 85.3%   | 89.2%   | 97.4%   |
| **Original model** | 1          | 12.1%   | 20.3%   | 24.3%   |
|                  | 3            | 16.3%   | 24.7%   | 30.1%   |
|                  | 5            | 21.4%   | 30.3%   | 34.1%   |

#### Table 8: Detection Accuracy under MCA
| Solutions        | # of samples | Top-1   | Top-3   | Top-5   |
|------------------|--------------|---------|---------|---------|
| **SecureDL**     | 1            | 91.6%   | 93.7%   | 96.8%   |
|                  | 3            | 93.2%   | 100%    | 100%    |
|                  | 5            | 95.9%   | 100%    | 100%    |
| **SSFDNN**       | 1            | 75.2%   | 79.8%   | 84.2%   |
|                  | 3            | 83.7%   | 89.7%   | 95.2%   |
|                  | 5            | 88.4%   | 94.6%   | 100%    |
| **Original model** | 1          | 18.7%   | 24.3%   | 27.9%   |
|                  | 3            | 22.7%   | 32.4%   | 37.3%   |
|                  | 5            | 24.2%   | 35.3%   | 40.3%   |

### Running Time with SIMD

Figure 5 illustrates the running time when using SIMD technology to perform classification tasks on encrypted data. Specifically, SecureDL is used to classify Breast tissues in ciphertext.

#### Figure 5(a)
- **CNN Network Configuration**: Two convolutional layers (20 and 50 feature maps), two average pooling layers, and two fully connected layers (256 and 10 neurons).
- **Observations**: As the batch size increases, the running time of SIMD remains relatively constant. SecureDL takes only 0.63 seconds to return results for a single query, even with a batch size of 282.

#### Figure 5(b)
- **CNN Network Configuration**: Three convolutional layers (one with 20 feature maps and two with 50 feature maps), two average pooling layers, and two fully connected layers (256 and 10 neurons).
- **Observations**: SecureDL takes 0.88 seconds to return results for a single query with a batch size of 282. Increasing the batch size to 6144 reduces the running time to 0.04 seconds per instance.

### Trade-off between Memory and Runtime

Larger batch sizes can speed up inference but also increase the network's memory footprint. Therefore, there is a trade-off between memory and runtime, and the appropriate batch size should be chosen based on the dataset size.

### Running Time of Classification over Encrypted Datasets

The following tables show the running time for classification and noise reduction over encrypted datasets for different numbers of convolutional layers (CL).

#### Table 10: Breast Tissues
| #CL* | Classification (s) | #C | Noise Reduction (s) |
|------|--------------------|----|---------------------|
| 1    | 201.23             | 21 | 140.22              |
| 2    | 220.56             | 28 | 153.03              |
| 3    | 241.34             | 35 | 166.91              |
| 4    | 263.63             | 42 | 179.15              |
| 5    | 283.17             | 49 | 190.23              |

#### Table 11: Crab
| #CL* | Classification (s) | #C | Noise Reduction (s) |
|------|--------------------|----|---------------------|
| 1    | 193.36             | 21 | 124.15              |
| 2    | 221.17             | 28 | 153.46              |
| 3    | 240.54             | 35 | 166.29              |
| 4    | 261.12             | 32 | 178.61              |
| 5    | 283.67             | 49 | 191.17              |

#### Table 12: Ovarian
| #CL* | Classification (s) | #C | Noise Reduction (s) |
|------|--------------------|----|---------------------|
| 1    | 233.63             | 21 | 150.17              |
| 2    | 251.16             | 28 | 164.39              |
| 3    | 272.64             | 35 | 178.38              |
| 4    | 294.70             | 42 | 190.29              |
| 5    | 314.63             | 49 | 202.03              |

### Summary

- **Detection Accuracy**: Tables 6, 7, and 8 show the detection accuracy for different solutions and sample sizes.
- **Running Time with SIMD**: Figures 5(a) and 5(b) demonstrate the running time for classification tasks using SIMD technology.
- **Trade-off**: Larger batch sizes can speed up inference but increase memory usage.
- **Classification Time**: Tables 10, 11, and 12 provide the running time for classification and noise reduction over encrypted datasets.