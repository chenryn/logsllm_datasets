title:Non-uniform distributions in quantitative information-flow
author:Michael Backes and
Matthias Berg and
Boris K&quot;opf
Non-Uniform Distributions in Quantitative Information-Flow
Michael Backes
Saarland University &
MPI-SWS
Saarbrücken, Germany
PI:EMAIL
Matthias Berg
Saarland University
Saarbrücken, Germany
Boris Köpf
IMDEA Software
Madrid, Spain
PI:EMAIL
PI:EMAIL
ABSTRACT
Quantitative information-ﬂow analysis (QIF) determines the amount
of information that a program leaks about its secret inputs. For
this, QIF requires an assumption about the distribution of the se-
cret inputs. Existing techniques either consider the worst-case over
a (sub-)set of all input distributions and thereby over-approximate
the amount of leaked information; or they are tailored to reason-
ing about uniformly distributed inputs and are hence not directly
applicable to non-uniform use-cases; or they deal with explicitly
represented distributions, for which suitable abstraction techniques
are only now emerging. In this paper we propose a novel approach
for a precise QIF with respect to non-uniform input distributions:
We present a reduction technique that transforms the problem of
QIF w.r.t. non-uniform distributions into the problem of QIF for
the uniform case. This reduction enables us to directly apply ex-
isting techniques for uniform QIF to the non-uniform case. We
furthermore show that quantitative information ﬂow is robust with
respect to variations of the input distribution. This result allows
us to perform QIF based on approximate input distributions, which
can signiﬁcantly simplify the analysis. Finally, we perform a case
study where we illustrate our techniques by using them to analyze
an integrity check on non-uniformly distributed PINs, as they are
used for banking.
Categories and Subject Descriptors
D.4.6 [Operating Systems]: Security and Protection—Informa-
tion ﬂow controls; H.1.1 [Models and Principles]: Systems and
Information Theory—Information theory
General Terms
Security
Keywords
Quantitative information ﬂow
1.
INTRODUCTION
The goal of an information-ﬂow analysis is to keep track of sensi-
tive information during computation. If a program does not expose
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ASIACCS ’11, March 22–24, 2011, Hong Kong, China.
Copyright 2011 ACM 978-1-4503-0564-8/11/03 ...$10.00.
any information about its secret inputs to unauthorized parties, it
has secure information ﬂow, a property that is often formalized as
noninterference.
In many cases, achieving noninterference is ex-
pensive, impossible, or simply unnecessary: Many systems remain
secure as long as the amount of exposed secret information is suﬃ-
ciently small. Consider for example a password checker. A failed
login attempt reveals some information about the secret password.
However, for well-chosen passwords, the amount of leaked infor-
mation is so small that a failed login-attempt will not compromise
the security of the system.
Quantitative information-ﬂow analysis (QIF) is a technique for
establishing bounds on the information that is leaked by a program.
The insights that QIF provides go beyond the binary output of Bool-
ean approaches, such as non-interference analyzers. This makes
QIF an attractive tool to support gradual development processes,
even without explicitly speciﬁed policies. Furthermore, because
information-theory forms the foundation of QIF, the quantities that
QIF delivers can be directly associated with operational security
guarantees, such as lower bounds for the expected eﬀort of uncov-
ering secrets by exhaustive search.
Technically, a quantitative information-ﬂow analysis requires an
assumption about the probability distribution of the conﬁdential in-
puts. Existing approaches deal with this assumption in four fun-
damentally diﬀerent ways. We brieﬂy present all four alternatives
and discuss their implications on applicability and automation of
quantitative information-ﬂow analyses.
The ﬁrst kind of approach focuses on computing the channel ca-
pacity, which is the maximum leakage with respect to all possible
input distributions [7, 8, 17, 23, 24, 27, 31]. Maximizing over all pos-
sible input distributions is a safe, but often overly pessimistic as-
sumption: Consider a password checker with two possible observ-
able outcomes, succeed and fail. The capacity of the channel
from secret passwords to observables is 1 bit, corresponding to a
distribution that assigns probability 0.5 to both outcomes. A naive
security analysis will infer that an n-bit password can be leaked in
as few as n login attempts and conclude that the system is insecure.
However, if the passwords are well-chosen (e.g. drawn uniformly
from a large set), a login attempt will reveal much less than one bit
of information, which is the reason why the password checker is in
fact secure.
The second kind of approach considers the maximum leakage
with respect to a subset of possible input distributions, where the
subset is speciﬁed in terms of bounds on the entropy of the input
variables [9, 11]. While entropy bounds are an attractive way of
specifying interesting subsets of input distributions, precise reason-
ing about the leakage of programs in terms of such bounds turns
out to be challenging. In particular, deriving tight bounds for the
leakage of programs with loops in terms of entropy bounds for their
input variables is still an open problem.
The third kind of approach analyzes programs with respect to
uniformly distributed inputs [2, 20, 22]. Under the uniformity as-
sumption, computing the information-theoretic characteristics of
deterministic programs can be reduced to computing the programs’
preimages and determining their numbers or sizes [20]. It has been
shown that these tasks can be performed using symbolic [2] and
randomized algorithms [22], allowing one to analyze large state-
spaces with precision guarantees. However, the applicability of
those techniques has so far been restricted to domains with uni-
formly distributed inputs.
Finally, the fourth kind of approach analyzes programs with re-
spect to an arbitrary, but ﬁxed, probability distribution on the secret
inputs [12, 25, 30]. The ﬁrst automated approach delivers precise
results [30], but is limited to programs with small state-spaces due
to the explicit representation of the input distribution. An abstrac-
tion technique [29] addresses this problem by partitioning the (to-
tally ordered) domain into intervals, on which a piecewise uniform
distributions is assumed. However, it is an open problem how to
choose the initial partition of the domain in order to allow for an
analysis that is precise and eﬃcient at the same time.
In summary, it has been an open problem to perform quantita-
tive information-ﬂow analysis with non-uniform distributions in a
precise, scalable, and general way. In this paper, we make the fol-
lowing contributions towards this goal.
Our ﬁrst contribution is a technique for reducing the problem
of QIF with respect to non-uniform distributions to the problem of
QIF with respect to uniform distributions. Our reduction enables
one to directly apply existing tools for uniform QIF [2, 20, 22] to
the non-uniform case. The main idea of the reduction is to repre-
sent a non-uniform distribution in terms of a generator program that
receives uniformly distributed input and produces outputs accord-
ing to the desired distribution. We exhibit and prove a connection
between the information-ﬂow properties of the target program and
the sequential composition of the target program with the generator
program. This connection enables us to analyze the composed pro-
gram with respect to uniform inputs, and to draw conclusions about
the information ﬂow of the target program with respect to the non-
uniform distribution. Our reduction is motivated by a number of
examples that occur in practice. For example, the (non-uniformly
distributed) PINs used in electronic banking are derived from uni-
form bit-strings, e.g., using decimalization techniques [13]. An-
other example are the keys of a public-key cryptosystem, which
are typically produced by key generation algorithms that operate
on uniformly distributed input.
Our second contribution is to show that QIF is robust with re-
spect to small variations in the input distribution. This allows us
to replace actual input distributions with approximate distributions.
Based on the quality of the approximation, we give upper and lower
bounds on the error this approximation introduces in the analysis.
Focusing on approximate distributions can simplify the information-
ﬂow analysis, e.g. by allowing to replace “almost uniform” distri-
butions by uniform distributions.
Finally, we give examples of how our two results can be used
for the quantitative information-ﬂow analysis of realistic systems.
We use our reduction technique to estimate the information leaked
by an integrity check on non-uniformly distributed PINs, and we
use our robustness result to bound the error that is introduced by
assuming uniformly distributed PINs.
The paper is organized as follows.
In Section 2 we introduce
basic notions of information ﬂow. The reduction of non-uniform
analysis to the uniform case is shown in Section 3. The robustness
results are presented in Section 4. Section 5 contains our experi-
ments where we apply our results to analyze an integrity check on
non-uniformly distributed PINs. We present related work in Sec-
tion 6 and conclude in Section 7.
2. PRELIMINARIES
2.1 Programs
A program P = (I, F, R) is a triple consisting of a set of initial
states I, a set of ﬁnal states F, and a transition relation R ⊆ I ×
F. We consider programs that implement total functions, i.e., we
require that for all s ∈ I there is exactly one s′ ∈ F with (s, s′) ∈ R,
and we use the shorthand notation P(s) = s′ for (s, s′) ∈ R.
Given a ﬁnal state s′ ∈ F, we deﬁne its preimage P−1(s′) to be
the set of all input states from which s′ is reachable, i.e.,
P−1(s′) ≡ {s | (s, s′) ∈ R} .
The preimage of an unreachable state is the empty set.
2.2 Qualitative Information Flow
We assume that the initial state of each computation is secret.
We consider an attacker that knows the program, in particular its
transition relation, and the ﬁnal state of each computation.
We characterize partial knowledge about the elements of I in
terms of partitions of I, i.e., in terms of a family {B1, . . . , Br} of
i=1 Bi = I. A partition of I
models that each s ∈ I is known up to its enclosing block Bi. We
compare partitions using the (im-)precision order ⊑ deﬁned by
pairwise disjoint blocks such that Sr
{B1, . . . , Br} ⊑ {B′
1, . . . , B′
r′ }
≡ ∀i ∈ {1, . . . , r} ∃ j ∈ {1, . . . , r′} : Bi ⊆ B′
j .
The knowledge gained by an attacker about initial states of com-
putations of the program P by observing their ﬁnal states is given
by the partition Π that consists of the preimages of reachable ﬁnal
states, i.e.,
Π ≡ {P−1(s′) | s′ ∈ F} .
The partition {I} consisting of a single block corresponds to the
case where no information leaks, and {{s} | s ∈ I} where each block
is a singleton set captures the case that P fully discloses its input.
Partitions Π with {{s} | s ∈ I} ⊏ Π ⊏ {I} capture that P leaks partial
information about its input.
More generally, one can assume that initial and ﬁnal states are
pairs of high and low components, i.e., I = IH × IL and F = FH × FL,
and that the observer can access the low components of the initial
and ﬁnal states of a given computation. For a low input l and a low
output l′ we then deﬁne the low-preimage P−1
l (l′) of l′ to be the set
of all high components of input states with low component l, from
which a ﬁnal state with low component l′ is reachable, i.e.
P−1
l (l′) ≡ {h | ∃h′ ∈ FH : ((h, l), (h′, l′)) ∈ R} .
As before, we can characterize the knowledge an attacker gains
about the high components of initial states states in terms of a par-
tition of IH. However, the exact shape of this partition strongly de-
pends on the role of the low input. For example, when the low input
is controlled by an attacker who can exhaustively run the program
with all possible low inputs, then the knowledge the attacker gains
about the high input is characterized by partition corresponding to
the intersection of all low-preimages, i.e.,
Π ≡ \l∈IL
{P−1
l (l′) | l′ ∈ FL} ,
where the intersection of partitions Π1, Π2 is deﬁned by pairwise
intersection of their blocks, i.e. Π1 ∩ Π2 = {A ∩ B | A ∈ Π1, B ∈ Π2}.
Several approaches in the literature consider weaker attackers, e.g.
those that run the program with a single, ﬁxed low input [25], or
those that can observe a bounded number of program runs with
adaptively chosen low inputs [20]. While the precise deﬁnition of
Π depends on the considered attacker model, the characterization
of attacker knowledge in terms of a partition (or an equivalence
relation) is universal.
The results of this paper rely only on such a partition-based char-
acterization of attacker knowledge and can hence be used in con-
junction with all of the aforementioned attacker models. For the
sake of presentation, we focus on the simplest scenario, namely
programs in which the entire initial state is high, and the entire ﬁ-
nal state is low (and hence Π = {P−1(s′) | s′ ∈ F}).
2.3 Quantitative Information Flow
We use information theory to characterize the information that P
reveals about its input. This characterization has the advantage of
being compact and easy to compare. Moreover, it yields concise
interpretations in terms of the eﬀort needed to determine P’s input
from the revealed information, e.g., by exhaustive search.
We begin by introducing necessary notation. Let A be a ﬁnite set
and p : A → R a probability distribution. For a random variable
we will also denote by Pr(X = x).
X : A → B, we deﬁne pX : B → R as pX(x) = Pa∈X−1 (x) p(a), which
The (Shannon) entropy [34] H(X) = −Px∈B pX(x) log2 pX(x) of
X is a lower bound for the average number of bits required for rep-
resenting the results of independent repetitions of the experiment
associated with X. Thus, in terms of guessing, the entropy H(X)
is a lower bound for the average number of questions with binary
outcome that need to be asked to determine X’s value [6]. Given
another random variable Y : A → C, we write H(X|Y = y) for the
entropy of X given that the value of Y is y. The conditional en-
tropy H(X|Y) of X given Y is the expected value of H(X|Y = y)
over all y ∈ C; it captures the remaining uncertainty about X when
Y is observed.
For analyzing programs, we assume a probability distribution p
on I and we suppose that it is known to the attacker. For analyzing
the program P, we deﬁne two random variables. The ﬁrst random
variable D : I → I models the choice of an input in I, i.e., D is the
identity D(s) = s. The second random variable captures the input-
output behavior of P. We overload notation and also denote it by P.
Formally, we deﬁne P : I → F by P(s) = s′ whenever (s, s′) ∈ R.
The conditional entropy H(D|P) captures the remaining uncer-
tainty about the program’s input when the output is observed. We
will use H(D|P) as a measure of information ﬂow in this paper, be-