title:Polisis: Automated Analysis and Presentation of Privacy Policies Using
Deep Learning
author:Hamza Harkous and
Kassem Fawaz and
R&apos;emi Lebret and
Florian Schaub and
Kang G. Shin and
Karl Aberer
Polisis: Automated Analysis and Presentation of 
Privacy Policies Using Deep Learning
Hamza Harkous, École Polytechnique Fédérale de Lausanne (EPFL);  
Kassem Fawaz, University of Wisconsin-Madison; Rémi Lebret, École Polytechnique Fédérale 
de Lausanne (EPFL); Florian Schaub and Kang G. Shin, University of Michigan;  
Karl Aberer, École Polytechnique Fédérale de Lausanne (EPFL)
https://www.usenix.org/conference/usenixsecurity18/presentation/harkous
This paper is included in the Proceedings of the 
27th USENIX Security Symposium.
August 15–17, 2018 • Baltimore, MD, USA
ISBN 978-1-939133-04-5
Open access to the Proceedings of the 27th USENIX Security Symposium is sponsored by USENIX.Polisis: Automated Analysis and
Presentation of Privacy Policies Using Deep Learning
Hamza Harkous1, Kassem Fawaz2, R´emi Lebret1, Florian Schaub3, Kang G. Shin3, and Karl Aberer1
1 ´Ecole Polytechnique F´ed´erale de Lausanne (EPFL)
2 University of of Wisconsin-Madison
3 University of Michigan
Abstract
Privacy policies are the primary channel through which
companies inform users about their data collection and
sharing practices. These policies are often long and difﬁ-
cult to comprehend. Short notices based on information
extracted from privacy policies have been shown to be
useful but face a signiﬁcant scalability hurdle, given the
number of policies and their evolution over time. Com-
panies, users, researchers, and regulators still lack usable
and scalable tools to cope with the breadth and depth of
privacy policies. To address these hurdles, we propose an
automated framework for privacy policy analysis (Poli-
sis). It enables scalable, dynamic, and multi-dimensional
queries on natural language privacy policies. At the core
of Polisis is a privacy-centric language model, built with
130K privacy policies, and a novel hierarchy of neural-
network classiﬁers that accounts for both high-level as-
pects and ﬁne-grained details of privacy practices. We
demonstrate Polisis’ modularity and utility with two ap-
plications supporting structured and free-form querying.
The structured querying application is the automated as-
signment of privacy icons from privacy policies. With
Polisis, we can achieve an accuracy of 88.4% on this
task. The second application, PriBot, is the ﬁrst free-
form question-answering system for privacy policies. We
show that PriBot can produce a correct answer among
its top-3 results for 82% of the test questions. Using an
MTurk user study with 700 participants, we show that at
least one of PriBot’s top-3 answers is relevant to users
for 89% of the test questions.
1
Introduction
Privacy policies are one of the most common ways of
providing notice and choice online. They aim to inform
users how companies collect, store and manage their
personal information. Although some service providers
have improved the comprehensibility and readability of
their privacy policies, these policies remain excessively
long and difﬁcult to follow [1, 2, 3, 4, 5]. In 2008, Mc-
Donald and Cranor [4] estimated that it would take an
average user 201 hours to read all the privacy policies
encountered in a year. Since then, we have witnessed
a smartphone revolution and the rise of the Internet of
Things (IoTs), which lead to the proliferation of ser-
vices and associated policies [6]. In addition, emerging
technologies brought along new forms of user interfaces
(UIs), such as voice-controlled devices or wearables, for
which existing techniques for presenting privacy policies
are not suitable [3, 6, 7, 8].
Problem Description. Users, researchers, and regula-
tors are not well-equipped to process or understand the
content of privacy policies, especially at scale. Users are
surprised by data practices that do not meet their expec-
tations [9], hidden in long, vague, and ambiguous poli-
cies. Researchers employ expert annotators to analyze
and reason about a subset of the available privacy poli-
cies [10, 11]. Regulators, such as the U.S. Department of
Commerce, rely on companies to self-certify their com-
pliance with privacy practices (e.g., the Privacy Shield
Framework [12]). The problem lies in stakeholders lack-
ing the usable and scalable tools to deal with the breadth
and depth of privacy policies.
Several proposals have aimed at alternative methods
and UIs for presenting privacy notices [8], including
machine-readable formats [13], nutrition labels [14], pri-
vacy icons (recently recommended by the EU [15]), and
short notices [16]. Unfortunately, these approaches have
faced a signiﬁcant scalability hurdle: the human effort
needed to retroﬁt the new notices to existing policies and
maintain them over time is tremendous. The existing re-
search towards automating this process has been limited
in scope to a handful of “queries,” e.g., whether the pol-
icy mentions data encryption or whether it provides an
opt-out choice from third-party tracking [16, 17].
Our Framework. We overcome this scalability hurdle
by proposing an automatic and comprehensive frame-
work for privacy policy analysis (Polisis). It divides a
privacy policy into smaller and self-contained fragments
USENIX Association
27th USENIX Security Symposium    531
of text, referred to as segments. Polisis automatically an-
notates, with high accuracy, each segment with a set of
labels describing its data practices. Unlike prior research
in automatic labeling/analysis of privacy policies, Poli-
sis does not just predict a handful of classes given the
entire policy document.
Instead, Polisis annotates the
privacy policy at a much ﬁner-grained scale. It predicts
for each segment the set of classes that account for both
the high-level aspects and the ﬁne-grained classes of em-
bedded privacy information. Polisis uses these classes to
enable scalable, dynamic, and multi-dimensional queries
on privacy policies, in a way not possible with prior ap-
proaches.
At the core of Polisis is a novel hierarchy of neural-
network classiﬁers that involve 10 high-level and 122
ﬁne-grained privacy classes for privacy-policy segments.
To build these ﬁne-grained classiﬁers, we leverage tech-
niques such as subword embeddings and multi-label
classiﬁcation. We further seed these classiﬁers with a
custom, privacy-speciﬁc language model that we gener-
ated using our corpus of more than 130,000 privacy poli-
cies from websites and mobile apps.
Polisis provides the underlying intelligence for re-
searchers and regulators to focus their efforts on merely
designing a set of queries that power their applications.
We stress, however, that Polisis is not intended to replace
the privacy policy – as a legal document – with an auto-
mated interpretation. Similar to existing approaches on
privacy policies’ analysis and presentation, it decouples
the legally binding functionality of these policies from
their informational utility.
Applications. We demonstrate and evaluate the modu-
larity and utility of Polisis with two robust applications
that support structured and free-form querying of privacy
policies.
The structured querying application involves extract-
ing short notices in the form of privacy icons from pri-
vacy policies. As a case study, we investigate the Dis-
connect privacy icons [18]. By composing a set of sim-
ple rules on top of Polisis, we show a solution that can
automatically select appropriate privacy icons from a pri-
vacy policy. We further study the practice of companies
assigning icons to privacy policies at scale. We empiri-
cally demonstrate that existing privacy-compliance com-
panies, such as TRUSTe (now rebranded as TrustArc),
might be adopting permissive policies when assigning
such privacy icons. Our ﬁndings are consistent with
anecdotal controversies and manually investigated issues
in privacy certiﬁcation and compliance processes [19, 20,
21].
The second application illustrates the power of free-
form querying in Polisis. We design, implement and
evaluate PriBot, the ﬁrst automated Question-Answering
(QA) system for privacy policies. PriBot extracts the
relevant privacy policy segments to answer the user’s
free-form questions. To build PriBot, we overcame the
non-existence of a public, privacy-speciﬁc QA dataset by
casting the problem as a ranking problem that could be
solved using the classiﬁcation results of Polisis. PriBot
matches user questions with answers from a previously
unseen privacy policy, in real time and with high accu-
racy – demonstrating a more intuitive and user-friendly
way to present privacy notices and controls. We evalu-
ate PriBot using a new test dataset, based on real-world
questions that have been asked by consumers on Twitter.
Contributions. With this paper we make the following
contributions:
• We design and implement Polisis, an approach for au-
tomatically annotating previously unseen privacy poli-
cies with high-level and ﬁne-grained labels from a pre-
speciﬁed taxonomy (Sec. 2, 3, 4, and 5).
• We demonstrate how Polisis can be used to assign pri-
vacy icons to a privacy policy with an average accu-
racy of 88.4%. This accuracy is computed by com-
paring icons assigned with Polisis’ automatic labels to
icons assigned based on manual annotations by three
legal experts from the OPP-115 dataset [11] (Sec. 6).
• We design, implement and evaluate PriBot, a QA sys-
tem that answers free-form user questions from pri-
vacy policies (Sec. 7). Our accuracy evaluation shows
that PriBot produces at least one correct answer (as in-
dicated by privacy experts) in its top three for 82% of
the test questions and as the top one for 68% of the test
questions. Our evaluation of the perceived utility with
700 MTurk crowdworkers shows that users ﬁnd a rele-
vant answer in PriBot’s top-3 for 89% of the questions
(Sec. 8).
• We make Polisis publicly available by providing three
web services demonstrating our applications: a ser-
vice giving a visual overview of the different aspects
of each privacy policy, a chatbot for answering user
questions in real time, and a privacy-labels interface
for privacy policies. These services are available at
https://pribot.org.
2 Framework Overview
Fig. 1 shows a high-level overview of Polisis. It com-
prises three layers: Application Layer, Data Layer, and
Machine Learning (ML) Layer. Polisis treats a privacy
policy as a list of semantically coherent segments (i.e.,
groups of consecutive sentences). It also utilizes a tax-
onomy of privacy data practices. One example of such a
taxonomy was introduced by Wilson et al. [11] (see also
Fig. 3 in Sec. 4).
Application Layer (Sec. 5, 6 & 7): The Applica-
tion Layer provides ﬁne-grained information about the
532    27th USENIX Security Symposium
USENIX Association
Application 
Layer
1
privacy 
policy link
App
Query Module
Class Comparison
Data 
Layer
Segmenter
ML
Layer
2
policy 
segments
1
user
query
4
query 
classes
3
annotated
segments
Query Analyzer
Segment Classifier
Legend:
Module
Data
flow
Privacy 
Taxonomy
Fig. 1: A high-level overview of Polisis.
privacy policy, thus providing the users with high mod-
ularity in posing their queries.
In this layer, a Query
Module receives the User Query about a privacy policy
(Step 1 in Fig. 1). These inputs are forwarded to lower
layers, which then extract the privacy classes embedded
within the query and the policy’s segments. To resolve
the user query, the Class-Comparison module identiﬁes
the segments with privacy classes matching those of the
query. Then, it passes the matched segments (with their
predicted classes) back to the application.
Data Layer (Sec. 3): The Data Layer ﬁrst scrapes the
policy’s webpage. Then, it partitions the policy into se-
mantically coherent and adequately sized segments (us-
ing the Segmenter component in Step 2 of Fig. 1). Each
of the resulting segments can be independently con-
sumed by both the humans and programming interfaces.
Machine Learning Layer (Sec. 4): In order to en-
able a multitude of applications to be built around Poli-
sis, the ML layer is responsible for producing rich and
ﬁne-grained annotations of the data segments. This layer
takes as an input the privacy-policy segments from the
Data Layer (Step 2) and the user query (Step 1) from the
Application Layer. The Segment Classiﬁer probabilisti-
cally assigns each segment a set of class–value pairs de-
scribing its data practices. For example, an element in
this set can be information-type=location with probabil-
ity p = 0.65. Similarly, the Query Analyzer extracts the
privacy classes from the user’s query. Finally, the class–
value pairs of both the segments and the query are passed
back to the Class Comparison module of the Application
Layer (Steps 3 and 4).
3 Data Layer
To pre-process the privacy policy, the Data Layer em-
ploys a Segmenter module in three stages: extraction, list
handling, and segmentation. The Data Layer requires no
information other than the link to the privacy policy.
Policy Extraction: Given the URL of a privacy pol-
icy, the segmenter employs Google Chrome in head-
less mode (without UI) to scrape the policy’s web-
Fig. 2: List merging during the policy segmentation.
page.
It waits for the page to fully load which hap-
pens after all the JavaScript has been downloaded and
executed. Then, the segmenter removes all irrelevant
HTML elements including the scripts, header, footer,
side/navigation menus, comments, and CSS.
Although several online privacy policies contain dy-
namically viewable content (e.g., accordion toggles and
collapsible/expandable paragraphs), the “dynamic” con-
tent is already part of the loaded webpage in almost all
cases. For example, when the user expands a collapsible
paragraph, a local JavaScript exposes an ofﬂine HTML
snippet; no further downloading takes place.
We conﬁrmed this with the privacy policies of the top
200 global websites from Alexa.com. For each privacy-
policy link, we compared the segmenter’s scraped con-
tent to that extracted from our manual navigation of the
same policy (while accounting for all the dynamically
viewable elements of the webpage). Using a fuzzy string
matching library,1 we found that the segmenter’s scraped
policy covers, on average, 99.08% of the content of the
manually fetched policy.
List Aggregation: Second, the segmenter handles any
ordered/unordered lists inside the policy. Lists require
a special treatment since counting an entire lengthy list,
possibly covering diverse data practices, as a single seg-
ment could result in noisy annotations. On the other
hand, treating each list item as an independent segment
is problematic as list elements are typically not self-
contained, resulting in missed annotations. See Fig. 2
from Google’s privacy policy as an example2.
Our handling of the lists involves two techniques: one
for short list items (e.g., the inner list of Fig. 2) and an-
other for longer list items (e.g., the outer list of Fig. 2).
For short list items (maximum of 20 words per element),
the segmenter combines the elements with the introduc-
tory statement of the list into a single paragraph element
(with  tag). The rest of the lists with long items are
transformed into a set of paragraphs. Each paragraph is a
distinct list element prepended by the list’s introductory
statement (Step 3 in Fig. 2).
1https://pypi.python.org/pypi/fuzzywuzzy
2https://www.google.com/intl/en US/policies/
privacy/archive/20160829/,
retrieved on Jun. 27, 2018
last modiﬁed on Aug. 29, 2016,
USENIX Association
27th USENIX Security Symposium    533
Further useful privacy and security related materials can be found through Google’spolicies and principles pages, including:oInformation about ourtechnologies and principles, which includes, among other things, more information on•how Google uses cookies.•technologies we use foradvertising.•how werecognize patterns like faces.oApagethat explains what data is shared with Google when you visit websites that use our advertising, analytics and social products.oThePrivacy Checkuptool, which makes it easy to review your key privacy settings.oGoogle’ssafety center, which provides information on how to stay safe and secure online.2. Append3. Prepend1. Merge short list Policy Segmentation: The segmenter performs an ini-
tial coarse segmentation by breaking down the policy
according to the HTML  and  tags. The out-
put of this step is an initial set of policy segments. As
some of the resulting segments might still be long, we
subdivide them further with another technique. We use
GraphSeg [22], an unsupervised algorithm that gener-
ates semantically coherent segments. It relies on word
embeddings to generate segments as cliques of related
(semantically similar) sentences. For that purpose, we
use custom, domain-speciﬁc word embeddings that we
generated using our corpus of 130K privacy policies (cf.
Sec. 4). Finally, the segmenter outputs a series of ﬁne-
grained segments to the Machine Learning Layer, where
they are automatically analyzed.
4 Machine Learning Layer
This section describes the components of Polisis’ Ma-
chine Learning Layer in two stages: (1) an unsupervised
stage, in which we build domain-speciﬁc word vectors
(i.e., word embeddings) for privacy policies from unla-
beled data, and (2) a supervised stage, in which we train a
novel hierarchy of privacy-text classiﬁers, based on neu-
ral networks, that leverages the word vectors. These clas-
siﬁers power the Segment Classiﬁer and Query Analyzer
modules of Fig. 1. We use word embeddings and neural
networks thanks to their proven advantages in text clas-
siﬁcation [23] over traditional techniques.
4.1 Privacy-Speciﬁc Word Embeddings
Traditional text classiﬁers use the words and their fre-
quencies as the building block for their features. They,
however, have limited generalization power, especially
when the training datasets are limited in size and scope.
For example, replacing the word “erase” by the word
“delete” can signiﬁcantly change the classiﬁcation result
if “delete” was not in the classiﬁer’s training set.
Word embeddings solve this issue by extracting
generic word vectors from a large corpus, in an unsu-
pervised manner, and enabling their use in new classiﬁ-
cation problems (a technique termed Transfer Learning).
The features in the classiﬁers become the word vectors
instead of the words themselves. Hence, two text seg-
ments composed of semantically similar words would be
represented by two groups of word vectors (i.e., features)
that are close in the vector space. This allows the text
classiﬁer to account for words outside the training set, as
long as they are part of the large corpus used to train the
word vectors.
While general-purpose pre-trained embeddings, such
as Word2vec [24] and GloVe [25] do exist, domain-
speciﬁc embeddings result in better classiﬁcation accu-
racy [26]. Thus, we trained custom word embeddings
for the privacy-policy domain. To that end, we created a