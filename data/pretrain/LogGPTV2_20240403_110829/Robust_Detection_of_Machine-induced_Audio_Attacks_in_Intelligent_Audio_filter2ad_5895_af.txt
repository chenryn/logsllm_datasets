demonstrate that the proposed methods can learn general features
that are able to distinguish machine-induced audio from genuine
speech to achieve robust detection of various types of audio attacks.
7.5 Ablation Study
Impact of Involved Channels. To investigate the impact of the
number of involved channels on the detection performance, we
train a group of models on the genuine and replayed audio data
recorded using device 2 by varying the number of input audio
channels and measure the resulting recognition accuracy and EER.
From the results shown in Figure 11, we observe that the recognition
accuracy increases as more channels are involved. The EER has
decreased from 17.1% to 11.0% if using four channels. These results
validate the effectiveness and benefits of using multiple channel
audio for audio attack detection.
Impact of Phase Information. To investigate the impact of
the phase information on the system, we modify the structure of the
proposed Type I network to only involve magnitude spectrograms
and evaluate its impact on the models’ performance. We get a
4The suggested data separation for the ReMASC dataset is shown in Appendix Table 11.
Figure 11: Results with different number of channels.
recognition accuracy of 96.3%, 87.9%, 73.1% and EER of 8.6%, 11.4%,
29.2% for device 1, 2, and 3, respectively. Compared to the model
that uses both magnitude and phase spectrogram as input, the
average EER is increased by 38.8%. This result validates that the
phase spectrogram can serve as complementary information in
addition to the magnitude spectrogram to help further improve the
performance of audio attack detection.
7.6 Model Interpretability Analysis
We further investigate the interpretability of our approach by visual-
izing the saliency map of the model and its learned representations.
Visualization of Saliency Map. We use the gradient-weighted
class activation map (Grad-CAM) to visualize the decision-making
process of the proposed deep learning model. Specifically, Grad-
CAM uses the gradient of the target class to produce a localization
map to highlight the important regions in the input feature map
used by the model to make the prediction, allowing us to visualize
the attention of the model. Figure 12 shows two examples of Gram-
CAM generated from our model, where the three columns from
left to right are the magnitude spectrogram of input, the generated
CAM image, and the CAM overlaid on the spectrogram. We can
observe that the most discriminative region on which the model
mainly focuses is the low-frequency region, with some attention
also being paid to the high-frequency noises. These findings are
well-correlated with previous studies on discriminative frequency
regions for replay attack detection [9, 12, 76], which demonstrates
the effectiveness of the proposed learning-based approach.
Visualization of Learned Representations. To investigate
the learned representations, we randomly select 20 audio samples
from the genuine speech and each type of the audio attacks recorded
using device 1 and compute the output of the first layer in the clas-
sifier of our Type I model as the embeddings. We first use Principle
Component Analysis (PCA) [77] to reduce the dimensionality of
each embedding to 100 and then use t-distributed Stochastic Neigh-
bor Embedding (t-SNE) [70] to visualize the embeddings on a 2D
plane. The visualization result is shown in Figure 13. From the
figure, we can see that the genuine and attack audio samples are
well-clustered, which verifies the model’s ability to extract discrim-
inative features. In addition, although the model is not trained to
distinguish different audio attacks, we are still able to observe some
patterns between different types of attacks. In particular, among all
considered attacks, synthesis attack can produce audio samples that
are the closest to genuine speech in the learned manifold, which
shows that the deep learning-powered speech synthesizer used in
our attack implementation can generate lifelike speech samples
that resemble human speech.
1234Number of Channels Used1012141618Equal Error Rate (%)8688909294Recognition Accuracy (%)Equal Error RateAccuracySession 6C: Audio Systems and Autonomous Driving CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1895Figure 12: Visualization of the discriminative regions using
Grad-CAM [45].
8 DISCUSSION
Integration with Intelligent Audio Systems. The developed au-
dio attack detection models can be integrated into commercial intel-
ligent audio systems with few or no modifications required on the
hardware. Besides standalone intelligent audio systems (e.g., smart
speakers), mobile intelligent audio systems such as smartphones
also come equipped with multiple microphones for stereo recording
and noise/reverberation cancellation. Since the microphone array
on smartphones (usually located at the top and bottom of the phone
frame) is of similar dimension with the 2-channel device (Google
AIY voice kit) used in our experiments, we expect that our model
can be easily adapted to smartphone use. Moreover, the model can
be simply inserted at the beginning of the inference pipeline to
check the legitimacy of the audio input before it reaches the speech
or speaker recognition model. Depending on the application sce-
nario as well as the capability of the system, the detection process
can be executed either via cloud-based services or directly on the
device. The proposed Type I model is desirable for cloud servers
with sufficient computational power for achieving the maximum
detection accuracy. In addition, the model can be used in paral-
lel with other optimization components (e.g., attention module)
and neural-based countermeasure models to potentially improve
performance. For systems that have limited communication band-
width or scenarios with rigorous privacy requirements, the data
can also be processed locally. To support on-device inference on
voice-controllable mobile and IoT devices that have constrained
storage and computational resources, the audio attack detection
model should be as compact and energy-efficient as possible. In this
study, we provide a fast and lightweight Type II network, which
is approximately 12× lighter and 1.5× faster compared to the pro-
posed Type I network with slightly compromised performance as
an option for resource-constrained devices. For future work, model
compression [18, 38] and acceleration [16, 34] techniques can be
adopted to further improve the efficiency of the model.
Potential Evasion. Grounded on a data-driven approach, the
effectiveness of the proposed model requires collecting samples
from existing audio attack methods for attack profiling. Thus, a so-
phisticated attacker with the ability to access the established profile
may leverage this knowledge to design adaptive attacks to bypass
the system. For instance, crafting an attack audio sample that is
close to the genuine audio samples in the learned representation
space may force the model to falsely accept it. However, launching
such an adaptive attack in practice still faces several challenges.
First, the attacker cannot directly regulate the received signal in
Figure 13: Visualization of the learned representation using
t-SNE [70].
its digital form as the model only accepts signals received through
the physical channel (i.e., picked up by the microphone array) as
valid inputs, while propagating in the physical environments will in-
evitably leave a certain level of traceable patterns to the audio signal.
Although injecting signals via other modalities such as laser [57]
may alleviate the distortion incurred by the over-the-air propaga-
tion, such attack only injects signal to one microphone channel
at a time and therefore can be defended by cross-checking signals
from all microphone channels before executing the command. An
attacker may also attempt to evade detection by manipulating the
sound field with multiple playback devices (e.g., a pair of stereo
loudspeakers or a multi-channel surround sound system) to control
the received signal in each microphone [64, 65]. However, precise
manipulation of the signal received by each microphone channel
is hard to achieve due to the low directionality and diffraction of
sound. In addition, such attacks still involve the same recording
and playback process which will cause distortions to be projected
into the magnitude and phase domain. Moreover, solely defeating
the detection model isn’t sufficient. Since our model is proposed
as an add-on module before the actual audio processing model
(e.g., speech or speaker recognition model), the attacker needs to
bypass both models to achieve a successful attack, which remains
challenging in practice.
9 CONCLUSION
In this paper, we propose a holistic solution for detecting machine-
induced audio attacks by leveraging the readily available micro-
phone array on modern intelligent audio systems. We utilize the
magnitude and phase information derived from multi-channel audio
and train a deep learning model to capture the fundamental differ-
ence between human speech and adversarial audio launched from
playback devices. To improve the generalizability to new acoustic
environments, we use unsupervised domain adaptation to help the
model learn to extract domain-invariant features. We also develop a
more compact model that’s suitable for resource-constrained mobile
and IoT devices. Extensive experiments on a public multi-channel
replay attack dataset and a self-collected advanced audio attack
dataset show that the proposed method can achieve an EER as
low as 6.6% for detecting a variety of audio attacks and still main-
tains a relatively high recognition accuracy even in the challenging
environment-independent case.
ACKNOWLEDGMENTS
We would like to thank the anonymous reviewers for their insight-
ful feedback. This work is supported in part by National Science
Foundation grants CNS2114161, CNS2114220, CCF1909963, and
CCF2028876, and Air Force Research Lab grant FA87501820058.
GenuineSpectrogramCAMCAM on SpectrogramReplayed−20−15−10−505101520Dimension 1−15−10−50510Dimension 2AdversarialInaudibleHVCGenuineModulatedSynthesisSession 6C: Audio Systems and Autonomous Driving CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1896REFERENCES
[1] 2020. Google Text-to-Speech. (2020). https://cloud.google.com/text-to-speech/
docs
com/demo
vifa/
[2] 2021. Hidden Voice Commands. (2021). https://www.hiddenvoicecommands.
[3] 2021. The LJ Speech Dataset. (2021). https://keithito.com/LJ-Speech-Dataset/
[4] 2021. Practical Hidden Voice Attacks against Speech and Speaker Recognition
Systems. (2021). https://sites.google.com/view/practicalhiddenvoice/home
[5] 2021. Ultrasonic Dynamic Speaker Vifa. (2021). http://www.avisoft.com/playback/
[6] 2021. ASVspoof 2021: Automatic Speaker Verification Spoofing and Countermea-
sures Challenge Evaluation Plan. (2021). https://www.asvspoof.org/asvspoof2021/
asvspoof2021_evaluation_plan.pdf
[7] Hadi Abdullah, Washington Garcia, Christian Peeters, Patrick Traynor, Kevin
R. B. Butler, and Joseph Wilson. 2019. Practical Hidden Voice Attacks against
Speech and Speaker Recognition Systems. (2019). arXiv:cs.CR/1904.05734
[8] Anup Agarwal, Mohit Jain, Pratyush Kumar, and Shwetak Patel. 2018. Oppor-
tunistic sensing with MIC arrays on smart speakers for distal interaction and
exercise tracking. In 2018 IEEE International Conference on Acoustics, Speech and
Signal Processing (ICASSP). IEEE, 6403–6407.
[9] Muhammad Ejaz Ahmed, Il-Youp Kwak, Jun Ho Huh, Iljoo Kim, Taekkyung Oh,
and Hyoungshick Kim. 2020. Void: A fast and light voice liveness detection system.
In 29th USENIX Security Symposium (USENIX Security 20). USENIX Association,
2685–2702. https://www.usenix.org/conference/usenixsecurity20/presentation/
ahmed-muhammad
[10] Jacob Benesty, Jingdong Chen, and Yiteng Huang. 2008. Microphone array signal
processing. Vol. 1. Springer Science & Business Media.
[11] Logan Blue, Hadi Abdullah, Luis Vargas, and Patrick Traynor. 2018. 2ma: Verifying
voice commands via two microphone authentication. In Proceedings of the 2018
on Asia Conference on Computer and Communications Security (ACM ASIA CCS).
89–100.
[12] Logan Blue, Luis Vargas, and Patrick Traynor. 2018. Hello, is it me you’re looking
for? differentiating between human and electronic speakers for voice interface
security. In Proceedings of the 11th ACM Conference on Security & Privacy in
Wireless and Mobile Networks. 123–133.
[13] Nicholas Carlini, Pratyush Mishra, Tavish Vaidya, Yuankai Zhang, Micah Sherr,
Clay Shields, David Wagner, and Wenchao Zhou. 2016. Hidden voice commands.
In 25th {USENIX} Security Symposium ({USENIX} Security 16). 513–530.
[14] Nicholas Carlini and David Wagner. 2018. Audio adversarial examples: Targeted
attacks on speech-to-text. In 2018 IEEE Security and Privacy Workshops (SPW).
IEEE, 1–7.
[15] Si Chen, Kui Ren, Sixu Piao, Cong Wang, Qian Wang, Jian Weng, Lu Su, and Aziz
Mohaisen. 2017. You can hear but you cannot steal: Defending against voice
impersonation attacks on smartphones. In 2017 IEEE 37th International Conference
on Distributed Computing Systems (ICDCS). IEEE, 183–195.
[16] Jian Cheng, Jiaxiang Wu, Cong Leng, Yuhang Wang, and Qinghao Hu. 2017.
Quantized CNN: A unified approach to accelerate and compress convolutional
networks. IEEE transactions on neural networks and learning systems 29, 10 (2017),
4730–4743.
[17] Phillip L De Leon, Michael Pucher, Junichi Yamagishi, Inma Hernaez, and Ibon
Saratxaga. 2012. Evaluation of speaker verification security and detection of
HMM-based synthetic speech. IEEE Transactions on Audio, Speech, and Language
Processing 20, 8 (2012), 2280–2290.
[18] Chunhua Deng, Siyu Liao, Yi Xie, Keshab K Parhi, Xuehai Qian, and Bo Yuan.
2018. PermDNN: Efficient compressed DNN architecture with permuted diagonal
matrices. In 2018 51st Annual IEEE/ACM International Symposium on Microarchi-
tecture (MICRO). IEEE, 189–202.
[19] Huan Feng, Kassem Fawaz, and Kang G Shin. 2017. Continuous authentication
for voice assistants. In Proceedings of the 23rd Annual International Conference on
Mobile Computing and Networking. 343–355.
[20] Yaroslav Ganin and Victor Lempitsky. 2015. Unsupervised domain adaptation by
backpropagation. In International conference on machine learning. PMLR, 1180–
1189.
[21] Yang Gao, Yincheng Jin, Jagmohan Chauhan, Seokmin Choi, Jiyang Li, and Zhan-
peng Jin. 2021. Voice In Ear: Spoofing-Resistant and Passphrase-Independent
Body Sound Authentication. Proceedings of the ACM on Interactive, Mobile, Wear-
able and Ubiquitous Technologies 5, 1 (2021), 1–25.
[22] Yuan Gong, Jian Yang, Jacob Huber, Mitchell MacKnight, and Christian
Poellabauer. 2019. ReMASC: realistic replay attack corpus for voice controlled
systems. arXiv preprint arXiv:1904.03365 (2019).
[23] Yuan Gong, Jian Yang, and Christian Poellabauer. 2020. Detecting Replay Attacks
IEEE Signal
Using Multi-Channel Audio: A Neural Network-Based Method.
Processing Letters 27 (2020), 920–924.
[24] Cemal Hanilçi. 2017. Features and classifiers for replay spoofing attack detection.
In 2017 10Th international conference on electrical and electronics engineering
(ELECO). IEEE, 1187–1191.
[25] Awni Hannun, Carl Case, Jared Casper, Bryan Catanzaro, Greg Diamos, Erich
Elsen, Ryan Prenger, Sanjeev Satheesh, Shubho Sengupta, Adam Coates, and
Andrew Y. Ng. 2014. Deep Speech: Scaling up end-to-end speech recognition.
(2014). arXiv:cs.CL/1412.5567
[26] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual
learning for image recognition. In Proceedings of the IEEE conference on computer
vision and pattern recognition. 770–778.
[27] Yitao He, Junyu Bian, Xinyu Tong, Zihui Qian, Wei Zhu, Xiaohua Tian, and
Xinbing Wang. 2019. Canceling inaudible voice commands against voice control
systems. In The 25th Annual International Conference on Mobile Computing and
Networking. 1–15.
[28] Andrew G Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun
Wang, Tobias Weyand, Marco Andreetto, and Hartwig Adam. 2017. Mobilenets:
Efficient convolutional neural networks for mobile vision applications. arXiv
preprint arXiv:1704.04861 (2017).
[29] Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q Weinberger.
2017. Densely connected convolutional networks. In Proceedings of the IEEE
conference on computer vision and pattern recognition. 4700–4708.
[30] Shehzeen Hussain, Paarth Neekhara, Shlomo Dubnov, Julian McAuley, and Fari-
naz Koushanfar. 2021. WaveGuard: Understanding and Mitigating Audio Adver-
sarial Examples. arXiv preprint arXiv:2103.03344 (2021).
[31] Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic opti-
mization. arXiv preprint arXiv:1412.6980 (2014).
[32] Tomi Kinnunen, Md Sahidullah, Héctor Delgado, Massimiliano Todisco, Nicholas
Evans, Junichi Yamagishi, and Kong Aik Lee. 2017. The ASVspoof 2017 challenge:
Assessing the limits of replay spoofing attack detection. (2017).
[33] Phillip L De Leon, Bryan Stewart, and Junichi Yamagishi. 2012. Synthetic speech
discrimination using pitch pattern statistics derived from image analysis. In Thir-
teenth Annual Conference of the International Speech Communication Association.
[34] En Li, Liekang Zeng, Zhi Zhou, and Xu Chen. 2019. Edge AI: On-demand accel-
erating deep neural network inference via edge computing. IEEE Transactions on
Wireless Communications 19, 1 (2019), 447–457.
[35] Zhuohang Li, Cong Shi, Yi Xie, Jian Liu, Bo Yuan, and Yingying Chen. 2020.
Practical adversarial attacks against speaker recognition systems. In Proceedings
of the 21st International Workshop on Mobile Computing Systems and Applications.
9–14.
[36] Zhuohang Li, Yi Wu, Jian Liu, Yingying Chen, and Bo Yuan. 2020. AdvPulse:
Universal, Synchronization-free, and Targeted Audio Adversarial Attacks via
Subsecond Perturbations. In Proceedings of the 2020 ACM SIGSAC Conference on
Computer and Communications Security. 1121–1134.
[37] Meng Liu, Longbiao Wang, Jianwu Dang, Seiichi Nakagawa, Haotian Guan,
and Xiangang Li. 2019. Replay attack detection using magnitude and phase
information with attention-based adaptive filters. In ICASSP 2019-2019 IEEE
International Conference on Acoustics, Speech and Signal Processing (ICASSP).
IEEE, 6201–6205.
[38] Zhuang Liu, Mingjie Sun, Tinghui Zhou, Gao Huang, and Trevor Darrell. 2018.
Rethinking the value of network pruning. arXiv preprint arXiv:1810.05270 (2018).
[39] Dibya Mukhopadhyay, Maliheh Shirvanian, and Nitesh Saxena. 2015. All your
voices are belong to us: Stealing voices to fool humans and machines. In European
Symposium on Research in Computer Security. Springer, 599–621.
[40] Alan V Oppenheim, John R Buck, and Ronald W Schafer. 2001. Discrete-time
signal processing. Vol. 2. Upper Saddle River, NJ: Prentice Hall.
[41] Nirupam Roy, Sheng Shen, Haitham Hassanieh, and Romit Roy Choudhury.
2018. Inaudible voice commands: The long-range attack and defense. In 15th
{USENIX} Symposium on Networked Systems Design and Implementation ({NSDI}
18). 547–560.
[42] Md Sahidullah, Tomi Kinnunen, and Cemal Hanilçi. 2015. A comparison of
features for synthetic speech detection. (2015).
[43] Jon Sanchez, Ibon Saratxaga, Inma Hernaez, Eva Navas, Daniel Erro, and Tuomo
Raitio. 2015. Toward a universal synthetic speech spoofing detection using phase
information. IEEE Transactions on Information Forensics and Security 10, 4 (2015),
810–820.
[44] Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-
Chieh Chen. 2018. Mobilenetv2: Inverted residuals and linear bottlenecks. In