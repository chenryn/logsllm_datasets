example, Avast AV software provides this functional-
ity by rerouting DNS requests from client machines
to its own DNS server in an encrypted channel [3].
In both cases, the resolvers are likely to be directly
controlled by operators behind malware and AV soft-
ware, which are hosted by cloud providers or dedi-
cated hosting services.
• Enterprise proxy. A large number of enterprises de-
ploy network proxies to regulate the trafﬁc between
employees’ devices and the Internet. Some proxies,
like Cisco Umbrella intelligent proxy [5], are able to
scrutinize DNS requests and determine whether the
corresponding web visits are allowed. Similar to the
AV setting, users are required to point their DNS re-
solvers to the proxy’s resolver.
Since the mapping between the IP addresses of re-
solvers and their owners is unknown to us, alternative re-
solvers owned by parties other than ISPs, like AV and en-
terprise resolvers, can be included by our study. Straight-
forward classiﬁcation using AS information is not always
reliable. For example, an enterprise resolver might be
mistakenly classiﬁed as an ISP resolver, if the enterprise
rents a subnet of the ISP. We are currently developing the
method to enable accurate resolver proﬁling to address
this issue.
3 Methodology and Dataset
In this section, we describe the methodology and data
collection of our study, which try to address the two
major challenges described in Section 1. We begin by
describing the high-level idea of our approach and the
design requirements it needs to meet. Then, we elabo-
rate the details of each component of our measurement
framework and how we obtain a large volume of glob-
ally distributed vantage points. Finally, ethical concerns
regarding our data collection are discussed.
illustrate our methodology of
3.1 Overview
We ﬁrst
identifying
DNSIntercept, which includes Request redirection, Re-
quest replication and Direct responding.
Approach. Detecting DNSIntercept is conceptually
simple. Recalling Normal resolution, upon receiving a
request from a client, a recursive resolver tries to contact
the authoritative nameserver for an answer, if the result
is not cached. However, as shown in Figure 3, when in-
terception takes place, requests forwarded by alternative
resolvers reach authoritative nameservers.
Therefore, our approach to identify interception con-
tains the following steps. We (1) instruct a client to send
a DNS request about one of our controlled domains to
a public resolver A; (2) record its corresponding request
at our authoritative nameservers, which originates from
recursive resolver B; and (3) compare A with B. As a
complementary step, we also (4) validate the response
eventually received by the client.
1116    27th USENIX Security Symposium
USENIX Association
Only when A matches B, the request is regarded as a
Normal resolution. Otherwise, for each request sent by
the client to public resolver A that gets a valid response, if
(1) no corresponding request is captured by authoritative
nameservers, we regard it as Direct responding; if (2) a
single request not from resolver A is captured, we regard
it as Request redirection; if (3) multiple identical requests
from resolvers, one of them being A, are captured, we
regard it as Request replication.
Design requirements. Our methodology should meet
several requirements to obtain valid results.
Firstly, the queried domain name of each request from
client should be different to avoid caching. Secondly, as
we capture packets separately from clients and authorita-
tive nameservers, we should be able to correlate a request
from client with the one captured by our authoritative
nameserver in the same resolution. As will be discussed
in Section 3.2, the two issues are addressed by uniquely
preﬁxing each requested domain name.
Thirdly, the clients in our study should be diverse, be-
ing able to send DNS packets directly to speciﬁed pub-
lic resolvers, even when local DNS resolvers have been
assigned by ISPs. Fourthly, aiming to study intercep-
tion characteristics in depth, the vantage points are ex-
pected to issue diversiﬁed DNS requests (e.g., requests
over different transport protocols and of different RR
types). The measurement infrastructure used by previous
works, including advertising networks [33], HTTP proxy
networks [19, 36, 37, 52] and Internet scanners [42, 48],
do not meet the requirements. How the two issues are
addressed will be discussed in Section 3.3.
Finally, public DNS services are accessed by clients
using anycast addresses (e.g., 8.8.8.8 of Google DNS).
These addresses rarely match the unicast addresses (e.g.,
74.125.41.0/24 of Google) when the requests are for-
warded to our authoritative nameservers. We propose a
novel method to identify the egress IPs of a public DNS
service, as will be elaborated in Section 3.2.
3.2 Methodology
Before presenting our methodology, we ﬁrst illustrate
an interception model with possible elements that inter-
ceptors may consider. On this basis, we elaborate our
methodology regarding how DNS requests are generated
and how egress IPs of public DNS services are identiﬁed.
Interception model. On-path devices are deployed to
inspect and manipulate DNS packets. We consider each
DNS packet to be represented by a tuple of ﬁve ﬁelds:
{Src IP, Dst IP, Protocol, RR Type, Requested Domain}
Each ﬁeld could decide how interception is actually
carried out. So, to understand DNSIntercept in a com-
prehensive way, we need DNS packets with diversiﬁed
ﬁeld values. To this end, we construct a client pool
with a large volume of source IPs (i.e., client IPs) dis-
tributed globally. Destination IPs point to our speci-
ﬁed public DNS resolvers.
Investigating all public re-
solvers would take a tremendous amount of time and
resources, so we narrow down to three representative
and widely-used public DNS services according to Alexa
trafﬁc ranking [57], including Google Public DNS [12],
OpenDNS [22] and Dynamic DNS [9]. As a supplement,
we also include a self-built public DNS service, named
EDU DNS, to make comparisons. Transport protocol can
be either TCP or UDP. As for resource record (RR), ﬁve
kinds of security-related records are considered [43], in-
cluding A, AAAA, CNAME, MX and NS. Lastly, we registered
four domains exclusively for our study, spanning four
TLDs including a new gTLD (com, net, org and club).
We avoid any sensitive keyword in the domain names.
Generating DNS requests. In this study, we need to ad-
dress the issue of the inconsistent source IPs between a
request from client and its corresponding request(s) sup-
posed to be launched by recursive resolvers. To this end,
we devise a method to link those requests through unique
domain preﬁx. The preﬁx includes a distinct UUID gen-
erated for each client (representing SrcIP) and a label of
public DNS service which is supposed to handle the res-
olution (representing DstIP). By considering RR Type at
the same time, we are able to identify DNS packets in the
same resolution. For instance, when a client launches a
DNS A-type request for UUID.Google.OurDomain.TL
D, this request is supposed to be handled by Google Pub-
lic DNS. Its corresponding request captured by author-
itative nameservers should be A-type as well and match
every label in the domain preﬁx.
Generating DNS responses. Under Request replica-
tion scenario, a client receives an in-band response and
an out-of-band response. We want to classify these
two cases but the regular response from the authorita-
tive nameservers cannot tell such difference. As such,
we need a reliable mechanism to link the response re-
ceived by the client to that from our authoritative name-
servers. Similar to the prior component, we encode a
unique nonce in the response. In particular, our author-
itative nameservers hash the timestamp, source address
and requested domain name together, and derive a unique
response from the hash string ﬁtting to the record type.
For instance, once receiving an A-type request, the re-
sponse is an IPv4 address converted from the hash value
(using the last 32 binary bits of the hash).
To notice, the response synthesized by this approach
might point the client to unwanted servers. For example,
the response IP could be used by botnet servers acciden-
tally. We want to emphasize that no actual harm will be
introduced to our vantage points, because clients’ actions
are no more than DNS lookups. There is no follow-up
connection to the servers.
USENIX Association
27th USENIX Security Symposium    1117
Resolvers are able to manipulate TTL value of a re-
sponse based on what is returned from authoritative
nameservers and their policies. We attempt to measure
this scenario by selecting a random TTL value between
1 and 86400.
Identifying egress IPs of public DNS. Our next task is
to identify whether a source IP contacting our authorita-
tive nameservers belongs to a public DNS service, i.e., is
an egress IP. From the client’s point of view, anycast ad-
dress is accessible, which essentially represents a proxy
in front of a set of recursive resolvers. Such design is for
load balancing. However, the unicast addresses of the
afﬁliated resolvers, which are observed by our authori-
tative nameservers, typically do not match their anycast
addresses. The ownership of the anycast addresses are
usually not known to public audiences. As such, we need
to infer the ownership.
Previous studies leveraged IP WHOIS data and infor-
mation from public forums [37,49] to identify egress IPs,
which are not sufﬁciently accurate when examined on
our data. We propose a more reliable method leverag-
ing DNS PTR and SOA record. Our method is based on
an assumption that, instead of scattered IP addresses, a
public DNS service tends to use addresses aggregated
in several network preﬁxes (e.g., /24 networks). There-
fore, for ease of management, identity information of an
IP address is usually embedded in PTR and SOA records
by network administrators. We validate this assumption
for the top 12 public DNS services according to Alexa
trafﬁc [57], from different vantage points in ﬁve ASes,
and ﬁnd all 12 DNS services embed identity information
in either PTR (e.g., Norton ConnectSafe) or SOA records
(e.g., Freenom), or both (e.g., OpenDNS). As an ex-
ample, responses from reverse lookups of egress IPs of
Google Public DNS are all dns-admin.google.com.
In practice, for an IP that contacts our authoritative
nameservers, we ﬁrst perform its reverse DNS lookup.
Subsequently, we recursively request the SOA record of
the responded domain name and build its SOA dependen-
cies (5 iterations), which is similar to [43]. If particular
SLDs (e.g., opendns.com) present in the dependency
chain, we regard the address as an egress IP of the cor-
responding public DNS service. For instance, the PTR
record of 45.76.11.166 (AS20473; Choopa, LLC) is
hivecast-234-usewr.as15135.net. The SOA record
of this domain name is ns0.dynamicnetworkservic
es.net, hence we regard 45.76.11.166 as an egress
IP of Dynamic DNS.
Using this method, we are able to infer ownership
of 85% addresses that contact our authoritative name-
servers. Meanwhile, compared to IP WHOIS method,
new egress ASes of public DNS services are discov-
ered by our method. For instance, AS20473 (for Dy-
namic DNS) and AS30607 (for OpenDNS) are found to
be egress ASes, yet they cannot be found with IP WHOIS
or BGP information.
Discussion. As discussed in Section 2.3, our methodol-
ogy may not be able to accurately distinguish whether an
interception is caused by network operators or other in-
terceptors. Secondly, by conﬁguring fake PTR and SOA
records for alternative resolvers, their egress IPs will not
be correctly identiﬁed. However, those furtive changes
should be observed from Passive DNS data, such as that
managed by Farsight [10] and DNS Pai [15]. At present,
we do not include Passive DNS data due to the access
limit and consider to include it in our future work. Mean-
while, PTR records have been proved to be a reliable
source to classify IP addresses in previous studies. As
an example, [48] used PTR records to identify domains
hosted on particular CDNs.
3.3 Vantage Points
Our study requires a large number of clients distributed
globally. Besides, our clients should be able to send
customized DNS requests about a domain to a speciﬁed
public resolver. To this end, we ﬁrst leverage a residen-
tial proxy network based on TCP SOCKS which allows us
to directly send DNS packets from globally-distributed
clients, to depict a global landscape of DNSIntercept
(this phase is named Global analysis). This exper-
iment, however, cannot reveal full characteristics of
DNSIntercept, because the proxy network does not al-
low us to change every ﬁeld of DNS request. Therefore,
we design another experiment in which we cooperate
with our industrial partner who develops security soft-
ware installed by millions of active users. We implement
a measurement script and integrate it to the software’s
network debugger module. When the change is deliv-
ered to the client, a consent is displayed and the script
is not executed until the client acknowledges the change.
As clients in this experiment are mainly from China, we
named it China-wide analysis.
Global analysis. Proxy networks have been used by pre-
vious studies as measurement vantage points [37, 52].
However, DNS requests from clients under those proxy
networks are only allowed to go to the pre-assigned local
DNS resolvers, which doesn’t satisfy our requirement.
To address the issue, we leverage a SOCKS proxy net-
work called ProxyRack [14], which allows us to send
customized DNS requests to any speciﬁed resolver over
TCP.
The network architecture of ProxyRack is shown in
Figure 4. It interacts with our measurement client with
a Super-proxy. When DNS packets are sent by our ma-
chine, they go to afﬁliated nodes and ﬁnally leave the net-
work from diverse exit nodes. The packets are forwarded
to the recursive resolvers which are supposed to contact
1118    27th USENIX Security Symposium
USENIX Association
Table 1: Statistics of collected dataset
Phase
Global
# Request # UUID
# IP
1,652,953 476,153 36,173
China-wide 4,584,413 400,491 112,305
# Country # AS
2,691
356
173
87
Figure 5: Format of collected data
In the phase of China-wide analysis, while sending re-
quests from a software client is more ﬂexible and efﬁ-
cient, we ought to limit the quantity of our requests to
avoid excessive trafﬁc. Therefore, for each client, we
consider two public DNS services, two TLDs, one trans-
fer protocol which are all randomly selected, and all ﬁve
RR types. In addition, we also send a single request to a
client’s assigned local DNS resolver.
3.4 Datasets
Table 1 summarizes our collected dataset in both phases.
In total, we obtain DNS trafﬁc from 148,478 distinct res-
idential and cellular IP addresses globally.
Format of dataset. Through launching DNS requests
from clients, monitoring DNS queries on authoritative
nameservers and capturing DNS responses, we are able
to “connect the dots” for each DNS resolution. To per-
form this correlation analysis, our collected data for each
DNS request is stored in a JSON format shown in Fig-
ure 5. For each client, we capture each request and
the corresponding response. At our authoritative name-
servers, we collect the arrival time and source IP of
the corresponding request(s), as well as the response re-
turned.
Geo-distribution of clients. Leveraging ProxyRack and
security software, we address the challenge of obtaining
clients globally. Here we use the geo-distribution [20]
of distinct IPs to give an evaluation of our clients.
In
Global analysis, our collected clients span more than
36K unique addresses in 173 countries. Figure 6 shows
the geo-distribution and our clients cover the majority of
countries in the world, with Korea, Russia, Japan and the
US topping the list. In China-wide analysis, the clients
we obtain are mostly from China, but still span 87 differ-
ent countries.
Figure 4: Network architecture of ProxyRack
our authoritative nameservers. Therefore our client pool
is in fact composed of those exit nodes. ProxyRack has
recruited more than 100K nodes [14], so we are able to
send DNS requests from nodes distributed globally to
public resolvers, and verify the responses, both by inter-
acting with the Super-proxy. However, ProxyRack only
accepts DNS requests over TCP, which is only used by a
small fraction of DNS requests in the real-world settings.
Therefore, we conduct the next experiment to measure