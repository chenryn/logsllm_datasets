business relationships.
Ambiguous Label Treatment. As briefly discussed in section 3,
two ASes can have different relationships based on the PoPs they
interconnect at [26]. In April 2018, the received validation data
contains multiple labels for 246 relationships involving 233 differ-
ent ASes. Arguably, those entries should be ignored for validation
unless the classification algorithm explicitly infers or handles them;
otherwise, it is ambiguous whether a simple relationship prediction
is correct. Interestingly, we find that those validation entries are
handled very differently in practice. If we treat an entry with mul-
tiple labels as P2P if it starts with P2P and otherwise as P2C, the
number of P2P and P2C links in the validation data for 2017 and
2018 matches exactly those reported in the Toposcope paper [38].
We observe a similar match for the numbers reported for 2017 in
the work by Jin et al. [36] if we treat an entry with multiple labels
always as P2C.
Sibling Labels. Sibling (S2S) relationships represent links be-
tween two ASes that belong to the same organization and, hence,
can use their resources interchangeably. When applying CAIDAâ€™s
AS-to-Organisation data set [33], we find that 210 relationships
in our validation data set and 2800 of the inferred relationships
are actually sibling relationships and should be ignored during the
validation process (unless specifically handled by the classification
algorithm).
5 IS OUR VALIDATION DATA BIASED?
Regional Imbalance. As briefly discussed in section 2, how an
AS routes traffic may depend on its geographic region. To analyze
regional bias, we first map each ASN to a geographic service region
using IANAâ€™s list of initial ASN assignments [34] and then refine
the mapping based on the daily delegation files published by the
Regional Internet Registries (RIRs) [2, 4, 6, 41, 58]. We abbreviate
AFRINIC, APNIC, ARIN, LACNIC, and RIPE NCC as AF, AP, AR,
L, and R, respectively. While IANAâ€™s list bootstraps the mapping
for all ASes, the RIR delegation files correct the mapping for re-
sources transferred between different regions after IANAâ€™s initial
assignments [55]. Notably, no mapping from ASes to geographical
regions is perfect; even with large amounts of active scanning, we
would neither be able to reliably measure all IPs (and respectively
infrastructure) that belong to an AS [8] nor would we be able to
perfectly geolocate them [15]. Yet, we argue that our mappingâ€”
which relies on an ASâ€™ organizational service region rather than its
614
IMC â€™21, November 2â€“4, 2021, Virtual Event, USA
Prehn, Lars and Feldmann, Anja
Figure 1: Regional imbalance: Fraction of
links (top) and validation coverage (bottom)
per geographical group with AF, AP, AR, L,
and R denoting AFRINIC, APNIC, ARIN, LAC-
NIC, and RIPE, respectively.
Figure 2: Topological imbalance: Fraction
of links (top) and validation coverage (bot-
tom) per topological group with H, S, T1, and
TR denoting Hypergiants, Stub ASes, Tier-1
providers, and Transit providers, respectively.
Figure 3: Transit degree imbalance for
transit links: consistently colored heatmaps
for inferred (top) and validatable (bottom)
links, binned by the transit degree of their
incident ASes.
infrastructure footprintâ€”is still representative enough to provide
hints on regional biases, if they really exist.
Using this mapping, we separate AS links into different link
classes: If one of the involved ASes is reserved, we discard the link.
If both ASes belong to the same region, we mark the link class
as Â° (e.g., AFÂ° for links between two ASes in AFRINIC).
If the ASes belong to different regions, we mark the link class as
- where  is always the lexicographi-
cally smaller region, i.e., we treat AS links as undirected links.
Figure 1 shows the distribution of inferred relationships onto
link classes as fractions (at the top) as well as the validation cov-
erage (at the bottom), i.e., the fraction of links in a class for which
we have validation labels. We observe that most (~79 %) of the rela-
tionships that we infer are between ASes of the same region. Yet,
we observe drastic differences for the validation coverage among
region-internal relationships: Even though we infer roughly the
same number of ARÂ° and LÂ° relationships, we validate more than
~31 % of ARÂ° links but less than 1 % of LÂ° links.
Topological Imbalance. Next, we focus on whether the posi-
tioning of an AS in the Internetâ€™s hierarchical structure yields a
mismatch in bias. First, we classify each AS into either "Stub" or
"Transit" based on whether the AS has at least one other AS in
its customer cone (see CAIDAâ€™s customer cone data setâ€”available
at [12]). Afterwards, we refine this basic mapping using two ad-
ditional data sources: We re-classify ASes as (i) "Tier-1" providers
based on a list from Wikipedia [63]6 and (ii) "Hypergiants" (i.e., the
largest content providers) based on the list generated by BÃ¶ttger et
al. [10].
Figure 2 shows the topological balance based on those classes in
a similar style as Figure 1. We observe that we only have substan-
tial validation data for classes that involve Tier-1 ASes. While this
6which largely overlaps with the set of clique ASes inferred by ASRank.
615
insight in itself is not very new (compare [43] and [36]), we find
its impact to be more drastic than previously reported: For our two
majority classes, S-TR and TRÂ°, that, in summary, contain 82 % of
all inferred links, we can only validate 6 % and 12 % of relationships,
respectively.
While most of the inferred links are in the S-TR class, this class
is rather uninteresting as it largely consists of P2C relationships
(67.8% according to validation data) for which all three classifiers
are well-known to perform near-perfect. Thus, we drill deeper into
our second largest class, links between Transit providers.
In particular, we want to understand whether the distribution of
AS "size" matches between inferred and validated TRÂ° links. Figure 3
shows a heatmap over all TRÂ° links in the inferred data (top) and the
validated data (bottom) where the x-axis shows the transit degree
for the larger incident AS while the y-axis shows the transit degree
for the smaller incident AS.7 We observe that the vast majority of
TRÂ° links that we infer are between relatively small transit ASes
(i.e., in the left-bottom corner). This mismatches with the more
uniform distribution of our validation data. We further repeated
this experiment with two alternative metrics: the provider-peer-
observed customer coneâ€”which relies on the correctness of the
inferred business relationships and might hence be biasedâ€”and the
node degree. The related figures (which can be found in Appendix
B) suggest an even stronger mismatch.
6 IS OUR VALIDATION BIASED?
Now that we have a basic understanding of regional and topologi-
cal bias mismatches in our validation data, we analyze how such
mismatches translate to differences in classification correctness. For
each of the tested classifiers, we calculate two confusion matrices
7The row above 150 and the column to the right of 1500 catch all transit degree equal of
larger than 150 and 1500, respectively. This prevents the few ASes with a substantially
larger transit degree from distorting the plot.
Links (share)0.390.150.140.080.080.060.030.020.020.010.01RÂ°ARÂ°LÂ°APÂ°AR-RAP-RAP-ARAF-RAR-LAFÂ°L-RVal. Cov.0.150.310.000.050.320.070.170.040.180.000.08Links (share)0.480.340.070.040.040.020.010.00S-TRTRÂ°S-T1SÂ°T1-TRH-TRH-SH-T1Val. Cov.0.060.120.740.000.740.070.000.5850100150Smaller Transit DegreeInference50010001500Larger Transit Degree50100150Validation0.0050.040.080.12Fraction of linksHow biased is our Validation (Data) for AS Relationships?
IMC â€™21, November 2â€“4, 2021, Virtual Event, USA
Class
ğ‘ƒğ‘ƒğ‘‰ğ‘ƒ ğ‘‡ ğ‘ƒğ‘…ğ‘ƒ
TotalÂ°
0.982
AP-AR 0.979
0.985
AP-R
APÂ°
0.992
0.930
AR-L
AR-R
0.956
0.926
ARÂ°
RÂ°
0.990
0.000
S-T1
S-TR
0.994
0.839
T1-TR
TRÂ°
0.991
ğ¿ğ¶ğ‘ƒ
0.990 14216
546
0.979
892
0.987
0.992
502
43
0.976
1752
0.978
617
0.954
0.996
9587
26
0.000
2538
0.988
0.955
641
0.996 10219
ğ‘ƒğ‘ƒğ‘‰ğ¶ ğ‘‡ ğ‘ƒğ‘…ğ¶
0.996
0.988
0.968
0.994
0.999
0.994
0.998
0.995
0.999
0.995
0.996
0.980
ğ¿ğ¶ğ¶ MMC
0.980
0.967
0.952
0.986
0.950
0.957
0.937
0.985
-0.001
0.987
0.886
0.959
0.992 30105
928
0.988
338
0.965
0.994
648
872
0.997
0.987
5707
0.996 12871
0.989
8318
0.999 15533
5334
0.997
7260
0.985
0.952
1822
Class
ğ‘ƒğ‘ƒğ‘‰ğ‘ƒ ğ‘‡ ğ‘ƒğ‘…ğ‘ƒ
TotalÂ°
0.966
AP-AR 0.973
0.973
AP-R
APÂ°
0.976
0.619
AR-L
AR-R
0.953
0.951
ARÂ°
RÂ°
0.971
0.295
S-T1
S-TR
0.980
0.718
T1-TR
TRÂ°
0.982
ğ¿ğ¶ğ‘ƒ
0.976 14216
546
0.939
892
0.995
0.989
502
43
0.975
1752
0.951
617
0.859
0.988
9587
26
0.650
2538
0.987
0.670
641
0.996 10219
ğ‘ƒğ‘ƒğ‘‰ğ¶ ğ‘‡ ğ‘ƒğ‘…ğ¶
0.988
0.960
0.986
0.991
0.998
0.984
0.993
0.985
0.999
0.994
0.971
0.978