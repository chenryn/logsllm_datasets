**Samza**：samza是一个分布式的流式数据处理框架（streaming
processing），它是基于Kafka消息队列来实现类实时的流式数据处理的。
**Spark Streaming**：Spark
Streaming是一种构建在Spark上的实时计算框架，它扩展了Spark处理大规模流式数据的能力。
**（10）批处理技术**
**MapReduce**：MapReduce是一种编程模型，用于大规模数据集（大于1TB）的并行运算。概念\"Map（映射）\"和\"Reduce（归约）\"，是它们的主要思想，都是从函数式编程语言里借来的，还有从矢量编程语言里借来的特性。它极大地方便了编程人员在不会分布式并行编程的情况下，将自己的程序运行在分布式系统上。
当前的软件实现是指定一个Map（映射）函数，用来把一组键值对映射成一组新的键值对，指定并发的Reduce（归约）函数，用来保证所有映射的键值对中的每一个共享相同的键组。
**（11）迭代式技术**
**Pregel**：Pregel是一个用于分布式图计算的计算框架，主要用于图遍历（BFS）、最短路径（SSSP）、PageRank计算等等。
**Giraph**：Giraph是一个迭代的图计算系统。Giraph计算的输入是由点和直连的边组成的图。
**GraphX**：Spark GraphX是一个分布式图处理框架，Spark
GraphX基于Spark平台提供对图计算和图挖掘简洁易用的而丰富多彩的接口，极大的方便了大家对分布式图处理的需求。
**Hama**：Apache Hama是一个纯BSP（Bulk Synchronous
Parallel）计算框架，模仿了Google的Pregel。用来处理大规模的科学计算，特别是矩阵和图计算。
**（12）引擎技术**
**Spark**：Spark是一种数据处理引擎。它声称，用在内存中时，其速度比MapReduce最多快100倍；用在磁盘上时，其速度比MapReduce最多快10倍。它可以与Hadoop和Apache
Mesos一起使用，也可以独立使用。
**Flink**：Apache
Flink是一个可伸缩的开源批处理和流处理平台。其核心模块是一个数据流引擎，该引擎在分布式的流数据处理的基础上提供数据分发、交流、以及容错的功能
**（13）数据存储技术**
**ACID**：指数据库事务正确执行的四个基本要素的缩写。包含：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）。一个支持事务（Transaction）的数据库，必需要具有这四种特性，否则在事务过程（Transaction
processing）当中无法保证数据的正确性，交易过程极可能达不到交易方的要求。
键值存储
**Dynamo**：Dynamo是亚马逊的key-value模式的存储平台，可用性和扩展性都很好，性能也不错：读写访问中99.9%的响应时间都在300ms内。
**Cassandra**：这种NoSQL数据库最初由Facebook开发，现已被1500多家企业组织使用，包括苹果、欧洲原子核研究组织（CERN）、康卡斯特、电子港湾、GitHub、GoDaddy、Hulu、Instagram、Intuit、Netfilx、Reddit及其他机构。它能支持超大规模集群；比如说，苹果部署的Cassandra系统就包括75000多个节点，拥有的数据量超过10
PB。
**Voldemort**：Voldemort是一个分布式键值存储系统，是Amazon's
Dynamo的一个开源克隆。
**（14）列存储技术**
BigTable：BigTable是Google设计的分布式数据存储系统，用来处理海量的数据的一种非关系型的数据库。
Hbase：HBase是为有数十亿行和数百万列的超大表设计的，这是一种分布式数据库，可以对大数据进行随机性的实时读取/写入访问。它有点类似谷歌的Bigtable，不过基于Hadoop和Hadoop分布式文件系统（HDFS）而建。
Hypertable：Hypertable是一种与Hadoop兼容的大数据数据库，承诺性能超高，其用户包括电子港湾、百度、高朋、Yelp及另外许多互联网公司。提供商业支持服务。
**（15）图存储技术**
**Neo4j**：Neo4j自称是"速度最快、扩展性最佳的原生图形数据库"，它承诺具有大规模扩展性、快速的密码查询性能和经过改进的开发效率。用户包括电子港湾、必能宝（Pitney
Bowes）、沃尔玛、德国汉莎航空公司和CrunchBase。
**Titan**：Titan
是一个在服务器集群搭建的分布式的图形数据库，特别为存储和处理大规模图形而优化。集群很容易扩展以支持更大的数据集，Titan有一个很好的插件式性能，这个性能让它搭建在一些成熟的数据库技术上像
Apache Cassandra、Apache HBase、 Oracle
BerkeleyDB。插件式索引架构可以整合 ElasticSearch 和Lucene技术。内置实现
Blueprints graph API，支持 TinkerPop所有的技术。
**（16）文档存储技术**
**CouchDB**：CouchDB 是一个开源的面向文档的数据库管理系统，可以通过
RESTful JavaScript Object Notation (JSON) API 访问。术语 "Couch" 是
"Cluster Of Unreliable Commodity Hardware" 的首字母缩写，它反映了
CouchDB
的目标具有高度可伸缩性，提供了高可用性和高可靠性，即使运行在容易出现故障的硬件上也是如此。
**MongoDB**：:
是目前非常流行的一种非关系型(NoSQL)数据库。MongoDB是一个面向文档的数据库,目前由10gen开发并维护,它的功能丰富,齐全。
# 统一日志管理需求分析
## 全面的日志采集需求
对全网设备、应用以及网络中的各类操作进行全面的日志采集。收集各种网络设备上的日志数据，将日志数据收集，实时监控系统事件，并根据设定条件对日志数据进行过滤，同时将无序杂乱的非结构化的日志转换成结构化数据提供统一管理方式，实现日志的日志持久化、标准化存储。
日志中心能够完成如下格式日志的采集：
日志中心主要完成如下类型的日志：
## 运维可用性监控及应用性能监控需求
用户通过日志对网络设备、服务器及应用程序状态实时监控，迅速定位问题根源，可以通过日志对应用程序性能实时监控，及时发现性能瓶颈。并且能够关联不同系统或模块的日志，进行端到端的服务监控和故障排查。监控全网设备中的各种设备服务使用情况，使运工作人员可以方便查看网络设备各种服务是否正常启动及运行状态，出现异常时可以报警提醒工作人员。
## 安全信息与事件管理需求
能够通过服务器日志发现端口扫描和非法入侵信息。查看防火墙、网络设备、服务器日志来进行安全跟踪分析为信息安全合规审计提供数据依据。
## 事件关联分析需求
事件关联是同时使用来自各种设备或者应用程序的多个日志。通过事件关联来确定发生了很么事情。例如：假设找到内部路由器日志上的一条可疑目录，该条目录涉及到一个主机设备，搜索网络防火墙的日志中提供关于该行为的更多信息的条目。事件关联的另一个用处是将事件进行彼此关联，如果邮件服务器受到攻击，可搜索来自交换机、防火墙和其他设备的各种网路日志，以此来寻找任何与该攻击事件的相关证据。
对于来自各个资源的日志信息，提供多维的关联分
析功能。面向系统用户，将一个用户在多个设备上的操作进行横向关联分析，形成以用户为主题的操作行为审计；面向特定安全事件，对于发生在多个设备上的事件痕迹进行关联分析，形成一个完整的事件相关操作过程，从设备角度，形成本设备全部访问情况的安全审计报告。
## 在线业务统计分析需求
通过日志统计业务系统的使用情况，访问核心关键用户，业务系统访问量的时间趋势与访问用户分布状态，分析计算业务系统核心操作的交互响应时间，统计操作成功失败次数与操作用户来源，并分析操作失败原因，
收集并分析业务系统运行各类错误、告警信息，展示错误数量的时间趋势与错误信息的分布状态。将错误告警推送至消息中心进行统一处理，结合大数据技术提供更全面、更及时、更准确的历史日志、实时日志和智能分析结果。
## 日志快速检索需求
对海量日志信息进行组合条件检索查询，真正实现了即查即显。查询结果根据归一化后的格式展现。同时为具有一定专业知识的运维人员提供归一化日志与原始日志同屏显示功能，运维人员可以更深入的分析原始日志数据。支持多条件日志检索查询；支持原始日志全文检索。
## 日志统一存储需求
原始日志信息是来自网络的第一手数据，需要长期存储，
并确保它们的完整性、保密性，不得随意访问、修改和删除。同时，由于日志量较大，应提供压缩存储机制。
传统的日志采集方式大多采用数据库或者EMC存储设备来存储海量的日志信息，数据库的存储方式无法适应TB级海量日志，同事数据库的schema无法适应千变万化的日志格式，无法提供全文检索。同时使用昂贵的EMC存储来保存日志在运维成本上很难接受。
## 符合标准政策规定内控需求
满足公安部82号令对日志的相关要求，并且根据Sox法案对企业内控的要求，强调通过内部控制加强公司治理，其中，IT系统内部控制就是面向具体的业务，日志是紧密围绕信息安全审计这一核心的。
## 业务审计需求
通过在业务主机上安装轻量级的Agent，将业务日志实时的送到日志中心，真实的还原业务的访问过程，精准的分析业务流程的时延，基于多种维度统计用户的访问习惯，用户的终端类型、访问时间、地理区域及运营商接入情况。精准的识别基于业务逻辑的攻击行为，对不符合业务流程的访问行为进行提取。为工作人员提供清晰的可视化的业务分析报表和业务攻击告警。
同时满足审计记录的规范化的需求，由于全网设备种类繁多，各设备日志信息存储格
式、字段含义、通信协议差异较大。需要对采集到的各种设备日志进行归一化处理，提取审计记录完整信息，为后续审计分析提供依据。
## 其他数据分析支撑需求
通过日志中心，可以为i6000、S6000、大数据分析平台等系统实时提供统一、规范、全面、完整、准确的日志数据和分析结果，为用户安全行为审计整体结构的实现提供分析数据来源。
# 总体架构
结合国网公司的特点及日志管理工作现状，日志中心采用集群式部署方式，总体架构如下图所示：
Agent
图1日志中心总体架构图
图1 总体架构图
总体构架包含四层，每层功能概述如下：
-   日志采集层：日志中心依据日志采集规范通过Agent、Syslog、ODBC、SNMP
    Trap、Socket、File等多种接口，采集各设备、系统和应用的本地型日志等；通过镜像等方式采集网络型日志，通过两种采集方式的合理配置，实现全部设备和资源的日志采集。
-   日志存储、加工层：实现日志的持久化、结构化存储，统一日志格式，并根据规则、策略库，对日志进行加工处理，结合资产信息实现日志信息的关联。
-   应用与展现层：实现系统管理、策略制定、规则制定、关键业务参数配置等基本业务功能，提供常用的告警分析场景，实现海量日志的快速查询，并提供对外接口服务。
-   物理层：采用分布式集群方式，在云平台环境下搭建日志中心环境，借助云计算机能力和存储的弹性扩展能力为日志中心提供可靠的运行环境。
功能说明：
1、日志中心采用主动采集被动收集两种方式实现日志采集功能，agent能自动增量读取日志文件，文件夹中批量日志文件，以及关系型数据库中的日志信息，能自动获取eventlog日志，并具有14:1的高压缩传输比，大大降低网络带宽消耗，另外，网络设备、安全设备可以通过syslog／rsyslog／snmptrap
方式主动发送日志到日志中心平台；对于业务系统特殊日志接口协议，通过定制开发，也可以快速实现接入。
2.日志上传到日志中心集群collector后，collector转发到kafka消息队列中，Kafka依据传递的日志类型对日志进行分析处理，并将消息队列中的日志消息通过Zookeeper的"资源同步协调"功能实现集群中各节点的数据同步功能。
3.日志中心将日志解析规则保存到持久化数据库中，用于spark对日志的解析与计算操作。
4.Spark从kafka消息队列中读取原始日志信息，由Master派发任务给Worker，进行结构化匹配，提取相关字段，按照日志解析规则进行处理，最后将处理后的日志回传到kafka的消息队列中。
5.日志中心搜索引擎从消息队列中读取结构化后日志，建立索引存储分布式文件系统中
6.日志中心搜索引擎采用分片及副本方式，并能根据日志类型，设定日志保存天数。
7.日志中心提供丰富的restful接口，极大方便系统进行二次开发。
8、日志管理中心实现对日志检索查询与分析展示的核心应用，它提供了对外统一的使用界面和应用接口。
9、其他来源日志包括;业务系统日志、用户行为审计日志等。
# 技术构架
日志中心采用的技术架构如下图所示：
图2 日志中心技术架构图
图2 技术架构图
## 日志采集技术
日志采集主要通过主动采集和被动收集两种方式实现。
通过heka的个性化定制开发，可以以终端代理的方式，实现对各类日志源的统一收集、数据补全和转发处理。
Heka
是一个高可扩展的数据收集和处理工具。它的可扩展性不仅仅是体现在程序本身可以进行插件开发、更可以方便的通过添加机器进行水平扩展。Heka是一个使用Go语言开发的工具，大量使用了Go的goroutine并发和channel通信，Heka程序的可扩展性体现在它的插件开发上。可开发的4种插件分别是：Input、Decoder、Filter、Output。通过Heka
用来收集和整理来自多个不同来源的日志信息，通过对各类日志进行收集和整理后发送结果到原始日志存储模块。Heka的
Agent/Router架构如下图：
图3 Agent/Router架构
heka在对日志整理的过程中可增加对日志描述的多个TAG标签，并对日志进行数据补全操作后发送至日志收集模块。
对heka进行插件开发，以满足对不同日志的整理需求。例如：对于多行日志的处理可以在heka中设定每条日志的分割标识，从而使多行日志的识别和处理在采集端完成。针对不同的日志类型进行定制heka插件的开发能够很有效的完成不同类型日志的收集和有效处理。