 **Elasticsearch version** :
    # elasticsearch --version
    Version: 2.3.4, Build: e455fd0/2016-06-30T11:24:31Z, JVM: 1.8.0_91
**JVM version** :
    # java -version
    openjdk version "1.8.0_91"
    OpenJDK Runtime Environment (build 1.8.0_91-8u91-b14-1~bpo8+1-b14)
    OpenJDK 64-Bit Server VM (build 25.91-b14, mixed mode)
**OS version** : Debian Jessie, elasticsearch is running in the container from
the official docker image.
**Description of the problem including expected versus actual behavior** :
**Steps to reproduce** :
  1. Index ~1 billion documents (I used 1 241 584 977 for 12h) in ~1kb doc average.
  2. Run topN query for low cardinality field with zero matches -> get instant response. Good!
  3. Run topN query for high cardinality field with zero matches -> get slow response. Bad!
The index in question has 50 shards and all fields are `doc_values`.
Query for low cardinality field:
    {
      "size": 0,
      "query": {
        "filtered": {
          "filter": {
            "bool": {
              "must": [
                {
                  "query": {
                    "query_string": {
                      "query": "zoneName:foo.bar"
                    }
                  }
                },
                {
                  "range": {
                    "@timestamp": {
                      "gte": "2016-08-03T00:00:00Z",
                      "lte": "2016-08-03T12:00:00Z"
                    }
                  }
                }
              ]
            }
          }
        }
      },
      "aggs": {
        "topn": {
          "terms": {
            "field": "status",
            "size": 10,
            "order": {
              "_count": "desc"
            }
          }
        }
      }
    }
Response:
    {
      "took": 148,
      "timed_out": false,
      "_shards": {
        "total": 50,
        "successful": 50,
        "failed": 0
      },
      "hits": {
        "total": 0,
        "max_score": 0,
        "hits": []
      },
      "aggregations": {
        "topn": {
          "doc_count_error_upper_bound": 0,
          "sum_other_doc_count": 0,
          "buckets": []
        }
      }
    }
Query for high cardinality field:
    {
      "size": 0,
      "query": {
        "filtered": {
          "filter": {
            "bool": {
              "must": [
                {
                  "query": {
                    "query_string": {
                      "query": "zoneName:foo.bar"
                    }
                  }
                },
                {
                  "range": {
                    "@timestamp": {
                      "gte": "2016-08-03T00:00:00Z",
                      "lte": "2016-08-03T12:00:00Z"
                    }
                  }
                }
              ]
            }
          }
        }
      },
      "aggs": {
        "topn": {
          "terms": {
            "field": "request",
            "size": 10,
            "order": {
              "_count": "desc"
            }
          }
        }
      }
    }
Response:
    {
      "took": 10634,
      "timed_out": false,
      "_shards": {
        "total": 50,
        "successful": 50,
        "failed": 0
      },
      "hits": {
        "total": 0,
        "max_score": 0,
        "hits": []
      },
      "aggregations": {
        "topn": {
          "doc_count_error_upper_bound": 0,
          "sum_other_doc_count": 0,
          "buckets": []
        }
      }
    }
Field cardinality for the same timespan:
  * `request`: 168154206
  * `status`: 127
Problem is: these 10 seconds came out of nowhere. I don't have any matching
documents, there's nothing to do. I'm afraid that I have to pay the price for
every request trying to do aggregation for index-wise high cardinality field,
even though query-wise the field is not that diverse.