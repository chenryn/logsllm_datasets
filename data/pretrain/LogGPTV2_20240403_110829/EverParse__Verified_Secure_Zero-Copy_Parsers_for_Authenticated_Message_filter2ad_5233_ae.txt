nating two value representations valid with respect to two
parsers p1, p2 (such as pairs, lists, tagged unions, or variable-
length data), p1 is required to have the strong preﬁx prop-
erty. Consider for instance serializing a pair of two pieces
of data x1,x2 using serializers s1,s2 correct with respect
to parsers p1, p2. We would like to prove that the serial-
ization s(x1,x2) = s1(x1)· s2(x2) obtained by concatenating
the two serializations, is correct with respect to the parser
for pairs. By correctness of s1, p1(s1(x1)) succeeds and
returns (x1,|s1(x1)|), but this is not enough to know that
p1(s1(x1)· s2(x2)) succeeds and also returns (x1,|s1(x1)|) (so
that we can cut the input after |s1(x1)| and apply p2 on the
remainder, s2(x2)), unless p1 has the strong preﬁx property.
These properties are included in the deﬁnition of parser_prop
on the metadata generated by QuackyDucky, hence enforced
by typing for all its parser speciﬁcations.
5.1 Speciﬁcation Combinators
LowParse is an extensible library of combinators. For each
parser speciﬁcation combinator, we attach a corresponding
metadata combinator; then, we deﬁne, when possible, a seri-
alizer combinator.
Parser combinators We deﬁne primitive parser combina-
tors below. For each of them, we prove injectivity and any
relevant additional properties indicated in their metadata, such
as the strong preﬁx property. We also deﬁne derived combina-
tors; in contrast, all their properties are established automati-
cally as the result of their deﬁnitions (by type uniﬁcation and
matching on their metadata). The code produced by Quacky-
Ducky only inserts annotations to prove their composability
conditions, for instance, by computing the length boundaries
of the derived metadata, which are then veriﬁed by F(cid:63).
We start by deﬁning primitive parser combinators: fail,
which consumes no input and fails; ret[x], which consumes no
input and succeeds returning x; read_byte, which consumes
and returns a single byte of input; and and_then, which se-
quentially composes two parsers where the second parser
depends on the value parsed by the ﬁrst parser (i.e., monadic
composition). For each of these basic combinators, we prove
non-malleability and/or the strong preﬁx property under suit-
able conditions. For instance, p and_then q has the strong
preﬁx property provided that p has it, q[x] has it for all x,
and, moreover, if q[x1] and q[x2] succeed on inputs b1 and b2,
respectively, and return the same value, then x1 = x2. (Other-
wise, consider for example p = read_byte and q = ret[0].)
USENIX Association
28th USENIX Security Symposium    1475
Using those primitive combinators, we deﬁne derived com-
binators, for which veriﬁcation of non-malleability and meta-
data correctness automatically follows by typing. Given
parsers p0 and p1 for t0 and t1, respectively, we can derive a
parser for pairs of type t0 ×t1 using p× q; mapping functions
over parsed results using p synth f ; ﬁltering parsed results by
some predicate using p ﬁlter f ; etc. proving non-malleability
and the strong preﬁx property for them under suitable condi-
tions.
More speciﬁcally, we derive parsers for ﬁxed-length ma-
chine integers, and we prove their non-malleability for both
endiannesses. For instance, we deﬁne little-endian 16-bit pars-
ing as (read_byte× read_byte) synth ((x,y) (cid:55)→ x + 256× y).
Our next combinators support variable-length data and lists:
• Given a parser p for type t, the parser plist[p] is deﬁned
by repeatedly applying p to its input. It fails as soon
as p fails or consumes zero bytes. If succeeds when p
eventually consumes its whole input and then returns the
resulting list of values.
• Given a parser p for type t and n > 0, the parser p truncn
succeeds when p succeeds on its input truncated to its
ﬁrst n bytes and consumes exactly n bytes.
The parser plist[p] does not have the strong preﬁx property,
but it consumes all its input. The parser p trunc n always has
the strong preﬁx property, even if p does not. If s is a correct
serializer for p at type t, then p trunc n is a parser for type
x : t{|s(x)| = n} and s is its correct serializer at that type.
We ﬁnally present further derived combinators, whose prop-
erties are automatically veriﬁed by construction:
Tagged unions: if p is a parser for type t and f : u → t and
q[x] is a parser for type (y : u{ f (y) = x}) for every x : t, then:
p (cid:46) f q = p and_then (x (cid:55)→ q[x] synth (y (cid:55)→ y))
is a parser for type u. This combinator is a strengthening of
and_then that enforces non-malleability of q by making its
codomain dependent: u is the union type, and t is the tag type,
and f gives the tag of an element of the union type. From
there, we deﬁne a combinator for sum types, which can be
used for tagged unions.
Enum types: if l is a list of key-value pairs where each key
and each value only appear once, then it deﬁnes both a closed
enum type (whose elements are the keys that appear in l)
and an open enum type (whose elements are the known keys
that appear in l and the unknown values that do not appear
in l). We deﬁne parsers for both variants penum(p,l) (where
p is the value parser), using ﬁlter, synth and the dictionary
function on key-value pair lists.
Variable-sized data: formats such as TLS often specify
variable-length data as a payload preﬁxed by its size in bytes.
If p is a parser for the payload, and if s is a serializer correct
with respect to p, then we deﬁne
vldata(p,l,h) = parse_u(cid:96) ◦ ﬁlter(n (cid:55)→ l ≤ n ≤ h)
(cid:46) f (n (cid:55)→ p trunc n)
as a parser for the reﬁned type (x : t{l ≤ |s(x)| ≤ h}), where
(cid:96) = 8×|log256(h)|, is the bit size of the size integer preﬁx, and
f (x) = |s(x)|. Such parsers inherit the strong preﬁx property
from the parser for the preﬁx size, regardless of whether it
holds for p.
Correct Serializers Not all parser speciﬁcations have cor-
rect serializers. For instance, ret[x] and and_then do not have
a generic serializer. So, in LowParse, we provide serializer
combinators for read_byte, fail, plist, synth, and (cid:46), for each of
which we prove correctness with respect to its corresponding
parser combinator (i.e., that they are inverse of one another).
We also easily prove that a correct serializer for p is also cor-
rect for p trunc n and p ﬁlter f (once its domain is restricted
accordingly). From there, we derive correct serializers for
×, nlist, vldata, etc. for which the correctness proof automati-
cally follows by typing.
Implementation Combinators
5.2
For each parser-speciﬁcation combinator, LowParse provides
combinators for its high-level parser and for its low-level
validators and jumpers (and similarly for serializers). For
primitive combinators, we implement their corresponding val-
idators jumpers and serializers; for each of them we prove
memory safety and functional correctness with respect to their
speciﬁcation. We implement most derived combinators by
following the same construction as for their specs, by assem-
bling the corresponding implementation combinators. Thus,
their memory safety and functional correctness automatically
follow by typing. We also deﬁne accessor combinators for
synth and tagged unions, and accessors for pair elements,
from which QuackyDucky derives accessors for struct ﬁelds
and sum types.
By design, our combinators are inherently higher-order and
so they cannot directly be extracted to C. Instead, we rely
on meta-programming features of F(cid:63) and KReMLin, based
on source code annotations, to ensure that all combinator
code is inlined and specialized before extraction. In most
cases, this is achieved by annotating our source code. In other
cases, we extend LowParse with F(cid:63) tactics [31], pieces of
F(cid:63) metaprograms written once and for all and evaluated at
typechecking time to automatically generate Low(cid:63) valida-
tors from some type deﬁnitions. For example, our validators
for enum values and tagged unions are speciﬁed using con-
stant key-value lists. Instead of programming a loop on these
lists, we meta-program their unrolling at compile-time, which
yields a cascade of ifs automatically turned into a switch by
many C compilers. In rare cases, such as unions tagged with
an enum value, we write additional validator combinators to
more precisely control their inlining by F(cid:63) and KReMLin.
In addition, metadata allow us to provide some generic
validator combinators that apply regardless of the actual parser
combinator. For example, if we know that a parser consumes
a constant n bytes and always succeeds, then we can use a
1476    28th USENIX Security Symposium
USENIX Association
TLS
Bitcoin
PKCS #1
LowParse
QD
1601
31
117
N/A
F(cid:63) LoC
69,534
1,925
4,452
32,210
Verify
46m
1m56s
2m14s
3m5s
Extract
C LoC
25m 192,229
1,344
3,368
185
1m14s
2m39s
1m5s
Obj.
717KB
8KB
26KB
739 B
Table 1: Overview of EverParse Applications
validator that just jumps n bytes. QuackyDucky selects these
combinators based on the metadata it computes.
6 Integration and Evaluation
We evaluate the integration of EverParse-generated parsers for
three applications: the TLS message format, integrated into
MITLS; the Bitcoin block and transaction format, integrated
into the Bitcoin Core benchmark; and the ASN.1 payload of
PKCS #1 signatures, integrated into mbedTLS.
Table 1 shows for each application the lines of Quacky-
Ducky input speciﬁcation, the amount of F(cid:63) code generated,
the time required for veriﬁcation and KReMLin extraction,
and the size of the C code and compiled objects. The Bitcoin
evaluation was performed on a 28-core Xeon E5-2680 v4
CPU with 128GB of RAM, running with turbo boost and all
but one core disabled. The rest of the ﬁgures were collected on
a 10-core Xeon W-2155 CPU with 128GB of RAM, running
F(cid:63) commit 7b6d77 with Z3 4.5.1 and GCC 7.4.
6.1 TLS Message Format
As described in §3, we have speciﬁed the TLS message format
for all versions of TLS from 1.0 to 1.3. However, integrat-
ing the generated parsers presents some major challenges:
implementations tend to deﬁne their own representations
of messages, with ﬁeld and tag names that differ from the
RFC, and some of them like mbedTLS interleave the pars-
ing and processing of messages. MITLS [7] uses functional,
high-level parser implementations and types, operating on
values. Most of the basic data types (such as cipher suite
names) are deﬁned in a module called TLSConstants, while
some specialized ones scattered in other modules (e.g. group
names in CommonDH). Extension types and parsers are in the
Extensions module, while message types and parsers are
in HandshakeMessage. We noticed that these ﬁles contain
many assumptions and incomplete proofs, many of which
have been completed for earlier drafts of TLS 1.3, but not
updated as the formats changed (with EverParse, such up-
dates and extensions only require a few changes to the format
description).
In total, in order to switch to the high-level implementation
produced by QuackyDucky, we update or rename over 200
types (and propagate these changes), which requires 2,865
additions and 3,266 deletions over 38 ﬁles (according to our
Github pull request). Unlike LowParse, MITLS individually
proves the non-malleability of each parser as a lemma separate
from parser deﬁnitions instead of a reﬁnement; the MITLS
proofs for such lemmas are lengthy and intricate. So, we
deﬁne a LowParseWrappers module to replace such proofs
with a uniform call to LowParse parser property lemmas. Our
changes do not break other existing proofs, but several gener-
ated types are more precise than the handwritten ones (notably,
all lists are reﬁned to ensure they can be serialized), which
leads to additional conditions to prove in many functions. The
generated parsers are also a lot stricter: for instance, we now
check at parsing which extensions can appear in a message,
and which messages can appear for the negotiated version.
To test the impact of EverParse parsers, we run the sim-
ple HTTP client and server tool distributed with MITLS to
compare how many requests can be served, using the default
algorithm choices. This tool is not optimized for production
and processes requests sequentially. We compare the time to
process 500 requests between the original MITLS parsers and
EverParse high-level parser implementations.
HTTP requests
MITLS
49.8 req/s
MITLS-EverParse
53.3 req/s
Integrating the low-level Low(cid:63) implementations into
MITLS requires a large effort, as many functions that are
currently pure (operating on values such as lists) become
stateful (the buffer that contains the valid positions matching
each value must be live). To anticipate the beneﬁts of this
effort, we run a synthetic benchmark that validates all mes-
sages from a public dataset of TLS handshakes published by
Lumen [39]. This dataset contains handshake produced by a
wide range of clients and servers, and contains over 13GB
of data (including the BSON overhead). As a baseline, we
compare in-place validation time with the cost of checking
the message length, allocating a buffer of the message size,
and copying the contents of the message in the buffer.
Memcpy
EverParse
1,864 MB/s
1.761 cy/B
2,684 MB/s
1.177 cy/B
6.2 Bitcoin Blocks and Transactions
To show that EverParse is extensible and evaluate the per-
formance of its low-level parsers, we implement the Bitcoin
block and transaction format, listed in Figure 9. We do not
implement Segregated Witness (“segwit”), an extension that