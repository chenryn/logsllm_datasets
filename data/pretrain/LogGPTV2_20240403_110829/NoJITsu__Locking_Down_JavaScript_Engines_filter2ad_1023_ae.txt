reduces the number of instructions that can feasibly corrupt
sensitive JavaScript objects.
We hoisted some of the permission changes as part of our
optimization (see Section IV-E). This optimization reduced the
average performance overhead from 5% to 2%, as discussed in
Section V-C. However, this performance gain may come at the
cost of reduced security, allowing additional write instructions
executed in the write window of sensitive JavaScript objects.
To analyze the security trade-off of our hosting optimization,
we measured the fraction of the write instructions that were
unnecessarily executed in the write window when the opti-
mization is enabled. The results are shown in the bottom
half of Table II. Note that a small behavioral change like
TABLE III: Default memory access permission at run time
Data
Bytecode
Object tables
JS Objects
JIT IR
JIT code
JIT data
Permissions
SpiderMonkey 60.0.0
with NOJITSU
RW
RW
RW
RW
RX
RX
R
R
R
R
X
R
our hosting optimization can affect the timing when the next
tier of execution (i.e., JIT code execution) is triggered in the
JavaScript engine. This may introduce noise when we directly
compare the dynamic instruction counts between optimized
and non-optimized versions of the executions. For example,
the percentage of single write instructions in the sensitive
object write window slightly decreased after the optimization
as a result of the noise. However, overall, the optimization
led to a mild increase in the write instructions executed
in the write window. After the optimization,
the number
increased from 0.19% to 1.72% while only sensitive objects
were accessible and increased from 0.13% to 0.43% while both
objects were accessible. This result suggests that the hosting
optimization provides a reasonable trade-off between security
and performance. The developer can decide the degree of
hosting optimization according to the performance and security
requirements of the system.
2) Code-Injection Attacks: While code-injection attacks are
already mitigated to some extent by the existing deployed
defense mechanisms [18], several advanced attacks aim at
bypassing them, e.g., by injecting constants and exploiting
unaligned instruction fetches [7], [13], [40]. These JIT spray-
ing attacks proved challenging to mitigate in practice, since
the performance overhead of constant blinding grows as the
protected constants get smaller in size [19]. As a result, the
current version of SpiderMonkey does not deploy constant
blinding in the interpreter or the Baseline JIT compiler [59]. In
NOJITSU we tackle this problem as part of our design policy to
enable execute-only memory for JIT code. Since JIT code will
be mapped non-readable in our prototype, we clearly separate
readable data such as constants from code (see Section III-A1).
This means that injected constants will no longer be mapped
as executable at run time within NOJITSU.
3) Code-Reuse Attacks: To verify NOJITSU’s ability to
stop code-reuse attacks, we re-implemented a fully working
JIT-ROP exploit based on CVE-2019-11707 which is already
present in the SpiderMonkey 60.0. We achieved arbitrary read-
write capability based on the CVE and launched our JIT-
ROP attack. Our JIT-ROP attack exploits gadgets which the
attacker dynamically inserts into the JIT code region, e.g.,
by forcing JIT compilation of maliciously inserted ad scripts.
We veriﬁed that our JIT-ROP attack works reliably against
the uninstrumented version of SpiderMonkey. We then ran
the JIT-ROP exploit against NOJITSU and found that it was
successfully stopped. The reason is that the generated code
pages are no longer mapped as readable (eXecute-only), and
hence,
the attacker is not able to locate and disassemble
potential gadgets at run time.
12
4) Bytecode Interpreter Attacks: As described in detail
in Section II we developed and successfully tested a new
attack against SpiderMonkey as part of our work. Since our
attack corrupts data objects that are handled by the interpreter
component, none of the previously proposed defenses were
able to stop our attack. One of the main motivating goals
behind NOJITSU is to resolve this situation. In our design,
we carefully analyzed each major component within the JIT
engine to identify and enforce the minimally required set of
access permissions. In our attack setting this means that the
attacker will no longer be able to write to the function object
using the type confusion vulnerability (CVE-2019-11707),
since NOJITSU separates sensitive objects and primitive ob-
jects into different protection domains. We veriﬁed and tested
that NOJITSU indeed successfully prevents our new attack on
SpiderMonkey. It is noteworthy that we not only protect the
interpreter component. Indeed, each of the major relevant data
sections such as the memory areas for Bytecode, Data Objects,
Data Tables, and JIT Compiler Data are also protected using
separate MPK keys in our scheme.
B. Coverage of Dynamic Object-Flow Analysis
As discussed in Section IV-C2, direct writes to JS objects
are handled by a limited set of functions, which we call
accessor functions. Our dynamic analysis,
therefore, only
needs to ﬁnd these accessor functions and does not require
entire code coverage of the engine. The accessor functions
will be fully exercised as long as each of the object types (of
which there are 29 in SpiderMonkey) is covered by one of our
test cases.
To evaluate the soundness of our approach, we ﬁrst ran our
dynamic analysis with a subset of the test suite and checked
whether the protected JavaScript engine based on the dynamic
analysis tolerates the bigger test cases. To this end, we ran our
dynamic analysis with the JIT test suite that contains 6,246
tests which is a subset of the full JavaScript test suite. Based
on this analysis result we applied our object protection to
the JavaScript engine. We then tested the protected version
of JavaScript engine against the entire JavaScript test suite
— which consists of 30,605 tests independent from the test
suite that we used for the dynamic analysis. Then we checked
if the new tests triggered any memory protection faults. A
fault would indicate that an instruction that was not covered
by our analysis wrote to a JavaScript object. We veriﬁed that
our JavaScript engine instrumented with the subset of the test
suite successfully passed the rest of the entire test suite without
triggering any faults. This conﬁrms that our dynamic analysis
is able to cover all possible accessor functions with only the
subset of test cases, and the resulting protection is robust
enough to tolerate much bigger test cases.
C. Performance
We evaluated the performance of our defense on a Intel
Xeon silver 4112 machine equipped with 2.60GHz CPU and
32GB memory. We ran benchmarks under Ubuntu 18.04.1 LTS
whose kernel version is 4.15.0-47-generic. We used LongSpi-
der [5] for our evaluation. LongSpider is a longer version
of sunspider benchmarks. The reason for using LongSpider
is that sunspider benchmarks are too microscopic. Most of
the sunspider benchmarks are less than 10ms, which doesn’t
catch the performance overhead of our recurring changes of
the protection. However, most of the LongSpider benchmarks
are longer than 100ms so they are more suitable for our
performance evaluation. Figure 9 shows the evaluation re-
sult. X axis is benchmarks and y axis is the performance
overhead compared to the baseline. There are ﬁve different
bars. The bar named JIT_PROT is for the overhead of
JIT protection. INTER_PROT is for the interpreter protec-
tion. ALL_PROT is the combined performance overhead for
both JIT and interpreter protections and OPT stands for the
optimization. On average, our NOJITSU has less than 5%
overhead and with optimization it becomes less than 2%. The
overhead for JIT is marginal, which is 0.6% on average.
Some benchmarks have better performance than the baseline
because all expensive mprotect operations are replaced
by cheap MPK register writes. However, benchmarks such
as bitops-bits-in-byte, date-format-tofte, and
string-tagcloud have higher overhead compared to the
others. We found that the root cause of the overhead are cache
misses. We need to position JIT code and data in different
pages for code and data separation, which loses cache locality.
For instance, if the size of code is too small, both the data
and the code using that data can ﬁt into the same cache line.
Code and data separation introduces a large(r) offset between
code and data regions, not allowing for both to ﬁt into the
same cache line. For the interpreter protection, there is almost
no overhead from bytecode and table protection because the
overhead comes from the generation of those data, which is
marginal compared to whole execution. Most of the observed
overhead is a result of the object protection, which keep
changing the protection during the execution. In Figure 9,
date-format-xparb and string-base64 cause a sig-
niﬁcant overhead for the object protection because they involve
frequent write operations to string objects. However, our
optimization drastically reduces this overhead. As discussed
earlier, we achieve this by hoisting certain instructions within
our instrumentation.
VI. DISCUSSION
A. Applicability to Other Systems
While we instantiated our attacks and defenses in Spider-
Monkey, the underlying approaches are generally applicable
to other script engines that employ bytecode interpreters. We
analyzed two mainstream JavaScript engines, V8 [30] and
JavaScriptCore [4], to clarify how our approaches could be
applied to these JavaScript engines. The engines have a number
of reported memory corruption vulnerabilities which may al-
low attackers to read and write arbitrary memory locations [1],
[2].
a) Attack: Our interpreter attack leverages the facts
that most of the key data structures of the interpreter remain
writable throughout the execution and that the interpreter has a
special way of calling native functions – in which contents of
certain JS objects determine the target address and arguments
of a function call. Speciﬁcally, our attack overwrites the two
data structures in SpiderMonkey: (i) a function object which
contains the address of the function to invoke, and (ii) the
context object which is always passed as the ﬁrst argument for
native function calls (see Section II-C). We found that in V8
and JavaScriptCore any types of JS objects remain writable,
13
Fig. 9: NOJITSU performance
and both of these engines have internal calling conventions
for native JS functions similar to SpiderMonkey. Therefore,
our presented interpreter attack would be possible for these
engines. For example, JavaScriptCore makes a native function
call by reading a target address from a function object and
passing a global object pointer as the ﬁrst argument. Therefore,
deliberately overwriting the function object and the global
object in the call frame would allow the attacker to invoke
his desired function.
that
b) Defense: The bytecode interpreters in V8 and
JavaScriptCore have different implementations than Spider-
Monkey – SpiderMonkey has a switch-based interpreter while
V8 and JavaScriptCore implement threaded interpreters; Spi-
derMonkey’s interpreter is a stack-based machine, whereas
the other two are register-based machines. Despite such dif-
ferences, the core mechanism of bytecode interpretation re-
mains the same,
is, each bytecode instruction has a
sequence of code that handles its desirable operation and, when
necessary, the instruction can access JavaScript objects via
object tables. Consequently, V8 and JavaScriptCore have the
same components that NOJITSU protects in our SpiderMonkey
prototype,
tables,
JIT IR cache, and JIT code cache. Like SpiderMonkey, V8
and JavaScriptCore have different types of JavaScript objects.
We identiﬁed several primitive objects as well as crucial
objects such as the function object which stores the address of
the corresponding function. Therefore, NOJITSU’s protection
mechanism could be directly applied to these engines that
use the similar data structures, by assigning minimum access
permissions for individual data structures and temporarily grant
extra permissions only when that is necessary.
i.e., bytecode, JavaScript objects, object
Bytecode itself normally does not change after the code is
generated and thus in NOJITSU the memory region containing
bytecode remains read-only after initialization. Previous ver-
sions of JavaScriptCore had an optimization called bytecode
inline caching which directly modiﬁes a bytecode stream.
Such an optimization could have induced more performance
overhead to our defense since modifying the bytecode would
require additional permission changes. However, this optimiza-
tion is not used anymore for memory reason and thus we do not
expect extra overhead applying NOJITSU to this engine [65].
B. Alternatives to Intel MPK
While our prototype uses Intel MPK, the design of NO-
JITSU is not heavily tied to its speciﬁc hardware imple-
mentation and using other hardware-based memory protection
schemes that allow restriction of memory access permissions
beyond traditional virtual memory protection, such as ARM
Memory Domains [6], should be feasible in principle. This
relation between Intel MPK and ARM Memory Domains was
also noted by prior work on Software-Fault Isolation and
Compartmentalization [20], [47], [63]. Similar to Intel MPK,
ARM Memory Domains support 16 different protection do-
mains. However, while Intel MPK allows domain switches
in user space, ARM Memory Domains require a system call
roundtrip. Although NOJITSU uses Intel MPK’s ability to
efﬁciently implement execute-only permissions, there are no
conceptual limitations that would prevent leveraging non-MPK
implementations [8], [15], [23] in support of that feature.
VII. RELATED WORK
JIT compilers have been under constant siege by adver-
saries ever since they were introduced in mainstream web
14
3d-cube3d-morph3d-raytraceaccess-binary-treesaccess-fannkuchaccess-nbodyaccess-nsievebitops-3bit-bits-in-bytebitops-bits-in-bytebitops-nsieve-bitscontrolflow-recursivecrypto-aescrypto-md5crypto-sha1date-format-toftedate-format-xparbhash-mapmath-cordicmath-partial-sumsmath-spectral-normstring-base64string-fastastring-tagcloudAverage0.0%5.0%10.0%15.0%20.0%25.0%JIT_PROTINTER_PROTINTER_PROT_OPTALL_PROTALL_PROT_OPTbrowsers. The earliest JIT compilers left
the code cache
writable and executable at all times. This trivially enabled
code-injection attacks [18], [55]. Early attempts to address this
issue included monitors that detected system calls originating
from writable code regions [26]. However, as JIT compilers
began to enforce strict W⊕X policies [18], either by double
mapping the JIT code cache or by toggling the writable and
executable permissions before and after code emission, JIT
code injection became a less interesting attack vector.
As an alternative, Blazakis proposed JIT spraying, an attack
technique that injects code indirectly by running a script that
contains user-speciﬁed constants (e.g., as part of a long XOR
computation) [7], [13], [40]. Since these constants appear as in-
struction operands in the JIT code cache, they can be executed
as if they were valid instructions. Several countermeasures
thwart JIT-spraying attacks by either eliminating user-speciﬁed
constants through obfuscation or constant blinding [19], ran-
domizing the JIT code [32], or by extending control-ﬂow
integrity to JIT code [46]. NOJITSU strengthens these existing
defenses by additionally separating data constants from JIT
code (see Figure 7). This enables us to enforce non-executable
permissions for constants.
Snow et al. proposed to attack JIT engines through code-
reuse attacks [56]. Their JIT-ROP attack leveraged a memory
disclosure vulnerability to recursively disassemble the code
region,
thereby discovering useful code gadgets on-the-ﬂy.
These gadgets can then be chained together to launch a return-
oriented programming attack [54]. Defenses against JIT-ROP
included execute-only memory combined with randomiza-
tion [8], [9], [23], [29], destructive code reads [61], [64], and
cross-checking reads performed by JIT code [28]. However,
some of these defenses were quickly bypassed [39], [57], while
others were not deployed due to impractical design or resource
requirements. As we demonstrate in our evaluation, NOJITSU
thwarts even dynamic code-reuse attacks such as JIT-ROP with
a low overhead. Our design is generic and leverages automated
dynamic analysis and instrumentation to scale to complex real-
world code bases such as SpiderMonkey.
Song et al. showed that direct code-injection attacks on
the JIT cache were still possible by leveraging JavaScript
worker threads [58]. Their proposed defense moved the JIT
compilation thread to a separate process, thereby preventing
the code cache from ever being writable in the JIT execution