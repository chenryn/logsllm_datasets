with g is g itself. The polynomial g = g(x) = x
+x+1 contains only 5 non-zero coeﬃcients (therefore also
x
called ‘pentanomial’). This polynomial can be represented
as [1 :: 10000111]. Multiplying this carry-less
with a 128 bit value and keeping the 128 most signiﬁcant
bits can be obtained by: (i) Shifting the 64 most signiﬁcant
bits of the input by 63, 62 and 57 bit positions to the right.
(ii) XOR-ing these shifted copies with the 64 least signiﬁcant
bits of the input. Next, we carry-less multiply this 128-bit
result with g, and keep the 128 least signiﬁcant bits. This
can be done by: (i) shifting the 128-bit input by 1, 2 and
7 positions to the left. (ii) XOR-ing the results. Hence we
split the ﬁnite ﬁeld multiplication into a ﬁeld-independent
part which we perform with PCLMULQDQ and a ﬁeld de-
pendent part which we reduce to a small number of shift and
XOR operations. Using this instruction we achieve a GCM
performance of approximately 2.6 cycles per byte or 3.9 cy-
cles per byte together with AES as discussed later. This is
about 3 times faster than typical HMAC-SHA-1 implemen-
tations.
256
6. A HIGH PERFORMANCE TLS PROTO-
COL STACK
6.1
Implementing the 1.2 Version
As the OpenSSL library only provides TLS implementa-
tions up to version 1.0, we have added the necessary changes
needed to have a functional TLS 1.2 version. The following
are the major diﬀerences that need to be implemented be-
tween TLS 1.0 and TLS 1.2. First, key generation is diﬀer-
ent in TLS 1.2. Key generation entails the creation of keys
for the record protocol of TLS from the security parame-
ters provided by the handshake phase. The major diﬀerence
between TLS 1.0 and TLS 1.2 is in the Pseudo Random
Function (PRF) employed. Speciﬁcally, the MD5/SHA-1
combination in TLS 1.0 is replaced by SHA-256 or stronger
141hashes. In addition in TLS 1.2, the PRF is negotiable during
the control channel handshake.
Second, there is diﬀerence in the IV generation between
TLS 1.2 and TLS 1.0 or prior versions. In the context of
AEAD algorithms (e.g., AES-GCM) which are introduced in
TLS 1.2 IV consists of two portions: an implicit part coming
from the key generation and an explicit part that needs to be
unique. This may not be the case for other ciphers or for ver-
sions prior to TLS 1.2. Other changes introduced in TLS 1.2
include error handling, certiﬁcate handling and deprecation
of older cipher suites. Perhaps the most important diﬀerence
between TLS 1.0 and TLS 1.2 from a performance perspec-
tive is the introduction of algorithmic agility which allows
us to beneﬁt from AEAD algorithms (e.g., AES-GCM). We
focus on this class of algorithms in the following subsection.
6.2 Use of AEAD Algorithms in the TLS stack
In versions of TLS prior to 1.2, discrete mode algorithms
are employed which provide conﬁdentiality and message au-
thentication. Each algorithm uses an independent key. AEAD
achieves both encryption and authentication using a single
key.
There is signiﬁcant diﬀerence regarding the integration
of AEAD and non-AEAD algorithms in the TLS 1.2 pro-
tocol. For AEAD ciphers an explicit IV value is generated
and transmitted with each payload. Furthermore an implicit
IV is created from the key generation process, concatenated
with the explicit IV and used as input to the algorithm. In
the data path, non-AEAD ciphers apply a message authenti-
cation code before encryption. Then they encrypt and trans-
mit the data. The MAC is encrypted in this case. However,
for AEAD, this operation is reversed. Encryption happens
prior to MAC generation. The MAC is not encrypted in this
case.
We implemented the Advanced Encryption Standard (AES)
algorithm in the Galois/Counter Mode (GCM) with a 128-
bit key. For the explicit IV we use the recommended method
of [33] (3.2.1). In the context of AES, the IV is comprised
of 8 bytes of explicit IV and 4 bytes implicit IV. The ex-
plicit IV is the sequence number that is sent and retrieved
together with the payload, whereas the implicit IV is derived
from the key generation process. By including a sequence
number in the IV, we can satisfy the requirement that the
IV values are unique.
AEAD allow additional data to be authenticated. In the
case of TLS 1.2 this additional data comprises a sequence
number, packet type, TLS version and the compressed packet
length.
Figure 6 shows how the ﬁelds of the data packet map onto
the inputs and outputs of the cipher AES-128 GCM. As in-
dicated in the ﬁgure, the data ﬁeld is encrypted and authen-
ticated, and is carried along with a header and a sequence
number. The header is authenticated by being included in
the authenticated data. The sequence number is included
in the IV. The authentication tag is carried along with the
encrypted data in the packet payload. Our implementation
is available in the public domain [14] for experimentation.
7. RESULTS
In what follows we describe the results from our exper-
iments on measuring the performance of various crypto-
graphic tasks and TLS banking worloads. We present re-
sults at an instruction level, function level and session level.
type
version
length
seq_num
plaintext
+ 4 bytes 
implicit IV
IV
+24
AAD
AES-GCM Encryption
type
version
length
seq_num
ciphertext
1 byte
2 bytes
2 bytes
8 bytes
tag
16 byte
Figure 6: AES-128 GCM Packet Format
24 clocks
6 clocks
2 clocks
AES Round
AES
AES
Latency
Instruction
(table lookups)
(table lookups)
Latency
Latency
Instruction
Throughput
Throughput
Figure 7: Instruction Level Performance
Instruction level performance pertains to the latency of in-
voking the AES round instructions. Function level pertains
to the cost of various modes of AES and RSA encryption for
a given input data set. Session level pertains to the perfor-
mance measurements taken in the context of an overall TLS
session. We dissect and describe the diﬀerent cryptographic
components that contribute to the overall cost of connecting
and maintaining a TLS session. We also demonstrate that
our technologies result in substantial performance improve-
ment. We compare against optimized cryptographic imple-
mentations we developed ourselves, as well as OpenSSL. We
used OpenSSL since it is hard to get access to other pro-
prietary cryptographic algorithm implementations. So, we
used one of the best suites available in the public domain.
7.1 AES Instruction Level
Figure 7 presents a performance comparison between an
AES software round implementation that does not use our
instructions vs. one that leverages the instructions intro-
duced in Section 5. This data is gathered using a 3 GHz
Xeon R(cid:2) processor with our instruction extensions.
The leftmost bar in the ﬁgure depicts the latency of an
AES round using the table lookup method. The next bar
depicts the latency of completing an AES round in combi-
natorial logic. The rightmost bar depicts the AES instruc-
tion throughput. By instruction ‘throughput’ we mean the
minimum time elapsed between the completion of two in-
142dependent AES round operations, which is smaller than the
instruction latency since the AES circuit is pipelined. Specif-
ically, for each separate data block requiring an AES oper-
ation, this is the time between the completion of an AES
operation on one block and the completion of the same AES
operation on another data block.
For the table lookup implementation, we observe a la-
tency of 24 clocks per round. This requires table lookups
for all bytes of the cipher state. The minimum time be-
tween the completion of independent round operations for
this approach is approximately 24 clocks too. The software
used to perform these measurements was an optimized AES
implementation, based on the code of Brian Gladman.
When performing AES rounds using our instructions, we
ﬁnd that the round latency is reduced to 6 clocks, returning a
4x improvement. Furthermore, the throughput decreases to
2 clocks, returning a 12x improvement. These measurements
relate to both AES encrypt and decrypt round operations
as well as encrypt and decrypt last rounds.
7.2 AES Function Level
In our tests we compare four representative modes of op-
eration of AES. Because of the diﬀerence in the way AES is
used in each mode, performance varies across modes of op-
eration. The ﬁrst three modes (CBC, CTR, ECB) support
encryption only. GCM supports encryption and message
authentication. The cycles per byte presented here are in
accordance with the instruction level results shown in Fig-
ure 7. Instruction latencies are applied to the full 10 round
implementation of AES-128 and amortized over a 16-byte
AES block.
Table 2: Algorithm Level Performance
algorithm mode
table lookups AES instructions
(cycles/byte)
(cycles/byte)
AES-128 CBC
encrypt
AES-128 CTR
encrypt
AES-128 ECB
encrypt
AES-128 GCM
encrypt
16.1
19.3
15.6
29.5
4.1
1.3
1.2
3.9
AES in the CBC mode results in a performance of 16.1 cy-
cles per byte using the table lookup method. This is reduced
to 4.1 cycles per byte when enabling the AES instructions.
This illustrates a 4x performance gain when leveraging our
AES hardware over pure software without it. CBC is not a
parallelizable mode since each input to a subsequent block
operation requires the output of the previous block. Because
of this CBC cannot take advantage of the small instruction
throughput shown in Figure 7.
AES in CTR and ECB modes displays the best results
with a 14x/13x performance improvement respectively. In
these modes AES leverages the round instructions in the
most optimal way.
In CTR and ECB each block can be
independently encrypted/decrypted without reliance on the
previous or next block, hence allowing eﬃcient hardware
parallelization and pipelining.
In the code used for these
measurements we encrypt/decrypt four blocks at a time.
The table lookup implementation of CTR demonstrates a
cost of 19.3 cycles per byte. CTR is slower than CBC and
ECB because of the need to perform an additional byte shuf-
ﬂing operation for endianness compliance for every block.
The performance of ECB is 15.5 cycles per byte. When us-
ing our instructions the performance of CTR becomes 1.3
cycles per byte, whereas the performance of ECB becomes
1.2 cycles per byte. Due to hardware pipelining the eﬀective
latency per round is only 2 clocks for these modes. In ad-
dition due to the fact that our instruction implementation
is done in the SIMD domain of the Intel R(cid:2) CoreTM micro-
architecture, the byte shuﬄing required by the CTR mode
is done eﬃciently using the PSHUFB instruction.
The results for AES-GCM are equally good, illustrating
a 7.5x gain over the table lookup implementation. GCM
removes the need for a separate data authenticity function
within the context of a protocol such as TLS. This improve-
ment becomes critical when comparing our GCM code (i.e,
combined encryption and authentication) against the ‘tradi-
tional’ discrete model of using AES-CBC and HMAC-SHA1.
SHA-1 costs approximately 8 cycles per byte. GCM process-
ing with the PCLMULQDQ instruction can be accomplished
at an additional cost of only 2.6 cycles per byte. The table
lookup approach consumes 10 cycles per byte for GCM [5].
The increase from 1.3 to 3.9 cycles per byte for this algorithm
is due to the additional Galois Field multiplication opera-
tion required. For an optimized software implementation of
AES-GCM, without the instructions, the typical cost is 29.5
cycles/byte. By comparison, our acceleration technologies
reduce this to 3.9 cycles/byte. Saturation of a 10 Gbps link
without our technologies requires 12 3.0 Ghz cores. Our op-
timizations bring this down to just over a single core, leaving
the remaining cores for other critical workloads. This analy-
sis excludes the RSA overhead for key establishment. Later
in the paper we take this overhead into account.
Acceleration gains are similar for other key sizes. For
AES-192 and AES-256, the CBC speedup is 4x and the GCM
speedup is 7.5x. AES-192 operates at 4.9 cycles/byte for
CBC and 4.2 cycles/byte for GCM. AES-256 operates at
5.6 cycles/byte for CBC and 4.5 cycles/byte for GCM.
7.3 RSA Function Level
The RSA performance depends on the performance of the
underlying integer multiplication building blocks. In what
follows we compare the performance of routines that per-
form 512 by 512, 1024 by 1024, and 2048 by 2048 bit multi-
plication coming from the OpenSSL libraries (0.9.8 and 1.0
versions) and our code. We have implemented two routines:
One based on the single iteration Karatsuba multiplication
variant described in [31] and one based on our optimized
schoolbook technique. Our results are shown in Table 3.
As is evident from the table, our schoolbook multiplication
routines outperform both the Karatsuba code and the multi-
plication code (schoolbook) from the OpenSSL library. For
example, the 512 by 512 bit multiplication can be completed
in only 257 clocks, whereas Karatsuba needs 434 clocks and
OpenSSL schoolbook 611 clocks.
Next we compare the RSA 1024 and RSA 2048 perfor-
mance at a private decrypt operation level coming from
OpenSSL 0.9.8, 1.0, our code using Karatsuba multiplica-
tion and our code using our optimized schoolbook technique.
Our results are shown in Table 4. The numbers mean private
decrypt operations per second per 3 GHz Intel R(cid:2) CoreTM i7
processor core.
The main diﬀerence between OpenSSL 0.9.8 and OpenSSL
1.0 is that the 1.0 version implements the word-by-word
143Table 3: Performance of Integer Multiplication (pro-
cessor clocks)
RSA-1024
2.17 
CPU cost (million clocks)
512 by
512 bit
1024 by
1024 bit
2048 by
2048 bit
OpenSSL
0.9.8, 1.0
our code
(Karatsuba)
our code
(schoolbook)
611
434
257
1937
1309
1052
6212
5024
3815
2.30
AES-128
RSA-1024 1.34
SHA1
1.18
other
0.73
AES-128
AES 128
SHA1
other
0.58
1.18
0.73
RSA 1024
RSA 1024
GCM
other
1.34
0.19
0.37
0.73
Table 4: Performance Comparison (private decrypt
operations per second)
state of the art,
AES-128 CBC,
HMAC-SHA1
our technologies,
AES-128 CBC,
HMAC-SHA1
our technologies,
AES-128 GCM
RSA 1024
RSA 2048
(private decrypt)
(private decrypt)
OpenSSL
0.9.8