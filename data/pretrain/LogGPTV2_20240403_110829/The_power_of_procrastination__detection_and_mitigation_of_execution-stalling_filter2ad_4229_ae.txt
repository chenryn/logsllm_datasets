AND KRUEGEL, C. A View on Current Malware Behaviors.
In Workshop on Large-Scale Exploits and Emergent Threats
(LEET) (2009).
[8] BAYER, U., MILANI COMPARETTI, P., HLAUSCHEK, C.,
KRUEGEL, C., AND KIRDA, E. Scalable, Behavior-Based
Malware Clustering. In Network and Distributed System
Security Symposium (2009).
[9] BRUMLEY, D., HARTWIG, C., LIANG, Z., NEWSOME, J.,
SONG, D., AND YIN, H. Towards automatically identifying
trigger-based behavior in malware using symbolic execution
and binary analysis. Tech. Rep. CMU-CS-07-105, Carnegie
Mellon University, 2007.
[10] CRANDALL, J., WASSERMANN, G., DE OLIVEIRA, D., SU,
Z., WU, F., AND CHONG, F. Temporal Search: Detecting
Hidden Malware Timebombs with Virtual Machines. In
Conference on Architectural Support for Programming
Languages and Operating Systems (ASPLOS) (2006).
[11] DINABURG, A., ROYAL, P., SHARIF, M., AND LEE, W.
Ether: Malware Analysis via Hardware Virtualization
Extensions. In ACM Conference on Computer and
Communications Security (2008).
294[12] FATTORI, A., PALEARI, R., MARTIGNONI, L., AND
MONGA, M. Dynamic and Transparent Analysis of
Commodity Production Systems. In International
Conference on Automated Software Engineering (ASE)
(2010).
[13] FERRIE, P. Attacks on Virtual Machines. In Proceedings of
the Association of Anti-Virus Asia Researchers Conference
(2007).
[14] FREDRIKSON, M., JHA, S., CHRISTODORESCU, M.,
SAILER, R., AND YAN, X. Synthesizing Near-Optimal
Malware Speciﬁcations from Suspicious Behaviors. In IEEE
Symposium on Security and Privacy (2010).
[15] FREILING, F., HOLZ, T., AND WICHERSKI, G. Botnet
Tracking: Exploring a Root-Cause Methodology to Prevent
Distributed Denial-of-Service Attacks. In European
Symposium On Research In Computer Security (ESORICS)
(2005).
[16] JOHN, J., MOSHCHUK, A., GRIBBLE, S., AND
KRISHNAMURTHY, A. Studying Spamming Botnets Using
Botlab. In Usenix Symposium on Networked Systems Design
and Implementation (NSDI) (2009).
[17] KANG, M., YIN, H., HANNA, S., MCCAMANT, S., AND
SONG, D. Emulating Emulation-Resistant Malware. In
Workshop on Virtual Machine Security (VMSec) (2010).
[18] KOLBITSCH, C., HOLZ, T., KRUEGEL, C., AND KIRDA, E.
Inspector Gadget: Automated Extraction of Proprietary
Gadgets from Malware Binaries. In IEEE Symposium on
Security and Privacy (2010).
[19] KOLBITSCH, C., MILANI COMPARETTI, P., KRUEGEL, C.,
KIRDA, E., ZHOU, X., AND WANG, X. Effective and
Efﬁcient Malware Detection at the End Host. In Usenix
Security Symposium (2009).
[20] MARTIGNONI, L., PALEARI, R., ROGLIA, G. F., AND
BRUSCHI, D. Testing CPU Emulators. In International
Symposium on Software Testing and Analysis (ISSTA) (2009).
[21] MOSER, A., KRUEGEL, C., AND KIRDA, E. Exploring
Multiple Execution Paths for Malware Analysis. In IEEE
Symposium on Security and Privacy (2007).
[22] PALEARI, R., MARTIGNONI, L., ROGLIA, G. F., AND
BRUSCHI, D. A Fistful of Red-Pills: How to Automatically
Generate Procedures to Detect CPU Emulators. In
usenix-woot (2009).
[23] RAFFETSEDER, T., KRUEGEL, C., AND KIRDA, E.
Detecting System Emulators. In Proceedings of the
Information Security Conference (2007).
[24] RUTKOWSKA, J. Red Pill... or how to detect VMM using
(almost) one CPU instruction. http://www.invisible
things.org/papers/redpill.html, 2004.
[25] SONG, D., BRUMLEY, D., YIN, H., CABALLERO, J.,
JAGER, I., KANG, M. G., LIANG, Z., NEWSOME, J.,
POOSANKAM, P., AND SAXENA, P. BitBlaze: A new
approach to computer security via binary analysis. In
Conference on Information Systems Security (Invited Paper)
(2008).
[26] SREEDHAR, V. C., GAO, G. R., AND FONG LEE, Y.
Identifying loops using DJ graphs, 1995.
[27] STONE-GROSS, B., COVA, M., CAVALLARO, L., GILBERT,
B., SZYDLOWSKI, M., KEMMERER, R., KRUEGEL, C.,
AND VIGNA, G. Your Botnet is My Botnet: Analysis of a
Botnet Takeover. In ACM Conference on Computer and
Communications Security (CCS) (2009).
[28] WILHELM, J., AND CHIUEH, T.-C. A Forced Sampled
Execution Approach to Kernel Rootkit Identiﬁcation. In
Recent Advances in Intrusion Detection. 2007.
the 5K malware samples in our training set (see Section 4). More
precisely, the ﬁgures show, for a particular number n of system
calls (depicted on the x-axis), the (absolute) number of time slots
during which we have seen n system calls (depicted on the y-axis).
For example, when analyzing the samples, we have recorded 150
successful system call invocations for roughly 1,000 intervals (see
Figure 5a). Likewise, Figure 5c shows that the number of times (y-
axis) a certain entropy value (x-axis) was encountered. Table 2
shows the thresholds that we derived from the training runs for
HASTEN’s detectors.
Table 2: Threshold values used in monitoring mode (for slot
time duration t = 5 seconds).
Threshold Threshold
Type
Name
Successful Smin/max,s
Failed
Entropy
Smax,f
Smin/max,e
(min)
3
−
0.17
(max)
600
900
20.0
B. HANDLING NESTED STALLING LOOPS
When HASTEN operates in passive mode, its goal is to ﬁnd and
whitelist code that stalls execution. To this end, the system checks
the program’s dynamic CFG for loops. When a number of ac-
tive, nested loops are found, HASTEN whitelists the innermost one
(as discussed in Section 5.2). This is a problem when the inner-
most, active loop is only a part of the entire stalling code (we have
encountered cases in real-world malware where a stalling loop is
itself executed many times by an outer loop).
In this case, the
system reverts back to monitoring mode as soon as the innermost
loop is ﬁnished. Unfortunately, the entire execution still does not
make progress, and the outer loop will simply execute the inner
loop again. Of course, the monitoring phase will detect insufﬁ-
cient progress, and the system will be switched into passive mode.
However, our analysis will ﬁnd the same active loops again. At this
point, whitelisting the inner loop only would be the wrong solution.
This would result in an execution where the system would con-
stantly switch between monitoring and passive mode. To address
this problem, the system keeps track of all loops that have been
previously whitelisted. When we ﬁnd that an active loop has been
previously whitelisted, but no progress has been made, the system
extends the whitelist to include the next enclosing loop. That is,
nested loops are incrementally added to the whitelist, starting from
the inner-most one, proceeding outwards.
C. PERSISTENT BEHAVIORAL FEATURES
Table 3: Persistent behavioral features.
Resource Action
ﬁle
create, delete, write, open-truncate
rename, set-information
any
keys: create, delete, save, restore;
set-value, set-information
create, terminate, set-information
load, unload
open window
network
registry
process
driver
GUI
APPENDIX
A. MONITORING MODE: PARAMETERS
Figures 5a and 5b show information about the number of suc-
cessful and failed system calls, respectively, that we observed for
D. DETAILED FINDINGS
As mentioned in Section 7.2, we can use different approaches for
measuring additional behavior. Table 4 shows additional behaviors
detected by HASTEN as measured by the optimistic and pessimistic
and metrics.
295(a) Successful system calls Ss.
(b) Failed system calls Sf .
(c) System call entropy Se.
Figure 5: Evaluating the progress of active samples by bucketing number of observed system calls (x-axis) and counting observed
number of time-slots for each bucket (y-axis).
Table 4: Additional behavior observed in Hasten.
Description
Runs total
# samples
3, 770
Passive
% # AV families
−
319
Added behavior (any activity)
- Added ﬁle activity
- Added network activity
- Added GUI activity
- Added process activity
- Added registry activity
No new behavior
- Exception cases
Added behavior (any activity)
- Added ﬁle activity
- Added network activity
- Added GUI activity
- Added process activity
- Added registry activity
Ignored (possibly random) activity
No new behavior
- Exception cases
2, 450
1, 873
906
28
895
795
1, 320
0
416
390
257
20
177
331
2, 034
1, 320
0
65.0%
49.7%
24.0%
0.7%
23.7%
21.1%
35.0%
0.0%
11.0%
10.3%
6.8%
0.5%
4.7%
8.8%
54.0%
35.0%
0.0%
188
169
73
16
79
107
225
0
# samples
2, 467
Optimistic Improvement
825
519
128
367
127
224
1, 642
277
Pessimistic Improvement
500
314
95
249
70
165
325
1, 642
277
86
80
41
12
42
60
156
225
0
Active
% # AV families
−
231
33.5%
21.0%
5.2%
14.9%
5.1%
9.1%
66.5%
11.2%
20.3%
12.7%
3.9%
10.1%
2.8%
6.7%
13.2%
66.5%
11.2%
139
100
39
69
48
62
174
63
94
69
29
49
34
46
84
174
63
296