only when evidence can be gathered that is suﬃcient at least
for probable cause.
The OneSwarm threat model is designed to be resistant to
the disclosure of user behavior to an attacker with control
over a limited number of overlay nodes and that wishes to
monitor millions of users. In contrast, our investigators want
to quickly gather suﬃcient evidence for a subset of actors that
are breaking the law, all while expending minimal resources.
The investigator is not looking to catch everyone at once,
but can repeat attacks over time.
Probable cause is a lower standard than the beyond a
reasonable doubt standard needed for conviction. There is no
quantitative standard for probable cause, and courts have
deﬁned it only qualitatively as a “fair probability” ; see United
States v. Sokolow, 490 U.S. 1 (1989). Accordingly, we say
a peer has been identiﬁed if the investigator’s statistical
conﬁdence is above a level suﬃcient to serve as probable
cause. While Isdal et al. analyze attacks requiring 95%
precision, we believe that 80%, or perhaps even lower, is
still a conservative quantiﬁcation of this standard, though of
course it depends on context. We evaluate diﬀerent scenarios
throughout this paper.
Evidence is forensically valid if gathered using techniques
that are based on testable hypotheses, have a known error
rate, are based on accepted scientiﬁc methods, and are peer
reviewed; see Daubert v. Merrell Dow Pharma. 509 U.S. 579
(1993).
A basic tenet of criminal forensics is that investigators
have limited resources. Like narcotics crimes, the number
of persons arrested for CP possession is generally limited by
investigator resources, not by the number of suspects. Each
identiﬁed peer requires weeks of additional legal processing,
and so maximizing the number identiﬁed is not necessary for
success.
2033.2 Model and Assumptions
The general approach adopted by law enforcement for
investigating CP traﬃcking is based on a series of legal
restrictions. We assume our attacker is in fact an investigator
in the US and following these restrictions. The law places
limits on how investigators can gather information prior to
the receipt of a search warrant. The primary restriction
is that investigators can only gather information in plain
view. For p2p networks, any traﬃc is in plain view if either:
(i) in the normal operation of the protocol the traﬃc can
be observed by any peer on the normal path (for example,
search queries that are broadcast to all peers, including the
attacker); (ii) if the traﬃc is destined for the attacker (for
example, a response to the attacker’s search query). U.S.
v. Gabel, 2010 WL 3927697 is a recent ruling that conﬁrms
this procedure’s legality. We do not allow attackers in our
model to analyze or compromise the contents of encrypted
traﬃc. We do not allow attackers to seize or compromise
peers through privilege escalation as that is outside the plain
view standard.
Our attacker controls some fraction of all peers in the
network. We detail three speciﬁc attacks on the anonymity of
OneSwarm in the following sections, and describe the value of
the evidence investigators discover from these attacks. Based
on these attacks, an investigator can determine if a speciﬁc
IP address is of interest. The ﬁrst attack leverages timing
information; the second leverages traﬃc information; the
third leverages TCP information.
With a magistrate-ordered subpoena, the billing record of
an IP address provides a speciﬁc geographic location. With
the attack’s evidence provided as part of a court-issued war-
rant, this location is searched, any computer systems and
media are seized, and the media are examined for other evi-
dence of the possession or distribution of CP. Such evidence
includes CP burned to a DVD or other unassailable [2] evi-
dence of intent to possess. Often the evidence gathered for
the search warrant is not introduced at the criminal trial
unless the search warrant is challenged; thus it is essential to
investigations but must meet only the lower probable cause
standard.
In comparison, a civil claim of copyright infringement need
meet much lower standards. While a warrant cannot be
issued by civil investigators, the billing records and comput-
ers at the location can be subpoenaed based on merely a
relevance standard. Evidence is relevant if it “has a ten-
dency to make any fact more probable or less probable than
it would be without the evidence” [23]. As previous work
has shown [14] this bar is very low, and the smallest success
from our attacks would be suﬃcient for civil subpoena —
precision of 95% conﬁdence, as we can achieve, is for a civil
subpoena extraordinarily high. Once at trial, only a prepon-
derance of evidence standard must be met for a judgment to
be awarded.
4. TIMING ATTACKS
In this section, we demonstrate that the current design of
OneSwarm is subject to a novel timing attack. We also show
that the deployed version of the system has this ﬂaw. We
then derive a conﬁguration of OneSwarm delays that deters
the attack; however, the new delays that OneSwarm enforces
for responding to queries must be increased to 133%–400% of
the delays imposed by Onion Routing. Further, the resultant
search traﬃc on OneSwarm ﬂoods potentially thousands of
nodes.
The basic design goal of OneSwarm is to prevent attackers
from distinguishing between two cases for some targeted
peer T and the source of some ﬁle (we use ﬁle and content
synonymously):
• Case A: T is the source a particular ﬁle;
• Case B: T is not the source a particular ﬁle. Instead
T is only a proxy on the path to some other peer it does
not know, S, that is a source.
There is a major diﬀerence between the goals of the One-
Swarm security model and the goals our forensic analysis.
When the source of a ﬁle is a trusted friend, the OneSwarm
design considers that as an example of Case B. In our analy-
sis, we consider it as an example of Case A since the peer
has explicit knowledge via the OneSwarm GUI of what its
trusted friends are sharing on the network, and the peer is
therefore a knowing source of the content as well; we return
to this point in Section 4.3.
OneSwarm’s design defeats a Basic Timing Attack where
a single peer A issues a query to its neighbor T . The at-
tacker compares the application-level response time to the
network-based roundtrip time; if they are similar, then the
attacker judges that T is the source.
To defeat the attack, when a peer is the source a requested
ﬁle, it introduces an artiﬁcial delay of 150–300ms before
answering queries, as described in Section 2. This response
delay, r, is chosen randomly but deterministically for the
speciﬁc ﬁle.
If a peer does not possess a queried ﬁle, it forwards the
query on to its neighbors only after a delay, q, which is
150–300ms in the paper (but exactly 150ms in the current
implementation). This added delay allows the original querier
and intermediaries the chance to send a query cancel message
that will catch up with the propagating query. Recall from
Section 2 that the cancel messages are essential in preventing
traﬃc explosions, since there are no TTL ﬁelds in OneSwarm
messages.
OneSwarm peers do not keep a cache of previously an-
swered queries. However, we discuss the eﬀects of query and
response caching on this attack later in the section and show
that the attack is not substantively aﬀected.
The attack makes use of two central variables:
• l is the one-way network layer delay between two peers.
We assume such delays are symmetric and let RT T = 2l.
• δ is the application-level roundtrip delay in receiving
OneSwarm search query responses from a source. Since
OneSwarm enforces extra delays, this is not equal to
the RTT.
4.1 The Twin Timing Attack
OneSwarm is vulnerable to a new attack using simultaneous
queries from two attackers, which we dub the twin timing
attack. The peers don’t need synchronized clocks, but the
two queries must be issued before the target changes from
possessing the ﬁle to not possessing it, and before network-
layer conditions change drastically. The complete attack
appears in Algorithm 4.1 and refers to two attackers C1 and
C2, both attached to a target peer T .
204Let sumB equal the sum of δ1 and δ2 for Case B.
sumB = 2l1 + 2q + 2l2 + 2r + 4l3
(7)
Because all application-level delays are chosen from 150–
300ms, we can bound sumB as
sumB ≥ 600 + 2l1 + 2l2 + 4l3
(8)
Let RT T1 and RT T2 be the measure network roundtrip time
to T from C1 and C2, respectively. When T is not the source
(Case B), the diﬀerence of the summed network RTTs and
the total response delay summed is at least
sumB − (RT T1 + RT T2) ≥ 600 + 4l3
(9)
When T is the source (Case A), the diﬀerence of the summed
network RTTs and the total response delay summed is at
most:
sumA − (RT T1 + RT T2) ≤ 600
(10)
In short, the attack works because the minimum value of
sumB is always larger than maximum value of sumA.
Therefore, if the diﬀerence between 2(l1 + l2) and δ1 + δ2 is
less than 600 ms, T is the source or T is knowingly conspiring
with the source as per Section 4.3.
2
Caching query results. OneSwarm does not cache queries
or query responses at peers. Doing so would thwart the attack
as it would not be clear if a response was from a cached result
or the original source. To defeat this defense, the timing
would instead be on the request for the actual content. We
assert that requests for content must also have delays as
queries for content (forwarding and response) otherwise the
Basic Timing Attack and variants would be possible. To
defeat the twin timing attack on the requests for content,
OneSwarm peers would have to cache actual content that
was recently transferred, which is an enormous change to the
OneSwarm’s design. It would increase the resources required
of peers dramatically.
4.2 Software Vulnerability to the Attack
In the OneSwarm software, r appears to be chosen between
170–340ms for text queries. If the node does not have the
ﬁle, it will forward the query after a delay of q = 150ms
but it appears that there are undocumented delays as well.
An added detail is that if a query is for a speciﬁc infohash,
the operation is slightly diﬀerent. First, the source chooses
a value for r between 170–340ms. Then, the querier learns
the torrent’s meta-information after this delay, it requests
speciﬁc pieces, and the responses to each are delayed by 20–
40ms by the source. We analyze only the text query process
in this paper. When responses to a query are forwarded to
an intermediate peer there is never a delay in forwarding.
With these settings in the software, the proof remains valid.
However, the multi-threaded nature of the software makes
it impossible for us to be sure of its actual operation. In
fact, in examining the software, we found unintended delays
unknown to the developers themselves, which were ﬁxed in
later versions that we did not test. An added delay of about
100 ms is unintended in the code according to the developers.
We rely on experimentation to empirically validate the attack
on the software since its exact operation is unclear.
We implemented the attack on a set of four machines
within our building on separate networks, taking the roles
Figure 1: The attacker attempts to distinguish two
scenarios. In Case A, peer T is the source of queried
content. In Case B, peer S, one hop from T , is the
source.
Algorithm 4.1: TwinTimingAttack(T )
1. C1 and C2 each measure their respective network roundtrip
time to T as RT T1 and RT T2, respectively.
2. C1 and C2 simultaneously query T for the same content.
3. Let δ1 and δ2 be the total delays after which C1 and C2
receive replies, respectively.
4. If (δ1 + δ2) − (RT T1 + RT T2)  min(q) − min(r) + RT T3
(12)
where RT T3 is the roundtrip time between the Target and
the Source as shown in Figure 1(right). We let max(·) and
min(·) represent the maximum and minimum values of a
given delay variable taken from uniform distributions.
PROOF: The twin timing attack is possible because of the
diﬀerence between the summed total delay for Cases A and