definition node. When it is important to make a distinction between the master definition
node and all other master nodes that are not the master definition node, the latter are
referred to as non-MDN nodes.
The master definition node has the following significance:
Copyright © 2010 - 2018 EnterpriseDB Corporation. All rights reserved. 23
EDB Postgres Replication Server User’s Guide
 The publication is initially created in the master definition node, and the tables
comprising the publication must exist in the database to be designated as the
master definition node at the time the publication is defined.
 The publication can be initially replicated to other master nodes by means of a
snapshot from the master definition node.
 Each subsequent master node added to the replication system must either: 1)
contain no tables with the same schema-qualified names as the publication tables
in the master definition node; or 2) contain all publication table definitions as they
exist in the master definition node with the same schema-qualified names. In the
first case, when you add the master node, you select the option to replicate the
publication schema from the master definition node. In the second case, you do
not select this option.
 The table rows in a master node can be reloaded from the master definition node.
The master node tables are truncated and the rows reloaded by a snapshot from
the master definition node.
Once the multi-master replication system is defined, changes (inserts, updates, and
deletions) to rows of the publication tables on any master node are synchronized to all
other master nodes on either an on demand or scheduled basis.
Generally, changes must not be made to the table definitions in any of the master
nodes including the master definition node. If such changes are made, they are not
propagated to other nodes in the multi-master replication system unless they are made
using the DDL change replication feature described in Section 7.8. If changes are made to
tables without using the DDL change replication feature, there is a risk that future
replication attempts may fail.
Copyright © 2010 - 2018 EnterpriseDB Corporation. All rights reserved. 24
EDB Postgres Replication Server User’s Guide
Figure 2-7 - In a multi-master replication system, table rows can be updated at any master node
2.2.5 Asynchronous
xDB Replication Server performs replications asynchronously. The systems hosting the
databases do not always have to be running continuously in order for successful
replication to occur. If one system goes offline, replication resumes when it comes back
online if there is still pending data to replicate.
In addition you can create a schedule for your replication system. xDB Replication Server
initiates and performs replications regularly according to the assigned schedule. This
allows you to run the replication system unattended. See Section 7.2 for directions on
creating a schedule.
2.2.6 Snapshot and Synchronization Overview
xDB Replication Server performs two different types of replications. These two main
types are called snapshot replication and synchronization replication.
In either method, the source tables refer to the tables from which the replication data is
originating (the publication in a single-master replication system, or the master node
whose changes are being replicated to another master node in a multi-master replication
system).
Copyright © 2010 - 2018 EnterpriseDB Corporation. All rights reserved. 25
EDB Postgres Replication Server User’s Guide
The target tables are the tables that are receiving the replication data from the source
tables (the subscription tables in a single-master replication system, or the master node
receiving changes from another master node in a multi-master replication system).
In snapshot replication, all existing rows in the target tables are deleted using the
database system’s TRUNCATE command. The tables are then completely reloaded from
the source tables of the publication.
In synchronization replication, only the changes (inserts, updates, and deletions) to the
rows in the source tables since the last replication are applied to the target tables.
Note: Deletion of all rows in a source table executed by the SQL TRUNCATE command
results in replication to the target tables only if the log-based method of synchronization
replication is used. If the trigger-based method of synchronization replication is used,
execution of the TRUNCATE command on a source table does not replicate the effect to
the target tables. You must perform a snapshot from the source table to the target tables if
the trigger-based method is used. (The difference between the trigger-based method and
the log-based method is discussed as follows.)
Synchronization replication is implemented using two different methods – the trigger-
based method and the log-based method.
In the trigger-based method changes to rows in the source tables result in the firing of
row-based triggers. These triggers record the changes in shadow tables. The changes
recorded in the shadow tables are then periodically extracted from the shadow tables,
converted to an in-memory data structure, and applied to the target tables by means of
SQL statements executed using JDBC. See Section 2.2.9 for information on the trigger-
based method.
In the log-based method changes to rows in the source tables are extracted from the
Write-Ahead Log segments (WAL files) using asynchronous streaming replication
implemented by the logical decoding feature available in Postgres database servers. The
extracted changes are converted to an in-memory data structure and applied to the target
tables by means of SQL statements executed using JDBC. See Section 2.2.10 for
information on the log-based method.
In a multi-master replication system, the manner in which changes accumulated on all
master nodes are replicated to all other master nodes is conceptually done in groups
identified by the source master node with the changes to be replicated. See Section 2.2.11
for information on this process and the improvement for the log-based method with
parallel replication.
In a single-master replication system, the very first replication to a newly created
subscription must always be done by a snapshot. Subsequent replications can be done by
snapshot or by synchronization provided that the publication is not defined as a snapshot-
only publication as discussed in Section 2.2.7.
Copyright © 2010 - 2018 EnterpriseDB Corporation. All rights reserved. 26
EDB Postgres Replication Server User’s Guide
In a multi-master replication system, the very first replication from the master definition
node to a newly added master node must always be done by a snapshot. Subsequent
replications between master nodes occur by synchronization. However, it is possible to
perform subsequent snapshots from the master definition node to any other master node.
2.2.7 Snapshot-Only Publications
When a publication is created in a single-master replication system, the publication can
be defined as a snapshot-only publication. Replication from a snapshot-only publication
can only be done using the snapshot replication method. Synchronization replication is
not permitted on a snapshot-only publication.
A snapshot-only publication cannot be created in a multi-master replication system.
See Section 2.4.4 for a discussion of the advantages of using a snapshot-only publication.
2.2.8 Snapshot Replication
In snapshot replication, the target tables are completely reloaded from the source tables.
The database system’s truncate operation is used to delete all rows from the target tables.
For Oracle and SQL Server only: Oracle and SQL Server target tables are loaded using
JDBC batches of INSERT statements.
For Postgres only: In general, Postgres target tables are loaded using the JDBC COPY
command since using truncation and COPY is generally faster than if you were to execute
an SQL DELETE statement against the entire table and then add the rows using JDBC
batches of INSERT statements. If the COPY command fails, the publication server retries
the snapshot using JDBC batches of INSERT statements.
If the target table (regardless of database type) contains a large object data type such as
BYTEA, BLOB, or CLOB then rows are loaded one at a time per batch using an INSERT
statement. This is to avoid a heap space error resulting from potentially large rows.
Loading time can be decreased by allowing multiple inserts per batch, which is done by
adjusting the configuration option lobBatchSize described in Section 5.8.1.
Note: Advanced Server supports a number of aliases for data types. Such aliases that
translate to BYTEA are treated as large object data types. See the Database Compatibility
for Oracle Developers Reference Guide for a listing of Advanced Server data types. (See
the Database Compatibility for Oracle Developer’s Guide for Advanced Server version
9.5 or earlier versions.)
Under certain circumstances, the corresponding Postgres target table created for certain
types of Oracle partitioned tables is a set of inherited tables. In these cases, the SQL
DELETE statement is used on the inherited child tables instead of truncation. See Section
10.4.1.4 for additional information on replicating Oracle partitioned tables.
Copyright © 2010 - 2018 EnterpriseDB Corporation. All rights reserved. 27
EDB Postgres Replication Server User’s Guide
A server configuration option is available that forces the snapshot replication process to
use the Oracle database link utility instead of JDBC COPY to populate the Postgres target
tables from an Oracle publication. Oracle database link provides an additional
performance improvement over JDBC COPY. See Section 5.8.1 for information on using
the Oracle database link option.
See Section 5.8.1 for information on various configuration options to optimize snapshot
replication.
2.2.9 Synchronization Replication with the Trigger-Based Method
If a publication in a single-master replication system is created that will be used in
synchronization replications with the trigger-based method, the publication server installs
an insert trigger, an update trigger, and a delete trigger on each publication table. In a
multi-master replication system, each replicated table in each master node employing the
trigger-based method has an insert trigger, an update trigger, and a delete trigger.
The publication server also creates a shadow table for each source table on which triggers
have been created. A shadow table is a table used by xDB Replication Server to record
the changes (inserts, updates, and deletions) made to a given source table. A shadow table
records three types of record images: For each row inserted into the source table, the
shadow table records the image of the inserted row. For each existing row that is updated
in the source table, the shadow table records the after image of the updated row. For each
row deleted from the source table, the shadow table records the primary key value of the
deleted row.
Note: In a multi-master replication system, the before image of an updated row is also
stored in the shadow table in order to perform update conflict detection. See Section 6.6
for information on conflict detection in a multi-master replication system.
After each change on the source table, one of the insert, update, or delete triggers is
executed. These are row triggers, so for each row affected by the change, the trigger
executes. Each execution of the trigger records a row of the appropriate type (insert,
update, or deletion) in the shadow table of the corresponding source table.
Though changes made to the source tables since the last replication occurred are applied
to the target tables using SQL INSERT, UPDATE, and DELETE statements, the actual SQL
statements run against the target tables are not the same SQL statements that were run
against the source tables.
When synchronization replication occurs, the publication server executes JDBC batches
of SQL statements (also referred to as transaction sets) against the target tables. The
batches contain an INSERT statement for each shadow table row recording an insert
operation, an UPDATE statement for each shadow table row recording an update
operation, and a DELETE statement for each shadow table row recording a delete
operation. Each batch is executed in one transaction.
Copyright © 2010 - 2018 EnterpriseDB Corporation. All rights reserved. 28
EDB Postgres Replication Server User’s Guide
Shadow table rows that were applied to target tables can be viewed as shadow table
history in the xDB Replication Console (see Section 7.4.3).
Note: A single SQL statement executed against a source table may result in many rows
recorded in a shadow table, and therefore, many SQL statements executed against the
target table. For example, if a single UPDATE statement affects 10 rows in the source
table, 10 rows will be inserted into the shadow table – one for each row in the source
table that was updated. When the publication server applies the changes to the target
table, 10 UPDATE statements will be executed.
Note: For greater efficiency, when changes to the source tables consist of SQL
statements that each affect a large number of rows, the publication server may employ the
use of prepared SQL statements. See Section 5.8.2 for directions on how to control the
usage of prepared SQL statements as well as information on various other configuration
options to optimize synchronization replication.
2.2.10 Synchronization Replication with the Log-Based Method
In PostgreSQL 9.4 a feature has been introduced called logical decoding (also called
logical replication or changeset extraction). This feature provides the capability to
extract data manipulation language (DML) changes from the Write-Ahead Log segments
(WAL files) in a readable format.
For information on logical decoding see the PostgreSQL Core Documentation located at:
https://www.postgresql.org/docs/current/static/logicaldecoding.html
The key significance of this feature is the ability to capture data changes to the
publication tables without impacting the online transaction processing rate against these
tables that occurs when using the trigger-based method. The trigger-based method results
in the firing of row-level triggers whenever data changes occur, then inserting these data
changes into shadow tables for temporary storage before applying the changes to the
target databases.
Thus, extracting data changes using logical decoding can be beneficial for improving
database server throughput and replication latency.
However, note that the logical decoding interface streams changes for all tables in a given
database, which may have a performance overhead associated with it. For example, if a
database contains 100 tables, and the user is interested in replicating only a small subset
of these tables, say only 20 tables in a single publication, the logical decoding protocol
will stream changes for all 100 tables to the publication server. The publication server
eventually filters out the changes for the irrelevant 80 tables. However, this results in
network overhead caused by the additional changeset load that is not required by the
replication system.
Copyright © 2010 - 2018 EnterpriseDB Corporation. All rights reserved. 29
EDB Postgres Replication Server User’s Guide
Using logical decoding to extract changes from a publication database during xDB
synchronization replication is referred to as the log-based method.
The following sections describe the basic requirements and concepts for the log-based
method of synchronization replication.
2.2.10.1 Requirements and Restrictions
The following are the general requirements and restrictions when using the log-based
method for any database of a single-master or multi-master replication system:
 The selection of either the trigger-based method or the log-based method is a
characteristic applicable to only the publication database. The choice is made
when defining the master database of a single-master replication system (see
Section 5.2.2) or the master definition node of a multi-master replication system
(see Section 6.2.2).
 The logical decoding feature, and hence the log-based method, is supported
beginning with PostgreSQL version 9.4. Therefore, in order to use the log-based
method for a publication database, that publication database must be running
under PostgreSQL version 9.4 or later, or under Advanced Server version 9.4 or
later.
 In a single-master replication system, whether the master database uses the
trigger-based method or the log-based method has no additional impact on the
rules for choosing the subscription database as described in Section 10.1. For
example, even if the log-based method is chosen for the master database, the
subscription database may be running on Postgres version 9.4 as well as any
supported, earlier version of Postgres, as well as Oracle or SQL Server as
described in Section 10.1.
 In a single-master replication system, the master database may contain one or
more publications (that is, named sets of tables for replication). This is applicable
to a master database using either the trigger-based method or the log-based
method.
 It is permissible to have multiple, single-master replication systems running under
a publication server where some master databases may use the trigger-based
method while others use the log-based method.
 In a multi-master replication system, the selection of either the trigger-based
method or the log-based method on the master definition node determines the
method for all other master nodes. In other words, if the trigger-based method is
chosen for the master definition node, then all other master nodes will use the
trigger-based method. If the log-based method is chosen for the master definition
node, then all other master nodes will use the log-based method.
 As a consequence of the restriction described in the preceding bullet point, in
order to use the log-based method for a multi-master replication system, all of the
master nodes of the system must be running under Postgres version 9.4 or later,
and all such Postgres database clusters must be configured to use logical decoding
for the log-based method.
Copyright © 2010 - 2018 EnterpriseDB Corporation. All rights reserved. 30
EDB Postgres Replication Server User’s Guide
Selection of the log-based method for any database impacts the configuration of the
Postgres database cluster containing that database.
If you plan to use the log-based method with any publication database running under a
Postgres database server, the following configuration parameter settings are required in
the configuration file, postgresql.conf, of that Postgres database server:
 wal_level. Set to logical.
 max_wal_senders. Specifies the maximum number of concurrent connections
(that is, the maximum number of simultaneously running WAL sender processes).
Set at minimum, to the total number of master databases of single-master
replication systems and master nodes of multi-master replication systems on this
database server that will use the log-based method.
 max_replication_slots. Specifies the maximum number of replication slots. If the
database server supports both single-master replication systems and multi-master
replication systems, then max_replication_slots must be set at minimum to
the sum of the requirements for both replication systems. For support of SMR
systems, the minimum requirement is the total number of master databases of the
single-master replication systems that will use the log-based method. For support
of MMR systems, the minimum requirement is the total number of master nodes
in the multi-master replication system multiplied by the number of master nodes
residing on this database server. For information, see Section 2.2.10.4.
 track_commit_timestamp. Set to on. This configuration parameter applies only
to Postgres database servers of version 9.5. See Section 6.6.1 for additional
information.
Also see Section 5.1.2 for setting these parameters for a single-master replication system.
See Section 6.1.2 for a multi-master replication system.
In addition, the pg_hba.conf configuration file of the Postgres database server must
contain an entry permitting REPLICATION access for each database using the log-based
method running on the database server. The access must be permitted to the publication
database user specified when creating the publication database definition using the xDB
Replication Console (see Section 5.2.2 for a single-master replication system or Section
6.2.2 for a multi-master replication system) or the xDB Replication Server Command
Line Interface (CLI) (see Section 8.3.6).
See Section 5.1.6.3 for setting REPLICATION access for a single-master replication
system. See Section 6.1.5 for a multi-master replication system.
For configuration options in the publication server configuration file that are specifically
applicable to the log-based method see Section 10.4.1.15.
Copyright © 2010 - 2018 EnterpriseDB Corporation. All rights reserved. 31
EDB Postgres Replication Server User’s Guide
2.2.10.2 Logical Replication Slots
When using the log-based method on a publication database, the underlying logical
decoding framework exposes the data changes (the changeset stream) by means of a
logical replication slot.
A logical replication slot represents a changeset stream and applies to a single database.
The xDB Replication Server assigns a unique identifier, called the slot name, to each
logical replication slot it creates in the form xdb_dboid_pubid where dboid is the
publication database object identifier (OID) and pubid is the publication ID assigned by
the xDB Replication Server. All slot names are unique within a Postgres database cluster.
Thus, for each single-master replication system using the log-based method, a replication
slot is required for the publication database of each such system.
For a multi-master replication system using the log-based method, each master node
requires a replication slot.
The maximum number of replication slots permitted for a database server is controlled by
the max_replication_slots configuration parameter in the postgresql.conf file.
Therefore this configuration parameter must be set to a large enough value to account for
all publication databases defined with the log-based method of single-master replication
systems running on the database server as well as all master nodes of a multi-master
replication system defined with the log-based method running on the database server.
Additional replication slots are required to support the usage of replication origin (see
Section 2.2.10.4).See Section 5.1.2 for additional information on configuration
parameters for single-master replication systems. See Section 6.1.2 for multi-master
replication systems.
2.2.10.3 Streaming Replication with the WAL Sender Process
The changeset stream is accessible to the xDB publication server by the WAL sender
process (walsender) using the streaming replication protocol.
The xDB publication server connects using the walsender interface through which
changes are streamed on a continual basis. The continuous streaming eliminates the need
for explicitly polling for changes.
The following are the basic synchronization steps using the log-based method: