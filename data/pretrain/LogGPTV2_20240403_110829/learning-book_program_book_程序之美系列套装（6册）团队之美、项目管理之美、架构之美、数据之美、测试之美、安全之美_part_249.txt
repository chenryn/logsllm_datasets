MySQL数据库。虽然连Oracle都无法帮助我们解决在ETL方面遇到
的可扩展性挑战，但是我们很高兴拥有一个能够正常运行的包含几
百万兆（T)数据的数据仓库。
1408
---
## Page 1410
然后，我们打并点击流日志：仅仅第一天，在Oracle数据库上就发
送了400GB的无结构化数据。我们再次对使用数据仓库表示怀疑。
超越数据仓库
根据互联网数据中心(IternetDataCenter,IDC)显示，数字世界在2011
年将超过1800exabyte（1exabyte=2byte）。这么庞大的数据将无法
通过关系数据库来管理。因此，对数据库管理系统存在很紧道的需
求，要求该系统能够从无结构化数据和结构化数据中抽取信息，但
是人们对如何进展没有达成一致。
特别是，自然语言数据量丰富，信息量大，但是数据仓库管理不
善。自然语言和其他无结构化数据通常在文档库和语音记录中获
取，为了管理这些数据，企业组织开始超越了数据仓库供应商的产
品，探索很多新的领域，包括企业搜索。
虽然很多搜索公司构建了很多工具来收集很多超链接文档即万维网
(WW)，一些企业搜索公司选择重点研究内部文档集的管理。
Autonomy公司成立于1996年，由一些剑桥大学的研究人员组成，他
们充分利用贝叶斯推导算法(Byesianinferencealgorithms）来帮助定位
重要的文档。FastSearch andTransfer(FAST)公司于1997年在挪威成
立，其核心技术是更直接的关键字搜索和排序。两年后，Endeca公
司成立了，其核心是研究使用结构化的元数据遍历文档集，该技术
即"分面搜索"(fcted search)技术。G公司看到了其在搜索领域专长的
机遇，在2000年推出了企业搜索设施。
在短短的几年内，企业搜索已经成长为拥有几十亿美元的市场，该
市场和数据仓库市场几乎完全分离。Endeca拥有一些处理更传统的
商业智能的工具，一些数据库供应商为系统引入了文本挖掘能力，
但是对结构化的和无结构化的企业数据进行管理仍然尚未实现一个
完善的、集成的解决方案。
企业搜索和数据仓库都是技术解决方案，这些方案是为了最大化利
用企业的信息资源来改进性能。早在1944年，MIT教授KurtLewin提
出了“行为研究"(ationresearch)的螺旋式框架，其每个螺旋阶段是由
计划、行为以及关于行为结果的事实发现组成的循环。对该问题更
现代的方法是PeterSenge的“学习型组织"(LarningOrganization)概
念，其思想在他的书《ThefifthDiscipline》（BoadwayBusiness出
版）中做了详细阐述。这两种管理理论在很大程度上都依赖于企业
1409
---
## Page 1411
组织根据先前收集到的行为信息做出反思并适应的能力。从这个角
度来说，信息平台是一个学习型组织用于摄取、处理和生成实现螺
旋式行为研究的必要信息的基础设施。
讨论完结构化和无结构化的数据管理，让我们一起回到Facebook的
故事。
“猎豹"和"大象”!]
从第一天开始对Facebook的点击流写日志起，到现在我们已经收集
了超过400GB的数据。对该数据集的加载、索引和聚集操作对
Oracle数据库的负载很重。虽然做了很多优化操作，但是我们还是
无法在24小时内完成对一天的点击流的聚集操作。很显然，我们需
要把日志文件聚集到数据库外，只在数据库中保存摘要信息
(smmaryinformation)供后期查询。
幸运的是，一个来自某大型网站的顶尖工程师加入了我们团队，他
有过处理大规模Web点击流的经验。仅仅几周的时间，该工程师就
构建了一个名为Cheetah（猎豹）的并发日志处理系统，该系统能够
在两个小时内处理一天的点击流。这实在太让人振奋了。
但是，Cheetah存在一些不足：首先，在处理完点击流数据后，原始
数据还是以归档方式保存(achival storage)，不能够被再次查询。此
外，Cheetah是从一个共享的NetApp归档数据中获取点击流数据，而
NetApp归档数据的读带宽受限。每个日志文件的“模式"(shema)是嵌
入在处理脚本中，而不是保存为可查询格式。我们没有收集进程信
息，而是通过Unix基础工具cron来调用Cheetah任务，因此无法应用
复杂的加载共享逻辑。最重要的是，Cheetah不是开源的。我们团队
很小，资源有限，无法分配更多的资源来并发、维护和给新用户培
训使用Cheetah系统。
Apache的Hadoop项目，由DougCutting和MikeCafarella于2005年末启
动，是我们取代Cheetah的最佳选择。以Doug的孩子的玩具大象命
名，Hadoop项目的目标是实现遵从Apache2.0许可的G公司的分布式
文件系统和MapReduce技术。雅虎在2006年1月聘用了Doug
Cutting，并投入了大量的工程资源来开发Hadoop。在2006年4月，
该软件使用188台服务器，能够在47小时内，对1.9T的数据进行排
序。虽然Hadoop的设计在很多方面优于Cheetah，但它在那时还太慢
了，不能够满足我们的需求。在2008年4月，Hadoop用910台服务
1410
---
## Page 1412
器，可以在209秒内对1T的数据进行排序。由于Hadoop性能的改
进，我说服了运行组团队利用60台Web服务器和3台500GB的SATA
驱动器，开始在Facebook第一次部署Hadoop集群。
在最开始，我们通过流方式在Hadoop和Cheetah中都导入一部分日
志。Hadoop增强的编程能力加上其能够查询历史数据，从而推动了
一些其他有趣的项目。其中一个应用是对所有Facebook用户交互的
有向对进行打分来确定这些用户的亲密程度；这个分数可以被用于
搜索和新闻订阅的排序。过了一段时间，我们把所有的Cheetah工作
流都迁移到Hadoop上，废弃了前者。后来，事务数据库收集程序也
都迁移到了Hadoop。
有了Hadoop,Facebook的基础设施可以支持对无结构化和结构化的数
据的大规模分析。随着平台扩展为每大儿百TB的数据规模，可以执
行成千上万个任务，我们发现由于现在系统能够存储和检索的数据
规模很大，我们可以构建新的应用，探索新问题的答案。
当Facebook向所有的用户开放注册，用户数在一些国家增长迅猛。
但是在那时，我们无法根据国家执行点击流粒度分析。自从有了
Hadoop集群，我们可以通过加载所有的历史访问日志到Hadoop，写
一些简单的MapReduce任务来重新分析Facebook在一些国家，如加
拿大和挪威，增长迅猛的原因。
Facebook的用户每天都有几百万的半公开(smi-public)的对话。据一
次内部估算，留言板的数据量是博客的10倍！但是，这些对话的内
容还是无法进行访问用来数据分析。在2007年，一个对语言学和统
计学有强烈兴趣的暑期实习生RoddyLindsay加入了数据组。通过
Hadoop,Roddy能够独立构建一个强大的趋势分析系统，该系统名为
Lexicon，每天晚上能够处理TB级别的留言板数据。可以通过
URL:http：//facebook.com/lexicon查看结果。
在为Facebook应用构建信誉积分系统时，我们证明了把不同系统的
数据存储到相同的存储库中会导致严重的问题。在2007年5月启动
了Facebook平台后不久，我们的用户就被“灌没"在添加应用的请求
中。我们很快意识到需要添加一个工具来识别有用的应用和用户认
为是spam（垃圾）的应用。通过收集API服务器的数据、用户信息
以及来自网站本身的行为数据，系统能够构建一个模型对应用进行
打分，这使得系统可以分发我们认为对用户最有用的应用邀请。
1411
---
## Page 1413
[L].猎豹和大象在此采用了借代的修辞方法。猎豹(ceetah)指的是
Facebook的TheCheetah日志处理系统，大象（eephant)指代的是
Hadoop项目，具体参见下文。
不合理的数据有效性
在最近的文章中，G公司研究员发表了三部曲，提炼出他们在尝试
解决机器学习中的一些最困难的挑战的心得。当讨论到语音识别和
机器翻译，他们认为"简单的模型和大量的数据总是胜过在少量数
据上构建的复杂(eaborate)模型。"我不想和他们的发现争论，但
是，当然存在某些领域，更复杂的模型会更成功。但是基于G公司
研究员的经验，确实存在大量问题，更多的数据和更简单的模型对
它们会更有效。
在Facebook,Hadoop是我们探索不合理的数据有效性的工具。比如，
当把Facebook网站翻译为其他语言时，我们试着征集那些母语为特
定语言的用户，以便帮助我们完成翻译任务。我们的一个数据科学
家CameronMarlow，对所有的Wikipedia进行了爬虫，对每种语言构
建了特征三元频率计数（caractertrigramfrequencycounts)。使用这些
频率计数，他构建了一个简单的分类器，该分类器可以通过识别用
户的一组留言来确定他的母语。使用该分类器，我们可以通过有针
对性方式，积极地征集用户加入我们的翻译项目中。Facebook和G
公司在很多应用中都用自然语言数据，详情请参看本书第14章Peter
Norvig对于该课题的探讨。
G公司的观点指出了对现代商业智能系统的第三条变革：除了在一
个系统中管理结构化和无结构化的数据，这些商业智能系统必须能
够扩展到可以存储足够多的数据，使得可以采取“简单模型，大量
数据”的方法来实践机器学习。
新工具和应用研究
在Facebook，绝大部分Hadoop集群的早期用户都是渴望追求新兴技
术的工程师。为了使企业的更多人可以访问信息，我们在Hadoop上
构建了一个数据仓库框架，并称为Hive。Hive的查询语言类似于
SQL，支持嵌入MapReduce逻辑、表分区、抽样和处理任意序列化
数据的能力。最后一个特征至关重要，因为收集到Hadoop的数据在
结构上不断变化：充许用户指定自己的序列化模式，可以使我们把
为数据指定结构问题转为把数据加载到Hive。此外，我们还实现了
1412
---
## Page 1414
一个简单的用户界面（uerinterface,UI来构建Hive查询，名为Hipal，
使用这些新的工具，市场、产品管理、销售和客户服务的非工程师
都能够在几TB的数据上自己执行查询。经过几个月的内部使用后，
在Apache2.0许可下，Hive成为Hadoop的官方子系统，现在仍然在
积极地开发中。
除了Hive，我们构建了分享图表和图形的门户Argus（受IBM的Many
Eyes项目启发）、工作流管理系统Databee、用Python写MapReduce
脚本的框架PyHive、为终端用户提供结构化数据服务的存储系统
Cassandra（现在作为开源，在Apache孵化器中）。
随着这些新系统的稳定，我们最终构建了由单一Hadoop集群管理的
多层模式(mlipletiers)的数据。企业中的所有数据，包括应用日志、
事务数据库和Web爬虫，都以原始数据格式，定期收集到Hadoop分
布式文件系统中(HFS)。夜间执行的几万个Databee进程将把一部分
数据转化为结构化格式，把它放入由Hive管理的HDFS文件目录
中。在Hive中执行下一步聚集操作，用来生成Argus服务报表。此
外，在HDFS内，在自己的home目录下维护“沙盒"(sndboxes)的工程
师可以运行原型(pototype)任务。
目前，Hadoop包含了将近25亿兆（2.5PB）的数据，而且以每天15TB
的数量级增加。每天都有3000个以上的MapReduce任务在运行，处
理55TB的数据。为了适应这些运行在集群上的任务的不同优先级，
我们构建了作业调度器，实现在多个队列上的资源共享。除了支持
内部和外部的报表、a/b测试管道和很多不同的数据密集型产品和服
务，Facebook的Hadoop集群可以实现一些有趣的应用研究项目。
由数据科学家ItamarRosenn和CameronMarlow主持的一个纵向研究
项目(lngitudinalstudy)用于预测长期的用户参与的最重要的因素是什
么。我们使用信息平台来选择一些用户的样本，删除游离点，并对
参与度的不同尺度使用一些最小角度回归技术(last-angleregression)
来生成大量的特性。有些特性能够通过Hadoop生成，包含计算好友
网络密度的各种尺度和基于信息特性的用户范围。
另一个探索激励新用户贡献内容的动机的内部研究，在2009年CHI
会议的论文"FeedMe:MotivatingNewcomerContributioninSocial
NetworkSites”中描述。Facebook数据组的一个更新的研究是查看信
息流是如何在Facebook的社会图中流动，该研究的标题为
1413
---
## Page 1415