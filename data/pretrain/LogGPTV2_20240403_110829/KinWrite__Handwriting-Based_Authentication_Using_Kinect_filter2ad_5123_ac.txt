To address this issue, we apply a Kalman ﬁlter to smooth
the raw 3D-signatures that have been normalized. For sim-
Figure 6. An illustration of path angle and cur-
vature.
plicity, we smooth the three coordinates of the raw 3D-
signature separately. Take the x-coordinate as an example.
We denote the prediction of the underlying ﬁngertip posi-
tion to be p(t) = (px(t), py(t), pz(t))T at the t-th frame
and deﬁne the state x(t) = (px(t), ˙px(t), ¨px(t))T at the t-th
frame as a vector of the predicted ﬁngertip position, velocity
and acceleration. The state transition of the Kalman ﬁlter is
then x(t) = Ax(t − 1) + wx(t). Based on the theory of
motion under a constant acceleration, we can deﬁne
 1 (cid:52)t
0
0
A =
(cid:52)t2
1 (cid:52)t
2
1
0
(1)
where (cid:52)t is the time interval between two consecutive
frames. Given the typical rate of 30 frames per second for a
Kinect sensor, we have (cid:52)t = 1
30 seconds.
For the observation in the x coordinate, we only have the
raw ﬁngertip position ps
x(t) but no velocity or acceleration.
Thus, we can write an observation equation for the Kalman
x(t) = cx(t) + vx(t), where c = (1 0 0). We
ﬁlter as ps
model the process noise wx(t) and the measurement noise
vx(t) to be zero-mean Gaussian distributions. For the pro-
cess noise, we choose the same covariance matrix Qx for
all the frames. More speciﬁcally, Qx is a 3 × 3 diagonal
matrix with three identical diagonal elements, which equals
the variance of acceleration (along x coordinate) estimated
x(t), t = 1, 2,··· , N. For the measurement noise,
from ps
−202−2−10123−505 x−axisy−axis z−axisRawSmoothed−2−1012−2−1012x−axisy−axis−2−1012−2−1012z−axisx−axis−2−1012−2−1012y−axisz−axisp(t-1)p(t)p(t+1)p(t+2)p(t+3)p(t+4)α(t)y-axisx-axisz-axis1/κ(a) X-axis
(b) Y-axis
(c) Z-axis
Figure 7. The position comparison of four 3D-signature samples: two ‘SA’ 3D-signatures were signed
by the same user, ‘USC’ and ‘JASON’ were from different users. The two ‘SA’ 3D-signature samples
show a larger degree of similarity than the others.
we choose the time-independent variance vx as the vari-
x(t), t = 1, 2,··· , N).
ance of the ﬁngertip positions (i.e., ps
Following the same procedure, we set the state-transition
and observation equations for y and z coordinates. With
the state-transition equation and the observation equation,
we use the standard Kalman ﬁlter algorithm to calculate
a smoothed 3D-signature with reﬁned ﬁngertip positions
p(t), t = 1, 2,··· , N. Figure 5 shows an example com-
paring the raw 3D-signature with the smoothed one.
4.2 Feature Extraction
4.2.1 Feature Selection
Based on the reﬁned signature that connects p(t), t =
1, 2,··· , N, we extract various features for veriﬁcation. As
discussed earlier, one major advantage of KinWrite is to
use simple, easy-to-remember passwords as the basis of 3D-
signatures to provide a user friendly authentication method.
Given a simple-shape signature, global features, such as the
central position and the average velocity, usually do not
contain much useful information for distinguishing differ-
ent signatures. Thus, we extract the following six types of
local features at each point and obtain a feature vector of 14
dimensions, as summarized in Table 1.
1. Position and Position Difference between Frames. The
ﬁngertip position in the t-th frame is denoted as
p(t) = (px(t), py(t), pz(t))T ,
and the inter-frame position difference is deﬁned as
d(t) = (cid:107)p(t + 1) − p(t)(cid:107).
2. Velocity. The velocity of the position in the t-th frame
is deﬁned as
˙p(t) = ( ˙px(t), ˙py(t), ˙pz(t))T .
3. Acceleration. The magnitude of acceleration for the
t-th frame is deﬁned as
(cid:107)¨p(t)(cid:107).
4. Slope Angle. The slope angles at the t-th frame are
deﬁned as
θxy(t) = arctan
θzx(t) = arctan
˙py(t)
˙px(t)
˙px(t)
˙pz(t)
,
.
5. Path Angle α(t) is the angle between lines p(t)p(t+1)
and p(t − 1)p(t), as shown in Figure 6.
6. Curvature. The last feature extracted for the i-th frame
is the log radius of curvature of the signature at p(t),
i.e., log 1
κ(t), where κ(t) is the curvature in 3D space:
(cid:113)
κ(t) =
where
( ˙p(t)2
x + ˙p2
y(t) + ˙p2
c2
zy(t) + c2
xz(t) + c2
yx(t)
z(t))3/2
,
czy(t) = ¨pz(t) × ˙py(t) − ¨py(t) × ˙pz(t).
For each frame t, the feature extractor constructs a 14
dimensional feature vector; we denote it as f(t). Then, for
a 3D-signature sample p(t), t = 1, 2,··· , N, the feature
extractor constructs a sequence of feature vectors f(t), t =
1, 2,··· , N. Figure 7 shows some of the features along x,
y, and z coordinates for four 3D-signature samples. For
ease of reading, we show the feature vectors derived from
the raw 3D-signature samples prior to data processing. We
observe that the 3D-signature samples from the same user
did appear to be similar, which is the basis of verifying users
according to their 3D-signatures.
050100150200250300350400100120140160180200220240260280300FrameX  SA1SA2USCJASON05010015020025030035040020406080100120140FrameY  SA1SA2USCJASON050100150200250300350400140014501500155016001650170017501800FrameZ  SA1SA2USCJASON1. The
six
Table
types
(14−dimension) of 3D features extracted from
smoothed 3D-Signatures.
summary of
Type
Positions & Distance
Velocity
Acceleration
Slope angle
Path angle
Log radius of curvature
Features
p(t), d(t)
˙p(t)
(cid:107)¨p(t)(cid:107)
θxy(t), θzx(t),
α(t)
log 1
κ(t)
4.2.2 Feature Processing
Figure 8. An illustration of DTW.
In practice, the values of different features may have dif-
ferent ranges, but their relevancy towards the correct veriﬁ-
cation are not necessarily determined by their ranges. For
example, a path angle has a range of [−π, π] while the po-
sition px(t) has been scaled to the range of [0, 1]. This does
not mean that a path angle is 3 times more relevant than
a position. Thus, we perform two-step feature processing:
normalization and weight selection.
First, we normalize each feature such that it conforms to
a normal Gaussian distribution N (0, 1) over all the frames.
Second, we weigh each feature differently to achieve a bet-
ter performance. To obtain the weight for each feature (di-
mension), we selected a small set of training samples for
each signature (e.g., n = 4 samples for each signature), and
veriﬁed these training samples using the DTW classiﬁer (to
be discussed in Section 5) based on one feature (dimension).
For each feature (dimension), we obtain a veriﬁcation rate
for each signature, i.e., the percentage of genuine samples
in the top n = 4 ranked samples, and we simply consider
the average veriﬁcation rate over all signatures as the weight
for this feature (dimension). The intuition is that a feature
that leads to a higher veriﬁcation rate should be assigned a
larger weight. Our experimental results show that the pro-
posed feature normalization and weighting can substantially
improve the veriﬁcation results.
5 Template Selection and Veriﬁcation
In this section, we elaborate on algorithms to verify users,
based on their 3D-signatures.
5.1 Why Dynamic Time Warping
A good veriﬁcation algorithm should perform accurately
without requiring a large number of training samples, be-
cause from the usability perspective, it is unpleasant to col-
lect a large number of training samples when a user enrolls
herself.
Hidden Markov Models (HMM) are well-known statis-
tical learning algorithms used in classical signature-based
veriﬁcation systems and have shown good veriﬁcation ac-
curacy. However, HMM usually requires a large training set
(i.e., representative signature samples) to construct an accu-
rate model. With the usability constraints, it is difﬁcult to
perform well, as has been validated with our experiments.
Thus, we use Dynamic Time Warping (DTW), where one
good template is sufﬁcient for veriﬁcation.
We use DTW to quantify the difference between two 3D-
signature samples. Instead of directly calculating the fea-
ture difference in the corresponding frames, DTW allows
nonrigid warping along the temporal axis. To some degree,
time warping can compensate the feature difference caused
by the signing speed. For instance, a user may sign her 3D-
signature slowly one day and quickly another day. Given
two 3D-signature samples, we denote their feature vectors
as f1(t), t = 1, 2,··· , N1 and f2(s), s = 1, 2,··· , N2,
and construct a N1 × N2 distance matrix D with an element
dts = (cid:107)f1(t) − f2(s)(cid:107), t = 1, 2,··· , N1, s = 1, 2,··· , N2.
DTW ﬁnds a non-decreasing path in D, starting from d11
and ending at dN1N2, such that the total value of the el-
ements along this path is minimum. This minimum total
value is deﬁned as the DTW distance between the two 3D-
signature samples; we denote it as d(f1, f2). Figure 8 illus-
trates such an example.
5.2 Template Selection
Utilizing DTW as the veriﬁcation algorithm, during the en-
rollment phase for a user u, we simply choose the most
representative 3D-signature sample fu from the training set,
which we call the template (3D-signature) of the user u.
With this template, we can verify a test 3D-signature sam-
ple f of the user u by evaluating their DTW distance d(fu, f):
If the DTW distance is larger than a threshold dT , the veri-
ﬁcation fails. Otherwise, the veriﬁcation succeeds.
How well KinWrite performs is determined by the
6 Experiment and Evaluation
In this section, we present experiment results to justify the
proposed veriﬁcation method.
6.1 Data Acquisition
We use the Microsoft Kinect for data collection. In our col-
lected data, each sample is a short video clip that captures
the motion of signing one 3D-signature sample. The length
of the video clip may vary for each sample, but typically
is in the range of [2, 12] seconds. We set the frame rate to
the maximum allowed value (i.e., 30 frames per second),
and set the resolution of the depth image to 240 × 320 pix-
els. The distance between the user and the Kinect was not
ﬁxed, but was in the range of [1.5, 2.5] meters. We alter-
nated three Kinect sensors for data collection and did not
differentiate samples collected by different Kinect sensors
to validate that our algorithm is insensitive to individual
Kinect sensors.
In total, we studied 18 users, allowing each user to en-
roll up to two different 3D-signatures (e.g., ‘ma’ and ’Bry’
are from the same user). In total, these users provided 35
different 3D-signatures, which we call signatures hereafter.
For each signature, we collected 18 to 47 3D-signature sam-
ples over a period of ﬁve months so that we could capture
the possible 3D-signature variation over time. We collected
fewer samples for some signatures because the users were
not always available over the entire ﬁve months of data col-
lection. In total, we collected 1180 genuine 3D-signature
samples for 35 signatures, and hereafter we call these sam-
ples the genuine samples.
We further collected attack data to evaluate the security
performance of KinWrite against impersonation attempts.
In particular, we chose four signatures as the ‘victims’, and
for each victim, we collected ﬁve types of attack samples
that simulate ﬁve different attack models.
• CA. We chose six attackers to launch content-aware at-
tacks. We gave them the spelling of the victims’ pass-
words, without any hint of the passwords’ geometry or
shape. Then, each of these six attackers produced 10
forged 3D-signature samples for each victim. In total
we collected 6× 10× 4 = 240 CA attack 3D-signature
samples.
• Ob-1. We selected a different group of 12 attackers to
perform observer attacks. Each of them watched the
signing process of each victim once and then produced
ﬁve forged 3D-signature samples. Given the four vic-
tims, we collected 12 × 5 × 4 = 240 Ob-1 attack sam-
ples.
• Ob-4. The same 12 attackers continued to observe
the signing process of each victim three more times
Figure 9. An illustration of threshold selec-
tion.
choice of the template. To select a template for each user,
we use a distance-based strategy and consider only her own
training samples.
In this strategy, given n training 3D-
signature samples f1, f2,··· , fn for a user u, we calculate
the pairwise DTW distance d(fi, fj), i, j = 1, 2,··· , n, and
choose the template that has the minimum total DTW dis-
tance to all these n samples, i.e.,
n(cid:88)
d(fu, fj) ≤ n(cid:88)
d(fi, fj), i = 1, 2,··· , n.
(2)
j=1
j=1
5.3 Threshold Selection
Another important issue for verifying a 3D-signature sam-
ple is threshold selection. The 3D-signatures from different
users may have different thresholds, and therefore we select