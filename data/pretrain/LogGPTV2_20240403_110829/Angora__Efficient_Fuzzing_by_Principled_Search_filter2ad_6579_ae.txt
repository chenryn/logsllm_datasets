therefore is not affected by the length of the image data.
Table 9 also shows that while Angora’s strategy generated
more useful inputs, it generated shorter inputs on average on
each program tested. Shorter inputs make many programs
run faster. This evaluation shows that Angora’s strategy
generates higher quality inputs than the random strategy.
5.6. Execution speed
Angora’s taint tracking is expensive. However, Angora
runs taint tracking once for each input, and then mutates
the input and runs the program many times without taint
tracking, so the one-time cost is amortized. Since branch
count dominates the running time of the instrumented code
without taint tracking, the Angora-instrumented program
runs at about
the same speed as its AFL-instrumented
version. Table 10 shows that AFL executes inputs at a
slightly higher rate than Angora. However, because Angora
generates higher-quality inputs that more likely explore new
branches, Angora had much better coverage and found
signiﬁcantly more bugs as shown earlier.
6. Related work
6.1. Prioritize seed inputs
Program Random Magic bytes
+ random
Gradient descent
ﬁle
jhead
xmlwf
djpeg
readpng
nm
objdump
size
63.5 %
86.9 %
77.4 %
66.1 %
19.9 %
57.5 %
47.0 %
44.1 %
76.0 %
87.1 %
81.4 %
73.6 %
23.7 %
66.4 %
54.9 %
52.4 %
87.1 %
97.6 %
97.0 %
78.3 %
24.5 %
80.2 %
56.3 %
54.3 %
TABLE 9: Comparison of Angora’s input length exploration
vs. other tools’ random strategy. The total columns report
how many times the strategies created a longer input, respec-
tively. The useful columns report how many of these inputs
successfully explored new branches, respectively. The two
rightmost columns report the average lengths of the inputs
in the useful columns, respectively.
Program
ﬁle
jhead
xmlwf
djpeg
readpng
nm
objdump
size
Longer inputs
Average length
Random
Angora
Useful
185
0
277
32
46
17
44
27
Total
79k
66k
143k
106k
35k
170k
214k
197k
Useful
251
0
588
474
43
19
60
33
Total
3342
26
2196
3476
152
872
1614
1482
Random Angora
889.9
0.0
190.3
846.6
2242.7
771.7
1271.6
1584.5
399.0
0.0
128.9
283.6
363.1
248.0
496.0
949.7
and reasoned about the seed selection scheduling problem.
They designed and evaluated six different seed selection
algorithms based on PeachFuzzer [23]. The algorithms used
different features to minimize the seed input set, such as
execution time and ﬁle size. The result showed that heuris-
tics employed by seed selection algorithms performed better
than fully random sampling. AFLFast [4] observed that
most fuzzing tests exercised the same few “high frequency”
paths. They used Markov chain to identify “low-frequency”
paths. AFLFast prioritized the inputs that contain such path.
VUzzer [25] used control-ﬂow features to model a path
to prioritize the input whose path is hard-to-reach. Addi-
tionally, VUzzer detected error-handing basic-blocks, and
prioritized the valid inputs that do not contain these basic-
blocks. By contrast, Angora selects the inputs whose paths
contain conditional statements with unexplored branches.
This is a more general strategy, which automatically directs
Angora to focus on the low-frequency paths after exploring
the high-frequency ones.
6.2. Taint-based fuzzing
An important optimization for mutation-based fuzzers is
to select the seed input wisely. Rebert et.al. [26] formulated
Taint tracking has many uses, such as analyzing mal-
ware behavior [24], detecting and preventing information
722
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:39:42 UTC from IEEE Xplore.  Restrictions apply. 
TABLE 10: Inputs tested per second
Program
ﬁle
jhead
xmlwf
djpeg
readpng
nm
objdump
size
AFL
971.17
2684.45
2225.07
1439.94
3374.43
1633.72
1882.05
1671.95
Angora
791.73
2648.91
2206.24
1185.52
2881.72
1045.35
1192.04
1174.55
leaks [10, 29], and debugging software [22, 12]. It can
also be used in fuzzing. Taint-based fuzzers analyze how an
application processes an input to determine which part of the
input should be modiﬁed. Some of these fuzzers [13, 2, 17]
aimed to locate the values used in security sensitive code in
input ﬁles, and then fuzzed these parts of input ﬁle to trigger
crashes. For example, BuzzFuzz [13] used taint tacking to
ﬁnd which input bytes were processed by “attack point” that
they deﬁned. Dowser [17] considered code that likely leads
to buffer overﬂow as security sensitive code. In other words,
these fuzzers aimed to exploit bugs in the reachable paths.
Woo et al. mentioned the trade off between exploration vs.
exploitation [32]. Angora can incorporate these techniques
to exploit the explored paths. Taintscope [31] used taint
analysis to infer checksum-handling code and bypassed
these checks by control ﬂow alteration, because these checks
are hard to satisfy by mutating the input.
taint
tracking to get
VUzzer [25] is an application-aware fuzzer that used
taint analysis to locate the position of “magic bytes” in
input ﬁles, and then assigned these magic bytes to ﬁxed
positions in the input. VUzzer can ﬁnd magic bytes only
when they appear continuously in the input. Steelix [19]
improved VUzzer by learning from program state where
the magic bytes are located in the input and how to mutate
the input to match the magic bytes efﬁciently. By contrast,
Angora applies byte-level
the byte
offsets in the input that ﬂow into each conditional statement,
and then mutates these bytes to satisfy the condition for the
unexplored branch, so Angora can ﬁnd many more types
of values efﬁciently than magic bytes, e.g., non-continuous
magic bytes or magic bytes that are not copied directly
from the input but are computed from the input. Besides,
VUzzer uses a compressed bit-set data structure to represent
taint labels where each bit corresponds to a unique byte
offset in the input. Therefore, the size of the taint label is
large for values with a complex pattern of input byte offsets
because they can not be effectively compressed. By contrast,
Angora stores the byte offsets in a tree and uses indices
into the tree as taint labels, so the size of the taint label
is constant regardless of how many input byte offsets are
in the label. For example, when the taint labels of several
values have the same byte offsets, VUzzer repeatedly stores
these byte offsets in each taint label, but Angora stores these
byte offsets only once in the tree, thus greatly reducing the
memory consumption.
Angora’s data structure for efﬁciently representing taint
labels is similar to reduced ordered binary decision diagrams
(roBDD). roBDD was used to represent dynamic slices [33]
and data lineage [20] compactly, but to the best of our
knowledge, Angora is the ﬁrst to use this idea to represent
taint labels efﬁciently.
6.3. Symbolic-assisted fuzzing
Dynamic symbolic execution provides high semantic in-
sight into the target application. Since such techniques know
how to trigger desired program state, they can be used to
ﬁnd vulnerabilities in programs directly. Classic approaches
performed symbolic execution to maximize code coverage to
ﬁnd crashes [5, 8]. But the challenges of path explosion and
constraint solving make symbolic execution hard to scale [6,
27]. Some tools tried to mitigate this obstacle by combining
it with fuzzing [15, 16, 7, 28]. DART [15] and SAGE [16]
used a dynamic symbolic execution engine to modify input
in fuzzing. SYMFUZZ [7] leveraged symbolic analysis on
an execution trace to detect dependencies among the bit
positions in an input, and then used this dependency to com-
pute an optimal mutation ratio to guide fuzzing. Driller [28]
used dynamic symbolic execution only when fuzzing with
AFL got stuck. However, all of them inherited the scalability
problem from symbolic execution. By contrast, Angora does
not use symbolic execution, and can ﬁnd many bugs on large
programs efﬁciently.
7. Conclusion
We designed and implemented Angora, a powerful
mutation-based fuzzer that produces high quality inputs,
thanks to the following key techniques: scalable byte-level
taint tracking, context-sensitive branch count, search algo-
rithm based on gradient descent, shape and type inference,
and input length exploration. Angora outperformed other
state-of-the-art fuzzers by a wide margin. It found signif-
icantly more bugs than other fuzzers on LAVA-M, found
103 bugs that the LAVA authors could not trigger when
they prepared the data set, and a total of 175 new bugs in
eight popular, mature open source programs. Our evaluation
shows that Angora raised the bar of fuzzing to a new level.
8. Acknowledgment
We thank Dongyu Meng for helpful discussions through-
out this project and for reviewing drafts of this paper. The
paper improved substantially thanks to the detailed feedback
from the anonymous reviewers.
References
[1] American fuzzy lop. URL: http://lcamtuf.coredump.
cx/aﬂ/.
723
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:39:42 UTC from IEEE Xplore.  Restrictions apply. 
[2] Soﬁa Bekrar et al. “A taint based approach for
smart fuzzing”. In: IEEE International Conference on
Software Testing, Veriﬁcation and Validation (ICST).
2012, pp. 818–825.
[3] Binary fuzzing strategies: what works, what doesn’t.
URL: https://lcamtuf.blogspot.sg/2014/08/binary-
fuzzing-strategies-what-works.html.
[4] Marcel Bhme, Van-Thuan Pham, and Abhik Roy-
choudhury. “Coverage-based greybox fuzzing as
markov chain”. In: Proceedings of the 2016 ACM
SIGSAC Conference on Computer and Communica-
tions Security. 2016, pp. 1032–1043.
[5] Cristian Cadar, Daniel Dunbar, and Dawson R Engler.
“KLEE: unassisted and automatic generation of high-
Coverage tests for complex systems programs.” In:
OSDI. Vol. 8. 2008, pp. 209–224.
[6] Cristian Cadar and Koushik Sen. “Symbolic execution
for software testing: three decades later”. In: Commu-
nications of the ACM 56.2 (2013), pp. 82–90.
[7] Sang Kil Cha, Maverick Woo, and David Brumley.
“Program-adaptive mutational fuzzing”. In: Security
and Privacy (SP), 2015 IEEE Symposium on. 2015,
pp. 725–741.
[8] Sang Kil Cha et al. “Unleashing mayhem on binary
code”. In: Security and Privacy (SP), 2012 IEEE
Symposium on. 2012, pp. 380–394.
[9] Brendan Dolan-Gavitt et al. “LAVA: large-scale au-
tomated vulnerability addition”. In: Security and Pri-
vacy (SP), 2016 IEEE Symposium on. 2016, pp. 110–
121.
[10] William Enck et al. “TaintDroid: an information-ﬂow
tracking system for realtime privacy monitoring on
smartphones”. In: ACM Transactions on Computer
Systems (TOCS) 32.2 (2014), p. 5.
[11] Fuzzing with AFL is an art. URL: http : / / moyix .
blogspot . com / 2016 / 07 / fuzzing - with - aﬂ - is - an -
art.html.
[12] Malay Ganai, Dongyoon Lee, and Aarti Gupta.
“DTAM: dynamic taint analysis of multi-threaded
programs for relevancy”. In: Proceedings of the ACM
SIGSOFT 20th International Symposium on the Foun-
dations of Software Engineering. 2012, p. 46.
[13] Vijay Ganesh, Tim Leek, and Martin Rinard. “Taint-
based directed whitebox fuzzing”. In: Proceedings of
the 31st International Conference on Software Engi-
neering. 2009, pp. 474–484.
gcov - a test coverage program. URL: https://gcc.gnu.
org/onlinedocs/gcc/Gcov.html#Gcov.
[15] Patrice Godefroid, Nils Klarlund, and Koushik Sen.
“DART: directed automated random testing”.
In:
ACM SIGPLAN Notices. Vol. 40. 6. 2005, pp. 213–
223.
[16] Patrice Godefroid, Michael Y Levin, and David
A Molnar. “Automated whitebox fuzz testing.” In:
NDSS. Vol. 8. 2008, pp. 151–166.
Istvan Haller et al. “Dowsing for overﬂows: a
guided fuzzer to ﬁnd buffer boundary violations.” In:
USENIX security. 2013, pp. 49–64.
[17]
[14]
[18] Chris Lattner and Vikram Adve. “LLVM: a compi-
lation framework for lifelong program analysis and
transformation”. In: CGO. San Jose, CA, USA, Mar.
2004, pp. 75–88.
[19] Yuekang Li et al. “Steelix: program-state based binary
fuzzing”. In: Proceedings of
the 2017 11th Joint
Meeting on Foundations of Software Engineering.
2017, pp. 627–637.
[20] Zhiqiang Lin, Xiangyu Zhang, and Dongyan Xu.
“Convicting exploitable software vulnerabilities: an
efﬁcient input provenance based approach”. In: De-
pendable Systems and Networks With FTCS and
DCC, 2008. DSN 2008. IEEE International Confer-
ence on. 2008, pp. 247–256.
[21] LLVM dataFlowSanitizer. URL: https://clang.llvm.
org/docs/DataFlowSanitizer.html.
[22] Wes Masri, Andy Podgurski, and David Leon. “De-
tecting and debugging insecure information ﬂows”.
In: Software Reliability Engineering, 2004.
IS-
SRE 2004. 15th International Symposium on. 2004,
pp. 198–209.
[23] Peach fuzzer. URL: http://www.peachfuzzer.com/.
[24] Georgios Portokalidis, Asia Slowinska, and Herbert
Bos. “Argos: an emulator for ﬁngerprinting zero-
day attacks for advertised honeypots with automatic
signature generation”. In: ACM SIGOPS Operating
Systems Review. Vol. 40. 4. 2006, pp. 15–27.
[25] Sanjay Rawat et al. “VUzzer: application-aware evo-
lutionary fuzzing”. In: NDSS. Feb. 2017.
[26] Alexandre Rebert et al. “Optimizing seed selection
for fuzzing”. In: 2014.
[27] Yan Shoshitaishvili et al. “SOK:(State of) the art
of war: offensive techniques in binary analysis”. In:
Security and Privacy (SP), 2016 IEEE Symposium on.
2016, pp. 138–157.
[28] Nick Stephens et al. “Driller: augmenting fuzzing
through selective symbolic execution”. In: Proceed-
ings of the Network and Distributed System Security
Symposium. 2016.
[29] Mingshen Sun, Tao Wei, and John Lui. “Taintart: a
practical multi-level information-ﬂow tracking system
for android runtime”. In: Proceedings of the 2016
ACM SIGSAC Conference on Computer and Com-
munications Security. 2016, pp. 331–342.
[30] Technical ”whitepaper” for aﬂ-fuzz. URL: http : / /
lcamtuf.coredump.cx/aﬂ/technical details.txt.
[31] Tielei Wang et al. “TaintScope: a checksum-aware
directed fuzzing tool for automatic software vulnera-
bility detection”. In: Security and privacy (SP), 2010
IEEE symposium on. 2010, pp. 497–512.
[32] Maverick Woo et al. “Scheduling black-box muta-
tional fuzzing”. In: Proceedings of the 2013 ACM
SIGSAC conference on Computer & communications
security. 2013, pp. 511–522.
[33] Xiangyu Zhang, Rajiv Gupta, and Youtao Zhang.
“Efﬁcient forward computation of dynamic slices us-
ing reduced ordered binary decision diagrams”. In:
724
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:39:42 UTC from IEEE Xplore.  Restrictions apply. 
Proceedings of the 26th International Conference on
Software Engineering. 2004, pp. 502–511.
725
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:39:42 UTC from IEEE Xplore.  Restrictions apply.