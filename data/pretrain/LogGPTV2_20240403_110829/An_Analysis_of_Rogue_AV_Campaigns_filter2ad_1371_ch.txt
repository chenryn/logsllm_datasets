2.59%
2.08%
1.74%
1.29%
1.26%
0.89%
0.43%
0.37%
Yoda’s Protector 0.33%
0.17%
0.13%
UPack
nPack
ASPack
ASProtect
Armadillo
yes
yes
yes
yes
FSG
Nspack
yes
yes
yes
yes
yes
yes
yes
yes
WinUPack
MEW
22.81
3.16
22.56 23.50
23.21
1.54
4.42
22.58
1.38
22.53
22.52
2.69
22.44 23.60
22.56
3.87
0.02
0.03
0.02
0.02
0.03
0.03
2.81
4.08
2.80
2.81
2.78
2.78
0.02
0.02
0.02
0.02
0.02
0.02
0.03
0.03
4.10
2.80
0.02
0.02
metacode and payload code, respectively. In the uninstrumented case, we deter-
mine the proper time split by using a priori knowledge of the packed program to
breakpoint its execution at the moment that control transfers from its metacode
to its payload code. In the instrumented case, our code-discovery instrumenta-
tion automatically identiﬁes this transition by capturing the control transfer to
the payload code. We report on SD-Dyninst’s pre-execution cost separately, as
one of the major beneﬁts of incorporating static analysis techniques into our
approach is that we are able to frontload much of the analysis of the program
so that it does not aﬀect the program’s execution time.
The most striking diﬀerences in Table 1 are in the pre-payload cost incurred
by SD-Dyninst from one packer to the next. These diﬀerences are proportional
to the number of occasions in which we discover and analyze new code in the
metacode of these binaries. Our instrumentation of the UPX, PolyEnE, nPack,
and Nspack packers caused little slowdown in their execution, as their metacode
is static and not obfuscated in ways that substantially limit our ability to parse
them prior to their execution, while the FSG, MEW, ASPack, UPack, and Win-
Upack packers are more heavily obfuscated and unpack in stages, requiring that
we analyze their code incrementally. The largest contributor to the incremental
analysis cost is SD-Dyninst’s current inability to resolve the targets of indirect
control transfers at parse time, coupled with a simplifying implementation
decision to instrument whole functions at a time, meaning that discovery of
a new basic block currently causes its entire function to be re-instrumented.
SD-Dyninst’s performance will improve signiﬁcantly in the near future through
Hybrid Analysis and Control of Malware
333
Table 2. A comparison of pre-payload execution times and instrumented program
locations in SD-Dyninst, Renovo, Saﬀron, and EtherUnpack on packed executables.
Pre-payload time
Packer
UPX
ASPack
FSG
WinUpack
MEW
SD-D. Ren.
5
5
8
8
6
0.5
4.4
1.6
23.6
4.0
Saﬀ. Ether
7.6
2.7
18.7
fail
31.1
1.4
23.5
67.8
150.5
fail
Instrumented locations
SD-D.
6
34
14
23
22
Ren.
2,278
2,045
18,822
18,826
21,186
Saﬀ.
4,526
4,141
31,854
32,945
35,466
the addition of code-slicing capabilities to Dyninst, which will allow SD-Dyninst
to resolve many indirect control transfers at parse time.
In Table 2 we compare the overall expense of our techniques to the most
eﬃcient tools for identifying dynamically unpacked and modiﬁed code, Renovo
[23], “Saﬀron for Intel PIN” [41], and EtherUnpack [17]. We executed Saﬀron
and EtherUnpack on our own hardware, but the Renovo tool is not yet publicly
available, so we compared against Renovo’s self-reported execution times for
packed notepad.exe executables, limiting this comparison to the top packer tools
that they also analyzed in their study. We ran SD-Dyninst and Saﬀron on an Intel
Core 2 Duo T2350 1.6GHz CPU with 2.5GB of memory, while Renovo’s study
was conducted on an Intel Core 2 Duo E6660 2.4GHz CPU with 4GB memory
and EtherUnpack executed on an Intel Xeon E5520 2.27GHz CPU with 6GB of
memory. These numbers reﬂect the post-startup time it took for SD-Dyninst,
Renovo, Saﬀron, and EtherUnpack to execute the instrumented metacode of the
various packer tools.
As seen in Table 2, except in the case of our unoptimized analysis of the Win-
Upack executable, our pre-payload execution times are comparable to those of
Renovo, Saﬀron, and EtherUnpack despite the fact that our tool also analyzes
the code while the other tools only identify its dynamically unpacked portions.
The Saﬀron unpacker only partially unpacked the ASPack and MEW executa-
bles, as it quits at the ﬁrst occurrence of written-then-executed code.
The savings aﬀorded by our use of analysis-guided instrumentation help to
amortize our analysis costs. Saﬀron instruments the program at every instruc-
tion, while Renovo instruments at all control transfers and at all write instruc-
tions (EtherUnpack’s single-step mechanism does not rely on instrumentation).
We estimated Saﬀron’s use of instrumentation by modifying its source code to
maintain a count of unique instrumented instructions, and estimated Renovo’s
use of instrumentation based on their algorithm description, by instrumenting
the packed programs to maintain a count of unique control transfer and write
instructions. Table 2 shows that our structural analysis allows us to instrument
the program at fewer than a 100th of the locations instrumented by Saﬀron and
Renovo, because our structural analysis allows us to limit our use of instrumen-
tation to instructions whose targets are statically unresolved.
334
K.A. Roundy and B.P. Miller
8.2 Malware Analysis
Accomplishing an analysis task using SD-Dyninst requires no more skill from the
analyst than performing the same task with Dyninst on a conventional binary. We
wrote a malware analysis factory that uses SD-Dyninst to perform code-coverage
of malicious program executions by instrumenting every basic block in the pro-
gram, (both statically present and dynamically unpacked blocks) and removing
the instrumentation once it has executed. This instrumentation code consists of
only ﬁfty lines. Our factory halts the malware at the point that it attempts its
ﬁrst network communication, exits, or reaches a 30-minute timeout. At this time,
the factory prints out a traversal of the program’s call stacks and outputs a CFG
of the binary that identiﬁes calls to Windows DLL functions and is annotated to
(a) The entire CFG.
(b) CFG excerpt showing Conﬁcker’s basic blocks and
its calls to system libraries. Basic blocks that have ex-
ecuted are shown in red blocks, non-executed blocks
are in light-grey, and API functions are shown as white
rectangles.
Fig. 5. Two views of Conﬁcker A’s control ﬂow graph. The CFG in part (a) can be
explored in an interactive viewer, as shown in the excerpt from part (b).
top pc=0x7c901231 DbgBreakPoint 0x7c901230 in ntdll.dll
[Win DLL]
pc=0x10003c83 DYNbreakPoint 0x10003c70 in dyn RT.dll [Instrument.]
pc=0x100016f7 DYNstopThread 0x10001670 in dyn RT.dll [Instrument.]
pc=0x71ab2dc0 select 0x71ab2dc0
in WS2 32.dll
base pc=0x401f34
func=nosym1f058 0x41f058 in cf.exe
[Win DLL]
[Conﬁcker]
Fig. 6. An SD-Dyninst stack walk taken when the Conﬁcker A binary executes
Winsock’s select routine. The stack walk includes frames from our instrumentation,
select, and Conﬁcker.
Hybrid Analysis and Control of Malware
335
distinguish between blocks that have executed and those that have not. If the mal-
ware fails to send a network packet, we verify our analysis by comparing against a
trace of the malware’s execution to ensure that our analysis reaches the same point.
We set up our malware analysis factory on an air-gapped system with a 32-bit
Intel-x86 processor running Windows XP with Service Pack 2 inside of VMWare
Server. We then analyzed 200 malware samples that were collected by Oﬀensive
Computing [3] in December 2009. Our tool detected code unpacking in 27%
of the samples, code overwrites in 16%, and signal-based control ﬂow in 10%.
33% of the malicious code analyzed by our hybrid techniques was not part of
the dynamic execution trace and would not have been identiﬁed by dynamic
analysis. For the malware samples that attempted to communicate with the
network, our analysis factory walked their call-stacks to identify the code in the
malicious executable that triggered the network communication.
As an example of the kinds of results produced by our factory, in Fig-
its analysis products for the Conﬁcker A
ures 5 and 6 we show two of
malware binary. Our factory created similar analysis products for all the
other malware binaries that we analyzed, and these can be viewed online at
http://www.paradyn.org/SD_Dyninst/. In Figure 5a we show the annotated
CFG of the Conﬁcker A binary in its entirety, while Figure 5b shows an excerpt
of that graph, highlighting the fact that SD-Dyninst has captured static and
dynamic code, both code in the executable and code in Windows DLL’s, and
both code that has executed and code that has not executed but that may be
of interest to the analyst. Figure 6 shows our traversal of Conﬁcker’s call stacks
at its ﬁrst call to the select routine. As seen in this stack trace, we are able to
identify the stack frames of functions that lack symbol information, an impor-
tant beneﬁt of our analysis capabilities. While existing stackwalking techniques
are accurate only for statically analyzable code [26], our hybrid analysis enables
accurate stackwalking by virtue of having analyzed all of the code that could be
executing at any given time.
9 Conclusion
We create a hybrid analysis algorithm that makes it possible to analyze and
control the execution of malicious program binaries in a way that is both more
intuitive and more eﬃcient than existing methods. Our combination of static
and dynamic analysis allows us to provide analysis-guided instrumentation on
obfuscated, packed, and self-modifying program binaries for the ﬁrst time. We
implemented these ideas in SD-Dyninst, and demonstrated that they can be
applied to most of the packing tools that are popular with current malware.
We demonstrated the usefulness of our techniques by applying SD-Dyninst to
produce analysis artifacts for the Conﬁcker A binary that would have required
substantial manual eﬀort to produce through alternative methods.
Ongoing research in the Dyninst project promises to address the two primary
limitations of this work. First, our instrumentation’s changes to the program’s
address space can be detected through anti-tampering techniques such as self-
checksumming. The second problem is that our parsing techniques assume that
336
K.A. Roundy and B.P. Miller
the targets of conditional control transfers always represent real code, meaning
that the obfuscation proposed by Collberg et al. [14] could be used to pollute
our parse with non-code bytes, potentially causing us to instrument data and
causing the program to malfunction. Both of these problems are being addressed
by a piece of ongoing research in Dyninst that will ensure that the presence of
instrumentation will not impact a program’s data accesses.
Two additional analysis-resistance techniques that merit discussion are anti-
debugging and timing checks. Several Windows API and system calls can be
used to detect the presence of a debugger. Invocations of such functions are
easily detected by SD-Dyninst instrumentation and we have disabled those we
have come across, but from the literature [18] we know there are additional anti-
debugging methods that our current implementation does not disable. Timing
checks similarly depend on Windows API calls, system calls, and special-purpose
instructions that are easily detected by SD-Dyninst. However, we have not had to
disable timing checks, as most existing checks are tuned to detect the signiﬁcant
slowdowns incurred by single-step debugging techniques and are not triggered
by our more eﬃcient instrumentation-based techniques. It is possible that fu-
ture timing checks could detect the slowdown caused by our algorithm’s online
analysis, in which case we could adapt Ether’s [17] clock emulation techniques
to hide the slowdown from the program.
Acknowledgments
This work is supported in part by Department of Energy grants DE-SC0004061,
08ER25842, 07ER25800, DE-SC0003922, Department of Homeland Security
grant FA8750-10-2-0030 (funded through AFRL), and National Science Founda-
tion Cybertrust grants CNS-0627501, and CNS-0716460.
The U.S. Government is authorized to reproduce and distribute reprints for
Governmental purposes notwithstanding any copyright notation thereon.
References
1. Computer economics 2007 malware report: The economic impact of viruses, spy-
ware, adware, botnets, and other malicious code (2007)
2. Darkparanoid virus (1998)
3. Oﬀensive computing, http://www.offensivecomputing.net
4. Anckaert, B., Madou, M., Bosschere, K.D.: A model for self-modifying code. In:
Information Hiding, Alexandria, VA, pp. 232–248 (2007)
5. Balakrishnan, G., Reps, T.: Analyzing memory accesses in x86 executables. In: In-
ternational Conference on Compiler Construction, New York, NY, pp. 5–23 (2004)
6. Bayer, U., Moser, A., Kruegel, C., Kirda, E.: Dynamic analysis of malicious code.
Journal in Computer Virology 2(1), 66–77 (2006)
7. Bellard, F.: QEMU, a fast and portable dynamic translator. In: USENIX Annual
Technical Conference, Anaheim, CA, pp. 41–46 (2005)
8. BitDefender: BitDefender anti-virus technology. White Paper (2007)
9. Bustamante, P.: Malware prevalence. Panda Research web article (2008)
10. Bustamante, P.: Packer (r)evolution. Panda Research web article (2008)
Hybrid Analysis and Control of Malware
337
11. Bustamante, P.: Personal correspondence (2009)
12. Chiang, K., Lloyd, L.: A case study of the rustock rootkit and spam bot. In: First
Conference on Hot Topics in Understanding Botnets, Cambridge, MA (2007)
13. Cifuentes, C., Emmerik, M.V.: UQBT: adaptable binary translation at low cost.
Computer 33(3), 60–66 (2000)
14. Collberg, C., Thomborson, C., Low, D.: Manufacturing cheap, resilient, and
stealthy opaque constructs. In: Symposium on Principles of Programming Lan-
guages, San Diego, CA, pp. 184–196 (1998)
15. Coogan, K., Debray, S., Kaochar, T., Townsend, G.: Automatic static unpacking
of malware binaries. In: Working Conference on Reverse Engineering, Antwerp,
Belgium (2009)
16. Danehkar, A.: Inject your code into a portable executable ﬁle (2005),
http://www.codeproject.com/KB/system/inject2exe.aspx
17. Dinaburg, A., Royal, P., Sharif, M., Lee, W.: Ether: Malware analysis via hard-
ware virtualization extensions. In: Conference on Computer and Communications
Security, Alexandria, VA (2008)
18. Ferrie, P.: Anti-unpacker tricks. In: International CARO Workshop. Amsterdam,
Netherlands (2008)
19. Garﬁnkel, T., Rosenblum, M.: A virtual machine introspection based architecture
for intrusion detection. In: Network and Distributed System Security Symposium,
San Diego, CA (2003)
20. Guo, F., Ferrie, P., Chiueh, T.: A study of the packer problem and its solutions.
In: Lippmann, R., Kirda, E., Trachtenberg, A. (eds.) RAID 2008. LNCS, vol. 5230,
pp. 98–115. Springer, Heidelberg (2008)
21. Hind, M., Pioli, A.: Which pointer analysis should I use? In: International Sympo-
sium on Software Testing and Analysis, Portland, OR, pp. 113–123 (2000)
22. Hollingsworth, J.K., Miller, B.P., Cargille, J.: Dynamic program instrumentation
for scalable performance tools. In: Scalable High Performance Computing Confer-
ence, Knoxville, TN (1994)
23. Kang, M.G., Poosankam, P., Yin, H.: Renovo: A hidden code extractor for packed