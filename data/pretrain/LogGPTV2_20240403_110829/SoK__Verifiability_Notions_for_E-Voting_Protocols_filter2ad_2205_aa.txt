title:SoK: Verifiability Notions for E-Voting Protocols
author:V&apos;eronique Cortier and
David Galindo and
Ralf K&quot;usters and
Johannes M&quot;uller and
Tomasz Truderung
2016 IEEE Symposium on Security and Privacy
2016 IEEE Symposium on Security and Privacy
SoK: Veriﬁability Notions for E-Voting Protocols
V´eronique Cortier∗, David Galindo†, Ralf K¨usters‡, Johannes M¨uller‡, Tomasz Truderung§
∗LORIA/CNRS, France
†University of Birmingham, UK
‡University of Trier, Germany
§Polyas GmbH, Germany
e-mail: PI:EMAIL, PI:EMAIL, {kuesters, muellerjoh}@uni-trier.de, PI:EMAIL
Abstract—There have been intensive research efforts in the last
numerous elections it has been demonstrated that the employed
two decades or so to design and deploy electronic voting (e-voting)
systems can easily be manipulated (e.g., by replacing hardware
protocols/systems which allow voters and/or external auditors
components in voting machines) or that they contained ﬂaws
to check that the votes were counted correctly. This security
that made it possible for more or less sophisticated attackers
property, which not least was motivated by numerous problems
to change the result of the elections (see, e.g., [29], [14],
is called veriﬁability. It is meant to
in even national elections,
[2], [3], [52], [53], [48], [25]). In some occasions, announced
defend against voting devices and servers that have programming
results were incorrect and/or elections had to be rerun (see,
errors or are outright malicious. In order to properly evaluate
e.g., [1], [4]). Given that e-voting systems are complex software
and analyze e-voting protocols w.r.t. veriﬁability, one fundamental
and hardware systems, programming errors are unavoidable
challenge has been to formally capture the meaning of this
and deliberate manipulation of such systems is often hard or
security property. While the ﬁrst formal deﬁnitions of veriﬁability
virtually impossible to detect.
were devised in the late 1980s already, new veriﬁability deﬁnitions
are still being proposed. The deﬁnitions differ in various aspects,
including the classes of protocols they capture and even their
formulations of the very core of the meaning of veriﬁability. This
is an unsatisfying state of affairs, leaving the research on the
veriﬁability of e-voting protocols in a fuzzy state.
In this paper, we review all formal deﬁnitions of veriﬁability
proposed in the literature and cast them in a framework proposed
by K¨usters, Truderung, and Vogt (the KTV framework), yielding
a uniform treatment of veriﬁability. This enables us to provide a
detailed comparison of the various deﬁnitions of veriﬁability from
the literature. We thoroughly discuss advantages and disadvan-
tages, and point to limitations and problems. Finally, from these
discussions and based on the KTV framework, we distill a general
deﬁnition of veriﬁability, which can be instantiated in various
ways, and provide precise guidelines for its instantiation. The
concepts for veriﬁability we develop should be widely applicable
also beyond the framework used here. Altogether, our work
offers a well-founded reference point for future research on the
veriﬁability of e-voting systems.
Keywords-e-voting; veriﬁability; protocol analysis
I.
INTRODUCTION
Systems for electronic voting (e-voting systems) have been
and are being employed in many countries for national, state-
wide and municipal elections, for example in the US, Estonia,
India, Switzerland, France, and Australia. They are also used
for elections within companies, organizations, and associations.
There are roughly two types of e-voting systems: those where
the voter has to go to a polling station in order to cast her
vote using a voting machine and those that allow the voter to
cast her vote remotely over the Internet, using her own device.
When voting at a polling station, the voter either has to ﬁll in
a paper ballot, which then is scanned by an optical scan voting
system, or the voter enters her vote into a machine directly, a
so-called Direct Recording Electronic (DRE) voting system.
For most voting systems used in practice today, voters
have no guarantees that their votes have actually been counted:
the voters’ devices, voting machines, and/or voting servers
might have (unintentional or deliberate) programming errors
or might have been tampered with in some other way. In
2375-1207/16 $31.00 © 2016 IEEE
© 2016, Véronique Cortier. Under license to IEEE.
DOI 10.1109/SP.2016.52
DOI 10.1109/SP.2016.52
779
779
Therefore, there has been intensive and ongoing research
in the last two decades or so to design e-voting protocols
and systems1 which provide what is called veriﬁability (see,
e.g., [21], [31], [17], [6], [15], [10], [9], [19], [34], [27], [33]).
Roughly speaking, veriﬁability means that voters and possibly
external auditors should be able to check whether the votes
were actually counted and whether the published election result
is correct, even if voting devices and servers have programming
errors or are outright malicious. Several of such systems have
already been deployed in real binding elections (see, e.g., [6],
[15], [7], [44], [13], [50], [22], [26]).
For the systematic security analysis of such systems and
protocols, one challenge has been to formally and precisely
capture the meaning of veriﬁability. While the ﬁrst attempts at a
formal deﬁnition stem from the late 1980s [12], new deﬁnitions
are still being put forward, with many deﬁnitions having been
proposed in the last few years [16], [35], [32], [37], [19],
[34], [33], [47], [49]. The deﬁnitions differ in many aspects,
including the classes of protocols they capture, the underlying
models and assumptions, the notation, and importantly, the
formulations of the very core of the meaning of veriﬁability.
This is an unsatisfying state of affairs, which leaves the
research on the veriﬁability of e-voting protocols and systems
in a fuzzy state and raises many questions, such as: What are
the advantages, disadvantages, problems, and limitations of the
various deﬁnitions? How do the security guarantees provided
by the deﬁnitions compare? Are they similar or fundamentally
different? Answering such questions is non-trivial. It requires
some common basis on which the deﬁnitions can be discussed
and compared.
Contribution of this paper. First, we show that the essence of
all formal deﬁnitions of veriﬁability proposed in the literature
so far can be cast in one framework. We choose the framework
proposed by K¨usters, Truderung, and Vogt [37] for this purpose.
1In what follows, we use the terms protocols and systems interchangeably.
We point out, however, that this work is mostly concerned with the protocol
aspects of e-voting rather than speciﬁc system aspects.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:17:36 UTC from IEEE Xplore.  Restrictions apply. 
The generic deﬁnition of veriﬁability in this framework is
applicable to essentially any kind of protocol, with a ﬂexible
way of dealing with various trust assumptions and types of
corruption. Most importantly, it allows us to capture many
kinds and ﬂavors of veriﬁability.
The casting of the different deﬁnitions in one framework
is an important contribution by itself as it yields a uniform
treatment of veriﬁability. This uniform treatment enables us to
provide a detailed and systematic comparison of the different
formal deﬁnitions of veriﬁability proposed in the literature
until now. We present thorough discussions of all relevant
deﬁnitions and models concerning their advantages, disad-
vantages, problems, and limitations, resulting in various new
insights concerning the deﬁnitions itself and their relationships.
Among others, it turns out that while the deﬁnitions share
a common intuition about the meaning of veriﬁability, the
security guarantees that are actually captured and formalized
often vary, with many technical subtleties involved. Cast
in tailored models, different, sometimes implicit, and often
unnecessary assumptions about the protocol structure or the
trust assumptions are made. For some deﬁnitions, we point out
severe limitations and weaknesses.
Finally, we distill
these discussions and insights into
detailed guidelines that highlight several aspects any veriﬁability
deﬁnition should cover. Based on the KTV framework, we
provide a solid, general, and ﬂexible veriﬁability deﬁnition
that covers a wide range of protocols, trust assumptions, and
voting infrastructures. Even if alternative frameworks are used,
for example in order to leverage speciﬁc proof techniques
or analysis tools, our guidelines provide insights on which
parameters may be changed and what the implications of such
modiﬁcations are. This lays down a common, uniform, and
yet general basis for all design and analysis efforts of existing
and future e-voting protocols. As such, our work offers a well-
founded reference point for future research on the veriﬁability
of e-voting systems and protocols.
Structure of this paper.
In Section II, we introduce some
notation which we use throughout this paper. We brieﬂy recall
the KTV framework in Section III. In Sections IV to VIII
we then cast various deﬁnitions in this framework and based
on this we carry out detailed discussions on these deﬁnitions.
Further deﬁnitions are brieﬂy discussed in Section IX, with
some of them treated in detail in the appendix. The mentioned
deﬁnitions and guidelines we distill from our discussions,
together with various insights, are presented in Section X.
The appendix contains further details, with full details provided
in our technical report [20].
II. NOTATION AND PRELIMINARIES
Next, we provide some background on e-voting and intro-
duce notation that we use throughout the paper.
In an e-voting protocol/system, a voter, possibly using some
voter supporting device (VSD) (e.g., a desktop computer or
smartphone), computes a ballot, typically containing the voter’s
choice in an encrypted or encoded form, and casts it. Often
this means that the ballot is put on a bulletin board (see also
below). The ballots are collected (e.g., from the bulletin board)
and tallied by tellers/voting authorities. In modern e-voting
protocols, the tallying is, for example, done by combining
all ballots into one, using homomorphic encryption, and then
decrypting the resulting ballot, or by using mix-nets, where the
ballots before being decrypted are shufﬂed. At the beginning
of an election, the voting authorities produce the election
parameters prm, typically containing keys and a set of valid
choices C, the choice space. In general, C can be an arbitrary
set, containing just the set of candidates, if voters can choose
one candidate among a set of candidates, or even tuples of
candidates, if voters can choose several candidates or rank
them. We emphasize that we consider abstention to be one of
the choices in C.
In this paper, we denote the voters by V1, . . . , Vn and their
VSDs (if any) by VSD1, . . . , VSDn. In order to cast a vote, a
voter Vi ﬁrst picks her choice ci ∈ C. She then runs her voting
procedure Vote(ci), which in turn might involve providing her
VSD with her choice. The VSD runs some procedure VoteVSD,
given certain parameters, e.g., the voters choice. The result
of running the voting procedure is a ballot bi, which, for
example, might contain ci in encrypted form. Some models do
not distinguish between the voter and her VSD, and in such a
case, we simply denote the voter’s voting procedure by Vote.
Often voters have to perform some veriﬁcation procedure
during or at the end of the election in order to prevent/detect
malicious behavior by their VSDs or the voting authorities. We
denote such a procedure by Verify. This procedure might for
example involve checking that the voter’s ballot appears on
the bulletin board or performing certain cryptographic tasks.
Carrying out Verify will often require some trusted device.
We denote the tellers by T1, . . . , Tm. As mentioned, they
collect the ballots, tally them, and output the election result
Tally, which belongs to what we call the result space R (ﬁxed
for a given election). The result is computed according to
a result function ρ : Cn → R which takes the voters’ choices
(cid:3)c = (c1, . . . , cn) as input and outputs the result. (Of course
dishonest tellers might try to manipulate the election outcome,
which by the veriﬁability property, as discussed in the next
section, should be detected.) The result function should be
speciﬁed by the election authorities before an election starts.
At the end or throughout the election, auditors/judges
might check certain information in order to detect malicious
behavior. Typically, these checks are based solely on publicly
available information, and hence, in most cases their task can
be carried out by any party. They might for example check
certain zero-knowledge proofs. In what follows, we consider
the auditors/judges to be one party J, who is assumed to be
honest.
As already noted above, most election protocols assume an
append-only bulletin board B. An honest bulletin board stores
all the input it receives from arbitrary participants in a list, and
it outputs the list on request. Typically, public parameters, such
as public keys, the election result, voters’ ballots, and other
public information, such as zero-knowledge proofs generated by
voting authorities, are published on the bulletin board. As we
will see, in most models (and many protocols) a single honest
bulletin board is assumed. However, trust can be distributed
[23]. Providing robust and trustworthy bulletin boards, while
very important, is mainly considered to be a task orthogonal
to the rest of the election protocol. For this reason, we will
mostly refer to the (honest) bulletin board B, which in practice
might involve a distributed solution rather than a single trusted
server.
III. THE KTV FRAMEWORK
In this section, we brieﬂy recall the KTV framework [37],
which is based on a general computational model and provides
780780
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:17:36 UTC from IEEE Xplore.  Restrictions apply. 
a general deﬁnition of veriﬁability. As already mentioned in the
introduction, in the subsequent sections we use this framework
to cast all other formal deﬁnitions of veriﬁability. Here, we
slightly simplify this framework without losing generality.
These simpliﬁcations help, in particular, to smoothly deal with
modeling dynamic corruption of parties (see below).
A. Computational Model
Processes are the core of the computational model. Based
on them, protocols are deﬁned.
Process. A process is a set of probabilistic polynomial-time
interactive Turing machines (ITMs, also called programs) which
are connected via named tapes (also called channels). Two
programs with a channel of the same name but opposite
directions (input/output) are connected by this channel. A
process may have external input/output channels, those that
are not connected internally. At any time of a process run,
one program is active only. The active program may send a
message to another program via a channel. This program then
becomes active and after some computation can send a message
to another program, and so on. Each process contains a master
program, which is the ﬁrst program to be activated and which
is activated if the active program did not produce output (and
hence, did not activate another program). If the master program
is active but does not produce output, a run stops.
We write a process π as π = p1 (cid:5)···(cid:5) pl, where p1 . . . , pl are
programs. If π1 and π2 are processes, then π1 (cid:5) π2 is a process,