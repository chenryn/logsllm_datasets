guided optimizations to achieve its overhead (which we do
not). VTV has lower precision [13] and has higher overhead –
4.1% on the C++ benchmarks of SPEC2006 (vs. 0.9% for us
on the C++ benchmarks SPEC2006). Additionally unlike those
two techniques, the overhead of our runtime checks does not
depend on the size of the class hierarchy.
Another branch of work focuses on VTable protection
for COTS binaries, an approach that does not require source
code. vfGuard [30] reconstructs a coarse class hierarchy from
stripped binaries by relying on C++ ABI derived invariants.
It incurs a higher overhead (18% on Firefox modules) due
to the use of dynamic instrumentation. Their class hierarchy
reconstruction is orthogonal and complimentary to our work.
VTint [42] identiﬁes writeable vtables and relocates them to
read only memory, separate from other data. At each virtual
method call site they check that the target vtable is read-only
by attempting to write to it, and thus forcing an exception.
Since these exceptions involve a context switch to the kernel,
we believe that their overhead will be signiﬁcantly higher
compared to our technique. The reported overhead for vtInt is
only 2% on average, however it is measured over a signiﬁcantly
smaller number of instrumented call sites. For example for
xalancbmk the authors report only 1.12% overhead, but they
ﬁnd only 29 vtables and instrument 4248 call sites whereas
we ﬁnd 958 vtables and instrument 11253 call sites. In our
experience we have not encountered any vtables laid out in
writable memory by LLVM.
LLVM 3.7 [22] implements a virtual call CFI scheme
utilizing bitsets (we called this the LLVM-VCFI technique
in our experimental evaluation). As we have already shown
in Section X, their technique has the same precision as ours,
but at higher runtime overhead (1.97% vs 1.17%) and higher
memory overhead (3.6% vs 1.7%).
Redactor++[8] provides a probabilistic defense against
vtable confusion attacks with similar overhead to us – 1.1%
over Chrome and SPEC2006. Unlike their work, our guaran-
tees are not probabilistic.
B. General CFI
General CFI techniques protect all computed control trans-
fers – including normal function pointer calls and returns.
Due to this difference in scope a direct comparison of the
runtime overhead between our technique and work described
in this section is difﬁcult. In general we achieve lower runtime
overhead than all surveyed work here. It’s important to keep
in mind that we protect a smaller set of computed transfers
than general CFI techniques, although for that smaller set, we
typically provide stronger guarantees.
CFI was ﬁrst
introduced by Abadi et al. [3]. In their
approach, ﬁne grained CFG’s derived from static analysis were
enforced by grouping sets of targets into equivalence classes,
and marking each with a secret cookie. Indirect control-ﬂow
instructions are instrumented to check at runtime the cookie
(placed as a no-op prior to the target). This enforcement
scheme is less precise than ours, as any two overlapping sets
of targets must be merged. In our setting, a similar technique
would not be able to distinguish different subtrees of a prim-
itive hierarchy. MCFI [28] extends Abadi’s work by adding a
level of indirection via runtime maps from branches and branch
targets to their corresponding equivalence class. Further MCFI
utilizes a thread safe dynamic update mechanism that allows
control-ﬂow graphs to be merged at runtime, thus allowing
separate compilation and dynamic linking. WIT [4] similarly
uses equivalence classes (colors) to protect indirect control-
ﬂow and extends this technique to protect writes as well.
CCFIR [43], HyperSafe [39] and MoCFI [9] replace code
pointers in writable memory with indices/pointers into tram-
poline sections. CCFIR utilizes randomization to reduce the
chance that an attacker can guess the index of a speciﬁc sen-
sitive function, while HyperSafe utilizes multiple springboard
sections to increase precision. Our technique could possibly be
used to extend these approaches by ordering the springboard
sections appropriately. As a result higher precision might be
achievable without additional runtime overhead and without
the need for randomization/multiple trampoline sections. This
is important, as the loss of precision has for example enabled
exploits of CCFIR [11].
binCFI [44] extends CFI to COTS binaries (similarly to
CCFIR) by combining reliable disassembly and binary trans-
lation. Computed transfers in binCFI are rewritten to index into
translation table using the candidate target, which restricts the
possible control-ﬂows.
Opaque CFI[26] combines coarse-grained CFI with code
randomization to defeat attackers with full access to the pro-
cess code section. Their technique covers all control transfers
and achieves 4.7% overhead over a set of SPEC benchmarks.
Their technique employs bound checks similarly to us, and is
the ﬁrst CFI technique to mention the potential for hardware
acceleration of bound checks via the upcoming Intel MPX
instructions[15].
13
C. SFI
SFI [38], [23], [40], [33], [41] is generally built on top of
a coarse-grained form of CFI, usually combining instructions
into aligned bundles. SFI techniques also leverage hardware
techniques such as segmentation or software techniques such
as masking to restrict writes to a given region. SFI has also
been applied to the Chrome through the Native Client [40]
project, where it provides sandboxing for parts of the browser.
D. Other Mitigation Techniques
Modern operating systems
employ DEP [31]
and
ASLR [29] to prevent code injection attacks and increase
the cost of jump-to-libc attacks. PointGuard [7] and [36]
propose pointer encryption as a means to prevent attackers
from accurately redirecting control-ﬂow. In their work code
pointers are encrypted (e.g. XOR-ed) using a secret key, and
unencrypted prior to use. An attacker would require the secret
key to accurately redirect control ﬂow. A slew of techniques
have been also proposed and deployed for protecting the stack
including stack canaries [6], SafeStack [20], shadow stacks [3]
and SafeSEH [25]. These techniques provide additional safety
complimentary to our work but recent work [5] shows that
they are not as secure as previously thought.
Kuznetsov et. al. [17] present CPI – a code pointer integrity
technique that protects all data which inﬂuences control-ﬂow.
Their technique provides stronger guarantees than us and
protects more computed transfers, but at a higher runtime
cost 8.4% (23% on the C++ benchmarks in SPEC2006). A
relaxation of CPI – Code-Pointer Separation (CPS) – provides
less precise protection for virtual dispatch than us, but still
covers more computed transfers (e.g. returns). CPS does not
protect the integrity of pointers to code pointers, which include
vptrs, and thus would allow vtable confusion attacks. CPS
incurs 1.9% on average (4.2% on the C++ benchmarks in
SPEC2006).
XII. LIMITATION AND FUTURE WORK
Our approach currently protects only C++ dynamic dis-
patch. We believe however that it might be possible to adapt
our technique so that it also checks the type safety of generic
function pointers. The idea would be to use a trampoline-
based technique such as CCFIR, while also laying out the
trampolines in memory using a “mock” class hierarchy based
on the function signatures. The merit of such an approach
requires further investigation as function signatures might be
too loose a safety criteria.
Another barrier to adoption that we plan on addressing is
the lack of support for dynamic linking and loading. While
dynamic linking could be supported through extending the
runtime linker, dynamic loading is a more difﬁcult feat. Merg-
ing the CFI policies of the modules concurrently with their
code running in itself is a difﬁcult problem [28]. In our setting
this is further complicated by the ordering and interleaving we
impose on pieces of data, and the immediate values in the code
section that depend on it.
Another interesting direction for future work would be to
adapt our technique to check C++ downcasts for safety at
runtime. Exploiting bugs in programs can lead to incorrect
14
C++ downcasts, which in turn can lead to type confusion and
heap corruption. Recent work [18] has shown that C++ casts
can be checked for safety with an overhead of about 7.6% on
Chrome (64.6% on Firefox). Since our approach is precisely
meant for checking that a vptr points to the vtable of a given
class or any of its subclasses, we believe that our approach
could possibly be a good ﬁt for checking dynamic casts too.
One slight caveat is that our approach would only work for
classes that have virtual methods (polymorphic classes), but
we believe this could be resolved using a hybrid approach: we
could use our approach for classes with virtual methods, and
the approach from [18] on all other classes.
Another direction for future work is protecting pointers to
member functions, and more speciﬁcally checking the validity
of the indices stored inside them. As already mentioned in
Section X-E, our approach does not currently handle such
pointers to member functions. LLVM-VCFI [22] also does not
handle such pointers, but SafeDispatch [16] does, by adding an
additional range check. OVT can trivially use the same check
as SafeDispatch since entries for a single (primitive) vtable are
still continuous. In the case of IVT this is more complicated
as entries of one vtable are interleaved with entries of related
subclasses and superclasses. One possible approach is to keep
old vtables, and refer to them from IVT for dereferencing
pointers to member functions, at the cost of additional code
bloat. Another possibility is to check member pointers directly
on the interleaved layout, but this would require coming up
with a set of carefully crafted range and stride checks.
XIII. CONCLUSION
We have presented an approach for protecting the control-
ﬂow integrity of C++ virtual method calls. Our approach is
based on a novel layout for vtables. Although our layout is
very different from a traditional one, our layout is backwards
compatible with the traditional way of doing dynamic dispatch.
Most importantly, our layout allows us to check the safety of
vtables using efﬁcient range checks. We have implemented
our approach in the LLVM compiler, and have experimentally
evaluated its runtime and memory overhead, showing that it
has lower overhead than the state-of-the-art techniques that
provide the same guarantee.
Although this paper focuses on protecting dynamic dis-
patch, our approach could possibly be a stepping stone to more
complicated forms of runtime enforcement. For example, as
we have already alluded to, our approach could possibly be
adapted to check the safety of C++ downcasts, or the type
safety of arbitrary function pointers.
ACKNOWLEDGMENTS
We would like to thank reviewers for their insightful
feedback, and Dongseok Jang for his guidance and advice.
This work was supported by NSF grant CNS-1228967 and a
generous gift from Google.
REFERENCES
[1]
[2]
“CWE-122.” Available from MITRE, CWE-ID CWE-122. [Online].
Available: https://cwe.mitre.org/data/deﬁnitions/122.html
“CVE-2012-0167.” Available from MITRE, CVE-ID CVE-2014-0160.,
2011.
[Online]. Available: https://cve.mitre.org/cgi-bin/cvename.cgi?
name=CVE-2012-0167
[31] V. A. S. Andersen, “Data execution prevention: Changes to func-
tionality in microsoft windows xp service pack 2, part 3: Mem-
ory protection technologies,” http://technet.microsoft.com/en-us/library/
bb457155.aspx, 2004.
[32] F. Schuster, T. Tendyck, C. Liebchen, L. Davi, A. Sadeghi, and
T. Holz, “Counterfeit object-oriented programming: On the difﬁculty
of preventing code reuse attacks in C++ applications,” in S&P, 2015,
pp. 745–762.
[33] C. Small, “Misﬁt: A tool for constructing safe extensible C++ systems,”
in USENIX Conference on Object-Oriented Technologies (COOTS),
S. Vinoski, Ed., 1997, pp. 175–184.
function table re-
mote code execution vulnerability,” http://www.symantec.com/security\
response/vulnerability.jsp?bid=54951, 2012.
[34] Symantec, “Microsoft
Internet Explorer virtual
[35] C. Tice, T. Roeder, P. Collingbourne, S. Checkoway,
´U. Erlingsson,
L. Lozano, and G. Pike, “Enforcing forward-edge control-ﬂow integrity
in GCC & LLVM,” in NDSS, 2014.
[36] N. Tuck, B. Calder, and G. Varghese, “Hardware and binary modi-
ﬁcation support for code pointer protection from buffer overﬂow,” in
37th Annual International Symposium on Microarchitecture (MICRO-
37, 2004, pp. 209–220.
[37] VUPEN, “Exploitation of Mozilla Firefox use-after-free vulnerabil-
ity,” http://www.vupen.com/blog/20120625.Advanced\ Exploitation\
of-Mozilla\ Firefox\ UaF\ CVE-2012-0469.php, 2012.
[38] R. Wahbe, S. Lucco, T. E. Anderson, and S. L. Graham, “Efﬁcient
software-based fault isolation,” in SOSP, 1993, pp. 203–216.
[39] Z. Wang and X. Jiang, “Hypersafe: A lightweight approach to provide
lifetime hypervisor control-ﬂow integrity,” in S&P, 2010.
[40] B. Yee, D. Sehr, G. Dardyk, J. B. Chen, R. Muth, T. Ormandy,
S. Okasaka, N. Narula, and N. Fullagar, “Native client: A sandbox
for portable, untrusted x86 native code,” in S&P, 2009, pp. 79–93.
[41] B. Zeng, G. Tan, and G. Morrisett, “Combining control-ﬂow integrity
and static analysis for efﬁcient and validated data sandboxing,” in CCS,
2011, pp. 29–40.
[42] C. Zhang, C. Song, K. Z. Chen, Z. Chen, and D. Song, “Vtint: Protecting
virtual function tables’ integrity,” in NDSS, 2015.
[43] C. Zhang, T. Wei, Z. Chen, L. Duan, L. Szekeres, S. McCamant,
D. Song, and W. Zou, “Practical control ﬂow integrity and random-
ization for binary executables,” in S&P, 2013, pp. 559–573.
[44] M. Zhang and R. Sekar, “Control ﬂow integrity for COTS binaries,” in
USENIX Security, 2013, pp. 337–352.
[3] M. Abadi, M. Budiu,
integrity,” in CCS, 2005.
´U. Erlingsson, and J. Ligatti, “Control-ﬂow
[4] P. Akritidis, C. Cadar, C. Raiciu, M. Costa, and M. Castro, “Preventing
memory error exploits with WIT,” in S&P, 2008, pp. 263–277.
[5] M. Conti, S. Crane, L. Davi, M. Franz, P. Larsen, M. Negro,
M. Qunaibit, and A.-r. Sadeghi, “Losing control : On the effectiveness
of control-ﬂow integrity under stack attacks,” In CCS, 2015.
[6] C. Cowan, “Stackguard: Automatic adaptive detection and prevention of
buffer-overﬂow attacks,” in USENIX Security, A. D. Rubin, Ed., 1998.
[7] C. Cowan, S. Beattie, J. Johansen, and P. Wagle, “PointguardTM:
Protecting pointers from buffer overﬂow vulnerabilities,” in USENIX
Security, 2003.
[8] S. Crane, S. Volckaert, F. Schuster, C. Liebchen, P. Larsen, L. Davi,
A.-R. Sadeghi, T. Holz, B. D. Sutter, and M. Franz, “Its a trap: Table
randomization and protection against function-reuse attacks,” In CCS,
2015.
[9] L. Davi, A. Dmitrienko, M. Egele, T. Fischer, T. Holz, R. Hund,
S. N¨urnberger, and A. Sadeghi, “Mocﬁ: A framework to mitigate
control-ﬂow attacks on smartphones,” in NDSS, 2012.
[10] C. Evans, “Exploiting 64-bit linux like a boss.” http://scarybeastsecurity.
blogspot.com/search?q=Exploiting+64-bit+linux, 2013.
[11] E. G¨oktas, E. Athanasopoulos, H. Bos, and G. Portokalidis, “Out of
control: Overcoming control-ﬂow integrity,” in In S&P, 2014.
[12] Google, “Heap-use-after-free in WebCore (exploitable),” https://code.
google.com/p/chromium/issues/detail?id=162835, 2012.
I. Haller, E. G¨oktas, E. Athanasopoulos, G. Portokalidis, and H. Bos,
“Shrinkwrap: Vtable protection without loose ends,” in ACSAC, 2015,
pp. 341–350.
[13]
[15]
[14] M.
InfoSecurity,
“Pwn2own at
cansecwest 2013,” https://labs.
mwrinfosecurity.com/blog/2013/03/06/pwn2own-at-cansecwest-2013,
2013.
Intel,
https://software.intel.com/en-us/articles/introduction-to-intel-memory-
protection-extensions, 2013.
intel memory
“Introduction
protection
extensions,”
to
[16] D. Jang, Z. Tatlock, and S. Lerner, “SafeDispatch: Securing C++ virtual
calls from memory corruption attacks,” in NDSS, 2014.
[17] V. Kuznetsov, L. Szekeres, M. Payer, G. Candea, R. Sekar, and D. Song,
“Code-pointer integrity,” in OSDI, J. Flinn and H. Levy, Eds., 2014, pp.
147–163.
[18] B. Lee, C. Song, T. Kim, and W. Lee, “Type casting veriﬁcation:
Stopping an emerging attack vector,” in USENIX Security, 2015.
[19] LLVM Team, “The llvm compiler infrastructure project,” http://llvm.
org/.
[20] ——, “http://clang.llvm.org/docs/safestack.html,” http://clang.llvm.org/
docs/SafeStack.html, 2014.
[21] ——, “Llvm link time optimization: Design and implementation,” http:
//llvm.org/docs/LinkTimeOptimization.html, 2014.
[22] ——, “Control ﬂow integrity design documentation,” http://clang.llvm.
org/docs/ControlFlowIntegrityDesign.html, 2015.
[23] S. McCamant and G. Morrisett, “Evaluating SFI for a CISC architec-
ture,” in In USENIX, 2006.
[24] Microsoft, “Vulnerability in Internet Explorer could allow remote
code execution,” http://technet.microsoft.com/en-us/security/advisory/
961051, 2008.
[25] Microsoft Visual Studio, “Image has safe exception handlers,” http:
//msdn.microsoft.com/en-us/library/9a89h429%28v=vs.80%29.aspx,
2005.
[26] V. Mohan, P. Larsen, S. Brunthaler, K. W. Hamlen, and M. Franz,
“Opaque control-ﬂow integrity,” in NDSS, 2015.
[27] H. D. Moore,
“Microsoft
corruption,”
memory
Microsoft-Internet-Explorer-Data-Binding-Memory-Corruption.html,
2010.
Internet Explorer
binding
http://packetstormsecurity.com/ﬁles/86162/
data
[28] B. Niu and G. Tan, “Modular control-ﬂow integrity,” in PLDI, 2014.
[29] PaX Team, “Pax address space layout randomization (aslr),” http://pax.
grsecurity.net/docs/aslr.txt, 2003.
[30] A. Prakash, X. Hu, and H. Yin, “vfguard: Strict protection for virtual
function calls in COTS C++ binaries,” in NDSS, 2015.
15