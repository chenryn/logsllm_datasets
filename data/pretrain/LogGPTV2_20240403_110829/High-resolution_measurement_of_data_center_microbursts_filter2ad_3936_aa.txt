title:High-resolution measurement of data center microbursts
author:Qiao Zhang and
Vincent Liu and
Hongyi Zeng and
Arvind Krishnamurthy
High-Resolution Measurement of Data Center Microbursts∗
Qiao Zhang
University of Washington
PI:EMAIL
Vincent Liu
University of Pennsylvania
PI:EMAIL
Hongyi Zeng
Facebook, Inc.
PI:EMAIL
Arvind
Krishnamurthy
University of Washington
PI:EMAIL
ABSTRACT
Data centers house some of the largest, fastest networks in the
world. In contrast to and as a result of their speed, these networks
operate on very small timescales—a 100 Gbps port processes a sin-
gle packet in at most 500 ns with end-to-end network latencies
of under a millisecond. In this study, we explore the fine-grained
behaviors of a large production data center using extremely high-
resolution measurements (10s to 100s of microsecond) of rack-level
traffic. Our results show that characterizing network events like
congestion and synchronized behavior in data centers does indeed
require the use of such measurements. In fact, we observe that more
than 70% of bursts on the racks we measured are sustained for at
most tens of microseconds: a range that is orders of magnitude
higher-resolution than most deployed measurement frameworks.
Congestion events observed by less granular measurements are
likely collections of smaller µbursts. Thus, we find that traffic at
the edge is significantly less balanced than other metrics might
suggest. Beyond the implications for measurement granularity, we
hope these results will inform future data center load balancing
and congestion control protocols.
CCS CONCEPTS
• Networks → Network measurement; Data center networks;
Network performance analysis; Network monitoring; Social media
networks;
KEYWORDS
Data center traffic, microbursts
ACM Reference Format:
Qiao Zhang, Vincent Liu, Hongyi Zeng, and Arvind Krishnamurthy. 2017.
High-Resolution Measurement of Data Center Microbursts. In Proceedings
of IMC ’17, London, United Kingdom, November 1–3, 2017, 8 pages.
https://doi.org/10.1145/3131365.3131375
∗Raw data for the distributions presented in the paper are available at https://github.
com/zhangqiaorjc/imc2017-data
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
IMC ’17, November 1–3, 2017, London, United Kingdom
© 2017 Copyright held by the owner/author(s). Publication rights licensed to Associa-
tion for Computing Machinery.
ACM ISBN 978-1-4503-5118-8/17/11...$15.00
https://doi.org/10.1145/3131365.3131375
1 INTRODUCTION
Data center networks are defined by their scale. The largest of
today’s data centers are massive facilities that house up to hun-
dreds of thousands of servers connected by thousands of network
switches. The switches in turn have high (and rapidly growing)
capacity, with state-of-the-art models able to process terabits of
traffic per second at 100 Gbps per port.
In contrast to the massive aggregate bandwidth of these de-
ployments is the minuscule timescales on which they operate: a
100 Gbps port processes packets in at most 500 ns, and a packet can
traverse the entire network in tens to hundreds of microseconds.
Unfortunately, much of what we know about data center traffic
(and, in fact, most production monitoring systems) are either on
the scale of minutes [7] or are heavily sampled [16]. While such
measurements can inform us of long-term network behavior and
communication patterns, in modern data center networks, coarse-
grained measurements fail to provide insight into many important
behaviors.
One example: congestion. In most prior work, large cloud net-
work operators have observed that packet discards occur, but are
uncorrelated or weakly correlated with observed link utilization,
implying that most congestion events are too short-lived to be
characterized by existing data sets. Coarse-grained measurements
also make it difficult to answer questions about concurrent behav-
ior like how many ports are involved in each congestion event or
how effective the network is at load balancing. The design of data
center switches, networks, and protocols depend on this type of
fine-grained behavior.
Our primary contribution is to provide a high-resolution char-
acterization of a production data center network. To do so, we
developed a custom high-resolution counter collection framework
on top of the data center operator’s in-house switch platform. This
framework is able to poll switch statistics at a 10s to 100s of mi-
croseconds granularity with minimal impact on regular switch
operations.
With the framework, we proceed to perform a data-driven analy-
sis of various counters (including packet counters and buffer utiliza-
tion statistics) from Top-of-Rack (ToR) switches in multiple clusters
running multiple applications. While our measurements are lim-
ited to ToR switches, our measurements and prior work [6, 9, 18]
indicate that the majority of congestion occurs at that layer. More
generally, we do not claim that our results are representative of all
modern data center networks—they are merely a slice of one large
operator’s network, albeit at a heretofore unprecedented granular-
ity. Our main findings include:
• µbursts, periods of high utilization lasting less than 1 ms, exist
in production data centers, and in fact, they encompass most
congestion events. The p90 burst duration is ≤200 µs.
IMC ’17, November 1–3, 2017, London, United Kingdom
Q. Zhang et al.
Figure 1: Scatter plot of ToR-server links’ drop rates and utilization
across the data center. Drops only include congestion discards and
not packet corruptions. Measurements were taken at a granularity
of 4 minutes, and samples were taken once per hour over the course
of 24 hours.
erally intense.
• Link utilization is multimodal; when bursts occur, they are gen-
• At small timescales, many multi-statistic features become pos-
sible to measure: load can be very unbalanced, packets tend to
be larger inside bursts than outside, and buffers are related to
simultaneous bursts in a nonlinear fashion.
2 BACKGROUND AND RELATED WORK
Much effort has gone into measuring and understanding data center
network behavior for the purpose of designing better networks.
For large-scale measurements, the existing studies along these lines
have taken one of two approaches:
Packet sampling. One method of measuring networks is to exam-
ine packets directly. tcpdump provides this functionality, but raw
dumps are not tractable for medium- to long-term measurement
without substantial dedicated hardware/overhead [17]. Instead,
some studies sample packets using sFlow in the network [16] or
iptables collection on end hosts [18]. Sampling is typically done
such that only one packet in thousands or tens of thousands
are recorded. Facebook, for instance, typically samples packets
with a probability of 1 in 30,000. Packet sampling can provide
insight into traffic patterns, as was the case in [18], which found
that patterns were mostly stable over time, but very different for
different applications.
Coarse-grained counters. An alternative to sampling packets is
to look at coarse-grained network counters like those provided
by SNMP [7]. Prior studies have relied heavily on such counters.
SNMP counters give up some information compared to packet
samples (e.g., source and destination), but provide a view into
the interaction of packets within the network. [6] and [9], for
example, analyze utilization/drops in networks, and found in-
dications of bursty behavior. Many data centers collect these
statistics by default as they provide useful aggregate statistics
and can be used to detect major problems in the network. Typical
granularities for SNMP collection in data centers are on the order
of minutes [6, 18].
In addition to the above, researchers have proposed switch hard-
ware modifications to provide more scalable, accurate measure-
ments [10, 12, 14, 20]; however, these are not deployed widely
enough to perform large-scale production measurements.
(a) Low-utilization Port
(b) High-utilization Port
Figure 2: Time series of drops on two different ports. (a) has rela-
tively low utilization, and (b) has relatively high utilization. Sam-
ples were taken at a granularity of 1 min over a 12 hr time span.
3 THE CASE FOR HIGH RESOLUTION
The granularity of coarse-grained counters and packet sampling
makes it difficult to answer many important questions about the
underlying behavior of the network. As an example of how gran-
ularity can hinder our view of network behavior, Fig. 1 shows a
scatter plot of utilization and packet discard counters of ToR-server
links across a data center. For every ToR-server in the data center
we studied and every hour in a day, we sub-sample by randomly
picking a 4-minute interval for the hour and take measurements
during that period. The utilization and drop rates are computed over
a 4-minute interval (the SNMP polling interval used in production).
Despite a wide range of observed average utilization, utilization
does not have a strong effect on drop rates (correlation coefficient
of 0.098).
Part of the issue is that, at this granularity, only severe or sus-
tained congestion would result in high drop rates. The time series of
switch behavior shown in Fig. 2 provides some further insight into
why utilization and drop rate do not match. We chose two switch
ports that were experiencing congestion drops and plotted their
drops at a granularity of 1 minute over time over the course of 12
hours. One switch port had relatively low utilization (∼9%) as it was
on the critical path for web requests. The other had high utilization
(∼43%) and ran offline data processing. In both cases, drops occur
in bursts, often lasting less than the measurement granularity (1
minute in this case). Succeeding intervals often have no drops.
We therefore pose the following questions:
• What do bursts look like and how often do they occur?
• What role do µbursts (high utilization lasting <1 ms) play?
• Does network behavior differ significantly inside a burst?
• Is there synchronized behavior during bursts?
High-Resolution Measurement of Data Center Microbursts
IMC ’17, November 1–3, 2017, London, United Kingdom
4 DATASETS AND METHODOLOGY
To answer the above questions, we built a measurement framework
that is able to collect extremely fine-grained samples of various
switch statistics. The goal of our framework is to be able to observe
network changes that occur on the order of a few RTTs. In this sec-
tion, we describe the framework we built for collecting fine-grained
switch measurements, the associated collection methodology, and
the resulting data sets.
4.1 High-resolution counter collection
Our sampling framework was built on top of the data center’s in-
house switch platform, and it allows operators to poll a subset of
switch counters at microsecond-level granularity.
Our framework takes advantage of the fact that modern switches
include relatively powerful general-purpose multi-core CPUs in
addition to their switching ASICs (Application-Specific Integrated
Circuits). The ASICs are responsible for packet processing, and as
part of their functionality, they maintain many useful counters. The
CPUs, on the other hand, are traditionally responsible for handling
control plane logic. By modifying the switch platform, we can enlist
the CPU to also poll its local counters at extremely low latency.
The CPU batches the samples before sending them to a distributed
collector service that is both fine-grained and scalable.
Polling intervals are best-effort as kernel interrupts and compet-
ing resource requests can cause the sampler to miss intervals. To
obtain precise timing, the framework requires a dedicated core, but
can trade away precision to decrease utilization to ≤ 20% in most
cases. The maximum polling rate depends on the target counter as
well as the target switch ASIC. Differences arise due to hardware
limitations: some counters are implemented in registers versus
memory, others may involve multiple registers or memory blocks.
For the counters we measure, we manually determine the minimum
sampling interval possible while maintaining ∼ 1% sampling loss.
For instance, one of the counters we measure (a byte counter) ex-
hibited the following sampling loss behavior, leading us to choose
a 25 µs interval:
Sampling interval Missed intervals
1 µs
10 µs
25 µs
100%
∼10%
∼1%
Table 1: The effect of sampling interval on miss rate for a byte
counter. When the sampler misses an interval, we still capture the
total number of bytes and correct timestamp.
Multiple counters can be polled together with a sublinear in-
crease in sampling rate depending on the specific combination of
counters. As with single counters, collection of groups of counters