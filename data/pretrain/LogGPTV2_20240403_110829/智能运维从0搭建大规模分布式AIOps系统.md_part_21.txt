saveAsHadoopFiles(prefix,[suffix])
saveAsObjectFiles(prefix,[suffix])
通过上文介绍我们知道，Spark Streaming 提供了方便的数据流、计算及结果输入方式,
通常将数据写入外部系统中需要创建连接对象（例如通过 TCP 连接到远程服务器），并使
时间分片对于 Spark Streaming 来说相当重要。因为 Spark 是按照时间分片提交作业的，如
1．设置合理的批处理时间
dstream.foreachRDD 是一个功能强大的原语，允许将数据发送到外部系统中。因此，了解
智能运维：从O搭建大规模分布式AIOps系统
优化运行时间
表 7-3Spark Streaming 支持的输出方法
其中执行RDD操作，这将强制计算流式RDD
最通用的输出运算符，将函数func 应用于从流中生成的每个 RDD 上。此功能应将每
缀“prefx-TIME_IN_MS[.suffix]”生成
将此DStream中的内容保存为Hadoop文件。每个批处理间隔的文件名都基于前缀和后
件名都基于前缀和后缀“prefx-TIME_IN_MS[.sufix]”生成
将此 DStream 中的内容保存为序列化 Java 对象的 SequenceFiles。每个批处理间隔的文
“prefix-TIME_IN_MS [.suffix]” 生成
数据库。请注意，函数func 在运行流应用程序的驱动程序进程中执行，并且通常会在
个RDD 中的数据推送到外部系统，例如将RDD 保存到文件，或者通过网络将其写入
将此DStream中的内容保存为文本文件。每个批处理间隔的文件名都基于前缀和后缀
开发和调试很有用
在运行流应用程序的驱动程序节点上的DStream中打印每批数据的前10个元素。这对
描述
系
并
---
## Page 142
流计算)，这也是Flink 的最大特点。Flink 支持本地快速迭代，以及一些环形的迭代任务。
设计思想正好相反（Spark Streaming 本质上是批处理，只是将计算分成了很小的单元，近似成
是流数据的一个极限特例而己。Flink 的批处理方式采用的是流式计算原理，这一点跟 Spark 的
主要还是依靠开源社区的贡献来发展的。对于 Flink，其处理的数据主要是流数据，批数据只
的最新版本已经更新到1.4.2。目前使用 Flink 的公司有阿里巴巴、Uber 等。
受，然后迅速成为ASF（Apache Software Foundation）的顶级项目之一。截至本书写作时，Flink
7.3
用。可以通过 Spark Driver 和 Executor 来配置合理的 CPU 计算资源。
法，然后根据业务场景进行配置。
接使用。
议采用Kryo系列化类来替代。
虑设置 inputStream 来提高接入的并行度
batchDuration 可以达到毫秒级；实际上，在数据量大的情况下很难达到毫秒级。
Flink 是一个针对流数据和批数据的分布式处理引擎，主要用 Java 代码实现。目前，Flink
2008 年，Flink2的前身已经是柏林理工大学的一个研究项目，2014 年被 Apache 孵化器接
Spark 计算依赖 CPU 资源，为计算配置足够的CPU计算资源，让集群的资源得到更好的利
6．设置合理的CPU数量
不合理的 Java 的 GC 方式对 Spark 的性能有很大影响。对于 GC 方式可以研究 Java GC方
Spark 是用 Scala 语言开发的，运行在 JVM 上就避免不了遇到因为内存不足导致的 GC 问
对于反复使用的计算结果数据，为避免重复计算，建议采用数据缓存或者持久化方式，直
4.减少数据重复计算
Spark 默认使用 Java 内置的系列化类，但是由于 java.io.Serializable 类的性能不佳，所以建
5.
3.
在设置计算的并行度时应尽可能利用集群的资源。如果是数据接入的性能不好，则可以考
2．增加Job并行度
Flink计算框架
．设置合理的GC
使用Kryo系列化类
第7章
实时计算框架
115
---
## Page 143
行；它具有很好的吞吐量和延迟特性。同时，Flink 提供了多种灵活的窗口函数。
用程序状态的同时无缝地从故障中恢复；它支持大规模计算能力，能够在数千个节点上并发运
7.3.2
数据。
Transformations 根据实际业务进行计算和转换。Data Sink是Flink 处理完的数据，即输出
其中，Data Source（数据源）就是要进入Flink 处理的数据，如 HDFS、Kafka 中的数据等。
大的优势。
次序错误等潜在问题。Flink 采用实时处理的执行模型，在数据处理精度和计算性能方面都有更
定是最优的。例如，批处理一直被应用于无界数据集的处理上，尽管它存在窗口、状态管理和
执行有限的数据的处理过程。不管采用哪种类型的执行模型来处理数据都是可以的，但却不一
物理传感器、金融市场、机器的日志数据。
无界数据集。无界数据集包括但不限于：与移动或 Web 应用程序交互的最终用户、提供测量的
有界数据集的数据是不可变的。许多传统上被认为是有界或“批”数据的真实数据集实际上是
7.3.1
116
Flink 是一个开源的分布式实时计算框架。Flink 是有状态的和容错的，可以在维护一次应
Flink程序包含的主要模块有：Data Source、Transformations 和Data Sink，如图7-6所示
3.Flink程序模块
实时处理是指当数据正在生成时连续执行的数据的处理过程。批处理是指在有限的时间内
2.执行模型
数据集（DataSet）分为有界数据集和无界数据集。无界数据集的数据会源源不断地流入，
1．数据集
智能运维：从0搭建大规模分布式AIOps系统
Flink特点
基本概念
Data Source
图7-6Flink程序包含的主要模块
Transformations
Data Sink
---
## Page 144
所示。
以准确、快速地做到从故障中以零数据丢失的效果进行恢复。Flink 的容错机制示意图如图7-10
的触发条件来支持更加复杂的流模式。
可能的到达延迟流中计算出准确的结果。Flink 的事件机制示意图如图 7-8 所示。
的数据集结果和状态。Flink 的状态管理机制示意图如图 7-7所示。
Flink 高效的容错机制允许系统在高吞吐量的情况下支持exactly-once 语义的计算。Flink 可
4.容错机制
Flink 支持基于时间、数目以及会话的非常灵活的窗口机制（window）。可以定制window
Flink支持流处理和窗口事件时间语义。事件时间可以很容易地通过事件到达的顺序和事件
Flink 检查点机制能保持 exactly-once 语义的计算。状态保持意味着应用能够保存已经处理
3
1．状态管理机制
：事件机制
窗口机制
图7-7
图7-9
图7-8Flink的事件机制示意图
）Flink的窗口机制示意图
Flink的状态管理机制示意图
Flink的窗口机制示意图如图7-9所示。
=1
L
实时计算框架
117
---
## Page 145
7.3.3
和Apache Storm完成分布式项目计数任务的性能对比。
118
可以通过Yarn 和 Mesos 等资源管理软件来管理和部署Flink。
6.部署
Flink 具有高吞吐量和低延迟（能快速处理大量数据）特性。图 7-11 展示了 Apache Flink
分布式执行 Flink 的链操作任务，每个任务都由一个线程执行。将操作符链接到任务中是
1．链操作任务
5．高吞吐量、低延迟
智能运维：从O 搭建大规模分布式 AIOps 系统
运行原理
Elementspersecond
(millions)
100
150
0
40
Throughput
FlinkStorm
图7-11Flink与Storm性能对比
图7-10Flink的容错机制示意图
120
snapshots
Latency (msecs)
state
50
100
150
0
Latency at Full Throughput
barriers
40
120
---
## Page 146
所示。
将心跳和统计信息汇报给 JobManager。TaskManager 之间以流的形式进行数据传输，如图 7-13
提交任务给 JobManager,JobManager 再调度任务到各个 TaskManager来执行，然后 TaskManager
JobManager。
可用性，设置了多个JobManager，其中一个是领导者，其他的作为备用。
量。可以配置链接行为，如图7-12所示。
一个有用的优化，其减少了线程间切换和缓冲的开销，并且在降低延迟的同时提高了总体吞吐
当 Flink 集群启动后，首先会启动一个 JobManager 和一个或多个 TaskManager。由客户端
3.运行
Client：客户端用来进行任务调度前期的准备（数据、环境变量等)，然后提交计算任务到
Task Tracker：执行任务（更具体地说，是一个数据流任务）、和缓冲区交换数据流。
JobTracker：协调分布式执行一
2.
任务提交
任务提交之后，客户端可以断开连接，也可以继续保持连接以接收进度报告。
sourcemal)
Operatorchain
Source
(subtesk)
map()
图7-12
Tasl
一安排任务、协调检查点、协调故障恢复等。为了具有高
Flink的链操作示意图
三
第7章实时计算框架
119
---
## Page 147
销。Flink 的任务槽示意图如图 7-14 所示。
接（通过多路复用）和心跳消息，它们也可能共享数据集和数据结构，从而减少每个任务的开
而拥有多个插槽，则意味着更多的子任务共享相同的JVM。同一个JVM 中的任务共享TCP 连
个插槽，这意味着每个任务组都可以在单独的JIVM中运行（例如，可以在单独的容器中启动)；
存。请注意，目前插槽仅分离托管的任务内存，不会进行CPU的隔离。。
将为每个插槽分配1/3隔离的内存资源，这意味着子任务不会与其他作业中的子任务来竞争内
个子任务。为了控制Worker 可以接收多少个任务，Worker 有所谓的任务槽（至少一个)。
120
通过调整任务槽的数量，用户可以定义子任务如何彼此隔离。每个 TaskManager 都拥有一
每个任务槽都代表TaskManager 的一个固定资源子集。例如，具有三个插槽的 TaskManager
每个 Worker（TaskManager）都是一个JVM 进程，并且可以在单独的线程中执行一个或多
4．任务槽和资源
Flink Program
智能运维：从O搭建大规模分布式AIOps系统
Praeram
Dataflowgraph
Client
图7-13Flink整体流程图（图片来源于Flink官网[2)
syctem
spatus
TaskManager
Memory& I/oManager
Network ManagerData Streams
ucancelb
Actor System
(Worker)
Statistis
Task
(Master/YARNApplicationMaste
JobManager
Actor System
Ccherkipliot
Scheduler
Statistics
Heartbeats
TaskStatus
Task
TaskManager
Memory & I/O Manager
Actor System
(Worker)
ter)
Task
/Checigeint
---
## Page 148
$ mvn archetype:generate\
构建更复杂的分析程序提供了良好的基础。
读取此频道，并计算每个用户在给定窗口时间内编辑的字节数。使用 Flink 很容易实现，并为
序
7.3.4
-DgroupId=wiki-edits\
-DarchetypeVersion=1.4.2\
-DarchetypeArtifactId=flink-quickstart-java\
-DarchetypeGroupId=org.apache.flink\
-DinteractiveMode=false
-Dpackage=wikiedits\
-DartifactId=wiki-edits
1．创建Maven工程
-Dversion=0.1\
维基百科提供了一个 IRC 频道，其中所有对 Wiki 的编辑都被记录下来。我们将在 Flink 中