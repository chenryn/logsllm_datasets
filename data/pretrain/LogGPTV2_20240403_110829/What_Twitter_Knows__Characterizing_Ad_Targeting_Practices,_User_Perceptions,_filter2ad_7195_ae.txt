### 4.4.2 Targeting Types: Awareness and Reactions

We also investigated participants’ familiarity with, or misconceptions of, the various targeting types. Before providing any information about a targeting type, we showed participants the term Twitter uses to describe that type [63] and asked them to indicate their current understanding or best guess of what the term meant in the context of online advertising.

#### Familiarity with Common Targeting Types
Nearly all participants had accurate mental models of location, age, gender, and keyword targeting, likely because these types are well-known and straightforward. Additionally, 93% of participants correctly defined interest targeting, suggesting it is also relatively easy to understand. Some participants confused other targeting types with interest targeting, as illustrated by P161's response on follower lookalike targeting: “I have never heard this term before. I’m guessing that they target ads based on your followers’ interests as well?”

#### Misunderstood Targeting Types
Tailored audience (list), behavior, and mobile audience targeting were the least understood. Specifically, 96.4%, 97.0%, and 100% of participants, respectively, provided incorrect or only partially correct definitions. The first two types rely on offline data being connected with participants’ online accounts, but most participants incorrectly defined them based solely on online activities. For mobile audience targeting, misunderstandings arose from different interpretations of "mobile" (e.g., P122 guessed, “advertising based on your phone network?”). The correct answer relates to the user’s interactions with mobile apps. Participants often believed a targeting type meant advertising that type of thing (e.g., an event) rather than leveraging user data about that thing for targeting ads (e.g., targeting a product only to users who attended an event).

#### Language and Platform Targeting
While 63.6% of participants correctly referenced the user’s primary language when defining language targeting, many of the 28.8% who defined it incorrectly proposed more involved and potentially privacy-invasive definitions. For example, P76 stated, “I suppose that language targeting would be communicating in a way that is targeted to how that specific person communicates. For example, as a millennial, I would want to see language that is similar to how I speak rather than how someone who is my parents' age would speak.” Similarly, platform targeting was misunderstood, with some participants believing it referred to targeting by social media platform use or even political stance, as P147 suggested: “It looks at my list of people I follow and sends me ads based on what they believe my political stance is.”

#### Misconceptions About Ad Targeting
Across targeting types, some participants believed that advertising is based on surreptitious recordings of phone audio. For instance, P231 said of conversation targeting: “Given what I know about how phone microphones are always on, I would guess that it’s when ads pop up based on what I’ve said in a conversation.”

### 4.5 Participant Responses to Ad Explanations

We examined reactions to our ad explanations among the 193 participants who saw all six variants. Our approximation of Twitter’s current explanation served as our primary basis of comparison. We also report qualitative opinions about what was memorable, perceived to be missing, or would be ideal.

#### Comparing Our Ad Explanations to Twitter’s
Overall, participants found explanations containing more detail to be more useful, as shown in Figure 5. Unsurprisingly, the Control explanation was the least useful; only 31.3% of participants agreed it was useful. This is significantly less than our Twitter baseline, where 48.8% agreed (V = 6344.5, p < 0.001). The Facebook explanation was comparable to the Twitter explanation (41.4% agreed; V = 3520.0, p = 0.154). In contrast, the three explanations we designed—Detailed Text, Detailed Visual, and Creepy—were rated as significantly more useful than Twitter’s (V = 1352.5–2336.0, all p < 0.001). Specifically, 63.6%, 71.2%, and 78.6% of participants, respectively, agreed that the Detailed Text, Detailed Visual, and Creepy explanations were useful.

The usefulness ratings closely resembled responses to whether the explanation provided “enough information to understand how the ad was chosen for me." Again, Twitter performed better than only the Control (V = 5906.0, p < 0.001) and did not significantly differ from Facebook (V = 4261.0, p = 0.091). Participants agreed that our explanations—Detailed Text, Detailed Visual, and Creepy—were most helpful in understanding how they were targeted; all three significantly differed from Twitter (V = 1928.0–2878.0, all p ≤ 0.001).

#### Privacy Concerns
For privacy concern, 77.2% of participants agreed that the Creepy explanation made them “more concerned about my online privacy,” compared to 34.8% for Twitter and just 28.2% for the Control. Privacy concern for the Creepy explanation was significantly higher than for Twitter (V = 989.5, p < 0.001). Both Facebook and Detailed Text also exhibited significantly more concern than Twitter (V = 1821.0, 2835.0; p = 0.002, 0.015), but to a lesser extent. Respondents reported comparable privacy concern for the Twitter explanation as for Detailed Visual and Control (V = 2029.5, 3751.0, p = 0.080, 0.064).

#### Trust in Advertisers
Transparency and usefulness generally did not translate to increased trust in an advertiser. Only a minority of participants agreed that they trusted the advertiser more as a result of any provided ad explanation. Only the Detailed Visual explanation increased trust significantly relative to Twitter (V = 1695.5, p < 0.001).

#### Preference for Ad Explanations
A majority of participants agreed they would “want an ad explanation similar to this one for all ads I see on Twitter” for our Creepy (68.8%), Detailed Visual (64.4%), and Detailed Text (54.9%) versions. Agreement for these was significantly larger (V = 1798.5–2132.0, all p < 0.001) than the 39.8% who wanted Twitter-like explanations. Participants significantly preferred Twitter to the Control (V = 6831.5, p < 0.001), but not to Facebook (V = 4249.0, p = 0.339).

### 4.5.2 Qualitative Responses to Ad Explanations

#### Detail and Indicators of Non-Use
Participants want detail and indicators of non-use. When asked what they found most memorable about each ad explanation, for the Control, Facebook, and Twitter, the most memorable aspect was the lack of detail about how participants were targeted (30.7%, 21.6%, and 13.3% of participants, respectively). By comparison, 16.3% (Detailed Text), 7.9% (Visual), and 3.1% (Creepy) of participants noted a lack of detail as the most memorable part. Conversely, 81.7% found the amount of detail in the Creepy explanation to be the most memorable part, followed by 61.2% for the Visual explanation. These findings may be because the Creepy explanation included the most information, and the Detailed Visual explanation indicated which targeting types were not used.

#### Perceived Missing Information
Ambiguity was perceived as missing information. We also asked participants what information, if any, they thought was missing from each ad explanation. In line with the quantitative results for usefulness, our Detailed Visual, Detailed Text, and Creepy explanations performed best, with 61.2%, 58.9%, and 53.0% of participants, respectively, answering that nothing was missing. Conversely, Facebook, Control, and Twitter performed less well, with 69.2%, 67.3%, and 52.4% of participants, respectively, stating that some information was missing or unclear. For Detailed Text and Detailed Visual, the most commonly noted missing information related to our use of “may” and “might” about which criteria actually matched the participant. This was necessitated by the ambiguity of the Twitter files (prior to receiving a clarification from Twitter; see Section 3.6 for details). For Facebook, the most commonly missing information was associated with the hashed tailored audience list: several wrote that they did not know what a hashed list was. P125 wrote, “The nature of the list mentioned should be clarified in some detail. It’s unfair to be put on a list without access to what the list is and who compiled it and who has access to it.”

#### Ideal Ad Explanations
Describing their ideal Twitter ad explanation, 46.8% of participants wanted to see the specific actions (e.g., what they Tweeted or clicked on) or demographics that caused them to see a given ad. 34.2% wanted to know more about how the advertiser obtained their information. They also wanted clear language (19.0%) and settings for controlling ads (13.4%).

### 5 Discussion

We studied Twitter’s targeted advertising mechanisms, which categorize users by demographic and psychographic attributes, as determined from information provided by the user, provided by advertisers, or inferred by the platform. While prior work has surfaced and studied user reactions to ad targeting as a whole [20, 70], or specific mechanisms like inferred interests [17], our work details advertisers’ use of 30 unique targeting types and investigates user perceptions into 16 of them. These distinct types, including follower lookalikes and tailored audiences, are rarely studied by the academic community but frequently used by advertisers (see Table 1). Our participants expressed greater discomfort with some of these less-studied targeting types, highlighting a need for future work.

We complement existing work on Facebook ad transparency by investigating ad explanations on a different platform, Twitter, and using participants’ own Twitter data to evaluate them. Strengthening prior qualitative work [20], we quantitatively find that our participants preferred ad explanations with richer information than currently provided by Facebook and Twitter. We also find significant user confusion with “hashed” lists, a term introduced to ad explanations by Facebook in 2019 [55] to explain how platforms match user data to information on advertiser-uploaded lists for tailored audience targeting (called custom audiences on Facebook).

#### Prohibiting Sensitive Targeting
We find several instances of ad targeting that appear to violate Twitter’s stated policy prohibiting targeting on sensitive attributes. Such targeting is often considered distasteful and, in some cases, may even be illegal. We observed these instances most commonly in targeting types where advertisers provide critical information: keywords (where advertisers can provide any keyword of choice, subject to Twitter acceptance) and variations of tailored audiences, where the advertiser provides the list of users to target. Potentially discriminatory keywords are a problem that Twitter could theoretically solve given a sufficiently accurate detection algorithm or (more likely) manual review. Tailored audiences, however, are more pernicious. Advertisers can use any criteria to generate a list. We were only able to identify potentially problematic cases because the list name, which is under advertiser control, happened to be meaningfully descriptive. It would be trivial for an advertiser to name a list generically to skirt scrutiny, calling into question whether Twitter’s policy on sensitive attributes has (or can have) any real force in practice. It also raises larger concerns about regulating potentially illegal or discriminatory practices as long as tailored audiences remain available.

#### Accuracy and Discomfort
Similarly to prior work, we found that the perceived inaccuracy of targeting instances correlates with users having less desire for such targeting to be used for them [14, 17]. This has potentially dangerous implications. If accuracy reduces discomfort, this may appear to justify increasing invasions of privacy to obtain ever-more-precise labels for users. However, participants’ free-text responses indicate an upper bound where increasing accuracy is no longer comfortable. For example, P220 noted that a specific instance of location targeting was “very accurate, ... but I don’t really like how they are able to do that without my knowledge and even show me ad content related to my location, because I choose not to put my specific location on my Twitter account in any way for a reason.” Future work should investigate how and when accuracy crosses the line from useful to creepy.

#### Transparency: A Long Way to Go
This work also contributes a deeper understanding of ad explanations, amid substantial ongoing work on transparency as perhaps the only way for the general public to scrutinize the associated costs and benefits. Participants found our ad explanations, which provide more details, significantly more useful, understandable, and desirable than currently deployed ad explanations from Twitter and Facebook. However, our results also highlight a significant challenge for transparency: platform and advertiser incentives. Some of our proposed explanations, despite being more useful, decreased participant trust in the advertiser, which clearly presents a conflict of interest. This conflict may explain why currently deployed explanations are less complete or informative than they could be.

Finally, our results suggest that it is insufficient to simply require data processing companies to make information available. While the option to download advertising data is a strong first step, key aspects of the ad ecosystem—such as the origins of most targeting information—remain opaque. In addition, even as researchers with significant expertise, we struggled to understand the data Twitter provided (see Section 3.6). This creates doubt that casual users can meaningfully understand and evaluate the information they receive. However, our participants indicated in free-response answers that they found the transparency information provided in our study useful and that it illuminated aspects of tracking they had not previously understood, making it clear that comprehensible transparency has value. We therefore argue that transparency regulations should mandate that raw data files be accompanied by clear descriptions of their contents, and researchers should develop tools and visualizations to make this raw data meaningful to users who want to explore it.

### Acknowledgments

We gratefully acknowledge support from the Data Transparency Lab and Mozilla, as well as from a UMIACS contract under the partnership between the University of Maryland and DoD. The views expressed are our own.

### References

[1] Online appendix. https://www.blaseur.com/papers/usenix20twitterappendix.pdf.
[2] Gunes Acar, Christian Eubank, Steven Englehardt, Marc Juarez, Arvind Narayanan, and Claudia Diaz. The Web Never Forgets: Persistent Tracking Mechanisms in the Wild. In Proc. CCS, 2014.
[3] Lalit Agarwal, Nisheeth Shrivastava, Sharad Jaiswal, and Saurabh Panjwani. Do Not Embarrass: Re-Examining User Concerns for Online Tracking and Advertising. In Proc. SOUPS, 2013.
[4] Muhammad Ali, Piotr Sapiezynski, Miranda Bogen, Aleksandra Korolova, Alan Mislove, and Aaron Rieke. Discrimination Through Optimization: How Facebook’s Ad Delivery Can Lead to Skewed Outcomes. In Proc. CSCW, 2019.
[5] Hazim Almuhimedi, Florian Schaub, Norman Sadeh, Idris Adjerid, Alessandro Acquisti, Joshua Gluck, Lorrie Cranor, and Yuvraj Agarwal. Your Location has been Shared 5,398 Times! A Field Study on Mobile App Privacy Nudging. In Proc. CHI, 2015.
[6] Athanasios Andreou, Márcio Silva, Fabrício Benevenuto, Oana Goga, Patrick Loiseau, and Alan Mislove. Measuring the Facebook Advertising Ecosystem. In Proc. NDSS, 2019.
[7] Athanasios Andreou, Giridhari Venkatadri, Oana Goga, Krishna P. Gummadi, Patrick Loiseau, and Alan Mislove. Investigating Ad Transparency Mechanisms in Social Media: A Case Study of Facebook’s Explanations. In Proc. NDSS, 2018.
[8] Julia Angwin and Terry Parris. Facebook Lets Advertisers Exclude Users by Race. ProPublica, October 28, 2016.
[9] @ashrivas. More Relevant Ads with Tailored Audiences. Twitter Blog, December 2013. https://blog.twitter.com/marketing/en_us/a/2013/more-relevant-ads-with-tailored-audiences.html.
[10] Rebecca Balebako, Pedro Leon, Richard Shay, Blase Ur, Yang Wang, and Lorrie Faith Cranor. Measuring the Effectiveness of Privacy Tools for Limiting Behavioral Advertising. In Proc. W2SP, 2012.
[11] Muhammad Ahmad Bashir, Sajjad Arshad, and William Robertson. Tracing Information Flows Between Ad Exchanges Using Retargeted Ads. In Proc. USENIX