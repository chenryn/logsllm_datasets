In particular, for each of the questions presented in Figure 4
besides Speciﬁc: Accurate, we generated a median response
for each participant of the up to four targeting types they were
asked questions about. From this, we found only 23 of our 231
participants disagreed or strongly disagreed as their median
response for all 4 questions.
4.4.2 Targeting Types: Awareness and Reactions
We were also interested in participants’ familiarity with, or
misconceptions of, the various targeting types. Before partici-
pants were given any information about a targeting type, we
showed them the term Twitter uses to describe that type [63]
and asked them to indicate their current understanding or best
guess of what that term meant in the context of online adver-
tising. Nearly all participants had accurate mental models of
location, age, gender, and keyword targeting, likely because
these types are fairly well-known and straightforward. Further,
93% of participants asked about interest correctly deﬁned it,
suggesting it is also relatively straightforward. In fact, some
participants confused other targeting types with interest tar-
geting: “I have never heard this term before. I’m guessing that
they target ads based on your followers’ interests as well?”
(P161 on follower lookalike targeting).
Tailored audience (list), behavior, and mobile audience
targeting were the least well understood, with 96.4%,
97.0%, and 100% of participants, respectively, providing an
incorrect or only partially correct deﬁnition. The ﬁrst two
rely on oﬄine data being connected with participants’ online
accounts, but most participants incorrectly deﬁned the term
only based on online activities. Mobile audience targeting
was misunderstood due to diﬀerent interpretations of “mobile”
(e.g., P122 guessed, “advertising based on your phone net-
work?”) or other mobile details. The correct answer relates
to the user’s interactions with mobile apps. Participants also
frequently believed a targeting type meant advertising that
type of thing (e.g., an event) as opposed to leveraging user
data about that thing for targeting ads (e.g., targeting a product
only to users who attended an event).
While 63.6% of participants who were asked to deﬁne lan-
guage targeting correctly referenced the user’s primary lan-
guage, many of the 28.8% who incorrectly deﬁned it posed a
more involved, and potentially privacy-invasive, deﬁnition: “I
suppose that language targeting would be communicating in a
way that is targeted to how that speciﬁc person communicates.
For example, as a millennial I would want to see language that
is similar to how I speak rather than how someone who is my
parents age would speak” (P76). Platform targeting was sim-
ilarly misunderstood, with some participants believing that
this was the practice of targeting by social media platform
use or even political platform: “It looks at my list of people
I follow and sends me ads based on what they believe my
political stance is” (P147). We also found evidence, across
targeting types, of the belief that advertising is based on sur-
reptitious recordings of phone audio. For example, P231 said
of conversation targeting: “Given what I know about how
phone microphones are always on, I would guess that it’s
when ads pop up based on what I’ve said in a conversation.”
4.5 Participant Responses to Ad Explanations
We examined reactions to our ad explanations among the 193
participants who saw all six variants. Our approximation of
Twitter’s current explanation served as our primary basis of
comparison. We also report qualitative opinions about what
was memorable, perceived to be missing, or would be ideal.
4.5.1 Comparing Our Ad Explanations to Twitter’s
Overall, participants found explanations containing
more detail to be more useful, as shown in Figure 5. Unsur-
prisingly, Control was the least useful explanation; only 31.3%
of participants agreed it was useful. This is signiﬁcantly less
than our Twitter baseline, where 48.8% agreed (V = 6344.5,
156    29th USENIX Security Symposium
USENIX Association
Figure 5: Participants’ level of agreement to questions about ad explanations.
p < 0.001). The Facebook explanation was comparable to the
Twitter explanation (41.4% agreed; V = 3520.0, p = 0.154). In
contrast, the three explanations we designed were rated as sig-
niﬁcantly more useful than Twitter’s (V = 1352.5–2336.0, all
p < 0.001). Speciﬁcally, 63.6%, 71.2% and 78.6% of partici-
pants respectively agreed the Detailed Text, Detailed Visual,
and Creepy explanations were useful.
The usefulness ratings closely resembled responses to
whether the explanation provided “enough information to
understand how the ad was chosen for me." Again, Twitter
performed better than only Control (V: 5906.0, p < 0.001),
and did not signiﬁcantly diﬀer from Facebook (V = 4261.0,
p = 0.091). Participants agreed our explanations—Detailed
Text, Detailed Visual, Creepy—were most helpful in under-
standing how they were targeted; all three signiﬁcantly dif-
fered from Twitter (V = 1928.0–2878.0, all p ≤ 0.001).
We saw a diﬀerent trend for privacy concern: 77.2% of par-
ticipants agreed Creepy made them “more concerned about
my online privacy,” compared to 34.8% for Twitter, and just
28.2% for the Control. Privacy concern for Creepy was signif-
icantly higher than for Twitter (V = 989.5, p < 0.001). Both
Facebook and Detailed Text also exhibited signiﬁcantly more
concern than Twitter (V = 1821.0, 2835.0; p = 0.002, 0.015),
but to a lesser extent. Respondents reported comparable pri-
vacy concern for the Twitter explanation as for Detailed Visual
and Control (V = 2029.5, 3751.0, p = 0.080,0.064).
Transparency and usefulness generally did not trans-
late to increased trust in an advertiser. In fact, only a mi-
nority of participants agreed that they trusted the advertiser
more as a result of any provided ad explanation. Only the De-
tailed Visual explanation increased trust signiﬁcantly relative
to Twitter (V = 1695.5, p < 0.001).
A majority of participants agreed they would “want an ad
explanation similar to this one for all ads I see on Twitter" for
our Creepy (68.8%), Detailed Visual (64.4%), and Detailed
Text (54.9%) versions. Agreement for these was signiﬁcantly
larger (V = 1798.5–2132.0, all p < 0.001) than the 39.8%
who wanted Twitter-like. Participants signiﬁcantly preferred
Twitter to the Control (V = 6831.5, p < 0.001), but not to
Facebook (V = 4249.0, p = 0.339).
4.5.2 Qualitative Responses to Ad Explanations
Participants want detail and indicators of non-use. We
asked participants what they found most memorable about
each ad explanation. For Control, Facebook, and Twitter, most
memorable was how little detail they gave about how partici-
pants were targeted (30.7%, 21.6%, and 13.3% of participants,
respectively). By comparison, 16.3% (Detailed Text), 7.9%
(Visual), and 3.1% (Creepy) of participants noted a lack of
detail as the most memorable part. Conversely, 81.7% found
the amount of detail in Creepy to be the most memorable part,
followed by 61.2% for Visual. These ﬁndings may be because
Creepy included the most information and Detailed Visual
indicated which targeting types were not used.
Ambiguity was perceived as missing information. We
also asked participants what information, if any, they thought
was missing from each ad explanation. We wanted to help
participants identify what information could be missing, so
our within-subjects design featured randomly-shown variants
that demonstrated information that could be included. In line
with the quantitative results for usefulness, our Detailed Vi-
sual, Detailed Text, and Creepy explanations performed best,
with 61.2%, 58.9%, and 53.0% of participants, respectively,
answering nothing was missing. Conversely, Facebook, Con-
trol, and Twitter performed less well, with 69.2%, 67.3%, and
52.4%, respectively, of participants stating that some informa-
tion was missing or unclear. For Detailed Text and Detailed
Visual, among the most commonly noted missing information
related to our use of “may” and “might” about which criteria
actually were matched the participant. This was necessitated
by the ambiguity of the Twitter ﬁles (prior to receiving a
clariﬁcation from Twitter; see Section 3.6 for details). For
Facebook, the most commonly missing information was as-
sociated with the hashed tailored audience list: several wrote
that they did not know what a hashed list was. P125 wrote,
“The nature of the list mentioned should be clariﬁed in some
detail. It’s unfair to be put on a list without access to what the
list is and who compiled it and who has access to it.”
Describing their ideal Twitter ad explanation, 46.8% of
participants wanted to see the speciﬁc actions (e.g., what they
Tweeted or clicked on) or demographics that caused them to
see a given ad. 34.2% wanted to know more about how the
advertiser obtained their information. They also wanted clear
language (19.0%) and settings for controlling ads (13.4%).
USENIX Association
29th USENIX Security Symposium    157
ControlCreepyDetailed TextDetailed VisualFacebookTwitter0%25%50%75%100%Useful0%25%50%75%100%Understand How Targeted0%25%50%75%100%Concerned About Privacy0%25%50%75%100%Increased Trust0%25%50%75%100%Want SimilarStronglyagreeAgreeNeitherDisagreeStronglydisagree5 Discussion
We study Twitter’s targeted advertising mechanisms, which
categorize users by demographic and psychographic at-
tributes, as determined from information provided by the user,
provided by advertisers, or inferred by the platform. While
prior work has surfaced and studied user reactions to ad target-
ing as a whole [20, 70], or speciﬁc mechanisms like inferred
interests [17], our work details advertisers’ use of 30 unique
targeting types and investigates user perceptions into 16 of
them. These distinct types, including follower lookalikes
and tailored audiences, are rarely studied by the academic
community, but frequently used by advertisers (see Table 1).
Our participants expressed greater discomfort with some of
these less studied targeting types, highlighting a need for
future work.
We complement existing work on Facebook ad trans-
parency by investigating ad explanations on a diﬀerent plat-
form, Twitter, and using participants’ own Twitter data to
evaluate them. Strengthening prior qualitative work [20], we
quantitatively ﬁnd that our participants preferred ad expla-
nations with richer information than currently provided by
Facebook and Twitter. We also ﬁnd signiﬁcant user confusion
with “hashed” lists, a term introduced to ad explanations by
Facebook in 2019 [55] to explain how platforms match user
data to information on advertiser-uploaded lists for tailored
audience targeting (called custom audiences on Facebook).
Can sensitive targeting be prohibited in practice? We
ﬁnd several instances of ad targeting that appear to violate
Twitter’s stated policy prohibiting targeting on sensitive at-
tributes. Such targeting is often considered distasteful and in
some cases may even be illegal. We observed these instances
most commonly in targeting types where advertisers provide
critical information: keywords (where advertisers can pro-
vide any keyword of choice, subject to Twitter acceptance)
and variations of tailored audiences, where the advertiser
provides the list of users to target. Potentially discriminatory
keywords are a problem that Twitter could theoretically solve
given a suﬃciently accurate detection algorithm or (more
likely) manual review. Tailored audiences, however, are more
pernicious. Advertisers can use any criteria to generate a list.
We were only able to identify potentially problematic cases
because the list name, which is under advertiser control, hap-
pened to be meaningfully descriptive. It would be trivial for an
advertiser to name a list generically to skirt scrutiny, calling
into question whether Twitter’s policy on sensitive attributes
has (or can have) any real force in practice. It also raises larger
concerns about regulating potentially illegal or discriminatory
practices as long as tailored audiences remain available.
More accuracy, fewer problems? Similarly to prior work,
we found that the perceived inaccuracy of targeting instances
correlates with users having less desire for such targeting
to be used for them [14, 17]. This has potentially danger-
ous implications. If accuracy reduces discomfort, this may
appear to justify increasing invasions of privacy to obtain ever-
more-precise labels for users. However, participants’ free-text
responses indicate an upper bound where increasing accu-
racy is no longer comfortable. For example, P220 noted that
a speciﬁc instance of location targeting was “very accurate,
. . . but I don’t really like how they are able to do that without
my knowledge and even show me ad content related to my
location, because I choose not to put my speciﬁc location on
my Twitter account in any way for a reason.” Future work
should investigate how and when accuracy crosses the line
from useful to creepy.
Transparency: A long way to go. This work also con-
tributes a deeper understanding of ad explanations, amid sub-
stantial ongoing work on transparency as perhaps the only
way for the general public to scrutinize the associated costs
and beneﬁts. Participants found our ad explanations, which
provide more details, signiﬁcantly more useful, understand-
able, and desirable than currently deployed ad explanations
from Twitter and Facebook. However, our results also high-
light a signiﬁcant challenge for transparency: platform and
advertiser incentives. Some of our proposed explanations, de-
spite being more useful, decreased participant trust in the
advertiser, which clearly presents a conﬂict of interest. This
conﬂict may explain why currently deployed explanations are
less complete or informative than they could be.
Finally, our results suggest it is insuﬃcient to simply re-
quire data processing companies to make information avail-
able. While the option to download advertising data is a strong
ﬁrst step, key aspects of the ad ecosystem — such as the ori-
gins of most targeting information — remain opaque. In addi-
tion, even as researchers with signiﬁcant expertise, we strug-
gled to understand the data Twitter provided (see Section 3.6).
This creates doubt that casual users can meaningfully under-
stand and evaluate the information they receive. However, our
participants indicated in free response answers that they found
the transparency information provided in our study useful and
that it illuminated aspects of tracking they had not previously
understood, making it clear that comprehensible transparency
has value. We therefore argue that transparency regulations
should mandate that raw data ﬁles be accompanied by clear
descriptions of their contents, and researchers should develop
tools and visualizations to make this raw data meaningful to
users who want to explore it.
Acknowledgments
We gratefully acknowledge support from the Data Trans-
parency Lab and Mozilla, as well as from a UMIACS contract
under the partnership between the University of Maryland
and DoD. The views expressed are our own.
158    29th USENIX Security Symposium
USENIX Association
References
[1] Online appendix.
https://www.blaseur.com/
papers/usenix20twitterappendix.pdf.
[2] Gunes Acar, Christian Eubank, Steven Englehardt, Marc
Juarez, Arvind Narayanan, and Claudia Diaz. The Web
Never Forgets: Persistent Tracking Mechanisms in the
Wild. In Proc. CCS, 2014.
[3] Lalit Agarwal, Nisheeth Shrivastava, Sharad Jaiswal, and
Saurabh Panjwani. Do Not Embarrass: Re-Examining
User Concerns for Online Tracking and Advertising. In
Proc. SOUPS, 2013.
[4] Muhammad Ali, Piotr Sapiezynski, Miranda Bogen,
Aleksandra Korolova, Alan Mislove, and Aaron Rieke.
Discrimination Through Optimization: How Facebook’s
Ad Delivery Can Lead to Skewed Outcomes. In Proc.
CSCW, 2019.
[5] Hazim Almuhimedi, Florian Schaub, Norman Sadeh,
Idris Adjerid, Alessandro Acquisti, Joshua Gluck, Lorrie
Cranor, and Yuvraj Agarwal. Your Location has been
Shared 5,398 Times! A Field Study on Mobile App
Privacy Nudging. In Proc. CHI, 2015.
[6] Athanasios Andreou, Márcio Silva, Fabrício Ben-
evenuto, Oana Goga, Patrick Loiseau, and Alan Mislove.
Measuring the Facebook Advertising Ecosystem.
In
Proc. NDSS, 2019.
[7] Athanasios Andreou, Giridhari Venkatadri, Oana Goga,
Krishna P. Gummadi, Patrick Loiseau, and Alan Mislove.
Investigating Ad Transparency Mechanisms in Social
Media: A Case Study of Facebook’s Explanations. In
Proc. NDSS, 2018.
[8] Julia Angwin and Terry Parris. Facebook Lets Adver-
tisers Exclude Users by Race. ProPublica, October 28,
2016.
More Relevant Ads with Tailored
[9] @ashrivas.
Audiences.
Twitter Blog, December 2013.
https://blog.twitter.com/marketing/en_us/
a/2013/more-relevant-ads-with-tailored-
audiences.html.
[10] Rebecca Balebako, Pedro Leon, Richard Shay, Blase Ur,
Yang Wang, and Lorrie Faith Cranor. Measuring the
Eﬀectiveness of Privacy Tools for Limiting Behavioral
Advertising. In Proc. W2SP, 2012.
[11] Muhammad Ahmad Bashir, Sajjad Arshad, and William
Robertson. Tracing Information Flows Between Ad
Exchanges Using Retargeted Ads. In Proc. USENIX