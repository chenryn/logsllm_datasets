87:99
678:988
102:89
333:127
1.4 × 10−6 s
Table 3: Baseline comparison on preparation time.
Firmware Image
DD-WRT r21676 (MIPS)
ReadyNAS v6.1.6 (ARM)
Binaries
143 (142)
1,510 (1,463)
Basic Blocks Multi-MH Multi-k-MH discovRE Genius Centroid
329,220
2,927,857
9,419
83,766
616
5,475
2.1
54.1
Preparation Time in Minutes
4.9
89.7
3.2
69.6
ing, the codebook size, the size of training data for codebook gen-
eration, and the feature encoding methods. All evaluation settings
were conducted on Dataset I.
A. Distance metrics and structural features. To verify the contri-
bution of the proposed structural features, we conducted bipartite
graph matching experiments with and without structural features.
As shown in Fig. 6a), the matching with structural features out-
performs the matching without it. Besides, we also evaluated two
distance metrics used in the LSH. Results show that the cosine dis-
tance performs better than the Euclidean distance.
B. Codebook sizes. We created codebooks of different sizes and
studies their search accuracy. We evaluated the accuracy in terms
of the recall rate at two representative false positive rates. Fig. 6b)
illustrates the results for the codebooks of 16, 32, 64, and 128 cen-
troids. We can see that the codebook size seems not having a signif-
icant inﬂuence on the accuracy of Genius. This result provides an
insight that allow us to reduce codebook preparation time by using
a smaller codebook n = 16.
C. Training data sizes. Another important parameter is the size
of training set used to generate codebook. We selected training
data samples of different sizes to generate the codebook for search.
Fig. 6c) shows their search results. We can see that the more sam-
ples used for training, the better Genius performed, but the in-
crease in accuracy becomes saturated when the training data is suf-
ﬁciently large, in our case up to 100 thousand functions. This is
consistent with observations from image retrieval methods.
D. Feature encoding methods. We discussed two feature encod-
ing methods in Section 4.2: bag-of-feature and VLAD encoding.
We compared their impacts on the search accuracy while ﬁxing
other parameters. Fig. 6d) illustrates the ROC curves using two
encoding methods. As we can see, VALD performs better than
Bag-of-Feature encoding. This observation suggests considering
the ﬁrst-order statistics is beneﬁcial for bug search problem. As the
computational cost is similar between VALD and bag-of-features,
we recommend using VALD feature encoding in practice.
5.5 Bug Search at Scale
We evaluated the scalability of Genius on Dataset III, which
consists of 8,126 ﬁrmware images containing 420,336,846 func-
tions, in terms of the preparation phase and search phase. We in-
vestigated the time consumption for each stage to demonstrate that
Genius is capable of handling ﬁrmware images at a large scale.
We encoded 1 million functions randomly selected from Dataset
III and collected the preparation time for each of them. The prepa-
ration time included the control ﬂow graph extraction and graph
Figure 5: The CDFs of search time on Dataset I.
is an ofﬂine stage and only an one-time effort, it is reasonable to
sacriﬁce some preparation time for the online search efﬁciency.
Online Search Efﬁciency. Similar to the accuracy comparison dis-
cussed above, we evaluated the online search efﬁciency on Dataset
I and II, respectively. We ﬁrst conducted the search on Dataset I,
searched all of the functions in the dataset and recorded their search
times for each target approach. Fig. 5 lists the Cumulative distri-
bution function (CDFs) of search time for the four approaches on
Dataset I, where the x-axis plots the search time in seconds. We
can see that Genius and the centroid-based approach have least
search time. DiscovRe, on the other hand, has the longest search
time because it requires expensive online graph matching. In the
best case, discovRe takes 10 ms for a query, whereas Genius only
requires 0.1 ms to return more accurate results. Unsurprisingly, we
also found that the version of discovRe without pre-ﬁltering has
even worse performance. It required nearly 2 hours for a single
query in the worst case, and was still less accurate than Genius.
Although the centroid approach had comparable efﬁciency with
Genius, as previously mentioned, centroid signiﬁcantly under-
performs Genius in terms of the accuracy.
We also conducted a second round evaluation on Dataset II for all
baseline approaches. We utilized the search time for the Heartbleed
vulnerability as the metric. Table 2 lists the search results. It shows
that Genius is orders of magnitude faster than Multi-MH, Multi-
k-MH and discovRE. This demonstrates that Genius outperforms
most of the existing methods in terms of efﬁciency.
5.4 Parameter Studies
We systematically studied the parameter’s impact on the accu-
racy of Genius under different settings. The parameters for evalu-
ation included the structural features used in bipartite graph match-
10-410-2100102104Search time in seconds00.20.40.60.81Percentage of # functionsDiscovRe without prefilteringDiscovReCentroidG(cid:72)(cid:81)(cid:76)(cid:88)(cid:86)487(a) Distance metrics and structural features
(b) Codebook sizes
(c) Training set size
(d) Feature encoding
Figure 6: Accuracy comparison with different parameter settings. a), c) and d) are ROC curves
encoding time. Fig. 10a) demonstrates the Cumulative Distribution
Function (CDF) of time consumption for randomly selected 1 mil-
lion query functions. We can see that nearly 90% of the functions
were encoded in less than 0.1 seconds. Additionally, less than 10%
of the functions needed more than 4 seconds to encode. This is be-
cause these functions have more than 1000 basic blocks, and thus
take longer to encode. The prepartion time across different sizes of
ACGFs is illustrated in Fig. 10b).
We further evaluated the search time for Genius in the large
scale codebase. We partitioned Dataset III into six codebases of
different scales from s = 103 to s = 108, where s is the total
number of functions in the codebase. Genius was tested against 1
to 10,000 sequentially submitted queries. Fig. 10c) shows the log-
log plot of the time consumption for Genius at the online search
phase. As we can see, the search time grows sublinearly according
to the increase of the codebase size, and the average search time
over observed was less than 1 second for a ﬁrmware codebase of
about 100 million functions.
5.6 Case Studies
We also evaluated the efﬁcacy of Genius in real bug search
scenarios. Case studies were conducted on Genius for the two
use scenarios discussed in Section 2. With the aid of case studies,
we demonstrated how Genius would work in the real world to
facilitate the vulnerability identiﬁcation process.
Scenario I. In this scenario, we conducted a vulnerability search on
Dataset III of 8,126 images using vulnerability queries extracted
from Dataset IV. We performed a comprehensive search for two
vulnerabilities (CVE-2015-1791 and CVE-2014-3508), which took
less than 3 seconds. We then manually veriﬁed the vulnerability
authenticity for the returned candidate functions. We disassembled
the binary code for each candidate, and looked into their seman-
tics to check whether they were patched or not. Due to the work-
load of manual analysis, we only veriﬁed the top 50 candidates for
the two selected vulnerabilities. We found 38 potentially vulnera-
ble ﬁrmware devices across 5 vendors, and conﬁrmed that 23 were
actually vulnerable. We also contacted these product vendors for
further conﬁrmation. The following gives the detailed discussion
about search results.
CVE-2015-1791. This vulnerability allows remote attackers to
cause a denial of service (double free and application crash) on
the device. In the top 50 candidates, we found that there were 14
ﬁrmware images potentially affected by this vulnerability. We were
able to conﬁrm that 10 of these images were actually vulnerable.
These images were from two vendors: D-LINK and Belkin.
CVE-2014-3508. This vulnerability allows context-dependent
attackers to obtain sensitive information from process stack mem-
ory by reading the output of sensitive functions. We found that
there were 24 ﬁrmware images which could have this vulnerability,
and we were able to conﬁrm that the vulnerabilities existed in 13
images from three vendors. These vendors included CenturyLink,
D-Link and Actiontec.
This clearly demonstrated that a security evaluator, after only 3
seconds, could get a list of candidate functions to prioritize their
search for vulnerable device ﬁrmware.
Scenario II. We chose the two latest commercial ﬁrmware images
from D-Link DIR-810 model as our evaluation targets. We built
the LSH indexes for these two ﬁrmware images and then searched
those two images for all 185 vulnerabilities from Dataset IV (dis-
cussed in Section 5.2).
It took less than 0.1 second on average
to ﬁnish searching for all 154 vulnerabilities. We conducted man-
ual veriﬁcation at the top 100 candidates for each vulnerability and
found 103 potential vulnerabilities in total for two images, 16 of
(cid:19)(cid:19)(cid:17)(cid:21)(cid:19)(cid:17)(cid:23)(cid:19)(cid:17)(cid:25)(cid:19)(cid:17)(cid:27)(cid:20)False postive rate(cid:19)(cid:19)(cid:17)(cid:21)(cid:19)(cid:17)(cid:23)(cid:19)(cid:17)(cid:25)(cid:19)(cid:17)(cid:27)(cid:20)True positive rate(cid:42)(cid:72)(cid:81)(cid:76)(cid:88)(cid:86)(cid:11)(cid:40)(cid:88)(cid:70)(cid:79)(cid:76)(cid:71)(cid:72)(cid:68)n(cid:12)(cid:42)(cid:72)(cid:81)(cid:76)(cid:88)(cid:86)(cid:11)C(cid:82)(cid:86)(cid:76)(cid:81)(cid:72)(cid:12)(cid:37)(cid:42)(cid:48)(cid:3)(cid:90)(cid:18)(cid:82)(cid:3)(cid:54)(cid:87)(cid:85)(cid:88)(cid:70)(cid:87)(cid:41)(cid:37)(cid:42)(cid:48)(cid:3)(cid:90)(cid:18)(cid:17)(cid:3)(cid:54)(cid:87)(cid:85)(cid:88)(cid:70)(cid:87)(cid:41)(cid:3)1632641280.650.70.750.80.850.9Codebook SizeRecallRecall@FPR(0.075)Recall@FPR(0.110)00.10.20.30.40.50.60.70.80.9100.20.40.60.81Flase Positive RateTrue Positive RateTraining Set 4KTraining Set 20KTraining Set 100K00.20.40.60.8100.20.40.60.81False Positive RateTrue Positive RateVALD EncodingBag−of−Feature Encoding488Figure 7: The CDF of preparation
time over#1 million functions
Figure 8: The preparation time cross
different size of CFG
Figure 9: The search time crossscales of
ﬁmware codebases(# of funcitons
Figure 10: The breakdown of the performance for Genius.
Table 4: Case study results for Scenario II
DIR-810L_REVB_FIRMWARE_2.03B02
Patched Vulnerability Type
DIR-810L_REVB_FIRMWARE_2.02.B01
Patched Vulnerability Type
Memory consumption
Heartbleed
NULL pointer dereference
Heap memory corruption
Memory consumption
Memory consumption
Information leakage
Memory consumption
Missing sanitation check
CVE
CVE-2016-0703 No
CVE-2015-1790 No
CVE-2015-1791 Yes
CVE-2015-0289 No
CVE-2014-8275 No
CVE-2015-0209 No
CVE-2015-3195 No
#
#
#
#
Allows man-in-the-middle attack
NULL pointer dereference
Double free
NULL pointer dereference
Missing sanitation check
Use-after-free
Mishandles errors
#
#
CVE
CVE-2015-0206 No
CVE-2014-0160 Yes
CVE-2015-0289 No
CVE-2016-0797 No
CVE-2016-0798 No
CVE-2014-3513 No
CVE-2014-3508 No
CVE-2015-0206 No
CVE-2014-8275 No
which were conﬁrmed (see Table 4). We contacted the product
vendor for further conﬁrmation.
Overall, these two case studies substantiate that Genius is an
effective tool to facilitate IoT ﬁrmware bug searching process for
security evaluators.
6. DISCUSSION
While we have demonstrated the efﬁcacy of Genius for accu-
rate, scalable bug search in IoT devices, there are several relevant
technical limitations. Our method utilizes static analysis to extract
syntactical features, and thus cannot handle obfuscated code which
is used to avoid similarity detection (e.g., malware).
Additionally, the accuracy of Genius heavily relies on the qual-
ity of CFG extraction. Although IDA pro [28] provides us rea-
sonable accuracy in our evaluation, we can rely on more advanced
techniques to further improve its accuracy such as [51].
Furthermore, the accuracy of Genius could be impacted by
function inlining, since it may change the CFG structures. Since
our main focus in this paper is to improve the scalability of existing
in-depth bug search, we will leave the evaluation of Genius for
this case as future work.
Like other CFG-based code search approaches, the accuracy of
Genius is also affected by the size of the CFG. The smaller the
size of CFG is, the more likely it is to have collisions. To be aligned
with other work [23], we also considered functions with at least
ﬁve basic blocks. We believe that this is a reasonable assumption
since small functions have signiﬁcantly lower chance to contain
vulnerabilities in a real-world scenario [37].
7. RELATED WORK
We have discussed closely related work throughout the paper. In
this section, we brieﬂy survey additional related work. We focus on
approaches using code similarity to search for known bugs. There
are many other approaches that aim at ﬁnding unknown bugs, such
as fuzzing or symbolic execution [11, 15, 17, 48, 52, 55] etc. Since
they are orthogonal to our approach, we will not discuss these ap-
proaches in this section.
Source-Level Bug Search. Many works focused on ﬁnding code
clones at the source code level. For example, [58] generates a code
property graph from the source code and conducts a graph query
to search for code clones with the same pattern. Similarly, token-
based approaches such as CCFinder [33] and CP-Miner [35] utilize
token sequence and scan for duplicate token sequences in other
source code. DECKARD [18] generates numerical vectors based
upon abstract syntax trees and conducts code similarity matching
for code clone detection. ReDeBug [29] provides an efﬁcient and
scalable search to ﬁnd unpatched code clones in OS-distribution
bases. All of these approaches require source code, and cannot ﬁnd
bugs in ﬁrmware images unless the source code is available.
Binary-Level Bug Search. Since we do not always have access
to ﬁrmware source code, bug search techniques that work on bi-
nary code are very important. One common issue with the current
approaches is that they only support a single architecture. It is com-
mon that bugs from ﬁrmware images in x86 can appear in images
of another architecture such as MIPS or ARM, so ﬁnding bugs in