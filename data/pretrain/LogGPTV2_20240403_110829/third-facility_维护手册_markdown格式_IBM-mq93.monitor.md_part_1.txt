9.3
Monitoring and Performance for IBM MQ
IBM
Note
Before using this information and the product it supports, read the information in “Notices” on page
385.
This edition applies to version 9 release 3 of IBM® MQ and to all subsequent releases and modifications until otherwise
indicated in new editions.
When you send information to IBM, you grant IBM a nonexclusive right to use or distribute the information in any way it
believes appropriate without incurring any obligation to you.
© Copyright International Business Machines Corporation 2007, 2023.
US Government Users Restricted Rights – Use, duplication or disclosure restricted by GSA ADP Schedule Contract with
IBM Corp.
Contents
Monitoring and performance..................................................................................5
Monitoring your IBM MQ network................................................................................................................5
Queue manager health check behavior.................................................................................................5
Event monitoring....................................................................................................................................8
Message monitoring.............................................................................................................................58
Accounting and statistics messages..................................................................................................136
Application activity trace...................................................................................................................202
System topics for monitoring and activity trace................................................................................287
Monitoring the IBM MQ Bridge to Salesforce....................................................................................296
Real-time monitoring.........................................................................................................................299
Monitoring clusters............................................................................................................................311
Monitoring application balancing......................................................................................................314
Monitoring performance and resource usage on z/OS......................................................................317
Tuning your IBM MQ network..................................................................................................................372
Tuning client and server connection channels..................................................................................372
Tuning distributed publish/subscribe networks................................................................................373
Reducing the number of unwanted topics in the topic tree..............................................................382
Aspera gateway can improve performance over high latency networks..........................................384
Notices..............................................................................................................385
Programming interface information........................................................................................................386
Trademarks..............................................................................................................................................386
iii
iv
IBM MQ Monitoring and performance
Use the monitoring information and guidance in this section, and the specific tuning tips, to help improve
the performance of your queue manager network.
About this task
Depending on the size and complexity of your queue manager network, you can obtain a range of
information from monitoring the network. You can use that information, along with the information
provided in specific tuning tips, to help you tune your network performance.
Monitoring your IBM MQ network
A number of monitoring techniques are available in IBM MQ to obtain statistics and other specific
information about how your queue manager network is running. Use the monitoring information and
guidance in this section to help improve the performance of your queue manager network.
The following list provides examples of reasons for monitoring your queue manager network:
• Detect problems in your queue manager network.
• Assist in determining the causes of problems in your queue manager network.
• Improve the efficiency of your queue manager network.
• Familiarize yourself with the running of your queue manager network.
• Confirm that your queue manager network is running correctly.
• Generate messages when certain events occur.
• Record message activity.
• Determine the last known location of a message.
• Check various statistics of a queue manager network in real time.
• Generate an audit trail.
• Account for application resource usage.
• Capacity planning.
Queue manager health check behavior
The queue manager carries out periodic health checks to ensure stable and reliable performance. This
topic describes some of the health checks that the queue manager makes and explains how they can be
configured based on environmental requirements.
In most environments, the default configuration is suitable and there is no need to change how frequently
these checks are made. Even using the default settings, it can be useful to understand how the queue
manager behaves when a problem is detected and the environmental problems that might cause a check
to fail. This topic is intended to explain some of those behaviors.
The different components of the queue manager use various means to detect and resolve inconsistencies
and this topic is not intended to describe all such mechanisms. For example, IBM MQ processes use
various mechanisms to ensure that other processes that they depend on are still running. The behaviors
that are described are those behaviors that are made periodically by the execution controller to spot
environmental or other unexpected situations. (The execution controller is the primary IBM MQ process
that starts and manages most other queue manager processes.) Because they are periodic checks, they
are made at specific intervals that can be modified to some extent by setting the appropriate tuning
parameters.
© Copyright IBM Corp. 2007, 2023 5
Some of the checks that are described are made by a dedicated health checking thread. If a problem
is detected with the health checking thread itself, a warning message AMQ5066 is written to the queue
manager error logs.
The behaviors that are described in this topic are subject to change in future releases, for example if a
different default value is observed to be more stable on a particular platform or configuration.
General health checks
The queue manager performs a variety of checks on a regular interval. By default, these checks are
performed every 10 seconds (in some cases, the check allows two cycles before reporting an error,
resulting in a 20-second interval for such checks). During the checks, the queue manager makes sure
that the various processes that run as part of the queue manager are still running. For a Native HA queue
manager, it checks that the queue manager is successfully replicating data to the standby instances.
If a critical check fails at this time (for example, if the amqzmuc0 process is no longer running) the queue
manager will be unable to continue running. However, most of the checks are made to tidy up system
resources that are no longer needed and might simply result in a message being written to the queue
manager error logs.
In most cases, it is not necessary to change the frequency of these general health checks. The majority
of events in the queue manager or in the operating environment are detected instantly without the
need for the general health check process to detect them. This process serves as a periodic check for
anything not detected elsewhere in the queue manager. If necessary, the frequency can be configured
using the ECHeartBeatLen tuning parameter. The minimum value is 10000 milliseconds (10 seconds).
The maximum value is 60000 milliseconds (60 seconds). If set to its maximum value of 60000, this might
result in a two-minute delay for certain checks.
Checks that log progress is being made
The queue manager checks that writes to the log are being made at a reasonable rate. This is not a
check that performance of the logger is optimal but is designed to spot conditions that might need further
attention. For example, if the disk that the log files are being stored on is particularly slow, or if the queue
manager is not receiving sufficient CPU time in a containerized environment to perform all of its work.
If this check fails, the action taken by the queue manager depends on the type of queue manager being
used:
• On a non-HA queue manager:
– An xecL_W_PERFORMANCE_BOTTLENECK FDC is written. This can be used as an indication that
some part of the system might need further attention. The queue manager remains running. If
xecL_W_PERFORMANCE_BOTTLENECK FDCs are seen in the errors directory, it might be necessary
to work with your storage or platform team to understand if the underlying system resources are
sufficient for IBM MQ to run. If IBM MQ is being run in containers on over-committed nodes then IBM
MQ might not receive enough scheduled CPU time to perform all of its messaging workload.
– From IBM MQ 9.3.0, a warning message AMQ5068W is written to the queue manager
error logs and no xecL_W_PERFORMANCE_BOTTLENECK FDC is written. If AMQ5068W messages are
seen in the logs, it might be necessary to work with your storage or platform team to understand if
the underlying system resources are sufficient for IBM MQ to run. If IBM MQ is being run in containers
on over-committed nodes then IBM MQ might not receive enough scheduled CPU time to perform
all of its messaging workload. If five AMQ5068W warning messages are written in succession, an
xecL_W_PERFORMANCE_BOTTLENECK FDC is written.
• On a multi-instance queue manager:
– If the log progress health check fails then the primary instance ends. If a standby instance is
available it will start and become the primary instance.
6 Monitoring and Performance for IBM MQ
– From IBM MQ 9.3.0, the primary instance checks if a standby instance is available
before ending. If a standby queue manager is available to fail over to the primary instance ends.
Additionally a warning message AMQ5068W is written to the queue manager error logs.
• On a Native HA queue manager, this check behaves in the same way as a non-HA queue manager.
• On an RDQM (replicated data queue manager), this check behaves in the same way as a non-HA queue
manager.
It is possible that a problem with the progression of the IBM MQ log is caused by a performance issue in
the queue manager itself.
By default this check is made every 60 seconds, although the queue manager waits for two cycles of the
check before taking an action. This means that with the default settings, two minutes would have to pass
before the queue manager wrote an error message (or failed over in the case of an HA queue manager).
In most cases, the default behavior is suitable even where the file system is slow or the queue manager
is allocated a small amount of CPU time because other checks such as file locking (see “Checks that
file locks are still held” on page 7) and basic file system operation will cause a primary instance to
failover before this check is made. If necessary, the frequency of this check can be configured using
the LivenessHeartBeatLen tuning parameter. The maximum value that it can be configured to is 600
seconds (10 minutes). The minimum value of 0 has the effect of disabling the check altogether. For a
non-HA queue manager, the only effect of the check is an extra warning message in the queue manager
error logs. For a multi-instance queue manager, you can configure the LivenessHeartBeatLen to cause
a primary instance of the queue manager to fail over more quickly (by reducing the value) or slowly
(by increasing the value). Increasing the value to reduce the frequency of the log progress check can
be useful if your environment occasionally experiences very slow file system IO but where you would
prefer the primary instance of the queue manager to remain running. This might be useful if you have
applications that are not designed to automatically reconnect to the standby instance and require manual
intervention to restart them.
Note: If the ECHeartBeatLen has been increased, this affects the timing of the
LivenessHeartBeatLen checks. Log progress checks are made when the general health checks are
performed so reducing the frequency of the general health checks (ECHeartBeatLen) might result in log
progress checks being made up to a 30 seconds after the configured LivenessHeartBeatLen.
Checks that file locks are still held
For a multi-instance queue manager, the execution controller periodically checks to make sure that it
still holds the exclusive lock on the primary multi-instance file. In many cases, if the lock is lost due to
a problem with the NFS server the primary instance fails over almost immediately (before this check is
made). Additional periodic file lock checks are made to ensure that the primary queue manager fails over
in the event of an unusual file system problem.
By default, these file lock checks are made every 20 seconds. If necessary, this value can be changed
by setting the FileLockHeartBeatLen tuning parameter. The default value for the tuning parameter
is 10 seconds (the queue manager allows two cycles of the check before taking an action resulting in
the default behavior of checking every 20 seconds). The minimum value of the tuning parameter is 10
seconds, the maximum value is 600 seconds (10 minutes).
Note: If the ECHeartBeatLen has been increased, this affects the timing of the
FileLockHeartBeatLen checks. File lock checks are made when the general health checks are
performed so reducing the frequency of the general health checks (ECHeartBeatLen) might result in
file lock checks being made up to 30 seconds after the configured FileLockHeartBeatLen.
Checks on user application health
The queue manager periodically checks that any locally bound applications that are no longer running
have performed an MQDISC MQI call before terminating. These checks are performed at the same time as
the general health checks described in “General health checks” on page 6. The default interval for such
checks is therefore 10000 milliseconds (10 seconds) and changing the value of the ECHeartBeatLen
tuning parameter changes the frequency at which they are made. This check is primarily to ensure any
IBM MQ Monitoring and performance 7
resources that are associated with an application connected are freed, it does not cause an HA or a
non-HA queue manager to end or to fail over to an alternative instance.
IBM MQ client applications that have terminated without issuing an MQDISC MQI call are separately
detected by the agent process and any resources associated with the connection are released.
Related concepts
High availability configurations
Event monitoring
Event monitoring is the process of detecting occurrences of instrumentation events in a queue manager
network. An instrumentation event is a logical combination of events that is detected by a queue manager
or channel instance. Such an event causes the queue manager or channel instance to put a special
message, called an event message, on an event queue.
IBM MQ instrumentation events provide information about errors, warnings, and other significant
occurrences in a queue manager. Use these events to monitor the operation of the queue managers
in your queue manager network to achieve the following goals:
• Detect problems in your queue manager network.
• Assist in determining the causes of problems in your queue manager network.
• Generate an audit trail.
• React to queue manager state changes
Related reference
“Event types” on page 11
Use this page to view the types of instrumentation event that a queue manager or channel instance can
report
Event message reference
Event message format
Publishing your IBM MQ event messages
How you prepare IBM MQ to publish event messages.
About this task
Event messages are written to specially named queues called SYSTEM.ADMIN..EVENT.
The important thing to note about these event queues is that it is the name that matters. By default, on
a queue manager, all event queues are defined as local queues. However, you can delete these queues
and redefine them, perhaps as a remote queue, so that all events are funneled to a dedicated event
processing queue manager. Alternatively, you can use an alias queue that is pointing at a topic object.
In either case, any redirection technique requires that your applications reading the event queues have
not hard-coded the name of the queue to read from. Therefore, you must be able to configure the queue
the applications are reading from.
The following commands show how you can redefine your event queues so that the event messages will
be published, using the following assumptions. You have:
• Not started using events, or
• Removed all the messages from the existing event queues and have deleted the local queues prior to
these steps.
These steps only show the QMGR and CHANNEL event queues being redefined, but this could be
extended for all events.
8 Monitoring and Performance for IBM MQ
Note: The topic string is designed so that an application can be subscribed to all events using a wildcard,
or to specific events, as required.
Procedure
Issue the following commands:
DEFINE TOPIC(ADMIN.QMGR.EVENT) TOPICSTR('Events/QMgr')
DEFINE TOPIC(ADMIN.CHANNEL.EVENT) TOPICSTR('Events/Channel')
DEFINE QALIAS(SYSTEM.ADMIN.QMGR.EVENT) TARGTYPE(TOPIC) TARGET(ADMIN.QMGR.EVENT)
DEFINE QALIAS(SYSTEM.ADMIN.CHANNEL.EVENT) TARGTYPE(TOPIC) TARGET(ADMIN.CHANNEL.EVENT)
DEFINE QLOCAL(ADMIN.EVENT)
DEFINE QLOCAL(ADMIN.QMGR.EVENT)
DEFINE SUB(EVENTS.ALL) TOPICSTR('Events/+') PSPROP(NONE)
DESTCLAS(PROVIDED) DEST(ADMIN.EVENT)
DEFINE SUB(EVENTS.QMGR) TOPICSTR('Events/QMgr') PSPROP(NONE)
DESTCLAS(PROVIDED) DEST(ADMIN.QMGR.EVENT)
Assuming that your event reading application is able to read event messages from any queue, that
application can be reconfigured to read from one of the queues defined above as required.
The PSPROP(NONE) configuration on the DEFINE SUB commands is to ensure that none of the message
properties added by the publish/subscribe engine, for example MQTopicString, is added to the event
message, ensuring that existing applications can continue to work unchanged.
Additionally, applications can also subscribe directly using the MQSUB call to receive the information, as
an alternate way instead of using the administrative DEFINE SUB command.
Now, multiple applications are able to consume the information emitted in events by the queue manager.
Instrumentation events
An instrumentation event is a logical combination of conditions that a queue manager or channel instance
detects and puts a special message, called an event message, on an event queue.
IBM MQ instrumentation events provide information about errors, warnings, and other significant
occurrences in a queue manager. You can use these events to monitor the operation of queue managers
(with other methods such as Tivoli® NetView® for z/OS® ).
Figure 1 on page 10 illustrates the concept of instrumentation events.
IBM MQ Monitoring and performance 9
Figure 1. Understanding instrumentation events
Event monitoring applications
Applications that use events to monitor queue managers must include the following provisions:
1.Set up channels between the queue managers in your network.
10 Monitoring and Performance for IBM MQ
2.Implement the required data conversions. The normal rules of data conversion apply. For example, if
you are monitoring events on an UNIX system queue manager from a z/OS queue manager, ensure that
you convert EBCDIC to ASCII.
Event notification through event queues
When an event occurs, the queue manager puts an event message on the appropriate event queue,
if defined. The event message contains information about the event that you can retrieve by writing a
suitable MQI application program that performs the following steps:
• Get the message from the queue.
• Process the message to extract the event data.
The related information describes the format of event messages.
Conditions that cause events
The following list gives examples of conditions that can cause instrumentation events:
• A threshold limit for the number of messages on a queue is reached.
• A channel instance is started or stopped.
• A queue manager becomes active, or is requested to stop.
• An application tries to open a queue specifying a user ID that is not authorized on IBM MQ for IBM i,
AIX®, Linux®, and Windows systems.
• Objects are created, deleted, changed, or refreshed.
• An MQSC or PCF command runs successfully.
• A queue manager starts writing to a new log extent.
• Putting a message on the dead-letter queue, if the event conditions are met.
Related concepts
“Performance events” on page 23
Performance events relate to conditions that can affect the performance of applications that use a
specified queue. The scope of performance events is the queue. MQPUT calls and MQGET calls on one
queue do not affect the generation of performance events on another queue.
“Sample program to monitor instrumentation events on Multiplatforms” on page 55
amqsevt formats the instrumentation events that a queue manager can create, and is supplied with IBM
MQ for Multiplatforms. The program reads messages from event queues, and formats them into readable
strings.
Event types
Use this page to view the types of instrumentation event that a queue manager or channel instance can
report
IBM MQ instrumentation events have the following types:
• Queue manager events
• Channel and bridge events
• Performance events
• Configuration events
• Command events
• Logger events
• Local events
For each queue manager, each category of event has its own event queue. All events in that category
result in an event message being put onto the same queue.
IBM MQ Monitoring and performance 11
This event queue: Contains messages from:
SYSTEM.ADMIN.QMGR.EVENT Queue manager events
SYSTEM.ADMIN.CHANNEL.EVENT Channel events
SYSTEM.ADMIN.PERFM.EVENT Performance events
SYSTEM.ADMIN.CONFIG.EVENT Configuration events
SYSTEM.ADMIN.COMMAND.EVENT Command events
SYSTEM.ADMIN.LOGGER.EVENT Logger events
SYSTEM.ADMIN.PUBSUB.EVENT Gets events related to Publish/Subscribe. Only
used with Multicast. For more information see,
Multicast application monitoring.
By incorporating instrumentation events into your own system management application, you can monitor
the activities across many queue managers, across many different nodes, and for multiple IBM MQ
applications. In particular, you can monitor all the nodes in your system from a single node (for those
nodes that support IBM MQ events) as shown inFigure 2 on page 12.
Instrumentation events can be reported through a user-written reporting mechanism to an administration
application that can present the events to an operator.
Figure 2. Monitoring queue managers across different platforms, on a single node
Instrumentation events also enable applications acting as agents for other administration networks, for
example Tivoli NetView for z/OS, to monitor reports and create the appropriate alerts.
Queue manager events
Queue manager events are related to the use of resources within queue managers. For example, a queue
manager event is generated if an application tries to put a message on a queue that does not exist.
The following examples show conditions that can cause a queue manager event:
• An application issues an MQI call that fails. The reason code from the call is the same as the reason
code in the event message.
A similar condition can occur during the internal operation of a queue manager; for example, when
generating a report message. The reason code in an event message might match an MQI reason code,
even though it is not associated with any application. Do not assume that, because an event message
12 Monitoring and Performance for IBM MQ
reason code looks like an MQI reason code, the event was necessarily caused by an unsuccessful MQI
call from an application.
• A command is issued to a queue manager and processing this command causes an event. For example:
– A queue manager is stopped or started.
– A command is issued where the associated user ID is not authorized for that command.
IBM MQ puts messages for queue manager events on the SYSTEM.ADMIN.QMGR.EVENT queue, and
supports the following queue manager event types:
Authority (on AIX, Linux, and Windows only)
Authority events report an authorization, such as an application trying to open a queue for which it
does not have the required authority, or a command being issued from a user ID that does not have
the required authority. The authority event message can contain the following event data:
• Not Authorized (type 1)
• Not Authorized (type 2)
• Not Authorized (type 3)
• Not Authorized (type 4)
• Not Authorized (type 5)
• Not Authorized (type 6)
All authority events are valid on AIX, Linux, and Windows only.
Inhibit
Inhibit events indicate that an MQPUT or MQGET operation has been attempted against a queue
where the queue is inhibited for puts or gets, or against a topic where the topic is inhibited for
publishes. The inhibit event message can contain the following event data:
• Get Inhibited
• Put Inhibited
Local
When an application or the queue manager has not been able to access a local queue or other local
object, for example, because the object has not been defined, the queue manager can generate a local