sent and received TLS records for both DoH and DoT for 100
webpages (Figure 7). We observe that DoT trafﬁc presents
much less variability in TLS record sizes than DoH.
To gain insights into the origin of this variability, we collected
and decrypted DoT and DoH trafﬁc for visits to a handful of
websites. We used a modiﬁed Stubby client8 to decrypt the
DoT trafﬁc, and used the tools described in Section V-A to
decrypt the DoH traces. For each website, we used Firefox and
Stubby (DoT setting) and, immediately after ﬁnishing loading
the page, we restarted Firefox with a clean proﬁle and visited
using Firefox’s native DoH client (DoH setting).
Upon inspection of the traces, we observe that DoH traces
contain requests for A and AAAA records while DoT traces
only have requests for A records. This shows how differ-
ent implementations of the client can generate signiﬁcantly
different trafﬁc, potentially affecting the performance of the
attack. This also explains why we observe a greater number
of TLS record sizes in Figure 7. We also ﬁnd differences in the
domains that are resolved. However, most of the differences
are domains that occur independently of the protocol and,
thus, cannot explain the difference in attack performance
between the two protocols. The most relevant difference is
that, excluding AAAA queries and responses, DoT traces have
8https://github.com/saradickinson/getdns/tree/1.5.2 add keylogging
11
fewer average number of DNS messages than DoH traces
for the same website. In addition, the TLS records in DoT
traces are larger than DoH’s9. We acknowledge that although
we identify possible causes for the variability of DoH’s TLS
record sizes, our observations are not conclusive on whether
this variability accounts for the better performance of the attack
on DoT than DoH.
Figure 7: Histogram of sent (top) and received (bottom) TLS
record sizes for DoT and DoH.
VII. CENSORSHIP ON ENCRYPTED DNS
DNS-based blocking is a wide-spread method of censoring
access to web content. Censors inspect DNS lookups and,
when they detect a blacklisted domain, they either reset the
connection or inject their own DNS response [77]. The use
of encryption in DoH precludes content-based lookup iden-
tiﬁcation. The only option left to the censor is to block the
resolver’s IP. While this would be very effective, it is a very
aggressive strategy, as it would prevent users from browsing
any web. Furthermore, some DoH resolvers, such as Google’s,
do not necessarily have a dedicated IP. Thus, blocking their IP
may also affect other services.
An alternative for the censor is to use trafﬁc analysis to identify
the domain being looked up. In this section, we study whether
such an approach is feasible. We note that to block access to
a site, a censor not only needs to identify the lookup from the
encrypted trafﬁc, but also needs to do this as soon as possible
to prevent the user from downloading any content.
A. Uniqueness of DoH traces
In order for the censor to be able to uniquely identify domains
given DoH trafﬁc,
the DoH traces need to be unique. In
particular, to enable early blocking, the ﬁrst packets of the
trace need to be unique.
To study the uniqueness of DoH trafﬁc, let us model the set of
webpages in the world as a random variable W with sample
space ΩW ; and the set of possible network traces generated
by those websites as a random variable S with sample space
ΩS. A website’s trace w is a sequence of non-zero integers:
i=1, si ∈ Z (cid:114) {0}, n ∈ N, where si represents the size (in
(si)n
bytes) of the i-th TLS record in the trafﬁc trace. Recall that
its sign represents the direction – negative for incoming (DNS
to client) and positive otherwise. We denote partial traces, i.e.,
only the l ﬁrst TLS records, as Sl.
9This might seem counterintuitive as DoH has HTTP headers that DoT does
not have. However, DoH’s RFC allows the use of HTTP compression (and
we observe its use in our dataset), while DoT’s RFC recommends against the
use of TLS compression.
12
H(W | Sl) = 
∀o∈ΩSl
Pr[Sl = o]H(W | Sl = o) .
Figure 8: Conditional entropy H(W | Sl) given partial
for different world sizes
observations of DoH traces
(|ΩW| = {10,100,500,1500,5000}). Each data point
is
averaged over 3 samples.
We measure uniqueness of partial traces using the conditional
entropy H(W | Sl), deﬁned as:
Here, H(W | Sl = o) is the Shannon entropy of the probability
distribution Pr[W | Sl = o]. This probability describes the
likelihood that the adversary guesses websites in W given the
observation o. The conditional entropy H(W | Sl) measures
how distinguishable websites in ΩW are when the adversary
has only observed l TLS records. When this entropy is zero,
sites are perfectly distinct. For instance, if the ﬁrst packet of
every DoH trace had a different size, then the entropy H(W |
S1) would be 0.
We compute the conditional entropy for different world sizes
|ΩW| and partial lengths l, using traces from the OW dataset.
We show the result in Figure 8. Every point is an average over
3 samples of |ΩW| webs. These webs are selected uniformly
at random from the dataset. The shades represent the standard
deviation across the 3 samples.
Unsurprisingly, as the adversary observes more packets, the
traces become more distinguishable and the entropy decreases.
For all cases, we observe a drop of up to 4 bits within the ﬁrst
four packets, and a drop below 0.1 bits after 20 packets. As
the world size increases, the likelihood of having two or more
websites with identical traces increases, and thus we observe
a slower decay in entropy. We also observe that, as the world
size increases the standard deviation becomes negligible. This
is because the OW dataset contains 5,000 websites. Thus, as
the size of the world increases, the samples of ΩW contain
more common websites.
Even when considering 5,000 pages, the conditional entropy
drops below 1 bit after 15 packets. This means that after
15 packets have been observed, there is one domain whose
probability of having generated the trace is larger than 0.5.
In our dataset 15 packets is, on average, just 15% of the
whole trace. Therefore, on average, the adversary only needs
to observe the initial 15% of a DoH connection to determine
a domain with more conﬁdence than taking a random guess
between two domains. We observe that as the number of
pages grows, the curves are closer to each other indicating
01234567891011121314151617181920x=Numberofobservedpackets0246810f(x)=H(W|Sx)(bits)Numsites5000150050010010Figure 10: Distribution of domain length in the Alexa top 1M.
Table VIII: Number of domains in each censorship test list and
their presence in the Alexa top 1M.
Turkmenistan
Censored domains
Not in Alexa-1M
344
246
Iran
877
600
S. Arabia
Vietnam
China
284
219
274
218
191
94
the censored page and others. At the cost of generating more
trafﬁc for users and resolvers, this would force the censor to
drop all DoH connections originating from a user’s IP or throt-
tle their DoH trafﬁc, causing more collateral damage.
Block on ﬁrst DoH query. A more aggressive strategy is
to drop the DoH connection before the ﬁrst DoH response
arrives. While this guarantees that the client cannot access any
content, not even index.html, it also results in all domains
with same name length being censored.
In order to understand the collateral damage incurred by
domain length based blocking relying on the fourth packet, we
compare the distribution of domain name lengths in the Alexa
top 1M ranking (see Fig. 10) with the distribution of domain
names likely to be censored in different countries. For the
former we take the global ranking as per-country rankings only
provide 500 top websites which are not enough for the purpose
of our experiments and, for some countries, the lists are not
even available. We take the test
lists provided by Citizen
Labs [79]. These lists contain domains that regional experts
identify as likely to be censored. While appearance in these
lists does not guarantee that the domains are actually censored,
we believe that they capture potential censor behavior.
We take ﬁve censorship-prone countries as examples: Turk-
menistan, Iran, Saudi Arabia, Vietnam, and China. Our analysis
of collateral damage is relative among the countries considered
in our study. Since the Alexa list contains only domains, we
extract the domains from the URLs appearing in Citizen Labs’
test lists. Table VIII shows the total number of domains in each
list and the number of those domains that are not present in
the Alexa-1M list. We observe that at most 51% (China) of the
domains appear in the ranking. For the other countries the ratio
is between 21% and 32%. This indicates that the potentially
censored domains themselves are mostly not popular.
Even if the censor blocks unpopular domains, there are two
side effects of blocking based on domain lengths. First, there
will be some collateral damage: allowed websites with the
same domain length will also be blocked. Second, there will
be a gain for the censor: other censored websites with the same
domain length are blocked at the same time.
We study the trade-off between collateral damage and censor
gain. The minimum collateral damage is attained when the
Figure 9: Histograms for domain name length (top) and fourth
TLS record length (bottom) in the LOC1 dataset, for 10
samples (normalized over the total sum of counts).
that convergence on uniqueness after the 15-th packet is likely
to hold in larger datasets.
The importance of the fourth packet. We hypothesized that
the large drop by the fourth packet might be caused by one
of these records containing the DNS lookup. As these traces
do not contain padding, the domain length would be directly
observable in the trace. We verify this hypothesis by comparing
the frequency of appearance of the domain’s and outgoing
fourth record’s length (incoming records cannot contain a
lookup). We discard TLS record sizes corresponding to HTTP2
control messages, e.g., the size “33” which corresponds to
HTTP2 acknowledgements and outliers that occurred 5% or
less times. However, We kept size “88” even though it appears
too often, as it could be caused by queries containing 37-
characters-long domain names.
We represent the frequency distributions in Figure 9. We see
that the histogram of the sizes of the fourth TLS record in our
dataset is almost identical to the histogram of domain name
lengths, being the constant difference of 51 bytes between the
two histograms the size of the HTTPS header. This conﬁrms
that the fourth packet often contains the ﬁrst-party DoH query.
In some traces the DoH query is sent earlier, explaining the
entropy decrease starting after the second packet.
B. Censor DNS-blocking strategy
We study the collateral damage,
i.e., how many sites are
affected when a censor blocks one site after a trafﬁc-analysis
based inference. We assume that upon decision, the censor uses
standard techniques to block the connection [78].
High-conﬁdence blocking. To minimize the likelihood of
collateral damage, the adversary could wait to see enough
packets for the conditional entropy to be lower than one bit.
This requires waiting for, on average, 15% of the TLS records
in the DoH connection before blocking. As those packets
include the resolution to the ﬁrst-party domain,
the client
can download the content served from this domain. Yet, the
censor can still disrupt access to subsequent queried domains
(subdomains and third-parties). This is a strategy already used
in the wild as a stealthy form of censorship [78].
To avoid this strategy, the clients could create one connection
per domain lookup, thereby mixing connections belonging to
13
4567891011121314151617181920212223242526272829303132333436374142First-partydomainnamelength(numberofcharacters)0.0000.0250.0500.0750.100Frequency5556575859606162636465666768697071727374757677787980818283848587889293FourthTLSrecordsize(bytes)0.0000.0250.0500.0750.100Frequency010203040506070Domainlength020000400006000080000CountFigure 11: Collateral damage in terms of ranking for three blocking strategies: minimum collateral damage set size, maximum
censor gain, most popular website.
censor blocks domains of length 6 (such as ft.com), resulting
on 1,318 affected websites. The maximum damage happens
when censoring domains of size 10 (such as google.com)
which affects other 66,923 websites, domains of size 11
(such as youtube.com) which affects other 78,603 web-
sites, domains of size 12 (such as facebook.com) which
affects other 84,471 websites, domains of size 13 (such as
wikipedia.org) which affects other 86,597 websites, and
domains of size 14 (such as torproject.org, which af-
fects other 83,493 websites. This means that, in the worst case,
collateral damage is at most 8.6% of the top 1M list.
To understand the censor gain, we consider Iran as an example.
The maximum gain is 97, for domain length of 13, i.e., when
the censor blocks domains of length 13, it blocks 97 domains
in the list. At the same time, it results in large collateral
damage (86,557 websites). The minimum gain is obtained for
domain length 5, which only blocks one website, but causes
small collateral damage (1,317 domains). If Iran blocks the
most popular domain in the list (google.com), this results in a
collateral damage of 66,887 websites.
The volume of affected websites is of course representative
of damage, but it is not the only factor to take into account.
Blocking many non-popular domains that are in the bottom of
the Alexa list is not the same as blocking a few in the top-100.
We show in Figure 11 boxplots representing the distribution of
Alexa ranks for three blocking strategies: minimum collateral
damage, maximum censor gain, and blocking the most popular
web. For each country, these strategies require blocking differ-
ent domain lengths. Thus, in terms of volume, the damage is
different but in the order of the volumes reported above. We
observe that the minimum collateral damage strategy results in
different impact depending on the country. Although for all of
them the volume is much lower than for the other strategies, in
Turkmenistan and Iran the median rank of the blocked websites
is much lower than those in the other strategies, indicating
that this strategy may have potentially higher impact than
blocking more popular or high-gain domains. On the positive
side, minimum collateral damage in Saudi Arabia, Vietnam,
and China, mostly affects high-ranking websites. Thus, this
strategy may be quite affordable in this country. The other
two strategies, maximum gain and blocking the most popular
website, result on a larger number of websites blocked, but
their median ranking is high (above 500,000) and thus can
also be considered affordable.
In conclusion, our study shows that while block on ﬁrst DoH
query is an aggressive strategy, it can be affordable in terms
of collateral damage. More research is needed to ﬁne-tune our
analysis, e.g., with access to large per-country rankings, or
exact lists of blacklisted domains.
VIII. LOOKING AHEAD
We have shown that, although it is a great step for privacy,
encrypting DNS does not completely prevent monitoring or
censorship. Current padding strategies have great potential
to prevent censorship, but our analysis shows that they fall
short when it comes to stopping resourceful adversaries from
monitoring users’ activity on the web.
Our countermeasures analysis hints that
the path towards
full protection is to eliminate size information. In fact, the
repacketization in constant-size cells offered by Tor provides
the best practical protection. Tor, however, induces a large
overhead both in the bandwidth required to support onion
encryption, as well as in download time due to the rerouting
of packets through the Tor network.
We believe that the most promising approach to protect DoH
is to have clients mimicking the repacketization strategies of
Tor, without replicating the encryption scheme or re-routing.
This has the potential
to improve the trade-off between
overhead and trafﬁc analysis resistance. A complementary
strategy to ease the achievement of constant-size ﬂows, is to
rethink the format of DNS queries and its headers. Reducing
the number of bits required for the headers would make it
easier to ﬁt queries and responses in one constant-size packet
with small overhead.
Besides protection against third party observers, it is important
that the community also considers protection from the re-
solvers. The current deployment of DoH, both at the resolvers
and browsers, concentrates all lookups among a small number
of actors that can observe the behavior of users. More research
in the direction of Oblivious DNS [80] is needed to ensure that
no parties can become main surveillance actors.
ACKNOWLEDGMENT
We would like to thank the Cloudﬂare team, Sara Dickinson,
and Daniel Kahn Gillmor, for their collaboration and support
on this work. We would also like to thank our shepherd,
Zhou Li, for his feedback that helped improve the paper. This
research is supported by the Spanish grant TIN2017- 88749-R
(DiscoEdge) and by the Research Council KU Leuven under
the grant C24/18/049. In addition, this work has been partially
supported by the United States Air Force and DARPA under
Contract No. FA8750-19-C-0502. Any opinions, ﬁndings and
conclusions or recommendations expressed in this material are
14
MinimumcollateraldamageMaximumcensorgainMostpopularwebsite02000004000006000008000001000000RankTurkmenistanIranSaudiaArabiaVietnamChinathose of the authors and do not necessarily reﬂect the views
of the United States Air Force and DARPA. Marc Juarez was
supported by a PhD fellowship of the Fund for Scientiﬁc
Research - Flanders (FWO).
REFERENCES
[1] Stephane Bortzmeyer. DNS privacy considerations. 2015.
[2] Christian Grothoff, Matthias Wachs, Monika Ermert, and
Jacob Appelbaum. NSA’s MORECOWBELL: Knell for
DNS. Unpublished technical report, 2017.
[3] The NSA ﬁles decoded. https://www.theguardian.com/
us-news/the-nsa-ﬁles. Accessed: 2019-05-13.
[4] Earl Zmijewski. Turkish Internet Censorship Takes a New
https://dyn.com/blog/turkish-internet-censorship,
Turn.
2014. Accessed: 2018-12-06.
[5] Nicholas Weaver, Christian Kreibich, and Vern Paxson.
Redirecting dns for ads and proﬁt. In FOCI, 2011.
[6] S. Bortzmeyer. DNS Privacy Considerations. RFC 7626,
2015.
[7] A.Cooper, H. Tschofenig, B. Aboba, J. Peterson, J. Mor-
ris, M. Hansen, and R. Smith. Privacy Considerations for
Internet Protocols. RFC 6973, 2015.
[8] Z. Hu, L. Zhu, J. Heidemann, A. Mankin, D. Wessels, and
P. Hoffman. Speciﬁcation for DNS over Transport Layer
Security (TLS). RFC 7858, RFC Editor, May 2016.