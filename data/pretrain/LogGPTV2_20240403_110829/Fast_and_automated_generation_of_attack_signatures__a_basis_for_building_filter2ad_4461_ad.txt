attacks, stack overﬂow, heap overﬂow, and format string. We illus-
trate how our system works using examples from each category.
OpenSSL heap overﬂow attack. OpenSSL 0.9.6d and older ver-
sions have a remotely exploitable vulnerability in handling client
master keys. This was the vulnerability exploited by the Linux
Slapper worm. Our evaluation was performed on an Apache web
server with the vulnerable SSL module. Normal requests were gen-
erated using a Mozilla web browser, which requests web pages us-
ing a version 2 SSL protocol. The attack was then launched, which
caused the vulnerable server to crash with a memory error. Our
system detected the SEGV signal. Using our table-based analysis,
our system identiﬁed the address in the vulnerable buffer. Our ap-
proach then searched recent inputs, and found that the second most
recent input contained the longest matching substring (of length
418 bytes) with the vulnerable buffer. Using input format speciﬁ-
cation, the attack was linked to the “Client Master Key” message
(represented using a integer), whose length was found to be 421
bytes. The signature generation module then retrieved the statistics
on all “Client Master Key” messages seen during normal execution,
and found that the maximum message length was 204 bytes. There-
fore, a signature was generated to ﬁlter out all “Client Master Key”
messages larger than 420 bytes. After the signature was deployed,
the attack did not affect the server, while normal server operation
was unaffected.
Samba stack overﬂow attack. Samba server versions 2.2.8 and
earlier have a vulnerability in processing a “transaction 2” open re-
quest. The server fails to perform bounds-checking on a buffer that
holds the name of the ﬁle to be opened. A long name in the request
will overwrite the return addresses on the stack. In our evaluation,
the server crashed when the overﬂowed return address was used.
Our system successfully identiﬁed the vulnerable buffer near the
stack top. The correlation step matched the vulnerable buffer with
a recent input, with the length of the match being 900 bytes. Using
input format speciﬁcation, this message was identiﬁed as a “trans-
action 2” open. This request had not been observed under normal
operation, i.e., maximum benign size was 0, while the attack size
was 2080. A signature based on this length was successfully gen-
erated.
WU-ftpd format string attack. There is a format string vulnera-
bility in wu-ftpd server version 2.6.0 and earlier. The vulnerability
is in “SITE EXEC” command, in which user-provided data can be
used as a format string to printf-family functions. When the ex-
ploit program speciﬁed an address to be changed via the format
string, it resulted in a memory error. As in the above two cases, our
system successfully identiﬁed the vulnerable buffer, and matched
the attack-bearing input message. The input message is 453 bytes,
while normal message is around 50 bytes. Moreover, normal com-
mands are all ASCII characters, while the attack contains binary
characters. Based on these facts, a signature that uses both the
length and character distribution information was generated.
Importance of input speciﬁcation. We can see the importance
of input speciﬁcation through the above examples. For example, in
the OpenSSL heap overﬂow vulnerability, the server accepted other
types of messages larger than the malicious “Client Master Key”
message. If the input format speciﬁcation was not used, we could
not generate a length-based signature. Moreover, since OpenSSL
is a binary protocol, it is unlikely that a robust signature based on
character distributions can be derived,
For Samba, once again the protocol uses a binary format.
In
addition, some of the messages, especially those involving ﬁle data
transfer, can be much larger than the transaction2 open request.
Thus, it is unlikely that a successful signature can be generated
without input format speciﬁcation.
For WU-ftpd, signature generation would likely succeed without
input format speciﬁcation, as the attack-bearing input contains bi-
nary data, instead of pure ASCII data in normal ftp sessions. How-
ever, if the attacker’s goal is to cause denial-of-service, he/she can
use pure ASCII as the attack payload to evade detection.
7.2 Performance
Effectiveness in signature generation.
In our evaluation, we
are interested in the result of our approach on “real-world” attacks.
The attacks used in our evaluation were selected from the website
securityfocus.com. In selecting attacks, our ﬁrst criterion is the
vulnerable program’s popularity, as popular programs’ vulnerabil-
ity have more real-world impact. Also, it is less likely for these
programs to contain obvious bugs, and thus the attacks on them
tend to be more sophisticated. Another criterion is the availabil-
ity of exploit code. Since developing exploit code is a non-trivial
effort, we limited our selection to the attacks that have working ex-
ploit on Linux. The attacks evaluated are shown in Table 1, and our
approach successfully generated signatures for all the attacks.
Speed of signature generation.
In all the evaluated examples,
our approach generated signatures within 10 milliseconds after the
attack is detected.
Performance overhead. We measured the performance overhead
of our system on an Apache web server, in which the server’s CPU
time is used as the metric. (The server throughput and latency met-
rics are likely to show much lower overheads because the work-
loads tend to be limited by the 100Mbps network bandwidth.) The
workload was produced by a script that downloads a set of ﬁles with
size ranging from 500 bytes to 5M bytes. The script was repeated
for 100 times in each test.
The regular Apache server took a CPU time of 2.52 seconds to
complete the task. The Apache server protected by our approach
took 2.70 seconds to ﬁnish the task, a moderate 7.1% overhead. In
this test, no ﬁlters were deployed. To test the performance impact
caused by ﬁltering inputs, we loaded 100 character distribution ﬁl-
ters into our system, and the CPU time increased to 2.74, a total
8.7% overhead. As the character distribution ﬁlter is more expen-
sive than length-based ﬁlters, in common case, the performance
overhead caused by deploying ﬁlters is rather small.
Protecting service availability. We also measured the availability
of three key servers under repeated attack. The servers are Apache,
BIND, and NTPD. Our results shows that COVERS enables the
Program Name Attack Type
Bugtraq ID Vulnerable Message Type
Ratio of Attack/Benign Size
ntpd
samba
passlogd
Stack Overﬂow
Stack Overﬂow
Stack Overﬂow
Stack Overﬂow
Stack Overﬂow
Format String
apache mod ssl Heap Overﬂow
epic4
gtkftpd
wu-ftpd
#2540
#7294
#7261
#8999
#8486
#1387
#5363
Read variables
Trans2open
Log Type
CTCP nickname
MKDIR command
SITE command
Client master key
234%
4333%
18000%
7780%
1130%
860%
207%
Table 1: Attacks used in effectiveness evaluation and the ratio of attack input size to benign input size.
protected servers to tolerate at least 10 times attacks per second
at a given server availability. For example, 50 attacks/second can
reduce an unprotected Apache server’s availability to 70%, but to
achieve the same effect on a server protected by our approach, the
attack rate need to be 500 attacks/second. On NTPD and BIND,
the availability gains were even more signiﬁcant.
7.3 Quality of Signatures
False positives.
In order to evaluate the quality of signatures,
we manually veriﬁed the signatures by analyzing the source code
of the vulnerable programs. For some of the programs, such as
passlogd, ntpd, and gtkftpd, the generated signature won’t have
false positives: Any input matching the signature will deﬁnitely
cause memory error in the program. For the rest of the programs,
as we can see from the last column of Table 1, the difference be-
tween the size of attack input and that of benign input is very large.
Therefore, the probability of a false positive is low.
Polymorphic attacks. Polymorphic attacks are based on chang-
ing the attack payload frequently. But they cannot change the fact
that the vulnerable buffer is overﬂowed, and the fact that binary
data such as return addresses must be included in the attack input.
Because the signatures generated by our approach tends to capture
the characteristics of the underlying vulnerability, and not the char-
acteristics of a speciﬁc instance of an attack, polymorphic attacks
will likely be defeated by our signatures.
7.4 Protection from Guessing Attacks on Random-
ization
Randomization-based approaches such as ASR and ISR are vul-
nerable to brute-force and guessing attacks. [29] describes an attack
on PaX address-space randomization that can successfully guess
the value used in randomization in about 104 attempts. [35] de-
scribes an attack on instruction set randomization that succeeds,
once again, using thousands of attack attempts.
With our approach protecting a vulnerable server, an effective
signature will be generated within the ﬁrst few unsuccessful attack
attempts. After this point, all attacks will be dropped even before
they reach the server, thereby ensuring that these attacks don’t com-
promise it.
[29] suggests that perhaps the ASR used in PaX is “unﬁxable.”
They claim that (a) there is no effective response that an automated
system can take when faced with such attacks, and (b) shutting
down servers is unacceptably expensive. The results presented in
this paper counters their claim, and provides an effective protection
against attacks that require multiple attempts before succeeding.
Of course, it is possible that an attack against randomization may
succeed on the ﬁrst attempt, in which case, no attack is ever de-
tected and hence no signatures can be generated. However, the
probability of succeeding on the ﬁrst attempt is very small with the
technique of [29]. The technique of [35] requires a large random
mask (several 32-bit words) to be broken step-by-step, one byte at a
time. Thus, the probability of mounting a successful attack in one
attempt is negligibly small. Moreover, when considering a large
population of hosts, it is clear that even if some machines are suc-
cessfully attacked, most other attempts will fail, and these systems
will then become immune to the attack. Moreover, the immunized
systems can distribute the signature to other machines, thereby pro-
viding even better protection for the population.
8. Related Work
Detection of Memory Errors and/or Exploits.
Several tech-
niques have been developed to detect attacks that exploit memory
errors in C/C++ programs. Initial efforts were targeted at stack-
smashing attacks [7, 10, 11]. Broader protection is provided by
approaches such as address-space randomization [1, 4, 5], which,
in its general form [5], can detect exploitation of all memory errors;
and instruction set randomization [3, 15] (and OS features such as
non-executable data segments) that can detect all code injection at-
tacks. There have also been more comprehensive techniques for
detecting all memory errors, regardless of whether they are being
used in an attack [13, 14, 20, 27, 41]. When these approaches
detect an attack, the victim process is generally terminated. Re-
peated attacks (such as those due to worms) will require repeated
and expensive application restarts, effectively rendering the service
unavailable.
Approaches for Recovering from Memory Errors. Automatic
patch generation (APG) [30] proposed an interesting approach that
uses source-code instrumentation to diagnose a memory error, and
automatically generate a patch to correct it. STEM [31] improved
on APG by eliminating the need for source code access. It uses
binary emulation instead, which can be very expensive. By limit-
ing emulation to a small section of code preceding the vulnerability,
they have shown that the overall performance overheads can be kept
surprisingly low (about 30%). STEM relies on code instrumenta-
tion to detect faults before there is substantial corruption of mem-
ory, so that recovery can be attempted. At this point, STEM uses
a memory update log to restore the memory changes performed
within the faulting function, and forces an error return from this
function. A similar error-recovery strategy was used in APG as
well. The difﬁculty with this strategy is that the application may
be unprepared to handle the error-code, and as a result, may not
recover. In their experiments, this strategy causes an application
crash in about 10% of cases. Even when the application contin-
ues to run, it isn’t clear that it will always work correctly. In con-
trast, our approach forces error returns for input functions. Since
server applications handle such errors, and implement application-
speciﬁc logic to recover from them, recovery is more reliable in our
approach.
Failure-oblivious computing [26] uses CRED [27] to instrument
program source-code to detect all memory errors at runtime. When
it detects an out-of-bounds write, it stores the data in a separate
section of memory, and returns this data when a corresponding read
operation is issued. This approach makes attacks harmless, and
allows for recovery as well. The main drawback of this approach is
that it often slows down programs by a factor of 2 or more.
DIRA [33] uses a source-code transformation for runtime log-
ging of memory updates. When an attack is detected, DIRA uses