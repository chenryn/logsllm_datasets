Hi, I'm trying to build a model with functional API. But I got some error only
when I use BatchNorm layer . A toy example:
    import numpy as np
    from keras.layers import Input, BatchNormalization, Dense
    from keras.models import Model
    # model1:
    input1 = Input((10,))
    bn1 = BatchNormalization()(input1)
    out1 = Dense(2, activation='softmax')(bn1)
    model1 = Model(input1, out1)
    # model2:
    input2 = Input((10,))
    out2 = Dense(10, activation='relu')(input2)
    model2 = Model(input2, out2)
    # model3 is just a simple stack of model1 and model2:
    input3 = Input((10,))
    out3 = model1(model2(input3))
    model3 = Model(input3, out3)
    # compile and train:
    model1.compile(loss='categorical_crossentropy',
                   optimizer='adam',
                   metrics=['accuracy'])
    y = np.zeros((10, 2))
    x = np.zeros((10, 10))
    model1.train_on_batch(x, y)
Then I get `InvalidArgumentError: You must feed a value for placeholder tensor
'input_3' with dtype float`. But model1 has nothing to do with input3 if I
train it separately. The weird thing is that if I remove bn1 of model1 or
change it to layers like Dense, this error will disappear.
I use tensorflow backend and both tensorflow and keras are updated. Do I use
functional API in the wrong way or it is a potential bug?