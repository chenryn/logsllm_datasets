of rij, q × r variables of r(cid:48)
ij, q × r secrets δij, q variables of
αj, q variables of X(cid:48), and one variable r(cid:48). Half of the random
variables rij and r(cid:48)
ij are obfuscated with p1 and the other half
are obfuscated with p2. Even if the PIR server knows the values
of these two prime numbers, it can only remove half of the
variables by calculating the shares in mod(p1) or mod(p2).
The server knows at most q× r points of the polynomials, and
it can remove half of rij and r(cid:48)
ij, which results in a more than
q × r degree of freedom for the secrets.
Robustness against colluding servers If all the PIR servers
collude, they can determine the client’s query since they can
factorize n and ﬁnd the prime numbers used in the scheme.
However, if we use larger prime numbers, the security of
the protocol will reduce to computationally secure against all
colluding servers based on the factorization problem, which
is an NP problem. To compromise a client, the servers ﬁrst
need to factorize n. This trades off between performance and
security: increasing the size of the prime numbers improves the
computational security, but the matrix multiplication will take
longer. Therefore, our protocol is information-theoretically
secure if up to t servers collude; with large prime num-
10
bers, our protocol is computationally secure even if all
the servers collude (given large prime numbers). This is
because, if all the servers collude, they still need to obtain the
prime factors of n to cancel the effect of random numbers. So,
if the prime numbers are large enough, e.g., n has 2048 bits
or more, the adversarial servers should solve the factorization
problem, which is an NP problem.
C. Overhead Comparison to Prior Work
1) Communication Cost: Table III compares the com-
munication costs of our protocol (Complete Version) with
different protocols and in different settings. We also compare a
homogeneous version of our HPIR protocol with state-of-the-
art homogenous protocols (in the homogenous version of our
protocol, we send equal number of shares to the servers). We
compare the protocols for the same volume of retrieved trafﬁc.
Therefore, we amplify Goldberg’s [26] communications by q
as it is a single-query protocol.
Also, note that our element size is two times of prior
works since our calculations are in mod(n), where n is a
multiplication of two prime numbers. Each prime number has
about w bits, so our elements are about 2 × w bits. However,
in prior works the calculations are in mod(p), where p is a w
bits prime number.
Homogeneous version of our protocol Compared to Gold-
berg’s PIR [26], homogeneous version of our protocol
is
slightly higher in upload and download bandwidth consump-
tion. Comparing to Henry et al. PIR [30], the number of
exchanged elements are the same, but each element of our
protocol is two times as their elements. However, since Henry
et al. PIR protocol is based on ramp secret sharing, they need
t + q servers for their protocol. It means that by increasing
the number of queries, they need more non-colluding servers,
while our protocol can be run on as few as two servers.
Heterogeneous version of our protocol We also compare
the heterogeneous version of our protocol (complete version)
with the heterogeneous versions of Goldberg’s PIR and Henry
et al. PIR. We create a heterogeneous version for these prior
works by making the client send more queries to one of the
PIR servers (the rich server). However, to maintain the privacy
level (the maximum number of colluding servers without
compromising client’s privacy), we need to increase the degree
of the polynomials used in their schemes. This results in
increasing the bandwidth/computation overhead on the rich
server of these prior works without reducing the burden on
the poor server. Therefore, the heterogeneous variant of these
prior works has no advantage over their homogenous versions.
Also, we see that using a PRNG in our protocol reduces the
upload bandwidth to the poor server at the cost of downgrading
our information-theoretic security to a computational security.
2) Computation Cost: Table IV compares the computation
cost of our protocol (Complete Version) with other protocols.
These numbers are based on standard matrix multiplication,
which take O(n3) operations. For large number of queries (q),
using the Strassen’s algorithm for matrix multiplication will
further reduce the order of matrix multiplication to O(n2.8)
operations.
Figure 2: Total computation time (s) (i.e., server and client
running times) vs. database sizes (GB) of protocol (complete
version) in retrieving one record with different element sizes.
w = 512 provides the least overhead.
VIII.
IMPLEMENTATION
Implementation Setup We have implemented our HPIR
protocol in C++, wrapped in Rust. We have implemented our
code to be compatible with the Percy++ PIR library [43]. We
use the NTL library [49] for handling big number operations
similar to the Percy++ [43] PIR suite. Our code is available at
https://github.com/SPIN-UMass/HPIR.
We measure the performance of our algorithm on a desktop
computer with a quad-core i7 CPU @ 3.6 GHz and 32 GB
of RAM, running Ubuntu 18.04. All of our experiments are
single-threaded, though our most expensive operation, which
is server computation, is highly parallelizable. In all of the
experiments, we load the database into the RAM before
measuring the time, so the measured times do not include
the I/O times. Note that the computation time of our protocol
depends mostly on the size of the database, not its dimensions,
so in all of the experiments we choose s = r =(cid:112)N/w, which
is the communication-optimal block size derived by Goldberg
et al. [26] (N is the size of database in bits and w is the element
size in bits). All of our experiments are performed in a two
servers scenario (that suits most of the real world applications):
a rich server with high communication/computation resources
and a poor server with lower resources.
We compare our protocol with Goldberg PIR [26] design
in a two servers scenario with privacy level t = 1. To ensure
a fair comparison, we integrate Goldberg’s PIR protocol from
Percy++ [43] into our test framework, which is wrapped in
Rust. We compare our design with this paper since Henry et
al. PIR [30] with single query (q = 1) is a variant of Goldberg’s
PIR.
Degree of Heterogeneity (DH) We deﬁne a degree of
heterogeneity (DH) parameter to represent the heterogeneity
of our protocol. For a two-server setting, we deﬁne DH to
11
0.0Database Size (GB)0Total Processing Time (s)0.51.01.52.012345w=256w=512w=768w=1024PIR Protocol
Goldbergs’s PIR [26]
Henry et al. PIR [30]
Homogeneous Version of Our Protocol
(Complete Version) (q + 1 servers, t = q)
Homogeneous Version of Our Protocol
(Complete Version) (2 servers, t = 1)
Heterogeneous version
of Goldberg’s PIR [26]
Heterogeneous version
of Henry et al. PIR [30]
Our Heterogeneous Protocol
(Complete Version), t = 1
Our Heterogeneous Protocol (Complete
Version) Using PRNG, t = 1
Table III: Communication cost comparison (bits)
Upload BW for
Download BW for
Each Server
q × r × w
r × w
2 × r × w
Each Server
q × s × w
s × w
2 × s × w
(cid:96) × q × r × w
(cid:96) × r × w
2 × (cid:96) × r × w
(cid:96) × q × s × w
(cid:96) × s × w
2 × (cid:96) × s × w
Total Upload BW Total Download BW
Minimum Number
of PIR Servers ((cid:96))
Rich Server:
Poor Server:
Rich Server:
Poor Server:
Rich Server:
Poor Server:
Rich Server:
Poor Server:
r × (q + 1) × w s × (q + 1) × w 2 × (q + 1) × r × w 2 × (q + 1) × s × w
q × r × t × w
q × r × w
r × t × w
r × w
2 × q × r × w
2 × r × w
2 × q × r × w
2 × w
2 × (q + 1) × r × w 2 × (q + 1) × s × w
(2 × q × r + 1) × w 2 × (q + 1) × s × w
((cid:96) + t) × q × r × w ((cid:96) + t) × q × s × w
((cid:96) + t) × s × w
((cid:96) + t) × r × w
q × s × t × w
s × t × w
s × t × w
s × w
2 × q × s × w
2 × s × w
2 × q × s × w
2 × s × w
t + 1
t + q
q + 1
2
t + 1
t + q
2
2
PIR Protocol
Goldbergs’s PIR [26]
Henry et al. PIR [30]
Table IV: Computation cost comparison
Computation Cost for Each Server
O(q × r2 × s)
O(q × r2 × s)
O(r2 × s)
O(r2 × s)
Total Computation Cost Minimum Number
of PIR Servers ((cid:96))
O((cid:96) × q × r2 × s)
O((cid:96) × r2 × s)
t + 1
t + q
O((q + 1) × r2 × s)
2
Our Heterogeneous Protocol (Complete Version)
Rich Server:
Poor Server:
be the ratio of the number of query shares the client sends
to the rich PIR server divided by the number of query shares
she sends to the poor PIR server. This metric represents the
bandwidth/computation ratio of the PIR servers. Note that in
our protocol, when retrieving q records, the maximum DH is
q/1, as the client will have q + 1 secret shares to send to the
servers.
Tuning the element size (w) parameter First, we measure
the computation overhead performance of our protocol for
different element sizes to ﬁnd the optimal value of w. Figure 2
shows the total computation times (server and client side) for
various database sizes, and for different values of w. The plot
suggests using w = 512 bits as the most efﬁcient value, which
we use for the rest of our experiments.
Note that a w = 512 bits results in n to have a size of 1024.
In case of the collusion of the PIR servers, the security of the
protocol will be tied to factorizing n. Therefore, increasing w
will improve the security of the protocol in case of collusion
at the cost of higher processing times.
A. Server Computation Overhead
The major computation performed by the servers in our
HPIR protocol is matrix multiplication (i.e., multiplying the
query matrix, Q, into the database matrix, D). Figure 3 shows
the server processing time for both the rich and poor servers
for different database sizes and different number of queries (q)
for a ﬁxed w = 512. As can be seen, the server processing
time is linear with the size of the database. The ﬁgure also
compares the rich and poor server processing times with that
of Goldberg’s ITPIR [26] for various number of queries. As
can be seen, the rich server processing time of our HPIR
protocol is very close to, but slightly larger than Godlberg’s
server processing time (for the same number of records q being
retrieved). On the other hand, the processing time of the poor
server is signiﬁcantly smaller than Goldberg’s homogeneous
server. As an example, to retrieve a 1.4 MB ﬁle (4 records)
from a 2 GB database, the rich and poor HPIR servers will take
12.5 and 4.09 seconds, respectively, whereas the two servers
of Goldberg will take 12.04 seconds each. That is, our HPIR
protocol signiﬁcantly reduces the computation overhead on
the poor server by slightly increasing the computation on
the rich (resourceful) server. We see that the computation
gain of our HPIR further increases by increasing the degree
of heterogeneity. As shown in below, increasing the degree of
heterogeneity slightly increases the client’s computation.
B. Client Computation Overhead
The client computation overhead has two parts: client
preparation time, which includes constructing the r polynomi-
als and generating the query matrices, and client data extraction
time, which includes the time of constructing s functions φk(x)
and extracting the elements of queried records. Figure 4 shows
the client processing time of our HPIR protocol for different
database sizes and different number of queries (for w = 512).
As can be seen, client processing time has a sub-linear (square-
root) relation with the database size, which is in agreement
with Goldberg’s results [26].
Also, as Figure 4 shows, our client processing time is larger
than Goldberg’s homogeneous algorithm. However, we see that
even the increased client computation times are highly practical
for typical clients, e.g., the computation time for q = 4 records
in a 1.5GB database is around 500ms for HPIR, compared
to 200ms for Goldberg’s. Also, note that server computation
times are the practical bottleneck in PIR protocols since they
are an order of magnitude larger that client computation times
12
(a) Server processing time of the rich server vs. Database size
(b) Server processing time of the poor server vs. Database size
Figure 3: Server processing time (for a degree of heterogeneity of q/1)
overhead of the poor and rich servers. For instance, for a
DH = 16/16 (which represents a homogeneous setting),
the download/upload bandwidth of the rich and poor servers
are 11.3MB each. By increasing DH to 31/1, the bandwidth
of the rich and poor servers will be 21.9MB and 724KB,
respectively. Therefore, we see that HPIR reduces the com-
munication overhead of the poor server by increasing the
communication overhead on the rich server. We also see
that the homogeneous version of our HPIR protocol (i.e., for
DH = 16/16) imposes computation overheads very close to
that of Goldberg’s homogeneous protocol. Finally, the ﬁgure
shows that the bandwidth of our poor server when we are using
a PRNG is always ﬁxed regardless of the value of DH, since
the client sends only one element (the seed of the PRNG).
Note that for the above results, we set s = r [26], which is
the optimal value as described in our implementation setup
section (so, s = 5792 results in records of size 0.35MB).
The client can also control DH by changing the value of s
(the number of elements in each database record), therefore
changing the required number of queries q for a given PIR
transaction. We demonstrate this in Figure 6; The ﬁgure shows
the download and upload bandwidth overheads (normalized by
the size of the queried ﬁle) of our heterogeneous protocol for
retrieving a 10.95MB ﬁle from a 2GB database for different
record sizes. We can see that there is a trade-off between
the upload bandwidth of the rich server and the download
bandwidth of the poor server; the client can adjust this by
changing s.
D. Comparison With State-Of-The-Art PIR Protocols
Here we compare our HPIR design with state-of-the-art
(homogenous) two-server PIR designs of PIR-PSI [19] and
RAID-PIR [18], as well as the state-of-the-art single-server
SealPIR [4], in terms of computation and communication costs.
Note that not all PIR protocols can be converted into an
HPIR format, so we compare with their regular (homogenous)
versions. In particular, RAID-PIR [18] is based on XOR, and
Figure 4: Client processing time vs. Database size