title:TIBFIT: Trust Index Based Fault Tolerance for Arbitrary Data Faults
in Sensor Networks
author:Mark D. Krasniewski and
Padma Varadharajan and
Bryan Rabeler and
Saurabh Bagchi and
Y. Charlie Hu
 TIBFIT: Trust Index Based Fault Tolerance for Arbitrary Data Faults in Sensor 
Networks 
Y.Charlie Hu 
Distributed Systems & Networking Lab 
School of Electrical and Computer Engineering, 
Purdue University 
Email: PI:EMAIL 
Mark Krasniewski, Padma Varadharajan, Bryan 
Rabeler, Saurabh Bagchi 
Dependable Computing Systems Lab 
School of Electrical and Computer Engineering, 
Email:{mkrasnie,pvaradha,brabeler,sbagchi} 
Purdue University 
@purdue.edu 
Abstract 
Since  sensor  data  gathering  is  the  primary  functionality  of 
sensor  networks,  it  is  important  to  provide  a  fault  tolerant 
method  for  reasoning  about  sensed  events  in  the  face  of 
arbitrary  failures  of  nodes  sending  in  the event  reports. In 
this paper, we propose a protocol called TIBFIT to diagnose 
and mask arbitrary node failures in an event-driven wireless 
sensor  network.  In  our  system  model,  sensor  nodes  are 
organized  into  clusters  with  rotating  cluster  heads.  The 
nodes,  including  the  cluster  head,  can  fail  in  an  arbitrary 
manner  generating  missed  event  reports,  false  reports,  or 
wrong  location  reports.  Correct  nodes  are  also  allowed  to 
make  occasional  natural  errors.  Each  node  is  assigned  a 
trust  index  to  indicate  its  track  record  in  reporting  past 
events correctly. The cluster head analyzes the event reports 
using  the  trust  index  and  makes  event  decisions.  TIBFIT  is 
analyzed  and  simulated  using  the  network  simulator  ns-2 
and  its  coverage  evaluated  with  a  varying  number  and 
varying  intelligence  of  the  malicious  nodes.  We  show  that 
once  TIBFIT  gathers  enough  system  state,  accurate  event 
detection is possible even if more than 50% of the network 
nodes are compromised. 
Keywords:  Sensor  networks,  secure  and  intrusion  tolerant 
systems, trust index, arbitrary data faults, event aggregation. 
1 
Introduction 
Recent innovations made in the fields of electronics and 
wireless  communication  have  enabled  the  advent  of  sensor 
networks.  These  networks  comprising  of  thousands  of 
inexpensive sensor nodes can be set up with relative ease by 
placing  the  nodes  in  predefined  locations  manually  or 
through the use of robots, as well as by random deployment 
of  self-organizing  nodes.  A  wide  gamut  of  applications 
ranging  from  health,  home,  environmental  to  military  and 
defense  make  use  of  sensor  nodes  for  collection  of 
appropriate  data.  The  sensor  nodes  comprising  of  data 
collecting, processing, and transmitting units are very small 
in size and can be densely deployed owing to their low cost.  
in  available 
resources, such as power, memory, and processing ability[2]. 
Sensor  nodes  have  serious 
limitations 
1
and 
architecture, 
The  sensor  nodes  and  wireless  links  are  prone  to  failure, 
while the network is also open to various malicious attacks. 
While  significant  research  has  been  done  in  the  areas  of 
communication 
energy 
conservation  in  sensor  networks,  development  of  fault 
tolerance  in  this  highly  volatile  scenario  remains  an 
interesting open research issue. Conventional fault tolerance 
and intrusion tolerance protocols do not translate well to the 
sensor  network  domain  due  to  its  large  scale  and  the 
resource constraints on the sensor nodes. 
routing, 
In  this  paper  we  consider  fault  tolerance  in  an  event 
driven  model  for  sensing.  An  event  driven  model  of 
behavior  for  sensing  finds  many  applications  in  civilian, 
military  as  well  as  industrial  scenarios. Examples  could be 
seismic  monitoring  to  detect  and  locate  tremors  in  a  given 
area, or military applications to sense any movement within 
a  cordoned-off  area.  The  inherent  unreliability  of  sensor 
nodes  makes  fault  tolerance  in  such  an  environment  an 
important  concern.  The  problem  is  essentially  one  of 
aggregating data from multiple sensor nodes to decide if an 
event has occurred and determining the location of the event, 
in  the  face  of  natural  and  malicious  failures  in  both  the 
sensing nodes as well as the aggregating nodes. In particular, 
our approach looks at arbitrary faults in the sensor networks, 
whether  natural  or  malicious.  Natural  arbitrary  faults  may 
arise suddenly and intermittently in sensor networks, thereby 
causing a node to miss reporting an event (missed alarms) or 
falsely  reporting  an  event  that  has  not  occurred  (false 
alarms).  Malicious  faults  occur  when  some  nodes  in  the 
network  have  been  compromised  by  an  adversary.  This 
adversary can make the nodes send out corrupt information 
intended  to  adversely  affect  the  data  gathering  role  of  the 
network. These malicious nodes, depending on their level of 
intelligence, may have some knowledge of how the network 
functions and can to behave in a manner to escape detection.  
The goal of the proposed TIBFIT protocol involves event 
detection  and  location  determination  in  the  presence  of 
faulty sensor nodes, coupled with diagnosis and isolation of 
faulty  or  malicious  nodes.  The  accuracy  of  the  system  is 
defined  in  terms  of  fraction  of  instances  when  an  event 
occurrence is correctly detected, and its location determined 
within the given error bound.  
The  approach  followed  by  the  protocol  is  to  maintain 
state  of  the  sensing  nodes  in  terms  of  the  fidelity  of  their 
previous sensing actions, and use this information in making 
decisions involving those sensing nodes. Sensor nodes report 
the  occurrence  and  location  of  events  to  a  data  sink,  and 
remain  silent  otherwise.  The  data  sink  then  decides  on 
whether  the  event  occurred  and  where  based  on  the 
aggregated data. To determine the location of the event the 
data  sink  must  aggregate  all  reports  from  nodes  within  the 
detection radius. The aggregation could be a simple voting 
scheme. However voting is a stateless approach and does not 
reflect on the past performances of the sensing nodes. TIBFIT 
introduces  a  new  parameter  called  trust  index  for  this 
purpose. The Trust Index (referred to as TI) of a node is a 
quantitative measure of the fidelity of previous event reports 
of that node as seen by the data sink. In a system comprised 
of  sensing  nodes,  the  data  sink  assigns  and  maintains  a  TI 
for  each  node  in  its  domain,  and  does  voting  in  a  stateful 
manner. As the system runs over a longer time, more state is 
built  up  concerning  the  performance  of  the  associated 
sensing  nodes,  and  hence  tolerance  for  faults  also  goes  up 
accordingly. So while the simple voting approach falls apart 
when more than 50% of the nodes within detection range of 
the  event  are  corrupted,  TIBFIT  can  tolerate  faults  in  a 
network with more than 50% of its nodes compromised after 
it has built up adequate state of the nodes. 
To  demonstrate  the  effectiveness  of  TIBFIT,  we  use  an 
event-driven simulation with ns-2. All nodes are considered 
liable to fail, whether in a natural or a malicious manner. We 
group the nodes into four categories: a) non-faulty nodes that 
naturally fault some percentage of the time; b) faulty nodes 
that err randomly; c) malicious nodes working independently 
that  err occasionally  and  attempt  to  subvert  the  system  but 
also  try  to  remain  undetected;  d)  malicious  nodes  that 
collaborate  and  err  occasionally  and  attempt  to  subvert  the 
system but also try to remain undetected. We show through 
simulation that TIBFIT is capable of accurately detecting and 
determining locations of events even when more than 50% 
of the network is compromised. Finally we also simulate a 
system that has a gradually increasing number of malicious 
nodes and analyze the accuracy of the system. 
The main contributions of this paper are the following: 
1.  TIBFIT  tolerates  nodes  that  fail  both  naturally  and 
maliciously,  and  makes  decisions  on  event  occurrence 
as  well  as  location.  Under  several  scenarios,  accurate 
event determination  and  localization  can be  done  even 
with more than 50% of the network compromised. We 
also demonstrate diagnosis and limited recovery in the 
system. 
2.  No  nodes  are  considered  immune  to  failure,  whether 
they are sensing nodes or the data sink. 
3.  We  have  come  up  with  an  adversary  model  with 
increasing  levels  of  sophistication  and  demonstrate  the 
effectiveness of the protocol in each case. 
4.  The protocol is generic and can be applied to any data 
sensing and aggregation application in sensor networks. 
The rest  of  the  paper  is  organized  as  follows. First, we 
discuss the parameters of our system model in Section 2, we 
discuss  TIBFIT  design 
the  simulation 
implementation  and  results  in  Section  4,  the  analysis  of 
TIBFIT  in  Section  5,  related  work  in  Section  6,  and 
conclusions in Section 7. 
in  Section  3, 
2  System Model 
All  nodes  in  the  network  are  identical  and  are  arranged 
into disjoint clusters, each with a set of cluster heads (CHs), 
only  one  of  which  is  active  at  any  point  in  time.  The  CH 
serves as the data sink for its particular cluster. The nodes in 
a cluster are within one hop communication of the CH. The 
clusters themselves are formed randomly around the elected 
CHs.  The  CHs  are  rotated  over  time  and  CH  election  is 
based on energy-related parameters of the constituent nodes. 
In each cluster, the node that is chosen to be the CH knows 
the  topology  of  the  cluster.  Nodes  that  are  within  the 
detection  range  of  an  event  are  called  event  neighbors  for 
that event. This topology is illustrated in figure 1.  
Event detection range 
Transmission range of N2 
Event to be detected 
Cluster Head 
Event Neighbors 
Other nodes in the cluster
Node N2 
Figure 1: Event detection 
When an event occurs, all the event neighbors are expected 
to  report  the  occurrence  of  the  event  to  the  CH.  The  CH 
makes  a decision  on  whether  the  event  has  occurred based 
on  the  reports  received  from  the  event  neighbors  and  their 
trust indices. A detailed description of the TI model follows 
in Section 3. 
The  sensor  network  is  deployed  by  placing  the  nodes 
randomly in the network. It is assumed that the nodes have 
the  ability  to  determine  their  own  locations.  This  can  be 
accomplished  through  GPS  mechanisms,  deploying  nodes 
with  deterministic  mobility  in  known  locations  and  using 
triangulation methods to compute their positions as functions 
of time, etc. Further discussion is beyond the scope of this 
paper. The locations of the nodes at a given time are known 
to  the  CHs,  but  not  necessarily  to  the  non-CH  nodes.  The 
network  could  be  stationary  or  mobile,  as  long  as  it  is 
possible  for  the  CH  to  estimate  the  positions  of  its  cluster 
nodes during decision making. The sensor nodes function in 
an  event-driven  model,  that  is,  they  sense  the  environment 
for  occurrence  of  a  particular  detection-level  event  and 
transmit  data  only  if  they  sense  such  an  event.  We  will 
assume  that  the  event  is  typically  detectable  by  multiple 
nodes, which makes our protocol practical. This assumption 
is not unreasonable for many practical sensor deployments.  
low  energy,  adaptive  hierarchical 
clustering protocol (LEACH), for cluster formation as well 
We  adopt 
the 
2
as CH election [3],[4]. This protocol architecture aids in the 
formation  of  self-organizing  clusters,  with  dynamically 
chosen  CHs.  Each  node  is  assigned  a  probability  of 
becoming  a  CH  at  the  beginning  of  each  round,  which 
depends  on  the  number  of  times  it  has  been  made  CH 
previously  and  the  energy  available  in  the  node.  These 
properties help spread energy usage equally throughout the 
network. We have also incorporated the TI of the node as an 
additional parameter to be considered for CH election. The 
TI  of  the  node  has  to  be  higher  than  a  threshold  value  to 
ensure that only sufficiently trusted nodes can become CHs. 
This is not a property of the original LEACH protocol.  
Each node independently decides if it wishes to be a CH. 
Once  a  node  decides  to  become  a  CH,  it  broadcasts  this 
information. Any node that receives advertisements from n 
different  contending  CHs,  affiliates  itself  with  a  single CH 
based on the strength of the signal received. If a node’s TI is 
below a certain threshold, the central base station will cancel 
this node’s effort to become a CH and re-initiate CH election. 
A CH that reaches the end of its leadership period sends the 
aggregate TI information that it has gathered for all nodes in 
its cluster to the base station before ending its leadership. A 
newly  CH  elected  for  an  existing  cluster  requests  the  base 
station for TI information for nodes in its cluster. 
We group event detection into two categories – binary 
event  detection  and  event  detection  with 
location 
determination.  Binary  event  detection  leads  to  the  system 
recognizing  the  occurrence  of  the  event  with  a  binary 
decision  about  whether  it  happened  or  not  and  not  being 
concerned with the location of the event. An example could 
be  detection  of  a  forest  fire  based  on  the  temperature 
reaching a critical threshold. Location determination is when 
the coordinates of the event are also reported by the sensing 
node.  In  the  forest  fire  example,  the  sensor  can  detect 
environmental  changes  such  as  wind  and  variation  in  light 
intensity  in  a  direction  and  estimate  the  location  of  the 
oncoming fire.  
2.1  Failure Model 
The  nodes  in  the  network  may  fail  due  to  accidental 
failures  or  may  be  compromised  by  an  adversary  and 
therefore exhibit failure due to malicious causes. Three types 
of failure scenarios are possible. A node may have a missed 
alarm  where  it  does  not  report  an  event  within  its  sensing 
radius to the data sink within a specified time. A node may 
provide a false alarm where it either reports an event outside 
of  its  sensing  radius  or  reports  an  event  within  its  sensing 
radius  that  did  not  occur.  A  node  may  exhibit  a  location 
faults  where  it  reports  an  event  but  at  the  wrong  location. 
Flooding  based  denial  of  service  (DoS)  attacks  are  not 
considered in this paper.  
Four categories of sensing nodes are identified. Correct 
nodes are not assumed to be 100% accurate, but are expected 
to  make  errors  within  a  specified  bound  referred  to  as 
natural error rate. Faulty nodes form the superset for nodes 
with natural or malicious failures. A faulty node can exhibit 
naïve  behavior  in  terms  of  randomly  sending  out  corrupt 
information  following  no  specific  pattern.  The  node  lies 
3
arbitrarily,  either  in  dropping  an  event  report,  falsely 
reporting an event, or reporting a faulty location (level 0). A 
smart faulty node is aware partially of the system model and 
tries  to  retain  its  TI  at  a  reasonably  high  level  where  it 
estimates it will not be detected and isolated. If a malicious 
node’s  TI  is  reaching  a  level  at  which  it  will  either  be 
dropped from the network or its vote has too little influence 
on the event decision, then the node will stop lying until its 
TI  is  raised  sufficiently.  The  smart  faulty  nodes  may  lie 
independently  (level  1)  or  in  collusion  (level  2).  The 
colluding nodes are assumed to be connected in a way that is 
undetectable by the reliable nodes in the network. 
3  Basic Design 
The goal of the TIBFIT protocol is to determine whether 
an event has occurred from analyzing reports from the event 
neighbors.  To  combat  failures  in  the  reporting  nodes,  each 
node is assigned a TI, maintained at the CH, to indicate its 
track  record  in  reporting  past  events  correctly.  The  TI  is  a 
real number between zero and one and is initially set to one. 
For each report a node makes that is deemed incorrect by the 
CH, the node’s TI is decreased. Similarly, for each report a 
node makes that is deemed correct by the CH, the node’s TI 
is increased, but not beyond one. Thus correctly functioning 
nodes  will  have  a  TI  approaching  one  while  faulty  and 
malicious nodes will have a lower TI.  
We  assume  that  correct  nodes  are  allowed  to  make 
occasional  errors  due  to  natural  causes.  The  rate  of  these 
errors  is  denoted  the  natural  error  rate  (NER).  The  TI  is 
decremented  exponentially.  Nodes  that  make  mistakes  are 
penalized  more  for  earlier  mistakes,  and  find  it  more 
difficult  to  regain  their  previous  trust  levels.  This  is 
considered better than a linear model where a node that lies 
50% of the time would still occasionally have the trust index 
value of one. If a node errs more frequently than its NER its 
index decreases, while if it errs less frequently then its index 
increases.  
The TI is calculated as follows. Let the natural error rate 
be fr (<1). A variable v is maintained for each node at the CH. 
Each time a node makes a report deemed faulty by the CH 
its v is incremented by the expression 1-fr. Each time a node 
makes  a  report  deemed  to  be  correct  by  the  CH  its  v  is 
decreased by fr if v is larger than zero. The TI is calculated 
as 
TI = e-λv 
where  λ  is  a  proportionality  constant  that  is  application 
dependent.  An  uncompromised  node’s  TI  is  expected  to 
remain at the same value. It can be expected to suffer a fault 
at  the  rate  of  one  per  every  1/fr  events  and  the  expected 
change in v is: 
E
[
∆
v
]
=
1(
−
f
r
)
−
f
r
=
0
1
f
r
−
*1
The design of the protocol is explained next by successively 
relaxing some simplifying assumptions. 
3.1  Binary Events 
Let  us  initially  assume  that  event  reports  are  binary  in 
nature simply specifying whether the event has occurred or 
not. All the nodes in the cluster, say k, are event neighbors 
for  any  event  detected  by  the  cluster.  A  sensing  node  can 
detect  the  occurrence  of  an  event  perfectly  for  events  that 
happen  within  a  radius  rs  surrounding  the  node.  All  the 
nodes  within  radius  rs  of  an  event  E  are  called  event 
neighbors for E.  
After the CH receives the first event report, it calculates 
the k event neighbors for the event. The CH then waits for a 
predefined  interval  of  time  Tout  for  event  reports  to  be 
received  from  these  nodes.  After  Tout  has  elapsed,  the  CH 
partitions the event neighbors into two sets R and NR based 
on whether they have reported the occurrence of the event or 
not,  respectively.  The  trust  indices  of  each  group  are 
summed and the group with the higher cumulative TI (CTI) 
wins  out.  The  trust  index  values  of  nodes  in  the  winning 
group are increased while the index values of nodes in the 
losing  group  are  decreased  according  to  the  formula  given 
above.  It  should  be  noted  that  a  smaller  group  of  reliable 
nodes can win the vote against a larger group of unreliable 
nodes  based  on  higher  TI  for  the  individual  reliable  nodes 
earned  over  past  events.  This  process  provides  detection, 
diagnosis, and masking of the fault.  
It is evident that we do not need a TI model for a system 
with  faulty  nodes  in  the  minority.  A  simple  voting  would 
suffice  to  mask  the decision  of  the faulty nodes. However, 
consider  a  system  where  the  density  of  faulty  nodes 
increases  over  time.  Examples  could  be  batteries  of  the 
nodes  dying  out  with  time,  or  existing  nodes  being 
compromised  by  adversaries.  The  faulty  nodes  that  have 
been  in  operation  for  a  while  would  have  had  their  TIs 
reduced to low values. Hence even when the total number of 
faulty  nodes  is  in  a  majority,  their  CTI  may  still  be  lower 
than  that  of  the  correct  nodes.  Hence,  TIBFIT  can  lead  to 
correct aggregation as well as diagnosis even with more than 
50%  of  the  nodes  compromised.  It  is  obvious  that  if  the 
initial  condition  consists  of  faulty  nodes  being  in  the 
majority, then the protocol will be unsuccessful in tolerating 
faults.  After  time,  the  system  can  identify  a  faulty  node 
when  its  TI  falls  below  a  certain  threshold.  It  can  then  be 
removed from the network.  
3.2  Location Determination 
In this section we build on the previous model by adding 
location  details  to  the  event  reports.  The  event  report 
consists  of  location  in  terms  of  (r,  Θ)  with  respect  to  that 
node.  The  nodes  do  not  sense  the  location  of  the  event 