## feature request description
The NLP community is shifting from LSTMs to Transformers for a number of NLP
tasks.  
This would be great if we could have a packed standard Transformer
implementation in the 'nn' package, i.e. a **nn.Transformer** , just like we
have a nn.LSTM.
## Code example
fairseq-py has a tested implementation of the Transformer encoder and decoder
(for LM and NMT)
https://github.com/pytorch/fairseq/blob/master/fairseq/models/transformer.py.
Wrapping this up in 'nn' should be the most straightforward approach to
reimplementing this model.
Thanks!