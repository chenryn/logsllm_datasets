## Feature Request Description

The natural language processing (NLP) community is increasingly adopting Transformers over Long Short-Term Memory (LSTM) networks for a variety of NLP tasks. It would be highly beneficial to include a standardized Transformer implementation in the `nn` package, similar to how we have `nn.LSTM`.

## Code Example

The `fairseq-py` library already provides a well-tested implementation of the Transformer encoder and decoder, which can be used for language modeling (LM) and neural machine translation (NMT). The relevant code can be found [here](https://github.com/pytorch/fairseq/blob/master/fairseq/models/transformer.py).

Integrating this implementation into the `nn` package would provide a straightforward and reliable way to use Transformers in PyTorch.

Thank you!