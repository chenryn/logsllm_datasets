installed in order to eliminate the SSL certiﬁcate pinning
protection of SIGNAL. For trafﬁc interception and manipula-
tion we used mitmproxy [17] in combination with a custom
script to automatically intercept SIGNAL messages. Two client
smartphones (Android 4.4.4) and one attacker smartphone
(Android 4.4.4) were used. The attacker smartphone (Mallory)
was preloaded with a modiﬁed version of SIGNAL to handle
intercepted messages and to forward intercepted messages
to the original recipient. The two client smartphones had
the latest version of SIGNAL installed (3.15.2). One client
smartphone was given to the study participant (Alice), the
other client smartphone was used by the operator (Bob) in
the operator room. Finally, because all smartphones shared the
same network, the smartphones connected to our attack proxy
via a ProxyDroid [18] conﬁguration. For each study participant
the devices were reset and re-registered with SIGNAL.
C. Pilot Study
We conducted a pilot study with six participants from the
authors’ research groups to reﬁne our study design before the
actual study. In our pilot study we asked users to “verify” their
communication partner. This request led to confusion as our
participants never reached SIGNAL’s veriﬁcation features and
had widely diverging understandings of the term “veriﬁcation”.
Thus no user successfully managed to compare keys. Based on
our results of the pilot study we included a brief explanation
of SIGNAL, to point participants towards SIGNAL’s technical
veriﬁcation features. Furthermore, we decided to include a
“hint”: the instructions told the participants that they could ask
for their communication partner (Bob) to enter the room at any
time. Since participants of the pre-study were unsure whether
Bob is a real person or a pre-scripted Bot, this information
was crucial to include.
IV. RESULTS
A. Participants and general Usability Results
Overall, 28 participants took part in our study (7 female,
21 male), which lasted about 30-45 minutes. All of the
participants were computer science students at the University
of Vienna, the majority of whom were enrolled in an HCI
course and recruited over that course. The only requirement
for participation in the study was experience with the Android
operating system. The students got a reward in the form of
extra points for the HCI course.
Two of the participants were 26-35 years old, the remaining
people were in the age between 18 and 25.
Nearly all of the participants actively use text messag-
ing/SMS (27) and WHATSAPP (26) as instant messaging
apps, followed by TELEGRAM (18), VIBER (8), FACEBOOK
MESSENGER (4) and KAKAOTALK (2). LINE, ANDCHAT,
SKYPE, SIGNAL, THREEMA and TANGO were used by one
participant each. Regarding self-assessment of computer secu-
rity knowledge, most of the participants said they had no or
some knowledge about privacy and security mechanisms (7
respectively 17), while 4 stated to have a lot of knowledge.
None of the participants claimed to be an expert in computer
security.
Privacy and security on smartphone apps are of importance
to the participants, and they care about third parties reading
their messages. Conﬁdentiality of text messages and active
security / privacy measures were weighted to be of average
importance. Regarding the ﬁrst usability task (in which par-
ticipants were asked to exchange a few messages with Bob
and send a picture of the lab room), six participants were only
partially able to complete the task, since SIGNAL’s interface
did not indicate whether the image had been send or not.
Those pictures were only sent at a later point. All of the
other participants were successful. In the second usability task
participants were asked to set a passphrase for the app and
import/export a backup of the app’s data. While setting the
passphrase seemed easy, six of the participants were unable
to ﬁnd the backup option. Most of the participants who failed
3
Fig. 3. Message delivery failure (1), notiﬁcation about Bob’s new identity
(2) and new identity dialogue (3)
Fig. 4.
“Verify identity” option in the conversation settings (1 & 2). Key
comparison page displaying Bob’s key at the top and Alice’s resp. the user’s
key at the bottom (3).
in this task searched for a backup list item in the preferences
section, with the wanted item being located in SIGNAL’s main
menu.
B. Users’ Reactions to the Attack
Shortly before the third task the MITM attack was
launched. After the launch of the MITM attack, messages sent
through SIGNAL were not delivered since SIGNAL’s protocol
needs mutual keys to send messages. In consequence all of the
users noticed the attack because of an error notiﬁcation next
to the undelivered message (see Figure 3), and clicked on the
notiﬁcation icon to open the error dialogue.
At this point the error dialogue already confronted the users
with the task of verifying Bob. While 24 out of 28 users read
the text in the subsequent dialogue, the remaining 4 directly
chose the “Accept” option whilst skipping the text. These
participants seemed to follow “the ﬂow” of the dialogue to
quickly reestablish messaging functionality.
Even if the participants were able to access the key
comparison page, whether from the error dialogue or later
in the task (8 users never did), the key veriﬁcation page of
SIGNAL’s Android application did not provide any instructions
on how to perform the actual veriﬁcation. As Figure 4 shows
(picture on the right), SIGNAL displays the Identity Keys
of both communication partners, but no further instructions
are provided. The participants of our study therefore faced
problems on how to use the displayed keys. One participant
e.g. stated: “. . . ok, those are keys, but what am I gonna do
with them?”.
In total 13 users asked Bob into the room during this task
for veriﬁcation, however less than half of those users managed
to successfully match keys with Bob (seven users). When
keys were correctly compared, a message about veriﬁcation
failure was raised due to the MITM attack (see Figure 2). The
error message, however, did not provide any information on
consequences, further mitigation strategies or strategy changes.
One participant thus said: “Well great, and now what?”, while
another participant told us: “To be honest. . . I have no idea
what to do now.”.
C. Mental Models of the Attack
Ideally, Alice and Bob compare their keys in person for
veriﬁcation purposes to conﬁrm their mutual identity. If Mal-
lory launched a MITM attack on their conversation, Alice and
Bob ideally recognize this type of attack, stop communicating
over SIGNAL and uninstall
the app. As previously stated,
successful MITM attacks on SIGNAL result from their central
key exchange services being compromised, Alice and Bob
thus need to stop using SIGNAL. In consequence, successful
veriﬁcation of Bob with matching keys was at no point possible
in our setup due to the MITM attack. However, 13 participants
assumed that they had successfully veriﬁed Bob in the ﬁnal
questionnaire, while they failed to correctly compare keys
with Bob. They therefore accepted Bob’s new identity and
would likely have continued to communicate over an insecure
connection since they assumed it to be secure. Those users
had different (false) veriﬁcation strategies, which we discuss in
subsection IV-C1. Seven users successfully matched keys with
Bob. Only three of those assumed some sort of attack, but did
not mention MITM in particular. Two of those users assumed
they were not chatting with Bob, but with the attacker Mallory.
Three other users thought that the app simply malfunctioned.
Thus matching of the keys did not necessarily lead to the
correct assumptions. We discuss our participants assumptions
below. The rest of the participants (eight users) did not manage
to compare keys with Bob and were unsure about having
veriﬁed Bob or knew they had not. Five of those participants
explicitly assumed a MITM attack took place. Subsequently,
not all users picked correct mitigation strategies. An overview
over strategies users would have chosen is outlined below.
1) Veriﬁcation Strategies: Out of the 13 participants who
thought to have veriﬁed Bob, but did not manage to do so by
comparing the keys, 12 came up with different veriﬁcation
strategies. 6 assumed that accepting Bob’s new key in the
error dialogue following the attack successfully veriﬁed Bob.
4 “veriﬁed” Bob by either meeting him in person or by asking
him questions about messages he received and his identity via
chat or via phone calls. One person assumed that the presence
of the keys on the key comparison page proves the authenticity
of Bob’s identity, while another person attempted to verify the
authenticity of the chat by asking Bob whether he thought the
chat was secure.
2) Assumptions about the Attack: In order to assess the
users’ assumptions about the attack we included an open ques-
tion about the “unexpected events” in the ﬁnal questionnaire.
Spoken remarks in the Think Aloud protocol were also taken
into account. Overall, 14 participants made remarks about pos-
sible explanations for the unforeseen events (multiple mentions
4
could be made). 7 participants speculated or stated that a
MITM attack could have taken place, although only one of
those participants compared keys correctly. As already stated
not all the participants who successfully compared keys made
the right assumptions about the events during the MITM attack.
Several other incorrect assumptions were drawn: 4 participants
stated that an attacker made an attempt to impersonate Bob,
thus they assumed that they had compared keys with Mallory
instead of Bob. Furthermore, 3 participants speculated that
Bob could have reinstalled SIGNAL as suggested in the error
message. Another 3 users assumed that the app was simply
malfunctioning. 2 participants ﬁnally stated that an attack
could have happened, but did not specify the type of attack.
3) Mitigation Strategies: The ﬁnal questionnaire contained
another open question about participants’ possible mitigation
strategies after the unexpected events. The type of attack was
deliberately not revealed so as not
to bias answers. Also
the users’ actions and remarks during the last study task
were considered. Several possible mitigation strategies (not
necessarily referring to MITM attacks in particular) arose from
the answers: 11 participants would simply uninstall the app
(the only valid mitigation strategy against compromise of the
server), although it was not clear whether they wanted to avoid
further hassle and would simply use another messaging app,
or whether they knew it was the recommended mitigation
strategy. Other strategies aimed at gathering more information,
such as contacting Bob on another channel via other apps,
phone or face-to-face meetings (8 participants), searching for
information on the Internet (6 participants) or asking friends
(4 participants). 3 participants would inform the developers or
read license agreements and policies (3 resp. 1 participants).
Another branch of strategies involved problem solving: restart-
ing the app (2 participants), disconnecting the phone from the
Internet (2 participants) or a virus scan (1 participant).
V. DISCUSSION
To the best of our knowledge we are the ﬁrst to study
the security, as well as usability, challenges of end-to-end-
encrypted messengers. The central services used to exchange
user keys pose the major security risk of today’s end-to-end
encrypted messengers. In our study we therefore simulate
a compromised key service by performing an active MITM
attack. Hence, we assess the usability of SIGNAL’s security
features in case of active attacks. However, like any user study,
our work has some limitations:
First, the participants recruited for the study were homoge-
neous since all were students of computer science and shared
the same age group. Similar experiments with different groups
of participants might
therefore lead to different outcomes.
Second, we had to balance the extent of information we
provided to participants on SIGNAL’s encryption/veriﬁcation
features. We decided to explicitly ask users to verify each
other in order to asses the usability of this core-security feature
of SIGNAL. Our initial study design tested in our pilot study
showed that none of the six participants used the veriﬁcation
feature in the face of our simulated attack. Similar experiments
with participants without a computer science background and
without a focus on a security subtask would likely result in
even less successful key veriﬁcations.
Overall, we were surprised by the outcome of our study,
especially given the fact that our participants had a computer
science background. Our results suggest that the “veriﬁcation”
process and therefore the overall security of end-to-end en-
cryption on mobile instant messaging faces serious usability
obstacles, since 21 of our 28 participants failed to properly
compare keys with their conversational partner. Especially
surprising in our study was the high number of participants
who thought they had successfully veriﬁed while in reality
they failed to compare keys.
SIGNAL, as an easy-to-use end-to-end encryption enhanced
app, should support struggling users to achieve security in
the sense of increased usable security. Usability problems, in
terms of missing support, can lead to serious security breaches,
e.g. aborting the reestablishment of a secure connection after
an attack. The gaps between self-assessment, mental models
of differing correctness respectively level of detail as well as
actual outcome (un/successful defense) could be explained in
several ways: Either participants lacked the required knowl-
edge, the app failed to support the users, they simply had
a different understanding of what “veriﬁcation” meant or the
effort for successful defense was simply too high. During the
MITM attack, SIGNAL was explicitly hinting at the fact that
the connection could have been compromised. The fact that
only 7 participants assumed the possibility of a MITM attack