be communicated. Foreshadow overcomes this limitation
by explicitly (re-)establishing 4 TLB entries for each
oracle slot. In addition we need to ensure that none of the
oracle slot entries are already present in the processor’s
cache. We achieve both requirements simultaneously by
issuing a clflush instruction for all 256 oracle slots.
Finally, we execute 5 the transient instruction se-
quence displayed in Listing 1. We provide a line-per-line
translation to the equivalent C code in Listing 2. When
called with a pointer to the oracle buffer and secret_ptr,
the secret value is read at Line 5. As we made sure to
mark the enclave page as not present, SGX’s abort page
semantics no longer apply and a fault will eventually be
issued. However, the transient instructions at Lines 6–7
will still be executed and compute the secret-dependent
location of a slot v in the oracle buffer before fetching it
from memory.
Phase III: Receiving the Secret. Finally when the pro-
cessor determines that it should not have speculatively
executed the transient instructions, uncommitted register
changes are discarded and a page fault is issued. After
the fault is caught by the operating system, the attacker’s
user-level exception handler is called. Here, she carefully
measures 6 the timings to reload each oracle slot to es-
tablish the secret enclave byte. If the transient instruction
after passing the address translation process. We experimentally veriﬁed
that such faults can be successfully exploited by an attacker enclave that
transiently dereferences a victim enclave’s pages via a malicious mem-
ory mapping. Future mitigations (Section 6) should therefore decisively
also take this microarchitectural exploitation path into account.
1 foreshadow:
2 # %rdi: oracle
3 # %rsi: secret_ptr
4
5 movb (%rsi), %al
6
7 movq (%rdi, %rax), %rdi
8
shl $12, %rax
retq
3
4 {
5
6
7
8 }
1 void foreshadow(
2
uint8_t ∗oracle,
uint8_t ∗secret_ptr)
uint8_t v = ∗secret_ptr;
v = v ∗ 0x1000;
uint64_t o = oracle[v];
Listing 1: x86 assembly.
Listing 2: C code.
sequence reached the execution at Line 7, the oracle slot
at the secret index now resides in the CPU cache and will
experience a signiﬁcantly shorter access time.
3.2 Reading Full Cache Lines
The basic Foreshadow attack of the previous section leaks
sensitive information while only leveraging the capabil-
ities of a conventional user space attacker. But as SGX
also aims to defend against kernel-level attackers, this
section presents various optimization techniques, some of
which assume root access (when indicated). In Section 4
we will show that these optimizations increase the band-
width plus reliability of our attack, enabling us to extract
complete cache lines from a single enclaved execution.
All of our optimization techniques share a common
goal. Namely, increasing the likelihood that we do not
destroy secrets as part of the measurement process. That
is, an adversary executing Phases II and III of the basic
Foreshadow attack should avoid inadvertently evicting en-
clave secrets that were originally brought into the L1 CPU
cache during the enclaved execution in Phase I. We par-
ticularly found that repeated context switches and kernel
code execution may unintentionally evict enclave secrets
from the L1 cache. When this happens, the transient ex-
ecution invariably loses the Meltdown race condition —
effectively closing the attack window before the oracle
slot is cached. Evicting enclave cache lines in this manner
not only destroys the current measurement, but also eradi-
cates the possibility to extract additional bytes belonging
to the same cache line without executing the enclave again
(Phase I). We therefore argue that minimizing cache pol-
lution is crucial to successfully extract larger secrets from
a single enclaved execution.
Page Aliasing (Root). When untrusted code accesses
enclave memory, abort page semantics apply and secrets
do not reach the transient execution. The basic Fore-
shadow attack avoids this behavior by revoking all access
rights from the enclave page through the mprotect in-
terface. However, as enclaved execution also abides by
page table-based access restrictions [58, 60], these privi-
USENIX Association
27th USENIX Security Symposium    997
That is, accessed oracle slots remain in the L1 cache.
Note that, while readily available on many processors,
TSX is by no means the only fault suppression mechanism
that attackers could leverage. Alternatively, as previously
suggested [24,40], the instruction dereferencing the secret
could also be speculatively executed itself, behind a high-
latency mispredicted branch. As a true hybrid between
Spectre [36] and Meltdown [40], such a technique would
deliberately mistrain the CPU’s branch predictor to ensure
that none of the instructions in Listing 1 are committed to
the architecture, and hence no faults are raised.
Keeping Secrets Warm (Root). Context switches to
kernel space are not the only sources of cache pollution.
In Phase III of the attack the access time to each oracle
slot is carefully measured. As each slot is loaded into
the cache, enclave secrets might get evicted from the L1
cache. To make matters worse, oracle slots are placed
4 KiB apart to avoid false positives from the cache line
prefetcher [26]. All 256 oracle slots thus share the same
L1 cache index and map to the same cache set.
We present two novel techniques to decrease pressure
on cache sets containing enclave secrets. First, root adver-
saries can execute the privileged wbinvd instruction to
ﬂush the entire CPU cache hierarchy before executing the
enclave (Phase I). This has the effect of making room in
the cache, such that non-enclave accesses to the cache set
holding a secret can be more likely accommodated in one
of the vacant ways. Second, for unprivileged adversaries,
instead of calling the transient execution Phase II once,
we execute it in a tight loop as part of the measurement
process (Phase III). That is, by transiently accessing the
enclave secret each time before we reload an oracle slot,
we ensure the cache line holding the secret data remains
“warm” and is less likely to be evicted by the CPU’s least
recently used cache replacement policy. Importantly, as
both techniques are entirely implemented in the untrusted
application runtime, we do not need to make additional
calls to the enclave (Phase I).
Isolating Cores (Root). We found overall system load
to be another signiﬁcant source of cache pollution. Intel
architectures typically feature an inclusive cache hierar-
chy: data residing in the L1 cache shall also be present
in the L2 and L3 caches [27]. Unfortunately, maintain-
ing this invariant may lead to unexpected cache evictions.
When an enclaved cache line is evicted from the shared
last-level L3 cache by another resource-intensive process
for instance, the processor is forced to also evict the en-
clave secret from the L1 cache. Likewise, since L1 and
L2 caches are shared among logical processors, cache
activity on one core might unintentionally evict enclave
secrets on its sibling core.
Figure 3: The physical enclave secret is mapped to an
inaccessible virtual address for transient dereference.
leges can only be revoked after the enclave call returned.
Unfortunately, we found that the mprotect system call
exerts pressure on the processor’s cache and may cause
the enclave secret to be evicted from the L1 cache.
We propose an inventive “page aliasing” technique to
avoid mprotect cache pollution for root adversaries. Fig-
ure 3 shows how our malicious kernel driver establishes
an additional virtual-to-physical mapping for the physical
enclave location holding the secret. As caches on modern
Intel CPUs are physically tagged [27], memory accesses
via the original or alias pages end up in the exact same
cache lines. That is, the aliased page behaves similarly to
the original enclaved page; only an additional page table
walk is required for address translation. We evade abort
page semantics for the alias page in the same way as in the
basic Foreshadow attack, by calling mprotect to clear
the present bit in the page table. Importantly, however,
we can now issue mprotect once in Phase I of the at-
tack, before entering the enclave. For the aliased memory
mapping is never referenced by the enclave itself.
Fault suppression. A second substantial source of
cache pollution comes from the exception handling mech-
anism. Speciﬁcally, after executing the transient instruc-
tion sequence in Phase II of the attack, the processor deliv-
ers a page fault to the operating system kernel. Eventually
the kernel transfers execution to our user-level exception
handler, which receives the secret (Phase III). At this
point, however, enclave secrets and/or oracle slots may
have already been unintentionally evicted.
We leverage the Transactional Synchronization eXten-
sions (TSX) included in modern Intel processors [27] to
silently handle exceptions within the unprivileged attacker
process. Previous research [9, 40, 53, 54] has exploited
an interesting feature of Intel TSX. Namely, a page fault
during transactional execution immediately calls the user-
level transaction abort handler, without ﬁrst signalling
the fault to the operating system. We abuse this property
to avoid unnecessary kernel context switches between
Phases II and III of the Foreshadow attack by wrapping
the entire transient instruction sequence of Listing 1 in
a TSX transaction. While the transaction’s write set is
discarded, we did not notice any difference in the read set.
998    27th USENIX Security Symposium
USENIX Association
In order to limit such effects, root adversaries can pin
the victim enclave process to a speciﬁc core, and ofﬂoad
interrupts as much as possible to another physical core.
Dealing with Zero Bias. Consistent with concurrent
work on Meltdown-type vulnerabilities [15, 24, 40, 42],
we found that the processor zeroes out the result of unau-
thorized memory reads upon encountering an exception.
When this nulling happens before the transient out-of-
order instructions in Phase II can operate on the real se-
cret, the attacker loses the internal race condition from the
CPU’s access control logic. This will show up as reading
an all-zeroes value in Phase III. To counteract this zero
bias, Foreshadow retries the transient execution Phase II
multiple times when receiving 0x00 in Phase III, before
decisively concluding the secret byte was indeed zero.
Since Foreshadow’s transient execution phase critically
relies on the enclave data being in the L1 cache, we con-
sistently receive 0x00 bytes from the moment a secret
cache line was evicted from the L1 cache. As such, the
processor’s nulling mechanism also enables us to reliably
detect whether the targeted enclave data still lives in the
L1 cache. That is, whether it still makes sense to proceed
with Foreshadow cache line extraction or not.
3.3 Preemptively Extracting Secrets
As explained above, Foreshadow’s transient extraction
Phase II critically relies on secrets brought into the L1
cache during the enclaved execution (Phase I). In the basic
attack description, we assumed secrets are available after
programmatically exiting the enclave, but this is often
not the case in more realistic scenarios. Secrets might be
explicitly overwritten, or evicted from the L1 cache by
bringing in other data from other cache levels.
To improve Foreshadow’s temporal resolution, we
therefore asynchronously exit the enclave after a secret
in memory was brought into the L1 cache, and before
it is later overwritten/evicted. We ﬁrst explain how root
adversaries can combine Foreshadow with the state-of-
the-art SGX-Step [57] enclave execution control frame-
work to achieve a maximal temporal resolution: memory
operands leak after every single instruction. Next, we
re-iterate that even unprivileged adversaries can pause
enclaves at a coarser-grained 4 KiB page fault granular-
ity [59, 60] through the mprotect system call interface.
Using this capability, we contribute a novel technique that
allows unprivileged Foreshadow attackers to reliably in-
spect private CPU register contents of a preempted victim
enclave.
Single-Stepping Enclaved Execution (Root). SGX
prohibits obvious interference with production enclaves.
Speciﬁcally, the processor ignores advanced x86 debug
features, such as hardware breakpoints or the single-step
trap ﬂag (RFLAGS.TF) [27]. We therefore rely on the re-
cently published open-source SGX-Step [57] framework
to interrupt the victim enclave instruction per instruction.
SGX-Step comes with a Linux kernel driver to estab-
lish convenient user space virtual memory mappings for
the local Advanced Programmable Interrupt Controller
(APIC) device. A very precise single-stepping technique
is achieved by conﬁguring the APIC timer directly from
user space, eliminating any noise from kernel context
switches. Carefully selecting a platform-speciﬁc APIC
timer interval ensures that the interrupt reliably arrives
within the ﬁrst instruction after eresume.
Dumping Enclaved CPU Registers. Section 2.1 ex-
plained how SGX securely stores the interrupted enclave’s
register contents in a preallocated SSA frame as part of
the AEX microcode procedure. By targeting SSA enclave
memory, a Foreshadow attacker can thus extract private
CPU register contents. For this to work, however, the SSA
frame data of interest should reside in the processor’s L1
cache. The entire SSA frame measures multiple cache
lines, with the general purpose register area alone already
occupying 144 bytes (2.25 cache lines). These SSA cache
lines could be unintentionally evicted as part of the kernel
context switches needed to handle interrupts, or during
Foreshadow’s transient extraction Phases II and III.
We contribute an inventive way to reliably extract com-
plete SSA frames. By revoking execute permissions on
the victim enclave’s code pages, the unprivileged applica-
tion context can provoke a page fault on the ﬁrst instruc-
tion after completing eresume. No enclaved instruction
is actually executed, and register contents thus remain un-
modiﬁed, but the entire SSA frame is re-ﬁlled and brought
into the L1 cache as a side effect of the AEX procedure
triggered by the page fault. We abuse such zero-stepping
as an unlimited prefetch mechanism for bringing SSA
data into the L1 cache. Before restoring execute permis-
sions, a Foreshadow attacker reads the full SSA frame
byte-per-byte, forcing the enclave to zero-step whenever
an SSA cache line was evicted (i.e., read all zero).
Together with a precise interrupt-driven or page fault-
driven enclave execution control framework, our SSA
prefetching technique allows for an accurate dump of the
complete CPU register ﬁle as it changes over the course
of the enclaved execution.
3.4 Concurrently Extracting Secrets
In modern Intel processors with HyperThreading tech-
nology, the L1 cache is shared among multiple logical
processors [27]. This property has recently been abused
to mount stealthy SGX PRIME+PROBE L1 cache side-
USENIX Association
27th USENIX Security Symposium    999
channel attacks entirely from a co-resident logical proces-
sor, without interrupting the victim enclave [6, 17, 51].
We explored such a stealthy Foreshadow attack mode
by pinning a dedicated spy thread on the sibling logical
core before entering the victim enclave. The spy thread
repeatedly executes Foreshadow in a tight loop to try and
read the secret of interest. As long as the secret is not
brought into the L1 cache by the concurrently running
enclave, the spy loses the CPU-internal race condition.
This shows up as consistently reading a zero value. We
use this observation to synchronize the spy thread. As
long as a zero value is being read, the spy continues to
transiently access the ﬁrst byte of the secret. When the
enclave ﬁnally touches the secret, it is at once extracted
by the concurrent spy thread.
This approach has considerable disadvantages as
compared to the above interrupt-driven attack variants.