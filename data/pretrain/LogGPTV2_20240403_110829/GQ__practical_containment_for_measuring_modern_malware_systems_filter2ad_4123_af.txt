Systems (TOCS), 18(3):263–297, 2000.
[17] C. Kolbitsch, T. Holz, C. Kruegel, and E. Kirda. Inspector
Gadget: Automated extraction of proprietary gadgets from
malware binaries. In 2010 IEEE Symposium on Security and
Privacy, pages 29–44. IEEE, 2010.
[18] C. Kreibich, C. Kanich, K. Levchenko, B. Enright, G. M.
Voelker, V. Paxson, and S. Savage. On the Spam Campaign
Trail. In Proceedings of the First USENIX Workshop on
Large-scale Exploits and Emergent Threats (LEET), San
Francisco, USA, April 2008.
[19] C. Kreibich, C. Kanich, K. Levchenko, B. Enright, G. M.
Voelker, V. Paxson, and S. Savage. Spamcraft: An inside
look at spam campaign orchestration. In Proceedings of the
Second USENIX Workshop on Large-scale Exploits and
Emergent Threats (LEET), Boston, USA, April 2009.
[20] N. McKeown, T. Anderson, H. Balakrishnan, G. Parulkar,
L. Peterson, J. Rexford, S. Shenker, and J. Turner. OpenFlow:
Enabling Innovation In Campus Networks. ACM SIGCOMM
Computer Communication Review, 38(2):69–74, 2008.
[21] B. Miller, P. Pearce, C. Grier, C. Kreibich, and V. Paxson.
What’s Clicking What? Techniques and Inovations of
Today’s Clickbots. In Conference on Detection of Intrusions
and Malware & Vulnerability Assessment (DIMVA).
Springer, July 2011.
[22] J. Mirkovic, T. V. Benzel, T. Faber, R. Braden, J. T.
Wroclawski, and S. Schwab. The DETER project:
Advancing the science of cyber security experimentation and
test. In IEEE Intl. Conference on Technologies for Homeland
Security (HST), page 7, November 2010.
[23] Norman ASA. Norman SandBox. http://www.norman.
com/security_center/security_tools/.
[24] V. Paxson. Bro: A System for Detecting Network Intruders
in Real-Time. Proceedings of the 7th USENIX Security
Symposium, pages 31–51, 1998.
[25] A. Pitsillidis, K. Levchenko, C. Kreibich, C. Kanich,
G. Voelker, V. Paxson, N. Weaver, and S. Savage. Botnet
Judo: Fighting Spam with Itself . In Proceedings of the 17th
Annual Network and Distributed System Security Symposium
(NDSS), San Diego, CA, USA, March 2010.
[26] J. Postel. Simple Mail Transfer Protocol. RFC 821, August
1982.
[27] G. Tenebro. W32.Waledac Threat Analysis.
http://www.symantec.com/content/en/us/
enterprise/media/security_response/
whitepapers/W32_Waledac.pdf, 2009.
[28] N. Villeneuve. Koobface: Inside a Crimeware Network.
http://www.infowar-monitor.net/reports/
iwm-koobface.pdf, November 2010.
[29] M. Vrable, J. Ma, J. Chen, D. Moore, E. Vandekieft,
A. Snoeren, G. Voelker, and S. Savage. Scalability, ﬁdelity,
and containment in the potemkin virtual honeyfarm. ACM
SIGOPS Operating Systems Review, 39(5):148–162, 2005.
[30] Y. Wang, D. Beck, X. Jiang, and R. Roussev. Automated
Web Patrol with Strider Honeymonkeys: Finding Web Sites
that Exploit Browser Vulnerabilities. In Proceedings of the
13th Annual Network and Distributed System Security
Symposium (NDSS), San Diego, CA, USA, March 2006.
[31] C. Willems, T. Holz, and F. Freiling. Toward automated
dynamic malware analysis using CWSandbox. IEEE Security
& Privacy, pages 32–39, 2007.
408Summary Review Documentation for 
“GQ: Practical Containment for Measuring Modern Malware 
Systems” 
Authors: C. Kreibich, N. Weaver, C. Kanich, W. Cui, V. Paxson 
Reviewer #1 
Strengths:	GQ is very useful for studying malware. The authors 
discuss some experiences from operating the farm for six years, 
which could be interesting for future farm developers.  
Weaknesses:  The  work  does  not  provide  new  insights  into  the 
design  of  containment  policies.  The  main  take-away  message  is 
that  policies  should  be  implemented  manually  from  a  deny-all 
starting  point,  which  does  not  add  something  new.  The  paper 
focuses  heavily  on  GQ  implementation  and  configuration  low-
level details. It was not clear what research challenges this work 
addresses. 
Comments to Authors: At some points I felt the paper reads a bit 
like  a  software  configuration/implementation  guide.  The  authors 
should  try  to  make  it  more  interesting  to  read,  perhaps,  by 
explaining  better  the  challenges  they  address  and  their  design 
options/choices.  
Previous  work  [Botlab]  found  the  problem  of  containment 
intractable because allowing even a benign msg could cause third-
party  bots  to  transmit  harmful  traffic.  I  wonder  what  is  the 
opinion of the authors, is the problem really intractable? I do not 
see how GQ solves this problem.  
The  authors  mention  “GQ  [...]  making  containment  policy 
development  a  natural  component  of  the  malware  analysis 
process”. It would be nice if it was a bit more clear what “natural 
component” means.  
In  Section  4,  I  didn’t  understand  what  the  paper  means  with 
“separation of policy with mechanism”. Is the point that the two 
entities  should  be  physically  separated 
to  avoid  resource 
contention?  
In  the  conclusion  the  authors  talk  about  “flexible  and  precise” 
containment  policies,  but  there  is  almost  nothing  in  the  paper 
about containment policies. 
Reviewer #2 
Strengths: The design is excellent and demonstrates the authors’ 
familiarity  with  practical,  real-world  malware  analysis.  The 
platform seems versatile enough to study most kinds of existing 
malware at the level of detail that is required while maintaining 
fine control over the damage that the malware can inflict upon the 
world at large. 
Weaknesses:  The  need  for  rigor  in  designing  a  containment 
platform is somewhat lessened by the fact that malware analysis 
is still going to be a very manual process. Moreover, the evolution 
of  their  platform  is  an  indicator  that  the  authors  are  stuck  in an 
arms race; the publication of this work could make the work itself 
obsolete. 
Comments to Authors: The GQ platform is quite impressive and 
I  have  no  complaints  about  the  technical  contributions  of  the 
paper.  The  weaknesses  I  mentioned  above  are  a)  acknowledged 
by the authors, and b) fundamental to the problem space. 
The  title  and  the  text  are  a  bit  mismatched.  The  title  involves 
“practical”,  yet  “practical”  does  not  appear  in  the  paper.  What 
makes GQ “practical”? Conversely, the text asserts a “principled 
approach” to containment policies, yet then fails to describe any 
actual “principles”. Perhaps there is a methodology... Or perhaps 
the principles are described and the reader is supposed to figure 
out  that  this  constitutes  a  “principled  approach”.  However,  it 
seems an unnecessary oversell of an engineering feat, as well as 
an implied knock against prior work that seems no less principled, 
and  I  am  disappointed  by  it.  Eventually,  in  the  conclusion,  the 
authors admit “[GQ] provides the basis for a principled approach 
to containment policy development” -- which appears to be a step 
back from the principled approach promised in the introduction.  
As  someone  relatively  unfamiliar  with  malware  research,  I 
wonder  just  what  having  GQ  will  provide  malware  researchers, 
given  that  each  piece  of  malware  still  requires  so  much  manual 
analysis. Is it helpful for avoiding causing external damage? The 
section “Mysterious blacklisting” suggests that mistakes can still 
be made and that human error is still a substantial hurdle. There’s 
no  clear  metric  for  measuring  how  much  easier  it  is  to  safely 
analyze  malware  with  GQ  than  without,  and  the  results  are  all 
anecdotal.  
The  paper  could  be  a  bit  more  readable.  Section  6  (6.2  in 
particular)  was perhaps too detailed to be interesting, unlike the 
rest  of  the  paper.  Section  8  was  particularly  important;  it 
answered a lot of questions that I had lingering in my head since 
the introduction, so I feel like it should really be moved closer to 
the  introduction  if  possible.  The  last  sentence  in  section  8  is 
accurate, insightful, and deeply troubling. 
Reviewer #3 
Strengths: The paper presents a real system that does something 
useful and challenging. The design is nice. 
Weaknesses:  However,  it  does  not  introduce  any  new  ideas,  or 
bring any new understanding to how malware works. Also, I think 
that  it  promises  more  than  it  delivers  (but  this  is  a  matter  of 
presentation). 
Comments  to  Authors:  There  is  no  denying  that  the  presented 
system  is  useful.  Also,  assigning  the  implementation  of  the 
409containment policies to separate containment servers sounds like a 
great  design  choice  that  would  make  it  significantly  easier  to 
experiment with new policies.  
But, despite appreciating all the hard and useful work done by the 
authors, it is not clear how this paper advances the state of the art. 
As  far  as  I  can  tell,  the  design  does  not  include  any  novel 
technique.  The  resulting  system  still  requires  manual  trial  and 
error to determine what containment policy to use for each flow. 
The results that the authors obtained using this system have been 
published in separate reports.  
A complaint regarding presentation: Imo, the paper overclaims. In 
particular,  the  title  talks  about  *practical*  containment;  I  don’t 
think  that  manual  trial  and  error  qualifies  as  practical.  The 
introduction  talks  about  “principled  containment”,  which  made 
me  expect  a  set  of  principles  that  would  guide  researchers  in 
choosing containment policies; the only principle advocated in the 
paper is to separate containment policy from enforcement.  
A  couple  of  minor  questions:  In  Section  5.5,  why  is  the  inmate 
controller  located  centrally  on  the  gateway?  Couldn’t  it  be 
implemented on a separate server? In the same section, it says that 
subfarms have their own containment servers, “thereby providing 
subfarm-specific  containment  policies.”  I  found  this  statement 
confusing.  It  implies  that  you  would  need  separate  servers  to 
implement separate policies, which is not the case, right? 
Reviewer #4 
Strengths:  Great  topic,  important  for  the  community.  Major 
questions  are  covered:  architecture,  implementation,  lessons 
learned / creation of policies. 
Weaknesses: Not enough information shared on past containment 
policies.  Didn’t  explain  how  this  is  different  from  your  past 
publications  (e.g.  reference  9).  Didn’t  cover  performance 
implications. 
Comments to Authors: Nice paper! Containment is indeed seen 
as a chore and it is great to bring attention to this issue. I’m not 
sure if I’m convinced that it will no longer be a chore with your 
system,  but  at  least  containment  will  be  easier  to  do  and  be 
implemented in a well thought manner.  
Did you think about whether it would make sense to release the 
tool (e.g. gateway + containment server) to the community?  
The  only  disappointment  is  that  I  was  hoping  to  see  more  info 
about the past containment policies that you have used. It’s great 
though  to  see  your  last  section  on  recommendations  about  the 
creation of containment policies.  
While this paper contains new material, you are still expected in 
your  reference  section  to  explain  how  your  work  is  not  only 
different  from  the  work  of  other  people,  but  also  how  this  is 
different from your 2006 paper (reference 9).  
In terms of readability, I had some difficulties at the beginning to 
separate  the  role  of  the  containment  server  from  the  role  of  the 
gateway and understand how they communicate. You cover this 
later in the paper, but you should already mention earlier in the 
paper, that you will cover how they communicate.  
Could you also explain what is the impact of your system on the 
performance  of  the  communications?  e.g.  how  much  delay  is 
added? 
Reviewer #5 
Strengths:  The  paper  presents  a  long  running  deployment 
experiment  of  a malware measurement and containment system. 
The system has been operational for the last 5 years, and there are 
many useful insights presented in the work. 
Weaknesses:  The  evaluation  and  anecdotal  part  of  the  system 
was a little light --- for a 5 year study, I would have expected the 
measurement part to be particularly central to the paper. Instead 
the authors present such operational experience in about 3 pages 
in this 14 page paper. 
Comments  to  Authors:  I  thought  the  problem  domain  and  the 
proposed  solution  was  quite  an  important  one.  Clearly  the 
approach proposed in this paper is a useful one and continues to 
have  significant  impact  in  the  world  of  network  security.  There 
were some interesting nuggets presented in the paper, e.g., their 
system  got  blacklisted  in  June  2009,  which  they  subsequently 
fixed.  
Since I do not have strong expertise in this area, I am unable to 
judge  the  relative  novelty  of  the  contributions.  However,  given 
this is a measurement paper, I was surprised at the lightness of the 
measurement  results  presented.  There  were  a  few  interesting 
nuggets  mentioned,  but  the  paper  seems  much  more  about  a 
potential  system  design  and  less  about  the  measurement  study 
itself. 
Response from the Authors 
Multiple  reviewers  suggested  that  the  research  question  we 
address  is  unclear,  and  that  technically  the  paper  provides  little 
new.  We offer in response that we view the main contribution to 
be  that  GQ  makes  containment  *development*  (as  opposed  to 
relying  on  preconceived,  fixed  filtering  policies)  a  first-grade 
component of the malware experimentation process. 
To  address  Reviewer  #1’s  concerns,  we  have  expanded  our 
commentary  on  the  theoretical  intractability  of  the  containment 
problem,  which  we  originally  only  mentioned  in  passing  at  the 
end of the paper.  We have also clarified what we mean by policy 
development becoming a “natural component”. 
We acknowledge Reviewer #2’s criticism that even given GQ, the 
containment  development  process  remains  largely  manual.   As 
stated in the paper, we do not think this is necessarily a bad thing. 
 In many situations one needs to understand what the monitored 
malware is doing.  We think the task of iteratively developing a 
suitable  containment  policy  is  in  fact  a  natural  way  for  gaining 
this understanding, at least until binary analysis tools that strive to 
extract 
semantics  of  malware  executables  become 
significantly more powerful.  We have strengthened this argument 
in  the  paper.   We  regret  that  this  reviewer  (and  also,  in  part, 
Reviewer  #3)  perceived  that  we  overstated  the  degree  to  which 
GQ  makes  developing  containment  policies  principled  and 
practical.  Our main perspective is that it does so in relative terms 
the 
410compared with existing work/approaches; we recognize that there 
is a good ways to go in absolute terms. 
Regarding  Reviewer  #4’s  question  as  to  whether  we  would 
consider  releasing  gateway  and  containment  server  code  to  the 
community,  we 
in  our 
experience malware execution platforms differ substantially, and 
it  would  likely  be  hard  to  make  our  code  work  in  a  variety  of 
environments.  In addition, we lack the support to commit to the 
maintenance necessary for such a public release to be effective. 
indeed  considered 
this. 
 However, 
We have improved our treatment of related work, as requested by 
Reviewer  #4,  and  clarified  the  distinction  of  gateway  and 
containment server. 
Regarding Reviewer #5’s comments, we would like to say that we 
felt  the  way  in  which  the  current  GQ  architecture  *enables* 
policy development is more important than reporting in detail on 
past  containment  policies,  which  by  the  very  nature  of malware 
turn out to be quite individual and generally ephemeral. 
Finally,  we  have  improved  wording  throughout  the  paper, 
hopefully addressing various reviewer requests for clarification. 
411