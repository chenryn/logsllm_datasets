While some spurious login submissions may make it through
these ﬁltering mechanisms, we assume for simplicity below
that our instrumentation is only monitoring legitimate login
attempts. Note that this is a conservative assumption: if the
data we collected contains illegitimate login attempts, then
the true rate of correctable typos for legitimate users would
be even higher. Our security analyses (Section VI) will not
make such assumptions.
Instrumentation. We modiﬁed the Dropbox password check-
ing code to perform additional checks on all legitimate login
attempts on the web interface. This provided a vast amount of
data, and it eliminated biases that could arise from selecting
some small percentage of accounts. This also made visible
multiple password submissions from a single user, which was
necessary for timing re-tries.
During the period of measurement, every password sub-
mission was processed as follows. If the password check
passed, do nothing. Otherwise, if it failed, apply one or more
typo corrections from some predeﬁned corrector function set
C = {f1, f2, . . . , fc} where corrector functions were deﬁned in
the last section. We used slightly different sets of correctors in
different experiments, as discussed below. One or more of the
corrected version(s) of the password are checked. For failed
login attempts, a log entry was generated that contained a
time stamp, whether login would have been successful with a
correction of the password, the type of correction fi that was
successful (if applicable), and the user agent string.
We emphasize that in our experiments login is not allowed
based on the corrected passwords. We did not modify Drop-
box’s effective login checks; we only collected the data needed
to evaluate whether doing so would be beneﬁcial.
Typos and login failure rates.
In an initial experiment
we set out
to measure the incidence rate of the top ﬁve
corrections seen in the MTurk study of Section III. Thus
for this experiment the set of corrector functions is Ctop5 =
{swc-all, swc-ﬁrst, rm-last, rm-ﬁrst, n2s-last}. For each in-
strumented failed password submission, one correction from
Ctop5 was chosen uniformly at random and applied to the
submitted password. The reason is that, in the current imple-
mentation, only sequential code is easily supported, and the
password hashing scheme used at Dropbox is (by design) slow
to compute. It was unclear a priori exactly what overhead the
additional checks would have on Dropbox infrastructure, and
so we conservatively only performed one additional check at
a time. The success of this initial experiment suggested the
performance impact was low, and later experiments applied
multiple corrections (see below). We collected information
over a 24-hour period.
We cannot report on the exact number of login attempts dur-
ing this period, as this is considered conﬁdential information
by Dropbox. We will therefore report only rates of success and
failure. In the following, we let cf denote the number of times
a corrector f was applied to an incorrect password during an
experiment. We let rf be the number of times f successfully
corrected an incorrect password during the experiment. The
ratio rf /cf gives the percentage of login failures correctable
by f.
The left ﬁgure of Figure 3 reports the measured ratios rf /cf
for each corrector in Ctop5 in during the 24-hour period. This
reveals that 9.3% of failures are due to typos correctable
by Ctop5, suggesting that typos indeed account for a signif-
icant number of failed (legitimate) password submissions3.
By correction type, we see that the most common correction
(switching the case of the ﬁrst character) accounts for 60% of
these, and the ﬁrst three (switching the case of all characters,
just the ﬁrst character, dropping the last character) account
for over 90% of these. Apparently capitalization errors are a
signiﬁcant source of errors, which provides evidence for why
Facebook accepts these typos.
Some disparity with the MTurk results is apparent. While
the top three of these ﬁve correctors are the same, the ordering
is distinct, with caps-lock errors proportionally higher in
MTurk then here. We believe this is due to the MTurk exper-
3We can add the fractions of typos because our correctors are mutually
exclusive.
805805
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:18:05 UTC from IEEE Xplore.  Restrictions apply. 
Corrected by (f)
swc-all
swc-ﬁrst
rm-last
rm-ﬁrst
n2s-last
Ctop5
rf /cf (%)
1.13
5.56
2.05
0.35
0.21
9.30
)
f
c
/
f
r
(
d
e
t
c
e
r
r
o
c
s
e
r
u
l
i
a
f
f
o
%
6
5
4
3
2
1
0
Desktop
Mobile
s
t
p
m
e
t
t
a
s
r
e
s
u
n
i
g
o
l
f
o
n
o
i
t
c
a
r
F
e
l
p
i
t
l
u
m
/
w
swc-all swc-ﬁrst
rm-last
rm-ﬁrst n2s-last
Corrector f
1
0.8
0.6
0.4
0.2
100
101
Time delay (s)
102
Fig. 3: (Left) The fraction of failed logins correctable by Ctop5 in a 24-hour study at Dropbox. (Middle) Performance of
Ctop5 on mobile versus desktop. For each corrector in Ctop5 we plot the fraction of failures for each platform correctable by
the corrector. (Right) CDF of time delay (in seconds) between the ﬁrst failed login due to a typo and ﬁrst successful login.
Included are only users that had a failed login attempt and later a successful one.
iment design, and that the Dropbox numbers more accurately
reﬂect rates in operational environments.
While collecting this data, we recorded the user agent for
all password submissions, so we were able to analyze the
performance of typo correction on mobile platforms versus
desktop platforms. We found that the estimated correction
rate for mobile was slightly higher at 10.5%, compared to
9.3% for desktop (calculated here with the denominator being
the number of rejected password submissions for mobile and
desktop, respectively). We show,
in the middle ﬁgure of
Figure 3, the estimated correction rates for each user agent
broken down by corrector function. We see that n2s-last is a
signiﬁcantly more effective correction on mobile, which may
be because mobile keyboards require switching to an alternate
keyboard to reveal symbols. We also see that swc-all is a more
effective correction on desktop, most likely because it’s easier
to leave caps lock enabled on conventional keyboards.4 This
dichotomy suggests the potential merit of applying different
correction policies on the server based on the user agent. We
leave the further analysis of this for future work.
Utility of the top three corrections. We perform a second
study that restricts attention to just
top three
correctors Ctop3 = {swc-all, swc-ﬁrst, rm-last} observed in
the previous study (and, in turn, the MTurk experiments).
For this experiment,
three
correctors to any password that failed to exactly match the
registered password. So, now cf is the number of failed login
attempts for every f ∈ Ctop3. As before, we recorded data for
24 hours.
the instrumentation applied all
the overall
We additionally recorded the time duration for a login
attempt to succeed. That is the time lag between the ﬁrst failed
submission and the ﬁrst successful submission by each user in
this 24-hour period. (Because Dropbox uses session cookies
most users typically need to successfully login only once per
24-hour period.) This allowed us to quantify the time delay
4On Android devices, enabling caps lock requires pressing and holding the
shift button, and on iPhone devices one has to double press the shift button
to enable caps lock.
between failures and successes, a measure of how much utility
is lost due to usability issues such as typos.
As we would expect, the success rate of corrections closely
matched the results of the previous 24-hour experiment.
Speciﬁcally, typos correctable by Ctop3 accounted for 9% of
failed password submissions. This also attests the stability of
these percentages over time.
We show in right ﬁgure of Figure 3 a CDF of the delay in
logging in over all users who eventually succeeded at logging
in (within the 24-hour period). Note that some small fraction
of users did not log in for a very long time, suggesting they
gave up and came back hours later. Even so, almost 20%
of users that experienced a failed login would have been
logged in a minute earlier should typo-tolerant checking have
been enabled. Aggregated across all failed login attempts,
typo-tolerance here would have increased logged in time by
several person-months just for this 24-hour experiment. This
represents a signiﬁcant impact on user experience and a clear
pain point for companies keen on making it easy for their
users to log in.
In aggregate, of all users who attempted to log into Dropbox
within the 24-hour measurement period, we discovered that
3% were turned away even though at
least one of their
submitted passwords was correctable by one of the correctors
in Ctop3. This also represents a signiﬁcant impact on user
experience, with users being prevented from using the service.
V. TYPO-TOLERANT CHECKING SCHEMES
In previous sections, we saw that
typos account for a
large fraction of login failures and that a simple set of typo
corrector functions could signiﬁcantly improve user experi-
ence. A natural follow-on question is whether we can achieve
typo-tolerance in password authentication systems without a
signiﬁcant security loss. We address that question here.
We will show, by introducing what we call
the “free
corrections theorem,” that for all natural settings there exist
typo-tolerant checking schemes that correct typos with no
security loss relative to exact checking for optimal attackers
806806
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:18:05 UTC from IEEE Xplore.  Restrictions apply. 
that (unrealistically) have exact knowledge of the distribution
of passwords. We will also specify the optimality of the
scheme underlying this theorem, i.e., showing that it achieves
the maximum utility possible with no security loss.
We will deﬁne the notion of a “natural” setting formally
below. Intuitively, it corresponds to the highly non-uniform,
sparse (in the space of all strings) passwords chosen in
practice. The schemes we analyze formally are not readily
applied as is in practice because, among other things, they
require exact knowledge of password and typo distributions.
Nevertheless, combing our measurement studies with a the-
oretical perspective guides us towards the design of several
concrete typo-tolerant checking schemes for which we give
empirical security estimates in Section VI.
A. Password and Typo Settings
Let S be a set of all possible strings that could be chosen as
passwords, e.g., ASCII strings up to some maximum length.
We associate to S a distribution p that models the probability
of user selection of passwords; thus p(w) is the probability
that some user selects a given string w ∈ S as a password.
We let PW ⊆ S be the set of possible passwords, which is
formally just the support of p. We write p(P ) to denote the
aggregate probability on a set P ⊆ S of strings. Following
prior work (c.f., [11]),
this model assumes for simplicity
that the distribution of passwords is independent of the user
selecting them, and that passwords are independently drawn
from p.
A key feature of our formalization approach is that we do
not appeal to a speciﬁc lexicographic notion of distance (e.g.,
Levenshtein distance) to model typos. Instead, we directly
model typos as probabilistic changes to strings. Speciﬁcally,
let τw( ˜w) denote the probability that upon authenticating, a
user with password w types the string ˜w. Thus τ is a family
of distributions over S, one distribution for each w ∈ PW.
If ˜w (cid:7)= w then ˜w is a typo; τw(w) is the probability that the
user makes no typo. Note that ˜w may or may not itself be
a password possibly chosen by a user, i.e., it may not be in
PW. We say that ˜w is a neighbor of w if τw( ˜w) > 0.
For all w ∈ PW, then, τw(·) deﬁnes a probability space
over S. That is, τw( ˜w) ∈ [0, 1] for any ˜w and
˜w∈S τw( ˜w) =
1. In practice, generally τw(w) > 0, i.e., users will sometimes
enter passwords correctly. Also, it will most often be the case
that τw( ˜w) (cid:7)= τ ˜w(w) for w (cid:7)= ˜w. For example, a user may
mistype her password w = “unlockme1” as ˜w =“unlockme”
as a result of accidentally dropping the last 1, while a user
whose password is ˜w =“unlockme” is less likely to type a 1
at the end of his password.
(cid:2)
In our model we assume that typos depend only on a user’s
password w and not, for example, on the user that typed them,
the time of day, or other factors. As we will see, this assump-
tion simpliﬁes operationalization of typo tolerance models. As
one example, modeling individual users’ typo habits would
require a server to record the user’s typo history. While higher-
accuracy correction for the user might then be possible, this
feature would, of course, result in a more complex system. It
could also leak password information: recording the fact that a
user fails to capitalize the ﬁrst character in her password leaks
the fact that character is a letter. From now on, a password
and typo setting, or simply setting, is a pair (p, τ ).
B. Password checkers
A password checker scheme consists of two algorithms:
• Reg is a randomized password registration algorithm. It
takes as input a password w and outputs a string s that
may, for example, be the output of a password hashing
scheme like scrypt. These are randomized since one must
choose a random salt value for each registration.
• Chk is a (possibly randomized) password veriﬁcation
takes as input a string ˜w and a stored
algorithm. It
string s, and outputs a Boolean value, either true or false.
In a modern, real-world service such as Dropbox, Chk is
one input in a complex authentication system that combines
multiple contextual, potentially probabilistic signals to make
an authentication decision. A typo-tolerant checker could
return a probabilistic estimate and/or combine with other con-
textual signals, but we focus our analysis only on deterministic
checkers. Our techniques extend in natural ways to conﬁdence
values (e.g., by returning an estimate of τw( ˜w)). In such a
scenario, the security impact of a typo-tolerant Chk will be
even lower. We also consider only complete checkers, meaning
that for all w, Chk(w, Reg(w)) ⇒ true.
An exact checker is one which never outputs true if ˜w (cid:7)= w.
In practice of course, exact checkers actually have a non-zero,
but cryptographically small probability of false acceptance (for
typical hash-function-based checkers, this small probability is
equal to the probability of having found a collision in the
hash function). We will throughout ignore this false acceptance
probability. We will use ExChk to denote some secure exact
checker, and assume the existence of one compatible with all
password settings of interest.
Typo-tolerant checkers. We will focus our attention on