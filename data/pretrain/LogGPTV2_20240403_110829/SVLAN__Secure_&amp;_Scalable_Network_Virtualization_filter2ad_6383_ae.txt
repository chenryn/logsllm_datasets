over the smallest SVLAN frame (136 bytes for 128-bit MACs)
on a 1 Gbps network link. Table III shows the time needed in
the worst case to successfully brute-force the MAC depending
on different sizes of the MAC and the underlying link capacity.
Compromised Veriﬁers. Compromising veriﬁers allows an
attacker to forward packets without a valid authorization proof.
Especially, in the case where only a limited number of veriﬁers
is deployed between two endpoints, the attack has a great
impact. For example, the compromised veriﬁer positioned in
the hop right before the destination, e.g., the receiver’s SVTEP,
can pretend all the incoming packets are legitimate. This has
the same impact of compromising ﬁrewalls which is the last
defense line for the victim. For such an attack, no fundamental
solution exists. Deploying more veriﬁers in the network would
degrade the impact of the attack by early ﬁltering the attack
packets before they reach the compromised veriﬁer. Another
viable mitigation is to apply a veriﬁcation method for infras-
tructure that monitors invariant security properties [52], [14],
[62].
B. Attacks leveraging SVLAN
In this attack class, we consider an attacker who abuses
the SVLAN protocols. The purpose of the attack is to disrupt
either network operation or SVLAN itself.
Bypassing Security Middleboxes. The original source routing
approach was leveraged to bypass the network defense mech-
anism, e.g., ﬁrewall [22]. The attacker speciﬁes the routing
path that detours around security equipments, such that attack
packets are not ﬁltered and arrive at the victim. Such an attack
is prevented by devolving the path construction to the AD; the
AD provides predeﬁned SegS→R and S can not specify or
manipulate the routing path, enforcing routing over veriﬁers.
Furthermore, as the receiver’s SVTEP is able to act as a veriﬁer
(see Section VIII-B), no attack packets will bypass the last
veriﬁer.
Man-In-The-Middle Attack (MITM). An adversary may
attempt MITM attacks against applications communicating
over SVLAN for eavesdropping, forgery of packet payload, or
packet injection. The network isolation mechanism of SVLAN
will prevent any host not belonging to the virtual LAN to
be able to obtain access to the packets, and thus, prevent the
MITM attack. Malicious on-path network equipment, however,
might observe the trafﬁc and could attempt an MITM attack;
which is a fundamental aspect of such systems in that the net-
work elements are trusted to perform their expected functions.
Nevertheless,
the bidirectional communication
path between two endpoints does not need to be symmetric,
such that the on-path MITM attack can also be mitigated by
using asymmetric communication paths.
Ampliﬁcation Attack. To ﬂood a target host, an adversary may
abuse the AD and amplify the attack volume. More precisely,
a compromised host sends getSegment() requests to the
AD with the address of its victim. The AD then replies to the
victim with an authorization proof. Nonetheless, this attack is
hardly successful, since the authorization-request has a small
ampliﬁcation factor of 4 (i.e., 8 bytes request and 32 bytes
reply). Compared to the typical ampliﬁcation attacks using
DNS or NTP, which have the ampliﬁcation factor of up to 52
and 556 respectively, the getSegment() is barely effective.
in SVLAN,
VIII. DISCUSSION
In this section, we describe some practical considerations
and discuss how our model can be realized on today’s Internet.
More precisely, we discuss the entities that could serve as
the ADs or veriﬁers, as well as how we coordinate SVLAN
entities.We then describe how SVLAN supports bidirectional
communication when the receiver also needs to send packets
to the sender. Later, we discuss incremental deployability.
A. Location of Authorization Delegates
There are two requirements for an entity on the Internet
to become an AD. From a technical perspective, ADs should
be positioned close to the senders so that the senders can
receive authorization proofs with minimal latency overhead.
From a business perspective, the entity should have incentives
to serve as the ADs for the receivers. We consider two different
candidates to serve as the ADs, i.e., the receiver’s AS and a
third-party entity, such as a cloud service provider.
Receiver’s AS. The receiver’s ISP has a clear incentive to
become an AD for its customers. It can offer AD services as
part of a security bundle for their customers or as a value-
added service for their premium customers. In addition, it can
use the service as a distinguishing feature from other ISPs to
attract customers in today’s competitive ISP market.
However, using the receiver’s AS as the AD may increase
communication latency. For senders far way from the receiver,
the process of getting authorization proof would incur one
additional RTT.
11
Third-Party Entity. Alternatively, we can use a third-party
entity such as a cloud service provider as the AD. Similar to
today’s cloud-based trafﬁc-scrubbing services, cloud providers
can bill the receivers based on the volume of (granted) autho-
rization requests. Communication overhead would be typically
lower than when using the receiver’s AS as AD but
the
latency depends on the footprint of the cloud; if the cloud is
geographically diverse and has distributed points-of-presence
(PoPs), the communication overhead would be reduced. There
is also a disadvantage of using a cloud provider as an AD: the
cloud operator learns which entities communicate. However,
the privacy loss is not as severe as today’s trafﬁc-scrubbing
services as the data between the sender and the receiver are
not forwarded through the cloud.
B. Choice of Veriﬁers
An entity that serves as a veriﬁer also needs to have an
incentive to serve as a veriﬁer. From a technical perspective,
the choice of veriﬁers has implications on the necessary state;
speciﬁcally, the ADs need to store every symmetric key that
they share with the veriﬁers (Section IV-A). Now, we provide
a summary of state overhead at the ADs based on the choices
of ADs and veriﬁers. We consider four entities as candidate
veriﬁers, of which three are on the path between the sender and
the receiver (i.e., the receiver, its ISP, and the sender’s ISP),5
and the other is a third-party entity (e.g., a cloud provider)
that may be off-path. We also discuss the advantages and
disadvantages of each choice.
Receiver. A receiver serves as the last line of defense to
drop a packet that it does not agree to, and it can drop the
packet with a light-weight operation (i.e., verify the validity
of the authorization proof), since symmetric cryptography can
be computed efﬁciently. In such a case, the authorization proof
plays a similar role as a TCP SYN cookie [50], which is used
to prevent SYN ﬂooding attacks. However, the fact that an
unwanted packet has reached the receiver may be problematic:
1) the network has already wasted bandwidth to forward a
packet that would be dropped anyways, 2) the receiver may
have latent vulnerabilities (e.g., backdoors) that the packet
could trigger, and 3) the adversary may be able to congest
the links to the receiver or overload the receiver’s processing
capabilities with superﬂuous trafﬁc.
In terms of state implication on the ADs, using the receiver
as the veriﬁers does not increase the amount of state at the
ADs, since they already store the receiving policies of all
receivers.
Receiver’s AS. Using the receiver’s AS as the veriﬁer al-
leviates the disadvantages of the above approach, since un-
wanted packets would be ﬁltered before reaching the receiver.
Moreover, the receiver’s ISP would be interested in serving as
the veriﬁer, since the early ﬁltering increases the efﬁciency of
its network and protects the receivers from potential danger,
which the ISP can sell as a value-added service to its customers
or use as a distinguishing feature to attract more customers.
To use the receiver’s AS as veriﬁers, the ADs need to
store per-AS keys, increasing the state overhead. Note that
the number of ASes could be relatively large compared to the
number of potential customers on an AS.
Sender’s AS. The main advantage of placing the veriﬁer at
the sender’s AS would be to drop packets early and thus
avoid the transmission through the network. However, as seen
by other technologies such as egress ﬁltering [6], the sender
AS may not have an incentive to ﬁlter out trafﬁc for remote
destinations, or a malicious source AS could still ﬂood the
receiver. Nonetheless, if the entire SVLAN is conﬁgured by a
single administrative entity such that it is one trusted network,
the sender-side veriﬁer becomes an attractive choice.
Third-Party Entity. We also consider using an off-path third-
party entity, such as a cloud provider, to serve as the veriﬁer.
This approach has three disadvantages: 1) it requires a detour
through the cloud, which can potentially increase latency and
the size of the packet due to the additional tunnel header to
redirect the packet to the cloud; 2) it requires additional per-
cloud state at the veriﬁers; and 3) similar to clouds that offer
today’s trafﬁc-scrubbing services, the cloud can observe all
data trafﬁc, leading to potential privacy problems.
C. Distributed Authorization Delegates
Running a cluster of multiple ADs is a possible de-
ployment approach for enhancing reliability, scalability, and
performance. For instance, SDN-based networks, which have
a similar architecture as SVLAN, often employ more than one
controller to mitigate the issue of single points of failure on
the control plane [26], [20]. Furthermore, instead of simply
employing an additional AD as a backup system, deploying
multiple ADs running in parallel such that each covers a geo-
graphical area would help load balancing, achieving scalabil-
ity [16]. It would also reduce latency by locating ADs closely
to the end hosts [51]. To ensure secure operation in running
multiple ADs deployed over a wide area, we consider two
coordination models for consistency in authorization policy
and SVTEP migration amongst ADs.
Coordination of Authorization Delegates. Keeping con-
sistency in authorization policy amongst ADs becomes an
essential part of the coordination process. In the context of dis-
tributed computing, the overhead in synchronization between
the distributed ADs increases as more ADs are joined into the
cluster, raising issues of scalability.
We consider consensus algorithms to ensure consistency
across the cluster,
that can be categorized as mainly two
approaches: strong consistency model [41], [45], [35] and
eventual consistency model [57], [27], [30]. With the strong
consistency model, the authorization policies across the dis-
tributed ADs are replicated, assuring the ADs have the latest
policies. In contrast, the eventual consistency model omits
the consensus process, thus improving the reactivity perceived
by SVTEP. The main drawback are possible short-term in-
consistencies. To provide a consistent control logic for the
entire network, the strong consistency model can be lever-
aged. Furthermore, open-source projects which enable reliable
distributed coordination can be used, such as ZooKeeper6 or
Consul7.
5We do not consider intermediate ISPs, since incentives for such ISPs are
unclear.
6https://zookeeper.apache.org/
7https://github.com/hashicorp/consul
12
SVTEP Migration. Once consistency of the authorization
policies amongst the distributed ADs is secured, the coordi-
nation of the SVTEPs becomes less critical; SVTEPs are able
to get the same result from any of the ADs. Therefore, the
main consideration for the SVTEP coordination is to discover
the best AD in terms of scalability, reliability and performance.
There are several ways to ﬁnd the AD, for instance:
•
•
Explicit conﬁguration: each SVTEP is conﬁgured with
AD information as an initial rendezvous point. Since
virtual LANs used to be provisioned by a single or a
few administrative entities, conﬁguring SVTEPs upon
setup is straightforward approach.
DNS-based discovery: through DNS entries (e.g., ad-
ditional text ﬁeld), a SVTEP can obtain information
on the AD. If only the destination IP address is known,
a reverse DNS lookup can ﬁrst be performed.
We consider that an SVTEP is initially conﬁgured with
a primary AD IP address and a set of secondary AD IP
addresses. The SVTEP ﬁrst tries to connect to the primary
AD and if the connection fails, then tries one of the secondary
ADs. That is, an SVTEP is connected to an AD at a time,
preventing duplicate processing of asynchronous requests that
could result in duplicate path segments or unnecessary resource
consumption. Unlike the concept of master and slave in
the distributed SDN controller architecture, the primary and
secondary ADs are functionally equal except for the delay in
the getSegment() protocol. Thus, the SVTEP migration
keeps to ﬁnd the best primary AD in terms of latency as well
as load balancing, and automatically adjust the target AD when
the network changes.
Similar
support
to the multiple-controller
in Open-
Flow [40], we intend the migration is initiated by the ADs,
which enables fast recovery from potential failure and load
balancing. The ADs coordinate the migration of the SVTEP
amongst themselves via the management plane, and decides
an AD to be a primary. Then, the next primary AD sends
a RoleChange() message to the SVTEP. It swaps the
primary AD from the current one to the requested one. In
the migration process, we intend to minimize the functionality
in the SVTEPs since it is not desirable and would cause
unnecessary overheads.
D. Bidirectional Communication
Thus far, we have only considered one-way communication
to the receiver. However,
where the sender sends packet
in reality, most communication is bidirectional; that is, the
receiver also sends packets back to the sender. In this section,
we discuss how we support bidirectional communication.
Implicit Consent. One possibility is to implicitly assume
that the sender would be willing to accept packets from the
receiver, since the sender initiates the communication to the
receiver. This model is promising as most communications are
bidirectional and has been adopted by NAT and other past
proposals [7].
However,
the case
where the sender wants the communication to be entirely
unidirectional. For example, fragile IoT devices may transmit
measurement data to the data-aggregation hub but may not
the implicit model cannot support
want to receive any message back from the hub for security
reasons. In addition, the realization of the implicit model in
NAT and off-by-default [7] requires the veriﬁer (in case of
NAT, the NAT device) to remember all active communication
to approve and/or forward packets from the receiver to the
sender.
Explicit Consent. Instead, we consider an explicit consent
where the receiver must acquire consent from the sender to
send a packet to the sender. In one approach, the receiver
can acquire consent by requesting an authorization proof from
the sender’s AD; however, such an approach incurs additional
communication latency. Instead, we add a ﬂag (i.e., RepFlag)
to the proof Equation (1) to indicate that the sender approves
packets from the receiver; then, the veriﬁer would only forward
a packet to the sender if the RepFlag is set. In terms of the
protocol (Section IV-B), we extend protocol 1, 2, and 3 to
include the RepFlag.