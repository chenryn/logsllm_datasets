### 优化后的文本

#### 实验结果对比
下表展示了不同配置下的EnFuzz在多个基准测试中的性能。具体数据如下：

| 配置 | 路径数 | 分支数 | 唯一漏洞数 | 性能提升 |
|------|--------|--------|------------|----------|
| EnFuzz | 4098 | 3644 | 13949 | 38% ↑ |
| EnFuzz-L | 1 | 3 | 1 | 208% ↑ |
| EnFuzz | 1 | 3 | 1 | 242% ↑ |
| EnFuzz-L | 1 | 3 | 1 | 342% ↑ |
| EnFuzz | 1 | 3 | 1 | 400% ↑ |

#### EnFuzz-A的性能
EnFuzz-A集成了AFL、AFLFast和FairFuzz作为基础fuzzer，并实现了基于全局覆盖率图的种子同步。与并行运行四个CPU核心的AFL、AFLFast和FairFuzz相比，EnFuzz-A在所有应用程序上执行了更多的路径并覆盖了更多的分支。总体而言，它覆盖了11.3%、25.9%和13.9%更多的路径，实现了7.2%、9.3%和4.8%更多的分支覆盖，并触发了8.8%、48%和23%更多的唯一漏洞。这表明即使基础fuzzer的多样性较小，鲁棒性和性能也可以得到提升。

#### EnFuzz-Q的性能
EnFuzz-Q集成了AFL、AFLFast、FairFuzz和QSYM作为基础fuzzer。实验结果如表9、表10和表11的第四列所示。与EnFuzz-A相比，EnFuzz-Q覆盖了1.1%更多的路径，执行了1.0%更多的分支，并触发了10.8%更多的唯一漏洞。然而，在Google的fuzzer-test-suite上的改进显著小于LAVA-M。

#### 性能下降的原因
LAVA-M和Google fuzzer-test-suite之间性能下降的原因在于，LAVA-M中的四个应用程序（who, uniq, base64和md5sum）的基础代码较小（2K-4K LOCs）。这些程序适合使用符号执行引擎，但在fuzzer-test-suite中，代码库通常达到100k LOCs，符号执行引擎表现不佳甚至会挂起。

#### EnFuzz-L的性能
EnFuzz-L集成了AFL、AFLFast、FairFuzz和libFuzzer作为基础fuzzer。实验结果如表9、表10和表11的第七列所示。根据第A节所述，这些基础fuzzer之间的多样性比EnFuzz-A更大。与EnFuzz-A相比，EnFuzz-L在所有目标应用程序上都表现更好。总体而言，它覆盖了23.6%更多的路径，执行了5.8%更多的分支，并触发了42.4%更多的唯一漏洞。

#### EnFuzz的性能
EnFuzz集成了AFL、AFLFast、libFuzzer和Radamsa作为基础fuzzer，其多样性最大，因为它涵盖了所有三种多样性启发式方法。与EnFuzz-L相比，EnFuzz覆盖了3.6%更多的路径，执行了1.8%更多的分支，并触发了13.2%更多的唯一漏洞。EnFuzz和EnFuzz-L的表现均优于EnFuzz-Q。这些统计数据表明，基础fuzzer之间的多样性越大，集成fuzzer的性能越好。对于具有大量代码库的实际应用，与混合符号执行或集成符号执行的fuzzer相比，不使用符号执行的集成fuzzer可能表现更好。

#### 实际应用中的模糊测试
我们将EnFuzz应用于更多来自GitHub和Cisco商业产品的实际应用程序，其中包括一些已经经过充分模糊测试的项目，如图像处理库libpng和libjpeg、视频处理库libwav、以及广泛使用的IoT设备通信协议libiec61850等。在24小时内，除了覆盖率的提升，EnFuzz还发现了60个未知的真实漏洞，其中44个已成功注册为CVE。所有这些新漏洞和安全漏洞都在一个64位机器上检测到，该机器配备了36个核心（Intel(R) Xeon(R) CPU E5-2630 PI:EMAIL）、128GB主内存，并且主机操作系统为Ubuntu 16.04。

#### 漏洞检测对比
我们还分别运行每个工具来检测这些实际应用程序中的未知漏洞。结果如表12所示。EnFuzz找到了所有60个独特的漏洞，而其他工具只找到了部分漏洞。与AFL、AFLFast、FairFuzz、LibFuzzer和QSYM相比，EnFuzz分别检测到了71.4%、114%、93.5%、76.4%和87.5%更多的独特漏洞。这些结果表明，EnFuzz在检测更多通用项目中的真实漏洞方面非常有效。例如，在已经经过充分模糊测试的libwav和libpng项目中，我们仍然检测到了13个新的真实漏洞，其中7个已被分配为CVE。

#### 具体案例分析
以libpng为例，这是一个广泛使用的C库，用于读写PNG图像文件。尽管它已经被多次模糊测试并且是Google OSS-Fuzz项目的一部分，但通过EnFuzz，我们检测到了三个漏洞，包括一个段错误、一个栈缓冲区溢出和一个内存泄漏。前两个漏洞被分配为CVE（CVE-2018-14047、CVE-2018-14550）。

特别地，CVE-2018-14047允许远程攻击者通过精心构造的输入导致段错误。我们使用AddressSanitizer分析了这个漏洞，发现它是一个典型的内存访问违规。问题在于png.c文件的第564行中的函数`png_free_data`，`info_ptr`试图访问无效的内存区域。在特定构造的文件中，`png_free_data`在释放与文本相关的数据时发生错误，导致读取无效或未知的内存。

单独使用每个基础fuzzer（AFL、AFLFast、FairFuzz、libFuzzer和QSYM）对libpng进行模糊测试时，上述漏洞未被检测到。要触发这个漏洞，需要6次函数调用和11次比较（2次整数比较、1次布尔比较和8次指针比较）。没有EnFuzz的种子同步机制，其他fuzzer很难检测到这种深层次路径中的漏洞。图4展示了这些fuzzer在libpng上的性能随时间的变化情况。结果显示，这些基础fuzzer存在泛化和可扩展性限制——优化后的fuzzer AFLFast和FairFuzz在libpng上的表现不如原始的AFL，而EnFuzz表现最佳。此外，除了在基准测试和实际项目上的评估外，EnFuzz已经在工业实践中部署，并且不断有新的CVE被报告。

#### 多样性的局限性
尽管基于LAVA-M和Google fuzzer-test-suite等多个基准测试和实际项目，我们证明了集成模糊测试方法优于任何基础fuzzer，但仍有一些局限性威胁着集成模糊测试的性能。主要的局限性和解决方法如下：

1. **基础fuzzer多样性的不足和不精确**：我们在第4.1节中描述了基础fuzzer的选择，提出了三种不同的启发式方法来表示基础fuzzer的多样性，包括覆盖率信息粒度的多样性、输入生成策略的多样性和种子变异选择策略的多样性。根据这些启发式方法，我们选择了AFL、AFLFast、FairFuzz、libFuzzer、Radamsa和QSYM作为基础fuzzer。然而，这些多样性的启发式方法可能不够全面。未来的工作中需要提出更多的多样性度量方法。例如，初始种子决定了模糊测试的初始方向，因此对于基于变异的fuzzer尤为重要。有些fuzzer利用符号执行生成的初始种子，而有些fuzzer则利用领域专家或语法规范构建的初始种子。然而，我们手动选择了基础fuzzer，这也不够准确。

一种可能的解决方案是量化不同fuzzer之间的初始多样性值，以进行更准确的选择。根据[14]中的定义，方差或多样性是衡量数据相对于平均值的距离的一种度量。数据集的标准差百分比表示每个测量值平均与其他测量值的差异程度。为了评估不同基础fuzzer的多样性，我们可以选择最广泛使用的AFL及其路径覆盖率作为基线，然后计算每个工具在Google fuzzer-test-suite上的标准差。然后可以计算这些值的标准差作为每个基础fuzzer的初始多样性度量，如公式（1）和（2）所示，其中n表示由这些基础fuzzer模糊测试的应用程序数量，pi表示当前fuzzer覆盖的目标应用程序i的路径数，pAi表示AFL覆盖的应用程序i的路径数。

\[ \text{mean} = \frac{1}{n} \sum_{i=1}^{n} \frac{p_i - p_{Ai}}{p_{Ai}} \]

\[ \text{standard deviation} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} \left( \frac{p_i - p_{Ai}}{p_{Ai}} - \text{mean} \right)^2} \]

通过这些方法，我们可以更准确地选择基础fuzzer，并进一步提高集成模糊测试的性能。