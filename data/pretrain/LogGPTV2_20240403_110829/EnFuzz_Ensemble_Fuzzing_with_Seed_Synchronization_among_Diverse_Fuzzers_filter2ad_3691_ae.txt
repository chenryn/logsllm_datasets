3531
4098
13267
614
21664
4538
4202
9680
52267
907
19323
3939
58018
44419
7268
16984
4589
60104
5503
3189
14210
43104
399719
35% ↑
EnFuzz
4108
285
3644
4169
13949
614
21899
4673
4216
9827
53912
907
19688
3945
58192
44708
7339
17071
4696
62918
5579
3216
14318
43217
407090
38% ↑
0
3
0
1
0
0
1
3
5
5
6
2
1
1
0
1
2
0
0
1
0
1
4
0
37
208% ↑
0
2
1
1
1
2
1
3
5
5
6
2
1
1
0
1
2
0
0
1
1
1
4
0
41
242% ↑
EnFuzz-L
1
3
1
2
1
2
2
4
5
6
7
2
2
1
0
1
2
0
0
2
3
2
4
0
53
342% ↑
EnFuzz
1
3
1
2
1
2
3
4
6
6
8
3
2
1
0
1
3
0
0
2
4
3
4
0
60
400% ↑
For EnFuzz-A, which ensembles AFL, AFLFast and Fair-
Fuzz as base fuzzers and implements the seed synchronization
with global coverage map, compared with AFL, AFLFast and
FairFuzz running in parallel mode with four CPU cores used
(as shown in Table 6, Table 7 and Table 8), it always executes
more paths and covers more branches on all applications. In
total, it covers 11.3%, 25.9% and 13.9% more paths, achieves
7.2%, 9.3% and 4.8% more covered branches, and triggers
8.8%, 48% and 23% more unique bugs. It reveals that the
robustness and performance can be improved even when the
diversity of base fuzzers is small.
For the EnFuzz-Q which integrates AFL, AFLFast, Fair-
Fuzz and QYSM as base fuzzers, the results are shown
in the fourth columns of Tables 9, 10 and 11. Compared
with EnFuzz-A, EnFuzz-Q covers 1.1% more paths, executes
1.0% more branches and triggers 10.8% more unique bugs
than EnFuzz-A. The improvement is signiﬁcantly smaller on
Google’s fuzzer-test-suite than on LAVA-M.
The reason for performance degradation between experi-
ments on LAVA-M and Google fuzzer-test-suite is that the
base codes of the four applications (who, uniq, base64 and
md5sum) in LAVA-M are small (2K-4K LOCs). The concolic
execution engine works well on them, but usually performs
the opposite or even hangs on real projects in fuzzer-test-suite
whose code base easily reaches 100k LOCs.
For the EnFuzz-L which integrates AFL, AFLFast, Fair-
Fuzz and libFuzzer as base fuzzers, the results are pre-
sented in the seventh columns of Tables 9, 10 and 11. As
mentioned in section A, the diversity among these base
fuzzers is much larger than with EnFuzz-A. Compared with
EnFuzz-A, EnFuzz-L always performs better on all target ap-
plications. In total, it covers 23.6% more paths, executes 5.8%
more branches and triggers 42.4% more unique bugs than
EnFuzz-A.
For the EnFuzz which integrates AFL, AFLFast, libFuzzer
and Radamsa as base fuzzers, the diversity is the largest be-
cause they cover all three diversity heuristics. Compared
with EnFuzz-L, it performs better and covers 3.6% more
paths, executes 1.8% more branches and triggers 13.2% more
unique bugs. Both EnFuzz and EnFuzz-L performs better
than EnFuzz-Q. These statistics demonstrate that the more di-
versity among these base fuzzers, the better the ensemble
fuzzer should perform. For real applications with a large
code base, compared with hybrid conclic fuzzing or ensem-
ble fuzzing with symbolic execution, the ensemble fuzzing
without symbolic execution may perform better.
5.6 Fuzzing Real-World Applications
We apply EnFuzz to fuzz more real-world applications from
GitHub and commercial products from Cisco, some of which
are well-fuzzed projects such as the image processing library
libpng and libjepg, the video processing library libwav, the
IoT device communication protocol libiec61850 used in hun-
dreds of thousands of cameras, etc. EnFuzz also performs
well. Within 24 hours, besides the coverage improvements,
EnFuzz ﬁnds 60 more unknown real bugs including 44 suc-
cessfully registered as CVEs, as shown in Table 13. All of
these new bugs and security vulnerabilities are detected in
a 64-bit machine with 36 cores (Intel(R) Xeon(R) CPU E5-
2630 PI:EMAIL), 128GB of main memory, and Ubuntu
16.04 as the host OS.
Table 12: Unique previously unknown bugs detected by each
tool within 24 hours on some real-world applications.
AFL
Project
Bento4_mp4com 5
5
Bento4_mp4tag
bitmap
1
1
cmft
1
ffjpeg
1
ﬂif
1
imageworsener
3
libjpeg-05-2018
libiec61850
3
2
libpng-1.6.34
3
libwav_wavgain
2
libwav_wavinfo
1
LuPng
pbc
5
1
pngwriter
total
35
AFLFast FairFuzz LibFuzzer QSYM EnFuzz
4
4
1
1
1
1
0
3
2
1
2
1
1
5
1
28
6
7
2
2
2
3
1
5
4
3
5
5
4
9
2
60
5
4
1
0
1
1
0
3
2
1
3
2
1
6
1
31
5
5
0
1
0
2
0
4
1
1
0
4
3
7
1
34
4
4
1
0
1
1
1
3
2
2
2
2
1
6
2
32
As a comparison, we also run each tool on those real-world
applications to detect unknown vulnerabilities. The results
are presented in table 12. EnFuzz found all 60 unique bugs,
while other tools only found a portion of these bugs. Com-
pared with AFL, AFLFast, FairFuzz, LibFuzzer and QSYM,
EnFuzz detected 71.4%, 114%, 93.5%, 76.4%, 87.5% more
unique bugs respectively. The results demonstrate the effec-
tiveness of EnFuzz in detecting real vulnerabilities in more
general projects. For example, in the well-fuzzed projects
libwav and libpng, we can still detect 13 more real bugs, 7
of which are assigned as CVEs. We give an analysis of the
project libpng for a more detailed illustration. libpng is a
widely used C library for reading and writing PNG image
ﬁles. It has been fuzzed many times and is one of the projects
in Google’s OSS-Fuzz, which means it has been continually
fuzzed by multiple fuzzers many times. But with EnFuzz, we
detect three vulnerabilities, including one segmentation fault,
one stack-buffer-overﬂow and one memory leak. The ﬁrst two
vulnerabilities were assigned as CVEs (CVE-2018-14047,
CVE-2018-14550).
In particular, CVE-2018-14047 allows remote attackers
to cause a segmentation fault via a crafted input. We ana-
lyze the vulnerability with AddressSanitizer and ﬁnd it is
a typical memory access violation. The problem is that in
function png_free_data in line 564 of png.c, the info_ptr
attempts to access an invalid area of memory. The error oc-
curs in png_free_data during the free of text-related data
with speciﬁcally crafted ﬁles, and causes reading of invalid
or unknown memory, as show in Listing 1. The new vulnera-
bilities and CVEs in the IoT device communication protocol
libiec6185 can also crash the service and have already been
conﬁrmed and repaired.
We also apply each base fuzzer (AFL, AFLFast, FairFuzz,
libFuzzer and QSYM) to fuzz libpng separately, the above
vulnerability is not detected. To trigger this bug, 6 function
calls and 11 compares (2 for integer, 1 for boolean and 8 for
USENIX Association
28th USENIX Security Symposium    1977
# ifdef PNG_TEXT_SUPPORTED
/* Free text item num or ( if num == -1)
all text items */
if ( info_ptr -> text != NULL &&
(( mask & PNG_FREE_TEXT ) &
info_ptr -> free_me ) != 0)
Listing 1: The error code of libpng for CVE-2018-14047
pointer) are required. It is difﬁcult for other fuzzers to detect
bugs in such deep paths without the seeds synchronization
of EnFuzz. The performances of these fuzzers over time in
libpng are presented in Figure 4. The results demonstrate
that generalization and scalability limitations exist in these
base fuzzers – the two optimized fuzzers AFLFast and Fair-
Fuzz perform worse than the original AFL for libpng, while
EnFuzz performs the best. Furthermore, except for those eval-
uations on benchmarks and real projects, EnFuzz had already
been deployed in industry practice, and more new CVEs were
being continuously reported.
(a) Number of paths over time
(b) Number of branches over time
Figure 4: Performance of each fuzzer over time in libpng.
Each fuzzer runs in four CPU cores for 24 hours.
Table 13: The 44 CVEs detected by EnFuzz in 24 hours.
Project
Bento4_mp4com 6
Count CVE-2018-Number
14584, 14585, 14586, 14587,
14588, 14589
13846, 13847, 13848, 14590,
14531, 14532
17073
13833
16781
12109
16782
11212, 11213, 11214, 11813
18834, 18937, 19093
14048, 14550
14052, 14549
14049, 14050, 14051
18581, 18582, 18583
14736, 14737, 14738, 14739,
14740, 14741, 14742, 14743,
14744
14047
Bento4_mp4tag
bitmap
cmft
ffjpeg
ﬂif
imageworsener
libjpeg-05-2018
libiec61850
libpng-1.6.34
libwav_wavgain
libwav_wavinfo
LuPng
pbc
pngwriter
6
1
1
1
1
1
4
3
2
2
3
3
9
1
6 Discussion
Based on benchmarks such as LAVA-M and Google’s fuzzer-
test-suite, and several real projects, we demonstrate that this
ensemble fuzzing approach outperforms any base fuzzers.
However, some limitations still threaten the performance
of ensemble fuzzing. The representative limitations and the
workarounds are discussed below.
The ﬁrst potential threat is the insufﬁcient and imprecise di-
versity of base fuzzers. Section 4.1 describes our base fuzzer
selection, we propose three different heuristics to indicate
diversity of base fuzzers, including diversity of coverage in-
formation granularity, diversity of input genera-tion strategy,
and diversity of seed mutation selection strategy. According
to these three heuristics, we select AFL, AFLFast, FairFuzz,
libFuzzer, Radamsa and QSYM as the base fuzzers. Further-
more, we implement four prototypes of ensemble fuzzing and
demonstrate that the greater the diversity of base fuzzers, the
better the ensemble fuzzer performs. However, these three
different heuristics of diversity may be insufﬁcient. More
diversity measures need to be proposed in future work. For
example, initial seeds determine the initial direction of fuzzing
and, thus, are signiﬁcantly important for fuzzing, especially
for mutation-based fuzzers. Some fuzzers utilize initial seeds
generated by symbolic execution [29, 35] while some other
fuzzers utilize initial seeds constructed by domain experts
or grammar speciﬁcations. However, we select base fuzzers
manually according to the initial diversity heuristic, which is
also not accurate enough.
A possible solution to this threat is to quantify the initial
diversity value among different fuzzers for more accurate
selection. As deﬁned in [14], the variance or diversity is a
measure of the distance of the data in relation to the average.
The average standard deviation of a data set is a percentage
that indicates how much, on average, each measurement dif-
fers from the other. To evaluate the diversity of different base
fuzzers, we can choose the most widely used AFL and its path
1978    28th USENIX Security Symposium
USENIX Association
coverage as a baseline and then calculate standard deviation
of each tool from this baseline on the Google fuzzing-test-
suite. Then we can calculate the standard deviation of these
values as the initial measure of diversity for each base fuzzer,
as presented in formula (2) and (1), where n means the num-
ber of applications fuzzed by these base fuzzers, pi means the
number of paths covered by the current fuzzer of the target
application i and pAi means the number of paths covered by
AFL of the application i.
mean =
1
n
∑
i=1
n
pi − pAi
pAi
pi − pAi
pAi
(1)
(2)