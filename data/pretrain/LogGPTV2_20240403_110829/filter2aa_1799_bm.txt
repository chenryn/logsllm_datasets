tialization internally). The API exists both as a Win32 variant, which calls into Ntdll.dll’s Run Time Library 
(Rtl) as all the other previously seen mechanisms do, as well as the documented Rtl set of APIs, which 
are exposed to kernel programmers in Ntoskrnl.exe instead (obviously, user-mode developers could 
bypass Win32 and use the Rtl functions in Ntdll.dll too, but that is never recommended). The only dif-
ference between the two implementations is that the kernel ends up using an event object for synchro-
nization, whereas user mode uses a keyed event instead (in fact, it passes in a NULL handle to use the 
low-memory keyed event that was previously used by critical sections).
Note Since recent versions of Windows now implement an address-based pushlock in 
kernel mode, as well as the address-based wait primitive in user mode, the Rtl library could 
probably be updated to use RtlWakeAddressSingle and ExBlockOnAddressPushLock, and in 
fact a future version of Windows could always do that—the keyed event merely provided a 
more similar interface to a dispatcher event object in older Windows versions. As always, do 
not rely on the internal details presented in this book, as they are subject to change.
208 
CHAPTER 8 System mechanisms
The init once mechanism allows for both synchronous (meaning that the other threads must wait for 
initialization to complete) execution of a certain piece of code, as well as asynchronous (meaning that 
the other threads can attempt to do their own initialization and race) execution. We look at the logic 
behind asynchronous execution after explaining the synchronous mechanism. 
In the synchronous case, the developer writes the piece of code that would normally execute after 
double-checking the global variable in a dedicated function. Any information that this routine needs 
can be passed through the parameter variable that the init once routine accepts. Any output infor-
mation is returned through the context variable. (The status of the initialization itself is returned as 
a Boolean.) All the developer has to do to ensure proper execution is call InitOnceExecuteOnce with 
the parameter, context, and run-once function pointer after initializing an INIT_ONCE object with 
InitOnceInitialize API. The system takes care of the rest.
For applications that want to use the asynchronous model instead, the threads call 
InitOnceBeginInitialize and receive a BOOLEAN pending status and the context described earlier. If the 
pending status is FALSE, initialization has already taken place, and the thread uses the context value 
for the result. (It’s also possible for the function to return FALSE, meaning that initialization failed.) 
However, if the pending status comes back as TRUE, the thread should race to be the first to create the 
object. The code that follows performs whatever initialization tasks are required, such as creating ob-
jects or allocating memory. When this work is done, the thread calls InitOnceComplete with the result of 
the work as the context and receives a BOOLEAN status. If the status is TRUE, the thread won the race, 
and the object that it created or allocated is the one that will be the global object. The thread can now 
save this object or return it to a caller, depending on the usage.
In the more complex scenario when the status is FALSE, this means that the thread lost the race. 
The thread must undo all the work it did, such as deleting objects or freeing memory, and then call 
InitOnceBeginInitialize again. However, instead of requesting to start a race as it did initially, it uses the 
INIT_ONCE_CHECK_ONLY flag, knowing that it has lost, and requests the winner’s context instead (for 
example, the objects or memory that were created or allocated by the winner). This returns another 
status, which can be TRUE, meaning that the context is valid and should be used or returned to the 
caller, or FALSE, meaning that initialization failed and nobody has been able to perform the work (such 
as in the case of a low-memory condition, perhaps).
In both cases, the mechanism for run-once initialization is similar to the mechanism for condition 
variables and SRW locks. The init once structure is pointer-size, and inline assembly versions of the SRW 
acquisition/release code are used for the noncontended case, whereas keyed events are used when 
contention has occurred (which happens when the mechanism is used in synchronous mode) and the 
other threads must wait for initialization. In the asynchronous case, the locks are used in shared mode, 
so multiple threads can perform initialization at the same time. Although not as highly efficient as the 
alert-by-ID primitive, the usage of a keyed event still guarantees that the init once mechanism will func-
tion even in most cases of memory exhaustion.
CHAPTER 8 System mechanisms
209
Advanced local procedure call
All modern operating systems require a mechanism for securely and efficiently transferring data 
between one or more processes in user mode, as well as between a service in the kernel and clients in 
user mode. Typically, UNIX mechanisms such as mailslots, files, named pipes, and sockets are used for 
portability, whereas in other cases, developers can use OS-specific functionality, such as the ubiquitous 
window messages used in Win32 graphical applications. In addition, Windows also implements an 
internal IPC mechanism called Advanced (or Asynchronous) Local Procedure Call, or ALPC, which is a 
high-speed, scalable, and secured facility for message passing arbitrary-size messages. 
Note ALPC is the replacement for an older IPC mechanism initially shipped with the very 
first kernel design of Windows NT, called LPC, which is why certain variables, fields, and 
functions might still refer to “LPC” today. Keep in mind that LPC is now emulated on top of 
ALPC for compatibility and has been removed from the kernel (legacy system calls still exist, 
which get wrapped into ALPC calls).
Although it is internal, and thus not available for third-party developers, ALPC is widely used in vari-
ous parts of Windows:
I 
Windows applications that use remote procedure call (RPC), a documented API, indirectly use
ALPC when they specify local-RPC over the ncalrpc transport, a form of RPC used to communi-
cate between processes on the same system. This is now the default transport for almost all RPC
clients. In addition, when Windows drivers leverage kernel-mode RPC, this implicitly uses ALPC
as well as the only transport permitted.
I 
Whenever a Windows process and/or thread starts, as well as during any Windows subsystem
operation, ALPC is used to communicate with the subsystem process (CSRSS). All subsystems
communicate with the session manager (SMSS) over ALPC.
I 
When a Windows process raises an exception, the kernel’s exception dispatcher communicates
with the Windows Error Reporting (WER) Service by using ALPC. Processes also can communi-
cate with WER on their own, such as from the unhandled exception handler. (WER is discussed
later in Chapter 10.)
I 
Winlogon uses ALPC to communicate with the local security authentication process, LSASS.
I 
The security reference monitor (an executive component explained in Chapter 7 of Part 1) uses
ALPC to communicate with the LSASS process.
I 
The user-mode power manager and power monitor communicate with the kernel-mode power
manager over ALPC, such as whenever the LCD brightness is changed.
I 
The User-Mode Driver Framework (UMDF) enables user-mode drivers to communicate with the
kernel-mode reflector driver by using ALPC.
210 
CHAPTER 8 System mechanisms
I 
The new Core Messaging mechanism used by CoreUI and modern UWP UI components use
ALPC to both register with the Core Messaging Registrar, as well as to send serialized message
objects, which replace the legacy Win32 window message model.
I 
The Isolated LSASS process, when Credential Guard is enabled, communicates with LSASS by
using ALPC. Similarly, the Secure Kernel transmits trustlet crash dump information through
ALPC to WER.
I 
As you can see from these examples, ALPC communication crosses all possible types of secu-
rity boundaries—from unprivileged applications to the kernel, from VTL 1 trustlets to VTL 0
services, and everything in between. Therefore, security and performance were critical require-
ments in its design.
Connection model
Typically, ALPC messages are used between a server process and one or more client processes of that 
server. An ALPC connection can be established between two or more user-mode processes or between 
a kernel-mode component and one or more user-mode processes, or even between two kernel-mode 
components (albeit this would not be the most efficient way of communicating). ALPC exposes a single 
executive object called the port object to maintain the state needed for communication. Although this 
is just one object, there are several kinds of ALPC ports that it can represent:
I 
Server connection port A named port that is a server connection request point. Clients can
connect to the server by connecting to this port.
I 
Server communication port An unnamed port a server uses to communicate with one of its
clients. The server has one such port per active client.
I 
Client communication port An unnamed port each client uses to communicate with its server.
I 
Unconnected communication port An unnamed port a client can use to communicate
locally with itself. This model was abolished in the move from LPC to ALPC but is emulated for
Legacy LPC for compatibility reasons.
ALPC follows a connection and communication model that’s somewhat reminiscent of BSD socket 
programming. A server first creates a server connection port (NtAlpcCreatePort), whereas a cli-
ent attempts to connect to it (NtAlpcConnectPort). If the server was in a listening state (by using 
NtAlpcSendWaitReceivePort), it receives a connection request message and can choose to accept it 
(NtAlpcAcceptConnectPort). In doing so, both the client and server communication ports are created, 
and each respective endpoint process receives a handle to its communication port. Messages are 
then sent across this handle (still by using NtAlpcSendWaitReceivePort), which the server continues to 
receive by using the same API. Therefore, in the simplest scenario, a single server thread sits in a loop 
calling NtAlpcSendWaitReceivePort and receives with connection requests, which it accepts, or mes-
sages, which it handles and potentially responds to. The server can differentiate between messages by 
reading the PORT_HEADER structure, which sits on top of every message and contains a message type. 
The various message types are shown in Table 8-30.
CHAPTER 8 System mechanisms
211
TABLE 8-30   ALPC message types
pe
Meaning
LPC_REQUEST
A normal ALPC message, with a potential synchronous reply
LPC_REPLY
An ALPC message datagram, sent as an asynchronous reply to a previous datagram
LPC_DATAGRAM
An ALPC message datagram, which is immediately released and cannot be synchro-
nously replied to
LPC_LOST_REPLY
Deprecated, used by Legacy LPC Reply API
LPC_PORT_CLOSED
Sent whenever the last handle of an ALPC port is closed, notifying clients and servers 
that the other side is gone
LPC_CLIENT_DIED
Sent by the process manager (PspExitThread) using Legacy LPC to the registered termi-
nation port(s) of the thread and the registered exception port of the process
LPC_EXCEPTION
Sent by the User-Mode Debugging Framework (DbgkForwardException) to the excep-
tion port through Legacy LPC
LPC_DEBUG_EVENT
Deprecated, used by the legacy user-mode debugging services when these were part 
of the Windows subsystem
LPC_ERROR_EVENT
Sent whenever a hard error is generated from user-mode (NtRaiseHardError) and sent 
using Legacy LPC to exception port of the target thread, if any, otherwise to the error 
port, typically owned by CSRSS
LPC_CONNECTION_REQUEST
An ALPC message that represents an attempt by a client to connect to the server’s con-
nection port
LPC_CONNECTION_REPLY
The internal message that is sent by a server when it calls NtAlpcAcceptConnectPort to 
accept a client’s connection request
LPC_CANCELED
The received reply by a client or server that was waiting for a message that has now 
been canceled
LPC_UNREGISTER_PROCESS
Sent by the process manager when the exception port for the current process is 
swapped to a different one, allowing the owner (typically CSRSS) to unregister its data 
structures for the thread switching its port to a different one
The server can also deny the connection, either for security reasons or simply due to protocol or 
versioning issues. Because clients can send a custom payload with a connection request, this is usu-
ally used by various services to ensure that the correct client, or only one client, is talking to the server. 
If any anomalies are found, the server can reject the connection and, optionally, return a payload 
containing information on why the client was rejected (allowing the client to take corrective action, if 
possible, or for debugging purposes).
Once a connection is made, a connection information structure (actually, a blob, as we describe 
shortly) stores the linkage between all the different ports, as shown in Figure 8-40.
212 
CHAPTER 8 System mechanisms
Handle
Client view
of section
Handle
Handle
Server view
of section
Client
communication
port
Server
communication
port
Kernel address space
Client address
space
Client process
Connection port
Server address
space
Server process
Message
queue
Shared
section
FIGURE 8-40 Use of ALPC ports.
Message model
Using ALPC, a client and thread using blocking messages each take turns performing a loop around the 
NtAlpcSendWaitReceivePort system call, in which one side sends a request and waits for a reply while 
the other side does the opposite. However, because ALPC supports asynchronous messages, it’s pos-
sible for either side not to block and choose instead to perform some other runtime task and check for 
messages later (some of these methods will be described shortly). ALPC supports the following three 
methods of exchanging payloads sent with a message:
I 
A message can be sent to another process through the standard double-buffering mecha-
nism, in which the kernel maintains a copy of the message (copying it from the source process),
switches to the target process, and copies the data from the kernel’s buffer. For compatibility, if
legacy LPC is being used, only messages of up to 256 bytes can be sent this way, whereas ALPC
can allocate an extension buffer for messages up to 64 KB.
I 
A message can be stored in an ALPC section object from which the client and server processes
map views. (See Chapter 5 in Part 1 for more information on section mappings.)
An important side effect of the ability to send asynchronous messages is that a message can be can-
celed—for example, when a request takes too long or if the user has indicated that they want to cancel 
the operation it implements. ALPC supports this with the NtAlpcCancelMessage system call. 
CHAPTER 8 System mechanisms
213
An ALPC message can be on one of five different queues implemented by the ALPC port object:
I 
Main queue A message has been sent, and the client is processing it.
I 
Pending queue A message has been sent and the caller is waiting for a reply, but the reply
has not yet been sent.
I 
Large message queue A message has been sent, but the caller’s buffer was too small to
receive it. The caller gets another chance to allocate a larger buffer and request the message
payload again.
I 
Canceled queue A message that was sent to the port but has since been canceled.
I 
Direct queue A message that was sent with a direct event attached.
Note that a sixth queue, called the wait queue, does not link messages together; instead, it links all 
the threads waiting on a message.
EXPERIMENT: Viewing subsystem ALPC port objects
You can see named ALPC port objects with the WinObj tool from Sysinternals or WinObjEx64 
from GitHub. Run one of the two tools elevated as Administrator and select the root directory. A 
gear icon identifies the port objects in WinObj, and a power plug in WinObjEx64, as shown here 
(you can also click on the Type field to easily sort all the objects by their type):
EXPERIMENT: Viewing subsystem ALPC port objects
You can see named ALPC port objects with the WinObj tool from Sysinternals or WinObjEx64 
from GitHub. Run one of the two tools elevated as Administrator and select the root directory. A 
gear icon identifies the port objects in WinObj, and a power plug in WinObjEx64, as shown here 
(you can also click on the Type field to easily sort all the objects by their type):
214 
CHAPTER 8 System mechanisms
You should see the ALPC ports used by the power manager, the security manager, and 
other internal Windows services. If you want to see the ALPC port objects used by RPC, you can 
select the \RPC Control directory. One of the primary users of ALPC, outside of Local RPC, is the 
Windows subsystem, which uses ALPC to communicate with the Windows subsystem DLLs that 
are present in all Windows processes. Because CSRSS loads once for each session, you will find its 
ALPC port objects under the appropriate \Sessions\X\Windows directory, as shown here:
Asynchronous operation
The synchronous model of ALPC is tied to the original LPC architecture in the early NT design and is 
similar to other blocking IPC mechanisms, such as Mach ports. Although it is simple to design, a block-
ing IPC algorithm includes many possibilities for deadlock, and working around those scenarios creates 
complex code that requires support for a more flexible asynchronous (nonblocking) model. As such, 
ALPC was primarily designed to support asynchronous operation as well, which is a requirement for 
scalable RPC and other uses, such as support for pending I/O in user-mode drivers. A basic feature of 
ALPC, which wasn’t originally present in LPC, is that blocking calls can have a timeout parameter. This 
allows legacy applications to avoid certain deadlock scenarios.
However, ALPC is optimized for asynchronous messages and provides three different models for 
asynchronous notifications. The first doesn’t actually notify the client or server but simply copies the 
data payload. Under this model, it’s up to the implementor to choose a reliable synchronization meth-
od. For example, the client and the server can share a notification event object, or the client can poll for 
data arrival. The data structure used by this model is the ALPC completion list (not to be confused with 
You should see the ALPC ports used by the power manager, the security manager, and 
other internal Windows services. If you want to see the ALPC port objects used by RPC, you can 
select the \RPC Control directory. One of the primary users of ALPC, outside of Local RPC, is the 
Windows subsystem, which uses ALPC to communicate with the Windows subsystem DLLs that 
are present in all Windows processes. Because CSRSS loads once for each session, you will find its 
ALPC port objects under the appropriate \Sessions\X\Windows directory, as shown here:
CHAPTER 8 System mechanisms
215