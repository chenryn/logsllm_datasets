在没有元类的情况下，每次创建实例，在先进入 __init__ 之前都会先进入 __new__ 。
class User:
def __new__(cls, *args, **kwargs):
print("in BaseClass")
return super().__new__(cls)
def __init__(self, name):
print("in User")
self.name = name
使用如下
>>> u = User('wangbm')
in BaseClass
in User
>>> u.name
'wangbm'
在有元类的情况下，每次创建类时，会都先进入 元类的 __new__ 方法，如果你要对类进行定制，
可以在这时做一些手脚。
综上，元类的 __new__ 和普通类的不一样：
元类的 __new__ 在创建类时就会进入，它可以获取到上层类的一切属性和方法，包括类名，魔
法方法。
而普通类的 __new__ 在实例化时就会进入，它仅能获取到实例化时外界传入的属性。
附录：参考文章
Python Cookbook - 元编程
深刻理解Python中的元类
第五章：魔法开发技巧
5.1 嵌套上下文管理的另类写法
当我们要写一个嵌套的上下文管理器时，可能会这样写
import contextlib
@contextlib.contextmanager
def test_context(name):
print('enter, my name is {}'.format(name))
yield
print('exit, my name is {}'.format(name))
with test_context('aaa'):
with test_context('bbb'):
print('========== in main ============')
输出结果如下
enter, my name is aaa
enter, my name is bbb
========== in main ============
exit, my name is bbb
exit, my name is aaa
除此之外，你可知道，还有另一种嵌套写法
with test_context('aaa'), test_context('bbb'):
print('========== in main ============')
5.2 将嵌套 for 循环写成单行
我们经常会如下这种嵌套的 for 循环代码
list1 = range(1,3)
list2 = range(4,6)
list3 = range(7,9)
for item1 in list1:
for item2 in list2:
for item3 in list3:
print(item1+item2+item3)
这里仅仅是三个 for 循环，在实际编码中，有可能会有更层。
这样的代码，可读性非常的差，很多人不想这么写，可又没有更好的写法。
这里介绍一种我常用的写法，使用 itertools 这个库来实现更优雅易读的代码。
from itertools import product
list1 = range(1,3)
list2 = range(4,6)
list3 = range(7,9)
for item1,item2,item3 in product(list1, list2, list3):
print(item1+item2+item3)
输出如下
$ python demo.py
12
13
13
14
13
14
14
15
5.3 单行实现 for 死循环如何写？
如果让你在不借助 while ，只使用 for 来写一个死循环？
你会写吗？
如果你还说简单，你可以自己试一下。
...
如果你尝试后，仍然写不出来，那我给出自己的做法。
for i in iter(int, 1):pass
是不是傻了？iter 还有这种用法？这为啥是个死循环？
关于这个问题，你如果看中文网站，可能找不到相关资料。
还好你可以通过 IDE 看py源码里的注释内容，介绍了很详细的使用方法。
原来iter有两种使用方法。
通常我们的认知是第一种，将一个列表转化为一个迭代器。
而第二种方法，他接收一个 callable对象，和一个sentinel 参数。第一个对象会一直运行，直到
它返回 sentinel 值才结束。
那 int 呢？
这又是一个知识点，int 是一个内建方法。通过看注释，可以看出它是有默认值0的。你可以在
console 模式下输入 int() 看看是不是返回0。
由于int() 永远返回0，永远返回不了1，所以这个 for 循环会没有终点。一直运行下去。
5.4 如何关闭异常自动关联上下文？
当你在处理异常时，由于处理不当或者其他问题，再次抛出另一个异常时，往外抛出的异常也会携
带原始的异常信息。
就像这样子。
try:
print(1 / 0)
except Exception as exc:
raise RuntimeError("Something bad happened")
从输出可以看到两个异常信息
Traceback (most recent call last):
File "demo.py", line 2, in 
print(1 / 0)
ZeroDivisionError: division by zero
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
File "demo.py", line 4, in 
raise RuntimeError("Something bad happened")
RuntimeError: Something bad happened
如果在异常处理程序或 finally 块中引发异常，默认情况下，异常机制会隐式工作会将先前的异常
附加为新异常的 __context__ 属性。这就是 Python 默认开启的自动关联异常上下文。
如果你想自己控制这个上下文，可以加个 from 关键字（ from 语法会有个限制，就是第二个表达
式必须是另一个异常类或实例。），来表明你的新异常是直接由哪个异常引起的。
try:
print(1 / 0)
except Exception as exc:
raise RuntimeError("Something bad happened") from exc
输出如下
Traceback (most recent call last):
File "demo.py", line 2, in 
print(1 / 0)
ZeroDivisionError: division by zero
The above exception was the direct cause of the following exception:
Traceback (most recent call last):
File "demo.py", line 4, in 
raise RuntimeError("Something bad happened") from exc
RuntimeError: Something bad happened
当然，你也可以通过 with_traceback() 方法为异常设置上下文 __context__ 属性，这也能在
traceback 更好的显示异常信息。
try:
print(1 / 0)
except Exception as exc:
raise RuntimeError("bad thing").with_traceback(exc)
最后，如果我想彻底关闭这个自动关联异常上下文的机制？有什么办法呢？
可以使用 raise...from None ，从下面的例子上看，已经没有了原始异常
$ cat demo.py
try:
print(1 / 0)
except Exception as exc:
raise RuntimeError("Something bad happened") from None
$
$ python demo.py
Traceback (most recent call last):
File "demo.py", line 4, in 
raise RuntimeError("Something bad happened") from None
RuntimeError: Something bad happened
(PythonCodingTime)
5.5 自带的缓存机制不用白不用
缓存是一种将定量数据加以保存，以备迎合后续获取需求的处理方式，旨在加快数据获取的速度。
数据的生成过程可能需要经过计算，规整，远程获取等操作，如果是同一份数据需要多次使用，每
次都重新生成会大大浪费时间。所以，如果将计算或者远程请求等操作获得的数据缓存下来，会加
快后续的数据获取需求。
为了实现这个需求，Python 3.2 + 中给我们提供了一个机制，可以很方便的实现，而不需要你去写
这样的逻辑代码。
这个机制实现于 functool 模块中的 lru_cache 装饰器。
@functools.lru_cache(maxsize=None, typed=False)
参数解读：
maxsize：最多可以缓存多少个此函数的调用结果，如果为None，则无限制，设置为 2 的幂
时，性能最佳
typed：若为 True，则不同参数类型的调用将分别缓存。
举个例子
from functools import lru_cache
@lru_cache(None)
def add(x, y):
print("calculating: %s + %s" % (x, y))
return x + y
print(add(1, 2))
print(add(1, 2))
print(add(2, 3))
输出如下，可以看到第二次调用并没有真正的执行函数体，而是直接返回缓存里的结果
calculating: 1 + 2
3
3
calculating: 2 + 3
5
5.6 如何流式读取数G超大文件
使用 with...open... 可以从一个文件中读取数据，这是所有 Python 开发者都非常熟悉的操作。
但是如果你使用不当，也会带来很大的麻烦。
比如当你使用了 read 函数，其实 Python 会将文件的内容一次性的全部载入内存中，如果文件有
10 个G甚至更多，那么你的电脑就要消耗的内存非常巨大。
## 
with open("big_file.txt", "r") as fp:
content = fp.read()
对于这个问题，你也许会想到使用 readline 去做一个生成器来逐行返回。
def read_from_file(filename):
with open(filename, "r") as fp:
yield fp.readline()
可如果这个文件内容就一行呢，一行就 10个G，其实你还是会一次性读取全部内容。
最优雅的解决方法是，在使用 read 方法时，指定每次只读取固定大小的内容，比如下面的代码
中，每次只读取 8kb 返回。
def read_from_file(filename, block_size = 1024 * 8):
with open(filename, "r") as fp:
while True:
chunk = fp.read(block_size)
if not chunk:
break
yield chunk
上面的代码，功能上已经没有问题了，但是代码看起来代码还是有些臃肿。
借助偏函数 和 iter 函数可以优化一下代码
from functools import partial
def read_from_file(filename, block_size = 1024 * 8):
with open(filename, "r") as fp:
for chunk in iter(partial(fp.read, block_size), ""):
yield chunk
如果你使用的是 Python 3.8 +，还有一种更直观、易于理解的写法，既不用使用偏函数，也不用掌
握 iter 这种另类的用法。而只要用利用 海象运算符就可以，具体代码如下
def read_from_file(filename, block_size = 1024 * 8):
with open(filename, "r") as fp:
while chunk := fp.read(block_size):
yield chunk
5.7 实现类似 defer 的延迟调用
在 Golang 中有一种延迟调用的机制，关键字是 defer，例如下面的示例
import "fmt"
func myfunc() {
fmt.Println("B")
}
func main() {
defer myfunc()
fmt.Println("A")
}
输出如下，myfunc 的调用会在函数返回前一步完成，即使你将 myfunc 的调用写在函数的第一行，
这就是延迟调用。
A
B
那么在 Python 中否有这种机制呢？
当然也有，只不过并没有 Golang 这种简便。
在 Python 可以使用 上下文管理器 达到这种效果
import contextlib
def callback():
print('B')
with contextlib.ExitStack() as stack:
stack.callback(callback)
print('A')
输出如下
A
B
5.8 如何快速计算函数运行时间
计算一个函数的运行时间，你可能会这样子做
import time
start = time.time()
## run the function
end = time.time()
print(end-start)
你看看你为了计算函数运行时间，写了几行代码了。
有没有一种方法可以更方便的计算这个运行时间呢？
有。
有一个内置模块叫 timeit
使用它，只用一行代码即可
import time
import timeit
def run_sleep(second):
print(second)
time.sleep(second)
## 
print(timeit.timeit(lambda :run_sleep(2), number=5))
运行结果如下
2
2
2
2
2
10.020059824
5.9 重定向标准输出到日志
假设你有一个脚本，会执行一些任务，比如说集群健康情况的检查。
检查完成后，会把各服务的的健康状况以 JSON 字符串的形式打印到标准输出。
如果代码有问题，导致异常处理不足，最终检查失败，是很有可能将一些错误异常栈输出到标准错
误或标准输出上。
由于最初约定的脚本返回方式是以 JSON 的格式输出，此时你的脚本却输出各种错误异常，异常调
用方也无法解析。
如何避免这种情况的发生呢？
我们可以这样做，把你的标准错误输出到日志文件中。
import contextlib
log_file="/var/log/you.log"
def you_task():
pass
@contextlib.contextmanager
def close_stdout():
raw_stdout = sys.stdout
file = open(log_file, 'a+')
sys.stdout = file
yield
sys.stdout = raw_stdout
file.close()
with close_stdout():
you_task()
5.10 快速定位错误进入调试模式
当你在写一个程序时，最初的程序一定遇到不少零零散散的错误，这时候就免不了调试一波。
如果你和我一样，习惯使用 pdb 进行调试的话，一定有所体会，通常我们都要先把
pdb.set_trace() 去掉，让程序畅通无阻，直到它把异常抛出来。
出现异常后，再使用 vim 跳转到抛出异常的位置，敲入 import pdb;pdb.set_trace() ，然后再到
运行，进入调试模式，找到问题并修改代码后再去掉我们加上的那行 pdb 的代码。
如此反复这样一个过程，直到最后程序没有异常。
你应该能够感受到这个过程有多繁锁，令人崩溃。
接下来介绍一种，可以让你不需要修改源代码，就可以在异常抛出时，快速切换到调试模式，进入
‘案发现场’排查问题。
方法很简单，只需要你在执行脚本时，加入 -i 参考
如果你的程序没有任何问题，加上 -i 后又会有什么不一样呢？
从下图可以看出，程序执行完成后会自动进入 console 交互模式。
5.11 在程序退出前执行代码的技巧
使用 atexit 这个内置模块，可以很方便的注册退出函数。
不管你在哪个地方导致程序崩溃，都会执行那些你注册过的函数。
示例如下
如果 clean() 函数有参数，那么你可以不用装饰器，而是直接调用
atexit.register(clean_1, 1, 2, 3='xxx') 。
可能你有其他方法可以处理这种需求，但肯定比上不使用 atexit 来得优雅，来得方便，并且它很容
易扩展。
但是使用 atexit 仍然有一些局限性，比如：
如果程序是被你没有处理过的系统信号杀死的，那么注册的函数无法正常执行。
如果发生了严重的 Python 内部错误，你注册的函数无法正常执行。