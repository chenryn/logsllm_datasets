by anomaly score, of the most suspicious processes. System
administrators can analyze process behavior through the SIG,
prioritizing the ones with the highest anomaly scores.
4.2 Software Installation Graphs
Similar to prior systems [23, 31], SIGL builds SIGs using
common logging frameworks (e.g., Windows ETW and Linux
Audit) based on standard provenance models [76]. SIGL trans-
forms each audit log event into an edge, whose source rep-
resents the subject of the event (i.e., the entity responsible
for creating the log record) and whose destination represents
the object being acted upon (e.g., ﬁles, socket connections).
The edge itself represents a dependency relationship between
these entities. Table 1 shows the dependency relationships
that we consider in our work.
2348    30th USENIX Security Symposium
USENIX Association
sent, while effectively leveraging the classic word2vec [55]
learning model. To the best of our knowledge, we are the
ﬁrst to use a neural-network-based approach to meaningfully
featurize system-level provenance nodes.
Node Embedding in SIGL. In NLP, word2vec embeds
words into a low-dimensional continuous vector space,
where words with similar context map closely together.
Given a sequence of words, word2vec employs a skip-gram
model whose objective is to maximize the log probability
of predicting the context around a given target word. A
ﬁxed size sliding window on the text sequence deter-
mines the context. Assuming the likelihood of observing
each context word is independent given the target word,
t=1 logP(wt−C, ...,wt+C|wt ) =
word2vec maximizes: max∑T
t=1 ∑−C≤c≤C logP(wt+c|wt ) . P(wt+c|wt ) is deﬁned by a
max∑T
softmax function: P(wt+c|wt ) = exp(wt+c·wt )
where C is the
i=1 exp(wi·wt )
∑V
window size, wt+c and wt are the embeddings of the context
word wt+c and the target word wt; V is the vocabulary size.
We apply word2vec as a basis for our embedding ap-
proach to featurize path names associated with SIG nodes.
Each node in a SIG, whether ﬁle, process, or socket, corre-
sponds to a ﬁle system path name. These path names en-
code important semantic relationships. Using the same ex-
ample from earlier, c:\windows\system32\ntdll.dll and
c:\windows\system32\kernel32.dll reside in the same
directory, because they both contain kernel functions.
To map semantically related nodes close in the embedding
space, we use a component-based node embedding model,
where SIGL learns the embedding of each component of a
path and then follows an additive method [34] to embed a
node as the normalized summation of its path components.
SIGL performs directed random walks of ﬁxed length l to
construct the causal context for each node: Given a source
node c0 in the SIG, SIGL traverses the graph following the
direction of the edges. If a node has more than one outgoing
edge, SIGL randomly picks an edge to continue the walk. Let
ci denote the ith node in the walk. The causal context C for c0
is {ci|i = 1, . . . ,l}, where ci is generated by the distribution:
P(ci = v|ci−1 = u) =
, where N is the number
of outgoing edges from ci−1. SIGL generates multiple causal
contexts for each node.
if (u,v) ∈ E
otherwise
(cid:40) 1
N
0
Unlike existing embedding frameworks [18, 25, 63], our
approach does not consider each node label as an atomic
individual whose meaning can be derived only from neighbor-
ing nodes through random walks along the network; instead,
each path component essentially becomes part of the context.
If we treat the pathname as a single attribute, such context
information is lost in the resulting embedding.
Embedding Unseen Nodes. The approach described so far
produces embeddings for only those nodes that have been
observed in the training graphs (GT ). As mentioned above,
software installation often creates temporary folders with
meaningless base path names, sometimes containing machine-
speciﬁc variations. In these cases, SIGL uses the à la carte
embedding model [41], which follows the distributional hy-
pothesis [30] to efﬁciently infer the embeddings for out-of-
vocabulary (OOV) words via a linear transformation of ad-
ditive context embedding (i.e., the average embeddings of
context words). Given the contexts Cw of a word w in a
vocabulary and assuming a ﬁxed context window size |c|,
a linear transformation is learned through vw ≈ Avadditive
=
A( 1|Cw| ∑c∈Cw ∑w(cid:48)∈c vw(cid:48) ) , where vw are existing high-quality
word embeddings. After learning the matrix A, any OOV
word f can be embedded in the same semantic space by
= A( 1|Cf | ∑c∈Cf ∑w∈c vw) . à la carte comple-
v f = Avadditive
ments the component-based embedding approach, because it
uses the same context-aware and additive mechanism. Thus,
we produce meaningful embeddings using both random walks
and pathname components. For example, given an unseen
DLL c:\windows\system32\wow64.dll, our component-
based approach allows à la carte to take into consideration
its parent directories (which are the same as those learned for
the ntdll.dll and kernel32.dll nodes), in addition to any
random walks that pass through the node.
w
f
SIGL trains the à la carte model using GT and uses the
trained model to featurize unseen nodes in the validation
graphs GV and during live deployment.
4.4 Deep Graph Learning on SIGs
SIGL uses an autoencoder to learn a robust representation
of the process nodes in a SIG for both anomaly detection
and prioritization. The autoencoder consists of two parts: an
encoder, for which we use a graph long short-term memory
network (graph LSTM), and a decoder, for which we use a
multilayer perceptron (MLP).
Graph LSTM. An LSTM [32] captures long-term depen-
dencies of linear sequences. Originally developed for NLP
tasks, LSTMs have been successfully adapted to a variety
of sequence modeling and prediction tasks, such as pro-
gram execution [83] and attack prediction [68]. The standard
LSTM architecture learns sequential information propagation
only; tree-structured LSTMs [72] and the more general graph
LSTMs [62] are two natural extensions that incorporate richer
network topologies. Graph LSTMs allow for ﬂexible graph
structures (e.g., DAGs) and consider distinct edge types. We
refer interested readers to Peng et al. [62] for technical details.
SIGL’s Autoencoder. Intuitively, SIGL’s autoencoder models
process nodes as a function of those nodes that came before
them (temporally) in the SIG. The intuition underlying this
encoder-decoder architecture is that anomalous nodes are
inherently difﬁcult to be represented accurately in the em-
bedding space, so trying to reconstruct them produces much
larger reconstruction losses. SIGL uses those losses to distin-
guish abnormal installations from normal ones (§ 4.5).
Although an alternative solution would be to use a binary
classiﬁer to determine if a SIG represents a normal installation
USENIX Association
30th USENIX Security Symposium    2349
or not, training such a classiﬁer would require more labeled
data (both normal and anomalous SIGs) than can easily be
collected [5]. A set of SIGs dominated by normal installations
produces class imbalance, and imbalanced two-class training
often results in poor model performance [80]. Additionally,
as an attacker’s modus operandi changes over time, keeping
the trained classiﬁer up-to-date becomes impractical [68].
Binary classiﬁcation also provides no insight on the cause of
the attack. A system administrator would have to manually
compare a problematic SIG to one or more known good SIGs
to identify potentially malicious processes.
SIGL’s autoencoder addresses limitations of binary classiﬁ-
cation through unsupervised one-class learning that requires
only normal SIGs. It jointly trains the graph LSTM, as the
encoder, with a MLP as the decoder. The encoder learns the
hidden representation of each process node through the graph
LSTM, taking into account the node’s attributes (i.e., feature
embedding) and the hidden representations of all its source
nodes (i.e., temporality) distinguished by the connection types
(i.e., heterogeneity). The decoder then learns to reconstruct
the original node embedding from the hidden representation
(h j). The objective is to minimize the reconstruction loss in
the training dataset GT , which consists of only normal SIGs
(i.e., unsupervised learning).
4.5 Anomaly Detection
The autoencoder’s neural network architecture learns to
reconstruct process nodes. Nodes that show signiﬁcant topo-
logical difference from those encountered during training
correspond to unexpected changes in installation behavior,
which signals malware activity and will lead to large recon-
struction errors. SIGL is a deviation-based anomaly detection
system [3], in that it treats process nodes with high reconstruc-
tion loss as anomalies. By ranking process nodes in a SIG by
their reconstruction losses (i.e., anomaly scores), SIGL helps
system administrators prioritize analysis of anomalous nodes
and quickly eliminate false alarms.
SIGL determines a normality threshold from the reconstruc-
tion losses observed during validation. We typically observe
that a small number of process nodes (e.g., those with a large
number of descendants) are inherently much more difﬁcult to
reconstruct than the rest of the process nodes in a SIG. These
nodes have orders of magnitude higher reconstruction losses.
If we arrange the losses in descending order, we observe “nat-
ural breaks” that partition nodes into ranges. The losses in the
ﬁrst range, i.e., the ones with the largest values, represent the
“limits” of SIGL’s representational capability, thus providing
us with a reasonable baseline to determine the threshold of
normal software installation.
SIGL uses Jenks’ natural breaks [36], a statistical map-
ping method, to systematically discover class intervals of the
natural breaks in the data series (i.e., reconstruction losses).
Jenks’ natural breaks is an iterative optimization method that
minimizes intra-class variance while maximizing inter-class
variance by moving one value from the class with the largest
deviations from the mean to the class with the lowest until the
sum of the intra-class deviations reaches its minimum [37].
Algorithm 1: Normality Threshold
:Validation graph set GV
:Normality threshold T
Input
Output
Variables :thresholdList ← list of largest average losses from GV
thresholdList ← []
for G ∈ GV do
nodeLosses = GraphAutoEncoder(G)
largestAverageLoss = JenksMaxZoneAvg(nodeLosses)
thresholdList.append(largestAverageLoss)
1
2
3
4
5
6 std ← standardDeviation(thresholdList)
7 mean ← mean(thresholdList)
8 T ← mean + 3 * std
9 return T
10 Func JenksMaxZoneAvg(nodeLosses):
11
12
zone1, zone2, . . . = JenksNaturalBreaks(nodeLosses)
return max(mean(zone1), mean(zone2), . . . )
Using Jenks’ natural breaks, which separates reconstruc-
tion losses of a SIG’s process nodes into multiple “zones”,
SIGL identiﬁes the zone with the largest average loss for each
validation graph and constructs a threshold list that contains
those average losses for all the validation graphs. The nor-
mality threshold in our experiments (§ 5) is set to be three
standard deviations above the average value of the thresh-
old list. However, system administrators can easily adjust
this threshold according to their needs (e.g., to optimize to-
wards a low false positive/negative rate). Alg. 1 shows the
pseudocode for setting the threshold. Given the normality
threshold, SIGL considers any SIG exceeding this threshold
as abnormal and provides system administrators with a list of
its process nodes sorted by their anomaly scores.
5 Evaluation
We present a number of experiments to evaluate SIGL as a
behavior-based malware detection system for secure software
installation on enterprise end-point systems and an experi-
mental testbed. We focus on the following research questions:
Q1. What is the performance of SIGL in detecting malicious
software installation, and how does it compare to existing
commercial TDS and other anomaly-based detection systems
that leverage data provenance? (§ 5.3, § 5.4)
Q2. Can SIGL effectively guide cyber-analysts to quickly
identify abnormal processes and potential malware? (§ 5.5)
Q3. Can SIGL be realistically used in an enterprise setting?
(§ 5.6, § 5.7, § 5.8, § 5.10, § 5.11)
Q4. How robust is SIGL against adversarial attackers? (§ 5.9)
Q5. Can SIGL generalize to a large variety of software pack-
ages and different platforms? (§ 5.12)
5.1 Datasets
We describe our methodology to collect audit data from
benign and malware-infected software installations from all
the workstations at NEC Labs America using Windows ETW.
We also generated additional datasets on our Linux testbed
using Linux Audit. All experiments related to the testbed are
2350    30th USENIX Security Symposium
USENIX Association
Software Installer
FireFox N
FileZilla N
PWSafe
MP3Gain
ShotCut
TeamViewer N
Foobar
7Zip
TurboVNC
WinMerge
Launchy
Skype N
WinRAR
DropBox N
Slack N
Flash N
OneDrive N
NotePad++
ICBC Anti-Phishing
ESET AV Remover (cid:70)
Version
18.1.0
3.35.1
3.48.0
1.2.5
18.12.23
14.4.2669
1.4.6
18.5.0
2.1.2
2.14.0
2.5
8.50.0
5.71.0
79.4.143
4.0.1
32.0.0.223
19.103.527
7.7.1
1.0.8
1.4.1
Installation Framework
Mozilla Installer
Nullsoft Scriptable Install System
Nullsoft Scriptable Install System
Nullsoft Scriptable Install System
Nullsoft Scriptable Install System
Nullsoft Scriptable Install System
Nullsoft Scriptable Install System
SFX
Inno Setup
Inno Setup
Inno Setup
Inno Setup
SFX
DropBox Installer
NuGet Package
Flash Installer
SFX
NotePad Installer
ICBC Installer
ESET Installer
# T
86
88
88
88
85
84
85
88
88
85
151
80
84
84
84
84
84
85
85
75
# V
12
12
12
11
12
12
12
12
12
11
21
11
12
11
12
12
12
11
11
10
# BT
24
24
24
23
24
24
24
24
24
23
42
22
24
23
24
24
24
23
23
21
# M
20
40
40
40
40
40