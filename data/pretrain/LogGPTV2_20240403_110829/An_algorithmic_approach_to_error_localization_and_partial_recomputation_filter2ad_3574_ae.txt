The input vector of the matrix vector product constitutes the
application checkpoint.
Each technique is applied to an instance of the Parallel CG
algorithm (N=10) on linear problems, deﬁned by the matrices
described in Section IV-B. These solvers are run until a ﬁxed
accuracy of 1e-6.
Figure 4 shows the performance overheads of each tech-
nique across varying fault rates ranging from 1e-8 to 1e-4 on
the axis. The y-axis shows the performance overhead that is
calculated for each matrix by:
(cid:18)
(cid:19)
T imetechi
T imeN ON E with zero faults
− 1
T imetechi
is the execution time of a given technique
and T imeN ON E is execution time of the solver without any
fault tolerance techniques applied. Each dot in the Figure 4
represents the average performance of a particular technique
applied to a speciﬁc problem. The overhead is calculated in
relation to runs with no fault tolerance and zero faults (as
discussed in Section
IV. Each line represents the mean
overhead across all of the problems at each fault rate. The
ﬁrst observation from these results is that the detection and
rollback techniques have a high cost (> 200%) as the fault
rate increases. For low fault rates (e.g., between 1e-8 and
1e-7), both the PR and DR based techniques have a similar
mean overhead around 50%, but after a fault rate of 1e-7, the
overheads of DR-based approaches increase to over 100% on
average. This is expected due to the higher cost of recovery
for these traditional approaches. If we observe the PR-based
techniques, however, we see that the mean overheads increase
much more slowly. In fact, PR-based techniques may have
as much as 2x-3x less overhead. In particular, the PR based
approach that only locates faults to within segments located
at 0.4 the total height of the binary search tree, shows only a
30% average overhead from fault rates ranging from 1e-8 to
1e-4 (as opposed to up to 3x with DR - perfect detection).
If the fault rates increase past a certain point, nearly every
entry of the output will end up being erroneous for the matrices
we chose. For such fault rates, the beneﬁts of PR-based ap-
proaches will diminish versus DR based approaches. However,
for most real world problems, the range of fault rates before
this “saturating point” is hit encompasses even the worst-
case expected operating points for future HPC systems. For
example, with the sparse matrices considered in this evaluation,
the high fault rate scenarios (1e-6 – 1e-4) correspond to only
0.0001% to 0.01% of the output being corrupted. As systems
and problems scale to even larger size (e.g. millions and
billions of nodes), increasingly smaller fraction of output will
be corrupted for any reasonable fault rate and as such the value
of the PR-based approaches will only increase.
Figure 4 also shows that the overheads at any given fault
rate can vary signiﬁcantly based on the properties of the matrix.
For example, for problems bcsstk16 and nd3k the overheads are
signiﬁcantly larger for the techniques using practical detection
schemes (PR-based and DR (t=1)). This is because the average
magnitude of entries within these problems is very large,
making it difﬁcult
to detect faults with a ﬁxed threshold
(bcsstk16 and nd3k contain average magnitudes of 1e6 and
1e − 4 respectively). Therefore, the detection and fault local-
ization process is less accurate and incurs greater overheads
from false negatives and false positives. Other problems are
simply poorly conditioned and incur high overheads across all
techniques (e.g. nasa2910 has a condition number of 1e64). In
general, the overheads for the different matrices are near their
representative means (±30%).
Each of the solver instances is run under faults until it either
hits the accuracy target or the limit on the maximum number
of iterations (10xnumberof rows). If the solver does not meet
the accuracy target by the maximum number of iterations, it
is considered as a failure. Figure 5 shows the success rate
for each of the techniques over the same set of matrices and
fault rates as Figure 4, on the x-axis. The solvers are run
until convergence and for a maximum number of iterations
(10*dimension of problem). As the fault rate increases, DR
is less likely to make forward progress, and increasingly not
able to meet the accuracy target by the maximum number of
iterations. All the techniques, except DR using a realistic
threshold, complete nearly 80% of the tested matrices. For
solver instances using DR(t = 1), the success rate drops off
quickly going from 1e-8 to 1e-4 due to the high overhead of
rollbacks and the overhead of extra iterations incurred due to
missed faults. Solver instances using DR with perfect detection
show good success rates until a fault rate of 1e-4 where the
high overhead of rollback-based recoveries prohibits the solver
from meeting the accuracy target by the iteration limit.
Fig. 4: Parallel CG Performance of techniques when scaling
the fault rate, (N=10). At a fault of 1e-4 none of the DR
experiments completed successfully (i.e. reached the accuracy
target in maximum number of iterations).
Fig. 5: Parallel CG Success Rate of techniques when scaling
the fault rate, (N=10).
implemented with MPI is included in Section
IV-C. Fig-
ure 6 illustrates the results of the experiments. Again, dots
correspond to individual experiments and lines corresponding
to the mean overheads. For these experiments, we calculated
the overhead for each matrix by:
(cid:18) T imetechi with N nodes and 1e-6 faults
(cid:19)
− 1
A. Scalability of Techniques
T imeN ON E with N nodes and zero faults
As the number of nodes in the system increases, we also
expect the beneﬁts of a partial computation based approach
vs traditional detection to increase. In order to evaluate the
scalability of the techniques, we ﬁx the fault rate (1e-6)
and run the same experiments with different numbers of
nodes ({1, 2, 10, 20, 100}). A description of the parallel solver
We see in Figure 6 that the beneﬁt of PR-based approaches
increases as the number of nodes scales up. At N=10, the
average overhead of DR-based approaches over PR is 50%.
As the number of nodes used in the solver is increased to
100, the overheads of DR over PR are even more pronounced,
increasing over 300% − 350%. These results indicate that
10
0501001502001e−081e−074e−071e−064e−061e−051e−04Fault ratePerformance Overhead(%)TechniquePR (d=1)PR (d=.4)DR (perfect detection)DR (t=1)0204060801001e−081e−074e−071e−064e−061e−051e−04Fault RateSuccess Rate (%)TechniquePR (d=1)PR (d=0.4)DR (perfect detection)DR (t=1)more realistic detection schemes using dynamic thresholds,
partial recomputation-based approaches are signiﬁcantly more
efﬁcient (CG converges 70% more often and performance
overheads 2x-3x smaller). For a ﬁxed moderate fault rate,
partial recomputation-based approaches with complete error
localization reduce the overhead by up to 32% on average
when scaled up to 10 nodes and 320% when scaled up to 100
nodes. Similarly, with the relaxed error localization routine the
overhead is reduced by up to 77% at 10 nodes and up to 390%
at 100 nodes.
Our results demonstrate the value of research into partial
recomputation in the context of a wider range of algorithms.
Since this approach is signiﬁcantly more efﬁcient than whole-
application recomputation and also signiﬁcantly simpler than
algorithmic correction techniques, we expect
this line
of work will be extremely productive in ensuring cheap and
effective resilience on future massively parallel systems.
that
VII. ACKNOWLEDGMENTS
This work was supported in part by NSF, ARO, GSRC,
and the Department of Energy Early Career award program.
It was also partially performed under the auspices of the U.S.
Department of Energy by Lawrence Livermore National Labo-
ratory under Contract DE-AC52-07NA27344. We thank Tzanio
Kolev and anonymous reviewers for their helpful feedback.
REFERENCES
[1] Mpich-v. http://mpich-v.lri.fr.
[2] International Technology Roadmap for Semiconductors.
White Paper, ITRS, 2010.
[3] J. Anﬁnson and F. T. Luk. A linear algebraic model of
IEEE Trans. Comput.,
algorithm-based fault tolerance.
37:1599–1604, December 1988.
[4] Greg Bronevetsky, Ignacio Laguna, Saurabh Bagchi, Bro-
nis R. de Supinski, Dong H. Ahn, and Martin Schulz.
AutomaDeD: Automata-Based Debugging for Dissimilar
Parallel Tasks. In 2010 IEEE/IFIP International Confer-
ence on Dependable Systems and Networks (DSN), pages
231 –240, Chicago, IL, 2010. resilience.
[5] Greg Bronevetsky, Daniel Marques, Keshav Pingali, and
Paul Stodghill. Automated application-level checkpoint-
ing of mpi programs. SIGPLAN Not., 38(10):84–94, June
2003.
[6] Zizhong Chen. Algorithm-based recovery for iterative
In Proceedings of the
methods without checkpointing.
20th international symposium on High performance dis-
tributed computing, HPDC ’11, pages 73–84, New York,
NY, USA, 2011. ACM.
[7] Timothy A. Davis. University of ﬂorida sparse matrix
collection. NA Digest, 92, 1994.
[8] Berman et. al. Exascale computing study: Technology
challenges in achieving exascale systems peter kogge,
editor & study lead. Technical report, DARPA IPTO,
SEP 2008.
[9] J. N. Glosli et. al. Extending stability beyond cpu mil-
lennium: a micron-scale atomistic simulation of kelvin-
the 2007
helmholtz instability.
ACM/IEEE conference on Supercomputing, SC ’07, pages
58:1–58:11, New York, NY, USA, 2007. ACM.
In Proceedings of
Fig. 6: Parallel CG Performance of techniques when scaling
up the number of nodes from 1 to 100, with a ﬁxed fault rate
of 1e-6
the rollback recovery mechanism represents a signiﬁcant bot-
tleneck for traditional parallel fault
tolerance mechanisms.
Additionally, it shows that the scalability of these applications
can be greatly approved by utilizing error localization and
partial recomputation to alleviate this bottleneck.
VI. CONCLUSIONS
Future HPC and massively parallel systems will be prone
to errors and severely energy constrained. For these systems, it
will be critical for errors to be efﬁciently tolerated in order to
ensure good forward progress. The traditional approach for
dealing with errors in massively parallel systems is to roll
the application back to a prior checkpoint whenever a fault is
detected. However, this approach incurs a high cost in transfer-
ring checkpoint data [23] and a large cost in recomputing lost
work. While this may be acceptable in scenarios where faults
are rare, the cost of full-application rollback can be prohibitive
for error prone HPC systems.
We propose a novel approach for algorithmic correction
of faulty application outputs based on error localization and
partial recomputation. The key insight of our approach is that
even under high error scenarios, a large fraction of the output is
correct even if a portion of it is erroneous. Therefore, instead of
simply rolling back to the most recent checkpoint and repeating
the entire segment of computation, our approach identiﬁes and
corrects the actual subsegments of the output which are faulty.
By alleviating a key bottleneck associated with recovery, the
parallel applications employing our fault tolerance techniques
are able to scale signiﬁcantly better. We explore this concept
in the context of numerical
linear algebra – the matrix-
vector multiplication (MVM) operation as well as iterative
linear solvers, in high error scenarios on parallel systems.
Numerical linear algebra dominates computation in many HPC
and RMS applications. Our experiments show that while tradi-
tional detection/rollback has 2x-3x overhead under high fault
rates, partial recomputation is 2x cheaper while maintaining
similar accuracy as ideal detection/rollback approaches. With
11
0100200300400500121020100Number of NodesPerformance Overhead (%)TechniquePR (d=1)PR (d=0.4)DR (perfect detection)DR (t=1)[10] Jack Dongarra Andrew et. al. A sparse matrix library in
page 11, nov. 2006.
c++ for high performance architectures, 1994.
[11] Keun Soo Yim et. al. Hauberk: Lightweight silent data
In Proceedings
corruption error detector for gpgpu.
of the 2011 IEEE International Parallel & Distributed
Processing Symposium, IPDPS ’11, 2011.
[12] Man-lap Li et. al. Swat: An error resilient system, 2008.
[13] Nahmsuk Oh et. al. Control-ﬂow checking by software
IEEE Transactions on Reliability, 51:111–
signatures.
122, 2002.
[23] Adam Moody, Greg Bronevetsky, Kathryn Mohror, and
Bronis R. de Supinski. Design, modeling, and evalua-
tion of a scalable multi-level checkpointing system.
In
ACM/IEEE Conference on Supercomputing, 2010.
[24] Sung-Boem Park, Anne Bracy, Hong Wang, and Sub-
hasish Mitra. Blog: post-silicon bug localization in
processors using bug localization graphs. In Proceedings
of the 47th Design Automation Conference, DAC ’10,
pages 368–373, New York, NY, USA, 2010. ACM.
[25] Valeria Simoncini, Daniel, and B. Szyld. Theory of
inexact krylov subspace methods and applications to
scientiﬁc computing. Technical report, 2002.
[26] J. Sloan, D. Kesler, R. Kumar, and A. Rahimi. A
numerical optimization-based methodology for applica-
tion robustiﬁcation: Transforming applications for error
tolerance. In Dependable Systems and Networks (DSN),
2010, June 2010.
[27] J. Sloan, R. Kumar, and G. Bronevetsky. Algorithmic
approaches to low overhead fault detection for sparse
In Dependable Systems and Networks
linear algebra.
(DSN), 2012, 2012-july 1 2012.
[28] Gregory F. Sullivan, Dwight S. Wilson, and Gerald M.
IEEE
Masson. Certiﬁcation of computational results.
Transactions on Computers, 44:833–847, 1995.
[29] Diana Szentivanyi, Simin Nadjm-Tehrani, and John M.
Noble. Optimal choice of checkpointing interval for
the 11th Paciﬁc
high availability.
Rim International Symposium on Dependable Computing,
PRDC ’05, pages 159–166, Washington, DC, USA, 2005.
IEEE Computer Society.
In Proceedings of
[30] Chao Wang, Frank Mueller, Christian Engelmann, and
Stephen L. Scott. A job pause service under lam/mpi+blcr
for transparent fault tolerance. In In International Parallel
and Distributed Processing Symposium, pages 26–30,
2007.
[31] Hadley Wickham. ggplot2: elegant graphics for data
analysis. Springer New York, 2009.
[14] Nithin Nakka et. al. An architectural framework for
In In DSN,
providing reliability and security support.
pages 585–594. IEEE Computer Society, 2004.
[15] Ronald F. Boisvert et. al. Matrix market: A web resource
for test matrix collections. In The Quality of Numerical
Software: Assessment and Enhancement, pages 125–137.
Chapman and Hall, 1997.
[16] Sarah Michalak et. al. Predicting the Number of Fatal
Soft Errors in Los Alamos National Laboratorys ASC
IEEE Transactions on Device and
Q Supercomputer.
Materials Reliability, 5(3), 2005.
[17] Michael A. Heroux and Mark Hoemmen. Fault-tolerant
iterative methods via selective reliability.
Technical
report, Sandia National Laboratories Technical Report,
2011.
[18] Kuang-Hua Huang and J.A. Abraham. Algorithm-based
fault tolerance for matrix operations. Computers, IEEE
Transactions on, C-33(6):518 –528, 1984.
[19] P. Hargrove J. Duell and E. Roman. The design and
implementation of berkeley labs linux checkpoint/restart.
Technical report, Berkeley lab Technical Report, 2002.
[20] C. Kong. Study of voltage and process variation’s impact
on the path delays of arithmetic units. In UIUC Master’s
Thesis, 2008.
[21] Yehuda Koren, Robert Bell, and Chris Volinsky. Matrix
factorization techniques for recommender systems, 2009.
[22] A.V. Mirgorodskiy, N. Maruyama, and B.P. Miller. Prob-
lem diagnosis in large-scale computing environments.
In SC 2006 Conference, Proceedings of the ACM/IEEE,
12