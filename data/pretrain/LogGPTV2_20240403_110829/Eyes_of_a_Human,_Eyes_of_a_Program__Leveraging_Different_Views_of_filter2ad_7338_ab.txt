JavaScript, although, as mentioned, many search engines do provide guidelines
for webmasters that are consistent with the necessity to expose content to spiders
that ignore JavaScript [14,28,47] and images [12,28,48], and many published
detection systems use static signature matching (e.g., [30,35,42]). The choice of
this boundary between the “human-browser” world and the “automated-parser”
world has also been indirectly conﬁrmed by our ﬁndings presented in Section 4.3:
Many pages (both benign and malicious) use JavaScript code to hide information
they do not want exposed to automated parsers.
4.1 Heuristic
Several encapsulation and encoding schemes are used to transfer text on the
web. A banking web site might, for example, provide content encoded in UTF-8,
compressed by the server with gzip and transferred over a TLS connection. From
the point of view of the client, however, these schemes are completely transparent:
once the encoding layers are removed, a well-deﬁned payload is reached for every
data transfer.
A key observation is that text will almost always appear as-is in the payload.
In the simplest case an HTML page will be retrieved from the network, its
content will be parsed in a tree, a layout will be constructed, and the resulting
page will be presented to the user. The browser will simply copy the content of
text nodes from the original payload, HTML entities being the only exception
to this rule.
Web pages can also use scripts to dynamically add content to the page tree. This
content may have already been present in the original payload (as a JavaScript
string literal, for example), or it may come from additional network requests. This
text does not have to be sent as-is: the script that loads the text is free to mangle
and re-code it as it sees ﬁt. There is, however, little reason to do so, and it seems
safe to assume that legitimate websites will never engage in such practices: In
fact, by comparing the dynamically constructed page with the observed payloads,
we have been able to conﬁrm that textual data is transferred as-is in the vast ma-
jority of cases.
There are a few fundamental reasons for this. For purely textual content (at
the sizes typically seen in web payloads), the built-in gzip compression is better,
needs no extra code transfers, and is far easier to use than custom code; in fact,
none of the JavaScript code compression tools in popular use signiﬁcantly alter
136
J. Corbetta et al.
string literals. Popular data transfer formats such as JSON and XML are also
text-based. There is also a historical preference for human-readable data on the
web (the HTTP protocol itself is an example), both to help debugging and to
ease interoperability.
While we have observed some overly-cautious escaping of content, most cases
where text was not transferred as-is were due to deliberate obfuscation attempts.
One can certainly devise obfuscation systems that necessarily require human
interaction and would hide text from this and any other automated detection
attempt: For example, the sensitive content can be encrypted and the password
presented in an image that cannot be easily parsed automatically (using, for
example, the same obfuscation techniques used for CAPTCHA test images).
However, this involves asking victims to perform a task that is diﬃcult to au-
tomate. Therefore, these techniques necessarily create signiﬁcant inconvenience
for the intended targets, who may not have a particularly strong motivation to
interact with an almost-empty page (content shown before the veriﬁcation is also
available to automated analyzers) if it requires eﬀort on their part. These kinds
of expedients would also strongly diﬀerentiate the page from regular benign sites,
even in the eye of an untrained user, so they are unlikely to be used in fraudulent
pages and were not observed in our dataset.
4.2 Implementation
Based on the discussion above, we detect content obfuscation by ﬁrst building
an extractor that page authors expect to face (e.g., a static text parser) and a
more powerful one (e.g., a full browser), and then observing the diﬀerences in
the extracted contents.
Our detector is based on the popular Firefox web browser, modiﬁed in order
to observe and record all network requests and the context in which they were
made. We also store the DOM tree of the page (including frames) and take a
screenshot of the website as it would be seen by a human user. Finally, the
browser has been modiﬁed to automatically conﬁrm all ﬁle save request and
dismiss all JavaScript popups. While using a real web browser may be slower
and less safe than using an ad-hoc solution, it also makes the simulation much
more realistic and helps us avoid being ﬁngerprinted by an attacker. The browser
visits the page in a temporary VM, and is fully automated.
The system uses two viewpoints to check for text on the web page. First, the
text present in the DOM tree is normalized by replacing HTML entities and URL-
encoded characters, removing non-alphabetic characters, and transforming all
text to lowercase. Then, the text that is present in network payloads is parsed and
decoded using information recorded from the browser (for example, unzipped),
and then normalized in the same way.
For every word in the body of the page (text of the DOM tree), an origin is
sought in the network payloads. In particular, the presence of a word is consid-
ered “justiﬁed” if it satisﬁes one of the following conditions:
Eyes of a Human, Eyes of a Program
137
1. It appears as-is in the body of one of the responses from the server, including
AJAX requests, requests made from iframes, etc. This rule matches most
regular text.
2. It appears in one of the URLs (e.g., as part of the domain name, in the query
string, etc). This rule takes care of pages that display information that is
passed to them via the URL and access it via the location object.
3. It appears in one of the HTTP headers, which are readable by JavaScript
for AJAX requests.
4. It can be obtained from the previously-mentioned sources:
(a) as the concatenation of two words,
(b) as the truncation of another word.
5. It is found in a whitelist of words that can be obtained directly from the
JavaScript language interpreter, including type names like none or HTML-
ParagraphElement, date components (e.g., month names), strings from the
navigator object, etc.
These rules attempt to construct a set of benign clear-text sources that would
be easily exposed to a static signature matcher, anticipate most real-world string
operations (that any signature matching algorithm can and probably should take
into account), and consider all page components that would possibly be exposed.
Words for which an origin could not be pinpointed are considered obfuscated.
For simplicity, our heuristic operates on single words only, and leaves the exten-
sion to sequences to the signature generator (Section 6.1). Purely image-based
obfuscation approaches would also escape our textual detector and would require
image-processing techniques for detection: similarly, we left this extension to our
proof-of-concept signature matcher (Section 6.2).
The previously-described extraction rules are also applied to the domain
names of URLs present in HTML attributes. This allows us to catch cases of
pages that try to hide from programs the URL to which they will redirect a
human viewer. Notice that text from a DOM tree is analyzed considering only
network payloads that have been seen before it was retrieved, so the presence of
links in a page cannot be justiﬁed with future HTTP headers.
In principle, our algorithm would also work for scripts and style sheets, but
such analysis is out of scope for this paper: ordinary human users do not “parse”
them, nor are they aware of their existence.1
4.3 Evaluation of the Detection of Obfuscated Content
Table 2 presents the samples for which we found obfuscated content (the benign,
malicious, or questionable nature was established by manual review).
While obviously not perfect, our heuristic presented very few false positives
in the detection of obfuscated content (that is, content incorrectly marked as
1 Of course, a possible extension of our work would be to consider the two “views” of a
malware analyst and of a web browser. As an example, in this model JavaScript ob-
fuscation would be a case of content easily interpreted by a browser but cumbersome
for a human to understand.
138
J. Corbetta et al.
obfuscated, regardless of the benign or malicious nature of the page) in our
dataset. These were often caused by incorrect parsing of the network payload,
as in some cases it is diﬃcult to replicate the exact parsing the browser will
perform: unclear speciﬁcations, buggy servers, and sloppy page coding practices
require browsers to rely on several heuristics, and previous research has shown
that diﬀerent clients can even give diﬀerent interpretations to the same data [2];
it should be noted, however, that the desire to increase the number of victims
can be a mitigation factor for this issue, especially for frauds: their authors have
an interest in having them functional on all major browsers.
Table 2. Samples found by the content obfuscation heuristic, grouped by source
Source
Page type Samples In-Feed Pct. Global Pct.
Alexa ranking (81,000 samples)
Fake AV feed (18,700 samples)
Benign
Questionable
Malicious
total
Benign
Questionable
Malicious
total
Received submissions (50,000 samples) Benign
All feeds (149,700 samples)
Questionable
Malicious
total
Benign
Questionable
Malicious
total
52
3
3
58
1
4
102
107
3
0
94
97
56
7
199
262
90%
5.2%
5.2%
100%
0.93%
3.7%
95%
100%
3.1%
0%
97%
100%
21%
2.7%
76%
100%
0.06%
0.004%
0.004%
0.07%
0.005%
0.02%
0.54%
0.57%
0.006%
0%
0.19%
0.2%
0.037%
0.005%
0.13%
0.18%
Manual review of the 3,000 randomly selected samples from the 50,000 sub-
missions received in real-time (Section 3), utilizing the screenshots and assisted
by Optical Character Recognition software, did not uncover any false negative
(obfuscated content not marked as such).
4.4 Observed Uses of Obfuscation
Even a simple unescape is enough to hide content from a straightforward HTML
parser, and many examples in our dataset did not go much further than that.
Code from exploit kits and fake antivirus scams, on the other hand, went to
great lengths to obfuscate both the content and the generating script.
Beside fraudulent content, the following categories of text were commonly
observed in obfuscated form:
– E-mail addresses: A precaution against address-harvesting spam bots. To
avoid these false positives, our heuristic ignores all mailto: links and strings
that look like e-mail addresses.
Eyes of a Human, Eyes of a Program
139
– Domain names: A pharmacy scam campaign and several exploit kits pre-
sented landing pages with redirection code. The target URL was obfuscated,
presumably to slow down blacklist-building crawlers and human analysts.
– Links: Some benign websites obfuscated hyperlinks to other pages or web-
sites, including seemingly innocuous links such as those to contact infor-
mation and the terms of service. This is probably done to make sure that
search engines do not focus on pages that are perceived as not signiﬁcant
by the webmaster; this particular technique may be an answer to Google’s
de-emphasizing of the nofollow attribute [9].
Our detector does not mark pages as questionably obfuscated if e-mail and
links are the sole hidden content types, as these kinds of obfuscation are also
used in benign sites.
Obfuscated target URLs, on the other hand, are deﬁnitely a strong signal of
malicious content. However, the speciﬁc URLs are highly variable, easily changed,
and not necessarily exposed to the user (who will likely only view and act on the
ﬁrst URL in the redirect chain), so they have also been ignored for the purposes
of our proof-of-concept detector.
4.5 From Obfuscation Detection to Maliciousness Detection
As mentioned, our simple heuristic is, in itself, an indication that a page may
contain suspicious content, but is not entirely reliable as a maliciousness detector
in itself.
It does, however, ﬁnd content that the page author wanted to hide: a good
starting point for a more punctual detection of maliciousness. In our study, we
chose to exploit the fact that cybercriminals typically run campaigns (they typ-
ically prepare many variations that implement a certain scheme) or implement