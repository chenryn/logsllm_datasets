(1 row)
postgres=# select pg_terminate_backend(43467);
 pg_terminate_backend 
----------------------
 t
(1 row)
postgres=# select * from tt;
 id  
-----
   1
   2
   3
   3
   4
 100
(6 rows)
postgres=# select pg_cancel_backend(43781);
 pg_cancel_backend 
-------------------
 t
(1 row)
postgres=# select * from tt;
 id  
-----
   1
   2
   3
   3
   4
 100
 101
(7 rows)
```  
## 17 同步模式 VS 异步模式 性能对比  
1、生成1亿TPC-B测试数据  
```  
pgbench -i -s 1000  
```  
2、多副本同步模式  
```  
postgres=# show synchronous_commit ;  
 synchronous_commit   
--------------------  
 remote_write  
(1 row)  
postgres=# show synchronous_standby_names ;  
 synchronous_standby_names   
---------------------------  
 ANY 1 (*)  
(1 row)  
```  
3、压测  
```  
pgbench -M prepared -n -r -P 1 -c 56 -j 56 -T 120  
transaction type:   
scaling factor: 1000  
query mode: prepared  
number of clients: 56  
number of threads: 56  
duration: 120 s  
number of transactions actually processed: 5381146  
latency average = 1.248 ms  
latency stddev = 4.118 ms  
tps = 44840.272218 (including connections establishing)  
tps = 44853.145859 (excluding connections establishing)  
script statistics:  
 - statement latencies in milliseconds:  
         0.002  \set aid random(1, 100000 * :scale)  
         0.001  \set bid random(1, 1 * :scale)  
         0.001  \set tid random(1, 10 * :scale)  
         0.001  \set delta random(-5000, 5000)  
         0.063  BEGIN;  
         0.171  UPDATE pgbench_accounts SET abalance = abalance + :delta WHERE aid = :aid;  
         0.096  SELECT abalance FROM pgbench_accounts WHERE aid = :aid;  
         0.109  UPDATE pgbench_tellers SET tbalance = tbalance + :delta WHERE tid = :tid;  
         0.118  UPDATE pgbench_branches SET bbalance = bbalance + :delta WHERE bid = :bid;  
         0.090  INSERT INTO pgbench_history (tid, bid, aid, delta, mtime) VALUES (:tid, :bid, :aid, :delta, CURRENT_TIMESTAMP);  
         0.597  END;  
```  
4、本地持久化，单副本模式  
```  
postgres@-> psql  
psql (10.3)  
Type "help" for help.  
postgres=# alter role postgres set synchronous_commit = local;  
ALTER ROLE  
postgres=# \q  
postgres@-> psql  
psql (10.3)  
Type "help" for help.  
postgres=# show synchronous_commit ;  
 synchronous_commit   
--------------------  
 local  
(1 row)  
```  
5、压测  
```  
pgbench -M prepared -n -r -P 1 -c 56 -j 56 -T 120  
transaction type:   
scaling factor: 1000  
query mode: prepared  
number of clients: 56  
number of threads: 56  
duration: 120 s  
number of transactions actually processed: 6684833  
latency average = 1.005 ms  
latency stddev = 1.494 ms  
tps = 55695.800213 (including connections establishing)  
tps = 55700.524316 (excluding connections establishing)  
script statistics:  
 - statement latencies in milliseconds:  
         0.002  \set aid random(1, 100000 * :scale)  
         0.001  \set bid random(1, 1 * :scale)  
         0.001  \set tid random(1, 10 * :scale)  
         0.001  \set delta random(-5000, 5000)  
         0.061  BEGIN;  
         0.133  UPDATE pgbench_accounts SET abalance = abalance + :delta WHERE aid = :aid;  
         0.096  SELECT abalance FROM pgbench_accounts WHERE aid = :aid;  
         0.108  UPDATE pgbench_tellers SET tbalance = tbalance + :delta WHERE tid = :tid;  
         0.114  UPDATE pgbench_branches SET bbalance = bbalance + :delta WHERE bid = :bid;  
         0.091  INSERT INTO pgbench_history (tid, bid, aid, delta, mtime) VALUES (:tid, :bid, :aid, :delta, CURRENT_TIMESTAMP);  
         0.400  END;  
```  
OLTP写场景本地持久化 VS 多副本性能对比：  
1、多副本模式，RT 提高了0.24毫秒，约20%     
2、多副本模式，TPS 下降了10855，约20%     
## 小结  
PostgreSQL的多副本复制非常的简单并且健壮。  
流复制有几个特点  
1、延迟及低，毫不畏惧大事务  
2、支持断点续传  
3、支持多副本  
4、配置简单，看本文  
5、备库与主库物理完全一致，并支持只读  
6、支持多级级联从库  
许多用户会使用流复制来搭建只读备库，容灾，备份节点，HA等。  
本文主要介绍了PostgreSQL一主多从的配置，以及多副本强同步的配置。  
如果想使用多副本实现“0数据丢失、高可用”方案，可以先实现内核层冻结receiver进程，这样可以更加容易的实现新主的选举。（否则需要使用pg_waldump来观察位点是谁的最新）。然后就可以愉快的切换到最新位点的从库，确保切换的0丢失。  
同时为了保证不出现脑裂，需要控制住了大于或等于（一会PG中参数指定“同步备库数 - 同步副本数 + 1”）个节点，再选择新的主节点(选出它们中WAL位点最新的作为新主节点)，则绝对不可能出现脑裂的问题，也不会丢失数据。  
至于使用智能DNS还是PROXY，又或者是VIP来实现业务端透明，根据你的数据库所在的环境来决定，哪个方便用哪个。VIP或者DNS的话性能应该是最好的，因为应用程序到达数据库的跳数最少。  
## 参考  
你可能还对如下文档感兴趣  
[《PostgreSQL 10 on ECS 实施 流复制备库镜像+自动快照备份+自动备份验证+自动清理备份与归档》](../201711/20171129_02.md)    
(它也可以代替pg_rewind来修复时间线问题，对于特别庞大的数据库非常有效。)    
[《PostgreSQL 10 + PostGIS + Sharding(pg_pathman) + MySQL(fdw外部表) on ECS 部署指南(适合新用户)》](../201710/20171018_01.md)    
[《PostgreSQL on Linux 最佳部署手册》](../201611/20161121_01.md)    
[《PostgreSQL - 鱼与熊掌可兼得 - 多副本0丢失与高性能兼得 - 事务级异步、同步开关》](../201712/20171207_01.md)    
 [《PG多节点(quorum based), 0丢失 HA(failover,switchover)方案》](../201706/20170612_02.md)    
[《PostgreSQL 同步流复制(高并发写入)锁瓶颈分析》](../201611/20161107_02.md)    
[《PostgreSQL 9.6 同步多副本 与 remote_apply事务同步级别》](../201610/20161006_02.md)    
[《PostgreSQL 同步流复制原理和代码浅析》](../201606/20160616_01.md)    
[《异步流复制模式如何保证不丢数据?》](../201705/20170504_03.md)    
[《PostgreSQL 流复制延迟的测试方法》](../201604/20160407_03.md)    
[《PostgreSQL 小改动，解决流复制遇到的pg_xlog已删除的问题(主库wal sender读归档目录文件发送给wal sender)》](../201603/20160310_02.md)    
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")