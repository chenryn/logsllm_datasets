hu.tagsoft.ttorrent.lite-15
jp.hotpepper.android.beauty.hair-12
Exposed Interface
Leaked Capability
Threat Description
Activity
Activity
Activity
Activity
Activity
Activity
Activity
Activity
Service
Activity
Service
Activity
Activity
Activity
Service
Activity
Raw Query
Internet
Selection Query
Internet
Selection Query
Selection Query
Internet
Internet
Internet
Raw Query
Raw Query
Raw Query
Selection Query
Selection Query
Internet
Raw Query
SQL Injection
Delegation Attack
SQL Injection
Delegation Attack
SQL Injection.
SQL Injection.
Delegation Attack
Delegation Attack
Delegation Attack
SQL Injection
SQL Injection
SQL Injection
SQL Injection
SQL Injection
Delegation Attack
SQL Injection
Fig. 7. Relative App Size in Percentage. Five curves quantify app sizes at
different stages.
Fig. 8.
statement placement and four phases of patch optimizations.
Cumulative Runtime. Runtime for slices computation, patch
increase of the program size is roughly proportional to the slice
size, which is expected. After patch statement placement, the
increased size is, on average, 41.6% compared to the original
program.
Consequently, the exploitation path is guaranteed to happen
every time a malicious Intent reaches the vulnerable interfaces.
In this case, simply blocking the exposed interface might be
as good as our patching approach.
Figure 7 further visualizes the impact of the four optimiza-
tions to demonstrate their performance. The ﬁve curves on the
ﬁgure represent the relative sizes of the program, compared
to the original app size, on different processing stages, respec-
tively. The top curve is the program size when patch statement
placement has been conducted, while the bottom one stands
for the app size after all four patch optimizations. We can see
that 1) for some of these apps, the increase of program size due
to patch statement placement can be big, and up to 130%; and
2) these optimizations are effective, because they signiﬁcantly
reduce the program sizes. In the end, the average size of patch
code drops to 15.9%.
C. Detailed Analysis
Here we present detail analysis for these vulnerable apps
to discuss the effectiveness and accuracy of our generated
patches.
Apps with Simple Exploiting Paths. Some of the apps are
vulnerable but exploitation paths are fairly simple. App 4, 7,
8, 9, 11, 12 fall into this category. Upon obtaining Intent data
from an open Activity or Service, these apps directly use it
either as URL to load a webpage in WebView, conduct a
HTTP GET, or as a SQL string to query an internal database.
However, for other apps, a manipulated input may not
always cause an actual exploitation.
Apps with Pop-up Dialogs. Some apps ask user for consent
before the capable sink API is called. App 2, 3, 5, 6, 10, 13
share this same feature. If the user does not approve further
operations, the exploitation will not occur. In this case, block-
ing at the open interface causes unnecessary interventions. Our
approach, on the other hand, disables the vulnerability and
requires only necessary mediations.
com.akbur.mathsworkout (version code 92) is one
of these examples. This app is a puzzle game, which is subject
to data pollution and leaks Internet capability. Granted with
Internet permission, the app is supposed to send user’s “High
Score” to a speciﬁc URL. However, the Activity to receive
“High Score” data is left unguarded. Thus, an malicious app
can send a manipulated Intent with a forged “score” to this
vulnerable Activity, polluting the latter’s instance ﬁeld. This
ﬁeld is accessed in another thread and the resulting data is sent
to Internet, once the thread is started. However, starting this
background thread involves human interactions. Unless a “OK”
button is clicked in GUI dialog, no exploitation will happen.
Our patch correctly addresses this case and only displays the
warning when sending thread is about to call the sink API (i.e.
HttpClient.execute()).
11
100%120%140%160%180%200%220%240%12345678910111213141516Propotional App SizeApp IDInstruO1O2O3O402040608010012014016018012345678910111213141516Runtime (in sec)App IDO4O3O2O1InstruAnalysiscom.cnbc.client (version code 1208 and 1209) asks
for user’s consent in a more straight-forward way. This ﬁnance
app exposes an Activity interface that can access internal
database, and thus is vulnerable to SQL injection attack. The
exposed Activity is intended to receive the “name” of a stock,
and further save it
to or delete it from the “watch list”.
Malicious Intent can manipulate this “name” and trick the
victim app to delete an important one or add an unwanted
one. Nevertheless, the deletion requires user’s approval. Before
deletion,
the app explicitly informs the user and asks for
decision. Similarly, if the user chooses “Cancel”, no harm
will be done. Our patch automatically enforces necessary
checks but avoids intervention in this scenario. Notice that
taint slices of this app take a great portion (27%) of the
program, and therefore it is extremely hard to conﬁrm and
ﬁx the vulnerability, or further discover aforementioned secure
path with pure human effort. In contrast, AppSealer automat-
ically differentiates secure and dangerous paths, and in the
meantime manages to signiﬁcantly reduce the amount of patch
statements.
Apps with Selection Views. A similar but more generic case is
that apps provide views such as AdapterView for selection.
The actual exploit only occurs if an item is selected. Apps 1,
14, 16 are of this kind.
CN.MyPrivateMessages (version code 52) is a com-
munication app which suffers the SQL injection attack. An
vulnerable Activity may save a manipulated Intent data to
its instance ﬁeld during creation. The app then displays an
AdapterView for user to select call logs. Only upon selection
does the event handler obtain data from the polluted ﬁeld and
use it to perform a “delete” operation in database.
Apps with Multiple Threads. Some samples extensively
create new threads during runtime and pass the manipulated
input across threads (e.g., app 2, 10, 15). Asynchronous
program execution makes it hard for developers or security
analysts to reproduce the exploitation and thus to conﬁrm the
vulnerability.
D. Effectiveness Evaluation
We run our generated patches on a physical device to verify
the effectiveness of our generated patches.
Patch Behavior in Benign Context. Firstly, we test the pro-
gram execution under normal circumstances. In other words,
only internal Intents are delivered to vulnerable public inter-
faces, and thus they should not cause patch code to raise
warnings. Our test combines automatic testing mechanism
with interactive manual examination. While automatic testing
helps to improve code coverage, manual efforts are made
to trigger speciﬁc execution paths which lead to component
hijacking vulnerability. Our automated testing is conducted
with monkey [20], which produces random GUI events to
feed an Android app. We did not observe any crashes in this
test. This demonstrates the feasibility of our approach. Next,
we manually explore different parts of the program. In our
observation, patched apps act the same as corresponding vul-
nerable ones, and the original program execution is preserved
with no interruption. This shows that our patch does not affect
normal usability.
Fig. 9. Hijacking information ﬂow detected during runtime.
Patch Behavior under Attacks. Then, we attempt to launch
component hijacking exploits on patched apps to ﬁnd out
whether patch code correctly mitigates the attack by informing
user of the risk. To launch the attack, we send custom
Intents from a testing app. In this custom Intent, a speciﬁc
vulnerable component is conﬁgured to be the receiver and
the payload is delicately organized to carry the manipulated
inputs. We manage to launch component hijacking attack on
6 vulnerable apps (app 1,2,4,5,6,10). On the vulnerable ones,
exploitations succeed; on the patched ones, a warning dialog
pops up when an attack is about to happen. Figure 9 illustrates
the case when the attack is detected and a warning is raised.
It is worth mentioning that launching a successful exploit is
nontrivial and time consuming. Thus, it is also hard, if not
possible, for inexperienced developers to reproduce the attack.
This might explain why many vulnerable apps had not been
ﬁxed since they were discovered.
E. Performance Evaluation
We evaluate both ofﬂine patching time cost and runtime
performance of the patched apps.
Performance of Patch Generation. Figure 8 illustrates the
time consumption of patch generation for 16 vulnerable An-
droid apps in our experiment. To be speciﬁc, it depicts the
execution time of slices computation, patch statement place-
ment, and four phases of patch optimization. We do not show
the bytecode conversion times here, because code conversion
by dex2jar is usually within several seconds and thus not
signiﬁcant as compared to the other steps. We ﬁnd that more
than 81.3% of the apps (13 out of 16) are processed within 60
seconds and the majority (15 out of 16) can be patched within
3 minute. However, still one app costs excessive time to ﬁnish.
Slice computation with global dataﬂow analysis dominates the
overall processing time. In comparison, the runtime of patch
statement placement and optimization is fairly short.
Runtime Performance. To estimate the runtime overhead
of the patched programs, we conduct experiment on Google
Nexus S, with Android OS version 4.0.4. We patch the 16
vulnerable apps, run both the original apps and patched ones
on the physical device, and compare the runtime performance
before and after patching.
We rely on the timestamps of
work debugging information (logcat
the Android frame-
logs) to compute the
12
Activity load time as benchmark. The Activity load
time is measured from when Android ActivityManager
starts an Activity component to the time the Activity
thread is displayed. This includes application resolution by
ActivityManager, IPC and graphical display. The runtime
is thus measured by adding up load time of all Activites that
appear in one execution trace. Activity startup is usually fairly
fast, and thus this measurement is susceptible to system noise.
Noise may even cause negative slowdown. To limit the side-
effect of noise, we measure the runtime 10 times and use the
average value to calculate runtime overhead for every case.
We ﬁrst test the runtime performance of all 16 apps under
normal circumstances. In other words, no attack is conducted.
We start the apps, navigate through several Views, reach the
vulnerable interfaces, walk through a series of Views again,
and eventually get to the capable components. The program
execution thus involves both intensively patched components
and other code which is not relevant to component hijack-
ing dataﬂow. Results show that patched apps usually incur
insigniﬁcant overhead. The average slowdown of 16 apps is
approximately 2%.
Further, we attempt to investigate the worst case. That is,
the execution trace involves largely, if not solely, those app
components that are heavily patched. To this end, we launch
component hijacking attack on the 6 apps (app 1,2,4,5,6,10)
to trigger the vulnerable interfaces directly and wait until
exploited components start. the overall overhead is still small,
with an average of 5% and a standard deviation of 2.8%.
The maxmum overhead is relatively higher (9.6%), due to
the heavy patching in the onCreate() method of the app
(com.kmshack.BusanBus).
VII. DISCUSSION
In this section, we discuss the limitations of our system and
possible solutions. We also shed light on future directions.
Soundness of Patch Generation. The soundness of our ap-
proach results from that of slice computation, patch statement
placement and patch optimizations.
We perform standard static dataﬂow analysis to compute
taint slices. Static analysis, especially on event-driven, object-
oriented and asynchronous programs, is known to introduce
false positives. However, such false positives can be veriﬁed
and mitigated during runtime, with our devised shadowing
mechanism and inserted patch code.
Our patch statement placement follows the standard taint
tracking techniques, which may introduce imprecision. Specif-
ically, our taint policy follows that of TaintDroid. While
effective and efﬁcient in a sense, this multi-level tainting is
not perfectly accurate in some cases. For instance, one entire
ﬁle is associated with a single taint. Thus, once a tainted object
is saved to a ﬁle, the whole ﬁle becomes tainted causing over-
tainting. Other aggregate structures, such as array, share the
same limitation. It is worth noting that improvement of tainting
precision is possible. More complex shadowing mechanism
(e.g., shadow ﬁle, shadow array, etc.) can be devised to
precisely track taint propagation in aggregations. However,
these mechanisms are more expensive considering runtime cost
and memory consumption.
Our optimizations take the same algorithms used in com-
pilers, such as constant propagation, dead code elimination.
Thus, by design, original program semantics is still preserved
when patch optimization is applied.
In spite of the fact that our approach may cause false posi-
tives in theory, we did not observe such cases in practice. Most
vulnerable apps do not exercise sophisticated data transfer for
Intent propagation, and thus it is safe to patch them with our
technique.
Conversion between Dalvik bytecode and Jimple IR. Our
patch statement placement and optimizations are performed
at Jimple IR level. So we need to convert Dalvik bytecode
program into Jimple IR, and after patching, back to Dalvik
bytecode. We use dex2jar [16] to translate Dalvik bytecode
into Java bytecode and then use Soot [15] to lift Java bytecode
to Jimple IR. This translation process is not always successful.
Occasionally we encountered that some applications could not
be converted. Enck et al. [21] pointed out several challenges
in converting Dalvik bytecode into Java source code, includ-
ing ambiguous cases for type inference, different layouts of
constant pool, sophisticated conversion from register-based to
stack-based virtual machine and handling unique structures
(e.g., try/ﬁnally block) in Java.
In comparison, our conversion faces the same, if not less,
challenges, because we do not need to lift all the way up to
Java source code. We consider these problems to be mainly
implementation errors. Indeed, we have identiﬁed a few cases