=== esma自动预测
movingavg的滑动窗口思路虽然不错，但是只能用于异常发现。在IT运维工作职责中，有一项和设备采购、流量调度等相关的任务，叫容量规划。这需要在历史数据的基础上，前瞻性的预估到未来一段时间的数据走势。日志易提供esma指令满足这一需求。
esma是exponentially smoothed moving average的首字母缩写。esma指令有其使用场景限制，但大多数IT运维相关KPI指标的时序数据，都能符合。为了能够更好更合理的使用esma指令，本节我们先简要介绍一下esma的简单原理。
时序数据的形式大致可以分为如下四类：
1.  平稳线性
2.  有固定趋势
3.  有周期性反复
4.  随机无规律
当然，实际场景中的数据肯定会有很多的噪音加入。如下图所示，就是一个线性趋势是如何一步步叠加上周期性、季节性和随机性，最后变成一个复杂的时序数据的。
image::images/timeseries-example.png[]
对于随机性占主要成分的时序数据，很难有比较好的办法进行未来预测。不过好在IT环境中，大多数时序数据是具有趋势性、周期性乃至季节性的。
对于这类数据，使用指数平滑算法通常可以有一定的效果。指数平滑算法兼容了全期平均法和移动平均法所长，即以更大权重考虑近期影响，又不完全舍弃远期数据，只是逐步收敛远期数据的权重为零。
针对含有不同成分的时序数据，也需要细分指数平滑算法的类型：
1.  一阶指数平滑：只需要一个α参数，适用于无明显趋势变化的时序数据；
2.  二阶指数平滑：需要α和β两个参数，适用于具有线性趋势的时序数据，又叫holt-linear算法；
3.  三阶指数平滑：需要α、β、γ三个参数，适用于具有周期性季节性的时序数据，还有加法和乘法模型两个选择，又叫holt-winters算法。
对于指数平滑算法的参数，合理的取值对最终效果影响很大。通常只能有些简单的经验范围，想要达到好的效果，需要反复尝试调整。
日志易采用机器学习方法，能够自动确定输入的时序数据是否具有趋势性、周期性、季节性，选择适当的阶次算法；在有周期性的时候，自动计算周期数值；并利用AIC选取最佳的模型；最后，通过Nelder-Mead simplex算法获取最小MSE下的优选参数取值。
简单的说，就是日志易提供的esma指令，无需您反复尝试和指定参数值，可以自动调整到最优状态，进行时序预测。
当然，在明确知道周期的情况，手动指定 period 参数更有利于结果计算。在 IT 数据中，最常见的周期就是一天，假设数据采样间隔为10分钟，则 period 可设置为 144。
比如，我们可以将访问日志的平均响应时间走势作为时序数据，以过去7天的历史数据，预测未来1天的情况。
image::images/search-example-esma-predict.png[]
为了对比查看，还可以结合同环比的形式，将预测曲线和实际曲线叠加在一起展示。最终的SPL语句如下：
[source,bash]
starttime="now-7d/d" endtime="now/d" *
  | bucket timestamp span=15m as ts
  | stats avg(apache.request_time) as avg_ by ts
  | esma avg_ timefield=ts futurecount=24
  | where empty(avg_)
  | eval time = formatdate(ts, "HH:mm")
  | table time, _predict_avg_
  | join type=left time [[
starttime="now/d" *
       | bucket timestamp span=15m as ts
       | stats avg(apache.request_time) as avg_ by ts
       | eval time = formatdate(ts, "HH:mm")
       | table time, avg_
]]
当然，既然可以把预测值和实际值叠加展示了，也就同样可以基于预测值进行异常检测告警。
同样的响应时间场景，改做告警时，一般会将时间间隔缩短。比如以最近两天的情况预测每分钟的取值。注意下面SPL指令中主查询的endtime设置：
[source,bash]
starttime=now-1d endtime=now-1m *
   | bucket timestamp span=1m as ts
   | stats avg(apache. request_time) as latency by ts
   | esma latency timefield=ts period=1440 futurecount=1
   | where empty(latency)
   | join ts [[
       starttime=now-1m endtime=now *
     | bucket timestamp span=1m as ts
     | stats avg(apache. request_time) as latency by ts
  ]]
   | eval predict_err_pct = abs(latency - _predict_latency)*100/latency
=== ARIMA时序预测
如果esma指令的自动调优效果不佳，而您对自身数据的了解又比较深，愿意进行手动调参，日志易还提供了一种适用范围更广的时序数据预测方法——ARIMA算法。
ARIMA是autoregressive integrated moving average的首字母缩写。事实上，上一节提到的Holt-winters算法可以认为是ARIMA在特殊场景下的实现。
ARIMA算法中，包括自回归项、差分项、移动平均项。自回归项代表当前值与过去多少个数据的相关性，差分项代表用几次差分来去除不平稳性，移动平均项代表过去多少个的预测偏差对当前值的影响。
日志易的ARIMA指令，使用order参数来依次指定这三项，三项值之间，用短横线-连接。
依然是上节的场景，如果改用ARIMA算法，假设我们确定采用自回归项为7、差分项为2、移动平均项为1，则最终SPL语句写作：
[source,bash]
starttime="now-7d/d" endtime="now/d" *
  | bucket timestamp span=15m as _time
  | stats avg(apache.requst_time) as avg_ by _time
  | fit ARIMA order="7-2-1", steps=24, conf_interval=95 from _time, avg_
日志易将在未来版本中，提供ACF和PACF函数，辅助您更好的设置order参数里的三个项。
=== Kmeans异常时序聚类
前面几节，我们通过不同的算法，来针对单条时间序列数据做预测和动态基线告警。但对于大规模IT环境来说，我们依然很难对海量的监控指标数据，逐一设置告警。过去的麻烦在于人力无法覆盖这么多指标的场景分析，现在的麻烦在于计算资源无法支撑这么多指标的动态基线计算。
针对这类问题，日志易提供了另一个思路。同一批应用的同类监控指标，比如挂在一台负载均衡器下的多台Web服务器的请求量、负载、IO等，在相同时间段内，应该是基本一致的。那么，如果有哪个指标的时序和其他时序相比比较另类的话，我们可以判定它出现了异常。这样，对同一类数据，我们只需要设置一个SPL告警即可。
发现异常时序数据的SPL语句如下：
[source,bash]
starttime="now-1d/d" endtime="now/d" appname:metric metric.node:BL685-* metric.table_name:KLZ_CPU
  | bucket timestamp span=1h as _time
  | stats avg(metric.busy_cpu) as avg_ by _time, metric.node
  | eval _time = formatdate(_time, "'hour'HH")
  | transpose row=metric.node column=_time valuefield=avg_
  | fit KMeans n_clusters=2 from hour00, hour01, hour02, hour03, hour04, hour05, hour06, hour07, hour08, hour09, hour10, hour11, hour12, hour13, hour14, hour15, hour16, hour17, hour18, hour19, hour20, hour21, hour22, hour23
  | where cluster==1
  | table metric.node
我们使用transpose指令，对时序数据做了一次行列置换，将每个小时的数值，作为一个特征值，传递给KMeans聚类算法。
为了更明确的看到异常时序的情况，可以把上面的SPL作为子查询条件，过滤异常时序的趋势图。效果如下：
image::images/search-example-kmeans.png[]
我们对比一下全体时序的趋势图情况，如下图所示，是同一批服务器的CPU负载的单日趋势图：
image::images/search-example-kmeans-before.png[]
我们通过肉眼观察，可以很明显看到，最上面两条很突出的曲线，正是我们通过Kmeans聚类过滤出来的那两条。
[IMPORTANT]
====
如果您的负载均衡器使用的不是RR轮询算法，而是WRR加权轮询或者WLC加权最近连接等其他算法，则不能简单的直接使用时序的原值作为特征值进行聚类，而需要预先做归一化处理，还可以计算一些时序数据的最大值、最小值、平均值、标注差作为特征值。
====
== 关联分析
针对跨多模块的业务请求，进行关联追踪，分析其业务状态及执行性能，是日志易的一个重要特色功能。应对不同的场景，SPL可以以多种不同形式实现最终的关联分析效果。本章将分别举例说明。
=== join
当不同环节或不同状态的日志及日志统计结果，可以通过左右键关联的方式串联在一起时，您可以使用join指令进行数据关联操作。多个join可以嵌套或串联在一起，最终生成一个宽表结果集。
比如，我们想分析网站不同域名的请求数、响应状态比例和响应时间分布。这三者分别需要不同的统计方式，同时计算比例时有需要合并计算。最终SPL写作：
[source,bash]
logtype:apache | stats count() as count_t by apache.domain
  | eval avg_=count_t/2/3600
  | join apache.domain [[logtype:apache
    | bucket apache.status ranges=((400,500),(500,MAX)) as rs
    | stats count() as count_ by apache.domain, rs
    | autoregress count_ p=1
    | where match(rs,"^500")]]
  | join apache.domain [[logtype:apache
    | bucket apache.resp_time ranges=((0,100),(100,500),(500,MAX)) as rs2
    | stats count() as count_r by apache.domain, rs2
    | autoregress count_r p=1-2
    | where match(rs2,"^500")]]
  | eval p4xx=format("%.3f %%",100*count__p1/count_t)
  | eval p5xx=format("%.3f %%",100*count_/count_t)
  | eval rt100=format("%.3f %%",100*count_r_p2/count_t)
  | eval rt500=format("%.3f %%",100*count_r_p1/count_t)
  | eval rtmax=format("%.3f %%",100*count_r/count_t)
  | fields apache.domain, count_t, avg_, p4xx, p5xx, rt100, rt500, rtmax
  | rename apache.domain as "域名"
  | rename count_t as "总数"
  | rename avg_ as "QPS均值"
  | rename p4xx as "4xx比例"
  | rename p5xx as "5xx比例"
  | rename rt100 as "100ms内响应比例"
  | rename rt500 as "500ms内响应比例"
  | rename rtmax as "500ms以上响应比例"
您可以看到，这段语句中，巧妙的利用了autoregress指令和match函数，做到了一行里包含有域名对应的不同区间的统计值。然后将三段统计结果join关联后，就可以计算得到百分比并统一展示了。
image::images/search-example-join.png[]