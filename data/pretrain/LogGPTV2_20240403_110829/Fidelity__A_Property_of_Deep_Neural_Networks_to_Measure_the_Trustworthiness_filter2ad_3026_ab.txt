ability of the jury to detect adversarial examples crafted for the
DNN model. If a jury performs well in detecting adversarial attacks,
we believe that such jury estimates the population distribution well,
and thus estimates the fidelity well.
The model pool consists of 9 models, so there are totally(cid:0)9
(cid:1) +
(cid:1) = 511 distinct combinations of jury. We enumerate the
(cid:1) + ... +(cid:0)9
2
511 candidate juries to evaluate their performance. The probability
density function of false positive rate (FPR) and true positive rate
(TPR) for the MNIST (CIFAR10) dataset are plotted in Figure 3. On
the MNIST (CIFAR10) original test set, the mean FPR of adversarial
attack detection is 9.20% (48.2%), the minimum FPR is 1.28% (25.7%),
and the maximum FPRs are both 100% (with extremely few juries).
On the MNIST (CIFAR10) JSMA set, the mean TPR is 97.26% (84.23%),
the minimum TPR is 82.0% (74.10%), and the maximum TPRs are
both 100%. On the MNIST (CIFAR10) FGSM set, the mean TPR
1
(cid:0)9
9
Figure 2: Illustration of the adversarial space.
3 FIDELITY MEASUREMENT
The goal of this work is not to increase the accuracy or robustness of
DNNs to adversarial examples, but rather to provide an additional
value to reflect the fidelity. Figure 1 shows an overview of our
work. For an input sample, the original DNN model still outputs its
predictions on it. We in parallel measure the fidelity of this result.
To quantitatively estimate fidelity, we propose a method that
uses a set of traditional ML models, namely jury, to estimate the
population distribution, and then compute the fidelity based on it.
The intuition is that the combined action of a set of diverse and
accurate models can help retain the local constancy/smoothness of
the local region around an legitimate input sample, such that the
adversarial example which is in such local region can be detected.
Selecting the optimal jury from universal models is expensive
and usually intractable. Therefore, we constrain the selection in a
predefined model pool. That is, we randomly train a set of tradi-
tional ML models on the same training set, so as to select diverse
and qualified models (jury members). We propose a method of bal-
ancing the diversity and qualification of jury members to select the
optimal jury. Specifically, we measure the diversity between mod-
els in adversarial settings because adversarial examples are typical
instances breaking the fidelity of DNN models. We theoretically
compute the dimensionality of the adversarial space (as shown in
JuryDeep Neural networkPopulation DistributionModel DistributionClass: 4Fidelity: 0.19Input SampleGround Truth: 1Adversarial AttackCompareUser……432Model 1N…6Model 5!"#$!"%&!'Adversarial	SpaceDecision	BoundaryPopulation	BoundaryBoundarySampling	SphereBasisAdversarial	ExampleLegitimate	SampleNon-adversarial	ExampleInput	Space$()*!"#$!"%&Poster PresentationAsiaCCS ’19, July 9–12, 2019, Auckland, New Zealand677Jury selection: balancing diversity and qualification. We
measure the diversity of the model pool and the DNN model ac-
cording to the transferability of adversarial examples between them.
After sampling 100 adversarial examples from the adversarial space
around each sample, we compute the symmetric transfer rate of
them between each pair of models, including the DNN model. Then
we are able to construct the matrix of symmetric transfer rate. Such
matrix is used as the measurement of the diversity between models.
We enumerate the model pool and the DNN model to find the
solution, which gives the jury of “KNN” and “R-SVM” (“KNN” and
“RF”) for the MNIST (CIFAR10) dataset. In Table 2, the jury given by
our approach ranks 3rd (2nd) in all 511 juries, which demonstrates
that our approach is effective to select the best possible jury. The
selected jury detects adversarial attacks with TPR 97.7% (81.9%),
96.9% (66.4%) and FPR 1.67% (30.6%) on the JSMA set, FGSM set and
benign test set of the MNIST (CIFAR10) dataset.
5 CONCLUSION
In this paper, we propose fidelity of ML models to name the gap
between what a model learns (model distribution) and what humans
learn (underlying population distribution). Fidelity is able to reflect
the trustworthiness of the outputs of machine learning models.
We propose an approach of using a set of traditional ML models
as a jury to measure the fidelity. The preliminary results of our
evaluation show that a jury is effective to estimate the fidelity,
with respectable high TPR and low FPR in detecting adversarial
examples. We also propose a jury selection approach to optimize the
fidelity measurement and evaluate the robustness of the selection
approach. As on-going work, the fidelity measurement is evaluated
in other task domains such as learning-based malware detection.
Acknowledgment. This research is supported by the National
Research Foundation, Prime Minister’s Office, Singapore (Grant No.
NRF2016NCR-NCR002-012).
REFERENCES
[1] George E Dahl, Jack W Stokes, Li Deng, and Dong Yu. 2013. Large-scale mal-
ware classification using random projections and neural networks. In 2013 IEEE
International Conference on ICASSP. IEEE, 3422–3426.
[2] Alhussein Fawzi, Omar Fawzi, and Pascal Frossard. 2015. Analysis of classifiers’
robustness to adversarial perturbations. arXiv preprint arXiv:1502.02590 (2015).
[3] Ian Goodfellow, Yoshua Bengio, and Aaron Courville. 2016. Deep Learning. MIT
Press. http://www.deeplearningbook.org.
[4] Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. 2014. Explaining and
harnessing adversarial examples. arXiv preprint arXiv:1412.6572 (2014).
[5] Eric Knorr. 2015. How paypal beats the bad guys with machine learning.
[6] Alex Krizhevsky and Geoffrey Hinton. 2009. Learning multiple layers of features
[7] Yann LeCun, Corinna Cortes, and Christopher JC Burges. 1998. The MNIST
from tiny images. (2009).
database of handwritten digits.
[8] Nicolas Papernot, Patrick McDaniel, Somesh Jha, Matt Fredrikson, Z Berkay Celik,
and Ananthram Swami. 2016. The limitations of deep learning in adversarial
settings. In Security and Privacy (EuroS&P), 2016 IEEE European Symposium on.
IEEE, 372–387.
[9] Nicolas Papernot, Patrick McDaniel, Xi Wu, Somesh Jha, and Ananthram Swami.
2016. Distillation as a defense to adversarial perturbations against deep neural
networks. In Security and Privacy (SP), 2016 IEEE Symposium on. IEEE, 582–597.
[10] Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
Ian Goodfellow, and Rob Fergus. 2013. Intriguing properties of neural networks.
arXiv preprint arXiv:1312.6199 (2013).
[11] Zhenlong Yuan, Yongqiang Lu, Zhaoguo Wang, and Yibo Xue. 2014. Droid-
sec: deep learning in android malware detection. In ACM SIGCOMM Computer
Communication Review, Vol. 44. ACM, 371–372.
Figure 3: Performance of juries in detecting adversarial at-
tacks for the MNIST and CIFAR10 models.
Table 2: Ground Truth Rank of Juries
Rank
1
2
3
4
5
6
7
8
9
10
...
507
508
509
510
511
Score
0.86
0.83
0.81
0.79
0.78
0.76
0.75
0.75
0.74
0.73
...
-6.28
-7.65
-7.95
-9.0
-9.0
MNIST
Jury
R-SVM
R-SVM, QDA
KNN, R-SVM
KNN, R-SVM, QDA
R-SVM, RF
R-SVM, RF, QDA
R-SVM, GNB
KNN, R-SVM, RF
KNN, R-SVM, RF, QDA
KNN, R-SVM, GNB
...
AdaB, GNB
QDA
AdaB, GNB, QDA
AdaB
AdaB, QDA
Score
-1.87
-2.32
-2.32
-2.43
-2.45
-2.46
-2.47
-2.48
-2.48
-2.48
...
-8.86
-8.97
-8.99
-9.0
-9.0
CIFAR10
Jury
RF
KNN, RF
L-SVM, RF
KNN, L-SVM, DT, RF, GNB, QDA
KNN, L-SVM, R-SVM, DT, RF, GNB, QDA
KNN, LR, L-SVM, DT, RF, GNB, QDA
KNN, L-SVM, DT, RF, AdaB, GNB, QDA
R-SVM, RF
L-SVM, DT, RF, GNB, QDA
KNN, DT, RF, GNB, QDA
...
LR, R-SVM
LR, R-SVM, AdaB
LR, AdaB
AdaB
R-SVM, AdaB
is 96.26% (77.27%), the minimum TPR is 64.53% (62.38%), and the
maximum TPRs are both 100%.
The results on the MNIST dataset demonstrate that the jury is
able to detect adversarial examples with a respectable TPR and
FPR. The TPR on the CIFAR10 dataset is comparable to that on the
MNIST dataset, but the average FPR is not that good. This result
comes as no surprise because the accuracy of the jury members
on the CIFAR10 test set is too low to be qualified. The average
accuracy (33.90%) of the pool models is even lower than the half
of the accuracy (82.35%) of the DNN model. Around half of the
test samples are misclassified by the juries. The FPR is expected to
decrease as the accuracy of the jury members increases.
We can conclude that the jury with sufficiently qualified jury
members is able to estimate the underlying population distribution
well and thus can estimate the fidelity.
4.2 Jury Selection
The goal of selecting a good jury is to maximize TPR and minimize
FPR. We rank the performance of all the 511 distinct juries in Ta-
ble 2. This ranking is based on the FGSM and the JSMA approach.
Considering the two approaches of crafting adversarial examples
are typically used in the community, we assume such ranking as the
ground truth of the jury performance to evaluate the jury selection
approach in this paper. The evaluation strategy is to compare the
selection result with the ground truth.
Poster PresentationAsiaCCS ’19, July 9–12, 2019, Auckland, New Zealand678