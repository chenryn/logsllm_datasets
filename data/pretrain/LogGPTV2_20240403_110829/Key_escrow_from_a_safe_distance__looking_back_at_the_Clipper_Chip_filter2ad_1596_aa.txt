title:Key escrow from a safe distance: looking back at the Clipper Chip
author:Matt Blaze
Key Escrow from a Safe Distance
Looking Back at the Clipper Chip
Matt Blaze
University of Pennsylvania
PI:EMAIL
ABSTRACT
In 1993, the US Government proposed a novel (and highly
controversial) approach to cryptography, called key escrow.
Key escrow cryptosystems used standard symmetric- and
public- key ciphers, key management techniques and pro-
tocols, but with one added feature: a copy of the current
session key, itself encrypted with a key known to the gov-
ernment, was sent at the beginning of every encrypted com-
munication stream. In this way, if a government wiretapper
encountered ciphertext produced under a key escrowed cryp-
tosystem, recovering the plaintext would be a simple matter
of decrypting the session key with the government’s key, re-
gardless of the strength of the underlying cipher algorithms.
Key escrow was intended to strike a “balance” between the
needs for eﬀective communications security against bad guys
on the one hand and the occasional need for the good guys
to be able to recover meaningful content from (presumably)
legally-authorized wiretaps.
It didn’t quite work out that way.
1. CARROTS, STICKS & ENCRYPTION
The 1990’s were interesting times for cryptography. The
civilian academic and commercial worlds were becoming se-
riously interested in this previously obscure and arcane sub-
ject, bolstered by new and exciting cryptologic advances
coupled with a brave new technological landscape in which
securing information was understood to be something that
would soon become a very important problem. Information
technology was getting inexorably faster, cheaper and bet-
ter, with the notable exception of security, which seemed
actually to get worse with every iteration of Moore’s law.
Cryptography, we believed (or hoped), could come to the
rescue, delivering its promise of securing information car-
ried over the increasingly insecure media of the Internet and
the “information superhighways” spoken about by visionar-
ies of the time. Cryptography, we increasingly sensed, would
soon no longer be merely the esoteric stuﬀ of spies, armies,
and governments, but would become an integral part of the
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ACSAC ’11 Dec. 5-9, 2011, Orlando, Florida USA
Copyright 2011 ACM 978-1-4503-0672-0/11/12 ...$10.00.
public information economy.
But there was a hitch.
Securing information, the government reminded us, can
be a double-edged sword. In the classic model for encrypted
communication, upstanding citizens Alice and Bob seek to
cryptographically protect their communication from Eve, an
evildoing eavesdropper. But in a world where transparent
cryptography is built in to every telephone, computer and
network node, giving the honest Alices and Bobs of the world
a mechanism to keep their secrets from Eve might also give
the less savory the ability to evade legal surveillance.
In
other words, what if Eve is occasionally the good guy?
And so even before the Web became synonymous with
the Internet, before a single bit of encrypted SSL traﬃc was
generated, lines were being drawn for what would become
an epic battle that would preoccupy a generation of cryp-
tographers.
(And it was a bad time for that community
to be preoccupied; this was the same time that the basic
foundations of the of web and other critical communications
technologies were designed and put into place. We’ve been
living with the security, or lack of security, built in to that
infrastructure ever since).
And the eavesdroppers had some leverage. While there
were no laws in the United States preventing Alice and Bob
from encrypting their communications as unbreakably as
they wanted, things weren’t so simple for the manufacturers
of the hardware and software they might need to eﬀectively
do it. Encryption technology, it turned out, was classiﬁed
as a munition, regulated under the same laws that control
traﬃcking in rocket launchers and nuclear weapons. These
laws made it legal to manufacture and sell cryptographic
equipment and software domestically, but required a special
license from the State Department to export any product
that incorporated the technology to any foreign destination.
Even making free encryption software available for download
over the Internet required obtaining an arms control license.
Make strong encryption that we can’t break, the govern-
ment made clear, and you will never get a license to export
your product to the world market. Anyone violating these
rules could be prosecuted under the same laws that apply to
arms traﬃckers and smugglers. That stick was more than
large enough to discourage the industry from incorporating
strong encryption into their products and standards, even
as the need for it was increasingly recognized.
But in April, 1993, the government dangled a carrot next
to the arms control stick: strong encryption that could be
incorporated into products and that could still be freely ex-
ported. The system, called key escrow, aimed to provide a
Figure 1: Mykotronx MYK-78T “Clipper” Escrowed
Encryption Chip (photo courtesy of the author)
Figure 2: AT&T TSD-3600 Telephone Security De-
vice (photo courtesy of the author)
strong cipher for public use with a “back door” that could
be exploited by law enforcement agents conducting a (pre-
sumably authorized) wiretap.
The centerpiece of the key escrow proposal was a tamper-
resistant hardware encryption module, called, in its initial
version, the Clipper Chip. Clipper was intended as a drop-
in replacement for a standard DES chip, but with a new
symmetric-key cipher algorithm, called Skipjack, designed
by the National Security Agency and using an 80 bit key.
But before any two Clipper chips could communicate, they
would ﬁrst exchange a Law Enforcement Access Field (LEAF)
that contained a copy of the current session key, itself en-
crypted with an “escrowed” Unit Key held by the govern-
ment. Any Clipper-encrypted communication could thus be
decrypted by government agents without needing to break
the (presumably strong) Skipjack cipher. The agents would
be able to recover the session key simply by decrypting the
copy in the LEAF (which they would intercept along with
the ciphertext) using their escrowed copy of the unit key.
The system would, however, still be secure against unau-
thorized eavesdroppers, who presumably would lack access
to the government’s escrowed key database. Clipper chips
(and other escrowed encryption modules in the same fam-
ily) were to be manufactured, under a government license,
by Mykotronx and available for sale to vendors of computers
and other secure communications hardware; see Figure 1.
It was, the policymakers must have thought, a perfect
solution.
2. BLOWING THE LEAF
Key escrow was not greeted by the technical community
with the unreserved warm reception for which the govern-
ment was perhaps hoping. Almost immediately, many objec-
tions were raised that questioned basic assumptions behind
the proposal. Why should the bad guys be expected to use
an encryption system that the government has announced in
advance it can decrypt? How will the key escrow database be
secured against unauthorized access? Why should industry
adopt expensive hardware encryption (as Clipper required)
just as software cryptography was becoming computation-
ally feasible? Why should anyone trust the Skipjack cipher,
an unpublished algorithm designed in secret by the NSA?
And would the system reliably even solve the problem it
aimed to address – ensuring government access to Clipper-
encrypted traﬃc?
The history of the 1990’s “crypto wars” has been well-
chronicled, and it is beyond the scope of this short paper
to address all the various problems, theoretical, practical,
and political, with key escrow as it was envisioned and as
it evolved. Instead, I will oﬀer here a personal perspective,
focusing on one small battle at the beginning of this (blood-
less but still damaging) “war.” I am surely omitting many
important episodes, details, and contributors, for which I
apologize; what follows should be understood as a war story,
which is at best an idiosyncratic, personal, recollection.
2.1 The AT&T Connection
AT&T (my employer at the time) was the ﬁrst (and ulti-
mately the only) company to produce a full product based
on the ill-fated escrow system, but that was not their orig-
inal plan. The AT&T TSD-3600D, announced in 1992, was
to be a voice encryption device that could be installed in
any standard wireline “POTS” telephone (between the phone
base and the handset). Calls placed to other TSD-3600D-
equipped telephones would be automatically digitized (at
4800bps) and encrypted using DES, making eavesdropping
on the conversation (by legal or illegal means) eﬀectively
infeasible under the technology of the time. The devices
weren’t cheap, but were designed by the same AT&T busi-
ness unit that produced the STU-III secure telephone for
the government, from which it borrowed some of its design
and security features. Two communicating TSDs would ﬁrst
perform a Diﬃe-Hellman key exchange (768 bit, in the ﬁrst
version of the product) to establish a session key, a 4 char-
acter hash of which was displayed on each unit’s LCD. To
detect ”man-in-the-middle” attacks, users could verify (by
voice over the encrypted session) that their displayed hashes
matched. See Figure 2.
When the US government learned of AT&T’s plans to
market the TSD, it worried that criminals might use the
devices to thwart wiretaps. Plans for a new escrowed en-
cryption system – with a wiretap backdoor – were hurriedly
drawn up by the NSA, and AT&T was persuaded to replace
the regular (non-escrowed) DES-based encryption scheme in
the original TSD product with one based on the new system,
which became known as the Clipper chip.
In 1993, when
Clipper was announced, a new Clipper-based TSD, dubbed
the TSD-3600E, was announced at the same time. As in-
centive for AT&T’s cooperation, the government agreed to
purchase a signiﬁcant quantity of Clipper-equipped TSD-
3600Es, which sold for over $1000 each. The original un-
escrowed DES-based TSD-3600D models were recalled by
AT&T and quickly disappeared from the market.
When key escrow – and AT&T’s involvement in it – was
made public, I was just starting my career as a cryptography
and security researcher in AT&T’s Bell Laboratories divi-
sion. My colleagues and I, like most members of the civilian
cryptography research community, learned about the escrow
scheme from the New York Times, and we were as skepti-
cal as anyone of the security and practicality of the govern-
ment’s plan. Working for a company that was so promi-
nently involved in what seemed like such a technically ill-
advised project was a bit uncomfortable, but it also had its
advantages. It was easier to get questions answered, to sort
out how this technology was supposed to work. There might
even be an opportunity to do some interesting research on
the subject. After some poking around, I managed to get
hold of a pair of ﬁrst generation TSD-3600s, but this was less
useful than I had hoped, especially given how infrequently I
needed to have sensitive telephone conversations. The real
breakthrough came when a group from NSA visited the Labs
to brief us and answer our questions, which was especially
helpful given the dearth of solid publicly released informa-
tion on the technology. My colleague Steve Bellovin and I
both took notes.
As the NSA meeting was breaking up, we asked, half-
jokingly, if they’d mind if we posted a summary of what
they’d told us to Usenet. To my great surprise, they en-
thusiastically agreed (evidently they were as eager to get
details out as we were to learn them). Steve and I compared
notes, and a few days later we posted a short writeup to the
sci.crypt newsgroup.
In writing the summary, we were careful to stick to the
facts, avoiding needlessly inﬂammatory commentary on the
wisdom of key escrow or on whether the NSA should be
trusted. This must have come as something of a relief to the
NSA’s readers of sci.crypt, ﬂooded as it was at the time
with relentless criticism of the Clipper program and of the
government’s intentions. A week later, the NSA invited me
to come down to their headquarters and R&D facility at Ft.
Meade, MD.
To make a long story short, I ended up bringing home
samples of a next generation key escrow device. This was
a PCMCIA card, code-named Tessera1,
intended for se-
cure PC email and other data encryption applications. The
Tessera card was based on a version of the key escrow chip,
called Capstone, that added some public key exchange and
digital signature features to its interface but was otherwise
similar to the Clipper chip in its functionality. The NSA
people asked only that I play with it and perhaps ﬁnd in-
teresting applications. I asked if I’d be able to publish my
results, and, again to my surprise, they agreed.
2.2 Oracles and Rogues
As a research platform, the Tessera PCMCIA card of-
fered a signiﬁcant advantage over the Clipper-based TSD-
3600 product: an open API with direct access to the encryp-
tion chip’s functional interface. I could simply connect the
card to a reader on my computer and write software to send
data directly to and interrogate results directly from the
Capstone chip (which included all the functions of the Clip-
per chip). This would be a much easier way to experiment
with key escrow than the other alternative available to me,
which involved removing the Clipper chip from a TSD-3600,
reverse-engineering its pinout, and building and debugging
an interface to it for my computer. With the PCMCIA card,
all that was already done.
So I could get right to work. Which, of course, raised the
question, to work on what, exactly? What questions would
be interesting to ask about key escrow?
At the time, most of the questions and criticisms of the
government’s key escrow proposal were either political (“why
should we trust the government to hold our keys?”) or re-
quired access to classiﬁed information (“how does the Skip-
jack cipher work?”). But I decided to start with a question
that the hardware might be helpful in answering: how do
key escrow devices enforce the escrow features? That is,
how do they prevent someone from using the Skipjack ci-
pher without sending the data ﬁelds that enable a govern-
ment eavesdropper to recover the key?
I found that the system included a number of safeguards