Adjusted propagation rates. In each iteration k, the aggregate
rate at which τ may enter Gf is strictly limited by the sum of
weights on the attack edges, which we denote by the volume
vol(Ea). Therefore, we aim to adjust the weights in the graph
such that vol(Ea) ∈ (0,|Ea|], without severely restricting trust
propagation in Gr. We accomplish this by assigning smaller
weights to edges incident to potential victims than other edges.
In particular, each edge {vi, vj} ∈ E keeps the default weight
w(vi, vj) = 1 if vi and vj are not potential victims. Otherwise,
we modify the weight as follows:
w(vi, vj) = min{1, β · (1 − max{p(vi), p(vj)})} ,
(4)
where β is a scaling parameter with a default value of β = 2.
Now, as vol(Ea) → 0 the portion of τ that enters Gf reaches
zero as desired. For proper degree normalization, we introduce
a self-loop {vi, vi} with weight w(vi, vi) = (1 − deg(vi)) /2
whenever deg(vi)  40. Moreover, notice
that real accounts that are not victims have similar rank values,
4(D) − T (cid:48)
where the largest difference is T (cid:48)
4(C)  50 iterations, the fakes collect similar or higher trust
than real accounts, following Equation 5. Also, notice that the
attack edges Ea = {{E, G},{E, F},{E, H}} have a volume
of vol(Ea) = 0.3, which is 10 times lower than its value if the
graph had unit weights, with vol(Ea) = 3. As we soon show
in Section V, adjusting the propagation rates is essential for
robustness against social inﬁltration.
3The deﬁnition of vol(U ) depends on whether U contains edges or nodes.
7
D. Trusted accounts and community structures
Íntegro is robust against social inﬁltration, as it limits the
portion of τ that enters Gf by the rate vol(Ea), regardless of
the number of attack edges, |Ea|. For the case when there are
few attack edges so that Gr and Gf are sparsely connected,
vol(Ea) is already small, even if one keeps w(vi, vj) = 1
for each attack edge {vi, vj} ∈ Ea. However, Gr is likely to
contain communities [37], [53], where each represents a dense
subgraph that is sparsely connected to the rest of the graph.
In this case, the propagation of τ in Gr becomes restricted
by the sparse inter-community connectivity, especially if Vt is
contained exclusively in a single community. We therefore seek
a selection strategy for trusted accounts, or seeds, that takes
into account the existing community structure in the graph.
Selection strategy. We pick trusted accounts as follows. First,
before rate adjustment, we estimate the community structure
in the graph using a community detection algorithm called
the Louvain method [54]. Second, after rate adjustment, we
exclude potential victims and pick small samples of nodes
from each detected community at random. Third and last, we
inspect the sampled nodes in order to verify they correspond to
real accounts that are not victims. We initialize the trust only
between the accounts that pass manual veriﬁcation by experts.
In addition to coping with the existing community structure
in the graph, this selection strategy is designed to also reduce
the negative impact of seed-targeting attacks. In such attacks,
fakes befriend trusted accounts in order to adversely improve
their ranking, as the total trust τ is initially distributed among
trusted accounts. By choosing the seeds at random, however,
the attacker is forced to guess the seeds among a large number
of nodes. Moreover, by choosing multiple seeds, the chance
of correctly guessing the seeds is further reduced, while the
amount of trust assigned to each seed in lowered. In practice,
the number of seeds depends on available resources for manual
account veriﬁcation, with a minimum of one seed per detected
community.
Community detection. We picked the Louvain method as it is
both efﬁcient and produces high-quality partitions. The method
iteratively groups closely connected communities together to
greedily improve the modularity of the partition [55], which is
a measure for partition quality. In each iteration, every node
represents one community, and well-connected neighbors are
greedily combined into the same community. At the end of the
iteration, the graph is reconstructed by converting the resulting
communities into nodes and adding edges that are weighted by
inter-community connectivity. Each iteration takes O(m) time,
and only a small number of iterations is required to ﬁnd the
A"B"C"DE"F"GHI"0"500"0"0"500"0"0"0"0"A"B"C"DE"F"GHI"231"(115)"316"(105)"5"(3)"46"(46)"129"(117)"13"(4)"237"(113)"13"(4)"10"(5)"A"B"C"DE"F"GHI"103"154"103"51"56"159"107"159"108"High"="1.0"Complementary"="0.25""Low"="0.1"Real"Trusted"VicOm"Fake"(a) Initialization!(b) After 4 iterations!(c) Stationary distribution!community structure which greedily maximizes the modularity.
While one can apply community detection to identify fake
accounts [19], doing so hinges on the assumption that fakes
always form tightly-knit communities, which is not necessarily
true [27]. This also means fakes can easily evade detection if
they establish sparse connectivity among themselves [9]. With
Íntegro, we do not make such an assumption. In particular, we
consider an attacker who can befriend a large number of real
or fake accounts, without any formal restrictions.
E. Computational cost
For an OSN with n users and m friendships, Íntegro takes
O(n log n) time to complete its computation, end-to-end. We
next analyze the running time in detail.
Runtime analysis. Recall that users have a limit on how many
friends they can have (e.g., 5K in Facebook, 1K in Tuenti),
so we have O(m) = O(n). Identifying potential victims takes
O(n log n) time, where it takes O(n log n) time to train an RF
classiﬁer and O(n) time to compute vulnerability scores. Also,
weighting the graph takes O(m) time. Detecting communities
takes O(n) time, where each iteration of the Louvain method
takes O(m) time, and the graph rapidly shrinks in O(1) time.
Propagating trust takes O(n log n) time, as each iteration takes
O(m) time and the propagation process iterates for O(log n)
times. Ranking and sorting users by their degree-normalized
trust takes O(n log n) time. So, the running time is O(n log n).
F. Security guarantees
For the upcoming security analysis, we consider attackers
who establish attack edges with victims uniformly at random.
Even though our design does not depend on the actual mixing
time of the graph, we assume the real region is fast mixing
for analytical tractability. This means that it takes O(log |Vr|)
iterations for trust propagation to converge in the real region.
In other words, we assume there is a gap between the mixing
time of the whole graph and that of the real region such that,
after O(log n) iterations, the propagation reaches its stationary
distribution in the real region but not in the whole graph.
Main theoretical result. The main security guarantee provided
by Íntegro is captured by the following theoretical result. For a
complete proof, we refer the reader to our technical report [56]:
Theorem 4.1: Given a social graph with a fast mixing real
region and an attacker who randomly establishes attack edges,
the number of fake accounts that rank similar to or higher than
real accounts after O(log n) iterations is O (vol(Ea) log n).
Proof sketch: Let us consider a graph G = (V, E) with a
fast mixing real region Gr. As weighting a graph changes its
mixing time by a constant factor [57], Gr remains fast mixing
after rate adjustment.
After O(log n) iterations, the trust vector Tω(V ) does not
reach its stationary distribution T∞(V ). Since trust propagation
starts from Gr, the fake region Gf gets only a fraction f  1 times higher aggregate trust than
it should receive in T∞(V ).
As Gr is fast mixing, each real account vi ∈ Vr receives
ω(vi) = c · τ /vol(V ),
approximately identical rank value of T (cid:48)
where τ /vol(V ) is the degree-normalized trust value in T∞(V )
(Equations 5 and 6). Knowing that Gf is controlled by the
attacker, each fake vj ∈ Vf receives a rank value T (cid:48)
ω(vj) that
depends on how the fakes inter-connect to each other. However,
since the aggregate trust in Gf is bounded, each fake receives
ω(vj) = f · τ /vol(V ), which is
on average a rank value of T (cid:48)
less than that of a real account. In the worst case, an attacker
can arrange a set Vm ⊂ Vf of fake accounts in Gf such that
each vk ∈ Vm receives a rank value of T (cid:48)
ω(vk) = c· τ /vol(V ),
while the remaining fakes receive a rank value of zero. Such a
set cannot have more than (f /c)· vol(Vs) = O (vol(Ea) log n)
accounts, as otherwise, f would not be less than 1 and Gf
would receive more than it should in Tω(V ).
Improvement over SybilRank’s bound. Íntegro shares many
design traits with SybilRank, which is the state-of-the-art in
graph-based detection [13]. In particular, modifying Íntegro by
setting w(vi, vj) = 1 for each (vi, vj) ∈ E will in fact result in
an identical ranking. It is indeed the prediction and incorpora-
tion of potential victims that differentiates Íntegro from other
proposals, giving it the unique advantages outlined earlier.
As stated by Theorem 4.1, the bound on ranking quality
relies on vol(Ea), regardless of how large the set Ea grows. As
we weight the graph based on the output of the victim classi-
ﬁer, our bound is sensitive to its classiﬁcation performance. We
next prove that if an OSN operator uses a victim classiﬁer that
is uniformly random, which means each user account vi ∈ V
is equally vulnerable with p(vi) = 0.5, then Íntegro is as good
as SybilRank in terms of ranking quality [13]:
Corollary 4.2: For a uniformly random victims classiﬁer,
the number of fake accounts that rank similar to or higher than
real accounts after O(log n) iterations is O(|Ea| log n).
Proof: This classiﬁer assigns each user account vi ∈ V
a score p(vi) = 0.5. By Equation 4, each edge {vi, vj} ∈ E
is assigned a unit weight w(vi, vj) = 1, where α = 0.5 and
β = 2. By Theorem 4.1, the number of fake accounts that
rank similar to or higher than real accounts after ω = O(log n)
iterations is O (vol(Ea) log n) = O(|Ea| log n).
By Corollary 4.2, Íntegro can outperform SybilRank in its
ranking quality by a factor of O (|Ea|/vol(Ea)), given the used
victim classiﬁer is better than random. This can be achieved
during the cross-validation phase of the victim classiﬁer, which
we thoroughly describe in what follows.
V. SYSTEM EVALUATION
We analyzed and evaluated Íntegro against SybilRank using
two real-world datasets recently collected from Facebook and
Tuenti. We also compared both systems through a large-scale
deployment at Tuenti in collaboration with its “Site Integrity”
team, which has 14 full-time account analysts and 10 full-time
software engineers who ﬁght spam and other forms of abuse.
Compared system. We chose SybilRank for two main reasons.
First, as discussed in Section IV-F, SybilRank utilizes a similar
ranking scheme based on the power iteration method, albeit on
an unweighted version of the graph. This similarity allowed us
to clearly show the impact of leveraging victim prediction on
fake account detection. Second, SybilRank outperforms other
8
Feature
Brief description
User activity:
Friends
Photos
Feed
Groups
Likes
Games
Movies
Music
TV
Books
Personal messaging:
Sent
Inbox
Privacy
Blocking actions:
Users
Graphics
Account information:
Last updated
Highlights
Membership
Gender
Cover picture
Proﬁle picture