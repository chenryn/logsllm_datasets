the resulting power would be below our target, and instead
relied on direct observations supported by crawler metadata. If
our experiment were to be repeated to validate improvements
in blacklisting or continuously test the ecosystem, we believe
that statistical tests could be highly useful in assessing whether
per-entity blacklisting performance improved signiﬁcantly for
each respective cloaking ﬁlter.
VI. SECURITY RECOMMENDATIONS
Based on analysis of our experimental ﬁndings, we propose
several possible improvements to the anti-phishing ecosystem.
A. Cloaking
Our ﬁrst set of recommendations focuses speciﬁcally on the
cloaking techniques we tested.
1) Mobile Users: We believe that
the highest priority
within the current ecosystem should be effective phishing
protection for mobile users. Such users are not only inher-
ently more vulnerable to phishing attacks [41], but now also
comprise the majority of web trafﬁc [4].
Our work has been impactful in better securing mobile users
by enhancing existing anti-phishing systems. For over a year
between mid-2017 and late 2018, GSB blacklists (with nearly
76% global market share) simply did not function properly on
mobile devices: none of our phishing sites with Filter A, E
or F (targeting both desktop and mobile devices) showed any
warnings in mobile Chrome, Safari, or Firefox despite being
blacklisted on desktop. We conﬁrmed the disparity between
desktop and mobile protection through periodic small-scale
testing and by analyzing an undisclosed dataset of trafﬁc to
real phishing sites. Following our disclosure, we learned that
the inconsistency in mobile GSB blacklisting was due to the
transition to a new mobile API designed to optimize data
usage, which ultimately did not function as intended. Because
(cid:18)(cid:20)(cid:22)(cid:22)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:42:45 UTC from IEEE Xplore.  Restrictions apply. 
blacklisting was not rectiﬁed after our full tests, we contacted
the entities anew. As a result, in mid-September 2018 Mozilla
patched Firefox (from version 63) such that all desktop
warnings were also shown on mobile. Google followed suit
days thereafter with a GSB API ﬁx that covered mobile GSB
browsers retroactively; mobile Chrome and Safari now mirror
desktop listings, albeit with a shorter-lived duration to lower
bandwidth usage. Chrome, Safari, and Firefox thus again join
Opera as mobile browsers with effective blacklists, though
some popular mobile browsers still lack such protection [41].
Upon close inspection of the preliminary test results, we
found that Filter B sites were solely blacklisted due to their
suspicious URLs rather than our reports. During our full tests,
not a single site with Filter B was blacklisted in any browser,
interestingly despite the fact that crawlers did successfully
retrieve many of these sites. GSB addressed this vulnerability
in mid-September 2018, together with the aforementioned API
ﬁx. Through a subsequent ﬁnal redeployment of PhishFarm,
we veriﬁed that sites with Filter B were being blacklisted
following reports to GSB,
the APWG, and PayPal. Other
entities— including ones we did not test— should ensure that
sites targeted at mobile users are being effectively detected.
2) Geolocation: Although our experiments only considered
two simple geolocation ﬁlters (US and non-US), our ﬁndings
are indicative of exploitable weaknesses in this area. Given the
overwhelming amount of crawler trafﬁc from the US (79%,
per Table IX in Appendix III), Filter C should not have
been as effective as it proved to be. We hypothesize that
other geo-speciﬁc ﬁlters would have similarly low blacklisting
rates, in part due to the crawler characteristics discussed in
Section V-F1. Country- or region-speciﬁc ﬁltering paired with
localized page content is not an unusual sight in real-world
PayPal phishing kits that we have analyzed.
3) JavaScript: It is trivial to implement JavaScript-based
cloaking such as Filter F. This technique proved to be effective
in slowing blacklisting by three of the ﬁve entities in our full
tests. Fortunately, SmartScreen bypasses this technique well,
and PayPal started doing so following our disclosure. The
broader ecosystem should better adapt to client-side cloaking,
in particular if its sophistication increases over time.
B. Anti-phishing Entities
We also offer a number of more general recommendations
for anti-phishing systems of tomorrow.
1) Continuous Testing: The mere failure of mobile black-
listing that we observed during our experiments is sufﬁcient to
warrant the need for continuous testing and validation of black-
list performance. Periodic deployment of PhishFarm could
be used for such validation. In addition, continuous testing
could help ensure that future cloaking techniques— which may
grow in sophistication— can effectively be mitigated without
compromising existing defenses. As an added beneﬁt, trends
in the relative performance of different entities and the overall
timeliness and coverage of blacklisting could be modeled.
2) Trusted Reporting Channels: The phishing reporting
channels we tested merely capture a suspected URL or a
malicious e-mail. While the latter is useful in identifying spam
origin, we believe a better solution would be the implementa-
tion of standardized trusted phishing reporting systems that
allow the submission of speciﬁc metadata (such as victim
geolocation or device). Trusted channels could allow detection
efforts to more precisely target high-probability threats while
minimizing abuse from deliberate false-negative submissions;
they could also simplify and expedite collaboration efforts
between anti-phishing entities and abused brands, which may
hold valuable intelligence about imminent threats.
3) Blacklist Timeliness: The gap between the detection
of a phishing website and its blacklisting across browsers
represents the prime window for phishers to successfully carry
out their attacks. At the level of an individual entity, cloaking
has a stronger effect on the occurrence rather than the time-
liness of blacklisting. However, if we look at the ecosystem
as a whole in Figure 3, cloaking clearly delays blacklisting
overall. Our test results show that blacklisting now typically
occurs in a matter of hours— a stark improvement over the
day- or week-long response time observed years ago [6],
[55]. However, given the tremendous increase in total phishing
attacks since then (on the order of well over 100 attacks per
hour in 2018 [2]), we believe that even today’s 40-minute
best-case blacklist response time is too slow to deter phishers
and effectively protect users. The gap needs to be narrowed,
especially by slower entities (i.e. those not directly in control
of blacklists). Future work should investigate the real-world
impact of delays in blacklisting on users and organizations
victimized by phishing attacks in order to accurately establish
an appropriate response threshold.
4) Volume: GSB, the APWG, and PayPal crawled nearly
all of the phishing sites we reported. In particular, GSB proved
to deliver a consistently agile response time despite the high
number of reports we submitted. Other entities fell short of
this level of performance. With increasing volumes of phishing
attacks, it is essential that all players in the ecosystem remain
robust and capable of delivering a consistent response.
5) Data Sharing: Data sharing has long been a concern
within the ecosystem [56]. We found that
the two main
blacklist operators (GSB and SmartScreen) did not appear
to effectively share data with each other, as per Table VI.
However, clearinghouse entities (APWG and PhishTank) and
PayPal itself showed consistent protection across all browsers.
Unfortunately, the timeliness and overall coverage of clearing-
houses appear to be inferior to those of the blacklist operators
in their respective browsers. Closer cooperation could thus not
only speed up blacklisting, but also ensure that malicious sites
are blocked universally. Strengthening this argument, perhaps
a breakdown in communication between infrastructure used by
different entities accounted for those of our sites which were
successfully crawled but not ultimately blacklisted.
VII. RELATED WORK
To the best of our knowledge, our work is the ﬁrst controlled
effort to measure the effects of cloaking in the context of
(cid:18)(cid:20)(cid:22)(cid:23)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:42:45 UTC from IEEE Xplore.  Restrictions apply. 
phishing. Several prior studies measured the general effective-
ness of anti-phishing blacklists and the behavior of phishing
kits; none of the prior work we identiﬁed considered cloaking,
which may have had a skewing effect on the datasets and
ecosystem ﬁndings previously reported. Cloaking itself has
previously been studied with respect
to malicious search
engine results; Invernizzi et al. [7] proposed a system to detect
such cloaking with high accuracy. Oest et al. [8] later studied
the nature of server-side cloaking techniques within phishing
kits and proposed approaches for defeating each.
The work most similar to ours is NSS Labs’ [39] recent use
of a proprietary distributed testbed [57] to study the timeliness
of native phishing blacklisting in Chrome, Firefox, and Edge.
The main limitation of NSS Labs’ approach is the reliance on
feeds of known phishing attacks; any delay in the appearance
of a site in each source feed can affect
the accuracy of
blacklisting time measurements. Furthermore, phishing sites
could be overlooked in the case of successful cloaking against
the feeds. We address these limitations by having full control
over the deployment and reporting time of phishing sites.
Sheng et al. [6] took an empirical approach to measure
the effectiveness of eight anti-phishing toolbars and browsers
powered by ﬁve anti-phishing blacklists. The authors found
that heuristics by Microsoft and Symantec proved effective
in offering zero-hour protection against a small fraction of
phishing attacks, and that full propagation across phishing
blacklists spanned several hours. This work also found that
false positive rates in blacklists are near-zero; we thus did
not pursue such tests in our experiments. While Sheng et al.’s
work was based on phishing sites only 30 minutes old, and
was thus better controlled than earlier blacklist tests [58], the
datasets studied were of limited size and heterogeneous in
terms of victim brands; the anti-phishing tools evaluated are
now dated. In addition, Sheng et al. checked blacklist status
with a granularity of one hour— longer than our 10 minutes.
Han et al. [25] analyzed the lifecycle of phishing sites
by monitoring cybercriminals’ behavior on a honeypot web
server. The authors timed the blacklisting of the uploaded
sites across Google Safe Browsing and PhishTank. Uniquely,
this work sheds light on the time between the creation and
deployment of real phishing sites. A key difference in our work
is our ability to customize and test different conﬁgurations of
phishing kits instead of waiting for one to be uploaded. For
instance, we could target speciﬁc brands or conﬁgure our own
cloaking techniques to directly observe the ecosystem’s re-
sponse. Our experiments suggest a signiﬁcantly faster blacklist
response time by the ecosystem than what Han et al. found;
our test sample size was also nearly ﬁve times larger.
Virvilis et al. [41] carried out an evaluation of mobile
web browser phishing protection in 2014 and found that
major mobile web browsers at the time included no phishing
protection. Like that of Sheng et al.,
this evaluation was
empirical and based on a set of known phishing URLs. In
our work, we found that mobile Chrome, Safari, and Firefox
now natively offer blacklist protection, but that this protection
was not functioning as advertised during our tests.
The differences between today’s phishing trends and those
seen in prior work show that
the ecosystem is evolving
quickly. This warrants regular testing of defenses and re-
evaluation of criminals’ circumvention techniques and attack
vectors; it also underscores the importance of scalable and
automatable solutions. Our testbed shares some similarities
with previous work [39], [6] but it is the only such testbed to
offer full automation without the need for intervention during
the execution of experiments, and the only one to actively
deploy sites and directly send reports to entities.
VIII. CONCLUSION
By launching and monitoring a large set of phishing sites,
we carried out the ﬁrst controlled evaluation of how cloaking
techniques can hamper the timeliness and occurrence of phish-
ing blacklist warnings in modern web browsers. As a result
of our disclosure to anti-phishing entities, mobile blacklisting
is now more consistent, and some of the cloaking techniques
we tested are no longer as effective; others represent ongoing
vulnerabilities which could be addressed through tweaks to
existing detection systems. Such tweaks should also seek to
improve overall timeliness of blacklists to better counter the
modern onslaught of phishing attacks. Blacklist protection
should not be taken for granted; continuous testing— such
as that supported by our framework— is key to ensuring that
browsers are secured sufﬁciently, and as intended.
Cloaking carries a detrimental effect on the occurrence of
blacklisting due to the fundamentally-reactive nature of the
main detection approach currently used by blacklists; it thus
has the potential to cause continuous damage to the organiza-
tions and users targeted by phishers. Although no single entity
we tested was able to individually defeat all of our cloaking
techniques, collectively the requisite infrastructure is already
in place. In the short
term, collaboration among existing
entities could help address their individual shortcomings. We
observed that proactive defenses (such as the URL heuristics
of SmartScreen) proved to deliver superior protection— but
only under the right circumstances. In the long term, the
ecosystem should move to more broadly implement general-
purpose proactive countermeasures to more reliably negate
is important for the ecosystem to be able to
cloaking. It
effectively bypass cloaking because it
is merely one way
in which phishing sites can be evasive. For instance, with
cloaking alongside redirection chains or bulletproof hosting,
phishing sites might otherwise avoid existing mitigations far
more successfully than what we have observed.
Phishing has proven to be a difﬁcult problem to solve due
to attackers’ unyielding persistence, the cross-organizational
nature of infrastructure abused to facilitate phishing, and the
reality that technical controls cannot always compensate for
the human weakness exploited by social engineers. We believe
that continuous and close collaboration between all anti-abuse
entities, which can lead to a deep understanding of current
threats and development of intelligent defenses, is the crux of
optimizing controls and delivering the best possible long-term
protection for phishing victims.
(cid:18)(cid:20)(cid:22)(cid:24)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:42:45 UTC from IEEE Xplore.  Restrictions apply. 
ACKNOWLEDGMENTS
The authors would like to thank the reviewers for their
insightful feedback and suggestions. This work was partially
supported by PayPal, Inc. and a grant from the Center for Cy-
bersecurity and Digital Forensics at Arizona State University.
REFERENCES
[1] “Anti-Phishing Working Group: APWG Trends Report Q4
[Online]. Available:
2016,” (Date last accessed 23-August-2017).
https://docs.apwg.org/reports/apwg trends report q4 2016.pdf
[2] “Anti-Phishing Working Group: APWG Trends Report Q1
[Online]. Available:
2018,” (Date last accessed 31-August-2018).
https://docs.apwg.org/reports/apwg trends report q1 2018.pdf
[3] J. Hong, “The state of phishing attacks,” Communications of the ACM,
vol. 55, no. 1, pp. 74–81, 2012.
[4] “Desktop
vs mobile
vs
tablet market
share worldwide,”
http://gs.statcounter.com/platform-market-share/desktop-mobile-tablet,
2018, [Online; accessed 31-Aug-2018].
[5] S. Chhabra, A. Aggarwal, F. Benevenuto, and P. Kumaraguru, “Phi. sh/$
ocial: the phishing landscape through short urls,” in Proceedings of the
8th Annual Collaboration, Electronic messaging, Anti-Abuse and Spam
Conference. ACM, 2011, pp. 92–101.
[6] S. Sheng, B. Wardman, G. Warner, L. F. Cranor, J. Hong, and C. Zhang,
“An empirical analysis of phishing blacklists,” 2009.
[7] L. Invernizzi, K. Thomas, A. Kapravelos, O. Comanescu, J.-M. Picod,
and E. Bursztein, “Cloak of visibility: Detecting when machines browse
a different web,” in Proceedings of the 37th IEEE Symposium on Security
and Privacy, 2016.
[8] A. Oest, Y. Safaei, A. Doup´e, G. Ahn, B. Wardman, and G. Warner,
“Inside a phisher’s mind: Understanding the anti-phishing ecosystem
through phishing kit analysis,” in 2018 APWG Symposium on Electronic
Crime Research (eCrime), May 2018, pp. 1–12.
[9] K. Thomas, D. McCoy, C. Grier, A. Kolcz, and V. Paxson, “Trafﬁcking
fraudulent accounts: The role of the underground market in Twitter spam
and abuse.” in USENIX Security Symposium, 2013, pp. 195–210.
[10] T. Holz, M. Engelberth, and F. Freiling, “Learning more about the
underground economy: A case-study of keyloggers and dropzones,”
Computer Security–ESORICS 2009, pp. 1–18, 2009.
[11] D. K. McGrath and M. Gupta, “Behind phishing: An examination of
phisher modi operandi.” LEET, vol. 8, p. 4, 2008.
[12] K. Thomas, F. Li, A. Zand, J. Barrett, J. Ranieri, L. Invernizzi,
Y. Markov, O. Comanescu, V. Eranti, A. Moscicki, D. Margolis, V. Pax-
son, and E. Bursztein, Eds., Data breaches, phishing, or malware?
Understanding the risks of stolen credentials, 2017.
[13] R. Dhamija, J. D. Tygar, and M. Hearst, “Why phishing works,” in
Proceedings of the SIGCHI Conference on Human Factors in Computing
Systems. New York, NY, USA: ACM, 2006, pp. 581–590.
[14] A. Emigh, “ITTC report on online identity theft technology and coun-
termeasures 1: Phishing technology, chokepoints and countermeasures,”
Radix Labs, Oct 2005.
[15] C. Jackson, D. Simon, D. Tan, and A. Barth, “An evaluation of extended
validation and picture-in-picture phishing attacks.” Microsoft Research,
January 2007.
[16] M. Wu, R. C. Miller, and S. L. Garﬁnkel, “Do security toolbars actually
prevent phishing attacks?” in Proceedings of the SIGCHI Conference on
Human Factors in Computing Systems. ACM, 2006, pp. 601–610.
[17] G. Stringhini, C. Kruegel, and G. Vigna, “Shady paths: Leveraging
surﬁng crowds to detect malicious web pages,” in Proceedings of
the 2013 ACM SIGSAC Conference on Computer & Communications
Security, ser. CCS ’13, 2013, pp. 133–144.
[18] Y. Takata, S. Goto, and T. Mori, “Analysis of redirection caused by
web-based malware,” Proceedings of the Asia-Paciﬁc advanced network,
vol. 32, pp. 53–62, 2011.
[19] “CWE-601: URL Redirection to Untrusted Site (’Open Redirect’).”
[Online]. Available: http://cwe.mitre.org/data/deﬁnitions/601.html
[20] C. Whittaker, B. Ryner, and M. Nazif, “Large-scale automatic
[Online].
classiﬁcation of phishing pages,” in NDSS ’10, 2010.
Available: http://www.isoc.org/isoc/conferences/ndss/10/pdf/08.pdf
[21] H. McCalley, B. Wardman, and G. Warner, “Analysis of back-doored
phishing kits.” in IFIP Int. Conf. Digital Forensics, vol. 361. Springer,
2011, pp. 155–168.
[22] M. Cova, C. Kruegel, and G. Vigna, “There is no free phish: An analysis
of “free” and live phishing kits,” in Proceedings of the 2nd Confer-
ence on USENIX Workshop on Offensive Technologies, ser. WOOT’08.
Berkeley, CA, USA: USENIX Association, 2008, pp. 4:1–4:8.
[23] D. Manky, “Cybercrime as a service: a very modern business,” Computer
Fraud & Security, vol. 2013, no. 6, pp. 9–13, 2013.
[24] D. Birk, S. Gajek, F. Grobert, and A. R. Sadeghi, “Phishing phishers
- observing and tracing organized cybercrime,” in Second International
Conference on Internet Monitoring and Protection, July 2007, p. 3.
[25] X. Han, N. Kheir, and D. Balzarotti, “Phisheye: Live monitoring of
sandboxed phishing kits,” in Proceedings of the 2016 ACM SIGSAC
Conference on Computer and Communications Security. ACM, 2016,
pp. 1402–1413.
[26] S. Hao, M. Thomas, V. Paxson, N. Feamster, C. Kreibich, C. Grier,
and S. Hollenbeck, “Understanding the domain registration behavior
of spammers,” in Proceedings of
the 2013 conference on Internet
measurement conference. ACM, 2013, pp. 63–76.
[27] Z. Ramzan, “Phishing attacks and countermeasures,” in Handbook of
information and communication security. Springer, 2010, pp. 433–448.
worldwide,”
accessed
browser market
http://gs.statcounter.com/browser-market-share/,
20-Aug-2017].
[28] “Statcounter:
share
[Online;
Desktop
[29] M. Matsuoka, N. Yamai, K. Okayama, K. Kawano, M. Nakamura, and
M. Minda, “Domain registration date retrieval system of urls in e-mail
messages for improving spam discrimination,” in Computer Software
and Applications Conference Workshops (COMPSACW), 2013 IEEE
37th Annual.
IEEE, 2013, pp. 587–592.
[30] M. Khonji, Y. Iraqi, and A. Jones, “Enhancing phishing e-mail clas-
for
siﬁers: A lexical url analysis approach,” International Journal
Information Security Research (IJISR), vol. 2, no. 1/2, p. 40, 2012.
[31] S. Duman, K. Kalkan-Cakmakci, M. Egele, W. Robertson, and E. Kirda,
“Emailproﬁler: Spearphishing ﬁltering with header and stylometric fea-
tures of emails,” in Computer Software and Applications Conference
(COMPSAC), vol. 1.
IEEE, 2016, pp. 408–416.
[32] L. Bilge, E. Kirda, C. Kruegel, and M. Balduzzi, “Exposure: Finding
malicious domains using passive dns analysis.” in NDSS, 2011.
[33] B. Liang, M. Su, W. You, W. Shi, and G. Yang, “Cracking classiﬁers for
evasion: A case study on Google’s phishing pages ﬁlter,” in Proceedings
of the 25th International Conference on World Wide Web.
International
World Wide Web Conferences Steering Committee, 2016, pp. 345–356.
[34] G. Xiang, J. Hong, C. P. Rose, and L. Cranor, “Cantina+: A feature-rich
machine learning framework for detecting phishing web sites,” ACM
Trans. Inf. Syst. Secur., vol. 14, no. 2, pp. 21:1–21:28, Sep. 2011.
[35] Y. Zhang, J. I. Hong, and L. F. Cranor, “Cantina: A content-based
approach to detecting phishing web sites,” in Proceedings of the 16th
International Conference on World Wide Web, 2007, pp. 639–648.
[36] D. Canali, D. Balzarotti, and A. Francillon, “The role of web hosting
providers in detecting compromised websites,” in Proceedings of the
22nd International Conference on World Wide Web, 2013, pp. 177–188.
[37] A. Lukovenko, “Let’s Automate Let’s Encrypt,” Linux Journal, no. 266,
Jun. 2016.
[38] J.
P. Randy Abrams, Orlando Barrera,
Comparative Analysis
https://www.helpnetsecurity.com/images/articles/Browser%20Security
%20CAR%202013%20-%20Phishing%20Protection.pdf.
Security
- Phishing Protection,” NSS Labs, 2013,
“Browser
“NSS
Labs,
[39] NSS
Test
of
Available:
labs-conducts-ﬁrst-cross-platform-test-of-leading-web-browsers/
Cross-Platform
Leading Web
[Online].
https://www.nsslabs.com/company/news/press-releases/nss-
Browsers,” Oct
Conducts
2017.
Labs
First
[40] R. Fielding, J. Gettys, J. Mogul, H. Frystyk, L. Masinter, P. Leach,
and T. Berners-Lee, “Hypertext transfer protocol – HTTP/1.1,” United
States, 1999.
[41] N. Virvilis, N. Tsalis, A. Mylonas, and D. Gritzalis, “Mobile devices:
A phisher’s paradise,” 2014 11th International Conference on Security
and Cryptography (SECRYPT), pp. 1–9, 2014.
[42] “Google Safe Browsing: Report Phishing Page.” [Online]. Available:
https://safebrowsing.google.com/safebrowsing/report phish/