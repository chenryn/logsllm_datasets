```
kubectl describe service my-svc
```
前面命令的结果将是以下输出:
```
Name:                   my-svc
Namespace:              default
Labels:                 app=web-application
Annotations:            
Selector:               app=web-application
Type:                   NodePort
IP:                     10.32.0.8
Port:                    8080/TCP
TargetPort:             8080/TCP
NodePort:                31598/TCP
Endpoints:              10.200.1.3:8080,10.200.1.5:8080
Session Affinity:       None
Events:                 
```
从这个输出中，我们看到`NodePort`线，我们为这个服务分配的端口是`31598`。因此，可以在`[NODE_IP]:[ASSIGNED_PORT]`的任何节点上访问该服务。
或者，我们可以手动为服务分配一个节点端口。手动分配的节点端口的 YAML 如下:
manual-nodeport-service.yaml
```
apiVersion: v1
kind: Service
metadata:
  name: my-svc
Spec:
  type: NodePort
  selector:
    app: web-application
  ports:
    - name: http
      protocol: TCP
      port: 80
      targetPort: 8080
      nodePort: 31233
```
如您所见，我们在`30000` - `32767`范围内选择了`nodePort`，在本例中为`31233`。要了解该节点端口服务如何跨节点工作，请查看下图:
![Figure 5.2 – NodePort Service](img/B14790_05_002.jpg)
图 5.2–节点端口服务
正如您所看到的，尽管该服务在集群中的每个节点(节点 A、节点 B 和节点 C)都可以访问，但网络请求仍然在所有节点(节点 A、节点 B 和节点 C)的 Pod 之间进行负载平衡，而不仅仅是被访问的节点。这是确保可以从任何节点访问应用的有效方法。然而，当使用云服务时，您已经有了一系列在服务器之间传播请求的工具。下一种类型的服务，负载平衡器，让我们在 Kubernetes 的上下文中使用这些工具。
# 设置负载平衡器服务
负载平衡器是 Kubernetes 中的一种特殊服务类型，它根据集群的运行位置来配置负载平衡器。例如，在 AWS 中，Kubernetes 将提供一个弹性负载平衡器。
重要说明
有关负载平衡器服务和配置的完整列表，请访问[https://Kubernetes . io/docs/concepts/Services-networking/service/# load balancer](https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer)查看 Kubernetes Services 的文档。
与`ClusterIP`或节点端口不同，我们可以以特定于云的方式修改负载平衡器服务的功能。通常，这是使用服务 YAML 文件中的注释块来完成的——正如我们之前讨论的，它只是一组键和值。为了了解如何为 AWS 做到这一点，让我们回顾一下负载平衡器服务的规范:
load balancer service . YAML-负载平衡器服务
```
apiVersion: v1
kind: Service
metadata:
  name: my-svc
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-ssl-cert: arn:aws.. 
spec:
  type: LoadBalancer
  selector:
    app: web-application
  ports:
    - name: http
      protocol: TCP
      port: 80
      targetPort: 8080
```
虽然我们可以在没有任何注释的情况下创建一个负载平衡器，但是支持的特定于 AWS 的注释为我们提供了指定我们希望将哪个 TLS 证书(通过亚马逊证书管理器中的 ARN)附加到负载平衡器的能力(如前面的 YAML 代码所示)。AWS 注释还允许为负载平衡器等配置日志。
在撰写本书时，以下是 AWS 云提供商支持的一些关键注释:
*   `service.beta.kubernetes.io/aws-load-balancer-ssl-cert`
*   `service.beta.kubernetes.io/aws-load-balancer-proxy-protocol`
*   `service.beta.kubernetes.io/aws-load-balancer-ssl-ports`
    重要说明
    所有提供商的注释和解释的完整列表可以在官方 Kubernetes 文档的**云提供商**页面上找到，网址为[。](https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller/)
最后，关于负载平衡器服务，我们已经介绍了您最可能使用的服务类型。但是，对于服务本身在 Kubernetes 之外运行的特殊情况，我们可以使用另一种服务类型:ExternalName。
# 创建外部名称服务
ExternalName 类型的服务可以用来代理实际上没有在您的集群上运行的应用，同时仍然保持服务作为一个可以随时更新的抽象层。
让我们设定场景:您有一个遗留的生产应用运行在 Azure 上，您希望从集群中访问它。您可以在`myoldapp.mydomain.com`访问该遗留应用。但是，您的团队目前正在容器化这个应用，并在 Kubernetes 上运行它，并且这个新版本目前正在您的集群上的`dev`命名空间环境中工作。
您可以始终在您的生产(`prod`)和开发(`dev`)名称空间中指向名为`my-svc`的服务，而不是要求您的其他应用根据环境与不同的地方进行对话。
在`dev`中，这个服务可以是一个`ClusterIP`服务，引导你在 Pods 上新的容器化应用。下面的 YAML 展示了正在开发的容器化服务应该如何工作:
cluster IP-for-external-service . YAML
```
apiVersion: v1
kind: Service
metadata:
  name: my-svc
  namespace: dev
Spec:
  type: ClusterIP
  selector:
    app: newly-containerized-app
  ports:
    - name: http
      protocol: TCP
      port: 80
      targetPort: 8080
```
在`prod`命名空间中，该服务将改为`ExternalName`服务:
externalname 服务. yaml
```
apiVersion: v1
kind: Service
metadata:
  name: my-svc
  namespace: prod
spec:
  type: ExternalName
  externalName: myoldapp.mydomain.com
```
因为我们的`ExternalName`服务实际上并没有将请求转发给 Pods，所以我们不需要选择器。相反，我们指定一个`ExternalName`，这是我们希望服务指向的域名。
下面的图显示了`ExternalName`服务如何在这种模式下使用:
![Figure 5.3 – ExternalName Service configuration](img/B14790_05_003.jpg)
图 5.3–外部名称服务配置
在上图中，我们的 **EC2 运行遗留应用**是一个 AWS 虚拟机，位于集群外部。我们的**外部名称**类型的**服务 B** 会将请求路由到虚拟机。这样，我们的 **Pod C** (或集群中的任何其他 Pod)只需通过 ExternalName 服务的 Kubernetes 域名就可以访问我们的外部遗留应用。
借助`ExternalName`，我们已经完成了对所有 Kubernetes 服务类型的审查。让我们继续讨论一种更复杂的公开应用的方法 Kubernetes Ingress 资源。
# 配置入口
正如本章开头提到的，入口提供了一种将请求路由到集群的粒度机制。入口不会取代服务，而是通过基于路径的路由等功能来增强服务。为什么有这个必要？原因很多，包括成本。有 10 条路径到达`ClusterIP`服务的入口比为每条路径创建一个新的负载平衡器服务要便宜得多，而且它使事情变得简单易懂。
Ingresses 不像 Kubernetes 中的其他服务那样工作。仅仅创建入口本身是没有用的。您需要两个附加组件:
*   入口控制器:您可以从许多实现中进行选择，构建在诸如 Nginx 或 HAProxy 之类的工具上。
*   预期路由的集群 IP 或节点端口服务。
首先，让我们讨论如何配置入口控制器。
## 入口控制器
通常，集群将不会配置任何预先存在的入口控制器。您需要选择一个并将其部署到集群中。`ingress-nginx`可能是最受欢迎的选择，但还有其他几个选择——完整列表见[https://kubernetes . io/docs/concepts/services-networking/ingress-controller/](https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/)。
让我们学习如何部署入口控制器——为了本书的目的，我们将坚持使用由 Kubernetes 社区`ingress-nginx`创建的 Nginx 入口控制器。
控制器之间的安装可能不同，但对于`ingress-nginx`来说，主要有两个部分。首先，要部署主控制器本身，请运行以下命令，该命令可能会根据目标环境和最新的 Nginx Ingress 版本而变化:
```
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v0.41.2/deploy/static/provider/cloud/deploy.yaml
```
其次，我们可能需要根据运行的环境来配置我们的入口。对于运行在 AWS 上的集群，我们可以将入口点配置为使用我们在 AWS 中创建的弹性负载平衡器。
重要说明
要查看所有特定于环境的设置说明，请参见位于[https://kubernetes.github.io/ingress-nginx/deploy/](https://kubernetes.github.io/ingress-nginx/deploy/)的`ingress-nginx`文档。
Nginx 入口控制器是一组 Pods，每当创建新的入口资源(自定义 Kubernetes 资源)时，它将自动更新 Nginx 配置。除了入口控制器之外，我们还需要一种将请求路由到入口控制器的方法——称为入口点。
### 入口点
默认的`nginx-ingress`安装还将创建一个单一的服务，向 Nginx 层提供请求，此时入口规则接管。根据您如何配置入口，这可以是负载平衡器或节点端口服务。在云环境中，您可能会使用云负载平衡器服务作为集群入口的入口点。