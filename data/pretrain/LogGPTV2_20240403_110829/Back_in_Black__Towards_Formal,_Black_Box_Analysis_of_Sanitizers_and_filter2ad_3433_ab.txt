lookahead property deﬁnition is based on the one given by
Veanes et al. [14] for Symbolic Transducers, however our
deﬁnition better ﬁts our terminology and the intuition behind
our algorithms.
∗ and outputs some γ ∈ Γ
For a given automaton M, we denote by Mq[s] the state
reached when the automaton is executed from state q on input
s. When the state q is omitted we assume that M is executed
from the initial state. Let l : Q → {0, 1} be a function denoting
whether a state is ﬁnal. We deﬁne the transduction function
TM (u) as the output of a transducer/Mealy Machine M on
input u omitting the subscript M when the context is clear.
For transducers we will also use the notation u[M ]v to signify
that TM (u) = v for a transducer M.
For a string s, denote by si the i-th character of the string.
In addition, we denote by s>i the substring s starting after si.
The operators si be the sufﬁx of z that is not processed
yet; by submitting the membership query siz>i we obtain αi.
Observe that based on the fact that z is a counterexample
it holds that α0 (cid:11)= α|z|. It follows that there exists some
i0 ∈ {0, . . . ,|z|− 1} for which αi0
(cid:11)= αi0+1. We can ﬁnd such
i0 via a binary search using O(log |z|) membership queries.
The new distinguishing string d will be deﬁned as the sufﬁx
of z>i0 that excludes the ﬁrst symbol b (denoted as z>i0+1).
We observe the following: recall that αi0 is the outcome of the
membership query of si0 z>i0 = si0 bz>i0+1 and αi0+1 is the
outcome of the membership query si0+1z>i0+1. Furthermore,
in H, si0 transitions to si0+1 by consuming b, hence we have
b ≡ si0+1 mod W . By adding d = z>i0+1 to W we
that si0
b, z>i0+1) (cid:11)= T (si0+1, z>i0+1) and hence the
have that T (si0
state si0+1 and the state that is derived by si0 consuming b
should be distinct (while H pronounced them equal). We ob-
serve that the new observation table OT is not closed anymore:
b (cid:11)≡ si0+1 mod W ∪ {d}
on the one hand, it holds that si0
(note that since ε ∈ W it should be that d (cid:11)= ε), while if
si0 b ≡ sj mod W ∪{d} for some j (cid:11)= i0 + 1 this would imply
that si0 b ≡ sj mod W and thus si0+1 ≡ sj mod W as well.
This latter equality contradicts the property of the OT being
reduced. Hence we conclude that the new OT is not closed
and the algorithm continues as stated above (speciﬁcally it will
introduce si0
b as a new state in S and so on).
We remark that originally, L∗ as described by Angluin
added all preﬁxes of a counterexample in S and thus violated
the reduced table invariant (something that lead to a sub-
optimal number of membership queries). The variant of L∗ we
describe above due to [20] maintains the reduced invariant.
For a target automaton M with n states, the total number
of membership queries required by the algorithm is bounded
by n2(|Σ| + 1) + n log m where m is the length of the longest
counterexample.
B. The Shabhaz-Groz (SG) Algorithm
In [12], Shabhaz and Groz extended Angluin’s algorithm
to the setting of Mealy machines which are deterministic
Transducers without ε-transitions.
The core of the algorithm remains the same: a table
OT will be formed and as before will be based on rows
corresponding to S ∪ S × Σ and columns corresponding to
distinguishing strings W . The table OT will not be a binary
9595
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:12:23 UTC from IEEE Xplore.  Restrictions apply. 
∗.
table in this case, but
instead it will have values in Γ
Speciﬁcally, the partial function T in the SG observation table
is deﬁned as T (s, d) = suﬀ(T (sd),|d|). The rows of T satisfy
the non-equivalence property, i.e., for any s, s(cid:5) ∈ S it holds
that s (cid:11)≡ s(cid:5)
mod W , thus as in the Rivest-Schapire variant of
L∗ each access string corresponds to a unique state in the
hypothesis automaton. Further, provided that Σ ⊆ W , we
have for each s ∈ S, the availability of the output symbol
produced when consuming any b ∈ Σ is given by T (s, b).
In this way a hypothesis Mealy machine can be constructed
in the same way as in the L∗ algorithm. On the other hand,
Shabhaz and Groz [12] contribute a new method for processing
counterexamples described below.
Let z be a counterexample, i.e., it holds that the hypothesis
machine H and the target machine produce a different output
in Γ. Let s be the longest preﬁx of z that belongs to the access
strings S. If s·d = z, in [12] it is observed that they can add d
as well as all of its sufﬁxes as columns in OT . The idea is that
at least one of the sufﬁxes of d will contain a distinguishing
string and thus it can be used to make the table not closed.In
addition, this method of processing counterexamples makes
the set W sufﬁx closed. After adding all sufﬁxes and making
the corresponding membership queries, the algorithm proceeds
like the L∗ algorithm by checking the table for closedness.
The overall query complexity of the algorithm is bounded by
O(|Σ|2n + |Σ|mn2) queries, where n, m, Σ are deﬁned as in
the L∗ algorithm.
IV. LEARNING SYMBOLIC AUTOMATA
In this section we present our algorithm for learning
symbolic ﬁnite automata for general predicate families. Then,
we specialize our algorithm for the case of regular expression
ﬁlters.
A. Main Algorithm
Symbolic ﬁnite automata extend classical ﬁnite automata
by allowing transitions to be labelled by predicate formulas
instead of single symbols. In this section we will describe the
ﬁrst, to the best of our knowledge, algorithm to infer SFAs
from membership and equivalence queries. Our algorithm,
contrary to previous efforts to infer symbolic automata [22]
which required the counterexample to be of minimal length,
works in the standard membership and equivalence query
model under a natural assumption, that the guards themselves
can be inferred using queries.
The main challenge in learning SFA’s is that counterexam-
ples may occur due to two distinct reasons: (i) a yet unlearned
state in the target automaton (which is the only case in the L∗
algorithm), (ii) a learned state with one of the guards being
incorrect and thus, leading to a wrong transition into another
already discovered state. Our main insight is that it is possible
to distinguish between these two cases and suitably adjust
either the guard or expand the hypothesis automaton with a
new state.
Technical Description. The algorithm is parameterized by
a predicate family P over Σ. The goal of the algorithm is
to both infer the structure of the automaton and label each
transition with the correct guard φ ∈ P. Compared to the L∗
algorithm, our learning algorithm, on top of the ability to make
membership and equivalence queries will also require that the
guards come from a predicate family for which there exists a
guard generator algorithm that we deﬁne below.
Deﬁnition 7. A guard generator algorithm guardgen() for
a predicate family P over an alphabet Σ takes as input a
sequence R of pairs (b, q) where b ∈ Σ and q an arbitrary
label and returns a set of pairs G of the form (φ, q) such that
the following hold true:
(Completeness) ∀(b, q) ∈ R ∃φ : (φ, q) ∈ G ∧ φ(b).
(Uniqueness) ∀φ, φ(cid:5), q : (φ, q), (φ(cid:5), q) ∈ G → φ = φ(cid:5).
(Determinism) ∀b ∈ Σ ∃!(φ, q) ∈ G : φ(b).
–