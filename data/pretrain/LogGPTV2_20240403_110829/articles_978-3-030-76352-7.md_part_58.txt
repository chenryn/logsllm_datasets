4 Experimental Result
4.1 Evaluation Methodology
Forevaluation,wefollowedamethodologysimilartotheoneproposedby[9].We
used a large rating dataset, i.e., MovieLense25M with 25M ratings, and filtered
out users who have rated at least 10 relevant items (i.e., items with ratings
equal or higher than 4). This ensured us that each user has a minimum number
of favorite items. Then we randomly selected 4000 users for our experiment. For
eachselecteduser,wechoose2itemswithratingequalorhigherthan4(forming
a favorite set of items). Then we randomly add 500 items not rated by the user
to this set. After that we predict the ratings for all the 502 movies using the
recommender system and order them according to the predicted ratings. For
each 1≤N ≤502, number of hits will be the number of favorite movies appear
in top N movies (e.g. 0, 1 or 2). Assume T is the total number of favorite items
in the test set for all selected users (T =8000 in our case), then:
#hits #hits recall@N
recall@N = and precision@N = = (2)
T N ·T N
In addition to these metrics, we also computed Root Mean Squared Error
(RMSE), i.e., the rating prediction error, and Coverage [38], i.e., the proportion
of items over which the system is capable of generating recommendations [24].
4.2 Experiment A: Exploratory Analysis
In experiment A, we performed a set of exploratory analysis. Due to the space
limit, we focus on reporting some interesting results we observed by analyzing
the time evolution of the audio features over the history of (sound) cinema. For
that, we computed the yearly average of every audio features for the period of
1940 to 2020. Figures1 and 2 illustrate the obtained results. Interestingly, there
8 https://zenodo.org/record/3266236#.Xx7hLPgzako.
372 M. H. Rimaz et al.
are two opposite trends in the evolution of the audio features over time, i.e., a
positive trend (for audio features such as Energy, Danceability, and Tempo
shown in Fig.1), and a negative trend (for audio features such as Liveness,
Acousticness, and Instrumentalness shown in Fig.2). These trends indicate
that while, over the history of cinema, the musics of the movies have become
more energetic with higher tempo (and perhaps more danceable), at the same
time,themusicsarealsolosingtheirliveness,acousticness,andinstrumentalness.
Another interesting observation is that, according to our collected audio fea-
tures, the musics of the newer movies (produced after 2000) have different char-
acteristicscomparedtotheoldermovies(producedbefore2000).Inearlieryears
ofcinema,themusicsofthemoviesillustratemorediversityintermsofouraudio
features.Thiscouldmeanthatcomposershavebeenmakingamoresimilartype
ofmusicfornewermovies.Inaddition,theobservedtrendfornewermoviesgoes
slightly into the opposite direction compared to the older movies (e.g., see the
u-turn in Fig.2-middle, around 2000s). This might be due to the fact that the
music production has encountered a big shift in 2000s with the introduction of
digital composition techniques9. We could not present all figures for the other
audio features, due to space limit. However similar trends have been observed
for them.
0.45
0.45
0.40
0.40
0.35 0.35 ytilibaecnad
ygrene
0.30
0.30
0.25
0.25
0.20
0.20 0.15
1940 1950 1960 1970 1980 1990 2000 2010 2020 1940 1950 1960 1970 1980 1990 2000 2010 2020
Year Year
125
120
115
opmet
110
105
100
1940 1950 1960 1970 1980 1990 2000 2010 2020
Year
Fig.1.TimeevolutionofEnergy(left),Danceability(right),andTempo(bottom)
audio features over history of cinema.
9 https://www.filmindependent.org/blog/know-score-brief-history-film-music/.
AudioLens 373
0.350
0.325
0.300
0.275
0.250 ssenevil
0.225
0.200
0.175
0.150
1940 1950 1960 1970 1980 1990 2000 2010 2020
Year
0.9
0.8
0.8 0.7 ssenlatnemurtsni
ssencitsuoca
0.7 0.6
0.5
0.6
0.4
0.5
0.3
1940 1950 1960 1970 1980 1990 2000 2010 2020 1940 1950 1960 1970 1980 1990 2000 2010 2020
Year Year
Fig.2. Time evolution of Liveness (top), Acousticness (left), and Instrumental-
ness(right)featuresoverhistoryofcinema.TimeevolutionofLiveness(top),Acous-
ticness (left), and Instrumentalness (right) features over history of cinema.
4.3 Experiment B: Recommendation Quality
In experiment B, we evaluated our audio-aware recommendation technique
(AudioLens) and compared it against different baselines, e.g., recommendation
based on other automatic features (i.e., musical key, visual features, and hybrid
features)aswellasrecommendationbasedonmanualtags(seeSect.3.1formore
details). Figure3 and Fig.4 illustrate the results.
In terms of the precision@N, as shown in Fig.3 (left), the best results have
been consistently achieved by AudioLens, i.e., our proposed recommendation
approach based (automatic) audio features. The precision value of AudioLens is
0.0023,0.0023,0.0022,0.0022forrecommendationsizes(N)of5,10,15,and20,
respectively. The second best approach is recommendations based on visual fea-
tures which achieves precision of 0.0017, 0.0018, 0.0019, and 0.0019 for growing
recommendationsizesof5,10,15,and20.Theworstresultshavebeenachieved
forrecommendationbasedon(manual)tagswithvaluesof0.0008,0.0010,0.0011,
and 0.0012 for different recommendation sizes.
IntermsofRecall@N,similarresultshavebeenobserved,asdepictedinFig.3
(right). Again, recommendation based on (automatic) audio features (Audi-
oLens) obtains the best results, visual features are the second best, and again,
the worst results achieved by recommendation based on tags.
In terms of RMSE, presented in Fig.4 (left), our proposed recommendation
technique based on the audio features (AudioLens) achieves superior results
compared to the other features, with RMSE values of 0.83. Recommendation
374 M. H. Rimaz et al.
based on visual features has also obtained relatively good results with RMSE
values of 0.86. The results of the other features were not substantially different
from each other, and indeed, despite the differences in the feature types, they
perform similarly in terms of rating prediction accuracy.
Finally, in terms of Coverage, illustrated in Fig.4 (right), all (automatic)
audio and visual features achieves the best coverage of 100%. This means that
these features can be used to cover the entire item catalog of a recommender
system. This is while recommendation based on tags achieves the worst results,
i.e., coverage of 93%.
Animportantobservationwemadeisthat,recommendationbasedon(auto-
matic)hybridfeatureshasnotachievedasuperiorperformancecomparedtothe
recommendation based on (automatic) audio features. This means that a com-
bining the audio and visual features will not necessarily result in improvement
on recommendation quality. This could be related to the hybridization method,
as we used a simple combination of audio and visual features, while a more
advanced feature fusion method can be expected to enhance these outcomes.
Fig.3. Quality of movie recommendation, based on different content features, w.r.t,
Precision (top) and Recall (bottom)
AudioLens 375
Fig.4. Quality of movie recommendation, based on different content features, w.r.t,
RMSE (top) and Coverage (bottom)
5 Conclusion
This paper addresses the cold start problem by proposing a recommendation
technique based on audio features that can be automatically extracted with no
need for human involvement. These novel features can represent video items
when neither any rating nor any tag is available for a new video item. We have
conducted a preliminary experiments to better investigate the potential power
of these audio features in generating video recommendation and compared the
results against user tags labeled manually. The experiment has been conducted
using our new dataset with novel audio features extracted from more than 9000
movies.Theresultsoftheexperimenthaveshownconsistentsuperiorityofthese
audiofeaturesingeneratingrelevantrecommendationandhenceeffectivelydeal-
ing with the cold start problem.
Our plans for future work includes building a mobile recommender system
with a specific design that adopts novel interface elements [8] for explaining
the audio features to the user. We also plan to elicit user-generated video con-
tent from other video sharing social networks (e.g., Instagram). We also plan to
obtaintheimplicitpreferencesofmusiclistenersthroughtheirfacialappearance
using recent findings [40] that have shown correlation between peoples musical
preferences and their facial expressions [41].
376 M. H. Rimaz et al.
References
1. Adomavicius, G., Tuzhilin, A.: Toward the next generation of recommender sys-
tems:asurveyofthestate-of-the-artandpossibleextensions.IEEETrans.Knowl.
Data Eng. 17(6), 734–749 (2005). https://doi.org/10.1109/TKDE.2005.99
2. Aggarwal, C.C.: Content-based recommender systems. In: Aggarwal, C.C. (ed.)
Recommender Systems, pp. 139–166. Springer, Cham (2016). https://doi.org/10.
1007/978-3-319-29659-3 4
3. Anderson, C.: The Long Tail. Random House Business, New York (2006)
4. BakhshandeganMoghaddam,F.,Elahi,M.:Coldstartsolutionsforrecommenda-
tionsystems.BigDataRecommenderSystems,RecentTrendsandAdvancesIET
(2019)
5. Brezeale,D.,Cook,D.J.:Automaticvideoclassification:asurveyoftheliterature.
IEEE Trans. Syst. Man Cybern. Part C Appl. Rev. 38(3), 416–430 (2008)
6. Cantador, I., Bellog´ın, A., Vallet, D.: Content-based recommendation in social
taggingsystems.In:ProceedingsoftheFourthACMConferenceonRecommender
Systems, pp. 237–240. ACM (2010)
7. Cantador, I., Konstas, I., Jose, J.M.: Categorising social tags to improve
folksonomy-based recommendations. Web Semant. Sci. Serv. Agents World Wide
Web 9(1), 1–15 (2011)
8. Cremonesi,P.,Elahi,M.,Garzotto,F.:Userinterfacepatternsinrecommendation-
empowered content intensive multimedia applications. Multimedia Tools Appl.
76(4), 5275–5309 (2016). https://doi.org/10.1007/s11042-016-3946-5
9. Cremonesi, P., Koren, Y., Turrin, R.: Performance of recommender algorithms on
top-n recommendation tasks. In: Proceedings of the Fourth ACM Conference on
Recommender Systems, pp. 39–46 (2010)
10. De Gemmis, M., Lops, P., Semeraro, G., Basile, P.: Integrating tags in a seman-
tic content-based recommender. In: Proceedings of the 2008 ACM Conference on
Recommender Systems, pp. 163–170. ACM (2008)
11. Deldjoo, Y., Constantin, M.G., Eghbal-Zadeh, H., Ionescu, B., Schedl, M.,
Cremonesi, P.: Audio-visual encoding of multimedia content for enhancing movie
recommendations.In:Proceedingsofthe12thACMConferenceonRecommender
Systems, RecSys 2018, New York, NY, USA, pp. 455–459. Association for Com-
puting Machinery (2018). https://doi.org/10.1145/3240323.3240407
12. Deldjoo, Y., Elahi, M., Cremonesi, P., Garzotto, F., Piazzolla, P., Quadrana, M.:
Content-based video recommendation system based on stylistic visual features. J.
Data Semant., 1–15 (2016)
13. Di Noia, T., Mirizzi, R., Ostuni, V.C., Romito, D., Zanker, M.: Linked open data
to support content-based recommender systems. In: Proceedings of the 8th Inter-
national Conference on Semantic Systems, pp. 1–8. ACM (2012)
14. Elahi,M.:Empiricalevaluationofactivelearningstrategiesincollaborativefilter-
ing. Ph.D. thesis, Ph.D. Dissertation. Free University of Bozen-Bolzano (2014)
15. Elahi, M., Braunhofer, M., Gurbanov, T., Ricci, F.: User preference elicitation,
rating sparsity and cold start (2018)
16. Elahi, M., Hosseini, R., Rimaz, M.H., Moghaddam, F.B., Trattner, C.: Visually-
aware video recommendation in the cold start. In: Proceedings of the 31st ACM
Conference on Hypertext and Social Media, pp. 225–229 (2020)
17. Elahi,M.,Ricci,F.,Rubens,N.:Asurveyofactivelearningincollaborativefiltering
recommender systems. Comput. Sci. Rev. 20, 29–50 (2016)
AudioLens 377
18. Enrich, M., Braunhofer, M., Ricci, F.: Cold-start management with cross-domain
collaborative filtering and tags. In: Huemer, C., Lops, P. (eds.) EC-Web 2013.
LNBIP, vol. 152, pp. 101–112. Springer, Heidelberg (2013). https://doi.org/10.
1007/978-3-642-39878-0 10
19. Ercegovac,I.R.,Dobrota,S.,Kuˇsˇcevi´c,D.:Relationshipbetweenmusicandvisual
art preferences and some personality traits. Empirical Stud. Arts 33(2), 207–227
(2015). https://doi.org/10.1177/0276237415597390
20. Gedikli, F., Jannach, D.: Improving recommendation accuracy based on item-
specific tag preferences. ACM Trans. Intell. Sys. Technol. (TIST) 4(1), 11 (2013)
21. Gillick, J., Bamman, D.: Telling stories with soundtracks: an empirical anal-
ysis of music in film. In: Proceedings of the First Workshop on Storytelling,
New Orleans, Louisiana, pp. 33–42. Association for Computational Linguis-
tics,June2018.https://doi.org/10.18653/v1/W18-1504.https://www.aclweb.org/
anthology/W18-1504
22. Harper, F.M., Konstan, J.A.: The movielens datasets: history and context. ACM
Trans. Interact. Intell. Syst. 5(4) (2015). https://doi.org/10.1145/2827872
23. Hazrati, N., Elahi, M.: Addressing the new item problem in video recommender
systems by incorporation of visual features with restricted Boltzmann machines.
Expert Syst. 38, e12645 (2020)
24. Herlocker,J.L.,Konstan,J.A.,Terveen,L.G.,Riedl,J.T.:Evaluatingcollaborative
filteringrecommendersystems.ACMTrans.Inf.Syst.22(1),5–53(2004).https://
doi.org/10.1145/963770.963772
25. Hornick,M.F.,Tamayo,P.:Extendingrecommendersystemsfordisjointuser/item
sets: the conference recommendation problem. IEEE Trans. Knowl. Data Eng. 8,
1478–1490 (2012)
26. Hu, W., Xie, N., Li, Zeng, X., Maybank, S.: A survey on visual content-based
videoindexingandretrieval.Trans.Sys.ManCyberPartC41(6),797–819(2011).
https://doi.org/10.1109/TSMCC.2011.2109710
27. Jannach, D., Zanker, M., Felfernig, A., Friedrich, G.: Recommender Systems: An
Introduction. Cambridge University Press, Cambridge (2010)
28. Liang, H., Xu, Y., Li, Y., Nayak, R.: Tag based collaborative filtering for recom-
mender systems. In: Wen, P., Li, Y., Polkowski, L., Yao, Y., Tsumoto, S., Wang,
G.(eds.)RSKT2009.LNCS(LNAI),vol.5589,pp.666–673.Springer,Heidelberg
(2009). https://doi.org/10.1007/978-3-642-02962-2 84
29. Lika, B., Kolomvatsos, K., Hadjiefthymiades, S.: Facing the cold start problem in
recommender systems. Expert Syst. Appl. 41(4), 2065–2073 (2014)
30. Lops,P.,deGemmis,M.,Semeraro,G.:Content-basedrecommendersystems:state
of the art and trends. In: Ricci, F., Rokach, L., Shapira, B., Kantor, P.B. (eds.)
Recommender Systems Handbook, pp. 73–105. Springer, Boston (2011). https://
doi.org/10.1007/978-0-387-85820-3 3
31. Melchiorre,A.B.,Schedl,M.:Personalitycorrelatesofmusicaudiopreferencesfor
modelling music listeners. In: Proceedings of the 28th ACM Conference on User