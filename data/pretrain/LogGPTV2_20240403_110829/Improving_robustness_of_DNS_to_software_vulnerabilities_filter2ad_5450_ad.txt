10
practice, these small communities are merged into what is colloquially called the “death
star” cluster: a large, noisy cluster that contains many small communities.
In Chapter 3, we propose a new spectral expansion algorithm, which uses spectral clus-
tering, to analyze the impression fraud problem of the botnet TDSS/TDL4. In Chapter 5,
we also analyze the robustness of spectral clustering in adversarial settings.
2.1.4
node2vec
Contrary to the strong homophily assumption of community detection and spectral cluster-
ing, node2vec [32] has the advantage of balancing homophily and structural equivalence
in its embeddings. For example, vertices that are sink nodes will have similar embeddings.
node2vec generates embeddings of vertices by optimizing the sum of the log likelihood of
seeing the network neighborhood given a vertex v, for all vertices on the graph:
(cid:88)
max
f
log P (NS(v)|f (v))
(2.1)
Where f (v) is the embedding of vertex v, NS(v) represents the network neighborhoods
of v with a series of vertices obtained by the sampling strategy S. node2vec proposes a
sampling strategy by random walks starting from every vertex on the graph with the fol-
lowing parameters: 1) number of walks from each vertex, 2) length of each walk, 3) prob-
ability to return to the same vertex (Breadth First Search), and 4) probability to explore
out to further vertices (Depth First Search). Once the walk samples have been obtained,
node2vec uses a tunable neighborhood size to get the neighborhood of vertices. For exam-
ple, a walk with length 5 {v1, v2, v3, v4, v5} generates the following neighborhoods with
size 3: N (v1) = {v2, v3, v4}, N (v2) = {v3, v4, v5}.
In order to compute the embeddings given f (v), Equation 2.1 is factorized as a product
of the conditional probability of each vertex in the neighborhood based on the conditional
independence assumption. Each underlying conditional probability is deﬁned as a sigmoid
function, and the embeddings are learned by stochastic gradient descent (SGD) with neg-
11
Figure 2.1: A brief overview of online advertising ecosystem.
ative sampling optimization. Effectively, node2vec learns embeddings in a fashion similar
to word2vec [43] but does not use skip-grams. Attackers can target the neighborhood size
and sampling parameters to encourage their vertices to be under-sampled and thus split into
multiple noisy clusters. In Chapter 5, we evaluate node2vec in adversarial settings.
2.2 Online Advertising Ecosystem
Our study in Chapter 3 and Chapter 4 are from two different vantage points in the online
advertising ecosystem. In Chapter 3, we are from vantage point V1 (Figure 2.1), which is
at the edge of the ad ecosystem, between infected machines and DNS/HTTP servers they
connect to. In Chapter 4, we observe the ad bidding requests within the ad ecosystem at
vantage point V2, between ad exchanges and a DSP. To explain that, we describe the ad
ecosystem in this section.
Figure 2.1 gives an overview of the online advertising ecosystem. There are three major
components in the ad ecosystem: supplier, demander, and the marketplace. Suppliers are
the publishers who provide ad inventories (e.g., spaces in the webpage), to show ads. Each
time an ad is shown is called an impression. As “demanders”, advertisers wish to secure the
optimal ad inventories to reach the most relevant audiences. Various entities in the market
place connect the demand the supply, which we use illustrate next.
When a user visits a publisher webpage (step 1, Figure 2.1), elements of the webpages
are loaded (step 2), during which the iFrame representing the ad inventory of the webpage
12
UserPublisherAd ServerAd ExchangeAd NetworkDSPAdvertiser3456V2Devices13789101112Logs clickLogs impressionWeb request12Javascript responseBrowserV1requests from the ad server to display an ad (step 3). The ad server delivers the ad unit
from an ad network (step 4), and also report any ad metrics available so a payment can take
place. Each ad network has its own group of publishers, and it can also sell ad inventories
to an ad exchange (step 5). If an ad request cannot be fulﬁlled, it will be further relayed
to a Demand Side Platform provider (DSP) (step 6), and advertisers working with the DSP
can purchase the impression. The advantage of using a DSP is that advertisers will have
access to multiple ad exchanges. The advertisers can target users of a speciﬁc proﬁle [44,
45], certain types of publishers, keywords [46], time of the day, ﬂexible daily budget, etc.
The DSP, ad exchanges, and ad networks consolidates this information and shows the
optimal ad back to the publisher’s page (step 7 to 10). An impression is therefore fulﬁlled
and logged. Impressions are often charged according the CPM (Cost Per Mille, or cost
per thousand impression). If the ad is clicked, the ad server will log the click (step 11),
and redirect the user (step 12) to the page of the advertiser (step 13). In such an event,
the advertiser is charged by the click. The CPC (Cost Per Click) varies according to the
keywords of the webpage and the user category.
Publishers can syndicate the ads to other downstream publishers. In turn, the syndicated
publishers can subsyndicate the ads further to other publishers. Syndication enables the ads
to reach a wider audience. Thus, there can be several redirections among publishers before
ad request reaches ad server (step 3).
Omitted from Figure 2.1 are a number of quality control actors who interact with mul-
tiple phases of the impression ﬂow. Such actors include ad veriﬁcation companies (e.g., In-
tegral Ad Sciences), fraud detection companies (e.g., ForensIQ), demographic veriﬁcation
companies (e.g., Nielsen), URL classiﬁcation companies who provide context for topical
ad selection (e.g., Peer39), and ad blocking companies (e.g., Ghostery).
Entities in the ad ecosystem perform fraud detection independently. The technical de-
tails are not disclosed in public documents in order to avoid evasion by the fraudsters [47,
48, 49]. As a countermeasure for fraud, ad networks employ smart pricing to normalize
13
CPC (Cost-Per-Click) based on distribution of conversion rates across all publishers [50,
48]. Different actions can be considered as conversion instead of a simple click or im-
pression, such as product news subscription, purchase activity, ﬁlling out a questionnaire,
etc. If trafﬁc from a publisher results in a low conversion rate compared to other publish-
ers serving similar ads, the ad network may use smart pricing to reduce the CPC used to
calculate payment to that publisher. The drawback of the smart pricing policy is that ad-
vertisers have to share the conversion data with the ad networks. The conversion data are
often considered sentitive information and therefore advertisers typically are not willing to
share them. In practice, ad networks take many factors into account that would indicate the
probability for a conversion [51]. No details about these factors are revealed. Nevertheless,
since the conversion data are limited, attackers have been able to get payments based on
CPC even after smart pricing discounts [52].
While smart pricing could make fraudulent clicks less proﬁtable, this is not the case
with fraudulent impressions. Only recently, Google and IAB announced the Ad “Viewa-
bility” standard in an effort to combat invalid impressions: at least 50% of ad pixels need
to be in view for a minimum of one second [4, 3]. Advertisers can now choose whether to
only bid on viewable impressions in the Real Time Bidding process [53]. However, it is
still a nontrivial problem to correctly measure viewability.
14
FINANCIAL LOWER BOUNDS OF ONLINE ADVERTISING ABUSE
CHAPTER 3
3.1 Motivation
Many researchers have observed a shift in how botnets are monetized [54], away from
traditional spam and bank fraud, towards advertising abuse [55]. Large botnets such as
Kelihos [56] and Asprox have moved to monetization methods that abuse the online ad
ecosystem. Unlike bank fraud and other types of abuse, impression and click fraud are
“low risk/high reward” for botmasters, given the inherent difﬁculty in ad abuse attribution
due to the complexity of the ad ecosystem [57].
To date, the evidence about the amount of ad-abuse attributed to modern botnets is
sporadic, mainly because of measurement challenges. Studying the monetization compo-
nents of botnets in a controlled environment (e.g., honeypots, dynamic malware analysis)
requires researchers to actively engage in the abuse, which poses ethical challenges. In
addition, dynamic malware analysis methods often fall short as botnets move their mon-
etization components away from binaries [58, 52], and instead deliver them as separate,
non-executable add-on modules. Such drawbacks point to the need for an efﬁcient passive
analysis system that can analyze the long-term monetization campaign separately from the
traditional infection, Command and Control (C&C) and malware update methods.
To enable efﬁcient, independent and passive analysis of the long-term ad-abuse caused
by botnets, we introduce a novel Ad-abuse Analysis System (A2S). A2S leverages spectral
clustering methods on passive DNS datasets to identify the network infrastructure (domain
names and IP addresses) the botnet under inspection uses to perform ad-abuse. It also em-
ploys sinkhole datasets to estimate lower bounds of ﬁnancial loss caused by the fraudulent
impressions generated by the botnet.
15
Using four years of long-term network datasets, A2S helped us estimate the scale of
the ad-abuse potentially inﬂicted on advertisers from one of the most notorious botnets
in history — TDSS/TDL4. Our conservative estimation shows that TDSS/TDL4 caused
ﬁnancial damage of at least $346 million in total; roughly $340 thousand per day. Further-
more, this estimate only includes less than 15% of the botnet’s population, which suggests
that the overall ﬁnancial loss of advertisers caused by all bots is likely higher.
While these numbers may appear large, they remain an underestimation of the overall
abuse due to the choices in our measurement methodology. We must emphasize that at
every step of our analysis, we err on the side of being overly conservative, as we are inter-
ested in lower bounds. This helps us establish as conservative of a lower bound as possible,
using aggressive, empirically driven ﬁltering and relying on the lowest possible estimates
for constants used in our ﬁnancial abuse calculation. We intentionally exclude highly likely
TDSS/TDL4 domains in exchange for a safer lower bound estimate.
We start by describing the necessary background information in Section 3.2. Next, we
describe the details of our Ad-abuse Analysis System in Section 3.3. In Section 3.4, we de-
scribe the datasets used to evaluate the ad-abuse component of the TDSS/TDL4 botnet. We
present the analysis of the botnet in Section 3.5, and two ad-abuse reports in Section 3.6.
We discuss ground truth and accuracy of the analysis in Section 3.7. Related work are dis-
cussed in Section 3.8. We conclude with Section 3.9 and the takeaways from this Chapter.
3.2 Background
3.2.1 Botnets and Sinkholes
In the Domain Name System (DNS) [59, 60], domain names are composed of labels, sep-
arated by periods, which correspond to namespaces in a hierarchical tree structure. Each
label is a node, and the root label (.) is root of the tree. The hierarchical concatenation of
nodes creates a fully qualiﬁed domain name. A zone is a collection of nodes that constitute
a subtree with DNS authority name servers responsible for its content. Figure 3.1 illustrates
16
Figure 3.1: A high level overview of DNS resolution (1-8), the sinkholing processes (A)
and the points where ad-abuse can be observed (B and C).
a typical resolution process. It begins with a stub resolver issuing a domain name resolution
request for a domain, example.com, to the local recursive DNS server (RDNS) (see step
1, Figure 3.1). In the event that the RDNS does not have the resolution answer in its cache,
it will begin an iterative process to discover it. The RDNS will iteratively “walk” the DNS
hierarchy, starting from root server (steps 2 and 3), to the next level of effective top-level
domain (TLD) server (steps 4 and 5), and down to the authority name server (ANS) for
the requested zone (steps 6). Once the RDNS receives (step 7) the authoritative mapping
between the requested domain names and its corresponding answer (e.g., IP address) from
the authority, it forwards the answer back to the stub resolver (step 8).
After a command and control (C&C) domain for a botnet is resolved, the next step
is a connection attempt (e.g., HTTP GET) from the stub to the C&C server. Network
administrators and security researchers often take over such C&C domain names to change
their DNS setting, effectively making them point to a new location. This is commonly
known as “sinkholing” a domain name [61].
If example.com is sinkholed, the stub
resolver will establish any future C&C connections to the sinkhole (step 9, Figure 3.1)
rather than the adversary’s C&C server.
In addition to sinkholing a domain’s A/AAAA record, one can also sinkhole the ANS
that serves it. For instance, example.com can be sinkholed by changing the ANS record
17
Stub Resolver. (Root Server)Recursive DNSServercom.(TLD Server)example.com.(Authority Name Server)DNS Sinkhole12345678The Ad EcosystemHTTP SinkholeACB(or)9to a server under the control of the sinkholing party (e.g., law enforcement or security
researchers). Such an action would have the following result: during the DNS lookup chain
in Figure 3.1, after steps 1 to 5, the recursive DNS server will ask the new DNS sinkhole
server controlled by the sinkholing party about the authoritative answer for the domain
name. Sinkholing both the domain name and the ANS server is a common practice in the
security community as it provides telemetry from both the DNS resolution and network
communication planes of the threat being sinkholed.
Attackers often change C&C domains to avoid sinkholing. Domain name generation
algorithms (DGAs) [62, 52] can be used to rapidly update the C&C domains to remain agile
against sinkholing efforts. A DGA can be implemented client-side in the malware sample
itself, or server-side in the C&C server. Intuitively, client-side DGAs can be reverse engi-
neered from the malware sample. Unfortunately, server-side DGAs are much more difﬁcult
to understand since the server computes and pushes new C&C domain conﬁgurations to the
bots. Reverse engineering requires obtaining the C&C server code, which is often heavily
protected by the author. However, monitoring trafﬁc from infected hosts guarantees the
observation of C&C domain changes.
3.2.2 Observing Ad-abuse In Local Networks
To understand where and what a network administrator can monitor, we need to examine
the typical life cycle of an infected host. First, the malware looks up the IP address of the
C&C domain (point C in Figure 3.1). Second, it contacts the C&C server to get commands
for doing impression and click fraud (point A in Figure 3.1). Next, the malware attempts
to execute the commands by interacting with the ad ecosystem (point B in Figure 3.1).
Stealthy malware carries out these tasks by blending in with users’ normal web browsing
activities in order to evade anti-abuse detection within the ad ecosystem. Additionally,
the malware often reports back to the botmaster various byproducts from the monetization
activities (e.g., user’s search history) for bookkeeping of the monetization campaign.
18
Typical egress monitoring functionality can be used to observe different aspects of ad-
abuse. Administrators can observe interaction between infected hosts and the Internet in-
frastructure that supports the monetization campaign (points A, C ), or between infected
hosts and the ad ecosystem (point B in Figure 3.1). From the network’s point of view, this
observation takes the form of DNS resolutions (i.e., for the domains facilitating ad-abuse
from point C in Figure 3.1) and any application-layer C&C communications between local
victims and the ad ecosystem (point B in Figure 3.1). We select observation points A and
C in Figure 3.1, so we can mine sinkhole and DNS datasets. Points A and C correspond to
the vantage point V1 in Figure 2.1, Section 2.2. We should also note that HTTP connections
can be observed for the sinkholed domain names (point A in Figure 3.1). The sinkholing
party did not return any commands to bots. Therefore, the communications to the sinkhole
did not, at any point, reach the ad ecosystem. This means that our efforts to study the bot-
net did not contribute any additional abuse to the advertisers and other parts of the online
advertising ecosystem.
3.3 Ad-abuse Analysis System
In this section we introduce the Ad-abuse Analysis System (A2S, Figure 3.2) that allows
administrators to systematically analyze ad-abuse in their networks. The goal of the system
is to provide a detailed analysis of the Internet infrastructure that supports ad-abuse mon-
etization. Such information helps administrators to independently (1) estimate the level of
ad-abuse that victims in the local networks contributed to the entire ad ecosystem and (2)
obtain a set of domain names and IPs that can be used for network policy actions. Network
administrators can take action against the monetization component of the botnet. If adver-
saries cannot monetize infected hosts in a network, the hosts in the network becomes less
appealing to compromise.
The system consists of three logical components: (i) the necessary datasets for its op-
eration, (ii) a module to link sinkholed network trafﬁc with long-term passively collected
19
Figure 3.2: Overview of the Ad-abuse Analysis System (A2S).
DNS datasets, and (iii) a module to identify additional ad-abuse domains using passive
datasets. We begin by providing an overview of A2S.
3.3.1 System Overview
The ﬁrst input of A2S is ground truth C&C domains obtained by either external threat
reports or manual analysis of a particular threat (Step (1), Figure 3.2). These reports are
added to our knowledge base, and act as input for two different modules: the DNS Ad-
abuse Rate Module (Step (2)) and the Spectral Expansion Module (Step (3)).
The DNS Ad-abuse Rate Module estimates how many ad-abuse events, i.e., C&C
connections requesting for impression or click fraud commands, are typically triggered
after a single DNS resolution request for any ad-abuse domain (Step (4)). This can be
achieved by “taking-over” a small portion of such ad-abuse C&C domain names for a
period of time. The takeover can be done by traditional sinkhole methods or commonly
used walled garden policy techniques [63] at the recursive DNS level and perimeter egress
points of a network.
The Spectral Expansion Module identiﬁes a set of domain names that have been used
20
ReportsPassive DNS DatasetsExternal Threat IntelligenceSinkhole DatasetsInfrastructure ReportFinancial Abuse ReportKnowledge BaseSpectral Expansion ModuleDNS Ad-abuse Rate Module(1)(2)(4)(3)(5)(6)(7)Ad-abuse Analysis System by the ad-abuse campaign historically. We assume that infected hosts contact both known
and unknown ad-abuse domains and these domains share Internet infrastructure. We com-