同时会具备交易查询和客户查询权限，当对应的业务部门涉及到对应职能时，将
该角色应用到业务部门即可。
当Sentry授权完成后，会对应的更新HDFS上的ACL权限。同样的，这样的
操作只能由一个管理员账号完成，需要建立统一的数据管理部门进行统一管理。
针对基于角色的授权模式，建议先分析当前系统中可能存在的数据访问模式，
将这些模式进一步整合成为系统角色。对应的业务部门建立以后，可以直接将对
应的数据访问权限给予用户组，不需要逐表或数据库进行操作。同样的，这里建
议建立业务组与用户组的对应，一个业务组内包含不同的用户组应，对不同的用
户组赋予不同的角色，例如管理员组具有相当于能够同事具备数据写入、读取的
角色，而用户组一般为数据读取角色。
5.6 平台自监控
运维平台每个组件都支持分布式部署，整体的部署架构较为复杂， 因此系
统本身的稳定性尤为重要，当系统本身出现异常或者性能问题时，需要及时告警
以及自动调整，平台自检的方面包含：通过心跳机制收集的各组件的基本状态，
通过流量监控收集每个组件的负荷，当单个节点出现故障时，其上下游节点会自
动切换到其他节点，确保系统可以继续对外提供服务。
同时，用户可以对平台内的每个服务器的硬件资源进行监控，可以以集群组
的方式监控同一集群内的所有服务器的状况，能提供包括并不局限于以下内容
类别 监控指标
服务器组的总的资源利用情况 CPU计算总的利用率
内存利用率
总的磁盘空间
磁盘总的使用空间
磁盘总的剩余空间
磁盘总的IO吞吐
单台服务器的资源利用情况 CPU计算总的利用率
CPU每个core的利用率
内存利用率
总的磁盘空间
磁盘总的使用空间
磁盘总的剩余空间
每个磁盘的磁盘空间
每个磁盘的使用空间
每个磁盘的剩余空间
磁盘IO的吞吐
网络吞吐
平台除了可以监控硬件及 OS 之上的服务以外，还可以对以下大数据平台服
务提供监控和报警：
 数据流的采集状态(采集 -> 队列 ->预处理 -> 入库)
 采集数据量监控（显示当天实时数据，历史数据以日为最小单位的时间
序列显示）
 各个分布式作业调度服务状态（如 Spark 内存作业调度服务,
SparkStreaming流处理作业调度情况）
 HDFS服务状况
 YARN资源管控状况
 Hbase NoSQL数据库服务
 Kafka消息队列状况
 ElasticSearch 资源及服务状况
第 章智能运维场景展示
6
本章整体描述了在本次光大证券的课题研究中，构建智能运维体系的成果展
示。
6.1 运维数据的展示
平台 WEB 服务提供日志展现、数据可视化，支持各种统计功能及图表展现，
实现流畅的图形用户交互。展示时间折线图、条形图、饼状图等，让数据分析更
直观。
集群主要是多主结构，各个节点完全平行，前端支持Nginx作为负载均衡器，
增强了系统跨平台、快速部署等特性。
用户在前台Web搜索界面输入搜索语法后，发送给前置模块Frontend（做语
法合规检查），Frontend通过Nginx将命令均衡转发到SPL服务器集群模块，SPL
服务器集群从搜索引擎中抽取相关索引数据，进行计算合并后，返回给用户前端
展示。前端支持全文检索、SPL统计语言分析查询指定时间范围内的日志。
本次落地场景将以O32应用系统为例进行说明展示，平台收集了核心数据库
性能指标、数据库alert日志、天旦交易指标、中间件主机CPU使用率、中间件
日志、应用日志和网管数据。
通过收集数据库 alert 日志，可以快速查询 ORA、ERROR 等报错信息，并进
行关键字高亮显示，同时通过错误关键字进行及时告警。
通过收集O32中间件日志，抽取日志关键字段后，用户可以点击展现的字段
值实现日志过滤，可以快速查询中间件等运行信息。并通过SPL查询实时保存成
趋势图和报表。
强大的SPL功能，支持新建字段、复杂的统计语句以及强大的关联搜索功能，
并且同时可以支持保存搜索语句，保存后可直接调用或共享给其他用户。通过交
易委托申报号聚合交易步骤。
6.2 智能场景的展示
本次落地场景将以O32应用为例进行说明展示，通过对自营O32的关键代码
功能耗时进行单指标异常检测，结合其他关键KPI以及日志，进行故障原因定位。
6.2.1 场景介绍
 发现问题 - 主动监控
通过对业务量，响应时间，数据库指标、操作系统关键KPI等单个KPI进行异
常检测，来监控指标是否异常；
通过对海量日志无监督学习，识别日志的模板序列，以及特征变量的分布来
检测日志中是否存在异常
 定位问题 - 故障定位
通过分析故障时的所有机器指标的关联性以及相似性，来定位问题发生的节
点以及相应指标
 分析问题 - 业务/机器指标的关联分析
通过关联业务和机器指标，将业务指标和机器指标进行关联分析，端到端的
分析当业务发生故障时，机器指标的是否存在问题，日志是否存在问题。
6.2.2 发现问题 - 单指标异常检测
6.2.2.1 算法支持
对于一条时间序列，首先对其特征进行表述，分为：
 通过算法自动找到时间序列的周期
 是否具有向上/向下的趋势性
 周期偏移情况
 数据抖动程度
 上下界极限值
 是否可以用阈值的方法以及阈值采用多少合适
之后根据时间序列的特征，计算资源的分配以及数据的时间来合理选用不同
的模型组合来训练并生成对应的模型，算法包括：
 变分自编码器
 渐进梯度回归树
 差分指数滑动平均
 极值理论
 周期性中值检测
6.2.2.2 场景展示
通过对 O32 系统的响应时间、交易量、数据库指标等进行单指标异常检测，
准确发现，11月13号真实故障。
单指标异常检测的相关算法应该具有如下几项核心能力：
 拥有变更处理机制应对变更（如系统升级、配置修改、业务变化）导致的KPI
模式剧变，之前模型失效，产生大量误报。
 检测到突变后，提供选项供管理员确认是否为变更导致，如果确认则能快速
利用最新数据建立模型，检测未来数据，防止误报
 利用周期性检测算法，识别历史重复性行为，并能处理跑批时间偏差（如每
天有几十分钟误差）
 自动检测到KPI历史上突增（可能是跑批），并判断的突增是否具备重复性，
确定重复性后检测突增时段的突增消失。
 自动识别指标的周期性，当指标不具备明显周期性时，采用不同的检测方法，
建立极限阈值，更合理检测此类指标异常
 自动根据日历数据确定特殊日（春节等节假日），这些天因为违反历史周期
性，采用非周期检测器，只利用局部数据进行检测。
 拥有简单易操作的检测敏感度调节，并实时看到调节效果。
6.2.3 发现问题–日志异常检测
6.2.3.1 算法支持
通过对 3-7 天的日志进行处理分析并建立模型，学习其规律后，系统可以在
线地对日志进行处理并分类接入Elasticsearch平台。步骤如下：
 对每条日志进行预处理分词，将时间、数字、IP地址、路径等变量和其他词
语区分开来。
 利用FT-Tree对其进行模板学习，提取日志的公共部分，并将分析结果作为
标签实时插入Elasticsearch。
6.2.3.2 场景展示
通过对数据库日志、应用以及中间件的日志进行分析，通过FT-Tree算法进
行模板提取及特征变量提取，根据日志模板数量的变化以及特征变量分布情况的
变化，判断日志中是否存在异常，通过异常摘要的形式提供出来。
1）日志异常摘要：通过对O32应用日志分析得出11月13号日志中所存在的问题
2）主要通过模板数量的变化以及变量分布情况的变化来确定日志中是否存在异
常，下图为O32系统UTODB的日志频率分布
通过放大，得出11月13号的日志频率出现异常
3）光从日志的数量上，不一定能够发现异常，也不一定能够合理解释异常的真
实原因。例如下图中，系统将平日训练时产生的日志各类变量分布（左4）和异
常时间段产生的同类型日志变量分布（右4）作出对比。通过对比可以从日志的
内容层面，对异常给出更加合理详尽的解释。例如下图中很明显地，交易记录类