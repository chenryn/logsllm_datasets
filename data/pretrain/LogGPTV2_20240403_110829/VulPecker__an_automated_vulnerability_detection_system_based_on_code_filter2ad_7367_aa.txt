title:VulPecker: an automated vulnerability detection system based on code
similarity analysis
author:Zhen Li and
Deqing Zou and
Shouhuai Xu and
Hai Jin and
Hanchao Qi and
Jie Hu
VulPecker: An Automated Vulnerability Detection System
Based on Code Similarity Analysis
Zhen Li†§, Deqing Zou†∗ , Shouhuai Xu‡, Hai Jin†, Hanchao Qi†, Jie Hu†
† Services Computing Technology and System Lab, Big Data Technology and System Lab, Cluster and Grid
Computing Lab, School of Computer Science and Technology
Huazhong University of Science and Technology, Wuhan, 430074, China
§School of Computer Science and Technology, Hebei University, Baoding, 071002, China
‡ Department of Computer Science, University of Texas at San Antonio, San Antonio, TX 78249, USA
PI:EMAIL
ABSTRACT
Software vulnerabilities are the fundamental cause of many
attacks. Even with rapid vulnerability patching, the prob-
lem is more complicated than it looks. One reason is that
instances of the same vulnerability may exist in multiple
software copies that are diﬃcult to track in real life (e.g.,
diﬀerent versions of libraries and applications). This calls
for tools that can automatically search for vulnerable soft-
ware with respect to a given vulnerability. In this paper, we
move a step forward in this direction by presenting Vulnera-
bility Pecker (VulPecker), a system for automatically detect-
ing whether a piece of software source code contains a given
vulnerability or not. The key insight underlying VulPecker
is to leverage (i) a set of features that we deﬁne to charac-
terize patches, and (ii) code-similarity algorithms that have
been proposed for various purposes, while noting that no
single code-similarity algorithm is eﬀective for all kinds of
vulnerabilities. Experiments show that VulPecker detects 40
vulnerabilities that are not published in the National Vulner-
ability Database (NVD). Among these vulnerabilities, 18 are
not known for their existence and have yet to be conﬁrmed
by vendors at the time of writing (these vulnerabilities are
“anonymized” in the present paper for ethical reasons), and
the other 22 vulnerabilities have been “silently” patched by
the vendors in the later releases of the vulnerable products.
CCS Concepts
•Security and privacy → Software security engineer-
ing;
Keywords
Vulnerability detection, code similarity, vulnerability signa-
ture
∗Corresponding author.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
ACSAC ’16, December 05-09, 2016, Los Angeles, CA, USA
c⃝ 2016 ACM. ISBN 978-1-4503-4771-6/16/12. . . $15.00
DOI: http://dx.doi.org/10.1145/2991079.2991102
1.
INTRODUCTION
It is diﬃcult to patch all vulnerabilities in software sys-
tems because of code reuse, namely that a vulnerability may
exist silently in multiple software programs without being
adequately tracked. This is a manifestation of what may
be called the vulnerability prevalence problem. Examples
are abundant: the same webpage rendering engine is used
by Safari and Chrome, the same Flash libraries are used by
Adobe Reader and Adobe Air, and Adobe Reader may be
included in printer drivers [22]. It is also not surprising to
see unpatched code clones in operating systems [13].
The vulnerability prevalence problem cannot be solved
simply by using multiple patch management mechanisms,
because they often do not cover all vulnerability instances.
While it may sound simple to track code reuse, it is actu-
ally unmanageable because of the large number of programs.
This can be witnessed by the fact that despite the presence
of 13 automated patching mechanisms, at least 86% median
fraction of computers are not patched at the time exploits
are available [22].
One solution to the vulnerability prevalence problem is to
automatically identify all vulnerable executables in a com-
puter. This turns out to be diﬃcult.
In this paper, we
address an alternate problem:
Source code vulnerability detection problem: Given
a vulnerability and the source code of a target
program, how can we automatically detect whether
the program contains the vulnerability or not? If
it does, what is the location of the piece of vul-
nerable code?
Our contributions. We address the source code vulner-
ability detection problem by presenting Vulnerability Pecker
(VulPecker), a system for automatically detecting whether
a program contains a given vulnerability or not. Such a
solution needs to deal with two challenges. First, there is
no readily available dataset for this kind of research. This
is so despite that vulnerability-related databases, such as
the National Vulnerability Database (NVD) [2] and Open
Sourced Vulnerability Database (OSVDB) [3], have become
publicly available. Though several studies [21, 24] have built
databases for mapping Common Vulnerabilities and Expo-
sures number or identiﬁers (CVE-IDs) to commits in soft-
ware revision, where each commit contains a diﬀ between
the source code prior to the commit and the source code af-
ter the commit, these databases are also insuﬃcient for our
201
purpose. Second, there is no single code-similarity algorithm
that is eﬀective for all kinds of vulnerabilities. For example,
ReDeBug [13] can quickly ﬁnd unpatched code clones at
the OS-distribution scale of code bases, but can hardly be
applied to code clones that involve variable name modiﬁca-
tions, line additions or deletions, etc. Moreover, each vul-
nerability has its own characteristics that should be taken
into consideration. For example, if the code representation
of a code-similarity algorithm cannot distinguish a piece of
vulnerable code from the patched piece of the corresponding
code, the algorithm is not appropriate for dealing with this
vulnerability because it can cause a false-positive. However,
it is not known which code-similarity algorithms would be
eﬀective for which vulnerabilities.
We address the ﬁrst challenge by building a Vulnerability
Patch Database (VPD) and a Vulnerability Code Instance
Database (VCID), which correspond to the C/C++ open
source products that have some vulnerabilities according to
the NVD. The VPD contains 19 products with 1,761 vul-
nerabilities related to 3,454 diﬀ hunks, and the VCID con-
tains 455 code reuse instances of vulnerability diﬀ hunks.
We have made the VPD and the VCID publicly available at
https://github.com/vulpecker/Vulpecker. We plan to main-
tain the two databases to accommodate the new vulnerabil-
ities published in the future. When used together with the
NVD, a query with a CVE-ID allows one to get information
about the patch and a number of code reuse instances.
We address the second challenge by designing algorithms
to automatically select the code-similarity algorithm(s) that
is eﬀective for one speciﬁc vulnerability. Our contribution
lies in the deﬁnition and use of vulnerability diﬀ hunk fea-
tures, especially the ones that are derived from vulnerability
patches. These features allow us to systematically evaluate
which code-similarity algorithms are eﬀective for which vul-
nerabilities. We consider a number of code-similarity algo-
rithms proposed in the literature, as well as the variants that
we devise for the purpose of the present study.
We conduct experiments to systematically evaluate the ef-
fectiveness of VulPecker. Experiments show that it detects
40 vulnerabilities that are not published in the NVD. Among
these vulnerabilities, 18 are not known for their existence
and have yet to be conﬁrmed by vendors at the time of writ-
ing1, while the other 22 vulnerabilities have been “silently”
patched by vendors in later releases of the aﬀected products.
The remainder of the paper is organized as follows. Sec-
tion 2 reviews the related work. Section 3 presents the de-
sign of VulPecker. Section 4 discusses the implementation
of VulPecker. Section 5 describes our experimental results.
Section 6 discusses the limitation of the present study. Sec-
tion 7 concludes the present paper with a discussion on fu-
ture research directions.
2. RELATED WORK
There are two approaches for vulnerability detection: us-
ing vulnerability patterns or using code similarity. The
pattern-based detection approach typically requires multi-
ple instances of the same or similar vulnerability before a
pattern can be identiﬁed [9, 28]. Its usefulness is therefore
limited. The code-similarity based detection approach only
1For ethical reasons, we do not give the detailed information
about these vulnerabilities, but we can release the informa-
tion to academic researchers for experimental repeatability.
requires a single instance of vulnerability. It is based on the
intuition that similar programs may contain the same vul-
nerability [23], which explains why it has been used for de-
tecting software cloning/plagiarism [5, 26]. In what follows,
we review the code-similarity based detection approach.
Code-similarity comparison algorithms can be character-
ized by three attributes: code-fragment level, code represen-
tation, and comparison method. The ﬁrst two attributes
describe the representation of a piece of code in an abstract
way, while the third attribute describes how to compare the
similarity between two pieces of code according to their rep-
resentations. However, it is not known what code-fragment
level and/or code representation would be eﬀective for vul-
nerability detection.
Code-fragment level. A code fragment is the unit at
which programs are compared. This means that for code-
similarity comparison, code needs to be abstracted at a
certain level of granularity. Five levels of code fragments
have been proposed: patch-without-context, slice, patch-
with-context, function, and ﬁle/component. At the patch-
without-context fragment level, a fragment is obtained from
the diﬀ ﬁle by extracting the continuous lines preﬁxed by
the “-” symbol (indicating the lines that should be patched).
This granularity has been used for bug detection [18]. At
the slice fragment level, a program is sliced based on its
Program Dependence Graphs (PDG). Since slicing typically
preserves the structure of PDG, the isomorphism between
subgraphs indicates code similarity. This granularity has
been used for clone detection [15]. At the patch-with-context
fragment level, a fragment is obtained from the diﬀ ﬁle by
extracting the lines preﬁxed by the “-” symbol and the lines
with no preﬁx. This granularity has been used for bug de-
tection [19] and vulnerability detection [13, 17, 25]. At the
function fragment level, a function is treated as an inde-
pendent unit. This granularity has been used for vulner-
ability extrapolation [29, 30] and clone detection [12]. At
the ﬁle/component fragment level, each ﬁle/component is
treated as a unit. This coarse-grained granularity has been
mainly used for vulnerability prediction [8, 23].
Code representation. Each code fragment can be rep-
resented via text, metric, token, tree, and graph. The text-
based representation accommodates little syntactic or se-
mantic information, and therefore is not appropriate for vul-
nerability detection. In the metric-based representation, a
fragment is represented by a vector of features, which are
then compared with each other [8, 23]. This representation
is often used at the ﬁle/component fragment level. In the
token-based representation, the source code is transformed
into a sequence of “tokens” via compiler-style lexical analy-
sis, and then the sequence is scanned for certain tokens. A
token may correspond to a line of code [13, 17] or a compo-
nent in a line [19]. This representation is often used for clone
detection [12, 14], bug detection [19], vulnerability detection
[13, 17], and vulnerability extrapolation [29, 30]. In the tree-
based representation, a tree represents the syntactic struc-
ture of variables, constants, function calls, and other tokens
in source code. This syntactic representation has been used
for clone detection [16], vulnerability detection [25], and vul-
nerability extrapolation [30]. In the graph-based represen-
tation, a function is represented as a graph, where a node
represents an expression or statement, and an edge repre-
sents control ﬂow, control dependency or data dependency.
This semantic representation has been used for clone detec-
202
tion [15, 20], bug detection [18], and vulnerability detection
[25].
Comparison method. There are two kinds of compar-
ison methods: vector comparison and approximate/exact
matching. The vector comparison method ﬁrst converts the
representation of a vulnerability and the representation of a
target program into vectors, and then compares these vec-
tors for detecting vulnerabilities [12, 25, 29, 30]. The ap-
proximate/exact matching method searches the representa-
tion of a vulnerability in the code representation of a target
program via containment [13, 17, 19], substring matching
[16], full subgraph isomorphism matching [18], or approxi-
mate γ-isomorphism matching [20].
Finally, it is worth mentioning that exploit signatures are
sometimes called vulnerability signatures, although they are
actually used to recognize exploits [4, 6]. These signatures
characterize the inputs that can be used to exploit vulnera-
bilities [6]. Exploit signatures are orthogonal to the vulner-
ability signatures we study in the present paper.
3. DESIGN
3.1 Overview
Input
Code-similarity algorithm selection
Output
Vulnerability Code 
Instance Database 
(VCID)
NVD
e
s
a
h
p
g
n
n
r
a
e
L
i
Vulnerability 
diff hunk feature 
generator
Vulnerability signature generation
Unpatched 
code fragment 
extraction
Vulnerability 
Patch Database 
(VPD)
Diff 
Patched/ 
unpatched diff 
code extraction
Vulnerability detection
Target program 
signature generator
e
s
a
h
p
n
o
i
t
c
e
t
e
D
Target programs
CVE-IDs
CVE-to- 
algorithm 
mapping
Vulnerability 
signatures
Algorithm 
selection 
engine
Vulnerability 
signature 
generator
CVE-to-
algorithm 
mapping
Vulnerability 
signatures
Vulnerability 
detection engine
Vulnerability 
locations
Figure 1: Overview of VulPecker: The learning
phase selects code-similarity algorithm(s) that is ef-
fective for a vulnerability. The select algorithms in
turn guide the generation of vulnerability signatures
and the detection of vulnerabilities.
Figure 1 gives an overview of VulPecker. It has two phases: