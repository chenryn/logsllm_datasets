compliant ad components in kids apps. Speciﬁcally, our
ﬁrst goal is to determine whether in-app ads or landing
pages pointed by these ads present forms that collect per-
sonal information. Although displaying collection forms
itself is not a violation, children might type in requested
personal information, especially if these websites claim
to offer free prizes or sweepstakes.
In such cases, if
these ads or landing pages do collect personal informa-
tion without explicit parental consent, this act could be
considered as a violation according to COPPA. Since it is
difﬁcult to model these legal terms into technical speciﬁ-
cations, we only report potential concerns in this section.
Our second goal is to test whether content displayed in
in-app ads or landing pages is appropriate for children.
Since this kind of judgement is fundamentally subjective,
we show the breakdown of content categories as labeled
by human testers.
Note that runtime observation is critical for this test-
ing, since ads displayed within apps change dynamically
depending on the inventory of ads at the time of request.
7.2 Testing Procedure
The testing has two steps. For a given app, we ﬁrst col-
lect ads displayed within apps and landing pages that are
pointed by the ads. Second, for each ad and landing page,
we determine: (1) whether they present forms to collect
personal information such as ﬁrst and last name, home
address, and online contact as deﬁned in COPPA; and
(2) whether their content appears inappropriate to chil-
dren and if so why.
Driving apps to display ads: We use Brahmastra to au-
tomatically drive apps to display ads. In this study, we
focus on two popular ad libraries, AdMob and Millen-
nial Media, because they account for over 40% of free
Android apps with ads [11]. To get execution paths that
produce ads, we use the following target methods as in-
put to Brahmastra:
Lcom/google/ads/AdView;->
Lcom/millennialmedia/android/MMAdView;->
Collecting ads & landing pages: We redirect all the net-
work trafﬁc from executing test apps through a Fiddler
proxy [8]. We install the Fiddler SSL certiﬁcate on the
phone emulator as a trusted certiﬁcate to allow it to ex-
amine SSL trafﬁc as well. We then identify the requests
made by the ad libraries to their server component us-
ing domain names. Once these requests are collected,
we replay these traces (several times, over several days),
to fetch ad data from the ad servers as if these requests
were made from these apps. This ad data is generally in
the form of a JSON or XML object that contains details
about the kind of ad served (image or text), the content
to display on the screen (either text or the URL of an im-
age), and the URL to redirect to if the ad is clicked upon.
We record all of above for analysis.
Analyzing ads & landing pages: We use two methods
to characterize ads and landing pages. First, for each
landing page URL collected, we probe the Web of Trust
(WoT) database [9] to get the “child safety” score. Sec-
ond, to better understand the reasons why landing pages
or ads may not be appropriate for children, we use crowd-
sourcing (via Amazon Mechanical Turk [3]) to label each
ad and landing page and to collect detailed information
such as the type of personal information that landing
pages collect. As data collected from crowds may in-
clude inconsistent labeling, we use majority voting to ﬁl-
ter out noise.
7.3 Results
Dataset: We collected our dataset in January 2014. To
ﬁnd apps intended for children, we use a list of apps
categorized as “Kids” in Amazon’s Android app store4.
Since apps offered from the Amazon store are protected
with DRM and resist bytecode rewriting, we crawled the
Play store for apps with the same package name.
Starting from slightly over 4,000 apps in the Kids cat-
egory, we found 699 free apps with a matching package
name in the Play store. Among these, we ﬁnd 242 apps
that contain the AdMob or Millennial Media ad libraries.
Using Brahmastra, we were successfully able to retrieve
at least one ad request for 220 of these apps (also in Jan-
uary 2014), for which we report results in this section.
For the remaining 22 apps, either Brahmastra could not
navigate to the correct page, or the app did not serve any
ad despite reaching the target page.
Results: We collected ads from each of the 220 apps
over 5 days, giving us a total collection of 566 unique
ads, and 3,633 unique landing pages. Using WoT, we de-
termine that 183 out of the 3,633 unique landing pages
have the child-safety score below 60, which fall in the
“Unsatisfactory”, “Poor” or “Very Poor” categories. 189
out of the 220 apps (86%) pointed to at least one of these
pages during the monitoring period. Note that WoT did
not contain child-safety ratings for 1,806 pages, so these
4Google Play store does not have a separate kids category.
1030  23rd USENIX Security Symposium 
USENIX Association
Info Type
Home address
First and last name
Online contact
Phone number
Total
Landing Pages
47
231
100
17
235
Apps
58
174
94
15
175
Table 2: Personal information collected by landing pages
numbers represent a lower bound. We then used Amazon
Mechanical Turk to characterize all 566 ads, and 2,111
randomly selected landing pages out of the 3,633. For
each ad and landing page, we asked Amazon Mechan-
ical Turk to check whether they collect personal infor-
mation (of each type) and whether they contain inappro-
priate content for children (see Appendix B for the task
details). We offered 7 cents (US) per each task (which
involves answering various questions for each website or
banner ad) and collected three responses per data point.
As discussed above, we only counted responses that were
consistent across at least two out of three respondents, to
ﬁlter out noise.
Table 2 summarizes the types of personal informa-
tion that landing pages ask users to provide as labeled
by Amazon Mechanical Turk. We ﬁnd that at least 80%
of the apps in the dataset had displayed ads that point to
landing pages with forms to collect personal information.
On a manual examination of a subset of these pages, we
found no labeling errors. We also found that none of the
sites we manually checked attempt to acquire parental
consent when collecting personal information. See Ap-
pendix B for examples.
Table 3 breaks down child-inappropriate content of the
ads displayed in apps as labeled by Amazon Mechani-
cal Turk. Although COPPA does not regulate the con-
tent of online services, we still ﬁnd it concerning that
36% (80 out of 220) of the apps display ads with con-
tent deemed inappropriate for children. In particular 26%
(58 apps) displayed ads that offer free prizes (e.g., Fig-
ure 13), which is considered a red ﬂag of deceptive adver-
tising, especially in ads targeting children as discussed in
guidelines published by the Children’s Advertising Re-
view [10]. We also analysed the content displayed on
the landing pages, and found a similar number of content
violations as the ad images.
8 Analysis of Social Media Add-ons
Our second use case is to test apps against a recently
discovered vulnerability associated with the Facebook
SDK [30]. Our testing with Brahmastra shows that 13
out of 200 Android apps are vulnerable to the attack.
Fixing it requires app developers to update the authen-
tication logic in their servers as recommended by [30].
the
Content Type
Child exploitation
Gambling, contests, lotteries or
sweepstakes
Misleading users about
product being advertised
Violence, weapons or gore
Alcohol, tobacco or drugs
Profanity and vulgarity
Free prize
Sexual or sexually suggestive
content
Total
Image Ads
2
3
Apps
8
2
7
4
3
0
39
12
62
16
5
3
0
58
29
80
Table 3: Breakdown of child-inappropriate content in ads
8.1 Testing Goal
The Facebook access token vulnerability discussed
in [30] can be exploited by attackers to steal the vic-
tim’s sensitive information stored in vulnerable apps. For
instance, if a malicious-yet-seemingly benign news app
can trick the victim once to use the app to post a fa-
vorite news story on the victim’s Facebook wall (which
is a common feature found in many news apps), then the
malicious app can use the access token obtained from the
Facebook identity service to access sensitive information
stored by any vulnerable apps that the victim had inter-
acted with and have been associated with the victim’s
Facebook account. This attack can take place ofﬂine—
once the malicious app obtains an access token, then it
can send the token to a remote attacker who can imper-
sonate as the victim to vulnerable apps.
Figure 10 gives the steps that allow a malicious appli-
cation to steal Victim’s information from VulApps. The
fact that the online service (VulApps) is able to retrieve
the user’s information from Facebook only means that
the client (MalAppc) possesses the privilege to the Face-
book service, but is not a proof of the client app’s iden-
tity (MalAppc (cid:31)= VulAppc). The shaded boxes in Figure 10
highlight the vulnerability. See [30] for more detail.
Wang et al. [30] manually tested 27 Windows 8 apps
and showed that 78% of them are vulnerable to the ac-
cess token attack. Our goal is to scale up the testing to a
large number of Android applications. Note that testing
for this vulnerability requires runtime analysis because
the security violation assumptions are based on the inter-
actions among the application, the application service,
and Facebook service.
8.2 Testing Procedure
The testing has three steps. For a given app, we ﬁrst need
to drive apps to load a Facebook login screen. Second,
we need to supply valid Facebook login credentials to ob-
serve interactions between the test application and Face-
USENIX Association  
23rd USENIX Security Symposium  1031
1. Click Login with Facebook
2. Initiate login with Facebook
3. Prompt Facebook login screen
4. Provide Victim’s Facebook credentials
5. Return access_token
6. Authenticate with access_token
7. Get user info with access_token
8. Provide Victim’s info
9. Authenticate this session as Victim
Victim
MalAppc
VulApps
Facebook ID service
Figure 10: Facebook’s access token, intended for autho-
rizing access to Victim’s info, is used by VulApps to au-
thenticate the session as Victim. From step 9, MalAppc
can steal Victim’s sensitive information in VulApps.
book ID service. Third, we need to determine whether
the test application misuses a Facebook access token for
authenticating a client (steps 7-9) by monitoring network
trafﬁc and application behavior after providing a fraudu-
lent access token.
Driving apps to display Facebook login: We use Brah-
mastra to automatically drive apps to invoke the Face-
book SDK’s authentication methods shown in Figure 7.
Once the authentication methods open the sign-in win-
dow, we supply valid Facebook credentials.
Manipulating trafﬁc with MITM proxy: As before,
we direct all network trafﬁc through a Fiddler proxy.
Since Facebook sign-in trafﬁc is encrypted over SSL, we
also install a Fiddler SSL certiﬁcate on the phone emu-
lator to decrypt all SSL trafﬁc.
To manipulate the login, we record an access token
from a successful login session associated with another
application (and therefore simulating an attacker as illus-
trated in the steps 1-5 of Fig. 10) and use the script shown
in Fig. 11. It runs over HTTP responses, and overwrites
an incoming access token with a recorded one.
8.3 Experiments
Dataset: We randomly draw 200 apps from the dataset
used in §6 for this testing.
Results: We ﬁnd that 18 out of 200 apps use a Face-
book access token for authentication, and among them 13
apps are vulnerable to a fraudulent access token (72%). 5
apps appear not vulnerable, and show some sort of error
message when given a fraudulent access token. The re-
maining 182 apps use the Facebook SDK merely to post
content to the user’s wall, and not as an authentication
mechanism. We determined this by looking at the net-
1 if(oSession.url.Contains("m.facebook.com")) {
2 var toReplace = "access_token=CAAHOi...";
3 ...
4 if(oSession.oResponse.headers.
5
6 {
7
oSession.oResponse.headers["Location"] =
oSession.oResponse.headers["Location"].
ExistsAndContains("Location", "access_token"))
8
9
replace(oRegEx, toReplace);
oSession["ui-customcolumn"] = "changed-header";
10
11 } }
Figure 11: A script used to manipulate access token:
We only show the ﬁrst 6 bytes of the access token used
in the attack.
work trafﬁc at the login event, and observing that all of it
is sent only to Facebook servers.
To understand how widespread the vulnerability is, we
look at the statistics for the number of downloads on the
Google Play store. Each of the 13 vulnerable apps has
been downloaded more than 10,000 times, the median
number of app downloads is over 500,000, and the most
popular ones have been downloaded more than 10 mil-
lion times. Further, these 13 apps have been built by
12 distinct publishers. This shows that the problem is
not restricted to a few na¨ıve developers. We shared the
list of vulnerable apps with a Facebook security team on
2/27/2014 and got a response immediately that night that
they had contacted the affected developers with the in-
structions to ﬁx. The privacy implications of the pos-
sessing the vulnerability are also serious. To look at what
user data can potentially be exﬁltrated, we manually in-
vestigated the 13 vulnerable apps. Users of these apps
may share a friends list, pictures, and messages (three
dating apps); photos and videos (two apps); exercise logs
and stats (one app); homework info (one app) or favorite
news articles, books or music preferences (remaining six
apps). By exploiting the vulnerability, a malicious app
could exﬁltrate this data.
9 Related Work
Automated Android app testing: A number of recent
efforts proposed improvements over Android Monkey:
AndroidRipper [13] uses a technique known as GUI rip-
ping to create a GUI model of the application, and ex-
plores its state space. To improve code coverage, An-
droidRipper relies on human testers to type in user cre-
dentials to get through blocking pages. However, de-
spite this manual effort, the tool shows less than 40%
code coverage after exploring an app for 4.5 hours. App-
sPlayground [26] employs a number of heuristics—by
guessing the right forms of input (e.g., email address, zip
code) and by tracking widgets and windows in order to
1032  23rd USENIX Security Symposium 
USENIX Association