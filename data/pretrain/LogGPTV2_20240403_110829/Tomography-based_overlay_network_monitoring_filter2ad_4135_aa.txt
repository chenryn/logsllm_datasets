title:Tomography-based overlay network monitoring
author:Yan Chen and
David Bindel and
Randy H. Katz
Tomography-based Overlay Network Monitoring
Yan Chen, David Bindel, Randy H. Katz
Computer Science Division
University of California at Berkeley
Berkeley, CA 94720-1776, USA
{yanchen, dbindel, randy}@cs.berkeley.edu
ABSTRACT
Overlay network monitoring enables distributed Internet ap-
plications to detect and recover from path outages and peri-
ods of degraded performance within seconds. For an overlay
network with n end hosts, existing systems either require
O(n2) measurements, and thus lack scalability, or can only
estimate the latency but not congestion or failures. Unlike
other network tomography systems, we characterize end-to-
end losses (this extends to any additive metrics, including
latency) rather than individual link losses. We ﬁnd a mini-
mal basis set of k linearly independent paths that can fully
describe all the O(n2) paths. We selectively monitor and
measure the loss rates of these paths, then apply them to es-
timate the loss rates of all other paths. By extensively study-
ing synthetic and real topologies, we ﬁnd that for reasonably
large n (e.g., 100), k is only in the range of O(n log n). This
is explained by the moderately hierarchical nature of Inter-
net routing.
Our scheme only assumes the knowledge of underlying IP
topology, and any link can become lossy or return to normal.
In addition, our technique is tolerant to topology measure-
ment inaccuracies, and is adaptive to topology changes.
Categories and Subject Descriptors
C.2.3 [Network Operations]: Network monitoring
General Terms
Measurement, Algorithms
Keywords
Overlay networks, Network measurement and monitoring,
Network tomography, Numerical linear algebra
1.
INTRODUCTION
With the rapid growth of the Internet, new large-scale
globally distributed network services and applications have
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
IMC’03, October 27–29, 2003, Miami Beach, Florida, USA.
Copyright 2003 ACM 1-58113-773-7/03/0010 ...$5.00.
emerged, such as overlay routing and location systems, application-
level multicast, and peer-to-peer ﬁle sharing. As these sys-
tems have ﬂexibility in choosing their communication paths
and targets, they can beneﬁt signiﬁcantly from dynamic net-
work distance prediction (e.g., latency and loss rate).
Existing network distance estimation systems can be grouped
into two categories: static estimation [18, 23] and dynamic
monitoring [13, 8, 3]. Previous static estimation systems,
such as Global Network Positioning (GNP) [18], achieve a
high level of accuracy, but also incur high overhead for con-
tinuously updating the estimates.
Dynamic monitoring can detect path outages and periods
of degraded performance within seconds. However, existing
schemes either require pair-wise measurements for all end
hosts, and thus lack scalability [3]; or they can only esti-
mate latency, but not congestion or failures [13, 8]. Existing
scalable systems, such as [13, 8], cluster end hosts based on
their network proximity or latency similarity under normal
conditions. However, end hosts in the same cluster may not
have similar losses, especially when the losses happen in the
last mile.
In this paper, we describe a scalable overlay network con-
gestion/failure monitoring system which is highly accurate
and incrementally deployable. Consider an overlay network
of n end hosts; we deﬁne a path to be a routing path be-
tween a pair of end hosts, and a link to be an IP link between
routers. A path is a concatenation of links. There are O(n2)
paths among the n end hosts, and we wish to select a min-
imal subset of paths to monitor so that the loss rates and
latencies of all other paths can be inferred. The loss rates
are used to estimate the congestion/failures on the overlay
paths.
To this end, we propose a tomography-based overlay net-
work monitoring system in which we selectively monitor a
basis set of k paths (typically k (cid:3) n2). Any end-to-end path
can be written as a unique linear combination of paths in
the basis set. Consequently, by monitoring loss rates for the
paths in the basis set, we infer loss rates for all end-to-end
paths. This can also be extended to other additive met-
rics, such as latency. The end-to-end path loss rates can be
computed even when the paths contain unidentiﬁable links
for which loss rates cannot be computed. We provide an
intuitive picture of this characterization process in terms of
virtual links.
Although congestion outbursts within seconds are hard to
detect and bypass, the delay in Internet inter-domain path
failovers averages over three minutes [16]. Our loss rate
estimation will ﬁlter out measurement noise with smoothing
techniques, such as exponentially-weighted moving average
(EWMA), and detect these path failovers quickly to have
applications circumvent them.
Our key observation is that k grows relatively slowly as a
function of n. The dimension k is bounded by the number
of links in the subgraph induced by the routing paths. In
an Internet-like topology with a power-law degree distribu-
tion, there are O(N ) links, where N is the total number of
end hosts in the network. This is because a small number of
nodes have high degree and the links between them are heav-
ily used [12]. Consequently, if n = O(N ), then k < O(n).
However, even when n (cid:3) N , the moderately hierarchical
structure of the network causes many routing paths to over-
lap [26], so that the number of links in the routing path sub-
graph grows much slower than O(n2). Our extensive study
of both synthetic and real Internet topologies suggests that
for a randomly selected subset of n end hosts, k grows like
O(n log n) when n is suﬃciently large (say 100).
Furthermore, our technique is tolerant to topology mea-
surement inaccuracies, and is adaptive to topology changes.
Besides simulating our system with various synthetic and
real topologies, we implemented our system on the Planet-
Lab testbed [22]. We deployed it on 51 global hosts (each
from a diﬀerent organization) and ran the experiments over
four weekdays with a total of 76.5M UDP packets. Both
simulation and implementation results show we achieve high
accuracy when estimating path loss rates with k measure-
ments. For example, the average absolute error of loss rate
estimation for the Internet experiments is only 0.0027 with
average k = 872 out of a total of 51 × 50 = 2550 paths. On
average, for 248 of the 2550 paths, the routing information
obtained via traceroute is unavailable or incomplete, which
shows that our technique is robust against topology mea-
surement errors. See our tech report [7] for details on both
simulation and experiments on PlanetLab.
The rest of the paper is organized as follows. We survey
related work in Sec. 2, describe our model and basic theory
in Sec. 3 and present algorithms in Sec. 4. Finally, we discuss
the generalization of our framework in Sec. 5 and conclude
in Sec. 6.
2. RELATED WORK
Network tomography has been extensively studied ( [10]
provides a good survey). Most existing systems assume that
limited measurement information is available (often in a
multicast tree-like structure), and they try to infer the char-
acteristics of the links [1, 2, 6, 20] or shared congestion [24]
in the middle of the network.
In many cases, these inferences are limited due to limited
measurement and the irregularity of Internet topologies. In
contrast, we do not care about the characteristics of indi-
vidual links. Furthermore, we do not have any restriction
on the paths to measure. Our goal is to selectively measure
a small subset of paths so that we can infer the loss rates of
all other paths.
As the closest work to ours, Shavitt et al. also use alge-
braic tools to compute the distances that are not explicitly
measured [25]. Given certain “Tracer” stations deployed
and some direct measurements among the Tracers, they
search for path or path segments whose loss rates can be in-
ferred from these measurements. Thus their focus is not on
Tracer/path selection. Neither do they examine the topol-
ogy measurement errors or the topology change problems.
Overlay Network 
Operation Center
End hosts
Figure 1: Architecture of a tomography-based over-
lay network monitoring system
Recently, Ozmutlu et al.
selected a minimal subset of
paths to cover all links for monitoring, assuming link-by-link
latency is available via end-to-end measurement [19]. Their
approach has the following three limitations. 1) Traceroute
cannot give accurate link-by-link latency. Many routers in
the Internet hide their identities. Besides, traceroute uses
the ICMP protocol for measurement, and routers often treat
ICMP packet diﬀerently from TCP/UDP packets. There-
fore, latency data is not representative. 2) It is not applica-
ble for loss rate, because it is diﬃcult to estimate link-by-link
loss rates from end-to-end measurements. Loss rate is often
more important for applications than latency. 3) It assumes
static routing paths and does not consider topology changes.
Many of the previous ﬁndings can be leveraged to reﬁne
loss rate prediction. For example, [20] ﬁnds that the end-to-
end losses are dominated by a small number of lossy links.
Thus, the path space to be monitored can be reduced to
those paths that include lossy links. Consequently, the basis
set and the amount of measurement will be reduced.
3. THE MODEL
In this section, we develop the model for tomography-
based overlay monitoring.
Given n end hosts to be monitored, we assume that they
belong to an overlay network (such as a virtual private net-
work), or that they cooperate to share the monitoring ser-
vices. Thus, we can measure the routing topology and loss
rate of any path. The end hosts are under the control of a
central authority (e.g., an overlay network operation center
(ONOC)) to measure the topology and loss rates of paths,
though in the future we plan to investigate techniques to
distribute the work of the central authority.
For simplicity, we mostly assume symmetric routing and
undirectional links in the paper. But our techniques work
without changes for asymmetric routing, as used in the In-
ternet experiments. Fig. 1 shows an example where there
are four end hosts on the overlay network. There are six
paths and four links. The end hosts measure the topology
and report to the ONOC, which selects four paths and in-
struments two of the end hosts to measure the loss rates of
the four paths. The end hosts periodically report the loss
rates measured to the ONOC. Then the ONOC infers the
loss rates of every link, and consequently the loss rates of
the other two paths. Applications can query the ONOC for
the loss rate of any path, or they can set up triggers to re-
ceive alerts when the loss rates of paths of interest exceed a
certain threshold.
The path loss rates can be measured by either passive ob-
servation of normal traﬃc to estimate packet drop rate [20]
or active measurement. The measurements of selected paths
do not have to be taken at exactly the same time because
Zhang et al. report that the loss rate remains operationally
stable in the time scale of an hour [27]. The network topol-
ogy can be measured via traceroute or other advanced tools [15,
9]. We discuss topology changes in Sec. 4.4.
3.1 Theory and Notations
Symbols
M
N
n
r = O(n2)
s
t
G ∈ {0, 1}r×s
¯G ∈ {0, 1}k×s
k ≤ s
li
pi
xi
bi
v
p
N (G)
R(GT )
Meanings
total number of nodes
number of end hosts
number of end hosts on the overlay
number of end-to-end paths
# of IP links that the overlay spans on
number of identiﬁable links
original path matrix
reduced path matrix
rank of G
loss rate on ith link
loss rate on ith measurement path
log(1 − li)
log(1 − pi)
vector in {0, 1}s (represents path)
loss rate along a path
null space of G
row(path) space of G (== range(GT ))
Table 1: Table of notations
Suppose an overlay network spans s IP links. We repre-
sent a path by a column vector v ∈ {0, 1}s, where the jth
entry vj is one if link j is part of the path, and zero other-
wise. Suppose link j drops packets with probability lj; then
the probability p of packet loss on the path represented by
v is given by
1 − p = Yj s.t. vj =1
(1 − lj)
By taking logarithms on both sides of (1), we have
(1)
(2)
log (1 − p) =
vj log (1 − lj)
s
Xj=1
If we deﬁne a column vector x ∈ R
s with elements xj :=
log (1 − lj ), and write vT for the row vector which is the
transpose of v, we can rewrite (2) in the following dot prod-
uct form:
log (1 − p) =
s
Xj=1
vj xj = vT x
(3)
Considering all r = O(n2) paths in the overlay network,
there are r linear equations of the form (3). Putting them
together, we form a rectangular matrix G ∈ {0, 1}r×s to
represent these paths. Each row of G represents a path in
the network: Gij = 1 when path i contains link j, and
Gij = 0 otherwise. Let pi be the probability of packet loss
during transmission on the ith path, and let b ∈ R
r be
a column vector with elements bi := log (1 − pi). Then we
write the system of equations relating the link losses to path
losses as
(4)