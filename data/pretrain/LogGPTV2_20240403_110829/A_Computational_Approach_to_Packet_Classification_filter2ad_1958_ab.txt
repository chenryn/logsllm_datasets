m1,W1 −1(x )
More Stages
mn−1, 0(x )
mn−1,Wn−1 −1(x )
v0
v1
v2
v|I |−1
Figure 3: RMI model structure and inference [18].
The performance drop is signiﬁcant even when the data struc-
tures ﬁt in the L3 cache. This cache is shared among all the cores,
whereas L1 and L2 caches are per-core. Thus, L3 is not only slower
(up to 90 cycles in recent X86 CPUs), but also suﬀers from cache
contention, e.g., when another core runs a cache-demanding work-
load and causes cache trashing. We observe the eﬀects of L3 con-
tention in §5.2.1.
NuevoMatch aims to provide more space eﬃcient representa-
tion of the rule index to scale to large rule-sets.
3 NUEVOMATCH CONSTRUCTION
We ﬁrst explain the RMI model for learned indexes which we use
as the basis, explain its limitations, and then show our solution that
overcomes them.
3.1 Recursive Model Index
Kraska et al. [18] suggest using machine-learning models for stor-
ing key-value pairs instead of conventional data structures such as
B-trees or hash tables. The values are stored in a value array, and
a Recursive Model Index (RMI) is used to retrieve the value given a
key. Speciﬁcally, RMI predicts the index of the corresponding value
in the value array using a model that learned the underlying key-
index mapping function.
The main insight is that any index structure can be expressed
as a continuous monotonically increasing function y = h(x) :
[0, 1] 7→ [0, 1], where x is a key scaled down uniformly into [0, 1],
and y is the index of the respective value in the value array scaled
down uniformly into [0, 1]. RMI is trained to learn h(x). The result-
secondary search in the array, in the vicinity ϵ of the predicted in-
dex, where ϵ is the maximum index prediction error of the model,
ing learned index modelbh(x) performs lookups in two phases: ﬁrst
it computes the predicted indexby = bh(key), and then performs a
namely |bh(key) − h(key)| ≤ ϵ.
Model structure. RMI is a hierarchical model made of several (n)
stages (Figure 3). Each stage i includes Wi submodels mi , j , j  threshold. s ← 2s
Figure 5: The submodel training process. The additional
phase for training submodels in the leaves is depicted with
dashed lines.
Deﬁnition 3.1 (RQ-RMI submodel). Denote the output of a 3-
layer fully-connected neural network as:
Ni , j (x) = A(cid:0)x · w1 + b1(cid:1) × w2 + b2
where x is a scalar input, w1, b1 are the weight and bias row-
vectors for layer 1 (hidden layer), and w2, b2 are the weight column-
vector and bias scalar for layer 2. Note that Ni , j (x) is a scalar. The
ReLU function A applies a function a on each element of an input
vector:
0
x ≥ 0
x < 0.
a(x) =(x
Mi , j (x) = H(cid:0)Ni , j (x)(cid:1)
The submodel output, denoted Mi , j (x), is deﬁned as follows:
where H (x) trims the output domain to be in [0, 1).
Corollary 3.2. Mi , j (x) is a piece-wise linear function.
3.5 RQ-RMI training
We use Corollary 3.2 to compute the transition inputs and the re-
sponsibility of the submodels. We provide a simpliﬁed description;
see Appendix for the precise explanation.
3.5.1 Overview. RQ-RMI training is similar to RMI’s. It is per-
formed stage by stage. Figure 5 illustrates the training process for
one stage. We start by training the single submodel in the ﬁrst
stage using the entire input domain. Next, we calculate its tran-
sition inputs (§3.5.2) and use them to ﬁnd the responsibilities of
the submodels in the following stage (§3.5.3). We proceed by train-
ing submodels in the subsequent stage using designated datasets
we generate based on the submodels’ responsibilities (§3.5.4). We
repeat this process until all submodels in all internal stages are
trained. For the submodels in the leaves (last stage), there is an
additional phase (dashed lines in Figure 5). After training, we cal-
culate their error bounds and retrain the submodels that do not
satisfy a predeﬁned error threshold (§3.5.6).
3.5.2 Computing transition inputs. Given a trained submodel
m we can analytically ﬁnd all its linear regions, and respectively
the inputs delimiting them, which we call trigger inputs ❕l . For
all inputs in the region [ ❕l , ❕l +1], the model function, denoted as
M(x), is linear by construction. On the other hand, the uniform out-
put quantization deﬁnes a step-wise function Q = ⌊M(x) · W ⌋/W ,
where W is the size of the quantized output domain (Figure 4).
Thus, for each input region [ ❕l , ❕l +1], the set of transition inputs
tl ∈ T are those where M(x) and Q intersect.
3.5.3 Computing the responsibilities of submodels in the follow-
ing stage. Given a trained submodel mi , j in an internal stage i,
we say that it maps a key to a submodel mi +1,k, k < Wi +1, if
⌊Mi , j (key) · Wi +1⌋ = k. As discussed informally earlier, the re-
sponsibility Ri +1,k of mi +1,k is deﬁned as all the inputs which are
mapped by submodels in stage i to mi +1,k . In other words, the
trained submodels at stage i deﬁne the responsibility of untrained
submodels at stage i + 1.
Knowing the responsibility of a submodel is crucial, as it deter-
mines the subset of the inputs used to train the submodel. RMI
exhaustively evaluates all the inputs, which is ineﬃcient. Instead,
we compute Ri +1,k using the transition inputs of mi , j. In the fol-
lowing, we assume for clarity that Ri , j is contiguous, and mi , j is
the only submodel at stage i.
We compute Ri +1,k by observing that it is composed of all the
inputs in the regions (tl , tl +1) that map to submodel mi +1,k , where
tl ∈ Ti , j are transition inputs of mi , j. By construction, the inputs
in the region between two adjacent transition points map to the
same output. Then, it suﬃces to compute the output of mi , j for its
transition points, and choose the respective input ranges that are
mapped to mi +1,k .
3.5.4 Training a submodel with ranges using sampling. Up to
this point, we used only key-index pairs as model inputs. Now we
focus on training on input ranges. A range can be represented as all
the keys that fall into the range, all associated with the same index
of the respective rule. For example, 10.1.1.0-10.1.1.255 includes 256
keys. Our goal is to train a model such that given a key in the range,
the model predicts the correct index. Enumerating all the keys in
the ranges is ineﬃcient. Instead, we use sampling as follows.
We generate the training key-index pairs by uniformly sampling
the submodel’s responsibility. We start with a low sampling fre-
quency. A sample is included in the training set if there is an in-
put rule range that matches the sampled key. Thus, the number of
samples per input range is proportional to its relative size in the
submodel’s responsibility. Note that some input ranges (or individ-
ual keys) might not be sampled at all. Nevertheless, they will be
matched correctly as we explain further.
3.5.5
Submodel training. We train submodels on the generated
datasets using supervised learning and Adam optimizer [14] with
a mean squared error loss function.
3.5.6 Computing error bounds. Given a trained submodel in the
last stage, we compute the prediction error bound for all inputs
in its responsibility by evaluating the submodel on its transition in-
puts. The prediction error is computed also for the inputs that were
not necessarily sampled, guaranteeing match correctness. If the er-
ror is too large, we double the number of samples, regenerate the
key-index pairs, and retrain the submodel. Training continues un-
til the target error bound is attained or after a predeﬁned number
of attempts. If training does not converge, the target error bound
may be increased by the operator. The error bound determines the
search distance of the secondary search; hence a larger bound causes
lower system performance. We evaluate this tradeoﬀ later (§5.3.4).
Port Number
R1
r 4
1
r 0
1
r 2
1
R0
R2
R3
R4
IP
Address
r 1
0
r 3
0
Figure 6: Rules from Figure 2 are split into two iSets:
{R0, R2, R4} (by port), and {R1, R3} (by IP).
3.6 Handling multi-dimensional queries with
range overlaps
NuevoMatch supports overlapped ranges and matching over mul-
tiple dimensions, i.e., packet ﬁelds, by combining two simple ideas:
partitioning the rule-set into disjoint independent sets (iSets), and
performing multi-ﬁeld validation of each rule. In the following, we
use the terms dimension and ﬁeld interchangeably.
Partitioning. Each iSet contains rules that do not overlap in one
speciﬁc dimension. We refer to the coverage of an iSet as the fraction
of the rules it holds out of those in the input. One iSet may cover all
the rules if they do not overlap in at least one dimension, whereas
the same dimension with many overlapping ranges may require
multiple iSets. Figure 6 shows the iSets for the rules from Figure 2.
Each iSet is indexed by one RQ-RMI. Thus, to ﬁnd the match to a
query with multiple ﬁelds, we query all RQ-RMIs (in parallel), each
over the ﬁeld on which it was trained. Then, the highest priority
result is selected as the output.
Each iSet adds to the total memory consumption and compu-
tational requirements of NuevoMatch. Therefore, we introduce a
heuristic that strives to ﬁnd the smallest number of iSets that cover
the largest part of the rule-set (§3.6.1).
Multi-ﬁeld validation. Since an RQ-RMI builds an index of the
rules over a single ﬁeld, it might retrieve a rule which does not
match against other ﬁelds. Hence, each rule returned by an RQ-
RMI is validated across all ﬁelds. This enables NuevoMatch to
avoid indexing all dimensions, yet obtain correct results.
3.6.1
iSet partitioning. We introduce a greedy heuristic that
repetitively constructs the largest iSet from the input rules, pro-
ducing a group of iSets. To ﬁnd the largest iSet over one dimension,
we use a classical interval scheduling maximization algorithm [15].
The algorithm sorts the ranges by their upper bounds, and repeti-
tively picks the range with the smallest upper bound that does not
overlap previously selected ranges.
We apply the algorithm to ﬁnd the largest iSet in each ﬁeld.
Then we greedily choose the largest iSet among all the ﬁelds and
remove its rules from the input set. We continue until exhausting
the input. This heuristic is sub-optimal but quite eﬃcient. We plan
to improve it in future work.
Having a larger number of ﬁelds in a rule-set might help im-
prove coverage. For example, if the rules that overlap in one ﬁeld
do not overlap in another and vice versa, two iSets cover the whole
rule-set, requiring more iSets for each ﬁeld in isolation.
3.7 Remainder set and external classiﬁers
Real-world rule-sets may require many iSets for full coverage, with
a single rule per iSet in the extreme cases. Using separate RQ-RMIs
for such iSets will hinder performance. Therefore, we merge small
iSets into a single remainder set. The rules in the remainder set are
indexed using an external classiﬁer. Each query is performed on
both the RQ-RMI and the external classiﬁer.
In essence, NuevoMatch serves as an accelerator for the external
classiﬁer. Indeed, if rule-sets are covered using a few large iSets, the
external classiﬁer needs to index a small remainder set that often
ﬁts into faster memory, so it can be very fast.
Two primary factors determine the end-to-end performance: (1)
the number of iSets required for high coverage (depends on the
rule-set), and; (2) the number of iSets for achieving high perfor-
mance (set by an operator).