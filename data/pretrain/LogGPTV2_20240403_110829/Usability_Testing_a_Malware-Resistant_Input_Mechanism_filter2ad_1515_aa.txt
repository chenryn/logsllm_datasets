title:Usability Testing a Malware-Resistant Input Mechanism
author:Alana Libonati and
Jonathan M. McCune and
Michael K. Reiter
Usability Testing a Malware-Resistant Input Mechanism
Alana Libonati
Jonathan M. McCune
Michael K. Reiter
University of North Carolina
Carnegie Mellon University
University of North Carolina
PI:EMAIL
PI:EMAIL
PI:EMAIL
Abstract
We report the results of a usability study of Bumpy, a
system that enables a user to provide secret inputs to re-
mote webservers without trusting the computer on which
she types those inputs. Achieving this somewhat paradoxi-
cal property via Bumpy requires extra diligence from users,
raising questions as to whether it is a viable protection
for the average user. We evaluate the originally proposed
Bumpy design and several new alternatives in a user study
involving 85 participants, each of whom utilized one of
these designs (or a control design) for roughly four months
to protect her password entries to a university course web
page. Beyond assessing the usability of Bumpy designs, our
study offers insights for designing security-relevant inter-
faces and training users to successfully utilize them.
1
Introduction
Malware infections are commonplace (e.g., [5, 14, 20]),
suggesting that a considerable percentage of users will sit
down to an infected computer at some point. There are few
defenses that help a user cope with such situations, partic-
ularly if the malware has inﬁltrated the lowest levels of the
operating system (or virtual machine monitor [15, 24, 34],
or lower [7, 35]). Those defenses that do must somehow
instill in each user a degree of mistrust in the computer she
is using, so that the user will employ a level of suspicion
that allows her to detect malware behaviors and / or avoid
divulging any further sensitive information to the malware.
One defense intended for such a circumstance is
Bumpy [17], a mechanism that enables a user to convey se-
cret information to remote webservers through a host with-
out trusting that host with the information itself. Brieﬂy,
Bumpy works by ﬁrst processing user keystrokes in a small,
trusted module that is isolated from all other software on the
computer using newly available hardware-enforced protec-
tions [12]. Because this module receives user inputs before
the other software does, the user can indicate an input that
she considers sensitive by preceding it with a secure atten-
tion sequence (SAS), causing the Bumpy module to treat
it differently from normal inputs (which it passes on to the
untrusted platform). In particular, Bumpy can queue sensi-
tive inputs and prepare them (e.g., encrypt them) for a target
destination, releasing only nondescript characters (e.g., as-
terisks) to the untrusted platform in their place. Aside from
the user remembering to type the SAS to indicate the immi-
nent arrival of a sensitive input, a central challenge in the
Bumpy design is enabling the user to verify for what desti-
nation site the input will be prepared and sent. Since the un-
trusted platform itself, including the display, is presumed to
be controlled by malware, the original Bumpy design [17]
suggested conveying this information to the user via a sep-
arate device, termed a Trusted Monitor (TM). For example,
the TM could be implemented using a dedicated token in the
form factor of a ﬂash drive, or it could even be implemented
by a user’s cell phone (albeit with the risks that would come
with employing a general-purpose device potentially with
its own vulnerabilities).
Typing a SAS and checking a TM for the proper destina-
tion for the forthcoming sensitive input might seem straight-
forward, particularly to computer security researchers.
However, faithfully following this procedure and reacting
appropriately in the face of unexpected results — poten-
tially caused by the malware that Bumpy is trying to protect
against — requires that the user adopt a degree of suspicion
of her own computer that, to our knowledge, has not pre-
viously been achieved among non-expert users. As such, if
malware can convince users to disclose their sensitive data
despite the presence of Bumpy (i.e., by causing them to mis-
use the system), then there is little point in deploying the
system.
In this paper, we evaluate the usability of the original
Bumpy design, hereafter referred to as Original, alongside
three other novel designs that we propose here. In the ﬁrst,
called Graphical, the entry of the SAS is replaced by a
graphical process for indicating forthcoming sensitive in-
put. In the second, called NoTM, the user enters a per-site
SAS to proactively instruct Bumpy as to which site the sub-
sequent sensitive input should be sent, thereby rendering the
TM unnecessary. In the third, called Challenge, the SAS is
entered as in Original, after which the TM displays a chal-
lenge that the Bumpy module expects to receive prior to the
sensitive input, thereby making inspection of the TM a non-
bypassable part of entering sensitive input.
We evaluate each of the four designs both in terms of
its imposition on the normal login process (impact on delay
and success rate) and in terms of users’ abilities to bene-
ﬁt from its protections despite the contrary efforts of mal-
ware. We performed this evaluation with a four-month user
study involving 85 participants, the overwhelming majority
of which were undergraduate college students majoring in
ﬁelds other than computer science or engineering. Each of
these 85 students was assigned to use one of the four Bumpy
variants described above to log into a course web page for
an entire semester (i.e., to protect her course login pass-
word) or to use a regular password login (Control). In this
user study, we subjected users to phases of normal system
use and to phases in which we simulated potent malware at-
tacks to trick them into divulging their passwords. We fol-
lowed the attack phase with an additional phase where users
were warned about the mistakes they made when faced with
simulated attacks. These warnings served as a form of train-
ing, and we analyze their effectiveness through additional
simulated attacks.
Through these phases, we were able to identify rela-
tive strengths and weaknesses of our designs and quantify
the degree of protection for sensitive data that the various
Bumpy designs can offer. Notably, we uncovered evidence
that the new designs that we introduce here yield the best re-
sults for many of the measures we studied, thereby improv-
ing over the original Bumpy design. That said, our study
does not conclude that one design is uniformly better than
all others. For example, the evidence suggests that some de-
signs are more secure while others yield faster login times.
Viewed more broadly, our study provides a number of
insights that may be useful in other contexts. Our study pro-
vides support for the usability of secure attention sequences
and to the better security afforded by interactive security
indicators (versus ones that a user is asked to simply ob-
serve). It also demonstrates that passive warnings are only
partially effective in molding user behavior. We also be-
lieve our study supports the conclusion that without train-
ing, users will face difﬁculties in distinguishing changes in
security-sensitive procedures (in our case, induced by mal-
ware attacks) from common discontinuities in the software
experience, i.e., failures or updates that change software be-
havior, often in subtle ways.
2 Related Work
Bumpy falls within the general class of approaches to ad-
dress the challenge of securely interacting with or through
an untrusted computer (e.g., [1, 2, 4, 11, 13, 18, 19, 23, 26,
27]). We believe that the results of our study can inform
other usability studies in this domain and potentially the de-
sign of alternative user experiences in this domain. In par-
ticular, common to many of these schemes is a secondary,
trusted device, such as the user’s smartphone or a dedicated
USB device.
In Bumpy’s original design (Original), this
secondary trusted device is the Trusted Monitor. The al-
ternative user experiences that we develop here — one that
eliminates the use of a TM (NoTM) and two others that re-
tain the TM but that alter the user experience (Graphical and
Challenge) — have parallels in other schemes, and our us-
ability results should be instructive in selecting from among
candidate designs elsewhere. Our results also underscore
the need to perform usability studies of these alternative ar-
chitectures to better understand the relative usability advan-
tages of architectures based on entering sensitive input into
a trusted mobile device (e.g., [1, 4, 11, 18, 19, 13, 26, 27]),
leveraging a trusted remote proxy in the “cloud” (e.g., [23]),
and employing a trusted virtualization layer (e.g., [2, 11]).
Bumpy’s user experience bears some similarity to tech-
niques developed to generate distinct domain-speciﬁc pass-
words from a single password, either for protecting pri-
vacy (e.g., LPWA [10]) or to defend against phishing at-
tacks (e.g., PwdHash [22]). Bumpy’s similarity to these
systems lies primarily in the user’s input of a secure atten-
tion sequence to convey instructions to the trusted module
that produces the domain-speciﬁc passwords. Chiasson et
al. performed a usability study of PwdHash and concluded
that it provides insufﬁcient user feedback [3]. Users were
unable to discern whether PwdHash was actually working,
resulting in situations where users reported that PwdHash
was easy to use and protecting their passwords when in fact
protections were disabled. This ﬁnding helps to motivate
the presence of a feedback mechanism in three of the four
Bumpy designs we considered.
Considerable work has been done regarding security in-
dicators and how they are often unnoticed or misinterpreted
by users (e.g., [6]). Researchers have tracked users’ eye
movements [29, 33] to determine whether they look at pas-
sive security indicators [9, 36], often ﬁnding that even the
complete disappearance of common security indicators is
ignored [25]. As the user is asked to pay attention to the
passive website destination indicator on her TM to thwart
attacks when using Original, these lessons from previous
studies motivate the other designs that we explore here. One
such design (Challenge) seemingly requires the user to pay
attention to the indicator so that she can transcribe two dig-
its, and another (NoTM) eliminates the indicator and en-
ables the user to gain assurance proactively. Our study can
inform others as to the effectiveness of such strategies to
combat user ambivalence towards security indicators.
Interactive training methods have had success in educat-
ing users about security attacks (e.g., [28]). This motivated
our evaluation of a similar training regimen in one phase of
our study.
3 The Bumpy User Experience
Here we describe the user experience of the original
Bumpy design, denoted Original, and how our other de-
signs Graphical, NoTM, and Challenge might appear to
the user as implemented with the low-level security mech-
anisms leveraged by the actual Bumpy system. Here we
focus on the user experiences exclusively, deferring to §4.1
the details of how we simulated these user experiences in
our study.
3.1 Original Design – Original
Bumpy is motivated by the desire to allow users to pro-
tect arbitrary input to web forms in the face of malware on
the user’s local system, e.g., keyloggers. Arbitrary input
means that the user can actively choose which data to pro-
tect. Logical choices include, but are not limited to, pass-
words and ﬁnancial account numbers.
Users are equipped with an external device called a
Trusted Monitor (TM). In practice this may be a dedicated
device, or it may be functionality offered by, e.g., smart-
phones. The TM serves as a trusted output device for infor-
mation about the user’s input, as the Bumpy design allows
for the user’s OS to be malicious. The TM receives this
input (in a cryptographically protected way) from a Bumpy
module that processes user inputs before releasing them to
the untrusted platform. The Bumpy module itself is pro-
tected from the OS with hardware-enforced isolation (see
Appendix A).
Consider a user who is providing input to a web form.
For example, she may be trying to log into an access-
controlled website, or she may be going through the check-
out process while making an online purchase. While inter-
acting with a web form, the Bumpy user takes the following
steps:
The user decides to protect the current form ﬁeld. Al-
lowing users to choose which data to protect is a feature of
Bumpy’s design. The following steps assume the user has
chosen to protect the current ﬁeld.
The user preﬁxes her input with a secure attention se-
quence (SAS). The Bumpy module detects that the user is
preparing to provide data that she considers sensitive when
it receives a SAS. Bumpy uses @@ as the SAS. Thus, the
user’s responsibility is to preﬁx her forthcoming sensitive
input with @@.
The user veriﬁes the destination for her input on the
Trusted Monitor. When the Bumpy module receives a
SAS, it updates the TM with information about the desti-
nation for forthcoming input. We chose to use the domain
name of the destination website and that website’s favicon
as a graphic logo for the website, since this information is
already readily available.1 The TM is further speciﬁed to
beep when updated, thereby providing two properties: (i) It
attracts the user’s attention and reminds her to check the in-
formation displayed on the TM; and (ii) It provides a timely
acknowledgment of the reception of the user’s SAS. Thus,
the user’s responsibility is to verify that the site information
displayed by the TM does indeed correspond to the website
where she wants her input to go. While the user’s primary
display may be controlled by malware and display anything
an attacker desires, the TM will always display where sen-
sitive input will truly go.
The user types her input. If satisﬁed with the information
displayed on the TM, the user now types her secret input.
This input will always appear as asterisks, even if the cur-
rent input ﬁeld is not a password ﬁeld, as the keystrokes
are intercepted and queued by the Bumpy module, with
asterisks released to the untrusted platform in their place.
She may use the backspace or arrow keys to correct mis-
takes. The end of sensitive input is signaled to the Bumpy
module by an input event that would cause a blur in the
web browser’s GUI. As such, the user does not need to
consciously indicate that she has ﬁnished sensitive input
to a given ﬁeld. However, because Bumpy interprets input
events that cause blurs to be meaningful, switching between
input ﬁelds before they are fully populated interrupts the se-
cure input process.
In summary, the main changes to the user experience are:
(a) She must decide which data to protect using Bumpy. (b)
She must remember to enter the SAS and conﬁrm that the
TM displays her intended destination for her input, before
entering that data. (c) Her sensitive input appears on-screen
as asterisks.
3.2 Alternative Designs
We now discuss the user experiences of our novel al-
ternative designs Graphical, NoTM, and Challenge, as in-
formed by the underlying hardware-enforced isolation tech-
nologies employed by the original Bumpy architecture.
These designs differ from Original primarily in how a user
signals to Bumpy that forthcoming input should be treated
as sensitive. In all cases, the end of sensitive input is sig-
naled to the Bumpy module by an input event that would
cause a blur in the web browser’s GUI.
1An alternative design is to allow this information to be chosen by the
user, perhaps in the spirit of PetNames [30]. We caution that if the infor-
mation can be freely speciﬁed by the destination website, then an attacker
may register a legitimate SSL certiﬁcate for a site under his control and
imitate the information of another site. Bumpy proposed drawing this in-
formation from the website’s SSL certiﬁcate – see Appendix A for details.
3.2.1 Graphical SAS – Graphical
This design alternative tests whether a graphical means to
denote sensitive input is more usable than a character-based
SAS (@@). Instead of preﬁxing sensitive input with a SAS,
users double-click within an input ﬁeld to toggle its sen-
sitivity. The sensitivity of an input ﬁeld is indicated by its
background color. We use green to indicate a ﬁeld that is de-
noted sensitive, and red to denote a ﬁeld that is unprotected
(the default). This design retains the TM and the operation
of the TM is unchanged from Original. The TM updates its
display when the user’s double-click within a ﬁeld toggles
that ﬁeld to sensitive.
We caution that this design alternative is challenging to
implement with the original Bumpy architecture because
of its dependence on a trustworthy GUI — a requirement
that is at odds with the assumption of malware on the
user’s computer. However, we believe it is important to
discover whether a graphical SAS is signiﬁcantly more us-
able than the character-based SAS of Original, NoTM, and
Challenge, and so we included this test despite its imple-
mentation challenges.
3.2.2 No Trusted Monitor – NoTM
This design alternative eliminates the need for a TM. With-
out a TM, there is no trustworthy path through which the
user can receive feedback about the destination for her
forthcoming sensitive input. NoTM addresses this chal-
lenge by supporting a unique SAS for each destination,
thereby allowing the user to specify the destination for her
forthcoming sensitive input proactively. Instead of @@, the
SAS is deﬁned to be @str@, where str is a user-chosen
string. The user can assign a particular string to a given
website by using the $ character instead of the @, i.e., $str$
will assign @str@ to be the SAS for the active website. Note
that this is a trust-on-ﬁrst-use model, in that there is no feed-
back mechanism by which the user can gain additional as-
surance of which site is bound to @str@. While problematic
at a completely unfamiliar computer like an internet kiosk,
this model is useful for computers that the user employs reg-
ularly but still does not completely trust (such as a shared
family computer).
While at ﬁrst glance this need to remember a per-site
SAS may seem to place a burden on the user’s already over-
taxed memory, str does not need to be secret. Only its in-
tegrity is required, and this is readily achieved because the
Bumpy module processes the user’s input stream before the
untrusted platform. Thus, a reasonable convention is for
str to be the ﬁrst few characters of the destination’s domain
name, e.g., ama for amazon.com. The user would then en-
ter $ama$ upon her ﬁrst visit to amazon.com, and subse-
quently preﬁx sensitive input intended for amazon.com with
@ama@. Note that by ﬁrst visit, we truly mean one visit;
Bumpy will remember the SAS assignments between ses-
sions. A user can even have more than one SAS for the
same website.
The intention of this design is to determine whether al-
lowing users to specify destinations for their sensitive inputs
proactively is a more usable interface for Bumpy. There is
reason to predict that NoTM would be comparatively effec-
tive, given the propensity of users to ignore passive security
indicators (e.g., SSL indicators [31] and anti-phishing tool-
bars [36]) and given that preﬁxing a sensitive input with a
per-destination SAS can be viewed as a type of direct navi-
gation (i.e., keyboard entry of a familiar website URL).
3.2.3 Random Challenge – Challenge
This design alternative is intended to require the user to
look at the TM. This is again motivated by the tendency
of users to ignore passive security indicators. Through this
design we seek to determine whether being required to look
at the TM will increase the likelihood that users will notice
if the TM is displaying an incorrect destination domain and
graphic logo.
To force the user to examine the TM, Challenge displays
a random 2-digit challenge value xy on the TM that must
be entered as part of the SAS for this login attempt. More
speciﬁcally, after the user clicks into a particular input ﬁeld
and enters @@ as the ﬁrst part of the SAS, the TM will up-
date its display to include a random two-digit challenge xy
sent to it by the Bumpy module. The user then enters this
challenge as the remainder of her SAS, yielding the full
SAS @@xy, and then immediately follows this with her sen-
sitive input. If it does not receive the values xy immediately
following the @@, the Bumpy module will discard the sen-
sitive input characters, thereby ensuring that they are not
leaked to malware.
4 User Study Methodology