• 
In a typical sample of text in the English language, is it more likely that a word starts 
with the letter K or that K is its third letter (not counting words with less than three 
letters)? 
Nearly 70% of people said that there were more words that started with K, even though 
there are nearly twice as many words with K in the third position as there are words that start 
with K.  But since words that start with K are easier to generate in one’s mind, people 
overestimate their relative frequency. 
In another, more real-world, experiment,32 subjects were divided into two groups.  One 
group was asked to spend a period of time imagining its college football team doing well during 
the upcoming season, and the other group was asked to imagine its college football team doing 
poorly.  Then, both groups were asked questions about the team’s actual prospects.  Of the 
subjects who had imagined the team doing well, 63% predicted an excellent season.  Of the 
subjects who had imagined the team doing poorly, only 40% did so.   
The same researcher performed another experiment before the 1976 presidential election.  
Subjects asked to imagine Carter winning were more likely to predict that he would win, and 
subjects asked to imagine Ford winning were more likely to believe he would win.  This kind of 
experiment has also been replicated several times, and uniformly demonstrates that considering 
a particular outcome in one’s imagination makes it appear more likely later. 
The vividness of memories is another aspect of the availability heuristic that has been 
studied.  People’s decisions are more affected by vivid information than by pallid, abstract, or 
statistical information. 
Here’s just one of many experiments that demonstrates this.33  In the first part of the 
experiment, subjects read about a court case involving drunk driving.  The defendant had run a 
stop sign while driving home from a party and collided with a garbage truck.  No blood alcohol 
test had been done, and there was only circumstantial evidence to go on.  The defendant was 
arguing that he was not drunk. 
After reading a description of the case and the defendant, subjects were divided into two 
groups and given eighteen individual pieces of evidence to read: nine written by the prosecution 
about why the defendant was guilty, and nine written by the defense about why the defendant 
was innocent.  Subjects in the first group were given prosecution evidence written in a pallid 
style and defense evidence written in a vivid style, while subjects in the second group were given 
the reverse. 
For example, here is a pallid and vivid version of the same piece of prosecution evidence: 
• 
On his way out the door, Sanders [the defendant] staggers against a serving table, 
knocking a bowl to the floor. 
• 
On his way out the door, Sanders staggered against a serving table, knocking a bowl 
of guacamole dip to the floor and splattering guacamole on the white shag carpet. 
And here’s a pallid and vivid pair for the defense: 
The Psychology of Security—DRAFT 
15 
• 
The owner of the garbage truck admitted under cross-examination that his garbage 
truck is difficult to see at night because it is grey in color. 
• 
The owner of the garbage truck admitted under cross-examination that his garbage 
truck is difficult to see at night because it is grey in color.  The owner said his trucks 
are grey “because it hides the dirt,” and he said, “What do you want, I should paint 
them pink?” 
After all of this, the subjects were asked about the defendant’s drunkenness level, his guilt, 
and what verdict the jury should reach. 
The results were interesting.  The vivid vs. pallid arguments had no significant effect on the 
subject’s judgment immediately after reading them, but when they were asked again about the 
case 48 hours later—they were asked to make their judgments as though they “were deciding the 
case now for the first time”—they were more swayed by the vivid arguments.  Subjects who read 
vivid defense arguments and pallid prosecution arguments were much more likely to judge the 
defendant innocent, and subjects who read the vivid prosecution arguments and pallid defense 
arguments were much more likely to judge him guilty. 
The moral here is that people will be persuaded more by a vivid, personal story than they 
will by bland statistics and facts, possibly solely due to the fact that they remember vivid 
arguments better. 
Another experiment34 divided subjects into two groups, who then read about a fictional 
disease called “Hyposcenia-B.”  Subjects in the first group read about a disease with concrete 
and easy-to-imagine symptoms: muscle aches, low energy level, and frequent headaches.  
Subjects in the second group read about a disease with abstract and difficult-to-imagine 
symptoms: a vague sense of disorientation, a malfunctioning nervous system, and an inflamed 
liver. 
Then each group was divided in half again.  Half of each half was the control group: they 
simply read one of the two descriptions and were asked how likely they were to contract the 
disease in the future.  The other half of each half was the experimental group: they read one of 
the two descriptions “with an eye toward imagining a three-week period during which they 
contracted and experienced the symptoms of the disease,” and then wrote a detailed description 
of how they thought they would feel during those three weeks.  And then they were asked 
whether they thought they would contract the disease. 
The idea here was to test whether the ease or difficulty of imagining something affected the 
availability heuristic.  The results showed that those in the control group—who read either the 
easy-to-imagine or difficult-to-imagine symptoms, showed no difference.  But those who were 
asked to imagine the easy-to-imagine symptoms thought they were more likely to contract the 
disease than the control group, and those who were asked to imagine the difficult-to-imagine 
symptoms thought they were less likely to contract the disease than the control group.  The 
researchers concluded that imagining an outcome alone is not enough to make it appear more 
likely; it has to be something easy to imagine.  And, in fact, an outcome that is difficult to 
imagine may actually appear to be less likely. 
Additionally, a memory might be particularly vivid precisely because it’s extreme, and 
therefore unlikely to occur.  In one experiment,35 researchers asked some commuters on a train 
platform to remember and describe “the worst time you missed your train” and other commuters 
to remember and describe “any time you missed your train.”  The incidents described by both 
groups were equally awful, demonstrating that the most extreme example of a class of things 
tends to come to mind when thinking about the class. 
The Psychology of Security—DRAFT 
16 
More generally, this kind of thing is related to something called “probability neglect”: the 
tendency of people to ignore probabilities in instances where there is a high emotional content.36  
Security risks certainly fall into this category, and our current obsession with terrorism risks at 
the expense of more common risks is an example. 
The availability heuristic also explains hindsight bias.  Events that have actually occurred 
are, almost by definition, easier to imagine than events that have not, so people retroactively 
overestimate the probability of those events.  Think of “Monday morning quarterbacking,” 
exemplified both in sports and in national policy.  “He should have seen that coming” becomes 
easy for someone to believe.  
The best way I’ve seen this all described is by Scott Plous: 
In very general terms: (1) the more available an event is, the more frequent or 
probable it will seem; (2) the more vivid a piece of information is, the more easily recalled 
and convincing it will be; and (3) the more salient something is, the more likely it will be to 
appear causal.37 
Here’s one experiment that demonstrates this bias with respect to salience.38  Groups of six 
observers watched a two-man conversation from different vantage points: either seated behind 
one of the men talking or sitting on the sidelines between the two men talking.  Subjects facing 
one or the other conversants tended to rate that person as more influential in the conversation: 
setting the tone, determining what kind of information was exchanged, and causing the other 
person to respond as he did.  Subjects on the sidelines tended to rate both conversants as equally 
influential. 
As I said at the beginning of this section, most of the time the availability heuristic is a good 
mental shortcut.  But in modern society, we get a lot of sensory input from the media.  That 
screws up availability, vividness, and salience, and means that heuristics that are based on our 
senses start to fail.  When people were living in primitive tribes, if the idea of getting eaten by a 
saber-toothed tiger was more available than the idea of getting trampled by a mammoth, it was 
reasonable to believe that—for the people in the particular place they happened to be living—it 
was more likely they’d get eaten by a saber-toothed tiger than get trampled by a mammoth.  But 
now that we get our information from television, newspapers, and the Internet, that’s not 
necessarily the case.  What we read about, what becomes vivid to us, might be something rare 
and spectacular.  It might be something fictional: a movie or a television show.  It might be a 
marketing message, either commercial or political.  And remember, visual media is more vivid 
than print media.  The availability heuristic is less reliable, because the vivid memories we’re 
drawing upon aren’t relevant to our real situation.  And even worse, people tend not to 
remember where they heard something—they just remember the content.  So even if, at the time 
they’re exposed to a message they don’t find the source credible, eventually their memory of the 
source of the information degrades and they’re just left with the message itself ((reference?)). 
We in the security industry are used to the effects of the availability heuristic.  It contributes 
to the “risk du jour” mentality we so often see in people.  It explains why people tend to 
overestimate rare risks and underestimate common ones.39  It explains why we spend so much 
effort defending against what the bad guys did last time, and ignore what new things they could 
do next time.  It explains why we’re worried about risks that are in the news at the expense of 
risks that are not, or rare risks that come with personal and emotional stories at the expense of 
risks that are so common they are only presented in the form of statistics. 
It explains most of the entries in Table 1. 
The Psychology of Security—DRAFT 
17 
Representativeness 
“Representativeness” is a heuristic by which we assume the probability that an example 
belongs to a particular class is based on how well that example represents the class.  On the face 
of it, this seems like a reasonable heuristic.  But it can lead to erroneous results if you’re not 
careful. 
The concept is a bit tricky, but here’s an experiment makes this bias crystal clear.40  
Subjects were given the following description of a woman named Linda: 
Linda is 31 years old, single, outspoken, and very bright.  She majored in philosophy.  
As a student, she was deeply concerned with issues of discrimination and social justice, and 
also participated in antinuclear demonstrations. 
Then the subjects were given a list of eight statements describing her present employment 
and activities.  Most were decoys (“Linda is an elementary school teacher,” “Linda is a 
psychiatric social worker,” and so on), but two were critical: number 6 (“Linda is a bank teller,” 
and number 8 (“Linda is a bank teller and is active in the feminist movement”).  Half of the 
subjects were asked to rank the eight outcomes by the similarity of Linda to the typical person 
described by the statement, while others were asked to rank the eight outcomes by probability. 
Of the first group of subjects, 85% responded that Linda more resembled a stereotypical 
feminist bank teller more than a bank teller.  This makes sense.  But of the second group of 
subjects, 89% of thought Linda was more likely to be a feminist bank teller than a bank teller.  
Mathematically, of course, this is ridiculous.  It is impossible for the second alternative to be 
more likely than the first; the second is a subset of the first.   
As the researchers explain:  “As the amount of detail in a scenario increases, its probability 
can only decrease steadily, but its representativeness and hence its apparent likelihood may 
increase.  The reliance on representativeness, we believe, is a primary reason for the 
unwarranted appeal of detailed scenarios and the illusory sense of insight that such 
constructions often provide.”41 
Doesn’t this sound like how so many people resonate with movie-plot threats—overly 
specific threat scenarios—at the expense of broader risks? 
In another experiment,42 two groups of subjects were shown short personality descriptions 
of several people.  The descriptions were designed to be stereotypical for either engineers or 
lawyers.  Here’s a sample description of a stereotypical engineer: 
Tom W. is of high intelligence, although lacking in true creativity.  He has a need for 
order and clarity, and for neat and tidy systems in which every detail finds its appropriate 
place.  His writing is rather dull and mechanical, occasionally enlivened by somewhat corny 
puns and flashes of imagination of the sci-fi type.  He has a strong drive for competence.  
He seems to have little feel and little sympathy for other people and does not enjoy 
interacting with others.  Self-centered, he nonetheless has a deep moral sense. 
 Then, the subjects were asked to give a probability that each description belonged to an 
engineer rather than a lawyer.  One group of subjects was told this about the population from 
which the descriptions were sampled: 
• 
Condition A:  The population consisted of 70 engineers and 30 lawyers. 
The second group of subjects was told this about the population: 
• 
Condition B:  The population consisted of 30 engineers and 70 lawyers. 
The Psychology of Security—DRAFT 
18 
Statistically, the probability that a particular description belongs to an engineer rather than 
a lawyer should be much higher under Condition A than Condition B.  However, subjects judged 
the assignments to be the same in either case.  They were basing their judgments solely on the 
stereotypical personality characteristics of engineers and lawyers, and ignoring the relative 
probabilities of the two categories. 
Interestingly, when subjects were not given any personality description at all and simply 
asked for the probability that a random individual was an engineer, they answered correctly: 
70% under Condition A and 30% under Condition B.  But when they were given a neutral 
personality description, one that didn’t trigger either stereotype, they assigned the description to 
an engineer 50% of the time under both Conditions A and B. 
And here’s a third experiment.  Subjects (college students) were given a survey which 
included these two questions: “How happy are you with your life in general?” and “How many 
dates did you have last month?”  When asked in this order, there was no correlation between the 
answers.  But when asked in the reverse order—when the survey reminded the subjects of how 