CONST
ENUM
GAST
NUMBER
REGEXP
URL
Total
# in Ground
Truth
95
9
0
24
10
9
147
# in
Templates
# of Correctly
Inferred
Accuracy
97
3
0
24
14
9
147
95
3
0
24
10
9
141
97.9%
100%
N/A
100%
71.4%
100%
95.9%
Figure 3: Template Matching Rate
(Medium Rate 99.2%).
Figure 4: The Loading Time of Alexa Top 50
Websites (Median Difference 9.1%).
Table 4: Real-world Applications with All Three Types of XSS Vulnerabili-
ties (Reﬂected, Stored and DOM-based)
Application
Codiad
Ektron CMS
FoeCMS
JForum
LiteCart
OrchardCMS
Version
2.4.3
9.1.0
0.0.1
2.1.9
1.1.2.1
1.9.0
Vulnerability
CVE-2014-9582
CVE-2015-4427
CVE-2014-4849
CVE-2012-5337
CVE-2014-7183
CVE-2015-5520
Language
PHP
ASP.NET
PHP
JAVA
PHP
ASP.NET
LOC
8,989
NA
17,943
61,247
29,175
109,467
human works involved in the evaluation, we use WordPress 4.2.3
as an example for the evaluation.
Our methodology is as follows. For each inline script in the
WordPress source code, we ﬁnd the corresponding template, and
manually compare each PHP part (i.e., runtime information) in the
inline script with each type in the template. For example, if the
type in the template is a URL, and the corresponding PHP variable
value of the inline script in the source code can only be URL, we
will consider the type in the template correctly inferred.
The evaluation results are shown in Table 3. The number of each
type in the WordPress source code, and the number of each type in-
ferred by CSPAutoGen in the templates are listed in the second and
third column respectively. We also list the number of correctly in-
ferred for each type and the corresponding accuracy. First, note that
the total numbers for all the types in both WordPress and templates
are exactly the same, indicating that CSPAutoGen correctly ﬁnds
all the possible locations. Second, the overall inference accuracy is
95.9%, a very high number. In some cases, the inferred types by
CSPAutoGen are looser or stricter than the one in WordPress. Par-
ticularly, two CONST types should be ENUM, and four REGEXP
types should be ENUM. The stricter inference (ENUM as CONST)
is because of missing values not captured in the training samples;
correspondingly, the looser inference (ENUM as REGEXP) is due
to the fact that the number of samples with those scripts is smaller
than our default threshold (i.e., 120). In this experiment, the de-
ployed WordPress contains only a few default pages, i.e., in real-
world websites, we expect the accuracy will be even higher, be-
cause the number of samples should reach the threshold, and the
number of training samples will be also larger.
6.4 Security
We evaluate the security of CSPAutoGen in three experiments.
First, we measure whether and how CSPAutoGen can successfully
protect real-world vulnerable applications against existing XSS at-
tacks. Second, as discussed in our type system, we manually re-
view the ﬂexible types, i.e., REGEXP types with sensitive charac-
ters such as ‘%’, ‘.’ and ‘:’. Third, from Alexa Top 50 websites, we
ﬁnd those with CSP deployed and compare their conﬁgured CSPs
with the CSPs generated by CSPAutoGen.
Real-world Applications. To evaluate the security of our system,
we apply CSPAutoGen on six real-world web applications (written
in ASP.NET, Java and PHP) with XSS vulnerabilities listed in Ta-
ble 4. Codiad is a lightweight and interactive web IDE; FoeCMS
is a content management application that is largely used in the
Spanish world; Litecart is a free development platform to build
e-commerce websites. These three applications are all written in
PHP. Orchard CMS and Ektron CMS are both content management
system written in ASP.NET. The former is open source, while the
latter is not. JForum is a lightweight discussion board system im-
plemented in Java. The involved vulnerabilities of these six appli-
cations cover all the three types of XSS, that is, reﬂected, stored
and DOM-based XSS attacks. In the table, we list the applications’
names, versions, vulnerabilities, languages and lines of codes.
We deploy the six applications and initiate XSS attacks against
them. The attacking payloads are created by XCampo [46], a popu-
lar XSS payload generator. We ﬁrst verify that these exploits work
on the applications. Then we deploy CSPAutoGen at the entrance
of each application and initiate the same attacks again. The eval-
uation results indicate none of these attacks succeed, showing that
CSPAutoGen defeats against all the three types of XSS attacks.
Manual Reviewing Flexible Types. We count the number of gASTs,
nodes, atom data nodes, complex data nodes, types and ﬂexible
types from the templates of Alexa Top 50 websites. The results are
shown in Table 5: ﬂexible types only account for 1.4% of all the
types. Further analysis shows that on average, four gASTs have one
data node or ﬁeld assigned with ﬂexible type; the number of ﬂexi-
ble type for each domain template ranges from 1 (e.g., ask.com) to
243 (i.e., amazon.com) with the median of 81 (i.e., baidu.com).
We then evaluate the workload of manual reviewing ﬂexible types.
We randomly pick out ﬁve websites (aliexpress.com, reddit.com,
taobao.com, weibo.com and youtube.com). The numbers of their
ﬂexible types are 121, 6, 59, 27 and 90 respectively. With the help
of visual template portal (Section 4.3), one student reviews and
modiﬁes these ﬂexible types in 2 days (16 hours). Our reviewing
shows that no ﬂexible type in these templates needs to be changed
to more restrictive ones. Also, fully understanding those reviewed
scripts are not required because the visual template portal lists all
the training samples and highlights the corresponding values.
Comparison with existing websites’ CSPs. Among Alexa Top
50 websites, six websites (facebook.com, twitter.com, yandex.ru,
mail.ru, pinterest.com and alibaba.com) have conﬁgured CSPs. How-
ever, ﬁve out of the six set both keywords “unsafe-inline” and “unsafe-
eval” in their CSPs, and the remaining one (twitter.com) sets “unsafe-
eval”. “unsafe-inline” still allows an attacker to inject scripts via
both stored and reﬂected XSS, and “unsafe-eval” allows DOM-
based XSS attacks. As a comparison, the CSPs generated by CSPAu-
toGen set neither “unsafe-inline” nor “unsafe-eval”, being more se-
cure than CSPs used in any of the six websites. That is, CSPAuto-
Gen can even help existing websites that partially adopt CSP and
enhance their security.
01020304050Websites9092949698100MatchingRate(%)051015202530LoadingTime(s)0.00.10.20.30.40.50.60.70.80.91.0PercentageofPagesWithCSPAutoGenWithoutCSPAutoGenTable 5: Templates Statistics of the Alexa Top 50 Websites.
gAST
Number
20,888
Total
Node
1,922,147
Atom
Data Node
225,807
Complex
Data Node
57,391
Type
322,194
Flexible
Type
4,580
Table 6: The Breakdown of CSPAutoGen Latency.
Min (ms) Median (ms) Max (ms)
1349.00
112.62
Latency Source
DOM Tree Parsing
Script Transmission (Rewriting Phase)
gAST Building
Template Matching
Runtime-included Script
Symbolic Template
1.97
23
∼0
∼0
9
∼0
51
0.2
0.1
107
9
332
33
0.5
1419
64
6.5 Performance Overhead
We ﬁrst evaluate CSPAutoGen’s overhead by calculating the time
difference of browsing Alexa Top 50 Websites with and without
CSPAutoGen. To have a better understanding of the performance,
we break down the overhead and measure the latency of DOM Tree
parse, JavaScript AST generation, template matching, and handling
runtime-included scripts and dynamic scripts.
Overall Latency Overhead. In this experiment, we deploy CSPAu-
toGen’s applier engine in a middlebox proxy, which runs on a 2.20
GHz Intel Xeon E5 server with 64GB RAM running Ubuntu 14.04.
Other CSPAutoGen components, including JavaScript server, vio-
lation report server and whitelist server, all run on the same server
but listen to different port. We refer to this server as CSPAuto-
Gen server. The client-side machine is a 1.4GHz Intel Core i5 Mac
Air machine with 8GB RAM running OSX 10.9 and Chrome 43.
The latency between the client and the CSPAutoGen server is 0.5
ms. Then, we evaluate our Alexa dataset with and without deploy-
ing CSPAutoGen on mitmproxy. Each experiment is repeated ﬁve
times without caching contents, and we use the median value.
Figure 4 shows the evaluation results with the blue solid line as
the loading time with CSPAutoGen and the red dotted line as the
one without CSPAutoGen. The median loading time are 5.94s and
5.11s respectively. When sorted by the difference of the two load-
ing times, the median value is 470ms, i.e., 9.1%. This means that
CSPAutoGen’s median overhead for the server and middlebox de-
ployment is 9.1%. If deployed at client side, the client-perceived
overhead should be CSPAutoGen’s overhead plus a proxy or exten-
sion’s overhead depending on how it is implemented.
Latency Overhead Breakdown. To have a better understanding
of CSPAutoGen’s latency, we break down its latency into the fol-
lowing categories (1) DOM Tree parsing, (2) scripts transmission
(sending all scripts in a webpage to JavaScript server for match-
ing from applier engine), (3). gAST building, (4) template match-
ing, (5) handling runtime-included script, and (6) handing dynamic
script. We evaluate the min, max and median value for each of them
on our Alexa dataset. DOM Tree parsing and scripts transmission
happen at rewriting phase; gAST building and template matching
happen at rewriting and runtime phase; handling runtime-included
scripts and dynamic scripts both happen at runtime phase.
Table 6 shows the evaluation results. Note that the time precision
of JavaScript is 1ms, so when evaluating the latency of JavaScript-
related codes, we repeat each snippet of codes to be measured for
ten times and then calculate the average number. For the ones
whose ten-time latency is still zero, we record them as ∼0, indi-
cating those latency negligible. From Table 6, the biggest overhead
comes from handling runtime-included script and DOM Tree pars-
ing. For the former, it works asynchronously and thus incurs little
overhead on the system; the later contributes most to the CSPAuto-
Gen’s overhead. One future work is to improve the performance by
replacing CSPAutoGen’s HTML parser (we now use html5lib [7],
Table 7: Script Matching Rates in Behind-the-login Functionality Experiment.
Domain
Runtime-included
Function
Eval
setTimeout &
setInterval
Inline Script
Amazon
Gmail
Google
Linkedin
Yahoo
100%
(48/48)
100%
(134/134)
100%
(182/182)
100%
(27/27)
N/A
(0/0)
100%
(168/168)
75%
(3/4)
N/A
(0/0)
100%
(81/81)
100%
(38/38)
99.6%
(69,221/69,499)
97.8%
(4,313/4,411)
98.0%
(539/550)
92.1%
(70/76)
99.8%
(1,602/1,606)
99.8%
(4,998/5,008)
98.8%
(2,038/2,061)
97.0%
(875/902)
89.6%
(831/927)