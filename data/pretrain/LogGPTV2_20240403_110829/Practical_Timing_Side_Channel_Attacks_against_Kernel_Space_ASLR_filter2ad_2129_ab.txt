(8, 192∗1, 024)/64 = 131, 072 single slots that are grouped into
131, 072/16 = 8, 192 different sets. Hence, 13 bits are needed
to select the appropriate set. Since the lower 6 bits (starting with
bit 0) of each address are used to select one particular byte from
each cacheline, the bits 18 to 6 determine the set. The remaining
upper 13 bits form the address tag, that has to be stored with
each cache line for the later lookup.
One essential consequence of the set associativity is that
memory addresses with identical index bits compete against
the available slots of one set. Hence, memory accesses may
193
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:55:20 UTC from IEEE Xplore.  Restrictions apply. 
evict and replace other memory content from the caches. One
common replacement strategy is Least Recently Used (LRU), in
which the entry which has not been accessed for the longest time
is replaced. Since managing real timestamps is not affordable in
practice, the variant Pseudo-LRU is used: an additional reference
bit is stored with each cacheline that is set on each access. Once
all reference bits of one set are enabled, they are all cleared
again. If an entry from a set has to be removed, an arbitrary
one with a cleared reference bit is chosen.
Virtual Memory and Address Translation: Contemporary
operating systems usually work on paged virtual memory in-
stead of physical memory. The memory space is divided into
equally sized pages that are either regular pages (e.g., with
a size of 4 KB), or large pages (e.g., 2 or 4 MB). When
accessing memory via virtual addresses (VA), they ﬁrst have
to be translated into physical addresses (PA) by the processor’s
Memory Management Unit (MMU) in a page walk: the virtual
address is split into several parts and each part operates as an
array index for certain levels of page tables. The lowest level
of the involved paging structures (PS), the Page Table Entry
(PTE), contains the resulting physical frame number. For large
pages, one level less of PS is needed since a larger space of
memory requires less bits to address. In that case, the frame
number is stored one level higher in the Page Directory Entry
(PDE). In case of Physical Address Extension (PAE) [30] or
64-bit mode, additional PS levels are required, i.e. the Page
Directory Pointer (PDP) and the Page Map Level 4 (PML4)
structures. Appendix A provides more information and examples
of such address resolutions for PAE systems.
In order to speed up this address translation process, resolved
address mappings are cached in Translation Lookaside Buffers
(TLBs). Additionally, there often are dedicated caches for the
involved higher level PS [31]. Depending on the underlying
system, the implementation of these translation caches differs a
lot. Current x86/x64 systems usually have two different levels
of TLB: the ﬁrst stage TLB0 is split into one for data (DTLB)
and another for instructions (ITLB), and the second stage TLB1
is used for both. Further, the TLBs are often split into one part
for regular pages and another for large pages.
Even with TLBs and PS caches, the address translation takes
some clock cycles, during which the resulting physical address
is not available yet. As an effect, the system has to wait for
the address translation before it can check the tag values of the
caches. Therefore, lower caches (mostly only the L1 cache) are
virtually indexed, but physically tagged. This means that the
cache index is taken from the virtual address but the stored
tag values from the physical one. With that approach,
the
corresponding tag values already can be looked up and then
quickly compared once the physical address is available.
Figure 2 illustrates all the different caching facilities of the
Intel i7 processor. The vertical arrows are labeled with the
amount of clock cycles that are normally required to access the
particular stages [32], [33]. The dashed arrow (pointing from the
TLB1 to the DCACHE) indicates that PS are not only cached
Physical
emory
Physical Memory 
cal Me
3 Cach
L3 Cache 
C h
L2 Cache 
L2 Cachh
2 Cach
e
ICACHE 
CACHE
DCACHE 
D
DCACHE
DCACH
0
0
1
>
5
3
0
1
4
Unified TLB1 
d TLB1
Unifiedfiedf d
d
IITLB0 
ITLB0
ITLB00
ITLB 
TLB
ITLB DTLB0 
0
ITLBDTLB0
0
0
1
>
PML4/PDP/ 
PDE Cach
PDE Cache 
6
1
CPU 
MMU M
MU
MU
Figure 2.
(based on [32], [33])
Intel i7 memory hierarchy plus clock latency for the relevant stages
in the TLB or PML4/PDP/PDE caches, but may also reside as
regular data within the DCACHE or higher level uniﬁed caches.
An essential part of each virtual memory system is the page
fault handler (PFH). It is invoked if a virtual address cannot be
resolved, i.e., the page walk encounters invalid PS. This may
happen for several reasons (e.g., the addressed memory region
has been swapped out or the memory is accessed for the ﬁrst
time after its allocation). In such cases, the error is handled
completely by the PFH. Although this happens transparently,
the process induces a slight time delay. Besides translation
information, the PS also contain several protection ﬂags (e.g.,
to mark memory as non-executable or to restrict access to
privileged code only). After successful translation, these ﬂags
are checked against the current system state and in case of a
protection violation, the PFH is invoked as well. In that case an
access violation exception is generated that has to be caught and
handled by the executing process. Again, a slight time delay may
be observable between accessing the memory and the exception
being delivered to the exception handler.
III. TIMING SIDE CHANNEL ATTACKS
Based on this background information, we can now explain
how time delays introduced by the memory hierarchy enable a
side channel attack against kernel-level ASLR.
A. Attacker Model
We focus in the following on local attacks against kernel
space ASLR: we assume an adversary who already has restricted
access to the system (i.e., she can run arbitrary applications) but
does not have access to privileged kernel components and thus
cannot execute privileged (kernel mode) code. We also assume
the presence of a user mode-exploitable vulnerability within
kernel or driver code, a common problem [27]. The exploitation
of this software fault requires to know (at least portions of)
the kernel space layout since the exploit at some point either
jumps to an attacker controlled location or writes to an attacker
controlled location to divert the control ﬂow.
Since the entire virtual address space is divided in both user
and kernel space, an attacker might attempt to directly jump to a
194
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:55:20 UTC from IEEE Xplore.  Restrictions apply. 
user space address from within kernel mode in an exploit, thus
circumventing any kernel space ASLR protections. However,
this is not always possible since the correct user space might
not be mapped at the time of exploitation due to the nature of the
vulnerability [14]. Furthermore, this kind of attack is rendered
impossible with the introduction of the Supervisor Mode Execu-
tion Protection (SMEP) feature of modern CPUs that disables
execution of user space addresses in kernel mode [34].
We also assume that the exploit uses ROP techniques due to
the W ⊕X property enforced in modern operating systems. This
requires to know a sufﬁciently large amount of executable code
in kernel space to enable ROP computations [10], [35]. Schwartz
et al. showed that ROP payloads can be built automatically
for 80% of Linux programs larger than 20 KB [36]. Further,
we assume that the system fully supports ASLR and that no
information leaks exist that can be exploited. Note that a variety
of information leaks exist for typical operating systems [18], but
these types of leaks stem from shortcomings and inconsequences
in the actual implementation of the speciﬁc OS. Developers can
ﬁx these breaches by properly adjusting their implementation.
Recently, Giuffrida et al. [37] argued that kernel information
leakage vulnerabilities are hard to ﬁx. While we agree that it is
not trivial to do so, we show that even in the absence of any
leak, we can still derandomize kernel space ASLR.
One of our attacks further requires that the userland process
either has access to certain APIs or gains information about
the physical frame mapping of at least one page in user space.
However, since this prerequisite holds only for one single attack
– which further turns out to be our least effective one – we do
not consider it in the general attacker model but explain its
details only in the corresponding Section IV-A.
In summary, we assume that the system correctly implements
ASLR (i.e., the complete system is randomized and no infor-
mation leaks exist) and that it enforces the W ⊕ X property.
Hence, all typical exploitation strategies are thwarted by the
implemented defense mechanisms.
B. General Approach
In this paper, we present generic side channels against proces-
sors for the Intel ISA that enable a restricted attacker to deduce
information about the privileged address space by timing certain
operations. Such side channels emerge from intricacies of the
underlying hardware and the fact that parts of the hardware
(such as caches and physical memory) are shared between both
privileged and non-privileged code. Note that all the approaches
that we present in this paper are independent of the underlying
operating system: while we tested our approach mainly on
Windows 7 and Linux, we are conﬁdent that the attacks also
apply for other versions of Windows or even other operating
systems. Furthermore, our attacks work on both 32- and 64-bit
systems.
The methodology behind our timing measurements can be
generalized in the following way: At ﬁrst, we attempt to set the
system in a speciﬁc state from user mode. Then we measure the
duration of a certain memory access operation. The time span of
this operation then (possibly) reveals certain information about
the kernel space layout. Our timing side channel attacks can be
split into two categories:
• L1/L2/L3-based Tests: These tests focus on the L1/L2/L3
CPU caches and the time needed for fetching data and code
from memory.
• TLB-based Tests: These tests focus on TLB and PS caches
and the time needed for address translation.
To illustrate the approach, consider the following example: we
make sure that a privileged code portion (such as the operating
system’s system call handler) is present within the caches by
executing a system call. Then, we access a designated set of
user space addresses and execute the system call again. If the
system call takes longer than expected, then the access of user
space addresses has evicted the system call handler code from
the caches. Due to the structure of modern CPU caches, this
reveals parts of the physical (and possibly virtual) address of
the system call handler code as we show in our experiments.
Accessing Privileged Memory: As explained in Sec-
tion II-B, different caching mechanisms determine the duration
of a memory access:
• The TLB and PS caches speed up the translation from the
virtual to the physical address.
• In case no TLB exists, the PS entries of the memory
address must be fetched during the page walk. If any of
these entries are present in the normal L1/L2/L3 caches,
then the page walk is accelerated in a signiﬁcant (i.e.,
measurable) way.
• After the address translation, the actual memory access is
faster if the target data/code can be fetched from the L1/-
L2/L3 caches rather than from the RAM.
While it is impossible to access kernel space memory directly
from user mode, the nature of the cache facilities still enables
an attacker to indirectly measure certain side-effects. More
precisely, she can directly access a kernel space address from
user mode and measure the duration of the induced exception.
The page fault will be faster if a TLB entry for the correspond-
ing page was present. Additionally, even if a permission error
occurs, this still allows to launch address translations and, hence,
generate valid TLB entries by accessing privileged kernel space
memory from user mode.
Further, an attacker can (to a certain degree) control which
code or data regions are accessed in kernel mode by forcing
ﬁxed execution paths and known data access patterns in the
kernel. For example, user mode code can perform a system call
(sysenter) or an interrupt (int). This will force the CPU
to cache the associated handler code and data structures (e.g.,
IDT table) as well as data accessed by the handler code (e.g.,
system call table). A similar effect can be achieved to cache
driver code and data by indirectly invoking driver routines from
user mode.
Note that the x86/x64 instruction set also contains a num-
ber of instructions for explicit cache control (e.g., invlpg,
195
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:55:20 UTC from IEEE Xplore.  Restrictions apply. 
Method
Cache Probing
Double Page Fault
Cache Preloading
Requirements
large pages or PA of eviction buffer, partial informa-
tion about kernel region location
none
none
Results
ntoskrnl.exe and hal.sys
allocation map, several drivers
win32k.sys
Environment
all
all but AMD
all
Success
(cid:2)
(cid:2)
(cid:2)
SUMMARY OF TIMING SIDE CHANNEL ATTACKS AGAINST KERNEL SPACE ASLR ON WINDOWS.
Table I
invd/wbinvd, clflush, or prefetch) [30]. However,
these instructions are either privileged and thus cannot be called
from user mode, or they cannot be used with kernel space
addresses from user mode. Hence, none of these instructions
can be used for our purposes. As a result, we must rely on
indirect methods as explained in the previous paragraphs.
C. Handling Noise
test
While performing our timing measurements we have to deal
with different kinds of noise that diminish the quality of our
data if not addressed properly. Some of this noise is caused by
the architectural peculiarities of modern CPUs [22]: to reach
a high parallelism and work load, CPU developers came up
with many different performance optimizations like hardware
prefetching, speculative execution, multi-core architectures, or
branch prediction. We have adapted our measuring code to take
the effects of these optimizations into account. For example,
we do not
the memory in consecutive order to avoid
being inﬂuenced by memory prefetching. Instead, we use access
patterns that are not inﬂuenced by these mechanisms at all.
Furthermore, we have to deal with the fact that our tool is not
the only running process and there may be a high CPU load
in the observed system. The thread scheduler of the underlying
operating system periodically and, if required, also preemptively
interrupts our code and switches the execution context. If we
are further running inside a virtual machine,
there is even
more context switching when a transition between the virtual
machine monitor and the VM (or between different VMs) takes
place. Finally, since all executed code is operating on the same