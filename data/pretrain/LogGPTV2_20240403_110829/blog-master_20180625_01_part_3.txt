$$  
LANGUAGE SQL IMMUTABLE PARALLEL SAFE  
;  
create index ON json_stack (json_age(json));  
```  
Again the estimate is much better:  
```  
explain (analyze,buffers)   select * from json_stack  
      where json_age(json) = '27';  
                         QUERY PLAN  
------------------------------------------------------------------------  
 Index Scan using json_stack_json_age_idx on json_stack  
  (cost=0.56..733177.05 rows=799908 width=1011)  
  (actual time=0.042..2355.179 rows=804630 loops=1)  
   Index Cond: ((json ->> 'age'::text) = '27'::text)  
   Buffers: shared read=737720  
   I/O Timings: read=1431.275  
 Planning time: 0.087 ms  
 Execution time: 2410.269 ms  
```  
Postgres estimates to get 799,908 records. we will check it.  
As I said, Postgres has statistics information based on a sample of data. This information is stored in a readable system catalog with the ```pg_stats``` view. With a functional index, Postgres sees it as a new column.  
```  
schemaname             | public  
tablename              | json_stack_json_age_idx  
attname                | json_age  
[...]  
most_common_vals       | {28,27,29,31,26,30,32,25,33,34,36,24,[...]}  
most_common_freqs      | {0.0248,0.0240333,0.0237333,0.0236333,0.0234,0.0229333,[...]}  
[...]  
```  
The column most_common_vals contains the most common values and the column most_common_freqs the corresponding selectivity.  
So for ```age = 27``` we have a selectivity of 0.0240333.  
这里使用了表达式时，PostgreSQL 评估为一对一输出，即输入一个A值返回一个与A相关的值，所以计算选择性可以使用原始列的柱状图。  
[《PostgreSQL 11 preview - 表达式索引柱状图buckets\STATISTICS\default_statistics_target可设置》](../201805/20180519_07.md)    
https://www.postgresql.org/docs/10/static/catalog-pg-proc.html  
Then we just have to multiply the selectivity by the cardinality of the table:  
```  
select n_live_tup from pg_stat_all_tables where relname ='json_stack';  
 n_live_tup  
------------  
   33283258  
select 0.0240333 * 33283258;  
    ?column?  
----------------  
 799906.5244914  
```  
Okay, estimate is much better. But is it serious if postgres is wrong? In the two queries above we see that postgres uses an index and that the result is obtained quickly.  
### Consequences of a bad estimate  
How can a bad estimate be a problem?  
When that leads to the choice of a bad plan.  
For example, this aggregation query that counts the number of posts by age:  
```  
explain (analyze,buffers)  select json->'age',count(json->'age')  
                          from json_stack group by json->'age' ;  
                             QUERY PLAN  
--------------------------------------------------------------------------------------  
 Finalize GroupAggregate  
  (cost=10067631.49..14135810.84 rows=33283256 width=40)  
  (actual time=364151.518..411524.862 rows=86 loops=1)  
   Group Key: ((json -> 'age'::text))  
   Buffers: shared hit=1949354 read=1723941, temp read=1403174 written=1403189  
   I/O Timings: read=155401.828  
   ->  Gather Merge  
        (cost=10067631.49..13581089.91 rows=27736046 width=40)  
        (actual time=364151.056..411524.589 rows=256 loops=1)  
         Workers Planned: 2  
         Workers Launched: 2  
         Buffers: shared hit=1949354 read=1723941, temp read=1403174 written=1403189  
         I/O Timings: read=155401.828  
         ->  Partial GroupAggregate  
            (cost=10066631.46..10378661.98 rows=13868023 width=40)  
            (actual time=363797.836..409187.566 rows=85 loops=3)  
               Group Key: ((json -> 'age'::text))  
               Buffers: shared hit=5843962 read=5177836,  
                        temp read=4212551 written=4212596  
               I/O Timings: read=478460.123  
               ->  Sort  
                  (cost=10066631.46..10101301.52 rows=13868023 width=1042)  
                  (actual time=299775.029..404358.743 rows=11094533 loops=3)  
                     Sort Key: ((json -> 'age'::text))  
                     Sort Method: external merge  Disk: 11225392kB  
                     Buffers: shared hit=5843962 read=5177836,  
                              temp read=4212551 written=4212596  
                     I/O Timings: read=478460.123  
                     ->  Parallel Seq Scan on json_stack  
                        (cost=0.00..4791997.29 rows=13868023 width=1042)  
                        (actual time=0.684..202361.133 rows=11094533 loops=3)  
                           Buffers: shared hit=5843864 read=5177836  
                           I/O Timings: read=478460.123  
 Planning time: 0.080 ms  
 Execution time: 411688.165 ms  
```  
Postgres expects to get 33,283,256 records instead of 86. It also performed a very expensive sort since it generated more than 33GB (11GB * 3 loops) of temporary files.  
The same query using the json_age function:  
```  
explain (analyze,buffers)   select json_age(json),count(json_age(json))  
                              from json_stack group by json_age(json);  
                                             QUERY PLAN  
--------------------------------------------------------------------------------------  
 Finalize GroupAggregate  
  (cost=4897031.22..4897033.50 rows=83 width=40)  
  (actual time=153985.585..153985.667 rows=86 loops=1)  
   Group Key: ((json ->> 'age'::text))  
   Buffers: shared hit=1938334 read=1736761  
   I/O Timings: read=106883.908  
   ->  Sort  
      (cost=4897031.22..4897031.64 rows=166 width=40)  
      (actual time=153985.581..153985.598 rows=256 loops=1)  
         Sort Key: ((json ->> 'age'::text))  
         Sort Method: quicksort  Memory: 37kB  
         Buffers: shared hit=1938334 read=1736761  
         I/O Timings: read=106883.908  
         ->  Gather  
            (cost=4897007.46..4897025.10 rows=166 width=40)  
            (actual time=153985.264..153985.360 rows=256 loops=1)  
               Workers Planned: 2  
               Workers Launched: 2  
               Buffers: shared hit=1938334 read=1736761  
               I/O Timings: read=106883.908  
               ->  Partial HashAggregate  
                  (cost=4896007.46..4896008.50 rows=83 width=40)  
                  (actual time=153976.620..153976.635 rows=85 loops=3)  
                     Group Key: (json ->> 'age'::text)  
                     Buffers: shared hit=5811206 read=5210494  
                     I/O Timings: read=320684.515  
                     ->  Parallel Seq Scan on json_stack  
                     (cost=0.00..4791997.29 rows=13868023 width=1042)  
                     (actual time=0.090..148691.566 rows=11094533 loops=3)  
                           Buffers: shared hit=5811206 read=5210494  
                           I/O Timings: read=320684.515  
 Planning time: 0.118 ms  
 Execution time: 154086.685 ms  
```  
Here postgres sorts later on a lot less lines. The execution time is significantly reduced and we save especially 33GB of temporary files.  
## Last word  
Statistics are essential for choosing the best execution plan. Currently Postgres has advanced features for [JSON](https://blog.anayrat.info/en/2017/11/26/postgresql---jsonb-and-statistics/#fn:4) Unfortunately there is no possibility to add statistics on the JSONB type. Note that PostgreSQL 10 provides the infrastructure to [extend statistics](https://www.postgresql.org/docs/current/static/sql-createstatistics.html). Hopefully in the future it will be possible to extend them for special types.  
In the meantime, it is possible to work around this limitation by using functional indexes.  
1、https://www.postgresql.org/docs/current/static/functions-json.html   
2、A bitmap node becomes lossy when postgres can not make a bitmap of all tuples. It thus passes in so-called “lossy” mode where the bitmap is no longer on the tuple but for the entire block. This requires reading more blocks and doing a “recheck” which consists in filtering obtained tuples. ^  
3、The [documentation](https://www.postgresql.org/docs/current/static/functions-json.html) is very complete and provides many examples: use of operators, indexing. ^  
## Related  
[PostgreSQL 10 : ICU & Abbreviated Keys](https://blog.anayrat.info/en/2017/11/19/postgresql-10--icu--abbreviated-keys/)  
[PostgreSQL 10 : Performances improvements](https://blog.anayrat.info/en/2017/10/04/postgresql-10--performances-improvements/)  
[PGDay : How does Full Text Search works?](https://blog.anayrat.info/en/2017/09/02/pgday--how-does-full-text-search-works/)  
[PostgreSQL 10 and Logical replication - Setup](https://blog.anayrat.info/en/2017/08/05/postgresql-10-and-logical-replication---setup/)  
[PostgreSQL 10 and Logical replication - Overview](https://blog.anayrat.info/en/2017/07/29/postgresql-10-and-logical-replication---overview/)  
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")