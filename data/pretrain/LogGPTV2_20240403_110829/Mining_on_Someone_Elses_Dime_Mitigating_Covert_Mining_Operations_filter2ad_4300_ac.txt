4
2
1
7
2
8
9
2
5
2
3
2
5
3
9
7
3
6
0
4
3
3
4
0
6
4
7
8
4
4
1
5
1
4
5
8
6
5
5
9
5
2
2
6
9
4
6
6
7
6
1
8
2
5
5
2
8
9
0
1
6
3
1
3
6
1
0
9
1
7
1
2
4
4
2
1
7
2
8
9
2
5
2
3
2
5
3
9
7
3
6
0
4
3
3
4
0
6
4
7
8
4
4
1
5
1
4
5
8
6
5
5
9
5
2
2
6
9
4
6
6
7
6
Miner
Data Caching
AI
H264
NAMD
Miner
Data Caching
AI
H264
NAMD
Fig. 3. Diﬀerence in behavior of a Litecoin CPU miner and four representative CPU
applications. The x axis shows time in units of 100 ms (miner in red). (Color ﬁgure
online)
298
R. Tahir et al.
Fig. 4. Similarity in behavior of three diﬀerent Bitcoin mining softwares. The x axis
shows time in units of 100 ms.
correspond to peaks in store count. Similarly, another interesting observation is
that for the Litecoin miner, the curves for the HPCs closely follow each other -
an increase in one is accompanied by an increase in the other, which is generally
not the case in the other workloads. Finally, even though data caching exhibits
a slight similarity to Litecoin for these two HPCs, it is quite diﬀerent for all
metrics taken together. We take away the following insight from these results:
CPU-miners exhibit a unique HPC-based signature and this signature can be
eﬀectively leveraged to detect virtual machines that are performing cryptocur-
rency mining.
Signature Homogeneity Within a Coin: Hackers usually employ various
techniques and mechanisms to bypass detection mechanisms. They use polymor-
phic, metamorphic and obfuscated malware to fool anti-virus software and run-
time checkers by completely overhauling their codebase. To show MineGuard’s
resilience against these techniques, we demonstrate how three completely diﬀer-
ent miner implementations that are mining the same coin still exhibit the same
HPC-based signature.
Figure 4 shows two graphs, one per HPC, for three diﬀerent miners all mining
for Bitcoin. The implementations of these miners are quite diﬀerent from one
another, however, the graphs all show similar HPC patterns, thereby backing our
claim that the mining signature is consistent across diﬀerent implementations.
The reason behind this, as mentioned previously, is that at their core, all miners
have to abide by a ﬁxed PoW algorithm. Not only does this limit the amount
of variability that can be aﬀorded by diﬀerent implementations, but since the
algorithm is run millions of times, it dwarfs any diﬀerences that are present
in polymorphic or metamorphic versions of the mining malware. Consequently,
the resulting signatures only have minor variations from miner to miner. These
variations are broadly manifested across three categories. Phase shifts (where
the patterns are oﬀset from each other by a small time delta), diﬀerences in
magnitude and occasionally in curve shape. We found that these changes are
rare and usually impact one or two HPCs largely keeping the signature similar
across implementations. MineGuard exploits this uniformity during its detection
phase allowing it to catch altered versions of a mining malware.
Mitigating Covert Mining Operations in Clouds and Enterprises
299
Fig. 5. Similarity in behavior of various cryptocurrencies (algorithms). The x axis
shows time in units of 100 ms.
Signature Homogeneity Across Coins: We also claim that diﬀerent cryp-
tocurrencies have similar signatures due to the nature of cryptomining. As evi-
dence, we present the signatures of ﬁve diﬀerent cryptocurrencies in Fig. 5. The
ﬁgure shows a subset of the signatures of cryptominers mining Litecoin, Byte-
coin, Dashcoin, Quarkcoin and Vertcoin. It is immediately obvious that all ﬁve
signatures follow the same pattern - periods of constant computation (the ﬂat
part of the curves, corresponding to hashing) punctuated by phases of expo-
nentially decaying irregular code that executes when new blocks are found, the
mining diﬃculty is changed, I/O is performed, etc. The only diﬀerences are in
the magnitudes of the various HPC values, which can be attributed to diﬀerent
PoW algorithms having higher or lower operation counts. However, when look-
ing at the combined signature of all HPCs, the similarities dwarf the diﬀerences,
as shown in Fig. 5.
Eﬀects and Characterization of Noise: So far, we have discussed the sig-
natures of miners and various other applications that were obtained in a non-
virtualized environment (OS). Although these signatures aptly present the simi-
larities and diﬀerences between various miners and non-mining applications, they
do not account for VM noise that would naturally be added when the aforemen-
tioned software are executed in a virtualized environment (guest OS) and proﬁled
from the hypervisor. Since monitoring virtual machines is the primary role of
MineGuard, we characterize this noise and study its eﬀects on mining signatures.
By performing per feature noise proﬁling (on both OS and VM environments
using all miner and cloud workloads) for all 26 HPCs (see Table 2), we found
that roughly one-fourth of the counters show variation in values due to noise e.g.,
cycles, instructions, stalled-cycles-fronted, context switches etc. Figure 6A shows
the process via which we arrived at the best ﬁt, which was determined using the
Akaike Information Criterion (AIC) [28]. The empirical data points (blue bars)
represent the noise added as we moved from native to in-VM execution. The
colored curves represent various distributions superimposed on top. As evident,
a vivid pattern can be extracted based on the distribution and later used for error
correction. Similarly, Fig. 6B shows the probability density functions for a few
HPC counters. The best ﬁt distributions in the depicted cases were Nakagami
(cycles, stalled-cycles-frontend) and Burr (instructions, stalled-cycles-backend)
300
R. Tahir et al.
y
t
i
s
n
e
D
y
t
i
l
i
b
a
b
o
r
P
-3
x 10
6
5
4
3
2
1
0 
0
2 x10-10
empirical
tlocationscale
generalized extreme value
logistic
normal
generalized pareto
1
HPC cycles : nakagami
HPC instructions : burr
HPC stalled-cycles-frontend : nakagami
HPC stalled-cycles-backend : burr
300
600
800
Noise Value
(A)
0
0
1
3
2
4
Noise Value
(B)
5
6
x 1010
Fig. 6. (A) The ﬁtting process via which we arrive at the ﬁnal best ﬁt distribution
(tLocation-Scale) for the context switch counter (ID 10). (B) Noise distribution for
number of instructions counter (ID 2). The best ﬁt distribution in this case is Burr.
distributions. Other HPCs, such as context switches, followed the tLocation-
Scale distribution. We found that three-fourths of the counters have negligible
change to their values or patterns when we move from OS to VM. This fact
justiﬁes our choice of HPCs for MineGuard given that virtualization has limited
impact on HPCs. Furthermore, if necessary, the discovered distributions can be
factored into the signatures to develop error-corrected proﬁles for even more
robust and accurate signatures.
To visually demonstrate how this noise distorts signatures, we present graphs
for native vs in-VM execution of miners in Fig. 7A. The graph depicts the values
of the L1 Loads counter. The curves have become more jagged and noisy as the
system processes of the guest OS inﬂuence counter values, but their involvement
results in a minimal degradation of the signature. For example, the peaks and
troughs can still be clearly seen. Similarly, the slopes are unchanged and the
noisy plateaus are still ﬂat, preserving the consistent behavior of miners. All
this follows from the fact that most HPCs do not suﬀer from virtualization-
induced noise as shown above and maintain unique patterns and characteristics
associated with mining.