Performs mathematical calculations such as cubic equation calcu-
lation and square root calculation on a set of constants.
Implements the Quick Sort algorithm on a list of words.
Finds corners of a black & white image of a rectangle.
Finds edges of a black & white image of a rectangle.
Smooths a black & white image of a rectangle.
Performs Fast Fourier Transformation on an array of data.
Performs reverse FFT on an array of data.
Implements the 32-bit Cyclic Redundancy Check on a sound ﬁle.
Uses Dijkstra’s algorithm to ﬁnd the shortest path between pairs of
nodes constructed from an adjacency matrix representation graph.
Implements the well known SHA (secure hash algorithm), generat-
ing a 160-bit digest from an ASCII text ﬁle.
Searches for words in phrases using case insensitive comparison.
Uses the breadth-ﬁrst search algorithm to compute the shortest-path
cost from a single node to every reachable node in an irregular graph
of uniform edge weights derived from the map of New York.
Computes a 2-D saturating histogram with a maximum bin count
of 255 of the default input set.
Calculates the sum of absolute differences in the default input set.
Computes the product of a sparse matrix with a dense vector. We
select the small input, which is a sparse matrix in coordinate format.
Each campaign consists of 10,000 fault injection experi-
ments to obtain tight error bounds. Thus, we perform a total
of 10, 000 ∗ 182 ∗ 15 = 27, 300, 000 experiments. We also
compute error bars at the 95% conﬁdence intervals.
The outcome of each experiment is classiﬁed into one of
the following categories:
• Benign. The program terminates normally and the in-
jected error does not affect the program’s output. This
category could be the result of internal robustness of the
program and it contributes to overall error resilience.
• Detected by Hardware Exceptions. The injected error
raises a hardware exception. Almost all these exceptions
cause the program to crash, however there are very
few cases where a hardware exception is raised without
causing a crash. Errors detected by hardware exception
mechanisms contribute to the overall error resilience, as
the program could potentially call a recovery routine
and prevent the program from producing an erroneous
result. These exceptions include segmentation faults (ac-
cessing memory words outside the legal memory segment
boundary), aborts (programs aborted by themselves or the
OS), misaligned memory accesses (memory accesses are
not aligned at four bytes), and arithmetic errors such as
division by zero.
• Hang. The program fails to terminate within a predeﬁned
time, which is set by LLFI to be one or two orders of
magnitude greater than the execution time of the fault-
free run of the program. Errors that result in this category
also contribute to the overall error resilience as watchdog
timers could be used to detect them.
• NoOutput. The program terminates, without generating an
output. Errors that result in this category also contribute
to the overall error resilience as there is an indication that
the program needs to be executed again.
• Silent Data Corruption (SDC). The program terminates
normally, but the output is incorrect (based on a bit-wise
comparison), and there is no indication of the failure.
As mentioned above,
the ﬁrst four outcome categories
(Benign, Detected by hardware exceptions, Hang, and NoOut-
put) contribute to the error resilience. Recall that the error
resilience is deﬁned as the probability that the program does
not cause an SDC, which is why we focus on the SDC
outcome category. Among the four error resilience categories,
the Benign category is the result of internal robustness of the
program, while the other three categories correspond to when
an error is detected - we refer to them as Detection.
F. Research Questions
In this section, we present the research questions that are
investigated in this paper. The research questions are motivated
by the three error pruning techniques we investigate.
The ﬁrst error space pruning layer deals with the selection of
an upper bound for the max-MBF parameter, since there is no
commonly agreed mapping model that could be used to reason
about the number of software-level errors due to a hardware
transient fault. Though we choose 30 as an upper bound for
the max-MBF, the actual number of activated errors may be far
fewer allowing us to prune the multiple error injection space.
So the ﬁrst research question deals with the number of errors
that are actually activated when multiple errors are injected
and do not result in program crashes.
injection results with respect
• RQ1. When multiple errors are injected, how many errors
are activated before the program crashes (if it crashes)?
In the second layer of error space pruning, we classify
to parameters such as
fault
the fault injection technique used (inject-on-read and inject-
on-write), the maximum number of bit-ﬂips injected (max-
MBF), and the dynamic window size between consecutive
injections (win-size), to investigate whether we could further
prune the error space by ﬁnding parameter values that result
in pessimistic percentage of SDCs (i.e., conservative upper-
bounds). Therefore, we ask the following research questions:
• RQ2. Does the single bit-ﬂip error model result in pes-
simistic percentage of SDCs when compared with the
multiple bit-ﬂip error model?
• RQ3. Is there an upper bound to the maximum number of
multiple bit-ﬂips needed to cause pessimistic percentage
of SDCs?
• RQ4. Is there a maximum dynamic window size that
causes pessimistic percentage of SDCs?
Using the results obtained from the second layer of error
space pruning,
the multiple bit-ﬂip error space could be
signiﬁcantly pruned allowing us to only focus on a certain
subset of the max-MBF and win-size parameters. However,
depending on the size of the program, conducting fault injec-
tion experiments even on the pruned error space may still be
very time-consuming. This is why in the third layer of error
space pruning, we ask the following question:
• RQ5. Is it possible to ﬁnd fault injection locations that
are insensitive to multiple bit-ﬂip errors compared to
single bit-ﬂip errors, and exclude them from the multiple-
injection error space?
IV. EXPERIMENTAL RESULTS
In this section, we present detailed classiﬁcations of fault
injection results with respect to the parameters, max-MBF and
win-size as well as the type of fault injection technique used.
These classiﬁcations help us quantify the differences between
candidate values that can be chosen for each parameter, which
allows us to answer the research questions presented in §III-F.
We start by understanding the outcomes of the single-bit fault
injection experiments (§IV-A), followed by multiple injections
into the same register (§IV-B), and then ﬁnally multiple fault
injections in different registers (§IV-C).
A. Results for the Single Bit-Flip Model
In this section, we present the results of fault injections
using the single bit-ﬂip model to serve as a baseline for com-
parison with the multiple bit-ﬂip injections. Fig. 1 shows the
outcome classiﬁcation results with the single bit-ﬂip model.
Fig. 1a and Fig. 1b show the results for when inject-on-
read and inject-on-write fault injection techniques are used,
respectively. Recall that the Detection category is the sum of
the results for Hang, NoOutput and Detected by Hardware
Exception categories. The percentage of experiments classiﬁed
as Hang and NoOutput is insigniﬁcant (less than 0.3%), and
hence most of the experiments in the Detection category were
detected by hardware exceptions.
Fig. 1 shows that overall, the SDC percentage when using
the inject-on-write technique is higher than that when using
the inject-on-read technique. A similar trend was also observed
by Sangchoolie et al. [23]. The reasons for this difference
are (i) the type of data-items stored in source/destination
registers as well as (ii) the number of times that
these
registers are accessed throughout the execution of the program.
Registers could hold data-items of different types such as
memory addresses, data variables, and control information.
Errors injected in memory addresses are mostly detected by
hardware exception mechanisms, causing a higher percentage
of crashes and hence lower percentage of SDCs [9], [23].
Both source registers and destination registers could hold a
memory address, however, an address may be read multiple
times after it is written into. This increases the probability of
an error being injected into an address when using the inject-
on-read technique, which would eventually result in a lower
percentage of SDCs for the results obtained using the inject-
on-read technique compared to the inject-on-write technique.
B. Results When Targeting Multiple Bits of the Same Register
Fig. 2 shows the classiﬁcation of fault injection results when
the multiple injections are performed into the same instruction
(i.e., register). In other words, for each program, the dynamic
window size (win-size) value is zero, and only the max-
MBF parameter is varied from 1 (the leftmost bar) to 30 (the
rightmost bar). The goal of this experiment is to understand
how much the max-MBF parameter alone contributes to the
percentage of SDCs.
Fig. 2a and Fig. 2b show the results for when inject-on-
read and inject-on-write fault injection techniques are used,
respectively. The leftmost result bar for each benchmark pro-
gram represents the percentage of SDCs when only a single-bit
error is injected, while the other result bars correspond to the
percentages of SDCs caused by different numbers of multiple
bit-ﬂip errors ranging from 2 to 30.
Fig. 2 shows that for the majority of the programs, the SDC
results obtained for the single bit-ﬂip model is either pes-
simistic, or very close to the ones obtained for the multiple bit-
ﬂip model. However, for basicmath and CRC32 programs, the
SDC results due to the single bit-ﬂip model are signiﬁcantly
lower (especially when using the inject-on-write) than the
results obtained for the multiple bit-ﬂip model, and hence the
single bit-ﬂip model does not yield pessimistic SDC results for
these programs. This behaviour can be explained by looking
at Fig. 1, where we see that single bit-ﬂip errors injected into
these programs result in the lowest percentage of Detections
(a) inject-on-read
(b) inject-on-write
Figure 1. Fault injection outcome classiﬁcation for campaigns using single bit-ﬂip model. The Detection category refers to the sum of Detected by Hardware
Exception, Hang and NoOutput categories. The error bars indicate 95% conﬁdence intervals.
(a) inject-on-read
(b) inject-on-write
Figure 2. Percentage of SDCs for injecting different number of errors into the same instruction/register (i.e., win-size = 0). The leftmost and rightmost bars,
for each program, represents the percentage of SDCs when injecting 1 and 30 errors, respectively. The error bars indicate 95% conﬁdence intervals.
when compared with the other programs. This implies that
there are fewer possibilities of hardware exceptions to be
raised due to the injection of errors in these programs. There-
fore, many of the errors injected remain undetected, thereby
resulting in a higher percentage of SDCs.
For qsort and susan-corner programs,
the single bit-ﬂip
model results in pessimistic percentage of SDCs compared to
the multiple bit-ﬂip model, except for the case when max-MBF
= 30. However, it is unlikely that these number of bits are
affected by a single fault; this conﬁguration (max-MBF = 30)
is mainly selected for answering RQ1. Therefore, for the qsort
and susan-corner programs also, the single bit-ﬂip fault model
provides us with a pessimistic estimate of the percentage of
SDCs caused due to multiple bit-ﬂip error injections.
RQ2-Answer: For the majority of the benchmark programs, the
results obtained for the single bit-ﬂip model is either pessimistic
or very close to the ones obtained for the multiple bit-ﬂip model
for bit-ﬂips in the same register (i.e., win − size = 0).
C. Results When Targeting Bits of Multiple Registers
instructions. To control
In this section, we consider multiple bit-ﬂips in multiple
registers accessed by different
the
distance between consecutive injections, we choose the dy-
namic window sizes (win-size) that are greater than zero (win-
size>0) from Table I. We ﬁrst attempt to bound max-MBF
by studying how many errors are activated when the max-
MBF=30 (§IV-C1). We ﬁnd that only a small fraction of these
errors are activated, making it unnecessary to select higher
values for max-MBF. However, as the error space is still
large, we search for max-MBF/win-size pairs in the space
that cause pessimistic percentage of SDCs (§IV-C2). Finally,
we investigate whether the single bit-ﬂip fault injection results
can help prune the multiple bit-ﬂip error space (§IV-C3).
1) Number of Activated Errors: Fig. 3 shows the distribu-
tion of the number of activated errors before causing a program
to crash, given that we intend to inject 30 bit-ﬂip errors. The
reason for selecting such a high value (max-MBF=30) is to
ﬁnd the portion of errors that could remain undetected and can
hence be pruned. Note that the results presented here include
all win-size values shown in Table I.
Fig. 3 shows that at most ﬁve activated errors are enough
to cause a program to crash in more than 96% (78%) of the
experiments using inject-on-read (inject-on-write) techniques.
Furthermore, 3% and 14% of the inject-on-read and inject-
on-write experiments, respectively, managed to activate six to
ten errors. And ﬁnally, only around 1% of the inject-on-read
experiments and 8% of the inject-on-write experiments had
more than 10 activated errors. Thus, we see that an upper
bound of 10 errors for max-MBF is sufﬁcient to capture the
majority of fault injection outcomes, and hence can be used to
bound the value of max-MBF. As one could expect, the errors
that remain undetected would most likely result in SDCs.
RQ1-Answer: Around 99% of inject-on-read and 92% of inject-
on-write experiments had fewer than 10 activated errors.
2) Max-MBF/win-size Pairs that Cause Pessimistic Percent-
age of SDCs: In the previous section, we studied the effects
of the max-MBF on the number of activated errors in the
program. We now examine the effects of the max-MBF on
the SDC percentages. Fig. 4 and Fig. 5 show the SDC results
for the experiments targeting bits of multiple registers using
the inject-on-read, and inject-on-write techniques, respectively.
Both of these ﬁgures show that when increasing the number
of bit-ﬂip errors, the general trend for the SDC results is
declining, regardless of the value of win-size selected. We
further study each technique in detail below.
a) Results for the inject-on-read Technique: Fig. 4 shows
the SDC results for the experiments targeting bits of mul-
tiple registers using the inject-on-read technique. The 95%
conﬁdence intervals for these results are between ±0.19 for
dijkstra and ±0.97 for sha. According to this ﬁgure, in 13
programs, the percentage of SDCs caused due to the single bit-
ﬂip model is higher than or almost the same as (i.e., difference
less than one percentage point) the ones caused due to the
multiple bit-ﬂip model. However, for 2 programs (CRC32 and
stringsearch), there are multiple bit-ﬂip campaigns that result
in a higher percentage of SDCs. Even for the 2 programs, the
percentage of SDCs caused due to the single bit-ﬂip model is
only around two percentage points lower than the multiple bit-