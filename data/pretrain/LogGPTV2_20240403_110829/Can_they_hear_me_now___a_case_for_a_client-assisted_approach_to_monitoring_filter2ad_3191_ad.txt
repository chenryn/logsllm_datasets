### Table 4: Standard Deviation of Long-Term and Short-Term Data

| Duration (min) | TCP (Kbps) | UDP (Kbps) | Jitter (msec) | Loss (%) |
|----------------|------------|------------|---------------|----------|
| 30             | 167        | 182        | 0.5           | ∼0       |
| 10             | 414        | 365        | 1.0           | ∼0       |

**Note:** The standard deviation of short-term data (10 seconds) is significantly higher than that of long-term data (30 minutes).

### Figure 6: Allan Deviation for UDP Throughput Measurements

- **(a) Location in Wisconsin (WI)**
- **(b) Location in New Jersey (NJ)**

**Description:** The Allan deviation for UDP throughput measurements at a given zone using Proximate subset traces. The Allan deviation is lowest around 75 minutes for the WI location, which corresponds to the epoch of the zone. For the NJ location, the process repeats every 15 minutes.

### Summary
When network metrics are aggregated at finer time scales (tens of seconds), they exhibit significantly more variability compared to coarser time scales (tens of minutes). Therefore, we use the minimum value of the Allan deviation in each zone to determine the epoch of that zone. This value is estimated regularly for each zone.

### 3.3 Composability of Client-Sourced Measurements

We use client-sourced measurements to collect data from different client devices, allowing us to estimate network properties for each epoch in each zone. Composability of measurements from diverse sources is feasible only if the measurements are similar to a certain extent. In our work, we have used laptop and single-board computer (SBC) hardware, each equipped with different cellular modems. Our results show that composability across this class of clients is possible. However, composability of measurements from a mobile phone and a laptop with a USB modem may not always be effective due to differences in their radio front-end and antenna systems. Future work will need to address normalization or scaling techniques for such compositions. For now, we suggest grouping devices into broad categories—mobile phones, laptops, SBCs with USB or PCMCIA modems—and performing client-assisted monitoring separately for each category.

### Demonstration of Closeness of Client-Sourced Samples to Stationary Data

To demonstrate the closeness of client-sourced samples to stationary data, we evaluate:
1. **Temporal Variability:** Whether the probability distribution of measurements collected at the same location by different clients at different times within the time epoch is statistically similar to the overall long-term distribution at that location.
2. **Spatial Variability:** Whether the probability distribution of measurement samples collected by different clients at different locations (within a bounded distance) during the same time epoch is statistically similar to the overall long-term distribution at that location.

#### Similarity Measure: Symmetric Normalized Kullback-Leibler Divergence (NKLD)

The NKLD is a measure of dissimilarity between two probability distributions. It is defined as:

\[
\text{NKLD}(p(x), q(x)) = \frac{1}{2} \left( \frac{D(p(x) || q(x))}{H(p(x))} + \frac{D(q(x) || p(x))}{H(q(x))} \right)
\]

where:
- \( p(x) \) and \( q(x) \) are the two probability distributions based on a common set \(\chi\).
- \( H(p(x)) = \sum_{x \in \chi} p(x) \log \left( \frac{1}{p(x)} \right) \) is the entropy of the random variable \( x \) with probability distribution \( p(x) \).
- \( D(p(x) || q(x)) = \sum_{x \in \chi} p(x) \log \left( \frac{p(x)}{q(x)} \right) \) is the Kullback-Leibler divergence.

A small value of NKLD indicates that the two distributions are close. For our experiments, an NKLD value of 0.1 or lower signifies that the distributions are similar.

### Temporal and Spatial Variability of Samples

#### Temporal Variability
- **Figure 7(a) and (c):** Plot of NKLD for UDP throughput collected at the same location (GPS coordinates) at different times in Madison, WI, and New Brunswick, NJ.
- **Results:** In Madison, the NKLD goes down to 0.1 with 50-60 samples, while in New Brunswick, it takes 80-90 samples. The distributions become similar after 120 samples in New Brunswick due to greater performance variation.

#### Spatial Variability
- **Figure 7(b) and (d):** Plot of NKLD for UDP throughput collected at different locations (within a zone) at the same time in Madison, WI, and New Brunswick, NJ.
- **Results:** In Madison, the NKLD is less than 0.1 with 80 measurements, and in New Brunswick, it is less than 0.1 with 100 measurements. This indicates that by accumulating around 100 samples, the distributions become similar in both locations.

### Conclusion
Client-sourced measurements can be used as an estimator of the ground truth for a zone.

### 3.3.1 Example: Client-Sourced Throughput Estimation

We aim to determine the minimal number of measurements necessary to estimate the network’s performance at a given location with a certain degree of accuracy. We use throughput estimation as an example, noting that similar methods can be applied to other metrics like jitter, loss, and latencies.

#### Bandwidth Measurement Tools
We experimented with Pathload and WBest but found that neither tool provides accurate approximations. WBest underestimates the actual bandwidth by up to 70%, and Pathload underestimates by up to 40%. Therefore, we perform simple UDP downloads over a duration to measure network performance.

#### Number of Packets Necessary
- **Table 5:** Number of back-to-back measurement packets required to estimate TCP/UDP throughput within 97% accuracy of the expected value.

| Network-Location | UDP | TCP |
|------------------|-----|-----|
| NetA-WI         | 90  | 60  |
| NetB-WI         | 40  | 40  |
| NetC-WI         | 120 | 50  |
| NetB-NJ         | 70  | 120 |
| NetC-NJ         | 40  | 40  |

**Conclusion:** We need to send a specific number of packets to accurately estimate the network throughput at a given location. Future work will focus on diagnosing the reasons behind the inaccuracies of the bandwidth measurement tools.