(30m)
167
182
0.5
∼0
Short
(10s)
414
365
1.0
∼0
TCP (Kbps)
UDP (Kbps)
Jitter (msec)
Loss (%)
Table 4: Table showing the standard deviation of long term (30 min) and short term (10 sec) data for each
network. The standard deviation of short term data is signiﬁcantly higher than that of long term data.
n
o
i
t
i
a
v
e
d
n
a
l
l
A
 1
 0.8
 0.6
 0.4
 0.2
 0
 1
 10
 100
 1000
Time(in minutes)
n
o
i
t
i
a
v
e
d
n
a
l
l
A
 1
 0.8
 0.6
 0.4
 0.2
 0
 1
 10
 100
 1000
Time(in minutes)
(a) Location in WI
(b) Location in NJ
Figure 6: Allan deviation for UDP throughput mea-
surements at a given zone for NetB using Proximate
subset traces. For the measured data, the Allan de-
viation is lowest around 75 minutes, which corre-
sponds to the epoch of the zone.
process repeats every 75 minutes, while for the zone in New
Brunswick it repeats every 15 minutes.
Summary: When aggregated at ﬁner time scales (tens of
seconds), the network metrics vary signiﬁcantly more, than
when aggregated at a coarser time scale (tens of minutes).
Hence, we use the minimum value of the Allan deviation in
each zone to determine the epoch of that zone. This value
is estimated regularly for each zone.
3.3 Composability of client sourced measure-
ments
We use client sourcing to collect measurements from diﬀer-
ent client devices, leading to estimation of network proper-
ties for each epoch in each zone. Composability of measure-
ments collected from diverse sources would be feasible only
when they are similar (to a certain) extent to one another. In
our work, we have only used laptop or single-board computer
(SBC) based hardware, each equipped with diﬀerent cellular
modems. This section shows that composability across this
class of clients is, indeed, possible. However, composability
of measurements from a mobile phone and a laptop equipped
with a USB modem may not always work well. This is be-
cause a mobile phone, among its other characteristics, has a
more constrained radio front-end and antenna system, than
a USB modem. Potentially data collected from such devices
with diﬀerent capabilities need to go through a normaliza-
tion or scaling process. We have not addressed such types of
composition in this work. Instead we suggest that we group
devices into broad categories — mobile phones, laptops or
SBCs with USB or PCMCIA modems, etc., and perform
client-assisted monitoring for each individual category sep-
arately. Given our experimentation was performed using
laptops and SBCs equipped with cellular modems (as this
was the platform used in our wide-area data collection eﬀorts
for various practical and logistical reasons), we demonstrate
that composability within its category. Future work would
require us to re-create some of these results with the mobile
phone category as well as as examining techniques for nor-
malization across categories, a signiﬁcant eﬀort unto itself.
To demonstrate the closeness of client sourced samples
to stationary data, we evaluate a) if the probability dis-
tribution of the measurements collected at the same loca-
tion (same GPS coordinates) by diﬀerent clients at diﬀer-
ent times within the time epoch are statistically similar to
the overall long-term distribution at that location and b)
if the probability distribution of the measurement samples
collected by diﬀerent clients at diﬀerent locations (within a
bounded distance) during the same time epoch are statis-
tically similar to the overall long-term distribution at that
location. While (a) measures the temporal variability, (b)
measures the spatial variability of the measurement samples
inside a zone.
We measure the similarity of two probability distribution
functions, using the symmetric Normalized Kullback-Leibler
Divergence (NKLD) between the data from the Static dataset
and the Proximate dataset for a given location. The sym-
metric NKLD is a measure of the dissimilarity between two
distributions.
The Kullback Liebler divergence (KLD) quantiﬁes the rel-
ative entropy between two probability distributions which
are generated from a common event. The KLD is zero for
two identical probability distributions. To rectify the asym-
metric nature of the metric we use a symmetric and normal-
ized version of the metric as used in [19]. The normalized
symmetric Kullback Leibler metric,
NKLD(p(x), q(x)) =
1
2 „ D(p(x)||q(x))
H(p(x))
+
D(q(x)||p(x))
H(q(x)) «
where, p(x) and q(x) are the two probability distributions
based on a common set χ.
H(p(x)) = Px∈χ p(x)log(1/p(x)) is the entropy of the
random variable x, with probability distribution p(x), and,
D(p(x)||q(x)) = Xx∈χ
p(x)|log
p(x)
q(x)
|
is the Kullback-Leibler divergence. A small value of NKLD
would signify that the two distributions are “close”. For our
experiments, we take an NKLD value of 0.1 and lower to
signify that the distribution of measurements are similar.
We plot the KLD distributions for UDP throughput for the
NetB network in Figure 7.
Temporal variability of samples: We randomly select
two measurement traces of two clients of progressively in-
106D
L
K
N
 2.5
 2
 1.5
 1
 0.5
 0
 0
 20  40  60  80  100
No. of Samples
D
L
K
N
 2.5
 2
 1.5
 1
 0.5
 0
 0
 20  40  60  80  100
No. of Samples
D
L
K
N
 2.5
 2
 1.5
 1
 0.5
 0
 0
 20  40  60  80  100
No. of Samples
D
L
K
N
 2.5
 2
 1.5
 1
 0.5
 0
 0
 20  40  60  80  100
No. of Samples
(a) NKLD for samples
collected at same loca-
tion (GPS co-ordinates)
at diﬀerent times in WI.
(b) NKLD for samples
collected at diﬀerent lo-
cations (within a zone) at
the same time in WI.
(c) NKLD for samples
collected at same loca-
tion (GPS co-ordinates)
at diﬀerent times in NJ.
(d) NKLD for samples
collected at diﬀerent lo-
cations (within a zone) at
the same time in NJ.
Figure 7: Plot of NKLD for UDP throughput (a) and (c) shows that samples collected at temporally diﬀerent
instances at same location are highly similar, (b) and (d) shows data collected at spatially diﬀerent locations
which are in the same zone are highly similar. Plots (a) and (b) corresponds to location in Madison, Wisconsin,
while (c) and (d) corresponds to location in New Brunswick, New Jersey.
creasing time durations with the same GPS coordinates and
calculate the divergence of this distribution with the overall
distribution consisting of all measurements, this process is
repeated across 100 iterations and the average of the NKLD
is calculated. We plot the results in Figure 7(a) and Fig-
ure 7(c). We ﬁnd that for the location in Madison, by the
time we have accumulated 50 to 60 samples, the NKLD goes
down to a 0.1 signifying that the two distributions are sim-
ilar to each other. For the location in New Brunswick, we
ﬁnd that the NKLD goes below 0.1 once we have accumu-
lated 80 to 90 samples. Furthermore, the two distributions
become similar once we have gathered around 120 samples.
We need higher number of samples in New Brunswick,
due to the greater degree of variation of its performance
compared to the network in Madison.
Spatial variability of samples: We randomly select lo-
cations which are 50-250 meters apart from each other and
simultaneously start UDP downloads using two clients at
both locations for a duration of 2 minutes. The test is re-
peated at 10 diﬀerent locations. We plot the divergence of
the distribution of throughput values collected from two lo-
cations in Figure 7(b) for Madison and Figure 7(d) for New
Brunswick. We ﬁnd that with 80 and 100 measurements in
Madison and New Brunswick respectively the NKLD is less
than 0.1. This signiﬁes that by the time we have accumu-
lated around 100 samples at two locations the distribution
of such samples becomes similar to one another in both the
representative locations.
Based on above results, we conclude that client sourced
measurements can be used as a estimator of the ground truth
for a zone.
3.3.1 Example: client sourced throughput estimation
We intend to determine the minimal amount of measure-
ments necessary to estimate the network’s performance at
a given location with a certain degree of accuracy. In this
section, we use throughput estimation as an example. We
note that similar methods can be used for client-sourced es-
timation of other metrics such as jitter, loss and latencies
etc..
A lot of research has focused on estimating the available
network bandwidth for wired as well as WiFi based net-
works [20, 21]. In contrast, few studies have concentrated
on characterizing the available bandwidth for the cellular
Network-Location UDP TCP
NetA-WI
NetB-WI
NetC-WI
NetB-NJ
NetC-NJ
90
60
40
120
70
60
40
40
120
50
Table 5: Table showing the number of back-to-
back measurement packets to be sent to estimate
TCP/UDP throughput within an accuracy of 97%
of the expected value.
networks. Availability of an accurate and eﬃcient estima-
tion algorithm is vital for client-assisted monitoring.
GU DP
We experimented with two such bandwidth measurement
tools: Pathload and WBest [20, 21]. To estimate the accu-
racy of these tools we take the average of UDP throughput
measured over 100 seconds for 10 iterations as the ground
truth at that location. We then deﬁne relative error as
E = X−GU DP
× 100%, where X is the result from available
bandwidth measurement tools (i.e., Pathload or WBest) and
GU DP is the ground truth UDP throughput. In our evalu-
ations we found that neither of the two tools give an ac-
curate approximation. WBest consistently under-estimates
the actual bandwidth by up to 70% while Pathload under-
estimates up to 40%. Similar benchmarking results are also
reported in [22]. Hence, we carry out simple UDP downloads
over a duration of time to measure the network performance.
In the rest of this section, we determine how many such sam-
ples should be sent to fairly accurately (∼97%) estimate the
network throughput at a speciﬁc location. We intend to
diagnose the reason behind the estimation inaccuracies for
the two bandwidth measurement tools as part of our future
work.
How many packets necessary? We revisit our TCP
and UDP throughput measurements from our Proximate
datasets to determine the minimum number of packets to
be collected for attaining a maximum accuracy in estimat-
ing the expected performance of a zone.
We select a given number of client collected packets and
calculate their average. We then compare it with the ground
truth throughput at that instant (calculated as mentioned
above). We repeat this process 100 times for a given packet
size. We present the number of packets necessary to at-
tain an accuracy of 97% in Table 5. We ﬁnd that for the
107F
D
C
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2