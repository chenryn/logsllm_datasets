## 论文的主要贡献这篇论文关注的是"**问答系统**"（Question &Answering）。问答系统不仅在实用领域受到大量用户的青睐，产生了诸如Quora、知乎、Stack Overflow等知名的在线问答服务，也在人工智能系统开发领域受到研究者的关注。我们曾经提到过"图灵测试"，用来衡量一个系统或者说是一个机器人是否具有真正的人工智能，这个测试其实就是建立在人机问答的交互场景下的。因此，建立有效的问答系统一直是人工智能研究，特别是自然语言处理研究的核心课题之一。这篇论文的作者们认为，在问答系统的场景中，一个非常重要的手段是针对已经提出的问题进行"**澄清式**"（Clarification）提问，从而能够引导其他回答者更加有效地进行回答。也就是说，作者们研究的主题是，**如何找到这些具有桥梁作用的"澄清式问题"**，这是这篇论文的第一个重要贡献。论文的第二个主要贡献是利用了"决策论"（DecisionTheoretic）框架下的**EVPI**（Expected Value of PerfectInformation，完美信息的期望价值），来衡量一个澄清式问题会对原始的问题增加多少有用的信息。简而言之，**EVPI就是这篇论文提出来的一个衡量有用信息的测度**（Measure）。论文的第三个贡献是通过 Stack Exchange 平台（Stack Overflow是其一个子站点），构造了一个 7 万 7千条含有澄清式问题的数据集。作者们从这个数据集中选取了 500个样本进行了实验，并且发现，提出的模型要明显好于一些之前在问题系统中的类似算法。
## 论文的核心方法既然这篇论文的一个核心贡献是提出了"澄清式提问"这么一个新的概念，用于帮助问答系统的开发。那么，**究竟什么是"澄清式提问"呢**？实际上在这篇文章里，作者们并没有对"澄清式提问"给出一个清晰的定义，而是仅仅提供了一个实例来解释什么是"澄清式提问"。例如，一个用户在 Ask Ubuntu 这个子论坛里，询问在安装 APE程序包时遇到的问题。这个时候，如果我们需要问"澄清式问题"，究竟什么样的问题可以激发其他人或者提出澄清式问题的人来进一步解答原始的问题呢？我们看下面几个从不同角度提出的问题：可以问这个用户使用的 Ubuntu系统具体的版本号；也可以问用户的 WiFi 网卡信息，还可以问用户是不是在 X86体系下运行 Ubuntu。那么，在这一个场景下，后两个问题要么无法为原始的问题提供更多有价值的信息，要么就是彻底的不相关，而第一个问题关于具体的版本号，很明显是用户可以提供的，并且可以帮助回答问题的人来缩小问题的范围。这也带出了这篇论文的第二个贡献点，**如何衡量一个帖子的价值呢**？要回答这个问题，我们需要知道这里有两种帖子是模型需要处理的。第一种帖子集合是候选的澄清式问题集合。第二种帖子集合是候选的最终回答集合。我们最终的目的是得到最佳的最终回答。这里面起到"搭桥"作用的就是澄清式问题。所以，作者们就构造了一个针对每一个最终问题的 EVPI值，用于衡量这个问题的"期望价值"。为什么是期望价值呢？因为这里面有一个不确定的因素，那就是根据不同的澄清式问题，可能会产生不同的回答。因此，作者们在这里使用了概率化的表达。也就是说，EVPI的核心其实就是计算给定当前的原始问题以及某一个澄清式回答的情况下，某一个最终回答的概率，乘以这个回答所带来的"收益"。当我们针对候选最终回答集合中所有的回答都进行了计算以后，然后求平均，就得到了我们针对某一个澄清式回答的EVPI。换句话说，**某一个澄清式回答的 EVPI就是其所能产生的所有可能的最终回答的加权平均收益**。从上面这个定义中，我们有两点不确定。第一，我们并不知道给定当前的原始问题以及某一个澄清式回答的情况下，某一个最终回答的条件概率；第二，我们并不知道问题的收益。因此，作者们利用了两个**神经网络模型**来对这两个未知量进行**联合学习**（JointLearning）。这可以算是本文在建模上的一个创新之处。具体来说，首先，作者们利用**LSTM**来针对原始问题、候选澄清问题、以及最后解答产生相应的**表达向量**。然后，原始问题和某一个候选澄清问题的表达向量，通过一个神经网络产生一个**综合的表达**。最后，作者们定义了一个**目标函数**来针对这些初始的表达向量进行优化。这个目标是需要我们学习到的答案的表达靠近初始得到的答案的表达，同时，也要靠近最终答案的表达，如果这个最终答案所对应的问题也靠近原来的问题。换句话说，**如果两个问题的表达相近，答案的表达也需要相近**。那什么样的问题是相近的问题呢？作者们利用了 Lucene这个信息检索工具，根据一个原始的问题寻找相近的问题。这里，作者们并没有真实的标签信息，所以利用了一些方法来标注数据，从而能够让模型知道两个问题是否相关。
## 论文的实验结果作者们利用了 Stack Exchange来构建一个分析澄清式问题的数据集。具体的思路是，如果原始问题曾经被作者修改过，那么后面的某一个帖子中所提出的问题就会被当作是澄清式问题，而原始问题就被当作是因为澄清式问题而得以改进的帖子。很明显，这是一个非常粗略的数据收集条件。当原始问题被作者修改过以后，并且最后因为这个修改得到回复，就被认为是一个最终的答案。经过这么一番构建，作者们整理了7 万 7 千多条帖子。作者们利用论文提出的方式和其他的经典模型进行比较。最后的结论是，提出的模型能够更好地找到最佳的澄清式问题，效果要好于仅仅是简单利用神经网络，来匹配原始问题和相应的澄清式问题。
## 小结今天我为你讲了 ACL 2018 的一篇最佳论文。一起来回顾下要点：第一，这篇论文提出了"澄清式提问"这个概念，来帮助问答系统的开发；第二，文章提出了一系列方法，对澄清式问题进行描述和衡量；第三，文章构建了一个数据集，通过实验论证了所提出方法的有效性。最后，给你留一个思考题，通过这篇文章关于澄清式问题的介绍，你能否给澄清式问题下一个定义呢？欢迎你给我留言，和我一起讨论。![](Images/5f1a3d2ca933c759573c72ee2ba198b7.png){savepage-src="https://static001.geekbang.org/resource/image/ef/b2/efd991ee74e55356bb2776f3d8d375b2.jpg"}
# 135 \| ACL 2018论文精读：什么是对话中的前提触发？如何检测？今天，我来和你分享 ACL 2018的第二篇最佳论文，题目是《让我们"再"次做到：检测副词前提触发词的第一种计算方法》（[Let'sdo it "again": A First Computational Approach to Detecting AdverbialPresuppositionTriggers](https://www.cs.mcgill.ca/~jkabba/acl2018paper.pdf)）。这篇论文的作者都来自加拿大麦吉尔大学（McGillUniversity）的计算机系。前三位学生作者是这篇论文的共同第一作者，对论文的贡献相同。他们的导师张智杰（JackieChi Kit Cheung）助理教授是这篇论文的最后一个作者。张智杰于 2014年从多伦多大学博士毕业，之前曾两次在微软研究院实习过，他长期从事自然语言处理的研究。
## 论文的主要贡献这篇论文的背景要从"语用学"（Pragmatics）说起。语用学是语言学的一个分支学科，与符号学理论相互交叉、渗透，研究语境对语言含义产生的影响和贡献。语用学包括言语行为理论、对话内涵义、交流中的对话，以及从哲学、社会学、语言学以及人类学等角度解析人类语言行为的研究。语用学分析研究语言行为（如招呼、回答、劝说）的文化准绳和发言规则。不同的文化之间皆有约定俗成、客套的对话，在跨文化交流中，为了避免因为语言规范的差异而在交谈之中产生误解，社会语言学的知识与务实能力是语言学习者所不能忽视的。``{=html}在语用学中，"前提"（Presuppositions）是交谈的参与者共同约定的假设和认知，而且在谈话中被广泛使用。同时，在这篇论文中，作者们把提示"前提"的"表达"（Expression）定义为"**前提触发**"（PresuppositionTriggers），包括一些动词、副词和其他短语。为了更加清晰地说明这些概念，作者们举了这么一个例子。假设我们现在有两句话：1.  约翰再次要去那家餐厅（John is going to the restaurant *again*）。2.  约翰已经去过了那家餐厅（John has been to the restaurant）。第一句话要能够成立必须要建立在第二句话的基础上。特别是"前提触发"词"再"（Again）的使用，是建立在第二句话真实的情况下。换句话说，第一句话必须在第二句话的上下文中才能够被理解。值得一提的是，即便我们对第一句话进行否定，"约翰不打算再去那家餐厅了"（Johnis not going to the restaurantagain），依然需要第二句话的支持。也就是说，"前提触发"词在这里并不受到否定的影响。**这篇论文的核心贡献就是对以副词为主的前提触发词进行检测**。这里面包括"再"（Again）、"也"（Also）和"还"（Still）等。再此之前，还没有对这方面词汇进行检测的学术研究工作。能够对这类前提触发词进行检测，可以应用到**文本的归纳总结**（Summarization）和**对话系统**等场景中。为了更好地研究这个任务，作者们还基于著名的自然语言处理数据 Penn Treebank和 EnglishGigaword，建立了两个新的数据集从而能够进行触发词的分类检测工作。最后，作者们设计了一个基于"关注"（Attention）机制的时间递归神经网络（RNN）模型来针对前提触发词进行检测，达到了很好的效果。
## 论文的核心方法现在，我们来讨论这篇论文的一些细节。首先，我们来看看**数据集是如何生成的**。数据中的每一个数据点都是一个**三元组**，分别是标签信息（正例还是负例），文本的单词，文本单词所对应的"词类标签"或简称为POS 标签（例如动词、名词）。数据点正例就表明当前数据包含前提触发词，反之则是负例。另外，因为我们需要检测的是副词性的前提触发词，因此我们还需要知道这个词所依靠的动词。作者们把这个词叫作副词的"**管理词**"（Governor）。作者们首先针对文档扫描，看是否含有前提触发词。当发现有前提触发词的时候，提取这个触发词的管理词，然后提取管理词前50个单词，以及管理词后面到句子结束的所有的单词。这就组成了正例中的单词。当找到了所有的正例之后，作者们利用管理词来构建负例。也就是说，在文本中寻找哪些句子含有一样的管理词，但并不包括后面的前提触发词，这样的句子就是负例。下面，我们来看一下作者们提出模型的一些构成。从大的角度来说，为了识别前提触发词，作者们考虑了一个**双向LSTM**的基本模型架构，在此之上有一个"关注机制"，在不同的情况下来选择LSTM 的中间状态。具体来说，整个模型的输入有两部分内容。第一部分，是**文本的单词进行了词向量（Embedding）的转换**。我们已经反复看到了，这是在自然语言处理场景中利用深度学习模型必不可少的步骤。这样做的好处就是把离散数据转换成了连续的向量数据。第二部分，是**输入这些单词相对应的 POS 标签**。和单词不一样的是，POS标签依然采用了离散的特性表达。然后，连续的词向量和离散 POS 标签表达合并在一起，成了双向 LSTM的输入。这里，利用双向 LSTM的目的是让模型针对输入信息的顺序进行建模。跟我们刚才提到的例子一样，前提触发词和其所依靠的动词，在一个句子的段落中很明显是和前后的其他单词有关联的。因此，双向LSTM 就能够达到对这个结构进行记忆的目的，并且提取出有用的中间变量信息。下面需要做的就是**从中间变量信息到最终的分类结果的变换**。这里，作者们提出了一个叫"**加权池化网络**"（WeightedPooling Network）的概念，并且和"关注"机制一起来进行这一步的中间转换。可以说，作者们这一步其实是借助了计算机视觉中的经常使用的卷积神经网络 CNN中的池化操作来对文档进行处理。具体来说，作者们把所有 LSTM产生的中间状态堆积成一个矩阵，然后利用同一个矩阵乘以其自身的转置就得到了一个类似于相关矩阵的新矩阵。可以说，这个新矩阵是完全抓住了当前句子通过LSTM 中间变量转换后所有中间状态的两两关系。然后，作者们认为最后的分类结构就是从这个矩阵中抽取信息而得到的。至于怎么抽取，那就需要不同的权重。这种根据不同的情况来设置权重的机制就叫作"关注"机制。经过矩阵中信息的抽取，然后再经过全联通层，最终就形成了标准的分类输出。