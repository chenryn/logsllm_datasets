double spending, however to make this relevant the amount
should exceed what such miner would be able to mine in
the real Bitcoin network. Also complete alternative Bitcoin
reality for all the users who access Bitcoin solely through Tor
is possible. This however would come at a cost of 5-10 times
slower conﬁrmations, which after some time can be detected
by the wallet software.
IV. USER FINGERPRINTING
In this section we describe a technique which can be used
to ﬁngerprint Bitcoin users by setting an “address cookie”
on their computers. A cookie can be set and checked even
when the user connects to the Bitcoin network through Tor or
through a chain of proxies. It can be used to correlate different
transactions of the same user even across different sessions (i.e.
after his computer was rebooted). If the user decides later to
send a non-sensitive transaction without Tor, his ﬁngerprint
can be correlated to his IP address, thus deanonymizing all
his transactions sent previously through Tor. The ﬁngerprinting
technique is based on the Bitcoin’s peer discovery mechanism.
More speciﬁcally on that a Bitcoin peer stores addresses
received from other peers and on that his database can be
queried.
As was described in section II-A3 whenever a peer receives
an unsolicited ADDR message, it stores the addresses from
this message in his local database. The attacker can use this
fact as follows. When a client connects to an attacker’s peer,
the peer sends him a unique combination of possibly fake
addresses (address cookie) or ﬁngerprint (we will use these
two terms interchangeably below). Unique non-existent peer
addresses work best, however a more sophisticated and more
stealthy adversary may use existing Bitcoin peer addresses
as well (exploiting the combinatorics of the coupon collector
problem). The client stores these addresses and the next time
he connects to (another) malicious peer, the peer queries his
address database. If the ﬁngerprint addresses are present in the
set of retrieved addresses, the attacker identiﬁes the user.
Consider a user C and a set of Bitcoin servers E1, ..., Ek
controlled by an attacker. Assume that one of the attacker’s
servers El
is among the user’s entry nodes. The attacker
executes the following steps:
1)
2)
3)
4)
Send a number of GETADDR messages to the user. The
user should reply with ADDR messages.
Check the received from the client addresses if they
already contain a ﬁngerprint. If the user already has
a ﬁngerprint, stop. Otherwise go to the next step.
Generate a unique combination of N fake addresses
F P and send them in an ADDR message to the
client. The ADDR message should contain at least 11
addresses so that it is not forwarded by the client.
If N is less than 11, pad the message with 11 − N
legitimate14 addresses.
If the user connects to the Bitcoin network directly
(i.e. without Tor), store the correspondence between
the client’s IP address and his ﬁngerprint as a tuple
(F P, IPC). If the user connects through Tor save him
as (F P, NIL).
There is a detail of the Bitcoin protocol which an attacker
should take into account. As was described in subsection II-
A1, when a client connects to the Bitcoin network over Tor,
he will accept and store in his database OnionCat addresses
only (thus ignoring IPv4 addresses). It means that in case of
Tor, the ﬁngerprint generated by the attacker should consist
of OnionCat addresses only. On the other hand when a client
connects to the network directly, he will ignore non-IPv4/IPv6
addresses. Hence an attacker should generate a ﬁngerprint
consisting of IPv4 addresses only. This results in that an
attacker needs to store 2 different types of cookies: OnionCat
and IPv4. At the same time, a client does not limit the types
of addresses he sends as a reply to a GETADDR message. This
means that once a cookie was set it can be queried both over
Tor and directly.
A. Stability of a Cookie
According to the Bitcoin core [10] source code, at the
startup when a client establishes outgoing connections he sends
GETADDR messages, and gets back a set of addresses (typically
2,500, the maximum possible number per GETADDR request).
Given 8 outgoing connection, the client will receive up to
20,000 non-unique addresses. These addresses can potentially
overwrite the address cookie previously set by an attacker.
Below we will try to estimate how this affects the stability of
the cookie. Assume that an attacker managed to set an address
cookie on a user’s computer and disconnected (e.g. the client
ended the session). The client then establishes a new session
sometime later.
First note that if the user reconnects to Bitcoin over Tor
and if the attacker has mounted the attack from section III, he
14By legitimate we mean that there are some Bitcoin servers running at
these addresses.
127127
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:08:31 UTC from IEEE Xplore.  Restrictions apply. 
controls all user’s trafﬁc and the cookie is preserved. Let us
now describe what happens if the client decides to connect to
the Bitcoin network directly.
When a client receives an address IPin he ﬁrst checks
if it is already contained in his database. If yes, he does
nothing (thus the cookie is not damaged). In case it is a
new IP address the client executes the following procedure.
He computes the bucket number (see section II-A4) based on
the peer which sent the address and the address itself. If this
bucket contains a “terrible”15 address IPterrible, it is replaced
by IPin. Otherwise 4 random addresses are chosen from the
bucket and the one with the oldest timestamp is replaced by
IPin.
In other words, in order for the incoming address IPin to
16 the following conditions
replace a cookie address IPcookie
should hold:
1)
2)
3)
IPin should not be in the user’s database;
IPin should belong to the same bucket B as IPcookie
and there should be no “terrible” addresses in B;
IPcookie should be among the four randomly chosen
addresses, and its timestamp should be the oldest.
These conditions as we will see below make the attacker’s
cookie quite stable for many hours (this also depends on the
number of user sessions since at each startup the address
database is refreshed).
In order to estimate the probability that a cookie address set
by the attacker is preserved we conducted the following exper-
iment. In November 2014 we queried running Bitcoin servers
by sending them GETADDR messages. We received 4,941,815
address-timestamp pairs. Only 303,049 of the addresses were
unique. This can be interpreted as that only about 6% of the
addresses received by a client will not be already contained in
his database (if the client re-connects immediately).
As the second step, we looked at the timestamp distribution
of the non-unique address set. This distribution can serve
as approximation of the distribution of address timestamps
of a client’s database. The results are shown in Table I:
89% of addresses had a timestamp more than 3 hours in the
past. Taking into account conditions stated above, it almost
guarantees that the attacker’s cookie will not be damaged
within the ﬁrst 3 hours. For 45% of addresses the timestamp
was older than 10 hours (which is the duration of a working
day); 9% of addresses were older than 1 week.
The results above could be summarized as follows: (1)
there is a high chance that an address received by a client will
already be contained in his database, which keeps the cookie
intact; (2) if a cookie IP address is among the 4 nominees for
erasing, it is likely that its timestamp will be fresher than that
of at least one of other nominees (and thus will not be erased).
Finally we conducted the following experiment. We set a
cookie consisting of 100 IPv4 addresses and monitored how
stable this cookie was across different sessions. Table II shows
15An address is called terrible if any of the following holds: 1) its timestamp
is 1 month old or more than 10 minutes in the future; 2) 3 consecutive
connections to this address failed.
16A cookies consists of several IP address, but
explanation simpler, we use just one address here.
in order to make the
128128
Address age, hours
1-CDF
89%
77%
45%
28%
19%
15%
13%
12%
9%
3
5
10
15
24
36
48
72 (3 days)
168 (1 week)
TABLE I.
COMPLEMENTARY CUMULATIVE DISTRIBUTION FUNCTION
FOR ADDRESSES TIMESTAMPS
the decay rate of the number of cookie addresses over time and
sessions. Note that by session we mean that the client switches
off Bitcoin software and switches it on again, which forces him
to make 8 new outgoing connections and retrieve up to 20,000
addresses.
Session number
Time since start, hours Remaining addresses
1
2
3
4
5
6
7
8
9
10
TABLE II.
0
0.5
1
1.5
2
2.5
3
3.5
5.5
8
100
100
100
100
100
100
98
92
50
36
ADDRESS COOKIE DECAY RATE (EXAMPLE)
The experiment shows that even after 10 sessions (i.e. after
reception of about 200,000 non-unique IP addresses) and 8
hours, one third of the ﬁngerprint remained in the user’s
database (thus it will be possible to identify the client). Note
that sessions 9 and 10 took 2 and 2.5 hours. On the average
an attacker will need about 90 peers (given that at the time of
writing there are about 7,000 Bitcoin servers) to become one
of the client’s entry nodes during any of these 10 sessions and
update the ﬁngerprint. Running this number of peers will cost
the attacker less than 650 USD per month (see section VII).
In another experiment we checked that in the case of two
sessions with 10 hours between sessions, our client kept 76%
of the initial ﬁngerprint addresses, and in the case of 24
hours between two sessions 55% of the initial ﬁngerprint were
kept (which again allows the user identiﬁcation). In order to
carry out the experiments from this section we built our own
rudimentary Bitcoin server which is able to connect/accept
connections to/from Bitcoin peers and is capable of send-
ing/receiving different Bitcoin messages on demand. We used
this server as a malicious Bitcoin server which sets new address
cookies and checks previously set cookies. In order to simulate
a user we used the ofﬁcial Bitcoin core software (developed
by the Bitcoin project) [10]. The attack from this section was
experimentally veriﬁed by tracking our own clients in the real
Bitcoin and Tor networks.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:08:31 UTC from IEEE Xplore.  Restrictions apply. 
B. Cookie extraction
to learn that
The remaining question is how many GETADDR messages
an attacker needs to send to the client
the
database of this client contains a cookie. According to [2],
section 9.2 it can be up to 80 messages to retrieve the full
collection of client’s addresses. However in practice we will
not need to collect all the addresses in a ﬁngerprint, which
signiﬁcantly reduces the number of requests. About eight
GETADDR messages would be sufﬁcient to retrieve about 90%
of the cookie addresses. This shows that the cookie can be
checked without raising suspicion.
C. Attack vectors
Deanonymization of Bitcoin over Tor users. Consider the
following case. A client uses the same computer for sending
both benign Bitcoin transactions and sensitive transactions. For
benign transactions the user connects to Bitcoin directly, but
for sensitive transactions he forwards his trafﬁc through a chain
of Tor relays or VPNs. If an attacker implements the attack
described in section III, all client’s sensitive transactions with
high probability will go through attacker’s controlled nodes
which will allow her to ﬁngerprint the user and record his
transactions.
When the client later connects to the Bitcoin network directly
to send benign transactions, he will with some probability
choose an entry node controlled by the attacker (in section V
we show how to increase this probability). Once it happens,
the attacker can query the client for the ﬁngerprint and thus
correlate his sensitive transactions with his IP address. Note
that even if the attacker is not implementing the complete man-
in-the-middle attack on Tor, but just injects Sybil peers and
Sybil hidden services she will be able to link many sensitive
transactions to the real IP addresses of users.
Linking different Tor sessions. In the case, when a client uses
a separate computer (or Bitcoin data folder17) to connect to
Bitcoin through Tor, the attacker will not be able to learn his IP
address. However, the attacker will still be able to link different
transactions of the same user (remember that if a client sends
a transaction through Tor the attacker can be certain that it
was generated by this client). This can be done even across
different sessions (computer restarts). This will in turn allow
the attacker to correlate different Bitcoin addresses completely
unrelated via transaction graph analysis.
Domino Effect. Tor multiplexes different streams of the same
user over the same circuits. This means that if the source of one
stream in the circuit is revealed by the ﬁngerprinting attack,
all other streams will also be deanonymized. Speciﬁcally, it
is likely that a user who sends a sensitive Bitcoin transaction
through Tor, will also browse a Darkweb site. Similar result
was also noted in [16] but in relation to Bittorrent over Tor
privacy issues. To prevent this it is recommended to enable
option IsolateSOCKSAuth when running Tor (this will pre-
vent sharing circuits with streams for which different SOCKS
authentication was provided).
17A Bitcoin data folder is a directory where Bitcoin clients store their wallets
and dump IP address databases between restarts.
V. LOW-RESOURCE SYBIL ATTACKS ON BITCOIN
In the previous section, we mentioned that a client needs
to connect directly to one of the attacker’s nodes in order to
reveal his IP address so that an attacker can deanonymize his
previous transactions done over Tor. Bitcoin as a peer-to-peer
network is vulnerable to Sybil attacks and just operating many
Bitcoin servers means that a client will sooner or later choose
an entry node controlled by the attacker (i.e. in some number
of sessions). However running too many servers can be costly
(see section VII for attack cost estimation). Fortunately for