title:SecGraph: A Uniform and Open-source Evaluation System for Graph
Data Anonymization and De-anonymization
author:Shouling Ji and
Weiqing Li and
Prateek Mittal and
Xin Hu and
Raheem A. Beyah
SecGraph: A Uniform and Open-source Evaluation 
System for Graph Data Anonymization  
and De-anonymization
Shouling Ji and Weiqing Li, Georgia Institute of Technology; Prateek Mittal,  
Princeton University; Xin Hu, IBM T. J. Watson Research Center; Raheem Beyah, 
Georgia Institute of Technology
https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/ji
This paper is included in the Proceedings of the 
24th USENIX Security Symposium
August 12–14, 2015 • Washington, D.C.
ISBN  978-1-939133-11-3
Open access to the Proceedings of  the 24th USENIX Security Symposium is sponsored by USENIXSecGraph: A Uniform and Open-source Evaluation System for Graph Data
Anonymization and De-anonymization
Shouling Ji
Georgia Institute of Technology
Xin Hu
Weiqing Li
Georgia Institute of Technology
Prateek Mittal
Princeton University
IBM Thomas J. Watson Research Center
Abstract
In this paper, we analyze and systematize the state-of-
the-art graph data privacy and utility techniques. Specif-
ically, we propose and develop SecGraph (available
at [1]), a uniform and open-source Secure Graph data
sharing/publishing system.
In SecGraph, we system-
atically study, implement, and evaluate 11 graph data
anonymization algorithms, 19 data utility metrics, and 15
modern Structure-based De-Anonymization (SDA) at-
tacks. To the best of our knowledge, SecGraph is the
ﬁrst such system that enables data owners to anonymize
data by state-of-the-art anonymization techniques, mea-
sure the data’s utility, and evaluate the data’s vulnerabil-
ity against modern De-Anonymization (DA) attacks. In
addition, SecGraph enables researchers to conduct fair
analysis and evaluation of existing and newly developed
anonymization/DA techniques. Leveraging SecGraph,
we conduct extensive experiments to systematically eval-
uate the existing graph data anonymization and DA tech-
niques. The results demonstrate that (i) most anonymiza-
tion schemes can partially or conditionally preserve most
graph utilities while losing some application utility; (ii)
no DA attack is optimum in all scenarios. The DA
performance depends on several factors, e.g., similar-
ity between anonymized and auxiliary data, graph den-
sity, and DA heuristics; and (iii) all the state-of-the-art
anonymization schemes are vulnerable to several or all
of the modern SDA attacks. The degree of vulnerability
of each anonymization scheme depends on how much
and which data utility it preserves.
1
Introduction
Many computing systems generate data with graph struc-
ture, e.g., social networks, collaboration networks, and
email networks [2–4]. Even mobility traces, e.g., WiFi
traces, Bluetooth traces,
instant message traces, and
check-ins, can be modeled by graphs via applying so-
phisticated techniques [3–5]. Generally, those data are
Raheem Beyah
Georgia Institute of Technology
called graph data. For research purposes, data and net-
work mining tasks, and commercial applications, these
graph data are often transferred, shared, and/or provided
to the public, research community, and/or commercial
partners. Since graph data carry a lot of sensitive private
information of users/systems who generated them [2, 3],
it is critical to protect users’ privacy during the data trans-
ferring, sharing, and/or publishing.
To protect users’ privacy, several anonymization tech-
niques have been proposed to anonymize graph data,
which can be classiﬁed into six categorizes: Naive
ID Removal, Edge Editing (EE) based techniques
[6], k-anonymity based techniques [7–11], Aggrega-
tion/Class/Cluster based techniques [12–14], Differen-
tial Privacy (DP) based techniques [15–19], and Random
Walk (RW) based techniques [20]. Fundamentally, these
techniques try to protect users’ privacy by perturbing the
original graph’s structure while preserving as much data
utility as possible.
Following Narayanan and Shmatikov’s work [2],
many new Structure-based De-Anonymization (SDA, we
use DA and SDA interchangeably in this paper) at-
tacks on graph data have been proposed, which can be
categorized into two classes: seed-based attacks, e.g.,
Narayanan-Shmatikov’s attack [2], and seed-free attacks,
e.g., Ji et al.’s attack [3]. For both types of attacks, the
goal is to de-anonymize anonymized users using their
uniquely distinguishable structural characteristics.
Surprisingly, although we already have many sophis-
ticated anonymization techniques (e.g., [6, 7, 12, 15, 20])
and powerful SDA attacks (e.g., [2,3,5,21–24]), whether
state-of-the-art anonymization techniques can defend
against modern SDA attacks is still an open problem.
This is because of the incomplete evaluation of exist-
ing anonymization and DA techniques. For anonymiza-
tion works,
they usually only evaluate the data util-
ity performance of their proposed techniques (although
some works provide a theoretical security guarantee,
these guarantees usually do not hold due to improper
USENIX Association  
24th USENIX Security Symposium  303
assumptions or incomplete considerations as analyzed
in Section 4). For DA works, they usually evaluate
their attacks’ performance without applying state-of-the-
art anonymization techniques (e.g., k-anonymity based
schemes, DP based schemes) to their test data.
Contributions. To address the above open problem,
we systematically study, implement, and evaluate ex-
isting graph data anonymization techniques and DA at-
tacks. Speciﬁcally, our main contributions are as follows.
(a) We design and implement a Secure Graph data
publishing/sharing (SecGraph) system (available at [1]).
SecGraph enables data owners to anonymize their data
using state-of-the-art anonymization techniques, mea-
sure the anonymized data’s graph and application util-
ities, and comprehensively evaluate their data’s actual
vulnerability against modern DA attacks. To the best of
our knowledge, SecGraph is the ﬁrst such system pub-
licly available to both academia and industry. More im-
portantly, SecGraph provides the ﬁrst uniform platform
that enables researchers to conduct accurate comparative
studies of anonymization/DA techniques, and to compre-
hensively understand the resistance/vulnerability of ex-
isting or newly developed anonymization techniques, the
effectiveness of existing or newly developed DA attacks,
and graph and application utilities of anonymized data.
im-
plement, and evaluate 11 state-of-the-art graph data
anonymization schemes and 19 graph and application
utility metrics. We also analyze the 11 anonymiza-
tion schemes with respect
to the 19 utility metrics,
both analytically and experimentally. The evaluation re-
sults demonstrate that most existing anonymization algo-
rithms can partially or conditionally preserve most graph
utilities. However, all the anonymization schemes lose
one or more application utility.
(b) In SecGraph, we systematically analyze,
(c) We summarize and analyze the fundamental prop-
erties of existing SDA attacks. Then, we systematically
implement and evaluate 15 modern SDA attacks on real-
world graph datasets. Our results show that modern SDA
attacks are powerful and robust to seed mapping errors.
Furthermore, no attack is optimum in all scenarios. The
DA performance of an attack depends on the similarity
between the anonymized and auxiliary data, graph den-
sity, DA heuristics, etc.
(d) We analytically and experimentally evaluate the
performance of existing graph data anonymization
schemes on defending against modern SDA attacks. We
ﬁnd that existing anonymization techniques are vulnera-
ble to modern SDA attacks. Their degree of vulnerabil-
ity depends on how much data utility is preserved in the
anonymized data.
Abbreviations. For convenient reference, we summa-
rize the used abbreviations in Table 1.
Roadmap. In Section 2, we study existing graph data
i
o
t
a
z
i
m
y
n
o
n
A
s SDA
m
DA
r
e
SF
T
n EE
DP
RW
k-NA
k-DA
k-auto
k-iso
Deg.
JD
ED
PL
LCC
GCC
CC
BC
EV
NC
NR
Infe.
RX
RE
IM
s
c
i
r
t
e
m
y
t
i
l
i
t
U
De-anonymization
Seed-Free
Edge Editing
Differential Privacy
Random Walk
k-Neighborhood Anonymity
k-Degree Anonymity
k-automorphism
k-isomorphism
Degree
Joint Degree
Effective Diameter
Path Length
Local Clustering Coefﬁcient
Global Clustering Coefﬁcient
Closeness Centrality
Betweenness Centrality
Eigenvector
Network Constraint
Network Resilience
Infectiousness
Role extraction
Reliable Email
Table 1: Abbreviations and acronyms.
Structure-based De-anonymization
Inﬂuence Maximization
Distance Vector [5]
Community Detection
De-Anonymization [25]
Secure Routing
Sybil Detection
Randomized Spanning Tress [5]
Recursive Subgraph Matching [5]
MINS Minimum-sized Inﬂuential Node Set
CD
SR
SD
DV
RST
RSM
DeA
ADA
BDK
NS
NSR
NKA
PFG
YG
KL
JLSB
Narayanan et al.’s attack [21]
Nilizadeh et al.’s attack [22]
Pedarsani et al.’s attack [23]
Yartseva-Grossglauser’s attack [27]
Narayanan-Shmatikov’s attack [2]
Adaptive De-Anonymization [25]
Backstrom et al.’s attacks [26]
Korula-Lattanzi’s attack [24]
Ji et al.’s attack [3]
n
o
i
t
a
z
i
m
y
n
o
n
a
-
e
D
anonymization schemes and their utility performance. In
Section 3, we study modern SDA attacks.
In Section
4, the effectiveness of existing anonymization schemes
against modern DA attacks is analyzed. We systemat-
ically implement and evaluate SecGraph in Section 5.
The future research directions are discussed in Section
6. We conclude this paper in Section 7.
2 Graph Anonymization
2.1 Status Quo
Generally, existing graph data anonymization techniques
can be classiﬁed into six categories. We discuss each
category as follows.
304  24th USENIX Security Symposium 
USENIX Association
2
Naive ID Removal. To anonymize graph data, a
straightforward method is naive ID removal. Although
this method has been demonstrated to be extremely vul-
nerable to SDA attacks, it is still widely used because
of its simplicity, ease of applicability, and scalability
[2, 3, 5, 26, 28].
Edge Editing based Anonymization. To protect
graph data’s privacy, Ying and Wu proposed spectrum
preserved Edge Editing (EE) based schemes Add/Del and
Switch [6]. Under Add/Del, k randomly chosen edges
will be added followed by the deletion of another k ran-
domly chosen edges. Under Switch, k random edge
switches are conducted.
k-anonymity. k-anonymity has been widely used to
anonymize relational data [29, 30]. Similarly, much ef-
fort has been spent to extend k-anonymity to graph data
[7–11]. To defend against neighborhood attacks, Zhou
and Pei proposed k-Neighborhood Anonymity (k-NA) for
graph data [7]. In another work, Liu and Terzi consid-
ered degree attacks and proposed k-Degree Anonymity
(k-DA) for graph data, under which for each user, there
exists at least k − 1 other users with the same degree
[8]. In [9], Zou et al. simultaneously considered four
types of structural attacks on graph data and proposed
k-automorphism (k-auto), where each user always has
k − 1 other symmetric users with respect to k − 1 auto-
morphic functions. Another similar work is [10], where
Cheng et al. proposed k-isomorphism (k-iso) to defend
against structural attacks. Under k-iso, a graph is parti-
tioned and anonymized into k disjoint isomorphic sub-
graphs. In [11], Yuan et al. considered personalized pri-
vacy protection for anonymizing graph data in terms of
both semantic and structural information.
Aggregation/Class/Cluster based Anonymization.
Another popular idea to protect graph data is to group
users into clusters (equivalently, groups, classes).
In
[12], Hay et al. proposed an aggregation based graph
anonymization algorithm, which ﬁrst partitions users and
then describes the graph at the level of partitions. An-
other work, at the semantics level, is [13], where Bhagat
et al. designed a class-based anonymization algorithm.
In [14], Thompson and Yao presented two cluster-based
anonymization schemes for graph data.
Differential Privacy. Differential Privacy (DP) is an
emerging anonymization technique with a strong privacy
guarantee [31, 32]. Initially, DP was proposed for sta-
tistical databases [31]. Recently, there have been works
that seek to enable differentially private graph data re-
lease. Aiming at protecting edge/link privacy, deﬁned
as the privacy of users’ relationship in graph data, in
[15], Sala et al. introduced Pygmalion, a differentially-
private graph model. To bypass many difﬁculties en-
countered when working with the worst-case sensitiv-
ity [15], Proserpio recently presented a general platform,
named wPING, for differentially private data analysis
and publishing [16, 17]. Similar to [15], Wang and Wu
also employed the dK-graph generation model for en-
forcing edge DP in graph anonymization [18]. Another
recent work for edge DP is [19], where Xiao et al. pro-
posed a Hierarchical Random Graph (HRG) model based
scheme to meet edge DP.
Random Walk based Anonymization.
In [20],
proposed a Random Walk (RW) based
Mittal et al.