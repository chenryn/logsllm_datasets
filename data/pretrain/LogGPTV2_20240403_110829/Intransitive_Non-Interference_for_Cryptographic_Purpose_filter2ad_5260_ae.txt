be delivered is considerably simpliﬁed since the abstract
ﬁrewall knows the sender of a message by construction:
It can simply let messages from S and G through, but not
from B. Thus, no information can ﬂow directly from B
to C in this ideal structure.
Now assume that C outputs the bit b correctly with
2 + ns(k) for ns (cid:10)∈ SMALL. The
probability at least 1
only possible cut is ˆC := {S, G}. Thus we deﬁne a
distinguisher for the abstract structure as follows, given
the view of S and G in a run and the random tape of C:
It simulates the user C by using C’s input information,
which the distinguisher knows as it must come from S
or G (note that no information at all can ﬂow from B
to C directly), and the content of C’s random tape. More
precisely, the machine D proceeds through the joint view
∗
∗
(cid:4) := b
of S and G. For each output that is directed to C, it calls
the state transition ϕC of C with the current position on
the random tape. If the function ϕC outputs a bit b
at
port p∗
C bit!, the distinguisher outputs this bit as its own
guess, i.e., b
. Otherwise, it updates the position
on the random tape of the simulated machine C to the
ﬁrst unused position, and continues proceeding through
the view. It is easy to see that the distinguisher simulates
the precise behavior of the machine C, since every input
of C must have come from S or G.
Using the preservation theorem (Theorem 5.1), this
property carries over to the concrete implementation, us-
ing cryptographic primitives and comprising error prob-
abilities, without any further work.
Remark. The construction of D is so easy because di-
rect information ﬂow from B to C is completely prohib-
ited, not just up to a negligible error probability. If we
had performed this proof for the real system, we would
have had to deal with certain runs where direct ﬂow in-
deed occurred, namely those where B succeeded in forg-
ing a signature of S or G. These runs cannot be properly
simulated by the distinguisher as it lacks the incoming
information of C in this case. One possibility to deal
with that is to collect these runs in so-called error sets,
and to show afterwards that the aggregated probability
of these runs is still negligible, or the underlying cryp-
tography could be broken. Although this technique is
common in simulatability proofs (e.g., see [21]), we do
not want to bother with it when proving non-interference
for particular applications. Hence our preservation the-
orem is indeed very useful.
7 Related Literature
Initiated by the deterministic deﬁnition of Goguen
and Meseguer [5], the notion of non-interference for
transitive policies was extended by many articles, with
deﬁnitions for possibilistic and non-deterministic sys-
tems [27, 15, 9, 29, 19, 16, 31, 4, 13].
Although the notion of probabilistic non-interference
was already introduced in 1992 by Gray [7], probabilis-
tic information ﬂow has rather been overlooked for quite
some time. However, because of the tremendous devel-
opment of cryptography, new interest arose in capturing
what information ﬂow means in the context of cryptog-
raphy. Laud [11] deﬁned real computational secrecy for
a sequential language, and presented a calculus. How-
ever, only encryption is covered so far, i.e., other impor-
tant concepts like authentication, pseudo-number gener-
ators, etc. are not considered. Moreover, the deﬁnition
is non-reactive, i.e., it does not comprise continuous in-
teraction between the user, the adversary, and the sys-
Proceedings of the 2003 IEEE Symposium on Security and Privacy (SP(cid:146)03) 
1081-6011/03 $17.00 ' 2003 IEEE 
tem, which is a severe restriction to the set of consid-
ered cryptographic systems. Volpano [28] investigated
which conditions are needed so that one-way functions
can be used safely in a programming language, but he
did not express non-interference, but the secrecy of a
speciﬁc secret. Abadi and Blanchet [1] introduced type
systems where asymmetric communication primitives,
especially public-key encryption can be expressed, but
these primitives are only relative to a Dolev-Yao abstrac-
tion [3], i.e., the primitives are idealized so that no com-
putational non-interference deﬁnition is needed. For a
discussion why the Dolev-Yao abstraction is not justi-
ﬁed by current cryptography, see [20]. Recently, we in-
troduced the notion of computational probabilistic non-
interference [2]. This deﬁnition is based on a fully reac-
tive setting, comprises error probabilities and computa-
tional restrictions, and hence allows for analyzing infor-
mation ﬂow for general cryptographic primitives. How-
ever, this deﬁnition, as all the previous ones, was de-
signed speciﬁcally for transitive information ﬂow poli-
cies.
For intransitive policies, no prior work for a proba-
bilistic deﬁnition of ﬂow exists to the best of our knowl-
edge. For deterministic systems, Goguen and Meseguer
proposed a deﬁnition of intransitive information ﬂow
based on an unless construct [6]. This deﬁnition serves
as an extension of the original deﬁnition of Goguen and
Meseguer [5] for transitive ﬂow policies. However, this
unless construct did not meet the intuitive requirements
of intransitive ﬂow, as it accepted many intuitively in-
secure systems as being secure. The ﬁrst satisfactory
formal deﬁnition of intransitive ﬂow was proposed by
Rushby [24], followed by deﬁnitions by Pinsky [22]
and recently by Roscoe and Goldsmith [23]. Today,
Rushby’s approach to information ﬂow for intransitive
policies seems to be the most popular one for deter-
ministic systems as case studies have shown its fea-
sibility for real applications [25]. Besides these def-
initions for deterministic systems, Mantel presented a
new approach for intransitive ﬂow that is suited for non-
deterministic systems [14]. However, since all these def-
initions are based on non-probabilistic systems, they are
not suited to capture probabilistic behaviors, and in par-
ticular cryptographic applications. Our deﬁnitions solve
this problem as they can be used to capture intransitive
non-interference for systems involving arbitrary crypto-
graphic primitives.
Finally, we brieﬂy address downgrading of informa-
tion as the most common application of intransitive ﬂow.
The problem of many of the above deﬁnitions is that
they are overly restrictive, preventing many useful sys-
tems from being built. This led to the approach of
downgrading certain information so that it may subse-
quently leak from the system [18, 32]. The amount
of leaked information can in some cases be rigorously
deﬁned using information-theoretic techniques [17, 10].
As prior approaches of downgrading are speciﬁc to non-
probabilistic systems, our deﬁnition is the ﬁrst that cap-
tures downgrading for probabilistic information ﬂow.
8 Conclusion
Despite the recent interest in linking information ﬂow
and probabilism, no probabilistic formalism existed to
capture intransitive ﬂow policies. In particular this cre-
ated a major gap between information ﬂow and applica-
tions based on cryptographic primitives. In this article,
we tried to bridge this gap by proposing deﬁnitions for
intransitive ﬂow for probabilistic systems, in particular
blocking non-interference, recognition non-interference,
and the weaker recognition non-interference for trusted
recipients. The ﬁrst deﬁnition is incomparable with the
other two, and typically one of each type should be ful-
ﬁlled. Further, we have deﬁned downgrading, in other
words the correct handling of mixed inputs by a system.
We took care that our deﬁnitions can indeed be ful-
ﬁlled by cryptographic primitives by capturing error
probabilities, computational restrictions, and fully reac-
tive systems.
In situations where several third parties
might be involved in an intransitive ﬂow, we had to con-
sider how cuts of the ﬂow graph block the ﬂow or join
their knowledge to detect information ﬂow. This illus-
trates a major difference between the probabilistic and
the non-probabilistic approach, pointing out why the no-
tion of probabilistic information ﬂow is much more ﬁne-
grained.
We have ﬁnally shown that
intransitive non-
interference properties proved for abstract speciﬁcations
carry over to concrete implementations without any fur-
ther work, provided that the implementations are cor-
rect according to the simulatability deﬁnitions of mod-
ern cryptography.
Acknowledgments
We thank Heiko Mantel and Michael Waidner for
helpful discussions.
References
[1] M. Abadi and B. Blanchet. Secrecy types for asymmetric
communication.
In Proc. 4th International Conference
on Foundations of Software Science and Computation
Structures (FOSSACS), volume 2030 of Lecture Notes in
Computer Science, pages 25–41. Springer, 2001.
[2] M. Backes and B. Pﬁtzmann. Computational probabilis-
tic non-interference. In Proc. 7th European Symposium
on Research in Computer Security (ESORICS), volume
2502 of Lecture Notes in Computer Science, pages 1–23.
Springer, 2002.
[3] D. Dolev and A. C. Yao. On the security of public key
IEEE Transactions on Information Theory,
protocols.
29(2):198–208, 1983.
[4] R. Focardi and F. Martinelli. A uniform approach to the
deﬁnition of security properties. In Proc. 8th Symposium
on Formal Methods Europe (FME 1999), volume 1708
of Lecture Notes in Computer Science, pages 794–813.
Springer, 1999.
[5] J. A. Goguen and J. Meseguer. Security policies and se-
curity models. In Proc. 3rd IEEE Symposium on Security
& Privacy, pages 11–20, 1982.
[6] J. A. Goguen and J. Meseguer. Unwinding and inference
In Proc. 5th IEEE Symposium on Security &
control.
Privacy, pages 75–86, 1984.
[7] J. W. Gray III. Toward a mathematical foundation for
information ﬂow security. Journal of Computer Security,
1(3):255–295, 1992.
[8] C. A. R. Hoare. Communicating Sequential Processes.
International Series in Computer Science, Prentice Hall,
Hemel Hempstead, 1985.
[9] D. M. Johnson and F. Javier Thayer. Security and the
composition of machines. In Proc. 1st IEEE Computer
Security Foundations Workshop (CSFW), pages 72–89,
1988.
[10] M. H. Kang, I. S. Moskowitz, and D. C. Lee. A network
version of the pump. In Proc. 16th IEEE Symposium on
Security & Privacy, pages 144–154, 1995.
[11] P. Laud. Semantics and program analysis of computa-
In Proc. 10th Euro-
tionally secure information ﬂow.
pean Symposium on Programming (ESOP), pages 77–91,
2001.
[12] N. Lynch. Distributed Algorithms. Morgan Kaufmann
Publishers, San Francisco, 1996.
[13] H. Mantel. Unwinding possibilistic security proper-
ties. In Proc. 6th European Symposium on Research in
Computer Security (ESORICS), volume 1895 of Lecture
Notes in Computer Science, pages 238–254. Springer,
2000.
[14] H. Mantel.
Information ﬂow control and applications
– bridging a gap. In Proc. 10th Symposium on Formal
Methods Europe (FME 2001), volume 2021 of Lecture
Notes in Computer Science, pages 153–172. Springer,
2001.
[15] D. McCullough. Speciﬁcations for multi-level security
and a hook-up property. In Proc. 8th IEEE Symposium
on Security & Privacy, pages 161–166, 1987.
[16] J. McLean. Security models. Chapter in Encyclopedia of
Software Engineering, 1994.
Proceedings of the 2003 IEEE Symposium on Security and Privacy (SP(cid:146)03) 
1081-6011/03 $17.00 ' 2003 IEEE 
[17] J. K. Millen. Covert channel capacity. In Proc. 8th IEEE
Symposium on Security & Privacy, pages 60–66, 1987.
[18] A. Myers and B. Liskov. Protecting privacy using the de-
centralized label model. ACM Transactions on Software
Engineering and Methodology, pages 410–442, 2000.
[19] C. O’Halloran. A calculus of information ﬂow. In Proc.
1st European Symposium on Research in Computer Se-
curity (ESORICS), pages 147–159, 1990.
[20] B. Pﬁtzmann and M. Waidner. Composition and integrity
preservation of secure reactive systems.
In Proc. 7th
ACM Conference on Computer and Communications Se-
curity, pages 245–254, 2000.
[21] B. Pﬁtzmann and M. Waidner. A model for asynchronous
reactive systems and its application to secure message
transmission. In Proc. 22nd IEEE Symposium on Secu-
rity & Privacy, pages 184–200, 2001.
[22] S. Pinsky.
Absorbing covers and intransitive non-
interference. In Proc. 16th IEEE Symposium on Security
& Privacy, pages 102–113, 1995.
[23] A. Roscoe and M. Goldsmith. What is intransitive non-
In Proc. 12th IEEE Computer Security
interference?
Foundations Workshop (CSFW), pages 226–238, 1999.
[24] J. Rushby. Noninterference, transitivity, and channel-
control security. Technical report, Computer Science
Laboratory, SRI International, 1992.
[25] G. Schellhorn, W. Reif, A. Schairer, P. Karger, V. Aus-
tel, and D. Toll. Veriﬁcation of a formal security model
for multiapplicative smart cards.
In Proc. 6th Euro-
pean Symposium on Research in Computer Security (ES-
ORICS), volume 1895 of Lecture Notes in Computer Sci-
ence, pages 17–36. Springer, 2000.
[26] A. Shamir. How to share a secret. Communications of
the ACM, 22(11):612–613, Nov. 1979.
[27] D. Sutherland. A model of information.
In Proc. 9th
National Computer Security Conference, pages 175–183,
1986.
[28] D. Volpano.
Secure introduction of one-way func-
In Proc. 13th IEEE Computer Security Founda-
tions.
tions Workshop (CSFW), pages 246–254, 2000.
[29] J. T. Wittbold and D. M. Johnson. Information ﬂow in
In Proc. 11th IEEE Sympo-
nondeterministic systems.
sium on Security & Privacy, pages 144–161, 1990.
[30] A. C. Yao. Protocols for secure computations. In Proc.
23rd IEEE Symposium on Foundations of Computer Sci-
ence (FOCS), pages 160–164, 1982.
[31] A. Zakinthinos and E. S. Lee. A general theory of secu-
rity properties. In Proc. 18th IEEE Symposium on Secu-
rity & Privacy, pages 94–102, 1997.
[32] S. Zdancewic and A. C. Myers. Robust declassiﬁca-
tion. In Proc. 14th IEEE Computer Security Foundations
Workshop (CSFW), pages 15–23, 2001.
Proceedings of the 2003 IEEE Symposium on Security and Privacy (SP(cid:146)03) 
1081-6011/03 $17.00 ' 2003 IEEE