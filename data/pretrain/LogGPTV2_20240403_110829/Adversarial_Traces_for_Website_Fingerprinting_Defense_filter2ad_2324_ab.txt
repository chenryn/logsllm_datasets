toward the target sample and we will add more overhead. We modify
the source sample by summing it with ∆, (I new
= Is + ∆). We
iterate this process, computing ∆ for each Is and updating the
source sample until we leave the source class, f (I new
) (cid:44) s or the
number of iterations passes the maximum allowed iterations. In
our experiments, we set this maximum as 200 iterations.
Because we only increase the bursts where − ∂D(I,IT )
> 0, we
may run into cases that after some iterations ∇(−D(I , IT )) does not
have any positive values or all the positive values are extremely
small such that they do not make any significant changes to Is.
− Is is smaller than a threshold (we used
In such cases, if I new
threshold 0.001) for a few iterations (we used 10 iterations), and we
are still in the source class, we refill the pool with new samples and
pick a new target sample IT to continue the process.
∂bi
s
s
3 EVALUATIONS
)
%
(
d
a
e
h
r
e
v
O
0.6
0.4
p = 1
p = 5
p = 3
WT
10
12
14
0
2
4
6
8
α
Figure 2: Bandwidth Overhead: the bandwidth overhead of
generated samples as α and target pool size vary. Dashed
lines show the results of Case I and solid lines show the re-
sults of Case II.
In our evaluation, we break the data into two non-overlapping
sets: the Attacker Set and the Defender Set. Each set has a monitored
set of 83 classes, each representing a website of interest to the
attacker, with 360 instances each. Moreover, our dataset contains
an unmonitored set of 40,000 instances from 40,000 different sites,
one instance per site.
We examine the bandwidth overhead and reduction in attacker
accuracy of traces protected by our method. We use traces in the
training data and generated their defended forms by the method
described in the previous section. We first require a detector (f (x))
to identify when the generated samples leave their source class.
Thus, we define the detector, a CNN model, and train it on the traces
in Attacker Set. In our evaluations we examine two cases:
• Case I: We fill the target pool with instances from the At-
tacker Set. In this case, the detector has been trained on the
target classes.
• Case II: We fill the target pool with instances from the un-
monitored. In this case, the detector has not been trained on
the target samples.
We generated defended samples with various settings. We varied
α and p to evaluate their effect on the strength of the defended traces
and the overhead. We measured the detectability of the defended
samples by applying the DF attack [8] on them. Sirinam el al. [8]
suggest using 5,000 packets. Because both Walkie-Talkie and our
method increase the size of the bursts, the number of packets in the
traces increases. We thus use an input size of 10,000 packets, which
is the 80th percentile of packet sequence lengths in our defended
traces.
Figure 2 shows the bandwidth overhead in both Walkie-Talkie
(WT) and our method for Case I (solid lines) and II (dashed lines)
as α and p vary. As shown in the figure, as we increase α, the
bandwidth overhead increases. Larger α values create longer steps
toward the target samples and less fine-grained searches for an
effective stopping point. Using a larger target pool moderately
decreases bandwidth overhead in most cases.
Case I leads to lower bandwidth overhead compared to Case II.
Therefore, picking target samples from classes that the detector has
Poster PresentationCCS’18, October 15-19, 2018, Toronto, ON, Canada2226(a) Case I
(b) Case II
Figure 3: Accuracy: the accuracy rate of the generated samples against the DF attack. Dashed lines depict the cases when the
input size to the DF attack is 5,000 packets and solid lines show the results when it is 10,000 packets.
been trained on will drop the overhead. In all the evaluated settings,
the bandwidth overhead of our method is lower than that of Walkie-
Talkie. For α = 1 and p = 5 in Case I, the bandwidth overhead of
our defense is 27%, 60% lower than for Walkie-Talkie. On the other
end, for α = 15 and p = 5 in Case I, the bandwidth overhead of our
defense is 56%, 18% lower than for Walkie-Talkie.
Figure 3 depicts the accuracy rate of the DF attack as α and p
vary, for input sizes of 5,000 packets and 10,000 packets. Figure 3a
and 3b depict the results of the evaluations in Case I and Case II,
respectively. As α increases in both cases, the accuracy rate drops
to its minimum and then slightly increases. On the other hand,
increasing α raises the bandwidth overhead monotonically. Raising
target pool size p can moderately increase the attacker’s accuracy.
According to Figure 3a, the lowest accuracy rate is 59% when α =
10 and p = 1, and its corresponding bandwidth overhead is 53%. α
= 10 and p = 1 in Case II provides the lowest accuracy rate (55%)
with bandwidth overhead of 63%.
Our evaluations show that Case I provides lower bandwidth over-
head than Case II (between 15% to 27% lower) and the detectability
of the generated samples is comparable with Case II. This means
that picking target samples from classes that the detector trained
on reduces bandwidth overhead. According to our results, our best
setting is to pick target samples from the classes that the detector
trained on with p=1 and α=5. Walkie-Talkie still has lower attack ac-
curacy than this setting, 49% to our 60%, but its bandwidth overhead
is 46% higher than our defense.
4 CONCLUSION & FUTURE WORK
In this work, we propose a new defense against WF attacks with
lower bandwidth overhead than Walkie-Talkie, the state-of-the-
art defense, with reasonable reductions in attacker accuracy. The
defense uses a novel mechanism that adapts techniques used to
create adversarial examples against machine learning classifiers,
applying them to website traffic traces. The generated adversarial
traces can limit the adversary even though he is trained on the
adversarial traces. To protect a traffic trace, we add fake packets to
the source trace to shorten the distance between the source sample
and a randomly selected target sample representing another website.
Our defense mechanism results in 47% bandwidth overhead and
drops the accuracy rate of the state-of-the-art WF attack from 98%
to 60%. We emphasize that our tests are conducted in the closed-
world setting, where the attacker knows that the user is visiting one
of the monitored set of websites. In the more realistic open-world
setting, where the user could visit any site on the Web, 60% accuracy
is very likely to lead to many false positives for the attacker. In
future work, we plan to investigate more to improve the defense
and show how to implement it.
ACKNOWLEDGMENT
This material is based upon work supported by the National Science
Foundation under Grants Numbers 1423163, 1722743, and 1816851.
REFERENCES
[1] Xiang Cai, Rishab Nithyanand, and Rob Johnson. 2014. CS-BuFLO: A Congestion
Sensitive Website Fingerprinting Defense. In Workshop on Privacy in the Electronic
Society (WPES).
passive website fingerprinting attacks. In USENIX Security Symposium.
[11] CV V Wright, SE E Coull, and Fabian Monrose. 2009. Traffic morphing: An
efficient defense against statistical traffic analysis. In Network & Distributed
System Security Symposium (NDSS).
[2] Xiang Cai, Rishab Nithyanand, Tao Wang, Rob Johnson, and Ian Goldberg. 2014.
A Systematic Approach to Developing and Evaluating Website Fingerprinting
Defenses. In ACM Conference on Computer and Communications Security (CCS).
[3] Xiang Cai, Xin Cheng Zhang, Brijesh Joshi, and Rob Johnson. 2012. Touching from
a Distance: Website Fingerprinting Attacks and Defenses. In ACM Conference on
Computer and Communications Security (CCS).
[4] Marc Juárez, Mohsen Imani, Mike Perry, Claudia Díaz, and Matthew Wright. 2016.
Toward an Efficient Website Fingerprinting Defense. In European Symposium on
Research in Computer Security (ESORICS).
[5] Xiapu Luo, Peng Zhou, EWW Chan, and Wenke Lee. 2011. HTTPOS: Sealing
Information Leaks with Browser-side Obfuscation of Encrypted Flows. In Network
& Distributed System Security Symposium (NDSS).
[6] Rishab Nithyanand, Xiang Cai, and Rob Johnson. 2014. Glove: A Bespoke Website
Fingerprinting Defense. In Workshop on Privacy in the Electronic Society (WPES).
Experimental Defense for Website Traffic Fin-
https://blog.torproject.org/blog/
gerprinting.
experimental-defense-website-traffic-fingerprinting.
[7] Mike Perry. 2011.
Tor Project Blog.
[8] Payap Sirinam, Mohsen Imani, Marc Juarez, and Matthew Wright. 2018. Deep Fin-
gerprinting: Undermining Website Fingerprinting Defenses with Deep Learning.
arXiv:arXiv:1801.02265
[9] Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
Ian Goodfellow, and Rob Fergus. 2013. Intriguing properties of neural networks.
In International Conference on Learning Representations (ICLR).
[10] Tao Wang and Ian Goldberg. 2017. Walkie-talkie: An efficient defense against
0510150.40.60.8αAccuracy(%)p=1p=3p=5WT0510150.40.60.8αAccuracy(%)p=1p=3p=5WTPoster PresentationCCS’18, October 15-19, 2018, Toronto, ON, Canada2227