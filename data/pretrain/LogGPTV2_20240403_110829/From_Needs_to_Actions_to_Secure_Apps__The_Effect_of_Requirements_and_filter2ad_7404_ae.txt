Psychological Testing: A Practical Approach to 
Design and Evaluation. SAGE Publications, Inc., 
Thousand Oaks, California, 2005. 
[25]  Kluyver, T., Ragan-kelley, B., Pérez, F., et al. Jupyter 
Notebooks: A Publishing Format for Reproducible 
Computational Workflows. In Positioning and Power 
in Academic Publishing: Players, Agents and Agendas. 
IOS Press, 2016, 87–90. 
[26]  Kruger, S., Nadi, S., Reif, M., et al. CogniCrypt: 
Supporting Developers in Using Cryptography. ASE 
2017 - Proceedings of the 32nd IEEE/ACM 
International Conference on Automated Software 
Engineering, (2017), 931–936. 
[27]  Li, L., Bartel, A., Bissyandé, T.F., et al. IccTA: 
Detecting Inter-Component Privacy Leaks in Android 
Apps. Proceedings - International Conference on 
Software Engineering 1, (2015), 280–291. 
[28]  Li, L., Bissyandé, T.F., Papadakis, M., et al. Static 
Analysis of Android Apps: A Systematic Literature 
Review. Information and Software Technology 88, 
(2017), 67–95. 
[29]  McDaniel, P. and Enck, W. Not So Great 
Expectations: Why Application Markets Haven’t 
Failed Security. IEEE Security & Privacy Magazine 8, 
5 (2010), 76–78. 
[30]  Nayak, K., Marino, D., Efstathopoulos, P., and 
Dumitraş, T. Some Vulnerabilities Are Different Than 
Others: Studying Vulnerabilities and Attack Surfaces 
in the Wild. International Symposium on Research in 
Attacks, Intrusions and Defenses (RAID), (2014). 
[31]  O’Brien, R.M. The Use of Pearson’s with Ordinal 
Data. American Sociological Review 44, 5 (1979), 
851–857. 
[32]  Oliveira, D., Rosenthal, M., Morin, N., Yeh, K.-C., 
Cappos, J., and Zhuang, Y. It’s the Psychology Stupid: 
How Heuristics Explain Software Vulnerabilities and 
How Priming Can Illuminate Developer’s Blind Spots. 
Proceedings of the 30th Annual Computer Security 
Applications Conference (ACSAC14), (2014). 
[33]  Oltrogge, M., Derr, E., Stransky, C., et al. The Rise of 
the Citizen Developer: Assessing the Security Impact 
of Online App Generators. Proceedings - IEEE 
Symposium on Security and Privacy, IEEE (2018), 
634–647. 
[34]  OWASP. Mobile Security Project - Top Ten Mobile 
Risks. 
https://www.owasp.org/index.php/Projects/OWASP_
Mobile_Security_Project_-_Top_Ten_Mobile_Risks. 
[35]  Pal, S. The Assumptions in Linear Correlations. 
Helpful Stats, 2017. 
https://helpfulstats.com/assumptions-correlation/. 
[36]  Presser, S., Couper, M.P., Lessler, J.T., et al. Methods 
for Testing and Evaluating Survey Questions. Public 
Opinion 68, 1 (2004), 109–130. 
[37]  Qualtrics. Qualtrics Survey Service. 
https://www.qualtrics.com/. 
[38]  Rasthofer, S., Arzt, S., Hahn, R., Kolhagen, M., and 
Bodden, E. Black Hat 2015: (In)Security of Backend-
as-a-Service. 2015. 
http://bodden.de/pubs/rah+15backend.pdf. 
[39]  Reyes, I., Wijesekera, P., Reardon, J., et al. Won’t 
Somebody Think of the Children? Examining COPPA 
Compliance at Scale. Proceedings on Privacy 
Enhancing Technologies 2018, 3 (2018), 63–83. 
[40]  Rumsey, D. Statistics II for Dummies. Wiley, 
Indianapolis, 2009. 
[41]  Safavian, S.R. and Landgrebe, D. A Survey of 
Decision Tree Classifier Methodology. IEEE 
Transactions on Systems, Man and Cybernetics 21, 3 
(1991), 660–674. 
[42]  Senarath, A. and Arachchilage, N.A.G. Why 
Developers Cannot Embed Privacy into Software 
Systems? Proceedings of the 22nd International 
Conference on Evaluation and Assessment in Software 
Engineering (EASE18), (2018), 211–216. 
[43]  Stack Overflow. Developer Survey Results 2019. 
2019. https://insights.stackoverflow.com/survey/2019. 
[44]  Stevens, S.S. On the Theory of Scales of 
Measurement. Science 103, 2684 (1946), 677–680. 
[45]  Such, J.M., Gouglidis, A., Knowles, W., Misra, G., 
and Rashid, A. Information Assurance Techniques: 
Perceived Cost Effectiveness. Computers and Security 
60, (2016), 117–133. 
[46]  The Harris Poll. Norton LifeLock Cyber Safety Insights 
Report. 2018. 
[47]  Turpe, S. The Trouble with Security Requirements. 
Proceedings - 2017 IEEE 25th International 
Requirements Engineering Conference, RE 2017, 
(2017), 122–133. 
[48]  USCF. Confidence Interval for a Proportion. 
http://www.sample-size.net/confidence-interval-
proportion/. 
[49]  Vaniea, K. and Rashidi, Y. Tales of Software Updates: 
The Process of Updating Software. Proceedings for 
Computer Human Interaction (CHI) 2016, (2016), 
3215–3226. 
[50]  Wei, F., Lin, X., Ou, X., Chen, T., and Zhang, X. JN-
SAF: Precise and Efficient NDK/JNI-Aware Inter-
Language Static Analysis Framework for Security 
Vetting of Android Applications With Native Code. 
Proceedings of the ACM Conference on Computer and 
Communications Security (CCS18), 1 (2018), 1137–
1150. 
USENIX Association
29th USENIX Security Symposium    303
[51]  Weir, C., Becker, I., Noble, J., Blair, L., Sasse, M.A., 
and Rashid, A. Interventions for Software Security: 
Creating a Lightweight Program of Assurance 
Techniques for Developers. Proceedings of the 41st 
International Conference on Software Engineering: 
Software Engineering in Practice, IEEE (2019). 
[52]  Weir, C., Hermann, B., Stransky, C., Wermke, D., and 
Fahl, S. Public Dataset from Online Android App 
Developer Survey. 2019. 
https://dx.doi.org/10.17635/lancaster/researchdata/319. 
[53]  Weir, C., Rashid, A., and Noble, J. I’d Like to Have an 
Argument, Please: Using Dialectic for Effective App 
Security. Proceedings 2nd European Workshop on 
Usable Security, Internet Society (2017). 
[54]  Wermke, D., Reaves, B., Huaman, N., Traynor, P., 
Acar, Y., and Fahl, S. A Large Scale Investigation of 
Obfuscation Use in Google Play. Proceedings of the 
34th Annual Computer Security Applications 
Conference (ACSAC), (2018), 222–235. 
[55]  De Win, B., Scandariato, R., Buyens, K., Grégoire, J., 
and Joosen, W. On the Secure Software Development 
Process: CLASP, SDL and Touchpoints Compared. 
Information and Software Technology 51, 7 (2009), 
1152–1171. 
[56]  Witschey, J., Zielinska, O., Welk, A., Murphy-Hill, E., 
Mayhorn, C., and Zimmermann, T. Quantifying 
Developers’ Adoption of Security Tools. Proceedings 
of the 2015 10th Joint Meeting on Foundations of 
Software Engineering - ESEC/FSE 2015, ACM Press 
(2015), 260–271. 
[57]  Xie, J., Lipford, H.R., and Chu, B.B.-T. Evaluating 
Interactive Support for Secure Programming. SIGCHI 
Conference on Human Factors in Computing Systems, 
ACM (2012), 2707–2716. 
[58]  Zhao, Q., Zuo, C., Pellegrino, G., and Lin, Z. Geo-
locating Drivers : A Study of Sensitive Data Leakage 
in Ride-Hailing Services. Symposium Network and 
Distributed System Security Symposium (NDSS), 
February (2019). 
Appendix A   Analysis Tool Versions 
The following are the versions of the tools we used for appli-
cation analysis. 
MalloDroid  
OPAL framework  
curl 
openssl 
FlowDroid  
LibScout  
CogniCrypt 
Appendix B   Survey Questions 
The following are the survey questions. Some questions were 
skipped if appropriate (marked with *). The answer formats 
are abbreviated as follows: 
Version Dec 30, 2013  
Version 1.0.0  
Version 7.64.0  
Version 1.1.1b 
Version 2.7.1 
Version 2.3.2 
Version 1.0.0 
YN 
SS 
MS 
LSS 
Yes or No 
Single Selection. 
Multiple Selection 
Likert-Style  Scale:  Extremely,  though  to 
Not at all. 
0-100  Slider selecting an integer 
N 
Integer 
In addition, ‘?’ indicates an ‘I don’t know’ option, and ‘O’ an 
‘Other’ option, where the participant could enter open text. In 
Q10 and Q21, the option descriptions give the encodings used 
in Appendix C .  
Q1-Q3 were text-only statements. 
Q4 Are you working in a team with others, such as develop-
ers, testers, project managers? [YN] 
Q5* What is your role? [SSO?] 
Programmer,  Tester,  Project  Manager,  Non-Spe-
cific 
Q6* What other roles apart from yourself are there in your 
team? [MS?] 
Programmer,  Tester,  Project  Manager,  Non-Spe-
cific 
Q7* About how many people (including developers, project 
managers, testers) are there in your team? [N] 
Q8 Please select all the ways you use to develop Android 
apps [MSO] 
Native Java, JavaScript, C#, Dart, Python, Kotlin, 
Lua, Native C++ 
Q10 How often did you release a new version of your app 
over the past two years? Please give your best estimate; if you 
have more than one app, please answer for that app that was 
most frequently updated. [SS] 
Never  (0),  Annually  (1),  Quarterly  (4),  Monthly 
(12), More frequently (24) 
Q11* Over the last one to two years, what content has been 
in your app updates (%)?  
New features [0-100] 
Non-security bug fixes [0-100] 
Security bug fixes [0-100] 
Third party library updates [0-100] 
Regular maintenance and refactoring [0-100] 
Q12 How important is each of the following for your app(s)? 
Runs on many different devices [LSS] 
Secure against malicious attackers [LSS] 
Protects users' privacy [LSS] 
Easy to use [LSS] 
Supports many features [LSS] 
Runs smoothly [LSS] 
Q13 How important is security for sales? [LSS] 
304    29th USENIX Security Symposium
USENIX Association
Q14 How knowledgeable do you consider yourself about in-
formation security? [LSS] 
Q15 Does your app development ever get support from pro-
fessional security experts? [YN?] 
Q16*  Who  are  these  professional  security  experts  (on 
team/external)? [SS] 
Q17* What support do you get from them? Please select all 
that apply [MSO] 
Penetration testing 
Audits 
Working on team 
Security training 
Design reviews 
I don't know  
Q18* About how often do you get support from them? [SS?] 
Continuously, Weekly, Monthly, Quarterly, Yearly 
Q19 Which of the following have led to changes in the secu-
rity of your app(s) in the past one to two years? [MSO] 
Decision from management  
Security crisis within your organization  
Media coverage about app security  
Something bad happening to a competitor  
Pressure from a partner company  
Drive from product or sales team  
Pressure from customers  
Developer initiative  
GDPR requirements  
Something bad almost happening to your organiza-
tion  
Q20* What changes have you made as a result of GDPR re-
quirements? [MSO] 
Addition of popup dialog(s)  
Removal of analytics or advertising based on it  
Adding or changing privacy policy  
Q21 How much do you use each of the following techniques 
to find security problems? [SS for each: 
Every  build  (4),  Every  release  (3),  Once  or  occa-
sionally (2), Decided not to use (1), Haven’t consid-
ered it (0).] 
Producing a threat assessment for the app 
Scanning code with an automatic code review tool 
Using a tool to scan for libraries with known vulnerabili-
ties 
Code review by someone other than the developer 
Penetration testing 
Q22 What other techniques do you use (if any)? [O] 
23 Do you have a security champion within your team? A 
security champion -- or security hobbyist -- is a non-expert, 
who takes a particular interest in security. [YN?] 
Q24 For how many years have you been developing Android 
apps? [N] 
Q25  For  how  many  years  have  you  been  programming  in 
general (not just for Android)? [N] 
Q26 About how many Android apps have you helped develop 
in total? [N] 
Q27 Is developing Android apps your primary job? [YN] 
Q28 Have you contributed to an open source project in the 
past year? [YN] 
Q29 To which gender identity do you most identify? [SS]: 
Female, Non-binary, Male, Prefer not to say 
Q30 What is the main spoken language you use at work? [SS] 
English, Chinese, Spanish, Arabic, German, French, 
Other 
Q31 In which country do you currently reside? [SS]  
Appendix C   Calculation of Scores 
This section describes how scores were calculated from the 
survey answers. 
Likert-Style Scales were encoded as:  
Extremely … (4), Very … (3), Moderately … (2), 
Slightly …(1), Not … at all  (0)  
Assurance Technique Score: sum of all five sub-questions of 
Q21, each encoded as shown.  
Developer Knowledge Score: LSS encoding of Q14 
Expertise Support Score: as the following table. 
Yes 
2 
3 
Q23: 
No 
Yes 
\  Q15:  No 
0 
1 
Requirements Score: sum of LSS encodings for Q12 (Secure 
against  malicious  attackers),  Q12  (Protects  users'  privacy) 
and Q13 
Security Update Frequency Score: This required an Update Fre-
quency Estimate of Q10 encoded as shown multiplied by Q11 
(Security bug fixes) and divided by 100. The score was Log 
(this value plus 1).  
Appendix D   Model Comparison 
To compare a decision tree model, we used the Python scikit-
learn library’s DecisionTreeRegressor, compared with Stats-
Models’ OLS (Ordinary Least Squares).   
We compared each pair of models using the F-Test calcula-
tion [13], taking the number of ‘leaf nodes’ in the decision 
tree as the degrees of freedom for that model in the F-Test. 
Applying  the  Bonferroni  correction  [40],  we  took  the  re-
quired Alpha P-value for significance as 0.01. The calculated 
P-values values ranged from 0.2 to 0.5, and did not approach 
that value. 
USENIX Association
29th USENIX Security Symposium    305