use MOS data to ﬁt model parameters, or machine learning models, where MOS
data is used to train the model.
2 https://www.w3.org/TR/navigation-timing/.
Narrowing the Gap Between QoS Metrics and Web QoE
35
Expert Models. Two well established [22], models of Web QoE are the ITU-T
recommendation model [17] and the IQX [14] hypothesis. The ITU-T model
follows the Weber-Fechner Law and assumes that the user QoE has a logarithmic
relationship with the underlying QoS metric. The model is in the form:
QoE(x) = α log(x) + γ,
(2)
where x is the QoS metric (typically, PLT) and with α, γ parameters. The ITU-T
models are derived for three diﬀerent contexts (fast, medium, and slow networks)
with a diﬀerent minimum and maximum session time for the diﬀerent contexts
so that QoE ∈ [1, 5].
Alternatively, the model based on the IQX hypothesis [14] postulates an
exponential interdependency between QoE and QoS metrics. The idea of the
model is that if the QoE is high, a small variation in the underlying QoS metric
will strongly aﬀect the QoE. Instead, a degradation in QoS metric will not lower
QoE as much if the overall QoE is already bad. Under IQX, for a given change
in QoS metric the change of QoE depends on the current level of QoE as:
QoE(x) = αe−βx + γ
(3)
where x is a QoS metric and with α, β, γ parameters. We evaluate both loga-
rithmic and exponential models in Sect. 4.
Machine Learning. While machine learning algorithms have been used to
model QoE for VoIP [12], video streaming [6] or Skype [23], its application to
Web browsing is still lacking. One marked exception is the work by Gao et al. [15],
where authors formulate a ternary classiﬁcation task (i.e., A is faster, B is faster,
none is faster) and employ Random Forest and Gradient Boosting ML techniques
with QoS metrics such as those described in Sect. 2.1 as input features. In this
paper, we focus on a more diﬃcult task, formulated as a regression problem in
the support M OS ∈ [1, 5] ⊂ R, and additionally contrast ML results to those
achievable by state of the art expert models.
3 Approximating the ATF time
One way to calculate the ATF time is to monitor the page rendering process
and identify when the pixels on the visible part of the page, also known as the
above-the-fold part, stop changing. This can be done by monitoring the individ-
ually rendered pixels (or histograms of the rendering) and detecting when they
stabilize. This approach, however, is processing intensive and diﬃcult to apply
in the wild, as the overhead may impair user experience. Webpages also contain
visual jitter due to, for example, layout instabilities or carousel elements [15],
making it harder to detect the ATF time using pixel comparison methods.
36
D. N. da Hora et al.
Methodology. We propose a method to approximate the ATF time from the
browser itself without requiring image processing. We leverage the browser’s
ability to determine the position of objects inside a fully rendered page and the
recorded loading times of HTTP requests. Our method works as follows. First,
we detect all the elements of the Webpage and the browser window size. Then,
we trace loading time and resource type for all HTTP requests, and determine
which objects are rendered above-the-fold. To do so, we use simple heuristics
to classify resource types between images, JavaScripts (JS), CSS, HTML, etc.
For objects that are directly rendered (e.g., of the image class), the coordinates
make it obvious whether they are, at least partly, above-the-fold. For objects
for which we have no direct indication whether they are used for rendering
(e.g., styles that are deﬁned through CSS; visual changes generated by JS), we
conservatively assume they are required for rendering above-the-fold content.
More formally, denoting with To the loading time of object o, and letting I be
the set of all images, IAT F the subset of images whose coordinates are at least
partially above-the-fold, J the set of all JavaScript HTTP requests and C the
set of all CSS requests, we calculate the Approximate ATF (AATF) time as:
AAT F = max
o
{To|o ∈ J ∪ C ∪ IAT F}
(4)
We stress that AATF should not be considered as a replacement metric for ATF:
to that extent, it would be necessary to comprehensively validate AATF against
pixel-based measurements of ATF, which we leave for future work. At the same
time, our experiments indicate that AATF has a good discriminative power as
it helps ameliorate forecasts of user MOS, and as such has value on its own.
Implementation. We implemented the method to approximate the ATF time
as an open-source Chrome extension [5]. The script executes after the onLoad
event triggers. We use jQuery to detect visible DOM objects. For each object, we
detect its position and dimensions on the page. We use this information along-
side the dimension of the browser window, which we obtain using JavaScript,
to determine which DOM objects are visible and above-the-fold. We use the
Window.performance API to obtain the name, type, and timing information
about the resources loaded in the page. We compare the src ﬁeld of DOM
object to the url of HTTP request to match HTML objects to its correspond-
ing timing information. Finally, we calculate the AATF time using (4). Figure 2
shows and comments an example of the results from the extension applied when
browsing the Amazon Webpage. It can be seen that only 8 of the 154 images
are located above-the-fold (circled in blue in Fig. 2), with a signiﬁcant diﬀerence
between PLT, ATF and derived metrics.
Approximations and Limitations. As in any real-world deployment, we
ﬁnd a number of technicalities which complicates the process of detecting the
resources located above the fold. For instance, some Webpages contain sliding
images which keep rotating in the above-the-fold area. Additionally, there are
Narrowing the Gap Between QoS Metrics and Web QoE
37
Fig. 2. Extension example: Time-instant metrics show that whereas DOM loads at
2.62 s, all objects above the fold are rendered on or before AATF=5.37 s and then
the page ﬁnishes loading at PLT=16.11 s. By deﬁnition, Time-integral metrics are
even shorter BIAAT F  0.8) Pearson correlation with MOS. Speciﬁcally, we see that counting
bytes (BI) and especially image bytes (II) is more valuable than counting objects
(OI). Additionally, results conﬁrm the importance of evaluating time-integrals by
narrowing their time-horizon before the PLT (as suggested by Gao et al. [15]),
conﬁrming the importance of estimating the ATF time (as proposed in this
paper). Overall, the metric with best correlation to MOS is IIAAT F (0.85), with
Narrowing the Gap Between QoS Metrics and Web QoE
39
Fig. 3. Expert models: Impact of (a) explanatory QoS metric x for the f (·) =IQX
hypothesis and (b) combined impact of metric x and mapping function f (·)
PLT ranking seventh (0.81). These results conﬁrm the soundness of using the
AATF time as proxy of user-perceived page loading time [24].