memory to keep execution deterministic. This can be ac-
complished by making the area inaccessible to the reader,
and intercepting all read attempts using the generated page
faults. Doing so would be expensive, especially if done from
user space. Fortunately, we have had no need for this in our
implementation.
Ioctls
3.1.3
I/O control, mostly performed using the ioctl system call,
is part of the interface between user and kernel space. Pro-
grams typically use ioctls to allow userland code to commu-
nicate with device drivers. Each request uses a command
number which identiﬁes the operation to be performed and
in certain cases the receiver. Attempts have been made to
apply a formula on this number that would indicate the di-
rection of an operation, as well as the size of the data being
transferred. Unfortunately, due to backward compatibility
issues and programmer errors actual ioctl numbers do not
always follow this convention. Furthermore, Android per-
forms most of its IPC through the kernel using the binder
framework [33]. Many of the binder operations actually re-
sult in one or more ioctls on the “/dev/binder” device. Thus,
it is important that we can access the Android kernel source
code to check the semantics of the various ioctls being used.
Fortunately, smartphones make use of fewer ioctls than PCs,
but the procedure is still a tedious one. Our prototype han-
dles about two hundred ioctl commands.
3.2 Execution Trace Compression
One of our primary goals is to minimise transmission costs,
which requires minimising the size of the execution trace.
Here we discuss the rules we applied to reduce the size of
the trace:
• Record only system calls that introduce nondetermin-
ism. Phone and replica execute the same instruction
stream, so there is no need to record system calls that
have identical eﬀects in both (e.g., creating a socket,
opening a ﬁle, reading from local storage, etc.). We
also do not record the results of systems call used for
IPC between processes, as the mirror processes on the
replica will generate the same data.
• Use a network proxy so that inbound data are not logged
in the trace. The data received by the phone over the
network are not directly seen by the replica (e.g., a re-
ceived email). We introduce a transparent proxy that
logs all Internet traﬃc towards the phone, and makes
it available to the security server upon request. This
way the phone does not need to waste precious energy
to log and transmit them to the replica.
• Compress data using three algorithms. First, we en-
code time related data returned by calls such as get-
timeofday and clock gettime using delta encoding, re-
placing the actual time data in the trace with the
diﬀerences of consecutive values. Second, we employ
Huﬀman encoding to represent frequent values in the
trace. For instance, we use a bit to represent a system
call that returned zero, another one to indicate that
a log entry has been produced by the same thread as
the previous entry, etc. Finally, we employ general
purpose compression using the DEFLATE algorithm
(also used by the gzip utility).
3.3 Attack Detection Mechanisms
We demonstrate the detection capabilities of the security
server by developing two very diﬀerent detection mecha-
nisms: an anti-virus scanner, and an emulator-based detec-
tor that uses dynamic taint analysis.
3.3.1 Virus Scanner
One of the security measures we apply at the server is anti-
virus scanning. For this purpose, we modiﬁed the popular
open source anti-virus ClamAV to run in the Android em-
ulator. ClamAV contains more than 500000 signatures for
viruses that a user would have to store locally on his phone
and update daily. Using PA, we perform ﬁle scanning on the
server where both storage and processing is much cheaper.
Moreover, if we wish to further increase detection coverage
we may employ multiple scanners at the same time, as sug-
gested by Oberheide et al. [30].
3.3.2 Dynamic Taint Analysis
PA can go a lot further than just running multiple anti-
virus software in the cloud. We modiﬁed the Android em-
ulator to apply dynamic taint analysis (DTA) on the re-
plica [10, 27]. DTA is a powerful, but expensive method to
detect intrusions. The technique ﬂags all data that arrive
from a suspect source (like the network) as tainted. Tainted
data are tracked throughout the execution of the system, so
that all data the depend on tainted data are also ﬂagged
Figure 2: Data generated by PA on a user operated
HTC G1 for a day.
as tainted. For instance, when tainted values are used as
source operands in ALU operations or copied, the destina-
tion is also tainted. When an attacker exploits a vulnera-
bility (e.g., a buﬀer overﬂow, a format string attack, a dan-
gling pointer, etc.) to inject and execute arbitrary code, or
simply arbitrarily redirect the execution ﬂow of the vulner-
able program (e.g., using return-to-libc, or return oriented
shellcode), DTA identiﬁes the illegal use of tainted data and
raises an alert. For instance, an alert is raised when tainted
data are executed, or used as an operand of a CALL instruc-
tion.
DTA works against a host of exploits, including zero-day
attacks, and incurs practically no false positives. Unfor-
tunately, the overhead imposed is very high, making it an
impractical solution to deploy on production systems (both
PCs and phones). By applying DTA on a smartphone’s re-
plica, we manage to hide its overhead from the end user,
and concurrently exploit the more powerful hardware in the
cloud to accelerate it.
4. EVALUATION
We evaluate our implementation of PA along three axes:
the amount of trace data generated during recording, the
overhead imposed by the tracer on the device, and ﬁnally the
performance and scalability of the server hosting the repli-
cas. We run the tracer on the HTC G1 developer phone,
while the replayer is hosted on the modiﬁed QEMU [1] em-
ulator that comes with the oﬃcial SDK. We do not perform
a security evaluation of our taint analysis implemention on
QEMU, as it has been suﬃciently demonstrated by [35].
4.1 Data Volume
The volume of data generated by the tracer constitutes
an important metric, as it directly aﬀects the amount of en-
ergy required to transmit the trace log to the server, and the
storage space needed to store it on the device when discon-
nected from the server. Additionally, the upload bandwidth
available to smartphone users (usually a few hundred Kbps)
is a scarce resource, as it is frequently much less than the
Hours00040812162024KiBytes5101520253035Average RateDataAverate Data Generation RateFigure 3: Average data generation rate, when per-
forming various tasks.
available download bandwidth.
Our traces collected from actual users using their phones
show, not surprisingly perhaps, that mobile devices are mostly
idle, or used for voice calls. A plot of the amount of data
generated by PA over time is shown in Figure 2. Mean-
while, Figure 3 shows that the data generated when the
device is idle or the user is making a call is negligible, with
an average of 64B/s and 121B/s respectively. Even when
performing more intensive tasks, such as browsing or listen-
ing to music, the tracer generates less than 2KiB/s. For
instance, 5 hours2 of audio playback would generate about
22.5MB of trace data. Transmitting such an amount of data
solely over 3G may burden users with excessive costs, spe-
cially when operators cap their bandwidth and charge extra
for data transfers over the cap, but it can be easily stored
locally on the smartphone (devices already oﬀer relatively
large amounts of storage; e.g., the iPhone 4 oﬀers 32GB of
storage) until a WiFi connection is available. Taking into
account that many users spend most of their time at home
or at the oﬃce, it is very likely that WiFi connectivity will
be frequently available to synchronize with the server.
4.2 Overhead
PA imposes two types of overhead on the phone. First,
it consumes additional CPU cycles and thus incurs a per-
formance overhead. Second, it consumes more power be-
cause of the increased CPU usage and the transmission of
the execution trace to the server. To quantify these costs, we
monitored the device’s CPU load average, and battery level,
while randomly browsing URLs from [7]. We performed this
task natively as well as under PA, and show the results in
Figure 4.
Figure 4 conﬁrms that PA increases the CPU load on the
device. In particular, the mean CPU load during this ex-
periment was about 15% higher when using PA. The use of
compression and encryption is somewhat costly in terms of
2Typical battery life when browsing or reproducing audio
can range from 3 to 8 hours depending on the device.
Figure 4: Battery level and CPU load average
while browsing on the HTC G1 developer phone.
We draw two independent experiments, where we
browse URLs from [7] natively and under PA.
processing, but the amount of data we generate does not
seem to justify for such a divergence. The ﬁgure also shows
how battery capacity drops in time while browsing. As ex-
pected power is consumed faster when using PA. When idle
or in light use, the additional battery consumption is mini-
mal, but heavyweight tasks, such as browsing may consume
up to 30% more energy.
However, most of this overhead seems to be due to the
additional CPU cycles consumed by the user space tracer.
We conﬁrmed this by way of an experiment where we only
transmit the trace data corresponding to the browsing ac-
tivity (using SSL as the tracer would do), and found that
the device did not report any drop in battery level. We in-
vestigate the cause behind this increase in CPU load and
battery consumption, and discuss our ﬁndings in 4.4.
4.3 Server Scalability
Chun et al. [6] has shown that simply moving computation
from a smartphone to faster hardware such as a PC, even
when running on an emulator, can increase performance up
to 11.8 times. While we cannot replay execution faster than
it is recorded, the signiﬁcant diﬀerence in processing power
between smartphones and PCs enables us to host multiple
replicas on each security server.
We corroborate our assumption by measuring the number
of phone replicas that can be run concurrently on various
hardware conﬁgurations. Each replica was run on the An-
droid Qemu-based emulator, executing the same task as the
original. It is also in-sync with the replayed device, i.e., the
replica has to wait for trace data from the device. While
running the replicas, we did not introduce any detection
mechanism or instrumentation, which represents an opti-
mal scenario for this experiment. The results are shown in
Figure 5, where we draw the number of replicas that can
be run under these conditions using diﬀerent hardware con-
ﬁgurations. Particularly, we used a dual-core (x2 2.26GHz
P8400) HP HDX18 notebook with 4GB of RAM, a four-
core (x4 2.40GHz Q6600) desktop PC with 8GB of RAM,
and a high-memory extra-large instance on Amazon’s Elastic
TasksBootingIdleCallingWebBrowsingGoogleMapsAudioPlayback00.511.522.5Rate (KiB/s)0Time0:000:100:200:30Battery capacity (%)80859095100CPU load average0123456Battery−NativeBattery−PALoad−NativeLoad−PAFigure 5: Number of replica instances that can be
run on a server without delay. As CPU utilisation
increases on the phone, fewer replicas can be exe-
cuting in sync with the phone.
Cloud (EC2) service with 68.4GB or RAM. When running
in the EC2 cloud, we were able to concurrently run more
than 100 replicas of devices exhibiting an average 25% CPU
utilisation. Utilisation is a key factor, since it determines
the number of replicas that can be run without delays, as
computation is relatively expensive when running under the
emulator.
Determining the average CPU utilisation of smartphones
in a realistic scenario is not a trivial task, and we are not
aware of any preexisting studies on the subject. Neverthe-
less, we can look at the intensity of diﬀerent tasks com-
monly performed on these devices. For instance, on the
HTC G1 developer phone we measured 90%-100% CPU util-
isation when running a game, 20%-25% when reproducing
audio, 30%-100% when browsing, and ﬁnally 0%-5% when
the phone is idle. We can intuitively argue that smartphones
remain idle or run non-interactive tasks like listening to mu-
sic most of the time. In the opposite case, battery is drained
quickly by the CPU (when running intensive tasks such as
browsing or gaming), the display, and various device sensors
(GPS, accelerometer, etc.).
We already mentioned that the results presented in Fig-
ure 5 present an optimal scenario, as no security mechanism
is applied. PA’s scalability actually depends on the type
and number of mechanisms introduced at the server. For
instance, previous work that implemented DTA for the x86
architecture using the Qemu emulator reported a x2-x2.5
slowdown compared with execution under Qemu alone. We
obtained similar results implementing DTA for the ARM ar-
chitecture using Android’s Qemu-based emulator. As such,
we estimate that if DTA is applied on every replica, we would
be able to run roughly half of the instances reported in Fig-
ure 5 without any delay. Finally, we have tested our scheme
on Amazon’s EC2 cloud service to demonstrate the scala-
bility of our approach. In practice, organisations that are
willing to invest in smartphone security, will most probably
host their own security servers as well as proxies to ensure
Figure 6: The time it takes to read 4Kbytes of data
from /dev/urandom natively, and when tracing.
Function
ptrace()
waitpid()
deﬂate slow()
pread64()
mcount interval()
event handler run()
Time Spent %
% 33.63
% 32.68
% 7.62
% 6.78
% 2.84
% 2.15
Table 1: Top executing functions in the tracer.
that privacy sensitive data remain within the organisation,
and to reduce costs3.
4.4 Overhead Imposed By Ptrace
We mentioned earlier that we observed an increase in CPU