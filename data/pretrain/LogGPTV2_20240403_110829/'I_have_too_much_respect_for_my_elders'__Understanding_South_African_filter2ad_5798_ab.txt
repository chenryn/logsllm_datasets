such as Facebook’s Free Basics platform. However, a study
done in 2018 [53] found that Free Basics users in South
Africa are unknowingly agreeing to additional data tracking
in exchange for free data, meaning that these users are left
more exposed in terms of privacy from the provider than users
of paid versions of those applications.2 Moreover, a study on
global Internet usage found that African countries tend to rank
near the bottom of all countries in terms of Internet connection
speeds, which also slows down social media usage [34].
2Free Basics uses a proxy for all apps offered through the platform allow-
ing Facebook access to data from all apps. This is not the case if a user is
using a paid version of the same app.
USENIX Association
29th USENIX Security Symposium    1951
3.2 Recruitment
We recruited participants over the age of 18 who lived and
worked in South Africa. We ﬁltered for participants with per-
sonal smart phones who were current users of the following
social media applications: Facebook, WhatsApp, Instagram,
and Facebook’s Free Basics platform. Users had to report
using at least one of these apps for at least three hours a day
to ﬁlter out novice users. This step ensured our users were
consistent with the proﬁle of an average African user who typ-
ically spends about three hours daily on social media [55]. We
focused on these applications because Facebook is the most
popular social media application in South Africa according to
Alexa’s rankings [1] and these other applications are part of
the Facebook suite. In addition, WhatsApp is one of the most
popular messaging applications in South Africa [60].
We recruited individuals through a variety of means, with
the understanding that users in different socioeconomic cir-
cumstances may have different usage patterns. To attract mid-
dle to upper class users, we created a targeted Facebook adver-
tisement for users who were between the ages of 18 and 65,
lived within 10 miles of Cape Town, and primarily accessed
Facebook from mobile devices. At the same time, we cre-
ated a banner advertisement on MyBroadband, South Africa’s
largest IT news site (ranked 60 on Alexa SA rankings [1]).
On both of those platforms, users who clicked on the adver-
tisement were directed to ﬁll out a questionnaire to ensure
that they were eligible for the study. We also publicized the
study on our research website and on Twitter.
To recruit individuals from lower-income backgrounds, our
research assistant in South Africa went into "spaza" shops
(small convenience stores) within the lower income commu-
nities of Langa, Delft, and Khayelitsha [18] which all form
part of a violence-prone area of Cape Town known as the
Cape Flats [2]. Individuals who were buying airtime were
approached and asked if they would agree to participate in our
study. Upon conﬁrming their eligibility, our research assistant
would set an appointment with them. Often, these individuals
would refer others for participation, but close friends or family
were not interviewed, so as not to bias the data.
None of our recruitment texts or verbal methods made
any reference to "security" or "privacy" to ensure that we
were not priming the subjects; rather, participants were told
they would be having a general conversation about "usage
of social media applications." We received interest from 54
individuals through the online advertisements. Of those, we
were able to schedule interviews with 16, due to time and
availability constraints, of which 12 arrived at their arranged
times to complete their respective interviews. Additionally, of
the 41 individuals recruited from lower-income communities,
40 completed their interviews, bringing the total number of
participants to 52. Attempts to remotely interview remaining
respondents on Skype were unsuccessful.
Interviews
3.3
Before participating in any interviews, each participant had
to complete two surveys. First, each completed a question-
naire that asked them how long they had been using social
media and which social media applications they used most fre-
quently of Facebook, WhatsApp, Instagram, and Free Basics.
We also asked if they used Snapchat, Twitter, or YouTube.
Secondly, each participant was given a demographic survey
to complete or verbally completed a survey that asked them
for their race/ethnicity, age, and gender identity.
Once participants completed the surveys, they were invited
for interviews. Those who had the means to travel were in-
terviewed at a non-proﬁt organization headquartered in Cape
Town and three were interviewed on Skype. All participants
from the Cape Flats were interviewed in their homes or home-
like settings near their places of residence. Additionally, all in-
terviews in the Cape Flats region were strictly time-bounded,
because the area is generally unsafe, and we did not want
our female research assistant to spend any more time than
absolutely necessary in the area. In some cases, this meant
we could not probe deeper into all topics e.g., detailed privacy
setting use on each social media application mentioned.
Most interviews were conducted in Xhosa (30/52), an of-
ﬁcial language of South Africa and the remainder were con-
ducted in English. All interviewees signed consent forms
before their interviews, which were all audio-recorded. Each
interview lasted approximately thirty to forty-ﬁve minutes and
participants were compensated for their participation with a
ZAR300 ($21 USD) gift voucher to Takealot.com, a widely-
used online shopping website in South Africa.
Each interview followed a tiered structure of questioning to
better understand participant’s mental models of privacy and
how they manage privacy on the Facebook suite of applica-
tions. First, the participants were asked questions about their
phones and their mobile data plans. Next, they were asked
about their usage on the applications: which of these social
media applications they visited most often and what their gen-
eral usage patterns were on each of those applications. We
did not ask about social media usage in a mobile browser. We
then asked the participants questions relating to their privacy
behaviors: who they thought could see their posts, which ap-
plications they were willing to share more information on,
what information they thought companies collect about them,
and if they knew of any settings on their social media appli-
cations that could help them maintain their online privacy.
Lastly, we asked participants questions relating to their on-
line privacy behavior: how they maintain their privacy on the
Internet, what tools, if any, they use to ensure their privacy, if
they had ever experienced a breach of privacy, and about their
usage of privacy settings on the Facebook suite of applications
or other applications/tool used for privacy purposes.
Example questions asked included:‘Is there anything you
avoid doing on social media? What? Why?’, ‘What does pri-
1952    29th USENIX Security Symposium
USENIX Association
Age
Group
18-25
26-34
35-44
45-54
55+
Total
24
15
10
2
1
Ethnicity
Group
Black
White
Indian/Asian
Total
46
5
1
Household Annual Income in USD
Group
Very Low Income (0−1,444)
Low Income (1,445−6,530)
Low Emerging Middle Class (6,531−14,482)
Entering Middle Class (14,483−29,570)
Did Not Disclose
Total
25
11
3
4
9
Gender
Group
Male
Female
Non-binary
Total
22
29
1
Table 1: Demographic breakdown of participants. Income is reported in United States Dollars (USD)
vacy on the Internet mean to you?’ and ‘Are you aware of pri-
vacy settings in any of the social media applications you use?’.
While the interviewers had a prepared set of questions to ask
the participants, all interviews followed a semi-structured for-
mat, so the researcher would follow up on particular questions
or subjects that generated unanticipated or relevant feedback
from each participant, which tended to vary vastly based on
the user’s usage patterns. All interviews were audio-taped.
3.4 Analysis
We ﬁrst transcribed the audio ﬁles, translating the 30 inter-
views that were conducted in Xhosa to English, and then
performed qualitative data coding on the transcripts. During
this process we tagged similar phrases or sentiments shared
by the participants using structural coding and thematic anal-
ysis [54]. The initial codebook we created was, at ﬁrst, largely
based on the interview guide, and was shared with our team
of ﬁve coders. Additionally, we edited and enhanced the code-
book as we noticed trends emerging from our ﬁrst pass over
the interviews. There were a total of 17 parent codes, with
each of them having 2-4 child codes, for a total of 34 codes as
shown in the Appendix. Examples of parent codes included:
‘Activities on phone’ and ‘Crime’ and example of child codes
included: ‘Expressed concern over advertisements’ and ‘Us-
age of privacy settings’.
Each interview underwent two rounds of coding by the
research team, comprised of 5 undergraduate students, includ-
ing the lead author, all trained in qualitative analysis. Each
transcript was coded by the lead author and at least one of
the other coders, and was reviewed by the most senior au-
thor. Once all the ﬁles were coded, each coder was assigned
1-2 parent codes and provided with all interview excerpts
tagged with those codes. Each coder performed a thematic
analysis on these excerpts and wrote a thematic summary.
The research team then held regular meetings to review all
of the summaries and to decide on the ﬁnal themes that are
discussed in the paper. Owing to the coding process, we did
not calculate inter-rater reliability (IRR) because thematic
analysis does not lend itself to such calculations and shared
consensus can still be reached without this measure [7]. 3
3As per McDonald et al. [41], calculating IRR is not necessary because
our coded data was not our end-goal but used as input for thematic analysis.
Although we did use multiple coders, all of our transcripts were read by the
lead and senior authors to ensure consistency. We resolved disagreements
In all interview snippets in this paper, I means that the
interviewer is speaking. Participants P1 through P12 were
interviewed by the ﬁrst author in downtown Cape Town, while
participants P13 through P52 were from the Cape Flats and
interviewed by our South African research assistant.
3.5 Participants
Our participants were very diverse (Table 1) with a nearly
even representation of females and males in the study. The
interviewees tended to skew towards a younger age range,
consistent with what should be expected for social media us-
age in South Africa [16]. Additionally, we asked individuals
what their household income levels were, so that we could
better understand if income levels had an inﬂuence on privacy
mental models. Using the Momentum Unisa Financial Well-
ness Index [66] as a reference, we conﬁrmed that most of the
participants fell into a lower-income bracket.
The majority of the participants were under 35 years of age
and most were Black with the remaining being White or In-
dian/Asian. 10/52 participants were students and 23/52 were
unemployed. Of those participants who disclosed income, the
majority earned less than ZAR21,500 ($1,444 USD) annually.
In the past 6 months, 24/52 participants reported that they
were unable to afford groceries in the last month, 26/52 re-
ported that they were concerned about paying bills, and 3/52
reported that their utilities were shut off due to unpaid bills.
90% of the Cape Flats participants reported being dependent
on welfare with no other source of income.
All of the participants reported using WhatsApp; only four
fewer reported Facebook use (Table 2). Fewer than half re-
ported using Instagram. More than a third of participants used
at least one of these three applications for greater than ﬁve
hours a day, while 23 others reported daily usage of between
three and ﬁve hours. Fewer participants used YouTube and
Snapchat, thus discussion of those apps was much more lim-
ited. The amount of time they had been using social media
varied. Many of the low income participants mentioned that
they often did not use apps that used up a lot of data such as
Instagram; they tried to use free apps and promotions such
as when one of the cellular networks offered Twitter for free
and Facebook’s Free Basics platform. Similar to ﬁndings in
poor areas of Kenya [75, 77, 78], participants said that they
use their phones for social media and to search for jobs.
using a dedicated Slack channel, email, and regular in-person team meetings.
USENIX Association
29th USENIX Security Symposium    1953
Category
App Use
Subcategory Count (X/52) Percent
WhatsApp
Facebook
YouTube
Instagram
Snapchat
>5 hours
4-5 hours
≤ 3 hours
>7 years
4-7 years
<4 years
52
48
19
16
5
21
23
8
23
16
13
Daily Use
Lifetime Use
100%
92%
37%
31%
10%
40%
45%
15%
44%
31%
23%
Table 2: Breakdown of participant social media habits
For the majority of participants in our study, WhatsApp was
their primary application used for messaging, whereas Face-
book was used more as a general social networking platform.
Participants also told us that WhatsApp was also preferred
because it uses far less data than Facebook, making it more
accessible and less expensive to use. Similarly, the few partic-
ipants who mentioned other social media apps, often spoke
of using these apps such as Twitter when there was a free
promotion to use it on their service provider or on a friend’s
phone or an Internet cafe. In a population in which data is
more of a luxury [53], ease of access is of high consideration4.
4 Findings
The main themes that emerged from the interviews were as
follows: First, the participants’ privacy concerns were primar-
ily centered around controlling their information and around