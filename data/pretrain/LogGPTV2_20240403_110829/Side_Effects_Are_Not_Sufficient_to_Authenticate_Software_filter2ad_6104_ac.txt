Genuinity test. First, the special instructions used in
the original test to access the instruction and data caches
and the TLB directly are not supported on Intel proces-
sors after the Pentium. To the best of our knowledge,
there are no available mechanisms to gain access to these
structures in more recent Intel processors. In addition,
the instruction counter did not return consistent results
between trials.
Intel does not guarantee the precision
or reproducibility of performance counters; they are in-
tended to be used as a guide for optimization. We there-
fore focused on two empirically repeatable counters that
approximated those from the original Genuinity descrip-
tion: one that measured ITLB misses and one that mea-
sured the number of conditional branch instructions.
We successfully implemented our attack; we were
able to compute the same checksum using the imposter
code as when using the unmodiﬁed checksum code. The
initial version of our attack code simply disabled the per-
formance counters before running any added code, then
re-enabled them before continuing. Unfortunately, the
multipurpose instructions required to do this are serializ-
ing (preventing instruction-level parallelism) on the x86
and cause a signiﬁcant slowdown; we stress that this is
an artifact of the design of the instruction set architec-
ture. On other architectures that provide dedicated in-
structions for this purpose, performance may be much
better. In response, we modiﬁed our attack code to cal-
culate the number of additional branches encountered
and the number of additional ITLB misses generated by
the attack and adjusted the counters appropriately.
The performance of the attack code, while not deﬁni-
tive in the absence of the original Genuinity code, was
encouraging. We ran each test with and without inlining
three times; the standard deviations in both cases were
less than 0.6%.
With inlining turned off in the C compiler, the im-
poster code took 35% longer than the legitimate code
(6.38s vs. 4.71s). This is the same as the 35% slow-
down allowed by Genuinity as determined by the ideal
simulator.
We also ran tests within inlining turned on. Due to
suboptimal inlining by our C compiler, the best per-
formance was obtained with no inlining. However, we
found that inlining all but the bit vector lookup table of
the imposter code could lead to a signiﬁcant speedup.
Inlining this portion in isolation gave an 18% speedup.
Adding in the time to execute the lookup table yielded a
net 42% slowdown over the fully inlined legitimate code.
While this is not within the 35% boundary, in Section 4.2
we discuss using a higher clock speed machine to reduce
the effective slowdown.
4.2 Improving attack performance
Suppose an adversary has an attack that computes the
checksum while inserting malicious code, but the com-
putation time does not fall inside the cutoff. The easiest
way to improve the checksum computing performance
is to increase clock speed. None of the side effects mea-
sures timing directly, because it is too difﬁcult to get ex-
actly repeatable results. Therefore, if all the CPU param-
eters except for clock speed are ﬁxed, an adversary will
compute the identical checksum value. This is easy to
do, since typically CPUs in the same line are released at
different clock speeds already. Another method would
be to use a higher-performance main memory system,
since main memory reads are the largest component of
the overall time. This modiﬁcation would not be re-
ﬂected in the checksum value either. It is reasonable to
expect that by claiming to have a 2 GHz Pentium 4 while
actually having a 3 GHz machine—a 50% increase in
clock speed—with an identical memory system, a con-
siderable amount of additional code could be executed
within the required time.
4.3 Countermeasures against substitution
attacks
One can already see a kind of arms race developing: test
writers might add new elements to the checksum, while
adversaries develop additional circumventions. While
it is possible to change the algorithm continually, it is
likely that hardware constraints will limit the scope of
the test in terms of available side effects; all an attacker
must do is break the scheme on some hardware. While
we believe that the attackers’ ability to have the “last
move” will always give them the advantage, we now
consider some countermeasures and examine why they
are unlikely to be signiﬁcantly more difﬁcult to accomo-
date than those we have already explored.
To prevent the single page substitution attack, Gen-
uinity could ﬁll the checksum code page with random
bits.
Genuinity could also use different performance
counter events or change the set used during the test.
However, since the authority precomputes the checksum
result, Genuinity must only use predictable counters in a
completely deterministic way; we can compute the ef-
fects of our malicious code on such counters and ﬁx
them on the ﬂy. For example, when the imposter check-
sum code starts executing instrutions that do not appear
in the original code, it disables the instruction counters,
and re-enables them after the extra instructions. Another
possible solution which we did not implement is to cal-
culate the difference in the number of instructions exe-
cuted by the imposter code and the original code, and
add this difference to the counter. We can treat other
counters similarly.
At least two other improvements are suggested in the
paper: self-modifying code and inspection of other in-
ternal CPU state related to instruction decoding. Since
our attack code is a superset of the legitimate checksum
code, and since we run on the same hardware (mod-
ulo clock speed) that we claim to have, neither of these
seems insurmountable. Clearly, self-modifying code
would require more sophisticated on-the-ﬂy rewriting of
the attack code, but by simply using a slightly faster ma-
chine (with the same TLB and cache parameters) this is
easily overcome: the attack code is quite modular and
easy to insert. As for inspection of instruction decod-
ing, since the original code is a subset of our code, the
internal state for the original instructions should be the
same.
4.4 Response to countermeasures: the two
page substitution attack
In Section 4.3, we describe some countermeasures Gen-
uinity could take to prevent the single page substitution
attack. We pick the ﬁrst of these, ﬁlling the code page
with random bits, and sketch a two page substitution at-
tack that defeats this countermeasure.
Suppose Genuinity ﬁlls the unused code page with
random bits, so the code page is not compressible. Then
the single page substitution attack does not work and the
imposter code must reside on a separate page.
We modify our attack somewhat
to accomodate
this change. The ﬁrst step is to identify an easily-
compressible page of code. Naturally, which particular
page is most easily compressible will depend on the par-
ticular build. Simple inspection of a recent Linux kernel
revealed that not only was the entire kernel compress-
ible by a factor of 3 (the original vmlinux kernel vs.
the compressed vmlinuz ﬁle), there were multiple 4K
contiguous regions containing either all zeroes or almost
all zeroes. Let us assume for the remainder of the discus-
sion that the page is all zeroes; it would take only minor
modiﬁcations to handle some non-zero values.
In ad-
dition, since our hijacked page is referenced very infre-
quently (approximately one data read out of every thou-
sand) that even if it took a little time to “uncompress” the
data, this would likely not increase the execution time
signiﬁcantly.
The key step is to “hijack” the page and use it to store
our imposter checksum code. The only memory region
this step requires modifying is the hijacked page. This
page, formerly zero-ﬁlled, now contains imposter check-
sum code.
The imposter code requires several ﬁxups to preserve
the invariants in Table 1.
The pseudocode looks like this:
imposter_memory_node:
addr = next_LFSR()
if page_number is hijacked_page
// Preserve data cache
temp = memory[addr]
// Add the original byte value
sum += 0
else
sum += memory[addr]
Let us review the checklist of invariants:
1. Instruction TLB. Instructions only come from only
one physical page. To preserve references to the
physical page number, we substitute the physical
address of the original code page. To preserve the
miss count, we can run the original checksum code
in advance and observe the TLB miss count when-
ever it is incorporated into the checksum. Eventu-
ally, this miss count should stabilize. Recall that
the checksum code is divided into 22 code chunks,
each of which refer to up to 2 virtual addresses.
Since the instruction TLB on the Pentium is fully
associative and contains 48 entries, all 44 of these
virtual addresses ﬁt into the ITLB. We estimate that
the TLB should stabilize quickly, so the observation
delay should not add signiﬁcantly to the total time
between receiving the challenge from the authority
and sending our response. After observing the pat-
tern of miss counts, the imposter checksum code
can use these wherever the TLB miss count should
be incorporated into the checksum.
In our implementation of the single page substi-
tution attack, the ITLB miss count stabilizes after
a single iteration through 22 code chunks, so this
ﬁxup is easy to accomplish.
2. Data TLB. The imposter checksum code performs
exactly the same pattern of memory loads as the
original code, so there are no changes to the DTLB.
3. Instruction cache. We simply ﬁll the cache line with
the contents of the original code page prior to ex-
ecuting the code to incorporate the cache data into
the checksum. To do this, we need to encode the
original checksum code in instructions, just as we
did for the bit vector in the single page attack (Sec-
tion 4.1). We unfortunately cannot read data di-
rectly from the original code page without altering
the data cache.
4. Data cache. There is no change to the data cache,
since the imposter code performs the same memory
loads as the original code.
5. Branch counter, instruction counter. These are the
same as in the original attack.
5 Breaking the key agreement protocol:
denial of service attacks
At the key agreement protocol level, two denial of ser-
vice attacks are possible. The ﬁrst is an attack against
the entity. Since there is no shared key between the au-
thority and the entity (the entity only has the authority’s
public key), anyone could simply submit fake Genuinity
test results for an entity, thereby causing the authority
to reject that entity and force a retest. A retest is par-
ticularly painful, since the Genuinity test must be run on
boot. Since the Genuinity test is designed to take as long
as possible, this DoS attack requires minimal effort on
the part of the attacker, since the attacker could wait as
long as the amount of time a genuine entity would take
to complete the test between sending DoS packets. It is
possible that Genuinity could ﬁx this problem by chang-
ing the key agreement protocol, but this attack works
against the current implementation.
The second denial of service attack, analyzed in more
depth in Section 6.2, is against the authority. Genuinity
assumes that an adversary does not have a fast simula-
tor for computing checksums, and so neither does the
authority. The authority must precompute checksums,
since the authority can compute them no more quickly
than a legitimate entity. The original paper claims that
the authority needs only enough checksums to satisfy the
initial burst of requests. This is true only in the absence
of malicious adversaries. It costs two messages for an
adversary to request a challenge and checksum. The ad-
versary can then throw away the challenge and repeat
indeﬁnitely. Further, the adversary can request a chal-
lenge for any type of processor the authority supports.
The adversary can choose a platform for which the au-
thority cannot compute the checksum natively. To make
matters worse, the authority cannot reuse the challenges
without compromising the security of the scheme, and
might have to deny legitimate requests.
5.1 Countermeasures against DoS attacks
To avoid the denial of service attack against the client,
Genuinity could assume that the client already has the
public key of the authority.
The second denial of service attack is more difﬁcult
to prevent. The authority could rate limit the number of
challenges it receives, but this solution does not scale for
widely-deployed, frequently used clients such as AIM.
6 Practical problems with implementing
the Genuinity test
We have presented a speciﬁc attack on the checksum
primitive, and an attack at the network key agreement
level. Genuinity could attempt to ﬁx these attacks with
countermeasures. However, even with countermeasures
to prevent attacks on the primitive or protocol, Genuinity
has myriad practical problems.
6.1 Difﬁculty of precisely simulating per-
formance counters
Based on our experience in implementing Genuinity, we
feel that it is likely to become increasingly difﬁcult, if
not impossible, to use many performance counters for a
genuinity test. Not only are many performance counter
values unrepeatable, even with interrupts disabled, they
are the product of a very complex microarchitecture do-
ing prefetching, branch prediction, and speculative exe-
cution. Any simulator—including the one used by the
authority—would have to do a very low-level simula-
tion in order to predict the values of performance coun-
ters with any certainty, and indeed many are not certain
even on the real hardware! We do not believe that such
simulators are likely to be available, let alone efﬁcient,
and may be virtually impossible; if the value of a per-
formance counter is off by even one out of millions of
samples, the results will be incorrect. This phenomenon
is not surprising, since the purpose of the counters is to
aid in debugging and optimization, where such small dif-
ferences are not signiﬁcant. The only counters that may
be used for Genuinity are those that are coarser and per-
fectly repeatable: precisely the ones on which the ef-
fects of attack code may be easily computed in order to
compensate for any difference. Finally, differences in
counter architecture between processor families can se-
riously hamper the effectiveness of the test. Much of the
strength of Genuinity in the original paper came from its
invariants of cache and TLB information, much of which
are no longer available for use.
6.2 Lack of asymmetry
Asymmetry is often a desirable trait in cryptographic
primitives and other security mechanisms. We want de-
cryption to be inexpensive, even if it costs more to en-
crypt. We want proof veriﬁcation for proof-carrying
code [Nec97] to be lightweight, even if generating
proofs is difﬁcult. Client puzzles [DS01] are used by
servers to prevent denial of service attacks by leveraging
asymmetry: clients must carry out a difﬁcult computa-
tion that is easy for the server to check.
Genuinity, by design, is not asymmetric: it costs the
authority as much, and likely more (because simulation
is necessary), to compute the correct checksum for a test
as it does for the client to compute it. This carries with
it two problems. First, it exposes the authority to de-
nial of service attacks, since the authority may be forced
to perform a large amount of computation in response,
ironically, to a short and easily-computed series of mes-
sages from a client. Second, it makes it no more expen-
sive for a well-organized impostor to calculate correct
checksums en masse than for legitimate clients or the
authority itself. We shall explore this latter possibility
further in Section 7.2.
6.3 Unsuitability for access control
The authors of the original paper propose to use Genuin-
ity to implement certain types of access control. A com-
mon form of access control ensures that a certain user
has certain access rights to a set of resources. Genuinity