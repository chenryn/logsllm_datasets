# Learning Unknown Attacks: A Start

## Authors
- James E. Just<sup>1</sup>
- James C. Reynolds<sup>1</sup>
- Larry A. Clough<sup>1</sup>
- Melissa Danforth<sup>2</sup>
- Karl N. Levitt<sup>2</sup>
- Ryan Maglich<sup>1</sup>
- Jeff Rowe<sup>2</sup>

### Affiliations
1. Teknowledge Corporation, 3900 Jermantown Road, Suite 100, Fairfax, VA 22030, USA
   - Email: {jjust, reynolds, lclough, rmaglich}@teknowledge.com
2. University of California, 3061 Engineering II, One Shields Avenue, Davis, CA 95616, USA
   - Email: {danforth, levitt, rowe}@cs.ucdavis.edu

## Abstract
Given the inherent difficulty in writing large-scale software without errors, any intrusion-tolerant system must be capable of withstanding rapid, repeated unknown attacks without exhausting its redundancy. Our system aims to provide continuous application services to critical users during an attack, with a goal of less than 25% degradation in productivity. Initial experimental results are promising, though it is not yet a general open solution.

Specification-based behavior sensors (allowable actions, objects, and QoS) detect attacks. The system learns unknown attacks by leveraging two characteristics of network-accessible software faults: attacks that exploit them must be repeatable (at least in a probabilistic sense), and, if known, attacks can be stopped at component boundaries. Random rejuvenation limits the scope of undetected errors. The current system learns and blocks single-stage unknown attacks against a protected web server by analyzing and testing service history logs in a sandbox after a successful attack. We also have an initial class-based attack generalization technique that stops web-server buffer overflow attacks. We are working to extend both techniques.

## 1. Introduction
Designing secure systems to withstand cyber-attacks is both challenging and complex. Initially, designers focused on building stronger security mechanisms to keep out attackers. However, protection was not perfect, and some attacks still penetrated. Subsequently, intrusion detection systems were added to alert us to the presence of attackers. Unfortunately, these detectors were not infallible, and some attacks still went undetected. More recently, the focus has shifted to building systems that continue to operate despite attacks, leveraging well-developed techniques in dependability and fault tolerance.

It is impossible to build an intrusion-tolerant system that survives for any meaningful period without addressing the problems of unknown attacks and finite failover resources. Hardening a system to increase the adversary's work factor is useful but has its limits. The time and effort required to identify a new vulnerability and develop an exploit may be substantial, but for a determined opponent, it is just a matter of time and money.

The real issue is that once an attack is developed and deployed, the time required to execute it is very small, and creating simple variants of the attack often requires minimal effort. If the threat environment includes a well-resourced adversary (e.g., state-sponsored cyber-terrorists or organized crime), the system must be capable of handling many unknown attacks, possibly repeated quickly (in seconds or minutes). This scenario will rapidly exhaust any redundant components and represents, in our opinion, the worst-case design point.

Many fault-tolerant mechanisms work because most faults are independent, low-probability events that can be easily masked. Common mode failure is a well-understood problem and is often avoided through diversity. However, attacks do not allow the assumption of independence, and the nature of the critical service may preclude the use of diversity.

This project is the first attempt to build a prototype system that combines intrusion detection, responses to block attacks, failover to remove compromised elements, learning to create rules for blocking future occurrences of attacks, and generalization to block even significant variants.

### 1.1 Background
Commercial organizations, governments, and even the military have reduced costs and arguably improved reliability through increased use of commercial off-the-shelf (COTS) software and hardware, even for critical applications. Unfortunately, this has also increased their vulnerability to well-resourced adversaries who aim to cause serious damage to critical infrastructure, steal information, and disrupt services. Most researchers agree that it is essentially impossible to build large-scale software without faults, and it is certainly impossible to prove such software contains no faults [1], [2], [3]. Moreover, as demonstrated by recent attacks (Code Red 1 and Code Red 2, which exploited a known buffer overflow vulnerability in Microsoft’s Internet Information Server), faults are being exploited long after patches are available. While software security can be improved, it is important to explore other approaches to security.

In 2000, the US Defense Advanced Research Project Agency (DARPA) initiated a program to apply fault tolerance techniques to building intrusion-tolerant systems. As part of this effort, several organizations, including Teknowledge Corporation and the University of California (Davis), are developing intrusion-tolerant clusters.

The specific goal of our project (Hierarchical Adaptive Control of QoS for Intrusion Tolerance or HACQIT) is to provide continuous COTS or GOTS-based application services in the face of multiple hours of aggressive cyber-attacks by a well-resourced adversary. Since we do not have access to source code, protections must be added around or to the binaries. We recognize that our defense cannot be perfect, so two implied goals are (1) significantly increasing the adversary's work factor for successful attacks and (2) significantly increasing the ratio of the attacker’s work factor to generate successful attacks to the defender’s work factor for responding to successful attacks. Given the high processing and overhead costs, we have modularized the components to vary the amount of protection according to need and budget.

### 1.2 Organization
The HACQIT project, its architecture, and basic intrusion-tolerant design approach have been described in other articles [4, 5, 6]. The next section will provide enough information on HACQIT to enable the reader to understand the context, uses, and limitations of the learning and generalization as they exist today. The remaining sections will summarize the problem, the learning and generalization approach, its current implementation, test results, and conclusions/next steps.

## 2. The HACQIT Context

### 2.1 The General Problem and System Model
Formal environment and attack assumptions have been made to specify the research problem as developing dependability in the face of network-based cyber-attacks rather than dealing with denial-of-service attacks, insiders, Trojans, and other lifecycle attacks. These assumptions include:
- Users and attackers interact with services via their computers and the LAN. There are no other hidden interactions.
- The LAN is reliable and cannot be flooded, i.e., DoS attacks against LAN bandwidth are beyond the scope of the research. The LAN is the only communication medium between users and services. DoS attacks directly against critical users or firewalls are also beyond the scope.
- Critical users and the system administrators for the cluster are trusted. No hosts on the external LAN are trusted.
- The protected cluster hardware and software are free of Trojans and trapdoors at startup and have been patched against known vulnerabilities. Attackers do not have and have not had physical access to the cluster hardware or software, preventing the planting of Trojan software/hardware and trapdoors through lifecycle attacks.
- Other unknown vulnerabilities exist throughout the system.

Figure 1 describes the "formal" system model of the problem and design environment being addressed by intrusion-tolerant systems. The goal is to protect critical applications so that critical users can continue to access them while under attack.

### 2.2 HACQIT System Model
HACQIT is not designed to be a general-purpose server connected to the Internet. Anonymous users are not allowed. All connections to the system are through authenticated Virtual Private Networks (VPNs). We assume that the configuration of the system has been done correctly, including patching all known vulnerabilities.

An attacker can be any agent other than the trusted users or HACQIT system administrators. Attackers do not have physical access to the HACQIT cluster. An attacker may take over a trusted user’s machine and launch attacks against HACQIT.

A failure occurs when observed behavior deviates from specified behavior. For HACQIT, we are concerned with software failures, which can be either repeatable or non-repeatable. Repeatable failures are caused by attacks (maliciously devised inputs) that exploit a vulnerability in one of our software components. Non-repeatable failures may be caused by intermittent or transient faults. We treat all inputs that cause repeated failures the same, recognizing that the system may fail intermittently from certain inputs, in which case we allow retry.

To develop a system that meets these requirements, most designers would make the cluster very intrusion-resistant, implement specification-based monitoring of server and application behavior, and use fault-tolerant mechanisms (e.g., redundancy and failover, process pairs, triple modular redundancy, n-version programming) for rapid failover and recovery. Our design employs these approaches and a few additional ones.

Our design is summarized in Figure 2. The HACQIT cluster consists of at least four computers: a gateway computer running a commercial firewall and additional infrastructure for failover and attack blocking; two or more servers of critical applications (one primary, one backup, and one or more online spares); and an Out-Of-Band (OOB) machine running the overall monitoring and control and fault diagnosis software. The machines in the cluster are connected by two separate LANs.

HACQIT uses primary and backup servers running as a process pair, but they are unlike ordinary primary and backup servers for fault tolerance. Only the primary is connected to users. The virtual private network (VPN), firewall, gateway, and IP switch together ensure that users only talk to the critical application through the specified port on the primary server and vice versa. The primary and backup servers are not on the same LAN; they are isolated by the OOB computer, so no propagation of faults, for example, by an automated worm or remote attacker, directly from the primary to the backup, is possible.

The potential for propagation from the primary to the Controller is limited by sharply constraining and monitoring the services and protocols by which the Controller communicates with the primary. When a failure is detected on the primary or backup server (possibly caused by an attack), it is taken offline. Continued service to the end user is provided by the remaining server of the process pair. A new process pair is formed with the online spare (if available), and both attack diagnosis and recovery of the failed server begin. Depending on policy, the Controller can also block future requests from the machine suspected of launching the attack.

The current critical application is a web-enabled message board duplicated on both the Microsoft IIS web server and the Apache web server machines. It contains dynamic data, so HACQIT must maintain consistent state across the hosts and resynchronize data (checkpoint and restore) when failover and new process pair formation occur. The spare server does not have the current state when it is promoted into the process pair, so a restore process is necessary to synchronize it.

### 2.3 HACQIT Software Architecture
The simplified software architecture is shown in Figure 3. The software implements a specification-based approach [7, 8] to monitoring and control for intrusion detection and defense in depth. It uses software wrappers [9], application and host monitors, response monitors, etc., to ensure that component behavior does not deviate from allowed. It does this in a protect-detect-respond cycle. Strong protections (and isolation) are combined with host and application-based fault, error, and failure detection mechanisms in a defense-in-depth design. Deviation from specified behavior may indicate an attack, triggering failover, integrity testing, and other responses.