### Optimized Text

#### Impact of ECN on Flow Completion Time (FCT)
For a smaller threshold (20KB), Karuna achieves a 57% to 85% lower FCT compared to Karuna without ECN, both at the average and 99th percentile. The use of ECN effectively controls queue build-up, thereby mitigating the impact of threshold-traffic mismatch.

#### Effect of Number of Queues
In Figure 10, we examine the effect of the number of queues on the FCT of type 2 and type 3 flows. For this experiment, we use traffic generated from a Web Search workload and consider 2, 4, and 7 priority queues (the first queue is reserved for type 1 flows). Our observations are as follows:
1. **General Improvement with More Queues**: Increasing the number of queues generally leads to better average FCT. This is expected because more queues allow Karuna to better segregate type 2 and type 3 flows, improving overall performance.
2. **Short Flows Performance**: The average FCT for short flows is comparable across all three cases. This suggests that even with only two queues, short flows benefit significantly from Karuna.

**Figure 12: Workloads in Simulation**

#### Large-Scale Simulations
Our simulations evaluate Karuna using realistic data center network (DCN) workloads on a common DCN topology. We test Karuna's performance under various conditions, including deadline completion, starvation, traffic variation, and bottlenecked scenarios.

**Topology**:
- **Simulation Setup**: We conduct large-scale packet-level simulations using the ns-3 [33] simulator and generate different scenarios with fnss [35].
- **Network Topology**: We use a 144-server spine-and-leaf fabric (Figure 11), a common topology for production DCNs [4], with 4 core switches, 9 top-of-rack (ToR) switches, and 16 servers per ToR. The links between servers and ToRs are 10G, and the ToR uplinks are 40G.
- **Multi-Hop and Multiple Bottlenecks**: This setting complements our testbed evaluations by providing a multi-hop, multiple bottleneck environment.

**Traffic Workloads**:
- **Realistic Workloads**: We use two widely-adopted [3, 6, 20, 30] realistic DCN traffic workloads: a web search workload [3] and a data mining workload [20]. In these workloads, more than half of the flows are less than 100KB in size, reflecting typical DCN traffic.
- **Long Flow Workload**: To cover cases where traffic may be biased towards larger sizes, we also create a "Long Flow" workload. In this workload, flow sizes are uniformly distributed from 1KB to 10MB, meaning half of the flows are larger than 5MB.
- **Flow Distribution**: The cumulative distribution functions (CDFs) of flow sizes from the three workloads are shown in Figure 12. Unless specified, each flow type (§2.1) accounts for one-third of the overall traffic. Flow arrival follows a Poisson process, and the source and destination for each flow are chosen uniformly at random. We vary the flow arrival rate (λarr) to achieve the desired load (ρ = λarr · E(F ), where E(F ) is the average flow size for flow size distribution F).

**Comparison with Other Schemes**:
- **Schemes Compared**: We compare Karuna with DCTCP, D2TCP, D3, and pFabric.
- **DCTCP Parameters**: For DCTCP, we follow the parameter settings in [3], setting the switch ECN marking threshold to 65 packets for 10Gbps links and 250 packets for 40Gbps links.
- **D2TCP and D3 Implementation**: We implemented D2TCP and D3 in ns-3, including the packet format and switch operations as described in [39]. For D2TCP, 0.5 ≤ d ≤ 2, and the base rate for D3 is one segment per RTT.
- **pFabric Settings**: For pFabric, we use the default parameter settings in [30] and run it with EDF scheduling as in §2.2. Each simulation runs for 60 seconds (virtual time).

**Key Strength of Karuna**:
Karuna reduces FCT for non-deadline flows without significantly sacrificing performance for deadline flows. To demonstrate this, we compare Karuna with deadline-aware schemes such as D3, D2TCP, and pFabric (EDF). In this simulation, we use flow sizes from the data mining workload, and source-destination pairs are randomly chosen. We control the load of type 1 flows (total expected rate Γ) by assigning deadlines as follows: we record the total expected rates of all active type 1 flows ˜Γ, and for each new flow, if ˜Γ < 500KB, we assign a deadline.

**Figures and Results**:
- **Figure 13: Karuna vs. Other Schemes**
- **Figure 14: Aging Against Starvation in Karuna**
- **Figure 16: AFCT Performance for Type 2 Flows (The same trend applies to type 3 flows)**
- **Figure 17: Karuna in Bottlenecked Environments**

**Performance in Bottlenecked Environments**:
All previous simulations assume a full bisection bandwidth network, which fits the one-switch assumption in estimating the network term in Eq.(11). To evaluate network term estimation, we intentionally create high loads for cross-rack deadline flows on 1 (destination ToR), 2 (source & destination ToRs), and 3 (source & destination ToRs, and core) intermediate links. We obtain ground-truth queue length and the estimated queue length in MCP in the simulator.

In Figure 17, for different loads on the bottleneck links, we show the average queue estimation error (100% × | ˆQ - Q / Q |) and average deadline miss rates. We observe that the queue estimation error increases as the setting deviates from our assumptions in (§4.2.1)—both load and the number of bottlenecks negatively affect the estimation accuracy. However, Karuna still manages to achieve a <7.9% miss rate for 2 bottlenecks at 99% load. This is because inaccurate estimation leads to the accumulation of residual rates, and when the deadline is near, the source term (Eq.(11)) drives up the sending rate for the flow to finish.

### Related Works
There is extensive literature on transport design. Here, we review works closely related to Karuna:

- **DCTCP [3]**: A transport protocol designed for DCNs. We employ DCTCP for handling type 2 and type 3 flows due to its effective congestion control with ECN. Unlike Karuna, DCTCP is not deadline-aware and cannot simulate SJF because DCTCP flows share bandwidth.
- **D2TCP [38]**: Adds deadline-awareness to DCTCP but does not address type 2 and type 3 flows.
- **D3 [39]**: Manages deadline flows using a greedy approach, leading to priority inversion and requiring significant modifications to switches. FCP [21] implements D3 with a pricing mechanism. In contrast, Karuna ensures the completion of most deadline flows while optimizing FCT for other types of flows.
- **PDQ [22] and pFabric [4]**: Both are criticality-based flow scheduling schemes that may harm other types of flows. Karuna maintains a high deadline meet rate for type 1 flows and leaves as much bandwidth as possible for other flows, achieving lower FCT for type 2 and type 3 flows.
- **PASE [30]**: Combines previous transport layer strategies to reduce average FCT but does not directly address the mixed-flow scheduling problem. PASE requires coordinated rate arbitration in the network control plane, whereas Karuna only needs ECN support.
- **PIAS [5]**: An information-agnostic flow scheduling scheme that simulates SJF without knowing flow sizes. PIAS is effective for type 3 flows but does not account for the other types. Every flow in PIAS is treated as a type 3 flow, which can hurt the performance of the other types. Karuna's sieving operation is inspired by PIAS but adds support for type 1 and type 2 flows.

**Note**: MCP-like behaviors (just-in-time strategy and smoothing out link usage) have been explored in other areas, such as traffic engineering [26] and job latency guarantees [18].

**Flexibility for Application Developers**:
Karuna is flexible in terms of the information needed for scheduling. Most protocols require developers to provide full information about deadlines and sizes [4, 21, 22, 30, 38, 39], while some cannot benefit from flow information [3, 6], even if provided. In contrast, Karuna can leverage any available information to achieve performance benefits for all types of traffic.

### Concluding Remarks
In this paper, we focused on scheduling a mix of flows in DCNs, an important and practical problem often neglected in prior work. Karuna resolves the tension between different types of flows through a joint design of rate control (MCP) and priority-based flow scheduling with limited priorities in commodity switches.

Karuna is not designed to be an optimal flow scheduling algorithm but rather a mixed-flow scheduling system that balances the interests of deadline and non-deadline flows. At a high level, Karuna trades off the average performance of one type of traffic (type 1 flows) to improve the average and tail performance of other traffic (type 2 and type 3 flows).

**Future Work**:
We intend to explore different formulations of the mixed-flow problem with the goal of improving average FCT for all types of flows, subject to deadline constraints.