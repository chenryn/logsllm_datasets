or a smaller threshold (20KB), Karuna achieves 57%∼85%
lower FCT compared to Karuna w/o ECN at both average
and 99th percentile. With ECN, we can effectively control
the queue build-up, thus mitigating the effect of threshold-
trafﬁc mismatch.
Effect of number of queues: In Figure 10, we inspect the
impact of queue number on FCT of type 2&3 ﬂows. For
this experiment, we use trafﬁc generated from Web Search
workload and consider 2, 4 and 7 priority queues (the ﬁrst
queue is reserved for type 1 ﬂows). We observe that: 1)
more queues leads to better average FCT in general. This is
expected because, with more queues, Karuna can better seg-
regate type 2&3 ﬂows into different queues, thus improving
overall performance; 2) the average FCT of short ﬂows are
Figure 12: Workloads in simulation.
comparable in all three cases. This indicates that with only
2 queues, the short ﬂows beneﬁt most from Karuna.
8.2 Large-scale simulations
Our simulations evaluate Karuna using realistic DCN work-
loads on a common DCN topology. We test the limits of
Karuna in deadline completion, starvation, trafﬁc variation,
and bottlenecked scenarios.
Topology: We perform large scale packet-level simulations
with ns-3 [33] simulator, and use fnss [35] to generate dif-
ferent scenarios. We use a 144-server spine-and-leaf fabric
(Figure 11), a common topology for production DCNs [4]
with 4 core switches, 9 ToRs, and 16 servers per ToR. It is a
multi-hop, multiple bottleneck setting, which complements
our testbed evaluations. We use 10G link for server to ToR
links, and 40G for ToR uplinks.
Trafﬁc workloads: We use two widely-used [3, 6, 20, 30]
realistic DCN trafﬁc workloads: a web search workload [3]
and a data mining workload [20]. In these workloads, more
than half of the ﬂows are less than 100KB in size, which
reﬂects the nature of DCN trafﬁc in practice. However, in
some parts of the network, the trafﬁc may be biased towards
large sizes. For a more comprehensive study, we also create
the “Long Flow” workload to cover this case. In this work-
load, the size is uniformly distributed from 1KB to 10MB,
which means that half of the ﬂows are larger than 5MB. The
CDFs of ﬂow sizes from the 3 workloads are shown in Fig-
ure 12. Unless speciﬁed, each ﬂow type (§2.1) amounts to
1/3 of overall trafﬁc. As in [4, 6, 30], ﬂow arrival follows a
Poisson process and the source and destination for each ﬂow
is chosen uniformly at random. We vary ﬂow arrival rate
(λarr) to obtain a desired load (ρ=λarr·E(F ), where E(F )
is the average ﬂow size for ﬂow size distribution F ).
We compare Karuna with DCTCP, D2TCP, D3, and pFab-
ric. To compare with DCTCP, we follow the parameter set-
ting in [3], and set the switch ECN marking threshold as
65 packets for 10Gbps links and 250 packets for 40Gbps
links. We implemented D2TCP and D3 in ns-3, including
the packet format and switch operations in [39]. Follow-
ing [38], 0.5≤d≤2 for D2TCP, and the base rate for D3 is
KarunaKaruna w/o ECNus010000average FCT - 20KB99th FCT - 20KBaverage FCT - 30KB99th FCT - 30KBaverage FCT - 2MB99th FCT - 2MB2 queues4 queues7 queues(0,100KB) AFCT(100KB,10MB] AFCTms406080ms0.80.9Load0.50.60.70.8Web SearchData MiningLong Flow00.51.01KB101KB102KB103KB104KB105KBFigure 13: Karuna vs other schemes.
Figure 14: Aging against starvation in Karuna.
one segment per RTT. For pFabric, we follow the default
parameter setting in [30], and it runs EDF scheduling as in
§2.2. Each simulation runs for 60s (virtual time).
8.2.1 Key strength of Karuna
Karuna reduces FCT for non-deadline ﬂows without sac-
riﬁcing much for deadline ﬂows. To show this, we compare
Karuna with deadline-aware schemes, D3, D2TCP, pFabric
(EDF). In this simulation, we choose ﬂow sizes from data
mining workload, and source-destination pairs are randomly
chosen. We control the load of type 1 ﬂows (total expected
rate Γ) by assigning deadlines as follows: we record the to-
tal expected rates of all active type 1 ﬂows ˜Γ, and for each
new ﬂow, if ˜Γ 500KBDCTCPKaruna%01020Scenario#123456789101112Deadline Miss Rate (Type 1)Figure 16: AFCT performance for type 2 ﬂows (The same trend
applies to type 3 ﬂows).
Figure 17: Karuna in bottlenecked environment.
have worse FCT, but not signiﬁcant. For DM, the matched
case is scenario #8, which also has the lowest FCT, whereas
the FCTs for other scenarios are relatively worse. For LF,
the thresholds are mismatched in all the scenarios, and the
FCTs are longer compared to the ﬁrst two groups.
In all
cases, Karuna achieves better FCT than DCTCP. The similar
trend applies to type 3 ﬂows as well (omitted for space).
In summary, for type 2&3 ﬂows, Karuna performs the best
when the thresholds match the trafﬁc, which demonstrates
the utility of the optimizations in Appendix A. When the
thresholds do not match the trafﬁc, the FCT degrades only
slightly (but still much better than DCTCP), which shows
that Karuna is resilient to trafﬁc variation, partially because
it has employed the ECN-based rate control to mitigate the
mismatch (as validated in §8.1.3).
8.2.4 Karuna in bottlenecked environments
All the above simulations assume a full bisection band-
width network, which ﬁts the one switch assumption in esti-
mating network term in Eq.(11). To evaluate network term
estimation, we intentionally create high loads for cross-rack
deadline ﬂows on 1 (destination ToR), 2 (source & desti-
nation ToRs), and 3 (source & destination ToRs, and core)
intermediate links. We obtain ground-truth queue length and
the estimated queue length in MCP in the simulator.
In Figure 17, for different loads on the bottleneck links,
we show the average queue estimation error (100%×| ˆQ−Q
Q |)
and average deadline miss rates. We observe that the queue
estimation error increases when the setting deviates more
from our assumptions in (§4.2.1)—both load and number of
bottlenecks negatively affect the estimation accuracy. How-
ever, Karuna still manages to achieve <7.9% miss rate for
2 bottlenecks at 99% load. This is because inaccurate esti-
mation leads to accumulation of residual rates, and when the
deadline is near, the source term (Eq.(11)) drives up sending
rate for the ﬂow to ﬁnish.
9. RELATED WORKS
There has been vast literature space on transport design.
Here we review works that are closely related to Karuna.
DCTCP [3] is a transport protocol designed for DCN. We
employ DCTCP in handling type 2&3 ﬂows since its con-
gestion control scheme works well with ECN. Compared to
Karuna, DCTCP is deadline-unaware and unable to simulate
SJF because DCTCP ﬂows share bandwidth.
For type 1 ﬂows, D2TCP [38] adds deadline-awareness
to DCTCP, but it does not address type 2&3 ﬂows. D3 [39]
deals with the deadline ﬂows using a greedy approach, which
leads to priority-inversion problem (§4) and requires heavy
modiﬁcations to switches. A ﬂexible transport framework,
FCP [21], also implements D3 with a pricing mechanism.
In contrast, Karuna ensures the completion of most deadline
ﬂows, and also optimizes FCT for other types of ﬂows.
PDQ [22] and pFabric [4] are both criticality-based ﬂow
scheduling schemes, and they may hurt other types of ﬂows
(see §2.2). In contrast, Karuna not only maintains high dead-
line meet rate of type 1 ﬂows, it also leaves as much band-
width as possible for other ﬂows, achieving lower FCT for
type 2&3 ﬂows.
PASE [30] combines previous transport layer strategies to
reduce average FCT, but does not directly address the mix-
ﬂow scheduling problem. Also, PASE requires coordinated
rate arbitration in the network control plane, whereas Karuna
requires only ECN support in the network.
PIAS [5] is an information agnostic ﬂow scheduling scheme
that simulates SJF without knowing the ﬂow sizes. PIAS is
effective for type 3 ﬂows, but does not account for the other
types. Every ﬂow in PIAS is treated as a type 3 ﬂow, which
hurts the performance of the other 2 types. The sieving oper-
ation in Karuna is inspired by PIAS, but Karuna adds support
for type 1&2 ﬂows.
It is worthwhile to note that MCP-like behaviors (just-in-
time strategy and smoothening out link usage) has been ex-
plored in areas other than ﬂow scheduling: e.g. trafﬁc engi-
neering [26] and guaranteeing job latencies [18].
For application developers, Karuna is ﬂexible in terms of
information needed for scheduling. Most of the above pro-
tocols require developers to provide full information about
deadlines and sizes [4, 21, 22, 30, 38, 39]; on the other hand,
some cannot beneﬁt from ﬂow information [3, 6], even if
developers can provide them. In contrast, Karuna can take
advantage of any available information given by developers
to achieve performance beneﬁts for all types of trafﬁc.
10. CONCLUDING REMARKS
In this paper, we focused on how to schedule a mix of
ﬂows in DCNs. This is an important and practical problem,
but has been neglected by prior work in this ﬁeld. Karuna
resolves the tension between different types of ﬂows with a
joint design of rate-control (MCP) and priority-based ﬂow
scheduling with limited priorities in commodity switches.
Karuna is not designed to be an optimal ﬂow scheduling
algorithm, but a mix-ﬂow scheduling system that balances
the interests of deadline and non-deadline ﬂows. At a high
KarunaDCTCPms0510123456789101112Type 2 AFCT (Web Search)Load=0.9Load=0.990%10%20%30%# Bottlenecks123Q Estimation Error0%5%10%15%# Bottlenecks123Deadline Miss Ratelevel, Karuna trades off the average performance of one type
of trafﬁc (type 1 ﬂows)to improve the average and tail per-
formance of other trafﬁc (type 2&3 ﬂows).
Future work: We intend to explore different formulations
of the mix-ﬂow problem with the goal of improving average
FCT for all types of ﬂows, subject to deadline constraints for