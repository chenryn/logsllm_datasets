Cache Used: 0 (0 B)
Cache Remaining: 0 (0 B)
Cache Used%: 100.00%
Cache Remaining%: 0.00%
Xceivers: 1
Last contact: Sat Sep 03 08:30:54 CST 2016
view http://xxx.xxx.xxx.xxx:50070/  
```
test hdfs  
```
$ hdfs dfs -mkdir -p /user
$ hdfs dfs -put /home/gpadmin/hadoop-2.7.3.tar.gz /user/
$ hdfs dfs -ls -R /
-rw-r--r--   1 gpadmin supergroup  214092195 2016-09-02 22:09 /user/hadoop-2.7.3.tar.gz
```
允许gpadmin访问hdfs  
```
$ /home/gpadmin/app/hadoop-2.7.3/bin/hdfs dfs -chown gpadmin hdfs://localhost:8020/
```
## yarn
如果需要使用yarn来做资源管理的话，需要安装YARN  
YARN is only needed when you want to use YARN as the global resource manager  
```
$ cd ~/app/hadoop-2.7.3
$ cp etc/hadoop/mapred-site.xml.template etc/hadoop/mapred-site.xml
$ vi etc/hadoop/mapred-site.xml
        mapreduce.framework.name
        yarn
$ vi etc/hadoop/yarn-site.xml
        yarn.nodemanager.aux-services
        mapreduce_shuffle
$ start-yarn.sh
```
view http://xxx.xxx.xxx.xxx:8088/  
## install hawq
```
cd ~
git clone https://git-wip-us.apache.org/repos/asf/incubator-hawq.git
CODE_BASE=`pwd`/incubator-hawq
cd ~
wget ftp://ftp.gnu.org/gnu/gsasl/libgsasl-1.8.0.tar.gz
tar -zxvf libgsasl-1.8.0.tar.gz
cd libgsasl-1.8.0
./configure --prefix=/home/gpadmin/app/sasl
make -j 32 
make install
cd ~
git clone https://github.com/google/googletest
cd googletest
mkdir build
cd build
cmake -DCMAKE_INSTALL_PREFIX:PATH=/home/gpadmin/app/google ..
make -j 32
make install
cd ~
cd $CODE_BASE/depends/libhdfs3
/*
  git clone https://github.com/Pivotal-Data-Attic/pivotalrd-libhdfs3
*/
mkdir build
cd build
../bootstrap --prefix=/home/gpadmin/app/libhdfs3 --dependency=/home/gpadmin/app/sasl:/home/gpadmin/app/google
make -j 32
make install
```
## YARN
```
libyarn
cd ~
cd $CODE_BASE/depends/libyarn
mkdir build
cd build
../bootstrap --prefix=/home/gpadmin/app/libyarn --dependency=/home/gpadmin/app/sasl:/home/gpadmin/app/google
make -j 32
make install
```
编译hawq  
```
cd ~
cd $CODE_BASE
CPPFLAGS="-I/home/gpadmin/app/libyarn/include -I/home/gpadmin/app/hadoop-2.7.3/include -I/home/gpadmin/app/libhdfs3/include" LDFLAGS="-L/home/gpadmin/app/libyarn/lib -L/home/gpadmin/app/hadoop-2.7.3/lib -L/home/gpadmin/app/libhdfs3/lib" ./configure --prefix=/home/gpadmin/app/hawq --with-python --with-r --with-pgcrypto --with-openssl --enable-debug --enable-orca --without-libyarn --without-libhdfs3 --without-thrift
# Run command to build and install
# To build concurrently , run make with -j option. For example, make -j8
# On Linux system without large memory, you will probably encounter errors like
# "Error occurred during initialization of VM" and/or "Could not reserve enough space for object heap"
# and/or "out of memory", try to set vm.overcommit_memory = 1 temporarily, and/or avoid "-j" build,
# and/or add more memory and then rebuild.
# On mac os, you will probably see this error: "'openssl/ssl.h' file not found".
# "brew link openssl --force" should be able to solve the issue.
make -j 32
# Install HAWQ
make install
```
配置环境变量  
```
cd ~
vi .bash_profile
. /home/gpadmin/app/hawq/greenplum_path.sh
export PATH=/home/gpadmin/app/hadoop-2.7.3/bin:/home/gpadmin/app/hadoop-2.7.3/sbin:/home/gpadmin/app/cmake/bin:$PATH
export JAVA_HOME=/home/gpadmin/app/jdk1.8.0_102
export HADOOP_HOME=/home/gpadmin/app/hadoop-2.7.3
export LD_LIBRARY_PATH=/home/gpadmin/app/libyarn/lib:/home/gpadmin/app/libhdfs3/lib:/home/gpadmin/app/google/lib:/home/gpadmin/app/sasl/lib:$LD_LIBRARY_PATH
export PGHOST=127.0.0.1
export PGPORT=1921
export PGDATABASE=postgres
export PGUSER=gpadmin
export PGPASSWORD=gpadmin
export PGDATA=/data01/gpadmin/pgdata_master
. ./.bash_profile
```
配置greenplum_path.sh(否则可能通过remote_ssh调用pg_ctl时报fgets failed的错误)  
```
vi /home/gpadmin/app/hawq/greenplum_path.sh
append below  
export PATH=/home/gpadmin/app/hadoop-2.7.3/bin:/home/gpadmin/app/hadoop-2.7.3/sbin:/home/gpadmin/app/cmake/bin:$PATH
export JAVA_HOME=/home/gpadmin/app/jdk1.8.0_102
export HADOOP_HOME=/home/gpadmin/app/hadoop-2.7.3
export LD_LIBRARY_PATH=/home/gpadmin/app/libyarn/lib:/home/gpadmin/app/libhdfs3/lib:/home/gpadmin/app/google/lib:/home/gpadmin/app/sasl/lib:$LD_LIBRARY_PATH
export PGHOST=127.0.0.1
export PGPORT=1921
export PGDATABASE=postgres
export PGUSER=gpadmin
export PGPASSWORD=gpadmin
export PGDATA=/data01/gpadmin/pgdata_master
```
配置初始化数据库集群目录  
```
$ mkdir -p /data01/gpadmin/pgdata_master
$ mkdir -p /data01/gpadmin/pgdata_segment
$ mkdir -p /data01/gpadmin/pgdata_master_tmp
$ mkdir -p /data01/gpadmin/pgdata_segment_tmp
```
配置hawq配置文件(hawq-site.xml的优先级配置比postgresql.conf更高)  
```
cd ~/app/hawq
vi etc/hawq-site.xml
                hawq_master_address_host
                0.0.0.0
                The host name of hawq master.
                hawq_master_address_port
                1921
                The port of hawq master.
                hawq_standby_address_host
                none
                The host name of hawq standby master.
                hawq_segment_address_port
                40000
                The port of hawq segment.
                hawq_dfs_url
                localhost:8020/hawq_default
                URL for accessing HDFS.
                hawq_master_directory
                /data01/gpadmin/pgdata_master
                The directory of hawq master.
                hawq_segment_directory
                /data01/gpadmin/pgdata_segment
                The directory of hawq segment.
                hawq_master_temp_directory
                /data01/gpadmin/pgdata_master_tmp
                The temporary directory reserved for hawq master.
                hawq_segment_temp_directory
                /data01/gpadmin/pgdata_segment_tmp
                The temporary directory reserved for hawq segment.
                hawq_global_rm_type
                none
                The resource manager type to start for allocating resource.
                                         'none' means hawq resource manager exclusively uses whole
                                         cluster; 'yarn' means hawq resource manager contacts YARN
                                         resource manager to negotiate resource.
                hawq_rm_memory_limit_perseg
                64GB
                The limit of memory usage in a hawq segment when
                                         hawq_global_rm_type is set 'none'.
                hawq_rm_nvcore_limit_perseg
                16
                The limit of virtual core usage in a hawq segment when
                                         hawq_global_rm_type is set 'none'.
                hawq_rm_yarn_address
                localhost:8032
                The address of YARN resource manager server.
                hawq_rm_yarn_scheduler_address
                localhost:8030
                The address of YARN scheduler server.
                hawq_rm_yarn_queue_name
                default
                The YARN queue name to register hawq resource manager.
                hawq_rm_yarn_app_name
                hawq
                The application name to register hawq resource manager in YARN.
                hawq_re_cpu_enable
                false
                The control to enable/disable CPU resource enforcement.
                hawq_re_cgroup_mount_point
                /sys/fs/cgroup
                The mount point of CGroup file system for resource enforcement.
                                         For example, /sys/fs/cgroup/cpu/hawq for CPU sub-system.
                hawq_re_cgroup_hierarchy_name
                hawq
                The name of the hierarchy to accomodate CGroup directories/files for resource enforcement.
                                         For example, /sys/fs/cgroup/cpu/hawq for CPU sub-system.
                default_hash_table_bucket_number
                1
```
初始化集群  
```
[gpadmin@digoal ~]$ hawq init cluster --locale=C --shared_buffers=256MB
20160903:21:02:02:029744 hawq_init:digoal:gpadmin-[INFO]:-Prepare to do 'hawq init'
20160903:21:02:02:029744 hawq_init:digoal:gpadmin-[INFO]:-You can find log in:
20160903:21:02:02:029744 hawq_init:digoal:gpadmin-[INFO]:-/home/gpadmin/hawqAdminLogs/hawq_init_20160903.log
20160903:21:02:02:029744 hawq_init:digoal:gpadmin-[INFO]:-GPHOME is set to:
20160903:21:02:02:029744 hawq_init:digoal:gpadmin-[INFO]:-/home/gpadmin/app/hawq
20160903:21:02:02:029744 hawq_init:digoal:gpadmin-[INFO]:-Init hawq with args: ['init', 'cluster']
Continue with HAWQ init Yy|Nn (default=N):
> y
20160903:21:02:03:029744 hawq_init:digoal:gpadmin-[INFO]:-No standby host configured, skip it
20160903:21:02:03:029744 hawq_init:digoal:gpadmin-[INFO]:-Check if hdfs path is available
20160903:21:02:03:029744 hawq_init:digoal:gpadmin-[WARNING]:-WARNING:'hdfs://localhost:8020/hawq_default' does not exist, create it ...
2016-09-03 21:02:03.692149, p29851, th140383720921408, WARNING the number of nodes in pipeline is 1 [localhost(127.0.0.1)], is less than the expected number of replica 3 for block [block pool ID: BP-1170303990-127.0.0.1-1472824907274 block ID 1073741844_1024] file /hawq_default/testFile
20160903:21:02:03:029744 hawq_init:digoal:gpadmin-[INFO]:-1 segment hosts defined
20160903:21:02:03:029744 hawq_init:digoal:gpadmin-[INFO]:-Set default_hash_table_bucket_number as: 1
20160903:21:02:04:029744 hawq_init:digoal:gpadmin-[INFO]:-Start to init master node: '0.0.0.0'
20160903:21:02:22:029744 hawq_init:digoal:gpadmin-[INFO]:-20160903:21:02:22:029973 hawqinit.sh:digoal:gpadmin-[INFO]:-Loading hawq_toolkit...
20160903:21:02:22:029744 hawq_init:digoal:gpadmin-[INFO]:-Master init successfully
20160903:21:02:22:029744 hawq_init:digoal:gpadmin-[INFO]:-Init segments in list: ['localhost']
20160903:21:02:22:029744 hawq_init:digoal:gpadmin-[INFO]:-Total segment number is: 1
.20160903:21:02:22:029744 hawq_init:digoal:gpadmin-[INFO]:-20160903:21:02:22:030426 hawqinit.sh:digoal:gpadmin-[ERROR]:-Postgres initdb failed
20160903:21:02:22:030426 hawqinit.sh:digoal:gpadmin-[ERROR]:-Segment init failed on digoal.com
20160903:21:02:22:029744 hawq_init:digoal:gpadmin-[ERROR]:-HAWQ init failed on localhost
.
20160903:21:02:24:029744 hawq_init:digoal:gpadmin-[INFO]:-0 of 1 segments init successfully
20160903:21:02:24:029744 hawq_init:digoal:gpadmin-[ERROR]:-Segments init failed, exit
```
如果master init成功但是segment init不成功，查日志信息，找到原因，直接初始化segment  
```
20160903:08:53:00:023687 hawq_init:digoal:gpadmin-[INFO]:-20160903:08:53:00:023915 hawqinit.sh:digoal:gpadmin-[INFO]:-Loading hawq_toolkit...
20160903:08:53:00:023687 hawq_init:digoal:gpadmin-[INFO]:-Master init successfully
20160903:08:53:00:023687 hawq_init:digoal:gpadmin-[INFO]:-Init segments in list: ['localhost']
20160903:08:53:00:023687 hawq_init:digoal:gpadmin-[INFO]:-Total segment number is: 1
fgets failure: Success
The program "postgres" is needed by initdb but was either not found in the same directory as "/home/gpadmin/app/hawq/bin/initdb" or failed unexpectedly.
Check your installation; "postgres -V" may have more information.
20160903:08:53:00:024177 hawqinit.sh:digoal:gpadmin-[ERROR]:-Postgres initdb failed
20160903:08:53:00:024177 hawqinit.sh:digoal:gpadmin-[ERROR]:-Segment init failed on digoal.com
20160903:08:53:00:023687 hawq_init:digoal:gpadmin-[INFO]:-20160903:08:53:00:024177 hawqinit.sh:digoal:gpadmin-[ERROR]:-Postgres initdb failed
20160903:08:53:00:024177 hawqinit.sh:digoal:gpadmin-[ERROR]:-Segment init failed on digoal.com
20160903:08:53:00:023687 hawq_init:digoal:gpadmin-[ERROR]:-HAWQ init failed on localhost
20160903:08:53:02:023687 hawq_init:digoal:gpadmin-[INFO]:-0 of 1 segments init successfully
20160903:08:53:02:023687 hawq_init:digoal:gpadmin-[ERROR]:-Segments init failed, exit
```
手工初始化segment
```
[gpadmin@digoal ~]$ hawq init segment
20160903:17:45:23:026080 hawq_init:digoal:gpadmin-[INFO]:-Prepare to do 'hawq init'
20160903:17:45:23:026080 hawq_init:digoal:gpadmin-[INFO]:-You can find log in:
20160903:17:45:23:026080 hawq_init:digoal:gpadmin-[INFO]:-/home/gpadmin/hawqAdminLogs/hawq_init_20160903.log
20160903:17:45:23:026080 hawq_init:digoal:gpadmin-[INFO]:-GPHOME is set to: