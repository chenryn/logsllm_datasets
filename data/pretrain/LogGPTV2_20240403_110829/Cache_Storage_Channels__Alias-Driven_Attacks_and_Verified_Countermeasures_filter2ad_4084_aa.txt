title:Cache Storage Channels: Alias-Driven Attacks and Verified Countermeasures
author:Roberto Guanciale and
Hamed Nemati and
Christoph Baumann and
Mads Dam
2016 IEEE Symposium on Security and Privacy
2016 IEEE Symposium on Security and Privacy
Cache Storage Channels:
Alias-Driven Attacks and Veriﬁed Countermeasures
Roberto Guanciale, Hamed Nemati, Christoph Baumann and Mads Dam
Department of Computer Science
KTH Royal Institute of Technology
{robertog, hnnemati, cbaumann, mfd}@kth.se
Stockholm, Sweden
Abstract—Caches pose a signiﬁcant challenge to formal proofs
of security for code executing on application processors, as the
cache access pattern of security-critical services may leak secret
information. This paper reveals a novel attack vector, exposing
a low-noise cache storage channel that can be exploited by
adapting well-known timing channel analysis techniques. The
vector can also be used to
attack various types of security-
critical software such as hypervisors and application security
monitors. The attack vector uses virtual aliases with mismatched
memory attributes and self-modifying code to misconﬁgure the
memory system, allowing an attacker to place incoherent copies
of the same physical address into the caches and observe which
addresses are stored in different levels of cache. We design and
implement three different attacks using the new vector on trusted
services and report on the discovery of an 128-bit key from an
AES encryption service running in TrustZone on Raspberry Pi
2. Moreover, we subvert the integrity properties of an ARMv7
hypervisor that was formally veriﬁed against a cache-less model.
We evaluate well-known countermeasures against the new attack
vector and propose a veriﬁcation methodology that allows to
formally prove the effectiveness of defence mechanisms on the
binary code of the trusted software.
I. INTRODUCTION
Over the past decade huge strides have been made to
realise the long-standing vision of formally veriﬁed execu-
tion platforms, including hypervisors [32], [33], separation
kernels [18], [41], and microkernels [30]. Many of these plat-
forms have been comprehensively veriﬁed, down to machine
code [30] and Instruction Set Architecture (ISA) [18] levels,
and provide unprecedented security and isolation guarantees.
Caches are mostly excluded from these analyses. The veri-
ﬁcation of both seL4 [29] and the Prosper kernels [18], [33]
assume that caches are invisible and ignore timing channels.
The CVM framework from the Verisoft project [4] treats
caches only in the context of device management [24]. For
the veriﬁcation of user processes and the remaining part of
the kernel, caches are invisible. Similarly, the Nova [45], [46]
and CertiKOS [21] microvisors do not consider caches in their
formal analysis.
How much of a problem is this? It is already well under-
stood that caches are one of the key features of modern com-
modity processors that make a precise analysis of, e.g., timing
and/or power consumption exceedingly difﬁcult, and that this
can be exploited to mount timing-based side channels, even
for kernels that have been fully veriﬁed [13]. These channels,
thus, must be counteracted by model-external means, e.g., by
adapting scheduling intervals [44] or cache partitioning [40],
[28].
The models, however, should preferably be sound with
respect to the features that are reﬂected, such as basic memory
reads and writes. Unfortunately, as we delve deeper into the
Instruction Set Architecture we ﬁnd that this expectation is not
met: Certain conﬁgurations of the system enable an attacker
to exploit caches to build storage channels. Some of these
channels are especially dangerous since they can be used to
compromise both conﬁdentiality and integrity of the victim,
thus breaking the formally veriﬁed properties of isolation.
The principle idea to achieve this, is to break coherency
of the memory system by deliberately not following the
programming guidelines of an ISA. In this report we focus
on two programming faults in particular:
1) Accessing the same physical address through virtual
aliases with mismatched cacheability attributes.
2) Executing self-modifying code without ﬂushing the in-
struction cache.
Reference manuals for popular architectures (ARM, Power,
x64) commonly warn that not following such guidelines may
result in unpredictable behaviour. However, since the under-
lying hardware is deterministic, the actual behaviour of the
system in these cases is quite predictable and can be reverse-
engineered by an attacker.
The ﬁrst fault results in an incoherent memory conﬁguration
where cacheable and uncacheable reads may see different val-
ues for the same physical address after a preceding write using
either of the virtual aliases. Thus the attacker can discover
whether the physical address is allocated in a corresponding
cache line. For the second fault, jumping to an address that
was previously written without ﬂushing the instruction cache
may result in the execution of the old instruction, since data
and instruction caches are not synchronised automatically. By
carefully selecting old and new instructions, as well as their
addresses, the attacker can then deduce the status of a given
instruction cache line.
Obtaining this knowledge, i.e., whether certain cache lines
contain attacker data and instructions, is the basic principle
behind the Prime+Probe ﬂavor of access-driven timing channel
attacks [47]. This type of attack can be adapted using the
new attack vector. The main advantage of this approach
2375-1207/16 $31.00 © 2016 IEEE
© 2016, Roberto Guanciale. Under license to IEEE.
DOI 10.1109/SP.2016.11
DOI 10.1109/SP.2016.11
38
38
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:13:33 UTC from IEEE Xplore.  Restrictions apply. 
is that the cache storage channels presented here are both
more stealthy, less noisy, and easier to measure than timing
channels. Moreover, an incoherent data cache state can be
used to subvert the integrity of trusted services that depend
on untrusted inputs. Breaking the memory coherency for the
inputs exposes vulnerabilities that enable a malicious agent
to bypass security monitors and possibly to compromise the
integrity of the trusted software.
The attacks sketched above have been experimentally val-
idated in three realistic scenarios. We report on the imple-
mentation of a prototype that extracts a 128-bit key from an
AES encryption service running in TrustZone on Raspberry
Pi 2. We use the same platform to implement a process that
extracts the exponent of a modular exponentiation procedure
executed by another process. Moreover, implementing a cache-
based
attack we subverted the integrity properties of an
ARMv7 hypervisor that was formally veriﬁed against a cache-
less model. The scenarios are also used to evaluate several
existing countermeasures against cache-based attacks as well
as new ones that are targeted to the alias-driven attack vector.
Finally, we propose a methodology to repair the formal
analysis of the trusted software, reusing existing means as
much as possible. Speciﬁcally, we show (1) how a countermea-
sure helps restoring integrity of a previously formally veriﬁed
software and (2) how to prove the absence of cache storage
side channels. This last contribution includes the adaptation of
an existing tool [6] to analyse the binary code of the trusted
software.
II. BACKGROUND
Natural preys of side-channel attacks are implementations
of cryptographic algorithms, as demonstrated by early works
of Kocher [31] and Page [36]. In cache-driven attacks, the
adversary exploits the caches to acquire knowledge about the
execution of a victim and uses this knowledge to infer the
victim’s internal variables. These attacks are usually classiﬁed
in three groups, that differ by the means used by the attacker
to gain knowledge. In “time-driven attacks” (e.g. [48]), the
attacker, who is assumed to be able to trigger an encryption,
measures (indirectly or directly) the execution time of the
victim and uses this knowledge to estimate the number of
cache misses and hits of the victim. In “trace-driven attacks”
(e.g. [2], [36], [55]), the adversary has more capabilities: he
can proﬁle the cache activities during the execution of the vic-
tim and thus observe the cache effects of a particular operation
performed by the victim. This highly frequent measurement
can be possible due to the adversary being interleaved with the
victim by the scheduler of the operating system or because the
adversary executes on a separate core and monitors a shared
cache. Finally, in “access-driven attacks” (e.g. [34], [47]), the
attacker determines the cache indices modiﬁed by the victim.
This knowledge is obtained indirectly, by observing cache
side effects of victim’s computation on the behaviour of the
attacker.
In the literature, the majority of trace and access driven
attacks use timing channels as the key attack vector. These
vectors rely on time variations to load/store data and to fetch
instructions in order to estimate the cache activities of the
victim: the cache lines that are evicted, the cache misses, the
cache hits, etc.
Storage channels, on the other hand, use system variables
to carry information. The possible presence of these channels
raises concerns, since they invalidate the results of formal
veriﬁcation. The attacker can use the storage channels without
the support of an external measurement (e.g. current system
time), so there is no external variable such as time or power
consumption that can be manipulated by the victim to close
the channel and whose accesses can alert the victim about ma-
licious intents. Moreover, a storage channel can be less noisy
than timing channels that are affected by scheduling, TLB
misses, speculative execution, and power saving, for instance.
Finally, storage channels can pose risk to the integrity of a
system, since they can be used to bypass reference monitors
and inject malicious data into trusted agents. Nevertheless,
maybe due to the practical complexities in implementing these
channels, few works in literature address cache-based storage
channels.
One of the new attack vectors of this paper is based on
mismatched cacheability attributes and has pitfalls other than
enabling access-driven attacks. The vector opens up for Time
Of Check To Time Of Use (TOCTTOU) like vulnerabilities.
A trusted agent may check data stored in the cache that is
not consistent with the data that is stored in the memory by
a malicious software. If this data is later evicted from the
cache, it can be subsequently substituted by the unchecked
item placed in the main memory. This enables an attacker to
bypass a reference monitor, possibly subverting the security
property of formally veriﬁed software.
Watson [50] demonstrated this type of vulnerability for
Linux system call wrappers. He uses concurrent memory
accesses, using preemption to change the arguments to a
system call in user memory after they were validated. Using
non-cacheable aliases one could in the same way attack the
Linux system calls that read from the caller’s memory. A
further victim of such attacks is represented by run time
monitors. Software that dynamically loads untrusted modules
often uses Software-based Fault Isolation (SFI) [49], [43] to
isolate untrusted components from the trusted ones. If an on-
line SFI veriﬁer is used (e.g. because the loaded module is the
output of a just-in-time compiler), then caches can be used to
mislead the veriﬁer to accept stale data. This enables malicious
components to break the SFI assumptions and thus the desired
isolation.
In this paper we focus on scenarios where the victim and the
attacker are hosted on the same system. An instance of such
scenarios consists of a malicious user process that attempts to
compromise either another user process, a run-time monitor
or the operating system itself. In a cloud environment, the
attacker can be a (possibly compromised) complete operating
system and the victim is either a colocated guest, a virtual
machine introspector or the underlying hypervisor. Further
instances of such scenario are systems that use specialised
3939
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:13:33 UTC from IEEE Xplore.  Restrictions apply. 
hardware to isolate security critical components from untrusted
operating systems. For example, some ARM processors imple-
ment TrustZone [1]. This mechanism can be used to isolate
and protect the system components that implement remote at-
testation, trusted anchoring or virtual private networks (VPN).
In this case, the attacker is either a compromised operating
system kernel or an untrusted user process threatening a
TrustZone application.
A1) write(VA_c, 1)
A2) write(VA_nc, 0)
A3) call victim
A4) D = read(VA_nc)
V1) if secret
access(VA3)
else
access(VA4)
V2) access(VA3+secret)
III. THE NEW ATTACK VECTORS: CACHE STORAGE
CHANNELS
Fig. 1. Conﬁdentiality threat due to data-cache (for write-back caches with
inertia and lazy write)
Even if it is highly desirable that the presence of caches is
transparent to program behaviour, this is usually not the case
unless the system conﬁguration satisﬁes some architecture-
speciﬁc constraints. Memory mapped devices provide a trivial
example: If the address representing the output register of
a memory mapped UART is cacheable,
the output of a
program is never visible on the serial cable, since the output
characters are overwritten in the cache instead of being sent
to the physical device. These behaviours, which occur due to
misconﬁgurations of the system, can raise to security threats.
To better understand the mechanisms that constitute our
attack vectors, we summarise common properties of modern
architectures. The vast majority of general purpose systems
use set-associative caches:
(i) Data is transferred between memory and cache in blocks
of ﬁxed size, called cache lines.
(ii) The memory addresses are logically partitioned into sets
of lines that are congruent wrt. a set index; usually set
index depends on either virtual addresses (then the cache
is called virtually indexed) or physical addresses (then
the cache is called physically indexed);
(iii) The cache contains a number of ways which can hold
one corresponding line for every set index.
(iv) A cache line stores both the data, the corresponding
physical memory location (the tag) and a dirty ﬂag
(which indicates if the line has been changed since it
was read from memory).
Caches are used by processors to store frequently accessed
information and thus to reduce the number of accesses to
main memory. A processor can use separate instruction and
data caches in a Harvard arrangement (e.g. the L1 cache in
ARM Cortex A7) or uniﬁed caches (e.g. the L2 cache in
ARM Cortex A7). Not all memory areas should be cached;
for instance, accesses to addresses representing registers of
memory mapped devices should always be directly sent to the
main memory subsystem. For this reason, modern Memory
Management Units (MMUs) allow to conﬁgure, via the page
tables, the caching policy on a per-page basis, allowing a ﬁne-
grained control over if and how areas of memory are cached.
In Sections III-A, III-B and III-C we present three new
attack vectors that depends on misconﬁgurations of systems
and caches. These attacks exploit the following behaviours:
• Mismatched cacheability attributes;
reports a hit on a memory location that
if the data cache
is marked
A1) invalidate(VA_c)
A2) write(VA_nc, 0)
A3) D = read(VA_c)
A4) write(VA_nc, 1)
A5) call victim
A6) D = read(VA_c)
Fig. 2. Conﬁdentiality threat due to data-cache (for write-through caches or
caches that do not guarantee inertia or lazy write)
as non-cacheable, the cache might access the memory
disregarding such hit. ARM calls this event “unexpected
cache hit”.
• Self-modifying code; even if the executable code is
updated, the processor might execute the old version of
it if this has been stored in the instruction cache.
The attacks can be used to threaten both conﬁdentiality and
integrity of a target system. Moreover, two of them use new
storage channels suitable to mount access driven attacks. This
is particularly concerning, since so far only a noisy timing
channel could be used to launch attacks of this kind, which
makes real implementations difﬁcult and slow. The security
threats are particularly severe whenever the attacker is able
to (directly or indirectly) produce the misconﬁgurations that
enable the new attack vectors, as described in Section III-D.
A. Attacking conﬁdentiality using data-caches
Here we show how an attacker can use mismatched
cacheability attributes to mount access-driven cache attacks;
i.e. measuring which data-cache lines are evicted by the
execution of the victim.
We use the program in Figure 1 to demonstrate the attacker
programming model. For simplicity, we assume that the cache
is physically indexed, it has only one way and that it uses
the write allocate/write back policy. We also assume that the
attacker can access the virtual addresses vac and vanc, both
pointing to the physical address pa; vac is cacheable while
vanc is not. The attacker writes 1 and 0 into the virtual