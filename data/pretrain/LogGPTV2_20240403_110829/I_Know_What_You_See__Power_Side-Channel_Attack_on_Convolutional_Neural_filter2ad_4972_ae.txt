### Optimized Text

#### Parallel Processing with Line Buffers
For images with multiple channels (e.g., three channels for an RGB image), multiple instances of line buffers are synthesized to enable parallel processing. Once all input pixels have been processed by the line buffer, one output feature map is completed and stored in the data buffer for the next round of processing. This procedure is repeated until all output feature maps are generated using different kernels. The operation of the line buffer ensures that, at each cycle, the output depends on a limited number of input pixels within the convolution window, which forms the basis for our proposed attack.

#### Implementation and Architecture
In this paper, we follow the implementation proposed by Zhao et al. [39], who developed an accelerator for a compressed version of CNNs [12] on FPGA. Their architecture is based on line buffers, and in their neural accelerator, the parameters and activations within the network model are limited to either 1 or -1. This allows the weights of the compressed network to be entirely stored within the RAM of the FPGA.

#### Basics of Power Side-Channel Analysis
**Power Consumption:**
Circuit power consumption can be categorized into static and dynamic. Static power consumption is due to the leakage current of transistors and is typically very low. Dynamic power consumption, which is more significant, results from internal transitions of transistors and is closely related to the input data. To measure power consumption, a 1Ω resistor is placed on the power supply line, and the voltage drop across it is measured using a high-resolution oscilloscope.

**Table 3: Estimated Power Consumption for Line Buffer Configurations**

| Configuration | Convolution Unit Power Estimation (mW) | Total Power Estimation (mW) |
|---------------|----------------------------------------|-----------------------------|
| IC: 1, LS: 28, KS: 3 x 3 | 0.67 | 0.57 |
| IC: 1, LS: 32, KS: 3 x 3 | 0.79 | 0.64 |
| IC: 1, LS: 28, KS: 5 x 5 | 1.51 | 1.25 |
| IC: 3, LS: 28, KS: 3 x 3 | 2.07 | 1.78 |

*IC – Image Channel, LS – Line Size, KS – Kernel Size*

#### Power Consumption of Line Buffer
As the line buffer is the primary target of our attack, we estimated the power consumption of the convolution unit and total power consumption using Xilinx XPower Analyzer, a software power emulator for FPGAs. We implemented the line buffer in RTL with various configurations, and the results are shown in Table 3. The convolution unit dominates the total power consumption, accounting for more than 80% in all configurations. Specifically, we implemented four common configurations: three with one input channel and varying line sizes (28 and 32) and kernel sizes (3x3 and 5x5). The fourth configuration has three input channels with the same line size and kernel size as the first. The power consumption of the convolution unit increases significantly with larger kernel sizes and more input channels, as more pixels are involved in the convolution. The change in line size has a minimal impact on the power consumed by the convolution units. Thus, the measured power can be considered a coarse-grain estimate of the convolution unit's power.

#### Discussion and Future Work
**Applicability:**
Although our power side-channel attack was evaluated on an FPGA-based accelerator, the attack targets the line buffer structure, where we exploit the power consumption of the sliding convolutional window over the input image. This makes the attack applicable to any design that uses a line buffer for convolution operations. Line buffers are popular in FPGA- and ASIC-based neural network accelerators [5, 29, 38], making our attack a significant threat to their security.

**Attack Target and Background Detection:**
The background detection method proposed in Section 6 may not always recover all background pixels, especially in images with complex backgrounds. The threshold used in background detection is based on the sharp decline in power consumption per cycle, which may not be observable if the number of background pixels is much smaller than the foreground pixels. Therefore, the method is most effective for images with a pure and relatively large background region.

**Extension to Other Datasets:**
Our attack was built and verified using the MNIST dataset. To demonstrate its applicability to other datasets, we applied both background detection and power template attacks to an image from the Digital Database for Screening Mammography (DDSM) [10]. The recovered image, while not perfect, retains enough detail to infer private information, such as the shape of the breast. This highlights the potential privacy risks associated with our attack.

**Countermeasures:**
Adding noise to the power side channel is a straightforward but not foolproof countermeasure. More effective methods include random masking and random scheduling. Random masking breaks the correlation between power consumption and sensitive data by adding a random number to each pixel value before convolution and subtracting it afterward. Random scheduling, by executing convolution computations in a random order, can prevent active adversaries from building accurate power feature vectors.

**Limitations and Future Work:**
Our attack is currently limited to designs based on line buffers and cannot be directly applied to GPU or TPU-based systems. Simple randomization techniques can also defend against our attack. Additionally, the attack's effectiveness depends on the similarity of the profiling and attack datasets. For more complex images, such as color images, more data and advanced techniques like PCA and SVM may be required to achieve acceptable results. Future work will focus on validating our method on more complex datasets, such as CIFAR-10 or ImageNet.

#### Attack Results on the MNIST Dataset
The recovered images from the power side channel are illustrated in Figure 11. We selected correctly classified images with the same input to compare the quality of the recovered images directly.

#### References
[References remain unchanged]

---

This optimized text aims to improve clarity, coherence, and professionalism, ensuring that the content is well-structured and easy to understand.