several channels (e.g., three channels for an RGB image), multi-
ple instances of line buffer are synthesized for parallel procession.
When all input pixels are processed by the line buffer, one output
feature map is finished and stored on the data buffer for process-
ing in the next round. The above-mentioned procedure is repeated
until we generate all output feature maps with different kernels.
As we can see from the operation of line buffer, at each cycle, the
output only depends on a limited number of input pixels (inside the
convolution window), which serves as the foundation to efficiently
launch our proposed attack.
In this paper, we follow the implementation proposed by Zhao
et al [39] who implement accelerator for a compressed version
of CNN [12] on FPGA. The convolution unit in their proposed
architecture is based on the line buffer. In their neural accelerator,
the parameters and activations inside the network model is limited
to either 1 or -1 so that the weights of compressed network can be
completely stored inside the RAM of FPGA.
A.3 Basics on Power Side Channel
Power Constitution and Measurement: The power consump-
tion of circuits can be divided into two categories: static and dy-
namic. Static power consumption arises from the leakage current of
transistors and is typically very low. Dynamic power consumption
comes from internal transitions of transistors which closely relate
to its input data and it usually dominates the total power consump-
tion in its magnitude. To measure the power consumption, a 1Ω
resistor is placed on the power supply line and the voltage drop on
it is measured using a high-resolution oscilloscope.
Table 3: Estimated power consumption for line buffer
Line Buffer
Configuration
Convolution Unit
Power Estimation
Total Power
Estimation
IC: 1, LS: 28, KS: 3 x 3
0.67mW
IC: 1, LS: 32, KS: 3 x 3
0.79mW
IC: 1, LS: 28, KS: 5 x 5
1.51mW
IC: 3, LS: 28, KS: 3 x 3
2.07mW
* IC – Image Channel, LS – Line Size, KS – Kernel Size
0.57mW
0.64mW
1.25mW
1.78mW
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
L. Wei et al.
Figure 9: (a) 2D Convolution operation in CNN. (b) Architecture of CNN implementation in [39]. (c) Structure of line buffer
Power Consumption of Line Buffer: As the line buffer is the
main attack target, we estimated the power consumption of the
convolution unit and total power consumption with Xilinx XPower
Analyzer, a software power emulator for FPGA. We implemented
the line buffer in RTL with various configurations and the result is
shown in Table 3, wherein the convolution unit dominates the total
power consumption. To be specific, we implemented four common
configurations of line buffer: three of them have only one input
channel, but the line size is 28 and 32 respectively and kernel size
can be either 3x3 or 5x5. The last configuration is of three input
channels, its line size and filter size are identical to that in the first
row. From the statistics of Table 3, the power consumption of the
convolutional unit increases significantly due to the increase of
kernel size and input channel. It is because in these two cases, the
pixels involved in the convolution unit increases. The change of line
size does not affect much of the power consumed by convolution
units. Whatever the configuration, the power in the convolution
unit occupies more than 80% of the total consumption. Therefore,
we can regard the measured power as a coarse-grain estimate for
the power of convolution unit.
B DISCUSSION AND FUTURE WORK
In this section, we first discuss the applicability of our proposed
attack and the attack target of background detection method. We
also discuss the countermeasures, limitations and future work.
Applicability: Though we evaluate our power side-channel attack
on the accelerator implemented on FPGA, the actual attack target
is the structure of line buffer where we exploit the power consump-
tion with the sliding convolutional window over the input image.
Thus our attack is applicable for whatever designs adopting the line
buffer to execute the convolutional operation. Though line buffer is
not suitable for DNN system on CPU or GPU, it enjoys popularity
among a variety of FPGA- or ASIC-based neural network acceler-
ators [5, 29, 38]. Considering the promising future application of
neural accelerators, the proposed attack is a severe threat for the
security of them.
Attack Target of Background Detection: Firstly, the background
detection method proposed in Section 6 is not guaranteed to find all
pixels in pure background because its recovery granularity is lim-
ited by the kernel size. Thus, the background detection method can
fail to recover the images with a messy background. Secondly, the
threshold used in background detection is determined by the sharp
descend of cycle counts of power consumed per cycle. We may not
be able to observe the decline if the number of background pixels is
far less than the foreground pixels. To summarize, the background
detection method can recover the images which contains a pure
and relatively large background region.
Extension to other datasets: In our proposed attack, we built our
template with MNIST dataset and verify the runtime results with
it. It is essential to discuss whether our attack method is still appli-
cable to other datasets. Ideally, the recovery template is built from
data inside the convolutional window and the corresponding power
consumption, which is independent from the chosen dataset if the
template is built in a way avoids overfitting. To demonstrate the
effectiveness of our proposed attack, we launch both background
detection and power template attacks on an image extracted from
the Digital Database for Screening Mammography (DDSM) [10],
a medical image dataset for mammography research. Fig. 10 (a)
shows the original image (resized to 168 × 84) from the dataset. It is
a side-view radiology image of human breast. Fig. 10 (b) and Fig. 10
(c) illustrate the recovered image using background detection and
power template respectively. The template used for this demonstra-
tion is the same with that we used to recover the MNIST images
in Section 7.2. From the recovered image, we can see the shape of
breast is pretty much preserved in Fig. 10 (b), thus for adversary
the shape can be used to infer the potential scanned organ of the
patient. This leakage somehow reveals the privacy of the patient.
We can also get more details in the image recovered from power
template. The pixels gradually get lighter from the border part of
the breast to the center part, which is consistent with the original
image. Though the quality of recovered image cannot reflect every
detail of the original image, it still can be used to deduce private
information by adversaries.
Countermeasures: The most straight forward way to prevent
the side channel attacker is to add noises on power side channel,
but it does not grant strong guarantees on the privacy protection
as noises can still be somehow cancelled with its distribution. For
performance and security reason, countermeasures against power
side channel attack can be implemented by mainly two ways: ran-
dom masking and random scheduling. Random masking breaks the
correlation between the power consumption and the sensitive data
by masking the intermediate result with a random number. For
ParamBufferDMAControllerConvolutionPoolingFully-connectedData BufferABCompute Units++++Convolution UnitNon-linear functionOutput (a)(b)Line 1 registersLine 2 registersLine 3 registers(c)000000001110001221100122210001221000111100011110000000-410-84Convolution KernelInput Feature MapOutput Feature MapSource pixelDestination pixelInputPixelsPower Side-Channel Attack on Convolutional Neural Network Accelerators
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Figure 10: Results on a Mammographic image
instance, before the convolution, each pixel value used for computa-
tion is added with a random number. Then after the convolution re-
sult is obtained, the result is subtracted by the sum of these random
numbers weighted by the convolution kernel. Random scheduling
is effective against active attackers who utilize power from multiple
kernels. If the convolution computation for each kernel is executed
in a random order rather than sequentially, active adversaries will
not be able to build an accurate power feature vector and they can
fail in producing a recognizable image.
Limitations and Future Work: As mentioned in above subsec-
tions, the current proposed attacking algorithm only works for
designs based on the line buffer (e.g., on FPGA or ASIC) and it
cannot be directly applicable for GPU or TPUs. The attacks can
also be defended by simple randomization techniques as discussed
in the previous subsection. Thirdly, our proposed attack algorithm
is currently profiling the power consumption with images coming
from the same sampling set. They inherently resemble each other
so that we can achieve high recognition accuracy with relatively
low overhead. On the other hand, the images adopted in the exper-
iment are either quasi-binary (MNIST) or simple gray-scale images
(mammographic pictures). If the attackers target at images with
multiple input channel (e.g., color images) or they are not able to
get the input images with same distribution of attack target in the
profiling phase, more data need to be enrolled to achieve acceptable
results. Thus, it is essential to handle the performance problem
incurred by complex image recovery task and limited capability of
obtaining data from similar distribution. We may resort to follow-
ing techniques to tackle the problem: we can use PCA to compress
the power feature vector and related pixel values to reduce the size
of the pre-built power template and use SVM or random forest to
choose candidates in actual attacks. We plan to incorporate them
in our future work and validate our method on more complicated
datasets, such as CIFAR-10 or even ImageNet.
C ATTACK RESULTS ON THE MNIST
DATASET
The recovered image of from power side channel is illustrated in
Fig. 11. For two recovery methods, we select the correctly classified
images with the same input image so that we can compare the
quality of recovered images directly.
REFERENCES
[1] Martín Abadi, Andy Chu, Ian J. Goodfellow, H. Brendan McMahan, Ilya Mironov,
Kunal Talwar, and Li Zhang. 2016. Deep Learning with Differential Privacy. In
Proc. of ACM SIGSAC Conference on Computer and Communications Security (CCS).
308–318.
[2] B. Bosi, Guy Bois, and Yvon Savaria. 1999. Reconfigurable pipelined 2-D con-
volvers for fast digital signal processing. IEEE Transactions on VLSI Systems 7, 3
(1999), 299–308.
[3] Eric Brier, Christophe Clavier, and Francis Olivier. 2004. Correlation Power
Analysis with a Leakage Model. In Proc. of Cryptographic Hardware and Embedded
Systems - CHES. 16–29.
[4] Omar Choudary and Markus G Kuhn. 2013. Efficient template attacks. In Inter-
national Conference on Smart Card Research and Advanced Applications. Springer,
253–270.
[5] Francesco Conti and Luca Benini. 2015. A ultra-low-energy convolution engine
for fast brain-inspired vision in multicore clusters. In Design, Automation & Test
in Europe Conference & Exhibition (DATE), 2015. IEEE, 683–688.
[6] Thomas Eisenbarth, Christof Paar, and Björn Weghenkel. 2010. Building a Side
Channel Based Disassembler. Trans. Computational Science 10 (2010), 78–99.
[7] Matt Fredrikson, Somesh Jha, and Thomas Ristenpart. 2015. Model Inversion
Attacks that Exploit Confidence Information and Basic Countermeasures. In Proc.
of ACM SIGSAC Conference on Computer and Communications Security (CCS).
1322–1333.
[8] Matthew Fredrikson, Eric Lantz, Somesh Jha, Simon Lin, David Page, and Thomas
Ristenpart. 2014. Privacy in Pharmacogenetics: An End-to-End Case Study
of Personalized Warfarin Dosing. In Proceedings of the 23rd USENIX Security
Symposium, San Diego, CA, USA, August 20-22, 2014. 17–32.
[9] Benedikt Gierlichs, Lejla Batina, Pim Tuyls, and Bart Preneel. 2008. Mutual
information analysis. Cryptographic Hardware and Embedded Systems–CHES
2008 (2008), 426–442.
[10] M. Heath, K. Bowyer, Daniel B. Kopans, P. Kegelmeyer Jr., Richard H. Moore,
K. Chang, and S. Munishkumaran. 1998. Current Status of the Digital Database
for Screening Mammography. In Digital Mammography, Fourth International
Workshop on Digital Mammograph, IWDM 1998, Nijmegen, The Netherlands, June
1998. 457–460. https://doi.org/10.1007/978-94-011-5318-8_75
[11] Weizhe Hua, Zhiru Zhang, and G. Edward Suh. 2018. Reverse engineering convo-
lutional neural networks through side-channel information leaks. In Proceedings
of the 55th Annual Design Automation Conference, DAC 2018, San Francisco, CA,
USA, June 24-29, 2018. 4:1–4:6.
[12] Itay Hubara, Matthieu Courbariaux, Daniel Soudry, Ran El-Yaniv, and Yoshua
Bengio. 2016. Binarized Neural Networks. In Advances in Neural Information
Processing Systems 29: Annual Conference on Neural Information Processing Systems
2016, December 5-10, 2016, Barcelona, Spain. 4107–4115.
[13] BigML Inc. 2017. BigML. https://www.bigml.com/
[14] Microsoft Inc. 2017. Microsoft Azure Machine Learning. https://azure.microsoft.
[16] National Instruments. 2017. NI Multisim. www.ni.com/multisim/
[17] Paul C. Kocher, Joshua Jaffe, and Benjamin Jun. 1999. Differential Power Analysis.
In Proc. of Annual International Cryptology Conference - CRYPTO ’99. 388–397.
[18] Satoh Lab./UEC. 2017. SAKURA-G. http://satoh.cs.uec.ac.jp/SAKURA/hardware/
SAKURA-G.html
[19] Satoh Lab./UEC. 2017. SAKURA: Side-channel AttacK User Reference Architec-
ture – Specification. http://satoh.cs.uec.ac.jp/SAKURA/hardware/SAKURA-G_
Spec_Ver1.0_English.pdf
[20] Yann LeCun, Yoshua Bengio, et al. 1995. Convolutional networks for images,
speech, and time series. The handbook of brain theory and neural networks 3361,
10 (1995), 1995.
[21] Yann LeCun, Corinna Cortes, and Christopher J.C. Burges. 2001–. THE MNIST
DATABASE of handwritten digits. http://yann.lecun.com/exdb/mnist/.
[22] Yannan Liu, Lingxiao Wei, Zhe Zhou, Kehuan Zhang, Wenyuan Xu, and Qiang
Xu. 2016. On Code Execution Tracking via Power Side-Channel. In Proc. of ACM
SIGSAC Conference on Computer and Communications Security (CCS). 1019–1031.
[23] Thomas S. Messerges. 2000. Using Second-Order Power Analysis to Attack DPA
Resistant Software. In Cryptographic Hardware and Embedded Systems - CHES
2000, Second International Workshop, Worcester, MA, USA, August 17-18, 2000,
Proceedings. 238–251.
[24] Payman Mohassel and Yupeng Zhang. 2017. SecureML: A System for Scalable
Privacy-Preserving Machine Learning. In Proc. of IEEE Symposium on Security
and Privacy SP. 19–38.
[25] Mehari Msgna, Konstantinos Markantonakis, and Keith Mayes. 2013. The B-
Side of Side Channel Leakage: Control Flow Security in Embedded Systems.
In Security and Privacy in Communication Networks - 9th International ICST
Conference, SecureComm 2013, Sydney, NSW, Australia, September 25-28, 2013,
Revised Selected Papers. 288–304.
[26] Tom O’Haver. 1997. A Pragmatic introduction to signal processing.
[27] Nicolas Papernot, Patrick D. McDaniel, Somesh Jha, Matt Fredrikson, Z. Berkay
Celik, and Ananthram Swami. 2016. The Limitations of Deep Learning in Ad-
versarial Settings. In Proc. of IEEE European Symposium on Security and Privacy,
EuroS&P. 372–387.
[28] Nicolas Papernot, Patrick D. McDaniel, Xi Wu, Somesh Jha, and Ananthram
Swami. 2016. Distillation as a Defense to Adversarial Perturbations Against
com/en-us/services/machine-learning/
[15] Xilinx Inc. 2017. Xilinx Spartan-6 FPGA family.
products/silicon-devices/fpga/spartan-6.html
https://www.xilinx.com/
(a) Original Image(b) Background Recovery(c) Recovery with TemplateACSAC ’18, December 3–7, 2018, San Juan, PR, USA
L. Wei et al.
Figure 11: Recovered image of correctly classified digits.
Deep Neural Networks. In Proc. of IEEE Symposium on Security and Privacy SP.
582–597.
[29] Jiantao Qiu, Jie Wang, Song Yao, Kaiyuan Guo, Boxun Li, Erjin Zhou, Jincheng Yu,
Tianqi Tang, Ningyi Xu, Sen Song, et al. 2016. Going deeper with embedded fpga
platform for convolutional neural network. In Proceedings of the 2016 ACM/SIGDA
International Symposium on Field-Programmable Gate Arrays. ACM, 26–35.
[30] Qualcomm. 2017. Artificial intelligence tech in Snapdragon 835. https://www.
qualcomm.com/snapdragon/artificial-intelligence
Education (2002).
[31] C Rafael Gonzalez and Richard Woods. 2002. Digital image processing. Pearson
[32] Christian Rechberger and Elisabeth Oswald. 2004. Practical Template Attacks. In
Information Security Applications, 5th International Workshop, WISA 2004, Jeju
Island, Korea, August 23-25, 2004, Revised Selected Papers. 440–456.
[33] Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov. 2017. Mem-
bership Inference Attacks Against Machine Learning Models. In Proc. of IEEE
Symposium on Security and Privacy, SP. 3–18.
[34] G. Edward Suh, Dwaine E. Clarke, Blaise Gassend, Marten van Dijk, and Srinivas
Devadas. 2003. AEGIS: architecture for tamper-evident and tamper-resistant
processing. In Proceedings of the 17th Annual International Conference on Super-
computing, ICS 2003, San Francisco, CA, USA, June 23-26, 2003. 160–171.
[35] Vivienne Sze, Yu-Hsin Chen, Tien-Ju Yang, and Joel Emer. 2017. Efficient process-
ing of deep neural networks: A tutorial and survey. arXiv preprint arXiv:1703.09039
(2017).
[36] Tektronics. 2017. MDO3000 Mixed Domain Oscilloscope. http://www.tek.com/
oscilloscope/mdo3000-mixed-domain-oscilloscope
[37] Florian Tramèr, Fan Zhang, Ari Juels, Michael K. Reiter, and Thomas Ristenpart.
2016. Stealing Machine Learning Models via Prediction APIs. In 25th USENIX
Security Symposium, USENIX Security 16, Austin, TX, USA, August 10-12, 2016.
601–618.
[38] Chi Zhang and Viktor Prasanna. 2017. Frequency domain acceleration of convo-
lutional neural networks on CPU-FPGA shared memory system. In Proceedings
of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate
Arrays. ACM, 35–44.
[39] Ritchie Zhao, Weinan Song, Wentao Zhang, Tianwei Xing, Jeng-Hau Lin, Mani B.
Srivastava, Rajesh Gupta, and Zhiru Zhang. 2017. Accelerating Binarized Convo-
lutional Neural Networks with Software-Programmable FPGAs. In Proc. of the
ACM/SIGDA International Symposium on Field-Programmable Gate Arrays FPGA.
15–24.
OriginalImageBackgroundDetection(3 x 3 Kern Size)Pixel Recoveryvia Power Template(3 x 3 Kern Size)