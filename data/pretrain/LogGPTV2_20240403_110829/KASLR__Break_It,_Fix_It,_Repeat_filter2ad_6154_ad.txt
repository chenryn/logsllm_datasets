the newest Cascade Lake CPUs.
Data Bounce [76] breaks KASLR by exploiting that the CPU only
performs store-to-load forwarding if a physical page backs a virtual
address, i.e., the virtual address can be resolved to a physical address.
Using this approach, they can break KASLR on all Intel CPUs going
back to 2004. They claim that the attack has perfect accuracy and
only requires 42 µs to detect the correct kernel location. One of the
advantages of this approach over Jang et al. [49] is that it does not
require TSX and, hence, is applicable to a broader range of CPUs.
However, the behavior of store-to-load forwarding was changed
in Cascade Lake CPUs to prevent this attack (cf. Table 1). Hence,
while their approach works on microarchitectures starting from
the Pentium 4 Prescott to Whiskey Lake and Coffee Lake R, it does
not work on the recent Cascade Lake.
EchoLoad relies on the load stalling behavior of the CPU, an
effect which has not been exploited so far. As this effect is deeply
rooted in the design of the microarchitecture, it cannot easily be
1,536
11
v4.15
6,144
5,632
5
v5.0
4
v5.2
4KB
2MB
Figure 5: On recent Linux, several 2 MB pages in the kernel
text segment have been replaced by 4 kB pages.
fixed (cf. Section 3.1), neither in software nor hardware. Moreover,
the attack does not have any requirements as it solely relies on
memory loads. As a consequence, even the most recent Cascade
Lake is affected by EchoLoad.
4 FLARE: MITIGATING KASLR BREAKS
In this section, we propose FLARE, a defense against KASLR attacks
rooted in a CPU’s microarchitecture.
FLARE has a negligible memory overhead of only a few kilobytes
and next to no runtime overhead. FLARE tackles the root causes of
all the microarchitectural KASLR breaks discussed in Section 3.5.
It builds on ideas from KAISER [31] and LAZARUS [26] to fix
remaining weaknesses efficiently and securely.
The challenge is to fully eliminate differences in:
C1: timing and behavior for mapped and unmapped pages,
C2: timing for different page sizes, and
C3: timing between executable and NX pages.
As we show in this section, FLARE successfully tackles these chal-
lenges. However, before we justify these challenges, we briefly
introduce a threat model. We then discuss implementation details,
corner cases, and pitfalls in Section 4.1.
Threat Model. Our attacker can run unprivileged native code
on an up-to-date OS. Furthermore, the attacker knows the exact
version of the Linux kernel that the victim uses and, hence, knows
the exact structure of the kernel image in memory.
In Sec-
C1: Differences for Mapped and Unmapped Pages.
tion 3.5, we discuss that recent attacks, including EchoLoad, can
distinguish mapped from unmapped pages [9, 32, 37, 49, 76]. There-
fore, the first challenge is to prevent an attacker from detecting the
KASLR offset based on that information.
To tackle this challenge, we map all unmapped virtual addresses
in the randomization range to a dummy physical page. Therefore,
none of the known attacks that rely on distinguishing mapped from
unmapped addresses can de-randomize the kernel anymore.
C2: Timing Differences for Page Sizes. In Section 3.5, we dis-
cuss that the attack by Gruss et al. [32] can distinguish different
page sizes: Even if the entire kernel space has a valid mapping, dif-
ferent page sizes can create a unique pattern which de-randomizes
the kernel. This is especially a problem as the kernel uses different
page sizes for its mapping (cf. Figure 5), possibly creating such a
unique pattern. We tackle this challenge by avoiding different page
sizes in the kernel altogether.
C3: Timing Difference between Executable and NX Pages.
Jang et al. [49] showed that there is a timing difference between
executable and NX pages. We analyzed the kernel and discovered
that executable and NX pages are strictly separated. That is, af-
ter the first NX page in the address space there is not a single
executable page in the remaining address space. To prevent this
straightforward KASLR break, we randomize the executable and
Executable
code
Non-Executable
data
0xffff ffff 8000 0000
0xffff ffff bfff ffff
0xffff ffff 9fff ffff
Figure 6: With FLARE, all possible kernel offsets are physi-
cally backed, i.e., any potentially read value from this range
will be zero. Code and data is independently randomized in
512 MB ranges. This setup allows preventing all currently
known microarchitectural attacks on KASLR.
the NX range separately and pad them each with executable and
NX pages respectively to the full randomization range.
4.1 Implementation Details
The different Linux kernel regions (cf. Section 2.5) are mapped
with different properties, i.e., different page sizes and permissions
(e.g., executable and NX). Note that we only need to protect the
trampoline code if KPTI is active, while we have to protect the
following regions without KPTI.
Text Segment. Figure 5 shows that the text segment is mapped
using both 4 kB and 2 MB pages. To address C1, we map the entire
range where the text segment can be mapped using 4 kB pages,
preventing the attacker from seeing the actual text-segment range.
To address C2, we map the text segment only with 4 kB pages,
preventing attacks that distinguish page sizes [32]. This is not a
large kernel change as this is already an ongoing development (cf.
Figure 5). The kernel already supports disabling the use of non-4 kB
pages by clearing the CPU capability X86_FEATURE_PSE.
Furthermore, to tackle C3, we use the solution shown in Figure 6.
We split the randomization range of the text segment in half. We
then use one half for the randomization of executable pages, i.e.,
the kernel code, and the other for NX pages, i.e., the kernel data.
Both regions are then randomized independently to not leak their
corresponding start and end addresses. This split does not introduce
any compatibility issues, even with relative addressing, as we stay
within the maximum addressable range of 4 GB.
Modules. Modules already use 4 kB pages only, solving C2. In our
proposal, we pad the code and data sections of every module to
a multiple of 1 MB, depending on the size of the largest currently
loaded module. We then map the remaining offsets in the address
range with dummy modules using 4 kB pages that look exactly the
same as the actual modules, i.e., same size for code and data sections.
Consequently, using the technique by Jang et al. [49] in the memory
range for kernel modules, we only see executable and NX regions of
all the same size. This mitigates the templating attack by Jang et al.
[49] as the attacker cannot infer anymore which module is real and
which one is not. With this approach, we solve all three challenges.
Naturally, the privileged user can dynamically load modules
which takes the place of a previous dummy module. Likewise, for
the unload, a dummy module replaces the kernel module mapping.
However, the implementation should be careful not to leave a small
time window open for an attack. In our FLARE proof-of-concept,
we enable the loading of modules by first removing the dummy
mapping by hooking the function load_module. Then the module
is loaded, and afterward, the mitigation is re-applied. However,
a proper implementation should exchange the page-table entries
directly instead. This way, it is guaranteed that no time window
is left for the attacker to observe the short unmapping from a
concurrent microarchitectural attack, as there simply is no short
unmapping. Furthermore, the loading and unloading of modules
typically does not happen for an average user.
Direct-Physical Map, Vmalloc, Vmemmap. We analyzed how
the direct-physical map, vmalloc, and vmemmap are mapped. None
of the pages mapped in this region is executable. Thus, we tackle
challenges C1 and C3 by mapping all pages in the corresponding
randomization regions in our dummy mapping as NX.
Currently, the kernel does not use an explicit randomization
range for each of the three regions. Instead, the kernel uses one
large range and only guarantees to preserve their order. To mitigate
the attack by Gruss et al. [32], all three must use the same page
size. We verified that this is already the case when clearing the
X86_FEATURE_PSE CPU capability at boot. As this causes significant
pressure on the TLB, we propose a different approach.
We propose that the kernel uses an explicit randomization range
for each of the three regions. Hence, to tackle C2, we can enforce
that the kernel consistently uses one page size per region. This
mitigates the attack by Gruss et al. [32]. In the analysis for our
defense, we empirically determined the page sizes used for each
region. On our test machine running Linux kernel 4.15, the kernel
indicates during the boot process that 1 GB pages are used for
mapping the direct-physical map. However, our analysis revealed
that it is mapped using all three page sizes, i.e., 4 kB, 2 MB, and
1 GB. Similarly, the vmalloc area uses both 4 kB and 2 MB pages.
The vmemmap area consisted of 2 MB pages only.
Based on this analysis, we propose to consistently use 2 MB pages
for the vmemmap region and 4 kB pages for the vmalloc region.
For the direct-physical map, we use 1 GB pages. Unfortunately, we
cannot use such a huge dummy page for our mapping as we would
reduce the available physical memory by 1 GB. Instead, we pick
1 GB of RAM, which is already mapped in the direct-physical map,
and map it using a 1 GB page in our dummy mapping. Hence, we
avoid the additional memory overhead without increasing the risk
for exploitation as we map the page as NX.
5 EVALUATION
In this section, we evaluate the overhead of FLARE in three as-
pects, namely runtime overhead using the SPEC CPU 2017 bench-
marks [16], module loading overhead, as well as the memory over-
head. We also evaluate the efficacy of FLARE by analyzing how
successful it is in preventing microarchitectural attacks on KASLR.
5.1 Overhead Analysis
Runtime. We create our dummy mapping directly in the init_mm
struct which is copied into every newly created process. We only
have to apply our mapping once, and every new process has the
mitigation enabled. Hence, we expect no runtime overhead.
We confirmed this using the LMbench microbenchmark suite [64].
We evaluated process-creation time (fork and exec) and context
switches on an Intel i7-8650U (Linux kernel 5.0.0-15). This involves
a larger number of TLB invalidations and address resolutions, i.e.,
the situations that may see a performance penalty. For process cre-
ation, we do not encounter any overhead. Both with and without
No Mitigation
Mitigation
4
5
9
,
3
9
5
9
,
3
3
2
2
,
3
4
2
2
,
3
4
3
1
,
7
2
3
1
,
7
8
5
4
,
3
0
7
4
,
3
1
6
5
,
2
2
5
5
,
2
1
7
9
,
1
0
8
9
,
1
e
m
i
t
n
u
R
2
9
1 7
4
3
8
0
2 8
4
3
3
0
5
3
0
5
7
0
4
7
0
4
9
1
4
9
6
4
4
4
5
5
4
5
4
9
2
3
9
2
7
7
2
4
7
2
perlbench mcf