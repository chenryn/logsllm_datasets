title:Secure Distribution of Events in Content-Based Publish Subscribe Systems
author:Lukasz Opyrchal and
Atul Prakash
USENIX Association
Proceedings of the
10th USENIX Security
Symposium
Washington, D.C., USA
August 13–17, 2001
© 2001 by The USENIX Association
Phone: 1 510 528 8649
FAX: 1 510 548 5738
THE ADVANCED COMPUTING SYSTEMS ASSOCIATION
All Rights Reserved
Email: PI:EMAIL
For more information about the USENIX Association:
WWW: http://www.usenix.org
Rights to individual papers remain with the author or the author's employer.
 Permission is granted for noncommercial reproduction of the work for educational or research purposes.
This copyright notice must be included in the reproduced paper. USENIX acknowledges all trademarks herein.
Secure Distribution of Events in Content-Based Publish Subscribe Systems 
Lukasz Opyrchal and Atul Prakash 
Electrical Engineering and Computer Science Department 
University of Michigan 
Ann Arbor, MI 48109-2122 
{lukasz,aprakash}@eecs.umich.edu 
Abstract 
Content-based publish-subscribe systems are an emerging paradigm for building a range of distributed applications. 
A  specific  problem  in  content-based  systems  is  the  secure  distribution  of  events  to  clients  subscribing  to  those 
events.    In  content-based  systems,  every  event  can  potentially  have  a  different  set  of  interested  subscribers.  To 
provide confidentiality guarantee, we would like to encrypt messages so that only interested subscribers can read the 
message. In the worst case, for n clients, there can be 2n subgroups, and each event can go to a potentially different 
subgroup. A major problem is managing subgroup keys so that the number of encryptions required per event can be 
kept low. We first show the difficulties in applying existing group key management techniques to addressing the 
problem. We then propose and compare a number of approaches to reduce the number of encryptions and to increase 
message throughput.  We present analytical analysis of described algorithms as well as simulation results. 
1 
Introduction 
Many  of today’s Internet applications require 
high  scalability  as  well  as  strict  security  guarantees.  
This new breed of applications includes large wireless 
delivery services with thousands to millions of clients, 
inter-enterprise supply-chain management applications, 
financial  applications,  workflow  applications,  and 
network management. 
they  want 
is  publish-subscribe  [B93]. 
Messaging technology has been introduced to 
create  much  more  flexible  and  scalable  distributed 
systems.  An  emerging  paradigm  of  messaging 
technology 
  In  such 
systems,  customers (or subscribers) specify the type of 
content 
to  receive  via  subscriptions.  
Publishers publish messages (events), and the publish-
subscribe  system  delivers  them  only  to  the  interested 
subscribers.    Publishers  are  often  decoupled  from 
subscribers,  creating  more  scalable  solutions.    Figure 
1shows a typical publish-subscribe system. Events may 
be  delivered  via  intermediate  brokers,  who  determine 
the set of subscribers that an event should be delivered 
to. Decoupling of publishers and subscribers works well 
for  increasing  scalability  but,  as we will see, makes it 
difficult to develop secure solutions. 
  This  work  is  supported  in  part  by  the  IBM  Research  Partnership 
Award  and  by  the  Defense  Advanced  Research  Projects  Agency 
(DARPA)  and  Air  Force  Research  Laboratory,  Air  Force  Materiel 
Command,  USAF,  under  agreement  number  F30602-00-2-0508.  The 
U.S.  Government  is  authorized  to  reproduce  and  distribute  reprints 
for  Governmental  purposes  notwithstanding  any  copyright  annotation 
thereon.  The  views  and  conclusions  contained  herein  are  those  of  the 
authors  and  should  not  be  interpreted  as  necessarily  representing  the 
official  policies  or  endorsements,  either  expressed  or  implied,  of 
DARPA, 
the  U.S. 
Government. 
the  Air  Force  Research  Laboratory,  or 
The  earliest  publish-subscribe  systems  used 
subject-based  subscription  [B93,  TIBCO].    In  such 
systems,  every  message  is  labeled  by  the  publisher  as 
belonging to one of a fixed set of subjects (also known 
as  groups,  channels,  or  topics).  Subscribers subscribe 
to all the messages within a particular subject or set of 
subjects.    Strength  of  this  approach is the potential to 
easily  leverage  group-based  multicast  techniques  to 
provide scalability and performance, by assigning each 
subject 
  In  fact,  group 
communication  can  be considered to be a special case 
of  subject-based  subscription  where  the  subject  is  the 
name  of  the  group.  A  significant  restriction  with 
subject-based publish-subscribe is that the selectivity of 
subscriptions is limited to the predefined subjects. 
to  a  multicast  group. 
An  emerging  alternative 
to  subject-based 
systems  is  content-based  messaging  systems [BCM99, 
C98,  CDF,  GKP99,  KR95,  MS97,  SA97].    These 
systems  support  an  event  schema  defining  the  type  of 
information  contained  in  each  event  (message).    For 
example, applications interested in stock trades may use 
the  event  schema  [issue:  string,  price: 
dollar,  volume:  integer].    A  content-based 
subscription  is  a  predicate  against  the  event  schema, 
such  as  (issue  =  ”IBM”  &  price   1000).  Only events that satisfy (match) 
the  subscription  predicate  are  delivered 
the 
subscriber. 
to 
With  content-based  subscription,  subscribers 
have the added flexibility of choosing filtering criteria 
along  multiple  dimensions,  without  requiring  pre-
definition of subjects.  In the stock trading example, a 
subject-based subscriber could be forced to select trades 
by  issue  name  because  those  are  the  only  subjects 
available.  In contrast, a content-based subscriber is free 
Client
Client
Client
Broker
Publish-Subscribe System
Broker
Broker
Client
Client
Fig. 1: An example of a publish-subscribe system. 
Client
Publisher
to use any orthogonal criterion, such as volume, or 
indeed a predicate on any collection of criteria, such as 
issue, price, and volume.   
The applications listed above require different 
security  guarantees.    For  example,  an  application 
distributing  premium  stock 
reports  may  require 
confidentiality  to  make  sure  that  only  authorized 
(paying) subscribers can access the data.  Integrity may 
be  required  to  ensure  that  reports  have  not  been 
modified  in  transit  from  publishers  to  subscribers and 
sender  authenticity  to  make  sure  that  fake  reports are 
not  sent  by  third  parties.    The  lack  of  those  security 
guarantees in content-based systems has prevented their 
wider use even in applications that could greatly benefit 
from content-based subscriptions.   
efficient 
The  fact  that  in  content-based  systems  every 
event  can  potentially  go  to  a  different  subset  of 
subscribers  makes 
implementation  of 
confidentiality  guarantees  difficult.    There  are  2N 
possible subsets, where N is the number of subscribers. 
With  thousands  (tens  of  thousands  or  hundreds  of 
thousands) of subscribers it is infeasible to setup static 
security groups for every possible subset.  Even the use 
of  a 
trusted 
servers/brokers to reduce the complexity can leave each 
broker  with  hundreds  or  thousands  of  subscribers, 
making the number of possible groups too large.   
limited  number  of 
intermediate 
This  paper  presents  and  compares  several 
algorithms for secure delivery of events from a broker 
to its subscribers.  Section 2 states the problem in detail.  
Section  3  presents  related  work.  Section  4  explores  a 
number  of  approaches  based  on  the  idea  of using and 
caching  multiple  subgroup  keys  to  address  the  secure 
end-point  delivery  problem.  We  described  the  use  of 
these  schemes  and  also  present  theoretical  analysis  of 
many  of  these  approaches.    Section  5  describes  our 
simulation  setup,  experiment  results  and  analysis  of 
those  results.    Section  6  discusses  the  results  and 
presents  some  theoretical  bounds  on  the  problem. 
Finally,  Section  7  presents  conclusions  and  directions 
for future work. 
2  Problem Description 
A  messaging  system  routes  events  from  a 
publisher  to  end-point  brokers.    The  brokers  then 
distribute those events to their subscribers.  In content-
based  systems,  each message could potentially go to a 
different  set  of  subscribers  (see  Fig.  2).    The  picture 
shows two events (E1 and E2) delivered by the delivery 
system  to  the  broker.    Each  event  is  then  sent  to  a 
different subset of subscribers connected to the broker. 
We want to add certain security guarantees to content-
based systems.  The security requirement that we focus 
on  in  this  paper  is  confidentiality.    The  system  must 
guarantee that only authorized subscribers can read an 
event.    Data  must  be  protected  from  other  (not 
authorized) subscribers as well as other malicious users 
on the network.   
This  paper  describes  issues  and  solutions  for 
only  a  subset  of  the  complex  security  problem  in  an 
entire  publish-subscribe  system.    To  provide  event 
confidentiality, we assume that events are protected on 
their way from a publisher, through the delivery system, 
to the end-point brokers.  In this paper, we focus on the 
data security on the last leg from end-point brokers to 
subscribers  in  an  efficient way when each broker may 
have  a  large  number  of  clients.    In  this  paper,  we 
assume  that  all  brokers  are  trusted  and  that  all 
subscribers and publishers are properly authenticated to 
the system.  All subscribers and publishers also have an 
individual  symmetric  pair-key  shared  only  with  their 
broker  (generated  during  the  authentication  process). 
The issues of security in transit between publishers and 
end-point brokers as well as the issue of broker trust are 
the subjects of our future work.  
 The publish-subscribe system allows dynamic 
access  control  to  the  events.    This  means  that  a 
predicate can be used at event publish time to check the 
set  of  subscribers  who  are  authorized  to  receive  the 
Broker 
Information 
Delivery System 
Subscribers 
matching E2 
E1 
E2 
Subscribers 
matching E1 
subscriber 
E1, E2     events 
Fig. 2: Secure end-point delivery problem. 
event.  It is possible for a subscriber to be interested in 
an event (have a subscription for a particular event) but 
not  be  authorized  to  read  that  event  (because  of 
restrictions from a publisher).  To simplify discussion, 
we  assume  that  all  interested  subscribers  are  also 
authorized 
is 
authorized to read all events it subscribes to.  Dynamic 
access  control  makes  it  infeasible  to  set  up  static 
security  groups  as  each  event  can  potentially  have  a 
different  set  of  authorized  subscribers  (as  well  as  a 
different set of interested subscribers).  
subscribers, 
i.e.,  each 
subscriber 
scenarios --- (1) where events go to random subgroups 
of  subscribers  and  (2)  where  there  are  some  popular 
subgroups  and  some  unpopular  subgroups. 
  The 
simplest solution is to encrypt each event separately for 
every  subscriber  receiving  the  event.    This  solution 
does not scale to large, high volume systems due to the 
throughput  reduction  of  encryption  algorithms  like 
DES.    This  paper  explores  a  number  of  dynamic 
caching  approaches 
the  number  of 
encryptions and to increase message throughput. 
reduce 
to 
Given the above restrictions and assumptions, 
providing confidentiality in content-based systems in an 
efficient  way  is  non-trivial.    Since  every  event  can 
potentially  go  to a different subset of subscribers, it is 
infeasible (for large numbers of clients) to set-up static 
security  groups.      The  simplest  solution  would  be  to 
encrypt  each  event  separately  for  every  subscriber 
receiving  the  event (using individual subscriber keys).  
For large systems where each broker has thousands of 
subscribers, this could mean hundreds or thousands of 
encryptions  per  event.   An additional performance hit 
involves  changing  keys  for  each  of  the  encryptions, 
which  drastically  slows  down  encryption  algorithms 
like  DES  [Pub97].    We  tested  this  by  encrypting  a 
random  64-bit  piece  of  data  with  DES.  We  compared 
throughput when continuously encrypting with one key 
and when using 500 different keys on a Pentium III 550 
Mhz  machine  running  Red  Hat  Linux.    The  results 
showed that changing keys for each subscription results 
in  throughput  as  low  as  10%  of  the  total  throughput 
when using only one key. 
In  short,  the  problem  presented  here  is  to 
preserve  confidentiality  using  small  number  of 
encryptions  while  distributing  events  from  end-point 
broker  to  its  subscribers.    Due  to  lack  of  good 
workloads  in  this  area,  we  consider  two  extreme 
3  Related Work 
Until  this  point,  the  problem  of  efficiently 
delivering  events  in  a  confidential  manner  to  only 
interested  subscribers  has  not  been  addressed  in 
content-based  systems.    However,  a  related and active 
area  of  research  is  secure  group  communication.  
Specifically,  group  key  management  services  are 
closely related to the problem described above.  Secure 
group  communication  systems  are  usually  meant  to 
provide  secure  channel  for  the  exchange  of  data 
between  group  members.    Secure  groups  are  often 
identified  by  a  session  key,  known  to  all  group 
members, which is used to encrypt all data sent to the 
group.  Key management services are used to facilitate 
member joins and leaves (including expulsions) as well 
as  periodic  re-keying  to  ensure  validity  of  the  session 
key.   
A  related  area  of  work 
is  research  on 
broadcast  encryption.    It  was  first  introduced  by  Fiat 
and  Naor  [FN93]  in  the  context  of  pay-TV.    The 
authors  presented  methods  for  securely  broadcasting 
information  such  that  only  a  selected  subset  of  users 
can decrypt the information while coalitions of up to k 
unprivileged  users  learn  nothing. 
  Unfortunately, 
schemes  presented  in  [FN93]  as  well  as  in extensions 
found  in  [BC94,  BFMS98,  SvT98]  require  a  large 
numbers  of  keys  to  be  stored  at  the  receivers  or  large 
broadcast messages.  Another problem in the context of 
secure  content-based  systems  is  that  coalition  of more 
than k unprivileged users can decrypt the information.  
Luby and Staddon [LS98] studied the trade-off between 
the  number  of  keys  stored  in  the  receivers  and  the 
transmission  length  in  large  and  small  target  receiver 
sets.  They prove a lower bound that shows that either 
the  transmission  must  be  very  long  or  a  prohibitive 
number  of  keys  must  be  stored  in  the  receivers.    An 
extension proposed in [ASW00] decreases the number 
of  keys  required  and  the  length  of  transmissions  by 
relaxing  the  target  set.    It  allows  a  small  fraction  of 
users  outside  the  target  set  to  be  able  to  decrypt  the 
information.  Such scheme may work well for pay-TV 
and  similar  applications  but  is  unacceptable  when 
confidentiality  of  broadcast 
information  must  be 
preserved. 
The  problem  of  secure  event  delivery  from 
end-point  brokers  to  subscribers  can  be  cast  as  group 
communication with very dynamic membership. Since 
in  content-based  systems  each  event  goes 
to  a 
potentially different and arbitrary subset of subscribers, 
it is likely that two events arriving one after another go 
to  completely  different  subsets  of  subscribers.    If  a 
group  communication  system  were  used  to  distribute 
events from a broker to subscribers, a group would have 
to  be  reconstructed  (possibly  entirely)  for  every  event 
arriving at the broker.  We describe a number of group 
key management approaches and show that none of the 
existing  algorithms  was  designed  to  support  dynamic 
membership  changes 
in  content-based 
systems.    The  key  management  techniques  for  group 
communication  are  likely  to  have  a  large  overhead 
when used in content-based system context. 
that  occur 
A simple group key distribution method would 
be to create a pair-key between each subscriber and its 
broker.  Whenever  there  is  a  membership  change,  the 
new session key is distributed to each member using its 
pair key. If an event requires a new subgroup of size N, 
this requires N encryptions to send a new session key.  
Since  membership 
in  content-based  systems  can 
potentially  change  for  every  event,    this  cost  can  be 
high for large groups. 
One  of  the  first  attempts  at  standardizing 
secure  multicast,  GKMP  [HM97a][HM97b]  defines  a 
protocol  under  which  group  session  keys  can  be 
efficiently distributed.  In GKMP, after being accepted 
into  the  group,  newly  joined  members  receive  a  Key 
Encrypting  Key  (KEK)  under  which  all  subsequent 
session  keys  are  delivered.    A  limitation  of  this 
approach  is  that  that  there  is  no backward or forward 
secrecy.  Anyone  with  the  possession  of  the  KEK  can 
potentially  access  all  the  past and future session keys. 
The  only  way  in  GKMP  to  provide  backward  and 
forward  secrecy  is  to  reform  the  group  with  a  new 
KEK. Obviously, the GKMP protocol does not support 
confidentiality  requirements  of  content-based  systems 
where  events  need  to  be  protected  from  all  but 
interested subscribers for that specific event. 
Mittra’s  Iolus  system  [M97]  attempts 
to 
overcome the problems in scalability of key distribution 
by  introducing  locally  maintained  subgroups.    Each 
subgroup  maintains  its  own  session  key,  which  is 
modified  on  membership  events. 
  Subgroups  are 
arranged  in  a  tree  hierarchy.    This  solution  is  more 
scalable than the simple group key distribution method 
for membership changes. And, in fact, our approach of 
assigning  subscribers  to  brokers  is  similar  to  the 
approach  of  subgrouping  in  Iolus.  However,  in  the 
worst  case,  note  that  the  session  keys  for  all  the 
subgroups may need to be changed for each event. And 
changing  the  key  in  a  subgroup  could  potentially 
require linear number of encryptions in the number of 
subscribers within each subgroup. 
irrespective  of 
The  cost  of  changing  keys  in  Iolus  within 
subgroups  can  be 
reduced  by  making  smaller 
subgroups.  In  the  extreme  case,  for  example,  a  small 
fixed number, K, of subscribers can be assigned to each 
subgroup, 
total  number  of 
subscribers, N.  In that case, however, one ends up with 
a large number of intermediate servers (N/K) who must 
be trusted with the content of all the events sent via the 
system. We would like to explore solutions that reduce 
the number of servers we trust with event contents to as 
low values as feasible.  
the 
an 
provide 
Approaches  based  on  logical  key  hierarchies 
[WHA98][WGL98][YL00] 
efficient 
approach to achieving scalable, secure key distribution 
on  membership  changes  in  group  communication 
systems.    A  logical  key  hierarchy  (LKH)  is  singly 
rooted  d-ary  tree  of  cryptographic  keys  (where  d  is 
usually  2,  but  can  be  arbitrary).    A  trusted  session 
leader assigns the interior node keys, and each leaf node 
key  is  a  secret  key  shared  between  the  session  leader 
and  a  single  member.    Once  the  group  has  been 
established, each member knows all the keys along the 
path from their leaf node key and the root.  As changes 
in  membership  occur,  re-keying  is  performed  by 
replacing  only  those  keys  known  (required)  by  the 
leaving (joining) member. It can be shown that the total 
cost  of  re-keying  in  key  hierarchies  in  response  to  a 
single  join  or  leave  scales  logarithmically  with  group 
size [WHA98][WGL98]. If the change in membership 
from  the  initial  tree  is  O(N),  as  is  the  case  with  a 
random group change, it may require up to O(N log(N)) 
number  of  encryptions  if  members  are  removed  (or 
added)  individually.  We  consider  that  too  high.  If the 
tree is entirely reconstituted for each event being sent to 
a  subgroup  of  size  k,  the  number  of  encryptions 
required per event is at least k, which can still be large. 
Another  approach  based  on  LKH  uses  the 
intermediate keys of the full tree.  Instead of rebuilding 
the tree to represent the appropriate subgroup for each 
event,  the  tree  can  be  searched  to  find  the  smallest 
subset  of  intermediate  keys  that  cover  all  subscribers 
interested in the particular event.  The search process is 
O(N)  but  the  number  of  encryptions  can  be  much 
smaller than in the tree rebuilding case.  We compare 
our algorithms to this scheme in Section 5. 
The  VersaKey  system  [WCS99]  extends  the 
LKH algorithm by converting the key hierarchy into a 
table of keys, based on binary digits in the identifiers of 
the members.  In this scheme, in the case of joins, no 
key  distribution  to  current  members  is  necessary.  
However,  the  VersaKey  approach  is  vulnerable  to 