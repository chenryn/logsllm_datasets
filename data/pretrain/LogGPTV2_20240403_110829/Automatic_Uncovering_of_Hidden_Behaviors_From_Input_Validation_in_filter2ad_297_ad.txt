### System Configuration
The other system runs Ubuntu 16.04 with an AMD EPYC 7251 CPU and 256 GB of memory. This system is responsible for extracting pre-installed applications from Samsung firmware images, downloading applications from alternative markets, and executing INPUTSCOPE to analyze these applications.

### Evaluation Results
INPUTSCOPE took approximately 24 days to identify mobile applications containing backdoors or blacklist secrets among the 150,000 mobile apps analyzed. Specifically, as shown in Table III, we identified 114,797 mobile apps that perform equivalence checking. An app can detect whether a user input is empty by simply checking if it is equivalent to an empty string. Among these, 34,958 apps only perform empty-only checks and were excluded from further analysis. In the remaining 79,839 apps, INPUTSCOPE identified 4,028 apps containing blacklist secrets and 12,706 apps containing backdoor secrets. Additionally, 7,584 apps contained secret access keys, 501 apps embedded master passwords, and 6,013 apps had secret commands. These security risks were generally consistent across all data sources. Specifically, the prevalence of backdoor secrets in apps was 6.86%, 5.32%, and 15.96% on the Google Play store, the alternative market, and pre-installed apps, respectively. The percentage of apps containing blacklist secrets in these three data sources was 1.98%, 4.46%, and 3.87%.

### Detailed Analysis
To better understand the implications of these findings, we examined two key questions: 
1. What kind of advantage could be taken by using the uncovered hidden behaviors such as backdoors?
2. What are the detailed items in a blacklist, and why are they blocked?

We manually inspected the top apps in each category and present a detailed security analysis. Note that the top apps from Google Play and Baidu Market can be easily identified based on their download numbers, but we cannot identify the top apps from the pre-installed dataset since they are all installed when users purchase the phone and likely have the same distribution. Therefore, we focus on the apps from the app stores in our case studies, though similar patterns were observed in pre-installed apps.

#### Hidden Backdoor Behaviors
INPUTSCOPE discovered three types of input-triggered hidden behaviors: (i) secret access keys, (ii) master passwords, and (iii) secret commands. We present a detailed analysis for each category below.

**1. Hidden Behaviors Triggered by Secret Access Keys**
To understand why such hidden behaviors exist, we manually inspected 30 randomly selected apps with more than one million installs and summarized the three most common types of usage. The detailed results of the top five apps for each usage, totaling 15 apps, are presented in Table IV. The first column describes the type of usage, the next three columns provide the number of downloads, its category, and its package name, respectively, and the last column shows the identified secret access key for each app. The three types of usages are:
- **Logging into Administrator Interfaces:** Access keys that allow logging into an app’s administrator interface, which is invisible to normal users and allows configuration changes. For example, a popular sports live streaming app with over 5 million installs allows anyone to log in as an administrator with the access key “U***S” from the hidden administrator interface in its “Settings” menu.
- **Resetting Arbitrary User Passwords:** Access keys that trigger the hidden behavior of recovering or resetting normal users’ passwords. For instance, a screen-locking app with over 5 million installs allows attackers to reset the password by providing the code 0**9* after multiple failed login attempts.
- **Bypassing Advanced Service Payment:** Access keys that can purchase in-app advanced services for free. For example, a popular translation app with over one million installs allows removing advertisements for free using the access key q***d, bypassing the $12.99 fee.

From these case studies, it is evident that user input validations in apps can expose secret access keys, leading to various attacks against both users and service providers. Surprisingly, these mistakes occur even in popular apps with millions of installs, and the same group of developers often makes the same mistake across their apps.

**2. Hidden Behaviors Triggered by Master Passwords**
INPUTSCOPE identified 501 master passwords among the tested apps. We randomly selected 10 popular apps to understand the hidden behaviors triggered by these master passwords, and the results are presented in Table V. A master password can be used to hijack or override another target, making it extremely dangerous. For example, a security app with over 10 million installs, designed to help users lock their smartphones remotely, contains a master password 9***8 to bypass its protection on privacy apps set to be locked when the phone is lost. Another example is a diary app where the password lv**3 can unlock the secret diary, even though the app displays "wrong password."

**3. Hidden Behaviors Triggered by Secret Commands**
INPUTSCOPE identified 6,013 mobile apps containing secret commands. We manually inspected the commands and present the detailed results of the top identified mobile apps in Table VI. The table includes the number of installs, category, package name, and the secret commands for each app.

### Conclusion
These detailed case studies highlight the potential security risks associated with hidden behaviors in mobile applications. The exposure of secret access keys, master passwords, and secret commands can lead to various attacks, affecting both users and service providers. It is crucial for developers to implement robust input validation and security measures to prevent such vulnerabilities.