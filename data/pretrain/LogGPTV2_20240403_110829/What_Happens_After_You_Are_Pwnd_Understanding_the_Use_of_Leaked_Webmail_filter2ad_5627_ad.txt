the advertised midpoint than credentials that are posted without any location information.
cybercriminals on paste sites exhibit more location mal-
leability, that is, masquerading their origins of accesses
to appear closer to the advertised location, when pro-
vided. It also shows that cybercriminals on the studied
forums are less sophisticated, or care less than the ones
on paste sites.
Statistical signiﬁcance. As we explained, Figures 6a
and 6b show that accesses to leaked accounts happen
closer to advertised locations if this information is in-
cluded in the leak. To conﬁrm the statistical signiﬁ-
cance of this ﬁnding, we performed a Cramer Von Mises
test [15]. The Anderson version [8] of this test is used
to understand if two vectors of values do likely have
the same statistical distribution or not. The p-value
has to be under 0.01 to let us state that it is possible
to reject the null hypothesis (i.e., that the two vectors
of distances have the same distribution), otherwise it
is not possible to state with statistical signiﬁcance that
the two distance vectors come from diﬀerent distribu-
tions. The p-value from the test on paste sites vec-
tors (p-values of 0.0017415 for UK location information
versus no location and 0.0000007 for US location infor-
mation versus no location) allows us to reject the null
hypothesis, thus stating that the two vectors come from
diﬀerent distributions while we cannot say the same ob-
serving the p-values for the tests on forum vectors (p-
values of 0.272883 for the UK case and 0.272011 for the
US one). Therefore, we can conclusively state that the
statistical test proves that criminals using paste sites
connect from closer locations when location information
is provided along with the leaked credentials. We can-
not reach that conclusion in the case of accounts leaked
to underground forums, although Figures 6a and 6b in-
dicate that there are some location diﬀerences in this
case too.
4.3.5 What are “gold diggers” looking for?
Cybercriminals compromise online accounts due to
the inherent value of those accounts. As a result, they
assess accounts to decide how valuable they are, and de-
cide exactly what to do with such accounts. We decided
to study the words that they searched for in the honey
accounts, in order to understand and potentially char-
acterize anomalous searches in the accounts. A limiting
factor in this case was the fact that we did not have ac-
cess to search logs of the honey accounts, but only to the
content of the emails that were opened. To overcome
this limitation, we employed Term Frequency–Inverse
Document Frequency (TF-IDF). TF-IDF is used to rank
words in a corpus by importance. As a result we re-
Median-dist-pastebin-noloc-CENT-UKMedian-dist-forum-noloc-CENT-UKMedian-dist-pastebin-UKMedian-dist-forum-UKMedian-dist-pastebin-noloc-CENT-USMedian-dist-forum-noloc-CENT-USMedian-dist-pastebin-USMedian-dist-forum-USSearched words
results
bitcoin
family
seller
localbitcoins
account
payment
bitcoins
below
listed
T F IDFR
0.2250
0.1904
0.1624
0.1333
0.1009
0.1114
0.0982
0.0768
0.1236
0.0858
T F IDFA
0.0127
0.0
0.0200
0.0037
0.0
0.0247
0.0157
0.0
0.0496
0.0207
T F IDFR − T F IDFA Common words
transfer
please
original
company
0.2122
0.1904
0.1423
0.1296
0.1009 would
energy
0.0866
information
0.0824
0.0768
about
email
0.0740
0.0651
power
T F IDFR
0.2795
0.2116
0.1387
0.0420
0.0864
0.0618
0.0985
0.1342
0.1402
0.0462
T F IDFA
0.2949
0.2608
0.1540
0.1531
0.1493
0.1471
0.1308
0.1226
0.1196
0.1175
T F IDFR − T F IDFA
-0.0154
-0.0493
-0.0154
-0.1111
-0.0630
-0.0853
-0.0323
0.0116
0.0207
-0.0713
Table 2: List of top 10 words by T F IDFR − T F IDFA (on the left) and list of top 10 words by T F IDFA (on the
right). The words on the left are the ones that have the highest diﬀerence in importance between the emails opened
by attackers and the emails in the entire corpus. For this reason, they are the words that attackers most likely
searched for when looking for sensitive information in the stolen accounts. The words on the right, on the other
hand, are the ones that have the highest importance in the entire corpus.
lied on TF-IDF to infer the words that cybercriminals
searched for in the honey accounts. TF-IDF is a prod-
uct of two metrics, namely Term Frequency (TF) and
Inverse Document Frequency (IDF). The idea is that we
can infer the words that cybercriminals searched for, by
comparing the important words in the emails opened by
cybercriminals to the important words in all emails in
the decoy accounts.
In its simplest form, TF is a measure of how fre-
quently term t is found in document d, as shown in
Equation 1. IDF is a logarithmic scaling of the fraction
of the number of documents containing term t, as shown
in Equation 2 where D is the set of all documents in the
corpus, N is the total number of documents in the cor-
pus, |d ∈ D : t ∈ d| is the number of documents in D,
that contain term t. Once TF and IDF are obtained,
TF-IDF is computed by multiplying TF and IDF, as
shown in Equation 3.
tf (t, d) = ft,d
idf (t, D) = log
N
|d ∈ D : t ∈ d|
tf idf (t, d, D) = tf (t, d) × idf (t, D)
(1)
(2)
(3)
The output of TF-IDF is a weighted metric that ranges
between 0 and 1. The closer the weighted value is to 1,
the more important the term is in the corpus.
We evaluated TF-IDF on all terms in a corpus of
text comprising two documents, namely, all emails dA
in the honey accounts, and all emails dR opened by
the attackers. The intuition is that the words that
have a large importance in the emails that have been
opened by a criminal, but have a lower importance in
the overall dataset, are likely to be keywords that the
attackers searched for in the Gmail account. We pre-
processed the corpus by ﬁltering out all words that have
less than 5 characters, and removing all known header-
related words, for instance “delivered” and “charset,”
honey email handles, and also removing signaling infor-
mation that our monitoring infrastructure introduced
into the emails. After running TF-IDF on all remaining
terms in the corpus, we obtained their TF-IDF values
as vectors T F IDFA and T F IDFR, the TF-IDF val-
ues of all terms in the corpus [dA, dR]. We proceeded
to compute the vector T F IDFR − T F IDFA. The top
10 words by T F IDFR − T F IDFA, compared to the
top 10 words by T F IDFA are presented in Table 2.
Words that have T F IDFR values that are higher than
T F IDFA will rank higher in the list, and those are the
words that the cybercriminals likely searched for.
As seen in Table 2, the top 10 important words by
T F IDFR − T F IDFA are sensitive words, such as “bit-
coin,”“family,” and “payment.” Comparing these words
with the most important words in the entire corpus re-
veals the indication that attackers likely searched for
sensitive information, especially ﬁnancial information.
In addition, words with the highest importance in the
entire corpus (for example, “company” and “energy”),
shown in the right side of Table 2, have much lower im-
portance in the emails opened by cybercriminals, and
most of them have negative values in T F IDFR−T F IDFA.
This is a strong indicator that the emails opened in the
honey accounts were not opened at random, but were
the result of searches for sensitive information.
Originally, the Enron dataset had no “bitcoin” term.
However, that term was introduced into the opened
emails document dR, through the actions of one of the
cybercriminals that accessed some of the honey accounts.
The cybercriminal attempted to send blackmail mes-
sages from some of our honey accounts to Ashley Madi-
son scandal victims [3], requesting ransoms in bitcoin,
in exchange for silence.
In the process, many draft
emails containing information about “bitcoin” were cre-
ated and abandoned by the cybercriminal, and other
cybercriminals opened them during later accesses. That
way, our monitoring infrastructure picked up “bitcoin”
related terms, and they rank high in Table 2, showing
that cybercriminals showed a lot of interest in those
emails.
4.4 Interesting case studies
5. DISCUSSION
In this section, we present some interesting case stud-
ies that we encountered during our experiments. They
help to shed further light into actions that cybercrimi-
nals take on compromised webmail accounts.
Three of the honey accounts were used by an attacker
to send multiple blackmail messages to some victims of
the Ashley Madison scandal. The blackmailer threat-
ened to expose the victims, unless they made some pay-
ments in bitcoin to a speciﬁed bitcoin wallet. Tutorials
on how to make bitcoin payments were also included in
the messages. The blackmailer created and abandoned
many drafts emails targeted at more Ashley Madison
victims, which as we have already mentioned some other
visitors to the accounts opened, thus contributing to
the opened emails that our monitoring infrastructure
recorded.
Two of the honey accounts received notiﬁcation emails
about the hidden Google Apps Script in both honey
accounts “using too much computer time.” The noti-
ﬁcations were opened by an attacker, and we received
notiﬁcations about the opening actions.
Finally, an attacker registered on an carding forum
using one of the honey accounts as registration email
address. As a result, registration conﬁrmation infor-
mation was sent to the honey account This shows that
some of the accounts were used as stepping stones by
cybercriminals to perform further illicit activity.
4.5 Sophistication of attackers
From the accesses we recorded in the honey accounts,
we identiﬁed 3 peculiar behaviors of cybercriminals that
indicate their level of sophistication, namely, conﬁgu-
ration hiding – for instance by hiding user agent in-
formation, location ﬁlter evading – by connecting from
locations close to the advertised decoy location if pro-
vided, and stealthiness – avoiding performing clearly
malicious actions such as hijacking and spamming. At-
tackers accessing the diﬀerent groups of honey accounts
exhibit diﬀerent types of sophistication. Those access-
ing accounts leaked through malware are stealthier than
others – they don’t hijack the accounts, and they don’t
send spam from them. They also access the accounts
through Tor, and they hide their system conﬁguration,
for instance, their web browser is not ﬁngerprintable by
Google. Attackers accessing accounts leaked on paste
sites tend to connect from locations closer to the ones
speciﬁed as decoy locations in the leaked account. They
do this in a bid to evade detection. Attackers access-
ing accounts leaked in underground forums do not make
signiﬁcant attempts to stay stealthy or to connect from
closer locations. These diﬀerences in sophistication could
be used to characterize attacker behavior in future work.
In this section, we discuss the implications of the
ﬁndings we made in this paper. First, we talk about
what our ﬁndings mean for current mitigation tech-
niques against compromised online service accounts, and
how they could be used to devise better defenses. Then,
we talk about some limitations of our method. Finally,
we present some ideas for future work.
Implications of our ﬁndings. In this paper, we made
multiple ﬁndings that provide the research community
with a better understanding of what happens when on-
line accounts get compromised. In particular, we dis-
covered that if attackers are provided with location in-
formation about the online accounts, they then tend
to connect from places that are closer to those adver-
tised locations. We believe that this is an attempt to
evade current security mechanisms employed by online
services to discover suspicious logins. Such systems of-
ten rely on the origin of logins, to assess how suspicious
those login attempts are. Our ﬁndings show that there
is an arms race going on, with attackers attempting
to actively evade the location-based anomaly detection
systems employed by Google. We also observed that
many accesses were received through Tor exit nodes, so
it is hard to determine the exact origins of logins. This
problem shows the importance of defense in depth in
protecting online systems, in which multiple detection
systems are employed at the same time to identify and
block miscreants.
Despite conﬁrming existing evasion techniques in use
by cybercriminals, our experiments also highlighted in-
teresting behaviors that could be used to develop eﬀec-
tive systems to detect malicious activity. For example,
our observations about the words searched for by the cy-
bercriminals show that behavioral modeling could work
in identifying anomalous behavior in online accounts.
Anomaly detection systems could be trained adaptively
on words being searched for by the legitimate account