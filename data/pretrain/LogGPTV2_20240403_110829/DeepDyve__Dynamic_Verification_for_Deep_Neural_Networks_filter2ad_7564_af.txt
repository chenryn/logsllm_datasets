DeepDyve brings latency and reduces throughput due to recompu-
tation, which needs to be considered when performing real-time
tasks. For example, there is about 1% of throughput loss for the
above DeepDyve model constructed on the GTSRB dataset. This
overhead can be reduced when the consistency rate between the
checker DNN and the task DNN models increases.
Also, our current evaluation is only on the 8-bit integer (INT-8)
data representation. One reason is that INT-8 is a popular data
type and supported by well known deep learning frameworks and
tool-chains, such as Pytorh 4, Tensorflow5, NVIDIA®TensorRD 6,
and Xilinx®DNNDK 7. Popular hardware platforms like TPU [15]
support integer operations as well. The second reason is that the
Pytorch 1.3 (the one we use) and the code from BFA attack 8 only
supports INT-8 quantization in its current version. We shall extend
our work to study the impact of different data types in the future.
4https://pytorch.org/docs/stable/quantization.html
5https://www.tensorflow.org/lite/performance/post_training_quantization
6https://developer.nvidia.com/tensorrt
7https://www.xilinx.com/products/design-tools/ai-inference/edge-ai-
platform.html#dnndk
8https://github.com/elliothe/BFA
8 RELATED WORKS
DNNs have become an enabling technology for many safety-critical
applications, and hence there is a growing research interest for
fault-tolerant DNN designs.
In the literature, some works focused on improving fault-tolerance
of DNN systems built with unreliable resistive random-access mem-
ory (RRAM) [3, 25, 41], an emerging device with huge energy ef-
ficiency benefits. However, this technology is still in its infancy
and is not applicable for safety-critical AI applications. Existing
fault-tolerant solutions for DNN systems built with conventional
CMOS devices can be categorized as passive solutions or active
solutions.
Passive fault-tolerant solutions reduce the probability of failure
occurrences for a certain level at the design stage, including fault-
mitigation techniques for the DNN design itself and fault-masking
solutions with redundant circuitries. To be specific, fault-mitigation
techniques include: (i) Resilient training [7, 16, 43, 46], which explic-
itly considers hardware faults during the DNN training phase; (ii)
Resilient architecture design [5, 6, 8, 37], which tries to find an error-
resilient network architecture or inserts redundancies for those
critical elements in the system; (iii) Device hardening [2, 23], which
tries to protect some critical storage elements in the system by
selectively hardening them. The above solutions require significant
design effort, and they usually cannot provide sufficient fault cov-
erage. Fault-masking techniques are conceptually simple. We could
use error-correcting codes (ECC) to protect memory elements [35]
and triple-modular redundancy (TMR) to protect computational
units [29, 42]. However, the corresponding hardware overhead is
exceptionally high.
Active fault-tolerant solutions detect and recover from faults
by re-organizing the system in real-time. To achieve active fault-
tolerance, we need to be able to detect faults online. There are a
few solutions in this direction [23, 24, 38]. Among these techniques,
[23, 38] has small hardware overhead, but their fault detection
capabilities are limited, especially for quantized DNNs; the fault
coverage of the replication-based solution in [24] is comparable to
DeepDyve, but its overhead is much higher.
9 CONCLUSION
In this paper, we proposed DeepDyve, a novel dynamic verifica-
tion technique against fault injection attacks on DNN systems. By
introducing a far simpler and smaller checker DNN into the sys-
tem, DeepDyve significantly outperforms state-of-the-art solutions,
reducing 90% risks at around 10% computational overhead.
ACKNOWLEDGMENTS
This work is supported in part by General Research Fund (GRF)
of Hong Kong Research Grants Council (RGC) under Grant No.
14205018 and No. 14205420, and in part by National Natural Science
Foundation of China (NSFC) under Grant No. 61532017.
REFERENCES
[1] Todd M Austin. 1999. DIVA: A reliable substrate for deep submicron microar-
chitecture design. In Proceedings of the 32nd Annual ACM/IEEE International
Symposium on Microarchitecture (MICRO). IEEE, 196–207.
[2] Arash Azizimazreah, Yongbin Gu, Xiang Gu, and Lizhong Chen. 2018. Tolerating
soft errors in deep learning accelerators with reliable on-chip memory designs.
In IEEE International Conference on Networking, Architecture and Storage (NAS).
IEEE, 1–10.
[3] Lerong Chen, Jiawen Li, Yiran Chen, Qiuping Deng, Jiyuan Shen, Xiaoyao Liang,
and Li Jiang. 2017. Accelerator-friendly neural-network training: Learning varia-
tions and defects in RRAM crossbar. In Proceedings of the Conference on Design,
Automation & Test in Europe (DATE). European Design and Automation Associa-
tion, 19–24.
[4] Yu-Hsin Chen, Tushar Krishna, Joel S Emer, and Vivienne Sze. 2016. Eyeriss:
An energy-efficient reconfigurable accelerator for deep convolutional neural
networks. In IEEE Journal of Solid-State Circuits (JSSC). IEEE, 127–138.
[5] C-T Chiu, Kishan Mehrotra, Chilukuri K Mohan, and Sanjay Ranka. 1993. Ro-
bustness of feedforward neural networks. In IEEE International Conference on
Neural Networks (ICNN). IEEE, 783–788.
[6] L-C Chu and Benjamin W Wah. 1990. Fault tolerant neural networks with hybrid
redundancy. In International Joint Conference on Neural Networks (IJCNN). IEEE,
639–649.
[7] Jiacnao Deng, Yuntan Rang, Zidong Du, Ymg Wang, Huawei Li, Olivier Temam,
Paolo Ienne, David Novo, Xiaowei Li, Yunji Chen, et al. 2015. Retraining-based
timing error mitigation for hardware neural networks. In Design, Automation &
Test in Europe Conference & Exhibition (DATE). IEEE, 593–596.
[8] Fernando Morgado Dias, Rui Borralho, Pedro Fontes, and Ana Antunes. 2010.
FTSET-a software tool for fault tolerance evaluation and improvement. In Neural
Computing and Applications (Neural. Comput. Appl.), Vol. 19. Springer, 701–712.
[9] Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. 2015. Explaining and
Harnessing Adversarial Examples. In 3rd International Conference on Learning
Representations (ICLR). OpenReview.net.
[10] Song Han, Huizi Mao, and William J. Dally. 2016. Deep Compression: Compress-
ing Deep Neural Network with Pruning, Trained Quantization and Huffman
Coding. In 4th International Conference on Learning Representations (ICLR). Open-
Review.net.
[11] Geoffrey Hinton, Oriol Vinyals, and Jeffrey Dean. 2014. Distilling the Knowledge
in a Neural Network. In NIPS Deep Learning and Representation Learning Workshop
(NIPS Workshop). Curran Associates Inc.
[12] Sanghyun Hong, Pietro Frigo, Yiğitcan Kaya, Cristiano Giuffrida, and Tudor
Dumitras,. 2019. Terminal brain damage: Exposing the graceless degradation in
deep neural networks under hardware fault attacks. In 28th {USENIX} Security
Symposium (USENIX Security). USENIX Association, 497–514.
[13] Andrew G Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun
Wang, Tobias Weyand, Marco Andreetto, and Hartwig Adam. 2017. Mobilenets:
Efficient convolutional neural networks for mobile vision applications. arXiv
preprint arXiv:1704.04861 (2017).
[14] ISO. 2016. ISO-26262: Road vehicles – Functional safety. ISO, Geneva, Switzer-
land.
[15] Norman P Jouppi and et al. 2017. In-datacenter performance analysis of a tensor
processing unit. In ACM/IEEE 44th Annual International Symposium on Computer
Architecture (ISCA). IEEE, 1–12.
[16] Sung Kim, Patrick Howe, Thierry Moreau, Armin Alaghi, Luis Ceze, and Visvesh
Sathe. 2018. MATIC: Learning around errors for efficient low-voltage neural net-
work accelerators. In Design, Automation & Test in Europe Conference & Exhibition
(DATE). IEEE, 1–6.
[17] Yoongu Kim, Daly Ross, and et. al. 2014. Flipping bits in memory without
accessing them: An experimental study of DRAM disturbance errors. In ACM/IEEE
41st International Symposium on Computer Architecture (ISCA). IEEE, 361–372.
[18] Raghuraman Krishnamoorthi. 2018. Quantizing deep convolutional networks
for efficient inference: A whitepaper. In arXiv preprint arXiv:1806.08342.
[19] Alex Krizhevsky, Geoffrey Hinton, et al. 2009. Learning multiple layers of features
from tiny images. Technical Report. Citeseer.
[20] Alexey Kurakin, Ian J. Goodfellow, and Samy Bengio. 2017. Adversarial Machine
Learning at Scale. In 5th International Conference on Learning Representations
(ICLR). OpenReview.net.
[21] Ya Le and Xuan Yang. 2015. Tiny imagenet visual recognition challenge. Stanford
CS 231N Course.
[22] Yann LeCun, John S Denker, and Sara A Solla. 1990. Optimal brain damage. In
Advances in neural information processing systems (NIPS). Curran Associates Inc.,
598–605.
[23] Guanpeng Li and et al. 2017. Understanding error propagation in deep learning
neural network (DNN) accelerators and applications. In Proceedings of the Inter-
national Conference for High Performance Computing, Networking, Storage and
Analysis (SC). ACM, 8:1–8:12.
[24] Yu Li, Yannan Liu, Min Li, Ye Tian, Bo Luo, and Qiang Xu. 2019. D2NN: a
fine-grained dual modular redundancy framework for deep neural networks.
In Proceedings of the 35th Annual Computer Security Applications Conference
(ACSAC). ACM, 138–147.
Res-
cuing memristor-based neuromorphic design with high defects. In 54th
[25] Chenchen Liu, Miao Hu, John Paul Strachan, and Hai Li. 2017.
ACM/EDAC/IEEE Design Automation Conference (DAC). IEEE, 1–6.
[26] Yannan Liu, Lingxiao Wei, Bo Luo, and Qiang Xu. 2017. Fault injection attack on
deep neural network. In IEEE/ACM International Conference on Computer-Aided
Design (ICCAD). IEEE, 131–138.
[27] Bo Luo, Yannan Liu, Lingxiao Wei, and Qiang Xu. 2018. Towards imperceptible
and robust adversarial example attacks against neural networks. In Proceedings of
the Thirty-Second AAAI Conference on Artificial Intelligence (AAAI). AAAI Press,
1652–1659.
[28] Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
Adrian Vladu. 2018. Towards Deep Learning Models Resistant to Adversar-
ial Attacks. In 6th International Conference on Learning Representations (ICLR).
OpenReview.net.
[29] Hamid Reza Mahdiani, Sied Mehdi Fakhraie, and Caro Lucas. 2012. Relaxed
fault-tolerant hardware implementation of neural networks in the presence of
multiple transient errors.
IEEE transactions on neural networks and learning
systems (TNNLS) 23, 1215–1228.
[30] Masato Matsubayashi, Akashi Satoh, and Jun Ishii. 2016. Clock glitch generator
on SAKURA-G for fault injection attack against a cryptographic circuit. In IEEE
5th Global Conference on Consumer Electronics (GCCE). IEEE, 1–4.
[31] Dongyu Meng and Hao Chen. 2017. Magnet: a two-pronged defense against
adversarial examples. In Proceedings of the ACM SIGSAC conference on computer
and communications security (CCS). ACM, 135–147.
[32] Nicolas Papernot, Patrick McDaniel, Ian Goodfellow, Somesh Jha, Z Berkay Celik,
and Ananthram Swami. 2017. Practical black-box attacks against machine learn-
ing. In Proceedings of the ACM on Asia conference on computer and communications
security (Asia CCS). ACM, 506–519.
[33] Adnan Siraj Rakin, Zhezhi He, and Deliang Fan. 2019. Bit-Flip Attack: Crushing
Neural Network with Progressive Bit Search. In IEEE/CVF International Conference
on Computer Vision (ICCV). IEEE, 1211–1220.
[34] Brandon Reagen, Udit Gupta, Lillian Pentecost, Paul Whatmough, Sae Kyu Lee,
Niamh Mulholland, David Brooks, and Gu-Yeon Wei. 2018. Ares: A framework
for quantifying the resilience of deep neural networks. In 55th ACM/ESDA/IEEE
Design Automation Conference (DAC). IEEE, 1–6.
[35] Brandon Reagen, Paul Whatmough, and et. al. Adolf. 2016. Minerva: Enabling
low-power, highly-accurate deep neural network accelerators. In ACM/IEEE 43rd
Annual International Symposium on Computer Architecture (ISCA). IEEE, 267–278.
[36] Yolan Romailler and Sylvain Pelissier. 2017. Practical fault attack against the
Ed25519 and EdDSA signature schemes. In Workshop on Fault Diagnosis and
Tolerance in Cryptography (FDTC). IEEE, 17–24.
[37] Christoph Schorn, Thomas Elsken, Sebastian Vogel, Armin Runge, Andre Guntoro,
and Gerd Ascheid. 2020. Automated design of error-resilient and hardware-
efficient deep neural networks. In Neural Computing and Applications (Neural.
Comput. Appl.). Springer, 1–19.
[38] Christoph Schorn, Andre Guntoro, and Gerd Ascheid. 2018. Efficient On-Line
Error Detection and Mitigation for Deep Neural Network Accelerators. In Inter-
national Conference on Computer Safety, Reliability, and Security (SAFECOMP).
Springer, 205–219.
[39] Johannes Stallkamp, Marc Schlipsing, Jan Salmen, and Christian Igel. 2012. Man vs.
computer: Benchmarking machine learning algorithms for traffic sign recognition.
Neural Networks 32, 323–332.
[40] Mingxing Tan and Quoc V. Le. 2019. EfficientNet: Rethinking Model Scaling
for Convolutional Neural Networks. In Proceedings of the 36th International
Conference on Machine Learning (ICML), Vol. 97. PMLR, 6105–6114.
[41] Lixue Xia, Mengyun Liu, Xuefei Ning, Krishnendu Chakrabarty, and Yu Wang.
2017. Fault-tolerant training with on-line fault detection for RRAM-based neu-
ral computing systems. In Proceedings of the 54th Annual Design Automation
Conference 2017 (DAC). ACM, 33:1–33:6.
[42] Zheyu Yan, Yiyu Shi, Wang Liao, Masanori Hashimoto, Xichuan Zhou, and
Cheng Zhuo. 2020. When Single Event Upset Meets Deep Neural Networks:
Observations, Explorations, and Remedies. In 25th Asia and South Pacific Design
Automation Conference (ASP-DAC). IEEE, 163–168.
[43] Lita Yang and Boris Murmann. 2017. SRAM voltage scaling for energy-efficient
convolutional neural networks. In 18th International Symposium on Quality Elec-
tronic Design (ISQED). IEEE, 7–12.
[44] Fan Yao, Adnan Siraj Rakin, and Deliang Fan. 2020. DeepHammer: Depleting
the Intelligence of Deep Neural Networks through Targeted Chain of Bit Flips.
In 29th USENIX Security Symposium (USENIX Security). USENIX Association,
1463–1480.
[45] Pu Zhao, Siyue Wang, Cheng Gongye, Yanzhi Wang, Yunsi Fei, and Xue Lin.
2019. Fault Sneaking Attack: a Stealthy Framework for Misleading Deep Neural
Networks. In Proceedings of the 56th Annual Design Automation Conference 2019
(DAC). ACM, 165.
[46] He Zhezhi, Rakin Adnan, Siraj, Li Jingtao, Chakrabarti Chaitali, and Deliang Fan.
2020. Defending and Harnessing the Bit-Flip based Adversarial Weight Attack.
In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). IEEE,
14083–14091.