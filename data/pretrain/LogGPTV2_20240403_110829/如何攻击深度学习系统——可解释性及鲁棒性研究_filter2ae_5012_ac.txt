Networks[C]// European Conference on Computer Vision. Springer, Cham, 2014.
[10]Poulin B, Eisner R, Szafron D, et al. Visual explanation of evidence with
additive classifiers [C] //Proc of the 18th Conf on Innovative Applications of
Artificial Intelligence. Palo Alto, CA: AAAI Press, 2006: 1822-1829
[11] Kononenko I. An efficient explanation of individual classifications using
game theory [J]. Journal of Machine Learning Research, 2010, 11(Jan): 1-18
[12]Huysmans J, Dejaeger K, Mues C, et al. An empirical evaluation of the
comprehensibility of decision table, tree and rule based predictive models
[J]. Decision Support Systems, 2011, 51(1): 141-154
[13] Poulin B , Eisner R , Szafron D , et al. Visual explanation of evidence
in additive classifiers[C]// Conference on Innovative Applications of
Artificial Intelligence. AAAI Press, 2006.
[14]Xu K, Ba J, Kiros R, et al. Show, attend and tell: Neural image caption
generation with visual attention [C] //Proc of the 32nd Int Conf on Machine
Learning. Tahoe City, CA: International Machine Learning Society, 2015:
2048-2057
[15] Yang C , Rangarajan A , Ranka S . Global Model Interpretation via
Recursive Partitioning[C]// 2018 IEEE 20th International Conference on High
Performance Computing and Communications; IEEE 16th International Conference
on Smart City; IEEE 4th International Conference on Data Science and Systems
(HPCC/SmartCity/DSS). IEEE, 2018.
[16] Frosst N , Hinton G . Distilling a Neural Network Into a Soft Decision
Tree[J]. 2017.
[17] Simonyan K , Vedaldi A , Zisserman A . Deep Inside Convolutional
Networks: Visualising Image Classification Models and Saliency Maps[J].
Computer ence, 2013.
[18] Li J , Monroe W , Jurafsky D . Understanding Neural Networks through
Representation Erasure[J]. 2016.
[19]Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. 2018. Anchors:
High-precision model-agnostic explana-tions. InProceedings of the 32nd AAAI
Conference on Artificial Intelligence (AAAI’18).
[20] Du M, Liu N, Song Q, et al. Towards explanation of dnn-based prediction
with guided feature inversion[C]//Proceedings of the 24th ACM SIGKDD
International Conference on Knowledge Discovery & Data Mining. 2018:
1358-1367.
[21]Goodfellow I J, Shlens J, Szegedy C. Explaining and harnessing adversarial
examples [J]. arXiv preprint arXiv:1412.6572, 2014
[22]Papernot N, Mcdaniel P, Jha S, et al. The limitations of deep learning in
adversarial settings [C] //Proc of the 1st IEEE European Symp on Security and
Privacy. Piscataway, NJ: IEEE, 2016: 372-387
[23] Papernot N, Mcdaniel P, Goodfellow I, et al. Practical black- box attacks
against machine learning [C] //Proc of the 12th ACM Asia Conf on Computer and
Communications Security. New York: ACM, 2017: 506-519
[24]吴亚丽, 李国婷, 付玉龙, 王晓鹏. 基于自适应鲁棒性的入侵检测模型. 控制与决策, 2019, 34(11): 2330-2336.
[25]Huang X, Kwiatkowska M, Wang S, et al. Safety verification of deep neural
networks[C]. International Conference on Computer Aided Verification, 2017:
3-29.
[26]Tjeng V, Xiao K, Tedrake R. Evaluating robustness of neural networks with
mixed integer programming[J]. arXiv preprint arXiv:1711.07356, 2017.
[27]Bunel R R, Turkaslan I, Torr P, et al. A unified view of piecewise linear
neural network verification[C]. Advances in Neural Information Processing
Systems, 2018: 4790-4799.
[28]Salman H, Li J, Razenshteyn I, et al. Provably robust deep learning via
adversarially trained smoothed classifiers[C]. Advances in Neural Information
Processing Systems, 2019: 11289-11300.
[29]Gowal S, Dvijotham K D, Stanforth R, et al. Scalable Verified Training for
Provably Robust Image Classification[C]. Proceedings of the IEEE International
Conference on Computer Vision, 2019: 4842-4851.
[30]Sunaga T. Theory of an interval algebra and its application to numerical
analysis[J]. RAAG memoirs, 1958, 2(29-46): 209.
[31]纪守领, 李进锋, 杜天宇,等. 机器学习模型可解释性方法、应用与安全研究综述[J]. 计算机研究与发展, 2019, 56(10).
[32]Ziqi Yang, Jiyi Zhang, Ee-Chien Chang, and Zhenkai Liang. Neural network
in- version in adversarial setting via background knowledge alignment. In
Lorenzo Cavallaro, Johannes Kinder, XiaoFeng Wang, and Jonathan Katz, editors,
Pro- ceedings of the 2019 ACM SIGSAC Conference on Computer and Communica-tions Security, CCS 2019, London, UK, November 11-15, 2019, pages 225–240.
ACM, 2019.
[33]Florian Tramèr, Zhang F , Juels A , et al. Stealing Machine Learning
Models via Prediction APIs[J]. 2016.
[34]https://www.anquanke.com/post/id/218839