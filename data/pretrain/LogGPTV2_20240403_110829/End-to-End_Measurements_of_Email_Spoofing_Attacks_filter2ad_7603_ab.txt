### Hosts and Measurement Challenges
The hosts were measured in February 2017, October 2017, and January 2018. Similar to the findings in [23, 27], this measurement method cannot be applied to DKIM because querying a DKIM record requires knowing the selector information for each domain. This selector information is only available in the DKIM signature within the email header, which is not publicly accessible. We will measure DKIM usage in a later end-to-end measurement.

### Recent Adoption Rates
Table 1 presents the statistics from the most recent snapshot in January 2018. Both SPF and DMARC have seen some increase in adoption rates, although the growth is not significant. Approximately 44.9% of domains had published a valid SPF record in 2018 (compared to 40% in 2015 [27]), and 5.1% had a valid DMARC record in 2018 (compared to 1.1% in 2015 [27]). Invalid records are often due to domain administrators using incorrect formats for SPF or DMARC records. Another common error is having multiple SPF or DMARC records, which, according to RFC7489 [50], is equivalent to having no record at all. Figure 2 illustrates the adoption rates across all three snapshots, showing a slow but steady increase.

Among the 1 million domains, 792,556 are MX domains (mail exchanger domains that host email services). The adoption rates for MX domains are slightly higher (SPF: 54.3%, DMARC: 6.0%). For non-MX domains, it is also important to publish SPF and DMARC records. For example, office.com, though not an MX domain, hosts the website for Microsoft Office. Attackers could spoof office.com to phish Microsoft Office users or even employees.

### Policy Failures
Both SPF and DMARC specify policies for actions that receivers should take if authentication fails. Table 1 shows that only a small fraction of domains set a strict "reject" policy: 12.5% of domains set "hard fail" for SPF, and 0.6% set "reject" for DMARC. The rest leave the decision to the email receiver. "Soft fail" or "quarantine" means the email should be processed with caution, while "neutral" or "none" indicates no specified policy. SPF's "pass" means the email should be allowed through. If a domain has both SPF and DMARC policies, DMARC overwrites SPF as long as the DMARC policy is not "none."

Domains using DKIM must also publish their policies through DMARC. The fact that only 5.1% of domains have a valid DMARC record and 0.6% have a "reject" policy suggests that most DKIM adopters do not specify a strict reject policy.

### Popular Domains
Unsurprisingly, popular domains have higher adoption rates, as shown in Figure 3. We divided the top 1 million domains into log-scale sized bins. For SPF, the top 1,000 domains have an adoption rate of 73%. For DMARC, the top 1,000 domains have an adoption rate of 41%. This indicates that administrators of popular domains are more motivated to prevent domain spoofing. However, many (popular) domains remain unprotected.

### End-to-End Spoofing Experiments
Given the current adoption rates of SMTP extension protocols, it remains challenging for email providers to reliably authenticate all incoming emails. When encountering questionable emails, we are curious about how email providers make such decisions. In the following sections, we describe our measurement methodology and procedures.

#### Experiment Setup
We conducted end-to-end spoofing experiments on popular email providers used by billions of users. As shown in Figure 4, for a given email provider (B.com), we set up a user account under B.com as the email receiver (PI:EMAIL). Then, we set up an experimental server (E.com) to send forged emails to the receiver account. Our server runs a Postfix mail service [3] to directly interact with the target mail server using SMTP. By controlling the input (the forged email) and observing the output (the receiver account), we infer the decision-making process inside the target email service.

**Selecting Target Email Providers:**
This study focuses on popular and public email services for two reasons. First, popular email services like Yahoo Mail and Gmail are used by over one billion users [46, 55]. Their security policies and design choices impact a large number of people. Second, to perform end-to-end experiments, we need to collect data from the receiver end. Public email services allow us to create an account as the receiver. Our experiment methodology can be applied to private email services but requires collaboration from internal users.

To obtain a list of popular public email services, we referred to Adobe’s leaked user database (152 million email addresses, 9.3 million unique email domains) [41]. We ranked the email domains based on popularity and manually examined the top 200 domains (accounting for 77.7% of all email addresses). After merging domains from the same service (e.g., hotmail.com and outlook.com) and excluding services that don’t allow account creation, we obtained a shortlist of 28 email domains. To include more recent public email services, we searched on Google and added 6 more services (yeah.net, protonmail.com, tutanota.com, zoho.com, fastmail.com, and runbox.com). We noticed that Google’s Gmail and Inbox have very different email interfaces and treated them as two separate services.

In total, we have 35 popular email services, covering 99.8 million email addresses (65.7%) in the Adobe database. As an additional reference, we analyzed the Myspace database (131.4 million email addresses) [54] and found that 101.8 million email addresses (77.5%) are from the 35 email services, confirming their popularity. The list of email providers is shown in Table 2.

#### Experiment Parameters
To examine how different factors affect the outcome of email spoofing, we applied various configurations to the experiment. We primarily focused on parameters likely to influence the spoofing outcome, including the spoofed sender address, email content, sender IP, and the receiver’s email client (user interface).

**Spoofed Sender Address:**
The sender address is a critical part of the authentication. For example, if the spoofed domain (A.com) has a valid SPF/DKIM/DMARC record, the receiver (in theory) should be able to detect spoofing. We configured three profiles for the spoofed sender domain:
1. **None:** No SPF/DKIM/DMARC record (e.g., thepiratebay.org).
2. **Relaxed:** SPF/DKIM with a "none" policy (e.g., tumblr.com).
3. **Strict:** SPF/DKIM with a strict "reject" policy (e.g., facebook.com).

For each profile, we randomly picked 10 domains (30 domains in total) from Alexa's top 5000 domains (detailed list in Appendix A).

**Email Content:**
Email content can affect how spam filters handle incoming emails [11]. Our experiment aims to minimize the impact of spam filters and focus on how the receivers' decisions are affected by address forgery alone. We configured five types of email content:
1. A blank email.
2. A blank email with a benign URL (http://google.com).
3. A blank email with a benign attachment (an empty text file).
4. A benign email with actual content (a real-world legitimate email informing a colleague about a meeting time change).
5. An email with phishing content (a real-world sample from a phishing attack targeting our institution recently, impersonating technical support to notify the victim that her internal account has been suspended and asking her to re-activate the account using a URL to an Amazon EC2 server).

**Sender IP:**
The IP address of the sender’s mail server may also affect spoofing success. We configured a static IP address and a dynamic IP address. Typically, mail servers use static IPs, but attackers may use dynamic IPs for lower costs.

**Email Client:**
We examined how different email clients warn users of forged emails. We considered three common email clients:
1. Web client.
2. Mobile app.
3. Third-party email client (e.g., Microsoft Outlook and Apple Mail).

All 35 selected services have a web interface, and 28 have a dedicated mobile app. Third-party clients allow users to check emails from any email provider.

### Spoofing Experiment Results
In this section, we describe the results of our experiments. First, we measure the authentication protocols that the target email providers use to detect forged emails. Then, we examine how email providers handle forged emails and identify key factors in the decision-making process. For emails that reached the inbox, we examine whether and how email providers warn users about potential risks. Note that all experiment results reflect the state of the target email services as of January 2018.

#### Authentication Mechanisms
To better interpret the results, we first examined how the 35 email providers authenticate incoming emails. One way to determine their authentication protocols is to analyze email headers for SPF/DKIM/DMARC authentication results. However, not all email providers add these results to the header (e.g., qq.com). Instead, we followed a more reliable method [27] by setting up an authoritative DNS server for our own domain and sending an email from our domain. The authoritative DNS server waited to see if the target email service would query the SPF/DKIM/DMARC record. We set the TTL of the SPF, DKIM, and DMARC records to 1 second to force the target email service to always query our authoritative DNS server. The results are shown in Table 2 (left four columns). The 35 email providers can be grouped into three categories based on their protocols:

- **Full Authentication (16):** Email services that perform all three authentication checks (SPF, DKIM, and DMARC). This category includes the most popular email services such as Gmail, Hotmail, and iCloud.
- **SPF/DKIM but no DMARC (15):** Email services that check either SPF or DKIM but do not check the sender’s DMARC policy. These email services are likely to make decisions on their own.
- **No Authentication (4):** Email services that do not perform any of the three authentication protocols.

#### Decisions on Forged Emails
Next, we examined the decision-making process for forged emails. For each of the 35 target email services, we tested all possible combinations of parameter settings (30 spoofed addresses × 5 types of email content × 2 IP addresses). The overall rate of forged emails reaching the inbox is shown in Table 2.