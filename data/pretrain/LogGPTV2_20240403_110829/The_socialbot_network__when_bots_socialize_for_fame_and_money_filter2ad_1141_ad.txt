the ﬁgure. The ﬁrst one constitutes 86% of the socialbots
and 70% of the overall inﬁltration, where each socialbot has
inﬁltrated 0–50 user proﬁles. The second league, on the
other hand, constitutes 10% of the socialbots and 23% of
the overall inﬁltration, where each socailbot has inﬁltrated
60–80 user proﬁles. The rest of the socialbots, which we
consider as outliers, constitute only 4% of the socialbots
with 7% of the overall inﬁltration.
As most of the resulted inﬁltration was the outcome of the
socialbots’ group work, we decided to calculate how much
new data a botherder can collect per socialbot, as opposed
to a completely public access. This is particularly useful
when trying to estimate how many socialbots (or connection
requests) are needed in order to collect a targeted amount
of speciﬁc users’ data, such as email addresses and birth
dates. Using a conservative SbN operation of 25 friendship
requests per socialbot per day, and a relaxed operation time
of 8 weeks, we found that a botherder is expected to collect
an average of 175 new chunks of users’ data in Facebook per
socialbot per day, as shown in Table 4.
5.4
Implications on other Systems
Operating the SbN for an extended period of time is ex-
pected to result in a signiﬁcantly larger inﬁltration, as the
socialbots will spend most of that time in the propagation
phase. Accordingly, the neighborhood size of each socialbot
is expected to keep increasing. This, however, has alarming
implications on software systems that use the social graph
of an OSN to provide services such as limiting Sybil nodes
in distributed systems [45] and modeling trust in socially-
informed recommender systems [43].
To explain why this is particularly important, let us con-
sider OSN-based Sybil defenses used in P2P overlay net-
works.6 In general, such a defense mechanism uses two types
of networks that share the same nodes: the P2P network
which we try to protect, and an external social network rep-
resenting a trust network such as Facebook [45]. Now, in
order to detect Sybil nodes in the P2P network, the fol-
lowing assumption is often made [41]: a Sybil node cannot
have many connections with non-Sybil nodes in the social
network. Thus, ﬁnding a well-connected node in the P2P
network, which is loosely connected in the social network, is
a good indication that this node is a Sybil. This assump-
tion, however, is not safe. We showed that the socialbots
can have arbitrarily many social connections with arbitrary
OSN users. Therefore, we believe that using a social network
such as Facebook to detect Sybil nodes in P2P networks is,
in fact, ineﬀective. This conclusion extends to all systems
that make this assumption about OSNs.
6. RELATED WORK
The closest threat to large-scale inﬁltration in OSNs is a
botnet called Koobface [5]. At ﬁrst, Koobface compromises
user accounts on OSNs, and then uses these accounts to
promote a provocative message with a hyperlink. The link
points to a phishing website that asks the user to install
6A Sybil node (or a Sybil for short) is an adversary-owned
online identity, account, proﬁle, or endpoint in a particular
network. Sybil nodes represent a serious threat and can be
used to subvert services such routing in P2P networks [11].
a Flash plugin which is, in fact, the Koobface executable.
Unlike Koobface, an SbN does not rely on hijacked proﬁles as
doing so requires infecting a large number of initial “zombie”
machines through OSN-independent distribution channels.
Bilge et al. [6] show that most users in OSNs are not
cautious when accepting connection requests that are sent
to them. The authors did an experiment to test how will-
ing users are to accept connection requests from forged user
proﬁles of people who were already in their friendship list
as conﬁrmed contacts. They also compared that with users’
response to connection requests from people that they do
not know (i.e., fake proﬁles representing strangers). In their
experiment, they show that the acceptance rate for forged
proﬁles was always over 60%, and about 20% for the fake
proﬁles. Unlike their targeted attack, we do not expect the
adversary to forge proﬁles as this limits the scalability of the
attack and makes it more susceptible to detection.
Other than the wide botnet literature, the majority of the
work we found relates to Twitter bots and diﬀerent tech-
niques to detect them. Ratkiewicz et al. [33] describe the
use of Twitter bots to spread misinformation in the run-up
to the U.S. political elections. Stringhini et al. [37] analyze
to what extent spam has entered OSNs, and how spam-
mers who target these OSNs operate. The authors develop
techniques to detect spammers, and show that it is possi-
ble to automatically identify the accounts they use. Grier
et al. [16] show that 8% of the unique URLs that are sent
in Twitter are later blacklisted. The authors also described
a test on Tweets’ timestamps to identify automated Twit-
ter accounts, or spambots, by regularities in the times when
they tweet, which they have found to have a high accuracy
in identifying Twitter spammers.
7. CONCLUSION
We have evaluated how vulnerable OSNs are to a large-
scale inﬁltration by a Socialbot Network (SbN). We used
Facebook as a representative OSN, and found that using
bots that mimic real OSN users is eﬀective in inﬁltrating
Facebook on a large scale, especially when the users and
the bots share mutual connections. Moreover, such social-
bots make it diﬃcult for OSN security defenses, such as the
Facebook Immune System, to detect or stop an SbN as it op-
erates. Unfortunately, this has resulted in alarming privacy
breaches and serious implications on other socially-informed
software systems. We believe that large-scale inﬁltration in
OSNs is only one of many future cyber threats, and defend-
ing against such threats is the ﬁrst step towards maintaining
a safer social Web for millions of active web users.
8. ACKNOWLEDGMENTS
We would like to thank San-Tsai Sun, Elizeu Santos-Neto,
Albina Muslukhova, and Bader AlAhmad for their kind help
and advice. We also would like to thank Cormac Herley,
Miranda Mowbray, and Adriana Iamnitchi for their feedback
on an early draft of this paper. This research is partially
supported through funding from the NSERC Internetworked
Systems Security Network (ISSNet).
9. REFERENCES
[1] Facebook Open Graph Protocol.
http://developers.facebook.com/docs/opengraph.
[2] Sick proﬁle maker.
http://sickmarketing.com/sick-profile-maker.
[3] Facebook Statistics.
http://www.facebook.com/press, March 2011.
[4] Jet bots. http://allbots.info, 2011.
[5] J. Baltazar, J. Costoya, and R. Flores. The real face of
Koobface: The largest web 2.0 botnet explained.
Trend Micro Research, July 2009.
[6] L. Bilge, T. Strufe, D. Balzarotti, and E. Kirda. All
your contacts are belong to us: automated identity
theft attacks on social networks. In WWW ’09:
Proceedings of the 18th International Conference on
World Wide Web, pages 551–560, New York, NY,
USA, 2009. ACM.
[7] N. Bos, K. Karahalios, M. Musgrove-Ch´avez, E. S.
Poole, J. C. Thomas, and S. Yardi. Research ethics in
the facebook era: privacy, anonymity, and oversight.
In CHI EA ’09: Proceedings of the 27th international
conference extended abstracts on Human factors in
computing systems, pages 2767–2770, New York, NY,
USA, 2009. ACM.
[8] D. Boyd. Social media is here to stay... Now what?
Microsoft Research Tech Fest, February 2009.
[9] G. Brown, T. Howe, M. Ihbe, A. Prakash, and
K. Borders. Social networks and context-aware spam.
In CSCW ’08: Proceedings of the ACM 2008
Conference on Computer Supported Cooperative Work,
pages 403–412, New York, NY, USA, 2008. ACM.
[10] Z. Coburn and G. Marra. Realboy: Believable twitter
bots. http://ca.olin.edu/2008/realboy, April 2011.
[11] J. R. Douceur. The sybil attack. In IPTPS ’01:
Revised Papers from the First International Workshop
on Peer-to-Peer Systems, pages 251–260, London, UK,
2002. Springer-Verlag.
[12] M. Egele, L. Bilge, E. Kirda, and C. Kruegel. Captcha
smuggling: hijacking web browsing sessions to create
captcha farms. In SAC ’10: Proceedings of the 2010
ACM Symposium on Applied Computing, pages
1865–1870, New York, NY, USA, 2010. ACM.
[13] N. B. Ellison, C. Steinﬁeld, and C. Lampe. The
beneﬁts of Facebook “friends:” social capital and
college students’ use of online social network sites.
Journal of Computer-Mediated Communication,
12(4):1143–1168, July 2007.
[14] N. FitzGerald. New Facebook worm - don’t click da’
button baby!
http://fitzgerald.blog.avg.com/2009/11/,
November 2009.
[15] M. Gjoka, M. Kurant, C. T. Butts, and
A. Markopoulou. Walking in Facebook: A case study
of unbiased sampling of osns. In Proceedings of IEEE
INFOCOM ’10, San Diego, CA, March 2010.
[16] C. Grier, K. Thomas, V. Paxson, and M. Zhang.
@spam: the underground on 140 characters or less. In
Proceedings of the 17th ACM Conference on Computer
and Communications Security, CCS ’10, pages 27–37,
New York, NY, USA, 2010. ACM.
[17] C. Herley. The plight of the targeted attacker in a
world of scale. In The 9th Workshop on the Economics
of Information Security (WEIS 2010), 2010.
[18] C. Hernandez-Castro and A. Ribagorda. Remotely
telling humans and computers apart: An unsolved
problem. In J. Camenisch and D. Kesdogan, editors,
iNetSec 2009 ? Open Research Problems in Network
Security, volume 309 of IFIP Advances in Information
and Communication Technology, pages 9–26. Springer
Boston, 2009.
Botnet judo: Fighting spam with itself. In NDSS,
2010.
[32] A. Rapoport. Spread of information through a
population with socio-structural bias: I. assumption of
transitivity. Bulletin of Mathematical Biology,
15:523–533, 1953. 10.1007/BF02476440.
[19] M. Huber, M. Mulazzani, and E. Weippl. Who on
[33] J. Ratkiewicz, M. Conover, M. Meiss, B. Gon¸calves,
earth is Mr. Cypher? automated friend injection
attacks on social networking sites. In Proceedings of
the IFIP International Information Security
Conference 2010: Security & Privacy — Silver
Linings in the Cloud, 2010.
[20] T. N. Jagatic, N. A. Johnson, M. Jakobsson, and
F. Menczer. Social phishing. Commun. ACM,
50(10):94–100, 2007.
[21] A. M. Kaplan and M. Haenlein. Users of the world,
unite! the challenges and opportunities of social
media. Business Horizons, 53(1):59 – 68, 2010.
[22] J. Leskovec and E. Horvitz. Planetary-scale views on a
large instant-messaging network. In Proceeding of the
17th International Conference on World Wide Web,
pages 915–924, New York, NY, USA, 2008. ACM.
[23] G. Livingston. Social media: The new battleground
for politics. http://mashable.com/2010/09/23/
congress-battle-social-media/, September 2010.
[24] D. Misener. Rise of the socialbots: They could be
inﬂuencing you online. http:
//www.cbc.ca/news/technology/story/2011/03/29/
f-vp-misener-socialbot-armies-election.html,
March 2011.
[25] A. Mislove, M. Marcon, K. P. Gummadi, P. Druschel,
and B. Bhattacharjee. Measurement and analysis of
online social networks. In IMC ’07: Proceedings of the
7th ACM SIGCOMM Conference on Internet
Measurement, pages 29–42, New York, NY, USA,
2007. ACM.
[26] E. Morozov. Swine ﬂu: Twitter’s power to misinform.
http://neteffect.foreignpolicy.com/posts/2009/
04/25/swine_flu_twitters_power_to_misinform,
April 2009.
[27] M. Motoyama, K. Levchenko, C. Kanich, D. McCoy,
G. M. Voelker, and S. Savage. Re: Captchas:
understanding captcha-solving services in an economic
context. In Proceedings of the 19th USENIX
Conference on Security, USENIX Security’10, pages
28–28, Berkeley, CA, USA, 2010. USENIX
Association.
[28] S. Nagaraja, A. Houmansadr, P. Agarwal, V. Kumar,
P. Piyawongwisal, and N. Borisov. Stegobot: A covert
social network botnet. In Proceedings of the
Information Hiding Conference, 2011.
[29] F. Nagle and L. Singh. Can friends be trusted?
exploring privacy in online social networks. In
Proceedings of the 2009 International Conference on
Advances in Social Network Analysis and Mining,
pages 312–315, Washington, DC, USA, 2009. IEEE
Computer Society.
[30] S. Patil. Social network attacks surge.
http://www.symantec.com/connect/blogs/
social-network-attacks-surge, June 2011.
[31] A. Pitsillidis, K. Levchenko, C. Kreibich, C. Kanich,
G. M. Voelker, V. Paxson, N. Weaver, and S. Savage.
S. Patil, A. Flammini, and F. Menczer. Truthy:
mapping the spread of astroturf in microblog streams.
In Proceedings of the 20th international conference
companion on World wide web, WWW ’11, pages
249–252, New York, NY, USA, 2011. ACM.
[34] C. P. Robert and G. Casella. Monte Carlo Statistical
Methods (Springer Texts in Statistics). Springer-Verlag
New York, Inc., Secaucus, NJ, USA, 2005.
[35] F. Salem and R. Mourtada. Civil movements: The
impact of Facebook and Twitter. The Arab Social
Media Report, 1(2), 2011.
[36] T. Stein, E. Chen, and K. Mangla. Facebook immune
system. In Proceedings of the 4th Workshop on Social
Network Systems, SNS ’11, pages 8:1–8:8, New York,
NY, USA, 2011. ACM.
[37] G. Stringhini, C. Kruegel, and G. Vigna. Detecting
spammers on social networks. In Proceedings of the
26th Annual Computer Security Applications
Conference, ACSAC ’10, pages 1–9, New York, NY,
USA, 2010. ACM.
[38] C. Taylor. Why not call it a Facebook revolution?
http://edition.cnn.com/2011/TECH/social.media/
02/24/facebook.revolution/, February 2011.
[39] S. T. Tong, B. Van Der Heide, L. Langwell, and J. B.
Walther. Too much of a good thing? the relationship
between number of friends and interpersonal
impressions on Facebook. Journal of
Computer-Mediated Communication, 13(3):531–549,
2008.
[40] J. A. Vargas. Obama raised half a billion online.
http://voices.washingtonpost.com/44/2008/11/
obama-raised-half-a-billion-on.html, November
2008.
[41] B. Viswanath, A. Post, K. P. Gummadi, and
A. Mislove. An analysis of social network-based sybil
defenses. In Proceedings of the ACM SIGCOMM 2010
conference on SIGCOMM, SIGCOMM ’10, pages
363–374, New York, NY, USA, 2010. ACM.
[42] L. von Ahn, M. Blum, N. J. Hopper, and J. Langford.
Captcha: Using hard AI problems for security. In
E. Biham, editor, EUROCRYPT, volume 2656 of
Lecture Notes in Computer Science, pages 294–311.
Springer, 2003.
[43] F. Walter, S. Battiston, and F. Schweitzer. A model of
a trust-based recommendation system on a social
network. Autonomous Agents and Multi-Agent
Systems, 16:57–74, 2008.
[44] H. Yeend. Breaking CAPTCHA without OCR.
http://www.puremango.co.uk/2005/11/breaking_
captcha_115/, November 2005.
[45] H. Yu, P. B. Gibbons, M. Kaminsky, and F. Xiao.
Sybillimit: A near-optimal social network defense
against sybil attacks. In Proceedings of the 2008 IEEE
Symposium on Security and Privacy, pages 3–17,
Washington, DC, USA, 2008. IEEE Computer Society.