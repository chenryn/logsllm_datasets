pmark = 0.5
t
ﬁ
e
n
e
b
0.6
0.4
0.2
0
1
4
7
10 13 16
1
4
7
10 13 16
(a) pmark = 0.2
µstop
(b) premark = 0.9
Figure 3: beneﬁt as a function of µstop with varying premark
and varying pmark (k = 32, Λ = 4)
a slight boost to the beneﬁt. However, increasing Λ or µstop,
shown in Fig. 2c and Fig. 2d respectively, causes beneﬁt to
drop slightly. The reasons behind these drops are that larger
Λ (i.e., more repeated logins by the attacker) give him a bet-
ter chance to leave with a reduced probability of detection,
and a larger µstop allows the attacker to observe more user
logins and so more remarkings (to minimize (cid:142)(cid:96)) before he is
detected by other means.
This latter eﬀect is illustrated in Fig. 3, which shows
beneﬁt as a function of µstop. When µstop ≤ 7, the settings
pmark = 0.2, premark = 0.9 yield the best beneﬁt among the
combinations pictured in Fig. 3. However, as µstop grows, the
longer time (i.e., larger (cid:96)) the attacker can wait to access the
account aﬀords him a lower (cid:142)(cid:96) and so a lower probability
of being detected when the legitimate user subsequently logs
in. This eﬀect can be oﬀset by decreasing premark (Fig. 3a),
increasing pmark (Fig. 3b), or both.
1
0.8
0.6
0.4
0.2
0
0
t
ﬁ
e
n
e
b
Λ = 1
Λ = 4
Λ = 7
Λ = 10
64 128 192 256
The impact of Λ is
shown in Fig. 4, which
plots beneﬁt as a function
of k for various Λ. Fig. 4
shows that even when the
attacker logs in more fre-
quently than the user by
a factor of Λ = 10, our al-
gorithm still remains eﬀec-
tive with beneﬁt ≈ 0.5 for
moderately large k. That
said, while Fig. 4 suggests
that increasing k into the
hundreds should suﬃce, we
will see in Sec. 5 that an
even larger k might be
warranted when credential
stuﬃng is considered.
Interpreting beneﬁt: As we deﬁne it, beneﬁt is a conserva-
tive measure, in two senses. First, beneﬁt is calculated (via
probabilistic model checking) against the strongest attacker
possible in our threat model. Second, beneﬁt is computed
only for one account, but detection on any account is enough
to inform the target of its breach. For an attacker whose goal
is to assume control of a large number of accounts at the
target (vs. one account speciﬁcally), the detection power of
our algorithm will be much higher.
Figure 4: beneﬁt as a func-
tion of k with varying Λ
(pmark = 0.3, premark = 1.0,
µstop = 8)
k
That said, quantifying that detection power holistically for
the target is not straightforward. Recall that beneﬁt is deﬁned
in terms of time units wherein the legitimate user is expected
to login λ = 1 time. As such, the real-time length of this unit
for a frequently accessed account will be diﬀerent than for
an infrequently accessed one. And, since µstop is expressed
in this time unit, µstop will be larger for a frequently accessed
account than for an infrequently accessed one, even though
the real-time interval that passes before a site detects its own
breach by means other than Amnesia might be independent of
the legitimate login rates to accounts. Thus, extrapolating the
per-account beneﬁt to the security improvement for a target
holistically requires knowledge of the legitimate login rates
across all the sites’ accounts as a function of real time, adjust-
ing µstop (and χstop) accordingly per account, and translating
the per-account beneﬁts back into a real-time measure.
5 Detecting Remotely Stuﬀed Honeywords
When a credential database is breached, it is common for at-
tackers to submit the login credentials therein (i.e., usernames
844    30th USENIX Security Symposium
USENIX Association
and passwords) to other sites, in an eﬀort to access accounts
whose user set the same password as she did at the breached
site. These attacks, called credential stuﬃng, are already the
primary attack yielding account takeovers today [41]. But
even worse for our purposes here, credential stuﬃng enables
an attacker to circumvent the honeywords at a breached target
site: If a user reused her password at another site, then stuﬀ-
ing the breached passwords there will reveal which is the
user-chosen password, i.e., as the one that gains access. The
attacker can then return to the target site with the correct
password to access the user’s account at the target.
The design in this section mitigates credential stuﬃng as a
method to identify the user’s chosen password, by ensuring
that stuﬃng honeywords at other sites probabilistically still
alerts the target site to its breach. At a high level, the target
maintains a set of monitor sites and can choose to monitor an
account at any of those monitors. To monitor the account at a
monitor, the target sends the monitor a private containment
retrieval (PCR) query for this account identiﬁer, to which the
monitor responds after any unsuccessful login attempt to this
account (potentially even if the account does not exist at the
monitor). In the abstract, a PCR query is a private (encrypted)
representation of a set X of elements known to the target,
and a response computed with element e reveals to the target
the element e if e ∈ X and nothing otherwise. In this case,
the target’s set X contains the local password hashes for the
user’s account. If a monitor then sends a response computed
using some e ∈ X, the target can treat e as if it were attempted
locally, permitting the detection of a breach just as in Sec. 4.
5.1 Threat Model
As in Sec. 4.1, we allow the adversary to breach the target
passively, thereby learning all information persistently stored
by the site for the purpose of determining the success of its
users’ login attempts. We highlight that in this section, the
breached information includes a private key that is part of
the target’s stored state for managing login attempts in our
algorithm. So, if the target is breached, then this private key
is included in the data that the attacker learns.
We permit the attacker that breaches the target to also ac-
tively compromise monitors, in which case these monitors
can behave arbitrarily maliciously. Malicious monitors can
refuse to help the target detect its own breach via our design,
e.g., by simply refusing to respond. However, our scheme
must ensure that even malicious monitors cannot convince a
target that it has been breached when it has not. Moreover,
malicious monitors should not be able to leverage their par-
ticipation in this protocol to attack passwords at a target that
is never breached.
We do not permit the attacker to interfere with commu-
nication between a (breached or unbreached) target and an
uncompromised monitor. Otherwise, the attacker could pre-
vent the target from discovering its breach by simply refusing
to let it communicate with uncompromised monitors.
Our design assumes that diﬀerent sites can ascertain a com-
mon identiﬁer a for the same user’s accounts at their sites, at
least as well as an attacker could. In practice, this would typi-
cally be the email address (or some canonical version thereof,
see [46]) registered by the user for account identiﬁcation or
password-reset purposes.
5.2 Private Containment Retrieval
The main building block for our design is a private contain-
ment retrieval (PCR) protocol with the following algorithms.
• pcrQueryGen is an algorithm that, on input a pub-
lic key pk and a set X, generates a PCR query Y ←
pcrQueryGenpk(X).
• pcrRespGen is an algorithm that, on input a public key pk,
an element e, and a query Y ← pcrQueryGenpk(X), outputs
a PCR response Z ← pcrRespGenpk(e,Y).
• pcrReveal is an algorithm that on input the private key
sk corresponding to pk, an element e(cid:48) ∈ X, and a response
Z ← pcrRespGenpk(e,Y) where Y ← pcrQueryGenpk(X),
outputs a Boolean z ← pcrRevealsk(e(cid:48),Z) where z = true
iﬀ e(cid:48) = e.
Informally, this protocol ensures that Y reveals nothing about
X (except its size) to anyone not holding sk; that Z computed
on e (cid:60) X reveals nothing about e (except e (cid:60) X); and that
if pcrRevealsk(e(cid:48),Z) = true, then the party that computed Z
knows e(cid:48). We make these properties more precise and provide
an implementation in Sec. 6.
5.3 Algorithm
We ﬁrst provide greater detail about how the target maintains
its credential database. Whereas in Sec. 4 we left hashing of
the honey and user-chosen passwords in DBa .auths implicit,
in this section we need to expose this hashing explicitly for
functional purposes. Consistent with current best practices,
the target represents DBa .auths as a set of hashes salted with
a random κ-bit salt DBa .salt, including one hash f (s, π) of the
user-chosen password π where s ← DBa .salt and a salted hash
f (s, π(cid:48)) for each of k honeywords π(cid:48). Then, testing whether
π is either a honey or user-chosen password amounts to test-
ing f (s, π) ∈ DBa .auths. In addition to these reﬁnements,
for this algorithm the target is also initialized with a public-
key/private-key pair (cid:104)pk,sk(cid:105) for use in the PCR protocol, and a
set S of possible monitors (URLs). If the target R is breached,
then all of DB, S, and (cid:104)pk,sk(cid:105) are captured by the attacker.
The algorithm below treats local logins at the target R sim-
ilar to how they were treated in Sec. 4, with the exception
of exposing the hashing explicitly. In addition, the algorithm
permits R to ask monitor S to monitor a. To do so, R sends
a PCR query Y to S computed on DBa .auths. Upon receiv-
ing this request, S simply saves it for use on each incorrect
login to a at S , to generate a PCR response to R. The hash
USENIX Association
30th USENIX Security Symposium    845
encoded in this response is then treated at R (for the purposes
of detecting a breach) as if it has been entered in a local login
attempt. In sum, the protocol works as described below.
Password registration at R: When the user (re)sets the
password for her account a at the target site R, she pro-
vides her chosen password π. The password registration
system at R executes:
• Πa ← HoneyGen(a, π,k)
• DBa .salt $← {0,1}κ
• DBa .auths ← { f (DBa .salt, π(cid:48))}π(cid:48)∈Πa
• mark(a, f (DBa .salt, π))
Login attempt at R: For a login attempted to account
a with password π at R, the outcome is determined as
follows, where h ← f (DBa .salt, π):
• If h (cid:60) DBa .auths, the login attempt is unsuccessful.
• If h ∈ DBa .auths and DBa .marks = 0, then the lo-
gin attempt is unsuccessful and a credential database
breach is detected.
• Otherwise (i.e., h ∈ DBa .auths and DBa .marks =
1), the login attempt is successful and R executes
mark(a,h) with probability premark.
R monitors a at S : At an arbitrary time, R can
ask S ∈ S to monitor account a by generating Y ←
pcrQueryGenpk(DBa .auths) and sending (cid:104)a, DBa .salt,
pk, Y(cid:105) to S .
S receives a monitoring request (cid:104)a, s,pk,Y(cid:105) from R: S
saves (cid:104)R,a, s,pk,Y(cid:105) locally.
Login attempt at S : For an unsuccessful login attempt
to an account a using (incorrect) password π, if S holds a
monitoring request (cid:104)R,a, s,pk,Y(cid:105), then it computes Z ←
pcrRespGenpk( f (s, π),Y) and sends (cid:104)a,Z(cid:105) to R.
R receives a monitoring response
If
pcrRevealsk(h,Z) is false for all h ∈ DBa .auths, then R
discards (cid:104)a,Z(cid:105) and returns. Otherwise, let h ∈ DBa .auths
be some hash for which pcrRevealsk(h,Z) is true. R
detects a breach if DBa .marks(h) = 0 and otherwise
executes mark(a,h) with probability premark.
(cid:104)a,Z(cid:105):
In the above protocol, the only items received by the
monitor S in (cid:104)a, s,pk,Y(cid:105) are all available to an attacker who
breaches R. In this sense, a malicious S gains nothing that an
attacker who breaches the target R does not also gain, and
in fact gains less, since it learns none of sk, DBa .auths, or S.
Indeed, the only advantage an attacker gains by compromising
S in attacking passwords at R is learning the salt s = DBa .salt,
with which it can precompute information (e.g., rainbow ta-
bles [35]) to accelerate its oﬄine attack on DBa .auths if it
eventually breaches R. If this possibility is deemed too risky,
R can refuse to send s to S in its request but instead permit S
to compute f (s, π(cid:48)) when needed by interacting with R, i.e.,
with f being implemented as an oblivious pseudo-random
function (OPRF) [17] keyed with s, for which there are eﬃ-
cient implementations (e.g., the DH-OPRF implementation
leveraged by OPAQUE [24]). This approach would require ex-
tra interaction between S and R per response from S , however,
and so we do not consider this alternative further here.
S should authenticate a request (cid:104)a, s,pk,Y(cid:105) as coming from
R, e.g., by requiring that R digitally sign it. Presuming that
this digital signing key (diﬀerent from sk) is vulnerable to
capture when R is breached, S should echo each monitoring
request back to R upon receiving it. If R receives an echoed
request bearing its own signature but that it did not create, it
can again detect its own breach. (Recall that we cannot permit
the attacker to interfere with communications between R and
an uncompromised S and still have R detect its breach.)
In practice, a monitor will not retain a monitoring record
forever, as its list of monitoring records—and the resulting
cost incurred due to generating responses to them—would
only grow. Moreover, it cannot count on R to withdraw its
monitoring requests, since R does not retain records of where
it has deposited what requests, lest these records be captured
when it is breached and the attacker simply avoid monitored
accounts. Therefore, presumably a monitor should unilater-
ally expire each monitoring record after a period of time or
in a randomized fashion. We do not investigate speciﬁc expi-
ration strategies here, nor do we explore particular strategies
for a target to issue monitoring requests over time.
5.4 Security
Several security properties are supported directly by the PCR