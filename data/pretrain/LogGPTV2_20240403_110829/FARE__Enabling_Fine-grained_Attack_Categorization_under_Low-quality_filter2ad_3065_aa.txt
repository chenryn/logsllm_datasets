title:FARE: Enabling Fine-grained Attack Categorization under Low-quality
Labeled Data
author:Junjie Liang and
Wenbo Guo and
Tongbo Luo and
Vasant Honavar and
Gang Wang and
Xinyu Xing
FARE: Enabling Fine-grained Attack Categorization
under Low-quality Labeled Data
Junjie Liang1§, Wenbo Guo1§, Tongbo Luo2, Vasant Honavar1, Gang Wang3, Xinyu Xing1
1The Pennsylvania State University 2Robinhood, 3University of Illinois at Urbana-Champaign
{jul672, wzg13, vhonavar, xxing}@ist.psu.edu, PI:EMAIL, PI:EMAIL
Abstract—Supervised machine learning classiﬁers have been
widely used for attack detection, but their training requires abun-
dant high-quality labels. Unfortunately, high-quality labels are
difﬁcult to obtain in practice due to the high cost of data labeling
and the constant evolution of attackers. Without such labels, it
is challenging to train and deploy targeted countermeasures.
In this paper, we propose FARE, a clustering method to enable
ﬁne-grained attack categorization under low-quality labels. We
focus on two common issues in data labels: 1) missing labels
for certain attack classes or families; and 2) only having coarse-
grained labels available for different attack types. The core idea
of FARE is to take full advantage of the limited labels while
using the underlying data distribution to consolidate the low-
quality labels. We design an ensemble model to fuse the results of
multiple unsupervised learning algorithms with the given labels
to mitigate the negative impact of missing classes and coarse-
grained labels. We then train an input transformation network
to map the input data into a low-dimensional latent space for
ﬁne-grained clustering. Using two security datasets (Android
malware and network intrusion traces), we show that FARE
signiﬁcantly outperforms the state-of-the-art (semi-)supervised
learning methods in clustering quality/correctness. Further, we
perform an initial deployment of FARE by working with a large
e-commerce service to detect fraudulent accounts. With real-
world A/B tests and manual investigation, we demonstrate the
effectiveness of FARE to catch previously-unseen frauds.
I.
INTRODUCTION
Machine learning is widely used to build security appli-
cations. Many security tasks such as malware detection and
abuse/fraud identiﬁcation can be formulated as a supervised
classiﬁcation problem [31], [45], [64], [10], [36], [19], [17].
By collecting and labeling benign and malicious samples,
defenders can train supervised classiﬁers to distinguish attacks
from benign data (or distinguish different attack types).
A key challenge faced by these supervised classiﬁers is
that their training requires abundant high-quality labels. Many
supervised models, especially deep-learning models, are data-
hungry, requiring a large quantity of labeled data to achieve
a decent training outcome. In addition, the labels need to
have good coverage of all
interest. A
classiﬁer cannot reliably detect a certain type of attack unless
the attack types of
§Equal contribution.
Network and Distributed Systems Security (NDSS) Symposium 2021
21-25  February  2021, Virtual 
ISBN  1-891562-66-5
https://dx.doi.org/10.14722/ndss.2021.24403 
www.ndss-symposium.org
the defender knows the attack exists and has collected labeled
data for training.
Unfortunately, in practice, obtaining abundant high-quality
labels is difﬁcult. This is particularly true for security appli-
cations, due to the high cost of data labeling and the evolving
nature of attacks. Data labeling is expensive because it requires
manual efforts. Unlike labeling images or text, investigating
new attack samples (e.g., new malware families) requires
substantial expertise, and often takes a longer time. As such,
only a small portion of data samples can be labeled manually.
Even for the labeled samples, the quality of the labels is often
far from satisfying. There are two common issues faced by
different security applications:
The ﬁrst common issue is the missing classes in the la-
beled data. Take malware detection for example. The malware
ecosystem is constantly evolving with new malware families
appearing frequently over time [56]. As a result, the labeled
dataset might miss certain malware families. Using a dataset
with missing classes, the trained classiﬁers would have a hard
time detecting related malware.
The second common issue is coarse-grained labels. Due
to the lack of time or expertise of the analysts, the provided
labels often lack speciﬁcity or contain errors. For example,
for malware attribution, malware of different families may
be incorrectly labeled as the same family; For online abuse
classiﬁcation, scrapers and trolls may be assigned to a generic
“abusive” label. In practice, coarse-grained labels pose a key
challenge to deploying timely and targeted countermeasures.
For example, different malware has different kill chains, and
scrapers and trolls should be given different penalties.
Proposed Solution.
In this paper, we aim to enable ﬁne-
grained attack categorization using low-quality labels. The
goal is to discover the clustering structures in the data to
assist human analysts to derive high-quality labels. We propose
FARE, a semi-supervised method to address the issues of
both missing classes and coarse-grained labels in poorly-
labeled datasets. At the high-level, FARE’s input is a dataset
where only a small portion of the data is labeled, and the
labels are of a low-quality. After running FARE, it outputs
the clustering assignment for all the data samples. The data
samples are expected to be either correctly clustered under the
known labels or form new groups to represent the new labels.
By correctly recovering the clustering structures in the input
dataset, FARE provides the much-needed support for human
analysts to generate high-quality labels.
The core idea of FARE is to take full advantage of the
limited labels while using the underlying data distribution to
consolidate the low-quality labels. More speciﬁcally, we design
an ensemble model to fuse the results of multiple unsupervised
learning algorithms with the given labels. This helps to miti-
gate the negative impact of missing classes and coarse-grained
labels, and reduce the randomness of the learning outcome.
Based on the fused labels, we design an input transformation
network by extending the basic idea of metric learning [26].
The network maps the input data into a low-dimensional latent
space, which makes it easier to identify ﬁne-grained clusters.
Experimental Evaluation. We evaluate FARE with two
popular security applications: malware categorization and net-
work intrusion detection. We use existing datasets of 270,000
malware samples and 490,000 network events to perform
controlled experiments. More speciﬁcally, by omitting different
classes or merging data labels, we simulate different scenarios
where only limited low-quality labels are available. We com-
pare FARE with the state-of-the-art semi-supervised learning
algorithms as well as unsupervised algorithms. Our results
show that FARE signiﬁcantly outperforms existing methods
when there are missing classes or coarse-grained labels in the
data, and maintains a comparable performance when the data
labels are correct. We ﬁnd that most existing methods have the
implicit assumption that the classes in the labels are complete,
and thus perform poorly when this assumption is violated. In
addition, we show that FARE is less sensitive to the variations
of datasets, and the ratio of available labels. This conﬁrms
the beneﬁts of fusing unsupervised learning results with given
labels to increase system stability. Finally, we show that the
computational overhead of FARE is comparable to commonly-
used clustering algorithms.
Testing on a Real-world Service. We work with an industrial
partner to test FARE in their production environment to detect
fraudulent accounts in a large e-commerce service. As the ini-
tial testing, we apply FARE to a sample of 200,000 active user
accounts. The dataset only has 0.5% of conﬁrmed fraudulent
account labels, and 0.1% of conﬁrmed trusted account labels.
Through an A/B test, we show that FARE helps to discover
previously-unseen fraudulent accounts. By initiating two-factor
re-authentication requests to the detected accounts, we ﬁnd
0% of them can successfully re-authenticate themselves, con-
ﬁrming a low false-positive rate. Further manual investigation
reveals new attack types such as accounts exploiting mistagged
prices for bulk product purchasing.
In summary, this paper makes three key contributions.
• We propose FARE to address the problem of low-
quality data labels, a common challenge faced by
learning-based security applications. We introduce a
series of new designs to enable ﬁne-grained attack cat-
egorization when the labeled data has missing classes
or coarse-grained labels.
Through experiments, we demonstrate existing semi-
supervised and unsupervised methods are not capable
of handling such low-quality labels. We show that
FARE signiﬁcantly outperforms existing methods in
recovering the true clustering structure in the data.
•
• We tested FARE in a real-world online service system.
We demonstrate the usefulness of FARE to analyze
and categorize fraudulent accounts.
To facilitate future research, we release the code of FARE,
and the malware and intrusion datasets used in this paper1.
II. BACKGROUND AND PROBLEM SCOPE
We start by describing the background of three key security
applications and the problems caused by missing-classes or
coarse-grained labels. Then, we discuss our problem scope and
assumptions.
A. Security Applications
Malware Identiﬁcation and Classiﬁcation. Researchers have
used machine learning methods to identify malware from
benign software (i.e., identiﬁcation) and classifying malware
into speciﬁc families (i.e, attribution) [1], [81], [56], [82].
Most existing works focus on the supervised learning setting
(in which a fully and correctly labeled malware dataset is
available) and have demonstrated promising performance of
machine learning models. However,
the problem becomes
more challenging in semi-supervised learning or unsupervised
learning settings when labels are incomplete. Labels are in-
complete for two main reasons. First, malware evolution: one
malware family could evolve into hundreds or even thousands
of malware variants in a short period of time [73]. Second,
labeling malware usually requires manual efforts from domain
experts, which is a time-consuming process.
Network Intrusion Detection. Existing network intrusion
detection systems can be categorized into rule-based system
and anomaly-based system [65], [47], [51], [15], [38]. Rule-
based systems detect a known attack by matching the attack
with the existing patterns stored in the knowledge base. These
systems are usually accurate on well-studied intrusions but
can fail to detect previously-unseen attacks. Anomaly-based
systems rely on unsupervised machine learning to detect out-
of-distribution samples. In practice, security platforms often
combine both systems for a better outcome. However, it is still
plausible for attackers to adapt their behaviors to evade such
detection systems. Identifying and characterizing such evasion
attacks requires manual investigations from domain experts,
which again is a time-consuming process.
Fraudulent Account Detection. Online service providers face
serious threats from fraudulent accounts that are created for
malicious activities (e.g., spam, scam, illegal content scraping,
and opinion manipulation) [14], [13], [68], [75], [71], [23],
[33]. A recent report shows that fraudulent credit card accounts
affected more than 250,000 U.S. consumers [27]. Similarly,
detecting fraudulent accounts has been a cat-mouse game. The
defenders are struggling with labeling new types of fraudulent
accounts as they change their behaviors to evade detection.
B. Problem Scope and Assumptions
A common challenge faced by these security applications
is data labeling. While the data labeling problem also exists
in other application domains (e.g., image analysis and natural
language processing), we argue that
two characteristics of
security applications make the problem more concerning. First,
unlike labeling images, labeling security data requires domain
expertise to perform in-depth manual analysis (and thus more
1https://github.com/junjieliang672/FARE
2
time consuming). Second, attacker behavior shift is a norm
in the security domain, which puts higher pressure on labeling
data in a timely fashion. In practice, security analysts can only
label a small subset of samples among a large volume of data.
Below, we discuss two critical issues:
Missing Classes. The ﬁrst issue is that the labeling is often
incomplete, which means not all the incoming data samples
have a label. Even for the labeled samples, it is difﬁcult to
guarantee that the labels perfectly cover all the attack cate-
gories. Take malware for example, it is unrealistic to assume
that the security analysts are aware of all the malware families
in the wild. As such, a common practice is to conservatively
leave the previously unseen families as unlabeled data. With
unlabeled data and missing classes, the trained classiﬁer will
have a bad performance when deployed in practice.
Coarse-grained Labels. Another common situation is that
analysts mistakenly group data from several classes into one
class, due to the lack of knowledge or time for in-depth
analysis. For example, given several malware families under
one parent family, an analyst who is only aware of the parent
family could label all child families as the parent class. Worse,
it is also possible for inexperienced analysts to assign two
different malware families under the same family. Similarly,
in online services, different attacks (scrapers, spammers, trolls)
may be assigned to the same generic “abuse” label.
Fine-grained labels are the key to deploying effective
countermeasures [21]. For example, different malware fam-
ilies usually have different kill chains (from malware de-
livery to exploitation, command & control, and data exﬁl-
tration/encryption). Knowing the ﬁne-grained malware label
allows defenders to use targeted countermeasures to disrupt the
kill chain before the damage is made. Similarly, in large online
services, different abusive accounts require different types of
penalties. For example, network throttling and CAPTCHA can
be effective against automated scrapers, but are ineffective
against trolls controlled by real users.
Problem Deﬁnition. Given a dataset with n true classes, we
deﬁne the two problems as the following.
• Missing classes: labels are completely missing for nc
classes. For the remaining n−nc classes, only a small
portion of their samples have labels available.
Coarse-grained labels: ng original classes are labeled
as one union class. For these n− ng + 1 classes, only
a small portion of their samples are labeled.
•
Our goal is to recover the true clustering structure of the
input data by leveraging the limited low-quality labels. After
processing the input dataset, we aim to 1) determine there are
n clusters in the dataset; and 2) correctly assign all the data
samples (including the unlabeled samples) to the n clusters.
Note that, our output is the clusters of data samples, but
these clusters do not yet have “labels” (i.e., what type of attack
each cluster represents). In practice, human analysts will then
inspect the output clusters to assign labels (i.e., determining
the attack type). This can be done by referencing the known
labels or manually analyzing a small number of samples per
cluster (see Section §VI and Appendix-F for more details). By
recovering the correct clustering structures, we empower the
human analysts to discover the previously missing classes and
ﬁne-grained sub-classes.
In this paper, we focus on recovering the true clustering
structure. The human labeling part is out of the scope of this
paper (i.e., potential user studies are future works).
Assumptions. We assume the given labels of the known
classes are correct (n− nc classes in the missing class setting,
and n − ng + 1 classes in the coarse-grained label setting). In
other words, we assume a small number of samples for the
well-known classes are labeled correctly in the input dataset.
C. Possible Solutions and Limitations
Before introducing our system design, we ﬁrst brieﬂy
discuss the possible directions and their limitations.
The most straightforward direction is to ignore the low-
quality labels and directly train a supervised classiﬁer on the
available labeled training data [1], [32], [44]. However, with
limited and low-quality labels, a supervised classiﬁer faces
challenges to learn the accurate decision boundary of the
true classes. More importantly, supervised classiﬁers cannot
handle new classes that are not part of the labeled data. To
detect new classes, an augmentation method is to use the
prediction probability (or conﬁdence) of the classiﬁer [34].
Intuitively, a low prediction probability could indicate the input
sample is from a new class. However, this approach has major
limitations. First, conﬁdence score is known to be unreliable