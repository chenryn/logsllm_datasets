title:Tolerating Hard Faults in Microprocessor Array Structures
author:Fred A. Bower and
Paul G. Shealy and
Sule Ozev and
Daniel J. Sorin
Tolerating Hard Faults in Microprocessor Array Structures
Fred A. Bower, Paul G. Shealy, Sule Ozev, and Daniel J. Sorin
Department of Electrical and Computer Engineering
Duke University
Abstract
In this paper, we present a hardware technique, called 
Self-Repairing  Array  Structures  (SRAS),  for  masking 
hard faults in microprocessor array structures, such as 
the reorder buffer and branch history table. SRAS masks 
errors that could otherwise lead to slow system recover-
ies.  To  detect  row  errors,  every  write  to  a  row  is  mir-
rored to a dedicated “check row.” We then read out both 
the  written  row  and  check  row  and  compare  their 
results.  To  correct  errors,  SRAS  maps  out  faulty  array 
rows with a level of indirection. 
1  Introduction
As  microprocessor  fabrication  technology  contin-
ues to shrink devices and wires and increase clock fre-
quencies,  hard  fault  rates  are  consequently  increasing. 
One  reason  is  the  increased  probability  of  short  and 
open circuits. As circuit dimensions continue to shrink, 
hard fault rates will increase [4, 17], as effects such as 
electromigration and gate dielectric breakdown become 
more likely. Moreover, with increasing numbers of tran-
sistors  being  used,  the  probabilities  of  microprocessor 
hard faults are correspondingly increasing. 
Existing solutions for hard faults, which we discuss 
in more detail in Section 2, are either very expensive or 
suffer  performance  penalties  for  many  classes  of  hard 
faults. One class of approaches uses redundant parallel 
processors (e.g. pair and spare) to provide forward error 
recovery  (FER).  These  systems  provide  high  availabil-
ity, but they use a large amount of hardware and are thus 
expensive.  At  the  other  end  of  the  high  availability 
design  spectrum,  a  recently  developed  scheme,  called 
DIVA [3], uses only a small on-chip checker to achieve 
almost  as  much  availability  as  redundant  processor 
schemes. DIVA uses much less hardware than redundant 
processors, but it incurs a signiﬁcant performance pen-
alty  for  recovery  every  time  a  fault  is  exercised.  This 
recovery  penalty  can  be  particularly  problematic  for 
hard faults in heavily used circuits, such as the reorder 
buffer  or  instruction  queue.  Ideally,  we  would  like  to 
enhance DIVA to mask hard faults so that they do not 
lead to frequent, slow recoveries. 
In  this  paper,  we  develop  a  lightweight  hardware 
technique,  called  Self-Repairing  Array  Structures 
(SRAS), that enables a microprocessor with DIVA to tol-
erate a broad class of hard faults without incurring fre-
quent  performance-degrading  recoveries.  SRAS  masks 
hard faults in array structures within the microprocessor, 
so  that  DIVA  recovery  does  not  have  to  be  invoked. 
Microprocessors contain many large array structures—
including  both  buffers  and  tables,  such  as  the  reorder 
buffer (ROB) and the branch history table (BHT)—and 
our goal is to tolerate hard faults in rows of these struc-
tures. To detect and diagnose row errors, every write to a 
row is mirrored to a dedicated “check row.” We can then 
read  out  both  the  written  row  and  the  check  row  and 
compare  their  results  to  detect  errors.  To  dynamically 
repair hard faults in rows, we extend a technique used in 
the context of disks and memories, in which faulty por-
tions  of  arrays  can  be  mapped  out  by  using  a  level  of 
indirection. While our high-level design logically uses a 
level of indirection, which could degrade processor per-
formance, we present a detailed implementation that can 
optimize certain critical paths. In particular, for buffers 
that are not randomly addressable, we present an imple-
mentation that incurs no performance penalty. 
To evaluate our idea, we simulate a microprocessor 
with our hard fault tolerance mechanisms, and we com-
pare its performance to unmodiﬁed DIVA (i.e., without 
SRAS). We inject several representative types of faults 
into  the  simulated  microprocessor.  Results  show  that 
adding  SRAS  to  DIVA  enables  a  microprocessor  to 
achieve  performance  close  to  the  fault-free  scenario 
despite  the  injection  of  hard  faults  into  certain  array 
structures.
2  Background
In  this  section,  we  provide  a  brief  background  in 
existing  techniques  for  tolerating  hard  faults  in  micro-
processors,  before  delving  into  the  details  of  our  fault 
model.
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 11:51:42 UTC from IEEE Xplore.  Restrictions apply. 
2.1  Existing Approaches
There  are  several  existing  techniques  for  compre-
hensively tolerating hard faults in microprocessor cores. 
The  most  obvious  approach  is  forward  error  recovery 
(FER) via the use of redundant microprocessors in par-
allel,  e.g.,  triple  modular  redundancy  (TMR).  For 
extreme reliability, this is an effective but not cost-efﬁ-
cient solution. IBM mainframes [22], Tandem S2 [11], 
and Stratus [24] are examples of systems that use redun-
dant  processors  to  mask  hard  faults.  Mainframes  also 
replicate  certain  structures  within  the  processors  to 
increase reliability [22]. The drawback of these schemes 
is the large added hardware expense and power usage of 
the redundant hardware. For non-mission-critical appli-
cations, this solution is not preferred.
Cost-effective approaches for comprehensively tol-
erating  hard  faults  can  be  far  less  expensive,  but  they 
often  sacriﬁce  performance  in  the  presence  of  hard 
faults. DIVA [3] protects a fast, aggressive processor—
from  both  hard  and  soft  faults—with  a  small,  simple, 
on-chip  checker  processor.  The  checker  processor  is 
simple enough that the designers could formally prove 
that its design is correct. The checker processor sits at 
the commit stage of the aggressive processor and com-
pares the results of its execution of each instruction to 
the result of execution on the aggressive processor. If the 
results differ, the checker assumes that it is correct and 
uses its result. This assumption is based on the provably 
correct design of the checker and its relatively small size 
with respect to the aggressive processor. To prevent the 
fault  in  the  aggressive  processor  from  propagating  to 
later instructions, DIVA then ﬂushes the aggressive pro-
cessor’s pipeline. In the fault-free scenario, the perfor-
mance of the system is virtually equal to that of the fast 
aggressive  processor,  since  the  simple  checker  can 
leverage  the  faster  processor  as  a  pre-fetch  engine. 
DIVA’s  small  amount  of  redundancy  is  far  less  expen-
sive  and  power  hungry  than  TMR,  but  it  has  a  perfor-
mance  penalty  for  each  error  it  detects.  Every  time  a 
hard fault manifests itself as an error, the performance of 
the  system  temporarily  degenerates  to  that  of  the 
checker  processor  until  the  aggressive  processor  reﬁlls 
its pipeline, since the aggressive processor cannot help 
it. The checker processor is very slow—the DIVA paper 
reports  that  performance  will  degrade  appreciably  for 
error rates greater than one per thousand instructions. In 
the presence of hard faults that could get exercised fre-
quently, performance will suffer. 
Cost-effective  approaches  for  tolerating  only  spe-
ciﬁc  classes  of  hard  faults  also  exist.  One  approach  is 
the use of error correcting codes (ECC). ECC can toler-
ate up to a targeted number of faulty bits in a piece of 
data, and it is a useful technique for protecting SRAM, 
DRAM,  buses,  etc.,  from  this  fault  model.  However, 
ECC  cannot  tolerate  more  than  a  certain  number  of 
faulty bits, nor can it be implemented quickly enough to 
be a viable solution for many performance-critical struc-
tures in a microprocessor. More general approaches for 
tolerating hard faults in memory storage are discussed in 
Section 3, since they are similar to SRAS. 
2.2  Hard Fault Model
Several structural fault models have been developed 
for logic circuits and storage components over the past 
few  decades  [1].  The  stuck-at  fault  model  is  the  most 
commonly used model in VLSI testing and fault toler-
ance  schemes.  In  the  stuck-at  fault  model,  a  physical 
defect manifests itself as a signal consistently having a 
certain  value  (either  zero  or  one)  independent  of  the 
input.  The  coupling  fault  model  has  been  recently 
deﬁned for storage components [5]. For coupling faults, 
a write to a certain memory location always prompts a 
write to a neighboring location or locations. 
In SRAS, we use check rows to determine whether 
data that is written into a row can be read out correctly. 
In  this  sense,  the  fault  detection  and  repair  scheme  of 
SRAS  is  independent  of  the  underlying  physical  fault 
model. A fault is detected as soon as it is excited. How-
ever,  in  order  to  study  the  impact  of  SRAS  on  overall 
operation,  we  need  to  inject  physical  faults.  We  inject 
single-bit and all-bits stuck-at faults within a given row 
of an array. The all-bits stuck-at-x fault is equal to the 
all-neighbors coupling fault when the write variable is x.
While single-bit stuck-at faults could be tolerated with 
ECC,  albeit  with  a  likely  performance  penalty,  all-bits 
stuck-at faults require a different approach. 
3  High-Level View of SRAS
Technology and microprocessor architecture trends 
are leading towards larger array structures within micro-
processors.  These  structures  include  the  instruction 
queue,  reorder  buffer  (ROB),  register  ﬁle,  reservation 
stations, register map table, branch history table (BHT), 
etc. We would like to protect these structures from hard 
faults  as  the  probability  of  hard  faults  continues  to 
increase,  but  we  cannot  afford  to  replicate  these  struc-
tures.  Instead,  we  combine  DIVA’s  cost-efﬁcient  fault 
tolerance with a small amount of hardware that detects, 
diagnoses,  and  masks  hard  faults  in  these  array  struc-
tures. SRAS ensures that the performance of DIVA does 
not  suffer  in  the  presence  of  hard  faults  in  frequently 
accessed array structures. 
We seek to protect these array structures in a fash-
ion  similar  to  the  way  in  which  existing  on-line 
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 11:51:42 UTC from IEEE Xplore.  Restrictions apply. 
data
address
address
decode
remap
storage
array
fault
info
FIGURE 1.
Array Remapping
(dynamic)  techniques  protect  large  memory  storage 
structures. The basic idea is to use a level of indirection 
to map out faulty portions of the structure. Especially as 
structures  grow  larger,  the  probability  of  a  hard  fault 
within them increases. Disk sizes, for example, long ago 
reached the point at which hard faults were expected and 
had to be tolerated. Whole disk failures were addressed 
by RAID [18]. For disk faults that did not incapacitate 
the entire disk, the solution was to map out faulty por-
tions  of  them  at  the  sector  granularity.  Thus,  a  faulty 
disk  could  continue  to  operate  correctly,  albeit  at  a 
smaller  effective  size.  Similar  approaches  have  been 
developed  for  DRAM  main  memory.  Whole  chip  fail-
ures are tolerated by chipkill memory and RAID-M [7, 
10], and partial failures are tolerated with schemes that 
map out faulty locations [6, 13, 19]. For SRAM caches, 
techniques  have  been  developed  to  map  out  defective 
locations  during  fabrication  [26]  and,  more  recently, 
during  execution  [16].  While  providing  insight  for  the 
use of spare memory locations for repair, direct applica-
tion of the aforementioned methods to array structures 
within the processor bears little hope due to the perfor-
mance criticality within microprocessors.
3.1  Mapping Out Faulty Rows
We logically add a level of indirection that can map 
out  faulty  rows  in  microprocessor  array  structures,  as 
shown in Figure 1. The remapper serves as the interface 
between  the  array  and  the  rest  of  the  microprocessor. 
There are numerous implementation issues to address in 
this design, including how to add the remapper into the 
pipeline, and we discuss them in Section 4.
3.2  Detecting and Diagnosing Faulty Rows
While DIVA can detect errors in processor execu-
tion due to faulty rows, it cannot isolate the row or even 
the structure that is faulty. DIVA only checks end-to-end 
correctness,  which  is  sufﬁcient  for  detection  but  not 
diagnosis. Thus, in conjunction with remapping to toler-
ate detected faults, SRAS incorporates a simple scheme 
for  detecting  row  errors  and  diagnosing  which  row  is 
faulty.  SRAS  adds  a  handful  of  check  rows  (some  are 
spares, which are used to avoid a single point of failure) 
to each structure we wish to protect. Every time an entry 
is  written  to  the  array  structure,  the  same  data  is  also 
written  into  a  check  row.  Immediately  after  the  two 
writes, both locations are read and their data are com-
pared (all off the critical path of execution). If the data 
differ,  then  one  of  the  rows  is  faulty.  Several  options 
exist  for  determining  which  one  is  faulty,  and  we  will 
explain a simple one after we ﬁrst describe the mecha-
nism we exploit for distinguishing hard faults from soft 
faults.  SRAS  maintains  small  saturating  counters  for 
each  row,  which  are  periodically  reset,  and  a  counter 
value above a threshold identiﬁes a hard fault. Now, to 
determine  if  the  operational  row  or  the  check  row  is 
faulty, we can simply increment both of their counters in 
the case of a mismatch in their values, as long as we ini-
tially  set  the  threshold  for  check  row  counters  to  be 
much higher than that for operational rows.
3.3  SRAS Operation
If an error is detected, but the hard fault threshold 
has not yet been reached, then the fault is considered to 
be transient and it is tolerated by DIVA with its associ-
ated performance penalty. If the detected error raises the 
counter to the hard fault threshold, then DIVA also toler-
ates this fault, but the system then repairs itself so as to 
prevent this hard fault from being exercised again. The 
repair actions taken depend on whether the faulty row is 
a non-check row or a check row. If it is a non-check row, 
then it can be immediately mapped out and a spare row 
can be mapped in to take its place. The spare row can 
get the correct data from the check row. If the faulty row 
is a check row, then SRAS maps in a spare check row. 
4  SRAS Implementation
In Section 3, we described SRAS at a high level. In 
this  section,  we  delve  into  the  implementation  issues. 
We develop several implementation variations of differ-
ent  aspects  of  SRAS,  and  we  discuss  the  various  pros 
and cons. Tolerating the faults and detecting/diagnosing 
them are mostly independent issues, from an implemen-
tation  standpoint,  so  we  split  our  discussion  into  these 
two topics (Section 4.1 and Section 4.2, respectively). In 
Section 4.3,  we  discuss  the  costs  of  SRAS,  and  in 
Section 4.4, we discuss the limitations of this implemen-
tation.
We  can  classify  array  structures  within  the  micro-
processor  core  into  two  categories:  non-addressable 
buffers for which the data location is determined at the 
time  of  access,  and  randomly  addressable  tables  for 
which the data location is determined before access. In 
order  to  allow  timing  efﬁcient  implementation  of  the 
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 11:51:42 UTC from IEEE Xplore.  Restrictions apply. 
repair  logic,  we  exploit  these  distinct  features  of  each 
type of array structures. Without loss of generality, we 