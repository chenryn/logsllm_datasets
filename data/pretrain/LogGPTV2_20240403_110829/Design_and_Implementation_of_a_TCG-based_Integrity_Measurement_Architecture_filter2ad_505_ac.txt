in Fig 2). Both are then returned to the attesting party in step
5. Finally, the attesting party can validate the information
Figure 2: TPM-based Integrity Measurement
and reason about the trustworthiness of the attesting system’s
run-time integrity in step 6.
4.1 Assumptions
Before we describe these three components of our architec-
ture, we establish assumptions about the attacker model be-
cause without such restrictions, there would always be attack-
ers that are able to fool a remote client.
We use services and protection offered by the TCG stan-
dards [11] in order to:
(1) enable challenging parties to
establish trust into the platform conﬁguration of the attest-
ing system (measurement environment) and (2) ensure chal-
lengers that the measurement list compiled by the measure-
ment environment has not been tampered with. We assume
that the TPM hardware works according to the TPM speci-
ﬁcations [11] and that the TPM is embedded correctly into
the platform, ensuring the proper measurement of the BIOS,
bootloader, and following system environment parts.
The TPM cannot prevent direct hardware attacks against
the system, so we assume that these are not part of the threat
model.
We assume that code measurements are sufﬁcient to de-
scribe its behavior. Thus, self-changing code can be evalu-
ated because the intended ability of code to change itself is
reﬂected in the measurement and can be taken into account
in veriﬁcation. The same holds for the kernel code that is
thought to be changed only through loading and unloading
modules. Kernel changes based on malicious DMA transfers
overwriting kernel code are not addressed; however, the code
setting up the DMA is measured and thus subject to evalua-
tion.
We also assume that the challenging party holds a valid and
trusted certiﬁcate binding a public RSA identity key AIKpub
of the attesting system’s TPM. AIKpub will be used by the
challenging party to validate the quoted register contents of
the attesting system’s TPM before using those registers to val-
idate the measurement list.
We assume that there are no conﬁdentiality requirements
on measurement data that cannot be satisﬁed by controlling
MeasurementAgentTPMPlatform Configuration Register 0Platform Configuration Register N...MeasurementAgentMeasurementAgentsTrusted BIOSMeasurementsReportb) Report2. QuoteReqKernel + Run-Time + File SystemsTrusted PlatformAttestationService1. IntegrityChallenge5. IntegrityResponse3. QuoteResMeasurementLista) Store4. RetrieveChallenger6. validateResponseAttesting System Platformthe access to the attestation service.
Finally, for the interpretation of system integrity measure-
ments, we rely on the challenger’s run-time because the val-
idation results must be securely computed, interpreted, and
acted upon. We assume that the challenger can safely decide
which measurements to trust either by comparing them to a
list of trusted measurements or by off-loading the decision to
trusted parties that sign trusted measurements according to a
common policy (i.e., common evaluation criteria).
4.2 Measurement Mechanism
Our measurements mechanism consists of a base measure-
ment when a new executable is loaded and the ability to mea-
sure other executable content and sensitive data ﬁles. The
idea is that BIOS and bootloader measure the initial kernel
code and then enable the kernel to measure changes to itself
(e.g., module loads) and the creation of user-level processes.
The kernel uses the same approach with respect to user-
level processes, where it measures the executable code loaded
into processes (e.g., dynamic loader and httpd loaded via
mmap). Then, this code can measure subsequent security sen-
sitive inputs it loads (e.g., conﬁguration ﬁles or scripts mea-
sured by httpd). The challenger’s trust is dependent on its
trust in the measured code to measure its security sensitive in-
puts, protect itself from unmeasured inputs, and protect data
it is dependent upon across reboots. The operating system
can provide further protection of applications through manda-
tory access control policy which can limit the sources of mali-
cious, unmeasured inputs and protect data from modiﬁcation.
However, the use of such policy is future work.
In this section, we discuss how measurements are made.
The application of these measurements to a complete mea-
surement system is described in Section 5.
To uniquely identify any particular executable content, we
compute a SHA1 hash over the complete contents of the ﬁle.
The resulting 160bit hash value unambiguously identiﬁes the
ﬁle’s contents. Different ﬁle types, versions, and extensions
can be distinguished by their unique ﬁngerprints.
The individual hashes are collected into a measurement list
that represents the integrity history of the attesting system.
Modiﬁcations to the measurement list are not permissible as
that would enable an attacker to hide integrity-relevant ac-
tions. As our architecture is non-intrusive, it does not prevent
systems from being corrupted, nor does it prevent the mea-
surement list from being tampered with afterwards. How-
ever, to prevent such malicious behavior from going unno-
ticed (preventing corrupted systems from cheating), we use a
hardware extension on the attesting system, known as Trusted
Platform Module, to make modiﬁcations of the measurement
list visible to challenging parties.
The TPM [11] provides some protected data registers,
called Platform Conﬁguration Registers, which can be
changed only by two functions: The ﬁrst function is reboot-
ing the platform, which clears all PCRs (value 0). The sec-
ond function is the T P M extend function, which takes one
160bit number n and the number i of a PCR register as ar-
guments and then aggregates n and the current contents of
PCR[i] by computing a SHA1(PCR[i] || n). This new value
is stored in PCR[i]. There is no other way for the system to
change the value of any PCR register, based on our assump-
tions that the TPM hardware behaves according to the TCG
speciﬁcation and no direct physical attacks occur.
We use the Platform Conﬁguration Registers to maintain
an integrity veriﬁcation value over all measurements taken by
our architecture. Any measurement that is taken is also ag-
gregated into a TPM PCR (using T P M extend) before the
measured component can affect and potentially corrupt the
system. Thus, any measured software is recorded before tak-
ing control directly (executable) or indirectly (static data ﬁle
of the conﬁguration). For example, if i measurements m1..mi
have been taken, the aggregate in the chosen PCR contains
SHA1(..SHA1(SHA1(0||m1)||m2)..||mi). The protected
storage of the TPM prevents modiﬁcation by devices or sys-
tem software. While it can be extended with other chosen
values by a corrupted system, the way that the extension is
computed (properties of SHA1) prevents a malicious system
from adjusting the aggregate in the PCR to represent a pre-
scribed system. Once a malicious component gains control,
it is too late to hide this component’s existence and ﬁngerprint
from attesting parties.
Thus, corrupted systems can manipulate the measurement
list, but this is detected by re-computing the aggregate of the
list and comparing it with the aggregate stored securely inside
the TPM.
4.3
Integrity Challenge Mechanism
The Integrity Challenge protocol describes how challenging
parties securely retrieve measurements and validation infor-
mation from the attesting system. The protocol must protect
against the following major threats when retrieving attesta-
tion information:
• Replay attacks: a malicious attesting system can replay
attestation information (measurement list + TPM aggre-
gate) from before the system was corrupted.
• Tampering: a malicious attesting system or intermedi-
ate attacker can tamper with the measurement list and
TPM aggregate before or when it is transmitted to the
challenging party.
• Masquerading: a malicious attesting system or interme-
diate attacker can replace the original measurement list
and TPM aggregate with the measurement list and TPM
aggregate of another (non-compromised) system.
We assume that this mechanism is used over a secure (e.g.,
SSL-authenticated and protected) connection to guarantee au-
thenticity and conﬁdentiality requirements. Fig. 3 depicts the
integrity challenge protocol used by the challenging party C
to securely validate integrity claims of the attesting system
AS.
In steps 1 and 2, C creates a non-predictable 160bit
random nonce and sends it in a challenge request message
ChReq to AS. In step 3, the attesting system loads a pro-
tected RSA key AIK into the TPM. This AIK is encrypted
with the so-called Storage Root Key (SRK), a key known only
to the TPM. The TPM speciﬁcation [11] describes, how a
2048-bit AIK is created securely inside the TPM and how the
corresponding public key AIKpub can be securely certiﬁed
by a trusted party. This trusted party certiﬁcate links the sig-
nature of the PCR to a speciﬁc TPM chip in a speciﬁc system.
Then, the AS requests a Quote from the TPM chip that now
signs the selected P CR (or multiple PCRs) and the nonce
originally provided by C with the private key AIKpriv. To
complete step 3, the AS retrieves the ordered list of all mea-
surements (in our case from the kernel). Then, AS responds
with a challenge response message ChRes in step 4, includ-
ing the signed aggregate and nonce in Quote, together with
the claimed complete measurement list M L.
1. C : create non-predictable 160bit nonce
2. C → AS : ChReq(nonce)
3a. AS : load protected AIKpriv into TPM
3b. AS : retrieve Quote = sig{P CR, nonce}AIKpriv
3c. AS : retrieve Measurement List M L
4. AS → C: ChRes(Quote, M L)
5a. C : determine trusted cert(AIKpub)
5b. C : validate sig{P CR, nonce}AIKpriv
5c. C : validate nonce and M L using P CR
Figure 3: Integrity Challenge Protocol
In step 5a, C ﬁrst
retrieves a trusted certiﬁcate
cert(AIKpub). This AIK certiﬁcate binds the veriﬁcation
key AIKpub of the QU OT E to a speciﬁc system and states
that the related secret key is known only to this TPM and
never exported unprotected. Thus masquerading can be dis-
covered by the challenging party by comparing the unique
identiﬁcation of AS with the system identiﬁcation given in
cert(AIKpub). This certiﬁcate must be veriﬁed to be valid,
e.g., by checking the certiﬁcate revocation list at the trusted
issuing party. C then veriﬁes the signature in step 5b.
In step 5c, C validates the freshness of the QU OT E and
thus the freshness of the P CR (the measurement aggregate).
Freshness is guaranteed if the nonces match as long the nonce
in step 2 is unique and not predictable. As soon as AS re-
ceives a nonce twice or can predict the nonce (or predict even
a small enough set into which the nonce will fall), it can
decide to replay old measurements or request TPM-signed
quotes early using predicted nonces. In both cases, the quoted
integrity measurements M L might not reﬂect the actual sys-
tem status, but a past one.
If the nonce offers insufﬁcient
security, then the validity of the signature keys can be re-
stricted, because the replay window for signed aggregates is
also bound to using a valid signature key.
Validating the signature in step 5b, C can detect tampering
with the TPM aggregate, because it will invalidate the sig-
nature (assuming cryptographic properties of a digital 2048-
bit signature today, assuming the secret key is known only
to the TPM, and assuming no hardware tampering of the
TPM). Tampering with the measurement list is made visible
in step 5c by walking through the measurement list M L and
re-computing the TPM aggregate (simulating the TPM ex-
tend operations as described in Section 4.2) and comparing
the result with the TPM aggregate P CR that is included in
the signed Quote received in step 4. If the computed aggre-
gate matches the signed aggregate, then the measurement list
is valid and untampered, otherwise it is invalid.
4.4
Integrity Validation Mechanism
The challenging party must validate the individual measure-
ments of the attesting party’s platform conﬁguration and the
dynamic measurements that have taken place on the attest-
ing system since it has been rebooted. The aggregate for the
conﬁguration and the measurement list has already been val-
idated throughout the integrity challenge protocol and is as-
sumed here. The same holds for the validity of the TPM ag-
gregate.
Concluding whether to trust or distrust an attesting sys-
tem is based on testing each measurement list entry indepen-
dently, comparing its measurement value with a list of trusted
measurement values. More sophisticated validation models
can relate multiple measurements to reach an evaluation re-
sult. Testing measurement entries is logically the same re-
gardless of whether the entry is code or data. The idea is that
the entry matches some predeﬁned value that has known in-
tegrity semantics. Unknown ﬁngerprints can result from new
program versions, unknown programs, or otherwise manipu-
lated code. As such, ﬁngerprints of program updates can be
measured by the challenging party and added to the database;
in turn, old program versions with known vulnerabilities [15]
might be reclassiﬁed to distrusted.
The challenging party must have a policy in place that
states how to classify the ﬁngerprints and how to proceed
with unknown or distrusted ﬁngerprints. Usually, a distrusted
ﬁngerprint leads to distrusting the integrity of the whole at-
testing system if no additional policy enforcement mecha-
nisms guarantee isolation of the distrusted executable. Al-
ternatively, trustworthy ﬁngerprints can be signed by trusted
third parties, e.g., regarding their suitability to enforce certain
security targets (Common Criteria Evaluation) related to their
purpose.
Transaction Integrity Usually, the integrity of the attest-
ing system is of interest when it processes a transaction that
is important to a challenging party. To verify the integrity
of a transaction that is taking place between the challenging
and the attesting party (e.g., a Web request), the challenging
party can challenge the integrity of the attesting system before
and after the transaction was processed, e.g., before sending
the Web request and after receiving the Web response. Then,
the attestation and the transaction can be bound to the same
system by securely linking the certiﬁcate used to validate the
TPM quote and the certiﬁcate used to authenticate the server
during the SSL connection setup as part of the Web request.
If the attesting system is trusted both times, then– so it seems
–the transaction can be trusted, too.
This is, however, not entirely true because it assumes that
both measurements have taken place in the same epoch (va-
lidity period), i.e., that any system change throughout the
transaction would have been recorded in the second measure-
ment. However, the attesting system could have been com-
promised just after the ﬁrst challenge and before the trans-
action took place. Then, the attesting system could have re-
booted before the second challenge took place. Thus, though
trusted at two points in time, the reboot covered the distrusted
attesting system state against the challenger. Even if the pos-
sibility seems small, systems can reboot very fast and actually
come up into an exactly pre-deﬁned state (thus exhibiting the
same measurement list as in earlier measurements) 1.
Fortunately, there is a way to discover if an epoch changes,
i.e., whether the system rebooted between two attestations.
For this purpose, we can use so-called TPM counters. As op-