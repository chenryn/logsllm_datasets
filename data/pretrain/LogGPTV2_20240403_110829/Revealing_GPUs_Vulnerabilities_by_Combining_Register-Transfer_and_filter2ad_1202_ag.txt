### Types and Averaging of Results
We consider three types (Max, Zero, and Random tiles), averaging the results obtained with four values per each input type. For t-MxM, we inject faults into the scheduler and pipeline registers but not in the functional units. As shown in Figure 4, faults in the functional units would not cause multiple thread corruptions in t-MxM (since there are no transcendental operations). The effects of single-thread SDCs would be the same as those observed by injecting the FU syndrome in software, without the need for costly RTL injection.

### Average AVF for DUEs and Corrupted Elements
Figure 7 shows the average Architectural Vulnerability Factor (AVF) for Detected Unrecoverable Errors (DUEs), single, and multiple corrupted elements in the t-MxM output for injections in the scheduler and pipeline. We note that we inject one fault per execution, and multiple corrupted elements result from the propagation of a single fault.

A significant difference from the micro-benchmarks' AVF in Figure 4 is that, for t-MxM, the scheduler AVF is higher than the pipeline AVF. This is because, while micro-benchmarks are simple and do not implement thread interactions, t-MxM includes several instructions for computing memory addresses and thread indices. The increased strain on the scheduler and the longer time spent in scheduling operations increase the AVF (for both SDCs and DUEs). Conversely, the pipeline AVF is higher in micro-benchmarks because a fault at the first instruction output is marked as an SDC, with no further chance to be masked (as there are no subsequent computations). In t-MxM, a wrong instruction output can be masked in a downstream operation (e.g., by multiplication with zero). This is supported by our pipeline data in Figure 7, which shows a much lower SDC AVF for the Z tile.

### Multiple SDCs and Geometrical Distribution
An additional interesting result from Figure 7 is that a high portion of SDCs affect multiple elements (at least 70% of scheduler-induced and 50% of pipeline-induced SDCs). To further study these multiple errors, we visualize the geometrical distribution of the corrupted elements. Figure 8 plots six different spatial patterns of multiple corrupted elements observed when injecting faults in the scheduler and pipeline registers. These patterns include: a row, a column, a row and a column, a block of elements (of varying sizes), random, and all (or almost all) elements corrupted. Table II lists the percentage of occurrences of these patterns (excluding single SDCs). Since the distribution of these patterns is similar across the three inputs (M, Z, R tiles), we list the average distributions. Pipeline injection mostly produces corrupted rows, while scheduler injection is more likely to affect the entire output matrix. Whole-column corruption is very unlikely for both injection sites due to the row-major calculation in t-MxM and the interplay between hardware and software error propagation. Although this distribution is not generic, the extended evaluation of t-MxM is crucial due to its importance in Convolutional Neural Networks (CNNs). As shown in [28], [29], multiple error patterns (but not single element corruptions) can induce misdetections in CNNs.

### Characterization of t-MxM Syndrome
We have also characterized the syndrome of t-MxM. Most syndromes are concentrated in a few values, following a power-law distribution. Figure 9 plots the relative error distribution for two examples: a row and a block error. The relative error distribution varies among the corrupted elements. To inject the t-MxM syndrome in software, we use Equation 1 to select the range of relative errors for all elements to corrupt, again using a power-law distribution for individual output elements.

### Real-World Applications Evaluation
In this section, we present the results obtained by injecting, in software, the fault syndromes discussed previously. We inject at least 6,000 syndromes per application, totaling over 48,000 injections that took 350 GPU hours, ensuring 95% confidence intervals below 5%. The specially crafted NVBiTFI version selects the most suitable fault syndrome based on the opcode, input, and the assumed fault-causing module. For this paper, we inject a cocktail of fault syndromes following the power-law distribution described in Section IV-B and depicted in Figures 5 and 6. While it is possible to focus software fault injection on a specific module or tune the syndrome injection with probabilities for different modules and/or instructions, such an evaluation requires area information and raw probabilities for transient faults, which are not publicly available and can only be measured through beam experiments.

### Selected Applications and PVF
We selected a set of applications listed in Table III, representative of different High-Performance Computing (HPC) computational classes: Floating Matrix Multiplication (MxM), Lower Upper Decomposition (LUD), Quicksort, particle simulation (Lava), Gaussian elimination, and fluid dynamics (Hotspot). We also considered CNNs for classification and object detection (LeNET and YoloV3). Each code stimulates specific GPU modules according to the opcode distribution in Figure 3, making the results representative for similar applications.

While NVBitFI can inject faults in multiple threads and the RTL fault syndrome includes information about multiple SDCs, we decided to inject only single-thread SDCs using our fault syndrome to better compare with traditional single bit-flip evaluation. This highlights the accuracy of random single bit-flip injection compared to the RTL fault syndrome. For CNNs, we also included an RTL fault-injection on the execution of t-MxM to evaluate the effects of scheduler faults and multiple thread corruptions in object detection and classification.

Figure 10 and Table III show the SDC Program Vulnerability Factor (PVF) for the HPC codes. PVF is the probability that faults injected in the software's visible states generate an SDC at the end of execution. We inject only in the 12 opcodes characterized by RTL fault injection, representing over 70% of all executed opcodes, as shown in Figure 3. RTL faults that generate DUEs (shown in Figure 4) are not considered in software fault injection, as they simply hang the application. We never observed DUEs caused by the injection of syndromes from RTL injections, mainly because GPU applications are highly data-intensive and avoid data-driven condition statements, making it hard for a data error to affect the control flow.

To compare our analysis with traditional fault injection, we consider two error models: single bit-flip (randomly injected in the 32-bit values) and the fault syndrome (injected using the power-law distribution) from RTL injection. For all codes presented in Figure 10, the fault syndrome model generates a higher or equal PVF compared to the traditional single bit-flip error model. Interestingly, we observe that single bit-flip injection would...