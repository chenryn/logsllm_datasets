title:PrivacyFlash Pro: Automating Privacy Policy Generation for Mobile
Apps
author:Sebastian Zimmeck and
Rafael Goldstein and
David Baraka
PrivacyFlash Pro: Automating Privacy Policy
Generation for Mobile Apps
Sebastian Zimmeck, Rafael Goldstein and David Baraka
Department of Mathematics and Computer Science, Wesleyan University
{szimmeck, rgoldstein01, dbaraka}@wesleyan.edu
Abstract—Various privacy laws require mobile apps to have
privacy policies. Questionnaire-based policy generators are in-
tended to help developers with the task of policy creation.
However, generated policies depend on the generators’ designs as
well as developers’ abilities to correctly answer privacy questions
on their apps. In this study we show that policies generated with
popular policy generators are often not reﬂective of apps’ privacy
practices. We believe that policy generation can be improved
by supplementing the questionnaire-based approach with code
analysis. We design and implement PrivacyFlash Pro, a privacy
policy generator for iOS apps that leverages static analysis.
PrivacyFlash Pro identiﬁes code signatures — composed of
Plist permission strings, framework imports, class instantiations,
authorization methods, and other evidence — that are mapped to
privacy practices expressed in privacy policies. Resources from
package managers are used to identify libraries.
We tested PrivacyFlash Pro in a usability study with 40 iOS
app developers and received promising results both in terms
of reliably identifying apps’ privacy practices as well as on
its usability. We measured an F-1 score of 0.95 for identifying
permission uses. 24 of 40 developers rated PrivacyFlash Pro with
at least 9 points on a scale of 0 to 10 for a Net Promoter Score of
42.5. The mean System Usability Score of 83.4 is close to excellent.
We provide PrivacyFlash Pro as an open source project to the
iOS developer community. In principle, our approach is platform-
agnostic and adaptable to the Android and web platforms as well.
To increase privacy transparency and reduce compliance issues
we make the case for privacy policies as software development
artifacts. Privacy policy creation should become a native extension
of the software development process and adhere to the mental
model of software developers.
I.
INTRODUCTION
Legislators around the world are enacting new privacy laws
to increase privacy protection online. Recent lawmaking activ-
ities stateside include Vermont’s Data Broker Regulation [Act
171 of 2018] and Nevada’s right of consumers to request their
information not being sold [SB 220]. Notably, California’s
enactment of the California Consumer Privacy Act [CCPA] is
the most comprehensive online privacy law in the US to date.
Many laws are based on notice and choice: users are notiﬁed
of applicable privacy practices and given the choice to opt
out; at least by not using a service. The instrument to convey
notice is the privacy policy, which serves as a manifestation of
the privacy practices an app developer is accountable for. App
Network and Distributed Systems Security (NDSS) Symposium 2021
21-25  February  2021, Virtual 
ISBN  1-891562-66-5
https://dx.doi.org/10.14722/ndss.2021.24100
www.ndss-symposium.org
developers can be subject to a host of privacy requirements
they have to disclose in their policies. They are also subject
to contractual privacy obligations. For example, the Apple
Developer Program License Agreement requires developers to
provide a policy explaining how they collect, use, disclose,
share, retain, and delete user and device data [9].
While app developers are often required to provide a
privacy policy, many are actually not familiar with the privacy
implications of their apps and the laws they have to comply
with [14]. Especially, individual developers and smaller organi-
zations with fewer employees and resources are often not able
to devote time or money to privacy considerations and may
need additional help with drafting privacy policies [14]. Con-
sequently, there is often a substantial disconnect between how
privacy practices are described in privacy policies and apps’
actual behavior [86]. This disconnect can lead to compliance
issues and is particularly prevalent for the use of permissions
by the developer and third parties as well as the integration
of third party libraries [86]. A recent study of 13,796 Android
apps and their privacy policies found that up to 42.4% of apps
either incorrectly disclose or omit disclosing their privacy-
sensitive data ﬂows [6].
Questionnaire-based policy generators promise a low-cost
solution to the problem of writing legally compliant privacy
policies. Such generators, available for web and mobile apps,
prompt developers with a set of privacy-related questions on
their apps and generate policies based on the supplied answers.
An estimated 25% of Android app developers make use of such
generators [66]. In addition to alleviating developers from the
task of writing privacy policies, questionnaire-based generators
may be advantageous from the users’ perspective as well. The
standardized language and format may make it more con-
venient to compare different policies. Generated policies are
also easier to analyze automatically. However, questionnaire-
based policy generators have fundamental limitations. They are
necessarily reliant on the correctness of answers provided by
the developers, which creates a risk of inaccurate policies due
to wrong or missing answers. Design ﬂaws in a generator may
reﬂect in the policies as well.
We propose to combine questionnaire- and code-based pol-
icy generation. Source code can be understood as a semantics-
rich documentation of an app’s privacy practices [48]. Thus,
app code, including code of integrated libraries, can serve as
the starting point for a privacy policy that is a traceable and
faithful representation of how an app behaves [85]. However,
while code analysis helps aligning policy disclosures with
actual app behavior, it still remains necessary to query the
developer for some input. For example, for how long personal
information is retained or whether an app is subject to the
CCPA cannot be solely derived from an app’s codebase. Com-
bining static code analysis and a questionnaire-based wizard
with templates, we implemented PrivacyFlash Pro, a privacy
policy generator for iOS apps written in Swift and integrated
Swift and Objective-C libraries. We demonstrate our idea for
iOS, but the same principles apply to Android, cross-platform
frameworks (e.g., React Native), and web apps. We believe that
especially indie developers, freelance developers, and startups
would beneﬁt the most from our work.
We believe that privacy policies should be recognized as
software development artifacts [85]. The integration of legal
requirements into the software development process enables
compliance traceability, that is, the ability to link requirements
originating from privacy laws to their corresponding software
implementations. This link strengthens the synchronization
between privacy-by-policy and privacy-by-architecture [23].
Just as for software licenses, an area where legal considerations
became part of the software development process, privacy poli-
cies can be selected, created, and maintained by developers. In
order for developers to perform this new task well it is crucial
to design it based on their mental model. Certainly, policy
generation will not eliminate the work of lawyers in all cases.
For complex apps and apps with unusual privacy practices it
will still be necessary to create individualized privacy policies.
However, for the average app with standard permission uses
and third party library integrations automating privacy policy
generation holds the promise of increased privacy compliance
and traceability. Thus,
in this study, we are making the
following contributions:
(1) We analyze the extent
to which the use of popular
questionnaire-based privacy policy generators helps iOS
app developers to accurately disclose the privacy prac-
tices of their apps. Our results suggest that many apps
behave differently than described and that the examined
generators are inherently limited by their design and the
exclusive reliance on their questionnaire-based approach.
(§ III).
(2) We design and implement PrivacyFlash Pro, a privacy
policy generator for iOS apps written in Swift. Priva-
cyFlash Pro combines questionnaire-based policy genera-
tion and standardized templates with automatic detection
of privacy practices in app code via static analysis. It is
available as an open source project.1 (§ IV).
(3) We evaluate PrivacyFlash Pro in a usability study with
40 iOS app developers. The policies that the developers
generated with PrivacyFlash Pro offer better coverage of
the privacy practices of their apps than their previous
policies. The developers also reported high levels of
product usability and satisfaction. (§ V).
II. RELATED WORK
Online privacy is fundamentally based on the principle of
notice and choice.
1PrivacyFlash Pro GitHub repository, https://github.com/privacy-tech-lab/
privacyﬂash-pro, accessed: January 7, 2021.
A. Notice and Choice
Users should be notiﬁed of applicable privacy practices
and given the choice to opt out. However, oftentimes, it is
not transparent to users how mobile and web apps use and
disclose the data they collect. Especially, mobile app users
are confronted with trade-offs between privacy and usability
due to the constraints of mobile devices when setting their
notiﬁcation preferences [74]. Notiﬁcations during app use,
instead of before app use, have proven to be effective [15],
however, may also lead to notiﬁcation fatigue. Reducing the
number of privacy decisions users have to make [21] and
leveraging social interaction for privacy features [4] could help
prevent such [73]. Using comic-based privacy policies [68],
ﬂyers [36], or paraphrased terms of use [75] are creative new
ways of engaging users’ interest.
B. Privacy Policy Generators
From a developer’s perspective, writing a privacy policy
that correctly reﬂects an app’s privacy practices and keeping
the policy up-to-date as the app evolves over time can be
a challenging task. Various solutions, most of which are
commercial, generate policies based on questionnaires ﬁlled
by the developer [7], [32], [35], [41], [53], [69], [70]. PAGE, a
plugin for the Eclipse IDE, can be used to create questionnaire-
based policies during the development process [59]. However,
purely questionnaire-based generators can lead to inaccurate
representations of an app’s privacy practices if the questions
are not answered, accurately, timely, and completely. We aim
to mitigate these shortcomings by leveraging code analysis.
The closest work to ours, Polidroid-AS, is an Android
Studio plugin that combines a simple privacy questionnaire
with code analysis functionality [63]. However, different from
Polidroid-AS, PrivacyFlash Pro has the goal of creating com-
prehensive and legally compliant policies for iOS apps beyond
the text snippets of Polidroid-AS. PrivacyFlash Pro intends to
create such policies by covering provisions of the FTC Act,
Children’s Online Privacy Protection Act [COPPA], California
Online Privacy Protection Act [CalOPPA], CCPA, and General
Data Protection Regulation [GDPR]. While no performance or
usability evaluations are available for Polidroid-AS, we provide
those in a usability study with iOS app developers, most of
which are full-time professionals (§ V).
AutoPPG is another closely related work [80]. Sim-
to Polidroid-AS, AutoPPG extracts code from An-
ilar
droid apps to create short
text snippets of app behavior.
A corpus of policies collected in the wild is used for
generating snippets of the form subject verb object
[condition], which, however, entails the risk of importing
non-compliant language into the generated snippets as many
policies are not compliant with the law [5]. Different from
AutoPPG, PrivacyFlash Pro aims to create fully legally compli-
ant policies by mapping app analysis results and questionnaire
answers to standardized legal templates. In addition, our study
goes beyond both AutoPPG and Polidroid-AS with a developer
usability study and a survey of questionnaire-based generators.
PrivacyInformer, another related tool, also creates text snippets,
though, only for apps created with the MIT App Inventor [46].
Code analysis is also used to generate templates with
app privacy settings [20] and security descriptions [82]. Such
2
templates and descriptions can be helpful for users to un-
derstand and adjust the privacy and security settings of an
app. Generally, proﬁling app behavior enables uncovering
privacy practices [58]. Though, any templates, descriptions,
and proﬁles are not directly usable as privacy policies.
C. Machine-readable Privacy Policies
While natural language privacy policies emerged as the
standard for disclosing privacy practices, machine-readable
policies would make it easier for browsers and other user
agents to process and act upon on what is disclosed in policies.
The Platform for Privacy Preferences (P3P) is one of the major
works taking steps towards this direction [24], [25]. Privacy
policy languages [78], [81] that allow a developer to specify
data ﬂows and enforce constraints are an interesting area of
automating policy processing as well. However, as none of the
suggested approaches received signiﬁcant industry adoption,
the natural language policy remains the default format and
its standardization via policy generators seems a more viable
avenue for making policies machine-readable rather than using
specialized policy languages.
D. Static and Dynamic Code Analysis
In order to identify the privacy practices an app is perform-
ing PrivacyFlash Pro relies on signature-based static analysis.
In the Android ecosystem Stowaway [30] paved the way for
the static analysis of permissions. FlowDroid [11] is still the
state of the art and was extended in various studies, e.g.,
for purposes of inter-component data-ﬂow analysis to detect
privacy leaks between app components [37]. It was shown
that many apps are circumventing permissions [56]. For iOS
code analysis is much less explored. PiOS [28] is one of the
few static analysis frameworks for iOS. Fortunately, it is not
necessary for us to leverage reverse-engineering techniques as
PrivacyFlash Pro is operating on apps’ source code. Even in
compiled libraries, APIs are visible in plaintext. As many apps
include such libraries, a comprehensive privacy analysis needs
to be able to reliably identify those [13].
E. Privacy Policy Analysis
Various studies examined the extent to which information
can be extracted from privacy policies [43], [55], most no-
tably, related to opt out mechanisms [60], purposes for app
permission usages [12], and sections that are relevant under the
GDPR [71]. While recently neural networks were used for this
purposes [33], simple machine learning techniques are often
sufﬁcient due to the limited variation in policy language [84].
Especially, ﬁnancial institutions’ privacy notices are usually
based on a standard template [26].
One analysis found that mobile ﬁnancial services often do
not disclose what types of personal information they collect
and store [17]. Whether in ﬁnance or other domains,
the
disclosure of third party practices is rare. An analysis of over
200,000 website privacy policies revealed that third party data
ﬂows are disclosed in fewer than 15% of required cases [40].
While many policies have internal contradictions [5], recent
lawmaking activity seems to have a positive effect. Polices
generally became more speciﬁc in the wake of the enactment
of the GDPR [42].
F. Privacy Compliance Analysis
Beyond policy analysis, compliance analysis seeks to
identify discrepancies between privacy practices described
(or omitted) in policies and actual code functionality. Apps
are potentially non-compliant due to developers’ use of app
building frameworks that add unnecessary permissions and
API invocations, reuse of privacy-sensitive functionality by
developers in multiple apps, support of secondary undocu-
mented app functionality, or use of third party libraries [77].
Policies can be in conﬂict with third party library policies [79].
Thus, the ability to correctly distinguish between ﬁrst and third
party functionality is crucial to identify compliance issues [6]
and is accounted for in PrivacyFlash Pro. Based on linking
policy phrases to privacy-sensitive API invocations numerous
potential compliance issues were identiﬁed for a set of top
Android apps [64]. Similar ﬁndings were conﬁrmed in a large-
scale analysis of about 1 million Android apps [86].
Privacy non-compliance even persists in sensitive domains.
A set of 80 health and ﬁnance apps displayed 20 “strong”
and 10 “weak” violations where their functionality did not
align with their privacy policies [76]. To prevent violations
of Institutional Review Board policies an app platform for
enforcing such policies was proposed [83]. Ultimately, current
privacy compliance analysis approaches of mobile apps are
grounded in the notion that an app’s codebase is a semantics-
rich documentation carrying meaningful privacy-related in-
formation [48]. Thus, natural
language processing can be
applied to automatically locate program elements of interest
and perform a learning-based program structure analysis to
identify those structures that are indeed carrying sensitive
content [48].
G. App Development Practices and Tools
least one code snippet
Various development practices are impacting the privacy
behavior of apps. Most notably, many developers are includ-
ing code from Stack Overﬂow [65] or other crowdsourcing
resources in their app code. An analysis of 1.3 million An-
droid apps revealed that 15.4% contained security-related code
snippets from Stack Overﬂow and 97.9% of these contained
at
that was not secure [31]. The
ofﬁcial Android API documentation is perceived as difﬁcult
to use; informal resources appear more accessible, though,
often lead to vulnerable code [2]. Boilerplate code from app
generators includes well-known security issues, such as code
injection vulnerabilities, however, due to their blackbox nature,
developers are often unaware of these hidden problems [51].
Individual developers and smaller organizations are more likely
to run into privacy and security issues, particularly, due to