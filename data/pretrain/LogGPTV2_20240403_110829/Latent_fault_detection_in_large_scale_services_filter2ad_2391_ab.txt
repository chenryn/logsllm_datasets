properly. In this case, we compare vm to its expected value
and ﬂag machines that have signiﬁcant deviations (recall that
t∈T S(m, x(t)); see framework Step 2). The
vm = 1
T
second method for computing the p-value is used when the
expected value of the scoring function is not known. In this
case, we use the empirical mean of (cid:107)vm(cid:107) and compare the
values obtained for each of the machines to this value. Both
methods take the number of machines M into account. The
resulting p-values are the probability of one false positive or
more across T , regardless of the number of machines.
In order to prove the convergence of vm, we use the L1, L2-
bounded property of the test S, as follows:
Deﬁnition 1: A test S is L1, L2-bounded if the following
two properties hold for any two input vector sets x and x(cid:48),
and for any m and t:
1) (cid:107)S (m, x(t)) − S (m, x(cid:48)(t))(cid:107) ≤ L1.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:20:08 UTC from IEEE Xplore.  Restrictions apply. 
2) Let ¯x be x where x(m, t) is replaced with x(cid:48)(m(cid:48), t).
Then for any m(cid:48) (cid:54)= m, (cid:107)S (m, x(t)) − S (m, ¯x(t))(cid:107) ≤
L2.
The above deﬁnition requires that the test is bounded in two
aspects. First, even if we change all the inputs, a machine score
cannot change by more than L1. Moreover, if we change the
counter values for a single machine, the score for any other
machine cannot change by more than L2.
The following lemmas deﬁne the two methods. Proofs are
omitted due to lack of space.
Lemma 1: Consider a test S which is L1, L2- bounded.
Assume that ∀m, t, x (m, t) ∼ X (t). Then for every γ > 0,
Pr [∃m s.t. (cid:107)vm(cid:107) ≥ E [(cid:107)vm(cid:107)] + γ] ≤ M exp
(cid:19)
(cid:18)
.
− 2T γ2
L2
1
The lemma follows by applying the bounded differences
inequality [14] and the union bound.
Lemma 2: Consider a test S that
The next lemma applies to the case where the expected
value of vm is not known. In this case, we use the empirical
mean as a proxy for the true expected value.
Assume that ∀m, t
E [(cid:107)vm(cid:107)] = E [(cid:107)vm(cid:48)(cid:107)]. Denote by ˆv = 1/M(cid:80)
is L1, L2- bounded.
x (m, t) ∼ X (t), and that ∀m, m(cid:48),
m (cid:107)vm(cid:107). Then
(cid:19)
Pr [∃m s.t. (cid:107)vm(cid:107) ≥ ˆv + γ]
≤ (M + 1) exp
for every γ > 0,
(cid:18)
−
√
.
(L1(1+
2T M γ2
M)+L2(M−1))2
In the proof we show that the random variable ˆv is a Lip-
schitz function and apply the bounded differences inequality
[14] to ˆv. Finally, we obtain the stated result by combining
with Lemma 1.
III. METHODS
Using the general framework described in Sec. II, we
describe three test implementations: the sign test (Sec. III-A),
the Tukey test (Sec. III-B), and the LOF test (Sec. III-C).
Their analyses provide examples of the use of the machinery
developed in Section II-E. Other tests can be easily incorpo-
rated into our framework. Such tests could make use of more
information, or be even more sensitive to the signals generated
by latent faults. For many well-known statistical tests, the
advantages of the framework will still hold: no tuning, no
domain knowledge, no training, and no need for tagged data.
A. The Sign Test
The sign test [15] is a classic statistical test. It veriﬁes the
hypothesis that two samples share a common median. It has
been extended to the multivariate case [16]. We extend it to
allow the simultaneous comparison of multiple machines.
Let m and m(cid:48) be two machines and let x(m, t) and x(m(cid:48), t)
be the vectors of their reported counters at time t. We use the
test
S (m, x(t)) =
1
M − 1
x(m, t) − x (m(cid:48), t)
(cid:107)x(m, t) − x (m(cid:48), t)(cid:107)
(cid:88)
m(cid:48)(cid:54)=m
as a multivariate version of the sign function. If all
the
machines are working properly, we expect this value to be
zero. Therefore, the sum of several samples over time is also
expected not to grow far from zero.
Algorithm 1: The sign test. Output a list of suspicious
machines with p-value below signiﬁcance level α.
foreach machine m ∈ M do
x(m,t)−x(m(cid:48),t)
(cid:107)x(m,t)−x(m(cid:48),t)(cid:107);
m(cid:48)(cid:54)=m
(cid:80)
T
t S (m, x(t));
S (m, x(t)) ← 1
M−1
vm ← 1
(cid:80)
(cid:80)
m (cid:107)vm(cid:107);
end
ˆv ← 1
foreach machine m ∈ M do
γ ← max (0,(cid:107)vm(cid:107) − ˆv);
p(m) ← (M + 1) exp
if p(m) ≤ α then
(cid:18)
M
(cid:19)
;
− T M γ2
√
2(
M +2)2
Report machine m as suspicious;
end
end
The following theorem shows that
if all machines are
working properly, the norm of vm should not be much larger
than its empirical mean.
Theorem 1: Assume that ∀m ∈ M and ∀t ∈ T , x(m, t)
is sampled independently from X(t). Let vm and ˆv be as in
Algorithm 1. Then for every γ > 0,
Pr [∃m ∈ M s.t. (cid:107)vm(cid:107) ≥ ˆv + γ]
≤ (M + 1) exp
(cid:18) −T M γ2
√
2(
M +2)2
(cid:19)
.
Proof: The sign test
2
Lemma 2, we obtain the stated result.
is 2,
M−1-bounded. Applying
Theorem 1 proves the correctness of the p-values computed
by the sign test. For an appropriate signiﬁcance level α,
Theorem 1 guarantees a small number of false detections.
A beneﬁcial property of the sign test is that it also provides
a ﬁngerprint for the failure in suspicious machines. The vector
vm scores every counter. The test assigns high positive scores
to counters on which the machine m has higher values than
the rest of the population and negative scores to counters on
which m’s values are lower. This ﬁngerprint can be used to
identify recurring types of failures [4]. It can also be used as
a starting point for root cause analysis, which is a subject for
future research.
B. The Tukey Test
The Tukey test is based on a different statistical tool, the
Tukey depth function [17]. Given a sample of points Z,
the Tukey depth function gives high scores to points near
the center of the sample and low scores to points near the
perimeter. For a point z, it examines all possible half-spaces
that contain the point z and counts the number of points of
Z inside the half-space. The depth is deﬁned as the minimum
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:20:08 UTC from IEEE Xplore.  Restrictions apply. 
number of points over all possible half-spaces. Formally, let
Z be a set of points in the vector space Rd and z ∈ Rd; then
the Tukey depth of z in Z is:
Depth(z|Z) = inf
w∈Rd
(|{z(cid:48) ∈ Z s.t. z · w ≤ z(cid:48) · w}|)
.
Algorithm 2: The Tukey test. Output a list of suspicious
machines with p-value below signiﬁcance level α.
Let I = 5;
for i ← 1, . . . , I do
πi ← random projection RC → R2;
foreach time t ∈ T do
foreach machine m ∈ M do
d(i, m, t) ← Depth (πi(x(m, t))|x(t));
end
end
(cid:80)
T
(cid:80)
end
foreach machine m ∈ M do
S(m, x(t)) ← 2
vm ← 1
I(M−1)
t S (m, x(t));
(cid:80)
M
m vm;
end
ˆv ← 1
foreach machine m ∈ M do
γ ← max(0, ˆv − (cid:107)vm(cid:107));
p(m) ← (M + 1) exp
if p(m) ≤ α then
(cid:18)
i d (i, m, t);
(cid:19)
;
− 2T M γ2
M +3)2
√
(
Report machine m as suspicious
end
end
In our setting, we say that if the vectors x(m, t) for a
ﬁxed machine m consistently have low depths at different time
points t, then m is likely to be behaving differently than the
rest of the machines.
However, there are two main obstacles in using the Tukey
test. First, for each point in time, the size of the sample is
exactly the number of machines M and the dimension is the
number of available counters C. The dimension C can be
larger than the number of points M and it is thus likely that
all the points will be in a general position and have a depth
of 1. Moreover, computing the Tukey depth in high dimension
is computationally prohibitive [18]. Therefore, similarly to
[19], we select a few random projections of the data to low
dimension (R2) and compute depths in the lower dimension.
We randomly select a projection from RC to R2 by creating
a matrix C × 2 such that each entry in the matrix is selected at
random from a normal distribution. For each time t, we project
x(m, t) for all the machines m ∈ M to R2 several times,
using the selected projections, and compute depths in R2
with a complexity of only O (M log(M )), to obtain the depth
d(i, m, t) for machine m at time t with the i’th projection.
The score used in the Tukey test is the sum of the depths
computed on the random projections:
S(m, x(t)) =
2
I (M − 1)
d (i, m, t)
.
(cid:88)
i
If all machines behave correctly, vm should be concentrated
around its mean. However, if a machine m has a much lower
score than the empirical mean, this machine is ﬂagged as
suspicious. The following theorem shows how to compute p-
values for the Tukey test.
Theorem 2: Assume that ∀m ∈ M and ∀t ∈ T , x(m, t)
is sampled independently from X(t). Let vm and ˆv be as in
Algorithm 2. Then for every γ > 0,
Pr [∃m ∈ M s.t. vm ≤ ˆv − γ]
≤ (M + 1) exp
 −2T M γ2
(cid:16)√
(cid:17)2
 .
M + 3
Proof: The Tukey test is 1,
M−1-bounded since 0 ≤
d (i, m, t) ≤ M − 1. Applying Lemma 2 with −vm and −ˆv,
we obtain the stated result.
2
C. The LOF Test
The LOF test is based on the Local Outlier Factor (LOF)
algorithm [20], which is a popular outlier detection algorithm.
The LOF test attempts to ﬁnd outliers by looking at the density
in local neighborhoods. Since the density of the sample may
differ in different areas, isolated points in less populated areas
are not necessarily outliers. The greater the LOF score is,
the more suspicious the point is, but the precise value of
the score has no particular meaning. Therefore, in the LOF
test the scores are converted to ranks. The rank r(m, x(t))
is such that the machine with the lowest LOF score will
have rank 0, the second lowest will have rank 1, and so
on. If all machines are working properly, the rank r(m, x(t))
is distributed uniformly on 0, 1, . . . , M − 1. Therefore, for
healthy machines, the scoring function
S(m, x(t)) =
2r(m, x(t))
M − 1
(1)
has an expected value of 1. If the score is much higher,
the machine is ﬂagged as suspicious. The correctness of this
approach is proven in the next theorem.
Theorem 3: Assume that ∀m ∈ M and ∀t ∈ T , x(m, t) is
sampled independently from X(t). Let vm be as deﬁned in
Algorithm 3. Then for every γ > 0,
Pr [∃m ∈ M s.t. vm ≥ 1 + γ] ≤ M exp
(cid:18)
(cid:19)
− T γ2
2
.
Proof: The LOF test
M−1-bounded since 0 ≤
r (m, x(t)) ≤ M − 1. Moreover, under the assumption of
this theorem, the expected value of the score is 1. Applying
Lemma 1, we obtain the stated result.
is 2,
2
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:20:08 UTC from IEEE Xplore.  Restrictions apply. 
Algorithm 3: The LOF test. Output a list of suspicious
machines with p-value below signiﬁcance level α.
foreach time t ∈ T do
l(m, t) ← LOF of x(m, t) in x(t);
foreach machine m ∈ M do
r(m, x(t)) ← rank of l(m, t) in {l(m(cid:48), t)}m(cid:48)∈M ;
S(m, x(t)) ← 2r(m,x(t))
;
M−1
end
(cid:80)