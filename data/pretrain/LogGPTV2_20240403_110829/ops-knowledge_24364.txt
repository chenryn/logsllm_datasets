User: I am trying to move multiple large folders (> 10 Gb , > 100 sub folders, > 2000 files ) between network drives. I have tried using shutil.copytree command in python which works fine except that it fails to copy a small percentage (< 1 % of files ) for different reasons. 
I believe robocopy is the best option for me as i can create a logfile documenting the transfer process. However as i need to copy > 1000 folders manual work is out of question.
So my question is essentially how can i call robocopy (i.e. command line ) from within a python script making sure that logfile is written in an external file. 
I am working on a Windows 7 environment and Linux/Unix is out of question due to organizational restrictions. If someone has any other suggestions to bulk copy so many folders with a lot of flexibility they are welcome.
Assistant: Like halfs13 said use subprocess but you might need to format it like so
from subprocess import call
 call(["robocopy",'fromdir', 'todir',"/S"])

Or else it may read the source as everything