additional algorithms on top of the regular algorithms the
primitive normally possess: EnKey(·), which embeds some
(private) owner related information into the public key, and
Rec(·) which recovers the private information from the pub-
lic key by interacting with any non-trivial implementation
(or “box”) which can be executed by anyone. While the con-
cept of a leakage-deterring cryptographic primitive can be
deﬁned in abstract terms for a wide class of primitives we
ﬁnd it more instructive to present it for three main cryp-
tographic primitives individually; we focus on encryption;
deﬁnitions of leakage-deterring signatures and identiﬁcation
are similar and we defer them for the full version. With these
examples at hand, it is relatively straightforward to derive
leakage-deterring deﬁnitions for other cryptographic primi-
tives following the same general structure (see also remarks
below).
Leakage-deterring Public Key Encryption:
• KeyGen(1λ): On input security parameter λ, this al-
gorithm returns a key pair (pk, sk).
• EnKey(O, A): This is a protocol between two parties
O (owner) and A (authority), with inputs (pk, sk, s)
and (pk, s) respectively that has the objective to em-
bed the private owner’s data s into his public-key; the
protocol terminates with the owner O obtaining an en-
hanced key pair (epk, esk) while A obtains simply the
enhanced epk.
• Enc(epk, m): On input a message m and the user’s
enhanced public key epk, this algorithm returns a ci-
phertext c.
• Dec(esk, c): On input a ciphertext c and enhanced
secret key esk, this algorithm returns m or ⊥ (fail).
• RecB,D(epk, δ):2 Using access to a decryption box B
and a plaintext distribution D (which is supposedly the
2Having access to D is necessary; to see that, consider the
following simple example: the box processes the input only
if the message encrypted is of the form sc||m for some secret
string sc; otherwise it outputs ⊥.
It follows that without
945one that B is suited for and is correct with probability
δ), as well as input the enhanced public key epk for a
certain user, this algorithm outputs s or ⊥ (fail).
Remarks. One can think of EnKey as an extension of
a public-key certiﬁcation operation by an authority. The
owner may still utilize (pk, sk) for the primitive’s operation
(as in a PKI one may still use an uncertiﬁed key) but epk is
the key designated for public use.
The deﬁnitions for other primitives are similar and we
present them in the full version. They share the same basic
structure in terms of the syntax of the recovering algorithm
but there is some variability across primitives with respect
to when this algorithm is supposed to operate. We tackle
this question in the following section. Furthermore, we note
that in the Rec algorithm, one may distinguish several ways
that the algorithm may have access to the main functional-
ity box (which is assumed to be resettable, i.e., it does not
maintain state from one query to the next). Speciﬁcally, be-
yond black-box access we will also consider a certain type of
non-black-box access.
2.2 Correctness and Security Modeling
In this section we introduce the main security require-
ments for leakage-deterring cryptographic primitives.
In
general any leakage-deterring primitive should oﬀer privacy
for the owner (as long as no implementation of the primitive
is leaked) and recoverability, i.e., that the recovering algo-
rithm will be able to produce the private data of the owner
as long as it has access to a non-trivial implementation of
the cryptographic primitive. Finally, it is important that the
introduction of the additional functionality does not disturb
the standard cryptographic properties of the primitive. We
examine these properties below.
Privacy (of Owner’s Data): For an honest owner who does
not leak any non-trivial box, the privacy of its data bound in
the enhanced public key should be protected. To deﬁne the
property formally we introduce the following game between
a challenger and an adversary A.
• The challenger runs KeyGen(·) and sends to the ad-
versary A the public key pk.
• The adversary A chooses two private strings s0, s1 and
sends them to the challenger.
• The challenger chooses b and simulates EnKey(·) on
sb and pk, sk; it sends epk to the adversary.
• A returns his guess b(cid:48) about b.
If there is no eﬃcient adversary A that can correctly
guess b with non-negligible advantage, i.e., for all PPT A,
2| ≤  where  is a negligible function, we
| Pr[b(cid:48) = b] − 1
say the leakage-deterring cryptographic scheme achieves pri-
vacy (in the sense of indistinguishability). Furthermore, in
the above game, we may allow the adversary to observe the
cryptographic functionality on a certain input distribution.
If the above deﬁnition holds even in the case that the adver-
sary has access to an oracle O(esk,·) (that is dependent on
the enhanced secret-key of the owner, e.g., decryption ora-
cle or signing oracle w.r.t. some plaintext distribution D)
we will say that the scheme achieves privacy with respect
knowledge of D, the box is useless. This counterexample
applies to the other leakage-deterring primitives.
to the secret-key oracle O(esk,·). Note that for privacy we
consider both owner and authority honest. It is possible to
extend the model to the case of a dishonest authority but
this goes beyond our current scope.
Recoverability (of Owner’s Data): If a dishonest owner re-
leases a functional box B, anyone having access to B should
be able to recover the owner’s private data from the en-
hanced public key epk. Formally, consider the following
game between a challenger and an adversary A:
• The adversary A on input 1λ generates a key pair
(sk, pk) and submits it together with the owner pri-
vate data s to the challenger.
• The challenger acting as the authority runs EnKey
with the adversary (playing the role of the owner) to
produce the enhanced key pair (epk, esk).
• A outputs an implementation B and a distribution D.
• The challenger outputs the value s(cid:48) = RecB,D(epk, δ).
For a given δ, we will say that the leakage-deterring cryp-
tographic primitive satisﬁes black-box recoverability with re-
spect to the class of input distributions D, if for any eﬃcient
adversary A the following event in the game above happens
with negligible probability.
(B is δ-correct w.r.t. D) ∧ (D ∈ D) ∧ (s
(cid:48) (cid:54)= s)
The predicate “B is δ-correct w.r.t. D” takes a diﬀerent form
depending on the cryptographic primitive and is intended
to capture the fact that the box produced by the adversary
should have some minimum utility parameterized by δ.
Consider the case of a PKE scheme (KeyGen, Enc, Dec).
The predicate for δ-correctness w.r.t. D in this case is as fol-
lows: Pr[B(Enc(epk, m)) = m] ≥ δ, s.t. m ← D where the
random variables epk,D, B are deﬁned as in the game. It is
worth noting that the largest class of distributions D we can
hope recoverability to work for is one that includes those dis-
tributions whose predicting probability3 is by a non-negligible
amount smaller than δ; otherwise, one can implement a de-
cryption box by always returning the most probable sample
from D. In a similar vein, we deﬁne correctness for digital
signatures and identiﬁcation in the full version.
We will also consider a form of the above deﬁnition where
a non-black-box technique is used for recovering the owner’s
private data. In this case we can think of the Rec algorithm
as a family of algorithms parameterized by the box algorithm
B (as opposed to being a single algorithm with black-box
access to B).
We next compare privacy and recoverability and observe a
natural trade-oﬀ between the two properties. Privacy w.r.t.
a secret-key oracle O(esk,·) for a distribution D (i.e., when
adversarial access to the cryptographic primitive is allowed
for input distribution D) can not be achieved if the leakage-
deterring cryptographic primitive satisﬁes black-box recov-
erability w.r.t. D, in case D ∈ D. This easily follows from
the fact that the privacy adversary can simulate the Rec
algorithm with the help of the secret key oracle.
Correctness Properties. Leakage-deterring cryptographic pri-
mitives should satisfy correctness in the usual sense (albeit
correctness should be expressed with respect to the enhanced
3Denoted by p(D) is equal to 2−H∞(D), where H∞(D) =
− log maxx Pr[x ∈ D] is the min-entropy of D.
946public and secret-keys). The extension of the deﬁnitions is
straightforward and we defer them for the full version.
Security Properties. We next consider how the individual
security properties for leakage-deterring primitives should
be amended. In general, the original security property (e.g.,
IND-CPA or unforgeability) should be retained with respect
to the enhanced public and secret-keys even in the presence
of a corrupted authority running the EnKey protocol.
IND-CPA/CCA Security (leakage-deterring public-key en-
cryption with dishonest authority): Consider the following
game between the adversary and the challenger:
• The challenger runs KeyGen(·) to get (pk, sk) and
returns pk to the adversary A.
• The adversary A selects s and playing the role of the
authority runs EnKey(·) with the challenger on input
pk, s.
• The adversary A chooses two messages m0, m1, and
sends them to the challenger.
• The challenger randomly picks a bit b ∈ {0, 1}, and
gives A the encryption of mb under epk.
• Finally, A returns a guess b(cid:48) about b.
Suppose there is no eﬃcient adversary A that can output
a correct guess about b with non-negligible advantage, i.e,
|P r[b(cid:48) = b] − 1
In
this case, we say that the leakage-deterring encryption is
IND-CPA-secure (with dishonest authority).
2| ≤ , where  is a negligible function.
If we allow the adversary to ask decryption queries at
anytime before outputting the guess (it can be both be-
fore and after receiving the challenge ciphertext, with the
only restriction being that the challenge ciphertext cannot
be queried), then we refer to this as IND-CCA2 security.
We can also consider the security deﬁnition with an hon-
est authority, in which case both KeyGen, EnKey are ex-
ecuted by the challenger. The deﬁnitions of unforgeability
for the case of digital signatures and impersonation resis-
tance for identiﬁcation schemes are in the same vein and are
deferred for the full version.
3. LEAKAGE-DETERRING PUBLIC KEY EN-
CRYPTION
In this section, we present constructions of leakage-deterring
public key encryption schemes. We start with a construc-
tion from any additive homomorphic encryption to demon-
strate our ﬁrst technique for implementing recoverability,
then, we show a generic construction of IND-CPA secure
leakage-deterring PKE from any IND-CPA secure encryp-
tion along with an improvement that achieves constant size
ciphertexts.
In section 3.3, we provide a general way to
achieve IND-CCA2 security for all leakage-deterring encryp-
tion schemes.
3.1
IND-CPA-secure Leakage-deterring PKE
from Homomorphic Encryption
Recall the trivial solution presented in the introduction
(encrypting the owner’s private data with its public-key).
It does not work because an adversarial decryption box is
able to test whether the queries fed by the recovering algo-
rithm match the ciphertext stored in epk. A seeming ﬁx is
to query via rerandomizing the ciphertext contained in the
enhanced public key. However, given that the private data
are known to the attacker, the adversarial box can check for
them and still refuse to cooperate. So in some sense to go
around the problem one has to re-randomize the plaintext as
well! (so that after re-randomization, the plaintexts should
be distributed according to D but in a way that is still some-
how useful for decrypting the private data). We provide a
solution along these lines in this section.
Informally, an encryption algorithm E(·) has a homomor-
phic property if E(m1 + m2) = E(m1) · E(m2) for some op-
erations (+,·) over plaintexts and ciphertexts respectively.
For instance, we can submit a ciphertext c∗ · E(r) to the
decryption box B, and retrieve the message in c∗ from the
answer by subtracting r. This method would be eﬀective
for our purpose only if B satisﬁes correctness w.r.t. to ran-
dom distributions over the whole message space. However
we would like a solution that works even for adversarially
chosen distributions that are unknown at the time of the
generation of epk. The recovering technique we introduce
below achieves this goal.
First assume that we have an underlying encryption E :
(KeyGen, Enc, Dec) that is an IND-CPA secure PKE with
a homomorphic property. Speciﬁcally, we assume that for
any message m and any a, b from the message space, Enc(m)a·
Enc(b) is identically distributed to Enc(am + b). We call
the following construction Scheme-I.
• KeyGen(1λ): Run the KeyGen algorithm of E, re-
turn (pk, sk).
• EnKey(O, A): This is a protocol between O and A
with input (pk, sk, s) and (pk, s) respectively. A ran-
domly chooses n = |s| messages ωi, i = 1, . . . , n accord-
ing to the uniform distribution over {0, 1}. Then A
1 . . . s(cid:48)
calculates s(cid:48)
n.
The protocol terminates with O obtaining the enhanced
key pair (epk, esk) where epk = (pk,{ci}, s(cid:48)), and esk =
sk, while A gets only the enhanced public key epk.
i = ωi ⊕ si, {ci = E(pk, ωi)}, s(cid:48) = s(cid:48)
• Enc(epk, m): This algorithm runs the encryption al-
gorithm Enc, returning c = Enc(pk, m).
• Dec(esk, c): This algorithm runs the decryption algo-
rithm Dec, returning m = Dec(sk, c).
• RecB,D(epk, δ): With access to a decryption box B
and a distribution D, over which B works with δ-
correctness, the objective of this algorithm is to trans-
form the ciphertexts c1, . . . , cn found in the epk to ci-
phertexts that look inconspicuous from the point of
view of the box B. For each ciphertext ci the algo-
rithm will operate as follows. First it will calculate
a suﬃciently long sequence of pairs (x, y) (the exact
length N of the sequence depends on the parameters
of B and D and will be determined in our security
analysis). For each pair, the algorithm ﬁrst indepen-
dently samples two plaintexts m0, m1 according to D.
Then it calculates x, y by solving the following linear
system:
(cid:26) 0 · x + y = m0
1 · x + y = m1
Let (xl, yl)l=1,...,N be the pairs produced by running
the above procedure N times and m0,l, m1,l be the
947pair of plaintexts used as constant terms of the lin-
ear system for the l-th sample. Having calculated
· E(pk, yl)
those, the algorithm computes c(cid:48)
for l = 1, . . . , N , and feeds B with those ciphertexts
(observe that their corresponding plaintexts follow the
distribution D). Let a1, . . . , aN , be the answers of the
box B where al = ⊥ if the box does not provide an an-
swer for the l-th ciphertext. Now consider the modiﬁed
answer sequence deﬁned as follows:
i,l = cxl
i
(cid:26) (al − yl)/xl
⊥
∗
l =
a
al ∈ {m0,l, m1,l)} ∧ xl (cid:54)= 0
otherwise
1, . . . , a∗
l ∈ {0, 1,⊥}. If the majority symbol among
Note that a∗
the non-⊥ symbols of (cid:104)a∗
N(cid:105) is deﬁned, the re-
covering algorithm calculates it as vi and proposes it
as the decryption of ci (otherwise the algorithm fails).
This procedure is repeated for all ciphertexts c1, . . . , cn
thus forming v = v1 . . . vn. Finally, the recovering al-
gorithm proposes as the private data of the owner the
string s(cid:48) ⊕ v where s(cid:48) is parsed from the epk.
Security Analysis: We will analyze correctness and three
security properties, i.e, security, privacy, recoverability. First
observe that correctness is trivial, according to the correct-
ness of the underlying encryption scheme E while IND-CPA
security is also relatively obvious since the extra informa-
tion exposed due to our extension are some independent
values (ω1 . . . ωn, s). Now regarding the privacy property,
we can see that the EnKey algorithm in Scheme-I is a