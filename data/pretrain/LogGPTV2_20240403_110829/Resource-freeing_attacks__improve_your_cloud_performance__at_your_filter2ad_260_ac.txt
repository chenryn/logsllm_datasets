the longer run periods reﬂect ﬁxed-length CPU tasks not correlated
with trafﬁc. Because Apache does not saturate its CPU allocation, it
retains “boost” priority, which allows it to preempt LLCProbe for
every request. Thus, LLCProbe also runs for short periods, causing
it to lose the data in its cache.
The rightmost columns in Figure 4 show the same experiment
when the two VMs are allowed to ﬂoat across all the cores (ﬂoat-
ing). We see a similar trend here, though slightly less severe be-
cause for some fraction of time, the victim and beneﬁciary VMs are
scheduled on different packages and do not share an LLC. Thus,
we expect in live settings such as EC2 to see less interference than
when both VMs are pinned to the same core.
We separately investigate the effect of contention with the Xen
driver domain, Dom0 1, which handles all device access such as
interrupts or requests to send a packet. In the typical setting where
Dom0 is assigned one VCPU per physical CPU, Dom0 may run
on any core and uses the same scheduling mechanism as other guest
VMs. As a result, Dom0 receives boost and can interfere with the
beneﬁciary just like the victim when it handles a network interrupt.
Dom0 and the beneﬁciary may share a CPU even if the victim is
scheduled elsewhere.
The attack. As alluded to in Section 4, the beneﬁciary’s perfor-
mance degradation is caused by a victim frequently preempting the
beneﬁciary and thereby polluting its cache. The preemptions occur
to handle static web page requests due to legitimate trafﬁc to the
victim. Our attack aims to exploit the victim’s CPU allotment as
a bottleneck resource in order to shift, in time, its accesses to the
cache, and to reduce the number of requests it serves. Doing so will
provide the beneﬁciary longer periods of uninterrupted access to the
cache and less cache pollution from handling requests, resulting in
increased cache hit rates and improved performance.
The trigger for this is the introduction of a small number of CGI
requests per second from a helper. Even a low rate of requests per
second can push the victim up to its CPU cap, forcing it to lose
boost and thus consolidating its use of the cache into a smaller time
frame. Introducing long-latency dynamic requests means that, in-
stead of interrupting LLCProbe frequently, the web server runs
continuously until the Xen scheduler preempts it, which allows LL-
CProbe to run uninterrupted. The Xen credit scheduler allows a
maximum of 30 ms of credit per VCPU, with each domain being al-
lotted only one VCPU in our case. Therefore, the helper sends RFA
requests that invoke the CPU-intensive CGI helper in an effort to
use up the victim’s CPU allotment. In addition, the CPU-intensive
requests displace legitimate trafﬁc and thus reduce the rate of re-
quests that pollute the cache.
Here the helper is any system that can make CGI requests. Given
the very low rate required, this could be a free micro instance run-
ning on the cloud or —scaling up— a single system that performs
the RFA against many victims in parallel (that are each co-resident
with a different beneﬁciary). While for some applications the helper
might be put to better use helping with whatever computation the
beneﬁciary is performing, in others this will not be possible (e.g., if
it is not easily parallelized) or not as cost effective. We also men-
tion that one might include a lightweight helper on the same VM as
As the workload of the victim increases, we see a corresponding
increase in the performance degradation of LLCProbe. To evaluate
our hypothesis that the effect arises due to frequent interruptions,
1The default conﬁguration in Xen is to run device drivers in a single
domain with privileged access to I/O hardware.
285)
s
u
(
e
m
i
t
n
u
R
.
g
v
A
20000
18000
16000
14000
12000
10000
8000
6000
4000
2000
0
No-RFA
160
320
640
Baseline
1000
2000
3000
Web Server Request Rate (rps)
)
s
u
(
e
m
i
t
n
u
R
.
g
v
A
20000
18000
16000
14000
12000
10000
8000
6000
4000
2000
0
No-RFA
160
320
640
Baseline
1000
2000
3000
Web Server Request Rate (rps)
Figure 5: Performance of LLCProbe workload when pinned to same core as co-resident web server. “Baseline” measures baseline
performance when no trafﬁc was sent to the victim; it is shown in each grouping for comparison. “No-RFA” measures performance
when no RFA requests were sent.
(Right)
Performance when they ﬂoat amongst cores. Error bars indicate one standard deviation.
(Left) Performance when LLCProbe and web server VMs are pinned to same core.
the beneﬁciary, but this would require care to ensure that interfer-
ence from the client does not outweigh the potential speedup due
to the RFA. In our experiments to follow, we run the helper on a
system different from the one on which the beneﬁciary and victim
co-reside.
5.1 Evaluation on Local Testbed
The results above show that LLCProbe experiences a signiﬁcant
performance gap when running on an otherwise idle server as op-
posed to one that is hosting one or more active web servers. In this
section, we show that this performance gap can be narrowed using
the RFA outlined above. In the following we look at the effective-
ness of the attack under a range of RFA intensities, which speciﬁes
the their total runtime per second. Unless otherwise noted, we im-
plement the RFA using CGI requests specifying 40 ms of compu-
tation. We investigate a range of RFA intensities: 160, 320, and
640 ms. This allows understanding both the effect of overloading
the victim by requesting more computation than its total allotment
of 400 ms.
We ﬁrst run LLCProbe ﬁfteen times while the victim VM is idle
to get a baseline. Then for each legitimate victim trafﬁc rate and
each level of RFA including “No-RFA”, we run LLCProbe ﬁfteen
times while offering the appropriate legitimate trafﬁc and RFA traf-
ﬁc.
The average runtimes of these tests are shown in Figure 5. We
observe several interesting trends. Consider the left chart, which
reports on a setting with both victim and beneﬁciary pinned to the
same core and all four Dom0 VCPUs ﬂoating across all cores. First,
introducing the extra load from the RFA requests helps the beneﬁ-
ciary. Second, the greater the victim’s load the higher the payoffs
from the RFA.
In order to understand these results, we ran additional experi-
ments trying to identify various sources of interference on the ben-
eﬁciary. There are three main sources of interference: two effects
on request processing by the web server and the effect of network
packet processing by Dom0 . RFA requests help mitigate the effect
of web server request handling in two ways. First, introducing sufﬁ-
ciently many CPU-intensive requests will deprive the web server of
the boost priority. This is the major reason for the high performance
improvement in the pinned case shown in Figure 5. Second, intro-
ducing long-running CGI requests reduces the amount of CPU time
available to serve legitimate trafﬁc and thus, implicitly reduces the
capacity of the web server. This is the reason for higher payoffs at
higher web-server request rates. Reducing Dom0 ’s impact on the
beneﬁciary can only be indirectly achieved by saturating the web
server and hence reducing the rate of incoming request to the web
server.
Figure 6 shows the CDF of runtime durations of the web server
(top chart) and LLCProbe (bottom chart) before being preempted
both with and without an RFA for the pinned case. What we see is
that LLCProbe runs for more than 1 ms 85% of the time in the RFA
case but only 60% of the time without the RFA. This accounts for
part of its improved performance. Similarly, the web server changes
from running longer than 1 ms for only 10% of the time to 60% of
the time. Furthermore, we can see that the web server often runs
out of scheduling credit from the vertical line at 30 ms, indicating
that it uses up some of its scheduling quanta.
Figure 7 shows the effect of displacing legitimate trafﬁc at higher
RFA intensities for the ﬂoating case. At low web-server request
rates and low RFA intensities, the offered and the observed load
remain similar. However, at 3000 rps and RFA intensity of 320,
the observed load reduces to 1995 rps, which leads LLCProbe to
have performance similar to No-RFA case at 2000 rps (right graph
in Figure 5). This is the primary reason for large performance im-
provement at 3000 rps in both pinned and ﬂoating case shown in
Figure 5.
In the ﬂoating case shown on the right in Figure 5, we see that
RFA requests can sometimes hurt performance. There appear to be
two reasons for this. First, some percentage of the time LLCProbe
and Apache are running concurrently on two different cores shar-
ing an LLC. Because the two loads run concurrently, every cache
access by the web server hurts the performance of LLCProbe. In
such a case, depriving the web server of boost is insufﬁcient and
LLCProbe performance increases only when the RFA rate is high
enough so that the web server saturates its CPU allotment and so
spends more than half the time waiting (40% CPU cap). In a sep-
arate experiment, we pinned the web server and the LLCProbe to
different cores on the same package, and used a web-server request
rate of 2000 rps. In this conﬁguration, a high RFA intensity im-
proved performance by a meager 2.4%. In contrast, when we pin
the two to the same core, performance improved by 70%. Thus,
improving performance when sharing a core is possible without re-
286No-RFA
320
640
e
c
n
a
m
r
o
f
r
e
P
d
e
z
i
l
a
m
r
o
N
1
0.95
0.9
0.85
0.8
0.75
0.7
a
s
t
a
r
b
z
i
p
2
h
m
m
m
c
f
e
r
s
p
h
i
n
x
g
r
a
S
P
E
p
h
5
C
j
b
b
0
0
Figure 8: Normalized performance (baseline runtime over run-
time) for SPEC workloads on our local testbed for various RFA
intensities. All values are at a web server request rate of 3000
rps.
ducing legitimate foreground trafﬁc, while without sharing a core it
requires displacing some legitimate trafﬁc.
Second, in this ﬂoating case the beneﬁciary will for some per-
centage of the time be scheduled to run on a core or package as
Dom0 . Since Dom0 handles all incoming and outgoing packets, it
may frequently interrupt the beneﬁciary and pollute its cache state.
When we pin LLCProbe and the web server to different packages
(no shared cache) but let Dom0 ﬂoat, LLCProbe still experiences
interference. At a load of 2000 rps on the web server, LLCProbe
suffered a 78% degradation in performance just due to Dom0 ’s in-
ference. The RFA we explore can only alleviate contention from
Dom0 by forcing a drop in the web server’s foreground trafﬁc rate
(by exhausting its VM’s CPU allocation as shown in Figure 7).
Finally, we analyze a spectrum of SPEC benchmarks. Each SPEC
benchmark is run three times with an idle webserver, an active web
server, and an active web server with various RFA intensities where
all the VMs (including Dom0 ) ﬂoat across all cores. Figure 8 de-
picts the normalized performance of seven benchmarks under no
RFA and intensities of 320 and 640. That is, the reported fractions
are computed as t′/t where t is the average runtime (request latency
is computed and used for SPECjbb) and t′ is the average baseline
performance when no trafﬁc is sent to the victim. All benchmarks
beneﬁt from the RFA, with the general trend that cache-sensitive
benchmarks (as indicated by a larger drop in performance relative
to the baseline) achieve more gains from the RFA. For example, the
640 RFA increases normalized performance of SPECjbb from 0.91
to 0.97, a 6 percentage point improvement in performance and a
66.5% reduction in harm due to contention. The smallest improve-
ment occurs with hmmer, which shows only a 1.1 percentage point
improvement because it only suffers a performance loss of 1.6%
without the RFA. Across all the benchmarks, the 640 RFA achieves
an average performance improvement of 3.4 percentage points and
recovers 55.5% of lost performance. These improvements come
largely from the ability of the RFA to reduce the request rate of the
victim web server.
Figure 6: Cumulative runtime distribution of
the
web server domain (with load 2,000 rps) and (bottom) the