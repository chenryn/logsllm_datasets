67
67
68
68
F1
0.05
0.04
0.04
0.03
0.01
0.05
0.04
0.04
0.04
0.02
0.06
0.05
0.05
0.03
0.03
N
N
-
k
L
U
M
U
C
P
F
-
k
In our analysis, we evaluated the accuracy for each website in
isolation and ranked all the websites to find a threshold that divides
them into the two types described above. We found that only 10
(in kNN) to 40 (in CUMUL) sites are perfectly classified, while the
other sites have at least one misclassified instance – some of them
are consistently misclassified by all three classifiers.
We have compared the misclassifications of all three attacks to
find sites that are misclassified by all the classifiers as opposed to
sites that at least one of identified correctly. Table 2 shows the top
five onion services ranked by number of misclassifications, where
we see a partial overlap of which sites are misclassified the most.
This means there is not only variation across websites within a
given classifier but also across different classifiers.
4.3 Comparison of Website Classification
Errors
Figure 2 shows a scaled Venn diagram of the classification errors.
The circles represent the errors made by each of the classifiers, and
the intersections represent the fraction of instances misclassified
by the overlapping classifiers. All numbers in the Venn diagram
add to one as each number is a fraction of all misclassifications, not
a fraction of the misclassifications for a specific classifier. This is to
represent how misclassifications are distributed over classifiers and
intersections of classifiers. The black region in the center represents
the errors that are common to all three classifiers, which accounts
for 31% of all classification errors. This large intersection indicates
that classification errors for a given website are correlated and
not independent for each classifier. Note that if the errors were
independent, the adversary would benefit from employing multiple
website fingerprinting classifiers; but the correlation suggests that
such gains will have limited returns.
The diagram in Figure 2 does not take into account whether the
classifiers that erred predicted the same mistaken label or not. In
kNN
0.26
Errors
0.08
0.31
CUMUL
0.07
0.15
0.05
0.08
kFP
Figure 2: Scaled Venn diagram of classification errors. Each
circle represents the set of prediction errors for a method:
kNN, CUMUL and kFP. In the intersections of these circles
are the instances that were incorrectly classified by the over-
lapping methods. 31% of the erred instances were misclassi-
fied by all three methods, suggesting strong correlation in
the errors.
Errors by coinciding guess
kNN
0.37
CUMUL
0.23
0.03
0.02
0.06
0.03
0.25
kFP
Figure 3: Scaled Venn diagram of classifications errors by
coinciding guess. The intersections contain instances that
were incorrectly classified with exactly the same label by the
overlapping classifiers. Only 2% of the errors were misclas-
sified to the same incorrect site by all three methods, while
85% were misclassified differently by each method, showing
that the methods do err in different ways.
Figure 3, we depict the Venn diagram of misclassifications accord-
ing to the (erroneous) guessed label. The percentage of instances
that were mislabeled in the same way by all three classifiers is
substantially smaller: only 2% of the errors are errors that all three
classifiers erred with the same predicted label. Interestingly, this
small intersection implies that even though these classifiers err on
the same instances (Figure 3), they do so in different ways, making
different predictions for a given instance.
4.4 Ensemble Classifier
In Figure 2 we observe that more than 25% of the errors occur in
only one of the methods, and an additional 17% of errors appear in
only two of the methods. A third of the errors were misclassified by
all three methods. Thus, an ensemble classifier that appropriately
combines the three classifiers can achieve higher accuracy than any
individual classifier alone, by correcting classification errors that
do not occur in all the methods.
We can estimate the maximum improvement that such an en-
semble could achieve by looking at the potential improvement
of the best classifier. In our case, CUMUL has the greatest accu-
racy with 874 errors that could be corrected using kNN or kFP. So
if CUMUL did not make these errors, its accuracy would be im-
proved by 874
33,740 = 2.6%. Even though the margin for improvement
is small, we build an ensemble to reduce the dependency of our
results on a single classifier. In addition, by choosing an ensem-
ble we ensure that we are not underestimating an adversary that
combines all the state-of-the-art classifiers. We therefore use the
results of the ensemble to determine fingerprintability, and com-
pute a site’s fingerprintability score as its F1 score from the
ensemble classifier.
We analyze the overlap in errors and TPs for the three classifiers
for different ensemble methods, as follows:
Random. For each instance, randomly select one of the pre-
dictions of the three classifiers. With this method the ensemble
achieves 79.98% accuracy.
Highest confidence. For each instance, take the prediction of
the classifier with highest confidence. kFP and CUMUL use Random
Forests and SVM respectively, and both output a classification prob-
ability for each of the possible classes. For kNN we use the distance
to the nearest neighbor as the confidence metric. The accuracy was
80.91% using this method.
P1 − P2 Diff. For each instance, use the output of the classifier
with the greatest difference in confidence between its first and
second predictions. We obtained 80.91% accuracy with this method.
We decided to use the P1 − P2 Diff for the rest of our analysis
because it uses most information about the confidence vector. Fig-
ure 4 shows the F1 score histograms for all classifiers including the
ensemble. The vertical dashed lines show the mean F1-scores. We
Figure 4: F1 score histograms for each classifier. Vertical
dashed lines represent the mean F1 score.
Figure 5: Median of total incoming packet size for misclas-
sified instances (true vs predicted site). We also plot the
dashed diagonal line, y = x, for comparison. We chose the
total incoming packet size for this analysis because it is the
most distinguishing feature (see Section 5).
note that the ensemble is only marginally better than CUMUL. The
main visible difference is in the relative weights of the second and
third highest bars: the ensemble improves the F1 score for a subset
of instances that in CUMUL contribute to the third bar, and to the
second in the ensemble.
In the histograms we can once more see the accuracy variation
across sites (horizontally) and across classifiers (vertically). Even
though for CUMUL and the ensemble most of the sites have high
F1 scores, we see there still are several sites in the low ranges of F1
scores that even CUMUL and ensemble cannot perfectly fingerprint
(the ones shown in Table 2).
4.5 Sources of Classification Error
In order to gain insight about the nature of the classifier errors, we
performed an exploratory analysis specific to the features of the
erred instances. We use the total incoming packet size as example
for illustrating the analysis, because, as we show in the following
sections, it is the most salient feature. However, this analysis can
as well be applied to any other feature.
In Figure 5, each point represents a misclassified instance, with
the x axis value being the median incoming packet size of the ‘true
site’ (site the instance truly belongs to), and the y axis value being
the median incoming packet size of the ‘predicted site’ (according
to the ensemble classifier). Note that the total incoming packet
sizes have been normalized to the interval [0, 1] using Min-Max
normalization across all instances. For visualization purposes, we
have clipped the range to focus on the region where approximately
80% of the data points are (101 points were excluded).
Figure 5 shows that the median incoming packet sizes of the
predicted and true sites are highly correlated: most of the instances
are close to the diagonal y = x (dashed line), meaning that for
most of the errors, true and predicted sites are similar to each
other in terms of median incoming packet size. In fact, since the
median incoming packet size approximates to the median total
CUMULkFPkNNEnsemble0.000.250.500.751.00050100150050100150050100150050100150F1 ScoreFrequency0.0000.0250.0500.0750.1000.0000.0250.0500.0750.100True Site − MedianPredicted Site − Medianthe confusion matrix is too large for any visualization to be useful.
This can be addressed by using confusion graphs instead, which
represent misclassifications as a directed graph [29].
To better understand the nature of classification errors we draw
a directed graph where nodes represent classes (onion services)
and edges represent misclassifications. Source and target nodes of
an edge represent true and predicted sites, respectively. The edge
weight encodes the misclassification frequency (i.e., number of
times the source class is misclassified as the target class). We have
created a confusion graph for CUMUL, which is the best performing
classifier in our dataset, shown in Figure 10 in the Appendix.
The nodes are colored based on the community they belong to,
which is determined by the Louvain community detection algo-
rithm [3], as implemented in the Gephi graph software. Node size
is drawn proportional to the node degree. We observe highly con-
nected communities on the top left, and the right which suggests
clusters of onion services which are commonly confused as each
other. Further, we notice several node pairs that are commonly
classified as each other, forming ellipses.
The mean outdegree and indegree of the graph is 4.9, meaning
that, on average, a site is misclassified as 5 distinct sites and con-
fused with 5 distinct sites. The onion service with the maximum
outdegree had 42 outgoing edges, meaning it is misclassified as 42
distinct sites. The onion service with the maximum indegree had
28 incoming edges, meaning it is confused with as many different
sites. Interestingly, the same onion service has zero outdegree, i.e.,
its instances are never misclassified as belonging to another site.
We have looked into the size of the sites for each community in
the graph. The sites in the dark green community at the bottom of
the graph are all of similar size and significantly larger than all the
others, explaining why they are confused between each other and
clustered into a community. For the other communities, however,
it is not obvious which common features define the community.
Further, we discovered that a few of the pairs of sites that form
ellipses are false negatives of our duplicates detection in the data
cleansing step, while the others require further analysis. We leave a
more detailed graph-based analysis of these communities for future
work.
sites are misclassified as Site A.
but A is consistently classified as A.
We analyze three cases of the symmetry of classifications:
• Symmetrical: Site A is misclassified as other sites and other
• Asymmetrical: One or more sites are misclassified as Site A,
• Asymmetrical: Site A is misclassified as one or more other
For each distinct misclassification pair (A → B) we check whether
there is a symmetric misclassification (B → A). The total number
of misclassifications with symmetric counterparts:
sites, but other sites are rarely misclassified as A.
• CUMUL: 74.8% (4868/6502)
• kFP: 73,4% (5517/7519)
• kNN: 80.6% (8174/10132)
The results show the majority of the misclassifications are sym-
metrical, meaning that there are sets of pages that provide cover
for each other, effectively forming anonymity sets . This suggests
that onion services may benefit from designing their site to have
features that enable them to join one of those sets.
Figure 6: Density plot for absolute value of Z-score distribu-
tion of total incoming packet size. Correctly classified (dark
gray) and misclassified (light gray) instances are plotted sep-
arately to contrast them with respect to their deviation from
the class mean.
size of the page, this shows that most of the misclassified pages
were confused with pages of similar size. Furthermore, as shown
by the histograms most of the misclassifications occur on pages of
small sizes, confirming the hypothesis that large pages are easier
to identify.
We also measure the deviation of each instance from its class
mean. We use Z-score, which indicates the number of standard de-
viations a sample is away from the mean. The Z-score is a standard
statistic that normalizes the deviation from the mean using the
class’ standard deviation. Unlike the standard deviation, this allows
to compare Z-scores between classes with standard deviations that
differ by orders of magnitude. This property is suited to our case
because the sites in our set have large differences in terms of the
total incoming packet sizes.
On the left side of Figure 6 we plot the density for the deviation
from the median for the total incoming packet size feature. Z-score
values around the origin correspond to low-deviation, whereas
values far from the origin correspond to high-deviation. We observe
that the correctly classified instances are more concentrated in the
center, while the misclassified instances are more concentrated in
the extremes. This confirms that the instances with higher deviation
from their class mean are more likely to be misclassified.
The right subfigure in Figure 6 shows the number of correctly
and erroneously classified instances for the 1, 755 outliers found
in our dataset. We used the Tukey’s method for outlier removal
based on the inter-quartile range and the first and third quartiles to
identify outliers. The bar plot shows that an outlier is three times
more likely to be misclassified (1, 327) than correctly classified (428).
An instance is counted as misclassified if it is misclassified by at
least one of the classifiers.
Figure 6 suggests that variation within a class such as that pro-
duced by web page dynamism can be beneficial to induce confusions
with other pages.
4.6 Confusion graph
Confusion matrices have been used in prior website fingerprint-
ing literature to visualize and help understand the nature of con-
fusions [11, 21]. However, for a multi-class problem of size 482,
0.00.20.40.6−4−2024Z−scoreDensityCorrectly classifiedMisclassified05001000Correctly classifiedMisclassifiedOutlier classificationCount5 NETWORK-LEVEL FEATURE ANALYSIS
We use classifier-independent feature analysis methods to deter-
mine which features are better predictors for website fingerprinting.
Knowing which features are more distinct across classes and less
distinct within a class helps us understand which features are im-
portant to each website fingerprinting method.
5.1 Methodology
To analyze the nature of the classification errors we borrow two
concepts from the field of machine learning: inter- and intra-class
(or cluster) variance. In particular, we use these concepts in the
following sense:
The intra-class variance of a feature is defined as the variance
of its distribution for a certain class, in this case a site. It quantifies
how much the feature varies among instances of the class. In website
fingerprinting, low intra-class variance indicates a feature remains
stable across different visits to the same page.
Inter-class variance is a measure of how much a feature varies
across different classes. We define it as the variance of the averages
of the feature for each class. That is, we create a vector where each
coordinate aggregates the instances of visits to a site by averaging
their feature values. Then, we calculate the inter-class variance as
the variance of that vector. In website fingerprinting, high-inter-
class variance means that websites are very distinct from each other
with respect to that feature.
In Section 4 we have shown evidence that both inter- and intra-
class variance play a role as the cause of classification errors: mis-
classified pages have similar sizes to the pages they are confused