title:Reduced Cooling Redundancy: A New Security Vulnerability in a Hot
Data Center
author:Xing Gao and
Zhang Xu and
Haining Wang and
Li Li and
Xiaorui Wang
Reduced Cooling Redundancy: A New Security
Vulnerability in a Hot Data Center
Xing Gao∗†
Zhang Xu†
Haining Wang∗
∗University of Delaware
{xgao,hnw}@udel.edu
†College of William and Mary
PI:EMAIL
Xiaorui Wang‡
Li Li‡
‡Ohio State University
{li.2251,wang.3596}@osu.edu
Abstract—Data centers have been growing rapidly in recent
years to meet the surging demand of cloud services. However, the
expanding scale and powerful servers generate a great amount of
heat, resulting in signiﬁcant cooling costs. A trend in modern data
centers is to raise the temperature and maintain all servers in a
relatively hot environment. While this can save on cooling costs
given benign workloads running in servers, the hot environment
increases the risk of cooling failure. In this paper, we unveil a
new vulnerability of existing data centers with aggressive cooling
energy saving policies. Such a vulnerability might be exploited to
launch thermal attacks that could severely worsen the thermal
conditions in a data center. Speciﬁcally, we conduct thermal
measurements and uncover effective thermal attack vectors at
the server, rack, and data center levels. We also present damage
assessments of thermal attacks. Our results demonstrate that
thermal attacks can (1) largely increase the temperature of victim
servers degrading their performance and reliability, (2) negatively
impact on thermal conditions of neighboring servers causing local
hotspots, (3) raise the cooling cost, and (4) even lead to cooling
failures. Finally, we propose effective defenses to prevent thermal
attacks from becoming a serious security threat to data centers.
I.
INTRODUCTION
As cloud computing has become the mainstream of provid-
ing IT services, data centers have expanded their scales and
are equipped with more powerful servers to meet the ever-
increasing service demands. Correspondingly, the amount of
heat emitted by those servers is also surging, which requires the
cooling system to more efﬁciently dissipate the increased heat.
Otherwise, the overheating would potentially lead to serious
hardware failures and even server shutdown for self-protection.
Unfortunately, in recent years, the online service interruptions
due to cooling failures have not been rare in cloud vendors
and enterprises,
including Microsoft [10], Rackspace [11],
Wikipedia [13], iiNet [9], and University of Pennsylvania [12].
To regulate the temperature in computer rooms, a signif-
icant portion of the power consumption of data centers is
used for cooling. The cooling cost has reached 24% of a data
center’s budget [7]. The key factor affecting the cooling cost
Network  and  Distributed  Systems  Security  (NDSS)  Symposium  2018 
18-21  February  2018,  San  Diego,  CA,  USA
ISBN  1-891562-49-5
http://dx.doi.org/10.14722/ndss.2018.23165
www.ndss-symposium.org
of CRAC (Computer Room Air Conditioning) systems is the
supply air temperature. Data centers have deployed a variety
of methods to control the CRAC supply air temperature. For
example, some data centers set the supply air temperature
automatically based on the workload. More importantly, a re-
cent study shows that increasing the supply air temperature by
merely 1◦C can save approximately 2-5 percent of the cooling
power [19]. Thus, there is a trend in data centers to raise the
highest set temperature from 75◦F to 85◦F or even higher.
It is reported that Google has raised the temperature of the
cold aisle to 80◦F [5]. Those aggressive cooling energy saving
policies achieve a low PUE (Power Usage Effectiveness)1 in
a data center. However, the temperature increment also forces
the servers running in a hotter environment than before.
Furthermore, advanced techniques like power oversubscri-
pion [20], [42] have been widely adopted to accommodate
more servers in data centers without upgrading existing power
and cooling infrastructures. While the infrastructures were
initially well designed with sufﬁcient cooling redundancies,
those redundancies have been excessively consumed by power
oversubscription. Under the reduced cooling redundancies, an
accidental synchronization of running intensive workloads in a
set of adjacent servers could result in a local hotspot and even
a cascade effect further deteriorating the thermal conditions.
In this paper, we systematically investigate the security risk
posed by those aggressive policies applied on data centers.
We introduce the concept of thermal attack, which can be
easily and remotely launched to seriously worsen the thermal
conditions at a server level, a rack level, or even a data
center level, without requiring any privileges of a hypervisor.
Thermal attacks simply run thermal-intensive workloads in
victim servers or VMs (Virtual Machines) to rapidly generate
a large amount of heat, forcing the victim servers into a
high temperature. The overheated servers suffer performance
and reliability degradation. Even worse, the accumulated heat
can further exacerbate the thermal condition of the peripheral
atmosphere, raising the inlet
temperature of other servers.
The increase of the inlet temperature then increases other
servers’ outlet temperatures, leading to a vicious cycle. The
consequence could be the great increase of hardware failures
of many servers in a data center, the signiﬁcant waste of the
cooling costs, and even thermal accidents that force some
servers to shut down.
1PUE is the ratio of the total energy consumption of a data center to the
energy consumed by computing equipments in the data center.
To form the basis for mounting a thermal attack, we
measure how thermal-related factors are exhibited in a real
server using different HPC (High Performance Computing)
benchmarks. We observe that CPU-intensive workloads can
generate more heat and cause a higher temperature than other
types of workloads, even if the system utilization is at the
same level; thus it can be used as thermal-intensive workload
to rapidly raise the temperature of a server (i.e., within a
few minutes), despite the fact that the temperature increase
requires the accumulation of heat. Then, based on our thermal
measurements on the real server, we propose to mount thermal
attacks in both non-virtualized and virtualized environments,
as well as a pulsation thermal attack. As expected,
those
attacks can largely raise the temperature of the hosting server
within a short period time. We further conduct a damage
analysis in terms of electromigration, time dependent dielectric
breakdown, thermal cycling intrinsic hard failure mechanisms,
and disk failure.
To evaluate the impact of thermal attacks on the entire data
center, we conduct thermal attacks at the data center level using
a computational ﬂuid dynamics based, trace-driven simulation,
with a special consideration of the air recirculation condition
in the data center. We observe that launching thermal attacks
on less than 2 percent of servers in a data center can seriously
affect the thermal conditions of the whole data center and raise
the cooling costs signiﬁcantly. Even worse, in some severe
attack scenarios, thermal attacks can lead to cooling failures.
Finally, we discuss the attack costs and propose effective
defenses against thermal attacks. Although some prior studies
have proposed temperature-aware load balancing (e.g., [40]),
their approaches are mainly designed based on a static proﬁle
of the data center thermodynamics, which is proﬁled using
normal server workloads. As a result, such solutions cannot
effectively handle hotspots that are generated rapidly by mali-
cious workloads at runtime, because the thermal conditions can
become signiﬁcantly different and even completely opposite to
the static pre-calculated proﬁle.
The remainder of the paper is organized as follows. We
provide the background information on system cooling and its
inherent vulnerability to a thermal attack in data centers in
Section 2. We present our thermal measurement study on a
real server in Section 3. We detail the thermal attacks in non-
virtualized/virtualized environments and the damage analysis
in Section 4. We evaluate the attacks and their impacts at both
the rack and data center levels in Section 5. We propose an
effective defense in Section 6. We survey the related work in
Section 7, and ﬁnally we conclude the paper in Section 8.
II. BACKGROUND
A. Server Cooling
Computers have to be operated within a speciﬁc range of
environmental temperatures. Otherwise, electronic devices may
fail to have their normal characteristics and may even mal-
function. Most hardware failures cause permanent damage and
cannot be recovered. For a server, all its components, like CPU,
memory, cache, and bus, produce heat. The mega-scale and
complicated design of integrated circuits and chips in modern
computer systems further exacerbates the heat generation prob-
lem. As a result, cooling techniques or thermal management
Fig. 1: Layout of a typical data center.
methods are critical for both hardware and software design.
For instance, the chip design must consider heat generation
and emission. The positions of different chip components must
be carefully chosen to avoid hotspots. A fan is also often
used to accelerate the heat emission. In software, various
dynamic thermal management mechanisms are proposed: If
the temperature violates a carefully selected threshold, the
component would have to degrade its performance by reducing
the operating frequency, or it may even be forced to shut down
for protection from physical damages [41]. Therefore, a redline
temperature is often set for a server. If the inlet temperature
exceeds the redline temperature, the server would be shut down
because the fan itself is not sufﬁcient to cool down the server.
B. Data Center Cooling
In a data center, tens to hundreds of thousands of high-
density (e.g., blade) servers are placed in one closed space,
running simultaneously with a high workload utilization. A
large amount of heat
is generated every second by those
servers. Moreover, the fans push the generated heat into the
room. Due to possible air recirculation,
the hot air may
inﬂuence the environmental temperature and further impact
other servers. Therefore, data center cooling is even more
critical due to the high server density.
To cool down servers, existing data centers are equipped
with various cooling technologies, including the traditional
CRAC air cooling, free air cooling, and liquid cooling. Re-
strained by geographic limitations and facility costs, CRAC-
based air cooling remains the most widely used cooling
solution. To enhance cooling efﬁciency, computer rooms are
divided into hot aisles and cold aisles, as shown in Figure 1.
In a cold aisle, cold air is supplied from the raised ﬂoor and
ﬂows through the back side of the server racks to absorb the
heat generated by the servers. The resulting hot air, with the
help of server fans, then enters the hot aisle from the front
side of the server racks, and is returned (through the ceiling
vents) to the CRAC system and cooled down by the chillers
again.
The inlet temperatures of servers must be strictly controlled
in a data center in order to avoid overheating, which increases
the possibility of causing permanent hardware damage. If the
inlet temperature exceeds a threshold, parts of servers or even
racks would be forced to shut down. Ideally, the data center
should have the cold air and hot air perfectly isolated for high
cooling efﬁciency. However, air recirculation can be common
in a data center, in which hot air enters the cold aisles through
2
 small gaps between insulation material and the server racks.
Thus, cold and hot air can get mixed to some extent as a
result. The air density, air ﬂow between servers, supply air
temperature of the cooling facilities, power consumption, and
outlet temperature of each server can get intertwined in a
complicated way to impact the temperature of the whole server
room. Therefore, the hot air generated by the servers could
potentially cause the inlet temperature to violate the threshold.
To keep the inlet temperature below the safe threshold, the
cooling facility’s supply air temperature selection is critical.
For safety, a low supply air temperature is desired to reduce
the possibility of any thermal emergencies. However, a lower
supply air temperature can result in a higher cooling cost. As
a result, many data centers (e.g., Google) are trying to raise
the supply air temperature for a lower cooling cost. Currently,
data centers can remain safe even with a higher supply air
temperature due to the existence of the cooling redundancies.
However, with the deployment of more powerful servers and
the current trend of power oversubscription [21], [54], which
allows managers to deploy more servers in a room, data centers
will soon have almost no redundancies in the near future. As a
result, the possibilities of thermal emergencies can signiﬁcantly
increase with a higher supply air temperature, making data
centers vulnerable to thermal-related attacks.
Currently in data centers, the common cause of a cooling
failure is the breakdown of cooling facilities [13], [11], [9],
which signiﬁcantly reduces cooling capacity and slow down
heat dissipation. Conversely, by intentionally running thermal-
intensive workloads, the vast heat generation can also exceed
the cooling capacity, resulting in a cooling failure in a data
center.
C. Threat of Thermal Attacks
The security threat posed by thermal attacks to a data center
is real and difﬁcult to address, mainly due to the following ﬁve
reasons.
I. The root cause of the threat lies in the wide adoption of
aggressive cooling and power management policies, such as
raising the supply air temperature and power oversubscription,
which allow more servers being deployed in a data center with
less cooling cost. Although data centers were initially designed
with sufﬁcient cooling redundancies, those aggressive policies
signiﬁcantly reduce the cooling redundancies, making data
centers themselves vulnerable to abnormal thermal conditions.
II. Although modern servers are equipped with various
chip-level sensors, such as temperature sensor for each core,
those chip-level sensors cannot provide server-level informa-
tion (e.g., server inlet and outlet temperature). Core tempera-
ture does not equal to inlet temperature and outlet temperature.
A core’s temperature varies much faster. An effective thermal
attack does not need to stress the CPU all the times but
just keep the outlet temperature at a high level. As a result,
Core sensors cannot provide server-level or DC-level thermal
monitoring.
III. While thermal sensors deﬁnitely help to monitor the
thermal conditions in a computer room, most of today’s
production data centers have just a few thermal sensors or
probes for the entire data center. Deploying sensors on the
Fig. 2: Inlet and outlet temperature of servers.
server- or rack-level would be very costly. Even with rack-
level sensors (only 2-4 sensors per rack), it is impossible
for them to cover hundreds of servers in a rack. Thus, the
occurrence of a local hotspot is inevitable. Without the global
knowledge of overall thermal conditions in a computer room,
chip-level protections, like the Intel RAPL (Running Average
Power Limit) providing and limiting the power consumption
for each CPU package, cannot prevent the occurrence of local
hotspots.
IV. To defend against thermal attacks on a data center, the
thermodynamics of a data center is important to consider. The
temperature-based feedback control mechanism would help
to limit the temperature for local hotspots. However, such a
feedback control mechanism does not exist in the current data
centers. At the chip-level, there are some feedback control
mechanisms used for overheating protection; however, at the
data-center-level, without the global knowledge on thermal
conditions, it is very challenging to deploy feedback control
mechanisms for temperature management of the whole data
center.
V. Since thermal-intensive workloads themselves are be-
nign and do not exploit any system vulnerabilities, it is difﬁcult
to distinguish attackers from normal users. Moreover, process-
level power/thermal proﬁling also cannot defend against data
center level thermal attacks. Attackers are not limited to use
just one process to generate much more heat. They can use
many accounts to run different workloads simultaneously to
generate a signiﬁcant amount of heats.
III. REAL SERVER MEASUREMENT
The thermal conditions of a server are affected by various
factors. Unlike power that can be generated and terminated
instantaneously, the change of temperature is a process of heat
accumulation and dissipation. Different components of a server
run simultaneously and generate heat. The accumulated heat
then causes the temperature to raise. To understand the thermal