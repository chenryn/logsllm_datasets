5.3 Transitive trust
Another method to determine if the keys you're receiving are legitimate is to ask someone else. Consider a
case where Alice wants to talk to Bob, but she can't validate Bob's key. However, Alice trusts Carol, and Carol
trusts Dave. Dave has Bob's key and has validated it. Now Alice can have some assurance that the key she is
using for Bob is a legitimate key.
This strategy has a few names that imply a few variations.
5.3.1 Web of Trust
The most popular term since the 1990s has been "web of trust". The web of trust implies a public database
where everyone can see everyone else's "connections" - who trusts whom. These connections may not be
symmetric - just because Alice trusts Carol, doesn't mean carol trusts Alice.
2Okay, maybe not tattoo it, that makes changing your key even harder!
12 | Secure Messaging for Normal People
NCC Group
Figure 7: The Web of Trust
There are many subtle problems with the web
of trust. The biggest one for the purposes of this
paper is that a new user is an island (as shown
above with Frank). Poor Frank trusts no one, and
no one trusts Frank. If Frank were real-life friends
with Dave, an attacker would easily be able to
impersonate Dave - because Frank has no way to
trust the Dave that is in the graph. Frank could
look at Dave and see he is connected to mutual
friends - but Frank can't validate those people
either!
Someone could have replaced Frank's
entire social circle – and Frank would have no
idea. This sounds far-fetched, but it's generally
easy to create spam accounts, and this attack has
been demonstrated before.
Another variant of this attack is a mutual friend of
the group, Gary, who has never signed up for the
service because he's staunchly opposed to the
idea of being near anything that transmits like a
radio. (He also lives in a cabin in the forest, removed his car stereo, and uses his own waste as manure, calling
it "humanure", which is why his friends don't visit him much.) If one day "Gary" signed up for the service - the
social circle wouldn't find out it wasn't the real "Gary" until they talked to him in person!
So, even for the Web of Trust, the first verification done must be another type: either TOFU or Out-Of-Band.
And this is required whenever social circles do not touch. If you communicate with a lot of different groups of
people: this could be very often.
Other attacks focus on the transitive nature of the web of trust. Everyone in the web must have the same
standards for how they "trust" someone. If Carol did a poor job of verifying Dave's key, Alice's message to
Bob could be compromised. The proliferation of social networks, and the easiness in which we may accept
friends on them, is a great example of how "Trust" may become "An attractive person messaged me". An
adversary on the web might do this intentionally, causing anyone who chains trust in this way to receive keys
belonging to that adversary instead of the real ones.
Additionally, the public nature of the web of trust means that it is possible for anyone to see with whom
someone communicates. That is a large leak of the social graph and metadata.
5.3.2 Trusted Introductions
An alternative to the public web of trust are private, trusted introductions. These take the form of someone
you already trust (in the diagram above, Carol could introduce Dave to Alice.) This seems similar to the web of
trust - but it's different because Alice has no way to learn that Dave knows Carol (unless one of them tells her).
Once Alice learns this, she can ask Carol to perform an introduction. The introduction is a private message no
one else sees.
Once introduced, Alice and Dave can communicate independently of Carol and introduce each other to more
people.
13 | Secure Messaging for Normal People
NCC Group
5.4 Validation is forever until it isn't
It's worthwhile to note that in a secure chat solution, key validation is only required once. The exception
to that is if your communications partners lose their keys, (For example, getting a new device or factory
resetting an existing one.) their fingerprint will change - and validating their new key is required just as before.
Once the new key is validated, the old key should not longer be accepted by the application - you wouldn't
want someone having their phone stolen, and the thief being able to impersonate them in an encrypted,
authenticated chat.
14 | Secure Messaging for Normal People
NCC Group
6 Group messaging
The above scenarios have assumed communications that are intended only for two people. Some other issues
arise when attempting to secure multiparty chats. The rest of the examples in this section assume some sort
of end-to-end encryption between all of the participants in the conversation, where each user is obligated to
send the same message to all users in the chat.
6.1 Ice cream attack
Figure 8: Poor Dave, he loves ice cream so much, but
he types so slow!
When a group of people are in a room, it's
obvious to see who is talking, and you can avoid
interrupting people (or do it on purpose.)
But
when several people are on a phone call, there is
that slight delay between when you start talking,
and when you hear someone else start talking.
This delay is magnified when users are typing
on keyboard, especially thumb-typing on small
keyboards. It may seem like a small problem, but
ordering messages is anything but.
The ice cream attack becomes even more power-
ful if the attacker is part of the chat, and purposely
delays some other users' messages to change the
context of what they say!
6.2 Membership changes
Another problem with group chats – especially
when you take into account the problem of
message ordering – is that it's difficult to remove
members.
Suppose the four friends have had
enough of Bob's fanaticism and want to remove
him from their ice cream chat.
How do they remove him?
There aren't many
good options:
1. Any member can arbitrarily remove any other member from a group chat. This works well for small
circles of friends, but completely breaks for random groups of people on the Internet
2. It requires a majority vote. This works horribly in a text messaging scenario where people take a long
time to reply or vote. Alice decides to call a vote to kick Bob... but any discussion about doing so
happens in front of Bob - because he's not kicked yet! And it requires a majority to vote
3. A majority vote with a time limit? It's not clear this is a particularly usable solution either.
4. There is the concept of a "moderator" who has the authority - First off, there's the social aspect of "Which
of your friends would you both trust and respect enough to moderate your circle of friends?" But there's
also the very real problem that the moderator has to be online and responsive or you have the same
delay problems.
15 | Secure Messaging for Normal People
NCC Group
6.3 Group chat protocols
Overall the encryption protocols for group chat systems are not as well understood as those for only two
parties, so there could be other issues lurking beneath the surface here that we don't know about yet. This
means that if your security needs are particularly acute, you probably should avoid group chat.
16 | Secure Messaging for Normal People
NCC Group
7 Open source
Many commentators on the topic of secure messaging clients will tell you that only open source programs are
safe. It is important to understand what exactly open source software contributes to the security posture of a
secure messaging program
7.1 Security audits
Errors in application design, coding, or cryptography can undermine the security of a secure messaging system.
In the past, a commonly held belief in some circles was that open source software would be more secure as
a result of its openness to be examined by anyone. The past couple years have shown that the availability of
source code to the public is not in itself enough to produce a secure result. The discovery of complex bugs
requires a concerted, methodical approach by talented individuals that simply cannot be applied en masse to
all open source software. But, open source software significantly lowers the barrier to both having an audit
conducted, and verifying that developers take security concerns seriously.
Generally speaking, you should use messaging systems that have been audited by experts and where the
problems uncovered during those audits were fixed in a timely manner. If a crypto vendor claims that an audit
was done, but they don't show you the results (hopefully both the findings and the fixes), you're pretty much
taking them at their word that the system is safe for use.
7.2 Does it do what it says?
A better argument for open source secure messaging systems is that an examination of the source is the best
way for the public to determine if a program is actually providing the protections it claims. With a closed
source system, the public can only take it on faith, based on how much they trust the creators of the software.
That being said, most members of the public are not able to do this analysis themselves. Instead, some
well-regarded members of the community might do some analysis of a particular program and then provide
some commentary about the security guarantees it provides.
7.3 Did we get the program we analyzed? (reproducible builds)
Unless you are going to manually inspect and build every program you use, you will have to at some point
take someone else's word that the programs that you use do what they say they do – and this applies to open
source software as much as closed source. If someone you trust analyzes the source of a program, how do
you know that you will receive the same thing that was analyzed? For closed source software, even if there
was an audit conducted by someone you trust, there is no guarantee that what you actually download is what
was audited.
For some threat models, one should assume that software delivery channels (Download sites (even over
HTTPS), App Stores, etc.) are potentially hostile. If your threat model includes these kinds of attackers, you
cannot trust any software provided over any of these channels, even if the application is open source and/or
audited by a trusted party.
On systems where it is easy to build your own software, you could hope that the people you trust who did the
audit provided some sort of signature over the code that was audited. Then, when you download the code
yourself, you could verify that the signature matches, and you could be reasonably certain that the software
you build is the same as the one that was analyzed.
But for people who have things to do, places to see, and sweet, sweet cinnamon buns to eat at every
opportunity - building every piece of software I want to run on my system is out of reach. So how can I, the
cinnamon bun-loving public, know that a program I download was produced from the source code that was
audited? Unfortunately, this is a very difficult problem currently. There are a few projects that have achieved
17 | Secure Messaging for Normal People
NCC Group
the holy grail of "reproducible builds" - but this is only possible on certain platforms (like desktop Operating
Systems and Android).
A trusted auditor could review the code, provide commentary, and then build the code and provide the
fingerprints for that build. A typical user could then use a verification program to ensure that a downloaded
binary actually corresponds to the code that was audited.
It's not likely that this will ever be usable for regular users for platforms like iOS, where only programs from the
App Store are allowed and binaries are modified by Apple before being delivered to a user3
7.4 Operating systems and open source
To continue down the rabbit hole, an application can only be as secure as the operating system it runs on.
Some threat models would include an attacker that could control operating system vendors. Most desktop
and laptop users are running closed-source operating systems. Mainstream mobile operating systems contain
some open-source components, but enough closed-source functionality exists in enough critical areas to
render the distinction meaningless for the purposes of this discussion.
We're still awaiting the year of Linux on the desktop. Even if we had it, most users aren't able to build an OS
from scratch anyway, so a subverted distribution channel would still be an issue.
7.5 How many operating systems are on your device? And what do they run on?
And if we're going to look into the rabbit hole, we may as well look in all the parts of the burrow and see just
how much is down here. (I've always suspected rabbits connect their burrows into a thriving rabbit-tropolis