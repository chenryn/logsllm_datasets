formed (e.g. privilege escalation). Having the exact mapping, the
cache sets are profiled in ascending order. But instead of group-
ing samples per page offset, the feature vector is constructed by
concatenating the sum of high samples for each cache set. Thus,
the final feature vector contains as many values as there are sets
in the cache. The purpose of the ordered vector is to evaluate the
performance of the previous two feature vectors. In the following
Section 4, it is used to mount a comparison attack that captures
cache activities with high resolution, but at the cost of additional
attack steps.
4 EXPERIMENT SETUP AND RESULTS
In total, we conduct three experiments in which our malicious app
detects running applications, visited websites, and streamed videos.
The attack targets are given in Appendix A. For each machine learn-
ing algorithm, we build a multi-class classifier. 90% of the measured
LLC profiles are thereby selected randomly for the training phase,
while the rest of the data is chosen to evaluate the efficiency of the
trained classifier. This 10% holdout approach yields the classifica-
tion rates that are presented in this section. The rates are thereby
based on the most likely label. Throughout the experiments, we
observed that 10-fold cross-validation results are consistent with
a 10% holdout approach. We also evaluated our classifiers against
unknown inputs accounting for activity the models have not been
trained with. In total, we collected more than 800 GB of cache
profiling data to evaluate our inference attack.
4.1 Target Device
We use a Google Nexus 5X with Android v8.0.0 for our experiments.
It features four ARM Cortex-A53 and two ARM Cortex-A57 pro-
cessor cores. The malicious code runs on one of the A57 cores and
profiles the LLC in the background. The LLC on the A57 core cluster
contains 1024 cache sets. The target applications are launched and
transition automatically to the A57 processor cluster. This is be-
cause the scheduler assigns resource-hungry processes (e.g. browser
or multimedia applications) to the A57 cores to leverage their high
performance. During all experiments, the system was connected
to the campus wireless network and background processes from
the Android OS and other apps were running. The timing source in
our malicious app is the POSIX clock_gettime system call, which is
available on all Android versions as part of the Bionic standard C
library [3]. For website inference, we run Google Chrome and for
video inference, we run the Netflix and YouTube apps.2
4.2 ML/DL Configuration
The following paragraphs discuss the parameter selection of the
machine learning algorithms and provide further details about their
usage. SVM and SAE classification is implemented with the help
of LibSVM [5], whereas CNN classification is done using custom
Keras [7] scripts together with the Tensorflow [1] GPU backend.
2Chrome v64.0.3282.137, Netflix v6.16.0, YouTube v13.36.50 .
6
Session 3B: Learning and AuthenticationAsiaCCS ’19, July 9–12, 2019, Auckland, New Zealand219The CNN is trained on a workstation with two Nvidia 1080Ti (Pas-
cal) GPUs, a 20-core Intel i7-7900X CPU, and 64 GB of RAM.
SVM. The ordered and unordered feature vectors are classified with
a linear SVM, while a non-linear SVM is used for the FFT feature
vector. This is because the FFT is computed with non-linear func-
tions (cos, sin) and the labels are linearly increasing for the classes.
This choice is verified in preliminary experiments. Similarly, we
determine that the linear kernel type outperforms radial basis and
polynomial options for the unordered and FFT feature vectors.
SAE. The SAE is constructed with two hidden layers of 250 and 50
neurons, respectively. The maximum number of epochs is set to 400,
since no improvements can be observed afterwards. We decrease
the effect of over-fitting by setting the L2 weight regularization
parameter to 0.01. The output layer is a softmax layer.
CNN. The CNN consists of two 1-D convolution layers that are fol-
lowed by maxpooling, dropout, as well as flatten and dense layers.
The selection of the layer parameters is done with the help of pre-
liminary experiments. Table 5 in Appendix A shows the parameter
space that we explored. Eventually, we selected the parameters that
yielded the lowest validation loss (highlighted in bold). The size of
the first 1-D convolution layer is varied from 8 to 1024. The lowest
validation loss is obtained with a size of 512. Similarly, the size of
the second convolution layer is varied between 32 and 256, and
eventually fixed to 256. A third convolution layer does not improve
classification. The activation function in the convolution layers is
set to rectified linear unit (ReLU). The size of the subsequent max-
pooling layer is varied from 2 to 8. The default size of 2 yields the
best results. The dropout of the following dropout layer is varied
between 0.1 and 0.5, and finally set to 0.2. A higher dropout, as
for example used in computer vision, adversely affects the clas-
sification. Next, the kernel size is adjusted and, out of the values
between 3 and 27, a size of 9 achieves the lowest validation loss. A
flatten layer shapes the data in our network, before a dense layer
with size 200 and tanh activation function is appended. Finally, we
employ a set of standard choices: the kernel initializers are chosen
uniformly at random, an Adam optimizer is used to speed up the
training phase, and the batch size is set to 50, as its effect on the
classification rate is negligible.
4.3 Evaluation Results
The following sections present the evaluation results for application,
website, and video inference.
4.3.1 Application Inference. For this attack, we target 100 ran-
dom mobile applications from the Google Play Store, including
dating, political, and spy apps. The full list is given in Table 3 in
Appendix A. The first 70 apps are used to train and evaluate the
machine learning models, while the remaining 30 apps are treated
as being unknown. Each app is started and profiled for 1.5 sec-
onds as described in Section 3. Within this time frame, we collect
nT = 1, 500 measurement samples per cache set. For the FFT com-
putation, the sampling rate nS = 1.9 MHz and the number of bins
nF = 15. A comparison of the machine learning techniques and
feature vectors is given in Figure 4. It contains three sub-plots that
each show the classification results of SVM, SAE, and CNN over
an increasing number of recorded LLC profiles. Recall that 90%
of the recorded profiles are used for training, whereas the rest is
(a) Ordered.
(b) Unordered.
(c) FFT.
Figure 4: Classification results for application inference over
an increasing number of LLC profiles for (a) ordered, (b) un-
ordered, and (c) FFT feature vectors.
used to obtain the classification rates shown in the plots. The stated
numbers of LLC profiles only reflect the measurement effort for the
training phase, which is done offline on a training device. In the
attack phase on the target device, recording a single LLC profile is
sufficient to conduct a successful inference attack. The same holds
for the results shown in figures 8 and 9. Plot 4(a) illustrates the
results of the comparison attack, which is based on the ordered
feature vector. The ordered profiling allows all three classifiers to
distinguish applications with high confidence. CNN even achieves
a classification rate of 97%. Plot 4(b) shows that classification rates
drop, if the LLC profiles are based on the unordered feature vec-
tor. SAE even falls down to 80%, while CNN remains above 95%.
The CNN we designed is therefore least affected by the unknown
mapping between eviction and cache sets. As shown in Plot 4(c),
the classification rates improve again, if the FFT feature vector is
used. In particular, CNN and SAE benefit from this transformation,
while SVM cannot fully leverage the information in the frequency
spectrum. Our CNN reaches a classification rate of 97.8% and is
thereby able to fully close the gap to the comparison attack.
A further performance metric for the three machine learning
techniques is shown in Figure 5. It displays the receiver operating
characteristic (ROC) curves for the FFT feature vector. For multi-
class classification, ROC curves are computed for each class against
all remaining classes (1 × N-1). The final ROC curve is then the
7
100200300400500600707580859095100Accuracy (%)CNNSVMSAE100200300400500600707580859095100Accuracy (%)CNNSVMSAE100200300400500600Number of LLC Profiles707580859095100Accuracy (%)CNNSVMSAESession 3B: Learning and AuthenticationAsiaCCS ’19, July 9–12, 2019, Auckland, New Zealand220Figure 5: Average receiver operating characteristic (ROC)
curves for SVM, SAE, CNN during application inference.
Figure 7: Probability estimates from the CNN softmax layer
while classifying known and unknown apps.
Figure 6: Average receiver operating characteristic (ROC)
curves for SVM, SAE, CNN during website inference.
Figure 8: Website classification with our CNN for ordered
(solid), unordered (dotted), and FFT (dashed) feature vectors.
average over all computed ROC curves. Figure 5 also provides the
area under the curve (AUC) values in the plot legend. The higher
the AUC, the less the machine learning technique suffers from
false positives. While all three classifiers produce low false positive
rates, CNN outperforms SVM and SAE. Based on the results of
the application detection, we conclude that the CNN is the most
suitable classifier for our inference attack. For website and video
inference, we will therefore only present the results of the CNN.
Unknown Applications. The inherent nature of supervised learn-
ing is to recognize events that are similar to those used in the
training phase. In practice, however, events may occur that the
model has never been trained with. This also applies to our infer-
ence attack. Naturally, we cannot train our models with all existing
applications on the app store. In fact, we want to focus only on
apps that are of interest. Hence, we need a way to recognize and
filter apps we have not trained yet. We achieve this by monitoring
the probability estimates obtained from the softmax layer. Recall
that we train only 70 apps out of the 100 that are given in Table 3.
When we classify all 100 apps on our target device, we obtain the
probability estimates shown in Figure 7. All known apps yield a
high probability estimate close to 1, whereas unknown apps yield
estimates that are significantly lower. We thus label each classifi-
cation that yields a probability estimate below a threshold to be
unknown. This threshold can be tuned according to attack require-
ments. A low value ensures that no application is missed during
the attack. However, this leads to the detection of apps that have
not been executed (false positives). A high threshold increases the
confidence that all detected apps have actually been running. How-
ever, this comes at the cost of misclassifying known apps to be
unknown (false negatives). As a general rule, we recommend to
set the threshold at the intersection of the probability distributions
8
obtained from the softmax layer. In our experiments, we chose a
threshold of 0.84, which is illustrated as a dashed line in Figure 7.
With this approach, our inference attack works reliably even in the
presence of unknown applications on the target device.
4.3.2 Website Inference. The results in the previous section il-
lustrate that our malicious app can reliably detect running appli-
cations with high confidence. Once a browser is detected, the app
tries to infer websites that are currently viewed. For this attack, we
target 100 different websites that are visited in Google Chrome. The
list of websites is given in Table 4 in Appendix A. To emphasize
that browsing histories are sensitive information, the list includes
news, social media, political, and dating websites. For each website,
we profile the LLC for 1.5 seconds and again obtain nT = 1, 500
samples per cache set. The features vectors are constructed in the
same way as for application detection. Figure 8 shows the CNN
classification results for all three feature vectors over an increasing
number of LLC profiles. Similar to application inference, the FFT
results match and slightly overshoot the results of the comparison
attack. With a classification rate of 86%, the CNN is able to infer
viewed websites with satisfactory confidence. The classification
rate is lower compared to application inference, because loading
and rendering websites leaves a weaker footprint in the last-level
cache than opening apps. The ROC curves for the FFT feature vec-
tor are shown in Figure 6. The AUC values in the plot legend again
illustrate that our CNN yields the lowest number of false positives.
The CNN classifier and the FFT feature vector are therefore the
best choices for website inference.
Unknown Websites. As previously, we train the CNN with only
70 websites and subsequently classify all 100 websites from Table 4.
The probability estimates of the softmax layer are similar to the
application inference and are thus not shown for the sake of brevity.
00.20.40.60.8False Positive Rate0.20.40.60.81True Positive RateCNN, AUC=0.998SVM, AUC=0.975SAE,  AUC=0.98600.20.40.60.8False Positive Rate0.20.40.60.81True Positive RateCNN, AUC=0.98SVM, AUC=0.89SAE,  AUC=0.940.20.40.60.81Probability Estimate00.51Distribution unknown known100200300400500600700800Number of LLC Profiles20406080100Accuracy (%)OrderedUnorderedFFTSession 3B: Learning and AuthenticationAsiaCCS ’19, July 9–12, 2019, Auckland, New Zealand221Figure 9: Video classification with our CNN for ordered
(solid), unordered (dotted), and FFT (dashed) feature vectors.
Figure 10: Average receiver operating characteristic (ROC)
curves for SVM, SAE, CNN during video inference.
4.3.3 Video Inference. Similar to website inference, our mali-
cious app also tries to detect videos that are being streamed in the
Netflix and YouTube applications. We therefore target a total of
20 videos, which are given in Table 2 in Appendix A. In contrast
to previous evaluations, we increase the profiling phase to 6 sec-
onds. This is because the LLC footprint of videos is significantly
less distinct compared to applications and websites. Within the
extended profiling phase, we collect nT = 6, 000 samples per cache
set. For the FFT computation, the number of bins, nF , is increased
to 60. Due to the high number of feature values, the size of the first
convolution layer in our CNN is increased to 1024. The rest of the
feature vectors are constructed in the same way as for application
and website inference.
Figure 9 shows the CNN classification results for all three feature
vectors over an increasing number of LLC profiles. The FFT results
again match the comparison attack, but eventually fall behind by
10%. With a classification rate of 80%, our inference attack is able
to infer streaming videos with moderate success. We believe that
the LLC profiles do not contain enough information to distinguish
multiple videos, as video processing is a rather homogeneous task.
In addition, parts of the video decoding are typically outsourced
to the GPU, which further reduces the cache footprint. Regarding
the ROC curves, which are shown in Figure 10, the CNN again
outperforms SVM and SAE. Due to the reduced success rate for
video classification, we skipped the evaluation of unknown videos.
Yet, we expect it to follow the same trend as for application and
website inference.
5 DISCUSSION
The previous section shows that modern machine learning tech-
niques enable successful inference attacks even when simple cache
profiling methods are employed. Throughout our experiments,
frequency-domain transforms of LLC profiles yield high success
rates when being classified by a CNN. The FFT thereby reduces
the noise in the measurements, while the CNN distills consistent
features despite the lacking order with which the cache sets are
profiled. The resulting classification closely matches the compari-
son attack that is based on precisely ordered LLC profiles obtained
with the help of additional attack steps. Clearly, an adversary can
omit these steps when using our inference attack. The limit of our
attack becomes apparent when the LLC activity is less distinct or
faints. While applications and websites can reliably be inferred, the
accuracy drops for video classification. This could be improved by
increasing the profiling time or including other side-channels such
9
as GPU activity. Nevertheless, the results clearly indicate that a
carefully crafted and well-trained CNN enables inference attacks
that are robust, easy to implement, and therefore practical.
Attack in Numbers. The pre-trained CNN model is approximately
24 MiB large. Together with the attack code, this yields a total app
size of 25 MiB. The other ML models are significantly smaller. If the
number of target classes increases, the size of the models grows
linearly. When the app is launched, it first creates the eviction sets
required for LLC profiling. As stated in Section 3.2, this takes 20
seconds on average. Recording one LLC profile takes at most 6
seconds. The subsequent classification is also a matter of seconds.
The work by Ignatov et al. [22] is a useful reference to assess the
performance of CNN classification on Android phones. On the
Nexus 5X, all CNN classification benchmarks finish in under 13
seconds, yielding a total attack time of well under a minute.
Attack Portability. Our inference attack is not limited to the de-
vice and scenario presented in this work. The attack components
are flexible and can be ported easily. The eviction set algorithms
presented in Section 3.2 are generic and can be adapted to other
environments with appropriate choices of r and τjump. The algo-
rithms are robust against changes in cache size, number of sets,
associativity, and replacement policy. They will therefore find evic-
tion sets not only on ARM-based mobile devices but also on x86
systems. With the unordered and FFT feature vectors introduced in
Section 3.3, the exact mapping of eviction sets to cache sets is not re-
quired for an attack. This has multiple advantages. First, the attack
does not require physical addresses and can be launched entirely
from user space. Second, it is agnostic to the page size of the system
and works with pages from less than 4 KiB to multiple MiB. Third,
the attack can be launched without additional and complex attack
steps (e.g. [14]) that would increase the attack effort and lower the
practicality. The designed convolutional neural network is a suitable
fit for the resulting cache observations. It allows to distill the cache
footprint of virtually any activity occurring on the target system.
Future research may study detecting exact versions of applications
or input events such as swipes, touches, or the like. The CNN pre-
sented in this work is a good starting point for any new attack
scenario. Since a fine-tuning of the parameters may be necessary,
Table 5 can be consulted for sensible parameter ranges. In summary,
our inference attack is versatile and constitutes a threat not only to
mobile applications, but also to virtual machines and containers on
servers and any desktop software. We consider the exploration of
other attack scenarios as future work.
100200300400500600700800900Number of LLC Profiles20406080100Accuracy (%)OrderedUnorderedFFT00.20.40.60.8False Positive Rate0.20.40.60.81True Positive RateCNN, AUC=0.9876SVM, AUC=0.9748SAE, AUC=0.9371Session 3B: Learning and AuthenticationAsiaCCS ’19, July 9–12, 2019, Auckland, New Zealand222Countermeasures. The inference attack proposed in this work has
two fundamental requirements. First, it relies on the mutual evic-
tion of cache lines from the last-level cache. This eviction can be
impaired by cache flushing [10], cache partitioning [31], schedul-
ing [46] and line replacement policies [25]. However, most of these
approaches require changes to the processor hardware or intro-
duce substantial performance overhead. The second requirement
is to time memory accesses. While disabling access to timers or
overlaying them with noise [21] complicates attacks, these strate-
gies seem far from sustainable, as timing sources can be crafted
artificially even in restrictive execution environments [9, 40]. An-
other approach is to craft adversarial examples against DL based
classification models [11]. Inci et al. [23] recently showed that CNN-
based side-channel attacks can be prevented by adding specially
crafted noise to performance counters. This approach could also
be adopted by applications running on mobile devices. A general
defense strategy is the detection of ongoing attacks, e.g., by monitor-
ing the memory access behavior of programs [50]. However, most
detection approaches are probabilistic and, thus, suffer from false
positives and false negatives. The generic nature of our inference
attack renders it extremely difficult to defend against, especially
without dedicated support from the processor hardware. For a fur-
ther discussion of relevant countermeasures we refer the interested
reader to the survey by Ge et al. [8].
6 RELATED WORK
Our inference attack relates to previous work in the areas of website
and application inference, cache attacks on ARM-based devices,
and machine learning in the context of side-channel attacks. The