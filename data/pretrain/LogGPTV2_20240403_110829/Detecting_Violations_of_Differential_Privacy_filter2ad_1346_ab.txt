density f (x | b) = 1
2) to query an-
2b
swers. The chosen variance depends on ϵ and the global sensitivity.
We use the notation Lap(b) to refer to the Laplace noise.
exp(−|x|/b) and variance 2b
Definition 3.3 (The Laplace mechanism [17]). For any numerical
query q : D → Rn, the Laplace mechanism outputs
M(D, q, ϵ) = q(D) + (η1, . . . , ηn)
where ηi are independent random variables sampled from Lap(∆q/ϵ).
Theorem 3.4 ([19]). The Laplace mechanism is ϵ-differentially
private.
3.2 Hypothesis Testing
A statistical hypothesis is a claim about the parameters of the dis-
tribution that generated the data. The null hypothesis, denoted by
H0 is a statistical hypothesis that we are trying to disprove. For
example, if we have two samples, X and Y where X was gener-
ated by a Binomial(n, p1) distribution and Y was generated by a
Binomial(n, p2) distribution, one null hypothesis could be p1 = p2
(that is, we would like to know if the data supports the conclusion
that X and Y came from different distributions). The alternative
hypothesis, denoted by H1, is the complement of the null hypothesis
(e.g., p1 (cid:44) p2).
A hypothesis test is a procedure that takes in a data sample
Z and either rejects the null hypothesis or fails to reject the null
hypothesis. A hypothesis test can have two types of errors: type I
and type II. A type I error occurs if the test incorrectly rejects H0
when it is in fact true. A type II error occurs if the test fails to reject
H0 when the alternative hypothesis is true. Type I and type II errors
are analogous to false positives and false negatives, respectively.
In most problems, controlling type I error is the most important.
In such cases, one specifies a significance level α and requires that
the probability of a type I error be at most α. Commonly used values
for α are 0.05 and 0.01. In order to allow users to control the type I
error, the hypothesis test also returns a number p – known as the
p-value – which is a probabilistic estimate of how unlikely it is that
the null hypothesis is true. The user rejects the null hypothesis if
p ≤ α. In order for this to work (i.e. in order for the Type I error to
be below α), the p-value must satisfy certain technical conditions:
(1) a p-value is a function of a data sample Z, (2) 0 ≤ p(Z) ≤ 1, (3) if
the null hypothesis is true, then P(p(Z) ≤ α | H0) ≤ α.
A relevant example of a hypothesis test is Fisher’s exact test [23]
for two binomial populations. Let c1 be a sample from a Binomial(n1, p1)
distribution and let c2 be a sample from a Binomial(n2, p2) distribu-
tion. Here p1 and p2 are unknown. Using these values of c1 and c2,
the goal is to test the null hypothesis H0 : p1 ≤ p2 against the alter-
native H1 : p1 > p2. Let s = c1 + c2. The key insight behind Fisher’s
test is that if C1 ∼ Binomial(n1, p1) 1 and C2 ∼ Binomial(n2, p2) and
if p1 = p2, then the value P(C1 ≥ c1 | C1 + C2 = s) does not depend
on the unknown parameters p1 or p2 and can be computed from
the cumulative distribution function of the hypergeometric distri-
bution; specifically, it is equal to 1 − Hypergeometric.cdf(c1 − 1 |
n1 + n2, n1, s). When p1  eϵ P(M(D2) ∈ E). Thus a counterexample involves
finding these two adjacent inputs D1 and D2, the bad output set E,
and to show that for these choices, P(M(D1) ∈ E) > eϵ P(M(D2) ∈
E).
Ideally, one would compute the probabilities P(M(D1) ∈ E) and
P(M(D2) ∈ E). Unfortunately, for sophisticated mechanisms, it is
not always possible to compute these quantities exactly. However,
we can sample from these distributions many times by repeatedly
running M(D1) and M(D2) and counting the number of times that
the outputs fall into E. Then, we need a statistical test to reject the
null hypothesis P(M(D1) ∈ E) ≤ eϵ P(M(D2) ∈ E) (or fail to reject
it if the algorithm is ϵ-differentially private).
We will be using the following conventions:
• The input to most mechanisms is actually a list of queries
Q = (q1, . . . , ql) rather than a database directly. For example, al-
gorithms to release differentially private histograms operate on
a histogram of the data; the sparse vector mechanism operates
on a sequence of queries that each have global sensitivity equal
to 1. Thus, we require the user to specify how the input query
answers can differ on two adjacent databases. For example, in a
histogram, exactly one cell count changes by at most 1. In the
sparse vector technique [19], every query answer changes by
at most 1. To simplify the discussion, we abuse notation and
use D1, D2 to also denote the answers of Q on the input adja-
cent databases. For example, when discussing the sparse vector
technique, we write D1 = [0, 0] and D2 = [1, 1]. This means
there are adjacent databases and a list of queries Q = [q1, q2]
such that they evaluate to [0, 0] on the first database and [1, 1]
on the second database.
• We use ϵ0 to indicate the privacy level that a mechanism claims
• We use Ω for the set of all possible outputs (i.e., range) of the
to achieve.
mechanism M. We use ω for a single output of M.
1This is read as "C1 is a random variable having the Binomial(n1, p1) distribution".
CCS ’18, October 15–19, 2018, Toronto, ON, Canada
Zeyu Ding, Yuxin Wang, Guanhong Wang, Danfeng Zhang, and Daniel Kifer
• We call a subset E ⊆ Ω an event. We use p1 (respectively, p2)
to denote P(M(Di) ∈ E), the probability that the output of M
falls into E when executing on database D1 (respectively, D2).
• Some mechanisms take additional inputs, e.g., the sparse vector
mechanism. We collectively refer to them as args.
Our discussion is organized as follows. We provide an overview
of the counterexample generator in Section 4.1. Then we incre-
mentally explain our approach. In Section 4.2 we present the hy-
pothesis test. That is, suppose we already have query sequences
D1 and D2 that are generated from adjacent databases and an out-
put set E, how do we test if P(M(D1) ∈ E) ≤ eϵ P(M(D2) ∈ E) or
P(M(D1) ∈ E) > eϵ P(M(D2) ∈ E)? Next, in Section 4.3, we con-
sider the question of output selection. That is, suppose we already
have query answers D1 and D2 that are generated from adjacent
databases, how do we decide which E should be used in the hy-
pothesis test? Finally, in Section 4.4, we consider the problem of
generating the adjacent query sequences D1 and D2 as well as
additional inputs args.
The details of specific mechanisms we test for violations of dif-
ferential privacy will be given in the experiments in Section 5.
4.1 Overview
At a high level, the counterexample generator can be summarized
in the pseudocode in Algorithm 1. First, it generates an InputList, a
set of candidate tuples of the form (D1, D2, arдs). That is, instead of
returning a single pair of adjacent inputs D1, D2 and any auxiliary
arguments the mechanism may need, we return multiple candidates
which will be filtered later. Each adjacent pair (D1, D2) is designed
to be short so that a developer can understand the problematic
inputs and trace them through the code of the mechanism M. For
this reason, the code of M will also run fast, so that it will be possible
to later evaluate M(D1, arдs) and M(D2, arдs) multiple times very
quickly.
Algorithm 1: Overview of Counterexample Generator
1 function CounterExampleDetection(M, ϵ):
ϵ: desired privacy (is M ϵ-differentially private?)
input: M: mechanism
// get set of possible inputs: (D1, D2, arдs)
InputList ← InputGenerator(M, ϵ)
E, D1, D2, arдs ← EventSelector(M, ϵ, InputList)
p⊤, p⊥ ← HypothesisTest(M, ϵ, D1, D2, arдs, E)
return p⊤, p⊥
2
3
4
5
The next step is the EventSelector. It takes each tuple(D1, D2, arдs)
from InputList and runs M(D1, arдs) and M(D2, arдs) multiple times.
Based on the type of the outputs, it generates a set of candidates
for E. For example, if the output is a real number, then the set of
candidates is the set of intervals (a, b). For each candidate E and
each tuple (D1, D2, arдs), it counts how many times M(D1, arдs)
produced an output ω ∈ E and how many times M(D2, arдs) pro-
duced an output in E. Based on these results, it picks one specific
E and one tuple (D1, D2, arдs) which it believes is most likely to
show a violation of ϵ0-differential privacy.
Finally, the HypothesisTest takes the selected E, D1, D2, and args
and checks if it can detect statistical evidence that P(M(D1, arдs) ∈
E) > eϵ P(M(D2, arдs) ∈ E) – which corresponds to the p-value
p⊤ – or eϵ P(M(D1, arдs) ∈ E) 
eϵ P(M(D2, arдs) ∈ E).
• p⊥. Small values indicate that probably P(M(D2, arдs) ∈ E) >
eϵ P(M(D1, arдs) ∈ E).
For each ϵ, we plot the minimum of p⊤ and p⊥. Figure 1 shows
typical results that would appear when the counterexample detector
is run with real mechanisms M as input.
In Figure 1a, M correctly satisfies the claimed ϵ0 = 0.7 differen-
tial privacy. In that plot, we see that the p-values corresponding
to ϵ = 0.2, 0.4, 0.6 are very low, meaning that the counterexam-
ple generator can prove that the algorithm does not satisfy differ-
ential privacy for those smaller values of ϵ. Near 0.7 it becomes
difficult to find counterexamples; that is, if an algorithm satisfies
0.7-differential privacy, it is very hard to statistically prove that it
does not satisfy 0.65 differential privacy. This is a typical feature of
hypothesis tests as it becomes difficult to reject the null hypothesis
when it is only slightly incorrect (e.g., when the true privacy pa-
rameter is only slightly different from the ϵ we are testing). Now,
any algorithm that satisfies 0.7-differential privacy also satisfies
ϵ-differential privacy for all ϵ ≥ 0.7. This behavior is seen in Figure
1a as the p-values are large for all larger values of ϵ.
Figure 1b shows a graph that can arise from two distinct sce-
narios. One of the situations is when the mechanism M claims to
provide 0.7-differential privacy but actually provides more privacy
(i.e. ϵ-differential privacy for ϵ  eϵ P(M(D2) ∈ E)
or if P(M(D2) ∈ E) > eϵ P(M(D1) ∈ E), as that would demonstrate
a violation of ϵ-differential privacy. We treat the P(M(D1) ∈ E) >
eϵ P(M(D2) ∈ E) case in this section, as the other case is symmetric.
To do this, the high level idea is to:
• Define p1 = P(M(D1) ∈ E) and p2 = P(M(D2) ∈ E)
Algorithm 2: Hypothesis Test. Parameter n: # of iterations
1 function pvalue(c1, c2, n, ϵ):
2
3
4
5 function HypothesisTest(n, M, arдs, ϵ, D1, D2 , E):
˜c1 ← Binomial(c1, 1/eϵ)
s ← ˜c1 + c2
return 1 − Hypergeom.cdf(˜c1 − 1 | 2n, n, s)
input: M: mechanism
arдs: additional arguments for M
ϵ: privacy budget to test
D1, D2: adjacent databases