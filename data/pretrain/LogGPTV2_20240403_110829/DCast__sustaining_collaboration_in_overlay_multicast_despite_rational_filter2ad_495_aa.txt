title:DCast: sustaining collaboration in overlay multicast despite rational
collusion
author:Haifeng Yu and
Phillip B. Gibbons and
Chenwei Shi
DCast: Sustaining Collaboration in Overlay Multicast
despite Rational Collusion
Haifeng Yu
National University of Singapore
Republic of Singapore
Phillip B. Gibbons
Intel Labs
Pittsburgh, PA, USA
Chenwei Shi
Mozat Pte Ltd
Republic of Singapore
PI:EMAIL
PI:EMAIL
PI:EMAIL
ABSTRACT
A key challenge in large-scale collaborative distributed systems is
to properly incentivize the rational/selﬁsh users so that they will
properly collaborate. Within such a context, this paper focuses on
designing incentive mechanisms for overlay multicast systems. A
key limitation shared by existing proposals on the problem is that
they are no longer able to provide proper incentives and thus will
collapse when rational users collude or launch sybil attacks.
This work explicitly aims to properly sustain collaboration de-
spite collusion and sybil attacks by rational users. To this end, we
propose a new decentralized DCast multicast protocol that uses a
novel mechanism with debt-links and circulating debts. We for-
mally prove that the protocol offers a novel concept of safety-net
guarantee: A user running the protocol will always obtain a rea-
sonably good utility despite the deviation of any number of rational
users that potentially collude or launch sybil attacks. Our prototyp-
ing as well as simulation demonstrates the feasibility and safety-net
guarantee of our design in practice.
Categories and Subject Descriptors
C.2.4 [Computer-Communication Networks]: Distributed Sys-
tems
Keywords
Algorithmic mechanism design, incentive mechanism, rational col-
lusion, sybil attack, whitewashing attack, overlay multicast
1.
INTRODUCTION
The past decade witnessed the emergence of many large-scale
collaborative distributed systems, where the individual rational (self-
ish) peers are supposed to collaborate. How to incentivize these ra-
tional peers to sustain such collaboration (and avoid the tragedy
of the commons) is a key and well-known problem [12, 20, 21,
22]. This paper focuses on one particular kind of collaborative
distributed system, overlay multicast, for its practical importance.
Overlay multicast has key practical applications such as video
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’12, October 16–18, 2012, Raleigh, North Carolina, USA.
Copyright 2012 ACM 978-1-4503-1651-4/12/10 ...$15.00.
streaming of sporting events or TV programs. A peer in over-
lay multicast is supposed to forward/relay the multicast data to
other peers. Without proper incentives however, a rational peer
may choose to save bandwidth by not forwarding the data to oth-
ers. Such user preference of minimizing bandwidth consumption
has been widely observed in previous measurement studies [1, 24],
where 30% of the Napster users deliberately under-reported their
available bandwidth to discourage others from downloading from
them and 70% of the Gnutella users did not contribute any band-
width. One way to sidestep this incentive problem in overlay multi-
cast, of course, is to deploy servers with high outgoing bandwidth
to directly send the data to each individual peer. Unfortunately,
compared to other collaborative systems, multicast is much less
amenable to such cloud computing style of solution, due to its ex-
cessive bandwidth requirements. As a result, current large-scale
commercial multicast systems (e.g., Adobe Flash Player 10.1 and
PPLive online TV platform [22]) often rely on overlay multicast.
To prevent peers from free-riding, researchers have proposed a
number of interesting and practical proposals on incentivizing over-
lay multicast in particular [9, 14, 15, 18, 22] and various collabo-
rative systems in general [2, 26, 30]. Unfortunately, these prior
solutions all share the key limitation that they can no longer prop-
erly provide incentives if rational peers collude, launch sybil at-
tacks1 [4], or launch whitewashing attacks2. In particular, some of
these incentive mechanisms may fail even if each rational peer only
colludes with a few other peers. While in some other designs, a peer
may survive purely on “seed money/credit” obtained via repeated
whitewashing (see Section 2). Thus in the presence of collusion
or sybil/whitewashing attacks, these prior proposals will again lead
to the tragedy of the commons, where no peer can obtain any data
from other peers.
It is worth noting that collusion in the virtual
world is far easier than one might expect at ﬁrst thought. For exam-
ple, all peers using the same “hacked” version of a protocol (e.g.,
posted online) are already coordinated and can readily collude. The
colluding peers do not need to know each other beforehand and the
collusion can form on-the-ﬂy.
Challenges in defending against collusion. The inability of these
previous approaches to deal with collusion is related to the follow-
ing two challenges. First, the key to incentivizing collaboration is
always the implementation of a (potentially implicit) punishment
mechanism, to punish those peers who fail to collaborate. The pres-
ence of collusion makes it challenging to punish. Evicting a peer
is no longer an effective punishment — the evicted peer may ob-
tain multicast data from its colluding peers. This problem is further
1In this paper, we focus on rational sybil attacks, in which it proﬁts
a user to create many identities.
2Whitewashing attack refers to a user abandoning her/his identity
to evade punishment and then rejoining with a new identity.
567complicated by sybil attacks and whitewashing attacks. Existing
sybil defense mechanisms (e.g., [28]) need to assume collaboration
among the peers in the ﬁrst place.
Second, in some cases the colluding peers might be able to ob-
tain the multicast data from each other more efﬁciently. For ex-
ample, suppose the multicast protocol is based on random gossip-
ing, for better robustness against churn. If the colluding peers have
low churn, then they can switch to using more efﬁcient tree-based
multicast amongst themselves. Such deviation is already proﬁtable.
Furthermore, the colluding peers can either continue to gossip with
the non-deviators as usual, or they can do so less frequently. De-
tecting such deviation from the non-deviators’ perspective is chal-
lenging, because occasional participation is indistinguishable from
legitimate but slow participation.
Our results: Safety-net guarantee and the DCast protocol. This
work aims to properly sustain collaboration in overlay multicast
despite collusion and sybil/whitewashing attacks by rational users.
As hinted by the previous example, we will ﬁrst show that in over-
lay multicast, it is impossible in practice to prevent proﬁtable de-
viations by a colluding set of peers. This contrasts sharply with
previous proposals that directly aim at eliminating proﬁtable devi-
ations (since they do not deal with collusion) [9, 14, 15, 18, 22].
On the other hand, note that it is not deviation that is harmful —
rather, it is the deviation’s negative impact on other (non-deviating)
peers that is harmful. This leads to our novel concept of a safety-net
guarantee in a game theoretic context, which formalizes the goal of
this work. Intuitively, a protocol offers a safety-net guarantee if a
peer running the protocol (called a non-deviator) is guaranteed to
at least obtain a reasonably good utility (called the safety-net util-
ity), despite deviations by any number of rational users who may
collude or launch sybil/whitewashing attacks. Note that in classic
security settings focusing on malicious attackers, one can often as-
sume that the number of malicious users is limited. In comparison
in our game theory context, since all users are rational and aim to
maximize their utilities, all users are ready to collude or deviate if
opportunities arise.
While the concept of a safety-net guarantee helps to circumvent
the above impossibility, the two fundamental challenges discussed
earlier remain. This paper then proposes a novel DCast multicast
protocol, which is the ﬁrst practical overlay multicast protocol with
such a safety-net guarantee. In contrast, previous designs [9, 14,
15, 18, 22] lack a safety-net guarantee, and a non-deviator can fail
to obtain any multicast data at all from other peers in the presence
of collusion among rational peers. DCast is also robust against a
small number of malicious peers. For achieving these guarantees,
DCast requires no crypto operations except for basic message au-
thentication and encryption.
Formally, we prove that DCast offers a safety-net guarantee with
a good safety-net utility. We further implement a DCast prototype
in Java, as well as a detailed simulator for DCast. Experimental
results from running the prototype on Emulab (with 180 peers)
and from simulation (with 10,000 peers) conﬁrm the feasibility and
safety-net guarantee of our DCast design in practice.
Key techniques. DCast achieves the safety-net guarantee via the
novel design of debt-links and doins. Debt-links instantiate the idea
of pairwise entry fees, which allow a peer to interact with some spe-
ciﬁc peers to a limited extent. A debt-link from a peer A to a peer B
is established by B sending some junk bits to A. Doins (shorthand
for debt coins) instantiate the idea of proﬁtable interactions. Doins
are circulating debts and can be viewed as a variant of bankless vir-
tual currency. A doin can be issued by any peer and circulates only
on debt-links. A doin occupies a debt-link that it passes through,
until the doin is eventually paid.
Occupied debt-links serve as an effective punishment, even in the
presence of collusion, to a peer that fails to pay for a doin. The doin
payment amount is explicitly designed to be strictly larger than the
cost of issuing the doin. Thus with proper debt-link reuse, the ac-
cumulated proﬁt from doin payments will offset and further exceed
the cost of accepting a debt-link establishment. This in turn in-
centivizes peers to accept debt-link establishments and issue doins.
Under proper parameters, such proﬁt also conveniently incentivizes
the colluding peers, even if they can enjoy a lower cost of dissemi-
nating data among themselves.
Summary of contributions. In summary, this paper aims to in-
centivize overlay multicast in the presence of rational collusion, a
setting where prior solutions will collapse. We make the following
main contributions: i) we introduce the notion of a safety-net guar-
antee in a game theoretic context, ii) we present the novel DCast
multicast protocol, iii) we formally prove that DCast offers a safety-
net guarantee, and iv) we demonstrate via prototyping and simula-
tion the feasibility and safety-net guarantee of the design in prac-
tice.
2. RELATED WORK
Concepts related to our safety-net guarantee. Designing algo-
rithms for sustaining collaboration among rational users is usually
referred to as algorithmic mechanism design [5]. Almost all previ-
ous efforts in algorithmic mechanism design aim to eliminate prof-
itable individual deviations (by forming a Nash equilibrium), or
to eliminate proﬁtable group deviations (by forming a collusion-
resistant Nash equilibrium [19]). In comparison, this work shows
that such equilibrium is not possible in our context and thus explic-
itly does not focus on equilibrium. Instead, we aim to protect the
utility of the non-deviators. Our goal is more related to the price
of collusion [8], which quantiﬁes the negative impact of collusion
on the overall social utility in a congestion game. In comparison,
our safety-net guarantee bounds the negative impact of collusion on
the utility of individual non-deviators in a multicast game. Further-
more, we consider all pareto-optimal strategy proﬁles of the collud-
ing peers, while the price of collusion considers only the strategy
proﬁle that maximizes the overall sum of the utilities of the collud-
ing peers.
Incentivizing overlay multicast. A number of interesting and
practical techniques have been developed for building incentives
into overlay multicast [9, 14, 15, 18, 22]. When rational users col-
lude, however, none of these approaches can continue to provide
proper incentives.
Speciﬁcally in the Contracts system [22], a peer issues receipts
to those peers who send it data. These receipts serve to testify those
peers’ contribution. Contracts is vulnerable to even just two collud-
ing users. For example, a user A wanting the multicast data can
trivially obtain fake receipts from a buddy B who does not actually
need the multicast data. (In return, A may give fake receipts to B
in some other multicast sessions where A does not need the data.)
Receipt validation as in Contracts does not help here since B does
not need the data. If we have another colluding peer C who fur-
ther gives B fake receipts, then A’s contribution will further have
a good effectiveness (see [22] for deﬁnition), meaning that A is
credited with contributing to other contributing peers. BAR gos-
sip [15] and FlightPath [14] rely on evicting peers as an effective
punishment. Section 1 already explained that this will not be effec-
tive with collusion. The approaches in [9, 18] punish a deviator by
not sending it data, which is equivalent to eviction. Similarly, all
these approaches are vulnerable to rational sybil attacks and white-
washing. Second, in scenarios where the colluding peers can ob-
568tain the data from each other more efﬁciently, the protocols in [9,
15, 18, 22] can no longer guarantee non-deviators’ utility. Flight-
Path [14] achieves a stronger guarantee under the assumption that a
peer will not deviate unless the deviation will bring at least ǫ (e.g.,
10%) extra utility, which corresponds to an ǫ-Nash [16]. The value
of ǫ usually is small since otherwise the ǫ-Nash assumption itself
becomes questionable. However, the colluding peers may easily
adopt optimizations speciﬁc to their own characteristics (e.g., low
churn rate) that far exceed such 10% threshold.
In contrast, the
safety-net guarantee of DCast continues to hold even if the utility
gain of the colluding peers is much higher (e.g., 100% or 200%).
In the grim trigger approach [13], if a peer does not receive
enough multicast data, it conceptually signals the multicast root to
shut down the entire multicast session. While this is indeed robust
against rational collusion, the approach is rather vulnerable to even
just a single malicious peer and to various performance instabili-
ties in the system. More recently, Tran et al. [25] aims to maintain
collusion-resilient reputation scores for peers, but their approach’s
guarantee is rather weak and colluding peers can increase their rep-
utation scores unboundedly as the number of colluding peers in-
creases. Finally, a preliminary version of this work was published
as a 2-page Brief Announcement [29].
Incentivizing other collaborative systems. There have been many
efforts on incentivizing general p2p systems. These efforts are
largely heuristics and often do not even prevent individual devia-
tion, let alone dealing with collusion. A further common limitation
of these approaches [2, 11, 21] is the need to give new users some
“seed money/credit” to bootstrap them (regardless of whether cur-