loop in ADVISE, we require that an optimization problem be
solved for each state transition. The inclusion of the adversary
decision poses a signiﬁcant performance hurdle.
The time to complete the adversary decision algorithm
corresponds directly to the size of the state lookahead tree
(SLAT). For typical models, the SLAT size can be hard to
compute, since the number of enabled attacks is not known a
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:50:07 UTC from IEEE Xplore.  Restrictions apply. 
priori. However, for a general model with A attack steps, each
attack step has O or fewer outcomes, and the adversary has a
look-ahead of L, the upper bound of the size of the SLAT is
AOL. Solving for the adversary decision is exponential in the
look-ahead.
The exponential algorithm is executed for each state the
adversary enters, during thousands of simulation iterations.
However, the adversary’s decision is static with respect to the
state. By caching the decision associated with a state, we avoid
subsequent rebuilding of the SLAT, and the complexity of the
decision algorithm is reduced from construction of the SLAT
to a simple lookup. Using a cache allows us to quickly return
the adversary’s decision if the adversary revisits a state.
However, we can utilize the cache for more than a single
simulation iteration. In order to return metrics that are within
the speciﬁed conﬁdence interval, we run a given experiment
thousands of times. Since nothing in the underlying model
changes between iterations, we can continue to use the cache.
Depending on the model, we can achieve a 100% cache hit rate
after the ﬁrst few simulation iterations, since only the attack
outcomes are probabilistic.
B. SLAT Construction
The simplest method of executing the adversary decision
algorithm is to construct the SLAT in a depth-ﬁrst manner.
That method leads to the AOL SLAT size mentioned above.
An improvement is to use a graph-based approach, storing
intermediate results of the SLAT and reusing them if the same
state is encountered again at the same look-ahead level.
We accomplish this, not by constructing the entire graph
and iterating over it, but rather by caching the cost, detection
probability, and expected payoff of the sub-tree for each state
and look-ahead level pair. In practice, that is an extension to
the depth-ﬁrst exploration of the SLAT, which signiﬁcantly
reduces the branching of the SLAT.
Because all intermediate values are cached, the size of the
SLAT is bounded by the look-ahead, L, times the size of
the state space (L ∗ 2|A||K||G|). That can still be very large;
however, because of the sequential nature of attacks, in typical
models, the reachable state space is signiﬁcantly smaller than
the potential state space.
C. Performance Data
In Table I, we present full execution timings for the base
implementation (Base), when caching was used at the decision
level (ADA Cache), when caching was used within the SLAT
(SLAT Cache), and ﬁnally when both caches were used
simultaneously (SLAT & ADA). The hyphen indicates that
one simulation could not be included in the data because it
took too long to execute. Those timings are generated from
an easily extensible model, which is fully described in [7].
The model consists of eight accesses, eight attack steps, and
seven goals. One access is designated as the initial access.
Then, seven of the attack steps are set up in order, so that
they can only be performed sequentially. The eighth attack
step is always enabled. Additionally, each attack step has two
7
outcomes, success and failure. The structure of the model
provides the exact size of the SLAT, since two attack steps
are always enabled, and each attack step has two outcomes.
The size of the SLAT is 4N , where N is the look-ahead.
Look-ahead
3
4
5
6
7
8
9
10
Base
4.79
17.80
69.12
289.81
1134.02
4303.11
18455.96
-
SLAT Cache
5.23
8.96
13.89
19.78
26.99
34.63
42.50
50.64
TABLE I
ADA Cache
0.57
0.57
0.57
0.58
0.60
0.65
0.94
1.94
SLAT & ADA
0.60
0.57
0.58
0.58
0.57
0.57
0.57
0.56
SIMULATION TIMING (IN SECONDS)
The base algorithm scales poorly with respect to the look-
ahead. By caching within the SLAT, essentially converting the
tree to a graph, we achieve signiﬁcant improvements. However,
those computations are repeated for each of the 100,000 runs.
Caching the adversary’s decision results in a single decision
computation over all of the simulation iterations for each state.
The times, which are shown in the ADA Cache column of
Table I, approach the lowest timing bound, because of the
simulation overhead. However, for large look-aheads, even a
single decision calculation takes a signiﬁcant amount of time
unless it is optimized. When we combine the two methods,
the execution time remains close to the simulation overhead
threshold, even with large look-aheads.
V. RELATED TOOLS
The ADVISE formalism implementation in M¨obius is not
the only system security analysis tool.
Researchers at George Mason University developed the
Topological Vulnerability Analysis (TVA) tool [18] to generate
attack graphs based on input from a network vulnerability
scanner. They developed a database of vulnerabilities that
speciﬁes a precondition and postcondition for each vulnerabil-
ity. To create an attack graph, the system information from the
scanner and the vulnerability information from the database
are combined with information about the starting state and
goal state of the attacker. The analysis of the attack graph
ﬁnds a minimum set of conditions such that the attacker can
reach the attack goal.
By adding visualization capabilities,
the researchers at
George Mason University developed a tool called Combina-
torial Analysis Utilizing Logical Dependencies Residing on
Networks (CAULDRON) [19], which is now available as a
commercial product.
Researchers at MIT Lincoln Laboratory developed a sys-
tem called NETwork Security and Planning Architecture
(NetSPA) [20] to generate attack graphs. NetSPA receives in-
put data from a network vulnerability scanner and vulnerability
databases. NetSPA also computes reachability, while assuming
monotonicity and independence of the time required to execute
an attack.
To facilitate the analysis of attack graphs generated by
NetSPA, an interactive visualization tool called Graphical At-
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:50:07 UTC from IEEE Xplore.  Restrictions apply. 
tack Graph and Reachability Network Evaluation Tool (GAR-
NET) [21] was developed. Like CAULDRON, GARNET dis-
plays the network topology and attack steps on that topology.
Further visualization improvements were implemented in the
next iteration of the tool, called NAVIGATOR (Network Asset
VIsualization: Graphs, ATtacks, Operational Recommenda-
tions) [22]. NAVIGATOR’s main contribution is the overlaying
of results on the network topology map.
Both CAULDRON and NAVIGATOR focus on the reacha-
bility of an attack goal. They only analyze live systems based
upon scanner input, and assume that there is no defensive
response. In contrast, ADVISE simulates adversary behavior
over time using attractiveness functions, provides the ability to
model arbitrary vulnerabilities, analyzes real or yet unrealized
systems, incorporates business and operational models, and
provides predictive probabilistic security metrics.
VI. CONCLUSION
The main contribution of this paper is a detailed discus-
sion of the implementation of the ADVISE formalism within
the M¨obius tool, and performance enhancements to solving
ADVISE models via simulation.
The ADVISE atomic model formalism implementation pro-
vides a graphical editor that modelers can use to construct
ADVISE models. Because we implemented the ADVISE
atomic model to conform with the standardized M¨obius AFI,
ADVISE models are fully integrated in the M¨obius tool.
The addition of ADVISE to M¨obius allows users to easily
model system security and adversary preferences, and quickly
compute relevant quantitative security metrics.
VII. ACKNOWLEDGMENTS
The work described in this paper was conducted, in part,
with funding from the Department of Homeland Security
under contract FA8750-09-C-0039 with the Air Force Re-
search Laboratory and the Army Research Ofﬁce under Award
No. W911NF-09-1-0273. We particularly wish to thank Dou-
glas Maughan, Director of the Cyber Security Division in
the Homeland Security Advanced Research Projects Agency
(HSARPA), within the Science and Technology (S&T) Direc-
torate of the Department of Homeland Security (DHS).
The authors would like to acknowledge the contributions of
current and former members of the M¨obius team and the work
of outside contributors for the M¨obius project. The authors
would also like to thank Jenny Applequist for her editorial
work.
REFERENCES
[1] D. D. Deavours, G. Clark, T. Courtney, D. Daly, S. Derisavi, J. M. Doyle,
W. H. Sanders, and P. G. Webster, “The M¨obius framework and its
implementation,” IEEE Transactions on Software Engineering, vol. 28,
no. 10, pp. 956–969, Oct. 2002.
[2] J. M. Doyle, “Abstract model speciﬁcation using the M¨obius modeling
tool,” Master’s thesis, University of Illinois at Urbana-Champaign,
Urbana, Illinois, January 2000.
8
[3] S. Derisavi, P. Kemper, W. H. Sanders, and T. Courtney, “The M¨obius
state-level abstract functional interface,” Perf. Eval., vol. 54, no. 2, pp.
105–128, Oct. 2003.
[4] D. Daly, D. D. Deavours, J. M. Doyle, P. G. Webster, and W. H.
Sanders, “M¨obius: An extensible tool for performance and dependability
modeling,” in Computer Performance Evaluation / TOOLS, 2000, pp.
332–336.
[5] E. LeMay, W. Unkenholz, D. Parks, C. Muehrcke, K. Keefe, and W. H.
Sanders, “Adversary-driven state-based system security evaluation,” in
Proceedings of the 6th International Workshop on Security Measure-
ments and Metrics (MetriSec 2010), Bolzano-Bozen, Italy, Sept. 15,
2010.
[6] E. LeMay, M. D. Ford, K. Keefe, W. H. Sanders, and C. Muehrcke,
“Model-based security metrics using ADversary VIew Security Evalua-
tion (ADVISE),” in Proceedings of the 8th International Conference on
Quantitative Evaluation of SysTems (QEST 2011), Aachen, Germany,
Sept. 5–8, 2011, pp. 191–200.
[7] E. LeMay, “Adversary-driven state-based system security evaluation,”
Ph.D. dissertation, University of Illinois at Urbana-Champaign, Urbana,
Illinois, 2011.
[8] D. Buckshaw, G. Parnell, W. Unkenholz, D. Parks, J. Wallner, and
O. S. Saydjari, “Mission oriented risk and design analysis of critical
information systems,” Military Operations Research, vol. 10, no. 2, pp.
19–38, 2005.
[9] S. R. Watson and D. M. Buede, Decision Synthesis: The Principles and
Practice of Decision Analysis. Cambridge University Press, 1987.
[10] M. D. Ford, P. Buchholz, and W. H. Sanders, “State-based analysis
in advise,” in Quantitative Evaluation of Systems (QEST), 2012 Ninth
International Conference on, sept. 2012, pp. 148 –157.
[11] J. McAffer, J.-M. Lemieux, and C. Aniszczyk, Eclipse Rich Client
Platform, 2nd ed. Addison-Wesley Professional, 2010.
[12] S. Northover and M. Wilson, SWT: The Standard Widget Toolkit, volume
1, 1st ed. Addison-Wesley Professional, 2004.
[13] R. Harris, The Deﬁnitive Guide to SWT and Jface, 2nd ed. Berkeley,
CA, USA: Apress, 2007.
[14] D. Steinberg, F. Budinsky, M. Paternostro, and E. Merks, EMF: Eclipse
Modeling Framework 2.0, 2nd ed. Addison-Wesley Professional, 2009.
[15] A. J. Stillman, “Model composition within the M¨obius modeling frame-
work,” Master’s thesis, University of Illinois, 1999.
[16] W. H. Sanders and J. F. Meyer, “Stochastic activity networks: Formal
deﬁnitions and concepts,” in Lectures on Formal Methods and Perfor-
mance Analysis, ser. Lecture Notes in Computer Science, E. Brinksma,
H. Hermanns, and J. P. Katoen, Eds., vol. 2090. Berg en Dal, The
Netherlands: Springer, 2001, pp. 315–343.
[17] M¨obius Team, The M¨obius Manual, www.mobius.illinois.edu, University
of Illinois at Urbana-Champaign, Urbana, IL, 2013. [Online]. Available:
https://www.mobius.illinois.edu/manual/MobiusManual.pdf
[18] S. Jajodia, S. Noel, and B. O’Berry, “Topological analysis of network
attack vulnerability,” in Managing Cyber Threats: Issues, Approaches
and Challenges, V. Kumar, J. Srivastava, and A. Lazarevic, Eds. New
York, NY: Springer, 2005, ch. 9.
[19] S. O’Hare, S. Noel, and K. Prole, “A graph-theoretic visualization
approach to network risk analysis,” in Proceedings of the 5th Interna-
tional Workshop on Visualization for Computer Security (VizSec 2008),
J. Goodall, G. Conti, and K.-L. Ma, Eds. Berlin, Germany: Springer-
Verlag, September 2008, pp. 60–67.
[20] K. Ingols, R. Lippmann, and K. Piwowarski, “Practical attack graph
generation for network defense,” in Proceedings of the 22nd Annual
Computer Security Applications Conference. Washington, D.C.: IEEE
Computer Society, 2006, pp. 121–130.
[21] L. Williams, R. Lippmann, and K. Ingols, “Garnet: A graphical attack
graph and reachability network evaluation tool,” in Proceedings of the
5th International Workshop on Visualization for Computer Security
(VizSec 2008), J. Goodall, G. Conti, and K.-L. Ma, Eds.
Berlin,
Germany: Springer-Verlag, 2008, pp. 44–59.
[22] M. Chu, K. Ingols, R. Lippmann, S. Webster, and S. Boyer, “Visualizing
attack graphs, reachability, and trust relationships with NAVIGATOR,”
in Proceedings of the Seventh International Symposium on Visualization
for Cyber Security, 2010, pp. 22–23.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:50:07 UTC from IEEE Xplore.  Restrictions apply.