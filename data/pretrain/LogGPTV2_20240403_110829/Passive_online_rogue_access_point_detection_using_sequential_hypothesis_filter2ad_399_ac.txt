and hence λ = 1 > 1/K. In this case, the null hypothesis H0
is not rejected. Therefore, we only consider the case where
θ  K
which is equivalent to
n  K
which is equivalent to
n > −
log K
log θ
.
(2)
When K = 106 and θ = 0.18, from (2), we have n ≥ 8.
This implies that we need at least 8 ACK-pairs to detect a
WLAN host for the above setting.
In addition to conditions (1) and (2), we also derive a
complementary condition to reject the null hypothesis H0
directly from Theorem 2. Theorem 2 states that, when
the number of inter-ACK observations n is between 43 and
100, we have P (ξn
.5(∆A) ≤ 600 µs) ≈ 1 for Ethernet hosts.
Therefore, an additional condition to reject H0 is when 43 ≤
n ≤ 100 and ˆp > 0.5 (because this condition implies that at
least half of the inter-ACK observations exceed 600 µs, that
is, ξn
.5(∆A) > 600 µs, which contradicts Theorem 2).
We combine the above three conditions to construct a
sequential hypothesis test as shown in Fig. 4. As we can
see, this test has very little computational and storage over-
head (it only stores the total number of inter-ACK times
and the number of inter-ACK times exceeding 600 µs for
each IP address being monitored). Last, note that it only
reports WLAN hosts, while the sequential hypothesis test
with training reports both WLAN and Ethernet hosts.
5. ONLINE ROGUE-AP DETECTION
SYSTEM
We design a system for online detection of rogue APs.
This system consists of three major components as illus-
trated in Fig. 5. The data capturing component collects
incoming and outgoing packet headers. These packet head-
ers are then passed on to the online detection engine, where
WLAN hosts are detected using the algorithms described in
the previous sections. Once a WLAN host is detected, its IP
address is looked up from an authorization list for rogue-AP
detection. We next describe the online detection engine, the
core component in the system, in more detail. Afterwards,
we describe how to identify ACK-pairs in real time and ob-
tain inter-ACK time distributions a priori (required by the
sequential hypothesis test with training).
5.1 Online Detection Engine
The online detection engine makes a detection on a per
host (or IP address) basis. Since TCP data packets and
ACKs come in on a per ﬂow basis and a host may have mul-
tiple simultaneous active TCP ﬂows3, the online detection
engine maintains a set of data structures in memory, each
corresponding to an active TCP ﬂow. We name the data
structure as an unacked-data-packet queue since it stores the
information on all the data packets that have not been ac-
knowledged by the receiver. Each item in a queue represents
a data packet in the corresponding active ﬂow. It records
the sequence number (4 bytes), the timestamp (8 bytes) and
size (2 bytes) of the packet. In addition, the online detec-
tion engine also records the latest ACK for each TCP ﬂow
in memory. These information is used to identify ACK-pairs
as follows. For each incoming ACK, the online detection en-
gine ﬁnds its corresponding unacked-data-packet queue (us-
ing a hash function for quick lookup) and then matches it
with the items in the queue to identify ACK-pairs. Once
an ACK-pair is identiﬁed, depending on whether training
data is available, it is fed into the sequential hypothesis test
with or without training to determine whether the host uses
WLAN.
The memory requirement of the online detection system
mainly comes from storing the unacked-data-packet queues.
Each queue contains no more than M items, where M is
the maximum TCP window size (since an item is removed
from the queue once its corresponding ACK arrives).
In
our experiments, we ﬁnd that most queues contain a very
small number of items (see Section 7.3), indicating that the
memory usage of this online detection system is low.
5.2 Online Identiﬁcation of TCP ACK-pairs
As described earlier, two successive ACKs form an ACK-
pair if the inter-arrival time of their corresponding data
packets at the monitoring point is less than a threshold T
(chosen as 240 µs or 400 µs in our system, see Section 7). In
addition to the above condition, we also take account of sev-
eral practical issues when identifying ACK-pairs. First, we
exclude all ACKs whose corresponding data packets have
been retransmitted or reordered. We also exclude ACKs
due to expiration of delayed-ACK timers if delayed ACK is
implemented (inferred using techniques in [25]). This is be-
cause, if an ACK is triggered by a delayed-ACK timer, it is
not released immediately after a data packet. Therefore, the
inter-arrival time of this ACK and its previous ACK does not
reﬂect the characteristics of the access link. Furthermore, to
ensure that two ACKs are successive, we require that the dif-
ference of their IPIDs to be no more than 1. We also restrict
that the ACKs are for relatively large data packets (of size
at least 1000 bytes), to be consistent with the assumption of
our analysis (in Section 3). Last, we require that the inter-
ACK time of an ACK-pair to be below 200ms. This is due
to the following reasons. Consider three ACKs, the second
and third ones being triggered by delayed-ACK timer.
If
3We deﬁne a ﬂow that has not terminated and has data
transmission during the last minute as an active ﬂow.
the second ACK is lost, the measurement point will only
observe a pair of ACKs (the ﬁrst and third ACK), which is
not a valid ACK-pair (since the third ACK is triggered by
delayed-ACK timer). Requiring the inter-ACK time of an
ACK-pair to be below 200 ms can exclude this pair of ACKs
because their inter-arrival time is at least 200 ms (it takes
at least 100 ms for a delayed-ACK timer to go oﬀ).
A user may purposely violate the above criteria for ACK-
pairs (e.g., by never using TCP, using smaller MTUs or tam-
pering with the IPID ﬁeld) so that the measurement point
does not capture any valid ACK-pair from this user. How-
ever, all the above cases are easy to detect and can raise an
alarm that this user may attempt to hide a rogue AP.
5.3 Obtaining Inter-ACK Time Distributions
Beforehand
To apply the sequential hypothesis test with training, we
need to know the inter-ACK time distributions for Ethernet
and WLAN beforehand.
In general, the inter-ACK time
distribution for a connection type can be acquired from a
training set, which contains TCP ﬂows known to use this
connection type. We detail how we construct training sets
for our experimental evaluation in Section 6.2; training sets
for other networks can be constructed in a similar manner.
6. EVALUATION METHODOLOGY
We evaluate the performance of our rogue-AP detection
algorithms through extensive experiments. In this section,
we describe our evaluation methodology, including the mea-
surement equipment, training sets, test sets, and oﬄine and
online evaluation.
6.1 Measurement Equipment
Our measurement equipment is a commodity PC, installed
with a DAG card [6] to capture packet headers. It is placed
at the gateway router of UMass, Amherst, connected via an
optical splitter to the access link connecting the campus net-
work to the commercial network. The TCP and IP headers
of all the packets that traverse this link are captured by the
DAG card, along with the current timestamp. The captured
data are streamed to our online detection algorithms, which
are running on the commodity PC. The PC has three In-
tel Xeon Y 2.80 GHz CPUs (cache size 512 KB), 2 Gbytes
memory, and SCSI hard disks.
6.2 Training Sets
Training sets are required to obtain inter-ACK time dis-
tributions (see Section 5.3). We construct training sets for
our experimental evaluation as follows. First, based on our
knowledge on the UMass campus network, we identify E and
W, denoting the set of IP addresses known to use Ethernet
and WLAN respectively. The set E consists of IP addresses
for hosts using 100 Mbps Ethernet in the Computer Science
department. The set W consists of IP addresses that are
reserved for the campus public WLAN (an 802.11 network
providing wireless access to campus users at public places
such as the libraries, campus eateries, etc.). The numbers
of IP addresses in E and W are 648 and 1177 respectively.
The training set for Ethernet (or WLAN) is constructed by
extracting TCP ﬂows destined to hosts in E (or W) from a
trace collected at the monitoring point. The trace for Eth-
ernet was collected between February and April, 2005. In
early 2006, 802.11g APs were deployed on UMass campus
1
0.8
0.6
0.4
0.2
y
t
i
l
i
l
b
a
b
o
r
p
e
v
i
t
a
u
m
u
c
l
a
c
i
r
i
p
m
e
0
LAN
WLAN
0.6 msec
102
100
milisecs
Figure 6: Ethernet and WLAN inter-ACK time dis-
tributions obtained from training sets (T = 240 µs).
and more users start to use 802.11g. Therefore, we collected
a new set of traces on 9/29/2006 for WLAN. Note that the
training set for WLAN contains a mixture of 802.11b and
802.11g traﬃc since a host can use either 802.11b or 802.11g
depending on whether its wireless card and its associated
AP support 802.11g.
From the training set (for Ethernet or WLAN), we iden-
tify a sequence of ACK-pairs, and discretize the inter-ACK
times to obtain the inter-ACK time distribution. The dis-
cretization is as follows. We divide the range from 0 to 1
ms into 50µs-bins, and divide the range from 1 ms to 200
ms (which is the maximum value for inter-ACK times) into
1ms-bins. Fig. 6 plots the CDFs (Cumulative Distribution
Function) of the inter-ACK times for Ethernet and WLAN,
where the threshold T = 240 µs. We observe that 2.5% of
the inter-ACK times for Ethernet hosts are above 600 µs,
while 59.0% of the inter-ACK times for WLAN hosts are
above 600 µs, conﬁrming our analytical results in Section 3
(for Ethernet, the observed value is lower than the analytical
result because our analysis is very conservative; for WLAN,
the samples contain a mixture of 802.11b and 802.11g traf-
ﬁc).
6.3 Test Sets
To validate that our algorithms can detect WLAN hosts
while does not misclassify Ethernet hosts, we construct a
WLAN and an Ethernet test set, containing IP addresses
known to use WLAN and Ethernet respectively. The WLAN
test set contains the IP addresses (of 1177 addresses) re-
served for the campus public WLAN. The Ethernet test set
contains the IP addresses of a subset of Dell desktops that
use Ethernet in the Computer Science building. It contains
258 desktops, each with documented IP address, MAC ad-
dress, operating system, and location information for ease of
validation. Among these desktops, 35% of them use diﬀer-
ent versions of Windows operating system (e.g., Windows
2000, Windows ME, Windows XP, etc.); the rest use dif-
ferent variants of Linux and Unix operating systems (e.g.,
RedHat, Solaris, CentOS, Fedora Core, etc.). These hosts
are three hops away from the university gateway router (and
the monitoring point).
In addition to these two test sets, we further investigate
whether our schemes can detect connection switchings and
other types of rogue APs by conducting additional experi-
ments in the Computer Science Department. The total IP
space monitored in our experimental evaluation consists of
the WLAN test set (1177 addresses) and all the IP addresses
in the Computer Science Department (2540 addresses), to-
tally 3217 addresses.
6.4 Ofﬂine and Online Evaluation
We evaluate the performance of our algorithms in both
oﬄine and online manners.
In oﬄine evaluation, we ﬁrst
collect measurements (to the hard disk) and then apply the
sequential hypothesis test to the collected trace.
In on-
line evaluation, we run the sequential hypothesis test online
while capturing the data at the measurement point. The
oﬄine evaluation, although does not represent the normal
operation mode of our algorithms, allows us to investigate
the impact of various parameters (e.g., T , the threshold to
identify ACK-pairs, K, the threshold in the sequential hy-
pothesis tests). The online evaluation investigates the per-
formance of our algorithms in their normal operation mode.
7. EXPERIMENTAL EVALUATION
We now describe our experimental results. In our experi-
ments, the online detection algorithms make a decision (de-
tecting WLAN, Ethernet or undetermined) with at most N
ACK-pairs, N = 100. A decision of WLAN or Ethernet
is referred to as a detection. The time it takes to make a
decision is referred to as detection time.
In the following, we ﬁrst evaluate the performance (in
terms of accuracy and promptness) of our online detection
algorithms (Sections 7.1 and 7.2). We then investigate the
scalability of our approach (Section 7.3). Afterwards, we
demonstrate that our approach is eﬀective to detect other
types of rogues (Section 7.4). Last, we show that our ap-
proach can quickly detect connection-type switchings (Sec-
tion 7.5) and is robust to high CPU, disk or network utiliza-