title:Integrity walls: finding attack surfaces from mandatory access control
policies
author:Hayawardh Vijayakumar and
Guruprasad Jakka and
Sandra Julieta Rueda and
Joshua Schiffman and
Trent Jaeger
Integrity Walls: Finding Attack Surfaces from
Mandatory Access Control Policies
Hayawardh Vijayakumar, Guruprasad Jakka, Sandra Rueda,
Joshua Schiffman and Trent Jaeger
Systems and Internet Infrastructure Security (SIIS) Laboratory
Department of Computer Science and Engineering,
The Pennsylvania State University
{hvijay,ggj102,ruedarod,jschiffm,tjaeger}@cse.psu.edu
ABSTRACT
Adding new programs or conﬁguration options to a system
often leads to new exploits because it provides adversaries
with new ways to access possible vulnerabilities. As a result,
application developers often must react to exploits as they
are found. One proactive defense is to protect programs
at their attack surfaces, the program entry points (e.g., sys-
tem calls) accessible to adversaries. However, experience has
shown that developers often fail to defend these entry points
because they do not locate all such system calls where pro-
grams access system resources controlled by attackers.
In
this paper, we develop a runtime analysis method to com-
pute program attack surfaces in system deployments, which
uses a novel approach to computing program adversaries
to determine which program entry points access adversary-
controlled objects. We implemented our design as a Linux
kernel mechanism capable of identifying entry points for
both binary and interpreted programs. Using this mecha-
nism, we computed the attack surfaces for all the programs
in the Ubuntu Linux 10.04 Desktop distribution automat-
ically. On examining located attack surfaces, we discov-
ered previously unknown vulnerabilities in an X Windows
startup script available since 2006 and the GNU Icecat web
browser. Our tools enable developers to ﬁnd attack surfaces
for their programs quickly and to produce defenses prior to
the emergence of attacks, potentially moving us away from
the penetrate-and-patch rut.
1.
INTRODUCTION
Protecting host system integrity in the face of determined
adversaries remains a major problem. Despite advances in
program development and access control, attackers continue
to compromise systems forcing security practitioners to reg-
ularly react to such breaches. With the emergence of more
sophisticated malware, such as Stuxnet, malware has begun
to target program entry points that are left undefended, thus
exacerbating the problem.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ASIACCS ’12, May 2–4, 2012, Seoul, Korea.
Copyright 2012 ACM 978-1-4503-0564-8/11/03 ...$10.00.
While security practitioners may eventually learn which
entry points must be defended over a software’s lifetime,
new software and conﬁguration options are frequently in-
troduced, opening additional vulnerabilities to adversaries.
The application developers’ problem is to identify the pro-
gram entry points accessible to adversaries and provide nec-
essary defenses at these entry points before the adversaries
use these to compromise the program. Unfortunately, this is
a race that developers often lose. While some program vul-
nerable entry points are well-known (mostly network), the
complexity of host systems makes it diﬃcult to prevent lo-
cal exploits should attackers gain control of any unprivileged
processing. For example, the OpenSSH daemon was reengi-
neered to defend two entry points in the privileged part
through which several vulnerabilities were exploited [25], but
a third entry point also existed that was vulnerable to any
user processes [28]. The question we explore in this paper is
whether the program entry points accessible to adversaries
can be found proactively, so defenses at these entry points
can also be developed proactively.
Prior eﬀorts to better understand how adversaries can ac-
cess programs focus either on system security policies or pro-
gram entry points, but each provide a limited view. With the
widespread introduction of mandatory access control (MAC)
enforcement in commercial operating systems (OSes) [36, 32,
35], it is possible to determine the subjects in the MAC pol-
icy that may be inﬂuenced by adversary-controlled data [34,
7, 14, 31]. Also, methods have been developed to compute
attack graphs [30, 23, 20], which generate a sequence of ad-
versary actions that may result in host compromise. How-
ever, these methods treat programs as black boxes, where
any program entry point may be able to access either adversary-
controlled data or benign data. As these accesses are not
connected to the program entry points that use them, it
is diﬃcult to know where exactly in the program or even
the number of points in the program that access adversary-
controlled data.
From the program’s perspective, researchers have argued
for defenses at a program’s attack surface [13], which is de-
ﬁned by the entry points of the program accessible to adver-
saries because they may access adversary-controlled data.
Unfortunately, programs often have a large number of li-
brary calls signifying potential entry points, and it is dif-
ﬁcult to know which of these are accessible to adversaries
using the program alone. Some experiments have estimated
attack surfaces using the value of the resources behind entry
points [17, 18]. However, if the goal is simply to take control
of a process, any entry point may suﬃce. While researchers
have previously identiﬁed that both the program and the
system security policy may impact the attack surface def-
inition [13], methods to compute the accessibility of entry
points have not been developed.
In this paper, we compute the attack surface entry points
for programs relative to the system’s access control policy,
thus overcoming the above limitations of focusing only on ei-
ther one, and enabling accurate location these entry points.
First, we propose an algorithm that uses the system’s ac-
cess control policy to automatically distinguish adversary-
controlled data from trusted data based on the permissions
of each program’s adversaries. This constructs what we call
a program’s integrity wall1. We use the system’s MAC (as
opposed to DAC) policy for this purpose because it is im-
mutable, thus preventing the permissions of adversaries from
changing dynamically. To determine adversary access us-
ing MAC policies, past work leveraged program packages
to deﬁne what is trusted by programs [31, 27]. However,
the subjects associated with packages are not all necessarily
trusted equally. For example, the Apache package includes
user-deﬁned CGI scripts, and clearly these cannot be trusted
by the Apache webserver. Instead, we propose a novel ap-
proach for computing per-program adversaries based on the
ability to modify the program’s executable content.
Second, we construct a runtime analysis to collect the pro-
gram entry points that access objects outside its integrity
wall. Fundamental to the runtime analysis are techniques to
ﬁnd the program entry points (instructions in the program’s
binary), that receive adversary-controlled inputs. Our tech-
niques support both binary code and several interpreted
languages (e.g., Bash, PHP, Python) to enable system-wide
computation of program attack surfaces. Where available,
we use developer test suites for application programs; these
often test multiple program conﬁgurations as well, using
which we were able to associate certain entry points with
conﬁguration options that enabled them.
We evaluate a prototype runtime analysis tool on Ubuntu
Linux LTS 10.04.2, using the distribution’s SELinux MAC
policy to build integrity walls and the application packages’
test suites to guide the runtime analysis to collect attack
surfaces. The tool found that this distribution’s trusted
computing base (TCB) processes have 2138 entry points,
but only 81 attack surface entry points that an adversary
could potentially exploit. While examining the system TCB
attack surface, we found a previously unknown vulnerabil-
ity in one entry point in a script that has been present in
Ubuntu for several years. Detailed analyses of Apache and
OpenSSH found an entry point in OpenSSH missed by a
previous manual analysis, and demonstrates the ability of
our tool to associate entry points with conﬁguration options
and ﬁnd subtle, easily overlooked entry points. Also, anal-
ysis of a recent program, the Icecat web browser, revealed
a previously unknown untrusted search path vulnerability,
demonstrating the value in applying this analysis proactively
on new programs.
1 Adversary-controlled data lies outside the program’s wall,
and trusted data inside the wall.
Figure 1: An example of a webserver process showing four input
entry points A to D. Objects and processes are shown with their
MAC labels. The shaded entry points deﬁne the program’s actual
attack surface (i.e., access adversary-controlled data), although
only entry point D is protected by ﬁltering. Entry point B is
only activated in certain conﬁgurations, but must nonetheless be
identiﬁed as part of the attack surface.
In summary, we make the following contributions:
• We propose an algorithm to construct an “integrity
wall” for applications based on MAC policy and a run-
time technique to precisely identify attack surface en-
try points in programs (including interpreted scripts)
using the constructed wall,
• We present results of the attack surface for the system
TCB for Ubuntu 10.04.2 and some of its applications,
which helped uncover two previously unknown bugs,
one present for several years in Ubuntu, showing the
value of locating attack surfaces before an adversary
does.
2. PROBLEM DEFINITION
The aim of this paper is to identify program entry points
that access adversary-controlled objects.
If an adversary
can modify an object that is accessed by a program entry
point that expects only safe objects, the running program
can often easily be compromised.
Consider some of the entry points in a typical webserver
program shown in Figure 1. During development, the ap-
plication developers have realized that entry point D re-
ceives adversary input via the network, making D part of
the program’s attack surface. As a result, the developers
have added defenses to ﬁlter input at D. The program is
then deployed in a system under a particular access con-
trol policy and conﬁguration that allows the accesses shown.
Entry point A reads a conﬁguration ﬁle, and under any rea-
sonable MAC policy the adversary cannot access that ﬁle.
Thus, A is not part of the attack surface. Suppose the
administrator has enabled the UserDir conﬁguration direc-
tive, allowing users to deﬁne their own HTML ﬁles (e.g.,
∼/public_html). Then, entry point B receives adversary-
controlled input (user-deﬁned web pages), but the develop-
ers have overlooked this entry point because it is opened only
under certain conﬁgurations and, moreover, not an obvious
threat. Finally, entry point C reads in module library ﬁles
(e.g., ModCGI) to serve a request. While this entry point
Webserver httpd_tLoad LibraryFilesRead user HTML pagesNetworkInput (HTTP)ReadConﬁgFileﬁlelib_tﬁlehttpd_user_content_ttcp sockethttpd_tﬁlehttpd_conﬁg_t  Adversaryuser_tABCDsocket sendfilewritefile readsocket recvfile readfile readfile readFilteredis supposed to read in ﬁles labeled lib_t from /usr/lib,
it has an untrusted search path bug that ﬁrst searches for
ﬁles in the current working directory. Hence, C exercises
permissions that it is not meant to, and reads the user’s
public_html directory for libraries. An adversary can eas-
ily take control of the web server and gain its privileges if she
plants a malicious module library in that directory. Thus,
the adversary has found two entry points B and C into the
program not anticipated by the developers.
In practice, we have seen much the same pattern. After
the Apache webserver was launched in 1998, vulnerabilities
were found at entry points that access log ﬁles, CGI script
output, user-deﬁned HTML ﬁles, and user-deﬁned conﬁg-
uration ﬁles over a period of six years2. We believe that
locating the attack surface proactively enables: (1) veriﬁ-
cation of where input ﬁltering is necessary to protect the
program, such as B and D, that have to handle adversary
input, and (2) identiﬁcation of entry points that should not
be part of the attack surface, such as C, so the program
or policy can be ﬁxed. Our evaluation (Section 5) found
two previously unknown vulnerabilities, one for each of the
above cases.
While classical security principles stress the importance
of recognizing where programs may receive adversary input
(e.g., Clark-Wilson [9] requires entry points to upgrade low-
integrity data), we lack systematic techniques to identify
these program attack surfaces entry points. Recent work
has focused on how programmers can express their attack
surfaces to systems for enforcement [29, 15, 37] or for further
testing [13, 17]. However, this work assumes developers al-
ready have a complete understanding of their program’s at-
tack surfaces, which experience and our results show to be
incorrect. Our results demonstrate that both mature and
new programs may have undefended attack surface entry
points, and many entry points are accessible to adversaries
in subtle ways.
Assumptions. Our work calculates attack surface entry
points in programs and not the attack surface of the OS ker-
nel itself. Thus, we assume the OS kernel to be free from
vulnerabilities that a local attacker can exploit. Further, we
assume that the reference monitor enforcing access control
in the OS enforces a MAC policy, and satisﬁes complete me-
diation and is tamperproof [2]. This implies that the only
way for local adversaries to attack programs is through rules
speciﬁed in the OS MAC policy.
3. DESIGN
Calculating the attack surface has two steps. First, for
a particular subject (e.g., httpd_t), we need to deﬁne its
adversaries (e.g., user_t), and locate OS objects under ad-
versarial control (e.g., httpd_user_content_t). We do this
using the system’s MAC policy. Next, we need to identify
the program entry points (e.g., entry points B, C, D) that
access these adversary-controlled objects. Statically analyz-
ing the program cannot tell which permissions are exercised
and which OS objects accessed at each entry point, and thus
we use a runtime analysis to locate such entry points. In this
section, we detail solutions to these two steps.
2CVEs 1999-1206, 2001-1556, 2002-1850, 2004-0940, 2004-
2343 respectively
3.1 Building Integrity Walls
A program may receive many inputs. However, not every
input into a program is necessarily under the control of ad-
versaries. A program depends on (i.e., trusts) some inputs
(e.g., etc_t and lib_t in Figure 1), whereas it needs to ﬁlter
(i.e., protect itself from) other inputs (e.g.,
httpd_user_content_t in Figure 1). Our insight is that the
system’s MAC policy enables diﬀerentiation between those
OS objects that a subject depends on and those OS objects
that it needs to ﬁlter. This is simply because a properly
designed MAC policy limits the modiﬁcation of OS objects
that a particular subject s depends on only to subjects that
are trusted by s, and any other object is untrusted and needs
to be ﬁltered on input. Thus, if we identify the set of sub-
jects trusted by s, we can then derive the trusted and un-
trusted objects for s from the MAC policy.
Integrity Wall Approach. The observations that we
use to calculate the set of trusted subjects are outlined be-
low. First, a process fundamentally depends on the integrity
of its executable program ﬁle. Thus, a subject in the MAC
policy has to trust other subjects that have the permission to
modify its executable program ﬁle3, called executable writ-
ers. While we could expand this deﬁnition to include all
code used by a process, such as libraries, we ﬁnd that the
set of labels for approved libraries are ambiguous and that
these are covered by the other cases below.
Second, a process depends on the integrity of its under-
lying system. If the kernel can be compromised, then this
process can be trivially compromised. Thus, all subjects de-
pend on the subject labels with permission to modify any
kernel objects, called kernel subjects. Naturally, each subject
also depends on the executable writers of the kernel subjects
as well. This combination forms the system’s trusted com-
puting base (TCB).
Third, several applications consist of multiple distinct pro-
cesses, some of which are trusted and some not. For exam-
ple, htpasswd is a helper program for Apache that maintains
the password ﬁle .htpasswd. Intuitively, Apache depends on
this program to maintain the password ﬁle properly. On the
other hand, Apache should ﬁlter inputs from user-deﬁned
CGI scripts. We state that a subject label s depends upon
a helper subject, if: (1) the two subject labels are part of
the same application (e.g., package) and (2) the helper sub-
ject’s executable writers are in the application or trusted by
s. Identifying that two subject labels are part of the same
application is often easy because MAC policies are now writ-
ten per application (e.g., there is an SELinux policy module
for Apache).
Integrity Wall Algorithm. The problem is thus to
compute for each subject a partition of the set of MAC pol-
icy labels P based on whether the subject depends on the
label or not, based on the three criteria above, forming that
subject’s integrity wall. An integrity wall for a subject s is
a partition of the set of labels4 in the system policy P into
sets Is and Os, such that s depends on labels in Is (”inside
3Typically, MAC policies are designed by assigning permis-
sions to each executable independently, which means there
is often a one-to-one mapping between subject labels and
executable ﬁles.
4The set of object labels includes the set of subjects labels
in the policy, but not vice versa. Also, we use the terms
subject and object for subject label and object label from
this point forward when unambiguous.
the wall”), and ﬁlters inputs from labels in Os (”outside the
wall”).
The integrity wall derivation computes Is = P − Os from
MAC policy containing relations x Write y and x Writex
y, which mean subjects of label x can write objects of label
y and subjects of label x can write executable ﬁle objects of
subject y, respectively.
1. The kernel subjects K ⊆ P of a system are:
K = {s1 | ∃o ∈ Kernel(P ), where (s1, o) ∈ Write}
2. The trusted computing base T ⊆ P of a system is:
T 0 = K;
T i = T i−1 ∪ {s2 | ∃s1 ∈ T i−1, (s2, s1) ∈ Writex};
i∈N T i
T =S
Es =S
3. The executable writers Es ⊆ P for a subject s are:
, (s2, s1) ∈ Writex};
E0
s = s;
s = Ei−1
Ei
s ∪ {s2 | ∃s1 ∈ Ei−1
i∈N Ei
s
s
4. The helper subjects Hs ⊆ App(s) for a subject s are:
Hs = {s1 | (s1 ∈ (App(s) − {s})) ∧ (Es1 ⊆ (App(s) ∪
Es))}
5. The trusted subjects Ts ⊆ P for a subject s are:
Ts = T ∪ Es ∪ Hs
6. The trusted objects Is ⊆ P for a subject s are:
Is = Ts ∪ {o |6 ∃s1 ∈ (P − Ts), (s1, o) ∈ Write}
First, we compute the kernel subjects (i.e., subjects with
Write access to Kernel(P ) objects) and TCB for the sys-
tem at large. The TCB is derived from a transitive closure
of the writers of the kernel subjects’ executables (Writex).
Then, for each subject we compute its executable writers
(again, using transitive closure) and its helper subjects.
Helper subjects must be part of the same application (App(s))
as the target subject s and can only be modiﬁed by a subject
outside the application that is trusted by s. Thus, htpasswd
is an Apache helper, but user scripts are not, as their exe-
cutable is written to by an untrusted subject (the user). Fi-
nally, we collect the trusted objects for the subject: the set