erwise be conducted under disproportional eﬀort.” (German
Federal Data Protection Code §4:.4.5 [337]).
The General Data Protection Regulation (GDPR) [44]
applies from May 423: to the collection and processing of
personal data in the EU and to organisations that oﬀer goods
or services to individuals in the EU [72]. It provides speciﬁc
measures to allow processing of personal data for scientiﬁc
research in the public interest, subject to appropriate safe-
guards such as encryption, pseudonymisation, and data min-
imisation. It mentions that scientiﬁc research should increase
knowledge and that personal data should not be included
in publications. It speciﬁcally allows the processing of data
collected for other purposes for scientiﬁc or historical research
(Article 7). It requires (Article 36.7.b) that the interests of
data subjects be protected and that information about the
data collected, how it is being processed and safeguarded,
and who is responsible be made publicly available. It encour-
ages the use of approved codes of conduct surrounding data
processing and it may be helpful for research communities
to develop such codes of conduct. Penalties for violating
the GDPR include ﬁnes of up to EUR 42 million, or 6% of
worldwide turnover, whichever is higher.
Terrorism: In some jurisdictions (e.g. UK) it may be an
oﬀence to fail to report terrorist activity [32:], including any
discovered during a research project. Additionally, possession
of terrorist materials may be an oﬀence unless speciﬁc excep-
tions for research are met. REB approval and institutional
oversight are likely to be necessary if the research involves
terrorist materials, such as discussion of planned attacks or
techniques, to ensure the researcher is protected [335].
Indecent images: Possession of indecent images of children
is an oﬀence in many jurisdictions including the UK [::],
USA [4], and Germany [59]. In general there are no exemp-
tions for research. Hence, care may need to be taken when
scraping or receiving some types of data dump in case they
contain such material.
National Security: Data obtained may be protected by
national security legislation. Therefore unauthorised use
or publication of these data may expose the researchers to
legal risks. Even if data is publicly available it may still be
classiﬁed [58]. This is discussed further in §6.7.4.
Contracts: Researchers may be exposed to civil liability
resulting from breach of contract by using certain data if
doing so violates terms of service or other contracts that
researchers have agreed to.
Occasionally research may be illegal but still ethical. In
such cases researchers should be transparent about what
they are doing and both they and their institutions should
be willing to accept the consequences. REB approval is
essential in such cases. In such circumstances researchers
should actively engage with lawmakers to improve the law
so that the ethical work that they want to do is made legal
in future [74].
There are generic defences against legal liability that may
apply. Mens rea: In some cases if the researcher can demon-
strate lack of criminal intent then a criminal prosecution
cannot succeed; REB approval may be a useful way to demon-
strate this. Not in the public interest to prosecute: This is
an especially generic defence, but it is uncertain.
The use of an REB may transfer legal risks to the re-
searcher’s institution or ensure that the institution provides
legal assistance to the researcher. This alone is a strong
incentive for individual researchers to use an REB.
5.3 Related work on law and ICTR
Others have discussed legal issues in ICTR for particular
kinds of research in particular jurisdictions.
Soghoian discusses legal risk arising from conducting phish-
ing experiments, with four case studies and a discussion of
the copyright, trespass to chattel, trademark, terms of ser-
vice violation, computer fraud, and anti-phishing issues in
the USA [322]. He recommends all such research should be
subject to ethical review as well as legal advice, and that the
institution IT staﬀ and anyone else likely to receive a cease
and desist letter related to the project should be consulted.
He also notes the importance of not gaining any ﬁnancial
beneﬁt from the work, for example, adverts should not be
shown on pages associated with the work.
Ohm et al. examine the legal issues for network measure-
ment research arising from USA Federal Law [:3]. They
suggest capturing only the required data, scrubbing IP ad-
dresses, encrypting data when not analysing it, restricting
monitoring to the smallest possible network, and ensuring
that measuring tools do not store the full packets to disk.
Burstein discusses the legal issues surrounding cyberse-
curity research, and in particular research using network
traces, running malware honeypots, or mitigating attacks by
interfering with malicious systems [37].
Ethical issues in research using datasets of illicit origin
IMC ’39, November 3–5, 4239, London, UK
6 CASE STUDIES
The ethical and legal considerations of conducting and pub-
lishing academic research with data of illicit origin depends
on the context [346]. Many factors may come into play, such
as the type of data involved, the measurement techniques
used or the results of the research. Thus, ethical and legal
consideration must be conducted separately for each research
activity. This section presents a series of concrete case studies
where diﬀerent kinds of data of illicit origin was used. We
do not attempt to provide a complete survey on each topic.
Instead, for each topic we consider recent and relevant work,
focussing on those that mention or expose interesting ethi-
cal issues. We selected from papers we were already aware
of, those we found from searches, and from following refer-
ences forwards and backwards. Decisions on which papers
to include were necessarily subjective. We consider work by
people who self-identify as researchers even if they do not
publish in academic venues, although we have focussed on
publications which have undergone peer review. We highlight
the ethical (e.g. Identiﬁcation of stakeholders) and legal (e.g.
Computer misuse) issues deﬁned in §4.3 and §5 in each case,
and the overall results are summarised in §7. We do not cover
research using active measurements such as the controversial
Encore work discussed by others [9:].
6.3 Malware and exploitation
Research conducted using hacking tools such as botnets or
exploit kits is necessary to understand how malicious actors
use them and to provide countermeasures. However, the use
of such tools can be harmful, and sometimes researchers have
used them without considering legal or ethical issues. In this
section we cover three particular cases: the use of a botnet to
scan the IPv6 address space, the exploitation of a discovered
vulnerability to gather email addresses, and research using
source code of malware specimens.
6.3.3 Carna scan. In 4234 an anonymous individual claimed
to have carried out a complete scan of all IPv6 addresses on
all ports and made the dataset publicly available. However,
the means they used to do this was a botnet of 642 222
devices with default passwords [3:]. Creating a botnet of
compromised computers to carry out research is illegal since it
is Computer misuse. Is research that uses these data ethical?
CMU CERT wrote a blog post explaining how these data
could be used and, while they pointed out there were some
ethical issues, they noted that: “As far as we can tell, this
data set does not contain legally restricted information, like
classiﬁed information, personally identiﬁable information, or
trade secrets.” [;;]. CAIDA found that there were some
problems with this data since some bot-devices were behind
HTTP proxies which meant that the results for port :2 scans
were incorrect [3:]. They noted ethical concerns without giv-
ing details, and referred the reader to the Menlo report [48].
To prevent harm, CAIDA only looked at data targeting their
own darknet. Malécot and Inoue took a similar approach,
analysing their network telescope [92]. However, they then
realised that they knew the IP addresses of the botnet devices
as they were the sources of the probes of their network tele-
scope. These IP addresses thus once belonged to devices that
could be easily brute forced as they had weak Telnet pass-
words, in doing so the authors Identify harms. The Safeguards
they used were that they kept these IP addresses conﬁdential
pending ﬁnding an ethically acceptable and practical way of
dealing with the situation.3
Krenc, Hohlfeld and Feldmann published a non-peer re-
viewed editorial note where they analysed the scan results [84].
They found numerous technical problems with the data, and
the authors concluded that given that Carna scan made no
technical contributions, it had been unethical to conduct.
While they did not provide an opinion on whether it is ethi-
cal to use these data for research, they did use it for these
purposes.
When these scan data were ﬁrst released, it was not neces-
sary to use them to answer research questions as researchers
could conduct their own scans legally, ethically, and with
better technical validity. For new research that requires com-
parison with the Internet of 4234, these Carna scan data
might be of use. However, due to substantial technical prob-
lems with these Carna scan data [84] in many cases there
will be no good argument for using them.
Dittrich, Carpenter and Karir use the Menlo report to
present a thorough analysis of the ethics of the Carna bot-
net [49], from which they conclude that there is a “lack of
a common understanding of ethics in the computer security
ﬁeld”.
6.3.4 AT&T iPad users database brute force. In 4232 re-
searchers from Goatse Security discovered a web service run
by AT&T that, when provided with the ICC-ID of a 5G
iPad, would return the associated email address. They used
this to obtain the email addresses for 336 222 iPad users
and passed this information to Gawker [328] as well as mak-
ing the vulnerability known to third parties. They did not
contact AT&T to report the vulnerability. The subsequent
FBI investigation [329] resulted in the authors being found
guilty of Computer misuse and one of them was sentenced
to 63 months imprisonment [52]. While it was argued that
this imprisonment was an overreaction [;:] the research was
clearly both unethical and illegal.
Finding vulnerabilities in third party systems without
permission can be ethical, since this helps that party to
Identify harms and to avoid future attacks. However, in
this case it was unethical, because: i) The authors collected
far more personal data than they needed to prove it to
be a real vulnerability, ii) The authors shared this data
and the existence of the vulnerability (including the exploit
script) with third parties before reporting the problem to
AT&T. Hence, the authors identiﬁed risks for iPad users,
but exploited the vulnerability and, given that they did not
contact AT&T, they failed to implement Safeguards. Indeed,
3In 4238 the Mirai botnet was also built by brute forcing Telnet
passwords. As a security research community we did not successfully
mitigate the risks that the Carna botnet demonstrated [;3]. We were
not able to contact Malécot and Inoue to discover if they found a
solution to ethically using the IP addresses.
IMC ’39, November 3–5, 4239, London, UK
Daniel R. Thomas et al.
the research work is not in the Public interest, since they did
not minimise harm or maximise beneﬁt, except to their own
notoriety (a lack of Justice).
6.3.5 Malware source code. Malware source code has been
publicly released on multiple occasions. This code has then
been used by malicious actors to attack computer systems or
networks. Additionally, malware source code can be obtained
from public databases such as vxHeaven or Contagio Dump.
For example, the source code for Zeus was leaked in 4233 [67].
Since then, many variants of Zeus have been reported by
anti-virus vendors. Similarly the source code for Mirai botnet
was released in 4238 [82]. The release of malware source
code often lowers the barrier to entry for using the malware:
after Mirai’s source code was released, myriad Mirai based
botnets began operation. Release of source code is sometimes
correlated with prosecution of its author, as in the example of
Agobot in 4226 [65]. Additionally, the release of source code
might result in changed business models for malware authors
such as the Zeus botnet as-a-service [67]. The source code of
malware can also be obtained from its operational settings.
Stone-Gross et al. [325] identiﬁed and obtained access to some
of the C&C servers for the Pushdo/Cutwail botnet (used
mainly for spam delivery) by contacting the hosting providers
(i.e. the authors ﬁrst performed Identiﬁcation of stakeholders).
They obtained sensitive data such as the statistics of infection,
target email addresses and the source code of the malware.
Kotov and Masacci collected source code of exploit kits
from a public repository as well as underground forums where
code was leaked or released [7:]. Their analysis showed how
exploit kits evade anti-crawling techniques and how malware
authors protect against code analysis. However, as the au-
thors state, the fact that the code was leaked biased their
analysis, for example due to removal of obfuscation from the
source code. Calleja et al. analysed 373 malware samples
dating from 3;97 to 4237. They show how the malware
landscape has evolved using traditional software metrics on a
dataset of malware code from various repositories, including
vxHeaven, GitHub, hacker-related magazines, and P4P net-
works. The authors do not share the collected source code,
but only provide a dataset containing the metrics obtained
from the malware pieces [39].
Research using malware source code has substantial ben-
eﬁts as better understanding of how malware works, so as
to facilitate developing new detection and mitigation tech-
niques. Publishing the results and explaining the tools and
techniques used to analyse the malware makes this research
of Public interest. Both possession and accidental disclosure
of malware could be illegal. Researchers could use secure
storage, enforce retention policies, and not publicly distribute
the malware source code as Safeguards. However, none of
the research works using source code mentioned ethical or
legal issues, nor whether they have obtained permission from
their corresponding REB. Calleja et al. shared a dataset with
metrics from the source code, but not the sources themselves,
as Safeguards that allow for reproducibility without releasing
the malware [39]. Additionally, stylometry analysis allows
code writers to be identiﬁed [38]. By identifying who has
written some piece of code, it is possible to group malware
families, detect plagiarism, and attribute attacks. Thus, the
release of source code (not just malware code) should be done
with care, since it can be used to identify the authors.
6.4 Password dumps
Password dumps are the archetypal leaked dataset – a list
of passwords that has been been made public, normally by
illegal action; criminals regularly compromise databases (e.g.
by SQL injection) and then publish the contents online [342].
Since people include personal data in passwords, the password
alone can be sensitive [326] and the lists may also include
other personal data such as email addresses or names.
Research into password dumps is controversial but widely
practised [326], not least because they provide researchers
with ground truth data, that otherwise would be diﬃcult
to obtain [54]. A variety of dumps have been investigated.
One of the largest dumps, is the RockYou dump, others
include MySpace leaked in 4228, or Facebook leaked in 4232.
These dumps and many others can be found online by using
common search engines.
Weir et al. use lists of compromised and publicly disclosed
passwords [343]. They say that “while publicly available, these
lists contain private data; therefore we treat all password
lists as conﬁdential” and that “due to the moral and legal
issues with distributing real user information, we will only
provide the lists to legitimate researchers who agree to abide
by accepted ethical standards”. In a later paper by the same
authors they note that it is a “mixed blessing” that research
into passwords used for high value targets, such as bank
accounts, will not be possible until relevant breaches occur
and the data is made public [342].
Das et al. study trends in password reuse across diﬀerent
sites by analysing passwords obtained through an internal
survey and several hundred thousand leaked passwords [46].
They state that the ethics of conducting research with data
acquired illegally is under debate, but they justify their work
saying that: 3) these datasets were used in several previous
studies, 4) they protected users privacy by only working
with hashed email addresses, 5) they obtained approval from
their REB to conduct the survey. Finally, the authors state
that their results help system administrators and researchers
understand how cross-site password attacks work.
Kelley et al. used two datasets of leaked passwords as well
as passwords collected through an online survey [79]. The
authors received approval from their REB for this survey, and
they discuss the ethics of using leaked databases of passwords.
They argue that, given these data were already public, using
it for research does not increase harm to users, since no
further connection with real identities is sought. Moreover,
given that attackers can use these datasets to construct
their dictionaries or cracking tools, system administrators
can beneﬁt from research and can prepare defences such as
improved password policies. This view is also shared by Ur
et al., who use three diﬀerent password dumps to compare
Ethical issues in research using datasets of illicit origin
IMC ’39, November 3–5, 4239, London, UK
real-world cracking techniques with those proposed in the
research literature [336].
Durmuth et al. proposed OMEN, a cracking algorithm
that outperforms state of the art crackers [53]. The authors
tested their algorithm on leaked databases from MySpace,
Facebook and the website RockYou. The authors justify this
by claiming that these datasets have been used in several
previous studies, and they have been made public. Moreover,
they claimed that these data have been treated carefully and
they do not reveal actual information about the passwords.
Bonneau used leaked password databases to investigate
the statistical properties of passwords and developed the
α-guesswork metric for password strength [35]. He notes that
“care was taken to ensure that no activities undertaken for
research made any user data public which wasn’t previously”
and rejects “the appropriateness of ever collecting cleartext
user passwords, with or without additional identifying infor-
mation”. By this argument, leaking a password database and
making a leaked password database more available than it
would otherwise be are both unethical.
Researchers mostly use two arguments to justify the ethics
of conducting research on password dumps. First, since the
passwords are public, studying them might not increase harm
and could help advance science. Moreover, since attackers
may have access to these lists as well, the defences derived
from analysis of these passwords may protect people, making
these works of Public interest. Second, most authors state
that they do not reveal personal information derived from
the passwords, and some of them claim that they “treat
these lists with the necessary precautions” [53] or that they
“treat them as conﬁdential” [343], which should include secure
storage of the lists. All the works covered Identify harms and
provide Safeguards. Some authors justify the ethics of their
research on the basis that previous research was conducted
with these dumps.