title:Characterizing roles of front-end servers in end-to-end performance
of dynamic content distribution
author:Yingying Chen and
Sourabh Jain and
Vijay Kumar Adhikari and
Zhi-Li Zhang
Characterizing Roles of Front-end Servers in End-to-End
Performance of Dynamic Content Distribution
Yingying Chen, Sourabh Jain, Vijay Kumar Adhikari, Zhi-Li Zhang
Department of Computer Science & Engineering
University of Minnesota - Twin Cities
Minneapolis, MN 55414, USA
{yingying,sourj,viadhi,zhzhang}@cs.umn.edu
ABSTRACT
This paper investigates the roles of front-end (proxy) servers
in improving user-perceived performance of dynamic con-
tent distribution. Using Bing and Google search services
as two case studies, we perform extensive network measure-
ment and analysis to understand several key factors that
aﬀect the overall user-perceived performance.
In particu-
lar, we develop a simple model-based inference framework
to indirectly measure and quantify the (directly unobserv-
able) “frontend-to-backend fetching time” comprised of the
query processing time at back-end data centers and the de-
livery time between the back-end data centers and front-end
servers. We show that this fetching time plays a critical role
in the end-to-end performance of dynamic content delivery.
Categories and Subject Descriptors
C.4 [Performance of Systems]: Performance attributes
General Terms
Measurement, Performance
Keywords
Dynamic content distribution, Search service, TCP-splitting
1.
INTRODUCTION
More and more content on the Internet is now stored at
powerful, large-scale data centers in the cloud. A signiﬁ-
cant portion of this content is dynamic in that in response
to a user’s request for content, the content returned to her
is generated dynamically and sometimes personalized. Web
search is one common example of such dynamic content gen-
eration. With the emergence of cloud computing and cloud-
based services, we expect that more data will be stored in
the cloud, and more dynamic content will be generated on
the ﬂy in response to user requests. Because of the sheer
scale and cost of building and operating large-scale powerful
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
IMC’11, November 2–4, 2011, Berlin, Germany.
Copyright 2011 ACM 978-1-4503-1013-0/11/11 ...$10.00.
data centers, their number is few and far between. Hence
they are generally far away from a large majority of users.
One way to mitigate this eﬀect and improve the user-
perceived performance (e.g., the overall response time) is
to deploy “proxy” servers – hereafter we refer to them as
front-end (FE) servers – closer to users. The usefulness of
such an approach for static content distribution (e.g., video)
is obvious because of content caching. FE servers can also
be exploited to improve the user-perceived performance of
dynamic content distribution due to the following two key
aspects [9,11]: i) a portion of the (dynamic) content may be
static; thus can be cached and delivered immediately from
the FE servers; and more importantly, ii) via split TCP con-
nections, a FE server can establish a persistent TCP con-
nection with the data center which not only eliminates the
eﬀect of TCP slow-start congestion window ramp-up on the
throughput of the TCP connection between the FE server
and the back-end (BE) data center, but also mitigates such
eﬀect on the throughput of the TCP connection between the
user and the FE server (due to the reduced RTT). Nonethe-
less, the overall user-perceived end-to-end performance likely
depends on a conﬂuence of various factors such as RTT, loss
rate and throughput of the connections between users and
FE servers and between FE servers and BE data centers, the
load on FE servers, the processing time at BE data centers
to generate user-requested dynamic content, and so forth.
To investigate the roles of FE servers in improving user-
perceived end-to-end performance of dynamic content distri-
bution, we conduct an active measurement-based compara-
tive study of Google and Microsoft Bing web search services.
Both services utilize a number of FE servers that are placed
closer to users to assist dynamic content (i.e., search results)
distribution: Google deploys a set of its own FE servers,
whereas Bing relies on Akamai’s content distribution net-
work (CDN). Using the PlanetLab nodes, we perform ex-
tensive measurements of Google and Bing search services
by emulating and generating a variety of keyword search
queries of varying popularity, granularity and complexity,
and collect a large amount of dynamically generated content
and application-layer measurement data. Through content
analysis and temporal clustering of packet-level events, we
conﬁrm that both Bing and Google search results contain
a static portion, such as the HTTP header, HTML header,
etc., which is cached and delivered immediately by the FE
servers upon receiving a user request. As the eﬀect of the
aforementioned second key aspect cannot be directly mea-
sured, we develop a novel model-based inference framework:
we classify and separate the content (i.e., search results) into
559two parts – the static portion that is cached and directly de-
livered by FE servers, and the dynamic portion that is gen-
erated by the BE data centers and then passed onto the FE
servers for delivery. We deﬁne several directly measurable
parameters to characterize and predict the delivery perfor-
mances of static and dynamic portions. These predictions
are indeed borne out by our measurement data, and thus en-
able us to deduce that despite that one utilizes a third-party
CDN (as FE servers) and the other does not, both Bing and
Google employ FE servers in a similar fashion.
Furthermore, our inference framework allows us to bound
the FE-BE fetch time (Tf etch) of dynamic content – namely,
the overall time it takes for a FE server to forward user
query to a BE data center, for the data center to dynam-
ically generate the user-requested content and deliver it to
the FE server – we note that this time cannot be directly
observed and measured at the end systems. Comparing Bing
and Google search services, we ﬁnd that the fetch time be-
tween Google FE servers and BE data centers tends to be
smaller and more stable for Google; in contrast, the fetch
time between the Akamai FE servers and Bing data centers
tends to be larger and shows higher variability. Hence, de-
spite Akamai FE servers are generally placed closer to users
(and their number is larger than that of Google FE servers),
user-perceived performance of the Bing search service tends
to vary signiﬁcantly from queries to queries. While it is
known that placing FE servers closer to users can generally
improve the user-perceived performance (e.g. [9]), our study
demonstrates a critical trade-oﬀ between placement of FE
servers and the FE-BE fetch time which limits this improve-
ment: there is a distance threshold within which placing FE
servers further closer to users is no longer helpful; instead,
the end-to-end performance is now determined solely by the
FE-BE fetch time. Thus, to improve the end-to-end perfor-
mance, it is also crucial to optimize the FE-BE fetch time.
Lastly, we develop heuristics to factor the FE-BE fetch time
so as to estimate the back-end processing time (Tproc) and
the BE-FE round-trip delivery time (RT Tbe) separately.
Related Work. Most prior works in this area focus on un-
derstanding the distribution of static content. For instance,
in [5], authors study the assignment of clients to the CDN
edge servers, in order to maximize the performance for each
user. Similarly, several other studies such as [4, 6, 7] develop
techniques to use a peer-to-peer based model to distribute
the content, which is assumed to be static. In [10] authors
study the various caching mechanisms used by CDN net-
works. Besides, a recent OSN study [12] show that placing
more proxy servers can enhance the content distribution for
Facebook users sharing similar interests. However, the fo-
cus of the study was to exploit the redundancy in the data
accessed by users in a given geography, and reduced the
user-perceived delay by caching the content at nearby proxy
servers. A study [9] that is more closely related to our work
compares the performance of cloud service with and with-
out tcp-splitting, and therefore dealt with only the indis-
pensability of TCP-splitting. On the other hand, in this
paper, by reverse engineering the strategies used by Google
and Bing to distribute the dynamic content, we shed light
on the trade-oﬀs among diﬀerent underlying factors in de-
signing TCP-splitting for dynamic content distribution.
2. PROBLEM SETTING & A SIMPLE MODEL
In this section, we describe the basic infrastructure with
FE servers for dynamic content distribution, and present a
simple abstract model to capture the interactions between
users and FE servers and between FE servers and BE data
centers. This model will guide us in the measurement and
analysis of dynamically generated search results from Bing
and Google.
Figure 1: Content distribution infrastructure.
Figure 2: Modeling search query timeline.
)
s
m
(
c
i
t
a
t
s
T
350
300
250
200
150
100
50
0
0
)
s
m
(
i
c
m
a
n
y
d
T
100 200 300 400 500
Samples
350
300
250
200
150
100
50
0
0
key1
key2
key3
key4
100 200 300 400 500
Samples
Figure 3: Tstatic and Tdynamic for diﬀerent keywords.
Figure 1 depicts a typical infrastructure set-up for dy-
namic content delivery consisting of FE servers that are
deployed at the “edge of the cloud” (thus relatively closer
to users) and BE data centers “deep in the cloud”. When
serving static content, FE servers often function as caches.
When serving dynamic content, FE servers can play two
key roles: i) they can cache certain portion of static content
that is common to all dynamically generated content, and
deliver it immediately upon receiving a user’s request; ii) by
splitting the end-to-end TCP connection, FE servers can es-
tablish persistent TCP connections with BE data center to
560speed up the delivery of the dynamically generated content
between them.
Unlike the static content distribution, there are several key
factors aﬀecting the user-perceived performance of dynamic
content distribution: the latency or round-trip time (RT T ),
available bandwidth and loss rate between a user and a FE
server, the load on a FE server, the latency or round-trip
time, available bandwidth and loss rate between a FE server
and the BE data center, the processing time at the data
center to generate dynamic content in response to a user’s
request, the load on servers at the data centers, and so forth.
Unfortunately most of these latter factors cannot be directly
observed and measured at the end hosts. To address this,
we develop a novel inference framework which allows us to
indirectly measure and quantify the overall (search query)
processing and delivery time between the data center and a
FE server.
As shown in Figure 2, we model the packet-level genera-
tion and reception process and deﬁne several (measurable)
parameters to capture the events of the static and dynamic
portions of the content distribution. The process starts at
tb with a TCP three-way handshake1. At time t1, a user
(client) sends an HTTP GET request, and receives the ACK
packet from the FE server after one RTT at t2. At t3 the
client receives the ﬁrst packet containing the static portion
of the content, and at t4 receives the last packet containing
the static content. At time t5, the ﬁrst packet containing dy-
namic content is received, and at time te, the ﬁnal packet of
the entire content is received. The correctness of the model
is validated in later sections, and is also quite consistent with
the descriptions given in [8, 9, 11].
In our model, the time when the ﬁrst and last packets
of the static content portion are received should, by deﬁni-
tion, hinge on the factors involving only the FE server and
client, namely, they are independent of the BE data cen-
ter. We deﬁne Tstatic := t4 − t2(= t4 − t1 − RT T ) which
bounds the processing and delivery of the static content por-
tion at the FE server side (assuming a constant RTT). We
deﬁne Tdynamic := t5 − t2 and Tdelta := t4 − t2. Then
Tdynamic upper-bounds the overall fetch time Tf etch, while
Tdelta := t5 − t4 serves as a (potentially loose) lower-bound
on this overall time. Meanwhile, Tf etch is mainly consisted
of the time it takes for the FE server to send the user re-
quest to a BE data center, for the data center to process
and dynamically generate a response (the dynamic content
portion) to the user request, and deliver it to the FE server.
Namely,
Tdelta ≤ Tf etch ≤ Tdynamic
Tf etch = Tproc + C ∗ RT Tbe
(1)
(2)
where C is constant, which depends on the TCP window size
on the BE data center. Moreover, ﬁxing a FE server, Tf etch
should be a constant, assuming the variability introduced by
FE server and data center loads, the available bandwidth
between them, etc., is small and negligible relative to the
RT T between the FE server and a client. In other words,
the time it takes for the FE server to receive the delivery of
the dynamically generated portion of the content from the
BE server is (roughly) a constant. On the other hand, the
delivery time (t4 − t3) for the static content is a function
of RT T . Hence our model predicts that as RT T increases,
1DNS resolution time is not included, as it is negligible as
compared to the overall user-perceived response time.
Tdelta decreases. With suﬃciently large RT T , Tdelta = 0;
thus the last packet of the static content portion and the
ﬁrst packet of the dynamic content portion will be delivered
back-to-back or even coalesce as a single packet.
3. ACTIVE MEASUREMENT & CONTENT
ANALYSIS
For our study, we develop an in-house user search query
emulator, which performs exactly the same functionality as
the web-based search box. We deploy the emulator on glob-
ally distributed2 PlanetLab nodes as well as on our lab and
home machines. The number of Planetlab nodes partici-
pating in each of our experiments ranges from 200 to 250,
depending on their reachability at the time being. We con-
duct extensive measurements by submitting the same search
queries to both Bing and Google search engines, and collect
detailed TCPdump with full application-layer payloads. We
perform two sets of experiments: 1) In the ﬁrst set, search
queries are launched from all measurement nodes to their
default3 FE servers every 10 seconds. 2) In the second set,
we ﬁx one FE server (of Bing or Google respectively) at
a time, and launch queries from all measurement nodes to
this server. We repeat these two sets of experiments using
diﬀerent sets of keywords and over diﬀerent times. We re-
fer to the data collected in the ﬁrst set/type of experiments
as Datasets A, and the second asDatasets B . Due to space
limitation, we omit the details of the active measurement
platform and experiment design and execution.
Parsing Application-Layer Packet Traces and Iden-
tifying the Static Content Part. Using the packet traces
collected via TCPdump, we perform detailed application
layer content analysis as well as transport layer temporal
classiﬁcation of packet generation and reception events. We
ﬁnd that in the search results returned by both Bing and
Google, there is a portion of the content that is static, namely,
independent of the search keywords submitted. This static
content portion includes the HTTP header, HTML header,
CSS style ﬁles, and the static menu bar, e.g. “Videos,”
“News,” “Shopping,” etc.
that are placed on top of each
search result page. The remaining dynamic portion includes
the keyword-dependent dynamic menu bar, search results
and ads. The temporal analysis of the packet-level events
conﬁrms that this static content portion is most likely cached
at FE servers and delivered immediately, as its delivery time
is largely a function of RTT, and does not vary signiﬁcantly
with, say, the types and complexity of search queries as does
the dynamic content portion (see below and Section 4).
Choice and Eﬀect of Search Queries. Since the dynam-
ically generated content portion is search query dependent,
we use diﬀerent sets of search keywords with varying popu-
larity, granularity, and complexity. For instance, the Bing
main page provides a list of most popular keywords at the
current time.
In terms of granularity, we generate search
queries with concatenated keywords which gives us increas-
ingly reﬁned search results (e.g., “Computer Science Depart-
ment” and “Computer Science Department at University of
Minnesota”). In terms of complexity, we use long and com-
2Although users are distributed globally, the size of the re-
turned search results are quite similar.
3The default server is whatever server IP address the DNS
resolution returns to the client.
561plex search queries and mixtures of keywords that are not
highly correlated (e.g., “computer and potato”).
As an example, Fig. 3 illustrates the eﬀect of 4 search key-
words of diﬀerent types on the Bing search performance: the
left and right panels plot Tstatic and Tdynamic, respectively,
for the 500 sample queries made in chronological order. As
the performance is susceptible to short-term ﬂuctuations, we
plot the moving median with the sample window size being
10. (The results using Google have similar distributions.)
We observe that Tdynamic varies signiﬁcantly with the types
of search keywords used, whereas Tstatic is mostly insensitive
to the search keywords used.
Do FE Servers Cache Search Results? To answer this