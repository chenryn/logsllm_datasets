# Characterizing Roles of Front-end Servers in End-to-End Performance of Dynamic Content Distribution

**Authors:**
Yingying Chen, Sourabh Jain, Vijay Kumar Adhikari, Zhi-Li Zhang

**Affiliation:**
Department of Computer Science & Engineering  
University of Minnesota - Twin Cities  
Minneapolis, MN 55414, USA  
{yingying, sourj, viadhi, zhzhang}@cs.umn.edu

## Abstract
This paper investigates the roles of front-end (proxy) servers in enhancing user-perceived performance for dynamic content distribution. Using Bing and Google search services as case studies, we conduct extensive network measurements and analyses to identify key factors affecting overall performance.

We develop a model-based inference framework to indirectly measure and quantify the "frontend-to-backend fetching time," which includes query processing at back-end data centers and delivery time between back-end data centers and front-end servers. Our results show that this fetching time is critical for end-to-end performance in dynamic content delivery.

## Categories and Subject Descriptors
C.4 [Performance of Systems]: Performance attributes

## General Terms
Measurement, Performance

## Keywords
Dynamic content distribution, Search service, TCP-splitting

## 1. Introduction
The Internet increasingly relies on powerful, large-scale data centers for storing and serving content. A significant portion of this content is dynamic, generated in response to user requests, often personalized. Web search is a prime example of such dynamic content generation. With the rise of cloud computing and cloud-based services, more data is stored in the cloud, and more dynamic content is generated on the fly.

Due to the high costs and complexity of building and operating large-scale data centers, they are typically few and far between, often located far from users. One approach to mitigate this issue and improve user-perceived performance (e.g., overall response time) is to deploy front-end (FE) servers closer to users. These FE servers can cache static portions of dynamic content and use split TCP connections to establish persistent connections with back-end (BE) data centers, thereby reducing the impact of TCP slow-start and improving throughput.

To investigate the roles of FE servers in dynamic content distribution, we conducted an active measurement-based comparative study of Google and Microsoft Bing web search services. Both services use FE servers to assist in distributing dynamic content (search results): Google deploys its own FE servers, while Bing uses Akamaiâ€™s content distribution network (CDN).

Using PlanetLab nodes, we performed extensive measurements by emulating various keyword search queries, collecting a large amount of dynamically generated content and application-layer data. Through content analysis and temporal clustering of packet-level events, we confirmed that both Bing and Google search results contain static portions (e.g., HTTP headers, HTML headers) that are cached and delivered immediately by FE servers.

Since the effect of split TCP connections cannot be directly measured, we developed a novel model-based inference framework to classify and separate the content into static and dynamic portions. We defined measurable parameters to characterize and predict the delivery performance of these portions. Our framework also allowed us to bound the FE-BE fetch time, which is the time it takes for a FE server to forward a user query to a BE data center, generate the content, and deliver it back to the FE server.

Our findings indicate that the fetch time between Google FE servers and BE data centers is generally smaller and more stable compared to the fetch time between Akamai FE servers and Bing data centers. Despite Akamai FE servers being closer to users, the variability in fetch time affects the user-perceived performance of Bing. This highlights a critical trade-off between FE server placement and FE-BE fetch time, suggesting that there is a distance threshold beyond which placing FE servers closer to users no longer improves performance. Instead, optimizing the FE-BE fetch time becomes crucial.

Finally, we developed heuristics to factor the FE-BE fetch time into back-end processing time and BE-FE round-trip delivery time.

### Related Work
Most prior works focus on the distribution of static content. For instance, [5] studies the assignment of clients to CDN edge servers to maximize performance. Other studies, such as [4, 6, 7], explore peer-to-peer models for static content distribution. [10] examines caching mechanisms in CDNs, and [12] shows that placing more proxy servers can enhance content distribution for Facebook users. [9] compares the performance of cloud services with and without TCP-splitting. In contrast, our work provides insights into the trade-offs in designing TCP-splitting for dynamic content distribution by reverse-engineering the strategies used by Google and Bing.

## 2. Problem Setting & Simple Model
In this section, we describe the basic infrastructure for dynamic content distribution with FE servers and present a simple abstract model to capture interactions between users, FE servers, and BE data centers. This model will guide our measurement and analysis of dynamically generated search results from Bing and Google.

### Infrastructure
Figure 1 depicts a typical setup for dynamic content delivery, with FE servers deployed at the edge of the cloud (closer to users) and BE data centers deep in the cloud. FE servers function as caches for static content and play two key roles in dynamic content distribution:
1. Caching common static portions of dynamically generated content.
2. Splitting TCP connections to establish persistent connections with BE data centers, speeding up the delivery of dynamic content.

### Key Factors
Several factors affect the user-perceived performance of dynamic content distribution:
- Latency or round-trip time (RTT), available bandwidth, and loss rate between a user and a FE server.
- Load on a FE server.
- Latency, available bandwidth, and loss rate between a FE server and a BE data center.
- Processing time at the BE data center to generate dynamic content.
- Load on servers at the data centers.

### Inference Framework
To address the challenge of measuring these factors, we developed a novel inference framework. As shown in Figure 2, we model the packet-level generation and reception process, defining several measurable parameters to capture the events of the static and dynamic portions of content distribution.

- **Tstatic**: Time from the first RTT to the last packet of the static content.
- **Tdynamic**: Time from the first RTT to the first packet of the dynamic content.
- **Tdelta**: Time from the last packet of the static content to the first packet of the dynamic content.

These parameters help us bound the overall fetch time (Tfetch), which is the sum of the processing time (Tproc) and the BE-FE round-trip delivery time (RTTbe).

\[
Tdelta \leq Tfetch \leq Tdynamic
\]
\[
Tfetch = Tproc + C \times RTTbe
\]

where \( C \) is a constant dependent on the TCP window size at the BE data center. Fixing a FE server, Tfetch should be relatively constant, assuming small variability due to loads and available bandwidth.

## 3. Active Measurement & Content Analysis
For our study, we developed an in-house user search query emulator, deployed on globally distributed PlanetLab nodes and lab/home machines. The number of participating PlanetLab nodes ranged from 200 to 250. We conducted extensive measurements by submitting the same search queries to both Bing and Google, collecting detailed TCPdump traces with full application-layer payloads.

### Experiments
We performed two sets of experiments:
1. **First Set**: Queries launched from all measurement nodes to their default FE servers every 10 seconds.
2. **Second Set**: Queries launched from all measurement nodes to a fixed FE server (one at a time for Bing and Google).

We repeated these experiments using different sets of keywords and over different times. The data collected in the first set is referred to as Datasets A, and the second as Datasets B.

### Parsing Application-Layer Packet Traces
Using the collected packet traces, we performed detailed application-layer content analysis and transport layer temporal classification of packet generation and reception events. We found that both Bing and Google search results contain a static portion (e.g., HTTP headers, HTML headers, CSS style files, and static menu bars) that is independent of the search keywords. The remaining dynamic portion includes keyword-dependent dynamic menu bars, search results, and ads.

### Choice and Effect of Search Queries
Since the dynamically generated content is query-dependent, we used different sets of search keywords with varying popularity, granularity, and complexity. For example, Bing's main page lists popular keywords, and we generated queries with concatenated keywords for refined results (e.g., "Computer Science Department" and "Computer Science Department at University of Minnesota"). We also used long and complex queries with uncorrelated keywords (e.g., "computer and potato").

### Results
Figure 3 illustrates the effect of four different search keywords on Bing search performance, plotting Tstatic and Tdynamic for 500 sample queries. Tdynamic varies significantly with the types of search keywords, while Tstatic is mostly insensitive to the keywords.

### Do FE Servers Cache Search Results?
To answer this, we analyzed the temporal behavior of the static and dynamic content portions. Our results suggest that FE servers do cache static portions of the content, delivering them immediately upon receiving a user request. This is confirmed by the consistent delivery times of static content, which are largely a function of RTT and do not vary significantly with the types and complexity of search queries.