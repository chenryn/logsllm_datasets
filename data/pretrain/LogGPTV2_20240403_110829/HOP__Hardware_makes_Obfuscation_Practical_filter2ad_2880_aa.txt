title:HOP: Hardware makes Obfuscation Practical
author:Kartik Nayak and
Christopher W. Fletcher and
Ling Ren and
Nishanth Chandran and
Satya V. Lokam and
Elaine Shi and
Vipul Goyal
HOP: Hardware makes Obfuscation Practical
Kartik Nayak∗, Christopher W. Fletcher†, Ling Ren‡, Nishanth Chandran§, Satya Lokam§, Elaine Shi(cid:107) and Vipul Goyal§
†UIUC – PI:EMAIL
∗UMD – PI:EMAIL
‡MIT – PI:EMAIL
§Microsoft Research – {nichandr, satya, vipul}@microsoft.com
(cid:107)Cornell University – PI:EMAIL
Abstract— Program obfuscation is a central primitive in cryp-
tography, and has important real-world applications in protecting
software from IP theft. However, well known results from the
cryptographic literature have shown that software only virtual
black box (VBB) obfuscation of general programs is impossible.
In this paper we propose HOP, a system (with matching theoretic
analysis) that achieves simulation-secure obfuscation for RAM
programs, using secure hardware to circumvent previous impos-
sibility results. To the best of our knowledge, HOP is the ﬁrst
implementation of a provably secure VBB obfuscation scheme in
any model under any assumptions.
HOP trusts only a hardware single-chip processor. We present
a theoretical model for our complete hardware design and prove
its security in the UC framework. Our goal is both provable
security and practicality. To this end, our theoretic analysis
accounts for all optimizations used in our practical design,
including the use of a hardware Oblivious RAM (ORAM), hard-
ware scratchpad memories,
instruction scheduling techniques
and context switching. We then detail a prototype hardware
implementation of HOP. The complete design requires 72% of the
area of a V7485t Field Programmable Gate Array (FPGA) chip.
Evaluated on a variety of benchmarks, HOP achieves an overhead
of 8× ∼ 76× relative to an insecure system. Compared to all prior
(not implemented) work that strives to achieve obfuscation, HOP
improves performance by more than three orders of magnitude.
We view this as an important step towards deploying obfuscation
technology in practice.
I.
INTRODUCTION
[4]
Program obfuscation [29],
is a powerful crypto-
graphic primitive, enabling numerous applications that rely
on intellectually-protected programs and the safe distribution
of such programs. For example, program obfuscation enables
a software company to release software patches without dis-
closing the vulnerability to an attacker. It could also enable a
pharmaceutical company to outsource its proprietary genomic
testing algorithms, to an untrusted cloud provider, without
compromising its intellectual properties. Here, the pharmaceu-
tical company is referred to as the “sender” whereas the cloud
provider is referred to as the “receiver” of the program.
Permission  to  freely  reproduce  all  or  part  of  this  paper  for  noncommercial 
purposes is granted provided that copies bear this notice and the full citation 
on the ﬁrst page. Reproduction for commercial purposes is strictly prohibited 
without the prior written consent of the Internet Society, the ﬁrst-named author 
(for  reproduction  of  an  entire  paper  only),  and  the  author’s  employer  if  the 
paper  was  prepared  within  the  scope  of  employment.
NDSS  ’17,  26  February  -  1  March  2017,  San  Diego,  CA,  USA
Copyright  2017  Internet  Society,  ISBN  1-891562-46-0
http://dx.doi.org/10.14722/ndss.2017.23349
Recently, the cryptography community has had new break-
through results in understanding and constructing program
obfuscation [21]. However, cryptographic approaches to-
wards program obfuscation have limitations. First, it is well-
understood that strong (simulation secure) notions of program
obfuscation cannot be realized in general [4] — although
they are desired or necessary in many applications such
as the aforementioned ones. Second, existing cryptographic
constructions of obfuscation (that achieve weaker notions of
security, such as indistinguishability obfuscation [22]) incur
prohibitive practical overheads, and are infeasible for most
interesting application scenarios. For example, it takes ∼ 3.3
hours to obfuscate even a very simple program such as an
80-bit point function (a function that is 0 everywhere except
at one point) and ∼ 3 minutes to evaluate it [37]. Moreover,
these cryptographic constructions of program obfuscation rely
on new cryptographic assumptions whose security is still
being investigated by the community through a build-and-break
iterative cycle [14]. Thus, to realize a practical scheme capable
of running general programs, it seems necessary to introduce
additional assumptions.
In this direction, there has been work by both the cryp-
tography and architecture communities in assuming trusted
hardware storing a secret key. However, proposals from the
cryptography community to realize obfuscation (and a closely
related primitive called functional encryption) have been
largely theoretical, focusing on what minimal trusted hardware
allows one to circumvent theoretical impossibility and realize
simulation-secure obfuscation [27], [15], [17]. Consequently
these works have not focused on practical efﬁciency, and
they often require running the program as circuits (instead of
as RAM programs) and also utilize expensive cryptographic
primitives such as fully homomorphic encryption (FHE) and
non-interactive zero knowledge proofs (NIZKs). On the other
hand, proposals from the architecture community such as Intel
SGX [42], AEGIS [53], XOM [38], Bastion [13], Ascend [18]
and GhostRider [40] are more practical, but
their designs
do not achieve cryptographic deﬁnition of obfuscation. In
this paper, we close this gap by designing and implementing
a practical construction of program obfuscation for RAM
programs using trusted hardware.
Problem statement. The problem of obfuscation can be
described as follows. A sender, who owns a program, uses an
obfuscate procedure to create an obfuscated program. It then
sends this obfuscated program to a receiver who can execute
the program on inputs of her choice. The obfuscated program
such as measuring power analysis or heat dissipation, we also
do not defend against hardware fault injection [8], [3], [34].
We assume that the program to be obfuscated is trustworthy
and will not leak sensitive information on its own, including
through possible software vulnerabilities such as buffer over-
ﬂows [7]. There exist techniques to mitigate these attacks, and
we consider them to be complementary to our work.
Challenges. It may seem that relying on secure hardware
as described above easily ‘solves’ the program obfuscation
problem. This is not the case: even with secure hardware, it
is still not easy to develop a secure and practical obfuscation
scheme. The crux of the problem is that many performance
optimizations in real systems (and related work in secure
processors [18], [40], [45]) hinge on exploiting program-
dependent behavior. Yet, obfuscation calls for completely
hiding all program-dependent behavior. Indeed, we started this
project with a strawman processor that gives off the impression
of executing any (or every) instruction during each time step
– so as to hide the actual instructions being executed. Not
surprisingly, this incurs huge (∼ 10, 000×; c.f. Section III-B)
overheads over an insecure scheme, even after employing a
state-of-the-art Oblivious RAM [26], [19] to improve the efﬁ-
ciency of accessing main memory. Moreover, in an obfuscation
setting, the receiver can run the same program multiple times
for different inputs and outputs. Introducing practical features
such as context switching — where the receiver can obtain
intermediate program state — enables this level of ﬂexibility
but also enables new attacks such as rewinding and mix-and-
match execution. Oblivious RAMs, in particular, are not secure
against rewinding and mix-and-match attacks and an important
challenge in this work is to protect them against said attacks
in the context of the HOP system.
A. Our Contributions
Given the above challenges, a primary goal of this paper
is to develop and implement an optimized architecture that is
still provably secure by the VBB obfuscation deﬁnition. We
stress that all the performance optimizations made in the paper
are included and proven secure in our theoretic analysis: we
want our practical design to match the theory to the extent
possible. We view this as an important step towards deploying
obfuscation technology in practice.
In more detail, we make the following contributions:
1. Theoretical contributions: We provide the ﬁrst theoretic
framework to efﬁciently obfuscate RAM programs directly on
secure hardware. One goal here is to avoid implicitly trans-
forming the obfuscated program to its circuit representation
(e.g., [17]), as the RAM to circuit transformation can incur
a polynomial blowup in runtime [23]. We also wish for our
analysis to capture important performance optimizations that
matter in an implementation; such as the use of a cryptographic
primitive called Oblivious RAM [25], [26], on-chip memory,
instruction scheduling, and context switching. As a byproduct,
part of our analysis achieves a new theoretical result (extending
[27]): namely, how to provide program obfuscation for RAM
Fig. 1: Obfuscation Scenario. The sender obfuscates pro-
grams using the obfuscate procedure. It sends (possibly mul-
tiple) obfuscated program(s) to the receiver. The receiver can
execute any obfuscated program with any input of its choice.
should be functionally identical to the original program. For
any given input, the obfuscated program runs for time T (ﬁxed
for the program) and returns an output.1 The receiver only has
a black box-like access to the program, i.e., it learns only
the program’s input/output behavior and the bound on the
runtime T . In obfuscation, the inputs/outputs are public (not
encrypted).
To make use of a trusted secure processor (which we
call a HOP processor), our obfuscation model is modiﬁed as
follows (cf. Figure 1). HOP processors are manufactured with
a hardwired secret key. The HOP processor (which is trusted)
is given to the receiver, and the secret key is given to the
sender. Using the secret key, the sender can create multiple
obfuscated programs using the obfuscate procedure and send
them to the receiver. The receiver then runs the execute pro-
cedure (possibly multiple times) to execute the program with
(cleartext) inputs of her choice. As mentioned, the receiver
(adversary) learns only the ﬁnal outputs and nothing else. In
other words, we offer virtual blackbox simulation security,
where the receiver learns only as much information as if she
were interacting with an oracle that computes the obfuscated
program. In particular, the receiver should not learn anything
from the HOP processor’s intermediate behavior such as timing
or memory access patterns, or the program’s total runtime
(since each program always runs for a ﬁxed amount of time
set by the sender).
Key distribution with public/private keys. We assume sym-
metric keys for simplicity. HOP may also use a private/public
key distribution scheme common in today’s trusted execution
technology. The obfuscate and execute operations can be de-
coupled from the exact setup and key distribution system used
to get public/private keys into the HOP processor. A standard
setup for key distribution [28], [42] is as follows: First, a
trusted manufacturer (e.g., Intel) creates a HOP processor with
a unique secret key. Its public key is endorsed/signed by the
manufacturer. Second, the HOP processors are distributed to
receivers and the certiﬁed public keys are distributed to senders
(software developers). The modiﬁcation to our scheme in the
public key setting is described in Appendix B. Note that the
key goal of obfuscation is to secure the sender’s program
and this relies on the secrecy of the private key stored in
the processor. Thus, it is imperative that the sender and the
manufacturer are either the same entity or the sender trusts
the manufacturer to not reveal the secret key to another party.
Non-goals. We do not defend against analog side channels
1T is analogous to a bound on circuit size in the cryptography literature.
2
obfuscateobfuscatedproginputoutputSender:Receiver:programexecutesendSendercanobfuscatediﬀerentprogramsReceivercanexecuteaprogramonwithsamekeymultipleinputstoreceiverrunsobfuscaterunsexecute(onmultipleinputs)(fromsender)programs directly assuming only ‘stateless’ secure hardware.2
We also show interesting technical subtleties that arise in
constructing efﬁcient RAM-model program obfuscation from
stateless hardware. In particular, we highlight the different
techniques used to overcome all possible forms of rewinding
and mix-and-match attacks (which may be of independent
interest). Putting it all together, we provide a formal proof of
security for the entire system under the universally composable
(UC) simulation framework [10].
of computation. Bitansky et al. [5] show a construction for
program obfuscation from “leaky” hardware. Similarly, Chung
et al. [15] considered basing the closely related primitive of
functional encryption on hardware tokens. Unfortunately, all
the above works require the obfuscated program run using a
universal circuit (or similar model) to achieve function privacy.
They do not support running RAM programs directly. This
severely limits the practicality of the above schemes, as we
demonstrate in Section VI-E.
2. Implementation with trusted hardware: We design and
implement a hardware prototype system (called HOP) that
attains the deﬁnition of program obfuscation and corresponds
to our theoretic analysis. To the best of our knowledge, this
effort represents the ﬁrst implementation of a provably secure
VBB obfuscation scheme in any model under any assump-
tions. For performance, our HOP prototype uses a hardware-
optimized Oblivious RAM, on-chip memory and instruction
scheduling (our current implementation does not yet support
context switching). As mentioned earlier, our key differentiator
from prior secure processor work is that our performance op-
timizations maintain program privacy and exhibit no program-
dependent behavior. With these optimizations, HOP performs
5× ∼ 238× better than the baseline HOP design across
simple to sophisticated programs while the overhead over
an insecure system is 8× ∼ 76×. The program code size
overhead for HOP is only an additive constant. Our ﬁnal design
requires 72% area when synthesized on a commodity FPGA
device. Of independent interest, we prove that our optimized
scheme always achieves to within 2× the performance of a
scheme that does not protect the main memory timing channel
(Section III-C).
II. RELATED WORK
Obfuscation. The formal study of virtual black-box (VBB)
obfuscation was initiated by Hada [29] and Barak et al. [4].
Unfortunately, Barak et al. showed that it is impossible to
achieve program obfuscation for general programs. Barak
et al. also deﬁned a weaker notion of indistinguishability
obfuscation (iO), which avoids their impossibility results.
Garg et al. [22] proposed a construction of iO for all circuits
based on assumptions related to multilinear maps. However,
these constructions are not efﬁcient from a practical standpoint.
There are constructions for iO for RAM programs proposed
where the size of the obfuscated program is independent of
the running time [6], [11], [36]. However, by deﬁnition, these
constructions do not achieve VBB obfuscation.
In order to circumvent the impossibility of VBB obfusca-
tion, Goyal et al. [27] considered virtual black-box obfuscators
on minimal secure hardware tokens. Goyal et al. show how
to achieve VBB obfuscation for all polynomial time com-
putable functions using stateless secure hardware tokens that
only perform authenticated encryption/decryption and a single
NAND operation. In a related line of work, D¨ottling et al. [17]
show a construction for program obfuscation using a single
stateless hardware token in universally input-oblivious models
2Roughly speaking, a HOP processor which allows the host to arbitrary
context switch programs on/off the hardware is equivalent
to ‘stateless’
hardware in the language of prior work [27], [15]. This is explained further
in Section III.
Oblivious RAMs. To enable running RAM programs directly
on secure hardware, we use a hardware implementation of
Oblivious RAM (ORAM) to hide access patterns to external
memory. ORAM was introduced by Goldreich and Ostrovsky
where they explored the use of tamper-proof hardware for
software protection [26]. Recently, there has been a lot of
work in making ORAMs practical. In this paper, we use an
efﬁcient hardware implementation of Path ORAM [52] called
Tiny ORAM [20], [19].
Secure processors. Secure processors such as AEGIS [53],
XOM [38], Bastion [13] and Intel SGX [42] encrypt and
verify the integrity of main memory. Applications such as
VC3 [48] that are built atop Intel SGX can run MapReduce
computations [16] in a distributed cloud setting while keeping
code and data encrypted. However, these secure processors
do not hide memory access patterns. An adversary observing
communication patterns between a processor and its memory