v
i
L
N
S
M
x
i
l
f
t
e
N
t
s
e
r
e
t
n
P
i
r
l
b
m
u
T
r
e
t
t
i
w
T
o
o
h
a
Y
e
b
u
T
u
o
Y
i
a
d
e
p
i
k
i
W
Figure 13: Call graph edges in Alexa’s top 20 sites for the
US. A single edge represents one or more invocations of a
unique caller/callee pair.
• Using an empirical analysis of JavaScript call graphs
in real web applications, we demonstrate that the vast
majority of function calls do not cross library bound-
aries. Thus, Pivot’s trusted master/untrusted satellite
decomposition is a natural one (§V-A).
• Since Pivot places untrusted libraries in separate
frames, it does not need to rewrite those libraries if
they do not make synchronous RPC calls. In contrast,
Jigsaw must rewrite all libraries. By avoiding many
of the dynamic security checks associated with full
writing, Pivot RPCs are typically one to two orders of
magnitude faster than Jigsaw RPCs (§V-B). Overall, a
Pivot version of the Silo web application [20] is 12.6
times faster than an equivalent Jigsaw version.
• Firefox’s current implementation of yield is slow
(§V-C), so rewritten Pivot code is currently slower than
rewritten Jigsaw code (§V-E). However, Pivot rewrites
less code than Jigsaw, so overall, Pivot applications will
be faster.
We ran all experiments on a machine with two 2.67 GHz
processors and 4 GB of RAM. All web pages were loaded
in Firefox v18.0.2. Firefox is currently the only browser to
implement the yield keyword; however, this keyword is an
ofﬁcial part of the upcoming JavaScript v6 speciﬁcation [9],
and other major browsers will soon implement the keyword.
For example, Chrome already provides the feature in devel-
oper builds of the browser (although the implementation still
has some bugs, which is why we do not present performance
graphs for Pivot on Chrome).
A. Cross-library Call Graphs
To determine how often web pages make cross-library
function calls, we visited the top 20 websites in the United
States as determined by Alexa. We interacted with those
pages as a normal user might, e.g., by scrolling down to
force the page to dynamically load below-the-fold images.
As we interacted with each page, we used Firefox’s built-
in JavaScript debugger to capture a call tree for each site.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:00:50 UTC from IEEE Xplore.  Restrictions apply. 
Amazon
% cross-lib % cross-lib
callees
% cross-lib % cross-lib
callees
Function
(*,*)
init(*, *, *)
c.Event(*, *)
H()
type(*)
Function
this._methodized()
$A(*)
Object.extend(*, *)
D(*)
extend(*, *)
callers
5.37%
0%
0%
0%
0%
CNN
callers
5.69%
0%
1.22%
0%
0%
0%
0%
0%
0%
0%
0%
0%
0%
0%
0%
Figure 14: The top ﬁve most invoked functions on Ama-
zon.com and CNN.com: how often those functions were
called by external libraries, and how often those functions
called functions deﬁned by external libraries. We omit results
for other sites due to space, but other sites had similar or
lower numbers of cross-library edges.
As Figure 13 shows, the vast majority of caller/callee edges
do not straddle library boundaries. Firefox’s debugger only
records unique caller/callee edges, not the number of times
a page traverses those edges, so Figure 13 still admits
the possibility that the small number of cross-library edges
are heavily traversed. To investigate this hypothesis, we
used a DynaTrace analytics web proxy [6] to instrument
each JavaScript function in each page and collect per-edge
traversal statistics. We found that cross-library calls are
exceedingly rare, as shown in Figure 14. Furthermore, the
cross-library edges almost always involved a caller residing
in core application “glue” code, and a callee residing in a
library like jQuery which is devoted to one task and which
rarely makes outcalls to the core application. Thus, Pivot’s
architecture (a small, trusted master and multiple untrusted
satellites) is a natural ﬁt for how developers already design
web pages.
B. End-to-end RPC Latency
To test the end-to-end latencies of cross-domain RPCs, we
built a mashup application that integrated three untrusted
JavaScript
libraries. We picked these particular libraries
because they were used to evaluate Jigsaw in the original
Jigsaw paper [22]. Our mashup application, called Shard,
is a privilege-separated implementation of the Silo applica-
tion [20]. The client-side Shard JavaScript collaborates with
a web server to layer a delta-encoding protocol atop HTTP.
When a user needs to fetch an HTML, JavaScript, or CSS
object, Shard downloads that object using an AJAX con-
nection. Shard then splits that object into chunks, calculates
Web server
Local disk
JsonRPC.js
(untrusted)
SHA1.js
(untrusted)
DomSQL.js
(untrusted)
Shard.js
(trusted)
Figure 15: Architecture of the Shard mashup: fetching data
from a web server, calculating the hash of the chunks, and
storing those chunks on the local disk.
a hash for each chunk, and stores each 
pair in local DOM storage [33]. Later, if the user needs to
fetch the latest version of that object, Shard sends a list
of locally resident chunk ids to the server. If the object
has changed, the server only sends the new object chunks,
avoiding the cost of sending the entire object. Once Shard
has received the new chunks, it fetches the relevant old
chunks from DOM storage, reconstructs the new object, and
uses document.write() to insert the new object into the
page’s HTML.
As shown in Figure 15, Shard fetches objects using
the JsonRPC AJAX library [11]. Shard uses the Stanford
JavaScript Crypto Library [30] to calculate SHA1 chunk
ids, and Shard writes those chunks to DOM storage using
DomSQL [5], a JavaScript library which layers a SQL query
interface atop DOM storage.
We built two versions of Shard, one that used Pivot,
and another that used Jigsaw. The Pivot version placed
unrewritten library code in each satellite frame; the code in
the trusted master frame was rewritten to allow the master
to make synchronous RPCs to satellite-deﬁned functions. In
the Jigsaw version of Shard, each library had to be rewritten
by the Jigsaw compiler; this ensured that it was safe to
place mutually untrusted libraries within the same frame.
As a performance baseline, we also implemented a version
of Shard which used standard JavaScript and which included
the unrewritten libraries in the same frame.
The ﬁrst three results in Figure 16 compare the perfor-
mance of Shard RPCs in Jigsaw and Pivot. Results are
normalized with respect to the performance of the baseline
implementation. Note that, for the JsonRPC calls, Shard con-
tacted a localhost web server. This allowed us to minimize
networking costs and focus on the CPU overhead of the
isolation frameworks.
For RPCs to the SHA1 library and DomSQL, Pivot was
20.6x faster and 128.2x faster than Jigsaw. Because Jigsaw
271
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:00:50 UTC from IEEE Xplore.  Restrictions apply. 
f
o
n
w
o
d
w
o
l
s
e
v
i
t
a
e
R
l
l
)
e
a
c
s
g
o
l
(
e
d
o
c
n
e
t
t
i
r
w
e
r
100
10
1
Jigsaw
Pivot
l
l
a
c
l
a
c
o
l
r
e
p
s
d
n
o
c
e
s
o
r
c
i
M
l
)
e
a
c
s
g
o
l
(
Standard JavaScript
Jigsaw
Pivot
1000
100
10
1
0.1
0.01
SHA1
DomSQL
JsonRPC
Bubblemark
Figure 16: Normalized, end-to-end RPC latencies: Jigsaw
versus Pivot. RPC latency is deﬁned as the time that elapses
between the invocation of an RPC and the reception of
the RPC result. Thus, RPC latency includes both message
transfer costs, and the computational costs of handling the
RPC request (e.g., issuing a DomSQL operation).
placed all libraries in the same frame, it had to inject costly
dynamic security checks into each library. Pivot avoided
those costs by placing unrewritten libraries in separate
frames. Jigsaw also had to virtualize the DOM interface,
presenting each library with a DOM emulation layer that
performed security checks before possibly accessing the real
DOM. Thus, when a Jigsaw library tried to access DOM
storage, it had to interact with an additional software layer
that Pivot applications did not have to traverse (each Pivot
satellite lived in its own frame and had private, isolated
DOM state).
Jigsaw virtualizes the XMLHttpRequest object, but Pivot
and Jigsaw had similar performance for JsonRPC calls
(1.15x slowdown versus 1.14x slowdown). This is because,
even though JsonRPC contacted a localhost server, the end-
to-end latency of the RPC was still dominated by HTTP
transfer costs.
The ﬁnal result
in Figure 16 shows the performance
of a simple mashup application that
invoked RPCs on
Bubblemark [10], a DOM-intensive animation program. The
trusted application core issued commands to the Bubble-
mark library like “start animation,” “stop animation,” and
“increase the number of animated objects.” Pivot is much
faster than Jigsaw for Bubblemark RPCs, just like it is faster
for DomSQL RPCs, because Pivot does not incur DOM
virtualization costs.
C. Generator Overhead
If a library does not need to issue synchronous RPC
calls, then Pivot can place the unrewritten library in an
iframe and avoid the rewriting costs incurred by Jigsaw.
However, when rewriting is necessary (e.g., in a master
frame), Pivot leverages the JavaScript yield statement to
implement generator functions. Firefox’s current implemen-
tation of generators is very slow. Calling an unrewritten
null function required 0.03 microseconds. However, creating
a new generator took an order of magnitude longer (0.39
microseconds), and calling next() on a null generator
Figure 17: Invocation latencies for a local null function and
recursive local null functions, demonstrating the impact of
generator overhead.
was similarly slow (0.44 microseconds). We also found
that accessing an object property within a generator was
22 times slower than accessing an object property within
a regular function. There is no fundamental reason why
generator overhead must be this high, since there is prior
work from the programming languages community which
describes how to make generators fast [16]. Thus, we expect
generator performance to improve once the new JavaScript
speciﬁcation is implemented in more browsers and there
is more developer pressure to make yield fast. Until that
happens, Pivot’s ability to safely integrate unrewritten code
is crucial for performance.
D. End-to-end Performance Improvement
To compare the end-to-end performance of our Shard
implementations, we measured the total time that an im-
plementation needed to fetch a 50 KB web object, split the
object into chunks, and store those chunks in DOM storage.
This end-to-end time captured both RPC latencies and the
computation time within the trusted application core and
the untrusted libraries. Overall, Shard on Pivot was 12.6
times faster than Shard on Jigsaw. Even though Pivot RPCs
can be 100 times faster than Jigsaw RPCs (Figure 16),
generator overhead within the rewritten master Shard frame
(Figure 17) can make rewritten Pivot code slower than
rewritten Jigsaw code. Nonetheless, end-to-end, Pivot is still
an order of magnitude faster than Jigsaw due to faster RPCs
and Pivot’s ability to selectively rewrite code. As yield
implementations get faster, we expect Pivot’s performance
advantage to grow.
E. RPC Communication Overheads
Figure 18 compares Jigsaw and Pivot, showing the end-to-