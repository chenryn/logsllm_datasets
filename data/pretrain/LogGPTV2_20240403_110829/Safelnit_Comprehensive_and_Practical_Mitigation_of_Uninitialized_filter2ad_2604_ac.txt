to be initialized to zero, our compiler can remove any zero
stores to freshly-allocated heap memory (treating all allocation
functions as equivalent to calloc); an example is shown in
Figure 7. Similarly, any loads from freshly-allocated memory
are known to be zero (rather than being undeﬁned behavior),
and we can replace them with a constant value.
If memory is fully initialized to a non-zero value, then our
optimizer can also rewrite the allocator call to an alternative
allocation function which skips any potential (unnecessary)
initialization; however, we want to be sure that only these
instances are left uninitialized by our custom allocator.
2) Non-constant-length store removal: Dead Store Elimi-
nation is generally only performed when the stores are of a
known constant length; we propose transforming stores with
non-constant lengths, which is important to remove unneces-
sary initializations of both dynamic stack allocations and heap
allocations. The simplest such situations are when an entire
existing store is overwritten, such as the code in Figure 8. Our
DSE also removes stores of a non-constant size, such as some
of our initialization stores, when they are entirely overwritten
by later stores.
3) Cross-block DSE: Our optimizer also performs Dead
Store Elimination across multiple basic blocks. This is an
active area of improvement for existing compilers, but is far
more relevant when universal initialization is introduced, and
is necessary to enable many of the optimizations below.
We need to remove both stores which are partially or
completely overwritten by other stores (standard DSE) as well
6
int result_buf[BUF_SIZE];
return shared_func(data, result_buf);
Fig. 9. Example of write-only/‘scratch’ buffer; initialization is unnecessary if
shared_func only writes to the pointer provided as the second argument.
as stores which are never used (for example, because the
value goes out of scope before being used), and while we are
primarily concerned about memset, we also remove normal
stores. New opportunities for rewriting heap functions may
also be revealed during this process, and our optimizer also
applies these optimizations here.
4) Non-constant-length store shortening: To enable other
optimizations, particularly involving string or other library
functions, we also attempt to shorten stores by non-constant
lengths. For example, if the ﬁrst x bytes of an array are initial-
ized, then we may be able to shorten an earlier initialization by
x bytes, assuming that the value of x does not change between
the stores. However, the compiler must either be able to prove
that x is never larger than the size of the array, or add an
additional (and potentially expensive) bounds check.
In practice, writing beyond the bounds of an array is
undeﬁned behavior, and existing compiler optimizations take
advantage of this to make assumptions. If execution is always
guaranteed to reach the second store after it has reached the
ﬁrst, the compiler can assume that the second store does not
write beyond the size of the array, and thus that the ﬁrst store
may always be shortened.
The conservative approach proposed by our design fails to
remove some stores which, in practice, are always safe. As
we discuss in implementation, this turned out to be a serious
limitation. The performance overhead of this optimization also
means that it is only worthwhile on relatively large stores; we
only apply it for stack allocations beyond a ﬁxed size.
5) Write-only buffers: Sometimes, memory is allocated, but
never written to. Removing unused local variables is known to
be an important optimization [27], but typically interprocedural
analysis has been unnecessary. A typical example is shown in
Figure 9, where a function requires a memory buffer as an
argument for storing results, but the caller never reads from
this buffer, simply discarding the content. Our initialization
further complicates this, by adding a new unnecessary write
to initialize such buffers.
If the called function never reads from the buffer, then the
entire buffer is unnecessary. One approach is to clone such
functions and remove the arguments in these cases, enabling
removal of the stores. However, this can dramatically increase
code size; inlining or cloning can be very expensive, and
our design aims to remain practical by avoiding the need for
any additional interprocedural analysis. Instead, we annotate
allocations and function (pointer) arguments which are only
written to. If we can then show that portions of memory are
only stored to, and not read, then all the stores can be removed.
VI.
IMPLEMENTATION
We implemented a prototype of SafeInit by extending the
clang compiler, and the LLVM compiler framework [35]. As
discussed, the dead store optimizations which are vital for
acceptable performance are an active area of development, so
we based our work on a recent pre-release version of the code
(LLVM revision 269558, from mid-May 2016).
A. Initialization pass
We implemented stack clearing as an LLVM pass, which
we run before any other optimization pass is allowed to run
– mostly importantly, before mem2reg, which will introduce
undef values when an uninitialized stack variable is read.
Local variables in LLVM are deﬁned by using the alloca
instruction; our pass performs initialization by adding a call to
the LLVM memset intrinsic after each of these instructions.
This guarantees that the entire allocation is cleared, and are
transformed into store instructions where appropriate.
B. Hardened allocator
We implemented our hardened allocator by modifying
tcmalloc, a modern high-performance heap allocator [22].
The underlying pages for the allocator are obtained using
mmap or sbrk, and are guaranteed to initially be be zero. We
force the use of MADV DONTNEED (or equivalent) when
freeing any such allocations, and so large heap allocations are
always zero, and need not be initialized. The performance over-
head of tracking the initialization status of smaller allocations
is excessive, so we simply clear all other heap allocations to
zero before the allocator returns a pointer.
We also modiﬁed LLVM to treat reads from newly-
allocated memory as returning zero, rather than undef, when
SafeInit is enabled. As discussed, this is vital for avoiding the
unpredictable consequences of undeﬁned values.
C. Optimizer
We implemented our proposed sinking stores optimization
for stack initialization by moving our inserted memset calls
to the dominating point of all uses of the alloca (ignoring
those which do not actually use the variable, such as casts or
debug intrinsics). When compiling with optimizations enabled,
clang will emit ‘lifetime’ markers which indicate the points
at which local variables come into scope; we modiﬁed clang
to emit appropriate lifetime markers in all circumstances, and
insert the initialization after these points.
The alloca instructions corresponding to local variables
are placed in the ﬁrst basic block, which is necessary for the
majority of LLVM optimizations to function correctly, and for
stack coloring to be performed. However, dynamic allocation
of stack space within a function may not be in the ﬁrst block
(such as when an alloca call is made from C/C++ code); in
these circumstances, we have to also ensure that initialization
is not performed before the allocation takes place.
We implemented initialization detection optimization by
adding a new intrinsic function, ‘initialized’, which has the
same store-killing side effects as memset, but is ignored by
code generation. By extending components such as LLVM’s
loop idiom detection to generate this new intrinsic where
replacing code with a memset is not possible, we allow
other existing optimization passes to take advantage of this
information without the need to modify them individually.
7
D. Dead Store Elimination
We implemented the other optimizations described above
by extending existing LLVM code, keeping our changes mini-
mal where possible. Our implementation of write-only buffers
made use of the patch in D18714 (since merged), which added
the basic framework for a writeonly attribute.
We also based our implementation of cross-block Dead
Store Elimination on the (rejected) patch in D13363. Due to
performance regressions, we disable this cross-block DSE for
small stores (≤ 8 bytes); we also extended this code to support
removing memset, and shortening such stores.
Our prototype currently only applies non-constant short-
ening to memset calls which overwrite an entire object, and
requires that they be at least 64 bytes for the efﬁciency reasons
discussed above. LLVM’s limited support for range analysis
severely limits the current optimization opportunities for such
shortening, since in the majority of cases we are unable to
prove accesses are safe without performing our own analysis.
Since our goal is to show techniques which are practical
to implement without needing additional analysis, we limited
ourselves to the typical analyses which are used by existing
in-tree code in such circumstances. These include checking
known bits, and making use of the ‘scalar evolution’ code for
loop variables. In turn, these limitations remove opportunities
for library call optimizations; we found that even our optimiza-
tions for string functions are of limited usefulness (outside of
artiﬁcial micro-benchmarks) due to the effect of these safety
checks.
E. Frame clearing
To put our evaluation into context, we also implemented an
alternative compiler hardening pass which clears the portion
of each frame reserved for local variables in every function
prologue. The performance of this frame clearing provides an
estimate of the lower bound for these naive approaches; we
apply our normal stack hardening pass to protect non-static
(dynamically-allocated) local variables.
This improves performance compared to simply clearing all
frames, since we do not clear space reserved for other purposes
such as spilled registers (although our optimized clearing code
sometimes clears part of this space, for alignment reasons).
This approach also fails to provide guarantees for overlapping
or re-used variables within the function; any changes to resolve
these (such as disabling stack coloring to avoid overlapping
variables) resulted in signiﬁcantly worse performance.
VII. DETECTION
Our hardened toolchain can also be combined with a
modern high-performance multi-variant execution system such
as [30] to provide a detection tool, inspired by DieHard [5]. We
compile multiple versions of the same application, initializing
memory to different values in each variant. This allows us to
perform high-performance detection of the majority of uses of
uninitialized values, including those which would typically be
removed by compiler optimizations or only stored in registers,
without the false positives resulting from ‘harmless’ memory
reads which do not affect the output. Example usage can be
seen in Figure 11.
int deny_access;
if (deny_access) {
printf("Access denied.");
return 0;
}
printf("Access granted.");
Fig. 10.
(Simpliﬁed) example of an uninitialized read which is optimized
away by existing compiler transforms; in this example, the code in the branch
is typically removed entirely.
$ var-cc -O2 example.c
$ multivar ./example-v0 ./example-v1
! SYSCALL MISMATCH for variants v0 and v1
˜ 0: write(1, "Access granted.", 15)
˜ 1: write(1, "Access denied.", 14)
== Backtrace ==
ip = 7271a9620 __write+16
...
ip = 727120de9 _IO_printf+153
ip = 4007ce check_access+366
Fig. 11. Example of an uninitialized read being detected, using optimized
builds of the code in Figure 10; since there is no uninitialized memory usage
in the optimized binaries, tools such as valgrind fail to detect such cases.
Filling memory with a constant value is much faster than
using random values, so we ﬁll all uninitialized bytes of
memory in each variant with the same constant. Some opti-
mizations are no longer possible when using non-zero values;
in particular, we need to clear all heap memory, since the zero
pages returned from the kernel are no longer appropriate.
However, multi-variant systems do not necessarily require
synchronization (they need not run variants in ‘lockstep’);
system calls need only be executed for one of the variants, the
so-called ‘leader’. Since our hardening has already mitigated
potential security issues, there is no need to run the variants
in lockstep. We initialize the values of the leader process with
zero, allowing it to run ahead of the other variants, which
reduces the overall runtime impact of this slower initialization.
VIII. EVALUATION
Our benchmarks were run on a (4-core) Intel
i7-3770
with 8GB of RAM, running (64-bit) Ubuntu 14.04.1. CPU
frequency scaling was disabled, and hyperthreading enabled.
Transparent Huge Pages were turned off, due to their extremely
unpredictable effect on runtime and memory usage – this is a
commonly-recommended vendor conﬁguration, and although it
has a negative effect on some benchmarks, it does not appear
to meaningfully change our overhead ﬁgures.
Our baseline conﬁguration is an unmodiﬁed version of
clang/LLVM, using an unmodiﬁed version of tcmalloc. As
well as comparing this to SafeInit, we also present results for
the naive approach, which simply applies our initialization
pass without any of our proposed optimizations, using a
hardened allocator which simply zeroes all allocations. We
do make use of a modiﬁed compiler which performs local
variable initialization and ensures that safety is maintained; for
8
20%
76% 36%
12%
naive SafeInit
SafeInit
3
2
1
0
−1
−2
8.0%
3.5%
2.2%
milc
namd
dealII
soplex
povray
lbm
sphinx3
Fig. 14. SPEC CFP2006, runtime overhead (%) for SafeInit
10
8
6
4
2
0
−2
perlbench
bzip2 gcc
mcf
gobmk
hm mer
libquantum
sjeng
h264ref
omnetpp
astar
xalancbmk
Fig. 12.
SafeInit
SPEC CINT2006, runtime overhead (%) when hardening with
20%
160% 36%
1
0
−1
−2
perlbench
bzip2 gcc
mcf
gobmk
hm mer
libquantum
sjeng
h264ref
omnetpp
astar
xalancbmk
frame clearing
SafeInit
Fig. 15.
without hardening applied
SPEC CINT2006, runtime overhead (%) of SafeInit’s optimizer
baseline compiler. Results for CFP2006 are similar, as shown
in Figure 14, with an average overhead of 2.2%.
Table I provides details of the number of allocas (repre-
senting the number of local variables, plus occasional copies of
arguments or dynamic allocations) for each benchmark. Many
initializations are transformed or removed during optimization,
but the table contains the number of initializations which are