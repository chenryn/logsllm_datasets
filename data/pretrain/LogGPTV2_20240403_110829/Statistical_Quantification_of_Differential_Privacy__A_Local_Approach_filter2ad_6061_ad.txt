where (x1, x
(approximating x works by setting x = x1 = ... = xB). If the
databases are chosen appropriately, the maximum on the right
side of (19) comes arbitrarily close to . Prior work suggests
that oftentimes simple heuristics already yield databases that
point to the global privacy parameter  [19]. Furthermore, the
structure of the data space D can naturally motivate search
(cid:2)
b to be “far apart” in
patterns (typically choosing xb and x
some sense).
We use the approximation in (19), combined with our
estimators for the data-speciﬁc privacy violations, for the
statistical inference of the parameters  and x. We integrate
these methods into the MPL algorithm presented in Section
IV-C and demonstrate that its output [LB,∞) is a one-sided,
asymptotic conﬁdence interval (Theorem 2).
A. Estimating data-speciﬁc privacy violations
We now consider the problem of estimating the data-speciﬁc
(cid:2) deﬁned
privacy violation x,x(cid:2) for two adjacent databases x, x
in (3). According to Theorem 1 we can express x,x(cid:2) as the
maximum of the loss function (cid:8)x,x(cid:2), i.e.
t∈Y (cid:8)x,x(cid:2) (t),
x,x(cid:2) = sup
where (cid:8)x,x(cid:2) is deﬁned in (18). It stands to reason to ﬁrst esti-
mate the privacy loss (cid:8)x,x(cid:2) by an empirical version ˆ(cid:8)x,x(cid:2), which
is then maximized to obtain an estimate for x,x(cid:2). Suppose that
A is either discrete or continuous, s.t. a realization of A(x) has
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:21:54 UTC from IEEE Xplore.  Restrictions apply. 
408
density fx. By running that algorithm n times on databases x
(cid:2) respectively, we can generate two independent samples
and x
of i.i.d observations X1, ..., Xn ∼ fx and Y1, ..., Yn ∼ fx(cid:2).
Recalling the deﬁnition of the loss function in (18), we can
naturally deﬁne the empirical loss function as
(cid:2)(cid:2) ln( ˆfx(t)) − ln( ˆfx(cid:2) (t))
(cid:2)(cid:2),
ˆ(cid:8)x,x(cid:2) (t) :=
(20)
where ˆfx, ˆfx(cid:2) are density estimators for fx, fx(cid:2). In the case
of continuous densities, we can obtain such estimators via the
TKDE algorithm (see Section II-B). For discrete densities, we
can use a truncated version of the relative frequency estimator,
which is described in the TDDE (truncated discrete density
estimator) algorithm and mathematically deﬁned as follows:
|{Xi : Xi = t}|
∨ τ .
ˆfx(t) :=
n
As in the TKDE algorithm “∨” denotes the maximum and
τ > 0 a ﬂoor to avoid instabilities due to small probabilities.
The ﬂoor can be chosen smaller if n is larger and the density
estimate more accurate. We formalize this in the following
assumption for discrete algorithms:
√
(D) The parameter
τ = O(ln(n)/
τ
n).
is
adapted to n and satisﬁes
for i = 1, 2, . . . , n do
Algorithm 2 Truncated discrete density estimator
Input: X = (X1, ..., Xn): data sample, t: evaluation point, τ: ﬂoor
Output: ˆf (t): density estimate at point t
1: function TDDE(X, t, τ)
2: out := 0
3:
4:
5:
6:
7:
8: out = out/n
9: return out ∨ τ
10: end function
if Xi = t then
out = out + 1
end for
end if
In principle, we could now approximate x,x(cid:2) by maximiz-
ing the empirical loss ˆ(cid:8)x,x(cid:2). Yet for algorithms with large
output spaces (in particular continuous algorithms) ˆ(cid:8)x,x(cid:2) can
yield unreliable estimates for extreme values of t, where
(almost) no observations are sampled. We therefore restrict
maximization to a closed, bounded set C ⊂ Y, usually an
interval (or hypercube in the multivariate case). Notice that
x,x(cid:2),C := sup
t∈C
(cid:8)x,x(cid:2) (t) ≈ sup
t∈Y (cid:8)x,x(cid:2) (t) = x,x(cid:2)
(21)
in the sense that the difference between x,x(cid:2),C and x,x(cid:2) can
be made arbitrarily small for sufﬁciently large C. For most
standard algorithms even strict equality holds for some ﬁxed
C (as is the case for all algorithms investigated in Section V).
This is in particular true for discrete algorithms with ﬁnite
range, where we can always choose C = Y.
Fig. 3: Loss function (cid:8)x,x(cid:2) (blue) and empirical loss ˆ(cid:8)x,x(cid:2)
(red) for the Laplace algorithm. The vertical line indicates the
location of the argmax ˆt and the horizontal line the maximum
ˆx,x(cid:2) of the empirical loss function.
We now state two regularity conditions that pertain to
continuous algorithms and guarantee reliable inference:
(C1) There exists a constant β ∈ (0, 1], such that for all x the
density fx corresponding to A(x) is β-H¨older continuous.
(cid:2) and any sequence (tn)n∈N in C, which
(C2) For any x, x
satisﬁes
n→∞ (cid:8)x,x(cid:2) (tn) = sup
lim
t∈C
(cid:8)x,x(cid:2) (t),
holds
it
arg maxt∈C (cid:8)x,x(cid:2) (t).
that
(tn)n∈N
has
a
limit
point
in
We brieﬂy comment on these assumptions: Condition (C1)
demands that our algorithm is not only continuous in the
sense that it has probability densities everywhere, but that
these additionally satisfy a weak regularity condition of β-
smoothness (see Section II-B). This guarantees reliable kernel
density estimators and thus a good approximation of (cid:8)x,x(cid:2) by
ˆ(cid:8)x,x(cid:2). Condition (C2) is a technical requirement that appears
more complicated than it is: It prohibits the maximum privacy
violation (of A on C) from occurring in locations where
both densities are 0, thus excluding pathological cases. Many
continuous algorithms satisfy both of these conditions (among
them all those discussed in this paper).
We now deﬁne the location ˆt of maximum privacy violation:
ˆt ∈ arg max
t∈C
ˆ(cid:8)x,x(cid:2) (t).
(22)
In the following we demonstrate that the maximum of the
empirical loss function, i.e.
ˆx,x(cid:2) := ˆ(cid:8)x,x(cid:2) (ˆt)
(23)
is close to the maximum of the true loss function.
To derive asymptotic convergence rates in the continuous
(cid:2) of the truncated kernel density
case, the bandwidths h and h
estimators ˆfx and ˆfx(cid:2) in (20) have to be chosen appropriately.
In addition, the ﬂoor τ must not be smaller than the precision
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:21:54 UTC from IEEE Xplore.  Restrictions apply. 
409
level of the density estimators (see Section II-B). We specify
the proper choice of parameters in the following condition:
(cid:4)
(cid:2) and τ are adapted to n and satisfy
(C3) The parameters h, h
− 1
− β
(cid:4)
τ = O(cid:3)
= O(cid:3)
(cid:2)
h, h
n
2β+d
,
n
2β+d ln(n)
.
Proposition 1. Suppose that C is a closed, bounded set and
x,x(cid:2),C ∈ (0,∞). If A is a discrete algorithm and condition
(D) is satisﬁed, it follows that
|ˆx,x(cid:2) − x,x(cid:2),C| = OP (n
−1/2)
and |(cid:8)x,x(cid:2) (ˆt) − x,x(cid:2),C| = OP (n
−1/2).
If A is a continuous algorithm such that conditions (C1) −
(C3) are satisﬁed, it follows that
|ˆx,x(cid:2) − x,x(cid:2),C| = OP
(cid:9)(cid:12)
(cid:9)(cid:12)
and |(cid:8)x,x(cid:2) (ˆt) − x,x(cid:2),C| = OP
ln(n)n
Furthermore, if x,x(cid:2),C ∈ {0,∞} it holds that
− β
2β+d
ln(n)n
− β
(cid:11)
(cid:11)
2β+d
.
ˆx,x(cid:2) →P x,x(cid:2),C
where “→P ” denotes convergence in probability (see Ap-
pendix A for a deﬁnition).
The ﬁrst identity for both the discrete and continuous case
in Proposition 1 suggests that the maximum privacy violation
(cid:2) is approximated by its empirical counterpart at the
for x, x
(cid:2)
x by their estimators, which
same rate as the densities fx, f
again is different in both settings. This rate -speciﬁcally in the
continuous case- should not be taken for granted: Admittedly,
if the two continuous densities fx, fx(cid:2) are bounded away from
0 on C, it is not difﬁcult to show that
|ˆ(cid:8)x,x(cid:2) (t) − (cid:8)x,x(cid:2) (t)| = OP
− β
2β+d
ln(n)n
sup
t∈C
(cid:9)(cid:12)
(cid:11)
,
which implies the Proposition. However, if the densities are not
bounded away from 0, it may not be true that (cid:8)x,x(cid:2) is uniformly
approximated by ˆ(cid:8)x,x(cid:2). Still, the approximation of the maxima
holds and is not slowed down in this case (even though the
mathematical proof gets substantially more involved).
The second identity (for both cases) states that ˆt is close
to the argmax of (cid:8)x,x(cid:2) in the sense that the true loss function
evaluated at ˆt is close to its maximum on C. This fact will be
used in the two subsequent sections, where we argue that a
conﬁdence interval for (cid:8)x,x(cid:2) (ˆt) automatically contains x,x(cid:2),C.
We conclude this section by stating the DPL algorithm
(cid:2), calculates the maximum
(Algorithm 3) which, given x and x
empirical privacy loss, as well as ˆt. In DPL, the binary variable
discr indicates whether a discrete (1) or continuous (0) setting
is on hand and the set C encloses the area of interest.
B. Statistical bounds for pointwise privacy loss
In the previous section, we have considered the problem of
estimating data-speciﬁc privacy violations. We now move to
the related topic of statistical inference in the sense of Section
II-A: Finding a conﬁdence interval for x,x(cid:2),C.
, closed and bounded set C,
and τ in accordance with (C3) if discr = 0
sample size n, speciﬁcation variable discr
Algorithm 3 Data-speciﬁc privacy loss
Input: neighboring databases x and x(cid:2)
Output: estimated loss ˆx,x(cid:2), location of loss ˆt
1: function DPL(x, x(cid:2), n, C, discr)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18: end function
Generate X = (X1,··· , Xn) with Xi ∼ A(x)
Generate Y = (Y1,··· , Yn) with Yi ∼ A(x(cid:2)
)
Set τ in accordance with (D) if discr = 1
Set h, h(cid:2)
Choose appropriate kernel K
if discr = 1 then
ˆfx(·) = TDDE(X,·, τ )
ˆfx(cid:2) (·) = TDDE(Y,·, τ )
ˆfx(·) = TKDE(X,·, h, K, τ )
ˆfx(cid:2) (·) = TKDE(Y,·, h(cid:2), K, τ )
end if
ˆ(cid:4)x,x(cid:2) (·) = | ln( ˆfx(·)) − ln( ˆfx(cid:2) (·))|
ˆt = arg max{ˆ(cid:4)x,x(cid:2) (t) : t ∈ C}
ˆx,x(cid:2) = ˆ(cid:4)x,x(cid:2) (ˆt)
return (ˆt, ˆx,x(cid:2) )
else
cn
σ
More precisely, we show in this section how to construct an
asymptotic conﬁdence interval for the pointwise privacy loss
(cid:8)x,x(cid:2) (t) for an arbitrary t ∈ C, which we apply later to the
choice t = ˆt (recall that according to Proposition 1 we have
(cid:8)x,x(cid:2) (ˆt) ≈ x,x(cid:2),C).
Suppose that (cid:8)x,x(cid:2) (t) ∈ (0,∞). In this situation it can be
shown by asymptotic normality of the density estimators and
the delta method (see [37]), that for all t ∈ R
(cid:11)
(cid:9)
(ˆ(cid:8)x,x(cid:2) (t) − (cid:8)x,x(cid:2) (t)) ≤ t
√
√
= Φ(t).
lim
n→∞ P
(24)
Here Φ(·) is the distribution function of a standard normal
n if the algorithm A is discrete
random variable and cn =
nhd if it is continuous. In the latter case h denotes
and cn =
the bandwidth of both ˆfx, ˆfx(cid:2) and is assumed to be adapted to
the sample size n as h = O(n
− 1
2β+d−γ) for some γ > 0. This
bandwidth is smaller than the one suggested in (C3) and leads
to a slower uniform convergence of the corresponding density
estimators (see Section II-B, (11)). Such a bandwidth choice,
which makes the variance of the density estimator larger than
its bias, is referred to as “undersmoothing”. Undersmoothing
is a standard tool in the statistical analysis of continuous
densities, where the two tasks of estimation and inference
require different degrees of smoothing (see [38] p.3999).
The variance σ2 on the right side of (24) can be expressed
as follows:
σ2 :=
⎧⎨
(cid:5)
⎩ 1
fx(t) + 1
K 2(s) ds
(cid:9)
fx(cid:2) (t) − 2,
1
fx(t) + 1
fx(cid:2) (t)
(cid:11)
A discrete
, A continuous.
Note that σ2 is well-deﬁned in both cases (in particular in
the discrete case 1/fx(t), 1/fx(cid:2) (t) > 1, s.t. the variance is
indeed positive). Also notice that σ2 is unknown, but easy
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:21:54 UTC from IEEE Xplore.  Restrictions apply. 
410
to estimate in practice, replacing the true densities by their
estimators ˆfx, ˆfx(cid:2), which yields
− 2,
ˆfx(t) + 1
ˆfx(cid:2) (t)
⎧⎨
(cid:9)
(cid:5)
⎩ 1
ˆfx(t) + 1
ˆfx(cid:2) (t)
K 2(s)ds
, A continuous.
A discrete
ˆσ2 :=
(cid:11)
1
It is straightforward to show that ˆσ2 = σ2 + oP (1). We can
now use this fact, together with the convergence in (24), to
see that for any α ∈ (0, 1)
1 − α ≈ P
(ˆ(cid:8)x,x(cid:2) (t) − (cid:8)x,x(cid:2) (t)) ≤ Φ
(cid:9)
(cid:9)
cn
ˆσ
ˆ(cid:8)x,x(cid:2) (t) +
= P
(cid:11)
−1(1 − α)
(cid:11)
(25)
Φ
−1(α)ˆσ
cn
≤ (cid:8)x,x(cid:2) (t)
.
−1 denotes the quantile function of the standard normal
Here Φ
−1(1 − α) =
distribution and we have used the identity Φ
−1(α). The approximation of 1− α by the probability gets
−Φ
more accurate as the sample size n increases and we see that
ˆIα := [ˆ(cid:8)x,x(cid:2) (t) + ˆσc
−1
n Φ
−1(α),∞)
is an asymptotic conﬁdence interval for (cid:8)x,x(cid:2) (t) (in the sense
of Section II-A).
Recall
C. A statistical procedure for the maximum privacy violation
the deﬁnition of x,x(cid:2),C in (21). In this section
we construct the algorithm called MPL (Maximum Privacy
Loss) whose output LB lower bounds the maximum of
B ,C with prescribed probability 1 − α. The
x1,x(cid:2)
choice of α is determined by the user but, guided by com-
mon practice in hypothesis testing, we recommend α ∈
{0.1, 0.05, 0.01}. By construction the inequality
1,C, ..., xB ,x(cid:2)
max{x1,x(cid:2)
1 , ..., xB ,x(cid:2)
B
} ≥ max{x1,x(cid:2)
1,C, ..., xB ,x(cid:2)
B ,C}
holds and both sides are arbitrarily close for large enough C.
Hence, LB will also constitute a tight lower bound for the
maximum on the left and thus of the privacy parameter  (see
(19)). An outline of MPL is given in Algorithm 4.
We now study the structure of the MPL algorithm, which
calculates LB for a given set
X = {(x1, x
(cid:2)
1), ..., (xB, x
B)}
(cid:2)
b by an estimate ˆxb,x(cid:2)
1 , ..., ˆxB ,x(cid:2)
of B adjacent pairs and is composed of two parts. The ﬁrst
part of the algorithm is dedicated to ﬁnding the pair of
max) ∈ X along with the corresponding