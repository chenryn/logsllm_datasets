> 
> **问题 1**、当你从一个环境切换到另一个环境时，你是否需要做一些操作来确保 I/O 权限设置能被保存和正确地恢复？为什么？
> 
> 
> 
注意本实验中的 `GNUmakefile` 文件，它用于设置 QEMU 去使用文件 `obj/kern/kernel.img` 作为磁盘 0 的镜像（一般情况下表示 DOS 或 Windows 中的 “C 盘”），以及使用（新）文件 `obj/fs/fs.img` 作为磁盘 1 的镜像（”D 盘“）。在本实验中，我们的文件系统应该仅与磁盘 1 有交互；而磁盘 0 仅用于去引导内核。如果你想去恢复其中一个有某些错误的磁盘镜像，你可以通过输入如下的命令，去重置它们到最初的、”崭新的“版本：
```
$ rm obj/kern/kernel.img obj/fs/fs.img
$ make
```
或者：
```
$ make clean
$ make
```
小挑战！实现中断驱动的 IDE 磁盘访问，既可以使用也可以不使用 DMA 模式。由你来决定是否将设备驱动移植进内核中、还是与文件系统一样保留在用户空间中、甚至是将它移植到一个它自己的的单独的环境中（如果你真的想了解微内核的本质的话）。
### 块缓存
在我们的文件系统中，我们将在处理器虚拟内存系统的帮助下，实现一个简单的”缓冲区“（实际上就是一个块缓冲区）。块缓存的代码在 `fs/bc.c` 文件中。
我们的文件系统将被限制为仅能处理 3GB 或更小的磁盘。我们保留一个大的、尺寸固定为 3GB 的文件系统环境的地址空间区域，从 0x10000000（`DISKMAP`）到 0xD0000000（`DISKMAP+DISKMAX`）作为一个磁盘的”内存映射版“。比如，磁盘的 0 号块被映射到虚拟地址 0x10000000 处，磁盘的 1 号块被映射到虚拟地址 0x10001000 处，依此类推。在 `fs/bc.c` 中的 `diskaddr` 函数实现从磁盘块编号到虚拟地址的转换（以及一些完整性检查）。
由于我们的文件系统环境在系统中有独立于所有其它环境的虚拟地址空间之外的、它自己的虚拟地址空间，并且文件系统环境仅需要做的事情就是实现文件访问，以这种方式去保留大多数文件系统环境的地址空间是很明智的。如果在一台 32 位机器上的”真实的“文件系统上这么做是很不方便的，因为现在的磁盘都远大于 3 GB。而在一台有 64 位地址空间的机器上，这样的缓存管理方法仍然是明智的。
当然，将整个磁盘读入到内存中需要很长时间，因此，我们将它实现成”按需“分页的形式，那样我们只在磁盘映射区域中分配页，并且当在这个区域中产生页故障时，从磁盘读取相关的块去响应这个页故障。通过这种方式，我们能够假装将整个磁盘装进了内存中。
> 
> **练习 2**、在 `fs/bc.c` 中实现 `bc_pgfault` 和 `flush_block` 函数。`bc_pgfault` 函数是一个页故障服务程序，就像你在前一个实验中编写的写时复制 fork 一样，只不过它的任务是从磁盘中加载页去响应一个页故障。在你编写它时，记住： (1) `addr` 可能并不会做边界对齐，并且 (2) 在扇区中的 `ide_read` 操作并不是以块为单位的。
> 
> 
> （如果需要的话）函数 `flush_block` 应该会将一个块写入到磁盘上。如果在块缓存中没有块（也就是说，页没有映射）或者它不是一个脏块，那么 `flush_block` 将什么都不做。我们将使用虚拟内存硬件去跟踪，磁盘块自最后一次从磁盘读取或写入到磁盘之后是否被修改过。查看一个块是否需要写入时，我们只需要去查看 `uvpt` 条目中的 `PTE_D` 的 ”dirty“ 位即可。（`PTE_D` 位由处理器设置，用于表示那个页被写入；具体细节可以查看 x386 参考手册的 [第 5 章](http://pdos.csail.mit.edu/6.828/2011/readings/i386/s05_02.htm) 的 5.2.4.3 节）块被写入到磁盘上之后，`flush_block` 函数将使用 `sys_page_map` 去清除 `PTE_D` 位。
> 
> 
> 使用 `make grade` 去测试你的代码。你的代码应该能够通过 check\_bc、check\_super、和 check\_bitmap 的测试。
> 
> 
> 
在 `fs/fs.c` 中的函数 `fs_init` 是块缓存使用的一个很好的示例。在初始化块缓存之后，它简单地在全局变量 `super` 中保存指针到磁盘映射区。在这之后，如果块在内存中，或我们的页故障服务程序按需将它们从磁盘上读入后，我们就能够简单地从 `super` 结构中读取块了。
.
> 
> **小挑战！**到现在为止，块缓存还没有清除策略。一旦某个块因为页故障被读入到缓存中之后，它将一直不会被清除，并且永远保留在内存中。给块缓存增加一个清除策略。在页表中使用 `PTE_A` 的 accessed 位来实现，任何环境访问一个页时，硬件就会设置这个位，你可以通过它来跟踪磁盘块的大致使用情况，而不需要修改访问磁盘映射区域的任何代码。使用脏块要小心。
> 
> 
> 
### 块位图
在 `fs_init` 设置了 `bitmap` 指针之后，我们可以认为 `bitmap` 是一个装满比特位的数组，磁盘上的每个块就是数组中的其中一个比特位。比如 `block_is_free`，它只是简单地在位图中检查给定的块是否被标记为空闲。
> 
> **练习 3**、使用 `free_block` 作为实现 `fs/fs.c` 中的 `alloc_block` 的一个模型，它将在位图中去查找一个空闲的磁盘块，并将它标记为已使用，然后返回块编号。当你分配一个块时，你应该立即使用 `flush_block` 将已改变的位图块刷新到磁盘上，以确保文件系统的一致性。
> 
> 
> 使用 `make grade` 去测试你的代码。现在，你的代码应该要通过 alloc\_block 的测试。
> 
> 
> 
### 文件操作
在 `fs/fs.c` 中，我们提供一系列的函数去实现基本的功能，比如，你将需要去理解和管理结构 `File`、扫描和管理目录”文件“的条目、 以及从根目录开始遍历文件系统以解析一个绝对路径名。阅读 `fs/fs.c` 中的所有代码，并在你开始实验之前，确保你理解了每个函数的功能。
> 
> **练习 4**、实现 `file_block_walk` 和 `file_get_block`。`file_block_walk` 从一个文件中的块偏移量映射到 `struct File` 中那个块的指针上或间接块上，它非常类似于 `pgdir_walk` 在页表上所做的事。`file_get_block` 将更进一步，将去映射一个真实的磁盘块，如果需要的话，去分配一个新的磁盘块。
> 
> 
> 使用 `make grade` 去测试你的代码。你的代码应该要通过 file\_open、filegetblock、以及 fileflush/filetruncated/file rewrite、和 testfile 的测试。
> 
> 
> 
`file_block_walk` 和 `file_get_block` 是文件系统中的”劳动模范“。比如，`file_read` 和 `file_write` 或多或少都在 `file_get_block` 上做必需的登记工作，然后在分散的块和连续的缓存之间复制字节。
.
> 
> **小挑战！**如果操作在中途实然被打断（比如，突然崩溃或重启），文件系统很可能会产生错误。实现软件更新或日志处理的方式让文件系统的”崩溃可靠性“更好，并且演示一下旧的文件系统可能会崩溃，而你的更新后的文件系统不会崩溃的情况。
> 
> 
> 
### 文件系统接口
现在，我们已经有了文件系统环境自身所需的功能了，我们必须让其它希望使用文件系统的环境能够访问它。由于其它环境并不能直接调用文件系统环境中的函数，我们必须通过一个远程过程调用或 RPC、构建在 JOS 的 IPC 机制之上的抽象化来暴露对文件系统的访问。如下图所示，下图是对文件系统服务调用（比如：读取）的样子：
```
      Regular env           FS env
   +---------------+   +---------------+
   |      read     |   |   file_read   |
   |   (lib/fd.c)  |   |   (fs/fs.c)   |
...|.......|.......|...|.......^.......|...............
   |       v       |   |       |       | RPC mechanism
   |  devfile_read |   |  serve_read   |
   |  (lib/file.c) |   |  (fs/serv.c)  |
   |       |       |   |       ^       |
   |       v       |   |       |       |
   |     fsipc     |   |     serve     |
   |  (lib/file.c) |   |  (fs/serv.c)  |
   |       |       |   |       ^       |
   |       v       |   |       |       |
   |   ipc_send    |   |   ipc_recv    |
   |       |       |   |       ^       |
   +-------|-------+   +-------|-------+
           |                   |
           +-------------------+
```
圆点虚线下面的过程是一个普通的环境对文件系统环境请求进行读取的简单机制。从（我们提供的）在任何文件描述符上的 `read` 工作开始，并简单地派发到相关的设备读取函数上，在我们的案例中是 `devfile_read`（我们还有更多的设备类型，比如管道）。`devfile_read` 实现了对磁盘上文件指定的 `read`。它和 `lib/file.c` 中的其它的 `devfile_*` 函数实现了客户端侧的文件系统操作，并且所有的工作大致都是以相同的方式来完成的，把参数打包进一个请求结构中，调用 `fsipc` 去发送 IPC 请求以及解包并返回结果。`fsipc` 函数把发送请求到服务器和接收来自服务器的回复的普通细节做了简化处理。
在 `fs/serv.c` 中可以找到文件系统服务器代码。它是一个 `serve` 函数的循环，无休止地接收基于 IPC 的请求，并派发请求到相关的服务函数，并通过 IPC 来回送结果。在读取示例中，`serve` 将派发到 `serve_read` 函数上，它将去处理读取请求的 IPC 细节，比如，解包请求结构并最终调用 `file_read` 去执行实际的文件读取动作。
回顾一下 JOS 的 IPC 机制，它让一个环境发送一个单个的 32 位数字和可选的共享页。从一个客户端向服务器发送一个请求，我们为请求类型使用 32 位的数字（文件系统服务器 RPC 是有编号的，就像系统调用那样的编号），然后通过 IPC 在共享页上的一个 `union Fsipc` 中存储请求参数。在客户端侧，我们已经在 `fsipcbuf` 处共享了页；在服务端，我们在 `fsreq`（`0x0ffff000`）处映射入站请求页。
服务器也通过 IPC 来发送响应。我们为函数的返回代码使用 32 位的数字。对于大多数 RPC，这已经涵盖了它们全部的返回代码。`FSREQ_READ` 和 `FSREQ_STAT` 也返回数据，它们只是被简单地写入到客户端发送它的请求时的页上。在 IPC 的响应中并不需要去发送这个页，因为这个页是文件系统服务器和客户端从一开始就共享的页。另外，在它的响应中，`FSREQ_OPEN` 与客户端共享一个新的 “Fd page”。我们将快捷地返回到文件描述符页上。
> 
> **练习 5**、实现 `fs/serv.c` 中的 `serve_read`。
> 
> 
> `serve_read` 的重任将由已经在 `fs/fs.c` 中实现的 `file_read` 来承担（它实际上不过是对 `file_get_block` 的一连串调用）。对于文件读取，`serve_read` 只能提供 RPC 接口。查看 `serve_set_size` 中的注释和代码，去大体上了解服务器函数的结构。
> 
> 
> 使用 `make grade` 去测试你的代码。你的代码通过 serveopen/filestat/file\_close 和 file\_read 的测试后，你得分应该是 70（总分为 150）。
> 
> 
> 
.
> 