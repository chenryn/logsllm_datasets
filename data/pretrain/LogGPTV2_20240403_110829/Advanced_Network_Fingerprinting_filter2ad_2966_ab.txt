else if T ype(nodea) = REP ET IT ION then
if not (#nodea = #nodeb) then
(cid:2)
Length
Report Dif f erence((cid:2)
, nodea, nodeb)
(cid:2)Non Terminals have
(cid:2)an unique child
(cid:2)In a Sequence
(cid:2)#nodea = #nodeb
end if
matches := Identif y Children M atches(nodea, nodeb)
if ∃ (i, j) ∈ matches : i ! = j then
(cid:2)
Order
, nodea, nodeb)
Report Dif f erence((cid:2)
end if
forall (i, j) ∈ matches do
N ODEDIF F (nodea.childi, nodeb.childj)
end for
else
end if
Report Dif f erence((cid:2)
end if
end procedure
(cid:2)
Choice
, nodea, nodeb)
380
H.J. Abdelnur, R. State, and O. Festor
Mi,j = resemblance(nodea.childi, nodeb.childj)
To ﬁnd the most adequate match, a greedy matching assignment based on the
concept of Nash Equilibrium [5] is used. Children with the biggest similarity are
bound. If a child from nodea shares the same similarity score with more than one
child from nodeb, some considerations have to be added respecting their position
in the repetitions.
Figure 4 illustrates an example match, assuming that the following matrix
was obtained using the Resemblance method with the path “Message.2.?”.
The rows in the matrix represent the children from the subtree in (a) and the
columns the children from subtree (b).
⎛
M =
⎝
⎞
⎠
.00 .00 .00
.33 .00 .00
.00 .61 .90
Fig. 4. Performed match between sub-branches of the tree
All the compared children share some common items besides the choice nodes
(colored). Those common items are Cosmetics nodes, which are required in the
message in order to be compliant with the grammar. Note that, besides the
Cosmetic ﬁelds, the ﬁrst item of the subtree (a) does not share any similarity
with any of the other nodes. It should therefore not match any other node.
Advanced Network Fingerprinting
381
4 Structural Features Extraction
4.1 Fields Classiﬁcation
One major activity that was not yet described is how non-invariant ﬁelds are
identiﬁed. The process is done by using all the messages coming from one device
and ﬁnding the diﬀerences between each two messages using Algorithm 1. For
each result, a secondary algorithm (Algorithm 2) is run in order to ﬁne tune the
extracted classiﬁcation.
Algorithm 2. Fields Classiﬁcation Algorithm
procedure FieldClassiﬁcation(dif f erencesa,b)
forall dif f ∈ dif f erencesa,b do
(cid:2)) then
V alue
(cid:2)
if dif f.type ==(cid:2)
V alue
else if dif f.type ==(cid:2)
else if dif f.type ==(cid:2)
else if dif f.type ==(cid:2)
Classif y as Dynamic((cid:2)
Classif y as Dynamic((cid:2)
Classif y as Dynamic((cid:2)
Order
if not (∀ (i, j), (x, z) ∈ dif f.matches :
(cid:2)
Length
then
(cid:2)
Length
Choice
then
then
(cid:2)
(cid:2)
, dif f.path)
Choice
, dif f.path)
, dif f.path)
(cid:2)
(i  x ∧ j > z)) then
(cid:2)Check if a permutation exists between the matched items.
Classif y as Dynamic((cid:2)
, dif f.path)
Order
(cid:2)
end if
end if
end for
end procedure
The Classify as Dynamic functions store in the global list, ﬁeldClassiﬁ-
cations, a tuple with the type of the found diﬀerence (e.g. ’Value’, ’Choice’,
’Length’ or ’Order’) and the partial path in the tree structure that represents
the node in the message.
This algorithm recognizes only the ﬁelds that are Dynamic. The set of Static
ﬁelds will be represented by the union of all the ﬁelds not recognized as Dynamic.
Assuming a training set Msg set, of messages compliant with the grammar as
M sg =
(cid:3)
n
i=0 msg seti
where n is quantity of devices and msg seti is the set of messages generated by
device i, the total number of comparisons computed in this process is
cmps1 =
n(cid:8)
|msg seti| ∗ (|msg seti| − 1)
i=0
2
(2)
382
H.J. Abdelnur, R. State, and O. Festor
4.2 Features Recognition
Some features are essential for an inter-device classiﬁcation. In contrast to the
Fields Classiﬁcation, this process compares all the messages from the training
set sourced from diﬀerent devices. All the Invariant Fields -for which diﬀerent
implementations have diﬀerent values- are identiﬁed. Algorithm 3 recognizes
these features. Its inputs are the ﬁeldClassiﬁcations computed by the Algorithm
2, the Devices Identiﬁer to which the compared message belongs as well as the
set of diﬀerences found by Algorithm 1 between the messages.
Algorithm 3. Features Recognition Algorithm
procedure featuresRecognition(f ieldClassif ications, DevIDa,b, dif f erencesa,b)
forall dif f ∈ dif f erencesa,b do
if not (dif f.type, dif f.path) ∈ f ieldClassif ications then
if dif f.type == (cid:2)
(cid:2) then
V alue
(cid:2)
, dif f.path, DevIDa,b, dif f.valuea,b)
V alue
else if dif f.type == (cid:2)
(cid:2)
Choice
(cid:2)
, dif f.path, DevIDa,b, dif f.namea,b)
Choice
else if dif f.type == (cid:2)
(cid:2)
Length
(cid:2)
, dif f.path, DevIDa,b, dif f.lengtha,b)
Length
else if dif f.type == (cid:2)
Order
addF eature((cid:2)
addF eature((cid:2)
addF eature((cid:2)
if (∃ (x, z) ∈ dif f.matches : x (cid:7)= z) then
then
(cid:2) then
then
addF eature((cid:2)
Order
(cid:2)
, dif f.path, DevIDa,b,
dif f.match, dif f.children nodesa,b)
end if
end if
end if
end for
end procedure
The add Feature function stores in a global variable, recognizedFeatures,
the partial path of the node associated with the type of diﬀerence (i.e. Value,
Name, Order or Length) and a list of devices with their encountered value.
However, the ’Order’ feature presents a more complex approach, requiring minor
improvements.
Assuming the earlier M sg set set, this process will do the following number
of comparisons:
cmps2 =
|msg seti| ∗
n(cid:8)
i=0
|msg setj|
n(cid:8)
j=i+1
(3)
From the recognizedFeatures only the Static ﬁelds are used. The recognized
features deﬁne a sequence of items, where each one represents the ﬁeld location
path in the tree representation and a list of Device ID with their associated
value.
The Recognized Features can be classiﬁed in:
Advanced Network Fingerprinting
383
– Features that were found with each device and at least two distinct values
are observed for a pair of devices,
– Features that were found in some of the devices for which such a location
path does not exists in messages from other implementations.
4.3 Fingerprinting
The classiﬁcation of a message uses the tree structure representation introduced
in section 3.1. The set of recognized features obtained in section 4 represents all
the partial paths in a tree structure that are used for the classiﬁcation process.
In some cases, the features are of type ’Value’, ’Choice’ or ’Length’. Their
corresponding value is easily obtained. However, the case of an ’Order’ represents
a more complex approach, requiring some minor improvements
Figure 5 illustrates some identiﬁed features for an incoming message.
Fig. 5. Features Identiﬁcation
Once a set of distinctive features is obtained, some well known classiﬁcation
techniques can be leveraged to implement a classiﬁer. In our work, we have
leveraged the machine learning technique described in [6].
384
H.J. Abdelnur, R. State, and O. Festor
5 Experimental Results
We have implemented the Fingerprinting Framework approach in Python. A
scannerless Generalized Left-to-right Rightmost (GLR) derivation parser has
been used (Dparser[7]) in order to solve ambiguities in the deﬁnition of the
grammar. The training function could easily be parallelized.
We have instantiated the ﬁngerprinting approach on the SIP protocol. The
SIP messages are sent in clear text (ASCII) and their structure is inspired from
HTTP. Several primitives - REGISTER, INVITE, CANCEL, BYE and OP-
TIONS - allow session management for a voice/multimedia call. Some additional
extensions do also exist -INFO, NOTIFY, REFER, PRACK- which allow the
support of presence management, customization, vendor extensions etc.
We have captured 21827 SIP messages from a real network, summarized in
Table 2.
Table 2. Tested equipment
Device
Asterisk
Cisco CallManager
Cisco 7940/7960
Grandstream Budge Tone-200 v1.1.1.14
Linksys SPA941
Thomson ST2030
Thomson ST2020
Software/Firmware version
v1.4.4
v5.1.1
vP0S3-08-7-00
vP0S3-08-8-00
SJPhone
Twinkle
Snom
Kapanga
X-Lite
Kphone
3CX
Express Talk
Linphone
Ekiga
v5.1.5
v1.52.1
v2.0.4.22
v1.60.289
v1.60.320
v1.65
v0.8.1
v0.9
v5.3
v0.98
v3.0
v4.2
v1.0
v2.02
v1.5.0
v2.0.3
The system was trained with only 12% of the 21827 messages. These messages
were randomly sampled. However, a proportion between the number of collected
messages and the number used for the training was kept; they ranged from 50 to
350 messages per device. Table 3 shows the average and total time obtained for
the comparisons of each training phase and for the message classiﬁcation process
(i.e. message ﬁngerprinting). During both Phase 1 and 2, the comparisons were
distributed over 10 computers ranging from Pentium IV to Core Duo. As it was
expected, the average comparison time per message in Phase 2 was lower than
in the previous phase, since only the invariant ﬁelds are compared. To evaluate
the training, the system classiﬁed all the sampled messages (i.e. 21927 messages)
in only in one computer (Core Duo @ 2.93GHz).
Advanced Network Fingerprinting
385
Table 3. Performance results obtained with the system
Type of Action
Average time Number of actions Total computed
per action
632 milisec
Msg. comparisons
for Phase 1
Msg. comparisons
for Phase 2
Msg. classiﬁcation 100 milisec.
592 milisec
computed
time
296616