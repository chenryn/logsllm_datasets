trace in timestamp order. Nodes are initialized using geographic
bootstrapping at the time that they ﬁrst appear in the trace. Subse-
quently, if a node is absent and then later returns, it rejoins using
the coordinates it had the last time it was in the trace. Thus our
evaluation reﬂects the churn that is present in online gaming.
During the training period, we simply feed each probe’s source
IP address, destination IP address, and RTT to the predictor. After
training ends, evaluation begins. For each session, for each of its
probes, we ask the predictor to predict the RTT from the source IP
address to the destination IP address. We evaluate these predictions,
then feed the predictor the session’s RTT measurements.
We use two main metrics to quantify the quality of a prediction.
The ﬁrst, prediction error, is the absolute difference between the ac-
tual median RTT and the prediction. This is relevant to applications,
like games, that care about absolute RTT magnitude, e.g., to decide
if a pairing meets some QoS requirement. The second, best-server
error, reﬂects the need to choose among a set of others the one with
the lowest latency, as is the approach of current matchmaking sys-
tems. It is computed on a per-session basis, as the additional RTT a
client would experience if it sought the lowest-RTT server based on
the predictor’s output instead of a perfect oracle. In best-server ex-
periments, we ignore sessions with only one probe; Table 2 shows
that this still leaves a large number of sessions for evaluation.
Given the enormous size of trace A, we did not have time to
evaluate every aspect of Htrae on it. We instead focus on trace B
for most of our evaluation, and use trace A for overall results and
evaluations of long-term properties such as convergence and drift.
4.3 Comparison to other systems
We compare Htrae to various other latency prediction systems,
including Pyxida [13], Hyperbolic Vivaldi [17], iPlane [18], and
OASIS [10]. Pyxida is the implementation of the Vivaldi algorithm,
with improvements, in the Azureus BitTorrent client. We turned off
the recent neighbor set after ﬁnding it unhelpful and after discus-
sions with an author indicating it was chieﬂy meant to deal with an
artifact of the Azureus deployment. Hyperbolic Vivaldi is an adap-
tation of Pyxida that uses hyperbolic coordinates, as described by
Lumezanu et al. [17].
iPlane uses multiple vantage points on the
Internet to create an atlas with information about every link. It uses
the atlas to predict the path and its RTT between a given pair of
nodes. OASIS’s main purpose is to select, for a given client, the
lowest-RTT server providing a given service. It uses infrastructure
nodes to periodically probe address preﬁxes and learn their geo-
graphic locations, which it then uses to estimate RTTs.
For Pyxida and Hyperbolic Vivaldi, the code and algorithms are
published, so we are able to evaluate them with trace replay. How-
ever, iPlane and OASIS are online services, so we use a different
methodology to compare to them. Since both are designed to re-
Figure 8. CDF of prediction error for Htrae, Geolocation, Pyx-
ida, and Naive on trace A. Horizontal axis limited to 150 ms.
ﬂect the current state of the Internet, we do not use historical data.
We use the last day of trace B, and query the systems on January 25,
2009, shortly after that trace was captured. To avoid overwhelming
the services, we randomly sample 0.5% of the sessions from the
last day and use only that subsample for evaluation. This subsam-
ple contains 10,869 probes in 2,648 sessions.
For illustration, we sometimes also compare to Oracle and
Naive. Oracle always predicts perfectly, i.e., it always returns the
actual RTT. Naive always guesses 85 ms, the average seen in Fig-
ure 1.
4.4 Deployment
To demonstrate the effectiveness of our Htrae implementation,
we deployed it on several friends’ home computers running Win-
dows at 23:00 PST on October 7, 2008. This deployment used an
older version of Htrae with a 3-dimensional virtual coordinate sys-
tem rather than the spherical coordinate system we later found to
be more accurate. We also used earlier versions of the MaxMind
database and Route Views BGP table. Eleven people participated
with locations in CA, IL, MA, NY, WA, and the U.K. We ran several
experiments serially, with each lasting approximately 30 minutes.
Everyone’s state reset at the start of each experiment. In each exper-
iment, every three seconds, each node calculated its RTT to another
and compared the result to what would have been predicted. It then
incorporated the RTT measurement into its predictor. For measure-
ment stability, it calculated RTT as the minimum from ten probes
sent 100 ms apart. The ﬁrst ﬁve minutes of each experiment are
considered training; we report results for only the remaining time.
5. EVALUATION
We begin our evaluation by comparing Htrae to other latency
prediction systems. We then examine in detail the impact of some
of Htrae’s components, followed by analyses of convergence, drift,
and a hybrid of probing and prediction. Finally, we summarize re-
sults from our modest deployment.
5.1 Htrae
Figure 8 shows the prediction error of Htrae on the month-long
trace A, comparing it to Pyxida, Geolocation, and Naive. We see
that Htrae substantially outperforms all other three. For 50% of
predictions, Htrae is off by under 15 ms, compared to 24 ms, 44 ms,
and 47 ms for Geolocation, Pyxida, and Naive respectively. At the
95th percentile, Htrae is at 138 ms, while Geolocation is at 208 ms,
Pyxida at 244 ms, and Naive at 285 ms. Figure 9 shows the results
from the week-long trace B, and as expected, they are similar.
01020304050607080901000102030405060708090100110120130140150cumulative % of predictionserror (ms)htraegeolocationpyxidanaïve319Figure 9. CDF of prediction error for Htrae, Geolocation, Pyx-
ida, and Naive on trace B
Figure 12. CDF of best-server error for Htrae, Geolocation,
Pyxida, and Naive in trace B
Figure 10. Estimates versus guesses in trace B. To avoid over-
loading the iPlane and OASIS services, a random subset of the
trace was considered.
Figure 13. CDF of best-server error for various systems, where
a system lacking coverage of a node pair is forced to guess.
the time, respectively. The rest of the time, when Htrae does not
pick the best server, it picks one that is still very close: the 95th
percentile of additional latency beyond optimal is only 46 ms. Ge-
olocation’s 95th percentile is much higher, at 107 ms, and Pyxida
and Naive are at 183 ms and 204 ms. Performance at the 95th per-
centile is important since players often judge games based on the
most memorably bad experience they have, or have heard about. A
penalty of up to 107 ms due to poor estimation is likely unaccept-
able for many online games. We now compare Htrae’s perfor-
mance to two online latency prediction systems, OASIS and iPlane,
which we query directly.
First, we ﬁnd that the coverage of Halo 3 players by these ser-
vices is quite low. OASIS produces estimates for only 22% of our
requests, while iPlane does 23%. For the remaining requests to
iPlane or OASIS, we use a guess, which is the median latency it
produced for all other probes: 9 ms for OASIS and 81 ms for iPlane.
In Figure 13, we see that these systems do only slightly better than
Pyxida, but much worse than Htrae. The main reason OASIS and
iPlane do poorly here is their lack of information for most pairs.
To go beyond the coverage issue, we now consider a different
approach. When comparing to OASIS, we discard any probe where
OASIS has no prediction, and similarly for iPlane. This gives them
a sizable advantage in that each gets to restrict the experiment to
the portion of the Internet it has modeled. Figure 14 presents the
results of the best-server comparison for OASIS. Despite only con-
sidering node pairs when OASIS has a prediction, Htrae still does a
better job. OASIS targets services that are in hosted environments
unlike home machines, and thus may not need to model last-mile
latencies. Our trace that Htrae trains on has end-to-end RTTs, and
hence it is able to model end nodes more accurately, which OASIS
was not designed to do. Finally, one of OASIS’s authors has in-
dicated to us that it uses stale geography information, since active
collection stopped a while ago due to various difﬁculties. The dif-
ﬁculty of keeping such geolocation information up-to-date further
Figure 11. CDF of best-server error for Htrae, Geolocation,
Pyxida and Naive in trace A
We also considered how often the errors were underestimates
or overestimates, but for space reasons we only present the follow-
ing summary of the results. For all predictors, the signiﬁcant error
is due to underestimation rather than overestimation: none of the
predictors overestimates by more than 85 ms more than 1% of the
time. Also, Htrae and Geolocation overestimate about as often as
they underestimate, while Pyxida and Naive usually underestimate:
80% and 76% of the time, respectively.
One explanation for a predictor’s good or bad performance is
the frequency with which it has no knowledge or 100% uncertainty
about one or both endpoints. In these cases, its best option is to
simply guess the average of 85 ms. Figure 10 shows how often each
predictor must guess. Pyxida guesses for 41% of the 14,810,694
post-training probes in trace B. In contrast, Geolocation guesses
only 4% of the time while Htrae guesses less than 1% of the time.
In Figures 11 and 12, we show the best-server results for traces
A and B. Htrae picks the best server over 70% of the time, while
Geolocation, Pyxida, and Naive do so only 61%, 35%, and 31% of
01020304050607080901000102030405060708090100110120130140150cumulative % of predictionserror (ms)htraegeolocationpyxidanaïve0%20%40%60%80%100%naïveoasisiplanepyxidageolocationhtrae -(sym,AS,TIV,history)htraeestimatesguesses01020304050607080901000102030405060708090100110120130140150cumulative % of predictionserror (ms)htraegeolocationpyxidanaïve01020304050607080901000102030405060708090100110120130140150cumulative % of predictionserror (ms)htraegeolocationpyxidanaïve01020304050607080901000102030405060708090100110120130140150cumulative % of predictionserror (ms)HtraeiPlaneOASISPyxida320Figure 14. CDF of best-server error for various systems, con-
sidering only client/server pairs OASIS makes a prediction for.
Figure 17. CDF of prediction error on trace B for Htrae; Htrae
without symmetric updates; Htrae without symmetric updates,
AS corrections, TIV avoidance, or history; Pyxida; Vivaldi with
hyperbolic coordinates; and Vivaldi with spherical coordinates.
Note the zoomed-in axes.
Figure 15. CDF of best-server error for various systems, con-
sidering only client/server pairs iPlane makes a prediction for.
Figure 18. CDF of best-server error for Htrae; Htrae without
symmetric updates; Htrae without symmetric updates, AS cor-
rections, TIV avoidance, or history; Pyxida; and Vivaldi with
spherical coordinates. The latter two lines overlap.
Figure 16. CDF of prediction error for various systems, consid-
ering only RTTs iPlane makes a prediction for.
demonstrates the need for the dynamic component of Htrae, which
can deal with geolocation inaccuracy.
In Figure 15, Htrae performs better than iPlane in picking the
best server, even when restricted to those that iPlane can pre-
dict. Figure 16 has the results for a prediction-error comparison
to iPlane, and Htrae does better here as well. We note that iPlane
probes only one representative out of a cluster of nodes, while our
traces have end-to-end measurements. This additional ﬁdelity in
Htrae’s training likely accounts for some of its advantage.
5.2 Components of Htrae
To understand where the improvements in Htrae come from, we
consider Figure 17, where we show how prediction error changes
as various components of Htrae are removed. Comparing Htrae
to Htrae without symmetric updates, we see that symmetric up-
dates provide a 3 ms prediction advantage at the 50th percentile
that grows to 37 ms at the 95th percentile. Considering the effect
of removing TIV avoidance, AS corrections, and history we ﬁnd
that those three elements combined provide a small additional im-
provement. This is as expected since TIVs, intra-AS probes, and
repeat probing are all relatively rare; when we look at only intra-
AS probes (not shown for space reasons), AS correction improves
latency prediction by several milliseconds. Finally, removing geo-
graphic bootstrapping to yield the basic Pyxida algorithm, we see
a large drop, showing that the majority of Htrae’s performance ad-
vantage comes from this bootstrapping. In particular, it is clearly
not due to the use of spherical coordinates, since we ﬁnd Vivaldi
does badly when modiﬁed to use them. We conclude that spherical
coordinates are only helpful due to the use of geographic bootstrap-
ping. Additionally, Vivaldi with hyperbolic coordinates performs
only marginally better than Vivaldi with spherical coordinates.
Figure 18 shows the error for best-server prediction. We again
see that geographic bootstrapping provides a major advantage, fol-
lowed by symmetric updates.
In an earlier trace from March 2008, we found that history pri-
oritization provided near-perfect prediction for 10% of predictions,
producing substantial improvement in both prediction error and
best-server error. However, in trace B, the occurrence of repeated
probes between pairs of nodes is extremely rare. We suspect this is
due to changes in player behavior as the game has matured.
5.3 Convergence
An important issue for a latency prediction system is how long
it takes to converge, i.e., reach its optimal operation point. An NCS,
in particular, can take a long time to converge as it adapts from its
initial positions to positions that reﬂect latency observations. Note
that in some contexts, NCS convergence indicates how long it takes
to reach an embedding with zero error, but since TIVs make a per-
01020304050607080901000102030405060708090100110120130140150cumulative % of predictionserror (ms)HtraeOASISPyxida01020304050607080901000102030405060708090100110120130140150cumulative % of predictionserror (ms)HtraeiPlanePyxida01020304050607080901000102030405060708090100110120130140150cumulative % of predictionserror (ms)HtraeiPlanePyxida5055606570751520253035404550556065cumulative % of predictionserror (ms)htraehtrae -(sym)htrae -(sym,AS,TIV,history)pyxidavivaldi (hyperbolic coords)vivaldi (spherical coords)01020304050607080901000102030405060708090100110120130140150cumulative % of predictionserror (ms)htraehtrae -(sym)htrae -(sym,AS,TIV,history)pyxidavivaldi (spherical coords)321Figure 19. 75th/90th quantile of prediction error seen within a
day as a function of number of days running.
Figure 21. Average prediction error per day for Htrae when
one of the involved machines is a new arrival.
Figure 20. Average per-machine coordinate movement, among
those whose coordinates changed, as a function of number of
days running.
fect embedding impossible this target is only possible in artiﬁcially
constructed networks. In this subsection, we compare the conver-
gence of Htrae on our game-machine trace to that of Pyxida.
One way to measure convergence is as the time when the error
rate reaches its steady state [6]. Thus, we measure, on each day, the
75th and 90th quantiles among all prediction errors occurring that
day. Note that all our evaluations include realistic churn as seen in
the trace. We turn off history prioritization in Htrae since we are
interested in the convergence of the coordinate system. Figure 19
shows the results. Note that there is some variation by day just
because of the nature of the data set, which one can see from the
variation in stateless geolocation. Pyxida takes about 2–3 days to
converge to its steady-state error levels, while Htrae converges es-
sentially immediately. Since Htrae, unlike Pyxida, initializes virtual
coordinates using reasonable albeit incomplete information, we get
much faster convergence across the full set of machines.
Another way to measure convergence is as the time when the
rate of coordinate shifting reaches its steady state. Thus, now we
measure, on each day, the average per-machine coordinate move-