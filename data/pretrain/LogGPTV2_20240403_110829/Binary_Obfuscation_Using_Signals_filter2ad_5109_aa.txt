title:Binary Obfuscation Using Signals
author:Igor V. Popov and
Saumya K. Debray and
Gregory R. Andrews
Binary Obfuscation Using Signals∗
Department of Computer Science, The University of Arizona, Tucson, AZ 85721, USA
Igor V. Popov, Saumya K. Debray, Gregory R. Andrews
Email: {ipopov, debray, greg}@cs.arizona.edu
Abstract
Reverse engineering of software is the process of recov-
ering higher-level structure and meaning from a lower-
level program representation.
It can be used for legit-
imate purposes—e.g., to recover source code that has
been lost—but it is often used for nefarious purposes,
e.g., to search for security vulnerabilities in binaries or to
steal intellectual property. This paper addresses the prob-
lem of making it hard to reverse engineering binary pro-
grams by making it difﬁcult to disassemble machine code
statically. Binaries are obfuscated by changing many
control transfers into signals (traps) and inserting dummy
control transfers and “junk” instructions after the signals.
The resulting code is still a correct program, but even
the best current disassemblers are unable to disassemble
40%–60% of the instructions in the program. Further-
more, the disassemblers have a mistaken understanding
of over half of the control ﬂow edges. However, the ob-
fuscated program necessarily executes more slowly than
the original. Experimental results quantify the degree of
obfuscation, stealth of the code, and effects on execution
time and code size.
1 Introduction
Software is often distributed in binary form, without
source code. Many groups have developed technology
that enables one to reverse engineer binary programs
and thereby reconstruct the actions and structure of the
program. This is accomplished by disassembling ma-
chine code into assembly code and then possibly de-
compiling the assembly code into higher level repre-
sentations [5, 6, 13]. While reverse-engineering tech-
nology has many legitimate uses (in particular, an im-
portant application of binary-level reverse engineering
is to analyse malware in order to understand its behav-
ior [4, 16–18, 25, 27, 33]), it can also be used to dis-
cover vulnerabilities, make unauthorized modiﬁcations,
or steal intellectual property.
∗
This work was supported in part by NSF Grants EIA-0080123,
CCR-0113633, and CNS-0410918.
Since the ﬁrst step in reverse engineering a binary
is disassembly, many approaches to binary obfuscation
focus on disrupting this step. This is typically done
by identifying assumptions made by disassemblers, then
transforming the program systematically so as to violate
these assumptions without altering program functional-
ity. Two fundamental assumptions made by disassem-
blers are that (1) the address where each instruction be-
gins can be determined; and (2) control transfer instruc-
tions can be identiﬁed and their targets determined. The
ﬁrst assumption is used to identify the actual instructions
to disassemble; most modern disassemblers use the sec-
ond assumption to determine which memory regions get
disassembled (see Section 2). In this context, this paper
makes the following contributions:
1. It shows how the second of these assumptions can
be violated, such that actual control transfers in the
program cannot be identiﬁed by a static disassem-
bler. This is done by replacing control transfer
instructions—jumps, calls, and returns—by “ordi-
nary” instructions whose execution raises traps at
runtime; these traps are then ﬁelded by signal han-
dling code that carries out the appropriate control
transfer. The effect is to replace control transfer
instructions either with apparently innocuous arith-
metic or memory operations or with what appear to
be illegal instructions that suggest an erroneous dis-
assembly.
2. It shows how the code resulting from this ﬁrst trans-
formation can be further obfuscated to additionally
violate the ﬁrst assumption stated above. This is
done using a secondary transformation that inserts
(unreachable) code, containing fake control trans-
fers, after these trap-raising instructions, in order to
make it hard to ﬁnd the beginning of the true next
instructions.
In earlier work, we showed how disassembly could be
disrupted by violating the ﬁrst assumption [20]; this pa-
per extends that work by showing a different way to ob-
fuscate binaries by replacing control transfer instructions
USENIX Association
16th USENIX Security Symposium
275
with apparently-innocuous non-control-transfer instruc-
tions. It is also very different from our earlier work on
intrusion detection [21], which proposed a way to hinder
certain kinds of mimicry attacks by obfuscating system
call instructions. That work sought simply to disguise the
instruction (‘int$0x80’ in Intel x86 processors) used by
applications to trap into the OS kernel; more importantly,
it required kernel modiﬁcations in order to to work. By
contrast, the work described in this paper applies to arbi-
trary control transfers in programs and requires no kernel
modiﬁcations. Taken together, these two differences lead
to signiﬁcant differences between the two approaches in
terms of goals, techniques, and effects.
It is important to note that code obfuscation is merely
a technique: just as it can be used to protect software
against attackers, so too it can be used to hide malicious
content. The work presented here can therefore be seen
from two perspectives: as a “defense model” of a new
approach for protecting intellectual property, or as an
“attack model” of a new approach for hiding malicious
content. In either case, it goes well beyond current ap-
proaches to hiding the content of executable code.
In
particular, the obfuscations cause the best existing dis-
assemblers to miss 40%–60% of the instructions in test
programs and to make mistakes on over half of the con-
trol ﬂow edges.
The remainder of the paper is organized as follows.
Section 2 provides background information on static dis-
assembly algorithms. Section 3 describes the new tech-
niques for thwarting disassembly and explains how they
are implemented. Section 4 describes how we evaluate
the efﬁcacy of our approach. Section 5 gives experimen-
tal results for programs in the SPECint-2000 benchmark
suite. Section 6 describes related work, and Section 7
contains concluding remarks.
2 Disassembly Algorithms
This section summarizes the operation of disassemblers
in order to provide the context needed to understand
how our obfuscation techniques work. Broadly speak-
ing, there are two approaches to disassembly: static and
dynamic, the difference between them being that the for-
mer examines the program without execution, while the
latter monitors the program’s execution (e.g., through a
debugger) as part of the disassembly process. Static dis-
assembly processes the entire input program all at once,
while dynamic disassembly only disassembles those in-
structions that were executed for the particular input that
was used. Moreover, with static disassembly it is eas-
ier to apply ofﬂine program analyses to reason about
semantic aspects of the program under consideration.
Finally, programs being disassembled statically are not
able to defend themselves against reverse engineering us-
ing anti-debugging techniques (see, for example, [2, 3]).
For these reasons, static disassembly is a popular choice
for low level reverse engineering. This paper focuses on
static disassembly: its goal is to render static disassem-
bly of programs sufﬁciently difﬁcult and expensive as to
force attackers to resort to dynamic approaches (which,
in principle, can then be defended against).
There are two generally used techniques for static dis-
assembly: linear sweep and recursive traversal [26]. The
linear sweep algorithm begins disassembly at the input
program’s ﬁrst executable location, and simply sweeps
through the entire text section disassembling each in-
struction as it is encountered. This method is used by
programs such as the GNU utility objdump [24] as well
as a number of link-time optimization tools [8, 23, 29].
The main weakness of linear sweep is that it is prone to
disassembly errors resulting from the misinterpretation
of data, such as jump tables, embedded in the instruction
stream.
The recursive traversal algorithm uses the control ﬂow
instructions of the program being disassembled in or-
der to determine what to disassemble.
It starts with
the program’s entry point, and disassembles the ﬁrst ba-
sic block. When the algorithm encounters a control
ﬂow instruction, it determines the possible successors of
that instruction—i.e., addresses where execution could
continue—and proceeds with disassembly at those ad-
dresses. Variations on this basic approach to disassem-
bly are used by a number of binary translation and opti-
mization systems [6, 28, 30]. The main virtue of recur-
sive traversal is that by following the control ﬂow of a
program, it is able to “go around” and thus avoid disas-
sembly of data embedded in the text section. Its main
weakness is that it depends on being able to determine
the possible successors of each such instruction, which
is difﬁcult for indirect jumps and calls. The algorithm
also depends on being able to ﬁnd all the instructions
that affect control ﬂow.
A recently proposed generalization of recursive traver-
sal is that of exhaustive disassembly [14,15], which is the
most sophisticated disassembly algorithm we are aware
of. This approach aims to work around certain kinds
of binary obfuscations by considering all possible disas-
semblies of each function. It examines the control trans-
fer instructions in these alternative disassemblies to iden-
tify basic block boundaries, then uses a variety of heuris-
tic and statistical reasoning to rule out alternatives that
are unlikely or impossible. Like the recursive traversal
algorithm it generalizes, the exhaustive algorithm thus
also relies fundamentally on identifying and analyzing
the behavior of control transfer instructions.
276
16th USENIX Security Symposium
USENIX Association
3 Signal-Based Obfuscation
3.1 Overview
In order to confuse a disassembler, we have to disrupt its
notion of where the instructions are, what they are doing,
and what the control ﬂow is. The choices we have for al-
tering the program are (1) changing instructions to others
that produce the same result, and (2) adding instructions
that do not have visible effects. Simple, local changes
will obviously not confuse a disassembler or a human.
More global and drastic changes are required.
The essential intuition of our approach can be illus-
trated via a simple example, given in Figure 1. The origi-
nal code fragment on the left-hand side of the ﬁgure con-
tains an unconditional jump to a location L; the jump
is preceded by Code-before and followed by Code-after.
This code is obfuscated by replacing the jump by code
that attempts to access an illegal memory location ` and
thereby generates a trap, which raises a signal. This is
ﬁelded by a handler that uses the address of the instruc-
tion that caused the trap to determine the target address
L of the original jump instruction and to cause control to
branch to L. In addition, Bogus Code is inserted after the
trap point; this code appears to be reachable, but in fact it
is not. Judicious choice of bogus code can throw off the
disassembly even further.
This example illustrates a number of key aspects of
our approach that increases the difﬁculty of statically de-
obfuscating programs:
– A variety of different instructions and addresses can
be used to raise a signal at runtime. The example
uses a load from an illegal address, but we could
have used many other alternatives, e.g., a store to
a write-protected location, or a load from a read-
protected location. Indeed, on an architecture such
as the Intel x86, any instruction that can take a mem-
ory operand, including all the familiar arithmetic in-
structions, can be used for this purpose. Moreover,
the address ` used to generate the trap can be a legal
address, albeit one that does not (at runtime) permit
a particular kind of memory access. We can further
hamper static reverse engineering by using some-
thing like an mprotect() system call to (possibly
temporarily) change the protection of the address `
being used to generate the trap at runtime, so that it
is not statically obvious that attempting a particular
kind of memory access at address ` will raise a trap.
– The address ` used to generate the trap need not be
a determinate value. For example, suppose that, as
in typical 32-bit Linux systems, the top 1 GB of the
virtual address space (i.e., addresses 0xC0000000
to 0xFFFFFFFF) is reserved for the kernel, and is
inaccessible to user processes. Then, any value of `
in that address range will serve to generate the de-
sired trap. Such values can be computed by starting
with an arbitrary value and then using bit manipu-
lations to obtain a value in the appropriate range, as
shown below (one can imagine many variations on
this theme), where A and B are arbitrary legal mem-
ory locations:
0 := contents of A
r
1 := contents of B
r
1 := r
r
1
r
1 := r
1
0 := r
r
0
| 0xC0 /* r
1
<< 24
/* r
1
| r
1
’s low byte ≥ 0xC0 */
≥ 0xC0000000 */
The actual runtime contents of memory locations
A and B are unimportant here: the value computed
into r
0—which may be different on different execu-
tions of this code—will nevertheless always point
into protected kernel address space, causing mem-
ory accesses through r
0 to generate a trap. Such
indeterminacy can further complicate the task of re-
verse engineering the obfuscated code. Note that
such indeterminate address computations can also
be applied to generate an arbitrary address within a
page (or pages) protected using mprotect() as
discussed above.
– A variety of different traps can be used. For exam-
ple, in addition to the memory access traps men-
tioned above, we can use arithmetic exceptions,
e.g., divide-by-zero. In fact, the “instruction” gen-
erating a trap need not be a legal instruction at all—
i.e., we can use a byte pattern that does not cor-
respond to any legal instruction to effect a control
transfer via an illegal instruction trap. Such ille-
gal byte sequences—which in general are indistin-
guishable from data legitimately embedded in the
instruction stream—can be very effective in confus-
ing disassemblers.
– The location following the trap-generating instruc-
tion is unreachable, but this is not evident from
standard control ﬂow analyses. We can exploit this
by inserting additional “bogus” code after the trap-
generating instruction to further confuse disassem-
bly. Section 3.2 discusses this in more detail.
We could conceivably obfuscate every jump, call, or
return in the source code. However, this would cause the
program to execute much more slowly because of signal-
processing overhead. We allow the user to specify a hot-
code threshold, and we only obfuscate control transfers
that are not in hot parts of the original program (see Sec-
tion 5 for details). Even so, we are able to obfuscate
about a third of the instructions in hot code blocks.
USENIX Association
16th USENIX Security Symposium
277
Code-before
jmp L
Code-after
=⇒
obfuscation
. . .
L:
. . .
Code-before
r :=(cid:26) compute a value `
r := load *r
Bogus Code
Code-after
/* ` is an illegal address */
/* trap – Segmentation fault */
/* unreachable */
. . .
L:
. . .
Figure 1: A Simple Example of our Approach to Obfuscation
Before obfuscating a program, we ﬁrst instrument the
program to gather edge proﬁles, and then we run the
instrumented version on a training input. The obfusca-
tion process itself has several steps. First, using the pro-
ﬁle data and hot-cold threshold, determine which con-
trol transfers should be obfuscated and modify each such
instruction as shown in Figure 1. Second, insert bogus
code at unreachable code locations such as after trap-
generating instructions. Third, intersperse signal han-
dling and restore (return from signal) code with the orig-
inal program code. Fourth, compute the new memory
layout, construct a table of mappings from trap instruc-
tions to target addresses, and patch the restore code to use
this table via a perfect hash function. Finally, assemble a
new, obfuscated binary.
3.2 Program Obfuscations
Within our obfuscator, the original program is repre-
sented as an interprocedural control-ﬂow graph (ICFG).
The nodes are basic blocks of machine instructions; the
edges represent the control ﬂow in the program.
Obfuscating Control Transfers
After some initialization actions, our obfuscator makes
one pass through the original program to ﬂip conditional
branches—i.e., reverse the sense of the branch condi-
tion and insert an explicit unconditional jump after it to
maintain the program’s semantics. This transformation
has the effect of increasing the set of candidate locations
where our obfuscation can be applied. Our obfuscator
then makes a second pass through the program to ﬁnd
and modify all control transfer instructions that are to be
obfuscated.
To obfuscate a control transfer instruction, we insert
Setup code that prepares for raising a signal and then
Trap code that causes a signal. The Setup code (1) al-
locates space on the stack for use by the signal handler
to store the address of the trap instruction, and (2) sets
a ﬂag that indicate to the signal handler that the com-
ing signal is from obfuscated code, not the original pro-
gram itself. To set a ﬂag, we use a pre-allocated array
(initialized to zero), and the Setup code moves a random
non-zero value into a randomly chosen element of the ar-
ray. Jump, return, and call instructions are obfuscated in
nearly identical ways; the only essential difference is the
amount of stack space that we need to allocate in order to
effect the intended control transfer. The Trap code gen-
erates a trap, which in turn raises a signal. In order not
to interfere with signal handlers that might be installed
in the original program, we only raise signals for which
the default action is to dump core and terminate the pro-
gram. In particular we use illegal instruction (SIGILL),
ﬂoating point exception (SIGFPE), and segmentation vi-
olation (SIGSEGV).
To determine which kind of trap to raise—and to avoid
the need to save and later restore program registers—we
ﬁrst do liveness analysis to determine which registers are
live at the trap point and which are available for us to
use. If no register is available, we randomly generate an
illegal instruction from among several possible choices.
Otherwise, we generate code to load a zero into a free
register r, then either dereference r (to cause a segmen-
tation fault), or divide by r (to cause a ﬂoating point ex-
ception). Since indirect loads are far more frequent than
divides in real programs, most of the time we choose the
former.
If we simply moved a zero into a register each time
that we wanted to trigger a ﬂoating point exception or
segmentation fault, there would be dozens of such in-
structions that would be a signature for our obfuscation.
To avoid this, we generate a sequence of instructions by
using multiple, randomly chosen rewriting rules that per-
form value-preserving transformations on the registers
that are free at each obfuscation point. Appendix A de-
scribes how we randomize the computation of values.
Inserting Bogus Code