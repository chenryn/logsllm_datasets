title:Taking the Edge off with Espresso: Scale, Reliability and Programmability
for Global Internet Peering
author:Kok-Kiong Yap and
Murtaza Motiwala and
Jeremy Rahe and
Steve Padgett and
Matthew J. Holliman and
Gary Baldus and
Marcus Hines and
Taeeun Kim and
Ashok Narayanan and
Ankur Jain and
Victor Lin and
Colin Rice and
Brian Rogan and
Arjun Singh and
Bert Tanaka and
Manish Verma and
Puneet Sood and
Muhammad Mukarram Bin Tariq and
Matt Tierney and
Dzevad Trumic and
Vytautas Valancius and
Calvin Ying and
Mahesh Kallahalla and
Bikash Koley and
Amin Vahdat
Taking the Edge off with Espresso: Scale, Reliability and
Programmability for Global Internet Peering
Steve Padgett Matthew Holliman
Kok-Kiong Yap Murtaza Motiwala
Taeeun Kim Ashok Narayanan Ankur Jain Victor Lin
Gary Baldus Marcus Hines
Colin Rice
Puneet Sood
Mukarram Tariq Matt Tierney Dzevad Trumic Vytautas Valancius Calvin Ying
Bert Tanaka Manish Verma
Brian Rogan Arjun Singh
Jeremy Rahe
Mahesh Kallahalla
Bikash Koley Amin Vahdat
Google
PI:EMAIL
ABSTRACT
We present the design of Espresso, Google’s SDN-based Internet
peering edge routing infrastructure. This architecture grew out of a
need to exponentially scale the Internet edge cost-effectively and to
enable application-aware routing at Internet-peering scale. Espresso
utilizes commodity switches and host-based routing/packet process-
ing to implement a novel fine-grained traffic engineering capability.
Overall, Espresso provides Google a scalable peering edge that is
programmable, reliable, and integrated with global traffic systems.
Espresso also greatly accelerated deployment of new networking
features at our peering edge. Espresso has been in production for
two years and serves over 22% of Google’s total traffic to the Inter-
net.
CCS CONCEPTS
• Networks → Network architectures; • Computer systems
organization → Availability;
KEYWORDS
Networking, Peering Routers, Traffic Engineering
Victor Lin
Colin Rice
Ankur Jain
Jeremy Rahe
Bert Tanaka Manish Verma
ACM Reference format:
Kok-Kiong Yap Murtaza Motiwala
Steve Padgett Matt-
hew Holliman Gary Baldus Marcus Hines Taeeun Kim Ashok Nara-
yanan
Ar-
Puneet Sood Mukarram Tariq
jun Singh
Matt Tierney Dzevad Trumic Vytautas Valancius Calvin Ying Ma-
hesh Kallahalla
Bikash Koley Amin Vahdat. 2017. Taking the Edge off
with Espresso: Scale, Reliability and Programmability for Global Internet
Peering. In Proceedings of SIGCOMM ’17, Los Angeles, CA, USA, August 21–25,
2017, 14 pages.
https://doi.org/10.1145/3098822.3098854
Brian Rogan
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
SIGCOMM ’17, August 21–25, 2017, Los Angeles, CA, USA
© 2017 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-4653-5/17/08.
https://doi.org/10.1145/3098822.3098854
432
1 INTRODUCTION
The Internet’s peering edge plays a critical and growing role in
the architecture of large-scale content providers, driven by High-
Definition Video and Cloud Computing. The largest peering edges
deliver Terabits/sec of Internet traffic and megawatts of com-
pute/storage. While most of the computing and storage for content
providers runs in data centers, the edge supports: i) peering with
partner autonomous systems, ii) a server pool of reverse proxies for
TCP termination, and iii) caching and content distribution of static
content. A properly designed edge architecture supports interactive
low latency to a global user population, is the first and most impor-
tant line of defense against DoS and related attacks, and reduces
the buildout of the backbone network back to centrally-located
data centers.
The dominant component of an edge architecture is Internet-
scale routers. These routers are hardware and software engineering
marvels, with at least three critical pieces of functionality. First, the
router must scale to hundreds of ports with the highest bandwidth
density and packet per second processing rates in each genera-
tion. The management and configuration complexity of Internet
routers is substantial, so our tendency has been to favor scale up
with as few, large routers as possible. Second, the router must sup-
port Internet-scale forwarding tables with potentially hundreds of
thousands of individual entries down to /24 subnets in the case of
IPv4 for global Internet-scale routing. Third, on the incoming path,
routers must support complex and large-scale access control lists to
support firewall rules and protect against DoS attacks. Otherwise
specialized firewalls have to be deployed in peering locations, con-
suming limited space and power. Finally, the router must support
high-end compute for BGP software that can manage hundreds of
sessions with remote peers.
In our experience running the network for one of the largest
global content providers, the flexibility, availability, and cost effi-
ciency of the peering edge was increasingly limited by these Inter-
net routers. Most critically, we could not introduce new functional-
ity leveraging a global view of traffic or cross-layer optimizations.
For example, we measure, in real time, the peer ports most likely
to deliver high-bandwidth/low-latency connectivity from our edge
by measuring across millions of individual users. Overriding BGP-
specified forwarding behavior at fine granularity is limiting. In
cases where it is possible, it often requires some change in the
vendor software or hardware. The simplest changes can take up
to a year to qualify, while more complex changes require either
SIGCOMM ’17, August 21–25, 2017, Los Angeles, CA, USA
K.K. Yap, M. Motiwala, et al.
standardization efforts or new versions of switch silicon. Further,
the scale up nature of high-end Internet routers means that any
upgrade or failure, however rare, would affect a substantial fraction
of our traffic. Finally, the cost per port of Internet routers dominated
our edge costs, typically 4 − 10× relative to the next tier of router
with more modest forwarding and ACL table size.
To address these challenges, we used our experience with SDN
in a different setting [21] to design and implement Espresso, a new
peering edge architecture. The key insight behind Espresso is exter-
nalizing most network control from the peering devices, and leaving
only a simple data-plane on device—specifically a commodity MPLS
switch. In particular, we move packet processing, including routing
on Internet-scale forwarding tables and ACLs, to high-performance
software packet processors running on the large-scale server in-
frastructure already present in the edge. Further, we integrate our
pre-existing global traffic engineering (TE) system into Espresso
to enable fine-grained, BGP-compliant bandwidth management
in a manner that would be difficult to implement in a distributed
environment and without an end-to-end view of per-flow perfor-
mance. Finally, we move BGP to a custom stack running on servers,
enabling finer-grained partitioning and much more computation
power than available in any Internet router.
Taken together, Espresso’s design accelerates delivery of innova-
tive networking features to our customers at a previously impos-
sible pace. Coupled with our global TE system, Espresso delivers
13% more user traffic on our infrastructure by integrating with
global application-aware TE system as compared to just BGP-based
routing, while also improving peer link utilization and end-to-end
user experience. For example, the mean time between rebuffers
(an important measure for video traffic) improves between 35% to
170%.
2 BACKGROUND AND REQUIREMENTS
Google runs two different WANs. B4 [21], our datacenter-to-datacenter
WAN supports global computation. B2 [5] provides connectivity
from our datacenters to our peering edge and eventually to end
users around the world (Figure 1). Google has one of the largest
peering surfaces in the world, exchanging data with Internet Service
Providers (ISPs) in over 70 metros.
B2 employs traditional vendor gear and decentralized routing
protocols to provide the highest levels of availability. Traditional IP
routing operates on low-level information for routing traffic, e.g.,
BGP announcements and policies. Supporting application-aware
fine-grained traffic policies therefore requires complex BGP rules
that are hard to manage, reason about [13] or even implement.
In contrast, we built B4 with internally-developed hardware,
SDN control and centralized traffic engineering, leveraging the fact
that much of our datacenter to datacenter traffic did not require
the same availability as B2. As we gained more experience with B4,
centralized traffic engineering and SDN, we were able to contin-
uously improve the availability of our SDN WAN while enjoying
the benefits of cost efficiency, fine-grained traffic management, and
high feature velocity. These capabilities formed the motivation for
Espresso: could we bring the benefits of SDN to a portion of B2
while maintaining the requisite availability and interoperability
433
Figure 1: Overview of Google WANs. Espresso runs in Peering Edge
Metros that connect to external peers and back to Data Centers via
B2. B4 is our SDN WAN that supports high volume traffic between
Data Centers.
with arbitrary external hardware and software? Doing so would
require us to meet the following requirements:
(1) Efficiency. Sustaining Google’s rapid Internet traffic growth
requires us to reduce the cost of our Internet peering edge
network at a faster rate, while simultaneously increasing
utilization of the peering ports.
(2) Interoperability. Espresso needs to interoperate with the
rest of the Internet and the peer networks, supporting all
standard Internet protocols, such as BGP and IPv4/IPv6. Pre-
vious SDN deployments [11, 21] were internal and only had
to interoperate with a controlled number of vendors and/or
software.
(3) Reliability. Espresso must carry all Google traffic to and
from users. Consequently, it must deliver better than 99.999%
global availability, or less than five minutes of downtime per
year for traffic that is routed through it. Measuring global
edge availability presents its own challenges and is beyond
the scope of this paper; here, we focus on our techniques for
maintaining availability while centralizing portions of our
network control.
(4) Incremental Deployment. For practical reasons, Espresso
must operate alongside existing traditional routing equip-
ment. Given the scale of Google’s network, it would be in-
feasible to forklift current deployments to support Espresso.
On the other hand, restricting Espresso to new edge turn
ups would limit its utility to Google.
(5) High Feature Velocity. Changing product requirements,
for example to support peering in heterogeneous Cloud de-
ployments, places a premium on rapid feature development
and qualification. Our goal is to deploy a developed feature
to production in two weeks, a process that could take up to a
year with existing practice. Our experience suggests that end
to end feature development and deployment has improved
by more than a factor of six with Espresso.
B4EspressoB2InternetPeering MetroUserJupiter Data CenterGoogleGoogleTaking the Edge off with Espresso
SIGCOMM ’17, August 21–25, 2017, Los Angeles, CA, USA
Centrally, a highly available peering edge and high feature ve-
locity are often at odds with each other. Having a highly avail-
able system often implies a more slowly-changing system because
management operations are often the cause of unavailability [16].
Trying to improve availability beyond the baseline for traditional
deployments, while increasing feature velocity, entails substantial
architectural care.
3 DESIGN PRINCIPLES
To meet our requirements, we employed several design principles
crucial to the success of Espresso. As shown in Table 1, Espresso
changes the traditional edge routing design by innovating on all
three planes: control, data and management.
(1) Espresso employs a hierarchical control plane split be-
tween local and global controllers. Local controllers apply
programming rules and application-specific traffic routing
policies that are computed by the global controller. This de-
sign is easier to reason about as compared to fully distributed
local controllers in metros peering with one another. This
approach achieves three main objectives: (i) global traffic
optimization to improve efficiency, (ii) improved reliabil-
ity as the local control plane can operate independently of
the global controller, and (iii) fast reaction to local network
events, for example on peering port or device failure the
local controller performs local repair while awaiting globally
optimized allocation from the global controller.
(2) We support fail static for high availability [16]. The data
plane maintains the last known good state so that the control
plane may be unavailable for short periods without impact-
ing packet forwarding. While we are exposed to simultane-
ous data plane failures while the control plane is unavailable,
such failures are typically small in scope, e.g., individual
peering link failure. Achieving fail static properties with
existing network hardware is challenging because of tight
coupling between the control and data plane. For example,
it is typically impossible to distinguish between a BGP stack
failure and a data plane failure. By externalizing control off
peering devices, Espresso is systematically engineered to
fail static. Different components in the control plane can
be unavailable for varying amounts of time while the data
plane and BGP peerings can continue to operate. This design
also allows us to upgrade the control plane frequently on a