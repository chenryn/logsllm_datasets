# Title: Taking the Edge off with Espresso: Scale, Reliability, and Programmability for Global Internet Peering

## Authors:
Kok-Kiong Yap, Murtaza Motiwala, Jeremy Rahe, Steve Padgett, Matthew J. Holliman, Gary Baldus, Marcus Hines, Taeeun Kim, Ashok Narayanan, Ankur Jain, Victor Lin, Colin Rice, Brian Rogan, Arjun Singh, Bert Tanaka, Manish Verma, Puneet Sood, Muhammad Mukarram Bin Tariq, Matt Tierney, Dzevad Trumic, Vytautas Valancius, Calvin Ying, Mahesh Kallahalla, Bikash Koley, Amin Vahdat

## Abstract
We present the design of Espresso, Google’s SDN-based Internet peering edge routing infrastructure. This architecture was developed to address the need for exponential scaling of the Internet edge in a cost-effective manner and to enable application-aware routing at Internet-peering scale. Espresso leverages commodity switches and host-based routing/packet processing to implement a novel fine-grained traffic engineering capability. Overall, Espresso provides Google with a scalable, programmable, and reliable peering edge that is integrated with global traffic systems. It has also significantly accelerated the deployment of new networking features at our peering edge. Espresso has been in production for two years and serves over 22% of Google’s total traffic to the Internet.

## CCS Concepts
- Networks → Network architectures
- Computer systems organization → Availability

## Keywords
Networking, Peering Routers, Traffic Engineering

## 1. Introduction
The Internet's peering edge plays a critical and growing role in the architecture of large-scale content providers, driven by high-definition video and cloud computing. The largest peering edges deliver terabits per second of Internet traffic and require megawatts of compute and storage. While most of the computing and storage for content providers runs in data centers, the edge supports:
1. Peering with partner autonomous systems.
2. A server pool of reverse proxies for TCP termination.
3. Caching and content distribution of static content.

A well-designed edge architecture supports interactive low latency for a global user population, acts as the first and most important line of defense against DoS and related attacks, and reduces the buildout of the backbone network back to centrally-located data centers.

The dominant component of an edge architecture is Internet-scale routers. These routers are hardware and software marvels, providing three critical functionalities:
1. **Scalability**: They must scale to hundreds of ports with the highest bandwidth density and packet-per-second processing rates.
2. **Forwarding Tables**: They must support Internet-scale forwarding tables with potentially hundreds of thousands of individual entries down to /24 subnets for IPv4.
3. **Access Control Lists (ACLs)**: They must support complex and large-scale ACLs to enforce firewall rules and protect against DoS attacks.
4. **BGP Management**: They must support high-end compute for BGP software to manage hundreds of sessions with remote peers.

In our experience running the network for one of the largest global content providers, the flexibility, availability, and cost efficiency of the peering edge were increasingly limited by these Internet routers. We could not introduce new functionality leveraging a global view of traffic or cross-layer optimizations. For example, real-time measurement of peer ports to deliver high-bandwidth/low-latency connectivity from our edge required overriding BGP-specified forwarding behavior, which was limiting and often required vendor-specific changes. 

To address these challenges, we designed and implemented Espresso, a new peering edge architecture. The key insight behind Espresso is externalizing most network control from the peering devices, leaving only a simple data plane on device—specifically, a commodity MPLS switch. Packet processing, including routing on Internet-scale forwarding tables and ACLs, is moved to high-performance software packet processors running on the large-scale server infrastructure already present in the edge. Additionally, we integrated our pre-existing global traffic engineering (TE) system into Espresso to enable fine-grained, BGP-compliant bandwidth management. Finally, we moved BGP to a custom stack running on servers, enabling finer-grained partitioning and more computational power than available in any Internet router.

Espresso's design accelerates the delivery of innovative networking features to our customers at an unprecedented pace. Coupled with our global TE system, Espresso delivers 13% more user traffic on our infrastructure compared to BGP-based routing alone, while also improving peer link utilization and end-to-end user experience. For example, the mean time between rebuffers (an important measure for video traffic) improves by 35% to 170%.

## 2. Background and Requirements
Google operates two different WANs: B4, which supports global computation between data centers, and B2, which provides connectivity from our data centers to our peering edge and eventually to end users around the world. Google has one of the largest peering surfaces, exchanging data with ISPs in over 70 metros.

B2 employs traditional vendor gear and decentralized routing protocols to provide the highest levels of availability. Traditional IP routing operates on low-level information, making it difficult to support application-aware fine-grained traffic policies without complex BGP rules.

In contrast, B4 was built with internally-developed hardware, SDN control, and centralized traffic engineering, leveraging the fact that much of our data center-to-data center traffic did not require the same availability as B2. As we gained more experience with B4, we continuously improved the availability of our SDN WAN while enjoying the benefits of cost efficiency, fine-grained traffic management, and high feature velocity. These capabilities motivated the development of Espresso: could we bring the benefits of SDN to a portion of B2 while maintaining the requisite availability and interoperability with arbitrary external hardware and software?

To achieve this, Espresso had to meet the following requirements:
1. **Efficiency**: Reduce the cost of our Internet peering edge network while increasing the utilization of peering ports.
2. **Interoperability**: Support all standard Internet protocols, such as BGP and IPv4/IPv6.
3. **Reliability**: Deliver better than 99.999% global availability, or less than five minutes of downtime per year.
4. **Incremental Deployment**: Operate alongside existing traditional routing equipment.
5. **High Feature Velocity**: Deploy new features to production in two weeks, a process that could take up to a year with existing practices.

## 3. Design Principles
To meet these requirements, we employed several design principles crucial to the success of Espresso. As shown in Table 1, Espresso innovates on all three planes: control, data, and management.

1. **Hierarchical Control Plane**: Espresso employs a hierarchical control plane split between local and global controllers. Local controllers apply programming rules and application-specific traffic routing policies computed by the global controller. This design achieves:
   - **Global Traffic Optimization**: Improves efficiency.
   - **Improved Reliability**: The local control plane can operate independently of the global controller.
   - **Fast Reaction to Local Events**: Local controllers can perform local repairs while awaiting globally optimized allocations from the global controller.

2. **Fail Static for High Availability**: The data plane maintains the last known good state so that the control plane may be unavailable for short periods without impacting packet forwarding. This design allows us to upgrade the control plane frequently without affecting the data plane and BGP peerings.

By externalizing control off peering devices, Espresso is systematically engineered to fail static. Different components in the control plane can be unavailable for varying amounts of time while the data plane and BGP peerings continue to operate.