waiting for statefulset rolling update to complete 1 pods at revision
web-56b5798f76...
Waiting for 1 pods to be ready...
Waiting for 1 pods to be ready...
waiting for statefulset rolling update to complete 2 pods at revision
web-56b5798f76...
Waiting for 1 pods to be ready...
Waiting for 1 pods to be ready...
statefulset rolling update complete 3 pods at revision web-56b5798f76...
查看更新后的镜像：
[root@K8S-master01 2.2.7]# for p in 0 1 2; do kubectl get po web-$p --template
'{{range $i, $c := .spec.containers}}{{$c.image}}{{end}}'; echo; done
dotbalo/canary:v1
dotbalo/canary:v1
dotbalo/canary:v1
（3）分段更新
StatefulSet可以使用RollingUpdate更新策略的partition参数来分段更新一个StatefulSet。分段
更新将会使StatefulSet中其余的所有Pod（序号小于分区）保持当前版本，只更新序号大于等于分
区的Pod，利用此特性可以简单实现金丝雀发布（灰度发布）或者分阶段推出新功能等。注：金丝
雀发布是指在黑与白之间能够平滑过渡的一种发布方式。
比如我们定义一个分区"partition":3，可以使用patch直接对StatefulSet进行设置：
# kubectl patch statefulset web -p
86 | 再也不踩坑的Kubernetes实战指南
'{"spec":{"updateStrategy":{"type":"RollingUpdate","rollingUpdate":{"partition
":3}}}}'
statefulset "web" patched
然后再次patch改变容器的镜像：
# kubectl patch statefulset web --type='json' -p='[{"op": "replace", "path":
"/spec/template/spec/containers/0/image",
"value":"K8S.gcr.io/nginx-slim:0.7"}]'
statefulset "web" patched
删除Pod触发更新：
kubectl delete po web-2
pod "web-2" deleted
此时，因为Podweb-2的序号小于分区3，所以Pod不会被更新，还是会使用以前的容器恢复
Pod。
将分区改为2，此时会自动更新web-2（因为之前更改了更新策略），但是不会更新web-0和
web-1：
# kubectl patch statefulset web -p
'{"spec":{"updateStrategy":{"type":"RollingUpdate","rollingUpdate":{"partition
":2}}}}'
statefulset "web" patched
按照上述方式，可以实现分阶段更新，类似于灰度/金丝雀发布。查看最终的结果如下：
[root@K8S-master01 2.2.7]# for p in 0 1 2; do kubectl get po web-$p --template
'{{range $i, $c := .spec.containers}}{{$c.image}}{{end}}'; echo; done
dotbalo/canary:v1
dotbalo/canary:v1
dotbalo/canary:v2
9. 删除StatefulSet
删除StatefulSet有两种方式，即级联删除和非级联删除。使用非级联方式删除StatefulSet时，
StatefulSet的Pod不会被删除；使用级联删除时，StatefulSet和它的Pod都会被删除。
（1）非级联删除
使用kubectldeletestsxxx删除StatefulSet时，只需提供--cascade=false参数，就会采用非级联删
除，此时删除StatefulSet不会删除它的Pod：
[root@K8S-master01 2.2.7]# kubectl get po
NAME READY STATUS RESTARTS AGE
web-0 1/1 Running 0 16m
web-1 1/1 Running 0 16m
web-2 1/1 Running 0 11m
You have new mail in /var/spool/mail/root
[root@K8S-master01 2.2.7]# kubectl delete statefulset web --cascade=false
statefulset.apps "web" deleted
[root@K8S-master01 2.2.7]# kubectl get sts
No resources found.
[root@K8S-master01 2.2.7]# kubectl get po
NAME READY STATUS RESTARTS AGE
第2章 Docker及Kubernetes基础 | 87
web-0 1/1 Running 0 16m
web-1 1/1 Running 0 16m
web-2 1/1 Running 0 11m
由于此时删除了StatefulSet，因此单独删除Pod时，不会被重建：
[root@K8S-master01 2.2.7]# kubectl get po
NAME READY STATUS RESTARTS AGE
web-0 1/1 Running 0 16m
web-1 1/1 Running 0 16m
web-2 1/1 Running 0 11m
[root@K8S-master01 2.2.7]# kubectl delete po web-0
pod "web-0" deleted
[root@K8S-master01 2.2.7]# kubectl get po
NAME READY STATUS RESTARTS AGE
web-1 1/1 Running 0 18m
web-2 1/1 Running 0 12m
当再次创建此StatefulSet时，web-0会被重新创建，web-1由于已经存在而不会被再次创建，
因为最初此StatefulSet的replicas是2，所以web-2会被删除，如下（忽略AlreadyExists错误）：
[root@K8S-master01 2.2.7]# kubectl create -f sts-web.yaml
statefulset.apps/web created
Error from server (AlreadyExists): error when creating "sts-web.yaml": services
"nginx" already exists
[root@K8S-master01 2.2.7]# kubectl get po
NAME READY STATUS RESTARTS AGE
web-0 1/1 Running 0 32s
web-1 1/1 Running 0 19m
（2）级联删除
省略--cascade=false参数即为级联删除：
[root@K8S-master01 2.2.7]# kubectl delete statefulset web
statefulset.apps "web" deleted
[root@K8S-master01 2.2.7]# kubectl get po
No resources found.
也可以使用-f参数直接删除StatefulSet和Service（此文件将sts和svc写在了一起）：
[root@K8S-master01 2.2.7]# kubectl delete -f sts-web.yaml
service "nginx" deleted
Error from server (NotFound): error when deleting "sts-web.yaml":
statefulsets.apps "web" not found
[root@K8S-master01 2.2.7]#
2.2.8 DaemonSet
DaemonSet（守护进程集）和守护进程类似，它在符合匹配条件的节点上均部署一个Pod。
1. 什么是DaemonSet
DaemonSet 确保全部（或者某些）节点上运行一个 Pod 副本。当有新节点加入集群时，也会
为它们新增一个 Pod。当节点从集群中移除时，这些 Pod 也会被回收，删除 DaemonSet 将会删除
88 | 再也不踩坑的Kubernetes实战指南
它创建的所有Pod。
使用DaemonSet的一些典型用法：
 运行集群存储daemon（守护进程），例如在每个节点上运行Glusterd、Ceph等。
 在每个节点运行日志收集daemon，例如Fluentd、Logstash。
 在每个节点运行监控daemon，比如Prometheus Node Exporter、Collectd、Datadog代理、
New Relic代理或 Ganglia gmond。
2. 编写DaemonSet规范
创建一个DaemonSet的内容大致如下，比如创建一个fluentd的DaemonSet：
apiVersion: apps/v1
kind: DaemonSet
metadata:
name: fluentd-es-v2.0.4
namespace: logging
labels:
K8S-app: fluentd-es
version: v2.0.4
kubernetes.io/cluster-service: "true"
addonmanager.kubernetes.io/mode: Reconcile
spec:
selector:
matchLabels:
K8S-app: fluentd-es
version: v2.0.4
template:
metadata:
labels:
K8S-app: fluentd-es
kubernetes.io/cluster-service: "true"
version: v2.0.4
# This annotation ensures that fluentd does not get evicted if the node
# supports critical pod annotation based priority scheme.
# Note that this does not guarantee admission on the nodes (#40573).
annotations:
scheduler.alpha.kubernetes.io/critical-pod: ''
seccomp.security.alpha.kubernetes.io/pod: 'docker/default'
spec:
serviceAccountName: fluentd-es
containers:
- name: fluentd-es
image: K8S.gcr.io/fluentd-elasticsearch:v2.0.4
env:
- name: FLUENTD_ARGS
value: --no-supervisor -q
resources:
limits:
memory: 500Mi
requests:
cpu: 100m
memory: 200Mi
volumeMounts:
第2章 Docker及Kubernetes基础 | 89
- name: varlog
mountPath: /var/log
- name: varlibdockercontainers
mountPath: /var/lib/docker/containers
readOnly: true
- name: config-volume
mountPath: /etc/fluent/config.d
nodeSelector:
beta.kubernetes.io/fluentd-ds-ready: "true"
terminationGracePeriodSeconds: 30
volumes:
- name: varlog
hostPath:
path: /var/log
- name: varlibdockercontainers
hostPath:
path: /var/lib/docker/containers
- name: config-volume
configMap:
name: fluentd-es-config-v0.1.4
（1）必需字段
和其他所有Kubernetes配置一样，DaemonSet需要apiVersion、kind和metadata字段，同时也
需要一个.spec配置段。
（2）Pod模板
.spec 唯一需要的字段是.spec.template。.spec.template 是一个 Pod 模板，它与 Pod 具有相同的
配置方式，但它不具有apiVersion和kind字段。
除了Pod必需的字段外，在DaemonSet中的Pod模板必须指定合理的标签。
在DaemonSet中的Pod模板必须具有一个RestartPolicy，默认为Always。
（3）Pod Selector
.spec.selector字段表示Pod Selector，它与其他资源的.spec.selector的作用相同。
.spec.selector表示一个对象，它由如下两个字段组成：
 matchLabels，与 ReplicationController 的.spec.selector 的作用相同，用于匹配符合条件的
Pod。
 matchExpressions，允许构建更加复杂的 Selector，可以通过指定 key、value 列表以及与
key和value列表相关的操作符。
如果上述两个字段都指定时，结果表示的是AND关系（逻辑与的关系）。
.spec.selector 必须与.spec.template.metadata.labels 相匹配。如果没有指定，默认是等价的，如
果它们的配置不匹配，则会被API拒绝。
（4）指定节点部署Pod
如果指定了.spec.template.spec.nodeSelector，DaemonSet Controller将在与Node Selector（节点
选择器）匹配的节点上创建Pod，比如部署在磁盘类型为ssd的节点上（需要提前给节点定义标签
Label）：
90 | 再也不踩坑的Kubernetes实战指南
containers:
- name: nginx
image: nginx
imagePullPolicy: IfNotPresent
nodeSelector:
disktype: ssd
提 示
Node Selector同样适用于其他Controller。
3. 创建DaemonSet
在生产环境中，公司业务的应用程序一般无须使用DaemonSet部署，一般情况下只有像Fluentd
（日志收集）、Ingress（集群服务入口）、Calico（集群网络组件）、Node-Exporter（监控数据采
集）等才需要使用DaemonSet部署到每个节点。本节只演示DaemonSet的使用。
比如创建一个nginxingress：
[root@K8S-master01 2.2.8]# pwd
/root/chap02/2.2.8
[root@K8S-master01 2.2.8]# kubectl create -f nginx-ds.yaml
namespace/ingress-nginx created
configmap/nginx-configuration created
configmap/tcp-services created
configmap/udp-services created
serviceaccount/nginx-ingress-serviceaccount created
clusterrole.rbac.authorization.K8S.io/nginx-ingress-clusterrole created
role.rbac.authorization.K8S.io/nginx-ingress-role created
rolebinding.rbac.authorization.K8S.io/nginx-ingress-role-nisa-binding
created
clusterrolebinding.rbac.authorization.K8S.io/nginx-ingress-clusterrole-nis
a-binding created
daemonset.extensions/nginx-ingress-controller created
此时会在每个节点创建一个Pod：
[root@K8S-master01 2.2.8]# kubectl get po -n ingress-nginx
NAME READY STATUS RESTARTS AGE
nginx-ingress-controller-fjkf2 1/1 Running 0 44s
nginx-ingress-controller-gfmcv 1/1 Running 0 44s
nginx-ingress-controller-j89qc 1/1 Running 0 44s
nginx-ingress-controller-sqsk2 1/1 Running 0 44s
nginx-ingress-controller-tgdt6 1/1 Running 0 44s
[root@K8S-master01 2.2.8]# kubectl get po -n ingress-nginx -o wide
NAME READY STATUS RESTARTS AGE
IP NODE NOMINATED NODE
nginx-ingress-controller-fjkf2 1/1 Running 0 50s
192.168.20.30 K8S-node01 
nginx-ingress-controller-gfmcv 1/1 Running 0 50s
192.168.20.21 K8S-master02 
nginx-ingress-controller-j89qc 1/1 Running 0 50s
192.168.20.22 K8S-master03 
nginx-ingress-controller-sqsk2 1/1 Running 0 50s
192.168.20.31 K8S-node02 
nginx-ingress-controller-tgdt6 1/1 Running 0 50s
第2章 Docker及Kubernetes基础 | 91
192.168.20.20 K8S-master01 
注 意
因为笔者的Master节点删除了Tain（t Taint和Toleration见2.2.18），所以也能部署Ingress
或者其他Pod，在生产环境下，在Master节点最好除了系统组件外不要部署其他Pod。
4. 更新和回滚DaemonSet
如果修改了节点标签（Label），DaemonSet 将立刻向新匹配上的节点添加 Pod，同时删除不
能匹配的节点上的Pod。
在Kubernetes 1.6以后的版本中，可以在DaemonSet上执行滚动更新，未来的Kubernetes版本
将支持节点的可控更新。
DaemonSet滚动更新可参考：https://kubernetes.io/docs/tasks/manage-daemon/update-daemon-set/。
DaemonSet更新策略和StatefulSet类似，也有OnDelete和RollingUpdate两种方式。
查看上一节创建的DaemonSet更新方式：
[root@K8S-master01 2.2.8]# kubectl get ds/nginx-ds -o
go-template='{{.spec.updateStrategy.type}}{{"\n"}}'
RollingUpdate
提 示
如果是其他DaemonSet，请确保更新策略是RollingUpdate（滚动更新）。
（1）命令式更新
kubectl edit ds/
kubectl patch ds/ -p=
（2）更新镜像
kubectl set image
ds/=--record=true
（3）查看更新状态
kubectl rollout status ds/
（4）列出所有修订版本
kubectl rollout history daemonset 
（5）回滚到指定revision
kubectl rollout undo daemonset  --to-revision=
DaemonSet的更新和回滚与Deployment类似，此处不再演示。
2.2.9 ConfigMap
一般用 ConfigMap 管理一些程序的配置文件或者 Pod 变量，比如 Nginx 配置、MavenSetting
92 | 再也不踩坑的Kubernetes实战指南
配置文件等。
1. 什么是ConfigMap
ConfigMap 是一个将配置文件、命令行参数、环境变量、端口号和其他配置绑定到 Pod 的容
器和系统组件。ConfigMaps 允许将配置与 Pod 和组件分开，这有助于保持工作负载的可移植性，
使配置更易于更改和管理。比如在生产环境中，可以将 Nginx、Redis 等应用的配置文件存储在
ConfigMap上，然后将其挂载即可使用。
相对于Secret，ConfigMap更倾向于存储和共享非敏感、未加密的配置信息，如果要在集群中
使用敏感信息，最好使用Secret。
2. 创建ConfigMap
可以使用kubectl create configmap命令从目录、文件或字符值创建ConfigMap：
kubectl create configmap 
说明：
 map-name，ConfigMap的名称。
 data-source，数据源，数据的目录、文件或字符值。