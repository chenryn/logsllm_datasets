132  25th USENIX Security Symposium 
USENIX Association
break more advanced defense techniques that rely on
ASLR-based information hiding.
Breaking ASLR has been fertile research ground for
years and became especially popular in recent years.
From the outset [30], pioneering work showed that the
randomization in 32-bit address spaces provide insufﬁ-
cient entropy against practical brute-force attacks, so we
focus on 64-bit architectures (x86-64) in this section.
In practice, bypassing standard (i.e., coarse-grained,
user-level) ASLR implementations is now common. For
an attacker, it is, for instance, sufﬁcient to disclose a sin-
gle code pointer to de-randomize the address space [33].
Even ﬁne-grained ASLR implementations [34] are vul-
nerable to attacks that start with a memory disclosure and
then assemble payloads in a just-in-time fashion [1].
More advanced attack vectors rely on side channels
via shared caches. Speciﬁcally, recently accessed mem-
ory locations remain in the last-level cache (LLC) which
is shared by different cores on modern x86-64 proces-
sors. As it is much faster to access memory locations
from the cache rather than from memory, it is possi-
ble to use this timing difference to create a side chan-
nel and disclose sensitive information. By perform-
ing three types of PRIME+PROBE attacks on the CPU
caches and the TLB, Hund et al. [35] could completely
break kernel-level ASLR by mapping the entire virtual
address-space of a running Windows kernel. To perform
a PRIME+PROBE attack, the attacker needs the mapping
of memory locations to cache sets. In modern Intel pro-
cessors, this mapping is complex and reverse engineering
requires substantial effort [35]. However, performance
counter-based and other techniques have been proposed
to lower the reverse engineering effort [36].
Even without a priori disclosures, attackers may still
break ASLR using Blind ROP (BROP) [10]. A BROP
attack sends data that causes a control transfer to an-
other address and observes the behavior of the program.
By carefully monitoring server program crashes, hangs,
or regular output, the attacker can infer what code exe-
cuted and, eventually, identify ROP gadgets. After many
probes (and crashes), she gets enough gadgets for a ROP
chain. BROP is a remote attack method applicable (only)
to servers that automatically respawn upon a crash.
In general, leaking information by means of side chan-
nels is often possible. To launch such an attack, an at-
tacker typically uses memory corruption to put a program
in a state that allows her to infer memory contents via
timings [21, 37, 12] or other side channels [10].
As ASLR by itself does not provide sufﬁcient protec-
tion against the attacks described above, the community
is shifting to more advanced defenses that build on ALSR
to hide sensitive data (such as code pointers) in a hidden
region in a large address space, typically not referenced
by any pointers within the attacker’s reach.
Hiding secret information in a large address space
is now common practice in a score of new defenses.
For example, Oxymoron [4] protects the Randomization-
agnostic Translation Table (RaTTle) by means of infor-
mation hiding, and Opaque CFI [23] protects the so-
called Bounds Lookup Table (BLT) in a similar way.
Likewise, Isomeron [19] keeps the execution diversiﬁer
data secret and StackArmor [25] isolates potentially vul-
nerable stack frames by means of hiding in a large ad-
dress space. Finally, on x86-64 architectures, CFCI [24]
also needs to hide a few MBs of protected memory.
One of the best-known examples of a defense that
builds on ASLR-backed information hiding is Code
Pointer Integrity [3]. CPI splits the address space in a
standard and a safe region and stores all code pointers in
the latter, while restricting accesses to the (huge) safe re-
gion to CPI-intrinsic instructions. Moreover, it also pro-
vides every thread with a shadow stack (called SafeStack
in CPI) in addition to the regular stack and uses the for-
mer to store return addresses and other proven-safe ob-
jects. Both the shadow stacks (which are relatively small)
and the safe region (which is huge) are hidden at a ran-
dom location in the virtual address space.
By means of probing on a timing side channel, Evans
et al.
showed that it is possible to circumvent CPI
and ﬁnd the safe region [12]. However, depending on
the construction of the safe region, the attack may re-
quire a few crashes or complete in several hours in or-
der to be stealthy (i.e., crash-free). Moreover, simi-
lar to the recent CROP [11] (which instead relies on
specially crafted crash-resistant primitives), this attack
needs to resort to full memory probing to locate small
hidden regions (unlike CPI’s) in absence of implementa-
tion ﬂaws. Full memory probing forces the attacker to
trigger many crashes and other detection-prone events,
and its efﬁciency quickly degrades when increasing the
address space entropy.
Concurrent work [31] relies on thread spraying to
reduce the entropy in ﬁnding a per-thread hidden ob-
ject. Allocation oracles can make thread spraying attacks
faster by providing a more efﬁcient disclosure primitive
compared to the memory probing primitives used in [31].
the existing attacks, allocation oracles
demonstrate that an attacker can craft pervasively avail-
able primitives and locate the smallest hidden regions in
the largest address spaces, while leaving little or no de-
tectable traces behind.
Unlike all
10 Conclusions
We have shown that information hiding techniques that
rely on randomization to bury a small region of sensitive
information in a huge address space are not safe on mod-
ern Linux systems. Speciﬁcally, we introduced new in-
USENIX Association  
25th USENIX Security Symposium  133
13
formation disclosure primitives, allocation oracles, that
allow attackers to probe the holes in the address space:
by repeated allocations of large chunks of memory, the
attacker discovers the sizes of the largest areas of unal-
located memory. Knowing the sizes of the largest holes
greatly reduces the entropy of randomization-based in-
formation hiding and allows an attacker to infer the lo-
cation of the hidden region with few to no crashes or no-
ticeable side-effects. We have also shown that allocation
oracles are pervasive in real-world software.
Unfortunately, information hiding underpins many of
the most advanced defense mechanisms today. Without
proper mitigation, they are all vulnerable to our attacks.
While one may deploy more conservative memory man-
agement polices to limit the damage, we emphasize that
the problem is fundamental in the sense that allocation
oracles always reduce the randomization entropy, regard-
less of the mitigation and the address space size. In gen-
eral, information hiding is vulnerable to entropy reduc-
tion by whatever means and it is not unlikely that attack-
ers can combine allocation oracles with other techniques.
In our view, it is time to reconsider our dependency on
the pseudo-isolation offered by randomization and opt
instead for stronger isolation solutions like software fault
isolation or hardware protection.
11 Disclosure
We have cooperated with the National Cyber Security
Centre in the Netherlands to coordinate disclosure of the
vulnerabilities to the relevant parties.
12 Acknowledgements
We thank the anonymous reviewers for their valuable
comments. This work was supported by the Euro-
pean Commission through project H2020 ICT-32-2014
“SHARCS” under Grant Agreement No. 644571 and
by Netherlands Organisation for Scientiﬁc Research
through project NWO 639.023.309 VICI “Dowsing”.
References
[1] K. Z. Snow, L. Davi, A. Dmitrienko, C. Liebchen, F. Monrose,
and A.-R. Sadeghi, “Just-in-time code reuse: On the effectiveness
of ﬁne-grained address space layout randomization,” in IEEE
S&P ’13.
[2] T. H. Dang, P. Maniatis, and D. Wagner, “The performance cost
of shadow stacks and stack canaries,” in ASIACCS ’15.
[3] V. Kuznetsov, L. Szekeres, M. Payer, G. Candea, R. Sekar, and
D. Song, “Code-pointer integrity,” in OSDI’ 14.
ment,” in Xen Summit, 2008.
administration,”
[15] “Redis
https://web.archive.org/web/
[5] PaX Team, “Address space layout randomization (ASLR),” 2003,
http://pax.grsecurity.net/docs/aslr.txt.
[6] K. Lu, C. Song, B. Lee, S. P. Chung, T. Kim, and W. Lee, “ASLR-
Guard: Stopping address space leakage for code reuse attacks,”
in CCS ’15.
[7] R. Wahbe, S. Lucco, T. E. Anderson, and S. L. Graham, “Efﬁcient
software-based fault isolation,” in SOSP ’93.
[8] B. Yee, D. Sehr, G. Dardyk, J. B. Chen, R. Muth, T. Orm,
S. Okasaka, N. Narula, N. Fullagar, and G. Inc, “Native client:
A sandbox for portable, untrusted x86 native code,” in IEEE S&P
’07.
[9] L. Deng, Q. Zeng, and Y. Liu, “ISboxing: An instruction substi-
tution based data sandboxing for x86 untrusted libraries,” in IFIP
SEC ’15, 2015.
[10] A. Bittau, A. Belay, A. Mashtizadeh, D. Mazières, and D. Boneh,
“Hacking blind,” in IEEE S&P ’14.
[11] R. Gawlik, B. Kollenda, P. Koppe, B. Garmany, and T. Holz,
“Enabling client-side crash-resistance to overcome diversiﬁcation
and information hiding,” in NDSS ’16.
[12] I. Evans, S. Fingeret, J. Gonzalez, U. Otgonbaatar, T. Tang,
H. Shrobe, S. Sidiroglou-Douskos, M. Rinard, and H. Okhravi,
“Missing the point(er): On the effectiveness of code pointer in-
tegrity.”
[13] “CVE-2015-3864,”
https://cve.mitre.org/cgi-bin/cvename.cgi?
name=CVE-2015-3864.
[14] D. Magenheimer, “Memory overcommit... without the commit-
20150905213905/http://redis.io/topics/admin.
[16] E. Sammer, Hadoop Operations, 2012, ch. 4.
[17] V. P. Kemerlis, G. Portokalidis, and A. D. Keromytis, “kGuard:
Lightweight kernel protection against return-to-user attacks,” in
USENIX Security ’12.
[18] M. Conti, S. Crane, L. Davi, M. Franz, P. Larsen, M. Negro,
C. Liebchen, M. Qunaibit, and A.-R. Sadeghi, “Losing control:
On the effectiveness of control-ﬂow integrity under stack at-
tacks,” in CCS ’15.
[19] L. Davi, C. Liebchen, A. Sadeghi, K. Z. Snow, and F. Monrose,
“Isomeron: Code randomization resilient to (just-in-time) return-
oriented programming,” in NDSS ’15.
[20] V. P. Kemerlis, G. Portokalidis, K. Jee, and A. D. Keromytis,
“Libdft: Practical dynamic data ﬂow tracking for commodity sys-
tems,” in VEE ’12.
[21] J. Seibert, H. Okhravi, and E. Söderström, “Information leaks
without memory disclosures: Remote side channel attacks on di-
versiﬁed code,” in CCS ’14.
[22] “Mmap
speedup,”
d89089d5a857ed08_1.htm.
http://www.verycomputer.com/180_
[23] V. Mohan, P. Larsen, S. Brunthaler, K. W. Hamlen, and M. Franz,
“Opaque control-ﬂow integrity,” in NDSS ’15.
[24] M. Zhang and R. Sekar, “Control-ﬂow and code integrity for
COTS binaries: An effective defense against real-world ROP at-
tacks,” in ACSAC ’15.
[25] X. Chen, A. Slowinska, D. Andriesse, H. Bos, and C. Giuffrida,
“StackArmor: Comprehensive protection from stack-based mem-
ory error vulnerabilities for binaries,” in NDSS ’15.
[4] M. Backes and S. Nürnberger, “Oxymoron: Making ﬁne-grained
memory randomization practical by allowing code sharing,” in
USENIX Security ’14.
[26] S. Crane, C. Liebchen, A. Homescu, L. Davi, P. Larsen, A. R.
Sadeghi, S. Brunthaler, and M. Franz, “Readactor: Practical code
randomization resilient to memory disclosure,” in IEEE S&P ’15.
134  25th USENIX Security Symposium 
USENIX Association
14
[27] S. J. Crane, S. Volckaert, F. Schuster, C. Liebchen, P. Larsen,
L. Davi, A.-R. Sadeghi, T. Holz, B. De Sutter, and M. Franz, “It’s
a TRaP: Table randomization and protection against function-
reuse attacks,” in CCS ’15.
[28] J. Gionta, W. Enck, and P. Ning, “HideM: Protecting the contents
of userspace memory in the face of disclosure vulnerabilities,” in
CODASPY ’15.
[29] C. L. Kjell Braden, Lucas Davi and M. F. P. L. Ahmad-
Reza Sadeghi, Stephen Crane, “Leakage-resilient layout random-
ization for mobile devices,” in NDSS ’16.
[30] H. Shacham, M. Page, B. Pfaff, E.-J. Goh, N. Modadugu, and
D. Boneh, “On the effectiveness of address-space randomiza-
tion,” in CCS ’04.
[31] E. Gökta¸s, R. Gawlik, B. Kollenda, E. Athanasopoulos, G. Por-
tokalidis, C. Giuffrida, and H. Bos, “Undermining information
hiding (and what to do about it),” in USENIX Security ’16.
[32] “SafeStack,” http://clang.llvm.org/docs/SafeStack.html.
[33] R. Strackx, Y. Younan, P. Philippaerts, F. Piessens, S. Lachmund,
and T. Walter, “Breaking the memory secrecy assumption,” in
EuroSec ’09.
[34] C. Giuffrida, A. Kuijsten, and A. S. Tanenbaum, “Enhanced op-
erating system security through efﬁcient and ﬁne-grained address
space randomization,” in USENIX Sec ’12.
[35] R. Hund, C. Willems, and T. Holz, “Practical timing side channel
attacks against kernel space ASLR,” in IEEE S&P ’13.
[36] C. Maurice, N. L. Scouarnec, C. Neumann, O. Heen, and A. Fran-
cillon, “Reverse engineering Intel last-level cache complex ad-
dressing using performance counters,” in RAID ’15.
[37] E. Bosman, K. Razavi, H. Bos, and C. Giuffrida, “Dedup est
machina: Memory deduplication as an advanced exploitation
vector,” in IEEE S&P ’16.
A Base EAP-only algorithm
Algorithm 1 Binary search using the Ephemeral Alloca-
tion Primitive; sizes are in pages.
function DEDUCE(low, high)
if low = high then
return low
if high - low = 1 then
res ← TEMP-ALLOC(high)
if SUCCESS(res) then
else
return high
return low
mid point ← (cid:30)(high + low)/2(cid:29)
res ← TEMP-ALLOC(mid point)
if SUCCESS(res) then
return DEDUCE(mid point, high)
else
return DEDUCE(low, mid point − 1)
Hole Total
0B
0B
0B
A
B
C
Max
131068GiB
1028GiB
4GiB
Table 3: Initial state for a PIE executable
B PAP-only algorithm
For each hole G, we maintain two variables, Gtotal and
Gmax. The ﬁrst variable tracks the number of bytes allo-
cated from G. The second holds the maximum number
of bytes that may still be allocatable from G at any point
in time. So when an allocation of size S is known to
originate from G, we increase Gtotal by S and decrease
Gmax by S. Crucially, when an allocation of size S fails,
we know that no hole has S bytes available. Therefore,
the max variable for every tracked hole needs to be ad-
justed to S minus the pagesize (see the functions HOLE-
SATISFIED, HOLE-FAILED-TO-SATISFY, called for holes
that satisﬁed or failed to satisfy an allocation request, re-
spectively).
function HOLE-SATISFIED(size, G)
Gmax ← Gmax − size
Gtotal ← Gtotal + size
if Gmax > size− pagesize then
Gmax ← size− pagesize
function HOLE-FAILED-TO-SATISFY(size, G)
A state consists of the set of max and total variables
for each tracked hole. In the initial state we may have
some information for the maximum size of each hole, but
no bytes have been allocated during the run of our algo-
rithm, so that Gtotal = 0,∀G. Given the size distributions
in Table 1, the initial state for a simple PIE executable is
as given on Table 3.
Descent mode The algorithm operates in two modes.
Suppose that the highest maximum value (hmv) is unique
across all the tracked holes and G is the hole it is asso-
ciated with (i.e. (cid:31)H : Gmax = Hmax). In this case, we try
decreasing allocation sizes which can only be satisﬁed
by G, in the hope that an allocation will succeed, caus-
ing Gmax to be decremented below the next-highest max-
imum (nhmv) value so that we will remain in this mode
for the next step of the algorithm.
There is an inherent tradeoff between the accuracy and
the number of allocations we try.
In the extreme, we
could explore the interval [nhmv,hmv] by starting with
hmv and decreasing the allocation size by one page af-
ter each failed attempt. Of course, this would result in
a huge number of allocation attempts, rendering the ap-
proach impractical.
USENIX Association  
25th USENIX Security Symposium  135
15
function CALCULATE-STEPS(high, low)
size ← high− low
if size = pagesize then
return [high]
step ← size/split
sizes ← []
idx ← 0
for n in 0..(split − 1) do
sz ← high− n∗ step