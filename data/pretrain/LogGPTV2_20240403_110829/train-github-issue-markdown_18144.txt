# ðŸŒŸ TAPAS (Weakly Supervised Table Parsing via Pre-Training)
## Model description
**TAPAS** ArXiV Paper Google AI Blog, an approach to question answering over
tables without generating logical forms. TAPAS trains from weak supervision,
and predicts the denotation by selecting table cells and optionally applying a
corresponding aggregation operator to such selection. TAPAS extends BERTâ€™s
architecture to encode tables as input, initializes from an effective joint
pre-training of text segments and tables crawled from Wikipedia, and is
trained end-to-end. We experiment with three different semantic parsing
datasets, and find that TAPAS outperforms or rivals semantic parsing models by
improving state-of-the-art accuracy on SQA from 55.1 to 67.2 and performing on
par with the state-of-the-art on WIKISQL and WIKITQ, but with a simpler model
architecture. We additionally find that transfer learning, which is trivial in
our setting, from WIKISQL to WIKITQ, yields 48.7 accuracy, 4.2 points above
the state-of-the-art.
## Open source status
  * [ X ] the model implementation is available: GitHub repo
  * [ X ] the model weights are available: in the "Data" section at their GitHub page
  * [ X ] who are the authors: Jonathan Herzig, PaweÅ‚ Krzysztof Nowak, Thomas Muller, Francesco Piccinno, Julian Martin Eisenschlos