30th USENIX Security Symposium    2401
data to the attacker. Meltdown-type attacks [18, 52, 70, 82, 85]
extract data across architectural protection domains by exploit-
ing transient execution after a hardware exception. Our focus,
however, is on Spectre-type attacks [13, 30, 36, 43, 45, 46, 54],
which exploit misprediction. Spectre-type attacks maneu-
ver the victim into leaking its own data, and are limited to
the depth of the speculation window. Spectre v1 (Spectre-
PHT [18]) exploits misprediction of conditional branch out-
comes. Spectre v2 (Spectre-BTB [18]) exploit misprediction
of indirect branch target addresses. The original Spectre v2
attacks poisoned the BTB to redirect control-ﬂow to arbitrary
locations; but as we shall see, even mispredicting a legal tar-
get is dangerous (§ 6). Other variants target return address
speculation [46, 54] or data speculation [36].
3 Threat model
We consider an attacker who is an unprivileged (non-root)
user on a multi-core machine running the latest Linux kernel.
The attacker’s goal is to obtain information located in the
kernel address space, which is not otherwise accessible to it.
We assume the system has all state-of-the-art mitigations
against transient execution attacks enabled. In particular, the
attacker cannot mount cross-protection domain Meltdown-
type attacks to directly read from the kernel address space.
We assume that the attacker knows kernel virtual addresses.
This knowledge can be obtained by breaking kernel address
space layout randomization (KASLR) using orthogonal side-
channel attacks [19, 84, 86] or even simply from accidental
information leak bugs in the kernel.
4 Speculative type confusion in eBPF
Linux’s extended Berkeley Packet Filter (eBPF) [68] subsys-
tem strives to let the Linux kernel safely execute untrusted,
user-supplied kernel extensions in privileged context. An
eBPF extension is “attached” to designated kernel events,
such as system call execution or packet processing, and is exe-
cuted when these events occur. eBPF thereby enables applica-
tions to customize the kernel for performance monitoring [3],
packet processing [2], security sandboxing [4], etc.
Unprivileged users can load eBPF extensions into the ker-
nel as of Linux v4.4 (2015) [75].5 An eBPF extension is
loaded in the form of a bytecode program for an in-kernel
virtual machine (VM), which is limited in how it can interact
with the rest of the kernel. The kernel statically veriﬁes the
safety of loaded eBPF programs. On the x86-64 and Arm
architectures, the kernel compiles eBPF programs to native
code; on other architectures, they run interpreted.
Both eBPF veriﬁcation and compilation do not consider
speculative type confusion, which allows an attacker to load
eBPF programs containing Spectre gadgets and thus read
5An unprivileged_bpf_disable conﬁguration knob exists for disal-
lowing unprivileged access to eBPF; it is not set by default.
Figure 2: eBPF speculative type confusion attack.
eBPF security model
from anywhere in the kernel address space (Figure 2). In the
following, we describe the eBPF security model (§ 4.1), detail
its vulnerability (§ 4.2), and describe our proof-of-concept
attack (§ 4.3).
4.1
In general, eBPF does not enforce safety at run time, but by
statically verifying that the eBPF program maintains memory
safety and is otherwise well-behaved. (One exception to this
principle are Spectre mitigations, discussed below.) An eBPF
program can only call one of a ﬁxed set of helper functions in
the kernel. The allowed set of helpers depends on the type of
eBPF program and on the privileges of the user that loaded it.
An eBPF program is restricted to accessing a ﬁxed set of
memory regions, known at compile time, including a ﬁxed-
size stack and a context, which is a program-speciﬁc object
type that stores the program’s arguments. An eBPF pro-
gram can further access statically-sized key/value dictionaries
called maps. The size of a map’s keys and values is ﬁxed at
map creation time. A map’s data representation (array, hash
table, etc.) is similarly speciﬁed on creation. Maps can be
shared by different eBPF programs and can also be accessed
by user processes. An eBPF program that successfully looks
up a value in a map receives a pointer to the value, and so can
manipulate it in-place.
eBPF veriﬁcation The kernel statically veriﬁes the safety
of an eBPF program in two steps. The ﬁrst step performs
control-ﬂow validation, to verify that the program (which
runs in privileged context) is guaranteed to terminate in a
ﬁxed amount of time. This property is veriﬁed by checking
that the program does not contain loops and does not exceed
a certain ﬁxed size. The second step veriﬁes the program’s
memory safety. Memory safety is veriﬁed by enumerating
every possible execution ﬂow to prove that every memory
access is safe. When processing a ﬂow, the veriﬁer maintains
a type for each register and stack slot, and checks that memory
accesses are valid with respect to these types.
The veriﬁer tracks whether each register is uninitialized,
holds a scalar (non-pointer) value, or holds a pointer. Point-
ers are further typed according to the region they point to:
the stack, the context, a map, a value from a map, and so on.
The veriﬁer also tracks whether a pointer is non-NULL and
maintains bounds for the pointer’s offset from its base ob-
ject. Using this information, the veriﬁer checks various safety
properties, such as:
2402    30th USENIX Security Symposium
USENIX Association
kerneleBPFbytecodecheck program semantics✓verifierbounds check bypass mitigationscompilerSpectretype confusion gadget• For every memory access, the operand register R contains
a pointer type, R (cid:54)= NULL, and R points to within its base
object.
• If a stack slot is read, then the program has previously
written to it. (This check prevents leaking of kernel data
that was previously stored in that location.)
• Pointers are not cast to scalars. (This check prevents
kernel addresses from leaking to userspace, since such
scalars can be stored to a map and read by the user.)
eBPF also allows certain program types to access kernel
data structures such as socket and packet objects, whose size
may not be known at compile time. In such cases, the runtime
stores the object size in the program’s context, and the veriﬁer
checks that any pointer to these objects undergoes bounds
checking before being dereferenced. We do not discuss this
further, since our attack does not exploit this functionality.
Compile-time Spectre mitigation Following the disclo-
sure of Spectre, the eBPF veriﬁer was extended to patch eBPF
programs with run-time mitigations for Spectre bounds check
bypass vulnerabilities [15,76]. The veriﬁer rewrites any array-
map access and any pointer arithmetic operation so that they
are guaranteed to be within the base object’s bounds. For
example, A[i] is rewritten as A[i & (A.size-1)], where
A.size is rounded up to be a power of 2. Pointer arithmetic is
handled similarly, leveraging the veriﬁer’s knowledge about
base objects’ size and pointer offsets.
4.2 Veriﬁer vulnerability
When verifying memory safety, the eBPF veriﬁer enumerates
only correct execution paths (i.e., that comply with the seman-
tics of the architecture’s instruction set). The veriﬁer does
not reason about the semantically incorrect execution paths
that arise due to (mis)speculative execution. As a result, the
veriﬁer can conclude that a memory read is safe, but there may
be a misspeculated execution ﬂow in which that instruction is
unsafe. Listing 2a shows an example.
In this example, the semantics of the program are such that
the execution of lines 3 and 5 is mutually exclusive: line 3
executes if and only if r0=0 and line 5 executes if and only
if r0=1. Therefore, the veriﬁer reasons that the only ﬂow in
which line 5 executes and memory is read is when r6 points
to a stack slot, and accepts the program. Speciﬁcally, when
the veriﬁer’s analysis reaches line 2, it enumerates two cases:
• If the condition on line 2 evaluates to TRUE, r6’s type
remains a valid stack variable.
• If the condition on line 2 evaluates to FALSE, r6’s type
changes to scalar, but the veriﬁer learns that r0 is 0.
Therefore, when it subsequently reaches line 4, it reasons
that the condition there must evaluate to TRUE, and does
not consider line 5 in these ﬂows.
In both cases, every execution ﬂow the veriﬁer considers is
safe. Moreover, the load in line 5 is not rewritten with Spectre
// r0 = ptr to a map array entry (verified (cid:54)= NULL)
// r6 = ptr to stack slot (verified (cid:54)= NULL)
// r9 = scalar value controlled by attacker
1
2
3
4
5
6
7
r0 = *(u64 *)(r0) // miss
r0 = *(u64 *)(r0) // miss
A:if r0 != 0x0 goto B
A:if r0 == 0x0 goto B
r6 = r9
r6 = r9
B:if r0 != 0x1 goto D
B:if r0 != 0x0 goto D
r9 = *(u8 *)(r6)
r9 = *(u8 *)(r6)
C:r1 = M[(r9&1)*512];//leak
D:...
C:r1 = M[(r9&1)*512];//leak
D:...
(a) Passes veriﬁcation.
(b) Fails veriﬁcation.
Listing 2: eBPF veriﬁcation vulnerability: leaking a bit (eBPF byte-
code; rX stand for eBPF bytecode registers).
mitigation code, because the pointer it dereferences is veriﬁed
to point to the stack (and thus within bounds). Nevertheless,
if an attacker manages to (1) make the dereference of r0
(line 1) be a cache miss, so that the branches take a long time
to resolve; and (2) mistrain the branch predictor so that both
branches predict “not taken” (i.e., do not execute the goto),
then the resulting transient execution sets r6 to the attacker-
controlled value in r9 (line 3), dereferences that value (line 5),
and leaks it (line 6).
We remark that in practice, the veriﬁer does not maintain
perfect information about each register, and so may end up
enumerating some impossible execution ﬂows. (I.e., the veri-
ﬁer enumerates an over-approximation of the correct execu-
tion ﬂows.) Consequently, the veriﬁer inadvertently rejects
some speculative type confusion eBPF gadgets. Listing 2b
shows an example. For scalar values, the veriﬁer maintains
either a register’s exact value or a possible range of values.
When the veriﬁer considers the case of the condition on line 2
evaluating to FALSE, it cannot track the implication that
r0(cid:54)=0, as that cannot be represented with a single range. Since
the veriﬁer has no additional information about r0, it goes
on to consider a continuation of the ﬂow in which the con-
dition in line 4 also evaluates to FALSE. In this ﬂow, line 5
dereferences a scalar value, and so the program is rejected.
This rejection is accidental. The goal of eBPF developers is to
increase the precisions of the veriﬁer’s information tracking,
and so under current development trends, we would expect the
veriﬁer to eventually accept Listing 2b. Improving the veri-
ﬁer’s precision is not a problem in and of itself, if eBPF adopts
general Spectre mitigations (i.e., not only bounds enforcing).
4.3 Proof of concept exploit
We now describe and evaluate a proof of concept exploit for
the eBPF vulnerability. The exploit implements a universal
read gadget [55], which allows the attacker to read from any
kernel virtual address. This ability allows the attacker to read
all of the machine’s physical memory, as the kernel maps all
USENIX Association
30th USENIX Security Symposium    2403
available physical memory in its virtual address space [5].
The eBPF bytecode is designed to easily map to the x86
architecture, which the eBPF compiler leverages to map eBPF
registers to x86 registers and eBPF branches to x86 branches.
To guarantee that our victim eBPF program has the required
structure (Listing 2a), we manually encode its bytecode in-
stead of using a C-to-eBPF compiler. The kernel then trans-
lates the bytecode to native x86 code in the obvious way.
The main challenge faced by the exploit is how to mistrain
the branch predictor, so that two conditional branches whose
“not taken” conditions are mutually exclusive both get pre-
dicted as “not taken.” Two further challenges are (1) how to
evict the value checked by these branches from the cache, so
that their resolution is delayed enough that the misspeculated
gadget can read and leak data; and (2) how to observe the
leaked data. These cache-related interactions are non-trivial to
perform because the eBPF program runs in the kernel address
space and the attacker, running in a user process, cannot share
memory with the eBPF program. (The main method of inter-
action is via eBPF maps, but processes can only manipulate
maps using system calls, not directly.)
Mistraining the branch predictor A common branch mis-
training technique in Spectre attacks is to repeatedly invoke
the victim with valid input (e.g., an in-bounds array index) to
train the branch predictor, and then perform the attack with
an invalid input (e.g., an out-of-bounds array index), at which
point the relevant branch gets mispredicted. This technique
does not apply in our case: we need to train two branches
whose “not taken” conditions are mutually exclusive to both
get predicted as “not taken.” This means that no matter what
input the eBPF victim gadget is given, at least one of the
branches is always taken in its correct execution. In other
words, we cannot get the branch predictor into a state that is
inconsistent with a correct execution by giving it only exam-
ples of correct executions.
To address this problem, we use cross address-space out-of-
place branch mistraining [18]. Namely, we set up a “shadow”
of the natively-compiled eBPF program in the attacker’s pro-
cess, so that the PHT entries (§ 2.2) used to predict the shadow
branches also get used to predict the victim branches in the
kernel.6 In our shadow, however, the branches are set up so
the “not taken” conditions are not mutually exclusive, and so
can be trained to both predict “not taken” (Listing 3).
To ensure PHT entry collision between the shadow and
victim branches, we must control the following factors, upon
which PHT indexing is based: (1) the state of the GHR and
(2) the BPU-indexing bits in the branches’ virtual addresses.
To control the GHR, we prepend a “branch slide” (List-
ing 4) to both the victim and its shadow. (For the eBPF victim,
we generate the branch slide using appropriate eBPF byte-
code, which the kernel compiles into the native code shown
6Note that this approach depends on the branch predictor state not being
cleared when the processor switches to privileged mode on kernel entry. This
is indeed the case in current processors.
// addresses A' and B' collide in the PHT
// with addresses A and B in Listing 2a
A': if r0 == 0x0 goto B'
// dummy register assignment
B': if r0 == 0x0 goto C'
// dummy pointer dereference
C': ...
Listing 3: Mistraining the branch predictor.
$0x1,%edi
$0x0,%rdi
L1
$0x0,%rdi
L2
mov
cmp
jne
cmp
jne
...
cmp
jne
# exploit starts here
$0x0,%rdi
Ln