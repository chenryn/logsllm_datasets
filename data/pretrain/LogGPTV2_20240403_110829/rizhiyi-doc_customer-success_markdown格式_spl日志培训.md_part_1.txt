招日志使用培训
1.功能介绍－日志搜索 14
106.39.75.135 - - [04/Jul/2015:16:08:42 +0800] "GET /api/v0/sources/upload_volum_info/ HTTP/1.1"
200 213 "https://zhang.u.rizhiyi.com/sources/input/" "Mozilla/5.0 (Windows NT 6.1; WOW64) Apple
WebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.124 Safari/537.36" "-" 0.026 0.026
1.自动提取日志的关键字段，将非结构化日志转化为结构化数据，方便用户点击任何一个字段就能自动查询；
2.支持全文检索，还可以使用字段、数值范围和布尔检索，查询指定时间范围内的日志；
3.自动统计各字段的事件数
1.功能介绍－日志搜索 14
通过“查看上下文”功能，可以快速定位error日志上下各25行的日志内容，方便快速分析故障原因。
1.功能介绍－日志告警 14
日志易基于已存搜索配置灵活的监控告警，当触发配置的告警条件时通过邮件或短
信接口通知，支持事件数告警，字段统计告警，连续统计告警，基线告警
1.功能介绍－日志分析展示 14
日志易通过搜索处理语言SPL(Search Processing Language)，进行可编程的日志分析统计，
通过简单鼠标点击操作就能形成统计列表和图形。
图形报表
表格
个人
仪表盘
1.功能介绍－仪表盘展示 14
1.功能介绍－定时任务 14
通过定时任务功能，可以定时运行统计语法，用户可以随时调取统计结果进行查询，同时，可
以利用统计结果进行二次统计，如利用每天统计等数据，实现周，月，甚至是年数据的统计
灵活的SPL语法，实现各种统计功能
定时统计结果
1.功能介绍－报表 14
用户可以自由定义日报，周报，月报内容（图形，表格），以及生成时间，发送邮箱等信息，
日志易后台会定时生成pdf报表，推送至用户邮箱
2.数据接入 14
目前招日志直接对接招行kafka消息队列，获取日志，因此如果需要接入日志到招日志，请提
供日志对应的topic。
{ {
"AGENT_TIMESTAMP": "1452072384554",
“context_id”: INDEX, 用于上下文查
"FILE_NAME": "paas.log", 询
"FILE_PATH": "/opt/app/paas/paas.log", "appname": SOURCE_TYPE,
"INDEX": 1450861702, "hostname": SOURCE_HOST,
"LOG": "Jan 6 09:26:24 loggregator "raw_message": LOG,
0.003147837 app_id:cf1416b1-8e9c-42ac-96fc-
8b88e58f8a94", "recv_timestamp": AGENT_TIMESTAMP,
"SOURCE_HOST": "PaaSSyslog01SZ-0", "tag": FILE_NAME, TOPIC,
"SOURCE_TYPE": "paaslogsz", "timestamp": AGENT_TIMESTAMP
"TOPIC": "paaslogs_sz" }
招日志数据格式
}
Kafka数据格式
3.数据分组 14
管理员可以通过“hostname”，“appname”（SOURCE_TYPE），“tag”（文件名，topic）
进行数据分组并赋予需要搜索该数据的用户组，通过数据分组，控制用户访问数据的权限，因
此，请提供“需要访问该数据的用户信息给管理员”
4.数据搜索 14
(注意：系统会自动分词，所有语法需要英文半角)
用户有了权限后，通过LDAP帐号登录到招日志，即可搜索到所属日志信息，如手机银行用户，
登录后，就能搜索到所有跟手机银行相关的日志。（操作演示），常用搜索语法：
全文检索: 113.66.199.117 GET 短语查询: "/api/v0/search/action/ HTTP/1.1" 通配符: *, ?
逻辑运算符: AND, OR, NOT, ( ) 字段值完全匹配: apache.method:"get” 字段值模糊匹配: hostname:10-6-24*
字段数值范围: apache.status:[400 TO 500]或apache.status:>400
5.数据解析 14
(注意：该部分暂时由管理员和厂家完成)
性能监控日志样例：
2016-03-01
00:00:11|6.389717|51.89774|31832|29.00602|29701|2806|30.31857|590123.6|19
5198.9|395576.7|142196.4|60312.06|344069.1|36.09176|15.19663|461|465|0|0|0
|15|889|0|0|1|0
需要提供需要解析的每个字段的说明给管理员，由管理员进行正则配置。
#CheckTime|PercentProcessorTime|FreeSpacePercentDriverC|FreeMegabytesDriverC
|FreeSpacePercentDriverD|FreeMegabytesDriverD|MemoryAvailbleMBytes|MemoryInU
se|NetworkTotal|NetworkReceived|NetworkSent|WebServiceSent|WebServiceReceive
d|WebServiceTotal|WebServiceGetRequest|WebServicePostRequest|WebServiceCurre
ntConnections|TCPv4Connections|DiskQueue|ASPNET4RequestWaitTime|ASPNET4Reque
stsQueued|ASPNET4RequestsCurrent|ASPNET4RequestExecutionTime|ASPNET4RequestW
aitTime|ASPNET4RequestsQueued|ASPNET4RequestsCurrent|ASPNET4RequestExecution
Time
5.数据解析 14
json格式，例子如下：
{"Guid":"99.8.169.22","AID":"RhJY6N7dUYrwd2n3EK\/hWv2T8Q0=","SID":"7Db1ZXvko+3U5uvXBbeX
XH8yHtU=","SessionID":"","LoginType":"","LoginID":"","IP":"99.8.169.22","LBS":"","AppID":"","URL":"\/
SHELL\/LOGIN\/CLIENT\/UNIONLOGOUT.ASPX","UrlReferrer":"","Time":"09:06:45:2040","Span":"31.2
001"}
对于json格式的日志，程序可以自动解析。
日志采用xml格式，例子如下：
20160302 10:28:31
ewUwsGlw0h0TLoH3ilTs37Yaqkk=TLWrbFtRbMKd+dRzy4WEc
YIQpZ8=Q815238Q815238/USER/ALLINONE_NOTICESERVICE.ASPX021010219
84071510160120160302
10:28:31Y59.44.59.48A6214830245290852EP01210102198407151016xxxx41.806955|
123.397853
对于xml格式日志，程序也可以自动解析。
6.数据统计分析－SPL语法
SPL语法参考
命令 描述
eval 对日志字段或统计结果进行计算表达式，并将表达式值放入新增字段中􏰫 􏰫
bucket 将连续的值分别放入按区间分割的桶中，用于计算趋势以及数组分组变化
fields 保留结果中的字段
join 类似sql的连接，将主管道的结果和子管道的结果连接在一起
limit 返回前n个结果，常用于限制统计结果数量
movingavg 计算列值之间移动平均值
rollingstd 计算列值之间的标准差
rename 重命名字段名
stats 提供各种统计函数，并可以选择按字段分组统计
sort 安装指定的字段对结果进行排序
where 使用表达式对结果进行过滤
save 将搜索结果保存为外部csv文件
transaction 将结果分组形成交易日志组合
top 对字段进行数量和百分比统计
6.数据统计分析－SPL语法－样例说明 14
hostname:10-10-17-113
appname: ucloud_nginx
tag: ucloud_access
logtype: apache －－日志类型
agent_send_timestamp: 1466172882411
apache.clientip: 119.129.209.5 －－来源ip
apache.geo.city: 广州市 －－geo地理信息
apache.geo.country: 中国
apache.geo.isp: 中国电信
apache.geo.province:广东
apache.method: GET －－请求方法
apache.referer: https://zrstny.u.rizhiyi.com/sources/input/ssa/ －－来源
apache.referer_domain.subdomain: zrstny
apache.req_time: 0.098 －－请求时长
apache.request_path:/api/v0/sources/upload_volum_info/ －－uri
apache.resp_len: 100 －－请求长度
apache.status: 200 －－请求结果代码
apache.ua.browser: Chrome －－浏览器信息
apache.ua.browser_v:Chrome 49.0.2623
apache.ua.device: Other
apache.ua.os: Windows 7
apache.ua.os_v: Windows 7
apache.upstream_resp_time: 0.098
apache.version: 1.1
timestamp: 1466172877000 －－日志产生时间
6.数据统计分析－SPL语法－eval 14
1. if(X, Y, Z)
Spl:
logtype:apache | eval desc = if (apache.status==200, "OK", "Error")
结果：
对eval出来的字段进行统计：
logtype:apache | eval desc = if (apache.status==200, "OK", "Error")|stats count(desc) by
desc
6.数据统计分析－SPL语法－eval 14
2. case(X, “Y”, ...􏰧 [default, Z])
Spl:
logtype:apache | eval
desc=case(apache.resp_len500,"high",default,"middle") | stats
count(desc) by desc
结果：
6.数据统计分析－SPL语法－eval 14
3. todouble(x), tolog(x) 对于原来是字符型的字段，如果需要进行计算，则需要先转成数值型
Spl:
logtype:apache | eval int_status= tolong(apache.status)
4. formatdate(x) unix时间转成指定／默认时间格式
Spl: