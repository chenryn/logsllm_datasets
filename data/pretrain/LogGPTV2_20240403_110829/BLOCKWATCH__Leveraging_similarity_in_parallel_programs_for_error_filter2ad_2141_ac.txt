15
16
17
18
19
20
21 bool visitInst ( inst ) {
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
category,
}
}
} else{ // op is NA
}
return false ;
Category category = NA;
for (op in operands) {
if (op is constant/global) {
category = lookupTable(
‘‘ share’’ );
} else if (op is thread id) {
category,
category = lookupTable(
} else if (op in categorymap) {
‘‘ threadID’’ );
category = lookupTable(
category, categorymap[op]);
Category old = categorymap[inst];
categorymap[inst] = category;
return (category != old );
EXAMPLE OF CATEGORY PROPAGATION ALGORITHM ON FIGURE 2
TABLE III
Initial
Variables
and
Branches
shared
test
NA
arg
i
NA
Branch 1 NA
Branch 2 NA
1st
it-
eration
2nd it-
eration
3rd it-
eration
shared
shared
shared
NA
NA
shared
shared
shared
shared
shared
shared
shared
shared
shared
shared
Final
Cate-
gory
shared
shared
shared
shared
shared
the visit function (lines 4 - 9) on the instruction. This process is
repeated until there are no more changes in the instructions’
similarity categories. The categorymap contains the inferred
categories of all similar branches at the end of the iterations.
The other branches are assigned to none in line 18.
The visitInst function(lines 23 - 36) takes an instruction as
an argument, and walks through each of its operands in turn.
For each operand, it infers the similarity category based on the
category of the operand or by looking up the operand in the
categorymap. Then it calls function lookupTable (not shown
in ﬁgure) with the current instruction’s category as well as
the category of the operand. The lookupTable function uses
Table II to ﬁnd the similarity category of the current instruction
and update it accordingly.
Note that the algorithm terminates in a ﬁnite number of
iterations (say k) because the number of similarity categories is
ﬁnite and the updated categories in Table II ﬂow monotonically
(i.e., in one direction only). Also, each iteration is proportional
to the number of instructions in the program (say N). In the
worst case, ‘k’ can be at most equal to ‘N’, and hence the
worst-case complexity of the algorithm is O(N 2). In practice,
‘k’ is less than ten for the programs we studied.
Example: We illustrate the algorithm in Figure 3 with the
example in Figure 2. Table III shows the similarity categories
of the variables and branches in the example after each
iteration of the algorithm. The variables are used as proxies
for the instructions that deﬁne them (these are not visible at
the source code level) 5. The algorithm converges within three
iterations in this example. Note that the categories of the two
branches in the ﬁrst iteration are NA because in SSA form,
the deﬁnition instruction of variable i has two operands: 0 and
i + 1, and i + 1 is executed after the branch 1 and branch 2.
Therefore, when we visit the two branches in the ﬁrst iteration,
the category of i is still NA and hence the branches’ categories
are not updated. Later in this iteration, the category of i is
determined as shared and the two branches’ categories are
changed in the 2nd iteration, after which there are no more
changes and hence the process is terminated.
Optimizations: We perform two optimizations over the
base algorithm in Figure 3 to improve the coverage and the
performance of the technique.
Because the algorithm for inferring static branch similarity
is conservative, it will label some branches as none even
if there is a single operand that
it determines as private
(not shared). However, in practice we ﬁnd that considerable
similarity exists even in these branches, as the private variable
may have the same value across threads. We therefore promote
Fig. 3. Pseudo-code to show the similarity category identiﬁcation algorithm
5In SSA form, instructions and variables are synonymous with each other.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:48:23 UTC from IEEE Xplore.  Restrictions apply. 
such branches to the partial category and only compare the
threads which have the same value for the private variable.
In some cases, a branch can be executed by no more than
one thread at a time (e.g., branches inside critical sections).
We remove the checks on such branches as BLOCKWATCH
needs a minimum of two threads to detect errors that violate
the threads’ similarity. Checking such branches would incur
runtime overheads while providing no coverage beneﬁt. We
assume that the program has no race conditions which violate
this constraint.
B. Runtime Checking
This section details the implementation of a runtime mon-
itor to check the statically inferred similar branches in Sec-
tion III-A. The monitor is spawned as a separate thread in
the program (BLOCKWATCH adds instrumentationto spawn
the monitor thread), and has three design goals as follows.
1) Asynchronous: The monitor must interfere minimally
with the program’s execution. In particular, it should not
be in the critical path of the program, and must execute
asynchronously with the program’s threads.
2) Unique branch identiﬁer and fast lookup: The monitor
must assign a unique identiﬁer for each runtime branch.
Moreover, given a speciﬁc branch identiﬁer, it must be
possible to do a fast lookup of the branch’s runtime
characteristics of different threads. The two requirements
are important for correlating the information across
multiple threads when storing the branches’ runtime
behaviors.
3) Lock freedom: The monitor must acquire no locks, as
doing so may introduce deadlocks in the program, and
also lead to unnecessary serialization of the program.
Architecture: We achieve goals 1 and 3 through sepa-
rate lock-free front-end queues adapted from Lamport’s algo-
rithm [15] for each thread to send its branch information. The
monitor thread asynchronously scans the queues and processes
the information without using any locks. We achieve goal 2
through the use of a back-end hash table to store the branches
based on their identiﬁers. The architecture of the monitor is
illustrated in Figure 4.
Operation: The operation of the monitor is as follows:
• When a branch is executed by a thread in the program,
it will execute an instrumentation function that transfers
the branch’s information to the monitor. This function is
inserted by the compiler for the branches identiﬁed as
similar by the algorithm in Section III-A.
• The function appends the branch information to the
thread-speciﬁc front-end queue of the monitor (recall that
in a shared memory architecture, the entire address space
is visible to all the threads), without taking a lock. The
function returns immediately after the insertion.
• The monitor thread asynchronously removes the branch
information from the thread-speciﬁc front-end queues in
round robin fashion. No lock is required as the removal
is done from the front of the queue while the insertion is
done at the back. Further the queues are of ﬁxed length6,
so there is no need to dynamically allocate memory.
• The monitor thread inserts the branch information into the
back-end hash-table using the identiﬁer of the branch as
6We set the queue length to a sufﬁciently large value to prevent it from
being a bottleneck. This value can be modiﬁed if needed.
Fig. 4. Architecture of the runtime monitor in BLOCKWATCH
the key (see below). Thus, all instances of a given branch
across different threads will occupy the same entry in the
hash table.
• Once all threads have reported the outcomes of a speciﬁc
branch, the monitor checks them by reading the hash table
entry corresponding to the branch.
Instrumentation: We instrument the similar branches iden-
tiﬁed by the static analysis algorithm in Section III-A with
calls to our custom library, which send the branches’ runtime
behaviours to the monitor.
We illustrate the instrumentation with an example. Figure 5
shows the instrumentation added for branch 4 in Figure 1.
Recall that this branch belongs to the partial category. The
library calls are highlighted with boldface in Figure 5, and
consist of the following two functions.
• sendBranchCondition: Sends the branch condition to the
monitor, so that the monitor can check if all threads for
which the condition variable is identical, have the same
branch outcome.
• sendBranchAddr: Sends the branch address to the moni-
tor, so that the monitor can compare the target addresses
of all threads for which the condition is the same.
In both cases, the functions send the static branch identiﬁer,
the outer loop iteration number, and the thread ID. The former
two ﬁelds are used to ﬁnd the hash table key of the branch,
while the thread ID is used to identify which thread sends the
data.
Hash table Key: The hash table key of a branch is
obtained by combining its static identiﬁer with a runtime
identiﬁer. The static identiﬁer encodes the static position of
the branch in the program. Each branch within a function
or loop is assigned the same static identiﬁer. The runtime
identiﬁer distinguishes among different instances of the branch
in different loop iterations and at different call sites (through
instrumentation). This is obtained by dynamically encoding
the call stack corresponding to the parent function’s invocation
and the loop iterations of outer loops. The combination of the
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:48:23 UTC from IEEE Xplore.  Restrictions apply. 
1 void slave() {
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
} else {
}
}
...
sendBranchCondition(4 /∗static branch ID∗/, procid,
private /∗condition∗/ ,
/∗ loop iter here means the loop iteration
number of all outer loops∗/
loop iter );
// Branch 4: Partial
if ( private > 0) {
sendBranchAddr(4 /∗static branch ID∗/, procid,
TAKEN /∗behavior∗/, loop iter);
...
sendBranchAddr(4 /∗static branch ID∗/, procid,
NOTTAKEN /∗behavior∗/, loop iter);
Fig. 5. Example code to show the instrumented program
static and runtime identiﬁer yields a unique hash table key for
each runtime instance of a branch. This key is used to store
the information about the branch in the hash table by each
thread that executes it.
We implement the hash table as a two level table. In the
ﬁrst level, the function’s call site ID (added by instrumented
code) and the static branch identiﬁer is used to generate the
key. In the second level, the loop iteration number of all outer
loops is used to generate the key. We separate the function’s
call site IDs and the loop iteration numbers to achieve better
utilization of the memory and reduction of access times. We
describe these and other optimizations made to the hash table
in more detail in the technical report version of this paper [16].
IV. EXPERIMENTAL SETUP
In this section, we ﬁrst describe the tools used in implement-
ing BLOCKWATCH. Then we describe the benchmarks used to
evaluate BLOCKWATCH. Finally, we discuss how we evaluate
the performance and the fault coverage of BLOCKWATCH.
Implementation Tools: We implement BLOCKWATCH
using the LLVM compiler infrastructure [17]. LLVM is a
compilation infrastructure for lifelong program analysis and
transformation. It has an intermediate representation (IR)
that uses Static Single Assignment (SSA) form. The IR is
manipulated by our custom passes before being compiled to
machine code. We ﬁrst compile the program to LLVM IR
and apply BLOCKWATCH’s static analysis to: (1) analyze the
program’s IR and ﬁnd the similarity category for each branch;
(2) instrument the program’s IR with calls to our custom
library. For each of the benchmarks, the static analysis and
instrumentation passes take less than 1 second on a quad-core
core i7 machine with 8 GB RAM. Finally, we compile the
instrumented IR to machine code on our target platform. We
also use the Boost library’s hash table in the runtime monitor’s
implementation [18].
Benchmarks: We use seven programs in the SPLASH-
2 Benchmark Suite [13] for evaluating BLOCKWATCH. The
SPLASH-2 Benchmark Suite has been extensively used for
studies of shared memory parallel programs. We use the de-
fault conﬁgurations of the suite except that we vary the number
of threads in order to study the scalability of BLOCKWATCH.
Table IV describes the characteristics of the programs. In the
table, the parallel section refers to the part of the program
which is executed concurrently by two or more threads.
Because BLOCKWATCH relies on the similarity across threads
to detect errors, we focus on the parallel section of the program
in reporting the similarity categories assigned to branches.
CHARACTERISTICS OF BENCHMARK PROGRAMS
TABLE IV
Benchmark Total
lines
of
code
(LOC)