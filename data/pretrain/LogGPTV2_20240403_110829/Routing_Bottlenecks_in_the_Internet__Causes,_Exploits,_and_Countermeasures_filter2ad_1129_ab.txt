if a link carries 10% of routes between S and D, its nor-
malized occurrence is 0.10. We observe that the normalized
link-occurrence distribution is accurately modeled by Zipf-
Mandelbrot distribution; namely,
f (k) (cid:24) 1=(k + (cid:12))(cid:11);
(1)
where k is the rank of the link, (cid:11) is the exponent of the
power-law distribution, and (cid:12) is the (cid:12)tting parameter. Ex-
ponent (cid:11) is a good measure of route concentration, or dis-
tribution skew, and hence of bottleneck size: the higher (cid:11),
the sharper concentration of routes in few links. Fitting pa-
rameter (cid:12) captures the (cid:13)atter values in the high-rank region
(i.e., lower values on the x-axis). This region is not modeled
as well by an ordinary Zipf distribution since its probabil-
ity mass function would be a straight line in log-log scale
on the entire range. The phenomenon of (cid:13)atter occurrence
in high-rank region is due to the nature of link sampling
via route measurement; that is, multiple links are sampled
together when each route is measured and there exist no
duplicate link samples in a route in general due to the loop-
freeness property of Internet routes. Thus, the occurrence
of extremely popular links are limited.4
To enable comparison of route concentration in a few links
of di(cid:11)erent destination regions, we (cid:12)x the (cid:12)tting parameter
(cid:12) and (cid:12)nd the values of exponent (cid:11) for the best (cid:12)t across
the (cid:12)fteen countries; i.e., (cid:12) = 7:8 causes the smallest (cid:12)tting
error.
In Fig. 2 and Fig. 14 (Appendix A), the (cid:12)fteen
countries and cities are ordered by increasing value of (cid:11) in
the range 1.31 { 2.36.
2.3 Causes
What causes routing bottlenecks, or high skew/power-law
distribution of link occurrence? Often, power-law distribu-
tions (especially Zipf-Mandelbrot distribution) arise from
4The same phenomenon was explained and validated by the
similar characteristics of data samples in [18].
Figure 3: Normalized link occurrence/rank in sim-
ulated inter-AS links in three countries.
processes that involve some cost minimization; e.g., mini-
mization of human-communication cost [30, 51]. Thus, one
would naturally expect that power-laws in link-occurrence
distributions are caused by the cost minimization criteria
used for route selection and network design in the Internet;
i.e., both intra- and inter-domain interconnections and rout-
ing in the Internet. Extra cost minimization is provided by
the \hot-potato" routing between domains.
2.3.1 Cost minimization in inter-domain routing
Inter-domain routing policy creates routing bot-
tlenecks in inter-AS links: BGP is the de facto routing
protocol for inter-domain (i.e., AS-level) Internet connectiv-
ity. The rule-of-thumb BGP policy for choosing inter-AS
paths is the minimization the network’s operating cost; i.e.,
whenever several AS paths to a destination are found, the
minimum-cost path5 is selected. This policy is intended to
minimize operating costs of routing in the Internet [15, 17].
To determine whether the rule-of-thumb routing policy
contributes to the creation of routing bottlenecks, we run
AS-level simulations on the CAIDA’s AS topology6 and com-
pare the operation of the rule-of-thumb routing policy (i.e.,
policy I) and a hypothetical routing policy that distributes
routes uniformly across possible inter-domain links (i.e., pol-
icy II). This hypothetical routing policy favors inter-domain
links that serve fewer AS paths for a particular destination.
We simulate this policy by Dijkstra’s algorithm with dy-
namically changing link weight, which are proportional to
the number of BGP paths served.
Fig. 3 shows the normalized link occurrence/rank plots
for inter-AS links when we create BGP paths from all stub
ASes to the ASes in Country1, Country8, and Country15 ac-
5If there exist multiple same cost paths, the shortest path
is selected.
6We use the dataset available for June 2012 from http://
www.caida.org/data/active/as-relationships/
3
Rank of LinkNormalized Link OccurrenceLegend:10010210410−5100Country15α=2.3610010210410−5100Country14α=2.3210010210410−5100Country13α=2.3110010210410−5100Country12α=1.8610010210410−5100Country11α=1.8510010210410−5100Country10α=1.8210010210410−5100Country9α=1.7610010210410−5100Country8α=1.6010010210410−5100Country7α=1.4810010210410−5100Country6α=1.4010010210410−5100Country5α=1.3810010210410−5100Country4α=1.3610010210410−5100Country3α=1.3310010210410−5100Country2α=1.3210010210410−5100Country1α=1.31MeasuredOccurrencePMF ofZipf−Mandelbrot(β = 7.8)10010210410−5100Country1α=1.31  10010210410−5100Country9α=1.76  MeasuredOccurrencePMF ofZipf−Mandelbrot(β = 7.8)Rank of (Inter−AS) Links     Normalized Link Occurrence10010110210−5100Country10.370.0810010110210−5100Country80.910.0610010110210−5100  Legend:Country150.930.14policy Ipolicy IIinter-AS links connecting two ASes and thus aggravates the
routing bottlenecks at the inter-AS links.
2.4 Characteristics
In this subsection we investigate the characteristics of the
links in the routing bottlenecks in terms of link types (e.g.,
intra-AS links, inter-AS links, or IXP-connecting links) and
distance from the hosts in the target region (e.g., average
router hops) as a backdrop to the design of countermeasures
against attacks that exploit bottleneck links. The variety of
link types found and their distribution make it impossible to
design a single ‘one-size-(cid:12)ts-all’ countermeasure. Instead, in
Section 5, we discuss several practical countermeasures that
account for the speci(cid:12)cs bottleneck link types.
2.4.1 Link types
We (cid:12)rst categorize the three link types based on their roles
in the Internet topology: intra-AS links, which connect two
routers owned by the same AS, inter-AS links, which con-
nect routers in two di(cid:11)erent ASes, and IXP-connecting links,
which connect to routers in IXPs. Although the link types
are clearly distinguished in the above de(cid:12)nitions, the infer-
ence of link types via traceroute is known to be surprisingly
di(cid:14)cult and error prone due to potential inference ambigu-
ity [32]. For example, the AS boundary ambiguity [32] arises
because routers at AS boundaries sometimes use IPs bor-
rowed from their neighbor ASes for their interfaces. This is
possible because the IPs at the both ends of the inter-AS
links are in the same pre(cid:12)x. Borrowed IPs make it di(cid:14)cult
to determine whether a link is an intra- or inter-AS link.
Our method of determining link type eliminates the AS
boundary ambiguity by utilizing route diversity at the bot-
tleneck links. Unlike the previous analysis [32, 21], our ex-
periment measures a large number of disjoint incoming/outgoing
routes to/from a bottleneck link. In other words, we gather
all visible links 1-hop before/after the bottleneck link, and
this additional information helps us infer the link types at
AS boundary without much ambiguity.8
Fig. 5 summarizes the percentage of the link types of the
50 most occurred links for each of the 15 countries. The
average percentage of all 15 countries is presented in the
rightmost bar. Notice that the intra-AS and the inter-AS
links are further categorized by the AS types, i.e., Tier-1,
Tier-2, and Tier-3 ASes. The list of Tier-1 ASes are obtained
from the 13 selected ASes in Renesys’ Baker’s Dozen9; Tier-3
ASes are the ones that have no customer but only providers
or peers; and the rest of the ASes are labeled as Tier-2 ASes.
Our investigation found three interesting results. The (cid:12)rst
is that the link types are approximately evenly distributed.
On average (see the rightmost bar in Fig. 5) 30% of them
are intra-AS links, 30% are inter-AS links, and 20% are
IXP-connecting links. The rest of 20% is not determined
due to lack of traceroute visibility. We note that the intra-
AS bottleneck links are located either in Tier-1 or Tier-2
ASes, but never in Tier-3 ASes. This high percentage of
intra-AS bottleneck links in Tier-1 or Tier-2 ASes contra-
dicts the common belief that large ISPs distribute routes
over their internal links very well using complete knowledge
8For IP to ASN mapping, we utilize a public IP-to-ASN
mapping database by Cymru (https://www.team-cymru.
org/Services/ip-to-asn.html).
9http://www.renesys.com/2014/01/
bakers-dozen-2013-edition/
Figure 4: Normalized link occurrence/rank in sim-
ulated AS-internal routes for three ISPs.
cording to the two BGP policies. To clearly see the di(cid:11)erent
skew of the link occurrence distribution of the two policies,
we measure the slopes of link distributions in log-log scale in
the high-rank region.7 Country1 and Country8 have barely
observable skew in this region (i.e., slope less than 0.1) with
policy II while they have much higher skew (i.e., slope of
0.37 { 0.91) with policy I. Country15 has a small skew (i.e.,
slope of 0.14) with policy II and a much higher skew of 0.93
with policy I. This suggests that, even though inter-domain
Internet routes may have no physical bottlenecks (or very
few, as in Country15), the BGP cost-minimization policy
creates inter-domain routing bottlenecks.
2.3.2 Cost minimization in intra-domain network topol-
ogy and routing
Internal AS router-level topology creates intra-
domain routing bottlenecks: Most ISPs build and man-
age hierarchical internal network structures for cost mini-
mization [42, 27] and these structures inherently create rout-
ing bottlenecks within ISPs. An ISP is composed of multiple
points of presence (or POPs) in di(cid:11)erent geographic loca-
tions and they are connected via few high-capacity backbone
links. Within each POP, many low-to-mid capacity access
links connect the backbone routers to the border routers.
In general, ISPs aim to minimize the number of expensive
long-distance high-capacity backbone links by multiplexing
as much tra(cid:14)c as possible at the few backbone links [27].
As a result, backbone links become routing bottlenecks. To
show this, we carry out simulations using Tier-1 ISP topolo-
gies inferred by Rocketfuel [42]. We construct ingress-egress
routes for all possible pairs of access routers using shortest-
path routing [29]. Fig. 4 shows the simulated normalized
link occurrence/rank for the three ASes belonging to di(cid:11)er-
ent ISPs. In all three ASes, we (cid:12)nd that the Zipf-Mandelbrot
distribution (cid:12)ts accurately with high value of (cid:11) (i.e., 1.77 {
1.89) when (cid:12) is deliberately (cid:12)xed to 2.10 for best (cid:12)tting and
direct skew comparison; that is, a few AS internal links are
extremely heavily used whereas most other internal links are
very lightly used. Moreover, most of the heavily used links
(i.e., 70%, 70%, and 90% of 10 most heavily used links in
each of the three ISPs, respectively) are indeed backbone
links that connect distant POPs. We recon(cid:12)rm this later
in Section 2.4.1 where we (cid:12)nd that a large percentage (i.e.,
30%) of links in routing bottlenecks are intra-AS links.
Hot-potato routing policy in ISPs aggravates inter-
domain routing bottlenecks: The hot-potato routing pol-
icy is another example of a cost-minimization policy used by
ISPs; i.e., this policy chooses the closest egress router among
multiple egress routers to the next-hop AS [47]. As already
reported [50], this policy causes a load imbalance at multiple
7Since the link-occurrence distribution of policy II is not
modeled by Zipf-Mandelbrot distribution, we simply mea-
sure the slope in the high rank region to compare the skew.
4
Rank of (Intra−AS) Links     Normalized Link Occurrence10010210−510−310−1AS3257α=1.7710010210−510−310−1AS6461α=1.7810010210−510−310−1  AS1755α=1.89simulatedlink occurrenceZipf−Mandelbrot(β = 2.1)Figure 5: Percentage of link types of the 50 most occurred links for each of the 15 countries. Three link
types (i.e., intra-AS links, inter-AS links, and IXP-connecting links) and three AS types (i.e., Tier-1, Tier-2,
and Tier-3) are used for categorization.
Figure 6: Router-hop distance of 50 bottleneck links
for each of the 15 countries from the target regions.
of, and control over, their own networks. This unexpected
result implies that, in practice, large ISPs (both Tier-1 and
Tier-2) are responsible for a large portion of the bottlenecks.
The second interesting observation is that inter-AS links are
also a common type of bottleneck links and the majority of
these are connecting Tier-1 ASes. Again, we conclude that
the Tier-1 ASes are responsible for the majority of inter-AS
bottleneck links as well. The third interesting observation
is that IXPs are another very popular type bottleneck links.
This result is consistent with the recent trend of increasing
popularity of IXPs [2].
2.4.2 Link distance
We also measure the router-hop distance of the bottle-
neck links from the hosts in the target regions. To measure
a bottleneck link’s distance, we take the average of router-
hop distances from the multiple hosts in the region. One
challenge in measuring the router-hop distance via tracer-
oute is that more than half of the destinations used have
(cid:12)rewalls in their local networks, which prevents discovery of
the last few router hops from the destinations. When tracer-
oute does not reach a destination we assume the presence of
an invisible (cid:12)rewall that is directly followed by the destina-
tion. Thus, our distance is a strict lower-bound of the real
distance from destination hosts.
Fig. 6 shows the average and standard deviation of the
link distance of the 50 bottleneck links for each of the 15
countries. The average distance ranges from 6 to 10 router
hops with average of 7.9 hops and no signi(cid:12)cant di(cid:11)erences
were found across the 15 countries. Considering the average
length of Internet routes is approximately 17 router hops
[12], we conclude that the bottleneck links are located in the
Figure 7: Connectivity degradation in the Ark
dataset relative to the PlanetLab dataset for 50
(cid:13)ooding links selected from the routes measured by
the PlanetLab nodes.
middle to the slightly closer to the target region on the routes
to the target. The distance analysis is also consistent with
the observation that the most bottleneck links are within or
connecting Tier-1 ASes.
3. ACCURACY OF BOTTLENECK MEASURE-
MENTS
3.1 Independence of Route Sources
One of the common pitfalls in Internet measurements is
the dependency on vantage point; that is, the location where
a measurement is performed can signi(cid:12)cantly a(cid:11)ect the in-
terpretation of the measurement [38]. Here we argue that
our routing-bottleneck results are independent of the selec-
tion of route sources S. To show this, we validate our com-
putation of routing-bottleneck results by comparing the con-
nectivity degradation10 calculated using the original source
set S (i.e., 250 PlanetLab nodes) with that calculated using
(i.e., 86 Ark monitors),11 as
an independent source set S
shown in Fig. 7. Notice that we select 50 bottleneck links
for each country by analyzing the routes measured by Plan-
0
10Connectivity degradation is measured in terms of degrada-
tion ratio, which will be explained in detail in Section 4.2.