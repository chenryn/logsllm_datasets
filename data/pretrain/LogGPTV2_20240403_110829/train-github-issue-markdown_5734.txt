 **Documentation issue**
In the documentation of PyTorch 1.0.1. It is mentioned that:
> batch_first â€“ If True, then the input and output tensors are provided as
> (batch, seq, feature). Default: False
So I would expect the ouput tensor h_n of shape: (batch, num_layers *
num_directions, hidden_size). But it is not the case. The batch is the second
dimension, which does not match with the above statement from the
documentation.
## To Reproduce
Steps to reproduce the behavior:
    input = torch.rand([60, 8, 256]) #batch size is 60, sequence size is 8, features are 256
    lstm = torch.nn.LSTM(256, 512, batch_first=True)
    _, (finalHiddenState, _) = lstm(input)
    print(finalHiddenState.shape)
    Ouput: torch.Size([1, 60, 512]) 
Batch (60) is now the second dimension here