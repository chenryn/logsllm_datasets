title:Protecting accounts from credential stuffing with password breach
alerting
author:Kurt Thomas and
Jennifer Pullman and
Kevin Yeo and
Ananth Raghunathan and
Patrick Gage Kelley and
Luca Invernizzi and
Borbala Benko and
Tadek Pietraszek and
Sarvar Patel and
Dan Boneh and
Elie Bursztein
Protecting accounts from credential stuffing with 
password breach alerting
Kurt Thomas, Jennifer Pullman, Kevin Yeo, Ananth Raghunathan, Patrick Gage Kelley, 
Luca Invernizzi, Borbala Benko, Tadek Pietraszek, and Sarvar Patel, Google; Dan Boneh, 
Stanford; Elie Bursztein, Google
https://www.usenix.org/conference/usenixsecurity19/presentation/thomas
This paper is included in the Proceedings of the 28th USENIX Security Symposium.August 14–16, 2019 • Santa Clara, CA, USA978-1-939133-06-9Open access to the Proceedings of the 28th USENIX Security Symposium is sponsored by USENIX.Protecting accounts from credential stufﬁng with password breach alerting
Kurt Thomas∗ Jennifer Pullman∗ Kevin Yeo∗ Ananth Raghunathan∗
Patrick Gage Kelley∗ Luca Invernizzi∗ Borbala Benko∗ Tadek Pietraszek∗
Sarvar Patel∗ Dan Boneh(cid:5) Elie Bursztein∗
Google∗ Stanford(cid:5)
Abstract
Protecting accounts from credential stufﬁng attacks remains
burdensome due to an asymmetry of knowledge: attackers
have wide-scale access to billions of stolen usernames and
passwords, while users and identity providers remain in the
dark as to which accounts require remediation. In this paper,
we propose a privacy-preserving protocol whereby a client can
query a centralized breach repository to determine whether
a speciﬁc username and password combination is publicly
exposed, but without revealing the information queried. Here,
a client can be an end user, a password manager, or an identity
provider. To demonstrate the feasibility of our protocol, we
implement a cloud service that mediates access to over 4
billion credentials found in breaches and a Chrome extension
serving as an initial client. Based on anonymous telemetry
from nearly 670,000 users and 21 million logins, we ﬁnd that
1.5% of logins on the web involve breached credentials. By
alerting users to this breach status, 26% of our warnings result
in users migrating to a new password, at least as strong as
the original. Our study illustrates how secure, democratized
access to password breach alerting can help mitigate one
dimension of account hijacking.
1 Introduction
The wide-spread availability of usernames and passwords
exposed by data breaches has trivialized criminal access to
billions of accounts. In the last two years alone, breach com-
pilations like Antipublic (450 million credentials), Exploit.in
(600 million credentials), and Collection 1-5 (2.2 billion cre-
dentials) have steadily grown as their creators aggregated
material shared on underground forums [21, 25]. Despite the
public nature of this data, it remains no less potent. Previ-
ous studies have shown that 6.9% of breached credentials
remain valid due to reuse, even multiple years after their ini-
tial exposure [51]. Absent defense in depth techniques that
expand authentication to include a user’s location and de-
vice details [12, 17], hijackers need only conduct a credential
stufﬁng attack—attempting to log in with every breached
credential—to isolate vulnerable accounts.
While users (or identity providers) can mitigate this hi-
jacking risk by resetting an account’s password, in practice,
discovering which accounts require attention remains a crit-
ical barrier. This has given rise to breach alerting services
like HaveIBeenPwned and PasswordPing that actively source
breached credentials to notify affected users [26, 43]. At
present, these services make a variety of tradeoffs spanning
user privacy, accuracy, and the risks involved with sharing
ostensibly private account details through unauthenticated
public channels. One consequence of these tradeoffs is that
users may receive inaccurate remediation advice due to false
positives. For example, both Firefox and LastPass check the
breach status of usernames to encourage password reset-
ting [13,42], but they lack context for whether the user’s pass-
word was actually exposed for a speciﬁc site or whether it was
previously reset. Equally problematic, other schemes implic-
itly trust breach alerting services to properly handle plaintext
usernames and passwords provided as part of a lookup. This
makes breach alerting services a liability in the event they
become compromised (or turn out to be adversarial).
In this paper, we present the design, implementation, and
deployment of a new privacy-preserving protocol that allows
a client to learn whether their username and password ap-
pears in a breach without revealing the information queried.
Our protocol offers two main advantages compared to exist-
ing schemes. First, our design takes into account the threat
of both an adversarial client (e.g., an attacker attempting to
steal usernames and passwords from our service) and an ad-
versarial server (e.g., an attacker harvesting usernames and
passwords sent to the service). We address these risks us-
ing a combination of computationally expensive hashing, k-
anonymity, and private set intersection. Second, these privacy
requirements allow us to check a client’s exact username and
password against a database of breached credentials (versus
only usernames, or only passwords currently), thus reducing
false positives that lead to warning fatigue.
To demonstrate the feasibility of our protocol, we publicly
USENIX Association
28th USENIX Security Symposium    1555
released a Chrome extension that warns users when they log
in to a website using one of over 4 billion breached usernames
and passwords. While in theory any identity provider or pass-
word manager can integrate with our protocol, we opted for
in-browser alerting ﬁrst as it scales to the long tail of domains.
Nearly 670,000 users from around the world installed our
extension over a period of February 5–March 4, 2019. During
this measurement window, we detected that 1.5% of over 21
million logins were vulnerable due to relying on a breached
credential—or one warning for every two users. By alerting
users to this breach status, 26% of our warnings resulted in
users migrating to a new password. Of these new passwords,
94% were at least as strong as the original.
Anonymous telemetry reported by our extension reveals
that users reused breached credentials on over 746,000 dis-
tinct domains. The risk of hijacking was highest for video
streaming and adult sites, where 3.6–6.3% of logins relied
on breached credentials. Conversely, users appeared to inter-
nalize password security advice (or were forced to do so via
password composition policies) speciﬁcally for ﬁnancial and
government sites, where only 0.2–0.3% of logins involved
breached credentials. Despite variations across industries, our
analysis reveals that the threat of credential stufﬁng extends
well into the long tail of the Internet. Absent new forms of au-
thentication, we believe that it is critical to democratize access
to breach alerting so that both users and identity providers
can proactively resecure their accounts.
In summary, we frame our key contributions as follows:
• We develop and publicly release a new protocol for
detecting whether a username and password pair ap-
pears in a data breach without revealing the informa-
tion queried. Our protocol improves on the privacy of
existing schemes while also reducing the risk of false
positives.
• We outline the technical challenges of deploying this
scheme in practice, including the computational over-
head, latency, and cost required to mediate access to over
4 billion breached usernames and passwords.
• Based on a real-world deployment, we ﬁnd that 1.5% of
logins across the web involve breached credentials. We
caution this is a lower bound as logins are not unique.
Roughly one in two of our 670,000 users received a
warning.
• Users responded to 26% of our warnings by resetting
their password; 94% of new passwords were as strong
or stronger than the original passwords.
2 Background and requirements
To start, we establish the design principles and threat model
that underpin our breach alerting protocol. We compare these
Figure 1: Abstract protocol for a breach alerting service. At a
high level, a client generates a request based on some compu-
tation over a username and password. The server then returns
a response that allows the client to arrive at a verdict for
whether their credential is in a breach.
requirements against existing solutions from HaveIBeen-
Pwned and PasswordPing—as well as related cryptographic
protocols like private information retrieval and oblivious
transfer—to highlight the tradeoffs that all of these approaches
make in terms of privacy, overhead, accuracy, and trust.
2.1 Abstract protocol
We provide an abstract protocol for our breach alerting ser-
vice in Figure 1. We reuse these function names and termi-
nology throughout our work. Here, a client with access to
a username and password tuple (u, p) executes some com-
putation via CreateRequest(u, p) that produces a local state
LS and request Req that it sends to the breach alerting ser-
vice. This service stores and regularly updates a database of
unsafe credentials S = {(u1, p1), . . . , (un, pn)}. Upon receiv-
ing a request, the server accesses its credential store S, runs
CreateResponse(S, Req), and sends the resulting response
Resp to the client. Finally, the client arrives at a verdict
whether the credential queried was exposed through a breach
by calculating Verdict(Resp, LS). Because new breaches
emerge over time, a client should regularly repeat this process
as prior verdicts may no longer be valid.
2.2 Design principles
Democratized access: At present, identity providers indi-
vidually collect breached password data to reset their af-
fected user accounts [4, 58]. This fails to scale to all identity
providers, resulting in patchy protection across services and
incidents. Any breach alerting service should be accessible to
all end users and identity providers, and as such, not require
trust between the parties involved. This means we cannot
rely on authenticated accounts as a form of rate limiting. We
deﬁne trust more formally in our threat model in Section 2.3.
Actionable, not informational: Any breach alerting service
should provide users with accurate and actionable security ad-
1556    28th USENIX Security Symposium
USENIX Association
ClientServerCreateRequest(u,p)LSCreateResponse(S, Req)Verdict(Resp, LS){true, false}ReqRespvice such as re-securing an account via a password reset. An
alert that warns a client about the mere presence of exposed
data such as a client’s email address, phone number, or physi-
cal address lacks a straightforward recovery step and is thus
out of scope for our design. Similarly, an alert merely warning
a client that password material was exposed (rather than the
speciﬁc password involved) may lead to false positives.
Breached, not weak: Alerting should only trigger when all
the information necessary to access an account (e.g., a user-
name and password) is exposed. While cracking dictionar-
ies (often composed from breached passwords) may include
a client’s weak, guessable password, any subsequent attack
potentially requires multiple guesses and thus represents a
smaller threat than full credential exposure. We assume that
most online services employ sufﬁcient throttling to make such
bruteforcing impractical. Conversely, attacks against exact
username and password pairs are actively deployed in the
wild. Indeed, Thomas et al. showed that users with non-stale
credentials exposed by third-party breaches were ten times
more likely to become hijacked than a random user [51]. Our
emphasis on breached credentials helps us prioritize scarce
user attention [5] and avoid potential warning fatigue sim-
ilar to other warning models [2]. While migrating users to
stronger passwords in general remains an important task, it is
out of scope for our design.
Near real-time: The time that elapses between a client query-
ing a credential and learning its breach status should be near
real-time in order to facilitate integration directly with ac-
count security ﬂows, password managers, or upon password
entry. This potentially constrains the level of privacy protec-
tions provided by any protocol due to computational overhead
and network latency of any cryptographic primitives involved.
2.3 Threat model
Democratized access hinges on mutual distrust between a
client and the server involved in our breach alerting proto-
col. We develop our threat model with both an adversar-
ial client and adversarial server in mind. In the case of an
adversarial client with access to their own breach dataset
D = {(u1, p1), . . . , (un, pn)}, the attacker seeks to learn u ∈
S − D (e.g., a new email to spam), p ∈ S − D (e.g., a new
password to add to a cracking dictionary), or a new credential
(u, p) ∈ S− D. In the case of an adversarial server where a
client has access to (u, p), the threat landscape is larger. An
adversarial server may learn the client’s identity u (even if
u ∈ S, this enables tracking), a client’s password p (even if
p ∈ S, this identiﬁes active usage), or the credential (u, p)
(even if (u, p) ∈ S).
To address these threats, we outline the minimum security
and privacy requirements any implementation of the abstract
protocol previously outlined in Figure 1 must satisfy. In the
security notions discussed below, we work with anonymity
sets (denoted K) that describe a set of values (in our case,
user credentials) that are large enough to give clients plausi-
ble deniability about their data even if their membership in
K is revealed. These sets must be carefully deﬁned to avoid
trivial constructions that are insecure. At a high-level, they
must have a sufﬁciently large support jointly over usernames
and passwords (to aid in plausible deniability regarding both),
should “partition” the space of credentials in a somewhat
uniform manner independent of any actual usernames or pass-
words, and roughly all values in an anonymity set should be
equally likely to be the client’s credentials. (A full discussion
is deferred to Appendix A.)
Requester credential anonymity: A protocol provides re-
quester credential anonymity if for every credential (u1, p1),
there exists a sufﬁciently large anonymity set K containing
(u1, p1) such that ∀(u2, p2) ∈ K:
CreateRequest(u1, p1) ≈ CreateRequest(u2, p2).
(1)
For two distributions A and B, we let A ≈ B denote the com-
putational indistinguishablity of the two distributions—that
no efﬁcient adversary given samples from A and B can distin-
guish them apart much better than randomly guessing. Thus,
clients with credentials from the same anonymity set cre-
ate requests that are indistinguishable to the server. While a
minimum |K| likely depends on the sensitivities of the client
involved, we set an initial threshold at |K| > 50,000. While
the IP address tied to a client’s request reduces |K|, a client
can rely on a mix network such as Tor to prevent this leakage.
IP address anonymity is out of scope of our threat model.
Responses with bounded leakage: Given a request for
(u, p), the response from a breach alerting service should
bound the information leaked, denoted L, about the mem-
bership of other credentials in S. To do this, we require an
efﬁcient simulator Sim that given only L can act as the server
without being noticed by the client:
CreateResponse(S, Req) ≈ Sim(L, Req).
(2)
The presence of a successful simulator shows that the client
may learn at most L by looking at responses from the server.
Ideally, we want leakage to consist of only the membership
of the queried credential and the anonymity set:
L = ([(u, p) ∈ S], K) .
(3)
We can rephrase this security notion as follows. For any
(u1, p1), (u2, p2) ∈ K such that their membership in S is iden-
tical, i.e., [(u1, p1) ∈ S] = [(u2, p2) ∈ S]:
CreateResponse(S, CreateRequest(u1, p1))
≈ CreateResponse(S, CreateRequest(u2, p2)).
(4)
In other words, our security notion implies that the responses
to credentials with identical leakage will be computationally
indistinguishable.
USENIX Association
28th USENIX Security Symposium    1557
Inefﬁcient oracle: Learning u, p, or (u, p) ∈ S via the breach
alerting service should be equally or less efﬁcient compared
to guessing attempts performed on the login portal where the
account originates from. Alternatively, a pragmatic attacker
should be better off ﬁnding a plaintext copy of the breach. Let
t(f) denote the running time of the function f. We capture this
for a remote attacker as there being a time period T such that:
t(CreateRequest(ui, pi)) > T,
(5)
for every (ui, pi). This requirement extends to an attacker with
direct access to S due to an insider risk, a court order, or a
breach of the alerting service’s database. We frame this as
merely checking the membership of a credential:
t ([(u, p) ∈ S]) > T(cid:48).
(6)
Ideally, T = T(cid:48), such that local access to S provides no ad-
vantage compared to the access mediated by the protocol.
We consider a protocol where T > 1 second to satisfy this
requirement.
Resistance to Denial of Service: A response from the server
should not require signiﬁcantly more computation than a
request by a client (including bogus requests). As such,
it should be difﬁcult for an attacker to ﬁnd a sequence