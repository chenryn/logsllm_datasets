corresponding characters in the two strings. This can lead
to problems when one of the strings (or both) are labeled.
Note that each character comparison operates on labeled ar-
guments and thus, is a branching point. As a result, when
a labeled string of n characters is compared with another
string, we create n states. Each of the states si : 0 ≤ i ≤ n
represents the case in which the ﬁrst i characters of both
strings match, while the two characters with the offset i + 1
differ. For practical purposes, we typically do not need this
detailed resolution for string comparisons. The reason is
that most of the time, a program only distinguishes between
the two cases in which both strings are either equal or not
equal. To address this problem, we implemented a heuris-
tics that attempts to recognize string comparisons. This is
implemented by checking for situations in which the same
compare instruction is executed repeatedly, and the argu-
ments of this compare have addresses that increase by one
on every iteration. When such a string comparison is en-
countered, we do not branch on every check. Instead, we
explore one path where the ﬁrst characters are immediately
different, and a second one in which the two strings match.
This optimization avoids the signiﬁcant increase of the over-
all number of states that would have to be processed other-
wise (often without yielding any additional information).
4.4 Limitations
In Section 4.1, we discussed our approach of never re-
turning any allocated resource to the operating system. The
goal was to avoid invalid handles that would result when a
process ﬁrst closes a handle and is then reset to a previous
snapshot (in which this handle is still valid). Our approach
works well in most cases. However, one has to consider
situations in which a process creates external effects, e.g.,
when writing to a ﬁle or sending data over a network.
There are few problems when a program writes to a ﬁle.
The reason is that the ﬁle pointer is stored in user memory,
and thus, it is automatically reset to the previous value when
the process is restored. Also, as mentioned previously, ﬁles
are never closed. Unfortunately, the situation is not as easy
while handling network trafﬁc. Consider an application that
opens a connection to a remote server and then exchanges
some data (e.g., such as a bot connecting to an IRC server).
When reverting to a previous state, the synchronization be-
tween the application and the server is lost. In particular,
when the program ﬁrst sends out some data, is later reset,
and then sends out this data again, the remote server re-
ceives the data twice. Typically, this breaks protocol logic
and leads to the termination of the connection. In our cur-
rent implementation, we solve this problem as follows: All
network system calls in which the program attempts to es-
tablish a connection or sends out data are intercepted and
not relayed to the operating system. That is, for these calls,
our system simply returns a success code without actually
opening a connection or sending packets. Whenever the
program attempts to read from the network, we simply re-
turn a string of random characters of the maximum length
requested. The idea is that because the results of network
reads are labeled, our multiple path exploration technique
will later determine those strings that trigger certain actions
(e.g., such as command strings sent to a bot).
Another limitation is the lack of support for signals and
multi-threaded applications. Currently, we do not record
signals that are delivered to a process. Thus, when a signal
is raised, this only happens once. When the process is later
reverted to a previous state, the signal is not resent. The lack
of support for multi-threaded applications is not a problem
per se. Creating a snapshot for the complete process works
independently of the number of threads. However, to ensure
deterministic behavior our system would have to ensure that
threads are scheduled deterministically.
It might also be possible for specially-crafted malware
programs to conceal some malicious behavior by prevent-
ing our system from exploring a certain path. To this end,
the program has to ensure that a branch operation depends
on a value that is related to other values via non-linear de-
pendencies. For example, malicious code could deliberately
apply non-linear operations such as xor to a certain value.
When this value is later used in a conditional operation, our
system would determine that it cannot be rewritten, as the
related memory locations cannot be updated consistently.
Thus, the alternative branch would not be explored. There
are two ways to address this threat. First, we could replace
the linear constraint solver by a system that can handle more
complex relationships. For instance, by using a SAT solver,
we could also track dependencies that involve bitwise op-
erations. Unfortunately, when analyzing a binary that is
speciﬁcally designed to withstand our analysis, our proto-
type will never be able to correctly invert all operations en-
countered. An example for that are one-way hash functions,
for which our system cannot infer the original data from the
hash value alone. Therefore, a second approach could be to
relax the consistent update requirement. That is, we allow
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:55:25 UTC from IEEE Xplore.  Restrictions apply. 
2007 IEEE Symposium on Security and Privacy(SP'07)0-7695-2848-1/07 $20.00  © 2007our system to explore paths by rewriting a memory loca-
tion without being able to correctly modify all related in-
put values. This approach leads to a higher coverage of the
code analyzed, but we lose the knowledge of the input that
is required to drive the execution down a certain path. In
addition, the program could perform impossible operations
(or simply crash) because of its inconsistent state. However,
frequent occurrences of conditional jumps that cannot be re-
solved by our system could be interpreted as malicious. In
this case, we could raise an appropriate warning and have a
human analyst perform a deeper investigation.
Finally, specially-crafted malware programs could per-
form a denial-of-service attack against our analysis tool by
performing many conditional branches on tainted data. This
would force our system to create many states, which in turn
leads to an exponential number of paths that have to be ex-
plored. One solution to this problem could be to deﬁne
a distance metrics that can compare saved snapshots and
merge sufﬁciently similar paths. Furthermore, we could
also treat a sudden, abnormal explosion of states as a sign
of malicious behavior.
5 Evaluation
In this section, we discuss the results that we obtained by
running our malware analysis tool on a set of 308 real-world
malicious code samples. These samples were collected in
the wild by an anti-virus company and cover a wide range
of malicious code classes such as viruses, worms, Trojan
horses and bots. Note that we performed our experiments
on all the samples we received, without any pre-selection.
The 308 samples in our test set belong to 92 distinct mal-
ware families (in certain cases, several different versions of
a single family were included in the sample set). We clas-
siﬁed these malware families using the free virus encyclo-
pedia available at viruslist.com. Analyzing the re-
sults, we found that 42 malware families belong to the class
of email-based worms (e.g., Netsky, Blaster). 30 families
are classiﬁed as exploit-based worms (e.g., Blaster, Sasser).
10 malware families belong to the classic type of ﬁle in-
fector viruses (e.g., Elkern, Kriz). The remaining 10 fami-
lies are classiﬁed as Trojan horses and backdoors, typically
combined with bot functionality (e.g., AceBot, AgoBot, or
rBot). To understand how wide-spread our malware in-
stances are, we checked Kaspersky’s top-20 virus list for
July 2006, the month that we received our test data. We
found that our samples cover 18 entries on this list. Thus,
we believe that we have assembled a comprehensive set
of malicious code samples that cover a variety of malware
classes that appear in the wild.
In a ﬁrst step, our aim was to understand to which ex-
tent malware uses interesting input to perform control ﬂow
decisions. To this end, we had to deﬁne appropriate input
sources. In our current prototype implementation, we con-
sider the functions listed in Table 1 to provide interesting
input. These functions were chosen primarily based on our
previous experience with malware analysis (and also based
on discussions with experienced malware analysts working
in an anti-virus company). In the past, we have seen ma-
licious code that uses the output provided by one of these
functions to trigger actions. Also, note that adding addi-
tional input sources, if required, is trivial and is not a lim-
itation of our approach. During the analysis, we label the
return values of functions that check for the existence of an
operating system resource. For functions that read from a
resource (i.e., ﬁle, network, or timer), we label the complete
buffer that is returned (by using one label for each byte).
Interesting input sources
Check for Internet connectivity
Check for mutex object
Check for existence of ﬁles
Check for existence of registry entry
Read current time
Read from ﬁle
Read from network
20
116
79
74
134
106
134
Table 1. Number of samples that access
tainted input sources.
After running our analysis on the complete set of 308
real-world malware samples, we observed that 229 of these
samples used at least one of the tainted input sources we de-
ﬁned. The breakdown of the usage based on input is shown
in Table 1. Of course, reading from a tainted source does
not automatically imply that we can explore additional ex-
ecution paths. For example, many samples copy their own
executable ﬁle into a particular directory (e.g., the Windows
system folder). In this case, our analysis observes that a ﬁle
is read, and appropriately taints the input. However, the
tainted bytes are simply written to another ﬁle, but not used
for any conditional control ﬂow decisions. Thus, there are
no alternative program paths to explore.
Out of the 229 samples that access tainted sources, 172
use some of the tainted bytes for control ﬂow decisions. In
this case, our analysis is able to explore additional paths
and extract behavior that would have remained undetected
with a dynamic analysis only based on a single execution
trace. In general, exploring multiple paths results in a more
complete picture of the behavior of that code. However, it
is unreasonable to expect that our analysis can always ex-
tract important additional knowledge about program behav-
ior. For example, several malware instances implement a
check that uses a mutex object to ensure that only a sin-
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:55:25 UTC from IEEE Xplore.  Restrictions apply. 
2007 IEEE Symposium on Security and Privacy(SP'07)0-7695-2848-1/07 $20.00  © 2007gle program instance is running at the same time. That is,
when the mutex is not found on the ﬁrst execution path, the
malware performs its normal malicious actions. When our
system analyzes the alternative path (i.e., we pretend that
the mutex exists), the program immediately exits. In such
situations, we are only able to increase our knowledge by
the fact that the presence of a speciﬁc mutex leads to im-
mediate termination. Of course, there are many other cases
in which the additional behavior is signiﬁcant, and reveals
hidden functionality not present in a single trace.
Table 2 shows the increase in coverage of the malicious
code when we explore alternative branches. More precisely,
this table shows the relative increase in the number of basic
blocks that are analyzed by our system when considering al-
ternative paths. The baseline for each sample is the number
of basic blocks covered when simply running the sample in
our analysis environment. For a small number of the sam-
ples (21 of 172), the newly detected code regions amount
to less than 10% of the baseline. While it is possible that
these 10% contain information that is relevant for an ana-
lyst, they are mostly due to the exploration of error paths
that quickly lead to program termination. For the remaining
samples (151 of 172), the increase in code coverage is above
10%, and often signiﬁcantly larger. For example, the largest
increase in code coverage that we observed was 3413.58%,
when analyzing the Win32.Plexus.B worm. This was
because this sample only executes its payload if its ﬁle name
contains the string upu.exe. As this was not the case for
the sample uploaded into our analysis system, the malware
payload was only run in an alternative path. Anecdotal evi-
dence of the usefulness of our system is provided in the fol-
lowing paragraphs, where we describe interesting behavior
that was revealed by alternative paths. However, examining
the quantitative results alone, it is evident that almost one
half of the malware samples in the wild contain signiﬁcant,
hidden functionality that is missed by a simple analysis.
Relative increase Number of samples
21
71
37
43
0 % - 10 %
10 % - 50 %
50 % - 200 %
> 200 %
Table 2. Relative increase of code coverage.
Behavioral analysis results. One interesting class of ma-
licious behavior that can be detected effectively by our sys-
tem is code that is only executed on a certain date (or in a
time interval). As an example for this class, consider the
Blaster code shown one the left side of Figure 4. This
code launches a denial-of-service attack, but only after the
15th of August. Suppose that Blaster is executed on the
1st of January. In that case, a single execution trace would
yield no indication of an attack. Using our system, however,
a snapshot for the ﬁrst check of the if-condition is created.
After resetting the process, the day is rewritten to be larger
than 15. Later, the system also passes the month check, up-
dating the month variable to a value of 8 or larger. Hence,
the multiple execution path exploration allows us to identify
the fact that Blaster launches a denial-of-service attack,
as well as the dates that it is launched.
Another interesting case in which our analysis can pro-
vide a more complete behavioral picture is when malware
checks for the existence of a ﬁle to determine whether it was
already installed. For example, the Kriz virus ﬁrst checks
for the existence of the ﬁle KRIZED.TT6 in the system
folder. When this ﬁle is not present, the virus simply copies
itself into the system folder and terminates. Only when the
ﬁle is already present, malicious behavior can be observed.
In such cases, an analysis system that performs a single ex-
ecution run would only be able to monitor the installation.
Finally, our system is well-suited to identify actions that
are triggered by commands that are received over the net-
work or read from a ﬁle. An important class of malware
that can be controlled by remote commands are IRC (Inter-
net Relay Chat) bots. When started, these programs usually
connect to an IRC server, join a channel, and listen to the
chat trafﬁc for keywords that trigger certain actions. Mod-
ern IRC bots can typically understand more than 100 com-
mands, making a manual analysis slow and tedious. Using
our system, we can automate the process and determine, for
each command, which behavior is triggered. In contrast,
when running a bot in existing analysis tools, it is likely that
no malicious actions will be seen, simply because the bot
never receives any commands. The code on the right side of
Figure 4 shows a fragment of the command loop of the bot
rxBot. This code implements a series of if-statements that
check a line received from the IRC server for the presence
of certain keywords. When this code is analyzed, the result
of the read from the network (that is, the content of array a)
is labeled. Therefore, all calls to the strcmp function are
treated as branching points, and we can extract the actions
for one command on each different path.
Performance. The goal of our system is to provide a mal-
ware analyst with a detailed report on the behavior of an
unknown sample. Thus, performance is not a primary re-
quirement. Nevertheless, for some programs, a signiﬁcant
number of paths needs to be explored. Thus, the time and
space requirements for saving and restoring states cannot be
completely neglected.
Whenever our system creates a snapshot, it saves the
complete active memory content of the process. In addi-
tion, the state contains information from the shadow mem-
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:55:25 UTC from IEEE Xplore.  Restrictions apply. 
2007 IEEE Symposium on Security and Privacy(SP'07)0-7695-2848-1/07 $20.00  © 2007  1:  GetDateFormat( LOCALE_409, 0, NULL, 
                                  "d", day, sizeof(day)); 
  2:  GetDateFormat( LOCALE_409, 0, NULL,
                                  "M", month, sizeof(month));
  3:
  4:  if (atoi(day) > 15 && atoi(month) >= 8)