with CRL (CRS is about 900 times cheaper than CRL in terms of
communication cost with the Federal PKI estimates). We omit this
analysis due to space limitations.
3.5 Incremental Updatability
The proposed scheme is also designed to facilitate incremental
database update. In relational database systems, database update
has been tailored to tuple operations (tuple insertion, deletion, and
modiﬁcation), where each tuple is uniquely identiﬁed by its pri-
mary key. In our scheme, both watermark generation and detection
are tuple oriented; each tuple is processed independently of other
tuples, based on its primary key.
The watermark is updated as follows. If a set of new tuples is
inserted into the watermarked data, the watermark generation algo-
rithm 1 can be performed on those new tuples only. As a result, a
set of corresponding new tuples is generated and inserted into the
watermark. If a set of tuples is deleted from the watermarked data,
the corresponding tuples with the same primary keys are simply
deleted from the watermark. In the case that a set of values is mod-
iﬁed, only the related tuples need to be updated in the watermark.
This can be done in a similar manner as in the tuple insertion case.
Note that if a modiﬁed value does not contribute any MSB to the
watermark, then no update is needed for that value.
The update of the watermark certiﬁcate follows the update of the
watermark. To update a watermark certiﬁcate, the owner of water-
marked data needs to authenticate himself to a DB-CA, revoke the
old certiﬁcate, and get a new certiﬁcate for the updated DB and wa-
termark. The new certiﬁcate may have an updated validity period,
but the original time will not be altered. As this process involves
interactions with a DB-CA, it may not be efﬁcient if executed fre-
quently. Fortunately, our scheme is very robust against database
update, as will be indicated in the next section. Therefore, the up-
date of the watermark and watermark certiﬁcate may lag behind the
update of the watermarked data; it can be done periodically after a
batch of data updates. The lag-behind watermark and certiﬁcate
can still be used for checking the ownership of the updated data as
long as the updates do not severely degrade the robustness of our
scheme.
3.6 Discussion
Like traditional PKI, the certiﬁcate revocation in our scheme is
handled only by the trusted party (i.e., the DB-CA). An alterna-
tive solution is to let the DB owner himself handle the certiﬁcate
revocation. After the DB-CA signs a watermark certiﬁcate C =
ID, K, h(W ), h(R), T, DB − CA, Y365, Sig, where Y365 =
F 365(Y0), it gives Y0 to the DB owner through a secure channel.
The DB owner keeps Y0 secret. On the i-th day in the validity
period of the certiﬁcate, the DB owner himself can generate and
publish Y365−i = F 365−i(Y0), based on which anyone can verify
the validity of the certiﬁcate. This solution further simpliﬁes our
scheme in the sense that the DB-CA does not need to generate Y-
values for all valid certiﬁcates each day, and that all DB owners do
not need to query a directory to update the Y-values. The commu-
nication cost is thus reduced substantially. Whenever the DB owner
deems it appropriate (e.g., after database is updated), he can refuse
to release new Y-values to the public, thus revoking the certiﬁcate
in a de facto manner, and apply a new certiﬁcate if necessary. This
solution works well for database updates because it is to the bene-
ﬁt of the DB owner to maintain the certiﬁcate status. However, it
may not work well in the case of DB-CA compromise or loss of
Y0, but this fortunately would not happen very often as compared
with database updates. It is possible to develop a hybrid solution
that combines the merits of both DB-owner-handled revocation and
CA-handled revocation.
4. ROBUSTNESS AND OVERHEAD
For a watermarking scheme to be useful, it must be robust against
typical attacks and be efﬁcient in practice. In this section, we ﬁrst
present a quantitative model for the robustness of our watermark-
ing scheme. We analyze the robustness of our scheme by the same
method (i.e., binomial probability) as was used in [1]. We then in-
vestigate the overhead of our watermarking scheme. We also study
the tradeoffs between the robustness and overhead in terms of the
watermarking generation parameter γ and watermarking detection
parameter τ .
4.1 Survival Binomial Probability
Consider n Bernoulli trials of an event, with probability p of
success and q = 1 − p of failure in any trial. Let Pp(k; n) be
the probability of obtaining exactly k successes out of n Bernoulli
trials (i.e., the discrete probability of binomial distribution). Then
kpkqn−k
Pp(k; n) = n
n
k =
n!
k!(n − k)!
(2)
(3)
Let Cp(k; n) denote the probability of having more than k suc-
cesses in n Bernoulli trials; that is, Cp(k; n) is the survival bino-
mial probability. According to the standard analysis of binomial
distribution, we have
Cp(k; n) =
ni=k+1
Pp(i; n)
(4)
In many widely available computation software packages such as
Matlab and Mathematica, the survival binomial probability can be
computed by Cp(k; n) = 1 − binocdf (k, n, p), where binocdf (k,
n, p) is the binomial cumulative distribution function with param-
eters n and p at value k. When n is large, the binomial distribu-
tion can be approximated by a normal distribution with mean np,
standard deviation √npq, at value k + 0.5, where 0.5 is the cor-
rection of continuity (for p = 0.5, the normal is a good approx-
imation when n is as low as 10; see chapter 7.6 in [31]). Thus,
Cp(k; n) = 1 − normcdf (k + 0.5, np,√npq), where normcdf
is the normal cumulative distribution function.
4.2 Detecting Non-Watermarked Data
First consider the robustness of our scheme in terms of false hit,
which is the probability of a valid watermark being detected from
non-watermarked data. The lower the false hit, the better the ro-
bustness. We show that the false hit is under control in our scheme
and can be made highly improbable.
Recall that in watermark detection, a collection of MSBs are
located in suspicious data and compared with the corresponding

bits recorded in the public watermark. When the watermark detec-
tion is applied to non-watermarked data, each MSB in data has the
same probability 1/2 to match or not to match the corresponding
bit in the watermark. Assume that the non-watermarked data has
the same number η of tuples (and the same primary keys) as the
original data. Let ω = ηγ be the total number of bits in the wa-
termark, where γ is the watermark generation parameter. The false
hit is the probability that at least τ portion of ω bits can be detected
from the non-watermarked data by sheer chance, where τ is the
watermark detection parameter. The false hit H can be written as
H = C1/2(τ ω, ω) = C1/2(τ γη, γη)
(5)
η =1000
100
10−5
H
t
i
h
e
s
a
F
l
H
t
i
h
e
s
a
F
l
τ =0.51
τ =0.52
τ =0.53
τ =0.54
τ =0.55
2
3
4
5
γ
6
7
8
9
10
Figure 2: False hit as function of γ
γ =5
τ =0.51
τ =0.52
τ =0.53
τ =0.54
τ =0.55
10−10
10−15
1
100
10−5
10−10
10−15
2000
4000
6000
η
8000
10000
Figure 3: False hit as function of η
Figure 2 shows the change of the false hit when the watermark
insertion parameter γ increases from 1 to 10 for ﬁxed η = 1000
and various values of the watermark detection parameter τ . The
ﬁgure illustrates that the false hit is monotonic decreasing with both
watermark insertion parameter γ and detection parameter τ . On
the one hand, the larger the insertion parameter γ, the more MSBs
are included in the watermark and the smaller the false hit. On
the other hand, the false hit can be decreased by increasing the
detection parameter τ , which is the least fraction of watermark bits
required for ownership assertion.
Figure 3 illustrates the trend of false hit when the number η of
tuples is scaled up from 1000 to 10,000. The trend is that the false
hit is monotonic decreasing with η. This trend is linear, which is
similar to that of increasing γ, as indicated in ﬁgure 2. A conclusion
drawn from these two ﬁgures is that with reasonably large values
of γ, τ , and/or η, the false hit can be made extremely low.
4.3 Detecting Watermarked Data
We now consider the robustness of our scheme in terms of false
miss, which is the probability of not detecting a valid watermark
from watermarked data that has been modiﬁed in typical attacks.
The robustness can also be measured in terms of the error intro-
duced by typical attacks. The less the false miss, or the larger the
error introduced by typical attacks, the better the robustness. The
typical attacks include database update, selective value modiﬁca-
tion, and suppression. Other typical attacks include the data frame-
up attack and the additive attack which have been addressed in a
previous section.
4.3.1 Typical Database Update
Typical database update includes tuple insertion, tuple deletion,
attribute deletion, and value modiﬁcation. For tuple deletion and
attribute deletion, the MSBs in the deleted tuples or attributes will
not be detected in watermark detection; however, the MSBs in other
tuples or attributes will not be affected. Therefore, all detected
MSBs will match their counterparts in the public watermark, and
the false miss is zero.
Though the deletion of tuples or attributes will not affect the false
miss, it will make the false hit worse. The more the tuples or at-
tributes are deleted, the larger the false hit, as indicated in Section
4.2. The effect to the false hit of deleting tuples is equivalent to that
of decreasing η as shown in Figure 3, while the effect of deleting
attributes is equivalent to decreasing γ proportionally as shown in
Figure 2.
Since the watermark detection is primary key based, a newly in-
serted tuple should have a valid primary key value; otherwise, there
is no corresponding tuple in the public watermark. We thus con-
sider tuple insertion to be “mix-and-match” [1]; that is, an attacker
inserts ξ new tuples to replace ξ watermarked tuples with their pri-
mary key values unchanged. For watermark detection to return a
false answer, at least γη − τ γη MSBs in those newly added tu-
ples (which consists of γξ MSBs) must not match their counterparts
in the public watermark (which consist of γη bits). Therefore, the
false miss Mξ for inserting ξ tuples in mix-and-match can be writ-
ten as
Mξ = C1/2(γη − τ γη − 1, γξ)
(6)
γ =5, η =1000
100
10−5
10−10
ξ
l
i
M
s
s
m
e
s
a
F
10−15
τ =0.51
τ =0.52
τ =0.53
τ =0.54
τ =0.55
80 82 84 86 88 90 92 94 96 98 100
ξ /η (%)
Figure 4: False miss (tuple insertion) as function of ξ
Figures 4, 5, and 6 show the false miss in the case of tuple inser-
tion. The default parameters in these ﬁgures are ξ/η = 90% (i.e.,

η =1000, ξ /η =90%
ζ values can be written as
ξ
i
M
s
s
m
e
s
a
F
l
100
10−5
10−10
10−15
1
τ =0.51
τ =0.52
τ =0.53
τ =0.54
τ =0.55
2
3
4
5
γ
6
7
8
9
10
100
10−5
10−10
ζ
i
M
s
s
m
e
s
a
F