set of permissions P granted to the request. If M ⊈P, then the request
FaaS platform layerPolicy Evaluation ServiceRequest + Role R5Labeling state databaseFetch data permissions Fetch protection stateIs foo ingress point?Deny requestProtection state databasePermissions P granted to RIngress point fooTraverse PSIs M in P?Allow requestCompute mandatory permissions MCompute conditional function invocations FFor each func in F, compute permissions C in subtree rooted at funcbarC1func2C2func3func4C3C4API gatewayApplication UserIncomingrequest to fooContainerFunction fooRequest HandlerAuthentication requestAuthentication serverAssigned user role R123Role RGraph PS rooted at fooConditional permission look-up table TExternal request handlerInternal request handlerStart4NYYN678Forward proxyConditional policy evaluation routineWRITE91011foo output and call bar 12call bar StartIs bar in PS ?Ybar invocation requestDeny requestAllow requestIs bar in table T ?Is C1 in P ?READNNYYNContainerFunction barRequest Handler13141516Mandatory policy evaluation routineConditional policy evaluation routineEndEndWorkflow Integration Alleviates Identity and Access Management in Serverless Computing
ACSAC 2020, December 7–11, 2020, Austin, USA
is immediately rejected because eventually the workflow will lack
necessary permissions to execute some downstream function. To ac-
count for the conditional function invocations in the protection state
graph, this routine computes the conditional permission look-up
table T which stores data permissions that will be required by these
invocations for later processing, but does not immediately verify the
presence of the conditional permissions. The accepted requests are
forwarded to the designated function instances.
6.3.2 Conditional Policy Evaluation. All internal function requests
are directed to the conditional policy evaluation routine. It trivially
accepts all absolute function requests, as access permissions for
them had already been verified in the mandatory policy evaluation.
However, for functions present in table T , this routine determines
whether the workflow should continue to execute or not. It checks
if the required permissions C by the target function f are satisfied
in P. Requests with unsatisfied permissions are aborted, whereas
accepted requests are forwarded to the gateway for routing to the
correct function instance.
6.4 Request Handler
In serverless platforms, a tiny webserver (i.e., a request handler)
runs inside the function container that accepts function invocation
requests. This request handler parses the incoming request object
and starts execution of the function. will.iam extends the design of
this request handler to remove the in-band headers used by will.iam
before handing the request off to the function routine. This allows
will.iam to be completely transparent to the function implementa-
tion and easily deployable to existing platforms without any function
modification. Additionally, the request handler runs a reverse proxy
for communicating with other functions in the workflow. This re-
verse proxy will readjust the in-band will.iam-specific headers in
the outgoing request and then redirect it to the policy evaluation
service to verify conditional violations.
7 IMPLEMENTATION
We implemented will.iam into the OpenFaaS serverless framework.
OpenFaaS can be deployed on multiple container orchestration plat-
forms, however in this paper we deploy OpenFaaS over Kubernetes.
We primarily modified two components of OpenFaaS, the "gateway"
and "of-watchdog", representing an addition of approximately 400
lines of Go code.
Gateway. The gateway is exposed to the public internet and ac-
cepts incoming requests to functions. We modify the gateway by
adding an extra HTTP middleware which modifies the body of the
incoming request as it exits the gateway. This modification handles
exchanging the token specified in the "Authorization" header of the
incoming HTTP request for a policy. The gateway then uses the
policy name and policy graph to build a list of data permissions
granted to the request. The gateway also uses the target function
name, which is specified in the URI path, and the Protection State
graph in order to build the list of data permissions that are absolutely
and conditionally required. If there is an element in the set of ab-
solute permissions that is not in the request’s permission set, the
gateway rejects the incoming request with an unauthorized error. If
there are conditional violations, the gateway encodes the allowed
data permissions for the request into a serialized in-band header
{
" f u n c t i o n s " :
{
" product−c a t a l o g −ap i " :
{
" p e r m i s s i o n s " :
[
{
" dataType " :
" o p e r a t i o n " :
" productCategory " ,
" read "
}
. . .
a d d i t i o n a l p e r m i s s i o n s omitted f o r
space
. . .
] ,
" ab so l ut e De pe n de n ci es " :
[ ] ,
" c o n d i t i o n a l D e p e n d e n c i e s " :
[ ]
} ,
. . .
a d d i t i o n a l
f u n c t i o n s omitted f o r
space
. . .
} ,
" p o l i c i e s " :
{
" customer " :
{
" dependencies " :
[
" p u b l i c "
] ,
" p e r m i s s i o n s " :
[
{
}
" dataType " :
" o p e r a t i o n " :
" creditCardsName " ,
" read "
a d d i t i o n a l p o l i c i e s omitted f o r
space
. . .
]
} ,
. . .
}
}
Figure 4: Snippet from an example JSON configuration file
used for defining will.iam security policies.
and transmits them to the target function. The target function runs
behind a modified version of the of-watchdog component described
below.
The gateway also handles routing of calls between functions in
the Protection State graph. For these intra-function requests, the
in-band header is already encoded into and the gateway checks for
conditional violations before forwarding the request. If a conditional
violation becomes absolute, the gateway rejects the request and the
unauthorized error is sent upstream to the user.
Of-Watchdog. The of-watchdog server is only reachable from
within the OpenFaaS cluster. It handles both receiving incoming
requests from the gateway and passing them onto the function. The
OpenFaaS framework allows functions to receive requests from the
of-watchdog server over standard input or over HTTP. We do not
modify this functionality and our changes are transparent to the
function.
We add extra HTTP middleware that removes the in-band header
containing the encoded access control logic from the gateway. We
also modify the watchdog to launch a reverse proxy server that is
bound to a port within the cloud function’s container. When the
HTTP middleware removes the in-band header from the request it
stores it in a map so that it can be looked up for the specific request.
The reverse proxy uses this map to retrieve that in-band header
associated with a request and add it back to the request before it is
sent to the gateway as an intra-function request.
Configuration. We require the access control policy writer to pro-
vide a JSON configuration file which provides the required infor-
mation about each function and policy in the access control model.
Figure 4 provides an example configuration file.
ACSAC 2020, December 7–11, 2020, Austin, USA
Arnav Sankaran, Pubali Datta, and Adam Bates
Figure 5: Container image build sizes for Hello, Retail!.
Figure 6: Container image build times for Hello, Retail!.
8 EVALUATION
We evaluate our access control system using Hello, Retail! [88], a
serverless application developed by Nordstrom Technology as a
proof-of-concept approach to an event driven computing model in
the retail industry. As one of the most mature open-source applica-
tions, Hello, Retail! has been used in many past studies of serverless
computing [80], including access control research [36, 47, 59].
We compare the performance of will.iam against two state-of-
the-art serverless information flow control systems, Trapeze 5 [36]
and Valve 6 [47], both of which have been open-sourced by their
respective authors. Trapeze is a language-based approach that traces
information flow at the language level, while Valve is a system-based
approach that, like will.iam, mediates events at the function level.
To compare against these systems, we use the modified version of the
application from Alpernas et al. [36], which replaces AWS-specific
components with open-source components that can be deployed
on top of Kubernetes and OpenFaaS. This is the same modified ver-
sion used in prior work to evaluate these systems providing us with
an apples-to-apples baseline upon which to compare performance.
We also write a complete will.iam security policy for Hello, Retail!,
which is provided and discussed in Appendix A.
All experiments were performed on a server-class machine with
an Intel(R) Xeon(R) CPU E5-2683v4 running at 2.10GHz and 135 GB
of RAM. The containerization and orchestration software used was
Docker 19.03.11 and Kubernetes 1.18.3. For the purposes of testing,
the Kubernetes cluster was configured as a single node cluster with
both control plane and user deployed pods being run on the single
master node. All Docker images required for all of the following
tests were pre-pulled in order to minimize the effects of external
networking variations.
8.1 Build Time Performance
The build time and build size overheads, averaged across 30 invo-
cations of each function, are given in Figure 5 and Figure 6. These
figures indicate that will.iam imposes very little overhead at build
time when compared to Vanilla OpenFaaS. Additionally it substan-
tially outperforms both Trapeze and Valve. For build size, the slightly
5https://github.com/kalevalp/trapeze
6https://github.com/Ethos-lab/Valve
Figure 7: Container deployment times for Hello, Retail!,
increased container size over Vanilla is due to the additional Go
code that is compiled into the of-watchdog binary for every func-
tion container. However, this addition pales in comparison to the
increased build size of Trapeze and Valve, where many additional
files are copied into the container image. Trapeze needs to copy in
Javascript files that help with securing its key-value store, while
Valve needs to copy in its HTTPS proxy binary. When comparing
build times, there was no meaningful difference between will.iam
and Vanilla OpenFaaS. The slight differences observed here were
due to variances in retrieving npm packages over the Internet during
the build process. In contrast, Trapeze and Valve both took signifi-
cantly longer to build due to the introduction of extensive additional
dependencies to the container. Although these costs are one-time
and can be largely ignored by the customer, they compound when
considering millions of customers if these approaches were to be
adopted at the platform layer, suggesting a significant advantage for
the adoptability of will.iam.
8.2 Orchestration Performance
Orchestration refers to platform management tasks, specifically the
deployment and teardown of containers as functions are requested
to be invoked. We report overheads for deployment and teardown,
averaged across 30 invocations of each function, in Figures 7 and 8,
 0 50 100 150 200 250 300 350product-photosproduct-purchase-publishproduct-purchase-get-priceproduct-purchase-authorize-ccproduct-purchase-authenticateproduct-photos-successproduct-photos-reportproduct-photos-recordproduct-photos-receiveproduct-photos-messageproduct-photos-assignproduct-catalog-builderproduct-catalog-apiproduct-purchaseSize (MB)OpenFaaSWILL.IAMTrapezeValve 0 50 100 150 200product-photosproduct-purchase-publishproduct-purchase-get-priceproduct-purchase-authorize-ccproduct-purchase-authenticateproduct-photos-successproduct-photos-reportproduct-photos-recordproduct-photos-receiveproduct-photos-messageproduct-photos-assignproduct-catalog-builderproduct-catalog-apiproduct-purchaseTime (S)OpenFaaSWILL.IAMTrapezeValve 0 1 2 3 4 5 6product-photosproduct-purchase-publishproduct-purchase-get-priceproduct-purchase-authorize-ccproduct-purchase-authenticateproduct-photos-successproduct-photos-reportproduct-photos-recordproduct-photos-receiveproduct-photos-messageproduct-photos-assignproduct-catalog-builderproduct-catalog-apiproduct-purchaseTime (S)OpenFaaSWILL.IAMTrapezeValveWorkflow Integration Alleviates Identity and Access Management in Serverless Computing
ACSAC 2020, December 7–11, 2020, Austin, USA
Figure 8: Container teardown times for Hello, Retail!.
Figure 10: Concurrent request latency for variable propor-
tions of bad (unauthorized) traffic.
performs a database read operation, and Product Purchase makes
additional function calls and performs a database read operation. For
each system, all requests made in this experiment had all required
permissions to be fully processed.
Figure 9: End-to-end workflow latency for web requests.
respectively, we did not observe any meaningful pattern of differ-
ences between any of the benchmarked systems. These results match
up with our expectations, since the overhead associated with these
operations is dominated by the performance of the orchestration
system rather than the specific containers being handled. In spite
of our results being averaged across many trials, no differences are
observable that are not better explained by noise due to orchestra-
tion scheduling decisions made by kube-scheduler and kubelet.
However, this is sufficient to demonstrate that will.iam does not
impose undue burden on orchestration routines.
8.3 Runtime Workflow Performance
Aswill.iammediatesactivityattheworkflowlevel,wenowcompare
performance of will.iam to Vanilla OpenFaaS and Trapeze using 3
end-to-end Hello, Retail! workflows. We were unable to include Valve
in these experiments because the authors did not make available
their Hello, Retail! policy along with their source code. We measure
the end-to-end latency of a request for 3 representative workflows in
the reference application: Catalog Builder, Catalog API, and Product
Purchase. These correspond to the ingress points f2, f10, and f9 in
Figure 1. They also represent 3 different kinds of workflows: Catalog
Builder makes additional function calls and performs a database
write operation, Catalog API makes no additional function calls but
Results, shown in Figure 9, are averaged over 1000 repetitions of
each workflow. Across all three workflows, we observe almost neg-
ligible overheads imposed by will.iam, averaging 0.51% and in thr
worstcase5.2%.Thisoverheadisduetothesearchesrequiredtodeter-
mineiftherequesthastherequiredpermissionsandtheencodingand
decoding of the in-band header. In contrast, Trapeze imposes signifi-
cant overheads on 2 of the 3 flows, specifically in conditions in which
many datastore read operations occur. This is because the language-
based Trapeze system transformation to programs incurs latency on
datastore reads for each entry accessed in its key-value store.
Proactive Authorization. The above experiments assumed that all
operations in the workflow were authorized, which does not capture
the performance benefits of will.iam’s proactive authorization. To
demonstrate the potential performance savings of this mechanism,
we measured the latency of 100 concurrent requests with increas-
ing proportions of unauthorized (“bad”) traffic being issued to the
ingress point. For this experiment, we make use of the Product Pur-
chase workflow. Each bad request is correctly formatted, but lacks
the required permissions to execute downstream functions after
the ingress point, potentially resulting in wasted computation. If
will.iam’s proactive authorization mechanism is effective, we ex-
pect to see decreased latencies for will.iam as compared to other
systems.
Results are shown in Figure 10, We observe that will.iam greatly
outperforms all of the other systems as the proportion of bad re-
quests increase. This is due to the ability of will.iam to preemptively
reject requests with absolute violations at the gateway rather than
allowing the request to be partially processed before being rejected.
The Vanilla system does not have this ability and as a result it’s
average latency decreases with a much smaller slope. Even through
Trapeze does allow for early rejection of requests with incorrect per-