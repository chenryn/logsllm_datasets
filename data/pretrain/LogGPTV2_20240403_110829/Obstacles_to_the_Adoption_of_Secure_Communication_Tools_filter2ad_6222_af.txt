### Understanding the Security of Communication Tools

#### Company Definitions of Security
P8 noted that companies often do not provide a clear definition of security, citing the rapidly evolving nature of threats. What is considered secure today may not be secure tomorrow. Additionally, P26 suggested that legal liability is another reason for this ambiguity; companies want the flexibility to change their definition of security in privacy policies as new developments arise.

#### Cost and Profit Motives
Participants P3, P19, P22, and P26 believe that no communication tools are truly secure because implementing robust security measures is expensive. They argue that companies prioritize profit over security, and since most tools are free, they rely on data collection and advertisements to generate revenue. Consequently, personal information and conversations are not adequately protected.

#### Past Experiences
P19 and P22 believe all messengers are secure because they have never experienced a breach. In contrast, P24 and P46 reported experiencing a security breach with Yahoo! Messenger, leading them to believe that all tools are inherently insecure. P46 stated, "My Yahoo! email account is probably one of the least secure because it has been hacked again recently."

#### Theoretical vs. Practical Security
P8 believes that "completely secure" tools exist only in theory. Software can be attacked due to bugs, and communications can be traced. P2 and P12 were the only participants who mentioned that the security of a tool can be evaluated based on the quality of its source code and the need for audits. P12, however, emphasized that these audits should remain confidential to prevent exposing the design of secure tools (see Section IV-D on threat models).

### EFF Secure Messaging Scorecard
We provided our participants with the first-generation EFF Secure Messaging Scorecard [2] and asked them to compare their rankings with those on the scorecard. No participant's ranking aligned with the scorecard. The scorecard includes seven security criteria, four of which were misunderstood: participants did not appreciate the difference between point-to-point and end-to-end (E2E) encryption, and they did not comprehend forward secrecy and fingerprint verification. The other three criteria—open design, documentation, and security audits—were viewed negatively, with participants believing that security requires obscurity.

#### Encrypted in Transit vs. Encrypted So the Provider Can't Read It
57 participants (excluding P2, P4, and P5) did not differentiate between point-to-point and E2E encryption. Recent literature suggests that users trust encrypted systems more if the ciphertexts are visible. However, our participants did not understand the security properties offered by each tool and incorrectly believed that encryption can always be broken (see Section IV-D).

#### Verifying Contact's Identity
Recent studies have assessed the usability and security of various representations of verification fingerprints. However, no participant (except P2) understood why some communication tools can verify a contact's identity through fingerprints.

#### Forward Secrecy
All participants (except P2 and P5) did not recognize the importance of forward secrecy, which ensures that past communications remain secure even if keys are stolen.

#### Open Design
The EFF Scorecard has three explicit criteria to ensure that the design and code have undergone independent reviews. Our participants, however, believed that proprietary tools are more secure, reflecting a misconception known as "security by obscurity." Only P2, P5, and P28 appreciated the value of open design.

### Discussion
Most user studies of secure communication tools, particularly encrypted email, have followed a similar pattern: assessing the usability of specific tools in a controlled setting. Participants are given security tasks to complete with fictional partners, and success is measured based on predefined goals. 

Users will not adopt a communication tool if they cannot use it effectively and efficiently. Our study identified usability issues, such as participants' inability to recognize Telegram's Secret Chat mode. However, our results also show that secure tools must offer utility, allowing users to reach their communication partners. While security may be part of users' primary communication goals, they often choose a usable but insecure tool over a secure but less functional one. For example, participants with iOS devices used WhatsApp and Skype instead of iMessage and FaceTime, despite perceiving Apple services as more secure, to avoid the overhead of using multiple tools.

When a new tool is both usable and attractive, users may accept the initial switching cost and adopt it. However, creating a tool that will be adopted by a critical mass of users requires significant resources and skills. If we want users to adopt secure communications, security engineers should focus on securing widely used tools. WhatsApp's implementation of E2E encryption for text, voice calls, and video communications is an example of this pragmatic approach [18].

In [61], De Luca et al. found that security and privacy are not primary factors driving users to adopt a particular messenger. We argue that this is not because users do not care about security. Users are aware of some threats and willing to make efforts to manage them, such as splitting credentials and sending them via different tools. Our participants preferred these cumbersome processes because they did not believe the available tools were secure, a perception fueled by misconceptions (e.g., believing service providers can read E2E-encrypted messages). These misconceptions, along with usability and utility issues, undermined the case for adoption.

### Key Takeaways
Non-experts do not understand abstract security properties and need context-specific explanations. For example, if users want to prevent service providers from reading their messages, we need to explain how E2E encryption protects against this threat. Our participants' existing mental models led them to believe that using any secure tool is futile, as they thought even the best encryption could be broken by governments or service providers. We need to help users understand that they can protect themselves with well-developed and auditable security mechanisms.

Based on our feedback, the EFF is redesigning the scorecard to group tools into general tiers from "most secure" to "insecure," providing textual descriptions of security properties without requiring users to understand specific mechanisms. The scorecard will also include non-security information, such as user base size, device/platform availability, and whether the tool is free, to drive adoption.

### Concluding Remarks
Our research, based on 10 unstructured and 50 semi-structured interviews, provides the broadest study of user perceptions of secure communications to date. While participants experienced usability issues, the primary obstacles to adopting secure tools are low motivation, small user bases, and incorrect mental models of secure communications. Based on our findings, we recommend:

1. **Secure tools with proven utility:** Prioritize securing widely adopted tools rather than improving the usability of niche secure tools.
2. **Understand the target population:** Develop a deeper understanding of users' goals and preferences to create user-centered secure communication tools.
3. **Improve Quality of Service (QoS):** Ensure that secure communication tools feel professional and perform well, as users often use proxy signals to evaluate security.

### Acknowledgments
We thank the reviewers for their helpful comments and suggestions. This work is supported by a gift from Google. Joseph Bonneau is supported by a Secure Usability Fellowship from the Open Technology Fund and Simply Secure.

### References
[1] N. Unger, S. Dechand, J. Bonneau, S. Fahl, H. Perl, I. Goldberg, and M. Smith, “SoK: Secure Messaging,” in IEEE Symposium on Security and Privacy, 2015, pp. 232–249.
[2] Electronic Frontier Foundation (EFF), “Secure Messaging Scorecard,” https://www.eff.org/secure-messaging-scorecard, accessed on: 09.07.2016.
[3] D. Yadron, “Apple Transparency Report: Over 1,000 Government Requests for User Data,” The Guardian, 2016.
[4] S. Gibbs, “Gmail Does Scan All Emails, New Google Terms Clarify,” The Guardian, 2014.
[5] R. Anderson, “Why Cryptosystems Fail,” in ACM Conference on Computer and Communications Security, 1993, pp. 215–227.
[6] S. Fahl, M. Harbach, H. Perl, M. Koetter, and M. Smith, “Rethinking SSL Development in an Appiﬁed World,” in ACM Conference on Computer and Communications Security, 2013, pp. 49–60.
[7] A. Whitten and J. D. Tygar, “Why Johnny Can’t Encrypt: A Usability Evaluation of PGP 5.0,” in USENIX Security Symposium, 1999.
[8] S. L. Garﬁnkel and R. C. Miller, “Johnny 2: A User Test of Key Continuity Management with S/MIME and Outlook Express,” in ACM Symposium on Usable Privacy and Security, 2005, pp. 13–24.
[9] S. Clark, T. Goodspeed, P. Metzger, Z. Wasserman, K. Xu, and M. Blaze, “Why (Special Agent) Johnny (Still) Can’t Encrypt: A Security Analysis of the APCO Project 25 Two-Way Radio System,” in USENIX Security Symposium, 2011, pp. 8–12.
[10] M. Lee, “Encryption Works: How to Protect Your Privacy in the Age of NSA Surveillance,” Freedom of the Press Foundation, 2013.
[11] “Tips, Tools and How-tos for Safer Online Communications,” https://ssd.eff.org/en, accessed on: 19.08.2016.
[12] McGregor, Susan E, “Digital Security and Source Protection for Journalists,” http://towcenter.org/digital-security-and-source-protection-for-journalists-research-by-susan-mcgregor/, accessed on: 20.08.2016.
[13] “The OpenPGP Alliance Home Page,” http://www.openpgp.org/resources/downloads.shtml, accessed on: 20.08.2016.
[14] “Tor,” https://www.torproject.org/projects/torbrowser.html.en, accessed on: 20.08.2016.
[17] “SecureDrop: The Open-source Whistleblower Submission System,” https://securedrop.org/, accessed on: 20.08.2016.
[15] “Tails: The Amnesic Incognito Live System,” https://tails.boum.org/, accessed on: 20.08.2016.
[16] “Off-the-Record Messaging,” https://otr.cypherpunks.ca/, accessed on: 20.08.2016.
[18] Natasha Lomas, “WhatsApp Completes End-to-End Encryption Rollout,” https://techcrunch.com/2016/04/05/whatsapp-completes-end-to-end-encryption-rollout, accessed on: 09.09.2016.
[19] A. J. Onwuegbuzie and N. L. Leech, “Validity and Qualitative Research: An Oxymoron?” Quality & Quantity, vol. 41, no. 2, pp. 233–249, 2007.
[20] A. Strauss and J. Corbin, “Grounded Theory Methodology,” Handbook of Qualitative Research, pp. 273–285, 1994.
[21] B. Harry, K. M. Sturges, and J. K. Klingner, “Mapping the Process: An Exemplar of Process and Challenge in Grounded Theory Analysis,” Educational Researcher, vol. 34, no. 2, pp. 3–13, 2005.