also adds this login to its changepoint list.
Hopper computes a path’s causal user by examining the
ﬁrst (earliest) login in the path. If the login’s source machine
is a server, then Hopper treats the target username as the path’s
causal user. However, if the ﬁrst login’s source machine is a
client, Hopper takes the owner of that source machine and
treats that username as the causal user: clients typically corre-
spond to the start of a user’s movement path and logins from
these machines should use their owner’s credentials. Addi-
tionally, Hopper takes a user-provided list of special “bastion”
machines: hardened gateway servers that provide access to
restricted network segments or machines, and which require
users to perform heightened authentication to access these
protected parts of the network (e.g., password and hardware-
based 2FA authentication during each login). Whenever Hop-
per encounters a login that originates from a bastion source
machine, it treats this login as the root login for the path:
i.e., Hopper treats the username of the bastion login as the
path’s causal user, and stops performing backwards-tracing
for the path. Because bastions require robust forms of authen-
tication, logins forwarded from bastion source machines (i.e.,
logins that successfully authenticated to the bastion server)
indicate that the login’s purported username does reﬂect the
true actor responsible for making the login.
Paths belong to one of three types: a BENIGN path, a path
with a CLEAR credential switch, or a path with UNCLEAR
causality. For each changepoint login in a path, Hopper checks
whether the changepoint login’s username matches any of the
usernames across its potential inbound (causal) logins. If
all of the inbound hops used a different username, or if the
changepoint login originated from a client source machine,
then the path has a CLEAR credential switch; otherwise, Hop-
per labels the path as UNCLEAR. If a path does not have any
changepoint logins, then Hopper marks the path as BENIGN.
For example, in Figure 3, if L1, L2, and L3 occurred within
24 hours prior to L4, Hopper will produce 3 causal paths for L4.
The paths starting with L1 and L3 will form UNCLEAR paths,
and the path starting with L2 will get marked as BENIGN. The
path from L2 to L4 will list Bob as its causal user and have
no changepoints logins. Both the attack path (L3 to L4) and
the path from L1 to L4 will list Alice as their causal user, and
contain L4 in their list of changepoint logins.
6 Detection and Alerting
Hopper classiﬁes each path given two additional inputs: a set
of historical logins for feature extraction and a user-provided
“budget” that controls the daily number of alerts that Hopper
produces for UNCLEAR paths (§ 6.2). Hopper ﬁrst checks
whether the path matches one of ﬁve benign scenarios; if so,
it does not generate an alert. For paths that do not match a
benign scenario, Hopper identiﬁes which of two attack sce-
narios the path might belong to and applies the scenario’s
corresponding detector. These detectors apply either a rule set
(§ 6.1) or an anomaly scoring algorithm (§ 6.2), and produce
an alert if the path is marked as suspicious.
Benign Movement Scenarios: In the ﬁrst benign scenario,
Hopper marks a path as benign if every one of its logins uses
its causal user’s credential (i.e., a path labeled as BENIGN
by the causality engine); because these paths do exhibit the
ﬁrst key attack property, Hopper discards them. Hopper also
labels approximately 170,000 paths as benign if they match
one of four other benign and low-risk scenarios.
First Hopper identiﬁes one-hop paths (i.e., logins) from new
machines and new users: Hopper labels the path as benign if
either the user and/or source machine have existed for less
than one week (based on their earliest occurrence in historical
logins and the organization’s inventory databases). Second,
Hopper ignores all paths that originate from a machine under-
going provisioning for a new owner. As part of this process,
an administrator runs a script that authenticates into several
specialized servers to conﬁgure the machine (e.g., installing
the operating system and conﬁguring the new owner’s ac-
count). These logins will seem suspicious to Hopper because
they will use an administrator’s credentials (target username)
that differs from the machine’s owner (the causal user). To
identify login events that relate to machine re-provisioning,
Hopper checks for three properties: (1) the login’s destina-
tion belongs to a set of dedicated provisioning servers, (2)
the login’s target user is a system administrator, and (3) the
login originates from a dedicated subnet used for machine
provisioning. If Hopper encounters a login with these three
properties, it does not run its causality engine or generate an
alert. In total, Hopper removes approximately 125,000 logins
related to new machines or those undergoing provisioning.
USENIX Association
30th USENIX Security Symposium    3099
Figure 4: Architecture of Hopper’s alert generator (§ 6). Given a login path (§ 5), Hopper checks whether the path matches a benign scenario
or an attack scenario. Based on the path’s scenario, Hopper either discards the path or generates an alert if the scenario’s detector triggers.
Third, the use of (non-human) service accounts produces
roughly 42,000 one-hop paths that Hopper would otherwise
label as cases of clear-credential switching. In these logins, a
legitimate user performed a login using a “mismatched” set
of credentials that correspond to a service account; however,
the credential “switch” in these logins reﬂects the benign, ex-
pected way to access these enterprise services. For example,
these logins include users running a script to launch testing
jobs when building a new version of Dropbox’s desktop appli-
cation; part of this script includes remote commands issued
to the build and test machines under a service account (e.g.,
user = test-services). Hopper infers a set of these service user-
names by identifying any username that (1) does not match
an employee username, and (2) was used in successful logins
from more than ten different source machines across a set of
historical data. To ensure that usernames inferred by Hopper
do not provide widespread access or highly privileged capa-
bilities, Hopper outputs the set of inferred service accounts
for an organization’s security team to conﬁrm, and uses only
the set of approved service usernames when ﬁltering these
benign logins. Because these accounts are designed for a lim-
ited and speciﬁc service operation, organizations can mitigate
the risk of lateral movement via these credentials by conﬁg-
uring them with a limited set of permissions to a speciﬁc
set of machines; at Dropbox, many of these service accounts
also access their destinations via a limited remote command
API [1], as opposed to creating a full interactive session.
The ﬁnal benign scenario involves logins to and from a bas-
tion host. Organizations often segment parts of their network
for improved efﬁciency, maintenance, and security by plac-
ing a set of machines behind a hardened bastion host [6, 49].
To access a server within this network segment, a user must
ﬁrst tunnel and authenticate through the network segment’s
bastion. Dropbox’s corporate network contains a few such
network segments. Because bastion machines correspond to
hardened hosts, perform a limited set of operations (authen-
tication and connection forwarding), and often do not allow
users to establish logins onto the host itself, a login that orig-
inates from a bastion likely reﬂects legitimate user activity.
Given a list of bastion hosts at an organization, Hopper does
not alert on any one-hop path that originates from a bastion
or any two-hop paths that traverse a bastion.
Attack Scenarios: If a path does not match any of these be-
nign scenarios, Hopper checks whether it matches one of
two attack scenarios and, if so, applies the corresponding de-
tection algorithm to see whether it should produce an alert.
First, if the path contains a login that switches credentials
and the causality engine has high conﬁdence that the switch
occurred (a CLEAR path), Hopper applies a simple rule set
to classify the path as suspicious or not (§ 6.1). However,
because of imperfect information contained in real-world au-
thentication logs, Hopper’s causality engine sometimes infers
multiple potential paths that a login could belong to, where
not all of the paths contain a credential switch (i.e., paths with
UNCLEAR causality). Because of this uncertainty, Hopper’s
second detector evaluates how suspicious each such path is
with a probabilistic scoring algorithm (§ 6.2) and alerts if the
path has one of the most suspicious scores in recent history.
6.1 Attack Scenario 1: Paths with a Clear Cre-
dential Switch
Paths with a clear credential switch contain at least one login
where Hopper knows that the causal user it inferred for the
path must have switched to a different set of credentials (the
ﬁrst key attack property). For these paths, Hopper generates
an alert if the path accesses any destination that its causal user
has never accessed in prior history; a conservative estimate of
when a path’s causal user accesses an unauthorized machine.
More formally, let P represent a path with a causal user of
Alice and DestP refer to the destination machines across all
of P’s logins. Hopper generates an alert if P exhibits the two
key attack properties:
1. Property 1: P has a CLEAR credential switch (path type).
2. Property 2: P contains at least one destination in DestP
that Alice has never accessed in the historical training
data (e.g., past 30 days).
3100    30th USENIX Security Symposium
USENIX Association
Inferred PathHistoricLoginsDomainContextNo AlertScenario MatcherAlertAlert BudgetAttack Scenario 1: Clear Credential SwitchNoYesPath FeatureExtractionAnomaly Scoring Historic AlertsYesNoAttack Scenario 2:Unclear CausalityBenign Path Scenarios6.2 Attack Scenario 2: Paths with Unclear
Causality
The second attack scenario handles paths with UNCLEAR
causality: when Hopper infers multiple causal paths for a lo-
gin, where some paths contain a credential switch and others
do not (§ 5). To handle unclear paths, Hopper uses a prob-
abilistic detection algorithm to identify and alert on paths
that are highly anomalous. This selective use of anomaly de-
tection, only in cases where the limitations of authentication
logs introduce uncertainty about whether a path contains the
key attack properties, distinguishes Hopper from prior work,
which simply applies anomaly detection to every path.
Alert Overview: Unclear Causality: Given an UNCLEAR
path (P), Hopper ﬁrst checks whether the path ever visits a ma-
chine that its causal user (Alice) has not previously accessed
in the training data (the second attack property). If Alice has
access to all of the path’s destinations, then Hopper marks
the path as benign.3 Otherwise, Hopper runs the following
anomaly detection algorithm on P.
First, Hopper extracts three features that characterize P’s
rareness. Next, Hopper uses P’s features to compute a “sus-
piciousness” score for the path, which it then uses to rank P
relative to a historical batch of paths (e.g., the past 30 days).
If P ranks among the top 30×B most suspicious historical
paths, then Hopper generates an alert. B corresponds to a user-
provided budget that speciﬁes the average number of daily
alerts that an analyst has time to investigate for these types of
attack paths.
Path Features: Hopper uses a set of historical “training” lo-
gins to extract three features for a path. Let A refer to the
path’s starting machine and Z refer to the path’s ﬁnal destina-
tion. Given a path’s changepoint login (Lc), Hopper computes
two numerical features. First, Hopper computes the historical
edge frequency for each login preceding Lc, where an edge’s
historical frequency equals the number of days that a suc-
cessful login with the exact same edge (source, destination,
and target username) has occurred in the training data; the
ﬁrst feature value equals the minimum (lowest) frequency
among these preceding logins. Second, Hopper computes the
historical edge frequency for each login in the remainder of
the path, and takes the lowest frequency value among these
hops; i.e., the historical frequency of the rarest login starting
at Lc until the path’s ﬁnal hop. For the third feature, Hopper
computes the number of historical days where any successful
login path connects Machine A and Machine Z. If a path has
multiple changepoint logins, Hopper computes these three
features for each changepoint login, runs its anomaly scoring
algorithm (below) for each feature set, and then uses the most
suspicious score for the path.
3Future logins in the path will cause Hopper to produce extended paths
that its detection algorithm will subsequently examine.
Algorithm 1 Hopper’s anomaly scoring algorithm
AlertGen(P, A (historical alerts), L (historical paths)):
1: for each path X in A do:
2:
3:
if Score(P, L) ≥ Score(X, L):
Alert on P
Score(P, L): ∏
Sub-Score(P, L, F (feature)):
F
Sub-Score(P, L, F)
1: SumF ← 0
2: N ← 0 (the total # of true causal paths)
3: for each path X in L do:
if P has a smaller value for F than X:
4:
SumF ← SumF + Cx
5:
where Cx = the path certainty for X (§6.2)
N ← N + Cx,
6:
7: Sub-ScoreF ← SumF / N
Anomaly Scoring: Given a path P and its features, Algo-
rithm 1 shows the anomaly scoring procedure that Hopper
uses to make its alerting decision. Intuitively, Hopper’s scor-
ing algorithm generates an alert for P if it has one of the most
suspicious feature sets in recent history.
Hopper’s alerting algorithm, ALERTGEN, takes three in-
puts: a path to score (P), a set of historical paths (L) to com-
pute P’s anomaly score, and a set of historical alerts (A) for
paths with unclear causality. Hopper generates the set of his-
torical paths (L) by iterating over each login in the historical
training data and running Hopper’s causality engine to pro-
duce an aggregate set of all paths for each login. For efﬁciency,
Hopper can compute this set of historical paths as a batch job
at the beginning of each week, and reuse it for the entire
week’s scoring. The historical set of alerts (A) consists of
the B × H most suspicious paths during the historical train-
ing window, where H is the number of days in the historical
window and B is the user-provided alert budget.
With these three inputs, Hopper computes an anomaly score
for P that represents the fraction of historical paths where P
had more (or equally) suspicious feature values. Hopper then
compares P’s anomaly score against the scores of the histori-
cal alerts, and generates an alert for P if its score exceeds any
historical alert’s score; i.e., Hopper produces an alert if P is
at least as suspicious as a previous alert’s path.
Computing Scores: Conceptually, a path P’s anomaly score
corresponds to a cumulative tail probability: how much more
suspicious (unlikely) is P relative to the kinds of paths that
benign users historically make? As described in the SCORE
subroutine in Algorithm 1, Hopper calculates this score by
computing a sub-score for each of the path’s features, and
then multiplies these sub-scores to get an overall score.
Each feature’s sub-score estimates the fraction of histor-
ical paths where P had a more suspicious feature value. In
USENIX Association
30th USENIX Security Symposium    3101
practice, imprecision from Hopper’s path inference algorithm
could lead a naive computation of this fraction to over-count
certain historical paths. For example, a historical login from
a server with many (N) inbound logins will generate N his-
torical paths, even though only one of those paths reﬂects a
true causal path. These types of paths, that involve servers
with many inbound logins, will have an inﬂated volume that
could skew the anomaly sub-scores that Hopper computes;
i.e., their features will be over-represented in the historical dis-
tribution. To mitigate this problem, when computing the set of
paths for each historical login Li, Hopper annotates each path
with a “Path Certainty” fraction, denoted as C, that equals 1 /
the total number of causal paths that Hopper inferred for Li.
When Hopper computes each sub-score for the current path
P, it uses C to down-weight the impact of each historical path
(Line 5 of the SUB-SCORE routine in Algorithm 1).
Alert Clustering: To avoid generating redundant alerts for
the same path, Hopper clusters its alerts each day. Hopper
maintains a list of every alert (path) it generates on the current
day. If a new alert path traverses the same exact edges as
any path on the day’s alert list, Hopper updates the existing
alert with information about this duplicate path and does not
generate a new alert.
6.3 Real-time Detection
Organizations can run Hopper as a real-time detector using a
design similar to the architecture described above. For real-
time detection, Hopper would maintain a “recent login” queue
of all logins over the past T hours, where T corresponds to
the causality threshold described in § 5. For each new login,
Hopper can run the path inference procedure described in
Section 5, and then apply its scoring algorithms to determine
whether any path produces an alert. Each night, Hopper can
prune the queue of recent logins to only retain those in the past
T hours, recompute the set of historical paths used for feature
extraction, and update the set of the historical alert paths that
Hopper uses when assessing a new path’s anomaly score
(Section 6.2). This real-time architecture retains the same
detection accuracy as running Hopper as a batch detector,