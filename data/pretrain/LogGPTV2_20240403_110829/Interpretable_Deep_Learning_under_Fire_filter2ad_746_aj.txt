measures the L1 distance between the adversarial and benign
attribution maps across different interpreters. For comparison,
it also shows the L1 measure for the adversarial inputs gener-
ated by PGD. Observe that the adversarial inputs crafted on
g tends to generate low-quality interpretations on a different
interpreter g(cid:48), with quality comparable to that generated by
an interpretation-agnostic attack (i.e., PGD). We can therefore
conclude:
Observation 7
The transferability of adversarial inputs across differ-
ent interpreters seems low.
Attack Robustness – It is observed in § 4 that the effec-
tiveness of ADV2 varies with the target interpreter. As shown
in Figure 6, among all the interpreters, ADV2 attains the low-
est IoU scores on GRAD, suggesting that GRAD may be more
robust against ADV2. This observation may be explained
as follows: GRAD uses the gradient magnitude of each in-
put feature to measure its relevance to the model prediction;
meanwhile, ADV2 heavily uses the gradient information to
optimize the prediction loss (cid:96)prd; it is inherently difﬁcult to
minimize (cid:96)prd while keeping the gradient intact.
We validate the conjecture by analyzing the robustness
of integrated gradient (IG) [53], another back-propagation-
guided interpreter, against ADV2. Due to their fundamental
equivalence [3], the discussion here also generalizes to other
back-propagation interpreters (e.g., [48, 50, 51]).
At a high level, for the i-th feature of a given input x, IG
computes its attribution m[i] by aggregating the gradient of
f (x) along the path from a baseline input ¯x to x:
∂ f (tx + (1−t) ¯x)
(cid:90) 1
(11)
dt
m[i] = (x[i]− ¯x[i])
0
∂x[i]
Like other back-propagation interpretation models [3], IG
satisﬁes the desirable completeness axiom [48] that the attri-
butions sum up to the difference between f ’s predictions for
the given input x and the baseline ¯x.
To simplify the exposition, let us assume a binary classiﬁca-
tion setting with classes C = {+,−}. The DNN f predicts the
probability of x belonging to the positive class as f (x). Given
an input x◦ from the negative class, the adversary attempts to
craft an adversarial input x∗ to force f to misclassify x∗ as pos-
itive. We deﬁne the prediction loss as (cid:96)prd(x∗) = f (x∗)− f (x◦)
(i.e., the increase in the probability of positive prediction),
which can be computed as:
(cid:96)prd(x∗) =
∇ f (tx∗ + (1−t)x◦)(cid:62)(x∗ − x◦)dt
(12)
Meanwhile, we deﬁne the interpretation loss as (cid:96)int(x∗) =
(cid:107)m◦ − m∗(cid:107)1, where m◦ and m∗ are the attribution maps of x◦
and x∗ respectively. While it is difﬁcult to directly quantify
(cid:96)int(x∗), we may use the attribution map of x∗ with x◦ as a
surrogate baseline:
(cid:90) 1
0
(cid:90) 1
0
∆m[i] = (x∗[i]− x◦[i])
∂ f (tx∗ + (1−t)x◦)
dt
(13)
∂x∗[i]
which quantiﬁes the impact of the i-th input feature on the
difference of f (x◦) and f (x∗). Thus, (cid:96)int(x∗) = (cid:107)∆m(cid:107)1.
Proposition 1. With IG, the prediction loss is upper bounded
by the interpretation loss as: (cid:96)prd(x∗) ≤ (cid:96)int(x∗).
Proof. We deﬁne u as the input difference u = (x∗ − x◦) and
v as the integral vector with its i-th element v[i] deﬁned as
(cid:90) 1
0
v[i] =
∂ f (tx∗ + (1−t)x◦)
∂x∗[i]
dt
USENIX Association
29th USENIX Security Symposium    1669
CAMAAACUnicbVJNTxsxEPWmfKZ8tsdeVoRKPUW7QFWOUC69VAKpASQcIe9klljxx8qeBSJr/0av7Y/qpX+FE06IVAgdydLTe2884ycXlZKesuxv0nqzsLi0vLLafru2vrG5tf3u3NvaAfbAKusuC+FRSYM9kqTwsnIodKHwohidTPSLW3ReWvODxhX2tbgxspQgKFKca0FDX4aT4+/N9VYn62bTSl+DfAY6bFan19tJxgcWao2GQAnvr/Kson4QjiQobNq89lgJGIkbvIrQCI2+H6ZLN+nHyAzS0rp4DKVT9nlHENr7sS6ic7rkvDYh/6sVem4ylYf9IE1VExp4GlzWKiWbThJJB9IhkBpHIMDJuHsKQ+EEUMytzQ3egdVamEHgANJBE/gIncm6n/Ge30J8PLrAh4W9D7vcxxsq8jRWyCfm3ab5527aMeN8PtHX4Hyvm+93984OOkdfZ2mvsA9sh31iOfvCjtg3dsp6DFjFfrJf7HfyJ3loxV/yZG0ls5737EW11h4BPu20sA==MASKAAACU3icbVDLThRBFK1uUXEUBVm66TiYuJp0o0aXqBsSQoLBARKqQ6rv3GYqU4+26jYyqfR3uNWPcsG3sLFmmAQdPEklJ+ee+6hTNUp6yvOrJL23cv/Bw9VHvcdP1p4+W994fuRt6wCHYJV1J5XwqKTBIUlSeNI4FLpSeFxNPs/qxxfovLTmK00bLLU4N7KWIChKJdeCxr4O+x8P97qz9X4+yOfI7pJiQfpsgYOzjSTnIwutRkOghPenRd5QGYQjCQq7Hm89NgIm4hxPIzVCoy/D/OouexWVUVZbF5+hbK7+3RGE9n6qq+icX7lcm4n/rVV6aTPVH8ogTdMSGrhZXLcqI5vNIslG0iGQmkYiwMl4ewZj4QRQDK7HDX4Hq7Uwo8ABpIMu8Ak6kw/e4SW/gPh5dIGPK3sZtriPExryNFXIZ+atrrt1d72YcbGc6F1ytD0o3gy2v7zt73xapL3KXrCX7DUr2Hu2w3bZARsyYN/YD/aT/Up+J9dpmq7cWNNk0bPJ/kG69gcUsLUVRTSAAACUnicbVJNTxsxEPWmH9CUttAee1k1VOop2oVW5YjKpUeg+ZJwhLyTWWLFHyt7lhJZ+ze4wo/qpX+FE06I1DZ0JEtP773xjJ9cVEp6yrLfSevJ02fPNzZftF9uvXr9Znvn7cDb2gH2wSrrRoXwqKTBPklSOKocCl0oHBazo4U+vETnpTU9mlc41uLCyFKCoEhxrgVNfRlOez+a8+1O1s2WlT4G+Qp02KqOz3eSjE8s1BoNgRLen+VZReMgHElQ2LR57bESMBMXeBahERr9OCyXbtKPkZmkpXXxGEqX7N8dQWjv57qIzuWS69qC/K9W6LXJVB6MgzRVTWjgYXBZq5RsukgknUiHQGoegQAn4+4pTIUTQDG3Njf4E6zWwkwCB5AOmsBn6EzW/YJX/BLi49EFPi3sVdjlPt5Qkae5Qr4w7zbNH3fTjhnn64k+BoO9br7f3Tv53Dn8tkp7k71nH9gnlrOv7JB9Z8esz4BV7JrdsNvkV3LXir/kwdpKVj3v2D/V2roHir602A==CAMAAACUnicbVJNTxsxEPWmfKZ8tsdeVoRKPUW7QFWOUC69VAKpASQcIe9klljxx8qeBSJr/0av7Y/qpX+FE06IVAgdydLTe2884ycXlZKesuxv0nqzsLi0vLLafru2vrG5tf3u3NvaAfbAKusuC+FRSYM9kqTwsnIodKHwohidTPSLW3ReWvODxhX2tbgxspQgKFKca0FDX4aT4+/N9VYn62bTSl+DfAY6bFan19tJxgcWao2GQAnvr/Kson4QjiQobNq89lgJGIkbvIrQCI2+H6ZLN+nHyAzS0rp4DKVT9nlHENr7sS6ic7rkvDYh/6sVem4ylYf9IE1VExp4GlzWKiWbThJJB9IhkBpHIMDJuHsKQ+EEUMytzQ3egdVamEHgANJBE/gIncm6n/Ge30J8PLrAh4W9D7vcxxsq8jRWyCfm3ab5527aMeN8PtHX4Hyvm+93984OOkdfZ2mvsA9sh31iOfvCjtg3dsp6DFjFfrJf7HfyJ3loxV/yZG0ls5737EW11h4BPu20sA==MASKAAACU3icbVDLThRBFK1uUXEUBVm66TiYuJp0o0aXqBsSQoLBARKqQ6rv3GYqU4+26jYyqfR3uNWPcsG3sLFmmAQdPEklJ+ee+6hTNUp6yvOrJL23cv/Bw9VHvcdP1p4+W994fuRt6wCHYJV1J5XwqKTBIUlSeNI4FLpSeFxNPs/qxxfovLTmK00bLLU4N7KWIChKJdeCxr4O+x8P97qz9X4+yOfI7pJiQfpsgYOzjSTnIwutRkOghPenRd5QGYQjCQq7Hm89NgIm4hxPIzVCoy/D/OouexWVUVZbF5+hbK7+3RGE9n6qq+icX7lcm4n/rVV6aTPVH8ogTdMSGrhZXLcqI5vNIslG0iGQmkYiwMl4ewZj4QRQDK7HDX4Hq7Uwo8ABpIMu8Ak6kw/e4SW/gPh5dIGPK3sZtriPExryNFXIZ+atrrt1d72YcbGc6F1ytD0o3gy2v7zt73xapL3KXrCX7DUr2Hu2w3bZARsyYN/YD/aT/Up+J9dpmq7cWNNk0bPJ/kG69gcUsLUVRTSAAACUnicbVJNTxsxEPWmH9CUttAee1k1VOop2oVW5YjKpUeg+ZJwhLyTWWLFHyt7lhJZ+ze4wo/qpX+FE06I1DZ0JEtP773xjJ9cVEp6yrLfSevJ02fPNzZftF9uvXr9Znvn7cDb2gH2wSrrRoXwqKTBPklSOKocCl0oHBazo4U+vETnpTU9mlc41uLCyFKCoEhxrgVNfRlOez+a8+1O1s2WlT4G+Qp02KqOz3eSjE8s1BoNgRLen+VZReMgHElQ2LR57bESMBMXeBahERr9OCyXbtKPkZmkpXXxGEqX7N8dQWjv57qIzuWS69qC/K9W6LXJVB6MgzRVTWjgYXBZq5RsukgknUiHQGoegQAn4+4pTIUTQDG3Njf4E6zWwkwCB5AOmsBn6EzW/YJX/BLi49EFPi3sVdjlPt5Qkae5Qr4w7zbNH3fTjhnn64k+BoO9br7f3Tv53Dn8tkp7k71nH9gnlrOv7JB9Z8esz4BV7JrdsNvkV3LXir/kwdpKVj3v2D/V2roHir602A==SourceAAAB+HicbVC7TsMwFL0pr1IeDTCyWFRITFVSkGCsYGEsgj6kNqoc12mt2klkO0gl6pewMIAQK5/Cxt/gpBmg5UiWjs651z4+fsyZ0o7zbZXW1jc2t8rblZ3dvf2qfXDYUVEiCW2TiEey52NFOQtpWzPNaS+WFAuf064/vcn87iOVikXhg57F1BN4HLKAEayNNLSrA4H1RIr0Pr9xPrRrTt3JgVaJW5AaFGgN7a/BKCKJoKEmHCvVd51YeymWmhFO55VBomiMyRSPad/QEAuqvDQPPkenRhmhIJLmhBrl6u+NFAulZsI3k1lMtexl4n9eP9HBlZeyME40DcnioSDhSEcoawGNmKRE85khmEhmsiIywRITbbqqmBLc5S+vkk6j7p7XG3cXteZ1UUcZjuEEzsCFS2jCLbSgDQQSeIZXeLOerBfr3fpYjJasYucI/sD6/AFo2JOTTargetAAAB+HicbVDLSgMxFM3UV62Pjrp0EyyCqzJTBV0W3bis0Be0Q8mkaRuaZIbkjlCHfokbF4q49VPc+Tdm2llo64HA4Zx7uScnjAU34HnfTmFjc2t7p7hb2ts/OCy7R8dtEyWashaNRKS7ITFMcMVawEGwbqwZkaFgnXB6l/mdR6YNj1QTZjELJBkrPuKUgJUGbrkvCUy0TJtEjxnMB27Fq3oL4HXi56SCcjQG7ld/GNFEMgVUEGN6vhdDkBINnAo2L/UTw2JCp2TMepYqIpkJ0kXwOT63yhCPIm2fArxQf2+kRBozk6GdzGKaVS8T//N6CYxugpSrOAGm6PLQKBEYIpy1gIdcMwpiZgmhmtusmE6IJhRsVyVbgr/65XXSrlX9y2rt4apSv83rKKJTdIYukI+uUR3dowZqIYoS9Ixe0Zvz5Lw4787HcrTg5Dsn6A+czx9ZVpOJGRADAAACU3icbVDLThRBFK1uUXEUBVm66TiYuJp0o0aXqCSwROIACdUh1XduM5WpR1t1G5lU+jvc6ke54FvYWDNMgg6epJKTc8991KkaJT3l+VWS3lu5/+Dh6qPe4ydrT5+tbzw/8rZ1gEOwyrqTSnhU0uCQJCk8aRwKXSk8riafZ/XjC3ReWvOVpg2WWpwbWUsQFKWSa0FjX4e9w4+73dl6Px/kc2R3SbEgfbbAwdlGkvORhVajIVDC+9Mib6gMwpEEhV2Ptx4bARNxjqeRGqHRl2F+dZe9isooq62Lz1A2V//uCEJ7P9VVdM6vXK7NxP/WKr20meoPZZCmaQkN3CyuW5WRzWaRZCPpEEhNIxHgZLw9g7FwAigG1+MGv4PVWphR4ADSQRf4BJ3JB+/wkl9A/Dy6wMeVvQxb3McJDXmaKuQz81bX3bq7Xsy4WE70LjnaHhRvBttf3vZ3Pi3SXmUv2Ev2mhXsPdth++yADRmwb+wH+8l+Jb+T6zRNV26sabLo2WT/IF37A/ontQc=GRADAAACU3icbVDLThRBFK1uUXEUBVm66TiYuJp0o0aXqCSwROIACdUh1XduM5WpR1t1G5lU+jvc6ke54FvYWDNMgg6epJKTc8991KkaJT3l+VWS3lu5/+Dh6qPe4ydrT5+tbzw/8rZ1gEOwyrqTSnhU0uCQJCk8aRwKXSk8riafZ/XjC3ReWvOVpg2WWpwbWUsQFKWSa0FjX4e9w4+73dl6Px/kc2R3SbEgfbbAwdlGkvORhVajIVDC+9Mib6gMwpEEhV2Ptx4bARNxjqeRGqHRl2F+dZe9isooq62Lz1A2V//uCEJ7P9VVdM6vXK7NxP/WKr20meoPZZCmaQkN3CyuW5WRzWaRZCPpEEhNIxHgZLw9g7FwAigG1+MGv4PVWphR4ADSQRf4BJ3JB+/wkl9A/Dy6wMeVvQxb3McJDXmaKuQz81bX3bq7Xsy4WE70LjnaHhRvBttf3vZ3Pi3SXmUv2Ev2mhXsPdth++yADRmwb+wH+8l+Jb+T6zRNV26sabLo2WT/IF37A/ontQc=According to the deﬁnitions, we have (cid:96)prd(x∗) = u(cid:62)v and
(cid:96)int(x∗) = (cid:107)u(cid:12) v(cid:107)1, where (cid:12) is the Hadamard product.
We have the following derivation: (cid:96)prd(x∗) = ∑i u[i]v[i] ≤
∑i(cid:107)u[i] · v[i](cid:107) = (cid:96)int(x∗). Thus the prediction loss is upper-
bounded by the interpretation loss.
In other words, in order to force x∗ to be misclassiﬁed
with high conﬁdence, the difference of benign and adversarial
attribution maps needs to be large. As the objectives of ADV2
here is to maximize the prediction loss while minimizing
the interpretation loss. The coupling between prediction and
interpretation losses results in a fundamental conﬂict.
Note that however this conﬂict does not preclude effec-
tive adversarial attacks. First, the constraint of prediction and
interpretation losses may be loose. Let γprd and γint be the
thresholds of effective attacks. That is, for an effective attack,
(cid:96)prd(x∗) ≥ γprd and (cid:96)int(x∗) ≤ γint. There could be cases that
γprd (cid:28) γint, making ADV2 still highly effective (e.g., Figure 8).
Second, the adversary may pursue attacks that rely less on the
gradient information to circumvent this conﬂict.
Overall, with the evidence of low attack transferability and
disparate attack robustness, we can conclude:
Observation 8
Existing interpreters tend to focus on distinct aspects
of DNN behavior, which may result in the prediction-
interpretation gap.
Q3. Potential Countermeasures
Based on our ﬁndings, next we discuss potential counter-
measures against ADV2 attacks.
Defense 1: Ensemble Interpretation – Motivated by the
observation that different interpreters focus on distinct aspects
of DNN behavior (e.g., CAM focuses on deep representations
while MASK focuses on input-prediction correspondence),
a promising direction to defend against ADV2 is to deploy
multiple, complementary interpreters to provide a holistic
view of DNN behavior.
Yet, two major challenges remain to be addressed. First, dif-
ferent interpreters may provide disparate interpretations (e.g.,
Figure 14). It is challenging to optimally aggregate such inter-
pretations to detect ADV2. Second, the adversary may adapt
ADV2 to the ensemble interpreter (e.g. optimizing the inter-
pretation loss with respect to all the interpreters). It is crucial
to account for such adaptiveness in designing the ensemble in-
terpreter. We consider developing the ensemble defenses and
exploring the adversary’s adaptive strategies as our ongoing
research directions.