all other strategies are derived. The choice of strategy that
acts as anchor strategy is also experimentally investigated in
Section IV-A.
C. Discussion
There are a number of features, ideas and assumptions in our
approach that merit further discussion. The main idea behind
our work is to model the uncertainty of input parameter values
caused by imperfect data collection. Although we use Normal
distributions based on the Central Limit Theorem, this is not
essential for our approach. Any model of parameter value
uncertainty can be used, including distributions different to
the Normal, and our solution approach still works, as does
the Basic Algorithm 1. Whether importance sampling can be
applied may depend on the speciﬁcs of the uncertainty mod-
elling approach. In general, the importance sampling approach
is valid as long as different strategies use the same sources,
since then the quotient in the weight (7) is well-deﬁned. We
already referred to this when discussing Equation (10). Of
note with respect to the application of importance sampling is
that in Equation (15) we have made the implicit assumption
that sources are independent, in order to use the product of
weights, and work out a speciﬁc case in detail. It should be
noted, however, that independence is not necessary to make
the importance sampling approach valid, the key aspect is that
the weight in Equation (15) are well-deﬁned.
The use of the Normal distribution is motivated by the
Central Limit Theorem applied to sample based data sources
(such as questionnaires or periodic measurements). This is
especially appropriate if some pilot run has been conducted,
because this would facilitate a faithful estimation of the sample
mean and sample variance based on already available data.
(In our formalism, Mi,j > 0 can be interpreted as that a
pilot run has been conducted for source Di,j.) However, even
if there are no initial samples (Mi,j = 0) one can use our
approach, it simply implies that parameters of the Normal need
to be based on experience of the modeller or other insights in
data collection. This may be a valid approach. Note that an
implicit assumption in our approach is that all sources Di,j for
one input parameter pi are unbiased and thus all converge to
provide the same value for the parameter when the number of
samples increases. It may be possible to relax this assumption,
but this needs to be studied.
An important characteristic of the current work is that we
aim at determining parameter values, and do not question
whether assumptions about model distributions, utility func-
tions, rewards or model structure are valid (such as discussed
in a general context in [13]). In particular, it means that we
consider strategies for determining input parameters such as
the mean, variance or other parameters of a distribution, but
not the distribution itself. As an example, if the model contains
a transition that is exponentially distributed, this paper aims to
estimate the mean of the distribution. This may sometimes lead
to the paradoxical situation in which we estimate a distribution
parameter based on samples, while the sample set itself does
not ﬁt the model distribution. If there was sufﬁcient uncertainty
about a distribution, it would be beneﬁcial to analyse the
samples against the chosen distributions during application
of the algorithm and after collection (not discussed here).
Uncertainty about the distributions, while attempting to blindly
reduce uncertainty of distribution parameters, could provide
false conﬁdence in uncertainty reduction. However, we feel
that it is fair to consider this issue beyond the scope of this
work. We accept that the modeller has chosen or created a
certain model, either because it reﬂects reality or because
it is appropriate for the assessment question addressed, and
we do not currently question the modeller’s decision and
validation. The distributions may also have been conﬁrmed
with initial sample collection M (Di,j). We look forward to
tackling this problem in future work. We believe that the
current work is relevant for many modelling exercises, for
many manners of data collection, using diverse tools ranging
from questionnaires to system measurements.
IV. EXPERIMENTS
The previously described method is demonstrated and eval-
uated with a single buffer M/M/1 server model. The M/M/1
model provides us with analytical result for the model, and
we can therefore focus completely on the efﬁciency of the
remaining algorithms. For the M/M/1 example we will com-
pare the efﬁciency of the algorithms under various assumptions
about the variance of data sources, and we will show the
efﬁciency of importance sampling to allocate between invest-
ing in collecting data for the arrival rate and the server rate,
respectively. In addition, we will apply all four optimization
problems formulated in Section II to see the differences in
data collection strategies for different formulations.
A. M/M/1 Queue
A single buffer server is modelled using an M/M/1 queue.
Inter-arrival time is exponentially distributed with rate λ and
the service time is exponentially distributed with rate µ. This
implies that there are two input parameters, parameter p1 is the
rate of the interarrival time and parameter p2 is the rate of the
service time distribution. The performance measure of interest
E[Y ] is the average time a job spends in the queue. Note that
value for the input parameters must obey p1 < p2 (in terms
of values of these parameters), otherwise the queue length
is inﬁnite. In our sampling from the Normal distributions,
we ignore cases where not p1 < p2 and resample. This
does not change the correctness of our approach, since these
samples are discarded for any data collection strategy, and
hence the importance sampling equations remain well deﬁned.
We note that we use MATLAB to implement the algorithms
we introduced in Section III.
Fig. 1. Scenario 1 with N (D1,1) + N (D2,1) = 500
We present a summary of results for each optimization
problem in Section II using results of two scenarios: (1) One
source for p1 with a variable number of samples and one
similar variable source for p2, (2) One source for p1 with
a variable number of samples and a ﬁxed number of samples
for p2.
Scenario (1) has two sources D1,1 : µ1,1 = 1; σ2
1,1 =
0.85; M (D1,1) = 30; C1,1 = 1} and D2,1 : µ1,1 = 2; σ2
2,1 =
0.85; M (D2,1) = 30; C2,1 = 2. Scenario (2) has one source
D1,1 where µ1,1 = 1, σ2
1,1 = 1.3 and M (D1,1) = 50. All
optimization Problems are tested using 1000 model executions
per strategy unless otherwise stated.
1) Optimal Strategies: Applying Optimization Problem 1
(the Sample Constraint problem) to scenario (1) constrains
strategies in S with a sample budget N = 500 to be divided
up between selected sources D1,1 and D2,1. It follows that
the optimal strategy will be one that is using all N samples to
minimize V ar[Y |S]. Figure 1 shows the results, with only
strategies where N (D1,1) + N (D2,1) = 500, which was
obtained using the Basic Algorithm. We see from Figure 1
that in this example the optimal strategies are around an even
split of additional samples N, although a slight preference
for sampling for the arrival rate can be seen (lower values
of N (D2,1) have slightly less variance). The curve is not
completely smooth, as the graph shows one thousand samples
for each strategy, and data source sample size is incremented
in units of ten.
Using scenario (1) again, Optimization Problem 2 changes
the sample budget to a maximum total collection cost C = 500
and sample costs C1,1 = 1 and C2,1 = 2 respectively. By
plotting results for all strategies against total cost (similar to
Figure 3) it was conﬁrmed that the optimal result lies on the
line:
N (D1,1) × C1,1 + N (D2,1) × C2,1 = 500
Figure 2 displays results only for valid strategies that meet
this requirement. The optimal strategies now appear around
N (D2,1) = 150 (was around N (D2,1) = 200 to 250 in Figure
(16)
05010015020025030035040045050000.0050.010.0150.020.0250.030.0350.04Var[Y | s]Additional samples N(D2,1)  Direct, N(D1,1) + N(D2,1) = 500Fig. 2. Scenario 1 with N (D1,1) × C1,1 + N (D2,1) × C2,1 = 500
1), due to their higher relative cost of N (D2,1) compared
to N (D1,1). Figure 2 also shows a more optimal result for
N (D2,1) = 0 compared to N (D1,1) = 0 (the extremes), this
could be due to varying parameter importance but in this case
it is due to cost. 500 budget allows N (D1,1) = 500 samples
at the left limit versus N (D2,1) = 250 samples at the right
limit. Using the alternative objective function of Optimization
Problem 3 we wish to minimize total cost while achieving
a variance constraint V ar[g(Y )|s] ≤ V = 0.02 (V is set
to some arbitrary value). Figure 3 shows the variance results
for all tested strategies against their total cost. The x-axis
displays the total strategy cost C. The optimal strategy or
strategies have the smallest cost on the x-axis while being
on or below the line V ar[g(Y )|s] = 0.02. In this case
s = {N (D1,1) = 100, N (D2,1) = 20}. Depending upon
optimization implementation and granularity of strategy space,
it may be possible to ﬁnd more than one optimal strategy for
Optimization Problem 3 with equal total costs. A secondary
objective function similar to that of Optimization Problem 1
& 2 would then be needed to select one strategy.
2) Efﬁciency of Importance Sampling: The remaining ﬁg-
ure and table refer to the Importance Sampling Algorithm 2.
The ﬁrst aspect of interest is to determine the most suitable
anchor strategy. We will see that to make effective use of
importance sampling it is recommended to sample from a
distribution with a ‘wider’ bell curve than the target distri-
bution. Figure 4 uses scenario 2 to illustrate the effect of
changing the anchor strategy while keeping the number of
model executions small. When the anchor strategy samples
from narrow tailed distributions (larger N (Di,j)) the weight-
ing struggles to achieve reliable results for the conditional
variance V ar[g(Y )|s] under importance sampling. In Figure
4 the correct result is labelled ‘Direct’ and the narrower the
Normal distribution of the anchor strategy is, the slower the
importance sampling result converges to the correct result.
Therefore an anchor strategy should be selected containing
the widest source Normal distributions, an s with the smallest
M (Di,j)s and N (Di, j) = 0 (provided one of them is greater
than zero). A poor choice of anchor strategy can be overcome
Fig. 3.
Scenario 1: using Minimise Cost objective. The line represents
maximum variance constraint, Circles feasible strategies and Dots infeasible
strategies.
Fig. 4. Scenario 2: Results for the importance sampling algorithm for various
anchor strategies
by a very large increase in the number of model executions.
Importance sampling is used to reduce the number of model
executions required for analysis, thus the anchor strategy needs
to be set accordingly.
Our algorithms require a sound stopping criterion. We are
interested in variance V ar[g(Y )|s] of the output metric given a
strategy uncertainty model. To decide to stop the optimization
algorithm we need to know if all possible strategies have been
evaluated accurately enough, which implies that we need to
determine a conﬁdence interval for the obtained variance. We
obtain this from text books [12], and since conﬁdence intervals
are completely determined by sample variance, we can use
the sample variance (for any metric of interest) to indicate the
05010015020025000.0050.010.0150.020.0250.030.0350.040.045Additional samples N(D2,1)Var[Y | s]  Direct, C = 50005010015020025030035040045050000.020.040.060.080.10.12Var[Y | s]N(d1,1) x c1,1 + N(d2,1) x c2,1 = C (Total Cost)05010015020025030035040045050000.0050.010.0150.020.0250.030.0350.04Additional samples for N(d1,1)Var [Y | s]  DirectI−S Anchor S1 (n = 0)I−S Anchor S8 (n = 140)I−S Anchor S18 (n = 340)I−S Anchor S26 (n = 500)QUOTIENT FOR VARIANCE OF V ar[Y |s]: IMPORTANCE SAMPLING OVER DIRECT CALCULATION
TABLE I
Target
Anchor Strategy
S1
[30, 30]
1
0.82609
0.42109
1.1178
1.1648
1.8015
0.24214
0.29472
0.51816
S2
[80, 30]
0.39534
1
0.47161
1.1786
1.1244
4.0192
0.63847
0.22063
1.9607
S3
S4
S5
[130, 30]
2.6575
3.5862
1
2.1128
1.8657
8.0906
3.0317
0.4548
2.4763
[180, 30]
5.398
15.68
1.3688
1
0.69592
4.6036
4.3496
1.033
2.5019
[230, 30]
3.7175
9.6661
1.2236
1.4236
1
55.168
44.63
6.0554
20.912
S6
[30, 80]
4.5997
139.85
104.45
289.47
277.84
1
0.54142
0.65997
0.37716
S7
[80, 80]
2.9072
9.4262
1.2456
1.787
1.5899
1.8872
1
0.52511
0.70011
S8
S9
[130, 80]
3.9585
39.205
19.732
38.685
26.83
20.579
4.6086
1