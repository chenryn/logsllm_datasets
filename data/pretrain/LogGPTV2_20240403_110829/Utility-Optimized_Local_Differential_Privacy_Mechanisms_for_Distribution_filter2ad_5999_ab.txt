bility distribution p, which generates x ∈ X with probability
p(x). Let X = (X (1),··· ,X (n)) and Y = (Y (1),··· ,Y (n)) be
tuples of all personal data and all obfuscated data, respec-
tively. The data collector estimates p from Y by a method
described in Section 2.5. We denote by ˆp the estimate of
p. We further denote by C the probability simplex; i.e.,
C = {p|∑x∈X p(x) = 1,p(x) ≥ 0 for any x ∈ X}.
1Note that these data might be sensitive for many/most users but not for all
in practice (e.g., some people might not care about their cheating experience).
However, we can regard these data as sensitive for all users (i.e., be on the
safe side) by allowing a small loss of data utility.
2.2 Privacy Measures
LDP (Local Differential Privacy) [19] is deﬁned as follows:
Deﬁnition 1 (ε-LDP). Let ε ∈ R≥0. An obfuscation mecha-
nism Q from X to Y provides ε-LDP if for any x,x(cid:48) ∈ X and
any y ∈ Y ,
Q(y|x) ≤ eεQ(y|x(cid:48)).
(1)
LDP guarantees that an adversary who has observed y can-
not determine, for any pair of x and x(cid:48), whether it is come from
x or x(cid:48) with a certain degree of conﬁdence. As the privacy
budget ε approaches to 0, all of the data in X become almost
equally likely. Thus, a user’s privacy is strongly protected
when ε is small.
2.3 Utility Measures
In this paper, we use the l1 loss (i.e., absolute error) and
the l2 loss (i.e., squared error) as utility measures. Let l1
(resp. l2
2) be the l1 (resp. l2) loss function, which maps
the estimate ˆp and the true distribution p to the loss; i.e.,
l1(ˆp,p) = ∑x∈X |ˆp(x)−p(x)|, l2
2 (ˆp,p) = ∑x∈X (ˆp(x)−p(x))2.
It should be noted that X is generated from p and Y is gener-
ated from X using Q(1),··· ,Q(n). Since ˆp is computed from
Y, both the l1 and l2 losses depend on Y.
In our theoretical analysis in Sections 4 and 5, we take the
expectation of the l1 loss over all possible realizations of Y.
In our experiments in Section 6, we replace the expectation of
the l1 loss with the sample mean over multiple realizations of
Y and divide it by 2 to evaluate the TV (Total Variation). In
Appendix C, we also show that the l2 loss has similar results to
the ones in Sections 4 and 6 by evaluating the expectation of
the l2 loss and the MSE (Mean Squared Error), respectively.
2.4 Obfuscation Mechanisms
We describe the RR (Randomized Response) [29, 30] and a
generalized version of the RAPPOR [51] as follows.
Randomized response. The RR for |X|-ary alphabets was
studied in [29, 30]. Its output range is identical to the input
domain; i.e., X = Y .
Formally, given ε ∈ R≥0, the ε-RR is an obfuscation mech-
anism that maps x to y with the probability:
(cid:40) eε
|X|+eε−1
|X|+eε−1
1
QRR(y|x) =
(if y = x)
(otherwise).
(2)
It is easy to check by (1) and (2) that QRR provides ε-LDP.
Generalized RAPPOR. The RAPPOR (Randomized Ag-
gregatable Privacy-Preserving Ordinal Response) [23] is an
obfuscation mechanism implemented in Google Chrome
browser. Wang et al. [51] extended its simplest conﬁgura-
tion called the basic one-time RAPPOR by generalizing two
USENIX Association
28th USENIX Security Symposium    1879
probabilities in perturbation. Here we call it the generalized
RAPPOR and describe its algorithm in detail.
The generalized RAPPOR is an obfuscation mechanism
with the input alphabet X = {x1,x2,··· ,x|X|} and the output
alphabet Y = {0,1}|X|. It ﬁrst deterministically maps xi ∈ X
to ei ∈ {0,1}|X|, where ei is the i-th standard basis vector. It
then probabilistically ﬂips each bit of ei to obtain obfuscated
data y = (y1,y2,··· ,y|X|) ∈ {0,1}|X|, where yi ∈ {0,1} is the
i-th element of y. Wang et al. [51] compute ε from two pa-
rameters θ ∈ [0,1] (representing the probability of keeping
1 unchanged) and ψ ∈ [0,1] (representing the probability of
ﬂipping 0 into 1). In this paper, we compute ψ from two
parameters θ and ε.
Speciﬁcally, given θ ∈ [0,1] and ε ∈ R≥0, the (θ,ε)-
generalized RAPPOR maps xi to y with the probability:
QRAP(y|xi) = ∏1≤ j≤|X| Pr(y j|xi),
where Pr(y j|xi) = θ if i = j and y j = 1, and Pr(y j|xi) = 1−θ
if i = j and y j = 0, and Pr(y j|xi) = ψ =
(1−θ)eε+θ if i (cid:54)= j and
y j = 1, and Pr(y j|xi) = 1− ψ otherwise. The basic one-time
RAPPOR [23] is a special case of the generalized RAPPOR
where θ = eε/2
eε/2+1. QRAP also provides ε-LDP.
θ
2.5 Distribution Estimation Methods
Here we explain the empirical estimation method [2, 27, 29]
and the EM reconstruction method [1,2]. Both of them assume
that the data collector knows the obfuscation mechanism Q
used to generate Y from X.
Empirical estimation method. The empirical estimation
method [2,27,29] computes an empirical estimate ˆp of p using
an empirical distribution ˆm of the obfuscated data Y. Note that
ˆp, ˆm, and Q can be represented as an |X|-dimensional vector,
|Y |-dimensional vector, and |X|×|Y | matrix, respectively.
They have the following equation:
ˆpQ = ˆm.
(3)
The empirical estimation method computes ˆp by solving (3).
Let m be the true distribution of obfuscated data; i.e.,
m = pQ. As the number of users n increases, the empiri-
cal distribution ˆm converges to m. Therefore, the empirical
estimate ˆp also converges to p. However, when the number
of users n is small, many elements in ˆp can be negative. To
address this issue, the studies in [23, 51] kept only estimates
above a signiﬁcance threshold determined via Bonferroni
correction, and discarded the remaining estimates.
EM reconstruction method.
The EM (Expectation-
Maximization) reconstruction method [1, 2] (also called the
iterative Bayesian technique [2]) regards X as a hidden vari-
able and estimates p from Y using the EM algorithm [26] (for
details of the algorithm, see [1, 2]). Let ˆpEM be an estimate
of p by the EM reconstruction method. The feature of this
Figure 1: Overview of ULDP. It has no transitions from XS to
YI, and every output in YI reveals the corresponding input in
XN. It also provides ε-LDP for YP.
algorithm is that ˆpEM is equal to the maximum likelihood
estimate in the probability simplex C (see [1] for the proof).
Since this property holds irrespective of the number of users
n, the elements in ˆpEM are always non-negative.
In this paper, our theoretical analysis uses the empirical
estimation method for simplicity, while our experiments use
the empirical estimation method, the one with the signiﬁcance
threshold, and the EM reconstruction method.
3 Utility-Optimized LDP (ULDP)
In this section, we focus on the common-mechanism sce-
nario (outlined in Section 2.1) and introduce ULDP (Utility-
optimized Local Differential Privacy), which provides a pri-
vacy guarantee equivalent to ε-LDP only for sensitive data.
Section 3.1 provides the deﬁnition of ULDP. Section 3.2
shows some theoretical properties of ULDP.
3.1 Deﬁnition
Figure 1 shows an overview of ULDP. An obfuscation mech-
anism providing ULDP, which we call the utility-optimized
mechanism, divides obfuscated data into protected data and
invertible data. Let YP be a set of protected data, and YI =
Y \ YP be a set of invertible data.
The feature of the utility-optimized mechanism is that it
maps sensitive data x ∈ XS to only protected data y ∈ YP.
In other words, it restricts the output set, given the input
x ∈ XS, to YP. Then it provides ε-LDP for YP; i.e., Q(y|x) ≤
eεQ(y|x(cid:48)) for any x,x(cid:48) ∈ X and any y ∈ YP. By this property,
a privacy guarantee equivalent to ε-LDP is provided for any
sensitive data x ∈ XS, since the output set corresponding to
XS is restricted to YP. In addition, every output in YI reveals
the corresponding input in XN (as in Mangat’s randomized
response [37]) to optimize the estimation accuracy.
We now formally deﬁne ULDP and the utility-optimized
mechanism:
Deﬁnition 2 ((XS,YP,ε)-ULDP). Given XS ⊆ X , YP ⊆ Y ,
and ε ∈ R≥0, an obfuscation mechanism Q from X to Y pro-
vides (XS,YP,ε)-ULDP if it satisﬁes the following properties:
1880    28th USENIX Security Symposium
USENIX Association
ࣲௌࣲࣲேࣳ௉ࣳࣳூH/'31. For any y ∈ YI, there exists an x ∈ XN such that
Q(y|x) > 0 and Q(y|x(cid:48)) = 0 for any x(cid:48) (cid:54)= x.
2. For any x,x(cid:48) ∈ X and any y ∈ YP,
Q(y|x) ≤ eεQ(y|x(cid:48)).
(4)
(5)
We refer to an obfuscation mechanism Q providing (XS,YP,
ε)-ULDP as the (XS,YP,ε)-utility-optimized mechanism.
Example. For an intuitive understanding of Deﬁnition 2,
we show that Mangat’s randomized response [37] provides
(XS,YP,ε)-ULDP. As described in Section 1, this mechanism
considers binary alphabets (i.e., X = Y = {0,1}), and regards
the value 1 as sensitive (i.e., XS = YP = {1}). If the input
value is 1, it always reports 1 as output. Otherwise, it reports
1 and 0 with probability p and 1− p, respectively. Obviously,
this mechanism does not provide ε-LDP for any ε ∈ [0,∞).
However, it provides (XS,YP,ln 1
(XS,YP,ε)-ULDP provides a privacy guarantee equivalent
to ε-LDP for any sensitive data x ∈ XS, as explained above.
On the other hand, no privacy guarantees are provided for
non-sensitive data x ∈ XN because every output in YI reveals
the corresponding input in XN. However, it does not matter
since non-sensitive data need not be protected. Protecting
only minimum necessary data is the key to achieving locally
private distribution estimation with high data utility.
p )-ULDP.
We can apply any ε-LDP mechanism to the sensitive data
in XS to provide (XS,YP,ε)-ULDP as a whole. In Sections 4.1
and 4.2, we propose a utility-optimized RR (Randomized
Response) and utility-optimized RAPPOR, which apply the
ε-RR and ε-RAPPOR, respectively, to the sensitive data XS.
In Appendix B, we also consider OSLDP (One-sided LDP),
a local model version of OSDP introduced in a preprint [17],
and explain the reason for using ULDP in this paper.
It might be better to generalize ULDP so that different
levels of ε can be assigned to different sensitive data. We
leave introducing such granularity as future work.
Remark. It should also be noted that the data collector needs
to know Q to estimate p from Y (as described in Section 2.5),
and that the (XS,YP,ε)-utility-optimized mechanism Q itself
includes the information on what is sensitive for users (i.e.,
the data collector learns whether each x ∈ X belongs to XS or
not by checking the values of Q(y|x) for all y ∈ Y ). This does
not matter in the common-mechanism scenario, since the set
XS of sensitive data is common to all users (e.g., public hospi-
tals). However, in the personalized-mechanism scenario, the
(XS∪X (i)
S ,YP,ε)-utility-optimized mechanism Q(i), which ex-
pands the set XS of personal data to XS ∪ X (i)
S , includes the
information on what is sensitive for the i-th user. Therefore,
the data collector learns whether each x ∈ XN belongs to X (i)
or not by checking the values of Q(i)(y|x) for all y ∈ Y , de-
spite the fact that the i-th user wants to hide her user-speciﬁc
S
sensitive data X (i)
S
issue in Section 5.
(e.g., home, workplace). We address this
3.2 Basic Properties of ULDP
Previous work showed some basic properties of differential
privacy (or its variant), such as compositionality [22] and im-
munity to post-processing [22]. We brieﬂy explain theoretical
properties of ULDP including the ones above.
Sequential composition. ULDP is preserved under adap-
tive sequential composition when the composed obfuscation
mechanism maps sensitive data to pairs of protected data.
Speciﬁcally, consider two mechanisms Q0 from X to Y0 and
Q1 from X to Y1 such that Q0 (resp. Q1) maps sensitive data
x ∈ XS to protected data y0 ∈ Y0P (resp. y1 ∈ Y1P). Then the
sequential composition of Q0 and Q1 maps sensitive data
x ∈ XS to pairs (y0,y1) of protected data ranging over:
(Y0 × Y1)P = {(y0,y1) ∈ Y0 × Y1 | y0 ∈ Y0P and y1 ∈ Y1P} .
Then we obtain the following compositionality.
Proposition 1 (Sequential composition). Let ε0,ε1 ≥ 0. If
Q0 provides (XS,Y0P,ε0)-ULDP and Q1(y0) provides (XS,
Y1P,ε1)-ULDP for each y0 ∈ Y0, then the sequential composi-
tion of Q0 and Q1 provides (XS, (Y0 × Y1)P,ε0 + ε1)-ULDP.
For example, if we apply an obfuscation mechanism
providing (XS,YP,ε)-ULDP for t
times, then we obtain
(XS, (YP)t ,εt)-ULDP in total (this is derived by repeatedly
using Proposition 1).
Post-processing. ULDP is immune to the post-processing by
a randomized algorithm that preserves data types: protected
data or invertible data. Speciﬁcally, if a mechanism Q0 pro-
vides (XS,YP,ε)-ULDP and a randomized algorithm Q1 maps
protected data over YP (resp. invertible data) to protected data
over ZP (resp. invertible data), then the composite function