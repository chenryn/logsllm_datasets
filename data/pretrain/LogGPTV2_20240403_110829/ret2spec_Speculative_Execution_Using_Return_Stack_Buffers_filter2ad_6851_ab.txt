after handling the fault, the cache line for that address will
remain cached, thus creating a side channel for leaking the
data. Conversely, Spectre uses legitimate features of branch
predictors to mount an attack: it mistrains the BPU for
conditional branches in Variant 1, and injects BTB entries
with arbitrary branch targets in Variant 2. Variant 1 can
be used to bypass bounds checking and thus read outside
the permitted bounds, while Variant 2 allows cross-process
BTB injection, allowing arbitrary speculative execution of
the code in other processes on the same physical core.
2.3 Return Stack Buffers
Return instructions are a specific type of indirect branch and
always jump to the top element on the stack (i.e., translated
to pop tmp; jmp tmp). Consequently, in principle, BTBs can
also be used here as a generic prediction mechanism. However,
given that functions are called from multiple different places,
BTBs will frequently mispredict the jump destination. To
increase the prediction rate, hardware manufacturers rely on
the fact that call and return instructions are always executed
in pairs. Therefore, to predict the return address at a return
site, CPUs remember the address of the instruction following
the corresponding call instruction. This prediction is done
via return stack buffers (RSBs) that store the ùëÅ most recent
return addresses (i.e., the addresses of instructions after the
ùëÅ most recent calls). Note that, in case of hyperthreading,
RSBs are dedicated to a logical core. The RSB size, ùëÅ, varies
per microarchitecture. Most commonly, RSBs are ùëÅ = 16
entries large, and the longest reported RSB contains ùëÅ = 32
entries in AMD‚Äôs Bulldozer architecture [11]. In this paper, we
assume an RSB size of 16, unless explicitly stated otherwise,
but our principles also work for smaller or larger RSBs.
RSBs are modified when the CPU executes a call or return
instruction. Calls are simple: a new entry (the address of the
next instruction) is added to the RSB and the top pointer
is incremented. If the RSB was already full, the oldest entry
will be discarded. Conversely, in case the of a return instruc-
tion, the value is taken from the RSB, the top pointer is
decremented, and the read value is used for prediction.
Due to the their limited size, it naturally happens that
the RSBs cannot fit all the return addresses. For example,
ùëÅ + 1 calls followed by ùëÅ + 1 returns will underflow the RSB
in the last return instruction. The way such an underflow
is handled depends on the microarchitecture. There are the
following possible scenarios: (a) stop predicting whenever
the RSB is empty, (b) stop using the RSB and switch to
the BTB for predictions, and (c) use the RSB as a ring
buffer and continue predicting (using ùëñùëëùë•%ùëÅ as the RSB top
pointer). Out of these scenarios, (a) is the easiest to imple-
ment; however, it stops predicting return addresses as soon
as the RSB is empty. The prediction rate is improved in (b),
which incorporates the BTB to predict return destinations.
However, the improvement is made at the expense of BTB
entries, which might detriment other branches. Finally, (c)
is an optimization for deep recursive calls, where all RSB
entries return to the same function. Therefore, no matter
how deep the recursion is, returns to the recursive function
will be correctly predicted. According to a recent study [37],
most Intel CPUs use the cyclic behavior described in variant
(c), while AMD‚Äôs use variant (a) and stop prediction upon
RSB underflows. Intel microarchitectures after Skylake are
known to use variant (b)3. Throughout the paper, we will
refer to (c) as cyclic, and (a) and (b) as non-cyclic.
3 GENERAL ATTACK OVERVIEW
Before detailing specific attack scenarios, in this section, we
introduce the basics of how RSB-based speculative execution
can be achieved and be abused. We explore whether and how
attackers may manipulate the RSB entries in order to leak
sensitive data using speculative execution that they could
not access otherwise. Similar to recent microarchitectural
attacks [8, 10, 22, 26, 29], we trick the CPU to execute in-
structions that would not have been executed in a sequential
execution. The goal is to leak sensitive information in spec-
ulation, e.g., by caching a certain memory area that can
be detected in a normal (non-speculative) execution. The
general idea of our attack can be divided into three steps:
(A1) trigger misspeculations in the return address predic-
tor, i.e., enforce that returns mispredict
(A2) divert the speculative execution to a known/con-
trolled code sequence with the required context
(A3) modify the architectural state in speculation, such
that it can be detected from outside
(A1) Triggering Misspeculation: From an attacker‚Äôs per-
spective, enforcing that the return predictor misspeculates
upon function return is essential to reliably divert speculative
execution to attacker-controlled code (see A2 for how to con-
trol the speculated code). Misspeculations can be achieved in
several ways, depending on the RSBs underflow behavior (as
discussed in Section 2.3).
Non-Cyclic RSB: If the RSB stops speculating upon under-
flow, triggering a misspeculation will require abnormal control
flow that violates the common assumption that functions re-
turn to their caller. Some examples of such abnormalities are:
(i) exception handling, i.e., a try-catch block in the upper call
stack and throwing an exception in a lower one (Figure 1a);
(ii) a setjmp/longjmp pair, i.e., saving the current execution
context at the time of calling setjmp, and restoring it at any
3https://patchwork.kernel.org/patch/10150765/
4
later point when (longjmp) is called (the stack layout will be
similar to Figure 1a, only with setjmp/longjmp instead of
try-catch/throw); (iii) a context switch from one process to
another, where the process being evicted was doing a chain of
calls, while the scheduled process will do a sequence of returns
(Figure 1b); and (iv) a process that deliberately overwrites
the return address to the desired destination and then re-
turns (Figure 1c). Unsurprisingly, (iv) is not commonly used;
however, it can be helpful for testing RSBs and triggering
the misspeculation on demand. In fact, in contrast to branch
predictors, which require training to trigger misspeculation,
RSBs can be forced to misspeculate with just a single write
instruction (mov [rsp], ADDRESS; ret, as in Figure 1c).
Cyclic RSB: If RSBs are cyclic, misspeculation can‚Äîin
addition to the methods mentioned before‚Äîbe triggered by
overflowing the RSB. Figure 1d depicts a scenario in which
function A calls B, function B calls C, and so on. Being limited
in size (ùëÅ = 4 in this example), the RSB only contains
the 4 most recently added return addresses. Therefore, after
correctly predicting four returns, when returning from E, the
RSB will mispredict H as the return address instead of D.
Cyclic RSBs can also be leveraged and prepared by recur-
sive functions. For example, if we have two recursive functions
A and B, and we call them in the following order:
‚àô A calls itself recursively ùëÅùê¥ times,
‚àô in its deepest recursion level, A then calls B
‚àô B calls itself recursively 16 times (size of the RSB)
then the first 16 returns, from B, will be predicted correctly.
However, the remaining ùëÅùê¥ returns will be mispredicted,
and B‚Äôs call site will be speculated instead of A‚Äôs.
(A2) Diverting Speculative Execution: Being able to trigger
a misspeculation, the next step is to control the code that
is executed speculatively. Generally, misspeculation means
that instructions from one function (e.g., B) are speculatively
executed within the context of another (e.g., A). As a simple
example, consider a function that returns a secret value in rax.
If this function is predicted to return to code that accesses
attacker-accessible memory relative to rax, this will leak the
secret value. Ideally, we control both, the context and the
speculated code; however, having either one or the other can
also be sufficient for a successful exploitation.
Let function B return and trigger a misspeculation in A
(right after the call to B). In the ideal case, we control the code
that is misspeculated in A, and the context (i.e., the contents
of the registers) in B. Combining them together allows us to
execute arbitrary code speculatively. This will be the case for
our attack in Section 5. Another, more complicated case is
when the context is fixed, e.g., the values of some registers are
known, and we are also limited with the possibly-speculated
code, e.g., it can be chosen from existing code pieces. In this
case, the challenge is to find code gadgets that use the correct
registers from the context to leak their values. For example,
if we know that r8 contains a secret, we need to find a gadget
that leaks r8. This case will be shown in Section 4.
(A3) Feedback Channel: Finally, being able to execute arbi-
trary code in speculation, we have to report back the results
(a) Exception handling: While the RSB predicts a return to function
Z, the exception is caught by function C, causing a chain of misspec-
ulations when C returns, as the RSB is misaligned to the return
addresses on the stack.
(b) Context switch: When the kernel switches from process P1 to P2,
the kernel will only evict a few entries with kernel-internal functions.
After the context switch, P2 may thus mispredict and return to the
remaining RSB entries that were added by P1.
(c) Direct overwrite: A process can enforce return mispredictions by
replacing return addresses stored on the stack.
(d) Circular RSB: After returning ùëÅ = 4 times, the predictor cycles
over and will repeat the same prediction sequence of return addresses.
Figure 1: Ways to enforce RSB misspeculation. We reduced the RSB size to ùëÅ = 4 entries for readability. The bold arrow points
to the top element of each RSB. Thin solid arrows indicate actual returns, thin dashed arrows speculated returns.
from within the speculative execution to the normal execu-
tion environment. To this end, similar to several side channels
proposed in the past [17, 31, 38], we use secret-dependent
memory accesses that modify the caching state. Technically, if
we want to leak the value in rax, we read attacker-accessible
memory using the secret value as offset, e.g., shl rax, 12;
mov r8, [rbx + rax]. This will result in caching the corre-
sponding memory address (rbx+rax*4096, where 4096 bytes
is the page size). Therefore, identifying the index of the
cached page from rbx will reveal the value of rax.
The adversary can then use existing side channel techniques
to observe these cache changes, such as Flush+Reload [38]
or Prime+Probe [31]. Flush+Reload is most accurate, but
requires that the attacker and victim processes share memory.
Typically this is granted, given that operating systems share
dynamic libraries (e.g., libc) to optimize memory usage.
Alternatively, Prime+Probe [31] works even without shared
memory. Here, the attacker measures whether the victim
evicts one of the attacker-prepared cache lines. By detecting
the evicted cache line, the attacker can leak the address bits
corresponding to the cache line.
4 CROSS-PROCESS SPECULATIVE EXEC.
In this section, we will describe how an attacker can abuse the
general attack methodology described in the previous section
to leak sensitive data from another process. In Section 5, we
will describe RSB-based attacks in scripting environments to
read memory beyond the memory bounds of sandboxes.
4.1 Threat Model
In the following, we envision a local attacker that can execute
arbitrary user-level code on the victim‚Äôs system. The goal of
the attacker is to leak sensitive data from another process
(presumably of a different user) on the system, e.g., leaking
input fed to the target process. In our concrete example, we
target a command line program that waits for user input
5
...catchZYXWStackCBAZYXWRSBthrowretK.YP1.DK.XP1.DP1.CP1.BP1.AP1.CK.YK.XP1.DP1.CRSB of P1RSB of P2RSB of OSFCBAStackDCBARSBretmov [rsp], F...HGFEStackBA...HGFERSBCDretretretretretretretretret(character-by-character), i.e., a blocking stdin, and we aim
to read the user-entered data. This setting is in line with
Linux programs such as bash or sudo. The attack principle,
however, generalizes to any setting where attackers aim to
read confidential in-memory data from other processes (e.g.,
key material, password lists, database contents, etc.).
For demonstration purposes, we assume that the kernel
does not contain the Spectre patches, and thus does not flush
RSBs upon a context switch. Furthermore, we assume that
the victim process contains all attacker-required gadgets. In
our example, we simply add these code pieces to the victim
process. Finally, we assume that ASLR is either disabled or
has been broken by the attacker.
4.2 Triggering Speculative Code Execution
We now apply the general attack principles to the scenario
where an adversarial process executes alongside a victim
process. The attacker aims to trigger return address mispre-
diction in the victim‚Äôs process, and divert the speculative
control flow to an attacker-controlled location. The fact that
victim and attacker are in different processes complicates
matters, as the context of the execution (i.e., the register
contents) is not under the control of the attacker. To the
attacker‚Äôs benefit, though, the RSB is shared across processes
running on the same logical CPU core. This allows the RSB
to be poisoned from one process, and then be used by another
process after a context switch. For this attack to work, we
have to perform the following steps:
‚àô We first fill the RSB with addresses of suitable code
gadgets that leak secrets by creating a call instruction
just before these gadgets‚Äô addresses and executing the
call 16 times (step A2 from Section 3).
RSBs store virtual addresses of target instructions.
Therefore, in order to inject the required address, we
assume the attacker knows the target process‚Äôs address
space. Alternatively, in the case of a randomized ad-
dress space (e.g., with ASLR), we can use RSBs the
opposite way, i.e., to leak the RSB entries, and thus to
reveal the addresses of the victim process.
‚àô After filling the RSB, we force a context switch to the
victim process (step A1 from Section 3). For example,
the attacker could call sched_yield in order to ask
the kernel to reschedule, ideally to the victim process.
For this, we assume that our process runs on the same
logical CPU core as the victim, and thus shares the
RSB. This can be accomplished by changing the affinity
of our process, to pin it to the victim‚Äôs core (e.g., by
using taskset in Linux), or alternatively, spawn one
process per logical core.
4.3 Proof-of-Concept Exploit
To illustrate the general possibility of such cross-process data
leaks, we picked a scenario where an attacker wants to leak
user input, e.g., in order to capture user-entered passwords.
Thus, in our tested example, the victim is a terminal process
6
that waits for user input, such as bash or sudo. At a high
level, such processes execute the following code:
while (inp = read_char ( stdin )) {
handle_user_input (inp);
}
The following shows the (simplified) steps taken in a typical
iteration of such an input-processing loop:
(1) The main loop starts.
(2) read_char is called, which itself calls other intermedi-
ate functions, finally reaching the read system call.
(3) The stdin buffer will be empty (until the user starts
typing) and the victim process is thus evicted.
(4) When the user presses a key, the victim process, waiting
for buffer input, is scheduled.
(5) Execution continues within the read system call (which
has just returned), and a chain of returns are executed
until the execution reaches the main loop.
(6) handle_user_input handles the read character.
In order to leak key presses, the attacker process has to be
scheduled before the victim continues execution in (5). This
will guarantee that when resuming the execution from read,
the victim process will use the attacker-tainted RSB entries.
4.3.1 Leaking Key Presses. To show the plausibility of this
attack, we implemented three programs:
Attacker: fills up RSB entries and preempts itself, so the
victim process is scheduled after it.
Measurer: probes for a predetermined set of memory