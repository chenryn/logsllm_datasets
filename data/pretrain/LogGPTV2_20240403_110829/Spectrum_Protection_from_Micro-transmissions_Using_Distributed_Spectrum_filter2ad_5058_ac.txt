smaller number of bits per sample compared to USRP and hence the compute
requirement is less.3
3.3 Variation in Transmitter’s Behavior
The detection performance depends on the received signal power relative to the
noise ﬂoor. To model this we vary the transmitter’s gain. Gain here is a scaling
factor that decides the power of the transmitted signal. When the received signal
power is low (due to the low gain in the Tx for example) there is a signiﬁcant
chance of false alarms. When the signal power is close to the noise ﬂoor, it
becomes diﬃcult for the sensors to diﬀerentiate between noise and the signal.
As a result, signal detection becomes diﬃcult because the sensors can falsely tag
noise as signal. The false alarm rate increases in this scenario as it is very hard to
detect the low power signals unless we keep the threshold close to noise. Keeping
the threshold closer to noise increases the probability of false alarm (PF A). We
choose a threshold similar to [5] by assuming the PF A as 10% and compute the
detection performance based on this threshold.
We experiment with the transmitter changing its gain from 100 to 1000 in
steps of 100. Figure 9 shows the detection performance during local and remote
processing. The detection ratio drops to zero when the transmitter changes its
gain to 50 during local processing on USRP-B210.4 The performance is much
worse on RTL-SDR, in that it becomes almost zero for gain around 200. This
performance degradation also exists for remote processing. The detection ratio
drops to 50% and 30% on USRP and RTL-SDR sensors respectively. The reason
3 Note that RTL-SDR has detection ratio similar USRP when the received signal
power is high. RTL-SDR performs poorly when the transmitter gain is very low and
signal power is close to noise ﬂoor (See Sect. 3.3).
4 Note that it is well known that signal power deteriorates as the transmitter decreases
its gain. The goal of this experiment is to understand the signiﬁcance of detecting
micro-transmissions under poor capabilities.
254
M. Dasari et al.
behind the poorer performance during the local processing is because of the dual
impact of PSD computation overheads and lower received signal power levels at
lower gain values. During remote processing, only lower gain has an impact on
the detection performance.
4 Discussion
In this section, we discuss the major ﬁndings of our study and provide a possible
solution to improve the detection performance of the inexpensive sensors.
4.1 Summary of Main Observations
The key takeaways of our benchmark study are:
– The optimal parameters for spectrum sensing such as eﬀective sampling rate,
FFT size, integration size need to be rethought for low-end inexpensive sen-
sors. For example, the optimal sampling rate of detecting 1 ms length micro-
transmissions on a Desktop is 8 Msps while on Odroid-C2 it is 1 Msps.
– Even when all signal processing is done remotely, the performance impact of
using low-end processors in the spectrum sensor could be signiﬁcant (<75%
on RPi-1 compared to Desktop, for 1 ms transmission). This is attributed to
two factors – (1) inaccurate spectrum sensors, and (2) poor compute hardware
that is not able to process high sampling rates.
– For local processing, availability of compute power is a much bigger factor
aﬀecting detection performance than the type of spectrum sensor. However,
this is not true for remote processing as the amount of samples dropped in
the network during shipping for remote processing is never high enough to
reduce detection ratio signiﬁcantly.
4.2 Data Fusion
In Sect. 3, we observed that inexpensive compute devices are limited in terms of
computation power because of their hardware. Moreover, the spectrum sensors
are also inaccurate in detecting the signal. We now overcome these limitations
and improve the signal detection performance while retaining the cost-eﬀective
motivation behind distributed sensing. We follow a similar idea from the previous
work [8] where the authors show that the inaccuracy of radios can be mitigated
by having more radios that are sensing together. This is because the samples are
dropped randomly by the devices due to computation bottleneck. The data is
later fused from all the sensors. Taking this further, we deploy 10 sensors each
with RTL-SDR and Odroid-C2 board at the same location in a campus area.
We use the same transmitter and the setup described in Sect. 2.1. The 10
sensors sense the single channel continuously, compute the PSD, and send the
power data to our central server. We use Kaa framework [16] and MongoDB [21]
to collect the data and store it in a central database. We use a fusing algorithm
Spectrum Protection from Micro-transmissions
255
Fig. 10. Improvement in detection performance with number of sensors used.
similar to [5] to combine the data from all the sensors. The detection perfor-
mance is shown in Fig. 10. We observe that using 8 sensors, a detection ratio of
almost 99% and 95% is reached in case of transmission lengths of 1 ms and 1 µs
respectively. This trade-oﬀ of cost versus performance beneﬁts shows that detec-
tion performance of inexpensive spectrum sensors can be improved by deploying
more sensors. A more complicated scenario is to detect the transmissions where
the transmitter is changing its gain. This brings the challenges of dealing with
PF A while fusing data and requires more sensors to detect all transmissions.
5 Related Work
The advent of inexpensive software radios has made the spectrum vulnerable to
unauthorized use [2,9,10,17,23,31]. We discuss two related lines of research: (1)
distributed spectrum patrolling, and (2) benchmarking of spectrum sensors.
Distributed Spectrum Patrolling: Multiple studies such as SpecSense [8],
ElectroSense [30] and RadioHound [18] have proposed deploying distributed
spectrum patrolling systems using commodity spectrum sensors. However, they
all deploy one or two diﬀerent varieties of sensors and compute devices. For
example, RadioHound uses RPi’s and laptops as the compute device whereas
ElectroSense and SpecSense use RPi’s and Odroid-C2’s respectively. Other stud-
ies such as [4] and [5] have focused on the heterogeneity of the sensors and their
impact on detection, or various performance issues related to distributed sensing,
such as inaccurate clocks [3] and noisy outputs [19,22]. However, these studies
do not investigate impact of sensing parameters or device hardware.
Benchmarking of Spectrum Sensors: A number of studies benchmark the
performance of individual spectrum sensors and the compute devices. For exam-
ple, [7,28] benchmarks the energy and performance trade-oﬀ of RPi and compare
it with a smartphone and a laptop based sensor. Other studies investigate the
performance of multiple compute devices such as RPi-2, RPi-3 and Beaglebone-
Black in the context of audio processing [11,12,20]. Finally, [29] benchmark FFT
computations on multiple inexpensive compute devices to study their utility for
on-board processing for space missions.
256
M. Dasari et al.
6 Conclusion
The demand for wireless spectrum sharing and co-existence technologies makes
large-scale, real-time spectrum measurements necessary. In this work, we explain
the key issues that current wide-area distributed spectrum sensing systems face,
by benchmarking the impact of sensor and device-related parameters when
detecting unauthorized micro-transmissions. We show that the detection per-
formance is no more than 45% even with optimal parameter settings for a 1 ms
transmission. The poor performance is mainly attributed to limited computation
capability of the device that results in lost samples. To improve this detection
performance, we deploy multiple sensors and demonstrate a 98% of detection
performance by fusing the data from all the sensors. We believe that this study
also serves the validation and reappraisal of distributed sensing systems such as
SpecSense [8] and ElectroSense [26].
Acknowledgments. This work is partially supported by NSF grant CNS-1642965 and
a grant from MSIT, Korea under the ICTCCP Program (IITP-2017-R0346-16-1007).
References
1. USRP B210. https://www.ettus.com/product/details/ub210-kit
2. Bazerque, J.A., Giannakis, G.B.: Distributed spectrum sensing for cognitive radio
networks by exploiting sparsity. IEEE Trans. Sig. Process. 58(3), 1847–1862 (2010)
3. Calvo-Palomino, R., Giustiniano, D., Lenders, V., Fakhreddine, A.: Crowdsourc-
ing spectrum data decoding. In: INFOCOM 2017-IEEE Conference on Computer
Communications, pp. 1–9. IEEE (2017)
4. Calvo-Palomino, R., Pfammatter, D., Giustiniano, D., Lenders, V.: A low-cost
sensor platform for large-scale wideband spectrum monitoring. In: Proceedings of
the 14th International Conference on Information Processing in Sensor Networks,
pp. 396–397. ACM (2015)
5. Chakraborty, A., Bhattacharya, A., Kamal, S., Das, S.R., Gupta, H., Djuric, P.M.:
Spectrum patrolling with crowdsourced spectrum sensors. In: IEEE INFOCOM
(2018)
6. Chakraborty, A., Das, S.R.: Measurement-augmented spectrum databases for white
space spectrum. In: CoNEXT, pp. 67–74. ACM (2014)
7. Chakraborty, A., Gupta, U., Das, S.R.: Benchmarking resource usage for spectrum
sensing on commodity mobile devices. In: Proceedings of the 3rd Workshop on Hot
Topics in Wireless, HotWireless 2016, pp. 7–11. ACM, New York (2016)
8. Chakraborty, A., Rahman, Md.S., Gupta, H., Das, S.R.: SpecSense: crowdsensing
for eﬃcient querying of spectrum occupancy. In: INFOCOM, pp. 1–9. IEEE (2017)
9. Chen, R., Park, J.-M., Bian, K.: Robust distributed spectrum sensing in cognitive
radio networks. In: INFOCOM, pp. 1876–1884. IEEE (2008)
10. Cordeiro, C., Challapali, K., et al.: Spectrum agile radios: utilization and sensing
architectures. In: DySPAN, pp. 160–169. IEEE (2005)
11. Dasari, M., Kelton, C., Nejati, J., Balasubramanian, A., Das, S.R.: Demystifying
hardware bottlenecks in mobile web quality of experience. In: Proceedings of the
SIGCOMM Posters and Demos, pp. 43–45. ACM (2017)
Spectrum Protection from Micro-transmissions
257
12. Dasari, M., Vargas, S., Bhattacharya, A., Balasubramanian, A., Das, S.R., Ferd-
man, M.: Impact of device performance on mobile internet QOE. In: Proceedings
of the Internet Measurement Conference 2018, pp. 1–7. ACM (2018)
13. NASA RF Propagation Database. https://propagation.grc.nasa.gov/
14. MTP Group et al.: Microsoft Spectrum Observatory, Seattle, November 2013
15. Iyer, A., Chintalapudi, K., Navda, V., Ramjee, R., Padmanabhan, V.N., Murthy,
C.R.: SpecNet: spectrum sensing sans frontieres. In: NSDI, pp. 351–364. USENIX
Association (2011)
16. KAA. https://www.kaaproject.org/
17. Khaledi, M., et al.: Simultaneous power-based localization of transmitters for
crowdsourced spectrum monitoring. In: Proceedings of the 23rd Annual Inter-
national Conference on Mobile Computing and Networking, pp. 235–247. ACM
(2017)
18. Kleber, N., et al.: RadioHound: a pervasive sensing platform for sub-6 GHZ
dynamic spectrum monitoring. In: 2017 IEEE International Symposium on
Dynamic Spectrum Access Networks (DySPAN), pp. 1–2. IEEE (2017)
19. Li, Z., et al.: Identifying value in crowdsourced wireless signal measurements. In:
WWW, pp. 607–616. International World Wide Web Conferences Steering Com-
mittee (2017)
20. McPherson, A.P., Jack, R.H., Moro, G., et al.: Action-sound latency: are our tools
fast enough? (2016)
21. MongoDB. https://www.mongodb.com/
22. Nika, A., et al.: Empirical validation of commodity spectrum monitoring. In: Sen-
Sys, pp. 96–108. ACM (2016)
23. Nika, A., et al.: Towards commoditized real-time spectrum monitoring. In: Pro-
ceedings of the 1st ACM Workshop on Hot Topics in Wireless, pp. 25–30. ACM
(2014)
24. ODROID-C2. https://wiki.odroid.com/odroid-c2/odroid-c2
25. Raspberry Pi. https://www.raspberrypi.org/
26. Rajendran, S., et al.: ElectroSense: open and big spectrum data. IEEE Commun.
Mag. 56(1), 210–217 (2018)
27. RTL-SDR. https://osmocom.org/projects/rtl-sdr/wiki/rtl-sdr
28. Saeed, A., Harras, K.A., Zegura, E., Ammar, M.: Local and low-cost white space
detection. In: 2017 IEEE 37th International Conference on Distributed Computing
Systems (ICDCS), pp. 503–516. IEEE (2017)
29. Schwaller, B.: Investigating, optimizing, and emulating candidate architectures for
on-board space processing. Ph.D. thesis, University of Pittsburgh (2018)
30. Van den Bergh, B., et al.: ElectroSense: crowdsourcing spectrum monitoring. In:
DySPAN, pp. 1–2. IEEE (2017)
31. Yucek, T., Arslan, H.: A survey of spectrum sensing algorithms for cognitive radio
applications. IEEE Commun. Surv. Tutor. 11(1), 116–130 (2009)
32. Zhang, T., Leng, N., Banerjee, S.: A vehicle based measurement framework for
enhancing whitespace spectrum databases. In: MobiCom, pp. 17–28. ACM (2014)