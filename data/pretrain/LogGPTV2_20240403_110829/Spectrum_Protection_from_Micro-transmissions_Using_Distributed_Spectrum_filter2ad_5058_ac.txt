### 3.3 Variation in Transmitter’s Behavior

The detection performance is highly dependent on the received signal power relative to the noise floor. To model this, we vary the transmitter's gain, which acts as a scaling factor that determines the power of the transmitted signal. When the received signal power is low (e.g., due to a low gain setting at the transmitter), the likelihood of false alarms increases. When the signal power is close to the noise floor, it becomes challenging for the sensors to differentiate between noise and the actual signal. This results in increased difficulty in signal detection, as the sensors may incorrectly tag noise as a signal, leading to a higher false alarm rate (FAR). We set the threshold for detection similar to [5], assuming a FAR of 10%, and compute the detection performance based on this threshold.

In our experiments, we varied the transmitter's gain from 100 to 1000 in steps of 100. Figure 9 illustrates the detection performance during both local and remote processing. The detection ratio drops to zero when the transmitter's gain is reduced to 50 during local processing on the USRP-B210. On the RTL-SDR, the performance degrades even more, with the detection ratio becoming almost zero at a gain of around 200. This degradation in performance is also observed during remote processing, where the detection ratio drops to 50% and 30% for USRP and RTL-SDR sensors, respectively. The poorer performance during local processing can be attributed to the dual impact of Power Spectral Density (PSD) computation overheads and lower received signal power levels at lower gain values. During remote processing, only the lower gain has a significant impact on the detection performance.

**Note:** 
- RTL-SDR has a detection ratio similar to USRP when the received signal power is high.
- RTL-SDR performs poorly when the transmitter gain is very low and the signal power is close to the noise floor (See Sect. 3.3).
- It is well known that signal power deteriorates as the transmitter decreases its gain. The goal of this experiment is to understand the significance of detecting micro-transmissions under poor conditions.

### 4 Discussion

In this section, we discuss the major findings of our study and propose a possible solution to improve the detection performance of inexpensive sensors.

#### 4.1 Summary of Main Observations

The key takeaways from our benchmark study are:
- **Optimal Parameters for Spectrum Sensing:** The optimal parameters for spectrum sensing, such as effective sampling rate, FFT size, and integration size, need to be rethought for low-end, inexpensive sensors. For example, the optimal sampling rate for detecting 1 ms length micro-transmissions on a desktop is 8 Msps, while on an Odroid-C2, it is 1 Msps.
- **Performance Impact of Low-End Processors:** Even when all signal processing is done remotely, the performance impact of using low-end processors in the spectrum sensor can be significant (less than 75% on RPi-1 compared to a desktop, for 1 ms transmission). This is due to two factors: (1) inaccurate spectrum sensors, and (2) poor compute hardware that cannot handle high sampling rates.
- **Compute Power vs. Sensor Type:** For local processing, the availability of compute power is a more significant factor affecting detection performance than the type of spectrum sensor. However, this is not true for remote processing, as the number of samples dropped during network transmission is not high enough to significantly reduce the detection ratio.

#### 4.2 Data Fusion

In Section 3, we observed that inexpensive compute devices are limited in terms of computational power due to their hardware. Additionally, the spectrum sensors are often inaccurate in detecting signals. To overcome these limitations and improve signal detection performance while maintaining cost-effectiveness, we follow a similar approach to previous work [8], where the authors show that the inaccuracy of radios can be mitigated by deploying multiple radios that sense together. This is because the samples are randomly dropped by the devices due to computational bottlenecks. The data is then fused from all the sensors.

To further this idea, we deployed 10 sensors, each equipped with an RTL-SDR and an Odroid-C2 board, at the same location on a campus. We used the same transmitter and setup described in Section 2.1. The 10 sensors continuously sensed a single channel, computed the PSD, and sent the power data to a central server. We used the Kaa framework [16] and MongoDB [21] to collect and store the data in a central database. We applied a fusing algorithm similar to [5] to combine the data from all the sensors. The detection performance is shown in Figure 10. Using 8 sensors, we achieved a detection ratio of almost 99% and 95% for transmission lengths of 1 ms and 1 µs, respectively. This trade-off between cost and performance demonstrates that the detection performance of inexpensive spectrum sensors can be improved by deploying more sensors. A more complex scenario involves detecting transmissions where the transmitter is changing its gain, which introduces challenges related to managing the false alarm rate (FAR) while fusing data and requires more sensors to detect all transmissions.

### 5 Related Work

The advent of inexpensive software-defined radios has made the spectrum vulnerable to unauthorized use [2, 9, 10, 17, 23, 31]. We discuss two related lines of research: (1) distributed spectrum patrolling, and (2) benchmarking of spectrum sensors.

#### Distributed Spectrum Patrolling

Multiple studies, such as SpecSense [8], ElectroSense [30], and RadioHound [18], have proposed deploying distributed spectrum patrolling systems using commodity spectrum sensors. These studies typically deploy one or two different types of sensors and compute devices. For example, RadioHound uses Raspberry Pis and laptops, while ElectroSense and SpecSense use Raspberry Pis and Odroid-C2s, respectively. Other studies, such as [4] and [5], have focused on the heterogeneity of the sensors and their impact on detection, or various performance issues related to distributed sensing, such as inaccurate clocks [3] and noisy outputs [19, 22]. However, these studies do not investigate the impact of sensing parameters or device hardware.

#### Benchmarking of Spectrum Sensors

Several studies have benchmarked the performance of individual spectrum sensors and compute devices. For example, [7, 28] benchmarks the energy and performance trade-offs of Raspberry Pi and compares it with a smartphone and a laptop-based sensor. Other studies investigate the performance of multiple compute devices, such as Raspberry Pi-2, Raspberry Pi-3, and Beaglebone-Black, in the context of audio processing [11, 12, 20]. Finally, [29] benchmarks FFT computations on multiple inexpensive compute devices to study their utility for on-board processing in space missions.

### 6 Conclusion

The demand for wireless spectrum sharing and coexistence technologies necessitates large-scale, real-time spectrum measurements. In this work, we address the key issues faced by current wide-area distributed spectrum sensing systems by benchmarking the impact of sensor and device-related parameters when detecting unauthorized micro-transmissions. Our results show that even with optimal parameter settings, the detection performance for a 1 ms transmission is no more than 45%. The poor performance is mainly attributed to the limited computational capability of the devices, which results in lost samples. To improve this detection performance, we deployed multiple sensors and demonstrated a 98% detection performance by fusing the data from all the sensors. We believe that this study also serves as a validation and reappraisal of distributed sensing systems such as SpecSense [8] and ElectroSense [26].

### Acknowledgments

This work is partially supported by NSF grant CNS-1642965 and a grant from MSIT, Korea under the ICTCCP Program (IITP-2017-R0346-16-1007).

### References

1. USRP B210. https://www.ettus.com/product/details/ub210-kit
2. Bazerque, J.A., Giannakis, G.B.: Distributed spectrum sensing for cognitive radio networks by exploiting sparsity. IEEE Trans. Sig. Process. 58(3), 1847–1862 (2010)
3. Calvo-Palomino, R., Giustiniano, D., Lenders, V., Fakhreddine, A.: Crowdsourcing spectrum data decoding. In: INFOCOM 2017-IEEE Conference on Computer Communications, pp. 1–9. IEEE (2017)
4. Calvo-Palomino, R., Pfammatter, D., Giustiniano, D., Lenders, V.: A low-cost sensor platform for large-scale wideband spectrum monitoring. In: Proceedings of the 14th International Conference on Information Processing in Sensor Networks, pp. 396–397. ACM (2015)
5. Chakraborty, A., Bhattacharya, A., Kamal, S., Das, S.R., Gupta, H., Djuric, P.M.: Spectrum patrolling with crowdsourced spectrum sensors. In: IEEE INFOCOM (2018)
6. Chakraborty, A., Das, S.R.: Measurement-augmented spectrum databases for white space spectrum. In: CoNEXT, pp. 67–74. ACM (2014)
7. Chakraborty, A., Gupta, U., Das, S.R.: Benchmarking resource usage for spectrum sensing on commodity mobile devices. In: Proceedings of the 3rd Workshop on Hot Topics in Wireless, HotWireless 2016, pp. 7–11. ACM, New York (2016)
8. Chakraborty, A., Rahman, Md.S., Gupta, H., Das, S.R.: SpecSense: crowdsensing for efficient querying of spectrum occupancy. In: INFOCOM, pp. 1–9. IEEE (2017)
9. Chen, R., Park, J.-M., Bian, K.: Robust distributed spectrum sensing in cognitive radio networks. In: INFOCOM, pp. 1876–1884. IEEE (2008)
10. Cordeiro, C., Challapali, K., et al.: Spectrum agile radios: utilization and sensing architectures. In: DySPAN, pp. 160–169. IEEE (2005)
11. Dasari, M., Kelton, C., Nejati, J., Balasubramanian, A., Das, S.R.: Demystifying hardware bottlenecks in mobile web quality of experience. In: Proceedings of the SIGCOMM Posters and Demos, pp. 43–45. ACM (2017)
12. Dasari, M., Vargas, S., Bhattacharya, A., Balasubramanian, A., Das, S.R., Ferdman, M.: Impact of device performance on mobile internet QOE. In: Proceedings of the Internet Measurement Conference 2018, pp. 1–7. ACM (2018)
13. NASA RF Propagation Database. https://propagation.grc.nasa.gov/
14. MTP Group et al.: Microsoft Spectrum Observatory, Seattle, November 2013
15. Iyer, A., Chintalapudi, K., Navda, V., Ramjee, R., Padmanabhan, V.N., Murthy, C.R.: SpecNet: spectrum sensing sans frontieres. In: NSDI, pp. 351–364. USENIX Association (2011)
16. KAA. https://www.kaaproject.org/
17. Khaledi, M., et al.: Simultaneous power-based localization of transmitters for crowdsourced spectrum monitoring. In: Proceedings of the 23rd Annual International Conference on Mobile Computing and Networking, pp. 235–247. ACM (2017)
18. Kleber, N., et al.: RadioHound: a pervasive sensing platform for sub-6 GHz dynamic spectrum monitoring. In: 2017 IEEE International Symposium on Dynamic Spectrum Access Networks (DySPAN), pp. 1–2. IEEE (2017)
19. Li, Z., et al.: Identifying value in crowdsourced wireless signal measurements. In: WWW, pp. 607–616. International World Wide Web Conferences Steering Committee (2017)
20. McPherson, A.P., Jack, R.H., Moro, G., et al.: Action-sound latency: are our tools fast enough? (2016)
21. MongoDB. https://www.mongodb.com/
22. Nika, A., et al.: Empirical validation of commodity spectrum monitoring. In: SenSys, pp. 96–108. ACM (2016)
23. Nika, A., et al.: Towards commoditized real-time spectrum monitoring. In: Proceedings of the 1st ACM Workshop on Hot Topics in Wireless, pp. 25–30. ACM (2014)
24. ODROID-C2. https://wiki.odroid.com/odroid-c2/odroid-c2
25. Raspberry Pi. https://www.raspberrypi.org/
26. Rajendran, S., et al.: ElectroSense: open and big spectrum data. IEEE Commun. Mag. 56(1), 210–217 (2018)
27. RTL-SDR. https://osmocom.org/projects/rtl-sdr/wiki/rtl-sdr
28. Saeed, A., Harras, K.A., Zegura, E., Ammar, M.: Local and low-cost white space detection. In: 2017 IEEE 37th International Conference on Distributed Computing Systems (ICDCS), pp. 503–516. IEEE (2017)
29. Schwaller, B.: Investigating, optimizing, and emulating candidate architectures for on-board space processing. Ph.D. thesis, University of Pittsburgh (2018)
30. Van den Bergh, B., et al.: ElectroSense: crowdsourcing spectrum monitoring. In: DySPAN, pp. 1–2. IEEE (2017)
31. Yucek, T., Arslan, H.: A survey of spectrum sensing algorithms for cognitive radio applications. IEEE Commun. Surv. Tutor. 11(1), 116–130 (2009)
32. Zhang, T., Leng, N., Banerjee, S.: A vehicle-based measurement framework for enhancing whitespace spectrum databases. In: MobiCom, pp. 17–28. ACM (2014)