code attacks to carry out multi-steps attacks to circumvent
sandboxes.
Code attacks correspond to instances where the attacker
is already able to execute code but with limited privileges,
e.g., inside a restrictive sandbox. For instance, in the Adobe
Reader exploit [11], it is assumed that an attacker has al-
ready compromised the sandboxed worker process. Although
attackers cannot run code outside of the sandbox, they can
exploit a vulnerability in the broker process. Speciﬁcally,
the attack exploited the worker-broker IPC interface — the
broker process only enforced policies by resolving the ﬁrst
level NTFS junction. A compromised worker can use a chain
of junctions to bypass the sandbox policy and write arbitrary
ﬁle to the ﬁle system with the broker permissions. Since
the broker ran with user privilege, attackers could therefore
escape the sandbox and modify any user ﬁles. Spif ran both
the broker and worker as untrusted processes. As a result,
the attack could only create or modify low-integrity ﬁles,
which means that any subsequent uses of these ﬁles were also
conﬁned by the low-integrity sandbox.
Spif stopped Stuxnet [10] by preventing the lnk vulnerabil-
ity from being triggered. Since the lnk ﬁle is of low-integrity,
Spif prevented Windows Explorer from loading it, and hence
stopped Windows Explorer from loading any untrusted DLLs.
We also tested the Microsoft Windows OLE Package Man-
ager Code Execution vulnerability, called Sandworm [46]. It
was exploited in the wild in October 2014. When users view
a malicious PowerPoint ﬁle, OLE package manager can be
exploited to modify a registry in HKLM, which subsequently
triggers a payload to run as system-administrator. Spif ran
PowerPoint as low-integrity when it opened the untrusted
ﬁle. The exploit was stopped as the low-integrity process
does not have permissions to modify the system registry.
The most common technique used to exploit the remain-
ing applications was an SEH buﬀer overﬂow. The upload
preference ﬁle uploadpref.dat of Calavera UpLoader and
Setting.ini of Total Video Player were modiﬁed so that
when the applications ran, the shell-code speciﬁed in the
ﬁles would be executed. Similarly, SEH buﬀer overﬂow can
also be triggered via data input, e.g., using a multimedia
playlist (.m3u) for Light Alloy or a word document (.wps) for
Kingsoft Oﬃce Writer. Other common techniques include
integer overﬂow (used in CCProxy.ini for CCProxy) and
stack overﬂow (triggered when MuPDF parsed a crafted xps
ﬁle or when WinAmp parsed a directory name with invalid
length). In the absence of Spif, these applications ran with
user’s privileges, and hence the attackers could abuse user’s
privileges, e.g., to make the malware run persistently across
reboots.
Although preference ﬁles are speciﬁc to applications, there
exists no permission control to prevent other applications
from modifying them. Spif makes sure that preference
ﬁles of high-integrity applications cannot be modiﬁed by
any low-integrity subject. This protects benign processes
from being exploited, and hence attackers cannot abuse
user privileges. On the other hand, Spif does not prevent
low-integrity instances of the applications from consuming
low-integrity preference or data ﬁles. While attackers could
exploit low-integrity processes, they only had privileges of
the low-integrity user. Furthermore, all attackers’ actions
were tracked and conﬁned by the low-integrity sandbox.
6. RELATED WORK
The ﬁrst step in most malware attacks is an exploit, typ-
ically targeting a memory corruption vulnerability to gain
arbitrary execution capability. Widespread deployment of
ASLR and DEP have raised the bar, but in the end, attackers
always seem to be able to bypass these defenses. Compre-
hensive memory corruption defenses [48, 33] can stop these
exploits, but they introduce some incompatibilities in large
and complex software. Light-weight bounds-checking [15]
avoids this problem by trading oﬀ oﬀ some protection for
increased compatibility and performance.
Instead of focusing on the exploit mechanism, most mal-
ware defenses target the payload execution phase. The pay-
load may be an exploit payload, or it may refer to installed
malware. These defenses can be partitioned into several
categories discussed below.
6.1 Sandboxing and Isolation
Various sandboxing techniques [13, 35, 45, 24, 49] have
been discussed earlier in the paper. A central challenge here
is policy development: how to identify a policy that eﬀec-
tively blocks attacks without unduly degrading functionality.
Although some techniques (e.g., model-carrying code [40])
have been devised to ease application-speciﬁc policy develop-
ment, they require some level of trust on the software. If one
suspects that it could be truly malicious, then a secure policy
will likely preclude all access, thus causing the application
to fail.
Full isolation is a more realistic alternative for software
that could be malicious. Android apps, by default, are fully
isolated from each other, thereby preventing one malicious
app from compromising another. This approach is so popular
that vendors back-ported the idea to recent desktop OSes
(Windows 8 and Mac OS X). Unfortunately, full isolation
means that no data can be shared. As a result, an untrusted
application cannot be used to view or process user ﬁles that
may have been created by another application. This diﬃculty
can be solved using the concept of one-way isolation [22],
which allows untrusted applications to read user ﬁles but not
overwrite them. The idea of shadowing ﬁles was proposed
in that work to permit untrusted applications to run safely
without experiencing any security failures.
In practice, full isolation proves to be too restrictive, so mo-
bile OSes such as Android permit apps to communicate with
each other, or with system applications, using well-deﬁned
interfaces. Unfortunately, the moment such interactions take
place, security can no longer be guaranteed:
if a benign
process receives and processes a request or data from an
untrusted process, it is entirely up to the benign process
to protect itself from damage due to this interaction. It is
in this context that information-ﬂow based techniques such
as Spif help: by keeping track of the provenance of input,
Spif can either prevent a benign process from consuming
the input, or downgrade itself into a low-integrity process
before consuming it.
6.2
Information ﬂow techniques
These techniques label every object and subject with an
integrity (and/or conﬁdentiality) label, and globally track
their propagation. The earliest works in this are date back
to the 1970s, and rely on centralized IFC, where the labels
are global to the system. In contrast, some recent eﬀorts
have focused on decentralized IFC (DIFC) [50, 9, 19], which
allows any principal to create new labels. This ﬂexibility
comes with the responsibility to make nontrivial changes to
application and/or OS code. Since backward compatibility
with existing code is a high priority for Spif, we have not
pursued a DIFC model.
Several recent works [42, 25, 21, 44] focused on making
IFC work on contemporary OSes, speciﬁcally Linux. Of these
PPI [42] speciﬁcally targeted the same problem as us, namely,
integrity protection for desktop systems against malware and
exploits. Unlike Spif, PPI relies on kernel modiﬁcations
(implemented using LSM hooks) for label propagation as
well as policy enforcement. While such an approach provides
more ﬂexibility and hence supports a wider range of policies,
its downside is that it is diﬃcult to port to other OSes. In
contrast, PIP [44] avoids OS changes and is hence most
closely related to Spif. Like Spif, PIP also re-purposes
multi-user protection for information-ﬂow tracking. But its
design, targeted at Unix, necessarily diﬀers from Spif that
targets Windows. Spif can take advantage of mechanisms
speciﬁc in Windows (such as ACLs and WIM) to remove
the need of helper process or the need for a separate display
server. Moreover, Spif’s design provides a greater degree of
portability across diﬀerent OS versions, and a higher-level
of application compatibility, having been applied to a much
larger range of complex, feature-rich applications. Spif’s
integration with the security zone in Windows also provides
a better end-to-end protection.
6.3 Provenance
Data provenance has become an important consideration
in many domains, including scientiﬁc computing, law and
health care. In these domains, provenance captures not only
the origin of date (“where”), but also how it was generated [6].
Securing data provenance [16] is an important concern in
many domains. Some recent eﬀorts have incorporated secure
provenance tracking into OSes, e.g., Linux [1].
Other works in security have been focused on (security)
applications of provenance. Reference [47] associates every
network packet with a keystroke event. These keystroke
events serve as provenance labels of a packet. This enables
the detection of malware-generated network packets that
won’t have these provenance labels. Reference [32] uses
provenance-tracking to correlate malicious network traﬃc to
the application that generated it. Spif combines the idea of
provenance and information ﬂow tracking to protect system
integrity against unknown malware.
7. CONCLUSION
In this paper, we presented Spif, a comprehensive system
for integrity protection on Windows that is based on system-
wide provenance tracking. Unlike existing malware defenses,
which are reactive in nature, Spif is pro-active, and hence
works against unknown and stealthy malware. We described
the design of Spif, detailed its security features, and features
designed to preserve application usability. Our experimental
results show that Spif imposes low performance overheads,
almost negligible on many benchmarks. It works on many
versions of Windows, and is compatible with a wide range
of feature-rich software, including all popular browsers and
Oﬃce software, media players, and so on. We evaluated it
against several malware samples from Exploit Database [34],
and showed that it can stop a variety of highly stealthy
malware.
We certainly don’t claim at this point that our proto-
type is free of vulnerabilities, or that it can stand up to
targeted attacks. But we do believe that any such weak-
nesses are the result of limited resources expended so far
on its implementation, and are not fundamental to its de-
sign. Hardening it to withstand targeted, real-world mal-
ware attacks will require substantial additional engineering
work, but we do believe that Spif represents a promising
new direction for principled malware defense. An open-
source implementation of our system is available from http:
//seclab.cs.stonybrook.edu/download.
8. REFERENCES
[1] Bates, A., Tian, D. J., Butler, K. R., and Moyer, T.
Trustworthy Whole-System Provenance for the Linux Kernel.
In USENIX Security (2015).
[2] Biba, K. J. Integrity Considerations for Secure Computer
Systems. In Technical Report ESD-TR-76-372, USAF
Electronic Systems Division, Hanscom Air Force Base,
Bedford, Massachusetts (1977).
[3] Brian Gorenc, J. S. Thinking outside the sandbox -
Violating trust boundaries in uncommon ways. In BlackHat
(2014).
[4] Brumley, D., and Song, D. Privtrans: Automatically
Partitioning Programs for Privilege Separation. In USENIX
Security (2004).
[5] BufferZone Security Ltd. BuﬀerZone,
http://buﬀerzonesecurity.com/.
[6] Buneman, P., Khanna, S., and Tan, W. C. Why and
Where: A Characterization of Data Provenance. In ICDT
(2001).
[7] Constantin, L. Researchers hack Internet Explorer 11 and
Chrome at Mobile Pwn2Own.
http://www.pcworld.com/article/2063560/researchers-hack-
internet-explorer-11-and-chrome-at-mobile-pwn2own.html/.
[8] Dell. Dell Data Protection | Protected Workspace.
http://www.dell.com/learn/us/en/04/videos˜en/
documents˜data-protection-workspace.aspx.
[9] Efstathopoulos, P., Krohn, M., VanDeBogart, S.,
Frey, C., Ziegler, D., Kohler, E., Mazi`eres, D.,
Kaashoek, F., and Morris, R. Labels and Event Processes
in the Asbestos Operating System. In SOSP (2005).
[10] Falliere, N., Murchu, L., and Chien, E. W32. Stuxnet
Dossier. White paper, Symantec Corp., Security Response
(2011).
[11] Fisher, D. Sandbox Escape Bug in Adobe Reader Disclosed.
http://threatpost.com/sandbox-escape-bug-in-adobe-reader-
disclosed/109637.
[12] Fraser, T. LOMAC: Low Water-Mark Integrity Protection
for COTS Environments. In S&P (2000).
[13] Goldberg, I., Wagner, D., Thomas, R., and Brewer,
E. A. A Secure Environment for Untrusted Helper
Applications (Conﬁning the Wily Hacker). In USENIX
Security (1996).
[14] Google Security Research. Windows Acrobat Reader 11
Sandbox Escape in MoveFileEx IPC Hook.
https://code.google.com/p/google-security-research/issues/
detail?id=103.
[15] Hasabnis, N., Misra, A., and Sekar, R. Light-weight
bounds checking. In CGO (2012).
[17] jduck. CVE-2010-3338 Windows Escalate Task Scheduler
[16] Hasan, R., Sion, R., and Winslett, M. Introducing Secure
Provenance: Problems and Challenges. In StorageSS (2007).
XML Privilege Escalation | Rapid7. http://www.rapid7.com/
db/modules/exploit/windows/local/ms10 092 schelevator.
[18] Katcher, J. Postmark: A new ﬁle system benchmark.
Technical Report TR3022, Network Appliance, 1997.
[24] Loscocco, P., and Smalley, S. Meeting Critical Security
Objectives with Security-Enhanced Linux. In Ottawa Linux
Symposium (2001).
[25] Mao, Z., Li, N., Chen, H., and Jiang, X. Combining
Discretionary Policy with Mandatory Information Flow in
Operating Systems. In TISSEC (2011).
[26] Microsoft. URL Security Zones (Windows) - MSDN -
Microsoft.
https://msdn.microsoft.com/en-us/library/ie/ms537021%28v=
vs.85%29.aspx.
[27] Microsoft. What is Protected View? - Oﬃce Support.
https://support.oﬃce.com/en-au/article/What-is-Protected-
View-d6f09ac7-e6b9-4495-8e43-2bbcdbcb6653.
[28] Microsoft. What is the Windows Integrity Mechanism?
https://msdn.microsoft.com/en-us/library/bb625957.aspx.
[29] Microsoft. Working with the AppInit DLLs registry value.
http://support.microsoft.com/kb/197571.
[30] Microsoft Research. Detours.
http://research.microsoft.com/en-us/projects/detours/.
[31] Mozilla. Buildbot/Talos/Tests.
https://wiki.mozilla.org/Buildbot/Talos/Tests.
[32] Nadji, Y., Giffin, J., and Traynor, P. Automated
Remote Repair for Mobile Malware. In ACSAC (2011).
[33] Nagarakatte, S., Zhao, J., Martin, M. M., and
Zdancewic, S. SoftBound: SoftBound: Highly Compatible
and Complete Spatial Memory Safety for C. In PLDI (2009).
[34] Offensive Security. Exploits Database,
http://www.exploit-db.com/.
[35] Provos, N. Improving Host Security with System Call
Policies. In USENIX Security (2003).
[36] Provos, N., Markus, F., and Peter, H. Preventing
Privilege Escalation. In USENIX Security (2003).
[37] Rahul Kashyap, R. W. Application Sandboxes: A
Pen-Tester’s Perspective. http://labs.bromium.com/2013/07/
23/application-sandboxes-a-pen-testers-perspective/.
[38] Reis, C., and Gribble, S. D. Isolating Web Programs in
Modern Browser Architectures. In EuroSys (2009).
[39] Sandboxie Holdings, LLC. Sandboxie,
http://www.sandboxie.com/.
[40] Sekar, R., Venkatakrishnan, V., Basu, S., Bhatkar, S.,
and DuVarney, D. C. Model-Carrying Code: A Practical
Approach for Safe Execution of Untrusted Applications. In
SOSP (2003).
[41] Sun, W., Sekar, R., Liang, Z., and Venkatakrishnan,
V. N. Expanding Malware Defense by Securing Software
Installations. In DIMVA (2008).
[42] Sun, W., Sekar, R., Poothia, G., and Karandikar, T.
Practical Proactive Integrity Preservation: A Basis for
Malware Defense. In S&P (2008).
[43] Sze, W. K., Mital, B., and Sekar, R. Towards More
Usable Information Flow Policies for Contemporary
Operating Systems. In SACMAT (2014).
[44] Sze, W. K., and Sekar, R. A Portable User-Level Approach
for System-wide Integrity Protection. In ACSAC (2013).
[45] Ubuntu. AppArmor. https://wiki.ubuntu.com/AppArmor/.
[46] Ward, S. iSIGHT discovers zero-day vulnerability
CVE-2014-4114 used in Russian cyber-espionage campaign.
http://www.isightpartners.com/2014/10/cve-2014-4114/.
[19] Krohn, M., Yip, A., Brodsky, M., Cliffer, N., Kaashoek,
M. F., Kohler, E., and Morris, R. Information Flow
Control for Standard OS Abstractions. In SOSP (2007).
[20] Li, H. CVE-2015-0016: Escaping the Internet Explorer
Sandbox.
http://blog.trendmicro.com/trendlabs-security-intelligence/cve-
2015-0016-escaping-the-internet-explorer-sandbox.
[21] Li, N., Mao, Z., and Chen, H. Usable Mandatory Integrity
Protection for Operating Systems . In S&P (2007).
[22] Liang, Z., Sun, W., Venkatakrishnan, V. N., and Sekar,
R. Alcatraz: An Isolated Environment for Experimenting
with Untrusted Software. In TISSEC (2009).
[23] Liang, Z., Venkatakrishnan, V., and Sekar, R. Isolated
program execution: An application transparent approach for
executing untrusted programs. In ACSAC (2003).
[47] Xu, K., Xiong, H., Wu, C., Stefan, D., and Yao, D.
Data-Provenance Veriﬁcation For Secure Hosts. In TDSC
(2012).
[48] Xu, W., DuVarney, D. C., and Sekar, R. An eﬃcient and
backwards-compatible transformation to ensure memory
safety of C programs. In FSE (2004).
[49] Yee, B., Sehr, D., Dardyk, G., Chen, J. B., Muth, R.,
Orm, T., Okasaka, S., Narula, N., Fullagar, N., and
Inc, G. Native Client: A Sandbox for Portable, Untrusted
x86 Native Code. In S&P (2009).
[50] Zeldovich, N., Boyd-Wickizer, S., Kohler, E., and
Mazi`eres, D. Making Information Flow Explicit in HiStar.
In OSDI (2006).