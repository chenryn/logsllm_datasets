### Introduction

Our initial findings, derived from end-user feedback, have motivated us to conduct a dynamic testing phase. This phase aims to empirically evaluate the published skills and identify any problematic ones in the skills store.

### Skill List
- **Guess Me**
- **ABCs**
- **Whose Turn**
- **Chompers**
- **NORAD Tracks Santa**
- **Science Kid Radio**
- **Animal Sounds**
- **ABC**
- **Goodnight, Sleep Tight**
- **Punish the Kids!**
- **Amazon Story Time**
- **Merry Christmas**
- **Trivial Pursuit**

### User Reviews
- "Collection of information"
- "Just want your kids' data"
- "The initialization process required my family member names"
- "You are giving the company permission to use way too much information about your kids."
- "Intrusion at its best (asking for credit card information)"
- "There are more advertisements/commercials..."
- "Asks for you to buy additional sounds"
- "Creepy skill with inappropriate content for kids"
- "Scared the kid"
- "Rude to kids"
- "Want your kid to hear a Boston Bombing story?"
- "Played like a few seconds of Santa sounds and the rest was lame advertisements"
- "I had to explain what 'sexual deviance' or some similar term was to my daughter last night"
- "My daughter got multiple questions about alcohol and TV shows that are NOT kid appropriate"

**Table 2: Selected Critical Reviews in the Kids Category**

### 5.1.2 Identifying Existing Risky Skills Through Dynamic Testing

The analysis of user reviews revealed potential policy violations in existing skills. To further investigate, we leveraged our security expertise to manually test each skill. Given the time-consuming nature of dynamic testing, we focused on 825 kids' skills that either had a privacy policy or received negative reviews. Our goal was to check if these skills were collecting any personally identifiable information (PII) from end users, which is not allowed for skills directed at children.

We also identified other policy violations, such as:
- Encouraging users to engage with content outside of Alexa.
- Promoting other skills.

In total, we found 52 problematic skills with policy violations. Table 3 lists these skills. Additionally, we discovered 51 broken skills (details in Table 6 of Appendix C).

**Figure 5: (a) A certified kids' skill collecting personal information. (b) Data stored in DynamoDB database.**

For example, one skill used the sample utterance `{my_name} {my_lastname}`, where “my_name” and “my_lastname” are slots to capture a user’s input. This clearly indicates the collection of full names. Upon checking the Amazon DynamoDB database, we found that the certification team had inputted full names (potentially fake names for testing purposes) but still certified the skill. Figure 5 illustrates a certified kids' skill collecting user names. The names shown in Figure 5(b) are for illustration purposes and not from the certification team. The certification team should have detected this and rejected the skill for collecting PII through a kids' skill. Moreover, the skill had no developer privacy policy, and the Privacy & Compliance form denied collecting PII from users.

For ethical considerations, we added disclaimers to the skills before any policy violation was spoken. We also included these disclaimers in the descriptions of some skills, but neither action led to rejection. No plagiarism check was conducted, and we were able to publish multiple copies of the same skill without any differences.

### 5 Consequences of Lenient Skill Certification

The results in Section 4 reveal that Alexa has not strictly enforced security policies during the certification process. This leniency provides opportunities for malicious developers to trick the certification process, placing end users in a vulnerable position. The lack of strict enforcement can lead to serious security consequences throughout the Alexa platform.

To address whether there are policy-violating or problematic skills in Alexa’s skills store due to lenient certification, we conducted a small-scale dynamic testing of kids' skills, given the stringent policies in this category.

### 5.1 Empirical Study on Kids' Skills

#### 5.1.1 Understanding Users’ Common Concerns

We focused on kids' skills because Alexa specifies more stringent policies for this category. For example, skills in the kids' category should never request PII, even if a privacy policy is provided. However, most privacy policies listed in the skills store are general and not specific to the skill. They do not provide clear information about what the skill collects or stores.

### 5.2 Possible COPPA Violations

Third-party skills in Amazon Alexa may violate the Children’s Online Privacy Protection Act (COPPA), a federal legal framework protecting the online privacy of children under 13. COPPA requires parental control over the information collected from their children. In 2019, YouTube paid $170 million for allegedly violating COPPA by collecting personal information from viewers of child-directed channels without parental consent.

Children's data privacy advocates have raised concerns against Amazon. Amazon claims that kids' skills do not collect PII without parental consent. However, the skills available in the store can violate COPPA rules. Skills that collect PII and do not provide a privacy policy can be easily developed and certified. According to COPPA, parents must be able to review and remove the information collected from their children.

### 5.3 Post-Certification Vulnerability

The back-end code of a third-party skill runs on the developer’s server, and Alexa does not require re-certification when changes are made. This makes users vulnerable to content-changing attacks after certification. Malicious developers can change the content of responses or questions, leading to inappropriate content or sensitive information leakage.

For a skill to collect specific data, it must have the capability before certification. Developers can only access user inputs that match specified sample utterances. For example, to collect addresses, the developer must add a sample utterance with a slot of type `AMAZON.PostalAddress` to a pre-defined intent. This cannot be added post-certification without re-certification.

In our experiment, we created a skill for kids with a custom slot that could accept multiple types of values (e.g., first/last names and city/street names). On submission, the skill only asked for the first name, which is acceptable. After certification, we changed the question to ask for other types of PII, successfully collecting and saving the data. For ethical reasons, we removed all collected data after testing.

Adversarial developers can exploit this vulnerability even if certification issues are fixed. They can pose as normal skills to earn good reviews and then alter the skill with malicious content. Additionally, if an attacker gains access to the back-end code of a benign developer, they can inject malicious code without notifying the developer or the VA platform provider.

### 6 Discussion

#### 6.1 Why Lenient Skill Certification in Alexa?

Several factors contribute to the leniency in Amazon’s certification process. With over 100,000 skills, many go unused. Leniency encourages developers to produce more skills, prioritizing quantity over quality. Google, in contrast, limits developers to 12 projects on the Actions on Google console, unless they request an increase. Both companies reward developers for creating multiple skills, but this prioritization results in insufficient checks for policy violations.

#### 6.2 Mitigation Suggestions

Based on our findings, we recommend the following to enhance the trustworthiness of VA platforms:

- **Enforcing Skill Behavior Integrity Throughout the Lifecycle:** Implement continuous certification/vetting processes. Re-certify skills whenever changes are made to the front-end or back-end. Periodically check and remove broken skills.
- **Automating Skill Testing:** Design a voice-based testing tool to automate the interaction with third-party skills. Apply deep learning techniques to train a user simulation model. Require developers to provide permissions to view their back-end code for code analysis.

#### 6.3 Limitation

Further research is needed to reinforce our findings. Our adversarial testing mainly focused on content policy violations and did not cover advanced features like interaction with smart home IoT devices. Scaling up dynamic testing to identify problematic skills at the level of the skills store is challenging. Future work should focus on designing a voice-based testing tool.

### 7 Conclusion

In this study, we conducted a comprehensive measurement of the trustworthiness of the Amazon Alexa platform. We crafted 234 policy-violating skills, all of which passed certification. Our results indicate that the skill certification process is disorganized. Through dynamic testing of 825 skills, we identified 52 problematic skills with policy violations and 51 broken skills under the kids' category.

### References

[1] 2016. Toddler asks Amazon’s Alexa to play song but gets porn instead. https://nypost.com/2016/12/30/toddler-asks-amazons-alexa-to-play-song-but-gets-porn-instead/. (2016).

[2] 2018. Portland Family Says Their Amazon Alexa Recorded Private Conversations. https://www.wweek.com/news/2018/05/26/portland-family-says-their-amazon-alexa-recorded-private-conversations-and-sent-them-to-a-random-contact-in-seattle/. (2018).

[3] 2018. Smart Audio Report 2018. https://www.edisonresearch.com/the-smart-audio-report-from-npr-and-edison-research-spring-2018/. (2018).