| 8.4 | Metrics |
|---|---|| For a system failure, if an approach only groups a part of its trig-gered alerts into an incident, we do not consider the incident to be wrong, since the incident still groups correlated alerts correctly. Only when an incident contains an uncorrelated alert, we consider the incident to be wrong. After correctness verification, incidents can be divided into three groups, correct incidents, wrong incidents, and isolated incidents. An isolated incident contains only one alert and has no contribution to alert summarizing, thus there is no need to judge its correctness. We use the incident accuracy (𝐴𝐶𝑅), the valid compression ratio (𝑉𝐶𝑅), and the time cost (𝑇𝐶) in summarizing stage to evaluate the performance of experimental approaches. The incident accuracy is defined as 𝐴𝐶𝑅 = incidents and 𝑁𝑤 is the number of wrong incidents. The incident 𝑁𝑐+𝑁𝑤×100%, where 𝑁𝑐 is the number of correct accuracy represents the proportion of correct incidents in non-isolated incidents. The valid compression ratio is defined as 𝑉𝐶𝑅 = number of alerts in wrong incidents and in isolated incidents. The (1 −𝑁𝑐+𝑛𝑤+𝑛𝑖 ) × 100%, where 𝑛𝑤 and 𝑛𝑖 respectively indicate the valid compression ratio represents the true summarizing ability of the approach, and it ignores the contribution of wrong incidents and isolated incidents. The higher the summarizing ability of the approach, the higher the valid compression rate. Moreover, for each approach, we record its time cost (𝑇𝐶) in summarizing stage to evaluate its efficiency. |For a system failure, if an approach only groups a part of its trig-gered alerts into an incident, we do not consider the incident to be wrong, since the incident still groups correlated alerts correctly. Only when an incident contains an uncorrelated alert, we consider the incident to be wrong. After correctness verification, incidents can be divided into three groups, correct incidents, wrong incidents, and isolated incidents. An isolated incident contains only one alert and has no contribution to alert summarizing, thus there is no need to judge its correctness. We use the incident accuracy (𝐴𝐶𝑅), the valid compression ratio (𝑉𝐶𝑅), and the time cost (𝑇𝐶) in summarizing stage to evaluate the performance of experimental approaches. The incident accuracy is defined as 𝐴𝐶𝑅 = incidents and 𝑁𝑤 is the number of wrong incidents. The incident 𝑁𝑐+𝑁𝑤×100%, where 𝑁𝑐 is the number of correct accuracy represents the proportion of correct incidents in non-isolated incidents. The valid compression ratio is defined as 𝑉𝐶𝑅 = number of alerts in wrong incidents and in isolated incidents. The (1 −𝑁𝑐+𝑛𝑤+𝑛𝑖 ) × 100%, where 𝑛𝑤 and 𝑛𝑖 respectively indicate the valid compression ratio represents the true summarizing ability of the approach, and it ignores the contribution of wrong incidents and isolated incidents. The higher the summarizing ability of the approach, the higher the valid compression rate. Moreover, for each approach, we record its time cost (𝑇𝐶) in summarizing stage to evaluate its efficiency. |Online Summarizing Alerts through Semantic and Behavior Information 	ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
(a) Incident accuracy (𝐴𝐶𝑅). 	(b) Valid compression ratio (𝑉𝐶𝑅) 	(c) Summarizing time cost (𝑇𝐶)
Figure 7: Experimental results of summarizing performance.
|  |  |  |
|---|---|---|
| (a) Incident accuracy (𝐴𝐶𝑅) |(b) Valid compression ratio (𝑉𝐶𝑅) |(c) Summarizing time cost (𝑇𝐶) |Figure 8: Experimental results of varying sample granularity 𝛼 in ABR.
|  |  |  |
|---|---|---|
| (a) Incident accuracy (𝐴𝐶𝑅) |(b) Valid compression ratio (𝑉𝐶𝑅) |(c) Summarizing time cost (𝑇𝐶) |
Figure 9: Experimental results of varying sample length 𝛽 in ABR.
|  |  |  |
|---|---|---|
| (a) Incident accuracy (𝐴𝐶𝑅) |(b) Valid compression ratio (𝑉𝐶𝑅) |(c) Summarizing time cost (𝑇𝐶) |Figure 10: Experimental results of varying time window 𝑤 in online summarizing.
ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
8.5 	Evaluation Results
To answer the proposed research questions, we evaluate our ap-proaches from four aspects, the summarizing performance of our approaches compared with the state of arts, the influence of the sample granularity 𝛼 in ABR, the influence of the sample length 𝛽 in ABR, and the influence of the time window 𝑤 in online summa-rizing.8.5.1 	RQ1: summarizing performance. In the first experiment, we compare the performance of approaches for each dataset. Figure 7 shows the result. From Figure 7(a) and Figure 7(b), we can find that, in terms of the semantic information, ASR has higher 𝐴𝐶𝑅 and 𝑉𝐶𝑅 than Jaccard, Word2Vec, and LDA, in terms of the behavior information, ABR has higher 𝐴𝐶𝑅 and 𝑉𝐶𝑅 than CSC, GoKrimp, SeqKrimp, and SWIFT. Furthermore, OAS has the best performance among experimental approaches.This is because ASR integrates the contextual information of words in an alert according to their semantic contributions. How-ever, Jaccard only considers the number of the same words between alerts, ignoring the common semantics between different words, Word2Vec equally treats the words in an alert, neglecting varying contributions of words to the overall semantics, and LDA distills the general topic of an alert, failing to capture the distinctive semantics for alerts of the same topic. Moreover, ABR mines the commonality between alert occurrence series, while SeqKrimp, GoKrimp, CSC, and SWIFT try to find naive frequent patterns of alerts. Neverthe-less, it is rare that the exact same failure recurs in a short period of time, thus correlated alerts may not have frequent co-occurrences.Since OAS further has a better performance than ASR and ABR, the experiment demonstrates that both ASR and ABR have their own contributions to alert summarizing, and OAS can effectively aggregate the semantic information and behavior information by ACT. In addition, in both datasets, ASR contributes the most to alert summarizing. As show in Figure 7(c), to capture the deep semantic information and behavior information of the alert, ASR, ABR and OAS have higher 𝑇𝐶 in summarizing stage than other approaches. However, ASR, ABR, and OAS can still process the alert within acceptable time. In case of OAS, which has the maximum 𝑇𝐶 for each dataset, its 𝑇𝐶 for Bank A is 26s, which corresponds to more than 240 alerts per second, and its 𝑇𝐶 for Bank B is 147.73s, which corresponds to more than 670 alerts per second.8.5.2 	RQ2: varying sample granularity 𝛼 in ABR. In this experiment, we evaluate the influence of the sample granularity, 𝛼, for the occurrence series in ABR. We vary 𝛼 from 1 to 60 minutes. For each 𝛼, we train a new ABR model and evaluate its performance by the dataset of Bank B. Although there are some fluctuations in Figure 8(a) and Figure 8(b), which reveals that the relationship between 𝛼 and summarizing performance is not strongly linear, a smaller𝛼 still tends to get better summarizing performance. Because when the sample length 𝛽 is unchanged, a smaller 𝛼 can generate a longer occurrence series, which is able to retain more detailed alert behavior information. As shown in Figure 8(c), since a larger 𝛼 can generate a shorter alert occurrence series, ABR is more efficient with a larger 𝛼. However, even with the smallest 𝛼 (1 minute), ABR still can process 100,000 alerts in about 2 minutes (more thanJia Chen, Peng Wang, and Wei Wang
810 alerts per second). Thus, in conditions permit, we recommend choosing the smallest possible 𝛼.8.5.3 	RQ3: varying sample length 𝛽 in ABR. As the sample length, 𝛽, in ABR determines the time range of the alert occurrence series, we evaluate its influence by varying 𝛽 from 1 to 24 hours. Similar to the above, for each 𝛽, we train a new ABR model by the dataset of Bank B. From Figure 9(a) and Figure 9(b), we can find that when the sample granularity 𝛼 is unchanged, as 𝛽 increases, 𝐴𝐶𝑅 and 𝑉𝐶𝑅 also increase at first, and then they both gradually stabilize. A larger 𝛽 results in a longer time range of the alert occurrence series, which contains richer behavior information. However, when 𝛽 reaches a certain threshold, the time range of the alert occurrence series can already reveal the complete behavior information of the alert. More specifically, in Figure 9(a) and Figure 9(b), when 𝛽 > 13 hours, 𝑉𝐶𝑅 stabilizes at about 54%, while 𝐴𝐶𝑅 is greater than 99%. Moreover, as shown in Figure 9(c), 𝑇𝐶 of ABR in summarizing stage has a linear relationship with 𝛽. When 𝛽 = 13 hours, 𝑇𝐶 is about 2 minutes (more than 809 alerts per second). Therefore, we recommend choosing a small 𝛽 that achieves a stable summarizing performance.8.5.4 	RQ4: varying time window 𝑤 in online summarizing. Since the time window,𝑤, in online summarizing controls the maximum time span between two correlated alerts, we thus evaluate its influence on ASR, ABR, and OAS by varying 𝑤 from 1 to 60 minutes. Same as above, we adopt the dataset of Bank B as the experimental data. As shown in Figure 10(a) and Figure 10(b), OAS always has a better performance than ASR and ABR, proving that ACT can effectively integrate ASR and ABR. For ASR, as 𝑤 increases, 𝑉𝐶𝑅 decreases at first and then slowly increase until it stabilizes. Such phenomenon indicates a trade-off between the number of alert correlations in result incidents and the accuracy of result incidents. A small 𝑤 can find a small number of alert correlations with high 𝐴𝐶𝑅 while a large 𝑤 can find a large number of alert correlations with low 𝐴𝐶𝑅. Nevertheless, for different 𝑤, both ABR and OAS have their 𝐴𝐶𝑅 stable above 98%. Because ABR concentrates on the robust historical behavior information of alerts, and OAS integrates the strengths of ASR and ABR.It should be noted that we use a five-minute𝑤 for the experiment of summarizing performance in Section 8.5.1, which seems not to be the best choice in Figure 10(b). This is due to that during the com-munication with front-line maintenance engineers, they propose that although a small𝑤 can lead to a high 𝐴𝐶𝑅, it also splits a failure into multiple fragmented incidents, and a large 𝑤 is prone to merge independent failures of the same type into one incident. Both cases are detrimental to the failure analysis work of maintenance engi-neers. According to the experience of maintenance engineers, they present that 5 minutes is usually the maximum interval between two correlated alerts for their bank service systems. In addition, for ASR, ABR, and OAS, there is a linear relationship between 𝑤 and 𝑇𝐶. Thus, to choose the the time window 𝑤, we recommend that both experimental results and the practical maintenance experience should be taken into consideration.8.6 	Threats to Validity
We identify following threats to validity in our study.
Online Summarizing Alerts through Semantic and Behavior InformationNoises in labeling: We obtain alert correlations from history failure reports written by domain experts. A failure report records the root cause and the impact of a failure, as well as correlated alerts. Since correlated alerts in a failure report are manually labeled by experts, mislabeling is hard to avoid during the manual process. However, as our experts are all front-line maintenance engineers with rich domain knowledge, we are confident that the amount of noises in labeling is small (if it exists).Generalizability: In our experiments, we use alerts from sys-tems of two large commercial banks, A and B. The performance of our approaches depends on the number of alerts and the quality of alert correlation data (failure reports). In our study, Bank A and Bank B have accumulated many historical alerts, and their engi-neers are required to write failure reports, which we use to label the alert correlation. Similarly, in most commercial companies, both historical alerts and failure reports are maintained for a long time. In addition, Bank A and Bank B are two very large-scale banks, providing service for more than a billion users from hundreds of countries. Thus, we believe our experimental results can demon-strate the value of our proposed approaches and our approaches can be generalized to alerts of other companies.Measurements: To demonstrate the summarizing performance of our approaches, we use 𝐴𝐶𝑅 (Accuracy) and 𝑉𝐶𝑅 (Valid Com-pression Ratio) as measurements, which are defined in Section 8.4. Although F-measure is a widely used measurement, it is unsuitable for our study. Because the correctness verification in F-measure is dichotomous. However, in alert summarizing, if an incident (not isolated) contains no uncorrelated alerts, then even if it does not contain all alerts of its corresponding failure, it is still correct in practical production. Therefore, after a discussion with domain experts, we propose 𝐴𝐶𝑅 and 𝑉𝐶𝑅 to measure the effectiveness of our approaches. 𝐴𝐶𝑅 measures the proportion of correct incidents, and it ignores the impact of isolated incidents that only contain one alert. 𝑉𝐶𝑅 measures the ability of mined incidents to summa-rize alerts, and it ignores the contribution of wrong incidents and isolated incidents to summarizing.9 	LESSONS LEARNEDIn our study, after we cooperated with some commercial compa-nies, we found that the alert management system of a large online service system needs a top layer or global design. First, the top layer design is useful to combine alerts from various tool, like Zabbix [16], Prometheus [6] and etc. Second, top layer design is helpful to avoid the monitoring blind spot. We can not find the root cause if it is not monitored. Moreover, we found that many large commercial com-panies have accumulated a large number of failure reports (or work orders). In our study, we use the knowledge in these failure reports to summarize alerts. However, we suggest that these failure reports can not only be used to correlate alerts, but also be considered as a knowledge base. These failure reports contain valuable expert ex-perience, such as the root cause of the failure, the alert correlation, and the troubleshooting process. Therefore, these failure reports should have a more important role to be explored.ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
10 	CONCLUSIONIn this paper, we propose a framework OAS to efficiently summarize alerts online. In OAS, to represent the alert semantic information, we present ASR, which aggregates the contextual information of alert words according to their semantic contributions. To represent the alert behavior information, we present ASR, which captures the commonality between the occurrence series of alerts. In addition, we present a novel model, ACT, to combine the semantic and be-havior information of the alert, and summarize the newly reported alert online by a time window. We conduct extensive experiments on real datasets from two large commercial banks, and the result demonstrates that our approaches outperform the state of the art. In future, we plan to provide the ability for OAS to suggest the root cause of the system failure based on the mined alert information.REFERENCES 
[1] Amey Agrawal, Rohit Karlupia, and Rajat Gupta. 2019. Logan: A Distributed 	Online Log Parser. In IEEE 35th International Conference on Data Engineering 	(ICDE). IEEE, 1946–1951.
[2] David M Blei, Andrew Y Ng, and Michael I Jordan. 2003. Latent dirichlet allocation. 	Journal of machine Learning research 3, Jan (2003), 993–1022.[3] Junjie Chen, Xiaoting He, Qingwei Lin, Yong Xu, Hongyu Zhang, Dan Hao, Feng Gao, Zhangwei Xu, Yingnong Dang, and Dongmei Zhang. 2019. An Empirical Investigation of Incident Triage for Online Service Systems. In IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Practice. IEEE, 111–120.[4] Yujun Chen, Xian Yang, Qingwei Lin, Hongyu Zhang, Feng Gao, Zhangwei Xu, Yingnong Dang, Dongmei Zhang, Hang Dong, Yong Xu, Hao Li, and Yu Kang.
2019. Outage Prediction and Diagnosis for Cloud Service Systems. In The World Wide Web Conference. ACM, New York, NY, USA, 2659–2665.[5] Min Du, Feifei Li, Guineng Zheng, and Vivek Srikumar. 2017. Deeplog: Anomaly detection and diagnosis from system logs through deep learning. In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security. ACM, 1285–1298.