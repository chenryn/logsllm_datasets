on the estimation error (or sample complexity) in distribu-
tion estimation of tabular data. However, they assume that
each original data value is independently sampled from an
underlying distribution. They cannot be directly applied to
our graph setting, because each triangle and each k-star in-
volve multiple edges and are not independent (as described
in Section 1). Rashtchian et al. [47] provide lower-bounds
on communication complexity (i.e., number of queries) of
vector-matrix-vector queries for estimating subgraph counts.
However, their lower-bounds are not on the estimation error,
and cannot be applied to our problem.
3 Preliminaries
3.1 Graphs and Differential Privacy
Graphs. Let N, Z≥0, R, and R≥0 be the sets of natural num-
bers, non-negative integers, real numbers, and non-negative
real numbers, respectively. For a ∈ N, let [a] = {1,2, . . . ,a}.
We consider an undirected graph G = (V,E), where V is
a set of nodes (i.e., users) and E is a set of edges. Let n ∈ N
be the number of users in V , and let vi ∈ V the i-th user;
i.e., V = {v1, . . . ,vn}. An edge (vi,v j) ∈ E represents a re-
lationship between users vi ∈ V and v j ∈ V . The number
of edges connected to a single node is called the degree of
the node. Let dmax ∈ N be the maximum degree (i.e., max-
imum number of edges connected to a node) in graph G.
Let G be the set of possible graphs G on n users. A graph
G ∈ G can be represented as a symmetric adjacency ma-
trix A = (ai, j) ∈ {0,1}n×n, where ai, j = 1 if (vi,v j) ∈ E and
ai, j = 0 otherwise.
Types of DP. DP (Differential Privacy) [22, 23] is known as
a gold standard for data privacy. According to the underlying
architecture, DP can be divided into two types: centralized DP
and LDP (Local DP). Centralized DP assumes the centralized
model, where a “trusted” data collector collects the original
personal data from all users and obfuscates a query (e.g.,
counting query, histogram query) on the set of personal data.
LDP assumes the local model, where each user does not trust
even the data collector. In this model, each user obfuscates a
query on her personal data by herself and sends the obfuscated
data to the data collector.
If the data are represented as a graph, we can consider
two types of DP: edge DP and node DP [27, 49]. Edge DP
considers two neighboring graphs G,G(cid:48) ∈ G that differ in
one edge. In contrast, node DP considers two neighboring
graphs G,G(cid:48) ∈ G in which G(cid:48) is obtained from G by adding
or removing one node along with its adjacent edges.
Although Zhang et al. [65] consider node DP in the local
model where each node represents a software component, we
consider a totally different problem where each node repre-
sents a user. In the latter case, node DP requires us to hide
the existence of each user along with her all edges. However,
many applications in the local model send the identity of
each user to a server. For example, we can consider a mobile
application that sends to a server how many friends a user
met today along with her user ID. In this case, the user may
not mind sending her user ID, but may want to hide her edge
information (i.e., who she met today). Although we cannot
use node DP in such applications, we can use edge DP to deny
the presence/absence of each edge (friend). Thus we focus on
edge DP in the same way as [46, 53, 63, 64].
Below we explain edge DP in the centralized model.
Centralized DP. We call edge DP in the centralized model
edge centralized DP. Formally, it is deﬁned as follows:
USENIX Association
30th USENIX Security Symposium    985
Deﬁnition 1 (ε-edge centralized DP). Let ε ∈ R≥0. A random-
ized algorithm M with domain G provides ε-edge centralized
DP if for any two neighboring graphs G,G(cid:48) ∈ G that differ in
one edge and any S ⊆ Range(M ),
Pr[M (G) ∈ S] ≤ eε Pr[M (G(cid:48)) ∈ S].
(1)
Edge centralized DP guarantees that an adversary who has
observed the output of M cannot determine whether it is
come from G or G(cid:48) with a certain degree of conﬁdence. The
parameter ε is called the privacy budget. If ε is close to zero,
then G and G(cid:48) are almost equally likely, which means that an
edge in G is strongly protected.
We also note that edge DP can be used to protect k ∈ N
edges by using the notion of group privacy [23]. Speciﬁcally,
if M provides ε-edge centralized DP, then for any two graphs
G,G(cid:48) ∈ G that differ in k edges and any S ⊆ Range(M ), we
obtain: Pr[M (G) ∈ S] ≤ ekε Pr[M (G(cid:48)) ∈ S]; i.e., k edges are
protected with privacy budget kε.
3.2 Local Differential Privacy
LDP (Local Differential Privacy) [20, 35] is a privacy met-
ric to protect personal data of each user in the local model.
LDP has been originally introduced to protect each user’s data
record that is independent from the other records. However, in
a graph, each edge is connected to two users. Thus, when we
deﬁne edge DP in the local model, we should consider what
we want to protect. In this paper, we consider two deﬁnitions
of edge DP in the local model: edge LDP in [46] and rela-
tionship DP introduced in this paper. Below, we will explain
these two deﬁnitions in detail.
Edge LDP. Qin et al. [46] deﬁned edge LDP based on a user’s
neighbor list. Speciﬁcally, let ai = (ai,1, . . . ,ai,n) ∈ {0,1}n be
a neighbor list of user vi. Note that ai is the i-th row of the
adjacency matrix A of graph G. In other words, graph G can
be represented as neighbor lists a1, . . . ,an.
Then edge LDP is deﬁned as follows:
Deﬁnition 2 (ε-edge LDP [46]). Let ε ∈ R≥0. For any i ∈ [n],
let Ri with domain {0,1}n be a randomized algorithm of
user vi. Ri provides ε-edge LDP if for any two neighbor lists
i ∈ {0,1}n that differ in one bit and any S ⊆ Range(Ri),
ai,a(cid:48)
(2)
Pr[Ri(ai) ∈ S] ≤ eε Pr[Ri(a(cid:48)
i) ∈ S].
Edge LDP in Deﬁnition 2 protects a single bit in a neighbor
list with privacy budget ε. As with edge centralized DP, edge
LDP can also be used to protect k ∈ N bits in a neighbor
list by using group privacy; i.e., k bits in a neighbor list are
protected with privacy budget kε.
RR (Randomized Response). As a simple example of a
randomized algorithm Ri providing ε-edge LDP, we explain
Warner’s RR (Randomized Response) [60] applied to a neigh-
bor list, which is called the randomized neighbor list in [46].
Given a neighbor list ai ∈ {0,1}n, this algorithm outputs
a noisy neighbor lists b = (b1, . . . ,bn) ∈ {0,1}n by ﬂipping
eε+1; i.e., for each j ∈ [n],
each bit in ai with probability p = 1
b j (cid:54)= ai, j with probability p and b j = ai, j with probability
1− p. Since Pr[R (ai) ∈ S] and Pr[R (a(cid:48)
i) ∈ S] in (2) differ by
eε for ai and a(cid:48)
i that differ in one bit, this algorithm provides
ε-edge LDP.
Relationship DP. In graphs such as social networks, it is usu-
ally the case that two users share knowledge of the presence
of an edge between them. To hide their mutual edge, we must
consider that both user’s outputs can leak information. We
introduce a DP deﬁnition called relationship DP that hides
one entire edge in graph G during the whole process:
Deﬁnition 3 (ε-relationship DP). Let ε ∈ R≥0. A tuple of
randomized algorithms (R1, . . . ,Rn), each of which is with
domain {0,1}n, provides ε-relationship DP if for any two
neighboring graphs G,G(cid:48) ∈ G that differ in one edge and any
S ⊆ Range(R1)× . . .× Range(Rn),
Pr[(R1(a1), . . . ,Rn(an)) ∈ S]
≤ eε Pr[(R1(a(cid:48)
1), . . . ,Rn(a(cid:48)
n)) ∈ S],
(3)
i) ∈ {0,1}n is the i-th row of the adjacency
where ai (resp. a(cid:48)
matrix of graph G (resp. G(cid:48)).
Relationship DP is the same as decentralized DP in [53]
except that the former (resp. latter) assumes that each user
knows only her friends (resp. all of her friends’ friends).
Edge LDP assumes that user vi’s edge connected to user v j
and user v j’s edge connected to user vi are different secrets,
with user vi knowing the former and user v j knowing the latter.
Relationship DP assumes that the two secrets are the same.
Note that the threat model of relationship DP is different
from that of LDP – some amount of trust must be given to
the other users in relationship DP. Speciﬁcally, user vi must
trust user v j to not leak information about their shared edge.
If k ∈ N users decide not to follow their protocols, then up to
k edges incident to user vi may be compromised. This trust
model is stronger than LDP, which assumes nothing about
what other users do, but is much weaker than centralized DP
in which all edges are in the hands of the central party.
Other than the differing threat models, relationship DP and
edge LDP are quite closely related:
Proposition 1. If randomized algorithms R1, . . . ,Rn provide
ε-edge LDP, then (R1, . . . ,Rn) provides 2ε-relationship DP.
Proof. The existence of edge (vi,v j)∈ E affects two elements
ai, j,a j,i ∈ {0,1} in the adjacency matrix A. Then by group
privacy [23], Proposition 1 holds.
Proposition 1 states that when we want to protect one edge
as a whole, the privacy budget is at most doubled. Note, how-
ever, that some randomized algorithms do not have this dou-
bling issue. For example, we can apply the RR to the i-th
986    30th USENIX Security Symposium
USENIX Association
neighbor list ai so that Ri outputs noisy bits (b1, . . . ,bi−1) ∈
{0,1}i−1 for only users v1, . . . ,vi−1 with smaller user IDs; i.e.,
for each j ∈ {1, . . . ,i−1}, b j (cid:54)= ai, j with probability p = 1
eε+1
and b j = ai, j with probability 1− p. In other words, we can
extend the RR for a neighbor list so that (R1, . . . ,Rn) outputs
only the lower triangular part of the noisy adjacency matrix.
Then all of R1, . . . ,Rn provide ε-edge LDP. In addition, the
existence of edge (vi,v j) ∈ E (i > j) affects only one ele-
ment ai, j in the lower triangular part of A. Thus, (R1, . . . ,Rn)
provides ε-relationship DP (not 2ε).
Our proposed algorithm in Section 4.3 also has this prop-
erty; i.e., it provides both ε-edge LDP and ε-relationship DP.
3.3 Global Sensitivity
In this paper, we use the notion of global sensitivity [23] to
provide edge centralized DP or edge LDP.
Let D be the set of possible input data of a randomized
algorithm. In edge centralized DP, D = G. In edge LDP,
D = {0,1}n. Let f : D → R be a function that takes data
D ∈ D as input and outputs some statistics f (D) ∈ R about
the data. The most basic method for providing DP is to add
the Laplacian noise proportional to the global sensitivity [23].
Deﬁnition 4 (Global sensitivity). The global sensitivity of a
function f : D → R is given by:
GS f =
D,D(cid:48)∈D:D∼D(cid:48)| f (D)− f (D(cid:48))|,
max
where D ∼ D(cid:48) represents that D and D(cid:48) are neighbors; i.e.,
they differ in one edge in edge centralized DP, and differ in
one bit in edge LDP.
In graphs, the global sensitivity GS f can be very large.
For example, adding one edge may result in the increase of
triangle (resp. k-star) counts by n− 2 (resp.(cid:0) n
(cid:1)).
k−1
One way to signiﬁcantly reduce the global sensitivity is
to use graph projection [16, 36, 48], which removes some
neighbors from a neighbor list so that the maximum degree
dmax is upper-bounded by a predetermined value ˜dmax ∈ Z≥0.
By using the graph projection with ˜dmax (cid:28) n, we can enforce
small global sensitivity; e.g., the global sensitivity of triangle
(resp. k-star) counts is at most ˜dmax (resp.(cid:0) ˜dmax
(cid:1)) after the
k−1
projection.
Ideally, we would like to set ˜dmax = dmax to avoid removing
neighbors from a neighbor list (i.e., to avoid the loss of utility).
However, the maximum degree dmax can leak some informa-
tion about the original graph G. In this paper, we address this
issue by privately estimating dmax with edge LDP and then
using the private estimate of dmax as ˜dmax. This technique
is also known as adaptive clipping in differentially private
stochastic gradient descent (SGD) [44, 54].
Table 1: Basic notations in this paper.
Description
Number of users.
Symbol
n
G = (V,E) Graph with n nodes (users) V and edges E.
vi