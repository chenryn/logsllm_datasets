j ∧ ∀i ≤ k < j : sk = s′
∃j ∈ [i, n) : sj < s′
k. We will
write s ≤i s′ if s <i s′ or ∀j ∈ [i, n) : sj = s′
j .
A more efﬁcient algorithm A to compute iv(a, R)(i)
runs as follows.
1. Sort the dump set R in ascending order with respect
to ≤i. Let s(1) ≤i s(2) ≤i . . . ≤i s(|R|) be the
sorted list of these dumps.
2. For j from 1 to |R| − 1, compare s(j) with s(j+1).
For the comparison, start with the i-th bit and move
towards the n − 1-st bit. Let kj be the index of the
ﬁrst bit in which s(j) differs from s(j+1). If no such
bit exists, output ⊥ and stop.
3. Output the interval [i, maxj∈[1,|R|](kj)].
Theorem 3. Let S ⊆ Bn be a dump set and a ∈ A
an attribute. Let R be a set of representatives of the
sets in bundles(a, S). Then the set T with T ∩ In =
diss(a, R) ∩ In is computed by A in time O(n2 |R| +
n |R| log |R|).
The calculation of the diss set is explained in Figure 4.
We start by taking a representative of each of the bundles.
Then, starting from the left, we calculate for each posi-
tion how far to the right we must go in order to ﬁnd a
distinguishing bit for each pair of dumps. For position 0
the ﬁrst two bits already make a distinction between the
three dumps, which gives the interval [0, 1] (indicated by
the ﬁrst line with asterisk symbols). For position 1 we
need three bits, because s3 and s4 coincide at positions 1
and 2. This gives the interval [2, 4], etc. Those sets be-
longing to the subset-minimal diss set are marked with
“minimal”.
rl
4
5
6
s1
s3
s4
dump
010100100111010000
101110101011010100
001010110111011011
**................ minimal
.***..............
..**.............. minimal
...**............. minimal
....****.......... minimal
.....****.........
......***.........
.......**......... minimal
etc.
Figure 4: Calculation of the diss set.
If we combine the comm set from Figure 3 and the
diss set from Figure 4, under the assumption that the
number of rides is encoded with 4 bits, we obtain the
four remaining possibilities from Figure 5. This result
includes the three possible attribute mappings from Fig-
ure 1.
rl
4
4
5
6
6
s1
s2
s3
s4
s5
dump
010100100111010000
001100100001010010
101110101011010100
001010110111011011
111010110011011001
...****...........
....****..........
.....****.........
............****..
Figure 5: The resulting attribute mappings.
7 The mCarve tool
We have implemented the algorithms of Section 6 in a
prototype called mCarve [12]. The prototype allows the
forensic analyst to input a collection of dumps and a col-
lection of attributes. Each of the dumps can be accompa-
nied by its attribute values. The prototype was written in
Python and consists of approximately 1200 lines of code
(excluding graphical user interface).
After entering the dumps and attributes the user can
run the commonalities algorithm for an attribute. The
output of the algorithm is the set of indexes I for which
all dumps with the same attribute value are the same. The
set I is used as a coloring mask to display any dump d
selected by the user: if i ∈ I, then di is colored blue,
otherwise red. The dissimilarities algorithm computes a
subset-minimal set of dissimilarity intervals. Since these
intervals may be overlapping, the prototype enumerates
them rather than showing them as one coloring mask.
This allows the user to step through the intervals. The
prototype displays the interval iv by applying a yellow
coloring mask to all bits di for i ∈ iv. A combined pro-
cedure consolidates the results from the commonalities
and dissimilarities algorithms.
The prototype further allows users to specify two types
of special attributes: a constant attribute and a hash at-
tribute. The former has a constant value for all dumps
and can be used to determine which bits never change.
The latter has a different value for all pairwise differ-
ent dumps and can be used to detect encrypted attributes.
The tool allows one to derive new attributes from other
attributes. These derived attributes can be used to ﬁnd
cyclic attribute mappings. The tool further allows one to
apply an encoding to a selected interval in each dump. A
number of standard encodings, such as ASCII and base
10, are implemented. Aside from displaying the out-
put onscreen, the user can choose to export the results
to JPEG or to LATEX (see Figure 7 for an example).
7.1 Performance
We illustrate the performance of our prototype by run-
ning our prototype on a generated test suite. The test
suite consists of dumps of sizes 8KB, 16KB, 32KB,
64KB, 128KB, and 256KB. For each ﬁle size, 5 dump
sets were generated. Each dump embeds one attribute at
a random position and is encoded in at most 64 bits. The
remaining bits are randomly generated.
The running time of the commonalities procedure is
linear in the number of dumps and the dissimilarities pro-
cedure is quadratic in the number of bundles. Therefore,
the execution time of the combined procedure is mainly
dependent on the number of bundles in the dump set.
Convergence tests show that, in general, fewer than 10
bundles are needed to ﬁnd an attribute in a dump set.
This allows us to restrict our performance tests to dump
sets of 10 bundles.
256 KB
128 KB
64 KB
32 KB
× 16 KB
8 KB
120
100
)
s
(
e
m
i
t
80
60
40
20
b0
0
×
1
×
2
×
3
×
4
×
5
×
6
×
7
×
8
×
9
×
10
bundles
Figure 6: Performance
The tests were run on a Linux machine (kernel 2.6.31-
22) with Intel Core 2 6400 @ 2.13 GHz processor run-
ning Python 2.6.4. Figure 6 shows on the horizontal axis
the number of bundles included in the dump set. On the
vertical axis it shows for each of the ﬁle sizes the time in
seconds (averaged over the 5 dump sets) needed to per-
form the combined procedure. The test shows that our
prototype is best suited for dumps of size smaller than
32KB, but it can deal reasonably well with size up to
256KB. Initial experiments have shown that performance
of the tool can be signiﬁcantly improved by implement-
ing the core procedures in a lower-level language.
7.2 Convergence
Another interesting measure for the mCarve tool is the
rate of convergence of the carved intervals. We will mea-
sure it by computing the number of dumps that are nec-
essary in order to ﬁnd an attribute in a dump set. For sim-
plicity, we assume that the dumps as well as the attribute
values are given by a uniformly random distribution.
Let q denote the bit length of the attribute’s encoding
in the dump, let N denote the number of dumps and let x
be the number of bundles. We ﬁrst compute the probabil-
ity of false positives, i.e. the probability of an accidental
occurrence of values matching an attribute. The proba-
bility that the bit string formed by a particular interval of
q bits in all N dumps matches a particular given string
of bits is 2−qN . There are (cid:18)2q
x(cid:19) · x! possible encodings
of x different values. The probability that the q bits in all
N dumps match one of these representations is therefore
2−qN(cid:18)2q
x(cid:19) · x!.
Thus if l denotes the length of the bit strings represent-
ing dumps, then the probability pnfp of no false positives
b
b
b
b
c
b
c
b
c
b
c
b
c
b
c
b
c
b
c
b
c
b
c
r
s
r
s
r
s
r
s
r
s
r
s
r
s
r
s
r
s
r
s
u
t
u
t
u
t
u
t
u
t
u
t
u
t
u
t
u
t
u
t
q
p
q
p
q
p
q
p
q
p
q
p
q
p
q
p
q
p
q
p
b
b
b
b
b
b
b
b
b
b
b
q
p
u
t
r
s
b
c
is given by
pnfp ≥ (cid:18)1 −
2−qN · 2q!
(2q − x)! (cid:19)l−q+1
.
The inequality is due to the fact that the product on the
right does not concern independent trials. We are inter-
ested in those values of x and N for which the probability
pnfp is large enough that the discovery of an attribute is
not coincidental.
Using the inequality(cid:18)n
k(cid:19) ≤
nk
k!
we obtain
(cid:18)1 −
l−q+1