### 8. Masking Transformation

#### 8.1 Implementation

As a proof of concept, we have implemented our type system for a subset of the C programming language that includes basic operators, static `for` loops, table lookups at public indices, and mutable secret state. We also extended this with libraries that implement core gadgets for various choices of \( K \). Additionally, we define a source-to-source certifying masking transformation, which takes an unprotected program and returns a masked algorithm accepted by our type system. This transformation selectively inserts refreshing gadgets as required for typing to succeed. It is important to note that the transformation itself does not need to be trusted, as the final program is subjected to type checking.

We chose C as the supporting language for convenience, given that many of the algorithms we consider have reference implementations in C. However, we do not claim that compiling and executing the C programs produced by our masking transformation will automatically yield secure executables. Our verification results are based on the algorithms described in the C language rather than on the C programs themselves. Practical use of these verification results still requires considering details not accounted for in the probing model. This is an important problem but is out of the scope of this paper and is a research area in its own right. For example, Balasch et al. [2] address some of the issues involved in securely implementing probing-secure algorithms.

##### 8.1.1 Passes in the Masking Transformation

**Parsing and Pre-Typing:**
This pass parses the C code into our internal representation, checks that the program is within the supported subset of C, performs C type-checking, and ensures that variables marked as sensitive (given type \( K \)) are never implicitly cast to public types. Implicit casts from public types to \( K \) (when compatible, e.g., casting a public `uint8_t` to a protected variable in \( GF(2^8) \)) are replaced with public encoding gadgets (which set one share to the public value and all other shares to 0).

**Gadget Selection and Generic Optimizations:**
This pass heuristically selects optimal gadgets based on their usage. For instance, multiplication of a secret by a public value can be computed using an affine gadget that multiplies each share of the secret, while the multiplication of two secrets must be performed using the `SecMult` gadget. Further efforts in formally proving precise types for specialized core gadgets may improve this optimization step. Since the encoding replaces scalar-typed variables (passed by value) with array-typed variables (passed by reference), it is necessary to slightly transform the program to ensure correctness. Additionally, we transform the input program to more closely follow the abstract language from Figure 1, making it easier to type-check.

**Type Inference and Refresh Insertion:**
This is the core of our transformation. We implement a type inference algorithm for the type system of Section 6. The algorithm simplifies policies on the fly, supports inferred types on sub-algorithms as gadget-invocation types, and fails when the simplified policy is inconsistent. Failure indicates the need for a refreshing operation. By tracking additional information and reinforcing typing constraints on sub-algorithms, we automatically insert `Refresh` gadgets where required. When type inference fails, the variable whose masks need to be refreshed is duplicated, and one of its uses is replaced with the refreshed duplicate. To avoid re-typing the entire program after inserting a refresh gadget, our transformation keeps track of typing information for each program point already traversed and simply rewinds the typing to the program point immediately after the modification.

**Code Generation:**
Finally, once all necessary mask refreshing operations have been inserted and the program has been type-checked, we produce a masked C program. This transformation is almost a one-to-one mapping from the instructions in the type-checked programs to calls to a library of verified core gadgets or to newly defined gadgets. Some cleanup is performed on loops to clarify the final code whenever possible, and to remove initialization code on normalized gadgets. Our transformation produces a (set of) C files that are parameterized by the masking order \( t \). Producing executable versions of the algorithm at a particular order, for example, to evaluate its performance, is as simple as defining a pre-processor macro at compile-time.

#### 8.2 Practical Evaluation

To test the effectiveness of our transformation, we applied it to different algorithms, generating equivalent masked algorithms at various orders. The following programs were used:

- **AES ((cid:12)):** A full computation (10 rounds including key schedule) of AES-128 masked using the multiplication gadget, implemented in \( GF(2^8) \).
- **AES (x (cid:12) g(x)):** A full computation (10 rounds including key schedule) of AES-128 masked using Coron et al.’s gadget for computing \( x (cid:12) g(x) \), implemented in \( GF(2^8) \).
- **Keccak:** A full computation (24 rounds) of Keccak-f[1600], implemented in \( GF(2^{64}) \).
- **Simon:** A block of Simon(128,128), implemented in \( GF(2^{64}) \).
- **Speck:** A block of Speck(128,128), implemented in \( GF(2)^{64} \), using one of the following modular addition algorithms:
  - **AddLin:** Coron, Großschädl, and Vadnala’s algorithm [14] for the computation of modular addition on boolean-masked variables (in \( GF(2)^{64} \)).
  - **AddLog:** Coron et al.’s improved algorithm [13] for the computation of modular addition on boolean-masked variables (in \( GF(2)^{64} \)).

We first discuss the performance of our verifier and the verification results before discussing the practical significance in terms of time, memory, and randomness complexity of our masking transformation. Finally, we discuss examples on which our tool implementation could be improved.

**Verification Performance and Results:**

Table 2 shows resource usage statistics for generating the masked algorithms (at any order) from unprotected implementations of each algorithm. The table includes the number of mask refreshing operations inserted in the program, the compilation time, and the memory consumption. For Keccak, we show two sets of figures: "no refresh" and "refresh in χ". The "refresh in χ" set is produced by running our tool on an annotated implementation where a mask refreshing operation is manually inserted in the χ function. We discuss discrepancies between these two sets in Section 9 and consider the "refresh in χ" set of statistics in all discussions until then.

We note significant improvements over the state of the art in formal verification for probing security. Our closest competitor [4] reports verifying all 10 rounds of AES (including key schedule) at order 1 in 10 minutes, and could not verify all 10 rounds for higher orders. In contrast, our tool verifies the probing security of Rivain and Prouff’s algorithm [31] as fixed by Coron et al. [15] at all orders in less than a second. Further, the masked algorithms our transformation produces for modular addition are the first known to be t-probing secure using only \( t + 1 \) shares. The original proofs [14,13] rely on the ISW framework and use \( 2t + 1 \) shares for t-probing security. Coron, Großschädl, and Vadnala’s algorithm [14] does not require the insertion of mask refreshing operations and is thus t-probing secure with \( t + 1 \) shares as originally described. To the best of our knowledge, the results obtained on Keccak, Simon, and Speck constitute the first generic higher-order masking schemes for these algorithms.

| Algorithm               | # Refresh        | Time  | Mem.  |
|-------------------------|------------------|-------|-------|
| AES ((cid:12))          | 2 per round      | 0.09s | 4MB   |
| AES (x (cid:12) g(x))   | 2 per round      | 0.05s | 4MB   |
| AddLin                  | 0                | 0.01s | 4MB   |
| AddLog                  | log2(k) − 1      | 0.01s | 4MB   |
| Keccak (no refresh)     | 1 per round      | ∼20min| 23GB  |
| Keccak (refresh in χ)   | 1 per round      | 18.20s| 456MB |
| Simon                   | 67 per round     | 0.38s | 38MB  |
| Speck (AddLin)          | 61 per round     | 0.35s | 15MB  |
| Speck (AddLog)          | 66 per round     | 0.21s | 8MB   |

**Performance of Masked Algorithms:**

Table 3 reports the time taken to execute the resulting programs 10,000 times at various orders on an Intel(R) Xeon(R) CPU E5-2667 0 @ 2.90GHz with 64GB of memory running Linux (Fedora). As an additional test, we masked an AES computation at order 100, which took approximately 0.11 seconds per block. For AES and Speck, the "unmasked" column shows execution times for the input to our transformation. Although these observations highlight the cost of security, using `RefreshA` when masking the AES SBox does not incur a significant timing gain for any of the masking orders we tested (\( t \leq 20 \)). However, the randomness cost is greatly reduced, which may be significant in hardware or embedded software settings. Further research in reducing the randomness cost of SNI mask refreshing or other gadgets can make security less costly [8,1,6]. We also confirm the 15% timing improvements reported by Coron et al. [15] when implementing the AES SBox using their gadget for computing \( x (cid:12) g(x) \).

| Algorithm               | Unmasked | Order 1 | Order 2 | Order 3 | Order 5 | Order 10 | Order 15 | Order 20 |
|-------------------------|----------|---------|---------|---------|---------|----------|----------|----------|
| AES ((cid:12))          | 2.697s   | 3.326s  | 4.516s  | 8.161s  | 21.318s | 38.007s  | 59.567s  |          |
| AES (x (cid:12) g(x))   | 2.278s   | 3.209s  | 4.368s  | 7.707s  | 17.875s | 32.552s  | 50.588s  |          |
| AddLin                  | 1.572s   | 3.057s  | 5.801s  | 13.505s | 42.764s | 92.476s  | 156.050s |          |
| AddLog                  | 0.279s   | 0.526s  | 0.873s  | 1.782s  | 11.551s | 20.140s  |          |          |
| Keccak                  | 6.136s   | 5.621s  | 19.991s | 42.032s |         |          |          |          |
| Simon                   | 0.078s   | 0.078s  | 0.238s  | 0.053s  | 0.022s  | 0.022s   |          |          |
| Speck (AddLin)          | 4.361s   | 10.281s | 20.053s | 47.389s | 231.423s| 357.153s | 603.261s |          |
| Speck (AddLog)          | 0.529s   | 1.231s  | 2.258s  | 72.358s |         |          |          |          |

We now look more closely at the statistics for the modular addition algorithms `AddLin` and `AddLog` and their effects on the performance of masked algorithms for Speck. Proving `AddLog` t-NI requires the addition of a mask refreshing gadget, whereas `AddLin` does not. Despite this additional cost, `AddLog` is better than `AddLin` when word size \( k \) grows, as it saves \( k - \log(k) \) multiplications and replaces them with a single mask refreshing operation. These performance gains on modular addition become overwhelming when seen in the context of a masked algorithm for Speck, which computes one 64-bit modular addition per round. It would be interesting to consider using our transformer to produce masked algorithms for other efficient circuits for modular addition [26] and measure their performance impact in terms of randomness, time, and memory when masked.

### 9. Discussions and Related Work

Here, we further discuss the relation between the definitions and results reported here and existing and future work in theoretical and practical cryptography. Our discussions focus mainly on:

1. **Adversary and Leakage Models:**
   We have considered security in the probing model of Ishai, Sahai, and Wagner [24], which is well-suited to automated analysis due to its tight relation to probabilistic non-interference. Our notion of t-NI is equivalent to the notions of t-probing security and perfect t-probing security used by Carlet et al. [10] and others [31,15].

   Despite its broad usage in the literature, the practical relevance of the probing model is not immediately obvious. In practice, side-channel adversaries observe leakage traces containing noisy information about all intermediate computations, rather than precise information about some. This threat model is more closely captured by the noisy leakage model, first introduced by Chari et al. [11] and extended by Prouff and others.