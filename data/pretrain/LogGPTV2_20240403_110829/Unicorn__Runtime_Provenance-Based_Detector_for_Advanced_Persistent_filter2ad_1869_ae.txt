26%-90% for commercial products such as Symantec End-
Parameter Value Max Memory Usage (MB)
R = 1
R = 2
R = 3
R = 4
R = 5
|S| = 500
|S| = 1,000
|S| = 2,000
|S| = 5,000
|S| = 10,000
562
624
687
749
812
312
437
687
1,374
2,498
TABLE IX: Memory overheads with varying hop counts and sketch sizes. The
highlighted conﬁgurations gave the best detection performance.
point Protection, Kaspersky Endpoint Security, and McAfee
Endpoint Security. However, direct comparison is difﬁcult.
Research IDS we surveyed (§ VIII) do not report metrics
that allow meaningful comparison. We leave the design of
meaningful performance benchmarks for IDS to future work.
11
Table IX shows memory overheads for the same workload
under two different parameters. Other parameters in the basic
conﬁgurations do not signiﬁcantly inﬂuence memory consump-
tion.
The graph histogram and the random variables sampled
for sketch generation represent the majority of UNICORN’s
memory usage. The size of the histogram is proportional to the
number of unique labels, which in turn is determined by the
size of the neighborhood that each vertex explores. Table IX
shows that as we increase the number of neighborhood hops,
UNICORN requires more memory for the histogram. In theory,
the total number of unique labels is bounded by the number of
possible combinations of node/edge types within |R| hops. In
practice, however, many parts of a provenance graph exhibit
similar structures and therefore the value is signiﬁcantly lower
than the theoretical upper bound. For example, the maximum
memory usage of the experiment corresponding to Fig. 5(a)
remains around 680MB, which is acceptable for modern sys-
tems. As we increase the sketch size, UNICORN consumes
more memory to store additional random variables sampled
for sketch generation and update. Although with |S| = 10, 000,
memory consumption increases up to 2.5GiB (Table IX), the
previous sections suggest that such large values are never a
good option.
VII. DISCUSSION & LIMITATIONS
Anomaly-based Detection. UNICORN shares assumptions,
architecture, and therefore limitations with other anomaly-
based intrusion detection systems.
First, we assume there is a modeling period where system
administrators can run their systems safely to capture system
behavior (§ III). Second, we assume that
there exists an
exhaustive, ﬁnite number of system behavior patterns and
most, if not all, patterns are observed during modeling [109].
UNICORN will raise a false alarm if it observes a new behavior
that is, in fact, normal; such alarms will require human-in-the-
loop intervention.
Adversaries may try to steer malicious behavior towards
learned models to evade detection, similar to the well-known
mimicry attacks [98]. However, conducting mimicry attacks
on provenance graphs and/or UNICORN’s graph sketches is
more challenging than on sequences of system calls, because
provenance graphs contain complex structural information that
is difﬁcult to imitate without affecting the attack. Additionally,
UNICORN’s consistent weighted sampling approach random-
izes sketch generation, making it hard to guarantee that the
low-dimensional projections of mimicry provenance graphs
will be close to learned normal clusters. At the same time, this
complexity will make it difﬁcult to use models to identify the
cause of an alarm. Fortunately, there exist tools that facilitate
attack causality analysis on provenance graphs (§ VIII).
UNICORN,
like other anomaly-based systems, requires
sufﬁcient benign behavior traces to learn behavior models.
Our current modeling design and implementation assumes that
UNICORN monitors a system from the same starting point as
its model, tracking state transitions as the system executes.
It can easily perform such continuous monitoring given its
high performance and scalability (§ VI). However, UNICORN
may raise false alarms if the current state does not match the
Fig. 5: Evaluation of UNICORN’s CPU utilization.
n
o
i
t
a
z
i
l
i
t
U
U
P
C
%
n
o
i
t
a
z
i
l
i
t
U
U
P
C
%
100
80
60
40
20
0
100
80
60
40
20
0
0
0
0
0
0
0
6
0
3
0
,
(a): Average CPU utilization with the baseline conﬁgurations.
,
,
,
,
,
,
2
9
0
2
0
5
0
8
0
1
0
4
1
1
2
3
0
2
0
0
7
0
0
0
1
0
0
0
0
0
3
,
3
0
5
2
0
5
5
7
5
7
0
0
2
5
2
2
0
5
2
5
7
2
0
0
5
2
0
5
1
1
1
1
Time (seconds)
(b): Per virtual CPU and average CPU utilization.
Average CPU
vCPU0
vCPU1
vCPU2
vCPU3
vCPU4
vCPU5
vCPU6
vCPU7
modeled state as a result of, e.g., the system restoring to a
saved state due to failure. One approach to addressing this issue
is to integrate UNICORN more closely with the system so that
it can save its model state at the same time the system creates
snapshots; when the system restores a snapshot, UNICORN
would restore the corresponding model state.
False Alarms. As brieﬂy mentioned above, when normal
system behavior changes, UNICORN might raise false positive
alarms, since it does not dynamically adjust its model (to avoid
attacker poisoning). The false alert problem is not unique to
UNICORN. In fact, it is a major concern even for signature-
based approaches used in practice, although in theory, these
approaches are designed to generate few such alarms due to
rigid attack matching [2]. UNICORN partially mitigates this
issue using concept drift (§ IV-B), modeling system evolution.
As we demonstrated in § VI, UNICORN improves precision
by 24% compared to the state-of-the-art and achieves near
perfect results on the DARPA datasets. However, UNICORN
must also ensure stability to avoid adversarial manipulation,
which inevitably increases the potential for false alerts. There-
fore, system administrators might need to periodically retrain
12
UNICORN’s model to stay up-to-date. Fortunately, updating
UNICORN models is quick; the important caveat is to ensure
that new training data is known to be devoid of malicious
activity.
Graph Analysis. UNICORN enables efﬁcient and powerful
graph analysis, but similar to many IDS [8, 23, 83, 87], it
also requires parameters that must be tuned to each system
to improve detection performance (§ VI-D). Finding ideal
parameters for a speciﬁc task is a well-known research topic
in machine learning [119]. We used OpenTuner [11] to enable
program autotuning. Although our tests are by no means
exhaustive, it is encouraging that we were able to use the
same settings on almost all of our evaluation datasets, even
though they came from disparate sources and modeled rather
different attacks. Due to time and space constraints, we leave
the discussion of automatically tuning UNICORN to future
work.
Heterogenous Host Activity. In testing, we observed that
UNICORN performed extremely well
in domains featuring
homogenous normal activities. For example, we achieve near-
perfect detection rates for the StreamSpot dataset (Table I).
This makes UNICORN a promising security tool in datacenters
and other production environments that perform well-deﬁned
tasks, which are frequently the target of attacks [22, 74, 106].
Hosts that exhibit more diverse behaviors, such as work-
stations [18], pose a greater challenge for IDS in general.
Modern provenance capture systems (e.g., CamFlow) help
mitigate this issue as they can separate provenance data based
on, e.g., namespaces and control groups [100]. However, we
acknowledge that endpoint security for workstations presents
extra challenges that UNICORN does not attempt to address in
this work, as it was originally designed to protect more stable
environments.
Larger Cross-evaluation. We emphasize that comparing UNI-
CORN with other existing IDS (most of which are syscall-
based) is difﬁcult for several reasons: A) many IDS are
not open-source; B) existing public IDS datasets are either
outdated [4, 85] or require a translation [28, 50, 51] from, e.g.,
syscall traces to data provenance, which is challenging and
sometimes impossible (due to lack of information); C) systems
that create their own private datasets only superﬁcially describe
their experimental procedures, making it difﬁcult
to fairly
reproduce the experiments for provenance data. We believe
that such a meta-study is a worthwhile endeavor that we plan
to pursue in future work.
VIII. RELATED WORK
This work lies at
the intersection of dynamic host-
based intrusion detection, graph-based anomaly detection, and
provenance-based security analysis. Therefore, we place UNI-
CORN in the context of prior work in these areas.
Dynamic Host-based Intrusion Detection. Dynamic host-
based intrusion detection (HID) was pioneered by Forrest et
al.’s anomaly detection system [37] that used ﬁxed-length
sequences of syscalls to deﬁne normal behavior for UNIX
processes. Debar et al. [29] and Wespi et al. [127] later
generalized the approach to incorporate variable-length pat-
terns. As attacks became increasingly sophisticated [117, 123],
systems that modeled only syscall sequences suffered from
low detection accuracy. Next generation systems added state
to provide contextual information to the syscalls. Sekar et
al. [109] designed a ﬁnite-state automaton (FSA) that modeled
each state as the invocation of a system call from a particular
call site. VtPath [36] extended this idea to avoid the impossible
path problem, in which there may exist sequences of state
transitions in the FSA that cannot happen in practice. VtPath
performed more extensive call stack analysis to identify such
impossible paths as anomalies. Jafarian et al. [62] addressed
the impossible path problem by using a deterministic push-
down automata (DPDA). Maggi et al. [81] extended these
approaches by combining models of system call sequences
with models for the parameters to those system calls. As
automaton-based models approach their theoretical accuracy
limit, which is equivalent
to a linear bounded automaton
(LBA) or a context-sensitive language model, their detection
capacity increases; however, the non-polynomial complexity
of such theoretical models makes it impossible to realize in
practice [113]. Even a constrained DPDA model exhibits a
polynomial time complexity [62]. Shu et al. [113] presented a
formal framework that surveyed host-based anomaly detection,
discussing in detail various dynamic and static approaches
orthogonal to our work. Liu et al. [78] summarized the state-
of-the-art host-based IDS [26, 68, 91] and discussed future
research trends, indicating data as one of the decisive factors
in IDS research.
UNICORN takes a completely different approach, because
traditional system call approaches are not well-suited for
APT attacks ( § II-A)
[61, 125]. Our graph representation
and analysis avoids costly control-ﬂow construction and state
transition automata, while accurately describing and model-
ing complex relationships among data objects in the system
for contextualized anomaly detection. To the best of our
knowledge, although some systems produce provenance-like
graphs from audit logs [83], UNICORN is the ﬁrst system to
detect intrusions via runtime analysis of native whole-system
provenance.
Graph-based Anomaly Detection. Akoglu et al. determine
graph or subgraph similarity for anomaly detection by catego-
rizing graphs based on their properties (i.e., static vs. dynamic,
plain vs. attributed)
[8].
Ding et al. [30] identiﬁed malicious network sources in
network ﬂow trafﬁc graphs based on cut-vertices, using simi-
larity metrics such as betweenness to detect cross-community
communication behavior. Liu et al. [77] constructed a software
behavior graph to describe program execution and used a
support vector machine (SVM) to classify non-crashing bugs
(e.g., logic errors that do not crash the program) based on
closed subgraphs and frequent subgraphs. These systems and
many other graph mining algorithms [39, 103] and graph
similarity measures (e.g., graph kernels [122]) are designed
only for static graphs and are difﬁcult to adapt to a streaming
setting.
Papadimitriou et al. [97] proposed ﬁve similarity schemes
for dynamic web graphs, and NetSimile [17] used moments of
distribution to aggregate egonet-based features (e.g., number of
neighbors) to cluster social networks. Aggarwal et al. [6] used
a structural connectivity model to deﬁne outliers and design a
reservoir sampling approach that robustly maintains structural
summaries of homogeneous graph streams. However, these and
13