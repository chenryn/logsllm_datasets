title:Try before You Buy: Privacy-preserving Data Evaluation on Cloud-based
Machine Learning Data Marketplace
author:Qiyang Song and
Jiahao Cao and
Kun Sun and
Qi Li and
Ke Xu
Try before You Buy: Privacy-preserving Data Evaluation on
Cloud-based Machine Learning Data Marketplace
Qiyang Song1, Jiahao Cao2,3, Kun Sun1, Qi Li2,3, and Ke Xu2,3
1Center for Secure Information Systems, George Mason University, Fairfax, VA, United States
2Department of Computer Science and Technology, Tsinghua University, Beijing, China
3Institute for Network Sciences and Cyberspace & BNRist, Tsinghua University, Beijing, China
PI:EMAIL,PI:EMAIL,PI:EMAIL,{qli01,xuke}@tsinghua.edu.cn
ABSTRACT
A cloud-based data marketplace provides a service to match data
shoppers with appropriate data sellers, so that data shoppers can
augment their internal data sets with external data to improve their
machine learning (ML) models. Since data may contain diverse
values, it is critical for a shopper to evaluate the most valuable data
before making the final trade. However, evaluating ML data typi-
cally requires the cloud to access a shopper’s ML model and sellers’
data, which are both sensitive. None of the existing cloud-based
data marketplaces enable ML data evaluation while preserving both
model privacy and data privacy. In this paper, we develop a privacy-
preserving ML data evaluation framework on a cloud-based data
marketplace to protect shoppers’ ML models and sellers’ data. First,
we provide a privacy-preserving framework that allows shoppers
and sellers to encrypt their models and data, respectively, while
preserving data functionality and model functionality in the cloud.
We then develop a privacy-preserving data selection protocol that
enables the cloud to help shoppers select the most valuable ML data.
Also, we develop a privacy-preserving data validation protocol that
allows shoppers to further check the quality of the selected data.
Compared to random data selection, the experimental results show
that our solution can reduce 60% prediction errors.
CCS CONCEPTS
• Security and privacy → Cryptography; Privacy-preserving
protocols.
KEYWORDS
Data Market, Neural Networks, Privacy-preserving
ACM Reference Format:
Qiyang Song1, Jiahao Cao2,3, Kun Sun1, Qi Li2,3, and Ke Xu2,3. 2021. Try
before You Buy: Privacy-preserving Data Evaluation on Cloud-based Ma-
chine Learning Data Marketplace. In Annual Computer Security Applications
Conference (ACSAC ’21), December 6–10, 2021, Virtual Event, USA. ACM, New
York, NY, USA, 13 pages. https://doi.org/10.1145/3485832.3485921
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
© 2021 Association for Computing Machinery.
ACM ISBN 978-1-4503-8579-4/21/12...$15.00
https://doi.org/10.1145/3485832.3485921
1 INTRODUCTION
Nowadays, the advent of deep learning techniques significantly
improves the performance of traditional machine learning (ML) in a
number of fields, such as image recognition [36], speech recognition
[15], and natural language processing [29]. The data-driven deep
learning algorithms heavily rely on a large amount of good-quality
data to train a well-performing learning model, and there is a need
for customers to augment or enrich their internal data sets with
external data. To enable large-scale data acquisition, the industry
gradually develops a number of data marketplaces [3, 9, 18], which
use the Data-as-a-Service mode [41] to build a data exchanging
platform for both enterprises and individuals.
A data marketplace usually offers data of different values for
training a ML model, where the valuable data may significantly
improve the model performance and the less valuable data have
minor contribution. Therefore, it is crucial for a cloud-based data
marketplace to assist data shoppers in evaluating and purchasing
the most valuable data. Typically, evaluating ML data for a data
shopper may require the cloud to access the shopper’s model and
sellers’ data. However, sellers are not willing to expose their data
before the final payment is settled, in fear of their data being leaked
and thus losing values. Meanwhile, shoppers are reluctant to dis-
close their proprietary models since the models are their digital
assets. Therefore, it is necessary to design a privacy-preserving ML
data evaluation framework on a cloud-based data marketplace.
Existing cloud-based data marketplaces [17, 21, 23] provide flex-
ible data search and evaluation. However, they do not support data
evaluation for ML models. Some semi-supervised machine learning
techniques [1, 2] can be used to evaluate valuable training data from
a data pool according to model functionality. However, these tech-
niques do not provide privacy protection on models and data in the
cloud. Existing ML encryption frameworks [7, 14, 16, 19, 27, 31, 32]
can be applied to preserve model privacy and data privacy in the
cloud; however, since they are built on either homomorphic encryp-
tion (HE) [7, 14, 16, 19] or secure multi-party computation (MPC)
schemes [27, 31, 32], they incur prohibitively expensive computa-
tion or communication overhead when executing model functions.
Furthermore, as these frameworks are not specially designed to
evaluate data, we cannot rely on them to provide privacy-preserving
data evaluation.
In this paper, we propose Primal, a privacy-preserving and effi-
cient machine learning data evaluation framework on a cloud-based
data marketplace. It not only enables data sellers to sell ML data
in the cloud without exposing data, but also allows data shoppers
to evaluate and purchase valuable ML data without leaking their
models. Primal is powered by three designs, namely, an efficient
260ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Qiyang Song1, Jiahao Cao2,3, Kun Sun1, Qi Li2,3, and Ke Xu2,3
ML encryption protocol, a privacy-preserving data selection proto-
col, and a privacy-preserving data validation protocol. Specifically,
the ML encryption protocol enables shoppers and sellers to en-
crypt their models and data in the cloud. The privacy-preserving
data selection and data validation protocol allow the cloud to help
shoppers screen out valuable data from sellers’ encrypted data.
Our ML encryption protocol allows shoppers and sellers to en-
crypt their models and data without depriving the functionality of
models and data in the cloud. Particularly, the functionality means
that the cloud can perform training and prediction operations with
encrypted models and data. For a neural network model, the first
step in training and prediction operations is matrix or convolution
computation. As the two types of computation can be transformed
to inner product operations, we utilize inner product functional
encryption (IFE) [1, 2] to encrypt input data and the parameters of
the first hidden layer. For the parameters of the remaining layers,
we apply matrix transformation to convert these parameters with
random numbers. Since IFE and matrix transformation are light-
weight, we achieve higher efficiency than HE-based and MPC-based
ML encryption.
tion framework on a cloud-based data marketplace.
In summary, we make the following contributions:
• We propose a privacy-preserving and efficient ML data evalua-
• We provide an efficient ML encryption protocol that can pre-
serve both the privacy and functionality of sellers’ models and
shoppers’ data in the cloud.
• We design a privacy-preserving data selection protocol and
data validation protocol that allow the cloud to help a shopper
select and refine valuable data.
• We conduct a security analysis and experiments to demonstrate
the security, effectiveness, and efficiency of Primal.
2 BACKGROUND
In this section, we provide the necessary background on neural
networks, active learning, and inner product functional encryption.
Neural Networks. Typical neural networks, e.g., CNNs and MLPs,
consist of an input layer, hidden layers, and an output layer. Par-
ticularly, the input layer receives high dimensional input data, the
output layer outputs the corresponding prediction values1, and
the hidden layers learn the relationship between input data and
prediction values. In this section, we briefly introduce two fun-
damental types of hidden layers, i.e., fully-connected layers and
convolution layers. A fully-connected layer receives the input data
from the previous layers and perform computation as f (W(cid:174)x + b),
where W is a parameter matrix, (cid:174)x is the input data, b is a bias, and
f is an activation function. Note that b can be embedded into the
matrix W. A convolution layer performs convolution computation
between convolution kernels and input data (a two-dimensional
matrix), runs activation functions, and then outputs a feature map
(activation values) to the next layer. Here, we provide a brief review
of some technical terms as follows.
• Convolution computation: maps a two-dimension matrix to a
new matrix with convolution kernels. It consists of multiple
convolution strides. In each stride, it executes inner product
operations between a subarea of the input matrix and kernels.
• Activation function: is a non-linear function. Prior work has
proposed a variety of activation functions, such as Relu, Sig-
moid, and Squared Function [10, 26].
• Cost function: computes the prediction errors between predic-
tion values and labels, which can reveal prediction performance.
• Feed forward: is a process that data flows from the input layer
to the output layer. It finally outputs prediction values.
• Back propagation: is a part of model training. It computes pa-
rameter gradients ∇W according to a cost function and then
updates parameters W. To be precise, the parameters are up-
dated as W − α ∗ ∇W, where α is a learning rate.
Active Learning. Active learning is a semi-supervised machine
learning approach, enabling a trainer to select informative training
data from an unlabeled data pool. Compared with random data
selection, active learning can select informative data to significantly
change the decision boundary of models. In the field of active
learning, uncertainty selection [5, 13, 20] is a popular data selection
algorithm, which can select informative data with prediction values
instead of accessing original data.
1Prediction values refer to the confidence values on multiple classes.
Note that the cloud cannot directly evaluate valuable data for a
data shopper since sellers’ data are encrypted in the cloud. There-
fore, we design a privacy-preserving data selection protocol that
allows the cloud and a shopper jointly to select valuable data. For a
shopper’s model, valuable data refer to some informative data that
can significantly improve its model performance. As active learning
[5, 13, 20] can estimate data informativeness with prediction values,
the cloud and shopper can utilize this technique to select valuable
data without seeing the original data. To provide prediction values
for evaluation, our data selection protocol offers a prediction ap-
proach that allows the cloud to use a shopper’s encrypted model
to predict sellers’ encrypted data. Then, the shopper can retrieve
some prediction values from the cloud to evaluate sellers’ data.
Although the data selection protocol can select informative data
for a shopper, the selected data may contain irrelevant or falsely
labeled data, which may poison the shopper’s model. Therefore, we
design a privacy-preserving data validation protocol that allows the
shopper to further examine the quality of the selected data. Note
that the shopper cannot access the original data before the final
payment. Thus, it cannot directly estimate data quality. Fortunately,
another possible approach is to use the selected data to retrain the
shopper’s model and observe the change of model performance to
estimate data quality. More specifically, the shopper first requires
the cloud to retrain its encrypted model with the selected data, and
it then collects some prediction values to estimate data quality.
We conduct a security analysis of Primal and prove its security
in the untrusted cloud. Additionally, we carry out experiments to
demonstrate the effectiveness and efficiency of Primal. Experimen-
tal results show Primal can effectively select valuable ML data that
significantly improves model performance. Compared to random
data selection, Primal can reduce 60% prediction errors. Even if the
selected data contain irrelevant and falsely labeled data, Primal can
detect such data with more than 99% accuracy. Furthermore, the
results show that Primal achieves high efficiency on encryption
and machine learning operations. For example, Primal can provide
17× faster prediction operations compared to a popular HE-based
ML encryption framework.
261Try before You Buy
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Inner Product Functional Encryption (IFE). As a new genera-
tion of public-key encryption, inner-product functional encryption
allows an untrusted party to efficiently compute inner products over
ciphertexts with restricted decryption keys. It works as follows:
• Setup(1k): takes a security parameter 1k as input, and outputs
a master key pair (msk, mpk).
• KeyGen((cid:174)x, msk): takes a vector (cid:174)x and a master secret key msk
as input, and outputs a secret functional key skx .
• Encrypt((cid:174)y, mpk): takes a vector (cid:174)y and a master secret key mpk
as input, and outputs a vector of ciphertexts (cid:174)Cy.
• Decrypt( (cid:174)Cy, skx ): takes a ciphertext (cid:174)Cy and a secret functional
key skx as input, and outputs the original inner product (cid:174)x · (cid:174)y.
• MDec( (cid:174)Cy, msk): takes a ciphertext (cid:174)Cy and a master secret key
msk as input, and outputs the original vector (cid:174)y.
3 SYSTEM OVERVIEW
In this section, we first describe our threat model and assumptions.
We then present the Primal architecture.
3.1 Threat Model and Assumptions
In this paper, we consider a typical cloud-based data marketplace
consisting of a data shopper, a group of data sellers, and an untrusted
cloud. To gain benefits from their data, sellers tend to upload their
data to the cloud for sale. The shopper tries to purchase valuable
sellers’ data from the cloud to improve its ML model. Rather than
access the original sellers’ data, the shopper retrieves auxiliary
information (i.e., prediction values) from the cloud to evaluate
sellers’ data. We assume the cloud is honest-but-curious [8, 28, 33].
In other words, the cloud follows the predefined protocol faithfully,
but it may exploit the shopper’s model and sellers’ data to make
profits or derive some personal information.
We do not particularly consider the adversarial relationship be-
tween the shopper and sellers. Although model inversion attacks
[12, 39] may facilitate the shopper to derive original data from pre-
diction values, these attacks are difficult to be launched since they
require enormous data to model the relationship between predic-
tion values and the original data; however, the shopper who intend
to purchase data often have a small amount of data. Additionally,
we assume sellers desire to profit fully from their data. Therefore,
they do not launch data poisoning attacks [35] since most of them
often degrade the shopper’s model performance, and thus they can
be easily detected. In this paper, we only consider that sellers may
unintentionally hold a small set of irrelevant or mislabeled data.
3.2 System Architecture
Figure 1 illustrates the architecture of Primal, a privacy-preserving
and efficient ML data evaluation framework on a cloud-based data
marketplace. Overall, Primal contains three components: (i) a group
of data sellers, who encrypt their data and upload them to the cloud
for sale; (ii) a data shopper, who encrypts its model parameters and
uploads them to the cloud for evaluation; (iii) a cloud server, which
can help the shopper evaluate sellers’ encrypted data.
Primal is powered by three designs: an efficient machine learning
encryption protocol, a data selection protocol, and a data valida-
tion protocol. Our encryption protocol applies lightweight inner
Figure 1: Primal Architecture
product functional encryption (IFE) and matrix transformation to
encrypt ML models and data. Additionally, it also allows the cloud
to perform prediction or training operations with the encrypted
model and data. By collecting prediction values from the cloud, the
data selection protocol utilizes active learning to select potentially
valuable data. As the selected data may contain irrelevant or falsely
labeled data, the data validation protocol further examines data
quality to screen out high-quality data.
Overall, Primal consists of five phases: Setup, Data encryption,
Model enryption, Data selection, and Data validation, where the first
three phases are included in our ML encryption protocol. Here, we
go through the five phases to provide a brief view of our framework.
Setup. The data shopper chooses a security parameter and initial-
izes a set of random numbers, a master public key, and a master
secret key. Then, the master public key is broadcast to data sellers
for data encryption, and the master secret key and random numbers
are used to encrypt model parameters.