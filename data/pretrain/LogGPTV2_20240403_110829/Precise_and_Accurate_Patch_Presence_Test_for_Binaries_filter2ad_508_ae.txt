Strictly
images for CVE-2016-5696.
898    27th USENIX Security Symposium
USENIX Association
∼70%
Step
Analyze
Translation
Cnt. ** Avg.
0.20s
5.49s
9.04s
11.66s
Total
21.52s
6.29s
1608.52s
6.00s
Match Ref.0 * 2647.78s
Match Ref.1 * 3415.54s
7.56s
* Match against reference kernels for uniqueness test.
* 0 for un-patched kernel, 1 for patched kernel.
** Analyze: Patch. Others: Binary Signature.
107
293
293
293
-
Table 3: Ofﬂine Phase Performance
speaking, FIBER intends to detect exactly the same
patch as appeared in the reference kernel, however, to be
conservative, we still
regard such cases as false
negatives.
(5) Other engineering issues. Some FN cases are
caused by engineering issues.
For example, certain
binary instructions cannot be recognized and decoded
by the frontend of angr (two cases in total), which will
affect
the subsequent CFG generation and symbolic
execution.
6.3 Performance
this
section we
evaluate FIBER’s
runtime
In
performance for both ofﬂine signature generation and
online matching. We list the time consumption of the
ofﬂine phase in table 3 and that of online phase in table
2. From the tables, we can see that a small fraction of
patches needs much longer time to be matched than
average, this is usually because the change sites in these
patches are positioned in very large and complex
functions (e.g., CVE-2017-0521),
thus the matching
engine may encounter root instructions deep inside the
function. However, most patches can be analyzed,
translated and matched in a reasonable time. In the end,
we argue that a human will take likely minutes, if not
longer, to verify a patch anyways. An automated and
accurate solution like ours is still preferable, not to
mention that we can parallelize the analysis of different
patches.
6.4 Unported Patches
As shown in table 2, for all the test subjects except
kernel #5, FIBER produces some TN cases, which
suggests un-patched vulnerabilities.
If related security
patches had already been available before the test
subject’s release date, then it means that the test subject
fails to apply the patch timely. Table 4 lists all the
vulnerabilities whose patches fail to be propagated to
one or multiple test subject kernel(s) timely in our
evaluation. Note that for security concerns, we do not
CVE
Patch Date *
(mm/yy)
Type**
Severity*
High
High
07/16
07/16
07/16
08/16
11/16
11/16
03/17
03/17
04/17
CVE-2014-9781
CVE-2016-2502
CVE-2016-3813
CVE-2016-4578
CVE-2016-2184
CVE-2016-7910
CVE-2016-8413
CVE-2016-10200
CVE-2016-10229
* Obtained from Android security bulletin.
** P: Privilege Elevation E: Remote Code Execution
** I: Information Disclosure
Moderate
Moderate
Critical
Critical
Moderate
Critical
Critical
P
P
I
I
P
P
I
P
E
Table 4: Potential Security Loopholes
correlate these vulnerabilities with actual kernels in
table 2.
From table 4, we can see that even some critical
vulnerabilities were not patched in time, indicating a
good potential that they can be leveraged to compromise
the kernel entirely to execute arbitrary code. One such
case is a patch delayed for more than half a year
affecting a major vendor (who conﬁrmed the case and
requested to be anonymized). This illustrates the value
of tools like FIBER.
Besides, we also identify 4 vulnerabilities in table 4
that eventually got patched in a later kernel release but
not in the earliest kernel release after the patch release
date,
the patch
propagation process.
indicating a signiﬁcant delay of
It is worth noting that FIBER intends to test whether
the patch exists in the target kernel, however, the absence
of a security patch does not necessarily mean that the
target kernel is exploitable. So the further veriﬁcation is
still needed.
6.5 Case Study
In this section, we demonstrate some representative
security patches used in our evaluation to show the
strength of FIBER compared to other solutions.
the
Take
function arguments.
Format String Change. There are 5 patches in our
collection that intend to change only the format strings
as
patch for
CVE-2016-6752 in Fig 6 as an example, the speciﬁer p
is changed to pK. It will be impossible to detect it at
binary level without dereferencing the string pointer,
since all other features (e.g.,.
instruction
type.) remain exactly the same. However, without patch
insights, it is extremely difﬁcult to decide which register
or memory location should be regarded as a pointer and
whether it should be dereferenced in the matching
topology,
USENIX Association
27th USENIX Security Symposium    899
CVE-2016-6752
-
+
pr_debug("UNLOAD_APP: qseecom_addr = 0x%p\n", data);
pr_debug("UNLOAD_APP: qseecom_addr = 0x%pK\n", data);
CVE-2016-3858
-
+
+
strlcpy(subsys->desc->fw_name, buf, count + 1);
strlcpy(subsys->desc->fw_name, buf,
min(count + 1, sizeof(subsys->desc->fw_name)));
CVE-2014-9785
-
+
if (__copy_from_user(&load_img_req,
if (copy_from_user(&load_img_req,
CVE-2016-8417
-
+
if (hw_cmd_p->offset > max_size) {
if (hw_cmd_p->offset >= max_size) {
CVE-2015-8944
-
+
+
proc_create("iomem", 0, NULL, &proc_iomem_operations);
proc_create("iomem", S_IRUSR, NULL, 
&proc_iomem_operations);
Figure 6: Example Security Patches
process, rendering all binary-only solutions ineffective
in this case. While FIBER can correctly decide that the
only thing changed is the argument format string (see
§4.2) and then test patch presence by matching the
string content.
Small Change Site. It is very common that a security
patch will only introduce small and subtle changes, such
as the one for CVE-2016-8417 shown in Fig 6, where
the operator “>” is replaced with “>=”. Such a change
has no impact on the CFG topology and only one
conditional jump instruction will be slightly different.
Thus, it will be extremely difﬁcult to differentiate the
patched
the
ﬁne-grained signature.
FIBER handles this case
correctly because the conditional jump is part of the root
instruction and we will check the comparison operator
associated with it.
functions without
un-patched
and
Patch Backport.
A downstream kernel may
selectively apply patches (security or other bug ﬁxes),
which can cause functions to look different
from
upstream. Our reference kernel (v3.10) is actually a
downstream compared to all test subjects except #6 as
shown in table 2.
The patch for CVE-2016-3858
(shown in Fig 6) has a prior patch in the upstream
(which deletes a “if-then-return” statement) for the same
affected function, which was not applied to our
reference kernel, making the two functions
look
different although both patched. FIBER is robust to
such backporting cases because the generated binary
signature is ﬁne-grained and related to only a single
patch.
Multiple Patched Function Versions.
After a
security patch is applied,
the same function may be
modiﬁed by future patches as well. Thus, similar to the
backporting cases, two patched functions can still be
different because they are on different versions.
CVE-2014-9785 is such an example. FIBER can still
precisely locate the same change site as shown in Fig 6
even when faced with a much newer target function,
which differs signiﬁcantly with the reference function.
Constant Change. Patch for CVE-2015-8944 in Fig
6 only changes a function argument from 0 to a
pre-deﬁned constant S IRUSR (0x100 in reference
kernel). Once again, such a small change makes the
patched and un-patched functions highly similar. Even
though a solution wants to strictly differentiate constant
values, it is in general unsafe because the constants are
prone to change across binaries. However, with the
insights of the ﬁne-grained change site, FIBER can
correctly ﬁgure out
that only the value of the 2nd
function argument matters in the matching and it should
be non-zero if patched,
thus effectively handle such
cases.
Similar Basic Blocks. FIBER generates ﬁne-grained
signatures containing only a limited set of basic blocks
(see §4.3.1). It is likely that there will be other similar
basic blocks as the signature if we only look at the basic
block level semantics. One such example has been
shown in Fig 1 and discussed in §3. Previous work
based on basic block level semantics [27, 26] may fail
to handle such cases, While FIBER tries to integrate
function level semantics into the local CFG, resulting in
ﬁne-grained signatures that are both stable and unique.
7 Conclusion
In this paper, we formulate a new problem of patch
presence test under “source to binary” scenario. We
then design and implement FIBER, a fully automatic
solution which can take the best advantage of source
level
information for accurate and precise patch
presence test in binaries. FIBER has been systematically
evaluated with real-world security patches and a diverse
set of Android kernel images, the results show that it
can achieve an excellent accuracy with acceptable
performance, thus highly practical for security analysts.
Acknowledgement
We wish to thank Michael Bailey (our shepherd) and the
anonymous reviewers for their valuable comments and
suggestions. Many thanks to Prof. Heng Yin and Prof.
Chengyu Song for their insightful discussions. This work
was supported by the National Science Foundation under
Grant No.1617573.
900    27th USENIX Security Symposium
USENIX Association
References
[1] Android Security Bulletin.
https://source.
android.com/security/bulletin/.
[2] BinDiff.
bindiff.html.
https://www.zynamics.com/
[3] CVE: Vulnerabilities By Year.
https://www.
cvedetails.com/browse-by-date.php.
[4] Github Annual Report.
github.com/.
https://octoverse.
[5] NetworkX Python Package. https://networkx.
github.io/.
[6] Security
Patch
for
CVE-2015-8955.
https://git.kernel.org/pub/
scm/linux/kernel/git/stable/
linux-stable.git/commit/?id=
8fff105e13041e49b82f92eef034f363a6b1c071.
[7] T. Avgerinos, A. Rebert, S. K. Cha, and D. Brum-
ley. Enhancing symbolic execution with veritest-
ing. ICSE’14.
[8] B. S. Baker. Parameterized duplication in strings:
Algorithms and an application to software main-
tenance.
SIAM J. Comput., 26(5):1343–1362,
October 1997.
[9] M. Bourquin, A. King, and E. Robbins. Binslayer:
Accurate comparison of binary executables.
In
Proceedings of the 2nd ACM SIGPLAN Program
Protection and Reverse Engineering Workshop.
[10] W. Cui, M. Peinado, Z. Xu, and E. Chan. Tracking
rootkit footprints with a practical memory analysis
system. USENIX Security’12.
[11] L. de Moura and N. Bjørner. Z3: An efﬁcient
In Tools and Algorithms for the
SMT solver.
Construction and Analysis of Systems, 2008.
[12] Q. Feng, M. Wang, M. Zhang, R. Zhou, A. Hender-
son, and H. Yin. Extracting conditional formulas
for cross-platform bug search. ASIACCS’17.
[13] Q. Feng, R. Zhou, C. Xu, Y. Cheng, B. Testa,
and H. Yin. Scalable graph-based bug search for
ﬁrmware images. CCS ’16.
[14] D. Gao, M. K. Reiter, and D. Song. Binhunt: Au-
tomatically ﬁnding semantic differences in binary
programs.
In Information and Communications
Security, 2008.
[15] F. K. Hwang, D. S. Richards, and P. Winter. The
Steiner tree problem, volume 53. Elsevier, 1992.
[16] J. Jang, A. Agrawal, and D. Brumley. Redebug:
ﬁnding unpatched code clones in entire os distribu-
tions. Oakland’12.
[17] L. Jiang, G. Misherghi, Z. Su, and S. Glondu.
Deckard: Scalable and accurate tree-based detec-
tion of code clones. ICSE’07.
[18] T. Kamiya, S. Kusumoto, and K. Inoue. Ccﬁnder:
a multilinguistic token-based code clone detection
system for large scale source code. IEEE Transac-
tions on Software Engineering, 28(7):654–670, Jul
2002.
[19] W. M. Khoo, A. Mycroft, and R. Anderson.
Rendezvous: A search engine for binary code. In
2013 10th Working Conference on Mining Software
Repositories (MSR), 2013.
[20] S. Kim, S. Woo, H. Lee, and H. Oh. Vuddy:
A scalable approach for vulnerable code clone
discovery. Oakland’17.
[21] J. Lee, T. Avgerinos, and D. Brumley.
Tie:
Principled reverse engineering of types in binary
programs. NDSS’11.
[22] Z. Li, S. Lu, S. Myagmar, and Y. Zhou. Cp-miner:
ﬁnding copy-paste and related bugs in large-scale
software code.
IEEE Transactions on Software
Engineering, 32(3):176–192, March 2006.
[23] Z. Li, D. Zou, S. Xu, H. Jin, H. Qi, and
J. Hu. Vulpecker: an automated vulnerability
detection system based on code similarity analysis.
ACSAC’16.
[24] J. Ming, M. Pan, and D. Gao.
ibinhunt: Binary
hunting with inter-procedural control ﬂow.
In
Proceedings of the 15th International Conference
on Information Security and Cryptology.
[25] OpenSignal.
Android Fragmentation Visual-
https://opensignal.com/reports/
ized.
2015/08/android-fragmentation/.
[26] J. Pewny, B. Garmany, R. Gawlik, C. Rossow, and
T. Holz. Cross-architecture bug search in binary
executables. Oakland’15.
[27] J. Pewny, F. Schuster, C. Rossow, L. Bernhard, and
T. Holz. Leveraging semantic signatures for bug
search in binary programs. ACSAC’14.
[28] D. A. Ramos and D. Engler. Under-constrained
symbolic execution: Correctness checking for real
code. USENIX Security’15.
USENIX Association
27th USENIX Security Symposium    901
[29] Y. Shoshitaishvili, R. Wang, C. Salls, N. Stephens,
M. Polino, A. Dutcher,
J. Grosen, S. Feng,
C. Hauser, C. Kruegel, and G. Vigna. SoK: (State
of) The Art of War: Offensive Techniques in Binary
Analysis. Oakland’16.
[30] Y. Tian, J. Lawall, and D. Lo.
bug ﬁxing patches. ICSE’12.
Identifying Linux
[31] X. Xu, C. Liu, Q. Feng, H. Yin, L. Song, and
D. Song. Neural network-based graph embedding
for cross-platform binary code similarity detection.
CCS ’17.
902    27th USENIX Security Symposium
USENIX Association