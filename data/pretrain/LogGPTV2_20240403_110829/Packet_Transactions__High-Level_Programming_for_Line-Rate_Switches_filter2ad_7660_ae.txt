Programming languages for networks. Many program-
ming languages target the network control plane [39, 62].
Domino focuses on the data plane, which requires different
programming constructs and compilation techniques.
Several DSLs target the data plane. Click [46] uses C++
for packet processing on software routers. packetC [36],
Intel’s auto-partitioning C compiler [33], and Microengine
C [12] target network processors. Domino’s C-like syntax
and sequential semantics are inspired by these DSLs. How-
ever, because it targets line-rate switches, Domino is more
constrained. For instance, because compiled programs run
at line rate, Domino forbids loops, and because Banzai has
no shared state, Domino has no synchronization constructs.
Jose et al. [43] focus on compiling P4 programs to pro-
grammable data planes such as the RMT and FlexPipe ar-
chitectures. Their work focuses only on compiling state-
less data-plane tasks such as forwarding and routing, while
Domino handles stateful data-plane algorithms.
Abstractions for stateful packet processing. SNAP [24]
programs stateful data-plane algorithms using a network
transaction: an atomic block of code that treats the entire net-
work as one switch [44]. It then uses a compiler to translate
network transactions into rules on each switch. SNAP needs
a compiler to compile these switch-local rules to a switch’s
pipeline, and can use Domino for this purpose.
FAST [50] provides switch support and software abstrac-
tions for state machines. Banzai’s atoms support more gen-
eral stateful processing beyond state machines that enable a
much wider class of data-plane algorithms.
7. DISCUSSION
Packet transactions provide a pathway to take algorithms
that were hitherto meant only for software routers and run
them on emerging programmable line-rate switching chips.
However, more work must be done before packet transac-
tions are ready for production use.
26
Predicated
ReadAddWrite
(PRAW)
Table 5: An atom’s minimum critical-path delay increases
with circuit depth. Mux is a multiplexer. RELOP is a rela-
tional operation (>, <, ==, !=). x is a state variable. pkt.f1
and pkt.f2 are packet ﬁelds. Const is a constant operand.
compiler to generate a codelet pipeline, inspect the stateful
codelets, and create an atom that expresses all the compu-
tations required by the stateful codelets. We check that an
atom can express all these computations by fully executing
the compiler on the data-plane algorithm with that atom as
the target. We then move on to the next algorithm, extending
our atom through a process of trial-and-error to capture more
computations, and using the compiler to verify our intuitions
on extending atoms. In the process, we generate a hierarchy
of atoms, each of which works for a subset of algorithms.
Our atom design process is manual and ad hoc at this
point, but it already shows how a compiler can aid in
instruction-set design for programmable switches. Using the
same iterative approach involving a compiler, we anticipate
the atoms in Banzai machines evolving as data-plane algo-
rithms demand more of the hardware.
6. RELATED WORK
Abstract machines for line-rate switches. NetASM [55] is
an abstract machine and intermediate representation (IR) for
programmable data planes that is portable across network
devices: FPGAs, virtual switches, and line-rate switches.
Banzai is a low-level machine model for line-rate switches
alone and can be used as a NetASM target. Because of its
role as a low-level machine model, Banzai models practical
constraints required for line-rate operation (§2.4) that an IR
like NetASM doesn’t have to. For instance, Banzai machines
pkt.f1Const2-to-1 Muxxpkt.f1ConstAdderxx02-to-1 Mux2-to-1 Muxpkt.f1ConstAdder2-to-1 MuxRELOPpkt.f2pkt.f1Const3-to-1 Muxpkt.f2xxx02-to-1 Muxx03-to-1 Mux2-to-1 Mux1. Packet transactions provide the ﬁrst transactional se-
mantics for line-rate packet processing. These seman-
tics make it easier to reason about correctness and
performance, but they exclude algorithms that cannot
run at line rate while respecting these semantics. Are
weaker semantics sensible? One possibility is approx-
imating transactional semantics by only processing a
sampled packet stream. This provides an increased
time budget for each packet in the sampled stream, po-
tentially allowing the packet to be recirculated through
the pipeline multiple times for packet processing.
2. Our compiler doesn’t aggressively optimize. For in-
stance, it is possible to fuse two stateful codelets in-
crementing two independent counters into the same in-
stance of the Pairs atom. However, by carrying out a
one-to-one mapping from codelets to the atoms imple-
menting them, our compiler precludes these optimiza-
tions. Developing an optimizing compiler for packet
transactions is an area for future work.
3. Supporting multiple packet transactions in Domino
also requires further work. When a switch exe-
cutes multiple transactions, there may be opportunities
for inter-procedural analysis [20], which goes beyond
compiling individual transactions and looks at multiple
transactions together. For instance, the compiler could
detect computations common to multiple transactions
and execute them only once.
4. Finally, we have a manual design process for atoms.
Formalizing this design process and automating it into
an atom-design tool would be useful for switch de-
signers. For instance, given a corpus of data-plane al-
gorithms, can we automatically mine this corpus for
stateful and stateless codelets, and design an atom
(or atoms) that captures the computations required by
some (or all) of them?
8. CONCLUSION
This paper presented Domino, a C-like imperative lan-
guage that allows programmers to write packet-processing
code using packet transactions, which are sequential code
blocks that are atomic and isolated from other such code
blocks. The Domino compiler compiles packet transac-
tions to hardware conﬁgurations for Banzai, which is a ma-
chine model based on programmable line-rate switch archi-
tectures [13, 19, 3]. Our results suggest that it is possible to
have both the convenience of a familiar programming model
and the performance of a line-rate switch, provided that the
algorithm can indeed run at line rate. Packet-processing lan-
guages are still in their infancy; we hope these results will
prompt further work on programming abstractions for high-
performance packet-processing hardware.
Acknowledgements
We thank our shepherd, Bruce Maggs, the anonymous SIG-
COMM reviewers, Amy Ousterhout, and Pratiksha Thaker
for their suggestions that improved the presentation of the
paper. This work was partly supported by NSF grants CNS-
1563826 and CNS-1563788. We thank the industrial part-
ners of the MIT Center for Wireless Networks and Mobile
Computing (Wireless@MIT) for their support.
9. REFERENCES
[1] 100G Data Planes, DP 6440, DP 6430 | Corsa Technology.
http://www.corsa.com/products/dp6440/.
[2] Arista - Arista 7050 Series.
https://www.arista.com/en/products/7050-series.
[3] Barefoot: The World’s Fastest and Most Programmable
Networks.
https://barefootnetworks.com/media/white_papers/Barefoot-
Worlds-Fastest-Most-Programmable-Networks.pdf.
[4] Cisco Nexus Family. http://www.cisco.com/c/en/us/
products/switches/cisco_nexus_family.html.
[5] Components of Linux Trafﬁc Control. http://tldp.org/
HOWTO/Trafﬁc-Control-HOWTO/components.html.
[6] Dell Force10. http://www.force10networks.com/.
[7] Design Compiler - Synopsys.
http://www.synopsys.com/Tools/Implementation/
RTLSynthesis/DesignCompiler/Pages/default.aspx.
[8] DPDK: Data Plane Development Kit. http://dpdk.org/.
[9] Flowlet Switching in P4. https://github.com/p4lang/tutorials/
tree/master/SIGCOMM_2015/ﬂowlet_switching.
[10] High Capacity StrataXGS®Trident II Ethernet Switch
Series. http://www.broadcom.com/products/Switching/Data-
Center/BCM56850-Series.
[11] High-Density 25/100 Gigabit Ethernet StrataXGS Tomahawk
Ethernet Switch Series. http://www.broadcom.com/products/
Switching/Data-Center/BCM56960-Series.
[12] Intel Enhances Network Processor Family with New
Software Tools and Expanded Performance.
http://www.intel.com/pressroom/archive/releases/2001/
20010220net.htm.
[13] Intel FlexPipe. http://www.intel.com/content/dam/www/
public/us/en/documents/product-briefs/ethernet-switch-
fm6000-series-brief.pdf.
[14] IXP4XX Product Line of Network Processors.
http://www.intel.com/content/www/us/en/intelligent-
systems/previous-generation/intel-ixp4xx-intel-network-
processor-product-line.html.
[15] LLVM Language Reference Manual - LLVM 3.8
documentation. http://llvm.org/docs/LangRef.html#abstract.
[16] Mellanox Products: SwitchX-2 Ethernet Optimized for SDN.
http://www.mellanox.com/page/
products_dyn?product_family=146&mtag=switchx_2_en.
[17] Sampled NetFlow. http://www.cisco.com/c/en/us/td/docs/
ios/12_0s/feature/guide/12s_sanf.html.
[18] Three-address code.
https://en.wikipedia.org/wiki/Three-address_code.
[19] XPliant™ Ethernet Switch Product Family.
http://www.cavium.com/XPliant-Ethernet-Switch-Product-
Family.html.
[20] A. V. Aho, R. Sethi, and J. D. Ullman. Compilers:
Principles, Techniques, and Tools. Addison-Wesley
Longman Publishing Co., Inc., Boston, MA, USA, 1986.
[21] M. Alizadeh, T. Edsall, S. Dharmapurikar, R. Vaidyanathan,
K. Chu, A. Fingerhut, V. T. Lam, F. Matus, R. Pan, N. Yadav,
and G. Varghese. CONGA: Distributed Congestion-Aware
Load Balancing for Datacenters. In SIGCOMM, 2014.
[22] M. Alizadeh, A. Kabbani, T. Edsall, B. Prabhakar, A. Vahdat,
and M. Yasuda. Less Is More: Trading a Little Bandwidth for
Ultra-Low Latency in the Data Center. In NSDI, 2012.
[23] J. R. Allen, K. Kennedy, C. Porterﬁeld, and J. Warren.
Conversion of Control Dependence to Data Dependence. In
POPL, 1983.
27
[24] M. T. Arashloo, Y. Karol, M. Greenberg, J. Rexford, and
D. Walker. SNAP: Stateful Network-Wide Abstractions for
Packet Processing. arXiv:1512.00822.
[25] H. Ballani, P. Costa, C. Gkantsidis, M. P. Grosvenor,
T. Karagiannis, L. Koromilas, and G. O’Shea. Enabling
End-Host Network Functions. In SIGCOMM, 2015.
[26] L. Bilge, E. Kirda, C. Kruegel, and M. Balduzzi.
EXPOSURE: Finding Malicious Domains Using Passive
DNS Analysis. In NDSS, 2011.
[27] P. Bosshart, D. Daly, G. Gibb, M. Izzard, N. McKeown,
J. Rexford, C. Schlesinger, D. Talayco, A. Vahdat,
G. Varghese, and D. Walker. P4: Programming
Protocol-Independent Packet Processors. SIGCOMM CCR,
July 2014.
[28] P. Bosshart, G. Gibb, H.-S. Kim, G. Varghese, N. McKeown,
M. Izzard, F. Mujica, and M. Horowitz. Forwarding
Metamorphosis: Fast Programmable Match-action
Processing in Hardware for SDN. In SIGCOMM, 2013.
[29] A. Cheung, A. Solar-Lezama, and S. Madden. Using
Program Synthesis for Social Recommendations. In CIKM,
2012.
[30] A. Cheung, A. Solar-Lezama, and S. Madden. Optimizing
Database-backed Applications with Query Synthesis. In
PLDI, 2013.
[31] G. Cormode and S. Muthukrishnan. An Improved Data
Stream Summary: The Count-Min Sketch and Its
Applications. Journal of Algorithms, April 2005.
[32] R. Cytron, J. Ferrante, B. K. Rosen, M. N. Wegman, and
F. K. Zadeck. Efﬁciently Computing Static Single
Assignment Form and the Control Dependence Graph. ACM
Transactions on Programming Language Systems, 1991.
[33] J. Dai, B. Huang, L. Li, and L. Harrison. Automatically
Partitioning Packet Processing Applications for Pipelined
Architectures. In PLDI, 2005.
[34] M. Dobrescu, K. Argyraki, and S. Ratnasamy. Toward
Predictable Performance in Software Packet-Processing
Platforms. In NSDI, 2012.
[35] M. Dobrescu, N. Egi, K. Argyraki, B.-G. Chun, K. Fall,
G. Iannaccone, A. Knies, M. Manesh, and S. Ratnasamy.
RouteBricks: Exploiting Parallelism to Scale Software
Routers. In SOSP, 2009.
[36] R. Duncan and P. Jungck. packetC Language for High
Performance Packet Processing. In 11th IEEE International
Conference on High Performance Computing and
Communications, 2009.
[37] C. Estan, G. Varghese, and M. Fisk. Bitmap Algorithms for
Counting Active Flows on High-speed Links. IEEE/ACM
Trans. Netw., Oct. 2006.
[38] S. Floyd and V. Jacobson. Random Early Detection
Gateways for Congestion Avoidance. IEEE/ACM Trans.
Netw., Aug. 1993.
[39] N. Foster, R. Harrison, M. J. Freedman, C. Monsanto,
J. Rexford, A. Story, and D. Walker. Frenetic: A Network
Programming Language. In ICFP, 2011.
[40] G. Gibb, G. Varghese, M. Horowitz, and N. McKeown.
Design Principles for Packet Parsers. In ANCS, 2013.
[41] A. Greenberg, J. R. Hamilton, N. Jain, S. Kandula, C. Kim,
P. Lahiri, D. A. Maltz, P. Patel, and S. Sengupta. VL2: A
Scalable and Flexible Data Center Network. In SIGCOMM,
2009.
[42] V. Jeyakumar, M. Alizadeh, Y. Geng, C. Kim, and
D. Mazières. Millions of Little Minions: Using Packets for
Low Latency Network Programming and Visibility. In
28
SIGCOMM, 2014.
[43] L. Jose, L. Yan, G. Varghese, and N. McKeown. Compiling
Packet Programs to Reconﬁgurable Switches. In NSDI, 2015.
[44] N. Kang, Z. Liu, J. Rexford, and D. Walker. Optimizing the
"One Big Switch" Abstraction in Software-deﬁned
Networks. In CoNEXT, 2013.
[45] D. Katabi, M. Handley, and C. Rohrs. Congestion Control
for High Bandwidth-Delay Product Networks. In
SIGCOMM, 2002.
[46] E. Kohler, R. Morris, B. Chen, J. Jannotti, and M. F.
Kaashoek. The Click Modular Router. ACM Trans. Comput.
Syst., 2000.
[47] S. S. Kunniyur and R. Srikant. An Adaptive Virtual Queue
(AVQ) Algorithm for Active Queue Management.
IEEE/ACM Trans. Netw., Apr. 2004.
[48] M. Lam. Software Pipelining: An Effective Scheduling
Technique for VLIW Machines. In PLDI, 1988.
[49] G. D. Micheli. Synthesis and Optimization of Digital
Circuits. McGraw-Hill Higher Education, 1st edition, 1994.
[50] M. Moshref, A. Bhargava, A. Gupta, M. Yu, and
R. Govindan. Flow-level State Transition As a New Switch
Primitive for SDN. In SIGCOMM, 2014.
[51] K. Nichols and V. Jacobson. Controlling Queue Delay. ACM
Queue, 10(5), May 2012.
[52] S. Palkar, C. Lan, S. Han, K. Jang, A. Panda, S. Ratnasamy,
L. Rizzo, and S. Shenker. E2: A Framework for NFV
Applications. In SOSP, 2015.
[53] P. M. Phothilimthana, T. Jelvis, R. Shah, N. Totla,
S. Chasins, and R. Bodik. Chlorophyll: Synthesis-aided
Compiler for Low-power Spatial Architectures. In PLDI,
pages 396–407, 2014.
[54] A. Roy, H. Zeng, J. Bagga, G. Porter, and A. C. Snoeren.
Inside the Social Network’s (Datacenter) Network. In
SIGCOMM, 2015.
[55] M. Shahbaz and N. Feamster. The Case for an Intermediate
Representation for Programmable Data Planes. In SOSR,
pages 3:1–3:6, 2015.
[56] A. Singh, J. Ong, A. Agarwal, G. Anderson, A. Armistead,
R. Bannon, S. Boving, G. Desai, B. Felderman, P. Germano,
A. Kanagala, J. Provost, J. Simmons, E. Tanda, J. Wanderer,
U. Hölzle, S. Stuart, and A. Vahdat. Jupiter Rising: A
Decade of Clos Topologies and Centralized Control in
Google’s Datacenter Network. In SIGCOMM, 2015.
[57] S. Sinha, S. Kandula, and D. Katabi. Harnessing TCPs
Burstiness using Flowlet Switching. In HotNets, 2004.
[58] A. Sivaraman, S. Subramanian, M. Alizadeh, S. Chole, S.-T.
Chuang, A. Agrawal, H. Balakrishnan, T. Edsall, S. Katti,
and N. McKeown. Programmable Packet Scheduling at Line
Rate. In SIGCOMM, 2016.
[59] A. Solar-Lezama, L. Tancau, R. Bodik, S. Seshia, and
V. Saraswat. Combinatorial Sketching for Finite Programs.
In ASPLOS, 2006.
[60] C. Tai, J. Zhu, and N. Dukkipati. Making Large Scale
Deployment of RCP Practical for Real Networks. In
INFOCOM, 2008.
[61] D. L. Tennenhouse and D. J. Wetherall. Towards an Active
Network Architecture. In DARPA Active Networks
Conference and Exposition, 2002.
[62] A. Voellmy, J. Wang, Y. R. Yang, B. Ford, and P. Hudak.
Maple: Simplifying SDN Programming Using Algorithmic
Policies. In SIGCOMM, 2013.
[63] M. Yu, L. Jose, and R. Miao. Software Deﬁned Trafﬁc
Measurement with OpenSketch. In NSDI, 2013.