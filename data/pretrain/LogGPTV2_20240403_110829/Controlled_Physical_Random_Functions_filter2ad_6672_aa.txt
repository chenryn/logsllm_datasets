title:Controlled Physical Random Functions
author:Blaise Gassend and
Dwaine E. Clarke and
Marten van Dijk and
Srinivas Devadas
Controlled Physical Random Functions ∗
† 
Blaise Gassend, Dwaine Clarke, Marten van Dijk 
and Srinivas Devadas
Massachusetts Institute of Technology
Laboratory for Computer Science
Cambridge, MA 02139, USA
{gassend,declarke,marten,devadas}@mit.edu
Abstract
A Physical Random Function (PUF) is a random func-
tion that can only be evaluated with the help of a complex
physical system. We introduce Controlled Physical Random
Functions (CPUFs) which are PUFs that can only be ac-
cessed via an algorithm that is physically bound to the PUF
in an inseparable way.
CPUFs can be used to establish a shared secret between
a physical device and a remote user. We present protocols
that make this possible in a secure and ﬂexible way, even in
the case of multiple mutually mistrusting parties.
Once established, the shared secret can be used to en-
able a wide range of applications. We describe certiﬁed
execution, where a certiﬁcate is produced that proves that a
speciﬁc computation was carried out on a speciﬁc proces-
sor. Certiﬁed execution has many beneﬁts, including pro-
tection against malicious nodes in distributed computation
networks. We also brieﬂy discuss a software licensing ap-
plication.
1. Introduction
A Physical Random Function (PUF) is a random func-
tion that can only be evaluated with the help of a complex
physical system. PUFs can be implemented in different
ways and can be used in authenticated identiﬁcation appli-
cations [GCvDD02, Rav01].
In this paper, we introduce
Controlled Physical Random Functions (CPUFs) which are
PUFs that can only be accessed via an algorithm that is
physically bound to the PUF in an inseparable way.
PUFs and controlled PUFs enable a host of applications,
including smartcard identiﬁcation, certiﬁed execution and
∗
†
This work was funded by Acer Inc., Delta Electronics Inc., HP Corp.,
NTT Inc., Nokia Research Center, and Philips Research under the MIT
Project Oxygen partnership.
Visiting researcher from Philips Research, Prof Holstlaan 4, Eind-
hoven, The Netherlands.
software licensing. In current smartcards, it is possible for
someone who is in possession of a smartcard to produce a
clone of it, by extracting its digital key information through
one of many well documented attacks [And01]. With a
unique PUF on the smartcard that can be used to authen-
ticate the chip, a digital key is not required: the smartcard
hardware is itself the secret key. This key cannot be du-
plicated, so a person can lose control of it, retrieve it, and
continue using it.
Certiﬁed execution produces a certiﬁcate which proves
that a speciﬁc computation was carried out on a speciﬁc
processor chip, and that the computation produced a given
result. The person requesting the computation can then rely
on the trustworthiness of the chip manufacturer who can
vouch that he produced the chip, instead of relying on the
owner of the chip, who could make up the result without
actually executing the computation.1 Certiﬁed execution is
very useful in grid computing (e.g., SETI@home) and other
forms of distributed computation to protect against mali-
cious volunteers. In fact, certiﬁed execution can enable a
business model for anonymous computing, wherein com-
putation can be sold by individuals and the customer can be
ensured reliability of service, via the generation of certiﬁ-
cates.
Controlled PUFs can also be used to ensure that a piece
of code only runs on a processor chip that has a speciﬁc
identity deﬁned by a PUF. In this way, pirated code would
fail to run.
In Section 2 we deﬁne PUFs and CPUFs. The reader
who is not interested in PUF or CPUF implementations can
then skip to Section 4. A possible implementation of PUFs
and controlled PUFs on silicon integrated circuits is the sub-
ject of Section 3. Then in Section 4, we describe our model
for using controlled PUFs. Section 5 describes a man-in-
the-middle attack, and the protocols that protect a CPUF
1Many software methods have been devised to get around this, but they
generally involve performing extra computation. We believe that these
methods are only justiﬁed until a satisfactory hardware solution becomes
widely available.
Proceedings of the 18th Annual Computer Security Applications Conference (ACSAC(cid:146)02) 
1063-9527/02 $17.00 ' 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:32:29 UTC from IEEE Xplore.  Restrictions apply. 
from it. Finally, in Section 6, we describe how controlled
PUFs can be applied to authentication and certiﬁed execu-
tion problems, and brieﬂy describe a software licensing ap-
plication.
2. Deﬁnitions
Deﬁnition 1 A Physical Random Function (PUF)2 is a
function that maps challenges to responses, that is embod-
ied by a physical device, and that veriﬁes the following
properties:
1. Easy to evaluate: The physical device is easily capable
of evaluating the function in a short amount of time.
2. Hard to characterize: From a polynomial number of
plausible physical measurements (in particular, deter-
mination of chosen challenge-response pairs), an at-
tacker who no longer has the device, and who can only
use a polynomial amount of resources (time, matter,
etc...) can only extract a negligible amount of infor-
mation about the response to a randomly chosen chal-
lenge.
In the above deﬁnition, the terms short and polynomial
are relative to the size of the device, which is the security
parameter. In particular, short means linear or low degree
polynomial. The term plausible is relative to the current
state of the art in measurement techniques and is likely to
change as improved methods are devised.
In previous literature [Rav01] PUFs were referred to
as Physical One Way Functions, and realized using 3-
dimensional micro-structures and coherent radiation. We
believe this terminology to be confusing because PUFs
do not match the standard meaning of one way functions
[MvOV96].
Deﬁnition 2 A PUF is said to be Controlled if it can only
be accessed via an algorithm that is physically linked to the
PUF in an inseparable way (i.e., any attempt to circumvent
the algorithm will lead to the destruction of the PUF). In
particular this algorithm can restrict the challenges that are
presented to the PUF and can limit the information about
responses that is given to the outside world.
The deﬁnition of control is quite strong. In practice, link-
ing the PUF to the algorithm in an inseparable way is far
form trivial. However, we believe that it is much easier to
do than to link a conventional secret key to an algorithm
in an inseparable way, which is what current smartcards at-
tempt.
2PUF actually stands for Physical Unclonable Function. It has the ad-
vantage of being easier to pronounce, and it avoids confusion with Pseudo-
Random Functions.
Control turns out to be the fundamental idea that allows
PUFs to go beyond simple authenticated identiﬁcation ap-
plications. How this is done is the main focus of this paper.
Deﬁnition 3 A type of PUF is said to be Manufacturer Re-
sistant if it is technically impossible to produce two iden-
tical PUFs of this type given only a polynomial amount of
resources.
Manufacturer resistant PUFs are the most interesting
form of PUF as they can be used to make unclonable sys-
tems.
3. Implementing a Controlled Physical Ran-
dom Function
In this section, we describe ways in which PUFs and
CPUFs could be implemented. In each case, a silicon IC
enforces the control on the PUF.
3.1. Digital PUF
It is possible to produce a PUF with classical crypto-
graphic primitives provided a key can be kept secret. If an
IC is equipped with a secret key k, and a pseudo-random
hash function h, and tamper resistant technology is used to
make k impossible to extract from the IC, then the function
x → h(k, x)
is a PUF. If control logic is embedded on the tamper resis-
tant IC along with the PUF, then we have effectively created
a CPUF.
However, this kind of CPUF is not very satisfactory.
First, it requires high quality tamper-prooﬁng. There are
systems available to provide such tamper-resistance. For
example, IBM’s PCI Cryptographic Coprocessor, encap-
sulates a 486-class processing subsystem within a tamper-
sensing and tamper-responding environment where one can
run security-sensitive processes [SW99]. Smart cards also
incorporate barriers to protect the hidden key(s), many of
which have been broken [And01]. In general, however, ef-
fective tamper resistant packages are expensive and bulky.
Secondly, the digital PUF is not manufacturer resistant.
The PUF manufacturer is free to produce multiple ICs with
the same secret key, or someone who manages to violate
the IC’s tamper-resistant packaging and extract the secret
key can easily produce a clone of the PUF.
Because of these two weaknesses, a digital PUF does not
offer any security advantage over storing a key in digital
form, and it is therefore better to use a conventional key
storage system.
Proceedings of the 18th Annual Computer Security Applications Conference (ACSAC(cid:146)02) 
1063-9527/02 $17.00 ' 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:32:29 UTC from IEEE Xplore.  Restrictions apply. 
3.2. Silicon PUF
3.2.1. Statistical Variation of Delay
By exploiting statistical variations in the delays of devices
(gates and wires) within the IC, we can create a manufac-
turer resistant PUF [GCvDD02]. Manufactured IC’s, from
either the same lot or wafer have inherent delay variations.
There are random variations in dies across a wafer, and from
wafer to wafer due to, for instance, process temperature and
pressure variations, during the various manufacturing steps.
The magnitude of delay variation due to this random com-
ponent can be 5% or more.
On-chip measurement of delays can be carried out with
very high accuracy, and therefore the signal-to-noise ratio
when delays of corresponding wires across two or more IC’s
are compared is quite high. The delays of the set of devices
in a circuit is unique across multiple IC’s implementing the
same circuit with very high probability, if the set of devices
is large [GCvDD02]. These delays correspond to an im-
plicit hidden key, as opposed to the explicitly hidden key
in a digital PUF. While environmental variations can cause
changes in the delays of devices, relative measurement of
delays, essentially using delay ratios, provides robustness
against environmental variations, such as varying ambient
temperature, and power supply variations.
3.2.2. Challenge-Response Pairs
Given a PUF, challenge-response pairs can be generated,
where the challenge can be a digital input stimulus, and the
response depends on the transient behavior of the PUF. For
instance, we can combine a number of challenge dependent
delay measures into a digital response. The number of po-
tential challenges grows exponentially with the number of
inputs to the IC. Therefore, while two IC’s may have a high
probability of having the same response to a particular chal-
lenge, if we apply enough challenges, we can distinguish
between the two IC’s.
3.2.3. Attacks on Silicon PUFs
There are many possible attacks on manufacturer resistant
PUF’s – duplication, model building using direct measure-
ment, and model building using adaptively-chosen chal-
lenge generation. We brieﬂy discuss these and show that
signiﬁcant barriers exist for each of these attacks. A more
detailed description can be found in [GCvDD02].
The adversary can attempt to duplicate a PUF by fabri-
cating a counterfeit IC containing the PUF. However, due
to statistical variation, unless the PUF is very simple, the
adversary will have to fabricate a huge number of IC’s and
precisely characterize each one, in order to create and dis-
cover a counterfeit.
Assume that the adversary has unrestricted access to the
IC containing the PUF. The adversary can attempt to create
a model of the IC by measuring or otherwise determining
very precisely the delays of each device and wire within
the IC. Direct measurement of device delays requires the
adversary to open the package of the IC, and remove several
layers, such as ﬁeld oxide and metal. One can also create a
package which has a signiﬁcant effect on the delays of each
device within the IC, and the removal of the package will
immediately destroy the PUF, since the delays will change
appreciably.
The adversary could try to build a model of the PUF by
measuring the response of the PUF to a polynomial number
of adaptively-chosen challenges.3 We believe this to be the
most plausible form of attack. However, there is a signiﬁ-
cant barrier to this form of attack as well because creating
timing models of a circuit accurate to within measurement
error is a very difﬁcult problem that has received a lot of at-
tention from the simulation community. Manageable-sized
timing models can be produced which are within 10% of
the real delays, but not within the measurement accuracy of
≈ 0.1%.
In addition to attacking the PUF directly, the adversary
can attempt to violate a CPUF’s control. This includes try-
ing to get direct access to the PUF, or trying to violate the
control algorithm (which includes the private and authenti-
cated execution environment that we will be discussing in
Section 5). The best way we have found to prevent this at-
tack is for the algorithm (i.e., the digital part of the IC) to be
embedded within the physical system that deﬁnes the PUF.
In the Silicon PUF case, this can be accomplished by over-
laying PUF delay wires over any digital circuitry that needs
to be protected. Damaging any one of those wires would
change the PUF, rendering the adversary’s attack useless.
This strategy obviates the need for active intrusion sensors
that are present in conventional secure devices to destroy
key material in the event that an invasive attack occurs. For
non invasive attacks such as irradiating the IC or making
it undergo voltage spikes and clock glitches, conventional
prevention methods must be used.
3.3. Improving a PUF Using Control
Using control, it is possible to make a silicon PUF more
robust and reliable. Figure 1 summarizes the control that
can be placed around the PUF to improve it. The full details
of these improvements can be found in [GCvDD02].
A random hash function placed before the PUF prevents
the adversary from performing a chosen challenge attack on
the PUF. This prevents a model-building adversary from se-
lecting challenges that allow him to extract parameters more
3Clearly, a model can be built by exhaustively enumerating all possible
challenges, but this is intractable.
Proceedings of the 18th Annual Computer Security Applications Conference (ACSAC(cid:146)02) 
1063-9527/02 $17.00 ' 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:32:29 UTC from IEEE Xplore.  Restrictions apply. 
Improved PUF
ID