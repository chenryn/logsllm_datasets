• Enumerate known strings used in attacks. For ex-
ample, HTML tags like  or attributes such as
onerror allow the user to execute JavaScript with a single
HTML injection. The ModSecurity Core Rule Set version
3.0 is, at the time of writing, one of the most comprehensive
lists of attack vectors.
• Detect characters used to escape from the contexts
where XSS vulnerabilities usually occur. For example,
if an XSS vulnerability existed by directly injecting HTML
where the application expected to just output text, a request
(cid:27)ltering mitigation will attempt to detect the injection of
. If the vulnerability is present when injecting inside
an HTML attribute, escaping from the attribute would be
detected as the vulnerability.
• Detect patterns and sequences frequently used in ex-
ploits. For example, when an XSS attack is succesful, the
user will often attempt to steal credentials, or issue HTTP
requests. Therefore, some mitigations attempt to detect ac-
cess to document.cookie, or access to XMLHTTPRequest.
They also attempt to detect usual mechanisms to obfuscate
code execution, like references to eval or innerHTML, even
after doing several layers of agressive decoding.
Examples of XSS mitigations that adopt these approaches are:
• NoScript XSS Filter
• Web Application Firewalls
Request (cid:27)ltering mitigations detect only speci(cid:27)c, XSS-related
HTML tags and attributes. Gadgets use HTML tags and attributes
that are considered benign, and that makes them capable of bypass-
ing such mitigations. For example, if a library takes the value of the
data-html attribute and executes it as HTML, mitigations in this
group would not be able to detect that as malicious. An example of
HTML markup triggering such gadget chain was shown in Listing
11.
In addition, detection of context-breaking characters suddenly
becomes ine(cid:29)ective because some gadgets change the meaning
of otherwise-safe text sequences, and make them dangerous. For
example, in AngularJS the use of two curly braces {{ is a way to
de(cid:27)ne the beginning of an AngularJS expression. Aurelia, in turn,
uses a di(cid:29)erent delimiter: ${. An example of such seemingly-benign
markup was shown in Listing 9.
Session H2:  Code Reuse AttacksCCS’17, October 30-November 3, 2017, Dallas, TX, USA1715
"
name="javascript:alert(1)">
Listing 13: Example of bypassing NoScript with Knockout
gadget
A good example of how to bypass request (cid:27)ltering mitigations
like NoScript with gadgets is presented in Listing 13. In this exam-
ple the expressiveness of the framework is used to split an exploit
such as location.href=name (which is detected as an attack by
NoScript as the global name property can generally be set by an
attacker to arbitrary content), into two components. a=location
followed by a.href=name. Individually, these expressions are harm-
less, but together they allow the user to redirect the user to a
JavaScript URL speci(cid:27)ed in the name attribute. NoScript is not able
to parse the markup to (cid:27)gure out that they are both meant to be
executed together.
4.3 Bypassing Response Sanitization
Mitigations
Response sanitization mitigations are designed to reduce the num-
ber of false positive results that are potentially generated by re-
quest (cid:27)ltering. Instead of blocking potentially malicious requests,
response sanitization mitigations aim to detect whether a suspicious
payload actually gets injected into the response.
Response sanitization mitigations usually follow one of two
di(cid:29)erent techniques:
• Remove or neuter the malicious attack. One possible
way to tackle the potential injection of code is to neuter
it, or remove it from the HTTP response. In this approach,
the rest of the response is left as-is, but the suspicious code
is removed or made inert.
• Block the response completely. Another possible way
to react to an injection attempt is to completely block the
response, and display an error to the user. This approach
avoids cases in which an attacker tricks a mitigation tech-
nique into blocking a legitimate script (e.g. a frame buster).
Examples of implementations of XSS mitigations that adopt these
types of approaches are:
• HTML sanitizers. Most HTML sanitizers work by taking
a piece of HTML code and cleaning it of any malicious
input, and returning otherwise safe HTML. Most HTML
sanitizers, however, are based on whitelists that try to enu-
merate safe HTML tags and attributes across all browsers.
• Internet Explorer / Edge XSS (cid:27)lter. The XSS (cid:27)lter in
Microsoft Internet Explorer and Edge also sanitizes HTML
by replacing parts of HTML attributes and tag names with
a pound # symbol. Note that while HTML sanitizers use
whitelists, XSS (cid:27)lters on the other hand work on a black-
listing approach, enumerating dangerous HTML tags and
attributes known by the browser.
Bypassing HTML sanitizers usually requires a slightly di(cid:29)erent
approach than bypassing XSS (cid:27)lters. For HTML sanitizers, the
gadgets must reuse an otherwise safe and whitelisted attribute,
such as class or id. Gadgets that bypass XSS (cid:27)lters can also use
custom HTML tags and attributes such as ng-click in Angular or
v-html in Vue.
Given that mitigations based on response sanitization only block
vulnerabilities, but make no attempts at detecting artifacts of ex-
ploits, this makes them easier to bypass, since gadgets are by de(cid:27)-
nition "safe" code that becomes unsafe when it interacts with other
JavaScript code that is otherwise safe. Aiming to lower the false
positive rate by using response sanitization has the downside of not
being able to detect attacks that exploit features that are normally
safe when the JavaScript library is not used.
&lt;script&gt;alert(1)&lt;/script&gt;’>
Listing 14: Example of bypassing DOMPurify with jQuery
Mobile gadget
An example on how to use gadgets to bypass response sani-
tization mitigations is presented in listing 14. As far as DOMPu-
rify is aware, the HTML it sanitized is completely safe. However,
jQuery Mobile, upon encountering an element with the attribute
data-role=popup, will automatically try to inject an HTML com-
ment with its id. In the code above, we can escape from that com-
ment and execute our code. Note that the same attack works against
Internet Explorer’s XSS (cid:27)lter.
4.4 Bypassing Code Filtering Mitigations
Code (cid:27)ltering mitigations are an evolution on top of response sani-
tization. They attempt to leave the potentially malicious markup
untouched, and instead focus on preventing the execution of mali-
cious code. This approach has even lower false positive rate than
sanitization, since the code is (cid:27)ltered out only if it’s actually about
to be executed.
However, one side-e(cid:29)ect of such an approach is that since gad-
gets do not directly execute any malicious code, but do so indirectly
through trusted code, it is a lot harder for XSS mitigations based
on code (cid:27)ltering to detect injections using gadgets.
The approaches taken by XSS mitigations based on code (cid:27)ltering
are:
• Detect malicious code. To detect whether a speci(cid:27)c piece
of code is malicious, it is checked against the HTTP request.
If the code to be executed is also present in the request,
it is blocked as not trustworthy and potentially attacker-
controlled.
• Detect benign code. Benign code passes various policy
checks based on code provenance, content, or generation
method. Code violating the policy requirements is consid-
ered malicious and its execution is blocked.
Examples of implementations of XSS mitigations that adopt this
approach are:
Session H2:  Code Reuse AttacksCCS’17, October 30-November 3, 2017, Dallas, TX, USA1716• Chrome and Safari’s XSS Auditor. The latest XSS (cid:27)lter
to be implemented in a major browser was Chrome and Sa-
fari’s XSS Auditor. The XSS Auditor hooks into JavaScript
runtime in the browser. XSS Auditor uses the ’detect mali-
cious code’ approach - before Auditor permits code exe-
cution, it validates that the code was not included in the
HTTP request, and blocks it if it was.
• Content Security Policy. Content Security Policy [34]
is the most popular example of code-(cid:27)ltering mitigation.
Web applications using this mitigation de(cid:27)ne a policy that
speci(cid:27)es which scripts are benign and should be allowed
to execute. Scripts violating the policy are blocked by the
supporting browser. Existing policies usually adopt one
the (cid:27)ltering variants described in Section 4.1.1. A typical
policy is either URL whitelist-based or nonce/hash-based. A
policy may also use strict-dynamic and/or unsafe-eval
source expressions. These keywords propagate trust to
additional code created by already trusted scripts, making
CSP easier to adopt on existing websites.
Code (cid:27)ltering mitigations hook on code execution and aim to
assure only legitimate code gets executed. Since script gadgets are
already part of a legitimate code base they are extremely useful in
bypassing this mitigation group. In the analysis performed against
popular frameworks and libraries in section 4.1, we found that code
(cid:27)ltering mitigations are the ones most vulnerable to gadgets. We
used element construction gadgets (3.5.2), JavaScript execution sink
gadgets (3.5.4) and gadgets in expression parsers (3.5.5) to bypass
code (cid:27)ltering mitigations. While we found that expression-parser-
based gadgets were the most universally applicable, some bypass
methods employed were mitigation-variant speci(cid:27)c:
Bypassing XSS Auditor. We bypassed XSS Auditor in 13 out
of 16 frameworks, as many gadgets use traditional DOM XSS [16]
sinks, DOM XSS protection being a known shortcoming of XSS
Auditor [32]. For example, a gadget in the Dojo framework calls an
eval function, with the value extracted from the data-dojo-props
attribute. This allowed us to create the following bypass:
Listing 15: Example of bypassing XSS Auditor with Dojo gad-
get
Bypassing unsafe-eval CSP. In order to bypass CSP with an
unsafe-eval keyword we either used gadgets in expression parsers
or gadgets calling an eval-like function. Listing 15 demonstrates
a bypass using such gadget. We were able to circumvent policies
using unsafe-eval in 10 out of 16 frameworks.
Bypassing strict-dynamic CSP. Adding a strict-dynamic
keyword to the CSP enables already trusted code to programmati-
cally create new script elements. When such scripts are introduced
into the DOM, they are implicitly trusted and allowed to execute.
We found that most analyzed JavaScript frameworks contain gad-
gets capable of creating and inserting script elements with con-
trolled body or src attribute. Such gadgets can be used to bypass
strict-dynamic CSP. As an example, we present the bypass found
in RequireJS:
Listing 16: Example of bypassing strict-dynamic with Re-
quireJS gadget
Since the  tag has a data-main attribute, a gadget in
RequireJS will generate a new script element, with its source
pointing to data:,alert(1). As RequireJS is already trusted,
strict-dynamic propagates this trust to the new element, and
the code will execute, bypassing the page’s Content Security Policy.
We found strict-dynamic bypasses in 13 out of 16 tested frame-
works (two of the bypasses relied on co-presence of unsafe-eval).
The prevalence of script gadgets in the tested JavaScript frame-
works suggests that using the strict-dynamic variant of CSP to
mitigate XSS vulnerabilities in modern web applications is less
e(cid:29)ective than previously thought [35].
Bypassing other CSP variants. Both aforementioned CSP key-
words relax the restrictions of the policy in order to facilitate its
adoption. Some websites opt to use a stronger version of CSP, e.g.
relying solely on nonces, or using a whitelist of script source URLs,
with no known bypasses in the list of allowed origins [35]. We found
that even such variants of Content Security Policy can be bypassed
using script gadgets in expression parsers (3.5.5). In some frame-
works, expression parsers themselves create a runtime environment
that allows the attacker to obtain a window object reference and call
arbitrary JavaScript functions. Such vectors do not use eval and do
not create new script elements, so Content Security Policy cannot
detect and block them. Listings 11 and 12 present examples for this
type of bypasses. Such gadgets were found in Aurelia, Vue.js and
Polymer 1.x. Additionally, in Ractive we found a gadget capable of
ex(cid:27)ltrating the CSP nonce into a newly created script, allowing for
its execution, despite a strong, only nonce-based policy:
alert(document.domain)
’>
Listing 17: Bypass ex(cid:27)ltrating CSP nonce in Ractive
It’s worth noting that the success of CSP mitigation depends on
the used variant. If the policy is con(cid:27)gured to use whitelists, hashes,
or nonces alone, then only gadgets in expression parsers (3.5.5) are
useful, as the code passed to JavaScript execution sinks (3.5.4) would
not be trusted. A notable exception is strict-dynamic, which
Session H2:  Code Reuse AttacksCCS’17, October 30-November 3, 2017, Dallas, TX, USA1717propagates trust to  tags generated programmatically.
Attackers may bypass such CSP with gadgets generating arbitrary
HTML elements, or importing nodes from foreign DOM documents.
Such gadgets are common in templating libraries.
As we have presented above, the gadgets used to bypass di(cid:29)erent
mitigations vary signi(cid:27)cantly from mitigation to mitigation. Some
abuse the expression language in libraries, others inject markup
in a text attribute, while others abuse trust propagation in DOM
element creation. This indicates which type of gadgets to search
for to bypass di(cid:29)erent types of mitigations.
5 PREVALENCE OF SCRIPT GADGETS
In this section we present the results of an empirical study on the
prevalence of script gadgets in real-world applications. We (cid:27)rst
present our research questions and methodology, then discuss the
results.
5.1 Research Statement
As shown above, script gadgets have the potential to undermine
the protections provided by XSS mitigations. While we manually
discovered many of these gadgets in popular libraries, it is important
to understand the prevalence of these code patterns at scale. If
gadgets are rare in real-world code, we can address the problem by
taking special care when building generic libraries. If script gadgets
are wide-spread in real-world applications however, addressing this
problem might be as hard as (cid:27)xing XSS itself. Therefore, the goal
of this study is to measure the prevalence of gadgets in real-world
applications.
After measuring gadget pervasiveness, we aim to (cid:27)nd out more
about the impact of script gadgets on speci(cid:27)c XSS mitigations.
Speci(cid:27)cally, we would like to focus on the Content Security Policy
and HTML sanitizers as these mitigation techniques seem to be the
most robust and relevant ones.
A previous study [35] has already demonstrated that the do-
main whitelisting and the ’unsafe-inline’ CSP source expres-
sion harm the protection capabilities of CSP. In this study, we’d like
to investigate the ’unsafe-eval’ and ’strict-dynamic’ source
expressions. Speci(cid:27)cally, we want to investigate how prevalent
script gadgets are that can potentially bypass these expressions.
Many sanitizers, by default, allow seemingly benign attributes
such as data-*, id or class. Furthermore, sanitizers usually allow
non-malicious tags such as div or span tags. Hence, we’d like to
understand how many real-world gadget chains can be triggered
from such tags and attributes.
5.2 Methodology
In order to detect gadgets in real-world applications, we built a
toolchain to automatically detect and verify them at scale. Based
on this toolchain, we crawled the Alexa Top 5000 Web sites.
Detecting Gadgets at Scale. As we did not expect to see many ex-
pression parsers (see 3.5.5) present in user-land code (assuming that
expression parsers are mostly present in JavaScript frameworks),
we decided to focus on gadgets that end in HTML, JavaScript or URL
execution sinks (see 3.5.4). In order to detect such potential gadgets,
we built a browser-based, dynamic taint tracking engine. The engine
is capable of reporting data (cid:30)ows from DOM nodes into security
sensitive functions such as eval, innerHTML, document.write, or
XMLHttpRequest.open()18. We used this engine to crawl our data
set and identify all data (cid:30)ows. Each of these (cid:30)ows represents a
potentially exploitable gadget chain.
Verifying Gadgets. In order to verify whether a found (cid:30)ow is
exploitable from benign HTML markup, we built a generator that
is capable of creating a real-world exploit based on each (cid:30)ow. The
generator is similar to the one presented in [17]. Subsequently, we
simulate a re(cid:30)ected XSS vulnerability in the page, into which we
inject the generated exploit. The goal of the exploit is to indirectly
execute a JavaScript function from a source that would not usually
execute such code (e.g. from a data- attribute). Listing 18 shows
an exemplary gadget that might exist in a legitimate JavaScript (cid:27)le.
Listing 18: An exemplary gadget
For this sample, the engine detects a data (cid:30)ow originating from
button.getAttribute(’data-text’) that ends up in the HTML
execution sink innerHTML. Based on the context of the sink (HTML,
JavaScript, URL), the exploit generator generates an exploit that
triggers JavaScript execution within this context:
Listing 19: XSS payload
Subsequently, we use the source element to generate the (cid:27)nal
exploit as shown in Listing 20. The actual XSS payload can thereby
be disguised via the use of di(cid:29)erent encoding schemes (depending
on the injection context).
Listing 20: Final Exploit
This lets us build the exploits in a way that our veri(cid:27)er function
does not trigger by default. This function is called only if a script
gadget reads the payload from benign markup and executes it.
Therefore, if the function gets called, we have veri(cid:27)ed the gadget
in a false-positive-free way.
18In total the engine supports 60+ sinks, which we cannot easily list due to space
constraints
Session H2:  Code Reuse AttacksCCS’17, October 30-November 3, 2017, Dallas, TX, USA1718Crawling The Data Set. Our initial seed data set consists of the
Alexa Top 5000 Web sites. We crawled these pages and also vis-
ited all the http: and https: links from these pages that point
to the same domain or a subdomain. This approach might bias
the data set, since Web pages with more links on the start pages
will be over-represented in the (cid:27)nal data set. The same is true for
subdomains: Some Web sites make excessive use of subdomains,
while others are not using them at all. Because of this, we decided
to deduplicate our (cid:27)nal results based on the (cid:27)rst domain before
the top level domain (subsequently called "second level domains").
E.g. we merge results from sub.example.co.uk, example.co.uk
and foo.example.co.uk and just regard all of these domains as
belonging to example.co.uk. We are aware that this approach has
a signi(cid:27)cant impact on the (cid:27)nal results, but we think that this
provides the most realistic view on the data.
5.3 Limitations
Our testing and veri(cid:27)cation approach has the following limitations:
Only (cid:27)rst level links: We only followed the (cid:27)rst-level of links,
so our data set does not cover all the pages of a site.