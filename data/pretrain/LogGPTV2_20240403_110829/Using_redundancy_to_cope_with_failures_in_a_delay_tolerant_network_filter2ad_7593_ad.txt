8
rithm
0.4% 0.8% 2%
MIP
Mkw 0.4% 0.8% 2%
SRep
6%
Prop
Number of slow MULEs (→)
14
16
4
6% 52%
6% 52%
6%
6% 52%
0.4% 3% 10% 18% 35% 63% 95%
10
3%
3%
6%
12
4%
4%
6%
6%
Table 2: Failure rates as more fragments are required for
p = .61, r = 2, and 32 MULEs. While
each message.
Markowitz is robust to forced fragmentation, SRep degrades
quickly. SRep-Code shows that SRep is greatly improved
by using erasure coding when fragmentation occurs.
1. In this regime, splitting is harmful. The optimal allocation is
thus to send a full copy of the message on the best two MULEs.
This is the approach of SRep, and both the MIP and Markowitz
identify this optimal allocation. However, Prop (proportional
allocation) splits the data equally among all the MULEs and, as
expected, has poor performance which gets worse as the number
of MULEs increase.
The second regime corresponds to the case when p · r is
only slightly greater than 1 (the “gray zone” when p = .61).
In this case, when the number of paths is small (≤ 16), the
splitting-based techniques (Markowitz, Prop, MIP) have the
same or slightly worse performance than SRep. However, as
n increases, the beneﬁts of increased splitting become evident,
and Markowitz has close to zero failure probability when n is
64. Finally, MIP has the same allocation as SRep when there
are only a few paths, but employs splitting as the number of
MULEs increase. However, even with only eight MULEs, the
absolute diﬀerence between Markowitz and MIP is small.
The third regime is the case when p· r is signiﬁcantly greater
than 1 (p = .86).
In this case, all techniques achieve good
performance, which is intuitive because all MULEs are generally
“good bets”. Furthermore, with a large number of MULEs,
the techniques that use erasure coding can achieve a near-zero
failure probability. In contrast, SRep will require a very large
replication factor to achieve such low failure probabilities. This
could be important in situations when very high assurance of
delivery is required.
6.2 Forced Splitting
In this section, we scale the message size to demonstrate the
eﬀects of being forced to split a message to ﬁt onto a contact.
SRep handles this constraint by splitting the message into the
largest fragments that can ﬁt over a single contact and then
choosing the best paths for each fragment sequentially. Note
that Markowitz, MIP, and Prop already account for volume
constraints.
Table 2 shows the results of these experiments. We ﬁrst ob-
serve that the performance of SRep drops sharply as the mes-
sage size increases. This is because, in SRep, at least one copy
of every distinct fragment must be received to successfully re-
construct the message. The probability of receiving all the frag-
ments decreases exponentially as the number of fragments in-
crease. The larger the message size, the the larger the number
of fragments, which explains the decrease in FR as overall mes-
sage size increases.
The performance of Markowitz is not aﬀected by forced split-
ting. This is because for p = .61, Markowitz spreads the code
blocks equally over the paths, and thus obeys the contact vol-
ume constraint.
Finally, when splitting is required, SRep is greatly enhanced
by erasure coding (SRep-Code). Interestingly, the performance
Table 3: Failure rates with 16 MULEs of two types:
fast
MULEs (p = .76) and slow MULEs (p = .28), and ﬁxed
r = 2. Prop (proportional) is unable to adapt to varia-
tions in MULE types, whereas, Markowitz maintains good
performance until all MULEs are slow.
here improves with a larger message size, simply because the
contact volume constraint forces more splitting and SRep-Code
approaches the equal-split allocation that is done by Markowitz.
This shows that if fragmentation is required, erasure coding is
almost essential for good performance.
6.3 Fast and Slow MULEs
We now consider the case where paths have diﬀerent success
probabilities. To construct such a scenario, we introduce two
kinds of MULEs: “fast” MULEs with a velocity of 10m/s and
“slow” MULEs at 5m/s. Recall that the only way data is lost in
this experiment is by message expiration. Thus, slower MULEs
will tend to lose data more often than faster ones. We ﬁx the
total number of MULEs at 16, the replication factor at 2, and
the deadline at two hours. These settings correspond to p = .76
for the fast MULEs and p = .28 for the slow ones. We vary
the slow MULEs to fast MULEs to understand how diﬀerent
techniques adapt to a heterogeneous set of MULEs.
As shown in Table 3, SRep has a relatively constant failure
probability of 6% as long as there are at least two fast MULEs,
but jumps to 52% when all the MULEs are slow. In contrast,
Prop is incapable of adapting to the mixture of path probabil-
ities, and demonstrates notably worse performance when more
than half the MULEs are slow. Finally, we see that the opti-
mal MIP solution and Markowitz take advantage of as many
fast MULEs as possible, and therefore obtain a much better
FP when there are many fast MULEs. As the number of slow
MULEs increases, the FP gradually degrades to approach that
of simple replication, until there are no more fast MULEs, when
the FP similarly jumps to 52%. We also considered other mix-
tures of path success probabilities, and ﬁnd that Markowitz
performs well in all cases.
6.4 Tolerance to Probability Estimation Errors
In this experiment, we discuss the impact of imperfect knowl-
edge of the path delivery probabilities on performance of the
various allocation techniques. This is an important considera-
tion for real-world deployment of DTN systems, because path
probabilities will generally need to be estimated and will not
be completely accurate. We estimate path success probabilities
by using a history of observations for each MULE; naturally,
the accuracy of these predictions depends on the number of ob-
servations. In this experiment, we vary the number of samples
used to estimate path probabilities and compare the reliable
delivery performance. We divide 16 MULEs equally into four
types, with velocities of 15, 12.5, 10, and 7.5m/s, respectively
(corresponding to p = .81, .73, .61, and .47, respectively). We
then examine ﬁve conﬁgurations (10, 20, 50, 100, and 1000) of
the number of samples used to make the probability estimate.
For each conﬁguration, we ran 100 simulations with diﬀerent
)
%
(
e
t
a
R
e
r
u
l
i
a
F
 10
 8
 6
 4
 2
 0
NS-10
NS-20
NS-50
NS-100
NS-1000
1 2 3
1 2 3
1 2 3
1 2 3
1 2 3
Different configurations (1=SRep, 2=Mkw, 3=Prop)
Figure 4: Failure rate distribution as the number of sam-
ples (denoted by NS-#) is varied, with 16 MULEs divided
equally with varied speeds (p = .81, .73, .61, and .47), and
r = 2. For each technique, we show the median, 5th, and
95th percentiles.
random seeds and therefore potentially diﬀerent estimates of
the underlying probabilities.
Figure 4 shows failure rates for SRep, Markowitz, and Prop
for diﬀerent number of samples. For each technique, the line
indicates the median failure probability along with the 5th per-
centile and the 95th percentile (of the results from the 100
runs) to show the variability. The MIP had similar behavior
as Markowitz and is omitted.
When only a few samples are used (NS-10 case), it is likely
that some slow MULEs will be mistakenly identiﬁed as fast
ones and vice-versa. Therefore, techniques such as SRep and
Markowitz that aggressively use path probabilities to guide de-
cisions will be adversely aﬀected by errors in probability esti-
mation; this is clear from high variability in the failure rates.
Having more samples leads to a more accurate estimate of
the probabilities and improved performance for both SRep and
Markowitz. Markowitz converges faster than SRep. This is be-
cause SRep will choose only two MULEs that it thinks have the
highest probability. If only a few samples are used to estimate
probabilities, it may choose the wrong MULEs. Markowitz, on
the other hand, will split code blocks among a larger number
of MULEs; it needs only a rough idea of which MULEs are
fast and which are slow. Somewhat surprisingly, Prop is only
marginally aﬀected by the number of samples, and reveals good
performance even with large estimation error. This is because it
spreads data over all paths. Even with a large estimation error,
it will send data on both the high and low probability paths,
and therefore achieve reasonable performance. In fact, for this
case, even a na¨ıve technique that allocates equal code blocks
among all paths (ignoring path probabilities) has performance
similar to Prop.
7. BUS NETWORK SCENARIO
Now we consider the San Francisco city bus network scenario,
as presented in previous work [8]. In this scenario, 20 city buses
are equipped with radio transceivers to move data. Although
the buses act as MULEs, this scenario has signiﬁcantly diﬀerent
properties from the previous MULE scenario. Here, path fail-
ures are not independent because a given destination is serviced
by a small number of bus routes. Therefore, it is possible that
multiple paths to that destination use the same bus contact,
introducing dependency between the paths.
Prior work assumed that buses always deliver messages with
probability one [8]. We extend that scenario by adding a fail-
ure model in which all data transmissions during a contact may
fail with a ﬁxed probability. Such failures might occur because
of channel contention, large unpredictable delays in bus move-
ments (resulting in timeouts), or buﬀer overﬂows. Although in
many ways similar to the MULE scenario, this case diﬀers in
four important ways:
• Buses follow published routes and this can be used to
determine an eﬃcient path. Unlike the MULE scenario, such a
delivery path may be multi-hop, complicating the scenario.
• Paths or buses may suﬀer complete outages, resulting in
all messages held in the failed bus to be discarded, irrespec-
tive of their timeouts. In the previous scenario, messages were
discarded only on expiration.
• Paths are dependent and this requires a solution approach
• The solution space for path selection is signiﬁcantly richer.
That is, messages with diﬀerent sources, sinks, departure times,
and expiration times may be assigned completely diﬀerent paths
and replication strategies. In the previous scenario, delivery of
all messages was constrained to a homogeneous set of MULEs.
which can incorporate this dependency among paths.
Simulation Setup
The bus mobility is assumed to follow the published city
schedule. We assume a radio bandwidth of 400kbps and a radio
range of 100 meters. Each simulation examines a 12 hour du-
ration. For each hour, 20 messages are sent between a random
pair of buses at a random start time within the hour. The mes-
sage size is 10KB, each bus has 1MB of storage, and the message
expiration time was set to six hours. Contact success proba-
bility was chosen between 0.8 and 1.0, and made available to
the allocation technique. The average path delivery probability,
however, is .643 because paths are multi-hop. The path failure
model is still Bernoulli. To apply Markowitz we need to com-
pute the covariance matrix (V ). We compute Vij (Cov(Si, Sj))
as follows.
Consider two paths i and j and let Cq denote the set of con-
tacts common between the two paths. Let Ci and Cj be the set
of contacts that exclusively belong to path i and j respectively.
Now, Vij = Cov(Si, Sj) = E[SiSj] − E[Si] E[Sj]
= P rob(Si = 1) (P rob(Sj = 1|Si = 1) − P rob(Sj = 1))
=	l∈Ci∪Cq pl (	l(cid:1)∈Cj pl(cid:1) −
=	l∈Ci∪Cq∪Cj pl (1 −
	l(cid:1)∈Cq pl(cid:1) )
	l(cid:1)∈Cj∪Cq pl(cid:1) )
The dynamic Dijkstra algorithm (ED) presented in [8] is used
to ﬁnd multiple path(s) between two buses within a given dead-
line. Taking all messages into account, the number of paths for
a message to be delivered ranges from 16 to 60, with a me-
dian of 34. For most messages, there are a few high probability
paths and many more (longer) ones of low probability. Fur-
thermore, many of these paths contain common buses, so they
have dependent delivery probabilities. The probability depen-
dence can be summarized in terms of the average correlation
coeﬃcient (¯ρ), which is 0.2. Though it is not immediately ob-
vious how this statistic corresponds to probability of delivery,
we note that a value of ¯ρ = 0 would imply independent paths,
and ¯ρ = 1 implies completely dependent paths.6
7.1 Multi-hop and dependent paths
Figure 5 shows failure rates for three diﬀerent replication fac-
tors of 2, 3 and 4. Each line shows the 5th, 50th and the 95th
percentiles of the the distribution of failure rates across 240
6 ¯ρ = 1
σij
σiσj . σij = Cov(Si, Sj ), σi
2 = V ar(Si)
n
j=1
n
n2 
i=1
)
%
(
e
t
a
R
e
r
u
l
i
a
F
 20
 15
 10
 5
 0
SRep MIP MkwNu Mkw MkwIg Prop
)
%
(
e
t
a
R
e
r
u
l
i
a
F
 14
 12
 10
 8
 6
 4
 2
 0
SRep MIP MkwNu Mkw MkwIg Prop
)
%
(
e
t
a
R
e
r
u
l
i
a
F
 8
 7
 6
 5
 4
 3
 2
 1
 0
SRep MIP MkwNu Mkw MkwIg Prop
(a) r = 2
(b) r = 3
(c) r = 4
Figure 5: Failure rate distributions for diﬀerent techniques and three diﬀerent replication factors. For each technique, the
plot shows the median, 5th and 95th percentiles across 240 simulated messages. MkwIg denotes the Markowitz approach
that ignores correlations. For clarity, the y-axis has a diﬀerent range and scale for the diﬀerent plots.
simulated messages. In all cases, the MIP technique produces
the optimal solution with the tightest range.7 Examining the
less expensive techniques, when r = 2, SRep performs slightly
better than Markowitz. The average path success probability
in this scenario is around .6, and so the product p · r is in the
“gray zone”. The eﬀectiveness of splitting over multiple paths
is further reduced because of dependencies among paths.
As we increase r, Markowitz shows a faster improvement than
SRep. The diﬀerence between Markowitz and SRep when com-
paring the 95th percentile FR is substantial. For example, when
r = 4, Markowitz has almost half the failure rate as SRep.
The most surprising revelation, however, is that even for higher
replication factors, when comparing the median failure rates,
Markowitz is only marginally better than SRep. Due to the
dependencies between paths and the limited number of viable
path alternatives, there is not much room for Markowitz to im-