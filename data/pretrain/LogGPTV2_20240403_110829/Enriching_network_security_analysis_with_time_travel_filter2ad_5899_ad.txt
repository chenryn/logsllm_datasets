bitrate of 155 Mbps. The TM’s cutoff reduced the total volume to
0.6 TB. It took a bit over 11 days until the TM exhausted its 500 GB
disk budget for the ﬁrst time and started to expire data. The NIDS
reported 66,000 operator-level notiﬁcations according to the con-
ﬁgured policy, with 98% of them referring to scanning activity.
5.2 NIDS Controls The TM
The TM provides a network-accessible control interface that the
NIDS can use to dynamically change operating parameters based
on its analysis results such as cutoffs, buffer budgets, and timeouts.
In our installation, we instrument the NIDS so that for every op-
erator notiﬁcation5, it instructs the TM to (i) disable the cutoff for
the affected connection for non-scan notiﬁcations, and (ii) change
the storage class of the IP address the attacker is coming from to
a more conservative set of parameters (higher cutoffs, longer time-
outs), and also assign it to separate memory and buffer pools. The
latter signiﬁcantly increases the retention time for the host’s activ-
5We note that the speciﬁcs of what constitutes an operator notiﬁca-
tion vary from site to site, but because we cannot report details of
LBNL’s operational policy we will refer only to broad classes of
notiﬁcations such as “scans”.
Internal
Network
Tap
Internet
NIDS
Queries
Traffic from
the past
Time 
Machine
Figure 11: Coupling TM and NIDS at LBNL.
ity, as it now no longer shares its buffer space with the much more
populous benign trafﬁc.
In concrete terms, we introduce two new TM storage classes:
scanners, for hosts identiﬁed as scanners, and alarms, for hosts
triggering operator notiﬁcations other than scan reports. The mo-
tivation for this separation is the predominance of Internet-wide
scanning: in many environments, scanning alerts heavily dominate
the reporting. By creating a separate buffer for scanners, we in-
crease the retention time for notiﬁcations not related to such activ-
ity, which are likely to be more valuable. The classes scanners and
alarms are provided with a memory budget of 75 MB and a disk
budget of 50 GB each. For scanners, we increase the cutoff from
15 KB to 50 KB; for all other offenders we disable the cutoff alto-
gether. Now, whenever the NIDS reports an operator notiﬁcation,
it ﬁrst sends a suspend_cutoff command for the triggering con-
nection to the TM. It then issues a set_class command for the
offending host, putting the address into either scanners or alarms.
Examining the commands issued by the NIDS during the two-
week period, we ﬁnd that it sent 427 commands to suspend the
cutoff for individual connections. Moreover, it moved 12,532 IP
addresses into the scanners storage class and 592 into the alarms
storage class.6
5.3 NIDS Retrieves Data From TM
Another building block for better forensics support is automatic
preservation of incident-related trafﬁc. For all operator notiﬁca-
tions in our installation, the NIDS queries the TM for the relevant
packets, which are then permanently stored for later inspection.
Storage: The NIDS issues up to three queries for each major (non-
scan) notiﬁcation. Two to_file queries instruct the TM to store
(i) all packets of the relevant connection and (ii) all packets in-
volving the offender’s IP address within the preceding hour. For
TCP trafﬁc, the NIDS issues a feed query asking it to also return
the connection’s packets to the NIDS. The NIDS then stores the
reassembled payload stream on disk. For many application proto-
cols, this eases subsequent manual inspection of the activity. We
restrict connection queries to in-memory data, while host queries
include disk-buffered trafﬁc as well. Our motivation is that con-
nection queries are time-critical while host queries are related to
forensics.
During the examined two-week period, the NIDS issued queries
for 427 connections (after duplicate elimination) and 376 individual
hosts. As queries for connections were limited to in-memory data,
their mean processing time was 210 ms (σ= 510 ms). Among the
queries, there was one strong outlier that took 10.74 sec to com-
6We note that the number of issued commands does not directly
correspond to the number of operator notiﬁcations generated by
the NIDS. The NIDS often reports hosts and connections multiple
times, but only sends the corresponding command once. Further-
more, the NIDS sometimes issues commands to change the storage
class for activity which does not generate a notiﬁcation.
XXX.XXX.XXX.XXX/57340 > XXX.XXX.XXX.XXX/smtp same gap on
link/time-machine (> 124/6296)
XXX.XXX.XXX.XXX/55529 > XXX.XXX.XXX.XXX/spop same gap on
link/time-machine (> 275/165)
XXX.XXX.XXX.XXX/2050 > XXX.XXX.XXX.XXX/pop-3 same gap on
link/time-machine (> 17/14)
Figure 13: Example of drops conﬁrmed by the TM.
its raw form, we can now quickly eliminate these as well. To fur-
ther automate this analysis, we plan to extend the setup so that the
NIDS itself checks the TM’s response for signs of an actual pass-
word list, and suppresses the notiﬁcation unless it sees one. Similar
approaches are applicable to a wide range of probing attacks.
For applications running on non-standard ports the TM has the
potential to signiﬁcantly help with weeding out false-positives.
Bro, for example, ﬂags outgoing packets with a destination port
69/udp as potential “Outbound TFTP” (it does not currently include
a TFTP protocol analyzer). Assessing the signiﬁcance of this notiﬁ-
cation requires looking at the payload. With the TM recordings we
were able to quickly identify in several instances that the reported
connection reﬂected BitTorrent trafﬁc rather than TFTP. In another
case, Bro reported parsing errors for IRC trafﬁc on 6667/tcp; in-
spection of the payload quickly revealed that a custom protocol
was using the port.
The information captured by the TM can also shed light on how
attacks work. In one instance, a local client downloaded a trojan
via HTTP. The NIDS reported the fact and instructed the TM to re-
turn the corresponding trafﬁc. Once the NIDS had reassembled the
payload stream, the trojan’s binary code was available on disk for
further manual inspection (though truncated at the 15 KB cutoff).
Finally, the TM facilitates the extraction of packet traces for var-
ious interesting network situations, even those not necessarily re-
ﬂecting attacks. Among others, we collected traces of TCP con-
nections opened simultaneously by both sides; sudden FIN storms
of apparently misconﬁgured clients; and packets that triggered in-
accuracies in Bro’s protocol processing.
5.4 Retrospective Analysis
In the following, we demonstrate the potential of a tighter in-
tegration of TM and NIDS by examining forms of retrospective
analysis this enables.
Recovering from Packet Drops: Under heavy load, a NIDS can
lack the processing power to capture and analyze the full packet
stream, in which case it will incur measurement drops [10]. Work-
ing in conjunction with the TM, however, a NIDS can query for
connections that are missing packets and reprocess them.
If the
same gap also occurs in the response received from the TM, the
NIDS knows that most likely the problem arose external to the
NIDS device (e.g., in an optical tap shared by the two systems,
or due to asymmetric routing).
We implemented this recovery scheme for the Bro NIDS. With
TCP connections, Bro infers a packet missing if it observes a se-
quence gap purportedly covered by a TCP acknowledgment.
In
such cases we modiﬁed Bro to request the affected connection from
the TM. If the TM connection is complete, Bro has recovered from
the gap and proceeds with its analysis.
If the TM connection is
however also missing the packet, Bro generates a notiﬁcation (see
Fig. 13). In addition to allowing Bro to correctly analyze the trafﬁc
that it missed, this also enables Bro to differentiate between drops
due to overload and packets indeed missing on the link.
Ofﬂoading the NIDS: NIDS face fundamental trade-offs between
depth of analysis and resource usage [24]. In a high-volume envi-
ronment, the operator must often choose to forego classes of anal-
ysis due to limited processing power. However, by drawing upon
Figure 12: Web-interface to notiﬁcations and their correspond-
ing network trafﬁc (packets and payload).
plete: it yielded 299,002 packets in response. Manual inspection of
the extracted trafﬁc showed that this was a large DNS session. Ex-
cluding this query, the mean time was 190 ms (σ= 100 ms). Queries
for individual hosts included on-disk data as well, and therefore
took signiﬁcantly longer; 25.7 sec on average. Their processing
times also varied more (median 10.2 sec, σ= 54.1 sec).
Interactive Access: To further reduce the turnaround time between
receiving a NIDS notiﬁcation and inspecting the relevant trafﬁc,
we developed a Web-based interface that enables browsing of the
data associated with each notiﬁcation; Fig. 12 shows a snapshot.
The prototype interface presents the list of notiﬁcations and indi-
cates which kind of automatically extracted TM trafﬁc is available.
The operator can then inspect relevant packets and payload using a
browser, including trafﬁc that occurred prior to the notiﬁcation.
Experiences: We have been running the joint TM/NIDS setup at
LBNL for two months, and have used the system to both analyze
packet traces and reassembled payload streams for more detailed
analysis. During this time, the TM has proven to be extremely use-
ful. First, one often just cannot reliably tell the impact of a speciﬁc
notiﬁcation without having the actual trafﬁc at hand. Second, it
turns out to be an enormous timesaver to always have the trafﬁc
related to a notiﬁcation available for immediate analysis. This al-
lows the operator to inspect a signiﬁcantly larger number of cases
in depth than would otherwise be possible, even those that appear
to be minor on ﬁrst sight. Since with the TM/NIDS setup double-
checking even likely false-positives comes nearly for free, the over-
all quality of the security monitoring can be signiﬁcantly improved.
Our experience from the deployment conﬁrms the utility of such
a setup in several ways. First, the TM enables us to assess whether
an attack succeeded. For example, a still very common attack
includes probing web servers for vulnerabilities. Consider Web
requests of the form foo.php?arg=../../../etc/passwd with
which the attacker tries to trick a CGI script into returning a list
of passwords. Since many attackers scan the Internet for vulnera-
ble servers, simply ﬂagging such requests generates a large number
false positives, since they very rarely succeed. If the NIDS reports
the server’s response code, the operator can quickly weed out the
cases where the server just returned an error message. However,
even when the server returns an 200 OK, this does not necessarily
indicate a successful attack. Often the response is instead a generic,
harmless page (e.g., nicely formatted HTML explaining that the re-
quest was invalid). Since the TM provides the served web page in
With Time Travel
Without Time Travel
y
t
i
s
n
e
D
6
5
4
3
2
1
0
0.0
0.2
0.4
0.6
0.8
1.0
CPU utilization
Figure 14: CPU load with and without Time Travel.
the TM, a NIDS can make ﬁne-grained exceptions to what would
otherwise be analysis omissions. It does so by requesting initially
excluded data once the NIDS recognizes its relevance because of
some related analysis that is still enabled.
For example, the bulk of HTTP trafﬁc volume in general orig-
inates from HTTP servers, rather than clients. Thus, we can sig-
niﬁcantly ofﬂoad a NIDS by restricting its analysis to client-side
trafﬁc, i.e., only examine URLs and headers in browser requests,
but not the headers and items in server replies. However, once
the NIDS observes a suspicious request, it can query the TM for
the complete HTTP connection, which it then analyzes with full
server-side analysis. The beneﬁt of this setup is that the NIDS can
now save signiﬁcant CPU time as compared to analyzing all HTTP
connections, yet sacriﬁcing little in the way of detection quality.
FTP data transfers and portmapper activity provide similar
examples. Both of these involve dynamically negotiated sec-
ondary connections, which the NIDS can discern by analyzing the
(lightweight) setup activity. However, because these connections
can appear on arbitrary ports, the NIDS can only inspect them di-
rectly if it foregoes port-level packet ﬁltering. With the TM, how-
ever, the NIDS can request subscriptions (§3.2) to the secondary
connections and inspect them in full, optionally also removing the
cutoff if it wishes to ensure that it sees the entire contents.
We explore the HTTP scenario in more detail to understand the
degree to which a NIDS beneﬁts from ofﬂoading some of its pro-
cessing to the TM. For our assessment, we need to compare two
different NIDS conﬁgurations (with and without the TM) while
processing the same input. Thus, we employ a trace-based eval-
uation using a 75 min full-HTTP trace captured on LBNL’s up-
stream link (21 GB; 900,000 HTTP sessions), using a two-machine
setup similar to that in §4.2. The evaluation requires care since
the setup involves communication with the TM: when working of-
ﬂine on a trace, both the NIDS and the TM can process their input
more quickly than real-time, i.e., they can consume 1 sec worth of
measured trafﬁc in less than 1 sec of execution time. However, the
NIDS and the TM differ in the rate at which they outpace network-
time, which can lead to a desynchronization between them.
To address these issues, the Bro system provides a pseudo-
realtime mode [25]: when enabled, it inserts delays into its exe-
cution to match the inter-packet gaps observed in a trace. When
using this mode, Bro issues queries at the same time intervals as
it would during live execution. Our TM implementation does not
provide a similar facility. However, for this evaluation we wish to
assess the NIDS’s operation, rather than the TM’s, and it therefore
sufﬁces to ensure that the TM correctly replies to all queries. To
achieve this, we preload the TM with just the relevant subset of the
trace, i.e., the small fraction of the trafﬁc that the Bro NIDS will
request from the TM. The key for preloading the TM is predicting
which connections the NIDS will request. While in practice the
NIDS would trigger HTTP-related queries based on URL patterns,
for our evaluation we use an approach independent of a speciﬁc
detection mechanism: Bro requests each HTTP connection with a
small, ﬁxed probability p.
Our ﬁrst experiment measures the performance of a stand-alone
NIDS. We conﬁgure Bro to perform full HTTP processing. To
achieve a fair comparison, we modify Bro to ignore all server pay-
load after the ﬁrst 15 KB of each connection, simulating the TM’s
cutoff. We then run Bro in pseudo-realtime mode on the trace and
log the CPU usage for each 1 sec interval. Fig. 14 shows the result-
ing probability density.
With the baseline established, we then examine the TM/NIDS
hybrid. We conﬁgure Bro to use the same conﬁguration as in the
previous experiment, except with HTTP response processing dis-
abled. Instead, we conﬁgure Bro to issue queries to the TM for a
pre-computed subset of the HTTP sessions for complete analysis.
We choose p = 0.01, a value that from our experience requests full
analysis for many more connections than a scheme based on pat-
terns of suspicious URLs would. We supply Bro with a preﬁltered
version of the full HTTP trace with all server-side HTTP payload
packets excluded.7 As described above, we provide the TM with
the trafﬁc which Bro will request.
We verify that the TM/NIDS system matches the results of the
stand-alone setup. However, Fig. 14 shows a signiﬁcant reduction
in CPU load. In the stand-alone setup, the mean per-second CPU
load runs around 40% (σ= 9%). With TM ofﬂoading, the mean
CPU load decreases to 28%, (σ= 7%). We conclude that ofﬂoading
indeed achieves a signiﬁcant reduction in CPU utilization.
Broadening the analysis context: Finally, with a TM a NIDS can
request historic network trafﬁc, allowing it to perform analysis on
past trafﬁc within a context not available when the trafﬁc originally
appeared. For example, once the NIDS identiﬁes a source as a scan-
ner, it is prudent to examine all of its trafﬁc in-depth, including its
previous activity. The same holds for a local host that shows signs
of a possible compromise. Such an in-depth analysis may for ex-
ample include analyzers that were previously disabled due to their
performance overhead. In this way the NIDS can construct for the
analyst a detailed application-level record of the offender, or the
NIDS might itself assess this broader record against a meta-policy
to determine whether the larger view merits an operator notiﬁca-
tion.
5.5 Implementing Retrospective Analysis
Implementing the TM/NIDS interface for the above experiments
requires solving a number of problems. The main challenge lies
in that processing trafﬁc from the past, rather than freshly cap-
tured, violates a number of assumptions a NIDS typically makes
about packets appearing in real-time with a causal order reﬂecting
a monotonic passage of time.
A simple option is to special-case the analysis of resurrected
packets by introducing a second data path into the NIDS exclu-
sively dedicated to examining TM responses. However, such an
approach severely limits the power of the hybrid system, as we in
this case cannot leverage the extensive set of tools the NIDS already
provides for live processing. For example, ofﬂoading applications,
as described in §5.4, would be impossible to realize without dupli-
cating much of the existing code. Therefore, our main design ob-
7We preﬁlter the trace, rather than installing a Bro-level BPF ﬁlter,
because in a live setting the ﬁltering is done by the kernel, and thus
not accounted towards the CPU usage of the Bro process.
jective for our Bro implementation is to process all TM-provided
trafﬁc inside the NIDS’s standard processing path, the same as for
any live trafﬁc—and in parallel with live trafﬁc. In the remainder
of this section, we discuss the issues that arose when adding such a
TM interface to the Bro NIDS.
Bro Implementation: Bro provides an extensive, domain-speciﬁc
scripting language. We extend the language with a set of predeﬁned
functions to control and query the TM, mirroring the functionality
accessible via the TM’s remote interface (see §3.2), such as chang-
ing the TM class associated with a suspect IP address, or querying
for packets based on IP addresses or connection 4-tuples. One basic
requirement for this is that the interface to the TM operates asyn-
chronously, i.e., Bro must not block waiting for a response.
Sending commands to the TM is straight-forward and thus omit-
ted. Receiving packets from the TM for processing, however, raises
subtle implementation issues: the timestamp to associate with re-
ceived query packets, and how to process them if they are replicates
of ones the NIDS has already processed due to direct capture from
the network, or because the same packet matches multiple streams
returned for several different concurrent queries.
Regarding timestamps, retrieved packets include the time when
the TM recorded them. However, this time is in the past and if
the NIDS uses it directly, confusion arises due to its assumptions
regarding time monotonicity. For example, Bro derives its measure