### (b) Success-Number Graph: 
- 1 List+ 
- 1 Markov+ 
- 1 PCFG

### (c) Success-Number: 
- 1 TarList+ 
- 1 TarMarkov+ 
- 1 TarPCFG

### (d) Flatness Graph: Tweaking-Tail

### (f) Flatness: 
- 1 TarList+ 
- 1 TarMarkov+ 
- 1 TarPCFG

**Figure 5.** Evaluating the tweaking-tail method [35] (under A1) and our two methods (under A3 and A4, respectively) using seven password datasets. Each dataset is split into 50% for training and 50% for testing. Our methods achieve 0.15-flatness under harsh attackers.

### (e) Flatness Graph: 
- 1 List+ 
- 1 Markov+ 
- 1 PCFG

Our methods ensure an acceptable level of security (i.e., 0.15-flatness) while being reasonably cost-effective, as shown in Section V-B.

## B. Empirical Evaluation Results
Note that our List method and TarList method will always yield the same security results as a perfect method under type-A1 and A2 attackers, respectively. This is because the optimal attacker needs to employ the List password model \( Pr_D(·) \) to compute Equation 3, and the server employs \( Pr_{D'}(·) \) to generate honeywords. The training set \( D \) can only approximate \( D' \), but it will never equal the target site’s password distribution \( D \). This has been empirically shown in Figures 6 and 3. Thus, we mainly evaluate our remaining two methods.

To avoid overfitting, the datasets used in all above exploratory experiments will not be used here. For fair evaluation, we perform attacks simulating a type-A1 attacker against tweaking-tail, attacks simulating a type-A3 attacker against 3PCFG, and attacks simulating a type-A4 attacker against 3TarPCFG. This is because each method is designed under a specified security model, and it is only sensible to claim some form of security under that model. Figure 5 shows that for most of the datasets, our methods can achieve 0.15-flatness, while this figure for tweaking-tail is 0.2+. Notably, our methods are evaluated under much harsher attackers. In particular, there are orders of magnitude fewer "low-hanging fruits" (see Figures 5(b) and 5(c)) that can be obtained by the attacker. Overall, our empirical results align well with the exploratory experiments, and when setting \( k=40 \), our methods can ensure the security level of 0.15-flatness.

### Discussion
Figure 5 shows that the language, service type, and size of the training/testing datasets significantly influence honeyword security. This is consistent with [53], [55]. Our evaluation results do not indicate that passwords/honeywords from English users are more or less secure than those of Chinese users. Moreover, the perceived risk (service type) of the site greatly influences users’ password behaviors, as confirmed in password research [32], [55]. For example, users on the QNB banking site (see Table II) have, on average, less common passwords: the top 10 most popular passwords account for only 0.59% of QNB users, while the figure for the remaining 10 datasets (in Table II) is 4.16% on average. Therefore, the closer the training set is to the passwords of the target site, the better/flat the generated honeywords will be. This explains why adaptive password/honeyword models are preferable. The results for QNB in Figure 5 demonstrate that our adaptive honeyword methods are suitable for highly sensitive services like banking.

### Overheads
The overall overheads of our methods are low and acceptable because:
1. All training, generation, and update processes are conducted on the server side and require no user interactions/feedbacks, thus not impairing user experience.
2. Training is costly but is only conducted once.
3. Generation and update processes mainly entail table lookups, which are lightweight. For instance, when \( k=40 \) and trained on 32M RockYou, training costs 70 minutes on a common PC; the generation time is 2 ms; honeyword storage for 10^7 users costs 12.8 GB when using PBKDF2-SHA256.

## C. Human-Based Evaluation Results
While our methods can provide desirable security against computer-automated attackers, whether the conclusion still holds under semantic-aware humans is unknown. This is particularly concerning because many semantics in passwords (e.g., bond007 and john1981) can be easily recognized by a human but difficult for an automated attacker. Thus, we recruited 11 graduate students who were taking a “network security” seminar to participate in our evaluation.

### Setups
Before starting the experiments, our participants were asked to read the honeyword-related literature [21], [24], [35], and were informed of both Juels-Rivest’s four [35] and our four honeyword-generation methods. One month later, they were asked to take a quiz covering various aspects of honeywords, and all passed. Their expertise enables them to understand all twelve attacking scenarios, and to know where and how to look for clues/weaknesses in telling honeywords and real passwords apart. Hence, they are competent adversaries in our setting. For incentive, we specified that, when given a list of \( k \) sweetwords, 1 CNY would be awarded if a participant finds the real password with the first attempt, 0.5 CNY with the second attempt, and so on. The procedure of human experiments was established with the help of two usable-security researchers with survey expertise.

The experiment lasted six consecutive days during a holiday. On each day, one attacking scenario was completed in the morning and another in the afternoon. During each scenario, a participant was given 40 sweetword lists, each including 20 sweetwords, and participants were asked to finish within 30 minutes. This led to a total consumption of 5280 (=40×2×6×11) user accounts (with PII), randomly drawn from the 161,517 PII-associated Dodonew password accounts (see Table IV). We initially attempted to include 40 sweetwords in each sweetword list (and one scenario costing about 45 minutes), but feedback from the two usable-security experts indicated this was too fatiguing. The schedule was established and sent to every participant before the experiment.

In the testing phase, they came to our lab to conduct the attacks. Each computer stored a dozen password datasets that the participant could query, simulating a basic attacker with type-A1 capability. For each attacking scenario, either the method or attacker type was different from the others. For a type-A1 attacker, participants were given 40 sweetword lists. For A2, the common PII of each victim was provided; for A3, the order of the sweetword list was just the order of user registration; for A4, this was the joint case of A2 and A3. For ethical considerations, all computers were disconnected from the Internet, no paper or memory device was allowed for recording, and Email suffix and NID were not given to the participants to make the users less identifiable.

### Results
Each sub-figure in Figure 9 in Appendix E shows the flatness curves for all 11 experts (denoted by A to K) under a given attacking scenario. As summarized in Table VI, the four methods in [35] achieve 0.40+-flatness under Type-A1 attacker and 0.48+-flatness under Type-A2 attacker, far from perfect flatness. In comparison, both List and 3PCFG methods achieve almost perfect flatness (i.e., \( \epsilon \approx \frac{1}{20} \)) under non-PII-aware attackers. Even when attackers are PII-aware (i.e., Type-A2 and A4), our corresponding methods still achieve 0.09-flatness. This suggests that our targeted methods can well capture user PII semantics. Compared to the four methods in [35], all our four methods are over 4.5 times more secure in terms of \( \epsilon \)-flatness. To sum up, results suggest that our methods are substantially better at resisting human-expert attackers.

Generally, when human experts are not provided with the victim user’s PII, they are considerably more effective than computer-automated algorithms (see Table X of [53]). For instance, when the victims’ PII is not available, human experts achieve a success rate of 40.23%~55.00% (with just one guess) at telling apart real passwords from honeywords generated by Juels-Rivest’s four methods [35], while the figure for computer-automated algorithms is 34.21%~49.02%. When human experts are provided with victims’ PII, their advantages are comparable to PII-enriched computer-automated algorithms. For instance, when the victims’ PII is available, human experts achieve a success rate of 58.64%~71.59% (with just one guess) at telling apart real passwords from honeywords generated by Juels-Rivest’s four methods [35], while the figure for computer-automated algorithms is 56.80%~67.90%.

### \( \epsilon \)-Flat Information Under Human Attacks
| Honeyword-Generation Methods | Attacker Type | \( \epsilon \)-Flatness |
|-------------------------------|---------------|------------------------|
| Tweak Tail                    | Type-A1       | 0.4023                 |
| Tweak Tail                    | Type-A2       | 0.5864                 |
| Model-Syntax                  | Type-A1       | 0.5500                 |
| Model-Syntax                  | Type-A2       | 0.7159                 |
| Hybrid                        | Type-A1       | 0.4886                 |
| Hybrid                        | Type-A2       | 0.6023                 |
| Simple Model                  | Type-A1       | 0.4682                 |
| Simple Model                  | Type-A2       | 0.6659                 |
| List                          | Type-A1       | 0.0568                 |
| List                          | Type-A2       | 0.0705                 |
| 3PCFG                         | Type-A3       | 0.0591                 |
| 3PCFG                         | Type-A4       | 0.0886                 |

The human-expert attacks on Dodonew have shown that Chinese human attackers are PII-aware in nature. Since English users and Chinese users show similar PII usage behaviors [55], it is likely that attackers in other languages would have similar performance. Thus, when user PII is available, honeywords should be generated with PII.

### Summary
Our empirical evaluation builds on 11 large-scale datasets and considers various attackers. Further, to see how our methods perform under semantic-aware humans, we conducted a user study of 11 trained expert attackers. Results show that our methods can survive both automated and human attacks.

## VI. Conclusion
We have systematically tackled the question of how best to attack, design, and evaluate honeyword-generation methods. For the first time, we provided theoretical proofs and empirical explorations of how best to attack honeywords. This in-depth understanding of honeyword attackers enabled us to suggest a suite of honeyword-generation methods using leading probabilistic password models. We demonstrated the effectiveness of our methods by conducting both automated experiments and trained human-expert attacks. In the meantime, we addressed two open problems left in [35] and one in [53].

## Acknowledgment
The authors are grateful to the shepherd and anonymous reviewers for their invaluable comments. Ding Wang is the corresponding author, and part of the work was done while he was at Peking University. This research was in part supported by the National Natural Science Foundation of China under Grant No. 62172240. There are no competing interests.

## References
[1] All Data Breach Sources, Oct. 2018, https://breachalarm.com/all-sources.
[2] Yahoo Raises Breach Estimate to Full 3 Billion Accounts, By Far Biggest Known, Oct. 2017, http://fortune.com/2017/10/03/yahoo-breach-mail/.
[3] The Password is Dead, Long Live the Password!, October 2016, https://www.nccgroup.trust/uk/about-us/newsroom-and-events/blogs/2016/october/the-password-is-dead-long-live-the-password/.
[4] F. Adowsett, What has been leaked: impacts of the big data breaches, April 2016, https://rantfoundry.wordpress.com/2016/04/19/what-has-been-leaked-impacts-of-the-big-data-breaches/.
[5] S. Agrawal, P. Miao, P. Mohassel, and P. Mukherjee, “Pasta: password-based threshold authentication,” in Proc. CCS 2018, pp. 2042–2059.
[6] A. Akshima, D. Chang, A. Goel, S. Mishra, and S. K. Sanadhya, “Generation of secure and reliable honeywords, preventing false detection,” IEEE Trans. Depend. Secur. Comput., vol. 16, no. 5, pp. 757–769, 2019.
[7] M. H. Almeshekah, C. N. Gutierrez, M. J. Atallah, and E. H. Spafford, “Ersatzpasswords: Ending password cracking and detecting password leakage,” in Proc. ACSAC 2015, pp. 311–320.
[8] M. Andrey, Building a Distributed Network in the Cloud: Using Amazon EC2 to Break Passwords, Aug. 2017, https://blog.elcomsoft.com/2017/08/breaking-passwords-in-the-cloud-using-amazon-p2-instances/.
[9] A. J. Aviv, D. Budzitowski, and R. Kuber, “Is bigger better? comparing user-generated passwords on 3x3 vs. 4x4 grid sizes for Android’s pattern unlock,” in Proc. ACSAC 2015, pp. 301–310.
[10] A. Biryukov, D. Dinu, and D. Khovratovich, “Argon2: new generation of memory-hard functions for password hashing and other applications,” in Proc. EuroS&P 2016, pp. 292–302.
[11] J. Blocki, B. Harsha, S. Kang, S. Lee, L. Xing, and S. Zhou, “Data-independent memory hard functions: New attacks and stronger constructions,” in Proc. CRYPTO 2019, pp. 573–607.
[12] J. Blocki, B. Harsha, and S. Zhou, “On the economics of offline password cracking,” in Proc. IEEE S&P 2018, pp. 35–53.
[13] L. Bloomberg, 50 Million MyFitnessPal Accounts Have Been Hacked, Under Armour Says, March 2018, http://fortune.com/2018/03/29/myfitnesspal-password-under-armour-data-breach/.
[14] J. Bonneau, “The science of guessing: Analyzing an anonymized corpus of 70 million passwords,” in Proc. IEEE S&P 2012, pp. 538–552.
[15] J. Bonneau, C. Herley, P. Oorschot, and F. Stajano, “The quest to replace passwords: A framework for comparative evaluation of web authentication schemes,” in Proc. IEEE S&P 2012, pp. 553–567.
[16] J. Bonneau, C. Herley, P. van Oorschot, and F. Stajano, “Passwords and the evolution of imperfect authentication,” Commun. ACM, vol. 58, no. 7, pp. 78–87, 2015.
[17] M. Burnett, Is there life after passwords?, July 2016, https://medium.com/un-hackable/is-there-life-after-passwords-290d50fc6f7d.
[18] J. Camenisch, A. Lehmann, and G. Neven, “Optimal distributed password verification,” in Proc. ACM CCS 2015, pp. 182–194.
[19] U. N. C. S. Centre, How password deny lists can help your users to make sensible password choices, April 2019, https://www.ncsc.gov.uk/blog-post/passwords-passwords-everywhere.
[20] A. Chaabane, G. Acs, and M. Kaafar, “You are what you like! information leakage through users’ interests,” in Proc. NDSS 2012.
[21] N. Chakraborty and S. Mondal, “Few notes towards making honeyword system more secure and usable,” in Proc. ACM SIN 2015, pp. 237–245.
[22] R. Chatterjee, A. Athalye, D. Akhawe, A. Juels, and T. Ristenpart, “Password typos and how to correct them securely,” in Proc. IEEE S&P 2016, pp. 799–818.
[23] C. Cimpanu, 26 million LiveJournal credentials leaked online, sold on the dark web, May 2020, https://www.zdnet.com/article/26-million-livejournal-credentials-leaked-online-sold-on-the-dark-web/.
[24] I. Erguler, “Achieving flatness: Selecting the honeywords from existing user passwords,” IEEE Trans. Depend. Secur. Comput., vol. 13, no. 2, pp. 284–295, 2016.
[25] S. Furnell and R. Esmael, “Evaluating the effect of guidance and feedback upon password compliance,” Comput. Fraud Secur., vol. 2017, no. 1, pp. 5–10, 2017.
[26] X. Gao, Y. Yang, C. Liu, C. Mitropoulos, J. Lindqvist, and A. Oulasvirta, “Forgetting of passwords: Ecological theory and data,” in Proc. USENIX SEC 2018, pp. 221–238.
[27] J. Goldman, Chinese Hackers Publish 20 Million Hotel Reservation-