(b) Success-num graph: 1
3 List+ 1
3 Markov+ 1
3 PCFG.
(c) Succ-num: 1
3 TarList+ 1
3 TarMarkov+ 1
3 TarPCFG.
(d) Flatness graph: Tweaking-tail.
(f) Flatness: 1
3 TarList+ 1
3 TarMarkov+ 1
3 TarPCFG.
Fig. 5. Evaluating tweaking-tail [35] (under A1) and our two methods (under A3 and A4, respectively) by using seven password datasets.
50% of each dataset is used as training and another 50% as testing. Our methods achieve 0.15-ﬂat under harsh attackers.
(e) Flatness graph: 1
3 List+ 1
3 Markov+ 1
3 PCFG.
ensure an acceptable level of security (i.e., 0.15-ﬂat) while
being reasonably cost-effective as shown in Sec. V-B.
B. Empirical evaluation results
Note that our List method and TarList method will always
yield the same security results as a perfect method under type-
A1 and A2 attackers, respectively. This is because the optimal
attacker needs to employ the List password model PrD(·) to
compute Eq. 3, and the server employs the PrD′ (·) to generate
honeywords, while A’s training set D can only approximate
′.
but will never equal the target site’s password distribution D
This has been empirically shown in Figs. 6 and 3. Thus, we
mainly evaluate our remaining two methods.
3TarMarkov+ 1
To avoid overﬁtting, the datasets used in all above explora-
tory experiments will not be used here. For fair evaluation,
we perform attacks simulating a type-A1 attacker against
tweaking-tail, attacks simulating a type-A3 attacker against
3PCFG, and attacks simulating a type-A4
3Markov+ 1
3List+ 1
1
3TarList+ 1
attacker against 1
3TarPCFG. This is
because each method is designed under a speciﬁed security
model, and it is only sensible to claim some form of security
under that model. Fig. 5 shows that for most of the datasets,
our methods can be 0.15-ﬂat, while this ﬁgure for tweaking-tail
is 0.2+ and actually, our methods are evaluated under much
harsher attackers. Particularly, in our methods there are orders
of magnitude less “low-hanging fruits”(see Figs. 5(b)∼5(c))
that can be obtained by A. In all, our empirical results well
accord with the exploratory experiments, and when setting
k=40, our methods can ensure the security level of 0.15-ﬂat.
Discussion. Fig. 5 shows that
the language, service type
and size of the training/testing datasets all have a signiﬁcant
inﬂuence on honeyword security. This is in line with [53],
[55]. There is no sign from our evaluation results that pass-
words/honeywords from English users are more vulnerable or
secure than those of Chinese users. Moreover, the perceived
risk (service type) of the site will greatly inﬂuence users’
password behaviors. This has been conﬁrmed in password
research [32], [55]. For instance, users on the QNB banking
site (see Table II) have, on average, less-common passwords:
The top 10 most popular passwords only account for 0.59%
of QNB users, while the ﬁgure for the remaining 10 datasets
(in Table II) is 4.16% on average. Thus, the closer the training
set is to the passwords of the target site, the better/ﬂatter the
generated honeywords will be. This explains why adaptive
password/honeyword models are preferable. Results of QNB
in Fig. 5 demonstrate that our adaptive honeyword methods
are suitable for highly sensitive services like Banking.
Overheads. The overall overheads of our methods are low and
acceptable, because: (1) All training, generation and update
processes are conducted on the server side and need no
user interactions/feedbacks, and thus they do not impair user
experience; (2) Training is costly, but it is only conducted
once; and (3) Generation and update processes mainly entail
some table lookups, which is lightweight. For instance, when
k=40 and trained on 32M Rockyou, training costs 70 min on
a common PC; the generation time is 2ms; honeyword storage
for 107 users costs 12.8GB when using PBKDF2-SHA256.
C. Human-based evaluation results
While our methods can provide desirable security against
computer-automated attackers, whether the conclusion still
holds under semantic-aware humans is unknown. This is of
particular concern when considering that,
there are many
semantics in passwords (e.g., bond007 and john1981) that
can be easily recognized by a human being but difﬁcult to
be understood by an automated attacker. Thus, we recruited
11 graduate students who were taking a “network security”
seminar to participate in our evaluation.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:19:56 UTC from IEEE Xplore.  Restrictions apply. 
977
Setups. Before starting the experiments, our participants were
asked to read the honeyword-related literature [21], [24], [35],
and were informed of both Juels-Rivest’s four [35] and our
four honeyword-generation methods. One month later, they
were asked to take a quiz with questions covering various
aspects of honeywords, and all passed. Their expertise enables
them to comprehend all the twelve attacking scenarios inside
out, and to know clues/weaknesses and where and how to
look for them in telling honeywords and real passwords apart.
Hence, they are competent adversaries in our setting. For the
sake of incentive, we specify that, when given a list of k
sweetwords, 1 CNY will be awarded if a participant ﬁnds
the real password with the 1st attempt, 1
2CNY with the 2nd
attempt, and so on. The procedure of human experiments is
established with the help of two usable-security researchers
with survey expertise.
The experiment lasted six consecutive days during a holiday.
On each day, one attacking scenario is accomplished in the
morning and another in the afternoon. During each scenario,
a participant will be given 40 sweetword lists, each of which
includes 20 sweetwords, and participants are asked to ﬁnish
within 30 minutes. This leads to a total consumption of
5280(=40×2×6×11) user accounts (with PII), which are
randomly drawn from the 161,517 PII-associated Dodonew
password accounts (see Table IV). The reason why we choose
Dodonew as the main dataset in this experiment is given in
Appendix E. We had initially attempted to include 40 sweet-
words in each sweetword list (and one scenario costs about 45
minutes), yet feedbacks from the two usable-security experts
signal that this is too fatiguing. The schedule was established
and sent to every participants before the experiment.
In the testing phase, they came to our lab to conduct the
attacks. Each computer stores a dozen of password datasets
that the participant can query, which simulates a basic attacker
with the type-A1 capability. For each attacking scenario, either
the method or attacker type will be different from the other
ones. For a type-A1 attacker, participants are only given 40
sweetword lists. For A2, the common PII of each victim will
be provided; for A3, the order of the sweetword list is just
the order of user registration; for A4, this is the joint case
of A2 and A3. For ethical considerations, all computers are
disconnected from the Internet, no paper or memory device
are allowed for recording, and Email sufﬁx and NID are not
given to the participants to make the users less identiﬁable.
Results. Each sub-ﬁgure in Fig. 9 in Appendix E shows
the ﬂatness curves for all 11 experts (denoted by A to
K) under a given attacking scenario. As summarized in
Table VI, the four methods in [35] achieve 0.40+-ﬂatness
under Type-A1 attacker and 0.48+-ﬂatness under Type-A2
attacker, far from perfect ﬂatness. In comparison, both List
3PCFG methods achieve almost perfect
and 1
ﬂatness (i.e., ϵ≈ 1
20) under non PII-aware attackers. Even when
attackers are PII-aware (i.e., Type-A2 and A4), our corre-
−-ﬂatness. This suggests
sponding methods still achieve 0.09
that our targeted methods can well capture user PII semantics.
3Markov+ 1
3List+ 1
As compared to the four methods in [35], all our four methods
are over 4.5=(0.4023/0.0886) times more secure in terms of
ϵ-ﬂatness. To sum up, results suggest that our methods are
substantially better at resisting human-expert attackers.
Generally, when human experts are not provided with
the victim user’s PII, they are considerably more effective
than computer-automated algorithms (see Table X of [53]).
For instance, when the victims’ PII is not available, human
experts achieve a success rate of 40.23%∼55.00% (with just
one guess) at telling apart real passwords from honeywords
generated by Juels-Rivest’s four methods [35], while the ﬁgure
for computer-automated algorithms is 34.21%∼49.02%. When
human experts are provided with victims’ PII, their advantages
are comparable to PII-enriched computer-automated algo-
rithms. For instance, when the victims’ PII is available, human
experts achieve a success rate of 58.64%∼71.59% (with just
one guess) at telling apart real passwords from honeywords
generated by Juels-Rivest’s four methods [35], while the ﬁgure
for computer-automated algorithms is 56.80%∼67.90%.
ϵ-FLAT INFORMATION UNDER HUMAN ATTACKS.
Honeyword-generation methods
TABLE VI
Tweak tail
Tweak tail
Model-syntax
Model-syntax
Hybrid
Hybrid
Simple model
Simple model
List
TarList
3 PCFG
3 TarPCFG
Attacker type
Type-A1
Type-A2
Type-A1
Type-A2
Type-A1
Type-A2
Type-A1
Type-A2
Type-A1
Type-A2
Type-A3
Type-A4
ϵ-ﬂatness
0.4023
0.5864
0.5500
0.7159
0.4886
0.6023
0.4682
0.6659
0.0568
0.0705
0.0591
0.0886
1
3 TarList+ 1
1
3 Markov+ 1
3 List+ 1
3 TarMarkov+ 1
The human-expert attacks on Dodonew have well shown
that Chinese human attackers are PII-aware in nature, and
since English users and Chinese users show quite similar PII
usage behaviors [55], it is highly likely that attackers in other
languages would have similar performance. Thus, when user
PII is available, honeywords shall be generated with PII.
Summary. Our empirical evaluation builds on 11 large-scale
datasets and considers various attackers. Further, to see how
our methods perform under sematic-aware humans, we con-
duct a user study of 11 trained expert attackers. Results show
that they can survive both automated and human attacks.
VI. CONCLUSION
We have systematically tackled the question of how best
to attack, design and evaluate honeyword-generation methods.
For the ﬁrst time, we provided theoretical proofs and empirical
explorations of how best to attack honeywords. This in-depth
understanding of honeyword attackers enables us to suggest a
suite of honeyword-generation methods by using leading prob-
abilistic password models. We demonstrated the effectiveness
of our methods by conducting both automated experiments and
trained human-expert attacks. In the meanwhile, we addressed
two open problems left in [35] and one in [53].
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:19:56 UTC from IEEE Xplore.  Restrictions apply. 
978
ACKNOWLEDGMENT
The authors are grateful to the shepherd and anonymous
reviewers for their invaluable comments. Ding Wang is the
corresponding author, and part of the work was done while he
was at Peking University. This research was in part supported
by the National Natural Science Foundation of China under
Grant No.62172240. There is no competing interests.
REFERENCES
[1] All Data Breach Sources, Oct. 2018, https://breachalarm.com/all-
sources.
[2] Yahoo Raises Breach Estimate to Full 3 Billion Accounts, By Far Biggest
Known, Oct. 2017, http://fortune.com/2017/10/03/yahoo-breach-mail/.
[3] The Password is Dead, Long Live the Password!, October 2016,
https://www.nccgroup.trust/uk/about-us/newsroom-and-events/blogs/
2016/october/the-password-is-dead-long-live-the-password/.
[4] F. Adowsett, What has been leaked: impacts of the big data breach-
es, April 2016, https://rantfoundry.wordpress.com/2016/04/19/what-has-
been-leaked-impacts-of-the-big-data-breaches/.
[5] S. Agrawal, P. Miao, P. Mohassel, and P. Mukherjee, “Pasta: password-
based threshold authentication,” in Proc. CCS 2018, pp. 2042–2059.
[6] A. Akshima, D. Chang, A. Goel, S. Mishra, and S. K. Sanadhya,
“Generation of secure and reliable honeywords, preventing false
detection,” IEEE Trans. Depend. Secur. Comput., vol. 16, no. 5, pp.
757–769, 2019.
[7] M. H. Almeshekah, C. N. Gutierrez, M. J. Atallah, and E. H. Spafford,
“Ersatzpasswords: Ending password cracking and detecting password
leakage,” in Proc. ACSAC 2015, pp. 311–320.
[8] M. Andrey, Building a Distributed Network in the Cloud: Using Amazon
EC2 to Break Passwords, Aug. 2017, https://blog.elcomsoft.com/
2017/08/breaking-passwords-in-the-cloud-using-amazon-p2-instances/.
[9] A. J. Aviv, D. Budzitowski, and R. Kuber, “Is bigger better? comparing
user-generated passwords on 3x3 vs. 4x4 grid sizes for android’s pattern
unlock,” in Proc. ACSAC 2015, pp. 301–310.
[10] A. Biryukov, D. Dinu, and D. Khovratovich, “Argon2: new generation
of memory-hard functions for password hashing and other applications,”
in Proc. EuroS&P 2016, pp. 292–302.
[11] J. Blocki, B. Harsha, S. Kang, S. Lee, L. Xing, and S. Zhou,
“Data-independent memory hard functions: New attacks and stronger
constructions,” in Proc. CRYPTO 2019, pp. 573–607.
[12] J. Blocki, B. Harsha, and S. Zhou, “On the economics of ofﬂine
password cracking,” in Proc. IEEE S&P 2018, pp. 35–53.
[13] L. Bloomberg, 50 Million MyFitnessPal Accounts Have Been
Hacked, Under Armour Says, March 2018, http://fortune.com/2018/
03/29/myﬁtnesspal-password-under-armour-data-breach/.
[14] J. Bonneau, “The science of guessing: Analyzing an anonymized corpus
of 70 million passwords,” in Proc. IEEE S&P 2012, pp. 538–552.
[15] J. Bonneau, C. Herley, P. Oorschot, and F. Stajano, “The quest to
replace passwords: A framework for comparative evaluation of web
authentication schemes,” in Proc. IEEE S&P 2012, pp. 553–567.
[16] J. Bonneau, C. Herley, P. van Oorschot, and F. Stajano, “Passwords
and the evolution of imperfect authentication,” Commun. ACM, vol. 58,
no. 7, pp. 78–87, 2015.
[17] M. Burnett, Is there life after passwords?, July 2016, https://medium.
com/un-hackable/is-there-life-after-passwords-290d50fc6f7d.
[18] J. Camenisch, A. Lehmann, and G. Neven, “Optimal distributed
password veriﬁcation,” in Proc. ACM CCS 2015, pp. 182–194.
[19] U. N. C. S. Centre, How password deny lists can help your users to
make sensible password choices, April 2019, https://www.ncsc.gov.uk/
blog-post/passwords-passwords-everywhere.
[20] A. Chaabane, G. Acs, and M. Kaafar, “You are what you like!
information leakage through users’ interests,” in Proc. NDSS 2012.
[21] N. Chakraborty and S. Mondal, “Few notes towards making honeyword
system more secure and usable,” in Proc. ACM SIN 2015, pp. 237–245.
[22] R. Chatterjee, A. Athalye, D. Akhawe, A. Juels, and T. Ristenpart,
“Password typos and how to correct them securely,” in Proc. IEEE S&P
2016, pp. 799–818.
[23] C. Cimpanu, 26 million LiveJournal credentials
leaked online,
sold on the dark web, May 2020, https://www.zdnet.com/article/
26-million-livejournal-credentials-leaked-online-sold-on-the-dark-web/.
[24] I. Erguler, “Achieving ﬂatness: Selecting the honeywords from existing
user passwords,” IEEE Trans. Depend. Secur. Comput., vol. 13, no. 2,
pp. 284–295, 2016.
[25] S. Furnell and R. Esmael, “Evaluating the effect of guidance and
feedback upon password compliance,” Comput. Fraud Secur., vol. 2017,
no. 1, pp. 5–10, 2017.
[26] X. Gao, Y. Yang, C. Liu, C. Mitropoulos, J. Lindqvist, and A. Oulasvirta,
“Forgetting of passwords: Ecological theory and data,” in Proc. USENIX
SEC 2018, pp. 221–238.
[27] J. Goldman, Chinese Hackers Publish 20 Million Hotel Reservation-