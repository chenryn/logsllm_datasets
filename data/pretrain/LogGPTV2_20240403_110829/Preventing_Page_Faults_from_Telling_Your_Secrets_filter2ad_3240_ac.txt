OS cannot determine which code and data block was actually used
within the staging area.
Example. For our AES case, we apply deterministic multiplexing
and copy the data table T3 to staging area (See Figure 5). Each
data access now incurs 2 data page copies and a code page copy
followed by multiplexed accesses. Similarly for EdDSA, we can
multiplex the called functions into SAcode (See Figure 6). This
asserts that the OS cannot differentiate whether the true or the false
z = 2*yFalseTrueTrueFalseBB3BB1BB5z != xpath_az < x+10path_bpath_cBB2BB4BB6z = 2*yFalseTrueTrueFalseBB3BB1BB5z != xpath_az < x+10dummy_padpath_bpath_cBB2BB4BB6BB6'BB5'dummy_padTable[idx]	Data	MUX	Selector	P1	P2		Table	1		Data	Staging	Area		Table	1		Figure 6: Deterministic Multiplexing for code page access. The
multiplexer executes the correct function in the staging area.
branch was executed, by looking at the page access proﬁle. Thus, in
both the cases the OS can observe the fetch and execute operations
only at the page granularity. It cannot determine which of the fetch
or execution operations is real and which is replicated.
Compacted Multiplexing. In the multiplexing mechanism, it is
important that both SAcode and SAdata must ﬁt in a single page
each to prevent information leakage. For ensuring this, we speciﬁ-
cally pick a block size such that at any given level in the execution
tree, all the blocks and the corresponding data always ﬁt in a single
page. However, there are cases where the execution tree is deep and
has large number of blocks (total size of more than 4096 bytes) at a
certain level. This results in a multi-page staging area. To address
this, we use a compaction scheme to ﬁt the staging area in a single
page. Speciﬁcally, in the fetch phase we create a dummy (not real)
block address in the staging area. The blocks which are not going
to be executed are saved at this dummy location during the fetch
step. Each new block from the execution tree overwrites (overlap)
the same location. Only the real block (which will be executed) is
copied in a non-overlapping address in the page. We term this as
a smart copy because each copy operation writes to either dummy
or real page-offset in the staging area. The adversary OS does not
see the offset of the faulting address, and hence cannot distinguish
a dummy vs. a real copy. Thus the staging area always ﬁts in a
single page. The semantics of the execute phase are unchanged.
4.3 Compiler-enforced Transformations
We build our design into the compiler tool chain which works on
a subset of C / C++ programs. Given a program, the programmer
manually annotates the source code to demarcate the secret input to
the program and speciﬁes the size of input with respect to which the
transformation should guarantee PF-obliviousness. Speciﬁcally, he
manually adds compiler directive begin_pf_sensitive and
end_pf_sensitive to mark the start and end of sensitive code
and data. For example, the developer can mark the encryption rou-
tine, decryption routine, key derivation, key, nonce, and so on as
secret. Our tool comprises of analysis and transformation steps to
enforce deterministic multiplexing which are discussed next.
Identifying Sensitive Code and Data. In the ﬁrst step, our com-
piler front-end parses the source code and identiﬁes the program-
mer added directives. It then performs a static analysis which tran-
sitively marks all the instructions and variables within the lexi-
cal scope of programmer-marked sensitive code as high. Non-
sensitive instructions and variables are marked as low. At the end
of the phase, each instruction and variable in the code has a sensi-
tivity tag (high or low).
Determinising the Page-layout. Next, our tool performs an anal-
ysis to decide the new virtual address layout for the sensitive data
and code (marked as high) for placing them in the staging area.
The initial step is to identify the existing execution tree of the sen-
sitive code. To achieve this, we create a super-CFG wherein each
function call is substituted with the body of the function and all the
bounded loops are unrolled. This creates an execution tree such
that all the sensitive execution blocks are identiﬁed. We seek a
mapping Γ : B (cid:55)→ L such that all the execution blocks at the same
level in the execution tree are relocated to the same virtual page
address. There are multiple possible Γ mappings which yield ac-
ceptable layouts, but our goal is to select the one where the code
and data staging areas always ﬁt in a single page. We ﬁrst try to use
the basic multiplexing for arranging the blocks if the total size of
all the blocks at a level is less than 4096 bytes. If the size of the re-
quired staging area exceeds one page, then we resort to compacted
multiplexing (See Section 4.2).
Instruction Rewriting. The last step of transformation comprises
of: (a) Adding logic for multiplexing (b) Adding prologue-epilogue
before and after the multiplexing to move the code / data to and
from staging area. Next, we rewrite the instructions to introduce
replicated accesses to data pages, and instrument each execution
block with a call to the code multiplexing logic as described in
Section 4.2. Finally, we add prologue and epilogue before and after
each execution block at each CFG level.
Example. In case of EdDSA, we manually add compiler pragmas
to mark the user key variable and the signing routine as sensitive.
Our analysis phase identiﬁes 31 functions, 701 execution blocks,
178 variables as sensitive. It also collects information about the
call graph, function CFG and access type (read or write) of the
variables. After the analysis, our tool calculates (a) the staging
area to be created in ﬁrst function ec_mul just before the ﬁrst
access to the key (b) layout of the data staging area such that all the
variables ﬁt in one page (c) the alignment of the execution block
in the staging area, (d) the new addresses of the sensitive variables
used in these execution block, and (e) instructions which are to be
updated for accessing the staging area. Finally, we add code for
preparing the staging area and instrument the code instructions to
use the data staging area values.
Security Invariant. The above compiler transformation ensures
that for the output program, all the execution blocks at the same
level in the execution tree are mapped to same ordered list of virtual
address locations. Thus for all the inputs, the program exhibits
the same page access proﬁle hence satisfying our PF-obliviousness
property.
5. DEVELOPER-AIDED OPTIMIZATIONS
Apart from the compiler enforced transformation, we have man-
ually conﬁrmed other strategies to make programs PF-oblivious.
We discuss these strategies which allow developer-aided optimiza-
tions. In the future, our compiler can be extended to search and
apply these optimization strategies automatically.
5.1 Exploiting Data Locality
The main reason that input-dependent data accesses leak infor-
mation in pigeonhole attacks is that the data being accessed is split
across multiple pages. In all such cases, the deterministic multi-
plexing repetitively copies data to and fro between the staging area
and the actual data locations. There are two key observations spe-
ciﬁc to these cases.
O1: Eliminating copy operations for read-only data. We ob-
serve that most of the table lookup operations are on pre-computed
data and the code does not modify the table entries during the entire
execution. Since these sensitive data blocks are used only in read
operations, we can fetch them into SAdata and discard them after
the code block executes. This saves a copy-back operation per code
block. Moreover, if the next code block in the execution tree uses
the same data blocks which already exist in SAdata, then we need
not copy them to SAdata. This save all the copy operations after
the data is fetched into the SAdata for the ﬁrst time. In case of
r[i] == 1 or 0 add_points{..} Code MUX Selector P1 P2 ec_mul {…} Code Staging Area add_points{..} ec_mul {…} Figure 7: (a) Simpliﬁed page access proﬁle for powm (Window size = 1) where A0, A1, A2, A3 denote transitions between mul_mod(),
powm(), set_cond() and karatsuba_release() respectively (b) Call graph before enforcing deterministic multiplexing. (c) Alignment
after optimization (O4) where dotted and shaded functions are moved to separate code staging pages.
Algorithm 1 Libgcrypt modular exponentiation (powm).
INPUT: Three integers g, d and p where d1...dn is the binary representation of d.
OUTPUT: a ≡ gd (mod p).
procedure P O W M (g, d, p)
(cid:46) P1
w ← GET_WINDOW_SIZE(d), g0 ← 1, g1 ← g, g2 ← g2
for i ← 1 to 2w−1 − 1 do
g2i+1 ← g2i−1 · g2 mul_mod p
(cid:46) Precomputation
end for
a ← 1, j ← 0
while d (cid:54)= 0 do
j ← j+ COUNT_LEADING_ZEROS(d)
d ← SHIFT_LEFT(d, j)
for i ← 1 to j + w do
a ← a · a mul_mod p
end for
t ← d1...dw;
j ← COUNT_TRAILING_ZEROS(t)
u ← SHIFT_RIGHT(t, j)
gu ← FETCH_POWER(set_cond(u))
a ← a · gu mul_mod p
d ← SHIFT_LEFT(d, w)
end while
end procedure
(cid:46) Outer loop
(cid:46) Inner Loop
(cid:46) P2
(cid:46) P3
(cid:46) P2
AES, we require only two operation to copy T able1 from P1 and
P2 to SAdata. We can apply the same strategy to T able3, so that
the entire execution needs only four copy operations.
O2: Page Realignment. All the data blocks which are spread
across page boundaries (speciﬁcally, S-Boxes) can be grouped to-
gether and realigned at the start of the page. This ensures that the
set of sensitive data pages is minimum for the entire execution.
In the context of AES example, both T able1 and T able3 cross
the page boundary and use 3 pages. They can be aligned to page
boundary and ﬁt in 2 pages. Thus for deterministic multiplexing,
the patch will incur only two copy operations in total.
Note that the above strategies are safe and respect the security
invariant (Section 4.3) because all the eliminations are independent
of the input and thus the reduction in the copy operations affects all
the inputs uniformly.
5.2 Exploiting Code Locality
In case of input-dependent control transfers, automatically deter-
minising the control ﬂow results in a high number of multiplexing
operations. To address this short-coming we propose a set of strate-
gies speciﬁc to the type of pigeonhole attacks, which reduces the
overheads to an acceptable range. We take the example of powm
and demonstrate our strategies.
Algorithm 1 shows the code structure and data access pattern
for the powm example. In the Libgcrypt implementation, the actual
function body (powm), the multiplication function (mul_mod) and
the table lookup function (set_cond) are located in three sepa-
rate pages say P1, P2, P3 respectively. Hence, the leakage from
powm is due to the different fault patterns generated from calls to
mul_mod and set_cond functions. Figure 7 (a) shows the page
fault pattern for powm with respect to these functions and Figure 7
(b) shows the function arrangement for powm. Let us consider the
implementations of deterministic multiplexing in Section 4.3 that
make calls to both these functions indistinguishable. For this, we
generate the call graphs of both functions which identiﬁes the set
of sensitive functions are to be masked. For each call to any of
these sensitive function, we perform a multiplexing operation. It
iterates over the set of these sensitive functions in a deterministic
manner and copies all the blocks to SAcode. The multiplexer then
selects the correct block and executes it. In case of powm, we move
powm, mul_mod and set_cond to the staging area. This imple-
mentation of Section 4.3 incurs an overhead of 4000×, which is
prohibitive. We discuss our strategies in the context of this exam-
ple to describe the reasoning for the optimization.
O3A: Level Merging. The dominating factor in the deterministic
multiplexing is the number of copy and multiplexing operations at
each level in the execution tree. We observe that by the virtue of
code locality, code blocks across multiple levels can be merged to-
gether in a single level. Speciﬁcally, we place the code blocks such
that the caller and callee function are contained within a page. For
example, consider 3 code blocks a, b, c located in three separate
pages. The call graph is such that c is called by both a and b. If
total size of a, b, c put together is less than a page (4096 bytes),
then we can re-arrange the code such that all three of them ﬁt in a
single page. In terms of the execution tree, it means that we fold
the sub-tree to a single code block.
O3B: Level Merging via Cloning. The above strategy will not
work in cases where the code blocks in a sub-tree cannot ﬁt in
a single page. To address this, we use code replication i.e., we
make copies of shared code block in multiple pages. In our exam-
ple, if blocks a, b, c cannot ﬁt into a single page, we rearrange
and replicate the block c in both P2 and P3. After replication, a
control-ﬂow to c from neither a nor b will incur a page fault. For
powm, we split the mul_mod into 2 pages and replicate the code
for set_cond. Thus, call to from powm to set_cond can be
resolved to either of the pages. It is easy to see that since secu-
rity guarantee of the compiler-transformed code holds true for the
un-optimized program execution tree, it trivially holds true for the
reduced trees in the above two cases because O3A-B are replicating
or merging the page access uniformly for all the inputs.
O4: MUX Elimination. Our next optimization is based on the
insight to eliminate the cost of the multiplexing operation itself by
rearranging the code blocks. To achieve this, we place the code
blocks in the virtual pages to form an execution tree such that all
the transitions from one level to the other exhibit the same page
fault. This eliminates the multiplexing step altogether. In the above
example of blocks a, b and c, we place a and b into one page and
c into another. Thus, the control-ﬂow from both a and b to c will
page fault in both the cases or none at all. We can chain successive
transitions for multiple levels in the tree, such that all the blocks in
powm	mul_mod	karatsuba_release	set_cond	karatsuba_case	mpih_divrem	mpih_mul																mul_N											mul_N_basecase														Arithme8c	Opera8ons	(addi8on,	subtrac8on,	shi<)	powm	mul_mod	karatsuba_release	set_cond	karatsuba_case	mpih_divrem	mpih_mul	mul_N											mul_N_basecase	Arithme8c	Opera8ons	(addi8on,	subtrac8on,	shi<)	Table 1: Summary of cryptographic implementations susceptible to pigeonhole attacks. ∗ denotes that the leakage depends on the
input. [a : b] denotes the split of S-Box where a and b is percentage of table content across two different pages.
Input Bits Leakage
(gcc)
128, 192,
% Leakage
(llvm)
14.01
2.34
4.69
6.25
0.78
6.25
8
2
*4
32
4
32
25
3
*6
32
4
32
512
256
400
2048
2048
128
128
512
100
512
*160
*238
*1245
*1247
2
16
Average
62.50
59.50
60.79
60.89
1.56
12.50
28.02