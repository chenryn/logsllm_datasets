in its capability to defend against OS-level adversary. All o-line
payment schemes rely on the secret stored on the mobile device,
which is often protected through hardware means. For example,
Apple Pay uses the secure element to store payment secret and
runs the payment process within its secure enclave. Samsung Pay
leverages its KNOX (built upon top of ARM trust-zone) to protect
the payment information in its secure element. They can all mitigate
the threat from the OS-level attackers, since the payment secret
stays within the hardware component the OS cannot directly access.
For the payment schemes not provided by the device manufacturers,
like PayPal, Alipay, etc., the hardware level protection is not in place
and can therefore only trust the OS to protect the payment process.
Once the OS is compromised (particularly on rooted or jail-broken
devices), the adversary can then get access to the payment secret to
generate legitimate payment token to steal from the victim. Actually,
during our research, we analyzed AliPay on a jail-broken device
and successfully extracted the secret.
Even if the mobile OS is not tampered, a recent study showed
that a malicious app is able to extract payment token during the
o-line payment scenario [8]. In particular, the reection of the QR
code will appear on the glass of POS scanner when user’s mobile
device comes close, and the malicious app can sni it by taking a
picture of the scanner glass.
2.3 Adversary Model
An o-line payment transaction involves four actors: the payer,
the OS, the vendor and the payment provider. In our research, we
assume the provider to be trusted and collaborative, willing to
protect the payer’s account and her transaction privacy, while the
software and the vendor are considered to be less trusted, each with
dierent capabilities. However, we do not assume they collude.
Curious vendor. More specically, we consider that the vendor
is curious but honest. He can save a photo of the screen of payer’s
phone, during the QR code scan, by reprogramming2 or customiz-
ing his scanner. However, we do not assume that he can acquire the
secret within the payer’s phone, including the payment secret and
other information for generating the protection for the screen (Sec-
tion 4). We neither assume he can get or set the internal status of
the POS (scanner is outside the POS and is controlled by the vendor).
In the meantime, we assume that he does not attempt to directly
steal money from the payer, an attempt that can be detected by the
provider (e.g., overcharging the payer for the purchased item).
Instead, the malicious intent of the vendor is to benet from
tracking or helping a third party track the payer’s purchase activi-
ties. It is undoubted that purchasing activity logs are valuable to
Figure 3: O-line QR code payment ow chart.
2Some scanner manufacturers provide programming guide to help vendor modify the
logic of the scanner[3].
79
SecretTimeUser IDAlgorithmTokenTokenAPPTokenPOSServerUser IDDBTimeSecretAlgorithmCompareTokenAccept/RejectACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Zhe Zhou et al.
merchants who are eager to know what their customers bought, re-
turned and what they might be interested. Starbucks, a well known
Apple friendly brand, hesitated to support Apple pay before 2016
because Apple pay is too anonymous [1]. On the other hand, we
assume the input to the tracking technique here is limited to the
screen image containing QR code (e.g., we assume the vendor does
not take a picture of buyer and use it for tracking).
Note that there are situations where the payment is done overtly,
without hiding the payer’s identity. Prominent examples include
purchasing through membership card. In these cases, the identity
information proactively provided by the payer enables the vendor
to not only link her transactions together across dierent stores
within the same organization, but also connect her behaviors across
organizations, should the vendor decide to sell the identity with
purchase information to a third party like the advertiser, which
results in unexpected privacy leakage (imagine a restaurant learns
what you’d like to order according to your Walmart’s history) .
However, the o-line scheme like the QR pay is designed to provide
the payer option to remain anonymous.
Untrusted OS. The OS in our model is untrusted, which can
be completely under the control of the adversary who not only
can get access to the secret of the victim’s wallet but can also
learn other information, for example, the secrets for creating screen
masks (Section 4). Further, the adversary also tries to acquire the
ngerprint of the device, though she cannot directly observe it from
the software of the device.
As mentioned before, the QR code payments like the one used
by Paypal do not have a secure container for the payment secret in
the phone, and only ask the OS to protect the secret, so when the
OS is compromised, everything is exposed to the adversary, except
the hardware features of the screen that cannot be directly “seen”
from the software stack of the system. With the wallet secret, the
adversary can generate a valid token and QR code (Section 2.2), by
using the same algorithm (which we assume is public) and time
information, for o-line payment.
Our assumption of untrusted OS is practical for the mobile pay-
ment scenario. Not all Android phone manufactures are prompt in
pushing updates to their users, resulting in a fragmented Android
eco-system with a lot of vulnerable devices open to attackers. Re-
cent attacks also showed that attackers can easily get the token of
the payment [6] with the help of vulnerable OS components.
3 SCREEN FINGERPRINTING
Our research shows that unique physical features of smartphone
screens can be used to identify them and defend against adversary
who has even obtained the payment secret. Extraction of these
features, however, is nontrivial, due to the impact of projective
distortions introduced when the screen is scanned by the camera.
In this section, we present a technique that addresses the issue
and ngerprints a screen using the image that can be conveniently
taken during a payment scan.
3.1 Overview
Firstly, we briey show how the screen ngerprint protects users
from secret key leakage if only the device is not physically acquired
by the attacker. At the registration phase, a photo of the screen
80
should be securely uploaded to the server, with which the server
can extract a piece of ngerprint. Every time a transaction happens,
the server not only veries if the QR code token is correct, but
also compares the ngerprint from the scanned photo against the
one collected at the registration phase. The transaction can only be
approved if the QR code and the ngerprint are both correct.
Our scheme does not protect users whose OSes are compromised
before registration. But if the registration phase is safe, even when
the OS is compromised thereafter, the attacker will fail to launch the
attack. When the attacker controls OS, she can acquire the secret
key for QR code generation with the acquired privilege. However,
there is no way for her to acquire the authentic screen ngerprint,
so the check of ngerprint comparison will fail and the server will
be notied.
3.2 Photo Extraction and Correction
Figure 4: Fingerprint visualization.
Figure 4 visualizes the luminance ngerprint of a screen, which
is illustrated through distortion correction, blurring and contour
drawing. This ngerprint can be picked up by the POS camera when
it is positioned at a right distance and angle toward the screen. What
is expected is that the screen is in parallel with the camera lens,
with its center right under the camera. In practice, hardly can this
be done perfectly by a payer, as illustrated in Figure 2, even when
a POS system is calibrated to identify the QR code shown on the
screen (with the code boxed by a square visualized to the party
who scans). As a result, the images snapped by the POS camera are
often distorted, which brings in the trouble to eective extraction
and comparison of ngerprints (distortion may make one phone
similar to another). Following we elaborate how this challenge is
addressed in our research through proper corrections.
Distortion correction. The picture of a screen taken by POS can
be viewed as a projection from the screen plane to the camera per-
spective plane (as they are not parallel), with an unknown angle
(see Figure 5). Most important to the distortion correction is to iden-
tify the angle. For this purpose, we come up with a new approach
that leverages the QR code on the screen as a reference to realign the
whole image through a projective transformation, which turns out
to be very eective in recovering the distorted screen ngerprint.
Specically, we consider that the phone screen sits on a display
plane (D). When its picture is taken, the screen image is projected
from D to a shooting plane (S), which is distorted. Our goal is
to project the image from S to a correction plane C parallel to D,
through a projective transformation (T).
Solving a projective transformation that perfectly reverts the
distortion requires the positions of at least 4 dierent points on S
Beware of Your Screen
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
on S are aligned to C while their relative location to the four mark-
ings are preserved. This process can be done using the standard
projective transformation solving method [5].
3.3 Fingerprint Extraction & Comparison
Fingerprint extraction. To get a clean ngerprint from the trans-
formed picture, we rstly applied noise cancellation techniques.
We applied a radius 2 gaussian lter to the photo to remove the
high frequency noise. Then we extract the luminance level after
grayscaling the photo.
After that, a ngerprint of a screen is generated as a matrix of the
luminance for each pixel (0 to 255). To visualize the screen features,
we use contours to connect the pixels with similar luminance levels
and then run Gaussian Blurs to smooth out the images. The right
image in Figure 4 is the ngerprint for the screen image on left.
Fingerprint comparison. Once the a ngerprint it extracted,
we need to compare it with other ngerprints to determine if the
screen has been seen before. For this purpose, we utilize the Pearson
product-moment correlation coecient to measure the similarity of
two ngerprints. The correlation coecient is chosen since it mea-
sures the distance between two vectors based upon the similarity of
the relations among the elements within each individual vector. This
allows us to overcome the dierences in the absolute brightness
values for the same pixel observed under various light conditions.
Specically, given two ngerprints, which are two matrices with
each element being either the brightness level of a pixel (100 to
255) or of 0 if the value of the element is removed during the dis-
tortion correction (border or virtual button) phase, we rst convert
these matrices into two vectors   and  0, through concatenating
their rows together, sequentially. Then we remove the elements
from individual positions within   and  0 if at least one of them
in that position is 0. After that, our approach compares   and  0
by calculating the Pearson product-moment correlation coecient.
The result needs to be adjusted by the dierence in the numbers
of “eective elements” in these two vectors, that is, those not being
removed (non-zero in value). This is important because the dier-
ence in vector lengths should also be taken into consideration in
the similarity measurement, but our previous steps dropped this
information. Let d be such a dierence between the two matrices
and e be the total number of non-zero elements copied to vectors.
The similarity between two ngerprints,  , is calculated as follows:
  = (1  
d
e )CorrCoe f ( , 0)
The similarity value is then compared to a threshold to determine
whether the two ngerprints belong to the same phone.
4 ANONYMOUS SCREEN AUTHENTICATION
While our ngerprinting technique could protect the user against
adversary who attempts to steal payment token and spares it with
another device, it also enables unwanted user tracking. In this
section, we describe our design of AnonPrint, which obfuscates a
screen with a digital brightness mask to prevent the linking across
payment transactions, while still enabling an authorized party to
authenticate the owner of the screen.
Figure 5: Projective distortion illustration. The three images
are considered to be on three planes (D, S and C) respectively.
Figure 6: Bullseyes locating algorithm.
and their counterparts on C. It turns out the four “bullseyes” of QR
code can be treated as the 4 markings. The “bullseyes” (see Figure 6)
are used by the decoding program to locate the QR code, including
three positioning markings to identify the direction of the code,
and an alignment marking to help with orientation. Specically,
we rst extract the coordinations of these “bullseyes” on S using
standard QR decoding algorithm and then map them to the middle
of a rectangle (0, 0) to (1800, 1080) of C, to obtain the transformation
parameters.
The above approach works when the coordinates of all four
“bullseyes” are correctly detected. However, these coordinations
cannot be obtained when QR decoding algorithm fails. To extract
ngerprint in this case (for multiple scan cases described later),
the coordinations are inferred from the screen picture using the
algorithm described below:
(1) Our approach extracts rectangles by identifying all quadri-
laterals from the picture and removing those quadrilaterals
unlikely to be foursquares. Tools like regionprops of Matlab
Image Processing Toolbox can achieve this goal.
(2) Within the rectangles, our approach further selects the triples
with their centroids forming an isosceles right triangle (ap-
proximately, due to the distortion). Oftentimes, this process
will discover a triple that consists of the top-left, the top-
right and the bottom-left bulleyes, as illustrated in Figure 6
middle.
(3) Finally, we look for a quadrilateral (the alignment mark)
whose centroid is approximately on the mid-perpendicular
of the right angle side of the isosceles we just found. The
quadrilateral should be moderately far from the right angle
vertex, which is shown in Figure 6 right.
Screen image recovery. Using the coordinates of the four bullseyes,
we can perform projective transformation to project the screen
image from the shooting plane S to the corrected plane C with
distortion eliminated. In essence, all the pixels within the image
81
Original      1)2)      3)Position MarksAlignment MarkACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Zhe Zhou et al.
Figure 7: Overview of AnonPrint.
4.1 Overview
Figure 7 illustrates the framework of AnonPrint and the payment
process that supports this anonymous screen authentication. The
framework is built upon the existing o-line payment system, with
only moderate changes made to the wallet app, POS scanner and
the service on the payment provider side. More specically, the
payer rst needs to submit the original screen ngerprint of her
device to the payment provider when she opens an account. The
wallet app is modied to synchronize a secret random seed with the