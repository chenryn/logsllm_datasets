mance on recall. The input of the sequential-based baselines Scores method (pHMMrep.) (CVrep.) combined) (TFILF)
haslargerentropywhichchallengesthediscriminationagainst RF 0.74±0.0 0.86±0.01 0.86±0.01 0.84±0.05
DT 0.74±0.0 0.78±0.04 0.78±0.03 0.84±0.08
normal sequences, leading to many of them being detected as F1 LR 0.72±0.0 0.86±0.0 0.87±0.0 0.8±0.1
failures, i.e., increasing the false positives. Comparing CLog AdaBoost 0.69±0.0 0.86±0.02 0.87±0.02 0.62±0.12
RF 0.74±0.0 0.86±0.01 0.86±0.01 0.83±0.05
against the quantitative-based method (PCA) leads to good DT 0.74±0.0 0.78±0.04 0.78±0.03 0.82±0.07
Precision
LR 0.71±0.0 0.85±0.0 0.87±0.0 0.77±0.08
performance in precision but reduced recall. The count vector
AdaBoost 0.71±0.0 0.86±0.02 0.86±0.02 0.59±0.13
representation and the limited modeling power of PCA (as a RF 0.75±0.0 0.87±0.01 0.87±0.01 0.86±0.06
DT 0.75±0.0 0.81±0.04 0.81±0.03 0.85±0.07
linear model) are potential causes for the incorrect detection Recall
LR 0.73±0.0 0.88±0.0 0.89±0.0 0.88±0.11
of the true failures. Notably, from an economic perspective, AdaBoost 0.73±0.0 0.87±0.02 0.88±0.02 0.74±0.14
the observed improvements are significant because improving
2) RQ2: How effective is CLog for the problem of failure
failure detection by even 0.1% in F1 score can save hundreds
type identification?: This RQ evaluates the capability of the
of thousands of dollars [9].
FTI module of CLog to reuse the historical information from
The improved performance of CLog against the two com-
the operator in detecting different types of failures. Specif-
monly used developer practices, i.e., log level (by 24% on
ically, we evaluate three representations of the subprocess
F1) and single line semantic-based approach, is mainly due
sequences for CLog (1. probability score from the HMM
to the problem of insufficient logging failure coverage. The
(pHMM), 2. count vectors (CV), and 3. combination of both)
semantic-based baseline is constructed based on the expert
against LogClass [4] as a baseline. LogClass uses single logs
as input. We randomly sample 60% of the labeled failure
1The code and the data are given in the GitHub repository of the project
https://github.com/context-aware-Failure-Identification/CLog.git sequences/logsfromtheoriginaldatasettotrainthemulticlass
using the synthetic dataset generation procedure previously
PCA DeepLog CLog
F1 Precision Recall described. TABLE IV shows the results. CLog’s detection
1.0 1.0 1.0 method preservers high detection performance even under a
high ratio of unstable sequences. The results demonstrate that
0.8 0.8 0.8 theextractedsubprocessesaresufficientlysensitivetothelocal
changes within the log sequences, making the performance
0.6 0.6 0.6
robust.
0.4 0.4 0.4
TABLEIV
0.2 120s180s240s300s0.2 120s180s240s300s0.2 CLOGFAILUREDETECTIONEVALUATIONONSYNTHETICDATA
60s 60s 60s 120s180s240s300s
window size window size window size
injectionratio F1 Precision Recall
Fig.6. Impactofthewindowsizeoverthedetectionperformance. 5% 0.94 0.97 0.91
10% 0.92 0.95 0.89
15% 0.90 0.95 0.86
20% 0.88 0.94 0.83
model, while the remaining 40% are used for evaluation.
To reduce the bias due to the sampling, we repeated the
experiments 30 times. We report the average performance V. RELATEDWORK
scoresandtheirstandarddeviationoverthedifferentmethods, Failure Detection. There are plenty of works considering
evaluating the representations independent of the methods. the problem of log-based failure detection. Considering the
TABLE III enlists the results of the three different repre- assumption of whether log labels are available or not, the
sentations of CLog and the baseline on the FTI subproblem. methods are categorized into: unsupervised and supervised.
The analysis of the three representations by CLog suggests We first discuss the unsupervised methods. They are consid-
thatthecombination(CV+pHMM)achievesthebestF1score. ered practically useful because they do not require labels [2].
Predominantly, the improvement originates from the count Predominantly, these are one-class methods modeling the
vectors, seen by the better individual results in comparison normalsystemstateandreportingfailureswhensignificantde-
with pHMM. Finally, the combination (CV+pHMM) of CLog viationsoccur.Yamanishietal.[17]introduceanunsupervised
outperforms the baseline LogClass. LogClass uses single logs sequentialmethod forfailure detectionthat usesHMM onlog
to identify the type of failures. Therefore, if the failure is event sequences to model the normal state. The probability
not explicitly logged, LogClass cannot identify its type. On under the HMM is used as a normality score. DeepLog [11]
the contrary, CLog considers the occurrence of the individual trains a neural network – LSTM on sequences of log events
subprocesses and can represent discriminative patterns among on the auxiliary task of next event prediction. If the output
the types of failures improving the performance. prediction of the auxiliary task is wrong, the method reports
3) RQ3:Howdoestheentropyofthesequencesinfluence failure. LogAnomaly [24] is similar to DeepLog, but further
thefailuredetectionperformanceindependentofthemodel?: augments the input of DeepLog with semantic and count-
With this question, we verify the impact of the unstable log based features. Another popular method is PCA [22]. It is
event sequences over the failure detection performance in a a reconstruction-based method that constructs subspace from
model agnostic manner. Following our key observation given the count vectors of the normal log event sequences and uses
inSectionII-B,wegroupedtheinputeventsintotime-intervals the reconstruction error to detect failures. Compared to other
of increasing window size and evaluated several models of methods that do not directly address the problem of unstable
CLog, DeepLog, and PCA similarly as in RQ1. The best sequences, CLog addresses it by representing the sequences
averageperformanceofCLogaveragedoverthewindowsizes of log events with sequences of subprocesses. The semantic-
(not individual as in RQ1) is obtained for 30 subprocesses. based methods use the semantics of the single logs to identify
Fig. 6 shows the results. It can be observed that as the failures. Despite the traditionally used approaches in industry,
window size increases, the detection performance decreases. like keyword search (e.g., search for ”error”) or log level
Paring the average entropy over the sequences for different search [5], another line of works learns properties of failure
window sizes (see Fig. 2) with the detection results reveals logs. One such example is Logsy [10]. It combines labeled
a negative correlation between the increased entropy and data from other software systems and a hyperspherical loss
failuredetectionperformance.Owningtothegreatermodeling whenlearningthediscriminativepropertiesofthefailures.The
power CLog, and DeepLog show a relatively lower drop in semantic baseline we considered assumes that methods like
performance in the range 4-5%. In comparison, PCA has a Logsy perform ideally, thereby, we do not directly compare
performance drop between 8-50%. Importantly, CLog outper- with it. These methods are unable to detect failures that not
formsDeepLogbecauseofthesmallerinstabilityintheinput. explicitly are logged. By modeling sequences, CLog detects
4) RQ4: How robust is CLog on the problem of failure contextual failures when abrupt changes in the normality
detection?: We conduct experiments on the synthetic dataset. contexts of the co-occurring events occur.
The failure detector was trained on the original data as in Supervised methods assume the availability of labels for
RQ1. We randomly inject b−percentages unstable sequences logs from the target system. LogRobust [8] uses a sequential
representation of the input to train a deep learning neural [2] S. He, J. Zhu, P. He, and M. R. Lyu, “Experience report: System log
network – LSTM augmented with an attention mechanism to analysisforanomalydetection,”inProc.ofthe27thIEEEInternational
SymposiumonSoftwareReliabilityEngineering,2016,pp.207–218.
learnfailuresequences.Othermethods,suchasSVM,decision
[3] S. He, P. He, Z. Chen, T. Yang, Y. Su, and M. R. Lyu, “A survey on
trees,logisticregressionandnearestneighbours,arealsobeing automatedloganalysisforreliabilityengineering,”ACMComput.Surv.,
considered [25]. Due to the evolution of logs and their large vol.54,2021.
[4] W. Meng, Y. Liu, S. Zhang, F. Zaiter, Y. Zhang, Y. Huang, Z. Yu,
volumes, the expensiveness of labeling is referenced critique
Y. Zhang, L. Song, M. Zhang, and D. Pei, “Logclass: Anomalous log
to supervised methods, questioning their usability [2]. identificationandclassificationwithpartiallabels,”IEEETrans.Netw.,
Failure Type Identification. In one of the earliest works, vol.18,pp.1870–1884,2021.
[5] Q. Lin, H. Zhang, J.-G. Lou, Y. Zhang, and X. Chen, “Log clustering
Oliner et al. [26] use keyword search of common words
based problem identification for online service systems,” in Proc. of
(e.g., ”interface failure”, ”error”, and similar) to identify the38thInternationalConferenceonSoftwareEngineeringCompanion,
different types of failures within single logs of four different 2016,p.102–111.
[6] X. Zhang et al., “Robust log-based anomaly detection on unstable log
supercomputer systems. Similarly, Meng et al. [27] use single
data,” in Proc. of the 27th ACM Joint European Software Engineering
log lines represented as bag-of-words, alongside the Random ConferenceandSymposiumontheFoundationsofSoftwareEngineering
Forest method to classify different types of system logs. Log- (ESEC/FSE),2019,p.807–817.
[7] S. He, Q. Lin, J.-G. Lou, H. Zhang, M. R. Lyu, and D. Zhang,
Class [4] introduces TF-ILF as a novel representation method
“Identifying impactful service system problems via log analysis,” in
for individual logs and applies commonly used multiclass Proc.ofthe26thJointEuropeanSoftwareEngineeringConferenceand
classification methods to categorize the type of failure. A SymposiumontheFoundationsofSoftwareEngineering,2018,p.60–70.
[8] Z.Chen,J.Liu,W.Gu,Y.Su,andM.R.Lyu,“Experiencereport:Deep
common drawback of these approaches is the assumption
learning-basedsystemloganalysisforanomalydetection,”CoRR,vol.
of full failure coverage in single logs. However, due to the 2107.05908,2021.
problem of insufficient logging coverage within the source [9] Y.Zhu,W.Meng,Y.Liu,S.Zhang,T.Han,S.Tao,andD.Pei,“Unilog:
Deployonemodelandspecializeitforallloganalysistasks,”2021.
code [3], this may not always be the case. Different from
[10] S.Nedelkoski,J.Bogatinovski,A.Acker,J.Cardoso,andO.Kao,“Self-
others, we pair count vectors from the subprocesses of a attentive classification-based anomaly detection in unstructured logs,”
given sequence with a multiclass classifier to use the past CoRR,vol.abs/2008.09340,2020.
[11] M.Du,F.Li,G.Zheng,andV.Srikumar,“Deeplog:Anomalydetection
information about similar failure types.
anddiagnosisfromsystemlogsthroughdeeplearning,”inProc.ofthe
ACM SIGSAC Conference on Computer and Communications Security
VI. CONCLUSION (CCS),2017,p.1285–1298.
[12] D. Cotroneo, L. De Simone, P. Liguori, R. Natella, and N. Bidokhti,
This paper addresses the problem of the automation of log- “Howbadcanabugget?anempiricalanalysisofsoftwarefailuresinthe
based failure identification, which is a crucial maintenance openstackcloudcomputingplatform,”inProceedingsofthe201927th
ACMJointMeetingonEuropeanSoftwareEngineeringConferenceand
task to enhance the reliability in cloud systems. It introduces
Symposium on the Foundations of Software Engineering. New York,
anovelmethodCLog,whichdecouplestheproblemoffailure NY,USA:AssociationforComputingMachinery,2019,pp.200–211.
identification into two subproblems 1) failure detection and [13] J.Zhu,S.He,J.Liu,P.He,Q.Xie,Z.Zheng,andM.R.Lyu,“Toolsand
benchmarksforautomatedlogparsing,”inProc.ofthe41stInternational
2) failure type identification. We observe that by representing
ConferenceonSoftwareEngineering:SoftwareEngineeringinPractice
the input log data as sequences of subprocesses instead of (ICSE-SEIP),2019,p.121–130.
sequencesofindividualevents,theentropyintheinput,caused [14] P.He,J.Zhu,Z.Zheng,andM.R.Lyu,“Drain:Anonlinelogparsing
approachwithfixeddepthtree,”in2017IEEEInternationalConference
by the unstable logs, is reduced. CLog uses this observation
onWebServices. NY,USA:CurranAssociates,2017,pp.33–40.
and introduces a novel subprocess extraction method, which
[15] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “BERT: Pre-
jointlytrainscontext-awaredeeplearningandclusteringmeth- trainingofdeepbidirectionaltransformersforlanguageunderstanding,”
inProc.ofthe2019ConferenceoftheNorthAmericanChapterofthe
odstoextractsubprocesses.Ourexperimentsdemonstratethat
AssociationforComputationalLinguistics,2019,pp.4171–4186.
the extracted sequences of subprocesses are beneficial for im-
[16] B.Yang,X.Fu,N.D.Sidiropoulos,andM.Hong,“Towardsk-means-
proving the performance of the two subproblems of 1) failure friendlyspaces:Simultaneousdeeplearningandclustering,”inProc.of
the34thInternationalConferenceonMachineLearning,2017.
detection (by 9-24% over the baselines) and 2) failure type
[17] K.YamanishiandY.Maruyama,“Dynamicsyslogminingfornetwork
identification(by7%overthebaseline).Further,weshowthat
failure monitoring,” in Proc. of the 11nd SIGKDD International Con-
CLog has robust performance, under high ratios of injected ferenceonKnowledgeDiscoveryandDataMining,2005,p.499–508.
unstablesequences,experiencingjusta6%performancedrop. [18] L.Breiman,“Randomforests,”Mach.Learn.,vol.45,pp.5–32,2001.
[19] J. R. Quinlan, “Induction of decision trees,” Mach. Learn., vol. 1, pp.
The key observation presented herein opens new possibilities
81–106,1986.
forhowtomostefficientlyextractmeaningfulsubprocesswith [20] T. Hastie, R. Tibshirani, and J. Friedman, The Elements of Statistical
minimal information about the sequences (e.g., discarding the Learning. NewYork,NY,USA:SpringerNewYorkInc.,2001.
[21] Y. Freund and R. E. Schapire, “A short introduction to boosting,” in
sequence identifiers), which we aim to explore next. These
Proc.ofthe16InternationalJointConferenceonArtificialIntelligence,
achievementscanultimatelybridgethegapbetweenautomatic 1999,pp.1401–1406.
log-based failure detection and root-cause analysis, further [22] W. Xu, L. Huang, A. Fox, D. Patterson, and M. I. Jordan, “Detecting
large-scale system problems by mining console logs,” in Proc. of the
enhancing the reliability of cloud systems.
22ndSymposiumonOperatingSystemsPrinciples,2009,p.117–132.
[23] H.Li,W.Shang,andA.E.Hassan,“Whichloglevelshoulddevelopers
REFERENCES choose for a new logging statement?” Empir. Softw. Eng., vol. 22, p.
1684–1716,2017.
[1] P.Garraghan,R.Yang,Z.Wen,A.Romanovsky,J.Xu,R.Buyya,and [24] W.Mengetal.,“Loganomaly:Unsuperviseddetectionofsequentialand
R. Ranjan, “Emergent failures: Rethinking cloud reliability at scale,” quantitativeanomaliesinunstructuredlogs,”inProc.oftheInternational
IEEECloudComputing,vol.5,pp.12–21,2018. JointConferencesonArtificialIntelligence,2019,pp.4739–4745.
[25] J.BreierandJ.Branisˇova´,“Anomalydetectionfromlogfilesusingdata
miningtechniques,”inInformationScienceandApplications. Berlin,
Heidelberg:SpringerBerlinHeidelberg,2015,pp.449–457.
[26] A. Oliner and J. Stearley, “What supercomputers say: A study of five
system logs,” in Proc. of the 37th Annual IEEE/IFIP International
ConferenceonDependableSystemsandNetworks,2007,pp.575–584.
[27] W. Meng, Y. Liu, S. Zhang, D. Pei, H. Dong, L. Song, and X. Luo,
“Device-agnosticloganomalyclassificationwithpartiallabels,”inProc
of26thInternationalSymposiumonQualityofService,2018,pp.1–6.