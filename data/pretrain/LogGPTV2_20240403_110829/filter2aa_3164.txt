### Professional Experience

**August 2017**
- **Senior Malware Scientist, Trend Micro**
  - **Project**: HITCON
  - **Contact**: [PI:EMAIL]
  - **Source**: [Ransomware Tracker](https://ransomwaretracker.abuse.ch/tracker/cerber/)

### Decision Tree Example

```plaintext
booster[0]:
0:[f1<127.5] yes=1,no=2,missing=1
1:[f7<28.5] yes=3,no=4,missing=3
3:[f5<30.95] yes=7,no=8,missing=7
7:[f0<5.5] yes=15,no=16,missing=15
15:leaf=-1.89091
16:leaf=-0.5
8:[f6<0.9045] yes=17,no=18,missing=17
```

### Pros and Cons of Decision Trees

**Pros:**
- Easy to program
- Very fast training
- Perform well with tabular input data
- Can incorporate human intelligence and heuristics

**Cons:**
- Hard to debug when predictions are incorrect
- High development cost
- Requires feature engineering

### LSTM Cell Structure

| Symbol | Description |
|--------|-------------|
| \( x \) | Input at time \( t \) |
| \( X_t \) | Input sequence up to time \( t \) |
| \( Y_t \) | Output sequence up to time \( t \) |
| \( y \) | Output at time \( t \) |
| \( z \) | Update gate |
| \( . \) | Pointwise multiplication |
| \( t \) | Time step |
| \( W \) | Weight matrix |
| \( i \) | Input gate |
| \( k \) | Cell state |
| \( h \) | Hidden state |

### Softmax Activation

The softmax function is used to convert a vector of values into a probability distribution.

**Example:**

| Class | Probability |
|-------|-------------|
| Cryptolocker | 0.6 |
| Clean | 0.2 |
| Locky | 0.1 |
| Cerber-RIGEK | 0.1 |

**Sources:**
- [Stack Exchange](https://stats.stackexchange.com/questions/273465/neural-network-softmax-activation)
- [Understanding LSTMs](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)
- [LSTM Networks](https://arxiv.org/pdf/1409.0473.pdf)

### Continuous Signals vs. Discrete Symbols

Continuous signals (e.g., audio and video) carry their natural semantics, whereas discrete symbols do not.

### GRU Cell Structure

| Symbol | Description |
|--------|-------------|
| GRU | Gated Recurrent Unit |
| Emb | Embedding layer |

### Dataset Details

**Features:**
- Shortest URLs
- Longest URLs
- ...

**Dataset Sourcing:**
- **Legitimate URLs**: Akamai log
- **Cryptolocker**: Malware operations team
- **Locky v2/Cerber-RIGEK**: Ransomware tracker

**Data Splits:**
- Train: 0.1
- Validation: 0.1
- Test: 0.8

### URL Analysis

**Before Training:**
- Undetected URL from `test-cryptolocker.txt`:
  ```
  www.leriov.com:80/leriov3/player1.php?id=aH!BeF0cHM6Ly9waG90b3MuZ29vZ2xlLmNvbS9zaGFyZS9B!BeFjF!BeFaXBNOHByemplbEEydU!BeFPX3ZZQTBLel!BeFKdjNmWVItMUFaM1UxQ1UtX25oWDho!BeFjNTaDh!BeFaEs0bF85WXNlYVVySUNBP2tleT1NMDV3YjB!BeFelNtVXpj@bfgo2TFdKVk1YQX!BeFjWHBOY0VKdGFEdElhMHBS&id2=
  ```

**After Training:**
- **Analysis**: This URL was misplaced in the test cryptolocker sample list. The missed detection is, therefore, a correct behavior.

### Additional Resources

- [Attention and Memory in Deep Learning and NLP](http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/)
- [Ransomware Tracker](https://ransomwaretracker.abuse.ch/)
- [Neural Turing Machines](https://arxiv.org/pdf/1412.7449v3.pdf)
- [LSTM Networks](https://arxiv.org/abs/1409.0473)
- [Lookback RNN and Attention RNN](https://magenta.tensorflow.org/2016/07/15/lookback-rnn-attention-rnn)
- [Recurrent Neural Network (RNN) Part 4: Attentional Interfaces](https://theneuralperspective.com/2016/11/20/recurrent-neural-network-rnn-part-4-attentional-interfaces/)
- [TensorFlow RNN Cell](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/ops/rnn_cell.py)
- [TensorFlow Issues](https://github.com/tensorflow/tensorflow/issues/4427)
- [Recurrent Neural Networks in TensorFlow III: Variable Length Sequences](http://r2rt.com/recurrent-neural-networks-in-tensorflow-iii-variable-length-sequences.html)