Aug 2017
Senior Malware Scientist ,Trend Micro
PI:EMAIL
HITCON
Source: https://ransomwaretracker.abuse.ch/tracker/cerber/
booster[0]:
0:[f1<127.5] yes=1,no=2,missing=1
1:[f7<28.5] yes=3,no=4,missing=3
3:[f5<30.95] yes=7,no=8,missing=7
7:[f0<5.5] yes=15,no=16,missing=15
15:leaf=-1.89091
16:leaf=-0.5
8:[f6<0.9045] yes=17,no=18,missing=17
 Pros
 Easy to program
 Very fast training
 Perform well against tabular input data
 Use human intelligence and heuristics
 Cons
 Hard to debug when it mis-predicts
 Development cost is high
 Feature engineering is required
Cell
x
Cell
Xt
Yt
Cell
y
Cell
z
Cell
.
Cell
t
Cell
w
Answer
h
t
t
t
W
Cell
i
Cell
k
Cell
3
Cell
.
Cell
h
Cell
k
Answer
Softmax
0.6
0.2
0.1
Cryptolocker
Clean
Locky
Cerber-RIGEK
0.1
Fully Connected
Source: https://stats.stackexchange.com/questions/273465/neural-network-softmax-activation
Source: http://colah.github.io/posts/2015-08-Understanding-LSTMs/
Source: http://colah.github.io/posts/2015-08-Understanding-LSTMs/
Source: https://arxiv.org/pdf/1409.0473.pdf
 Symbols do not carry their natural semantics within them whereas 
continuous signals such as audios and videos do.
www.facebook.com/n/?kjoha
GRU
GRU
GRU
GRU
Emb
Emb
Emb
Emb
Emb
Emb
GRU
GRU
GRU
GRU
GRU
Shortest URLs
Longest URLs
â€¦
Cryptolocker
Clean
Locky
Cerber-RIGEK
 Feature
 Dataset
 Sourcing
 Legitimate URLs: Akamai log
 Cryptolocker: Malware operations team
 Locky v2/ Cerber-RIGEK : Ransomware tracker
 Splits
 train : validation : test = 0.1 : 0.1 : 0.8
Before Training
After Training
 Undetected URL from test-cryptolocker.txt
www.leriov.com:80/leriov3/player1.php?id=aH!BeF0cHM6
Ly9waG90b3MuZ29vZ2xlLmNvbS9zaGFyZS9B!BeFjF!BeFaXBNOH
B!BeFcmplbEEydU!BeFPX3ZZQTBLel!BeFKdjNmWVItMUFaM1UxQ
1UtX25oWDho!BeFjNTaDh!BeFaEs0bF85WXNlYVVySUNBP2tleT1
NMDV3YjB!BeFelNtVXpj@bfgo2TFdKVk1YQX!BeFjWHBOY0VKdGF
FdElhMHBS&id2=
 Analysis
This URL was misplaced in the test cryptolocker sample list. So this 
missed detection is a correct behaviour.
 Training and Testing by the samples
http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/
https://ransomwaretracker.abuse.ch/
https://arxiv.org/pdf/1412.7449v3.pdf
https://arxiv.org/abs/1409.0473
https://magenta.tensorflow.org/2016/07/15/lookback-rnn-attention-rnn
https://theneuralperspective.com/2016/11/20/recurrent-neural-network-rnn-part-4-
attentional-interfaces/
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python
/ops/rnn_cell.py
https://github.com/tensorflow/tensorflow/issues/4427
http://r2rt.com/recurrent-neural-networks-in-tensorflow-iii-variable-length-
sequences.html