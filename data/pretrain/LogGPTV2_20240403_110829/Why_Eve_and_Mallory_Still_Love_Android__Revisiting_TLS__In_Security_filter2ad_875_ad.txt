Ambiguous Pinning Conﬁgurations. We analyzed our
dataset for apps that include ambiguous pinning conﬁgura-
tions, such as pins speciﬁed for the system-certiﬁcate with
the overridePins ﬂag, which overrides the pinning secu-
rity beneﬁts. We found 6, including two parental control
apps and two that explicitly activate override pins for user-
installed certiﬁcates, which developers registered as non-
default trust anchors. Therefore, attackers can more easily
mount MitMAs using social engineering. We further ﬁnd all
of these apps to be rather popular with more than 100,000
downloads. In 129 apps that pin speciﬁc domains we also
found the permitClearTextTraffic="true" ﬂag, which
overrides pinning if HTTP is used instead of HTTPS.
Copy & Paste of Insecure Conﬁgurations. We investigate
if apps contain NSC ﬁles that were copied & pasted from the
Internet by manually inspecting common NSC snippets. We
found applications that copy NSC snippets from information
sources like library documentations, blog articles or Q&A
threads [2,5,23]. We ﬁnd NSC snippets in 496 apps that solve
problems with an exception that requires HTTPS for speciﬁc
network connections as HTTP is not sufﬁcient. These snippets
can be found on either StackOverﬂow [3] or in the MoPub
app monetization documentation [11]. Overall, we ﬁnd 1,609
applications that include a NSC snippet from the MoPub
library documentation that instructs application developers
to permit cleartext trafﬁc globally [11] (cf. Listing 5 in the
appendix). While the snippet permits cleartext trafﬁc, it also
restricts cleartext trafﬁc for the domain example.com. For
the cases we found, developers used the same code without
making any changes. Similarly, we found 4 apps that use
certiﬁcate pinning for the datatheorem.com or subdomains
thereof. As these are related to Trustkit [25] and have no
further effects, they are likely copied from the Trustkit demo
application [26].
4.1.7
Impact of NSC on Android Ecosystem
Overall, NSC impacts app security on all levels of popularity.
While most apps have less than 1,000 installs, there are nu-
merous top apps with immense popularity. Within the most
popular apps with more than a billion downloads, we ﬁnd
NSC to be mostly used to circumvent safe defaults, for ex-
ample, to permit cleartext trafﬁc in Android 9. This is the
case for WhatsApp and several Google applications such as
Youtube and GMail [39], all of which had more than ﬁve
billion downloads. We further ﬁnd a popular web browser
that uses NSC to re-enable trust for user-installed certiﬁcates.
We found all cases of misconﬁgurations and malformed NSC
conﬁgurations we described in Section 4.1.6 in popular apps
with more than one million downloads. Particularly interest-
ing, we found one of the few cases where re-enabling trust for
user-installed certiﬁcates leads to ineffective pinning. Simi-
larly, we found copied & pasted code in apps with 100 million
downloads. Overall, our ﬁndings suggest that the insecure use
of NSC is not limited to amateur or unpopular apps.
4.1.8 Manual Analysis
Static analysis of NSC settings can show the potential for se-
curity problems for apps. However, the fact that NSC settings
for insecure TLS certiﬁcate validation are present in an app’s
NSC or Manifest ﬁle does not necessarily mean that it is used
or that sensitive information is passed along it. Even more
detailed automated app analysis techniques cannot guarantee
that all uses are correctly identiﬁed. Hence, we decided to
conduct an in-depth manual investigation of affected apps.
We aimed to ﬁnd out what sort of information is actually
sent over potentially insecure network connections. There-
fore, we installed a set of apps that re-enabled HTTP cleartext
trafﬁc by installing the apps on an Android device and execut-
ing a passive MitMA against the apps. We focused on apps
that re-enabled cleartext trafﬁc since this vulnerability was
widespread and is easy to exploit by a passive MitMA.
Therefore, we selected two sets of apps that re-enabled
cleartext trafﬁc for speciﬁc domains or globally:
Random apps. First, we selected and analyzed 20 random
apps. We found 13 of them to use HTTP to transfer user data.
In general, we found that affected apps use HTTP to transfer
ad, tracking and debugging information including personally
USENIX Association
30th USENIX Security Symposium    4355
identiﬁable information such as device identiﬁers. However,
we also found a smart home app that allows users to remotely
talk to their doorway devices and a school app that connects
schools, parents and teachers. Both send sensitive account
information including username and passwords from their
users’ devices to the service providers.
Privacy sensitive apps. Additionally, we analyzed 20 apps
likely to handle sensitive data. 6 In this set of apps, eleven
apps used HTTP. In all eleven apps we found login-related
information, including usernames, emails, passwords, or pass-
codes. Similar to the random app set, we found one school
for parents and a shopping app that send login credentials via
HTTP.
In conclusion we ﬁnd that in both sets more than half of
the apps we tested manually used HTTP to transfer sensitive
user data including login credentials.
5 Google Play Safeguards
In addition to NSC, Google Play changed their TLS policies
and implemented new safeguards. In 2016, they announced
to block new Android apps and updates that include insecure
certiﬁcate validation code [67, 68].
In particular, Google announced to detect three imple-
mentations: TrustManagers vulnerable to attacks using
invalid certiﬁcates [67], HostnameVeriﬁers vulnerable to
malicious domains and hostnames [68], and WebView-
Client.onReceivedSSLError implementations that do not ap-
propriately handle HTTPS errors in a WebView [66]. To
investigate root causes for the ﬁndings in previous work
[70, 75, 80, 86] and the efﬁcacy of these safeguards, we con-
ducted multiple controlled experiments. We aimed to identify
under which conditions Google Play still accepts apps with
insecure certiﬁcate validation code. Therefore, we simulated
a benign Android app developer who accidentally published
vulnerable certiﬁcate validation code as part of their app. In
each experiment, we included one or more vulnerable cer-
tiﬁcate validation implementations. After submitting each
experiment to Google Play, the app went through the Google
Play app review procedure. Once the veriﬁcation process con-
cluded, we checked for security alerts in the Google Play
Console. 7
Table 6 gives an overview of the four categories of exper-
iments we performed: TrustManagers (TM), HostnameVer-
iﬁers (HV), WebViewClients (WV) and Libraries (LB). Li-
braries refer to insecure third party libraries we experimented
6To identify these apps, we extracted static HTTP URL strings from app
apks, tested their availability on the default HTTP port 80, and selected apps
with URLs containing substrings such as ’login’, ’register’ and ’secure’.
7In case a vulnerable app was accepted, we removed it immediately to
avoid that clueless users would install vulnerable software on their device.
Given Google Play’s download reports, no user installed one of our vulnerable
apps.
Table 6: Details of our TLS security policy experiments.
y
t
i
l
i
b
a
h
c
a
e
R
d
e
s
s
a
P
Validation Logic
Experiment
TrustManager
(cid:88) No Validation at All
TM-U
(cid:88) No Validation at All
TM-R
(cid:88) No Validation at All
TM-D
(cid:88) No Validation at All, Renamed
TM-R-renamed
(cid:88) Cert Is Not Expired
TM-R-expired
(cid:88) Cert Is selfsigned and Not Expired
TM-R-selfsigned
(cid:88) Cert Has a Chain
TM-R-chain
TM-R-chainexpired (cid:88) Cert Has a Chain or Is Not Expired
HostnameVeriﬁer
HV-R
HV-D
HV-R-global
HV-R-contains
WebViewClient
WV-R
WV-D
WV-wrapped
Library
LB-U-acra
LB-U-jsoup
LB-U-asynchttp
X Acra with Insecure TM
(cid:88) JSoup with Insecure TM and HV
(cid:88) async-http with insecure TM
Always (R)eachable; Hidden Using a Debug Flag;
(cid:88) No Validation at All
(cid:88) No Validation at All, Debug switch
(cid:88) No Validation at All, Used by Default
(cid:88) Verify Hostname Using "string.contains"
X always proceed
(cid:88) always proceed, Debug switch
(cid:88) always proceed, Depend on invariant condition
(U)nreachable
(cid:88) App was accepted by Google Play; X App was blocked by Google Play
with, trying to reproduce developer complaints we found on-
line on GitHub [12, 17, 24, 27]. We also distinguish if the
faulty code was reachable (R), hidden behind debug options
(D), or unreachable (U).
5.1 TrustManager Implementations
We started with investigating insecure TrustManager imple-
mentations [54, 58].
Empty TrustManager. First, we conducted experiments on
an empty TrustManager implementation. Therefore, our test
app used to download a ﬁle from a remote server. This was
one of the most common insecure implementations [54, 58]
and is frequently discussed in online Q&A forums [15, 16].
Given Google Play’s announcement [67], this insecure im-
plementation should be rejected. For full coverage, we tested
multiple different empty TrustManager implementations: One
that could be toggled with a debug ﬂag (TM-D)8, one that was
always used (TM-R) and ﬁnally one where the TrustManager
code was unreachable (TM-U). None of these implementa-
tions was blocked by Google Play. Additionally, we renamed
the TM-R implementation to TrustAllTrustManager (TM-
R-renamed) to match the most common TrustManager name
reported by Fahl et al. [54]. This passed as well, which implies
8Some apps use such a ﬂag for debugging purposes.
4356    30th USENIX Security Symposium
USENIX Association
that the veriﬁcation process employed by Google does not
test for empty TrustManagers.
Non-Empty but Insecure TrustManager. Since not all in-
secure implementations reported in previous work [54] and
discussed in online developer forums [29] are empty imple-
mentations, we extended the TrustManager experiments from
above to also investigate non-empty but still insecure imple-
mentations. First, we implemented certiﬁcate validation logic
that only tested for the server’s certiﬁcate expiration date (TM-
R-expired, TM-R-chainexpired, TM-R-selfsigned). Second,
we tested an implementation that only checked whether the
server sends a certiﬁcate chain (TM-R-chain). In both cases
we did not implement secure certiﬁcate validation and only
tested code that was always reachable. Again, Google Play
accepted both vulnerable implementations.
5.2 HostnameVeriﬁer Implementations
Our second set of experiments investigated the efﬁcacy of
Google Play’s safeguards against insecure hostname veriﬁca-
tion in apps [54].
Always True Hostname Veriﬁcation. We started with in-
cluding HostnameVeriﬁer implementations that accept any
hostname for a certiﬁcate. We tested both, a reachable (HV-
R) and a debugging implementation that was protected by a
boolean debug ﬂag (HV-D). These implementations turned
off hostname veriﬁcation. We further investigated an app that
registered a global HostnameVeriﬁer for all TLS connections
by calling the static setDefaultHostnameVerifier method
for the HttpsURLConnection class with the HV-R implemen-
tation (HV-R-global). Google Play accepted all vulnerable
implementations.
Insufﬁcient Hostname Veriﬁcation. Next, we tested a Host-
nameVeriﬁer implementation, which included code that did
not always return true but only included insufﬁcient hostname
veriﬁcation logic. As discussed in previous work [54], de-
velopers publish apps with implementations that only check
for substring inclusion instead of testing the entire hostname.
Hence, our experiment included a respective implementation
(HV-R-contains). Again, this faulty implementation was ac-
cepted.
5.3 WebViewClient Implementations
The experiments in this section investigate Google Play’s
safeguard efﬁcacy against insecure HTTPS error handling in
WebViewClient implementations.
No Error Handling at All. First, we investigated HTTPS
error handling logic that ignored certiﬁcate validation errors
entirely and always proceeded with the TLS handshake. Sim-
ilar to the experiments above, we tested vulnerable code that
was always reachable (WV-R) and code that was hidden be-
hind a debug ﬂag (WV-D). Google Play detected WV-R and
blocked the app from being published. However, the slightly
more complex implementation WV-D passed without warn-
ing.
Obfuscated Error Handling. Motivated by previous
work [74], we included an experiment that obfuscated in-
secure error handling. We tested error handling logic that
hides the proceed call behind a boolean expression based
on an invariant check (WV-wrapped). Again, this vulnerable
implementation passed the Google Play checks.
5.4 Reproducing Complaints of Developers
Finally, we conducted a set of experiments to reproduce com-
plaints of Android developers we found online [12,17,24,27]
concerning problems with speciﬁc Android libraries. We
searched StackOverﬂow and GitHub issues for Google Play
Console warning messages in the context of vulnerable certiﬁ-
cate validation and found three vulnerable versions of popular
android libraries (LB-U-acra, LB-U-jsoup, LB-U-asynchttp).
Acra 4.2.3. We aimed to reproduce the GitHub issue [27] in
which a developer reports that the use of the Acra [7] library
that provides application crash reports for Android in version
4.2.3 was rejected by Google Play on 2019/11/20 (LB-U-
acra). We isolated and tested the vulnerable implementation
and were able to conﬁrm this issue as our app was blocked
with this speciﬁc version of the library.
JSoup 1.11.1. In this experiment, we aimed to reproduce an
error report for the JSoup [18] library for HTML parsing in
version 1.11.1. Developers report that their apps were rejected
because of a vulnerable TrustManager implementation [17,
24] (LB-U-jsoup). Similar to the experiment above, we used
the exact same version of JSoup in our test app. However,
we could not reproduce the error. Our app passed the Google