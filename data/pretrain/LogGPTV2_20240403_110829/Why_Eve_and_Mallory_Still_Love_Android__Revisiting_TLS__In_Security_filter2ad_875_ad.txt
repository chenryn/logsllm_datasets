### Ambiguous Pinning Configurations
We analyzed our dataset to identify applications that incorporate ambiguous pinning configurations. For instance, some apps specify pins for the system certificate with the `overridePins` flag, which negates the security benefits of pinning. Our analysis revealed 6 such cases, including two parental control apps and two others that explicitly activate override pins for user-installed certificates. These developers registered non-default trust anchors, making it easier for attackers to launch man-in-the-middle (MitM) attacks using social engineering. Notably, all these apps are quite popular, with over 100,000 downloads each.

In 129 apps that pin specific domains, we also found the `permitClearTextTraffic="true"` flag, which overrides pinning if HTTP is used instead of HTTPS. This further compromises the security of these applications.

### Copy & Paste of Insecure Configurations
To investigate whether apps contain Network Security Configuration (NSC) files that were copied and pasted from the internet, we manually inspected common NSC snippets. We discovered that several applications have copied NSC snippets from various sources, such as library documentations, blog articles, and Q&A threads [2,5,23]. Specifically, we found 496 apps that use NSC snippets to handle exceptions requiring HTTPS for specific network connections, as HTTP alone is insufficient. These snippets can be found on platforms like StackOverflow [3] or in the MoPub app monetization documentation [11].

Overall, 1,609 applications include a NSC snippet from the MoPub library documentation, which instructs developers to permit cleartext traffic globally [11] (refer to Listing 5 in the appendix). While this snippet permits cleartext traffic, it also restricts cleartext traffic for the domain `example.com`. In the cases we examined, developers used the same code without any modifications. Additionally, we found 4 apps that use certificate pinning for `datatheorem.com` or its subdomains. These are likely copied from the Trustkit demo application [26], as they are related to Trustkit [25] and have no further effects.

### Impact of NSC on the Android Ecosystem
NSC affects app security across all levels of popularity. While most apps have fewer than 1,000 installs, many top apps are immensely popular. Among the most popular apps with over a billion downloads, NSC is often used to circumvent safe defaults, such as permitting cleartext traffic in Android 9. This includes apps like WhatsApp and several Google applications, such as YouTube and Gmail, all of which have more than five billion downloads [39].

We also found a popular web browser that uses NSC to re-enable trust for user-installed certificates. All the misconfigurations and malformed NSC configurations described in Section 4.1.6 were present in popular apps with more than one million downloads. One particularly interesting case involved re-enabling trust for user-installed certificates, leading to ineffective pinning. Additionally, we found copied and pasted code in apps with 100 million downloads. Our findings suggest that the insecure use of NSC is not limited to amateur or unpopular apps.

### Manual Analysis
Static analysis of NSC settings can reveal potential security issues, but the presence of insecure TLS certificate validation settings in an app's NSC or Manifest file does not necessarily mean that the settings are used or that sensitive information is transmitted. Even advanced automated app analysis techniques cannot guarantee the identification of all uses. Therefore, we conducted an in-depth manual investigation of affected apps to determine what kind of information is actually sent over potentially insecure network connections.

We installed a set of apps that re-enabled HTTP cleartext traffic on an Android device and executed a passive MitM attack against them. We focused on apps that re-enabled cleartext traffic, as this vulnerability is widespread and easily exploitable. We selected two sets of apps:
- **Random Apps:** We analyzed 20 random apps and found that 13 of them used HTTP to transfer user data, including ad, tracking, and debugging information, as well as personally identifiable information like device identifiers. We also found a smart home app and a school app that sent sensitive account information, including usernames and passwords.
- **Privacy-Sensitive Apps:** We analyzed 20 apps likely to handle sensitive data. In this set, 11 apps used HTTP to transfer login-related information, including usernames, emails, and passwords. Similar to the random app set, we found a school app and a shopping app that sent login credentials via HTTP.

In conclusion, more than half of the apps in both sets used HTTP to transfer sensitive user data, including login credentials.

### Google Play Safeguards
In addition to NSC, Google Play has implemented new safeguards to improve TLS policies. In 2016, they announced plans to block new Android apps and updates that include insecure certificate validation code [67, 68]. Specifically, Google aims to detect three types of vulnerabilities: 
- **TrustManagers** vulnerable to attacks using invalid certificates [67]
- **HostnameVerifiers** vulnerable to malicious domains and hostnames [68]
- **WebViewClient.onReceivedSSLError** implementations that do not appropriately handle HTTPS errors in a WebView [66]

To investigate the root causes of previous findings [70, 75, 80, 86] and the efficacy of these safeguards, we conducted multiple controlled experiments. We simulated a benign Android app developer who accidentally published vulnerable certificate validation code. Each experiment included one or more vulnerable certificate validation implementations, and we checked for security alerts in the Google Play Console after submission.

### Table 6: Details of Our TLS Security Policy Experiments
| Experiment | Validation Logic | Reachability | Result |
|------------|------------------|--------------|--------|
| TM-U       | No Validation at All | Unreachable | Accepted |
| TM-R       | No Validation at All | Always Reachable | Accepted |
| TM-D       | No Validation at All | Debug Switch | Accepted |
| TM-R-renamed | No Validation at All, Renamed | Always Reachable | Accepted |
| TM-R-expired | Cert Is Not Expired | Always Reachable | Accepted |
| TM-R-selfsigned | Cert Is self-signed and Not Expired | Always Reachable | Accepted |
| TM-R-chain | Cert Has a Chain | Always Reachable | Accepted |
| TM-R-chainexpired | Cert Has a Chain or Is Not Expired | Always Reachable | Accepted |
| HV-R       | Always True Hostname Verification | Always Reachable | Accepted |
| HV-D       | Always True Hostname Verification | Debug Switch | Accepted |
| HV-R-global | Global HostnameVerifier | Always Reachable | Accepted |
| HV-R-contains | Insufficient Hostname Verification | Always Reachable | Accepted |
| WV-R       | No Error Handling at All | Always Reachable | Blocked |
| WV-D       | No Error Handling at All | Debug Switch | Accepted |
| WV-wrapped | Obfuscated Error Handling | Always Reachable | Accepted |
| LB-U-acra  | Acra with Insecure TM | Unreachable | Blocked |
| LB-U-jsoup | JSoup with Insecure TM and HV | Unreachable | Accepted |
| LB-U-asynchttp | async-http with insecure TM | Unreachable | Accepted |

### 5.1 TrustManager Implementations
We started by investigating insecure TrustManager implementations [54, 58]. We tested multiple empty TrustManager implementations, including one that could be toggled with a debug flag (TM-D), one that was always used (TM-R), and one where the TrustManager code was unreachable (TM-U). None of these implementations was blocked by Google Play. We also renamed the TM-R implementation to `TrustAllTrustManager` (TM-R-renamed), which passed the checks, indicating that the verification process does not test for empty TrustManagers.

For non-empty but still insecure TrustManager implementations, we tested logic that only checked for the server’s certificate expiration date (TM-R-expired, TM-R-chainexpired, TM-R-selfsigned) and whether the server sends a certificate chain (TM-R-chain). Google Play accepted all these vulnerable implementations.

### 5.2 HostnameVerifier Implementations
We investigated the effectiveness of Google Play’s safeguards against insecure hostname verification in apps [54]. We tested HostnameVerifier implementations that accept any hostname for a certificate, including a reachable (HV-R) and a debugging implementation (HV-D). We also tested an app that registered a global HostnameVerifier for all TLS connections (HV-R-global). Google Play accepted all these vulnerable implementations.

Next, we tested a HostnameVerifier implementation with insuficient hostname verification logic (HV-R-contains), which was also accepted.

### 5.3 WebViewClient Implementations
We tested WebViewClient implementations for insecure HTTPS error handling. We investigated logic that ignored certificate validation errors entirely and always proceeded with the TLS handshake (WV-R and WV-D). Google Play detected and blocked WV-R, but the slightly more complex implementation WV-D passed without warning. We also tested obfuscated error handling (WV-wrapped), which also passed the checks.

### 5.4 Reproducing Complaints of Developers
Finally, we conducted experiments to reproduce complaints from Android developers about specific Android libraries. We searched StackOverflow and GitHub issues for Google Play Console warning messages related to vulnerable certificate validation and found three vulnerable versions of popular Android libraries (LB-U-acra, LB-U-jsoup, LB-U-asynchttp).

- **Acra 4.2.3:** We confirmed that the use of the Acra library in version 4.2.3 was rejected by Google Play, as reported in a GitHub issue [27].
- **JSoup 1.11.1:** We aimed to reproduce an error report for the JSoup library in version 1.11.1, but our app passed the Google Play checks, despite using the same version of JSoup.
- **async-http:** We also tested the async-http library, and our app was accepted, confirming the reported issue.

In summary, our findings suggest that while Google Play has implemented safeguards, there are still gaps in the detection of insecure certificate validation code, particularly in non-empty but insecure TrustManager and HostnameVerifier implementations.