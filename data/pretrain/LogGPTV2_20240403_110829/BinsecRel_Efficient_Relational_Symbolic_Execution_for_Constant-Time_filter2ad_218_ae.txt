16.8k
2.8
4.3
31.8k
3.5k
.6
33.9
38.5k
35.7k
406
22.7M 3154
S
29 × 
12 × 
110 × 
130 × 















296 × 
Table II: Bounded veriﬁcation of constant-time cryptographic
implementations where #I (resp. #Iu) is the number of static
(resp. unrolled) instructions, T is the execution time in sec-
for timeout or  for exhaustive
onds, and S is the status (
exploration).
that any version of clang with -O3 introduces a secret-
dependent conditional jump which violates constant-time;
• functions ct_sort and ct_sort_mult, veriﬁed by
ct-verif [16] (LLVM bytecode compiled with clang),
are vulnerable when compiled with gcc -O0 or clang
-O3 -m32 -march=i386.
A few more details on these vulnerabilities are provided
in the next study. Finally, we describe the application of
BINSEC/REL to the Lucky13 attack in Appendix D.
S



utility
Comment
1 new 
2 new 
≈ #I #Iu
767
T CT
src
.29 Y 21× 21
ct-select 735
ct-sort 3600 7513 13.3 Y 18× 44
32
aes_big 375
873 1574 N
8
des_tab 365 10421
9.4 N
950 11372 2574 N
5
6025 30946 4172 - 42× 110
BearSSL
OpenSSL tls-rempad-luk13
Total
Table III: Bug-ﬁnding of constant-time in cryptographic imple-
mentations where #I (resp. #Iu) is the number of static (resp.
unrolled) instructions, T is the execution time in seconds, CT
src means that the source is constant-time, S is the status (
for insecure program), and
is the number of bugs.
-
-
-
-
Effects of compiler optimizations on CT (RQ1, RQ2).
Simon et al. [12] manually analyse whether clang optimiza-
tions break the constant-time property, for 5 different versions
of a selection function. We reproduce their analysis in an
automatic manner and extend it signiﬁcantly, adding: 29 new
functions, a newer version of clang, the ARM architecture,
the gcc compiler and arm-linux-gnueabi-gcc version
5.4.0 for ARM – for a total of 408 executables (192 in the
initial study). Results are presented in Table IV.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:41:43 UTC from IEEE Xplore.  Restrictions apply. 
1030
 
 
 
 
cl-3.9
cl-7.1 gcc-5.4 gcc-8.3 arm-gcc
cl-3.0
O0 O3 O0 O3 O0 O3 O0 O3 O0 O3 O0 O3
ct_select_v1
           
ct_select_v2
           
ct_select_v3
           
ct_select_v4
           
select_naive (insecure)  
 
ct_sort
           
ct_sort_mult
           
sort_naive (insecure)
 
 
hacl_utility (×11)
           
openssl_utility (×13)            
tea_encrypt
           
tea_decrypt
           
Table IV: Constant-time analysis of several functions compiled
with gcc or clang (cl) and optimization levels O0 or 03. 
indicate that the program is secure and  that it is insecure.
Bold programs and compilers are extensions of [12] and 
indicates a different result than [12].
 
 
 
 
We conﬁrm the main conclusion of Simon et al. [12] that
clang is more likely to optimize away CT protections as
the optimization level increases. Yet, contrary to their work,
our experiments show that newer versions of clang are
not necessarily more likely than older ones to break CT
(e.g. ct_sort is compiled to a non-constant-time code with
clang-3.9 but not with clang-7.1).
Surprisingly, in contrast with clang, gcc optimizations
tend to remove branches and thus, are less likely to introduce
vulnerabilities in constant-time code. Especially, gcc for ARM
produces secure binaries from the insecure source codes 7
sort_naive and select_naive.
Although [12] reports that the ct_select_v1 function
is secure in all their settings, we ﬁnd the opposite. Manual
inspection conﬁrms that clang with -O3 introduces a secret-
dependent conditional jump violating constant-time.
Finally, as previously discussed, we found that
the
ct_sort and ct_sort_mult functions, taken from the
benchmark of the ct-verif [16] tool, can be compiled
to insecure binaries. Those vulnerabilities are out of reach
of ct-verif because it targets LLVM code compiled with
clang, while the vulnerabilities are either introduced by
gcc or by backend passes of clang – we did conﬁrm
that ct-verif with the setting -clang-options="-O3
-m32 -march=i386" does not report the vulnerability.
Conclusion (RQ1, RQ2). We perform an extensive analysis
over 338 samples of representative cryptographic primitive
studied in the literature [11], [15], [16], compiled with dif-
ferent versions and options of clang and gcc, over x86 and
ARM. Overall, it demonstrates that BINSEC/REL does scale
to realistic applications for both bug-ﬁnding and bounded-
veriﬁcation (RQ1), and that the technology is generic (RQ2).
We also get the following interesting side results:
• We proved CT-secure 296 binaries of interest;
7The compiler takes advantage of the many ARM conditional instructions
to remove conditional jumps.
• We found 3 new vulnerabilities that slipped through pre-
vious analysis – manual on binary code [12] or automated
on LLVM [16];
• We signiﬁcantly extend and automate a previous study on
effects of compilers on CT [12];
• We found that gcc optimizations tend to help enforcing
CT – on ARM, gcc even sometimes produces secure
binaries from insecure sources.
B. Comparisons (RQ3,RQ4,RQ5)
We compare BINSEC/REL with standard approaches based
on self-composition (SC) and relational symbolic execution
(RelSE) (RQ3),
then we analyze the performances of our
different simpliﬁcations (RQ4), and ﬁnally we investigate
the overhead of BINSEC/REL compared to standard SE, and
whether our simpliﬁcations are useful for SE (RQ5).
Experiments are performed on the programs introduced in
Section VII-A for bug-ﬁnding and bounded-veriﬁcation (338
samples, 70k instructions). We report the following metrics:
total number of unrolled instruction #I, number of instruction
explored per seconds (#I/s),
total number of queries sent
to the solver (#Q), number of exploration (resp. insecurity)
queries (#Qe), (resp. #Qi), total execution time (T), timeouts
( ), programs proven secure (), programs proven insecure
(), unknown status (∼). Timeout is set to 3600 seconds.
Comparison vs. Standard Approaches (RQ3). We evaluate
BINSEC/REL against SC and RelSE. Since no implementation
of these methods ﬁt our particular use-cases, we implement
them directly in BINSEC. RelSE is obtained by disabling
BINSEC/REL optimizations (Section V-A), while SC is imple-
mented on top of RelSE by duplicating low inputs instead of
sharing them and adding the adequate preconditions. Results
are given in Table V.
  ∼
#I/s
SC
16k 154k 65473 15 282 41 15
3.9 170k
RelSE
78k 59316 14 283 42 13
97k
19k
5.4
3.9k 2.7k
BINSEC/REL 22.8M 3861
1.3k
0
#I
252k
320k
#Q #Qe
0 296 42
5895
#Qi
T
Table V: BINSEC/REL vs. standard approaches
While RelSE performs slightly better than SC (×1.38
speedup) thanks to a noticeable reduction of the number of
queries (≈50%), both techniques are not efﬁcient enough on
binary code: RelSE times out in 14 cases and achieves an
analysis speed of only 5.4 instructions per second while SC
is worse. BINSEC/REL completely outperforms both previous
approaches, especially its simpliﬁcations drastically reduce
the number of queries sent to the solver (×60 less insecurity
queries than RelSE):
• BINSEC/REL reports no timeout, it is 715 times faster
than RelSE and 1000 times faster than SC;
• BINSEC/REL performs bounded-veriﬁcation of large pro-
grams (e.g. donna, des_ct, chacha20, etc.) that were
out of reach of standard methods.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:41:43 UTC from IEEE Xplore.  Restrictions apply. 
1031
Version
#Qe
#Qi
T
  ∼
#I
#I/s
#Q
Standard RelSE with Unt and fp
RelSE
+ Unt
+ fp
BINSEC/REL (RelSE + FlyRow + Unt + fp)
RelSE+FlyRow 22.8M 3075
+ Unt
22.8M 3078
+ fp
22.8M 3861
4018
4018
3980
2688
2688
2688
5.4 96919 19058 77861 59316 14 283 42 13
320k
8.4 48071 20929 27142 44195
8
373k
7
391k 10.5 33929 21649 12280 37372
8 288 42
7 289 42
1330
1330
1292
7402
7395
5895
0 296 42
0 296 42
0 296 42
0
0
0
Table VI: Performances of BINSEC/REL simpliﬁcations.
Performances of Simpliﬁcations (RQ4). We consider on-
the-ﬂy read-over-write (FlyRow), untainting (Unt) and fault-
packing (fp). Results are reported in Table VI:
• FlyRow is the major source of improvement in BIN-
SEC/REL, drastically reducing the number of queries sent
to the solver and allowing a ×569 speedup w.r.t. RelSE;
• Untainting and fault-packing do have a positive impact on
RelSE (untainting alone reduces the number of queries by
50%, the two optimizations together yield a ×2 speedup);
• Yet, their impact is more modest once FlyRow is ac-
tivated: untainting leads to a very slight speedup, while
fault-packing still achieves a ×1.25 speedup.
Still, fp can be interesting on some particular programs, when
the precision of the bug report is not the priority. Consider for
instance the non-constant-time version of aes in BearSSL (i.e.
aes_big): BINSEC/REL without fp reports 32 vulnerable
instructions in 1580 seconds, while BINSEC/REL with fp
reports 2 vulnerable basic blocks (covering the 32 vulnerable
instructions) in only 146 seconds.
Comparison vs. Standard SE (RQ5). Standard SE is directly
implemented in the REL module and models a single execution
of the program with exploration queries but without insecurity
queries. We also consider a recent implementation of read-
over-write [66] implemented as a formula pre-processing,
posterior to SE (PostRow). Results are presented in Table VII.
SE
SE+PostRow[66]
SE+FlyRow
RelSE
RelSE+PostRow
BINSEC/REL
#I
440k
509k
#I/s
15.1
18.5
22.8M 6804
5.4
4.0
22.8M 3861
320k
254k
#Q
23453
27252
2688
96919
75043
3980
T
29122
27587
3346
59316
63693
5895
7
7
0
14
16
0
Table VII: Performances of relational symbolic execution
compared to standard symbolic execution with/without binary
level simpliﬁcations.