ﬁle (text, graphics, etc.).
• Content streams. They provide a means for efﬁcient
storage of various parts of the document content.
There are 9 basic object types in PDF. Simple object
types are Boolean, Numeric, String and Null. PDF strings
have bounded length and are enclosed in parentheses ’(’ and
’)’. The type Name is used as an identiﬁer in the descrip-
tion of the PDF document structure. Names are introduced
using the character ‘/’ and can contain arbitrary characters
except null (0x00). The aforementioned 5 object types will
be referred to as primitive types in this paper. An Array
is a one-dimensional ordered collection of PDF objects en-
closed in square brackets, ‘[’ and ‘]’. Arrays may contain
PDF objects of different type, including nested arrays. A
Dictionary is an unordered set of key-value pairs enclosed
between the symbols ‘>’. The keys must be
name objects and must be unique within a dictionary. The
values may be of any PDF object type, including nested dic-
tionaries. A Stream object is a PDF dictionary followed by
a sequence of bytes. The bytes represent information that
may be compressed or encrypted, and the associated dictio-
nary contains information on whether and how to decode
the bytes. These bytes usually contain content to be ren-
dered, but may also contain a set of other objects3. Finally,
an Indirect object is any of the previously deﬁned objects
supplied with a unique object identiﬁer and enclosed in the
keywords obj and endobj. Due to their unique identi-
ﬁers, indirect objects can be referenced from other objects
via indirect references.
The syntax of PDF objects is illustrated in a simpliﬁed
exemplary PDF ﬁle shown in the left-hand side of Fig-
ure 1.
It contains four indirect objects denoted by their
two-part object identiﬁers, e.g., 1 0 for the ﬁrst object, and
the obj and endobj keywords. These objects are dictio-
naries, as they are surrounded with the symbols ‘>’. The ﬁrst one is the Catalog dictionary, denoted by
its Type entry which contains a PDF name with the value
Catalog. The Catalog has 2 additional dictionary entries:
Pages and OpenAction. OpenAction is an example of a
nested dictionary.
It has two entries: S, a PDF name in-
dicating that this is a JavaScript action dictionary, and JS, a
PDF string containing the actual JavaScript script to be ex-
ecuted: alert(’Hello!’);. Pages is an indirect refer-
ence to the object with the object identiﬁer 3 0: the Pages
dictionary that immediately follows the Catalog. It has an
integer, Count, indicating that there are 2 pages in the docu-
ment, and an array Kids identiﬁable by the square brackets,
with two references to Page objects. The same object types
are used to build the remaining Page objects. Notice that
each of the Page objects contains a backward reference to
the Pages object in their Parent entry. Altogether, there are
three references pointing to the same indirect object, 3 0,
the Pages object.
The relations between various basic objects constitute
the logical, tree-like document structure of a PDF ﬁle, il-
lustrated in the middle part of Figure 1. The nodes in the
document structure are objects themselves, and the edges
correspond to the names under which child objects reside
in a parent object. For arrays, the parent-child relationship
is nameless and corresponds to an integer index of individ-
ual elements. Notice that the document structure is, strictly
speaking, not a tree but rather a directed, potentially cyclic
graph, as indirect references may point to other objects any-
where in the document structure. The root node in the doc-
ument structure is a special PDF dictionary with the manda-
tory Type entry containing the name Catalog. Any object of
a primitive type constitutes a leaf in the document structure.
The following list shows exemplary structural paths from
real-world benign PDF ﬁles:
3This feature has been originally intended for storing collections of
small objects in a compressed form. However, it has become a popular
tool for obfuscation of the document structure by attackers.
Figure 1. Various representations of the PDF structure: physical layout (left), logical structure (mid-
dle) and a set of structural paths (right)
/Metadata
/Type
/Pages/Kids
/OpenAction/Contents
/StructTreeRoot/RoleMap
/Pages/Kids/Contents/Length
/OpenAction/D/Resources/ProcSet
/OpenAction/D
/Pages/Count
/PageLayout
...
It was learned in experiments presented in Section 5.3.5 that
these are the structural paths whose presence in a ﬁle is most
indicative that the ﬁle is benign, or, alternatively, whose ab-
sence indicates that a ﬁle is malicious. For example, ma-
licious ﬁles are not likely to contain metadata in order to
minimize ﬁle size, they do not jump to a page in the docu-
ment when it is opened and are not well-formed so they are
missing paths such as /Type and /Pages/Count.
The following is a list of structural paths from real-world
malicious PDF ﬁles, learned in the same experiment:
/AcroForm/XFA
/Names/JavaScript
/Names/EmbeddedFiles
/Names/JavaScript/Names
/Pages/Kids/Type
/StructTreeRoot
/OpenAction/Type
/OpenAction/S
/OpenAction/JS
/OpenAction
...
We see that malicious ﬁles tend to execute JavaScript stored
within multiple different locations upon opening the doc-
ument, and make use of Adobe XML Forms Architecture
(XFA) forms as malicious code can also be launched from
there.
In the following section, we present the general method-
ology and the technical instruments needed for the analysis
of the document structure leading to a reliable discrimina-
tion between malicious and benign PDF documents.
4 System Design
The proposed method for structure-based detection of
malicious PDF documents comprises the following two
steps, schematically shown in Figure 2:
1. Extraction of structural features. As the basic pre-
processing step, the content of a PDF document is
parsed and converted into the special form, bag-of-
paths, which characterizes the document structure in
a well-deﬁned way.
2. Learning and classiﬁcation. The detection process is
driven by examples of malicious and benign PDF doc-
leads to different leaf objects. Empirical evidence indicates
that the counts of speciﬁc paths in a document constitute a
good measure of structural similarity between different doc-
uments. This motivates the choice of the set of structural
paths as the intrinsic features of our system.
Due to the widespread use of indirect references in PDF
documents, multiple structural paths may lead to the same
object. Indirect references may even form circular depen-
dencies, in which case the set of structural paths becomes
inﬁnite.
In some semantic constructs of PDF, e.g., page
trees, multiple paths are required in order to facilitate con-
tent rendering. Precise treatment of indirect references is
only possible with directed graphs. Since the comparison
of graphs is computationally difﬁcult, we adhere to the tree-
like view of the document structure and introduce additional
heuristics in the following section which produce a ﬁnite set
of structural paths while maintaining a reasonable semantic
approximation of the existing relations.
Thus, the main operation to be performed in our feature
extraction step is counting of the structural paths in a docu-
ment. Additional transformations, to be referred to as “em-
beddings”, can be applied to the path counts. The binary
embedding detects the presence of non-zero counts, the fre-
quency embedding divides the counts over the total number
of paths in a document, and the count embedding refers to
the path count itself. All three embeddings were experimen-
tally evaluated and the binary one was chosen over the other
two for its slightly better detection performance.
4.2 Extraction of PDF Document Structure
Extraction of the structural features deﬁned in Sec-
tion 4.1 must meet the following requirements:
R1: All paths must be extracted with their exact counts.
R2: The algorithm must be repeatable and robust, i.e., it
must produce the same set of paths for PDF ﬁles with
the same logical structure.
R3: The choice among multiple paths to a given object
should be semantically the most meaningful one with
respect to the PDF Reference [25].
As a ﬁrst step in the extraction process, the document is
parsed using the PDF parser POPPLER5. The key advan-
tages of POPPLER are its robust treatment of various encod-
ings used in PDF and the reliable extraction of objects from
compressed streams.
In principle, any other robust PDF
parser would be suitable for extraction of structural paths,
and our choice of POPPLER was only motivated by its free
availability and ease of installation. The parser maintains
5http://poppler.freedesktop.org/, v.0.14.3.
Figure 2. System architecture
uments. During the learning step, a model is created
from the data with known labels (“training data”). The
model encodes the differences between the malicious
and benign data. During the classiﬁcation step, the
model is applied to new data (“test data”), to classify it
as malicious or benign.
The technical realization of these two fundamental tasks is
presented below.
4.1 Feature Deﬁnition
A common approach to the design of data-driven secu-
rity instruments is to manually deﬁne a set of “intrinsic fea-
tures” which are subsequently used for learning and clas-
siﬁcation.
It was successfully applied for network intru-
sion detection [20, 22], botnet detection [12], detection of
drive-by-downloads [9, 10, 6], and other related problems.
The challenge in deﬁning features for detection of malicious
PDF documents lies in the complex structure of the PDF
format. We therefore depart from the knowledge-driven
strategy mentioned above and consider a richer set of poten-
tial features that capture PDFs’ complexity. These features
will be later automatically reduced to a smaller subset based
on the available data.
The ultimate goal of the structural analysis of PDF doc-
uments is to recover all parent-child relations between its
objects. The tree-like structure of PDF documents can be
represented by a set of paths from the root to leaves, as
shown in the rightmost part of Figure 1. Formally, we de-
ﬁne a structural path to be a concatenation of the names
encountered along the edges leading to a speciﬁc leaf. For
notational convenience, we will use the forward slash sym-
bol ’/’ as a delimiter between the names on a structural
path4. The same structural path may occur multiple times
in a document if the same path crosses some arrays and
4Technically, null is the only character that is not allowed in a PDF
name and hence, the only suitable delimiter in a structural path.
an internal representation of the document and provides ac-
cess to all ﬁelds of individual objects. Conceptually, path
extraction amounts to a recursive enumeration of leafs in
the document structure, starting from the Catalog object re-
turned by the parser. The extracted paths are inserted into a
suitable data structure, e.g., a hash table or a map, to accu-
mulate the counts of structural paths.
Several reﬁnements must be introduced to this general
algorithm to ensure that it terminates and that the above re-
quirements are met.
The requirement R1 is naturally satisﬁed by the recur-
sive nature of our feature extraction. Since our recursion
terminates only if a leaf node is encountered, the algorithm
is guaranteed to never underestimate the count of a partic-
ular path. To prevent an overestimation of the path count
due to multiple paths as well as an inﬁnite recursion due to
circular references, the requirement R3 must be enforced.
The enforcement of requirements R2 and R3 is tightly
coupled and ultimately relies on the intelligent treatment
of indirect references. Obviously, one cannot always de-
reference them, as this may result in an inﬁnite recursion.
One cannot also avoid their de-referencing, as the algorithm
would hardly ever move beyond the root node. Hence, a
consistent strategy for selective de-referencing must be im-
plemented.
In our extraction algorithm, we approach these issues by
maintaining a breadth-ﬁrst search (BFS) order in the enu-
meration of leaf objects. This strategy assumes that the
shortest path to a given leaf is semantically the most mean-
ingful. For example, this observation intuitively holds for
various cases when circular relations arise from explicit up-
ward references by means of the Parent entry in a dictio-
nary, as demonstrated by our example in Figure 1. Although
we do not have further evidence to support this observation,
in our experience the BFS traversal always produced mean-
ingful paths.
Two further technical details are essential for the imple-
mentation of the BFS traversal. It is important to keep track
of all objects visited at least once during the traversal and
backtrack whenever an object is visited more than once. It
is also necessary to sort all entries in a dictionary in some
ﬁxed order before descending to the node’s children. Since
no speciﬁc ordering of dictionary ﬁelds is required by the
PDF Reference, such ordering must be artiﬁcially enforced
in order to satisfy the requirement R2.
4.3 Learning and Classiﬁcation
Once the counts or other embeddings over the set of
structural paths are extracted, almost any learning algorithm
can be applied to create a model from the given training
data and use this model to classify unknown examples. For
an overview of suitable algorithms, the reader may refer to
any standard textbook on machine learning, e.g., [4, 14],
or use any entry-level machine learning toolbox, such as
SHOGUN6 or WEKA7. It is beyond the scope of this pa-
per to provide a comprehensive experimental evidence as to
which machine learning method is most suitable for detec-
tion of malicious PDF documents using the structural paths.
We have chosen two speciﬁc algorithms, decision trees and
Support Vector Machines, for subjective reasons presented
in the following section along with a high-level description
of the respective method.
Although both of the chosen methods are, in principle,
suitable for high-dimensional data, we have decided to ar-
tiﬁcially reduce its dimensionality for computational rea-
sons by selecting only those sequential paths that occur in
at least 1,000 ﬁles in our corpus (see Section 5.1 for a de-
tailed description of the data used in our experimental eval-
uation). This reduces the number of features, i.e., structural
paths, in our laboratory experiments from over 9 million
to 6,087. We did not use class information for the selection
of “discriminative features” as it was done, e.g., in ZOZZLE
[10]. Such manual pre-selection of features introduces an
artiﬁcial bias to a speciﬁc dataset and provides an attacker
with an easy opportunity to evade the classiﬁer by adding
features from the opposite class to his malicious examples.
4.3.1 Decision Trees
The decision tree is a popular classiﬁcation technique in
which predictions are made in a sequence of single-attribute
tests. Each test either assigns a certain class to an example
or invokes further tests. Decision trees have arisen from
the ﬁeld of operational decision making and are especially
attractive for security applications, as they provide a clear
justiﬁcation for speciﬁc decisions – a feature appreciated
by security administrators. An example of a decision tree
classifying whether a person may be involved in a trafﬁc
accident is shown in Figure 3.
Figure 3. Example of a decision tree
6http://www.shogun-toolbox.org/
7http://www.cs.waikato.ac.nz/ml/weka/
The goal of automatic decision tree inference is to build
a decision tree from labeled training data. Several classi-
cal algorithms exist for decision tree inference, e.g., CART
[5], RIPPER [7], C4.5 [28]. We have chosen a modern de-
cision tree inference implementation C5.0 which provides
a number of useful features for practical applications, such
as automatic cross-validation and class weighting8. It can
also transform decision trees into rule sets which facilitate
the visual inspection of large decision trees.
4.3.2 Support Vector Machines
The Support Vector Machine (SVM) is another popular ma-
chine learning algorithm [8]. Its main geometric idea, illus-
trated in Figure 4, is to ﬁt a hyperplane to data in such a way
that examples of both classes are separated with the largest
possible margin M. In the case of a linear decision func-
tion, it is represented by the hyperplane’s weight vector w
and the threshold ρ which are directly used to assign labels
y to unknown examples x:
y(x) = w⊤x − ρ
Nonlinear decision functions are also possible by applying