with the IC-Program diversity. Each time a new IC-Program
is generated, the attacker has only one chance to ﬁnd an
injection scheme such that the ﬁnal number of instructions
is less than the threshold we design for. The new program in
the next iteration will require a new injection method and thus
any runtime method to automatically ﬁnd the optimal method
will require computations that will be detected by our current
measurements.
However, the attacker can redirect the data pointer by chang-
ing the page table pointer (register cr3); this attack is hard
to thwart, we might consider using the System Management
Mode (SMM) execution mode which disables paging [29].
Attacker hiding: If an attacker attempts to hide, he or she
523
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:32:10 UTC from IEEE Xplore.  Restrictions apply. 
must predict when the POWERALERT-protocol will be initi-
ated. POWERALERT’s random initiation mechanisms ensure
that the attacker cannot predict those instances. Our game-
theoretic analysis shows that when the defender is using an
exponential initiation strategy, the attackers best strategy is
to hide more often if the defender is aggressive. Note that
because POWERALERT is using a random strategy, the attack
will not always correctly predict the strategy. Thus, some of
POWERALERT actions will be run when the attacker is not
hiding, leading to detection. The attacker’s strategy, to be
stealthy, can delay detection but cannot prevent it.
Forced retraining: In this attack, the attacker forces POW-
ERALERT to retrain by simulating a hardware fault that re-
quires a CPU change, to lead POWERALERT to a compromised
model. If this occurs, POWERALERT’s process is to wipe the
permanent storage, retrain using a clean OS, and then restore
data. Since we assume that the attacker does not modify the
hardware state, by removing permanent storage, we prevent
the attacker from affecting the retraining process.
IX. RELATED WORK
1) Timing Attestation: Seshadri et al. propose Pioneer [24]
extended by Kovah et al. [19] a timing-based remote attes-
tation system for legacy system (without TPM). The timing
is computed using the network round trip time. The work
assumes that the machine can be restricted to execution in
one thread. The issue with the work is that the round trip time
is affected by the network conditions which the authors do
not explore, a heavily congested network will lead to a high
variation on the RRT causing a high rate of false positives.
Moreover, the restriction of execution in one thread can be
evaded by a lower level attacker. In later work the authors
discuss the issues of Time Of Check, Time Of Use attacks,
we talk the problem in our work. Later work adapted timing
attestation to embedded devices [10].
Hern´andez et al. [14] implement a monitor integrity check-
ing system by estimating the time it takes for a software to
run. The timing information is sent from the machine to a
remote server that uses a phase change detection algorithms
to detect malicious changes. The issue of this work is that
the timing information is sent by the untrusted machine and
thus the information can be easily manipulated. Armknecht et
al. [2] propose a generalized framework for remote attestation
in embedded systems. The authors use timing as a method
to limit the ability of an attacker to evade detection. The
framework formalizes the goals of the attacker and defender.
The authors provide a generic attestation scheme and prove
sufﬁcient conditions for provable secure attestation schemes.
researchers use
power usage to detect malware. In WattsUPDoc, Clark [6]
collect power usage data by medical embedded devices and
extract features for anomaly detection. The authors exploit the
regularity of the operation of an embedded device to detect
irregularities. The authors however do not investigate mimicry
attacks. Kim et al. [17] use battery consumption as a method
to detect energy greedy malware. The power readings are
2) Power Malware Detection: Several
sent from the untrusted device to a remote server to compare
against a trusted baseline. The problem of this work is that
the power readings can be manipulated by the attacker as the
data is sent through the untrusted software. PowerProf [18] is
another in-device unsupervised malware detection that uses
power proﬁles. The power information is similarly passed
through the untrusted stack and is thus susceptible to attacker
evasion through tampering.
3) Hardware Attestation: Secure Boot [7] veriﬁes the in-
tegrity of the system, with the root of trust a bootloader.
Later on Trusted Platform Modules (TPMs) uses Platform
Conﬁguration Registers (PCRs) store the secure measurements
(hash) of the system. Both methods are static in that the
integrity is checked at boot time. Dynamic attestation on the
other hand can perform attestation on the current state of the
system. Such features are supported by CPU extensions (for
example Intel TXT). El Defrawy et al. propose SMART [8],
an efﬁcient hardware-software primitive to establish a dynamic
root of trust in an embedded processor, however the authors
do not assume any hardware attack.
4) VM based Integrity checker: OSck [15] proposed by
Hofmann et al. is a KVM based kernel integrity checker
that inspects kernel data structures and text to detect rootkits.
The checker runs as a guest OS thread but is isolated by
the hypervisor. Most VMM introspection intergrity checker
assume a trusted hypervisor. Those techniques are vulnerable
to hardware level attacks [20], [26], [28]. In our work we
do not have any trust assumption as the attestation device is
external to the untrusted machine.
5) Checksum Diversity: Wang et al. [27] propose using
diversity of probe software for security. The authors obfuscate
the control ﬂow by ﬂattening the probing software in order
to make it harder for an attacker to reverse engineer the
program for evasion. While the ﬂattened control ﬂow is
hard to statically analyze, the programs are susceptible to
active learning thus allowing an attacker to adapt over time.
Gifﬁn et al. [12] propose self-modifying to detect modiﬁcation
of checksum code modiﬁcation. The experiments show an
overhead of 1 microsecond to each checksum computation, the
method is however costly for large programs adding second
per check. The authors in [1] use randomized address checking
and memory noise to achieve unpredictability.
X. CONCLUSION
In this work we presented POWERALERT, which is an exter-
nal integrity checker that uses power measurements as a trust
base to achieve resilience against a stealthy attacker. By using
the power signal, POWERALERT is relying on an untainted,
trustworthy, and very accurate side-channel to observe the be-
havior of the untrusted computer. POWERALERT initiates the
checking protocol by sending a randomly generated integrity
checking program to the machine. The diversity of the IC-
program prevents the attacker from adapting; we showed that
the space of IC-programs is practically impossible to exhaust.
The untrusted machine is expected to run the IC-program and
send its output back to POWERALERT. While the IC-program
524
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:32:10 UTC from IEEE Xplore.  Restrictions apply. 
is executed, POWERALERT measures the current drawn by
the processor to compare it to a learned model. Any deviation
from the expected output is an indication of tampering by an
attacker. To understand how often checking should be initiated,
we modeled the interaction between POWERALERT and the
attacker using a time-continuous game. Our analysis shows
that POWERALERT can either force the attacker into hiding
or have the attacker risk detection.
REFERENCES
[1] T. AbuHmed, N. Nyamaa, and D. Nyang, “Software-based remote code
attestation in wireless sensor network,” in Proceedings of
the 28th
IEEE Conference on Global Telecommunications, ser. GLOBECOM’09.
Piscataway, NJ, USA: IEEE Press, 2009, pp. 4680–4687. [Online].
Available: http://dl.acm.org/citation.cfm?id=1811982.1812159
[2] F. Armknecht, A.-R. Sadeghi, S. Schulz, and C. Wachsmann,
the analysis and design of software
“A security framework for
attestation,” in Proceedings of
the 2013 ACM SIGSAC Conference
on Computer &#38; Communications Security, ser. CCS ’13. New
York, NY, USA: ACM, 2013, pp. 1–12.
[Online]. Available:
http://doi.acm.org/10.1145/2508859.2516650
[3] U. N. Bhat and G. K. Miller, Elements of applied stochastic processes.
J. Wiley, 1972.
[4] C. Castelluccia, A. Francillon, D. Perito,
software-based attestation of
in Proceedings
“On the difﬁculty of
devices,”
Computer and Communications Security,
York, NY, USA: ACM, 2009, pp. 400–409.
http://doi.acm.org/10.1145/1653662.1653711
the
of
16th ACM Conference
and C. Soriente,
embedded
on
ser. CCS ’09. New
[Online]. Available:
[5] J. R. Celaya, P. Wysocki, V. Vashchenko, S. Saha, and K. Goebel,
“Accelerated aging system for prognostics of power semiconductor
devices,” in 2010 IEEE AUTOTESTCON, Sept 2010, pp. 1–6.
[6] S. S. Clark, B. Ransford, A. Rahmati, S. Guineau, J. Sorber, W. Xu,
and K. Fu, “Wattsupdoc: Power side channels to nonintrusively
discover untargeted malware on embedded medical devices,” in
Presented as part of
the 2013 USENIX Workshop on Health
Information Technologies. Berkeley, CA: USENIX, 2013. [Online].
Available:
https://www.usenix.org/conference/healthtech13/workshop-
program/presentation/Clark
[7] D. L. Davis, “Secure boot,” Aug. 10 1999, uS Patent 5,937,063.
[8] K. Eldefrawy, A. Francillon, D. Perito, and G. Tsudik, “SMART:
Secure and Minimal Architecture for (Establishing a Dynamic) Root
of Trust,” in NDSS 2012, 19th Annual Network and Distributed
System Security Symposium, February 5-8, San Diego, USA,
San Diego, UNITED STATES, 02 2012.
[Online]. Available:
http://www.eurecom.fr/publication/3536
[9] W. Felleb, An Introduction to Probability Theory and Its Applications,
2nd ed.
John Wiley and Sons, New York, 1957.
[10] A. Francillon, Q. Nguyen, K. B. Rasmussen, and G. Tsudik,
“A minimalist approach to remote attestation,” in Proceedings of
ser.
the Conference on Design, Automation & Test
DATE ’14.
3001 Leuven, Belgium, Belgium: European Design and
Automation Association, 2014, pp. 244:1–244:6. [Online]. Available:
http://dl.acm.org/citation.cfm?id=2616606.2616905
in Europe,
[11] S. Gao and D. Panario, “Tests and constructions of
irreducible
polynomials over ﬁnite ﬁelds,” in Selected Papers of a Conference
on Foundations of Computational Mathematics, ser. FoCM ’97. New
York, NY, USA: Springer-Verlag New York, Inc., 1997, pp. 346–361.
[Online]. Available: http://dl.acm.org/citation.cfm?id=270376.270489
[12] J. T. Gifﬁn, M. Christodorescu, and L. Kruger, “Strengthening software
self-checksumming via self-modifying code,” in Proceedings of
the
21st Annual Computer Security Applications Conference, ser. ACSAC
’05. Washington, DC, USA: IEEE Computer Society, 2005, pp. 23–32.
[Online]. Available: http://dx.doi.org/10.1109/CSAC.2005.53
[13] B. Greskamp, S. R. Sarangi, and J. Torrellas, “Threshold voltage vari-
ation effects on aging-related hard failure rates,” in IEEE International
Symposium on Circuits and Systems, May 2007, pp. 1261–1264.
[14] J. M. Hern´andez, A. Ferber, S. Prowell, and L. Hively, “Phase-space
detection of cyber events,” in Proceedings of the 10th Annual Cyber
and Information Security Research Conference, ser. CISR ’15. New
[21] Y. Li,
sandman: Using intel txt to attack bioses,” Hack in the Box, 2015.
J. M. McCune, and A. Perrig, “Viper: Verifying the
integrity of peripherals’ ﬁrmware,” in Proceedings of the 18th ACM
Conference on Computer and Communications Security, ser. CCS ’11.
New York, NY, USA: ACM, 2011, pp. 3–16. [Online]. Available:
http://doi.acm.org/10.1145/2046707.2046711
“Response
conversational
transactions,” in Proceedings of the December 9-11, 1968, Fall Joint
Computer Conference, Part I, ser. AFIPS ’68 (Fall, part I). New
York, NY, USA: ACM, 1968, pp. 267–277.
[Online]. Available:
http://doi.acm.org/10.1145/1476589.1476628
in man-computer
time
[22] R. B. Miller,
York, NY, USA: ACM, 2015, pp. 13:1–13:4. [Online]. Available:
http://doi.acm.org/10.1145/2746266.2746279
[15] O. S. Hofmann, A. M. Dunn, S. Kim, I. Roy, and E. Witchel,
“Ensuring operating system kernel integrity with osck,” in Proceedings
of the Sixteenth International Conference on Architectural Support for
Programming Languages and Operating Systems, ser. ASPLOS XVI.
New York, NY, USA: ACM, 2011, pp. 279–290. [Online]. Available:
http://doi.acm.org/10.1145/1950365.1950398
advanced
and T.-F. Yen,
[16] A.
of
of
Emergent Threats.
Available:
and-case-advanced-persistent-threat
case
Juels
the
part
the 5th USENIX Workshop on Large-Scale Exploits and
[Online].
https://www.usenix.org/conference/leet12/sherlock-holmes-
Berkeley, CA: USENIX,
holmes
and
in Presented
“Sherlock
threat,”
persistent
the
as
2012.
[17] H. Kim, J. Smith, and K. G. Shin, “Detecting energy-greedy anomalies
and mobile malware variants,” in Proceedings of the 6th International
Conference on Mobile Systems, Applications, and Services,
ser.
MobiSys ’08. New York, NY, USA: ACM, 2008, pp. 239–252.
[Online]. Available: http://doi.acm.org/10.1145/1378600.1378627
[18] M. B. Kjærgaard and H. Blunck, Unsupervised Power Proﬁling for
Mobile Devices. Berlin, Heidelberg: Springer Berlin Heidelberg, 2012,
pp. 138–149.
[19] X. Kovah, C. Kallenberg, C. Weathers, A. Herzog, M. Albin, and
J. Butterworth, “New results for timing-based attestation,” in 2012 IEEE
Symposium on Security and Privacy, May 2012, pp. 239–253.
[20] X. Kovah, C. Kallenberg, J. Butterworth, and S. Cornwell, “Senter
[23] A. Pathak, Y. C. Hu, M. Zhang, P. Bahl, and Y.-M. Wang, “Fine-
grained power modeling for smartphones using system call tracing,”
in Proceedings of
the Sixth Conference on Computer Systems, ser.
EuroSys ’11. New York, NY, USA: ACM, 2011, pp. 153–168.
[Online]. Available: http://doi.acm.org/10.1145/1966445.1966460
[24] A. Seshadri, M. Luk, E. Shi, A. Perrig, L. van Doorn, and P. Khosla,
“Pioneer: Verifying code integrity and enforcing untampered code
execution on legacy systems,” in Proceedings of
the Twentieth
ACM Symposium on Operating Systems Principles, ser. SOSP ’05.
New York, NY, USA: ACM, 2005, pp. 1–16. [Online]. Available:
http://doi.acm.org/10.1145/1095810.1095812
[25] M. Shaneck, K. Mahadevan, V. Kher,
and Y. Kim, Remote
Software-Based Attestation for Wireless Sensors. Berlin, Heidelberg:
Springer Berlin Heidelberg, 2005, pp. 27–41. [Online]. Available:
http://dx.doi.org/10.1007/11601494 3
[26] W. Song, H. Choi, J. Kim, E. Kim, Y. Kim, and J. Kim, “Pikit:
A new kernel-independent processor-interconnect
rootkit,” in 25th
USENIX Security Symposium (USENIX Security 16). Austin, TX:
USENIX Association, Aug. 2016, pp. 37–51.
[Online]. Avail-
able:
https://www.usenix.org/conference/usenixsecurity16/technical-
sessions/presentation/song
[27] C. Wang, J. Hill, J. C. Knight, and J. W. Davidson, “Protection
of
software-based survivability mechanisms,” in Proceedings of
the 2001 International Conference on Dependable Systems and
Networks (Formerly: FTCS), ser. DSN ’01. Washington, DC, USA:
IEEE Computer Society, 2001, pp. 193–202.
[Online]. Available:
http://dl.acm.org/citation.cfm?id=647882.738073
[28] R. Wojtczuk and J. Rutkowska, “Attacking smm memory via intel cpu
cache poisoning,” Invisible Things Lab, 2009.
[29] F. Zhang, K. Leach, K. Sun, and A. Stavrou, “Spectre: A dependable
introspection framework via system management mode,” in Dependable
Systems and Networks (DSN), 2013 43rd Annual IEEE/IFIP Interna-
tional Conference on.
IEEE, 2013, pp. 1–12.
[30] Y. Zhang, D. Parikh, K. Sankaranarayanan, K. Skadron, and M. Stan,
“Hotleakage: A temperature-aware model of subthreshold and gate
leakage for architects,” University of Virginia Dept. of Computer Science
Technical Report, 2003.
525
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:32:10 UTC from IEEE Xplore.  Restrictions apply.