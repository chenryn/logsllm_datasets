[18] Duda, R., Hart, P., Stork, D.: Pattern Classiﬁcation, 2nd edn. Wiley-Interscience, Hoboken
(2000)
[19] Elz, R., Bush, R.: (July 1997), http://www.faqs.org/rfcs/rfc2181.html
[20] The Measurement Factory. DNS Survey: Cache Poisoners (2008),
http://dns.measurement-factory.com/surveys/poisoners.html
[21] Gummadi, K., Saroiu, S., Gribble, S.: King: Estimating latency between arbitrary internet
end hosts. In: Procceding of the 2nd ACM SIGCOMM IMW (2002)
[22] ISC. SIE@ISC, http://sie.isc.org
[23] Kaminsky, D.: Black ops 2008: It’s the end of the cache as we know it or: “64k should be
good enough for anyone” (2008), http://www.doxpara.com/DMK_BO2K8.ppt
[24] Karmasphere. The open reputation network (2006),
https://dnsparse.insec.auckland.ac.nz/dns
[25] Klein, A.: BIND 9 DNS Cache Poisoning (2008),
http://www.trusteer.com/files/BIND_9_DNS_Cache_Poisoning.pdf
[26] Osterweil, E., Massey, D., Zhang, L.: Observations from DNSSEC deployment. In: Pro-
ceedings of the 3rd NPSec (2007)
[27] Perdisci, R., Antonakakis, M., Luo, X., Lee, W.: WSEC DNS: Protecting Recursive DNS
Resolvers from Poisoning Attacks. In: Proceedings of DSN-DCCS, Estoril, Lispon, July 2
(2009)
[28] The Spamhaus Project. Lasso: The Spamhaus Don’t Route Or Peer List (2008),
http://www.spamhaus.org/drop/drop.lasso
[29] The Spamhaus Project. PBL: The Policy Block List (2008),
http://www.spamhaus.org/pbl
[30] The Spamhaus Project. XBL: Exploits block list (2008),
http://www.spamhaus.org/xbl
[31] WIDE Project. The TOTD (‘trick or treat daemon’) dns proxy (January 2006),
http://www.vermicelli.pasta.cs.uit.no
[32] Samosseiko, D.: The PARTNERKA - What is it, and why should you care? In: Proceedings
of USENIX, Workshop on Hot Topics in Cloud Computing (2009)
[33] Schuba, C.: Addressing weaknesses in the domain name system protocol. Master’s thesis,
Purdue University (1993)
A Centralized Monitoring Infrastructure for Improving DNS Security
37
[34] Ulevitch, D.: Phishtank: Out of the Net into the Tank (2009),
http://www.phishtank.com/
[35] USDJ. Eugene E. Kashpureff pleaded guilty to unleashing malicious software on the inter-
net (July 1997)
[36] Vixie, P.: RFC 2671 - Extension Mechanisms for DNS, EDNS0 (1999),
http://www.faqs.org/rfcs/rfc2671.html
[37] Vixie, P.: DNS complexity. ACM Queue 5(3) (April 2007)
[38] Wendlandt, D., Andersen, D., Perrig, A.: Perspectives: Improving ssh-style host authentica-
tion with multi-path probing. In: Proceedings of the Usenix ATC (June 2008)
[39] Wessels, D.: DNS Cache Poisoners Lazy, Stupid, or Evil? (2002),
http://www.nanog.org/mtg-0602/pdf/wessels.pdf
[40] Witten, I., Frank, E.: Data mining: practical machine learning tools and techniques. In:
Morgan Kaufmann Series in Data Management Systems. Morgan Kaufman, San Francisco
(June 2005)
[41] Yuan, L., Kant, K., Mohapatra, P., Chuah, C.: DoX: A Peer-to-Peer Antidote for DNS Cache
Poisoning Attacks. In: ICC 2006 (2006)
Behavior-Based Worm Detectors Compared(cid:2)
Shad Staﬀord and Jun Li
University of Oregon
{staffors,lijun}@cs.uoregon.edu
Abstract. Many worm detectors have been proposed and are being de-
ployed, but the literature does not clearly indicate which one is the best.
New worms such as IKEE.B (also known as the iPhone worm) continue
to present new challenges to worm detection, further raising the ques-
tion of how eﬀective our worm defenses are. In this paper, we identify six
behavior-based worm detection algorithms as being potentially capable
of detecting worms such as IKEE.B, and then measure their performance
across a variety of environments and worm scanning behaviors, using
common parameters and metrics. We show that the underlying network
trace used to evaluate worm detectors signiﬁcantly impacts their mea-
sured performance. An environment containing substantial gaming and
ﬁle sharing traﬃc can cause the detectors to perform poorly. No single
detector stands out as suitable for all situations. For instance, connection
failure monitoring is the most eﬀective algorithm in many environments,
but it fails badly at detecting topologically aware worms.
Keywords: Internet worm, worm detector, behavior-based detection.
1 Introduction
Network worms have long posed a threat to the functioning of the Internet. As
early as the outbreak of the Morris worm in 1988 [1], they have been capable of
disrupting traﬃc over large swathes of the Internet. Signiﬁcant outbreaks such as
the CodeRed [2] and Slammer [3] worms in 2001 and 2003 brought the threat to
national prominence and spurred the development of a wide range of mechanisms
to detect the presence of worms and to harden operating systems against common
attacks. The emergence of the Conﬁcker worm [4] in late 2008 showed that those
eﬀorts had not eradicated worms completely. As the Internet continues to play
a more important role in everyday life for hundreds of millions of people and as
the very nature of the devices on the Internet is changing (e.g., consumer-level
mobile devices begin to make up a substantial portion of connected devices),
the Internet requires more protection than ever. The question remains—can we
protect our networks from worms?
(cid:2) This material is based upon work supported by the United States National Science
Foundation under Grant No. CNS-0644434. Any opinions, ﬁndings, and conclusions
or recommendations expressed in this material are those of the authors and do not
necessarily reﬂect the views of the National Science Foundation.
S. Jha, R. Sommer, and C. Kreibich (Eds.): RAID 2010, LNCS 6307, pp. 38–57, 2010.
c(cid:2) Springer-Verlag Berlin Heidelberg 2010
Behavior-Based Worm Detectors Compared
39
The relevance of this question was further highlighted in late 2009 when a net-
work worm was found propagating exclusively on iPhones. The IKEE.B worm [5]
takes advantage of a default root password set in some jail-broken iPhones to
propagate. It brings to light some shortcomings in current worm detection and
prevention work. Speciﬁcally, because it propagates via an encrypted channel, it
bypasses worm detectors that rely on examining the content of network traﬃc;
and because it exploits a conﬁguration error rather than a buﬀer overﬂow to
gain control of the target machine, it is undeterred by defensive techniques such
as address space randomization.
In this paper, we examine our ability to detect the presence of a worm in
a protected network. Existing detection schemes can be broadly classiﬁed into
host-based systems that monitor system call information or other host-level be-
havior for illegal operations, and network-based systems that monitor network
traﬃc. Network-based systems can be further broadly divided into content-based
systems that monitor the bytes transmitted across the network and behavior-
based systems that monitor the patterns of network traﬃc.
Unfortunately, it is unclear how these detection systems perform relative to
each other as there is very little work that directly compares them. Algorithms
are typically published with evaluations against a single network trace, which is
diﬀerent for diﬀerent algorithms and generally not available publicly. For exam-
ple, the MRW detector was evaluated against an unidentiﬁed week-long trace
of a university department with 1,133 identiﬁed hosts [6], whereas the TRW
algorithm was evaluated against two traces collected at the peering link of an
ISP containing 404 and 451 identiﬁed hosts [7]. Furthermore, worm detectors are
evaluated with diﬀerent performance metrics, and tested worms do not always
follow the same set of parameters (such as scanning strategy and speed). For
example, the detection latency of the DSC detector is measured in the percent
of the network infected at detection time [8] while the MRW detector does not
provide detection latency results at all.
We seek to remedy this situation by performing a comprehensive analysis of
several worm detectors that are easily deployable and in principle capable of
detecting IKEE.B. We select six of the most prominent behavior-based worm
detection techniques and measure their detection performance against a variety
of worm propagation strategies over a common set of network traces. We evaluate
each detector using key performance metrics related to accuracy and latency.
The questions we seek to answer include: Is any one detection algorithm clearly
superior to the others, including cases when fast worms are the only concern
or a special network environment is protected (e.g., residential networks that
see game or peer-to-peer network usage)? If a worm adopts smart scanning
strategies such as slowing down or intelligently choosing victims, can it evade
these detectors? And, does the network trace selected for evaluation signiﬁcantly
impact the detection performance?
Highlights of our ﬁndings include: (1) We ﬁnd that the network trace impacts
the sensitivity of the detectors. They are less sensitive in environments with more
Internet gaming and ﬁle sharing activity, which appears more similar to worm
40
S. Staﬀord and J. Li
activity than other benign activities such as web browsing. (2) Our results show
that there is no clear winner and every detector has its limitations. For example,
connection-failure monitoring is the most consistently sensitive detection tech-
nique for random scanning and local-preference worms, but it fails drastically in
the case of a topologically aware worm. (3) In all environments, a stealthy worm
scanning at one scan per minute and employing some form of topologically aware
scanning that avoids connection failures could evade all the detectors evaluated
in all environments.
The rest of this paper is organized as follows: We ﬁrst discuss how we selected
detectors in Section 2, and then examine the selected detectors in some detail in
Section 3. We discuss our selected metrics in Section 4, followed by the method-
ology by which we evaluate detectors in Section 5. We present the results of our
evaluations in Section 6. Section 7 reviews related work, with our conclusions in
Section 8.
2 Detector Selection
In this section we describe published worm detection algorithms and justify our
choice of six speciﬁc detectors for this comparison study. We performed an exten-
sive evaluation of proposed worm detectors, considering 36 diﬀerent published
works. We grouped them into the following categories based on their detection
algorithm: host-based detectors, content-based detectors, and behavior-based
detectors. Each category has its own strengths and weaknesses.
Detectors that we classiﬁed as host-based included, among others: COV-
ERS [9], DACODA [10], TaintCheck [11], and Sweeper [12]. Several factors,
however, lead us to exclude host-based detectors from this study. Host-based
detectors require end-host deployment but a network operator may have no con-
trol over what software is installed on the end-hosts running in their network.
Furthermore, users may circumvent host-based software installs as illustrated
by IKEE.B, which targeted only those users who intentionally installed an un-
supported operating system. Finally, it is unclear whether host-based systems
are capable of detecting an attack like that used by IKEE.B. The systems listed
above all rely on observing malicious memory manipulations such as buﬀer over-
ﬂows, but IKEE.B did not perform any illegal memory operations; it merely
exploited a conﬁguration vulnerability.
Detectors that monitor the network instead of end-hosts seem much more
promising because they do not require deployment on each host to be protected.
We ﬁrst look at detectors that examine the contents of network traﬃc, includ-
ing AutoGraph [13], EarlyBird [14], PAYL [15], Anagram [16], and LESG [17].
Each of these detection mechanisms share a similar limitation that leads us to
exclude them from our comparison: they are unable to monitor encrypted traﬃc.
Encrypted traﬃc is a special case of making a worm polymorphic. Content-based
systems designed to catch polymorphic worms (such as Polygraph [18]) depend
on attack-speciﬁc, invariant sections of content which may not be present for
an encrypted worm. Even when worms are transmitted using unencrypted con-
nections, advances in polymorphism research such as [19] have threatened the
Behavior-Based Worm Detectors Compared
41
promise of these detectors. Also, it is prohibitively diﬃcult to acquire a variety
of network traces which contain full network content, making it infeasible to
evaluate these detectors.
The remaining and largest class of detectors is behavior-based (or payload
oblivious) detectors. These include TRW [7], RBS [20], PGD [21], and many
others. These systems also monitor network traﬃc, but they examine the behav-
ior of traﬃc from end hosts rather than the contents of their packets. This type
of system is easily deployed, requiring as little as a single monitor at the net-
work gateway. They are capable of detecting worms regardless of the scanning
mechanism or propagation type (including propagation via encrypted channels),
and many of them are capable of identifying the worm-infected hosts. However,
we do exclude some behavior-based systems that a network operator could not
easily deploy. For example, detectors using network telescopes (such as those by
Wu et al. [22] and Zou et al. [23]) require a large dark address space and cannot
be deployed by a network operator unless they control a large address space.
After our exhaustive evaluation of worm detectors, we are left with the fol-
lowing selections: TRW [7], RBS [20], TRWRBS [20], PGD [21], DSC [8], and
MRW [6]. We discuss these detectors in greater detail in the next section.
3 The Selected Worm Detectors
Having selected detectors for our comparison work, we now describe them each
in more detail in roughly chronological order of their publication. We present
only a brief a summary of each work, please refer to the original publications for
more detail. Note we used existing acronyms for each work where available.
The TRW detector was published by Schechter et al. in 2004 [7]. TRW identi-
ﬁes a host as worm infected if connection attempts to new destinations result in
many connection failures. TRW is based on the idea that a worm-infected host
that is scanning the network randomly will have a higher connection failure rate
than a host engaged in legitimate operations. Even with the IPv4 address space
getting closer to complete allocation, the majority of addresses will not respond
to a connection attempt on any given port. Randomly targeted connections (as
in worm scanning) will likely fail.
The destination-source correlation detector (DSC) was published in 2004 by
Gu et al.
[8]. It detects a worm infection by correlating an incoming connection
on a given port with subsequent outgoing infections on that port. If the outgoing
connection rate exceeds a threshold established during training, the alarm is
raised. A diﬀerent threshold is maintained for each destination port.
The MRW detector was ﬁrst published in 2006 [6]. It is based on the obser-
vation that whereas worm scanning results in connections to many destinations,
during legitimate operations the growth curve of the number of distinct des-
tinations over time is concave. And as the time window increases, destination
growth slows. This can be leveraged by monitoring over multiple time windows
with diﬀerent thresholds for each window. If the number of new destinations for
a host within a given window exceeds the threshold, the alarm is raised.
42
S. Staﬀord and J. Li
The RBS detector was ﬁrst published in 2007 [20] by Jung et al. . Similar to
the MRW detector, RBS measures the rate of connections to new destinations.
The work is based on the hypothesis that a worm-infected host contacts new
destinations at a higher rate than a legitimate host does. RBS measures this rate
by ﬁtting the inter-arrival time of new destinations to a exponential distribution.
The TRWRBS detector was published alongside the RBS detector [20]. It
combines the TRW and RBS detectors into a uniﬁed scheme, and observes both
the connection failure rate and the ﬁrst contact rate. It performs a sequential
hypothesis testing on the combined likelihood ratio to detect worms.
The Protocol Graph detector (PGD) was introduced by Collins and Reiter
in 2007 [21]. It is targeted at detecting slowly propagating hit-list or topologi-
cally aware worms. PGD works by building protocol-speciﬁc graphs where each
node in the graph is a host, and each edge represents a connection between
two hosts over a speciﬁc protocol. Collins and Reiter made the observation that
during legitimate operations over short time periods, the number of hosts in
the graphs is normally distributed and the number of nodes in the largest con-
nected component of each graph is also normally distributed. During a worm
infection, however, both numbers will go beyond their normal range, indicating
the presence of the worm.
4 Performance Metrics
The goal of this study is to evaluate the selected detectors over a comprehen-
sive parameter space to identify their strengths and weaknesses. We must ﬁrst,
however, determine which performance attributes we are most interested in cap-
turing, and what metrics would be suitable for assessing them.
The focus of this study is on the ability of the detectors to discover the
presence of a worm in the network. We thus want to measure their accuracy:
does a detector alert us when a worm is present—but not do so when there is
no worm? Furthermore, we want to measure its ability to detect a broad range
of worm scanning algorithms. Moreover, accurate detection is not helpful if it
happens too far after the fact. We must obtain some notion of the speed of the
detectors—does it ﬁnd a worm quickly or does it allow the worm free action for
a long time before raising the alarm.
There are some attributes that we are not as interested in. At this time we
are ignoring runtime costs such as processing or memory requirements. These
are dependent on implementation and optimization details, and can vary widely
for a given detection algorithm (for example, see the hardware implementation
of TRW by Weaver et al.
[24]). It is beyond the scope of this work to attempt
to determine how eﬃciently each of these algorithms could be implemented.
Similarly, we do not consider the complexity of installing or running the detec-
tor. This is not because installation complexity does not impact the potential
adoption rate of a detector, but because it is somewhat orthogonal to the accu-
racy of the detector itself and could be addressed separately from the detection
algorithm itself.
Behavior-Based Worm Detectors Compared
43
As shown in Table 1, we have identiﬁed four metrics as the most useful mea-
sures of the performance of a worm detector. We explain them below:
Table 1. Metrics
F-
F+ by host
F+ by time
Detection Latency
Percentage of experiments where worm traﬃc is present
but not detected in time period τ
The number of false alarms raised during a time period τ ,
limited to at most one false alarm per host
Percentage of minutes during a time period τ where a false
alarm is triggered for any host
The number of outbound worm connections from an in-
fected network prior to detecting the worm
Our false negative metric works as follows. For each experiment we introduce
a worm to the background legitimate traﬃc. The detector is limited to a time
period τ (typically an hour) to detect the worm after it becomes active. If in that
time span an alarm is not raised, the experiment is scored as a false negative
for the detector. The false negative rate (F-) is the percentage of experiments
scored as false negatives. (We report F- for each diﬀerent scanning rate of the
worm.)
The ﬂip side of false negatives is false positives: reporting legitimate traﬃc
as a worm infection. This is a critical metric for worm detectors, because a
detector that repeatedly raises a false alarm (“cries wolf”) will quickly be ignored
by network administrators. We measure false positives by running the detector
against benign traﬃc with no injected worm activity. (Because we have inspected
the traces for known worm activity, we consider every alarm raised by a worm
detector a false alarm.) However, because worm detectors often repeat their
worm infection tests—on every connection in some cases, the same set suspicious
behavior may cause the alarm to be raised repeatedly, and these repetitive alarms
should be coalesced into a single notiﬁcation to the network administrators. But
the exact mechanism and scope of alarm coalescing will be speciﬁc to the needs
and resources of the network administrators at each site. As a result, we present
two forms of false positive rate. We present the number of hosts identiﬁed as
infected (coalescing alarms by network address) as the false positive rate by host
(F+ by host). We also deﬁne false positive rate by time (F+ by time), which
is the fraction of minutes of the trace where an alarm is raised on at least one
host; note the alarm duration is only until the end of the current minute as we
coalesce alarms into 1 minute bins. The combination of these two metrics give a
better view of the overall false positive performance of the detector than either
does individually.
The next major performance attribute to consider is the speed with which a
worm is detected. The faster detection occurs, the less damage the worm can
do. We measure detection latency as the number of outbound worm connections
44
S. Staﬀord and J. Li
initiated by all infected hosts in the protected network prior to detection of any
internal infection. (Scans that do not leave the network do not inﬂict damage
on the Internet as a whole and are not included in this count.) Alternative
approaches such as using clock time or infected host count are less accurate and
less descriptive than our metric.
5 Experiment Design
We run the detectors against legitimate traﬃc to measure false positives, then
against legitimate traﬃc plus known worm traﬃc to measure false negatives
and detection latency. We developed a custom testing framework and imple-
mented each detector in our framework based on the detector’s published speci-
ﬁcations. Our framework can run against online, real-time traﬃc on the DETER
testbed [25], as well as run in an oﬄine (not real-time) mode. We use legitimate
traﬃc from a variety of sources and generate known worm traﬃc by simulating a