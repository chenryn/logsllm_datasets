(1)
The interpretation of a leakage transformer as a cost transformer
is defined from the leakage transformer only: it neither depends on
the program nor on the compilation pass.
Cost transformers are monotone; therefore, they can be soundly
composed. Indeed, given two leakage transformers ðœ1 and ðœ2 cor-
responding to two successive compilation passes, the following
inequality holds:
(cid:16)âŸ¦ðœ2âŸ§âŸ¦ðœ1âŸ§â„“(cid:17) âŠ‘ âŸ¦ðœ2âŸ§âŸ¦ðœ1âŸ§tocost(â„“)
ðœ…
ðœ…
.
tocost
It means that a sequence of two leakage transformer can be inter-
preted as a sound cost transformer by composing their interpreta-
tion7.
The actual definition of the interpretation functions (for each of
the three languages of leakage transformers described in this work)
6The study of more general languages for cost transformers that could improve the
precision or cover more program transformations is left as further work.
7The result of this semantic composition may not be the most precise cost transformer,
but we leave the study of syntactic composition of leakage transformers as future
work.
fn poly1305_ref3(reg u64 out in len k) {
reg u64 j;
// . . .
while (len >=u 16) { // A
// . . .
len -= 16;
}
if len >u 0 {
// . . .
j = 0;
while (j <u len) { // B
// . . .
j += 1;
A
B
}
// . . .
}
// . . .
}
Figure 12: Source code (left, excerpt) and target control-flow
graph (right) of a MAC function (Poly1305)
is tedious but unsurprising; the details, as well as the soundness
proofs, can be found in the supplementary material.
As already mentioned, the cost transformers for all but one pass
are exact: the soundness relation (equation (1) above) holds even
when the partial order on costs âŠ‘ is equality. For loop unrolling,
however, it only holds for the slightly less precise pointwise order-
ing of counters (with natural numbers ordered as usual).
Source-level cost analysis of target programs. In order to il-
6.2.3
lustrate the use of cost transformers, we have implemented a static
analysis of the cost of Jasmin source programs. It infers linear re-
lations between counters, auxiliary variables that are incremented
at the beginning of basic blocks: their final values describe how
many times each basic block has been executed. This method has al-
ready been used in the context of worst case execution time (wcet)
analysis [19]. The value analysis that is part of the safety checker
of Jasmin programs can be directly used to infer these relations.
Notice that the analysis result, in particular, includes loop bounds.
The soundness of the cost transformer makes it possible to di-
rectly interpret these linear relations about source counters as linear
relations between upper bounds on target counters. We illustrate
this fact by a brief example.
The source code shown on the left of Figure 12 is excerpted from
an implementation of the Poly1305 message authentication code
(MAC). Given a message of arbitrary length and a 32-byte one-time
key, it computes a 16-byte tag that can be used to authenticate
the message. The message is processed in 16-byte chunks in a
first loop; in case the message length is not evenly divisible by
sixteen, the last bytes are finally processed in a second loop. For
the sake of clarity, only this logic is reproduced in the code shown
on the figure; in the actual implementation, the three control-flow
constructions are spread in three distinct functions. The right of
Figure 12 shows the (complete) control-flow graph (CFG) of this
function at the end of the compilation. The leakage transformer
produced by the compilation of this program interpreted as a cost
transformer, proves (among others) that the basic-block labelled A
(resp. B) in the CFG is executed as most as many times as the source
basic-block equally labelled.
Session 2B: Formal Analysis and Verification CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea471The source-level cost analysis infers the following properties,
where ð´ (resp. ðµ) is the number of times that the first (resp. second)
loop body is executed, and ð¿ is the message length (initial value of
the variable len): 0 â©½ ð´, 0 â©½ ðµ â©½ 15, and ð¿ = 16 Â· ð´ + ðµ.
The soundness of the cost transformers implies that these prop-
erties also apply at the assembly level (where ð´ and ðµ are upper
bounds rather than exact counts). Using these properties, one can
compute at assembly level a more basic notion of cost, for instance,
the number of executed instructions.
7 EVALUATION
In this section, we evaluate our methodology in terms of proof
effort, compile-time overhead, run-time overhead and precision of
the source-level reasoning. We study the following questions.
â€¢ How much does the Jasmin compiler (programs & proofs) need
â€¢ How much compile-time overhead is incurred by the genera-
â€¢ Is the code generated by our modified compiler different than
â€¢ How precise is a cost analysis (of the target program) performed
to be modified and expanded to support our methodology?
tion of explicit leak-transformers?
before modifying the compiler?
at the source level?
7.1 Proof effort
The Jasmin compiler (branch master) features sixteen compilation
passes that are implemented or validated in Coq; they manipulate
five different intermediate languages. Three languages have the
same syntax; three languages have the same semantics for expres-
sions. There are roughly 30 thousands lines of Coq.
In order to reason about non-functional properties like cryp-
tographic constant-time and cost, all semantics have been instru-
mented with leakages as described in Section 5. Accordingly, all
passes are modified to precisely describe how they transform the
leakage. There is a single pass that preserves leakages (elimination
of dead functions) for which there are no modifications to the im-
plementation of the program transformation. Note that for passes
that are implemented as an external oracle and validated in Coq,
the validator infers the correct leakage transformer: the program
analyses and transformations that are implemented in OCaml have
not been modified at all.
The correctness statements for each pass have been strengthened,
and their proofs updated accordingly. This is tedious but relatively
straightforward. The main theorems presented in Section 6 are
stated once for the compiler as a whole: they are simple corollaries
of the correctness theorem. Their proofs are, therefore a few lines
long. Globally, the changes made to the Coq files modify 5 thousands
lines and add 6 thousands new lines (i.e., a 20 % increase).
The definitions and proofs related to cost and cost transformers
are built on top of the leakages and leakages transformers only: they
are independent of the number and complexity of the compilation
passes. In particular, if the compiler is extended with new passes, no
changes are required to this part. Only extensions of the language
of leakage transformers would need to be reflected on the cost
transformers.
Table 1: Compilation times (s) of selected implementations
of cryptographic primitives with (LT) and without (Ref.) com-
putation of leak-transformers
Name
xxhash64
poly1305 (ref)
gimli (avx2)
chacha20 (ref)
poly1305 (avx2)
gimli (ref)
bash (avx2)
blake2b
chacha20 (avx2)
bash (ref)
curve25519
Ref. (s) LT (s)
0.06
0.06
0.11
0.18
0.32
0.9
2.6
3.0
4.0
7.4
8.3
0.06
0.06
0.09
0.16
0.29
0.8
2.4
2.8
3.9
6.5
7.6
7.2 Compiler behavior
When compiling a program, in order to produce accurate leak-
transformers, the compiler computes more data; moreover, the
modifications described above may imply that the generated code
is different. In order to measure the compile-time overhead of the
computation of leak-transformers, we compile a set of Jasmin pro-
grams with two versions of the Jasmin compiler (with and without
our modifications), measure the total compilation time and compare
the generated assembly code.
We have run this experiment on a machine running Ubuntu
Linux on an IntelÂ® XeonÂ® processor (E5-2687W v3 @ 3.10GHz) us-
ing a sample of Jasmin implementations of cryptographic primitives
from various sources (examples available with the compiler, case
studies in published works, private communication with Jasmin
programmers). The compilation times are reported in Table 1. The
compile-time overhead is about 10 %. The run-time overhead is zero
(not shown in the table): the generated assembly is identical with
the two versions of the compiler.
Note that to prove preservation of CCT, the leakage transformer
needs only to exist (hence need not be computed at compile-time).
If we are concerned by the running-time of the compiler, it is possi-
ble to define a modified version that does not compute the leakage
transformer and straightforward to formally prove that they pro-
duce the same assembly program. Such modified compiler also
preserves CCT.
Nonetheless, as described in other parts of this paper, the leakage-
transformer as a product of the compilation can be a useful artifact:
looking at the leakage-transformer for a particular program can
tell precise information about the compilation of this program (for
instance, how its run-time cost is transformed). In this case, indeed,
the extra computation incurs an additional cost (but provides extra
information).
7.3 Cost analysis
With accurate leakage-transformers at hand, a range of source-
level reasoning becomes possible. In this section, we combine (as
described in Section 6.2) a source-level cost analysis with the leak-
age transformers in order to statically compute upper-bounds of
Session 2B: Formal Analysis and Verification CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea472param int N = 10;
fn inc(reg u64 x) âˆ’â†’ reg u64 {
inline int i;
reg u64 r;
r = x;
for i = 0 to N {
if x == i {
r += 1; // A
}
}
return r;
}
Figure 13: Run-time cost analysis (blue line is 2.9 instr/cycle)
run-time cost of target programs. We then compare the results with
actual run-time measurements. The purpose of this experiment
is to assess the precision of the leakage transformers and not to
design a cycle-accurate cost analysis for x86 assembly programs.
In particular, our cost model is fairly simple: we count the (total)
number of executed instructions. Nonetheless, we are confident
that using precise hardware models, it is possible to use the leakage
transformers in a similar way to build source analyses that yield
precise results about target programs.
7.3.1 Methodology. We have selected a sample of representative
Jasmin programs (permutations, hash functions, etc.). For each
program, the source-level cost analysis computes a set of linear
constraints between execution counters (at the granularity of basic-
blocks) and initial values of the (main) function arguments. The
leakage transformers produced at compile-time yield cost trans-
formers that map each target instruction to a source basic block.
From this cost-transformer, we compute a symbolic upper bound of
the total run-time cost: an affine combination of source execution
counters.
We then fix some run-time parameters (typically, the size of the
inputs) and solve the resulting integer linear program: we search
for the maximal cost satisfying the constraints. This gives a static
numerical estimate of the cost for the given input size.
We also run each compiled program on inputs of the correspond-
ing sizes and measure8 the number of executed instructions and
elapsed CPU cycles. Elapsed time is estimated by a Rust program
that calls the Jasmin functions; it is built on top of Criterion.rs, a
â€œstatistics-driven micro-benchmarking toolâ€.
7.3.2 Results. Experimental results are shown in Figure 13. Each
point of the graph corresponds to one program and one choice of
input size. The programs Gimli and Bash are permutations: their
inputs have fixed sizes. Both come in two versions: a reference and
one optimized for platforms with avx2 vectorized instructions (the
capital V at the end of the names mark the vectorized versions).
8by reading Linux performance counters on a laptop running Linux 5.4 on a IntelÂ®
Coreâ„¢ i7-8665U CPU @ 1.90GHz.
Exact cost: 21 + ð´ instructions; computed bound: 21 + 10 Â· ð´.
Figure 14: Precision loss in cost transformation
The xxhash64 and poly1305 programs are a (non-cryptographic)
hash algorithm and a MAC function (respectively). In both cases the
control-flow structure is slightly complex as there are two different
paths for short and long messages, and there are many loops to
handle the input message in chunks of decreasing sizes. Finally, the
program blake2b is a cryptographic hash algorithm that can produce
digests of any size between 1 and 64 bytes. It is also made of several
loops to first consume the message and then produce the digests of
the appropriate size. In all cases, the measured number of executed
instructions is exactly predicted by the static analysis (not shown
on the graph). The measurement shows that the processor executes
between 2 and 4 instructions per cycle. The plain line on the graph,
obtained through linear regression of the measurements, has a slope
of 2.9 instructions per cycle (with a correlation coefficient of 0.999).
7.3.3 Remark on precision loss. As mentioned in Section 6.2, the
cost-transformer for loop unrolling may lose some precision, as
illustrated in the (artificial) example depicted in Figure 14. When
the loop is unrolled, its body is replicated, and each copy is executed
as many times as the original loop. However, at most, a single copy
of the nested basic block (labeled A) is executed, but the compiler
cannot predict which one, hence the loss of precision, assuming
that each copy may be executed.
Such pathological cases do not occur in practice as conditions
that are nested in unrolled loops and involve the loop counters are
usually resolved at compile-time.
8 RELATED WORK
Compilation and Cryptographic Constant-Time. To our best knowl-
edge, preservation of CCT is first considered in [7], and proved
formally (in Coq) for a toy compiler inspired from Jasmin. The
proof is based on CT-simulations, an adaptation for CCT of the clas-
sic simulation technique. Informally, a CT-simulation establishes
that equality of leakage in two source executions entails equality
of leakage in the corresponding target executions. Although very
general, CT-simulations require reasoning about four executions
and are more difficult to establish than the classic simulations. By
introducing structured leakage and leakage transformers, our work
is the first to forego completely the use of CT-simulations.
More recently, [6] consider a direct method based on proving
that leakage of target programs is identical (up to erasure) to leak-
age of the corresponding source programs. They use their method
Static bound (instructions)102104106xxhash64xxhash64GimliGimliVBashBashVxxhash64poly1305blake2bxxhash64poly1305blake2b19324819225565521Input size  (octets)101103105Measured cost (cycles)Session 2B: Formal Analysis and Verification CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea473for proving preservation of CCT for a patched version of CompCert.
We briefly discuss some of the main differences with our work:
i) [6] does not handle leakage in expressions: the first verified pass
of [6] is C#minorgen. In particular, SimplLocals is not proved CCT-
preserving. In contrast, our techniques are able to reason about
leakage in expressions; ii) the method of [6] applies to transforma-
tions that preserve or erase leakage. This excludes Linearize, for
which a CT-simulation is used. In contrast, leakage transformers
do not impose restrictions on how transformations modify leakage,
and our proof of Linearize is straightforward; iii) instantiating the
method of [6] requires syntactic restrictions on programs (e.g. the
RTLgen pass is only proved correct for programs without switch
statements). We believe that our method would be able to lift these
restrictions; iv) our notion of instrumented correctness is new and