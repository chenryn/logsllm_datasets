researchers and law enforcement agencies cannot aid the botnet in any way,
including the returning of valid neighbors when being asked. B¨ock et al. [5] use
the Local Clustering Coeﬃcient (LCC) mechanism to detect sensors that do not
have any neighbors or groups of sensors that are fully meshed. Moreover [11],
improves upon this and introduces two other mechanisms based on PageRank
[19] and Strongly Connected Components (SCCs). Their proposed mechanisms
cannot be easily avoided by defenders as they require either large numbers of col-
luding sensors or active sharing of valid neighbors when being requested. Lastly,
Vasilomanolakis et al. propose the use of computational trust for calculating
trust scores for all neighbors of a bot [25]. This allows them to automatically
blacklist bots that refuse to cooperate in the sharing of commands.
4 Botnet Monitoring Under Adverse Conditions
The adoption of advanced countermeasures will change the landscape of botnet
monitoring. Here, we deﬁne the term adverse conditions and discuss approaches
for monitoring in the presence of countermeasures. Furthermore, we introduce
the idea of leveraging the Membership Management (MM) to obstruct moni-
toring operations. Moreover, we discuss the limitations of the MM design with
regard to the trade-oﬀ between monitoring resistance and the resilience of bot-
nets.
4.1
Identifying the Worst-Case Monitoring Scenario
We contend, that existing botnet monitoring mechanisms may no longer be feasi-
ble under adverse conditions (see Sect. 3). Therefore, new approaches to monitor
botnets are urgently needed. Based on our analysis of the related work, we pro-
pose ﬁve approaches to conduct monitoring in adverse conditions. Namely these
are: short-term monitoring, network traﬃc analysis, network scanning, taking
control of active bots, and running botnet malware in controlled environments.
Depending on the speciﬁcs of the implemented anti-monitoring mechanisms,
short-term monitoring may be possible for monitoring using crawlers and sen-
sors. To avoid preemptive blacklisting of legitimate bots, anti-monitoring mech-
anisms may require multiple anomalous interactions before a blacklisting occurs
[25]. This can allow short-time monitoring, in which the anti-monitoring mecha-
nisms are not triggered. Furthermore, if suﬃcient resources are available, black-
listed IPs can be replaced to perform continuous monitoring. The major draw-
Next Generation P2P Botnets: Monitoring Under Adverse Conditions
517
back of this approach is the scarcity of IP addresses which leads to higher costs
and eventually IPs run out due to blacklisting.
Network traﬃc analysis based monitoring approaches are not aﬀected by the
anti-monitoring mechanisms described in Sect. 3. Traﬃc based monitoring pas-
sively analyzes the network traﬃc and is therefore outside the scope of advanced
countermeasures. Approaches such as [8,17] can detect botnet traﬃc on top of
Internet Service Provider (ISP) level network traces. The beneﬁt of this approach
is that it provides a centralized view on all bot infections within the network
and their neighbors. Nevertheless, this approach is unlikely to provide a holistic
view of the botnet unless all ISPs cooperate and share their information.
Alternatively, another approach is to scan the Internet for botnet activity
on speciﬁc ports. Such a network scanning approach has already been done to
obtain bootstrap nodes for crawling the ZeroAccess botnet [15]. This requires
the botnet to use a ﬁxed port for its communication which is the case for botnets
such as the ZeroAccess family [18]. In fact, tools such as ZMAP are capable of
rapidly scanning the entire IPv4 address space [1]. However, many recent botnets
implement dynamic ports to avoid being scanned easily.
Another approach to obtain intelligence about a botnet can be to take control
of active bots. This could theoretically be realized by anti-virus companies or
operating system manufacturers. Once the malware is identiﬁed, the related
network traﬃc can be analyzed to identify other infected hosts. Furthermore,
if detailed knowledge about the malware is available, malicious traﬃc could be
blocked. This would allow the controlling parties to use the infected machines
themselves as monitors by analyzing the MM traﬃc.
In addition, it is also possible to run and observe botnet malware in a con-
trolled environment, such as a bare metal machine or a controlled virtual envi-
ronment. Contrary to taking control of an infected device, a clean machine is
deliberately infected with the botnet malware. This allows to set up machines
speciﬁcally for botnet monitoring, e.g. not storing sensitive data, rate limiting
network connections, or installing software to analyze the network traﬃc. Even
with such safeguards, legal and ethical limitations need to be considered with
this approach.
Deﬁning exactly how much information can be gathered under adverse con-
ditions is not possible, as combinations of monitoring and sophisticated counter-
measures will only lead to a never-ending arms race. However, all of the discussed
monitoring approaches can gather at least as much information as a regular bot
without being detected. In fact, network-based monitoring approaches on the
ISP level will likely observe traﬃc of multiple infections at once. To avoid the
aforementioned arms race, we focus on the worst-case scenario and establish a
lower boundary for monitoring under adverse conditions.
Based on the ﬁndings of this section, we want to deﬁne the term Monitoring
Device (MD) as any monitoring approach, that obtains intelligence based on the
view of a bot. Similarly, we deﬁne the term adverse conditions as a botnet envi-
ronment in which any behavior deviating form that of a normal bot can be auto-
matically detected by botmasters. Therefore, we argue that the lower boundary
518
L. B¨ock et al.
for monitoring operations in adverse conditions is limited to the knowledge/view
that can be obtained by any regular bot itself.
4.2 Limiting Monitoring Information Through the MM Design
The amount of information a single bot can obtain inﬂuences the results of
monitoring in adverse conditions. Hence, it is likely that botmasters will design
their botnets such that a single bot learns as less as possible about the botnet
without jeopardizing the resilience of the botnet itself. This can be achieved by
tweaking the MM protocol of the botnet. At its core, the MM protocol must
provide three features: maintain an NL, provide a means to update the NL and
frequently check the availability of neighbors. To identify how these requirements
are met by existing botnets, we identiﬁed and compared the related parameters
of ﬁve existing P2P botnets in Table 1.
The need of maintaining an NL is commonly addressed with two parameters,
the NL-size and the Neighborlist Minimum Threshold (NLMT). The NL-size is
an integer indicating the maximum size of the NL. The NLMT is another integer
indicating the minimum number of bots that should always be maintained. A
bot will not remove any more bots once this threshold is reached, and it will start
sending NL-requests to obtain fresh entries. Oftentimes, botnets do not explicitly
state an NLMT and instead have NL-size = NLMT. To update a bot’s NL, both
push or pull based NL-updates can be used. Push based updates allow a bot to
insert itself into another bot’s NL and are commonly only used for bots joining
a botnet. Pull based updates are usually realized through NL-request messages,
which allow a bot to ask actively for additional bots. NL-request messages are
often aﬀected by an Neighborlist Reply Size (NLRS) which limits the number
of bots shared upon a single request, and the Neighborlist Reply Preference
(NLRP) which deﬁnes how the shared bots are selected. Lastly, to check the
availability of their neighbors, bots commonly probe all NL-entries during the
MMI.
To illustrate how MM can be used to limit monitoring information, we con-
sider the following scenario. The NLMT indicates the minimal number of neigh-
bors with whom a bot communicates regularly. Thus, limiting the NLMT is an
eﬀective measure to limit the knowledge that can be obtained by a bot. However,
the NLMT is not the only parameter that can limit this type of knowledge. Other
parameters such as the MMI, the number of nodes returned upon an NL-request,
the churn behavior of the botnet or which neighbors are returned when being
requested, can inﬂuence the amount of knowledge each bot can obtain about
the botnet. In Sect. 6, we examine in detail, how each parameter inﬂuences the
knowledge obtainable by a single bot, i.e., the lower boundary knowledge for
monitoring operations under adverse conditions.
4.3 Botnet Design Constraints
Optimizing a botnet’s MM to impede monitoring operations, comes at a cost.
The usage of P2P overlays for inter-bot communication was initially intended
Next Generation P2P Botnets: Monitoring Under Adverse Conditions
519
Table 1. Analysis of common MM parameters and their values.
GameOver
Zeus [3]
Pull based updates Yes
Push based updates Always
Yes
Join
40 min
1000
1
980
30 min
50
<= 10
25
MMI
NL-size
NLRS
NLMT
NLRP
Sality [6] ZeroAccess
Kelihos F. [20]
Nugache [20]
[26]
Yes
Join
1 s
256
16
Yes
Join
10 min
3000
Yes
Join
Random
100
250 (v3), 500 (v5,v6) 100
Unknown
Unknown
Unknown
Latest
Custom
Random Latest
Latest
to improve the resilience against takedown attempts. However, we expect that
the resilience of a botnet’s overlay is inversely proportional to the monitoring
resistance of a botnet. That is, by limiting the knowledge obtainable by a bot,
the robustness of the resulting overlay suﬀers.
This can be visualized by observing two extreme cases. On the one hand,
the most resilient network architecture is a complete mesh in which each node
knows all other nodes in the system. Such a network is very resilient as the
failure of some nodes does not inﬂuence the connectivity of the remaining nodes.
However, in a complete mesh, every bot also has complete knowledge about the
botnet population. On the other hand, a minimally connected network such as
a ring provides minimal knowledge to nodes at the cost of poor resilience to
node failures or targeted attacks. Therefore, a botmaster has to consider both
resilience and resistance against monitoring operations when designing the MM.
4.4 Connecting the Dots
Within this section, we discussed possible approaches to conduct monitoring in
adverse conditions, how MM can be used to obstruct monitoring operations, and
the trade-oﬀ between monitoring resistance and resilience in MM design.
We argue, that we can use this information to identify a lower boundary for
the success of monitoring operations in any P2P botnet. In fact, we have dis-
cussed several approaches to monitor P2P botnets, that can at least obtain as
much knowledge as any regular bot. While the information of bots can be limited
through MM design, this is limited by the trade-oﬀ with resilience. Therefore,
we can establish a lower bound by determining the boundaries of optimal MM
designs. That is, identifying the MM parameters that provide the greatest mon-
itoring resistance while maintaining adequate resilience. In Sect. 6, we identify
and discuss, what constitutes such an optimal MM design and to what extent
monitoring is possible under such adverse conditions.
5 Modeling and Simulating Botnet Churn
As one of the core contributions of this paper, we propose and verify a novel
churn model and generator, focused on the simulation of botnet churn based on
520
L. B¨ock et al.
real world measurements. Section 5.1 discusses the shortcomings of existing churn
generators with regard to simulation of real world botnet churn. Furthermore,
Sect. 5.2 introduces our churn generator.
5.1 Simulation of Real World Churn Models
The availability of a bot’s neighbors directly inﬂuences whether old connections
are retained or if newer connections need to be established. Therefore, churn
signiﬁcantly impacts the overall structure of the botnet overlay. This is why we
consider churn generators as a crucial feature for a P2P botnet simulator.
A recent survey by Surati et al. [24] examined the existing P2P simulators.
We analyzed each of these simulators with regard to their churn generator func-
tionalities. Out of all simulators, Peerfactsim.kom [22] and OverSim [4] provide
the most advanced churn functionalities. Peerfactsim.kom implements a churn
generator that is based on the exponential distribution, whereas OverSim pro-
vides the choice between random, life-time and Pareto churn models. However,
according to Stutzbach et al. [23] exponential and Pareto distributions do not ﬁt
churn characteristics observed in real world P2P networks. Moreover, a random
churn model is also not suitable as it only provides rudimentary presentation
of churn and does not characterize the network accurately. This leaves only the
option of life-time based churn models. Such a churn, which is implemented in
OverSim, allows the usage of diﬀerent probability distributions, e.g., the Weibull
distribution. According to both [11,23], Weibull distributions ﬁt well with the
churn observed in regular P2P networks and P2P botnets.
However, the implementation in OverSim has two major drawbacks. First,
the life-time and down-time of nodes is drawn from the same probability distri-
bution. We speculate that this is done to allow for an easily adjustable active
population. However, this is a critical issue, as it is highly unrealistic that life-
and down-time distributions are equal, at least in the case of P2P botnets.
Second, the implementation in OverSim requires the overall population of the
simulated network to be exactly double of the desired active population. This
allows to have an equal number of active and inactive nodes. In combination