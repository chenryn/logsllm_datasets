and restoring of our simulated registers. The instructions on
lines 8–9 increment our simulated stack pointer and corre-
spond to line 3 in Fig. 2a. Similarly, lines 10–13 increment
the simulated instruction pointer to point to the next opcode,
as in line 4 of Fig. 2a.
While the example described above and pictured in Fig. 2
is for a single instruction, TASE instead generates interpretable
models for entire basic blocks of the original project. We
elaborate further in Sec. V-A.
7
E. State Management
In addition to managing the transition between native
execution and interpretation, TASE must also handle the
exploration of a potentially large number of execution paths.
Handling this “state explosion” problem is a crucial aspect of
symbolic execution, and has been a primary concern of many
papers [12], [10], [13], [17].
In TASE, multiple execution paths are explored in parallel
by using a native forking mechanism. Unlike other systems
that explore multiple execution states within a single address
space, TASE is unable to handle multiple execution states
concurrently within a single address space. Attempting to
explore states concurrently with multiple threads on one ad-
dress space could cause unintended transactional aborts when
threads access a common memory address.
Whenever the target program encounters a control ﬂow
instruction (e.g., a jmp or branch) that depends on a symbolic
variable, execution must revert to the interpreter. After the
interpreter takes control, execution states are created corre-
sponding to the different possible destinations of the control
ﬂow instruction, and the fork system call is invoked. The
resulting two processes extend the current execution in cases
that the branch condition is true or false, respectively. We
address indirect control-ﬂow transfers dependent on a symbolic
variable by producing an execution state for each possible
destination. EXE [11] uses a similar mechanism to handle state
exploration, and in both TASE and EXE this approach provides
the beneﬁt of hardware-based copy-on-write to mitigate the
cost of creating new processes. Both EXE and TASE also
have at
least some cases in which state exploration and
path prioritization require child processes to halt and wait
for a central state management process to authorize further
execution. This potentially introduces bottlenecks when many
child processes are exploring a large state space; however the
centralization of state management in a single process helps to
prevent “fork bombing” issues in which the machine hosting
TASE is overwhelmed with too many processes.
Forcing each process following a fork to signal back to
the central management process allows a variety of search
heuristics to be implemented by the central coordinator. We
intend to explore the use of simple heuristics, such as breadth-
ﬁrst and depth-ﬁrst search, as well as ones tailored to particular
applications. For example, in prior research on client behavior
veriﬁcation, Cochran et al. [19] leveraged the next message
inbound from the client to prioritize the order in which paths
were explored to identify a path consistent with that message
having been sent next by the client. This prioritization was
based on data collected from the client program during a
training phase. In this approach, when a path search reaches a
symbolic branch, the central coordinator determines which of
the currently paused processes—i.e., either the two resulting
from this fork, or another one—is on a path that is “closest”
to one that, in training, could typically be used to “explain” the
latest message received from the client. That process would
then be signaled to continue its search until reaching the
next symbolic branch. Of course, this prioritization is only
an example strategy, and we intend to explore others, as well.
V.
IMPLEMENTATION
In this section we brieﬂy discuss implementation details of
TASE.
A. IR Generation
Like other symbolic execution engines, TASE requires
an intermediate representation of code to perform symbolic
execution. Speciﬁcally, TASE uses LLVM IR to model each
x86 instruction that potentially touches symbolic data, as
discussed in Sec. IV-D.
Crucially, unlike some other symbolic execution tools,
TASE requires access to source code, from which TASE
produces an instrumented executable using a custom compiler.
Controlling the compiler allows us to selectively limit the
pool of instructions available to the LLVM backend’s code-
generation algorithms. This drastically simpliﬁes the laborious
task of producing IR models for x86 instructions, at the cost
of requiring source code.
Additionally, we use information provided by the LLVM
backend during compilation to record FLAGS-register liveness
information around basic blocks, which we use to periodically
kill the FLAGS register. This beneﬁts our execution in TASE
because it reduces the overall amount of symbolic data the
interpreter must handle, and, in certain situations, allows the
interpreter to more quickly produce a fully concrete copy of
its simulated GPRs needed to return to native execution.
Because execution within a basic block in TASE must
occur either entirely in the interpreter or natively for the dura-
tion of the basic block, we employ an additional optimization
to speed up interpretation. We “batch” the IR for all x86
instructions in a basic block together and invoke the interpreter
to interpret the whole basic block at once, rather than doing so
per instruction within the basic block. In practice, we observe
that this optimization reduces the total size of the LLVM
interpretation bitcode by a factor of roughly three. Assuming
access to source and control over the compiler also helps here;
by disabling the selection of instructions that modify certain
ﬂags bits (e.g., the direction ﬂag used by string-manipulation
instructions), the overall size of the IR is reduced and more
opportunities to omit redundant ﬂags computations appear.
Moreover, we found that reducing instruction selection based
on ﬂags usage offered opportunities to completely kill ﬂags in
certain cases after control ﬂow instructions were used, reducing
the likelihood of expressions “snowballing” together due to
ﬂags computations being continuously OR’d together.
Finally, we structured our C models of x86 instructions
to more effectively use the compiler’s aliasing optimizations.
For example, using the “restrict” keyword before accessing our
simulated register ﬁle or simply using local variables (rather
than pointer access, as used in Fig. 2) helped the compiler to
optimize as if the simulated registers and simulated memory
were separate address spaces, thus reducing the size the LLVM
IR models of the x86 instructions.
B. Forking and Path Exploration
As noted in Sec. IV-E, we employ a native Unix fork call
to explore multiple execution states in TASE when execution
encounters a symbolic branch. Execution in TASE begins with
a central “manager” process forking off a child process to
begin path exploration of the project’s code. The manager
uses signal-based job-control mechanisms, shared memory,
and system-level semaphores to steer and control execution
through different branches as a pre-deﬁned maximum number
of worker processes execute in parallel. If a worker encounters
a symbolic branch, it halts execution until the manager process
determines what course of action to take.
Native forking in TASE beneﬁts from hardware-based
copy-on-write, but still incurs overhead; among other things,
the Linux kernel copies the parent process’ page table entries
for the child [24]. To reduce this cost, our experiments in
TASE use the Linux transparent huge pages feature to reduce
the size of page table mappings without explicitly modifying
the applications. The daemon used by the kernel to coalesce
small (4KB) pages into huge (2MB) pages periodically runs
at a predeﬁned interval; we experimentally determined that
10ms appeared roughly optimal for our behavioral veriﬁcation
application in Sec. VI-B.
C. Transaction Sizing
As discussed in Sec. IV-B, the stride of a transaction in
TASE is set to a constant smax by default; after executing smax
basic blocks, the transaction will be closed. A value smax that is
too small will hurt performance by closing transactions more
frequently than necessary, whereas a value that is too large
can incur a substantial performance penalty when a transaction
aborts, since all the work it performed will be thrown away.
To maximize performance, smax would ideally be tuned per
project and per platform, since the size of the L1 data cache
limits the amount of data that a transaction can read or write
and since the frequency at which symbolic data is accessed
may vary depending on the application. In the future, we
plan to explore dynamically adjusting smax based on runtime
conditions, as well. For the purposes of our evaluation in
Sec. VI, we simply set smax = 16.
Because the basic block is the smallest granularity at which
transaction size can be controlled in TASE, it is also necessary
that basic blocks be limited to a maximum size. In our present
implementation, basic blocks are limited to 50 instructions.
Here again, the limit of 50 was chosen experimentally; we
plan to explore methods in future work to automatically tune
this constant.
VI. EVALUATION
In this section we measure TASE’s performance. We ﬁrst
detail TASE’s performance in a series of microbenchmarks in
Sec. VI-A, and then we consider an application of symbolic
execution to validating the messaging behavior of a software
client in Sec. VI-B. Finally, we explore application of TASE’s
techniques to memory protection in Sec. VI-C. All perfor-
mance experiments described in this section were conducted
on a computer with a 3.5GHz Intel Xeon CPU E3-1240 v5
processor and 64GB of RAM. All tools in the evaluation
were either Dockerized,2 or, if not Dockerized, ran directly
on Ubuntu 16.04.7.
2All Dockerized tools were executed in a fully-privileged container (i.e.,
with the “–privileged” ﬂag). Surprisingly, we observed that performance
degraded by up to a factor of 2 when containers were created with default
permissions.
8
Test
BigNum add
sha256
md5sum
cksum
tsort
factor
S2E
KLEE
QSYM
TASE SymCC
13.15× 11.40× 42.79× 903.63× 2403.53×
8.96× 13.95× 18.15× 2239.19× 1738.23×
12.27× 17.45× 71.94× 1904.99× 7208.67×
2.83× 7.23× 10.25× 691.18× 1137.48×
15.11× 7.51× 35.56× 1073.89× >20,000×
7.16× 4.41× 30.32× 1131.95× 1070.42×
TABLE I: Concrete computation costs relative to native ex-
ecution, averaged over ﬁve runs; relative standard deviations
were < 5.3%. BigNum addition was performed byte-by-byte
on two 10MB integers. Hashes were computed on a 44MB
ﬁle. tsort was run on a ﬁle with 500,000 edges. factor was run
on a 38-digit number with ﬁve prime factors.
A. Microbenchmarks
In this section we report the results of various microbench-
marks to compare TASE to alternatives when executing on
mostly concrete workloads—the contexts for which TASE
was designed. Our ﬁrst microbenchmark evaluations compared
TASE to native execution and execution by S2E, QSYM,
SymCC, and KLEE,3 for six programs: the ﬁrst added two
concrete 10MB integers byte-by-byte with a one-byte carry;
sha2564, md5sum5, and cksum6 were each applied to a con-
crete 44MB ﬁle; tsort7 was run on a ﬁle with 500,000 edges;
and factor8 was run on a 38-digit number with ﬁve prime
factors. These programs were compiled using Clang 7.1.0 with
O2 optimization for the native, S2E, and QSYM targets, and
with Clang 9.0.1 with O2 optimization for KLEE (as 9.0.1
was the Clang version included with KLEE). SymCC’s custom
compiler was run with O2 optimization. In contrast, TASE
supports only a limited version of O1 optimization at the time
of this writing. The results of these executions are shown
in Table I. TASE overheads ranged between ≈3–15× native
execution on these benchmark programs. SymCC overheads
ranged from ≈4–17× native execution. S2E was ≈10–72×
slower than native, and QSYM and KLEE incurred overheads
of ≈691–2239× and from ≈1070× to over 20,000× native
execution, respectively.
TASE is tailored to executing projects with small amounts
of symbolic data, and so increasing the amount of symbolic
data does impact its performance. Fig. 3 shows the perfor-
mance of byte-by-byte BigNum addition using the same code
represented in Table I (but only 50KB operands), but with a
byte at a varying index marked symbolic. Once this byte is
encountered, the carry byte becomes symbolic and remains so
for the rest of the computation; as such, the bytes of the sum
tainted by the symbolic carry byte are symbolic, as well.
The location of this symbolic data did not affect
the
3We used Dockerized QSYM from February 10, 2020 (https://github.
com/sslab-gatech/qsym); Dockerized KLEE from December 23, 2020 (https:
//klee.github.io/docker/); Dockerized SymCC from September 6, 2020 (https:
//github.com/eurecom-s3/symcc); and S2E retrieved on July 11, 2019 (https:
//github.com/s2e/s2e-env.git).
4https://github.com/coreutils/gnulib/blob/master/lib/sha256.c
5https://github.com/kﬂ/mosml/blob/master/src/runtime/md5sum.c
6https://github.com/coreutils/coreutils/blob/master/src/cksum.c