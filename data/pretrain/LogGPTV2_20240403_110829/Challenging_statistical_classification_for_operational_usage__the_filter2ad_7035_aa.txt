title:Challenging statistical classification for operational usage: the
ADSL case
author:Marcin Pietrzyk and
Jean-Laurent Costeux and
Guillaume Urvoy-Keller and
Taoufik En-Najjary
Challenging Statistical Classiﬁcation for Operational
Usage: the ADSL Case
Marcin Pietrzyk,
Jean-Laurent Costeux
Orange Labs, France
ﬁPI:EMAIL
Guillaume Urvoy-Keller,
Taouﬁk En-Najjary
Eurecom, France
{urvoy,ennajjar}@eurecom.fr
ABSTRACT
Accurate identiﬁcation of network traﬃc according to ap-
plication type is a key issue for most companies, including
ISPs. For example, some companies might want to ban p2p
traﬃc from their network while some ISPs might want to
oﬀer additional services based on the application. To clas-
sify applications on the ﬂy, most companies rely on deep
packet inspection (DPI) solutions. While DPI tools can be
accurate, they require constant updates of their signatures
database. Recently, several statistical traﬃc classiﬁcation
methods have been proposed. In this paper, we investigate
the use of these methods for an ADSL provider managing
many Points of Presence (PoPs). We demonstrate that sta-
tistical methods can oﬀer performance similar to the ones of
DPI tools when the classiﬁer is trained for a speciﬁc site. It
can also complement existing DPI techniques to mine traf-
ﬁc that the DPI solution failed to identify. However, we
also demonstrate that, even if a statistical classiﬁer is very
accurate on one site, the resulting model cannot be applied
directly to other locations. We show that this problem stems
from the statistical classiﬁer learning site speciﬁc informa-
tion.
Categories and Subject Descriptors: C.2.3 [Computer
Communication Networks]: Network Operations
General Terms: Measurements, Algorithms.
Keywords: Traﬃc Classiﬁcation, Machine Learning.
1.
INTRODUCTION
A key issue for companies and Internet Service Providers
(ISPs) is the ability to precisely identify the applications
ﬂowing in their networks. Motivations behind this need
are manifold: (i) enforcement of internal or national rules,
e.g., banning p2p traﬃc from an Intranet, (ii) better under-
standing of actual and emerging applications (iii) assessment
of the impact of those applications on peering agreements
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
IMC’09, November 4–6, 2009, Chicago, Illinois, USA.
Copyright 2009 ACM 978-1-60558-770-7/09/11 ...$10.00.
and/or the return on investment if some p4p initiative was
taken [23] or (iv) possibility to oﬀer additional services based
on application, e.g., protection of multimedia transfers.
The current state of the art for most companies, includ-
ing ISPs, is to rely on some proprietary solutions that im-
plement deep packet inspection (DPI) techniques featuring
signatures and ad-hoc heuristics to detect current applica-
tions. While this approach can be accurate, it is expensive,
scales poorly to high bandwidth and requires constant up-
dates of the signatures database to detect new applications
or new usage of existing applications or protocols. Further-
more, the growing trend of obfuscating traﬃc highlights the
need of alternative detection methods. Recently, several so-
lutions based on machine learning techniques and per ﬂow
features were proposed in the literature e.g. [13, 3, 2, 12, 14].
The majority of these techniques were tested on academic
traces, use diﬀerent traﬃc features as inputs to the statisti-
cal classiﬁcation algorithm and deﬁne ﬂows and application
classes diﬀerently.
In this paper, we adopt the perspective of an ADSL
provider. We are evaluating statistical classiﬁcation1 as a
complementary tool to deep packet inspection.
Indeed, it
might be too costly to deploy a DPI tool at each point of
presence (PoP) of an ISP. A typical use could be to de-
vise a statistical classiﬁer built upon the knowledge (refer-
ence point) collected on the PoPs where some DPI solutions
are available, to be deployed where those DPI solutions are
missing. In addition, whatever the DPI tool is used, there
is always a fraction of traﬃc that it can not identify.
In
our traces, this unidentiﬁed traﬃc represents between 8 and
24% of the bytes. A statistical classiﬁcation solution could
help decreasing those values.
We have collected several hour long traces at various ADSL
PoPs of a French ISP. Our data set is unique, as those traces
form an homogeneous set in the sense that they were cap-
tured at about the same period (beginning of 2008) and all
PoPs are under the control of the same ISP. Using those
traces, we address the following issues:
• Can we obtain a high classiﬁcation accuracy, and this,
for all the applications of interest?
• Can statistical methods help in mining the traﬃc that
DPI tools failed to classify?
1In this paper, we focus on supervised statistical classiﬁca-
tion where a speciﬁc machine learning algorithm is trained
on a so-called training set (for which the reference point is
known), using a speciﬁc set of features. We call statistical
classiﬁer the resulting tool.
122• Is the statistical model representative of the applica-
tions, i.e., can we train the classiﬁer on one site and
use it on another one without speciﬁc adjustments or
re-training? Could we use a statistical tool as a alter-
native to commercial DPI tools?
Contributions of our study can be categorized into two
sets. The ﬁrst set relates to the use of statistical techniques
for each site independently of the others. In such a sce-
nario, we demonstrate that:
• Statistical classiﬁcation can help revealing the traﬃc
left unknown by the ground truth establishment tool.
More precisely, we demonstrate that supervised clas-
siﬁcation techniques can divide by a factor of 2 the
amount of bytes previously unidentiﬁed by our DPI
tool.
• Statistical classiﬁcation is ﬂexible enough to allow to
group traﬃc based on application rather than protocol.
This is particularly important for the case of HTTP
that is a bearer for many applications ranging from
mail to video streaming.
When the statistical classiﬁer is applied on a site diﬀerent
from the one on which it was trained, we show that:
• Average performance is good – when considering all
ﬂows and applications – but results can greatly dete-
riorate on an application basis. This means that some
applications that are correctly classiﬁed when the clas-
siﬁer is applied on the same site where it was trained,
become diﬃcult to identify when applied on another
site. We demonstrate that many applications can suf-
fer from this problem, including mail, ftp and some p2p
applications. A precise investigation of those cases al-
lows us to prove that the problem stems from an over-
ﬁtting of the data, where the classiﬁer learns some site
speciﬁc characteristics used by local users/applications.
The remainder of this paper is organized as follows. After
reviewing related work in Section 2, we describe our data,
reference point establishment method and methodology in
Sections 3 and 4. Section 5 presents the results of classi-
ﬁcation per site.
In Section 6, we challenge the classiﬁer
in cross-site experiment. We show how statistical classiﬁca-
tion can help mining unknown traﬃc in Section 7. Section
8 concludes the paper.
2. RELATED WORK
Recently, many diﬀerent methods have been introduced
to solve the traﬃc classiﬁcation problem. Early approaches
relied on port numbers. Observation of the decrease of ac-
curacy of classical port number approaches was reported no-
tably in [9]. It triggered the emergence of deep packet in-
spection (DPI) solutions. In this approach, packet payloads
are checked against signatures of known applications [18].
The emergence of encryption and obfuscation of packet con-
tent, the need of constant updates of application signatures
and governments regulations, might however undermine the
ability to inspect packets content.
Newer approaches classify traﬃc by recognizing statisti-
cal patterns in externally observable attributes of the traf-
ﬁc. Their ultimate goal is either clustering IP traﬃc ﬂows
into groups that have similar traﬃc patterns, or classifying
one or more applications of interest. Moore et al.
in [14]
presented a statistical approach to classify the traﬃc into
diﬀerent types of services based on a combination of ﬂow
features. This line of inquiry attracted particular attention,
resulting in a variety of machine learning algorithms, ﬂow
features and heuristics, e.g., [15, 22, 5, 2, 4]. A systematic
survey of eighteen recent works is provided in [21].
Experience has shown that the combination of a small
number of ﬂow features already has a strong discriminative
power to diﬀerentiate services or network applications on a
given dataset. In this work, we focus on the spatial stability
of the classiﬁcation of ADSL traﬃc, i.e., the ability to train
a statistical classiﬁer on one site before using it to monitor
other sites. This is key issue for the operational deployment.
To the best of our knowledge, the only studies that tackled
this problem in a way similar to our are [12] and [13]. How-
ever, they considered either overly heterogeneous traces [12]
or traces collected in academic environments [13] and with
long periods of time (one year) between subsequent traces.
3. TRAFFIC DATA
In this section, we present our dataset, how we establish
the reference point (ground truth) that is used as bench-
mark for our statistical classiﬁer, the deﬁnition of our traﬃc
classes and the traﬃc breakdown.
3.1 Dataset
Our dataset consists of four recent packet traces collected
at three diﬀerent ADSL PoPs in France from the same ISP.
All traces were collected using passive probes located be-
hind a Broadband Access Server (BAS), which routes traﬃc
to and from the digital subscriber line access multiplexers
(DSLAM) and the Internet. Captures, which include full
packet payloads, were performed without any sampling or
loss and contains over four million TCP ﬂows. Each trace
contains at least one hour of full bidirectional traﬃc, with
similar number of active local users varying between 1380
and 2100. For details, see Table 1.
Traces have some important spatial and temporal features:
traces MSI and RIII were captured at exactly the same time
at two diﬀerent locations which helps assess spatial stability
of the method2. Traces RII and RIII were captured at the
same location with an oﬀset of seventeen days between them.
3.2 Reference point
In order to benchmark the performance of any classiﬁca-
tion method, a dataset with pre-labeled classes of traﬃc is
needed. We term such a dataset our reference point (a.k.a
ground truth). Establishing a reference point is fundamental
when evaluating traﬃc classiﬁcation mechanisms to provide
trust-worthy results. As a human-labeled dataset is almost
impossible to have, we rely on DPI tools.
Signatures commonly used in recent works [12, 5] provide
deceptive results with our traces, as more than 55 % of the
ﬂows are classiﬁed as unknown. To label applications in our
dataset, we rely on an internal tool of Orange, that we term
Orange DPI tool, or ODT for short. ODT is constantly un-
der developement and in use on several PoPs of Orange in
France. It can detect several types of applications, includ-
ing encrypted ones. We have compared ODT to Tstat [20],
2We also term this problem as the “cross-site” issue.
123Set
MS-I
R-II
R-III
T-I
Date
2008-02-04
2008-01-17
2008-02-04
2006-12-04
Start
14:45
17:05
14:45
12:54
Dur
1h
1h 10m
1h
1h 48m
Size [GB] Flows [M] TCP [%] TCP Bytes [%] Local users Distant IPs
26
55
36
60
0.99
1.8
1.3
4.1
63