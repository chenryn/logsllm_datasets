vacy constraints of CreateHeadList algorithm. If
mO > 1 is desired, one should modify the algorithm.
Remaining parameter choices (mC, fC, fO, M ) are
driven purely by utility considerations.
The number of records to collect from each
client, mC = 1: Across a range of experimental val-
ues, collecting 1 record per user always yielded great-
est utility, motivating this parameter choice. Apple
makes an analogous choice in their implementation
– they (temporarily) store all relevant items on a
client’s device, and then choose 1 item of each type
to transmit at random each day [37].
How to split the privacy budget between
query and url reporting for clients, fC = 0.85:
Figure 11 shows the eﬀects of the budget split on
both the L1 and NDCG metrics. Unsurprisingly,
Figure 11a shows that the larger the fraction of
client algorithm’s budget dedicated to query estima-
tion as opposed to URL estimation, the better the
L1 score for the client and Blender results. The
NDCG metric in Figure 11b shows a trade-oﬀ that
emerges as we assign more budget to the queries,
de-emphasizing the URLs; before and after 0.85, we
start seeing a drop in NDCG values for the client
algorithm. The orange opt-in line in Figure 11b is
constant, as the opt-in group is not aﬀected by the
budget split. Somewhat surprisingly with this pa-
rameter setting, the NDCG for Blender result is
also consistently high (nearly equal to and hidden
by the opt-in line) and is unaﬀected by the budget
split, unlike the L1 metric.
What fraction of opt-in data to use for cre-
ating the headlist, fO = 0.95: Our goal is to
build a large candidate head list, and unless we al-
locate most of the opt-in user data to building such
a head list (algorithm CreateHeadList), our sub-
sequent results may be accurate but apply only to
a small number of records. Since our opt-in group’s
size is small relative to our client group size, and it
is diﬃcult to generate a head list in the local pri-
vacy model – it makes sense to utilize most of the
opt-in group’s data for the task that is most diﬃcult
in the local model. Through experiment we observe
that increasing fO past 95% gives diminishing re-
turns for increasing the head list size; on the other
hand, there is a signiﬁcant utility gain (NDCG and
L1) from the use of a small fraction of opt-in users
for estimating probabilities of the head list. Thus,
rather than using the entire opt-in group for head
list generation (i.e., fO = 1), we reserve 5% of the
opt-in data for probability estimation.
What should be the ﬁnal size of the set for
which we provide probability estimates, M :
The choice of M is inﬂuenced by competing con-
siderations. The larger the head list for which we
provide the probability estimates, the more eﬀective
the local search application (subject to those proba-
bility estimates being accurate). However, as desired
head list size increases, the accuracy of our estimates
drops (most notably due to client data privatiza-
tion). We want to strike a balance that allows us
to get a sensibly large record set with reasonably ac-
curate probability estimates it. We choose M = 50
and M = 500 for the AOL and Yandex datasets, to
reﬂect their diﬀering sizes.
Subsequently, we use the parameters shown in Fig-
ure 10 unless explicitly stated.
4.2.2 Utility Comparison to Alternatives
The closest related work is a recent paper by
Qin et al. [34] for heavy hitter estimation with local
diﬀerential privacy, in which they provide a utility
USENIX Association
26th USENIX Security Symposium    757

δ
|O|
|O|+|C|
Parameter AOL
4
10−5
5%
1
1
0.95
0.85
50
mO
mC
fO
fC
M
Yandex
4
10−7
2.5%
1
1
0.95
0.85
500
Figure 10: Experimental parameters.
evaluation of their algorithm on the AOL data set
for the head list size of 10. We perform a direct
comparison of their NDCG results with Blender’s
across  values in the range of 1–5, which we plot
in Figure 12. Across the entire range of the pri-
vacy parameter, our NDCG values are above 95%,
whereas the reported NDCG values for Qin et al. are
in the 30% range, at best. We believe that given the
intense focus on search optimization in the ﬁeld of
information retrieval, NDCG values as low as those
of Qin et al. are generally unusable, especially for
such a small head list size. Overall, Blender signif-
icantly outperforms what we believe to be the closest
related research project.
A caveat to these ﬁndings is that Qin et al. [34]
and this work use slightly diﬀerent scoring func-
tions. The former’s relevance score is based on the
rank of queries in the original AOL data set, which
results in penalizing mis-ranked queries regardless
of how similar their underlying probabilities may
be. Blender’s relevance score relies on the under-
lying probabilities, so mis-ranked items with simi-
lar underlying probabilities have only a small nega-
tive impact on the overall NDCG score; we believe
this choice is justiﬁed. Although it yields increased
NDCG scores, Blender operates on records (rather
than queries, as Qin et al. does). Because of this, the
generalized NDCG score used to evaluate Blender
(Section 4) is a strictly less forgiving metric than
the traditional NDCG score. Thus, although simul-
taneously compensating for both diﬀerences would
yield the ideal comparison, the one in Figure 12 is
reasonable.
4.2.3 Robustness
We now discuss how the size of the opt-in group and
the choice of  aﬀect Blender’s utility.
Evaluation of trend computation: Figure 13
shows the L1 values as a function of the opt-in per-
centage ranging between 1% and 10%. We see slight
diﬀerences in the two data sets and across the var-
ious head list sizes. Some of the diﬀerences might
be due to the fact that given the relatively small
size of the AOL data set, we need to consider higher
opt-in percentages to get reasonably sized head lists
(a) L1
(b) NDCG
Figure 11: Comparing AOL data set results across a range of
budget splits for client, opt-in, and blended results.
Figure 12: Comparing to the results in the CCS’16 paper by
Qin et al. across a range of  values; head list size=10.
and L1 values. In fact, when we increase the opt-
in percentage to 10% for the AOL data set, we see
a decline in L1 values similar to what is observed
in Figure 13b for the Yandex data set. If our goal
is to have head lists of 500+, we see that with the
larger Yandex data set, an opt-in percentage as small
as 2.5% is suﬃcient to achieve high utility. On the
other hand, portions of lines do not appear on ﬁgures
if the desired head list size was not reached; e.g., in
Figure 13a, the line for a head list of size 50 does
not begin until 4.5% because that size head list was
not created with a smaller opt-in percentage.
758    26th USENIX Security Symposium
USENIX Association
00.010.020.030.040.050.550.650.750.850.95Query estimate L1 distanceClient budget split fractionBlendedClientOpt-in0.85, 0.6944067520.50.550.60.650.70.750.80.850.90.9510.550.650.750.850.95NDCGClient budget split fractionBlendedClientOpt-in0.9620.9710.9710.9730.9750.1750.2950.3150.3600.38500.10.20.30.40.50.60.70.80.9112345NDCGepsilonBlenderCCS'16(a) AOL
(a) AOL
(b) Yandex
(b) Yandex
Figure 13: L1 statistics as a function of the opt-in percentage
for select head list sizes.
Figure 14: NDCG statistics as a function of the opt-in percent-
age for select head list sizes.
Figure 15 shows the L1 values as a function of ,
ranging from 1 to 5. For both data sets, we see a
steady decline in the L1 metric, despite aggregating
L1 values over longer estimate vectors. With more
data in the Yandex data set, we are able to hit small
values of L1 (under 0.1) with  ≥ 1. Similar to the
case with small opt-in percentages, having too small
an  makes it diﬃcult to achieve head lists of their
target size; e.g., in Figure 15a, the line for a head
list of size 50 does not begin until  = 3 because that
size head list was not created with a smaller  value.
Evaluation of local search computation: Fig-
ure 14 shows the NDCG measurements as a func-
tion of the opt-in percentage ranging between 1%
and 10%. The results are quite encouraging; for the
smaller AOL data set, for instance, we need to have
an opt-in level of ≈5% to achieve an NDCG level
of 95%, which we regard as acceptable. However, for
the larger Yandex data set, we hit that NDCG level
even sooner: the NDCG value for 1.5% is above 95%
for all but the largest head list size.
Figure 16 shows how the NDCG values vary across
the two data sets for a range of head list sizes and
 values. We see a clear trend toward higher NDCG
values for Yandex, which is not surprising given the
sheer volume of data. For the Yandex data set, we
can keep  as low as 1 and still achieve NDCG values
of 95% and above for all but the two largest head
list sizes. For those, we must increase  in order to
generate larger head lists from the opt-in users.
5 Related Work
Algorithms for the trusted curator model:
Researchers have developed numerous diﬀerentially
private algorithms operating in the trusted curator
model that result in useful data for a variety of ap-
plications. For example, [24, 26, 16, 31] address the
problem of publishing a subset of the data contained
in a search log with diﬀerential privacy guarantees;
[27] and [6] propose approaches for frequent item
identiﬁcation; [14] propose an approach for monitor-
ing aggregated web browsing activities; and so on.
Algorithms for the local model: Although the
demand for privacy-preserving algorithms operating
in the local model has increased in recent years, par-
USENIX Association
26th USENIX Security Symposium    759
00.010.020.030.040.051.00%1.50%2.00%2.50%3.00%3.50%4.00%4.50%5.00%5.50%6.00%6.50%7.00%7.50%8.00%8.50%9.00%9.50%10.00%Query estimate L1 distancePercentage of users that opt-in10255000.020.040.060.080.10.121.00%1.50%2.00%2.50%3.00%3.50%4.00%4.50%5.00%5.50%6.00%6.50%7.00%7.50%8.00%8.50%9.00%9.50%10.00%Query estimate L1 distancePercentage of users that opt-in1025501005000.90.910.920.930.940.950.960.970.980.9911.00%1.50%2.00%2.50%3.00%3.50%4.00%4.50%5.00%5.50%6.00%6.50%7.00%7.50%8.00%8.50%9.00%9.50%10.00%NDCGPercentage of users that opt-in1025500.90.910.920.930.940.950.960.970.980.9911.00%1.50%2.00%2.50%3.00%3.50%4.00%4.50%5.00%5.50%6.00%6.50%7.00%7.50%8.00%8.50%9.00%9.50%10.00%NDCGPercentage of users that opt-in102550100500(a) AOL
(a) AOL
(b) Yandex
(b) Yandex
Figure 15: L1 statistics for AOL and Yandex data sets as a
function of  for select head list sizes.
Figure 16: NDCG statistics for AOL and Yandex data sets as a
function of  for select head list sizes.
ticularly among practitioners [17, 35], fewer such al-
gorithms are known [40, 19, 8, 13, 5]. Furthermore,
the utility of the resulting data obtained through
these algorithms is signiﬁcantly limited compared to
what is possible in the trusted curator model, as
shown experimentally [15, 21] and theoretically [22].
The recent work of [34] also takes a two-stage ap-
proach: ﬁrst, spend some part of the privacy budget
to learn a candidate head list and then use the re-
maining privacy budget to reﬁne the probability esti-
mates of the candidates. However, that’s where the
similarities with Blender end, as [34] focuses en-
tirely on the local model (and thus has to use entirely
diﬀerent algorithms from ours for each stage) and
addresses the problem of estimating probabilities of
queries, rather than the more challenging problem
of estimating probabilities of query-URL pairs.
Our contribution: Our work signiﬁcantly im-
proves upon the known results by developing
application-speciﬁc local privatization algorithms
that work in combination with the trusted curator
model algorithms. Speciﬁcally, our insight of pro-
viding all users with diﬀerential privacy guarantees
but achieving it diﬀerently depending on whether
or not they trust the data curator, enables an eﬃ-
cient privacy-preserving head list construction. The
subsequent usage of this head list in the algorithm
operating in the local model helps overcome one of
the main challenges to utility of privacy-preserving
algorithms in the local model [15]. Moreover, the
weighted aggregation of probability estimates ob-
tained from algorithms operating in the two models
(that explicitly factors in the amount of noise each
contributed), enabled remarkable utility gains com-
pared to usage of one algorithm’s estimates. As dis-
cussed in Section 4.2.2, we signiﬁcantly outperform
the most recently introduced local algorithm of [34]
on metrics of utility in the search context.
6 Discussion
Operating in the hybrid model is most beneﬁcial
utility-wise if the opt-in user records and client user
records come from the same distribution – i.e., the
two groups have fairly similar observed search be-
havior. If that is not the case, the diﬀerential privacy
760    26th USENIX Security Symposium
USENIX Association
00.0050.010.0150.020.0250.030.03512345Query estimate L1 distanceepsilon10255000.010.020.030.040.050.0612345Query estimate L1 distanceepsilon1025501005000.90.910.920.930.940.950.960.970.980.99112345NDCGepsilon1025500.950.9550.960.9650.970.9750.980.9850.990.995112345NDCGepsilon102550100500guarantees still hold, but the accuracy of Blender’s
estimates may decrease.
Improvement in utility over what can be achieved
in the local model comes from two sources: the hy-
brid privacy model lets us develop a better algorithm
for client data collection and the analysis of algo-
rithms’ variances lets us smartly combine the results.
In practice, a system for local search or trend com-
putation would be run at regular intervals in order
to refresh the data as well as accommodate for users
being added to, removed from, or moving between
the opt-in and the client groups. We have focused on
the problem of obtaining local search or trend com-
putation results for a single execution of the system.
While one could simply re-run Blender at regular
intervals to obtain new results (with potentially dif-
ferent opt-in and client groups), this comes at a cost
to privacy. We leave the task of improving the tem-
poral aspect of Blender beyond what is achievable
with standard composition techniques of diﬀerential
privacy [11] to future work.
7 Conclusions
We proposed a hybrid privacy model and a blended
approach that operates within it that combines the
upsides of two common models of diﬀerential pri-
vacy: the local model and the trusted curator model.
Using local search as a motivating application, we
demonstrated that our proposed approach leads to
a signiﬁcant improvement in terms of utility, bridg-
ing the gap between theory and practicality.
Future work: We plan to continue this work in two
directions: ﬁrst, to address any systems and engi-
neering challenges to Blender’s adoption in prac-
tice, including those that arise due to data chang-
ing over time; and second, to develop algorithms for
other settings where the hybrid privacy model is ap-
propriate, thus facilitating adoption of diﬀerential
privacy in practice by minimizing the utility impact
of privacy-preserving data collection.
References
[1] Acquisti, A., Brandimarte, L., and Loewenstein, G.
Privacy and human behavior in the age of information.
Science 347, 6221 (2015), 509–514.
[2] Acquisti, A., and Grossklags, J. Privacy and ratio-
nality in individual decision making. IEEE Security and
Privacy 3, 1 (2005), 26–33.
[3] Baeza-Yates, R., Gionis, A., Junqueira, F., Mur-
dock, V., Plachouras, V., and Silvestri, F. The
impact of caching on search engines.
In ACM SIGIR
Conference on Research and Development in Informa-
tion Retrieval (2007), pp. 183–190.
[4] Baeza-Yates, R., Gionis, A., Junqueira, F. P., Mur-
dock, V., Plachouras, V., and Silvestri, F. Design
trade-oﬀs for search engine caching. ACM Transactions
on the Web 2, 4 (2008), 20.
[5] Bassily, R., and Smith, A. Local, private, eﬃcient
protocols for succinct histograms. In Proceedings of the
Symposium on Theory of Computing (STOC) (2015),
pp. 127–135.
[6] Bhaskar, R., Laxman, S., Smith, A., and Thakurta,