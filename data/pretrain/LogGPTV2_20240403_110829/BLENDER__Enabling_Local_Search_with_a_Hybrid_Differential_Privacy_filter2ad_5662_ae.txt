### Privacy Constraints and Parameter Choices for the CreateHeadList Algorithm

If a value of \( mO > 1 \) is desired, the CreateHeadList algorithm must be modified. The remaining parameter choices (i.e., \( mC \), \( fC \), \( fO \), and \( M \)) are driven by utility considerations.

#### Number of Records to Collect from Each Client (\( mC = 1 \))

Across a range of experimental values, collecting one record per user consistently yielded the highest utility. This motivates the choice of \( mC = 1 \). Apple employs a similar strategy in their implementation: they temporarily store all relevant items on a client’s device and then randomly select one item of each type to transmit daily [37].

#### Budget Split Between Query and URL Reporting for Clients (\( fC = 0.85 \))

Figure 11 illustrates the effects of the budget split on both the L1 and NDCG metrics. As expected, Figure 11a shows that allocating a larger fraction of the client algorithm's budget to query estimation (as opposed to URL estimation) improves the L1 score for both the client and Blender results. However, Figure 11b reveals a trade-off: as more budget is assigned to queries, the NDCG metric for the client algorithm begins to drop after 0.85. The opt-in group, represented by the orange line in Figure 11b, remains unaffected by the budget split. Surprisingly, the NDCG for the Blender result remains consistently high (nearly equal to and hidden by the opt-in line) and is not influenced by the budget split, unlike the L1 metric.

#### Fraction of Opt-In Data for Creating the Headlist (\( fO = 0.95 \))

Our goal is to build a large candidate head list. Unless most of the opt-in user data is allocated to this task, our subsequent results may be accurate but apply only to a small number of records. Given the relatively small size of our opt-in group compared to the client group, and the difficulty of generating a head list in the local privacy model, it makes sense to utilize most of the opt-in group's data for the more challenging task. Experiments show that increasing \( fO \) beyond 95% provides diminishing returns for the head list size. Conversely, using a small fraction of opt-in users for probability estimation yields significant utility gains (NDCG and L1). Therefore, we reserve 5% of the opt-in data for probability estimation, rather than using the entire opt-in group for head list generation (i.e., \( fO = 1 \)).

#### Final Size of the Set for Probability Estimates (\( M \))

The choice of \( M \) is influenced by competing considerations. A larger head list with accurate probability estimates enhances the effectiveness of the local search application. However, as the desired head list size increases, the accuracy of our estimates decreases, primarily due to client data privatization. We aim to strike a balance that allows us to generate a reasonably large record set with accurate probability estimates. For the AOL and Yandex datasets, we choose \( M = 50 \) and \( M = 500 \), respectively, to reflect their differing sizes.

Subsequently, we use the parameters shown in Figure 10 unless explicitly stated otherwise.

### Utility Comparison to Alternatives

The closest related work is a recent paper by Qin et al. [34], which evaluates heavy hitter estimation with local differential privacy. They provide a utility evaluation of their algorithm on the AOL dataset for a head list size of 10. We compare their NDCG results with Blender's across a range of \( \epsilon \) values (1–5), as shown in Figure 12. Across the entire range of the privacy parameter, our NDCG values exceed 95%, while Qin et al.'s reported NDCG values are in the 30% range at best. Given the focus on search optimization in information retrieval, such low NDCG values are generally unusable, especially for a small head list size. Overall, Blender significantly outperforms the closest related research project.

A caveat to these findings is that Qin et al. [34] and our work use slightly different scoring functions. Qin et al.'s relevance score is based on the rank of queries in the original AOL dataset, penalizing mis-ranked queries regardless of their underlying probabilities. In contrast, Blender's relevance score relies on the underlying probabilities, so mis-ranked items with similar probabilities have only a small negative impact on the overall NDCG score. Although this yields higher NDCG scores, Blender operates on records rather than queries, making the generalized NDCG score used to evaluate Blender a stricter metric than the traditional NDCG score. Thus, while simultaneously compensating for both differences would yield the ideal comparison, the one in Figure 12 is reasonable.

### Robustness

We now discuss how the size of the opt-in group and the choice of \( \epsilon \) affect Blender's utility.

#### Evaluation of Trend Computation

Figure 13 shows the L1 values as a function of the opt-in percentage ranging between 1% and 10%. Slight differences are observed between the two datasets and across various head list sizes. These differences may be due to the relatively small size of the AOL dataset, which requires higher opt-in percentages to generate reasonably sized head lists. When the opt-in percentage is increased to 10% for the AOL dataset, a decline in L1 values is observed, similar to what is seen in Figure 13b for the Yandex dataset. For head lists of 500 or more, an opt-in percentage as small as 2.5% is sufficient for the larger Yandex dataset to achieve high utility. Portions of lines do not appear in figures if the desired head list size was not reached; for example, in Figure 13a, the line for a head list of size 50 does not begin until 4.5% because that size head list was not created with a smaller opt-in percentage.

#### Evaluation of Local Search Computation

Figure 14 shows the NDCG measurements as a function of the opt-in percentage ranging between 1% and 10%. The results are encouraging: for the smaller AOL dataset, an opt-in level of approximately 5% is needed to achieve an NDCG level of 95%, which is acceptable. For the larger Yandex dataset, an NDCG level above 95% is achieved even sooner, with an opt-in percentage of 1.5% for all but the largest head list size.

Figure 16 shows how the NDCG values vary across the two datasets for a range of head list sizes and \( \epsilon \) values. A clear trend toward higher NDCG values for the Yandex dataset is observed, given its larger volume of data. For the Yandex dataset, \( \epsilon \) can be as low as 1 and still achieve NDCG values of 95% and above for all but the two largest head list sizes. For those, \( \epsilon \) must be increased to generate larger head lists from the opt-in users.

### Related Work

#### Algorithms for the Trusted Curator Model

Researchers have developed numerous differentially private algorithms operating in the trusted curator model, resulting in useful data for various applications. For example, [24, 26, 16, 31] address the problem of publishing a subset of the data contained in a search log with differential privacy guarantees; [27] and [6] propose approaches for frequent item identification; [14] propose an approach for monitoring aggregated web browsing activities; and so on.

#### Algorithms for the Local Model

Although the demand for privacy-preserving algorithms operating in the local model has increased, particularly among practitioners [17, 35], fewer such algorithms are known [40, 19, 8, 13, 5]. The utility of the resulting data obtained through these algorithms is significantly limited compared to what is possible in the trusted curator model, as shown experimentally [15, 21] and theoretically [22]. The recent work of [34] also takes a two-stage approach: first, spending some part of the privacy budget to learn a candidate head list and then using the remaining budget to refine the probability estimates of the candidates. However, [34] focuses entirely on the local model and addresses the problem of estimating probabilities of queries, rather than the more challenging problem of estimating probabilities of query-URL pairs.

### Our Contribution

Our work significantly improves upon known results by developing application-specific local privatization algorithms that work in combination with trusted curator model algorithms. Specifically, our insight of providing all users with differential privacy guarantees but achieving it differently depending on whether they trust the data curator enables efficient privacy-preserving head list construction. The subsequent usage of this head list in the local model algorithm helps overcome one of the main challenges to utility in the local model [15]. Moreover, the weighted aggregation of probability estimates obtained from algorithms operating in the two models, factoring in the amount of noise each contributed, enabled remarkable utility gains compared to using one algorithm's estimates. As discussed in Section 4.2.2, we significantly outperform the most recently introduced local algorithm of [34] on metrics of utility in the search context.

### Discussion

Operating in the hybrid model is most beneficial utility-wise if the opt-in user records and client user records come from the same distribution, i.e., the two groups have fairly similar observed search behavior. If this is not the case, the differential privacy guarantees still hold, but the accuracy of Blender's estimates may decrease. Improvement in utility over what can be achieved in the local model comes from two sources: the hybrid privacy model allows for a better algorithm for client data collection, and the analysis of algorithms' variances enables smart combination of results. In practice, a system for local search or trend computation would be run at regular intervals to refresh the data and accommodate changes in user groups. While re-running Blender at regular intervals is possible, it comes at a cost to privacy. Improving the temporal aspect of Blender beyond standard composition techniques of differential privacy [11] is left for future work.

### Conclusions

We proposed a hybrid privacy model and a blended approach that combines the advantages of the local model and the trusted curator model. Using local search as a motivating application, we demonstrated that our approach leads to a significant improvement in utility, bridging the gap between theory and practicality. Future work will address systems and engineering challenges for Blender's adoption in practice, including handling data changes over time, and develop algorithms for other settings where the hybrid privacy model is appropriate, thus facilitating the adoption of differential privacy in practice by minimizing the utility impact of privacy-preserving data collection.

### References

[1] Acquisti, A., Brandimarte, L., and Loewenstein, G. Privacy and human behavior in the age of information. Science 347, 6221 (2015), 509–514.
[2] Acquisti, A., and Grossklags, J. Privacy and rationality in individual decision making. IEEE Security and Privacy 3, 1 (2005), 26–33.
[3] Baeza-Yates, R., Gionis, A., Junqueira, F., Murdock, V., Plachouras, V., and Silvestri, F. The impact of caching on search engines. In ACM SIGIR Conference on Research and Development in Information Retrieval (2007), pp. 183–190.
[4] Baeza-Yates, R., Gionis, A., Junqueira, F. P., Murdock, V., Plachouras, V., and Silvestri, F. Design trade-offs for search engine caching. ACM Transactions on the Web 2, 4 (2008), 20.
[5] Bassily, R., and Smith, A. Local, private, efficient protocols for succinct histograms. In Proceedings of the Symposium on Theory of Computing (STOC) (2015), pp. 127–135.
[6] Bhaskar, R., Laxman, S., Smith, A., and Thakurta,