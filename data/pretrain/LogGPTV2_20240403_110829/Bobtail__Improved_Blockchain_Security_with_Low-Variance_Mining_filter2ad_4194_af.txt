Protocols,” in Proc. Conference on Secure Information Networks:
Communications and Multimedia Security, 1999, pp. 258–272. [Online].
Available: http://dl.acm.org/citation.cfm?id=647800.757199
[30] A. Juels and J. Brainard, “Client puzzles: A cryptographic counter-
measure against connection depletion attacks.” in Proc. Networks and
Distributed Security Systems, 1999, pp. 151–165.
[31] E. K. Kogias, P. Jovanovic, N. Gailly, I. Khofﬁ, L. Gasser, and B. Ford,
“Enhancing bitcoin security and performance with strong consistency
via collective signing,” in Proc. USENIX Security Symposium, 2016, pp.
279–296.
[32] B. Laurie and R. Clayton, ““Proof-of-work” proves not to work; version
0.2,” in Proc. Workshop on Economics and Information Security, 2004.
[33] Litecoin, https://litecoin.org/.
[34] A. Miller, A. Juels, E. Shi, B. Parno, and J. Katz, “Permacoin:
Repurposing bitcoin work for data preservation,” in Proc. IEEE Security
and Privacy, 2014, pp. 475–490.
[35] S. Nakamoto, “Bitcoin: A Peer-to-Peer Electronic Cash System,” https:
//bitcoin.org/bitcoin.pdf, May 2009.
[36] A. P. Ozisik, G. Andresen, G. Bissias, A. Houmansadr, and B. N.
Levine, “Graphene: A New Protocol for Block Propagation Using Set
Reconciliation,” in Proc. of International Workshop on Cryptocurrencies
and Blockchain Technology (ESORICS Workshop), Sept 2017.
[37] A. P. Ozisik and B. N. Levine, “An Explanation of Nakamoto’s Analysis
of Double-spend Attacks,” University of Massachusetts, Amherst, MA,
Tech. Rep. arXiv:1701.03977, January 2017.
[38] A. P. Ozisik, B. N. Levine, G. Bissias, G. Andresen, G. Bissias, D. Tapp,
and S. Katkuri, “Graphene: Efﬁcient Interactive Set Reconciliation
Applied to Blockchain Propagation,” in Proc. ACM SIGCOMM, August
2019.
[39] R. Pass and E. Shi, “Fruitchains: A fair blockchain,” in Proc. ACM
Symposium on Principles of Distributed Computing, 2017, pp. 315–324.
[40] P. Rizun, “Subchains: A Technique to Scale Bitcoin and Improve the
User Experience,” Ledger, vol. 1, pp. 38–52, 2016.
[41] A. Sapirshtein, Y. Sompolinsky, and A. Zohar, “Optimal Selﬁsh Mining
Strategies in Bitcoin,” in Proc. Financial Cryptography and Data Security
(See also https://arxiv.org/pdf/1507.06183.pdf ), Feb 2016.
[42] M. Vukoli´c, “ The Quest for Scalable Blockchain Fabric: Proof-of-Work
vs. BFT Replication,” in International Workshop on Open Problems in
Network Security, 2015.
[43] X. Wang and M. K. Reiter, “Defending against denial-of-service attacks
with puzzle auctions,” in Proc. IEEE Symposium on Security and Privacy,
2003, pp. 78–92.
[44] R. Zhang and B. Preneel, “Lay Down the Common Metrics: Evaluating
Proof-of-Work Consensus Protocols’ Security,” in IEEE Symposium on
Security and Privacy, 2019.
APPENDIX
In this appendix, we prove that Vi, the value of the ith order
statistic, is gamma distributed (Theorem 6). We also prove that
Xi, which is the number of hash intervals required for the
ith order statistic to fall below target v, is gamma distributed
(Theorem 7). Both theorems are applied in Section IV. We then
derive the joint distribution of the ith and jth order statistics
in Lemma 8, which is applied in Section IV-C.
A. Properties of Bobtail Order Statistics
We begin with a supporting lemma. Consider the distribution
of H an arbitrary random variable chosen from the sequence
of block hashes H1, . . . , Hh. We have fH (t; S) = 1/S and
FH (t; S) = t/S.
LEMMA 7: The probability density function (PDF) of
the ith order statistic, Vi, from h samples (i.e., hashes) is
fVi(t; S, h) =
=
(i−1)!(h−i)! fH (t) (FH (t))i−1 (1 − FH (t))h−i
(i−1)!(h−i)!
(cid:1)i−1(cid:0)1 − t
(cid:1)h−i
(cid:0) t
1
S
h!
h!
S
S
.
(23)
The above result is well known; see for example, Casella and
Berger [12].
When hash interval I corresponds to the desired block
time, say 600 seconds for Bitcoin, there will be many hashes
performed during the interval. So it is reasonable to consider
how the distribution for Vi changes in the limit
that h
approaches inﬁnity.
THEOREM 6:
In the limit that h approaches inﬁnity,
Vi ∼ Gamma(i, v), where v is the expected value of the
minimum hash.
PROOF: Deﬁne g(t; i, v) to be the PDF of the gamma
distribution with shape parameter i and scale parameter v.
If the number of hashes approaches inﬁnity, then so must the
15
size of the hash space, and yet S must always be larger than
h. Therefore, we assume that h = S/v for arbitrary parameter
v > 1. Under this assumption we can equivalently consider the
limit that S approaches inﬁnity. We have
fVi(t; S, h) = lim
h→∞ fVi(t; S, h)
(cid:1)i−1(cid:0)1 − t
(cid:0) t
(cid:1) S
ti−1(cid:0)1 − t
(cid:21)(cid:104)
(cid:0)1 − t
S
v −i
S
S
lim
S→∞
S
= lim
S→∞
(S/v)!
(i−1)!( S
v −i)!
1
S
(cid:20)
(S/v)!
Si(i−1)!( S
v −i)!
v −i+1)
v )...( S
Si
( S
= lim
S→∞
= ti−1
(i−1)!
ti−1
=
(i−1)!vi e
lim
S→∞
−t
v
= g(t; i, v),
v −i
(cid:1) S
v −i(cid:105)
(cid:1) S
(24)
(25)
The second-to-last step follows from the fact that
(cid:0) S
(cid:1)i
= lim
S→∞
v
Si =
1
vi ,
(cid:0) S
v
(cid:1) . . .(cid:0) S
lim
S→∞
Si
and the common limit
which implies that
v −i
(cid:0)1 − t
S
(cid:1) S
lim
S→∞
v − i + 1(cid:1)
(cid:18)
(cid:104)
1 − t
S
lim
=
S→∞
= 1 · e
−t
v .
v
(cid:19) S
(cid:0)1 − t
S
lim
S→∞
−t
v ,
= e
(cid:1)−i(cid:105)(cid:104)
(26)
v(cid:105)
(cid:1) S
(cid:0)1 − t
S
lim
S→∞
(27)
When i = 1, V1 ∼ Gamma(t; 1, v) = Exponential(t; v).
And since the expected value of an exponential random variable
is equal to the value of its scale parameter, we can see that v
is simply the expected value of the minimum hash.
Next, deﬁne Xi as the number of intervals required for Vi
to fall below v, and consider the PDF of Xi, fXi(x; S, v). After
x hash intervals, let E, L, and G be, respectively, the events
that the ith order statistic is equal to v, the order statistics
below i are less than v, and the order statistics above i are
greater than v. Furthermore, let O be the set of all divisions of
H1, . . . , Hh into distinct sets {H | H = Vi}, {H | H  Vi}. We have
fXi (x; S, v) = (cid:80)
=(cid:0) hx
o∈O
P [E(x), L(x), G(x) | o]
(cid:1)(hx−i+1) · Pr[E(x)|o] · Pr[L(x)|o] · Pr[G(x)|o]
i−1
(i−1)!(hx−i)! · Pr[E(x)|o] · Pr[L(x)|o] · Pr[G(x)|o]
(i−1)!(hx−i)!
(cid:1)i−1(cid:0)1 − v
(cid:1)hx−i
(cid:0) v
(hx)!
(hx)!
1
S
S
S
=
=
(28)
Assuming that I is large, it again makes sense to consider
the limit as h approaches inﬁnity.
THEOREM 7:
In the limit that h approaches inﬁnity,
Xi ∼ Gamma(i, 1/r) where r is the expected rate, in
units of I, at which Vi falls below v.
PROOF: The probability that any given hash succeeds, i.e.
falls below v, is given by p = v
S . Again, we would like to
consider the limit as h approaches inﬁnity. But in doing so,
we must ensure that p remains constant. In other words, the
probability of hash success must diminish as h increases. So
there must exist some constant r such that r
S . It
follows that
h = p = v
(cid:0) r
h
(cid:1)i−1(cid:0)1 − r
h
(cid:1)hx−i
(29)
fXi(x; S, v) =
(hx)!
(i−1)!(hx−i)!
r
h
Arguing in similar fashion as for Vi, we ﬁnd that
lim
h→∞ fXi(x; S, v) = g(x; i, 1/r).
Thus, E[Xi] = 1/r, which implies that r should be interpreted
as the expected rate at which Vi falls below v during a single
interval I.
2
B. Joint Distribution
Here we derive the limiting joint distribution of the ith and
jth order statistics Vi and Vj, which are applied in Section IV-C
to derive the variance of Wk.
LEMMA 8:
In the limit that h approaches inﬁnity, the
joint distribution of the ith and jth order statistics of
uniform random samples H1, . . . , Hh is given by
fVi,Vj (ti, tj; v) = g(ti; i, v)g(tj − ti; j − i, v).
(30)
where v is the expected value of the minimum hash.
2
PROOF: It is well known5 that the joint distribution of the
ith and jth order statistics, out of h total samples, is given by
(i−1)!(j−1−i)!(h−j)! fH (ti)fH (tj)[FH (ti)]i−1
fVi,Vj (ti, tj; v) =
× [FH (tj) − FH (ti)]j−1−i[1 − FH (tj)]n−j.
(31)
h!
Thus, we have
fVi,Vj (ti, tj; S, v)
i
(tj−ti)j−1−i
= ti−1
Sj
v −j+1)
v ...( S
Sj
=
S
h!
(i−1)!(j−1−i)!(h−j)!
ti−1
(tj−ti)j−1−i
1 − tj
(i−1)!(j−1−i)!
S
i
(cid:16)
(cid:17)h−j
(cid:16)
(cid:17) S
1 − tj
v −j
S
.
(32)
Finally, assuming j > i, and reasoning in the limit as S → ∞
in the same manner as in Theorem 6,
fVi,Vj (ti, tj; v) = lim
i
(tj−ti)j−1−i
S→∞ fVi,Vj (ti, tj; S, v)
ti−1
(i−1)!(j−1−i)! e− tj
vj−i(j−1−i)! e− tj−ti
(tj−ti)j−1−i
= 1
vj
= ti−1
= g(ti; i, v)g(tj − ti; j − i, v).
vi(i−1)! e− ti
v
v
v
i
(33)
2
5See Casella and Berger [12], Theorem 5.4.6.
16