get
able
paying-the-wannacry-ransom-will-probably-get-you-nothing-heres-why.
html.
ransom will
PCWorld,
2017,
at
[37] G. Kaptchuk, I. Miers, and M. Green, “Managing secrets with consensus
networks: Fairness, ransomware and access control,” Cryptology ePrint
Archive, Report 2017/201 (Revision 20170228:194725), 2017, https:
//eprint.iacr.org/2017/201.
[38] B. Kauer, “OSLO: Improving the Security of Trusted Computing,” in
Usenix ’07. Berkeley, CA, USA: USENIX Association, 2007. [Online].
Available: http://dl.acm.org/citation.cfm?id=1362903.1362919
[39] A. Kosba, A. Miller, E. Shi, Z. Wen, and C. Papamanthou, “Hawk:
The blockchain model of cryptography and privacy-preserving smart
contracts,” in 2016 IEEE Symposium on Security and Privacy (SP),
May 2016, pp. 839–858.
I. Krsti´c, “Behind the Scenes with iOS Security,” In BlackHat. Avail-
able
at https://www.blackhat.com/docs/us-16/materials/us-16-Krstic.
pdf, August 2016.
[40]
[41] LastPass, “How is LastPass secure and how does it encrypt/decrypt
my data safely?” Available at https://lastpass.com/support.php?cmd=
showfaq&id=6926, 2017.
[42] K. Lewi, A. J. Malozemoff, D. Apon, B. Carmer, A. Foltzer,
D. Wagner, D. W. Archer, D. Boneh, J. Katz, and M. Raykova, “5gen:
A framework for prototyping applications using multilinear maps and
matrix branching programs,” in Proceedings of the 2016 ACM SIGSAC
Conference on Computer and Communications Security, ser. CCS ’16.
New York, NY, USA: ACM, 2016, pp. 981–992. [Online]. Available:
http://doi.acm.org/10.1145/2976749.2978314
J. Liu, T.
Jager, S. A. Kakvi, and B. Warinschi, “How to
build time-lock encryption,” Designs, Codes and Cryptography,
vol. 86, no. 11, pp. 2549–2586, Nov 2018.
[Online]. Available:
https://doi.org/10.1007/s10623-018-0461-x
[43]
[44] S. Matetic, M. Ahmed, K. Kostiainen, A. Dhar, D. Sommer, A. Gervais,
A. Juels, and S. Capkun, “ROTE: Rollback protection for trusted
execution,” Cryptology ePrint Archive, Report 2017/048, 2017, http:
//eprint.iacr.org/2017/048.
[45] F. McKeen, I. Alexandrovich, A. Berenzon, C. V. Rozas, H. Shaﬁ,
V. Shanbhogue, and U. R. Savagaonkar, “Innovative instructions and
software model for isolated execution.” in HASP@ ISCA, 2013, p. 10.
[46] M. Milutinovic, W. He, H. Wu, and M. Kanwal, “Proof of luck: an
efﬁcient blockchain consensus protocol,” Cryptology ePrint Archive,
Report 2017/249, 2017, https://eprint.iacr.org/2017/249.
[47] S. Nakamoto, “Bitcoin: A peer-to-peer electronic cash system, 2008,”
2008. [Online]. Available: http://www.bitcoin.org/bitcoin.pdf
[48] K. Nayak, C. W. Fletcher, L. Ren, N. Chandran, S. Lokam, E. Shi, and
V. Goyal, “HOP: hardware makes obfuscation practical,” in NDSS ’17,
2017.
[49] D. Paletta, “FBI Chief Punches Back on Encryption,” Wall Street
Journal, July 2015. [Online]. Available: http://www.wsj.com/articles/
fbi-chief-punches-back-on-encryption-1436217665
[50] B. Parno, J. R. Lorch, J. R. Douceur, J. Mickens, and J. M.
McCune, “Memoir: Practical state continuity for protected modules,”
in Proceedings of the 2011 IEEE Symposium on Security and Privacy,
ser. SP ’11. Washington, DC, USA: IEEE Computer Society, 2011,
pp. 379–394. [Online]. Available: https://doi.org/10.1109/SP.2011.38
[51] K. Poulsen, “DirecTV attacks hacked smart cards,” The Reg-
ister, 2001, https://www.theregister.co.uk/2001/01/25/directv attacks
hacked smart cards/.
[52] A. Project, “Full-Disk Encryption,” Available at https://source.android.
com/security/encryption/full-disk.html, 2017.
[53] D. Rao, “Intel SGX Product Licensing,” Available at https://software.
intel.com/en-us/articles/intel-sgx-product-licensing, 2016.
[54] P. Rogaway, “Authenticated encryption with associated data,” in CCS
’02. ACM Press, 2002.
[55] ——, “Formalizing human ignorance,” in VIETCRYPT 2006, P. Q.
Nguyen, Ed. Berlin, Heidelberg: Springer Berlin Heidelberg, 2006,
pp. 211–228.
[56] D.
Sinegubko,
- CBT-Locker Goes
Blockchain,” Sucuri Blog. Available at https://blog.sucuri.net/2016/04/
website-ransomware-ctb-locker-goes-blockchain.html, April 2016.
“Website Ransomware
[57] S. Skorobogatov, “The bumpy road towards iPhone 5c NAND
mirroring,” CoRR, vol. abs/1609.04327, 2016. [Online]. Available:
http://arxiv.org/abs/1609.04327
14
[58] S. P. Skorobogatov and R. J. Anderson, “Optical fault
induction
attacks,” in CHES ’02, B. S. Kaliski, c¸. K. Koc¸, and C. Paar,
Eds. Berlin, Heidelberg: Springer Berlin Heidelberg, 2003, pp. 2–12.
[Online]. Available: https://doi.org/10.1007/3-540-36400-5 2
[59] Technology.org, “Ransomware authors arrest cases,” Available at http:
//www.technology.org/2016/11/21/ransomware-authors-arrest-cases/,
November 2016.
[60] M. Tran, L. Luu, M. S. Kang, I. Bentov, and P. Saxena, “Obscuro: A
bitcoin mixer using trusted execution environments,” Cryptology ePrint
Archive, Report 2017/974, 2017, http://eprint.iacr.org/2017/974.
[61] B. Ur, S. M. Segreti, L. Bauer, N. Christin, L. F. Cranor,
S. Komanduri, D. Kurilova, M. L. Mazurek, W. Melicher, and
R. Shay, “Measuring real-world accuracies and biases in modeling
password guessability,” in 24th USENIX Security Symposium (USENIX
Security 15). Washington, D.C.: USENIX Association, 2015,
pp. 463–481. [Online]. Available: https://www.usenix.org/conference/
usenixsecurity15/technical-sessions/presentation/ur
J. Van Bulck, M. Minkin, O. Weisse, D. Genkin, B. Kasikci, F. Piessens,
M. Silberstein, T. F. Wenisch, Y. Yarom, and R. Strackx, “Foreshadow:
Extracting the keys to the Intel SGX kingdom with transient out-
of-order execution,” in Proceedings of
the 27th USENIX Security
Symposium. USENIX Association, August 2018, see also technical
report Foreshadow-NG [?].
[62]
[63] N. Weaver, “iPhones,
August 2015.
iphones-fbi-and-going-dark
the FBI, and Going Dark,” Lawfare Blog,
[Online]. Available: https://www.lawfareblog.com/
[64] K.
Zetter,
“Why
ransomware,”
ransomware-why-hospitals-are-the-perfect-targets/, 2016.
Available
hospitals
at
are
the
for
https://www.wired.com/2016/03/
perfect
targets
[65] F. Zhang, E. Cecchetti, K. Croman, A. Juels, and E. Shi, “Town crier:
An authenticated data feed for smart contracts,” in Proceedings of the
2016 ACM SIGSAC Conference on Computer and Communications
Security, ser. CCS ’16. New York, NY, USA: ACM, 2016, pp. 270–
282. [Online]. Available: http://doi.acm.org/10.1145/2976749.2978326
APPENDIX
Proof Sketch. Due to lack of space, we provide a proof sketch
with many of the details omitted. A complete proof of security
is available in the full version of this work.
We give a simulation based deﬁnition for ELI, and we use
two basic experiments in our proof. In the Real experiment,
we consider an interaction in which an adversarial host user H
interacts with an honest Ledger Oracle and an honest Enclave
Oracle, as described in §III, to execute the ELI protocol. The
Ideal experiment has adversarial ideal host ˆH that interacts
with a trusted, multi-step, computational functionality, exposed
as a Compute Oracle. At each step of the experiment, this
functionality takes as input a program, a program input, and
a “session ID” provided by ˆH, and runs the program using
real random coins and with the most recent program state it
has associated with this session ID. The trusted functionality
stores the resulting state internally, records the public outputs
on a table available to all parties, and returns both outputs to
the user. This ideal model intuitively describes what we wish
to accomplish from a secure multi-step interactive computing
system.
We augment
these experiments slightly to account for
ledger authenticator forgability. Particularly when the ledger
authenticator tags are secured economically, we must ensure
that the security degrades gracefully in face of a small number
of forgeries. While we cannot prevent an attack from obtaining
some advantage from successfully forging an authenticator,
we can successfully bound the attacker’s capability in this
setting. To capture this notion in our proof, we give the Real
experiment adversary access to a Forgery Oracle. In the
Ideal experiment, we provide a Fork Oracle that allows the
adversary to run a single step of computation using an older
state of their choosing. In each experiment, the adversary can
only make a maximum of qforge queries to these oracles.
We prove that for every p.p.t. adversarial real-world hosts
H, there must exist a p.p.t. ideal-world host ˆH that does “as
well” in the ideal experiment as the real host does in the
real experiment. Note that this would imply that a real-world
adversary with the ability to forge qforge authenticators would
be able to make exactly qforge single step computations, a very
reasonable bound. Formally:
Deﬁnition 1 (Simulation security for ELI): An
ELI
scheme Π = (ExecuteApplication, ExecuteEnclave)
is
simulation-secure if for every p.p.t. adversary H, sufﬁciently
large λ, and non-negative qforge, there exists a p.p.t. ˆH such
that the following holds:
Real(H, λ, qforge)
c≈ Ideal( ˆH, λ, qforge)
Proof Sketch: Given the space concerns, we cannot give the
full description of the ideal-world adversary ˆH. Intuitively, ˆH
mediates the communication between H and the oracles. When
H attempts to query the Ledger Oracle, ˆH forwards it to the
real ledger. When H queries Enclave Oracle, ˆH references
its internal records of previous interactions and decides if it is
(1) an invalid query, (2) a previous query, (3) a query with a
forged authenticator, or (4) a fresh query. In case (1), ˆH aborts.
In case (2), ˆH replays the appropriate old output. In case (2),
ˆH forwards the request to the Forgery Oracle. And ﬁnally, in
case (3), ˆH forwards the query to the Compute Oracle. The
bulk of the proof is showing that ˆH can distinguish each of
these cases successfully.
Discussion. Let D be a p.p.t. distinguisher that succeeds in
distinguishing ˆH’s output in the Ideal experiment from H’s
output in the Real experiment with non-negligible advantage.
The proof proceeds via a series of hybrids, where in each
hybrid H interacts as in the Real experiment. The ﬁrst hybrid
(Game 0) is identically distributed to the Real experiment,
and the ﬁnal hybrid represents ˆH’s simulation above. We enu-
merate the hybrids below but, due to space constraints, omit the
proof that each pair is computationally indistinguishable. The
proof concludes by invoking the hybrid lemma to show that the
Real experiment and Ideal experiment are indistinguishable.
Game 0 is simply the Real experiment. We now sketch the
remaining games:
Game 1 (Abort on [adversary-]forged authenticators.)
If H queries the Enclave oracle on (post, σ) such that (1)
Ledger.Verify(post, σ) = 1, and yet (2) the pair was not the
input (resp. output) of a previous call to either the Ledger or
Forgery oracles, then abort and output Eventforge. This event
occurs with at most negligible probability if authenticators are
unforgeable.
Game 2 (Abort on hash collisions.) If H causes the
functions H, HL to be evaluated on inputs s1 (cid:54)= s2 such that
H(s1) = H(s2) or HL(s1) = HL(s2), then abort and output
Eventhashcoll. This occurs with at most negligible probability if
the hash is collision resistant.
H queries
= Cj
collisions.)
If
the Enclave oracle at
i, j where Ci
= Commit(pp, (i, Ii,Si, P, posti.CID); ri) =
commitment
steps
Game 3 (Abort
on
yet
and
Commit(pp, j(cid:107)Ij(cid:107)Sj(cid:107)posti.CID; rj)
(i, Ii,Si, Pi,
posti.CID) (cid:54)= (j, Ij,Sj, Pj, postj.CID), then abort and output
Eventbinding. This occurs with at most negligible probability
if the commitment is binding.
Game 4 (Duplicate Enclave calls give identical out-
puts.) If H queries the Enclave oracle repeatedly on the same
values (Pi, i, Ii,Si, posti) (here we exclude σi) and the oracle
(as implemented in the previous hybrid) does not output ⊥,
replace the response to all repeated queries subsequent to the
ﬁrst query with the same result as the ﬁrst query. This does not
change the distribution because the scheme is deterministic.
Game 5 (Abort on colliding ledger hashes.) If H
quries the Enclave oracle on two distinct inputs (Pi, i, Ii,Si,
posti, σi) and (Pj, j, Ij,Sj, postj, σj), and if the two inputs do
not represent repeated inputs (according to Game 4), then: if
both (posti, σi) and (postj, σj) are valid outputs of the Ledger
oracle and yet posti.Hash = postj.Hash then abort and output
Eventledgercoll. This occurs with at most negligible probability
if the hash is collision resistant.
Game 6 ( ˆH can always uniquely identify CID.) This
hybrid modiﬁes the previous as follows:
if at step i the
adversary H calls the Enclave the oracle (as implemented in
the previous hybrid) and (1) the oracle does not return ⊥, (2)
the inputs to the two calls are not identical (this would be
excluded by the earlier hybrids), and (3) the pair (posti, σi)
are in the Ledger table, and (4) posti.Hash matches two
distinct entries in the Ledger table, then abort and output
Eventledgerrepeat. This event occurs with at most negligible
probability.
Game 7 (Replace the session keys and pseudorandom
coins with random strings.) If Enclave does not abort or
is not called on repeated inputs, then the pair (ki+1, ¯ri) is
sampled uniformly at random and recorded in a table for later
use. The use of a PRF makes this hybrid indistinguishable
from the previous,.
Game 8 (Reject inauthentic ciphertexts.) If H queries
the Enclave oracle on an input Si (cid:54)= ε such that (1) the oracle
does not reject the input, (2) Decrypt(ki,Si) does not output
⊥, and yet (3) the pair (Si, ki) was not generated during a
previous query to Enclave, then abort and output Eventauth.
If the scheme is AE, this event occurs with at most negligible
probability.
Game 9 (Abort if inputs are inconsistent.) On H’s the
ith query to the Enclave oracle, when the input Si
(cid:54)= ε,
let (post.CID
) be the inputs/outputs associated
that produced Si. If (1)
with the previous Enclave call
the experiment has not already aborted due to a condition
described in previous hybrids and (2) if the Enclave oracle
as implemented in the previous hybrid does not reject the
input, and (3) any of the provided inputs (post.CID, P, i −
1, Pubi−1) (cid:54)= (post.CID
) differ from those
associated with the previous call to the Enclave, abort and
output Eventmismatch. This event cannot occur in the current
protocol.
, P (cid:48), i(cid:48), Pubi−1
, P (cid:48), i(cid:48), Pubi−1
(cid:48)
(cid:48)
(cid:48)
(cid:48)
Game 10 (Replace ciphertexts with dummy cipher-
texts.) This hybrid modiﬁes the previous as follows: we modify
the generation of each ciphertext S(cid:48)
out to encrypt the unary
string (1Max(P ), 1(cid:96)). If the scheme is AE, then this hybrid
cannot be distinguished vrom the previous.
15