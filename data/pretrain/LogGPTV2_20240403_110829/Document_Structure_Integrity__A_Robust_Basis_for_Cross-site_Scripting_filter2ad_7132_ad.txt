### Mechanisms for Taint Information and Selective Delimiter Placement

Mechanisms that provide taint information can be directly utilized to selectively place delimiters in server output. We have experimented with PHPTaint [38], an implementation of taint-tracking in the PHP 5.2.5 engine, to automatically augment minimal serialization primitives for all tainted data seen in the web server's output. We enabled dynamic taint tracking for GET/POST request parameters and database pulls. We disabled taint declassification for data sanitized by PHP sanitization functions, as we treat even sanitized data as potentially malicious. All tainted output data are augmented with surrounding delimiters for minimal serialization. Our modifications demonstrate that automatic serialization is possible using off-the-shelf tools.

For more complex websites with a multi-component architecture, cross-component dynamic taint analysis may be necessary. This is an active area of research, and automatic support for minimal serialization at the server side would benefit from advances in this field. Recent techniques proposed for program analysis to identify taint-style vulnerabilities [22, 16] could help identify taint sink points in larger web applications, where manual identification is challenging. Similarly, Nanda et al. have shown that cross-component dynamic taint tracking for the LAMP architecture is feasible [25].

### Communicating Valid Suffixes

In our design, it is sufficient to communicate {Cs, n} securely, where Cs is the random number generator seed and n is the number of invocations to generate the set C of valid delimiter suffixes. Our scheme communicates these as two special HTML tag attributes, `seed` and `suffixsetlength`, as part of the HTML head tag. We assume that the server and the browser use the same pseudo-random number generator. Once read by the browser, it generates this set for the entire lifetime of the page and does not recompute it, even if the attacker corrupts the value of the special attributes dynamically. We have verified that this scheme is backward-compatible with HTML handling in current browsers, i.e., these special attributes are completely ignored for rendering in current browsers.

### Choice of Serialization Alphabet for Encoding Delimiters

We discuss two schemes for encoding delimiters:

1. **Unicode Whitespace Characters:**
   - We propose using byte values from the Unicode Character Database [37] that render as whitespace on major browsers, independent of the selected character set used for web page decoding. The rationale for using whitespace characters is their uniformity across all common character sets and the fact that they do not hinder parsing of HTML or script in most relevant contexts (including between tags, between attributes and values, and strings). In certain exceptional contexts where these may hinder parsing semantics, these errors would show up in pre-deployment testing and can be easily fixed.
   - There are 20 such character values that can be used to encode start and end delimiter symbols. All of these characters, as shown in Appendix A, render as whitespace on current browsers. To encode the delimiters' random suffixes, we can use the remaining 18 characters (2 are used for delimiters themselves) as symbols. Thus, each symbol can encode 18 possible values, so a suffix ℓ symbols long should be sufficient to yield an entropy of ℓ × log₂(18) or (ℓ × 4.16) bits.
   - A compliant browser can easily distinguish pages served from a non-compliant web server versus a randomization-compliant web server by checking the `seed` attribute in the `<head>` element of the web page. When a compliant browser views a non-compliant page, it treats the delimiter encoding bytes as whitespace per current semantics. When a compliant browser renders a compliant web page, it treats any found delimiter characters as valid only if they have valid suffixes; otherwise, it discards the sequence of characters as whitespace. This ensures the scheme is secure whether the page is DSI-compliant or not.

2. **Special Delimiter Tags:**
   - Another approach is to use special delimiter tags, e.g., `<qtag check="suffix">`. Qtags have a lesser impact on code readability than the above scheme. Qtags use the same encoding mechanism as `<qtag>` tags proposed informally [7]. We verified that they render safely in today’s popular browsers in most contexts but are unsuitable for use in certain contexts, such as within strings. Additionally, XHTML does not allow attributes in end tags, so they may not render well in XHTML pages on non-compliant browsers and may be difficult to standardize.

### Policy Specification

Our policies confine untrusted data only. Currently, we support per-page policies enforced for the entire web page rather than region-based policies. By default, we enforce the terminal confinement policy, which is a fail-close policy. In most cases, this policy is sufficient for several websites to defend against reflected XSS attacks. A more flexible policy allows certain HTML syntactic constructs in inline untrusted data, such as a restricted set of HTML markup in user blog posts. We support a whitelist of syntactic HTML elements as part of a configurable policy.

We allow configurable specification of whitelisted HTML construct names through an `allowuser` tag attribute for the `<html>` tag, which can have a comma-separated list of allowed tags. For instance, the following specification would allow untrusted nodes corresponding to paragraph, boldface, line break elements, the `id` attribute (in all elements), and the anchor element with an optional `href` attribute (only with the anchor element) in the parse tree to not be flagged as an exploit. The following markup renders properly in non-compliant browsers since unknown markup is discarded in popular browsers.

For security, untrusted data is disallowed to define the `allowuser` tag without exception. Policy development and standardization of default policies are important problems that involve a detailed study of common elements safe to allow on most websites. However, we consider this beyond the scope of this paper but deem it worthy of future work.

### Implementation

#### DSI-Compliant Browser

We have implemented a proof-of-concept PLI-enabled web browser by modifying Konqueror 3.5.9. Before each HTML parsing operation, the HTML parsing engine identifies special delimiter tags. This step is performed before any character decoding, and our choice of the Unicode alphabet for delimiters ensures compatibility with all character set encodings. The modified browser simulates a pushdown automaton during parsing to keep track of delimiter symbols for matching. Delimited characters are initialized as quarantined, represented by enhancing the type declaration for the character class in Konqueror with a quarantine bit. Parse tree nodes derived from quarantined characters are also marked as quarantined. Before any quarantined internal node is updated to the document’s parse tree, the parser invokes the policy checker to ensure the update is permitted by the policy. Any internal nodes not permitted by the policy are collapsed with their subtree and rendered as a string literal.

We modified the JavaScript interpreter in Konqueror 3.5.9 to facilitate automatic quarantine bit tracking and prevent tainted access through the JavaScript-DOM interface. The modifications required substantial effort compared to the HTML parser modifications. Internal object representations were enhanced to store the quarantine bits, and handlers for each JavaScript operation were altered to propagate the quarantine bits. The implemented policy checks ensure that quarantined data is only interpreted as a terminal in the JavaScript language.

#### DSI-Compliant Server

We employed PHPTaint [38], an existing implementation of dynamic taint tracking in the PHP interpreter. It enables taint variables in PHP and can be configured to indicate which data sources are marked as tainted in the server. We made minor modifications to PHPTaint to integrate it into our framework. By default, when untrusted data is processed by a built-in sanitization routine, PHPTaint endorses the data as safe and declassifies (or clears) the taint. We changed this behavior to not declassify taint in such situations, even though the data is sanitized. Whenever data is echoed to the output, we interpose in PHPTaint and surround tainted data with special delimiter tags with randomized values at runtime. For serialization, we used the Unicode character U+2029 as a start-delimiter, followed by ℓ randomly chosen Unicode whitespace characters (the key) from the remaining 18 Unicode characters. We chose ℓ = 10, though this is easily configurable in our implementation. Following the key is the end-delimiter U+2028 to signify that the key has been fully read.

#### Example Application

Figure 9(a) shows a vulnerable web forum application, phpBB version 2.0.18, running on a vanilla Apache 1.3.41 web server with PHP 5.2.5, viewed with a vanilla Konqueror 3.5.9 with no DSI enforcement. The attacker posts a post containing a script tag, resulting in a cookie alert. To prevent such attacks, we deployed the phpBB forum application on our DSI-compliant web server. No changes to the web application code were required. Figure 9(b) shows how the attack is nullified by our client-server DSI enforcement prototype, which employs PHPTaint to automatically mark forum data (derived from the database) as tainted, enhances it with minimal serialization, and enables a DSI-compliant version of Konqueror 3.5.9 to nullify the attack.

#### Client-Side Proxy Server

For evaluating 5,328 real-world websites, we could not use our prototype taint-enabled PHP-based server because we do not have access to the server code of the vulnerable websites. To overcome this, we implemented a client-side proxy server that approximately mimics the server-side operations. When the browser visits a vulnerable website, the proxy web server records all GET/POST data sent by the browser and maintains state about the HTTP request parameters. The proxy performs content-based tainting across data sent to the real server and the received response, approximating what the server would do in a full deployment of the client-server architecture. The proxy performs a lexical string match between the sent parameter data and the data received in the HTTP response. For all data in the HTTP response that matches, the proxy performs minimal serialization (approximating the operations of a DSI-compliant server) by lexically adding randomized delimiters to demarcate matched data in the response page as untrusted, before forwarding it to the PLI-enabled browser.

### Evaluation

To evaluate the effectiveness and overhead of PLI and PLI-enabled browsers, we conducted experiments with two configurations. The first configuration consists of running our prototype PLI-enabled browser and a server running PHPTaint with the phpBB application. This configuration was used to evaluate effectiveness against stored XSS attacks. The second configuration ran our PLI-enabled web browser, directing all HTTP requests to the proxy web server described in section 7. This configuration was used to study real-world reflected attacks, as we did not have access to the vulnerable web server code.

#### Experimental Setup

Our experiments were performed on two systems: one ran Mac OS X 10.4.11 on a 2.0 GHz Intel processor with 2 GB of memory, and the other ran Gentoo GNU/Linux 2.6.17.6 on a 3.4 GHz Intel Xeon processor with 2 GB of memory. The first machine ran an Apache 1.3.41 web server with PHP 5.2.5 engine and MySQL backend, while the second ran the DSI-compliant Konqueror. The two machines were connected by a 100 Mbps switch. We configured our prototype PLI-enabled browser and server to apply the default policy of terminal confinement to all web requests unless the server overrides with another whitelisting-based policy.

#### Experimental Results and Analysis

##### Attack Detection

| Attack Category | # Attacks | # Prevented |
|-----------------|-----------|-------------|
| Reflected XSS   | 5,328     | 5,243 (98.4%) |
| Stored XSS      | 25        | 25 (100%)    |

Figure 10: Effectiveness of DSI enforcement against both reflected XSS attacks [43] and stored XSS attack vectors [12].

In the reflected XSS category, there were 5,328 websites in our final test dataset. Our DSI-enforcement using the proxy web server and DSI-compliant browser nullified 98.4% of these attacks. Further analysis of the false negatives revealed that 46 of the remaining cases were missed because the real web server modified the attack input before embedding it on the web page. Our web server proxy failed to recognize this server-side modification, as it performs a simple string matching between data sent by the browser and the received HTTP response. We believe that in full deployment, these would be captured with the server explicitly demarcating untrusted data. We could not determine the cause of missing the remaining 39, as the sent input was not discernible in the HTTP response web page. We showed that the policy of terminal confinement, if supported in web servers as the default, is sufficient to prevent a large majority of reflected XSS attacks.

##### Performance Overheads

We evaluated the performance overheads of our system. For the stored XSS experiment, we set up a vulnerable version of the phpBB web blog application (version 2.0.18) on our DSI-enabled web server and injected 30 benign text and HTML-based posts, along with all stored attack vectors taken from XSS performance [1]. The system was configured to generate dynamic forum web pages of sizes varying from 10 KB to 40 KB. In our experiment, 64,000 requests were issued to the server with 16 concurrent requests. As shown in Figure 12, we observed average CPU overheads of 1.2%, 2.9%, and 3.1% for pages of 10 KB, 20 KB, and 40 KB in size, respectively. This is consistent with the performance overheads reported by the authors of PHPTaint [38]. Figure 11 shows a comparison between the vanilla web server and a DSI-compliant web server (both running phpBB) in terms of the percentage of HTTP requests completed within a certain response time frame. For 10 concurrent requests, the two servers perform nearly identically, whereas for 30 concurrent requests, the server with PHPTaint shows some degradation for completing more than 95% of the requests.

##### False Positives

We observed a lower false positive rate in our stored XSS attacks experiment than in the reflected XSS experiment. In the stored experiment, we did not observe any false positives. In the reflected XSS experiment, we observed false positives when we deliberately provided inputs that matched existing page content. For the latter experiment, we manually browsed the Global Top 500 websites listed on Alexa [2], browsing with deliberate intent to raise false positives. For each website, we visited an average of 3 second-level pages by creating accounts, logging in with malicious inputs, and performing searches for dangerous keywords.