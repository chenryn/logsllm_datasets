title:Deep-Dup: An Adversarial Weight Duplication Attack Framework to Crush
Deep Neural Network in Multi-Tenant FPGA
author:Adnan Siraj Rakin and
Yukui Luo and
Xiaolin Xu and
Deliang Fan
Deep-Dup: An Adversarial Weight Duplication 
Attack Framework to Crush Deep Neural Network 
in Multi-Tenant FPGA
Adnan Siraj Rakin, Arizona State University; Yukui Luo and Xiaolin Xu, 
Northeastern University; Deliang Fan, Arizona State University
https://www.usenix.org/conference/usenixsecurity21/presentation/rakin
This paper is included in the Proceedings of the 30th USENIX Security Symposium.August 11–13, 2021978-1-939133-24-3Open access to the Proceedings of the 30th USENIX Security Symposium is sponsored by USENIX.Deep-Dup: An Adversarial Weight Duplication Attack Framework to Crush Deep
Neural Network in Multi-Tenant FPGA
Adnan Siraj Rakin *
Yukui Luo *
Xiaolin Xu
Arizona State University
Northeastern University
PI:EMAIL
PI:EMAIL
Northeastern University
PI:EMAIL
Deliang Fan
Arizona State University
PI:EMAIL
*Both Authors Contributed Equally
Abstract
The wide deployment of Deep Neural Networks (DNN) in
high-performance cloud computing platforms brought to light
multi-tenant cloud ﬁeld-programmable gate arrays (FPGA) as
a popular choice of accelerator to boost performance due to
its hardware reprogramming ﬂexibility. Such a multi-tenant
FPGA setup for DNN acceleration potentially exposes DNN
interference tasks under severe threat from malicious users.
This work, to the best of our knowledge, is the ﬁrst to ex-
plore DNN model vulnerabilities in multi-tenant FPGAs. We
propose a novel adversarial attack framework: Deep-Dup, in
which the adversarial tenant can inject adversarial faults to
the DNN model in the victim tenant of FPGA. Speciﬁcally,
she can aggressively overload the shared power distribution
system of FPGA with malicious power-plundering circuits,
achieving adversarial weight duplication (AWD) hardware at-
tack that duplicates certain DNN weight packages during data
transmission between off-chip memory and on-chip buffer,
to hijack the DNN function of the victim tenant. Further,
to identify the most vulnerable DNN weight packages for
a given malicious objective, we propose a generic vulnera-
ble weight package searching algorithm, called Progressive
Differential Evolution Search (P-DES), which is, for the ﬁrst
time, adaptive to both deep learning white-box and black-box
attack models. The proposed Deep-Dup is experimentally val-
idated in a developed multi-tenant FPGA prototype, for two
popular deep learning applications, i.e., Object Detection and
Image Classiﬁcation. Successful attacks are demonstrated in
six popular DNN architectures (e.g., YOLOv2, ResNet-50,
MobileNet, etc.) on three datasets (COCO, CIFAR-10, and
ImageNet).
1 Introduction
Machine Learning (ML), especially deep neural networks
(DNN), services in high-performance cloud computing are
gaining extreme popularity due to their remarkable perfor-
mance in intelligent image/video recognition [1–4], natural
language processing [5–7], medical diagnostics [8], malware
detection [9], and autonomous driving [10, 11]. Similar to
many other high-performance computing (HPC) platforms
(e.g., CPU, GPU, ASIC), reconﬁgurable computing devices
like ﬁeld-programmable gate arrays (FPGA) have been widely
deployed in HPC system for DNN acceleration due to their
low-effort hardware-level re-programmability to adapt vari-
ous DNN structures, as well as fast algorithm evolution. For
example, IBM and Intel integrated FPGAs in their CPU prod-
ucts for acceleration purposes [12, 13]. Alongside the rapid
growth of the cloud computing market and critical develop-
ments in DNN hardware acceleration, FPGA has become a
signiﬁcant hardware resource for public lease. Recently, the
leading cloud service providers have also started integrating
FPGAs into their cloud servers. For example, the Stratix-V
FPGA from Intel/Altera has been deployed by the Microsoft
Project Catapult for DNN acceleration [14]. Amazon also
released its EC2 F1 instances equipped with programmable
hardware (UltraScale+VU9P FPGAs) from Xilinx [15].
For high efﬁciency and performance, there have been
growing efforts to support multiple independent tenants co-
residing/sharing an FPGA chip over time or simultaneously
[16, 17]. The co-tenancy of multiple users on the same FPGA
chip has created a unique attack surface, where many new
vulnerabilities will appear and cause dangerous effects. With
many hardware resources being jointly used in the multi-
tenant FPGA environment, a malicious tenant can leverage
such indirect interaction with other tenants to implement var-
ious new attacks. However, as a relatively new computing
infrastructure, as well as one of the main hardware acceler-
ator platforms, the security of multi-tenant FPGAs for DNN
acceleration has not been investigated in-depth.
From DNN algorithm point of view, its security has been
under severe scrutiny through generating malicious input
noise popularly known as Adversarial Examples [18–20].
Even though tremendous progress has been made in protect-
ing DNN against adversarial examples [21–23], neglecting
fault injection-based model parameter perturbation does not
guarantee the overall security of DNN acceleration in FPGA
(DNN-FPGA) system. Several prior works have effectively
demonstrated depletion of DNN intelligence by tempering
USENIX Association
30th USENIX Security Symposium    1919
model parameters (i.e, weights,biases) using supply chain
access [24, 25] or through popular memory fault injection
techniques [26–29], which could be in general classiﬁed as
adversarial weight attack. Adversarial weight attack can dras-
tically disrupt the inference behavior towards the intent of a
malicious party [26–30]. The large DNN model’s parameters
(e.g., weights) are extensively tuned in the training process
to play a key role in inference accuracy. However, almost all
the existing adversarial weight attacks assume an extremely
relaxed threat model (i.e., white-box), where the adversary
can access all DNN model parameters, like architecture and
gradients. Even though it is pivotal to study white-box at-
tacks to understand the behavior of DNN models in the pres-
ence of input or weight noise, it is also important to explore
how to conduct adversarial weight attacks in a much more
strict black-box setup, where the attacker does not know DNN
model information.
In summary, three primary challenges are i) Consider-
ing multiple tenants co-reside on an FPGA, can a malicious
user leverage a novel attack surface to provide the luxury of
perturbing DNN model parameters of the victim tenant? ii)
Can the adversary conduct a black-box adversarial weight at-
tack with no knowledge of DNN model parameters, gradient,
etc., instead of white-box attack used in prior works [26, 28]?
iii) Given an FPGA hardware fault injection attack scheme
and a strict black-box threat model, can an adversary design
an efﬁcient searching algorithm to identify critical parame-
ters for achieving a speciﬁc malicious objective? Inspired by
those challenges, we propose Deep-Dup attack framework in
multi-tenant DNN-FPGA, which consists of two main mod-
ules: I) a novel FPGA hardware fault injection scheme, called
adversarial weight duplication (AWD), leveraging two dif-
ferent power-plundering circuits to intentionally inject faults
into DNN weight packages during data transmission between
off-chip memory and on-chip buffer; II) a generic searching
algorithm, called Progressive Differential Evolution Search
(P-DES), to identify the most vulnerable DNN weight package
index and guide AWD to attack for given malicious objective.
As far as we know, Deep-Dup is the ﬁrst work demonstrat-
ing that the adversarial FPGA tenant could conduct both un-
targeted accuracy degradation attack and targeted attack to
hijack DNN function in the victim tenant, under both deep
learning white-box and black-box setup. The key contribu-
tions of this work are summarized as follows:
1): The proposed Adversarial weight duplication (AWD)
attack is an FPGA hardware-based fault injection method,
leveraging the co-tenancy of different FPGA users, to aggres-
sively overload the shared power distribution system (PDS)
and duplicate certain DNN model weight parameters dur-
ing data transmission between off-chip memory and on-chip
buffer. Two different power plundering circuits, i.e., Ring
Oscillator (RO) and RO with latch (LRO) are explored and
validated in the FPGA attack prototype system.
2): To maximize attack efﬁciency, i.e. conducting AWD-
based fault injection into the most vulnerable DNN weight
data packages for any given malicious objective, we propose
a generic vulnerable weight package searching algorithm,
called Progressive Differential Evolution Search (P-DES). It
is, for the ﬁrst time, adaptive to both deep learning white-box
and black-box setup. Unlike prior works only demonstrated
in a deep learning white-box setup [28], our success in both
white-box and black-box mainly comes from the fact that our
proposed P-DES does not require any gradient information
of DNN model.
3): We are the ﬁrst to develop an end-to-end Deep-Dup at-
tack framework, one type of adversarial DNN model fault in-
jection attack, utilizing our DNN vulnerable parameter search-
ing software (i.e. P-DES) to guide and search when/where to
inject fault through multi-tenant FPGA hardware fault injec-
tion (i.e. AWD) for efﬁcient and effective un-targeted/targeted
attacks (i.e., un-targeted attack to degrade overall accuracy
and targeted attack to degrade only targeted group accuracy).
4): A multi-tenant FPGA prototype is developed to vali-
date the proposed Deep-Dup for two different deep learning
applications (i.e., Object Detection and Image Classiﬁcation).
Successful un-targeted and targeted attacks are validated and
demonstrated in six different popular DNN architectures (e.g.
YOLOv2, ResNet-50, MobileNetV2, etc.) on three data sets
(e.g., COCO, CIFAR-10, and ImageNet), under both white-
box and black-box setups(i.e. attacker has no knowledge of
model parameters (e.g. weights/gradients/ architecture)).
5): As proof-of-concept, our Deep-Dup black-box attack
successfully targets the ’Ostrich’ class images (i.e., 100 %
attack success rate) on ImageNet with only 20 (out of 23
Million) weight package fault injection through AWD attacks
on ResNet-50 running in FPGA. Besides, Deep-Dup requires
just one AWD attack to completely deplete the intelligence
of compact MobileNetV2.
2 Background
2.1 Related Attacks on Multi-tenant FPGA
The re-programmability of FPGA makes it a popular hard-
ware accelerator for customized computing [31]. To further
explore the advantages of FPGA, leading hardware vendors
like Intel and Xilinx have integrated FPGAs with CPUs [13] or
ARM cores to build ﬂexible System-on-Chips (SoCs) [32, 33].
These heterogeneous computing platforms have recently been
integrated into cloud data centers [34], where the hardware
resources are leased to different users. The co-tenancy of
multiple users on the same FPGA chip, although improves
the resource utilization efﬁciency and performance, but also
creates a unique attack surface, where many new vulnera-
bilities will appear and cause dangerous results. With many
critical hardware components (e.g., power supply system) be-
ing jointly used in the multi-tenant FPGA environment, a
malicious tenant can leverage such indirect interaction with
other tenants to implement various new attacks.
1920    30th USENIX Security Symposium
USENIX Association
Generally, the attacks on multi-tenant FPGAs can be clas-
siﬁed into two classes: 1) side-channel attack, in which the
adversarial FPGA user can construct hardware primitive as
sensors(e.g., ring oscillator (RO)), to track and analyze the
secret of victim users. For example, in [34], the RO-based
sensor used as power side-channel has successfully extracted
the key of RSA crypto module, similarly, key extraction from
advanced encryption standard (AES) is successfully demon-
strated in [35] based on RO-caused voltage drop. More re-
cently, it has been demonstrated that a malicious user can
leverage the crosstalk between FPGA long-wires as a remote
side-channel to steal secret information [36, 37]. 2) Fault in-
jection attack, in which the adversary targets to inject faults to
or crash the applications of victim users. For example, the en-
tropy of true random number generator is corrupted by power
attacks in multi-tenant FPGAs [38]. In [39], the aggressive
power consumption by malicious users causes a voltage drop
on the FPGA, which can be leveraged to introduce faults.
With Machine Learning as a service (MLaaS) [40, 41] be-
coming popular, public lease FPGAs also become an emerg-
ing platform for acceleration purposes. However, the security
of using multi-tenant FPGA for DNN acceleration is still
under-explored in existing works, which is the main target of
this paper. Specially, the proposed Deep-Dup methodology
belongs to the fault injection category, which leverages mali-
cious power-plundering circuits to compromise the integrity
of the DNN model for un-targeted or targeted attacks.
2.2 Deep Learning Security
There has been a considerable amount of effort in developing
robust and secure DL algorithms [18, 19, 22, 25, 42–49]. Ex-
isting deep learning attack vectors under investigation mainly
fall into three categories: 1) Attacks that either mislead pre-
diction outcome using maliciously crafted queries (i.e., ad-
versarial inputs/examples [22, 50]) or through miss-training
the model with poisoned training set (i.e., data poisoning at-
tacks [51, 52]). 2) DL information leakage threats such as
membership inference attacks [49, 53] and model extraction
attacks [47, 54] where adversaries manage to either recover
data samples used in training or infer critical DL model pa-
rameters. 3) Finally, adversarial fault injection techniques
have been leveraged to intentionally trigger weight noise to
cause classiﬁcation errors in a wide range of DL evaluation
platform [26–29, 55].
The ﬁrst two attacks are generally considered as external
adversaries that exploit training and inference inputs to the
deep learning model. Despite the progress in protecting DNN
against this external adversaries [21–23], neglecting internal
adversarial fault injection still puts the overall security of
DNN acceleration in FPGA (DNN-FPGA) systems under
threat. The most recent adversarial weight attacks [27, 28, 30,
56] demonstrated, in both deep learning algorithm and real-
word general-purpose computer system, that it is possible to
modify an extremely small amount (i.e., tens out of millions)
Figure 1: Threat model for the proposed Deep-Dup.
of DNN model parameters using row-hammer based bit-ﬂip
attack in computer main memory to severely damage or hijack
DNN inference function. Even those injected faults might
be minor if leveraged by a malicious adversary, such internal
adversarial fault injection harnessing hardware vulnerabilities
may be extremely dangerous as they can severely jeopardize
the conﬁdentiality and integrity of the DNN system.
3 Threat Model and Attack Vector
Multi-tenant FPGA Hardware Threat Model. In this
work, we consider the representative hardware abstraction
of multi-tenant FPGA used in the security works [36, 57, 58],
and operating system works [17, 59]. The threat model is
shown in Fig. 1, which has the following characteristics: (1)
Multiple tenants co-reside on a cloud-FPGA and their circuits
can be executed simultaneously. The system administrator
of cloud service is trusted. (2) Each tenant has the ﬂexibil-
ity to program his design in the desired FPGA regions (if
not taken by others). (3) All tenants share certain hardware