,
(2)
j=1
k=1
where (cid:96)(x, t) is a loss function. A simple loss function is the 0-1 loss function (cid:96)(x, t) = 1{sign(x) (cid:54)= t},
which assigns a uniform loss of 1 whenever the sign of the predicted value x does not match the target
value t. However, from an optimization perspective, the 0-1 loss is not a good loss function since it is
non-convex and neither continuous nor diﬀerentiable. Practitioners have instead used continuous convex
approximations to the 0-1 loss, such as the SVM hinge loss (cid:96)hinge(x, t) = max(0, 1 − tx) [RVC+04] and its
quadratically smoothed variant, the modiﬁed Huber hinge loss [Zha04]:
tx ≥ −1
otherwise.
max(0, 1 − tx)2
−4 · tx
(cid:96)huber(x, t) =
(cid:40)
(3)
In our setting, we use the modiﬁed Huber hinge loss (cid:96)huber. While (cid:96)huber is convex in the input x, it is not
convex in the optimization parameters A, B (due to the matrix product), and so the objective function
J(A, B) is not convex in A, B. Thus, standard optimization algorithms like LBFGS [BLNZ95] are not
guaranteed to ﬁnd the global optimum. The hope is that even a local optimum will correspond to a
low-rank, sign-preserving decomposition of the matrix M , and indeed, we conﬁrm this empirically.
When we perform the optimization using LBFGS, the matrices A, B are real-valued. To obtain matrices
over the integers, we scale the entries in A, B by a constant factor and round. The scaling factor is
empirically chosen so as to preserve the relation sign(ABT ) = M . We describe this in greater detail in
Section 5.3.
4 Private Navigation Protocol
In this section, we describe our protocol for privately computing shortest paths. First, we describe the
cryptographic building blocks we employ in our construction.
3This is not the same as computing a low-rank approximation of M . Our goal is to ﬁnd low-rank matrices whose product
preserves the signs of the entries of M . In practice, the matrix M is full-rank, and not well-approximated by a low-rank
product.
6
Private information retrieval. A computational private information retrieval (PIR) [CMS99, CGKS95,
KO97, Cha04, GR05, Lip05, OI07] protocol is a two-party protocol between a sender who holds a database
D = {r1, . . . , rn} and a receiver who holds an index i ∈ [n]. At the conclusion of the PIR protocol, the
receiver learns ri while the sender learns nothing. A PIR protocol only ensures privacy for the receiver’s
index (and not for the remaining records in the sender’s database).
Oblivious transfer. Similar to PIR, an 1-out-of-n oblivious transfer (OT) protocol [NP99, NP01, NP05,
Rab05] is a two-party protocol that allows the receiver to privately retrieve a record ri from the sender who
holds a database {r1, . . . , rn}. In contrast with PIR, an OT protocol also provides privacy for the sender:
the receiver only learns its requested record ri, and nothing else about the other records. Closely related
is the notion of symmetric PIR (SPIR) [KO97, GIKM00, NP05], which is functionally equivalent to OT.
circuit C : {0, 1}n → {0, 1}m and produces a garbled circuit ˜C along with n pairs of encodings(cid:8)k0
(cid:9)
Garbled circuits. Yao’s garbled circuits [Yao86, LP09, BHR12] were initially developed for secure two-
party computation. The core of Yao’s construction is an eﬃcient transformation that takes a Boolean
i∈[n].
i }i∈[n]
i , k1
i
Then, for any input x ∈ {0, 1}n, the combination of the garbled circuit ˜C and the encodings Sx = {kxi
(where xi denotes the ith bit of x) enable one to compute C(x), and yet reveal nothing else about x.
4.1 Protocol Design Overview
We ﬁrst give an intuitive overview of our fully-private navigation protocol. As described in Section 3, we
ﬁrst preprocess the network G to have maximum out-degree d = 4 and then associate a cardinal direction
with each of the edges in G. As in Section 3, let (M (ne), M (nw)) be the precomputed next-hop routing
matrices for G, and let (A(ne), B(ne)), (A(nw), B(nw)) be the compressed representation of M (ne), M (nw),
respectively.
Our private shortest paths protocol is an iterative protocol that reveals the shortest path from a source
s to a destination t one hop at a time. When the client engages in the protocol with input (s, t), it learns
which neighbor v of s is the next node on the shortest path from s to t. Then, on the next round of the
protocol, the client issues a query (v, t) to learn the next node in the path, and so on, until it arrives at the
destination node t. With this iterative approach, each round of our protocol can be viewed as a two-party
computation of the entry (M (ne)
) from the next-hop routing matrices. We give the full description
of our private navigation protocol in Figure 3, and sketch out the important principles here. To simplify
the presentation, we ﬁrst present the core building blocks that suﬃce for semi-honest security. We then
describe additional consistency checks that we introduce to obtain security against a malicious client and
privacy against a malicious server.
, M (nw)
st
st
4.1.1 Semi-honest Secure Construction
Abstractly, we can view each round of our protocol as computing the following two-party functionality
twice (once for M (ne) and once for M (nw)). The server has two matrices A, B ∈ Zn×d, which we will refer
to as the source and destination matrices, respectively, and the client has two indices s, t ∈ [n]. At the
end of the protocol, the client should learn sign((cid:104)As, Bt(cid:105)), where As and Bt are the sth and tth rows of A
and B, respectively. The client should learn nothing else about A and B, while the server should not learn
anything. Our protocol can thus be decomposed into two components:
1. Evaluation of the inner product (cid:104)As, Bt(cid:105) between the source vector As and the destination vector Bt.
2. Determining the sign of (cid:104)As, Bt(cid:105).
7
In the following, we will work over a ﬁnite ﬁeld Fp large enough to contain the entries in A, B. In particular,
we view A, B as n × d matrices over Fp.
Evaluating the inner product. The ﬁrst step in our protocol is evaluating the inner product between
the source vector As and the destination vector Bt. Directly revealing the value of (cid:104)As, Bt(cid:105) to the client,
however, leaks information about the entries in the compressed routing matrices A, B. To protect against
this leakage, we instead reveal a blinded version of the inner product. Speciﬁcally, on each round of the
r←− Fp. We then construct the protocol such
protocol, the server chooses blinding factors α
that at the end of the ﬁrst step, the client learns the blinded value α(cid:104)As, Bt(cid:105) + β instead of (cid:104)As, Bt(cid:105).
r←− F∗
p and β
One candidate approach for computing the blinded inner product is to use a garbled circuit. However,
while Yao’s garbled circuits suﬃce for private evaluation of any two-party functionality, when the underlying
operations are more naturally expressed as addition and multiplication over Fp, it is more convenient to
express the functionality in terms of an arithmetic circuit. In an arithmetic circuit (over Fp), the “gates”
correspond to ﬁeld operations (addition and multiplication), and the values on the wires correspond to
ﬁeld elements.
metic circuits. In particular, evaluating a function of the form f (x, y) = (cid:104)x, y(cid:105) +(cid:80)
In recent work, Applebaum et al. [AIK14] construct the analog of Yao’s garbling procedure for arith-
i∈[d] zi, where x, y ∈ Fd
and each zi ∈ Fp is a constant can be done eﬃciently using the aﬃnization gadgets from [AIK14, §5].
Speciﬁcally, for each xi, yi, we deﬁne the following aﬃne encoding functions Laﬃne
(xi), Laﬃne
(yi):
p
xi
yi
Laﬃne
(cid:16)
(cid:16)
(cid:17)
i − r(3)
are chosen uniformly from Fp. We will also write Laﬃne
i + zi + r(3)
i − r(1)
i r(2)
xi − r(1)
yi − r(2)
, xir(2)
, yir(1)
(xi) =
Laﬃne
(yi) =
(cid:17)
xi
yi
i
i
i
i
,
(4)
Laﬃne
y
y1
Laﬃne
(y1), . . . , Laﬃne
(y) =
(y; r) to denote the aﬃne encoding of vectors x, y ∈ Fd
(yd)
yd
.
p using ran-
(y) provides statistical privacy for the input vectors
(6)
(x; r), Laﬃne
y
p . The aﬃne encodings Laﬃne
x
(x), Laﬃne
y
Similarly, we write Laﬃne
domness r ∈ F3d
x, y [AIK14, Lemma 5.1].
x
ﬁrst step of the protocol. At the beginning of each round, the server chooses blinding factors α
r←− Fp. Then, it constructs the aﬃne encoding functions Laﬃne
Next, we describe how these aﬃne encodings can be used to compute the blinded inner product in the
r←− F∗
p
and β
for the function fα,β(x, y) =
(cid:104)αx, y(cid:105) + β according to Eq. (4). Next, the server prepares two encoding databases Dsrc and Ddst where the
sth record in Dsrc consists of the aﬃne encodings Laﬃne
(As) of each source vector, and the tth record in Ddst
consists of Laﬃne
(Bt) of each destination vector. To evaluate the blinded inner product, the client performs
two SPIR queries: one for the sth record in Dsrc to obtain the encodings of As and one for the tth record
, Laﬃne
x
x
y
y
8
i
, r(3)
, r(2)
where r(1)
aﬃne encodings of xi and yi using randomness ri ∈ F3
evaluating f (x, y) corresponds to evaluating the expression
i
i
p. Given Laﬃne
xi
(xi; ri), Laﬃne
xi
yi
(xi) and Laﬃne
(yi; ri) to denote
(yi) for all i ∈ [n],
(cid:88)
(cid:104)
i∈[n]
·(cid:104)
(cid:105)
1
(cid:105)
(cid:104)
(cid:105)
Laﬃne
xi
(xi)
Laﬃne
yi
(yi)
+
1
Laﬃne
xi
(xi)
+
2
Laﬃne
yi
(yi)
,
(5)
where we write [·]i to denote the ith component of a tuple. For notational convenience, we also deﬁne
Laﬃne
(x) and Laﬃne
(y) as
x
y
(cid:16)
(cid:16)
Laﬃne
x
(x) =
Laﬃne
x1
(x1), . . . , Laﬃne
xd
(xd)
yi
(cid:105)
2
(cid:104)
(cid:17)
(cid:17)
in Ddst to obtain the encodings of Bt.4 The client then evaluates the arithmetic circuit using Eq. (5) to
obtain z = fα,β(As, Bt). To a malicious client, without knowledge of α or β, the value fα,β(As, Bt) appears
uniform over Fp and independent of As, Bt.
Determining the sign. To complete the description, it remains to describe a way for the client to learn
the sign of the inner product (cid:104)As, Bt(cid:105). The client has the value z = α(cid:104)As, Bt(cid:105) + β from the output of the
arithmetic circuit while the server knows the blinding factors α, β. Since computing the sign function is
equivalent to performing a comparison, arithmetic circuits are unsuitable for the task. Instead, we construct
a separate Yao circuit to unblind the inner product and compare it against zero. More speciﬁcally, let
g(x, γ, δ) = 1{[γx+δ]p > 0}, where [·]p denotes reduction modulo p, with output in the interval (−p/2, p/2).
Then,
g(z, α−1,−α−1β) = sign(As, Bt).
To conclude the protocol, the server garbles a Boolean circuit Cunblind for the unblinding function g to
obtain a garbled circuit ˜Cunblind along with a set of encodings Lunblind. It sends the garbled circuit to the
client, along with encodings of the unblinding coeﬃcients γ = α−1, δ = α−1β to the client. The client
engages in 1-out-of-2 OTs to obtain the input encodings of z, and evaluates the garbled circuit ˜Cunblind to
learn sign((cid:104)As, Bt(cid:105)).
4.1.2 Enforcing Consistency for Stronger Security
As described, the protocol reveals just a single edge in the shortest path. Repeated iteration of the protocol
allows the client to learn the full shortest path. Moreover, since the server’s view of the protocol execution
consists only of its view in the PIR and OT protocols, privacy of these underlying primitives ensures privacy
of the client’s location, even against a malicious server.5
Security for the server only holds if the client follows the protocol and makes consistent queries on each
round. However, a malicious client can request the shortest path for a diﬀerent source and/or destination
on each round, thereby allowing it to learn edges along arbitrary shortest paths of its choosing. To protect
against a malicious client, we bind the client to making consistent queries across consecutive rounds of the