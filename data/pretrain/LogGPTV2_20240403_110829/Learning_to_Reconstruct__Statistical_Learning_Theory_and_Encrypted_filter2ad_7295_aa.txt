title:Learning to Reconstruct: Statistical Learning Theory and Encrypted
Database Attacks
author:Paul Grubbs and
Marie-Sarah Lacharit&apos;e and
Brice Minaud and
Kenneth G. Paterson
2019 IEEE Symposium on Security and Privacy
Learning to Reconstruct: Statistical Learning
Theory and Encrypted Database Attacks
Paul Grubbs∗, Marie-Sarah Lacharit´e†, Brice Minaud‡§, Kenneth G. Paterson†
†Royal Holloway, University of London, {marie-sarah.lacharite.2015, kenny.paterson}@rhul.ac.uk
∗Cornell University, PI:EMAIL
‡ ´Ecole Normale Sup´erieure, CNRS, PSL University
§Inria, PI:EMAIL
Abstract—We show that the problem of reconstructing en-
crypted databases from access pattern leakage is closely related
to statistical
learning theory. This new viewpoint enables us
to develop broader attacks that are supported by streamlined
performance analyses. As an introduction to this viewpoint,
we ﬁrst present a general reduction from reconstruction with
known queries to PAC learning. Then, we directly address the
problem of -approximate database reconstruction (-ADR) from
range query leakage, giving attacks whose query cost scales only
with the relative error , and is independent of the size of the
database, or the number N of possible values of data items.
This already goes signiﬁcantly beyond the state-of-the-art for
such attacks, as represented by Kellaris et al. (ACM CCS 2016)
and Lacharit´e et al. (IEEE S&P 2018). We also study the new
problem of -approximate order reconstruction (-AOR), where
the adversary is tasked with reconstructing the order of records,
except for records whose values are approximately equal. We
show that as few as O(−1 log −1) uniformly random range
queries sufﬁce. Our analysis relies on an application of learning
theory to PQ-trees, special data structures tuned to compactly
record certain ordering constraints. We then show that when
an auxiliary distribution is available, -AOR can be enhanced to
achieve -ADR; using real data, we show that devastatingly small
numbers of queries are needed to attain very accurate database
reconstruction. Finally, we generalize from ranges to consider
what learning theory tells us about the impact of access pattern
leakage for other classes of queries, focusing on preﬁx and sufﬁx
queries. We illustrate this with both concrete attacks for preﬁx
queries and with a general lower bound for all query classes.
I. INTRODUCTION
This article concerns the analysis of leakage from encrypted
databases. The latter are cryptographic techniques that al-
low a client to outsource a database to an untrusted server
while maintaining the ability to make queries on the data.
Fuller et al. [1] give a comprehensive survey of this area.
All known techniques represent a trade-off between security
and efﬁciency, with various forms of leakage being intrinsic
to these approaches. For example, without
taking special
precautions such as using oblivious memory techniques, the
access pattern, that is, the set of records returned in response
to queries, leaks to the server. While in many cases, formal
security proofs are able to establish that nothing more than the
access pattern leaks to the adversarial server, there still remains
the question: what is the practical impact of this leakage? A
more reﬁned version of the question is:
If an encrypted database supports a certain class
of queries, but leaks the access pattern, then
how damaging is that leakage as a function of
the query and data distribution and number of
queries?
The setting of this article is one in which only access pattern
is leaked to an adversarial server. Access pattern leakage
is inherent to nearly all practical constructions of encrypted
databases, and the survey by Fuller et al. [1] overviews a
plethora of schemes to which such attacks apply. In the
particular case of range queries, all known practical solutions
leak this information [2]. Nevertheless, the previous question
is currently answered using ad hoc cryptanalysis, requiring
cumbersome and laborious analyses to establish the impact of
leakage as a function of the number of queries. The central
aim of our work is to transform this situation by bringing
statistical learning theory to bear on the problem.
A. Database Reconstruction: State of the Art
Range queries are fundamental to the operation of databases,
and have rightfully received signiﬁcant attention in the at-
tack literature. The state-of-the-art
for attacks based on
leakage from range queries is represented by the work of
Kellaris-Kollios-Nissim-O’Neill (KKNO) [3] and Lacharit´e-
Minaud-Paterson (LMP) [2]. KKNO gave attacks showing
that O(N 4 log N ) queries sufﬁce to achieve Full Database
Reconstruction (FDR), that is, to reconstruct the exact value
for every record. Here, N is the number of different possible
values, which we assume without loss of generality come from
the interval [1, N ]. For dense data, where every possible value
is in at least one record, this was improved to O(N 2 log N )
queries by KKNO and then to O(N log N ) queries by LMP.
All of these results assume the query distribution is uniform
on ranges (though for the results in the dense setting, this
assumption is needed only to facilitate analysis and not for
the algorithms to succeed).
A typical value of N might be, say, 125 for data pertaining
to age in years, making even an O(N 4 log N ) attack poten-
tially worrisome. But for many data types, N can be much
larger – think of discrete data such as numerical zip codes,
timestamps, or salary data. For large N, especially when the
data is sparse rather than dense (as is typically the case), FDR
© 2019, Paul Grubbs. Under license to IEEE.
DOI 10.1109/SP.2019.00030
1067
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:47:08 UTC from IEEE Xplore.  Restrictions apply. 
is much too expensive (KKNO proved a general lower bound
of Ω(N 4) on the number of range queries needed), and really
too strong an attack goal.
For this reason, LMP introduced the notion of Approximate
Database Reconstruction (ADR), where the adversary’s goal
is to ﬁnd the value of every record up to an (additive) error
of N rather than exactly. For small , such an attack is still
extremely effective: imagine learning all salaries in a database
up to an error of 1%. LMP gave the ﬁrst algorithm for ADR,
which achieves -ADR from access pattern leakage on only
O(N · log −1) queries. However, it still requires a density
assumption and its analysis is highly complex.
B. Overview of Our Contributions
None of the aforementioned attacks exploiting range query
leakage is fully satisfactory: FDR is too expensive for large N,
while the only ADR algorithm we have (from LMP’s work [2])
relies on a density assumption and its query cost still scales
with N. This presents a potentially misleading picture of the
impact of leakage for range queries, one which may lead to
underestimating the potential damage. Additionally, leakage
from other kinds of queries has received little attention, nor
have other attack settings of practical importance like known-
query attacks.
In this work, we show how statistical
learning theory
effectively addresses the problem of database reconstruction,
yielding new results across a range of settings. A common
thread through all of our results is the analysis of concept
spaces over the set of all queries. The results we apply from
learning theory rely on the VC dimension of the concept space,
intuitively a measure of how complex it is. (See Appendix A
for a short primer on statistical learning theory.)
PAC learning and known-query attacks.
In Section II,
we show that database reconstruction given a set of known
queries can be recast as an instance of Probably Approxi-
mately Correct (PAC) learning, and standard results from that
ﬁeld can predict how many queries are needed to achieve
reconstruction. We present this reduction to PAC learning as
an introduction to how we view database reconstruction as a
learning problem, as well as an illustration of the power of this
viewpoint. While the attack model here is rather powerful, it
is considered realistic in some recent literature [6], [5], [7];
our analysis largely resolves the question of how damaging
such attacks can be. In the remainder, we no longer assume
queries are known, aligning our setting with most prior work.
Sacriﬁcial -ADR.
In Section III, we present two new -
ADR algorithms for range queries. These attacks are scale-
free: their query complexity depends not on the number of
possible values N, but only the precision . They accommo-
date any number of queries, as opposed to the “all-or-nothing”
attacks of KKNO and LMP. To obtain scale-freeness, we must
sacriﬁce recovering some records near the endpoints. As we
explain in Section III-A, scale-free -ADR is impossible in
general – O(N ) queries are necessary to recover values near
the endpoints 1 and N, so we must sacriﬁce these.
The ﬁrst algorithm (Section III-B), whose analysis is some-
what simpler, achieves sacriﬁcial -ADR using O(−4 log −1)
uniformly random range queries. Setting  = 1/N yields an
FDR attack with the same complexity as KKNO’s original
FDR attack. Indeed, our algorithm can be seen as generalizing
the ideas of KKNO to the ADR setting, and making it
scale-free. In Section III-C, we introduce our second attack,
the ApproxValue algorithm, which achieves sacriﬁcial -
ADR using only O(−2 log −1) uniformly random queries,
but under the additional, mild requirement that the database
contains a record whose value is in the range [0.2N, 0.3N ]
(or its reﬂection). Setting  = 1/N in our algorithm again
yields a FDR algorithm with complexity O(N 2 log N ) that
works whether data is sparse or dense, assuming only a single
favorably-located record. Our proof techniques for both attacks
are rooted in learning theory, using VC dimension and the
concept of -samples. Both attacks also come with general
lower bounds showing that they are optimal in the number of
queries within a log factor.
In order to assess the effectiveness of these algorithms and
the tightness of our bounds, we implement our attacks and
experiment on synthetic data (Section III-D). For example, if
N = 106 and the condition of the ApproxValue algorithm
is met, KKNO’s FDR attack would require about 1026 queries.
We found experimentally that only 500 queries (or 24 orders
of magnitude fewer than KKNO) are needed to approximate
almost all records to within 5% error.
Lifting requirements on the query distribution.
In view of
the previous attacks, it may seem that the topic of analyzing
leakage from range queries is mostly closed, but these attacks
still require that the adversary knows the query distribution,
and that queries are independently and identically distributed
(i.i.d.). This second requirement especially makes little sense
for real-world queries, and we contend that practical attacks
should not require it. In this regard, we view KKNO’s work
and our aforementioned results as important indicators of what
is possible in principle, and valuable warnings regarding the
power of range query leakage, but not as practical, ready-for-
use attacks.
The question, then, is what an attacker can hope to learn in
practice, given only the access pattern leakage of some range
queries, without the (unrealistic) assumption of a known i.i.d.
query distribution. We investigate this question in Section IV.
The LMP results were a step in this direction: their algorithms
are not distribution-dependent. However, they do require that
the database is dense, whereas we would like to investigate this
question in the general setting. First, we observe that what the
adversary can learn in that setting is the order of the records’
values, rather than their values directly.
Sacriﬁcial -AOR.
In Section IV, we introduce the attack
target of sacriﬁcial -Approximate Order Reconstruction (sac-
riﬁcial -AOR). This asks that the order of all records should
be recovered, except for records that are within N of each
other (which the algorithm groups), and the sacriﬁced records
whose values are within N of 1 or N. Thus, save for
1068
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:47:08 UTC from IEEE Xplore.  Restrictions apply. 
sacriﬁced values, sacriﬁcial -AOR reveals the order of any
two records as soon as they are at least N apart.
As our main result in Section IV, we introduce the scale-free
ApproxOrder algorithm, which takes as input the access
pattern leakage of some range queries, builds a PQ-tree, and
extracts from it approximate order information. The algorithm
does not use any knowledge of a query distribution. If, for the
sake of analyzing the algorithm, we assume a uniform query
distribution, ApproxOrder achieves sacriﬁcial -AOR after
only O(−1 log −1) queries. Once again, our analysis relies
on learning theory, more speciﬁcally the concept of an -net.
We also prove that the query complexity of our algorithm is
optimal within a constant factor.
For  = 1/N, -AOR yields exact order reconstruction for
all records. If the database is dense, then recovering order
directly implies recovering values, so we obtain full database
reconstruction in O(N log N ) queries, recovering as a special
case the main result of LMP.
The ApproxOrder algorithm is not merely theoretical,
but highly practical. There is no barrier (such as the i.i.d. query
assumption) to running it on real data. Our experiments in
Section IV-C show that the attack behaves as predicted by the
theory. As an example, for N = 106, after only 500 queries,
the attack is able to fully order records, except for records
whose difference in value is less than 2% of the support size.
-AOR to -ADR. A crucial question remains: what are the
implications of the AOR attack? That is, what does learning
approximate order reveal to the attacker? It is well known
that leaking record order is highly damaging, if only because
it can be closely correlated to record values using an auxiliary
distribution [4], [5]. In fact, the severe implications of order
leakage is one of the main motivations behind the develop-
ment of second-generation encrypted databases schemes that
attempt to hide that leakage, as argued in [2]. To concretize
that point, in Section IV-D we present an attack showing
how approximate database values can be reconstructed from
approximate order information: we extend our sacriﬁcial -
AOR attack to a sacriﬁcial -ADR attack using an auxiliary
model of the database distribution. (As per [4], [2], such
distributions are often available.)
Throughout
the set of
[n] denotes
values of records, which allows an attacker to group records
whose values are close. Further, we show how to use an -net
to precisely analyze how many queries are needed to guarantee
all groups of records have small diameter according to γ. We
construct, analyze, and evaluate the ﬁrst reconstruction attack
on preﬁx queries. We conclude the section with a general
lower bound, via a reduction to PAC learning, relating the
query class’s VC dimension, attack accuracy, and number
of queries needed for any reconstruction attack using access
pattern leakage. In addition to being of theoretical interest,
this suggests VC dimension or similar concepts from learning
theory could be a useful way to compare different techniques
which leak access pattern.
Notation.
integers
{1, . . . , n}; [a, b] denotes the set of integers within the given
interval; and open brackets such as [a, b[ denote that
the
corresponding endpoint is excluded. (If b ≤ a, [a, b[ is empty.)
We model a database as a set of R records where each record
has a single attribute that takes an integer value in [N ]. We
let val(r) ∈ [N ] denote the value of the record r.
Assumptions. We assume the adversary knows the number
of possible values N, and the set of all possible queries. We
do not assume that the adversary knows the set of all records
in advance, or even their number. We do not assume that every