âˆ‘ï¸
ğ‘™ âˆ’ 1(cid:105)
âˆ‘ï¸
ğ‘—=1
ğ‘â€²
ğ‘— ğ‘â€²
ğ‘—=1
ğ‘â€²
ğ‘— ğ‘â€²
ğ‘™â‰ ğ‘—
ğ‘™â‰ ğ‘—
ğ‘™â‰ ğ‘—
(ğ‘â€²
ğ‘™â‰ ğ‘—
ğ‘™(cid:170)(cid:174)(cid:172)
ğ‘â€²
ğ‘— ğ‘â€²
ğ‘š
ğ‘—=1
ğ‘—=1
ğ‘—=1
= ğ‘š2(cid:104) 1
+ ğµâˆ‘ï¸
(cid:169)(cid:173)(cid:171) ğµâˆ‘ï¸
+ ğµâˆ‘ï¸
= ğ‘š2(cid:104) 1
(cid:169)(cid:173)(cid:171) ğµâˆ‘ï¸
+ ğµâˆ‘ï¸
= ğ‘š(cid:169)(cid:173)(cid:171) ğµâˆ‘ï¸
becauseğµ
ğ‘—=1
(ğ‘â€²
ğ‘—)2
ğ‘ ğ‘—
ğ‘—=1
ğ‘—=1
(c)
ğ‘š
(cid:32)
âˆ‘ï¸
ğ‘™
âˆ’ ğ‘â€²
ğ‘— ğ‘â€²
ğ‘š
ğ‘™â‰ ğ‘—
(ğ‘â€²
ğ‘—)2(1 âˆ’ ğ‘ ğ‘—)
(ğ‘â€²
(ğ‘â€²
ğ‘—)2
ğ‘ ğ‘—
(ğ‘â€²
ğ‘ ğ‘—
ğ‘—=1
ğ‘—=1
ğ‘—)2 + ğµâˆ‘ï¸
âˆ’ ğµâˆ‘ï¸
ğ‘—)2 + ğµâˆ‘ï¸
âˆ’ 1(cid:170)(cid:174)(cid:172) .
ğ‘—)2 +ğµ
ğ‘—=1
E(cid:2)ğ‘’ğ‘ ğ‘‹(cid:3)
ğ‘’ğ‘ ğ‘¡
ğ‘ 2ğ‘šğœˆ2
2
ğ‘’ğ‘ ğ‘¡
ğ‘’
Pr [ğ‘‹ â‰¥ ğ‘¡] â‰¤ min
ğ‘ â‰¥0
â‰¤ min
ğ‘ â‰¥0
ğ‘—
(cid:17)2
ğ‘— ğ‘â€²
ğ‘™ =
ğ‘—=1 ğ‘â€²
ğ‘—=1(ğ‘â€²
1, . . . , ğ‘â€²
Here, step (b) uses properties of multinomial distribution:
Eğ’‰âˆ¼ğœ‡0[â„ ğ‘—] = ğ‘šğ‘ ğ‘—, Eğ’‰âˆ¼ğœ‡0[â„2
ğ‘— , and
Eğ’‰âˆ¼ğœ‡0[â„ ğ‘—â„ğ‘™] = âˆ’ğ‘šğ‘ ğ‘— ğ‘ğ‘™ + ğ‘š2ğ‘ ğ‘— ğ‘ğ‘™ for ğ‘— â‰  ğ‘™. Step (c) follows
= 1, as
ğ‘—] = ğ‘šğ‘ ğ‘— (1 âˆ’ ğ‘ ğ‘—) + ğ‘š2ğ‘2
ğ‘—=1ğ‘™â‰ ğ‘— ğ‘â€²
(cid:16)ğµ
ğ‘—=1 ğ‘ ğ‘— 1{ğ‘Œğ‘– =ğ‘— }
ğµ) is a probability distribution.
ğ’‘â€² = (ğ‘â€²
(3) Let ğ‘Œğ‘– denote the random variable associated with the output
of the local randomizer at the ğ‘–â€™th client. So, Pr [ğ‘Œğ‘– = ğ‘—] = ğ‘ ğ‘—
for ğ‘— âˆˆ [ğµ]. Recall that â„ ğ‘— denote the number of clients
that map to the ğ‘—â€™th element from [ğµ]. This implies that
ğ‘–=1 1{ğ‘Œğ‘– =ğ‘— }. For any ğ‘– âˆˆ
for any ğ‘— âˆˆ [ğµ], we have â„ ğ‘— =ğ‘š
(cid:17) âˆ’ 1,
(cid:17) âˆ’ 1 = 0. With these definitions, we
(cid:17) âˆ’ ğ‘š as
[ğ‘š], define a random variable ğ‘‹ğ‘– =
where ğ‘ ğ‘— =
. Observe that ğ‘‹1, . . . , ğ‘‹ğ‘š are zero mean
i.i.d. random variables, because for any ğ‘– âˆˆ [ğ‘š], we have
E [ğ‘‹ğ‘–] =
can equivalently represent ğ‘‹(ğ’‰) =
ğ‘–=1 ğ‘‹ğ‘–, which is the sum of ğ‘š zero mean i.i.d.
r.v.s. Furthermore, since ğ‘ ğ‘— âˆˆ [ğ‘’âˆ’ğœ–0, ğ‘’ğœ–0] for any ğ‘— âˆˆ [ğµ],
we have ğ‘‹ğ‘– âˆˆ [ğ‘’âˆ’ğœ–0 âˆ’ 1, ğ‘’ğœ–0 âˆ’ 1]. Since any bounded r.v.
ğ‘ âˆˆ [ğ‘, ğ‘] is a sub-Gaussian r.v. with parameter (ğ‘âˆ’ğ‘)2
4
(see [38, Lemma 1.8])), we have that ğ‘‹ğ‘– is a sub-Gaussian r.v.
with parameter ğœˆ2 = (ğ‘’ğœ–0âˆ’ğ‘’âˆ’ğœ–0)2
(cid:16)ğµ
ğ‘‹(ğ’‰) = ğ‘š
(cid:16)ğµ
(cid:16)ğµ
ğ‘—=1 ğ‘ ğ‘— ğ‘ ğ‘—
ğ‘—=1 ğ‘ ğ‘—â„ ğ‘—
, i.e.,
ğ‘â€²
ğ‘—
ğ‘ ğ‘—
(cid:104)ğ‘’ğ‘ ğ‘‹ğ‘–(cid:105) â‰¤ ğ‘’
It follows that ğ‘‹ (h) =ğ‘š
4
ğ‘ 2 ğœˆ2
2
E
,
âˆ€ğ‘  âˆˆ R.
ğ‘–=1 ğ‘‹ğ‘– is also a sub-Gaussian ran-
dom variable with parameter ğ‘šğœˆ2. The remaining steps are
similar to bound the moments of a sub-Gaussian random
variable. We write them here for completeness. From Cher-
noff bound we get
(b)â‰¤ ğ‘’âˆ’ ğ‘¡2
where (b) follows by setting ğ‘  =
bound the term Pr [âˆ’ğ‘‹ â‰¥ ğ‘¡]. Thus, we get
2ğ‘šğœˆ2
ğ‘¡
ğ‘šğœˆ2 . Similarly, we can
Pr [|ğ‘‹| â‰¥ ğ‘¡] â‰¤ 2ğ‘’âˆ’ ğ‘¡2
2ğ‘šğœˆ2
0
0
= ğ‘–
2ğ‘šğœˆ2 ğ‘‘ğ‘¡
â‰¤ 2ğ‘–
(b)
ğ‘¡ğ‘–âˆ’1 Pr [|ğ‘‹| â‰¥ ğ‘¡] ğ‘‘ğ‘¡
ğ‘¡ğ‘–âˆ’1ğ‘’âˆ’ ğ‘¡2
Hence, the ğ‘–â€™th moment of the random variable ğ‘‹ can be
bounded by
E(cid:2)ğ‘‹ ğ‘–(cid:3) â‰¤ E(cid:2)|ğ‘‹|ğ‘–(cid:3)
âˆ« âˆ
âˆ« âˆ
= ğ‘–(cid:16)2ğ‘šğœˆ2(cid:17)ğ‘–/2âˆ« âˆ
= ğ‘–(cid:16)2ğ‘šğœˆ2(cid:17)ğ‘–/2
ables). In the last step, Î“ (ğ‘§) =âˆ« âˆ
have E(cid:2)|ğ‘‹|ğ‘–(cid:3) â‰¤ ğ‘–Î“ (ğ‘–/2)(cid:0)2ğ‘šğœˆ2(cid:1)ğ‘–/2, where ğœˆ2 = (ğ‘’ğœ–0âˆ’ğ‘’âˆ’ğœ–0)2
2ğ‘šğœˆ2 (change of vari-
0 ğ‘¥ğ‘§âˆ’1ğ‘’âˆ’ğ‘¥ğ‘‘ğ‘¥ denotes the
Gamma function. Thus, we conclude that for every ğ‘– â‰¥ 3, we
.
â– 
where step (b) follows by setting ğ‘¢ = ğ‘¡2
0
Î“ (ğ‘–/2) ,
ğ‘¢ğ‘–/2âˆ’1ğ‘’âˆ’ğ‘¢ğ‘‘ğ‘¢
4
This completes the proof of Lemma 6.1.
C.2 Proof of Lemma 6.2
Lemma (Restating Lemma 6.2). We have the following bound:
(cid:169)(cid:173)(cid:171) ğµâˆ‘ï¸
ğ‘—=1
ğ‘â€²2
ğ‘—
ğ‘ ğ‘—
âˆ’ 1(cid:170)(cid:174)(cid:172) =
sup
(ğ’‘,ğ’‘â€²)âˆˆTğœ–0
(ğ‘’ğœ–0 âˆ’ 1)2
.
ğ‘’ğœ–0
ğ‘—=1
Proof. For any (ğ’‘, ğ’‘â€²) âˆˆ Tğœ–0, define ğ‘“ (ğ’‘, ğ’‘â€²) = ğµ
(ğ‘â€²
ğ‘—)2
.
ğ‘ ğ‘—
Since the function ğ‘” (ğ‘¥, ğ‘¦) = ğ‘¥2
ğ‘¦ is convex in (ğ‘¥, ğ‘¦) for ğ‘¦ > 0, it
implies that the objective function ğ‘“ (ğ’‘, ğ’‘â€²) is also convex in (ğ’‘, ğ’‘â€²).
It is easy to verify that Tğœ–0 is a polytope.
Since we maximize a convex function ğ‘“ (ğ’‘, ğ’‘â€²) over a polytope
Tğœ–0, the optimal solution is one of the vertices of the polytope. Note
that any vertex (ğ’‘, ğ’‘â€²) of the polytope in ğµ dimensions satisfies
all the ğµ LDP constraints (i.e., ğ‘’âˆ’ğœ–0 â‰¤ ğ‘ ğ‘—
â‰¤ ğ‘’ğœ–0, ğ‘— = 1, . . . , ğµ) with
ğ‘â€²
equality. Without loss of generality, assume that the optimal so-
lution ( Ëœğ’‘, Ëœğ’‘â€²) is a vertex such that Ëœğ‘â€²
= ğ‘’ğœ–0 for ğ‘— = 1, . . . , ğ‘™ and
Ëœğ‘ ğ‘—
Ëœğ‘â€²
ğµâˆ‘ï¸
Ëœğ‘ ğ‘—
(cid:17)
= ğ‘’âˆ’ğœ–0 for ğ‘— = ğ‘™ + 1, . . . , ğµ, for some ğ‘™ âˆˆ [ğµ]. Thus, we have
ğ‘™âˆ‘ï¸
Ëœğ‘ ğ‘— + ğ‘’âˆ’ğœ–0(cid:16)1 âˆ’ ğ‘™âˆ‘ï¸
= ğ‘’âˆ’ğœ–0 + (ğ‘’ğœ–0 âˆ’ ğ‘’âˆ’ğœ–0)
Ëœğ‘ ğ‘— + ğ‘’âˆ’ğœ–0
Ëœğ‘â€²
ğ‘— = ğ‘’ğœ–0
ğ‘™âˆ‘ï¸
ğµâˆ‘ï¸
ğ‘™âˆ‘ï¸
ğ‘—=ğ‘™+1
= ğ‘’ğœ–0
1 =
ğ‘—=1
ğ‘—=1
Ëœğ‘ ğ‘—
Ëœğ‘ ğ‘—
Ëœğ‘ ğ‘—
ğ‘—
ğ‘—
ğ‘—
ğ‘—=1
ğ‘—=1
ğ‘—=1
Session 7D: Privacy for Distributed Data and Federated Learning CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea 2339ğ‘’ğœ–0+1. This impliesğ‘™
ğ‘—=1 Ëœğ‘â€²
1
ğ‘— =
1
ğ‘’ğœ–0+1. Now the result fol-
Rearranging the above givesğ‘™
ğ‘’ğœ–0+1, which in turn impliesğµ
ğ‘™âˆ‘ï¸
ğ‘“ (cid:0) Ëœğ’‘, Ëœğ’‘â€²(cid:1) =
ğ‘—=1 Ëœğ‘ ğ‘— =
ğ‘—=ğ‘™+1 Ëœğ‘â€²
ğ‘’ğœ–0
ğ‘— =
lows from the following set of equalities:
ğ‘— + ğµâˆ‘ï¸
ğµâˆ‘ï¸
Ëœğ‘â€²
=
( Ëœğ‘â€²
ğ‘—)2
Ëœğ‘ ğ‘—
ğ‘™âˆ‘ï¸
ğ‘—=1
Ëœğ‘â€²
ğ‘— + ğ‘’âˆ’ğœ–0
ğ‘—=1
= ğ‘’ğœ–0
Ëœğ‘â€²
ğ‘—
Ëœğ‘ ğ‘—
ğµâˆ‘ï¸
ğ‘—=ğ‘™+1
Ëœğ‘â€²
ğ‘—
Ëœğ‘â€²
ğ‘—
Ëœğ‘ ğ‘—
Ëœğ‘â€²
ğ‘—
ğ‘—=ğ‘™+1
ğ‘—=1
ğ‘’2ğœ–0