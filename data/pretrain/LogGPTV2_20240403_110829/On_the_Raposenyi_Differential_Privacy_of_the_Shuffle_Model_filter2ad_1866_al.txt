∑︁
𝑙 − 1(cid:105)
∑︁
𝑗=1
𝑝′
𝑗 𝑝′
𝑗=1
𝑝′
𝑗 𝑝′
𝑙≠𝑗
𝑙≠𝑗
𝑙≠𝑗
(𝑝′
𝑙≠𝑗
𝑙(cid:170)(cid:174)(cid:172)
𝑝′
𝑗 𝑝′
𝑚
𝑗=1
𝑗=1
𝑗=1
= 𝑚2(cid:104) 1
+ 𝐵∑︁
(cid:169)(cid:173)(cid:171) 𝐵∑︁
+ 𝐵∑︁
= 𝑚2(cid:104) 1
(cid:169)(cid:173)(cid:171) 𝐵∑︁
+ 𝐵∑︁
= 𝑚(cid:169)(cid:173)(cid:171) 𝐵∑︁
because𝐵
𝑗=1
(𝑝′
𝑗)2
𝑝 𝑗
𝑗=1
𝑗=1
(c)
𝑚
(cid:32)
∑︁
𝑙
− 𝑝′
𝑗 𝑝′
𝑚
𝑙≠𝑗
(𝑝′
𝑗)2(1 − 𝑝 𝑗)
(𝑝′
(𝑝′
𝑗)2
𝑝 𝑗
(𝑝′
𝑝 𝑗
𝑗=1
𝑗=1
𝑗)2 + 𝐵∑︁
− 𝐵∑︁
𝑗)2 + 𝐵∑︁
− 1(cid:170)(cid:174)(cid:172) .
𝑗)2 +𝐵
𝑗=1
E(cid:2)𝑒𝑠𝑋(cid:3)
𝑒𝑠𝑡
𝑠2𝑚𝜈2
2
𝑒𝑠𝑡
𝑒
Pr [𝑋 ≥ 𝑡] ≤ min
𝑠≥0
≤ min
𝑠≥0
𝑗
(cid:17)2
𝑗 𝑝′
𝑙 =
𝑗=1 𝑝′
𝑗=1(𝑝′
1, . . . , 𝑝′
Here, step (b) uses properties of multinomial distribution:
E𝒉∼𝜇0[ℎ 𝑗] = 𝑚𝑝 𝑗, E𝒉∼𝜇0[ℎ2
𝑗 , and
E𝒉∼𝜇0[ℎ 𝑗ℎ𝑙] = −𝑚𝑝 𝑗 𝑝𝑙 + 𝑚2𝑝 𝑗 𝑝𝑙 for 𝑗 ≠ 𝑙. Step (c) follows
= 1, as
𝑗] = 𝑚𝑝 𝑗 (1 − 𝑝 𝑗) + 𝑚2𝑝2
𝑗=1𝑙≠𝑗 𝑝′
(cid:16)𝐵
𝑗=1 𝑎 𝑗 1{𝑌𝑖 =𝑗 }
𝐵) is a probability distribution.
𝒑′ = (𝑝′
(3) Let 𝑌𝑖 denote the random variable associated with the output
of the local randomizer at the 𝑖’th client. So, Pr [𝑌𝑖 = 𝑗] = 𝑝 𝑗
for 𝑗 ∈ [𝐵]. Recall that ℎ 𝑗 denote the number of clients
that map to the 𝑗’th element from [𝐵]. This implies that
𝑖=1 1{𝑌𝑖 =𝑗 }. For any 𝑖 ∈
for any 𝑗 ∈ [𝐵], we have ℎ 𝑗 =𝑚
(cid:17) − 1,
(cid:17) − 1 = 0. With these definitions, we
(cid:17) − 𝑚 as
[𝑚], define a random variable 𝑋𝑖 =
where 𝑎 𝑗 =
. Observe that 𝑋1, . . . , 𝑋𝑚 are zero mean
i.i.d. random variables, because for any 𝑖 ∈ [𝑚], we have
E [𝑋𝑖] =
can equivalently represent 𝑋(𝒉) =
𝑖=1 𝑋𝑖, which is the sum of 𝑚 zero mean i.i.d.
r.v.s. Furthermore, since 𝑎 𝑗 ∈ [𝑒−𝜖0, 𝑒𝜖0] for any 𝑗 ∈ [𝐵],
we have 𝑋𝑖 ∈ [𝑒−𝜖0 − 1, 𝑒𝜖0 − 1]. Since any bounded r.v.
𝑍 ∈ [𝑎, 𝑏] is a sub-Gaussian r.v. with parameter (𝑏−𝑎)2
4
(see [38, Lemma 1.8])), we have that 𝑋𝑖 is a sub-Gaussian r.v.
with parameter 𝜈2 = (𝑒𝜖0−𝑒−𝜖0)2
(cid:16)𝐵
𝑋(𝒉) = 𝑚
(cid:16)𝐵
(cid:16)𝐵
𝑗=1 𝑎 𝑗 𝑝 𝑗
𝑗=1 𝑎 𝑗ℎ 𝑗
, i.e.,
𝑝′
𝑗
𝑝 𝑗
(cid:104)𝑒𝑠𝑋𝑖(cid:105) ≤ 𝑒
It follows that 𝑋 (h) =𝑚
4
𝑠2 𝜈2
2
E
,
∀𝑠 ∈ R.
𝑖=1 𝑋𝑖 is also a sub-Gaussian ran-
dom variable with parameter 𝑚𝜈2. The remaining steps are
similar to bound the moments of a sub-Gaussian random
variable. We write them here for completeness. From Cher-
noff bound we get
(b)≤ 𝑒− 𝑡2
where (b) follows by setting 𝑠 =
bound the term Pr [−𝑋 ≥ 𝑡]. Thus, we get
2𝑚𝜈2
𝑡
𝑚𝜈2 . Similarly, we can
Pr [|𝑋| ≥ 𝑡] ≤ 2𝑒− 𝑡2
2𝑚𝜈2
0
0
= 𝑖
2𝑚𝜈2 𝑑𝑡
≤ 2𝑖
(b)
𝑡𝑖−1 Pr [|𝑋| ≥ 𝑡] 𝑑𝑡
𝑡𝑖−1𝑒− 𝑡2
Hence, the 𝑖’th moment of the random variable 𝑋 can be
bounded by
E(cid:2)𝑋 𝑖(cid:3) ≤ E(cid:2)|𝑋|𝑖(cid:3)
∫ ∞
∫ ∞
= 𝑖(cid:16)2𝑚𝜈2(cid:17)𝑖/2∫ ∞
= 𝑖(cid:16)2𝑚𝜈2(cid:17)𝑖/2
ables). In the last step, Γ (𝑧) =∫ ∞
have E(cid:2)|𝑋|𝑖(cid:3) ≤ 𝑖Γ (𝑖/2)(cid:0)2𝑚𝜈2(cid:1)𝑖/2, where 𝜈2 = (𝑒𝜖0−𝑒−𝜖0)2
2𝑚𝜈2 (change of vari-
0 𝑥𝑧−1𝑒−𝑥𝑑𝑥 denotes the
Gamma function. Thus, we conclude that for every 𝑖 ≥ 3, we
.
■
where step (b) follows by setting 𝑢 = 𝑡2
0
Γ (𝑖/2) ,
𝑢𝑖/2−1𝑒−𝑢𝑑𝑢
4
This completes the proof of Lemma 6.1.
C.2 Proof of Lemma 6.2
Lemma (Restating Lemma 6.2). We have the following bound:
(cid:169)(cid:173)(cid:171) 𝐵∑︁
𝑗=1
𝑝′2
𝑗
𝑝 𝑗
− 1(cid:170)(cid:174)(cid:172) =
sup
(𝒑,𝒑′)∈T𝜖0
(𝑒𝜖0 − 1)2
.
𝑒𝜖0
𝑗=1
Proof. For any (𝒑, 𝒑′) ∈ T𝜖0, define 𝑓 (𝒑, 𝒑′) = 𝐵
(𝑝′
𝑗)2
.
𝑝 𝑗
Since the function 𝑔 (𝑥, 𝑦) = 𝑥2
𝑦 is convex in (𝑥, 𝑦) for 𝑦 > 0, it
implies that the objective function 𝑓 (𝒑, 𝒑′) is also convex in (𝒑, 𝒑′).
It is easy to verify that T𝜖0 is a polytope.
Since we maximize a convex function 𝑓 (𝒑, 𝒑′) over a polytope
T𝜖0, the optimal solution is one of the vertices of the polytope. Note
that any vertex (𝒑, 𝒑′) of the polytope in 𝐵 dimensions satisfies
all the 𝐵 LDP constraints (i.e., 𝑒−𝜖0 ≤ 𝑝 𝑗
≤ 𝑒𝜖0, 𝑗 = 1, . . . , 𝐵) with
𝑝′
equality. Without loss of generality, assume that the optimal so-
lution ( ˜𝒑, ˜𝒑′) is a vertex such that ˜𝑝′
= 𝑒𝜖0 for 𝑗 = 1, . . . , 𝑙 and
˜𝑝 𝑗
˜𝑝′
𝐵∑︁
˜𝑝 𝑗
(cid:17)
= 𝑒−𝜖0 for 𝑗 = 𝑙 + 1, . . . , 𝐵, for some 𝑙 ∈ [𝐵]. Thus, we have
𝑙∑︁
˜𝑝 𝑗 + 𝑒−𝜖0(cid:16)1 − 𝑙∑︁
= 𝑒−𝜖0 + (𝑒𝜖0 − 𝑒−𝜖0)
˜𝑝 𝑗 + 𝑒−𝜖0
˜𝑝′
𝑗 = 𝑒𝜖0
𝑙∑︁
𝐵∑︁
𝑙∑︁
𝑗=𝑙+1
= 𝑒𝜖0
1 =
𝑗=1
𝑗=1
˜𝑝 𝑗
˜𝑝 𝑗
˜𝑝 𝑗
𝑗
𝑗
𝑗
𝑗=1
𝑗=1
𝑗=1
Session 7D: Privacy for Distributed Data and Federated Learning CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea 2339𝑒𝜖0+1. This implies𝑙
𝑗=1 ˜𝑝′
1
𝑗 =
1
𝑒𝜖0+1. Now the result fol-
Rearranging the above gives𝑙
𝑒𝜖0+1, which in turn implies𝐵
𝑙∑︁
𝑓 (cid:0) ˜𝒑, ˜𝒑′(cid:1) =
𝑗=1 ˜𝑝 𝑗 =
𝑗=𝑙+1 ˜𝑝′
𝑒𝜖0
𝑗 =
lows from the following set of equalities:
𝑗 + 𝐵∑︁
𝐵∑︁
˜𝑝′
=
( ˜𝑝′
𝑗)2
˜𝑝 𝑗
𝑙∑︁
𝑗=1
˜𝑝′
𝑗 + 𝑒−𝜖0
𝑗=1
= 𝑒𝜖0
˜𝑝′
𝑗
˜𝑝 𝑗
𝐵∑︁
𝑗=𝑙+1
˜𝑝′
𝑗
˜𝑝′
𝑗
˜𝑝 𝑗
˜𝑝′
𝑗
𝑗=𝑙+1
𝑗=1
𝑒2𝜖0