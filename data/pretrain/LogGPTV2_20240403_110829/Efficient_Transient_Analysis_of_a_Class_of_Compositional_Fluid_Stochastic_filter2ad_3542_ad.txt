= 1
δ(3)
k1δ(3)
(k1+1)δ(3)
k1δ(3)
(1.8ξ + 0.1)dξ
= 1.8(2k1 + 1)δ(3)/2 + 0.1
for k1 = 0, . . . , n3 − 1,
3)
(2)
tf1
a
(k1, k1 + 1) = 1
δ(2)
(2)
in (tf1 , ξ)dξ
(2)
tf2
a
(k1, k1)
(k1+1)δ(2)
f
= 1
δ(2)
(2)
in (tf2 , ξ)dξ
(cid:12)
(cid:12)
(cid:12)
(cid:12)
k1δ(2)
(k1+1)δ(2)
k1δ(2)
= 1
δ(2)
(1.8ξ + 0.1)dξ
= 1.8(2k1 + 1)δ(2)/2 + 0.1
for k1 = 0, . . . , n2 − 1,
(3)
in (tf2 , ξ)dξ
(k1+1)δ(3)
f
k1δ(3)
(k1+1)δ(3)
(1 − ξ)dξ
= 1
δ(3)
= 1 − k1δ(3) − δ(3)/2
k1δ(3)
for k1 = 0, . . . , n3 − 2.
(3)
tf2
a
(k1, k1 + 1) = 1
δ(3)
In matrix notation, we have
A(1)
tfi
= I
for i = 1, 2,
and for the three different ﬂow rate functions we obtain
for function 1:
A(2)
tf1
A(2)
tf2
= supdiag( I1T ), A(3)
tf1
A(3)
= I,
tf2
= I,
= supdiag( I1T ),
for function 2:
A(2)
tf1
A(3)
tf1
A(3)
tf2
= supdiag((1 − δ(2)
= I, A(2)
= I,
tf2
= supdiag((1 − δ(3)
2 , . . . , 1 − (n2 − 2)δ(2) − δ(2)
2 , . . . , 1 − (n3 − 2)δ(3) − δ(3)
2 )T ),
2 )T ),
2 , . . . , 1 − (n2 − 2)δ(2) − δ(2)
= supdiag((1 − δ(2)
= supdiag(( 1.8δ(3)
= supdiag(( 1.8δ(2)
= supdiag((1 − δ(3)
for function 3:
A(2)
2 )T ),
tf1
A(3)
+ 0.1)T ),
tf1
A(2)
+ 0.1)T ),
tf2
A(3)
2 )T ),
tf2
where supdiag(·) denotes a matrix with nonzero entries in its
(cid:2)
superdiagonal given by its vector argument.
2 , . . . , 1 − (n3 − 2)δ(3) − δ(3)
2 + 0.1, . . . ,
2 + 0.1, . . . ,
1.8(2n3−1)δ(3)
1.8(2n2−1)δ(2)
2
2
t
. It is well known that the relation S ⊆ ×J
We now introduce how Q can be expressed in terms of the
j=1S (j)
matrices A(j)
holds. Unfortunately, the potential state space ×J
j=1S (j) is
often a superset of the reachable state space S [4]. In this
case, an additional hierarchy is introduced to compose subsets
of the local states. Different approaches to generate such a
hierarchy are nowadays well known [3], [9], [10], [22] and
will not be repeated here.
We brieﬂy introduce the hierarchical structure. Each subnet
state space is decomposed into disjoint subsets S (j)[k] for
k = 0, . . . , m(j) − 1. The macro state space is then deﬁned as
MS ⊂ ×J
S =
j=1{0, . . . , m(j) − 1} such that
×J
j=1S (j)[kj].
S[k] =
(cid:15)
(9)
(cid:15)
k∈MS
(k1,...,kJ )∈MS
According to the decomposition of the state space, each matrix
A(j)
can be decomposed into (m(j))2 submatrices A(j)[k, l]
t
297
t
I1T
J(cid:18)
J(cid:18)
t = diag
(cid:9)
t∈T λt
(cid:9)
t∈T λt
(cid:16)
(cid:17)
for k, l = 0, . . . , m(j) − 1. Furthermore, we deﬁne diagonal
matrices D(j)
A(j)
. Matrix Q can then be
represented in a block structured form with |MS|2 blocks
Q[k, l] (k, l ∈ MS) such that
⎧⎪⎪⎨
Q[k, l] =
⎪⎪⎩
[kj, lj]
[kj, kj] − D(j)
(10)
(cid:13)J
This representation is compact because a matrix of dimension
j=1 |S (j)|) is represented by small
|S| which is often in O(
matrices of order |S (j)|. The representation is particularly well
suited for iterative numerical methods since the vector matrix
products with matrix Q can be realized efﬁciently [9], [25].
For transient analysis, which is considered here, the uni-
A(j)
(cid:16)
A(j)
for k (cid:14)= l,
for k = l.
[kj, kj]
(cid:17)
j=1
j=1
t
t
t
formization method is often applied, resulting in
∞(cid:2)
(cid:19)
(cid:20)k
1
Q
k=0
I +
π(τ ) = π(0)
P oiss(qmaxτ, k)
(11)
where P oiss are the Poisson probabilities and qmax ≥
max
. Other transient solvers like Runge-Kutta For-
mulae (RKF) or Backward Differentiation Formulae (BDF)
can be realized similarly. For details we refer to [25].
(cid:10)|Qs,s|(cid:11)
qmax
,
Although matrix Q is represented in compact form helping
us to circumvent the curse of dimensionality to a large extent,
numerical analysis as in (11) requires vectors of length |S|,
which still limits the applicability of semi discretization. In
the following section, we present a more compact approach
to represent vectors which requires, in contrast to the exact
compact representation of matrix Q, the introduction of an
approximation.
Example.(continued) For the simple example, a hierarchical
structure is not necessary because the reachable state space is
identical to the potential state space consisting of the cross
product of the state spaces of the three components. Thus the
discretized system has 2n2n3 states and the transition matrix
can be represented by sums of Kronecker products of three
matrices with the dimensions 2 × 2, n2 × n2 and n3 × n3,
(cid:2)
respectively.
IV. TRANSIENT NUMERICAL ANALYSIS
The problem of combinatorially growing state spaces for
high dimensional problems is, of course, not restricted to
FSPNs. It is known in many areas where PDEs are used, exam-
ples are biological systems or statistical physics. In these areas
compact representations to approximate higher dimensional
tensors in a more efﬁcient way have been developed [17],
[23]. These representations have recently also been applied to
the stationary analysis of Markov models [5], [19]. We extend
the approaches here to the transient analysis of SFSPNs.
In the following, we consider the representation of a vector
x including one entry for each state from S[k]. This vector
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:47:40 UTC from IEEE Xplore.  Restrictions apply. 
is multiplied with submatrices Q[k, l] in numerical analysis
algorithms. To represent all states, |MS| vectors are necessary.
The simplest form of a compact representation for x using
data structures with O(maxj∈{1,...,J} |S (j)[kj]|) entries is the
following representation as a Kronecker product [17], [25]
x ≈ J(cid:21)
j=1
x(j)
,
(12)
(cid:9)
where vectors x(j) are of length |S (j)[kj]|. Since matrix
t ⊗J
j=1C (j)
Q[k, l] =
, the multiplication can be realized
⎞
⎛
as follows.
J(cid:21)
⎝(cid:2)
⎠
⎛
⎝ J(cid:21)
J(cid:21)
(cid:2)
⎞
⎠ =
x(j)C (j)
x(j)
t
t
(13)
C (j)
t
j=1
t
j=1
t
j=1
Consequently, the result is a sum of Kronecker products of
vectors, one for each term in the sum. This implies that for an
exact computation, in each iteration of the transient solution
algorithm the number of Kronecker products is increased by
a factor of O(|T |) which means that after some iterations
the representation is no longer compact. A straightforward
idea is to approximate a sum of Kronecker products with a
single Kronecker product as done in [6]. However, although
this approach resulted in some cases in good results,
the
approximation error is uncontrolled and the representation
is ﬁxed. More appropriate is a ﬂexible representation which
allows one to control the approximation error.
Such a representation is available with the HTD format [17],
[21] which will be brieﬂy introduced here. The idea is to
represent vector x as a binary tree, as shown for the case
J = 4 in Fig. 2. Matrix U (j) is a |S (j)[kj]| × r(j) matrix, the
intermediate matrices B(ij) are of dimensions r(i)r(j) × r(ij)
for (i, j) ∈ {(1, 2), (3, 4)} and the root matrix B(1234) is a
r(12)r(34) × 1 matrix (a vector). This representation can be
easily extended to more than 4 subnets. If the number of
subnets is not a power of 2, still one node per subnet has
to be at the bottom level.
Vector x with the HTD representation from Fig. 2 can then
be represented as
(cid:16)
U (1) ⊗ U (2) ⊗ U (3) ⊗ U (4)
xT =
(cid:17)(cid:16)
B(12) ⊗ B(34)
(cid:17)
B(1234)
.
Memory requirements for such a representation with J subnets
are bounded by Jnmaxrmax + (J − 2)r3
max ﬂoating
point numbers, where nmax = max
and rmax =
max(r(i)) for some node i in the tree. Values r(i) denote ranks,
and as long as the ranks are not too large, the representation
remains compact.
(cid:10)|S (j)[kj]|(cid:11)
max + r2
(cid:17)T
The interesting aspect is that we can compute the product
of a Kronecker product of matrices with a vector in HTD
(cid:16)
form in a very efﬁcient way, mainly by computing products
U (j)
C (j). For details we refer to the corresponding
algorithm in [21]. If two vectors in HTD form are added, then
the rank of the resulting representation equals the sum of the
ranks of the two representations that are added. Thus, the same
298
problem as for simple Kronecker products comes up. However,
for the HTD representation a well deﬁned approximation
algorithm exists. This algorithm computes for each matrix in
the tree a singular value decomposition which allows one to
truncate the ranks according to a well deﬁned error bound (for
details see [5], [21]). The local truncation operation in each
node results in an optimal local approximation of the exact
representation in terms of the 2-norm [14].
Algorithms to add vectors in HTD format and to perform
the truncation can be found in [21]. By setting a truncation
bound, a trade off between accuracy and memory requirements
is achieved. For the transient analysis of FSPNs, three approxi-