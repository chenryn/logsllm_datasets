### Analysis of HTTP Traffic Exiting Tor and Connecting to Popular Websites

A significant amount of HTTP traffic exits the Tor network and connects to popular websites, potentially exposing a vast collection of private user information. The ratio of unencrypted connections in this traffic is even higher than that observed in a typical university network. However, it is likely that fewer users are logged in when using Tor, as more experienced users may be aware of the security risks and avoid accessing unprotected pages and subdomains over untrusted connections. Despite this, many users will exhibit normal browsing patterns, thereby exposing their cookies to potential attackers.

Furthermore, while we cannot determine the exact number of users who are logged in and thus susceptible to cookie hijacking (which would require examining the cookie names), for some websites, observing encrypted connections is a strong indicator that we are also seeing HTTP traffic from logged-in users. For example, for Amazon and Baidu, encrypted traffic often signifies account-related functionality (e.g., Amazon checkout) that requires users to be logged in, and this is typically accompanied by HTTP traffic (e.g., Amazon product pages). Therefore, we believe that a considerable number of Tor users may be at risk of deanonymization through hijacked cookies.

### User Bias in New Exit Nodes

Since this is a newly deployed exit node, the population of users connecting to it may be biased towards less experienced users, as more privacy-conscious individuals may avoid exiting through such nodes. Consequently, the observed ratio of encrypted connections or the websites users connect to may differ from other exit nodes. However, adversaries could already own exit nodes with long uptimes or monitor outgoing traffic from legitimate exit nodes, which is a common adversarial model in Tor-related research [50]. Thus, we consider this a credible and severe threat to Tor users who wish to maintain their anonymity while browsing popular websites.

### Countermeasures and Discussion

Our work highlights the privacy implications of HTTP cookie hijacking attacks and demonstrates the gravity and pervasiveness of sensitive information exposure by high-profile services. We discuss potential causes for the current vulnerable state of major websites and evaluate the effectiveness of existing security mechanisms in practice. While the defenses against these attacks are known and seemingly straightforward, our experiments show that even the most popular and resourceful websites can fall victim to design and implementation flaws.

#### Partial Encryption and Personalization

Due to the complexity of implementing large-scale web services and defining precise access privileges for multiple (inter-dependent) cookies across different subdomains, web developers are prone to errors such as incomplete separation of access control for unauthenticated cookies. This allows passive eavesdroppers who hijack HTTP cookies to obtain sensitive information. Although we tested certain websites where partial encryption did not result in privacy leakage, none of these services offered a personalized version of the service to HTTP cookies. This indicates the conflicting nature of offering personalization while maintaining ease-of-use without requiring re-authentication. Therefore, we argue that any service that supports user accounts and personalizes the experience should enforce ubiquitous encryption to mitigate the privacy threats we have explored.

#### Cookie Flags

By setting the Secure cookie flag to True, websites can ensure the confidentiality of a cookie by instructing the browser to send it only over encrypted connections. However, while this can prevent passive eavesdroppers from acquiring the cookies, it is known that active attackers can overwrite secure cookies from an insecure channel [52]. Therefore, the Secure flag alone is insufficient protection and should be used in combination with fully deployed HSTS and support for ubiquitous encryption. Additionally, the HttpOnly flag should be set to prevent remote cookie hijacking.

#### Security Mechanisms

We evaluated the impact of browser-supported security mechanisms on the feasibility of our attacks. Here, we discuss our findings regarding the protection these mechanisms offer and their limitations.

##### HSTS

Recent work has extensively studied HSTS and discussed the pitfalls of its deployment, reporting that many developers fail to implement it correctly [11]. In our work, we focus on the fact that even if implemented correctly, partial deployment nullifies the protection it offers, leaving users exposed. This is particularly apparent when the main landing page of a website does not enforce HSTS. Even if users are subsequently redirected to HTTPS (as is the case with Google), the HTTP cookies are exposed during the initial connection. Given that users often directly visit popular websites by typing their name in the address bar, facilitated by auto-completion, this practice can expose a large number of users to cookie hijacking attacks. Considering our findings on the amount of personal information and account functionality that unauthenticated cookies can access, this is a significant privacy risk. The need for full HSTS deployment has also been argued by others [11], [52].

##### HTTPS Everywhere

Through our experimentation, we found that this browser extension improves user security by minimizing the attack surface and can prevent risks due to partial (or non-existent) deployment of HSTS. However, it is crucial to note that, even with this extension, users are not entirely protected. As site functionality can break if the server does not support HTTPS for a specific subdomain or page, HTTPS Everywhere relies on rule-sets that contain exceptions for these cases. While certain websites might be significantly covered, other cases still contain a considerable number of unprotected pages. If users click on the extension’s notification icon, a menu shows information about the current page and whether content has been fetched over non-encrypted connections. However, users often ignore warnings, and the design of these warnings can significantly affect user actions [53]. The menu contains an option to block such connections, which, while it can break the browsing experience, may be a prudent choice for users who prioritize their privacy. This could apply to users who rely on systems like Tor for maintaining their anonymity, who can be deanonymized as discussed in Section V. Nonetheless, this is not the default option, and if the user visits such a website before enabling the option, the HTTP cookies will be exposed. Enabling this option by default and allowing users to opt-out is a safer approach.

##### VPN

End users should also consider using VPN technology when connecting to untrusted public wireless networks, as it reduces the threat of their traffic being sniffed [54].

### Ethics and Disclosure

To ensure the ethical nature of our research, we provided a detailed description of our data collection and analysis process to Columbia University’s IRB and obtained approval for both our experiments with the public wireless network and the Tor network. Furthermore, all captured data was destroyed after the end of our evaluation measurements.

Disclosing attacks against popular services raises ethical issues, as one might argue that adversaries may have previously lacked the know-how to conduct these attacks. However, the practicality of cookie hijacking suggests that such attacks could soon happen in the wild (if not happening already). To that end, we have already contacted all the audited websites to disclose our findings in detail. We have also contacted Tor developers to inform them of the deanonymization threat users face. By shedding light on this significant privacy threat, we aim to incentivize services to streamline support for ubiquitous encryption. Additionally, we must alert users to the privacy risks they face when connecting to public wireless networks or browsing through Tor and educate them on the extent of protection offered by existing mechanisms.

### Related Work

#### Hijacking and Other Cookie-Related Issues

Zheng et al. [52] recently presented an empirical study on the feasibility of cookie injection attacks. While cookies have the Secure flag that can prevent browsers from sending them over unencrypted connections, there is no provision to ensure that such cookies are also set only over HTTPS connections. As a result, during an HTTP connection to a domain, a man-in-the-middle attacker can inject cookies that will be appended in future HTTPS connections to that specific domain. In their real-world assessment of this attack, the authors explored how cookie injection could enable attacks such as account and (sub-)session hijacking, and cart manipulation in e-commerce sites. They also identified how browser-specific handling of cookies can enable attacks. Bortz et al. [55] had previously described cookie injection attacks and proposed origin cookies for achieving session integrity in web applications.

Wang et al. [56] identified flaws in popular ID providers of single-sign-on services that allowed attackers to log into services as the users. Karlof et al. [57] introduced pharming attacks that relied on DNS hijacking and allowed attackers to hijack user sessions. Lekies et al. [58] leveraged the exemption of remote scripts included through the HTML script tag from the Same-Origin policy for leaking personal information and, in some cases, hijacking sessions. Barth et al. [59] introduced the login CSRF attack, where the user is logged into a legitimate service as the attacker, which can result in the exposure of sensitive user information.

Numerous approaches have been proposed for preventing session hijacking [60]–[62]. Jackson and Barth presented ForceHTTPS [63], a browser extension for enforcing HTTPS connections, which was later reformed and standardized as HSTS [12]. Kranch and Bonneau [11] performed an extensive study on the adoption of HSTS and certificate pinning in the wild, reporting a lack of understanding by web developers on the proper use of these mechanisms. Selvi [64] demonstrated scenarios where an attacker could bypass HSTS protection. Bhargavan et al. [65] showed how the HSTS header could be partially truncated, resulting in the expiration of the HSTS entry within seconds. Singh et al. [3] studied the incoherencies of web access control and showed that user actions and resources could be improperly exposed to web applications.

Mayer and Mitchel [40] discussed the policy and technology issues of third-party web tracking. Roesner et al. [41] studied the behavior of web trackers and found an extensive set of trackers. They also explored the impact of browser mechanisms, such as cookie blocking and DoNotTrack, and found that preventing web-tracking from popular social network widgets also broke their functionality. Sivakorn et al. [66] demonstrated how HTTP cookies could be used for influencing Google’s advanced risk analysis system and bypassing reCAPTCHA challenges. Attackers could use hijacked cookies in a similar fashion, which can bypass even more stringent safeguards that require extensive browsing history.

#### Risks of Personalization

The personal information leakage we identify in our attacks is a direct result of websites offering a personalized experience to users. Castelluccia et al. [4] highlighted the problem of privacy leakage that can occur when personalized functionality is accessible to HTTP cookies. The authors demonstrated how adversaries could reconstruct a user’s Google search history by exploiting the personalized suggestions. Korolova presented novel attacks that use targeted ads for obtaining private user information [46]. Toch et al. [67] analyzed the privacy risks that emerge from popular approaches to personalizing services.

#### Encrypted Connections

The privacy threats we study are also the result of websites not enforcing encryption across all pages and subdomains. Previous work has shown the risks of supporting mixed-content websites, where pages accessed over HTTPS also include content fetched over HTTP [68]. While security mechanisms or browser extensions reduce the attack surface, they do not entirely mitigate these attacks. A significant step towards improving user privacy is the deployment of ubiquitous encryption. Naylor et al. [2] discussed the “cost” of a wide deployment of HTTPS and analyzed aspects such as infrastructure costs, latency, data usage, and energy consumption. However, even when the connection is encrypted, previous work has demonstrated the feasibility of a wide range of attacks at both the application and cryptographic level that can subvert the protection [10], [69]–[72]. Fahl et al. [73], [74] explored such attacks in the mobile domain.

#### Deanonymizing Tor Users

Huber et al. [75] discussed how Tor users could be deanonymized by PII being leaked in HTTP traffic. Chakravarty et al. [76] proposed the use of decoy traffic with fake credentials for detecting adversaries monitoring traffic from Tor exit nodes. While their prototype focused on IMAP and SMTP servers, their technique could be extended to leverage decoy accounts in major websites. If the attacker does not change the account in a visible way, this technique will only detect attacks if the service offers information about previous logins (e.g., as Gmail does). Winter et al. [77] deployed their tool HoneyConnector for a period of 4 months and identified 27 Tor exit nodes that monitored outgoing traffic and used stolen decoy credentials.

### Conclusion

In this paper, we presented an extensive in-depth study on the privacy threats that users face when attackers steal their HTTP cookies. We audited a wide range of major services and found that cookie hijacking attacks are not limited to a specific type of website but pose a widespread threat to any website that does not enforce ubiquitous encryption. Our study revealed numerous instances of major services exposing private information and protected account functionality to non-authenticated cookies. This threat is not restricted to websites, as users' cookies are also exposed by official browser extensions, search bars, and mobile apps. To better understand the risk posed by passive eavesdroppers in practice, we conducted an IRB-approved measurement study and detected that a large portion of the outgoing traffic in public wireless networks remains unencrypted, thus exposing a significant number of users to cookie hijacking attacks.

We also evaluated the protection offered by popular browser-supported security mechanisms and found that they can reduce the attack surface but cannot protect users if websites do not support ubiquitous encryption. The practicality and pervasiveness of these attacks also render them a significant threat to Tor users, as they can be deanonymized by adversaries monitoring the outgoing traffic of exit nodes.

### Acknowledgements

We would like to thank the anonymous reviewers for their feedback. We would also like to thank the CUIT team of Joel Rosenblatt and the CRF team of Bach-Thuoc (Daisy) Nguyen at Columbia University for their technical support throughout this project. Finally, we would like to thank Georgios Kontaxis, Vasileios P. Kemerlis, and Steven Bellovin for informative discussions and feedback. This work was supported by the NSF under grant CNS-13-18415. Author Suphannee Sivakorn is also partially supported by the Ministry of Science and Technology of the Royal Thai Government. Any opinions, findings, conclusions, or recommendations expressed herein are those of the authors and do not necessarily reflect those of the US Government or the NSF.

### References

[1] E. Butler, “Firesheep,” 2010, http://codebutler.com/firesheep.
[2] D. Naylor, A. Finamore, I. Leontiadis, Y. Grunenberger, M. Mellia, M. Munafò, K. Papagiannaki, and P. Steenkiste, “The Cost of the ”S” in HTTPS,” in Proceedings of the 10th ACM International on Conference on Emerging Networking Experiments and Technologies, ser. CoNEXT ’14. ACM, 2014, pp. 133–140.
[3] K. Singh, A. Moshchuk, H. J. Wang, and W. Lee, “On the Incoherencies in Web Browser Access Control Policies,” in Proceedings of the 2010 IEEE Symposium on Security and Privacy, 2010.
[4] C. Castelluccia, E. De Cristofaro, and D. Perito, “Private Information Disclosure from Web Searches,” in Privacy Enhancing Technologies, ser. PETS ’10, 2010.
[5] B. Krishnamurthy and C. E. Wills, “On the leakage of personally identifiable information via online social networks,” in Proceedings of the 2nd ACM workshop on Online social networks, ser. WOSN ’09, 2009.
[6] B. Krishnamurthy and C. Wills, “Privacy Leakage in Mobile Online Social Networks,” in Proceedings of the 3rd Workshop on Online Social Networks, ser. WOSN ’10, 2010.
[7] S. Englehardt, D. Reisman, C. Eubank, P. Zimmerman, J. Mayer, A. Narayanan, and E. W. Felten, “Cookies That Give You Away: The Surveillance Implications of Web Tracking,” in Proceedings of the 24th International Conference on World Wide Web, ser. WWW ’15, 2015.
[8] Y. Liu, H. H. Song, I. Bermudez, A. Mislove, M. Baldi, and A. Tongaonkar, “Identifying Personal Information in Internet Traffic,” in Proceedings of the 3rd ACM Conference on Online Social Networks, ser. COSN ’15, 2015.
[9] B. Möller, T. Duong, and K. Kotowicz. (2014, Oct.) This POODLE bites: exploiting the SSL 3.0 fallback. https://googleonlinesecurity.blogspot.com/2014/10/this-poodle-bites-exploiting-ssl-30.html.
[10] M. Marlinspike, “New Tricks For Defeating SSL In Practice,” BlackHat DC, Feb. 2009.
[11] M. Kranch and J. Bonneau, “Upgrading HTTPS in Mid-Air: An Empirical Study of Strict Transport Security and Key Pinning,” in Proceedings of the Network and Distributed System Security Symposium, ser. NDSS ’15, 2015.
[12] J. Hodges, C. Jackson, and A. Barth, “HTTP Strict Transport Security,” RFC 6797, 2012.
[13] Can I use. HSTS Browser Support. http://caniuse.com/#feat=stricttransportsecurity.
[14] L. Garron. HSTS Preload. https://hstspreload.appspot.com/.
[15] M. Stevens, A. Sotirov, J. Appelbaum, A. Lenstra, D. Molnar, D. A. Osvik, and B. De Weger, “Short chosen-prefix collisions for MD5 and the creation of a rogue CA certificate,” in Advances in Cryptology-CRYPTO 2009, 2009, pp. 55–69.
[16] C. Palmer and C. Evans, “Certificate Pinning Extension for HSTS,” RFC 6797, 2012.
[17] C. Palmer, C. Evans, and R. Sleevi, “Certificate Pinning Extension for HSTS,” RFC 7469, 2015.