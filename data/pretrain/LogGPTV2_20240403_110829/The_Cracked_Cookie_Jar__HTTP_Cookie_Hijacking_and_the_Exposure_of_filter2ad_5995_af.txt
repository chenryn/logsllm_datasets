amount of HTTP trafﬁc exiting Tor and connecting to popular
websites that expose a vast collection of private user infor-
mation. While the ratio of unencrypted connections is even
higher than that of our university’s network, possibly fewer
users will be logged in when using Tor. More experienced
users may be aware of the shortcomings of this mechanism and
avoid the pages and subdomains that are not protected when
connecting over untrusted connections. Nonetheless, we expect
that many users will exhibit normal browsing patterns, thus,
exposing their cookies to attackers. Furthermore, even though
we can not know how many of the users are indeed logged
in and susceptible to cookie hijacking (that would require
looking at the cookie names), for some websites observing
encrypted connections is an almost deﬁnitive sign that we
are also observing HTTP trafﬁc of logged in users; due to
functionality breaking and the corresponding exceptions in the
HTTPS Everywhere rule-sets, HTTPS trafﬁc for Amazon and
Baidu signiﬁes account-related functionality that requires users
to be logged in (e.g., Amazon checkout) and is accompanied
by HTTP trafﬁc (Amazon products pages). Thus, we believe
that a considerable number of Tor users may be facing the risk
of deanonymization through hijacked cookies.
User bias. As this is a newly deployed exit node,
the
population of users connecting to it may be biased towards in-
experienced users, as more privacy-conscious ones may avoid
exiting from such nodes. Thus, our observed ratio of encrypted
connections or the websites users connect to, may present
differences to other exit nodes. Nonetheless, adversaries could
already own exit nodes with long uptimes, or be able to
monitor the outgoing trafﬁc from legitimate exit nodes, which
is a common adversarial model for Tor-related research [50].
Thus, we believe this to be a credible and severe threat to Tor
users that want to maintain their anonymity while browsing
(popular) websites.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:10:26 UTC from IEEE Xplore.  Restrictions apply. 
VI. COUNTERMEASURES AND DISCUSSION
Our work focuses on highlighting the privacy ramiﬁcations
of HTTP cookie hijacking attacks, and we have demonstrated
the gravity and pervasiveness of sensitive information being
exposed by high-proﬁle services. We discuss potential causes
for the current vulnerable state of major websites, and how
existing security mechanisms fare in practice. While the de-
fenses for preventing these attacks are known and, seemingly,
straightforward, our experiments demonstrate that even the
most popular and resourceful websites succumb to design and
implementation ﬂaws.
Partial encryption and personalization. Due to the
complexity in implementing large-scale web services, and
also deﬁning precise access privileges for multiple (inter-
dependent) cookies for different subdomains, web developers
are prone to errors such as the incomplete separation of
access control for unauthenticated cookies. In turn, this allows
passive eavesdroppers that hijack HTTP cookies to obtain
sensitive information. While we tested certain websites where
partial encryption did not result in privacy leakage, none of
those services offered a personalized version of the service to
HTTP cookies. This indicates the conﬂicting nature of offering
personalization while aiming to maintain ease-of-use by not
requiring re-authentication. As such, we argue that any service
that supports user accounts and personalizes the experience,
should enforce ubiquitous encryption, which would mitigate
the privacy threats we have explored.
Cookie Flags. By setting the Secure cookie ﬂag to
True, websites can ensure the conﬁdentiality of a cookie by
instructing the browser to only send over encrypted connec-
tions. However, while this can prevent passive eavesdroppers
from acquiring the cookies, it is known that active attackers
can overwrite secure cookies from an insecure channel [52].
Therefore, the Secure ﬂag as a stand-alone measure cannot
fully protect users. It should be used in combination with
fully deployed HSTS and support for ubiquitous encryption.
Furthermore, the HttpOnly ﬂag should be set to prevent
remote cookie hijacking.
Security mechanisms. We have evaluated the impact of
browser-supported security mechanisms on the feasibility of
our attacks. Here we discuss our ﬁndings about the protection
these mechanisms offer and their shortcomings.
HSTS. Recent work presented an extensive study on HSTS
and discussed the pitfalls of deploying it in practice, reporting
that many developers fail to implement it correctly [11]. In
our work, we focus on the fact that even if implemented
correctly, partial deployment nulliﬁes the protection it offers
and users remain exposed. This is particularly apparent when
the main landing page of a website does not enforce HSTS.
Even if users are subsequently redirected to HTTPS (as is
the case with Google), the HTTP cookies are exposed during
the initial connection. As it is common for users to directly
visit popular websites by typing their name in the address
bar, which is facilitated by auto-completion functionality, this
practice can expose a large number of users to cookie hijacking
737737
attacks. Taking into consideration our ﬁndings regarding the
amount of personal information and account functionality that
unauthenticated cookies can access, this is a signiﬁcant privacy
risk that users face. The need for full HSTS deployment has
also been argued for by others [11], [52].
HTTPS Everywhere. Through our experimentation, we
found that this browser extension improves user security by
minimizing the attack surface, and can prevent risks due to
partial (or non-existent) deployment of HSTS. However, it is
crucial to note that, even with this extension in place, users
are not entirely protected. As site functionality can break if
the server does not support HTTPS for a speciﬁc subdomain
or page, HTTPS Everywhere relies on rule-sets that contain
exceptions for these cases. As such, while certain websites
might be signiﬁcantly covered, other cases still contain a
considerable number of unprotected pages. If users click on
the extension’s notiﬁcation icon, a menu shows information
regarding the current page and if content has been fetched over
non-encrypted connections. However, users are notoriously
good at ignoring warnings, and their design can signiﬁcantly
affect user actions [53]. The menu contains an option to
block such connections. While this can break the browsing
experience, it may be a prudent choice for users that consider
their privacy of paramount
importance. This could apply
to users that rely on systems such as Tor for maintaining
their anonymity, who can be deanonymized as we discuss in
Section V. Nonetheless, this is not the default option, and if
the user visits such a website before enabling the option, the
HTTP cookies will be exposed. Thus, enabling this option by
default and allowing users to opt-out is a safer approach.
VPN. End users should also consider the use of VPN tech-
nology when connecting to untrusted public wireless networks,
as it reduces the threat of the user’s trafﬁc being sniffed [54].
VII. ETHICS AND DISCLOSURE
To ensure the ethical nature of our research, we provided a
detailed description of our data collection and analysis process
to Columbia University’s IRB, and obtained approval for both
our experiments with the public wireless network and the Tor
network. Furthermore, all captured data was destroyed after
the end of our evaluation measurements.
Disclosing attacks against popular services raises ethical
issues as, one might argue, adversaries may have previously
lacked the know-how to conduct these attacks. However the
practicality of cookie hijacking suggests that such attacks
could soon happen in the wild (if not happening already). To
that end, we have already contacted all the audited websites
to disclose our ﬁndings in detail. We have also contacted Tor
developers to inform them of the deanonymization threat users
face. We believe that by shedding light on this signiﬁcant pri-
vacy threat, we can incentivize services to streamline support
for ubiquitous encryption. Furthermore, we must alert users of
the privacy risks they face when connecting to public wireless
networks or browsing through Tor, and educate them on the
extent of protection offered by existing mechanisms.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:10:26 UTC from IEEE Xplore.  Restrictions apply. 
Privacy leakage. Krishnamurthy and Willis explored online
social networks and the leakage of users’ personally identiﬁ-
able information (PII) in HTTP headers, and described how
third-party servers can exploit the PII leakage to link it with
user actions across different domains [5]. In follow-up work,
the authors focused on the privacy leakage in social networks
that leveraged the GPS capabilities of mobile devices to offer
location-based functionality [6], and explored how pieces of
information collected from different social networks could be
combined for further compromising user privacy. Englehardt et
al. [7] explored the feasibility of conducting mass surveillance
by monitoring unencrypted trafﬁc and inspecting third-party
tracking cookies. They also identiﬁed cases of PII being
exposed in unencrypted trafﬁc, which can be leveraged for
improving the clustering of user trafﬁc and linking different
requests to the same user. While their work focuses on
a different attack scenario,
the
threat of unencrypted connections. Liu et al. [8] developed
a novel method for detecting PII being transmitted in network
trafﬁc, without prior knowledge of the ﬁelds and form of the
information transmitted by each service. Due to the very small
fraction of ﬁelds that actually contain PII, the authors argue
that looking for ﬁelds with values that are unique to a user
results in very high false positives and false negatives. Thus,
mass surveillance attacks will have to employ more advanced
techniques. The evaluation of the proposed approach on a
large-scale trace presented a false positive rate of 13.6%.
their results also highlight
information sent
These approaches, however, have a limited viewpoint and
can only detect
in clear text during the
monitoring period. There exist multiple common scenarios
where exposed personal information will not be detected: (i)
websites are highly dynamic and content may be fetched in an
obfuscated form and constructed at runtime on the client side,
(ii) sensitive content may always be fetched over encrypted
connections, even though HTTP cookies may (erroneously)
have sufﬁcient access privileges, (iii) certain pieces of infor-
mation are only exposed after speciﬁc user actions, which
may not occur during the monitoring period. Furthermore,
cookie hijacking attacks can also access protected account
functionality in certain cases due to imprecise access control.
Overall, our goal is to explore the prevalence and criticality of
private information and account functionality being accessible
to HTTP cookies, and understanding how varying components
of the complicated ecosystem (from browser security mecha-
nisms to mobile apps) affect the attack surface and feasibility
of hijacking. Furthermore, as the authors state [7], using the
Tor bundle likely defeats their attack scenario. On the other
hand, we demonstrate that while the Tor bundle reduces the
attack surface, cookie hijacking remains feasible.
VIII. RELATED WORK
Hijacking and other cookie-related issues. Zheng et
al. [52] recently presented an empirical study on the feasibility
of cookie injection attacks. While cookies have the Secure
ﬂag that can prevent browsers from sending them over un-
encrypted connections, there is no provision to ensure that
such cookies are also set only over HTTPS connections. As
a result, during an HTTP connection to a domain, a man-in-
the-middle attacker can inject cookies that will be appended
in future HTTPS connections to that speciﬁc domain. In their
real-world assessment of this attack, the authors explored how
cookie injection could enable attacks such as account and
(sub-)session hijacking, and cart manipulation in e-commerce
sites. They also identify how browser-speciﬁc handling of
cookies can enable attacks. Bortz et al. [55] had previously
described cookie injection attacks, and proposed origin cookies
for achieving session integrity in web applications.
Wang et al. [56] identiﬁed ﬂaws in popular ID providers
of single-sign-on services that allowed attackers to log into
services as the users. Karlof et al. [57] introduced pharming
attacks that relied on DNS hijacking and allowed attackers to
hijack user sessions. Lekies et al. [58] leveraged the exemption
of remote scripts included through the HTML script tag
from the Same-Origin policy for leaking personal information
and,
in some cases, hijacking sessions. Barth et al. [59]
introduced the login CSRF attack where the user is logged
into a legitimate service as the attacker, which can result in
the exposure of sensitive user information.
Numerous approaches have been proposed for prevent-
ing session hijacking [60]–[62]. Jackson and Barth pre-
sented ForceHTTPS [63], a browser extension for enforcing
HTTPS connections. This was reformed and standardized as
HSTS [12]. Kranch and Bonneau [11] performed an extensive
study on the adoption of HSTS and certiﬁcate pinning in the
wild. They reported a lack of understanding by web developers
on the proper use of these mechanisms, as they often use them
in illogical or invalid ways. Selvi [64] demonstrated scenarios
where an attacker could bypass HSTS protection. Bhargavan et
al. [65] also showed how the HSTS header could be partially
truncated, resulting in the expiration of the HSTS entry within
seconds. Singh et al. [3] studied the incoherencies of web
access control and showed that user actions and resources
could be improperly exposed to web applications.
Mayer and Mitchel [40] discussed the policy and technology
issues of third-party web tracking. Roesner et al. [41] studied
the behavior of web trackers and found an extensive set of
trackers. They also explored the impact of browser mecha-
nisms, such as cookie blocking and DoNotTrack, and found
that preventing web-tracking from popular social network
widgets also broke their functionality. Sivakorn et al. [66],
demonstrated how HTTP cookies could be used for inﬂuenc-
ing Google’s advanced risk analysis system and bypassing
reCAPTCHA challenges. Attackers could use hijacked cookies
in a similar fashion, which can bypass even more stringent
safeguards that require extensive browsing history.
Risks of personalization. The personal information leakage
we identify in our attacks is a direct result of websites offering
a personalized experience to users. Castelluccia et al. [4] high-
lighted the problem of privacy leakage that can occur when
personalized functionality is accessible to HTTP cookies. The
authors demonstrated how adversaries could reconstruct a
user’s Google search history by exploiting the personalized
738738
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:10:26 UTC from IEEE Xplore.  Restrictions apply. 
suggestions. Korolova presented novel attacks that use tar-
geted ads for obtaining private user information [46]. Toch et
al. [67] analyzed the privacy risks that emerge from popular
approaches to personalizing services.
Encrypted connections. The privacy threats we study are
also the result of websites not enforcing encryption across all
pages and subdomains. Previous work has shown the risks
of supporting mixed-content websites, where pages accessed
over HTTPS also include content fetched over HTTP [68].
While security mechanisms or browser extensions reduce the
attack surface, they do not entirely mitigate these attacks. A
signiﬁcant step towards improving user privacy, is the deploy-
ment of ubiquitous encryption. Naylor et al. [2] discussed
the “cost” of a wide deployment of HTTPS and analyzed
aspects such as infrastructure costs, latency, data usage, and
energy consumption. However, even when the connection is
encrypted, previous work has demonstrated the feasibility of
a wide range of attacks at both application and cryptographic
level that can subvert the protection [10], [69]–[72]. Fahl et
al. [73], [74] explored such attacks in the mobile domain.
Deanonymizing Tor users. Huber et al. [75] discussed
how Tor users could be deanonymized by PII being leaked
in HTTP trafﬁc. Chakravarty et al. [76] proposed the use of
decoy trafﬁc with fake credentials for detecting adversaries
monitoring trafﬁc from Tor exit nodes. While their prototype
focused on IMAP and SMTP servers, their technique could be
extended to also leverage decoy accounts in major websites.
If the attacker doesn’t change the account in a visible way,
this technique will only detect attacks if the service offers
information about previous logins (e.g., as Gmail does). Winter
et al. [77] deployed their tool HoneyConnector for a period
of 4 months, and identiﬁed 27 Tor exit nodes that monitored
outgoing trafﬁc and used stolen decoy credentials.
IX. CONCLUSION
In this paper we presented our extensive in-depth study on
the privacy threats that users face when attackers steal their
HTTP cookies. We audited a wide range of major services
and found that cookie hijacking attacks are not limited to
a speciﬁc type of websites, but pose a widespread threat to
any website that does not enforce ubiquitous encryption. Our
study revealed numerous instances of major services exposing
private information and protected account functionality to
non-authenticated cookies. This threat
is not restricted to
websites, as users’ cookies are also exposed by ofﬁcial browser
extensions, search bars and mobile apps. To obtain a better
understanding of the risk posed by passive eavesdroppers in
practice, we conducted an IRB-approved measurement study
and detected that a large portion of the outgoing trafﬁc in
public wireless networks remains unencrypted, thus, exposing
a signiﬁcant amount of users to cookie hijacking attacks.
We also evaluated the protection offered by popular browser-
supported security mechanisms, and found that they can reduce
the attack surface but can not protect users if websites do not
support ubiquitous encryption. The practicality and pervasive-
ness of these attacks, also renders them a signiﬁcant threat
739739
to Tor users, as they can be deanonymized by adversaries
monitoring the outgoing trafﬁc of exit nodes.
X. ACKNOWLEDGEMENTS
We would like to thank the anonymous reviewers for their
feedback. We would also like to thank the CUIT team of Joel
Rosenblatt and the CRF team of Bach-Thuoc (Daisy) Nguyen
at Columbia University, for their technical support throughout
this project. Finally we would like to thank Georgios Kontaxis,
Vasileios P. Kemerlis and Steven Bellovin for informative
discussions and feedback. This work was supported by the
NSF under grant CNS-13-18415. Author Suphannee Sivakorn
is also partially supported by the Ministry of Science and
Technology of the Royal Thai Government. Any opinions,
ﬁndings, conclusions, or recommendations expressed herein
are those of the authors, and do not necessarily reﬂect those
of the US Government or the NSF.
REFERENCES
[1] E. Butler, “Firesheep,” 2010, http://codebutler.com/ﬁresheep.
[2] D. Naylor, A. Finamore, I. Leontiadis, Y. Grunenberger, M. Mellia,
M. Munaf`o, K. Papagiannaki, and P. Steenkiste, “The Cost of the ”S” in
HTTPS,” in Proceedings of the 10th ACM International on Conference
on Emerging Networking Experiments and Technologies, ser. CoNEXT
’14. ACM, 2014, pp. 133–140.
[3] K. Singh, A. Moshchuk, H. J. Wang, and W. Lee, “On the Incoherencies
in Web Browser Access Control Policies,” in Proceedings of the 2010
IEEE Symposium on Security and Privacy, 2010.
[4] C. Castelluccia, E. De Cristofaro, and D. Perito, “Private Information
Disclosure from Web Searches,” in Privacy Enhancing Technologies,
ser. PETS ’10, 2010.
[5] B. Krishnamurthy and C. E. Wills, “On the leakage of personally
identiﬁable information via online social networks,” in Proceedings of
the 2nd ACM workshop on Online social networks, ser. WOSN ’09,
2009.
[6] B. Krishnamurthy and C. Wills, “Privacy Leakage in Mobile Online
Social Networks,” in Proceedings of the 3rd Workshop on Online Social
Networks, ser. WOSN ’10, 2010.
[7] S. Englehardt, D. Reisman, C. Eubank, P. Zimmerman, J. Mayer,
A. Narayanan, and E. W. Felten, “Cookies That Give You Away: The
Surveillance Implications of Web Tracking,” in Proceedings of the 24th
International Conference on World Wide Web, ser. WWW ’15, 2015.
[8] Y. Liu, H. H. Song, I. Bermudez, A. Mislove, M. Baldi, and A. Ton-
gaonkar, “Identifying Personal Information in Internet Trafﬁc,” in Pro-
ceedings of the 3rd ACM Conference on Online Social Networks, ser.
COSN ’15, 2015.
[9] B. M¨oller, T. Duong, and K. Kotowicz. (2014, Oct.) This POODLE bites:
exploiting the SSL 3.0 fallback. https://googleonlinesecurity.blogspot.
com/2014/10/this-poodle-bites-exploiting-ssl-30.html.
[10] M. Marlinspike, “New Tricks For Defeating SSL In Practice,” BlackHat
DC, Feb. 2009.
[11] M. Kranch and J. Bonneau, “Upgrading HTTPS in Mid-Air: An Empiri-
cal Study of Strict Transport Security and Key Pinning,” in Proceedings
of the Network and Distributed System Security Symposium, ser. NDSS
’15, 2015.
[12] J. Hodges, C. Jackson, and A. Barth, “HTTP Strict Transport Security,”
RFC 6797, 2012.
stricttransportsecurity.
[13] Can
I
use. HSTS Browser Support.
http://caniuse.com/#feat=
[14] L. Garron. HSTS Preload. https://hstspreload.appspot.com/.
[15] M. Stevens, A. Sotirov, J. Appelbaum, A. Lenstra, D. Molnar, D. A.
Osvik, and B. De Weger, “Short chosen-preﬁx collisions for MD5 and
the creation of a rogue CA certiﬁcate,” in Advances in Cryptology-
CRYPTO 2009, 2009, pp. 55–69.
[16] C. Palmer and C. Evans, “Certiﬁcate Pinning Extension for HSTS,” RFC
[17] C. Palmer, C. Evans, and R. Sleevi, “Certiﬁcate Pinning Extension for
DRAFT, 2011.
HSTS,” RFC 7469, 2015.