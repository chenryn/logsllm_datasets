### References

1. Paul Emmerich, Sebastian Gallenmüller, Daniel Raumer, Florian Wohlfart, and Georg Carle. 2015. MoonGen: A Scriptable High-Speed Packet Generator. In *Proc. of ACM IMC*.

2. Zaoxing Liu et al. 2019. NitroSketch Source Code. https://github.com/zaoxing/NitroSketch

3. Seyed K. Fayaz, Yoshiaki Tobioka, Vyas Sekar, and Michael Bailey. 2015. Bohatei: Flexible and Elastic DDoS Defense. In *Proc. of USENIX Security*.

4. FD.io. 2018. Vector Packet Processing. https://fd.io/technology/

5. William Feller. 1943. Generalization of a Probability Limit Theorem of Cramér. *Trans. Amer. Math. Soc.* (1943).

6. Pedro Garcia-Teodoro, Jesus E. Diaz-Verdejo, Gabriel Macia-Fernandez, and E. Vazquez. 2009. Anomaly-Based Network Intrusion Detection: Techniques, Systems and Challenges. *Computers and Security* (2009).

7. Robert D. Gordon. 1941. Values of Mills’ Ratio of Area to Bounding Ordinate and of the Normal Probability Integral for Large Values of the Argument. *The Annals of Mathematical Statistics* (1941).

8. Arpit Gupta, Rob Harrison, Marco Canini, Nick Feamster, Jennifer Rexford, and Walter Willinger. 2018. Sonata: Query-Driven Streaming Network Telemetry. In *Proc. of ACM SIGCOMM*.

9. Sangjin Han, Keon Jang, Aurojit Panda, Shoumik Palkar, Dongsu Han, and Sylvia Ratnasamy. 2015. SoftNIC: A Software NIC to Augment Hardware. Technical Report.

10. Thomas Holterbach, Edgar Costa Molero, Maria Apostolaki, Alberto Dainotti, Stefano Vissicchio, and Laurent Vanbever. 2019. Blink: Fast Connectivity Recovery Entirely in the Data Plane. In *Proc. of USENIX NSDI*.

11. Nan Hua, Bill Lin, Jun (Jim) Xu, and Haiquan (Chuck) Zhao. 2008. BRICK: A Novel Exact Active Statistics Counter Architecture. In *Proc. of ACM/IEEE ANCS*.

12. Qi Huang, Ken Birman, Robbert van Renesse, Wyatt Lloyd, Sanjeev Kumar, and Harry C. Li. 2013. An Analysis of Facebook Photo Caching. In *Proc. of ACM SOSP*.

13. Qun Huang, Xin Jin, Patrick P. C. Lee, Runhui Li, Lu Tang, Yi-Chao Chen, and Gong Zhang. 2017. SketchVisor: Robust Network Measurement for Software Packet Processing. In *Proc. of ACM SIGCOMM*.

14. Qun Huang, Patrick PC Lee, and Yungang Bao. 2018. SketchLearn: Relieving User Burdens in Approximate Measurement with Automated Statistical Inference. In *Proc. of ACM SIGCOMM*.

15. Intel. 2012. Intel Advanced Vector Extensions. https://software.intel.com/en-us/isa-extensions/intel-avx

16. Intel. 2018. Intel VTune Amplifier. https://software.intel.com/en-us/vtune

17. T. S. Jayram, Andrew McGregor, S. Muthukrishnan, and Erik Vee. 2007. Estimating Statistical Aggregates on Probabilistic Data Streams. *Proc. of ACM PODS* (2007).

18. Xin Jin, Xiaozhou Li, Haoyu Zhang, Robert Soulé, Jeongkeun Lee, Nate Foster, Changhoon Kim, and Ion Stoica. 2017. NetCache: Balancing Key-Value Stores with Fast In-Network Caching. In *Proc. of ACM SOSP*.

19. Abdul Kabbani, Mohammad Alizadeh, Masato Yasuda, Rong Pan, and Balaji Prabhakar. 2010. AF-QCN: Approximate Fairness with Quantized Congestion Notification for Multi-tenanted Data Centers. In *Proc. of IEEE HOTI*.

20. Maurice George Kendall, Alan Stuart, and Keith Ord. 1987. *Kendall’s Advanced Theory of Statistics*. Oxford University Press, Inc.

21. Balachander Krishnamurthy, Subhabrata Sen, Yin Zhang, and Yan Chen. 2003. Sketch-based Change Detection: Methods, Evaluation, and Applications. In *Proc. of ACM IMC*.

22. Ashwin Lall, Vyas Sekar, Mitsunori Ogihara, Jun Xu, and Hui Zhang. 2006. Data Streaming Algorithms for Estimating Entropy of Network Traffic. In *Proc. of ACM SIGMETRICS/Performance*.

23. Junda Liu, Aurojit Panda, Ankit Singla, Brighten Godfrey, Michael Schapira, and Scott Shenker. 2013. Ensuring Connectivity via Data Plane Mechanisms. In *Proc. of USENIX NSDI*.

24. Zaoxing Liu, Zhihao Bai, Zhenming Liu, Xiaozhou Li, Changhoon Kim, Vladimir Braverman, Xin Jin, and Ion Stoica. 2019. DistCache: Provable Load Balancing for Large-Scale Storage Systems with Distributed Caching. In *Proc. of USENIX FAST*.

25. Zaoxing Liu, Antonis Manousis, Gregory Vorsanger, Vyas Sekar, and Vladimir Braverman. 2016. One Sketch to Rule Them All: Rethinking Network Flow Monitoring with UnivMon. In *Proc. of ACM SIGCOMM*.

26. Zaoxing Liu, Greg Vorsanger, Vladimir Braverman, and Vyas Sekar. 2015. Enabling a "RISC" Approach for Software-Defined Monitoring Using Universal Streaming. In *Proc. of ACM HotNets*.

27. Yi Lu, Andrea Montanari, Balaji Prabhakar, Sarang Dharmapurikar, and Abdul Kabbani. 2008. Counter Braids: A Novel Counter Architecture for Per-Flow Measurement. In *Proc. of ACM SIGMETRICS*.

28. MACCDC. 2012. Capture Traces from Mid-Atlantic CCDC. http://www.netresec.com/?page=MACCDC

29. Jiri Matousek and Jan Vondrak. 2008. The Probabilistic Method—Lecture Notes. http://www.cs.cmu.edu/~15850/handouts/matousek-vondrak-prob-ln.pdf

30. Andrew McGregor, A. Pavan, Srikanta Tirthapura, and David P. Woodruff. 2016. Space-Efficient Estimation of Statistics Over Sub-Sampled Streams. *Algorithmica* (2016).

31. Ahmed Metwally, Divyakant Agrawal, and Amr El Abbadi. 2005. Efficient Computation of Frequent and Top-k Elements in Data Streams. In *Proc. of ICDT*.

32. Microsoft. 2016. Hyper-V Virtual Switch Overview. https://technet.microsoft.com/en-us/library/hh831823.aspx

33. Jayadev Misra and David Gries. 1982. Finding Repeated Elements. Technical Report.

34. M. Mitzenmacher, T. Steinke, and J. Thaler. 2012. Hierarchical Heavy Hitters with the Space Saving Algorithm. In *Proc. of ALENEX*.

35. Srinivas Narayana, Anirudh Sivaraman, Vikram Nathan, Prateesh Goyal, Venkat Arun, Mohammad Alizadeh, Vimalkumar Jeyakumar, and Changhoon Kim. 2017. Language-Directed Hardware Design for Network Performance Monitoring. In *Proc. of ACM SIGCOMM*.

36. George Nychis, Vyas Sekar, David G. Andersen, Hyong Kim, and Hui Zhang. 2008. An Empirical Evaluation of Entropy-based Traffic Anomaly Detection. In *Proc. of ACM IMC*.

37. Ben Pfaff, Justin Pettit, Teemu Koponen, Ethan Jackson, Andy Zhou, Jarno Rajahalme, Jesse Gross, Alex Wang, Joe Stringer, Pravin Shelar, Keith Amidon, and Martin Casado. 2015. The Design and Implementation of Open vSwitch. In *Proc. of USENIX NSDI*.

38. Robert Schweller, Ashish Gupta, Elliot Parsons, and Yan Chen. 2004. Reversible Sketches for Efficient and Accurate Change Detection over Network Data Streams. In *Proc. of ACM IMC*.

39. Vibhaalakshmi Sivaraman, Srinivas Narayana, Ori Rottenstreich, S. Muthukrishnan, and Jennifer Rexford. 2017. Heavy-Hitter Detection Entirely in the Data Plane. In *Proc. of ACM SOSR*.

40. Eric V. Slud. 1977. Distribution Inequalities for the Binomial Law. *The Annals of Probability* (1977).

41. Mea Wang, Baochun Li, and Zongpeng Li. 2004. sFlow: Towards Resource-Efficient and Agile Service Federation in Service Overlay Networks. In *Proc. of IEEE ICDCS*.

42. Li Yang, Wu Hao, Pan Tian, Dai Huichen, Lu Jianyuan, and Liu Bin. 2016. CASE: Cache-assisted Stretchable Estimator for High Speed Per-flow Measurement. In *Proc. of IEEE INFOCOM*.

43. Tong Yang, Jie Jiang, Peng Liu, Qun Huang, Junzhi Gong, Yang Zhou, Rui Miao, Xiaoming Li, and Steve Uhlig. 2018. Elastic Sketch: Adaptive and Fast Network-wide Measurements. In *Proc. of ACM SIGCOMM*.

44. Lei Ying, R. Srikant, and Xiaohan Kang. 2015. The Power of Slightly More than One Sample in Randomized Load Balancing. In *Proc. of IEEE INFOCOM*.

45. Da Yu, Yibo Zhu, Behnaz Arzani, Rodrigo Fonseca, Tianrong Zhang, Karl Deng, and Lihua Yuan. 2019. dShark: A General, Easy to Program and Scalable Framework for Analyzing In-network Packet Traces. In *Proc. of USENIX NSDI*.

46. Minlan Yu, Lavanya Jose, and Rui Miao. 2013. Software Defined Traffic Measurement with OpenSketch. In *Proc. of USENIX NSDI*.

### Analysis of AlwaysCorrect NitroSketch

We now formally analyze the accuracy guarantees of AlwaysCorrect NitroSketch (Algorithm 1). We start with Lemma 6, which shows that once AlwaysCorrect NitroSketch converges (see Line 14), the \( L_2 \) norm is large enough to justify sampling with probability \( p_{\min} \). We analyze the worst-case scenario where, once we start sampling, we always use the smallest probability, denoted as \( p \equiv p_{\min} \).

**Lemma 6.** When AlwaysCorrect NitroSketch starts sampling:
\[ \Pr\left(L_2 \geq \frac{11}{\epsilon^2 p}\right) \geq 1 - \delta. \]

**Proof.** Since \( L_2 \) grows monotonically with the number of packets, it suffices to show that the condition in Line 14 implies the lower bound on the \( L_2 \) value. Specifically, we assume that:
\[ \text{median}_i \left( \sum_{y=1}^{w} w_{i,y} \right) > \frac{1}{2} \left(1 + \epsilon \sqrt{p}\right) \frac{\epsilon}{\sqrt{p}}. \]

It is known that given a Count Sketch configured for an \((\epsilon', \delta)\)-guarantee, it is possible to compute a \((1 + \epsilon')\)-approximation of the \( L_2 \) norm with probability \( 1 - \delta \) [5]. As our sketch is identical to a Count Sketch (with \(\epsilon' = \epsilon \sqrt{p}\)) during the processing of \( S \), we have:
\[ \Pr \left( \left| \left( \text{median}_i \left( \sum_{y=1}^{w} w_{i,y} \right) \right)^2 - L_2^2 \right| > \epsilon' L_2^2 \right) \leq \delta. \]

Combining this with the above assumption, the lemma follows.
\[ \blacksquare \]

In AlwaysCorrect NitroSketch, there are \( d = O(\log \delta^{-1}) \) rows, each having \( w = \frac{11}{\epsilon^2 p} \) counters. As long as the sketch has not converged (see Line 14), it is indistinguishable from a Count Sketch [17] with a guarantee of \(\epsilon' \equiv \epsilon \sqrt{p}\). Thus, given a flow \( x \), if `converged` = 0, then Algorithm 1 guarantees:
\[ \Pr \left( \left| \hat{f}_x - f_x \right| \leq \epsilon' L_2 \right) \leq \delta. \]

Since \(\epsilon' = \epsilon \sqrt{p} \leq \epsilon\), the algorithm provides the desired accuracy guarantee prior to convergence. Henceforth, we assume that the sketch has converged and show that the error is still at most \(\epsilon L_2\).

Let \( u \) be the index of the packet that, during its processing, the condition in Line 14 was satisfied, and the sketch converged. That is, packets \( a_1, \ldots, a_u \) were processed using `UPDATE(1)`, while \( a_{u+1}, \ldots, a_m \) followed `UPDATE(p)`. Further, we denote by \( S \equiv a_1, \ldots, a_u \) the substream of the first \( u \) packets, by \( \bar{S} \equiv a_{u+1}, \ldots, a_m \) the remaining substream, and for a flow \( x \), we use \( f_x \) and \( \bar{f}_x \) to denote its frequency in \( S \) and \( \bar{S} \), respectively. Note that the overall frequency of \( x \) is \( f_x = f_x + \bar{f}_x \). Additionally, we denote the number of times a packet that belongs to a flow \( x \) in \( \bar{S} \) was sampled by the \( i \)-th row as \( \bar{f}_{x,i} \).

Similarly to the analysis of Theorem 2, we first analyze the guarantee provided by a single row. Fix some flow \( x \in U \) and a row \( i \in \{1, \ldots, d\} \); the counter associated with \( x \) on this row is \( C_{i,h_i(x)} \). Observe that we can express the value of the \( i \)-th estimator as:
\[ C_{i,h_i(x)} \cdot g_i(x) = \sum_{y: h_i(y) = h_i(x)} f_y \cdot g_i(x) \cdot g_i(y) + \frac{1}{p} \sum_{y: h_i(y) = h_i(x)} \bar{f}_{y,i} \cdot g_i(x) \cdot g_i(y). \]

That is, every flow \( y \) that is mapped to the same counter as \( x \) (i.e., \( h_i(y) = h_i(x) \)) changes the estimation by \( f_y \cdot g_i(x) \cdot g_i(y) + \frac{1}{p} \bar{f}_{y,i} \cdot g_i(x) \cdot g_i(y) \) — every packet of \( y \) in \( S \) surely adds \( g_i(y) \) to the counter (Algorithm 1, Line 13), while every sampled packet in \( \bar{S} \) modifies the counter by \( \frac{1}{p} g_i(y) \) (Algorithm 1, Line 20).

Next, we denote \( A \equiv \sum_{y: h_i(y) = h_i(x)} f_y \cdot g_i(x) \cdot g_i(y) \) and \( B \equiv \frac{1}{p} \sum_{y: h_i(y) = h_i(x)} \bar{f}_{y,i} \cdot g_i(x) \cdot g_i(y) \) (i.e., \( C_{i,h_i(x)} \cdot g_i(x) = A + B \)). We note that \( A \) and \( B \) are independent and that \( \mathbb{E}[C_{i,h_i(x)} \cdot g_i(x)] = \mathbb{E}[A] + \mathbb{E}[B] = f_x + \bar{f}_x = f_x \). That is, the resulting estimator for row \( i \) is unbiased.

We now turn to bound the variance of the estimator by bounding \( \text{Var}[A - f_x] \) and \( \text{Var}[B - \frac{1}{p} \bar{f}_{x,i}] \). First, since \( \Pr[h_i(x) = h_i(y)] = \frac{1}{w} \) for \( x \neq y \), observe that:
\[ \text{Var}[A - f_x] = \text{Var} \left( \sum_{y: h_i(y) = h_i(x)} f_y \cdot g_i(x) \cdot g_i(y) - f_x \right) \leq \frac{1}{w} \sum_{y \in U} f_y^2. \]

That is, the probability that each row estimates the frequency of \( x \) with an error no larger than \( \epsilon L_2 \) is at least \( \frac{5}{8} \). Finally, the standard use of Chernoff's inequality shows that \( d = O(\log \delta^{-1}) \) (independent) rows are required for their median to amplify the probability to \( 1 - \delta \). Taking the union bound over the events of sampling too early and having an error in the row’s median, we have an error probability no larger than \( 2\delta \). This concludes the proof of Theorem 5.

### Comparison to Uniform Sampling

Our sketch updates each row, for every packet, with probability \( p \). An alternative approach, uniform sampling, would be updating all rows with probability \( \frac{1}{p} \). We note that the two approaches make the same number of hash computations in expectation. Here, we claim that our approach is superior to that of uniform sampling.

Intuitively, our sketch uses the fact that for each row \( i \), with probability \( \frac{3}{4} \), we have \( L_2,i = O(\sqrt{p} \log \delta^{-1}) \). This reduction in the second norm allows one to increase the row width by a factor of \( p \) (compared to Count Sketch) to make up for the extra error introduced by sampling.