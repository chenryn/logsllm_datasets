ments or distinguish the dummy segments. This is expected
due to three reasons: (1) the segments are very short; (2)
the dummy segments are generated using a state-of-the-art
language model; and (3) we observed that most of the tran-
scription errors happen in the ﬁrst and last words of a segment
due to breaking the context. These errors add to the difﬁculty
of re-ordering. Moreover, if the user partitions S among mul-
tiple CSP’s (Sec.4.5.3), then consecutive segments would not
go to the same CSP with high probability. This setting would
increase Prεεch’s protection against re-ordering attacks.
7.4 Q4: Flexibility of the Control Knobs
7.4.1 Utility-Privacy Trade-off
In this section, we empirically evaluate the controls knobs
that provide a utility-privacy trade-off.
USENIX Association
29th USENIX Security Symposium    2717
7.4.2 Usability-Privacy Trade-off
In our setting, usability can be measured along three dimen-
sions: latency, monetary cost, and implementation overhead.
However, we would like to stress that Prεεch is not designed
for real-time speech transcription. Hence, latency is not a pri-
mary concern for Prεεch. Nevertheless, we include it in the
following discussion for the sake of completeness.
Latency Evaluations: Note that all the operations of Prεεch
are performed on speech segments. Hence, the latency is
linear in the number of segments. We evaluate the end-to-end
system latency per segment (with length ∼ 6s) for the OSP,
the CSP, and Prεεch; the latency values are 2.17s, 1.70s,
and 14.90s, respectively. We observe that the overhead of
Prεεch is mostly attributed to the many-to-one VC (11s per
segment on average). When voice cloning (or one-to-one VC)
is applied instead, Prεεch’s end-to-end per segment latency
reduces to 3.90s (or 11.47s) at the expense of a privacy loss
as discussed in Sec.7.4.1.
Vocabulary Size: Considering a larger V (Sec. 4.5.3) in-
creases the scope of the DP guarantee. For example, adding
external words provides protection against statistical analysis
like text classiﬁcation (Sec.7.3). However, larger V results in
increased amount of dummy segments and hence, increased
monetary cost (Table 3). For example, extending V by ∼ 1000
out-of-domain words for the Carpenter dataset incurred a total
cost of $25 at d = 15.
Distance Parameter d: As explained in Sec. 4.5.2, larger
the value of d, greater is the scope of privacy. However, the
amount of required noise increases by d. For example, for the
dataset VCTK p266, increasing d from 2 to 15 increases the
cost by roughly $5 (Table 3).
7.4.3 Utility-Usability Trade-off
The following control knobs provide a venue for customizing
the utility-usability trade-off.
Number of CSPs: As discussed in Sec. 4.5.2, using multiple
CSPs reduces the amount of dummy segments (and hence,
the monetary cost) in Prεεch. However, it comes at the price
of utility; the transcription accuracy of the different available
CSPs varies. For example, from Table 1, we observe that
AWS has a higher WER than Google. Thus, using multiple
CSPs may result in a lower mean utility.
One-to-One VC: As discussed above, one-to-one VC tech-
nique has lower WER than many-to-one VC technique (Table
2). However, it requires access to representative samples of
the source speaker voice for parallel training thereby limiting
scalability for previously unseen speakers (Sec. 4.6).
8 Related Work
In this section, we provide a summary of the related work.
Privacy by Design: One class of approaches redesigns the
speech recognition pipeline to be private by design. For exam-
ple, Srivastava et al. proposes an encoder-decoder architecture
for speech recognition [42]. Other approaches address the
problem in an SMC setting by representing the basic opera-
tions of a traditional ASR system using cryptographic primi-
tives [32]. VoiceGuard is a system that performs ASR in the
trusted execution environment of a processor [8]. However,
these approaches require redesigning the existing systems.
Speech Sanitization: Recent approaches have considered
the problem from a similar perspective as ours. They sanitize
the speech before sending it to the CSP. One such approach
randomly perturbs the MFCC, pitch, tempo, and timing fea-
tures of a speech before applying speech recognition [45].
Others sanitize the speaker’s voice using vocal tract length
normalization (VTLN) [33, 34]. A recent approach modiﬁes
the features relevant to emotions from an audio signal, makes
them less sensitive through a GAN [4]. Last, adversarial at-
tacks against speaker identiﬁcation systems can provide some
privacy properties. These approaches apply minimal pertur-
bations to the speech ﬁle to mislead a speaker identiﬁcation
network [9, 22].
These approaches are different from ours in two ways.
First, they do not consider the textual content of the speech
signal. The only exception is the approach by Qian et al. [34],
which addresses the problem of private publication of speech
datasets. This approach requires a text transcript with the
audio ﬁle, which is not the case for the speech transcription
task. In addressing the textual privacy of a speech signal,
Prεεch adds indistinguishable noise to the speech ﬁle. The
proposed techniques fail to provide this property. Second,
the approaches above only consider voice privacy against a
limited set of features, such as speaker identiﬁcation or emo-
tion recognition. Prεεch applies many-to-one VC to provide
perfect voice privacy.
9 Conclusion
In this paper, we have proposed Prεεch, an end-to-end system
for speech transcription that (1) protects the users’ privacy
along the acoustic and textual dimensions at (2) an improved
performance relative to ofﬂine ASR, (3) while providing cus-
tomizable utility, usability, and privacy trade-offs.
Acknowledgment
The work reported in this paper was supported in part by the
NSF under grants 1661036, 1838733, 1942014, and 1931364.
We also acknowledge Google for providing us with Google
Cloud Platform credits and NVIDIA Corporation with the
donation of the Quadro P6000 GPU used for this research.
We would like to thank the anonymous reviewers for their
useful comments and Micah Sherr for shepherding this paper.
2718    29th USENIX Security Symposium
USENIX Association
References
[1] An
all-neural
on-device
speech
recognizer.
https://ai.googleblog.com/2019/03/
an-all-neural-on-device-speech.html.
[2] Prεεch demo. https://bit.ly/2Vytbx7.
[3] S. Ahmed, A. R. Chowdhury, K. Fawaz, and P. Ra-
manathan. Preech: A system for privacy-preserving
speech transcription. arXiv preprint arXiv:1909.04198,
2019.
[4] R. Alouﬁ, H. Haddadi, and D. Boyle. Emotionless:
Privacy-preserving speech analysis for voice assistants.
arXiv preprint arXiv:1908.03632, 2019.
[5] D. Amodei, S. Ananthanarayanan, R. Anubhai, J. Bai,
E. Battenberg, C. Case, J. Casper, B. Catanzaro,
Q. Cheng, G. Chen, et al. Deep speech 2: End-to-end
speech recognition in english and mandarin. In Interna-
tional conference on machine learning, pages 173–182,
2016.
[6] J. Bater, X. He, W. Ehrich, A. Machanavajjhala, and
J. Rogers. Shrinkwrap: Differentially-private query
processing in private data federations. arXiv preprint
arXiv:1810.01816, 2018.
[7] P. Boersma. Accurate short-term analysis of the fun-
damental frequency and the harmonics-to-noise ratio
Institute of Phonetic Sciences -
of a sampled sound.
University of Amsterdam, 17:97–110, 1993.
[8] F. Brasser, T. Frassetto, K. Riedhammer, A.-R. Sadeghi,
T. Schneider, and C. Weinert. Voiceguard: Secure and
private speech processing. In Interspeech, pages 1303–
1307, 2018.
[9] W. Cai, A. Doshi, and R. Valle. Attacking speaker recog-
nition with deep generative models. arXiv preprint
arXiv:1801.02384, 2018.
[10] K. Chatzikokolakis, M. E. Andrés, N. E. Bordenabe, and
C. Palamidessi. Broadening the scope of differential pri-
vacy using metrics. In E. De Cristofaro and M. Wright,
editors, Privacy Enhancing Technologies, pages 82–102,
Berlin, Heidelberg, 2013. Springer Berlin Heidelberg.
[11] R. Chen, N. Mohammed, B. C. Fung, B. C. Desai, and
L. Xiong. Publishing set-valued data via differential pri-
vacy. Proceedings of the VLDB Endowment, 4(11):1087–
1098, 2011.
[12] M. Davino. Assessing privacy risk in outsourcing. As-
sessing Privacy Risk in Outsourcing/AHIMA, American
Health Information Management Association, 2004.
[13] C. Dwork, A. Roth, et al. The algorithmic foundations
of differential privacy. Foundations and Trends® in
Theoretical Computer Science, 9(3–4):211–407, 2014.
[14] O. Etzioni, M. Cafarella, D. Downey, A.-M. Popescu,
T. Shaked, S. Soderland, D. S. Weld, and A. Yates. Un-
supervised named-entity extraction from the web: An
experimental study. Artiﬁcial intelligence, 165(1):91–
134, 2005.
[15] A. Friedman and A. Schuster. Data mining with differ-
ential privacy. In Proceedings of the 16th ACM SIGKDD
international conference on Knowledge discovery and
data mining, pages 493–502. ACM, 2010.
[16] J. S. Garofolo, L. F. Lamel, W. M. Fisher, J. G. Fis-
cus, and D. S. Pallett. Darpa timit acoustic-phonetic
continous speech corpus cd-rom. nist speech disc 1-1.1.
NASA STI/Recon technical report n, 93, 1993.
[17] A. Graves, A.-r. Mohamed, and G. Hinton. Speech
recognition with deep recurrent neural networks.
In
2013 IEEE international conference on acoustics,
speech and signal processing, pages 6645–6649. IEEE,
2013.
[18] A. Hannun, C. Case, J. Casper, B. Catanzaro, G. Di-
amos, E. Elsen, R. Prenger, S. Satheesh, S. Sengupta,
A. Coates, et al. Deep speech: Scaling up end-to-end
speech recognition. arXiv preprint arXiv:1412.5567,
2014.
[19] T. Hofmann. Probabilistic latent semantic analysis.
arXiv preprint arXiv:1301.6705, 2013.
[20] Y. Jia, Y. Zhang, R. Weiss, Q. Wang, J. Shen, F. Ren,
z. Chen, P. Nguyen, R. Pang, I. Lopez Moreno, and
Y. Wu. Transfer learning from speaker veriﬁcation to
multispeaker text-to-speech synthesis. In Advances in
Neural Information Processing Systems 31, pages 4480–
4490. Curran Associates, Inc., 2018.
[21] K. Kobayashi and T. Toda. sprocket: Open-source voice
conversion software. In Odyssey, pages 203–210, 2018.
[22] F. Kreuk, Y. Adi, M. Cisse, and J. Keshet. Fooling end-
to-end speaker veriﬁcation with adversarial examples.
ICASSP 2018, Apr 2018.
[23] J. Lindberg and M. Blomberg. Vulnerability in speaker
veriﬁcation-a study of technical impostor techniques. In
Sixth European Conference on Speech Communication
and Technology, 1999.
[24] J. Lorenzo-Trueba, J. Yamagishi, T. Toda, D. Saito,
F. Villavicencio, T. Kinnunen, and Z. Ling. The voice
conversion challenge 2018: Promoting development
of parallel and nonparallel methods. arXiv preprint
arXiv:1804.04262, 2018.
USENIX Association
29th USENIX Security Symposium    2719
[25] S. E. McGregor, P. Charters, T. Holliday, and F. Roesner.
Investigating the computer security practices and needs
of journalists. In 24th {USENIX} Security Symposium
({USENIX} Security 15), pages 399–414, 2015.
[26] H. Muckenhirn, M. M. Doss, and S. Marcell. Towards
directly modeling raw speech signal for speaker veriﬁca-
tion using cnns. In 2018 IEEE International Conference
on Acoustics, Speech and Signal Processing (ICASSP),
pages 4884–4888. IEEE, 2018.
[27] K. S. R. Murty, B. Yegnanarayana, and M. A. Joseph.
Characterization of glottal activity from speech signals.
IEEE signal processing letters, 16(6):469–472, 2009.
[28] G. J. Mysore.
Can we automatically transform
speech recorded on common consumer devices in real-
world environments into professional production quality
speech?—a dataset, insights, and challenges. IEEE Sig-
nal Processing Letters, 22(8):1006–1010, 2014.
[29] A. Nautsch, C. Jasserand, E. Kindt, M. Todisco, I. Tran-
coso, and N. Evans. The gdpr & speech data: Re-
ﬂections of legal and technology communities, ﬁrst
steps towards a common understanding. arXiv preprint
arXiv:1907.03458, 2019.
[30] S. Nutanong, C. Yu, R. Sarwar, P. Xu, and D. Chow.
A scalable framework for stylometric analysis query
processing. In ICDM 2016, pages 1125–1130. IEEE,
2016.
[31] V. Panayotov, G. Chen, D. Povey, and S. Khudanpur.
Librispeech: an ASR corpus based on public domain
audio books. In ICASSP 2015, pages 5206–5210. IEEE,
2015.
[36] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and
I. Sutskever. Language models are unsupervised multi-
task learners. OpenAI Blog, 1(8):9, 2019.
[37] D. Ramage, D. Hall, R. Nallapati, and C. D. Manning.
Labeled lda: A supervised topic model for credit attribu-
tion in multi-labeled corpora. In EMNLP 2009, pages
248–256, Stroudsburg, PA, USA, 2009. Association for
Computational Linguistics.
[38] A. Rousseau, P. Deléglise, and Y. Esteve. Ted-lium:
an automatic speech recognition dedicated corpus. In
LREC, pages 125–129, 2012.
[39] S. Safavi, M. Russell, and P. Janˇcoviˇc. Automatic
speaker, age-group and gender identiﬁcation from chil-
dren’s speech. Computer Speech & Language, 50:141–
156, 2018.
[40] B. Schuller and A. Batliner. Computational paralin-
guistics: emotion, affect and personality in speech and
language processing. John Wiley & Sons, 2013.
[41] B. Schuller, S. Steidl, A. Batliner, F. Burkhardt, L. Dev-
illers, C. MüLler, and S. Narayanan. Paralinguistics in
speech and language—state-of-the-art and the challenge.
Computer Speech & Language, 27(1):4–39, 2013.
[42] B. M. L. Srivastava, A. Bellet, M. Tommasi, and E. Vin-
cent. Privacy-Preserving Adversarial Representation
In INTER-
Learning in ASR: Reality or Illusion?
SPEECH 2019, Graz, Austria, Sept. 2019.
[43] M. Steyvers and T. Grifﬁths. Probabilistic topic models.
Handbook of latent semantic analysis, 427(7):424–440,
2007.
[32] M. A. Pathak, B. Raj, S. D. Rane, and P. Smaragdis.
Privacy-preserving speech processing: cryptographic
and string-matching frameworks show promise. IEEE
signal processing magazine, 30(2):62–74, 2013.
[44] L. Sun, K. Li, H. Wang, S. Kang, and H. Meng. Pho-
netic posteriorgrams for many-to-one voice conversion
without parallel data training. In ICME 2016, pages 1–6.
IEEE, 2016.
[33] J. Qian, H. Du, J. Hou, L. Chen, T. Jung, X.-Y. Li,
Y. Wang, and Y. Deng. Voicemask: Anonymize and
sanitize voice input on mobile devices. arXiv preprint
arXiv:1711.11460, 2017.
[34] J. Qian, F. Han, J. Hou, C. Zhang, Y. Wang, and X.-Y. Li.
Towards privacy-preserving speech data publishing. In
IEEE INFOCOM 2018-IEEE Conference on Computer
Communications, pages 1079–1087. IEEE, 2018.
[35] A. Radford, K. Narasimhan, T. Salimans, and
under-
I. Sutskever.
URL
standing
https://s3-us-west-2.
com/openai-
assets/researchcovers/languageunsupervised/language
understanding paper. pdf, 2018.
by generative
pre-training.
Improving
language
amazonaws.
[45] T. Vaidya and M. Sherr. You talk too much: Limit-
ing privacy exposure via voice input. In International
Workshop on Privacy Engineering (IWPE), 2019.
[46] C. Veaux, J. Yamagishi, K. MacDonald, et al. Cstr
vctk corpus: English multi-speaker corpus for cstr voice
cloning toolkit. University of Edinburgh. The Centre for
Speech Technology Research (CSTR), 2017.
[47] Z. Wu, N. Evans, T. Kinnunen, J. Yamagishi, F. Alegre,
and H. Li. Spooﬁng and countermeasures for speaker
veriﬁcation. Speech Commun., 66(C):130–153, Feb.
2015.
2720    29th USENIX Security Symposium
USENIX Association