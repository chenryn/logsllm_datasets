:: ∃r0 > 0, ∃r1 > r0 : Psu (Π0, r0, r0)
∧ Pk (Π0, r0+1, r0+1)
∧ Pk (Π0, r1, r1)
Predicate Psu (Π0, r1, r2) ensures that rounds from r1
to r2 are so called “space uniform” for the processes in
Π0. Predicate Pk (Π0, r1, r2) ensures a weaker property (k
stands for kernel). Predicate P 2
otr (Π0) ensures two consec-
utive rounds such that the ﬁrst satisﬁes Psu (Π0, −, −) and
the second Pk (Π0, −, −). Predicate P 1/1
otr (Π0) ensures the
same property for two rounds that do not need to be consec-
utive. We clearly have:
(∃Π0, s.t. |Π0| > 2n/3 : P 2
(∃Π0, s.t. |Π0| > 2n/3 : P 1/1
otr (Π0)) ⇒ P restr
otr (Π0)) ⇒ P restr
otr
otr
.
We give below algorithms for Psu (−, −, −) and
Pk (−, −, −), for both deﬁnitions of good periods. We also
analyze the timing property of the algorithms under the fol-
lowing two scenarios:
1. Assume that a good period starts at an arbitrary time
tG resp. τG = tG/Φ−. We compute, in the worst
case, the minimal length of the good period needed to
implement the communication predicates. We call this
value minimal length of a good period.
2. We do the same, assuming that a good period starts
from the beginning, i.e., τG = 0. We call this value
minimal length of an initial good period.
Intuitively, scenario 2 allows us to compute the time to
solve consensus in the fault-free case, which is often called
a “nice” run. Scenario 1 allows us a timing analysis of con-
sensus in “not nice” runs.
4.2.1. Ensuring P restr
otr
in a “π0-down” good period
Let us consider a “π0-down” good period that is “long
enough”, with π0 arbitrary. Algorithm 2 implements
Psu (π0, −, −). The function Srp
p at line 7 returns the mes-
sage to be sent; the send occurs at line 8. Variable ip
(line 9, 11) counts the number of receive steps. If p ex-
ecutes x steps, at least x and at most xφ (normalized) time
has elapsed (see Section 4.1). Process p executes at most
⌈2δ + n + 2φ⌉ receive steps, see line 12 (message reception
takes place at line 14; non-empty messages are added to
the set msgsRcvp, see line 16). Process p executes receive
steps (1) until ⌈2δ + n + 2φ⌉ receive steps have been exe-
cuted, or (2) if p receives a message from a round r′ larger
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:50:59 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007Algorithm 2 Ensuring Psu (π0, −, −) with a ‘π0-down”
good period
1: Reception policy: Highest round number ﬁrst
2: msgsRcv p ← ∅
3: rp ← 1
4: next rp ← 1
5: sp ← initp
6: while true do
7: msg ← Srp
8:
p (sp)
{set of messages received}
{round number}
{next round number}
{state of the consensus algorithm}
send hmsg, rpi to all
ip ← 0
while next rp = rp do
ip ← ip + 1
if ip ≥ 2δ + n + 2φ then
next rp ← rp + 1;
receive a message
if message is hmsg, r′i from q then
msgsRcv p ← msgsRcv p ∪ {hmsg, r′, qi}
if r′ > rp then
9:
10:
11:
12:
13:
14:
15:
16:
17:
next rp ← r′
18:
19: R ← {hmsg′, q′i | hmsg′, rp, q′i ∈ msgsRcv p}
20:
sp ← T rp
forall r′ in [rp+1, next rp−1] do sp ← T r′
rp ← next rp
p (R, sp)
21:
22:
p (∅, sp)
than rp. In both cases the state transition function T rp
is
p
executed with the set R of messages received in round rp
(line 20). Then the state transition function T rp
p is executed
for all rounds rp + 1 to next rp − 1 with an empty set of
messages.8
In order to cope with recoveries after crashes, variables
rp and sp are stored on stable storage. In case of a recovery,
the algorithm starts on line 6, with msgsRcvp and next rp
reinitialized. Reading variables on stable storage is inefﬁ-
cient. The implementation can be made more efﬁcient by
keeping a copy of the variables in main memory: a read op-
eration reads the in memory copy, a write operation updates
the in memory and the stable storage copies. Upon recov-
ery, the in memory copy is reset with the value of the stable
copy.9
Algorithm 2 is not optimized regarding space, i.e., the set
msgsRcv p grows forever. Obviously, messages for round
smaller than rp can safely be discarded. To keep the pre-
sentation short, we did not include this simple optimization.
It should be noted that Algorithm 2 relies exclusively on
messages sent by the upper algorithmic layer: Algorithm 2
does not send any additional message.
We prove Algorithm 2 in two steps. First we prove that
there exists r > 0 such that, for any x > 0, Algorithm 2 en-
sures Psu (π0, r, r+x−1), assuming a “long enough” good
8This is required only if T
rp
p (∅, sp) 6= sp. Calling the sending func-
tion S
rp
p is not needed, since the function does not change the state sp.
9We could express this formally as a variant of Algorithm 2, but the
space constraints prevent us from doing this.
period. Then we compute the minimal duration of a good
period to ensure P 2
otr (π0), and the minimal duration of two
good periods to ensure P 1/1
otr (π0). Note that by the deﬁni-
tion of a π0-down good period, all processes in π0 are down
in a good period, and no messages from these processes are
in transit in the good period. In other words, processes in
π0 can simply be ignored.
Theorem 3. With Algorithm 2, the minimal length of a good
period to achieve Psu (π0, ρ0, ρ0 +x−1) is:
(x + 1)(2δ + n + 2φ + 1)φ + δ + φ.
The proof, also for all other theorems of this paper,
can be found in [16]. The following Corollary follows di-
rectly from Theorem 3 with x=1 and x=2, and the fact that
Psu (−, −, −) ⇒ Pk (−, −, −):
Corollary 4. For implementing P 2
we need one “π0-down” good period of length
otr (π0) with Algorithm 2,
(6δ + 3n + 3 + 6φ)φ + δ + φ.
For implementing P 1/1
“π0-down” good periods of length
otr (π0) with Algorithm 2, we need two
(4δ + 2n + 2 + 4φ)φ + δ + φ.
Corollary 4 shows an interesting trade-off in terms of the
length of a good period. The next theorem gives us the min-
imal length of an initial good period:
Theorem 5. With Algorithm 2, the minimal length of an
initial good period to achieve Psu (π0, 1, x) is:
x(2δ + n + 2φ + 1)φ.
As already pointed out, Theorem 5 is related to so-called
“nice” runs, while Theorem 3 is related to “not nice” runs.
This second case has not been addressed in the literature
with a time analysis as done here (see Section 5). The re-
sults show a factor of approximately 3/2 between the two
cases for the relevant value x = 2.
4.2.2. Ensuring P restr
otr
in a “π0-arbitrary” good period
In this section we consider a π0-arbitrary good period.
Compared with the previous section, the problem is more
complex. We proceed in two steps.
First we show
how to implement the predicate Pk (π0, −, −). Second,
we show how to obtain the predicate Psu (π0, −, −) from
Pk (π0, −, −). Note that we introduce here a parameter f
deﬁned such that |π0| = n − f . The implementation of
Pk (π0, −, −) requires f  rp then
next rp ← r′
if received f +1 messages hINIT, rp +1, −i from distinct
processes then
next rp ← max{rp + 1, next rp}
i ← i + 1
if i ≥ 2δ + n + nφ + φ then
send hINIT, rp + 1, msgi to all
20:
21: R ← {hmsg′, q′i | hmsg′, rp, q′i ∈ msgsRcv p}
22:
sp ← T rp
forall r′ in [rp+1, next rp−1] do sp ← T r′
rp ← next rp
p (R, sp)
23:
24:
p (∅, sp)
Theorem 6. With Algorithm 3 and f < n/2, the minimal
length of a good period to achieve Pk (π0, ρ0, ρ0 +x−1) is
c) Putting it all together
(x + 2)[τ0φ + δ + nφ + 2φ] + τ0φ =
= (x+2)[(2δ+nφ+φ)φ+δ+2nφ+2φ]+(2δ+n+nφ+φ)φ
Theorem 7. With Algorithm 3 and f < n/2, the minimal
length of an initial good period to implement Pk (π0, 1, x)
is:
(x − 1)[τ0φ + δ + nφ + 2φ] + τ0φ + φ.
b) Implementing Psu (π0, −, −) from Pk (π0, −, −)
We show now that f+1 rounds that satisfy Pk (π0, −, −),
with |π0| = n − f , allow us to construct one macro-round
that satisﬁes Psu (π0, −, −). The “translation” is given by
Algorithm 4, which is derived from a similar translation
in [6]. Let r1, . . . , rf +1 denote the sequence of the f + 1
rounds that form a macro-round R. In round r1, every pro-
cess p sends its message for macro-round R (line 7).
In
all subsequent rounds r2, . . . , rf +1 messages previously re-
In round rf +1 (i.e., r ≡ 0
ceived are relayed (line 7).
(mod f+1), see line 9), the set of messages of macro-round
R to be received by p are computed (lines 13 and 14).