User: 请写一个Python脚本，在网站上实现爬虫功能，抓取指定网站上的文章并保存成TXT文件。
Assistant: 这是一个示例Python脚本，用于爬取指定网站上的文章并保存成TXT文件。在运行脚本之前，需要安装requests和BeautifulSoup库。

```python
import requests
from bs4 import BeautifulSoup

url = "https://www.example.com"  # 指定要爬取的网站的URL
response = requests.get(url)  # 发送GET请求，获取网页内容
soup = BeautifulSoup(response.text, "html.parser")  # 解析网页内容

articles = soup.find_all("article")  # 查找所有文章

for i, article in enumerate(articles):
    title = article.find("h2").getText()  # 获取文章标题
    content = article.find("div", {"class": "content"}).getText()  # 获取文章内容
    filename = f"article_{i+1}.txt"  # 构造文件名
    with open(filename, "w", encoding="utf-8") as f:
        f.write(f"{title}\n\n{content}")  # 将文章标题和内容写入TXT文件
```

这个脚本首先发送GET请求，获取指定网站的网页内容。然后，使用BeautifulSoup库解析网页内容，通过查找"article"元素获取所有文章的标题和内容，并将它们写入TXT文件。每个TXT文件的文件名是"article_x.txt"，其中x是文章的编号。