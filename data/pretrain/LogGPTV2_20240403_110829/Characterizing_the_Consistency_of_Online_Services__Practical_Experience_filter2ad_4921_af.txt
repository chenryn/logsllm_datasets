46% of the tests are exhibiting this type of occurrence on Facebook Feed and
25% in Google+. This anomaly was detected in Facebook Group in a single test.
Figure 3.9a shows a long tail in the number of observations per test in Google+.
Although the anomaly is much more prevalent in Facebook Feed, the results
show that it is mostly detected a single time per agent per test. Figure 3.9c
indicates a mostly local phenomenon in both services.
Violations of the last session guarantee, Writes Follow Reads, are more
frequent in Facebook Feed. As depicted in Figure 3.6, this anomaly only occurs
40
3.4. RESULTS
(a) Google+
(b) Facebook Feed
(c) [Correlation of anomalies
Figure 3.9: Distribution of Monotonic Reads anomalies per test.
in Facebook Group twice. Figure 3.10 shows that, although this is a somewhat
frequent anomaly, it does not occur recurrently, with only a few observations
occurring per agent in each test for Facebook Feed. In contrast, for Google+
we verify the opposite. Figure 3.10c depicts the set of agents that observe the
lack of causality in each test. This indicates a mostly local phenomenon in both
services, particularly located in Oregon for Facebook Feed.
3.4.3 Divergence
We now check the presence of divergence events in the collected data. We start
by looking at content divergence. Figure 3.11 shows the percentage of tests
with divergence between the state observed by pairs of agents.
These results show that content divergence occurs very frequently in Google+
and in Facebook Feed, which indicates the likely use of weakly consistent repli-
cation that privileges performance over strong consistency. In particular, the
41
 0 1 2 3 4 5 6 7 812345>5Percentage of TestsNumber of Observed AnomaliesORIEJP 0 2 4 6 8 10 12 14 1612345>5Percentage of TestsNumber of Observed AnomaliesORIEJP 0 2 4 6 8 10 12 14 16 18 20ORIEJPOR/IEOR/JPJP/IEALLPercentage of TestsLocation of Agent(s)Google+Facebook FeedCHAPTER 3. MEASUREMENT STUDY
(a) Google+
(b) Facebook Feed
(c) Correlation of anomalies
Figure 3.10: Distribution of Writes Follow Reads anomalies per test.
percentage of tests that show content divergence in Google+ is up to 85%, be-
ing less pronounced between Oregon and Japan than between the remaining
pairs of agents. This might suggest that the Oregon and the Japan agents are
connecting to the same data center, whereas the other pairs of agents are not.
In the case of Facebook Feed, this occurrence is more uniform across all pairs
of agents, and the prevalence is also high (above 50% across all pairs of agents).
In the case of Facebook Group the prevalence is extremely low with a total of
15 occurrences of this anomaly, 9 of which happened across a sequence of tests,
where the Tokyo agent was unable to observe the operations of other agents.
This suggests the agent in Tokyo connects to a diﬀerent data center than the
other agents, hence these anomalies might be caused by a transient fault or
network partition.
In terms of the presence of order divergence anomalies, Figure 3.6 shows
that this phenomenon occurs in Google+ and in Facebook Feed, with a preva-
lence that is less pronounced than content divergence in Google+. Similarly to
42
 0 0.5 1 1.5 2 2.5 3 3.5 412345>5Percentage of TestsNumber of Observed AnomaliesORIEJP 0 1 2 3 4 512345>5Percentage of TestsNumber of Observed AnomaliesORIEJP 0 1 2 3 4 5 6 7 8ORIEJPOR/IEOR/JPJP/IEALLPercentage of TestsLocation of Agent(s)Google+Facebook Feed3.4. RESULTS
(a) Google+
(b) Facebook Feed
(c) Facebook Group
Figure 3.11: Percentage of tests with content divergence anomalies.
(a) Google+
(b) Facebook Feed
Figure 3.12: Percentage of tests with order divergence anomalies.
43
 0 20 40 60 80 100OR / JPOR / IE IE / JPPercentage of TestsLocation of Agent 0 20 40 60 80 100OR / JPOR / IE IE / JPPercentage of TestsLocation of Agent 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8OR / JPOR / IE IE / JPPercentage of TestsLocation of Agent 0 20 40 60 80 100OR / JPOR / IE IE / JPPercentage of TestsLocation of Agent 0 20 40 60 80 100OR / JPOR / IE JP / IEPercentage of TestsLocation of AgentCHAPTER 3. MEASUREMENT STUDY
(a) Google+
(b) Facebook Feed
(c) Facebook Group
Figure 3.13: Cumulative distribution of content divergence windows.
the previously reported results, in Figure 3.12, we observed that this anomaly
is much less frequent between Oregon and Japan (below 1%) than between the
remaining pairs of agents (around 14%). In Facebook Feed, the prevalence is
near 100% across all locations.
While the results for Facebook Feed may seem surprising, they are ex-
plained by the semantics of the service. This is because the reply to a read
contains a subset of the writes, which are not the most recent ones, but a selec-
tion of writes based on a criteria that depends on the expected interest of these
writes for the user issuing the read operation.
3.4.4 Quantitative metrics
Next, we analyze several quantitative measurements.
Figure 3.13 shows the CDF of the content divergence window. This distri-
bution is shown for each pair of agents and each service (only considering the
largest divergence window for each pair of agents in each test). The results
44
 0 10 20 30 40 50 60 70 80 90 100 0 2000 4000 6000 8000 10000 12000CDF (%)Divergence Window (ms)OR / JPOR / IEJP / IE 0 10 20 30 40 50 60 70 80 90 100 0 500 1000 1500 2000 2500 3000 3500 4000CDF (%)Divergence Window (ms)OR / JPOR / IEIE / JP 10 20 30 40 50 60 70 80 90 100 0 2000 4000 6000 8000 10000 12000CDF (%)Divergence Window (ms)OR / JPOR / IEJP / IE3.4. RESULTS
(a) Google+
(b) Facebook Feed
(c) Facebook Group
Figure 3.14: Tests where an anomaly of content divergence was observed, but
where the window is zero.
show a smooth distribution of this window, with Google+ taking substantially
longer than the remaining services for all agents to regain a consistent view
of the system state (on the order of seconds in Google+ versus hundreds of
milliseconds in Facebook Feed and most of the content divergence instances
observed in Facebook Group). Figure 3.13(a) shows that the Oregon and Japan
agents have a convergence time that is much faster than the remaining pairs
of agents, and that the other two pairs exhibit similar convergence times. This
suggests that writes issued from Oregon and Japan may be processed by the
same replica (i.e., data center).
The results depicted in Figure 3.13(b) show that content divergence occurs
in Facebook Feed across all agents and all pairs of agents, and takes approxi-
mately the same time to converge to a consistent view of the service state (on
the order of a few seconds). Again, the semantics of reads in this service may
explain these results.
Finally, Figure 3.13(c) depicts the results for Facebook Group, showing that
45
 0 5 10 15 20 25 30 35 40OR / JPOR / IEJP / IEPercentage of TestsLocation of Agents 0 5 10 15 20 25 30 35 40OR / JPOR / IEJP / IEPercentage of TestsLocation of Agents 0 5 10 15 20 25 30 35 40OR / JPOR / IEJP / IEPercentage of TestsLocation of AgentsCHAPTER 3. MEASUREMENT STUDY
(a) Google+
(b) Facebook Feed
Figure 3.15: Cumulative distribution of order divergence windows.
Figure 3.16: Tests where an anomaly of order divergence was observed in
Google+, but where the window is zero.
content divergence between the agent in Japan and the two remaining agents
takes longer to be resolved. This indicates that the agent in Japan may be
contacting a diﬀerent replica than the remaining agents.
We remind the reader that these CDFs excluded all values where the win-
dow was zero, as explained in Section 3.3. In Figure 3.14, we show the per-
centage of content divergence windows that were computed to have a value
of zero according to our methodology. Even though there is a relatively high
percentage of more than 30% in Google+ and Facebook Group, we note that
this may not be statistically relevant, since there were very few instances of
content divergence in this cases. In Facebook Feed the results show a relatively
high percentage between all agents that can be associated with the semantics
of the service.
The last set of measurements refer to the order divergence window. This
46
 0 20 40 60 80 100 0 5000 10000 15000 20000 25000CDF (%)Divergence Window (ms)OR / JPOR / IEJP / IE 0 10 20 30 40 50 60 70 80 90 100 0 500 1000 1500 2000 2500 3000 3500 4000CDF (%)Divergence Window (ms)OR / JPOR / IEJP / IE 0 5 10 15 20 25OR / JPOR / IEJP / IEPercentage of TestsLocation of Agents3.5. COMPARISON TO RELATED WORK
Figure 3.17: Tests where an anomaly of order divergence was observed in
Facebook Feed, but where convergence was not reached during the test.
anomaly was only observed in Google+ and Facebook Feed. For Google+, Fig-
ure 3.15a shows that a coherent order is more quickly re-established between
the Oregon and Japan agents than for the remaining pairs, which can take over
ten seconds to achieve this. The reason behind the steps in the curve is that,
after the ﬁrst 12–14 reads, which are more frequent, our agents perform reads
with a period of one second, to deal with the imposed limits of the services.
As such, the detection of the end of a window is done at the resolution of one
second, and in a synchronized way, as shown in the CDF. When looking at the
percentage of windows with zero values, reported in Figure 3.16, we note that
one of the cases has a high value of 25%, but corresponds to one out of four
occurrences. For the Facebook Feed service we observe that a coherent order is
established among the several pairs of agents faster.
These results exclude runs where convergence was not reached during the
test. In Figure 3.17, we show the fraction of tests where this occurred, between
Oregon and Tokyo was 81%, for Oregon and Ireland 94%, for Tokyo and Ireland
89%, again, this might be explained by the semantics of the service.
3.5 Comparison to Related Work
Here, we revisit related work in light of our contributions. In particular, we
now focus on a detailed contrast to the more closely related proposals found in
the literature.
47
 0 10 20 30 40 50 60 70 80 90 100OR / JPOR / IEJP / IEPercentage of TestsLocation of AgentsCHAPTER 3. MEASUREMENT STUDY
The most closely related study is the work of Lu et al. [50], which studied
the consistency of TAO, Facebook’s graph store. The study was performed by
logging information inside the infrastructure of Facebook. In contrast, our
approach uses the Web APIs of the services, allowing to study the consistency
of services, as perceived by end users, without access to their infrastructure.
The other main distinction is that our methodology allowed us to study several
Internet services, instead of a single one.
The works of Wada et al. [68] and Bermbach et al. [19] have focused on test-
ing the consistency properties on cloud storages, like Amazon S3. In contrast
to both studies, our measurement study focuses on understanding the consis-
tency properties oﬀered by service APIs (i.e., above the storage layer), and for
the particular case of clients scattered across diﬀerent geographic locations.
At an even lower layer, Xu et al. [69] conducted a measurement study of
response times of virtual machines launched at Amazon EC2. This represents
a layer that is even further apart from the one we are analyzing. Furthermore,
that study focuses only on performance and not on consistency.
The studies of Anderson et al. [10] and Zellag et al. [73], proposed analytic
models to determine the consistency properties implemented by distributed
key-value stores, based on measurements taken from inside the system. In
contrast, we conduct a measurement study of consistency properties oﬀered by
Internet services, focusing on a more general mode than key-value stores.
Finally, the work of Bailis et al. [15], where they modeled the consistency
of weak quorums as a probabilistic bound on staleness, and the work of Yu
and Vahdat [71] where they limit the divergence to the ﬁnal replica state, are
diﬀerent from our work, because part of our analysis builds on the idea of
quantifying divergence but, in contrast, our goal is to understand its existence
in several APIs.
3.6 Summary
We presented a measurement study of the consistency oﬀered by the APIs of
four online services. To this end, we started by identifying a set of anomalies
48
3.6. SUMMARY
that are not permitted by various consistency levels, and devised two tests that
have the ability to expose these anomalies. Our measurement study, based on
these tests, ran on Google+, Blogger, Facebook Feed, and Facebook Groups for
an aggregate period of one month in each service. Our study showed the rela-
tively frequent occurrence of most of the anomalies across all services except
in Blogger.
49
t
p
a
e
r 4
h
C
Fine-Grained Consistency for
Online Services
As we saw in the previous Chapter, developers who design applications for
online services such as Facebook or Google+ have little information about their
consistency, which exacerbates the complexity of reasoning about the semantics
of the application they are developing. In particular, we evaluated a set of ser-
vices and found a relevant number of consistency anomalies, which motivates
the need to automatically enrich the consistency guarantees provided by these
services. In this chapter, we are going to present the design of a middleware
that provides ﬁne-grained consistency guarantees on top of these services.
4.1 Target systems
Our goal is to provide particular consistency guarantees to third-party appli-
cations that leverage popular online web services that expose public APIs. In
particular, the application developer may choose to have individual session
guarantees (Read Your Writes, Monotonic Reads, Monotonic Writes, and Writes
Follow Reads) as well as combinations of these properties (in particular, all four
session guarantees when combined corresponds to causality [26]). To achieve
this, we provide a middleware that can be easily attached to the third-party
51
CHAPTER 4. FINE-GRAINED CONSISTENCY FOR ONLINE SERVICES
Figure 4.1: Arquitecture overview
client application, allowing us to enrich the semantics exposed through the
system public API. Figure 4.1 depicts an overview of our architecture. There
are multiple popular systems that provide such public APIs, with various dif-
ferences in terms of the interface they expose. As such, we needed to focus
on a group of APIs with a similar service interface that we can easily adapt
to. We chose to focus on a particular class of services, namely social networks,
such as Facebook, Twitter, or Instagram. Our choice is based on the relevance
and popularity of these services and also on the large number of third-party
applications that are developed for them. In particular, we target services that
expose a data model based on key-value stores, where data objects can be ac-
cessed through a key, and that associate a list of objects to each key. We observe
that this data model is prevalent in online social network services, particularly
since they share concepts such as user feeds and comment lists. In particu-
lar, we target services where the API provides two fundamental operations to
manipulate the list of objects associated with a given key: an insert operation
to append a new object to the ﬁrst position of the list, and a get operation,
depicted in Figure 4.2, that exposes the ﬁrst N elements of the list (i.e., the
most recent N elements added to that list). Note that most of existing services
52
Service (Web API acess)MiddlewareClientApplicationMiddlewareClientApplicationMiddlewareClientApplication4.1. TARGET SYSTEMS
Figure 4.2: Service get operation, returns N elements of the list
specify a maximum of N elements, which means that our middleware must
assume that the service can return less than N elements for read operations.
Since we access these services through their public APIs, we need to view
the service implementation as a black box, meaning that no assumptions are
made regarding their internal operation. Furthermore, we design our proto-
cols without making any assumption regarding the consistency guarantees
provided through the public service API. The importance of not assuming any
guarantees from existing services is justiﬁed by our own previous measure-
ment study, which showed a high prevalence of violations of multiple session
guarantees in public APIs provided by services of this class.
Our algorithms require storing metadata alongside the data, which can
be diﬃcult to do when accessing services as black boxes, namely when the
service has no support for including user managed metadata (this is the case
of Facebook, which we explore in the context of our prototype experimental
evaluation). In this case, we need to encode this metadata as part of the data
itself. As a consequence, when the service is accessed by native clients (i.e., web
applications or third party applications that do not resort to our Middleware)
the user might observe this metadata. However, we believe that this is not a
53
Message1Message 2Message 3Message 4Message 5Message 6NTOPCHAPTER 4. FINE-GRAINED CONSISTENCY FOR ONLINE SERVICES
crucial issue, since many third party applications only access data objects (i.e,
lists) that are used exclusively by that application.
In order to arbitrate an ordering among operations issued by the local client
and other remote clients, our Middleware needs an approximate estimate of
the current time. To achieve this, two options are available. If the service
has a speciﬁc call in its public API that exposes the time in the server, such
call can directly be used by our system. Otherwise, if the service exposes a
Representational State Transfer (REST) API (which is typical in many services)
a simple REST call can be performed to the service, and the server time can
be extracted from a standard HTTP response header (called Date). Note that,
even though it is desirable that this estimate is synchronized across clients,
we do not require either clock or clock rate synchronization for correctness. In
particular, the only negative eﬀect of clocks being out of synch is a reordering of
concurrent events from diﬀerent sessions that is incoherent with their real time
occurrence; this can imply, in the case of a service that outputs a sliding window
of recent events, that more recent messages may be considered eligible for being
truncated (i.e., considered older than the lower end of the window). However,
we guarantee that such ordering never violates the correctness conditions we
are enforcing.
Finally, we observe that, in practice, the public API exposed by these ser-
vices often imposes rate limits for operations issued by client applications.
These rate limits are exposed under the form of a maximum number of opera-
tions that can be executed within a given time window. In particular, we have