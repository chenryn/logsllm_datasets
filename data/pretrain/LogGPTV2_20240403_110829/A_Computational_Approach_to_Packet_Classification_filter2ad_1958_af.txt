[30] Ben Pfaﬀ, Justin Pettit, Teemu Koponen, Ethan Jackson, Andy Zhou, Jarno Raja-
halme, Jesse Gross, Alex Wang, Joe Stringer, Pravin Shelar, Keith Amidon, and
Martin Casado. 2015. The Design and Implementation of Open vSwitch. In
USENIX NSDI.
Deep
September
Learning
Inference
25,
2019
[31] Alon Rashelbach. 2020. NeuvoMatch source code. Retrieved June 21, 2020 from
https://github.com/acsl-technion/nuevomatch
[32] Ori Rottenstreich and János Tapolcai. 2015. Lossy Compression of Packet Clas-
siﬁers. In ACM/IEEE ANCS.
[33] Nadi Sarrar, Steve Uhlig, Anja Feldmann, Rob Sherwood, and Xin Huang. 2012.
Leveraging Zipf’s law for traﬃc oﬄoading. Computer Communication Review
42, 1 (2012), 16–22.
[34] Sumeet Singh, Florin Baboescu, George Varghese, and Jia Wang. 2003. Packet
Classiﬁcation Using Multidimensional Cutting. In ACM SIGCOMM.
[35] Ed Spitznagel, David E Taylor, and Jonathan S Turner. 2003. Packet classiﬁcation
using extended TCAMs. In IEEE ICNP.
[36] Venkatachary Srinivasan, Subhash Suri, and George Varghese. 1999. Packet Clas-
siﬁcation Using Tuple Space Search. In ACM SIGCOMM.
[37] David E Taylor. 2005. Survey and Taxonomy of Packet Classiﬁcation Techniques.
ACM Computing Surveys (CSUR) 37, 3 (2005), 238–275.
[38] David E. Taylor and Jonathan S. Turner. 2005. Scalable packet classiﬁcation using
distributed crossproducing of ﬁeld labels. In IEEE INFOCOM.
[39] David E Taylor and Jonathan S Turner. 2007. Classbench: A Packet Classiﬁcation
Benchmark. IEEE/ACM Transactions on Networking (TON) 15, 3 (2007), 499–511.
[40] Asaf Valadarsky, Michael Schapira, Dafna Shahaf, and Aviv Tamar. 2017. Learn-
ing to Route with Deep RL. In NIPS Deep Reinforcement Learning Symposium.
[41] Balajee Vamanan, Gwendolyn Voskuilen, and T. N. Vijaykumar. 2010. EﬃCuts:
Optimizing Packet Classiﬁcation for Memory and Throughput. In ACM SIG-
COMM.
[42] Matteo Varvello, Rafael Laufer, Feixiong Zhang, and T. V. Lakshman. 2016. Mul-
tilayer Packet Classiﬁcation with Graphics Processing Units. IEEE/ACM Trans-
actions on Networking (TON) 24, 5 (2016), 2728–2741.
[43] Hyunho Yeo, Youngmok Jung, Jaehong Kim, Jinwoo Shin, and Dongsu Han. 2018.
Neural Adaptive Content-aware Internet Video Delivery. In USENIX OSDI.
[44] Sorrachai Yingchareonthawornchai, James Daly, Alex X. Liu, and Eric Torng.
2018. A Sorted-Partitioning Approach to Fast and Scalable Dynamic Packet Clas-
siﬁcation. IEEE/ACM Transactions on Networking (TON) 26, 4 (2018), 1907–1920.
[45] Yasir Zaki, Thomas Pötsch, Jay Chen, Lakshminarayanan Subramanian, and
Carmelita Görg. 2015. Adaptive Congestion Control for Unpredictable Cellular
Networks. In ACM SIGCOMM.
[46] Hongyi Zeng, Peyman Kazemian, George Varghese, and Nick McKeown. 2012.
Automatic Test Packet Generation. In ACM CoNEXT.
Appendices are supporting material that has not been peer-
reviewed.
A RQ-RMI CORRECTNESS
A.1 Responsibility of a submodel
Denote the input domain of an RQ-RMI model as D ⊂ R and its
number of stages as n.
Theorem A.1 (Responsibility Theorem). Let si be a trained
stage such that i  0 such
that the function is linear in each of (x − δ , x), (x, x + δ ). Accord-
ingly, we can refer to the left slope and the right slope of a point,
deﬁned as those of the two linear functions.
Deﬁnition A.5 (Trigger Inputs). We say that an input ❕ ∈ D is a
trigger input of a submodel mi , j if one of the following holds: (i) ❕
is a boundary point of D (namely, ❕ = miny ∈D y or ❕ = maxy ∈D y).
(ii) ❕ is an internal point of D and the left and right slopes of Mi , j (❕)
diﬀer.
Deﬁnition A.6 (Transition Inputs). We say that an input t ∈ D is a
transition input of a submodel mi , j if it changes submodel selection
in the following stage. Formally, there exists ϵ > 0 such that for all
0  0 such that for all 0  0 such that for all 0 < δ < ϵ:
Bi(cid:0)Si (z − δ )(cid:1) , Bi(cid:0)Si (z + δ )(cid:1)
Since Si consists of the outputs of submodels in si , there exists a
submodel mi ,k such that Si (z) = Mi ,k (z). Therefore, z ∈ Ti ,k and
z ∈ Ri ,k , which means z ∈ Ui , in contradiction to deﬁnition of u0
and u1.
(cid:3)
Lemma A.12. Let si be an RQ-RMI stage such that i ∈ {0, 1, ..., n −
2}. The function fi +1 deﬁned over the space D can be calculated using
the inputs Ui over Si .
Proof. Let u0 < u1 ∈ Ui be two adjacent values. By Lemma
A.11 there exists a submodel mi +1, j such that Si +1(x) = Mi , j (x) for
all x ∈ (u0, u1). From Deﬁnition A.2, fi +1(x) = j for all x ∈ (u0, u1).
By calculating Bi (Si (u0)) and Bi (Si (u1)), fi +1(x) is known for all
x ∈ [u0, u1]. Since min{D} ∈ Ui and max {D} ∈ Ui , fi +1(x) is
known for all x ∈ D.
(cid:3)
y
c
n
e
t
a
L
p
u
d
e
e
p
S
6
5
4
3
2
1
0
1K Rules
10K Rules
1K Rules
10K Rules
1
2
3
4
5
6
7
8
9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
1
2
3
4
5
6
7
8
9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
NuevoMatch w/ CutSplit
NuevoMatch w/ TupleMerge
2
1 .5
1
0 .5
0
t
u
p
h
g
u
o
r
h
T
p
u
d
e
e
p
S
Figure 17: A detailed version of end-to-end performance for small rule-sets. Speedup in throughput and latency of NuevoMatch
against stand-alone versions of CutSplit and TupleMerge. Classiﬁers with no valid iSets are not displayed.
A.2 Submodel prediction error
Theorem A.13 (Submodel Prediction Error). Let sn−1 be the
last stage of an RQ-RMI model. The maximum prediction error of any
submodel in sn−1 can be calculated using a ﬁnite set of inputs over
the stage sn−1.
The intuition behind Theorem A.13 is to address the set of range-
q0 and q1. Calculating the responsibilities of all pairs is performed
by repeating the process for any two adjacent points in Un−1.
At this point, as we know Rp for all p = hr , vi, calculating the
set (r \ Rp ) ∪ (Rp \ r ) is trivial. Acquiring the responsibility of any
submodel in sn−1 using Theorem A.1 enables us to calculate its
misclassiﬁed pair set immediately.
(cid:3)
value pairs as an additional, virtual, stage in the model.
Proof of Theorem A.13
Deﬁnition A.14 (Range-Value Pair). A range-value pair hr , vi is
deﬁned such that r is an interval in D and v ∈ {0, 1, 2, ...} is unique
to that pair.
We term Wn the number of range-value pairs an RQ-RMI model
should index. Similar to the deﬁnitions for submodels, we extend fi
such that fn (x) = ⌊Sn−1(x)·Wn ⌋, and say that the responsibility Rp
of a pair p = hr , vi is the set of inputs {x | fn (x) = v }. Consequently,
we make the following two observations. First, all inputs in the
range r \ Rp should have reached p but did not. Second, all inputs
in the range Rp \ r did reach p but should not.
Deﬁnition A.15 (Misclassiﬁed Pair Set). Let m be a submodel in
sn−1 with a responsibility Rm. Denote Pm as the set of all pairs such
that a pair p = hr , vi ∈ Pm satisﬁes (r \ Rp ) ∪ (Rp \ r ) ∩ Rm , ∅. In
other words, Pm holds all pairs that were misclassiﬁed by m, and
termed the misclassiﬁed pair set of m.
Deﬁnition A.16 (Maximum Prediction Error). Let m be a sub-
model in sn−1 with a responsibility Rm and a misclassiﬁed pair
set Pm. The maximum prediction error of m is deﬁned as:
Proof. Let m be a submodel in sn−1 with a responsibility Rm.
For simplicity, we address the case where Rm is a continuous range.
Extension to the general case is possible by repeating the proof for
any continuous range in Rm.
Denote the submodel’s ﬁnite set of trigger inputs as Gm. Deﬁne
the set Q as follows:
Q = min Rm ∪ (Gm ∩ Rm) ∪ max Rm
Let q0 < q1 be two adjacent values in Q. From the deﬁnition of
trigger inputs, m outputs a linear function in [q0, q1]. Hence, the
set of values S0 = { fn (x)|x ∈ [q0, q1]} can be calculated using only
q0 and q1 over Sn−1. From Lemma A.17, the misclassiﬁed pair set
Pm can be calculated using the ﬁnite set Un−1. Denote the set
ˆP0 = {hr , vi | hr , vi ∈ Pm , r ∩ [q0, q1] , ∅}
Calculating max{s − v |s ∈ S0, hr , vi ∈ ˆP0} yields the maximum
error of m in [q0, q1]. Repeating the process for any two adjacent
points in Q yields the maximum error of m for all Rm.
(cid:3)
Rule-set names in Figures 8 and 17, by order: ACL1, ACL2, ACL3,
ACL4, ACL5, FW1, FW2, FW3, FW4, FW5, IPC1, IPC2.
max(cid:8)| fn (x) − v |(cid:12)(cid:12) hr , vi ∈ Pm , x ∈ Rm(cid:9)
Lemma A.17. The misclassiﬁed pair sets of all submodels in sn−1
can be calculated using Un−1 over Sn−1.
Proof. Let q0 < q1 be two adjacent values in Un−1. From
Lemma A.11 there exists a single submodel mn−1, j , j ∈ Wn−1 s.t
Sn−1(x) = Mn−1, j (x) for all x ∈ (q0, q1). Hence, using Corollary 3.2,
Sn−1 is linear in (q0, q1). Therefore, the values of Sn−1 in [q0, q1]
can be calculated using q0 and q1 alone. Consequently, according
to the deﬁnitions of fn and the responsibility of a pair, the set of
pairs Pj with responsibilities in [q0, q1] can also be calculated using
Table 4: RQ-RMI conﬁgurations for diﬀerent input rule-set
sizes.
#Rules
#Stages
Stage Widths
Less than 103
103 to 104
104 to 105
More than 105
2
3
3
3
[1, 4]
[1, 4, 16]
[1, 4, 128]
[1, 8, 256] or [1, 8, 512]