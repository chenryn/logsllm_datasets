scope of this work. Furthermore, history has shown that de-
velopers are rarely better oﬀ rolling their own cryptographic
implementations as opposed to using well-tested library func-
tionality. Thus, any such implementation is most likely less
secure than the OS provided cryptographic algorithms.
3http://www.scoreloop.com/
4http://developer.android.com/google/play/
licensing/index.html
5The source for the LVL and the AESObfuscator can be ob-
tained at: http://code.google.com/p/marketlicensing/
source/browse/library/src/com/android/vending/
licensing/AESObfuscator.java
80#Occurences
5,878
4,803
1,151
741
501
473
468
443
235
221
220
205
155
104
Symmetric encryption scheme
AES/CBC/PKCS5Padding
AES *
DES/ECB/NoPadding
DES *
DESede *
DESede/ECB/PKCS5Padding
AES/CBC/NoPadding
AES/ECB/PKCS5Padding
AES/CBC/PKCS7Padding
DES/ECB/PKCS5Padding
AES/ECB/NoPadding
DES/CBC/PKCS5Padding
AES/ECB/PKCS7Padding
AES/CFB8/NoPadding
Table 4: Distribution of frequently used symmetric
encryption schemes. Schemes marked with * are
used in ECB mode by default.
Recent events demonstrated that the assumption that
cryptographic primitives are implemented correctly can be
violated [20]. However, CryptoLint’s focus is to identify
applications that use these primitives incorrectly and not
the identiﬁcation of ﬂawed implementations of the primitives
themselves.
7 Mitigations
We now discuss a set of possible countermeasures that would
likely reduce the prevalence of misused cryptographic prim-
itives in Android applications. As explained in the intro-
duction three main issues cause the problems we see with
applying cryptography in Android applications. (1) APIs
are not expressive enough to enforce semantic contracts (e.g.,
IVs should be unique and non-predictable). (2) APIs ship
with poor default conﬁgurations, and (3) the documentation
insuﬃciently describes the APIs.
Semantic contracts in APIs . One approach is to use
tools such as CryptoLint to vet software, e.g., as part of
the Google Play marketplace. Additionally, compilers can
provide safety warnings on typically insecure method calls to
the crypto API. For example, a call to the ECB encryption
mode could raise a warning similar to the way that the
strcpy function is ﬂagged by the Microsoft C compiler.
Poor default conﬁgurations in APIs . Switching default
conﬁgurations in APIs is challenging, especially in the light
of backward compatibility. However, because of the negative
characteristics of today’s default values, we believe that
choosing better defaults would mitigate many problems that
lead to misused cryptography.
Table 4 lists the symmetric encryption schemes used by at
least 100 applications in our dataset. The most popular API
call is to CBC mode encryption, where CBC mode is explic-
itly picked in the name. The second (AES), fourth (DES),
and ﬁfth most popular (DESede) do not indicate which mode
is being used. One possibility is to ban APIs that do not
make the encryption mode explicit. Such an approach would
require developers to investigate an appropriate encryption
mode. Paired with appropriate documentation, this change
would potentially make more developers aware of the crypto-
graphic issues associated with block cipher encryption modes.
API documentation. The Java and Android API documen-
tation contains a disclaimer that it is not designed to teach
a developer the prerequisites of cryptography. However, the
documentation could suggest sane defaults, e.g., CBC mode
with a random IV because it is secure. Furthermore, we
strongly advocate that the documentation for the crypto-
graphic security provider explicitly state the default values.
In some cases the default value is not mentioned at all. For
example, the Cipher class states that a block cipher mode
can be requested. However, it fails to mention if no mode is
requested, ECB mode will be used by default. As it stands,
the only way for a developer to determine default values,
and whether they are secure, is via trial and error, Internet
searches, or the inspection of the source code of the security
provider.
Although Google regularly pulls up-to-date BouncyCastle
revisions into the Android source tree, not all enhancements
within the security provider are exposed to applications via
the SDK. For example, BouncyCastle has supported Galois
counter mode (GCM 6) for authenticated encryption with
associated data since 2008. Oracle Java has supported this
mode and the necessary APIs since version 1.7, which was
released in 2011. However, the latest Android version (at
the time of writing Jelly Bean 4.3) does not expose the
necessary APIs to use associated data with any authenticated
encryption modes. Furthermore, the Android documentation
does not mention authenticated encryption at all. Thus,
developers who want to use these encryption modes have to
gather their knowledge from other resources.
8 Related Work
The popularity of the Android operating system has at-
tracted the attention of many researchers in the past. With
TaintDroid, Enck et al. [13] track the propagation of sensi-
tive information through Android applications. Hoﬀmann
et al. [17] present SAAF, a static analysis framework that
helps a human analyst to examine Android applications. Fur-
thermore, the Android permission system has been at the
core of many scientiﬁc publications [14, 16, 24]. While the
permission system is the ﬁrst line of defense in the Android
security landscape, cryptographic primitives allow develop-
ers to add another line of defense by encrypting data before
storing or transmitting it. Thus, to the best of our knowl-
edge, CryptoLint is the ﬁrst approach that investigates
whether application developers make correct (i.e., secure)
use of cryptographic primitives.
Zhou [29] and Vidas [26] investigate malicious applica-
tions in the Android ecosystem. The focus of CryptoLint,
however, is to identify benign applications that employ cryp-
tographic primitives incorrectly.
Our work is similar to the Lint program checker [18]. That
is, we identify a series of common programming mistakes
and automatically identify applications that contain such
mistakes. Similarly, LCLint [21] uses source-code analysis
and manual annotations to identify likely buﬀer overﬂows in
C programs. The main diﬀerence between these approaches
and CryptoLint is, however that CryptoLint does not
have access to source code and operates on compiled Android
applications instead. To ensure wide applicability of Cryp-
toLint, we have to operate on compiled Android applications
6 Within the Android documentation GCM is used to refer
to the Google Cloud Messaging API.
81instead. Chen and Wagner presented MOPS [8] to examine
security properties of software at compile time. CryptoLint
is similar to MOPS as its goal is also to evaluate security
properties. However, CryptoLint operates on compiled
applications. Furthermore, a major contribution of this work
is the broad overview that we gained about the prevalence of
misused cryptographic functionality in Android applications.
Fahl et al. [15] presented MaloDroid, a system that identi-
ﬁes Android applications that do not perform the necessary
validation on SSL certiﬁcates. MaloDroid is similar to Cryp-
toLint as it targets Android applications. However, the
single property that is evaluated by MaloDroid is whether
applications adequately verify SSL certiﬁcates. CryptoLint
checks for properties that are generally applicable to a cryp-
tographic context, such as the proper use of initialization
vectors, or random salt values for password based encryption
schemes.
Mitchell et al. [22] present Murϕ a tool that allows them to
detect vulnerabilities in cryptographic and security-relevant
protocols through state enumeration. Bhargavan et al. [7]
illustrate how veriﬁcation tools can be used to show the
security of cryptographic protocol implementations. The ver-
iﬁcation of the TLS1.0 protocol required the authors to write
an implementation from scratch that makes itself amenable
to the suggested veriﬁcation techniques. While such an ap-
proach is desirable, it seems unreasonable to require the large
population of Android application developers to adapt such
programming standards. Similar to these two approaches, we
treat encryption primitives as black boxes. That is, we trust
their security and implementations. However, developers
using cryptographic primitives rarely implement well known
protocols themselves.
Similar to Whitten et al. [28] and Clark and Goodspeed [9]
we analyze the usability of cryptography. However, while the
mentioned works analyze the usability for end-users, Cryp-
toLint focuses on the usability of cryptographic APIs, and
functionality for application developers. However, our ﬁnd-
ings are somewhat comparable in that end-users as well as
developers seem to lack the proper knowledge or support to
make correct decisions when applying cryptography.
9 Conclusions and Future work
CryptoLint checks real-world Android applications for the
violation of the six security rules outlined in Section 3. With
this automated approach we identiﬁed 10,327 applications
(88% of our dataset) that violate at least one of these rules.
We identiﬁed one of the contributing factors to be the undoc-
umented insecure default conﬁguration of the BouncyCastle
cryptographic security provider used on the Android plat-
form. Based on the insights we gained from the large-scale
analysis of real-world Android applications, we also illus-
trated diﬀerent mitigation approaches, we believe would be
beneﬁcial to the overall security of the Android ecosystem.
We are currently working on making CryptoLint a pub-
licly accessible online service where developers and curi-
ous users can submit Android applications and have them
evaluated with respect to the cryptographic security rules
described herein. In the future we also plan to extend Cryp-
toLint with security rules that capture the misuse of asym-
metric cryptography.
Acknowledgements
This material is based on research sponsored by DARPA
under CSSP #23143.2.1080246 and agreement number
FA8750-12-2-0101. The U.S. Government is authorized to
reproduce and distribute reprints for Governmental
purposes notwithstanding any copyright notation thereon.
References
[1] The legion of the bouncy castle.
http://bouncycastle.org/, 2013.
[2] M. Abadi and B. Warinschi. Password-Based
Encryption Analyzed. In Proceedings of the
international colloquium of Automata, Languages and
Programming, pages 664–676. Springer, 2005.
[3] I. Apple. iOS Security Contents, 2012.
[4] M. Bellare, T. Kohno, and C. Namprempre.
Authenticated encryption in SSH: Provably Fixing the
SSH Binary Packet Protocol. In Proceedings of the 9th
ACM conference on Computer and communications
security, pages 1–11, 2002.
[5] M. Bellare, T. Ristenpart, and S. Tessaro.
Multi-instance Security and Its Application to
Password-Based Cryptography. In Proceedings of the
32nd Annual Cryptology Conference, pages 312–329.
Springer, 2012.
[6] M. Bellare and P. Rogaway. Course notes for
introduction to modern cryptography. cseweb.ucsd.
edu/users/mihir/cse207/classnotes.html.
[7] K. Bhargavan, C. Fournet, R. Corin, and E. Zalinescu.
Cryptographically veriﬁed implementations for TLS. In
Proceedings of the 15th ACM conference on computer
and Communications security, pages 459–468, 2008.
[8] H. Chen and D. Wagner. MOPS: An Infrastructure for
Examining Security Properties of Software. In
Proceedings of the 9th ACM conference on Computer
and communications security, pages 235–244, 2002.
[9] S. Clark and T. Goodspeed. Why (special agent)
Johnny (still) can’t encrypt: a security analysis of the
APCO project 25 two-way radio system. In Proceedings
of the 20th USENIX Security Symposium, 2011.
[10] R. Cytron, J. Ferrante, B. K. Rosen, M. N. Wegman,
and F. K. Zadeck. Eﬃciently Computing Static Single
Assignment Form and the Control Dependence Graph.
ACM Transactions on Programming Languages and
Systems, 13(4):451–490, Oct. 1991.
[11] J. Dean, D. Grove, and C. Chambers. Optimization of
object-oriented programs using static class hierarchy
analysis. In Proceedings of the 9th European Conference
on Object-Oriented Programming, pages 77–101.
Springer, 1995.
[12] A. Desnos. Androguard: Reverse engineering, malware
and goodware analysis of android applications ... and
more (ninja !).
http://code.google.com/p/androguard/.
[13] W. Enck, P. Gilbert, B.-G. Chun, L. P. Cox, J. Jung,
P. McDaniel, and A. N. Sheth. TaintDroid: an
information-ﬂow tracking system for realtime privacy
monitoring on smartphones. In Proceedings of the 9th
82USENIX Symposium on Operating Systems Design and
Implementation, 2010.
[14] W. Enck, M. Ongtang, and P. McDaniel. On
lightweight mobile phone application certiﬁcation. In
Proceedings of the 16th ACM conference on computer
and Communications security, pages 235–245, 2009.
[15] S. Fahl, M. Harbach, T. Muders, M. Smith,
L. Baumg¨artner, and B. Freisleben. Why Eve and
Mallory Love Android: An Analysis of Android SSL
(In)Security. In Proceedings of the 19th ACM
conference on Computer and communications security,
pages 50–61, 2012.
[16] A. P. Felt, E. Chin, S. Hanna, D. Song, and D. Wagner.
Android permissions demystiﬁed. In Proceedings of the
18th ACM conference on Computer and
communications security, pages 627–638, 2011.
[17] J. Hoﬀmann, M. Ussath, T. Holz, and
M. Spreitzenbarth. Slicing droids: program slicing for
smali code. In In Proceedings of the 28th ACM
Symposium on Applied Computing, 2013.
[18] S. C. Johnson. Lint , a C Program Checker. Technical
report, 1978.
[19] B. Kaliski. PKCS #5: Password-based cryptography
speciﬁcation version 2.0.
http://tools.ietf.org/html/rfc2898.
[20] A. Klyubin. Some SecureRandom thoughts.
http://android-developers.blogspot.co.uk/2013/
08/some-securerandom-thoughts.html, 2013.
[21] D. Larochelle and D. Evans. Statically Detecting Likely
Buﬀer Overﬂow Vulnerabilities. In Proceedings of the
10th USENIX Security Symposium, pages 177–190,
2001.
[22] J. C. Mitchell, M. Mitchell, and U. Stern. Automated
Analysis of Cryptographic Protocols Using Murphi. In
Proceedings of the IEEE Symposium on Security and
Privacy, pages 141–151, 1997.
[23] B. Moeller. TLS insecurity (attack on CBC).
http://www.openssl.org/~bodo/tls-cbc.txt, 2001.
[24] M. Nauman, S. Khan, and X. Zhang. Apex: extending
android permission model and enforcement with
user-deﬁned runtime constraints. In Proceedings of the
5th ACM Symposium on Information, Computer and
Communications Security, pages 328–332, 2010.
[25] P. Pearce, A. P. Felt, G. Nunez, and D. Wagner.
AdDroid: Privilege separation for applications and
advertisers in android. In Proceedings of the 7th ACM
Symposium on Information, Computer and
Communications Security, 2012.
[26] T. Vidas, D. Votipka, and N. Christin. All Your Droid
Are Belong To Us: A Survey of Current Android
Attacks. In Proceedings of the 5th USENIX Workshop
on Oﬀensive Technologies, 2011.
[27] M. Weiser. Program Slicing. In Proceedings of the 5th
international conference on Software engineering, pages
439–449, 1981.
[28] A. Whitten and J. Tygar. Why Johnny Can’t Encrypt :
A Usability Evaluation of PGP 5.0. In Proceedings of
the 8th USENIX Security Symposium, 1999.
[29] Y. Zhou, Z. Wang, W. Zhou, and X. Jiang. Hey, you,
get oﬀ of my market: Detecting malicious apps in
oﬃcial and alternative android markets. In Proceedings
of the 19th Annual Network and Distributed System
Security Symposium, 2012.
83