n∏
(
P r(Ai(D
n∏
i=1
′
i) = ai)
)
P r(Ai(Di) = ai)
)
·
n(D
) = r) =
′
(
P r(A∗
is+δ−1∏
≤
≤ exp(ϵ)P r(A∗
i=is
exp(ϵi)
i=1
n(D) = r)
Similarly argument holds for any pair D and D
D + {x} and x is near the source. Therefore, A∗
diﬀerentially private under δ-neighbourhood.
where D
=
n is ϵ-
′
′
For instance, if ϵi = δ
−1 for all i, under standard neigh-
bourhood, A∗
n is a n/δ-diﬀerentially private, but it is a
1-diﬀerentially private mechanism under δ-neighbourhood.
Note that the assurance is independent of n, and thus it is
possible to continue publishing indeﬁnitely and yet achieve
Figure 7: Improvement of oﬄine version for δ = 4.
1012141618202224262830050100150200250300350400Length of dataset: nSum of Square ErroreOwithp=0.5eIwithp=0.5eOwithp=0.75eIwithp=0.75167In general, solving the above optimization problem is diﬃ-
cult. However, when the objective function is quadratic, it is
a convex optimization problem whose solution can be found
using existing optimization solvers, for example, a SDPT3
solver [22][23].
In this section, we study error function of
the form Erri(ϵ) = ciϵ
−2 for some constant ci. This for-
m of error function corresponds to mechanisms such as the
Laplace mechanism, whereby the variance of the error is a
quadratic function w.r.t. ϵ
. Since the constant ci can be
captured by the weight vector w, Without loss of generality,
we assume ci = 1 for all i.
⟩, which corresponds to an allocation
that divides the budget equally across time; and let eO to
be the optimal allocation. Note that eI is in the feasible
region of the problem and could be a good initial solution
for a solver.
Let eI = ⟨ ϵ
δ , . . . , ϵ
−1
i
δ
Figure 7 shows the comparison of errors between eI and
the optimal budget allocation eO, where w is a binary vector
and each wi ∈ {0, 1} is independently randomly chosen to
be 1 with probability p = 0.5 and p = 0.75, respectively.
7.2 Online Allocation
Under online setting, only w1, . . . , wi are available at time
i, and the allocating algorithm has to commit the budget
for ei which may later turn out to be sub-optimal. Indeed,
it is easy to construct a counter example to show that for
any deterministic algorithm, in the worst case, there is an
instance where the error incurred is twice as large than the
oﬄine optimal.
In this section, we focus on average case
performance where the w is drawn from some distribution
known to the publisher.
We propose an online algorithm as follow. At time i, given
the committed budget allocation e1, . . . , ei−1 and w1, . . . , wi,
the following steps are carried out:
1. N (in our experiment, N =1,000) samples of weights
w1, . . . , wN are drawn from the distribution on condi-
tion that the ﬁrst i values are w1, . . . , wi.
2. For each candidate of ei (in our experiment, we try
0.01, 0.02, . . . , 1) and each w among the N weight sam-
ples, compute the “optimal” error by solving the con-
strained oﬄine allocation problem given below (Prob-
lem 2). After the errors by the N samples are obtained,
the average error is computed.
3. The candidate that attains the smallest average error
is committed to be the budget of ei.
Problem 2 Constrained Oﬄine Allocation
′
2, . . . , ϵ
m⟩ ∈ Rm≥0,
′
′
1, ϵ
= ⟨ϵ
δ ∈ Zn, ϵ, e
′
w = ⟨w1 . . . wn⟩ ∈ Rn≥0
n∑
⟨ϵ1, ϵ2, . . . , ϵn⟩
wiErri(ϵi)
δ∑
i=1
Given:
Find:
Minimize:
Subject to:
ϵk+i ≤ ϵ, for k = 1, 2, . . . , (n − δ);
i=1
′
k, for k = 1, 2, . . . , m.
ϵk = ϵ
7.3 Evaluations
We evaluate the performance of the online algorithm, com-
paring to the oﬄine optimal solution and eI . We consider
ϵ = 1, and δ = 4 or 7. For each setting, we repeat the ex-
periment for 1,000 times and record the average error of the
three solutions.
We consider a w where each wi ∈ {0, 1} is taken to be
1 with probability p = 0.5. Figure 8(a) shows the errors of
eO, eX and eI for δ = 4, and Figure 8(b) shows errors when
δ = 7. Figure 8(c) consider a w where each wi ∈ {0, 1} is
taken to be 1 with probability p = 0.75.
8. RELATED WORK
There are extensive works on privacy-preserving data pub-
lishing. The recent survey by Fung et al. [10] gives a com-
prehensive overview on various notions, for example, k-anon-
ymity [20], ℓ-diversity [16], and diﬀerential privacy [4].
In practice, ϵ-diﬀerential privacy can be too strong to be
achieved in some scenarios. Many relaxations capture alter-
native notions of “indistinguishability”, in particular, on how
the two conditional probabilities in the bound are compared.
For example, (ϵ, δ)-diﬀerential privacy [5] relaxes the bound
with an additive factor δ, and (ϵ, τ )-probabilistic diﬀerential
privacy [17] allows the bound to be violated with a probabil-
ity τ . Similar to our work, Konstantinos et al.[2] proposed
broadening the diﬀerential privacy deﬁnition by considering
diﬀerent underlying metrics.
Alternative relaxations include attribute diﬀerential priva-
cy and bit diﬀerential privacy considered by Kifer et al. [14],
where two datasets are neighbours if they diﬀer at only one
attribute value or one bit. Blocki et al. [1] consider diﬀer-
entially private graph algorithms, with restriction that the
maximum degree of any node in a social network graph is
bounded. They consider the restricted datasets and show
that such restricted sensitivity can be signiﬁcantly lower
than the smooth sensitivity for subgraph counting queries
and local proﬁle queries.
There are many mechanisms designed for histogram pub-
lishing. Xiao et al. [24] proposed a mechanism of adding
Laplace noise to the coeﬃcients of a wavelet transformation
of an equi-width histogram, whereby range query can be
answer with diﬀerent combination of the published trans-
formation. Hay et al. [11] proposed a method that a series
of equi-width histograms for diﬀerent bin-widths is to be
published, and a range query can then be decomposed and
answered from the histograms series diﬀerent scales. Li et
al. [15] gave an analysis on linear transformations to answer
to a query workload. Machanavajjhala et al. [17] proposed
a 2D dataset publishing method that can handle the sparse
data in 2D equi-width histogram. However, it is not clear
how to adapt the above-mentioned mechanisms to exploit
δ-neighbourhood. One exception is the method by Fang et
al. [9] as demonstrated in Section 5.5.
Dwork et al. [7] consider applications that involve repeat-
ed computations on dynamic datasets, such as monitoring
data or searching thread. They gave a general transforma-
tion that converts mechanisms on static dataset to mecha-
nisms under dynamic dataset. The idea of processing dy-
namic datasets also lead to a concept of pan-privacy [8],
which require each datum to be discarded immediately after
processing, and therefore guarantee that the internal state
be diﬀerentially private as well.
168(a) δ = 4, p = 0.5.
(b) δ = 7, p = 0.5.
(c) δ = 4, p = 0.75.
Figure 8: Comparison of oﬄine and online algorithms.
9. CONCLUSION
In this paper, we propose to relax diﬀerential privacy by
adopting an alternative deﬁnition of neighbourhood which
“redistributes” the assurances based on the underlying dis-
tance of the entities. Although the idea is simple, for some
applications, it is not clear how to exploit the relaxation to
achieve higher utility. We consider two types of datasets,
spatial datasets and dynamic datasets, and show that the
noise level can be further reduced by constructions that ex-
ploit the δ-neighbourhood. We give a few scenarios where
δ-neighbourhood would be more appropriate, and we believe
the notion provides a good trade-oﬀ for better utility.
10. REFERENCES
[1] J. Blocki, A. Blum, A. Datta, and O. Sheﬀet.
Diﬀerentially private data analysis of social networks
via restricted sensitivity. In Proceedings of the 4th
conference on Innovations in Theoretical Computer
Science, pages 87–96, 2013.
[2] K. Chatzikokolakis, M. E. Andr´es, N. E. Bordenabe,
and C. Palamidessi. Broadening the scope of
diﬀerential privacy using metrics. In Privacy
Enhancing Technologies, pages 82–102, 2013.
[3] G. Cormode, C. Procopiuc, D. Srivastava, E. Shen,
and T. Yu. Diﬀerentially private spatial
decompositions. In ICDE, pages 20–31, 2012.
[4] C. Dwork. Diﬀerential privacy. Automata, languages
and programming, pages 1–12, 2006.
[5] C. Dwork, K. Kenthapadi, F. McSherry, I. Mironov,
and M. Naor. Our data, ourselves: Privacy via
distributed noise generation. Advances in
Cryptology-EUROCRYPT, pages 486–503, 2006.
[6] C. Dwork, F. McSherry, K. Nissim, and A. Smith.
Calibrating noise to sensitivity in private data
analysis. Theory of Cryptography, pages 265–284, 2006.
[7] C. Dwork, M. Naor, T. Pitassi, and G. Rothblum.
Diﬀerential privacy under continual observation.
Proceedings of the 42nd ACM symposium on Theory of
computing, pages 715–724, 2010.
[8] C. Dwork, M. Naor, T. Pitassi, G. Rothblum, and
S. Yekhanin. Pan-private streaming algorithms. In
Proceedings of ICS, 2010.
[9] C. Fang and E. C. Chang. Adaptive diﬀerentially
private histogram of low-dimensional data. Privacy
Enhancing Technologies, pages 160–179, 2012.
[10] B. Fung, K. Wang, R. Chen, and P. Yu.
Privacy-preserving data publishing: A survey of recent
developments. ACM Computing Surveys, pages 14–57,
2010.
[11] M. Hay, V. Rastogi, G. Miklau, and D. Suciu.
Boosting the accuracy of diﬀerentially private
histograms through consistency. VLDB Endowment,
pages 1021–1032, 2010.
[12] Infochimps. Twitter census: Twitter users by location
[online].
http://www.infochimps.com/datasets/twitter-census-
twitter-users-by-location.
[13] B. Kaluˇza, V. Mirchevska, E. Dovgan, M. Luˇstrek,
and M. Gams. An agent-based approach to care in
independent living. Ambient Intelligence, pages
177–186, 2010.
[14] D. Kifer and A. Machanavajjhala. No free lunch in
data privacy. Proceedings of the 2011 international
conference on Management of data, pages 193–204,
2011.
[15] C. Li, M. Hay, V. Rastogi, G. Miklau, and
A. McGregor. Optimizing linear counting queries
under diﬀerential privacy. ACM symposium on
Principles of database systems of data, pages 123–134,
2010.
[16] A. Machanavajjhala, J. Gehrke, D. Kifer, and
M. Venkitasubramaniam. ℓ-diversity: Privacy beyond
k-anonymity. International Conference on Data
Engineering, pages 24–36, 2006.
[17] A. Machanavajjhala, D. Kifer, J. Abowd, J. Gehrke,
and L. Vilhuber. Privacy: Theory meets practice on
the map. International Conference on Data
Engineering, pages 277–286, 2008.
[18] K. Nissim, S. Raskhodnikova, and A. Smith. Smooth
sensitivity and sampling in private data analysis.
ACM Symposium on Theory of Computing, pages
75–84, 2007.
[19] A. Roth and T. Roughgarden. Interactive privacy via
the median mechanism. ACM Symposium on Theory
of Computing, pages 765–774, 2010.
[20] P. Samarati. Protecting respondents identities in
microdata release. Knowledge and Data Engineering,
pages 1010–1027, 2001.
[21] S. Silvey. Statistical inference, volume 7. Chapman &
Hall/CRC, 1975.
[22] K. Toh, M. Todd, and R. T¨ut¨unc¨u. Sdpt3 ,a la matlab
software package for semideﬁnite programming,
version 1.3. Optimization Methods and Software, pages
545–581, 1999.
1012141618202224262830050100150200250Length of dataset: nSum of Square ErroreOeXeI10121416182022242628300100200300400500600700800Length of dataset: nSum of Square ErroreOeIeX101214161820222426283050100150200250300350400Length of dataset: nSum of Square ErroreOeXeI169[23] R. T¨ut¨unc¨u, K. Toh, and M. Todd. Solving
semideﬁnite-quadratic-linear programs using sdpt3.
Mathematical programming, pages 189–217, 2003.
[24] X. Xiao, G. Wang, and J. Gehrke. Diﬀerential privacy
via wavelet transforms. IEEE Transactions on
Knowledge and Data Engineering, pages 1200–1214,
2010.
[25] J. Xu, Z. Zhang, X. Xiao, Y. Yang, and G. Yu.
Diﬀerentially private histogram publication.
International Conference on Data Engineering, pages
32–43, 2012.
170