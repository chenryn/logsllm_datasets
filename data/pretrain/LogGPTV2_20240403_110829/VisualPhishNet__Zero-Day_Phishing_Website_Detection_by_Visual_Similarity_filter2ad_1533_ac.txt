g
n
i
l
p
m
a
S
2 stages
Random
h
c
t
a
M
1
-
p
o
T
g
n
i
h
s
i
h
P
%
a
e
r
A
C
O
R
40% 81.03% 0.9879
0.8871
0.655
0.9739
0.6449
0.8517
0.8721
0.9174
0.8703
0.8526
0.9477
0.9899
75.31%
64.8%
73.91%
68.61%
78.94%
80.05%
80.19%
79.91%
78.52%
75.3%
20% 74.37%
Table 1: A summary of the ablation study. Row 1 is the fi-
nally used model, cells indicated by " " denotes the same cell
value of row 1 (VisualPhishNet).
Figure 5: The three main lists used in training, the list col-
lected from PhishTank, a subset of Alexa list, and a subset
of SimilarWeb list.
7
As shown in Table 2, when adding new websites to the training
trusted-list, the performance of the classification (indicated by the
ROC area and the top-1 match) decreased. However, this decrease
in performance was relatively slight, which indicates the robustness
of VisualPhishNet to adding a few more websites to training.
6.4 Comparison with Prior Work and Baselines
Furthermore, we compared VisualPhishNet with alternative ap-
proaches that we re-implemented on the VisualPhish dataset. In
recent years, deep learning and CNNs have been demonstrated to
achieve a breakthrough over local and hand-crafted features (used
in previous work) on many benchmarks [23]. Moreover, off-the-
shelf pre-trained CNNs features (even without fine-tuning) have
been shown to outperform local features in many tasks [29, 43, 52].
Therefore, we first compare VisualPhishNet’s embeddings to the
embeddings of two off-the-shelf CNNs: VGG16 and ResNet50. Also,
since our work is the first to utilize deep learning, the pre-trained
CNNs provide a baseline for deep learning approaches. As we show
in Table 3, VisualPhishNet outperforms these two baselines with a
significant performance gain.
To provide additional evidence, we re-implemented the methods
of phishing detection using SURF matching from [39], HOG match-
ing from [5], and ORB matching from [31] which reported that ORB
is more suited for the logo detection task than SIFT. Unlike previous
work, our approach and dataset do not rely on page-to-page match-
ing, thus, not all phishing pages have legitimate counterparts in the
training list. This limits the applicability of methods that are based
on layout segmentation and explicit block matching (such as [25]).
Nevertheless, HOG descriptors, which we compare to, were used to
represent the page layout in [5]. As shown in Table 3, the use of pre-
trained CNNs (in particular VGG16) does indeed outperform the
other baselines. In all of our experiments, similar to VisualPhishNet
training for a fair comparison, 40% of the phishing set was added
to the training list.
This analysis demonstrates that previous image matching meth-
ods are not efficient on our dataset containing phishing pages whose
contents and visual appearances were not seen in the trusted-list
Experiment
PhishTank list (155 websites)
Add SimilarWeb list (32+155 websites)
Add Alexa list (38+155 websites)
Top-1 Match ROC Area
81.03%
78.3%
78.1%
0.9879
0.9764
0.9681
Table 2: A summary of our experiments when adding more
websites from Alexa and SimilarWeb lists to training.
Method
VisualPhishNet
VGG16
ResNet50
ORB
HOG
SURF
Top-1 Match ROC Area
81.03%
51.32%
32.21%
24.9%
27.61%
6.55%
0.9879
0.8134
0.7008
0.6922
0.58
0.488
Table 3: Our experiments to compare VisualPhishNet’s per-
formance against prior methods and alternative baselines.
PhishTankListAlexa: top 500SimilarWeb: top 400Subset1Subset238 websites32 websites155 websites(a) VisualPhishNet
(b) VisualPhishNet
(c) VGG16
(d) VGG16
Figure 6: t-SNE visualizations of VisualPhishNet’s embeddings compared with the pre-trained VGG16 ones as a baseline. Fig-
ures (a) and (c) show the trusted webpages color-coded by websites. Figures (b) and (d) show the trusted webpages (blue) and
their phishing pages (red and orange) in comparison with legitimate test pages outside the trusted-lists (green).
(as shown later in subsection 7.1). Additionally, it shows that pre-
trained CNNs are not adequate and further optimization to find the
discriminating cues, as done in VisualPhishNet, is needed.
6.5 Embeddings Visualization
VisualPhishNet produces a feature vector (dimensions: 512) for each
screenshot that represents an encoding that resulted from mini-
mizing the triplet loss. In this learned feature space, same-website
screenshots should be in closer proximity compared with screen-
shots from different websites. To verify this, we used t-Distributed
Stochastic Neighbor Embedding (t-SNE) [30] to reduce the dimen-
sions of the embeddings vectors to a two-dimensional set. We show
the visualization’s results in Figure 6 in which we compare the
embeddings of VisualPhishNet with pre-trained VGG16 ones (as the
best performing baseline). We first visualized the embeddings of the
training trusted-list’s webpages categorized by websites as demon-
strated in Figure 6a and Figure 6c for VisualPhishNet and VGG16
respectively. As can be observed, the learned embeddings show
higher inter-class separation between websites in the case of Visu-
alPhishNet when compared with VGG16. Additionally, Figure 6b
and Figure 6d show the training trusted-list’s pages in compari-
son with phishing and legitimate test ones for VisualPhishNet and
VGG16 respectively. For successful phishing detection, phishing
pages should have smaller distances to trusted-list’s pages than
legitimate test pages, which is more satisfied in the case of Visual-
PhishNet than VGG16.
6.6 Distance Threshold Selection
To determine a suitable distance/similarity threshold for the binary
classification between phishing and legitimate test sets, we split
the phishing and legitimate hold-out sets to validation and test
8
sets. We computed the minimum distances of both of them to the
training trusted-list. Figure 7a shows the two density histograms
and the fitted Gaussian Probability Density Functions (PDF) of
the minimum distance for the validation sets of both classes. The
vertical line (at ≈8) represents a threshold value with an equal
error rate. Additionally, Figure 7b shows the true and false positive
rates of the test sets over different thresholds where the indicated
threshold is the same one deduced from Figure 7a, which achieves
≈93% true positive rate at ≈4% false positive rate.
6.7 Robustness and Security Evaluation
To test the robustness of VisualPhishNet, we define two models for
evasion attacks. In the first one, we study how susceptible Visual-
PhishNet is to small changes in the input (e.g. change of color, noise,
and position). In the second one, we assume a white-box attack
where the adversary has full access to the target model and the
dataset used in training (including the closest point to the phish-
ing page). In both models, we assume that the attacker’s goal is to
violate the target model’s integrity (in our case: similarity detec-
tion to the targeted website) by crafting phishing pages that show
differences from their corresponding original pages that might be
included in the trusted-list. However, we assume that the adversary
is motivated to not introduce very perceivable degradation in the
design quality for his phishing page to seem trusted and succeed in
luring users.
Performance against hand-crafted perturbations. We studied 7
types of perturbations [51] that we applied to the phishing test set
(without retraining or data augmentation): blurring, brightening,
darkening, Gaussian noise, salt and pepper noise, occlusion by
insertion of boxes, and shifting. Table 4 demonstrates an example
of each of these changes along with the corresponding relative
decrease in performance. Our findings revealed that the matching
accuracy and the ROC area dropped slightly (by up to ≈4.3% and
≈1.8% respectively) for the imperceptible noise, while it dropped
by up to ≈6.7% and ≈5% respectively for the stronger noise that we
assume that it is less likely to be used. Further improvement could
be achieved with data augmentation during training.
Adversarial perturbations. Another direction for evasion attacks
is crafting adversarial perturbations with imperceptible noise that
would change the model decision when added to the input test
points [24]. There is a lot of work towards fixing the evasion prob-
lem [3], however, adversarial perturbations are well-known for
classification models. In contrast, VisualPhishNet is based on a met-
ric learning approach that, at test time, is used to compute distances
to the training points. We are not aware of any prior adversarial
perturbation methods on similarity-based networks and therefore
we propose and investigate an adaptation of the adversarial exam-
ple generation methods to our problem by using the Fast Gradient
Sign Method (FGSM) [15] defined as:
where(cid:101)x is the adversarial example, x is the original example, y is
(cid:101)x = x + ϵ sign(∇x J(θ, x, y))
the example’s target (0 in the triplet loss), θ denotes the model’s
parameters and J is the cost function used in training (triplet loss
(a)
(b)
Figure 7: Distance threshold selection. (a) shows a density
histogram of the minimum distances between the phish-
ing (red) and legitimate (blue) validation sets to the training
trusted-list. (b) shows the true and false positive rates of the
test sets over thresholds, the vertical green line marks the
threshold from (a).
in VisualPhishNet). Adapting this to our system, we used the phish-
ing test example as the anchor image, sampled an image from the
same website as the positive image (from the training trusted-list),
and an image from a different website as the negative image. We
then computed the gradient with respect to the anchor image (the
phishing test image) to produce the adversarial example. We ex-
perimented with two values for the noise magnitude (ϵ): 0.005 and
0.01, however, the 0.01 noise value is no longer imperceptible and
causes noticeable noise in the input (as shown in Figure 8). We also
examined different triplet sampling approaches when generating
the adversarial examples, in the first one, we select the positive
image randomly from the website’s images. However, since the
matching decision is based on the closest distance, in the second ap-
proach, we select the closest point as the positive. We demonstrate
our results in Table 5 where we show the relative decrease in the
top-1 matching accuracy and the ROC AUC for each case averaged
over 5 trials as we randomly sample triplets for each example. Our
results showed that the matching accuracy and the AUC dropped
by ≈10.5% and ≈6.5% for the 0.005 noise and by ≈22.8% and ≈12.4%
for the higher 0.01 noise. Also, targeting the closest example was
similar to sampling a random positive image. In addition, we tested
an iterative approach of adding a smaller magnitude of noise to the
closest point at each step (0.002 noise magnitude for 5 steps) which
was comparable to adding noise with a larger magnitude (0.01) at
only one step.
We then performed adversarial training by fine-tuning the trained
VisualPhishNet for 3000 mini-batches. In each mini-batch, half of
the triplets were adversarial examples generated with FGSM with
an epsilon value that is randomly generated from a range of 0.003
Model
Original
Retrained
Epsilon (ϵ)
0.005
0.005
0.01
0.002
0.005
0.01
Sampling
random
closest point
random
iterative
random
random
Matching drop ROC AUC drop
10.5%
10.11%
22.81%
20.8%
2.54%
9.78%
6.47%
6.07%
12.35%
12.05%
0.07%
3.61%
Table 5: The relative performance decrease (with respect to
the original test set) of the FGSM adversarial examples.
Blurring
Sigma=1.5
Darkening
Gamma=1.3
Brightening
Gamma=0.8
Gaussian noise
Salt and Pepper
Var=0.01
Noise=5%
Occlusion
Last quarter
Shift
(-30,-30) pixels
Matching drop
ROC AUC drop
1.38%
0.17%
4.31%
1.56%
1.72%
0.36%
Sigma=3.5
Gamma=1.5
Gamma=0.5
1.9%
1.47%
Var=0.1
2.07%
1.79%
1.2%
0.12%
3.09%
0.86%
Noise=15%
Second quarter
(-50,-50) pixels
Matching drop
ROC AUC drop
4.13%
1.17%
5.68%
2.65%
6.36%
3.35%
6.71%
2.65%
6.54%
3.04%
5.34%
4.99%
6.54%
1.65%
Table 4: The studied hand-crafted perturbations applied to the phishing test set. The table shows the relative decrease in the
top-1 matching accuracy and ROC AUC with respect to the performance on the original phishing set.
9
0510152025Distance0.000.050.100.150.20DensityPhish Val.Legit Val.0246810Distance100101102Percentage (%)Test FPs rateTest TPs rateused to collect the dataset to further test against possible variations.
We then tested the trained model with this new set (without retrain-
ing), and 93.25% were correctly matched (top-5: 96%), compared to
81% (top-5: 88%) on the harder and more dissimilar dataset’s phish-
ing pages (see Appendix A for matching examples). Additionally, as
a baseline, the VGG-16 matching accuracy of this new set is 65.8%.
Alexa top-10K. To further test the false positives, we crawled the
Alexa top 10K websites (excluding the trust-list’s domains) to use
as a benign test set. Using the same trained model, the ROC AUC
of classifying this new benign set against the original phishing set