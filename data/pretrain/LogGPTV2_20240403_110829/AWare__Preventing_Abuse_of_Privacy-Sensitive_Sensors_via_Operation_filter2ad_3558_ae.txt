store among the most downloaded apps13.
The experiment took 13 hours and 28 minutes to com-
plete, and AWare passed 126,681 of the 126,686 executed
tests. Two of the failed tests were minor compatibility
issues due to attempted programmatic accesses to the plat-
form’s camera and microphone, respectively. The ﬁrst
failure was due to HappyShutter, an app that automat-
ically takes pictures when the user smiles. The second
failure was due to SnapClap, an app that automatically
takes snapshots when the user claps. By default, AWare
blocks apps from programmatically accessing privacy-
11https://www.statista.com/chart/1435/top-10
-countries-by-app-usage/
12https://source.android.com/compatibility/cts/
13The Absolute 1,000 Top Apps for Android. http://bestapps
USENIX Association
26th USENIX Security Symposium    391
sensitive sensors by intercepting API calls from running
apps and verifying if the user has indeed initiated the op-
eration. These checks provide a high level of protection.
Thankfully, as described in Appendix A, less than 1%
of the 1,000 analyzed apps require programmatic access
to privacy-sensitive sensors. However, we enhanced the
original AWare prototype to notify the user the ﬁrst time
that a programmatic access is attempted by an app. Such
notiﬁcation asks the user for an explicit authorization to
grant the app persistent access to the privacy-sensitive
sensor. The user is notiﬁed of the inherent high risk and is
discouraged from granting such type of permission. We
evaluated such feature in our ﬁeld-based study as reported
in Table 2. From our experiments, we found that only 1
of the 24 users granted persistent access to the front cam-
era for the HappyShutter app, whereas, only 2 other
users granted persistent access to the microphone for the
SnapClap app.
The other two failures were due to remote access to
the smartphone’s camera attempted by two apps, namely
Lockwatch and Prey Anti-Theft, which can capture
pictures with the front camera when someone tries to
unlock the smartphone’s screen with a wrong passcode.
However, as described in Appendix A, we anticipated this
issue and suggested the extension of the mechanisms pro-
vided by AWare also to the remote app components that
enable remote access. To validate the proposed extension,
we have developed a proof-of-concept app that receives
remote commands for the initiation of video recording
via the mobile platform’s back camera. We successfully
tested it on a Nexus 5X smartphone running the Android
OS integrating AWare.
Lastly, AWare caused another spurious false positive
with the Viber app, which attempted access to the cam-
eras and microphone at each system reboot. AWare, iden-
tiﬁed the access without a user input action and blocked
the operation after displaying an onscreen alert and log-
ging the attempted operation. After analyzing the Viber
app, we noticed that the app was testing the sensors (e.g.,
cameras and microphone) at each reboot. However, pre-
venting the Viber app from using the sensors for testing
purposes did not cause subsequent video or voice calls to
fail. Thus, we believe that blocking such attempts is the
desired behavior to prevent stealthy operations targeting
privacy-sensitive sensors.
8.3 Performance Measurements
We measured the overall system performance overhead
introduced by AWare by using a macrobenchmark that
exercises the same 1,000 apps selected from the Google
Play store via the Android UI/Application Exerciser Mon-
key14. Although software exercisers only achieve a low
code coverage, they can create events that target speciﬁc
high-level operations and generate the same sequence of
events for comparison among several testing platforms.
Indeed, the Monkey was conﬁgured to exercise apps by
generating the exact same sequence of events and target
all operations on privacy-sensitive sensors on both the
Nexus 5X and Nexus 5 smartphones when running both
the stock Android OS and the modiﬁed version of An-
droid with AWare enabled. We open-sourced the exerciser
script for the macrobanchmark on github.com15.
The experimental results reported in the ﬁrst row of Ta-
ble 3 show that the average recorded system-wide perfor-
mance overhead is 0.33% when measuring the additional
time required by AWare to handle the operation binding
construction, authorization and caching.
We also performed a microbenchmark to measure the
overhead introduced by AWare while speciﬁcally handling
access requests for operations targeting privacy-sensitive
sensors, such as the camera to take photos and videos,
the microphone to record audio, and the screen to capture
screenshots; and to measured the overhead introduced
for the authentication of app-speciﬁc widgets and their
display contexts. The overhead for operations targeting
privacy-sensitive sensors was calculated by measuring
the time interval from the time a user input action was
detected to the time the corresponding app request was
granted/denied by AWare. Instead, the overhead for the
widgets’ and display contexts’ authentication was calcu-
lated by measuring the time interval from the time the app
provided the user interface to the Window Manager to the
time such interface was rendered on the platform’s screen
by AWare. Table 3 reports the average time and stadard
deviation over 10,000 operation/rendering requests, and
the recorded overhead introduced by AWare.
Our measurements show that AWare performs efﬁ-
ciently, with the highest overhead observed being below
4%, as shown in Table 3. Notice, the experiment artiﬁ-
cially stressed each operation with unusual workloads,
and the overhead for a single operation/rendering is on
the order of microseconds. Thus, the overhead is likely
not to be noticeable by users.
Lastly, we recorded the average cache size used by
AWare to store authorized operation bindings and the ac-
tivity window call graphs, which was around 3 megabytes.
Overall, we did not observe a discernible performance
drop compared to the stock Android OS.
9 Related Work
Security-Enhanced Android [49] and Android Security
Framework [5] deploy restrictive security models based
on the Android Permission mechanism. However, such
models mainly operate at the kernel level, therefore, do
14https://developer.android.com/studio/test/
monkey.html
15https://github.com/gxp18/AWare
392    26th USENIX Security Symposium
USENIX Association
Stock Android
Nexus 5X
31,873.71
±217.82
Nexus 5
33,001.32
±109.79
Nexus 5
32,983.38
±103.76
AWare
Nexus 5X Average
Overhead
31,981.02
±207.81
System-Wide
Front Camera 15.90±1.54 14.39±1.12 16.11±1.77 15.01±1.38
Back Camera 16.08±1.32 15.68±1.87 16.44±1.06 16.37±1.91
12.36±2.01 11.86±1.99 12.65±2.15 12.32±1.85
Microphone
17.76±0.99 16.23±0.69 18.61±0.90 17.02±1.01
Screen
22.12±0.35 21.66±0.54 24.61±0.32 23.45±0.12
Widget
Table 3: AWare performance overhead in microseconds (µs). Numbers
give mean values and corresponding standard deviations after 5 indepen-
dent runs for the system-wide experiment and after 10,000 independent
requests for the device-speciﬁc microbenchmark.
3.22%
3.13%
3.01%
3.98%
2.79%
0.33%
not have the necessary information regarding higher level
events required to associate app requests to user input
actions for operations targeting privacy-sensitive sensors.
Input-Driven Access Control (IDAC) [33] mediates
access to privacy-sensitive sensors based on the temporal
proximity of user interactions and applications’ access
requests. However, if another application’s request occurs
ﬁrst after a user input event and within the given temporal
threshold, then the user input is directly used to authorize
the other applications request, no matter what operation
the application is requesting.
In What You See is What They Get [23] the authors pro-
pose the concept of a sensor-access widget. This widget
is integrated into the user interface within an applica-
tions display and provides a real-time representation of
the personal data being collected by a particular sensor
to allow the user to pay attention to the application’s at-
tempt to collect the data. Also, a widget is a control point
through which the user can conﬁgure the sensor to grant
or deny the application access. Such widgets implement
a so-called Show Widget and Allow After Input and De-
lay (SWAAID) policy. According to such policy, any
active user input, upon notiﬁcation, is implicitly consid-
ered as an indication that the user is paying attention to
the widget. Thus, after a waiting period, the application
is directly authorized to access the sensor. However, the
delay introduced for the waiting time (necessary to allow
explicit denial) may cause issues for time-constrained
applications and may frustrate users.
User-Driven Access Control (UDAC) [39, 41] proposes
the use of access control gadgets to prevent malicious
operations from applications trying to access privacy-
sensitive sensors without a user-initiated input. However,
access control gadgets deﬁne the start points for when
permissions are granted but do no provide an end limit
for the sensor’s use or control points (Section 7.1) to the
users. Moreover, each sensor’s usage should be limited
to the particular conﬁguration within which it has been
authorized by the user and should be terminated when the
application tries to continue using the sensor in a different
conﬁguration.
Researchers have also explored a trusted output solu-
tion to provide the user with an on-screen security indica-
tor to convey the application developer’s identity for the
application with which the user is interacting [6]. Such
a solution aids the user in identifying applications devel-
oped by trusted sources (i.e., Google Inc.), but it does not
provide the user with the actual application identity or
information about when and how such an application uses
privacy-sensitive sensors.
Lastly, researchers have proposed a new operating sys-
tem abstraction called object recognizer for Augmented
Reality (AR) applications [22]. A trusted object recog-
nizer takes raw sensor data as input and only exposes
higher-level objects, such as a skeleton of a face, to appli-
cations. Then, a ﬁne-grained permission system, based
on the visualization of sensitive data provided to AR ap-
plications, is used to request permission at the granularity
of recognizer objects. However, the proposed approach
applies only to AR applications which are a very small
fraction of the applications available on the app market.
Indeed, among the 1,000 applications used for our eval-
uation, fewer than 1% of them provide AR features. All
the other applications require full access to the raw data
in order to function properly.
10 Conclusion
To prevent abuse of privacy-sensitive sensors by untrusted
applications, we propose that user authorizations for oper-
ations on such sensors must be explicitly bound to user in-
put events and how those events are obtained from the user
(e.g., widgets and user interface conﬁguration), called
operation bindings. We design an access control mech-
anism that constructs operation bindings authentically
and gains user approval for the application to perform
operations only under their authorized operation bindings.
By reusing such authorizations, as long as the applica-
tion always requests that operation using the same user
input event obtained in the same way, the number of ex-
plicit user authorizations can be reduced substantially. To
demonstrate the approach, we implemented the AWare
framework for Android, an extension of the Android Mid-
dleware that controls access to privacy-sensitive sensors.
We evaluated the effectiveness of AWare for eliminat-
ing ambiguity in a laboratory-based user study, ﬁnding
that users avoided mistakenly authorizing unwanted op-
erations 93% of the time on average, compared to 19%
on average when using proposed research methods and
only 9% on average when using ﬁrst-use or install-time
authorizations. We further studied the compatibility of
AWare with 1,000 of the most-downloaded Android ap-
plications and demonstrated that such applications can
operate effectively under AWare while incurring less than
4% performance overhead on microbenchmarks. Thus,
AWare offers users an effective additional layer of defense
against untrusted applications with potentially malicious
USENIX Association
26th USENIX Security Symposium    393
purposes, while keeping the explicit authorization over-
head very modest in ordinary cases.
Acknowledgements
Thanks to our shepherd Matt Fredrikson and the anony-
mous reviewers. This research was sponsored by the
Army Research Laboratory and was accomplished un-
der Cooperative Agreement Number W911NF-13-2-0045
(ARL Cyber Security CRA). The views and conclusions
contained in this document are those of the authors and-
should not be interpreted as representing the ofﬁcial poli-
cies,either expressed or implied, of the Army Research
Laboratory or the U.S. Government. The U.S. Govern-
ment is authorized to reproduce and distribute reprints for
Government purposes not with standing any copyright no-
tation here on. The research activities of Jens Grossklags
are supported by the German Institute for Trust and Safety
on the Internet (DIVSI).
References
[1] Dendroid malware can take over your camera, record audio, and
sneak into Google play. 2014.
[2] Runtime and security model for web applications. 2015.
[3] App permissions explained-what are they, how do they work, and
should you really care? 2016.
[4] The Judy Malware: Possibly the largest malware campaign found
on Google Play. 2017.
[5] M. Backes, S. Bugiel, S. Gerling, and P. von Styp-Rekowsky. An-
droid security framework: Extensible multi-layered access control
on android. In Proceedings of the 30th annual computer security
applications conference, pages 46–55. ACM, 2014.
[6] A. Bianchi, J. Corbetta, L. Invernizzi, Y. Fratantonio, C. Kruegel,
and G. Vigna. What the app is that? deception and countermea-
sures in the Android user interface. In 2015 IEEE Symposium on
Security and Privacy, pages 931–948, May 2015.
[7] F. Chang, A. Itzkovitz, and V. Karamcheti. User-level resource-
constrained sandboxing. In Proceedings of the 4th USENIX Win-
dows Systems Symposium, volume 91. Seattle, WA, 2000.
[8] P. T. Cummings, D. Fullan, M. Goldstien, M. Gosse, J. Picciotto,
J. L. Woodward, and J. Wynn. Compartmented model workstation:
Results through prototyping. In Security and Privacy, 1987 IEEE
Symposium on, pages 2–2. IEEE, 1987.
[9] R. Dhamija, J. D. Tygar, and M. Hearst. Why phishing works.
In Proceedings of the SIGCHI Conference on Human Factors in
Computing Systems, CHI ’06, pages 581–590, New York, NY,
USA, 2006. ACM.
[10] A. P. Felt, E. Ha, S. Egelman, A. Haney, E. Chin, and D. Wagner.
Android permissions: User attention, comprehension, and behav-
ior. In Proceedings of the Eighth Symposium on Usable Privacy
and Security, SOUPS ’12, pages 3:1–3:14, New York, NY, USA,
2012. ACM.
[11] A. P. Felt, E. Ha, S. Egelman, A. Haney, E. Chin, and D. Wagner.
Android permissions: User attention, comprehension, and behav-
ior. In Proceedings of the Eighth Symposium on Usable Privacy
and Security, SOUPS ’12, pages 3:1–3:14, New York, NY, USA,
2012. ACM.
[12] A. P. Felt and D. Wagner. Phishing on mobile devices, 2011.
[13] https://en.wikipedia.org/. Robbins v. Lower merion school district
federal class action lawsuit.
[14] https://www.ftc.gov. FTC letters warn companies of privacy risks
in audio monitoring technology. 2016.
[15] http://www.nytimes.com. How spy tech ﬁrms let governments see
everything on a smartphone. 2016.
[16] http://www.scmagazine.com. Fireeye intern pleads guilty in dark-
ode case. 2015.
[17] http://www.sfgate.com. Lawsuit claims popular warriors app ac-
cesses phone’s microphone to eavesdrop on you. 2016.
[18] http://www.tripwire.com. Fireeye intern pleads guilty to selling
dendroid malware on darkode. 2014.
[19] http://www.welivesecurity.com. Krysanec trojan: Android back-
door lurking inside legitimate apps. 2014.
[20] L.-S. Huang, A. Moshchuk, H. J. Wang, S. Schechter, and C. Jack-
son. Clickjacking: Attacks and defenses. In Proceedings of the
21st USENIX Conference on Security Symposium, Security’12,
pages 22–22, Berkeley, CA, USA, 2012. USENIX Association.
[21] L.-S. Huang, A. Moshchuk, H. J. Wang, S. Schecter, and C. Jack-
son. Clickjacking: Attacks and defenses. In USENIX Security
Symposium, pages 413–428, 2012.
[22] S. Jana, D. Molnar, A. Moshchuk, A. M. Dunn, B. Livshits, H. J.
Wang, and E. Ofek. Enabling ﬁne-grained permissions for aug-
mented reality applications with recognizers. In USENIX Security,
pages 415–430, 2013.
[23] S. S. Jon Howell. What you see is what they get: Protecting users
from unwanted use of microphones, cameras, and other sensors.
In Web 2.0 Security and Privacy. IEEE, May 2010.
[24] J. Jung, S. Han, and D. Wetherall. Short paper: enhancing mobile
application permissions with runtime feedback and constraints. In
Proceedings of the second ACM workshop on Security and privacy
in smartphones and mobile devices, pages 45–50. ACM, 2012.
[25] P. M. Kelly, T. M. Cannon, and D. R. Hush. Query by image
the comparison algorithm for navigating digital im-
example:
In IS&T/SPIE’s Symposium
age databases (candid) approach.
on Electronic Imaging: Science & Technology, pages 238–248.
International Society for Optics and Photonics, 1995.
[26] W. Li, M. Ma, J. Han, Y. Xia, B. Zang, C.-K. Chu, and T. Li.
Building trusted path on untrusted device drivers for mobile de-
vices. In Proceedings of 5th Asia-Paciﬁc Workshop on Systems,
page 8. ACM, 2014.
[27] W. Li, M. Ma, J. Han, Y. Xia, B. Zang, C.-K. Chu, and T. Li.
Building trusted path on untrusted device drivers for mobile de-
vices. In Proceedings of 5th Asia-Paciﬁc Workshop on Systems,
page 8. ACM, 2014.
[28] J. Lin, S. Amini, J. I. Hong, N. Sadeh, J. Lindqvist, and J. Zhang.
Expectation and purpose: understanding users’ mental models of
mobile app privacy through crowdsourcing. In Proceedings of the
2012 ACM Conference on Ubiquitous Computing, pages 501–510.
ACM, 2012.
[29] T. Luo, X. Jin, A. Ananthanarayanan, and W. Du. Touchjacking
attacks on web in android, ios, and windows phone. In Interna-
tional Symposium on Foundations and Practice of Security, pages
227–243. Springer, 2012.
394    26th USENIX Security Symposium
USENIX Association
[30] L. Malisa, K. Kostiainen, and S. Capkun. Detecting mobile ap-
plication spooﬁng attacks by leveraging user visual similarity
perception. IACR Cryptology ePrint Archive, 2015:709, 2015.