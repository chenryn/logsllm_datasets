### 1. Transparency and Security Interfaces

The assumption that transparency is inherently beneficial for security interfaces is challenged by the lack of visual cues, which proved problematic for both programs. This absence left users confused and uncertain about how to proceed.

### 2. Password Migration Clarity

It is essential to clearly explain the process of migrating existing passwords from an unprotected state to one managed by a password manager. Despite providing instructions on how to activate the program and explaining that users must change their passwords, confusion still arose. Several users attempted to "change" their passwords at the initial login prompt for a webpage rather than using the site's Change Password interface. They mistakenly believed that since the program was installed on their computer, "changing their password" meant they could use the plug-in to enter their password on a website.

### 3. Feedback for Error Resolution

If something goes wrong, feedback should be concise, understandable, and provide guidance on how to address the problem. This is a standard usability principle. However, it may be challenging to implement because the issue might originate from the target website rather than the plug-in itself.

### 4. Tracking Protected Accounts

Users should have a way to check which of their accounts are currently protected by the password manager. Migrating to such a system is non-trivial, as users need to track which accounts have been migrated and which remain to be done. We suggest that the plug-in maintains a list of currently protected web accounts on the user’s primary computer.

Better integration with actual web pages, while technically difficult, would significantly help users. For example, when a password is incorrectly entered, users currently do not know if the problem is a typing error or an issue with the password manager. We observed users resorting to random guessing, which poses a security risk as these attempts could expose sensitive passwords. Providing accurate error messages would reduce user frustration.

### 5. User Acceptance and View of Necessity

From a usability standpoint, user satisfaction and acceptance are crucial, even though users may sometimes have no choice (e.g., when it is required for a critical part of their job). When users must make an "opt-in" decision, it is particularly important that they accept the system; otherwise, they may turn to alternative (possibly insecure) services or find ways to bypass the security mechanisms. Lack of user satisfaction and acceptance can lead to a lack of security.

We believe that helping users form a clearer mental model would significantly improve their acceptance of password managers. Currently, users are uncomfortable with the software and do not trust it because they do not understand it. They worry about the safety of their accounts and fear that the password manager will prevent them from accessing their accounts. As an intermediary, the password manager needs to appear reliable, consistent, and predictable.

To increase user acceptance, we recommend educating users about the importance of protecting passwords and how password managers can achieve this goal. While security is not the primary goal for most end-users, password managers have the advantage of potentially simplifying tasks (e.g., by requiring fewer or less-complicated passwords). Once users understand this, we expect higher acceptance.

### 6. Criteria for Usable Security Software

Whitten and Tygar highlighted issues that arise when users have inaccurate or incomplete mental models, suggesting that for security software to be usable, users must:

1. Be reliably made aware of the security tasks they must perform.
2. Be able to figure out how to successfully perform those tasks.
3. Not make dangerous errors.
4. Be sufficiently comfortable with the interface to continue using it.

We suggest two additional criteria:

5. Be able to tell when their task has been completed.
6. Have sufficient feedback to accurately determine the current state of the system.

The fifth criterion addresses a usability problem seen in both the Whitten and Tygar study and our current study: users were unable to tell whether their task had been successfully completed and sometimes incorrectly assumed success. This can cause security vulnerabilities. The sixth criterion draws on the well-known usability guideline of feedback, which is especially important for supporting accurate mental models in security interfaces. Transparency in this case can be dangerous because it leaves users free to make assumptions about the system that could lead to security exposures.

### 7. Related Work

Background on usability testing is provided in Section 3.1. Section 2 mentions a few alternate password managers (see [11] and [24] for a summary of other password managers). Here, we focus on related work, including usability tests for authentication mechanisms. Although the situation is now changing, there have been surprisingly few such academic papers.

Cranor and Garfinkel [4] and the Symposium on Usable Privacy and Security (SOUPS) reflect growing interest in this area. Zurko and Simon [34] introduced "user-centered security" in 1996. Prominent past work includes the case study of PGP 5.0 [31], which included a cognitive walkthrough inspection analysis and a lab user test involving 12 participants (see Section 6). Another early authentication usability study is the D´ej`a Vu work [8], which included interviews with 30 people on password behavior and user testing with 20 participants, focusing on the creation of password (image) portfolios and memorability.

Recent papers involving user studies on graphical passwords include Davis et al. [6], focusing on security and poor user choices, and Wiedenbeck et al. [32], focusing on memorability in the PassPoints system. Weinshall [30] introduces a challenge-response authentication protocol relying on image recognition and presents results from a small user study.

Although not specifically on passwords, Garfinkel and Miller [10] conducted a 43-subject user test of a secure email prototype, focusing on key continuity management features. They reported increased protection against certain forms of social engineering but not from attacks from new (unfamiliar) email addresses or phishing.

Related to our observations that more visibility (vs. more transparency) would enhance the usability of some security features, DePaula et al. [7] explore making relevant features of security mechanisms visible, allowing more informed user decisions.

### 8. Concluding Remarks

While the security community seeks to develop systems with stronger security, it is now commonly recognized that even the most technically secure system, if unusable, will fail in practice. Without measurements on real users, we cannot evaluate usability. Usability tests with real users should be included in the development of security systems and in research proposing new security tools and plug-ins. Both formative and summative usability tests are desirable. Formative tests guide the development and identify potential usability problems, while summative tests gather performance data and validate the usability of a system.

We have refrained from making specific suggestions for changing the interfaces of the studied password managers, as any suggestions should themselves be tested for usability. Instead, we have suggested further guidelines and requirements for the interfaces. Further work is needed to identify specific mechanisms to comply with these guidelines and address the requirements.

The goal of usability studies is to uncover problems so that they can be corrected. We have identified several usability problems with Password Multiplier and Pwd-Hash, which we believe are likely to exist in other similar password manager proposals. The next step is to identify mechanisms, if possible, by which these interface problems can be addressed. Ideally, we would then build a new interface that implements these mechanisms and conduct further usability evaluation to test if this actually improves usability.

### 9. Acknowledgements

We thank the anonymous reviewers for their comments, which helped improve this paper. We also thank the members of the Carleton’s Digital Security Group and Mary Ellen Zurko for their feedback on earlier versions of this work. The first and third authors are supported in part by the "Legal and Policy Approaches to Identity Theft" project funded by the Ontario Research Network for E-Commerce. The second author is Canada Research Chair in Network and Software Security, supported in part by the Canada Research Chairs Program and an NSERC Discovery Grant.

### Notes

1. Lack of feedback hindered users’ ability to form accurate mental models and determine if passwords were being protected.
2. One person did not try P-Multiplier; they quit after completing the tasks with PwdHash. Therefore, only partial data is available for this participant, leaving 25 participants for P-Multiplier.
3. Using a third computer would have been a better experimental design, allowing participants to complete the task, but we do not expect that this would have led to different results.
4. Technical problems caused one participant to miss the Log In and Second Login tasks with PwdHash.
5. A t-test is a ratio giving a measure of the difference between two means relative to the variability of each set. Larger ratios mean that the two groups are more distinct from each other. Significance p shows the likelihood that the results are due to chance.
6. They note [25]: "Psychological acceptability: It is essential that the human interface be designed for ease of use, so that users routinely and automatically apply the protection mechanisms correctly. Also, to the extent that the user’s mental image of his protection goals matches the mechanisms he must use, mistakes will be minimized."
7. Ideally, this hypothesis would be verified by a separate study.

### References

[1] A. Adams and M.A. Sasse. Users are not the enemy. Comm. of the ACM, 42(12):41–46, 1999.
[2] R. Anderson. Why cryptosystems fail. In Proceedings of the 1st ACM Conference on Computer and Communications Security, December 1993.
[3] J.M. Carroll, P.L. Smith-Kerker, J.R. Ford, and S.A. Mazur-Rimetz. The minimal manual. Human-Computer Interaction, 3:123–153, 1987-1988.
[4] L.F. Cranor and S. Garfinkel. Security and Usability: Designing Systems that People Can Use. O’Reilly Media, edited collection edition, 2005.
[22] C. Perfetti and L. Landesman. Eight is not enough. User Interface Engineering, 2001.
[23] K. Renaud. Evaluating Authentication Mechanisms. In L.F Cranor and S. Garfinkel, editors, Security and Usability, chapter 6, pages 103–128. O’Reilly Media, 2005.
[24] B. Ross, C. Jackson, N. Miyake, D. Boneh, and J. Mitchell. Stronger password authentication using browser extensions. In Proceedings of the 14th USENIX Security Symposium, Baltimore, August 2005.
[25] J.H. Saltzer and M.D. Schroeder. The protection of information in computer systems. Proceedings of the IEEE, 63(9):1278–1308, 1975.
[26] M.A Sasse and I. Flechais. Usable Security: Why do we need it? How do we get it? In L.F. Cranor and S. Garfinkel, editors, Security and Usability, chapter 2, pages 13–30. O’Reilly Media, 2005.
[27] B. Shneiderman. Designing the User Interface. Addison Wesley, 3rd edition, 1998.
[28] J. Spool and W. Schroeder. Testing web sites: Five users is nowhere near enough. In Proceedings of ACM Conference on Human Factors in Computing Systems (CHI 2001), 2001.
[29] R.A. Virzi. Refining the test phase of usability evaluation: How many subjects is enough? Human Factors, 34:457–468, 1992.
[30] D. Weinshall. Cognitive Authentication Schemes Safe Against Spyware (Short Paper). In Proceedings of the IEEE Symposium on Security and Privacy, Oakland, CA, May 2006.
[31] A. Whitten and J.D. Tygar. Why Johnny Can’t Encrypt: A Usability Evaluation of PGP 5.0. In Proceedings of the 8th USENIX Security Symposium, Washington, D.C., August 1999.
[32] S. Wiedenbeck, J. Waters, J.-C. Birget, A. Broditskiy, and N. Memon. Authentication Using Graphical Passwords: Effects of Tolerance and Image Choice. In First Symposium on Usable Privacy and Security (SOUPS 2005), Pittsburgh, July 2005.
[33] N. Wolff. Password Generator web site, http://angel.net/˜nic/, accessed January 2006.
[34] M.E. Zurko and Richard T. Simon. User-centered security. In Proceedings of the 1996 New Security Paradigms Workshop, pages 27–33, Lake Arrowhead, CA USA, 1996. ACM.
[5] D. Davis. Compliance defects in public key cryptography. In Proceedings of the 6th USENIX Security Symposium, July 1996.
[6] D. Davis, F. Monrose, and M. Reiter. On user choice in graphical password schemes. In Proceedings of the 13th USENIX Security Symposium, August 2004.
[7] R. DePaula, X. Ding, P. Dourish, K. Nies, B. Pillet, D. Redmiles, J. Ren, J. Rode, and R. Silva Filho. Two experiences designing for effective security. In First Symposium on Usable Privacy and Security (SOUPS 2005), Pittsburgh, July 2005.
[8] R. Dhamija and A. Perrig. D´ej`a Vu: A User Study Using Images for Authentication. In Proceedings of the 9th USENIX Security Symposium, 2000.
[9] L. Faulkner. Beyond the five-user assumption: Benefits of increased sample sizes in usability testing. Behavior Research Methods, Instruments, & Computers, 35(3):379–383, 2003.
[10] S.L. Garfinkel and R.C. Miller. Johnny 2: A User Test of Key Continuity Management with S/MIME and Outlook Express. In First Symposium on Usable Privacy and Security (SOUPS 2005), Pittsburgh, July 2005.
[11] J. Halderman, B. Waters, and E. Felten. A convenient method for securely managing passwords. In Proceedings of the 14th International World Wide Web Conference, 2005.
[12] J. Alex Halderman. Password Multiplier web site, www.cs.princeton.edu/˜jhalderm/projects/password/, accessed January 2006.
[13] A. Karp. Site-specific passwords. Technical report, Hewlett-Packard Laboratories, January 2002.
[14] J. LaPoutre. Password Composer web site, http://www.xs4all.nl/˜jlpoutre/BoT/Javascript/, accessed January 2006.
[15] Password Maker web site, http://passwordmaker.org/, accessed January 2006.
[16] R. Likert. A technique for the measurement of attitudes. Archives of Psychology, 140, June 1932.
[17] B. Myers. Why are human-computer interfaces difficult to design and implement? Technical Report CMU-CS-93-183, Carnegie Mellon University, Department of Computer Science, 1993.
[18] J. Nielsen. Usability Engineering. Boston: AP Professional, 1993.
[19] J. Nielsen and R.L. Mack. Usability Inspection Methods. John Wiley & Sons, Inc, 1994.
[20] D.A. Norman. Cognitive engineering. In D.A. Norman and S.W. Draper, editors, User Centered System Design: New Perspectives on Human-Computer Interaction, chapter 3, pages 31–62. Lawrence Erlbaum Associates, Publishers: Hillsdale, NJ, 1986.
[21] D.A. Norman. The Design of Everyday Things. Basic Books, 1988.