dicts the assumption that transparency is good for
security interfaces. The lack of visual cues was
problematic for both programs because it left users
confused and unsure about how to proceed.
3. It should be clear how existing passwords are mi-
grated (from pre-manager unprotected,
to with-
manager protection). Even with instructions on how
to activate the program and an explanation that users
must change their password, confusion arose. Sev-
eral users attempted to “change” their password at
the initial login prompt for a webpage rather than
logging on then using the site’s Change Password
interface. They felt that since the program was in-
stalled on the computer, “changing their password”
meant that they could simply start using the plug-in
to enter their password on a web site.
4. If something goes wrong, feedback should be short,
understandable, and reveal how to address the prob-
lem. This is a standard usability principle. Unfortu-
USENIX Association
Security ’06: 15th USENIX Security Symposium
13
nately, it is unclear if this would be easy to imple-
ment since the problem may stem from the target
web site rather than from the plug-in.
5. There should be a way for users to check which of
their accounts are currently protected. Migrating to
one of these systems is non-trivial since users will
need to track which accounts have been migrated
and which remain to be done. We suggest that the
plug-in keeps a list of currently protected web ac-
counts on the user’s primary computer.
Better integration with the actual web pages may be
technically difﬁcult, but it would certainly help users.
For example, when a password is incorrectly entered,
users currently do not know if the problem is a typing
error or an error in activating the manager. We observed
users resorting to random guessing in hopes that some-
thing would work – with one security risk being that
such passwords could all be exposed (see Section 5.4)
and might include sensitive passwords (which the user
resorts to trying) for unrelated accounts. Providing accu-
rate error messages would reduce user frustration.
6.2 User Acceptance and View of Necessity
From a usability standpoint, user satisfaction and ac-
ceptance is always important (although sometimes users
may have no choice, e.g., when it is required for a criti-
cal part of their job). When users must make an “opt-in”
choice, it is particularly important that users accept the
system – otherwise they may turn to an alternative (pos-
sibly insecure) service or ﬁnd ways to bypass the security
mechanisms [2, 5, 26]. Lack of user satisfaction and ac-
ceptance can lead to a lack of security.
We believe that helping users form a clearer mental
model would signiﬁcantly help with user acceptance of
the studied password managers. Currently, users are un-
comfortable with using the software (see Figure 3) and
do not trust it because they do not understand it. They
are worried about the safety of their accounts. They are
worried that they will be unable to reach their accounts
because the password manager will stand in their way.
As an intermediary, the password manager needs to ap-
pear reliable, consistent, and predictable.
To increase user acceptance, we also recommend that
along with the installation of password managers, users
be educated about the importance of protecting pass-
words, and how password managers can achieve this
goal. As with other security measures this is not a simple
task since security is not the primary goal of most end-
users; however, password managers have the advantage
of potentially simplifying users’ tasks (e.g., by requiring
them to remember fewer or less-complicated passwords).
Once users understand this, we would expect higher user
acceptance.7
6.3 Criteria for Security Software to be Usable
Whitten and Tygar highlighted issues that arise when
users have inaccurate or incomplete mental models, sug-
gesting that for security software to be usable, users
must [31]:
1. be reliably made aware of the security tasks they
must perform;
2. be able to ﬁgure out how to successfully perform
those tasks;
3. not make dangerous errors; and
4. be sufﬁciently comfortable with the interface to
continue using it.
We suggest the following two additional criteria (closely
related or supporting 2 and 3):
5. be able to tell when their task has been com-
pleted; and
6. have sufﬁcient feedback to accurately determine
the current state of the system.
The ﬁfth concerns a usability problem seen in both the
Whitten and Tygar study and our current study: users
were unable to tell whether their task had been success-
fully completed and sometimes incorrectly assumed suc-
cess. This can cause security vulnerabilities (e.g., as in-
formation believed to be secure can be left unprotected).
The sixth draws on the well-known usability guideline
of feedback, which is especially important for support-
ing accurate mental models in security interfaces. Trans-
parency in this case can be dangerous because it leaves
users free to make assumptions about the system that
could lead to security exposures.
7 Related Work
Background on usability testing is given in Section 3.1.
Section 2 mentions a few alternate password managers
(see [11] and [24] for a good summary of other pass-
word managers). Here we focus on related work includ-
ing usability tests for authentication mechanisms. Al-
though the situation is now changing signiﬁcantly, there
have been surprisingly few such academic papers.
reﬂected by Cranor
and
Garﬁnkel [4], and the Symposium on Usable Pri-
vacy and Security (SOUPS). Zurko and Simon [34]
introduced “user-centered security” in 1996. Prominent
among past work is the case study of PGP 5.0 [31],
which included a cognitive walkthrough inspection
analysis and a lab user test involving 12 participants (see
Section 6). Another early authentication usability study
is the D´ej`a Vu work [8], which included interviews with
30 people on password behaviour, and user testing with
20 participants; the focus of the user testing was on cre-
ation of password (image) portfolios, and memorability
results. Prior to this, Adams and Sasse [1] explored
password-related user behaviours and memorability
Growing interest
is
14
Security ’06: 15th USENIX Security Symposium
USENIX Association
issues through questionnaires and interviews, leading to
a number of recommendations.
Recent papers involving user studies on graphical
passwords include Davis et al. [6] with focus on se-
curity and poor user choices made by real users; and
Wiedenbeck et al. [32] with focus on memorability in
the PassPoints system, presenting results of a user study
involving 32 undergraduates. Weinshall [30] introduces
a challenge-response authentication protocol relying on
recognition of images and presents results of a small user
study.
Although not speciﬁcally on passwords, Garﬁnkel and
Miller [10] carried out a 43-subject user test of a se-
cure email prototype with focus on key continuity man-
agement features (automating certain key and certiﬁcate
management activities related to signing email); they re-
port increased protection against certain forms of social
engineering, but not from attacks from new (unfamiliar)
email addresses or from phishing.
Related to our observations that more visibility (vs.
more transparency) would enhance usability of some se-
curity features, Depaula et al. [7] explore making rele-
vant features of security mechanisms – including conﬁg-
urations, activities and implications of available security
mechanisms – visible, to allow more informed user deci-
sions.
8 Concluding Remarks
While the security community seeks to develop systems
with stronger security, it is now commonly recognized
that even the most technically secure system, if unusable,
will fail in practice. However, without measurements on
real users, we cannot evaluate usability. Usability tests
with real users should be included in not only the devel-
opment of security systems, but also in research which
proposes new security tools and plug-ins. Both forma-
tive and summative usability tests are desirable. Forma-
tive tests are conducted throughout the development of
the system to guide the development and ﬁnd potential
usability problems as they arise; these tests are typically
less formal and their goal is to highlight any problems.
Summative tests are used to gather performance data and
provide measures of usability; they are more controlled
and their goal is to validate the usability of a system or
compare its performance for different groups of users.
We have refrained from making speciﬁc suggestions
for changing the interfaces of the studied password man-
agers, as any suggestions should themselves be tested for
usability – and we have not done so. Thus until such
time, we cannot authoritatively conclude that they would
work. Instead, we have suggested further guidelines and
requirements for the interfaces. Further work is needed
to identify speciﬁc mechanisms to use in order to comply
with these guidelines and address the requirements.
The goal of usability studies is to uncover problems
so that they can be corrected. We have identiﬁed several
usability problems with Password Multiplier and Pwd-
Hash which we believe are likely to exist in other similar
password manager proposals. The next step is to iden-
tify mechanisms, if possible, by which these interface
problems can be addressed. Ideally, we would then build
a new interface that implements these mechanisms, and
conduct further usability evaluation to test if this actually
improves usability.
9 Acknowledgements
We thank the anonymous reviewers for their comments
which helped improve this paper to its present form. We
also thank the members of the Carleton’s Digital Security
Group and Mary Ellen Zurko for their feedback on ear-
lier versions of this work. The ﬁrst and third authors are
supported in part by the “Legal and Policy Approaches to
Identity Theft” project funded by the Ontario Research
Network for E-Commerce. The second author is Canada
Research Chair in Network and Software Security, and
is supported in part by the Canada Research Chairs Pro-
gram, and an NSERC Discovery Grant.
Notes
1Lack of feedback hindered users’ ability to form accurate mental
models, and to determine if passwords were being protected.
2One person did not try P-Multiplier; they quit after completing the
tasks with PwdHash. Therefore only partial data is available for this
participant. This left 25 participants for P-Multiplier.
3Using a third computer would have been a better experimental de-
sign, allowing participants to complete the task, but we do not expect
that this would have led to different results.
4Technical problems caused one participant to miss the Log In and
Second Login tasks with PwdHash
5A t-test is a ratio giving a measure of the difference between two
means relative to the variability of each set. Larger ratios mean that the
two groups are more distinct from each other. Signiﬁcance p shows the
likelihood that the results are due to chance.
6They note [25]: “Psychological acceptability: It is essential that
the human interface be designed for ease of use, so that users routinely
and automatically apply the protection mechanisms correctly. Also, to
the extent that the user’s mental image of his protection goals matches
the mechanisms he must use, mistakes will be minimized.”
7Ideally, this hypothesis would be veriﬁed by a separate study.
References
[1] A. Adams and M.A. Sasse. Users are not the enemy.
Comm. of the ACM, 42(12):41–46, 1999.
[2] R. Anderson. Why cryptosystems fail. In Proceedings of
the 1st ACM Conference on Computer and Communica-
tions Security., December 1993.
[3] J.M. Carroll, P.L. Smith-Kerker, J.R. Ford, and S.A.
Mazur-Rimetz. The minimal manual. Human-Computer
Interaction, 3:123–153, 1987-1988.
[4] L.F. Cranor and S. Garﬁnkel. Security and Usability: De-
signing Systems that People Can Use. O’Reilly Media,
edited collection edition, 2005.
USENIX Association
Security ’06: 15th USENIX Security Symposium
15
[22] C. Perfetti and L. Landesman. Eight is not enough. User
Interface Engineering, 2001.
[23] K. Renaud. Evaluating Authentication Mechanisms. In
L.F Cranor and S. Garﬁnkel, editors, Security and Us-
ability, chapter 6, pages 103–128. O’Reilly Media, 2005.
[24] B. Ross, C. Jackson, N. Miyake, D. Boneh, and
J. Mitchell.
Stronger password authentication using
browser extensions. In Proceedings of the 14th USENIX
Security Symposium, Baltimore, August 2005.
[25] J.H. Saltzer and M.D. Schroeder. The protection of infor-
mation in computer systems. Proceedings of the IEEE,
63(9):1278–1308, 1975.
[26] M.A Sasse and I. Flechais. Usable Security: Why do
we need it? How do we get it?
In L.F. Cranor and
S. Garﬁnkel, editors, Security and Usability, chapter 2,
pages 13–30. O’Reilly Media, 2005.
[27] B. Shneiderman. Designing the User Interface. Addison
Wesley, 3rd edition, 1998.
[28] J. Spool and W. Schroeder. Testing web sites: Five users
is nowhere near enough.
In Proceedings of ACM Con-
ference on Human Factors in Computing Systems (CHI
2001), 2001.
[29] R.A. Virzi. Reﬁning the test phase of usability evaluation:
How many subjects is enough? Human Factors, 34:457–
468, 1992.
[30] D. Weinshall. Cognitive Authentication Schemes Safe
Against Spyware (Short Paper).
In Proceedings of the
IEEE Symposium on Security and Privacy, Oakland, CA,
May 2006.
[31] A. Whitten and J.D. Tygar. Why Johnny Can’t Encrypt:
A Usability Evaluation of PGP 5.0.
In Proceedings of
the 8th USENIX Security Symposium, Washington, D.C.,
August 1999.
[32] S. Wiedenbeck, J. Waters, J.-C. Birget, A. Broditskiy, and
N. Memon. Authentication Using Graphical Passwords:
Effects of Tolerance and Image Choice.
In First Sym-
posium on Usable Privacy and Security (SOUPS 2005),
Pittsburgh, July 2005.
[33] N. Wolff.
Password Generator web
site,
http://angel.net/˜nic/, accessed January 2006.
[34] M.E. Zurko and Richard T. Simon. User-centered secu-
rity. In Proceedings of the 1996 New Security Paradigms
Workshop, pages 27–33, Lake Arrowhead, CA USA,
1996. ACM.
[5] D. Davis. Compliance defects in public key cryptography.
In Proceedings of the 6th USENIX Security Symposium,
July 1996.
[6] D. Davis, F. Monrose, and M. Reiter. On user choice in
graphical password schemes. In Proceedings of the 13th
USENIX Security Symposium, August 2004.
[7] R. DePaula, X. Ding, P. Dourish, K. Nies, B. Pillet,
D. Redmiles, J. Ren, J. Rode, and R. Silva Filho. Two
experiences designing for effective security. In First Sym-
posium on Usable Privacy and Security (SOUPS 2005),
Pittsburgh, July 2005.
[8] R. Dhamija and A. Perrig. D´ej`a Vu: A User Study Us-
ing Images for Authentication. In Proceedings of the 9th
USENIX Security Symposium, 2000.
[9] L. Faulkner. Beyond the ﬁve-user assumption: Beneﬁts of
increased sample sizes in usability testing. Behavior Re-
search Methods, Instruments, & Computers, 35(3):379–
383, 2003.
[10] S.L. Garﬁnkel and R.C. Miller. Johnny 2: A User Test
of Key Continuity Management with S/MIME and Out-
look Express. In First Symposium on Usable Privacy and
Security (SOUPS 2005), Pittsburgh, July 2005.
[11] J. Halderman, B. Waters, and E. Felten. A convenient
method for securely managing passwords.
In Proceed-
ings of the 14th International World Wide Web Confer-
ence, 2005.
[12] J. Alex Halderman.
Password Multiplier web site,
www.cs.princeton.edu/˜jhalderm/projects/password/, ac-
cessed January 2006.
[13] A. Karp.
Site-speciﬁc passwords. Technical report,
Hewlett-Packard Laboratories, January 2002.
[14] J. LaPoutre.
site,
http://www.xs4all.nl/˜jlpoutre/BoT/Javascript/, accessed
January 2006.
Password Composer web
[15] Password Maker web site, http://passwordmaker.org/, ac-
cessed January 2006.
[16] R. Likert. A technique for the measurement of attitudes.
Archives of Psychology, 140, June 1932.
[17] B. Myers. Why are human-computer interfaces difﬁ-
cult to design and implement? Technical Report CMU-
CS-93-183, Carnegie Mellon University, Department of
Computer Science, 1993.
[18] J. Nielsen. Usability Engineering. Boston: AP Profes-
sional, 1993.
[19] J. Nielsen and R.L. Mack. Usability Inspection Methods.
John Wiley & Sons, Inc, 1994.
[20] D.A. Norman. Cognitive engineering. In D.A. Norman
and S.W. Draper, editors, User Centered System Design:
New Perspectives on Human-Computer Interaction, chap-
ter 3, pages 31–62. Lawrence Erlbaum Associates, Pub-
lishers: Hillsdale, NJ, 1986.
[21] D.A. Norman. The Design of Everyday Things. Basic
Books, 1988.
16
Security ’06: 15th USENIX Security Symposium
USENIX Association