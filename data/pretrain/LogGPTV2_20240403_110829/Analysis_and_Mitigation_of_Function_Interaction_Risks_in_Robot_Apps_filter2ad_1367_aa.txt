title:Analysis and Mitigation of Function Interaction Risks in Robot Apps
author:Yuan Xu and
Tianwei Zhang and
Yungang Bao
Analysis and Mitigation of Function Interaction Risks
in Robot Apps
1State Key Laboratory of Computer Architecture, Institute of Computing Technology
Yuan Xu1,2,3, Tianwei Zhang4,*, Yungang Bao1,2,3
2University of Chinese Academy of Sciences
3Peng Cheng Laboratory
4Nanyang Technological University
ABSTRACT
Robot apps are becoming more automated, complex and diverse. An
app usually consists of many functions, interacting with each other
and the environment. This allows robots to conduct various tasks.
However, it also opens a new door for cyber attacks: adversaries can
leverage these interactions to threaten the safety of robot operations.
Unfortunately, this issue is rarely explored in past works.
We present the first systematic investigation about the function
interactions in common robot apps. First, we disclose the potential
risks and damages caused by malicious interactions. By investigat-
ing the relationships among different functions, we identify and
categorize three types of interaction risks. Second, we propose
RTron, a novel system to detect and mitigate these risks and pro-
tect the operations of robot apps. We introduce security policies
for each type of risks, and design coordination nodes to enforce
the policies and regulate the interactions. We conduct extensive
experiments on 110 robot apps from the ROS platform and two
complex apps (Baidu Apollo and Autoware) widely adopted in in-
dustry. Evaluation results indicated RTron can correctly identify
and mitigate all potential risks with negligible performance cost. To
validate the practicality of the risks and solutions, we implement
and evaluate RTron on a physical UGV (Turtlebot) with real-word
apps and environments.
CCS CONCEPTS
• Security and privacy → Mobile platform security; Informa-
tion flow control; Software security engineering.
KEYWORDS
Robot apps; Function interaction; Risk analysis and mitigation
ACM Reference Format:
Yuan Xu1,2,3, Tianwei Zhang4,*, Yungang Bao1,2,3, 1State Key Laboratory of
Computer Architecture, Institute of Computing Technology, 2University of
* Corresponding author: Tianwei Zhang, tianwei.zhang@ntu.edu.sg.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
RAID ’21, October 6–8, 2021, San Sebastian, Spain
© 2021 Association for Computing Machinery.
ACM ISBN 978-1-4503-9058-3/21/10...$15.00
https://doi.org/10.1145/3471621.3471854
1
Chinese Academy of Sciences, 3Peng Cheng Laboratory, 4Nanyang Techno-
logical University. 2021. Analysis and Mitigation of Function Interaction
Risks in Robot Apps. In 24th International Symposium on Research in At-
tacks, Intrusions and Defenses (RAID ’21), October 6–8, 2021, San Sebastian,
Spain. ACM, New York, NY, USA, 16 pages. https://doi.org/10.1145/3471621.
3471854
1 INTRODUCTION
The robotics technology is rapidly integrated into every aspect of
our life. Different types of robots and applications were designed
to assist humans with many dangerous or tedious jobs. A robot app
usually consists of multiple processes (a.k.a. nodes), with each one
focusing on one specific function, e.g., localization, path planning.
They interact with each other to complete the end-to-end task.
To ease the development of robot apps, many companies expose
interfaces of massive functions for their products (e.g. Ford Open XC
[15], Dji Onboard SDK [8], UR Application Builder [5]). Developers
can then use these functions to create new apps. Alternatively,
public platforms are introduced, where functions are developed in a
crowd-sourcing manner by third-party developers and distributed
through the open-source function markets. The most mainstream
platform is the Robot Operating System (ROS) [2], which provides
thousands of open-source robot functions. Functions from this
platform have been widely adopted in the research community and
many commercial products, such as Dji Matrice 200 drone [8], PR2
humanoid [21] and ABB manipulator [19].
However, these functions can be the Achilles’ Heel of robot
apps, threatening the safety of robot operations. There are two
reasons that facilitate this hazard. (1) Public platforms like ROS
allow third-party developers to share their functions. Different from
other well-developed app stores (e.g., mobile devices [3, 10], PCs
[13, 31, 32], IoT [4, 11, 28]), the ROS platform does not enforce
any security inspection over the submitted code. An adversary
can easily upload malicious functions to the platform for users to
download. (2) Function nodes in a robot app have dynamic and
frequent interactions with each other and the physical environment.
Even one malicious node can affect the states and operations of the
entire app, leading to severe privacy breach and physical damages
[48, 70]. For instance, Chrysler Corporation recalled 1.4 million
vehicles in 2015 due to a software vulnerability in its Uconnect
dashboard computers [1]. An adversary could exploit it to hack into
a jeep remotely and take over the dashboard functions.
To ensure the safety of robot apps, it is critical to protect the
interactions among various functions inside the apps. We are inter-
ested in two questions: What potential risks and security incidents
can a malicious interaction bring? How can we detect and mitigate
RAID ’21, October 6–8, 2021, San Sebastian, Spain
Yuan Xu, Tianwei Zhang and Yungang Bao
autonomous vehicle industry. RTron successfully identifies 198
high-risk interactions in these 4 apps, and mitigates them promptly
and effectively. (3) We demonstrate a practical end-to-end attack
with a physical robot (Turtlebot UGV) and environment, to demon-
strate the feasibility and severity of malicious interactions in robot
apps. We show this threat can be eliminated by RTron.
Figure 1: An example of the navigation app.
malicious interactions? Unfortunately, there are currently few stud-
ies focusing on the interactions in robot apps. Security analysis
of interactions in IoT systems have been explored [39, 41, 42, 45,
53, 60, 61, 67, 83, 88]. As robot apps have more complex and dis-
tinct features, it is hard to apply the above methods to the robot
ecosystem, as discussed in § 8.
In this paper, we present the first study to explore the function
interactions in common robot apps from the perspective of security
and safety. We make three contributions to answer the above two
questions. First, we analyze potential risks from those interactions
in common robot apps. We classify these risks into three types. (1)
General Risk: it happens when multiple function nodes share same
states, and malicious nodes attempt to compromise the states by
sending wrong messages. (2) Robot-Specific Risk: this is caused by
the conflict between the robot’s velocity and the frame rate of the
image recognition function. (3) Mission-Specific Risk: this refers to
the violation of users’ expectation regarding the safe and secure
behaviors of the robot system. We provide detailed analysis and
examples to show the possible consequences of each risk.
Second, we introduce RTron, a novel system to detect and miti-
gate risks caused by suspicious interactions in robot apps. The core
of RTron is a set of coordination nodes, which are used to regulate
the interactions and enforce security policies. We design a coor-
dinate node with some security policies to mitigate each type of
risks. Specifically, RTron includes two stages. At the development
stage, it generates the interaction graph from the source code of
the robot app, and helps developers discover all high-risk function
nodes, which may trigger potential malicious interactions. Based on
the generated risk information, RTron deploys coordination nodes
along with these high-risk function nodes. This is achieved without
changing the original function node. At the operation stage, RTron
deploys a security service to keep monitoring all the information
from the coordination nodes. A visualized interface is provided to
end users to observe the high-risk interactions. If a risk occurs, the
corresponding coordination node will enforce the desired policy
configured by users during the app launch to mitigate it.
Third, we conduct extensive experiments to evaluate the effec-
tiveness, efficiency and practicality of RTron. (1) We select 110
robot apps from the ROS platform, covering 24 robots of 4 types.
RTron can correctly identify all potential risks from three types of
vulnerable interactions, with negligible overhead at both the offline
and online stages. (2) We perform large-scale evaluations on more
complex and practical robot apps: we select 2 apps from the ROS
platform for the home and autorace scenarios, each containing 10
functions to perform 6 tasks; we also deploy 2 self-driving apps
(Autoware [6] and Apollo [7]), which are widely adopted in the
2 BACKGROUND & THREAT MODEL
2.1 Interaction in Robot Apps
Robot apps run on the embedded computer of a robot device to
interpret sensory data collected from the environment, and make
the corresponding action decisions. The workflow of a robot app can
be represented as an interaction graph, where each node represents
a certain function, and edges represent the dependencies of the
functions in this app. Figure 1 shows a navigation app as an example.
This robot app is composed of three major processing stages [76]: (1)
Perception: the robot extracts estimated states of the environment
and the device from raw sensory data. It uses the Localization
node to determine the device position, and the CostmapGen node to
model the surroundings. (2) Planning: the robot determines the long-
range actions. It uses the Path Planning node to find the shortest
path, and the Exploration node to search for all accessible regions.
The Exploration node also exposes an external service for users
to launch a navigation mission. (3) Control: the robot processes the
execution action and forwards these motions to the actuators. It uses
the Path Tracking node to produce velocity commands following
the planned path, and the Velocity Driver node to convert the
velocity to instructions for the motor to drive the wheels.
One big feature of robot apps is the high interactions among
various function nodes in the workflow. Based on the triggered
events, the interactions can be classified into two groups:
Direct interaction (solid line). This denotes the interaction be-
tween two functions (ellipses), which are directly connected in the
workflow and sharing common robot states (squares). Robot states
are defined as the collection of all aspects and knowledge of the
device that can impact future behaviors [78], e.g., position, orienta-
tion, explored maps. The computation of one function can change
some robot states, which will affect the computation of another
function. For instance, in Figure 1, the action of Path Planning
is triggered by the event that Localization generates the robot’s
current position and orientation. Then the two nodes have direct
interaction over the robot states of position and orientation.
Indirect interaction (dotted line). This refers to the dependency
of two functions, which are not connected in the workflow, but can
interact with each other via the environmental context. One node in
the app can issue actions to change the environmental context (e.g.,
obstacles, space, etc.), which will further influence another node.
In the navigation app, the functions in the Control stage generate
commands to control the robot to change the physical environment.
This triggers the functions in the Perception to conduct new compu-
tations. For instance, the map created by the CostmapGen function
depends on the action from the Path Tracking function. As a
result, these two function nodes are indirectly interacted, although
they are not directly connected in the workflow.
Note that Figure 1 is just an abstract interaction graph. An actual
robot app can have a very complex interaction graph with large
2
LocalizationExploreMapGlobalMapPosePathExplorationPathTrackingVelocityDriverPathPlanningLocalMapCostmapGenVelocityGoalSENSORSPERCEPTIONPLANNINGCONTROLACTUATORSNavigation AppENVAnalysis and Mitigation of Function Interaction Risks
in Robot Apps
RAID ’21, October 6–8, 2021, San Sebastian, Spain
Figure 2: The relationship among the app, repo, package and
function in ROS
numbers of nodes and interactions. Figure 15 in Appendix A gives
an interaction graph for a real-world home-based robot app.
2.2 Robot App Platform
In robotics, the most popular app platform is Robot Operating
System (ROS) [2]. Both the research community and industry widely
adopt ROS as the foundation or the testbed for their apps, such as Dji
Matrice 200 drone [8], PR2 humanoid [21] and ABB manipulator
[19]. In this paper, we mainly focus on the ROS platform. Our
methods and conclusions can be generalized to other platforms as
well.
The ROS platform offers two kinds of services. First, it provides
robot core libraries, which act as the middleware between robot apps
and hardware. These core libraries support hardware abstraction,
message passing mechanisms and device drivers for hundreds of
sensors and motors. Second, the ROS platform maintains thousands
of robot code repositories (a.k.a. repos) for distributed version control,
code management and sharing. As shown in Figure 2, the platform
stores a list of ROS indexes (i.e. repo names), and each index is
linked to the source code of this repo in the hosting site (e.g. GitHub,
BitBUcket, GitLab). A repo commonly consists of one or multiple
ROS packages. The developers can add their repos to the ROS
platform through sending a pull request to the ROS maintainer. If
it succeeds, both the repos and included packages can get specific
indexes for other developers to download and use.
A robotic function can be implemented by one or multiple pack-
ages. It means one repo can have two or more functions. These
functions are then integrated with functions from other repos or cus-
tomized by users to form a ROS application. This work shows that
untrusted repos from the ROS platform can significantly threaten
the robot apps built from them.
Development and operation of robot apps. Figure 3 illustrates
the key concepts and components in the lifecycle of robot app
development and operation. First, the design of the app is decom-
posed into several necessary functions. Among them core functions
(white ellipses) need to be customized by the developer, while non-
core functions (black ellipses) can be downloaded from ROS code
repos (❶). Then the developer uses ROS core libraries to organize
these functions as an app workflow (❷) and deploys the app to the
robot (❸). Each function is abstracted as a ROS node and connected
with others through ROS Topics. The ROS topics are many-to-many
named buses that store the robot or environment states. Each topic
is implemented by the publish-subscribe messaging protocol: some
Figure 3: The lifecycle of robot app development (blue parts)
and operation (green parts).
nodes can subscribe to a topic to obtain relevant data, while some
nodes can publish data to a topic.
The robot communicates with end users through ROS Services.
The ROS services are a set of interfaces of the robot app exposed
to end users. Each service is implemented by the Remote Procedure
Call (RPC) protocol and allows users to launch tasks or adjust
function parameters. Once the robot receives a mission from the
user’s phone (❹), it executes the mission and interacts with the
surrounding environment at runtime (❺). The user will receive the
notification from the robot when all tasks are completed (❻).
2.3 Threat Model and Problem Scope
In this paper, we consider a threat model where some nodes of a
robot app are untrusted. Those adversarial nodes aim to compro-
mise the robot’s operations, forcing it to perform dangerous actions.
This can result in severe security and safety issues to machines,
humans and environments [43, 49, 50].
This threat model is drawn from four observations. First, the
ROS platform is open for everyone to upload and share their code
repos. Different from app stores of other ecosystems [3, 4, 10, 11, 13,
28, 31, 32], the ROS platform does not have any security check over
the submitted code. As a result, an adversarial developer can insert
malicious code to a repo and publish it to the ROS platform for