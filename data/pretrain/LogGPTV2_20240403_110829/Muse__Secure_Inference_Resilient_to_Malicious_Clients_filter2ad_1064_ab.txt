• The protocol should evaluate the network iteratively by
applying subprotocols for evaluating linear and non-linear
layers.
2Our attack also supports networks with average pooling layers, as these
are linear layers, but don’t contain any weights that need to be recovered
USENIX Association
30th USENIX Security Symposium    2203
• For each subprotocol, the input and output of the client and
the server should be secret shares of the actual layer input
and output, respectively.
• The client’s ﬁnal output should be the plaintext output of
the ﬁnal linear layer.
A number of two-party and multi-party secure inference pro-
tocols have these properties [Moh+17; Liu+17a; Ria+18;
Juv+18; Cha+19; Mis+20; Rat+20].
Remark 2.1 (Other semi-honest protocols). Our attack does
not affect semi-honest secure inference protocols based on
fully-homomorphic encryption (FHE) [Gil+16; Cho+18;
Bru+18; San+18; Dat+19] or garbled circuits (GC) [Rou+18;
Bal+19; Ria+19]. However, this does not immunize these
protocols against other kinds of malicious client attacks:
• FHE-based protocols use noise ﬂooding [Gen09a] to hide
the server’s model. This technique is inherently semi-honest
as it requires the pre-existing noise to be honestly bounded;
if this does not hold, the noise term can reveal information
about the server’s model despite noise ﬂooding.
• GC-based protocols use oblivious transfer (OT) [Rab81]
to transfer labels for the client’s input. However, if this OT
is only semi-honest secure, a malicious client can attack it
to learn both labels for the same input wire, which breaks
the privacy guarantees of the garbled circuit, and leads to a
leak of the server’s model.
2.2 Attack strategy
Notation. Let NN be an (cid:96)-layer network convolutional neu-
ral network that classiﬁes an image into one of m classes.
That is, NN consists of (cid:96) matrices M1, . . . ,M(cid:96) so that NN(x) =
M(cid:96)(ReLU(. . .M2(ReLU(M1(x))))) where M(cid:96) ∈ Rm×t and the
image of M(cid:96) is Rm. We denote by NNi(x) the partial eval-
uation of NN up to the i-th linear layer. That is, NNi(x) :=
Mi(ReLU(. . .M2(ReLU(M1(x))))). Below we denote by e j
the j-th unit vector (the vector whose j-th entry is 1, and
other entries are 0). Finally, for simplicity of exposition, we
assume that biases are zero,3 and that the network contains
only fully-connected layers; for details on how to recover
convolutional layers, see Remark 2.2 and Appendix A.
Prelude. Our attack proceeds in a bottom-up fashion: the
client ﬁrst recovers the parameters of the last linear layer
M(cid:96) ∈ Rm×t, and then iteratively recovers previous layers. We
describe the subroutine for recovering the last layer in Sec-
tion 2.2.1, and then describe our subroutine for recovering
intermediate layers in Section 2.2.2. In both subroutines, the
client sets its initial input to the network be the all-zero vector.
2.2.1 Recovering the last layer
At a high level, to recover M(cid:96), the client proceeds column-
by-column as follows: for each j ∈ [t], the client provides
3One can handle a bias b in a linear layer L(x) = Mx + b by treating it as
= M||b, so that the linear
a simply another column in the modiﬁed matrix M(cid:48)
layer becomes L(x) = M(cid:48) · (x||1).
as initial input the all-zero vector, and then honestly follows
the secure inference protocol until the (cid:96)-th layer. At the (cid:96)-th
layer, however, the client malleates its share of the input to
M(cid:96) so that it becomes e j. This means that result M(cid:96) · e j is the
j-th column of M(cid:96). We illustrate this graphically for the ﬁrst
column below.
x(cid:96)−1(cid:122)(cid:125)(cid:124)(cid:123)(cid:20)0
(cid:21) malleate
+e1−−−−−→
x(cid:48)
(cid:96)−1(cid:122)(cid:125)(cid:124)(cid:123)(cid:20)1
(cid:21) query M(cid:96)
−−−−−→
0
0
(cid:122)
(cid:125)(cid:124)
(cid:20)−0.1
M(cid:96)
−1.1
ﬁrst column of M(cid:96)
(cid:123)
(cid:21)(cid:20)1
(cid:21)
0.2
1.2
=
0
(cid:122) (cid:125)(cid:124) (cid:123)
(cid:20)−0.1
(cid:21)
−1.1
2.2.2 Recovering intermediate layers
The foregoing algorithm works for recovering the last layer
because the client can directly read off M(cid:96) column-by-column
by “solving” a linear system. However, this approach does not
work as is for recovering the weights of intermediate linear
layers, as we now demonstrate by considering the case of
recovering the (cid:96)− 1-th linear layer M(cid:96)−1. We then describe
how to resolve the issues that arise. (The case of the remaining
layers follows similarly).
Problem 1: Intervening ReLUs are lossy and non-linear.
ReLUs between M(cid:96)−1 and M(cid:96) disrupt the linearity of the
system, preventing the use of linear system solvers.
Solution 1: Force ReLUs to behave linearly. To resolve
this issue, we recall the fact that ReLU behaves like the iden-
tity function on inputs that are positive. We use malleability
to exploit this property and force the remaining M(cid:96)(ReLU(·))
computation to behave linearly, which means that we can once
again solve a linear system to learn information about M(cid:96)−1.
In more detail, let (cid:104)y(cid:96)−2(cid:105)C be the client’s share after ap-
plying M(cid:96)−1. The client malleates (cid:104)y(cid:96)−2(cid:105)C by setting it to
(cid:104)y(cid:48)
(cid:96)−2(cid:105)C := (cid:104)y(cid:96)−2 + δ(cid:105)C, where δ is a constant vector whose
elements are all greater than the magnitude of the largest ele-
ment in y(cid:96)−2.4 This forces all entries of y(cid:48)
(cid:96)−2 to be positive,
which means ReLU acts like the identity function. Then, after
evaluating the ReLU and obtaining (cid:104)x(cid:48)
(cid:96)−1(cid:105)C, the client “un-
does” the malleation by subtracting δ. The following equation
provides a graphical illustration of this process.
(cid:125)(cid:124)
(cid:122)
(cid:20)−0.1
M(cid:96)−1
−1.1
(cid:123)
(cid:21)(cid:20)1
(cid:21)
0
0.2
1.2
(cid:122) (cid:125)(cid:124) (cid:123)
(cid:20)−0.1
y(cid:96)−2
−1.1
(cid:21) malleate
−−−−−→
δ := 10
y(cid:48)
(cid:96)−2
(cid:122)(cid:125)(cid:124)(cid:123)
(cid:20)9.9
(cid:21)
8.9
ReLU−−−→
x(cid:48)
(cid:96)−1
(cid:122)(cid:125)(cid:124)(cid:123)
(cid:20)9.9
(cid:21) unmalleate
−−−−−−→
8.9
(cid:122) (cid:125)(cid:124) (cid:123)
(cid:20)−0.1
(cid:21)
x(cid:96)−1
−1.1
=
Problem 2: Underconstrained linear system. While the
foregoing technique enables us to force the network to behave
like a linear function, we have no guarantees that the resulting
linear system is solvable. Indeed, neural networks necessarily
map a high-dimensional feature to a low-dimensional classiﬁ-
cation, and so the resulting “linearized” neural network must
be lossy. The following ﬁgure illustrates this graphically:
4Note that since model weights are usually small (in the range [−1,1]),
(cid:96)−2
we can set δ to be a large value (say, ∼ 10) to ensure that all entries of y(cid:48)
are positive.
2204    30th USENIX Security Symposium
USENIX Association
(cid:122) (cid:125)(cid:124) (cid:123)
(cid:20)1
(cid:21)
M2
3
4
2
(cid:122)
(cid:20)a1
b1
·
(cid:125)(cid:124)
M1
a2
b2
(cid:123)
(cid:21)
a3
b3
(cid:122)
(cid:20) a1 + 3b1
2a1 + 4b1
=
(cid:125)(cid:124)
M3
a2 + 3b2
2a2 + 4b2
(cid:123)
(cid:21)
a3 + 3b3
2a3 + 4b3
Here, M1 and M2 are the ﬁrst and last layers of the network,
respectively. We have used the technique in Section 2.2.1 to
recover M2, and now must recover M1. If we try to do this
by querying M3, we get three (independent) equations for six
variables, which is insufﬁcient:
3a1 + 6b1
 and M3e2 =
M3e1 =
0
0
3a2 + 6b2
0
0
 and M3e3 =
0
0
3a3 + 6b3
Solution 2: Masking variables. The issue is that M3 does
contain sufﬁcient information to recover M1, but querying it
naively loses that information. To resolve this, we use mal-
leability again: the client uses the intervening ReLUs to “zero”
out all but m entries of intermediate state, as follows:
1
 =
1
0
M1 ·
(cid:20)a1 + a2
b1 + b2
(cid:21) malleate
+ mask−−−−−→
(cid:20)a1 + a2 + δ
b1 + b2 − δ
(cid:21) ReLU +
−−−−−−→
unmalleate
(cid:20)a1 + a2
(cid:21)
0
Now, the client can obtain M2 · [a1 + a2,0], and can solve the
resulting equations to learn a1 and a2. It can then repeat this
process with different queries and “masks” to learn all of M1.
For a detailed description of our algorithm, see Ap-
pendix A.
Remark 2.2 (recovering convolutional layers). To recover
the kernel of a convolutional linear layer, we can reuse the
foregoing ideas, but must change how we malleate the input to
the target layer: we instead sample a random input and query
the kernel via linearly independent columns of (the im2col
transform of) this input. See Appendix A for details. Note that
for simplicity of exposition, our description in Appendix A
assumes that the number of channels and number of ﬁlters in
each convolutional layer are both 1, and that the number of
parameters in the kernel is less than the number of classes;
these restrictions are easy to lift by adapting the masking
techniques from above.
2.3 Efﬁciency and evaluation
Efﬁciency. Given a neural network where the i-th linear
layer has dimension mi × ti, and the number of classes is
m(cid:96) = m, the foregoing algorithm learns the model parameters
m (cid:101)·ti queries. Furthermore, the complexity of
in just ∑(cid:96)
our attack depends only on the number of parameters, and
not on other factors such as the depth.5 (This is not the case
for other model-extraction attacks, which fail when extracting
deep models that have few parameters.)
i=1(cid:100) mi
5Note that any implementation of our attack will have to contend with
errors due to limited ﬂoating point precision, but our experiments did not
encounter such failures.
Evaluation.
In Table 2, we compare our work to the state-
of-the-art prior work on model extraction [Car+20], which
does not rely on the existence of a secure inference protocol
(and hence does not exploit properties of such protocols). Our
experiments match the query complexity derived above.
network
dimensions
FC-only networks
784-128-1
784-32-1
10-10-10-1
10-20-20-1
40-20-10-10-1
80-40-20-1
80×5-40-20-1
1000-500-1
1000-500-10
2000×2-1000-100
1000×2-40×8-20-10
# params
# queries
speedup
us
[Car+20]
100,480
25,120
210
620
1,110
4,020
29,620
500,500
505,000
6,100,000
1,052,200