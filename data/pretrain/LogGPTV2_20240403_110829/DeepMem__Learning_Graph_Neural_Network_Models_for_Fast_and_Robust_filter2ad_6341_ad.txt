in the training phase, and this guarantees that the detection model
never sees the testing set in the training phase.
In each training iteration, we randomly select an image from the
training dataset for training. To determine whether the model is
fully trained, we monitored the loss and accuracy on the validation
dataset during the training process. When the loss reaches a rela-
tively small and stable value, we deem the model as fully trained
or it reaches its learning capacity. Dropout layers [35] are added to
prevent the over-fitting problem. We set the keep probability to 0.8
in the training phase, and to 1 in the evaluation phase and testing
phase.
By default, the experiments are all performed under the same
parameter setting as described in Table 3.
3
3
Value
Parameters
Layers of σ
Layers of ψ
Optimizer
Learning Rate
Propagation Iteration T
Input Vector Dimension
Embedding Vector Dimension
keep_prob
Table 3: Default Parameters of Experiments.
Adam Optimizer
3
64
64
0.8
0.0001
4.4 Detection Accuracy
We measured the accuracy using a number of different metrics,
including precision, recall, and F-score [24]. For each object type,
precision calculates the correctly classified samples against all de-
tected samples. Recall calculates the correctly classified samples
against all labeled samples in this type. F-score is the harmonic
mean of precision and recall.
Table 2 shows the detection results of various kernel object types
on raw memory images by training for 13 hours. We can see from
the result, the overall recall rate is satisfactory, ranging from 98.304%
to 99.979%. Most large kernel objects (≥ 120 bytes) have over 98%
precision rate. Important kernel object types _EPROCESS, _ETHREAD
both achieve over 99.6% recall rate, and over 99.5% precision rate.
Also, we observed a tendency that larger objects achieve better
recognition results. The reason is that for small objects, there are
fewer nodes and pointers inside them. Then, the chance of obtaining
stable key nodes is lower.
4.5 Robustness
For the evaluation of robustness, we performed three experiments.
The first experiment is pool tag manipulation, with the aim to
evaluate its impact on signature scanning tools and DeepMem. The
second experiment is pointer manipulation, with the aim to evaluate
if DeepMem is still effective in DKOM process hiding attacks. The
third experiment is a general yet more destructive attack which is
to randomly mutate arbitrary bytes in memory, with the aim to see
whether our approach is resistant to various attack scenarios, and
to what extent it can tolerate random mutations.
4.5.1 Pool Tag Manipulation. To perform pool tag manipulation,
we change the 4 bytes pool tags [33] of each object to random values
in the memory dump file. Using the manipulated dump, we then
test the effectiveness of our approach and several Volatility plugins.
In our experiment, we randomly select 10 memory dumps as the
testing set, and take scanning _FILE_OBJECT object as an example.
As shown in Table 4, the filescan plugin of Volatility cannot cor-
rectly report _FILE_OBJECT objects. Its recall rate drops to a small
value of 0.0082%. The reason is that filescan first needs to search
for the pool tag of _FILE_OBJECT in the entire memory dump. As
a result, most of the _FILE_OBJECT objects are not reported.
As a comparison, DeepMem works normally in evaluation re-
sults. It can achieve a recognition precision of 99.1% and recall
of 99.05%. The reason is that DeepMem examines every byte of a
memory dump to detect objects, rather than merely rely on pool tag
constraints to locate objects. Hence, without valid pool tags, Deep-
Mem can still detect objects in the memory dump. This indicates
that approaches based on hard constraint matching are not robust.
In contrast, our approach is based on soft features automatically
learned from raw object bytes, which can capture a more robust
representation of an object.
Method Avg. #TP Avg. #FP Avg. #FN Precision% Recall%
0.0082%
filescan
DeepMem
99.05%
Table 4: Results of _FILE_OBJECT Pool Tag Manipulation
3661.8
34.9
100%
99.1%
0.0
32.9
3627.2
0.3
4.5.2 DKOM Process Hiding. This DKOM attack is to hide a ma-
licious process by unlinking its connections to precedent and an-
tecedent processes in a double linked list. In this case, list traversal
related tools, like the pslist plugin in Volatility, will fail to discover
the hidden process through this broken link list.
In our experiment, we randomly choose 20 memory dumps as a
testing set, and then manipulated the value of the forward link field
in each _EPROCESS object to random value. In Table 5, we can see
that the Volatility plugin pslist fails to discover most _EPROCESS
objects except the first one in each dump. Since the _EPROCESS
list is broken by the manipulation, it cannot traverse through the
double linked list to find other processes. In contrast, DeepMem
can still find 99.77% _EPROCESS objects with 100% precision.
Method
pslist
DeepMem
Avg. #TP Avg. #FP Avg. #FN Precision% Recall%
1.21%
99.77%
1.05
86.55
100%
100%
85.7
0.2
0.0
0.0
Table 5: Results of DKOM Process Hiding Attacks
4.5.3 Random Mutation Attack. It is hard to simulate all kinds
of DKOM attacks. Therefore, we take a simple approach to find
out how much DeepMem can tolerate DKOM attacks: we gradually
increase the number of bytes to be manipulated in random positions
of kernel objects, including the pointer and non-pointer fields, and
evaluate the precision and recall rate at different mutation levels. In
Section 4.5.1 and Section 4.5.2, we have already demonstrated how
DeepMem works on memory dumps with small changes. In this
section, we will show how DeepMem perform when large bytes are
changed.
Even if an attacker largely changes the contents and topologies
in kernel objects of the operating system, DeepMem can be used
in this scenario without retraining the detection model with the
samples from that attack. We just need to lower the prediction
threshold δ. However, in extreme case, if the threshold is set to a
very small value, then most addresses in candidate address set S
will be reported, causing many false positives and low precision. To
guarantee a high precision while getting a recall as high as possible,
it is better to report the objects cross-validated by at least two
voters. This can be achieved by setting the threshold δ of prediction
function f (s, c) to 1 (If there are more than two voters, the reward
function γ(s, c) = |L(s, c)| − 1 ≥ 1, the prediction confidence > 1.
See Equation (8)).
We evaluate the detection results by mutating different amount of
bytes in objects for _EPROCESS and _ETHREAD objects, with thresh-
old δ is set to 1. We can see from Figure 5, as the number of mutated
bytes increases, the precision rate remains stable at around 97% -
98% with tiny perturbations. Recall rate curve stays at a high rate
at first, then drops down as the number of mutated bytes further in-
creases. Specifically, for _EPROCESS, it achieves over 97% precision
rate at all mutation levels, and 100% recall rate before 20 bytes are
changed. Our model can tolerate up to 50 bytes random mutation,
without causing the precision and recall rate drop significantly.
For _ETHREAD, our model can tolerate up to 30 bytes random muta-
tion. We can see when we set the threshold δ to a low value 1, the
precision rate does not drop significantly.
The causes of the high precision and recall rate are twofold. First,
the neural network itself can inherently tolerate small mutations
due to the robust features it learns from the training data. Second,
even when deep model incorrectly predicts the labels of some nodes
of an object, the remaining nodes can make cross-validation and
collectively conclude the presence of an object. The recall rate
indeed drops significantly with larger mutations. However, these
larger mutations will likely cause system crashes or instability, and
therefore might be rarely seen in real-world attacks.
4.6 Efficiency
To investigate the efficiency of DeepMem, we measure the time
allocations in different phases. We consider three types of time
consumption: GNN model training time Tt , memory graph con-
struction time Tд and object detection time Td. 1) The training time
Tt measures the time from inputting raw labeled training dataset
dumps to obtaining a fully trained model with a small and stable
prediction loss. 2) The memory graph construction time Tд mea-
sures the time from inputting a raw memory dump to obtaining
matrix representation of the memory graph. 3) The object detection
time Td measures the time from inputting a memory graph ma-
trix to obtaining detected kernel object set of a certain object type.
The experiment settings of training and detection are described in
Section 4.1.
In the training phase, we utilize the GPU in the computing center
to train the model because the major computation of training is
matrix-based and GPU can accelerate the matrix computation. We
train the model for 13 hours for one object type. After training, the
model can be saved to disk and deployed in a desktop computer(with
or without GPU). In our detection experiment, we copy the model
to a moderate desktop computer without GPU. On average, it takes
79.7 seconds to construct the whole memory graph for one memory
(a) Random Mutation Attack of _EPROCESS Object
(b) Random Mutation Attack of _ETHREAD Object
Figure 5: Random Mutation Attack
dump of 1GB size, and 12.73 seconds to recognize the objects of a
certain type in it, as shown in Figure 6. This detection time can be
accelerated by using GPU. In our computing center, the detection
time can be reduced to about 7.7 seconds.
DeepMem is efficient for two reasons. First, it turns a memory
dump into a graph structure denoted as large node matrices and
edge matrices, which is especially suitable for fast GPU parallel
computation. Second, since it converts the memory dump into an
intermediate representation (memory graph), and performs the
detection of various object types on this graph, there is no need to
scan the raw memory multiple times to match the various set of
signatures for different object types.
Time Measurements
Std Dev
Training Tt (per object type)
Training
Detection Graph Construction Tд (per dump)
Object Detection Td (per type)
Table 6: Time Consumption at Different Phases. Training is
performed on the computing center. Detection is performed
on a desktop computer. The setting is in Section 4.1
N/A
6.64
1.24
Mean
13 Hours
79.7 Sec
12.73 Sec
4.7 Understanding Node Embedding
We plot the embedding vectors of nodes using t-SNE visualization
technique [22] in Figure 6. Each node embedding vector in multi-
dimensional space is mapped as a point in two-dimensional space.
We collect embedding vectors of different object types at the output
layer of the embedding network before they are fed into the classi-
fier network. Figure 6 shows the distribution of embedding vectors
in 2D space, where different colors are used to denote different
types of node labels. To clearly show plenty of embeddings of differ-
ent types, we only plot the first 10 key nodes for each object type.
We expect to observe that points of the same colors locate near
each other, and different colors locate far from each other. From the
figure, we can see that the visualized results meet that expectation.
These embeddings can capture the intrinsic characteristics of nodes,
and different types of nodes are well separated.
4.8 Impact of Hyperparameters
We plot ROC curves [14] of detection results to show the impact
of the different hyperparameters of our model. We adjust three
parameters: the propagation iteration timesT , the embedding vector
size, and the embedding depth of embedding network σ. ROC curve
shows the trade-off between sensitivity (true positive rate) and
specificity (false positive rate) of the object detector.
Figure 7(a) shows the performance of the _FILE_OJBECT detec-
tor by tuning the iteration parameter T of node embedding network
ϕ. We can see that the ROC curve of T = 3 is nearest to the upper
left corner, followed by the curves of T = 2 and T = 1. The trend
demonstrates the importance of topological information propaga-
tion in object detection. With more information collected through
propagation, the prediction ability of the object detector is further
improved.
Figure 7(b) shows the performance of _FILE_OBJECT detector
by tuning embedding vector size of node embedding network ϕ.
In the figure, the ROC curve with larger embedding size is closer
to the upper left corner. It shows that larger embedding vector
size is more expressive and better approximate the data intrinsic
characteristics. However, this is also a trade-off between learning
ability and training time. In practical usages, for the same level of
learning ability, a smaller embedding size is preferred for faster
training and testing. The determination of such embedding size
should be a combined consideration of the task complexity and
training effort.
Figure 7(c) shows the performance of _FILE_OBJECT detector
by tuning embedding layers depth of σ. In the figure, the ROC
curve with more layers is closer to the upper left corner. It indicates
that the learning ability of deeper neural network is stronger than
shallower networks. Enlarging the number of layers and embedding
size is a preferred solution for training complex object types.
5 DISCUSSION
In this section, we discuss several limitations and potential issues