Iran 2013/03 [122]
Iran 2013/04a [123]
Iran 2013/04b [123]
Iran 2014 [124]
Kazakhstan 2012a [125]
Kazakhstan 2012b [125]
Philippines 2012 [126, 127]
Saudi Arabia 2007 [63]
Syria 2011 [63]
Syria 2012/12 [128]
Thailand 2006 [63]
Tunisia 2009a [63]
Tunisia 2009b [63]
Turkey 2014 [94]
UAE 2012 [129]
Tor
Tor
SSL
Tor
SSL?
Tor
Tor
Tor etc?
SSL
Tor etc.
Tor etc.
Tor
non-HTTP
encryption
Tor
Tor
Tor
Tor
Tor
Tor
Tor
Tor
non-web
SSL+
Tor etc.
Tor
Check requests for Tor (‘.torproject.org’) then Send TCP reset
Check whether server IP is in blacklist then Timeout
Get Tor relays’ IP addresses from public list then Blacklist server IP address AND
Check whether server IP-port pair is in blacklist then Block
Get Tor bridges’ IP addresses from webpage then Blacklist server IP address AND
Check whether server IP is in blacklist then Block
Get Tor bridges’ IP addresses from email then Blacklist server IP address AND
Check whether server IP is in blacklist then Block
DPI for Tor’s TLS ‘Client Hello’ for cipherlist then Graylist server IP-port pair AND
Probe server for circumvention handshake looking for version cell then Blacklist server IP-port pair AND
Check whether server IP-port pair is in blacklist then Block
Observe suspected circumvention ﬂow (method unknown) then Graylist server IP-port pair AND
Probe server for circumvention handshake (looking for what?) then Blacklist server IP-port pair AND
Check whether server IP-port pair is in blacklist then Block
Observe suspected circumvention ﬂow (method unknown) then Graylist server IP-port pair AND
Probe server for circumvention handshake (looking for what?) then Blacklist server IP-port pair AND
Check whether server IP-port pair is in blacklist then Block
DPI for TLS ‘Server Hello’ for cipher 0x0039 sent by the Tor relay or bridge then Drop packet
Check GET requests for Tor (‘/tor/’) then Cut connection
Identify SSL (method unknown) then Throttle
DPI for Tor’s DH parameter in SSL then Block AND
Check whether server IP is in blacklist then TCP FIN
Identify SSL for Tor (method unknown) then Throttle
DPI for Tor’s SSL and TLS certiﬁcate lifetime then Block
DPI for TLS ‘Client Hello’ for SNI that resolves to Tor relay/bridge then Block
DPI on TLS for client key exchange then Send a TCP reset and drop packet
Identify SSL handshake then Block
Check whether server IP-port pair is in blacklist then Block
Search for ‘Tor’ as a keyword, e.g., as a search term then Block
DPI for Tor’s SSL and TLS certiﬁcate lifetime then Block
Check for port 80 and whether protocol is non-HTTP (method unknown) then Send a TCP reset
Check for encryption (method unknown) then Throttle
Find IP addresses of Tor directory authorities then Blacklist server IP-port pair AND
Check whether server IP-port pair is in blacklist then Block
DPI for TLS ‘Server Hello’ for cipher 0x0039 sent by the Tor relay or bridge then Drop packet
DPI for Tor’s TLS ‘Client Hello’ for cipherlist then Block
DPI for TLS ‘Server Hello’ for cipher 0x0039 sent by the Tor relay or bridge then Block
Check GET requests for Tor (‘/tor/’) then Cut connection
DPI for Tor’s TLS renegotiation then Blacklist server IP address AND
Check whether server IP is in blacklist then Block
DPI for Tor’s TLS renegotiation then Blacklist server IP address AND
Check whether server IP is in blacklist then Block
Check DNS requests for whether they are for Tor’s website then Redirect to a block page
Check whether port is not 80 or 443 then Block
Check whether port is not 80 (and client IP is on a graylist?) then Block
Check DNS requests for whether they are for Tor’s website then Block
DPI for TLS ‘Server Hello’ for cipher 0x0039 sent by the Tor relay or bridge then Drop packet
Steps in Real-world Censorship Attacks Affecting Tor, including Detecting Suspicious Traffic, Blacklisting IP Addresses, and Disruption Actions. The
exploits of an attack are separated by “And,” with “then” separating the detection and action steps of an exploit.
TABLE II
In late 2013, Lantern [42] had a surge of Chinese users,
who increased in number from 200 to 10,000 in just two
weeks [135], followed soon after by blocking of the network
and its website [136], with only a few users remaining able
to connect.
In 2015, GreatFire.org, a website
Denial-of-Service Attacks.
oﬀering information about and approaches for circumventing
censorship in China, suﬀered from a DoS attack orchestrated
by Chinese censors [77, 137, 138]. The major fallout for
GreatFire was not downtime but rather a $30,000-a-day bill
from their web hosting provider. The attack came shortly after
the publication of a Wall Street Journal article regarding the
website.
In 2011, Iran launched a series
Man-in-the-Middle Attacks.
of MITM attacks using fraudulent TLS certiﬁcates for many
Internet services [139], including one for the Tor website.
(This, however, did not aﬀect the certiﬁcates used by the Tor
network itself [140].) In 2013, China conducted an HTTPS
MITM attack against GitHub that lasted a few days [141].
Malicious Software. Green Simurgh [51] is a circumvention
tool designed for users in Iran. In 2012, fraudulent copies
of the software were found in the wild backdoored with a
919919
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:11:18 UTC from IEEE Xplore.  Restrictions apply. 
keylogger and other malicious features [142].
V. Channel-based Circumvention
We now survey approaches from both research papers and
real deployments for “channel approaches” to circumvent cen-
sorship, which involve establishing a channel to a forwarder.
In the next section we then analyze their evaluations.
Channel approaches vary in the form of censorship they
aim to address, such as regarding the censor’s motivations.
For example, one approach may excel for use in the context
of a highly repressive regime censoring and punishing political
dissidents, while another may focus on causal users accessing
social media in a moderately repressive regime.
Channel approaches also vary in their level of abstrac-
tion and implementation. Research papers sometimes propose
channel protocols or schemes that could be instantiated in
multiple ways (e.g., StegoTorus [19] and FTE [143] are
parametrized). In some cases, researchers implement a pro-
tocol and benchmark it using a particular instantiation of
an in-the-lab emulation of a censored network. Researchers
rarely actually deploy their approaches for real users by setting
up the necessary infrastructure. More often, activists deploy
pragmatic homespun approaches due to the considerable eﬀort
required to actually deploy even a simple approach. Deploy-
ment typically involves a circumvention advocate setting up
and maintaining the forwarder and associated infrastructure,
providing documentation for users, and promoting the ap-
proach to attract users. In some cases, an advocate may skip
setting up and maintaining the forwarder by directing users to
a found forwarder, some pre-existing infrastructure maintained
for some other purpose that can act as a forwarder (e.g.,
CacheBrowser [144]).
Table III provides an overview of circumvention approaches.
We can divide the previously proposed circumvention systems
into two main categories based upon what they primarily at-
tempt to obfuscate: setup or usage. The setup category contains
approaches that attempt to obfuscate the information about
who will be communicating (e.g., IP address) and how (e.g.,
protocol identiﬁers). The usage category contains approaches
that attempt to protect the usage of the approach during its
employment. This entails obfuscating the user’s behaviors to
make them look non-circumventing. For tools that do both
forms of obfuscation, we classify it based upon which form
the tool designers focused on or presented as novel.
Additionally, we can split the approaches into those that
focus on polymorphism and those that focus on steganography
for obfuscation. (Most use a bit of both.) Both are methods of
obfuscating a feature of the traﬃc that an approach produces,
such as packet sizes or the value of parameters in a crypto-
graphic handshake, that could reﬂect a vulnerability enabling
identiﬁcation of the approach producing the traﬃc.
Polymorphism is a way of spreading out behavior. To be
polymorphic in a feature means that the feature takes on
multiple values among diﬀerent instances, such as messages.
Spreading out the values of a feature used in a blacklist’s
signature can result in the signature no longer identifying
disallowed traﬃc, increasing false negatives.
Steganography is a way of looking like allowed commu-
nications. To be steganographic in a feature means having
values that are very close to allowed communications. The
censor may fail to distinguish such steganographic traﬃc from
genuine allowed traﬃc, resulting in false negatives.
The two concepts are not mutually exclusive. A polymor-
phic approach might steganographically match the characteris-
tics of a generic class of traﬃc that censors allow due to their
inability to identify it. Alternatively, matching an allowed pro-
tocol with random behavior requires polymorphism. However,
the approaches we studied fall into two groups: those trying to
not look like blacklisted traﬃc using polymorphism, and those
trying to blend in with allowed traﬃc using steganography.
For example, ScrambleSuit [23], an approach polymorphic
over usage, attempts to look random in hopes of having no
easily recognizable behavior. SkypeMorph [18], an approach
steganographic over usage, attempts to look like Skype traﬃc.
Meek [26], steganographic over channel setup (not usage),
also tries to look like allowed traﬃc, namely traﬃc headed to
an allowed site hosted by a content delivery network (CDN).
However, unlike SkypeMorph, Meek makes no eﬀort to match
the usage patterns of real CDN traﬃc, and instead just ensures
that the connection setup looks similar by using the same IP
address and URL as allowed traﬃc.
Looking at Table III, we see that research approaches (or at
least their presentations) cluster in the area of steganography
over usage, in which almost all approaches are only designs
and are not deployed. It behooves us to consider the merits
or drawbacks of this emphasis. We approach this question by
analyzing how censors block approaches.
Approaches also vary in their identiﬁer distribution mech-
anisms (IDMs). Such mechanisms include receiving IP ad-
dresses from friends by hand or via email. Some approaches
include keys that authorize users to forwarders. Unlike a
channel, an IDM does not need to be able to communicate
arbitrary information to arbitrary destinations, nor are latency
and bandwidth typically as salient concerns. Due to these
diﬀerences, the problem of identiﬁer distribution is largely
orthogonal to channel setup and usage, with its own disjoint
set of papers (e.g., [145–147]). To maintain focus in our work,
moving forward we set IDMs aside except to comment on real
censors’ attacks on them when it sheds light on their abilities
to also attack channels.
VI. Evaluation Criteria
To understand how advocates and researchers evaluate
current circumvention approaches—both those presented in
papers as well as used in practice—we identiﬁed 55 docu-
ments about circumvention approaches to study. We selected
33 academic papers by searching the top computer security
conferences, Google Scholar, and Microsoft Academic search
using keywords like “censorship circumvention” and “censor-
ship resistance,” taking those papers that present a channel-
based circumvention approach. We selected 25 documents,
such as webpages and posted speciﬁcations, about approaches
deployed in the wild by taking those that appear functional
or to have had users. Of these deployed tools, 7 were also
920920
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:11:18 UTC from IEEE Xplore.  Restrictions apply. 
Setup
Usage
Polymorphism
Tor Sep, 2011a, BridgeDB [2], CGIProxy [38],
Flash Proxy [17], FreeGate [40], Green Simurgh [51],
GTunnel [44], Hotspot Shield [45], JAP [46], Lantern [42],
Psiphon [41], Ultrasurf [39], uProxy [37], VPN Gate [32],
Your Freedom [47]
Steganography
Tor Jan, 2011b, Tor Jun, 2012c, CacheBrowser [50],
Cirripede [13], CloudTransport [36], Decoy routing [14],
GoAgent [25], Meek [26], OSS [27], TapDance [35], Telex [15]
Dust [24], GoHop [52], MessageStreamEncryption [8],
Obfs2 [20], Obfs3 [21], Obfs4 [22], ScrambleSuit [23]
Bit-smuggler [43], Castle [48], CensorSpoofer [16],
Collage [12], DEFIANCE [3], Facade [33], Facet [34],
FOE [9], FreeWave [30], FTE [28],
Identity-based Steganographic Tagging [5], Infranet [4],
MailMyWeb [10], Marionette [29], Message in a Bottle [6],
Rook [49], SkyF2F [11], SkypeMorph [18], StegoTorus [19],
SWEET [31], Trist [7]
TABLE III
Prior research on evading network-based censorship using obfuscation, organized by primary obfuscation method. Columns show the primary type of
obfuscated feature. Bold denotes deployed approaches. aTor 0.2.3.4-alpha: changed TLS cert expiration time to make it less distinct. bTor 0.2.2.22-alpha:
changed TLS D-H parameter to one used by Apache’s mod ssl. cTor 0.2.3.17-beta: updated TLS cipher list to match Firefox version 8 or later.
selected as academic papers counted above. Lastly, we added
4 reports on the evaluation of circumvention tools, looking
for those that mention technical criteria. Amongst the papers
we included the documentation of Bit-smuggler [43], which
is a tool though not deployed. While we did not cover every
existing approach, we believe we have covered the ones that
eﬀectively shape the circumvention arms race in research and
practice.
it, disrupt
Table IV shows the criteria related to censorship attacks,
it, or
such as how easily a censor can detect
harm its users. To create this table, we started by reading
the selected documents, paying particular attention to sections
with titles such as “evaluation”, “experiments”, “threat model”,
and “design goals”. We then made a large superset of all
criteria discussed in any evaluation. We combined similar
criteria where reasonable, losing some nuances and making
adjustments to terminology when needed.
Next, we organized the criteria into two classes: (1) abstract
goals and (2) concrete metrics. A goal motivates metrics that
measure an aspect of how well an approach meets the goal.
For example, some approaches have the goal of resistance to
traﬃc analysis; their developers measured the satisfaction of
this goal using various metrics, such as the packet size distri-
bution produced by their approach, which show how similar
it looks to allowed and disallowed traﬃc. Under metrics, we
include not just traditional quantitative measurements, such as
throughput, but also binary properties about the approach, such
as whether it employs authentication. While ideally metrics
objectively measure an approach, we allow a bit of vagueness
in their deﬁnitions since obvious ways of making concepts
like “popular hosts” precise exist despite some documents not
discussing them. We used the motivations for metrics provided
in the documents to categorize them under goals, per Table IV;
where not all documents agreed, we used our judgement. Note
that some metrics fall under two goals each.
To understand the evaluations that document authors had in
mind, as opposed to how well an approach did, for each goal
and metric we determined whether each document mentioned
it, giving it a box (cid:2) in the table if so. We included discussed
criteria regardless of whether a documented approach actually
met it, or even tried to.
For documents about a single approach, we also assessed
which metrics the authors “checked oﬀ” (denoted by (cid:2)).
For binary metrics, we checked oﬀ those that the document
stated that the approach provided. For quantitative metrics, we
checked oﬀ those for which the document provided a measured
value, since these have no clear cutoﬀs for satisfaction. We
did not check oﬀ goals, since there is no clear meaning of
satisfying most of them due to their generality.
The reason we checked oﬀ metrics was not because we
wanted to evaluate the approaches; rather, we did so to under-
stand which metrics the authors took seriously enough to either
meet or at least measure. As such, we only record the criteria
as documented: we made no eﬀort to infer undocumented
relationships between goals and metrics, to discover undoc-
umented features of approaches, to evaluate the correctness of
the evaluations performed, or to rank approaches.
To improve our assessments, we did two rounds of emailing
the authors of each document that included contact informa-
tion. Each round led to corrections to our assessments of tools
and to adjustments to our list of criteria. We re-examined the
documents to check that we listed the correct criteria as our
criteria list changed. Some authors sent us additional docu-
mentation to consider, which we accepted as long as it was
publicly available and created by the same team as the primary
document. Even with the two rounds, as of this writing some
(non)assignments of criteria to tools have not been validated by
the tools’ authors, particularly those involving criteria newly
introduced in response to the second round of replies. This
process made clear to us the subjective judgement involved
in deciding whether a “document” (such as an amorphous
website) “discusses” a criteria in an “evaluation” given the
vagueness of language (both ours and theirs).
In the end, we have 23 goals and 74 metrics. Of these, 15
goals and 46 metrics relate to how easily a censor can attack
an approach. Because we focus on criteria related to attacks,
we relegate the others to the appendix.
Since we consider most of the criteria in Table IV to be
self-explanatory, for reasons of limited space we forgo an
enumeration of them here and only touch upon the interesting
921921
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:11:18 UTC from IEEE Xplore.  Restrictions apply. 
s
r
e
p
a
P
n
o
i
t
a
u
l
a
v
E
s
e
h
c
a
o
r
p
p
A
g
n
i
s
o
p
o
r
P
s
r
e
p
a
P
c
i
m
e
d
a
c
A
s
r
e
p
a
P
&
d
e
y
o
l
p
e
D
s
l
o
o
T
d
e
y
o
l
p
e
D
]
6
5
[
]
5
5
[
]
4
5
[
]
3
5
[
]
0
5
[
]
9
4
[
]
8
4
[
]
3
4
[
]
6
3
[
]
5
3
[
]
4
3
[
]
3
3
[
]
1
3
[
]
0
3
[
]
9
2
[
]
7
2
[
]
4
2
[
]
9
1
[
]
8
1
[
]
7
1
[
]
6
1
[
]
5
1
[
]
4
1
[
]
3
1
[
]
2
1
[
]
1
1
[
]
7
[
]
6
[
]
5
[
]
4
[
]
3
[
]
2
5
[
]
6
4
[
]
2
3
[
]
8
2
[
]
6
2
[
]
3
2
[
]
1
5
[
]
7
4
[
]
5
4
[
]
4
4
[
]
2
4
[
]
1
4
[
]
0
4
[
]
9
3
[
]
8
3
[
]
7
3
[
]
5
2
[
]
2
2
[
]
1
2
[
]
0
2
[
]
0
1
[
]
9