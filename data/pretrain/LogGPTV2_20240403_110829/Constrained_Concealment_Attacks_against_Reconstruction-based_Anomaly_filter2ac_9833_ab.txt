A. Erba et al.
actuators, and spoof sensor values to hide problems in the phys-
ical process [17, 27, 59]. Such activities produce anomalies in the
physical sensor data that can be successfully leveraged for attack
detection. Hence, attackers can attempt to conceal the physical
anomalies through replay attacks [39] or through stealthy attacks
based on solving models of the (known) physical processes [54, 57].
A promising anomaly detection technique in industrial con-
trol systems involves the use of machine learning-based classi-
fiers and, in particular, reconstruction-based classifiers as proposed
in [20, 32, 51]. An attacker who wants to conceal the physical anom-
alies from this detector will modify a sample to induce a wrong
classification outcome: This can be framed as an Adversarial Ma-
chine Learning (AML) evasion attack. So far, no systematic analysis
of evasion attack against reconstruction-based detectors has been
proposed.
Evasion attacks in the context of ICS (which we call Concealment
Attacks to distinguish them from the general case) face novel and
specific challenges, which make standard AML techniques [26] not
directly applicable.
In particular, adversarial examples1 obtained with a concealment
attack must meet four requirements. R1: Due to the distributed
nature of the system, the attacker is constrained to manipulate
only a subset of features. R2: Adversarial examples must meet the
temporal and spatial correlations expected from the observed phys-
ical processes [24, 53]. Particularly, adversarial examples must not
introduce contextual anomalies (i.e., observations classified as ab-
normal only when viewed against other variables that characterize
the behavior of the physical process [24]). R3: Most AML attacks in
other domains target end-to-end Neural Network Classifiers instead
of reconstruction-based classifiers. We realized that this requires
the attacker to optimize the Mean Squared Error loss instead of
optimizing the cross-entropy loss (Section 4.5). R4: To the best of
our knowledge, previous work either assumes unlimited computa-
tional power to compute ideal pertubations [9] or assumes static
systems that allow universal adversarial perturbations [35, 41]. For
real-time attacks2 on dynamic ICS, neither approach is feasible, and
new solutions are required.
In this work, we propose and evaluate constrained concealment
attacks against reconstruction-based anomaly detectors. To meet R1,
we formalize a detailed attacker model and evaluate different set-
tings relating to attacker constraints, i.e., the number of features
under the control of the attacker. To meet R2, the attacker leverages
passive observation of system behavior to approximate how realis-
tic examples should behave. Based on that, we consider a white box
attacker that can leverage knowledge on the system to perform it-
erative attacks on general reconstruction-based detectors (meeting
R3). Moreover, we consider a black box attacker and show that it is
possible to craft effective adversarial samples in milliseconds (meet-
ing R3 and R4). Our implementation meets all four requirements
for Reconstruction-based detectors.
We summarize our main contributions as follows:
• We propose a detailed attacker model that formalizes implicit
models in prior work, introduce constraints on the attacker
1We differentiate between sample (original set of sensor readings), and adversarial
example (manipulated set of sensor readings).
2With real-time, we mean examples are crafted w.r.t. the current dynamic state of the
system, in less time than the sampling rate (e.g., 10ms).
motivated by real-world ICS, and provide an AML taxonomy
for the attacker.
• We show that replay attacks do not conceal anomalies when
the attacker is constrained to manipulate less than 95% of
the ICS features, due to physical correlations that are not
exploited by such attacks.
• We propose and design concealment attacks on ICS process-
based anomaly detectors which produce examples that do
not violate correlations (outperforming replay attacks in
constrained scenarios). A white box attacker exploits the
knowledge of the Anomaly Detection System launching an
iterative attack based on coordinate descent algorithm. A
black box attacker without the knowledge of the Anomaly
Detection System uses learning-based attack leveraging ad-
versarially trained autoencoders3.
• We evaluate and discuss the proposed attacks, and compare
their performance against replay attacks. The evaluation is
conducted over a simulated ICS process dataset and a real ICS
process dataset, both containing data of water distribution
systems4.
• We practically implement and demonstrate the attacks in
real-word Industrial Control System testbed, and show that
they are possible in real-time.
The remainder of this work is structured as follows. Background
is introduced in Section 2. We present the problem of adversarial
learning attacks on ML-based detectors in Section 3. Our design
is proposed in Section 4, and its implementation and evaluation is
presented in Section 5. We summarize related work in Section 6.
The paper is concluded in Section 7.
2 BACKGROUND
In this section, we provide a brief overview on Industrial Control
Systems and Evasion Attacks. A review of related work is presented
in Section 6.
2.1 Industrial Control Systems
Industrial Control Systems are universally employed to control an
industrial process [18]. In an ICS, Physical components include the
hardware equipment required to execute the process; among these,
actuators and sensors represent the junction point between Cyber
and Physical components. Cyber components comprise the com-
puter hardware and software that is deployed to execute the plant
control logic and monitoring. Typical industrial control hardware
contain Programmable Logic Controllers (PLCs) and a Supervi-
sory Control and Data Acquisition (SCADA) system. In an ICS,
one or more PLCs implement the process control logic by moni-
toring sensor values and sending commands to actuators. Sensor
values and actuator states are reported from PLC to the SCADA
system. In a distributed ICS, several PLCs control the system; tak-
ing control of a sub-process governed by a single PLC can dis-
rupt the system. Attacks targeting both the cyber and physical
components of industrial processes have occurred during the past
decades. A notable example is Stuxnet [59], an attack that targeted
the physical part of an ICS to reduce rotation frequencies of nuclear
3Note: Not to be confused with Adversarial Autoencoders [38].
4Implementation available at https://github.com/scy-phy/ICS-Evasion-Attacks
Constrained Concealment Attacks against Reconstruction-based detectors in ICS
ACSAC 2020, December 7–11, 2020, Austin, USA
manipulations), or uses steganographic approaches to authenticate
sensor readings [40]. The SCADA feeds an attack detection system,
whose goal is to accurately identify the instances in which the
attacker manipulates the physical process while minimizing the
number of false detections. The attack detection system generally
consists of two main components: a system model, which is used to
generate additional features, and a classifier, which (for each time
step) classifies the system as either under attack or under normal
operating conditions (see Section 6 for more details on classifiers
in this context). During the attack, the physical process may be
in an anomalous state, which will be detected unless the attacker
manages to conceal it. The anomalies themselves are out of the
scope of this work; we use prior-work datasets [28, 53].
To the best of our knowledge, our work is the first one that
enables the use of constraints on the number of sensors that can be
manipulated by an attacker (see Section 3.2). As we will show, the
performance of the attack degrades when lowering the number of
channels that are under the attacker’s control. Fully authenticated
sensor signals would eventually prevent the attack to occur at
the process level, but would impose cost on the normal system
operations. Since our attacks exploit sensor signals received by the
detector, they can be deployed somewhere else w.r.t. the industrial
plant. Software exploits on the machine running the detector or
historian server could also offer the attack surface to mount our
proposed concealment attacks (those alternative attacker models
are not modeled here for the sake of simplicity).
3.2 Attacker Model
3.2.1 Attacker Goal and Capabilities. The goal of the attacker is to
launch a concealment attack on an ICS to hide the real state of the
process from an anomaly detector. The modeled attacker is assumed
to have access to the ICS network, e.g., by physically attaching
malicious devices to the network, intercepting communications to
selected remote substations, or performing a Man-in-the-PLC [17]
attack. The attacker is thus assumed to control a subset of the
communication between PLCs and the SCADA system, and as a
result, able to eavesdrop on traffic and send manipulated sensor