### Potential Leakage in Data Synthesis

#### Acknowledgments
The authors, affiliated with Southeast University, were partially supported by the Jiangsu Provincial Key Laboratory of Network and Information Security (No. BM2003201). Minhui Xue was also supported in part by the Australian Research Council (ARC) Discovery Project (DP210102670) and the Research Center for Cyber Security at Tel Aviv University, established by the State of Israel, the Prime Minister’s Office, and Tel Aviv University. Aiqun Hu and Minhui Xue are the corresponding authors of this paper.

### Figure 17: Defense Comparisons on Three Datasets
- **(a) ML Prediction**
- **(b) Marginal Likelihood**

**Marginal Likelihood**: Compute \( E_i(l_1) \).

Mitigation methods generally decrease the prediction accuracy compared to the no-defense baseline. In Fig. 17(b), we compare ECDFs using \( E_i(l_1) \) (recall Section 5.3.1). A lower score indicates better marginal fitness. The experimental results show that the improved defense outperforms the naive defense and is comparable to the no-defense baseline. The improved defense successfully compensates for the statistical deviation caused by the naive defense (see Fig. 16(c)). Additional ECDFs for the naive and improved defenses are shown in Figs. 19, 20, and 21.

In summary, both the naive and improved defenses protect against TableGAN-MCA and partially preserve the learning ability of the released synthetic data. Moreover, the improved defense achieves better marginal fitness than the naive defense. Despite these effective mitigations, TableGAN-MCA remains a threat due to sub-optimal privacy-utility trade-offs, such as reduced synthetic data diversity and under-performance for tiny-domain datasets (see Compas datasets for details).

### 8. Related Work
Membership privacy concerns the existence of individuals [25, 36]. Existing studies have demonstrated membership disclosure in both discriminative and generative machine learning models. For discriminative models, such as classifiers [28, 33, 41–43, 47], an adversary can infer whether a specific data point was used to train a target model by querying classifier APIs and using predicted probability vectors, labels, logits, etc., to train attack models. For example, Shokri's shadow model [43] infers membership against overfitted multi-class classifiers by training an attack model with labeled synthetic data that mimics the private training data. Subsequent works have further relaxed the adversary’s background knowledge [42] by extending attacks to white-box [33] and label-only settings [9, 26].

For generative models, such as Generative Adversarial Networks (GANs) [7, 20, 21, 35], several successful approaches have been proposed, including TableGAN [35], LOGAN [20], MC [21], and GAN-leaks [7]. Some of these approaches, originally designed for image data, can be extended to attack tabular data. These methods are summarized in Table 1. LOGAN [20] and TableGAN [35] leverage the output of the overfitting discriminator to train an attack model, similar to Shokri et al. [43] in the context of GAN synthesis. However, their attacks require the predicted probability vector of the target model.

### References
[Abbreviated references for brevity]

### Appendix
#### A. DP-WGAN
We list the differentially private (DP)-related hyper-parameters for WGAN in Table 8. Additionally, we show the ECDFs of marginals for \((\epsilon, \delta)\)-DP synthesized data in Fig. 18. Smaller training dataset sizes generally result in less satisfactory generation quality under DP training with a similar privacy budget.

#### B. Naive and Improved Defenses
We provide additional ECDFs of marginals for "Remove Colliding Members" mitigation and "GAN-constrained Training" mitigation in Figs. 19, 20, and 21.

### Table 8: Hyper-parameters in DP-WGAN
- **(\(\epsilon, \delta\))**: Privacy budget
- **\(S\)**: Clip threshold
- **\(\sigma\)**: Standard deviation of the noise added in each step

| Datasets | (\(\epsilon, \delta\)) | (\(S, \sigma\)) | Sampling Rate |
|----------|-----------------------|-----------------|---------------|
| Adult    | (0.5, 10^-5)          | (0.1, 0.5)      | 500/31655     |
|          | (1.0, 10^-5)          | (0.1, 0.45)     | 500/31655     |
|          | (2.0, 10^-5)          | (0.1, 0.4)      | 500/31655     |
|          | (4.0, 10^-5)          | (0.1, 0.3)      | 500/31655     |
|          | (8.0, 10^-5)          | (0.1, 0.17)     | 500/31655     |
|          | (16.0, 10^-5)         | (0.1, 0.11)     | 500/31655     |
| Lawschool| (0.5, 10^-5)          | (0.1, 0.4)      | 500/43011     |
|          | (1.0, 10^-5)          | (0.1, 0.45)     | 500/43011     |
|          | (2.0, 10^-5)          | (0.1, 0.48)     | 500/43011     |
|          | (4.0, 10^-5)          | (0.1, 0.25)     | 500/43011     |
|          | (8.0, 10^-5)          | (0.1, 0.15)     | 500/43011     |
|          | (16.0, 10^-5)         | (0.1, 0.11)     | 500/43011     |
| Compas   | (2.0, 10^-4)          | (0.1, 0.9)      | 100/3694      |
|          | (4.0, 10^-4)          | (0.1, 0.48)     | 100/3694      |
|          | (8.0, 10^-4)          | (0.1, 0.27)     | 100/3694      |
|          | (16.0, 10^-4)         | (0.1, 0.16)     | 100/3694      |
|          | (32.0, 10^-4)         | (0.1, 0.11)     | 100/3694      |

### Figures
- **Figure 18**: ECDF comparison between training data and differentially private GAN-synthesized data.
  - **(a) Adult, \(\epsilon = 0.5, \delta = 10^{-5}\)**
  - **(b) Lawschool, \(\epsilon = 0.5, \delta = 10^{-5}\)**
  - **(c) Compas, \(\epsilon = 2.0, \delta = 10^{-4}\)**

- **Figure 19**: ECDF comparisons for "Remove Overlapping" mitigation and "GAN-constrained Training" mitigation.
  - **(a) Adult ECDF, Remove Overlapping**
  - **(b) Adult ECDF, GAN-constrained Training**

- **Figure 20**: ECDF comparisons for "Remove Overlapping" mitigation and "GAN-constrained Training" mitigation.
  - **(a) Lawschool ECDF, Remove Overlapping**
  - **(b) Lawschool ECDF, GAN-constrained Training**

- **Figure 21**: ECDF comparisons for "Remove Overlapping" mitigation and "GAN-constrained Training" mitigation.
  - **(a) Compas ECDF, Remove Overlapping**
  - **(b) Compas ECDF, GAN-constrained Training**

---

This revised version aims to improve clarity, coherence, and professionalism.