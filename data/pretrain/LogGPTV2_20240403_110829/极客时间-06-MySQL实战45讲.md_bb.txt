# redo log 的写入机制接下来，我们再说说 redo log 的写入机制。在专栏的[第 15篇答疑文章](https://time.geekbang.org/column/article/73161)中，我给你介绍了redo log buffer。事务在执行过程中，生成的 redo log 是要先写到 redo logbuffer 的。然后就有同学问了，redo log buffer里面的内容，是不是每次生成后都要直接持久化到磁盘呢？答案是，不需要。如果事务执行期间 MySQL发生异常重启，那这部分日志就丢了。由于事务并没有提交，所以这时日志丢了也不会有损失。那么，另外一个问题是，事务还没提交的时候，redo log buffer中的部分日志有没有可能被持久化到磁盘呢？答案是，确实会有。这个问题，要从 redo log 可能存在的三种状态说起。这三种状态，对应的就是图2 中的三个颜色块。![](Images/0b8674db00e35da26a3c5af0e37f3c77.png){savepage-src="https://static001.geekbang.org/resource/image/9d/d4/9d057f61d3962407f413deebc80526d4.png"}```{=html}```图 2 MySQL redo log 存储状态]{.reference}```{=html}```这三种状态分别是：1.  存在 redo log buffer 中，物理上是在 MySQL    进程内存中，就是图中的红色部分；2.  写到磁盘 (write)，但是没有持久化（fsync)，物理上是在文件系统的 page    cache 里面，也就是图中的黄色部分；3.  持久化到磁盘，对应的是 hard disk，也就是图中的绿色部分。日志写到 redo log buffer 是很快的，wirte 到 page cache也差不多，但是持久化到磁盘的速度就慢多了。为了控制 redo log 的写入策略，InnoDB 提供了innodb_flush_log_at_trx_commit 参数，它有三种可能取值：1.  设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log    buffer 中 ;2.  设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘；3.  设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page    cache。InnoDB 有一个后台线程，每隔 1 秒，就会把 redo log buffer 中的日志，调用write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘。注意，事务执行中间过程的 redo log 也是直接写在 redo log buffer中的，这些 redo log也会被后台线程一起持久化到磁盘。也就是说，一个没有提交的事务的 redolog，也是可能已经持久化到磁盘的。实际上，除了后台线程每秒一次的轮询操作外，还有两种场景会让一个没有提交的事务的redo log 写入到磁盘中。1.  **一种是，redo log buffer 占用的空间即将达到 innodb_log_buffer_size    一半的时候，后台线程会主动写盘。**注意，由于这个事务并没有提交，所以这个写盘动作只是    write，而没有调用 fsync，也就是只留在了文件系统的 page cache。2.  **另一种是，并行的事务提交的时候，顺带将这个事务的 redo log buffer    持久化到磁盘。**假设一个事务 A 执行到一半，已经写了一些 redo log 到    buffer 中，这时候有另外一个线程的事务 B 提交，如果    innodb_flush_log_at_trx_commit 设置的是    1，那么按照这个参数的逻辑，事务 B 要把 redo log buffer    里的日志全部持久化到磁盘。这时候，就会带上事务 A 在 redo log buffer    里的日志一起持久化到磁盘。这里需要说明的是，我们介绍两阶段提交的时候说过，时序上 redo log 先prepare， 再写 binlog，最后再把 redo log commit。如果把 innodb_flush_log_at_trx_commit 设置成 1，那么 redo log 在 prepare阶段就要持久化一次，因为有一个崩溃恢复逻辑是要依赖于 prepare 的 redolog，再加上 binlog 来恢复的。（如果你印象有点儿模糊了，可以再回顾下[第15篇文章](https://time.geekbang.org/column/article/73161)中的相关内容）。每秒一次后台轮询刷盘，再加上崩溃恢复这个逻辑，InnoDB 就认为 redo log 在commit 的时候就不需要 fsync 了，只会 write 到文件系统的 page cache中就够了。通常我们说 MySQL 的"双 1"配置，指的就是 sync_binlog 和innodb_flush_log_at_trx_commit 都设置成1。也就是说，一个事务完整提交前，需要等待两次刷盘，一次是 redolog（prepare 阶段），一次是 binlog。这时候，你可能有一个疑问，这意味着我从 MySQL 看到的 TPS是每秒两万的话，每秒就会写四万次磁盘。但是，我用工具测试出来，磁盘能力也就两万左右，怎么能实现两万的TPS？解释这个问题，就要用到组提交（group commit）机制了。这里，我需要先和你介绍日志逻辑序列号（log sequencenumber，LSN）的概念。LSN 是单调递增的，用来对应 redo log的一个个写入点。每次写入长度为 length 的 redo log， LSN 的值就会加上length。LSN 也会写到 InnoDB 的数据页中，来确保数据页不会被多次执行重复的 redolog。关于 LSN 和 redo log、checkpoint的关系，我会在后面的文章中详细展开。如图 3 所示，是三个并发事务 (trx1, trx2, trx3) 在 prepare 阶段，都写完redo log buffer，持久化到磁盘的过程，对应的 LSN 分别是 50、120 和 160。![](Images/2b53768e263988977cb31181061af9e8.png){savepage-src="https://static001.geekbang.org/resource/image/93/cc/933fdc052c6339de2aa3bf3f65b188cc.png"}```{=html}```图 3 redo log 组提交]{.reference}```{=html}```从图中可以看到，1.  trx1 是第一个到达的，会被选为这组的 leader；2.  等 trx1 要开始写盘的时候，这个组里面已经有了三个事务，这时候 LSN    也变成了 160；3.  trx1 去写盘的时候，带的就是 LSN=160，因此等 trx1 返回时，所有 LSN    小于等于 160 的 redo log，都已经被持久化到磁盘；4.  这时候 trx2 和 trx3 就可以直接返回了。所以，一次组提交里面，组员越多，节约磁盘 IOPS的效果越好。但如果只有单线程压测，那就只能老老实实地一个事务对应一次持久化操作了。在并发更新场景下，第一个事务写完 redo log buffer 以后，接下来这个 fsync越晚调用，组员可能越多，节约 IOPS 的效果就越好。为了让一次 fsync 带的组员更多，MySQL有一个很有趣的优化：拖时间。在介绍两阶段提交的时候，我曾经给你画了一个图，现在我把它截过来。![](Images/901e08b9add7085339e02cc13fb4171b.png){savepage-src="https://static001.geekbang.org/resource/image/98/51/98b3b4ff7b36d6d72e38029b86870551.png"}```{=html}```图 4 两阶段提交]{.reference}```{=html}```图中，我把"写 binlog"当成一个动作。但实际上，写 binlog 是分成两步的：1.  先把 binlog 从 binlog cache 中写到磁盘上的 binlog 文件；2.  调用 fsync 持久化。MySQL 为了让组提交的效果更好，把 redo log 做 fsync 的时间拖到了步骤 1之后。也就是说，上面的图变成了这样：![](Images/4141df161d231298b44260878c4d0667.png){savepage-src="https://static001.geekbang.org/resource/image/5a/28/5ae7d074c34bc5bd55c82781de670c28.png"}```{=html}```图 5 两阶段提交细化]{.reference}```{=html}```这么一来，binlog 也可以组提交了。在执行图 5 中第 4 步把 binlog fsync到磁盘时，如果有多个事务的 binlog已经写完了，也是一起持久化的，这样也可以减少 IOPS 的消耗。不过通常情况下第 3 步执行得会很快，所以 binlog 的 write 和 fsync间的间隔时间短，导致能集合到一起持久化的 binlog 比较少，因此 binlog的组提交的效果通常不如 redo log 的效果那么好。如果你想提升 binlog 组提交的效果，可以通过设置binlog_group_commit_sync_delay 和binlog_group_commit_sync_no_delay_count 来实现。1.  binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync;2.  binlog_group_commit_sync_no_delay_count    参数，表示累积多少次以后才调用 fsync。这两个条件是或的关系，也就是说只要有一个满足条件就会调用 fsync。所以，当 binlog_group_commit_sync_delay 设置为 0的时候，binlog_group_commit_sync_no_delay_count 也无效了。之前有同学在评论区问到，WAL 机制是减少磁盘写，可是每次提交事务都要写redo log 和 binlog，这磁盘读写次数也没变少呀？现在你就能理解了，WAL 机制主要得益于两个方面：1.  redo log 和 binlog 都是顺序写，磁盘的顺序写比随机写速度要快；2.  组提交机制，可以大幅度降低磁盘的 IOPS 消耗。分析到这里，我们再来回答这个问题：**如果你的 MySQL现在出现了性能瓶颈，而且瓶颈在 IO 上，可以通过哪些方法来提升性能呢？**针对这个问题，可以考虑以下三种方法：1.  设置 binlog_group_commit_sync_delay 和    binlog_group_commit_sync_no_delay_count 参数，减少 binlog    的写盘次数。这个方法是基于"额外的故意等待"来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。2.  将 sync_binlog 设置为大于 1 的值（比较常见是    100\~1000）。这样做的风险是，主机掉电时会丢 binlog 日志。3.  将 innodb_flush_log_at_trx_commit 设置为    2。这样做的风险是，主机掉电的时候会丢数据。我不建议你把 innodb_flush_log_at_trx_commit 设置成0。因为把这个参数设置成 0，表示 redo log 只保存在内存中，这样的话 MySQL本身异常重启也会丢数据，风险太大。而 redo log 写到文件系统的 page cache的速度也是很快的，所以将这个参数设置成 2 跟设置成 0其实性能差不多，但这样做 MySQL异常重启时就不会丢数据了，相比之下风险会更小。
# 小结在专栏的[第 2 篇](https://time.geekbang.org/column/article/68633)和[第15篇](https://time.geekbang.org/column/article/73161)文章中，我和你分析了，如果redo log 和 binlog 是完整的，MySQL 是如何保证 crash-safe的。今天这篇文章，我着重和你介绍的是 MySQL 是"怎么保证 redo log 和binlog 是完整的"。希望这三篇文章串起来的内容，能够让你对 crash-safe这个概念有更清晰的理解。之前的第 15篇答疑文章发布之后，有同学继续留言问到了一些跟日志相关的问题，这里为了方便你回顾、学习，我再集中回答一次这些问题。**问题 1：**执行一个 update 语句以后，我再去执行 hexdump 命令直接查看ibd 文件内容，为什么没有看到数据有改变呢？回答：这可能是因为 WAL 机制的原因。update 语句执行完成后，InnoDB只保证写完了 redo log、内存，可能还没来得及将数据写到磁盘。**问题 2：**为什么 binlog cache 是每个线程自己维护的，而 redo log buffer是全局共用的？回答：MySQL 这么设计的主要原因是，binlog 是不能"被打断的"。一个事务的binlog 必须连续写，因此要整个事务完成后，再一起写到文件里。而 redo log 并没有这个要求，中间有生成的日志可以写到 redo log buffer中。redo log buffer中的内容还能"搭便车"，其他事务提交的时候可以被一起写到磁盘中。**问题 3：**事务执行期间，还没到提交阶段，如果发生 crash 的话，redo log肯定丢了，这会不会导致主备不一致呢？回答：不会。因为这时候 binlog 也还在 binlog cache 里，没发给备库。crash以后 redo log 和 binlog都没有了，从业务角度看这个事务也没有提交，所以数据是一致的。**问题 4：**如果 binlog 写完盘以后发生crash，这时候还没给客户端答复就重启了。等客户端再重连进来，发现事务已经提交成功了，这是不是bug？回答：不是。你可以设想一下更极端的情况，整个事务都提交成功了，redo log commit完成了，备库也收到 binlog并执行了。但是主库和客户端网络断开了，导致事务成功的包返回不回去，这时候客户端也会收到"网络断开"的异常。这种也只能算是事务成功的，不能认为是bug。实际上数据库的 crash-safe 保证的是：1.  如果客户端收到事务成功的消息，事务就一定持久化了；2.  如果客户端收到事务失败（比如主键冲突、回滚等）的消息，事务就一定失败了；3.  如果客户端收到"执行异常"的消息，应用需要重连后通过查询当前状态来继续后续的逻辑。此时数据库只需要保证内部（数据和日志之间，主库和备库之间）一致就可以了。最后，又到了课后问题时间。今天我留给你的思考题是：你的生产库设置的是"双 1"吗？如果平时是的话，你有在什么场景下改成过"非双1"吗？你的这个操作又是基于什么决定的？另外，我们都知道这些设置可能有损，如果发生了异常，你的止损方案是什么？你可以把你的理解或者经验写在留言区，我会在下一篇文章的末尾选取有趣的评论和你一起分享和分析。感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。
# 上期问题时间我在上篇文章最后，想要你分享的是线上"救火"的经验。\@Long 同学，在留言中提到了几个很好的场景。-   其中第 3    个问题，"如果一个数据库是被客户端的压力打满导致无法响应的，重启数据库是没用的。"，说明他很好地思考了。\    这个问题是因为重启之后，业务请求还会再发。而且由于是重启，buffer    pool 被清空，可能会导致语句执行得更慢。-   他提到的第 4    个问题也很典型。有时候一个表上会出现多个单字段索引（而且往往这是因为运维工程师对索引原理不够清晰做的设计），这样就可能出现优化器选择索引合并算法的现象。但实际上，索引合并算法的效率并不好。而通过将其中的一个索引改成联合索引的方法，是一个很好的应对方案。还有其他几个同学提到的问题场景，也很好，很值得你一看。> \@Max> 同学提到一个很好的例子：客户端程序的连接器，连接完成后会做一些诸如> show columns 的操作，在短连接模式下这个影响就非常大了。\> 这个提醒我们，在 review 项目的时候，不止要 review> 我们自己业务的代码，也要 review> 连接器的行为。一般做法就是在测试环境，把 general_log> 打开，用业务行为触发连接，然后通过 general log 分析连接器的行为。> \@Manjusaka> 同学的留言中，第二点提得非常好：如果你的数据库请求模式直接对应于客户请求，这往往是一个危险的设计。因为客户行为不可控，可能突然因为你们公司的一个运营推广，压力暴增，这样很容易把数据库打挂。\> 在设计模型里面设计一层，专门负责管理请求和数据库服务资源，对于比较重要和大流量的业务，是一个好的设计方向。> \@Vincent 同学提了一个好问题，用文中提到的 DDL 方案，会导致 binlog> 里面少了这个 DDL> 语句，后续影响备份恢复的功能。由于需要另一个知识点（主备同步协议），我放在后面的文章中说明。![](Images/48edcb93fb03e3e52d7e7099be6b5cb3.png){savepage-src="https://static001.geekbang.org/resource/image/09/77/09c1073f99cf71d2fb162a716b5fa577.jpg"}
# 24 \| MySQL是怎么保证主备一致的？在前面的文章中，我不止一次地和你提到了 binlog，大家知道 binlog可以用来归档，也可以用来做主备同步，但它的内容是什么样的呢？为什么备库执行了binlog 就可以跟主库保持一致了呢？今天我就正式地和你介绍一下它。毫不夸张地说，MySQL 能够成为现下最流行的开源数据库，binlog 功不可没。在最开始，MySQL是以容易学习和方便的高可用架构，被开发人员青睐的。而它的几乎所有的高可用架构，都直接依赖于binlog。虽然这些高可用架构已经呈现出越来越复杂的趋势，但都是从最基本的一主一备演化过来的。今天这篇文章我主要为你介绍主备的基本原理。理解了背后的设计原理，你也可以从业务开发的角度，来借鉴这些设计思想。
# MySQL 主备的基本原理如图 1 所示就是基本的主备切换流程。![](Images/ba850a9829780c53f1c4e21537be61c7.png){savepage-src="https://static001.geekbang.org/resource/image/fd/10/fd75a2b37ae6ca709b7f16fe060c2c10.png"}```{=html}```图 1 MySQL 主备切换流程]{.reference}```{=html}```在状态 1 中，客户端的读写都直接访问节点 A，而节点 B 是 A 的备库，只是将A 的更新都同步过来，到本地执行。这样可以保持节点 B 和 A 的数据是相同的。当需要切换的时候，就切成状态 2。这时候客户端读写访问的都是节点 B，而节点A 是 B 的备库。在状态 1 中，虽然节点 B 没有被直接访问，但是我依然建议你把节点B（也就是备库）设置成只读（readonly）模式。这样做，有以下几个考虑：``{=html}1.  有时候一些运营类的查询语句会被放到备库上去查，设置为只读可以防止误操作；2.  防止切换逻辑有 bug，比如切换过程中出现双写，造成主备不一致；3.  可以用 readonly 状态，来判断节点的角色。你可能会问，我把备库设置成只读了，还怎么跟主库保持同步更新呢？这个问题，你不用担心。因为 readonly 设置对超级 (super)权限用户是无效的，而用于同步更新的线程，就拥有超级权限。接下来，我们再看看**节点 A 到 B 这条线的内部流程是什么样的**。图 2中画出的就是一个 update 语句在节点 A 执行，然后同步到节点 B的完整流程图。![](Images/02e08fa178a98082c56d6750b4008573.png){savepage-src="https://static001.geekbang.org/resource/image/a6/a3/a66c154c1bc51e071dd2cc8c1d6ca6a3.png"}```{=html}```图 2 主备流程图]{.reference}```{=html}```图 2 中，包含了我在上一篇文章中讲到的 binlog 和 redo log的写入机制相关的内容，可以看到：主库接收到客户端的更新请求后，执行内部事务的更新逻辑，同时写binlog。备库 B 跟主库 A 之间维持了一个长连接。主库 A内部有一个线程，专门用于服务备库 B的这个长连接。一个事务日志同步的完整过程是这样的：1.  在备库 B 上通过 change master 命令，设置主库 A 的    IP、端口、用户名、密码，以及要从哪个位置开始请求    binlog，这个位置包含文件名和日志偏移量。2.  在备库 B 上执行 start slave    命令，这时候备库会启动两个线程，就是图中的 io_thread 和    sql_thread。其中 io_thread 负责与主库建立连接。3.  主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取    binlog，发给 B。4.  备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log）。5.  sql_thread 读取中转日志，解析出日志里的命令，并执行。这里需要说明，后来由于多线程复制方案的引入，sql_thread演化成为了多个线程，跟我们今天要介绍的原理没有直接关系，暂且不展开。分析完了这个长连接的逻辑，我们再来看一个问题：binlog里面到底是什么内容，为什么备库拿过去可以直接执行。