### Evaluation of NEZHA's Performance

#### Comparative Analysis with AFL and libFuzzer
In a series of 100 runs, each starting from a different seed corpus of 1000 certificates, we observed that NEZHA, on average, identified 6 times and 3.5 times more differences per tested input compared to AFL and libFuzzer, respectively. This finding underscores the limitations of using a single application for driving input generation in differential testing. In the absence of a widely-adopted, domain-agnostic differential testing framework, we modified libFuzzer’s guidance engine to support differential testing using global code coverage. Apart from its guidance mechanisms, this modified version of libFuzzer is identical to NEZHA in all other aspects, including mutations and corpus minimization. As shown in Figure 6, even with these modifications, NEZHA still yields 30% more discrepancies per tested input and achieves 1.3% higher code coverage.

**Result 3:** NEZHA identifies 6 times more discrepancies than AFL, which was adapted to differentially test multiple applications using a single test program for input generation.

#### Comparison of NEZHA's δ-Diversity Engines
To compare the performance of NEZHA’s δ-diversity engines, we conducted experiments on six SSL/TLS libraries, enabling one guidance engine at a time. We ensured that the discrepancies reported were due to NEZHA’s guidance and not its mutation strategies. When running NEZHA without any δ-diversity guidance, no discrepancies were found across the SSL/TLS libraries.

Figures 7 and 8 illustrate the relative performance of different δ-diversity engines in terms of the number of unique discrepancies discovered. Figure 7 shows the probability of finding at least \( n \) unique discrepancies across the six tested SSL/TLS libraries, starting from a corpus of 1000 certificates and performing 100,000 generations. The corresponding git commit for this experimental setup is 1f0a7ed0f324a2fb43f5ad2250fba68377076622. We observed that NEZHA reports at least 57 discrepancies with more than 90% probability, regardless of the engine used. Additionally, all δ-diversity engines report more discrepancies than global coverage. Figure 8 shows the rate at which each engine finds discrepancies during execution. Both δ-diversity guidance engines report differences at higher rates than global coverage using the same initial set of inputs.

In this experiment, NEZHA’s output δ-diversity yielded 521 discrepancies, while path δ-diversity yielded 491 discrepancies, resulting in 30% and 22.75% more discrepancies than using global code coverage (which resulted in 400 unique discrepancies). In terms of control flow graph (CFG) coverage, output δ-diversity and path δ-diversity guidance achieved 1.38% and 1.21% higher coverage, respectively, than global coverage guidance.

**Figure 9** presents the distribution of discrepancies reported by the different engines. We noticed that 348 discrepancies were found by all three guidance engines, 121 discrepancies were reported using δ-diversity, and 48 discrepancies were reported by our custom libFuzzer global code coverage engine. This result indicates that δ-diversity performs differently from global code coverage in input generation, generating a broader set of discrepancies within a given time budget while exploring similar portions of the application CFG (with a 1.21% difference in coverage).

One notable finding is that output δ-diversity, despite being a black-box approach, achieves equally good coverage as NEZHA’s gray-box engines and even reports more unique discrepancies. This suggests that the internal state of an application can, in some cases, be adequately approximated based on its outputs alone, provided there is enough diversity in the return values.

**Result 4:** NEZHA’s output and path δ-diversity guidance find 30% and 22.75% more discrepancies, respectively, than NEZHA using global-coverage-based guidance.

However, we expect that output δ-diversity will perform worse for applications with very coarse output granularity. For example, discrepancies found in an application providing debug messages or fine-grained error codes are expected to be more numerous than those in applications with less expressive outputs, such as a web application firewall that only returns "ACCEPT" or "REJECT" based on its input. To verify this assumption, we performed an experiment with three SSL libraries (OpenSSL, LibreSSL, and BoringSSL), limiting the number of error codes to 32, 64, 128, and 256. Our results, presented in **Figure 10**, show that a limit of 32 error codes results in significantly fewer discrepancies than a more expressive set of error values. When the limit was further reduced to 16 possible error codes, NEZHA did not find any discrepancies.

### Case Studies of Bugs Found by NEZHA

#### ClamAV File Format Validation Bugs
Discrepancies in file format validation logic across programs can have severe security implications. Here, we highlight two critical bugs where ClamAV fails to parse specially crafted ELF and XZ files, allowing malware to evade detection.

1. **ELF - Mishandling of Malformed Header:**
   According to the ELF specification, the `e_ident[EI_CLASS]` field specifies the type of machine (32- or 64-bit) the ELF file is compiled to run on. Values greater than 2 for this field are undefined. In parsing ELF binaries, ClamAV differs from binutils when it encounters illegal values in `e_ident[EI_CLASS]`. ClamAV treats ELF binaries with such illegal values as invalid and does not scan them, while binutils correctly parses such binaries. We verified that such ELF binaries can be successfully executed, allowing malware with a corrupted ELF header to evade ClamAV detection while retaining its capability to execute in the host OS.

   **Listing 1:** ClamAV code that parses the `e_ident` field.
   ```c
   static int cli_elf_fileheader(...) {
       ...
       switch(file_hdr->hdr64.e_ident[4]) {
           case 1:
               ...
           case 2:
               ...
           default:
               ...
               return CL_EFORMAT;
       }
   ```

   **Listing 2:** Error checks for ELF loading in the Linux kernel (the `e_ident` field is not checked).
   ```c
   static int load_elf_binary(struct linux_binprm *bprm) {
       ...
       retval = -ENOEXEC;
       if (memcmp(loc->elf_ex.e_ident, ELFMAG, SELFMAG) != 0)
           goto out;
       if (loc->elf_ex.e_type != ET_EXEC &&
           loc->elf_ex.e_type != ET_DYN)
           goto out;
       if (!elf_check_arch(&loc->elf_ex))
           goto out;
       ...
   ```

2. **XZ - Mishandling of the Dictionary Size Field:**
   According to the XZ specifications, the LZMA2 decompression algorithm can use a dictionary size ranging from 4kB to 4GB. The dictionary size varies from file to file and is stored in the XZ header. ClamAV differs from XZ Utils when parsing this dictionary size field. XZ Utils strictly conforms to the specifications and allocates a buffer based on the permitted dictionary sizes. ClamAV, however, includes an additional check on the dictionary size that deviates from the specifications, failing to parse archives with a dictionary size greater than 182MB. As a result, ClamAV skips scanning compressed malware in such archives.

   **Listing 3:** XZ Utils code that parses the dictionary size correctly.
   ```c
   extern lzma_ret lzma_lz_decoder_init(...) {
       ...
       // Allocate and initialize the dictionary.
       if (next->coder->dict.size != lz_options.dict_size) {
           lzma_free(next->coder->dict.buf, allocator);
           next->coder->dict.buf = lzma_alloc(lz_options.dict_size, allocator);
       ...
   }

   lzma_alloc(size_t size, const lzma_allocator *allocator) {
       ...
       if (allocator != NULL && allocator->alloc != NULL)
           ptr = allocator->alloc(allocator->opaque, 1, size);
       else
           ptr = malloc(size);
       ...
   ```

   **Listing 4:** ClamAV’s additional erroneous check on dictionary size.
   ```c
   SRes LzmaDec_Allocate(.., const Byte *props, ...) {
       ...
       dicBufSize = propNew.dicSize;
       if (p->dic == 0 || dicBufSize != p->dicBufSize){
           ...
           // Invoke __xz_wrap_alloc()
           p->dic = (Byte *)alloc->Alloc(alloc, dicBufSize);
           if (p->dic == 0) {
               ...
               return SZ_ERROR_MEM;
           ...
   }

   void *__xz_wrap_alloc(void *unused, size_t size) {
       // Fails if size > (182*1024*1024)
       if(!size || size > CLI_MAX_ALLOCATION)
           return NULL;
       ...
   ```

#### X.509 Certificate Validation Discrepancies
We present two examples of certificate validation semantic bugs found by NEZHA, one involving LibreSSL and one GnuTLS.

1. **LibreSSL - Incorrect Parsing of Time Field Types:**
   The RFC standards for X.509 certificates restrict the Time fields to two forms: UTCTime (YYMMDDHHMMSSZ) and GeneralizedTime (YYYYMMDDHHMMSSZ), which are 13 and 15 characters wide, respectively. Despite these standards, we observe that 11- and 17-character time fields are used in practice. Some SSL libraries like OpenSSL and BoringSSL are more permissive in parsing such time fields. LibreSSL, however, tries to comply strictly with the standards but introduces a bug by ignoring the ASN.1 time format tag and inferring the time format type based on the length of the field. This can lead to LibreSSL erroneously parsing the time fields, treating valid certificates as not yet valid or accepting expired certificates.

   **Listing 5:** LibreSSL code that parses the time field.
   ```c
   int asn1_time_parse(..., size_t len, ..., int mode) {
       ...
       int type = 0;
       /* Constrain to valid lengths. */
       if (len != UTCTIME_LENGTH && len != GENTIME_LENGTH)
           return (-1);
       ...
       switch (len) {
           case GENTIME_LENGTH:
               // mode is "ignored" -- configured to 0 here
               if (mode == V_ASN1_UTCTIME)
                   return (-1);
       ...
   ```

These case studies highlight the importance of thorough testing and the effectiveness of NEZHA in identifying critical security vulnerabilities.