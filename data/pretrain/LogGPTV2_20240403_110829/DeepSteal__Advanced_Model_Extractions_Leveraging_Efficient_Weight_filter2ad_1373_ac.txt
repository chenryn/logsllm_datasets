3
2
1
3
1
P1
P2
P3
S
w
a
p
s
p
a
c
e
Attacker Page
2
P1
P2
P3
S
w
a
p
s
p
a
c
e
(a)
(b)
(c)
Fig. 5: Overview of the operations of HammerLeak.
Vulnerable cell
P1
P3
(d)
P2
①
②
③
(cid:4)(cid:9)(cid:6)(cid:17)(cid:9)(cid:11)(cid:1)(cid:14)(cid:5)(cid:8)(cid:7)
(cid:2)(cid:17)(cid:17)(cid:5)(cid:6)(cid:10)(cid:7)(cid:15)(cid:1)(cid:14)(cid:5)(cid:8)(cid:7)(cid:16)
(cid:2)(cid:4)(cid:7)(cid:9)(cid:1)(cid:8)(cid:6)(cid:8)(cid:10)(cid:12)(cid:15)
(cid:4) (cid:3)(cid:19)(cid:5)(cid:14)(cid:1)(cid:13)(cid:18)(cid:17)
(cid:5) (cid:3)(cid:19)(cid:5)(cid:14)(cid:1)(cid:9)(cid:12)
(cid:2)(cid:3)(cid:5)(cid:4)(cid:1)(cid:6)
(cid:3)(cid:14)(cid:4)(cid:11)(cid:1)(cid:13)(cid:11)(cid:4)(cid:5)(cid:6)
Fig. 6: Memory eviction technique occupying large memory
space by attacker, forcing victim data to swap out (x). When
victim accesses the data, its swap in (y) to a different location.
memory massaging is needed at the beginning of each round in
order to leak new bits. Note that the prior memory massaging
technique leveraging page deduplication (e.g., [64]) is not
applicable as the attacker is not aware of the victim’s page
content. Furthermore, page cache evictions as proposed in [52]
do not work well for relocating anonymous pages. We propose
a four-step HammerLeak framework to augment a practical
rowhammer-based side channel tackling these challenges.
Step 1: Anonymous Page Swapping. In the ﬁrst step, the
attacker aims to evict the victim’s pages from main memory
to swap space so that they later get relocated by the operating
system at the next time these pages are accessed by the victim.
During this step, the attacker ﬁrst allocates a large chunk of
memory using mmap with MAP_POPULATE ﬂag. This triggers the
OS to evict other data (including victim’s pages) from the main
memory to the swap space. At the end of this step (Figure 5a),
the attacker occupies most of the physical memory space with
victim pages stored in swap space. This procedure is illustrated
in Figure 6 where the victim page (Page 1) is swapped out of
main memory to the swap space (x). Once the victim accesses
this page again, the OS swaps in Page 1 to the main memory
at a new location (y).
Step 2: Bit Flip-aware Page Release. In this step, the at-
tacker process systematically releases his own pages during
victim’s execution to enforce desired relocations of victim’s
pages. By obtaining the knowledge of virtual to physical page
frame mapping of attacker’s process [7], [52], the attacker
ﬁrst creates a list of potential pages for the victim to occupy
as aggressors during the rowhammer-based leakage attack
(i.e., pages that are adjacent to a Tr holding one or more
Vc). At each round of HammerLeak, the attacker chooses
a predetermined number of pages from the list. Finally, the
attacker releases the selected pages (i.e., by calling munmap)
as illustrated in Figure 5b.
Step 3: Deterministic Victim Relocation. In this step, the
attacker manages to place victim pages in predetermined loca-
this also ensures that
tions to create an appropriate memory layout for rowhammer.
Crucially,
the victim page location
is known to the attacker so that the attacker can correlate
leaked bits with exact data in the victim domain. We ex-
ploit the per-core page-frame cache structure (i.e., per-cpu
pageset [65]) to manipulate the OS page allocation, which
allows the attacker to control where the victim pages are
relocated. Speciﬁcally, per-core pageset is a last-in-ﬁrst-out
(LIFO) structure maintained by the Linux kernel that holds the
recently-freed pages by processes running on that core. When
the OS needs to allocate a page for a process, it ﬁrst checks
the pageset corresponding to the core to obtain a free memory
location. We exploit the LIFO policy to deterministically place
victim pages into the desired memory locations by running
the attacker process on the same core. In particular, based on
the order of pages released by the attacker during Step 2, the
relocation of victim pages can be performed with extremely
high accuracy [37] as illustrated in Figure 5c. Here P1 (page
1), P2 and P3 are allocated for the victim in order and these
pages are placed in memory location 3,2 and 1 respectively
following the reverse order of page release during Step 2.
Step 4: Recovering Secrets Using Rowhammer. After Step
3, the victim pages are placed in the appropriate locations. The
attacker mounts our rowhammer-based information leakage
attack (as discussed in Section V-A) to steal victim’s data.
Based on the ﬂip direction of a speciﬁc Vc (i.e., ﬂip in either
0→1 or 1→0 direction), we preset the Vc and adjacent attacker
controlled aggressor row bit respectively to 0-1 (for 0→1) or
1-0 (for 1→0). After hammering, the attacker reads the value
of Vc and examines for bit ﬂips. An observed bit ﬂip indicates
that the adjacent bit in victim controlled aggressor row is the
same as the preset bit in the attacker’s controlled aggressor
row. This way, the attacker recovers secret bits from all of the
selected Tr iteratively to maximize the data leakage in one
round of HammerLeak.
C. Batched Victim Page Massaging
While the one-time bit ﬂip-aware page release during one
round of HammerLeak is sufﬁcient for victim programs with
small memory footprints, this is not the case for applications
with large memory allocations since the per-cpu pageset has
a ﬁxed size. For applications that have a large working set
(i.e., larger than 2MB), deterministic victim page relocation
cannot be guaranteed if all targeted pages in the victim in one
round are released at once during Step 2. This is because if
the required number of pages exceeds the size of pageset, the
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:59:25 UTC from IEEE Xplore.  Restrictions apply. 
1162
pageset will be overﬂown and the system will start to release
some of the free pages to the global memory pool. At that
point, the attacker can no longer leverage the LIFO policy of
pageset to perform deterministic page relocation.
We propose batched victim page massaging to tackle this
challenge. Speciﬁcally, HammerLeak periodically releases a
small number of pages at speciﬁc points (i.e., anchor points)
of victim execution so that the pageset does not get overﬂown.
Additionally, this allows the attacker to have better control
over ﬁltering non-secretive victim pages by placing them at
non-leakable locations. In order to determine when to release
leakable pages, the attacker needs to monitor victim’s activities
that
lead to secretive page access. We built a cache side
channel based tracking tool to set up function anchor point
for this monitoring purpose. Speciﬁcally, we assume that the
attacker and the victim application share the same library
(which results in shared read-only physical pages [58]). For
applications using open-source libraries (common for many
crypto algorithm implementations and ML applications), the
attacker analyzes and determines the execution points that
access the targeted secret (e.g., DNN model weights) through
source/binary code inspection (e.g., speciﬁc functions per-
forming computation using secretive data). The attacker then
launches the Flush+Reload attack [31] at certain anchor points
in those functions to synchronize with the victim’s execution.
Through inspection of victim’s execution ﬂow, the attacker can
determine the victim’s memory access pattern (e.g., whether
there are non-secretive page accesses between a chunk for
secret page access) and derive the number of non-secretive
pages the victim allocates after each anchor point, which
guides the page releasing in batch.
Putting everything together, prior to the attack, the attacker
determines anchor points in victim’s execution path, which
symbolizes the victim accessing certain secret. The attacker
also determines secret page access pattern (i.e., number of
non-secretive pages before accessing the secret–Pb, secret
page accesses–Ps, and intermediate non-secretive pages access
between secrets–Pi). During the attack phase, the adversary
monitors access to the anchor points. Once the victim access
is detected, the attacker releases Pb + Ps + Pi = P physical
pages in reverse order of victim’s page accesses (i.e., LIFO
access). Out of these pages, only Ps pages need to be in the
adjacent rows to Vc for information leakage. If Ps is larger
than the size of per-core pageset, the attacker will choose a
different anchor point, which effectively divides the victim
secret page access into additional smaller chunks. By chaining
several page batches for memory massaging, HammerLeak can
eventually steal bits spawning hundreds to thousands of pages
in each round, enabling bit leakage in bulk.
VI. SUBSTITUTE MODEL TRAINING WITH MEAN
CLUSTERING
At Stage-2 of DeepSteal, we leverage the bit information
leaked by HammerLeak to learn a substitute prototype of the
victim DNN model. To fully leverage those leaked partial bit-
wise data, we propose a novel substitute model training algo-
rithm to reconstruct a neural network model, targeting high
accuracy and high ﬁdelity. Moreover, this learned substitute
model will help the attacker generate highly effective adver-
sarial input samples to fool the victim model successfully.
Fig. 7: First row: N-Bit quantized weight level; Second row:
Once the MSB of weight Wt in the victim model is leaked, we
can narrow down the projected range of Wt in the substitute
model; Last row: Leaking all the bits can track down the exact
value of Wt for the substitute model training.
A. Hammer Leaked Data Filtering
At stage-1, HammerLeak recovers a portion of the neu-
ral network weight bit information scattered across different
signiﬁcant bits (i.e., from LSB to MSB) for each weight.
However, not all of those recovered bits will be used for
substitute model training since it is a mixture of signiﬁcant
bits for each weight. As shown in Figure 7, for each weight
parameter, it is preferred to recover MSB ﬁrst. Thus it forms
a smaller and closed searching space (i.e., either positive or
negative), rather than full-scale space, for this weight during
substitute model training to minimize loss. With the knowledge
of MSB, the 2nd MSB or more following bits will further
reduce the closed searching space. Otherwise, only recovering
lower signiﬁcant bits, without higher signiﬁcant bits, does not
provide much useful information about this weight’s potential
range. As a consequence, to use the leaked bit information
effectively, the attacker must ﬁlter and reorganize the leaked
bits in a sequence from MSB to LSB. Therefore, before
substitute model training, we sort out the leaked weight bits in
the following sequence: MSB leaked, MSB+2nd MSB leaked,
MSB+(2nd & 3rd MSB) leaked, and so on, to develop a proﬁle
for each weight with a projected range, as described in Figure
7. Note that, if no MSB is recovered, the projected weight
value range will be treated as full scale.
In Figure 7, we visualize the relationship between i) ﬁltered
bits (leaked by HammerLeak) information of weights from a
victim model and ii) the expected range of that corresponding
weight during the training of the substitute model. It shows
gradually leaking more bit information (i.e., MSB, MSB+2nd
MSB,..) of one target weight Wt can help an attacker reduce
the searching space of Wt during model training. We deﬁne
this expected range as projected range of each weight in the
substitute model.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:59:25 UTC from IEEE Xplore.  Restrictions apply. 
1163
B. Mean Clustering Optimization
Leveraging the proﬁle of such projected range of each
weight, we propose a novel training algorithm for the substi-
tute model using Mean Clustering weight penalty. It applies
an additional loss penalty to the cross-entropy loss during
the training process. The Mean Clustering penalty term aims
to penalize each weight to converge near the mean of the
projected range.
To formally deﬁne the problem, let’s consider the weight
matrix of the victim DNN model at layer l to be ˆW l. Based
on the leaked weight bits at this layer, the attacker can compute
the projected range of each weight in the substitute model W l.
The projected range can be represented as: W l
max
matrix; the minimum and maximum projected value matrix
corresponding to each weight in W l. Using this closed range,
the projected mean matrix W l
max
+ W l
min)/2. Next, leveraging this mean matrix, we propose
to design a Mean Clustering loss penalty as highlighted in
Equation (1). This loss term is added to the inference loss L
and the optimization process can be formulated as:
mean is computed as: (W l
min & W l
l=1), y)+
min
{Wl}L
l=1
Ex L(f (x,{Wl}L
λ · L(cid:2)
(cid:3)
(||Wl − Wl
(cid:4)(cid:5)
l=1
mean||)
(cid:6)
(1)
l=1)
Takes victim model architecture ˆMθ as input
Takes the leaked parameter list ˆθL
l=1 as input.
Randomly Initialize Substitute model Mθ.
Perform step-1, data ﬁltering of the leaked bits.
for Each layer l = 1, . . . , L do
Algorithm 1 Substitute Model Training with Mean Clustering
1: procedure TRAIN SUBSTITUTE MODEL (Mθ, ˆMθ, ˆθL
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
Re-Initialize model Mθ using following rules:
Weight Set-1 (Full 8-bit recovered): Initialize the
weights at the exact recovered value. This weight set
will not be trained (i.e., set gradients to zero).
Compute Initial W l
Estimate W l
max using ˆθl.
mean = (W l
min & W l
min+ W l
end for
max)/2.
-
-
13:
14:
n = 0, . . ., 6)): Initialize the weights using the
{W l
Weight Set-2 (Partial bit recovered (i.e., MSB+n;
mean}L
Weight Set-3 (0 bit
l=1 matrix & set λ suitably.
recovered): Random Initialization
-
-
- & set λ in Equation (1) to zero.
for each training iteration do
for each training batch (x, y) do
Compute Loss using Equation (1).
Perform a gradient descent step to update θ.
Update W l
max & W l
min, W l
mean.
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25: end procedure
end for
Clip {W l}L
l=1 within the projected range.
end for
Return: Trained Substitute Model Mθ.
loss penalty for Mean Clustering