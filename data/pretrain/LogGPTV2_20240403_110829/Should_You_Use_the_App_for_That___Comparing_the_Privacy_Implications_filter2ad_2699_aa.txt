title:Should You Use the App for That?: Comparing the Privacy Implications
of App- and Web-based Online Services
author:Christophe Leung and
Jingjing Ren and
David R. Choffnes and
Christo Wilson
Should You Use the App for That?
Comparing the Privacy Implications of App- and
Web-based Online Services
Christophe Leung, Jingjing Ren, David Choffnes, Christo Wilson
Northeastern University
{tophe, renjj, choffnes, cbw}@ccs.neu.edu
ABSTRACT
Many popular, free online services provide cross-platform
interfaces via Web browsers as well as apps on iOS and An-
droid. To monetize these services, many additionally include
tracking and advertising libraries that gather information
about users with signiﬁcant privacy implications. Given that
the Web-based and mobile-app-based ecosystems evolve in-
dependently, an important open question is how these plat-
forms compare with respect to user privacy.
In this paper, we conduct the ﬁrst head-to-head study of
50 popular, free online services to understand which is better
for privacy—Web or app? We conduct manual tests, extract
personally identiﬁable information (PII) shared over plain-
text and encrypted connections, and analyze the data to un-
derstand diﬀerences in user-data collection across platforms
for the same service. While we ﬁnd that all platforms ex-
pose users’ data, there are still opportunities to signiﬁcantly
limit how much information is shared with other parties by
selectively using the app or Web version of a service.
1.
INTRODUCTION
Web browsers and mobile apps are the dominant media
through which people interact with online services such as
social media, news, weather, and dating. Many of these ser-
vices are provided for free to users, with providers support-
ing their costs through revenue from advertising and data
analytics. This necessarily raises important privacy con-
cerns regarding what information is collected about users
and how it is used.
Previous work investigates the question of what infor-
mation is collected, either in the Web browsing environ-
ment [8, 15, 22, 24, 33–35] or in the mobile environment
[29, 38, 42]. A close reading of this literature reveals dif-
ferences between these media, with the Web having more
sophisticated tracking infrastructure overall, versus apps
which have more direct access to sensitive information
through APIs. However, to date no work has directly com-
pared these media for the same service to understand a fun-
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
IMC ’16, November 14–16, Santa Monica, CA, USA.
c(cid:13) 2016 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ISBN 978-1-4503-4526-2/16/11. . . $15.00
DOI: http://dx.doi.org/10.1145/2987443.2987456
damental question:
privacy—app or Web?
is there a medium that is better for
This paper provides a ﬁrst look at this issue, which re-
quires addressing two key challenges. First, we must gather
a representative sample of information that large numbers
of online services expose of the Internet, both via apps and
Web sites. Second, we must reliably identify the personally
identiﬁable information (PII) in network traﬃc generated by
these services. By providing greater transparency into how
apps and Web sites share PII, we seek to provide the com-
munity with better insight into the data collected by speciﬁc
apps and Web sites, as well as help users make informed de-
cisions about how they interact with online services.
To address the ﬁrst challenge, we use a dataset consisting
of network traces gathered from manual interactions with
iOS, Android, and Web versions of the same 50 free on-
line services. This includes major services like The Weather
Channel, Yelp, and BBC News. We address the second chal-
lenge by conducting controlled experiments where ground-
truth information about users’ PII, coupled with state-
of-the-art inference techniques to identify PII in network
ﬂows [38]. Unlike our prior work that exclusively focuses on
PII leaked by apps, this paper aims to provide a comparison
of Web- and app-based data collection by the same service.
Using this approach, we determine the PII exposed by
services over plaintext and/or to advertising and analytics
(A&A) third-party domains, and analyze their implications
on privacy. Our key ﬁndings are as follows.
• Should you use the app? It depends. Due to
the potentially large set of PII that apps can access
with user permission, we expected that they would
generally leak more PII than Web sites. However, we
ﬁnd that in 40% of cases, Web sites leak more types of
information than apps. To help guide users toward us-
ing an app or Web site for a speciﬁc service, we provide
an online interactive interface that makes custom sug-
gestions based on user-speciﬁed privacy preferences at:
• What information leaks more from diﬀerent
media? We ﬁnd that locations and names leak more
often from Web sites than from apps, whereas only
apps leak unique identiﬁers and other device-speciﬁc
information. Surprisingly, we ﬁnd passwords leaked
(albeit over HTTPS) to third parties that have no rea-
son to receive them.
• Web sites directly contact more trackers and
advertisers than apps. We ﬁnd that Web sites of-
ten include content from multiple advertisers and third
https://recon.meddle.mobi/appvsweb/
parties, and cause browsers to redirect through several
more via real-time bidding.
In contrast, most apps
include a single advertisement library, which contacts
fewer domains.
• How much tracking is in common between app
and Web for the same service? We ﬁnd that both
apps and Web sites can leak locations, names, gender,
phone number, and e-mail addresses. Unlike for apps,
we found no evidence in our tests that Web sites are
able to access and share device-speciﬁc unique identi-
ﬁers, such as an IMEI and a MAC address. Whether
this is true for other services remains an open question.
In addition to providing an online interface to make
customized privacy recommendations, we make our dataset
and code available at:
https://recon.meddle.mobi/appvsweb/
2. BACKGROUND AND RELATED WORK
Users are increasingly concerned with the amount of track-
ing and data collection conducted by online services [32,41].
In response, regulators such as the FTC, FCC, and the EU
Commission enacted rules that protect consumer privacy;
non-proﬁts such as the Data Transparency Lab and Mozilla
support eﬀorts to increase transparency of online tracking;
and tools like AdBlock and Disconnect limit tracking.
These eﬀorts are supported by a large body of research
that identiﬁes when Personally Identiﬁable Information
(PII) is exposed by online services. Previous work focuses
either on Web sites or apps to determine privacy risks, but
not both. In contrast, to the best of our knowledge, we are
the ﬁrst to directly compare information gathered through
Web sites and apps for the same online service, allowing us
to provide a relative ranking of which one is less invasive ac-
cording to various metrics. Although this study represents
a snapshot of online service behavior at one point in time,
our approach is general and can be repeated to observe how
the privacy landscape evolves.
2.1 Web Privacy
Well before there were apps and modern smartphones, re-
searchers observed that advertisers and analytics companies
were tracking users via Web site content [25]. These ini-
tial observations motivated a wide range of research on Web
tracking, from understanding the tracking ecosystem over
time and the economics behind it [11, 18, 26, 27], to identify-
ing speciﬁc techniques used to track users [5,8,15,22,24,33–
35,39], to examining how tracking varies geographically [16].
While several proposals attempt to help users regain control
over their privacy when browsing the Web [28, 36], tracking
remains pervasive.
Unlike prior work, our paper focuses on characterizing
third-party tracking and the PII they collect for services that
are also available as apps. Further, to the best of our knowl-
edge no other study focuses on Web tracking and its privacy
implications from mobile browsers. (For our purposes, only
the operating system’s native browser application is consid-
ered. Embedded browser components such as WebViews are
not included.) This is an increasingly important distinction,
as mobile browsers have access to sensors (e.g., GPS) that
are not available on desktops.
2.2 Mobile App Privacy
Due to the rich sensors, APIs, and availability of PII
on mobile devices, a large body of work focuses on under-
standing privacy from the perspective of tracking and data-
collection by mobile apps. Early testbed studies showed that
popular apps exposed location, usernames, passwords, and
phone numbers [40]. Follow-up work observed similar behav-
ior at scale “in-the-wild” [29, 38, 42]. A number of projects
focus on detecting and mitigating privacy violations from
mobile apps [6, 7, 12, 14, 17, 19, 21, 23, 30, 38, 43–46].
In this paper, we focus on comparing the PII exposed by
mobile apps and Web sites for the same service. To accom-
plish this, we use tools from prior work [38] to identify PII
leaks in mobile-device traﬃc.
2.3 Mobile Experimentation Methods
For scalability reasons, most previous work uses auto-
mated tests to analyze mobile apps [9, 20, 31]. However, a
key limitation of this approach is that they cannot automat-
ically explore apps that require signing in [13]. Further, our
recent study shows that automated tools only reveal a small
fraction of the PII exposed when manually interacting with
apps [38]. In this work, we use manual tests of Web sites and
apps, both to ensure that the PII exposure is representative
of what users would see, and to ensure that we explore the
same features of the service across both Web and app.
3. DATA COLLECTION
In this section, we describe the online services we investi-
gated, our experimental methodology for eliciting and iden-
tifying PII sent over the network, and high-level statistics
about our gathered dataset.
3.1 Selecting Online Services
Our ﬁrst task is selecting online services to measure, each
of which must meet the following criteria: 1) it must be pop-
ular (according to app store rankings) and/or “featured” in
an app store, 2) it must provide a free app in the Google
Play Store and the Apple App Store, 3) it must provide
equivalent functionality via a mobile Web browser, and 4)
it must not implement certiﬁcate pinning. For example, In-
stagram fails criteria (3) because the mobile Web site does
not oﬀer the same functionality as its app. Similarly, Pan-
dora fails because it will not stream music via Chrome on
Android. Facebook’s app fails criteria (4). In general, we
omitted any service for which we could not make an apples-
to-apples comparison.
To locate candidate apps, we crawled the top 100 free An-
droid apps listed in the US version of the Google Play Store
on March 23, 2016. To avoid personalized recommendations
that would impact the set of presented apps, we browsed
the Google Play Store with a clean browsing history and no
cookies stored. Only 75 apps met the requirements for our
study. We added to this set “featured and recommended”
apps that were promoted on the home page of the Google
Play Store. In total, we selected a subset of 50 services to
test, and chose them based on broadly covering popular apps
across diﬀerent app categories, then ﬁlling in with apps that
are likely to collect PII (shopping, travel, entertainment).
While we cannot make any claims about generality, we be-
lieve this set provides an interesting cross-section of online
services with respect to privacy.
3.2 Experiment Methodology
Understanding privacy implications of mobile apps and
Web sites requires interacting with these services in ways
that normal users would. Using automated testing frame-
works for this purpose is tempting, due to their simplicity,
low eﬀort, and ability to test large numbers of apps in a short
period of time. However, previous work show that such tests
miss important UI features (e.g., logging in, entering valid
user data into text ﬁelds) [38]; further, there is a lack of good
automated testing tools for iOS and for mobile browsers.
Instead, we conducted manual tests of 50 online services.
Manual tests avoid the pitfalls of automated ones because
testers can interpret UIs, enter reasonable data into arbi-
trary ﬁelds, and ensure similar (or identical) service func-
tionality is exercised both over apps and Web sites. While
we cannot claim generality or representativeness based on
the 50 online services we tested, these comprise some of the
most popular services used in the United States. We used
the following procedures to test each online service.
Test Environment.
Each test consisted of interacting
with a given service via an app or Web site for four min-
utes. We collected network traﬃc generated during each
experiment using Meddle [37], and used Mitmproxy [3] to
capture both HTTP and the plaintext content of HTTPS
ﬂows. For each service requiring a login, we created a new
account using a previously unused email address.
We used two phones (a Nexus 4 and a Nexus 5) running
stock Android 4.4, and an iPhone 5 running
iOS 9.3.1.
We speciﬁcally chose to test on Android 4.4 because it was
the most common Android version in-the-wild as of April
2016 [4]. All three phones were factory reset before our ex-
periments, and included no apps beyond the stock services
and the 50 apps evaluated in this work.
Interacting with Services.
Each experiment used
the following steps. We installed the service’s app, then
connected the device to Meddle using a VPN tunnel. Next,
we opened the app and used it for its intended purpose for
approximately four minutes. We approved any system per-
mission requests when prompted. After the time expired,
we closed the VPN connection and uninstalled the app.
We repeated this procedure using the operating system’s
default browser: Chrome for Android, and Safari on iOS.
To avoid contamination due to browsing history and stored
cookies, we used “private mode” browsing. When interacting
with the Web version of the service, we attempted to conduct
identical operations as in the app (to the extent possible).
To ensure fairness, when asked to log-in, we used the same
pre-created account credentials used to test the app.
Note that we cannot claim to exhaustively cover all poten-
tial PII leaks using only four minutes of manual app testing.
However, based on a number of tests using longer durations
(10 minutes) for a subset of apps (the ﬁve apps that leaked
the most and least during four-minute tests), we found that
four minutes strikes a good balance between providing ad-
equate time to use most features of a service, and quickly
covering a reasonably large number of services in a ﬁxed
amount of time. Speciﬁcally, we found that the number
of third parties contacted and number of times PII leaked
were roughly proportional to the duration of the experiment
(because longer experiment durations lead to more network
ﬂows), but we generally did not see additional types of PII
leaked during the longer experiment duration (with the ex-
ception of one additional PII type, e-mail address, leaked
from one app after four minutes).
Regardless, our results represent a conservative lower
bound on the PII leaked from apps and Web sites. Based
on the substantial amount of leaks discovered, we believe
this to be an important ﬁrst step toward understanding dif-
ferences between PII leaks over apps and Web sites.
Filtering.
One issue with collecting network traces
from mobile devices is that ﬂows may be generated by the
foreground process (i.e., the app or Web site we are investi-
gating) or background processes. We use three methods to
minimize background traﬃc from our traces. First, we use a
clean, factory-reset lab phone to conduct the tests. Second,
we turn oﬀ background synchronization and manually close
all background apps before each experiment. Finally, we ﬁl-
ter traﬃc to domains that are known to be associated with
OS services (e.g., Google Play Services and Apple iCloud).
Identifying PII.
The next step in our methodology is
identifying PII in our network traces. This task is greatly
simpliﬁed because our experiments are controlled, i.e., we
know all the PII that is available on our test devices. This in-
cludes usernames and passwords, MAC address, IMEI, GPS
coordinates, ZIP code, etc.
However, knowing the PII in advance is not a catch-all for
detecting it in network traﬃc. GPS locations are sent with
arbitrary precision, unique identiﬁers are formatted incon-
sistently, a user’s inferred gender is not stored in the phone,
etc. Thus, we use the following approach to identify PII.
First, we use the automated ReCon tool [38], which uses ma-
chine learning to detect likely PII in network traﬃc without
needing to know the precise PII values. Second, to minimize
the risk of ReCon missing PII, we augment its results with
PII found via direct string matching on known PII. Finally,
we manually verify ReCon predictions and excluded false
positives based on our ground-truth information.