title:Checking Array Bound Violation Using Segmentation Hardware
author:Lap-Chung Lam and
Tzi-cker Chiueh
Checking Array Bound Violation Using Segmentation Hardware
Lap-chung Lam Tzi-cker Chiueh
Computer Science Department
{lclam, chiueh}@cs.sunysb.edu
Stony Brook University
Abstract
The ability to check memory references against their as-
sociated array/buffer bounds helps programmers to detect
programming errors involving address overruns early on
and thus avoid many difﬁcult bugs down the line. This paper
proposes a novel approach called Cash to the array bound
checking problem that exploits the segmentation feature in
the virtual memory hardware of the X86 architecture. The
Cash approach allocates a separate segment to each static
array or dynamically allocated buffer, and generates the in-
structions for array references in such a way that the seg-
ment limit check in X86’s virtual memory protection mecha-
nism performs the necessary array bound checking for free.
In those cases that hardware bound checking is not possi-
ble, it falls back to software bound checking. As a result,
Cash does not need to pay per-reference software checking
overhead in most cases. However, the Cash approach in-
curs a ﬁxed set-up overhead for each use of an array, which
may involve multiple array references. The existence of this
overhead requires compiler writers to judiciously apply the
proposed technique to minimize the performance cost of ar-
ray bound checking. This paper presents the detailed design
and implementation of the Cash compiler, and a compre-
hensive evaluation of various performance tradeoffs asso-
ciated with the proposed array bound checking technique.
For the set of complicated network applications we tested,
including Apache, Sendmail, Bind, etc., the latency penalty
of Cash’s bound checking mechanism is between 2.5% to
9.8% when compared with the baseline case that does not
perform any bound checking.
1
Introduction
Checking memory references against the bounds of the
data structures they belong to at run time provides a valu-
able tool for early detection of programming errors that
could have otherwise resulted in subtle bugs or total appli-
cation failures. In some cases, these software errors might
lead to security holes that attackers exploit to break into
computer systems and cause substantial ﬁnancial losses.
For example, the buffer overﬂow attack, which accounts for
more than 50% of the vulnerabilities reported in the CERT
advisory over the last decade [3, 14, 18], exploits the lack
of array bound checking in the compiler and in the applica-
tions themselves, and subverts the victim programs to trans-
fer control to a dynamically injected code segment. Al-
though various solutions have been proposed to subjugate
the buffer overﬂow attack, inoculating application programs
with strict array bound checking is considered the best de-
fense against this attack. Despite these beneﬁts, in practice
most applications developers still choose to shy away from
array bound checking because its performance overhead is
considered too high to be acceptable [13]. This paper de-
scribes a novel approach to the array bound checking prob-
lem that can reduce the array bound checking overhead to
a fraction of the input program’s original execution time,
and thus make it practical to apply array bound checking to
real-world programs.
The general problem of bound checking requires com-
paring the target address of each memory reference against
the bound of its associated data structure, which could be a
statically allocated array, or a dynamically allocated array
or heap region. Accordingly, bound checking involves two
subproblems: (1) identifying a given memory reference’s
associated data structure and thus its bound, and (2) com-
paring the reference’s address with the bound and raising
an exception if the bound is violated. The ﬁrst subprob-
lem is complicated by the existence of pointer variables. As
pointers are used in generating target memory addresses, it
is necessary to carry with pointers the ID of the objects they
point to, so that the associated bounds could be used to per-
form bound checking. There are two general approaches
to this subproblem. The ﬁrst approach, used in BCC [4],
tags each pointer with additional ﬁelds to store information
about its associated object or data structure. These ﬁelds
could be a physical extension of a pointer, or a shadow vari-
able. The second approach [12] maintains an index struc-
ture that keeps track of the mapping between high-level ob-
jects and their address ranges, and dynamically searches
this index structure with a memory reference’s target ad-
dress to identify the reference’s associated object. The ﬁrst
approach performs much faster than the second, but at the
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
expense of compatibility of legacy binary code that does not
support bound checking. The second subproblem accounts
for most of the bound checking overhead, and indeed most
of the research efforts in the literature were focused on how
to cut down the performance cost of address-bound com-
parison, through techniques such as redundancy elimination
or parallel execution. At the highest compiler optimiza-
tion level, the minimum number of instructions required in
BCC [4], a GCC-derived array bound checking compiler,
to check a reference in a C-like program against its lower
and upper bounds is 6, two to load the bounds, two compar-
isons, and two conditional branches. In programs that in-
volve many array references, this bound checking overhead
could lead to serious performance penalty, even in the pres-
ence of various software optimizations. In this paper, we
propose a new approach, called Cash1, which exploits the
segmentation support in the virtual memory hardware of In-
tel’s X86 architecture [10] to perform array bound checking
without any per-reference overhead. A segment in the X86
architecture can be of arbitrary size, ranging from a single
byte to an entire address space. To provide inter-segment
protection, X86’s virtual memory hardware compares every
memory reference with its associated segment’s base ad-
dress and limit, thus essentially checking it against the seg-
ment’s lower and upper bounds. Recognizing the similarity
between segment bound check and array bound check, Cash
allocates a separate segment to each array, and generates the
array reference instructions in such a way that the X86 ar-
chitecture’s segment bound checking hardware effectively
performs the required array bound check for free. When
array bound checking is done through segmentation hard-
ware, there is no per-reference overhead. However, in some
cases hardware bound checking is not possible, and Cash
falls back to traditional software bound checking. There-
fore, the overhead of Cash mainly comes from additional
segments set-up required for hardware bound checking, and
occasional software-based bound checking.
The general bound checking problem requires checking
for each memory reference, including references to a ﬁeld
within a C-like structure. However, because the X86 archi-
tecture only supports a ﬁxed number of segments (8192),
allocating a segment to each object may quickly exhaust
all the available segments.
In addition, because Cash in-
curs a per-object set-up overhead, checking against bounds
of non-array objects may actually slow down the programs
even more than the software approach. For these reasons,
the current Cash prototype focuses only on bound check-
ing for array-like references inside a loop, i.e., those of
the form A[i], A++, ++A, A--, or --A, where A
could be a pointer to a static array or a dynamically allo-
cated buffer. For example, if a dynamic buffer is allocated
through a malloc() call of the following form
X = (* TYPE) malloc(N * sizeof(TYPE))
1Checking Array bounds using Segmentation Hardware
where N is larger than 1, then Cash takes X as a pointer into
an array of N elements, and Cash will check the references
based on X if these references are used inside a loop. Be-
cause all known buffer overﬂow attacks take place in a loop
context, focusing only on array-like references that are in a
loop does not compromise Cash’s protection strength.
The rest of this paper is organized as follows. Section
2 reviews previous work on array bound checking and con-
trasts Cash with these efforts. Section 3 describes the de-
tailed design decisions of the Cash compiler and their ra-
tionale. Section 4 presents a performance evaluation of the
Cash compiler based on a set of array-intensive programs,
and a discussion of various performance overheads associ-
ated with the Cash approach. Section 5 concludes this paper
with a summary of the main research ideas and a brief out-
line of the on-going improvements to the Cash prototype.
2 Related Work
Most previous array bound checking research focused on
the minimization of run-time performance overhead. One
notable exception is the work from the Imperial College
group [12], which chose to attack the reference/objection
association problem in the presence of legacy library
routines. The general approach towards optimizing ar-
ray bound checking overhead is to eliminate unnecessary
checks, so that the number of checks is reduced. Gupta [15,
16] proposed a ﬂow analysis technique that avoids redun-
dant bound checks in such a way that it still guaranteed to
identify any array bound violation in the input programs,
although it does not necessarily detect these violations im-
mediately after they occur at run time. By trading detection
immediacy for reduced overhead, this approach is able to
hoist some of the bound checking code outside the loop and
thus reduce the performance cost of array bound checking
signiﬁcantly. Asuru [11] and Kolte and Wolfe [13] extended
this work with more detailed analysis to further reduce the
range check overhead.
Concurrent array bound checking [6] ﬁrst derives from
a given program a reduce version that contains all the array
references and their associated bound checking code, and
then runs the derived version and the original version on
separate processors in parallel. With the aid of a separate
processor, this approach is able to achieve the lowest array
bound checking overhead reported until the arrival of Cash.
Unlike most other array bound checking compiler
projects,
the Bounds Checking GCC compiler (BCC)
checks the bounds for both array references and general
pointers. Among the systems that perform both types of
bound checks, BCC shows the best software-only bound
checking performance. However, BCC only checks the up-
per bound of an array when the array is accessed directly
through the array variable (not pointer variable) while Cash
automatically checks both the upper and lower bounds.
Since the Cash compiler is based on BCC, it can also check
the bounds for general pointers.
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Virtual   Address
Segment Selector
T
I PL
0
2
16
Offset
31
0
Physical
Address
+
Linear
Address
GDT/LDT
19
Limit
19:16
31
24
Base
31:24
31
Base
15:00
16
P
13
15
DPL
Limit
15:00
16
7
Base
23:16
0
0
+4
+0
Descriptor Format
Two−Level
Page Table
Page Frame Address
31
12
U W
P
2
1 0
Page Table Entry Format
Figure 1. MemorytranslationprocessintheX86ar-
chitecture’svirtualmemoryhardware
Intel X86 architecture includes a bound instruction [9]
for array bound checking. However, the bound instruction is
not widely used because on 80486 and Pentium processors,
the bound instruction is slower than the six normal equiv-
alent instructions. The bound instruction requires 7 cycles
on a 1.1 GHz P3 machine while the 6 equivalent instruc-
tions require 6 cycles. Although the segmentation hard-
ware feature has existed since the 386 days, this architec-
tural feature was never exploited by the operating systems
or the compiler writers. A conspicuous exception is the Pal-
ladium system [19], which exploits segmentation hardware
for intra-address space protection, which achieves the low-
est inter-protection domain control transfer overhead that
has ever been reported in the literature. Glen Pearson de-
scribed a programming technique for programmers to ex-
ploit segmentation hardware in a way similar to Cash to
add array bound checking to DOS applications [5]. Glen
Pearson replaced the Turbo C malloc library with his own
library, which allocates a new segment for each dynami-
cally allocated buffer. However, this method cannot deal
with the arrays not allocated through malloc since it re-
quires the modiﬁcation of the compiler. According to our
best knowledge, Cash is the only C compiler that utilizes
the segmentation hardware to optimize the bound checking
of both static and dynamic allocated arrays.
3 The Cash Approach
3.1 Segmentation-Based Virtual Memory Sup-
port in the X86 Architecture
Before describing the detailed design of the Cash com-
piler,
let’s brieﬂy review the X86 architecture’s virtual
memory hardware. Intel X86 architecture’s virtual mem-
ory hardware supports both variable-length segments and
ﬁxed-sized pages, as shown in Figure 1. A virtual address
consists of a 16-bit segment selector, which resides in one of
the six on-chip segment registers, and a 32-bit offset, which
is given by EIP register for instruction references, ESP reg-
ister for stack operations, or other registers/operands in the
case of data references. The segment selector contains a
13-bit index into the Global Descriptor Table (GDT) or the
current process’s Local Descriptor Table (LDT). The choice
between GDT and LDT is determined by a TI bit in the seg-
ment selector. Each process has its own LDT whereas the
GDT is shared among processes. The number of entries
in each LDT and the GDT is 8192. The GDT or LDT entry
indexed by the segment selector contains a segment descrip-
tor, which, among other things, includes the base and limit
addresses of the segment, the segment’s descriptor privilege
level (DPL), and read/write protection bits. The 32-bit off-
set is added to the associated segment’s start address to form
a 32-bit linear address. The most signiﬁcant 20 bits of a lin-
ear address are a virtual memory page number and are used
to index into a two-level page table to identify the corre-
sponding physical page’s base address, to which the remain-
ing 12 bits are added to form the ﬁnal physical address. The
page size is 4 Kbytes.
The ﬁrst entry of the GDT is not used by the X86 ar-
chitecture. A segment selector that points to this entry of
the GDT (that is, a segment selector with an index of 0 and
the TI ﬂag set to 0) is used as a null segment selector. The
processor does not generate an exception when a segment
register (other than the code and stack segment registers) is
loaded with a null selector. It does, however, generate an
exception when a segment register holding a null selector is