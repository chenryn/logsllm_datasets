# 熔断设计的重点在实现熔断器模式的时候，以下这些因素需可能需要考虑。-   **错误的类型**。需要注意的是请求失败的原因会有很多种。你需要根据不同的错误情况来调整相应的策略。所以，熔断和重试一样，需要对返回的错误进行识别。一些错误先走重试的策略（比如限流，或是超时），重试几次后再打开熔断。一些错误是远程服务挂掉，恢复时间比较长；这种错误不必走重试，就可以直接打开熔断策略。-   **日志监控**。熔断器应该能够记录所有失败的请求，以及一些可能会尝试成功的请求，使得管理员能够监控使用熔断器保护服务的执行情况。-   **测试服务是否可用**。在断开状态下，熔断器可以采用定期地 ping    一下远程服务的健康检查接口，来判断服务是否恢复，而不是使用计时器来自动切换到半开状态。这样做的一个好处是，在服务恢复的情况下，不需要真实的用户流量就可以把状态从半开状态切回关闭状态。否则在半开状态下，即便服务已恢复了，也需要用户真实的请求来恢复，这会影响用户的真实请求。-   **手动重置**。在系统中对于失败操作的恢复时间是很难确定的，提供一个手动重置功能能够使得管理员可以手动地强制将熔断器切换到闭合状态。同样的，如果受熔断器保护的服务暂时不可用的话，管理员能够强制将熔断器设置为断开状态。-   **并发问题**。相同的熔断器有可能被大量并发请求同时访问。熔断器的实现不应该阻塞并发的请求或者增加每次请求调用的负担。尤其是其中对调用结果的统计，一般来说会成为一个共享的数据结构，它会导致有锁的情况。在这种情况下，最好使用一些无锁的数据结构，或是    atomic 的原子操作。这样会带来更好的性能。-   **资源分区**。有时候，我们会把资源分布在不同的分区上。比如，数据库的分库分表，某个分区可能出现问题，而其它分区还可用。在这种情况下，单一的熔断器会把所有的分区访问给混为一谈，从而，一旦开始熔断，那么所有的分区都会受到熔断影响。或是出现一会儿熔断一会儿又好，来来回回的情况。所以，熔断器需要考虑这样的问题，只对有问题的分区进行熔断，而不是整体。-   **重试错误的请求**。有时候，错误和请求的数据和参数有关系，所以，记录下出错的请求，在半开状态下重试能够准确地知道服务是否真的恢复。当然，这需要被调用端支持幂等调用，否则会出现一个操作被执行多次的副作用。
# 小结好了，我们来总结一下今天分享的主要内容。首先，熔断设计是受了电路设计中保险丝的启发，其需要实现三个状态：闭合、断开和半开，分别对应于正常、故障和故障后检测故障是否已被修复的场景，并介绍了Netflix 的 Hystrix对熔断的实现。最后，我总结了熔断设计的几个重点。下篇文章中，我们讲述限流设计。希望对你有帮助。也欢迎你分享一下你实现过的熔断使用了怎样的算法？实现的过程中遇到过什么坑？文末给出了《分布式系统设计模式》系列文章的目录，希望你能在这个列表里找到自己感兴趣的内容。-   弹力设计篇    -   [认识故障和弹力设计](https://time.geekbang.org/column/article/3912)    -   [隔离设计        Bulkheads](https://time.geekbang.org/column/article/3917)    -   [异步通讯设计        Asynchronous](https://time.geekbang.org/column/article/3926)    -   [幂等性设计        Idempotency](https://time.geekbang.org/column/article/4050)    -   [服务的状态        State](https://time.geekbang.org/column/article/4086)    -   [补偿事务 Compensating        Transaction](https://time.geekbang.org/column/article/4087)    -   [重试设计 Retry](https://time.geekbang.org/column/article/4121)    -   [熔断设计 Circuit        Breaker](https://time.geekbang.org/column/article/4241)    -   [限流设计        Throttle](https://time.geekbang.org/column/article/4245)    -   [降级设计        degradation](https://time.geekbang.org/column/article/4252)    -   [弹力设计总结](https://time.geekbang.org/column/article/4253)-   管理设计篇    -   [分布式锁 Distributed        Lock](https://time.geekbang.org/column/article/5175)    -   [配置中心 Configuration        Management](https://time.geekbang.org/column/article/5819)    -   [边车模式        Sidecar](https://time.geekbang.org/column/article/5909)    -   [服务网格 Service        Mesh](https://time.geekbang.org/column/article/5920)    -   [网关模式        Gateway](https://time.geekbang.org/column/article/6086)    -   [部署升级策略](https://time.geekbang.org/column/article/6283)-   性能设计篇    -   [缓存 Cache](https://time.geekbang.org/column/article/6282)    -   [异步处理        Asynchronous](https://time.geekbang.org/column/article/7036)    -   [数据库扩展](https://time.geekbang.org/column/article/7045)    -   [秒杀 Flash        Sales](https://time.geekbang.org/column/article/7047)    -   [边缘计算 Edge        Computing](https://time.geekbang.org/column/article/7086)![](Images/1c1e992cf41f5294df097aabed82f9e4.png){savepage-src="https://static001.geekbang.org/resource/image/fc/e9/fcc761001867c60f526665e237f831e9.jpg"}
# 49 \| 弹力设计篇之"限流设计"保护系统不会在过载的情况下出现问题，我们就需要限流。我们在一些系统中都可以看到这样的设计，比如，我们的数据库访问的连接池，还有我们的线程池，还有Nginx 下的用于限制瞬时并发连接数的 limit_conn 模块，限制每秒平均速率的limit_req 模块，还有限制 MQ 的生产速，等等。
# 限流的策略限流的目的是通过对并发访问进行限速，相关的策略一般是，一旦达到限制的速率，那么就会触发相应的限流行为。一般来说，触发的限流行为如下。-   **拒绝服务**。把多出来的请求拒绝掉。一般来说，好的限流系统在受到流量暴增时，会统计当前哪个客户端来的请求最多，直接拒掉这个客户端，这种行为可以把一些不正常的或者是带有恶意的高并发访问挡在门外。-   **服务降级**。关闭或是把后端服务做降级处理。这样可以让服务有足够的资源来处理更多的请求。降级有很多方式，一种是把一些不重要的服务给停掉，把    CPU、内存或是数据的资源让给更重要的功能；一种是不再返回全量数据，只返回部分数据。    因为全量数据需要做 SQL Join 操作，部分的数据则不需要，所以可以让 SQL    执行更快，还有最快的一种是直接返回预设的缓存，以牺牲一致性的方式来获得更大的性能吞吐。-   **特权请求**。所谓特权请求的意思是，资源不够了，我只能把有限的资源分给重要的用户，比如：分给权利更高的    VIP    用户。在多租户系统下，限流的时候应该保大客户的，所以大客户有特权可以优先处理，而其它的非特权用户就得让路了。-   **延时处理**。在这种情况下，一般会有一个队列来缓冲大量的请求，这个队列如果满了，那么就只能拒绝用户了，如果这个队列中的任务超时了，也要返回系统繁忙的错误了。使用缓冲队列只是为了减缓压力，一般用于应对短暂的峰刺请求。-   **弹性伸缩**。动用自动化运维的方式对相应的服务做自动化的伸缩。这个需要一个应用性能的监控系统，能够感知到目前最繁忙的    TOP 5 的服务是哪几个。    然后去伸缩它们，还需要一个自动化的发布、部署和服务注册的运维系统，而且还要快，越快越好。否则，系统会被压死掉了。当然，如果是数据库的压力过大，弹性伸缩应用是没什么用的，这个时候还是应该限流。``{=html}
# 限流的实现方式