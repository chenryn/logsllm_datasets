have found evidence for faults which are not necessarily to
blame on the developer of the vulnerable Web application,
but rather are either a combination of incompatible ﬁrst- and
third-party code or even caused completely by third-party
libraries. This paradigm is enabled by the Web’s program-
ming model, which allows for third-party code to be included
in a Web page, gaining full access to that page’s DOM.
In addition, we have found patterns of mistakes, which
are caused by developers due to their misunderstanding of
browser-provided APIs or even the explicit decoding of user-
provided data to allow for a convenient use of such data.
1428Apart from the example shown here, we have found addi-
tional misguided attempts at securing applications, allowing
an attacker to easily bypass these measures. This leads us to
believe that even developers, who are aware of the potential
pitfalls of using attacker-controllable data in their applica-
tion, sometimes lack the knowledge of how to properly secure
their application.
7. RELATED WORK
Client-Side Cross-Site Scripting: In 2005, Amit Klein
coined the term of DOM-based XSS [11]. One of the ﬁrst
tools speciﬁcally designed to detect DOM-based XSS was
DOMinator, which used taint-tracking to detect vulnerable
ﬂows [7]. We extended the concept, presenting an automated
means of detecting and verifying client-side XSS vulnerabili-
ties, ﬁnding that about 10% of the Top 10k Web pages carry
at least one such vulnerability [12]. On top of this taint-
tracking engine, we built a taint-aware XSS ﬁlter aimed at
thwarting client-side XSS [27]. Previous work by Saxena
et al. has investigated so-called Client-Side Vulnerabilities,
mainly aiming at the exploitation of client-side XSS ﬂaws.
Using “taint enhanced blackbox fuzzing”, they were able to
discover eleven previously unknown vulnerabilities on real-
world Web pages [22].
In contrast to that, Criscione pre-
sented a brute-force blackbox testing approach [5]. To ﬁnd
bugs in complex JavaScript code, Saxena et al. developed a
symbolic execution framework for JavaScript, which helped
them to ﬁnd two previously unknown vulnerabilities [21].
JavaScript Analysis: Furthermore, attention has been
given to JavaScript error sources in general. Two research
groups presented empirical studies of JavaScript source code
included in popular sites. Richards et al.
investigated the
general runtime behavior of JavaScript and concluded that
the language is a “harsh terrain for static analysis”, conﬁrm-
ing our decision to use a dynamic approach [20]. Ocariza
et al. categorized the diﬀerent kinds of errors they encoun-
tered with speciﬁc test cases they created for the top 100
Web sites [17]. Although these sites were in a mature pro-
ductive state, the same well-deﬁned categories of errors were
discovered frequently.
In 2011, Guarnieri et al.
Richards et al. evaluated the use of eval in depth and
came to the conclusion that up to 82% of all Web sites uti-
lize the construct, often in a dangerous way. They did, how-
ever, ﬁnd that replacing eval altogether is still unfeasible
[8] presented ACTARUS,
[19].
which is capable of conducting taint-aware static analysis of
JavaScript on real-world Web sites, ﬁnding over 500 vulner-
abilities on eleven sites. Later, Meawad et al. developed
the tool Evalorizer, aiming to assist programmers in the
removal of unnecessary eval constructs [14]. As our work
has shown, Web sites often incorporate cross-domain Java-
Script code. In their work, Nikiforakis et al. investigated the
trust relationships between web pages of the Alexa Top 10k
sites [16], demonstrating that sites often open themselves to
attacks by including third-party content.
Vulnerability Analysis: Other research has focussed on
more general vulnerability analysis. In 2008, Shin et al. con-
ducted an analysis on how well code complexity metrics can
be used to predict vulnerabilities in the Mozilla JavaScript
Engine [26]. They conclude that while complexity metrics
can be useful in ﬁnding ﬂaws with a low false positive rate,
they carry a high false negative rate. Besides complexity,
Shin et al. looked at code churn and developer activity met-
rics to determine indicators of vulnerabilities and were able
to use them to “to prioritize inspection and testing eﬀort”
[25]. Complexity, coupling, and cohesion metrics with sim-
ilar results have also been used to discover vulnerabilities
statically by Chowdhury et al. [3]. Another approach, aim-
ing at ﬁnding improper input validation was presented by
Scholte et al. [23], using automatic data type inferring for
the validation functions. Doing so, they found that 65% of
the (server-side) XSS ﬂaws in their set were simple enough
to be stopped by their approach, without causing any has-
sle for the developers, which coincides with the number of
simple ﬂows we discovered in our study.Static taint analysis
has been used by Wassermann and Su to identify server-
side XSS using a policy of allowed inputs based on the W3C
recommendation [30]. Yamaguchi et al. have conducted ad-
ditional work to identify new vulnerabilities using machine
learning and a set of previously known vulnerabilities [31]
as well as based on Abstract Syntax Trees [32].
To summarize, while previous research has focussed on the
detection of client-side XSS, JavaScript security analysis and
general vulnerability analysis, no prior work has investigated
the underlying causes of client-side XSS ﬂaws. Our work
aims at closing this gap in previous research.
8. LIMITATIONS AND FUTURE WORK
The results of our analysis are naturally inﬂuenced by the
methodology used to ﬁnd the vulnerabilities. Most impor-
tantly, our method only ﬁnds vulnerabilities in code that is
executed during a normal page visit. Hence, ﬂows that are
dependent on a certain condition (such as a speciﬁc URL pa-
rameter) cannot be detected. Since no ground truth in terms
of all real-world client-side XSS vulnerabilities is known, we
have no means of ascertaining whether such ﬂaws are even
more complex than the ones underlying our study. Extend-
ing the detection methodology with static analysis to dis-
cover more vulnerabilities is therefore a promising extension
which could subsequently be transferred to our current work.
An interesting extension of our work is the application
of code coverage metrics by instrumenting the cached Java-
Script code [24]. This approach, however, has limitations of
its own, as rewriting cannot be conducted on code which is
dynamically generated at runtime using eval.
In addition, with the gathered data, we are able to inves-
tigate the usage of ﬁltering functions on the Web, e.g., the
regular expression used. Therefore, we believe the analysis
of these deployed ﬁlters might shed light on improper use of
such functions, especially as we have anecdotal evidence of
improperly used regular expression ﬁltering.
9. CONCLUSION
In this paper we investigated the root cause of client-side
XSS, i.e., the underlying issues related to this class of XSS
vulnerabilities. To do so, we throughly analyzed a set of
1,273 real-world vulnerabilities and classiﬁed them according
to their complexity.
Our work shows that a large number of ﬂaws are compar-
atively simple and, thus, most likely rooted in insuﬃcient
security awareness of the responsible developers. Based on
the classiﬁcation approach introduced in this paper, about
two thirds of all examined vulnerabilities fall into this cate-
gory. In contrast, about 15% of the discovered ﬂaws have a
1429high combined complexity rating, showing that developers
may also be overwhelmed by the complexity of the vulner-
able code; in 59 cases we even discovered interrupted code
ﬂows, signiﬁcantly impeding the ﬂaw discovery. Our study,
however, also found that for randomly sampled ﬂows, the
complexity metrics generally yield higher values, i.e., non-
exploitable code is often even more complex than vulnerable
code.
In addition to these ﬁndings, our gained insights highlight
that the aforementioned reasons are not the only causing
factors for client-side XSS. The presented ﬁndings show that
developers are not always to blame, as ﬂaws might be caused
by third-party code. In 273 of our vulnerabilities, this third-
party code was solely responsible for the ﬂaw, whereas an
additional 165 ﬂaws was caused by a combination of third-
and ﬁrst-party code, in parts related to the careless use of
outdated and vulnerable libraries. Our work also uncovered
patterns which highlight that developers lack the knowledge
of the inner workings of browser-provided APIs, in at least
one case actually introducing a vulnerability to begin with.
In summary, we ﬁnd that there is no single reason for the
existence of client-side XSS. Instead, the issues are caused
by a number of factors, ranging from developers who are
unaware of the security implications when using attacker-
controllable data and their failed attempts at securing ap-
plication to highly complex constructs of code and issues
introduced by third parties.
Acknowledgements
We would like to thank the anonymous reviewers for their
valuable feedback. This work was in parts supported by the
EU Project STREWS (FP7-318097).
10. REFERENCES
[1] D. Bates, A. Barth, and C. Jackson. Regular
expressions considered harmful in client-side XSS
ﬁlters. In WWW, 2010.
[2] BuiltWith. jQuery Usage Statistics.
http://goo.gl/czK9XU (accessed 16/05/15), 2015.
[3] I. Chowdhury and M. Zulkernine. Can Complexity,
Coupling, and Cohesion Metrics Be Used As Early
Indicators of Vulnerabilities? In SAC, 2010.
[4] A. Cortesi and M. Hils. mitmproxy.
https://goo.gl/VA9xw4 (accessed 16/05/15), 2014.
[5] C. Criscione. Drinking the Ocean - Finding XSS at
Google Scale. Talk at the Google Test Automation
Conference, (GTAC’13), http://goo.gl/8qqHA, 2013.
[6] M. E. Daggett. Enforcing Style. In Expert JavaScript.
2013.
[7] S. Di Paola. DominatorPro: Securing Next Generation
of Web Applications. https://goo.gl/L6tJth
(accessed 16/05/15), 2012.
[8] S. Guarnieri, M. Pistoia, O. Tripp, J. Dolby,
S. Teilhet, and R. Berg. Saving the World Wide Web
from Vulnerable JavaScript. In International
Symposium on Software Testing and Analysis, 2011.
[9] I. Hickson and D. Hyatt. HTML 5 - A vocabulary and
associated APIs for HTML and XHTML. W3c
working draft, W3C, 2008.
[10] jQuery Bug Tracker. SELECTOR INTERPRETED
AS HTML. http://goo.gl/JNggpp (accessed
16/05/15), 2012.
[11] A. Klein. DOM based cross site scripting or XSS of
the third kind. Web Application Security Consortium,
2005.
[12] S. Lekies, B. Stock, and M. Johns. 25 Million Flows
Later: Large-scale Detection of DOM-based XSS. In
CCS, 2013.
[13] M. McDaniel and M. H. Heydari. Content based ﬁle
type detection algorithms. In HICSS, 2003.
[14] F. Meawad, G. Richards, F. Morandat, and J. Vitek.
Eval begone!: semi-automated removal of eval from
javascript programs. ACM SIGPLAN Notices, 47,
2012.
[15] Mozilla Developer Network. Element.innerHTML -
Web API Interfaces | MDN. https://goo.gl/udFqtb
(accessed 16/05/15), 2015.
[16] N. Nikiforakis, L. Invernizzi, A. Kapravelos, S. Van
Acker, W. Joosen, C. Kruegel, F. Piessens, and
G. Vigna. You Are What You Include: Large-scale
Evaluation of Remote JavaScript Inclusions. In CCS,
2012.
[17] F. Ocariza, K. Pattabiraman, and B. Zorn. JavaScript
errors in the wild: An empirical study. In Software
Reliability Engineering, 2011.
[18] E. Oftedal. Retire.js - identify JavaScript libraries
with known vulnerabilities in your application.
http://goo.gl/r4BQoG (accessed 16/05/15), 2013.
[19] G. Richards, C. Hammer, B. Burg, and J. Vitek. The
eval that men do. In ECOOP. 2011.
[20] G. Richards, S. Lebresne, B. Burg, and J. Vitek. An
Analysis of the Dynamic Behavior of JavaScript
Programs. In PLDI, 2010.
[21] P. Saxena, D. Akhawe, S. Hanna, F. Mao,
S. McCamant, and D. Song. A Symbolic Execution
Framework for JavaScript. In IEEE S&P, 2010.
[22] P. Saxena, S. Hanna, P. Poosankam, and D. Song.
Flax: Systematic discovery of client-side validation
vulnerabilities in rich web applications. In NDSS,
2010.
[23] T. Scholte, W. Robertson, D. Balzarotti, and
E. Kirda. Preventing input validation vulnerabilities
in web applications through automated type analysis.
In Computer Software and Applications Conference.
IEEE, 2012.
[24] A. Seville. Blanket.js - seamless javascript code
coverage. http://goo.gl/hzJFTn (accessed 16/05/15),
2014.
[25] Y. Shin, A. Meneely, L. Williams, and J. Osborne.
Evaluating Complexity, Code Churn, and Developer
Activity Metrics as Indicators of Software
Vulnerabilities. Transactions on Software Engineering,
2011.
[26] Y. Shin and L. Williams. An Empirical Model to
Predict Security Vulnerabilities Using Code
Complexity Metrics. In International Symposium on
Empirical Software Engineering and Measurement,
2008.
[27] B. Stock, S. Lekies, T. Mueller, P. Spiegel, and
M. Johns. Precise client-side protection against
DOM-based cross-site scripting. In USENIX Security,
2014.
[28] The jQuery Foundation. Working with JSONP.
https://goo.gl/Wdqgo3 (accessed 16/05/15), 2015.
[29] W3Techs. Usage Statistics and Market Share of
JQuery for Websites, February 2015.
http://goo.gl/jyQEZR (accessed 16/05/15), 2015.
[30] G. Wassermann and Z. Su. Static detection of
cross-site scripting vulnerabilities. In International
Conference on Software Engineering, 2008.
[31] F. Yamaguchi, F. Lindner, and K. Rieck. Vulnerability
Extrapolation: Assisted Discovery of Vulnerabilities
Using Machine Learning. In USENIX WOOT, 2011.
[32] F. Yamaguchi, M. Lottmann, and K. Rieck.
Generalized Vulnerability Extrapolation Using
Abstract Syntax Trees. In ACSAC, 2012.
1430