to the one used by the corresponding AOSP base image. First, we
found a positive indication. The vendor’s binaries in common with
the AOSP base image have the same mitigation techniques, that
is, third-party vendors do not (usually) modify the AOSP settings.
However, the results are different when we compare the binaries
that are only present in the vendor’s ROM (i.e., those binaries that
are not present in any version of vanilla AOSP). Figure 3 presents
the result of this analysis as the mean computed over the ROMs
aggregated by SDK version. The vertical red line shows the point in
time when the security feature was mentioned in the SE for the first
time (Stack Canaries and NX have no vertical line because they were
introduced even before SDK 10). The dash-dotted line represents
the means of AOSP binaries, while the continuous line (supplied
with standard deviation) the vendors’ binaries. All graphs clearly
show that the new binaries added by the vendors consistently use
fewer mitigation techniques than the binaries in AOSP. At a closer
look, we can also observe other interesting trends. For instance,
even if stack canaries are the oldest security feature presented in the
SE, it took several years for vendors to adopt them (and still today,
96
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:28:06 UTC from IEEE Xplore.  Restrictions apply. 
0%50%100%Stack Canaries (I)0%50%100%NX (II)0%50%100%PIE (III)0%50%100%Full RELRO (IV)1015161718192122232425262728SDK Level0%50%100%FORTIFY_SOURCE (V)First SE appearanceAOSP binariesVendors' binaries1015161718192122232425262728SDK Level050100150200250ServiceServiceService at Boot as Rootside of the violin plot covers all new services, while the right side
only covers those that start at boot and with root permissions. The
plot shows how, over the years, vendors have made considerable
changes to init scripts and, in particular, how the total number of
newly defined services is constantly growing—with some ROMs
defining almost 250 additional services compared with AOSP.
To put this in terms of absolute numbers, for instance, an AOSP
8.0 (SDK 26) had, on average, 59 services defined in the init script,
while an average ROM had 90, with a peak of vendors defining
195 additional services. The astonishing number of services that
start as root is worrisome, and vendors are likely violating the least
privilege principle. It is, in fact, much more straightforward for
vendors to run a binary as root with respect to running it with less
privilege, granting it only the capabilities that are strictly needed,
and properly configuring SELinux policies.
Another interesting trend we observed while analyzing the init
script ecosystem is how vendors customize AOSP specific services
by changing or adding a root user as the owner of the service. Even
though the numbers are not very high, we noticed how, over the
years, starting from Android 4.0.3, on average, vendors customize
at least one service. This customization is very hard to explain
since these core services are supposed to run on the system without
modification. Extending the permissions of these services might
result in having an unnecessary over-privileged service. One possible
cause of this change might be due to aggressive and dangerous
customization that requires root privileges to work correctly.
We also cross-referenced the list of new services with the
results obtained in the previous subsection, where we found
binaries usually used for debugging purposes in commercial
ROMs. Surprisingly, we found that some of those binaries are also
automatically started at boot. For instance, we identified 18 ROMs
(of 2 different vendors) configured to start tcpdump at boot and
with root privileges. In this case, a manual investigation showed
that the tcpdump process was configured to monitor incoming
packets on all the interfaces and save the first 134 bytes of data
from each packet into a log file. To make it worse, some of these
ROMs use tcpdump version 4.9.2, which is outdated (it was
released in 2017) and is affected by several CVEs [33], [34] some
of which with public proof-of-concept exploits. Surprisingly, we
identified these problems even in a ROM branded as Android One,
and built in 2019. Listening and processing packets from untrusted
sources expose the device to potential remote and local attackers,
thus severely negatively affecting the entire device’s security.
D. SELinux Customization
As presented in Section V-B, vendors often customize the
SELinux configuration. This section discusses an in-depth analysis
of the most frequent vendor SELinux-related changes and their
impact on the overall system’s security (independently from whether
these changes are compliant with the CDD and other requirements).
SELinux plays a crucial role in the entire security of Android,
and this component can also be used to introduce temporary patches
to mitigate a vulnerability introduced at the software level. For
example, the vold privilege escalation bug was properly mitigated
first by a SELinux rule, before the vulnerable daemon vold was
patched [35], [36]. Unfortunately, there might be cases in which
vendors modify these policies without verifying whether the change
can introduce new vulnerabilities (or make existing vulnerabilities
exploitable). This is the case for Motorola that, by just introducing
one single policy change for some of its devices, has introduced
a logical bug that reverted the patch introduced to mitigate the
problem on vold, allowing attackers to get root [37]. In other cases,
the vulnerability can also be part of the base AOSP policy defined
by Google. This is the case for CVE-2018-9488 in which one of
the default SELinux domain of AOSP was wrongly configured and
allowed a local attacker to perform a privilege escalation [38].
These examples show that defining SELinux policies is a delicate
and error-prone process. However, SELinux changes are necessary
for the vendors. Every new process, file, and resource must be cor-
rectly labeled, and each new change introduced by a vendor must be
configured accordingly. This means that each new component intro-
duced by the vendor potentially requires introducing new domains,
types, classes, and rules. In our analysis, we extracted and analyzed
all vendor rules that were not present in the corresponding basic
AOSP policy. We identify three different cases: 1) rules that modify a
pre-existing rule to extend the permissions and operations allowed on
a given resource; 2) rules that modify an exiting core policy domain
but just by extending it to support new resources introduced by the
vendor; 3) rules that are completely new and that operate on domains
and resources that are not present in the original AOSP policy.
We now present the results of our analysis. Figure 5 shows the
changes to the allowrule defined by a vendor for its system, while
Figure 6 shows the changes affecting the definition of domains,
types, and classes.
For each SDK, the first figure shows the distribution of the
number of SELinux rules present in the policy. The graph combines
a traditional boxplot on the left, showing the first and third quartiles,
with a violin plot on the right side to show the distribution of the
number of ROMs that define a given number of rules. The plot also
includes two dots to indicate the average number of rules present in
the correspondent AOSP policy compared to the average number of
rules found in the different vendor policies. Also note that to accom-
modate outliers better, the Y-axis is plotted on a logarithmic scale.
We noticed how these outliers aggressively modified the default
policy defined in AOSP to add a significant number of rules. For
example, for SDK 27, an AOSP policy contained in average 10,000
rules, but some vendors defined a policy containing more than
232,000 rules (i.e., over a 20x increment). A similar trend also
appears in the changes to the definition of domains, types, and
classes, as presented in Figure 6.
These results highlight how the problem of customization has
significantly affected SELinux policies and how vendors often
behave very differently from one another. If we consider that even
very restrictive policies with a very limited number of rules, such
as those provided by AOSP, have been found to contain problems,
it is difficult to foresee vendors’ policies that introduce a number
of rules 20 times greater than the average can be free from logical
misconfiguration or even from real vulnerabilities introduced by
a completely insecure rule.
Figure 7 presents a more fine-grained breakdown of the changes.
In this case, for each modified rule, we checked if it applies to new
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:28:06 UTC from IEEE Xplore.  Restrictions apply. 
97
Fig. 5. Distribution of SELinux rules present in the policy (in log scale)
Fig. 6. Distribution of SELinux domains, types, and classes present in the policy
trend has seen a significant increase in versions from SDK 25 to 27.
For instance, in SDK 27, we found vendors introducing more than
130,000 permission changes to the corresponding AOSP core policy.
Depending on the attack model considered, some SELinux policy
changes can be more problematic than others. In particular, two
domains, isolated app, and untrusted app, play a particular role in
the security of the system, and therefore their basic policy included
in AOSP is very restrictive. The isolated app domain is mainly
used as an additional sandbox for the Chrome renderer process,
or to sandbox processes that should not have permissions of their
own. Adding rules to this context could widen the attack surface for
remote attacks, potentially allowing an easier sandbox escape. The
untrusted app domain is used instead for all third-party applications,
and therefore also for potential malware that might be inadvertently
installed by the user. Any change to this predefined policy could
widen the attack surface for local privilege escalation attacks.
Figure 7 shows that vendors modify these domains less often, but
the numbers are still not negligible (e.g., an average of 95 changes
to isolated and untrusted app were introduced in Android SDK 26).
For each domain, we now present significant dangerous changes
made by vendors and discuss their impact on the overall security.
Customization isolated app Domain. We identified a total of
58,776 changes to this context, 1,375 of which are unique. By
manually inspecting these modifications, we identified several
severe and dangerous cases. For instance, in SDK 19, we found
44 different ROMs that allowed an isolated app process to perform
read, write, and ioctl operations directly on kernel drivers. More
recently, some devices targeting SDK 23 and 25 changed a rule that
allows a process running on this domain to perform open, read, and
write operations on application data files. We noticed how this rule
is also violating a neverallow rule for this process since isolated
apps should never directly open application data files themselves.
Customization untrusted app Domain. Across the years, vendors
have made 95,577 changes to this context, 4,228 of which are unique.
Among these customizations, we found old systems (based on
Android 4.4) that allowed an untrusted app process to perform read
and ioctl operations directly on kernel drivers. On newer policies,
the risks have been reduced by removing the ioctl capability, while
still allowing the domain to read from kernel components. Another
interesting finding, affecting newer devices targeting SDK 27, is
Fig. 7. Evolution and Classification of Rule Changes
domains added by the vendor, if it interests AOSP domains, if it
is adding permissions to a previous rule, or if it is a modification
that interests sensitive domains. The graph shows that most of the
vendors’ changes consist of rules that involve new domains that are
not present in the original AOSP policy. These new rules are usually
introduced by the vendors to configure custom components properly.
We also observe a substantial number of changes to rules that
affect domains shared with AOSP, but which see the introduction
of classes and types that are not present in the basic policy. These
numbers exemplify the problem of customization by showing how
many changes the vendor makes to the initial policy configuration
so that new third-party components can interact correctly with the
entire system. But this also shows how intrusive vendor changes are,
and how, as noted above, this dangerous trend is continuing to grow.
A more important finding emphasized by Figure 7 is the number
of changes vendors made to the base policy, by extending the permis-
sions and privileges for default AOSP domains. In principle, these
rules only affect AOSP components that the vendor should not mod-
ify. However, if a vendor applies some customizations to services
running on these domains, some of these modifications might raise a
runtime SELinux violation since one new feature introduced by the
vendor violates a rule defined in the original policy. Furthermore, this
98
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:28:06 UTC from IEEE Xplore.  Restrictions apply. 
18192122232425262728SDK Level3001k3k10k30k100k300kAllowruleAVG VendorAVG AOSP18192122232425262728SDK Level5001K1.5K2K2.5K3K3.5KDomain, Types, and ClassesAVG VendorAVG AOSP18192122232425262728SDK Level7504003k20kAllow Rules CustomizationsNew PermissionsNew Vendor rulesRules on Vendor DomainsRules on AOSP domain,Vendor type/classSensitive Domainsrelated to a rule that allows a process running on this domain to read
files containing the device’s MAC address. Google is restricting
access to this information in many ways, including a neveral-
low rule that prevents this operation [39]. Despite this effort, we
still find vendors that nullify these defensive measures by allowing,
unintentionally, other applications to access this information.
Our work significantly differs and complements all these
previous ones, for both the type of analysis performed and the
components considered, as it is the first to discuss a longitudinal
analysis on OEM customizations, their compliance aspect, and
details about system binaries, libraries, SELinux policies, Android
init scripts, and user- and kernel-space hardening techniques.
VII. RELATED WORK
There are mainly two areas of works relevant to this paper: the
perils of Android customizations and SELinux policy analysis.
The Perils of Android Customizations. The problems related to
Android’s customizations have been analyzed in prior studies from
different points of view. Aafer et al. [7] have demonstrated how
vendors have introduced severe security issues within their systems
by modifying security components within the Android framework.
Their analysis mainly focused on the framework component, ana-
lyzing the various deltas between the XML security configurations
of the various ROMs, looking for inconsistencies. Dai et al. [40]
instead illustrate how the Android customizations on the framework
might be a direct cause of the patch gapping, showing how vendors
fail to roll out all of the security patches published by Google in a
reasonable time. On the same topic, Daniel et al. [41] suggest that
another reason updates are not provided in a reasonable time may be
due to the large number of entities involved in the supply chain that
have to cooperate for the patch to reach the device. Instead, Zhou
et al. [6] focus their analysis on vendors’ custom drivers, showing
how the customized drivers are often sources of security problems
and how this problem is not so widespread and common in the
drivers offered by the official Android platform. Tian et al. [42]
analyzed over 2,000 Android smartphone firmwares across 11
vendors to extract custom and hidden AT commands. To conclude,
Wu et al. [43] and Gamba et al. [44] analyzed the customization
problems analyzing the pre-installed apps on the device, showing
how vendors’ customizations introduce several issues for what
concerns the security of the system as well as the user privacy.
SELinux Policy Analysis. The analysis of SELinux is a problem
that has been addressed in many ways by previous work. Among
the first works, Reshetova et al. [45] present SELint, a tool that
helps OEMs overcome common challenges and avoid mistakes
when writing SELinux policies. The same authors then present
another tool, in [46], that can improve policy design and analysis.
However, the usage of this tool requires a real device, rooted (or
with an engineering build), and it is thus not possible to use it for
a large scale analysis. Another relevant work is EASEAndroid [47],
which presented an analytic platform for automatic SELinux policy
analysis and refinement. This refinement process is automated
using semi-supervised learning, and it was trained over millions of
SELinux denial logs from real-world devices. Another category of
work focuses on the static analysis of this component. Im et al. [48]
performed the first measurement on the evolution of SELinux
policies available in the official AOSP repository, proposing a
new metric to measure the complexity of a given policy. Last,
Hernandez et al. [49] proposed BigMac, a new policy analysis
framework that works on firmware images and extract attack paths
between processes and can help to identify dangerous rules.
VIII. CONCLUDING REMARKS
In this work, we have focused on the four main components that
are responsible for the security of the Android OS: SELinux con-
figurations, system binaries hardening, init scripts, and the Android
Linux kernel. However, over the years, due to changes introduced
by vendors, these same components have also been a source of
severe vulnerabilities. To address this issue, Google has introduced
a number of requirements (e.g., CDD) and many automated routines
to check for a subset of them (e.g., CTS and VTS). Google also
recently re-architectured the Android OS with Project Treble, in an
attempt to disentangle vendors’ customizations from AOSP.
This paper discusses the first longitudinal, large-scale analysis
on a dataset of 2,907 ROMs from 42 different vendors: our results
are worrisome. About 20% of ROMs in our dataset did not meet
at least one of the security requirements imposed by Google, and
among them, to our great surprise, 11 ROMs are branded by Google
itself. We observed 190/2,396 (∼8%), from 10 different vendors,
including Google, contain non-compliant kernels, while 443/1,533
(∼29%) violate the SELinux policies requirements. We also show
how vendors often configure over-privileged services, introduce
dangerous and over-permissive changes to SELinux policy, and do
not use compiler-level mitigations. Finally, our results show that
these problems did not improve over time and with new versions
of Android.
The first insight is that the current set of regulations and checks
is clearly insufficient. The same goes for Project Treble: while
the engineering effort is admirable, it is clear that its impact was
not enough to mitigate the aforementioned problems. The current
testing and verification procedure, which is fundamentally based on
trust since the tests are executed by the vendors themselves, is not ef-
fective at catching problems and it is very often violated. We believe
that the vast majority of vendors act in good faith, but some changes
suggest intentional attempts to circumvent, for practicality reasons,
Google’s safety nets (e.g., SELinux neverallow rules).
Looking forward, we believe more checks should be automated
and that the existing ones should be more accurate. An automatic
framework like the one we presented in this paper, which is already
able to identify CDD violations that are not detected by the existing
test suites, can be used as a basis for these automated analyses.
The second part of our paper shows that there are several areas of
customizations that, even if they do not violate any strict requirement,
are the root cause for severe security problems. While the CDD is
a great starting point, we believe it should be significantly extended
to prevent vendors from customizing their ROMs in ways that go
against many well-established security practices and principles.
In conclusion, we hope this paper inspires future works and
analysis in the important area of OEM customizations, and that
Google adopts a stronger stance on OEM customizations that favor
performance and ease of development rather than security.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:28:06 UTC from IEEE Xplore.  Restrictions apply. 
99
[29] “Experts Found a Unicorn in the Heart of Android.” https:
//blog.zimperium.com/experts-found-a-unicorn-in-the-heart-of-android/.
Accessed December 22, 2020.
[30] “Security Enhancements.” https://source.android.com/security/enhancements.
Accessed December 22, 2020.