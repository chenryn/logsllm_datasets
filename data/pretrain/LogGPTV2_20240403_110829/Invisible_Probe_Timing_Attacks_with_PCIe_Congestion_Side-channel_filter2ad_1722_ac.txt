accesses 4 bytes only. When the number of bytes is large, PCIe
switch may increase the buffer size to ease congestion. When
the number of bytes is less than 4, we found the throughput
and delay remain the same. To keep sampling, the attacker
needs to monitor the send queue and make sure it is non-
empty by continuously adding requests. However, this strategy
might make multiple requests arrive at the I/O switch at the
same time, resulting in inaccurate measurement. We address
this issue by making the requests “mutually exclusive”: we
set a fence (IBV_SEND_FENCE) after each request, holding
the next request to wait for the reply of the prior one.
Algorithm 1: Collection of Delay Sequence with
RDMA
Result: DelaySeq
Alloc SendQueue(withFence), CompletionQueue;
SendQueue.enqueue(a batch of RDMA read
operations);
lastTimestamp = device.getTimeStamp();
while notEnough(DelaySeq) do
wr = CompletionQueue.pop();
DelaySeq.append(wr.timestamp - lastTimestamp);
lastTimestamp = wr.timestamp;
if SendQueue.isAlmostEmpty() then
SendQueue.enqueue(a batch of RDMA read
operations);
end
end
We set the IBV_EXP_CQ_TIMESTAMP ﬂag to the sending
queue in order to collect the hardware timestamps of the
replies, which are stored into the completion queue. The
collected timestamp is much more precise than the timestamp
of CPU (e.g., RDTSCP). The interval between consecutive
hardware timestamps is close to the delay of the request,
because 1) kernel and CPU are bypassed; 2) no congestion
should happen at the sender and receiver NICs due to mutually
exclusive requests; 3) the Inﬁniband network introduces ultra
low and stable latency (e.g.130 nanosecond from one switch
port to another [38]).
Fig. 2: Delay variance based on the PCIe congestion status.
We found the designed probe can achieve a very high
sampling rate and high sensitivity to congestion. On our
experiment platform, the sampling rate can be as high as
0.77 million points per second (the interval between probes
is around 1.3 microseconds or 206 RDMA NIC cycles) when
the upstream PCIe link is not shared with other devices. When
the PCIe link is busy, as we let the CPU pass a large array
(30,000×30,000 integers) to GPU and read it back, the interval
is increased to 9.6 microseconds or 1,520 RDMA NIC cycles.
As shown in Figure 2, 6 times difference can be observed. The
high entropy embedded within the interval variance enables
ﬁne-grained proﬁling of the victim device.
A recent work, NetCat
[23], carried out an RDMA
Prime+Probe attack against LLC (last level cache) of a server
to infer the victim’s secret. Though our RDMA probe also
touches LLC, what is measured is different from the RDMA
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:30:32 UTC from IEEE Xplore.  Restrictions apply. 
326
013s2001.5k2kInterval (cycles)Prime+Probe of NetCat [23]. First, Prime+Probe requires an
eviction set ﬁlled with carefully selected memory addresses 2,
but our probe reads ﬁxed 4 bytes only. Second, Prime+Probe
introduces the timing difference of accessing LLC (between
hit and miss) at 100 nanoseconds, but the difference is far
larger in our attack (8.3 microseconds).
B. Attack 1: User-input Inference
We observe that even a keystroke a victim enters, which
introduces fairly small amount of data, is distinguishable under
INVISIPROBE. When a keystroke is entered to a GUI input, a
character will be rendered by GPU. In addition, the UI element
around it, e.g., textbox, will be refreshed. Before the rendering,
CPU passes the character and UI elements from memory to
GPU via PCIe link and issues the rendering commands to
GPU. Though the data volume is small, CPU will try to use
all PCIe lanes to transmit the data, still introducing noticeable
congestion when INVISIPROBE is launched at the same time,
leading to a surge of probe delays, as shown in the top
of Figure 3. In contrast, when the displayed content is not
updated, the CPU-GPU PCIe link will stay “quiet”. Therefore,
INVISIPROBE can infer the keystroke dynamics. To notice,
though the display is refreshed at a constant rate, e.g., 60Hz,
the frequency of data transmission on PCIe and GPU rendering
are not constant.
This attack assumes the rendering is facilitated with the
GPU on the remote server. This feature has been supported
by remote desktop services of Windows [40] and Linux [41],
which can be turned on by changing the system conﬁgurations
on the server. Mainstream cloud providers like Amazon EC2
also offered this support
in their VMs [42]. Game cloud
providers like Steam Cloud Play started to render games
for users in remote server, which aroused over 94 million
users [43]. When a user is using a resource-constrained device,
e.g., a thin client in an enterprise network, for tasks requiring
GPU acceleration, like browsing using WebGL, gaming, and
data visualization [44], remote GPU acceleration is recom-
mended [45]. We expect
this setting will be encountered
more often along with the increased adoption of remote
desktop [46].
In Section VI-B, we evaluate whether INVISIPROBE can
learn when a keystroke occurs and how likely a word typed
by a victim can be inferred. Below we describe the steps.
Inferring keystroke events. By modeling the surge of probe
delays,
the occurrences of keystrokes could be detected.
The main problem we need to solve is how to distinguish
keystrokes with other UI updates (e.g., screen transition) from
the delay surge. After analyzing the delay sequences resulted
from a set of keystrokes, we found that any keystroke will
increase the delay of 7 consecutive probes, while other UI
activities rarely exhibit the same pattern (e.g., UI transition
impacts far more probes). According to this observation, we
propose the following method to identify a keystroke:
1) We compute the intervals between all probe requests and
save them into a delay sequence.
2) We set a lower-bound T HL and an upper-bound T HH
to select the sampling points. These points are likely
to be related to keystrokes and we call them suspected
points. As shown in the bottom of Figure 3, unrelated
sampling points can be ﬁltered out reliably.
3) We use a sliding window of W in readings to scan
the intervals. If there are over K suspected points, we
consider there is a suspected keystroke happening in the
time window. The red stars and blue circles in Figure 3
show the suspected keystrokes.
After empirical analysis, we set the values of T HL, T HH,
W in and K to 1000, 3000, 50,000 and 6. Though for a
different machine the delay patterns might be varied (e.g.,
5 might be sufﬁcient for K), the adversary can update the
parameters according to the target machine.
Removing caret. Though the above method produces good
recall of keystroke events, we found the blinking caret in the
textbox is detected as well, as it has a similar impact on our
probe intervals. On the other hand, the blinking caret can be
ﬁltered out due to their unique UI patterns: 1) the blink has
a constant interval; 2) the caret blinks only when the user is
not typing in most applications3.
Speciﬁcally, we compute the intervals between the sus-
pected keystrokes and remove the ones with the constant
intervals (e.g., 598 milliseconds or 1193 milliseconds for
Google Chrome, and 403 milliseconds or 793 milliseconds
for gedit). The chances of removing real keystrokes are very
small, as keystroke usually takes a much shorter interval. The
blue circles in Figure 3 show the carets that are successfully
detected.
Recovering word. Though the learnt keystroke events do not
tell which keys are typed, according to prior studies, their
intervals reveal what words are typed [12], [47], [48], based
on a language model. Take English words as an example. In
essence, the attacker can ﬁrst collect the keystroke timings
about English words from a dictionary words, and then use
Hidden Markov Model (HMM) [49] to build the relationship
between the intervals and the hidden states (i.e., pair of
characters). The transition probabilities between certain states
such as (’i’, ’o’) are adjusted based on their probabilities of
occurring together. The “SPACE” character between words are
detected based on its longer inter-keystroke interval [12]. Then,
the attacker applies Viterbi algorithm [49] to obtain the top n
most likely character sequences given an interval sequence.
The candidate sequences that fail spelling checks are removed
before the result is presented.
C. Attack 2: Webpage Inference
Using GPU to accelerate webpage rendering has become
a standard technique for browsers, like Google Chrome [50],
Mozilla Firefox and Internet Explorer. Take Google Chrome
2Maurice et al. [39] showed Prime+Probe is feasible under addressing
uncertainty, but it is used to construct covert channel.
3We tested 10 applications and only found the caret keeps blinking in
Firefox regardless of typing. The 10 applications are described in Appendix C.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:30:32 UTC from IEEE Xplore.  Restrictions apply. 
327
Fig. 3: Recovery of keystroke events. The top ﬁgure shows the raw delay sequence. The bottom ﬁgure shows the sequence
after the pre-processing. The predicted keystrokes are marked with red stars while carets are marked with blue circles.
(a) Collected at RDMA NIC, when a
different websites
victim visits
three
(www.android.com,
www.12306.cn,
www.pptv.com).
(b) Collected at RDMA NIC, when a victim
trains three different ML models (DCGAN,
RNN-LSTM, AutoEncoder).
(c) Collected at NVMe SSD, when a victim
visits three different websites (sohu.com,
tmall.com, baidu.com).
Fig. 4: Interval sequences in the three attacks.
as an example. The renderer process of CPU rasterizes (i.e.,
converts the geometry description of the image to pixel de-
scription) the webpage and pushes the data to the CPU mem-
ory shared with GPU. The GPU process copies the data from
CPU memory to the GPU memory and invokes OpenGL [50]
APIs to draw the bitmaps region-by-region. Lastly, the Chrome
compositor stitches the rendered images together to draw the
whole webpage using GPU. Initially, a website needs to call
WebGL APIs [51] to direct Google Chrome to use GPU for
rendering. But recently, GPU acceleration is conﬁgured as the
default setting in Google Chrome [52]. Since the data related
to the webpage has to be moved from CPU to GPU, PCIe
congestion can be introduced as well when INVISIPROBE is
launched.
We speculate visiting a webpage could yield a unique
delay sequence, because it usually triggers downloading many
web ﬁles (e.g., JavaScript, HTML and image ﬁles) from
different web origins. The browser executes each ﬁle after
it is downloaded instead of waiting for all of them [53]. As
such, the data transmission between CPU to GPU becomes
intermittent, resulting in distinguishable I/O patterns. Figure 4a
(a) compares the sequences when visiting 3 different web-
pages. Based on the above observation, we take the entire
delay sequence and classify it.
In Section VI-C, we evaluate INVISIPROBE in a close-
world setting: we proﬁle 100 webpages ahead and examine
if INVISIPROBE can identify the webpage being visited.
Classifying delay sequence. Loading the same webpage might
observe different delay sequences due to network conditions,
OS events, and dynamic content (e.g., online advertisement).
To achieve robust classiﬁcation on the ever-changing delay
sequences, we leverage LSTM (Long short-term memory),
an RNN model family capable of handling complex time-
series [54], [55]. LSTM is able to track long-term dependen-
cies in a sequence, which is ideal for our problem setting, as
ﬁle downloading events can span the whole lifetime of web-
page rendering. In particular, we choose AttBLSTM (Attention-
Based Bidirectional LSTM) model [13] under the LSTM
family to classify our delay sequence. AttBLSTM considers
both forward and backward dependencies and uses an attention
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:30:32 UTC from IEEE Xplore.  Restrictions apply. 
328
013sCollected raw interval sequence3kInterval (cycles)013sPre-processed interval sequence and prediction results3kInterval (cycles)013s3k013s3kInterval (cycles)013s3k06.5s3k06.5s3kInterval (cycles)06.5sTime3k010s30010s30Interval (us)010s30embedding mode.
D. Attack 3: Machine-learning Model Inference
Nowadays, GPU is extensively used to train machine-
learning models. The structure of a machine-learning model
can be considered as “intellectual property” (IP) [57], as
many companies have invested a large amount of resources
to develop it. In this attack, we consider the adversary is
interested in learning the model structure for IP infringement
or use the information to improve the adversarial attacks [57].
This attack setting has been studied by a number of works
recently (surveyed in Section VIII), but none of them exploited
the PCIe congestion side-channel.
More speciﬁcally, we consider the structure of a DNN (Deep
Neural Network) model has been decided by a developer
and it is trained using TensorFlow on the targeted server.
When the training is initialized, TensorFlow compiles the
model structure to a Tensorﬂow graph where each node is
a TensorFlow operation (or op). For each op in the graph, the
graph executor on CPU will transfer a batch of data to GPU
memory as initialization. Thus, there is data movement from
CPU to GPU through PCIe link [58] and different ops could
introduce different data movement patterns, and our goal is
to infer the op sequence, which can be leveraged to recover
the secret model structure. Though the valid combinations of
ops are virtually inﬁnite, only a few ops can be chosen, in-
cluding Conv (convolution), FC (fully-connected), BN (batch
normalization), ReLU, Pool, and etc. As shown in a recent
work [59], those ops all introduce unique PCIe usage patterns,
and their combination may result in a unique delay sequence.
Similar to Attack 2, the attacker probes the shared PCIe
link to obtain a delay sequence. Then she uses the same
AttBLSTM model described in Section IV-C to classify the
whole delay sequence into a model structure that has been
proﬁled. In evaluation (Section VI-D), we proﬁled 10 models
and classiﬁes a sequence to one of them.
V. ATTACKING NIC WITH NVME SSD
In this scenario, we show that even when a low-speed
device, in particular an Ethernet NIC, is used by the victim,
the sensitive information can be leaked under INVISIPROBE.
Similar to the prior section, we describe the probe design and
a concrete attack under this scenario.
A. Design of Probe
When attacking GPU using NIC, the congestion is mainly
caused by the GPU used by the victim, and the I/O delay is
measured by the RDMA NIC. In contrast, the attacker in this
scenario uses her device (i.e., NVMe SSD) to cause congestion
and measure delay together, because the data volume intro-
duced by the victim’s NIC alone might be limited. Ethernet
NICs that support 10Mbps, 100Mbps, 1Gbps data rates are
usually connected to PCH via a single PCIe lane [60] 4. A
PCH can forward 4GB/s data but a 1Gbps NIC only introduces
0.125GB/s data, ﬁlling 3.1% bandwidth of PCH at maximum.
4Higher-speed NICs, like 10Gbps NIC, are rarely plugged to PCH.
Fig. 5: AttBLSTM Model for classifying webpage visits.
layer to focus on the elements that have a decisive role in the
sequence. It outperforms the vanilla LSTM model especially
when the number of sequence elements (e.g., downloaded ﬁles
in our case) is not ﬁxed [56]. Figure 5 shows the structure of
our classiﬁer based on AttBLSTM.
While AttBLSTM can directly process the delay sequence,
we found the performance is unsatisfying as each sequence has
a huge number of data points, ranging from 1 million to 10
million. Therefore, we add a pre-processing layer before the