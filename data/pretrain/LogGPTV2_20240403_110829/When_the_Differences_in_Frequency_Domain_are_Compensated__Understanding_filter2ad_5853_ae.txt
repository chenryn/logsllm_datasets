easy deployment.
Frequency-Domain Detection. We conduct experiments to eval-
uate the accuracy for DualGuard to detect direct replay attacks in
the frequency domain. To decide the decision threshold of Algo-
rithm 2, we first obtain the Area Under CDF curve (AUC) from the
amplitude spectrum of audios. Figure 10 shows the AUC distribu-
tions for both genuine audios and direct replay audios. We can see
that the AUC values of genuine audios are concentrated and close
to 1, which indicates that the low-frequency energy is dominant.
However, the AUC values of direct replay audios are distributed and
small, which is consistent with the distributed spectrum of replay
audios. As shown in Figure 10, the best decision threshold is 0.817
since it can minimize the classification errors between genuine
audios and replay audios. Table 1 shows the detection accuracy
of DualGuard on direct replay attacks using Algorithm 2 with a
decision threshold of 0.817. The accuracy with different speakers
always exceeds 89%. We also calculate the false positive rate of our
method in detecting direct replay attacks. It always maintains less
than 5% false positive rate. Moreover, we conduct experiments with
the ASVspoof 2017 and 2019 datasets to show that DualGuard can
effectively detect classic replay attacks. Our experimental results
show that DualGuard can achieve 87.13% and 83.80% accuracy in
these two datasets, respectively.
Moreover, we train another model only with frequency features
from a mix of genuine audios, direct replay audios, and modulated
replay audios in order to demonstrate the necessity to detect all
replay attacks in two domains. Our experimental results show that
the accuracy can only reach 63.36%. It is due to the great spectral
similarity of genuine audios and modulated replay audios in the fre-
quency domain. Therefore, the dual-domain detection is necessary
to accurately detect both two types of replay attacks.
5.4 Robustness of Dual-Domain Detection
We conduct experiments to show the robustness of our dual-domain
detection under different sampling rates, different recording devices,
different speaker devices, and different noisy environments.
Impact from Genuine Audio Sampling Rate. We evaluate the
impact of the sampling rate for recording the initial human voice
(a) accuracy vs. sampling rate.
(b) accuracy vs. noise level.
Figure 11: Detection accuracy of different recording devices
with different factors.
by attackers. We first use TASCAM DR-40 digital recorder with
fs = 96 kHz to capture initial human voice. We also use iPhone
X with fs = 48 kHz to capture human voice. For both sampling
rates, the average detection accuracy of DualGuard on modulated
replay attack is 98.05%. That is because the sampling rate used by
attackers only changes the spectral resolution in the modulation
process. However, the waveform of modulated replay audios will
not be changed since D/A converter will convert modulated signals
into analog form before the replay process.
Impact from ASR Sampling Rate. We conduct experiments on
different recording devices with different sampling rates. In our
experiments, there are three settings of sampling rates for our
recording devices: (S1) TASCAM DR-40 with 96 kHz, (S2) TASCAM
DR-40 with 48 kHz, and (S3) a mobile phone (Xiaomi 4) with 44.1
kHz. Figure 11(a) shows the experimental results. We can see the
detection accuracy usually increases with the increase of sampling
rates. We find that although changing the sampling rate has little
effect on the frequency-domain detection, it significantly affects the
time-domain detection due to the change of the sampling interval.
Note that the smaller sampling interval means the finer detection
granularity of local extrema ratios, which increases the detection
accuracy. Moreover, in Figure 11(a), our experiments show that
DualGuard still achieves around 85% detection accuracy in the
worst case where the sampling rate is 44.1 kHz. We note that 44.1
kHz is the minimum sampling rate of common electronic devices in
our lives [23]. Therefore, DualGuard can achieve a good detection
accuracy with different sampling rates in common devices.
Impact from Different Recording Devices. In Figure 11(a), the
detection accuracy does not significantly change when we use
different recorders with the same sampling rate. The detection
accuracy changes less than 2% with different recording devices
when the sampling rate is 48 kHz or 44.1 kHz. The results show
DualGuard can be applied to different recording devices in our lives.
Impact from Different Noisy Environments. To test the detec-
tion accuracy under different noisy environments, we introduce
noise factors in our experiments. We test our detection method
under three scenarios: (1) in a quiet environment, (2) in a noisy en-
vironment with the signal-to-noise ratio (SNR) of 60 dB, and (3) in a
noisy environment with the SNR of 40 dB. The additive noise signal
is produced by a loudspeaker that plays a pre-prepared Gaussian
white noise signal, simulating the noise in the real world. The noise
is mixed with the test signals with specific SNR. Figure 11(b) illus-
trates the detection accuracy in various noise conditions. We can
 0 5 10 15 20 25 30 35 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1Proportion (%)Area Under CDF curve (AUC)Genuine AudioReplay Audio 76 78 80 82 84 86 88 90 92iPhoneiPadMi PhoneNexusBOSETVDetection Accuracy (%)96 kHz 48 kHz 44.1 kHz  76 78 80 82 84 86 88 90 92iPhoneiPadMi PhoneNexusBOSETVDetection Accuracy (%)Quiet Env.SNR = 60 dBSNR = 40 dBsee that the impact of noise is limited. Particularly, the detection
accuracy remains unchanged when the SNR is 60 dB. When the SNR
drops to 40 dB, the detection accuracy decreases by 3.2% on average.
Actually, the impact of noise is mainly reflected in the time-domain
defense. General noise has little effect on the frequency-domain
defense part. With the increase of noise power, the burr amplitude
in the noise will also increase. As a result, noise can result in the
imprecise detection of the local extrema pattern in the test signals.
However, our experimental results indicate that DualGuard still
works well at the general ambient noise level.
5.5 Overhead of Dual-Domain Detection
We implement DualGuard with C++ language, and build a system
prototype in ReSpeaker Core v2, which is a popular voice interac-
tive platform with quad-core ARM Cortex-A7 of 1.5GHz and 1GB
RAM on-board. Our experimental results show that the embedded
program takes 5.5 ùëöùë† on average to process a signal segment of 32
ùëöùë† length with the CPU usage of 24.2%. The largest memory usage
of the program is 12.05 MB. The results demonstrate the feasibility
of applying our dual-domain detection system in the real world.
6 RELATED WORK
In this section, we review related research on attacks targeting ASR
systems, techniques on loudspeaker frequency response compensa-
tion, and defense systems against replay attacks, respectively.
Attacks on Speaker Dependent ASRs. A speaker dependent
ASR system is designed to only accept voice commands from spe-
cific users [66]. It verifies the speaker‚Äôs identity by matching the in-
dividual characteristics of human voice. There are four main spoof-
ing attacks against the speaker dependent ASRs. First, an attacker
can physically approach a victim‚Äôs system and alter its voice to im-
personate the victim [22]. Second, the attacker can launch a simple
replay attack by playing back a pre-recorded speech of the victim
to the ASR systems [60, 62]. Third, speech synthesis attacks gener-
ate artificial speech to spoof the ASR systems [12, 15, 34]. Fourth,
speech conversion attacks aim to achieve a speech-to-speech con-
version, so that the generated speech has the same timbre and
prosody with the victim speech [30, 67].
Attacks on Speaker Independent ASRs. A speaker independent
system is designed to accept commands from any person without
identity verification. Comparing to the speaker dependent system,
it is more vulnerable to attacks [3, 17, 26, 44]. Recently, researchers
found more surreptitious attacks that humans cannot easily per-
ceive or interpret. Dolphin attack is hard to be noticed since the ma-
licious audio is modulated into the ultrasonic range [47, 53, 71]. The
voice commands can also be modulated into laser light to launch au-
dio injection attack [54]. Also, the malicious audio can be perturbed
into an unintelligible form in either time domain or frequency do-
main [1]. To attack the machine learning module in ASRs, recent
research shows attackers can produce noise-like [11, 32, 58, 76]
or song-like [70] voice commands that cannot be interpreted by
human. Psychoacoustic model can also be applied to generate the
adversarial audio below the human perception threshold [49]. By
fooling the natural language processing (NLP) module after ASRs,
skill squatting attacks mislead the system to launch malicious ap-
plications [18, 31, 40, 74, 75].
Loudspeaker Frequency Response Compensation. In the field
of room acoustics, loudspeaker frequency response compensation is
a technique used to improve the sound reproduction [13]. The basic
method is to design an intelligent filter to flatten the frequency
response of the loudspeakers [10]. The frequency response com-
pensation can also be achieved by advanced filter with a generic
Hammerstein loudspeaker model [16]. For a multichannel loud-
speaker system, the minimax approximation method is proposed to
flatten the spectral response around the crossover frequency [37].
Also, a polynomial based MIMO formulation is proposed to solve
the multi-speaker compensation problem [9].
Defenses against Replay Attacks. In ASVspoofing Challenge [29],
several replay detection methods are proposed by exploiting the
frequency-based features, such as Linear Prediction Cepstral Coeffi-
cient (LPCC) [42], Mel Frequency Cepstral Coefficient (MFCC) [68],
Constant Q Cepstral Coefficients (CQCC) [56], High Frequency Cep-
stral Coefficients (HFCC) [41] and Modified Group Delay Cepstral
Coefficient (MGDCC) [35]. Besides, the high-frequency sub-band
features can be used to detect live human voice by the linear predic-
tion (LP) analysis [65]. The sub-bass (low-frequency range) energy
is also an effective feature to detect the replay signals, though
this method can be bypassed by altering the speaker enclosure or
modulating the signals with our inverse filter [8]. The frequency
modulation features [21, 28, 55] can also be leveraged due to the
degraded amplitude components of replay noise.
Researchers propose to detect replay attacks using physical prop-
erties. Gong et al. detect the body-surface vibration via a wearable
device to guarantee the voice comes from a real user [19]. 2MA [7]
verifies the voice commands by sound localization using two micro-
phones. Yan et al. propose a spoofing detection method based on
the voiceprint difference between the authentic user and loudspeak-
ers [69]. All these methods require special equipment or specific
scenarios. VoiceLive [73] detects live human voice by capturing
the time-difference-of-arrival (TDoA) dynamic of phoneme sound
locations. VoiceGesture [72] reuses smartphones as a Doppler radar
and verifies the voice by capturing the articulatory gesture of the
user when speaking a passphrase. However, these two methods
work well only when there is a short distance between the recorder
and the user‚Äôs mouth.
7 CONCLUSION
In this paper, we propose a new modulated replay attack against
ASR systems. This attack can bypass all the existing replay detection
methods that utilize different frequency domain features between
electronic speakers and humans. We design an inverse filter to
help compensate frequency distortion so that the modulated replay
signals have almost the same frequency features as human voices.
To defeat this new attack, we propose a dual-domain defense that
checks audio signal‚Äôs features in both frequency domain and time
domain. Experiments show our defense can effectively defeat the
modulated replay attacks and classical replay attacks.
ACKNOWLEDGMENTS
This work is partially supported by the U.S. ARO grant W911NF-
17-1-0447, U.S. ONR grants N00014-18-2893 and N00014-16-1-3214,
and the NSFC grants U1736209 and 61572278. Jiahao Cao and Qi Li
are the corresponding authors of this paper.
REFERENCES
[1] Hadi Abdullah, Washington Garcia, Christian Peeters, Patrick Traynor, Kevin
R. B. Butler, and Joseph Wilson. 2019. Practical Hidden Voice Attacks against
Speech and Speaker Recognition Systems. In Proceedings of the 2019 The Network
and Distributed System Security Symposium (NDSS ‚Äô19).
[2] E. Alepis and C. Patsakis. 2017. Monkey Says, Monkey Does: Security and Privacy
on Voice Assistants. IEEE Access 5 (2017), 17841‚Äì17851. https://doi.org/10.1109/
ACCESS.2017.2747626
[3] E. Alepis and C. Patsakis. 2017. Monkey Says, Monkey Does: Security and Privacy
on Voice Assistants. IEEE Access 5 (2017), 17841‚Äì17851. https://doi.org/10.1109/
ACCESS.2017.2747626
[4] Amazon Alexa. 2018. Wikipedia, The Free Encyclopedia. https://en.wikipedia.
org/wiki/Amazon_Alexa, [accessed December 2018].
[5] Google Assistant. 2019. Google. https://assistant.google.com/, [accessed Decem-
ber 2019].
[6] The Offical WeChat Blog. 2019. Voiceprint: The New WeChat Password. https:
//www.techinasia.com/baidu-lenovo-voice-recognition-android-unlock, [Ac-
cessed September, 2019].
[9] L. Br√§nnmark, A. Bahne, and A. Ahl√©n. 2013.
[7] Logan Blue, Hadi Abdullah, Luis Vargas, and Patrick Traynor. 2018. 2MA: Ver-
ifying Voice Commands via Two Microphone Authentication. In Proceedings
of the 2018 on Asia Conference on Computer and Communications Security (In-
cheon, Republic of Korea) (ASIACCS ‚Äô18). ACM, New York, NY, USA, 89‚Äì100.
https://doi.org/10.1145/3196494.3196545
[8] Logan Blue, Luis Vargas, and Patrick Traynor. 2018. Hello, Is It Me You‚ÄôRe
Looking For?: Differentiating Between Human and Electronic Speakers for Voice
Interface Security. In Proceedings of the 11th ACM Conference on Security & Privacy
in Wireless and Mobile Networks (Stockholm, Sweden) (WiSec ‚Äô18). ACM, New
York, NY, USA, 123‚Äì133. https://doi.org/10.1145/3212480.3212505
Compensation of Loud-
speaker‚ÄìRoom Responses in a Robust MIMO Control Framework. IEEE Trans-
actions on Audio, Speech, and Language Processing 21, 6 (June 2013), 1201‚Äì1216.
https://doi.org/10.1109/TASL.2013.2245650
[10] A. Carini, S. Cecchi, F. Piazza, I. Omiciuolo, and G. L. Sicuranza. 2012. Multiple
Position Room Response Equalization in Frequency Domain. IEEE Transactions
on Audio, Speech, and Language Processing 20, 1 (Jan 2012), 122‚Äì135. https:
//doi.org/10.1109/TASL.2011.2158420
[11] Nicholas Carlini, Pratyush Mishra, Tavish Vaidya, Yuankai Zhang, Micah Sherr,
Clay Shields, David Wagner, and Wenchao Zhou. 2016. Hidden Voice Commands.
In 25th USENIX Security Symposium (USENIX Security 16). USENIX Association,
Austin, TX, 513‚Äì530. https://www.usenix.org/conference/usenixsecurity16/
technical-sessions/presentation/carlini
[12] N. Carlini and D. Wagner. 2018. Audio Adversarial Examples: Targeted Attacks
on Speech-to-Text. In 2018 IEEE Security and Privacy Workshops (SPW). 1‚Äì7.
[13] Stefania Cecchi, Alberto Carini, and Sascha Spors. 2018. Room Response Equaliza-
tion‚ÄîA Review. Applied Sciences 8, 1 (2018). https://doi.org/10.3390/app8010016
[14] Microsoft Cortana. 2019. Microsoft. https://www.microsoft.com/en-us/cortana,
[accessed December 2019].
[15] P. L. De Leon, M. Pucher, J. Yamagishi, I. Hernaez, and I. Saratxaga. 2012. Evalu-
ation of Speaker Verification Security and Detection of HMM-Based Synthetic
Speech. IEEE Transactions on Audio, Speech, and Language Processing 20, 8 (Oct
2012), 2280‚Äì2290. https://doi.org/10.1109/TASL.2012.2201472
[16] B. Defraene, T. van Waterschoot, M. Diehl, and M. Moonen. 2013. Embedded-
optimization-based loudspeaker compensation using a generic Hammerstein
loudspeaker model. In 21st European Signal Processing Conference (EUSIPCO 2013).
1‚Äì5.
[17] Wenrui Diao, Xiangyu Liu, Zhe Zhou, and Kehuan Zhang. 2014. Your Voice
Assistant is Mine: How to Abuse Speakers to Steal Information and Control Your