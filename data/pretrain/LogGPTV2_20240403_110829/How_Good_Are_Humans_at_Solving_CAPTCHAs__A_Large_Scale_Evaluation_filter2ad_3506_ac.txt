captchas. This is actually a surprisingly large percentage
compared to our expectations, and shows the importance
of studying human understanding of both audio and image
captchas.
V. EXPERIMENTAL RESULTS
From our corpus of captchas, we presented 5000 image
captchas and 3500 audio captchas to Turkers, and 1000
image captchas to the underground service following our
study methodology above. To allow for some analysis of
human agreement on captcha answers, we had three subjects
annotate each of the captchas, for both Turkers and the
underground service. As a result we have annotated 195 000
image captcha and 84 400 audio captcha by the Turker and
39 000 captchas by the underground service. Overall this
study is based on more than 318 000 captcha.
Total captcha
Audio captcha
Failure
Audio ratio
Failure ratio
Day 1
2079120
15592
31709
0.75%
1.52512
Day 2
2041526
15476
30179
0.76%
1.47826
Day 3
1902752
14370
28475
0.75%
1.49652
Day 4
1825314
14482
28484
0.79%
1.56050
Day 5
1825314
14482
28484
0.79%
1.56050
Day 6
2178870
16412
33516
0.75%
1.56050
Day 7
2104628
16578
32564
0.79%
1.54726
EBAY CAPTCHA STATISTICS FOR A WEEK IN NOVEMBER 2009
Table III
when captchas are not frequently presented, the 20 or more
seconds taken by audio captchas may present a substantial
annoyance for users.
In the cases where we believe we know the correct
answer for a captcha, we can compare the time it takes
a user to give the correct answer with the time it takes
them to give an incorrect answer. Across the Turkers, the
underground service, and both image and audio captchas,
we see that correct answers are given more quickly than
incorrect answers, though this difference is most pronounced
for audio captchas, where correct answers are 6.5 seconds
faster than incorrect ones. This is another argument for
making sure that the captcha scheme used is sufﬁciently easy
for humans, because the more they fail, the longer they’ll
be spending on the captchas.
It is worth noting that for all these mean solving times, the
standard deviations are quite large. This is even true after
we remove outliers greater than three standard deviations
from the mean, as we do for all of our graphs. This is the
standard ﬂaw of taking timing measurements on the internet
– people are always free to stop midway through and go
do something else for a while if they like (even though the
Turkers were explicitly requested not to).
Figures 2 and 3 show histograms of solving times for our
users, demonstrating the very long tail of this distribution,
but also showing that there is a clear clustering of most users
in the 5-15 second range.
Figures 2 and 3 also show how the solving times differ
for the different schemes. For image captchas, we see
that mail.ru and Microsoft captchas take the most
time
for Turkers, with means around 13 seconds. The fastest
image captchas were from Authorize, Baidu and eBay which
take on average around 7 seconds each. In audio captchas,
Google, reCaptcha and Yahoo captchas were the most time
consuming, with means over 25 seconds, while Authorize,
eBay and Slashdot all averaged 12 seconds or less. Note
that these timings closely track the average duration of each
scheme as shown in Table II, indicating that audio captcha
solving time is dominated by the time spent listening to
the captcha. These results suggest that careful selection of a
captcha scheme can substantially reduce the friction of the
captcha system on the user.
Figure 1. Average solving time for image and audio captchas, for Turkers
and the underground service.
We focus on two primary research questions when an-
alyzing the resulting data: how much inconvenience (user
friction) does a typical captcha present to a user, and how
different captcha schemes affect users with different back-
grounds. The following sections explore these two questions
in detail.
A. Captcha Friction
Captchas are meant to be a quick and easy veriﬁcation that
a user is in fact a human. Captchas that are time consuming
or difﬁcult for humans represent friction or inconvenience
for the user. We consider some forms of captcha friction in
the following sections.
1) Solving Time: One simple measure of friction is the
total time a user spends on a given captcha, and Figure 1
shows these statistics.
Overall, we see that image captchas take Turkers about
9.8 seconds to view and solve, while audio captchas take
Turkers about 28.4 seconds to hear and solve8. While 5-10
seconds is probably an acceptable inconvenience for a user
8The underground service takes around 22.44 seconds to solve image
captchas, but we can only measure the turnaround time through their API,
which may include some overhead for routing, etc.
406
8.9421.6222.259.822.4428.3510.1325.4528.70Number of seconds0102030405060   Image Turk   Image Bypass   Audio TurkKnown correctOverallKnown incorrectFigure 4.
answers
Percents of image and audio captchas given 1, 2 or 3 distinct
humans, all three subjects annotating the captcha will agree
on the answer, while on a difﬁcult captcha, subjects will
disagree and more than one distinct answer will be given.
Thus, the greater the number of distinct answers, the greater
the disagreement and the harder the captcha.
Figure 4 shows the percent of image and audio captchas
that were given 1, 2 or 3 distinct answers by our subjects.
Both the Turkers and the underground service reach similar
numbers for overall agreement on image captchas, with all
three subjects agreeing on a single answer for around 70% of
all captchas. Only about 5% of the image captchas were so
bad that we got a different answer from each of the subjects.
Audio captchas are a total different story: All subjects
agree on only 31.2% of these captchas, and on 33.6%
everyone had a different answer. These results imply that
many audio captchas are just
too difﬁcult for humans.
As with solving time, we also see differences by scheme
when looking at number of distinct answers. Figures 5, 6
and 7 show percents of distinct answers for each scheme.
Authorize.net has the easiest image captchas for humans,
with three subjects agreeing on the answer over 93% of the
time. On the other end of the spectrum is the extremely dif-
ﬁcult mail.ru image captchas, which have perfect agreement
among subjects less than 35% of the time. On the audio side,
Google, Microsoft, and Digg audio captchas are by far the
most difﬁcult, with all subjects producing the same answer
only about 1% of the time. Some of this difﬁculty with audio
captchas may be because we give no instructions on what
kinds of words or letters to expect, but this is consistent with
for example the Google interface, which at the time of this
writing was just a single button beside the image captcha
text box that used Javascript to play the recording9. Again,
we see that captcha friction on users can be substantially
reduced by selecting a different captcha scheme.
9The alternate reCaptcha audio captchas, not tested in this study, which
do not include intentional distortion may better agreement on these.
Figure 2. Solving times for image captcha schemes
Figure 3. Solving times for audio captcha schemes
2) Solving Agreement: Another source of friction worth
considering is the inconvenience of having to solve another
captcha if a human can’t guess the correct answer to the ﬁrst
one. Since we collected the captchas rather than generating
them ourselves, we do not know the correct answer for each
captcha, so we cannot determine with certainty when a user
gets a captcha right or wrong. However, we can get an
approximation of this by looking at the number of distinct
answers given for each captcha. On a captcha that is easy for
407
01000100020001000100010005001000200020001000200020012345678910111213141516171819202122232425authorizebaiducaptchas.netdiggebaygooglemailrumsliverecaptchaskyrockslashdotblizzardyahoo050050050050050050050050345678910111213141516171819202122232425262728293031323334353637383940AuthorizeDiggeBayGoogleMicrosoftRecaptchaSlashdotYahoo71.0167.1731.1823.2228.0935.245.774.7433.60%10%20%30%40%50%60%70%Image TurkImage BypassAudio Turk1 distinct answer2 distinct answer3 distinct answerFigure 5. Percents of image captchas given 1, 2 or 3 distinct answers by
Turkers for each scheme
Figure 6. Percents of image captchas given 1, 2 or 3 distinct answers by
the underground service for each scheme
Figure 7. Percents of audio captchas given 1, 2 or 3 distinct answers by
Turkers for each scheme
3) Optimistic Solving Accuracy: As a ﬁnal measure of
captcha friction, we wanted to calculate how often a human
can expect to pass the captcha challenge. Again, we don’t
know all the answers for the captchas we collected, but we
can make an approximation: if the three subjects produced
the same answer, we assume that answer is correct. For two
distinct answers we make the optimistic assumption that
2 out of 3 answers are correct and when the three users
disagree make the optimistic assumption that 1 out of the 3
answers is correct.
Because our accuracy measurement is not perfect, looking
at the absolute values may be misleading, but differences in
solving accuracy in different scenarios should still reﬂect
real differences.
Figure 8 shows the optimistic solving accuracy for image
and audio captchas through both Mechanical Turk and the
underground service. Even with our optimistic accuracy, the
underground service achieves only 84% accuracy on image
captchas, while Turkers achieve 87%. We see again that
audio captchas are the most difﬁcult, with Turkers solving
them correctly only 52% of the time. Figure 8 also compares
the optimistic solving accuracy across different schemes.
Among image captchas, both Turkers and the underground
service are worst on the mail.ru captchas, achieving 61%
and 70% accuracy respectively. The easiest captchas are the
authorize.net captchas, where Turkers achieve 98% accuracy
and the underground service achieves 95% accuracy. Note
that these results mostly parallel what we saw in the analysis
of solving time and solving agreement, where for example,
408
93.25180.97859.94978.49582.27166.71834.60853.24842.74787.1168.11785.49468.7056.517816.31932.11319.03115.82725.38541.00433.63338.56511.99526.13213.63226.0320.230952.70277.93852.47451.90137.897424.38813.11918.6890.895145.75060.874495.2632AuthorizeBaiducaptchas.netDiggeBayGoogleMail.ruMicrosoftRecaptchaSkyrockSlashdotBlizzardYahoo0%10%20%30%40%50%60%70%80%90%100%1 answer2 answer3 answer85.48473.79343.85264.25380.67270.66720.04868.4937.69479.55746.85571.63570.49213.82521.83942.00830.54316.5972442.51225.82140.57618.96633.83924.51925.6150.691244.367814.1395.20362.73115.333337.445.689321.7291.477819.3063.84623.8934AuthorizeBaiduCaptchas.netDiggeBayGoogleMail.ruMicrosoftRecaptchaSkyrockSlashdotBlizzardYahoo0%20%40%60%80%1 answer2 answer3 answer19.1131.012924.7870.409651.52647.867832.48634.36339.23212.61538.7974.187510.82325.51239.47436.43941.65586.37236.41795.40387.6566.6228.0429.197AuthorizeDiggeBayGoogleMicrosoftRecaptchaSlashdotYahoo0%10%20%30%40%50%60%70%80%90%100%1 answer2 answer3 answerScheme
Authorize
Baidu
Captchas.net
Digg
eBay
Google
mail.ru
Microsoft
Recaptcha
Skyrock
Slashdot
Blizzard
Yahoo
Authorize audio
Digg audio
eBay audio
Google audio
Microsoft audio
Recaptcha audio
Slashdot audio
Yahoo audio
Time
6.8
7.1
8.2
8.2
7.3
9.7
12.8
13
11.9
7.9
7.7
9.3
10.6
11.9
14.8
11.8
35.2
16.6
30.1
11.7
25
Accuracy
Expected time
0.98
0.93
0.84
0.92
0.93
0.86
0.7
0.8
0.75
0.95
0.87
0.95
0.88
0.59
0.38
0.63
0.35
0.38
0.47
0.68
0.68
6.9
7.6
9.8
8.9
7.8
11.3
18.3
16.3
15.8
8.3
8.8
9.8
12
20.2
39
18.8