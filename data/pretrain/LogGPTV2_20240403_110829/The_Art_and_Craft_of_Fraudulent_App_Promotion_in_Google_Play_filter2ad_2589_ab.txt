We identi(cid:27)ed 25 participants who control at least 100 accounts on
Google Play, have been active for at least 1 year, and have completed
at least 100 ASO tasks. Following recruitment, and before starting
the interview, we read to these participants the introductory script
included in the auxiliary document. 18 of them (all male, 19-29
years old, located in Bangladesh(13), India(4) and New Zealand(1))
agreed to participate.
In the following, we refer to the interview participants as P1,
.., P18. With these participants, we conducted a structured inter-
view study that had 46 questions, with additional 72 questions for
clari(cid:27)cations, see auxiliary document. The questions range from
demographic information to work(cid:30)ow, and from the devices used
to the operational methods employed. We conducted the interviews
over Skype, between August and October, 2018. Interviews lasted
from 33 to 66 minutes (M = 46.38, SD = 12.34). We paid a rate of
5 USD for every 15 minutes a participant spent in our interview.
We audio recorded the interviews with the participant permission,
then transcribed and anonymized the data.
We analyzed the anonymized data using the Grounded Theory
method [33]. We used open coding to identify 169 unique codes,
including both abstract and concrete labels. Two members of our
team independently coded the data. The inter-coder agreement was
84.61%. In the cases where codes of the two coders did not match,
a discussion was held with a third member of our team, to decide
the (cid:27)nal code. We used axial coding to relate the generated codes,
and ended up with 22 categories grounded in the collected data.
Some of the categories are: account blending, account creation, de-
vices, early-bird fraud, extreme reviews, strategy, etc. We have then
further re(cid:27)ned our categories into the codes that form subsection
titles in § 5.
4.2 Quantitative Investigation
We performed a quantitative investigation with user accounts col-
lected from 39 ASO workers, di(cid:29)erent from the qualitative study
participants, but recruited using the same methods described in
$ 4.1. In the following, we refer to the quantitative study partici-
pants as F1, .., F39. Each of the selected workers claimed to control
up to 500 Google Play accounts (M = 211, SD = 166), and each
shared the IDs of at least 15 Google Play accounts that they control.
This yielded a total of 1,164 account IDs for analysis.
We then crawled the 6,362 unique apps that the ASO workers
reviewed using those IDs, and that were available in Google Play.
These apps had received 21,767 reviews from the 1,164 worker-
controlled accounts, and a total of 218,167,727 reviews. We used
the AppBrain API [3] to collect the category and release date of
each app.
Device model data collection. We have collected information
provided by Google Play about the devices used to post fraudulent
reviews. Google Play’s client-side enforced functionality, allows
an authenticated user to (cid:27)lter reviews according to the model of
her registered devices. We used this functionality to query the
reviews posted for an app, for all possible device models, and thus
identify the device model used to post any individual review. We
used the list of 21,597 Google supported devices [10], that contains
the parameters that we needed to identify the device models used to
post the above 21,767 reviews, posted from the 1,164 ASO worker-
controlled accounts, as perceived by Google’s systems. In addition,
we collected the device release date and price (in EUR) from GSM
Arena [12] and Gadgets360 [8].
4.3 Ethical Considerations
Some ASO work is considered unethical according to several ethical
frameworks, and many ASO workers belong to low-paid vulnerable
groups. This is why our study took utmost care to follow the best
ethical practices for conducting sensitive research with vulnerable
populations [29]. Our study had a very clear declaration of the
researchers’ identity, research objective, and potential impact on
the participants’ work without following any sort of deception.
The whole study procedure was scrutinized and approved by the
institutional review board of a major North American university
Session 10D: Mobile SecurityCCS ’19, November 11–15, 2019, London, United Kingdom2439Figure 2: Venn diagram of participant categories, reveals di-
versity and complexity of fraud organizations. Participants
are part of teams that are either (1) physically co-located or
online, (2) hierarchical or (cid:30)at, and (3) sockpuppet account
based or organic.
(IRB-18-0077@FIU). We include our recruitment message and in-
troductory script in Appendix A. We include a discussion of the
process of our recruitment, the possible reasons for our participants
to respond, and other relevant issues, in the auxiliary document.
We used GDPR [70] recommended pseudonymisation for data
processing and statistics, and other generally accepted good prac-
tices for privacy preservation. After data collection, we have deleted
all device-to-identity links and only generated statistics that allowed
us to validate our assumptions. We have avoided obtaining addi-
tional information about the devices used or the accounts involved.
We have contacted Google about our discovered device model iden-
ti(cid:27)cation issue, through Google’s vulnerability reward program
(VRP) [11] (issue: 119676181). Google has accepted our (cid:27)nding and
has invited us to join their hall of fame.
5 FINDINGS
We organize, analyze and report (cid:27)ndings from the interview and
quantitative studies. Figure 1 provides a map of the topics that we
investigated.
5.1 Team, Location, and Organization
All the 18 interview participants claimed to be part of organizations
dedicated to posting fraud in Google Play. Our data shows that ASO
workers assemble in various organizational structures. While some
of them work in a team where each person has a well-articulated
role and they are salaried on a regular basis, many of them work
in a more unstructured team and the whole team share their earn-
ings. We classify ASO teams into several categories, based on their
location, organization type, the type of fraud, and pro(cid:27)t sharing
structure. Figure 2 shows the Venn diagram of the 18 participants
grouped according to 4 of these categories, for readability.
Team size. The (cid:27)rst column of Table 1 lists the team sizes claimed
by each participant for their organization, including both physically
co-located and online team members. 5 participants claimed to work
alone. The other 13 participants claimed to have a team with at
least 10 members. Notably, P4 claimed to be part of a big company
with around 150 people in their team, who organize 15,000 organic
ASO workers through virtual (WhatsApp, Facebook) groups.
Figure 3: Photo taken by participant P10 in our study, with
the premises and (anonymized) employees of his business.
Photo reproduced with permission from the participant.
Physical co-located vs. online teams. Seven participants (Fig-
ure 2) claimed to work with a physically co-located team. 5 of them
claimed to have brick and mortar o(cid:28)ces. Figure 3 shows a photo
taken by P10, with the premises and employees of his fraud team.
7 others claimed to have strictly online teams. The remaining 4
claimed to be a part of hybrid organizations that (1) are a physical
team, including working alone with their own devices and accounts,
and (2) have access to online ASO workers. Notably, P18 said (1) “I
run a mobile repair shop. I use the devices that I get to repair.” and (2)
“I share the link in my group and they review it.” P11 said “ I use two
types of accounts, my friends and family, and my own 100 accounts.”
Organization structure: hierarchical vs. (cid:30)at. 15 participants
claimed a hierarchical structure of their organizations (Figure 2). 11
of them described speci(cid:27)c roles in their organizations, that include
job managers, who interface with the developers and manage work
from the marketplace, team admins, who organize, distribute tasks,
and verify the work of review posters, and new account creators.
For instance, P3 said “I am one of the admins in our team and we
have 10–12 admins. Under each admin, we have 15–20 members. All
admins work as subcontractors, and some of our other team members
work with the developers and manage work from the marketplace.”
However, 2 participants claimed to work in teams with a (cid:30)at orga-
nization. For instance, P15 said “We all work together. There is no
hierarchy.”
Organic fraud. 9 participants claimed to organize or be part of
online teams of “organic” users, workers who use their personal
accounts to post fake reviews (Table 1). P5 said “I also have my own
Facebook group where I have combined 60 real users to write reviews.”
P7 did not specify the number of organic accounts that they can
access, but stated “we have 3,000 accounts. If we need more we run
CPI/CPA campaign where people get an incentive to install apps.”
Pro(cid:27)t sharing. One participant claimed to pay team members a
monthly salary, while another one claimed an even split among
members. Three of them mentioned preferential cuts for the job
manager (10–25%) and team lead (10–50%) and equal split of the
rest among the actual review posters. Two participants claimed a
(cid:30)at rate for the review posters ($0.40 per review). The rest of the
participants did not respond to this question.
Summary. Our study thus con(cid:27)rms observations made by existing
work, that fraud is perpetrated by experts who control either (1)
many sockpuppet user accounts, e.g., [28, 37, 55, 59, 60, 63, 64,
77, 93, 95, 99] or (2) organic fraudsters, i.e., real account owners
Session 10D: Mobile SecurityCCS ’19, November 11–15, 2019, London, United Kingdom2440Accounts
Devices
0
0
0
0
400
0
200
500
0
1,000
0
0
0
15,000
15,000
300
1,500
0
0
300
40
200
0
0
0
15,000
100
0
N/A
P Members Organic Inorganic Mobile Laptop Online
P1
P2
P3
P4
P5
P6
P7
P8
P9
P10
P11
P12
P13
P14
P15
P16
P17
P18
40
12
195
150
12
1
50
35
15
30
1
1
13
34
10
50
1
1
0
0
0
0
0
0
0
0
0
35
0
0
13
0
0
0
0
0
1,500
3,000
150
0
450
100
0
60
500
0