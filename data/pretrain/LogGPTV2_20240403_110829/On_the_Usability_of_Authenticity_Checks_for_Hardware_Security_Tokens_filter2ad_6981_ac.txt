### Elaborate Process and Attack Vectors

Creating an original-looking cast from scratch is a highly intricate process. These attacks have the advantage that the internal hardware does not need to be genuine; only the exterior case needs to appear authentic (assuming end users typically do not x-ray their devices). Although it is feasible, conducting bus snooping or IC microprobing by drilling small, resealable holes into the case is also a very complex task.

### Openable Tokens and Visual Inspectability

On one hand, openable tokens and visual inspectability allow users to detect implants and make token replica attacks more difficult. On the other hand, they also provide easy access to attackers. It can be assumed that well-crafted, subtle hardware implants would not be noticeable to users. IC modifications are also possible, as chips come in standardized packages that can be easily reconstructed.

**Usability:**
Visually comparing the interior of the device with manufacturer-provided images is a cumbersome and error-prone method. Users might damage the case when opening it, which reduces the feasibility and usability of this approach. Tamper-resistant cases do not exhibit these usability issues.

### 5.2.3 Hardware (Circuit)

Electronic signals on the printed circuit board (PCB) or within an integrated circuit (IC) are vulnerable to interception and manipulation. Shielding critical data and the respective circuitry can be achieved through a secure CPU or by integrating an external co-processor (secure element) on the PCB. The keys reside inside the CPU or secure element and never leave it. Many software-based authenticity checks provide strong protection only when implemented in such hardened CPU designs and architectures (e.g., firmware or key attestation). In our wallet sample, only Ledger uses a secure element [59]. Trezor argues against secure elements, citing closed-source software and the potential for increased hacker attention if widely used [94].

**Effectiveness:**
Many secure CPUs and secure elements are designed with hardware attackers in mind and include preventive measures such as side-channel-resistant design and tamper-detection circuits. However, even with secure CPUs (including enclaves), transient execution attacks [51, 64, 107] can extract secrets via cache-timing side-channels once the attacker achieves code execution. Such features are still rare in low-end microcontrollers used in wallets and authentication tokens. All wallets in our device overview use ARM Cortex M0-M4 architectures, which do not employ data caches or transient execution. External secure elements are vulnerable to hardware implants [93] and susceptible to bus snooping. Rewiring or snooping signals on a PCB requires less equipment than doing the same on an IC. Additionally, fraudulent firmware could, in theory, still leak secrets via a physical channel [79]. Technical challenges of ARM TrustZone have been reported recently [84, 92].

**Usability:**
In this case, the user is not involved. However, if users are aware of these measures, they can base their trust decisions on them.

### 5.2.4 Software (Automatic)

For all assessed hardware wallets, the authenticity of the bootloader and/or firmware is verified using hash or signature verification. This is carried out either by the firmware, the bootloader, or the secure element. The simplest form of software attestation provided by our tested devices is local firmware validation, where the bootloader validates the integrity of the firmware (via a signature check), or vice versa. For two of the assessed devices, the secure element locally attests the authenticity of the microcontroller unit via a signature check. A more sophisticated approach is remote firmware attestation, where the internal status of the device is verified by a trusted third party (e.g., using challenge-response protocols).

Yubico is very secretive about any of their implemented automatic software attestation methods, making it unclear whether such methods are applied to our tested YubiKeys.

**Effectiveness:**
Remote firmware attestation is more effective than local methods as it complicates token replication. With remote attestation, attackers would need to mimic the third-party attestation protocol. Generally, the effectiveness of all firmware attestation methods is enhanced if secure CPUs or secure elements are involved. Despite these measures, several attacks on firmware have been carried out. Although manufacturers usually fix these vulnerabilities, their existence, even if only for a short time, poses a significant threat. As the manufacturing of hardware tokens becomes more sophisticated and globally distributed, and the time-to-market constantly shortens, the probability of software vulnerabilities increases [8]. Furthermore, automatic software attestation methods are ineffective against hardware implants, IC modification, USB exploits, token pre-initialization, and secret extraction.

**Usability:**
Automatic software checks do not require user interaction and thus do not cause any usability issues. However, if these checks are not visible and/or known to users, they cannot make related trust decisions.

### 5.2.5 Software (Manual)

YubiKeys come with a pre-loaded attestation key and a manufacturer-signed attestation certificate. Users can manually verify the authenticity of their YubiKey by visiting a sub-page of the manufacturer’s website [115]. In our sample, Yubico and Ledger check the attestation key of the devices. A server (e.g., an online banking service) can optionally request an attestation certificate from a YubiKey during user registration to verify the device’s authenticity. YubiKeys also offer Personal Identity Verification (PIV) attestation for newly generated keys to ensure that a certain asymmetric key was generated on the device and not imported from elsewhere.

Another attack prevention method, used by two of the tested hardware wallets, is to ship tokens without firmware, forcing users to manually load the firmware during initialization. This erases any pre-loaded keys or seeds.

**Effectiveness:**
Key attestation prevents token replicas if implemented with a secure CPU or secure element from which an attestation key and certificate cannot be extracted. This raises the bar for firmware modification, as attackers cannot simply flash fraudulent firmware. Forcing manual firmware loading complicates token replicas and prevents firmware modifications, given that the user overwrites fraudulent firmware with the legitimate one. This also complicates secret extraction attacks because an extracted secret would lose its value once the new firmware is installed.

**Usability:**
Manual authenticity checks are often not user-friendly. In many cases, users must run scripts via the terminal (e.g., YubiKey PIV attestation, YubiKey attestation certificates, hardware wallets’ secure element authenticity check). Manufacturers neither sufficiently explain nor advertise these methods.

### 6. Survey

Our user survey was designed to address RQ2. Specifically, we sought to answer the following questions:
- Which automatic authenticity checks are users aware of?
- Which manual authenticity checks do users perform?
- Are these authenticity checks perceived as useful?
- Do users' perceptions of security guarantees match the technical reality?

Participants who owned (i) a hardware wallet, (ii) a YubiKey, and/or (iii) a smartphone were eligible to participate. They were presented with questions regarding the respective device. We recruited smartphone users as a control group to compare usage and authenticity check patterns of devices designed for security purposes (hardware wallets, YubiKeys) with general-purpose devices (smartphones). We did not include attack vectors and attestation features that solely apply to smartphones in our market review. However, all presented attack vectors (see Section 4.1) also apply to smartphones.

### 6.1 Discussion Rounds

Following Jensen and Laurie [47], we conducted a small-scale qualitative research study to explore the problem space before designing our survey. Two researchers conducted two discussion rounds with (i) a group of IT security professionals who owned an HST such as a hardware wallet or a YubiKey (9 participants), and (ii) a group of people without technological expertise who owned a smartphone (3 participants). Both groups were recruited at our institution.

We asked the following questions:
- Which HSTs or devices do you own?
- Do you think your hardware device was genuine when you received it?
- Why do you think your hardware device was (not) genuine?
- Which attacks on your device can you imagine could have happened while it was distributed?

One researcher led the discussion while the other took notes. We recorded and transcribed both discussion rounds after obtaining informed consent. Both researchers independently coded the data, extracting recurring themes and discussing them to collect important findings for our survey design. We considered the results of both discussion rounds and our market review when designing the main questionnaire.

### 6.1.1 Results (Smartphone Group)

All participants stated that they did not spend much thought on the authenticity of their device when they received it but assumed it was genuine. The two most important factors influencing their trust were (i) the high-quality design of the packaging and (ii) the integrity of the stickers on the package or device. One participant stated: "The packaging is very high quality. I’m not sure that someone who forges it [the smartphone] would put so much effort into the packaging."

This participant further elaborated that the quality of the smartphone met expectations, i.e., the display and buttons functioned properly. Another participant mentioned that a protective screen foil influenced their trust.

The participants' assessments of the likelihood of distribution attacks were mixed. One participant said: "From the moment it [the smartphone] is in the supply chain, packaged, and this foil is on it... When you open that up, to get it all back in the same way, that is very time-consuming."

In contrast, another participant stated: "I can imagine that one would build something like that into the hardware, for example, spying stuff."

### 6.1.2 Results (HST Group)

In contrast to the smartphone group, the majority of HST users said they did not fully trust the genuineness of their device when they received it. One participant explained that one could never entirely trust the cryptography on the device if they had not implemented it themselves. Another participant said: "If someone changes the hardware, there is no chance for the normal user to detect it. Especially with the Yubikey, which is cast in plastic... You can only hope you got an original key."

Still, some participants reported that their trust in their HST was positively influenced by stickers on the packaging and the fact that their device arrived at their home address shortly after purchasing it. One participant stated: "I trust the Yubikey because the advertising is good and because other people I trust do trust this product."

None of the participants opened their HST, as they (i) were afraid to break it, (ii) did not want to spend time on it, or (iii) did not think that attacks based on added hardware could work. Two participants said they checked the authenticity of their HST on the vendor's website as recommended in the manual. Another participant mentioned that the potential damage caused by a non-genuine device, i.e., how valuable the secrets protected by the token are, is important when deciding which authenticity checks to use. This might be why the HST group invested more time and thought into the authenticity of their devices than the smartphone group.

### 6.2 Study Design

We opted for an online survey [56] to gather a large, geographically distributed sample and obtain quantitative insights into user perceptions and usability problems of authenticity checks deployed in HSTs. We designed our survey based on the discussion rounds and a comprehensive literature study of attack vectors. The survey consists of 25-27 closed questions (multiple-choice, 5-point Likert scale) and 2-3 open questions depending on the answers (some questions were follow-up questions). To assess the participants' security affinity, we used the Security Behavior Intentions Scale (SeBIS) [25], which quantifies intentions and self-assessments of the respondents' security behavior. We hosted the questionnaire on Surveymonkey.com [103]. The full questionnaire can be found on our GitHub repository [1].

If participants owned multiple eligible devices, we assigned them to the hardware wallet sample (first choice) or the YubiKey sample (second choice), assuming that HST users are harder to recruit than smartphone users.

### 6.3 Recruitment and Participants

We distributed our survey through Bitcoin, blockchain, and Yubikey mailing lists (18%), social media (75%), and personal contacts at partner institutions (7%). As compensation, we raffled gift vouchers and premium fair-trade chocolates (winning chance: 6%). This approach aligns with studies by Deutskens et al. [21] and Laguilles et al. [55], which show that lotteries with smaller prizes but a higher winning chance are effective for increasing response rates in surveys. The demographics of our final data set are shown in Appendix 7. The sample consists mainly of male and technically adept participants, corresponding to the demographics of Bitcoin users [9] and the technology industry in general [89].

### 6.4 Validity and Reliability of Our Dataset

To ensure sufficient statistical power, we calculated the effective sample size [61] with a significance level of .05 (95% confidence interval) and a power of .8 (the best practice value currently used [65]). These numbers yield a minimum sample size of 61 users per group. Our final dataset consists of responses from 62 hardware wallet (H), 66 YubiKey (Y), and 66 smartphone users (S). We asked participants for demographic data, including their occupation and whether it is within IT security. Two-thirds of our participants work in IT, with 42% professionally involved in IT security topics and decision-making.

We pre-tested our survey design through a think-aloud study with seven participants (non-tech-savvy and tech-savvy users) to check the comprehension of technical terms (taken from the manufacturers' websites) and remove biased phrasing as far as possible. Additionally, we collected expert feedback from other researchers. Our main concern was to reduce social desirability biases, especially with more security-aware participants. The survey was distributed in English and German; two independent translators revised the translations. To allow unaided answers, we provided "Others" options.

To eliminate re-submissions and automated submissions, we performed technical measures and allowed only one submission per email/IP address and device. We are confident that none of our participants lied about possessing a hardware wallet, YubiKey, or smartphone to unfairly obtain a prize, assuming that smartphones are common. Participants who owned none of the three devices were immediately redirected to the SeBIS [25] questions. We implemented three exclusion criteria to ensure a reliable set of data and applied them in the following order:

- Four open and two check-up questions (rephrasing earlier questions or providing invalid answer possibilities), which we manually checked for consistency and meaningfulness (21 participants were removed).
- One attention check question with shuffled answer options (58 participants were removed).
- Completing the questionnaire was mandatory (six participants were removed).

In total, 279 participants took part in our survey. After applying our exclusion criteria, we reached a final sample of n = 194 for our analysis.

### 6.5 Data Analysis

Besides descriptive statistics, we performed statistical tests. For closed-ended nominal scaled questions, we conducted pairwise χ2 tests between our three groups and interpreted the effect size Cramér’s V [49]. In cases where the expected frequencies were smaller than 5, we additionally conducted a Fisher’s Exact test. To counteract the multiple comparisons problem for multiple answer questions, we applied the Holm–Bonferroni correction [41]. For interval-scaled questions, we calculated the Pearson correlation coefficient ρ. We rejected the null hypothesis of independence when p was smaller than .05 (95% confidence interval).

Regarding the open questions (qualitative data), two researchers independently coded the responses concerning (i) the improvement suggestions of authenticity checks and (ii) the "other" answer option to closed-ended questions. We created a codebook, coded the entire data, and discussed conflicts until agreement was reached among the coders. Our inter-rater reliability α = .91 (Krippendorff’s Alpha value [54]) indicates a high level of agreement.

### 6.6 Ethical Considerations

Our ethical review board approved the study. Preserving the participants' privacy and limiting the collection of sensitive information as far as possible are fundamental principles. We assigned the study participants IDs to anonymously process their data. The collected email addresses from raffle participants were stored separately from the survey responses. All participants were informed about the data handling procedures and gave informed consent. The study strictly followed the EU’s General Data Protection Regulation (GDPR).

### 6.7 Results

#### 6.7.1 Device Usage (Q2, Q3, Q18)

We observed significant differences in device usage across all groups (χ2(YH,YS,HS): p > .39 [large]). In contrast, no notable differences emerged between Y and S. The majority of Y and S reported using their devices in both their private and professional life (Y: 50%, S: 47%), followed by exclusive use in their professional life (Y: 27%, S: 30%) and exclusive use in their private life (Y: 23%, S: 23%).

This structured and detailed approach ensures clarity, coherence, and professionalism in the text.