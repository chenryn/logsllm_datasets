a very elaborate process, since an original-looking cast has
to be built from scratch. At the same time, these attacks have
the advantage that the built-in hardware does not need to look
genuine, only the case does (assuming that end users usually
do not x-ray their devices). Lastly, it is feasible—although
very elaborate—to conduct bus snooping or IC microprobing
by drilling small, resealable holes into the case.
On the one hand, openable tokens and visual inspectability
enable users to discover implants and make token replica
attacks more difﬁcult. On the other hand, openable tokens
give attackers easy access as well. It can be assumed that
well-made, subtle hardware implants would not be noticeable
to users. IC modiﬁcations are also possible, since chips come
in standardized packages which are easily reconstructed.
Usability: Visually comparing the interior of the device
with manufacturer-provided pictures is a cumbersome and
error-prone method. Users might damage the case when open-
ing it, which reduces the feasibility and usability of this ap-
proach. Tamper-resistant casts do not exhibit these usability
issues.
5.2.3 Hardware (Circuit)
Electronic signals on the printed circuit board (PCB) or within
an IC are subject to interception and manipulation. Shielding
of critical data and the respective circuitry can be accom-
plished through a secure CPU, or by integrating an external
co-processor (secure element) on the PCB. The keys reside
USENIX Association
30th USENIX Security Symposium    41
inside the CPU or element and never leave it. Many software-
based authenticity checks only provide strong protection
when implemented in such hardened CPU design and architec-
ture (e.g., ﬁrmware or key attestation). In our wallet sample,
only Ledger facilitates a secure element [59]. Trezor in fact
argues against secure elements, as they are closed source soft-
ware, and postulates that if “secure elements [are] widely used,
it will increasingly attract the attention of hackers” [94].
Effectiveness: Many secure CPUs and secure elements are
designed with the hardware attacker in mind and provide
the respective prevention measures. They usually employ
side-channel-resistant design and tamper-detection circuits
within the IC. However, even if secure CPUs (including en-
claves) are used, transient execution attacks [51, 64, 107] can
extract secrets via i.a. cache-timing side-channels once the
attacker achieves code execution. Such features are still sel-
dom found in low-end microcontrollers as used in wallets and
authentication tokens. All wallets in our device overview use
ARM Cortex M0-M4 architectures which neither employ data
caches nor transient execution. External secure elements are
vulnerable to hardware implants [93] and susceptible to bus
snooping. Rewiring or snooping signals on a PCB requires
far less equipment than doing the same on an IC. Moreover, a
fraudulent ﬁrmware could, in theory, still leak secrets via a
physical channel [79]. Technical challenges of ARM Trust-
Zone have been reported recently [84, 92].
Usability:
In this case, the user is not involved. However, if
users are aware of these measures, they can accordingly base
their trust decisions on them.
5.2.4 Software (Automatic)
For all assessed hardware wallets, the authenticity of the boot
loader and/or ﬁrmware is checked by a hash or signature
veriﬁcation. This is carried out either by the ﬁrmware, the boot
loader, or the secure element. The simplest form of software
attestation provided by our tested devices is local ﬁrmware
validation. Thereby, the boot loader validates the integrity
of the ﬁrmware (by conducting a signature check), or vice
versa. For two of the assessed devices, the secure element
locally attests the authenticity of the micro-controller unit via
a signature check. A more sophisticated approach is to use
remote ﬁrmware attestation where the internal status of the
device is attested by a trusted third party (e.g., by utilizing
challenge-response protocols).
Yubico is very secretive about any of their implemented au-
tomatic software attestation methods. Thus, it remains unclear
whether such methods are applied to our tested YubiKeys.
Effectiveness: Remote ﬁrmware attestation is more effec-
tive than local methods since it complicates token replica-
tion. With remote attestation in place, attackers would have
to mimic the third-party attestation protocol. Generally, the
effectiveness of all ﬁrmware attestation methods is increased
if secure CPUs or secure elements are involved. Despite these
approaches being implemented, several attacks on ﬁrmware
have been carried out. Although manufacturers usually ﬁx
these vulnerabilities, their existence—even if only for a short
time—poses a threat which is hard to defeat. As the man-
ufacturing of hardware tokens becomes more sophisticated
and globally distributed, and the time-to-market constantly
shortens, the probability of software vulnerabilities is grow-
ing [8]. Furthermore, automatic software attestation methods
are ineffective against hardware implants, IC modiﬁcation,
USB exploits, token pre-initialization, and secret extraction.
Usability: Automatic software checks do not require user
interaction, hence they do not cause any usability issues. How-
ever, if these checks are not visible and/or known to users,
they are not able to make related trust decisions.
5.2.5 Software (Manual)
YubiKeys come with a pre-loaded attestation key and a
manufacturer-signed attestation certiﬁcate. Users can man-
ually verify the authenticity of their YubiKey by visiting a
sub-page of the manufacturer’s website [115]. With regard to
our sample, Yubico and Ledger do check the attestation key
of the devices. A server (e.g., an online banking service) can
optionally request an attestation certiﬁcate from a YubiKey
during user registration to check the device’s authenticity.
YubiKeys additionally have the option to run Personal Iden-
tity Veriﬁcation (PIV) attestation for newly generated keys
to ensure that a certain asymmetric key was generated on the
device and not imported from elsewhere.
A further attack prevention method (used by two of the
tested hardware wallets) is to ship tokens without ﬁrmware,
thus forcing users to manually load the ﬁrmware when ini-
tializing their wallet. Thereby, any pre-loaded keys or seeds
are erased.
Effectiveness: Key attestation does prevent token replicas,
if implemented with a secure CPU or secure element from
which an attestation key and certiﬁcate cannot be extracted.
This raises the bar for ﬁrmware modiﬁcation, since attack-
ers cannot simply ﬂash fraudulent ﬁrmware. Forcing manual
ﬁrmware loading complicates token replicas and prevents
ﬁrmware modiﬁcations, given that the user overwrites fraudu-
lent ﬁrmware with the legitimate one. This also complicates
secret extraction attacks because an extracted secret would
lose its value as soon as the new ﬁrmware is installed.
Usability: Manual authenticity checks are often not user-
friendly. In many cases, users have to run a script via the
terminal (i.e., YubiKey PIV attestation, YubiKey attestation
certiﬁcates, hardware wallets’ secure element authenticity
check). Also, manufacturers neither sufﬁciently explain nor
advertise these methods.
6 Survey
Our user survey was designed to address RQ2. In particular,
we sought to answer the following questions:
• Which automatic authenticity checks are users aware of?
42    30th USENIX Security Symposium
USENIX Association
• Which manual authenticity checks do users perform?
• Are these authenticity checks perceived as useful?
• Do users’ perceptions of security guarantees match the
technical reality?
Participants who owned (i) a hardware wallet, and/or (ii)
a YubiKey, and/or (iii) a smartphone were eligible to par-
ticipate. They were presented with questions regarding the
respective device. We recruited smartphone users as a control
group to compare usage and authenticity check patterns of de-
vices designed for security purposes only (hardware wallets,
YubiKeys) with general-purpose devices (smartphones). We
did not include attack vectors and attestation features which
solely apply to smartphones in our market review. However,
all presented attack vectors (see Section 4.1) also apply to
smartphones.
6.1 Discussion Rounds
Following Jensen and Laurie [47], we conducted a small-scale
qualitative research study to ﬂexibly explore the problem
space before designing our survey. Two researchers did two
discussion rounds with (i) a group of people working in the
ﬁeld of IT security who owned an HST such as a hardware
wallet or a YubiKey (9 participants), and (ii) a group of people
without technological expertise who owned a smartphone (3
participants). Both groups were recruited at our institution.
We asked the following questions: (i) Which HSTs or devices
do you own? (ii) Do you think that your hardware device was
genuine when you received it? (iii) Why do you think that
your hardware device was (not) genuine? (iv) Which attacks
on your device can you imagine could have happened while
it was distributed?
One researcher led the discussion while the other one took
notes. We recorded and transcribed both discussion rounds
after obtaining informed consent. Both researchers openly
coded the data independently, extracting re-occurring themes
and then discussing them to collect important ﬁndings for our
survey design. We took the results of both discussion rounds
and our market review into account when designing the main
questionnaire.
6.1.1 Results (Smartphone Group)
All participants stated that they did not spend much thought
on the authenticity of their device when they received it, but
just assumed that it was genuine. The two most important
factors inﬂuencing the participants’ trust were (i) the high-
quality design of the packaging, and (ii) the integrity of the
stickers on the package or device. One participant stated:
“The packaging is very high quality. I’m not sure that someone
who forges it [the smartphone] would put so much effort into
the packaging.”
This participant further elaborated that the quality of the
smartphone met expectations, i.e., the display and the buttons
functioned properly. Another participant mentioned that a
protection foil on the screen inﬂuenced their trust.
The participants’ assessments of the likelihood of distri-
bution attacks were mixed. One participant said: “From the
moment it [the smartphone] is in the supply chain, packaged,
and this foil is on it... When you open that up, to get it all back
in the same way, that is very time-consuming.”
In contrast, another participant stated: “I can imagine that
one would build something like that into the hardware, for
example, spying stuff.”
6.1.2 Results (HST Group)
In contrast to the smartphone group, the majority of the HST
users said that they did not fully trust the genuineness of their
device when they received them. One participant explained
that one could never entirely trust the cryptography on the
device if one has not implemented it themself. Another par-
ticipant said: “If someone changes the hardware, there is no
chance for the normal user to detect it. Especially with the
Yubikey, which is cast in plastic...You can only hope you got
an original key.”
Still, some participants reported that their trust in their HST
was positively inﬂuenced by stickers on the packaging and by
the fact that their device arrived at their home address shortly
after purchasing it. One participant furthermore stated: “I
trust the Yubikey because the advertising is good and because
other people I trust do trust this product.”
None of the participants opened their HST as they (i) were
afraid to break it, (ii) did not want to spend time on it, or
(iii) did not think that attacks based on added hardware could
work. Two participants said that they checked the authen-
ticity of their HST on the vendor’s website since that was
recommended in the manual. Another participant mentioned
that the potential damage caused by a non-genuine device,
i.e., how valuable the secrets protected by the token are, is
important when deciding which authenticity checks to use.
This might be a reason why the HST group invested more
time and thought into the authenticity of their devices than
the smartphone group.
6.2 Study Design
We opted for an online survey [56] to get a large number
of—also geographically distributed—participants and, thus,
quantitative insights about user perceptions and usability prob-
lems of authenticity checks deployed in HSTs. We designed
our survey based on the discussion rounds and a comprehen-
sive literature study of attack vectors. The survey consists
of 25–27 closed questions (multiple-choice, 5-point Likert
scale) and 2–3 open questions depending on the answers
(some questions were follow-up questions). To assess the
participants’ security afﬁnity, we used the Security Behavior
Intentions Scale (SeBIS) [25] which quantiﬁes intentions and
self-assessments of the respondents’ security behavior. We
hosted the questionnaire on Surveymonkey.com [103]. The
full questionnaire can be found on our GitHub repository [1].
If participants owned multiple eligible devices, we assigned
them either to the hardware wallet sample (ﬁrst choice) or the
USENIX Association
30th USENIX Security Symposium    43
YubiKey sample (second choice), assuming that HST users
are harder to recruit than smartphone users.
6.3 Recruitment and Participants
We distributed our survey through Bitcoin, blockchain, and
Yubikey mailing lists (18%), social media (75%), and per-
sonal contacts at partner institutions (7%). As compensation,
we rafﬂed gift vouchers and premium fair-trade chocolates
(winning chance: 6%). This approach is in line with studies
by Deutskens et al. [21] and Laguilles et al. [55] which both
showed that lotteries with smaller prizes but a higher win-
ning chance are an effective strategy for increasing response
rates in surveys. The demographics of our ﬁnal data set are
shown in Appendix 7. The sample consists mainly of male
and technically adept participants, corresponding to the de-
mographics of Bitcoin users [9] and the technology industry
in general [89].
6.4 Validity and Reliability of our Dataset
To ensure sufﬁcient statistical power, we calculated the effec-
tive sample size [61] with a signiﬁcance level of .05 (95%
conﬁdence interval), and a power of .8 (the best practice value
currently used [65]). These numbers yield a minimum sample
size of 61 users per group. Our ﬁnal dataset consists of re-
sponses from 62 hardware wallet (H ), 66 YubiKey (Y ), and
66 smartphone users (S). We asked the participants for de-
mographic data including their occupation and whether it is
within IT security. Two-thirds of our participants work in IT,
from which 42% are professionally involved in IT security
topics and decision-making.
We pre-tested our survey design through a think-aloud
study with seven participants (non-/tech-savvy users) to check
the comprehension of technical terms (taken from the man-
ufacturers’ websites) and remove biased phrasing as far as
possible. Additionally, we collected expert feedback from
other researchers. Our main concern was to reduce social
desirability biases, especially with respect to more security-
aware participants. The survey was distributed in English and
German; two independent translators revised the translations.
To allow unaided answers, we provided "Others" options.
In order to eliminate re-submissions and automated submis-
sion, we performed technical measures and allowed only one
submission per email/IP address and device. We are conﬁdent
that none of our participants lied about the possession of a
hardware wallet, YubiKey, or smartphone to unfairly obtain a
price in our rafﬂe, assuming that smartphones are common.
Participants who owned neither of the three devices were
immediately redirected to the SeBIS [25] questions. We im-
plemented three exclusion criteria to ensure a reliable set of
data and applied them in the following order:
• Four open and two check-up questions (re-phrasing ear-
lier questions or providing invalid answer possibilities),
which we manually checked for consistency and mean-
ingfulness (21 participants were removed).
• One attention check question with shufﬂed answer op-
tions (58 participants were removed).
• Completing of the questionnaire was mandatory (six
participants were removed).
In total, 279 participants took part in our survey. After
applying our exclusion criteria, we reached a ﬁnal sample of
n = 194 for our analysis.
6.5 Data Analysis
Besides descriptive statistics, we also performed statistical
tests. For closed-ended nominal scaled questions, we con-
ducted pair-wise χ2 tests between our three groups and in-
terpreted the effect size Cramér’s V [49]. In cases where
the expected frequencies were smaller than 5, we addition-
ally conducted a Fishers’ Exact test. To counteract the multi-
ple comparisons problem for multiple answer questions, we
applied the Holm–Bonferroni correction [41]. For interval-
scaled questions, we calculated the Pearson correlation co-
efﬁcient ρ. We rejected the null-hypothesis of independence
when p was smaller than .05 (95% conﬁdence interval).
Regarding the open questions (qualitative data), two re-
searchers independently coded the responses concerning (i)
the improvement suggestions of authenticity checks, and (ii)
the “other” answer option to closed-ended questions. We cre-
ated a codebook, coded the entire data, and discussed conﬂicts
until agreement was reached among the coders. Our inter-
rater reliability α = .91 (Krippendorff’s Alpha value [54])
indicates a high level of agreement.
6.6 Ethical Considerations
Our ethical review board approved the study. Preserving the
participants’ privacy and limiting the collection of sensitive
information as far as possible are fundamental principles. We
assigned the study participants IDs to anonymously process
their data. The collected email addresses from rafﬂe partici-
pants were stored separately from the survey responses. All
participants were informed about the data handling proce-
dures and gave informed consent. The study strictly followed
the EU’s General Data Protection Regulation (GDPR).
6.7 Results
6.7.1 Device Usage (Q2, Q3, Q18)
We observed signiﬁcant differences in the device usage across
all groups (χ2(Y H ,Y S ,H S ) : p  .39 [large]). In contrast, no no-
table differences emerged between Y and S. The majority
of Y and S reported to use their devices in both their private
and professional life (Y :50%, S:47%), followed by exclu-