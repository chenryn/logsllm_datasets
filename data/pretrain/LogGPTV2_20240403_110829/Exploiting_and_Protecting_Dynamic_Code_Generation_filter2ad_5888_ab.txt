In this section, we describe in detail
the code cache
injection threat we are addressing in this paper. We begin this
section with our assumptions and threat model. Next, we show
how the code cache can be attacked to bypass state-of-the-art
exploit mitigation techniques. Finally, we demonstrate how a
naive W⊕X enforcement can be bypassed by exploiting race
conditions.
A. Assumptions and Threat Model
SDCG focuses on preventing remote attackers from leverag-
ing the code cache as an attack vector to achieve arbitrary code
execution. We focus on two classic attack scenarios discussed
as follows. In both scenarios, we assume the code generator
itself is trusted and does not have security vulnerabilities.
• Foreign Attacks. In this scenario, the code generator is
a component of a program (e.g., a web browser). The
program is benign, but components other than the code
generator are assumed to be vulnerable when handling
input or contents provided by an attacker (e.g., a malicious
web page). Attackers can then exploit
the vulnerable
components to attack the code cache.
• Jailbreak Attacks. In this scenario, the code generator is
used to sandbox or monitor an untrusted program, and
attacks are launched within the code cache. This could
happen under two circumstances. First, the sandboxed
program itself is malicious. Second, the program is be-
nign, but the dynamically generated code has vulnerabil-
ities that can be exploited by attackers to jailbreak.
Without loss of generality, we assume that the following
mitigation mechanisms for both general and JIT-based exploits
have been deployed on the target system.
• Address Space Layout Randomization. We assume that
the target system has at least deployed base address ran-
domization, and all predictable memory mappings have
been eliminated.
• JIT Spray Mitigation. For JIT engines, we assume that
they implement a full-suite of JIT spray mitigation mecha-
nisms, including but not limited to random NOP insertion,
constant splitting, and those proposed in [5, 60].
• Guard Pages. We assume the target system creates guard
pages (i.e., pages without access permission) to wrap each
pool of the code cache, as seen in the Google V8 JS
engine. These guard pages can prevent buffer overﬂows,
both overﬂows out of the code cache, and overﬂows into
the code cache.
• Page Permissions. We assume that the underlying hard-
ware has support for mapping memory as non-executable
(NX), and that writable data memory like the stack and
normal heap are set to be non-executable. Furthermore,
we assume that all statically generated code has been set
to non-writable to prevent overwriting. However, almost
all JIT compilers map the code cache as both writable
and executable.
The target system can further deploy the following ad-
vanced mitigation mechanisms for the purpose of sandboxing
and monitoring:
• Fine-grained Randomization. The target system can en-
force ﬁne-grained randomization by permuting the order
of functions [27] or basic blocks [59], randomizing the
location of each instruction [39], or even randomizing the
instruction set [8].
• Control Flow Hijacking Mitigation. The target system can
deploy control ﬂow hijacking mitigation mechanisms, in-
cluding (but not limited to): control ﬂow integrity enforce-
ment, either coarse-grained [63, 64] or ﬁne-grained [2,
37]; return-oriented programming detection [13, 40]; and
dynamic taint analysis based hijacking detection [36].
To allow overwriting of
the code cache, we assume
there is at
least one vulnerability that allows attackers to
write to an attacker-speciﬁed address with attacker-provided
contents. We believe this is a realistic assumption, because
many types of vulnerabilities can be exploited to achieve this
goal, such as format string [35], heap overﬂow [16], use-
after-free [14], integer overﬂow [15], etc. For example, the
attack described in [43] obtained this capability by exploiting
an integer overﬂow vulnerability (CVE-2013-6632); in [11],
the author described how ﬁve use-after-free vulnerabilities
(CVE-2013-0640, CVE-2013-0634, CVE-2013-3163, CVE-
2013-1690, CVE-2013-1493) can be exploited to perform
arbitrary memory writes. It is worth noting that in many attack
scenarios, the ability to do arbitrary memory write can easily
lead to arbitrary memory read and information disclosure
abilities.
B. Overwriting the Code Cache to Bypass Exploit Mitigation
Techniques
1) Software Dynamic Translator: For ease of discussion,
we use the term software dynamic translator (SDT) to represent
software that leverages dynamic code generation to translate
code in one format to another format. Before describing the
4
attacks, we ﬁrst give a brief introduction on SDT. A core task
of all SDTs is to maintain a mapping between untranslated
code and translated code. Whenever a SDT encounters a new
execution unit (depending on the SDT, the execution unit could
be a basic block, a function, or a larger chunk of code), it
ﬁrst checks whether the execution unit has been previously
translated. If so, it begins executing the translated code residing
in the code cache; otherwise, it translates this new execution
unit and installs the translated code into the code cache.
2) Exploit Primitives: In this section, we describe how the
code cache with full WRX permission can be overwritten. This
is done in two steps. First, we need to bypass ASLR and ﬁnd
out where the code cache is located. Second, we need to write
to the identiﬁed location.
a) Bypassing ASLR: The effectiveness of ASLR or
any randomization based mitigation mechanism relies on two
assumptions: i) the entropy is large enough to stop brute-force
attacks; and ii) the adversary cannot learn the random value
(e.g., module base, instruction set).
Unfortunately, these two assumptions rarely hold in prac-
tice. First, on 32-bit platforms, user space programs only
have 8 bits of entropy for heap memory, which is subject
to brute-force guessing [53] and spray attacks [18]. Second,
with widely available information disclosure vulnerabilities,
attackers can easily recover the random value [46, 50]. In fact,
researchers have demonstrated that even with a single restricted
information disclosure vulnerability, it is possible to traverse
a large portion of memory content [55].
When attacking a code cache, we can either launch a
JIT spray attack to prepare a large number of WRX pages
on platforms with low entropy, or leverage an information
disclosure vulnerability to pinpoint the location of the code
cache. Note that as one only needs to know the location of
the code cache, most ﬁne-grained randomizations that try to
further randomize the contents of memory are ineffective for
this attack. Since the content of code cache will be overwritten
in the next step (described below), none of the JIT spray
mitigation mechanisms can provide effective protection against
this attack.
b) Writing to the Code Cache: The next step is to inject
shellcode to the code cache. In most cases, the code cache will
not be adjacent to other writable heap memory (due to ASLR),
and may also be surrounded by guard pages. For these reasons,
we cannot directly exploit a buffer overﬂow vulnerability to
overwrite the code cache. However, as our assumption section
suggests, besides logic errors that directly allow one to write
to anywhere in memory, several kinds of memory corruption
vulnerabilities can also provide arbitrary memory write ability.
In the following example, an integer overﬂow vulnerability is
exploited to acquire this capability.
3) An In-the-Wild Attack: We have observed one disclosed
attack [43] that leveraged the code cache to achieve reliable ar-
bitrary code execution. This attack targeted the mobile Chrome
browser. By exploiting an integer overﬂow vulnerability, the
attack ﬁrst gained reliable arbitrary memory read and write
capabilities. Using these two capabilities, the attack subse-
quently bypassed ASLR and located the permanently writable
and executable code cache. Finally, it injected shellcode into
the code cache and turned control ﬂow to the shellcode.
4) Security Implication: In practice, we have only observed
this single attack that injects code into the code cache. We
believe this is mainly due to the convenience of a popular
ROP attack pattern, which works by: i) preparing traditional
shellcode in memory; ii) exploiting vulnerabilities to launch an
ROP attack; iii) using the ROP gadgets to turn on the execution
permission of memory where the traditional shellcode resides;
and iv) jumping to the traditional shellcode to ﬁnish the
intended malicious tasks. However, once advanced control ﬂow
hijacking prevention mechanisms such as ﬁne-grained CFI are
deployed, this attack pattern will be much more difﬁcult to
launch.
The code cache injection attack can easily bypass most of
the existing exploit mitigation mechanisms. First, all control
ﬂow hijacking detection/prevention mechanisms such as CFI
and ROP detection rely on the assumption that
the code
cannot be modiﬁed. When this assumption is broken, these
mitigation mechanisms are no longer effective. Second, any
inline reference monitor based security solution is not effective
because the injected code is not monitored.
C. Exploiting Race Conditions to Bypass W⊕X Enforcement
A naive defense against the code cache injection attack is
to enforce W⊕X by manipulating page permissions (Figure 1).
More speciﬁcally, when the code cache is about to be modiﬁed
(e.g., for new code generation or runtime garbage collection),
the code generator turns on the write permission and turns off
the execution permission (t1). When the code cache is about
to be executed, the generator turns off the write permission
and turns on the execution permission (t2).
This solution prohibits the code cache to be both writable
and executable at the same time. If the target program is
single-threaded, this approach can prevent code cache injection
attacks. Since the code cache is only writable when the SDT
is executing and we assume that the SDT itself is trusted and
not vulnerable, attackers cannot hijack or interrupt the SDT to
overwrite the code cache. However, as illustrated in Figure 2, in
a more general multi-threaded programming environment, even
if the SDT is trusted, the code cache can still be overwritten
by other insecure threads when the the code cache is set to be
writable for one thread.
In this section, we use a concrete attack to demonstrate the
feasibility of such attacks, i.e., with naive W⊕X enforcement,
it is still possible to overwrite the code cache with the same
exploit primitives described above.
1) Secure Page Permissions: Since the V8 JS engine does
not have the expected page permission protection, i.e., the
naive W⊕X enforcement, we implemented this naive protec-
tion in V8 to demonstrate of our attack.
By default, when a memory region is allocated from the OS
(e.g., via mmap) for the code cache, it is allocated as executable
but not writable. We will turn on the write permission and turn
off the execution permission of the code cache for:
• New Code Installation. Usually, the JavaScript program
(e.g., a function) is ﬁrst compiled into native code, and
then copied into the code cache. To allow the copy
operation, we need to turn on the write permission of
the code cache.
5
• Code Patching. Existing code in the code cache is patched
under certain circumstances. For instance, after new code
is copied into the code cache, its address is thus deter-
mined; instructions that require address operands from
this new code fragment are resolved and patched.
• Runtime Inline Caching. Inline caching is a special patch-
ing mechanism introduced to provide better performance
for JIT-compiled programs written in dynamically typed
languages. With runtime execution proﬁle information,
the JIT compiler caches/patches the result (e.g., the result
of object property resolving) into instructions in the code
cache at runtime.
• Runtime Garbage Collection. The JavaScript engine needs
to manage the target JavaScript program’s memory via
garbage collection. This will require the code cache to
be modiﬁed for two main reasons. First, when an unused
code fragment needs to be removed; and second, when
a data object is moved to a new address by the garbage
collector, instructions referencing it have to be updated.
When these operations ﬁnish, or any code in the code cache
needs to be invoked, we turn off the write permission of the
code cache and turn on the execution permission.
To further reduce the attack surface, all of the above
policies are enforced with ﬁne-grained granularity. That is,
1) each permission change only covers memory pages that
are accessed by the write or execution operations; and 2) the
write permission is turned on only when a write operation
is performed, and is turned off immediately after the write
operation ﬁnishes. This ﬁne-grained implementation provides
maximum protection for code caches.
2) Multi-threaded Programming in SDT: To launch the
race-condition-based attack, we need two more programming
primitives. First, we need the ability to write multi-threaded
programs. Note that some SDTs such as Adobe Flash Player
also allows “multi-threaded” programming, but each “thread”
is implemented as a standalone OS process. For these SDTs,
since the code cache is only writable to the corresponding
thread, our proposed exploit technique would not work. Sec-
ond, since the attack window is generally small, we need the
ability to coordinate threads before launching the attack.
• Thread Primitives. A majority of SDTs have multi-
threaded programming support. JavaScript (JS) used to be
single-threaded and event-driven. With the new HTML5
speciﬁcation, JS also supports multi-threaded program-
ming through the WebWorker speciﬁcation [57]. There
are two types of WebWorker: dedicated worker and
shared worker. In V8, the dedicated worker is imple-
mented as a thread within the same process; a shared
worker is implemented as a thread in a separate process.
Since we want to attack one JS thread’s code cache with
another JS thread, we leverage the dedicated worker. Note
that although each worker thread has its own code cache,
it is still possible to launch the attack, because memory
access permissions are shared by all threads in the same
process.
• Synchronization Primitives. To exploit the race condition,
two attacker-controlled threads need to synchronize their
operations so that the overwrite can happen within the
exact
time window when the code cache is writable.
Since synchronization is an essential part of multi-
threaded programming, almost all SDTs support thread
synchronization. In JS, thread synchronization uses the
postMessage function.
3) A Proof-of-Concept Attack: Based on the vulnerability
disclosed in the previous real-world exploit, we built a proof-
of-concept race-condition-based attack on the Chrome browser.
Since the disclosed attack [43] already demonstrated how
ASLR can be bypassed and how arbitrary memory write
capability can be acquired, our attack focuses on how race
conditions can be exploited to bypass naive W⊕X enforce-
ment. The high level workﬂow of our attack is as follows:
i) Create a Worker. The main JS thread creates a web worker,
and thus a worker thread is created.
ii) Initialize the Worker. The worker thread initializes its
environment, making sure the code cache is created.
It
then sends a message to the main thread through
postMessage that it is ready.
iii) Locate the Worker’s Code Cache. Upon receiving the
worker’s message, the main JS thread locates the worker
thread’s code cache, e.g., by exploiting an information
disclosure vulnerability. In the Chrome V8 engine, at-
tackers can locate the code cache using the previously
disclosed exploit. Instead of following the pointers for the
current thread, attackers should go through the thread list
the JS engine maintains and follow pointers for the worker
thread. Then, the main thread informs the worker that it
is ready.
iv) Make the Code Cache Writable. Upon receiving the main
thread’s message, the worker thread begins to execute
another piece of code, forcing the SDT to update its
code cache. In V8, the worker can execute a function
that is large enough to force the SDT to create a new
MemoryChunk for the code fragment and set it to be
writable (for a short time).
v) Monitor and Overwrite the Code Cache. At the same time,
the main thread monitors the status of the code cache
and tries to overwrite it once its status is updated. In
V8, the main thread can keep polling the head of the
MemoryChunk linked list to identify the creation of a
new code fragment. Once a new code fragment is created,
the main thread can then monitor its content. Once the ﬁrst
few bytes (e.g., the function prologue) are updated, the
main thread can try to overwrite the code cache to inject
shellcode. After overwriting, the main thread informs the
worker it has ﬁnished.
vi) Execute the Shellcode. Upon receiving the main thread’s
new message, the worker calls the function whose content
has already been overwritten. In this way, the injected
shellcode is executed.
It is worth noting that the roles of the main thread and the
worker thread cannot be swapped in practice, because worker
threads do not have access to the document object model