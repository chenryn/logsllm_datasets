title:Gatling: Automatic Attack Discovery in Large-Scale Distributed Systems
author:Hyojeong Lee and
Jeff Seibert and
Charles Edwin Killian and
Cristina Nita-Rotaru
Gatling: Automatic Attack Discovery in Large-Scale Distributed Systems
Hyojeong Lee, Jeff Seibert, Charles Killian and Cristina Nita-Rotaru
Department of Computer Science
Purdue University
{hyojlee, jcseiber, ckillian, crisn}@purdue.edu
Abstract
In this paper, we propose Gatling, a framework that au-
tomatically ﬁnds performance attacks caused by insider at-
tackers in large-scale message-passing distributed systems.
In performance attacks, malicious nodes deviate from the
protocol when sending or creating messages, with the goal
of degrading system performance. We identify a represen-
tative set of basic malicious message delivery and lying ac-
tions and design a greedy search algorithm that ﬁnds effec-
tive attacks consisting of a subset of these actions. While
lying malicious actions are protocol dependent, requiring
the format and meaning of messages, Gatling captures them
without needing to modify the target system, by using a type-
aware compiler. We have implemented and used Gatling on
six systems, a virtual coordinate system, a distributed hash
table lookup service and application, two multicast systems
and one ﬁle sharing application, and found a total of 41
attacks, ranging from a few minutes to a few hours to ﬁnd
each attack.
1 Introduction
Building robust, high-performance,
large scale dis-
tributed systems is a challenging task given the complex-
ity of designing,
testing, and debugging such systems.
Programming environments [27, 33, 35, 36, 38], execution
logging and replay tools [20, 39],
test case generation
tools [13], and a variety of testbeds [4, 7, 44], emula-
tions [1, 2, 52], and simulation platforms [3, 5, 6] were cre-
ated to ease code development and testing.
Given the difﬁculty of ﬁnding bugs manually, several
techniques have been applied to ﬁnd them automatically.
Model checking using static analysis [25, 34] has been used
to verify that the design of a system is correct. Given the
model of the system, this approach proves that some invari-
ants hold for every reachable state in the system. Model
checking has limited applicability for complex designs due
to the intractable number of states that must be checked.
Checking the design is not a guarantee that the actual code
is free from bugs because models do not capture all the in-
tricacies of real implementations and additional bugs can be
introduced during implementation.
Finding bugs in distributed systems implementation has
been done with the use of symbolic execution, fault injec-
tion, and model checking. Symbolic execution [13] has
been used to generate test cases that are capable of cover-
ing many control ﬂow branches. This technique also suffers
from a state-space explosion when applied to more com-
plex implementations. Fault injection [24] has been used
to discover unknown bugs by testing fault handling code
that would not normally be tested. Fault injection is often
limited in scope because it is difﬁcult to apply to an imple-
mentation in a systematic manner. Finally, model checking
using a systematic state-space exploration [25,26,41,56,57]
has been used on system implementations to ﬁnd bugs
that violate speciﬁed invariants. To mitigate the effect of
state-space explosion, the state exploration uses an itera-
tive search, bounding some aspect of the execution. These
heuristics do not prove bug absence, but rather help pinpoint
where bugs do exist.
More recently, debugging techniques have been applied
to automatically ﬁnd attacks. Many works have been fo-
cused on ﬁnding or preventing vulnerabilities that either
cause the victim to crash or allow the attacker to gain es-
calated privileges [16, 22, 37, 43, 54]. Dynamic taint anal-
ysis [37, 43, 54] has been used to protect implementations
from well-deﬁned attacks, such as buffer overﬂow attacks.
Taint analysis is limited in that it is a detection mechanism,
not a search mechanism. Fault injection with an iterative
parameter space search [11] has also been used to ﬁnd vul-
nerabilities in distributed systems. However, this approach
requires a costly parameter optimization limiting the size of
the system it can be used to analyze.
are designed to meet
Most distributed systems
application-prescribed metrics
that ensure availability
and high-performance. However, attacks can signiﬁcantly
degrade performance, limiting the practical utility of these
systems in adversarial environments.
In particular, com-
promised participants can manipulate protocol semantics
through attacks that target the messages exchanged with
honest nodes. To date, ﬁnding attacks against performance
has been primarily a manual task due to both the difﬁculty
of expressing performance as an invariant in the system and
the state-space explosion that occurs as attackers are more
realistically modeled. The only works we are aware of
that focused on automatically ﬁnding performance attacks
are the works in [50] which considers lying in headers of
packets in two-party protocols, and [32] which assumes the
user supplies a suspect line of code, indicating that it should
not be executed many times. The method in [50] explores
all states and does not scale for a distributed system. The
method used in [32] has better scalability by combining
static with runtime testing, but focuses only on attacks that
exploit control ﬂow and where attackers know the state of
the benign nodes.
In this work we focus on how to automatically detect
performance attacks on implementations of large-scale mes-
sage passing distributed systems. We consider insider at-
tacks that have a global impact on system performance and
which are conducted through message manipulation. We
focus on these attacks given they have received limited at-
tention, they can cause signiﬁcant disruption on the system,
and they are applicable to many distributed systems. Our
goal is to provide a list of effective attacks to the user in
a timely manner, requiring the user to provide only one or
several metrics measuring system progress. Our contribu-
tions are:
• We propose Gatling, a framework that combines a
model checker and simulator environment with a fault
injector to ﬁnd performance attacks in event-based
message passing distributed systems. We identify ba-
sic malicious message delivery and message lying ac-
tions that insider attackers can use to create attacks.
We design an attack discovery algorithm that uses a
greedy search approach based on an impact score that
measures attack effectiveness. Gatling works for a
large class of distributed systems and does not require
the user to write a malicious implementation. While
Gatling does not ﬁx attacks nor prove their absence, it
provides the user with protocol-level semantic mean-
ing about the discovered attacks.
• We provide a concrete implementation of Gatling for
the Mace [27] toolkit. Mace provides a compiler and
runtime environment for building high performance,
modular distributed systems. Our changes include:
(1) adding an interposition layer between Mace ser-
vices and the networking services to implement ma-
licious message delivery actions, (2) modifying the
Mace compiler to include a message serialization code
injector to implement message lying actions, and (3)
modifying the simulator to implement our attack dis-
covery algorithm. The user provides an implementa-
tion of the distributed system in Mace and speciﬁes an
impact score in a simulation driver that allows the sys-
tem to run in the simulator.
• We demonstrate with a case study how to use Gatling
to ﬁnd attacks on a real system implementation, the
BulletPrime peer-to-peer ﬁle distribution system. Our
goal is not to criticize BulletPrime’s design, but to ex-
plore its behavior in an adversarial environment. While
some of the attacks found on BulletPrime were ex-
pected, such as delaying or dropping data messages,
others were more surprising.
Speciﬁcally, Bullet-
Prime’s reliance on services that provide improved
download times led to a number of vulnerabilities.
• We further validate Gatling by applying it to ﬁve addi-
tional systems having different application goals and
designs:
the Vivaldi [19] virtual coordinate system,
the Chord lookup service and distributed hash table
(DHT) [51], and two multicast systems: ESM [17] and
Scribe [49]. Gatling found a total of 41 performance
attacks across the systems tested, 17 attacks based on
message lying actions and 24 attacks based on mes-
sage delivery actions. Finding each attack took a few
minutes to a few hours.
Roadmap. Sections 2 and 3 describe the design and
implementation of Gatling. Section 4 provides an exam-
ple of how to use Gatling to ﬁnd attacks in a well-known
distributed ﬁle sharing system, BulletPrime [28]. Section 5
presents results on using our tool on ﬁve representative dis-
tributed systems: Vivaldi [19], Chord, DHT [51], ESM [17],
and Scribe [49]. Section 6 presents related work and Sec-
tion 7 concludes our paper.
2 Gatling Design
The design goal of Gatling is to automatically ﬁnd in-
sider attacks in distributed systems. We focus on attacks
against system performance where compromised partici-
pants running malicious implementations try to degrade the
overall performance of the system through their actions.
Such attacks require that the system has a performance met-
ric, that when evaluated gives an indication of the progress
it has in completing its goals. For example, for an overlay
multicast system throughput is an indication of the perfor-
mance of the system. Speciﬁcally, we deﬁne:
Performance attack A set of actions that deviate from the
protocol, taken by a group of malicious nodes, that re-
sults in performance that is worse than in benign sce-
narios by some ∆.
Next, we describe the system model we consider, iden-
tify malicious actions which represent building blocks for
an attack, and describe our algorithm that searches and dis-
covers attacks consisting of multiple malicious actions.
2.1 Design Overview
Model checking event-driven state machines. Many
distributed systems [27, 29–31, 36, 40, 46–48, 55] are de-
signed following event-based state machines that commu-
nicate through messages. Also several other systems use
RPCs [35, 51], continuations [33], or data ﬂow [38], which
are compatible with this approach. Thus, we focus on
distributed systems implementations that are conceptually
message passing event-driven state machines, and we will
refer to this as the message-event model.
A well-known approach to ﬁnd bugs in distributed sys-
tems is to use model checking which allows a user to ex-
plore the set of all possible behaviors. This approach, when
applied to systems implementations, results in a systematic
state-space exploration through carefully controlled execu-
tion to determine all reachable system states. The state of
a distributed system is conceptually the combination of the
state maintained at each node, in conjunction with the state
of the network connecting distributed nodes.
The message-event model provides opportunities for re-
ducing the state space. First, it avoids the complexity of
simulating networking and routing layers by abstracting the
network to be a basic service which either provides FIFO
reliable message passing (such as TCP), or best-effort mes-
sage passing (such as UDP). As a result, the network state is
given by the set of messages in-ﬂight, and the corresponding
service guarantees for each message. Second, it limits the
complexity model of concurrency by maintaining the event
queue, and systematically executing each possible event se-
quence. Events may be network events (e.g. delivery of a
message), scheduled events (e.g. expiration of a timer), or
application events (e.g. user request for an action).
Several prior model checker designs [21, 26, 41, 42] have
explored the capabilities of event-driven state machines to
ﬁnd bugs in systems implementations. Each of these de-
signs provide mechanisms to explore complex interactions
between nodes which would normally be infeasible for a
user to exhaustively explore. However, due to the expo-
nential state space explosion as the search depth increases,
these systems settle for heuristically exploring the state
space and locating correctness bugs only in an execution
with benign participants.
Our approach. Finding performance problems is very
challenging in an exhaustive approach because often these
bugs are the result of speciﬁc timings, for which ﬁnding
would require searching on the space of possible timings
of events, a far less practical approach. On the other hand,
simulating performance of a system is straightforward - as
the simulator keeps an ordered list of outstanding events, in-
cluding the time at which they are scheduled to occur. Each
time an event executes, the clock of that node advances, al-
lowing the system to conduct a time-based event driven sim-
ulation. However, it does not systematically explore all the
possible executions.
Our design, Gatling, overcomes these limitations by us-
ing a hybrid approach. Speciﬁcally, Gatling uses a time-
based simulation model to provide support for detecting
performance attacks, and integrates a search algorithm into
the time-based simulation model to ﬁnd in a practical way
such attacks. The resulting architecture is illustrated in
Fig. 1. Gatling constructs a set of nodes, with a fraction
of them ﬂagged as being malicious. Gatling maintains an
event queue sorted by event start time, and simulates the
event queue normally. However, when an event is exe-
cuting on a node selected to be malicious, Gatling uses a
model-checking exploration approach to test the set of dif-
ferent possibilities for what new events are scheduled by
the malicious node; in particular, the set of messages sent
by the malicious node. Note, Gatling does not require the
developer to provide a malicious implementation. Instead,
Gatling requires type-awareness of the messaging protocol,
and applies the basic actions described in the next section
to the outputs of a non-malicious node implementation. To
measure the impact of the malicious action, Gatling exe-
cutes an impact score function, considering only the nodes
not ﬂagged as malicious.
2.2 Malicious Actions
An insider attacker can globally inﬂuence the perfor-
mance of the system by misleading other honest participants
through exchanged messages. We classify all malicious ac-
tions on messages into two categories, message delivery ac-
tions and message lying actions. Message delivery actions
refer to how a message is sent, while message lying actions
refer to what a message contains. The list we present is not
an exhaustive list and can be easily extended by adding ad-
ditional delivery or lying strategies. Below we describe the
speciﬁc malicious actions we consider.
Message delivery actions. Performing message deliv-
ery actions does not require knowledge of the messaging
protocol, because the actions are being applied to where
and when the message is delivered, rather than modifying
the message contents. We deﬁne the following types of ma-
licious message delivery actions.
• Dropping: A malicious node drops a message instead
of sending it to its intended destination.
• Delaying: A malicious node does not immediately
send a message and injects a delay.
e
u
e
u
Q
t
n
e
v
E
Simulator 
n1 
n
2 
n3 
n4 
Messages generated and 
result of impact score 
Simulator invokes 
event handlers 
Figure 1. Gatling simulator model
• Diverting: A malicious node does not send the mes-
sage to its destination as intended by the protocol, and
instead enqueues the message for delivery to a node
other than the original destination. The destination is
randomly chosen from the set of nodes in the system.
• Duplicating: A malicious node sends a message twice
instead of sending only one copy, applying delay to
the second copy. We consider two versions of message
duplication. One is to send the duplicated message to
the original destination again, and the other is to divert
the duplicated message to another random destination
in the system.
Message lying actions. We deﬁne message lying ac-
tions as actions where malicious participants modify the
content of the message they are sending to another partici-
pant. An effective lying action involves intelligently modi-
fying ﬁelds of messages to contain contents likely to cause
different behaviors, which is more sophisticated than ran-
dom bit-ﬂipping. Gatling makes data-type-speciﬁc changes
to message contents by being dependent on the messaging
protocol. As the number of possible values that the mes-
sage ﬁeld could contain may be extremely large, we deﬁne
a few general strategies for ﬁeld types that stress the system
in different ways based on general experience on the kind
of error cases or hand-crafted attacks observed in practice
previously. We provide the following strategies for numeric
types.
type. Spanning values are important because protocols
sometimes use only a subset of legal values, apply san-
ity checks to inputs, or fail to apply sanity checks when
necessary to avoid e.g. overﬂow/underﬂow. Spanning
values can be chosen assisted by static analysis or de-
veloper insight; we ﬁnd that a range of values orders of
magnitude apart are sufﬁcient to ﬁnd attacks in many
systems.
• Random: A malicious node can select a random value
from the range of the type.
In addition to the above choices, boolean values have an
additional option: toggling the value between true and false.
The list can be easily extended, for example using a “com-
plement” strategy for integral values (a generalization of the
boolean ﬂipping).
Node identiﬁers, such as an IPv4 address or a hash key,
are integral aspects of distributed systems. Thus, we treat
them as a native type and allow lying on them as well. Ma-
licious nodes can lie about node identiﬁers, where lying val-
ues are selected randomly from the identiﬁers of all nodes,
malicious nodes, or benign nodes.
We also have special handling for non-numeric types.
For simplicity, collections (e.g.
list, set, map, etc.) are
treated as applying one of the above strategies to all of the
elements within the collection. Users can further extend
Gatling as needed to provide lying strategies for additional
types, as we have done for node identiﬁers.
• Min or Max: A malicious node can change the value
to be the minimum or maximum value for the type.
2.3 Discovering Attacks
• Zero: For signed types, a malicious node can addition-
ally change the value of the ﬁeld to be the number 0.
• Scaling: A malicious node could increase or decrease
the numeric value by a percentage.
• Spanning: A malicious node can select speciﬁc val-
ues from a set which spans the range of the data
A naive approach to discovering attacks is executing all
possible sequences of actions (malicious and benign) in the
system and then ﬁnding the sequences that cause perfor-
mance to degrade below the benign case scenario. However,
this approach becomes intractable because of the size of the
search space considering the number of possible sequences
of actions. Speciﬁcally, at every time step, any benign event
could execute based on timings, but additionally, any mali-
cious node could generate any message deﬁned by the sys-
tem, performing any combination of malicious actions on
it and send it to any node. Considering all possible attack
values for a message containing a single 32-bit integer en-
tails an exploration branching at the impractical rate of at
least 232. Benign state-space exploration is shielded from
this problem by the fact that while the message ﬁeld could
theoretically contain any of the 232 values, at any point in
time only a small subset of those values would be sent by a
non-malicious node.
Attack properties. As a ﬁrst step toward practical au-
tomated search of attacks, we focus on a class of perfor-
mance attacks that have several properties that reduce the
state space exploration needed to discover them:
1) Single-behavior: We deﬁne a single-behavior attack
as a list which describes, for each type of message, what
malicious or benign action all malicious nodes will take
whenever sending a message of that type. Intuitively, this
attack deﬁnition is based on the principle that in some cases,
past success is an indication of future success. Thus, ev-