from generator is a synthetic or true data sample. Recently, GAN
gains a huge success in synthesizing meaningful images.
2 PROPOSED METHOD
In this section, we present a series of differentially private synthetic
data generation algorithms for tabular data and graphs1.
2.1 Basic Idea
Here, we still follow the similar strategy in [3, 6], learning the
input distribution for private data release. However, since training an
optimal BN is NP-Hard, one explicitly removes correlation among
attributes for efficiency [6]. We make an observation that a well-
trained machine learning (ML) model also aims to approximate the
input distribution without removal of explicit structures. Thus, we
deal with the challenge (C1) by learning the input distribution with
ML model. Note that we particularly consider deep learning (DL)
family, because DL can easily gain speedup with the GPUs whereas
whether BN and JT algorithms can be parallelized remain unclear.
On the other hand, in fact, if the input data are well-represented,
DL is able to learn the input distribution, irrespective of the form of
input data. Hence, one can develop a differential private DL model
to approximate the input distribution, from which one generates and
publishes the synthetic data, resolving the challenge (C2).
2.2 DP-DNN for Tabular Data
We first present a differential private data release scheme, DP-DNN,
by taking advantage of DNN, as a strawman solution. The idea be-
hind our design is the observation that a well-trained DNN inherently
models the original dataset D ∈ Rn×m. Thus, a DNN model trained
from D can be used by the sampling procedure for data synthesis.
However, we need to deal with two obstacles when implementing
the above idea. First, recent research results show that DNN model
itself may expose the privacy of training data. Thus, we instead train
a DNN in a differentially private manner. In particular, by using
the recent moment accountant approach in manipulating the privacy
parameters ϵ and δ in differential privacy [1], we construct a DNN
with fully connected layers via differentially private SGD. In essence,
due to the use of differentially private SGD, DP-DNN reveals no
individual information in D. Second, DNN is supposed to take as
input the labelled dataset but D might be unlabelled (i.e., no clear
distinction between quasi-identifiers and sensitive attributes). Here,
we propose to randomly pick an attribute as a label for records in D,
turning an unlabelled dataset to labelled one. In essence, this design
choice does not change the structure of D; only the way for DP-DNN
to perceive the data is changed.
random sample a ∈ R1×(m−1). Data owner sets D′ = D′∪{[a DP-DNN(a)] ∈
After DP-DNN construction, data owner generates a uniformly
(a) classification accuracy.
(b) Bhattacharyya distance.
Figure 1: DP-DNN results with varying ϵ’s and δ’s.
2.3 DP-GAN for Tabular Data
With the observation that GAN can approximate the input distribu-
tion, we construct a differentially private GAN, DP-GAN, for private
data synthesis. More specifically, we train a DP-GAN, perform ran-
dom sampling from DP-GAN, and release the dataset composed of
random samples. The only obstacle is how to make GAN differen-
tially private. We make an observation that though GAN consists
of two parts, generator and discriminator, only the latter has the
access to D, when learning the input distribution. Therefore, since
the discriminator of GAN in our consideration is a DNN, we con-
struct DP-GAN by simply using DP-DNN in Sec. 2.2 in place of the
ordinary DNN.
We note that at the time of writing, we also found that Beaulieu-
Jones et al. [2] also propose similar idea on differentially private
data synthesis. However, they craft a DP-GAN based on AC-GAN,
a variant of GAN, while our design of DP-GAN is based on the
DC-GAN (ordinary GAN) with DNN as discriminator. Moreover,
our further discussion on the novel use of DP-GAN (see Sec. 2.4
and Sec. 2.5 is also not included in [2].
1The source code of all
https://goo.gl/94qyQz.
the proposed algorithms can be downloaded from
2Wine Data Set: https://archive.ics.uci.edu/ml/datasets/wine
10-210-1100101privacy budget 2030405060708090100classification accuracyδ=10-5δ=10-210-210-1100101privacy budget 2.72.752.82.852.92.953Bhattacharyya distanceδ=10-5δ=10-2PosterCCS’17, October 30-November 3, 2017, Dallas, TX, USA2548(a) Original Dataset.
(b) DP-DNN.
(c) DP-GAN.
(d) DP-GAN-DNN.
Figure 2: Correlation matrices from different solutions.
The experiment results are shown in Figures 2c and 3. One can
easily see that, compared to DP-DNN, though more correlations
among attributes in D are preserved in DP-GAN, both classification
accuracy and Bhattacharyya distance are even worse, rendering the
impracticality of such a design of DP-GAN.
(a) classification accuracy.
(b) Bhattacharyya distance.
Figure 3: DP-GAN results with varying ϵ’s and δ’s.
2.4 DP-GAN-DNN for Tabular Data
The failure of DP-DNN in preserving the correlation structure in
D stems from the independently random sampling. In essence, if
random samples to be sent to DP-DNN naturally satisfy the input
distribution, D′ generated from DP-DNN could better preserve the
correlation structure in D. Thus, a straightforward idea is to combine
the use of DP-DNN and DP-GAN such that random samples to be
sent to DP-DNN are first generated by DP-GAN. All the remaining
procedure are exactly the same as those in Sec. 2.2.
The experiment results are shown in Figures 2d and 4, where
the classification accuracy reaches the acceptable level and Bhat-
tacharyya distance is also reduced, compared to DP-GAN. One
can also see from Figures 2a and 2d that more correlations among
attributes in D are now preserved.
2.5 DP-GAN for Graph
We also consider publishing node degree distribution of a given
grpah in the sense of node-DP [4, 5], instead of the tabular data.
The similar approach is conducted; data owner learns the input
distribution, and publishes the synthetic node degree distribution.
Nonetheless, the obstacle is that, in contrast to the tabular data case
(a) classification accuracy.
(b) Bhattacharyya distance.
Figure 4: DP-GAN-DNN results with varying ϵ’s and δ’s.
where one see each record as a sample from an inherent data distri-
bution, now we have a single instance of graph and therefore cannot
train a DP-GAN. To solve this issue, we first generate graph isomor-
phisms of the original graph G. Then, we vectorize the adjacency
matrix of each graph isomorphism as a row vector (record). All the
vectorized adjacency matrices can be stacked together and regarded
as a tabular data, each record from which is sampled from an inher-
ent edge distribution. All the remaining procedures are the same as
ones in Sec. 2.3.
The dataset for all the experiment results in Sec. 5 is Zachary’s
Karate Club3, and each result in Figure 5 is the average of ten inde-
pendent experiments. L1 Error measures the dissimilarity between
the released and true node degree distribution. |E′|/|E| is a ratio of
the number |E′| of edges in the synthetic graph G′ and the number
|E| of edges in G. The experiment results in Figure 5 show that DP-
GAN achieves less information loss than the state-of-the-art solution
[4].
(a) L1 error.
(b) |E′|/|E |.
Figure 5: DP-GAN for Graph.
3 CONCLUSION
The GAN-based framework of differentially private data release
shows a great potential in preserving the data utility and unifying
the DP approaches for different types of data.
REFERENCES
[1] M. Abadi, A. Chu, I. Goodfellow, H. B. McMahan, I. Mironov, K. Talwar, and L. Zhang. Deep
learning with differential privacy. ACM CCS, 2016.
[2] B. K. Beaulieu-Jones, Z. Wu, C. Williams, and C. S. Greene. Privacy-preserving generative
deep neural networks support clinical data sharing. bioRxiv, July 5, 2017.
[3] R. Chen, Q. Xiao, Y. Zheng, and J. Xu. Differentially private high-dimensional data publication
via sampling-based inference. ACM KDD, 2015.
[4] W.-Y. Day, N. Li, and M. Lyu. Publishing graph degree distribution with node differential
privacy. ACM SIGMOD, 2016.
[5] S. Raskhodnikova and A. Smith. Lipschitz extensions for node-private graph statistics and the
generalized exponential mechanism. IEEE FOCS, 2016.
[6] J. Zhang, G. Cormode, C. M. Procopiuc, D. Srivastava, and X. Xiao. Privbayes: private data
release via bayesian networks. ACM SIGMOD, 2014.
3 https://networkdata.ics.uci.edu/data.php?id=105
10-210-1100101privacy budget 1820222426283032343638classification accuracyδ=10-5δ=10-210-210-1100101privacy budget 66.577.588.59Bhattacharyya distanceδ=10-5δ=10-210-210-1100101privacy budget 30405060708090classification accuracyδ=10-5δ=10-210-210-1100101privacy budget 55.15.25.35.45.55.65.75.8Bhattacharyya distanceδ=10-5δ=10-210-210-1100101privacy budget 202530354045L1 Errorδ=10-5δ=10-2[3]10-210-1100101privacy budget 0.60.811.21.41.61.822.2|E'|/|E|δ=10-5δ=10-2[3]PosterCCS’17, October 30-November 3, 2017, Dallas, TX, USA2549