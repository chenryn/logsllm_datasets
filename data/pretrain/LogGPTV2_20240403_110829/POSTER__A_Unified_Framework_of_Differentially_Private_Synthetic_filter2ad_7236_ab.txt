# 1. Introduction
Generative Adversarial Networks (GANs) have recently achieved significant success in synthesizing meaningful images, whether the data is synthetic or real. This paper introduces a series of differentially private synthetic data generation algorithms for both tabular data and graphs.

# 2. Proposed Method

## 2.1 Basic Idea
Our approach follows a similar strategy to [3, 6], which involves learning the input distribution for private data release. However, training an optimal Bayesian Network (BN) is NP-Hard, so previous methods explicitly remove correlations among attributes for efficiency [6]. We observe that a well-trained machine learning (ML) model, particularly deep learning (DL) models, can approximate the input distribution without removing explicit structures. DL models are advantageous because they can be easily parallelized on GPUs, whereas the parallelization of BN and junction tree (JT) algorithms remains unclear. Therefore, we address the challenge of learning the input distribution by using DL models. A differentially private DL model can then generate and publish synthetic data, thereby addressing the privacy concerns.

## 2.2 DP-DNN for Tabular Data
We propose a differentially private data release scheme, DP-DNN, which leverages Deep Neural Networks (DNNs). A well-trained DNN inherently models the original dataset \( D \in \mathbb{R}^{n \times m} \), making it suitable for data synthesis. However, there are two main challenges:
1. **Privacy Concerns**: Recent research has shown that DNNs can expose the privacy of the training data. To mitigate this, we train the DNN using differentially private Stochastic Gradient Descent (SGD) with the moment accountant approach [1]. This ensures that the DNN does not reveal individual information from \( D \).
2. **Unlabeled Data**: DNNs typically require labeled datasets, but \( D \) might be unlabeled. To address this, we randomly select an attribute as a label for the records in \( D \), effectively turning the unlabeled dataset into a labeled one. This change does not alter the structure of \( D \); it only changes how the DP-DNN perceives the data.

After constructing the DP-DNN, the data owner generates a uniformly random sample \( a \in \mathbb{R}^{1 \times (m-1)} \) and sets \( D' = D' \cup \{[a, \text{DP-DNN}(a)]\} \).

## 2.3 DP-GAN for Tabular Data
Given that GANs can approximate the input distribution, we construct a differentially private GAN (DP-GAN) for private data synthesis. The key challenge is to make the GAN differentially private. Since the discriminator of the GAN has access to \( D \) during training, we use the DP-DNN from Section 2.2 as the discriminator. This ensures that the entire GAN is differentially private.

We note that Beaulieu-Jones et al. [2] also proposed a similar idea, but their design is based on AC-GAN, while ours is based on the standard DCGAN with a DNN as the discriminator. Additionally, our further discussion on the novel use of DP-GAN (Sections 2.4 and 2.5) is not covered in [2].

## 2.4 DP-GAN-DNN for Tabular Data
The failure of DP-DNN in preserving the correlation structure in \( D \) is due to independently random sampling. If the random samples sent to the DP-DNN naturally satisfy the input distribution, the generated \( D' \) could better preserve the correlation structure. Therefore, we combine the use of DP-DNN and DP-GAN, where the random samples are first generated by DP-GAN before being sent to DP-DNN.

Experimental results show that this combination improves classification accuracy and reduces Bhattacharyya distance compared to DP-GAN alone, and more correlations among attributes in \( D \) are preserved.

## 2.5 DP-GAN for Graphs
For graph data, we aim to publish the node degree distribution under node differential privacy (node-DP) [4, 5]. The challenge is that, unlike tabular data, we have a single instance of a graph and cannot directly train a DP-GAN. To overcome this, we first generate graph isomorphisms of the original graph \( G \). Each isomorphism's adjacency matrix is vectorized into a row vector, and all these vectors are stacked to form a tabular dataset. The remaining procedures follow those in Section 2.3.

The dataset used for experiments is Zacharyâ€™s Karate Club [3], and each result in Figure 5 is the average of ten independent experiments. The L1 error measures the dissimilarity between the released and true node degree distributions, and \( |E'|/|E| \) is the ratio of the number of edges in the synthetic graph \( G' \) to the number of edges in \( G \). Our results show that DP-GAN achieves less information loss than the state-of-the-art solution [4].

# 3. Conclusion
The GAN-based framework for differentially private data release shows great potential in preserving data utility and unifying differential privacy approaches for various types of data.

# References
[1] M. Abadi, A. Chu, I. Goodfellow, H. B. McMahan, I. Mironov, K. Talwar, and L. Zhang. Deep learning with differential privacy. ACM CCS, 2016.
[2] B. K. Beaulieu-Jones, Z. Wu, C. Williams, and C. S. Greene. Privacy-preserving generative deep neural networks support clinical data sharing. bioRxiv, July 5, 2017.
[3] R. Chen, Q. Xiao, Y. Zheng, and J. Xu. Differentially private high-dimensional data publication via sampling-based inference. ACM KDD, 2015.
[4] W.-Y. Day, N. Li, and M. Lyu. Publishing graph degree distribution with node differential privacy. ACM SIGMOD, 2016.
[5] S. Raskhodnikova and A. Smith. Lipschitz extensions for node-private graph statistics and the generalized exponential mechanism. IEEE FOCS, 2016.
[6] J. Zhang, G. Cormode, C. M. Procopiuc, D. Srivastava, and X. Xiao. Privbayes: private data release via bayesian networks. ACM SIGMOD, 2014.