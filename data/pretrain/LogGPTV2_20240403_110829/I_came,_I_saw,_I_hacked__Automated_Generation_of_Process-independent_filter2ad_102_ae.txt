(Codesys). Moreover, it is possible to extract and manipulate the
PID variable values from the binary of the control code [21]. Thus,
changing the Proportional (ğ¾ğ‘ƒ), Integral (ğ¾ğ¼ ) and Derivative (ğ¾ğ·)
coefficients, becomes a natural choice to inject stealthy payload.
The transfer function, a ratio between output and input signals
in the frequency domain, reflects the characteristics of the pro-
cess. Let ğºğ‘(ğ‘ ) and ğºğ‘(ğ‘ ) denote the controller and plant transfer
desired specification (reference or set-point ğ‘…(ğ‘ )) with allowable
deviation or Error (ğ¸(ğ‘ )). From the definition of transfer function,
the output ğ‘‚(ğ‘ ) = ğºğ‘(ğ‘ )ğºğ‘(ğ‘ )ğ¸(ğ‘ ). A typical control system and
expression ğ¸(ğ‘ ) = ğ‘…(ğ‘ ) âˆ’ ğ‘‚(ğ‘ ), for any reference input and unity
functions respectively, which define the characteristics of each of
these modules. Any feedback loop in a control system tracks the
the observability of an attacker is summarized in Fig. 5. The error
feedback is given by [16]:
ğ¸(ğ‘ ) =
ğ‘…(ğ‘ )
1 + ğºğ‘(ğ‘ )ğºğ‘(ğ‘ )
(1)
ğ¸(ğ‘ ) =
ğ‘˜/ğ‘ 
1 + ğºğ‘(ğ‘ )ğºğ‘(ğ‘ )
quantity), then Eq. 1 becomes:
A stable perturbation is analogous to a control error. Therefore, a
Since Laplace transform of a constant-valued function like ğ‘Ÿ(ğ‘¡) = ğ‘˜
is ğ‘˜/ğ‘ , if the set-point is a constant (for example: constant pres-
sure, constant temperature etc. where ğ‘Ÿ(ğ‘¡) is a constant physical
stable perturbation ğ‘’(ğ‘¡) is an error measured in steady-state (when
this is equivalent to measuring ğ‘ ğ¸(ğ‘ ) as ğ‘  â†’ 0. Thus, the stable
1+ğºğ‘(ğ‘ )ğºğ‘(ğ‘ ). An attacker with direct access
to PLC source code, can change ğ‘…(ğ‘ ) or ğ‘˜ directly. For an attacker
with access to PLC binary, can only ğºğ‘(ğ‘ ) coefficients using ICSREF.
(ğºğ‘(ğ‘ )) becomes [16]:
ğºğ‘(ğ‘ ) = ğ¾ğ‘ƒ + ğ¾ğ·ğ‘  + ğ¾ğ¼/ğ‘ 
(3)
Thus, from Eq. 2 and 3 and expression for ğ¸ğ‘†ğ‘ƒ, we have two impor-
tant inferences in terms of designing our attack strategy:
ğ‘¡ â†’ âˆ). From the Final Value Theorem (FVT) of Laplace transform,
At frequency ğ‘ , the transfer function of a generic PID controller
perturbation is ğ¸ğ‘†ğ‘ƒ =
ğ‘˜
(2)
ğ¸ğ‘†ğ‘ƒ = 0 âˆ€ğ¾ğ¼ â‰  0
ğ¸ğ‘†ğ‘ƒ âˆ 1
ğ¾ğ‘ƒ
We apply these control-theoretic rules to build our attack strategy
as summarized in Table 9. First, the payload switches off the in-
tegral controller (ğ¾ğ¼ = 0). Then, it slowly decreases the value of
proportional gain coefficient (ğ¾ğ‘ƒ), while getting feedback on attack
impact. Please note, in our attack strategy, we avoid manipulation
of ğ¾ğ· because it makes the system unstable [16].
5.2 Oscillatory perturbation attack
A special case of perturbation-based attacks are when the perturba-
tions change very rapidly but, not beyond operational limits. These
kind of attacks are very much dependent on the type of the plant
(by extension ğºğ‘(ğ‘ )) and may not be applicable to all the control
loops in the plant. To achieve oscillatory perturbation, we use the
empirical tuning philosophy of a common PID tuning technique
called Ziegler-Nichols (ZN) PID tuning [5]. This technique is useful
to empirically find the values of ğ¾ğ‘ƒ, ğ¾ğ· and ğ¾ğ¼ for plants with
simple transfer functions such that the controller meets the design
criteria of output response. The method followed is that first the
derivative controller and integral controller are switched off. Then,
it is required to find the ideal sign of ğ¾ğ‘ƒ, i.e. if a positive change
in reference value reflects as a positive or negative change in the
output response. We follow this method to find the ideal sign, how-
ever, we also experiment with the negative sign of ğ¾ğ‘ƒ because with
negative proportional gain, positive feedback increases oscillations
in the system [16], which is the goal of the attack. Then, like in
ZN method of PID tuning, we increase the ğ¾ğ‘ƒ value to the point of
sustained oscillations. The value of ğ¾ğ‘ƒ changes the frequency and
amplitude of oscillations and it can be experimentally evaluated to
find the value for a particular frequency and amplitude.
5.3 Physically configurable attack-trigger time
These are attacks which get triggered at a configurable time solely
based on values manipulated in the control code (by only changing
ğ¾ğ‘ƒ, ğ¾ğ¼ and ğ¾ğ· coefficients). They do not need any extra trigger
logic; our attack model just changes values of existing variables
of controller code to prevent getting detected by code injection
This is the accepted version of the article shared by the authors. The final published version will be available at AsiaCCS 2020 Proceedings.
Attack type Attack
on
Set-
point
Stable
Perturbation
ğ¾ğ‘ƒ
Â±ğ¾ğ‘ƒ
ğ¾ğ‘ƒ
Oscillatory
Perturbation
Physically
configurable
trigger time
Attack design strategy
New Set-point = Actual
- Target perturbation
ğ¾ğ¼ = 0;
Stable perturbation âˆ 1
ğ¾ğ‘ƒ
ğ¾ğ¼ = 0; Increase Â±ğ¾ğ‘ƒ for
sustained oscillations
Trigger time âˆ 1
ğ¾ğ‘ƒ
Enabler
PLC
source
code
ICSREF
ICSREF
ICSREF
Table 9: Summary of payload characteristics.
1
1
ğ¾ğ‘ƒ ğ´
1+1/ğ¾ğ‘ƒ ğºğ‘(ğ‘ ). Since, we aim to change
(1/ğ‘)ğ‘ +1 is ğ‘’âˆ’ğ‘ğ‘¡, where 1/ğ‘ is the time constant. Now,
1/ğ‘
defense mechanisms. Although both integral and proportional con-
troller gains effect time response, the adversary can only manipulate
the proportional controller to perform the attack since both our
attack strategies have ğ¾ğ¼ = 0. Thus, in this case the closed-loop
transfer function becomes
the response characteristics of the system, we need to manipulate
the time constants of the system. Before we calculate the time con-
stant of the system, it is important to note that inverse Laplace
transform of
for simplicity, let us consider a first-order control system i.e. power
of ğ‘  in denominator of the transfer function is 1, then the plant
transfer function is of the form ğ´
ğ‘ +ğ‘ and the closed-loop transfer
ğ‘ +ğ¾ğ‘ƒ ğ´+ğ‘ . For such a transfer function, the closed-loop
function is
time constant is
ğ¾ğ‘ƒ ğ´+ğ‘ . For higher-order systems, similar analysis
shows that the time constant is inversely proportional to ğ¾ğ‘ƒ. Thus,
a higher value of ğ¾ğ‘ƒ will lead to lower value of time-constant which,
in turn, leads to faster time-response.
5.4 Selection of attack
Completing the automated attack generation, in this subsection we
provide recommendations on the choice of attack for the common
ICS processes (from literature) along with the ones found in the
constructed dataset of the PLC binaries. We state the following
simple rules based on the characteristics of the attack to maximize
its impact while adhering to the operational thresholds:
â€¢ Choosing Stable perturbation attack: Since this attack cre-
ates a simple deviation, any attack vector generated will drive the
plant to a sub-optimal state. But the adversary must be careful
not to force the deviation towards â€˜explosionâ€™ (high speed, high
pressure, high temperature, etc.). However, since processes are
designed for maximum functional profit, reducing them would in-
cur financial losses. Thus, for pressure, temperature, speed, timer,
flow-rate control loops, our general recommendation is to make
the process less efficient/slower by selecting stable perturbations.
â€¢ Choosing Oscillatory perturbation attack: This attack lever-
ages the un-modeled characteristics (e.g., oscillations of a product
against the walls of the container/pipes causing quality degrada-
tion) and has potential for physical damage (e.g., Stuxnet). Since
this attack involves complex parametric oscillations, attack vec-
tors for smaller amplitude should be generated. Prime process
targets are production, level, and valve control loops.
In our end-to-end case study, the payload chooses an attack based
on the above recommendations. This can also be completely con-
figurable based on the attackerâ€™s motivation.
6 CASE STUDY: TENNESSEE EASTMAN
In this section, we give an overview of the attack and present an end-
to-end case study on a Hardware-In-The-Loop (HITL) testbed of a
chemical plant. Tennessee-Eastman (TE), is a non-linear chemical
process which takes in five input products(ğ´, ğµ, ğ¶, ğ·, ğ¸), performs
exothermic reactions, and produces two main products(ğº, ğ») and
one by-product(ğ¹). The process reactions depend on temperature,
pressure, and quality (molar concentrations) conditions. These re-
actions are performed by five major physical components: Reactor,
Condenser, Stripper, Separator, and Compressor. Each of these com-
ponents imposes safety conditions over possibly explosive physical
quantities (like pressure, compressor speed, temperature, etc.) and
together drive the plant towards a profitable state. [10] is a lin-
earized MATLAB simulation of TE which contains 18 PID loops. It
embeds process disturbances which give sufficient complexity in
emulation of real-world plants. It also embeds alarms relating to
unsafe conditions which the designed attacks aim to avoid. In the
real-world scenario, we consider that different PLCs will execute
different PID loops. Therefore, in our HITL TE testbed, we migrate
two such PID loops to a PLC. The PLC runs two cascading PI loops
that take in the values from two sensors and control the reactor
pressure and purge rate. The hardware used is shown in Fig. 6. The
testbed uses a Wago 750-881 PLC which has a 32-bit ARM CPU that
runs on a Nucleus RTOS, and a 32KB non-volatile memory. The
PLC was programmed in Structured Text. To communicate with
the simulation model hosted on the PC, the testbed deploys a Serial-
Interface Board (SIB) that is equipped with analog-to-digital (A/D)
and digital-to-analog (D/A) converters. Following the guidelines
presented in Section 5, the payload operates as:
ICS Sector fingerprinting: Congruent to our threat model, we
assume that in the real world, the adversary would be able to infect
the general-purpose computer which hosts the HMI (like the one
shown in our setup in Fig. 6). We perform the ICS sector fingerprint-
ing by taking a screenshot of the TE HMI and running it through
our parallel classification model. Our 49.1 KB HMI-based finger-
printing script refers to the weights for image-based classification,
extracts text-strings for text-based classification, and finally utilizes
the parallel architecture to classify an image in 3.09 seconds with
â‰ˆ 98% class prediction probability as Chemical Sector.
ICS Process fingerprinting and intelligence extraction: From
the HMI, our code traverses the ICS network to identify PLCs con-
trolled by the HMI. Through an FTP connection, the code extracts
the control binary from the PLC. Our payload extracts the FBs and
strings from the binary, classifying the binary as a Pressure Control
process. This classification reflects the actual functionality of our
TE testbed. ICSREF, which is 383.1 kB in size and included in our
payload, identifies the presence of a PID function block and extracts
its values. This process takes 30.57 seconds.
Attack: Post plant reconnaissance, the payload designs attack val-
ues for pressure control (identified variable). From the process-
aware attack point of view, pressure is a good candidate for attack
evaluation because it controls the chemical reactions and also may
This is the accepted version of the article shared by the authors. The final published version will be available at AsiaCCS 2020 Proceedings.
caused here attest to our philosophy of attack design; we phys-
ically stay within the operational limits but cause damages that
accumulate over time. We investigated many loops in TE testbed to
find suitable attack vectors (including oscillatory perturbation and
physically configurable trigger time) for different alarm thresholds
and reported our findings in Appendix.
7 POSSIBLE DEFENSES
Defense against fingerprinting from HMI screenshots: There
have been many advances in adversarial machine learning, where
undetectable addition of noise to images can change the prediction
of an input; These attacks have been demonstrated on facial recog-
nition [39] and text classification using OCR [41]. Recent work on
reverting malicious classifications by addition of noise and using
majority voting of the fuzzed copies may also be used to confuse
fingerprinting mechanisms [38].
Defense against fingerprinting from PLC binaries: Fingerprint-
ing using control binaries depends on the attacker ability to extract
PLC binary. A practical method to prevent binary extraction is
to disable FTP connections, but the control binary cannot be up-
loaded remotely anymore. A more realistic solution is to enforce
a password-protected FTP connection without default passwords.
Semantically, assuming the attacker can have access to the binary,
the binary functional blocks and strings can be poisoned by adding
random code and text. Adding random code and text is relatively
straightforward. We advise against removing descriptive binary
strings as important messages in stressful situations can be helpful.
Process-aware defenses: Focusing on defenses applicable to our
attacks, one of the most efficient ways to detect malicious manipu-
lations in sensor measurements is by modeling it [27]. Two models
that have been used as benchmarks are Auto-regressive (AR) model
[18] and Linear Dynamic State-Space (LDS) model [40]. AR over-
simplifies ICS processes, sometimes making it difficult to model the
sensor readings, and LDS requires extensive ICS domain knowledge
to precisely predict a measurement.PASAD [3], a recent work from
CCS â€™18, outperforms the other defense mechanisms by detecting
even the most subtle deviations by leveraging the departure of ICS
dynamics from baseline. However, stealthy adversarial examples on
sensor measurements [13] has opened the path to control-theory
based attacks leveraging Deep-Learning frameworks to fool state-
of-the-art defense mechanisms like PASAD.
8 CONCLUSION
In this work, we consider a constrained threat model where the
adversary has no prior knowledge of the target ICS environment.
We present a methodology for single-point infiltration through an
HMI. For successful identification of the plant, we constructed a
dataset using publicly available ICS HMI images and PLC binaries.
We then trained several machine learning models to select our final
classifier that identifies ICS sector and process. We also use the HMI
screenshots and the binaries to extract data to build intelligence
for attack design. We leverage control theory to devise generic
perturbation-based attacks in ICS. Our results show that, depending
on the sector/process/visibility, an adversary can carry-out an end-
to-end attack with high accuracy, even with no prior knowledge.
This calls for exhaustive security assessment of ICS and the design
of robust defense mechanisms that would reduce the attack surface.
Figure 6: Experimental setup to demonstrate ICS finger-
printing and intelligence collection based on HMI screen-
shots and PLC binaries. The setup is a Hardware-in-the-loop
testbed for Tennessee Eastman Chemical process.
Figure 7: Stable perturbation attack on pressure control.
cause explosions if not controlled within safe limits [22]. We assume
that the inherent alarm thresholds of the MATLAB model as the
baseline for operational limits of our testbed. For pressure control
loop, 3000 kPa is defined as the fail-safe condition. Compromising
the pressure PLC, we were able to gain all the intelligence regarding
operational limits and set-points.
According to the recommendations of subsection 5.4, our au-
tomated payload selected a stable perturbation attack setting the
lower operational limit to 10% of the original set-point. Under such
constraints, the attack could cause a maximum decrease of 280 kPa
in pressure from 2800 kPa to 2520 kPa. Fig. 7 describes the results
of the experiment. Four successful attack vectors could be gener-
ated from principles described in section 5 changing the pressure
between 2625 kPa and 2750 kPa. This can result in financial degra-
dation, and it can be seen in the increase in operational cost from
$89,000 per month to $103,000 per month. The financial damages
This is the accepted version of the article shared by the authors. The final published version will be available at AsiaCCS 2020 Proceedings.
ACKNOWLEDGEMENTS
This project was supported by the U.S. Office of Naval Research
under Award N00014-15-1-2182, the NYU Abu Dhabi Global PhD
Fellowship program, and NYU Abu Dhabi Center for Cyber Security.
RESOURCES
The constructed datasets, and the baseline ML models trained for
ICS sector and process fingerprinting are available at https://github.
com/momalab/ICS_research_resources.
REFERENCES
[1] S. Amin, X. Litrico, S. Sastry, and A. M. Bayen. 2013. Cyber Security of Water
SCADA Systemsâ€”Part I: Analysis and Experimentation of Stealthy Deception
Attacks. IEEE Transactions on Control Systems Technology 21, 5 (2013), 1963â€“1970.
[2] S. Amin, X. Litrico, S. S. Sastry, and A. M. Bayen. 2013. Cyber Security of
Water SCADA Systemsâ€”Part II: Attack Detection Using Enhanced Hydrodynamic
Models. IEEE Transactions on Control Systems Technology 21, 5 (2013), 1679â€“1693.
[3] W. Aoudi, M. Iturbe, and M. Almgren. 2018. Truth Will Out: Departure-Based
Process-Level Detection of Stealthy Attacks on Control Systems. In Proceedings
of the 2018 ACM CCS (CCS â€™18). 817â€“831.
[4] W. Ashford. 2018. Social engineering at the heart of critical infrastructure at-
tack. https://www.computerweekly.com/news/252454369/Social-engineering-at-
the-heart-of-critical-infrastructure-attack. [Online].
[5] K.J. Astrom and R. M. Murray. 2008. PID Tuning, Feedback Systems: An Introduction
for Scientists and Engineers. Princeton University Press, Princeton, NJ, USA.
[6] J. Berr. 2017.
WannaCry ransomware attack losses could reach $4
https://www.cbsnews.com/news/wannacry-ransomware-attacks-
billion.
wannacry-virus-losses/. [Online].
[7] E. Byres. 2012.
#1 ICS and SCADA Security Myth: Protection by Air
https://www.tofinosecurity.com/blog/1-ics-and-scada-security-myth-
Gap.
protection-air-gap.
[8] A. A. CÃ¡rdenas, S. Amin, Z. Lin, Y. Huang, C. Huang, and S. S. Sastry. 2011.
Attacks against process control systems: risk assessment, detection, and response.
In AsiaCCS.