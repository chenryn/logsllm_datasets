it takes to recognize the policy. Additional false positives
occur outside of this region and additional false negatives
occur within this region; neither include the start or ﬁnish
lag. Figure 6 shows each value visually. These values rely, of
course, on speciﬁc characteristics of a trace; we attempted to
construct realistic evaluation scenarios to get a conceptual
idea of how well these policies work in practice.
We ran our traces with an outward-facing Kinect attached
to a Lenovo W520 laptop (Core i7, 16 GB RAM, 160 GB
SSD). This setup let us log traces without aﬀecting events
rates, relying on a large memory to buﬀer all events un-
til trace completion. Without logging, we achieved similar
event rates on a less powerful Samsung tablet (Core i5, 2
GB RAM). We expect that continuous sensing devices will
approach the capabilities of these more powerful machines.
6.2.2 Evaluation Results
We describe lessons learned from our experience, sup-
ported by policy-speciﬁc evaluations (Figures 8–9).
Adding policy memory reduces jitter. We ﬁnd that
certain policy technologies show high variability in detec-
tion. For example, QR codes are detected only about every
third RGB frame when present, WiFi signals are unreliable
at a building’s perimeter (presumably far from an access
point), and audio frequency is sensitive to other ambient
audio (e.g., running water in the bathroom).
We ﬁnd that we can minimize this detection jitter by
adding memory to the policy. For example, in the origi-
nal QR code policy, we consult the most recent QR code
event for each RGB event to determine if the policy should
be applied. In the “QR code with memory” policy, we look
farther into the past, consulting up to ﬁve recent QR code
events and applying the most recent policy it ﬁnds (if any).
Microsoft Research Tech Report MSR-TR-2014-67
Trace Name Policy Trigger
Intended Policy for Targeted Event Type
LOC Total Events
Length
Bathroom
Bathroom
Bathroom
Block RGB events in bathroom.
QR Code
Block RGB events in bathroom.
Bluetooth
Audio Frequency (900 Hz) Block RGB events in bathroom.
Person
Person
Person
Person
QR Code
QR Code with memory
Bluetooth + Person
Color
Remove person from RGB events.
Remove person from RGB events.
Remove person from RGB events.
Remove person from RGB events.
Speaking
Speech Keyword
Block audio events after sensitive keyword.
Corporate
WiFi
Commute
Location
Block RGB events in corporate building.
Blur location events in sensitive area.
24
23
35
84
89
69
104
23
23
29
10435
10435
10435
7132
7132
7132
7132
4529
21064
475
83 sec.
83 sec.
83 sec.
60 sec.
60 sec.
60 sec.
60 sec.
42 sec.
191 sec.
482 sec.
Figure 7: Evaluated Policies. We constructed scenarios, took traces using our prototype, and evaluated the eﬀectiveness of various
policies. In the third column, the type of event targeted by the policy is bolded; the fourth column reports total events in the trace.
Trace Name Policy Trigger
# Target Events
Start Lag
Finish Lag
Additional FN Additional FP
Bathroom
Bathroom
Bathroom
QR Code
Bluetooth
Audio Frequency (900 Hz)
Person
Person
Person
Person
QR Code
QR Code with memory
Bluetooth + Person
Color
Speaking
Speech Keyword
Corporate
WiFi
Commute
Location
1946
1946
1946
1244
1244
1244
1244
375
2823
475
0 (0 sec)
-50 (-2.1 sec)
0 (0 sec)
0 (0 sec)
183 (7.8 sec)
0 (0 sec)
279 (13.5 sec)
279 (13.5 sec)
210 (10.1 sec)
147 (6.1 sec)
0 (0 sec)
0 (0 sec)
8 (0.4 sec)
0 (0 sec)
16 (1.8 sec)
27 (3.0 sec)
21 (1.4 sec)
0 (0 sec)
14 (14.2 sec)
4 (4.1 sec)
0
0
81
88
20
0
23
0
171
0
0
0
0
0
0
30
23
0
417
0
Figure 8: Evaluation Results. This table shows the results from running each policy against the corresponding trace. The ﬁrst two
columns match those in Figure 7. Figure 6 explains how start/ﬁnish lag and additional false positives/negatives are calculated.
(One QR code event, or null if no QR code is found, is gen-
erated per RGB frame.) This change makes the QR code
policy more robust:
if at least one of ﬁve RGB frames re-
sults in a correctly detected QR code, the policy will not
jitter in the interim. The tradeoﬀ is that too much memory
may lead to a longer ﬁnish lag or more false positives.
Hybrid techniques can improve performance. Tech-
nologies can be combined to exploit their respective strengths.
For example, in the Person trace, we used Bluetooth (which
has a wider range) to bootstrap person removal using color
or the Kinect’s person detection (which can localize the ob-
ject to be modiﬁed in a frame). This result challenged our
initial intuition that policies should be detectable via the
same sensor as the events to which the policy applies. We
reasoned that if the system is in a state where it misses a
policy trigger (e.g., the camera is oﬀ), then it should also be
in a state to miss the events to which the policy applies (e.g.,
RGB events). However, this proposal fails due to diﬀerences
in the characteristics of diﬀerent policy technologies.
Bootstrap remote policies early with passports. We
experimented with passports in the Person trace, using Blue-
tooth and QR codes to load person removal policies. Pass-
ports let us easily extend our system without rebuilding it.
Additionally, the latency incurred by loading policy code can
be hidden by bootstrapping it as early as possible. It took
on average 227.6 ms (10 trials) to load and install a passport
(197.9 ms of which is network latency), increasing the start
lag by 5-6 RGB frames if the policy is to be used immedi-
ately. Communicating a person’s opt-out via BLE, rather
than in a QR code on the person, would thus allow enough
time to load the policy before the person is encountered.
Accuracy and latency may conﬂict. Recall that we
trade oﬀ policy accuracy with performance in our imple-
mentation (Section 5). Rather than waiting to dispatch an
RGB event until the corresponding QR event arrives, we
dispatch all RGB events immediately, relying on the most
recent (possibly out of date) QR code event to detect a pol-
icy. We observe that start lag consists of two components:
(1) the time it takes to be in range of the policy (e.g., close
enough to the QR code), and (2) the number of unmodi-
ﬁed events after the policy comes into range but the trigger
is not yet recognized. Our choice to trade oﬀ accuracy for
performance potentially aﬀects the second component.
We measured the eﬀect of this implementation choice for
QR codes. We ﬁnd that the accuracy impact is negligible: in
the Bathroom trace, the diﬀerence is just one frame (40 ms).
That is, one RGB event contained a QR code and was let
through, but the policy was applied by the next RGB event.
In the Person trace, the lag is four frames (160 ms); these
accuracy diﬀerences are not discernible in Figure 9. How-
ever, the same performance lag may noticeably impact the
user in some cases: to avoid distracting lag between the real
and virtual objects in augmented reality, for example, sensor
input events must be dispatched in as close to real-time as
possible [2]. Systems may diﬀer in their requirements.
Better technology will improve accuracy. Because the
Kinect has a relatively low RGB resolution (640x480, up to
30 frames per second), in two traces we simultaneously col-
lected additional video using a GoPro camera (1280x1080,
up to 60 fps) aﬃxed to the Kinect (included in Figures 9a–
b.) We synchronized Kinect and GoPro frames by hand,
downsampling the GoPro points and marking the policy as
enforced if any collapsed frames were blocked or modiﬁed.
The barcode library could decode QR codes up to one sec-
ond earlier in the GoPro traces, with fewer false negatives.
The GoPro’s wide-angle lens also allowed it to decode QR
Microsoft Research Tech Report MSR-TR-2014-67
(a) Bathroom Scenario: RGB-Blocking Policies
(b) Person Scenario: RGB-Modifying Policies
(c) Speech Scenario: Audio-Blocking Policy
(d) Corporate Scenario: RGB-Blocking Policy
Figure 9: Policy Evaluation. The grey regions were annotated as “depends” in the ground truth, i.e., the human annotator believed
that either blocking or not blocking the event would be acceptable; these events are not counted in Figure 8. Figure 6 shows an example.
codes in the periphery (e.g., near but not on the bathroom
door) that the Kinect did not see. Thus, as mobile cameras
improve, so will their ability to detect world-driven policies.
We expect that other cases in which our system failed to
match ground truth will also be improved by better tech-
nology. For example, the speech keyword recognizer is slow,
resulting in large start and ﬁnish lags. Similarly, the start
lag is long for all person removal policies (Figure 9b) because
the trace involves approaching the person down a hall, and
no method is eﬀective until the camera is close enough.
World-driven access control is practical. Our expe-
riences suggest that world-driven policies can be expressed
with modest developer eﬀort, that the system can be seam-
lessly extended with passports, and that policies can be de-
tected and enforced with reasonable accuracy given the right
choice of technology. Even without advances in computer
vision or other technologies, world-driven access control al-
ready signiﬁcantly raises the bar in some scenarios — e.g.,
the accuracy of our system in the bathroom setting.
7. REFLECTIONS AND FUTURE WORK
Continuous sensing applications will become increasingly
prevalent as technologies like Google Glass and Microsoft
Kinect become more ubiquitous and capable. World-driven
access control provides a new alternative to controlling ac-
cess to sensor streams. As our work uncovers, important
challenges arise when attempting to instantiate this approach
in a real system. One key challenge is the tradeoﬀ between
policy detection accuracy and enforcement latency. A sec-
ond key challenge is the need to verify the authenticity of
signals communicated from real-world objects. Though we
designed and evaluated speciﬁc approaches for overcoming
both challenges, future insights may lead to alternate solu-
tions. We highlight these challenges in this section, with
the hope of providing targets for and beneﬁting future re-
searchers focused on access control for continuous sensing.
We also highlight a separate challenge: the tension be-
tween the speciﬁcity of the information broadcast in a pol-
icy and an object’s privacy. While speciﬁc object descrip-
tions (e.g., “no pictures of car with license plate 123456”) are
valuable both for policy veriﬁcation and for extending the
system’s object recognition capabilities, they reveal informa-
tion to anyone receiving the broadcast. We view this issue
as separate from our study of how to eﬀectively communi-
cate and manage world-driven policies, our primary goal,
but we believe it is important to consider if world-driven
access control systems are deployed with highly expressive
policies. Currently, policy creators must balance policy ac-
curacy and description privacy, considering evolving social
norms in the process. Since speciﬁc object descriptions in
passports are nevertheless valuable for verifying that a pol-
icy has not been moved by an adversary, we encourage fu-
ture work on privacy-preserving, expressive policies (e.g., en-
crypted policies accessible only by trusted policy modules).
A separate privacy issue arises with the use of crypto-
graphic signatures on policies: if the signatures on each ob-
ject are unique, then they can be used to track objects; we
observe, however, that there are many other methods to