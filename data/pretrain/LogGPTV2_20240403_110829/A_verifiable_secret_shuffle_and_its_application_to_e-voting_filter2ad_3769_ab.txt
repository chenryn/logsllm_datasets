1. P secretly generates, randomly and independently from
Zq, k − 1 elements, θ1, . . . θk−1. P then computes
A1 = Y θ1
1
A2 = X θ1
2 Y θ2
2
(9)
...
... =
Ai = X θi−1
... =
...
i
Y θi
i
Ak = X θk−1
k
and reveals to V the sequence A1, . . . , Ak.
ρi(M ) = (mi1, . . . , mil)
τj(M ) = *(
m1j
...
mkj
+)
(5)
(6)
2. V generates a random challenge, γ ∈ Zq and reveals it
to P.
3. P computes k − 1 elements, r1, . . . , rk−1, of Zq satis-
118−γ
1
(10)
fying
Y r1
1
2 Y r2
2
X r1
= A1 X
= A2
...
= Ai
...
... =
... =
X ri−1
i
Y ri
i
X rk−1
k
= Ak Y (−1)(k−1)γ
k
and reveals the sequence r1, . . . , rk−1 to V. (We will
see in the proof of completeness, below, how these val-
ues are computed.)
4. V accepts the proof if and only if all of the equations
in (10) hold.
Theorem 1. The ILMPP is a three-move, public coin
proof of knowledge for the relationship in equation (7) which
is special honest-veriﬁer zeroknowledge. The number of ex-
ponentiations required to construct the proof is k, and the
number of exponentiations required to verify it is 2k. If V
generates challenges randomly, the probability of a forged
proof is 1/q.
Remark 2. All exponentiations in the SILMPP occur in
pairs of the form X aY b, so numerical techniques can reduce
this to eﬀectively less than 1.25k exponentiations. (See [18],
p. 617-618, “simultaneous multiple exponentiation”.) Also
note that in constructing the proof, all exponentiations can
be done to the same base, g, so precomputation can be em-
ployed as well.
= *****(
0
0
...
0
+++++)(12)
γ yk
The (k − 1) × (k − 1) sub-system
0
x2
0
...
0
0
y2
x3
...
0
0
0
y3
...
···
···
¯r1
¯r2
...
¯rk−2
¯rk−1
0
0
...
yk−1
xk
···
0
···
0
...
···
0 xk−1
0
+++++)
*****(
+++++)
*****(
is non-singular since its determinant is 3k
k;j=i+1 yj
xj
¯ri = (−1)(k−i−1) γ
ally implies (11). This is because
i=2 xi, which is
non-zero by assumption (8). Hence, one can always solve it
for ¯r1, . . . , ¯rk−1. In fact, the solution is
However, under the hypotheses of the problem, (12) actu-
(13)
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
+++++++)
0 =
=
xi − k;i−1
x1
0
0
...
0
(−1)kyk
k;i=1
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
*******(
yi
(14)
y1
x2
0
...
0
0
0
y2
x3
...
0
0
0
0
y3
...
···
···
···
0
···
0
···
0
...
···
0 xk−1
0
0
0
0
0
...
yk−1
xk
which, combined with the fact that the sub-matrix on the
left of equation (12) is non-singular, means that the ﬁrst
column vector of the k × k matrix in (14) must be a linear
combination of the remaining k − 1 column vectors.
Proof: The protocol is clearly three-move and public coin.
The exponentiation count in the construction of the proof
looks like it should be 2k − 2, but actually it can be con-
structed with only k exponentiations. This is because P
knows the logarithms xi and yi, and hence can compute Ai
as Ai = gθi−1xi+θiyi for all 2 ≤ i ≤ k − 1.
Soundness
If the ﬁrst column vector of the matrix on the left of equa-
tion (14) is not a linear combination of the remaining k − 1
column vectors, then there can be at most one value of
γ ∈ Zq for which equation (11) holds. Thus, if γ is cho-
sen randomly, there is at most a chance of 1 in q that P can
produce r1, . . . , rk−1 which convince V.
Completeness
Completeness means that, given arbitrary (cid:126)θ = (θ1, . . . , θk−1)
and γ, P can always ﬁnd (cid:126)r = (r1, . . . , rk−1) satisfying the
system of equations in (10). To see that this is the case, take
logg of each side of the equations in (10), and set ¯ri = ri− θi
for 1 ≤ i ≤ k − 1. One obtains the following k × (k − 1)
system of linear equations in Zq for ¯r1, . . . , ¯rk−1
¯r1
¯r2
¯r3
...
¯rk−2
¯rk−1
*******(
+++++++)
(11)
*******(
0
0
0
...
yk−1
xk
···
0
···
0
···
0
...
···
0 xk−1
0
0
−γ x1
0
0
...
0
(−1)(k−1) γ yk
y1
x2
0
...
0
0
0
y2
x3
...
0
0
0
0
y3
...
···
···
=
*******(
+++++++)
+++++++)
(cid:126)A = *****(
+++++)
= *****(
Special Honest-Veriﬁer Zeroknowledge
Honest-veriﬁer zero-knowledge holds because, for random γ
and random (cid:126)r = (r1, . . . , rk−1), and for
X γ
1 Y r1
2 Y r2
X r1
...
(15)
2
1
A1
A2
...
Ak−1
Ak
k−1 Y rk−2
X rk−2
k−1
Y (−1)kγ
X rk−1
k
k
the triple ( (cid:126)A, γ, r) is an accepting conversation. It is easy
to see that the distribution so generated for (cid:126)A is identical
to that generated according to (9), again because the ﬁrst
column vector of the matrix in (14) is a ﬁxed linear combina-
tion of the remaining column vectors. So if V is honest, the
simulation is perfect. Since the challenge, γ, can be chosen
freely, we also have special honest-veriﬁer zero-knowledge.
+++++)
119Remark 3. The solutions for ¯ri in (13) could also be
written formally as
¯ri = (−1)(i−1) γ
i;j=1 xj
yj
However, this will not work if some of the yj are 0. In the
case of equation (13), this problem was avoided by assump-
tion (8). Of course, the main part of the solution could just
have well be set up under the assumption that yi (cid:54)= 0 for all
1 ≤ i ≤ k − 1 – the choice of expression for ri just needs to
be kept consistent with the form of the assumption.
Remark 4. We leave it to the reader to check that in the
case k = 2, the SILMPP reduces exactly to the well known
Chaum-Pedersen protocol. In so doing, it is worth recalling
remark 1, equation (2).
Remark 5. Special Soundness
As is the case with the Chaum-Pedersen protocol, which
proves that P knows s = logG X = logH Y , the SILMPP
proves that P knows s1, . . . , sk such that logg Xi = logg Yi,
i=1 si = 1. This is clear because from two accepting
conversations, ( (cid:126)A, γ, (cid:126)r ) and ( (cid:126)A, γ (cid:48), (cid:126)r (cid:48) ), with the same ﬁrst