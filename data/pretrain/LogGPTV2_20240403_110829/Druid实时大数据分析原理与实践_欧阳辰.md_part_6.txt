数据处理和分析，开发成本会比较高，适合非结构化的数据查询处理。
Spark也提供了大量的算法用来查询和分析数据，其开发语言采用Scala，因此直接在上面做
如机器学习格外有用，比如有些操作需要重复执行很多次才能达到结果的最终收敛。同时，
能复用持久化到内存中的数据，从而为选代算法提供更快的计算速度。这对一些工作流例
生态组件也较多，核心组件如图2-11所示。
HDFS，因此Spark的运行速度更快，适用于对性能有要求的数据挖掘与数据分析场景。Spark
算结果可以缓存在内存中，这样选代计算时可以从内存直接获取中间结果而不需要频繁读写
也是基于分布式计算，拥有Hadoop MapReduce的所有优点；不同的是，Spark任务的中间计
2.
生态并能够对接很多Hadoop生态中的数据源。
作为其深度存储（Deep Storage）数据文件的一种解决方案。另外，Druid也全面拥抱Hadoop
需求方面Hadoop并不擅长。
是高吞吐的批处理系统，适合大型任务的运行，但在对任务响应时间和实时性有严格要求的
Spark是实现弹性分布式数据集概念的计算集群系统，可以看作是商业分析平台。RDD
Spark是UC Berkeley AMPlab开源的类Hadoop MapReduce通用的并行计算框架，同样
Spark
Druid正好是Hadoop的一个有利补充，它提供了一套非常实时的方案，并可利用 HDFS
Hadoop基于可靠的分布式存储，通过MapReduce进行选代计算，查询批量数据。Hadoop
oOop
Flume
Sqoop
LogCollector
Data Exchange
Zookeeper
Coordination
HadoopDistributed FileSystem
HDFS
Oozie
图2-10 Hadoop 软件生态图
Workflow
Provisioning,Managingand Monitoring Hadooop Clusters
Pig
Scripting
Mahout
YARN Map Reduce v2
Machine Learning
R Connectors
Statistics
Druid实时大数据分析原理与实践
Hive
4
SQLQuery
Ambari
Hbase
Columnar
Store
---
## Page 49
开处理。其中RealtimeNode处理实时数据查询，HistoricalNode处理历史数据。
鼎鼎的Kafka就来源于LinkedIn，因此Pinot在推出后就备受关注和追捧。
司于2015年年底开源的一个分布式列式数据存储系统。LinkedIn在开源界颇具盛名，大名
1.Pinot
2.3.4
理规模更大的批处理任务。
实时分析的场景，结果返回时间在亚秒级。Spark可以对任何 Schema进行灵活操作，适合处
第2章
在架构上，Pinot也采用了Lambda架构，如图2-12所示，将实时数据流和批处理数据分
·类似于SQL的查询语言和各种常用聚合
如果要找一个与Druid最接近的系统，那么非LinkedInPinot莫属。Pinot是LinkedIn公
Druid的核心是通过数据预先聚合提高查询性能，针对预先定义好的 Schema，因此适合
·水平扩展和容错
·支持多值字段
·从Kafka的准实时数据灌人和从Hadoop的批量数据灌人
·可插入的索引技术一
Pinot的技术特点如下。
可以根据Query和Segment元数据进行查询和执行计划的优化
一个面向列式存储的数据库，支持多种压缩技术
开源分析数据库
数据分析及相关软件
BlinkDB
SOL
Streaming
—Sorted Index、Bitmap Index 和 Inverted Index
图2-11Spark的核心组件
Spark Core Engine
40
Graphx
Gropn
Alpha /Pre-alpha
Ron Spark
SparkR
---
## Page 50
多管理功能，例如 Web 管理、访问控制、支持LDAP、支持HyperLoglog 的近似算法。
支持标准的OLAPCube，查询数据更加方便，与大量BI工具无缝整合。另外，它提供了很
至开源社区。Kylin能在亚秒内查询巨大的Hive表。
多维分析（OLAP）能力，可以支持超大规模数据。
2.Kylin
路要走。
的整体设计比Druid更加完整和系统化，但是该技术刚刚开源，离成熟应用还有很长一段
的集群管理也使用Apache开源软件Helix，性能更可靠，可管理性更强。总体来说，Pinot
较单一的Bitmap方式的索引。对于查询语言来说，Pinot的查询语法更接近SQL方式。Pinot
列就会采用字典编码（DictonaryEncoding），而后对列内的数据进行压缩存储。Druid支持比
样，目前Pinot社区也非常活跃。Pinot的索引结构支持更多的索引格式，如ForwardedIndex、
7
Kylin的优势很明显，它支持标准的ANSISQL接口，可以复用很多传统的数据集成系统，
Kylin是Apache开源的一个分布式分析引擎，提供了在 Hadoop之上的 SQL查询接口及
相比Druid，Pinot还比较年轻，相关生态支持力度小，但像很多刚开放的开源软件-
cohatimer
EXEUUYOR
REALTIMECONSUMPTION
REALTIMENODE
KAFKA
图2-12Pinot架构示意图
SCATTER GATHER
CLUSTERMANAGER
Zokee
Apache
DSERVEY
PinotBroker
READSEGMENT
NFS
。它最初由eBay公司开发并于2015年贡献
EXEUERYOR
Druid实时大数据分析原理与实践
HDFS
---
## Page 51
的最大优势是支持SQL访问，可以兼容传统的BI工具和报表系统，在性能上没有太大优势。
力度弱于Druid。Druid的设计轻巧，代码库也比较容易懂，支持比较灵活的功能增强。Kylin
问题非常类似。Pinot架构的设计比较规范，系统也比较复杂，由于开源时间短，社区的支持
扩展的OLAP引擎。
部分，所以使用Kylin很容易得到很好的中文支持。Kylin的愿景就是创建一个分布式的高可
构。Kylin架构示意图如图2-13所示。
用BitmapIndex作为实时处理部分的数据结构，而使用MOLAPCube作为历史数据的数据结
Kylin缺少实时数据摄人的能力。Druid使用Bitmap Index作为统一的内部数据结构；Kylin使
式的缺点也很明显，查询缺乏灵活性，需要预先定义好查询的一些模式、一些表结构。目前，
结果，而不需要访问Hive原始数据。
多数据事先存储在以HBase为基础的OLAPCube中，大部分查询可以直接访问HBase获取
第2章数据分析及相关软件
3.
Kylin
Druid、Pinot和Kylin比较
Druid、Pinot 和Kylin是数据分析软件选型经常碰到的问题。Druid和 Pinot解决的业务
另外，在Kylin开发成员中有很多开发人员来自中国，因此在PMC成员中中国人占了大
Hive.
Hadoop
这几个软件的特点如图2-14所示。
从技术上理解，Kylin在HadoopHive表上做了一层缓存，通过预计算和定期任务，把很
Star Schema Data
Web App.Mobile
Third Party App
RESTAPI
图2-13Kylin架构示意图
SOL
Cube Build Engine
Metadata
Query Engine
REST Server
Routing
、虽然数据缓存、
(Bl tools:Tableau
SOL-Based Tool
JDBC/ODBC
SOL
，预计算可以提高查询效率，但这种方
LowLatency-Seconds
OLAP Cube is transparent to users
Only SOL for End User
OfflineData Flow
Orline Analysis Data Flow
Key Value Data
Cube
OLAP
乙
---
## Page 52
的优化和权衡。
计原理。该论文写于2006年，公开于2010年，Dremel为了支持Nested Data，做了很多设计
非常成功。Dremel的应用如下。
也成为MapReduce的一个有利补充。Dremel在Google Big Query的Report引擎上的应用也
功能，进行深度的数据探索（Exploration）。谷歌开发的Dremel将处理时间缩短到秒级，它
的数据，可以对网状数据的只读数据进行随机查询访问，帮助数据分析师提供AdHoc查询
4.
28
·抓取的网页文档分析，主要是一些元数据
Dremel是谷歌的“交互式”数据分析系统，支持上千台机器的集群部署，处理PB级别
神秘的谷歌Dremel
谷歌公开的论文Dremel:InteractiveAnalysis of WebScaleDatasets，总体介绍了Dremel的设
·其他
·作弊（Spam）分析
·追踪Android市场的所有安装数据
：谷歌产品的Crash报告
谷歌代码库中的Symbol和依赖分析
谷歌数据中心中任务的资源分析
上千万的磁盘1/O分析
谷歌分布式构建（Build）系统中的测试结果
技术
资助者
发布时间
接口协议
开发语言
使用场景
图2-14Druid、Pinot 和Kylin特点
实时聚合
/Imply.io
MetaMarkets
2011年
JSON
实时处理分析
Druid
Java
实时聚合
Linkedln
2015年
JSON
实时处理分析
Pinot
ava
Druid实时大数据分析原理与实践
预处理，Cache
eBay
2015年
OLAP/JDBC
OLAP分析引擎
ava
Kylin
---
## Page 53
态架构。
架构中的关系查询引擎和数据库构建是有先决条件的，即假设所有数据都有一个简单的静
户能查询固定架构，支持各种格式和数据存储中的模式无关（schema-free）数据。该体系
引擎，进行快速全表扫描，以快速返回结果，其高层架构示意图如图2-15所示。
的定时任务完成导入。在数据的实时性方面，论文中并没有讨论太多。
果集或者建立分析原型。
的替代品，它只是可以执行非常快的分析，在使用的时候，常常用它来处理MapReduce的结
上面。所以它需要GFS 这样的文件系统作为存储层。在设计之初，Dremel并非 MapReduce
并发处理数据。和MapReduce一样，Dremel也需要和数据运行在一起，将计算移动到数据
现也是非常复杂的。
便嵌套数据查询。论文详细解释了嵌套数据类型的列存储，这个特性是Druid所缺少的，
用列式方法存储这些数据，由于嵌套数据结构，Dremel引人了一种树状的列式存储结构，
据模型，一种嵌套的（Nested）数据模型，类似于ProtocolBuffer定义的数据结构。Dremel采
要复杂的容错设计，少量节点的读失败（或慢操作）不能影响整体操作。
么在1s内处理1TB 数据，意味着至少需要有1万个磁盘并发读，对于如此大量的读写，
第2章数据分析及相关软件
5.
Apache Drill
在使用Dremel时，工程师需要通过MapReduce将数据导入Dremel,可以通过MapReduce
ApacheDrill通过开源方式实现了谷歌Dremel。Drill架构的整个思想还是通过优化查询
Dremel采用层级的执行引擎。Dremel在执行过程中，SQL查询输人会转化成执行计划
Dremel支持嵌套的数据结构。互联网数据常常是非关系型的。Dremel还支持灵活的数
Dremel是一个大规模的高并发系统。举例来说，磁盘的顺序读速度在100MB/s上下，那
ApacheDrill基于 SQL的数据分析和商业智能（BI）引人了JSON文件模型，这使得用
Dremel系统有以下几个主要技术特点。
SQL
图2-15ApacheDrill高层架构示意图
RPC Endpoint
Distributed Cache
Optimizer
Physical
Plan
K
Hive
HBase
方
---
## Page 54
（schema-free）的数据输人，随时增加索引。
结构比较适合基数较大的列，比如人名、单词等。ES支持灵活的数据输人，支持无固定格式
要文本搜索的场景下，直接使用ES作为简单的数据分析平台也是快速的解决方案。
出色的交互界面，可以对接常用的仪表盘（Dashboard）功能。因此，在一些数据量不大，需
OLAP的一些简单的 Count、Group by功能。另外，套件中内置的Kibana可视化工具提供了
公司将ES用于日志分析和数据的可视化，慢慢转成一个数据分析平台。它能够提供类似于
似的软件还有Solr，两个软件有一定的相似性。
语言开发，并作为Apache许可条款下的开放源码发布，它是流行的企业搜索引擎。与之类
6.Elasticsearch
模型，这样执行引擎就可以支持更多的数据类型。
行在上万台机器上计算数以PB的数据。
提速），而“Drill”将有助于Hadoop用户实现更快查询海量数据集的目的。
源版本的谷歌Dremel Hadoop工具（谷歌使用该工具为Hadoop数据分析工具的互联网应用
JSON文件模式下能实现记录断点性能（record-breaking performance）。该项目将会创建出开
新编译，也称为 schema discovery）的执行引擎。这些独一无二的性能使得Apache Drill在
擎（columnar execution engine），也是唯一一个能在查询执行期间进行数据驱动查询（和重
集；ES用于数据索引l；Kibana用于可视化表现。
一个高可靠、可扩展、分布式的全文搜索引擎，提供了方便的RESTfulWeb接口。ES采用Java
ES内部使用了Lucene的倒排索引l，每个Term后面都关联了相关的文档ID列表，这种
Elastic主推 ELK产品，它是一个提供数据分析功能的套装，包括LogStash 用于数据收
前几年，ES的定位一直是文本的倒排索引引擎，用于文本搜索的场景。最近几年，Elastic
Elasticsearch（ES）是Elastic公司推出的一个基于Lucene 的分布式搜索服务系统，它是
Scalable data source：支持多种数据源，现阶段以 Hadoop为数据源。
Nesteddataformat：嵌套数据模型，和Dremel类似，也支持CSV、JSON、YAML之类的
Low-lantency distribute execution engine：执行引擎，可以支持大规模扩展和容错，并运
Query language：类似谷歌BigQuery的查询语言，支持嵌套模型，名为DrQL。
目前，Drill已经完成的需求和架构设计，总共分为以下4个组件。
Apache Drill的架构是独一无二的。它是唯一一个支持复杂和无模式数据的柱状执行引
Druid实时大数据分析原理与实践
---
## Page 55
操作还是会带来非常慢的查询体验。所有尝试Hive的公司，几乎都会转型到Impala的应用。
MapReduce应用，十分适合数据仓库的统计分析。Hive并不适合那些需要低延迟的应用，例
库表，并提供简单的 SQL查询功能，可以将 SQL 语句转换为 MapReduce任务运行。其优
2.3.5
数据规模不大的情况下，ES也是非常不错的选择。Druid更善于处理更大规模、实时性更强
原始数据将会丢弃，因此无法召回具体的某一数据行。
进行索引，而且数据结构也支持数组等灵活的数据类型。Druid需要定义清楚维度和指标列。
著不同是，ES是schema-free的，也就是说，无须定义Schema，就可以直接插人JSON数据，
时的数据摄入功能，但是性能比Druid要慢很多，因为它的索引过程更加复杂。另外一个显
第2章数据分析及相关软件
整个查询过程也比较慢，不适合实时数据分析。
如联机事务处理（OLTP）。Hive查询操作过程严格遵守HadoopMapReduce的作业执行模型，
点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的
点。
中，
的数据。
还有一个很大区别，就是ES会保持元素的文档数据，而Druid在按照时间粒度数据聚合后
儿乎所有的Hadoop 环境都会配置Hive的应用，虽然 Hive 易用，但内部的 MapReduce
。常用的分析过程有以下几种。
，数据的持久化和可靠性得到了保证，但是如何快速挖掘出其中的价值却是很多公司的痛
最近几年，ES一直在增加数据分析的能力，包括各种聚合查询等，性能提升也很快。在
相比Druid，ES 对于基数大的列能够提供完美的索引方案，例如文本。ES 也提供了实
Hive是一个基于Hadoop 的数据仓库工具，可以将结构化的数据文件映射为一张数据
Hive
接下来，我们来看看简单的SQL查询是如何访问HDFS的。
Hadoop生态发展了多年，越来越多的公司将重要的日志数据存入Hadoop的HDFS系统
。基于HDFS，编写SQL直接访问。
·基于HDFS，写代码通过MapReduce进行数据分析。
·数据从HDFS导人RDBMS/NoSQL。
SQL on Hadoop/Spark
访问引擎直接访问HDFS文件系统。
。SQL访问内部转换为MapReduce任务。
31
---
## Page 56
MapReduce任务，一个接着一个运行，每一个任务从磁盘读取输入数据并且将中间结果输出
图2-17展示了简化的Presto系统架构示意图。
是一个分布式SQL查询引擎，它被设计专门用于进行高速、实时的数据分析。它支持标准的
3.FacebookPresto
也会花费不少时间。
的数据流程图如图2-16所示。