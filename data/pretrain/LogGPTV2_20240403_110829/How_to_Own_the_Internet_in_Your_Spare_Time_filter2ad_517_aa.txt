title:How to Own the Internet in Your Spare Time
author:Stuart Staniford and
Vern Paxson and
Nicholas Weaver
USENIX Association
Proceedings of the
11th USENIX Security
Symposium
San Francisco, California, USA
August 5-9, 2002
© 2002 by The USENIX Association
Phone: 1 510 528 8649
FAX: 1 510 548 5738
THE ADVANCED COMPUTING SYSTEMS ASSOCIATION
All Rights Reserved
Email: PI:EMAIL
For more information about the USENIX Association:
WWW: http://www.usenix.org
Rights to individual papers remain with the author or the author's employer.
 Permission is granted for noncommercial reproduction of the work for educational or research purposes.
This copyright notice must be included in the reproduced paper. USENIX acknowledges all trademarks herein.
How to 0wn the Internet in Your Spare Time
∗
Stuart Staniford
Silicon Defense
Vern Paxson
†
ICSI Center for Internet Research
‡
Nicholas Weaver
UC Berkeley
PI:EMAIL
PI:EMAIL
PI:EMAIL
Abstract
1 Introduction
The ability of attackers to rapidly gain control of vast
numbers of Internet hosts poses an immense risk to the
overall security of the Internet. Once subverted, these
hosts can not only be used to launch massive denial of
service ﬂoods, but also to steal or corrupt great quantities
of sensitive information, and confuse and disrupt use of
the network in more subtle ways.
We present an analysis of the magnitude of the threat.
We begin with a mathematical model derived from em-
pirical data of the spread of Code Red I in July, 2001. We
discuss techniques subsequently employed for achiev-
ing greater virulence by Code Red II and Nimda. In this
context, we develop and evaluate several new, highly vir-
ulent possible techniques: hit-list scanning (which cre-
ates a Warhol worm), permutation scanning (which en-
ables self-coordinating scanning), and use of Internet-
sized hit-lists (which creates a ﬂash worm).
We then turn to the to the threat of surreptitious worms
that spread more slowly but in a much harder to detect
“contagion” fashion. We demonstrate that such a worm
today could arguably subvert upwards of 10,000,000 In-
ternet hosts. We also consider robust mechanisms by
which attackers can control and update deployed worms.
In conclusion, we argue for the pressing need to de-
velop a “Center for Disease Control” analog for virus-
and worm-based threats to national cybersecurity, and
sketch some of the components that would go into such
a Center.
∗
†
Research supported by DARPA via contract N66001-00-C-8045
Also with the Lawrence Berkeley National Laboratory, University
of California, Berkeley.
‡
Additional support from Xilinx, ST Microsystems, and the Cali-
fornia MICRO program
If you can control a million hosts on the Internet, you
can do enormous damage. First, you can launch dis-
tributed denial of service (DDOS) attacks so immensely
diffuse that mitigating them is well beyond the state-of-
the-art for DDOS traceback and protection technologies.
Such attacks could readily bring down e-commerce sites,
news outlets, command and coordination infrastructure,
speciﬁc routers, or the root name servers.
Second, you can access any sensitive information
present on any of those million machines—passwords,
credit card numbers, address books, archived email,
patterns of user activity, illicit content—even blindly
searching for a “needle in a haystack,” i.e., information
that might be on a computer somewhere in the Internet,
for which you trawl using a set of content keywords.
Third, not only can you access this information, but you
can sow confusion and disruption by corrupting the in-
formation, or sending out false or conﬁdential informa-
tion directly from a user’s desktop.
In short, if you could control a million Internet hosts,
the potential damage is truly immense: on a scale where
such an attack could play a signiﬁcant role in warfare
between nations or in the service of terrorism.
Unfortunately it is reasonable for an attacker to gain con-
trol of a million Internet hosts, or perhaps even ten mil-
lion. The highway to such control lies in the exploita-
tion of worms: programs that self-propagate across the
Internet by exploiting security ﬂaws in widely-used ser-
vices.1 Internet-scale worms are not a new phenomenon
[Sp89, ER89], but the severity of their threat has rapidly
grown with (i) the increasing degree to which the In-
1 We distinguish between the worms discussed in this paper—
active worms—and viruses (or email worms) in that the latter require
some sort of user action to abet their propagation. As such, they tend to
propagate more slowly. From an attacker’s perspective, they also suf-
fer from the presence of a large anti-virus industry that actively seeks
to identify and control their spread.
Figure 1: Onset of Code Red I v2, Code Red II, and Nimda:
Number of remote hosts launching conﬁrmed attacks corre-
sponding to different worms, as seen at the Lawrence Berkeley
National Laboratory. Hosts are detected by the distinct URLs
they attempt to retrieve, corresponding to the IIS exploits and
attack strings. Since Nimda spreads by multiple vectors, the
counts shown for it may be an underestimate.
ternet has become part of a nation’s critical infrastruc-
ture, and (ii) the recent, widely publicized introduction
of very large, very rapidly spreading Internet worms,
such that this technique is likely to be particularly cur-
rent in the minds of attackers.
We present an analysis of the magnitude of the threat.
We begin with a mathematical model derived from em-
pirical data of the spread of Code Red I v2 in July and
August, 2001 (Section 2). We then discuss techniques
employed for achieving greater effectiveness and viru-
lence by the subsequent Code Red II and Nimda worms
(Section 3). Figures 1 and 2 show the onset and progress
of the Code Red and Nimda worms as seen “in the wild.”
In this context, we develop the threat of three new
techniques for highly virulent worms: hit-list scanning,
permutation scanning, and Internet scale hit-lists (Sec-
tion 4). Hit-list scanning is a technique for accelerat-
ing the initial spread of a worm. Permutation scanning
is a mechanism for distributed coordination of a worm.
Combining these two techniques creates the possibility
of a Warhol worm,2 seemingly capable of infecting most
or all vulnerable targets in a few minutes to perhaps an
hour. An extension of the hit-list technique creates a
ﬂash worm, which appears capable of infecting the vul-
nerable population in 10s of seconds: so fast that no
human-mediated counter-response is possible.
We then turn in Section 5 to the threat of a new class of
2So named for the quotation “In the future, everyone will have 15
minutes of fame.”
Figure 2: The endemic nature of Internet worms: Number
of remote hosts launching conﬁrmed attacks corresponding to
different worms, as seen at the Lawrence Berkeley National
Laboratory, over several months since their onset. Since July,
139,000 different remote Code Red I hosts have been con-
ﬁrmed attacking LBNL; 125,000 different Code Red II hosts;
and 63,000 Nimda hosts. Of these, 20,000 were observed to
be infected with two different worms, and 1,000 with all three
worms. (Again, Nimda is potentially an underestimate because
we are only counting those launching Web attacks.)
surreptitious worms. These spread more slowly, but in a
much harder to detect “contagion” fashion, masquerad-
ing as normal trafﬁc. We demonstrate that such a worm
today could arguably subvert upwards of 10,000,000 In-
ternet hosts.
Then in Section 6, we discuss some possibilities
by which an attacker could control the worm using
cryptographically-secured updates, enabling it to remain
a threat for a considerable period of time. Even when
most traces of the worm have been removed from the
network, such an “updatable” worm still remains a sig-
niﬁcant threat.
Having demonstrated the very serious nature of the
threat, we then in Section 7 discuss an ambitious but
we believe highly necessary strategy for addressing it:
the establishment at a national or international level
of a “Center for Disease Control” analog for virus-
and worm-based threats to cybersecurity. We discuss
the roles we envision such a Center serving, and offer
thoughts on the sort of resources and structure the Cen-
ter would require in order to do so. Our aim is not to
comprehensively examine each role, but to spur further
discussion of the issues within the community.
020406080050001000020000Days Since July 18, 2001Distinct Remote Hosts Attacking LBNLJul 19Aug 1Sep 1Sep 19Oct 1Code Red I v2Code Red IINimda0501001500500100015002000Days Since Sept. 20, 2001Distinct Remote Hosts Attacking LBNLOct 1Oct 15Nov 1Nov 15Dec 1Dec 15Jan 1Jan 15NimdaCode Red I v2Code Red II2 An Analysis of Code Red I
The ﬁrst version of the Code Red worm was initially
seen in the wild on July 13th, 2001, according to Ryan
Permeh and Marc Maiffret of Eeye Digital Security
[EDS01a, EDS01b], who disassembled the worm code
and analyzed its behavior. The worm spread by compro-
mising Microsoft IIS web servers using the .ida vulner-
ability discovered also by Eeye and published June 18th
[EDS01c] and was assigned CVE number CVE-2001-
0500 [CV01].
Once it infected a host, Code-Red spread by launching
99 threads which generated random IP addresses, and
then tried to compromise those IP addresses using the
same vulnerability. A hundredth thread defaced the web
server in some cases.
However, the ﬁrst version of the worm analyzed by
Eeye, which came to be known as CRv1, had an apparent
bug. The random number generator was initialized with
a ﬁxed seed, so that all copies of the worm in a particular
thread, on all hosts, generated and attempted to compro-
mise exactly the same sequence of IP addresses. (The
thread identiﬁer is part of the seeding, so the worm had a
hundred different sequences that it explores through the
space of IP addresses, but it only explored those hun-
dred.) Thus CRv1 had a linear spread and never com-
promised many machines.
On July 19th, 2001, a second version of the worm began
to spread. This was suspected informally via mailing list
discussion, then conﬁrmed by the mathematical analysis
we present below, and ﬁnally deﬁnitively conﬁrmed by
disassembly of the new worm. This version came to be
known as CRv2, or Code Red I.
Code Red I v2 was the same codebase as CRv1 in al-
most all respects—the only differences were ﬁxing the
bug with the random number generation, an end to web
site defacements, and a DDOS payload targeting the IP
address of www.whitehouse.gov.
We developed a tentative quantitative theory of what
happened with the spread of Code Red I worm. The new
version spread very rapidly until almost all vulnerable
IIS servers on the Internet were compromised. It stopped
trying to spread at midnight UTC due to an internal con-
straint in the worm that caused it to turn itself off. It then
reactivated on August 1st, though for a while its spread
was suppressed by competition with Code Red II (see
below). However, Code Red II died by design [SA01]
on October 1, while Code Red I has continued to make
a monthly resurgence, as seen in Figure 2. Why it con-
tinues to gain strength with each monthly appearance re-
mains unknown.3
We call this model the Random Constant Spread (RCS)
model. The model assumes that the worm had a good
random number generator that is properly seeded. We
deﬁne N as the total number of vulnerable servers which
can be potentially compromised from the Internet. (We
make the approximation that N is ﬁxed—ignoring both
patching of systems during the worm spread and normal
deploying and removing of systems or turning on and
off of systems at night. We also ignore any spread of the
worm behind ﬁrewalls on private Intranets).
K is the initial compromise rate. That is, the number
of vulnerable hosts which an infected host can ﬁnd and
compromise per hour at the start of the incident, when
few other hosts are compromised. We assume that K is
a global constant, and does not depend on the processor
speed, network connection, or location of the infected
machine.
(Clearly, constant K is only an approxima-
tion.) We assume that a compromised machine picks
other machines to attack completely at random, and that
once a machine is compromised, it cannot be compro-
mised again, or that if it is, that does not increase the
rate at which it can ﬁnd and attack new systems. We
assume that once it is compromised, it stays that way.
T is a time which ﬁxes when the incident happens.
We then have the following variables:
• a is the proportion of vulnerable machines which
have been compromised.
• t is the time (in hours).
Now, we analyze the problem by assuming that at
some particular time t, a proportion of the machines
a have been compromised, and then asking how many
more machines, N da, will get compromised in the next
amount of time dt. The answer is:
N da = (N a)K(1 − a)dt.
(1)
The reason is that the number of machines compromised
in the next increment of time is proportional to the num-
ber of machines already compromised (N a) times the
number of machines each compromised machine can
3One possibility is that, since the default install of Windows 2000
server includes IIS, new vulnerable machines have been added to the
Internet.
This is interesting because it tells us that a worm like this
can compromise all vulnerable machines on the Internet
fairly fast.
Figure 3 shows hourly probe rate data from Ken Eich-
mann of the Chemical Abstracts Service for the hourly
probe rate inbound on port 80 at that site. Also shown
is a ﬁt to the data with K = 1.8, T = 11.9, and with
the top of the ﬁt scaled to a maximum probe rate of
510,000 scans/hour. (We ﬁt it to fall slightly below the
data curve, since it seems there is a ﬁxed background
rate of web probes that was going on before the rapid
rise due to the worm spread.) This very simple theory
can be seen to give a reasonable ﬁrst approximation ex-
planation of the worm behavior. See also Section 4.3 for
validation of the theory via simulation.
Note that we ﬁt the scan rate, rather than the number of
distinct IPs seen at this site. The incoming scan rate seen
at a site is directly proportional to the total number of in-
fected IPs on the Internet, since there is a ﬁxed probabil-
ity for any worm copy to scan this particular site in the
current time interval. However, the number of distinct
IPs seen at a site is distorted relative to the overall in-
fection curve. This is because a given worm copy, once
it is infected, will take some amount of time before it
gets around to scanning any particular site. For a small
address space, this delay can be sizeable and causes the
distinct IP graph at the given site to lag behind the over-
all Internet infection rate graph.
Two implications of this graph are interesting. One is
that the worm came close to saturating before it turned
itself off at midnight UTC (1900 CDT), as the num-
ber of copies ceased increasing a few hours before the
worm’s automatic turnoff. Thus it had found the bulk of
the servers it was going to ﬁnd at this time. Secondly,
the infection rate was about 1.8 per hour—in the early
stages of the infection, each infected server was able to
ﬁnd about 1.8 other servers per hour.
Although Code Red I turned itself off at midnight UTC
on July 19th, hosts with inaccurate clocks kept it alive
and allowed it to spread again when the worm code al-
lowed it to re-awaken on August 1st. Figure 4 shows
similar data and ﬁt for that incident. The K here is about
0.7. Since the worm code-base was the same, this lower
spread rate indicates that the number of vulnerable sys-
tems was a little less than 40% as many as the ﬁrst time
around. That is, the data appears consistent with slightly
more than half the systems having been ﬁxed in the 11
days intervening.
Figure 3: Hourly probe rate data for inbound port 80 at the
Chemical Abstracts Service during the initial outbreak of Code
Red I on July 19th, 2001. The x-axis is the hour of the day
(CDT time zone), while the y-axis is probe rate, the number
of different IP addresses seen, and a ﬁt to the data discussed in
the text.
compromise per unit time (K(1 − a)), times the incre-
ment of time (dt). (Note that machines can compromise
K others per unit time to begin with, but only K ·(1− a)
once a proportion of other machines are compromised