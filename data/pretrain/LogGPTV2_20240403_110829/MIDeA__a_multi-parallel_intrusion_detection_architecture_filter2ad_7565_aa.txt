title:MIDeA: a multi-parallel intrusion detection architecture
author:Giorgos Vasiliadis and
Michalis Polychronakis and
Sotiris Ioannidis
MIDeA: A Multi-Parallel Intrusion Detection Architecture
Giorgos Vasiliadis
FORTH-ICS, Greece
PI:EMAIL
Michalis Polychronakis
Columbia University, USA
PI:EMAIL
Sotiris Ioannidis
FORTH-ICS, Greece
PI:EMAIL
ABSTRACT
Network intrusion detection systems are faced with the challenge
of identifying diverse attacks, in extremely high speed networks.
For this reason, they must operate at multi-Gigabit speeds, while
performing highly-complex per-packet and per-ﬂow data process-
ing. In this paper, we present a multi-parallel intrusion detection
architecture tailored for high speed networks. To cope with the
increased processing throughput requirements, our system paral-
lelizes network trafﬁc processing and analysis at three levels, us-
ing multi-queue NICs, multiple CPUs, and multiple GPUs. The
proposed design avoids locking, optimizes data transfers between
the different processing units, and speeds up data processing by
mapping different operations to the processing units where they
are best suited. Our experimental evaluation shows that our proto-
type implementation based on commodity off-the-shelf equipment
can reach processing speeds of up to 5.2 Gbit/s with zero packet
loss when analyzing trafﬁc in a real network, whereas the pattern
matching engine alone reaches speeds of up to 70 Gbit/s, which
is an almost four times improvement over prior solutions that use
specialized hardware.
Categories and Subject Descriptors
C.2.0 [General]: Security and Protection
General Terms
Design, Performance, Security
Keywords
Intrusion Detection, Pattern Matching, Acceleration, GPU, NIDS
1.
INTRODUCTION
Network intrusion detection systems (NIDS) are commonly clas-
siﬁed into anomaly-based and signature-based systems. Anomaly-
based systems are used to detect unknown attacks, but usually gen-
erate false positives [8,42]. In contrast, signature-based systems are
typically more precise, but cannot detect attacks for which they do
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’11, October 17–21, 2011, Chicago, Illinois, USA.
Copyright 2011 ACM 978-1-4503-0948-6/11/10 ...$10.00.
not have a signature, and therefore, they require continuous updat-
ing [33, 36]. Due to their low false-positive rate and their higher
performance, signature-based detection approaches are the basis
for the majority of the existing NIDSs. Unfortunately, as the speed
of network links increases, keeping up with the inspection of all
trafﬁc becomes quite challenging.
A number of approaches have been proposed to address the prob-
lem of matching stateful signatures in high-speed networks, both
hardware and software based. Hardware-based implementations
offer a scalable method of inspecting packets in high-speed envi-
ronments [6, 9, 10, 24, 26, 27, 29, 45]. These systems usually consist
of special-purpose hardware, such as FPGAs, CAMs, and ASICs,
that is used to process network packets in parallel. Although the
use of specialized hardware achieves high processing rates, most
implementations require custom programming, and are usually tied
to the underlying device. As a consequence, they are very difﬁcult
to extend and reprogram. Additionally, most of these approaches
focus on the raw inspection of the network packets alone, with-
out implementing crucial functionalities of modern NIDSs, such as
protocol analysis and application-level parsing.
In contrast, software implementations based on commodity pro-
cessors are low-cost and easily programmable. The advent of multi-
core processors has lead researchers to employ them for high-speed
trafﬁc processing. Previous approaches have focused extensively
on multi-core general-purpose processors [19, 20, 37, 39, 47], in
which the NIDSs operations are decomposed to different process-
ing elements. Graphics processors have also been used to boost
computationally intensive tasks, like string searching [18, 41, 48]
and regular expression matching [49].
The majority of these approaches take advantage of parallelism
only at a single level, either through trafﬁc splitting [21, 47], ﬂow-
level parallelization [19, 20, 39], or content inspection [18, 41, 48,
49]. In practice, however, the performance of modern NIDSs de-
pends on several operations, including packet capture and decod-
ing, TCP stream reassembly, and application-level protocol analy-
sis. A scalable architecture must exploit parallelism for each op-
eration individually, otherwise Amdahl’s Law will fundamentally
limit the performance that the hardware can provide [34].
In this paper, we present MIDeA, a new model for network in-
trusion detection systems, which combines commodity, general-
purpose hardware components in a single-node design, tailored for
high-performance network trafﬁc analysis. Our system takes ad-
vantage of the parallelism offered by modern network interface
cards, multiple CPUs, and multiple GPUs, to improve scalabil-
ity and runtime performance. By mapping each operation to the
appropriate device, we implemented a NIDS with no serialized
components—no component needs to be synchronized and wait for
another component to ﬁnish its execution, or contend for a shared
297resource. This design allows for signiﬁcant performance gains.
On a single box, MIDeA performs stateful packet analysis and in-
spection at 5.2 Gbit/s, while the raw processing throughput of the
computationally-intensive pattern matching operations exceeds 70
Gbit/s when ofﬂoaded to the GPUs.
In summary, the main contributions of this work are:
• We introduce a novel multi-parallel architecture for high-
performance processing and stateful analysis of network traf-
ﬁc. Our architecture is based on inexpensive, off-the-shelf,
general-purpose hardware, and combines multi-queue NICs,
multi-core CPUs, and multiple GPUs.
• We present our prototype implementation based on Snort [36],
the most widely used open-source NIDS, demonstrating that
the proposed model is practical and can be adopted by exist-
ing systems.
• We present the design and implementation of a number of
system-level optimizations that improve end-to-end perfor-
mance. We demonstrate that our implementation scales well
with the number of processing units.
• We experimentally evaluate our prototype implementation
under various conﬁgurations, and show that commodity hard-
ware can be used effectively to drastically improve the per-
formance of trafﬁc processing applications. Our evaluation
on 10 Gbit/s links demonstrates a signiﬁcant increase in pro-
cessing throughput compared to existing approaches.
The rest of the paper is organized as follows. Section 2 presents
the design objectives and challenges of our proposed architecture.
In Section 3, we describe the architecture of our parallel network
intrusion detection system in detail. Section 4 presents optimiza-
tions implemented to overcome bottlenecks and reduce speciﬁc over-
heads. In Section 5, we thoroughly evaluate our architecture using
different benchmarks and workloads. In Section 6, we discuss the
limitations of our system and directions for future work. Finally,
we discuss related work in Section 7 and conclude in Section 8.
2. DESIGN OBJECTIVES
We begin by discussing the design principles and practical chal-
lenges of mapping the different functional components of a signature-
based network intrusion detection system to a multi-parallel system
architecture.
Inter-ﬂow Parallelism. Our aim is to design a NIDS architecture
that scales with the number of available processing units, enabling
it to operate at line-rates without packet loss. The primary role
of a NIDS is to passively capture the network packets through the
network interface (NIC), process them, and report any suspicious
events. Therefore, the main tasks of the NIDS can be summa-
rized as: (i) packet capturing, usually at multi-Gigabit rates, and (ii)
packet processing, including TCP stream reassembly, application-
level protocol parsing, and pattern matching.
In current hardware NIDS platforms [1, 44], packet processing
operates at line-rates, handling a single input port; therefore, the
platform must inspect input trafﬁc at several Gigabit per second.
Existing software-based NIDS, in contrast, typically follow a multi-
core approach and split the trafﬁc at the ﬂow-level to N slices,
where N is the number of processing nodes available to the sys-
tem [39, 47]. Flow-based partitioning achieves an almost even pro-
cessing load at all processing nodes, without requiring any intra-
node communication for processing operations that are limited in
scope to a single ﬂow. Trafﬁc is distributed using either an exter-
nal trafﬁc splitter—which is quite a costly solution—or a software-
based load-balancing scheme, where a simple hash function is ap-
plied on each captured packet, based on which it is assigned to the
appropriate node for processing.
Unfortunately, having many different cores receiving trafﬁc from
the same network interface or a shared packet queue, increases
contention to the shared resource, which incurs additional delay in
packet capturing [19, 20]. This observation leads us to our ﬁrst de-
sign principle: trafﬁc has to be separated at the network ﬂow level
using existing, commodity solutions, without incurring any serial-
ization on the processing path.
In Section 3, we show how our
system takes advantage of recent load-balancing technologies such
as Receive-Side Scaling (RSS) [3], which allows different cores to
receive portions of the monitored trafﬁc directly. This inherently
leads us to a multi-core architecture, in which each core runs a sep-
arate instance of the inspection engine, processing only a subset of
the network ﬂows.
Intra-ﬂow Parallelism. Distributing the monitored trafﬁc to dif-
ferent CPU cores offers signiﬁcant performance beneﬁts. Recent
studies [20,39] have shown a close-to-linear speedup in the number
of cores. However, the CPU is still saturated by the large number of
diverse and computationally heavy operations it needs to perform:
network ﬂow tracking, TCP stream reassembly, protocol parsing,
string searching, regular expression matching, and so on. The prob-
lem then is how to further parallelize content inspection on each
core, enabling a further increase in the overall trafﬁc processing
throughput, without incurring any packet loss.
This leads us to our second design principle: per-ﬂow trafﬁc pro-
cessing should be parallelized beyond simple per-ﬂow load bal-
ancing across different CPU cores. To enable such “intra-ﬂow”
parallelism, network packets from the same ﬂow have to be pro-
cessed in parallel, while also maintaining ﬂow-state dependencies.
In Section 3.2.2, we discuss how our system can take advantage of
multiple graphics processors to inspect high-volume trafﬁc concur-
rently with the CPU cores. Intra-ﬂow parallelism is achieved by
buffering incoming packets and transferring them to the graphics
card in large batches. Although this buffering scheme adds some
latency to the processing path, it pays off in terms of the processing
throughput that can be sustained.
By parallelizing both packet pre-processing and content inspec-
tion across multiple CPUs and GPUs, the proposed multi-parallel
NIDS architecture can operate at line rate in multi-Gigabit net-
works using solely commodity components. Our parallelization
scheme also leads to an architecture that is incrementally extensi-
ble in terms of hardware resources. We demonstrate that the over-
all processing throughput of the system can be increased simply by
adding more processing elements.
Resulting Trade-off. A potential issue of our design is the data
transfer operations that must take place between the memory ad-
dress spaces of each device. Speciﬁcally, network packets are trans-
ferred from the NIC to the main memory of the host, and from there
to the device memory of the GPU. However, the extra data trans-
fers between the CPU and the GPU over the PCIe bus can be worth
the computational gain offered by the GPU. To further mitigate this
data transfer overhead, we have implemented a pipelining scheme
that allows CPU and GPU execution to overlap, and consequently
hides the added latencies. Although the raw computational power
of the GPU offers enough performance beneﬁts even when con-
sidering all data transferring overheads, the pipelining scheme that
we introduce offers an additional level of parallelism to the over-
all execution path.
In Section 4, we discuss in detail how these
optimizations have been implemented in our system.
298Output
Detection Engines
Detection Engines
GPU 1
GPU 2
Preprocessors
Preprocessors
Preprocessors
Preprocessors
Preprocessors
Preprocessors
Preprocessors
Preprocessors
Packet decode
Packet decode
Packet decode
Packet decode
Packet decode
Packet decode
Packet decode
Packet decode
Core 1
Core 2
Core 3
Core 4
Core 5
Core 6
Core 7
Core 8
ring buffer
ring buffer
ring buffer
ring buffer
ring buffer
ring buffer
ring buffer
ring buffer
Rx
Queue
Rx
Queue
Rx
Queue
Rx
Queue
Rx
Queue
Rx
Queue
Rx
Queue
Rx
Queue
Driver
RSS (Resource Side Scaling)
10 Gbps NIC
Figure 1: MIDeA architecture.
3. ARCHITECTURE
In this section, we describe the overall design of our multi-parallel
network intrusion detection architecture. The key factors for achiev-
ing good performance are: (i) load balancing between processing
units, and (ii) linear performance scalability with the addition of
more processing units. Additionally, for high-performance packet
capturing we consider the use of only inexpensive commodity NICs.
As shown in Figure 1, the NIDS application is mapped to the dif-
ferent processing units using both task and data parallelism across
the incoming network ﬂows. In particular, the network interface
distributes the captured packets to the CPU-cores, ensuring ﬂow-
pinning and equal workload across the cores. Each CPU-core re-
assembles and normalizes the captured trafﬁc before ofﬂoading it
to the GPU for pattern matching. Any matching results are logged
by the corresponding CPU-core using the speciﬁed logging mech-
anism, such as a ﬁle or database.
This design has a number of beneﬁts: First, it does not require
any synchronization or lock mechanisms since different cores pro-
cess different data in isolation. Second, having several smaller data
structures (such as the TCP reassembly tables) instead of sharing a
few large ones, not only reduces the number of table look-ups re-
quired to ﬁnd a matching element, but also reduces the size of the
working set in each cache, increasing overall cache efﬁciency.
3.1 Packet Capturing
Our system uses 10GbE NICs, which are currently the state-of-
the-art general-purpose network interfaces. Capturing packets at
these rates is non-trivial and requires the coordinated effort of the
network controller and the multi-core CPUs.
3.1.1 Multiqueue NICs
To avoid contention when multiple cores access the same 10GbE
port, modern network cards can partition incoming trafﬁc into sev-
eral Rx-queues [28]. This allows each CPU core to access its own
hardware queue independently, while the NIC controller is respon-
sible for classifying incoming network packets and distributing them
to the appropriate queue. The Rx-queues are not shared between
the CPU cores, eliminating the need of synchronization. Each Rx-
queue is dedicated to a speciﬁc user-level process that is mapped
to a different core, as shown in Figure 1. Each user-level pro-
cess fetches packets from a single queue and forwards them to the
next processing module. The controller can set up a number of
Rx-queues equal to the number of available CPU cores (the Intel
82599EB Ethernet controller [2] that we used in our implementa-
tion supports up to 128 Rx-queues).
To avoid costly packet copies and context switches between user
and kernel space, we use the PF_RING network socket [11]. The
most efﬁcient way to integrate a PF_RING socket with a multi-
queue NIC is to dedicate a separate ring buffer for each available
Rx-queue [15]. Network packets of each Rx-queue are stored into a
separate ring buffer and are pulled by the user-level process through
DMA, without going through the kernel’s network stack.
We also take into consideration the interrupt handling of each
queue. In Linux, interrupts are handled automatically by the ker-
nel through the irqbalance daemon. This daemon is responsi-
ble for evenly distributing interrupts from each Rx-queue to CPU
cores, in a round-robin fashion. Unfortunately, this is not the opti-
mal solution for multi-core systems, because distributing the han-
dling of interrupts from a single Rx-queue to multiple cores re-
sults in cache invalidation and performance degradation [25]. This
means that irqbalance does not guarantee that the interrupt
of the next packet of the same ﬂow will be handled by the same
core. Therefore, we bind the interrupt handling of each Rx-queue
to a speciﬁc CPU core by setting the corresponding /proc/irq
/X/smp_affinity entry (where X is the IRQ number of each
Rx-queue, which can be obtained from /proc/interrupts).
2993.1.2 Load Balancing
A major implication when partitioning the incoming trafﬁc to
multiple instances is to guarantee that all packets of a speciﬁc ﬂow
will be processed by the same user-level process.
It is also im-
portant to distribute the load equally to the different processing
cores. Modern NICs [3] support hash-based (or ﬂow-based), and
address-based classiﬁcation schemes. In hash-based schemes, such
as Receive-Side Scaling (RSS), a hash function is applied to the
protocol headers of the incoming packets in order to assign them to
one of the Rx-queues. In address-based schemes, such as Virtual
Machine Device Queues (VMDQ), each Rx-queue is assigned a
different Ethernet address, to provide an abstraction of a dedicated
interface to guest virtual machines.
For our purposes, we choose the hash-based method. The hash
function, computed on the typical 5-tuple  achieves good distribu-
tion among the different queues. The RSS speciﬁcation [28] allows
the explicit parameterization of the tuple ﬁelds that will be used to
compute the hash. Unfortunately, current RSS-enabled network in-