iteration, i.e., the first instruction of N1, we label the top of the
path stack as the start of a new stack frame for a new event path,
and push the top index of the path stack onto the loop stack.
During the execution of the current iteration, the control-flow
events accumulate into the new stack frame as an event path, i.e.,
= {(N3, Np),(Np , N5)}. When this iteration reaches an end at
pidx1
the last instruction of N5, we compare the top event path pidx1 with
the event paths indexed by the elements of the loop stack above
the top-most ⊥. Because no other event path is indexed above the
top-most ⊥, we have not found path duplication at this time and
pidx1 is reserved. Then the second iteration starts from N1 to N5
= {(N4, Nu),(Nu , N5)} is accumulated on the path stack.
and pidx2
pidx2 is also reserved because it is a different event path compared
with pidx1. From the third iteration, the accumulated event path
pidx3 should be identical to either pidx1 or pidx2. Since duplicated
event path is found, we pop the top event path pidx3 and its index
idx3 from the path stack and loop stack respectively. Finally, when
the loop ends at the first instruction of N6, we pop the content of
the loop stack above the top-most ⊥. The two deduplicated event
paths {(N3, Np),(Np , N5)} and {(N4, Nu),(Nu , N5)} become a part
of the outer stack frame to continue the folding of the outer loop.
To fold the recursions, we firstly detect four kinds of points, the
start and return points of recursion function (r s, rd), the exter-
nal call sites to recursive functions (r e), and the external call-after
Figure 3: Folding Nested Loops
points of recursive functions (r x ), which stand for the end of recur-
sion. Considering the recursion program in Fig. 4b, at the external
call site to the function func, i.e. the last instruction of Nb, we
push a tag ⊥ onto the recursion stack which is an alias of loop stack
here. At the start and return points (r s, rd) of func, we instrument
deduplication actions to check if the currently accumulated top
event path (if exists) is identical to some other event path indexed
by the elements of the recursion stack above the top-most ⊥. If du-
plicated event paths are found, the top event path and its index are
popped from the path stack and recursion stack respectively. In con-
sequence, after pushing {(Nb , N1)} on the path stack, {(N3, N1)}
and {(N5, N4)} are pushed and deduplicated for many times. At
the end of the recursion, i.e. the start of Nx , another event path
{(N5, Nx)} is pushed and we pop the content of the recursion stack
above the top-most ⊥.
The loop stack and recursion stack are implemented with the
same data structure. This design can naturally deal with the inter-
leaving loops and recursions. There are recursion cases that cause
the above recursion folding approach to trigger false positives at the
verifier. Considering the recursion in Fig. 4c, when using the above
recursion folding, we derive a path {(Nb , N1),(N3, N1),(N7, N4),
(N5, Ne),(Ne , N7),(N7, N4),(N6, No),(No, N7),(N7, Nx)}. This path
contains four calls and five returns, thus will trigger a false alert of
CFI violation at the verifier. The reason is that from N4 to N7 there
are two subpaths of control-flow events, making the outer recursive
call (N3, N1) fail to match with the two (N7, N4). To avoid these
false positives, we use static analysis to detect if there are multiple
control-flow event paths from N4 to N7. The analysis is an offline
depth-limited depth-first traversal. If there is only one path from
N4 to N7, we apply the recursion folding; otherwise, we treat the
points Nb , N1, N7, and Nx as the ordinary points of control-flow
events to avoid folding this recursion.
2.3.3 Phase-3: Greedy Compression. The above recursion folding
requires static analysis to correctly locate the critical points for
instrumentation, which prevents our approach from being applied
on mutual recursion. We propose a path compression algorithm
to further reduce the size of control-flow events to be sent to the
verifier. The algorithm takes the sequence of control-flow events
generated by Phase-2 as input. The compression will insert several
leading knots for the compressed part of the sequence. For example,
if the control-flow event sequence is e1e2e3e4e2e3e4e5, the output of
the algorithm will be e1⟨2, 3⟩e2e3e4e5 where the knot ⟨2, 3⟩ means
the subsequent events with length 3 are repeated twice. The knots
are encoded as a number distinguishable from code addresses.
The compression algorithm is presented in Algorithm 1. p is the
input control-flow event sequence. r is the list to store the com-
pression result. BOU N D is the upper bound of a sliding window.
丄pidx1pidx2pidx3idx1idx2idx3…丄…⤹popped if (pidx1=pidx3)V(pidx2=pidx3)outer loop stk frameinner loop stk framepath stackloop stack314ReCFA: Resilient Control-Flow Attestation
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
(a) Loop Example
(b) Recursion Example
Algorithm 1: GreedyCompression(p, BOU N D)
idx ← 0; r ← [];
for posw ← 0 to lenдth(p) − 1 do
nr ep ← 0; szw ← 1;
while szw  lenдth(p) ∧ nr ep = 0 then
break;
end
for j ← 0 to szw ∧ poschk + j < lenдth(p) do
if p[posw + j] (cid:44) p[poschk + j] then
break;
end
end
if j = szw then
else
nr ep ← nr ep + 1;
else if nr ep = 0 then
szw ← szw + 1;
knot(r , idx, ⟨nr ep + 1, szw⟩);
r[idx ..(idx + szw)] ← p[posw ..(posw + szw)];
idx ← idx + szw ;
posw ← posw + szw ∗ (nr ep + 1);
nr ep ← 0; szw ← 1;
end
end
r[idx] ← p[posw];
idx ← idx + 1;
end
compress(r , idx);
(c) Excluded Recursion
Figure 4: Program Examples
The sliding window has a starting position posw and a size szw .
nr ep holds the times of repetition of the content in the sliding win-
dow. When the content in the sliding window is found repeated,
the algorithm iterates on the while-loop to capture the repeat-
ing times into nr ep. The predicate knot(r , pos, k) means attaching
knot number k at the position pos of the list r. The final predicate
compress(l, n) means compressing the size-n content in the list l,
as well as the attached knot numbers, with an off-the-shelf com-
pression algorithm, Zstandard [2] as reported to outperform other
compressions in [36]. We choose the greedy algorithm instead of
migrating from the Rabin-Karp rolling hashing because hash-based
comparison may introduce false positives. The complexity of the
algorithm is O(n × BOU N D). Also, the greedy matching tends to
fold short repeated subsequences instead of the longest ones for ef-
ficiency. For example, the event sequence e1e2e1e2e3e1e2e1e2e3 will
be compressed to ⟨2, 2⟩e1e2e3⟨2, 2⟩e1e2e3 instead of ⟨2, 5⟩e1e2e1e2e3.
A later step is to generate the key-based authentication code and
nonce for the compression results used in the procedure of ordinary
remote attestation, which is out of the scope of this work.
2.4 Context-Sensitive Remote Enforcement
The context-sensitive enforcement on the verifier relies on a shadow
stack. Traditional shadow stacks are located on the monitored ad-
dress space and need to be protected in safe memory regions, e.g.,
by segmentation with hardware or isolation with SFI. In contrast,
our shadow stack is held at the verifier side which is assumed under
protection and resisting the attack like [14].
Different from using the CFG for generating the measurements
[36], we use static binary-level arity-based CFG generated by Ty-
peArmor [37] directly as our security policy. The indirect jumps are
resolved by Dyninst [6]. Because we only monitor function calls,
indirect jumps, and returns at the prover, the control-flow edges
other than these edges are unnecessary for the verifier. To facilitate
the enforcement, we derive another mapping F statically for the
forward edges. The element of F is of form cs (cid:55)→ (ca, tдts). The
 N0,N1: for(int i=0; i<n; i++){ N2:  if(i%2==0){ N3:   privileged(); N4:  else unprivileged(); N5:  endif  } N6: ... Np: privileged() {...} Nu: unprivileged() {...} N2N3N4NpNuN5N6N1callretcallretN0ℓeℓxℓsℓd    Nb: res = func(3); Ne: ...  int func(int n) {   int result=0; N1:  if (n<=1) N2:   result=1;   else N3,N4:  result=n+func(n-1); N5:  return result;  } NbN1N2N3N5NecallretretcallN4rerxrsrd     N0,N1: for(int i=0; i<n; i++){ N2:  if(i%2==0){ N3:   privileged(); N4:  else unprivileged(); N5:  endif  } N6: ... Np: privileged() {...} Nu: unprivileged() {...} N2N3N4NpNuN5N6N1callretcallretN0ℓeℓxℓsℓd    Nb: res = func(3); Nx: ...  int func(int n) {   int result = 0; N1:  if (n <= 1) N2:   result = 1;   else N3,N4:  result = n + func(n-1); N5:  return result;  } NbN1N2N3N5NxcallretretcallN4rerxrsrd   Nb: res = func(3); Nx: ...  int func(int n) { N1:    int result;     if (n <= 1) { N2:       result = 1;     } else { N3,N4:    result = n + func(n-1);     if (n % 2 == 0) N5:       evenFunc();     else N6:       oddFunc();     } N7:    return result;  } Ne: evenFunc() {...} No: oddFunc() {...} NbN1N2N3N7NxretcallN4N5N6retNeNocallcallretretcall    N0,N1: for(int i=0; i<n; i++){ N2:  if(i%2==0){ N3:   privileged(); N4:  else unprivileged(); N5:  endif  } N6: ... Np: privileged() {...} Nu: unprivileged() {...} N2N3N4NpNuN5N6N1callretcallretN0ℓeℓxℓsℓd    Nb: res = func(3); Nx: ...  int func(int n) {   int result = 0; N1:  if (n <= 1) N2:   result = 1;   else N3,N4:  result = n + func(n-1); N5:  return result;  } NbN1N2N3N5NxcallretretcallN4rerxrsrd   Nb: res = func(3); Nx: ...  int func(int n) { N1:    int result;     if (n <= 1) { N2:       result = 1;     } else { N3,N4:    result = n + func(n-1);        if (n % 2 == 0) N5:          evenFunc();        else N6:          oddFunc();     } N7:    return result;  } Ne: evenFunc() {...} No: oddFunc() {...} NbN1N2N3N7NxretcallN4N5N6retNeNocallcallretretcall   315ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Yumei Zhang, Xinzhi Liu, Cong Sun, Dongrui Zeng, Gang Tan, Xiao Kan, and Siqi Ma
key cs is the call site address of a forward edge; ca is the address
of the call-after point of the call site and tдts is the set of valid
target addresses of the call. Different types of forward edges can
be identified in the mapping. For an indirect jump at address addr,
we encode it as addr (cid:55)→ (⊥, jmp_tдts). For a direct call at cs, we
encode it as cs (cid:55)→ (ca, ∅) because the target of a direct call can not
be counterfeited by our attacker model thus not monitored at the
prover.
The first step of the runtime enforcement is to recover the control-
flow event sequence by a reverse procedure of Phase-3 discussed in
Section 2.3, which is trivial due to the knot numbers. Then, for each
edge (s, t) in the recovered control-flow event sequence, we look
up s in the mapping F to decide if the edge is a forward edge. If it
is a direct call, we push the call-after point tracked from F onto the
shadow stack. If it is an indirect jump, we check if its runtime target
t is in the jmp_tдts tracked from F and report security violation
when t (cid:60) jmp_tдts. If it is an indirect call, after confirming its
runtime target t is in the valid targets tracked from F , we push
its call-after point onto the shadow stack. For the backward edge,
we check if its return target is identical to the top element of the
shadow stack.
A critical step for the correct enforcement is to recover the
skipped direct call sites from the control-flow event sequence. The
procedure is, for each consecutive event pair, e.g., eiei +1 in the
sequence, we recursively track the mapping M initially from ei to
find the subsequent skipped edge sequence of ei that reaches ei +1.
We apply the above enforcement strategies on these skipped edges
before the edge ei +1. For the example in Fig. 2b, after the enforce-
ment dealing with the return to 406416 (by matching 406416 with
and then popping the top of shadow stack), we look up 406416’s
value in the mapping M; in this case, 406416. It means the skipped
call at 406416 should be dealt with at once by tracking 406416 at
the mapping F .
The setjmp/longjmp breaks the calling convention to enable
non-local indirect jumps and challenges the shadow stack’s tracking.
To deal with this case, when we find the top expected return target
on the shadow stack mismatching the runtime return target from
the event sequence, we pop more elements iteratively from the
shadow stack for comparison until some element of shadow stack
matches the runtime return target, or the shadow stack becomes
empty. The latter case accounts for the control-flow hijacking.
3 IMPLEMENTATION
In this section, we elaborate implementation details of our approach.
Static analysis. Before the binary instrumentation, we conduct
static analysis on the program binary of the prover. The analysis is
still offline but is more efficient than measuring all the legitimate
control-flow paths as proposed in [4]. First, we derive a binary-level
CFG with TypeArmor [37]. We use this CFG to conduct the call-site
filtering of Section 2.3.1 and identify the list of skipped call sites.
Since our approach does not instrument the calls to the library func-
tions, we skip these calls before constructing the abstract graph G in
the filtering procedure. Then we derive mapping M for the skipped
call sites and mapping F for the forward edges. We store both
mappings at the verifier. In the call-site filtering, setjmp/longjmp
should be addressed in the static analysis. longjmp can lead to a
context that calls another function. If we skip longjmp as a library
function call, the predecessor of longjmp in G may mistakenly de-
cide its successor as skippable. Therefore, longjmp is treated as an
ordinary call in the call-site filtering. For the setjmp, there may
be many longjmp to the subsequent instructions of setjmp but we
cannot infer them. For the direct calls successive to the subsequent
instruction of setjmp, because we cannot infer their predecessors,
we conservatively treat them as unskippable.
Encoding control-flow edges. The encoding of different control-
flow events affects the amount of data delivered to the verifier. For
the indirect calls, indirect jumps, and return, the edges are encoded
as a pair of code addresses. For the unskippable direct calls, since
their target cannot be hijacked by the attacker model, we only
encode their call site, i.e., a single code address with a special tag
bit to identify the edge type.
Static Binary Instrumentation. We use Dyninst to instrument
the prover program. We target at x64 binaries. The first step is
to identify the specific program points for instrumenting differ-
ent functionalities. For the loop and recursion points used by the
control-flow events folding, we traverse the loop tree structures of
CFG with Dyninst to find the loop points. We detect direct recur-
sions by checking if a subroutine called by each function is itself.
We use the pattern of instruction operators to differentiate between
direct and indirect branches. For the direct calls, we only instru-
ment the unskippable direct calls based on the results of call-site
filtering. Capturing the runtime indirect branches with Dyninst is
straightforward. However, for the runtime return edge, the API of
Dyninst can only help to capture the return into the trampoline
section after instrumentation instead of into the original code sec-
tion. To recover the return target at the original code section, we
pair the return instruction of the callee with the call-after point in
the caller using a flip flag. The flag is set at the return instruction.
At the call-after point in the caller function, we pair this point with
the latest return only after confirming the flag is set. The flip flag
avoids the call-after point being captured mistakenly when it is a
jump target instead of a return target. Such prover-side flag-based
matching is to avoid wrongly recorded control-flow events of the
benign program. It does not detect the violation of backward-edge
CFI, which is left to the verifier.
In the implementation, the operations of capturing and folding
the control-flow events are held in and loaded from a shared object
file by the instrumented code. Although the shared object can be
linked to the enclave shared object and protected by SGX as the trust
anchor, in this work, we use a more lightweight system-call based
approach to ensure the instrumented code cannot be bypassed. To
protect the data structures (loop/recursion stack and path stack)
used by the control-flow events folding, we use Intel’s memory
protection keys (MPK) [22] to protect the writing of these data
structures in the userspace. As we know, ScaRR [36] chooses to
write the control-flow edges into the kernel space. However, we
do not take this approach due to the potential enormous context
switching cost for the control-flow events on an order of magnitude
in gigabytes. With the system-call based approach for code integrity
and MPK-based protection for data integrity, we can ensure the
integrity of CFA-data collection.
316ReCFA: Resilient Control-Flow Attestation
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
First, we attach the MPK operations into the instrumented code
snippets for recording the CFA data. Specifically, a code snippet first
enables the writing privilege to the CFA data region, then writes
data, and finally disables the writing privilege. We write the user-
accessible PKRU register with instrumented system calls, which
wraps the WRPKRU instruction, to switch the permission to the
memory region storing the CFA data. The MPK-based switching
does not provide strong memory protection since the attacker may
write the PKRU register and obtain the write permission to the CFA
data region. To ensure the execution of every code snippet cannot
be tampered with, we insert guards at the entry and exit points of
each instrumented code snippet to record the type of each snippet
and the guarded point in the snippet. For example, the loop entry
snippet starts with a call sys_rec(loop_entrystar t ) and ends with
a call sys_rec(loop_entryend). In all, a code snippet s1 looks like
“sys_rec(s1star t ), MPK-ops, data-ops, MPK-ops, sys_rec(s1end)”. At
the kernel level, we use a kernel thread to pair the consecutive
entry and exit guards with the same snipped type. The code reuses
exploiting the instrumented code will cause the kernel to detect
disordering and mismatching at the start- or end-point of the in-
strumented code snippet. For example, when an attacker hijacks
control flow and jumps inside the snippet s1, the guard s1end will
be executed but s1star t will be missing. With the guards, the only
possible bypass is to hijack control flow and jump out of a snippet
after the writing privilege is enabled. Then, the attacker corrupts
the CFA data and jumps back to the original snippet. Our solution
is to avoid indirect branches in snippets. Hence, the integrity of
code snippets is guaranteed and the memory corruption attacks
cannot lead to forged control-flow events.
4 EVALUATIONS
Our experiments are conducted on an elastic compute service with
2.5GHz×8 Intel Xeon(R) Platinum 8269CY CPU, 16GB RAM, Linux
4.15.0-135-generic kernel (Ubuntu 18.04 64-bit). To take no account
of the network latency, we run the prover and verifier on the same
machine. The network overhead is measured with the size of data
delivered between the prover and the verifier. The binaries are com-
piled respectively with GCC v7.5.0 and LLVM v10.0.0 under the
default optimization level. For the binary analysis and instrumenta-
tion, we use Dyninst 10.1.0. The commit id of TypeArmor we used is
ee018f0. The offline procedure is on the same machine. We applied
ReCFA on SPEC CPU 2006’s C benchmarks. To ensure standard
runtime input, we use the test workloads to run the instrumented
binaries of SPEC2k6 benchmarks.
RQ.1. Is the prover-side performance overhead reasonable?
We evaluate the control flows condensing procedure and reveal
the effect of each phase respectively. Firstly, we evaluate the call-
site reduction by the call-site filtering. We report the number of the
original direct calls and the skipped direct calls in the binary-level
CFG in Table 1. The ratio of reduction ranges 16.1%∼57.2% for GCC
binaries and 16.1%∼54.5% for LLVM binaries. The overall reduction
is around 40.5%.
To evaluate the control-flow event folding, we first report the
runtime overhead of instrumented program compared with the
original program. Then we evaluate the reduction on the control-
flow events compared with the case that the control-flow events
Table 1: Effect of Call-Site Filtering (reduction =
Σd-callskipped / Σd-callorig.)
GCC
LLVM
Program
400.perlbench
401.bzip2
403.gcc
429.mcf
433.milc
445.gobmk
456.hmmer
458.sjeng
462.libquantum