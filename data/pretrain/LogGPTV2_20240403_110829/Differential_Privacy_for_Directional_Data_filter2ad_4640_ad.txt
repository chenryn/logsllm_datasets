every time a distance equal to the circumference of the sphere
has been traversed; therefore, Polar Laplace can be regarded as
two-dimensional variant of the WL mechanism (cf. Section 3.6.2).
Angular density and expected distance. In order to compare the
Polar Laplace and Purkayastha mechanisms on the sphere S2, we
again use their angular densities as auxiliary. We simulated 64M
samples to approximate the angular density PolArc(𝜅)[𝜃] and its
expected value for 𝜃. We compare it with the (exact) solutions for
the three-dimensional Purkayastha angular density PurArc(3, 𝜅)[𝜃]
and its expected value, as provided in Eq. (9) and Theorem 22.
Figure 2b shows the angular densities of the Purkayastha and
Polar distributions. For all values of 𝜅, PurArc(3, 𝜅)[𝜃] is higher
near 𝜃 = 0 and approaches 0 as 𝜃 → 𝜋, whereas PolArc(𝜅)[𝜋] is
1Implementation in laplace.js at https://github.com/chatziko/location-guard.
2Solution formula from https://www.movable-type.co.uk/scripts/latlong.html.
Session 4D: Differential Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1211𝜅
n
o
i
t
a
r
t
n
e
c
n
o
C
0.0001
0.001
0.01
0.1
1.0
10.0
100.0
1000.0
128.7 138.5 89.3
129.2 137.4 89.0
128.3 138.5 89.6
127.4 137.8 90.3
126.9 139.4 91.3
119.3 134.6 87.5
113.0 132.9 82.9
47.4
41.0
51.4
2
3
4
88.1
88.7
88.7
89.0
91.2
88.4
83.8
41.4
5
65.2
65.6
65.1
65.8
67.2
65.9
62.5
34.5
6
67.1
67.4
67.4
67.0
68.7
68.1
64.7
35.5
7
52.6
52.8
52.9
52.7
54.5
54.1
50.8
30.5
8
52.6
52.1
50.9
52.1
53.3
53.6
51.0
30.3
9
43.1
42.9
43.6
42.4
44.4
44.5
41.8
26.2
10
36.7
36.9
36.8
36.5
38.1
38.3
36.6
23.6
12
37.3
43.5
37.7
43.6
37.1
43.7
37.3
43.4
38.9
45.2
38.6
44.8
36.8
42.9
26.7
23.9
13
11
Dimension 𝑛
32.4
32.3
32.3
32.1
33.7
33.7
32.0
21.5
14
33.1
33.1
32.6
32.7
33.6
34.2
32.5
21.7
15
19.7
19.8
19.7
19.6
20.2
20.8
20.2
14.8
25
4.966 0.873 0.447 0.084 0.041
9.8
5.002 0.882 0.449 0.084 0.043
9.8
4.994 0.905 0.444 0.088 0.041
9.8
5.222 0.901 0.443 0.088 0.042
9.9
10.1 5.312 0.880 0.441 0.085 0.041
10.9 5.318 0.911 0.454 0.085 0.041
10.0 5.202 0.917 0.457 0.084 0.041
4.534 0.846 0.415 0.077 0.040
8.5
100
50
5000 10000
1000
500
c
e
s
/
s
e
l
p
m
a
s
0
0
0
1
100
50
0
Figure 3: Sampling rate (×103) of the Purkayastha approximate inversion method (Algorithm 1) with various parameters.
strictly above 0. The expected angles of both spherical distributions
are shown in Figure 2c (orange lines) and approach 0 for 𝜅 → 𝜋.
As 𝜅 decreases from 𝜋 to 0, E𝜃∼PurArc[𝜃] steadily rises to 𝜋
2 and
approaches the uniform distribution. In contrast, E𝜃∼PolArc[𝜃] goes
up to over 1.7 at 𝜅 ≈ 0.6 (i.e., worse than the uniform distribution),
and only then falls back to 𝜋
To explain this phenomenon, consider the expected displacement
radius which amounts to E𝑟∼Γ(2,1/𝜅) [𝑟] =
𝜋 ≈ 0.637,
it is close to 𝜋, which is the farthest distance we can go from 𝒙 to
its antipodal point −𝒙 on S2; consequently, most random points
will end up on the “wrong” hemisphere. This raises the expected
angle E𝜃∼PolArc[𝜃] ≈ 1.733 to over 𝜋
2 for such 𝜅, indicating a point
of no return where the distribution’s mode reverses from 𝒙 to −𝒙.
Overall, these results indicate an advantage for Purkayastha over
Polar Laplace, particularly for 𝜅 ≈ 2
𝜋 .
2 , which is quite remarkable.
𝜅 . For 𝜅 ≈ 2
2
4 EXPERIMENTS
In this section, we experimentally verify the proposed methods. We
start by testing the efficiency of our novel Purkayastha sampling
algorithm, which is crucial for the Purkayastha mechanism. We then
apply our methods to real-world data: First, we analyze the impact of
the privacy mechanisms on the circular mean and ranking statistics.
Next, we consider temporal and spatial histograms from periodic
times-of-day and geolocations on a spherical coordinate system.
Finally, we compute “busyness” histograms indicating the activity
or popularity of certain locations, such as stores or restaurants, over
the course of a day, through a combined application of directional
privacy mechanisms to both spatial and temporal check-in data.
Implementation. We use Python 3 for our experiments. Arith-
metic and computations are based on numpy [32, 41] and scipy
[39]. For confluent hypergeometric and special functions, we rely
on the mpmath multi-precision library [22]. We implemented both
sampling algorithms, Algorithm 1 for Purkayastha and the VMF
rejection method by Ulrich [38] and Wood [44], with basic opti-
mizations such as vectorization and JIT compilation via Numba [28].
4.1 Sampling efficiency
To measure the efficiency of our proposed Purkayastha approximate
inversion method, we run our implementation of Algorithm 1 with
varying 𝑛 and 𝜅 for at least 60 seconds and count the number of gen-
erated samples. Based on the counts and elapsed times, we compute
the individual rate of samples per second. While single-threaded,
our implementation uses vectorization to work on multiple samples
simultaneously. The experiments were run in parallel on a 48-core
Xeon Platinum 8259CL system with each instance corresponding
to one parametrization (𝑛, 𝜅) of the PurArc distribution.
Results. Figure 3 shows the achieved sampling rate of our Pur-
kayastha approximate inversion method in thousands of samples
per second. We push beyond the status quo [7] by generating sam-
ples even in thousands of dimensions. Clearly, the rate decreases
with the dimensionality 𝑛 due to the increasing number of terms in
Eq. (10) that is used to compute PurArc(𝑛, 𝜅)[𝜃 ≤ 𝜗] (Corollary 23).
Another factor is the concentration parameter 𝜅: Larger values
decrease the sampling rate first slightly, and then more pronounced
for 𝜅 ≳ 100. However, with DP, we typically prefer low privacy
losses 𝜖 that correspond to small values of 𝜅 (cf. Section 3.5)—and
thus yield higher speeds.
Sampling rates of tens to over hundreds of thousands samples
per second clearly show that the Purkayastha approximate inver-
sion method is practical in the low- to medium-dimensional setting.
As the dimensionality 𝑛 gets larger, however, the sampling rate
decreases steadily until it will eventually become too low for the
method to be practical. As this is an intrinsic issue with the method
being based on formula whose complexity increases with 𝑛, it leaves
room for further research. Still, practical improvements to the cur-
rent approach are possible, for instance by porting the Python code
to a native language like C or parallelization on multiple cores.
Lastly, we note that even fewer than hundreds of samples per sec-
ond may be sufficient for many real-world applications, particularly
in the local model where each participant perturbs just their own
data (i.e., only few samples) prior to submitting it to a central server.
4.2 Circular mean on periodic data
The National Sleep Foundation (NSF) regularly conducts surveys of
US citizens on their sleep habits including questions on their bed
and wake times. Among the key reported figures in the surveys’
findings are the average wake and bed times; these times-of-day are
periodic on a 24-hour scale and hence provide a natural example of
directional data that is suitable for directional privacy.
Scenario and privacy models. Suppose we work for a polling
agency that wants to conduct a similar survey of sleeping habits,
but with formal privacy guarantees as offered by differential privacy.
The survey results with statistics such as average bed and wake
times shall be made public or shared with another third party. We
can distinguish two major approaches corresponding to the central
and local privacy models introduced in Section 2.1.
Session 4D: Differential Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1212In the central model, the survey participants trust the polling agency
to handle their sensitive data confidentially. Hence, they faithfully
report their unaltered answers to the agency. After collection of all
survey responses, the agency prepares the statistics from the origi-
nal data and applies appropriate privacy mechanisms to sanitize
the results, which can then be shared or made public.
The local model can provide a suitable alternative if the survey
participants do not trust the polling agency: Instead of providing
faithful answers, the respondents first sanitize their answers them-
selves before reporting the altered responses back to the agency.
From the collected obfuscated responses, the agency computes the
desired statistics that can be publicized afterwards.
Circular statistics. When taking the average or difference of peri-
odic data, it is not sufficient to simply take the arithmetic mean or
absolute distances. Instead, we must use periodic variants such as
the circular mean which works by averaging the direction vectors, or
the circular distance which takes the shortest path in any direction,
clock- or counterclockwise, so two times differ by at most 12 hours.
Let 𝒕 = (𝑡1 . . . , 𝑡𝑁) be a sequence of real numbers. We write the
usual arithmetic mean of 𝒕 as ∅(𝒕) = ∅(𝑡1, . . . , 𝑡𝑁) ≔
let us assume 𝒕 is periodic with period (circumference of the circle)
𝑝 > 0, i.e., each 𝑡𝑖 ∈ [0, 𝑝). Then the circular mean of 𝒕 is
∅𝑝(𝒕) = ∅𝑝(𝑡1, . . . , 𝑡𝑁) ≔
The circular difference between 𝑝-periodic values 𝑠 and 𝑡 is
𝑖 𝑡𝑖. Now
(cid:17)(cid:19)