Nonintrusive Monitoring of Microservice-based
Systems
Fa´bio Pina, Jaime Correia, Ricardo Filipe, Filipe Araujo and Jorge Cardoso
CISUC, Dept. of Informatics Engineering
University of Coimbra
Coimbra, Portugal
PI:EMAIL, PI:EMAIL, PI:EMAIL, PI:EMAIL, PI:EMAIL
Abstract—Breaking large software systems into smaller func- anomaly in hundreds or thousands of machines, with services
tionally interconnected components is a trend on the rise. This that have high elasticity and communicate with each other.
architecturalstyle,knownas“microservices”,simplifiesdevelop-
This huge increase in complexity, creates a herculean task for
ment,deploymentandmanagementattheexpenseofcomplexity
administrators.
andobservability.Infact,inlargescalesystems,itisparticularly
difficult to determine the set of microservices responsible for Therearesomemonitoringtools,thatduetotheirprovenca-
delaying a client’s request, when one module impacts several pabilities in standard systems, were also adopted in microser-
other microservices in a cascading effect. Components cannot
vice architectures. These tools — e.g. Nagios or Zabbix
be analyzed in isolation, and without instrumenting their source
—, normally monitor several infrastructure metrics, such as
code extensively, it is difficult to find the bottlenecks and trace
their root causes. To mitigate this problem, we propose a much CPU or memory usage, and include dashboards to provide
simpler approach: log gateway activity, to register all calls to an overview of the system, with functionalities to notify
and between microservices, as well as their responses, thus administrators when some rule or threshold is violated.
enabling the extraction of topology and performance metrics,
without changing source code. For validation, we implemented Othermonitoringplatforms,suchasNewRelic[2]orDyna-
the proposed platform, with a microservices-based application trace[3]areintrinsicallycoupledtotheprogramminglanguage
thatweobserveunderload.Ourresultsshowthatwecanextract and system to monitor, but offer an overall overview of the
relevant performance information with a negligible effort, even infrastructure. Other interesting approaches are Kibana[4]
in legacy systems, where instrumenting modules may be a very
or Grafana [5]. Kibana is used primarily to analyze logs
expensive task.
and Grafana is more prepared to analyze and create visual-
Index Terms—Black-box monitoring; Gateway; Microservices
izations of system metrics such as CPU or I/O utilization.
Since there is communication between several microser-
I. INTRODUCTION vices, a more powerful monitoring technique consists of
instrumenting all the modules, creating traceability for a
Microservice modules have become a trend in the develop-
particular request. Tracing normally propagates a correlation
mentofdistributedsystem.Thisnewparadigmevolveddueto
identifier that can be used to determine the flow through
a number of factors. First, standard monolithic systems were
several microservices. In other words, tracing allows system
difficult to maintain, deploy, develop and scale. Hence, there
administrators to determine the entire workflow of applica-
was the need to decompose these vertical systems in modules
tions. There are some frameworks that help to implement
that are function-oriented and that could be handled sepa-
tracing, such as ZipKin [6], Opentracing [7] or Dapper [8].
rately, in terms of development and management. Secondly,
Despite the benefits, tracing brings two major drawbacks.
microservicearchitecturesarebettersuitedfordeploymentand
First,allmicroservicesmusthavetracingimplementedandbe
operation in Docker [1] or other containers. Finally, method-
responsible to send the data to a central point. This platform
ologies in product development, such as Agile or DevOps,
gathers, processes and aggregates the raw data. Therefore,
with smaller teams that work independently, are more aligned
developers have to focus, not only on the business algorithm,
withmicroservicearchitectures.Therefore,microserviceshave
but also on monitoring and operation of the microservice.
tremendous benefits in term of development, operation, avail-
Secondly,thecentralpointmaybeasystembottleneck,dueto
ability and scalability, and have thus become a standard for
the large number of records. In fact, tracing systems normally
large-scale systems.
purge older samples or save only a small percentage of data.
Despite the aforementioned benefits, there are some chal-
Bearing in mind the aforementioned solutions, one could
lengestotackle.Oneofthesechallengesismonitoring.Inold
thinkthatadministratorshaveallthetoolstomonitorsystems.
monolithic systems, monitoring was restricted to the system,
However, in reality, operators use a plethora of platforms and
withastableinfrastructureandlittleelasticity.Inmicroservice
frameworks, some of them adopted from monolithic systems.
systems, administrators have to pinpoint the root cause of the
Thesetoolsonlygiveinsightsofwhatishappeninginthesys-
978-1-5386-7659-2/18/$31.00(cid:13)c2018IEEE tem,andistheadministrators’responsibilitytoendurethehard
task to navigate through several dashboards and notifications microservice A microservice B microservice C
toidentifytheproblem.Hence,microserviceshaveintroduced
a new paradigm to develop distributed systems, with well idx
defined functions and boundaries, but still use monitoring
techniquessimilartowhatwecouldfindinolderarchitectures.
idy
The approach we propose here is completely “black-box”,
Source
decoupling monitoring functionalities from function-oriented Source code Source
microservices. It is a solution that is neither invasive, nor code code
disruptive, as it requires no adaptations on the microservice
level. As a consequence, it is a good solution to already
implementedproductionsystems.Toachievethis,weusedand
adapted a gateway from Netflix, named Zuul [9], to collect
metrics from the requests made by the microservices. Based
inmetricssuchasresponsetime,originanddestinationofthe
requests, we aggregated the raw data in a concise output with
relevant information, such as average response time, topology
and overall service characterization. Tracing System
Our results show that we can obtain relevant and useful
Fig. 1: Tracing of microservices application (optimizations to
information to system administration, even though we use
reduce tracing messages omitted).
a non intrusive approach methodology. We do not need to
instrument microservices or add agents to the infrastructure,
resortingonlytocomponentsalreadyneededbymicroservices correlation, for example, an HTTP header with the same
modules.Therefore,thesolutionpresentedisuseful,viable— identifier (idx = idy). Unfortunately, this involves changing
specially in very dynamic and elastic systems —, and aligned thesourcecodeoftheapplication.Whilethistechniquecreates
with microservice methodology. several monitoring points, these are also additional points of
The rest of the paper is organized as follows. Section II failure and maintenance that couple monitoring with business
describes the problem we tackle and the method we used to logic. This goes against the microservice methodology, which
solve it. Section III describes the experimental settings. In followsthepremiseoffunction-orientedfine-grainedmodules.
SectionIVwepresentandevaluatethemeaningoftheresults, To eliminate the need for instrumentation, we follow a non-
the strengths of this approach and its limitations. Section V traditional approach. Knowing that microservices resort to
presents the related work. Finally, Section VI concludes the a gateway to make service discovery and redirect requests,
paper and describes future directions. we added the capability to collect some monitoring metrics
to this gateway. The idea is to make the gateway gather
II. PROPOSEDMETHODOLOGY information, such as response time, IP and port of origin and
destination, and the identification of the function that was
In this paper we tackle the problem of monitoring mi-
invoked.Thisapproachbringsadvantages,suchasdecoupling
croservice architectures. In vertical solutions, monitoring is
the monitoring system from the application without hindering
easier,becausetheapplicationdoesnotchangethatmuchover
systemscalability,becausethegatewayandassociatedservices
time. Microservice systems evolved from new development
are horizontally scalable.
methodologies,suchasAgileorDevOpsandnewdeployment
techniques, such as containers. System monitoring did not In the next subsections we describe our methodology in
follow this evolution and is still based on the applications and more detail. First, we present the architecture, and how we
techniques for monolithic systems. In Section V, we discuss incorporate our solution in Netflix modules. Secondly, we go
how major worldwide technological companies are struggling through the metrics we can collect in the gateway and discuss
with this fact, being forced to create customized platforms the information dashboards we can build with standard tools.
for their needs. Indeed, monitoring is a complex and difficult Finally, we present how we implemented and distributed the
problem in highly dynamic systems. tool.
We analyzed the monitoring problem from a different per-
A. Architecture
spective. A typical approach for monitoring would consists
of instrumenting or adding agents in as much layers as Inamicroserviceinfrastructure,itisacommonapproachto
possible, from hosts to middleware, up to the application solve the service discovery problem with a gateway. Hence, it
layer. Refer to Figure 1, which shows a sequence of three is very appealing to take advantage of this module to observe
microservices, where some function in A invokes a function the system. We resorted to three Netflix components: Zuul,
in B, which invokes a function in C. To bring the infor- Ribbon and Eureka, responsible for gateway, load balancing
mation of the interdependent invocations to the monitoring and registry of scalable service, respectively. These services
system, messages must carry some identifier that allows their allow us to gather metrics outside of the critical path, being
TABLEI.COLLECTEDMETRICS
Besidestandardplotswithaveragesandquartiles,e.g.,asin
Metric Type box-plots, this raw information allows us to create high-level
StartTime Long information about the system. For example, it is possible to
EndTime Long
dynamically extract topological information and characterize
Duration Long
the level of interaction among different microservices. Ad-
OriginIP String
OriginPort Integer ditionally, we can also calculate response times and load of
DestinationService String each microservice, inferring maximum capacity and quality-
DestinationInstance String
of-service of each module, to ensure correct dimensioning.
DestinationIP String
DestinationFunction String For the frontend layer of our monitoring system, we used
Grafana[5],anopenplatformforanalyticsandmonitoring,
highly flexible and customizable. To display a few more
an advantage to monitor microservice systems. In Figure 2,
complex plots, we used as a complement, graphics generated
we present the high level architecture.
using the R language — a common standard in the academic
Our methodology has four components, that are aligned field, for simulation and analysis, incorporating the output on
with microservice best practices, such as service discovery or Grafana.
containerization. First, the module “Metric Storage” gathers
metrics collected by the customized Zuul application. These C. Implementation
metrics are response time — in requests between services or
directly from the client —, IP and port of origin and destina- To validate our method, we made a fully nonintrusive
tion of the request, and function invoked on the destination implementation for the docker swarm container manage-
microservice. This module, also acts as a backend to the ment platform. The source-code and deployment instructions
“Frontend” module, where we display relevant information are available on GitHub [10] as open-source. Additionally,
such as response times, topology and characterization of it also contains the sample microservice application used in
services. our experimental validation, of Section III. The tool is easily
deployable in a system with Docker and Swarm Manager
The other two modules are associated with “Service Re-
installed. Since the monitoring tool needs an overlay net-
gistry” and “Failure Detection”. In this paper, we focused
work [11], the system must have this network created and
on docker containers [1], given its popularity. By analyzing
configured, to ensure the correct operation of our approach.
containerization, data description of containers and how the
container manager works, it is possible to fully automate Afterwards, the only parametrization needed is the name
the process of registry and failure detection. This give us of the overlay network. The remaining parameters may be
a tremendous advantage, since we do not need container defined with the default values without loss of functionality.
instrumentation. In this case, our module is notified when a To use our monitoring solution, one could download the