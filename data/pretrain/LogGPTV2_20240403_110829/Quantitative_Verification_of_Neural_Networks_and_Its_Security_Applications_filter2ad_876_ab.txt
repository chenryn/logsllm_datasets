samples from the test set can differ significantly from the total set
of trojaned inputs specified as in property P2.
Fairness. The right notion of algorithmic fairness is being widely
debated[24, 25, 30, 37, 52, 108]. Our framework can help quan-
titatively evaluate desirable metrics measuring “bias” for neural
networks. Consider a scenario where a neural network f is used to
predict the recommended salary for a new hire in a company. Hav-
ing been trained on public data, one may want to check whether f
makes biased predictions based on certain sensitive features such
as race, gender, or marital status of the new hire. To verify this,
one can count how often f proposes a higher salary for inputs
when they have a particular sensitive feature (say “gender”) set to
certain values (say “male”), given all other input features the same.
Formally, this property can be encoded for given sensitive features
xs1 ∈ x1, xs2 ∈ x2, where x = x1 ∪ x2, along with values s1, s2, as:
P3(x, y, xs1 , xs2 , s1, s2) = (xs1
= s2)∧
((x1 − xs1) = (x2 − xs2)) ∧ y1 = y2
= s1) ∧ (xs2
(P3)
Notice the NPAQ counts over all possible inputs where the non-
sensitive feature remain equal, but only the sensitive feature changes,
which causes no change in prediction. An unbiased model would
produce a very high count, meaning that for most inputs (or with
high probability), changing just the sensitive feature results in no
change in outputs. A follow-up query one may ask is whether
setting the sensitive feature to a certain input value, keeping all
other values the same, increases (or decreases) the output salary
P4(x, y, xs1 , xs2 , s1, s2) = (xs1
= s2)∧
((x1 − xs1) = (x2 − xs2)) ∧ y1 = HIGH ∧ y2 = LOW
= s2)∧
((x1 − xs1) = (x2 − xs2)) ∧ y1 = LOW ∧ y2 = HIGH
P5(x, y, xs1 , xs2 , s1, s2) = (xs1
(P4)
(P5)
= s1) ∧ (xs2
= s1) ∧ (xs2
prediction. This can be encoded as property P4 (or P5) below.
NPAQ can be used to quantitatively verify such properties, and
compare models before deploying them based on such estimates.
Section 6.4 presents more concrete evaluation details and interpre-
tation of BNNs trained on the UCI Adult dataset [2].
4 APPROACH
Recall that exact counting (as defined in NQV) is #P-hard. Even
for approximate counting, many widely used sampling-based ap-
proaches, such as based on Monte Carlo methods [51, 53, 58, 74], do
not provide soundness guarantees since existence of a method that
only requires polynomially many samples computable in (random-
ized) polynomial time would imply N P = RP (See Remark 1). For
sound estimates, it is well-known that many properties encodable
in our framework require intractably large number of samples—for
instance, to check for distributional similarity of two networks f1
and f2 in the classical model, a lower bound of O(√
2x) samples are
needed to obtain estimates with reasonable (ϵ, δ) guarantees. How-
ever, approximate counting for boolean CNF formulae has recently
become practical. These advances combine the classical ideas of
universal hashing with the advances in the Boolean satisfiability
by invoking SAT solvers for NP queries, i.e., to obtain satisfiable
witnesses for queried CNF formulae. The basic idea behind these
approximate CNF counters is to first employ universal hashing to
randomly partition the set of solutions into roughly small buckets.
Then, the approximate counter can enumerate a tractably small
number of witnesses satisfying P using a SAT solver within one
bucket, which calculates the “density” of satisfiable solutions in
that bucket. By careful analysis using concentration bounds, these
estimates can be extended to the sum over all buckets, yielding a
provably sound PAC-style guarantee of estimates. Our work lever-
ages this recent advance in approximate CNF counting to solve the
problem of (ϵ, δ)-NQV [92].
The Equi-witnessability framework. Our key technical advance
is a new algorithmic framework for reducing (ϵ, δ)-NQV to CNF
counting with an encoding procedure that has provable soundness.
The procedure encodes N and P into φ, such that model counting
in some way over φ counts over N ∧ P. This is not straight-forward.
For illustration, consider the case of counting over boolean circuits,
rather than neural networks. To avoid exponential blowup in the
encoding, often one resorts to classical equisatisfiable encoding [99],
which preserves satisfiability but introduces new variables in the
process. Equisatisfiability means that the original formula is satisfi-
able if and only if the encoded one is too. Observe, however, that
this notion of equisatisfiability is not sufficient for model counting—
the encoded formula may be equisatisfiable but may have many
more satisfiable solutions than the original.
We observe that a stronger notion, which we call equi-witnessability,
provides a principled approach to constructing encodings that pre-
serve counts. An equi-witnessability encoding, at a high level, en-
sures that the model count for an original formula can be computed
by performing model counting projected over the subset of variables
in the resulting formula. We define this equi-witnessability relation
rigorously and prove in Lemma 4.2 that model counting over a con-
straint is equivalent to counting over its equi-witnessable encoding.
Further, we prove in Lemma 4.3 that the equi-witnessability relation
is closed under logical conjunction. This means model counting over
conjunction of constraints is equivalent to counting over the con-
junction of their equi-witnessable encodings. Equi-witnessability
CNF encodings can thus be composed with boolean conjunction,
while preserving equi-witnessability in the resulting formulae.
With this key observation, our procedure has two remaining sub-
steps. First, we show equi-witnessable encodings for each neural
net and properties over them to individual equi-witnessability CNF
formulae. This implies ψ, the conjunction of the equi-witnessability
CNF encodings of the conjuncts in φ, preserves the original model
count of φ. Second, we show how an existing approximate model
counter for CNF with (ϵ, δ) guarantees can be utilized to count
over a projected subset of the variables in ψ. This end result, by
construction, guarantees that our final estimate of the model count
has bounded error, parameterized by ε, with confidence at least
1 − δ.
Formalization. We formalize the above notions using notation
standard for boolean logic [15, 42, 62, 75]. The projection of an
assignment σ over a subset of the variables t, denoted as σ|t, is an
assignment of t to the values taken in σ (ignoring variables other
than t in σ).
witnessable to a formula ψ : u → {0, 1} where t ⊆ u, if:
Definition 4.1. We say that a formula φ : t → {0, 1} is equi-
(a) ∀τ |= φ ⇒ ∃σ ,(σ |= ψ) ∧ (σ|t = τ), and
(b) ∀σ |= ψ ⇒ σ|t |= φ.
An example of a familiar equi-witnessable encoding is Tseitin [99],
which transforms arbitrary boolean formulas to CNF. Our next
lemma shows that equi-witnessability preserves model counts. We
define R(ψ) ↓ t, the set of satisfying assignments of ψ projected
over t, as {σ|t : σ |= ψ}.
Lemma 4.2 (Count Preservation). If ψ is equi-witnessable to φ,
then |R(ψ) ↓ t| = |R(φ)|.
Proof. By Definition 4.1(a), for every assignment τ |= φ, there
is a σ |= ψ and the σ|t = τ. Therefore, each distinct satisfying
assignment of φ must have a unique assignment to σ|t, which
must be in R(ψ) ↓ t. It follows that |R(ψ) ↓ t| ≥ |R(φ)|, then. Next,
observe that Definition 4.1(b) states that everything in R(ψ) ↓ t has a
satisfying assignment in φ; that is, its projection cannot correspond
to a non-satisfying assignment in φ. By pigeonhole principle, it must
be that |R(ψ) ↓ t| ≤ |R(φ)|. This proves that |R(ψ) ↓ t| = |R(φ)|. □
Lemma 4.3 (CNF-Composibility). Consider φi : ti → {0, 1} and
ψi : ui → {0, 1}, such that φi is equi-witnessable to ψi , for i ∈ {1, 2}.
If u1 ∩ u2 = t, where t = t1 ∪ t2, then φ1 ∧ φ2 is equi-witnessable to
ψ1 ∧ ψ2.
(a) ∀τ |= φ1 ∧ φ2 ⇒ (τ |= φ1) ∧ (τ |= φ2). By
Proof.
Definition 4.1(a), ∃σ1, σ2, σ1 |= ψ1 ∧ σ2 |= ψ2. Further, by
= τ|t1 and σ2|t2
= τ|t2. This implies
Definition 4.1(a), σ1|t1
= τ|t1∩t2. We can now define the
= σ2|t1∩t2
that σ1|t1∩t2
x1
x2
x3
v1
v2
v3
v4
v5
Cardinality Constraints:
x1 + x2 + x3 ≥ 2 ⇔ v1 = 1
x1 + x2 + x3 ≥ 1 ⇔ v2 = 1
x1 + x2 + x3 ≥ 1 ⇔ v3 = 1
x1 + x2 + x3 ≥ 1 ⇔ v4 = 1
x1 + x2 + x3 ≥ 1 ⇔ v5 = 1
v1 + v2 + v3 + v4 + v5 ≥ 5 ⇔ y
x1
0
0
0
0
1
1
1
1
x2
0
0
1
1
0
0
1
1
x3
0
1
0
1
0
1
0
1
f (x)
0
0
0
1
0
1
0
1
y
Cardinality Constraints:
x1 + x2 + x3 ≥ 1 ⇔ v5
v1 + v2 + v3 + v4 + v5 ≥ 5
⇔ y
f1 : v2 = v3 = v4 = 1
f2 :x1 + x3 ≥ 2 ⇔ v1
x1 + x2 + x3 ≥ 1 ⇔ v2
x1 + x2 + x3 ≥ 1 ⇔ v3
x1 + x2 + x3 ≥ 1 ⇔ v4
x1
0
0
0
0
1
1
1
1
x2
0
0
1
1
0
0
1
1
x3
0
1
0
1
0
1
0
1
f1(x)
0
0
0
1
0
1
0
1
f2(x)
0
0
0
0
0
1
0
1
Figure 1. Example of encoding different BNNs (f , f1, f2) as a conjunction over a set of cardinality constraints. An attacker
manipulates f with the goal to increase the inputs with trigger x3 = 1 that classify as y = 0. Specifically, to obtain f1 the
weights of x1, x2, x3 in constraints of f for v2, v3, v4 are set to 0 (highlighted with dashed lines, on the left). To obtain f2, we set
w21 = 0. The trojan property P (cid:17) (y = 0) ∧ (x3 = 1) is satisfied by one input (left) for f , whereas for f2 we find two (right).
Table 1. BNN definition as a set of layers of transformations.
A. Internal Block fblkk (vk) = vk +1
1) Linear Layer
tlin
i
= ⟨vk , wi⟩ + bi
σ1 ⊗ σ2 = σ1|u1−t1 ∪ σ2|u2−t2 ∪ (σ1|t ∩ σ2|t). Since (u1 − t)
∩ (u2 − t) is empty (the only shared variables between
u1 and u2 are t), it follows that σ1 ⊗ σ2 |= ψ1 ∧ ψ2 and
that (σ1 ⊗ σ2)|t = τ. This proves part (a) of the claim that
φ1 ∧ φ2 is equi-witnessable to ψ1 ∧ ψ2.
(b) ∀σ |= ψ1 ∧ψ2 ⇒ (σ |= ψ1)∧(σ |= ψ2). By Definition 4.1(b),
|= φ2. This implies σ|t
σ|t1
|= φ1 ∧ φ2,
thereby proving the part (b) of the definition for the claim
that φ1 ∧ φ2 is equi-witnessable to ψ1 ∧ ψ2.
|= φ1 and σ|t2
□
Final count estimates. With the CNF-composability lemma at
hand, we decompose the counting problem over a conjunction
of neural networks N and property P, to that of counting over
the conjunction of their respective equi-witnessability encodings.
Equi-witnessability encodings preserve counts, and taking their
conjunction preserves counts. It remains to show how to encode
N to boolean CNF formulae, such that the encodings are equi-
witnessable. Since the encoding preserves counts originally de-
sired exactly, we can utilize off-the-shelf approximate CNF coun-
ters [21, 92] which have (ϵ, δ) guarantees. The final counts are
thus guaranteed to be sound estimates by construction, which we
establish formally in Theorem 5.5 for the encodings in Section 5.
Why not random sampling? An alternative to our presented
approach is random sampling. One could simply check what frac-
tion of all possible inputs satisfies φ by testing on a random set
of samples. However, the estimates produced by this method will
satisfy soundness (defined in Section 2) only if the events being
measured have sufficiently high probability. In particular, obtaining
such soundness guarantees for rare events, i.e., where counts may
be very low, requires an intractably large number of samples. Note
that such events do arise in security applications [17, 105]. Special-
ized Monte Carlo samplers for such low probability events have
been investigated in such contexts [105], but they do not provide
soundness guarantees. We aim for a general framework, that works
irrespective of the probability of events measured.
5 NPAQ DESIGN
Our tool takes as input a set of trained binarized neural networks
N and a property P and outputs “how much" P holds over N with
(ϵ, δ) guarantees. We show a two-step construction from binarized
where i = 1, ..., nk +1, wi is the ith column in Wk ∈
{−1, 1}nk×nk +1, b is the bias row vector ∈ Rnk +1 and
y ∈ Rnk +1
2) Batch Normalization
i − µki
tlin
σki
tbn
i =
· αki
+ γki
where i = 1, ..., nk +1, αk is the kth weight row vector ∈
Rnk +1, γk is the bias ∈ Rnk +1, µk ∈ Rnk +1 is the mean and
σk ∈ Rnk +1 is the standard deviation.
3) Binarization
i ≥ 0 ⇒ vk +1i
tbn
i < 0 ⇒ vk +1i
tbn
where i = 1, ..., nk +1.
B. Output Block fout(vd) = y
1) Linear Layer
= 1
= −1
i = ⟨vd , wj⟩ + bi
qlin
where vd ∈ {−1, 1}nd , wj is the jth column ∈ Rnd×s, b ∈
Rs is the bias vector.
2) Argmax
yi = 1 ⇔ i = arg max(qlin)
(1)
(2)
(3)
(4)
(5)
(6)
neural nets to CNF. The main principle we adhere to is that at every
step we formally prove that we obtain equi-witnessable formulas.
While BNNs and, in general, neural nets can be encoded using
different background theories, we choose a specialized encoding of
BNNs to CNF. First, we express a BNN using cardinality constraints
similar to [73] (Section 5.1). For the second step, we choose to