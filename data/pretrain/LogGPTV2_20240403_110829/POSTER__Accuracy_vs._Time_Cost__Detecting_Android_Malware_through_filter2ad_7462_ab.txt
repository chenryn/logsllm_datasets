8: return T =
opt.sel = arg minTt∈P E (Tt) +w j · |Tt|
(cid:3)
P : the ensemble with the highest accuracy of each group
(2)
opt.sel, . . . , T
(1)
opt.sel, T
(l)
opt.sel
(j)
T
(l)
opt.sel
.
(cid:2)
T
.
As shown in Algorithm 1, the ensemble pruning process takes as
input the training dataset, the validation set, and outputs the pruned
ensembles that minimize the combined loss with wi. g(N1) de-
notes that the training set for each base learner is randomly chosen
from N1 in an out-and-in manner. The base classiﬁers of different
groups are generated on different training sets using SVM. We im-
plement the PEP algorithm [4] to solve the bi-objective optimiza-
tion problem, and return a Pareto optimal ensemble set I for each
group. The idea behind PEP solver is that it randomly selects an en-
semble from the base classiﬁer pool, denoted as t ∈ {0, 1}m, stores
it in P , and ﬂips each bit with probability 1
. The
(cid:3)
. If
goal is to evaluate if there exist solutions in P that dominate t
it is true, it continues this process without augmenting P ; other-
(cid:3)
into
wise it excludes the ones that are dominated by t
P . From the second selection on, it selects an ensemble each time
from P , ﬂips, and generates another ensemble. This process is it-
erative until it reaches the upper-bound of iteration times. Finally,
P contains the Pareto solutions. We then pick out the ensembles
with the highest accuracy of each group P = {p1, p2, . . . , p5}
(see line 4 in Algorithm 1) to determine the ﬁnal ensembles with
different trade-off levels.
(cid:3)
m and generates t
and adds t
(cid:3)
17493. EMPIRICAL EVALUATION
The goal of our experiments is to examine the relation between
accuracy and time cost of real-time analysis.
3.1 Dataset and Setup
The 4,000 benign samples are downloaded from Google Play
Store, and the 4,000 malicious samples are from [2]. Following the
methodology of [2], we select 155 features in total to perform a
binary classiﬁcation. Four types of features are shown below:
• Permission. Android required permission for each app can
be extracted from the AndroidManifest ﬁle. It is often used
as a metric to detect malware. We ﬁnally select 59 out of the
original 120 permissions.
• Sensitive API Calls. API calls are extracted from the smali
ﬁles that are generated by decompiling the APKs. We ﬁnally
select 90 out of the 240 extracted sensitive API calls.
• Sequence. Sequence is extracted from smali ﬁles by record-
ing the number of sensitive API calls requested by the
malicious apps and the benign ones, respectively. Three
quantitive metrics are applied to extract features, which are
“Subtraction-Differential” metric, “Logarithm-Differential”
metric, and “Subtraction-Logarithm” metric [2].
• Dynamic Behavior. Dynamic behavior observes the mali-
cious activities triggered by each application through ana-
lyzing the log ﬁles of DroidBox [2].
We automatically generate the base classiﬁers on each training
set using SVM, whereby we prune the base classiﬁers and calculate
the error rate on the validation set. The size of the base classiﬁer
pool is n (n = 10, 20, . . . ,50 of each group in our experiment).
when dealing with the bi-
Iteration times is set to be
objective solver [4].
3.2 Accuracy vs. Time Cost
n2 log n
(cid:4)
(cid:5)
Table 1 shows that ensemble pruning takes more time to obtain
an optimal ensemble when pursuing higher accuracy. To trade off
the two objectives, provided by a trade-off level w, we select the
ﬁnal ensemble that minimizes the combined loss (i.e., E (Tt) + w ·
|Tt|). For example, as shown in Figure 2, given different trade-off
levels, w = 0.0006 and w = 0.00025. The ﬁnal ensembles are the
p2 and p4 accordingly, minimizing the combined errors.
Table 1: Accuracy vs. Time Cost
# Group Size
Time (sec)
10
20
30
40
50
60
460
1,546
3,654
7,450
Accuracy
93.40%
94.20%
94.70%
95.00%
95.20%
Note that accuracy column indicates the highest accuracy of each group.
(cid:7)
3.3 Discussion
(i) Dependency on bi-objective Pareto optimization solver. The
ensembles selected by Algorithm 1 highly rely on the performance
solver used is expected to O (cid:6)
of the bi-objective solver. The computational complexity of the
, indicating that the expected
O (cid:6)
iterations for generating the approximating optimal Pareto set is
, where k is the size of the base classiﬁer pool. More-
over, the solver [4] has been proved to be more effective than other
ensemble pruning methods, thereby rendering the performance of
our approach relatively reliable.
(ii) Limitations of ensemble pruning process. Since we use Bag-
ging to obtain our base classiﬁers, the random out-and-in strategy
k2log k
k2log k
(cid:7)
e
t
a
r
r
o
r
r
E
0
7
0
.
0
5
6
0
0
.
0
6
0
.
0
5
5
0
.
0
0
5
0
.
0
5
4
0
.
0
p1
G
0.07=y+0.0006x
p2
G
0.060=y+0.00025x
p3
G
p4
G
Pareto Set P
p5
G
0
10
20
30
40
50
60
Number of base classifiers to be pruned
Figure 2: An example of selecting an optimal from Pareto solu-
tions
of selecting the training set may cause some randomness in each
training process. Different size of the training set and different it-
eration times of the Pareto ensemble pruning may affect the perfor-
mance of the pruned ensembles. We therefore conduct our experi-
ment n times to choose the best size and iteration times to ensure
our experimental results reliable.
4. CONCLUSION
In this paper, we proposed a malware detection system, termed
Begonia, through Pareto ensemble learning to trade off classiﬁca-
tion accuracy and time cost. (We only consider the pruning time
in this paper, since prediction time is so small as to be negligible.).
Experimental results show that Begonia can trade off accuracy and
time cost when given a desirable trade-off level and achieve a rel-
atively higher accuracy with relatively lower overhead. Only time
will tell whether Begonia can be highly effective either as a stan-
dalone system or as a complementary technique to contemporary
tools to overcome the limitations of traditional anti-malware solu-
tion in detecting the zero-day and modern malware.
Acknowledgements
This work was supported in part by the National Natural Sci-
ence Foundation of China, under Grant 61502170, 61272444,
61411146001, U1401253, and U1405251,
in part by the Sci-
ence and Technology Commission of Shanghai Municipality under
Grant 13ZR1413000, and in part by Pwnzen Infotech Inc.
5. REFERENCES
[1] D. Arp, M. Spreitzenbarth, M. Hubner, H. Gascon, and
K. Rieck. Drebin: Effective and explainable detection of
android malware in your pocket. In NDSS, 2014.
[2] S. Chen, M. Xue, Z. Tang, L. Xu, and H. Zhu. Stormdroid: A
streaminglized machine learning-based system for detecting
android malware. In Proceedings of the 11th ACM on Asia
CCS, pages 377–388. ACM, 2016.
[3] K. N. Khasawneh, M. Ozsoy, C. Donovick, N. B.
Abu-Ghazaleh, and D. V. Ponomarev. Ensemble learning for
low-level hardware-supported malware detection. In RAID,
2015.
[4] C. Qian, Y. Yu, and Z.-H. Zhou. Pareto ensemble pruning. In
AAAI, 2015.
[5] C. Smutz and A. Stavrou. When a tree falls: Using diversity in
ensemble classiﬁers to identify evasion in malware detectors.
In NDSS, 2016.
1750