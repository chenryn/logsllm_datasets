residential networking devices as they meet at least one of the fol-
lowing criteria as shown in Table 2: (i) HTTP probes to the de-
vice show that the Web server reports itself as RomPager, which
is a well-known software package for creating Web interfaces in
embedded devices, (ii) HTTP probes to the device show the use
of basic authentication with a realm indicating a likely home de-
vice (e.g., “3068 DSL-2641R”), (iii) the IP address is listed in the
Spamhaus PBL, or (iv) the device replies to a DNS probe from a
port other than the port to which the probe was directed. We spec-
ulate that the ﬁnal criteria is caused by a low-end NAT device that
is performing translation on its own packets. Together, these indi-
cators provide supporting evidence that the ODNSes we discover
are overwhelmingly low-end network devices residing in residen-
tial settings.
5.1 ODNS Discovery
The fundamental aspect of discovery is ﬁnding ODNSes since,
as we will show, these are the windows into the client-side DNS in-
frastructure. Several projects leverage full scans of the Internet ad-
dress space [1, 13] to understand the prevalence of open resolvers.
However, we are interested not only with discovering the existence
of ODNSes, but also with understanding their characteristics and
behavior, which entails sending far more requests than discovery
would dictate (as detailed in subsequent sections). Additionally,
we ﬁnd—as previously developed in the literature [8,13]—the win-
dow of accessibility for ODNSes to be in general fairly short (see
below). Therefore, we must do in-depth probing in conjunction
F
D
C
1
0.8
0.6
0.4
0.2
0
1
30M
20M
10M
d
e
r
e
v
o
c
s
i
d
s
e
S
N
D
O
f
o
r
e
b
m
u
N
0
0
256
Random IP
Scan on First Hit
1B
2B
Number of probes sent
3B
4B
Number of ODNSes per /24 IP address block
10
100
Figure 2: Distribution of ODNSes per /24 IP address block,
excluding empty blocks.
with ODNS discovery as returning to the given address later may
well be fruitless. Finally, our probing rate has to result in a man-
ageable load on the ADNS—both the server itself and the host-
ing network—where ultimately the measurement trafﬁc converges.
For our ADNS, the resource constraints and desire to ﬁnish exper-
iments in a reasonable time frame necessitates a partial scan. The
key questions that arise from this choice involve (i) understanding
the effectiveness of randomly probing arbitrary IP addresses with
DNS requests in the hope of stumbling upon ODNSes, and (ii)
whether there are probing strategies to improve the efﬁciency of
this process.
Our ﬁrst observation is that ODNSes are unevenly distributed
throughout IP space. As sketched above, in S3 we choose and
probe random /24 address blocks. We ﬁnd that only 14% of these
blocks contain ODNSes. Further, as Figure 2 shows, the distri-
bution of ODNSes among the blocks that have some ODNSes is
uneven. We ﬁnd a small number of “dense” blocks with many
ODNSes. For instance, the top 10% of the address blocks each
contain over 30 ODNSes while 40% of the blocks have no more
than two ODNSes. The average across all blocks with at least one
ODNS is approximately 13 ODNSes per /24 block.
Discovery within such a sparse address space requires extensive
scanning. For collecting a sample of ODNSes with a partial scan,
we examine two methods of ODNS discovery. The ﬁrst method
is a random scanning of IP addresses labeled “Random IP”. The
second method, “Scan on First Hit”, acts like “Random IP” but,
once an ODNS is discovered, proceeds to scan the entire /24 block
in which the ODNS resides. This latter method utilizes the above
observation of uneven ODNS distribution among /24 blocks to in-
crease the ODNS discovery rate.
To compare the two methods fairly, we simulate both of them
based on the same dataset from the S3 scan using the following
methodology. We consider the Internet’s 232 IP addresses divided
into 224 /24 blocks. We mark a random 14% of /24 blocks as
“productive” —which as previously discussed is the fraction of /24
blocks found to contain at least one ODNS server—and in each
productive block we mark a number of IP addresses as ODNS ac-
cording to the distribution from Figure 2. ”Random IP” is then
simulated by selecting randomly without replacement from the full
232 address range and counting the rate of discovering ODNS. For
“Scan on First Hit”, we again select an address randomly without
replacement. If the selected address is an ODNS, we count not only
this address, but also all addresses marked as ODNS in the encom-
passing /24 block and remove the block from the address pool for
further selection.
Figure 3: ODNS discovery rate versus DNS requests sent (ex-
trapolation from the S3 scan to the Internet scale).
Figure 3 shows the discovery rate for both methods. We ﬁnd
a drastically higher initial discovery rate using the “Scan on First
Hit” strategy, which maintains its advantage for all scan sizes un-
til the techniques converge to discover the entire set of ODNSes
with a complete scan. The discovery rate of “Scan on First Hit” de-
creases over time. The reason is that the more dense a /24 address
block is the higher the probability of ﬁnding an ODNS; therefore,
dense /24 address blocks have a greater chance of being discov-
ered early. The purely random scan shows steady progress across
the entire scan but is overall less productive for limited scans. As
noted above, only 14% of the /24 blocks contain ODNSes. So,
the random scan misses opportunities to learn about the “neighbor-
hood” when ﬁnding an ODNS and chances are that neighborhood
is populated with additional ODNSes.
While the “Scan on First Hit” strategy discovers more ODNSes
with fewer probes, it has a downside in that it introduces a bias in
the set of discovered ODNSes. Blocks with higher concentrations
of ODNSes have a greater chance of being discovered, thus bias-
ing the resulting dataset towards ODNS in well-populated address
blocks. Thus, when using this efﬁcient discovery method, one must
consider implications of its bias. We consider effects of this bias on
our results in §8.
5.1.1 Rediscovery and Whitelisting
ODNSes have previously been found to be short lived [8,13] and
we conﬁrm these results. In our S6 scan conducted from 2/26/2013
through 3/28/2013 we repeatedly probe discovered ODNSes for a
period of 1M seconds after discovery. Details of the S6 scan and the
intervals at which the ODNSes were probed are discussed in §7. As
shown in Figure 4, 40% of the discovered ODNSes answer queries
for no more than one day and 80% of the ODNSes cease answering
queries within one week. As noted above, there is evidence that the
ODNSes we ﬁnd are predominantly home network devices. There-
fore, we suspect that short ODNS lifetimes are due to DHCP lease
expirations. Thus, we conclude that our lists of ODNSes become
stale and biased quickly and for this reason we discover ODNSes
anew for each phase of our study.
Rescanning can be an expensive and time consuming process.
Fortunately, we ﬁnd that ODNSes demonstrate a tight IP spa-
tial cohesion: while an individual ODNS can be short lived, pro-
ductive /24 blocks tend to remain productive. We rescanned the
same /24 address blocks from the S3 scan between 11/16/2012 and
11/24/2012, nearly three months after the S3 scan ended; this scan
is labeled S5 in Table 1. We also ﬁnd that 76% of the 67K produc-
F
D
C
C
1
0.8
0.6
0.4
0.2
0
1
1M
10
100K
Length of ODNS accessibility (seconds)
10K
100
1K
Figure 4: Distribution of the duration of ODNS accessibility.
800K
600K
400K
200K
d
e
r
e
v
o
c
s
i
d
s
e
S
N
D
O
f
o
r
e
b
m
u
N
0
0
Random IP on Whitelist
Random IP on Internet
4M
12M
Number of probes sent
8M
16M
Figure 5: ODNS discovery rate using whitelisting in the S5 scan
compared to the discovery rate of the S2 scan.
tive /24 address blocks during the former scan remain productive
during the repeat scan. This spatial cohesion over time enables the
use of “whitelisting” to rescan just those /24 address blocks which
were previously productive. Using the same simulation method-
ology we employ to explore Random IP vs. Scan on First Hit
above (Figure 3) we study re-scanning previously productive /24
blocks. Figure 5 shows the discovery rate for rescanning the 67K
productive /24 address blocks from the S5 scan using Random IP—
i.e., scanning random IP addresses from the whitelisted /24 address
blocks—in contrast to random IP selection from the entire Inter-
net address space based on the S2 scan. Clearly, rescanning us-
ing whitelisting is more efﬁcient than random scanning. We also
note that whitelisting may be used in conjunction with the “Scan
on First Hit” strategy to generate a whitelist containing dense /24
address blocks. Rescanning using such a whitelist would likely
have a much higher discovery rate than Figure 5 suggests.
5.2 RDNS Discovery
RDNS discovery provides more of a challenge than ODNS dis-
covery for two reasons. First, unlike ODNS discovery, RDNS dis-
covery is an indirect process whereby the characteristics and behav-
iors of the ODNSes may impact the process. Second, the RDNS re-
solver topologies are complex, unlike the ODNS population, which
is by deﬁnition just a set of simple servers. In particular, an ODNS
may forward DNS queries to a pool of resolvers, which may option-
ally utilize another layer of resolvers before the queries egress the
infrastructure and are visible at our ADNS. For example, Google’s
public DNS utilizes a two-level topology that hashes the requested
hostnames to particular egress resolvers to improve their cache ef-
fectiveness [9]. Unfortunately, we can only discover the egress
RDNSes and do not have a technique for discovering HDNSes in
the middle of the infrastructure.
We use a two-pronged approach for RDNS discovery. First, for a
given ODNS we send multiple DNS requests for hostnames within
our domain in an attempt to spread those requests throughout the
RDNS pool—if such exists. For this we use unique hostnames such
that each request must move through the entire infrastructure and
end up at our ADNS. Second, our ADNS returns a variable-length
chain of CNAME records to queries from RDNSes3. We know
from experience that the RDNS that sends a DNS request is often
not the same RDNS that resolves the CNAME redirections. We use
both these mechanisms until we stop discovering new members of
the observed RDNS pool. Speciﬁcally, our strategy is as follows.
• When a ﬁrst probe to a newly discovered ODNS arrives
at our ADNS through a previously discovered RDNS, the
ADNS responds with a special A record indicating that no
new RDNS discovery has occurred.
• However, when this ﬁrst query arrives from a previously
unknown RDNS, the ADNS responds to a query with a
CNAME record of a new subdomain. After receiving the
subsequent query for this new subdomain we repeat the pro-
cess four additional times. When this batch of ﬁve CNAME
queries leads to the discovery of at least one new RDNS then
the entire process is repeated with ﬁve additional CNAMEs.
This process continues until no new RDNS is found, at which
point a special A record is returned to the client indicating
that new RDNSes were discovered.
• When the A record returned—through the ODNS—indicates
new RDNS were discovered,
the client sends ﬁve more
probes for distinct subdomains to this ODNS. Note that these
subsequent probes may trigger a series of CNAME responses
by our ADNS as described above. As long as the A record
from the ADNS indicates new RDNS discovery, probing ex-
tends with another batch of ﬁve probes.
• When the A record returned to the client indicates that no
new RDNSes were found, the discovery process terminates.
Our S2 scan uses the above procedure. Furthermore, to enable
exploration of alternate scanning strategies—as well as to discover
RDNS pools in §6—our S3 scan uses a modiﬁed version of the
above procedure that triggers a new CNAME batch as long as new
RDNSes are discovered for the current ODNS rather than consult-
ing the full set of RDNSes from all probing.
We test this basic RDNS discovery mechanism with four ODNS
probing strategies: “Random IP”, “Scan On First Hit”, and “Ran-
dom /24 Block” described earlier, plus “Aborted Random Block”,
which is a scan of random /24 address blocks that terminates af-
ter the ﬁrst ODNS in that block is found. The idea behind the last
strategy is that the ODNSes in a /24 block will all share the same
RDNS infrastructure and so the ﬁrst ODNS will trigger the dis-
covery of the lion’s share of the RDNSes. The results for all four
strategies reﬂect simulations driven by the dataset collected by the
S3 scan.
Figure 6 shows the discovery rates of our four methods. The
“Scan on First Hit” method has a higher rate than the alternate
strategies for two reasons. First, we ﬁnd that ODNSes within
the same /24 address block do not all use the same RDNS or
RDNS pool—contrary to our intuition. Therefore, learning about
the “neighborhood” is beneﬁcial not only for ODNS discovery but
also for RDNS discovery. This accounts for “Scan on First Hit”
3A CNAME record indicates a “canonical” name for the hostname
queried. On receiving this record, the resolver will issue a new
query for the name contained in the CNAME record.
40K
30K
20K
10K
d
e
r
e
v
o
c
s
i
d
s
e
S
N
D
R
f
o
r
e
b
m
u
N
0
0
Random IP
Scan On First Hit
Aborted Random Block
Random Block
20M
40M
80M
Number of probes sent
60M
100M 120M
Figure 6: RDNS discovery rate versus DNS requests sent, sim-
ulated from the S3 scan.
RDNSd and comparing the returned time-to-live (TTL) value with
the TTL we expect to be set by the Web site’s ADNS—which we
established separately. A TTL value in a DNS response that is less