### Table 3: Feature Vectors for Hosts in Two Example Clusters
Each row corresponds to the feature vector for a host in that cluster. The last row shows the maximum value for each feature across all clusters on April 24, 2013.

| Feature 1 | Feature 2 | Feature 3 | ... | Feature N |
|-----------|------------|------------|-----|-----------|
| 19        | 34         | 29         | ... | 0         |
| 2         | 2          | 1          | ... | 2         |
| ...       | ...        | ...        | ... | ...       |
| 114       | 47833      | 418        | ... | 48        |

### App Engine and Bitcoin Mining
Several hosts were found to be mining bitcoins. These hosts were labeled as “Other - Automated.” Additionally, 8.03% of the incidents either had high numbers (thousands per day) of consented connections, indicating that the user had explicitly acknowledged the company’s network policies before proceeding to the site, or long periods (i.e., lasting several hours) of continuous web traffic to various domains. Without further evidence of malicious behavior, these incidents were classified in the “Other - Browsing” category, though they may not be entirely user-driven.

### 4.3 Investigation by the SOC
The first-round manual labeling process described in Section 4.2 yielded 81 incidents (10.33%) for which we could not identify the applications responsible for the observed behavior. The hosts in these incidents communicated with low-reputation websites (e.g., flagged by antivirus vendors, registered within the past six months, with DGA-like subdomains), downloaded executables or zipped files, used malformed HTTP user-agent strings, or repeatedly contacted the same URL at semi-regular intervals. We labeled these incidents as “suspicious” and presented them to the enterprise SOC for a second round of analysis.

#### Table 5: “Suspicious” Incidents Categorized by the SOC at EMC

| SOC Label                     | Number of Suspicious Incidents | Percentage |
|-------------------------------|--------------------------------|------------|
| Adware or Spyware             | 35                             | 43.21%     |
| Further investigation         | 26                             | 32.09%     |
| Other malware                 | 9                              | 11.11%     |
| Policy Violation - Gaming     | 1                              | 1.23%      |
| Policy Violation - IM         | 1                              | 1.23%      |
| Policy Violation - Streaming  | 2                              | 2.47%      |
| Other - Uncategorized sites   | 7                              | 8.64%      |

While 54.32% of the “suspicious” incidents were confirmed by the SOC as adware, spyware, or known malware, a significant fraction (32.09%) were considered serious incidents and merit further investigation. These questionable activities are potentially previously unknown malware or other threats opaque to state-of-the-art security tools, and in-depth host inspection is necessary to determine the exact root cause. A small number of the investigated “suspicious” incidents were identified as policy violations (4.93%) or uncategorized sites (8.64%). Their association with obscure software or low-reputation sites prompted their identification as “suspicious” in the first-round investigation.

### 4.4 Summary
With assistance from the enterprise SOC, we manually investigated 784 Beehive incidents generated over the course of two weeks. Overall, we find 25.25% of the incidents to be malware-related or warrant further SOC investigation, 39.41% to be policy violations, and 35.33% associated with unrecognized but automated software or services. Only 8 of the 784 incidents (1.02%) were detected by existing state-of-the-art security tools, demonstrating Beehive’s ability to identify previously unknown anomalous behaviors.

### 5. Related Work
Network and host-based intrusion detection systems that use statistical and machine learning techniques have been extensively researched over the past two decades [11, 15, 33]. Both commercial and open-source products that combine signature, traffic, and anomaly inspection techniques are widely available today [1, 2, 3]. To the best of our knowledge, this is the first study addressing the challenges of sanitizing, correlating, and analyzing large-scale log data collected from an enterprise of this scale, and detecting both compromised hosts and business policy violations.

There are many existing systems aimed at helping human analysts detect compromised hosts or stolen credentials, and there are also numerous case studies on enterprise networks. For example, Chapple et al. [12] present a case study on the detection of anomalous authentication attempts to a university virtual private network using a clustering technique focused on geographic distance. Zhang et al. [41] extend this approach with additional machine-learning features to automatically detect VPN account compromises in university networks.

In an earlier study, Levine et al. [26] used honeypots to detect exploited systems on enterprise networks. Similarly, Beehive aims to automate detection tasks for security analysts. In addition to new detection methods, we present the largest-scale case study so far on a real-life production network, along with the unique challenges of analyzing big and disjoint log data.

While there is work that analyzes specific types of malicious activity on the network (e.g., worms [37] or spammers [32]), recent attempts at malware detection mainly focus on botnets. For instance, several systems [10, 27, 35] use classification and correlation techniques to identify C&C traffic from IRC botnets. BotTrack [16] combines a NetFlow-based approach with the PageRank algorithm to detect P2P botnets. Several studies monitor crowd communication behaviors of multiple hosts and analyze the spatial-temporal correlations between them to detect botnet-infected hosts independent of the protocol used for C&C communication [18, 20, 24, 40], while others specifically focus on DNS traffic similarity [13, 36]. BotHunter [19] inspects two-way communications at the network perimeter to identify specific stages of botnet infection. DISCLOSURE [8] presents a set of detection features to identify C&C traffic using NetFlow records. Other works focus on tracking and measuring botnets [4, 14, 17, 22, 34].

Some systems aim to identify domains that exhibit malicious behavior instead of infected hosts. For example, some systems [30, 29, 31, 21] propose various detection mechanisms for malicious fast-flux services. In a more general approach, EXPOSURE [9], Notos [5], and Kopis [6] perform passive DNS analysis to identify malicious domains. Ma et al. [28] extract lexical and host-based URL features from spam emails and use active DNS probing on domain names to identify malicious websites. Another branch of research aims to detect dynamically generated malicious domains by modeling their lexical structures and utilizing the high number of failed DNS queries observed in botnets using such domains [7, 38, 39]. In comparison, Beehive uses standard log data to detect suspicious activity in an enterprise network.

These approaches use network data for detection. In contrast, Beehive uses dirty enterprise log data to detect potentially malicious host behavior as well as policy violations specific to an enterprise setting.

### 6. Conclusions
In this paper, we presented a novel system called Beehive that addresses the problem of automatically mining and extracting knowledge in a large enterprise from dirty logs generated by a variety of network devices. The major challenges are the “big data” problem (at EMC, an average of 1.4 billion log messages—about 1 terabyte—are generated per day) and the semantic gap between the information stored in the logs and that required by security analysts to detect suspicious behavior.

We developed efficient techniques to remove noise in the logs, including normalizing log timestamps to UTC and creating an IP-to-hostname mapping that standardizes host identifiers across log types. Using a custom whitelist built by observing communication patterns in the enterprise, we effectively reduced the data Beehive inspects from 300 million log messages per day to 80 million (a 74% reduction).

Beehive improves on signature-based approaches to detecting security incidents. Instead, it flags suspected security incidents in hosts based on behavioral analysis. In our evaluation, Beehive detected malware infections and policy violations that went otherwise unnoticed by existing, state-of-the-art security tools and personnel. Specifically, for log files collected in a large enterprise over two weeks, 25.25% of Beehive incidents were confirmed to be malware-related or to warrant further investigation by the enterprise SOC, 39.41% were policy violations, and 35.33% were associated with unrecognized software or services.

To the best of our knowledge, ours is the first exploration of the challenges of “big data” security analytics at the scale of real-world enterprise log data.

### Acknowledgments
We are grateful to members of the EMC CIRT team for providing us access to the enterprise log data and for their help in investigating Beehive alerts. This research is partly funded by the National Science Foundation (NSF) under grant CNS-1116777. Engin Kirda also thanks Sy and Laurie Sternberg for their generous support.

### References
[1] OSSEC – Open Source Security. http://www.ossec.net.
[2] Snort. http://www.snort.org.
[3] The Bro Network Security Monitor. http://www.bro.org/.
...
[41] J. Zhang, R. Berthier, W. Rhee, M. Bailey, P. Pal, F. Jahanian, and W. H. Sanders. Safeguarding Academic Accounts and Resources with the University Credential Abuse Auditing System. In DSN, 2012.