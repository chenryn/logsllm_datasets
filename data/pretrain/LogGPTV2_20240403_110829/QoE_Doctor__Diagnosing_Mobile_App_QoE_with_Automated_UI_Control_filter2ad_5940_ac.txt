In this section, we ﬁrst evaluate the QoE measurement accuracy
and overhead of QoE Doctor, and then use QoE Doctor to
systematically and quantitatively study various factors which may
have impact on our 3 QoE metrics.
In this paper, we consider
three factors potentially impacting QoE: (1) the network type and
quality, for WiFi and 3G and LTE cellular networks; (2) the app’s
design and conﬁguration; and (3) the carrier, in particular carrier
rate limiting mechanisms for throttling. These factors are identiﬁed
based on either our experiences with the apps or practical problems
from real user experience identiﬁed by the authors at T-Mobile.
We summarize our experiment goals in Table 2. In this section, 2
carriers are involved in our experiments, which we denote as C1
and C2.
7.1 Tool Accuracy and Overhead
In this section, we report our evaluation results of the accuracy
and overhead of QoE Doctor. Table 3 summarizes the results
in the section along with the IP packet to RLC PDU mapping
performance reported in §5.4.2.
156Section
Experiment goal
Relevant factor
Application
§7.2
§7.3
§7.4
§7.5
§7.6
§7.7
Device and network delay on the critical path for user-perceived latency
Data and energy consumption during application idle time
Impact of app design choices on user-perceived latency
Network condition, app
Network condition, app
Network condition, app
Impact of carrier throttling mechanisms on user-perceived latency
Network condition, carrier
Impact of video ads on user-perceived latency
Network condition, app
Facebook
Facebook
Facebook
YouTube
YouTube
Impact of the RRC state machine design on user-perceived latency
Network condition, carrier Web browsers
Table 2: Experiment goals and mobile applications studied in §7.
Item
Value
User-perceived latency
≤40 ms (td)
measurement error
Transport/network to
≤4% (td/tscreen)
99.52% (uplink)
RLC data mapping ratio
88.83% (downlink)
CPU overhead
6.18%
Table 3: Tool accuracy and overhead summary of QoE Doctor.
QoE measurement accuracy. The mobile data consumption
metric is a precise value, calculated directly from data in the
transport/network layer.
The network energy consumption is
calculated directly from RRC/RLC layer information using a well-
established model [22, 48]. For the user-perceived latency metric,
however,
the UI data changes in the UI layout tree may not
precisely correspond to screen changes due to UI drawing delays
(Fig. 4). We evaluate the measurement accuracy by recording a
video of the screen at 60 frames per second for each of the user-
perceived latency tests we perform. Each experiment is repeated
30 times. The result shows that for all actions, the average time
difference td between tscreen and the measurement result from
QoE Doctor is under 40 milliseconds. We determine how the
user-perceived latency measurements are affected by calculating
the ratio of td to tscreen for each metric, as shown in Fig. 6. As
td is not proportional to tscreen, the ratio differences between the
5 metrics are due to tscreen. To calculate an upper bound on this
ratio, for each metric we use the shortest tscreen among all the
experiments in this section in Fig. 6. As shown, for all experiment
results the latency measurement error is less than 4%.
QoE measurement overhead. We use DDMS [3] to compare the
CPU time when manually inputting the target user behavior with
the CPU time when using QoE Doctor. We ﬁnd the upper bound
of this overhead by running the most compute-intensive operation,
parsing the UI tree (Fig. 4), on the most computation-intensive
app operation: uploading a Facebook post. We run this test 30
times, and ﬁnd the average worst-case CPU computation overhead
introduced by QoE Doctor is 6.18%.
7.2 Facebook: Post Uploading Time Break-
down Analysis
In this section, we focus on the action of uploading a post to
Facebook, leveraging our multi-layer analysis to break down the
roles the device and the network play in the user-perceived latency.
Experiment setup. We run the experiments on Facebook version
5.0.0.26.31 on a Samsung Galaxy S3 device with Android 4.3. We
use QoE Doctor to post status, check-in, and 2 photos every 2
seconds for C1 3G and C1 LTE network. Each action is repeated
50 times.
Finding 1: The network delay is not always on the critical
path. To understand the role of the device and the network in the
end-to-end delay, we break down the device and network latency
according to the steps of uploading a post shown in Fig. 4. To
separate out the network latency portion, we ﬁrst identify the TCP
ﬂows which are responsible for the post uploading using techniques
described in §5.4.1. Even though the trace is encrypted, it is
not hard to identify the ﬂow with high conﬁdence since in most
cases only one ﬂow has trafﬁc during the QoE window (deﬁned
in §5.4.1). We then calculate the network latency as the timestamp
difference between the earliest and latest packet of this TCP ﬂow,
and calculate the device latency by subtracting the network latency
from the user-perceived latency.
Fig. 7 shows the breakdown results for posting 2 photos, status
and check-in for C1 3G and C1 LTE network. In the ﬁgure, the
standard deviation values of the latencies for posting 2 photos are
all less than 0.7 seconds, and those for posting a check-in and a
status are all less than 0.25 seconds. Surprisingly, we ﬁnd that the
network delay contributes little to the check-in and status uploading
latency. We double-checked the network trace, and found that
the corresponding TCP ACK packets for both actions are actually
outside the QoE window. This indicates that showing these posts on
the news feed list doesn’t depend on the response from Facebook
server. In other words, the Facebook app pushes a local copy of
status and check-in posts directly onto the news feed list to remove
the network delay from the critical path, which ensures low user-
perceived latency. Note that this only happens to posting a status
and a check-in; for posting 2 photos, the network latency always
falls inside the QoE window, suggesting that it is very likely to be
on the critical path, which is the case described in Fig. 4.
Finding 2: 3G RLC transmission delay contributes more than
expected in the end-to-end photo posting time. Unlike status and
check-in posting, Fig. 7 shows that for 2 photo uploading action
the network latency has more than 65% share in the end-to-end
latency. Using our cross-layer analysis between the application
and transport/network layers, we always see a clear pattern of
uploading then downloading two large chunk of data in the TCP
ﬂow inside QoE Window.
Interestingly, for this action 3G has
around 50% more network latency than LTE, while their device
latencies are similar. To ﬁnd out the reason, we further break
down the network latency using our cross-layer analyzer between
the transport/network layer and the RRC/RLC layer as described
in §5.4.1.
In this more ﬁne-grained network latency breakdown, we target
four metrics: IP-to-RLC delay (t1), RLC transmission delay (t2),
the ﬁrst-hop OTA delay (t3), and other delay (t4) as shown in
Fig. 9. The IP-to-RLC delay is the time difference between an IP
packet and its ﬁrst mapped RLC PDU when no other RLC PDUs
are transmitted. For the RLC transmission delay, we ﬁrst identify
the periods where the device is “busy" transmitting RLC PDUs
using a burst analysis for RLC PDUs. We implement this analysis
by checking whether the inter-PDU time is less than the estimated
ﬁrst-hop OTA RTT deﬁned in §5.3. Then, the RLC transmission
delay is calculated by summing up all the inter-PDU time within
157)
%
(
o
i
t
a
r
r
o
r
r
e
t
n
e
m
e
r
u
s
a
e
M
 6
 5
 4
 3
 2
 1
 0
Facebook post updates
Facebook pull-to-update
YouTube initial loading
YouTube rebuffering
Web browsing page loading
User-perceived latency metrics
)
s
(
y
c
n
e
a
t
l
i
d
e
v
e
c
r
e
p
-
r
e
s
U
 9
 8
 7
 6
 5
 4
 3
 2
 1
 0
Network delay
Device delay
3G
LTE
2 p
h
C
h
Status
eck-in
otos
2 p
h
C
h
Status
eck-in
otos
)
s
(
y
c
n
e
t
a
l
k
r
o
w
e
N
t
 5
 4
 3
 2
 1
 0
RLC transmission delay
IP to RLC delay
First-hop OTA delay
Other delay
3G
LTE
Fine-grained network latency breakdown
Figure 6: Error ratio of user-perceived
latency measurements for each action.
Figure 7: Device and network delay
breakdown for different post uploads.
Figure 8: Fine-grained network latency
breakdown for 2 photo uploading.
IP
Layer
A
tAB
B
tBC
C
RLC
Layer
t1
A1 A2
...
P
A19
t2
B1
...
S1
P
B36 S2
t3
C1
...
C27
t4
t1
t2
Figure 9: Example cross-layer network latency breakdown.
tAB and tBC are the inter-IP packet times. Although tAB > 0,
A and B are transmitted back-to-back within one PDU burst
in the RLC layer. PDUs with letter P are polling PDUs. S1 and
S2 are STATUS PDUs.
each RLC burst. For the ﬁrst-hop OTA delay, we notice that not all
the ﬁrst-hop OTA RTTs are on the critical path. For example, the
RTT from A19 to S1 is not on the critical path but the RTT from
B36 to S2 is, because for the former the device is busy transmitting
B1 but not explicitly waiting for S1. Therefore, we deﬁne the
ﬁrst-hop OTA delay as the summation of the ﬁrst-hop OTA RTTs
which the device explicitly waits for. Other delay is calculated by
subtracting the end-to-end time by the IP-to-RLC delay, the RLC
transmission delay, and the ﬁrst-hop OTA delay. The IP-to-RLC
delay, the RLC transmission delay, and the ﬁrst-hop OTA delay
are all within one hop range from the local devices, so other delay
consists of the latencies outside of the one-hop range, for example
the latency in the switch/router, server processing delay, etc.
The breakdown results are shown in Fig. 8. In the ﬁgure, the
RLC transmission delay in C1 3G is signiﬁcantly greater than that
in C1 LTE. We manually inspect the traces of posting 2 photos,
and ﬁnd that there are on average 270 IP packets transmitted within
the QoE window, corresponding to 10553 RLC PDUs for C1 3G
and 4132 RLC PDUs for C1 LTE. Such 2.55× additional number
of RLC PDUs implies signiﬁcant RLC PDU header processing
overhead, which could be the potential reason of the higher RLC
transmission delay in C1 3G.
7.3 Facebook:
Background Trafﬁc Data
Consumption and Energy Analysis
To ensure that users can get interesting content from their social
network at any time, Facebook app keeps communicating with the
server even when it is not in the foreground. How much mobile data
and energy are consumed by these background network events?
How can we as users reduce cost and battery power usage while
still getting timely updates? In this section, we use QoE Doctor to
explore the answers.
Experiment setup. We use two devices, a Samsung Galaxy S3
device with Android 4.3 (referred as device A) and a Samsung
Galaxy S4 device with Android 4.3 (referred as device B), and
conﬁgure the accounts on device A and B to be mutual and
exclusive friends with each other. Then, we use QoE Doctor’s
controller on device A to post statuses with texts of identical
lengths, causing device B to receive these status updates. We
change the settings of the account in device B so that it receives
a notiﬁcation for every news feed post from device A. Thus,
device A simulates Facebook friends or public pages from which
the user with device B wants to get updated with no delay. We
consider these content to be time-sensitive. On device B, we only
use the data collection functionality of QoE Doctor controller.
Since our target is Facebook background trafﬁc, we use ﬂow
analysis and only analyze TCP ﬂows which talk to Facebook DNS
domain names. For energy consumption, we use QxDM RRC state
machine logs as described in §5.3.
Finding 3. Facebook’s non-time-sensitive background trafﬁc
adds non-negligible overhead to users’ daily mobile data and
energy consumption. To see how uploading frequency impacts
mobile data and energy consumption, we set
the uploading
frequency on device B to be every 10 minutes, 30 minutes, 1 hour,
and no uploading. We run the experiment for 16 hours, and the
results are shown in Fig. 10 and Fig. 11. For uploading every 10
minutes, 30 minutes and 1 hour, the results are expected: data
and energy consumptions are strictly proportional to the upload
frequency of device A. These content is time-sensitive for device
B, so these overhead is acceptable. However, to our surprise,
when device A’s only friend, device B, posts nothing, device