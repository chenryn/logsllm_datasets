The ten scheduler variants are meant to represent varying degrees severity
of a given attack—during each accounting period, each variant will randomly
decide whether to deduct credits from the attacker VM, with variant n being
414
K. Leach et al.
4n% likely to skip credit deduction. That is, scheduler variant 10 is 40% likely
to skip the deduction of credits on the attacker VM. This means that, over time,
the attacker will have more credits and thus more time to get scheduled.
We ran several benchmark applications in both guests using each of the
ten scheduler variants: pi, gzip, and PARSEC [11]. Computing pi represents a
highly CPU-bound workload, while gzip on a large random ﬁle represents a more
mixed CPU and I/O-bound workload. The PARSEC benchmark suite has been
used previously in the area of cloud performance and economics [37,39]. Under
benign circumstances, each guest should get 50% of the CPU time regardless
of workload. When the attack variants are considered, an increasing amount of
CPU time should be allocated to the attacker.
Table 1. Ratio of attacker VM CPU time to guest VM CPU time.
Scheduler attack severity level
Benign 1
2
3
4
5
6
7
8
9
10
Scotch
1.00
1.04 1.07 1.10 1.13 1.17 1.21 1.26 1.31 1.36 1.41
Ground truth 0.99
1.05 1.09 1.12 1.15 1.17 1.20 1.25 1.30 1.35 1.39
Table 1 shows the results of this experiment. We ran each benchmark pro-
gram for ﬁve minutes measuring the CPU time allocated. We report the ratio
between the attacker VM and victim VM CPU time for both Scotch and xen-
trace [3]. Furthermore, we average the results of all benchmarks. We note that,
under benign circumstances, Scotch and xentrace both report a ratio of 1.0.
However, as the attack becomes more severe, the attacker VM gets a higher ratio
of CPU time, again validated against xentrace. This pattern is consistent across
all workloads. Overall, Scotch performs accurate resource accounting even in
the face of severe scheduler attacks.
6.3 RQ2: Overhead
We note that executing our isolated SMI handler resource accounting code takes
additional time during each context switch and interrupt. Our SMI handler code
takes 2248± 69 cycles to execute. On our 2.8 GHz platform, that corresponds to
about 1 µs. However, acquiring granular resource accounting information means
this 1 µs cost must be incurred every context switch and every interrupt. In
contrast, a typical VM switch takes roughly 20,000 cycles, or roughly 7.1 µs.
Adding our resource accounting code thus increases context switching time 14%.
However, in purely CPU-bound workloads, Xen uses a 30 ms default quantum
per guest. Thus, the context switching time is amortized into the 30 ms runtime
per quantum. In other words, every 30 ms of useful work requires a total of
8.1 µs overhead in Scotch, compared to 7.1 µs overhead in default systems.
Thus, we can estimate the additional system overhead incurred by Scotch on
CPU-bound workloads with:
|8.1 µs − 7.1 µs|
(30 ms + 7.1 µs)
= 33 × 10
−6additional overhead
Scotch
415
That is, our system incurs an additional .0033% overhead by using our sys-
tem. As I/O operations typically take much longer in comparison to CPU-bound
computation, this overhead reasonably approximates the worst-case overhead
incurred by Scotch.
However, for the complete picture, we must also consider more realistic mixed
CPU- and I/O-bound workload. Using gzip, we compressed a large randomly-
generated ﬁle for a total of 5 min. The ﬁle was twice the size of guest system
memory preclude caching the entire ﬁle and force operations to go all the way
to disk. We measured the amount of CPU time and the amount of time spent
servicing disk requests using our approach. In ﬁve minutes, there were 8070
context switches in which 214.59 s of CPU time were consumed. Thus, we can
estimate the amount of CPU time consumed after each context switch with:
214.59 s
8070 switches
= 26.6 ms,
which is reasonable (for reference, recall the standard quantum in Xen is 30 ms):
gzip would be spending some amount of time executing CPU-bound compression
code. Using the formula above, we get an additional overhead of 0.0038%.
In contrast, there were 1371 interrupts going to disk, which took a total
of 85.42 s. This corresponds to 62.3 ms per interrupt. Using a similar formula
above, we can estimate the additional overhead incurred on disk-bound interrupt
events. For interrupts, this additional overhead is 0.0016%. Both values represent
a signiﬁcant improvement over existing SMM-based work [24]. While part of this
improvement is due to faster SMI-handler code, much of the overhead depends
on the underlying capability of the CPU to switch into SMM. Previous work has
found SMI handler code takes on the order of 10 µs [43,45]. That said, even with
a 100-fold increase in execution time of our SMI handler code, we still incur an
overhead below 1%.
Note that we can further improve performance using an interval-based app-
roach. Instead of invoking our code on every task switch or I/O interrupt, we
can instead invoke our code after x such events, where x is a random number
between 1 and some maximum interval. This random interval approach prevents
transient resource attacks from going unnoticed because such attacks cannot
learn a pattern for our resource accounting invocation. Thus, in the long run,
such an approach maintains high accuracy with regard to resource accounting,
but features a lower overhead. That said, spreading out the interval does create
an opportunity for a sophisticated attacker to hide malicious activity; such an
attacker could risk a certain amount of detection (determined by the measure-
ment interval) by attempting to steal resources and counting on not be measured
with our approach. Ultimately, the end user must decide the level of granularity
of resource accounting information they need in comparison to the amount of
overhead incurred by Scotch.
416
K. Leach et al.
6.4 RQ3: Resource Interference Attacks
We also consider accounting in the face of resource interference attacks [35].
Scotch is capable of maintaining accurate resource accounting information even
in the presence of such attacks. Because Scotch is invoked on every task switch
and I/O interrupt, we maintain an accurate picture of resource consumption by
construction. For example, as discussed in Sect. 3.2, a resource freeing attack
may work by causing a victim to block on I/O and thus free up CPU time for
the attacker—but they still involve standard task switching and I/O interrupts.
Thus, in such an attack, Scotch will accurately report that one guest is blocked
on I/O and that the other is using the CPU.
We note that resource interference attacks often rely on an attacker’s knowl-
edge of a victim’s workload. We reiterate that Scotch does not detect or pre-
vent such an attack per se (although an analyst may do so by inspecting the
resource accounting information). Instead, Scotch provides a guarantee about
the quality and accuracy of resource accounting information our system delivers,
even in the face of such attacks. This represents an improvement over previous
approaches [12,24], which neither detect nor prevent nor accurately account for
resource usage in the presence of such attacks.
6.5 RQ4: VM Escape Attacks
Next, we discuss the viability of using Scotch even when the hypervisor has
been compromised completely. Attacks such as Venom [15] or CloudBurst [27]
allow a malicious VM guest to exploit vulnerabilities in the underlying hypervisor
to escape the virtualized environment and execute arbitrary code in the hyper-
visor context. These are particularly dangerous attacks because they have the
potential to compromise all of the other VM guests on the hypervisor. Addition-
ally, such attacks are capable of changing resource allocation arbitrarily, poten-
tially inﬂuencing ultimate billing for benign customers. In such cases, Scotch
can provide accurate resource accounting information that can be used to provide
accurate billing for all customers.
Recall that our resource accounting code is stored in isolated SMRAM. Even
if an attacker is allowed ring 0 privilege in the underlying hypervisor, there is not
a way for such an attacker to either (1) change previously-collected accounting
information, or (2) change the accounting code itself. While ring 0 code could
inﬂuence conﬁguration registers and invoke spurious SMIs, a cursory analysis of
the data transmitted to the Remote System would reveal such behavior. Addi-
tionally, such an attacker is not able to change SMM-related conﬁguration regis-
ters because they are locked before the BIOS transfers control to the hypervisor.
However, malicious ring 0 code could alter kernel structures (Direct Kernel
Object Manipulation [30]) or sensitive registers to inﬂuence accounting informa-
tion before it is seen by the SMI handler. An attacker could, for instance, write
the TSC register so that it appears a particular guest has consumed fewer cycles
than it actually has, leading to an accounting discrepancy. In such cases, we could
employ an instruction-level instrumentation approach similar to MalT [45] while
kernel code executes to detect TSC writes or other malicious DKOM activity.
Scotch
417
6.6 RQ5: Beyond CPU Time
RQ1 discusses experiments related to CPU time as a resource. However, Scotch
is also capable of accurately recording VM guests’ consumption of other system
resources as well. First, by invoking our code on every I/O interrupt as well as
every task switch, we have the opportunity to examine consumption of peripheral
devices (e.g., network and disk). As discussed in Sect. 5, VT-x allows us to gather
information about the cause of the interrupt via the VMCS. Second, we do
not give the hypervisor an opportunity to execute any code after the interrupt
occurs—instead, after our resource accounting code executes, we transfer control
to the next guest VM that was supposed to run after the interrupt completed.
In doing so, there is no opportunity for a compromised hypervisor to alter the
results of an interrupt to make it appear as though a diﬀerent resource had been
consumed.
6.7 Threats to Validity
Scotch is a system meant to provide accurate resource accounting information
in the cloud so that end customers have greater assurance that they are billed cor-
rectly according to the resources they really consume. While we have conducted
experiments validating the high accuracy and low overhead of our approach, we
discuss some assumptions we have made in conducting this evaluation.
First, we did not experiment using a test in the wild. For example, we imple-
mented a resource-based attack by directly modifying the scheduler’s behav-
ior. We favored this approach because it admits controlled experimentation: it
allowed us to vary how much of the CPU time was being stolen. We believe this
represents diﬀerent modalities of attackers with varying goals—some attackers
may wish to operate more stealthily for longer periods of time, while others
might operate more blatantly. We believe a controlled attack such as the one we
have created is reasonably indicative of a variety of attacker behavior. Similarly,
the benchmark workloads we evaluated on may not generalize. We attempted
to mitigate this threat by including both microbenchmarks (CPU-bound and
mixed) as well as the PARSEC [11] benchmarks which have been previously
used in the area of cloud performance.
Second, invoking SMIs may cause perturbations in the behavior of certain
caching mechanisms. For instance, the instruction cache might be cleared, and
diﬀerent chipsets and CPUs may perform other tasks while switching to SMM.
Attacks abusing knowledge of this low-level detail have been documented [41,42].
In this paper, we assume that the hardware is trusted and that hardware-level
bugs that admit such attacks are out of scope.
Third, while DMA attacks would be unable to aﬀect the integrity of data
stored in SMRAM or within the SGX enclave, there is a potential opportunity
for an attacker to compromise data while it is being marshalled into the enclave
from SMM. In Scotch, we conﬁgured the system to immediately transfer control
to the enclave entry code after resuming from SMM. Depending on the platform’s
418
K. Leach et al.
RSM implementation, there may be a small window to corrupt that marshalled
data.
Finally, modifying the SMI handler to enable Scotch requires some degree
of trust in the hardware vendor’s BIOS code. Several attacks against SMM and
related ﬁrmware have been discovered [17,25]; such attacks could compromise
the resilience of data collected by Scotch. We can mitigate such concerns by
using open source ﬁrmware where available, such as Coreboot [16] as used in
Spectre [43] and MalT [45]. This would allow evaluating the ﬁrmware before
deployment while trusting a restricted set of closed-source vendor code.
6.8 Evaluation Conclusions
Unlike previous approaches, Scotch was able to perform accurate resource
accounting in the face of scheduler attacks, producing results that were within
2% of the ground truth. Scotch increases the cost of each context switch by
14%, which corresponds to a .0033% overhead for CPU-bound workloads and a
.0016% overhead on more mixed workloads. This can be mitigated by account-
ing at random intervals, trading oﬀ granularity for overhead. By construction,
Scotch provides accurate accounting in the face of resource interference attacks,
since such attacks still use standard task switching and I/O interrupts. Scotch
also provides accurate accounting in the presence VM escape attacks, since even
the hypervisor cannot tamper with SMRAM or SMI handler code. In addition
to accurately measuring CPU time, techniques in Scotch can address resources
such as disk and network I/O that are processed through interrupts. Over-
all, Scotch provides transparent and accurate resource accounting for virtual
machine guests.
7 Related Work
In this section, we discuss four main areas of related work: (1) Resource account-
ing techniques that propose helping cloud providers guarantee a particular ser-
vice level to their customers, (2) SMM-based system protection techniques, (3)
SGX-based system protection techniques, and (4) other multi-tenancy virtual-
ization studies.
7.1 Resource Accounting
Chen et al. [12] propose Alibi, a system for veriﬁable resource accounting. It
places a reference monitor underneath the service provider’s software platforms
(i.e., nested virtualization). Jin et al. [24] propose another veriﬁable resource
accounting mechanism for CPU and memory allocation even when the hypervisor
is compromised. Similar to our system, their approach also uses SMM as a trusted
execution environment to account the resource usage. However, our system diﬀers
from previous work in the following ways:
Scotch
419
1. By invoking our resource accounting code every context switch and inter-
rupt, we can derive a granular resource usage report for each guest. This
allows a rapid identiﬁcation of discrepancies in resource usage. By contrast,
Jin et al. employ a polling technique that requires running the analysis for
a long time before a conclusion can be made—if an attacker is trying to be
stealthy by stealing fewer resources, our approach can be used to more quickly
identify such behavior, possibly within a few context switches, depending on
the workload.
2. In addition, the manner in which our resource accounting code is invoked
guarantees that we do not miss transient events—other techniques that
employ polling for resource auditing may miss malicious guests that learn
their polling behavior. For instance, Wang et al. [38] provides a systematic
analysis of evasion attacks (i.e., transient attacks) for polling-based SMM sys-
tems. In such attacks, the adversary can circumvent the defense mechanisms
by studying their polling behavior. With Scotch, if a malicious guest wants
CPU time, control must transfer to it at some point, at which point our SMI
handler will be invoked.
However, this guarantee comes at the price of performance. As noted in
Sect. 6, our resource accounting code incurs an additional 1 µs per task switch
and I/O event. We can tune this depending on the end-user’s needs, instead
invoking our code on random intervals to amortize the 1 µs cost. Ultimately,
the 1 µs cost corresponds to a worst-case additional overhead of .0033%, which
may be low enough for most applications.