free  [2].  Developers  or  other  experts  evaluating  the 
system determine its accuracy and assurance. Intrusion 
detection  systems  have  a  challenge  similar  to  that  of 
users,  since  they  can  take  input  from  a  wide  array  of 
sources  across  the  system.  The  trustworthiness  of  the 
sources can vary. The logic of determining whether or 
not  an 
is  kept  compact, 
sophisticated  and  explicit.  User  processing  will  not 
necessarily reflect any of those attributes.  
intrusion  has  occurred 
Studies on trust indicate that users decide whether to 
trust a system based on all the information immediately 
available  to  them  [37].  This  includes  non-security 
aspects that might reflect the trustworthiness of humans 
associated  with  a  service,  such  as  how  professional  a 
web  site  design  is.  Information  on  past  history,  like 
eBay’s  reputation  service,  can  also  promote  trust. 
When considered from a classic assurance perspective, 
many  of  the  things  people  rely  on  to  determine  trust 
can easily be manipulated orthogonally from how truly 
trustworthy  a  web  site 
traditional 
indicators  of  social  trustworthiness,  applied  to  social 
situations where computers are used to mediate.  
is.  They  are 
While  users  may  rely  on  components  not  meant  to 
provide security, the flip side can occur where there are 
components  in  a  platform  providing  useful  security 
functions  (encryption,  signing,  trust  root  storage)  but 
not  actually  securing  the  system  in  any  meaningful 
fashion. This can happen in standards and other efforts 
that  begin  by  specifying  the  security  subsystems  that 
are  needed  before  determining  how  the  subsystems 
secure  the  overall  system.  Current  examples  are 
frameworks  such  as  OSGi  and  Eclipse  [23].  Security, 
like other qualities such as usability and performance, 
is  a  system-wide  concern,  requiring  system  wide 
thinking to be effective.  
How can we integrate human assurance with classic 
security assurance? Making all user visible aspects part 
of  the  security  kernel  increases  the  complexity  of  the 
part  of  the  system  that  should  be  given  the  most 
rigorous attention. That approach does accurately apply 
security  assurance  techniques  to  the  interfaces  upon 
which  security  relevant  decisions  will  be  made. 
Firefox’s  approach  [41]  to  simplifying  the  security 
surface for users and minimizing false end user alerts is 
to  rely  on  rapid,  timely  updates  to  the  code  base  in 
response  to  future  attacks  (much  as  virus  protection 
does today). We need more work on security assurance 
for  the  end  user,  including  mechanisms  that  can  take 
hints  based  on  data  not  part  of  the  core  security 
processing functions.  
2.3. Implementation and Deployment Are The 
Golden Spike 
Much  of  the  information  in  the  current  literature 
focuses  on  how  user-centered  security  is  or  can  be 
achieved using specific designs or technologies. There 
are  not  yet  tools  or  best  practices  that  allow  a  larger 
body of practitioners or researchers to incorporate user 
centered  security  into  their  system.  There  are  no 
criteria or checklists for evaluating how usably secure a 
system or approach is likely to be.  
HCI  made  great  strides  as  a  discipline  through  the 
promotion  of  guidelines,  tool  kits,  and  processes  for 
incorporating  usability  into  products  at  a  reasonable 
cost by anyone willing to take the time to learn to use 
them.  Security  assurance  has  not  made  similar 
advances  in  consumability.  Security  assurance  comes 
from use of algorithms and techniques that have been 
shown  to  provide  security  in  practice,  have  proven  to 
be secure (in the  formal sense), or that are backed by 
process and assurances that demonstrate their strength.  
How can we integrate the lessons from practice into 
our  research  thinking  so  that  we  achieve  usable 
security  in  practice?  And  how  can  we  specify  and 
implement reusable security components that support a 
user-centered  security  model  in  the  system  they’re 
integrated into? 
2.3.1. Integrating research and practice.  
In  theory,  there  is  no  difference  between  theory 
and practice. In practice, there is. 
feedback 
Yogi Berra 
The  establishment  of  best  practices  relies  on  some 
history  of 
research, 
development,  deployment,  and  use.  There  is  some 
communication  built  into  the  system  from  research  to 
development. In commercial software companies, it is 
often called “technology transfer.” Development feeds 
naturally  into  deployment,  which  feeds  naturally  into 
use.  
loops  between 
their  use 
Communication up this chain is rarer. As [34] points 
out,  the  security  weaknesses  of  text  passwords  were 
revealed  only  by 
in  practice.  Those 
weaknesses are so well established that they have been 
communicated  back  to  research,  sparking  solid  work 
on looking for suitable alternatives. Changing practice 
could also have changed the degree of usable security 
provided  by  passwords.  Generated  passwords  were  a 
reasonable 
solution  20  years  ago  when  only 
professionals  needed  them  and  they  only  had  one 
password,  and  it  was  only  used  at  a  computer  in  an 
office  with  a  lock  on  the  door.  Now  users  deal  with 
many  passwords  with  many  different  but  overlapping 
strength and management policies, rendering almost all 
forms of deployed passwords unusably insecure. Users 
Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005) 
1063-9527/05 $20.00 © 2005 IEEE 
cannot create and recall many difficult passwords for a 
multitude  of  systems.  They  will  reuse  them  and  write 
them down, both of which can be exposures.  
[5] recommends that products know their audience, 
and  that  responsible  parties  interact  directly  with 
customers  and  users.  This  is  classic  business  advice; 
there  is  no  substitute  for  understanding  the  customer 
and their goals and business. It provides feedback from 
deployment  and  use  to  development.  Many  HCI 
techniques provide feedback  from use to other stages. 
User  advocates  can  provide  related  information.  If  a 
technical  writer  cannot  explain  how  to  use  a  security 
mechanism  in  a  practical  and  safe  fashion,  it’s  a  safe 
bet that users won’t know how to do so.  
Tradeoffs  that  are  critical  in  practice  must  inform 
research  if  research  is  to  successfully  transfer  to 
practice  and  products.  Some  of  these  tradeoffs  are 
surprisingly  mundane.  For  example, 
in  product 
development, screen space is often at a premium, with 
many important pieces of information vying for a place 
in the sun.  CoPilot [16] takes a substantial amount of 
primary screen real estate to get its point across; more 
than  would  be  likely  to  be  allotted  to  security  in  a 
general  purpose  email  product.  This  squeeze  is  not 
encountered 
in  special  purpose  dialogs  [62].  To 
advance  usable  security,  research  needs  to  actively 
seek  development,  deployment,  and  use  experience, 
and  development  needs  to  actively  seek  deployment 
and use experience.  
2.3.2. Components Contributing To Usable Security.  
With these kinds of proposals, the devil is in the 
details.  
both 
increasing 
John B. Larson  
Reuse  of  security  component  allows  concentration 
on  the  assurance  of  the  algorithms  and  the  code.  It 
supports  centralization  of  security  concerns,  which 
makes  it  possible  to  simplify  security  mechanisms, 
potentially 
and 
understandability [60]. Standards provide another form 
of  reuse,  in  algorithms,  mechanisms,  and  APIs.  They 
make  security  usable  by  developers;  they  can  use  the 
security  mechanisms  developed  by  others  instead  of 
inventing  them.  Abstraction  of  the  security  specific 
functions  allows  mechanisms  such  as  authentication 
credentials to change over time when the infrastructure 
changes, without disrupting the rest of the system.  
assurance 
Both  reuse  and  abstraction  pose  a  challenge  to 
usable  security.  Security  is  often  most  obvious  to  the 
user  when  things  go  wrong,  when  an  error  or  alert  is 
raised  by  a  security  mechanism.  Very  directed  users 
will  even  ignore  alerts,  until  they  are  unable  to 
accomplish  their  task,  because  of  either  the  security 
problem  or  its  solution.  Exceptions  or  errors  from 
security components are often either very low level or 
abstracted.  Low  level  error  messages  are  likely  to 
require  more  detailed  knowledge  to  understand  than 
most users possess. Abstracted error messages remove 
the security situation from the specific context the user 
is in, stripping them of useful clues.  
The security use of protocols can also change when 
their  use  changes  [36].  Repurposing  a  security 
mechanism, such as a protocol, can change the security 
properties because of the changed context and threats. 
For example, we considered in some detail the usability 
of using SSL as provided by JSSE to protect rich client 
protocols such as IIOP, HTTP, and SIP used to access 
backend  servers.  In  the  browser,  the  URL  defines  the 
desired  target,  and  the  protocol  action  (get  or  submit) 
maps  directly  to  a  user  action.  When  a  form  is 
submitted  by  a  button  press,  users  can  get  confused 
about what protections are available. There have been 
several  reports  of  web  forms  which  were  themselves 
SSL  protected  mistakenly  submitting  data 
in  an 
unprotected URL.  
The  connection  between  user  action  and  protocol 
activity is even more opaque in a rich client. The client 
programs  actions  may  be  any  one  of  a  number  of 
housekeeping  operations,  including  initial  access  of 
data  for  a  particular  application,  synchronization  of 
data between local and remote stores, or getting server 
updates of code or metadata. If there is a problem with 
some  SSL  server’s  certificate,  the  user  will  want  to 
know what server the network layer was connecting to, 
for what purpose, and with what data. That data is not 
readily  available  to  callbacks  that  process  exceptions 
and errors.  
[55]  encapsulated  several 
likely  browser-based 
scenarios  in  his  recommendations  on  enhancing  the 
usability of the SSL security dialogs. They develop the 
general principle of some sessions being more sensitive 
than others, and allowing the user to trust the certificate 
for just a session. This approach can apply to rich client 
use  as  well,  though  the  definition  of  a  session  is 
dependant  on  the  structure  of  the  calling  application. 
They  stop  short  of  addressing  the  question  of  how 
sensible the security model is. For example, just what 
threat  should  the  user  consider  if  the  certificate’s 
validity time period has not yet begun?  
Rich  clients  can  provide  additional  tools  that  when 
used  will  eliminate  the  occurrences  of  some  security 
errors.  These  include  tools  to  notify  administrators 
when  certificates  are  going  to  expire  and  to  easily 
update trust roots across the client base.  
In general, no error message or exception should be 
specified  or  implemented  in  a  security  component 
unless it is linked with an action the user can take when 
they  receive  it,  or  an  action  that  an  administrator  or 
user  can  be  told  to  take  to  ensure  the  error  does  not 
occur.  Security  modules  that  can  be  reused  need  to 
Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005) 
1063-9527/05 $20.00 © 2005 IEEE 
consider  what  information  will  be  needed  to  process 
these errors or alerts, should they reach the user. 
3. Effective User-Centered Security Today 
today.  Most  of 
Despite  the  many  substantial  challenges,  there  is  a 
solid  body  of  work  on  user-centered  security  that  we 
can  use 
the  work  addresses 
technology’s relationship to user-centered security, but 
some address the human and social aspects, and some 
covers implementation and use. References to existing 
work  may  be  found  in  the  bibliography  of  this  essay, 
and on the HCISEC reference list [24]. There is now a 
symposium  dedicated  to  usable  security  and  privacy 
[47],  a  newly  published  book  security  and  usability 
[25], and an email community on the topic [26]. 
certain  HCI 
The  two  best  tools  we  have  mastered  so  far  are 
security 
applying 
mechanisms,  and  distilling  and  applying  some 
principles  of  usably  secured  systems  established  by 
work so far. Each of these is discussed in more detail 
below.  
techniques 
There are many other areas that can yield results that 
are  less  well  explored.  Much  work  in  the  area  of 
useable  security  gives  process  advice,  or  shows  how 
experts  in  the  area  can  apply  usable  security  to  a 
specific  problem  or  domain.  In  the  former  case,  the 
process advice is almost always to security people, and 