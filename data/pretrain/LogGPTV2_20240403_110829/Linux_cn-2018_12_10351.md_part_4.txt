> 
> 
##### 测试
运行 `user/faultread`（make run-faultread）你应该会看到：
```
    ...
    [00000000] new env 00001000
    [00001000] user fault va 00000000 ip 0080003a
    TRAP frame ...
    [00001000] free env 00001000
```
运行 `user/faultdie` 你应该会看到：
```
    ...
    [00000000] new env 00001000
    i faulted at va deadbeef, err 6
    [00001000] exiting gracefully
    [00001000] free env 00001000
```
运行 `user/faultalloc` 你应该会看到：
```
    ...
    [00000000] new env 00001000
    fault deadbeef
    this string was faulted in at deadbeef
    fault cafebffe
    fault cafec000
    this string was faulted in at cafebffe
    [00001000] exiting gracefully
    [00001000] free env 00001000
```
如果你只看到第一个 “this string” 行，意味着你没有正确地处理递归页故障。
运行 `user/faultallocbad` 你应该会看到：
```
    ...
    [00000000] new env 00001000
    [00001000] user_mem_check assertion failure for va deadbeef
    [00001000] free env 00001000
```
确保你理解了为什么 `user/faultalloc` 和 `user/faultallocbad` 的行为是不一样的。
> 
> **小挑战！**扩展你的内核，让它不仅是页故障，而是在用户空间中运行的代码能够产生的所有类型的处理器异常，都能够被重定向到一个用户模式中的异常服务程序上。写出用户模式测试程序，去测试各种各样的用户模式异常处理，比如除零错误、一般保护故障、以及非法操作码。
> 
> 
> 
#### 实现写时复制 Fork
现在，你有个内核功能要去实现，那就是在用户空间中完整地实现写时复制 `fork()`。
我们在 `lib/fork.c` 中为你的 `fork()` 提供了一个框架。像 `dumbfork()`、`fork()` 应该会创建一个新环境，然后通过扫描父环境的整个地址空间，并在子环境中设置相关的页映射。重要的差别在于，`dumbfork()` 复制了页，而 `fork()` 开始只是复制了页映射。`fork()` 仅当在其中一个环境尝试去写入它时才复制每个页。
`fork()` 的基本控制流如下：
1. 父环境使用你在上面实现的 `set_pgfault_handler()` 函数，安装 `pgfault()` 作为 C 级页故障服务程序。
2. 父环境调用 `sys_exofork()` 去创建一个子环境。
3. 在它的地址空间中，低于 UTOP 位置的、每个可写入页、或写时复制页上，父环境调用 `duppage` 后，它应该会映射页写时复制到子环境的地址空间中，然后在它自己的地址空间中重新映射页写时复制。[ 注意：这里的顺序很重要（即，在父环境中标记之前，先在子环境中标记该页为 COW）！你能明白是为什么吗？尝试去想一个具体的案例，将顺序颠倒一下会发生什么样的问题。] `duppage` 把两个 PTE 都设置了，致使那个页不可写入，并且在 “avail” 字段中通过包含 `PTE_COW` 来从真正的只读页中区分写时复制页。
然而异常栈是不能通过这种方式重映射的。对于异常栈，你需要在子环境中分配一个新页。因为页故障服务程序不能做真实的复制，并且页故障服务程序是运行在异常栈上的，异常栈不能进行写时复制：那么谁来复制它呢？
`fork()` 也需要去处理存在的页，但不能写入或写时复制。
4. 父环境为子环境设置了用户页故障入口点，让它看起来像它自己的一样。
5. 现在，子环境准备去运行，所以父环境标记它为可运行。
每次其中一个环境写一个还没有写入的写时复制页时，它将产生一个页故障。下面是用户页故障服务程序的控制流：
1. 内核传递页故障到 `_pgfault_upcall`，它调用 `fork()` 的 `pgfault()` 服务程序。
2. `pgfault()` 检测到那个故障是一个写入（在错误代码中检查 `FEC_WR`），然后将那个页的 PTE 标记为 `PTE_COW`。如果不是一个写入，则崩溃。
3. `pgfault()` 在一个临时位置分配一个映射的新页，并将故障页的内容复制进去。然后，故障服务程序以读取/写入权限映射新页到合适的地址，替换旧的只读映射。
对于上面的几个操作，用户级 `lib/fork.c` 代码必须查询环境的页表（即，那个页的 PTE 是否标记为 `PET_COW`）。为此，内核在 `UVPT` 位置精确地映射环境的页表。它使用一个 [聪明的映射技巧](https://pdos.csail.mit.edu/6.828/2018/labs/lab4/uvpt.html) 去标记它，以使用户代码查找 PTE 时更容易。`lib/entry.S` 设置 `uvpt` 和 `uvpd`，以便于你能够在 `lib/fork.c` 中轻松查找页表信息。
> 
> **练习 12**、在 `lib/fork.c` 中实现 `fork`、`duppage` 和 `pgfault`。
> 
> 
> 使用 `forktree` 程序测试你的代码。它应该会产生下列的信息，在信息中会有 ‘new env'、'free env'、和 'exiting gracefully’ 这样的字眼。信息可能不是按如下的顺序出现的，并且环境 ID 也可能不一样。
> 
> 
> 
> ```
>         1000: I am ''
>         1001: I am '0'
>         2000: I am '00'
>         2001: I am '000'
>         1002: I am '1'
>         3000: I am '11'
>         3001: I am '10'
>         4000: I am '100'
>         1003: I am '01'
>         5000: I am '010'
>         4001: I am '011'
>         2002: I am '110'
>         1004: I am '001'
>         1005: I am '111'
>         1006: I am '101'
> ```
> 
> 
.
> 
> **小挑战！**实现一个名为 `sfork()` 的共享内存的 `fork()`。这个版本的 `sfork()` 中，父子环境共享所有的内存页（因此，一个环境中对内存写入，就会改变另一个环境数据），除了在栈区域中的页以外，它应该使用写时复制来处理这些页。修改 `user/forktree.c` 去使用 `sfork()` 而是不常见的 `fork()`。另外，你在 Part C 中实现了 IPC 之后，使用你的 `sfork()` 去运行 `user/pingpongs`。你将找到提供全局指针 `thisenv` 功能的一个新方式。
> 
> 
> 
.
> 
> **小挑战！**你实现的 `fork` 将产生大量的系统调用。在 x86 上，使用中断切换到内核模式将产生较高的代价。增加系统调用接口，以便于它能够一次发送批量的系统调用。然后修改 `fork` 去使用这个接口。
> 
> 
> 你的新的 `fork` 有多快？
> 
> 
> 你可以用一个分析来论证，批量提交对你的 `fork` 的性能改变，以它来（粗略地）回答这个问题：使用一个 `int 0x30` 指令的代价有多高？在你的 `fork` 中运行了多少次 `int 0x30` 指令？访问 `TSS` 栈切换的代价高吗？等待 …
> 
> 
> 或者，你可以在真实的硬件上引导你的内核，并且真实地对你的代码做基准测试。查看 `RDTSC`（读取时间戳计数器）指令，它的定义在 IA32 手册中，它计数自上一次处理器重置以来流逝的时钟周期数。QEMU 并不能真实地模拟这个指令（它能够计数运行的虚拟指令数量，或使用主机的 TSC，但是这两种方式都不能反映真实的 CPU 周期数）。
> 
> 
> 
到此为止，Part B 部分结束了。在你运行 `make grade` 之前，确保你通过了所有的 Part B 部分的测试。和以前一样，你可以使用 `make handin` 去提交你的实验。
### Part C：抢占式多任务处理和进程间通讯（IPC）
在实验 4 的最后部分，你将修改内核去抢占不配合的环境，并允许环境之间显式地传递消息。
#### 时钟中断和抢占
运行测试程序 `user/spin`。这个测试程序 fork 出一个子环境，它控制了 CPU 之后，就永不停歇地运转起来。无论是父环境还是内核都不能回收对 CPU 的控制。从用户模式环境中保护系统免受 bug 或恶意代码攻击的角度来看，这显然不是个理想的状态，因为任何用户模式环境都能够通过简单的无限循环，并永不归还 CPU 控制权的方式，让整个系统处于暂停状态。为了允许内核去抢占一个运行中的环境，从其中夺回对 CPU 的控制权，我们必须去扩展 JOS 内核，以支持来自硬件时钟的外部硬件中断。