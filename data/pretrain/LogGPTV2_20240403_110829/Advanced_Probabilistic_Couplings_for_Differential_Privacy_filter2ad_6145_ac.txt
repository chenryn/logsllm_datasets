a bound number of iterations, again assuming that the guards are
equal in both programs.
The next two rules, [LAPNULL] and [LAPGEN], are for relating
two sampling instructions from the Laplace distribution. Intuitively
[LAPNULL] models adding identical noise on both sides, so that
the distance between the samples (y1(cid:104)1(cid:105), y2(cid:104)2(cid:105)) is equal to the
distance between the means (e1(cid:104)1(cid:105), e2(cid:104)2(cid:105)). [LAPGEN] is a general
rule for assuming that the two samples are shifted and related by
y1(cid:104)1(cid:105) + k = y2(cid:104)2(cid:105); the privacy cost depends on how far the means
(e1(cid:104)1(cid:105) + k, e2(cid:104)2(cid:105)) are.
The ﬁnal group of rules are the structural rules. Besides the usual
rules for consequence and framing ([CONSEQ] and [FRAME]), the
most interesting rule is the pointwise equality rule [PW-EQ]. This
rule proves differential privacy by showing a pointwise judgment
for each possible output value i, and is the key tool for supporting
privacy proofs beyond the standard composition theorems.
3.5 The union bound logic
When reasoning about privacy, we will sometimes need to prove
probabilistic bounds on accuracy. Since accuracy properties are not
relational, we cannot verify them in apRHL. There is a long history
of research for formally verifying probabilistic properties, and we
are free to choose any of these techniques to interface with our logic.
In our favor, we are interested in simple accuracy properties of the
form Pr[Ψ]  0] < 0.2, stating that the probability x is positive
is at most 0.2, is an accuracy property. Accuracy properties appear
in privacy proofs in a variety of ways. For instance, they may imply
that the privacy cost  is smaller than expected. Or, privacy may be
conditional: if the accuracy property holds then we have differential
privacy, otherwise the algorithm fails and there is no guarantee.
Programs in the latter case satisfy (, δ)-differential privacy, where
the probability of failure is included in δ.
4.1 Up-to-bad reasoning
To integrate accuracy assertions into apRHL, we will use a
technique from cryptographic veriﬁcation: up-to-bad reasoning.
Roughly speaking, rather than directly proving the equality lifting
corresponding to differential privacy:
µ1 (=)(cid:93)(,δ) µ2,
we will prove a conditional, up-to-bad lifting:
µ1 {(x1, x2) | (¬Φ(x1, x2) → x1 = x2)}(cid:93)(,δ) µ2.
Here, Φ is an assertion involving just variables from one side.
Roughly speaking, the lifting shows that if the bad event Φ does not
hold, then we have differential privacy. Then, we conclude the proof
with a structural rule that combines the bad event assertion—proved
externally in aHL—with the up-to-bad lifting, removing the bad
event while adjusting the privacy parameters (, δ).
To support this reasoning in our program logic, we propose the
two rules in Fig. 3. The rules, [UTB-L] and [UTB-R], internalize
an approximate version of up-to-bad reasoning. If the assertion Θ
holds, then we have the (, δ)-lifting of equality. So, if we know
the probability of ¬Θ is at most δ(cid:48), then we can show the (, δ +
δ(cid:48))-differential privacy when Θ is a property of the ﬁrst run, and
(, δ + eδ(cid:48))-differential privacy when Θ is a property of the second
run. The asymmetry in the left and right versions of the rule reﬂects
the asymmetric deﬁnition of approximate lifting, which is in turn
inspired by the asymmetric deﬁnition of differential privacy.
In order to include these rules, we show that they are valid. To
prove the equality lifting for privacy, we would like to use the equiv-
alence in Proposition 11. However, there is a catch: we only know
that the distributions over e are differentially private—the distri-
butions over the whole memory may not be differentially private.
Therefore, we will use a new property of approximate liftings: they
are well-behaved when mapping the underlying distribution.
Proposition 12. For a function f : A → B, let f (cid:93): Distr(A) →
Distr(B) denote function lifted to a map on distributions. If f is
surjective, and R is a relation on B, then
µ1 {(x1, x2) | f (x1) R f (x2)}(cid:93)(,δ) µ2
if and only if
f (cid:93) (µ1) {(y1, y2) | y1 R y2}(cid:93)(,δ)f (cid:93) (µ2).
In particular, if we have a set E of equivalence classes of A
and the distribution µ/E : Distr(E) represents the probability of
being in each equivalence class, taking f : A → E mapping an
element to its equivalence class and R to be the equivalence relation
gives a result by Barthe and Olmedo [2, Proposition 8]:
µ1 (=E)(cid:93)(,δ) µ2 ⇐⇒ µ1/E (=)(cid:93)(,δ) µ2/E.
ASSN (cid:96) x1 ← e1 ∼(cid:104)0,0(cid:105) x2 ← e2 : Ψ{e1(cid:104)1(cid:105), e2(cid:104)2(cid:105)/x1(cid:104)1(cid:105), x2(cid:104)2(cid:105)} =⇒ Ψ
COND
(cid:96) c1 ∼(cid:104),δ(cid:105) c2 : Φ ∧ b1(cid:104)1(cid:105) =⇒ Ψ
(cid:96) if b1 then c1 else c
2 : Φ ∧ ¬b1(cid:104)1(cid:105) =⇒ Ψ
(cid:48)
1 ∼(cid:104),δ(cid:105) if b2 then c2 else c
2 : Φ ∧ b1(cid:104)1(cid:105) = b2(cid:104)2(cid:105) =⇒ Ψ
(cid:48)
(cid:48)
1 ∼(cid:104),δ(cid:105) c
(cid:96) c
(cid:48)
SEQ
(cid:96) c1 ∼(cid:104),δ(cid:105) c2 : Φ =⇒ Ψ
(cid:48)
1 ∼(cid:104)(cid:48),δ(cid:48)(cid:105) c
(cid:96) c
(cid:48)
(cid:48)
(cid:48)
2 : Ψ
1 ∼(cid:104)+(cid:48),δ+δ(cid:48)(cid:105) c2; c
2 : Φ =⇒ Ψ
(cid:48)
(cid:48)
(cid:96) c1; c
=⇒ Ψ
WHILE
(cid:96) c1 ∼(cid:104)k,δk(cid:105) c2 : Θ ∧ b1(cid:104)1(cid:105) ∧ b2(cid:104)2(cid:105) ∧ e(cid:104)1(cid:105) = k =⇒ Θ ∧ b1(cid:104)1(cid:105) = b2(cid:104)2(cid:105) ∧ e(cid:104)1(cid:105) < k
(cid:96) while b1 do c1 ∼(cid:104)(cid:80)n
|= Θ ∧ e(cid:104)1(cid:105) ≤ 0 → ¬b1(cid:104)1(cid:105)
k=1 δk(cid:105) while b2 do c2 : Θ ∧ b1(cid:104)1(cid:105) = b2(cid:104)2(cid:105) ∧ e(cid:104)1(cid:105) ≤ n =⇒ Θ ∧ ¬b1(cid:104)1(cid:105) ∧ ¬b2(cid:104)2(cid:105)
k=1 k,(cid:80)n
LAPNULL
(cid:96) y1 $← L(e1) ∼(cid:104)0,0(cid:105) y2 $← L(e2) : (cid:62) =⇒ y1(cid:104)1(cid:105) − y2(cid:104)2(cid:105) = e1(cid:104)1(cid:105) − e2(cid:104)2(cid:105)
y1 /∈ F V (e1)
y2 /∈ F V (e2)
LAPGEN (cid:96) y1 $← L(e1) ∼(cid:104)k(cid:48)·,0(cid:105) y2 $← L(e2) : |k + e1(cid:104)1(cid:105) − e2(cid:104)2(cid:105)| ≤ k
(cid:48) → Ψ
(cid:48) ∼(cid:104)(cid:48),δ(cid:48)(cid:105) c1 : c2 =⇒ Ψ
(cid:48)
(cid:96) Φ
(cid:48)
=⇒ y1(cid:104)1(cid:105) + k = y2(cid:104)2(cid:105)
(cid:48) ≤ 

(cid:48) ≤ δ
δ
CONSEQ
(cid:48)
|= Φ → Φ
|= Ψ
(cid:96) c1 ∼(cid:104),δ(cid:105) c2 : Φ =⇒ Ψ
FRAME
(cid:96) c1 ∼(cid:104),δ(cid:105) c2 : Φ =⇒ Ψ
F V (Θ) ∩ M V (c1, c2) = ∅
(cid:96) c1 ∼(cid:104),δ(cid:105) c2 : Φ ∧ Θ =⇒ Ψ ∧ Θ
PW-EQ
∀i. (cid:96) c1 ∼(cid:104),δi(cid:105) c2 : Φ =⇒ x(cid:104)1(cid:105) = i → x(cid:104)2(cid:105) = i
(cid:96) c1 ∼(cid:104),(cid:80)
i∈I δi(cid:105) c2 : Φ =⇒ x(cid:104)1(cid:105) = x(cid:104)2(cid:105)
Figure 2: Selected proof rules of apRHL [6, 10]
|= Φ → Φ0(cid:104)1(cid:105)
|= Φ → Φ0(cid:104)2(cid:105)
UTB-L
UTB-R
(cid:96) c ∼(cid:104),δ(cid:105) c
(cid:48)
(cid:96) c ∼(cid:104),δ+δ(cid:48)(cid:105) c
(cid:96) c ∼(cid:104),δ(cid:105) c
(cid:48)
(cid:96) c ∼(cid:104),δ+eδ(cid:48)(cid:105) c
(cid:48)
(cid:48)
: Φ =⇒ Θ(cid:104)1(cid:105) → e(cid:104)1(cid:105) = e(cid:104)2(cid:105)
: Φ =⇒ e(cid:104)1(cid:105) = e(cid:104)2(cid:105)
: Φ =⇒ Θ(cid:104)2(cid:105) → e(cid:104)1(cid:105) = e(cid:104)2(cid:105)
: Φ =⇒ e(cid:104)1(cid:105) = e(cid:104)2(cid:105)
(cid:96)δ(cid:48) c : Φ0 =⇒ Θ
(cid:96)δ(cid:48) c
(cid:48)
: Φ0 =⇒ Θ
Figure 3: Up-to-bad rules
This result allows us to prove an approximate lifting for a distri-
bution over memories by proving an approximting lifting for the
distribution over a single variable or expression. We defer the details
of the proof to the full version. Now, we are ready to show soundness
of the up-to-bad rules.
Theorem 13. The rules [UTB-L] and [UTB-R] are sound.
Proof. We will start with [UTB-L]. Take any two memories
(m1, m2) such that (m1, m2) |= Φ, and let µ1, µ2 be [[c]]m1 and
[[c(cid:48)]]m2 respectively. Note that m1 |= Φ0. By validity of the premise,
we know
[¬Θ] ≤ δ
(cid:48)
Pr
m∼µ1
and we have a pair of witnesses µL, µR for the relation
R (cid:44) Θ(cid:104)1(cid:105) → e(cid:104)1(cid:105) = e(cid:104)2(cid:105),
such that ∆(µL, µR) ≤ δ. Our goal is to show that the marginal
distributions of [[e]] in µ1, µ2 satisfy (, δ + δ(cid:48))-differential privacy,
i.e. for any set S,
Pr
m∼µ1
[[[e]]m ∈ S] ≤ e Pr
m(cid:48)∼µ2
[[[e]]m(cid:48) ∈ S] + δ + δ
(cid:48)
.
To begin, we know that
Pr
m∼µ1
[[[e]]m ∈ S] = Pr
m∼µ1
[[[e]]m ∈ S ∧ m |= Θ]
[[[e]]m ∈ S ∧ m |= ¬Θ]
[[[e]]m ∈ S ∧ m |= Θ] + δ
(cid:48)
+ Pr
m∼µ1
≤ Pr
m∼µ1
since the probability of ¬Θ in µ1 is at most δ(cid:48). Now, we can con-
clude with the coupling:
[[[e]]m ∈ S ∧ m |= Θ] + δ
(cid:48)
[[[e]]m ∈ S ∧ m |= Θ] + δ
(cid:48)
[[[e]]m ∈ S ∧ m |= Θ] + δ + δ
(cid:48)
Pr
m∼µ1
=
≤ e
≤ e
Pr
(m,m(cid:48))∼µL
Pr
(m,m(cid:48))∼µR
Pr
m ∈ S] + δ + δ
(cid:48)
[[[e]]
(m,m(cid:48))∼µR
m ∈ S] + δ + δ
(cid:48)
[[[e]]
,
(cid:48)
(cid:48)
= e Pr
m(cid:48)∼µ2
where the ﬁrst inequality uses ∆(µL, µR) ≤ δ, while the second
inequality uses (m, m(cid:48)) ∈ supp(µR). So, the distributions of [[e]]
satisfy differential privacy. By Proposition 11 and Proposition 12
with equivalence classes deﬁned by the value of [[e]], we can con-
clude soundness of [UTB-L].
We can show soundness of [UTB-R] in a similar way. Let µ1, µ2
be as above. We can use the coupling as follows:
Pr
m∼µ1
=
≤ e
= e
+ e
≤ e
[[[e]]m ∈ S]
Pr
(m,m(cid:48))∼µL