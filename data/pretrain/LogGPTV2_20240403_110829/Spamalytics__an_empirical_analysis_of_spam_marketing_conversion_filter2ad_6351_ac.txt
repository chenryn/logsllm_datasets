### URL Construction and Spam Campaigns

To ensure that the generated spam is indistinguishable from genuine Storm sites, we meticulously construct the URLs in the same manner as the real Storm sites. This includes using raw IP addresses, as seen in self-propagation campaigns, or the specific "noun-noun.com" naming convention used by the pharmacy campaign. An important exception, unique to the pharmacy campaign, is the addition of an identifier at the end of each URL. This identifier allows us to unambiguously associate individual spam messages with subsequent site accesses. We did not add this identifier to the self-propagation campaigns, as their URLs typically consist entirely of raw IP addresses, and adding a text identifier might reduce the authenticity and potentially bias user click behavior.

### Storm C&C Dataflow and Infrastructure

**Figure 2: The Storm spam campaign dataflow (Section 3.3) and our measurement and rewriting infrastructure (Section 4).**

1. **Workers Request Spam Tasks:** Workers request spam tasks through proxies.
2. **Proxies Forward Workload Responses:** Proxies forward spam workload responses from master servers.
3. **Workers Send Spam:** Workers send the spam.
4. **Delivery Reports:** Workers return delivery reports.

Our infrastructure infiltrates the Command and Control (C&C) channels between workers and proxies, allowing us to monitor and rewrite the traffic.

### Detailed Description of the Storm C&C Rewriting Engine

In the following sections, we provide a detailed description of our Storm C&C rewriting engine, discuss how we use this tool to obtain empirical estimates for spam delivery, click-through, and conversion rates, and describe the heuristics used to differentiate real user visits from those driven by automated crawlers, honeyclients, etc. We also review the ethical basis upon which these measurements were conducted.

#### 4.1 C&C Protocol Rewriting

Our runtime C&C protocol rewriter consists of two main components:

1. **Custom Click-based Network Element:** This element redirects potential C&C traffic to a fixed IP address and port.
2. **User-space Proxy Server:** Implemented in Python, this server accepts incoming connections and impersonates the proxy bots. It then forwards connections back into the Click element, which redirects the traffic to the intended proxy bot.

To associate connections, the Click element injects a SOCKS-style destination header into the flows. The proxy server uses this header to forward a connection to a specific address and port, allowing the Click element to make the association. From that point on, traffic flows transparently through the proxy server, where C&C traffic is parsed and rewritten as required. Rules for rewriting can be independently installed for templates, dictionaries, and email address target lists. The rewriter logs all C&C traffic between workers and our proxy bots, between the proxy bots and the master servers, and all rewriting actions on the traffic.

Since C&C traffic arrives on arbitrary ports, the proxy server is designed to handle any type of connection and fall back to passive pass-through for non-C&C traffic.

### Mimicking Web Sites

We created two web sites to mimic those used in the associated campaigns (screenshots in Figure 3):

1. **Pharmaceutical Site:**
   - A nearly-precise replica of the site normally advertised by Storm, including the same naming convention for the domains.
   - Our site mirrors the original site’s user interface, product advertising, and navigation up to the checkout process.
   - When a user clicks on "Checkout," we return a 404 error message.
   - We log all accesses to the site, allowing us to determine when a visitor attempts to make a purchase and what the content of their shopping cart is at the time.

2. **Postcard-Themed Self-Propagation Site:**
   - Unlike the pharmacy example, we could not mirror the graphical content of the postcard site, as it was stolen from a legitimate Internet postcard site.
   - Instead, we created a close analog designed to mimic the overall look and feel.
   - We “defanged” our site by replacing its link to the Storm malware with a benign executable.
   - If run, our executable performs a simple HTTP POST with a harmless payload ("data=1") to a server under our control and then exits.
   - As a rough timeout mechanism, the executable will not send the message if the system date is 2009 or later.
   - We served three executables with different target filenames in the POST command, matching the postcard site's behavior.
   - All accesses to the site are logged, and we can identify when our binary has been downloaded and executed.

### Separating Users from Crawlers

Not all visits to our web sites are prospective conversions. Automated and semi-automated processes, such as web crawlers, honeyclient systems, and security researchers, also visit our sites. To filter out these visits (which we generically call "crawlers") from intentional ones, we have developed a series of heuristics:

1. **Unique Identifier Check:** Hosts that access the pharmacy site without using a URL containing the unique identifier are considered crawlers.
2. **Robots.txt Access:** Hosts that access `robots.txt` or make malformed requests are blacklisted.
3. **JavaScript and Image Loading:** Hosts that disable JavaScript and do not load embedded images are blacklisted.
4. **Multiple Unique Identifiers:** IP addresses accessing the pharmacy site with more than one unique identifier with the same User-Agent field are blacklisted.
5. **Executable Requests:** Any host that requests the downloaded executable from the postcard site ten or more times is blacklisted.
6. **New IP Addresses:** We injected new IP addresses (never advertised in spam messages) into the self-propagation dictionary during periods of inactivity. Visitors to these IP addresses are added to our crawler blacklist.

### Measurement Ethics

We have carefully designed experiments that are consistent with current U.S. legal doctrine and fundamentally ethical. Our instrumented proxy bots do not create any new harm; they only provide a conduit between worker bots making requests and master servers providing responses. Where we modify C&C messages, these actions strictly reduce harm. Users who click on altered spam are directed to innocuous doppelganger websites that do not infect users with malware or collect credit card information.

### Timeline and Statistics

**Figure 5: Timeline of proxy bot workload.**

**Table 1: Campaigns used in the experiment.**

| CAMPAIGN | DATES | WORKERS | E-MAILS |
|----------|-------|---------|---------|
| Pharmacy | Mar 21 – Apr 15 | 31,348 | 347,590,389 |
| Postcard | Mar 9 – Mar 15 | 17,639 | 83,665,479 |
| April Fool | Mar 31 – Apr 2 | 3,678 | 38,651,124 |
| **Total** | | **52,665** | **469,906,992** |

**Figure 4: Number of e-mail messages assigned per hour for each campaign.**

**Figure 3: Screenshots of the Web sites operated to measure user click-through and conversion.**

**DOMAIN**
- hotmail.com
- yahoo.com
- gmail.com
- aol.com
- yahoo.co.in
- sbcglobal.net

This comprehensive approach ensures that our measurements are both accurate and ethically sound.