= PrD,A[S| t]
= PrD,A[S| t]
DEFINITION 3.5
(DOWNWARD SCALABLE FAMILIES). We
say that that a family D is downward scalable if and only if for any
distribution D ∈ D, any entity t such that 0  0, D also contains a distribution D′ that is t-scaled from
D such that PrD′ [t]  γ · PrD,A[S|¬ t]. There are two cases.
Case one: PrD,A[S|t] > 0 and PrD,A[S|¬ t] = 0. Let p = 1
γ .
Because D is downward scalable, it must contain a D′ which is t-
scaled from D such that PrD′ [t] = p′  γp′ =
γ PrD′ [t], which contradicts the fact that A satisﬁes (D, γ)-PMP.
Case two: PrD,A[S|t] = α PrD,A[S|¬t], where α > γ ≥ 1.
Because D is downward scalable, it must contains a D′ which is t-
scaled from D such that PrD′ [t] = p′  γ, one could choose a small p′
(forcing p′  γ, contradicts
the fact that A satisﬁes (D, γ)-PMP.
3.4 Infeasibility of PMP under Arbitrary Dis-
tributions
PMP is parameterized by D. Given two families of distributions
D1 and D2 such that D1 ⊆ D2, if A provides (D2, γ)-PMP, then
A also provides (D1, γ)-PMP. Therefore, to provide the maximum
level of privacy, it is desirable to provide (D, γ)-PMP for as large
a family D as possible. We use DU to denote the largest family of
distributions, namely the set of all distributions over 2U . Unfortu-
nately, achieving PMP under DU requires A to provide almost no
utility, as A must provide very similar output distributions on any
pair of dataset T1 and T2, even if when T1 = ∅ and T2 = U.
PROPOSITION 3.7. If an algorithm A provides (DU , γ)-PMP,
then for any datasets (T1, T2) such that T1 \ T2 6= ∅, and any
S ⊆ range(A), it must be
Pr[A(T1) ∈ S] ≤ γ Pr[A(T2) ∈ S]
(5)
PROOF. If A provides (DU , γ)-PMP, then it must provide γ-
PMP for the family that consists of all distributions of the form
{hT1 : pi, hT2 : 1 − pi}. Clearly, this family is downward scalable.
Let t be any tuple in T1 \ T2, from Theorem 3.6, A must satisfy
∀S, Pr[S| t] ≤ γ Pr[S|¬t]. Note that Pr[S| t] = Pr[S| T1] and
Pr[S|¬ t] = Pr[S| T2]; thus (5) holds.
Proposition 3.7 requires A’s output on any pair of datasets to be
close. For example, when T1 = U and T2 = ∅, and A is supposed
to answer a simple counting query. For any result that A(U) may
return with probability p, A(∅) must also return it with probability
at least p
γ . This destroys the utility of publishing A(T ), since one
could compute A(∅), and the distribution of A(T ) for any T would
be similar. Therefore, we must be content with choosing some sub-
families of DU for PMP.
3.5 Negative Membership Privacy
Note that satisfying PMP will upper-bound Pr[t|S]; however,
PMP does not lower-bound Pr[t|S]. That is, it is permitted that
after observing an output, one concludes with high conﬁdence that
an entity is not in the input dataset. While we believe that for the
vast majority of cases, satisfying PMP is sufﬁcient for privacy pro-
tection, it is possible that in some unusual situations one desires
protection against inference of non-membership as well as infer-
ence of membership.
DEFINITION 3.8. [Negative Membership Privacy ((D, γ)-
NMP)]: We say that a mechanism A provides γ-negative member-
ship privacy under a distribution family D ((D, γ)-NMP), if and
only if for any S ⊆ range(A), any D ∈ D, and any tuple t ∈ U,
we have both Pr[¬t|S] ≤ γ · Pr[¬t] and Pr[t|S] ≥ Pr[t]
γ , which
are equivalent to
Pr[¬ t|S] ≤ min(cid:18)γ Pr[¬t],
γ − 1 + Pr[¬t]
γ
(cid:19) ,
and to
Pr[t|S] ≥ max(cid:18)γ Pr[t] − γ + 1,
Pr[t]
γ (cid:19)
The properties of NMP are analogous to PMP.
(6)
(7)
DEFINITION 3.9
(UPWARD SCALABLE FAMILIES). We say
that that a family D is upward scalable if and only if for any dis-
tribution D ∈ D, any entity t such that 0  p.
THEOREM 3.10. For any mechanism A, γ, and any upward s-
calable family D, A satisﬁes (D, γ)-NMP if and only if for any
D ∈ D, any entity t, any entity t s.t. 0 < Pr[t] < 1, and any S, we
have Pr[S|¬t] ≤ γ · Pr[S|t].
The proof for Theorem 3.10 is analogous of the proof for Theo-
rem 3.6, and is omitted here.
3.6 Privacy Axioms
In [18], it is suggested that all privacy notions should satisfy
the two axioms: the Privacy Axiom of Choice and the Axiom of
Transformation Invariance. The following two theorems show that
(D, γ)-PMP satisfy both axioms.
THEOREM 3.11. Given two mechanisms A1 and A2 that both
satisfy (D, γ)-PMP, for any p ∈ [0, 1], let Ap be the mechanism
that outputs A1 with probability p and A2 with probability 1 − p,
then Ap satisﬁes (D, γ)-PMP.
Proof is Appendix A.1
4. DIFFERENTIAL PRIVACY AS MEM-
BERSHIP PRIVACY
Informally, differential privacy requires that the output of a data
analysis mechanism is not overly affected by any single tuple in the
input dataset.
DEFINITION 4.1
(ǫ-DIFFERENTIAL PRIVACY [8, 10]).
A mechanism A gives ǫ-differential privacy if for any pair of
neighboring datasets T and T ′, and any S ⊆ Range(A),
Pr[A(T ) ∈ S] ≤ eǫ · Pr[A(T ′) ∈ S].
There are two major ﬂavors of differential privacy, depending on
the condition under which two datasets are considered to be neigh-
bors. In [19], these were referred to as unbounded and bounded
differential privacy. In Unbounded Differential Privacy (UDP), T
and T ′ are neighbors if T can be obtained from T ′ by adding or
removing an entity. In Bounded Differential Privacy (BDP), T and
T ′ are neighbors if T can be obtained from T ′ by replacing one
entity in T ′ with another entity.
In UDP, closeness in output distributions is required only be-
tween two datasets that contain the same number of entities. There-
fore, one could output the accurate total number of entities in a
dataset without affecting BDP at all. Thus, there exist algorithm-
s that satisfy ǫ-BDP for ǫ = 0 and yet do not satisfy ǫ′-UDP for
any value of ǫ′. On the other hand, any algorithm that satisﬁes ǫ-
UDP must also satisfy 2ǫ-BDP, since replacing one entity can be
achieved by removing an entity and then adding another.
In the rest of this section, we show that these two differential pri-
vacy notions are instantiations of the membership privacy frame-
work, by choosing particular families of distributions. This rela-
tionship enables a clear understanding of the power and limitations
of differential privacy.
4.1 Unbounded Differential Privacy
We ﬁrst establish the relation between UDP and membership pri-
vacy. We decompose the UDP condition into the conjunction of the
following two conditions.
DEFINITION 4.2
(POSITIVE AND NEGATIVE UDP). A
mechanism A gives ǫ-positive unbounded differential privacy if
and only if for any dataset T , any entity t, and any S ⊆ Range(A),
Pr[A(T ∪ {t}) ∈ S] ≤ eǫ · Pr[A(T ) ∈ S].
(8)
A mechanism A gives ǫ-negative unbounded differential privacy if
and only if for any dataset T , any entity t, and any S ⊆ Range(A),
Pr[A(T ) ∈ S] ≤ eǫ · Pr[A(T ∪ {t}) ∈ S].
(9)
As it turns out, UDP corresponds to membership privacy under
the family of mutually independent distributions.
DISTRIBUTION FAMILY 4.3. DI : Mutually Independent (MI)
Distributions. We say that a distribution is mutually independent if
and only if it can be characterized by assigning a probability pt to
each tuple t such that the probability of any dataset T is given by
Pr[T ] = Yt∈T
ptYt6∈T
(1 − pt)
THEOREM 3.12. Given A1 that satisﬁes (D, γ)-PMP, and any
algorithm A2, A(·) = A2(A1(·)) satisﬁes (D, γ)-PMP.
Proof is Appendix A.2. The same results hold for NMP; we omit
explicitly stating them here.
DI includes all such mutually independent distributions over U.
We note that DI includes distributions in which the probabilities
for different entities differ. In particular, DI includes distribution-
s where some entities have probability 1 and some other entities
have probability 0. We also observe that in a mutually independent
distribution, we have
Pr[T ∪ {t}] = Pr[T ]qt, where qt =
pt
1 − pt
(10)
We note that the deﬁnition for positive UDP essentially means
that Pr[S|t]
Pr[S|¬t] ≤ eǫ for all prior distributions such that each distri-
bution has just two possible datasets: D ∪ {t} and D. We use D2
I
to denote the family that includes all such distributions.
DISTRIBUTION FAMILY 4.4. D2
I: 1-out-2 MI Distributions.
D2
I includes every MI distribution for which there are only two
datasets with nonzero probability.
In other words, there exists t
such that 0 < Pr[t] < 1, and furthermore, for any t′ 6= t, either
Pr[t′] = 1 or Pr[t′] = 0. In such a distribution, only two datasets
are possible: T ∪ {t} and T , where T = {t ∈ U | Pr[t] = 1}.
Clearly, D2
I is a subset of DI. Also, D2
I is both upward and down-
ward scalable. Combining the observation that positive UDP is e-
quivalent to Pr[S|t]
I with Theorem 3.6, it follows that
ǫ-positive UDP is equivalent to (D2
Pr[S|¬t] ≤ eǫ for D2
I , eǫ)-PMP.
The elegance and power of differential privacy lies in the fact
that while positive UDP directly achieves PMP only for D2
I, it turns
that this is sufﬁcient for achieving PMP for the larger family DI , as
shown by the following theorem.
THEOREM 4.5. A mechanism A satisﬁes ǫ-positive UDP if and
only if it provides (DI , eǫ)-PMP.
PROOF. The “if” direction is trivial since DI is a superset of D2
I,
and ǫ-positive UDP is equivalent to (D2
I , eǫ)-PMP.
Pr[S|¬t] ≤ eǫ. Satisfying positive UDP gives us Pr[S|T ∪{t}]
For the “only if” direction. If A satisﬁes ǫ-positive UDP, then
given any distribution D ∈ DI, for any entity t, we want to show
that Pr[S|t]
Pr[S|T ] ≤
eǫ for any individual dataset T . Let Ti range over 2U −{t}, i.e., Ti
ranges over all datasets without t, then Ti ∪ {t} ranges over all
datasets that contain the tuple t. We have
Pr[S|t]
Pr[S|¬t] =
(cid:16)PTi
Pr[Ti∪{t}]
Pr[Ti∪{t}] Pr[S|Ti∪{t}](cid:17)/ PTi
(cid:16)PTi
Pr[Ti] Pr[S|Ti](cid:17)/ PTi
Pr[Ti]·qt Pr[S|Ti∪{t}](cid:17)/ PTi
(cid:16)PTi
Pr[Ti] Pr[S|Ti∪{t}]
Pr[Ti] Pr[S|Ti](cid:17)/ PTi
Pr[Ti]
Pr[Ti]
Pr[Ti]·qt
(cid:16)PTi
=
= PTi
≤ PTi
PTi
PTi
Pr[Ti] Pr[S|Ti]
Pr[Ti] Pr[S|Ti]eǫ
Pr[Ti] Pr[S|Ti] = eǫ
The second equality above uses the fact that D is mutually inde-
pendent and therefore Pr[Ti ∪ {t}] = Pr[Ti]qt (Equation 10). The
≤ above uses the positive UDP condition.
A natural question is whether ǫ-positive UDP would satisfy PM-
P for distributions that are not mutually independent. The follow-
ing observations hints that in a sense the family of all mutually-
independent distributions is the limit for which UDP guarantees
PMP. This corroborates the analysis that differential privacy’s pro-
tection is limited to the case where all entities are mutually inde-
pendent [19].
Consider the following distribution Dk
NI , in which all entities
except for t1, t2, · · · , tk are independent from any other sets of
entities but t1, t2, · · · , tk are totally correlated, i.e., either all of
them or none of them are included. It is easy to see that satisfy-
NI , ekǫ)-PMP; however, there exist
ing ǫ-positive UDP satisﬁes (Dk
mechanisms that satisfy ǫ-positive UDP, yet does not satisfy γ-PMP
for any γ < ekǫ.
the number of
random noise