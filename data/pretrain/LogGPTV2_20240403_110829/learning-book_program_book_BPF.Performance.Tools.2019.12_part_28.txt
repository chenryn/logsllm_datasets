[Betired load instructions with L3 cache hits as data sources Supports address
vhen precise (Preclse event1]
nem_load_reti.red.13_miss
[Retired load instructions missed L3 cache as data souroes Supports address
vhen precise (Preclse event1]
[. . - ]
This output shows the alias names you can use with o. For example, you can count these events
on all CPUs (using a, which recently became the default) and print output with an interval of
1000 milliseconds (I 1000):
t.ine
counts unit events
1.001228842
69 *5.9
men_1load_retized.13_h1t
1.001228842
868, 728
men_load_retired.13_niss
2. 002185329
746, 869
men_load_retired.13_hit
2.002185329
965, 421
men_load_retized.13_nlss
3.002952548
96L*E2.*T
nen_load_retized.13_h1t
[...]
---
## Page 228
6.2 Traditional Tools
191
There are hundreds of PMCs available, documented in the processor vendor guides [Intel 16]
[AMD 10]. You can use PMCs together with model-specific registers (MSRs) to determine how CPU
internal components are performing, the current clock rates of the CPUs, their temperatures and
energy consumption, the throughput on CPU interconnects and memory buses, and more.
tlbstat
As an example use of PMCs, I developed the tlbstat tool to count and summarize translation
lookaside buffer (TLB)related PMCs. My goal was to analyze the performance impact of the Linux
kernel page table isolation (KPTI) patches that work around the Meltdown vulnerability [74] [75]:
+ tlbstat -C0 1
K_CYCLES K_INSTR
IFC DTLB_KALKS ITLB_BALKS K_DTLBCYC_ K_ITLBCYC DTLBS ITLB1
2875793
276051
0.10 89709496
65862302
787913
650834
27,40 22, 63
L550987
85162888 01*0
65213248
TOC08L
644292
27,28 22.52
2885138
276533
0.10 89683045
65813992
787391
650494
27.29 22.55
243104
0.10 79055465
58023221
016669
891EL5
27,40 22.63
[..]
tlbstat prints the following columns:
• K_CYCLES: CPU cycles (in lots of 1000)
● K_INSTR: CPU Instructions (in lots of 1000)
• IPC: Instructions per cycle
• DTLB_WALKS: Data TLB walks (count)
• ITLB_WALKS: Instruction TLB walks (count)
 K_DTLBCYC: Cycles (in lots of 1000) when at least one page-miss handler (PMH) is active
with data TLB walks
● K_ITLBCYC: Cycles (in lots of 1000) when at least one PMH is active with instruction
TLB walks
• DTLB%: Data TLB active cycles as a ratio of total cycles
• ITLB%: Instruction TLB active cycles as a ratio of total cycles
The output shown earlier is from a stress test where the KPT1 overhead was the worst: It shows
27% of CPU cycles in the DTLB and 22% in the ITLB. This means that half of the system-wide
CPU resources were consumed by the memory management unit servicing virtual-to-physical
address translations. If tlbstat showed similar numbers for production workloads, you would want
to direct your tuning efforts toward the TLB.
---
## Page 229
192
2 Chapter 6 CPUs
6.2.3Hardware Sampling
perf(1) can use PMCs in a different mode, where a count is chosen and, at a rate of one in every
count, a PMC event causes an interrupt to be sent to the kernel so that it can capture event state.
For example, the command below records the stack trace (g) for L.3 cache-miss events (e ..) on
all CPUs (a) for 10 seconds (s 1eep 10, a dummy command used to set the duration):
  ---e-0 -5x - 
[ perf record: Moken up 1 tines to rite data ]
[[setdses Ze] eaep*gxed gH sse*e eqoxn pue pexnqdeo ipxooex Ixed 1
The samples can be summarized using perf report or dumped using pexf 1ist:
 perf list
kxorker/u17:4 11563 [007] 2707575,286552: men_1oad_retired.13_mis81
Tfffba5d8c52 move_freepages_block 1[kernel,kallsyns])
Tffba5d8e02 steal_suitable_fallback I[kernel.kallsyns]]
Tffrba5da4a8 get_page_Cron_freeliat ([kernel ,kallsyms[)
Tfffba5dc3fb a1loc_pages_nodenask ([kernel .ka1lsyms|1
Tfffba63a8ea alloc_pages_cuxrent ([kernel.kallsyms)
Tfffc01faa5b cypt_page_alloc <[kernel.kallayms])
Tfffba5d3Tel menpoo1_a1loc ([kernel.kallsyms])
Tfffc01fd870 kcryptd_crypt ([kernel.ka1layms])
Tfffba4a983e pzocess_one_voxk ([kermel kallsyma])
Tfffba4a9as2 vorker_th.read <[kernel.ka1layms])
Tfffba4b066l kthread ([kernel,xa1lsyas])
Tfffbae02205 ret_from_fork ([kernel.kallayms])
[.- - ]
in this case it shows the kernel functions that led to the L.3 cache-miss event.
This output shows a single stack trace sample. The stack is listed in order from child to parent, and
Note that you will want to use PMCs that support precise event-based sampling (PEBS) wherever
possible to minimize issues of interrupt skid.
PMC hardware sampling can also trigger BPF programs. For example, instead of dumping all
sampled stack traces to user space via the perf buffer, BPF can frequency-count them in kernel
context to improve efficiency.
6.2.4 Timed Sampling
Many profilers support timer-based sampling (capturing the instruction pointer or stack trace
at a timed interval). Such profilers provide a coarse, cheap-to-collect view of which software is
consuming CPU resources. There are different types of profilers, some operating in user mode
only and some in kernel mode. Kernel-mode profilers are usually preferred, as they can capture
both kernel- and user-level stacks, providing a more complete picture.
---
## Page 230
6.2 Traditional Tools
193
perf
perf(1) is a kernel-based profiler that supports timed sampling through software events or PMCs:
it defaults to the most accurate technique available. In this example, it is capturing stacks across
all CPUs at 99 Hertz (samples per second per CPU) for 30 seconds:
+ perf record -P 99 -a -g -- sleep 30
I pexf zecoxd: Boken up 1 tines to xrlte data 1
[perf cecord: Captured and vrote 0.,661 MB perf.data (2890 sanples)1
99 Hertz was chosen instead of 100 to avoid lockstep sampling with other software routines,
which would otherwise skew the samples. (This is explained in more detail in Chapter 18.)
Roughly 100 was chosen instead of, say, 10 or 10,000 as a balance between detail and overhead:
Too low, and you don’t get enough samples to see the full picture of execution, including large
and small code paths; too high, and the overhead of samples skews performance and results.
When this perf(1) command is run, it writes the samples to a perf.data file: this has been opti-
mized by use of a kernel buffer and an optimal number of writes to the file system. The output
tells us it only needed to wake up once to write this data.
The output can be summarized using perf report, or each sample can be dumped using per f
scr1pt. For example:
 perf report -n --stdio
[..]
 Ch11dzen
Self
Comnand Shared object
Synbo1
+
99 , 415
0.085
1perf
L1bp thz
ad-2.27.50
[- ]
-_libc_xriti
-99.331--_1ibc_vrite
--98.515=entry_SYsCALl_64_aftex_hvfrane
-=98,381--do_sysca1l_64
1xxs5-=56*86
[ - - - ]
The perf report summary shows a tree of functions from root to child. The order can be reversed,
as it was by default in earlier versions.) Unfortunately, there is not much conclusive to say from
this sample of outputand the full output was six thousand lines, The full output of perf script,
dumping every event, was over sixty thousand lines. These profiles can easily be 10 times this size
on busier systems. A solution in such a case is to visualize the stack samples as a flame graph.
---
## Page 231
194
Chapter 6 CPUs
CPU Flame Graphs
Flame graphs, introduced in Chapter 2, enable visualization of stack traces. They are wel suited
for CPU profiles and are now commonly used for CPU analysis.
The flame graph in Figure 6-3 summarizes the same profile data captured in the previous section.
CPU Flame Graph
Figure 6-3 CPU flame graph
---
## Page 232
6.2 Traditional Tools
195
When this data is presented as a flame graph, it is easy to see that the process named iperf
was consuming all CPU and exactly how: via sock_sendmsg0), which led to two hot on-CPU
functions, copy_user_enhanced_fast_string() and move_freepages_block(), seen as the two
plateaus. On the right is a tower that continues back into the TCP receive path; this is iperf doing
 loopback test,
Below are the steps to create CPU flame graphs using perf(1) to sample stacks at 49 Hertz fo1
30 seconds, and my original flame graph implementation:
 git clone https : //github .com/bzendangzegg/FlameGraph
+cd FlaneGraph
 perf zecord -F 49 -ag -- sleep 30
Bss'tauetg < Td' qdezbaueta/ 1 td gzadaadetrooxoese/-1 xapeau-- 4daos yad +
The stackcollapse-perf.pl program converts perf s cr ipt output into a standard format to be
read by the flamegraph.pl program. There are converters in the FlameGraph repository for many
other profilers. The flamegraph.pl program creates the flame graph as an SVG file with embedded
JavaScript for interactivity when loaded in a browser. flamegraph.pl supports many options for
customizations: run flamegraph.pl help for details.
I recommend that you save the output of perf scr1pt header for later analysis. Netflix has
developed a newer flame graph implementation using d3, along with an additional tool that can 
read pezf scx 1pt output, FlameScope, which visualizes profiles as subsecond offset heatmaps
from which time ranges can be selected to see the flame graph. [76] [77]
Internals
When perf(1) does timed sampling, it tries to use PMC-based hardware CPU cycle overflow events
that trigger a non-maskable interrupt (NMI) to perform the sampling In the cloud, however,
many instance types do not have PMCs enabled. This may be visible in dmesg(1):
M dex6 1 6seup 
2.827349] Performance Events: unsupported p6 CPU model 85 no PM0 driver,
so.ftware events only.
On these systems, perf(1) falls back to an hrtimer-based software interrupt. You can see this when
running perf with v:
+ perf record -F 99 -a -v
Warning;
The cycles erent is not supported, trying to fall back to cpu-elock-ticks
This software interrupt is generally sufficient, although be aware that there are some kernel code
paths that it cannot interrupt: those with IRQs disabled (including some code paths in schedul
ing and hardware events). Your resulting profile will be missing samples from these code paths.
For more about how PMCs work, see Section 2.12 in Chapter 2
---
## Page 233
196
Chapter 6 CPUs
6.2.5 Event Statistics and Tracing
Tools that trace events can also be used for CPU analysis. The traditional Linux tools that do this
are perf(1) and Ftrace. These tools can not only trace events and save per-event details but can also
count events in kernel context.
jed
perf(1) can instrument tracepoints, kprobes, uprobes, and (as of recently) USDT probes. These can
provide some logical context for why CPU resources were consumed.
As an example, consider an ssue where system-wide CPU utilization is high, but there is no
visible process responsible in top(1). The issue could be short-lived processes. To test this hypoth-
esis, count the sched_process_exec tracepoint system-wide using pezf scxipt to show the rate of
exec() family syscalls:
+ perf stat -e sched:sched_process_exec -I 1000
t.ine
count.s
unit events
1, 000258841
169
schedi:sched_process_exec
2 . 00055070T
168
sched:sched_prooess_xec
3.000676643
167
schedi:sched_process_exec
4.000880905
167
sched:sched_process_exec
[...]
This output shows that there were over 160 execs per second. You can record each event using
pert record,then dump the events using perf ser1pt2:
+ perf record -e sched:sched_process_exec -a
^C[ perf record: Noken up 1 times to vrite data ]
[ pexf zecoxd: Captuxed and wzote 3,464 HB pexf.data (95 sanples) ]
4dtxos yzed 
make 28767 [007] T12132.535241: sched:sched_process_exec: f1lenane=/usr/b1n/nake
pid=28767 old_pid=28767
pid=28768 o1d_pid=28768
sh 28768 [004] T12132.537036: sched:sched_process_exec: f11enane=/bin/sh
csake 28769 [007] 712132.538138: sched:sched_process_exec1 f11enane=/usx/bLn/cnake
pid=28769 o1d_pid=28769
make 28770 [001] T12132.548034: sched:sched_process_exec: f11enane=/usr/bin/nake
pid=28770 old_pid=28770
sh 28771 [004] T12132.550399: sched:sched_process_exec: f11enane=/bin/sh
pid=28771 old_pid=2877]
[..-]
2 In csse aryone is wondering why I don’t use strace(1) for this. The current implementation of strace(1) uses bresk
weoe(dai auo ueu auow esn uogonpoud oj snouauep 1 Bupyew *(xoot jano) salueq au mojs Ageadl ueo eq sgujod
is in development, inclkuding the perf trace subcommand, and another that is BPF bssed. Also, this example traces the
exec( syscall system-wide, which strace(1) currently cannot do.
---
## Page 234
6.2 Traditional Tools
197
The output shows that the processes executed had names including make, sh, and cmake, which
leads me to suspect that a software build is the culprit. Short-lived processes are such a common
issue that there is a dedicated BPF tool for it: execsnoop(8). The fielkds in this output are: process
name, PID, [CPU], timestamp (seconds), event name, and event arguments .
perf(1) has a special subcommand for CPU scheduler analysis called pef sched. It uses a dump-
and-post-process approach for analyzing scheduler behavior and provides various reports that
pue *(fejap) Aouae| 1agnpaqos unuxeu pue aesane aq dnaxem sad atuguns nd aq mouqs ue)
ASCII visualizations to show thread execution per CPU and migrations. Some example output:
+ perf sched record -- sleep 1
[ perf zecoxd: loken up 1 tines to xrlte data 1
[perf record: Captured and vrote 1.886 MB perf.data (13502 sanples) ]
+ perf sched tinehist
Sanples do not have callchains.
t1me
cpu task nane
xait tine
sch delay
run tine
[pd/pT]
(nsec)
(msec)
(nsec)
[. ..]
991963.885740 [0001]
:17008[17008]
25,613
0,000
0.057
991963. 886009 [0001]
leep [16999]
1000.104
0.006
0.269
[5000] Bt0988*E96166
cc1[17083]
19.908
0,000
9.948
[...]
The output is verbose, showing all scheduler context switch events as a line summary with the
milliseconds. This output shows a sleep(1) command that slept for 1 second, and a cc1 process
time sleeping (wait time), scheduler latency (sch delay), and time spent on CPU (runtime), all in
that ran for 9.9 milliseconds and slept for 19.9 milliseconds.
The perf sched subcommand can help solve many types of scheduler issues, incluxing problems
with the kernel scheduler implementation (the kernel scheduler is complex code that balances
many requirements). However, the dump-and-post-process style is costly: This example recorded
schexduler events for 1 second on an eight-CPU system, resulting in a 1.9 Mbyte perf.data file. On a
larger, busier system, and for a longer duration, that file could be hundreds of Mbytes, which can 
become a problem with the CPU time needed to generate the file and the file system I/O to write
it to disk.
To make sense of so many scheduler events, perf(1) output is often visualized. perf(1) also has a
timechart subcommand for its own visualization.
Where possible, I recommend using BPF instead of pexf sched as it can do in-kernel summaries
that answer similar questions and emit the results (for example, the runqlat(8) and runqlen(8)
tools, covered in Sections 6.3.3 and 6.3.4).
---
## Page 235
198
Chapter 6 CPUs
Ftrace
Ftrace is a collection of different tracing capabilities, developed by Steven Rostedt and first adlded
to Linux 2.6.27 (2008). As with perf(1), it can also be used to explore the context of CPU usage via
tracepoints and other events.
As an example, my perf-tools collection [78] mostly uses Ftrace for instrumentation, and includes
funccount(8) for counting functions. This example counts the ext4 file system calls by matching
those that begin with *ext*:
 pezf-tools/bin/funccount *ext*
Tracing *ext*"... Ctrl-C to end.
FUBIC
COUNT
apouaepdnopxa
523
ext4_inode_csun.isra.56
523
asunoapoux9
523
ext4_nark_11oc_dixty
523
ext4_reserve_inode_write
523
ext4_lnode_table
551
osapdnxa
564
ext4_nonda_svitch
586
ext4_bio_vrite_page
604
ext4_jouxnal_check_start
1001
pabxauaquesaxa
1111
ext4_file_getattr
7159
extf_getattr
7285
The output here has been truncated to show only the most frequently used functions. The most
frequent was ext4_getattr0, with 7285 calls while tracing.
Function calls consume CPU, and their names often provide clues as to the workload performed.
In cases where the function name is ambiguous, it is often possible to find the source code to the
function online and read it to understand what it does. This is especially true of Linux kernel
functions, which are open source.
Ftrace has many useful canned capabilities, and recent enhancements have added histograms and
more frequency counts (*hist triggers°). Unlike BPF, it is not fully programmable, so it cannot be
used to fetch data and present it in completely custom ways.
6.3BPF Tools
This section covers the BPF tools you can use for CPU performance analysis and troubleshooting.
They are shown in Figure 6-4 and listed in Table 6-3.
---