e
F
mov ( var1 ) ,
% rax
mov ( var2 ) ,
% rbx
cmp ( secret ) , ’a ’
jnz .else
add $1 , % rax
mov %rax , ( var1 )
add $1 , % rbx
mov %rbx , ( var2 )
ret
0 x3 :
0 x8 :
0 xc :
0 xe :
0 x10 :
0 x14 :
0 x19 :
0 x1d :
0 x22 :
...
.else :
0 x2b :
0 x2f :
0 x34 :
0 x38 :
0 x3d :
(b) Secret-dependent branch in asm
add $2 , % rax
mov %rax , ( var1 )
add $2 , % rbx
mov %rbx , ( var2 )
ret
Int #1
Int #2
Int #3
Int #4
Int #1
Int #2
Int #3
Int #4
Figure 1: A secret-dependent branch in C and x86 assembly.
Both branches in the assembly code ﬁt within the same cache-
line (64B). The virtual address of the instructions is reported
on the left. Note that while the branches are instruction-wise
identical, their instructions get grouped differently by the
fetch window (which always start at multiples of 16B).
its execution time to be independent of which branch is taken
and hence not to have any correlation with the secret input.
However, when the above sequence is run within an SGX
enclave, our attack shows that a local attacker can learn which
branch was taken, and therefore, derive the secret value of the
branch condition. Our attack leverages two main observations.
First, even if the branches have the same instructions, they are
often aligned differently within the fetch windows (Listing 1b)
– in our experiments, this alone did not produce observable
differences in the execution times (cf. Section 4). Second, if
the execution of both branches is frequently interrupted, the
difference in their alignments w.r.t. the fetch windows will
cause the CPU to fetch instructions at different times (Table 1),
resulting in a measurable difference in the execution times of
the instructions and therefore of the branches (cf. Section 4).
To give an insight into why interrupts lead to a successful
attack, we show which instructions are fetched by the CPU
when the execution is interrupted after each instruction. There
are two main factors to consider: which instructions among
those already in the pipeline are retired when an interrupt is re-
ceived, and how execution is resumed after an interrupt. Intel
guarantees that only the oldest pending instruction in the re-
order buffer is retired 2 before the interrupt is handled [29]. In
out-of-order processors, other instructions might have already
2Or discarded, if it raises an exception
Int #1
add
Int #2 mov
Int #3
add
Int #4 mov
If
mov
add
ret
Else
add
add
mov
add
mov
ret
add mov
mov
ret
ret
Table 1: Here we show how instructions are batched
into fetch windows when the enclave resumes execution,
according to which branch is executing. If an instruction
crosses a fetch window boundary, we assume it is decoded
together with the instructions in the following window. The
interrupts refer to the instructions in Figure 1b.
been executed, but none of these will be retired. To resume
execution after the interrupt is handled, the CPU needs to
fetch the instruction sequence starting at the current program
counter. However, while the program counter can, in general,
have any value, fetch windows are statically aligned at 16
bytes code blocks [31]. Assume that the program counter
falls 5 bytes after the start of the fetch window. Those initial 5
bytes will be fetched only to be then discarded by the frontend.
Thus out of 16 bytes fetched, only 11 are usable. Now assume
that the same instruction sequence begins 10 bytes after the
start of the fetch window. Instead of 11 bytes as before, there
are only 6 bytes that can be decoded, meaning we now need
two fetch windows (and hence two cycles) to decode the same
number of instructions as we did before in just one fetch win-
dow. Alignment w.r.t. fetch windows can, therefore, change
the order in which instructions are forwarded to other stages
of the CPU and ultimately populate the pipeline. To help clar-
ify this point, for both branches of our example code, we show
in Table 1 which instructions are fetched after every interrupt.
In principle, given the same system conditions, a partic-
ular instruction should exhibit the same time distribution at
different virtual addresses. However, we experimentally ob-
serve that depending on the alignment within a fetch win-
dow and the number and type of instructions present around
them, some instructions consistently take longer to execute
than others. In Section 4, we provide more details on which
alignments of instructions produce measurable execution time
differences. This observation hence allows us to associate the
measured instruction execution time with the alignment in
the fetch window, and therefore with the instruction virtual
address (i.e., with the instruction pointer). These leaked exe-
cution times and addresses can then be used to infer executed
branches (e.g., when they depend on the secret value). In this
work, we focus on the use of our attack in the context of secret-
dependent branching. In particular, for the scenario given
above in Table 1 when enough mov are fetched after a mov in
the branch, the interrupt latency is measurably different. In
our example, we measured interrupt #2 in the table to be faster
if the code is executing in the “else” branch, as compared to
the “if” branch, despite the fact that we are interrupting the
same instruction under the exact same system conditions.
666    30th USENIX Security Symposium
USENIX Association
Let’s again consider Listing 1b. By running SGX-Step, we
can time all instructions by stepping through them one by one.
As a consequence of the observations made above, we will
observe two scenarios for the 6th instruction measured, which
is the instruction at address 0x14 or 0x2f, depending on the
secret value. If the interrupt is “slower” (compared to the
others measured), we must be executing the mov at address
0x14.
Inversely, if the interrupt is “faster”, we must be
executing the mov at address 0x2f. Since the control ﬂow of
the program depends on the secret, this allows us to recover
its value, and hence break the SGX conﬁdentiality guarantees.
The snippet presented in Figure 1 produces distinguishable
timings for the ﬁrst mov instruction inside the branch. We
were able to use the timing difference to predict the secret
with ≥ 65% accuracy. By adding three more movs after the
branches (which are executed by both paths), we were able
to obtain success rates > 90%. The attack presented above il-
lustrates how fully balanced branches actually produce secret-
dependent timings when interrupted frequently. Given that
this side-channel is due to the design and behavior of the
CPU frontend, we name our attack the Frontal attack. In the
following sections, we will analyze our attack in more detail.
4 Frontal Attack Proﬁling
In this section, we provide more detail and clariﬁcation to
that help in understanding under which circumstances the
Frontal attack works. More speciﬁcally, we ask and answer
the following questions: (i) are the interrupts required for the
attack to be successful? (ii) what are the effects of the fetch
window alignment / instruction address on the attack? and (iii)
which instructions produce observable timing differences?
To answer these questions we perform experiments over the
code snippet shown in Figure 2. Similar to code in Figure 1,
this code snippet contains two perfectly symmetric branches
depending on a secret. It still consists of two perfectly bal-
anced branches but differs in that now each branch contains 25
sequences of add-mov instructions. We chose this longer code
sequence since it produces timing differences that are more
clearly above the noise ﬂoor than the code in Figure 1 and
therefore better illustrates timing and alignment effects under
different experiment conﬁgurations. Namely, code sequences
that include several mov instructions like the one in Figure 2
are particularly susceptible to the Frontal attack and allow us
to extract the secret branch condition with an accuracy of at
least 99%, whereas with shorter sequences that contain few
movs (like the one in Figure 1), this accuracy drops to ≥ 65%.
We discuss this effect in more detail later in this section.
4.1 The Role of Interrupts
To analyze the effect of frequent interrupts on the behavior
of the processor we measure the execution time of our test
code snippet (Figure 2) with and without interrupts.
.align (x - 0 x4 )
x - 0 x4 :
x - 0 x2 :
cmp ( secret ) , 1
jnz .else
.if :
.rept 25
x + 0 x0 :
x + 0 x3 :
add %rax , % rbx
mov %rcx , ( var1 )
.endr
x + 0 x190 :
...
ret
.align y
.else :
.rept 25
y + 0 x0 :
y + 0 x3 :
add %rax , % rbx
mov %rcx , ( var1 )
.endr
y + 0 x190 :
ret
Figure 2: ASM Code with high attack success probability,
which we use to proﬁle the attack. The .rept 25 ...
.endr assembler directive repeats the instructions within the
block 25 times, leading to an address of x+0x190 for the ret
instruction.
Outside SGX without interrupts We ﬁrst measured the
overall execution time of the code snippet outside SGX
without interrupts. We executed the code with two billion
independent random inputs, and we observed no signiﬁcant
correlation between execution times and the branch that was
executed (Pearson’s coefﬁcient = −2.51· 10−5). An approx-
imate distribution of this measurement is shown in Figure 3.
In SGX without interrupts
In order to exclude any effect
due to SGX, we further measure the overall execution time
of the code within an SGX enclave, again without interrupts.
Note that SGX does not provide any way to get a precise
timer (cf. Section 2), so we have to measure the execution
time from the untrusted app.
We perform this measurement using three different
methods. All methods use the same code snippet in a loop,
but they differ in how the measurement is collected and where
the loop is executed. We do this to ﬁlter out any effects of the
enclave entry and exit operations. First, we measure a whole
enclave call from the untrusted app. Multiple measurements
are collected by having a loop in the untrusted app. Second,
we run the loop entirely inside the enclave and collect the
iteration execution time with two ocalls to the untrusted app.
The two ocalls are done at the beginning and the end of each
loop iteration. Third, we use a similar setup as the second
method, but instead of performing ocalls, the enclave sam-
ples the value of a counter stored in shared memory. A thread
of the untrusted app increments the counter in a loop, thus
simulating the time stamp counter, albeit at a lower precision.
All three methods use an independent uniform random value
as the “secret” given to the code at each iteration.
For all three methods, similar to the experiment outside
of SGX, we observed no signiﬁcant correlation (Pearson’s
USENIX Association
30th USENIX Security Symposium    667
identical: the instructions they contain and their inputs are the
same. This is especially important because it highlights the
fact that the timing difference is due to the way the instruc-
tions are executed, and not some external system state. For
instance, the difference cannot be due to the state of the cache,
the state of the branch predictor, or in general to some spec-
ulation decisions made by the CPU. If the cause of the differ-
ences were to be due to any of these factors, we would expect
two key differences. First, as we choose secrets at random,
these effects would manifest with equal probability in any of
the two branches. Second, we would expect the experiments
in which we do not interrupt the code to also show some bias.
However, we see a clear bias in one of the two branches, and
the interrupt-free runs showed no correlation with the secret.
Observation 1: When code execution is frequently
interrupted, the execution times of selected instruc-
tions depend on their location in the victim binary
and therefore on their virtual memory address.
4.2 Relationship to Virtual Addresses
While the instructions in both branches are identical, there
is one key difference between them: their virtual address.
Therefore, we analyze what virtual addresses make the two
branches distinguishable when frequently interrupted, and
to what degree. In particular, as discussed in Section 3, we
also study how the relationship between the alignment of the
branches with respect to the fetch window affects the success
of the attack. As can be seen in Figure 2, we use the align
compiler directive to explicitly align each branch to a given
address. With .align X we indicate that the code following
the directive starts at the next virtual address whose lower
bits are equal to X.5 For example, if X = 3 and Y = 2, then
the if branch will start at address 0x13 and end at address
0x1a3, while the else branch will start at address 0x1b2.
To evaluate different alignments, we run an experiment to
test if different values of X and Y in Figure 2 have any effect on
the observed timing differences. We repeat the interrupt exper-
iment described at the end of Section 4.1. That is, we send an
interrupt to each instruction and then use the interrupt timing
of one of the instructions in the branch as a discriminator to
determine which branch was taken, and thus what the secret
was. We then calculate the attack success as the percentage of
correctly identiﬁed secret bits. Therefore, the attack success
rate will tell us how good a certain combination of the align-
ments X and Y are for the attack. The higher the percentage
the better an alignment combination is for the attack, while a
result close to 50% indicates that predicting which branch was
taken is as good as a random guess. We collect these percent-
ages for each combination of {X,Y} ∈ [0,31]2 by running the
5This is equivalent to combining the two gcc asm directives .align
(X//2n) and .space (X%2n) (for the biggest n such that 2n < X)
Figure 3: Distribution of the overall execution time of the
branches in Figure 2 when run outside of SGX without
interrupts (computed from 2∗ 109 samples).
coefﬁcient ≈ 10−2 with 106 runs) between the execution
time and the secret provided to the enclave.
In SGX with interrupts We now investigate which effects
frequent interrupts have on the execution time of the code.
We execute the same code snippet as before but we interrupt it
after each instruction. Upon each interrupt the CPU performs
an asynchronous enclave exit (AEX), handles the interrupt,
and then performs an ERESUME to resume the enclave
execution. Such an experiment would normally require very
fast and extremely precise interrupts, which is usually hard to
achieve. However, in the case of a victim code running within
SGX, we can use SGX-Step [29] to single step through each
instruction and collect its execution time. Given these inter-
rupts, we can not only measure the overall execution time,
but also the execution time of each instruction. This means
that in each run of our code, we obtain 51 measurements.3
We then analyzed whether any of the 51 measured
instruction execution times correlate with the executed