number of other common applications. The Linux
protocol stack and the Bro intrusion detection sys-
tem simply XOR their input together, 32 bits at a
time. Thus, collisions may be directly computed
from the algebraic structure of the hash function.
2.2 Application limits on hash tables
Many applications are sensitive about their over-
all memory usage, and thus have limits designed
to control how large their hash tables might grow.
If a hash table can never have enough elements in it
for the worst-case O(n2) behavior to dominate, then
our attack will fail.
2.2.1 Explicit limits
Some applications have explicit limits on their hash
tables. We ﬁrst consider the Linux IP fragment re-
assembly code. In response to earlier attacks, Linux
currently allows at most 256 kbytes of storage to-
ward reassembling incomplete packets. If we wish
to attack the hash table being used to store these
packet fragments, the longest hash chain we can in-
duce will still be under 256 kbytes in total. We can
still force Linux to repeatedly scan this chain, in-
creasing the CPU load on the kernel, but we are
unsure whether we can cause enough slowdown to
be interesting.
(Florian Weimer reports that he found an ex-
ploitable hashing vulnerability in the Linux route
cache, allowing 400 packets per second from an at-
tacker to overload a quad-processor Pentium Xeon
server, despite the size limits present in the route
cache’s hash table [20].)
The Apache web server collects ﬁelds from HTTP
request headers into a vector (auto-sizing array). If
there are multiple header ﬁelds with the same type,
Apache concatenates them with an O(n2) opera-
tion. This was a target for attack [19], however
Apache now imposes a limit on the number of ﬁelds
that can appear in an HTTP request (100 ﬁelds, by
default). Even with 100 entries naming the same
ﬁeld, a O(n2) worst-case running time will still be
small, because n is too small for the quadratic per-
formance to become noticeable.
2.2.2
Implicit limits
There are many other places where there are lim-
its on the attacker’s ability to inﬂuence a hash ta-
ble. For instance, as discussed in Section 2.1.1, the
freedom of an attacker to construct arbitrary inputs
may be limited. In the case of network packets in-
tended to attack a network sniffer, the attacker is
limited both by the packet ﬁelds being watched by
the sniffer, and by the packet headers necessary to
route the packet toward the targeted machine. More
generally, many applications operate on restricted
data types, or otherwise place limits on an attacker’s
ability to generate arbitrary input for the targeted
hash table.
In some sense, these applications are
lucky, but they could be vulnerable to attack in the
future if their environment changes (e.g., moving
from IPv4 to IPv6 will increase the size of IP ad-
dresses, giving more freedom to attack tables that
hash IP addresses).
USENIX Association
12th USENIX Security Symposium 
33
3 Application analysis: Squid, DJBDNS,
would be vulnerable to attack.
and Perl
We did a short analysis of three programs to ana-
lyze how vulnerable they are to attack. We analyzed
and attacked the hash tables used by two versions
of the the Perl interpreter. We also analyzed and at-
tacked the Squid web proxy cache. We investigated
the DJB DNS cache and found it less vulnerable to
these attacks.
3.1 Squid
The Squid Internet object cache [14] is intended to
reduce network bandwidth by caching frequently
used objects [7]. We analyzed the hash tables used
within version 2.5STABLE1.
While we have not performed an exhaustive audit
of Squid, we did discover a hash table used to track
objects cached in memory. The hash table is keyed
with an integer counter, the HTTP request method
(i.e., GET, HEAD, etc.), and the URL in question.
When Squid is operating as part of a caching clus-
ter, it omits the integer counter and only hashes the
HTTP request method and URL. (For reasons that
escape us, Squid calls this “private key” vs. “pub-
lic key” mode; this seems to have nothing to do
with the traditional cryptographic senses of those
terms.) An MD5 cryptographic checksum is per-
formed over these values, and the resulting 128-bit
value is truncated to 13 bits, identifying the hash
bucket.
As an attacker, we cannot necessarily predict the
value of the counter, making it difﬁcult to compute
hash collisions. However, Squid can be tricked into
believing that it is part of a cluster by sending it
a single UDP packet, an Internet Caching Proto-
col (ICP) MISS NO FETCH message [21]. This
packet is accepted by the default conﬁguration, and
it’s unclear whether this packet could be easily ﬁl-
tered, even using Squid’s access control features.
Regardless, any Squid cluster would already be for-
going the use of the “private key” mode, and thus
A full benchmarking environment for Squid would
require multiple web servers and clients to simulate
the load experienced by the Squid web cache. To
simplify things, we ran Squid on a stand-alone ma-
chine, where the URL requests were parsed from a
local ﬁle and were satisﬁed with constant-sized web
page results, served by a local proxy server. This
environment is undeniably not suitable for mak-
ing general remarks about Squid’s general-purpose
throughput, but it allows us to place pressure on this
particular hash table and observe the effects.
We measured the wall-clock time necessary for
Squid, in our restrictive conﬁguration, to load ap-
proximately 143k URLs. We compared the per-
formance of loading randomly chosen URLs with
URLs carefully chosen to collide with Squid’s hash
function. Squid took 14.57 minutes to process the
attack URLs versus 10.55 minutes to process the
randomly chosen URLs. Thus, our attack added,
on average, approximately 1.7ms of latency to each
request serviced by the Squid cache.
This attack does not represent a “smoking gun” for
algorithmic complexity attacks, but it does illus-
trate how common network services may be sen-
sitive to these attacks. Furthermore, this attack
demonstrates how seemingly innocuous features
(e.g., Squid’s “private key” mechanism, whatever
it actually does) may have an effect on an applica-
tion’s resistance to these attacks.
3.2 DJBDNS
Dan Bernstein’s DNS server is designed to have
several independent programs serving different du-
ties. His DNS cache is one program in this collec-
tion. If we can pollute the cache with requests for
domains under our control (e.g., “x1.attacker.org”,
“x2.attacker.org”, etc.), we may be able to mount
an algorithmic complexity attack against the DNS
cache’s hash table.
Upon code inspection, DJBDNS uses a determin-
34
12th USENIX Security Symposium 
USENIX Association
istic hash function in its implementation of a DNS
cache. Interestingly, the lookup code has an explicit
check for being subject to “hash ﬂooding;” after
following a chain for 100 entries, it gives up and
treats the request as a cache miss. We presume this
design is intended to prevent the DNS cache from
burning an excessive amount of CPU on any given
request. Bernstein essentially anticipated a version
of our attack, although, as we discuss in Section 5,
his ﬁx could be improved.
3.3 Perl
Perl is a widely-used programming language with
built-in support for hash tables (called “associative
arrays”). While attacking a large number of Perl
scripts is behind the scope of this paper, we expect
that many deployed Perl scripts take untrusted in-
put and store it directly in associative arrays. We
demonstrate attacks against the associative arrays
in Perl, versions 5.6.1 and 5.8.0; the hash function
was changed between these two versions.
The hash functions in both versions of Perl form
state machines. The internal state is the 32 bit ac-
cumulated hash value. The input being hashed is
mixed in, one byte at a time, using a combination of
addition, multiplication, and shift operations. The
structure of the hash functions in both Perl 5.6.1
and 5.8.0 allow us to efﬁciently compute generators
(see Section 2.1.2). Spending around one CPU hour
attacking both hash functions, we were able to ﬁnd
46 generators for Perl 5.6.1 and 48 generators for
Perl 5.8.0, yielding 97k-110k colliding inputs of 24
characters in length. We then loaded these strings
directly into associative arrays in both interpreters.
The results are presented in Table 1. When an in-
terpreter is fed the input designed to collide with its
hash function, the running time was three orders of
magnitude worse (2 seconds vs. almost two hours)
than when fed the data designed to attack the other
Perl version. This represents how devastating an al-
gorithmic complexity attack can be. One hour of
pre-computed CPU work, on the client, can cause
almost two hours of online work for a server. Dou-
bling the number of inputs by either ﬁnding new
File version
Perl 5.6.1
Perl 5.8.0
Perl 5.6.1
program
6506 seconds
<2 seconds
Perl 5.8.0
program
<2 seconds
6838 seconds
Table 1: CPU time inserting 90k short attack strings
into two versions of Perl.
generators or using longer inputs would quadruple
the victim’s work. The exponent in the victim’s
O(n2) worst-case behavior is clearly dominant.
4 Application analysis: Bro
Bro [15] is a general-purpose network intrusion de-
tection system (IDS) that can be conﬁgured to scan
for a wide variety of possible attacks. Bro is open-
source and is used in production at a number of
commercial and academic sites. This makes it an
attractive target, particularly because we can di-
rectly study its source code. Also, given that Bro’s
job is to scan and record network packets, correlat-
ing events in real time to detect attacks, we imag-
ine it has numerous large hash tables with which it
tracks these events. If we could peg Bro’s CPU us-
age, we potentially knock the IDS off the air, clear-
ing the way for other attacks to go undetected.
In order to keep up with trafﬁc, Bro uses packet ﬁl-
ters [13] to select and capture desired packets, as
a function of its conﬁguration. Following this, Bro
implements an event-based architecture. New pack-
ets raise events to be processed. Synthetic events
can also be timed to occur in the future, for exam-
ple, to track the various time-outs that occur in the
TCP/IP protocol. A number of Bro modules ex-
ist to process speciﬁc protocols, such as FTP, DNS,
SMTP, Finger, HTTP, and NTP.
4.1 Analysis
Bro contains approximately 67,000 lines of C++
code that implement low-level mechanisms to ob-
USENIX Association
12th USENIX Security Symposium 
35
serve network trafﬁc and generate events. Bro also
provides a wide selection of scripts, comprising ap-
proximately 9000 lines of code in its own inter-
preted language that use the low-level mechanisms
to observe network behavior and react appropri-
ately. While we have not exhaustively studied the
source code to Bro, we did observe that Bro uses
a simple hash table whose hash function simply
XORs together its inputs. This makes collisions ex-
ceptionally straightforward to derive. The remain-
ing issue for an attack any is to determine how and
when incoming network packets are manipulated
before hash table entries are generated.
We decided to focus our efforts on Bro’s port
scanning detector, primarily due to its simplicity.
For each source IP address, Bro needs to track
how many distinct destination ports have been con-
tacted. It uses a hash table to track, for each tuple
of (cid:3)source IP address, destination port(cid:4), whether
any internal machine has been probed on a given
port from that particular source address. To attack
this hash table, we observe that the attacker has 48-
bits of freedom: a 32-bit source IP address and a
16-bit destination port number. (We’re now assum-
ing the attacker has the freedom to forge arbitrary
source IP addresses.)
If our goal is to compute
32-bit hash collisions (i.e., before the modulo op-
eration to determine the hash bucket), then for any
good hash function, we would expect there to be
approximately 216 possible collisions we might be
able to ﬁnd for any given 32-bit hash value. In a hy-
pothetical IPv6 implementation of Bro, there would
be signiﬁcantly more possible collisions, given the
larger space of source IP addresses.
Deriving these collisions with Bro’s XOR-based
hash function requires understanding the precise
way that Bro implements its hash function. In this
case, the hash function is the source IP address,
in network byte order, XORed with the destination
port number, in host order. This means that on a
little-endian computer, such as an x86 architecture
CPU, the high-order 16 bits of the hash value are
taken straight from the last two octets of the IP ad-
dress, while the low-order 16 bits of the hash value
result from the ﬁrst two octets of the IP address and
the port number. Hash collisions can be derived
by ﬂipping bits in the ﬁrst two octets of the IP ad-
dress in concert with the matching bits of the port
number. This allows us, for every 32-bit target hash
value, to derive precisely 216 input packets that will
hash to the same value.
We could also have attempted to derive bucket colli-
sions directly, which would allow us to derive more
than 216 collisions in a single hash bucket. While
we could guess the bucket count, or even gener-
ate parallel streams designed to collide in a num-
ber of different bucket counts as discussed in Sec-
tion 2.1.1, this would require sending a signiﬁcant
amount of additional trafﬁc to the Bro server. If the
216 hash collisions are sufﬁcient to cause an notica-
ble quadratic explosion inside Bro, then this would
be the preferable attack.
4.2 Attack implementation
We have designed attack trafﬁc that can make Bro
saturate the CPU and begin to drop trafﬁc within
30 seconds during a 160kb/s, 500 packets/second
ﬂood, and within 7 minutes with a 16kb/s ﬂood.
Our experiments were run over an idle Ethernet,
with a laptop computer transmitting the packets to
a Bro server, version 0.8a20, running on a dual-
CPU Pentium-2 machine, running at 450MHz, with
768MB of RAM, and running the Linux 2.4.18 ker-
nel. Bro only uses a single thread, allowing other
processes to use the second CPU. For our experi-
ments, we conﬁgured Bro exclusively to track port
scanning activity. In a production Bro server, where
it might be tracking many different forms of net-
work misbehavior, the memory and CPU consump-
tion would be strictly higher than we observed in
our experiments.
4.3 Attack results
We ﬁrst present the performance of Bro, operating
in an off-line mode, consuming packets only as fast
as it can process them. We then present the latency
and drop-rate of Bro, operating online, digesting
36
12th USENIX Security Symposium 
USENIX Association
Total CPU time
Hash table time
Attack Random
.86 min
.02 min
44.50 min
43.78 min
Table 2: Total CPU time and CPU time spent in
hash table code during an ofﬂine processing run of
64k attack and 64k random SYN packets.
packets at a variety of different bandwidths.
4.3.1 Ofﬂine CPU consumption
Normally, on this hardware, Bro can digest about
1200 SYN packets per second. We note that this
is only 400kb/s, so Bro would already be vulnera-
ble to a simple ﬂood of arbitrary SYN packets. We
also note that Bro appears to use about 500 bytes of
memory per packet when subject to random SYN
packets. At a rate of 400kb/s, our Bro system, even
if it had 4GB of RAM, would run out of memory
within two hours.
We have measured the ofﬂine running time for Bro
to consume 64k randomly chosen SYN packets.
We then measured the time for Bro to consume
the same 64k randomly chosen packets, to warm
up the hash table, followed by 64k attack packets.
This minimizes rehashing activity during the attack
packets and more closely simulates the load that
Bro might observe had it been running for a long
time and experienced a sudden burst of attack pack-
ets. The CPU times given in Table 2 present the re-
sults of benchmarking Bro under this attack. The
results show that the attack packets introduce two
orders of magnitude of overhead to Bro, overall,
and three orders of magnitude of overhead specif-
ically in Bro’s hash table code. Under this attack,
Bro can only process 24 packets per second instead
of its normal rate of 1200 packets per second.
In the event that Bro was used to process an ex-
tended amount of data, perhaps captured for later
ofﬂine analysis, then an hour of very low bandwidth
attack trafﬁc (16kb/s, 144k packets, 5.8Mbytes of
Packet rate
16kb/s
16kb/s
64kb/s
160kb/s
(clever)
Packets sent Drop rate
31%
71%
75%
78%
192k
128k
320k
320k
Table 3: Overall drop rates for the different attack