tional Conference on Web and Social Media (ICWSM), 2020.
[3] F. Benevenuto, G. Magno, T. Rodrigues, and V. Almeida.
In Collaboration, electronic
Detecting spammers on twitter.
messaging, anti-abuse and spam conference (CEAS), 2010.
[4] A. Bessi and E. Ferrara. Social bots distort the 2016 US
Presidential election online discussion. First Monday, 21(11),
2016.
[5] V. D. Blondel, J.-L. Guillaume, R. Lambiotte, and E. Lefeb-
vre.
Fast unfolding of communities in large networks.
Journal of Statistical Mechanics: Theory and Experiment,
2008(10):P10008, Oct 2008.
[6] L. Breiman. Random forests. Machine Learning, 45(1), 2001.
[7] Z. Cai and C. Jermaine. The latent community model for
In ISOC Network
detecting sybil attacks in social networks.
and Distributed Systems Security Symposium (NDSS), 2012.
[8] Q. Cao, X. Yang, J. Yu, and C. Palow. Uncovering large groups
of active malicious accounts in online social networks. 2014.
[9] G. Danezis and P. Mittal. Sybilinfer: Detecting sybil nodes using
In ISOC Network and Distributed Systems
social networks.
Security Symposium (NDSS), 2009.
[10] C. A. Davis, O. Varol, E. Ferrara, A. Flammini, and F. Menczer.
In The Web
BotOrNot: A System to Evaluate Social Bots.
Conference (WWW), 2016.
[11] Z. Deng, X. Zhu, D. Cheng, M. Zong, and S. Zhang. Efﬁcient
kNN classiﬁcation algorithm for big data. Neurocomputing, 195,
2016.
[12] R. Dutt, A. Deb, and E. Ferrara.
’Senator, We Sell Ads’:
the 2016 Russian Facebook Ads Campaign.
Analysis of
arXiv:1809.10158, 2018.
[13] M. Egele, G. Stringhini, C. Kruegel, and G. Vigna. Towards de-
tecting compromised accounts on social networks. Transactions
on Dependable and Secure Computing (TDSC), 2015.
[14] E. Ferrara. Disinformation and social bot operations in the run
up to the 2017 French presidential election. ArXiv 1707.00086,
2017.
[15] E. Ferrara, O. Varol, C. Davis, F. Menczer, and A. Flammini.
The rise of social bots. Communications of the ACM, 2016.
[16] P. Gal´an-Garc´ıa, J. G. d. l. Puerta, C. L. G´omez, I. Santos, and
P. G. Bringas. Supervised machine learning for the detection
of troll proﬁles in twitter social network: Application to a real
case of cyberbullying. Logic Journal of the IGPL, 24(1):42–53,
2016.
[17] H. Gao, J. Hu, C. Wilson, Z. Li, Y. Chen, and B. Y. Zhao.
Detecting and characterizing social spam campaigns. In ACM
Internet Measurement Conference (IMC), 2010.
[18] Gensim. Word2vec embeddings.
https://radimrehurek.com/
gensim/models/word2vec.html.
[19] S. Ghosh, B. Viswanath, F. Kooti, N. K. Sharma, G. Korlam,
F. Benevenuto, N. Ganguly, and K. P. Gummadi. Understanding
and combating link farming in the twitter social network. In The
Web Conference (WWW), 2012.
[20] C. Grier, K. Thomas, V. Paxson, and M. Zhang. @spam: The
Underground on 140 Characters or Less. In ACM Conference
on Computer and Communications Security (CCS), 2010.
[21] M. A. Hearst, S. T. Dumais, E. Osuna,
B. Scholkopf.
Systems and their Applications, 13(4):18–28, 1998.
Support vector machines.
J. Platt, and
IEEE Intelligent
[22] S. Hegelich and D. Janetzko. Are Social Bots on Twitter
Political Actors? Empirical Evidence from a Ukrainian Social
Botnet. In AAAI International Conference on Web and Social
Media (ICWSM), 2016.
[23] J. W. Henry Weller.
with Deep Learning and BERT Word Embeddings.
//web.stanford.edu/class/cs224n/posters/15739845.pdf, 2019.
Identifying Russian Trolls on Reddit
https:
[24] P. N. Howard and B. Kollanyi. Bots, #StrongerIn, and #Brexit:
Computational Propaganda during the UK-EU Referendum.
CoRR, abs/1606.06356, 2016.
[25] M. Jacomy, T. Venturini, S. Heymann, and M. Bastian. Forceat-
las2, a continuous graph layout algorithm for handy network
visualization designed for the gephi software. PLOS ONE,
9(6):1–12, 06 2014.
[26] V. Kulkarni, R. Al-Rfou, B. Perozzi, and S. Skiena. Statistically
signiﬁcant detection of linguistic change, 2014.
[27] S. Kumar, J. Cheng, J. Leskovec, and V. Subrahmanian. An
army of me: Sockpuppets in online discussion communities. In
The Web Conference (WWW), 2017.
[28] H. Kwak, C. Lee, H. Park, and S. Moon. What is twitter,
a social network or a news media? In The Web Conference
(WWW), 2010.
[29] M.
J.
Lavin.
IDF.
analyzing-documents-with-tﬁdf, 2019.
Analyzing Documents with
TF-
https://programminghistorian.org/en/lessons/
[30] S. Lee and J. Kim. Warningbird: Detecting suspicious urls
In ISOC Network and Distributed Systems
in twitter stream.
Security Symposium (NDSS), 2012.
[31] K. Lerman and R. Ghosh. Information contagion: An empirical
study of the spread of news on digg and twitter social networks.
In AAAI International Conference on Web and Social Media
(ICWSM), 2010.
[32] L. Liu, Y. Lu, Y. Luo, R. Zhang, L. Itti, and J. Lu. Detecting”
smart” spammers on social network: A topic model approach.
arXiv:1604.08504, 2016.
[33] L. Luceri, S. Giordano, and E. Ferrara. Detecting troll behavior
via inverse reinforcement learning: A case study of russian trolls
in the 2016 us election. In AAAI International Conference on
Web and Social Media (ICWSM), 2020.
[34] G. Mezzour and K. M. Carley. Spam diffusion in a social
International
network initiated by hacked e–mail accounts.
Journal of Security and Networks, 9(3):144–153, 2014.
[35] T. Mihaylov, G. Georgiev, and P. Nakov. Finding Opinion
Manipulation Trolls in News Community Forums. In CoNLL,
2015.
[36] T. Mihaylov and P. Nakov. Hunting for Troll Comments in
News Community Forums. In ACL, 2016.
[37] R. S. Mueller. The mueller report: Report on the investigation
into russian interference in the 2016 presidential election. https:
//www.justice.gov/archives/sco/ﬁle/1373816/download, 2019.
[38] National Intelligence Council. Foreign threats to the 2020 us
federal elections. https://www.dni.gov/ﬁles/ODNI/documents/
assessments/ICA-declass-16MAR21.pdf, 2021.
[39] A. Nematzadeh, E. Ferrara, A. Flammini, and Y.-Y. Ahn.
Optimal network modularity for information diffusion. Physical
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:00:10 UTC from IEEE Xplore.  Restrictions apply. 
2174
review letters, 2014.
[40] S. Nilizadeh, F. Labr`eche, A. Sedighian, A. Zand, J. Fernandez,
C. Kruegel, G. Stringhini, and G. Vigna. POISED: Spotting
In ACM Conference on
Twitter Spam Off the Beaten Paths.
Computer and Communications Security (CCS), 2017.
[41] PRAW.
The Python Reddit API Wrapper.
https://praw.
readthedocs.io/en/latest/.
[42] J. Ratkiewicz, M. Conover, M. R. Meiss, B. Gonc¸alves,
A. Flammini, and F. Menczer. Detecting and Tracking Political
Abuse in Social Media. In AAAI International Conference on
Web and Social Media (ICWSM), 2011.
[43] Reddit. Reddit’s 2017 transparency report and suspect account
ﬁndings.
https://www.reddit.com/r/announcements/comments/
8bb85p/reddits 2017 transparency report and suspect/, 2017.
[44] M. H. Saeed, S. Ali, J. Blackburn, E. D. Cristofaro, S. Zan-
nettou, and G. Stringhini. TROLLMAGNIFIER: Detecting
State-Sponsored Troll Accounts on Reddit.
arXiv preprint
2112.00443, 2021.
[45] M. Samory and T. Mitra. Conspiracies online: User discussions
in a conspiracy community following dramatic events. In AAAI
International Conference on Web and Social Media (ICWSM),
2018.
[46] K. Starbird. Examining the alternative media ecosystem through
the production of alternative narratives of mass shooting events
on twitter. In AAAI International Conference on Web and Social
Media (ICWSM), 2017.
[47] K. Starbird, A. Arif, and T. Wilson. Disinformation as col-
laborative work: Surfacing the participatory nature of strategic
information operations. Proceedings of the ACM on Human-
Computer Interaction, 2019.
[48] L. Steward, A. Arif, and K. Starbird. Examining Trolls and
Polarization with a Retweet Network. In MIS2, 2018.
[49] G. Stringhini, C. Kruegel, and G. Vigna. Detecting spammers
on social networks. In Annual Computer Security Applications
Conference (ACSAC), 2010.
and G. Vigna. {EVILCOHORT}: Detecting communities of
[50] G. Stringhini, P. Mourlanne, G. Jacob, M. Egele, C. Kruegel,
malicious accounts on online services.
Symposium, 2015.
In USENIX Security
B. Y. Zhao. You are how you click: Clickstream analysis for
sybil detection. In USENIX Security Symposium, 2013.
[61] Y. Wang, F. Tamahsbi, J. Blackburn, B. Bradlyn, E. De Cristo-
faro, D. Magerman, S. Zannettou, and G. Stringhini. Under-
In AAAI
standing the use of fauxtography on social media.
International Conference on Web and Social Media (ICWSM),
2021.
[62] L. Weng, F. Menczer, and Y.-Y. Ahn. Virality prediction and
community structure in social networks. Scientiﬁc reports, 3,
2013.
[63] T. Weninger. An exploration of submissions and discussions
in social news: Mining collective intelligence of reddit. Social
Network Analysis and Mining, 2014.
[64] T. Weninger, X. A. Zhu, and J. Han. An exploration of
discussion threads in social news sites: A case study of the
reddit community. In ASONAM, 2013.
[65] Y. Xia, J. Lukito, Y. Zhang, C. Wells, S. J. Kim, and C. Tong.
Disinformation, performed: Self-presentation of a russian ira
Information, Communication and Society,
account on twitter.
2019.
[66] T. Xu, G. Goossen, H. K. Cevahir, S. Khodeir, Y. Jin, F. Li,
S. Shan, S. Patel, D. Freeman, and P. Pearce. Deep entity clas-
siﬁcation: Abusive account detection for online social networks.
In USENIX Security Symposium, 2021.
[67] W. Xu, F. Zhang, and S. Zhu. Toward worm detection in online
In Annual Computer Security Applications
social networks.
Conference (ACSAC), 2010.
[68] C. Yang, R. C. Harkreader, and G. Gu. Die free or live hard?
empirical evaluation and new design for ﬁghting evolving twitter
spammers. In International Workshop on Recent Advances in
Intrusion Detection, 2011.
[69] S. Yardi, D. Romero, G. Schoenebeck, and d. boyd. Detecting
spam in a twitter network. First Monday, 2009.
[70] S. Ye and S. F. Wu. Measuring message propagation and social
inﬂuence on Twitter. Springer, 2010.
[71] D. Yuan, Y. Miao, N. Z. Gong, Z. Yang, Q. Li, D. Song,
Q. Wang, and X. Liang. Detecting fake accounts in online social
networks at the time of registrations. In ACM Conference on
Computer and Communications Security (CCS), 2019.
[72] S. Zannettou, B. Bradlyn, E. De Cristofaro, G. Stringhini,
and J. Blackburn. Characterizing the use of images by state-
In AAAI International
sponsored troll accounts on twitter.
Conference on Web and Social Media (ICWSM), 2019.
[73] S. Zannettou, T. Caulﬁeld, E. De Cristofaro, N. Kourtellis,
I. Leontiadis, M. Sirivianos, G. Stringhini, and J. Blackburn.
The Web Centipede: Understanding How Web Communities
Inﬂuence Each Other Through the Lens of Mainstream and
In ACM Internet Measurement
Alternative News Sources.
Conference (IMC), 2017.
[74] S. Zannettou, T. Caulﬁeld, E. De Cristofaro, M. Sirivianos,
G. Stringhini, and J. Blackburn. Disinformation warfare: Un-
derstanding state-sponsored trolls on twitter and their inﬂuence
on the web. In WWW Companion, 2019.
[75] S. Zannettou, T. Caulﬁeld, W. Setzer, M. Sirivianos, G. Stringh-
the trolls out?: Towards
In ACM Conference on
ini, and J. Blackburn. Who let
understanding state-sponsored trolls.
Web Science, 2019.
[76] S. Zannettou, J. Finkelstein, B. Bradlyn, and J. Blackburn. A
Quantitative Approach to Understanding Online Antisemitism.
In AAAI International Conference on Web and Social Media
(ICWSM), 2020.
[77] Y. Zhang, J. Lukito, M.-H. Su, J. Suk, Y. Xia, S. J. Kim,
L. Doroshenko, and C. Wells. Assembling the networks and
audiences of disinformation: How successful russian ira twitter
accounts built their followings, 2015–2017. Journal of Commu-
nication, 01 2021.
[51] P. H. Swain and H. Hauska. The decision tree classiﬁer: Design
IEEE Transactions on Geoscience Electronics,
and potential.
15(3), 1977.
[52] K. Thomas, C. Grier, J. Ma, V. Paxson, and D. Song. Design
and evaluation of a real-time url spam ﬁltering service. In IEEE
Symposium on Security and Privacy, 2011.
[53] Twitter.
Information Operations. https://transparency.twitter.
com/en/reports/information-operations.html, 2019.
[54] O. Varol, E. Ferrara, C. A. Davis, F. Menczer, and A. Flammini.
Online Human-Bot Interactions: Detection, Estimation, and
In AAAI International Conference on Web
Characterization.
and Social Media (ICWSM), 2017.
[55] O. Varol, E. Ferrara, F. Menczer, and A. Flammini. Early
detection of promoted campaigns on social media. EPJ Data
Science, 2017.
[56] B. Viswanath, M. A. Bashir, M. Crovella, S. Guha, K. P. Gum-
madi, B. Krishnamurthy, and A. Mislove. Towards detecting
anomalous user behavior in online social networks. In USENIX
Security Symposium, 2014.
[57] D. Volcheck.
One Professional Russian Troll Tells All.
https://www.rferl.org/a/how-to-guide-russian-trolling-trolls/
26919999.html, 2015.
[58] S. Volkova and E. Bell. Account Deletion Prediction on RuNet:
A Case Study of Suspicious Twitter Accounts Active During the
Russian-Ukrainian Crisis. In NAACL-HLT, 2016.
[59] S. Vosoughi, D. Roy, and S. Aral. The spread of true and false
news online. Science, 359(6380):1146–1151, 2018.
[60] G. Wang, T. Konolige, C. Wilson, X. Wang, H. Zheng, and
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:00:10 UTC from IEEE Xplore.  Restrictions apply. 
2175