Compression rate: Obfuscated strings may be confused with com-
pressed data, such as images compressed using JPEG and stored
in strings. To identify those strings, we compressed them and
1We were not able to obfuscate every app with every obfuscator due to version
incompatibilities between obfuscators and APKs to be obfuscated.
Pre-processAndroid APKs.apk.jarenjarifyslicingcriteriasliced codeslicingde-obfuscated stringsexecutioninitial analysismethods with obfuscated stringsfind string usagescompared the resulting length against the original length; the re-
sulting length changes if the original content is not already com-
pressed [43].
Cryptographic libraries: Cryptographic libraries use byte-encoded
strings to initialize their algorithms, and this may cause false posi-
tives because they are similar to obfuscated strings. To avoid match-
ing such encoded strings, we check if a string usage is contained in
a known cryptographic library.
Dictionary words: The study in Section 2 revealed that obfuscated
strings contain only a few words or none at all. We use a dictionary
to check whether a string contains words or identifiers [19]. To
match words from foreign languages (e.g., Chinese) that do not use
separators such as white spaces, we apply Lucene’s ICUTokenizer
word splitting approaches. Furthermore, to match strings consisting
Table 2: Feature List for the Detection of Obfuscated Strings
Category
Format
Statistical Tests
AndroDet[38]
Compression Rate
Cryptography Library
Dictionary Words
String Characteristics
Description
- User Agents
- URLs
- Character set of regular expressions
- Network protocols (e.g., WiFi)
- Common OS commands
- JSON format
- Encodings (e.g., UTF-8)
- E-Mail address
- DTD
- HTML Colors
- Class Path
- SQL Queries
- Keywords for seven programming languages
- Country names
- XML
- IP
- HTTP state
- Date
- Numeric
- Cryptographic primitives
- Mobile phone brands
- HTML special characters (e.g., uuml)
- String-encoded certificate
- String-encoded Android certificate
- Private/Public key
- String signatures of social network apps
- String-encoded images (e.g. JPEG)
- Tests if all chars in the given string are equally,
distributed indicating a random distribution.
- The average distribution which is close to the
Gaussian distribution for plain strings,
- The normalized entropy of the strings,
- Number of equals
- Number of dashes
- Number of slashes
- Number of pluses
- Sum of repetitive characters
- The rate of the GZIP compression
- The string is used in a known crypto library
- The shortest word length
- The largest word length
- The number of words
- The number of unique words from a
multiple language dictionary
- Number of vocals
- Number of consonants
- Number of digits
- Number of characters
- Number of unique characters
- Number of non letters
- Maximum number of consecutive characters
- Maximum occurrences of the same character
of concatenated words (e.g. getLength), we use Samurai [19], which
splits identifiers by camel case and frequently used words.
String characteristics: Finally, we extract eight features related to
character distributions, e.g., character counts, digits.
Evaluation We use 80% of our data set for training and testing
and 20% for validation. To train and test the model, we use a 10-fold
cross-validation measure. Our validation data revealed a precision
of 98.79% and a recall of 89.75%. We identified two root causes for
false negatives. The first cause is that obfuscated strings accidentally
contain valid words (this is exacerbated by languages where a single
character can be a valid word, e.g. Chinese). The second, more
prevalent cause is obfuscated strings that consist of digits since
these frequently occur in plain text strings as well.
3.1.3 Classifier for Deobfuscation Methods. The string classifier
may miss obfuscated strings that are hidden in other data types, e.g.,
strings represented as byte arrays (cf. Table 1 BA). To address this
problem, we train a second classifier that identifies deobfuscation
methods. We use the identified methods from Section 2.
Approach. We postulate that deobfuscation methods use certain
instructions more often than ordinary methods. This idea is inspired
by statistical analysis of English text, which, e.g., contains a high
number of the character ’e’ [43]. Likewise, deobfuscation methods
may use the XOR instructions more frequently than ordinary meth-
ods. To this end, we extract all instructions used in deobfuscation
methods of the identified schemes (cf. Section 2). The extraction of
the instructions is performed using the Structure-preserving Repre-
sentation (SPR) [22]. This representation preserves the structural
tokens of a method’s instructions but abstracts away information
that gets changed in obfuscated code and, thus, would produce
noise for the classification, e.g., all name and type information that
does not occur in the Android standard library is removed. We
compare the SPR-token distribution of our set of deobfuscation
methods with the ones found in apps using Spearman’s correlation
to identify similar methods. This comparison enables the method
classifier to handle obfuscation schemes that do not use string rep-
resentations (e.g. BAs) and identify not only exact matches of the
token distribution but also variations of it. Furthermore, we limit
our token extraction to those tokens occurring in known deobfus-
cation methods; as a result, our method classifier is also able to
identify in-lined deobfuscation logic.
Evaluation The primary purpose of the method classifier is
to locate deobfuscation schemes that represent obfuscated strings
in other data structures. As reported in Section 2, only two such
schemes exist (cf. BA in Table 1), and these also generate variations
of the deobfuscation logic. Nevertheless, to assess the precision
and recall of the method classifier, we use not only the schemes
which generate variations of known deobfuscation methods as a
ground truth but the methods of all the obfuscation tools acquired in
Section 2. We use methods generated by all tools since the method
classifier discriminates all kinds of deobfuscation methods, not only
those that handle other data structures than strings.
The two mentioned tools vary the logic of the deobfuscation
methods in different ways. First, they use random numbers as obfus-
cation keys. Second, they permute the order of formal parameters
or change the method’s signature. Third, they alter the position of
code blocks, whose execution order does not matter. Finally, deob-
fuscation methods may also depend on the context of string usages.
For instance, if a string is used only once in a class, one tool in-lines
the deobfuscation logic at the string usage site; in other cases, this
logic is extracted into a separate called method.
To measure the precision of the classifier and recall for each
variation, we applied the both obfuscators to the F-Droid data set
(cf. Section 3.1.1). We were able to generate 2,127 obfuscated apps,
at least 1,000 apps for each obfuscator 3. The deobfuscation methods
in the resulting obfuscated apps constitute our ground truth for
measuring recall and precision.
To extract them, we use information from the mapping files
produced by the obfuscator tools for each app. Mapping files enable
app developers to find the original names in the source code for
crash reports using obfuscated names. Consequently, methods and
fields with no entry in the mapping file must have been added by the
obfuscator. We add all new methods and also methods that access
newly added fields to the ground-truth list. The newly added fields
are used to identify in-lined deobfuscation logic, which resides in a
previously existing method.
Altogether, we obtain a list of 144,190 methods that contain
deobfuscation logic, either in a separate method or in-lined into
previously existing methods. The comparison of this list with the
method classifier’s output shows that it identifies the variants of
deobfuscation methods generated by the two subject obfuscator
tools with a precision of 99.66% and a recall of 97.42%. We conclude
that our classifier is very accurate, missing only a few deobfuscation
methods. A detailed analysis revealed that these methods have in-
lined obfuscation logic, but already used byte arrays before the
obfuscation. These previously existing byte arrays add noise to the
measured token distribution and weaken the correlation between
the method under analysis and our set of known deobfuscation
methods.
3.2 Slicing Relevant String Usages
A slicing criterion (scrit ) is any instruction within certain methods,
which we call candidate methods, that produces a string value.
A method m is in the set of candidate methods if (a) it contains
instructions that consume a char sequence as a parameter (method
calls, but also field writes, array stores, and return instructions),
called Locations of Interest (LoIs), and (b) satisfies one of following
conditions: (i) the string classifier found an obfuscated string in m,
(ii) m calls a method n, which the method classifier identified as a
deobfuscation method, or (iii) m is itself classified as a deobfuscation
method (in-lined deobfuscation logic).
Since the classifiers identify neither LoIs nor slicing criteria, we
have to search for them in the candidate methods. We use OPAL [18]
to find all instructions that operate on values of type CharSequence,
or a subtype thereof, in particular java.lang.String. All scrit are
expressions that result in strings which are afterward passed to
some LoI. Given a candidate method that contains LoIs, we identify
all scrit while ignoring constant string expressions.
3We were not able to obfuscate every app with every obfuscator due to version
incompatibilities between obfuscators and APKs to be obfuscated.
Our slicing algorithm performs backward slicing with forward-
phases to collect all instructions necessary for the execution of
other relevant instructions. For instance, if the slice contains a new
instruction, we also collect the corresponding constructor invoca-
tion. Additionally, if several potential sources for a given string
parameter are present, we start form each of them as separate
slicing criterion.
For example, Listing 1 shows two sources of msg (Line 2) cor-
responding to the two branches of the tertiary operator (Line 1),
which load either "US()" or "INT()". In such cases, StringHound
would start the slicing process for each source.
1
2
String msg = simCountryIso().equals("US") ? US() : INT();
invoke("+01234", msg);
Listing 1: Example with Two Sources
3.3 Our targeted Slicing
Our slicing technique (cf. Algorithm 1) is inspired by traditional
slicing algorithms (cf. Binkley et al. [6]), and implemented using
OPAL [18] with definitions (cf. Aho et al. [1]) of the functions
defined in Table 3.
Given a method along with its control-flow graph (CFG), a LoI
and a slicing criterion scrit , we initialize the worklist W (Line 2 of
Figure 1) with scrit . For each instruction in W (Line 6) that is not
already part of the slice (Line 8), we perform the following steps:
(1) We add the current instruction currInstr to the slice (Line 9).
Table 3: Definitions of Helper Functions for the Algorithm
def
use
du
ud
cd
br
Instr → P(V ar)
Instr → P(V ar)
V ar × Instr → P(Instr)
V ar × Instr → P(Instr)
Instr → P(Instr)
Instr → P(Instr)
variables defined by an instruction
variables used by an instruction
definition-use instructions
use-definition instructions
transitive control dependency instructions
set of backwards reachable instructions
Algorithm 1: Slicing Algorithm
Input: m a method with a body
corresponds to one node n ∈ N of д
I the instructions of the method m
д the CFG of m where each i ∈ I
LoI ∈ I the location of interest
scr it ∈ I the slicing criterion
Output: Nslice ⊆ I
1 Nslice := {}
2 W := {scr it }
3 cdcr it := cd(scr it )
4 brLoI := br(LoI)
5 while W (cid:44) ∅ do
curr Instr := head(W )
W := W \ curr Instr
if currInstr (cid:60) Nslice then
6
7
8
9
10
11
12
13
14
15
16 end
end
Nslice := Nslice ∪ { curr Instr }