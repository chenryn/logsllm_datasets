72,955
ELF
56,330
52,991
ELF
Table 1: Test programs used in our evaluation.
ing instructions are handled by simply copying labels
from the original value to the result.
5 Evaluation
We evaluate PGA by comparing its performance directly
to DTA, and in direct applications for bug ﬁnding and
security analysis. Speciﬁcally, we run experiments to
answer the following questions:
1. Dataﬂow Accuracy: Is PGA more accurate than
DTA in tracking dataﬂows?
2. Overhead: How does the overhead introduced by
PGA compare to DTA?
3. Guided Fuzzing: Does using PGA to guide fuzzing
lead to better edge coverage?
4. CVE Analysis: Can PGA detect and analyze re-
cent CVEs that taint is typically used to detect?
5. Bug Discovery: Is PGA an eﬀective tool for ﬁnd-
ing bugs?
6. Information Leaks: Can PGA detect and analyze
memory and timing-based information leaks?
5.1 Experimental Setup
Test Programs. We perform tests on a set of 5 widely
used ﬁle parsing libraries and 7 total programs. We use
ﬁle parsers because these programs often must process
ﬁles from untrusted sources, making them a common
target for attacks. Table 1 shows the test programs and
SLOC associated with each executable tested. In total
the programs have 391,883 SLOC.
Fuzzers Evaluated. For our fuzzing experiments, we
use the latest version of NEUZZ 1 and VUzzer 2.
Test Environment. All of our evaluations are per-
formed on an Ubuntu 16.04 server with an Intel Xeon
E5-2623 v4 2.60GHz CPU and 192G of memory unless
otherwise speciﬁed.
1www.github.com/Dongdongshe/neuzz
2www.github.com/vusec/vuzzer64
5.2 Performance
We ﬁrst evaluate the performance of PGA as a tool
for dynamic dataﬂow analysis. In our experiments, we
compare PGA to DataFlowSanitizer (dfsan), LLVM’s
state-of-the-art DTA implementation. Since our imple-
mentation of PGA is based on the dfsan architecture,
our setup ensures that any diﬀerences in performance
between PGA and DTA are to due the respective perfor-
mance of gradient and taint and not due to diﬀerences
in the underlying architectures.
We compare performance in three areas: ﬁrst, we esti-
mate the accuracy of the dataﬂows predicted by PGA
and DTA. Second, we evaluate the overhead introduced
by the PGA instrumentation. Third, we compare the
edge coverage achieved by a dataﬂow-guided fuzzer using
either PGA or DTA to guide its mutation strategy.
Evaluation Inputs. We use the same set of initial input
ﬁles for all of the performance evaluations. The gzip,
pdf, and ELF ﬁles are sourced from the AFL sample
seeds included in the distribution3. The jpeg input was
generated from running a small jpeg image through a
jpeg reduction service4. The libxml input was selected
from the libxml5 test inputs smaller than 700 bytes with
the greatest AFL branch coverage.
5.2.1 Dataﬂow Accuracy
We evaluate the accuracy of PGA in comparison to DTA
against an estimate of ground truth dataﬂows. This com-
parison setting favors DTA since it does not take the
ﬁne grained dataﬂow information from PGA into ac-
count (i.e., only considers binary 0/1 inﬂuence), but still
illustrates the beneﬁts of PGA’s increased precision. In
addition to comparing against dfsan, we also compare
against libdft, another widely used DTA framework
that uses Intel PIN to instrument the binary directly,
Neutaint, which uses the gradients of a neural network
to model dataﬂows, and an ablation of PGA with bi-
nary gradients, grsan (binary). Notably, libdft tracks
taint at byte level granularity and incorporates special
case rules to handle operations that cancel out dataﬂows,
such as y = x - x.
Ground truth estimation. To estimate ground truth
dataﬂows, we measure if changes in taint sources cause
changes in sink values during execution. When recording
executions, we only consider executions that follow the
same path to remove implicit ﬂows, since neither DTA nor
PGA can detect these. We mark each byte read from the
input ﬁle as a source and each branch condition as a sink,
because branches ultimately determine the behavior of a
program, and because many security vulnerabilities can
3https://github.com/google/AFL
4https://tinyjpg.com/
5https://gitlab.gnome.org/GNOME/libxml2/
1618    30th USENIX Security Symposium
USENIX Association
Neutaint
Prec. Rec.
0.55
0.02
0.33
0.02
0.002
0.19
0.69
0.07
0.20
0.03
0.39
0.02
0.06
0.39
F1
0.04
0.04
0.004
0.12
0.05
0.03
0.11
minigzip
djpeg
mutool
xmllint
objdump
strip
size
libdft
Prec. Rec.
0.42
0.29
-
-
0.70
0.47
0.26
0.20
-
-
0.32
0.67
0.59
0.59
dfsan
Prec. Rec.
0.60
0.29
1.00
0.22
0.63
0.61
0.99
0.62
0.93
0.37
0.96
0.20
0.37
0.95
F1
0.39
0.37
0.62
0.76
0.52
0.33
0.53
grsan (binary)
Prec. Rec.
F1
0.22
0.15
0.41
0.62
0.63
0.62
0.87
0.50
0.63
0.89
0.87
0.91
0.58
0.66
0.51
0.53
0.72
0.42
0.54
0.76
0.63
grsan (ﬂoats)
F1
0.57
0.69
0.64
0.92
0.71
0.63
0.74
Prec. Rec.
0.51
0.63
0.83
0.60
0.86
0.51
0.91
0.94
0.77
0.66
0.86
0.50
0.62
0.91
F1
0.17
-
-
0.22
0.28
0.18
0.30
Table 2: Summary of accuracy comparison results for DTA and PGA systems. Neutaint, libdft, and dfsan
are state-of-the-art DTA systems, while binary grsan is an ablation of PGA that only uses binary (1 or 0)
gradients to test the impact of precise gradients on accuracy. Best F1 scores for each program are highlighted.
Experiments with libdft on djpeg and xmllint timed out after 24hrs. PGA (with ﬂoating point gradients)
outperforms DTA on all programs, and full precision (ﬂoats) grsan outperforms binary grsan on all programs.
only be exploited when certain branches are taken. For
each input byte, we set the byte to 0, 255, and toggling
each bit for a total of 10 samples. We found that this
sampling strategy usually triggered a change in the sink
variable when there was a valid dataﬂow.
Accuracy evaluation. We perform the accuracy eval-
uation on the programs shown in Table 1 using a set
of small seed ﬁles (<1Kb) to make sampling each byte
feasible. Since valid dataﬂows often only involve a few
input bytes, we use F1 accuracy, which is a standard
metric for evaluating predictions on imbalanced classes
in classiﬁcation problems. F1 accuracy is computed as
F1 = 2∗ precision∗recall
precision+recall. Precision indicates the propor-
tion of bytes with predicted dataﬂows that are correct
(i.e. not false positives), while recall indicates the pro-
portion of valid dataﬂows that were correctly predicted
(i.e. not false negatives). Results are shown in Table 2.
Generally, PGA achieves a signiﬁcant improvement in
precision, achieving up a 37% increase in precision and
33% increase in F1 accuracy (20% on average) compared
to the best performing DTA system, dfsan. Overall PGA
gets higher F1 scores for all programs. In spite of incor-
porating special case dataﬂow cancellation rules for its
bitwise and numerical operations, libdft achieves lower
accuracy than dfsan in the evaluation. We hypothesize
this is due to the diﬃculty in writing handcrafted rules
for all possible X86 instructions, which leads to errors in
propagation rules as noted in [12]. The binary gradient
PGA ablation, grsan (binary), also has much lower
accuracy than full precision PGA, indicating gradients
are essential to computing accurate dataﬂows with PGA.
We discuss the binary gradient ablation in more detail
in Appendix A.
Result 1: PGA achieves the highest F1 accuracy on
all 7 tested programs compared to 3 state-of-the-art
DTA systems, and is up to 33% more accurate than
the next most accurate DTA system, dfsan.
Additional Accuracy Experiments. In addition to
the accuracy experiment in Table 2, we run experiments
to address the following: (1) How do varying compiler
optimization levels eﬀect the accuracy of PGA vs. DTA?
(2) How does PGA perform against Neutaint in Hot-
byte prediction? (3) On which speciﬁc operations does
PGA vary from DTA due to 0 gradients? (4) How does
PGA compare with Quantitative Information Flow (QIF)
techniques? We summarize the results here and describe
these experiments in detail in Appendix A.
1. Compiler Optimization. PGA’s accuracy im-
provement over DTA is robust to varying compiler
optimization levels. On average, PGA is at least 18%
more accurate than DTA on compiler optimization
levels -O0 through -O2.
2. Hotbyte Prediction. When we reproduce the Hot-
byte experiment described in Neutaint [43], (i.e.
identifying input bytes with the most dataﬂows to
branches) PGA achieves 43.8% accuracy while Neu-
taint achieves 64.3% accuracy on average. Neutaint
achieves higher average accuracy because it trains
on a large corpus of recorded execution traces, while
PGA and the DTA reason about a single input and
execution trace at a time. We see Neutaint as a
complementary method that performs well in iden-
tifying hotbytes, while PGA has better ﬁne grained
dataﬂow accuracy, and both methods could be used
together in program analysis.
3. Zero Gradient Analysis. PGA avoids overtaint-
ing errors when it computes zero gradients on oper-
ations where DTA would propagate taint. We ﬁnd
the zero gradients occur most frequently on And,
Remainder, Sub, Mul, and Shift operations, and that
zero gradients are most often caused by masking,
shifting, or composition eﬀects.
4. QIF Comparison. We compare PGA with a QIF
tool Flowcheck that quantiﬁes information ﬂow
USENIX Association
30th USENIX Security Symposium    1619
Figure 7: Comparison of guided fuzzer edge coverage achieved by PGA and DTA over 100k mutations from a
single seed. Overall gradient-guided fuzzing achieves up to 56% higher coverage and improves the rate of new
edge discovery by 10% on average.
in the form of bit leakage [28]. PGA outperforms
Flowcheck by 22% on average in terms of F1 accu-
racy.
5.2.2 Overhead
We observe two conﬂicting phenomena when measur-
ing overhead: PGA can either increase overhead due to
the additional ﬂoating point storage and computation
required by gradients, or decrease runtime and memory
overhead when its increased precision reduces unneces-
sary dataﬂow tracking operations that use additional
computation and shadow memory.
We evaluate the overhead introduced by our imple-
mentation of PGA in runtime and memory relative to
dfsan on a single source dataﬂow. Note that if we con-
sider overhead for multiple sources, the runtime will be
lower and the memory overhead will be higher for a
multi-source implementation. In the worst case PGA has
21.7% greater overhead in runtime and 21.5% in memory
relative to DTA, but on average only adds 3.21% rela-
tive overhead in runtime and 1.48% in memory. Table 9
and Table 10 in Appendix B show the detailed results.
We also provide overhead measurements for libdft, al-
though it adds signiﬁcantly more overhead due to the
binary instrumentation.
Result 2: On average PGA increases runtime overhead
by 3.21% runtime and memory overhead by 1.48%
relative to DTA, and increases runtime by 21.7% and
memory usage by 21.5% relative to DTA in the worst
case.
5.2.3 Dataﬂow-Guided Fuzzing
Since dynamic dataﬂow analysis is often used as a tool
to guide fuzzing, we evaluate PGA in comparison to
DTA as a method for guiding fuzzer mutations. Unlike
our evaluation of dataﬂow accuracy, this experiment
emphasizes the dataﬂow magnitude information provided
by the program gradient, since bytes with the largest
derivatives are selected for fuzzing.
We ﬁrst compare PGA and DTA using a simple de-
terministic strategy for mutating input bytes based on
dataﬂows to branches. This ensures there is no bias
from randomized mutation strategies or other heuristics
employed by state-of-the-art fuzzers in this evaluation.
First, we execute the program with all inputs set as
sources and all branches set as sinks. We then select
128 bytes from the input bytes based on the measured
taint and gradient ﬂows to branches. With PGA, the
bytes with the greatest gradients are prioritized, this
approach utilizes the additional information provided
by PGA to improve the mutation strategy. The fuzzer
performs a deterministic set of mutations on the selected
128 bytes, in which each byte in turn is set to all 256
possible values.
Edge coverage comparison. We execute the fuzzer
with both PGA and DTA for 100,000 mutations, and
record coverage every 10,000 mutations. Figure 7 shows
the relative edge coverage achieved by each method.
On average the gradient guided fuzzing outperforms
taint in increasing edge coverage by 10% per 10,000
mutations. The gradient guided fuzzer achieves higher
coverage on all programs, with the greatest improvement
in overall edge coverage of 56% on strip. We note that
for some programs such as xmllint, there is a signiﬁcant
disparity between the results of the guided fuzzing and
precision evaluations. We believe this diﬀerence is caused
by two factors: the magnitude of the gradient was more