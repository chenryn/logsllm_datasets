ments are aggregated. A matching provides a score representing
how many instructions from the original trace appear in either the
obfuscated subtrace or our relevant subtrace.
As a ﬁnal step, we wish to calculate how effective our analysis
has been. To do this, we must take into account two competing
factors. First, our analysis is trying to identify as many instructions
from the original trace as possible. At the same time, we are trying
to eliminate as many virtual machine instructions as we can. To
this end, we present two numbers for each test. The ﬁrst, which
we call the relevance score, is the percentage of the instructions
from the original trace that are included in the relevant subtrace.
The second, which we call the obfuscation score, is the percentage
of instructions added by the obfuscator that are correctly excluded
from the relevant subtrace. It is easy to optimize either of these
values individually, but achieving good (i.e., close to 100%) scores
for both is difﬁcult, and will provide a fair evaluation of our work.
Taking into account the above discussion and concerns, we present
the following methodology for evaluating our analysis:
1. Original source code of a test program is compiled into an
executable.
2. A dynamic trace is generated for the original executable on
some input set.
3. An original subtrace is generated by including only instruc-
tions from the executable module.
4. The executable ﬁle is protected using an available virtualization-
obfuscation technique.
5. A dynamic trace is generated for the obfuscated version of
the executable.
6. We perform our analysis per Section 2 on the obfuscated sub-
trace, and generate a relevant subtrace.
7. The obfuscated subtrace is matched to the original subtrace,
and scores are produced.
8. The relevant subtrace is matched to the original subtrace, and
scores are produced.
9. The relevance score and obfuscation score are calculated.
10. The process is repeated for all combinations of virtualization-
obfuscation techniques and input test ﬁles.
3.2 Experimental Results
To evaluate our analysis, we tested three toy programs simple
enough that results could be checked by hand–an iterative facto-
rial implementation, a matrix multiplaction program with double
nested loops, and a recursive ﬁbonacci implementation. We also
tested two samples of malicious code–BullMoose and hunatcha–
whose C source code was available from the VX Heavens web
282Name
Original trace size Obfuscated trace size Relevant trace size
relevant matching
Rel. Score Obf. Score
Table 1: Results for programs obfuscated with VMProtect
factorial
matrx_mult
ﬁbonacci
BullMoose
hunatcha
md5
92
651
151
94
2226
2257
15365
138798
16438
6900
3327
77219
222
597
167
376
1347
5347
54
345
63
36
1347
1700
58.7%
53.0%
41.7%
38.3%
60.5%
75.3%
99.0%
99.8%
99.4%
95.0%
100.0%
95.1%
Name
Original trace size Obfuscated trace size Relevant trace size
relevant matching
Rel Score Obf Score
Table 2: Results for programs obfuscated with CodeVirtualizer
factorial
matrx_mult
ﬁbonacci
BullMoose
hunatcha
md5
92
651
151
94
2226
2257
172249
1571686
223053
120982
3881611
5732714
48720
270143
18560
32817
1066993
2613431
56
454
102
67
1524
2099
60.9%
69.7%
67.5%
71.3%
68.5%
93.0%
71.7%
82.8%
91.7%
72.9%
72.5%
54.4%
site [1]. Finally, we tested a simple benchmark utility that performs
the md5 checksum. The results of our analysis on VMProtect ob-
fuscated code are shown in Table 1 and the results of our analysis
on CodeVirtualizer obfuscated code are shown in Table 2.
Table 1 shows that for most of our test programs, our analysis
is able to identify better than half of the original programs instruc-
tions, while in all cases eliminating over 90% of the obfuscation
introduced by VMProtect. Similarly, Table 2 shows even better
results, identifying on average about 70% of original program in-
structions from CodeVirtualizer obfuscated code. However, our
analysis fairs worse, eliminating about 75% of obfuscation instruc-
tions on average. Overall, these results are encouraging, since our
approach only identiﬁes those instructions that affect the behavior
of the program. We anticipate that many of the “missed” instruc-
tions are performing functions like allocating memory or initializ-
ing data structures, and will not be caught by our analysis under any
conditions. Hand analysis reveals that some of the missed instruc-
tions result from instruction implementations whose equivalences
(see Section 3.1) were not anticipated. For example, some push
and pop instructions were replaced with mov.
We note that, unlike the rest of our test programs, we were not
able to achieve our results for the md5 benchmark program through
totally automated means. The analysis of this program, even on
the unprotected version, used excessive amounts of memory and
crashed. The problem resulted from some of the return values of
early calls to fopen and fread functions being used in later calcu-
lations. The resulting expressions were not able to be simpliﬁed
easily by our equational reasoning system, which resulted in larger
and larger expressions being generated late in the dynamic trace.
We would also like to note, however, that our equational reasoning
system allowed us to identify this problem easily, and also to se-
lect these function call return values for manual simpliﬁcation. We
were able to make these simpliﬁcations in about an hour, and feel
that the results were still worth reporting.
We examined the results by hand, and found the reason for the
lower obfuscation scores on CodeVirtualizer ﬁles as compared to
VMProtect ﬁles. CodeVirtualizer uses an interesting technique that
artiﬁcially creates a dependency between some original program
instructions and the virtual machine interpreter instructions. We
believe that this may result from the use of constant values that are
stored in memory, and manipulated to add obfuscation. For ex-
ample, instructions that require the constant 1, may instead use a
reference to a variable that holds the value 1. Furthermore, if this
variable is modiﬁed every time it is used (e.g., it is incremented
then decremented just before use), this will create an artiﬁcial de-
pendency between the use of the value, and all previous instances
of manipulation. Of course, the obfuscator cannot change the func-
tion of the original program, so we believe these dependencies can
be identiﬁed. We have had some success using code simpliﬁcation
techniques such as constant propagation and arithmetic simpliﬁca-
tion, but work on this issue continues.
The results in both tables also show the extraordinary increase
in the number of executed instructions for both obfuscators. Our
toy ﬁbonacci program, for example, executes 151 instructions in
the original trace. However, the VMProtect obfuscated version ex-
ecutes 16,438 instructions, and the CodeVirtualizer obfuscated ver-
sion executes 223,053.
4. DEFEATING OUR ANALYSIS
The previous discussion begins to answer an obvious question:
how would an attacker defeat our analysis? We must assume that
once our analysis is known, malware authors will attempt to exploit
its vulnerabilities. Our analysis is highly dependent on the output of
our equational reasoning system, which attempts to build simpliﬁed
equations for each instruction in the dynamic trace. In the case of
the md5 analysis, we have seen how calls to fopen and fread could
not be simpliﬁed away, leading to longer and longer expressions
later in the trace of both the unprotected and protected versions of
the test ﬁle. We have similar results when analyzing the CodeVirtu-
alizer protected versions of code, which stores important values in
encrypted form in memory, then decrypts these values before use.
The decryption routine is difﬁcult to simplify, and if properly cho-
sen, could similarly cause runtime and memory usage issues in the
equational reasoning system. Hence, any such algorithm, embed-
ded in the code, that cannot be simpliﬁed away has the potential to
cripple our analysis by making the problem impractical.
We have also seen how CodeVirtualizer builds artiﬁcial depen-
dencies between the virtual machine code and the original program
283code. Since our analysis is based on the idea of separating these
two sets of instructions, successfully building such dependencies
has the effect of thwarting the analysis. If done properly, it may be
possible to build such dependencies between most, or all, instruc-
tions in the trace, thus driving our obfuscation scores toward 0%.
Because the obfuscation cannot change the function of the original
program, we speculate that such dependencies can, in theory, be
identiﬁed and handled. However, to date, we have not explored this
idea in depth, and leave such analysis for future work.
5. RELATED WORK
The deobfuscation of code obfuscated using virtualization ob-
fuscators has been discussed by Rolles [12], Sharif et al. [13], and
Falliere [6]. These works follow the outside-in approach outlined
in Section 1. Lau discusses the use of dynamic binary translation
to deal with virtualization obfuscators [9].
There has been some work, in the programming language com-
munity, on using a technique called partial evaluation [7] for code
specialization, in particular for specializing away interpretive code.
However, the literature assumes that the program analysis and trans-
formation are static, which suggests that its application to highly
obfuscated malware binaries may not be straightforward.
The notion of obfuscation through virtualization has some sim-
ilarities with the idea of control ﬂow ﬂattening [17]. Udupa et al.
discuss techniques for deobfuscating code that has been subjected
to this transformation [15]. These techniques are static, and there-
fore very different from the ideas presented here.
There is a rich body of work on various sorts of dependence anal-
ysis in the program analysis literature. The notion of ud-chains
for relating uses and deﬁnitions of variables during static program
analysis is well-established [2]. There is an extensive body of lit-
erature on program slicing [14], but as discussed earlier this tech-
nique seems too imprecise for our needs.
6. CONCLUSIONS
Virtualization-obfuscated programs are difﬁcult to reverse engi-
neer because examining the machine instructions of the program,
either statically or dynamically, does little to shed light on the pro-
gram’s logic, which is hidden in the interpreted byte-code. Prior ap-
proaches to reverse-engineering virtualization-obfuscated programs
typically work by ﬁrst reverse engineering the byte-code interpreter,
and then working back from this to work out the logic embedded
in the byte code. This paper describes a different approach that fo-
cuses on identifying the ﬂow of values to system call instructions.
This new approach can be applied to a larger number of obfuscated
binaries because it makes fewer assumptions about the nature of the
virtual machine interpreter, and still produces good results on test
ﬁles including two malware executables and one benchmark util-
ity. On average, we identify 50% to 75% of instructions from the
original program, while eliminating approximately 75% to 90% of
instructions added by the obfuscator.
The system works by gradually adding instructions that are cal-
culated to be of importance, and adding these to a relevant sub-
trace that represents the behavior of the original, unobfuscated pro-
gram. Instructions that contribute to the values of system call argu-
ments are included, as are call/return pairs, and conditional control
ﬂow statements. We note that our analysis only identiﬁes condi-
tional control ﬂow statements of the original program that appear
in the dynamic trace, and, thus, misses code paths that are not exe-
cuted. In principle, it should be possible to extend multi-path anal-
ysis techniques (see, e.g., [10]) to the conditionals so identiﬁed.
In practice, our intuition is that this will likely be challenging be-
cause virtualization-based obfuscation will mean that identifying
path constraints (as in Moser et al’s work) will not be straightfor-
ward. The issue is beyond the scope of this work, but would be
interesting and relevant for future work.
Acknowledgements
This work was supported in part by the National Science Founda-
tion via grant no. CNS-1016058, as well as by a GAANN fellow-
ship from the Department of Education award no. P200A070545.
7. REFERENCES
[1] VX Heavens, 2011. http://vx.netlux.org/.
[2] A. V. Aho, R. Sethi, and J. D. Ullman. Compilers – Principles,
Techniques, and Tools. Addison-Wesley, Reading, Mass., 1985.
[3] F. Bellard. QEMU, a fast and portable dynamic translator. In
USENIX Annual Technical Conference, FREENIX Track, pages
41–46. USENIX, 2005.
[4] K. Coogan and S. Debray. Equational reasoning on x86
assembly code. Source Code Analysis and Manipulation, IEEE
International Workshop on, 2011.
[5] A. Dinaburg, P. Royal, M. I. Sharif, and W. Lee. Ether:
malware analysis via hardware virtualization extensions. In
Proceedings of the 2008 ACM Conference on Computer and
Communications Security, CCS 2008, Alexandria, Virginia,
USA, October 27-31, 2008, pages 51–62, 2008.
[6] N. Falliere. Inside the jaws of Trojan.Clampi. Technical
report, Symantec Corp., Nov. 2009.
[7] N. D. Jones, C. K. Gomard, and P. Sestoft. Partial Evaluation
and Automatic Program Generation. Prentice Hall, 1993.
[8] A. Lakhotia, E. U. Kumar, and M. Venable. A method for
detecting obfuscated calls in malicious binaries. IEEE
Transactions on Software Engineering, 31(11):955–968, 2005.
[9] B. Lau. Dealing with virtualization packer. In Second CARO
Workshop on Packers, Decryptors, and Obfuscators, May 2008.
[10] A. Moser, C. Kruegel, and E. Kirda. Exploring multiple
execution paths for malware analysis. In SP ’07: Proceedings
of the 2007 IEEE Symposium on Security and Privacy, pages
231–245, 2007.
[11] Oreans Technologies. Code virtualizer: Total obfuscation
against reverse engineering, Dec. 2008.
http://www.oreans.com/
codevirtualizer.php.
[12] R. Rolles. Unpacking virtualization obfuscators. In Proc. 3rd
USENIX Workshop on Offensive Technologies (WOOT ’09),
Aug. 2009.
[13] M. Sharif, A. Lanzi, J. Gifﬁn, and W. Lee. Automatic reverse
engineering of malware emulators. In Proc. 2009 IEEE
Symposium on Security and Privacy, May 2009.
[14] F. Tip. A survey of program slicing techniques. Journal of
Programming Languages, 3:121–189, 1995.
[15] S. K. Udupa, S. K. Debray, and M. Madou. Deobfuscation:
Reverse engineering obfuscated code. In Proc. 12th IEEE
Working Conference on Reverse Engineering, pages 45–54,
Nov. 2005.
[16] VMProtect Software. Vmprotect software protection, 2008.
http://vmpsoft.com/.
[17] C. Wang, J. Davidson, J. Hill, and J. Knight. Protection of
software-based survivability mechanisms. In Proc.
International Conference of Dependable Systems and
Networks, July 2001.
284