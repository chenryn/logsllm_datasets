title:FLAX: Systematic Discovery of Client-side Validation Vulnerabilities
in Rich Web Applications
author:Prateek Saxena and
Steve Hanna and
Pongsin Poosankam and
Dawn Song
FLAX: Systematic Discovery of Client-side Validation Vulnerabilities
in Rich Web Applications
Prateek Saxena§
Steve Hanna§
Pongsin Poosankam‡§
Dawn Song§
{prateeks,sch,ppoosank,dawnsong}@eecs.berkeley.edu
§University of California, Berkeley
‡Carnegie Mellon University
Abstract
The complexity of the client-side components of web
applications has exploded with the increase in popularity
of web 2.0 applications. Today, traditional desktop ap-
plications, such as document viewers, presentation tools
and chat applications are commonly available as online
JavaScript applications.
Previous research on web vulnerabilities has primarily
concentrated on ﬂaws in the server-side components of web
applications. This paper highlights a new class of vulnera-
bilities, which we term client-side validation (or CSV) vul-
nerabilities. CSV vulnerabilities arise from unsafe usage of
untrusted data in the client-side code of the web applica-
tion that is typically written in JavaScript.
In this paper,
we demonstrate that they can result in a broad spectrum of
attacks. Our work provides empirical evidence that CSV
vulnerabilities are not merely conceptual but are prevalent
in today’s web applications.
We propose dynamic analysis techniques to systemati-
cally discover vulnerabilities of this class. The techniques
are light-weight, efﬁcient, and have no false positives. We
implement our techniques in a prototype tool called FLAX,
which scales to real-world applications and has discovered
11 vulnerabilities in the wild so far.
1
Introduction
Input validation vulnerabilities constitute a majority of
web vulnerabilities and have been widely studied in the
past [4, 8, 24, 28, 30, 35, 42, 43]. However, previous vul-
nerability research has focused primarily on the server-side
components of web applications. This paper focuses on
client-side validation (or CSV) vulnerabilities, a new class
of vulnerabilities which result from bugs in the client-side
code.
A typical Web 2.0 application has two parts: a server-
side component and a client-side component. The server-
side component processes the user’s request and generates
an HTML response that is sent back to the browser. The
client-side code of the web application, typically written in
JavaScript, is sent with the HTML response from the server.
The client-side component executes in the web browser and
is responsible for processing input data and dynamically up-
dating the view of web page on the client. We deﬁne a CSV
vulnerability as one which results from unsafe usage of un-
trusted data in the client-side code of the web application.
CSV vulnerabilities belong to the general class of in-
put validation vulnerabilities, but are different from tradi-
tional web vulnerabilities like SQL injection [10, 35] and
reﬂected/stored cross-site scripting [18, 26, 37, 39]. For ex-
ample, one type of CSV vulnerability involves data that
enters the application through the browser’s cross-window
communication abstractions and is processed completely by
JavaScript code, without ever being sent back to the web
server. Another type of CSV vulnerability is one where a
web application sanitizes input data sufﬁciently before em-
bedding it in its initial HTML response, but does not sani-
tize the data sufﬁciently for its use in the JavaScript compo-
nent.
CSV vulnerabilities are becoming increasingly likely
due to the growing complexity of JavaScript applications.
Increasing demand for interactive performance of rich web
2.0 applications has led to rapid deployment of application
logic as client-side scripts. A signiﬁcant fraction of the data
processing in AJAX applications (such as Gmail, Google
Docs, and Facebook) is done by JavaScript components.
JavaScript has several dynamic features for code evaluation
and is highly permissive in allowing code and data to be
inter-mixed. As a result, attacks resulting from CSV vulner-
abilities often result in compromise of the web application’s
integrity.
Goals. As a ﬁrst step towards ﬁnding CSV vulnerabil-
ities, we aim to develop techniques that analyzes a web
application in an end-to-end manner. Since most existing
works have targeted their analyses to server-side compo-
nents (written in PHP, Java, etc.), this paper develops com-
plementary techniques to discover vulnerabilities in client-
side code. In particular, we develop a framework for sys-
tematic analysis of JavaScript1 code. Our objective is to
build a tool for vulnerability discovery that does not require
developer annotations, has no false positives and is usable
on real-world applications.
Challenges. The ﬁrst challenge of holistic application anal-
ysis is in dealing with the complexity of JavaScript. Many
JavaScript programs use code evaluation constructs to dy-
namically generate code as well as to serialize strings into
complex data structures (such as JSON arrays/objects). In
addition, the language supports myriad high-level opera-
tions on complex data types, which makes the task of prac-
tical analysis difﬁcult.
In JavaScript application code, we observe that parsing
operations are syntactically indistinguishable from valida-
tion checks. This makes it infeasible for automated syn-
tactic analyses to reason about the sufﬁciency of validation
checks in isolation from the rest of the logic. Due to the
convenience of their use in the language, developers tend
to treat strings as a universal type for exchange, both of
code as well as data. Consequently, complex string op-
erations such as regular expression match and replace are
pervasively used both for parsing input and for performing
custom validation checks.
Third, in many web applications the client-side code pe-
riodically sends data to a remote server for processing via
browser interfaces such as XMLHttpRequest, and then
operates on the returned result. We call such a ﬂow of data,
to a server and back, a reﬂected ﬂow. Client-side analyses
face the inherent difﬁculty of dealing with hidden process-
ing on remote servers due to reﬂected ﬂows.
Existing Approaches. Fuzzing or black-box testing is a
popular light-weight mechanism for testing applications.
However, black-box fuzzing does not scale well with a large
number of inputs and is often inefﬁcient in exploration of
the input space. A more directed approach used in the past
in the context of server-side code analysis is based on dy-
namic taint-tracking. Dynamic taint analysis is useful for
identifying a ﬂow of data from an untrusted source to a
critical operation. However, dynamic taint-tracking alone
alone can not determine if the application sufﬁciently vali-
dates untrusted data before using it, especially when parsing
and validation checks are syntactically indistinguishable. If
an analysis tool treats all string operations on the input as
parsing constructs, it will fail to identify validation checks
and will report false positives even for legitimate uses (as
shown by our experiments in Section 5). On the other hand,
1Our JavaScript analysis techniques take a blackbox view of the server-
side code currently, though in the future these could be be combined with
existing whitebox analyses of server-side components
if the analysis treats any use of untrusted data which has
been passed through a parsing/validation construct as safe,
it is likely to miss many bugs. Static analysis is another
approach [14, 17]; however static analysis tools do not di-
rectly provide concrete exploit instances and require addi-
tional developer analysis to prune away false positives.
Recently, symbolic execution techniques have been used
for discovering and diagnosing vulnerabilities in server-side
logic [9, 23, 25, 42]. However, web applications pervasively
use complicated operations on string and arrays data types,
both of which raise difﬁculties for decision procedures in-
volved in symbolic execution techniques. The power and
expressiveness of string decision procedures today is lim-
ited. Practical implementations of string decision proce-
dures presently do not deal with the generality of JavaScript
string constraints involving common operations (such as
String.replace, regular expression match, concatena-
tion and equality) expressed together over multi-variable,
variable-length inputs [9,20,23,25]. Other approaches have
been limited to a subset of input-transformation operations
in PHP [4]. The present limitations of symbolic execution
tools motivate the need for designing lighter-weight tech-
niques.
Our Approach. We propose a dynamic analysis approach
to discover vulnerabilities in web applications called taint
enhanced blackbox fuzzing. Our technique is a hybrid ap-
proach that combines the features of dynamic taint analy-
sis with those of automated random fuzzing.
It remedies
the limitations of purely dynamic taint analysis (described
above), by using random fuzz testing to generate test cases
that concretely demonstrate the presence of a CSV vulner-
ability. This simple mechanism eliminates false alarms that
would result from a purely taint-based tool.
The number of test cases generated by vanilla blackbox
fuzzing increases combinatorially with the size of the input.
In our hybrid approach, we use character-level precise dy-
namic taint information to prune the input search space sig-
niﬁcantly. Dynamic taint information extracts knowledge
of the type of sink operation involved in the vulnerability,
thereby making the subsequent blackbox fuzzing special-
ized for each sink type (or in other words, be sink-aware).
Taint enhanced blackbox fuzzing scales well because the
results of dynamic taint analysis are used to create indepen-
dent abstractions of the original application which are small
and take fewer inputs, and can be tested efﬁciently with
sink-aware fuzzing. From our experiments (Section 5), we
report an average reduction of 55% in the input sizes with
the use of dynamic taint information.
Summary of Results. We implement our techniques into a
prototype tool called FLAX. So far, FLAX has discovered
11 CSV vulnerabilities in our preliminary study of 40 pop-
ular real-world JavaScript-intensive programs in the wild,
which includes several third-party iGoogle gadgets, web
sites, AJAX applications and third-party libraries. These
vulnerabilities were unknown to us prior to the experi-
ments. Our ﬁndings conﬁrm that CSV vulnerabilities are
not merely conceptual but are prevalent in web applications
today. Our experimental results also provide a quantitative
measurement of the improvements taint enhanced blackbox
fuzzing gains over vanilla dynamic taint analysis or random
testing in our application.
Summary of Contributions. This paper makes the follow-
ing contributions:
1. We introduce client-side validation vulnerabilities, a
new class of bugs which result from unvalidated usage
of untrusted data in JavaScript code. We provide em-
pirical evidence of these vulnerabilities in real-world
applications.
2. We build a framework to systematically discover CSV
vulnerabilities called FLAX, which has found 11 pre-
viously unknown CSV bugs. Internally, FLAX simpli-
ﬁes JavaScript semantics to an intermediate language
that has a simple type system and a small number of
operations. This enables dynamic analyses employed
in FLAX to be implemented in a robust and scalable
way. Additionally, FLAX is designed to analyze ap-
plications with reﬂected ﬂows without the need for a
server analysis component.
3. FLAX employs taint enhanced blackbox fuzzing : a
hybrid, dynamic analysis approach which combines
the beneﬁts of dynamic taint analysis and random
fuzzing. This technique is light-weight as compared to
symbolic execution techniques, has no false positives
and is scalable enough to use on real-world applica-
tions.
2 Problem Deﬁnition
In this section, we outline our threat model, give exam-
ples of CSV vulnerabilities and conceptualize them as a
class, and deﬁne the problem of ﬁnding CSV vulnerabili-
ties.
2.1 Threat Model and Problem Deﬁnition
We deﬁne a CSV vulnerability as a programming bug
which results from using untrusted data in a critical sink
operation without sufﬁcient validation. A critical sink is a
point in the client-side code where data is used with spe-
cial privilege, such as in a code evaluation construct, or as
an application-speciﬁc command to a backend logic or as
cookie data.
In our analysis, any data which is controlled by an ex-
ternal web principal is treated as untrusted. Additionally,
user data (such as from form ﬁelds or text areas) is treated
as untrusted as well. Untrusted data could enter the client-
side code of a web application in three ways. First, data
from an untrusted web attacker could be reﬂected in the
honest web server’s HTML response and subsequently read
for processing by the client side code. Second, untrusted
data from other web sites could be injected via the browser’s
cross-window communication interfaces. These interfaces
include HTML 5’s postMessage, URL fragment identi-
ﬁers, and window/frame cross-domain properties. Finally,
user data fed in through form ﬁelds and text areas is also
marked as untrusted.
The ﬁrst two untrusted sources are concerned with the
threat model where the attacker is a remote entity that has
knowledge of a CSV vulnerability in an honest (but buggy)
web application. The attacker’s goal is to remotely ex-
ploit a CSV vulnerability to execute arbitrary code, to poi-
son cookie data (possibly inject session identiﬁers), or to
issue web application-speciﬁc commands on behalf of the
user. The attack typically only involves enticing the user
into clicking a link of the attacker’s choice (such as in a
reﬂected XSS attack).
We also consider the “user-as-an-attacker” threat model
where the user data is treated as untrusted. In general, user
data should not be interpreted as web application code. For
instance, if user can inject scripts into the application, such
a bug can be used in conjunction with other vulnerabilities
(such as a login-CSRF vulnerabilities) in which the victim
user is logged-in as the attacker while the application be-
havior is under attacker’s control [6]. In our view, FLAX
should make developers aware of the existence of errors in
this threat model, even though the severity of resulting ex-
ploits is usually limited and varies signiﬁcantly from appli-
cation to application.
This paper addresses the problem of ﬁnding CSV vulner-
abilities in the target web application by generating concrete
witness inputs. The problem of vulnerability discovery has
two orthogonal challenges — exploring the entire function-
ality of the program, and ﬁnding an input that exposes a
vulnerability in some explored functionality. In this paper,
we focus solely on the second challenge, assuming that our
analysis would be driven by an external test harness that
explores the large space of the application’s functionality.
Speciﬁcally, the input to our analysis is a web application
and an initial benign input. Our analysis aims to ﬁnd an ex-
ploit instance by systematically searching the equivalence
class of inputs that force the program execution down the
same path as the given benign input.
Running Example. For ease of explanation and concrete-
ness, we introduce a running example of a hypothetical
AJAX chat application. The example application consists
of two windows. The main window, shown in Figure 1,
asynchronously fetches chat messages from the backend
1: var chatURL = "http://www.example.com/";
2: chatURL += "chat_child.html";
3: var popup = window.open(chatURL);
4: ...
5: function sendChatData (msg) {
6:
7:
}
var StrData = "{\"username\": \"joe\", \"message\": \"" + msg + "\"}";
popup.postMessage(StrData, chatURL);
Figure 1. An example of a chat application’s JavaScript code for the main window, which fetches
messages from the backend server at http://example.com/
server. Another window receives these messages from the
main window and displays them, the code for which is
shown in Figure 2. The communication between the two
windows is layered on postMessage2, which is a string-
based message passing mechanism proposed for inclusion
in HTML 5. The application code in the display window
has two sources of untrusted data — the data received via
postMessage that could be sent by any browser win-
dow, and the event.origin property, which is the origin
(port, protocol and domain) of the sender.
2.2 Attacks resulting from CSV Vulnerabilities
structs (such as eval). This class of attacks is commonly
referred to as DOM-based XSS [27,29]. An example of this
attack is shown in Figure 2 on line 19. In the example, the
display child window uses eval to serialize the input string
from a JSON format, without validating for its expected
structure. Such attacks are prevalent today because popular
data exchange interfaces, such as JSON, were speciﬁcally
designed for use with the eval constructs. In Section 5,
we outline additional phishing attacks in iGoogle gadgets
layered on such XSS vulnerabilities, to illustrate that a wide
range of nefarious goals can be achieved once the applica-
tion integrity is compromised.
While some of the vulnerabilities described below have
been discussed in previous research literature by leveraging
other web vulnerabilities, in this section we show that they
can result from CSV vulnerabilities as well.
Origin Mis-attribution. Certain cross-domain commu-
nication primitives such as postMessage are designed
to facilitate sender authentication. Applications using
postMessage are responsible for validating the authen-
ticity of the domain sending the message. The example in
Figure 2 illustrates such an attack on line 13. The vulnera-
bility arises because the application checks the domain ﬁeld
of the origin parameter insufﬁciently, though the protocol
sub-ﬁeld is correctly validated. The failed check allows any
domain name containing “example”, including an attacker’s