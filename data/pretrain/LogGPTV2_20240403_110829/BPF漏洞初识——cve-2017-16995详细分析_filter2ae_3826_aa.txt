# BPF漏洞初识——cve-2017-16995详细分析
|
##### 译文声明
本文是翻译文章
译文仅供参考，具体内容表达以及含义原文为准。
>
> Linux内核为了执行效率，损失了很多安全性。但是在用户空间很难触发内核代码，所以给内核漏洞利用造成了很大的困难。但是BPF使得用户空间拥有了与内核通信和数据共享的能力，所以成为了内核漏洞的高发区。本文以CVE-2017-16995漏洞初步学习了BPF漏洞的利用技巧。若有错误，敬请各位师傅斧正。
## 基础知识
###  eBPF简介
`linux`的用户层和内核层是隔离的，如果想让内核空间执行用户的代码，正常流程是编写内核模块。但是内核模块的编写执行需要有`root`权限，这对于攻击者是不理想的。而
`BPF(Berkeley Packet
Filter)`则使普通用户拥有了让内核执行用户代码并共享数据的能力。用户可以将`eBPF`指令字节码传输给内核，然后通过`socket`写事件来触发内核执行代码。并且用户空间和内核空间会共享同一个`map`内存，且用户空间和内核空间都对其拥有读写能力。这就为攻击者提供了极大的便利。`BPF`发展经历了
2 个阶段，`cBPF(classic BPF)`和 `eBPF(extend
BPF)`，`cBPF`已退出历史舞台，所以后文的`BPF`都指`eBPF`。
###  eBPF虚拟指令系统
`eBPF`虚拟指令系统属于 `RISC`，拥有 10 个 虚拟寄存器， `r0-r10`在实际运行时，虚拟机会把这 10 个寄存器——对应于硬件
`CPU`的 10 个物理寄存器，以 `x64`为例，对应关系如下：
        R0 – rax
        R1 - rdi
        R2 - rsi
        R3 - rdx
        R4 - rcx
        R5 - r8
        R6 - rbx
        R7 - r13
        R8 - r14
        R9 - r15
        R10 – rbp（帧指针，frame pointer）
`eBPF`的指令格式如下：
    struct bpf_insn {
        __u8    code;       /* opcode */
        __u8    dst_reg:4;  /* dest register */
        __u8    src_reg:4;  /* source register */
        __s16   off;        /* signed offset */
        __s32   imm;        /* signed immediate constant */
    };
例如一条简单的`x86`指令`mov edi 0xffffffff`，其`eBPF`的指令结构如下：
    #define BPF_MOV32_IMM(DST, IMM)                 \
        ((struct bpf_insn) {                    \
            .code  = BPF_ALU | BPF_MOV | BPF_K,     \
            .dst_reg = DST,                 \
            .src_reg = 0,                   \
            .off   = 0,                 \
            .imm   = IMM })
所以，最后编写的格式如下`BPF_MOV32_IMM(BPF_REG_1,
0xFFFFFFFF)`，其字节码为：`\xb4\x09\x00\x00\xff\xff\xff\xff`。
###  BPF加载过程
一个 `BPF`的正常程序流程为：
  1. 用户程序调用 `syscall(__NR_bpf, BPF_MAP_CREATE, &attr, sizeof(attr))`申请创建一个 `map`，在 `attr`结构体中指定 `map`的类型、大小、最大容量等属性。之后调用 `sys_bpf`进而使用系统调用 `syscall(__NR_bpf, BPF_MAP_CREATE, attr, size);`创建一个 `map`数据结构，最终返回 `map`的文件描述符。这个文件是用户态和内核态共享的，因此后续内核态和用户态可以对这块共享内存进行读写： 
        //lib/bpf.c
    int bpf_create_map(enum bpf_map_type map_type, 
    int key_size,int value_size, int max_entries)
    {
     union bpf_attr attr;
     memset(&attr, '\0', sizeof(attr));
     attr.map_type = map_type;
     attr.key_size = key_size;
     attr.value_size = value_size;
     attr.max_entries = max_entries;
     return sys_bpf(BPF_MAP_CREATE, &attr, sizeof(attr));
    }
    //lib/bpf.c
    static int sys_bpf(enum bpf_cmd cmd, union bpf_attr *attr,
            unsigned int size)
    {
     return syscall(__NR_bpf, cmd, attr, size);
    }
    //bpf.h
    union bpf_attr {
     struct { /* anonymous struct used by BPF_MAP_CREATE command */
         __u32   map_type;   /* one of enum bpf_map_type */
         __u32   key_size;   /* size of key in bytes */
         __u32   value_size; /* size of value in bytes */
         __u32   max_entries;    /* max number of entries in a map */
     };
     struct { /* anonymous struct used by BPF_MAP_*_ELEM commands */
         __u32       map_fd;
         __aligned_u64   key;
         union {
             __aligned_u64 value;
             __aligned_u64 next_key;
         };
         __u64       flags;
     };
     struct { /* anonymous struct used by BPF_PROG_LOAD command */
         __u32       prog_type;  /* one of enum bpf_prog_type */
         __u32       insn_cnt;
         __aligned_u64   insns;
         __aligned_u64   license;
         __u32       log_level;  /* verbosity level of verifier */
         __u32       log_size;   /* size of user buffer */
         __aligned_u64   log_buf;    /* user supplied buffer */
         __u32       kern_version;   /* checked when prog_type=kprobe */
     };
     struct { /* anonymous struct used by BPF_OBJ_* commands */
         __aligned_u64   pathname;
         __u32       bpf_fd;
     };
    } __attribute__((aligned(8)));
    //bpf.h
    /* BPF syscall commands, see bpf(2) man-page for details. */
    enum bpf_cmd {
     BPF_MAP_CREATE,
     BPF_MAP_LOOKUP_ELEM,
     BPF_MAP_UPDATE_ELEM,
     BPF_MAP_DELETE_ELEM,
     BPF_MAP_GET_NEXT_KEY,
     BPF_PROG_LOAD,
     BPF_OBJ_PIN,
     BPF_OBJ_GET,
    };
  2. 用户程序调用 `syscall(__NR_bpf, BPF_PROG_LOAD, &attr, sizeof(attr))`来将我们写的 `BPF`代码加载进内核，`attr`结构体中包含了指令数量、指令首地址、日志级别等属性。在加载之前会利用虚拟执行的方式来做安全行校验，这个校验包括对指定语法的检查、指令数量的检查、指令中的指针和立即数的范围及读写权限检查，禁止将内核中的地址暴露给用户空间，禁止对 `BPF`程序 `stack`之外的内核地址读写。安全校验通过后，程序被成功加载至内核，后续真正执行时，不再重复做检查；
  3. 用户程序通过调用 `setsocopt(sockets[1], SOL_SOCKET, SO_ATTACH_BPF, &progfd, sizeof(progfd))`将我们写的 `BPF`程序绑定到指定的 `socket`上，`Progfd`为上一步骤的返回值；
  4. 用户程序通过操作上一步骤中的 `socket`来触发 `BPF`真正执行。
###  eBPF代码执行过程
对 `eBPF`指令的解释执行，最后会进入 `__bpf_prog_run`函数。可以看到这里是根据指令，对寄存器进行了相应的操作。如果后续要分析
`eBPF`指令的执行过程，就需要对这个函数进行深入分析。(此处代码经过省略)，可以看到 `__bpf_prog_run`函数自己使用栈模拟了一个
`ebpf`程序的栈和寄存器。所以，`ebpf`程序的指令是能够直接控制内核栈数据，为后续漏洞利用提供了方便。
    /**
     *    __bpf_prog_run - run eBPF program on a given context
     *    @ctx: is the data we are operating on
     *    @insn: is the array of eBPF instructions
     *
     * Decode and execute eBPF instructions.
     */
    static unsigned int __bpf_prog_run(void *ctx, const struct bpf_insn *insn)
    {
        u64 stack[MAX_BPF_STACK / sizeof(u64)];
        u64 regs[MAX_BPF_REG], tmp;
        static const void *jumptable[256] = {
            [0 ... 255] = &&default_label,
            /* Now overwrite non-defaults ... */
            /* 32 bit ALU operations */
            [BPF_ALU | BPF_ADD | BPF_X] = &&ALU_ADD_X,
            [BPF_ALU | BPF_ADD | BPF_K] = &&ALU_ADD_K,
            [BPF_ALU | BPF_SUB | BPF_X] = &&ALU_SUB_X,
            [BPF_ALU | BPF_SUB | BPF_K] = &&ALU_SUB_K,
            ...        //有省略
            [BPF_LD | BPF_ABS | BPF_B] = &&LD_ABS_B,
            [BPF_LD | BPF_IND | BPF_W] = &&LD_IND_W,
            [BPF_LD | BPF_IND | BPF_H] = &&LD_IND_H,
            [BPF_LD | BPF_IND | BPF_B] = &&LD_IND_B,
            [BPF_LD | BPF_IMM | BPF_DW] = &&LD_IMM_DW,
        };
        u32 tail_call_cnt = 0;
        void *ptr;
        int off;
    #define CONT     ({ insn++; goto select_insn; })
    #define CONT_JMP ({ insn++; goto select_insn; })
        FP = (u64) (unsigned long) &stack[ARRAY_SIZE(stack)];
        ARG1 = (u64) (unsigned long) ctx;
        /* Registers used in classic BPF programs need to be reset first. */
        regs[BPF_REG_A] = 0;
        regs[BPF_REG_X] = 0;
    select_insn:
        goto *jumptable[insn->code];
        /* ALU */
    #define ALU(OPCODE, OP)            \
        ALU64_##OPCODE##_X:        \
            DST = DST OP SRC;    \
            CONT;            \
        ALU_##OPCODE##_X:        \
            DST = (u32) DST OP (u32) SRC;    \
            CONT;            \
        ALU64_##OPCODE##_K:        \
            DST = DST OP IMM;        \
            CONT;            \
        ALU_##OPCODE##_K:        \
            DST = (u32) DST OP (u32) IMM;    \
            CONT;
        ALU(ADD,  +)
        ALU(SUB,  -)
        ALU(AND,  &)
        ALU(OR,   |)
        ALU(LSH, >)
        ALU(XOR,  ^)
        ALU(MUL,  *)
    #undef ALU
        ALU_NEG:
            DST = (u32) -DST;
            CONT;
        ALU64_NEG:
            DST = -DST;
            CONT;
        ALU_MOV_X:
            DST = (u32) SRC;
            CONT;
        ALU_MOV_K:
            DST = (u32) IMM;
            CONT;
        ALU64_MOV_X:
            DST = SRC;
            CONT;
        ALU64_MOV_K:
            DST = IMM;
            CONT;
        LD_IMM_DW:
            DST = (u64) (u32) insn[0].imm | ((u64) (u32) insn[1].imm) imm)(BPF_R1, BPF_R2, BPF_R3,
                                   BPF_R4, BPF_R5);
            CONT;
        JMP_TAIL_CALL: {
            struct bpf_map *map = (struct bpf_map *) (unsigned long) BPF_R2;
            struct bpf_array *array = container_of(map, struct bpf_array, map);
            struct bpf_prog *prog;
            u64 index = BPF_R3;
            if (unlikely(index >= array->map.max_entries))
                goto out;
            if (unlikely(tail_call_cnt > MAX_TAIL_CALL_CNT))
                goto out;
            tail_call_cnt++;
            prog = READ_ONCE(array->ptrs[index]);
            if (unlikely(!prog))
                goto out;
            /* ARG1 at this point is guaranteed to point to CTX from
             * the verifier side due to the fact that the tail call is
             * handeled like a helper, that is, bpf_tail_call_proto,
             * where arg1_type is ARG_PTR_TO_CTX.
             */
            insn = prog->insnsi;
            goto select_insn;
    out:
            CONT;
        }
        /* JMP */
        JMP_JA:
            insn += insn->off;
            CONT;
        JMP_JEQ_X:
            if (DST == SRC) {
                insn += insn->off;
                CONT_JMP;
            }
            CONT;
        JMP_JEQ_K:
            if (DST == IMM) {
                insn += insn->off;
                CONT_JMP;
            }
            CONT;
        JMP_JNE_X:
            if (DST != SRC) {
                insn += insn->off;
                CONT_JMP;
            }
            CONT;
        JMP_JNE_K:
            if (DST != IMM) {
                insn += insn->off;
                CONT_JMP;
            }
            CONT;
            ...
        /* STX and ST and LDX*/
    #define LDST(SIZEOP, SIZE)                        \
        STX_MEM_##SIZEOP:                        \
            *(SIZE *)(unsigned long) (DST + insn->off) = SRC;    \
            CONT;                            \
        ST_MEM_##SIZEOP:                        \
            *(SIZE *)(unsigned long) (DST + insn->off) = IMM;    \
            CONT;                            \
        LDX_MEM_##SIZEOP:                        \
            DST = *(SIZE *)(unsigned long) (SRC + insn->off);    \
            CONT;
        LDST(B,   u8)