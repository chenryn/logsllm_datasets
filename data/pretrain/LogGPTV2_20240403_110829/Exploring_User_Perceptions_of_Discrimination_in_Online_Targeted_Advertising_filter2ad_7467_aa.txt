# Exploring User Perceptions of Discrimination in Online Targeted Advertising

**Authors:**
- Angelisa C. Plane, University of Maryland
- Elissa M. Redmiles, University of Maryland
- Michelle L. Mazurek, University of Maryland
- Michael Carl Tschantz, International Computer Science Institute

**Publication:**
Proceedings of the 26th USENIX Security Symposium, August 16–18, 2017, Vancouver, BC, Canada
ISBN 978-1-931971-40-9
Open access to the Proceedings is sponsored by USENIX

## Abstract

Targeted online advertising now dominates the advertising market, surpassing both TV and print ads. While it can enhance users' online shopping experiences, it also has potential negative effects. Recent research has uncovered instances where targeted ads may be discriminatory, leading certain groups to see better offers (e.g., job ads) based on personal characteristics such as gender. To develop effective policies and guide advertisers in making ethical decisions, it is crucial to understand user concerns. In this study, we conducted a pilot study and a multi-step main survey (n=2,086 in total) presenting users with various discriminatory advertising scenarios. Our findings indicate that 44% of respondents were moderately or very concerned by the scenarios presented. Respondents found the scenarios more problematic when discrimination was based on explicit demographic targeting rather than online behavior. However, their opinions did not differ based on whether a human or an algorithm was responsible for the discrimination. These results suggest that future policy documents should explicitly address discrimination in targeted advertising, regardless of its origin, and that corporate responses blaming the algorithmic nature of the ad ecosystem may not alleviate public concerns.

## 1. Introduction

Online advertising revenue is projected to reach $83 billion in 2017, a $20 billion increase (40%) since 2015 [27, 36]. It now accounts for 37% of the media market share, surpassing TV and print advertising [2]. This growth is attributed to the increasing number of digital users and the ability to perform highly specific ad targeting. Targeted advertising, often driven by inferencing—using collected information about a user's digital habits to infer demographics and preferences [8]—offers several consumer benefits, such as seeing more relevant ads [19, 34, 40]. However, it also raises serious concerns, including threats to privacy and the potential for discrimination [5, 6, 13, 21, 28, 29, 32, 37, 47].

Privacy issues related to targeted advertising have been extensively studied by researchers, media, and government agencies [5, 9, 14, 16, 18, 19, 22, 33, 34, 40, 44]. More recently, algorithmic discrimination in targeted advertising has gained attention [5, 6, 13, 21, 28, 29, 32, 37, 47]. For example, Datta et al. found that Google showed high-paying job ads more frequently to men than women [13].

While general privacy threats from targeted advertising are well-documented [30, 33, 39, 40], little research has focused on users' attitudes toward discriminatory practices arising from inferencing and online behavioral advertising (OBA). Understanding these attitudes is critical, as instances of discrimination in targeted advertising raise complex legal and moral issues. Consumer preferences, while not the only factor, help us understand the current landscape. Companies can use this information to avoid egregious mistakes that lead to bad press and lawsuits [22, 44]. Advocates of algorithmic fairness can also use this knowledge to focus their public awareness efforts. Finally, policymakers can consider these attitudes when developing regulatory frameworks for this controversial ecosystem.

To gain insight into these attitudes, we conducted three surveys (two pilots and a main survey) comparing respondents' reactions to different discriminatory advertising scenarios. We varied factors such as the responsible entity, whether the decision was made by an algorithm or a human, and whether the targeting was based on explicit demographics or inferred behavior. We recruited a diverse sample of respondents from Amazon's Mechanical Turk (MTurk) and a web panel with quota sampling to match U.S. demographics. The two pilot surveys helped us refine our questions and develop a regression model, which we applied in the main survey.

In our main survey (n=891), 44% of respondents viewed the discriminatory advertising scenarios as a moderate or severe problem. The severity of the problem depended on how the discrimination occurred—whether based on explicit demographic targeting or inferred behavior—and who was discriminated against. Scenarios involving behavioral inference were rated as less problematic and more ethical than those based on explicit demographics. Surprisingly, whether a human or an algorithm made the targeting decision had no significant impact on perceptions of problem severity or ethics. Additionally, the entity responsible for the discrimination (e.g., the ad network or the advertiser) did not significantly affect perceptions. Based on these results, we provide implications for companies and policymakers and suggest future work to deepen our understanding of attitudes toward discrimination in targeted advertising.

## 2. Related Work

### 2.1 Discrimination in Online Targeting

The inner workings of the ad process are opaque, so most insights into behavioral advertising come from black-box observations. Researchers have developed tools to create profiles with specific attributes (e.g., age, gender) to scrape and compare ads seen by these profiles, providing insights into the frequency and attributes influencing targeting [6, 13, 28, 29, 32, 35, 47]. Mikians et al. found early evidence of price and search discrimination based on user characteristics [35]. Another study found that up to 65% of ads across tested categories were targeted based on behavioral or profile aspects, such as browsing patterns [32].

Some identified targeting can be considered discriminatory. Sweeney found that ads displayed during searches were more likely to associate stereotypically African American names with claims about arrest records [37]. Carrascosa et al. [10] found that health and religion were used in assigning advertisements, even though this is prohibited by E.U. law and may be prohibited by U.S. law for certain advertisements [42]. Datta et al. determined that ads promoting high-paying executive jobs were shown more frequently to simulated men than women [13].

### 2.2 Perceptions of Inferencing and Behavioral Advertising

Significant research has explored users' perceptions of targeted advertising, including their understanding of the process and their attitudes and opinions. Studies indicate that the process of targeted advertising is poorly understood. McDonald and Cranor found that people do not understand the mechanisms or frequency of tracking [34]. Ur et al. identified a mismatch between participants' mental models and actual OBA implementations [40]. Warshaw et al. found that high-school-educated adults did not understand or believe in strong behavioral inferencing, instead believing that targeting decisions were based on stereotypes or straightforward intuitions [45].

Reactions to behavioral advertising are mixed, with some appreciation of potential benefits but also concern for potential harms. Ur et al. found that people informed about OBA expressed interest in receiving more relevant ads but also had strong concerns about data collection and privacy [40]. Similarly, Agarwal et al. found that people were interested in relevant ads but were concerned about personal or intimate advertisements, especially when others might see them [3]. Turow et al. found that many users accept benefits like discounts or relevant ads as consolation for unavoidable tracking [39].

In a lab experiment, Malheiros et al. concluded that more personalized ads were more noticeable, but users became less comfortable as the degree of personalization increased [33]. Coen et al. found that people were less concerned about inferencing when they believed the results were accurate [11]. Tschantz et al. found no statistically significant associations between profile accuracy and people's concern about tracking or confidence in avoiding it [38].

## 3. Overview of Studies

To examine people's perceptions of discriminatory advertising, we first conducted an exploratory pilot study (Pilot 1, Section 4) to identify a smaller set of relevant constructs and relationships. In our main study, we used a two-step regression analysis. We conducted a second pilot study (Pilot 2, Section 5.2) to collect training data, performed an exploratory regression analysis, and distilled a set of parsimonious models to evaluate. Finally, we collected a larger dataset to validate these models and generate our final results (Section 5.3).

The survey structure was similar in both Pilot 1 and the final survey. Participants were given a scenario about discrimination in targeted advertising, along with a brief explanation of how the discrimination occurred. The scenario involved a fictional technology company, Systemy, placing a job ad using the fictional ad network Bezo Media. The job ad, appearing on a local newspaper's website, was shown more frequently to people in some target group than to others. This scenario was loosely based on real-life findings from Datta et al. [13].

Explanations included information about how the decision to target a specific group was made: whether an algorithm or a human made the decision, which company in the scenario made the decision, and what behavioral or demographic cues led to the targeting decision.

Participants then answered Likert-scale questions about the responsibility of various entities (e.g., the advertiser, the ad network) for the discrimination, whether each entity acted ethically, and whether the overall situation constituted a problem. We asked the responsibility questions before the question about the problem's severity to avoid priming the responsibility answers. We also asked participants how believable they found the scenario and provided an option for free-text feedback. Finally, we collected standard demographic information, including age, gender, education level, and ethnicity. The full set of questions is shown in Appendix A. All surveys were deployed using the Qualtrics web survey tool.

All three studies were approved by the University of Maryland’s Institutional Review Board (IRB).

## 4. Pilot 1: Evaluating a Broad Range of Discriminatory Factors

We designed the first pilot study to explore a broad range of factors that might be important to respondents' perceptions of discrimination in targeted online advertising.

### 4.1 Scenarios

As described in Section 3, respondents were presented with a scenario describing an online targeted advertising situation that resulted in discrimination. They were then asked questions about their opinion of the scenario. Respondents in Pilot 1 were randomly assigned to one of 72 total scenarios, varying along two axes: the target of the discriminatory ads and the explanation for how the targeting came about. The eight explanations were drawn from suggested explanations posited by the authors of an ad-discrimination measurement study [12], intended to span a range of plausibility and discriminatory intent. A ninth condition, with no explanation provided, served as a control. The targets and explanations used in Pilot 1 are listed in Table 1.

Because we used racial, political, and health characteristics in the target sets, we included questions about race/ethnicity, political affiliation, and health status in the demographic portion of the survey.

### 4.2 Cognitive Interviews

We anticipated that the explanations of discriminatory targeting provided in our scenarios might be complex and unfamiliar to our respondents. Therefore, we pre-tested the wording of our explanations and subsequent questions using cognitive interviews, a standard technique for evaluating the intelligibility and effectiveness of survey questions [46]. We conducted eight in-person cognitive interviews with respondents from a variety of demographic groups (Table 2). As a result of these interviews, we made the scenario descriptions more narrative, clarified the wording of some questions, and added the question about believability.

### 4.3 Respondents

The targets and explanations in this pilot study were designed to cover a broad range of possible topics, helping us identify the most salient and relevant issues to explore further. To ensure a broad sample, we contracted Survey Sampling International (SSI) to obtain a near-census-representative sample.

In August and September 2016, 988 respondents completed our Qualtrics questionnaire, which took on average four to five minutes. Respondents were compensated according to their individual agreements with SSI, which could include a donation to a charity, frequent flyer miles, a gift card, or other options. We paid SSI $3.00 per completion. The demographic makeup of the respondents was close to the U.S. population, with slightly more educated individuals (Table 3). Between 15 and 16 respondents were assigned to each of the 72 scenarios.

### 4.4 Results

We examined the results using exploratory statistics and data visualizations to identify the most interesting themes.

| Metric | Male | Female | Caucasian | Hispanic | Asian | African American | Other |
|--------|------|--------|-----------|----------|-------|------------------|-------|
| SSI Census | 48.2% | 51.8% | 64.0% | 16.0% | 5.4% | 12.0% | - |

---

This revised version aims to make the text more coherent, clear, and professional, while maintaining the original content and structure.