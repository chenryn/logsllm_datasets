title:Exploring User Perceptions of Discrimination in Online Targeted Advertising
author:Angelisa C. Plane and
Elissa M. Redmiles and
Michelle L. Mazurek and
Michael Carl Tschantz
Exploring User Perceptions of Discrimination  
in Online Targeted Advertising
Angelisa C. Plane, Elissa M. Redmiles, and Michelle L. Mazurek, University of Maryland; 
Michael Carl Tschantz, International Computer Science Institute
https://www.usenix.org/conference/usenixsecurity17/technical-sessions/presentation/plane
This paper is included in the Proceedings of the 26th USENIX Security SymposiumAugust 16–18, 2017 • Vancouver, BC, CanadaISBN 978-1-931971-40-9Open access to the Proceedings of the 26th USENIX Security Symposium is sponsored by USENIXExploring User Perceptions of Discrimination
in Online Targeted Advertising
Angelisa C. Plane
University of Maryland
Michelle L. Mazurek
University of Maryland
Elissa M. Redmiles
University of Maryland
Michael Carl Tschantz
International Computer Science Institute
Abstract
Targeted online advertising now accounts for the largest
share of the advertising market, beating out both TV and
print ads. While targeted advertising can improve users’
online shopping experiences, it can also have negative
eﬀects. A plethora of recent work has found evidence that
in some cases, ads may be discriminatory, leading certain
groups of users to see better oﬀers (e.g., job ads) based
on personal characteristics such as gender. To develop
policies around advertising and guide advertisers in mak-
ing ethical decisions, one thing we must better understand
is what concerns users and why. In an eﬀort to answer
this question, we conducted a pilot study and a multi-step
main survey (n=2,086 in total) presenting users with dif-
ferent discriminatory advertising scenarios. We ﬁnd that
overall, 44% of respondents were moderately or very con-
cerned by the scenarios we presented. Respondents found
the scenarios signiﬁcantly more problematic when dis-
crimination took place as a result of explicit demographic
targeting rather than in response to online behavior. How-
ever, our respondents’ opinions did not vary based on
whether a human or an algorithm was responsible for the
discrimination. These ﬁndings suggest that future pol-
icy documents should explicitly address discrimination in
targeted advertising, no matter its origin, as a signiﬁcant
user concern, and that corporate responses that blame the
algorithmic nature of the ad ecosystem may not be helpful
for addressing public concerns.
1
Introduction
Online advertising revenue is projected to reach $83 bil-
lion in 2017, an increase of $20 billion and 40% since
2015 [27, 36]. It has surpassed T.V. and print advertis-
ing, accounting for 37% of the media market share [2].
The growth of online advertising can be attributed both to
growth in digital users and the ability to do unprecedent-
edly speciﬁc targeting of ads: individually customizing
advertisements to users. Targeted advertising is often
driven by inferencing: the process of using collected in-
formation about a user’s digital habits to infer beliefs
about her demographics and preferences [8]. Targeted
advertising—also known as online behavioral advertising,
or OBA—has a number of consumer beneﬁts (e.g., seeing
more interesting or relevant ads) [19, 34, 40] but it has
also raised serious concerns [5,6,13,21,28,29,32,37,47],
including threats to consumer privacy and the potential
for discrimination.
Consumer privacy issues related to targeted advertising
have received considerable attention from researchers,
media, and government agencies for several years [5, 9,
14, 16, 18, 19, 22, 33, 34, 40, 44]. More recently, the issue
of algorithmic discrimination in targeted advertising has
begun to attract similar attention [5, 6, 13, 21, 28, 29, 32,
37, 47]. In one example, Datta et al. found that Google
showed ads promoting certain high-paying jobs more
frequently to men than women [13].
Consumer opinions about general privacy threats from
targeted advertising have been fairly well documented [30,
33, 39, 40]. Recent work has also begun to examine how
well users understand the process of inferencing [45]
and how inference accuracy aﬀects attitudes and percep-
tions [11, 38]. To the best of our knowledge, however,
little to no investigation has focused on people’s attitudes
toward discriminatory practices that arise, possibly unin-
tentionally, from inferencing and OBA.
We argue that better understanding of such attitudes
is critical, because the instances of discrimination in tar-
geted advertising touch on complicated legal and moral
issues. While consumer preferences are far from the only
important factor to consider, they do help us to under-
stand the current landscape. Companies might use in-
formation about consumer attitudes to avoid particularly
egregious mistakes that can lead to bad press and even
lawsuits [22, 44]. Knowledge of people’s attitudes can
also aid advocates of algorithmic fairness in understand-
ing how to focus their public awareness eﬀorts. Finally,
USENIX Association
26th USENIX Security Symposium    935
data about consumer attitudes may prove valuable to pol-
icymakers, who can take these attitudes—and resulting
corporate incentives—into account (as two of many im-
portant factors) when developing a regulatory framework
for this increasingly controversial ecosystem.
As a ﬁrst step toward achieving this understanding, we
conducted three surveys (two smaller pilots and then a
main survey) comparing respondents’ attitudes to diﬀer-
ent discriminatory advertising scenarios, with the aim of
understanding which speciﬁc scenarios people ﬁnd most
problematic and why. In particular, we varied factors
such as which player in the ecosystem was responsible,
whether targeting decisions were made by an algorithm or
a human, and whether the targeting was based explicitly
on demographic factors or arose from behavioral factors.
To ensure we encountered a range of attitudes, we re-
cruited a broad array of respondents, both from Amazon’s
Mechanical Turk crowdsourcing site (MTurk) and from a
web panel with quota sampling to closely match the de-
mographics of the U.S. population. We used the two pilot
surveys to develop a ﬁnal set of questions and a candidate
regression model, which we applied in our main survey.
In our main survey (n=891), a large portion (44%) of
respondents viewed our scenarios of discrimination in
targeted advertising as a moderate or severe problem. The
severity of the problem, however, depended primarily
on how the discrimination occurred—based on explicit
targeting of demographic factors or behavioral inferenc-
ing—and who was discriminated against. Respondents
tended to rate scenarios in which diﬀerences in behavioral
patterns led to discriminatory eﬀects as less problematic
and more ethical than scenarios in which discrimination
was explicitly based on demographics. To our surprise,
however, whether a human or an algorithm made the tar-
geting decision had no statistically signiﬁcant impact on
perceptions of problem severity or ethics. Responses on
severity also did not appear to diﬀer based on the entity
responsible for the discrimination (e.g., the ad network or
the advertiser), and many participants held both entities
responsible, regardless of which was explicitly named
as the perpetrator. Based on these results, we suggest
implications for companies and policymakers and suggest
future work to deepen understanding of attitudes toward
discrimination in targeted advertising.
2 Related Work
We review related work in two key areas: empirically
observed discrimination in online targeted advertising
and end-user perceptions of inferencing and behavioral
advertising.
2.1 Discrimination in Online Targeting
Since the inner workings of the ad process are opaque,
most knowledge of behavioral advertising has been de-
rived through black-box observation.
Researchers have designed tools that create proﬁles
with speciﬁc attributes (e.g., age, gender) to scrape
ads seen with this proﬁle and compare to other pro-
ﬁles’ ads, providing insight into how often targeted
ads are displayed and which attributes inﬂuence target-
ing [6, 13, 28, 29, 32, 35, 47]. Mikians et al. found early
evidence of price and search discrimination based on user
characteristics [35]. In another measurement, up to 65%
of the ads seen across the ad categories tested were tar-
geted based on some behavioral or proﬁle aspect, such as
browsing patterns [32].
Some of the identiﬁed targeting can be considered dis-
criminatory. In one of the earliest examples, Sweeney
found that ads displayed during search were more likely
to associate stereotypically African American names than
stereotypically white names with claims about arrest
records [37]. Carrascosa et al. [10] found that health
and religion were used in assigning advertisements to
consumers, even though this is prohibited by E.U. law
and may be prohibited by U.S. law for certain advertise-
ments [42]. Finally, using the AdFisher tool, Datta et al.
determined that ads promoting the seeking of high-paying
executive jobs were shown signiﬁcantly more often to
simulated men than women [13].
2.2 Perceptions of Inferencing and Behav-
ioral Advertising
Signiﬁcant research has explored users’ perceptions of
targeted advertising, including both their understanding
of the process and their attitudes and opinions.
There are strong indications that the process of tar-
geted advertising is poorly understood. McDonald and
Cranor found in surveys and interviews that people did
not understanding the mechanisms or frequency of track-
ing [34]. Ur et al. identiﬁed a mismatch between par-
ticipants’ mental models and actual OBA implementa-
tions [40]. Warshaw et al. interviewed high-school-only-
educated adults and found that they did not understand
or believe in strong behavioral inferencing; instead, par-
ticipants believed that targeting decisions were based on
stereotypes or on straightforward intuitions [45].
Reaction to behavioral advertising has been mixed,
with some appreciation of potential beneﬁts but also con-
cern for potential harms. Ur et al. found that people
informed about online behavioral advertising express in-
terest in receiving more-relevant ads, but also strong con-
cerns about data collection and privacy [40]. Similarly,
Agarwal et al. found that people expressed interest in rel-
936    26th USENIX Security Symposium
USENIX Association
evant ads but were concerned about personal or intimate
advertisements being shown, particularly when other peo-
ple might also see them [3]. Turow et al. found that many
users are resigned to privacy violations, and therefore ac-
cept beneﬁts such as discounts or relevant ads as some
consolation for unavoidable tracking [39].
In a lab experiment, Malheiros et al. concluded that
when ads were more personalized to the user they were
more noticeable, but that the users also became less com-
fortable as the degree of personalization increased [33].
More recently, Coen et al. found that people were less con-
cerned about inferencing when they believed the results
were accurate [11]. Tschantz et al. found no statistically
signiﬁcant associations between proﬁle accuracy and peo-
ple’s concern about tracking or conﬁdence in avoiding
it [38].
3 Overview of Studies
To examine peoples’ perceptions of discriminatory ad-
vertising, we ﬁrst performed an exploratory pilot study,
Pilot 1 (Section 4), which looked broadly at a wide va-
riety of possible discrimination situations, with the goal
of identifying a smaller set of relevant constructs and re-
lationships to further examine. In our main study, we
used the resulting smaller set of questions in a two-step
regression analysis. First, we conducted a second pilot
study, Pilot 2 (Section 5.2), in order to collect training
data. Using this data, we conducted an exploratory regres-
sion analysis and distilled a set of parsimonious models
to evaluate. Finally, we collected a ﬁnal larger data set
to validate these models and generate our ﬁnal results
(Section 5.3).
The structure of the survey questions was similar in
both Pilot 1 and the ﬁnal survey. In each case, the partici-
pant was given a scenario about discrimination in targeted
advertising, together with a brief explanation of how the
discrimination occurred. In each case, the scenario con-
sisted of a ﬁctional technology company, Systemy, plac-
ing a job ad using the ﬁctional ad network Bezo Media.
The job ad, which in the scenario appeared on a local
newspaper’s website, was shown more frequently to peo-
ple in some target group than to people in other groups.
This scenario was loosely based on real-life ﬁndings from
Datta et al. about discriminatory ads [13].
Explanations included information about how the de-
cision to target a speciﬁc group was made: whether an
algorithm or a human made the decision, which company
in the scenario made the decision, and what behavioral or
demographic cues led to the targeting decision.
The participant then answered Likert-scale questions
about how responsible various entities (e.g., the advertiser,
the ad network) were for the discrimination, whether each
entity had acted ethically, and whether the overall situ-
ation constituted a problem. We deliberately asked the
responsibility questions before the question about how
problematic the scenario was, to avoid priming the re-
sponsibility answers with an assumption that the scenario
was problematic. In addition, we asked the participant
how believable they found the scenario they had read.
We then asked respondents to optionally provide free-text
feedback on the scenario. Finally, we collected standard
demographic information, including age, gender, edu-
cation level, and ethnicity. The full set of questions is
shown in Appendix A. All surveys were deployed using
the Qualtrics web survey tool.
All three studies were approved by the University of
Maryland’s Institutional Review Board (IRB).
4 Pilot 1: Evaluating a Broad Range of Dis-
criminatory Factors
We designed the ﬁrst pilot study to explore a broad range
of factors that might prove important to respondents’ per-
ceptions of discrimination in targeted online advertising.
4.1 Scenarios
As described in Section 3, in our survey respondents were
presented with a scenario describing an online targeted
advertising situation that resulted in discrimination. They
were then asked questions about their opinion of the sce-
nario. Respondents in Pilot 1 were assigned randomly
to one of 72 total scenarios. The scenarios varied along
two axes. The ﬁrst was the target of the discriminatory
ads, that is, one of eight groups of people who saw the
job ad more frequently. The second was the explanation
for how the targeting came about. We drew the eight
explanations we considered in part from suggested ex-
planations posited by the authors of an ad-discrimination
measurement study [12] with the intent to span a range of
both real-life plausibility and discriminatory intent. We
also used a ninth condition, in which no explanation was
provided, as a control. The targets and explanations used
in Pilot 1 are listed in Table 1.
Because we used racial, political, and health charac-
teristics in the target sets, we included questions about
race/ethnicity, political aﬃliation, and health status in the
demographic portion of the survey.
4.2 Cognitive Interviews
We anticipated that the explanations of discriminatory
targeting provided in our scenarios might be complex and
unfamiliar to our respondents. As such, we carefully pre-
tested the wording of our explanations and subsequent
questions using cognitive interviews, a standard technique
USENIX Association
26th USENIX Security Symposium    937
Targets:
Explanations:
• Are/be over 30 years old
• Are/be a registered Democrat
• Are/be white
• Have a pre-existing health condition
• Are/be under 30 years old
• Are/be a registered Republican
• Are/be Asian
• Have no pre-existing health condition
• No explanation given (control).
• An HR employee at Systemy chooses to target individuals who [target].
• An employee at Bezo Media chooses to target individuals who [target].
• An advertising sales employee at the local news site chooses to target Systemy’s ads to individuals who [target].
• An HR employee at Systemy chooses to advertise on the local news site speciﬁcally because its readers are known to mostly
[target].
• Individuals who [target] tend to click on diﬀerent ads than [opposite of target]. Bezo Media’s automated system has observed
this diﬀerence and automatically assigns the Systemy ads to individuals who [target].
• Systemy requests that this ad be shown to viewers who have recently visited technology-interest websites. People who [target]
tend to visit more technology-interest websites than individuals [opposite of target].
• Bezo Media charges less to reach individuals who [target] than individuals who [opposite of target], and a Systemy marketing
employee chooses the less expensive option.
• Bezo Media charges less to reach individuals who [target] than individuals who [opposite of target], and Systemy’s marketing
computer program automatically selects the less expensive option.
Table 1: Scenarios for Pilot 1. Each respondent viewed one explanation, with one targeted group ﬁlled in as receiving
more of the targeted ads.
Education
High School
Race
Black
Black
Gender Age
Female
Female
Male
Female
Female
Female
Male
Male
52 yrs
34 yrs White M.S.
22 yrs
B.S.
22 yrs White B.S.
20 yrs
39 yrs
31 yrs
44 yrs White B.S.
Black
Black
Black
Some College
High School
High School
Table 2: Cognitive Interview Demographics
for evaluating the intelligibility and eﬀectiveness of sur-
vey questions by asking respondents to think aloud while
answering the survey questions [46]. We conducted eight
in-person cognitive interviews with respondents from a
variety of demographic groups (Table 2). As a result of
these interviews, we made the scenario descriptions more
narrative, clariﬁed the wording of some questions, and
added the question about believability.
4.3 Respondents
The targets and explanations in this pilot study were delib-
erately designed to cover a broad range of possible topics,
to help us identify the most salient and relevant issues to
explore further. As such, we wanted to ensure that we
sampled from a broad range of respondents, so that is-
sues important to diﬀerent demographic groups would be
potentially salient in our results. This goal seemed partic-
ularly critical in light of prior work suggesting that people
with less educational attainment have important miscon-
ceptions about targeted advertising [45]. To achieve these
broad demographics, we contracted Survey Sampling In-
ternational (SSI) to obtain a near-census-representative
sample.
In August and September of 2016, 988 respondents
completed our Qualtrics questionnaire, which took on
average four to ﬁve minutes. Respondents were paid
according to their individual agreements with SSI; this
compensation could include a donation to a charity of
their choosing, frequent ﬂier miles, a gift card, or a variety
of other options. We paid SSI $3.00 per completion. The
demographic makeup of the respondents was close to the
U.S. population as seen in table 3, with slightly more
educated individuals. Between 15 and 16 respondents
were assigned to each of the 72 scenarios.
4.4 Results
We examined the results using exploratory statistics and
data visualizations to identify themes of most interest.
938    26th USENIX Security Symposium
USENIX Association
Metric
Male
Female
Caucasian
Hispanic
Asian
African American
Other
up to H.S.
Some college
B.S. or above
18–29 years
30–49 years
50–64 years
65+ years
SSI Census
48.2%
51.8%
64.0%
16.0%
5.4%
12.0%