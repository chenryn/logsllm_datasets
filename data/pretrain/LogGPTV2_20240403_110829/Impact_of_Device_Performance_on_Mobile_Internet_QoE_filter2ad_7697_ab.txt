from when the request was issued to when the application starts dis-
playing frames. The stall ratio is the amount of time the video stalls
during the playback expressed as a fraction of playback time. Both
of these metrics can be measured using YouTube player APIs [3].
The performance is measured over a 5 min FullHD (1080p) video
clip. Note that the received video quality is the same in all the exper-
iments because we have high network bandwidth. We use ADB [2]
to programmatically request the video content for repeatability.
IntexAmaze+GioneeF103GoogleNexus4GalaxyS2GooglePixelCGalaxyS6-EdgeGooglePixel20.02.55.07.510.012.5PLT(Seconds)IntexAmaze+GioneeF103GoogleNexus4GalaxyS2GooglePixelCGalaxyS6-EdgeGooglePixel20246Start-upLatency(Seconds)0.00.20.40.60.81.0StallRatioStart-upLatencyStallRatioIntexAmaze+GioneeF103GoogleNexus4GalaxyS2GooglePixelCGalaxyS6-EdgeGooglePixel2010203040FrameRateImpact of Device Performance on Mobile Internet QoE
IMC ’18, October 31-November 2, 2018, Boston, MA, USA
(a) Clock Frequency
(b) Memory
(c) Number of Cores
(d) Governors
Figure 3: Impact of device parameters on Web browsing (Google Chrome)
Video Telephony: We use Skype to measure the performance
of video telephony. We measure QoE in terms of call setup delay
(network-centric) and frame rate (device-centric) metrics. The frame
rate is measured as the number of frames shown per second and
call setup delay is the time it takes for the client to get the response
once the receiver answers the call. Because Skype does not provide
APIs to extract such QoE information, we use an indirect approach.
We configure Skype to display the frame rate and call setup delay
on the screen during the video call. Similar to [9], we screen-record
the Skype call using the AZ screen recorder [28] and extract the
QoE information using an optical character recognition tool [33].
Because Skype is an interactive application, it requires an active
participant on both ends. In our setup, when the Skype call is
placed from the mobile device to a laptop, the laptop runs a virtual
webcam [21] that plays a video file in Skype instead of the camera
feed; at the mobile end, the video can be viewed during the Skype
call. To automate (starting and ending) the Skype calls, we use the
AndroidViewClient (AVC) library [5].
Network Setup: Because the focus of this work is to measure
the impact of the device hardware, the experiments are setup to
minimize the impact of the network and the Web/video servers. We
host the video and pages on a desktop on our LAN created using an
Aruba Access Point (AP) with a 72 Mbps link speed, 10 ms RTT, and
0% loss. The mobile device connects to the server over our LAN.
For each workload, we repeat the experiment 20 times and present
the average and standard deviation. For each experiment, we use
default values for non-treatment variables.
2.2 QoE Across Devices
Fig. 2 shows the performance of the three applications across the
devices. Based on the device model, a significant difference in per-
formance exists even though all experiments are done in the same
network conditions.
For Web page loads (Fig. 2a), there is a 7 sec difference in average
PLT between the low-end Intex Amaze+ phone and the high-end
Google Pixel2. The standard deviation in PLT is also higher (>3 sec-
onds) in the Intex Amaze+ than in the Pixel2. This must stem from
the device itself because the network conditions remain unchanged.
In the case of YouTube (Fig. 2b), a linear increase occurs in start-
up latency from 2 to 5 seconds from the high-end to low-end devices.
However, after the start-up latency, there is zero impact on the stall
ratio. In effect, when the user waits for the video to start, there
is practically no difference in QoE between the low-end and the
high-end device. For Skype (Fig. 2c), the frame rate decreases from
30fps to 18fps between the high- and low-end devices.
For the most part, application QoE correlates with device cost.
A cheaper device provides poorer performance. The only outlier is
the Pixel2, which outperforms the SG S6-edge despite being less
expensive. The underlying reason for this difference is how these
two phones use big and little cores in the big.LITTLE architecture
to trade between performance and power consumption.
Based on this study, our goal is to (i) understand why video
applications are not affected by low-end phones and transfer the
lessons learned to the Web, and (ii) study which hardware compo-
nent has the greatest effect on performance both for Web and video
applications to inform future hardware design.
3 IMPACT OF DEVICE PARAMETERS
Four device parameters related to available resources (Table 1) can
potentially impact application performance – CPU clock, mem-
ory capacity, number of cores, and Android governor. The first
three parameters are self-explanatory. The Android governor is
a set of scaling algorithms used by Android to change the clock
frequency based on the CPU utilization and battery life. We observe
four common frequency governors used by most Android phones:
the Ondemand (OD), Powersave (PW), Interactive (IN), and Per-
formance (PF) governors, each with a different trade-off between
power and performance [12].
Experimental Setup: The effect of a given resource is isolated
by changing its value while keeping the remaining setup constant.
We change the clock, number of cores, and governors using ADB
commands on a rooted phone. We change the memory capacity
by creating RAM disks [19] from available memory and assigning
these RAM disks to the application. The experiments are repeated
over three phones—the Pixel2, Intex Amaze+, and Nexus4. These
three phones were chosen to represent a high-end, low-end, and
medium-end phone. We present the results from Nexus4 in detail
and summarize the results from the other two for brevity. Similarly,
for brevity, we present the PLT results only for the Chrome browser.
We have experimented with two other browsers (Firefox and Opera
Mini), which qualitatively have the same experience.
Figures 3-5 show the impact of these parameters – CPU clock,
memory, number of cores, and governors on Google Chrome, YouTube,
and Skype. The experimental setup is the same as that of §2.1.
3.1 QoE of Web Browsing
The PLT increases by 4× when the CPU clock frequency drops
from 1512 MHz to 384 MHz (Fig. 3a). This trend is similar to that
of Fig. 2a, where the page loads much slower on low-end devices
than on higher-end devices. This performance degradation is due
384486594702810918102611341242135014581512ClockFrequency(MHz)0510152025PLT(Seconds)0.511.52Memory(GB)0246810PLT(Seconds)1234NumberofCores0246810PLT(Seconds)PFINUSODPWGovernors0246810PLT(Seconds)IMC ’18, October 31-November 2, 2018, Boston, MA, USA
M. Dasari et al.
(a) Clock Frequency
(b) Memory
(c) Number of Cores
(d) Governors
Figure 4: Impact of device parameters on video streaming (YouTube)
to two reasons: a slower clock results in (1) slower page processing
(e.g., parsing, scripting, rendering, and painting) and (2) slower
packet processing (§4.2) that in turn slows down the downloading
of objects.
We estimate the time on the critical path involving computation
and network activities using the WProf tool [23, 36]. Network time
on the critical path increases from an average of 2 seconds when
the clock speed is 1512 MHz to 6 seconds when the clock speed is
decreased to 384 MHz – a 66% increase. Compute time increases by
76% for the same CPU slowdown.
We find that compute time increases even more compared to the
network time for more complex Web pages. We further dissect the
computational activities to find the root cause of the application
bottlenecks. We observe that scripting time increases the most as the
CPU clock slows down; it accounts for 51% of the overall compute
times at high CPU frequencies and 60% at slower CPU frequencies.
The layout and painting times account for only 4% of the compute
time on the critical path. To confirm the impact of slower Javascript
execution, we experiment with different categories of Web pages
(e.g., business, health, shopping, news, and sports) and find that
news and sports Web pages are affected the most (about 6×) because
they have more scripting than the other categories.
Apart from the clock frequency, the PLT is not affected by other
parameters significantly. For example, the PLT increases by about
2× when memory is reduced from 2GB to 512MB. The PLT increases
by roughly 50% when the Powersave governor is used relative to
the others. This is because this governor prefers the slowest clock
to trade off performance for power savings.
PLT changes only modestly when the number of cores is reduced
from four to one. This is because the browser does not exploit the
thread-level parallelism on multi-core mobile devices. We confirm
this observation by measuring the CPU utilization across cores and
find that, during Web page loads, only two of the cores are utilized
irrespective of the number of cores available (see Fig. 3c).
Takeaway1: Web browsing underutilizes the multiple cores and
suffers significantly with slower CPU clock. A key component of
improving Web page loads, especially with a slow CPU clock, is to
improve the efficiency of scripting.
3.2 QoE of Video Streaming
Fig. 4 shows the start-up latency (network-centric) and stall ratio
(device-centric) metrics of YouTube for the four device parameters
on Nexus 4. The start-up latency increases from 1.2 to 3.5 seconds
as the clock speed decreases; however, there is no impact on the
stall ratio. This trend is similar to the one observed in Fig. 2b across
low-end and high-end phones.
In practice, the stall ratio is a more important QoE metric be-
cause the start-up latency is only a one-time effect. The stall ratio is
not affected by a slow CPU even though network throughput drops
when the CPU is slow. The reasons for this are several video-specific
optimizations: i) most smartphones (even low-end phones) support
hardware-based video coding. The video coding is offloaded to ded-
icated hardware accelerators and are not bottlenecked by a slow
CPU. Moreover, YouTube serves device-specific video content (e.g.,
it does not stream FullHD video on an Intex phone). ii) after video
decoding, the post-processing tasks such as muxing and demux-
ing of audio and video indeed happen on the CPU, which could
potentially be impacted by a slower clock. The Android multime-
dia framework is highly parallelized and exploits multiple cores,
unlike Web browsing, and thus, the impact of the slower clock is
not prominent. We confirm this observation by measuring the CPU
utilization during the video experiments across cores. Figure 4c
further shows that the performance of video applications degrades
as the number of cores decreases. There is an increase of 4 seconds
in start-up latency as well as a 15% increase in the stall ratio under
a single core. iii) YouTube and other streaming services [10, 24]
prefetch video content; YouTube prefetches 120 seconds’ (called
read-ahead time) worth of content. Therefore, even under slower
clocks, the read-ahead time is reached within 40 seconds of the
video start-up, resulting in zero stalls.
For memory and governors, YouTube has a similar trend in start-
up latency as Web browsing does, with zero stalls.
Takeaway2: Specialized coprocessors reduce the role of the general-
purpose CPU for video streaming. To the extent that the CPU is used,
multiple cores can be exploited. Thus, the impact of low-end phones
is largely masked for the QoE of video streaming because even low-
end phones have at least two cores and specialized coprocessors.
3.3 QoE of Video Telephony
The key difference between streaming and telephony is that tele-
phony is interactive. This means that, unlike streaming, video
frames cannot be prefetched by the application. We measure the
QoE with the call setup delay (network-centric) and frame rate
(device-centric) metrics as described in §2.1. Fig. 5 shows the effect
of device parameters on QoE during the Skype video call.
We observe an 18-second increase in call setup delay when the
CPU clock drops from 1512 MHz to 384 MHz. This effect is due
to the increase in network packet processing caused by slow CPU
speeds because the external network condition remains the same.
The frame rate drops to 17 frames per second (fps) at slow CPU
speeds from 30 fps at high CPU speeds. The decreased frame rate
occurs despite the fact that video coding is offloaded to hardware
384486594702810918102611341242135014581512ClockFrequency(MHz)0246810Start-upLatency(Seconds)0.00.20.40.60.81.0StallRatioStart-upLatencyStallRatio0.511.52Memory(GB)0246810Start-upLatency(Seconds)0.00.20.40.60.81.0StallRatioStart-upLatencyStallRatio1234NumberofCores0246810Start-upLatency(Seconds)0.00.20.40.60.81.0StallRatioStart-upLatencyStallRatioPFINUSODPWGovernors0246810Start-upLatency(Seconds)0.00.20.40.60.81.0StallRatioStart-upLatencyStallRatioImpact of Device Performance on Mobile Internet QoE
IMC ’18, October 31-November 2, 2018, Boston, MA, USA
(a) Clock Frequency
(b) Memory
(c) Number of Cores
(d) Governors
Figure 5: Impact of device parameters on video telephony (Skype)
and specialized NIC-level processing (e.g., [22]), little attention has
been paid to this aspect in the context of mobile applications.
To demonstrate the impact, we conduct a study using the IPerf
tool [16] from a server that generates continuous traffic to the
Nexus4 smartphone. We measure the average throughput over 5
minutes and repeat the experiment 20 times for 12 clock frequencies.
Fig. 6 shows the effect of clock frequency on network throughput.
When the clock frequency is reduced from 1512 MHz to 384 MHz,
the average throughput drops from 48 Mbps to 32 Mbps. This de-
crease in throughput is entirely internal to the device. Recall (§2.1)
that we host the content on our LAN. The reason for the decreased
TCP throughput is that packet processing is computationally inten-
sive, and a slow CPU increases the packet processing time.
This second-order effect has significant implications, especially
for Web and Video telephony applications. As we discussed in §3,
these applications perform poorly under slow CPU speeds partly
because of the TCP processing delays.
Takeaway4: A takeaway is that we require research on improving
TCP processing, not only in the context of data centers but also in
the context of mobile applications.
4.2 Accelerating Web Page Load
Based on the lessons learned from video applications, we explore
how offloading computation to a coprocessor may improve the
performance of Web page loads under slower clocks. Many modern
mobile phones include GPUs, DSPs, and other specialized hardware
accelerators. We study the effect of offloading Web computations
to a DSP. To this end, we examine the computation performed
on the CPU during Web page loads and identify that Javascript
execution is a major time-consuming component. We then drill
down into the execution of the script functions for the slowest set
of Web pages in our study (news and sports pages) and find that a
significant fraction (20% of scripting time) of the page load time is
spent in regular expression evaluation (e.g., for URL matching and
list operations). This makes a case for exploring the possibility of
offloading regular expression evaluation to the DSP.
We conducted our analysis by offloading Javascript regular ex-