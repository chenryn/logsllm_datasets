# deep part for all input features    deep = tf.keras.layers.DenseFeatures(numerical_columns + categorical_columns)(inputs)    deep = tf.keras.layers.Dense(128, activation='relu')(deep)    deep = tf.keras.layers.Dense(128, activation='relu')(deep)    
# wide part for cross feature    wide = tf.keras.layers.DenseFeatures(crossed_feature)(inputs)    both = tf.keras.layers.concatenate([deep, wide])    output_layer = tf.keras.layers.Dense(1, activation='sigmoid')(both)    model = tf.keras.Model(inputs, output_layer)从代码中我们可以看到，在创建模型的时候，我们依次配置了模型的 Deep部分和 Wide 部分。我们先来看 Deep 部分，它是输入层加两层 128维隐层的结构，它的输入是类别型 Embedding向量和数值型特征，实际上这跟上节课 Embedding+MLP模型所用的特征是一样的。Wide部分其实不需要有什么特殊操作，我们直接把输入特征连接到了输出层就可以了。但是，这里我们要重点关注一下Wide 部分所用的特征crossed_feature。    movie_feature = tf.feature_column.categorical_column_with_identity(key='movieId', num_buckets=1001)    rated_movie_feature = tf.feature_column.categorical_column_with_identity(key='userRatedMovie1', num_buckets=1001)    crossed_feature = tf.feature_column.crossed_column([movie_feature, rated_movie_feature], 10000)在生成 crossed_feature 的过程中，我其实仿照了 Google Play的应用方式，生成了一个由"用户已好评电影"和"当前评价电影"组成的一个交叉特征，就是代码中的crossed_feature，设置这个特征的目的在于让模型记住好评电影之间的相关规则，更具体点来说就是，就是让模型记住"一个喜欢电影A 的用户，也会喜欢电影B"这样的规则。当然，这样的规则不是唯一的，需要你根据自己的业务特点来设计，比如在电商网站中，这样的规则可以是，购买了键盘的用户也会购买鼠标。在新闻网站中，可以是打开过足球新闻的用户，也会点击NBA 新闻等等。在 Deep 部分和 Wide 部分都构建完后，我们要使用`concatenate layer`把两部分连接起来，形成一个完整的特征向量，输入到最终的 sigmoid神经元中，产生推荐分数。总的来说，在我们上一节的 Embedding MLP 模型基础上实现 Wide&Deep是非常方便的，Deep 部分基本没有变化，我们只需要加上 Wide部分的特征和设置就可以了。Wide&Deep 的全部相关代码，我都实现在了SparrowRecsys 的 WideNDeep.py文件中，你可以直接参考源代码。但我更希望，你能尝试设置不同的特征，以及不同的参数组合，来真实地体验一下深度学习模型的调参过程。小结这节课，我们一起实现了业界影响力非常大的深度学习模型Wide&Deep，它是由 Wide 部分和 Deep 部分组成的。其中，Wide部分主要是为了增强模型的"记忆能力"，让模型记住"如果 A，那么B"这样的简单但数量非常多的规则。Deep部分是为了增强模型的"泛化能力"，让模型具备对于稀缺样本、以及从未出现过的特征组合的预测能力。Wide&Deep正是通过这样取长补短的方式，让模型的综合能力提升。在具体实践的时候，我们继续使用 TensorFlow 的 Keras 接口实现了Wide&Deep 模型。相比上节课 Embedding MLP模型的实现，我们新加入了"用户已好评电影"和"当前评价电影"组成的交叉特征crossed_feature，让 Wide 部分学习"一个喜欢电影 A 的用户，也会喜欢电影B"这样的规则。好了，这就是我们这节课的主要内容，同样，我也把重要的知识点总结在了表格里，你可以利用它来巩固复习。![](Images/01a6507d10e8a44c9428e3fd8ddc7669.png)savepage-src="https://static001.geekbang.org/resource/image/1d/12/1d5985d8e9b7d92a87baa80f619a8a12.jpeg"}课后思考对于 Deep 部分来说，你觉得我们一股脑地把所有特征都扔进 MLP中去训练，这样的方式有没有什么改进的空间？比如说，"用户喜欢的电影风格"和"电影本身的风格"这两个特征，我们能不能进一步挖掘出它们之间的相关性，而不是简单粗暴地扔给神经网络去处理呢？欢迎把你的思考和疑问写在留言区，如果的你朋友也正在为 Wide&Deep模型的实现而困扰，欢迎你把这节课转发给他，我们下节课见！