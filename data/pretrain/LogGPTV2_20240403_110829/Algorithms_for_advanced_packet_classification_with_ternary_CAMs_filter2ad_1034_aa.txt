title:Algorithms for advanced packet classification with ternary CAMs
author:Karthik Lakshminarayanan and
Anand Rangarajan and
Srinivasan Venkatachary
Algorithms for Advanced Packet Classiﬁcation with
Ternary CAMs
Karthik Lakshminarayanan
Srinivasan Venkatachary
Univ. of California, Berkeley Cypress Semiconductor Cypress Semiconductor
Anand Rangarajan
ABSTRACT
Ternary content-addressable memories (TCAMs) have gained wide
acceptance in the industry for storing and searching Access Control
Lists (ACLs). In this paper, we propose algorithms for addressing
two important problems that are encountered while using TCAMs:
reducing range expansion and multi-match classiﬁcation.
Our (cid:2)rst algorithm addresses the problem of expansion of rules
with range (cid:2)elds(cid:151)to represent range rules in TCAMs, a single
range rule is mapped to multiple TCAM entries, which reduces the
utilization of TCAMs. We propose a new scheme called Database
Independent Range PreEncoding (DIRPE) that, in comparison to
earlier approaches, reduces the worst-case number of TCAM en-
tries a single rule maps on to. DIRPE works without prior knowl-
edge of the database, scales when a large number of ranges is
present, and has good incremental update properties.
Our second algorithm addresses the problem of (cid:2)nding mul-
tiple matches in a TCAM. When searched, TCAMs return the
(cid:2)rst matching entry; however, new applications require either the
(cid:2)rst few or all matching entries. We describe a novel algorithm,
called Multi-match Using Discriminators (MUD), that (cid:2)nds multi-
ple matches without storing any per-search state information in the
TCAM, thus making it suitable for multi-threaded environments.
MUD does not increase the number of TCAM entries needed, and
hence scales to large databases.
Our algorithms do not require any modi(cid:2)cations to existing
TCAMs and are hence relatively easy to deploy. We evaluate the
algorithms using real-life and random databases.
Categories Subject Descriptors
C.2.6 [Internetworking]: Routers.
General Terms
Algorithms, Performance, Design.
Keywords
Packet classi(cid:2)cation, Ternary CAMs, Multi-match, Range.
1.
INTRODUCTION
High-speed packet classi(cid:2)cation algorithms that scale to large
multi-(cid:2)eld databases have become a widespread requirement for a
variety of applications such as network security appliances, qual-
ity of service (cid:2)ltering and load balancers. For classifying pack-
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for pro(cid:2)t or commercial advantage and that copies
bear this notice and the full citation on the (cid:2)rst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speci(cid:2)c
permission and/or a fee.
SIGCOMM’05, August 22–26, 2005, Philadelphia, Pennsylvania, USA.
Copyright 2005 ACM 1›59593›009›4/05/0008 ...$5.00.
ets, a router employs a classiﬁcation database (also called a policy
database) which has several access control lists (ACLs). Each ACL
consists of rules that are applied on incoming or outgoing packets.
While the syntax of these rules varies based on the router vendor,
the semantics of the rules allows similar classi(cid:2)cation information
to be speci(cid:2)ed(cid:151)the rules allow the de(cid:2)nition of various patterns
based on the packet header. Furthermore, for each rule, the set of
actions to be taken on packets that match the rule is also speci(cid:2)ed.
Designing algorithms that scale to millions of rules and millions
of searches per second has been and continues to be an impor-
tant stream of research. Several advances in algorithmic approaches
that use off-chip random access memories have been made in the
past few years. Recursive Flow Classi(cid:2)cation [8], Crossproduct-
ing [18, 20], HyperCuts [15], Extended Grid-of-Tries [1] are some
examples; refer to [19,23] for details of these techniques.
However, in the past few years, the industry has increasingly em-
ployed Ternary Content Addressable Memories (TCAMs) for per-
forming packet classi(cid:2)cation [5, 9, 12]. A large class of current-
and next-generation systems that require up to a few hundred thou-
sand rules have adopted TCAMs for packet classi(cid:2)cation at multi-
gigabit speeds.1 The number of TCAM devices that have been de-
ployed worldwide in 2004 is over 6 million [3].
A TCAM is a memory device that stores data as a massive ar-
ray of (cid:2)xed-width ternary entries. A ternary entry is a string of
bits where each bit is either 0, 1 or x (don’t care). Given a search
key, the TCAM searches the key in parallel against all the ternary
entries stored in the TCAM and produces the (cid:2)rst match as the
result. TCAMs provide two main characteristics that make them
suitable for router design: deterministic search throughput and de-
terministic capacity. Current TCAMs can support up to 133 mil-
lion searches per second for 144-bit wide keys, and can store 128K
ternary entries that are 144 bits wide in a single device.
1.1 Problems
While TCAMs are well-suited for performing high-speed
searches on databases with ternary entries, the following problems
and trends reduce the ef(cid:2)ciency of TCAMs.
Range rules: To store a rule with range ﬁelds, multiple TCAM
entries are needed, which reduces the ef(cid:2)ciency of TCAMs [11,16].
In IP router ACLs, the port (cid:2)elds usually have ranges. As ranges
cannot be directly stored in TCAMs, traditionally, ranges are con-
verted to a corresponding set of pre(cid:2)xes, and each pre(cid:2)x is stored
in a separate TCAM entry (see Section 3.1.1). When this range-
to-pre(cid:2)x expansion technique is applied on the port (cid:2)elds, which
are 16 bits wide, a rule with a single range (cid:2)eld can expand to
30 TCAM entries in the worst case. By analyzing router ACL
databases dated 1998 and 2004, we provide evidence for the fol-
lowing temporal trends that make the range expansion problem an
important one. Table 1 (see Section 3) provides the actual numbers.
1Due to power and cost considerations, current-generation TCAMs face
scalability challenges. A cost-effective approach to supporting millions of
rules at high speeds is still a topic of research.
193(cid:15) Number of rules in router ACL databases is increasing.
(cid:15) Percentage of rules with one range (cid:2)eld is increasing.
(cid:15) Percentage of rules with two range (cid:2)elds is increasing.
(cid:15) Number of unique ranges is increasing.
Multi-match classiﬁcation: Security applications and account-
ing applications require the ﬁrst k matching entries, or in some
cases all the matching entries, for a given key [25]. TCAMs do
not natively support (cid:2)nding multiple matches; they report only the
(cid:2)rst matching entry.
1.2 Our Contributions
In this paper, we propose algorithms for addressing the range
expansion and multi-match classi(cid:2)cation problems using off-the-
shelf TCAMs. Our (cid:2)rst algorithm, Database Independent Range
PreEncoding (DIRPE), reduces the worst-case number of TCAM
entries a single rule maps on to, when compared to earlier schemes.
DIRPE works without knowledge of the database, scales when a
large number of ranges is present, and has good incremental update
properties. Our second algorithm, Multi-match Using Discrimina-
tors (MUD), enables multiple matches to be found using a TCAM
without storing any per-search state information in the TCAM, thus
making it suitable for multi-threaded packet processing environ-
ments. MUD can scale to large databases since it does not expand
the number of TCAM entries needed. The bene(cid:2)ts of MUD come
at the cost of extra search cycles; however, we show that MUD can
still support multi-match classi(cid:2)cation at multi-gigabit link speeds.
Both our algorithms utilize unused bits in the TCAM array to en-
code relevant information. Though the algorithms solve seemingly
different problems, we draw similarities between the algorithms,
and apply similar ideas for both the algorithms.
Our schemes do not require any change to existing TCAMs and
hence are relatively easy to deploy. This metric is important as
TCAMs are complex devices and architectural changes that mod-
ify TCAMs involve millions of dollars of investment and more than
two years of development time. Hence, algorithmic approaches that
utilize current TCAMs to solve a problem are preferable.
The rest of the paper is organized as follows. In Section 2, we
provide some background and describe the metrics and terminol-
ogy used in the paper. In Section 3, we present our database-
independent range encoding algorithm. In Section 4, we describe
our multi-match classi(cid:2)cation algorithm. Related work, evaluation
of the schemes, and comparison with earlier approaches are pre-
sented in the corresponding sections themselves.
2. PACKET
PROCESSING ENVIRON-
MENT
Figure 1 shows a packet processor connected to a set of TCAMs.
Packets are classi(cid:2)ed using a classi(cid:2)cation database consisting of
several access control lists (ACLs), each of which holds several
rules. The control plane software maintains the ACLs and stores
them in the TCAMs. When data packets arrive, the packet proces-
sor parses the packet headers, and forms keys to search the appro-
priate ACLs (based on factors such as the interface the packet ar-
rives on). A typical search key is of the form:
A parallel search is performed on the entries stored in the
TCAM. The search returns the index of the (cid:2)rst entry that matches
the search key. A memory location corresponding to the result in-
dex is used to store the action to be taken when a search key
matches the entry. Typical actions include permit/deny, update
counters and replicate on a port.
CONTROL(cid:13)
PLANE(cid:13)
MEMORY(cid:13)
DATA(cid:13)
PLANE(cid:13)
LINECARD CPU(cid:13)
(LCPU)(cid:13)
Table Management(cid:13)
Software(cid:13)
CPU Interface bus(cid:13)
(e.g., PCI)(cid:13)
Packet(cid:13)
in(cid:13)
Packet Processor(cid:13)
(ASIC or FPGA(cid:13)
or programmable(cid:13)
Network Processor)(cid:13)
Packet(cid:13)
out(cid:13)
MEM(cid:13)
Result(cid:13)
Instruction(cid:13)
Packet(cid:13)
Buffers(cid:13)
Address/(cid:13)
Assoc.(cid:13)
Data(cid:13)
TCAM(cid:13)
TCAM(cid:13)
Figure 1: System picture of a router line card showing control and
data planes.
    (cid:13)
TCAMs constitute a signi(cid:2)cant portion of the cost of a multi-
gigabit linecard. For example, the price for a 10 gigabit linecard in
the next couple of years is expected to be less than a thousand dol-
lars [6]. However, TCAMs that can support 128K entries of 144-bit
width are expected to cost over $200 for the next few years [5,9,12].
Hence, to design ef(cid:2)cient, low-cost multi-gigabit linecards, it is
critical to utilize TCAMs as ef(cid:2)ciently as possible. Though today’s
TCAMs do not scale to millions of rules due to cost and power con-
siderations, they are well-suited for storing databases with up to a
few hundred thousand rules.
State-of-the-art TCAMs provide 18M ternary bits which are or-
ganized into 32, 64 or 128 blocks. Each block can be independently
con(cid:2)gured to have a width of 72, 144, 288 or 576 bits. After the
(cid:2)elds of an ACL rule are encoded in the TCAM, typically there are
some extra bits that are left unused. For example, most IPv4 ACLs
consist of an identi(cid:2)er and a protocol (8 bits), destination address
(32 bits), source address (32 bits), destination port (16 bits) and
source port (16 bits)(cid:151)a total of 104 bits. Usually, 4 more bits are
used to encode miscellaneous (cid:2)elds. Since TCAMs are typically
con(cid:2)gured to be 144 bits wide, 36 extra bits remain unused.
We now describe some metrics for comparing algorithms used in
the packet classi(cid:2)cation subsystem for multi-gigabit routers.
2.1 Metrics
Speed/Throughput: The system has to support a guaranteed
throughput (in gigabits per second (Gbps)). To compute the guar-
anteed rate in millions of packets per second (MPPS), we assume a
minimum packet size of 64 bytes [1].
The system requires a certain minimum throughput (measured in
Millions of Packets Per Second (MPPS)), which is usually the wire-
rate assuming smallest-sized packets. Assuming 64-byte packets,
OC-48 corresponds to roughly 5 MPPS and OC-192 to 20 MPPS.
Capacity: Capacity is the number of rules that can be supported
in the search subsystem. In our experiments, we compared the ca-
pacity of candidate algorithms using worst-case, real-life, and ran-
dom databases.
Update Speed: Traditionally, rules are updated manually, and low
update speeds of the order of a few hundred per second are ac-
ceptable. However, newer systems that perform real-time active re-
sponse to hostile network events [4] require incremental updates at
much higher speeds.
Overhead on Packet Processor: This is the cost of the extra logic,
if any, that is needed as part of the packet processor.
Multi-threading Support: Most packet processors use many
threads of execution to achieve high speed. Components such as
TCAMs attached to the network processor are shared by all these
threads. Hence, algorithms that utilize such components must take
multi-threading into account.
In this paper, we compare various schemes using the metrics de-
scribed above. For real-life comparisons, we provide results us-
ing some Internet Service Provider (ISP) databases that we ob-
tained. Due to privacy reasons, we cannot reference the ISP. We
also use the Snort database, a publicly available intrusion detection
database [2].
2.2 Terminology
We now introduce some terminology that we use in the paper.
Let N denote the number of rules in a database Fdat. Let a range
(cid:2)eld be W bits wide. Let R denote the closed range [s; e], where s
and e are W -bit numbers.
A key S is a collection of K (cid:2)elds from the packet header
H. These header (cid:2)elds are denoted H[1]; H[2]; : : : ; H[K], where
each (cid:2)eld is a string of bits.
A preﬁx P is a bit string of length between 0 and W . length(P )
denotes the number of bits in a pre(cid:2)x. (P padded with 0’s is the
smallest number encompassed by P and P padded with 1’s is the
largest number encompassed by P ).
A ﬁlter rule or ACL rule F is a collection of K (cid:2)elds. Each
(cid:2)eld F [i] in a rule can specify any of three kinds of matches: exact
match, preﬁx match, or range match. A rule that has at least one
of its (cid:2)elds having a range match speci(cid:2)cation is referred to as a
range rule.
An exact match speci(cid:2)cation is a value speci(cid:2)ed for a rule (cid:2)eld
i. A header (cid:2)eld H[i] is an exact match for the rule (cid:2)eld F [i] if and
only if H[i] = F [i].
A preﬁx match speci(cid:2)cation is a pre(cid:2)x speci(cid:2)ed for a rule (cid:2)eld
i. A header (cid:2)eld H[i] is a pre(cid:2)x match for the rule (cid:2)eld F [i] if and
only if the leading length(F [i]) bits of H[i] are the same as F [i].
A range match speci(cid:2)cation is a range of values F [i] =
valstart; : : : ; valend for rule (cid:2)eld i. A header (cid:2)eld H[i] is a range
match for the rule (cid:2)eld F [i] if and only if valstart (cid:20) H[i] (cid:20)
valend.
A rule F is said to be a matching rule for a header H if and only
if each (cid:2)eld H[i] of H matches the corresponding (cid:2)eld F [i] of F .
3. REDUCING EXPANSION OF RANGE
RULES
Ternary CAMs are directly suited for storing ACL tables that
have rules with wildcards. However, a range cannot be stored di-
rectly in a TCAM since a TCAM supports storing only 0, 1 and x
(don’t-care) states. Hence, storing range rules could take a large
number of TCAM entries. In this section, we present DIRPE,
a database-independent algorithm that reduces the expansion of
range rules even in the worst-case. We (cid:2)rst review earlier ap-
proaches and motivate our algorithm.
Statistic
Total number of rules
With single
range (cid:2)eld
With two
range (cid:2)elds
With single range (cid:2)eld
excluding (cid:147)(cid:21) 1024(cid:148) speci(cid:2)cation
Unique ranges in (cid:2)rst (cid:2)eld
Unique ranges in second (cid:2)eld
1998 database
41190
4236
(10.3%)
553
(1.3%)
0
(0%)
62
0
2004 database
215183
54352
(25.3%)
25311
(11.8%)
3225
(1.5%)
270
37
Table 1: Number of rules with range ﬁelds in a collection of ACLs
obtained in 1998 and 2004.
3.1 Earlier Approaches
3.1.1 Prefix Expansion of Ranges
A well-known method for representing range rules in TCAMs
is to expand each range into a set of pre(cid:2)xes, which can then be
used directly as the TCAM entries [19]. For rules with multiple
range (cid:2)elds, the sets of pre(cid:2)xes corresponding to all the (cid:2)elds are
crossproducted to get the TCAM entries. The worst-case expansion
for a W -bit range is 2W (cid:0)2. A simple proof by construction is as
follows. Consider the range [1; 2W (cid:0)2]. The smallest set of pre(cid:2)xes
needed to cover this range is f01*, 001*, 0001*, : : :, 0W (cid:0)11, 10(cid:3),
110(cid:3), : : :, 1W (cid:0)10g. For a 16-bit range (cid:2)eld, the worst-case expan-
sion is 30. Hence, an IP ACL rule which has two 16-bit port (cid:2)elds
can expand to 30 (cid:2) 30 = 900 entries in the worst case.
3.1.2 Database-dependent Encoding of Ranges
To reduce the expansion of rules, additional bits in the TCAM
can be used to encode the ranges that appear frequently. To illus-
trate this scheme, consider the example of an ACL database that
contains the range R in several range rules. Consider the following