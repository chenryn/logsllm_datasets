analyzed this ordinal data with the Kruskal-Wallis H test (KW) for
omnibus comparisons. Using the Mann-Whitney U Test (U), KW’s
analogue for two groups, we ran seven planned contrasts between
condition pairs: comparing Longitudinal:Interests to each of the
other five conditions, and comparing both Current:Connections and
Current:Trackers to Control:Static. To minimize Type II error, we
performed Holm correction within each set of contrasts and across
each set of omnibus tests. We analyzed SUS data and participants’
estimates of tracking similarly, though treating data as continuous.
Many questions asked both pre- and post-usage also elicited
responses on scales. To understand how responses in this repeated-
measures design changed over time both regardless of condition and
by condition, we built repeated-measures ordinal logistic regression
models. Responses were the DV for each, and the time period (pre-,
post-usage), condition, and interaction between the two were the
IVs. We performed Holm correction within each set of questions.
Similarly, for the two IUIPC sub-scales, we summed responses
across scale items and analyzed these (continuous) sums with a
repeated-measures ANOVA.
We analyzed free-response data through qualitative open coding.
One member of the research team read responses and created a
codebook with thematic codes, iteratively updating as necessary.
Each survey question had its own set of 7 or 8 unique, but not mu-
tually exclusive, codes. A second researcher independently coded
the full set of data. Inter-coder reliability, measured with Cohen’s κ,
ranged from 0.76 to 0.82 per question, with a median of 0.80. This
level of agreement is “substantial” [47] or “excellent" [33].
4.6 Limitations
To limit self-selection by especially privacy-interested participants,
we advertised our study as “evaluating a web browser visualization
tool” without mention of privacy, though we did mention tracking
as part of the procedures. However, there may also have been
contradictory self-selection in which privacy-conscious people may
have been unwilling to install an unknown extension and therefore
decline participation. Further, MTurk participants are generally
younger, more technical, and more privacy-sensitive than the the
overall U.S. population [42]. This is evident in our results, which
demonstrate high initial levels of knowledge about tracking. We
believe these limitations are acceptable, as our tool targets people
with an interest in learning more about online tracking and privacy.
Further, while our participants displayed high initial knowledge
about tracking and privacy, less-aware populations may stand to
benefit even more from visualizations like ours.
As in any online study, participants may not answer carefully,
and some may try to participate multiple times. We follow best prac-
tices [68], using high-reputation workers and forbidding multiple
submissions from one MTurk account. In addition to participants’
high initial privacy literacy, the phrasing of our questions is another
possible cause of the ceiling effect in some of our results.
We were only able to survey Chrome and Firefox users. These
are the two most popular desktop browsers [85], so we consider this
reasonably representative. The extension only attempts to detect
third-party tracking in desktop browsing; the mobile tracking/ad
ecosystem is significantly different. The extension also does not
account for cross-browser or cross-device tracking [13, 15, 104].
Our simulation of inferences that could be made based on a user’s
browsing history is only an approximation of what advertising
networks may actually be doing. While the simulated nature of
these inferences is a clear limitation of our protocol, advertising
networks do not provide consumers or researchers access to actual
data mapping precise browsing activities to specific inferences.
While imperfect, our methods are one of the only ways for us to
evaluate users’ reactions to inference-level information.
Further, detecting trackers by using web requests may result in
false positives for tracking-unrelated requests, but it captures many
types of tracking including cookie storage and access, as well as
fingerprinting. Other blocking tools that a user has installed may
block requests to trackers and prevent our extension from detecting
them, but this would accurately reflect the extent to which the user
is actually tracked. We detected whether participants had blocking
tools installed and found that there was a slight decrease in the
number of trackers detected for those users. Finally, our qualitative
results indicated that some participants in the Control:Static condi-
tion may have realized they were in a control condition. However,
a control was necessary to facilitate comparisons across conditions.
Given ongoing escalations between ad-blockers and advertis-
ers [41], plus the potential of fingerprinting browser extensions [37,
83], it is possible sites could identify and retaliate against future
tools like Tracking Transparency. Sites could manipulate the text
parsed by the topic modeling algorithm or otherwise try to avoid
classification. As we used Tracking Transparency with a small pop-
ulation during a short experiment, it seems unlikely we provoked
such retaliation. Any widely deployed tool employing a similar
mechanism would need to defend against adversarial scenarios.
5 FIELD STUDY RESULTS
In this section, we present results from our field study assessing
how the Tracking Transparency interface affects user attitudes.
We begin by characterizing our participants and their usage of
the extension (Section 5.1). We then present qualitative analysis of
participants’ reactions to the information Tracking Transparency
presented (Section 5.2). Participants were surprised by the extent
of tracking. They newly learned how trackers infer their interests.
Section 5.3 describes how using the extension increased partici-
pants’ intentions to take privacy-protective actions. Conditions that
displayed more information saw larger increases in intentions. We
then briefly discuss how the extension did not significantly impact
participants’ knowledge of targeted advertising (Section 5.4), which
was mostly correct to begin with, or their broad attitudes about
the practice (Section 5.5). Table 4 in the appendix gives the full
statistical results. Finally, Section 5.6 describes how longitudinal
information helped participants more accurately quantify tracking.
5.1 Participants and Usage
Demographics. A total of 456 participants completed the study.
We exclude the 6.8% of participants who visited fewer than 100 web
pages, leaving 425 participants. As conditions were randomly as-
signed, the distribution of participants varied: 71 in Control:Static,
82 in Control:Browsing Only, 63 in Current:Trackers, 70 in Cur-
rent:Connections, 66 in Longitudinal:Trackers, and 73 in Longitudi-
nal:Interests. In total, 52.2% participants identified as female, 46.8%
as male, and 1.0% as non-binary. Most (72.2%) were 25–44 years
old; 7.8% were under 25, while 20.0% were 45+. Most had bachelor’s
degrees (40.5%) or some college (35.3%), while fewer had graduate
degrees (9.6%) or high school diplomas (14.6%). Additionally, 23.1%
reported holding a degree or job related to IT or CS.
Browser usage. Most (89.9%) participants installed the Tracking
Transparency extension on Google Chrome, as opposed to Firefox
(10.1%). Participants estimated a median of 80% of their browsing
was on the device and browser they installed the extension on.
Just under half (48.5%) of participants reported current use of
an ad- or tracker-blocking tool, and an additional 18.6% reported
having used such a tool in the past. However, only 8.5% reported
current use of a dedicated tracker-blocking tool (Ghostery, Privacy
Badger, Firefox Tracking Protection, and Disconnect, in order of
frequency). Our extension checked for the presence of other block-
ing tools by querying whether certain popular extensions were
installed, finding that 39% of participants had such a tool. A minor-
ity of participants reported having viewed ad preferences pages on
Facebook (37.4%) and Google (28.9%), and only 7.5% recognized the
AdChoices icon that indicates targeted ads [51].
Over the week-long study, our 425 participants visited a total of
1,068,302 web pages and encountered 533 different trackers. The
top trackers observed were Amazon (present on 64.2% of pages),
Google (47.0%), Facebook (10.1%), comScore (6.4%), and Microsoft
(4.5%). Our extension detected an average of 2.58 trackers per page
for users with no other blocking tools installed, and an average of
2.15 trackers for those with a blocking tool installed. Most of the
533 trackers were only observed on a small fraction of pages visited,
demonstrating a long-tailed distribution consistent with large-scale
measurements by Engelhardt et al.’s OpenWPM tool [27].
Tracking Transparency’s inferencing approximation layer (Sec-
tion 3.3) assigned a total of 230 unique interest categories across
participants. The median participant was assigned 59 interest cat-
egories (µ = 58.6, σ = 16.8) that the extension guessed might be
inferrable from the participant’s page visits. “Travel,” “News,” “Shop-
ping,” “Books & Literature,” and “Online Communities” were the
five most frequent categories, and all 425 participants had at least
one page assigned the “Travel” topic. There was a long tail of topics
assigned, including relatively obscure and infrequently assigned
categories like “Medical Literature & Resources.” In total, 58 of the
Table 2: The percentage of participants per condition who organically mentioned different classes of information when de-
scribing what was surprising, what was new to them, and what they already knew.
Code
Number of trackers
Interests are inferred
Own browsing habits
Detail of data
Frequency of tracking
Sites without tracking
Unexpected third parties
Tracking occurs
Connections
Nothing
Number of trackers
Frequency of tracking
How interests inferred
Own browsing habits
Tracking used to target
Tracking methods
Connections
Nothing
Tracking occurs
Tracking used for ads
Frequency of tracking
Interests are inferred
Own browsing habits
Tracking used to target
Tracking methods
g
n
i
s
i
r
p
r
u
S
n
o
i
t
a
m
r
o
f
n
i
w
e
N
w
e
n
k
y
d
a
e
r
l
A
Representative quote
“I would have to say the sheer number of trackers found and how many different pages I actually visited I
could not believe it was that many.”
“I’m surprised by the depth of the information, such as topics, that are gathered from multiple sites, even
my email server.”
“I really didn’t think that I surfed the web that much.”
“Just how many and how well they track the sites you visit.”
“Just exactly how much of the time that Amazon was tracking me. I mean talk about stalking. I knew that
they were suggesting things from my google searches and such but their trackers seem to be on the majority
of webpages out there.”
“I was surprised at times when nobody was tracking when I expected someone to be.”
“That the information was being sold or shared with so many third party website that I haven’t heard of
before. I never visited them but they have my information anyways.”
“How all of my online activity is tracked and all connected in a virtual world where my fingerprint is all
over the place even if I am unaware.”
“I just didn’t know how enmeshed the companies were with each other.”
“There was nothing that was very surprising, but it was still interesting to see it all.”
“A lot more services track me than I knew about.”
“I learned that most of the sites were tracking what I was doing.”
“I learned what information sites are pulling when I’m visiting them.”
“I didn’t realize how many site/pages I use throughout the day.”
“I learned more about how the ads I see when browsing magically appear to be personalized.”
“I did not know the manner in which trackers tracked my interest.”
“I learned that there are far more connections between first and third party sites I visit.”
“Nothing really. I knew that some sites would track me.”
“I was aware of the presence of trackers...but not to the level that the extension confirmed.”
“I knew some ads were generated based on my browsing and search results.”
“Sites are connected. Google is often at the center of that. Sites are always tracking you.”
“Companies would track my activity to pool my interests and then use them to target me with ads going
forward. I knew Facebook did this frequently.”
“I visit a lot of pages. Most likely a lot of them track my activity.”
“I knew that companies were able to see some of the information i search for to input dedicated ads but i did
not realize the extent of it.”
“I knew about cookies, pixels, and browser finger printing.”
% of participants mentioning
y
l
n
O
g
n
i
s
w
o
r
B
:
l
o
r
t
n
o
C
c
i
t
a
t
S
:
l
o
r
t
n
o
C
s
n
o
i
t
c
e
n
n
o
C
:
t
n
e
r
r
u
C
s
r
e
k
c
a
r
T
:
l
a
n
i
d
u
t
i
g
n
o
L
s
t
s
e
r
e
t
n
I
:
l
a
n
i
d