and detect an attack. Each component has a default policy
and can easily incorporate user-deﬁned policies as well.
In addition, each component can be conﬁgured to log in-
formation about taint propagation, which can be used by
the fourth component we have designed, the Exploit An-
alyzer. When an attack is detected, the Exploit Analyzer
performs post-analysis to provide information about the
attack, including identifying the input that led to the at-
tack, and semantic information about the attack payload.
This information can be used in automatic attack signature
generation, as we show in Section 6.
2.1. TaintSeed
TaintSeed marks any data that comes from an untrusted
source of input as tainted. By default, TaintSeed considers
input from network sockets to be untrusted, since for most
programs the network is the most likely vector of attack.
TaintSeed can also be conﬁgured to taint inputs from other
sources considered untrusted by an extended policy, e.g.,
input data from certain ﬁles or stdin.
Each byte of memory, including the registers, stack,
heap, etc., has a four-byte shadow memory that stores a
pointer to a Taint data structure if that location is tainted,
or a NULL pointer if it is not. We use a page-table-like
structure to ensure that the shadow memory uses very little
memory in practice. TaintSeed examines the arguments
and results of each system call, and determines whether
any memory written by the system call should be marked
as tainted or untainted according to the TaintSeed pol-
icy. When the memory is tainted, TaintSeed allocates a
Taint data structure that records the system call number,
a snapshot of the current stack, and a copy of the data
that was written. The shadow memory location is then
set to a pointer to this structure. This information can
later be used by the Exploit Analyzer when an attack is
detected. Optionally, logging can be disabled, and the
shadow memory locations can simply store a single bit
indicating whether the corresponding memory is tainted.
2.2. TaintTracker
into three categories:
TaintTracker tracks each instruction that manipulates
data in order to determine whether the result is tainted.
UCode Instructions fall
data
movement instructions that move data (LOAD, STORE,
MOVE, PUSH, POP, etc.), arithmetic instructions that
perform arithmetic operations on data (ADD, SUB, XOR,
etc.), and those that do neither (NOP, JMP, etc.). The
default policy of TaintTracker is as follows:
for data
movement instructions, the data at the destination will be
tainted if and only if any byte of the data at the source
location is tainted; for arithmetic instructions, the result
will be tainted if and only if any byte of the operands is
tainted. While arithmetic instructions also affect the pro-
cessor’s condition ﬂags, we do not track whether the ﬂags
are tainted, because it is normal for untrusted data to in-
ﬂuence them. Note that for both data movement and arith-
metic instructions, literal values are considered untainted,
since they originate either from the source code of the pro-
gram or from the compiler.
A special case is for constant functions where the out-
put of the function does not depend on the inputs. For
example, a common IA-32 idiom to zero out a register,
“xor eax, eax”, always sets eax to be zero regard-
less of whether the original value in eax is tainted or not.
TaintTracker recognizes these special cases such as xor
eax, eax and sub eax, eax, and sets the result lo-
cation to be untainted. Note that there can be more gen-
eral cases of constant functions where a sequence of in-
structions computes a constant function. We do not han-
dle these more general cases. However, such cases will
only make the dynamic taint analysis conservative and it
has not been an issue in practice.
In order to track the propagation of tainted data, Taint-
Tracker adds instrumentation before each data movement
or arithmetic instruction. When the result of an instruc-
tion is tainted by one of the operands, TaintTracker sets
the shadow memory of the result to point to the same Taint
structure as the tainted operand. Optionally, TaintTracker
can instead allocate a new Taint structure with information
about the relevant instruction (including the operand loca-
tions and values, and a snapshot of the stack) that points
back to the previous Taint structure. When an attack is
detected, the Exploit Analyzer can follow this chain of
Taint structures backwards to determine how the tainted
data propagated through memory.
2.3. TaintAssert
TaintAssert checks whether tainted data is used in ways
that its policy deﬁnes as illegitimate. TaintAssert’s default
policy is designed to detect format string attacks, and at-
tacks that alter jump targets including return addresses,
function pointers, or function pointer offsets. When Taint-
Check detects that tainted data has been used in an illegit-
imate way, signalling a likely attack, it invokes the Exploit
Analyzer to further analyze the attack.
The following are potentially illegitimate ways in which
tainted data might be used. TaintAssert’s policy can be
speciﬁed to check for any of these independently.
(cid:15) Jump addresses By default, TaintAssert checks
whether tainted data is used as a jump target, such as
a return address, function pointer, or function pointer
offset. Many attacks attempt to overwrite one of
these in order to redirect control ﬂow either to the
attacker’s code, to a standard library function such
as exec, or to another point in the program (possi-
bly circumventing security checks). In contrast, there
are very few scenarios in which tainted data would be
used as a jump target during normal usage of a pro-
gram, and we have not found any such examples in
our testing. Hence, these checks detect a wide variety
of attacks while generating very few false positives.
Note that jump tables are a possible exception to this
rule. A jump table could use user input as an offset to
a jump address. This is an acceptable programming
practice if there are checks in place to sanitize the
tainted data. gcc does not appear to construct jump
tables in this way in practice, but other compilers or
hand-coded assembly might. See Section 3 for fur-
ther discussion of this scenario.
We implemented these checks by having TaintCheck
place instrumentation before each UCode jump in-
struction to ensure that the data specifying the jump
target is not tainted. Note that IA-32 instructions that
have jump-like behavior (including call and ret)
are translated into UCode jump instructions by Val-
grind.
(cid:15) Format strings By default, TaintAssert also checks
whether tainted data is used as a format string argu-
ment to the printf family of standard library func-
tions. These checks detect format string attacks, in
which an attacker provides a malicious format string
to trick the program into leaking data or into writing
an attacker-chosen value to an attacker-chosen mem-
ory address. These checks currently detect whenever
tainted data is used as a format string, even if it does
not contain malicious format speciﬁers for attacks.
This could be used to discover previously unknown
format string vulnerabilities. Optionally, TaintAssert
can instead only signal when the format string both
is tainted and contains dangerous format speciﬁers
such as %n. This option is useful when a vulnera-
bility is already known, and the user only wants to
detect actual attacks.
To implement these checks, we intercept calls to the
printf family of functions (including syslog)
with wrappers that request TaintCheck to ensure that
the format string is not tainted, and then call the orig-
inal function. For most programs, this will catch
any format string attack and not interfere with nor-
mal functionality. However, if an application uses its
own implementation of these functions, our wrappers
may not be called.
(cid:15) System call arguments TaintAssert can check
whether particular arguments to particular system
calls are tainted, though this is not enabled in Taint-
Check’s default policy. This could be used to detect
attacks that overwrite data that is later used as an ar-
gument to a system call. These checks are imple-
mented using Valgrind’s callback mechanism to ex-
amine the arguments to each system call before it is
made.
As an example, we implemented an optional pol-
icy to check whether the argument speciﬁed in any
execve system call is tainted. This could be used
to detect if an attacker attempts to overwrite data that
is later used to specify the program to be loaded via
an execve system call. We disabled this check by
default, because some programs use tainted data in
this way during normal usage. A notable example is
that Apache uses part of a URL string as the argu-
ment to execve when a CGI is requested.
(cid:15) Application or library-speciﬁc checks TaintAssert
can also be conﬁgured to detect attacks that are spe-
ciﬁc to an application or library. It can do this by
checking speciﬁed memory ranges at speciﬁed points
of the program. In particular, it can be conﬁgured to
check whether a particular argument to a particular
function is tainted whenever that function is called.
An example of this is checking the format strings
supplied to printf-style functions, as described
above.
To implement this, TaintCheck could be told to
check whether a particular address range or register
is tainted whenever the program counter reaches a
particular value, or whenever it is used in a certain
way. The address range speciﬁed could be absolute,
or could be relative to the current stack frame. This
policy is application dependent and is disabled by de-
fault.
Format String
Buffer Overflow
Double Free
Heap S mash
Default Policy
Optional Policy
Return Address
Jump Address
Function Pointer
Fn Ptr Offset
System Call Args
Function Call Args
Figure 2. Attack detection coverage.
These checks are sufﬁcient to catch a wide range of at-
tacks. There are two other types of checks we also con-
sidered, but decided not to use. The ﬁrst is tracking which
ﬂags are tainted, and checking when a tainted ﬂag is used
to alter control ﬂow. This could detect when the attacker
overwrites a variable that affects the behavior of the pro-
gram. However, tainted data is used to alter control ﬂow
on a regular basis, and it is unclear whether there is a reli-
able way to differentiate the normal case from an attack.
The second type is checking whether addresses used in
data movement instructions are tainted. This could detect
when an attacker overwrites a data pointer in order to con-
trol where data is moved to or loaded from. However, it is
common to use tainted data as an offset to data movement
instructions, particularly in the case of arrays.
collect additional samples of a worm, which can be used
to help generate a signature for that worm.
The Exploit Analyzer could also be used to provide se-
mantic information about the attack payload. This infor-
mation can be used to automatically generate attack sig-
natures more accurately and with fewer samples than is
possible with purely content-based analysis of the attack
payload. To demonstrate this idea, the Exploit Analyzer
currently identiﬁes the value used to overwrite the return
address. We show in Section 6 that the most signiﬁcant
bytes of this value can be used in a signature of the attack.
Note that our techniques are related to dynamic program
slicing [4, 23], although dynamic program slicing consid-
ers control-ﬂow dependencies and is often based on source
code analysis.
2.4. Exploit Analyzer
3. Security analysis of TaintCheck
When TaintAssert detects that tainted data has been
used in a way violating its security policy, thus signal-
ing a likely exploit, the Exploit Analyzer can provide use-
ful information about how the exploit happened, and what
the exploit attempts to do. These functions are useful for
identifying vulnerabilities and for generating exploit sig-
natures.
Information logged by TaintSeed and TaintTracker
shows the relevant part of the execution path in between
tainted data’s entry into the system, and its use in an ex-
ploit. By backtracing the chain of Taint structures, the Ex-
ploit Analyzer provides information including the original
input buffer that the tainted data came from, the program
counter and call stack at every point the program operated
on the relevant tainted data, and at what point the exploit
actually occurred. The Exploit analyzer can use this infor-
mation to help determine the nature and location of a vul-
nerability quickly, and to identify the exploit being used.
The Exploit Analyzer can optionally allow an attack to
continue in a constrained environment after it is detected.
We currently implement an option to redirect all outgoing
connections to a logging process. This could be used to
In this section, we analyze the attacks that can be de-
tected by TaintCheck and the false positives and false neg-
atives incurred by TaintCheck.
Attacks detected by TaintCheck Figure 2 classiﬁes
overwrite attacks by the type of value that is overwritten,
and by the method used to perform the overwrite. In gen-
eral, TaintCheck is capable of detecting any overwrite at-
tack that overwrites a value that would not normally be
tainted. TaintCheck’s default policy is that jump targets
and format strings should not be tainted, allowing it to
detect attacks that overwrite jump targets (such as return
addresses, function pointers, and function pointer offsets),
whether altered to point to existing code (existing code at-
tack) or injected code (code injection attack), and all for-
mat string attacks. It’s important to note that most of the
worm attacks we have seen to date fall into these cate-
gories, including all the major worms such as the Slam-
mer Worm and the CodeRed Worm. TaintCheck’s policy
can also be customized in order to detect an even wider
range of attacks, as described in Section 2.3
False negative analysis A false negative occurs if an at-
tacker can cause sensitive data to take on a value of his
choosing without that data becoming tainted. This can be
achieved if the altered data does not originate and is not
arithmetically derived from untrusted inputs, but is still in-
ﬂuenced by untrusted inputs. In particular, because we do
not consider the tainted attribute of ﬂags, the attacker can
alter data by inﬂuencing the control ﬂow of conditional
branches to evade tainting. For example, suppose the vari-
able x is tainted. A structure of the form if (x == 0)
y = 0; else if (x == 1) y = 1; ... is se-
mantically the same as y = x but would not cause y to
become tainted, since the value for y is only inﬂuenced
indirectly by x, via the condition ﬂags.
If the attacker
could later cause y to overwrite a sensitive value, the at-
tack would be undetected. Another potential problem is if
tainted data is used as an index into a table. For example,
IIS translates ASCII input into Unicode via a table [15].
The resulting translation is not tainted, because the values
were copied from hard-coded literals, rather than arith-
metically derived from the input.
Other false negatives can occur if TaintCheck is conﬁg-
ured to trust inputs that should not be trusted. The current
default conﬁguration of not trusting data read from net-
work sockets is sufﬁcient to detect most remote attacks.
However, an attacker may be able to control data from
other input sources, depending on the application. An ex-
ample of this is a vulnerability in the innd news server, in
which data from the network is ﬁrst written to a ﬁle on
disk, and then read back into memory [1, 15]. These types
of false negatives can be minimized by using a more re-
strictive policy of what inputs should be tainted. In our
experiments, marking data read from ﬁles other than dy-
namically loaded libraries did not cause false positives,
except in the case of some conﬁguration ﬁles. In those
cases, it is straightforward to conﬁgure TaintCheck not to
taint data read from those ﬁles.
Analysis and handling of false positives
In cases
where TaintCheck detects that tainted data is being used
in an illegitimate way even when there is no attack tak-