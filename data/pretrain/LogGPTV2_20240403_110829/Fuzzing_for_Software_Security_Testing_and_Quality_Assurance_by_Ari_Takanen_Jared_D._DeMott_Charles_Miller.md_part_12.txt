cation or unneeded sessions), and to log the ones that succeed in causing the target
to fail in some way. It is still an open question as to how many test cases are enough,
but using a metric based approach and code coverage results, it may be possible to
shed light on this difficult decision. More on this later in the book.
2.7 Defenses
This section focuses on what can be done to mitigate the risks of implementation
errors. There are many coding techniques, hardware/software protections, and fur-
ther system designs that can be put in place to minimize the risk of software failure
or malicious compromise.
To this end, Microsoft’s operating systems since Vista have made significant
strides toward becoming a more secure operating and development platform. Section
26 See Section 2.4.5.
6760 Book.indb 64 12/22/17 10:50 AM
2.7 Defenses 65
2.7.5 will introduce some of these protections. Other operating systems have other
protections, but a comprehensive discussion is beyond the scope of this book.
2.7.1 Why Fuzzing Works
Fuzzing has been found effective because manually conceiving and creating every
possible permutation of test data to make good test cases is difficult if not impossible.
Testers try their best, but fuzzing has a way of slamming around to find interesting
corner cases. Of course, intelligent fuzzing is required to advance into multi-leg, or
more complex, protocols. This will be discussed later in this book.
Fuzzing works against any application that accepts input, no matter what pro-
gramming language is used: Java, C++, C, C#, PHP, Perl, or others. However,
applications written in C and C++ are particularly susceptible to fuzzing. Compiled
C code is probably the fastest high-level language. For example, a network server
that needs to be able to run at very high speeds would not be written in Python
or Ruby, because it would be too slow. C would be the best choice for speed. This
is because C provides the programmer the ability to manage low-level operations,
such as memory management (malloc(), free(), etc.).
C and C++ are a hacker’s favorite target languages. This is because C code
traditionally handles its own memory; from static buffer declarations that lead to
stack overflows to heap allocations that can easily go wrong. With the ability to
optimize memory for speed comes the ability to shoot oneself in the foot. General
applications should never be managing their own memory these days. Computers
are fast, and programmers make too many mistakes. It only makes sense to code
in C and manage memory when an application’s speed is more important than an
application’s security, or you have to integrate with legacy code. In these (and really
all) applications, defensive coding should be the norm. Kernels are also written in
C/C++ out of necessity.
2.7.2 Defensive Coding
Defensive coding may also be known as defensive or secure programming. The
general goal is to reduce the number of bugs in software, make the source code
more readable, and keep the software from executing in unpredictable ways. The
following is a short list of some of the guidelines defensive programmers should
keep in mind:27
1. Reduce code complexity. Never make code more complex that it needs to
be; complexity equals bugs.
2. Source code reviews. All code should be reviewed using automatic source
code auditing tools. Many software development organizations have source
code scanning tools embedded in the build process, and they automatically
look for certain patterns and potentially dangerous functions. For example,
in C, strcpy() should never be used.
27 http://en.wikipedia.org/wiki/Defensive_programming.
6760 Book.indb 65 12/22/17 10:50 AM
66 Software Vulnerability Analysis
3. Quality control. All code should be thoroughly tested. Fuzz testing is a must
for applications with potentially vulnerable attack surfaces. This should be
part of a full security audit (design review, code review, fuzz testing, and so
on). Software testing is discussed more in Chapter 3.
4. Code reuse. If there are snippets that have been well tested, reuse is better
than a rewrite when applicable. This saves time (money) and is more secure.
Look out for legacy problems or buggy libraries, however.
5. Secure input/output handling. Nothing should be assumed about externally
supplied data. All user input should be rigorously verified before being used
by the application.
6. Canonicalization. Remember that on Unix-based operating systems /etc/
passwd is the same as /etc/.///passwd. Input string auditing may require the
use of canonicalization APIs to defend against such tricks.
7. Principle of least privilege. Avoid running software in privileged modes if
possible. Do not grant more privileges to the application than are needed.
8. Assume the worst. If similar applications have had bugs in a particular rou-
tine, assume your code does as well. This follows the Same Bug Different
Application (SBDA) theory, which holds true surprisingly often. A touch of
paranoia is good. All code is insecure even after testing. Defense in depth
is good.
9. Encrypt/authenticate. Encrypt everything transmitted over networks (when
possible). Local encryption may be employed as well. Use encryption librar-
ies. Mistakes are often made in home-grown encryption. Rolling custom
cryptography is often a bad idea. Use public libraries when possible.
10. Stay up to date. Exceptions can be better than return codes because they
help enforce intended API contracts, where lazy programmers may or may
not look at return codes. However, recently exception handlers are being
considered bad, because they are often used incorrectly.28
2.7.3 Input Verification
Input verification, or input handling, is how an application verifies the correctness
of data provided to it via an external source. Improper verification (sanitization)
has led to such bugs as directory traversals, code injections, buffer overflows, and
more. Some basic filter techniques are
• Whitelist. A list of known good inputs. This is a list that essentially says
“a, b, and c are ok; all else is to be denied.” Such a listing is best but is not
always possible.
• Blacklist. A list of known bad inputs. This list says, “all are ok, but deny x
and y.” This is not as effective as whitelisting because it relies on the program-
mer’s thinking of every possible troublesome input.
28 http://blogs.msdn.com/david_leblanc/archive/2007/04/03/exception-handlers-are-baaad.aspx.
6760 Book.indb 66 12/22/17 10:50 AM
2.7 Defenses 67
• Terminate on input problem. This approach terminates as soon as any problem
is found with the provided input data and logs the problem. Software assumes
it is under attack, and will terminate or block further communication.
• Filter input. Takes input, even bad input, and attempts to filter. For example,
if the ‘&’ is a disallowed character, “&jared” would be interpreted as “jared.”
This is not as secure as “Terminate on Input problem,” but often required.
• Formal grammar. Input data can also be verified via a formal grammar
such as XML. In this case, just make sure to use well-tested, secure verifica-
tion software.
Generally, the most secure way to filter input is to terminate on malformed
input by using whitelists.
2.7.4 hardware Overflow protection
Buffer overflows have been so troublesome for software developers (and so nice for
hackers) that both hardware and software protections have been developed. In this
section two hardware/software solutions are shown.
2.7.4.1 Secure Bit
Secure bit is an example of a hardware/software overflow solution, which was stud-
ied at Michigan State University. Secure bit is a technology developed to help reduce
the risks of buffer overflow attacks on control data (return addresses and function
pointers). Secure bit requires hardware (processor) and kernel OS modifications.
Secure bit is transparent to user software and is compatible with legacy code.
Secure bit works by marking addresses passed between buffers as insecure. This
is also known as user input tainting. Once data has been tainted, there is no way to
unmark it. If control instructions try to use these marked addresses, an exception
is raised. Robustness and minimal run-time impact are two impressive elements of
the secure bit technology.29
2.7.4.2 Hardware DEP
Data execution protection (DEP) is a Microsoft hardware/software solution to per-
form additional checks to help prevent malicious exploits from executing in memory.
In Windows Server 2003 with Service Pack 1, XP SP2, Vista and later operating
systems, DEP is enforced by both hardware and software.
Hardware-enforced DEP marks all noncode segments in a process as nonex-
ecutable unless the location explicitly contains executable code. Attacks such as
overflows attempt to insert and execute code from nonexecutable memory locations,
29 R. Enbody and K. Piromsopa, “Secure Bit: Transparent, Hardware Buffer-Overflow Protec-
tion,” IEEE Transactions on Dependable and Secure Computing, 3(4)(October 2006): 365–376.
ISSN:1545-5971.
6760 Book.indb 67 12/22/17 10:50 AM
68 Software Vulnerability Analysis
such as the stack or heap. DEP helps prevent these attacks by raising an exception
when execution is attempted from such locations.
Hardware-enforced DEP relies on processor hardware to mark memory with an
attribute that indicates that code should not be executed from that memory. DEP
functions on a per-virtual-memory-page basis, usually changing a bit in the page
table entry (PTE) to mark the memory page.
The actual hardware implementation of DEP and marking of the virtual memory
page varies by processor architecture. However, processors that support hardware-
enforced DEP are capable of raising an exception when code is executed from a
page marked with the appropriate attribute set.
Both Advanced Micro Devices (AMD) and Intel Corporation have defined and
shipped Windows-compatible architectures that are compatible with DEP.
32-bit versions of Windows Server 2003 with Service Pack 1 utilize the no-
execute page-protection (NX) processor feature as defined by AMD or the Execute
Disable bit (XD) feature as defined by Intel. In order to use these processor features,
the processor must be running in Physical Address Extension (PAE) mode. The
64bit versions of Windows use the NX or XD processor feature on 64-bit exten-
sion processors and certain values of the access rights page table entry (PTE) field
on IPF processors.
2.7.4.3 Control-flow Enforcement Technology
Control-flow enforcement technology (CET)30 is a hardware solution that is designed
to prevent usage of exploitation techniques that divert control flow instructions from
their original target address to an address pointed by the attacker, which happens
for example when the stack is overwritten. The main features in CET are shadow
stack and indirect branch tracking.
Shadow stack is designed to prevent attacker from altering the return address
after it is pushed in the stack. When activated, CALL instruction pushes the return
address to the data stack and shadow stack. On RET instruction the return address
is popped from both stacks and compared, if an attacker has modified the return
address the value from data stack is not equal to the value from shadow stack and
an exception is raised.
In addition to addresses in stack, program execution can also be changed in
to an address that is stored outside of the stack, with commands like call and jmp.
Indirect branch tracking implements a new ENDBRANCH instruction that is used
to mark valid target for this type of control flow changes. When the CPU executes
call or jump, the next instruction has to be ENDBRANCH, or an exception is raised.
2.7.5 Software Overflow protection
This section will present some of the software protections that are available to try
to mitigate the effects of buffer overflows. The idea is that no one protection is suf-
ficient and that a defense in depth strategy is required.
30 https://software.intel.com/sites/default/files/managed/4d/2a/control-flow-enforcement-technology-
preview.pdf.
6760 Book.indb 68 12/22/17 10:50 AM
2.7 Defenses 69
2.7.5.1 GS
The Buffer Security Check (“/GS” compile flag) is a Microsoft Visual Studio C++
compile option that works by placing a cookie (referred to as a canary in other
technologies) on the stack, between the return address and local variables, as each
function is called. This cookie is initialized to a new value each time the application
is run. The integrity of the cookie is checked before a function returns. If a buffer
overflow occurred, which normally overwrites a contiguous block of data values,
the cookie will have been altered, and the application will terminate with an error.
Guessing the cookie value is difficult, but much work has been done on defeating
canary-based stack protection.31,32
2.7.5.2 Software DEP
An additional set of DEP security checks has been added since Windows Server
2003 with Service Pack 1. These checks, known as software-enforced DEP, are
designed to mitigate exploits of exception handling mechanisms in Windows. By
default, software-enforced DEP protects only limited system binaries, regardless of
the hardware-enforced DEP capabilities of the processor.
Software-enforced DEP performs additional checks on exception handling
mechanisms in Windows. If the program’s image files are built with Safe Struc-
tured Exception Handling (SafeSEH), software-enforced DEP ensures that before
an exception is dispatched, the exception handler is registered in the function table
located within the image file.
If the program’s image files are not built with SafeSEH, software-enforced DEP
ensures that before an exception is dispatched, the exception handler is located
within a memory region marked as executable.
2.7.5.3 ASLR
Address space layout randomization (ASLR) randomizes the memory locations used
by system files and other programs, making it harder for exploits to call code from
process memory. ASLR was introduced in Windows Vista, and is used in subsequent
versions of Windows. This type of technology is widely used in all operating systems.
2.7.5.4 SafeSEH and more
Figure 2.9 shows all of the security enhancements added in the Vista platform.
Each of these will not be explained as that is not the focus of this book. However,
a few of the hardware and software protections have been discussed. SafeSEH will
be further detailed because it is very interesting to hackers.
There is a class of attacks used by hackers and security researchers, against
Windows, called an SEH overwrite. SEH is short for Structured Exception Handler.
31 D. Litchfield, “Defeating the Stack Based Overflow Prevention Mechanism of Microsoft Windows
2003 Server,” Sept. 2003, crypto.stanford.edu/cs155old/cs155-spring08/papers/litch.pdf.
32 Analysis of GS protections in Microsoft® Windows Vista™ Ollie Whitehouse, Architect, Symantec
Advanced Threat Research. http://www.symantec.com/avcenter/reference/GS_Protections_in_Vista
.pdf.
6760 Book.indb 69 12/22/17 10:50 AM
70 Software Vulnerability Analysis
Figure 2.9 Overview of Microsoft Windows Vista’s security enhancements. (Security Implications of
Microsoft® Windows Vista™,” Symantec Advanced Threat Research, www.symantec.com/avcenter/
reference/Security_Implications_of_Windows_Vista.pdf.)
In the case of a stack overflow, even if a return address cannot be affected, if an
exception handler address can be overwritten, malicious execution control can
still be obtained. On the next exception, Windows will attempt to execute code at
the address pointed to by the overwritten exception pointer. To limit the success
of such attacks, Microsoft developed SafeSEH, which is the heart of the Software
DEP described in the previous section. Again, SafeSEH works by not allowing an
SEH pointer to be an arbitrary value. It must point to a registered exception han-
dler (as opposed to some spot in the heap or stack like an attacker would prefer).
However, if the attack returns to code in any module not protected by SafeSEH,
the attack may still succeed.33
2.7.5.5 PAX and ExecShield
PAX from the GRSec family of kernel patches and ExecShield (originally from Red-
Hat) are both methods of marking data memory as nonexecutable and by marking
the program memory as nonwritable on the Linux operating systems. The result of
these protections is the lack of memory pages that are both writable and executable.
This method helps to protect the system from code that has been injected into the
process through a vulnerability. Although there has been heated debate and exploit
workarounds for both of these solutions, it is an excellent safeguard against most
33 More information about bypassing SafeSEH see for example http://sploitfun.blogspot.fi/2012/10/
bypassing-safeseh.html.
6760 Book.indb 70 12/22/17 10:50 AM
2.8 Summary 71
generic exploitation attempts. The exact implementation of these technologies has
subtle differences, and is worth investigating.
2.7.5.6 StackGuard
StackGuard is also a protection mechanism on Linux, but uses a slightly different
method than the previous two protections mentioned. It is more akin to the GS
compiler flag from Microsoft. StackGuard uses a canary value that gets checked
after a function call, and when destroyed, shows that a stack overflow has occurred
somewhere in the preceding code.
2.7.5.7 Control Flow Guard
Control Flow Guard (CFG) is a security feature in Windows platform that protects
from memory corruption vulnerabilities.34 CFG creates a link of valid memory
addresses where functions begin, restricting exploits to jump elsewhere in memory.
This feature is available in Microsoft Visual Studio 2015, and runs on CFG-Aware
versions of Windows—the x86 and x64 releases for the desktop and server of Win-
dows 10 and Windows 8.1 Update (KB3000850).35
2.8 Summary
Fuzzing used to be a secretive activity. Although developed through publicly avail-
able research, mostly only government agencies and underground hackers performed
fuzzing as part of their vulnerability assessment practices. But now, as is evidenced
by this book, it is an openly talked about subject. As fuzzing blends more and more
with the software development process, university courses that talk about fuzzing
have appeared. Fuzzing is already a frequent subject at most security conferences
like BlackHat, Defcon, Chaos Communication Congress (CCC), CanSecWest, and
Toorcon. A large percent of all vulnerabilities are reported to have been found via
fuzz testing.
Chapter 2 was intended to whet one’s appetite for bug hunting by presenting
various types of bugs, defenses, security career paths, and more. This hopefully has
made you hunger for the more in-depth chapters on fuzzing and available fuzz tools,
as well as given you a solid introduction into the security mindset and community
experiences of those who have worked for years in security.
34 https://msdn.microsoft.com/en-us/library/windows/desktop/mt637065.
35 https://documents.trendmicro.com/assets/wp/exploring-control-flow-guard-in-windows10.pdf.
6760 Book.indb 71 12/22/17 10:50 AM
6760 Book.indb 72 12/22/17 10:50 AM
C h a p t e r 3