(19)
(20)
(21)
with the following ratio:
ğ‘ƒ(ğœƒğ‘£|ğ‘šğ‘– = 1, ğ‘¥ğ‘–, ğ‘†)
ğ‘ƒ(ğœƒğ‘£|ğ‘šğ‘– = 0, ğ‘¥ğ‘–, ğ‘†) =
where
ğ‘ƒ(ğœƒ|ğ‘†âˆ’ğ‘–) =
ğœƒâ€² exp(âˆ’ğ‘™(ğ‘¥ğ‘–, ğœƒâ€²))ğ‘ƒ(ğœƒâ€²|ğ‘†âˆ’ğ‘–)ğ‘‘ğœƒâ€²
exp(âˆ’ğ‘™(ğ‘¥ğ‘–, ğœƒğ‘£))
âˆ«
exp(âˆ’ğ‘—â‰ ğ‘– ğ‘š ğ‘— Â· ğ‘™(ğ‘¥ ğ‘— , ğœƒ))
âˆ«
ğœƒâ€² exp(âˆ’ğ‘—â‰ ğ‘– ğ‘š ğ‘— Â· ğ‘™(ğ‘¥ ğ‘— , ğœƒâ€²))ğ‘‘ğœƒâ€²
(cid:18)âˆ«
ğ‘ƒ(ğ‘šğ‘– = 0) ) âˆ’ ğ‘™(ğ‘¥ğ‘–, ğœƒğ‘£)
(22)
(cid:19)
Putting things together, we have
ğ‘ƒ(ğ‘šğ‘– = 1|ğœƒğ‘£, ğ‘¥ğ‘–, ğ‘†) = ğœ[ log( ğ‘ƒ(ğ‘šğ‘– = 1)
ğœƒâ€²
âˆ’ log
exp(âˆ’ğ‘™(ğ‘¥ğ‘–, ğœƒâ€²))ğ‘ƒ(ğœƒâ€²|ğ‘†âˆ’ğ‘–)ğ‘‘ğœƒâ€²
]
(23)
The first term is equivalent to the log ratio of the prior probabil-
ity, i.e., the fraction of training data in the query set. In most of
our experiments, we use a balanced split which makes this term
vanish. Thus, only the second and last term will affect the attacker
prediction. Next, we investigate the last term. By applying Jensenâ€™s
inequality, we can bound the last term from above.
âˆ’ log
= âˆ’ log Eğœƒâ€² exp(âˆ’ğ‘™(ğ‘¥ğ‘–, ğœƒâ€²))
â‰¤ âˆ’Eğœƒâ€² log exp(âˆ’ğ‘™(ğ‘¥ğ‘–, ğœƒâ€²))
= Eğœƒâ€²ğ‘™(ğ‘¥ğ‘–, ğœƒâ€²)
(24)
Additionally, we can obtain the lower bound by taking the optimi-
mum over the full parameter space, i.e.
exp(âˆ’ğ‘™(ğ‘¥ ğ‘— , ğœƒâ€²))ğ‘ƒ(ğœƒâ€²|ğ‘†âˆ’ğ‘–)ğ‘‘ğœƒâ€²
(cid:18)âˆ«
(cid:19)
ğœƒâ€²
(cid:18)âˆ«
ğœƒâ€²
âˆ’ log
exp(âˆ’ğ‘™(ğ‘¥ ğ‘— , ğœƒâ€²))ğ‘ƒ(ğœƒâ€²|ğ‘†âˆ’ğ‘–)ğ‘‘ğœƒâ€²
(cid:19)
â‰¥ âˆ’ log max
ğœƒâ€²
ğ‘™(ğ‘¥ğ‘–, ğœƒâ€²)
= min
ğœƒâ€²
exp(âˆ’ğ‘™(ğ‘¥ğ‘–, ğœƒâ€²))
(25)
Under the assumption of a highly peaked posterior, e.g. uni-modal
Gaussian [57], we can well approximate this quantity by using one
sample, i.e. using one reference model that is not trained on the
query sample. Formally,
ğ‘ƒ(ğ‘šğ‘– = 1|ğœƒğ‘£, ğ‘¥ğ‘–, ğ‘†) â‰ˆ ğœ [âˆ’ğ‘™(ğ‘¥ğ‘–, ğœƒğ‘£) + ğ‘™(ğ‘¥ğ‘–, ğœƒğ‘Ÿ)]
= ğœ [âˆ’ğ¿(ğ‘¥, R(ğ‘¥|Gğ‘£)) + ğ¿(ğ‘¥, R(ğ‘¥|Gğ‘Ÿ)]
= ğœ [âˆ’ğ¿cal(ğ‘¥, R(ğ‘¥|Gğ‘£)]
(26)
where the dependence on ğ‘†, ğœƒğ‘£ is absorbed in the calibrated distance
ğ¿cal(ğ‘¥, R(ğ‘¥|Gğ‘£)).
Hence, the optimal attacker classifies ğ‘¥ğ‘– as in the training set if the
membership probability is sufficiently large, i.e., ğ¿cal(ğ‘¥, R(ğ‘¥|Gğ‘£))
is sufficiently small (than a threshold), following from the non-
decreasing property of ğœ.
â–¡
B EXPERIMENT SETUP
B.1 Hyper-parameter Setting
We fix ğ‘˜ to be 20k for evaluating the full black-box attacks. We set
ğœ†1 = 1.0, ğœ†2 = 0.2, ğœ†3 = 0.001 for our partial black-box and white-
box attack on CelebA, and set ğœ†1 = 1.0, ğœ†2 = 0.0, ğœ†3 = 0.0 for the
other cases. The maximum number of iterations for optimization
are set to be 1000 for our white-box attack and 10 for our partial
black-box attack.
B.2 Model Architectures
We use the official implementations of the victim GAN models.2 We
re-implement WGANGP model with a fully-connected structure
for non-image datasets. The network architecture is summarized in
Table 4. The depth of both the generator and discriminator is set to
5. The dimension of the hidden layer is fix to be 512 . We use ReLU
as the activation function for the generator and Leaky ReLU with
ğ›¼ = 0.2 for the discriminator, except for the output layer where
either the sigmoid or identity function is used.
Generator
(MIMIC-III)
FC (512)
ReLU
FC (512)
ReLU
FC (512)
ReLU
FC (512)
ReLU
FC (dim(ğ‘¥))
Sigmoid
Generator
(Instagram)
FC (512)
ReLU
FC (512)
ReLU
FC (512)
ReLU
FC (512)
ReLU
FC (dim(ğ‘¥))
Identity
Discriminator
(MIMIC-III and Instagram)
FC (512)
LeakyReLU (0.2)
FC (512)
LeakyReLU (0.2)
FC (512)
LeakyReLU (0.2)
FC (512)
LeakyReLU (0.2)
FC (1)
Identity
Table 4: Network architecutre of WGANGP on MIMIC-III
and Instagram.
B.3 Implementation of Baseline Attacks
We provide more details of implementing baseline attacks that are
discussed in Section 6.7.
LOGAN. For CelebA, we employ DCGAN as the attack model,
B.3.1
which is the same as in the original paper [25]. For MIMIC-III and
Instagram, we use WGANGP as the attack model.
B.3.2 MC. For implementing MC in the full black-box setting on
CelebA, we apply the same process of their best attack on the RGB
image dataset: First, we employ principal component analysis (PCA)
on a data subset disjoint from the query data. Then, we keep the
first 120 PCA components as suggested in the original paper [29]
and apply dimensionality reduction on the generated and query
data. Finally, we calculate the Euclidean distance of the projected
data and use the median heuristic to choose the threshold for MC
attack.
C ADDITIONAL RESULTS
C.1 Sanity-check in the White-box Setting
C.1.1 Analysis on optimization initialization. Due to the non-convexity
of our optimization problem, the choice of initialization is of great
importance. We explore three different initialization heuristics in
2
https://github.com/tkarras/progressive_growing_of_gans,
https://github.com/igul222/improved_wgan_training,
https://github.com/carpedm20/DCGAN-tensorflow,
https://github.com/mp2893/medgan,
https://drive.google.com/drive/folders/10RCFaA8kOgkRHXIJpXIWAC-
uUyLiEhlY
âˆ¥Gğ‘£(ğ‘§)âˆ’ğ‘¥âˆ¥2
our experiments, including mean (ğ‘§0 = ğœ‡), random (ğ‘§0 âˆ¼ N(ğœ‡, Î£)),
and nearest neighbour (ğ‘§0 = argminğ‘§âˆˆ{ğ‘§ğ‘– }ğ‘˜
2). We find
ğ‘–=1
that the mean and nearest neighbor initializations perform well
in practice, and are in general better than random initialization
in terms of the successful reconstruction rate (reconstruction er-
ror smaller than 0.01). Therefore, we apply the mean and nearest
neighbor initialization in parallel, and choose the one with smaller
reconstruction error for the attack.
C.1.2 Analysis on Optimization Method. We explore three opti-
mizers with a range of hyper-parameter search: Adam [39], RM-
SProp [63], and L-BFGS [46] for reconstructing generated samples
of PGGAN on CelebA. Figure 13 shows that L-BFGS achieves supe-
rior convergence rate with no additional hyper-parameter. There-
fore, we select L-BFGS as our default optimizer in the white-box
setting.
Figure 13: Convergence rate of various optimizers (Adam,
RMSProp, L-BFGS) with different learning rates. Mean ini-
tialization (ğ‘§0 = ğœ‡) is applied in this analysis study.
C.1.3 Analysis on Distance Metric Design for Optimization. We
show the effectiveness of our objective design (Equation 8). Al-
though optimizing only for element-wise difference term ğ¿2 yields
reasonably good reconstruction in most cases, we observe unde-
sired blur in reconstruction for CelebA images. Incorporating deep
image feature term ğ¿lpips and regularization term ğ¿reg benefits the
successful reconstruction rate. See Figure 14 for a demonstration.
Table 5: Successful reconstruction rate for generated sam-
ples from different GANs.
Success rate (%)
DCGAN PGGAN WGANGP VAEGAN
99.89
99.25
99.83
99.55
Sanity Check on Distance Metric Design for Optimization. In
C.1.4
addition, we check if the non-convexity of our objective function
affects the feasibility of attack against different victim GANs. We
apply optimization to reconstruct generated samples. Ideally, the
reconstruction should have no error because the query samples are
directly generated by the model, i.e., their preimages exist. We set a
030060090012001500iterations0.000.050.100.150.200.250.300.35reconstructionerrorAdam,lr=0.001Adam,lr=0.002Adam,lr=0.005Adam,lr=0.010Adam,lr=0.015Adam,lr=0.020Adam,lr=0.025RMSProp,lr=0.001RMSProp,lr=0.002RMSProp,lr=0.005RMSProp,lr=0.010RMSProp,lr=0.015RMSProp,lr=0.020RMSProp,lr=0.025L-BFGS(a)
(b)
(c)
Figure 14: Reconstruction error plots of PGGAN-generated samples on CelebA. The x-axis represents the Euclidean distance
between a reconstructed latent code to its ground truth value. The y-axis represents the ğ¿2 residual in the image domain. The
images in orange frame are generated samples. Their reconstructed copies are shown on their right. Samples below the dashed
line have reconstruction residuals smaller than 0.01, where no visual difference can be observed. Therefore, the reconstruction
is in general better if there is a higher portion of sample points below the dashed line (a higher successful reconstruction rate).
(a) Reconstruction results when disabling ğ¿lpips and ğ¿reg (ğœ†1 = 1.0, ğœ†2 = 0, ğœ†3 = 0). (b) Reconstruction results when disabling ğ¿reg
(ğœ†1 = 1.0, ğœ†2 = 0.2, ğœ†2 = 0). (c) Reconstruction results when enabling all the ğ¿2, ğ¿lpips and ğ¿reg terms (ğœ†1 = 1.0, ğœ†1 = 0.2, ğœ†2 = 0.001).
We find that using all the terms most benefits the reconstruction.
threshold of 0.01 to the reconstruction error for counting successful
reconstruction rate, and evaluate the success rate for four GAN
models trained on CelebA. Table 5 shows that we obtained more
than 99% success rate for all the GANs, which verifies the feasibility
of our optimization-based attack.
C.1.5 Analysis on Distance Metric Design for Classification. We
propose to enable/disable ğœ†1, ğœ†2, or ğœ†3 in Equation 8 to investigate
the contribution of each term towards classification thresholding
(membership inference) on CelebA. In detail, we consider using (1)
the element-wise difference term ğ¿2 only, (2) the deep image feature
term ğ¿lpips only, and (3) all the three terms together to evaluate
attack performance. Figure 15 shows the AUCROC of attack against
each various GANs. We find that our complete distance metric
design achieves general superiority to single terms. Therefore, we
use the complete distance metric for classification thresholding.
Figure 15: White-box attack performance against GANs on
CelebA, w.r.t. distance metric design for classification.
C.2 Additional Quantitative Results
C.2.1 Evaluation on Full Black-box Attack. Attack Performance
w.r.t. Training Set Size: Table 6 corresponds to Figure 5(a), Fig-
ure 5(b), and Figure 5(c) in the main paper.
PGGAN
WGANGP
64
1.00
1.00
128
1.00
1.00
64
WGANGP
0.98
MEDGAN 0.78
128
0.97
0.65
(a) CelebA
512
256
0.99
1.00
1.00
0.97
(b) MIMIC-III
512
256
0.87
0.93
0.57
0.54
(c) Instagram
1024
0.95
0.89
2048
0.79
0.72
4096
0.58
0.62
20k
0.51
0.51
1024
0.81
0.52
2048
0.68
0.52
4096
0.54
0.51
8192
0.52
0.51
WGANGP
64
1.00
128
1.00
256
0.97
512
0.90
1024
0.72
2048
0.54
4096
0.50
8192
0.50
10k
0.50
Table 6: Full black-box attack performance w.r.t. training set
size.
Attack Performance w.r.t. Training Set Selection: Table 7 cor-
responds to Figure 6 in the main paper.
C.2.2 Evaluation on Partial Black-box Attack. Attack Performance
w.r.t. Training Set Selection: Table 7 corresponds to Figure 6 in
the main paper.
051015202530zspaceeuclideandistance0.000.020.040.060.080.10pixelspaceeuclideandistance99.395%L2051015202530zspaceeuclideandistance0.000.020.040.060.080.10pixelspaceeuclideandistance99.735%L2+Llpips051015202530zspaceeuclideandistance0.000.020.040.060.080.10pixelspaceeuclideandistance99.825%L2+Llpips+LregPGGANWGANGPDCGANVAEGAN0.50.60.7AUCROCCelebAL2LlpipsL2+Llpips+Lreg(a) Full black-box
PGGAN WGANGP DCGAN VAEGAN
random
identity
0.51
0.53
0.51
0.53
0.51
0.51
0.50
0.51
PGGAN
WGANGP