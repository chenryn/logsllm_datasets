interrupts may be routed to either non-secure state exception handlers, or secure
state exception handlers based on the SAU conﬁguration. Figure 1 denotes a
typical memory layout for a TZ-M equipped device. Each memory region known
to the SAU may be declared as either Non-Secure (❶), Secure (❷) or Secure Non-
Secure Callable (NSC ❸). While Secure memory contains the secure program
image and data, the NSC memory contains secure gateway veneers 4, i.e., branch
instructions (❼) which point to the actual subroutine code in Secure memory
(❹). The purpose of the NSC is to prevent non-secure program code to branch
into invalid entry points in secure program code (such as into the middle of a
function, as is often done in atleast ROP). To this end, the ARMv8-M instruction
set also introduces a Secure Gateway (sg) instruction, which is included in the
beginning of each veneer (❻) and acts as a call gate to the secure program code.
From the non-secure program code a call to a secure subroutine is performed
using a regular bl instruction (❺), targeting the corresponding veneer in the
NSC. Calls targeting a memory address in the NSC will automatically cause
a context switch to secure state, and the processor will validate that the call
targets a valid entry point with a sg instruction. In particular, calls from non-
secure state calling secure memory outside the NSC, or non-sg instructions in
the NSC will fail in a Secure Fault, a new type of hardware exception which
always traps into secure state. Secure subroutines return by executing a bxns
lr instruction (❽), which otherwise behaves like a return through bx lr, but
additionally switches the processor to non-secure state.
3 Problem Statement
3.1 Code-Reuse Attacks on ARM
Code-reuse attacks are a class of software exploits that allow attackers to exe-
cute arbitrary code on a compromised device, even in the presence of hardware
countermeasures against code injection, such as W⊕X [28]. In a return-to-libc
attack [45], the subroutine return address on the call stack is replaced by the
address of an entry point to a subroutine in the executable memory of a process.
The technique has been generalized into Return-Oriented Programming [44]
(ROP) for the x86 architecture, which has since become the exploitation tech-
nique of choice for modern memory-safety vulnerability attacks. Subsequently
ROP has been extended to various other CPU architectures [6,9,21], including
ARM microprocessors [32].
Many code-reuse attacks on x86 platforms use unintended instruction
sequences found by performing a branch into the middle of otherwise benign
instructions. Such unintended sequences cannot be formed in the 32-bit ARM,
4 http://www.keil.com/support/man/docs/armclang link/armclang link
pge1444644885613.htm.
CFI CaRE: Hardware-Supported Call and Return Enforcement
265
or in the 16-bit Thumb instruction sets where branch target alignment is enforced
on instruction load, and hence may only target the intended instruction stream.
However, the presence of both 32-bit and 16-bit instructions in Thumb-2 code
introduces ambiguity when decoding program code from memory. When decod-
ing Thumb-2 instructions, ARM processors still enforce 2-byte alignment on
instruction fetches, but the variable-length encoding allows the second half-word
in a 32-bit Thumb-2 instruction to be interpreted as the ﬁrst half-word of an
unintended instruction. Such unintended instructions have been successfully uti-
lized in prior work [35,36] to exploit ARM code.
It has been shown that, on both x86 and ARM, it is also possible to perform
ROP attacks without the use of return instructions [8] in what has become to
be known as Jump-Oriented Programming (JOP). On ARM platforms, JOP can
be instantiated using indirect subroutine calls.
3.2 Control-Flow Integrity
A well known approach to address code-reuse attacks is enforcing the Control-
Flow Integrity (CFI) of the code. The execution of any program can be abstractly
represented as a Control-Flow Graph (CFG), where nodes represent blocks
of sequental instructions (without intervening branches), and edges represent
control-ﬂow changes between such nodes (branch instructions). CFI enforcement
strives to ensure that the execution of the programs conforms to a legitimate
path in the program’s CFG. CFI builds on the assumption that program code
in memory is not writable (i.e., that memory pages can be marked W⊕X) as
a countermeasure against code injection attacks. Code immutability allows CFI
checks to be omitted for nodes in the CFG that end in direct branch instruc-
tions [2,20], i.e., branches with a statically determined target oﬀset. As a result,
CFI is typically applied to nodes in the CFG that end in an indirect branch.
Indirect branches are typically emitted for switch-case statements, subroutine
returns, and indirect calls (subroutine calls to dynamic libraries, calls through
function pointers, e.g. callbacks, as well as C++ virtual functions).
While the construction of the CFG can occur through static inspection of
the program binary, the actual enforcement of CFI must occur at runtime. In
inlined CFI enforcement the checks that validate control-ﬂow changes are inter-
spersed with the original program code at subroutine call sites, as well as in the
subroutine prologue and epilogue. The insertion of these checks can be achieved
through compiler extensions [10], or by binary machine-code rewriting. Binary
instrumentation that adds additional instructions to a pre-built program binary
by necessity modiﬁes the memory layout of the code, and hence will require
memory addresses referenced by the program to be adjusted accordingly.
Traditional ROP targets return instructions that read the return address oﬀ
the program stack. A well known technique to enforce that subroutine returns
target the original call site is the notion of a shadow call stack [14]. The shadow
call stack is used to hold a copy of the return address. On subroutine return the
return address on the shadow call stack is compared to the return address on
the program stack. If they match, the return proceeds as usual. A mismatch in
266
T. Nyman et al.
return addresses on the other hand indicates a failure of CFI and triggers an
error which terminates the program prematurely. Recent results show that, in
fact, shadow stacks are essential for the security of CFI [7].
3.3 CFI Challenges for Microcontrollers
We identify the following challenges in realizing CFI protection on IoT devices:
– Interrupt awareness: Since the software to be protected is a single,
interrupt-driven bare-metal program, the CFI scheme needs to handle both
interruptible code, as well as execution in interrupt contexts. To the best of
our knowledge, no existing CFI scheme meets this requirement.
– Hardware-based shadow stack protection: Protection of shadow stack
must leverage lightweight hardware-based trust anchors like TrustZone-M.
The code size and performance overhead of purely software-based CFI is pro-
hibitive on resource constrained devices and techniques for general purpose
computing devices often rely on hardware (such as x86 segmentation sup-
port [2]) that is unavailable in simple MCUs.
– Layout-preserving instrumentation: Since software for MCUs is com-
monly deployed as monolithic ﬁrmware images with strict size requirements,
CFI instrumentation must preserve memory layout of the image so as to avoid
extensive rewriting and to minimize the increase in code size.
– On-device instrumentation: To avoid having to rely on the developer (or
some other external entity) to perform the required instrumentation, the CFI
scheme must be amenable to on-device instrumentation.
3.4 Adversarial Model
We consider a powerful adversary with arbitrary read-access to code memory
and arbitrary read-write access to data memory of the non-secure state program.
This model accounts for buﬀer overﬂows or other memory-related vulnerabili-
ties (e.g. an externally controlled format string5) that, in practice, would allow
adversaries to gain such capabilities. The adversary cannot modify code memory,
a property that is achievable even on MCU class systems through widespread
countermeasure against code injection (e.g. MPU-based W⊕X). Nevertheless,
arbitrary read-access necessitates a solution that is able to withstand informa-
tion disclosure (the strongest attack scenario in Dang et al.s [14] evaluation of
prior work on CFI). Our threat model is therefore similar to previous work on
CFI, but we also consider an even stronger adversary who can exploit interrupt
handling to undermine CFI protection.
This model applies even when an attacker is in active control of a module or
thread within the same address space as the non-secure state program, such as
gaining control of an unprotected co-processor on the System-On-Chip (SoC).
5 CWE-134: Use of Externally-Controlled Format String https://cwe.mitre.org/data/
deﬁnitions/134.html.
CFI CaRE: Hardware-Supported Call and Return Enforcement
267
However, the adversary lacks the ability to read or modify memory allocated to
the secure state software.
In this work, we do not consider non-control data attacks [46] such as Data-
Oriented Programming [29]. This class of attacks can achieve privilege escalation,
leak security sensitive data or even Turing-complete computation by corrupting
memory variables that are not directly used in control-ﬂow transfer instructions.
This limitation also applies to prior work on CFI.
4 CFI CaRE
We now present CaRE (Call and Return Enforcement), our solution for ensuring
control-ﬂow integrity. CaRE speciﬁcally targets constrained IoT devices, which
are expected to stay active in the ﬁeld for a prolonged time and operate unat-
tended with network (Internet) connectivity, possibly via IoT gateways. This
kind of deployment necessitates the incorporation of software update mechanisms
to ﬁx vulnerabilities, update conﬁguration settings and add new functionality.
We limit our scope to small, more or less bare-metal IoT devices. The system
software is deployed as monolithic, statically linked ﬁrmware images. The secure
and non-secure state program images are distinct from each other [1], with the
secure state software stack structured as a library. The conﬁguration of the SAU
and the secure state program image is performed before the non-secure code is
started. The entry to the secure state library happens through a well-deﬁned
interface describing the call gates available to non-secure software. Functions
in the secure state are synchronous and run to completion unless interrupted
by an exception. The system is interrupt-driven, reacting to external triggers.
While it is possible that the non-secure state software is scheduled by a simple
Real-Time Operating System (RTOS), the secure state software does not have
separate scheduling or isolation between distinct software components for the
simple reason that the device is single-purpose rather than a platform for running
many programs from many stakeholders in parallel. Even when an RTOS is
present, it is seldom necessary for non-secure state code to support dynamic
loading of additional code sequences.
4.1 Requirements
Given the above target deployment scenario, we formulate the following require-
ments that CaRE should meet:
Requirement 1. It must reliably prevent attacks from redirecting the ﬂow of
execution of the non-secure state program.
Requirement 2. It must be able to protect system software written in standard
C and assembler conformant to the AAPCS.
Requirement 3. It must have minimal impact on the code footprint of the non-
secure state program.
268
T. Nyman et al.
Requirement 4. Its performance overhead must be competitive compared to the
overhead of software-based CFI schemes.
We make the following assumptions about the target device:
Assumption 1. A trust anchor, such as TZ-M, which enables isolated code
execution and secure storage of data at runtime is available.
Assumption 2. All (secure and non-secure) code is subject to a secure boot
sequence that prevents tampering of program and update images at rest. This
bootstrap sequence itself is not vulnerable to code-reuse attacks, and routines in
the bootstrap code are not invoked again after the device startup completes.
Assumption 3. All code is non-writable. It must not be possible for an attacker
to modify the program code in memory at runtime.
Assumption 4. All data is non-executable. It must not be possible for an
attacker to execute data as it were code. Otherwise, an attacker will be able
to mount code injection attacks against the device.
Assumption 1 is true for commercial oﬀ-the-shelf ARMv8-M MCUs. There
also exist several research architectures, such as SMART [18], SANCUS [40], and
Intel’s TrustLite [31] that provide equivalent features. Assumption 2 is true for
currently announced ARMv8-M SoCs6. Assumptions 3 and 4 are in line with
previous work on CFI and can be easily achieved on embedded devices that are
equipped with MPUs. These assumptions can be problematic in the presence of
self-modifying code, runtime code generation, and unanticipated dynamic load-
ing of code. Fortunately, most embedded system software in MCUs is typically
statically linked and written in languages that compile directly to native code.
Even when an RTOS is present, it is seldom necessary for non-secure state code
to support dynamic loading of additional code sequences.
4.2 Architecture
Our design incorporates protection of a shadow call stack on low-end ARM
embedded devices featuring TZ-M. The shadow call stack resides in secure mem-
ory, and is only accessible when the processor executes in the secure state. We
also propose a layout-preserving binary instrumentation approach for Thumb
code, with small impact to code footprint, and an opportunity for on-device
instrumentation as part of code installation. The main aspect of this property is
that the binary program image is rewritten without aﬀecting its memory layout.
Figure 2 shows an overview of the CaRE architecture.
The premise for CaRE is instrumentation of non-secure state code in a man-
ner which removes all function calls and indirect branches and replaces them with
dispatch instructions that trap control ﬂow to a piece of monitor code, the Branch
6 https://www.embedded-world.de/en/ausstellerprodukte/embwld17/product-98637
96/numicro-m2351-series-microcontroller.
CFI CaRE: Hardware-Supported Call and Return Enforcement
269
Monitor (❶), which runs in non-secure state. As a result, each subroutine call
and return is now routed through the Branch Monitor. The Branch Monitor
maintains the shadow stack by invoking secure functions (❷) only callable from
the Branch Monitor, before transferring control to the original branch target.
Other indirect branches, such as ones used to branch into switch case jump tables
can be restricted by the Branch Monitor to a suitable range and to target direct
branches in jump table entries. Thus, the Branch Monitor provides complete
mediation of instrumented non-secure state code.
Apart from the Branch Monitor, the program image also contains bootstrap
routines (labeled bn) that are used to initialize the runtime environment (❸).
Such routines may initially need to operate without a stack and other mem-
ory structures in place, and as such are typically hand written in assembler.
Due to these constraints, the bootstrap routines are likely to deviate from usual
AAPCS conventions. In particular, all calls are not guaranteed to result in a
subsequent matching return as fragments of bootstrap routines may simply be
chained together until eventually transferring control to the named C entry point
marking the beginning of main program code. On the other hand, the initializa-
tion code is typically not entered again after control has been transfered to the
main function until the device is reset.
Hence, from the perspective of maintaining control-ﬂow integrity, both the
Branch Monitor and bootstrap code exist outside benign execution paths encoun-
tered in the program during normal operation. Henceforth, we will refer to the
code reachable from the main function as the main program. The CFG nodes
labeled fn in Fig. 2 represent the instrumented main program (❹). The main
program and bootstrap code do not share any routines (Assumption 2), even
though routines belonging to one or the other may be interleaved in program
memory. The main program code constitutes a strongly connected component
within the call graph 7. This observation leads us to consider the main program
code as a complete ensemble in terms of instrumentation target. It can include
an RTOS and/or interrupt handlers. Interrupts handlers labeled hn (❺), with
the exception of the supervisor call handler that hosts the Branch Monitor, are
considered to be part of the main program. Conceptually, interrupts may be
reached from any node in the program’s CFG.
By eliminating non-mediated calls and returns in the non-secure state main
program, thus forcing each indirect branch through the Branch Monitor, we can
unequivocally eliminate control-ﬂow attacks that utilize such branches.
4.3 Instrumentation