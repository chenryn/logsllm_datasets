### References

1. **Private Linear Branching Programs with Medical Applications**  
   ESORICS 2009, Volume 5789 of LNCS, Pages 424–439. Springer, 2009.

2. **The Round Complexity of Secure Protocols**  
   D. Beaver, S. Micali, and P. Rogaway. Proceedings of the Twenty-Second Annual ACM Symposium on Theory of Computing, Pages 503–513. ACM, 1990.

3. **Foundations of Garbled Circuits**  
   M. Bellare, V. Hoang, and P. Rogaway. Cryptology ePrint Archive, Report 2012/265, 2012.

4. **The Security of Triple Encryption and a Framework for Code-Based Game-Playing Proofs**  
   M. Bellare and P. Rogaway. EUROCRYPT 2006, Volume 4004 of LNCS, Pages 409–426. Springer, 2006.

5. **One-Round Secure Computation and Secure Autonomous Mobile Agents**  
   C. Cachin, J. Camenisch, J. Kilian, and J. Müller. 27th Intl. Colloquium on Automata, Languages, and Programming — ICALP 2000, Pages 512–523. Springer, 2000.

6. **Structured Encryption and Controlled Disclosure**  
   M. Chase and S. Kamara. ASIACRYPT 2010, Volume 6477 of LNCS, Pages 577–594. Springer, 2010.

7. **A Minimal Model for Secure Computation (Extended Abstract)**  
   U. Feige, J. Kilian, and M. Naor. 26th ACM STOC, Pages 554–563. ACM Press, 1994.

8. **Privacy-Preserving Credit Checking**  
   K. Frikken, M. Atallah, and C. Zhang. Proceedings of the 6th ACM Conference on Electronic Commerce, Pages 147–154. ACM, 2005.

9. **Non-Interactive Verifiable Computing: Outsourcing Computation to Untrusted Workers**  
   R. Gennaro, C. Gentry, and B. Parno. CRYPTO 2010, Volume 6223 of LNCS, Pages 465–482. Springer, 2010.

10. **Cryptography and Cryptographic Protocols**  
    O. Goldreich. Manuscript, 2001.

11. **How to Play Any Mental Game, or a Completeness Theorem for Protocols with Honest Majority**  
    O. Goldreich, S. Micali, and A. Wigderson. 19th ACM STOC, Pages 218–229. ACM Press, 1987.

12. **One-Time Programs**  
    S. Goldwasser, Y. Kalai, and G. Rothblum. CRYPTO 2008, Volume 5157 of LNCS, Pages 39–56. Springer, 2008.

13. **Efficient Two Party and Multi-Party Computation Against Covert Adversaries**  
    V. Goyal, P. Mohassel, and A. Smith. EUROCRYPT 2008, Volume 4965 of LNCS, Pages 289–306. Springer, 2008.

14. **Secure Guaranteed Computation**  
    A. Herzberg and H. Shulman. Cryptology ePrint Archive, Report 2010/449, 2010.

15. **Faster Secure Two-Party Computation Using Garbled Circuits**  
    Y. Huang, D. Evans, J. Katz, and L. Malka. USENIX Security Symposium, 2011.

16. **Efficient Secure Computation with Garbled Circuits**  
    Y. Huang, C. Shen, D. Evans, J. Katz, and A. Shelat. ICISS, Volume 7093 of Lecture Notes in Computer Science, Pages 28–48. Springer, 2011.

17. **Randomizing Polynomials: A New Representation with Applications to Round-Efficient Secure Computation**  
    Y. Ishai and E. Kushilevitz. 41st FOCS, Pages 294–304. IEEE Computer Society Press, 2000.

18. **Perfect Constant-Round Secure Computation via Perfect Randomizing Polynomials**  
    Y. Ishai and E. Kushilevitz. ICALP, Volume 2380 of Lecture Notes in Computer Science, Pages 244–256. Springer, 2002.

19. **Cryptography with Constant Computational Overhead**  
    Y. Ishai, E. Kushilevitz, R. Ostrovsky, and A. Sahai. 40th ACM STOC, Pages 433–442. ACM Press, 2008.

20. **Outsourcing Multi-Party Computation**  
    S. Kamara, P. Mohassel, and M. Raykova. Cryptology ePrint Report 2011/272, 2011.

21. **Special-Purpose Garbled Circuits**  
    S. Kamara and L. Wei. Unpublished Manuscript.

22. **Round-Optimal Secure Two-Party Computation**  
    J. Katz and R. Ostrovsky. CRYPTO 2004, Volume 3152 of LNCS, Pages 335–354. Springer, 2004.

23. **Improved Garbled Circuit: Free XOR Gates and Applications**  
    V. Kolesnikov and T. Schneider. ICALP 2008, Part II, Volume 5126 of LNCS, Pages 486–498. Springer, 2008.

24. **Billion-Gate Secure Computation with Malicious Adversaries**  
    B. Kreuter, A. Shelat, and C. Shen. Proceedings of the 21st USENIX Security Symposium (USENIX 2012), 2012.

25. **Secure Function Evaluation with Ordered Binary Decision Diagrams**  
    L. Kruger, S. Jha, E. Goh, and D. Boneh. ACM CCS 06, Pages 410–420. ACM Press, 2006.

26. **An Efficient Protocol for Secure Two-Party Computation in the Presence of Malicious Adversaries**  
    Y. Lindell and B. Pinkas. EUROCRYPT 2007, Volume 4515 of LNCS, Pages 52–78. Springer, 2007.

27. **A Proof of Security of Yao’s Protocol for Two-Party Computation**  
    Y. Lindell and B. Pinkas. Journal of Cryptology, 22(2):161–188, 2009.

28. **Secure Two-Party Computation via Cut-and-Choose Oblivious Transfer**  
    Y. Lindell and B. Pinkas. TCC 2011, Volume 6597 of LNCS, Pages 329–346. Springer, 2011.

29. **Fairplay — A Secure Two-Party Computation System**  
    D. Malkhi, N. Nisan, B. Pinkas, and Y. Sella. Proceedings of the 13th Conference on USENIX Security Symposium-Volume 13, Pages 20–20. USENIX Association, 2004.

30. **Efficiency Tradeoffs for Malicious Two-Party Computation**  
    P. Mohassel and M. Franklin. PKC 2006, Volume 3958 of LNCS, Pages 458–473. Springer, 2006.

31. **Communication Preserving Protocols for Secure Function Evaluation**  
    M. Naor and K. Nissim. 33rd ACM STOC, Pages 590–599. ACM Press, 2001.

32. **Privacy Preserving Auctions and Mechanism Design**  
    M. Naor, B. Pinkas, and R. Sumner. Proceedings of the 1st ACM Conference on Electronic Commerce, Pages 129–139. ACM, 1999.

33. **Practical Secure Evaluation of Semi-Private Functions**  
    A. Paus, A. Sadeghi, and T. Schneider. ACNS 09, Volume 5536 of LNCS, Pages 89–106. Springer, 2009.

34. **A Leakage-Resilient Mode of Operation**  
    K. Pietrzak. EUROCRYPT 2009, Volume 5479 of LNCS, Pages 462–482. Springer, 2009.

35. **Cryptographic Techniques for Privacy-Preserving Data Mining**  
    B. Pinkas. ACM SIGKDD Explorations Newsletter, 4(2):12–19, 2002.

36. **Secure Two-Party Computation is Practical**  
    B. Pinkas, T. Schneider, N. P. Smart, and S. C. Williams. ASIACRYPT 2009, Volume 5912 of LNCS, Pages 250–267. Springer, 2009.

37. **The Round Complexity of Secure Protocols**  
    P. Rogaway. MIT Ph.D. Thesis, 1991.

38. **Worry-Free Encryption: Functional Encryption with Public Keys**  
    A. Sahai and H. Seyalioglu. ACM CCS 10, Pages 463–472. ACM Press, 2010.

39. **Engineering Secure Two-Party Computation Protocols – Advances in Design, Optimization, and Applications of Efficient Secure Function Evaluation**  
    T. Schneider. PhD thesis, Ruhr-University Bochum, Germany, February 9, 2011.  
    [http://thomaschneider.de/papers/S11Thesis.pdf](http://thomaschneider.de/papers/S11Thesis.pdf)

40. **Engineering Secure Two-Party Computation Protocols**  
    T. Schneider. Springer, Berlin Heidelberg, 2012.

41. **Privacy Preserving Error Resilient DNA Searching Through Oblivious Automata**  
    J. R. Troncoso-Pastoriza, S. Katzenbeisser, and M. Celik. ACM CCS 07, Pages 519–528. ACM Press, 2007.

42. **How to Generate and Exchange Secrets**  
    A. Yao. Foundations of Computer Science, 1986., 27th Annual Symposium on, Pages 162–167. IEEE, 1986.

43. **Protocols for Secure Computations**  
    A. C. Yao. 23rd FOCS, Pages 160–164. IEEE Computer Society Press, 1982.

### Appendix: Related Work

We do not attempt a comprehensive review of the literature, but we elaborate on some selected prior work.

#### Randomized Encodings
Loosely related to garbling schemes, randomized encodings (initially randomized polynomials) were introduced by Ishai and Kushilevitz [25] and have been further developed by Applebaum, Ishai, Kushilevitz, and others [2–6, 26, 27, 46]. The authors use language such as: a function \( F(x, r) \) is a randomized encoding of \( f(x) \) if:
- (Correctness) There exists a polynomial-time (PT) algorithm \( \text{De} \) such that \( \text{De}(F(x, r)) = f(x) \) for almost all \( r \).
- (Privacy) There exists a PT algorithm \( \text{Sim} \) such that the ensembles \( F(x, r) \) and \( \text{Sim}(f(x)) \) are computationally indistinguishable.

To be useful, encodings must have additional properties, such as decomposability, where every bit of \( F(x, r) \) depends on at most one bit of \( x \). Proven realizations meeting these requirements [3, 4] do not closely resemble conventional realizations of garbled circuits [35, 40].

There is a significant syntactic gap between the notion of randomized encodings and a garbling scheme. In the former, no language is provided to describe the algorithm that transforms \( f \) to \( F \); in contrast, this transformation is central to a garbling scheme. Additionally, the syntax of randomized encodings does not address the representation of functions, which is explicit and central in garbling schemes. Finally, the syntax does not separate the garbling of a function and the creation of a garbled input, unlike a garbling scheme.

#### Obscuring Topology
We are not the first to observe that conventional means to garble a circuit obscure each gate's function but not its topology. A 2002 paper by Pinkas [43] (Section 2.3) already notes that "In this form the representation reveals nothing but the wiring of the circuit." Later, Paus, Sadeghi, and Schneider [41] use the phrase "circuit topology" to name what is revealed by conventional garbled circuits. However, the topology of a circuit has never been formalized, and no one has proven that a particular scheme reveals only the topology. We are also the first to explain the equivalence between the prv.sim and prv.ind notions relative to \( \Phi_{\text{topo}} \).

#### Eclectic Representations
Scattered throughout the literature, one finds various computational objects being garbled, including arithmetic circuits [6], branching programs [9], circuits with lookup tables [39], DFAs [49], and ordered binary decision diagrams [33]. This range suggests that general-purpose definitions for garbling schemes should not be tied to circuits.

#### Concurrent Work
Concurrent work by Kamara and Wei (KW) investigates the garbling of structured circuits [29], a computational model resembling ordinary circuits except that gates perform operations on an arbitrary data structure. KW define what they call a garbling scheme, with a syntax similar to ours but without the function ev. They define Ind1 and Sim1 security, which ask only for input-hiding, not function hiding. They show these definitions are equivalent for sampleable circuits and provide dynamic versions (Ind2 and Sim2) and an unforgeability notion (Unf2). These definitions resemble the weaker forms of the dynamic-security definitions (prv1, obv1, and aut1) mentioned in our Introduction and the subject of separate work.

Although KW speak of circuits as finitary objects described by DAGs, they appear to have in mind families of circuits indexed by a security parameter. Unlike our treatment, circuits are not provided by the adversary; security notions are with respect to a given circuit. A garbling scheme is provided in KW, but it is not a "conventional" one: it garbles a structured circuit and is based on a collection of structured encryption schemes, a notion from Chase and Kamara [14].

#### Obliviousness and Authenticity
Some prior papers exploit the obliviousness and authenticity of garbled circuits to achieve desired applications, such as private medical diagnostics [9], verifiable computation and private verifiable computation [17], and correctable verifiable computation [5]. These notions are not seen as properties of a stand-alone primitive corresponding to a garbling scheme.

In the last of the works mentioned, Applebaum, Ishai, and Kushilevitz [5] describe generic transformations from privacy to obliviousness and to authenticity:
1. **Obliviousness**: Instead of garbling a circuit \( f \), let \( g \) be a circuit such that \( g(x \parallel r) = f(x) \oplus r \) for every \( x \in \{0, 1\}^n \) and \( r \in \{0, 1\}^m \). Then, choose \( r \in \{0, 1\}^m \), run \( (F, e, d) \leftarrow \text{Gb}(g) \), and output \( (F, (e, r), d) \). The garbled input corresponding to \( x \) will be \( e(x \parallel r) \).
2. **Authenticity**: Instead of garbling a circuit \( f \), let \( g \) be a circuit such that \( g(x \parallel K) = f(x) \parallel \text{MAC}_K(f(x)) \) for any \( x \in \{0, 1\}^n \) and any key \( K \). Then, choose a random key \( K \), run \( (F, e, d) \leftarrow \text{Gb}(g) \), and output \( (F, (e, K), d) \). The garbled input corresponding to \( x \) will be \( e(x \parallel K) \).

Applied to Garble1, these transformations lead to schemes slightly (for (1)) or substantially (for (2)) less efficient than Garble2, and (2) requires a cryptographic assumption. More fundamentally, Applebaum et al. do not formalize any definition for the obliviousness or authenticity of a garbling scheme.

The only work that explicitly defines obliviousness and authenticity in this domain is a recent paper by Kamara, Mohassel, and Rakova [28]. Their syntax is designed specifically for their application, and their notion of obliviousness requires hiding only the input, while obv.ind requires hiding both the input and the function.