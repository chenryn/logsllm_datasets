### 3. Classification Accuracy and False Positives

- **Classification Accuracy:** 0.987 (AUC = 98.4%)
- **False Positives:** 0.3% to 1.1%

**Figure 3: Classification accuracy. (AUC=Area Under the ROC Curve)**

### 4. Evaluation of Malware Domains

We used a malware domain list from `malwareurls.com`, which was not part of our initial training set. During the experimental period, this source reported 569 domains as malicious. Out of these, 216 domains were queried by infected machines in the networks we monitored. The remaining 363 domains were not requested. Therefore, our detection rate evaluation is based on the 216 queried domains.

Five of these 216 domains were queried fewer than 20 times during the monitoring period. Since we filter out domains with fewer than 20 queries, we only considered the remaining 211 domains. All of these domains, previously unknown to our system, were automatically detected as malicious by EXPOSURE. This resulted in a detection rate similar to the 98% estimated from the percentage split and cross-validation evaluations on the training set.

While our approach is not comprehensive, it significantly improves the detection of unknown malicious domains in DNS traffic compared to previous methods.

### 5. Evaluation of False Positives

Determining the real false positive rate is challenging due to the lack of labeled data. Manually checking all 17,686 identified domains is not feasible. To estimate the false positives, we conducted three experiments:

#### 5.1 Categorization of Domains

We categorized the domains into ten groups:
- Spam
- Blacklisted
- Fast-Flux
- Malware
- Conficker
- Adult content
- Risky (as flagged by Norton Safe Web and McAfee Site Advisor)
- Phishing
- No Information
- Benign but detected as malicious (False Positives)

**Table 2: Tests for False Positives**

| Group          | Count |
|----------------|-------|
| Spam           | 18    |
| BlackList      | 8     |
| FastFlux       | -     |
| Malware        | 6     |
| Conficker      | 4     |
| Adult          | 3     |
| Risky          | -     |
| Phishing       | 3     |
| No Info        | 5     |
| False Positives| 1     |

#### 5.2 Manual Investigation

In the first experiment, we manually investigated 50 randomly selected domains from the list of 17,686. We used Google, websites discussing malicious networks, and other sources to identify any reported malicious behavior. Among the 50 domains, three benign domains were incorrectly classified as malicious, all showing abnormal TTL change behavior.

#### 5.3 Automated Cross-Checking

In the second experiment, we cross-checked the identified malicious and suspicious domains using online site rating tools such as McAfee Site Advisor, Google Safe Browsing, and Norton Safe Web. The results indicated a false positive rate of approximately 7.9%. Given that EXPOSURE can automatically identify malicious domains, this false positive rate is acceptable for large-scale deployment.

### 6. Real-World, Real-Time Detection with EXPOSURE

To test EXPOSURE's feasibility and scalability, we deployed it in an ISP network for two weeks. The ISP provided complete access to its DNS servers, which handle queries from approximately 30,000 clients.

During this period, EXPOSURE analyzed and classified 100 million DNS queries without pre-filtering. It detected 3,117 new malicious domains, none of which were known to the system or used in the training set. Of these, 2,821 were generated by a Domain Generation Algorithm (DGA) and belonged to the same malicious entity. Five of the remaining 396 domains were later reported as malicious by security companies like Anvira.

All detected domains were classified as risky by McAfee Site Advisor. Figures 5(a) and 5(b) show the number of new, previously unknown malicious domains detected daily. After the initial seven days of local training, EXPOSURE produced daily detections, averaging 200 new malicious domains per day.

After the experiments, we provided the ISP with a list of potentially infected clients or victims of scams. The distinct number of IP addresses querying the detected malicious domains was 3,451. Given the dynamic IP assignment, this number does not represent the exact number of infected machines. We estimated the number of infected machines by grouping the malicious domains according to their mapped IP addresses, resulting in an estimated 800 infected machines.

### 7. Comparison with Previous Work

#### 7.1 Fast-Flux Detectors

Our classifier identified 114 Fast-Flux Service Networks (FFSNs) during the initial training phase. Compared to Perdisci et al. [30], our approach is equally effective in detecting FFSNs while being more generic.

#### 7.2 Notos: Reputation-Based Malicious Domain Detection

Notos, proposed by Antonakakis et al. [11], dynamically assigns reputation scores to domain names. While Notos relies heavily on network-based features, EXPOSURE uses time-based features, allowing it to detect short-lived domains. Notos may miss-classify certain domains and requires a large passive DNS collection, whereas EXPOSURE only needs a week of local training and less DNS data.

### 8. Related Work

DNS has been increasingly used by attackers for managing malicious infrastructures. Recent research on botnet detection has focused on distinguishing between malicious and benign DNS usage. Early work by Zdrnja et al. [42] and others have laid the groundwork, but EXPOSURE offers significant improvements in detection and false positive rates.

### 9. Conclusion

EXPOSURE demonstrates high accuracy and low false positive rates in detecting malicious domains, making it a valuable tool for real-world, real-time detection and early warning systems.