Yes 
Yes (6.2E-7) 
Labeling 
HotCaptcha 
Labeling 
Asirra 
Labeling 
Orientation (with 
3 images) 
Removing 
bad images 
No 
Yes 
Very subjective 
No 
Accuracy:83.4%Ti
me: 15s 
Broken 
No 
Yes 
No (1.19%) 
Yes (0.024%) 
Yes 
Accuracy: 84% 
Yes 
Yes 
Yes (0.009%) 
Video 
Labeling 
No 
Cortcha 
No 
Yes 
Accuracy: 90% 
Time: 22s 
Accuracy:86.2% 
Time: 18.3s 
No 
Yes 
No 
Yes 
No (>2% ) 
Yes (≤0.125%) 
2 Some animals are popular only in a few countries [12]. 
190 
Click: Yes 
Annotation: 
No 
No 
No 
No 
No 
Yes 
3.  OUR ATTACK ON IMAGINATION 
3.1  Basic Ideas on Our Attack 
The dithering process during the generation of a click challenge in 
IMAGINATION  produces  many  false  boundaries.  To  be  a  good 
CAPTCHA, some true boundaries should be still readily visible so 
that  humans  can  easily  determine  at  least  one  constituent  image’s 
location. Let’s look how humans would deduce such a location. A 
candidate  region  is  first  located.  Then  the  two  sides  along  the 
boundary  of  the  candidate  are  compared.  If  both  sides  are  very 
similar,  the  boundary  is  likely  false,  and  another  candidate  should 
be  examined.  This  process  is  iteratively  applied  until  a  confident 
image location is found. This image location should agree with the 
likely locations of the neighboring constituent images. This process 
is also applied in our attack on the click test of IMAGINATION.  
Our attack consists of the following three steps: 
•  Detect  all  possible  rectangular  regions.  Each  rectangular 
region 
location.  These 
rectangular  regions  can  be  ranked  according  to  the  likelihood 
of being a rectangular region.  
represents  a  candidate 
image 
•  Compare  objects  and  textures  on  both  sides  along  the 
boundary of each candidate rectangle. An object that crosses a 
boundary  is  called  a  traversing  object  of  the  boundary.  A 
boundary  with  traversing  objects  is  likely  a  false  image 
boundary.  A  boundary  with  very  different  textures  on  both 
sides  is  likely  to  be  a  true  image  boundary.  Any  rectangular 
region  with  a  false  boundary  is  removed  from  the  set  of 
candidates.  The  likelihood  to  be a  true  image  location  is  then 
adjusted for each survived rectangle.  
•  Check  each  candidate’s  consistency  with  its  neighboring 
rectangles.  The  rectangle  with  the  highest  likelihood  is 
selected  and  its  geometric  center  is  sent  back  as  the  response 
to the test.  
These steps will be described in detail in the following subsections.  
3.2  Details of Our Attack 
3.2.1  Detection of Candidate Rectangles 
To detect all the possible rectangular regions in a composite image, 
color edge detection is first applied, and vertical and horizontal line 
segments are then detected. By enumerating possible combinations 
of these line segments, candidate rectangular regions are generated.  
3.2.1.1  Color Edge and Line Segment Detection 
Region-based  color  edge  detection  is  used  to  detect  significant 
vertical  and  horizontal  color  edges  in  a  composite  image.  This  is 
because  a  dithered  composite  image  is  quite  noisy  that  a  local 
gradient based method would lead to a lot of false edge responses. 
Before  the  edge  detection,  an  input  composite  image  is  smoothed 
location  in  the  image,  we  draw  a  circle  of  radius  R  and  divide  it 
by  a 5×5  Gaussian  filter  in  order  to  reduce  noise.  For  each 
along  the  diameter  at  four  different  directions: 0°, 45° , 90° ,  and 
135°. The radius R should be selected carefully. A value that is too 
large  would  result  in  imprecise  edge  localization.  A  value  that  is 
too  small  would  generate  many  noisy  fragments.  The  color  model 
in  each  semi-circle  is  represented  as  the  histogram  in  a  jointly 
partitioned region by the color components in the Lab color space. 
The color edge intensity in each different direction is estimated by 
191 
calculating the χଶdistance between the models of the two resulting 
disc halves: 
߯ଶሺℎଵ,ℎଶሻ= ଵ
ଶ∑
#௕௜௡௦
௡ୀଵ
ሺ௛భ೙ି௛మ೙ሻమ
௛భ೙ା௛మ೙
 ,                        (1) 
where  1h  and  2h  are  the  color  histograms  of  the  two  disc  halves. 
The direction with the maximum color edge intensity is considered 
as the edge direction, and the maximum value as the edge intensity 
shown  in  Figure  3(b)  along  with  the  challenge  image  shown  in 
at  the  current  location.  The  resulting  edge  candidate  map ܫ௖  is 
Figure  3(a).  Non-maxima  suppression  is  then  applied  to ܫ௖  to 
generate  a  total  edge  map ܫ௘ௗ௚௘,  shown  in  Figure  3(c).  A  binary 
is  obtained  by  removing  all 
the  non-
image 
edge 
binI
−
vh
vertical/horizontal edge points after applying a threshold.  
Figure 3. (a) Original challenge image. (b) Edge candidate map 
ࡵࢉ. (c) Total edge map ࡵࢋࢊࢍࢋ. (d) Horizontal and vertical line 
segments after the line segment detection is applied. 
The  horizontal  and  vertical  edge  points  found  above  may  be 
slightly  off  the  actual positions by  up  to  a  couple of  pixels,  which 
makes a boundary not a straight line. We can refine the accuracy of 
these  edge  points  by  applying  local  gradient  based  edge  detection 
around the found edge points and adjust the edge point positions if 
necessary.  The  two-step  procedure  described  in  Appendix  9.1  is 
applied  to  the  binary  image 
 to  detect  all  the  potential 
binI
−
vh
vertical  and  horizontal  line  segments.  The  resulting  vertical  and 
horizontals line segments are shown in Figure 3(d). 
3.2.1.2  Generating Candidate Rectangles 
Candidate  rectangles  are  generated  by  enumerate  all  the  possible 
rectangles  from  the  horizontal  and  vertical  line  segments  obtained 
from  the  last  step.  A  priori  knowledge  is  then  applied  to  remove 
unlikely image rectangles: a rectangle that is too small or too large 
is removed.  A very small rectangle is unlikely used to fill with an 
image  since  it  is  too  hard  for  humans  to  recognize.  A  very  large 
rectangle makes other images too small. The rectangles that are too 
close to the boundary of the composite image are also removed for 
the same reason.  
In the next step, the candidate rectangles are processed and ranked 
according to the edge intensity, traversing objects, and edge density 
variation cues. The detail is described in Appendix 9.2.  
3.2.2  Consistency Inference 
The  a  priori  knowledge  that  constituent  images  cover  the  whole 
composite image and that there is no overlapping between any two 
constituent  images  is  used  to  check  consistency  of  the  survived 
rectangles  in  order  to  select  one  as  the  response  to  the  click  test. 
Two rectangles are said to be neighbors if one contains at least one 
pixel  in  the  neighborhood  of  some  pixel(s)  in  the  other  rectangle. 
Two neighboring rectangles are said to agree with each other if they 
share at least one boundary or one boundary of a rectangle is on the 
extension  of  a  boundary  of  the  other  rectangle.  Two  distinct 
rectangles are said to be inconsistent with each other if they overlap 
each other or they are close enough to each other such that the gap 
between them is too small to hold a constituent image.   
The  following  steps  are  applied  to  determine  a  rectangle  with  its 
geometric center as the response to the click test:  
1)  All  the  rectangles  with  a  confidence  value  of  1,  if  any,  are 
selected.  Each  selected  rectangle  is  then  checked  against  all 
the  other  rectangles 
the  set  of  candidates.  If  any 
inconsistency  is  detected,  the  rectangle  is  dropped  from  the 
selected  rectangles.  If  there  is  any  selected  rectangle  that 
survives  the  inconsistency  checking,  the  one  with  the  largest 
number  of  agreed  neighboring  rectangles  is  located  and  its 
geometric center is returned. Then the attack ends. 
in 
2)  Each  rectangle  in  the  set of  candidates  is  checked  against  the 
other rectangles in the set of candidates. If no inconsistency is 
detected, the rectangle is selected. At the end of this process, if 
there is any rectangle selected, the one with the largest number 
of agreed neighboring rectangles and, if there are still multiple 
choices,  with  the  highest  confidence  value  is  located  and  its 
geometric center is returned. Then the attack ends.   
If  all  the  candidate  rectangles  are  inconsistent  with  some 
candidate rectangle, the rectangle with the highest confidence 
is located and its geometric center is returned. 
3) 
Figure 4. Two challenge images and the image regions (enclosed 
by red lines) returned by our attack. 
them 
to  compare  with 
3.3  Attacking Results 
We have used both our own implementation of IMAGINATION’s 
click test and IMAGINATION’s online service [14] to evaluate our 
attack  algorithm.  Using  our  own  implementation,  the  evaluation 
process  was  automated  and  fast,  but  our  implementation  might  be 
different  from  the  actual  IMAGINATION.  Therefore  we  collected 
109  click  test  images  from  IMAGINATION’s  online  service,  and 
attacked 
the  result  from  our  own 
implementation.  Unlike  our  own  implementation,  the  evaluation 
using  IMAGINATION’s  online  service  could  not  be  automated 
since the service applied an annotation test after a click test, denied 
access  if  failing  either  test  more  than  a  small  threshold  number. 
Each  collected  image  was  first  manually  labeled  to  locate 
perceivable  image  boundaries.  The  output  of  our  attack  algorithm 
was then compared with the labeled result to determine if the attack 
was  successful  or  not.  For  the 109  collected  click  test  images,  our 
attack solved 81 test images correctly, resulting in a success rate of 
74.31%.  Figure  4  shows  the  image  regions  (enclosed  by  the  red 
lines) returned by our attack algorithm for two collected challenge 
images. This success rate agrees with the result evaluated with our 
own  implementation  of  IMAGINATION’s  click  test  where  2000 
click  test  images  were  used.  Our  average  attack  speed  was  0.962s 
per  image  when  running  on  a  PC  with  3.2GHz  Intel  P4  and  2GB 
memory. 
If we use a random guess for the annotate test of IMAGINATION, 
the success rate will be 1 in 15, or 6.67%. By combining the attack 
results  of  IMAGINATION’s  two  tests,  our  attack  algorithm  can 
achieve  an  overall  success  rate  of 74.31%	×	6.67%,	 or  4.95%. 
This  number  can  be  increased  if  a  technique  better  than  a  random 
guess  is  used  for  the  annotate  test.  In  fact,  this  annotate  test  has 
several  shortcomings,  e.g.,  difficult  to  build  an  image  database 
large  enough  to  meet  the  demand  of  a  large  scale  application, 
language-dependent, and poor rejection of a random guess.      
4.  OTHER ATTACKS 
4.1  Low-level Features and Semantics 
A  typical  image  contains  rich  information  which  can  be  classified 
roughly into two types: low-level features and high-level semantics. 
Low-level  features  are  the  information  that  can  be  extracted  from 
an  image  with  little  or  nothing  to  do  with  perception  or 
understanding  of  the  image.  Many  low-level  features  have  been 
developed  for  various  tasks.  Commonly  used  low-level  features 
include color, shape, texture, color layout, among others. Color is a 
widely used feature. A color feature can be represented by the color 
histogram which is a distribution of the colors in an image. Texture 