between January 1, 2016 and May 1, 2019 [7].
How can computer-aided cryptography help? Crypto-
graphic code is an ideal target for program veriﬁcation. Such
code is both critically important and difﬁcult to get right. The
use of heavyweight formal methods is perhaps the only way
to attain the high-assurance guarantees expected of them. At
the same time, because the volume of code in cryptographic
libraries is relatively small (compared to, say, an operating
system), verifying complex, optimized code is well within
reach of existing tools and reasonable human effort, without
compromising efﬁciency.
What are the ﬁne-print caveats? Functional correctness
makes implicit assumptions, e.g., correct modeling of hard-
ware functional behavior. Another source of implicit assump-
tions is the gap between code and veriﬁed artifacts, e.g.,
veriﬁcation may be carried out on a veriﬁcation-friendly
representation of the source code, rather than on the source
code itself. Moreover, proofs may presuppose correctness of
libraries, e.g., for efﬁcient arithmetic. Finally, as with any
software, veriﬁcation tools may have bugs.
What background do I need to know? Functional cor-
rectness is the central focus of program veriﬁcation. An
implementation can be proved functionally correct
in two
different ways: equivalence to a reference implementation, or
satisfying a functional speciﬁcation, typically expressed as pre-
conditions (what the program requires on inputs) and post-
conditions (what the program guarantees on outputs). Both
forms of veriﬁcation are supported by a broad range of tools.
A unique aspect of cryptographic implementations is that
their correctness proofs often rest on non-trivial mathematics.
Mechanizing them thus requires striking a good balance be-
tween automation and user control. Nevertheless, SMT-based
automation remains instrumental for minimizing veriﬁcation
effort, and almost all tools offer an SMT-based backend.
tasks, which are then compiled into custom protocol imple-
mentations. These have been proposed for veriﬁable compu-
tation [82]–[85], zero-knowledge [86]–[89], and secure mul-
tiparty computation [90] protocols, which are parameterized
by a proof-goal or a functionality to compute. Some are
supported by proofs that guarantee the output protocols are
correct and/or secure for every input speciﬁcation [91]–[94].
We recommend readers to also consult other related surveys.
Blanchet [95] surveys design-level security until 2012 (with
a focus on ProVerif). Cortier et al. [96] survey computational
soundness results, which transfer security properties from the
symbolic world to the computational world.
III. FUNCTIONAL CORRECTNESS AND EFFICIENCY
In this section, we focus on the role of computer-aided
cryptography in developing functionally correct and efﬁcient
implementations.
A. Critical Review
Why are functional correctness and efﬁciency important?
To reap the beneﬁts of design-level security guarantees, im-
plementations must be an accurate translation of the design
proven secure. That is, they must be functionally correct (i.e.,
have equivalent input/output behavior) with respect to the de-
sign speciﬁcation. Moreover, to meet practical deployment re-
quirements, implementations must be efﬁcient. Cryptographic
routines are often on the critical path for security applications
(e.g., for reading and writing TLS packets or ﬁles in an
encrypted ﬁle system), and so even a few additional clock-
cycles can have a detrimental impact on overall performance.
How can functional correctness and efﬁciency fail?
If performance is not an important goal,
then achieving
functional correctness is relatively easy—just use a refer-
ence implementation that does not deviate too far from the
speciﬁcation, so that correctness is straightforward to argue.
However, performance demands drive cryptographic code into
extreme contortions that make functional correctness difﬁcult
to achieve, let alone prove. For example, OpenSSL is one of
the fastest open source cryptographic libraries; they achieve
this speed in part through the use of Perl code to generate
strings of text that additional Perl scripts interpret to produce
input to the C preprocessor, which ultimately produces highly
tuned, platform-speciﬁc assembly code [103]. Many more
examples of high-speed crypto code written at assembly and
pre-assembly levels can be found in SUPERCOP [107], a
benchmarking framework for cryptography implementations.
More broadly, efﬁciency considerations typically rule out
exclusively using high-level languages. Instead, C and as-
sembly are the de facto tools of the trade, adding memory
safety to the list of important requirements. Indeed, memory
errors can compromise secrets held in memory, e.g., in the
Heartbleed attack [108]. Fortunately, as we discuss below,
proving memory safety is table stakes for most of the tools we
discuss. Additionally, achieving best-in-class performance de-
mands aggressive, platform-speciﬁc optimizations, far beyond
what is achievable by modern optimizing compilers (which are
Typically, functional correctness proofs are carried out at
source level. A long-standing challenge is how to carry guar-
antees to machine code. This can be addressed using veriﬁed
compilers, which are supported by formal correctness proofs.
CompCert [111] is a prime example of moderately optimizing
veriﬁed compiler for a large fragment of C. However, the
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:10:25 UTC from IEEE Xplore.  Restrictions apply. 
783
Memory
safety
Automation Parametric
veriﬁcation Input language
Target(s)
TCB
SAT, SMT
Boolector, MathSAT, Singular
Boogie, Z3
C, Java
C
C#, Java, JavaScript, Go
OCaml, F#, C, Asm, Wasm Z3, typechecker
Coq, C compiler
C
Coq, Alt-Ergo, Why3
C
g++, Sage
C
Asm
Coq, Dafny, Z3
Dafny or F*, Z3
Asm
Coq
C
OCaml
SMT, Coq
C, Java
CryptoLine
Dafny
F∗
Gallina
C
C
Jasmin
Vale
Gallina
WhyML
Automation
Tool
Cryptol + SAW [97]
CryptoLine
[98]
[99]
Dafny
F∗
[60]
[6]
Fiat Crypto
[100]
Frama-C
[101]
gfverif
Jasmin
[102]
[103], [104]
Vale
[105]
VST
Why3
[106]
– automated
– automated + interactive
– interactive
OVERVIEW OF TOOLS FOR FUNCTIONAL CORRECTNESS. SEE SECTION III-B FOR MORE DETAILS ON COMPARISON CRITERIA.
TABLE III
trade-off is that veriﬁed compilers typically come with fewer
optimizations than mainstream compilers and target fewer
platforms.
B. Program Veriﬁcation Tools: State of the Art
Table III presents a taxonomy of program veriﬁcation tools
that have been used for cryptographic implementation. Tools
are listed alphabetically and are categorized as follows.
Memory-safety (S). Can the tool verify that programs are
memory safe? Memory safety ensures that all runs of a
program are free from memory errors (e.g., buffer overﬂow,
null pointer dereferences, use after free).
Automation (U). Tools provide varying levels of automa-
tion. We give a coarse classiﬁcation: automatic tools ( ), tools
that combine automated and interactive theorem proving ( ),
and tools that allow only interactive theorem proving ( ).
Parametric veriﬁcation (U). Can the tool verify parame-
terized implementations? This enables writing and verifying
generic code that can be used to produce different implemen-
tations depending on the supplied parameters. For example,
Fiat Crypto [6] can generate veriﬁed elliptic curves implemen-
tations parameterized by a prime modulus, limb representation
of ﬁeld elements, and hardware platform; Vale [103], [104]
implementations are parameterized by the operating system,
assembler, and hardware platform.
Input language (U). What is the input language? Many
toolchains use custom veriﬁcation-oriented languages. Dafny
imperative language, whereas F∗, Gallina
is a high-level
(used in Coq), and WhyML (used in Why3) are functional
languages. CryptoLine, Jasmin, and Vale are assembly-like
languages; Jasmin and Vale provide high-level control-ﬂow
structures such as procedures, conditionals, and loops. Other
tools take code written in existing languages (e.g., C, Java).
Target(s) (A,S). At what level is the analysis carried out
(e.g., source-level or assembly-level)? Note that tools target-
ing source-level analysis must use veriﬁed compilers (e.g.,
CompCert [111]) to carry guarantees to machine-level, which
comes with a performance penalty. Tools targeting assembly-
level analysis sidestep this dilemma, but generally veriﬁcation
becomes more difﬁcult.
Trusted computing base (T). What lies in the trusted com-
puting base? Many veriﬁcation frameworks rely on building-
Implementation
evercrypt
precomp
sandy2x
hacl
jasmin
amd64
ﬁat
donna64
FC CT
Tool(s)
F∗, Vale
−
−
F∗
Jasmin
Coq, SMT
Fiat Crypto
−
Target
64-bit C, Intel ADX asm
Intel ADX asm
Intel AVX asm
64-bit C
Intel x86 64 asm
Intel x86 64 asm
64-bit C
64-bit C
% faster
25.92
25.77
11.15
8.69
7.88
6.11
5.39
0.00
[7]
[112]
[113]
[7]
[102]
[114]
[6]
[115]
Functional correctness (FC), Constant-time (CT)
– veriﬁed
– partially veriﬁed
– not veriﬁed
COMPARISON OF CURVE25519 IMPLEMENTATIONS. % FASTER
CALCULATED USING DONNA64 AS THE BASELINE.
TABLE IV
block veriﬁcation tools, such as SMT solvers (e.g., Z3) and
interactive theorem provers (e.g., Coq). While these are ac-
knowledged to be important trust assumptions of veriﬁcation
tools, veriﬁed artifacts tend to rely on additional trust assump-
tions, e.g., unveriﬁed interoperability between tools or only
verifying small routines in a larger primitive.
C. Discussion
Achievements: Veriﬁed primitives are being deployed at
Internet-scale. A recent milestone achievement of computer-
aided cryptography is that veriﬁed primitives are being de-
ployed at scale. Veriﬁed primitives in the HACL∗ [5] library
are used in Mozilla Firefox’s NSS security engine, and ver-
iﬁed elliptic curve implementations in the Fiat Cryptography
library [6] are used in Google’s BoringSSL library.
There are several common insights to these successes. First,
veriﬁed code needs to be as fast or faster than the code being
replaced. Second, veriﬁed code needs to ﬁt the APIs that are
actually in use. Third, it helps if team members work with or
take internships with the companies that use the code. In the
case of HACL∗, it additionally helped that they replaced an
entire ciphersuite, and that they were willing to undertake a
signiﬁcant amount of non-research work, such as packaging
and testing, that many academic projects stop short of.
Takeaway: Veriﬁed implementations are now as fast or
faster than their unveriﬁed counterparts. Through decades
of research in formal veriﬁcation, it was commonly accepted
that the proof burden in verifying complex, optimized code
was exorbitant; veriﬁed code would be hard-pressed to com-
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:10:25 UTC from IEEE Xplore.  Restrictions apply. 
784
pete with unveriﬁed code in terms of performance. However,
various projects in the cryptography domain have challenged
this position. We are seeing veriﬁed implementations that meet
the performance of the fastest unveriﬁed implementations. We
conclude that there is currently no conceptual or technological
barrier that prevents verifying the fastest
implementations
available, although more effort is expected.
As a small case study, we look at Curve25519 [116],
a widely used elliptic curve that has received considerable
interest from the applied cryptography community (in setting
new speed records) and the formal methods community (in
verifying that high-speed implementations are correct and se-
cure). We compare a number of Curve25519 implementations