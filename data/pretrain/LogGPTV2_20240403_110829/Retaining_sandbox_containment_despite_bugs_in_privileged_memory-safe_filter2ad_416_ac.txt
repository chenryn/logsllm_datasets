### 6.2 Transparent Forensic Logging
To facilitate the investigation of potential abuses, support auditing, and aid in debugging our platform, we aimed to collect various local information, such as the destination of traffic and the rate of resource consumption. A key requirement for this data collection is that the researcher using the machine should not be able to modify the collected data.

We implemented this functionality by interposing on the calls that need to be logged and writing the collected data into a file. To prevent modification or deletion of this file, the library traps the `openfile` and `removefile` capabilities. By leveraging security layers, we were able to move this functionality outside of the sandbox kernel without compromising the transparency of the application code.

### 6.3 Dynamic Policy Loading
Administrators may need to add or remove security layers for a large number of machines under their control. Manually making these changes on each system is time-prohibitive. We developed an administrator control required library that retrieves a list of security layers to load from a user-specified server. This list is signed with the administrator’s private key (along with other security metadata to prevent replay attacks) and contains the names, locations, and secure hashes of the security layers to be loaded.

### 6.4 Location-Aware Resource Restriction
Required libraries also simplify the construction of adaptive policies. For example, a policy that changes based on the machine’s location can be implemented as a required library that periodically checks the machine’s IP address and adjusts the capabilities set according to the machine’s geolocation. This allows a user to have different network restrictions when their laptop is at home or at work.

### 7. EVALUATION
In this section, we evaluate our approach. First, we compare the resiliency of our sandbox to the JVM by considering previous security bug reports for the Java code portion of the JVM [42]. We manually translate these bugs into the context of our sandbox to understand how they would manifest. We categorize the impact of these bugs on our sandbox and detail how security layers help mitigate them. Second, we evaluate the cost of our techniques by quantifying the performance impact and memory overhead of constructing and using security layers in Python.

#### 7.1 Risk Reduction
To evaluate the change in risk with using security layers, we considered the set of critical Java security vulnerabilities studied by Paul and Evans [42]. For each bug, we attempted to understand how the vulnerability impacts our sandbox if the component containing the vulnerability were translated into our sandbox. Our translation was guided by considering how the buggy component would be implemented in our system, relying on the underlying motivation of our project to migrate as much functionality as possible out of the sandbox kernel. Because this evaluation effort is inherently qualitative, we mitigated the subjective nature of the analysis by having three authors independently categorize the severity of each bug. The authors then actively discussed any disagreements until a complete consensus on the appropriate category for each bug was reached.

Table 1 describes the bugs, their severity in Java, and their categorized severity in our sandbox. The values in the security layer severity column of this table mean the following:
- **Prevented**: Bug cannot manifest in our sandbox.
- **Insufficient detail**: Bug report did not provide enough information to make the translation possible.
- **Cannot translate**: Bug is specific to the JVM and cannot be mapped into the context of our sandbox.
- **Exception**: An exception is raised when the bug is triggered.
- **Hang**: The bug hangs the sandbox.
- **Allowed**: The bug is explicitly allowed to manifest due to security policies of our sandbox kernel.
- **Unknown**: The bug does not have a single definitive translation.

The most critical bugs in Table 1 allow arbitrary code execution or read access to the entire file system. We now discuss these critical bugs in more detail in the order they appear in the table.

- **CVE-2001-1008**: Leveraging this bug, an attacker can execute signed code with expired signatures. This is a risk because this code may be native code containing flaws. Our sandbox prohibits users from executing native code (whether signed or not). The closest translation of this bug would manifest as a security layer that only loads code if it is signed. A similar flaw in this layer would allow malicious code to be loaded and executed, but the malicious code would not be able to escape the sandbox.

- **CVE-2005-3905 and CVE-2005-3906**: These provide insufficient information to make a translation possible. If the reflection vulnerabilities exist due to bugs in type conversion or memory safety, similar bugs would allow arbitrary code execution in our sandbox as well. However, if the flaws are related to incorrect capabilities when using reflection, there is no security risk as this portion of our implementation (e.g., `eval`) exists in a security layer.

- **CVE-2002-0865, CVE-2002-0866, and CVE-2002-1293**: These result from different standard libraries using custom code loading mechanisms. In our sandbox, custom code loading functionality would be implemented inside the security layer hosting the standard library (e.g., XML, CAB), which would prevent the vulnerability.

- **CVE-1999-0766, CVE-1999-0141, CVE-2000-0327, CVE-2002-0076, CVE-2003-0111, and CVE-2004-2627**: These cannot be easily translated because the bug descriptions have inadequate information. These bugs are in the bytecode verifier, which is significantly different in Java and Python. Our implementation does not load Python bytecode but instead passes the interpreter the program’s source (Appendix A). However, our implementation would prevent CVE-1999-0440 (a missing check for bytecode security) since the only way to load code is through a single call provided by the sandbox kernel.

- **CVE-2003-0896, CVE-2000-0676, and CVE-2000-0162**: These exist due to insufficient checks on file system access. In our implementation, there is a single set of routines in the sandbox kernel that all routines must use. We prevent this category of flaws by placing the appropriate file system access check in a single place.

One category of bugs listed in Table 1 deals with violations of the same-origin policy (CVE-2000-0711, CVE-2000-0563, CVE-1999-0142, CVE-1999-1262, and CVE-2002-0058). As our sandbox is partly used for networking research, our network policy is more permissive than the same-origin policy. Users typically choose between allowing arbitrary network connections (no security layer interposition) or using a security layer like the Controlled Node Communication layer (Section 6.1).

There is also a large class of bugs that crash or hang the JVM (CVE-2002-0867, CVE-2002-1289, CVE-2003-0525, CVE-2002-1287, CVE-2005-3583, CVE-2004-1503, CVE-2004-2540, and CVE-2004-0651), potentially leading to more serious attacks. In our framework, these bugs most likely result in exceptions or hang the sandbox, thus having a similar denial-of-service effect.

The security policy manipulation bug (CVE-2002-1292) exists because Java had outdated security checks that an attacker can manipulate. Since valid security policies rarely use this interface, the main impact of the vulnerability would be to allow a malicious party to prevent the loading of arbitrary classes. A similar vulnerability would exist in our framework if an outdated security layer with a vulnerability was loaded on client machines.

The final classification of bugs includes those that leak sensitive information or access but do not allow escape of the sandbox (CVE-2004-0723, CVE-2002-1260, CVE-2002-1290, CVE-2002-1288, CVE-2002-0979, and CVE-2002-1325). It is difficult to directly translate these issues to our sandbox. However, in general, using a small sandbox kernel makes it easier to manage and mitigate such vulnerabilities.