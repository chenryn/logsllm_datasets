# Bandwidth and Time Analysis for Various Sized Blocks and Intensities

- **/0, intensity=16**
- **/0, intensity=4**
- **/0, intensity=1**
- **/8, intensity=16**
- **/8, intensity=4**
- **/8, intensity=1**
- **/16, intensity=16**
- **/16, intensity=4**
- **/16, intensity=1**
- **/24, intensity=16**

Time intervals:
- 1 year
- 1 month
- 1 week
- 1 day
- 6 hours
- 1 hour
- 1 minute

Bandwidth values:
- 1e+00
- 64K
- 256K
- 1M
- 4M
- 16M
- 64M
- 256M
- 1G
- 4G

**Figure 11: Bandwidth vs. Time for Various Sized Blocks and Intensities with 64-byte Markers**

## Marking Order

The order in which we mark blocks or addresses within a block can significantly influence the likelihood of our marking activity being detected. For instance, an advanced Intrusion Detection System (IDS) that performs spatial and longitudinal analysis of captured events may detect such activities. Therefore, it is advisable to randomize the order in which we send the markers.

## 4.5 Gathering Additional Information

Several supplementary procedures can be employed to gather additional information before or between series of marking activities:

### ICMP-Based Reconnaissance

Some systems explicitly state that their sensors respond to ICMP requests to attract and capture packets from adversaries who check if a target host is alive prior to an actual attack. This feature can be leveraged to select a set of candidates from a target region before the actual marking process.

### Sensor Fingerprinting

Threat monitors, especially those deployed by large organizations, often use uniform hardware and software platforms for their sensors. Once the first sensor is identified, it can be fingerprinted to help identify additional sensors of the same type. Our study shows that we can fingerprint sensors responding to ICMP requests by characterizing their responses to various ICMP requests, such as Echo Requests, Timestamp Requests, Mask Requests, or Information Requests.

### Topological Inference

For sensors to be effective, they must be deployed in a manner that allows them to monitor as much traffic as possible. It is often undesirable to deploy sensors behind firewalls or in small network segments. Therefore, sensors within an intranet are likely not deeply embedded in the topology. Tools like traceroute can be used to study the internal topology of address blocks assigned to intranets, and then perform marking activities against those address blocks closer to the ingress point of the intranet. Address blocks assigned to intranets can be identified using tools like whois. The fact that many hosts respond to ICMP Mask Requests can also be used to build a topology map of a particular intranet.

### FQDN Filtering

During the detection process, candidate addresses may be converted into Fully Qualified Domain Names (FQDNs) via DNS reverse lookups. We can then examine their names and exclude those containing words indicating common purposes, such as "www", "mail", or "ns". This filter is particularly useful for address ranges covering intranets. In our experience, this kind of filtering can reduce the number of addresses in the candidate list significantly, sometimes from 64 to just 2.

For some of these algorithms, it is necessary to use a non-spoofed source address because they require bidirectional interaction with hosts and routers in or near the target region. The drawback of using non-spoofed addresses is that traffic from them may be easier to detect and could alert monitor operators to the fact that their sensors are under attack.

## 5 Case Studies

We have successfully determined the addresses of several sensors belonging to multiple threat monitors. In this process, we employed actual marking using live networks and simulated environments, as well as mathematical simulations. Below are some significant cases that can be discussed without compromising the security of the vulnerable monitors.

### 5.1 System A

System A corresponds to the threat monitor described in the introductory example in Section 3.1. In our initial study, we derived four small address blocks suspected to host sensors. Using time-series uniform-intensity marking on each block, we discovered one sensor in one of the blocks.

This system provides a feedback report in the form of a port table in addition to the graph-type feedback used in the first cycle. The second cycle was run using address-encoded-port marking on the block determined in the first cycle, with 4 redundantly encoded markers per address. To remain undetected, we scrambled the markers so that there was no obvious relationship between bit patterns of sensor addresses and port numbers. From the feedback, the complete address of the sensor was successfully decoded.

During the feedback delay of the second cycle, another set of methods was tested on this block. First, an ICMP-recon on addresses in this block was run. The address block was scanned with ICMP echo requests and connection requests (TCP-SYN) on ports 22/tcp and 1433/tcp. Addresses that responded to ICMP echo requests but did not respond to connection requests were kept in the list, which finally held 227 addresses. Since the original block was /22 (1024 addresses), the ICMP-recon reduced the list size to one-fifth. The list was then put through an FQDN-filter. Since this block was assigned to an intranet, almost all addresses in the list were resolved into names that resembled specific functions, except for two addresses. These two addresses were marked with time-series uniform-intensity marking on ICMP echo requests, revealing a complete sensor address that matched the results from the second cycle.

### 5.2 System B

This is an imaginary case but can be applied to many existing threat monitors. The "Dabber Worm" targeting port 9898/tcp is known to have explicit periods of activity and inactivity, as shown in Figure 12. The active period lasts for a few hours at a fixed time of the day, followed by an inactive period until the next active period. Events captured during the active period range from 1 to 10 per sensor, depending on the monitor. Virtually no events are captured during the inactive period, except for occasional spikes of up to one event per sensor.

As readers might have noticed, the activity profile and intensity figures of the Dabber Worm provide graphs that can be exploited during the period of inactivity. The simplest example would be a time-series uniform-intensity marking using destination 9898/tcp. The marking intensity depends on how feedback intensity is presented, but due to the activity profile of the Dabber Worm, this event group should stay or recur in the graph (delayed development marking with an autonomous development phase).

### 5.3 System C

This is another existing system that publishes daily accumulated port reports covering the entire port range. This type of feedback is a target for address-encoded-port marking. However, the challenge (or strength) of this system is that it deploys numerous sensors, making the port report table very noisy. Most ports are occupied, and clean ports are hard to predict.

The port report provided by this system includes not only total event counts but also the number of different sources and targets for each port, as shown in Figure 13.

| Port | Total Events | # of Sources | # of Targets |
|------|--------------|--------------|--------------|
| 0    | 17630        | 1367         | 533          |
| 1    | 188          | 37           | 27           |
| 2    | 123          | 20           | 21           |
| ...  | ...          | ...          | ...          |
| 65535| 47           | 9            | 5            |

Examination of these figures reveals strong statistical trends. For example, the ratio of the number of targets to the number of sources (TSR) can be analyzed. 

### Algorithm Outline

1. **From yesterday’s port table, drop ports with EC(eventcount) > 100.** These are ports with incredibly large event counts that affect the statistical operations of this algorithm. Since we will never manipulate these ports, it is safe to drop them first.
2. **Compute average and standard deviation of remaining reports, avg(EC) and stddev(EC) respectively, and drop those ports with EC ≥ avg(EC) + stddev(EC).** These ports are unlikely to move.
3. **Compute TSR value for all remaining ports and compute their average avg(TSR) and stddev(TSR).**
4. **Let STHRESH, the threshold value for Region S, be avg(TSR) - stddev(TSR).**
5. **Let TTHRESH, the threshold value for Region T, be STHRESH - 0.5 × stddev(TSR).** Leaving little space between Region S and T avoids ports in Region S that should not move from wandering into Region T.
6. **From remaining ports, select ports with TSR > STHRESH.**
7. **For each selected port, add nmarker to the number of sources, add 1 to the number of targets, and calculate a new TSR.** This simulates the "what if marked with nmarker different sources" situation.
8. **If the new TSR ≤ TTHRESH, then add the port to the encoding space.** The port "could have been moved."
9. **Sort the encoding space in ascending order, using EC as a sort key.** Lower count ports are easier to manipulate.
10. **Trim the encoding space so that the size of the space is 2n.** At this point, we have an encoding space for n-bit.
11. **Run an actual address-encoded-port marking using the encoding space and obtain the feedback.**
12. **Look for ports with TSR ≤ TTHRESH in the feedback.**

### Simulation and Evaluation

We can confirm the validity of this idea by running a simulation of this algorithm using port reports from the target system. An encoding space is generated from the port report of the first day, and all ports in the encoding space are marked artificially in the port report of the second day. The result of the artificial marking can be evaluated as follows:

- **False Positive:** The original TSR of a port was already in Region T without marking. The algorithm will still detect this port as a successful marking, so this is a false positive case.
- **Successful Marking (Hit):** The original TSR was in Region S, and the artificial marking moved this port into Region T. This is a successful marking.
- **False Negative:** The original TSR was in Region S, and the artificial marking could not move this port into Region T.

This type of simulation yields a more precise evaluation of the algorithm than running an actual marking. As results from the actual marking are affected by the disposition of actual sensors in the target address region, we would not know the correct number of actual sensors. The simulation derives the probability of successful markings, assuming all addresses in the target region host sensors.

We simulated this algorithm against 30 pairs of actual port reports from 31 consecutive days in December 2004, with an encoding space size set to 16,384 (14-bit). Also, nmarker, the number of markers, was set to stddev(EC), unless stddev(EC) is greater than 16, in which case nmarker was set to 16. Table 2 only shows results for the first week, but other dates yielded similar numbers. The last column shows the result of 4-way majority marking, where a hit is counted when at least 3 out of 4 markers satisfy the hit condition.

As shown in the table, the algorithm performs well despite its simplicity. The 4-way redundant marking with an "at least 3 out of 4" majority condition achieves almost perfect results, even though it reduces the available port-space to one quarter of the original size. More sophisticated trend analysis methods may further improve performance, especially in the non-redundant case.

For some day-pairs, the number of markers, or intensity, can be much smaller, sometimes as small as 8 markers without sacrificing performance. However, the table shows mechanically computed values based on the standard deviation of event counts, which is for stealthiness. The intensity seems unrelated to any of the statistical values used in our example algorithm, so there may be other factors at play. Nevertheless, with an intensity of at most 16 markers, the algorithm remains effective.