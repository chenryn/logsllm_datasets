t
e
l
p
m
o
c
o
t
e
m
T
i
/0,intensity=16
/0,intensity=4
/0,intensity=1
/8,intensity=16
/8,intensity=4
/8,intensity=1
/16,intensity=16
/16,intensity=4
/16,intensity=1
/24,intensity=16
1 year
1 month
1 week
1 day
6 hours
1 hour
1 min
1e+00
64K
256K
1M
4M
16M
64M
256M
1G
4G
Bandwidth (bps)
Figure 11: Bandwidth v.s. Time for Various Sized
Blocks and Intensities for 64-byte Markers
Marking Order
The order in which we mark blocks or addresses
within a block may increase or decrease the likelihood
of our marking activity being detected. One example
would be the presence of an advanced IDS that does spa-
tial and longitudinal analysis of captured events. For this
reason, we may want to scramble the order in which we
send the markers in some way or other.
4.5 Gathering Additional Information
There are several supplemental procedures that can be
used to gather additional information before or in be-
tween series of marking activities.
ICMP-Based Recon Some systems explicitly state that
their sensors respond to ICMP requests to attract
and capture packets from adversaries who check if
a target host is alive prior to an actual attack. This
feature can be used to select a set of candidates
from a target region prior to the actual marking pro-
cess.
Sensor Fingerprinting There are threat monitors, es-
pecially those prepared and deployed by large or-
ganizations that use uniform hardware and soft-
ware platforms for their sensors. In this case, once
218
14th USENIX Security Symposium
USENIX Association
the ﬁrst sensor has been detected, it can be ﬁnger-
printed to help with identifying additional sensors
of the same type.
For the purpose of detecting sensors of threat
monitors, ICMP is the only method we can use.
However, our study shows that we can ﬁngerprint
the sensors that respond to ICMP requests to some
extent by characterizing their responses to various
ICMP requests, such as Echo Requests, Timestamp
Requests, Mask Requests, or Information Requests.
Topological inference For sensors to be useful, it is
necessary that they are deployed in fashion that
gives them access to as much trafﬁc as possible. In
particular, it is often undesirable to deploy sensors
behind ﬁrewalls or small network segments. There-
fore, it seems likely that sensors deployed within an
intranet are not placed deeply in the topology. So,
for address blocks assigned to intranets, we can use
tools like traceroute to study their internal topol-
ogy, and then carry out our marking activity can
against those address blocks closer to the ingress
point of the intranet. Note that address blocks as-
signed to intranets can be identiﬁed through the use
of whois and similar tools. The fact that surpris-
ingly many hosts respond to ICMP Mask Requests
can also be used to build a topology map of a partic-
ular intranet. It is ironic that features which facil-
itate administrating Internet hosts provide us with
an improved way to compromise another class of
systems intended for Internet management.
FQDN ﬁltering At some stage in the detection process,
candidate addresses may be converted into FQDNs
via DNS reverse lookups. We can then examine
their names and drop those from the list that contain
words that indicate some common purpose, such as
“www”, “mail” or “ns”. This ﬁlter is particularly
useful for address ranges that cover intranets. In our
experience, this kind of ﬁltering actually cut down
the number of addresses in the candidate list from
64 to only 2.
For some of these algorithms, it is necessary to use
a non-spoofed source address because they require bidi-
rectional interaction with hosts and routers in or near the
target region. The drawback of using non-spoofed ad-
dresses is that trafﬁc from them may be easier to detect
and could alert monitor operators to the fact that their
sensors are under attack.
5 Case Studies
We have successfully determined the addresses of sev-
eral sensors belonging to multiple threat monitors.
In
this process, we employed actual marking using live net-
works and simulated environments but also mathemati-
cal simulations. In this section, we present some signif-
icant cases that can be discussed without compromising
the security of the vulnerable monitors.
5.1 System A
System A corresponds to the threat monitor described in
the introductory example in Section 3.1. As described
earlier, in our initial study of the system, we were able
to derive four small address blocks that we suspected
to host sensors. We used time-series uniform-intensity
marking on each block and disovered that there was ac-
tually one sensor in one of the blocks.
This system provides a feedback report in the form of
a port table in addition to the graph type feedback used
in the ﬁrst cycle. The second cycle was run using the
address-encoded-port marking on the block determined
in the ﬁrst cycle, using 4 redundantly encoded markers
per address. To remain undetected, we scrambled the
markers so that there was no obvious relationship be-
tween bit patterns of sensor addresses and port numbers.
From the feedback, the complete address of the sensor
was successfully decoded.
During the feedback delay of the second cycle, an-
other set of methods was tested on this block. First, the
ICMP-recon on addresses on this block was run. The ad-
dress block was scanned with ICMP echo request, con-
nection request (TCP-SYN) on 22/tcp and 1433/tcp. Ad-
dresses that respond to ICMP echo request but did not re-
spond to connection requests were kept in the list, which
ﬁnally held 227 addresses. Since the original block was
/22 (1024 addresses), the ICMP-recon has cut down the
size of the list to one-ﬁfth. Then, the list was put through
FQDN-ﬁlter. Since this block was assigned to a intranet,
almost all addresses in the list were resolved into names
that resembles some kind of a particular function, except
two addresses. These two addresses were marked with
time-series uniform-intensity marking on ICMP echo re-
quest, and revealed a complete sensor address, which in-
deed matched with the results from the second cycle.
5.2 System B
This is an imaginary case, but can be applied to many
existing threat monitors. The “Dabber Worms” hitting
9898/tcp is very well known to have explicit period of
activity and inactivity, as shown in Figure 12. The active
period always last for few hours at ﬁxed time of the day,
followed by inactive period that last until next active pe-
riod. Events captured during the active period is likely
to be in the range of 1-10 per sensor, depending on the
monitor. On the other hand, virtually no events are cap-
tured during the inactive period, except for occasional
spikes that goes as high as one event per sensor.
As readers might have noticed already, the activity
proﬁle and intensity ﬁgures of the Dabber Worm proﬁle
USENIX Association
14th USENIX Security Symposium
219
Region T
  Region S
40000
30000
20000
10000
)
s
t
r
o
P
(
y
c
n
e
u
q
e
r
F
0.1
0.5
TSR (Target Source Ratio) Value
1.5
1.0
2.0
Figure 14: Target/Source (TSR) Value Distribution Ex-
ample
Figure 14 shows a distribution of TSR values, calcu-
lated from the actual port report from this system, on
a particular day in December 2004. Each bar repre-
sents occurrences of values smaller than the correspond-
ing horizontal label (inclusive), and larger than the next
smaller horizontal label (exclusive). Clean ports (no re-
ports, no sources, no destinations) are counted as having
TSR=1.0 for convenience. From this graph, we see the
obvious strong bell shaped distribution with TSR=1.0 at
the center.
Because we can always mark with spoofed source ad-
dresses, we can manipulate the TSR value for a particu-
lar port to be smaller than it actually would, by marking
the port with different source addresses. Now, let us de-
ﬁne two regions in the distribution graph, Region S and
Region T as in Figure 14. Here, Region S is where ports
to be marked reside, and Region T is where ports marked
should move into. That is, if we can move ports that
were otherwise in Region S into Region T by reason-
able number of markers with different source addresses,
and if we can detect these movements, then we have a
variation of the address-encoded-port marking.
One way to implement this marking is to use the yes-
terday’s port report to identify ports that could have been
moved if they were marked, and use these ports as ad-
dress encoding space for today’s marking activity. This
sounds very naive, but if counts on ports tend to change
gradually from day to day, it should work.
Below is the outline of the algorithm, using standard
statistical operations to determine threshold values for
Region S and T.
1. From yesterday’s port
table, drop ports with
EC(eventcount) > 100. These are ports with in-
credibly large event counts that affect the statistical
operations of this algorithm. Since we will never
manipulate these ports, it is safe to drop them ﬁrst.
2. We do the same thing with some more precision.
Figure 12: A Typical Dabber Worm Event Proﬁle in
Solid Black Lines (Vertical Axis is total events captured
expressed in log scale). The period of inactivity provides
a good space for marking in a Top-N type graph.
provides graphs containing this proﬁle to be exploited
during the period of inactivity. The simplest example
would be a time-series uniform-intensity marking using
destination 9898/tcp. The marking intensity depends on
how feedback intensity is presented, but because of the
activity proﬁle of the Dabber Worm, this event group
should stay or recur in the graph (delayed development
marking with autonomous development phase).
5.3 System C
This is another existing system, that publishes daily ac-
cumulated port reports that covers entire port range. This
type of feedback is a target for the address-encoded-port
marking. However, the problem (or the strength) of this
system is that it deploys numerous number of sensors,
and as a result, the port report table is very noisy. Most
ports are occupied, and clean ports are hard to predict.
However, the port report provided by this system in-
cludes not only total event counts, but also numbers of
different sources and targets for each port, as shown in
Figure 13.
port
0
1
2
...
65535
total events
17630
188
123
# of src
1367
37
20
# of tgt
533
27
21
47
9
5
 



Figure 13: A Hypothetical Port Report From System C
Examination of these ﬁgures reveals that there are
strong statistical trends in these reports. Take ratio
of number of targets and number of sources (#tar-
gets/#sources, abbreviated as TSR here after) for exam-
ple.
220
14th USENIX Security Symposium
USENIX Association
Compute average and standard deviation of re-
maining reports, avg(EC) and stddev(EC) respec-
tively, and drop those ports with EC ≥ avg(EC) +
stddev(EC). These ports are unlikely to move.
3. Compute T SR value for all
4. Let STHRESH, the threshold value for Region S to
remaining ports,
and also compute their average avg(TSR) and
stddev(TSR).
avg(TSR)− stddev(TSR).
5. Let T T HRESH, the threshold value for Region T
to STHRESH − 0.5× stddev(TSR). Leaving little
space between Region S and T avoids ports in Re-
gion S that should not move from wondering into
Region T.
6. From remaining ports, select ports with TSR >
STHRESH.
7. For each of the selected port, add nmarker to num-
ber of sources, add 1 to number of targets, and cal-
culate a new TSR. This simulates “what if marked
with nmarker different sources” situation.
8. If the new T SR ≤ T T HRESH, then add the port
to the encoding space. The port “could have been
moved”.
9. Sort the encoding space in ascending order, using
EC as a sort key. This is because lower count ports
are easier to manipulate.
10. Trim the encoding space so that the size of the
space is 2n. At this point, we have a encoding space
for n-bit.
11. Run an actual address-encoded-port marking using
12. Look for ports with T SR ≤ T THRESH in the feed-
the encoding space, and obtain the feedback.
back.
We can conﬁrm the validity of this whole idea by run-
ning a simulation of this algorithm using port reports
from the target system. An encoding space is generated
from the port report of the ﬁrst day, then all ports in the
encoding space are marked artiﬁcially in the port report
of the second day. The result of the artiﬁcial marking
can then be evaluated as follows.
False Positive The original TSR of a port was already
in Region T without marking. The algorithm will
still detect this port as a successful marking, so this
is a false positive case.
Successful Marking (Hit) The original TSR was in
Region S, and the artiﬁcial marking moved this port
into Region T. This is a successful marking.
False Negative The original TSR was in Region S, and
the artiﬁcial marking could not move this port into
Region T.
Note that this type of simulation yields a more pre-
cise evaluation of the algorithm than running an actual
marking. As results from the actual marking are affected
by the disposition of actual sensors in the target address
region, we would not know the correct number of ac-
tual sensors. The simulation derives the probability of
successful markings, under the assumption that all ad-
dresses in the target region host sensors.
We simulated this algorithm against 30 pairs of ac-
tual port reports from 31 consecutive days in Decem-
ber 2004, with encoding space size set to 16,384 (14-
bit). Also, nmarker, number of markers, was set to
stddev(EC), unless stddev(EC) is greater than 16, in
which case nmarker was set to 16. Table 2 only shows
results for the ﬁrst week, but other dates came up with
similar numbers. The last column shows result of 4-way
majority marking, in which hit is counted when at least
3 out of 4 markers satisfy the hit condition.
As shown in this table, the algorithm does perform
well, despite the fact that it is quite naive. In fact, the 4-
way redundant marking with ’at least 3 out of 4’ majority
condition achieves almost perfect results, even though
it reduces the available port-space to one quarter of the
original size. More sophisticated ways of trend analy-
sis that derive better port space may further improve the
performance, especially in the non-redundant case.
For some day-pairs, the number of markers, or in-
tensity, can be much smaller, some times as small as 8
markers without sacriﬁcing the performance. However,
the table shows mechanically computed value, which is
based on standard deviation of event counts, which is
for stealthiness. The intensity seems unrelated to any of
the statistical values we have used in our example algo-
rithm, so there must be something that we have missed
here. Nevertheless, with intensity of at most 16 mark-