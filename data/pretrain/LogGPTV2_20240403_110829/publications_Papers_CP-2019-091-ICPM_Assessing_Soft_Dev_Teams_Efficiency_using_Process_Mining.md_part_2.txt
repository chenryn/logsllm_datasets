timestamps that formed the table’s unique key were used for
B. Experimental Setup
merging duplicated data. Figure 1 presents a schema of the
1) Subjects: Subjects were finalists (3rd year) of a BSc
data collection workflow.
degree on computer science at the ISCTE-IUL university,
attending a compulsory software engineering course. By this
time they had been trained across the same set of almost
30 courses and therefore had similar backgrounds. They
worked in teams up to 4 members each and were requested
to complete a code-smells detection assignment, aiming at
identifying refactoring opportunities, using the JDeodorant
tool2. This tool allowed the detection of four different types
of code smells: Long Method, God Class, Feature
Envy and Type Checking [25]. Once they have detected
the occurrences of those code smells, they were required to
apply JDeodorant’s automatic refactoring features to the
critical ones.
2) Data Collection Instrument: The Eclipse IDE has an
internaleventbusaccessedbytheinterfaceIEventBroker3
which is instantiated once the application starts. It contains a
publishing service to put data in the bus, whilst the subscriber
service reads what’s in that bus. This allows a subscriber to
read all or part of the events being managed within the IDE.
UsingthisfeaturewedevelopedanEclipseplugin4 capable
of listening to the actions developers were executing. Before
the experiment, the plugin was installed on each subject work
1http://jasml.sourceforge.net/ Fig.1. ExperimentDataCollectionWorkflow
2https://marketplace.eclipse.org/content/jdeodorant
3https://wiki.eclipse.org/Eclipse4/RCP/Event Model
4https://github.com/jcaldeir/iscte-analytics-plugins-repository 5https://azure.microsoft.com/en-us/services/event-hubs/
5) Data Preparation: When the software quality task perform process variants comparisons [24], [30]. All of these
ended, all events stored in the database were converted to the fit within the well defined [15] and generally accepted four
IEEE eXtensible Event Stream (XES) standard format [26] dimensionstoassessthequalityofamodel:fitness,precision,
and imported into ProM process mining tool6. The following simplicity and generalization.
eventpropertiesweremappedwhenconvertingtoXESformat: 2) ProcessDiscovery: Severalwellknownalgorithmsexist
• team was used as CaseID since we were interested to to discover process models, such as, the α-algorithm, the
look into process instances of teams, not of individual heuristics, genetic and fuzzy miner. However, our need to
programmers. discover and visualize the processes in multiple ways lead us
• Properties categoryName and commandName forming a to choose the ProM’s StateChart Workbench plugin
hierarchical structure were used as the activity in the [24]. This plugin, besides supporting process model discovery
process. usingmultiplehierarchiesandclassifiers,alsoallowstovisual-
• Thetimestamp beginandtimestamp end werebothused ize the model as a Sequence Diagram and use notations such
as activity timestamps. as Petri Nets and Process Trees. This plugin is particularly
• Other properties were used as a resource in the process. suitable for mining software logs, where an event structure is
supposedtoexist,butitalsosupportsminingofotherso-called
6) DataDemographics: Aspreviouslymentioned,weonly
generic logs.
analyzeddatacollectedonthesamesoftwaresystem,toblock
Events collected from software in operation (e.g. Java pro-
confounding factors. The chosen system was Jasml (Java
Assembling Language)7. grams) reveals the presence of a hierarchical structure, where
methods reside within classes, and classes within packages
The plugin collected two types of events: events within a
[31]. The same applies to IDE usage actions, since identified
project context(PE) and generic events(GE) at the Eclipse
menuoptionsandexecutedcommandsbelongtoaspecificcat-
global context. The former summarizes events for which
egory of command options built-in the Eclipse framework.
we have associated project and file names. This information
Supported by this evidence, we used the Software log Hierar-
expresses actions done by each developer in the project
chical discovery method with a Structured Names heuristic,
where JDeodorant features, such as, detecting a God
to discover the models based on the fact that the events
Class, Long Method, File Open, File Edit,
were using a category|command structure (e.g. Eclipse
Refactoring, Delete Resources,wereapplied.The
Editor|File Open). Several perspectives can be used to
latter represents events captured from Eclipse command
discover and analyze a business process and the most com-
actions not associated with any project (e.g. Update
monly used are: Control-Flow, Organizational,
Eclipse Software, Install New Software,
SocialandPerformance.Forthesakeofspace,wehave
Open Eclipse View Task List, etc).
justfocusedontheControl-Flowperspectiveinthispaper.
We present their statistics in Table I. Project events should
It defines an approach that consists in analyzing how each
be seen as fundamental events for the task programmers were
task/activity follows each other in an event log, and infer
requestedtoexecute,and,inacertainwayrepresentthefocus
a possible model for the behavior captured in the observed
their are putting into that work. Generic events are seen as
process.
collateral actions not mandatory for the task in hand, but that
3) Process Variant Comparison: Our goal was also to
programmers may need or want to execute to prepare their
compare the behaviour among the teams involved in the
environment. These generic events somehow convey a lack of
experiment against the ”best practice” process, as performed
focus on the task developers were supposed to execute.
by the expert, and identify the ones with less differences. For
The REFERENCE(also identified as REF.) team, corre-
this purpose, we used the Process Comparator plugin
sponds to the professor that proposed the task itself. Being
[30], which is a tool that compares a collection of event logs,
the main expert, he executed it in one of the most efficient
usingadirectedflowgraph.Itusestransitionsystemstomodel
ways. The full dataset, that includes data on all teams with
behavior and to highlight differences. Transition systems are
finegraineddatathatisnotaddressedinthispaper,ispublicly
available.8 annotatedwithmeasurements,andusedtocomparethebehav-
ior in the different variants. The annotations of each variant
C. Data Analysis are compared using statistical significance tests, in order to
1) Context: Several approaches have been proposed to detect relevant differences.
evaluate the quality of discovered process models. Software
IV. RESULTS
quality metrics were mapped to process metrics in [27].
Figure 2 presents team T-26 process variant, showing the
Groups of metrics were also used in [28], [29] to evaluate
code smells detection activities, and the correspondent statis-
several dimensions in a process model and, more recently,
tics about the process followed to execute the requested task.
artifactswerecreatedtosupportprocessqualityevaluationand
Itisclear,basedonthedifferentlevelsofblueintheactivities
6version6.8,availableathttp://www.promtools.org performed, that they executed moreoften the activities related
7http://jasml.sourceforge.net/ withthecodesmellsdetectionandcorrection.Weconfirmthis
8doi:10.17632/8dmdwpgdy4.1
TABLEI
COLLECTEDEVENTSSTATISTICS
Team TM UCC UCA UEA PE(#/%) GE(#/%) TE(#)
T-43 4 10 38 39 790/85.13% 138/14.87% 928
T-41 2 10 37 40 615/77.75% 176/22.25% 791
T-02 3 12 41 24 552/74.80% 186/25.20% 738
T-26 2 8 28 22 360/77.25% 106/22.75% 466
T-23 1 9 23 22 276/93.24% 20/6.76% 296
T-21 1 9 27 23 272/77.71% 78/22.29% 350
T-24 1 8 26 13 181/89.60% 21/10.40% 202
T-01 4 13 45 16 105/29.49% 251/70.51% 356
REF. 1 4 12 20 134/97.10% 4/2.90% 138
TM-Teammembers,UCC-UniqueCommandCategories,UCA-UniqueCommandActions,UEA-UniqueEditedArtifacts
PE-Projectrelatedevents,GE-GenericEclipseevents,TE-Totalevents
by observing the Eclipse Editor | File Editing good proficiency in the task, as seen in Table IV, but showed
activity which was executed more than any other activity. high levels of complexity in the model. This means we are
Globally, our attention went to the evaluation of the Sim- dealing with a case where the team was effective, because
plicity (or Complexity) of the models discovered. Simplicity they achieved the task with success, although without being
alludetotherulethatthesimplestmodelthatcandescribethe efficient in the process. This is confirmed by the high number
behavior found in a log, is indeed the best model. of different commands executed showed in Table I.
Software artifacts with higher cyclomatic complexity tend We also compared the behaviour between the 3 teams with
to be harder to maintain. It has been claimed that the same less complex models against the reference model. The level
rationale is applicable to process models [32]. Based on this, of Control-Flow differences based on activity frequencies, as
we were looking for the teams with less complexity in their calculated with the Process Comparator plugin, is plotted in
processes. As shown, teams T-26, T-24 and T-41 are the ones table III. Team T-24 was the one with less differences when
with less Cyclomatic Complexity (as represented by compared with the reference model, followed very closely
differentlevelsofgreen),thereforeclosertothecomplexityof by T-26. Based on the complexity measurements, control-
theREFERENCEmodel.Thatisalsoreflectedbythenumber flow differences and team size, we advocate that T-26 had
of Simple and Composite States, and Activities accomplished the task with the best overall efficiency and
discovered in each of those models. Team T-26 modelled effectiveness. In fact, that is also reflected in the proficiency
behavior was also the one discovered with best precision mark given by the professor (that acted as the task expert), as
(45%) among these 3 teams. shownintableIV.Thisraisesasetofotherresearchquestions,
On the opposite pole (as represented by different levels such as: can process mining be used to assess the proficiency
of red) with an unique characterization, we have team T- of developers in general, or just for specific kinds of tasks?
01, with four members, which did not delivered the results
of the requested task. Its proficiency was insufficient and TABLEII
carefulreviewoftheprocessrevealedthisteamproducedmore MODELSDISCOVERED-METRICSSUMMARIZATION
genericeventsthanprojectrelatedevents,asshowninTableI.
Team F(%) P(%) A HD SS CS T CC
From Figure 3 we can also learn this team used more unique
T-43 85.8% 39.9% 37 2 93 12 130 35
command actions and respective categories than any other T-41 74.2% 43.9% 38 2 88 11 121 31
team, and that did not increase the number of edited files, as T-02 81.6% 33.8% 47 2 109 11 159 48
T-26 80.1% 45.0% 25 2 60 6 85 23
one would have expected. This leads us to think its members
T-23 79.7% 32.3% 31 2 104 16 141 35
did not understand or follow the process at all, since many
T-21 94.2% 46.5% 36 2 93 12 131 36
of their actions in the IDE apparently were not aligned with T-24 94.4% 35.9% 30 2 74 8 103 27
the required task. The high values of complexity, activities, T-01 91.7% 43.0% 52 2 147 18 209 60
number of transitions and composite states metrics observed REF. 85.1% 53.7% 16 2 47 6 64 15
in Table II complements this assumption.
We can, therefore, state the following: T-01 was an ”ex- F-Fitness,P-Precision,A-Activities,HD-HierarchyDepth,
pensive” team and the one that presented more risks from a SS-SimpleStates,CS-CompositeStates,T-Transitions,
CC-CyclomaticComplexity
project management perspective. When compared with other
teams, this team had a similar process duration (see table IV)
inexecutingthetask,butdidnotdelivertheexpectedoutcomes A. Validity Threats
at all. This team was not only non effective, but also showed 1) Internal validity: Since some teams worked in shared
major inefficiencies in whatever they tried to produce. laboratories at the university campus, different team members
AninterestingcasetostudydeeperisteamT-02whichhada may have used, in the same computer, the same user/key pair
UniqueCommandCategories UniqueCommandActions UniqueEditedFiles
40
30
20
10