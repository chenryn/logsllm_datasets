the victim thread again ﬂushes the cache lines. We again
rule out any leaks via store-to-load forwarding, by turning
on Speculative Store Bypass Disable (SSBD [44]) for both
attacker and victim. Figure 5 shows the RIDL results. For
WB without ﬂushing, there is a signal only for the last
cache line, which suggests that the CPU performs write
combining in a single entry of the LFB before storing the
data in the cache. More importantly, we observe the signal
regardless of the memory type when ﬂushing. Since both
ﬂushing and the WT, WC and UC memory types enforce
direct invalidation of writes, they must go through the
LFB. This third experiment again indicates that the source
of our leak must be the LFB.
Conclusion: our RIDL variant leaks from the Line Fill
Buﬀers (LFBs).
(cid:26)(cid:20)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:51:31 UTC from IEEE Xplore.  Restrictions apply. 
earlier (based on Flush + Reload, or Evict + Reload
when clflush is not available) to expose the desired
data. The key diﬀerence with prior Meltdown/L1TF-style
attacks that cross privilege boundaries and address spaces
is that the target address used by the attacker can be per-
fectly valid. In other words, the attack does not necessarily
require a TSX transaction or an invalid page fault, but
can also be applied to a correct, branchless execution with
demand paging (i.e., a valid page fault) as we showed in
Section V. This bypasses side-channel mitigations deployed
on all the major operating systems and extends the threat
surface of prior cross-address space speculative execution
attacks to managed sandboxes (e.g., JavaScript). In the
next sections, we explore how RIDL can be used to leak
sensitive information across diﬀerent security boundaries.
Covert channel. We performed an extensive evaluation
of RIDL over a number of microarchitectures, showing that
it aﬀects all recent Intel CPUs. To verify that RIDL works
across all privilege boundaries, we implemented a proof-of-
concept covert channel, sending data across address space
and privilege boundaries.
In Table I, we present the bandwidth of the covert
channel. Note that our implementation is not yet opti-
mized for all architectures. For convenience, we utilize
Intel TSX on the architectures where available, as this
gives us the most reliable covert channel. Using TSX, we
achieve a bandwidth of 30-115 kB/s, where the limiting
factor is Flush + Reload. Where TSX is not available,
we present numbers from an unoptimized proof-of-concept
implementation which uses either demand paging, or ex-
ception suppression using speculative execution.
Challenges. In the previous sections, we discussed how
the building blocks of RIDL are used to leak in-ﬂight data
and that we can use RIDL to leak information across se-
curity domains. Applying these techniques to exploit real-
world systems—leaking conﬁdential data—presents some
additional challenges that we need to overcome:
1) Getting data in-ﬂight. We need to ﬁnd ways to get
restricted data that we want to leak into the LFB. There
are some obvious mechanisms for an unprivileged user to
get privileged data in-ﬂight: interaction with the kernel
(i.e., syscalls), and interaction with a privileged process
(i.e., invoking a setuid binary). There are also many other
possibilities, such as manipulating the page cache.
2) Targeting. Due to the high amount of LFB activity,
getting the desired data out of the LFB poses a challenge.
We describe two mechanisms for targeting the data we
want to leak: synchronizing the victim, and aligning the
leaked data by repeating the attack multiple times while
ﬁltering out the noise.
In the next sections, we demonstrate a number of
exploits that use RIDL. We evaluated all the exploits on
the Intel Core i7-7800X running Ubuntu 18.04 LTS.
A. Cross-process attacks
In a typical real-world setting, synchronizing at the
exact point when sensitive data is in-ﬂight becomes non-
trivial, as we have limited control over the victim process.
Fig. 6: Leaking the secrets A and B written by the victim to a
series of cache lines to trigger continuous eviction. On the left,
the victim writes A then B using a 1:4 ratio. On the right, the
victim writes A then B using a 2:1 ratio.
between two diﬀerent values to write after ﬁnishing every
loop and also vary the amount of pages to write during
the loop. For the ﬁrst test, we write the ﬁrst value 1024
times and the second value 256 times (ratio 1:4) and for
the second test, we write the ﬁrst value 512 times and the
second 1024 times (1:2 ratio). Figure 6 shows the results
of this experiment, where we observe the ﬁrst value 80%
of the times and the second value 20% of the times in the
case of ratio 1:4 and the ﬁrst value 33.3% of the times and
the second value 66.6% of the times in the case of ratio 2:1.
Hence, we conclude that we can control the (dirty) cache
entry to leak through eviction.
Conclusion: we can use serialization, contention and
eviction to synchronize attacker and victim.
VI. Exploitation with RIDL
The techniques described in the previous section allow
us to leak in-ﬂight CPU data in a controlled fashion. Since
the underlying buﬀers are independent of address spaces
and privilege levels, we can mount attacks across these
security boundaries.
We have veriﬁed that we can leak information across
arbitrary address spaces and privilege boundaries, even on
recent Intel systems with the latest microcode updates and
latest Linux kernel with all the Spectre, Meltdown, L1TF
default mitigations up (KPTI, PTE inversion, etc.). In
particular, the exploits we discuss below exemplify leaks
in all the relevant cases of interest: process-to-process,
kernel-to-userspace, guest-to-guest, and SGX-enclave-to-
userspace leaks. Not to mention that such attacks can
be built even from a sandboxed environment such as
JavaScript in the browser, where the attacker has limited
capabilities compared to a native environment.
We stress that the only requirement is the presence of
in-ﬂight secret data managed by the processor. In a non-
SMT single-core attack scenario, this is data recently read-
/written by the victim before a mode switching instruction
(iret, vmenter, etc.). In an SMT attack scenario, this
is data concurrently read/written by another hardware
thread sharing the same CPU core. Once we have spec-
ulatively leaked a value, we use the techniques discussed
(cid:26)(cid:21)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:51:31 UTC from IEEE Xplore.  Restrictions apply. 
TABLE I: Our results for 15 diﬀerent microarchitectures and the measured bandwidth across security domains.
Page Fault
Demand Paging
Misaligned
Read
TSX
SGX
Bandwidth (B/s)
CPU
Intel Xeon Silver 4110 (Skylake SP)
Intel Core i9-9900K (Coﬀee Lake R)
Intel Core i7-8700K (Coﬀee Lake)
Intel Core i7-7800X (Skylake X)
Intel Core i7-7700K (Kaby Lake)
Intel Core i7-6700K (Skylake)
Intel Core i7-5775C (Broadwell)
Intel Core i7-4790 (Haswell)
Intel Core i7-3770K (Ivy Bridge)
Intel Core i7-2600 (Sandy Bridge)
Intel Core i3-550 (Westmere)
Intel Core i7-920 (Nehalem)
AMD Ryzen 5 2500U (Raven Ridge)
AMD Ryzen 7 2600X (Pinnacle Ridge)
AMD Ryzen 7 1600X (Summit Ridge)
r
a
e
Y
2017
2018
2017
2017
2017
2015
2015
2014
2012
2011
2010
2008
2018
2018
2017
d
a
e
r
h
T
-
e
m
a
S
R/W

R/W
R/W
R/W
R/W
R/W
R/W
R/W
R/W
R/W
R/W



d
a
e
r
h
T
-
s
s
o
r
C
R/W

R/W
R/W
R/W
R/W
R/W
R/W
R/W
R/W
R/W
R/W



d
a
e
r
h
T
-
e
m
a
S
R/W
R/W
R/W
R/W
R/W
R/W
R/W
R/W
R/W
R/W
R/W
R/W



d
a
e
r
h
T
-
s
s
o
r
C
R/W
R/W
R/W
R/W
R/W
R/W
R/W
R/W
R/W
R/W
R/W
R/W



d
a
e
r
h
T
-
e
m
a
S
d
a
e
r
h
T
-
s
s
o
r
C
d
a
e
r
h
T
-
s
s
o
r
C
s
d
s
a
e
c
e
r
o
h
r
P
T
-
-
s
e
s
m
o
r
a
C
S
(cid:2) (cid:2)
45k
(cid:2) (cid:2) (cid:2) (cid:2) 71k
(cid:2) (cid:2) (cid:2) (cid:2) 54k
(cid:2) (cid:2)
37k
(cid:2) (cid:2) (cid:2) (cid:2) 65k
(cid:2) (cid:2) (cid:2) (cid:2) 68k
(cid:2) (cid:2)
21k
100
92
107
1k
79
e
g
e
l
i
v
i
r
P
-
s
s
o
r
C
25k
48k
49k
36k
46k
20k
16k
50
41
73
245
32
M
V
-
s
s
o
r
C
3k
10k
46k