### Victim Thread and Cache Line Flushing

The victim thread flushes the cache lines, and to rule out any potential leaks via store-to-load forwarding, we enable Speculative Store Bypass Disable (SSBD) for both the attacker and the victim. The results of the RIDL experiment are shown in Figure 5. When write-back (WB) is performed without flushing, a signal is observed only for the last cache line, indicating that the CPU performs write combining in a single entry of the Line Fill Buffer (LFB) before storing the data in the cache. More importantly, the signal is observed regardless of the memory type when flushing. Since both flushing and the Write-Through (WT), Write-Combining (WC), and Uncacheable (UC) memory types enforce direct invalidation of writes, they must go through the LFB. This third experiment further suggests that the source of the leak is the LFB.

**Conclusion:** Our RIDL variant leaks from the Line Fill Buffers (LFBs).

### Covert Channel and Bandwidth

To expose the desired data, earlier methods such as Flush + Reload or Evict + Reload (when `clflush` is not available) were used. The key difference with prior Meltdown/L1TF-style attacks, which cross privilege boundaries and address spaces, is that the target address used by the attacker can be perfectly valid. This means the attack does not necessarily require a TSX transaction or an invalid page fault; it can also be applied to a correct, branchless execution with demand paging (i.e., a valid page fault), as demonstrated in Section V. This bypasses side-channel mitigations deployed on all major operating systems and extends the threat surface of prior cross-address space speculative execution attacks to managed sandboxes (e.g., JavaScript).

In the following sections, we explore how RIDL can be used to leak sensitive information across different security boundaries.

#### Covert Channel Evaluation

We conducted an extensive evaluation of RIDL across various microarchitectures, showing that it affects all recent Intel CPUs. To verify that RIDL works across all privilege boundaries, we implemented a proof-of-concept covert channel, sending data across address space and privilege boundaries.

Table I presents the bandwidth of the covert channel. Note that our implementation is not yet optimized for all architectures. For convenience, we utilized Intel TSX where available, as it provides the most reliable covert channel. Using TSX, we achieve a bandwidth of 30-115 kB/s, with the limiting factor being Flush + Reload. Where TSX is not available, we present numbers from an unoptimized proof-of-concept implementation using either demand paging or exception suppression via speculative execution.

### Challenges in Exploitation

In the previous sections, we discussed how the building blocks of RIDL are used to leak in-flight data and how RIDL can be used to leak information across security domains. Applying these techniques to exploit real-world systems—leaking confidential data—presents some additional challenges:

1. **Getting Data In-Flight:** We need to find ways to get restricted data into the LFB. Some obvious mechanisms for an unprivileged user include interacting with the kernel (e.g., syscalls) and interacting with a privileged process (e.g., invoking a setuid binary). Other possibilities include manipulating the page cache.
2. **Targeting:** Due to the high amount of LFB activity, extracting the desired data poses a challenge. We describe two mechanisms for targeting the data: synchronizing the victim and aligning the leaked data by repeating the attack multiple times while filtering out the noise.

### Cross-Process Attacks

In a typical real-world setting, synchronizing at the exact point when sensitive data is in-flight becomes non-trivial, as we have limited control over the victim process. Figure 6 illustrates the results of an experiment where the victim writes two values, A and B, to a series of cache lines to trigger continuous eviction. On the left, the victim writes A then B using a 1:4 ratio, and on the right, the victim writes A then B using a 2:1 ratio. We observe the first value 80% of the time and the second value 20% of the time in the case of a 1:4 ratio, and the first value 33.3% of the time and the second value 66.6% of the time in the case of a 2:1 ratio. This demonstrates that we can control the (dirty) cache entry to leak through eviction.

**Conclusion:** We can use serialization, contention, and eviction to synchronize the attacker and the victim.

### Exploitation with RIDL

The techniques described in the previous section allow us to leak in-flight CPU data in a controlled manner. Since the underlying buffers are independent of address spaces and privilege levels, we can mount attacks across these security boundaries.

We have verified that we can leak information across arbitrary address spaces and privilege boundaries, even on recent Intel systems with the latest microcode updates and the latest Linux kernel with all the Spectre, Meltdown, and L1TF default mitigations enabled (KPTI, PTE inversion, etc.). The exploits discussed below exemplify leaks in all relevant cases: process-to-process, kernel-to-userspace, guest-to-guest, and SGX-enclave-to-userspace leaks. Such attacks can be built even from a sandboxed environment like JavaScript in a browser, where the attacker has limited capabilities compared to a native environment.

We emphasize that the only requirement is the presence of in-flight secret data managed by the processor. In a non-SMT single-core attack scenario, this is data recently read/written by the victim before a mode switching instruction (e.g., `iret`, `vmenter`, etc.). In an SMT attack scenario, this is data concurrently read/written by another hardware thread sharing the same CPU core. Once we have speculatively leaked a value, we use the techniques discussed to extract the information.

### Bandwidth Results

Table I summarizes our results for 15 different microarchitectures and the measured bandwidth across security domains. The table includes various configurations such as Page Fault, Demand Paging, Misaligned Read, TSX, and SGX, along with the corresponding bandwidth in bytes per second (B/s).

| CPU | Year | Page Fault | Demand Paging | Misaligned Read | TSX | SGX | Bandwidth (B/s) |
| --- | ---- | ---------- | -------------- | ---------------- | --- | --- | --------------- |
| Intel Xeon Silver 4110 (Skylake SP) | 2017 | R/W | R/W | R/W | R/W | - | 45k |
| Intel Core i9-9900K (Coffee Lake R) | 2018 | R/W | R/W | R/W | R/W | - | 71k |
| Intel Core i7-8700K (Coffee Lake) | 2017 | R/W | R/W | R/W | R/W | - | 54k |
| Intel Core i7-7800X (Skylake X) | 2017 | R/W | R/W | R/W | R/W | - | 37k |
| Intel Core i7-7700K (Kaby Lake) | 2017 | R/W | R/W | R/W | R/W | - | 65k |
| Intel Core i7-6700K (Skylake) | 2015 | R/W | R/W | R/W | R/W | - | 68k |
| Intel Core i7-5775C (Broadwell) | 2015 | R/W | R/W | R/W | R/W | - | 21k |
| Intel Core i7-4790 (Haswell) | 2014 | R/W | R/W | R/W | R/W | - | 100 |
| Intel Core i7-3770K (Ivy Bridge) | 2012 | R/W | R/W | R/W | R/W | - | 92 |
| Intel Core i7-2600 (Sandy Bridge) | 2011 | R/W | R/W | R/W | R/W | - | 107 |
| Intel Core i3-550 (Westmere) | 2010 | R/W | R/W | R/W | R/W | - | 1k |
| Intel Core i7-920 (Nehalem) | 2008 | R/W | R/W | R/W | R/W | - | 79 |
| AMD Ryzen 5 2500U (Raven Ridge) | 2018 | - | - | - | - | - | 25k |
| AMD Ryzen 7 2600X (Pinnacle Ridge) | 2018 | - | - | - | - | - | 48k |
| AMD Ryzen 7 1600X (Summit Ridge) | 2017 | - | - | - | - | - | 49k |

This table provides a comprehensive overview of the performance and applicability of RIDL across a wide range of microarchitectures.