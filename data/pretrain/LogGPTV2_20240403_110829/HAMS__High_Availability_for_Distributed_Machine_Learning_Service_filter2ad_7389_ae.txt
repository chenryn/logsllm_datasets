### HAMS Performance and Fault Tolerance Analysis

#### State Retrieval and Delivery Times
HAMS demonstrated efficient state retrieval (e.g., 11.63ms in FD) and state delivery times to the backup (e.g., 2.4ms in FD). The NPSB protocol effectively masks latency overhead across all batch sizes. We also evaluated HAMS-Remus under the same experimental settings, as shown in Figure 11b. For all combinations of services and batch sizes, HAMS-Remus exhibited an average latency overhead that was 5.51X higher than HAMS.

Figure 12 illustrates the throughput of four systems, normalized to bare metal. HAMS incurred minimal throughput overhead. For SA, HAMS-Remus also had little impact on throughput. This is because the audio transcriber operator, which is the throughput bottleneck for SA, remains unaffected by HAMS-Remus's fault tolerance logic. Overall, HAMS's performance in normal operation is reasonable for deploying real-world ML services.

#### Summary of Normal Case Performance Overhead
HAMS incurs minimal normal case performance overhead if two conditions are met:
1. In a stateful model, the time taken by the computation stage for the (n + 1)th batch of requests is longer than the time taken by HAMS to retrieve the model’s state updated by the nth batch. This allows NSPB to retrieve the model’s state in parallel with the computation stage of the next batch.
2. Each stateful model has downstream models in the service DAG, allowing the delivery of the stateful model’s state to be done in parallel with the processing of downstream models. If the stateful model is the last in the DAG (e.g., in the AP service), its outputs must be buffered at the frontend until the state updated by the client’s request is delivered to the model’s backup. HAMS incurred minimal performance overhead in SA because SA's latency is dominated by the first operator. Our evaluation found that both conditions were often met when the batch size of a service was at least 64, a typical setting in real-world deployments.

#### Effectiveness of HAMS Components
The NSPB protocol in HAMS includes two components for low performance overhead: retrieving a model’s state without stopping and fast output releasing without waiting for state delivery to the backup. To analyze the effectiveness of these components, we evaluated the six services’ latencies with a batch size of 64 under two settings:
1. Disabling the fast output releasing and buffering the output until the state is delivered to the backup (HAMS-S1).
2. Disabling the non-stop state retrieving but still enabling the fast output releasing (HAMS-S2).

The results show that HAMS-S1 incurred a maximum latency slowdown of 53.94% compared to HAMS in the normal case, while HAMS-S2 incurred a maximum latency slowdown of 57.05%. Both HAMS-S1 and HAMS-S2 had lower latency than HAMS-Remus, indicating that both components are essential.

#### Recovery Time
We compared the recovery time of three fault tolerance systems: HAMS, HAMS-Remus, and LS. For HAMS and HAMS-Remus, we randomly selected one stateful operator in each of the six services (with a batch size of 64) and killed its primary. For LS, we killed the primary operator in each service at the 50th batch of requests from its latest checkpoint (LS performs a checkpoint every 150 batches of requests).

Both HAMS and HAMS-Remus achieved sub-second recovery times. HAMS and HAMS-Remus have a hot standby backup for each stateful operator, so the recovery time mainly consists of failure discovery, recovery protocol, and backup handover. LS achieved minute-level recovery times, primarily due to the operator’s checkpoint loading and replay time. We set LS’s checkpoint interval to every 1 batch of requests, resulting in an 81% average latency overhead, as LS essentially became HAMS-Remus.

We also killed a stateless operator in each service and found that HAMS, LS, and HAMS-Remus showed similar recovery times, averaging 320.45 milliseconds. The recovery time for all three systems was dominated by the time to update the service graph’s topology and the proxies' logic.

To evaluate HAMS’s recovery on correlated failures, we conducted three experiments on the SP and AP services. First, we killed O3 (a stateless model) and O4 (a stateful model) in the SP service, resulting in an average recovery time of 344.79ms, dominated by the time to relaunch a new stateless O3. Second, we killed the primaries of O2 and O3 (two adjacent stateful models in AP) and collected an average recovery time of 172.24ms, approximately 20ms longer than killing one of them due to the additional timeout for suspecting the second failure. HAMS’s recovery time for these correlated failures was only slightly longer than for a single failure, as HAMS recovers each failed model in parallel.

Third, we triggered the case in Figure 6 using AP by delaying state delivery of O2 and then killing its primary, and simultaneously killing O3’s backup. HAMS ensured global consistency, but this extreme case incurred an average recovery time of 731.24ms, primarily due to O3’s primary stopping its current execution on GPU and rolling back to a previous state. This result suggests that promoting downstream models’ backups is more efficient than rolling back their primaries when an upstream stateful model fails, aligning with NSPB’s design choice.

#### Limitations
HAMS has three limitations:
1. It requires 2X resources for replicating each stateful model, which is deemed worthwhile for ensuring sub-second failover time for mission-critical services. Only a small portion of models in a service graph are stateful and require extra resource usage.
2. Developers need to identify the computation and update stages of a stateful model, which can be done with 4-10 lines of code using HAMS’s API.
3. HAMS’s NSPB protocol is applicable only to ML operators that follow the compute-then-update manner, which is typical for neural networks. Studying other ML algorithms (e.g., graph-based ML) is left for future work.

#### Related Work
HAMS can be integrated into existing ML serving systems such as Clipper, Michelangelo, TensorFlow-Serving, TensorRT, Pretzel, and Ray, which simplify the deployment of ML models but do not focus on high availability. GranSLAm and Inferline optimize the deployment of ML service graphs but do not handle failures. ParM uses a parity model trained with erasure code to reconstruct prediction results of a failed model but does not support stateful models. State Machine Replication (SMR) models a stateful application as a deterministic state machine, but these systems are not suitable for ML models running on GPUs due to non-deterministic scheduling. Plover, Eve, and Colo compare state updates or outputs among replicas and invoke a state transfer on divergence, but they fall back to Remus for ML service graphs. Fault tolerance systems like TensorFlow, Apache Flink, Naiad, and Horovod use periodical global checkpoints and coordinated rollbacks, leading to long recovery times. Guard reduces normal case overhead with asynchronous checkpoints, while Ray, CIEL, Drizzle, Noria, Manetho, and Lineage Stash record runtime lineage information to reconstruct lost state on failures but do not handle internal non-determinism during replay.

#### Conclusion
HAMS is an efficient system for deploying highly available ML service graphs. The NSPB protocol combines the strengths of primary-backup and checkpoint-replay to meet fault tolerance requirements. HAMS can serve as a recovery component in existing ML serving systems, significantly improving their reliability. The source code is available on GitHub.

#### Acknowledgment
We thank all reviewers for their valuable comments. This work is funded by grants from the Huawei Innovation Research Program (HIRP) Flagship, HK RGC ECS No. 27200916, HK RGC GRF No. 17207117, No. 17202318, Croucher Innovation Award, and NSF China No. 61802358.