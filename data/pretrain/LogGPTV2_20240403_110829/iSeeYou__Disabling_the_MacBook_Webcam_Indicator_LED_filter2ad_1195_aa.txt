title:iSeeYou: Disabling the MacBook Webcam Indicator LED
author:Matthew Brocker and
Stephen Checkoway
iSeeYou: Disabling the MacBook  
Webcam Indicator LED
Matthew Brocker and Stephen Checkoway, Johns Hopkins University
https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/brocker
This paper is included in the Proceedings of the 23rd USENIX Security Symposium.August 20–22, 2014 • San Diego, CAISBN 978-1-931971-15-7Open access to the Proceedings of  the 23rd USENIX Security Symposium is sponsored by USENIXUSENIX Association  
23rd USENIX Security Symposium  337
iıSeeYou:DisablingtheMacBookWebcamIndicatorLEDMatthewBrockerJohnsHopkinsUniversityStephenCheckowayJohnsHopkinsUniversityAbstractTheubiquitouswebcamindicatorLEDisanimportantprivacyfeaturewhichprovidesavisualcuethatthecam-eraisturnedon.WedescribehowtodisabletheLEDonaclassofAppleinternaliSightwebcamsusedinsomeversionsofMacBooklaptopsandiMacdesktops.Thisenablesvideotobecapturedwithoutanyvisualindicationtotheuserandcanbeaccomplishedentirelyinuserspacebyanunprivileged(non-root)application.ThesametechniquethatallowsustodisabletheLED,namelyreprogrammingtheﬁrmwarethatrunsontheiSight,enablesavirtualmachineescapewherebymalwarerunninginsideavirtualmachinereprogramsthecameratoactasaUSBHumanInterfaceDevice(HID)keyboardwhichexecutescodeinthehostoperatingsystem.Webuildtwoproofs-of-concept:(1)anOSXapplica-tion,iSeeYou,whichdemonstratescapturingvideowiththeLEDdisabled;and(2)avirtualmachineescapethatlaunchesTerminal.appandrunsshellcommands.Tode-fendagainsttheseandrelatedthreats,webuildanOSXkernelextension,iSightDefender,whichprohibitsthemodiﬁcationoftheiSight’sﬁrmwarefromuserspace.1IntroductionVideoisineffablycompelling.The(consensual)shar-ingofvideoisanactofintimacyasitallowsthevieweraglimpseintothelifeofthesharer.ItisnosurprisethenthattheInternet’sﬁrst“lifecast,”JenniferRingley’s“JenniCam”in1996[24],wasvideoandnotaudio.Simi-larly,YouTube,themostpopularwebsiteforsharinguser-createdvideos,predatesSoundCloud,awebsitewithsim-ilarfunctionalityforaudio,byseveralyearseventhoughtechnologicalconstraintswouldsuggesttheoppositeor-der.Itispreciselybecauseoftheintimacyofvideothatturningonsomeone’scamerawithouthisorherknowl-edgeorconsentisaviolationmorefundamentalthanrecordingaudio.Beyondintentionalsharing,videomakesformorecompellingevidencethataneventoccurredasclaimedthaneitheranafter-the-facteyewitnessaccountoraudiorecording.Thisistruewhetheritisavideoofasuc-cessfullyperformedfeatofskill—e.g.,insports[44]orevenvideogames[49]—videoofpolicebrutality[55],videoofviolentcrime[63],orwebcamvideousedforblackmail[15].(a)Imagesensor(front)(b)Imagesensor(back)(c)Mainboard(front)(d)Mainboard(back)Figure1:TheiSightfroma2008MacBookwestudied.ThevalueofvideoevidenceissohighthatTheWash-ingtonPostrecentlyreportedthattheUSFederalBureauofInvestigation(FBI),hasdevelopedsurveillancemal-ware,similartotheproof-of-conceptdescribedinthispaper,whichcancovertlyturnonavictim’swebcam[59].Ofcourse,thethreattoprivacyfromwebcamsvulnerabletohackingcomesnotonlyfromlawenforcement.Atthebeginningofthe2008schoolyear,theLowerMerionSchoolDistrictprovidedaMacBooklaptoptoeachenrolledstudent.Theselaptopscamepre-loadedwiththeLANrevremoteadministrationtool(RAT)whichallowedschooldistrictofﬁcialsto,amongotherthings,captureimagesfromtheMacBooks’built-iniSightweb-cam.Duringthefollowing18months,ofﬁcialscapturedmorethan30thousandimagesfromthesewebcams[5,6].Theﬁrstindicationthatimageswerebeingcapturedwaseverytimethesoftwaretookapicture,thegreenindicatorLEDwouldbrieﬂyilluminate[5,6,42].Someteachersweresoconcernedbythistheytheycoveredthelensofthewebcamsontheirownlaptops[6].Here,theindicatorLEDworkedexactlyasitwassupposedtoandalertedtheusersthattheywerebeingphotographed.Thepossibilitythatawebcamcouldbecapturingpic-tureswithouttheLEDilluminatinghasledtosuggestionsthatownersshouldtapeoverthewebcam[43]aswellasproductsdesignedtocoverthecamerastickers[10,58].1This incident illustrates the dangers of passive sensors
attached to computers like cameras, microphones, and
GPS receivers. Unlike active input devices like keyboards
and mice that require user actions to provide input, a pas-
sive sensor requires no action on the part of the user to
capture input. Indeed, a user is typically unaware that
input is being captured at all unless speciﬁc mechanisms
are built into the technology to indicate that the sensor is
currently in use. Such mechanisms include camera-use in-
dicator LEDs, shutter sounds on cell phone cameras, and
GPS-use indicator icons on mobile devices and laptops.
In the past few years, the ever-expanding set of sen-
sors present in commodity laptops and smart phones has
prompted the security and privacy community to begin
researching ways to detect and limit the undesired use of
sensors [20, 22, 26, 27, 31]. At the same time, researchers
have demonstrated attacks exploiting the presence of sen-
sors such as a clickjacking attacks against Adobe Flash
to gain access to the camera and microphone [23] from
a malicious web page and exﬁltrating audio from micro-
phones in modern automobiles [11]. (See Section 2 for
more examples.)
Our results in this paper demonstrate that, at least in
some cases, people have been correct to worry about mal-
ware covertly capturing images and video. We show a
vulnerability in the iSight webcam that affects a particu-
lar range of Apple computers — including the MacBooks
given to the students in the Lower Merion School Dis-
trict — that can be exploited to turn on the camera and
capture images and video without the indicator illuminat-
ing.
At a high level, our investigation of the iSight revealed
that it is designed around a microprocessor and a sepa-
rate image sensor with an indicator LED sitting between
them such that whenever the image sensor is transmit-
ting images to the microcontroller, a hardware interlock
illuminates the LED. We show how to reprogram the mi-
crocontroller with arbitrary, new ﬁrmware. This in turn
enables us to reconﬁgure the image sensor, allowing us to
bypass the hardware interlock and disable the LED. We
also show a new method of performing a virtual machine
escape based on our ability to reprogram the microcon-
troller.
Speciﬁcally, our technical contributions in this paper
are ﬁve-fold:
1. We describe the architecture of the Apple internal
iSight webcam found in previous generation Apple
products including the iMac G5 and early Intel-based
iMacs, MacBooks, and MacBook Pros until roughly
2008 (Section 3).
2. We demonstrate how to bypass the hardware inter-
lock that the iSight uses to turn on the indicator
LED whenever the camera is capturing images or
video (Section 4) and provide a proof-of-concept
user space application, iSeeYou, to do so (Section 6).
3. We demonstrate how to use the capability developed
to bypass the hardware interlock to achieve a virtual
machine escape (Appendix A1).
4. We develop an OS X kernel extension, iSightDe-
fender, to defend against these attacks (Section 7).
5. We sketch the design space for building a secure
camera module (Section 8).
The ability to bypass the interlock raises serious pri-
vacy concerns and the technical means by which we ac-
complish it raises additional security concerns which we
discuss in Section 9.
Threat model. To mount our main attack where we cap-
ture video without any external indication to the victim,
we assume that an attacker is able to run native code on
the victim’s computer as an unprivileged user. Further,
we assume the code is unencumbered by defenses such
as Apple’s App Sandbox [4] which is used for applica-
tions downloaded from the Mac App Store but by little
else. This assumption is quite mild and would typically
be satisﬁed by malware such as RATs.
For the virtual machine escape, we assume the attacker
has code running locally in the virtual machine and with
whatever privileges the guest OS requires to communi-
cate with USB devices. We also assume that the virtual
machine monitor has exposed the iSight device to the
virtual machine. This second assumption is quite strong
as virtual machine monitors typically do not expose USB
devices to the guest OS unless the user speciﬁcally con-
ﬁgures it to do so, for example to use video conferencing
software.
Generality of results. We stress that our main result —
disabling the iSight LED — only applies to the ﬁrst gen-
eration internal iSight webcams, found in some Apple
laptops and desktops, and we make no claims of security
or insecurity of later models, including the most recent
(renamed) FaceTime cameras. The virtual machine es-
cape described in Appendix A likely holds for other USB
devices that use the Cypress EZ-USB chip used in the
iSight, but we have not yet tested other devices.
2 Related work
General purpose computers contain a variety of proces-
sors designed for performing specialized tasks other than
general-purpose computation. Examples include graph-
ics processing units (GPUs) which produce video output;
processors in network interface controllers (NICs) which
perform network packet processing; microcontrollers in
perhipherals such as keyboards, mice, and webcams; mi-
crocontrollers in laptop batteries; and, in some systems,
baseboard management controllers (BMCs) which en-
1Although we regard this as a major contribution, we have moved
the details to an appendix to improve the paper’s ﬂow
2
338  23rd USENIX Security Symposium 
USENIX Association
ables out-of-band system management independent of the
host computer’s CPU.
Security researchers have only recently begun examin-
ing these additional processors and the ﬁrmware that runs
on them. In many cases, the designers of these systems
appear not to have appreciated the security implications
of their interfaces and implementations.
Perhaps the most well-studied processor apart from the
CPU is the GPU. Vasiliadis et al. [60] demonstrate using
the GPU to harden malware against detection by using
the GPU to implement unpacking and runtime polymor-
phism. Ladakis et al. [33] use the GPU’s direct memory
access (DMA) capability to monitor the system’s key-
board buffer to build a keylogger. Beyond GPU mal-
ware itself, researchers have used the GPU to acceler-
ate malware detection [32] and intrusion detection sys-
tems [50].
Duﬂot and Perez [17] demonstrate exploiting a NIC to
achieve arbitrary code execution. In follow up work, Du-
ﬂot et al. [18] build a NIC malware detection framework.
Miller [39] demonstrates how to communicate with
Apple laptop batteries using the System Management
Bus, authenticate to the battery to “unseal” it, and change
both conﬁguration values and ﬁrmware. This enables
overcharging the battery resulting in overheating and, po-
tentially, leading to a ﬁre.
Tereshkin and Wojtczuk [57] introduce the concept of
a “Ring −3” rootkit which runs on Intel’s Active Manage-
ment Technology (AMT) hardware which has a processor
independent of the host CPU with a separate interface to
the NIC and DMA access to main memory.
In a very similar vein, Farmer [21] discusses weak-
nesses and vulnerabilities in the Intelligent Platform Man-
agement Interface (IPMI) — the standard interface to the
baseboard management controller (BMC). Like AMT, a
BMC has direct access to the host system but its oper-
ation is completely independent making exploits both
extremely powerful and difﬁcult to detect. Moore [41]
builds on this work to produce a penetration tester’s guide
for examining IPMI and BMCs.
A webcam is just a particular type of sensor attached to
a computing device. Others include microphones, ac-
celerometers, and GPS receivers. Our work joins an
emerging line of research on the security and privacy
implications of such sensors. For example, Schlegel et al.
[54] show how to use a smartphone’s microphone to ex-
tract credit card numbers and PINs from spoken and tone-
based interfaces. Marquardt et al. [36], Owusu et al. [46]
and Miluzzo et al. [40] use smartphone accelerometers to
extract information about key presses. Checkoway et al.
[11] extract audio and GPS coordinates from automobiles.
Templeman et al. [56] use smartphone cameras to covertly
take pictures which are then used to create 3D models of
physical spaces.
Our virtual machine escape (Appendix A) is not the ﬁrst
to emulate a USB Human Interface Device (HID) such
as a mouse or keyboard. Wang and Stavrou [62] use a
compromised smart phone to act as a USB HID keyboard
and send key presses to the host system. Kennedy and
Kelley [30] use a small microcontroller to interact with the
Windows Powershell. Pisani et al. [48] similarly describe
having USB devices pose as HID keyboards to control
the computer. Elkins [19] adds a RF receiver for remote
controlling a fake HID keyboard.
3
This section describes the architecture of the internal
iSight webcam in sufﬁcient detail to understand how the
multi-step attack described in Section 4 works. Readers
who are already familiar with the iSight or the Cypress
EZ-USB or who are not interested in the low-level details
of the device are encouraged to skip directly to Section 4
and use this section and Figure 2, in particular, as a refer-
ence as needed.
Internal iSight architecture
The internal iSight consists of a Cypress CY7C68013A
EZ-USB FX2LP, a Micron MT9V112 CMOS digital im-
age sensor, a 16 byte conﬁguration EEPROM, and an
indicator LED (see Figure 1). A block diagram is given
in Figure 2.
3.1 Cypress EZ-USB
The host computer interacts with the iSight entirely
through a USB connection to the Cypress EZ-USB. The
EZ-USB is responsible for handling all USB requests and
sending replies including video data.
The EZ-USB has an internal Intel 8051-compatible mi-
crocontroller core and 16 kB of on-chip RAM accessible
as both code and data “main” memory2 but lacks persis-
tent storage [13]. In general, the ﬁrmware for the 8051
core can be located in one of three locations: (1) external
memory such as ﬂash or EPROM attached to the EZ-USB
address/data bus; (2) an I2C EEPROM; or (3) loaded from
USB. The iSight loads its ﬁrmware at boot from the host
computer over USB (see Section 4.2).
3.2 Micron digital image sensor
The Micron digital image sensor is a low-power system-
on-a-chip (SOC) capable of producing an image in several
formats. The sensor is conﬁgured by the I2C interface
which can read from and write to several hundred con-
ﬁguration registers [37]. In addition to the I2C interface,
several hardware signals inﬂuence the operation of sensor.
The most important signals from our perspective are
the active-low #RESET and active-high STANDBY sig-
2The standard 8051 is a Harvard architecture which has separate code
and data memory differentiated by hardware signals. In the conﬁguration
used by the iSight, the signals are combined effectively giving a single
main memory address space.
USENIX Association  
23rd USENIX Security Symposium  339
3
CMOS Digital Image 
MT9V112
Sensor
EEPROM
L
C
S
A
D
S
L
C
S
A
D
S
L
C
S
A
D
S
]
:
[
0
7
T
U
O
D
8
]
:
0
7
D
F
[
T
E
S
E
R
#
Y
B
D
N
A
T
S
Vcc
LED driver
circuit
0
A
P
3
D
P
USB D+
USB D-
CY7C68013A
EZ-USB FX2LP
Figure 2: Internal iSight architecture block diagram con-
sisting of a Cypress EZ-USB, a Micron digital image sen-
sor, a 16 byte conﬁguration EEPROM, and an indicator
LED. The SCL and SCA lines comprise the I2C bus.
nals. The corresponding hardware pins are connected
directly to the EZ-USB’s general purpose I/O (GPIO)
pins. As shown in Figure 2, #RESET is connected to
pin 0 of GPIO port A and STANDBY is connected to
pin 3 of GPIO port D. The other connection between
the image sensor and the EZ-USB shown in Figure 2
DOUT[7:0]→FD[7:0] is an 8 bit unidirectional bus
which transfers pixel data to the EZ-USB’s FIFO inter-
face. Other, less important, control signals are omitted
from the diagram.
The #RESET signal performs a hardware reset, reset-
ting all conﬁguration registers to their default value. The
STANDBY signal controls output enable and power down
functions. That is, when STANDBY is asserted, the im-
age sensor stops producing data on DOUT[7:0] which
enters the high impedance state as well as allowing the
image sensor to transition to a low-power state.
3.3 Conﬁguration EEPROM