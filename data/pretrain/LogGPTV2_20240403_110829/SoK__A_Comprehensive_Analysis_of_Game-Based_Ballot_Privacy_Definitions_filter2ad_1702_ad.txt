505505
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:02:30 UTC from IEEE Xplore.  Restrictions apply. 
checking which candidate obtained at least two votes. This
attack was successfully implemented against Helios 2.0 by
Cortier and Smyth [27], [28], who also showed this constitutes
a privacy threat in real scenarios by studying the potential
impact on French legislative elections.
Let us argue that RPRIV does not capture replay attacks.
Consider a protocol where voters submit their encrypted votes
on a secure channel,
to an election server that publishes
the encrypted votes on the board (thus allowing ciphertext
copying). Assume moreover that only the result of the election
is published, once the voting phase is closed. Clearly, this
protocol is subject to replay attacks and therefore does not
ensure privacy. However, it is declared private by RPRIV.
Indeed, the only information that the adversary obtains is
the encrypted ballots and the result of the election. Since the
encryption scheme is IND-CPA, the adversary does not get any
information from the encrypted votes, so it must use the result
itself to try to win the RPRIV distinguishing game. Moreover,
by deﬁnition of this game, the adversary can see the result
only in cases where both ballots boxes yield identical results.
Therefore the adversary cannot win the game, since encrypted
votes without the result give no information, and the result
does not help distinguishing the boxes, since it is identical in
both boxes. For similar reasons, RPRIV would declare Helios
2.0 private.
IV. BALLOT PRIVACY: A COMPREHENSIVE
CRYPTOGRAPHIC GAME-BASED DEFINITION FOR VOTE
PRIVACY
Based on our ﬁndings on existing deﬁnitions of privacy, we
propose a new deﬁnition that avoids the aforementioned issues.
As in [12], [18], [19], [17], [22], we deﬁne ballot secrecy for
a voting scheme V in terms of a game between a challenger
and an adversary.
We give our new security notion in two steps. We start with
a vanilla variant that reﬂects the core deﬁnitional ideas behind
our notion and allows a focused discussion on its features.
Then, we explain how to incorporate in the deﬁnition the
existence of global setup assumption (e.g. random oracles or
common reference strings) as used by many existing voting
protocols.
Recall
that ballot privacy attempts to capture the idea
that during its execution a secure protocol does not reveal
information about the votes cast, beyond what is unavoidably
leaked (e.g. what
the result of the election leaks). As in
previous deﬁnitions, we formalize this idea via an adversary
that attempts to distinguish between two worlds. In the ﬁrst
world the adversary has (indirect) access to a ballot box that
contains ballots created by honest users as well as adversarial
ballots and gets to see the result corresponding to the ballot
box. In the second world the adversary sees a fake board
instead of the real one, yet gets to see the result of the election
as tallied on the real ballot box. Since we model explicitly
the additional information that the tally may include besides
the result (e.g. a proof of correct tally), we require that this
information does not reveal any information either: we require
via
the
We
formalize
discussion
the existence of a simulator that can “fake” the additional
information corresponding to the real result, but with respect
to the fake ballot box.
this
experiments
Expbpriv,βA,V (λ) deﬁned in Figure 2. In these games BB0, BB1
are ballot boxes that start out empty. Ballot box BB0
corresponds to the real election (that will be tallied). The
adversary gets access to BB0 in the ﬁrst game and access to
BB1 (a fake ballot box) in the second game. The experiment
starts with generating long term keys sk and pk;
the
adversary A is given the public key and access to the oracles
that we describe below and formalize in Figure 2.
Oboard: This models the ability of the adversary to see the
publishable part of the ballot box, i.e. the bulletin board.
The oracle returns Publish(BBβ).
OvoteLR: The left-right oracle OvoteLR takes two potential
votes (v0, v1) for user id, produces ballots b0 and b1 for
these votes and places them on the ballot box (one on
BB0 and one one on BB1), provided that bβ is valid with
respect to BBβ.
Ocast: This oracle allows the adversary to cast a ballot b on
behalf on any party. If the ballot is valid with respect to
BBβ, it is placed on both ballot boxes.
Otally: This oracle allows the adversary to see the result of the
election. In both worlds the result is obtained by tallying
BB0. In the ﬁrst experiment the additional information
calculated by the tally is given to the adversary, whereas
in the second experiment the additional information is
simulated.
The adversary can call oracles OvoteLR,Ocast,Oboard in
any order, and any number of times. Finally, A can call Otally
once; after it receives the answer to his query A returns a
guess bit on the value of β. This bit is the result returned by
the game.
Deﬁnition 7 (BPRIV): Consider a voting scheme V =
(Setup, Vote, Valid, Publish, Tally, Verify) for a set I of voter
identities and a result function ρ. We say the scheme has
ballot privacy if there exists an algorithm SimProof such
that no efﬁcient adversary can distinguish between games
Expbpriv,0
B,V (λ) deﬁned by the oracles in Figure
2, that is for any efﬁcient algorithm A
(cid:2)
B,V (λ) and Expbpriv,1
Expbpriv,0A,V (λ) = 1
Expbpriv,1A,V (λ) = 1
(cid:2)
(cid:4)(cid:4)(cid:4) Pr
(cid:3)
− Pr
(cid:3) (cid:4)(cid:4)(cid:4)
is negligible in λ.
A. Extension of the deﬁnition to setup assumptions
Most voting protocols rely on non-interactive zero knowl-
edge (NIZK) proofs to enforce honest behaviors for the parties
involved, yet such proofs require some setup assumptions (like
the CRS or the RO model). To be able to analyze these
protocols we need to extend our deﬁnition to account for such
setups. While it would be simple enough to provide a deﬁnition
of ROM-BPRIV or CRS-BPRIV, we would like our deﬁnition
to abstract away details of any particular model of zero-
knowledge as far as possible. Finding a truly model-agnostic
506506
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:02:30 UTC from IEEE Xplore.  Restrictions apply. 
ESOR.11
[12]
ESOR.09
[31], [33]
game-based
notion
detects leaky
revote policies
Helios 2.0 is
not private
protects ag. vote
comparisons
compatible with
tally uniqueness
admits duplicate
weed before tally
admits duplicate
weed inside tally
detects leaky
tally proofs
revoting allowed
models partially
hidden board
admits result
functions w/o
partial tallying
(cid:2)

(cid:2)
(cid:2)
?
(cid:2)

?
(cid:2)

(cid:2)


(cid:2)

(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)


PODC86
STOC94
[23]
[25]
(cid:2)

(cid:2)

(cid:2)


(cid:2)
(cid:2)


Benaloh
[24]
ESOR.13
[22]
ASIA. 12
[19]
PKC13
[21]
S&P 10
[10]
CCS12
[17]
ACNS04
[13]
Ours
Sec. IV
(cid:2)

(cid:2)
(cid:2)
(cid:2)


(cid:2)
(cid:2)


(cid:2)

(cid:2)
(cid:2)



(cid:2)
(cid:2)
/(cid:2)
(cid:2)
(cid:2)

(cid:2)
(cid:2)
(cid:2)
(cid:2)


(cid:2)

(cid:2)
(cid:2)



(cid:2)
(cid:2)

(cid:2)
(cid:2)

?

(cid:2)
(cid:2)

(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)



?
(cid:2)
(cid:2)
(cid:2)
(cid:2)

(cid:2)
?

(cid:2)

?
(cid:2)
(cid:2)
(cid:2)
?
?
(cid:2)



(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)