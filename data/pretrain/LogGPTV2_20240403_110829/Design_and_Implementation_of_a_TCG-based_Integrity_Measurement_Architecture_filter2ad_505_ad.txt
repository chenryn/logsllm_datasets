posed to the PCRs, these counters are never cleared or de-
creased but can only increase throughout the lifetime of a
TPM. Increases of one of these counters could be triggered
by the BIOS each time the system reboots. The BIOS is
also responsible to disable the TPM as soon as the counter
has reached its maximum value. Typical TPM have multi-
ple counters that can be combined and thus are sufﬁcient for
normal platform lifetimes 2. Thus, a trusted kernel includ-
ing such a counter into the measurement list ensures that the
preﬁxes of two measurement lists differ at least in this single
counter measurement once the system is rebooted.
Consequently, in this enhanced version, transaction in-
tegrity can be validated by ensuring that the measurement list
validated at the ﬁrst challenge before the transaction is a pre-
ﬁx of the measurement list validated at the second challenge
after the transaction. Then, the system did not reboot and thus
(given our assumptions) any distrusted system component po-
tentially impacting the transaction on the attesting system,
would show in the measurement list of the second challenge.
In effect, our architecture does not offer predictable security
as long as it is non-intrusive, yet it can offer retrospective as-
1This is used in another TPM mechanism allowing to seal a secret to a
platform conﬁguration, though originally this did not include any dynamic
measurements.
2The TPM speciﬁcation [11] demands that the externally accessible coun-
ters must allow for 7 years of increments every 5 seconds without causing a
hardware failure.
surance of the integrity state of a system.
5
Implementation
This section describes the enhancements we have made to
the Linux system to implement the measurement function-
ality. Before any of our dynamic measurements are initiated
(i.e., before linuxrc or init are started), our kernel pre-loads its
measurement list with the expected measurements for BIOS,
bootloader, kernel, and initrd (if applies), and uses the ag-
gregate of the real boot process, found in a pre-deﬁned TPM
PCR, as the starting point for our own measurement aggre-
gate. If the actual boot process differs from the expected one,
the validation of the measurement list will fail. We focus on
the stages measuring dynamic run-time content following the
initial OS boot.
Our prototype implementation is done on a RedHat 9.0
Linux distribution as a Linux Security Module (LSM) of a
2.6.5 kernel 3. The prototype implementation is divided into
four major components:
inserting measurement points into
the system to measure ﬁles or memory (Section 5.1), mea-
suring ﬁles or memory (Section 5.2), protecting against by-
passing the measurements (Section 5.3), and validating the
measurements to ensure that an implementation of our ar-
chitecture is actually in place on the attesting system (Sec-
tion 5.4).
5.1
Inserting Measurement Points
In Section 4.2, we outlined the approach to measurement, in-
cluding measurement in the kernel and also by user-level pro-
grams. Here we describe the implementation.
We implemented kernel measurements based on the Linux
kernel LSM interface. Using the file_mmap LSM hook,
we induce a measurement on any ﬁle before it is mapped ex-
ecutable into virtual memory.
Using the sysfs ﬁle system, we allow user-space appli-
cations to issue measure requests by writing requests to
/sys/security/measure, including the ﬁle descriptor
of the ﬁle to measure. Using the kernel load_module rou-
tine, we induce a measure call on the memory area of a
loading module before it is relocated.
In Section 4.2, we outline the approach to measurement,
where measured executable code itself (e.g., shell) can induce
additional measurements on loaded ﬁle contents its behavior
depends on (e.g., shell command ﬁles).
If that executable
code is not of high integrity, it will be detected (because it is
already in the measurement list). If it is of high-integrity, then
it may be trusted to measure its loaded data.
We describe below how we measure dynamic run-time
loads and how we protect measured ﬁles throughout their use.
3The mechanisms presented here are sufﬁciently generic that porting to a
Unix-like system should be straightforward.
User-level Executables: User-level executables are loaded
through the user-level loader. When a binary executable is in-
voked via the system call execve, the kernel calls the binary
handler routine, which then interprets the binary and locates
the appropriate loader for the executable. The kernel then
maps the loader into memory and sets up the environment
such that when the execve call returns, execution resumes
with the loader. The loader in turn performs further loading
operations and ﬁnally passes control to the main function of
the target executable. In the case of a statically linked binary,
the only ﬁle being loaded is the target binary itself, which we
measure in the file_mmap LSM hook, called by the kernel
before mapping it.
Dynamically Loadable Libraries: A dynamically linked
binary typically requires loading of additional libraries that
it depends on. This process is done by the user-level loader
and is transparent to the kernel. However, the linker maps
shared libraries (ﬂagged executable) into virtual memory
by using the mmap system call, which always invokes the
file_mmap LSM hook. Thus, the mediation provided by
the file_mmap LSM hook instrumentation yields measure-
ments of all statically and dynamically linked executables in-
cluding shared libraries.
Kernel Modules: Kernel modules are extensions to the
kernel that can be dynamically loaded after the system is
booted. Module loading can be explicit (via insmod or mod-
probe) or implicit if automatic module loading is enabled.
In the latter case, when the kernel detects that a module is
needed, it automatically ﬁnds and loads the appropriate mod-
ule by invoking modprobe in the context of a user process.
With a 2.6 kernel, both programs load kernel modules into
memory and then call the sys_init_module system call
to inform the kernel about the new module that is then copied
into kernel memory and relocated. Thus, kernel modules can
either be measured by insmod or modprobe on user level
when they are loaded from the ﬁle system, or they can be
measured in the kernel when they reside in kernel memory
and before they are relocated. We implemented both versions.
However, we prefer the latter version because it prevents
exploits of (possibly unknown) vulnerabilities in the kernel
loader applications insmod or modprobe from tampering the
measurement of kernel level code. Because there is no suit-
able LSM hook available, we added a measure call into the
load_module routine that is called by the init_module
system call to relocate a module that is in memory.
Scripts: Script interpreters are loaded and measured as
binary executables. However, interpreters load additional
code that determines their behavior, so we would prefer that
the script interpreters also be capable of measuring their
integrity-relevant input. At present, we have instrumented the
bash shell to measure any interpreted script and conﬁguration
ﬁles before loading and interpreting them. This includes all
service startup scripts into the measurement list. We observe
about 60-70 measurements of bash scripts and source ﬁles
in our experiments booting Redhat 9.0 Linux and running a
Gnome Desktop system. Instrumenting other programs (Perl,
Java) is straightforward, but we anticipate the need for more
support from application programmers.
5.2 Taking Measurements
This section describes the implementation of the kernel level
measure call used at the measurement points to initiate the
measurement of a ﬁle or a memory area (in case of kernel
modules). The measure call takes one argument, namely, a
pointer to the ﬁle structure containing the ﬁle to be measured.
From the ﬁle structure one can look up the corresponding in-
ode and data blocks, and take a SHA1 over the data blocks.
There are three places from which a measure call is is-
sued: (1) the implementation of the write/store routine to the
the pseudo ﬁle system /sys/security/measure used
by user level applications, (2) the file_mmap security LSM
hook measuring ﬁles that are being memory-mapped as ex-
ecutable code, and (3) the load_module routine measur-
ing kernel module code in memory before it is relocated.
The file_mmap hook receives the ﬁle pointer as argu-
ment, and the write routine of the sysfs entry receives the
ﬁle descriptor, from which the ﬁle pointer is retrieved using
the fget routine. We ignore file_mmap calls where the
P ROT EXEC bit is not set in the properties parameter, as
those ﬁles are not mapped executable.
The consistency between ﬁle-measurements and what is
actually loaded depends on: (1) accurate identiﬁcation of the
inode loaded and (2) detection of any subsequent writes to
the ﬁle described by the inode. Both cases are handled by the
kernel in the case of memory-mapped executables. Protec-
tive locks that the kernel holds at measurement time ensure
that the ﬁle cannot be written to by others as long as it is
mapped executable. This lock is held by the mapping func-
tion at the time of measurement. Modules are measured when
they are already in kernel memory, thus they are not suscep-
tible to such inconsistencies. For ﬁles measured from user
space, we assume that the measuring application keeps the
ﬁle descriptor –used to initiate the measurement– open until
it is done reading the contents or to issue a new measure-
ment call when the ﬁle is re-opened. This ensures that the
ﬁle measured is the ﬁle actually read. Second, there could
be a race between the measure and read user level calls
and another write call that modiﬁes the data. We call this
case a Time-of-Measure-Time-of-Use (ToM-ToU) race con-
dition and describe in Section 5.3 how we handle this case.
However, remote NFS ﬁles cannot be measured dependably
unless the ﬁle’s complete contents are cached and protected
on the local system. We do not implement such caching at
present.
A naive measurement implementation would be to take a
ﬁngerprint for every measure call. This approach would,
however, incur signiﬁcant performance overhead (see Sec-
tion 6.2) for executable ﬁles and libraries that are loaded quite
often.
Instead, we use caching to reduce performance overhead.
The idea is to keep a cache of measurements that have already
been performed, and take a new measurement only if the ﬁle
has not been seen before (cache-miss) or the ﬁle might have
changed since last measurement. For the latter case, we only
record a new ﬁle measurement if the ﬁle has actually changed.
Recording identical measurements each time an application
runs would have severe impact on the management (storage,
retrieval, validation) of the list. Kernel modules are always
measured in memory at load-time but their measurement is
added only if it is not yet in the measurement list.
We store all measurements in a singly-linked, ordered list.
The order of measurements is essential to detect any modiﬁ-
cation to the measurement list. If the measurements are not
checked in order, then the aggregate hash will not match the
TPM aggregate that results from the TPM extend operations.
Additionally, we gather meta information related to the mea-
sured ﬁle –such as the ﬁle name, user ID, group ID or security
labels of the loading entity, or the ﬁle system type–, which
might be useful for evaluating the impact of loading this ﬁle
or matching it with local security policies. At this time, our
implementation gathers this additional data informally in the
measurement list, but does not include it in the measurement.
For efﬁciency reasons, we overlay the linked list with two
hash tables, one keyed with the inode number and device
number of the measured ﬁle, the second keyed with the result-
ing ﬁngerprint (SHA1 value) of the measured ﬁle. Thus, each
measurement entry can be reached by traversing the measure-
ment list, by its inode (for ﬁle measurements only), or by its
ﬁngerprint. The measure call uses the inode corresponding
to the ﬁle descriptor of the target ﬁle to quickly look up the
ﬁle in the hash table and see if it has been measured before.
Each measurement entry contains a dirty ﬂag bit, indicating
whether the ﬁle is CLEAN (not modiﬁed), or DIRTY (possibly
modiﬁed). We describe the semantics of measurement below.
Measuring new ﬁles: If the ﬁle is not found in the inode-
keyed hash table, then we measure the ﬁle by computing a
SHA1 hash over its complete content. At this point, we use
the computed ﬁngerprint to check whether it is present in the
hash table keyed by the SHA1 hash value of existing mea-
surements. If the measured ﬁngerprint is not found, then we
create a new measurement entry, and add it to the list and ad-
just the hash table structures. We ﬁnally extend the relevant
Platform Conﬁguration Register in the protected TPM hard-
ware by the SHA1 hash before returning from the call and
allowing the loading of the executable content. If the ﬁnger-
print was already measured before, then we return from the
system call without extending the TPM or the measurement
list. This can happen if executable ﬁles are copied and thus
yield the same ﬁngerprint. In this case, we assume for our
purpose that both executables are equivalent.
Remeasuring ﬁles: If the ﬁle is found in the inode-keyed
hash table, then it was measured before. If the dirty ﬂag of the
found measurement entry is CLEAN (clean-hit), then nothing
needs to be done, and the system call returns. If the dirty ﬂag
bit is DIRTY (dirty-hit), then we compute the SHA1 value
of the ﬁle. If the measured ﬁngerprint is identical to the one
stored in the measurement list, then we re-set the dirty ﬂag.
We do not extend the PCR or record this measurement as it is
known already.
If the measured ﬁngerprint differs from the one stored in
the found measurement entry for the inode, then we look up
the new ﬁngerprint in the hash table using the SHA1 value as
the key. If the SHA1 value exists, then the same ﬁle contents
were measured before (copy of the current ﬁle). We return
without recording the measurement, as above. If the SHA1
value does not exist in the hash table, then the current ﬁle has
changed. A new measurement entry is created and added to
the table, and the PCR is extended before the measure call
returns.
Dirty ﬂagging: We set the dirty ﬂag bit to DIRTY when-
ever the target ﬁle (a) was opened with write, create, truncate,
or append permission, (b) was located on a ﬁle system we
can’t control access to (e.g., NFS), or (c) belongs to a ﬁle
system which was unmounted. This seems a bit conservative,
since an open for write (or unmounting a ﬁle) does not nec-
essarily result in modiﬁcations to the ﬁle. The SHA1-keyed
hash table enables us to clear the dirty ﬂag if a ﬁle did not
change after an open with write permission.
If we control
access to the ﬁle, then we clear the dirty ﬂag in such cases.
Experiments show that on a non-development system using
local ﬁle systems, the percentage of dirty-hits on the cache is
far less than 1%.
Measuring kernel modules: We issue a measure calls
whenever a kernel module is being prepared for integration
into the kernel. We calculate the SHA1 value of the memory
area where the not-yet relocated kernel module resides in the
load_module kernel function and thus we yield a single
representative measurement for each kernel module indepen-
dently of its ﬁnal memory location. Then, we check whether