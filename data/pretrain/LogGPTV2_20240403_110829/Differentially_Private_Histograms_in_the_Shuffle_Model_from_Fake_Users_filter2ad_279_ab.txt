private
algorithms M1, . . . , Md,
ˆM3
is
deﬁned
=
2d log 1
dδ , 2dδ
ε(eε − 1) · d + ε ·(cid:113)
For
ˆM3((cid:126)x)
algorithm
the
(M1((cid:126)x), . . . ,Md((cid:126)x))
-differentially private.
(ε, δ)-differentially
(cid:17)
II.4.
by
(cid:16)
Refer to Theorems 3.14 and 3.20 in [13] for proofs.
B. Local Model
In an extreme case, no user trusts any other party with
protecting their data; here, we model the dataset as a distributed
object where each of n users holds a single row. Each user i
provides their data point as input to a randomizing function R
and publishes the outputs for some analyzer to compute on.
Deﬁnition II.5 (Local Model [20, 14]). A protocol P in the
local model consists of two randomized algorithms:
• A randomizer R : X → Y mapping data to a message.
• An analyzer A : Y n → Z that computes on a vector of
messages.
We deﬁne its execution on input (cid:126)x ∈ X n as
II. PRELIMINARIES
A. Differential Privacy
We deﬁne a dataset (cid:126)x ∈ X n to be an ordered tuple of n
rows where each row is drawn from a data universe X and
corresponds to the data of one user. Two datasets (cid:126)x, (cid:126)x (cid:48) ∈ X n
are considered neighbors (denoted as (cid:126)x ∼ (cid:126)x (cid:48)) if they differ in
at most one row.
Deﬁnition II.1 (Differential Privacy [12]). An algorithm M :
X n → Z satisﬁes (ε, δ)-differential privacy if, for every pair
of neighboring datasets (cid:126)x and (cid:126)x (cid:48) and every subset Z ⊂ Z,
P((cid:126)x) := A(R(x1), . . . ,R(xn)).
We assume that R and A have access to an arbitrary amount
of public randomness.
Deﬁnition II.6 (Local Differential Privacy [12, 18]). A local
protocol P = (R,A) is (ε, δ)-differentially private if R is
(ε, δ)-differentially private. The privacy guarantee is over the
internal randomness of the users’ randomizers and not the
public randomness of the protocol.
For brevity, we typically call these protocols “locally private.”
P[M((cid:126)x) ∈ Z] ≤ eε · P[M((cid:126)x (cid:48)) ∈ Z] + δ.
(1)
C. Shufﬂe Model
We remark that an algorithm can be well-deﬁned for a
superset X of the data universe (meaning X ⊃ X ) but (1)
We focus on differentially private protocols in the shufﬂe
model, which we deﬁne below.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:25:20 UTC from IEEE Xplore.  Restrictions apply. 
442
[2] , [10]
[16]
[17]
Thm III.4
Thm V.1
O(log d)
O(log d)
O(log n + log log d)
O
O(log n log d)
O(log d)
d
O(log d(1 + d
n · v(ε, δ, d))) ∗
(cid:16) 1
(cid:17) ∗
Thm V.3
O
ε2 log d log3 log d
δ
Thm C.1,
via [16, 15]
d
O(d)
min
log 1
δ , 1
εn
log d log 1
δ
(cid:16)
O
Max Error
(90% Conﬁdence)
(cid:113)
(cid:17)(cid:17)
(cid:113)
(cid:17)
(cid:19)
(cid:17)
log d log 1
δ
εn
log3/2 d
εn
log log d
δ
(cid:113)
(cid:113)
O
n + 1
εn
log d log 1
εδ
O
O
ε2n
(cid:16) 1
(cid:16) 1
(cid:18)
(cid:16) log d
(cid:16) log d
(cid:16) 1
(cid:32)
√
εn
O
O
log d
n +
O
n + 1
εn
O( 1
(cid:113)
εn log d)
log d log 1
δ
(cid:17)
(cid:17)(cid:17)
log d log3/2(cid:16) log d
(cid:33)
(cid:1) 1
(cid:0)log 1
4
δ
√
√
log d
3
4
εn
δ
ε2
(cid:17)
log log d
O(d1/100)
(cid:16) log3 d
(cid:16) 1
(cid:17)
ε2 log 1
n · u(ε, δ)) ∗
O
εδ
δ
1 + O( d
2
O(log d)
1
Source
Bits per message
Messages per user
Table I: Summary of shufﬂe protocols for histograms. ∗ indicates bounds on expected values. To simplify presentation, we
assume ε = O(1), δ = O(1/n), and n = Ω( log d
and v(ε, δ, d)
ε2
for log d + log(1/δ)
δ ). We also use u(ε, δ) as shorthand for log2(1/δ)
δ log log d
log 1
ε2
.
ε2
of messages.
Deﬁnition II.7 (Shufﬂe Model [5, 10]). A protocol P in the
shufﬂe model consists of three randomized algorithms:
• A randomizer R : X → Y∗ mapping a datum to a vector
• A shufﬂer S : Y∗ → Y∗ that applies a uniformly random
• An analyzer A : Y∗ → Z that computes on a permutation
As S is the same in every protocol, we identify each shufﬂe
protocol by P = (R,A). We deﬁne its execution by n users
on input (cid:126)x ∈ X n as
permutation to the messages in its input.
of messages.
P((cid:126)x) := A(S(R(x1), . . . , R(xn))).
We allow R and A to have parameters that depend on n.
We use the following deﬁnition of differential privacy in
this model.
Deﬁnition II.8 (Shufﬂe Differential Privacy [10]). A protocol
P = (R,A) is (ε, δ)-shufﬂe differentially private for n users
if the algorithm (S ◦ Rn)((cid:126)x) := S(R(x1), . . . ,R(xn)) is
(ε, δ)-differentially private. The privacy guarantee is over the
internal randomness of the users’ randomizers and not the
public randomness of the shufﬂe protocol.
For brevity, we typically call these protocols “shufﬂe private.”
D. Deﬁnitions for Histogram and Top-t Selection Problems
Each user i has one private value belonging to the ﬁnite set
[d]. It is encoded as a “one-hot” binary string: if ej,d is the
binary string of length d with zeroes in all entries except for
coordinate j, user i owns data xi = ej,d for some j. Let Xd
denote the set {e1,d, . . . , ed,d} and let 0d denote the binary
string of all zeroes.
(cid:80)n
1
n
be shorthand for the vector (hist1((cid:126)x), . . . , histd((cid:126)x)).
For any j ∈ [d], let histj((cid:126)x) be the function that takes the
vector of one-hot values (cid:126)x ∈ {e1,d, . . . , ed,d}n and reports
i=1 xi,j, which is the frequency of ej,d in (cid:126)x. Let hist((cid:126)x)
We will use (cid:96)∞ error to quantify how well a vector (cid:126)z ∈ Rd
estimates the histogram hist((cid:126)x). Speciﬁcally, we minimize
(cid:107)(cid:126)z − hist((cid:126)x)(cid:107)∞ := maxj |zj − histj((cid:126)x)|.2
Having deﬁned histograms, we move on to deﬁning the top-t
items. For any vector (cid:126)h ∈ Rd and value j ∈ [d], let rankj((cid:126)h)
be the relative magnitude of hj: the index of hj after sorting
(cid:126)h in descending order. For any t ∈ [d], let topt((cid:126)h) denote the
set of j such that rankj((cid:126)h) ≤ t.
We now establish notation to quantify how well a set
approximates the top-t items. Let hist[t]((cid:126)x) denote the fre-
quency of the t-th largest item: the quantity histj((cid:126)x) where
rankj(hist((cid:126)x)) = t. .
Deﬁnition II.9. For any (cid:126)x ∈ X n
d , a set of candidates C ⊂ [d]
α-approximates the top-t items in (cid:126)x if |C| = t and histj((cid:126)x) >
hist[t]((cid:126)x) − α for all j ∈ C.
Other metrics include precision p (the fraction of items in
candidate set C that are actually in the top t) and recall r (the
fraction of items in the top t that are in C). Note that when
|C| = t, p = r so that the F1 score—the quantity 2 · p·r
p+r —is
exactly p = r.
III. OUR HISTOGRAM PROTOCOL
Here, we assume that the number of users n and universe
size d are known to (whoever instantiates) the protocol and that
2Other norms could be studied, but we seek consistency with prior work in
the shufﬂe model (which show that shufﬂe protocols are not beholden to the
lower bound by Bassily & Smith [4] developed for local privacy).
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:25:20 UTC from IEEE Xplore.  Restrictions apply. 
443
privacy parameters ε, δ are likewise already chosen. Protocol
parameters k ∈ N, q ∈ (0, 1/2) will be determined, in that
order, by functions of n, d, ε and δ.
A user i who executes our protocol’s local randomizer RFLIP
(Algorithm 1) will report k + 1 messages. They make their
ﬁrst message by running randomized response on their one-hot
string: each bit of xi is ﬂipped with some probability q. We use
Rd,q to refer to this subroutine (Algorithm 2). The user makes
the k other messages by repeatedly executing Rd,q(0d), with
fresh randomness in each execution. This inserts k fake users
into the protocol. We note that our privacy analysis requires
the extra inputs to be 0d.
Collectively, fake and real users produce nk + n messages;
stacking them results in a (nk + n) × d binary matrix. To
estimate the frequency of j, our analyzer AFLIP (Algorithm 3)
simply de-biases and re-scales the sum of the j-th column.
Algorithm 1: RFLIP, a randomizer for histograms
Input: x ∈ Xd; implicit parameters d, k, q
Output: (cid:126)y ∈ ({0, 1}d)k+1
Initialize (cid:126)y as an empty message vector.
Append message generated by Rd,q(x) to (cid:126)y
For j ∈ [k]
Append message generated by Rd,q(0d) to (cid:126)y
Return (cid:126)y
Algorithm 2: Rd,q, bitwise randomized response
Input: x ∈ {0, 1}d
Output: y ∈ {0, 1}d
For j ∈ [d]
Sample ﬂipj ∼ Ber(q)
yj ← 1 − xj if ﬂipj = 1, else yj ← xj
Return y
Algorithm 3: AFLIP, an analyzer for histograms
Input: (cid:126)y ∈ ({0, 1}d)nk+n; implicit parameters d, k, q
Output: (cid:126)z ∈ Rd
For j ∈ [d]
zj ← 1
(cid:80)nk+n
1−2q · (yi,j − q)
i=1
n
1
Return (cid:126)z ← (z1, . . . , zd)
When k = 0, we simply have shufﬂed the outputs of
randomized response. In Appendix C, we show differential
√
privacy is possible when ﬂipping frequency q is assigned to a
value ∝ 1/
n. This leads to error ∝ 1/n3/4 (Theorem C.1).
But a better dependence on n is possible in the k > 0 case
because we prove q can be ∝ 1/nk. More precisely,
Claim III.1. Fix any ε > 0, δ  2
k + 1
(cid:115)
1
2
β
·
1
1 − 2q
n
is at most β.
We prove this claim in Section III-A. It follows from analysis
of expectation and variance, then an application of a Chernoff
bound. For a ﬁxed q, note that the above error bound grows
with the number of fake users k. But if we instead assign q
to the function of k, ε, δ implicit in Claim III.1, the bound
actually shrinks with k:
Theorem III.3. Fix any ε > 0, δ  132
δ , there is a
choice of parameter q < 1/2 such that the protocol PFLIP =
(RFLIP,AFLIP) has the following properties
a. PFLIP is (ε, δ)-shufﬂe private for inputs from Xd.
b. For any j ∈ [d] and (cid:126)x ∈ X n
d , PFLIP((cid:126)x) reports frequency
eε−1 )2 ln 4
estimate zj such that
|zj − histj((cid:126)x)| <
1
n
· eε + 1
eε − 1
·
ln 20 · g(k)
ln
4
δ
5
(cid:114) 264
(cid:32)
(cid:114) 264
with probability 9/10, where g(k) monotonically approaches
1 from above.
Proof. Because k is sufﬁciently large, there is a solution ˆq to
the quadratic equation q(1 − q) = 33
δ that lies in
the interval (0, 1/2). Also, let ˜q ← 1
When we set q ← max(ˆq, ˜q), Part a follows immediately
from Claim III.1 and the error |zj − histj((cid:126)x)| is at most
5nk ( eε+1
nk+n ln 2
eε−1 )2 ln 4
β < 1/2.
max
1
n
· eε + 1
eε − 1
·
ln
4
δ
ln 20,
2
n
5