### II. Preliminaries

#### A. Differential Privacy

We define a dataset \(\mathbf{x} \in X^n\) as an ordered tuple of \(n\) rows, where each row is drawn from a data universe \(X\) and corresponds to the data of one user. Two datasets \(\mathbf{x}, \mathbf{x}' \in X^n\) are considered neighbors (denoted as \(\mathbf{x} \sim \mathbf{x}'\)) if they differ in at most one row.

**Definition II.1 (Differential Privacy [12]).** An algorithm \(M: X^n \to Z\) satisfies \((\epsilon, \delta)\)-differential privacy if, for every pair of neighboring datasets \(\mathbf{x}\) and \(\mathbf{x}'\) and every subset \(Z \subset Z\),
\[ P[M(\mathbf{x}) \in Z] \leq e^\epsilon \cdot P[M(\mathbf{x}') \in Z] + \delta. \]

#### B. Local Model

In an extreme case, no user trusts any other party with protecting their data. Here, we model the dataset as a distributed object where each of \(n\) users holds a single row. Each user \(i\) provides their data point as input to a randomizing function \(R\) and publishes the outputs for some analyzer to compute on.

**Definition II.5 (Local Model [20, 14]).** A protocol \(P\) in the local model consists of two randomized algorithms:
- A randomizer \(R: X \to Y\) mapping data to a message.
- An analyzer \(A: Y^n \to Z\) that computes on a vector of messages.

The execution of \(P\) on input \(\mathbf{x} \in X^n\) is defined as:
\[ P(\mathbf{x}) := A(R(x_1), \ldots, R(x_n)). \]

We assume that \(R\) and \(A\) have access to an arbitrary amount of public randomness.

**Definition II.6 (Local Differential Privacy [12, 18]).** A local protocol \(P = (R, A)\) is \((\epsilon, \delta)\)-differentially private if \(R\) is \((\epsilon, \delta)\)-differentially private. The privacy guarantee is over the internal randomness of the users' randomizers and not the public randomness of the protocol.

For brevity, we typically call these protocols "locally private."

#### C. Shuffle Model

We focus on differentially private protocols in the shuffle model, which we define below.

**Definition II.7 (Shuffle Model [5, 10]).** A protocol \(P\) in the shuffle model consists of three randomized algorithms:
- A randomizer \(R: X \to Y^*\) mapping a datum to a vector of messages.
- A shuffler \(S: Y^* \to Y^*\) that applies a uniformly random permutation to the messages in its input.
- An analyzer \(A: Y^* \to Z\) that computes on a permutation of messages.

As \(S\) is the same in every protocol, we identify each shuffle protocol by \(P = (R, A)\). The execution of \(P\) by \(n\) users on input \(\mathbf{x} \in X^n\) is defined as:
\[ P(\mathbf{x}) := A(S(R(x_1), \ldots, R(x_n))). \]

We allow \(R\) and \(A\) to have parameters that depend on \(n\).

**Definition II.8 (Shuffle Differential Privacy [10]).** A protocol \(P = (R, A)\) is \((\epsilon, \delta)\)-shuffle differentially private for \(n\) users if the algorithm \((S \circ R^n)(\mathbf{x}) := S(R(x_1), \ldots, R(x_n))\) is \((\epsilon, \delta)\)-differentially private. The privacy guarantee is over the internal randomness of the users' randomizers and not the public randomness of the shuffle protocol.

For brevity, we typically call these protocols "shuffle private."

#### D. Definitions for Histogram and Top-t Selection Problems

Each user \(i\) has one private value belonging to the finite set \([d]\). It is encoded as a "one-hot" binary string: if \(e_{j,d}\) is the binary string of length \(d\) with zeroes in all entries except for coordinate \(j\), user \(i\) owns data \(x_i = e_{j,d}\) for some \(j\). Let \(X_d\) denote the set \(\{e_{1,d}, \ldots, e_{d,d}\}\) and let \(0_d\) denote the binary string of all zeroes.

For any \(j \in [d]\), let \(\text{hist}_j(\mathbf{x})\) be the function that takes the vector of one-hot values \(\mathbf{x} \in \{e_{1,d}, \ldots, e_{d,d}\}^n\) and reports \(\sum_{i=1}^n x_{i,j}\), which is the frequency of \(e_{j,d}\) in \(\mathbf{x}\). Let \(\text{hist}(\mathbf{x})\) be shorthand for the vector \((\text{hist}_1(\mathbf{x}), \ldots, \text{hist}_d(\mathbf{x}))\).

We will use \(\ell_\infty\) error to quantify how well a vector \(\mathbf{z} \in \mathbb{R}^d\) estimates the histogram \(\text{hist}(\mathbf{x})\). Specifically, we minimize
\[ \|\mathbf{z} - \text{hist}(\mathbf{x})\|_\infty := \max_j |z_j - \text{hist}_j(\mathbf{x})|. \]

Having defined histograms, we move on to defining the top-\(t\) items. For any vector \(\mathbf{h} \in \mathbb{R}^d\) and value \(j \in [d]\), let \(\text{rank}_j(\mathbf{h})\) be the relative magnitude of \(h_j\): the index of \(h_j\) after sorting \(\mathbf{h}\) in descending order. For any \(t \in [d]\), let \(\text{top}_t(\mathbf{h})\) denote the set of \(j\) such that \(\text{rank}_j(\mathbf{h}) \leq t\).

We now establish notation to quantify how well a set approximates the top-\(t\) items. Let \(\text{hist}[t](\mathbf{x})\) denote the frequency of the \(t\)-th largest item: the quantity \(\text{hist}_j(\mathbf{x})\) where \(\text{rank}_j(\text{hist}(\mathbf{x})) = t\).

**Definition II.9.** For any \(\mathbf{x} \in X_d^n\), a set of candidates \(C \subset [d]\) \(\alpha\)-approximates the top-\(t\) items in \(\mathbf{x}\) if \(|C| = t\) and \(\text{hist}_j(\mathbf{x}) > \text{hist}[t](\mathbf{x}) - \alpha\) for all \(j \in C\).

Other metrics include precision \(p\) (the fraction of items in candidate set \(C\) that are actually in the top \(t\)) and recall \(r\) (the fraction of items in the top \(t\) that are in \(C\)). Note that when \(|C| = t\), \(p = r\) so that the F1 score—the quantity \(\frac{2 \cdot p \cdot r}{p + r}\)—is exactly \(p = r\).

### III. Our Histogram Protocol

Here, we assume that the number of users \(n\) and universe size \(d\) are known to (whoever instantiates) the protocol and that privacy parameters \(\epsilon, \delta\) are likewise already chosen. Protocol parameters \(k \in \mathbb{N}\), \(q \in (0, 1/2)\) will be determined, in that order, by functions of \(n\), \(d\), \(\epsilon\), and \(\delta\).

A user \(i\) who executes our protocol's local randomizer \(R_{\text{FLIP}}\) (Algorithm 1) will report \(k + 1\) messages. They make their first message by running randomized response on their one-hot string: each bit of \(x_i\) is flipped with some probability \(q\). We use \(R_{d,q}\) to refer to this subroutine (Algorithm 2). The user makes the \(k\) other messages by repeatedly executing \(R_{d,q}(0_d)\), with fresh randomness in each execution. This inserts \(k\) fake users into the protocol. We note that our privacy analysis requires the extra inputs to be \(0_d\).

Collectively, fake and real users produce \(nk + n\) messages; stacking them results in a \((nk + n) \times d\) binary matrix. To estimate the frequency of \(j\), our analyzer \(A_{\text{FLIP}}\) (Algorithm 3) simply de-biases and re-scales the sum of the \(j\)-th column.

**Algorithm 1: \(R_{\text{FLIP}}\), a randomizer for histograms**

**Input:** \(x \in X_d\); implicit parameters \(d, k, q\)

**Output:** \(\mathbf{y} \in (\{0, 1\}^d)^{k+1}\)

1. Initialize \(\mathbf{y}\) as an empty message vector.
2. Append message generated by \(R_{d,q}(x)\) to \(\mathbf{y}\).
3. For \(j \in [k]\):
   - Append message generated by \(R_{d,q}(0_d)\) to \(\mathbf{y}\).
4. Return \(\mathbf{y}\).

**Algorithm 2: \(R_{d,q}\), bitwise randomized response**

**Input:** \(x \in \{0, 1\}^d\)

**Output:** \(y \in \{0, 1\}^d\)

1. For \(j \in [d]\):
   - Sample \(\text{flip}_j \sim \text{Ber}(q)\).
   - If \(\text{flip}_j = 1\), then \(y_j \leftarrow 1 - x_j\); else \(y_j \leftarrow x_j\).
2. Return \(y\).

**Algorithm 3: \(A_{\text{FLIP}}\), an analyzer for histograms**

**Input:** \(\mathbf{y} \in (\{0, 1\}^d)^{nk+n}\); implicit parameters \(d, k, q\)

**Output:** \(\mathbf{z} \in \mathbb{R}^d\)

1. For \(j \in [d]\):
   - \(z_j \leftarrow \frac{1}{n} \sum_{i=1}^{nk+n} \frac{y_{i,j} - q}{1 - 2q}\).
2. Return \(\mathbf{z} \leftarrow (z_1, \ldots, z_d)\).

When \(k = 0\), we simply have shuffled the outputs of randomized response. In Appendix C, we show differential privacy is possible when flipping frequency \(q\) is assigned to a value \(\propto \frac{1}{\sqrt{n}}\). This leads to error \(\propto \frac{1}{n^{3/4}}\) (Theorem C.1).

But a better dependence on \(n\) is possible in the \(k > 0\) case because we prove \(q\) can be \(\propto \frac{1}{nk}\). More precisely,

**Claim III.1.** Fix any \(\epsilon > 0\), \(\delta < \frac{1}{32}\). For any \(\beta > 0\), there exists a choice of parameter \(q < \frac{1}{2}\) such that the expected \(\ell_\infty\) error of the protocol \(P_{\text{FLIP}} = (R_{\text{FLIP}}, A_{\text{FLIP}})\) is at most \(\beta\).

We prove this claim in Section III-A. It follows from the analysis of expectation and variance, then an application of a Chernoff bound. For a fixed \(q\), note that the above error bound grows with the number of fake users \(k\). But if we instead assign \(q\) to the function of \(k\), \(\epsilon\), \(\delta\) implicit in Claim III.1, the bound actually shrinks with \(k\):

**Theorem III.3.** Fix any \(\epsilon > 0\), \(\delta < \frac{1}{32}\). There is a choice of parameter \(q < \frac{1}{2}\) such that the protocol \(P_{\text{FLIP}} = (R_{\text{FLIP}}, A_{\text{FLIP}})\) has the following properties:
a. \(P_{\text{FLIP}}\) is \((\epsilon, \delta)\)-shuffle private for inputs from \(X_d\).
b. For any \(j \in [d]\) and \(\mathbf{x} \in X_d^n\), \(P_{\text{FLIP}}(\mathbf{x})\) reports a frequency estimate \(z_j\) such that
\[ |z_j - \text{hist}_j(\mathbf{x})| < \frac{1}{n} \left( e^\epsilon + \frac{1}{e^\epsilon - 1} \right) \cdot \sqrt{\frac{264 \ln \frac{4}{\delta}}{5 \ln 20 \cdot g(k)}} \]
with probability \(9/10\), where \(g(k)\) monotonically approaches 1 from above.

**Proof.** Because \(k\) is sufficiently large, there is a solution \(\hat{q}\) to the quadratic equation \(q(1 - q) = \frac{33}{\delta}\) that lies in the interval \((0, \frac{1}{2})\). Also, let \(\tilde{q} \leftarrow \frac{1}{\sqrt{nk}}\).

When we set \(q \leftarrow \max(\hat{q}, \tilde{q})\), Part (a) follows immediately from Claim III.1, and the error \(|z_j - \text{hist}_j(\mathbf{x})|\) is at most
\[ \frac{1}{n} \left( e^\epsilon + \frac{1}{e^\epsilon - 1} \right) \cdot \sqrt{\frac{264 \ln \frac{4}{\delta}}{5 \ln 20}}. \]
\(\blacksquare\)