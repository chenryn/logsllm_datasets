9
9
10
12
17
19
23
11
Figure 3: Performance overheads for other programs.
Program
%age of variable accesses
Local
(non-buffer)
99.9
99.3
96.5
91.8
90.5
88.2
72.9
59.2
(buffer)
0.004
0.047
0.247
1.958
0.954
0.400
0.186
0.018
Global
(static)
0.1
0.6
3.2
6.2
8.5
10.9
26.9
40.7
grep
bc
tar
patch
enscript
bison
ctags
gzip
Figure 4: Dynamic proﬁle information for data access
a 100Mbps network. We ran the benchmark with two,
sixteen and thirty clients. In the experiments, the clients
were simulated to access the web server concurrently,
randomly fetching html ﬁles of size varying from 500
bytes to 5MB. The benchmark was run for a duration
of 30 minutes, and the results were averaged across ten
such runs. Results were ﬁnally rounded off to the nearest
integral values.
We analyzed the performance impact further by
studying the execution proﬁle of the programs. For this,
we instrumented programs to collect additional statistics
on memory accesses made by the transformed program.
Speciﬁcally, the instrumentation counts the total number
of accesses made to local variables, variables on shadow
stack, global variables and so on.
Figure 4 shows the dynamic proﬁle information.
(We did not consider servers in this analysis due to the
difﬁculties involved in accurately measuring their run-
times.) From this result, we see that for most programs,
the vast majority of memory accesses are to local vari-
ables. Our transformation doesn’t introduce any over-
heads for local variables, which explains the low over-
heads for most programs in Figure 3. Higher overheads
264
14th USENIX Security Symposium
USENIX Association
Program # calls
grep
tar
bison
bc
enscript
patch
gzip
ctags
×106
0.02
0.43
2.69
22.56
9.62
3.79
26.72
251.63
calls/
sec.
×106
0.06
0.41
4.11
4.24
6.68
9.75
11.52
26.60
Shadow
stack
allocations
per call
0.412
0.140
0.103
0.080
0.070
0.017
0.000
0.006
Figure 5: Dynamic proﬁle information for function calls
are associated with programs that perform a signiﬁcant
number of global variable accesses, where an additional
memory access is necessitated by our transformation.
A second source of overhead is determined by the
number of function calls made by a program. This in-
cludes the overhead due to the additional level of in-
direction for making function calls, the number of al-
locations made on shadow stack, and the introduction
of inter-stack-frame gap. To analyze this overhead, we
instrumented the transformed programs to collect num-
ber of function calls and number of shadow stack allo-
cations. The results, shown in Figure 5, illustrate that
programs that make a large number of function calls per
second, e.g., ctags and gzip incur higher overheads.
Surprisingly, bison also incurs high overheads despite
making small number of function calls per second. So
we analyzed bison’s code, and found that it contains
several big switch statements. This could be the main
reason behind the high overheads, because our current
implementation performs sequential lookup for the case
values. However, with binary search based implementa-
tion, we should be able to get better performance.
We point out that the proﬁle information cannot
fully explain all of the variations in overheads, since it
does not take into account some of the factors involved,
such as compiler optimizations and the effect of cache
hits (and misses) on the additional pointer dereferences
introduced in the transformed program. Nevertheless,
the proﬁle information provides a broad indication of the
likely performance overheads due to each program.
5 Effectiveness
Effectiveness can be evaluated experimentally or an-
alytically. Experimental evaluation involves running
a set of well-known exploits (such as those reported
on Securityfocus.com) against vulnerable programs,
and showing that our transformation stops these exploits.
We have not carried out a detailed experimental evalu-
ation of effectiveness because today’s attacks are quite
limited, and do not exercise our transformation at all.
In particular, they are all based on a detailed knowledge
of program memory layout. We have manually veriﬁed
that our transformation changes the memory locations
of global variables, local variables, heap-allocated data
and functions for each of the programs discussed in the
previous section. It follows from this that none of the
existing buffer overﬂow attacks will work on the trans-
formed programs.
In contrast with the limitations of an experimental
approach, an analytical approach can be based on novel
attack strategies that haven’t been seen before. More-
over, it can provide a measure of protection (in terms of
the probability of a successful attack), rather than sim-
ply providing an “yes” or “no” answer. For this reason,
we rely primarily on an analytical approach in this sec-
tion. We ﬁrst analyze memory error exploits in general,
and then discuss attacks that are speciﬁcally targeted at
randomization.
5.1 Memory Error Exploits
All known memory error exploits are based on corrupt-
ing some data in the writable memory of a process.
These exploits can be further subdivided based on the
attack mechanism and the attack effect. The primary at-
tack mechanisms known today are:
• Buffer overﬂows. These can be further subdivided,
based on the memory region affected: namely, stack,
heap or static area overﬂows. We note that integer
overﬂows also fall into this category.
• Format string vulnerabilities.
Attack effects can be subdivided into:
• Non-pointer corruption. This category includes at-
tacks that target security-critical data, e.g., a variable
holding the name of a ﬁle executed by a program.
• Pointer corruption. Attacks in this category are based
on overwriting data or code pointers.
In the for-
mer case, the overwritten value may point to injected
data that is provided by the attacker, or existing data
within the program memory. In the latter case, the
overwritten value may correspond to injected code
that is provided by the attacker, or existing code
within the process memory.
Given a speciﬁc vulnerability V , the probability of
its successful exploitation is given by P (Owr)∗P (Eff),
where P (Owr) denotes the probability that V can be
used to overwrite a speciﬁc data item of interest to the
attacker, and P (Eff) denotes the probability that the
overwritten data will have the effect intended by the at-
tacker. In arriving at this formula, we make either of the
following assumptions:
• (a) the program is re-randomized after each failed at-
USENIX Association
14th USENIX Security Symposium
265
tack. This happens if the failure of the effect causes
the victim process to crash, (say, due to a memory
protection fault), and it has to be explicitly restarted.
• (b) the attacker cannot distinguish between the fail-
ure of the overwrite step from the failure of the effect.
This can happen if (1) the overwrite step corrupts crit-
ical data that causes an immediate crash, making it in-
distinguishable from a case where target data is suc-
cessfully overwritten, but has an incorrect value that
causes the program to crash, or (2) the program in-
corporates error-handling or defense mechanisms that
explicitly masks the difference between the two steps.
Note that (a) does not hold for typical server programs
that spawn children to handle requests, but (b) may hold.
If neither of them hold, then the probability of a success-
ful attack is given by min(P (Owr), P (Eff)).
5.1.1 Estimating P (Owr)
We estimate P (Owr) separately for each attack type.
5.1.1.1 Buffer overﬂows
Stack buffer overﬂows. These overﬂows typically tar-
get
the return address, saved base pointer or other
pointer-type local variables. Note that the shadow stack
transformation makes these attacks impossible, since all
buffer-type variables are on the shadow stack, while the
target data is on a different stack.
Attacks that corrupt one buffer-type variable by
overﬂowing the previous one are possible, but unlikely.
As shown by our implementation results, very few
buffer-type variables are allocated on the stack. More-
over, it is unusual for these buffers to contain pointers
(or other security-critical data) targeted by an attacker.
Static buffer overﬂows. As in the case of stack over-
ﬂows, the likely targets are simple pointer-type vari-
ables. However, such variables have been separated by
our transformation from buffer-type variables, and hence
they cannot be attacked.
For attacks that use overﬂow from one buffer to the
next, the randomization introduced by our transforma-
tion makes it difﬁcult to predict the target that will be
corrupted by the attack. Moreover, unwritable pages
have been introduced periodically in-between buffer-
type static variables, and these will completely rule out
some overﬂows. To estimate the probability of success-
ful attacks, let M denote the maximum size of a buffer
overﬂow, and S denote the granularity at which inac-
cessible pages are introduced between buffer variables.
Then the maximum size of a useful attack is min(M, S).
Let N denote the total size of memory allocated for
static variables. The probability that the attack success-
fully overwrites a data item intended by the attacker is
given by min(M, S)/N . With nominal values of 4KB
for the numerator and 1M B for the denominator, the
likelihood of success is about 0.004.
In general, heap allocations are non-
Heap overﬂows.
deterministic, so it is hard to predict the effect of over-
ﬂows from one heap block to the next. This un-
predictability is further increased by our transforma-
tion to randomly increase the sizes of heap allocation
requests. However, there exist control data in heap
blocks, and these can be more easily and reliably tar-
geted. For instance, heap overﬂow attacks generally tar-
get two pointer-valued variables that are used to chain
free blocks together, and appear at their beginning.
The transformation to randomly increase malloc
requests makes it harder to predict the start address of
the next heap block, or its allocation state. However,
the ﬁrst difﬁculty can be easily overcome by writing al-
ternating copies of the target address and value many
times, which ensures that the control data will be over-
written with 50% probability. We believe that the uncer-
tainty on allocation state doesn’t signiﬁcantly decrease
the probability of a successful attack, and hence we con-
clude that our randomizations do not signiﬁcantly de-
crease P (Owr). However, as discussed below, P (Eff)
is very low for such attacks.
5.1.1.2 Format string attacks. These attacks exploit
the (obscure) "%n" format speciﬁer. The speciﬁer needs
an argument that indicates the address into which the
printf-family of functions will store the number of char-
acters that have been printed. This address is speciﬁed
by the attacker as part of the attack string. Note that
in the transformed program, the argument correspond-
ing to the "%n" format speciﬁer will be taken from the
main stack, whereas the attack string will correspond to
a buffer-type variable, and be held on the shadow stack
(or the heap or in a global variable). As a result, there
is no way for the attacker to directly control the ad-
dress into which printf-family of functions will write,
and hence the usual form of format-string attack will fail.
that some useful data
pointers may be on the stack, and they could be used as
the target of writes. The likelihood of ﬁnding such data
pointers on the stack is relatively low, but even when
they do exist, the inter-stack frame gaps of the order of
28 bytes reduces the likelihood of successful attacks to
4/28 = 0.016. This factor can be further decreased by
increasing the size of inter-frame gaps in functions that
call printf-family of functions.
is possible, however,
It
In summary, the approach described in this paper sig-
niﬁcantly reduces the success probability of most likely
attack mechanisms, which include (a) overﬂows from
stack-allocated buffers to corrupt return address or other
pointer-type data on the stack, (b) overﬂows from static
266
14th USENIX Security Symposium
USENIX Association
variable to another, and (c) format-string attacks. This
should be contrasted with previous ASR techniques that
have no effect at all on P (Owr). Their preventive abil-
ity is based entirely on reducing P (Eff) discussed in the
next section.
5.1.2 Estimating P (Eff)
5.1.2.1 Corruption of non-pointer data. This class of
attacks target security-critical data such as user-ids and
ﬁle names used by an application. With our technique,
as well as previous ASR techniques, it can be seen that
P (Eff) = 1, as they have no bearing on the inter-
pretation of non-pointer data. The most likely location
of such security-critical data is the static area, where
our approach provides protection in the form of a small
P (Owr). This contrasts with previous ASR approaches
that provide no protection from this class of attacks.
5.1.2.2 Pointer corruption attacks.
Corruption with pointer to existing data. The probabil-
ity of correctly guessing the absolute address of any data
object is determined primarily by the amount of random-
ization in the base addresses of different data areas. This
quantity can be in the range of 227, but since the objects
will likely be aligned on a 4-byte boundary, the probabil-
ity of successfully guessing the address of a data object
is in the range of 2−25.
Corruption with pointer to injected data. Guessing the
address of some buffer that holds attacker-provided data
is no easier than guessing the address of existing data
objects. However, the odds of success can be improved
by repeating the attack data many times over.
If it is
repeated k times, then the odds of success is given by
k × 2−25. If we assume that the attack data is 16 bytes
and the size of the overﬂow is limited to 4K, then k has
the value of 28, and P (Eff) is 2−17.
Corruption with pointer to existing code. The proba-
bility of correctly guessing the absolute address of any
code object is determined primarily by the amount of
randomization in the base addresses of different code
areas.
In our current implementation, the uncertainty
in the locations of functions within the executable is
216/4 = 214. We have already argued that the random-