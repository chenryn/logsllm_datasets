### Most of the Servers Using No Wait

Most of the servers using no wait are running either some version of the Windows operating system or older versions (2.0.37 or earlier) of the Linux operating system.

### 4.6 Response to ECN

**Explicit Congestion Notification (ECN)** [28] is a mechanism that allows routers to mark TCP packets to indicate congestion, rather than dropping them when possible. Although ECN-capable routers are not yet widely deployed, the latest versions of the Linux operating system include full ECN support. Following the deployment of ECN-enabled end nodes, there were widespread complaints that ECN-capable hosts could not access certain websites [16].

To investigate whether ECN-enabled packets were being rejected by popular web servers, we developed a TBIT test. In this test, the behavior of the web server is indistinguishable from the behavior of firewalls or load-balancers along the path to the server. The rejection of packets from ECN-enabled hosts is actually due to firewalls and load-balancers, not the web servers themselves [1].

### Setting Up an ECN-Enabled TCP Connection

Setting up an ECN-enabled TCP connection involves a handshake between the sender and the receiver. This process is described in detail in [28]. Here, we provide a brief overview of the relevant aspects:

- An ECN-capable client sets the ECN ECHO and CWR (Congestion Window Reduced) flags in the header of the SYN packet, known as an ECN-setup SYN.
- If the server is also ECN-capable, it will respond by setting the ECN ECHO flag in the SYN/ACK, known as an ECN-setup SYN/ACK.
- From that point onwards, all data packets exchanged between the two hosts, except for retransmitted packets, can have the ECN-Capable Transport (ECT) bit set in the IP header.
- If a router along the path wishes to mark such a packet as an indication of congestion, it does so by setting the Congestion Experienced (CE) bit in the IP header of the packet.

### Goal of the Test

The goal of the test is to detect broken equipment that results in denying access to certain web-servers from ECN-enabled end nodes. The test is not meant to verify full compliance with the ECN standard [28].

### Test Steps

1. **TBIT constructs an ECN-setup SYN packet** and sends it to the remote web server.
2. **If TBIT receives a SYN/ACK from the remote host**, TBIT proceeds to step 4.
3. **If no SYN/ACK is received after three retries (failure mode 1), or if a packet with RST is received (failure mode 2)**, TBIT concludes that the remote server exhibits a failure. The test is terminated.
4. **TBIT checks if the SYN/ACK was an ECN-setup SYN/ACK** with the ECN ECHO flag set and CWR flag unset. If this is the case, the remote web server has negotiated ECN usage. Otherwise, the remote web server is not ECN-capable.
5. **Ignoring whether the remote web server negotiated ECN usage**, TBIT sends a data packet containing a valid HTTP request, with the ECT and CE bits set in the IP header.
6. **If an ACK is received, check if the ECN ECHO flag is set**. If no ACK is received after three retries, or if the resulting ACK does not have the ECN ECHO flag set (failure mode 3), TBIT concludes that the remote web server does not support ECN correctly.

### Robustness Checks

To ensure robustness, before running the test, we check to make sure that the remote server is reachable from our site and would ACK a SYN packet sent without the ECN ECHO and CWR flags set. Robustness against packet loss is ensured by retransmitting a SYN or the test data packet as mentioned in steps 4 and 6.

### ECN Test Results (September 2000)

The ECN test was conducted in September 2000, involving a larger set of hosts (about 27,000). The purpose was to investigate the problem reported in [16], so we included the same list of web servers. Each host was tested only once, and the test returned a result for 24,030 hosts. The cumulative findings are reported in Table 16.

| **Test Result** | **Servers** |
|-----------------|-------------|
| Server not ECN-Capable | 21,602 |
| Failure mode 1: No response to ECN-setup SYN | 1,638 |
| Failure mode 2: RST in response to ECN-setup SYN | 513 |
| Failure mode 3: ECN negotiated, but data ACK does not report ECN ECHO | 255 |
| ECN negotiated, and ECN reported correctly in data ACK | 22 |
| **Total** | 24,030 |

### Analysis of Failure Modes

- **Failure mode 1**: Many hosts seem to be running a version of the AIX operating system. We have contacted people at IBM, and they are working on the problem.
- **Failure mode 2**: NMAP results indicated that many hosts were behind Cisco’s LocalDirector 430 [7], which is a load balancing proxy. Some hosts were identified as using Cisco’s PIX firewall. Both issues have been brought to Cisco’s attention, and a fix has since been made available.
- **Failure mode 3**: Most of the hosts seem to be running older versions of Linux (Linux 2.0.27-34). Of the 22 hosts negotiating ECN and using ECN correctly, 18 belong to a single subnet. NMAP could not identify the operating systems running on these 18 hosts. Of the remaining four, three seem to be running newer versions of Linux (2.1.122-2.2.13).

### Repeated ECN Tests (April 2001)

We repeated the ECN tests in April 2001 for the servers reporting failure mode 1 or 2 in the September 2000 tests. Of the 1,699 web servers responding, 1,039 still exhibited failure mode 1, 326 still exhibited failure mode 2, and 332 no longer exhibited failure. The list of failing web servers is available on the TBIT web page [22].

### 5. Discussion of Results

This section discusses in more detail the reasons why a TBIT test might terminate without returning any result. The fraction of tests that do not return a result is highest for the SACK test, where a total of 19% of the tests failed to return a result. These reasons for failing to return a result are enumerated in Tables 1, 4, 7, 10, and 13.

#### Reasons for Test Termination

1. **No connection**
2. **No data**
3. **Receipt of a packet with the RST or FIN flag set before the test is complete**

When any of these three occur, the TBIT test ends without returning a result.

4. **Large MSS**: TBIT terminates the test if the server sends a packet with an MSS larger than the maximum set by the receiver. While one might argue that this should not be a reason to terminate the test immediately, especially for simpler tests like the ICW test, we decided to do so because the sender TCP is not supposed to exceed the MSS value set by the receiver [2]. We are working on relaxing this requirement.

#### Other Important Reasons for Test Terminations

- **Packet drops and packet reordering** detected by TBIT before the completion of the test. For the ICW test, while certain packet drops can be detected and their impact on the final result can be correctly anticipated, we chose not to do so to keep the test code simple. Packet reordering is not an issue for the ICCT test.
- **For the CCA, CCC, and SACK tests**, packet drops and packet reordering cause significant problems, as the results from these tests depend upon the ordering and timing of the packets received. We have developed code to avoid terminating the test for some simple cases of packet losses and reordering. However, we decided that the incremental gain was not worth the added complexity.

#### Timewait Test

The Timewait test is not affected by packet reordering. It is also unaffected by any packet drops within the data stream. Packet drops during the handshake and teardown do affect the test. As described in Section 4.5, we guard against them by using retransmissions, similar to TCP. In Table 13, we see that 112 tests terminated without returning a result due to packet drops. This is due to a bug in our code, which terminated the test whenever the very first data packet sent by the server is lost. We plan to fix this error in a future version of TBIT.

### Variability in Test Results

A TBIT test might return different results when run against the same host at different times. The hosts belonging to categories 3 and 4 in Tables 2, 5, 8, 11, and 14 exhibit this problem. We speculate that there are at least two causes for this:

1. **Certain packet loss sequences** that TBIT is unable to detect and guard against. For example, during an ICW test, packets can be lost from the “top” of the congestion window. TBIT cannot detect this loss and would return a value of ICW that is smaller than the one actually used by the server. In the CCA test, all duplicate ACKs sent by TBIT for packet 13 may be lost, leading to a timeout and misclassification.
2. **Web servers as clusters of computers** answering to the same IP address. Depending on the load balancing algorithm used, we may contact different machines in the cluster if the same test is repeated at different times. These machines may run different operating systems and hence different TCP stacks.

Since we found no easy way to deal with these issues, we ran each TBIT test multiple (five) times and reported results only about those hosts that returned results for a minimum number (three) of these tests and returned the same result each time.

### Category 5 Hosts

Hosts belonging to Category 5 failed to return answers for any of the five tests. Some of these hosts were offline for various reasons during our testing period. Others would not send packets with a small MSS. Persistent packet reordering was also a problem, especially for hosts across transoceanic links. TBIT tests like CCA, CCC, and SACK tend to fail more often with such hosts.

### Usefulness of TBIT Tests

The number of hosts belonging to Category 1 can be thought of as a metric of the "usefulness" of TBIT tests. If a TBIT test verifies an interesting property of TCP but requires a large number of packets to complete and must terminate for any packet loss or reordering, few hosts would belong to the first category. For all the tests reported in this paper, more than 70% of the hosts belong to the first category. We had reported poorer performance in an earlier report [23] due to not verifying that all hosts would send sufficient data to complete the test. We have made improvements in the TBIT code to reduce the number of instances in which a test has to be terminated early.

### Operating System Identification

We used NMAP to identify the operating system running on the web servers being tested. Any assertions regarding the operating system running on a web server are subject to the accuracy of NMAP identification. In many cases, NMAP provides a set of operating systems as potential candidates.

### 6. Conclusion

In this paper, we have described TBIT, a tool for characterizing the TCP behavior of remote web servers. TBIT can be used to check any web server without special privileges on that web server in a non-disruptive manner. The source code for TBIT is available from the TBIT web page [22]. This kind of data (e.g., versions of congestion control algorithms running on web servers, sizes of initial window, time wait duration) is being reported for the first time. As a result of these tests, we have more information about the congestion control mechanisms used by traffic in the Internet. As a side effect, we uncovered several bugs in TCP implementations of major vendors and helped them correct these bugs.

### Future Work

We plan to continue this work in several ways:

1. **Develop tests for more aspects of TCP behavior**: For example, tracking the deployment of new TCP mechanisms such as the DSACK option (RFC 2883), Limited Transmit (RFC 3042), or Congestion Window Validation (RFC 2861), or investigating the details of retransmit timeout mechanisms. One goal is to provide comprehensive standards-compliance testing of TCP implementations.
2. **Explore the possibility of using TBIT to automatically generate models of TCP implementations** for use in simulators such as NS [10].
3. **Extend TBIT to gather more information about the infrastructure surrounding web servers**, as it affects the behavior of the server (e.g., firewalls that block ICMP packets).
4. **Develop active but non-destructive tools** to explore the effectiveness (or ineffectiveness) of queue management at congested routers on the path to the web server, by examining the pattern of drops and end-to-end delay.

There is a great deal still to do to understand both the behavior in the Internet and the rate of deployment of new mechanisms in the infrastructure.

### Acknowledgments

We are grateful to Aaron Hughes for his generosity and immense patience during the time we used his systems for NMAP scans. Without Aaron’s generosity, a large part of this work would not have been possible. We thank Stefan Savage for the source code of the Sting tool. We thank Mark Handley for help with system administration issues and several helpful discussions about the ECN test. We thank Vern Paxson for his help in developing the time-wait duration test. We thank Balachander Krishnamurthy for the list of web servers used in [17]. We thank Mark Allman, Fred Baker, Nick Bastin, Alan Cox, Jamal Hadi-Salim, Tony Hain, Dax Kelson, Balachander Krishnamurthy, Alexey Kuznetsov, Jamshid Mahdavi, William Miller, Erich Nahum, Kacheong Poon, K. K. Ramakrishnan, N. K. Srinivas, Venkat Venkatsubra, Richard Wendland, and participants of NANOG 20 for helpful discussions and comments. We also thank the anonymous SIGCOMM referees for their helpful feedback.

### References

[1] ECN-under-Linux Unofficial Vendor Support Page. http://gtf.org/garzik/ecn/.

[2] Internet protocol, September 1981. RFC791.

[3] M. Allman. A Web Server’s View of the Transport Layer. Computer Communication Review, 30(5), October 2000.

[4] M. Allman, S. Floyd, and C. Partridge. Increasing TCP’s Initial Window, September 1998. RFC2414.

[5] M. Allman, V. Paxson, and W. Stevens. TCP Congestion Control, April 1999. RFC2581.

[6] N. Cardwell, S. Savage, and T. Anderson. Modeling TCP Latency. In Proc. IEEE INFOCOM, 2000.

[7] Cisco Systems. How to Cost-Effectively Scale Web Servers. Packet Magazine, Third Quarter 1996. http://www.cisco.com/warp/public/784/5.html.

[8] K. Claffy, G. Miller, and K. Thompson. The Nature of the Beast: Recent Traffic Measurements from an Internet Backbone. In Proceedings of INET’98, 1998.

[9] K. Fall and S. Floyd. Simulation-based Comparisons of Tahoe, Reno, and SACK TCP. Computer Communication Review, 26(3), July 1996.

[10] K. Fall and K. Varadhan. ns: Manual, February 2000.

[11] S. Floyd and K. Fall. Promoting the use of End-to-end Congestion Control in the Internet. IEEE/ACM Trans. Networking, August 1999.

[12] S. Floyd and T. Henderson. The NewReno Modification to TCP’s Fast Recovery Algorithm, April 1999. RFC 2582.

[13] Fyodor. Remote OS detection via TCP/IP Stack Fingerprinting. Phrack 54, 8, Dec. 1998. URL "http://www.insecure.org/nmap/nmap-fingerprinting-article.html".

[14] T. Gao and J. Mahdavi. On Current TCP/IP Implementations and Performance Testing, August 2000. Unpublished manuscript.

[15] V. Jacobson. Congestion Avoidance and Control. Computer Communication Review, 18(4), August 1988.

[16] D. Kelson, September 2000. http://www.uwsg.iu.edu/-hypermail/linux/kernel/0009.1/0342.html.

[17] B. Krishnamurthy and M. Arlitt. PRO-COW: Protocol Compliance on the Web—A Longitudinal Study. In USENIX Symposium on Internet Technologies and Systems, 2001.

[18] B. Krishnamurthy and J. Rexford. Web Protocols and Practice: HTTP/1.1, Networking Protocols, Caching, and Traffic Measurement. Addison-Wesley, 2001.

[19] M. Mathis, J. Mahdavi, S. Floyd, and A. Romanow. TCP Selective Acknowledgment Options, October 1996. RFC2018.

[20] S. McCanne and V. Jacobson. The BSD Packet Filter: A New Architecture for User-level Packet Capture. In Proceedings of the winter USENIX technical conference, January 1993.

[21] T. Miller. Intrusion Detection Level Analysis of Nmap and Queso, August 2000.

[22] J. Padhye and S. Floyd. The TBIT Web Page. http://www.aciri.org/tbit/.

[23] J. Padhye and S. Floyd. Identifying the TCP Behavior of Web Servers. Technical Report 01-002, ICSI, 2001.

[24] K. Park, G. Kim, and M. Crovella. On the Relationship between File Sizes, Transport Protocols and Self-Similar Network Traffic. In Proc. International Conference on Network Protocols, 1996.

[25] V. Paxson. End-to-End Internet Packet Dynamics. In Proc. ACM SIGCOMM, 1997.

[26] V. Paxson, M. Allman, S. Dawson, W. Fenner, J. Griner, I. Heavens, K. Lahey, J. Semke, and B. Volz. Known TCP Implementation Problems, March 1999. RFC2525.

[27] J. Postel. Transmission Control Protocol, September 1981. RFC793.

[28] K. K. Ramakrishnan and S. Floyd. A Proposal to add Explicit Congestion Notification (ECN) to IP, January 1999. RFC2481.

[29] L. Rizzo. Dummynet and Forward Error Correction. In Proc. Freenix, 1998.

[30] S. Savage. Sting: a TCP-based Network Measurement Tool. Proceedings of the 1999 USENIX Symposium on Internet Technologies and Systems, pages 71–79, Oct. 1999.

[31] W. Stevens. TCP/IP Illustrated, Vol.1 The Protocols. Addison-Wesley, 1997. 10th printing.