Most of the servers using no wait seem to be running either some
version of the Windows operating system, or older versions (2.0.37
or less) of the Linux operating system.
4.6 Response to ECN
Explicit Congestion Notiﬁcation (ECN) [28] is a mechanism to
allow routers to mark TCP packets to indicate congestion, instead
of dropping them, when possible. While ECN-capable routers are
not yet widely deployed, the latest versions of the Linux operat-
ing system include full ECN support. Following this deployment
of ECN-enabled end nodes, there were widespread complaints that
ECN-capable hosts could not access a number of websites [16].
We wrote a TBIT test to investigate whether ECN-enabled packets
were being rejected by popular web servers. For this test, the be-
havior of the web server is indistinguishable from the behavior of
ﬁrewalls or load-balancers along the path to the server; the rejection
of packets from ECN-enabled hosts in fact is due to the ﬁrewalls
and load-balancers, and not due to the web servers themselves [1].
Setting up an ECN-enabled TCP connection involves a hand-
shake between the sender and the receiver. This process is de-
scribed in detail in [28]. Here we provide only a brief descrip-
tion of the aspects of ECN that we are interested in. An ECN-
capable client sets the ECN ECHO and CWR (Congestion Window
Reduced) ﬂags in the header of the SYN packet; this is called an
ECN-setup SYN. If the server is also ECN-capable, it will respond
by setting the ECN ECHO ﬂag in the SYN/ACK; this is called an
ECN-setup SYN/ACK. From that point onwards, all data packets
exchanged between the two hosts, except for retransmitted pack-
ets, can have the ECN-Capable Transport (ECT) bit set in the IP
header. If a router along the path wishes to mark such a packet as
an indication of congestion, it does so by setting the Congestion
Experienced (CE) bit in the IP header of the packet.
The goal of the test is to detect broken equipment that results
in denying access to certain web-servers from ECN-enabled end
nodes. The test is not meant to verify full compliance to the ECN
standard [28].
1. TBIT constructs an ECN-setup SYN packet, and sends it to
the remote web server.
2. If TBIT receives a SYN/ACK from the remote host, TBIT
proceeds to step 4.
3. If no SYN/ACK is received after three retries (failure mode
1), or if a packet with RST is received (failure mode 2), TBIT
concludes that the remote server exhibits a failure. The test
is terminated.
4. TBIT checks to see if the SYN/ACK was an ECN-setup SYN/-
ACK, with the ECN ECHO ﬂag set and CWR ﬂag unset. If
this is the case, then the remote web server has negotiated
ECN usage. Otherwise, the remote web server is not ECN-
capable.
5. Ignoring whether the remote web server negotiated ECN us-
age, TBIT sends a data packet containing a valid HTTP re-
quest, with the ECT and CE bits set in the IP header.
6. If an ACK is received, check to see if the ECN ECHO ﬂag
is set.
If no ACK is received after three retries, or if the
resulting ACK does not have the ECN ECHO ﬂag set (failure
mode 3), TBIT concludes that the remote web server does not
support ECN correctly.
To ensure robustness, before running the test we check to make
sure that the remote server is reachable from our site, and would
ACK a SYN packet sent without the ECN ECHO and CWR ﬂags
set. Robustness against packet loss is ensured by the retransmission
of a SYN or of the test data packet as mentioned in steps 4 and 6.
The ECN test was conducted in September, 2000, and used a
larger set of hosts (about 27,000). The purpose of the ECN test
was to investigate the problem reported in [16], so we included the
same list of web servers. Each host was tested only once. The test
returned a result in case of 24,030 hosts. The cumulative ﬁndings
are reported in Table 16. The ﬁrst row reports hosts that do not sup-
port ECN, but interact correctly with clients that do support ECN.
The second and third row represent hosts that deny access to ECN-
capable clients. The fourth row represents hosts that negotiate ECN
support, but fail to respond to CE bits set in data packets. These
three cases, failure modes 1 through 3, are broken implementations
or ﬁrewalls that need to be corrected. The ﬁfth row represents hosts
that seem to support ECN correctly.
NMAP results indicated that many hosts with failure mode 2
were behind Cisco’s Localdirector 430 [7], which is a load bal-
ancing proxy. Some of the hosts with failure mode 2 have been
identiﬁed by others as using Cisco’s PIX ﬁrewall. Both of these
problems have been brought to Cisco’s attention, and a ﬁx has since
been made available. Most hosts with failure mode 1 seem to be
running a version of the AIX operating system. We have contacted
people at IBM, and they are working on the problem. Some of these
failures are due to ﬁrewalls and load-balancers that mistake the use
of the ECN-related ﬂags in TCP for a signature for a port scanner
tool [21]. Most of the hosts with failure mode 3 seem to be running
older versions of Linux (Linux 2.0.27-34). Of the 22 hosts in the
ﬁfth row, negotiating ECN and using ECN correctly, 18 belong to
a single subnet. NMAP could not identify the operating systems
running on these 18 hosts. Of the remaining four, three seem to be
running newer versions of Linux (2.1.122-2.2.13).
We repeated the ECN tests in April, 2001 for the servers report-
ing failure mode 1 or 2 in the September 2000 tests. Of the 1699
web servers responding, 1039 still exhibited failure mode 1, 326
still exhibited failure mode 2, and 332 no longer exhibited failure.
The list of the failing web servers is available on the TBIT web
page [22].
5. DISCUSSION OF RESULTS
This section discusses in more detail the reasons why a TBIT
test might terminate without returning any result. The fraction of
tests that do not return a result is highest for the SACK test, where
a total of 19% of the tests failed to return a result. These reasons
for failing to return a result are enumerated in Tables 1, 4, 7, 10 and
13.
The ﬁrst three reasons in the tables are: (i) no connection, (ii) no
data and (iii) receipt of a packet with the RST or FIN ﬂag set before
the the test is complete. When any of these three happen, the TBIT
test ends without returning a result.
The fourth reason in each of the tables is “Large MSS”. TBIT
terminates the test if the server sends a packet with MSS larger
Test result
Server not ECN-Capable
Failure mode 1: No response to ECN-setup SYN
Failure mode 2: RST in response to ECN-setup SYN
Failure mode 3: ECN negotiated, but data ACK does not report ECN ECHO
ECN negotiated, and ECN reported correctly in data ACK
Total
Servers
21602
1638
513
255
22
24030
Table 16: ECN test results, September 2000.
than the maximum set by the receiver. One might argue that this
should not be a reason to terminate the test immediately, especially
for simpler tests like the ICW test, and for tests such as the Time-
wait test, where the data ﬂow itself is not of interest. However, we
decided to do so, because the sender TCP is not supposed to exceed
the MSS value set by the receiver [2]. We are working on relaxing
this requirement.
The two other important reasons for test terminations are packet
drops and packet reordering detected by TBIT before the comple-
tion of the test. For the ICW test, while certain packet drops can be
detected and their impact on the ﬁnal result can be correctly antic-
ipated, we chose not to do so to keep the test code simple. Packet
reordering is not an issue for the ICW test.
For the CCA, CCC amd SACK tests, packet drops and packet re-
ordering cause signiﬁcant problems, as the results from these tests
depend upon the ordering and timing of the packets received. We
have developed code to avoid terminating the test for some simple
cases of packet losses and reordering. However, we decided that
the incremental gain was not worth the added complexity.
The Timewait test is not affected by packet reordering. It is also
unaffected by any packet drops within the data stream. Packet
drops during the handshake and teardown do affect the test. As
described in Section 4.5, we guard against them by using retrans-
missions, in a manner similar to TCP. In Table 13, we see that 112
tests terminated without returning a result due to packet drops. This
is due to a bug in our code, which terminated the test whenever the
very ﬁrst data packet sent by the server is lost. We plan to ﬁx this
error in a future version of TBIT.
We also note that a TBIT test might return different results when
run against the same host at different times. The hosts belonging to
categories 3 and 4 in Tables 2, 5, 8, 11 and 14 exhibit this problem.
We speculate that there are at least two causes for this.
The ﬁrst cause may be certain packet loss sequences that TBIT
is unable to detect and guard against. For example, during an ICW
test, packets can be lost from the “top” of the congestion window.
TBIT can not detect this loss, and would return a value of ICW that
is smaller than the one actually used by the server. In case of the
CCA test, all of the duplicate ACKs sent by TBIT for packet 13
may be lost. In that case, the remote host would be forced to take
a timeout, and may be erroneously classiﬁed as “TCP without Fast
Retransmit”.
Another possibility is that some of the web servers are, in effect,
clusters of computers answering to the same IP address. Depending
on the load balancing algorithm used, we may contact two differ-
ent machines in the cluster if the same test is repeated at different
times. These two computers may run different operating systems,
and hence different TCP stacks. We have seen some evidence of
this in the SACK test as discussed in Section 4.4.
Since we found no easy way to deal with either of the two prob-
lems discussed above, we chose to ran each TBIT test multiple
(ﬁve) times, and report results only about those hosts that returned
results for some minimum number (three) of these tests, and re-
turned the same result each time.
It is possible to devise more
elaborate schemes to ensure robustness of test results, and we are
investigating these further.
Hosts belonging to Category 5 also deserve special attention.
These hosts failed to return answers for any of the ﬁve tests. We
found that some of these hosts were simply ofﬂine for a variety
of reasons (failed dot-coms?) during our testing period. Some
would not send packets with a small MSS. We also found that
packet reordering was a persistent problem for some of the hosts,
especially the ones that appear to be across transoceanic links. TBIT
tests like CCA, CCC and SACK tend to fail more often with such
hosts.
We note that the number of hosts belonging to Category 1 may
be thought of as a metric of “usefulness” of TBIT tests. Suppose
we were to come up with a TBIT test that veriﬁed some interest-
ing property of TCP, but required very large number of packets to
complete, and had to terminate for any packet loss or reordering.
It is likely that for such a test, few hosts would belong to the ﬁrst
category. Thus, the results of such a test would always be question-
able. We note that for all of the tests reported in this paper, more
than 70% of the hosts belong to the ﬁrst category. We had reported
considerably poorer performance in an earlier report [23] on this
work. The poor performance was due to the fact that we had not
veriﬁed that all the hosts would send sufﬁcient data to complete the
test. We have also made improvements in the TBIT code to reduce
the number of instances in which a test has to be terminated early.
We used NMAP to identify the operating system running on the
web servers being tested. Any assertions we make regarding the op-
erating system running on a web server are subject to the accuracy
of NMAP identiﬁcation. We also note that in many cases, rather
than providing a single guess, NMAP provides a set of operating
systems as potential candidates.
6. CONCLUSION
In this paper, we have described a tool, TBIT, for characterizing
the TCP behavior of remote web servers. TBIT can be used to
check any web server, without the need for any special privileges
on that web server, in a non-disruptive manner. The source code for
TBIT is available from the TBIT web page [22]. We believe that
this kind of data (e.g. versions of congestion control algorithms
running on web servers, sizes of initial window, time wait duration)
is being reported for the ﬁrst time. As a result of these tests, we
have more information about the congestion control mechanisms
used by trafﬁc in the Internet. As a side effect of this work, we
uncovered several bugs in TCP implementations of major vendors,
and helped them correct these bugs.
We plan to continue this work in several ways. First, we plan
to develop tests for more aspects of TCP behavior. For example,
it would be useful to track the deployment of new TCP mecha-
nisms such as the DSACK option (RFC 2883), Limited Transmit
(RFC 3042), or Congestion Window Validation (RFC 2861), or to
investigate the details of retransmit timeout mechanisms. One goal
is to provide comprehensive standards-compliance testing of TCP
implementations. In addition, we are exploring the possibility of
[12] S. Floyd and T. Henderson. The NewReno Modiﬁcation to
TCP’s Fast Recovery Algorithm, April 1999. RFC 2582.
[13] Fyodor. Remote OS detection via TCP/IP Stack
FingerPrinting. Phrack 54, 8, Dec. 1998. URL
”http://www.insecure.org/nmap/nmap-ﬁngerprinting-
article.html”.
[14] T. Gao and J. Mahdavi. On Current TCP/IP Implementations
and Performance Testing, August 2000. Unpublished
manuscript.
[15] V. Jacobson. Congestion Avoidance and Control. Computer
Communication Review, 18(4), August 1988.
[16] D. Kelson, September 2000. http://www.uwsg.iu.edu/-
hypermail/linux/kernel/0009.1/0342.html.
[17] B. Krishnamurthy and M. Arlitt. PRO-COW: Protocol
Compliance on the Web-A Longitudinal Study. In USENIX
Symposium on Internet Technologies and Systems, 2001.
[18] B. Krishnamurthy and J. Rexford. Web Protocols and
Practice: HTTP/1.1, Networking Protocols, Caching, and
Trafﬁc Measurement. Addison-Wesley, 2001.
[19] M. Mathis, J. Mahdavi, S. Floyd, and A. Romanow. TCP
Selective Acknowledgment Options, October 1996.
RFC2018.
[20] S. McCanne and V. Jacobson. The BSD Packet Filter: A New
Architecture for User-level Packet Capture. In Proceedings
of the winter USENIX technical conference, January 1993.
[21] T. Miller. Intrusion Detection Level Analysis of Nmap and
Queso, August 2000.
[22] J. Padhye and S. Floyd. The TBIT Web Page.
http://www.aciri.org/tbit/.
[23] J. Padhye and S. Floyd. Identifying the TCP Behavior of
Web Servers. Technical Report 01-002, ICSI, 2001.
[24] K. Park, G. Kim, and M. Crovella. On the Relationship
between File Sizes, Transport Protocols and Self-Similar
Network Trafﬁc. In Proc. International Conference on
Network Protocols, 1996.
[25] V. Paxson. End-to-End Internet Packet Dynamics. In Proc.
ACM SIGCOMM, 1997.
[26] V. Paxson, M. Allman, S. Dawson, W. Fenner, J. Griner,
I. Heavens, K. Lahey, J. Semke, and B. Volz. Known TCP
Implementation Problems, March 1999. RFC2525.
[27] J. Postel. Transmission Control Protocol, September 1981.
RFC793.
[28] K. K. Ramakrishnan and S. Floyd. A Proposal to add
Explicit Congestion Notiﬁcation (ECN) to IP, January 1999.
RFC2481.
[29] L. Rizzo. Dummynet and Forward Error Correction. In Proc.
Freenix, 1998.
[30] S. Savage. Sting: a TCP-based Network Measurement Tool.
Proceedings of the 1999 USENIX Symposium on Internet
Technologies and Systems, pages 71–79, Oct. 1999.
[31] W. Stevens. TCP/IP Illustrated, Vol.1 The Protocols.
Addison-Wesley, 1997. 10th printing.
using TBIT to automatically generate models of TCP implementa-
tions for use in simulators such as NS [10].
More generally, we believe that active tools like TBIT are neces-
sary to test other aspects of Internet behavior as well. Similar work
has already been done to test the deployment of HTTP/1.1 in web
servers [17], and to test the protocol behavior of web clients [3], in
addition to the wealth of other measurement-related research. One
possibility would be to extend TBIT to gather more information
about the infrastructure surrounding web servers, as it affects the
behavior of the server. (Firewalls that block ICMP packets come
to mind.) A completely different approach would be to develop
active but non-destructive tools to explore the effectiveness (or in-
effectiveness) of queue management at the congested router(s) on
the path to the web server, by examining the pattern of drops and
of end-to-end delay. There is a great deal still to do to understand
both the behavior in the Internet and the rate of deployment of new
mechanisms in the infrastructure.
Acknowledgments
We are grateful to Aaron Hughes for his generosity and immense
patience during the time we used his systems for NMAP scans.
Without Aaron’s generosity, a large part of this work would not
have been possible. We thank Stefan Savage for the source code of
the Sting tool. We thank Mark Handley for help with system ad-
ministration issues and several helpful discussions about the ECN
test. We thank Vern Paxson for his help in developing the time-wait
duration test. We thank Balachander Krishnamurthy for the list of
web servers used in [17]. We thank Mark Allman, Fred Baker,
Nick Bastin, Alan Cox, Jamal Hadi-Salim, Tony Hain, Dax Kelson,
Balachander Krishnamurthy, Alexey Kuznetsov, Jamshid Mahdavi,
William Miller, Erich Nahum, Kacheong Poon, K. K. Ramakrish-
nan, N. K. Srinivas, Venkat Venkatsubra, Richard Wendland and
participants of NANOG 20 for helpful discussions and comments.
We also thank the anonymous SIGCOMM referees for their helpful
feedback.
7. REFERENCES
[1] ECN-under-Linux Unofﬁcial Vendor Support Page.
http://gtf.org/garzik/ecn/.
[2] Internet protocol, September 1981. RFC791.
[3] M. Allman. A Web Server’s View of the Transport Layer.
Computer Communication Review, 30(5), October 2000.
[4] M. Allman, S. Floyd, and C. Partridge. Increasing TCP’s
Initial Window, September 1998. RFC2414.
[5] M. Allman, V. Paxson, and W. Stevens. TCP Congestion
Control, April 1999. RFC2581.
[6] N. Cardwell, S. Savage, and T. Anderson. Modeling TCP
Latency. In Proc. IEEE INFOCOM, 2000.
[7] Cisco Systems. How to Cost-Effectively Scale Web Servers.
Packet Magazine, Third Quarter 1996.
http://www.cisco.com/warp/public/784/5.html.
[8] K. Claffy, G. Miller, and K. Thompson. The Nature of the
Beast: Recent Trafﬁc Measurements from an Internet
Backbone. In Proceedings of INET’98, 1998.
[9] K. Fall and S. Floyd. Simulation-based Comparisons of
Tahoe, Reno, and SACK TCP. Computer Communication
Review, 26(3), July 1996.
[10] K. Fall and K. Varadhan. ns: Manual, February 2000.
[11] S. Floyd and K. Fall. Promoting the use of End-to-end
Congestion Control in the Internet. IEEE/ACM Trans.
Networking, August 1999.