### 优化后的文本

#### 计算真实图像的密度比
\[ r(x) = \frac{C(D(x))}{1 - C(D(x))} \]

#### 计算虚假图像的密度比
\[ r(x') = \frac{C(D(x'))}{1 - C(D(x'))} \]

\[ p = \min\left(1, \frac{r(x)}{r(x')} \right) \]

如果 \( u \leq p \)，则 \( x \leftarrow x' \)

```markdown
end while
end if
end for
if x 不是真实图像 then
    Append(x, images)
```

**表7：不同先验分布下的保真度提取攻击性能。我们使用标准正态分布和在-1到1区间上的均匀分布生成潜在代码。查询次数固定为50K。**

| 攻击模型 | 先验分布 | SNGAN (高斯) | SNGAN (均匀) | PGGAN (高斯) | PGGAN (均匀) |
| --- | --- | --- | --- | --- | --- |
| 保真度 | FID(\( \tilde{p}_g, p_g \)) | 4.49 | 4.29 | 1.02 | 0.98 |
| 准确性 | FID(\( \tilde{p}_g, p_r \)) | 9.29 | 9.16 | 4.93 | 4.85 |

### A 附录

#### A.1 实现细节
我们基于以下代码实现了PGGAN和SNGAN：
- PGGAN: [tkarras/progressive_growing_of_gans](https://github.com/tkarras/progressive_growing_of_gans)
- SNGAN: [christiancosgrove/pytorch-spectral-normalization-gan](https://github.com/christiancosgrove/pytorch-spectral-normalization-gan)

对于SNGAN，我们选择了ResNet架构。PGGAN的架构与官方实现相同。SNGAN使用铰链损失，而PGGAN使用WGAN-GP损失。对于合成数据中的目标GAN（图5），我们使用了四个带有ReLU激活函数的全连接层作为生成器和判别器，并且先验是一个二维的标准正态分布。训练数据是25个二维高斯分布的混合（每个分布的标准差为0.05）。我们使用标准损失函数进行训练。在第7节的案例研究中，我们直接使用预训练的StyleGAN（训练于LSUN-Bedroom数据集）作为目标模型。除了案例研究中使用分辨率为256×256的图像外，论文中所有使用的图像都被调整为64×64分辨率。SNGAN、PGGAN和StyleGAN的潜在空间维度分别为256、512和512，其潜在代码均从标准高斯分布中抽取。对于攻击模型，我们使用原始模型提供的建议超参数，并仅修改与计算资源相关的部分。

#### A.2 MH算法
算法1展示了MH子采样算法[65]。该算法的输入包括一个目标生成器（仅用于查询）、一个白盒判别器（用于子采样生成样本）以及部分真实样本（用于校准判别器）。输出是经过精炼的样本，其分布更接近真实训练数据的分布。

#### A.3 不同先验分布下的攻击性能
对手可以通过尝试常见的先验分布来生成潜在代码，从而查询目标模型。高斯分布和均匀分布在几乎所有GAN中都广泛使用[6, 31–33, 47, 53]。表7展示了两种先验分布下的攻击性能。我们选择以标准正态先验分布训练的CelebA数据集上的PGGAN作为目标模型。从表7可以看出，无论潜在代码的先验分布如何，对手都能获得相似的攻击性能。

#### A.4 分布差异的附加结果

##### A.4.1 理解SNGAN目标模型的保真度提取
图9展示了训练于CelebA数据集的SNGAN目标模型的分布差异。表8统计总结了这些差异。

##### A.4.2 深入理解GAN的准确性提取
按照第5.3.3节所述的相同程序，我们还分析了准确性提取的分布差异。具体来说，我们选择了PGGAN-PGGAN的情况作为示例（见图6），攻击模型为PGGAN。从图10可以看出，对于CelebA，具有最小准确值的白盒准确性提取方法与训练数据的分布更为一致，通过降低最高比例的类别。对于LSUN-Church，也可以观察到类似的结果。表9统计总结了这些差异。

#### A.5 防御技术

##### A.5.1 语义插值防御
语义插值防御的过程如图11所示。它包括两个阶段：找到语义超平面和生成语义图像。在第一阶段，我们首先为每个语义信息训练一个预测模型。然后，使用训练好的预测模型对通过潜在代码z生成的每个图像预测语义得分s。由此得到潜在代码-得分对，并将最高的k个得分标记为正，最低的k个得分标记为负。最后，在数据集中训练一个线性支持向量机（SVM），其中潜在代码作为训练数据，得分为标签。训练好的线性SVM包含一个分离特定语义信息的超平面。在第二阶段，我们可以通过插值获得每个语义超平面的语义图像。

##### A.5.2 防御效用
我们定量和定性地评估了防御措施的效果，即部署防御措施后生成图像的质量。图14和图15展示了基于输入扰动和输出扰动的防御措施返回的图像。表10显示了图像质量分数。我们使用了两种广泛采用的无参考图像质量评分：自然图像质量评价器（NIQE）[46]和基于感知的图像质量评价器（PIQE）[67]。总体而言，我们的防御措施不会影响生成图像的质量。

##### A.5.3 各种防御技术下SNGAN攻击模型的性能
图12展示了黑盒保真度提取场景下各种防御措施下SNGAN攻击模型的性能。

##### A.5.4 不同防御技术下的保真度
图13展示了黑盒保真度提取场景下不同防御措施下攻击模型的保真度。我们观察到，随着查询次数的增加，攻击模型的保真度值显著下降。

希望这些优化能帮助你更好地表达你的想法！如果有任何进一步的修改需求，请告诉我。