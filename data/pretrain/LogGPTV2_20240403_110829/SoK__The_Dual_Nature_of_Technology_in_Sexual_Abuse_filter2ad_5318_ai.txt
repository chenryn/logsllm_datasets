Technological design
does not account for the
changes in relationships
Examples
“The ‘SafeBand’ system is comprised of a wearable band to be used
by the victim, and two mobile applications to be used by the victim
and by the police. Women can wear the device as a wristband or
locket which will comprise of a button and a light. When the user
(victim) presses the button, it identiﬁes the location of the user
through Global Positioning System (GPS) and sends a message
incorporating the location to the nearest police station and
previously saved contacts (number of relatives)” [173].
“Many apps studied were difﬁcult to ﬁnd in the App Store. This
limits their visibility and utility to prospective users” [160].
“One of the major challenges that survivors face is that it requires
more effort and more technical knowledge for them to erase their
electronic footprints, than it does for their abuser to follow them.
Therefore redressing the balance in favour of the survivor will
require a range of measures including redesigned websites, history
cleaning technologies and training” [68].
“There is a need to protect victims from abusers who may have
access to victim information because of their jobs. As one
participant said, ‘Sometimes the abuser is a policeman’ ” [43].
“Despite the potential for a website or app ... to improve access to
help and support, the young women emphasized the importance of
the technology being safe ... for users. Concerns were raised by some
participants over the possibility of a perpetrator or another party
viewing a woman’s browser history or recently used apps” [178].
“Accessibility for clients and service providers with disabilities was
a concern, especially with already limited ﬁnancial resources that
typically are available to these agencies” [43].
“The research shows that survivors have ... barriers to successfully
accessing the support services that they require ... the fear of
provoking further abuse if their abuser discovers that they have been
seeking help” [68].
“Many apps were limited in their scope, providing intervention
materials to only a narrow group of users (usually female individuals
victimized by male perpetrators)” [160].
“ ... the app was previously packaged with other apps that included
We-Consent and charged fees [which] could seem
exploitative” [157].
“ ‘It just generally seemed like you could do the same things without
the app, because iPhones nowadays are so intricate, you could click
details on your messages and press ‘send location’ and type a short
message. I feel like that wouldn’t take nearly as long as opening the
app, clicking the button, sending the messages. ... I think personally
for me, it would just be easier to call or text them. It wasn’t any
easier to do that [using the app]’ ” [176].
“Considering user’s psychological proﬁle: user’s mental state could
affect the effectiveness of the solution. While under duress and
constant fear, it is inevitable that survivors might panic and struggle
to use features that would normally be straightforward to use, or to
miss certain precautionary routines” [118].
“Social networking sites do not account for the dynamism of
relationships, and assume that a “friend” on these sites stays that
way” [93].
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:58:18 UTC from IEEE Xplore.  Restrictions apply. 
2340
Victim blaming
The design of some
solutions encourages
victim blaming
Security and
privacy concerns
Lack of safety
evaluation
There are security and
privacy concerns with
using some solutions
The solutions are not
evaluated for victims’
safety
Stereotype
mentality
Lack of human
support for victims
Solutions are designed
with certain stereotypes
in mind
Solutions do not provide
human support
Stakeholder
involvement
Stakeholders should be
involved in the
development of solutions
Lack of usable
solutions
Solutions are not usable
for victims
Technology
maintenance
Technology is not
maintained or updated
Lack of
personalization of
solutions
The solutions are
designed as
one-size-ﬁts-all
“Bystanders are encouraged ... to step up and prevent violent
circumstances, but like many anti-violence initiatives, women are
targeted in prevention efforts. Problematically, such applications are
aimed at women as needing to be responsible for violence, rather
than, for example, education initiatives that would target perpetrators
of violence. That is, women are problematically expected to change
their behavior by tracking their whereabouts and ‘checking in’ with
friends to prevent violence” [39].
“Security breaches are a third area of signiﬁcant threat, especially in
light of the acutely sensitive nature of intimate data” [204].
“It is recommended that some form of evaluation be built into these
apps (beyond simply the number of downloads). It is also
recommended that app developers give more consideration to the
claims they make in their marketing and to give greater consideration
to the ways their apps could be used in harmful ways” [37].
“If [I’m] really in a (sexual abuse) emergency ... I feel like
personally that would only happen if I were that drunk, and if I
were that drunk, I don’t know if I’d be able to use [the app]” [176].
“A particular challenge for an online intervention—if it is designed
to be used without human interaction ... the young women felt that a
web or smartphone app could not completely replace the “human
touch” of real life support” [178].
“Moreover, technologists interested in creating interventions that aid
survivors ... must recognize that the technology cannot be developed
in isolation. Instead, technical advances will need to be accompanied
by parallel advances in legal and social support systems. For
example, developing new techniques to collect legally valid digital
evidence will require the legal system to evolve so as to recognize
the new techniques” [79].
“... survivors’ stories demonstrated that the usability of privacy and
security features is important, emphasizing ﬁndings from prior work
focused on the general population ... in a higher risk context. For
example, during the physical control and escape phases survivors
beneﬁted from access to technology to maintain communication with
their support network, but they also wanted to hide those
communications from an abuser who had physical access to them
and their devices. But survivors faced high levels of stress and risk,
which may have made it harder than usual for them to pay attention
to user interface details. We observed that participants made
mistakes when deleting or clearing information. Designers should
therefore consider both the general usability of privacy and security
features, and their use during high-stress, high-risk situations” [32].
“Apps that are developed at a low level of sophistication — or apps
that are developed at a high level of sophistication but are not well
maintained — experience a lack of regular updates and poor data
storage. Most ... apps are not regularly updated. Apps included in
this review often contain links to outside sources (such as hotlines or
advocacy resources) and apps that are not updated have a higher
susceptibility to broken links and outdated information” [160].
“Diverse user needs and experiences of abuse. People’s experiences
of abuse and their journeys through that experience are complex. It
is important to recognise that abuse can take place in any
relationship, regardless of gender or sexuality. It can also take many
forms, including coercive control, and psychological, physical,
sexual, ﬁnancial, and emotional abuse” [68].
TABLE A.2: Deﬁnitions and examples of sub-themes in our codebook on the theme of how technology assists victims.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:58:18 UTC from IEEE Xplore.  Restrictions apply. 
2341
3. How
technology
assists victims
Evidence
Challenges with
evidence
Evidence
gathering
Various
technological
sources
Large amount of
evidence
The use of technology to
gather evidence about a
sexual abuse incident
The gathering of
evidence through
multiple technological
sources
Difﬁculties with
collating large amounts
of evidence
Ambiguous
evidence
Revictimization
The gathered evidence is
ambiguous
Revictimization in
collecting evidence
Victim’s
responsibility to
gather evidence
Lack of clarity on
if consent is
needed
The responsibility of
evidence gathering falls
on the victim
Unclear if consent is
needed to gather
evidence
Stakeholder
knowledge gaps
Stakeholders are not
familiar with technology
use cases
Unclear if consent
was given
Unclear if consent is
needed to gather
evidence
“Evidence gathering via SNSs (social networking sites) ... the police
using such sites to gather evidence for an investigation (such as
collecting information about a victim or offender from their
SNSs)” [101].
“... what you may ﬁnd is that they do it on Facebook, but they’ll
also be doing it on email, and will also be doing it on SMS. And so
do you pursue all those different forums? Do you pursue enquiries
with the telecommunication providers to determine when and where
the emails were sent?” [87].
“The sheer abundance of data generated by communication
technologies ... poses investigators for a ‘needle-in-a-haystack
problem.’ As the pool of publicly available information is nothing
short of overwhelming, police work in this area is progressively
becoming a big data research problem” [61].
“Evidence collected through ‘ambiguous’ technological forms ... can
be excluded before national Courts” [78].
“ ‘My concern ... is the idea that women have private and
unrestrained access to their mobile phones ... having an app on your
phone is the same as having the local women’s aid card in your
phone - you’re asking a woman to make a risk assessment about
whether it is safe to do so’ ” [37].
“Victims feel that the responsibility of gathering evidence of the
abuse is theirs, in order to avoid situations in which it is the victim’s
version of events versus the perpetrator’s” [58].
“... forum members are placing themselves at risk in order to gather
evidence without knowing whether the recordings are admissible as
evidence ... ‘I’m wondering if without his consent it would be
inadmissible in court as evidence’ ” [58].
“Even in cases where police were successful in arresting and
charging the perpetrator, police ... understanding of the techno-social
aspects of the case impacted their decision to investigate and their
advice to clients” [90].
“Evidence collected ... without compliance with the conditions
provided by law can be excluded before national Courts” [78].
TABLE A.3: Deﬁnitions and examples of sub-themes in our codebook on the theme of the use of technological evidence in
investigating abuse.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:58:18 UTC from IEEE Xplore.  Restrictions apply. 
2342
Surveillance
systems
The use of surveillance
systems by the
government to track
victims and perpetrators
“Growing use of new technologies, including drones in the ﬁght
against human trafﬁcking, is the EUROSUR (European Border
Surveillance system) Regulation” [78].
4. How
technology
assists victims
and its
challenges
Government and
technological
service providers
Hiding shelters in
Google Maps
Hiding victim shelters in
Google Maps
Challenges with
government and
technological
service providers
Legislative laws
Different laws exist in
various jurisdictions
Privacy concerns
with surveillance
Surveillance could raise
privacy concerns for
victims
“Recognizing the impact of technologies on violent practices,
NNEDV (National Network to End Domestic Violence) (2010) has
advocated for increased safety measures with large technology
corporations. Partnering with NNEDV, Google has begun to create
user privacy and notiﬁcation options for location-based services and
worked closely with Google when the company launched ‘Street
View’ to ensure that no undisclosed shelter appeared in Google
Maps or Google Street View” [39].
“Some cases demonstrated the challenges law enforcement face
when the perpetrator or the content is outside local jurisdictions. For
example, in one case a client’s ex-partner was in Malaysia and
threatened to disseminate her intimate images on social media.
Police responded that they were unable to proceed as he was outside
of the country. Similarly, in another case where the perpetrator
hacked a client’s Dropbox and posted her images onto local forums,
police knew he was a ‘serial uploader’ yet they were unable to
proceed as the sites were hosted in the US and therefore outside of
SPF (Special Police Force) jurisdiction. ... These cases illustrate the
long-observed challenges that law enforcement face when
investigating technologically facilitated crimes. Often the perpetrator
is outside their jurisdiction” [90].
“While tracking technology can certainly offer new opportunities to
intervene ... it must be pointed out that being a form of surveillance
it can be highly invasive on a person’s privacy” [78].
TABLE A.4: Deﬁnitions and examples of sub-themes in our codebook on the theme of how government and service providers
restrict abuse.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:58:18 UTC from IEEE Xplore.  Restrictions apply. 
2343