```
import logging
LOGGER=logging.getLogger(__name__)
```
考虑到这一点，你现在必须明确日志级别的语义。这其中有很多选项，但是下面这些是我的最爱：
* `Error`：发送一个即时警告。应用程序处于一个需要操作人员引起注意的状态。（这意味着包含 `Critical` 和 `Error`）
* `Warning`：我喜欢把这些称作“工作时间警报”。这种情况下，应该有人在一个工作日内关注一下。
* `Info`：这是在正常工作流程中发出的。如果怀疑有问题的时候，这个是用来帮助人们了解应用程序在做什么的。
* `Debug`：默认情况下，这个不应该在生产环境中出现。在模拟环境或开发环境下，可以发出来，也可以不发。如果需要更多的信息，在生产环境也可以特地被打开。
任何情况下都不要在日志中包含 个人身份信息   Personal Identifiable Information （PII）或密码。无论日志级别是什么，都是如此，比如级别更改，激活调试级别等等。日志聚合系统很少是  PII 安全   PII-safe 的，特别是随着 PII 法规的不断发展（HIPAA、GDPR 等等）。
#### 日志聚合
现代系统几乎都是分布式的。 冗余   redundancy    、     扩展性       scaling       ，有时是     管辖权       jurisdictional       需要更多的水平分布。微服务意味着垂直分布。登录到每个机器去查看日志已经是不现实的了。出于合理的控制原因，允许开发人员登录到机器中会给予他们更多的权限，这不是个好主意。 
所有的日志都应该被发到一个聚合器。有一些商业的方案，你可以配置一个 ELK 栈，或者也可以使用其他的数据库（SQL 或则 no-SQL）。作为一个真正的低技术解决方案，你可以将日志写入文件，然后将它们发送到对象存储中。有很多解决方案，但是最重要的事情是选择一个，并且将所有东西聚合到一起。
#### 记录查询
在将所有东西记录到一个地方后，会有很多日志。具体的聚合器可以定义如何写查询，但是无论是通过从存储中搜索还是写 NoSQL 查询，记录查询以匹配源和细节都是很有用的。
### 指标抓取
 指标抓取   Metric Scraping    是一个     服务器拉取       server pull          模型。指标服务器定时和应用程序连接，并且拉取指标。      
最后，这意味着服务器需要连接和找到所有相关的应用服务器。
#### 以 Prometheus 为标准
如果你的指标聚合器是 Prometheus，那么 [Prometheus](https://opensource.com/article/21/7/run-prometheus-home-container) 格式做为一个 端点   endpoint 是很有用的。但是，即使聚合器不是 Prometheus，也是很有用的。几乎所有的系统都包含与 Prometheus 端点兼容的 垫片   shim 
使用客户端 Python 库给你的应用程序加一个 Prometheus 垫片，这将使它能够被大多数的指标聚合器所抓取。当 Prometheus 发现一个服务器，它就期望找到一个指标端点。这经常是应用程序路由的一部分，通常在 `/metrics` 路径下。不管 Web 应用的平台是什么，如果你能在一个端点下运行一个定制类型的定制字节流，Prometheus 就可以将它抓取。
对于大多数流行的框架，总有一个中间件插件或者类似的东西收集指标，如延迟和错误率。通常这还不够。你需要收集定制的应用数据：比如，每个端点的缓存 命中/缺失   hit/miss 率，数据库延迟，等等。
#### 使用计数器
Prometheus 支持多个数据类型。一个重要且巧妙的类型就是计数器。计数器总是在前进 —— 但有一点需要注意。
当应用重置，计数器会归零。计数器中的这些“ 历时   epochs ”通过将计数器“创建时间”作为元数据发送来管理。Prometheus 知道不去比较两个不同 历时   epochs 的计数器。
#### 使用仪表值
仪表值会简单很多：它们测量瞬时值。用它们来测量会上下起伏的数据：比如，分配的总内存大小，缓存大小，等等。
#### 使用枚举值
枚举值对于整个应用程序的状态是很有用的，尽管它们可以以更精细的方式被收集。比如，你正使用一个 功能门控   feature-gating 框架，一个有多个状态（比如，使用中、关闭、 屏蔽   shadowing  等）的功能，也许使用枚举会更有用。
### 分析
分析不同于指标，因为它们要对应连续的事件。比如，在网络服务器中，事件是一个外部请求及其产生的工作。特别是，在事件完成之前事件分析是不能被发送的。
事件包含特定的指标：延迟，数量，以及可能产生的对其他服务请求的细节，等等。
#### 结构化日志
现在一个可能的选择是将日志结构化。发送事件只发送带有正确格式的有效 载荷   payload 的日志。这个数据可以从日志聚合器请求，然后解析，并且放入一个合适的系统，这样可以对它的可见性。
### 错误追踪
你可以使用日志来追踪错误，也可以用分析来追踪错误。但是一个专门的错误系统还是值得的。一个为错误而优化的系统可以发送更多的错误，因为错误毕竟还是罕见的。这样它就可以发送正确的数据，并且用这些数据，它能做更多智能的事情。Python 中的错误追踪系统通常和一般的异常处理关联，然后收集数据，并且把它发到一个专门的错误聚合器。
#### 使用 Sentry
很多情况下，自己运行 Sentry 是正确的做法。当错误发生时，就说明有些东西就出问题了。可靠地删除敏感数据是不可能的，因为一定有会出现敏感数据被发送到不应该的地方。
通常，这种工作量并不会很大：异常并不常出现。最后，这个系统并不需要很高的质量，也不需要高可靠性的备份。昨天的错误应该已经修复了，希望如此，如果没有，你还会发现的！
### 快速、安全、可重复：三者都要
可观测的系统开发起来更快，因为它们可以给你提供反馈。它们运行起来也更安全，因为当出问题的时候，它们也会更早的让你知道。最后，因为有反馈回路，可观测性也有助于围绕它构建可重复的过程。可观测性可以让你了解你的应用程序。而更了解它们，就胜利了一半。
#### 磨刀不误砍柴功
构建所有的可观测层是一件困难的事情。总会让人感觉是在浪费的工作，或者更像是“可以有，但是不急”。
之后再做这个可以吗？也许吧，但是不应该。正确的构建可观测性可以加速后面所有阶段的开发：测试、监控，甚至是培训新人。在一个和科技行业一样动荡的行业，减少培训新人的工作量绝对是值得的。
事实上，可观测性很重要，所以尽早把它写出来，然后就可以在整个过程中进行维护。反过来，它也会帮你维护你的软件。
---
via: 
作者：[Moshe Zadka](https://opensource.com/users/moshez) 选题：[lujun9972](https://github.com/lujun9972) 译者：[MCGA](https://github.com/Yufei-Yan) 校对：[wxy](https://github.com/wxy)
本文由 [LCTT](https://github.com/LCTT/TranslateProject) 原创编译，[Linux中国](https://linux.cn/) 荣誉推出