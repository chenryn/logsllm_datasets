TPR
Method
WiID [46]
92.80%
≤97%
VAuth [25]
P2Auth [33] ≤99.55%
96.51%
HandLock
FAR
-
0.10%
2.1%
0.82%
Extra Hardware Device Free
WiFi transceiver
Yes
No
No
Yes
Wearable
Wearable
No
features in normal voice frequency and calculates mouth move-
ment speed derived from ultrasound signal to authenticate users.
EarEcho [26] takes advantages of the unique physical and geomet-
rical characteristics of human ear canal to authenticate users using
inaudible signals. However, all of these schemes require users to
hold the device in close proximity (within a few centimeters) of the
microphones to perform authentication.
Distinction with Prior Work. To the best of our knowledge, we
are the first to propose an acoustic hand gesture based 2-FA system
for VAs. Our approach is device-free and non-obtrusive. As we will
later on show our approach is able to not only thwart emulation
attempts by an attacker, but can also allow multiple users in a
household to enroll with different gestures. Table 1 highlights a
comparison with other existing VA authentication systems. Hand-
Lock achieves similar effectiveness when compared with existing
approaches. However, unlike other approaches HandLock does not
require any additional hardware and operates device free. Thus,
our approach is fully compatible with existing VAs.
3 SYSTEM DESIGN
3.1 System Overview
The key principal of HandLock is to derive the unique hand ges-
ture fingerprint of an individual by analyzing the acoustics signals
bouncing off from the individual’s hand when he/she is making
a gesture. Once the received acoustic signal is prepossessed it is
then compared with known fingerprints of authorized users to
complete the verification step. Figure 2 shows an overview of our
proposed system, which consists of five main components: signal
sensing, signal processing, feature extraction, user modeling, and
verification.
In the signal sensing phase, as soon as the VA enters a sensitive
operation (i.e., operations that a user wants to limit by an 2-FA
approach), such as confirming an online purchase, the embedded
speaker of the VA device prompts the user to perform a hand gesture
and starts emitting inaudible continuous wave (CW) signal. The
microphone array on the VA simultaneously starts recording the
inaudible sound as the user performs a gesture over the VA. In the
signal processing phase, the received signal (RF) is first multiplied
with the transmitted signal cos 2π f t and its phase-shift version
− sin 2π f t. We then use a low pass filter to get the corresponding,
In-phase (I) and Quadrature (Q) signals. Given that we can extract
the acoustic phase shift from the Q signal which is less susceptible
to noise (as we will show in Section 3.3.2), we use the Q trace
alone to extract features. Next, we extract the phase shift from Q
trace and divide phase signals into small segments that contain the
hand movements. These signal segments are then passed through
a feature extraction process, where HandLock uses an automated
feature engineering process to select the top distinguishing features
3
253RAID ’21, October 6–8,2021, San Sebastian, Spain
Shaohu Zhang and Anupam Das
Figure 2: System overview. There are five major components: ultrasonic sensing, signal processing, feature extraction, user
modeling, and verification.
across different users. Next, we use these features to train machine
learning (ML) classifiers for different settings, like single-user or
multi-user authentication. Lastly, HandLock uses the developed ML
classifier to distinguish a known user from a set of unknown users.
We provide more details of each step below.
3.2 Signal Sensing
In designing the signal sensing process, where HandLock emits
audio signals we considered two factors: user experience and sys-
tem performance. To make our system unobtrusive, the acoustic
signal emitted by the VA is made inaudible. Therefore, HandLock
uses sound waves with frequencies higher than 16 kHz, which are
inaudible to most people and supported by Commercial-Off-The-
Shelf (COTS) voice assistant devices. We transmit and record audio
signals at 48 kHz. Next, to improve acoustic sensing capability, we
use multiple carrier frequencies of inaudible signal of A cos 2π f t to
improve phase detection. A gesture usually takes 1.5 ∼ 3 seconds
and the hand trace moves up to 1 meter during this time, so the
hand speed (v) is up to 0.67 m/s. The frequency shift caused by a
hand movement can be measured at the microphone (fr ) using the
following equations.
c + v
c − v
fr = f0
∆f = fr − f0
(1)
(2)
The Doppler shift can be simplified as ∆f = 2v f0/c, where c is the
sound speed in air and f0 is the original transmitted frequency from
the speaker, thus ∆f = 2∗0.67∗20000/343 ≈ 78Hz, when the source
frequency is 20kHz. To ensure there is no interference of Doppler
shifts caused by two source signals of varying frequencies, we use
a frequency interval of 400 Hz. Figure 3 illustrated the recorded
signal when we use 16 different source frequencies with an interval
of 400 Hz, i.e., source frequencies = { f
: f = 16000 + 400i, i =
0, 1, ..., 15}. We sum and normalize the 16-frequency signals as
f =16000 cos 2π f t. The sound pressure was observed to be 80 dB
when the signal amplitude A is set to 1. To reduce the loudness of
the emitted signal to 50 dB, we set A to 0.5.
A22000
3.3 Signal Processing
Recorded acoustic signals are processed in three steps as shown in
Figure 2. We provide the details of these steps here.
Signal I/Q Modulation. A transmitted signal arrives at the
3.3.1
microphone from multiple paths including the structure-borne path
4
Figure 3: Received signal at 16 different frequencies.
Figure 4: I/Q modulation process.
via the body of the device, the Light-Of-Sight (LOS) propagation
path via the air, and other reflection paths by surrounding objects
(e.g., the user’s body, the table where the device seats). Let us assume
the phase of the source signal (A cos 2π f t) changes by δ due to the
Doppler effect caused by a hand movement. Let 2π f D(t)/c repre-
sents the phase delay (i.e., impact of multi-path) caused by the prop-
agation delay of D(t)/c, where c is the speed of sound. The recorded
inaudible signal will then be A′ cos(2π f t + 2π f D(t)/c + δ). Let ϕ
represents phase shift 2π f D(t)
+ δ, then the received signal can be
simplified using the equation shown below:
c
′ cos(2π f t + ϕ) = A
′(cos 2π f t cos ϕ − sin 2π f t sin ϕ)
(3)
This equation (i.e., Eq. 3) can further be simplified by substituting
the in-phase (I = A′ cos ϕ) and quadrature (Q = A′ sin ϕ) compo-
nents of the signal as shown below:
A
′ cos(2π f t + ϕ) = I cos 2π f t − Q sin 2π f t
(4)
The general pipeline to derive I and Q signals is shown in Figure 4.
The received signal is first multiplied with the transmitted signal
cos 2π f t and its phase-shifted version − sin 2π f t. We then use a
low pass filter (LPF) to filter out frequencies greater than 24 kHz
(i.e., maximum possible frequency at 48 kHz sampling rate) and get
the corresponding desired I and Q traces.
A
I = LPF(2A
′ cos(2π f t + ϕ)cos(2π f t)) = A
′ cos ϕ
(5)
254HandLock: Enabling 2-FA for Smart Home Voice Assistants using Inaudible Acoustic Signal
RAID ’21, October 6–8,2021, San Sebastian, Spain
Q = LPF(−2A
′ cos(2π f t + ϕ)sin(2π f t)) = A
′ sin ϕ
(6)
Figure 5: Corresponding I/Q signal when performing a ‘Z’
gesture.
3.3.2 Phase Extraction. Acoustic signal recorded by a microphone
typically includes ambient noise such as human voice or environ-
mental noise. Our data collection process took place in a lab envi-
ronment that emulated a smart home living room. Hence, various
smart home devices such as desktop computers, smart TVs, motion
sensors and smart cameras were all present in the room while data
was being collected. Also, some of the participants spoke while per-
forming hand gestures. As we discussed in Section 3.2, the Doppler
shift caused by hand movement is below 100Hz. We use a third-
order Butter-worth low-pass filter [4] with a stop frequency at 100
Hz to remove undesired high-frequency noises of the modulated
I/Q signal, caused by human speech and ambient noise. The fil-
tered signal is then down sampled by a factor of 100 to reduce the
system computational overhead, that is, the sampling frequency is
decreased from 48 kHz to 480 Hz. Figure 5 shows the corresponding
I/Q signals after the denoising and down-sampling process when a
user is performing a ‘Z’ gesture.
However, due to hardware imperfections, the center of the recorded
signal is not around 0. Figure 6 shows the offset present in I and Q
trace, where IDC=0.01 and QDC=-0.01, respectively. Thus, I and Q
can be written as I = IDC + A′ cos ϕ and Q = QDC + A′ sin ϕ.
Limitations of prior works. Figure 7 highlights a short time
series of IQ trace. Prior works [23, 59] approximates phase (ϕ) by
points in a circle. Specifically, the chord length (Chordi) is propor-
tional to the angle formed by an arc when it is very small. The
length of chord between two neighbouring IQ points is calculated
considering small arcs (Pi Pi +1) formed by two neighbouring IQ
(cid:113)(Ii +1 − Ii)2 + (Qi +1 − Qi)2
as: Pi Pi +1 =
Using Taylor’s series we know, sin ϕ = ∞
= 2R sin(ϕi/2) ≈ Rϕi
where R is the radius of the circle IQ points form, and ϕ is the
central angle of the corresponding chord.
(−1)−n
(2n+1)!ϕ2n+1 =
3! +.... Thus, sin ϕ ≈ ϕ, when ϕ is small. Assuming R is constant
ϕ− ϕ3
in a given short time, ∆Chordi ≈ R(ϕi +1 − ϕi) as shown in Eq. 8,
which is proportional to the phase change. We call this process
Chord-based phase extraction. However, as shown in Figure 5 and
n=0
(7)
5
Figure 6: I/Q signal with DC offset caused by hardware im-
perfections.
Figure 7: Sample I/Q trace.
Figure 8: Phase change based on Chord-based and Q-based
approach. Q-based approach does not require approximat-
ing the value of R.
Figure 7, R changes dramatically within one gesture signal, which
causes an inaccurate approximation of phase change if we consider
R to be constant.
∆Chordi = ∥Pi +1Pi +2 −Pi Pi +1∥ = ∥R(ϕi +1 − ϕi)∥
Qi +1 − Qi = QDC + A
′ sin ϕi +1 − (QDC + A
) = A
+ δi +1 − 2π f D(t)
i +1
3! +
ϕ3
i
3!
′ sin ϕi)
′(ϕi +1 − ϕi)
− δi)
c
′(ϕi +1 − ϕi − ϕ3
′(2π f D(t)
′(δi +1 − δi)
c
= A
= A
= A
(8)
(9)
Our approach. As Q = A′ sin ϕ, the phase shift can be extracted
from the Q trace alone as shown in the Eq. 9. Our approach is not
dependent on approximating the value of R, and at the same time
removes the DC offset and reduces the impact of multi-path propa-
gation (eliminating both QDC and 2π f D(t)
). Figure 8 contrasts the
Chord-based and our Q-based approach of approximating phase
change. In our approach, phase change can, therefore, be repre-
sented by θi = ∥δi +1 − δi ∥ = ∥(Qi +1 − Qi)/A′∥. As A′ is constant,
θi is proportional to ∥Qi +1 − Qi ∥.
c
0100200300400500600700Samples-0.04-0.0200.020.04AmplitudeIQ-0.04-0.0200.02I-0.0200.020.04Q P1 P2 P30200400600Samples00.010.02Phase ChangeChord basedQ based255RAID ’21, October 6–8,2021, San Sebastian, Spain
Shaohu Zhang and Anupam Das
(a) cv of phase change
(b) Detecting the start and end of gesture
Figure 9: Detection of the start and end point of a hand ges-
ture within a signal.
Signal Segmentation. After phase extraction, we need to de-
3.3.3
tect the start and end of a hand gesture to properly extract signal
features. This means we need to find segments within the signal
that represents hand gestures. Empirically, we found that the signal
phase remains close to zero in the absence of any hand movement,
whereas it is deterministically non-zero in the presence of hand
movements as shown in Figure 9b. Consequently, the coefficient of
variation (cv) for any signal value is much smaller in the absence
of hand movements than in the presence of hand movements. We,
therefore, select a threshold T on the coefficient of variation of θi to
detect the start and end of a gesture. HandLock first calculates the