Created_at
Repo
FavioVazquez/ds-cheatsheets
facebookresearch/flashlight
2018-12-23T07:37:38Z mahmoud/awesome-python-applications
2018-12-23T07:37:44Z
2018-12-23T07:38:02Z
2018-12-23T07:39:19Z
2018-12-23T07:39:30Z
2018-12-23T07:39:38Z
2018-12-23T07:39:46Z
2018-12-23T07:40:00Z
FAQGURU/FAQGURU
alibaba/x-deeplearning
trekhleb/homemade-machine-learning
ghost1****/t****
alash3al/redix
Star Count
6,369
3,597
762
8,749
716
3,529
2,145
689
Repo Type
Popular Author
Popular Author
Organization
Popular Author
Promotion Target
Popular Author
Organization
Popular Author
Table 3: Features Used by Our Classifier
Table 4: Comparison of Classifier Performance
Name
NO14
NSFE
RSFA
AAOPM1
AAOPM2
AAOPM3
AAOPH1
Description
Number of Different Operations
(14-Dimension)
Number of Star and Fork Operations
Ratio of Sum of Star and Fork Operations
in All the Operations
Average of Adjacent Operations Pair
Average of Adjacent Operations Pair
in One Minutes
in Two Minutes
Average of Adjacent Operations Pair
in Three Minutes
Average of Adjacent Operations Pair
in One Hour
3.4 Dataset for Training
By using our honeypot repository, we identified promotion ac-
counts that had made stars and forks to the honeypot repository.
Since we never advertised our honeypot projects and the projects
had no meaningful code or documents at all, all stars and forks
must come from promotion services we infiltrated. These identi-
fied promotion accounts serve as positive samples for training the
classifier.
For the negative samples, we consider authentic users who made
major active contributions in well-known repositories. Specifically,
we collected two kinds of accounts: the contributors of popular
GitHub repositories and those who have proposed valuable issues
on popular repositories. The former accounts have a considerable
proportion of commit and push events, while the latter have a
number of operations, including push, issue, and comment events.
Considering the diversity of negative samples, we selected the top
10 programming languages reported by GitHub [9], and found the
most popular repository in https://gitstar-ranking.com/ 2 for each
different language. From these repositories, we collected 1,550 users
as negative samples, including 200 high-profile users who are quite
active all the time and 1,350 normal users.
2A site in which one can see top 1,000 users, organizations, and repositories.
Classifier
Naive Bayes
KNN
Logistic
Regression
Decision Tree
Random Forest
SVM
Precision (%) Recall (%)
95.4
96.2
95.7
97.9
98.3
98.5
64.5
87.3
98.7
98.7
99.5
99.7
F1
0.77
0.915
0.972
0.983
0.989
0.991
3.5 Features
In Section 3.3, we discuss the differences between promotion ac-
counts and normal ones, which can help us to select proper features
for developing classifiers. First of all, promotion accounts have
much more frequent operations than normal users in terms of 14
different operation types, especially in WatchEvent and ForkEvent.
Therefore, we selected the number of these operations as features.
Moreover, promoters basically focus on star and fork. Thus, we com-
puted the total number and ratio of fork and star operations among
all the operations. Meanwhile, we also need to capture the burst
of promotion accounts (i.e., a number of star and fork operations
in a short time period). The burst is associated with the promotion
nature. To this end, we calculated the average time interval between
successive operations of promotion accounts. Specifically, this aver-
age time interval is set to different timing granularity, ranging from
one minute, two minutes, three minutes, to one hour. The detailed
description of the features is presented in Table 3. The features are
normalized by dividing the largest feature value.
3.6 Classifiers
We used the features mentioned in Table 3 for model training.
We employed six different popular classification algorithms for
promoter detection, including Naive Bayes, K-Nearest Neighbors
(KNN), Logistic Regression, Decision Tree, Random Forest, and SVM
(Support Vector Machine). Based on the training dataset, we evalu-
ated their classification performance with 10-fold cross-validation,
and used the standard binary classification metrics of recall (R), pre-
cision (P), and F1-measure (F1) to measure classification accuracy.
Understanding Promotion-as-a-Service on GitHub
ACSAC ‚Äô20, December 07‚Äì11, 2020, Online
Figure 4: Star distribution over time for a normal repository (top) and a suspiciously promoted repository (bottom).
In this step, ‚ÄúRecall‚Äù refers to the ratio of the amount of correctly
classified promotion accounts over the total amount of real promo-
tion accounts. ‚ÄúPrecision‚Äù is the ratio of the number of correctly
classified promotion accounts to the total number of classified pro-
motion accounts. ‚ÄúF1-measure‚Äù combines precision and recall, and
it is defined in equation 1 as the harmonic mean of precision and
recall. The F1 score reaches its best value at 1 and its worst at 0.
Our classification results are listed in Table 4.
ùêπ1 = 2 √ó (ùëÉ √ó ùëÖ)/(ùëÉ + ùëÖ)
(1)
Among these six different classification algorithms, SVM achieves
the highest classification accuracy, as all three classification metrics
of SVM are higher than those of the other classifiers. Finally, we
applied the SVM-based classifier on the dataset in Section 3.2, and
detected 63,872 suspected promotion accounts.
When we finished modeling the algorithm comparison, we fur-
ther attempted to determine the effectiveness of different features in
Table 3. Therefore, we divided them into three categories according
to their characteristics and evaluated them individually. The first
category is quantitative, including NO14 and NSFE. The second is
proportional category, including RSFA. The third is time-distributed
category, including AAOPM1-3 and AAOPH1. When only the first
category features are included, the accuracy of the classifier is 73.3%.
After adding the second category features, it reaches 83.9%. When
the time distribution type is included, it reaches 98.5% (All these re-
sults are from the SVM classifier). However, if only the proportional
or time-distributed features are included, the accuracy is less than
80%. This shows that all these three types of features are necessary
for the classifier.
3.7 Account Validation
Due to the lack of ground-truth data, it is difficult to validate sus-
pected promotion accounts. In contrast to validating malware or
spam samples, there is no malicious content associated with sus-
pected promotion accounts. Here we verified whether an account
is used for promotion by checking the associated repositories. We
notice when a repository rising in popularity receives many stars
in a short time, it has a long-tail distribution and shrinks slowly.
However, a promoted repository will shrink sharply because pro-
moters tend to complete the promotion tasks as fast as possible
for maximizing their profits. If a repository shows a sharp increase
in the number of stars or forks, followed by a sharp decrease, we
would consider the repository abnormal and the related accounts
suspicious.
To demonstrate these distinct patterns between normal repos-
itories and promoted ones, we plot the time distribution of stars
between a normal repository and a suspicious promoted repository
in Figure 4. The top is the VScode repository published by Microsoft,
which obtained a total of 26,211 stars in 2018. The bottom is related
to a suspicious promoted repository identified by us. We can see
that in the promoted scenario, there are extraordinary star spikes
in August 2018 with 453, 259, and 125 stars. On the right side, we
can see the star cumulative distributions of these two repositories.
The top one linearly increases, while the bottom one has a big jump,
followed by an insignificant increase. This indicates that promoted
repositories usually experience a drastic increase in the number
of stars and forks within a short time period, significantly deviat-
ing from a normal increase pattern. After the drastic increase, the
owner of the promoted repository stopped to use the promotion
service, and then the repository will seldomly receive any stars or
forks from other users.
Based on the feature mentioned above, we randomly sampled
1,000 out of those 63,872 suspected promotion accounts and focused
on the repositories that had been starred or forked. First, we checked
the number variation of the stars or forks of the repositories against
time. Then, we counted the increase of stars and forks per day
and employed the standard deviation of star and fork increments
of the repository per day to determine whether the growth rates
of stars and forks are much larger than normal. Specifically, we
classified those repositories with standard deviations larger than 25
as suspected repositories. Note that we empirically selected a rather
large threshold 25 to lower the false positive rate. Finally, we found
ACSAC ‚Äô20, December 07‚Äì11, 2020, Online
Kun Du, Hao Yang, Yubao Zhang, Haixin Duan, Haining Wang, Shuang Hao, Zhou Li, and Min Yang
Table 5: Organization distribution
Organi-
zation
foss****3
EpicG****
b3***
github-****
NV****
GameW****
co***
gats****
no****
phi****
fashio****
Singapore
United
States
China
Location Member
Count
1,353
2,021
820
507
359
315
336
358
107
85
-
-
-
-
-
-
-
Suspected
Promoter
count
101
98
38
32
26
15
15
14
14
13
of suspected promotion accounts was more than doubled than the
previous year. By 2019, the total number has increased to 37,239.
4.2 Organization Distribution
We further inspected how many suspected promotion accounts
belong to a developer organization. We extracted the organization
information from user profiles. We observed that 4,122 (14.59%) of
suspected promotion accounts have organization information. The
top 10 organizations with the most suspected promotion accounts
are listed in Table 5. From the table, we can see that the first organi-
zation has more than 100 suspected promotion accounts, which has
a total of 1,353 members and is located in Singapore. The second
organization is located in United States and has 2,021 members
with only two repositories. The last commit from this organization
happened in 2017, and there were only 11 commits in total. We
speculate that the organization was closed for business.