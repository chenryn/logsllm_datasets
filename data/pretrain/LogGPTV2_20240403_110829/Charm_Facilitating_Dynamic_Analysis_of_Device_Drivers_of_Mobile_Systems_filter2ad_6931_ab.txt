tages. First, Syzkaller can beneﬁt from other dynamic
analysis techniques only available for virtual machines.
Speciﬁcally, record-and-replay can facilitate the analysis
of the bugs triggered by Syzkaller, as discussed earlier.
Second, it is easier to leverage new kernel sanitizers
of Syzkaller in a virtual machine compared to a mo-
bile system. Kernel sanitizers instrument the kernel at
compile time to allow Syzkaller to ﬁnd non-crash bugs
by monitoring the execution of the kernel. Examples
are KASAN [9], which ﬁnds use-after-free and out-of-
bounds memory bugs, KTSAN [11], which detects data
races, KMSAN [10], which detects the use of uninitial-
ized memory, and KUBSAN [12], which detects unde-
ﬁned behavior. Unfortunately, these sanitizers are not of-
ten supported in the kernel of mobile systems. To the best
of our knowledge, only the Google Pixel smartphone’s
kernel supports KASAN [16].
In contrast, in Charm,
one can simply choose a virtual machine kernel with sup-
port for these sanitizers. For example, we show that we
can easily use KASAN in Charm by simply porting our
drivers to a KASAN-enabled virtual machine kernel.
Finally, Syzkaller can more effectively capture and an-
alyze crash bugs when fuzzing a virtual machine com-
pared to a mobile system. Syzkaller reads the kernel logs
of the operating system through its “console”. It needs
the kernel logs at the moment of the crash to capture the
dump stack. The console of the virtual machine is reli-
ably available by the hypervisor at the time of a crash.
On the other hand, getting the console messages from a
mobile system at the time of the crash is more challeng-
ing and requires a specialized adapter [8], which is not
available to all analysts and is not easy to use. Indeed,
kernel developers are familiar with the difﬁculty of hav-
ing to use a serial cable on a desktop or laptop to get
the last-second console messages from a crashing ker-
nel in order to be able to debug the crash. Getting the
console logs from a crashing mobile system is as chal-
lenging, if not more. When such debugging hardware
is not available, one can try to read the kernel messages
through the Android Debug Bridge (ADB) interface, the
main interface used over USB for communication to An-
droid mobile systems. Unfortunately, the interface can-
not deliver the kernel crash logs since the ADB daemon
on the phone crashes as well. One can attempt to read
the crash logs after the mobile system reboots, but crash
logs are not always available after reboot since a crash
might corrupt the kernel, hindering its ability to ﬂush the
console to storage. These challenges are also conﬁrmed
by the Syzkaller’s developers: “Android Serial Cable or
Suzy-Q device to capture console output is preferable but
optional. Syzkaller can work with normal USB cable as
well, but that can be somewhat unreliable and turn lots of
crashes into lost connection to test machine crashes with
no additional info” [8]. Running the device driver in a
virtual machine signiﬁcantly alleviates this problem.
In our prototype, we use Syzkaller as one of the anal-
ysis tools used on top of Charm. We choose Syzkaller in
order to be able to compare its performance with that of
fuzzing directly on mobile systems. However, note that
Charm can also support a fuzzer such as kAFL, which is
impossible to use directly on a mobile system.
3 Overview
Our goal in this work is to facilitate the application of ex-
isting dynamic analysis techniques to mobile I/O device
drivers.
3.1 Straw-man Approaches
Before describing our solution, we discuss two straw-
man approaches that attempt to run a device driver inside
a virtual machine. The ﬁrst approach is to try to run the
device driver in an existing virtual machine in a worksta-
tion (without the solutions presented by Charm). Unfor-
tunately, this approach does not work out of the box since
the driver requires access to the I/O device hardware in
the mobile system. As a result, at boot time, the driver
will not get initialized by the kernel since the kernel does
not see the I/O device. If forced (e.g., by forcing the call
to initialize the driver), the driver will immediately throw
an error (since it will not be able to interact with the I/O
device hardware), potentially resulting in a kernel panic
in the virtual machine.
In this case, one might wonder whether we can emu-
late the I/O device hardware for the virtual machine in
software. Unfotunately, doing so requires prohibitive en-
gineering effort due to the diversity of I/O devices in mo-
bile systems today.
The second approach is to run the device driver in
a virtual machine in the mobile system and use the di-
rect device assignment technique [21,24,43,53,54] (also
294    27th USENIX Security Symposium
USENIX Association
known as device passthrough) to enable the virtual ma-
chine to access the underlying I/O device. This approach
suffers from two important limitations. First, exist-
ing implementations of direct device assignment mainly
support PCI devices common in x86 workstations, but
not I/O devices of mobile systems. Second, running a
hardware-based virtual machine within commodity mo-
bile systems is impossible. While many mobile systems
today incorporate ARM processor with hardware virtual-
ization support, the hypervisor mode is disabled on these
devices to prevent its use by rootkits. This leaves us with
the option of software-based virtualization, which suffers
from poor performance.
3.2 Charm’s Approach
We present Charm, a system solution to facilitate the
dynamic analysis of device drivers of mobile systems.
Charm decouples the execution of the device driver from
the mobile system hardware. That is, it enables the de-
vice driver to run in a virtual machine on a different phys-
ical machine, i.e., a workstation.
As mentioned earlier, a device driver needs access to
its I/O device for correct execution. Our key idea to
achieve this in Charm is to reuse the physical I/O devices
through remote device driver execution. That is, we con-
nect the physical mobile system directly to the worksta-
tion with a USB cable. The device driver executes fully
in the workstation and only the infrequent low-level I/O
operations are forwarded and executed on the physical
mobile system.
In Charm, the latency of remoting the low-level I/O
operations to the mobile system is of critical importance.
High latency would result in various time-out problems
in the device driver or I/O device. First, device drivers
often wait for a bounded period of time for a response
from the I/O device.
In case the response comes later
than expected, the device driver triggers a time-out error.
Second, the I/O device might require timely reads and
writes to registers. For example, after the device triggers
an interrupt, it might require the driver to clear the inter-
rupt (by writing to a register) in a short period of time. If
not, the device might re-trigger the interrupt, potentially
repeatedly.
In Charm, we leverage an x86 virtual machine in the
workstation to execute the device driver. Given that mo-
bile systems use ARM processors, one might wonder
why we do not use an ARM virtual machine. Indeed, in
our ﬁrst prototype of Charm, we used a QEMU ARM vir-
tual machine with ARM-to-x86 instruction interpretation
on our x86-based workstation and implemented Charm
fully in QEMU. Unfortunately, the overhead of instruc-
tion interpretation slowed the execution down to a point
that our device drivers triggered various time-out errors.
This made us realize that native execution is needed to
meet the device driver’s latency requirements, and hence
we used a hardware-virtualized x86 virtual machine and
reimplemented Charm in KVM.
Note that it is possible to use an ARM workstation in
order to have native ARM execution for the Charm’s vir-
tual machine. However, while x86 workstations are eas-
ily available, ARM workstations are not yet common-
place. Therefore, we did not adopt this approach since
we want Charm to be available to security analysts im-
mediately.
3.3 Potential Concerns
There are two potential concerns with Charm’s design.
Fortunately, as we will report in our evaluation, we have
managed to show that Charm overcomes both concerns.
The ﬁrst concern is potentially poor performance. Re-
moting I/O operations can signiﬁcantly slow down the
execution of the device driver. This can result in in-
correct behavior due to time-outs. Even if there are no
time-outs, it can slow down the dynamic analysis’ exe-
cution, e.g., fuzzing time. In this paper, we show that
by leveraging native execution of an x86 processor and
a customized low-latency USB channel, we can not only
eliminate time-outs but also achieve performance on par
with the execution of the analysis running directly on the
mobile system.
The second concern is that the disparity between the
ARM Instruction Set Architecture (ISA) used in mobile
systems vs. the x86 ISA used in the virtual machine may
result in incorrect device driver behavior, which can af-
fect the analysis, e.g., false positives in bugs detected by
a fuzzer. Fortunately, as we will show, that is not the
case. For example, we have not yet encountered a con-
ﬁrmed false positive bug detected by Charm. Moreover,
we have veriﬁed that several Proof-of-Concept codes
(PoC’s) publicly reported for a device driver are also
effective in Charm. The reason behind this is that de-
vice drivers are written almost fully in C and they suffer
from bugs in the source code, which are effective regard-
less of the ISA that they are compiled to. We do, how-
ever, note that “compiler bugs”, e.g., undeﬁned behavior
bugs [70], can show different behavior in the mobile sys-
tem vs. Charm. This is because a compiler bug present
in a C x86 compiler might not be present in a C ARM
compiler, and vice versa. Therefore, Charm might result
in false compiler bug reports (although we have not yet
come across one) . However, note that bugs due to un-
deﬁned behavior are not necessarily false positives since
they happen due to the driver code wrongly relying on
an undeﬁned behavior of the language. Finally, Charm
might result in false negatives for ARM compiler bugs
as well.
USENIX Association
27th USENIX Security Symposium    295
(a)
(b)
Figure 2: (a) Device driver execution in a mobile system. (b) Remote device driver execution in Charm.
4 Remote Device Driver Execution
The key enabling technique in Charm is the remote exe-
cution of mobile I/O device drivers. In this technique, we
run the device driver in a virtual machine in the worksta-
tion. We then intercept the low-level interactions of the
driver with the hardware interface of the I/O device and
route them to the actual mobile system through a USB
channel. Similarly, interrupts from the I/O device in the
mobile system are routed to the device driver in the vir-
tual machine. Figure 2 illustrates this technique. We will
next elaborate on the solution’s details.
4.1 Device and Device Driver Interactions
The remote device driver technique requires us to ex-
ecute the device driver in a different physical machine
from the one hosting the I/O device. At ﬁrst glance, this
sounds like an impossible task. The device driver inter-
acts very closely with the underlying hardware in the mo-
bile system. Therefore, this raises the question: is remote
execution of a device driver even possible? We answer
this question positively in this paper. To achieve this, a
stub module in the workstation’s hypervisor communi-
cates with a stub module in the mobile system to support
the device driver’s interactions with its hardware. These
interactions are three-fold: accesses to the registers of
the I/O device, interrupts, and Direct Memory Access
(DMA). Charm currently supports the ﬁrst two. We will
demonstrate that these two are enough to port and exe-
cute many device drivers remotely. In §8, we will discuss
how we plan to support DMA in the future.
Register accesses. Using the hypervisor in the work-
station, we intercept the accesses of the device driver to
its registers. Upon a register write, we forward the value
to be written to the stub in the mobile system. Upon a
register read, we send a read request to the stub module,
receive the response, and return it to the device driver in
the virtual machine.
Interrupts. The stub module in the mobile system
registers an interrupt handler on behalf of the remote
driver. Whenever the corresponding I/O device in the
mobile system triggers an interrupt, the mobile stub for-
wards the interrupt to the stub in the workstation, which
then injects it into the virtual machine for the device
driver to handle.
4.2 Device Driver Initialization
For the device driver to get initialized in the kernel of
the virtual machine, the kernel must detect the corre-
sponding I/O device in the system. Therefore, for a re-
mote device driver to get initialized in the virtual ma-
chine, we must enable the kernel of the virtual machine
to “detect” the corresponding I/O device as being con-
nected to the virtual machine. ARM and x86 machines
use different approach for I/O device detection.
In an
ARM machine, a device tree is used, which is a software
manifest containing the list of hardware components in
the system.
In this machine, the kernel parses the de-
vice tree at boot time and initializes the corresponding
device drivers. In an x86 machine, hardware detection
is mainly used through the Advanced Conﬁguration and
Power Interface (ACPI). In an x86 virtual machine, the
ACPI interface is emulated by the hypervisor.
The ﬁrst solution that we considered was to add a
remote I/O device to the hypervisor’s ACPI emulation
layer so that the virtual machine kernel can detect it.
However, this solution would require signiﬁcant engi-
neering effort to translate the device tree entries into
ACPI devices. Therefore, we take a different approach.
We have the x86 kernel parse and use device trees as
well. That is, we ﬁrst allow the kernel to ﬁnish its ACPI-
based device detection. After that, the kernel parses the
296    27th USENIX Security Symposium
USENIX Association
I/O deviceUser spaceKernelDevice driver(including the bus driver, when applicable)Mobile systemResident modules: Power mgr., clock mgr., pin control, etc.OSResident hardwareUSB channelUser spaceKernelUser spaceKernelDevice driver(including the bus driver, when applicable)WorkstationMobile systemStubHypervisorVirtual machine OSOSI/O deviceResident modules: Power mgr., clock mgr., pin control, etc.Resident hardwareStubdevice tree to detect the remote I/O devices. This signiﬁ-
cantly reduces the engineering effort. To support the ini-
tialization of a new device driver, we only need to copy
the device tree entries corresponding to the I/O device of
interest from the device tree of the mobile system to that
of the virtual machine.
4.3 Low-Latency USB Channel
We use USB for connecting the mobile system to the
workstation as USB is the most commonly used connec-
tion for mobile systems. USB provides adequate band-
width for our use cases. For example, the USB 3.0 stan-
dard (used in modern mobile systems) can handle up to
5 Gbps.
In Charm, in addition to bandwidth, the latency of the
channel between the workstation and the mobile system
is of utmost importance. High latency can result in time-
out problems in both the I/O device and the device driver.
In our initial prototypes of Charm, we experienced vari-
ous time-out problems in the device driver and I/O device
due to high latency of our initial channel implementa-
tion. In this prototype, we used a TCP-based socket over
the ADB interface. However, our measurements showed
that this connection introduces a large delay (about one
to two milliseconds for a round trip). This latency is due
to several user space/kernel crossings both in the virtual
machine and mobile system. To address this problem,
we implement a low-level and customized USB chan-
nel for Charm. In this channel, we create a USB gad-
get interface [13] for Charm and attach ﬁve endpoints to
this interface. Two endpoints are used for bidirectional
communication for register accesses. Two endpoints are
used for bidirectional communication for RPC calls (ex-
plained in §4.4). And the last endpoint is used for uni-
directional communication for interrupts (from the mo-
bile system to the workstation). Both in the mobile sys-
tem and in the workstation, our stub modules read and
write to these endpoints directly in the kernel (the host
operating system kernel in the case of the workstation)
hence avoiding costly user/kernel crossings. Therefore,
this channel eliminates all user space/kernel crossings,
signiﬁcantly reducing the latency.
To further minimize the latency of communication
over this channel, we perform an optimization: write
batching. That is, we batch consecutive register writes
by simply sending the write request over the USB chan-
nel and receiving the acknowledgment asynchronously,