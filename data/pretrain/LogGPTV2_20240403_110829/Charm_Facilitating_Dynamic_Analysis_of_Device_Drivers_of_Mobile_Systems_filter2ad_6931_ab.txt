### Benefits of Using Syzkaller with Virtual Machines

First, Syzkaller can benefit from other dynamic analysis techniques that are only available for virtual machines. Specifically, record-and-replay can facilitate the analysis of bugs triggered by Syzkaller, as discussed earlier.

Second, it is easier to leverage new kernel sanitizers in a virtual machine compared to a mobile system. Kernel sanitizers instrument the kernel at compile time, allowing Syzkaller to find non-crash bugs by monitoring the execution of the kernel. Examples include KASAN [9], which detects use-after-free and out-of-bounds memory bugs; KTSAN [11], which identifies data races; KMSAN [10], which finds the use of uninitialized memory; and KUBSAN [12], which detects undefined behavior. Unfortunately, these sanitizers are not often supported in the kernels of mobile systems. To the best of our knowledge, only the Google Pixel smartphone's kernel supports KASAN [16]. In contrast, in Charm, one can simply choose a virtual machine kernel with support for these sanitizers. For example, we demonstrate that KASAN can be easily used in Charm by porting our drivers to a KASAN-enabled virtual machine kernel.

Finally, Syzkaller can more effectively capture and analyze crash bugs when fuzzing a virtual machine compared to a mobile system. Syzkaller reads the kernel logs of the operating system through its "console." It needs the kernel logs at the moment of the crash to capture the dump stack. The console of the virtual machine is reliably available via the hypervisor at the time of a crash. On the other hand, obtaining console messages from a mobile system at the time of a crash is more challenging and requires specialized hardware [8], which is not always available or easy to use. Kernel developers are familiar with the difficulty of using a serial cable on a desktop or laptop to get the last-second console messages from a crashing kernel to debug the crash. Obtaining console logs from a crashing mobile system is equally, if not more, challenging. When such debugging hardware is unavailable, one can try to read the kernel messages through the Android Debug Bridge (ADB) interface, the main USB-based communication interface for Android mobile systems. However, the ADB daemon on the phone may also crash, preventing the delivery of kernel crash logs. Attempting to read the crash logs after the mobile system reboots is also unreliable, as a crash might corrupt the kernel, hindering its ability to flush the console to storage. These challenges are confirmed by Syzkaller’s developers: “An Android Serial Cable or Suzy-Q device to capture console output is preferable but optional. Syzkaller can work with a normal USB cable as well, but that can be somewhat unreliable and turn many crashes into lost connection to test machine crashes with no additional info” [8]. Running the device driver in a virtual machine significantly alleviates this problem.

In our prototype, we use Syzkaller as one of the analysis tools on top of Charm. We chose Syzkaller to compare its performance with fuzzing directly on mobile systems. However, note that Charm can also support fuzzers like kAFL, which cannot be used directly on a mobile system.

### Overview

Our goal in this work is to facilitate the application of existing dynamic analysis techniques to mobile I/O device drivers.

#### Straw-man Approaches

Before describing our solution, we discuss two straw-man approaches that attempt to run a device driver inside a virtual machine. The first approach is to try to run the device driver in an existing virtual machine on a workstation (without the solutions presented by Charm). Unfortunately, this approach does not work out of the box because the driver requires access to the I/O device hardware in the mobile system. As a result, the driver will not be initialized by the kernel at boot time since the kernel does not see the I/O device. If forced (e.g., by forcing the call to initialize the driver), the driver will immediately throw an error, potentially resulting in a kernel panic in the virtual machine.

One might wonder whether we can emulate the I/O device hardware for the virtual machine in software. Unfortunately, this requires prohibitive engineering effort due to the diversity of I/O devices in mobile systems today.

The second approach is to run the device driver in a virtual machine on the mobile system and use direct device assignment [21, 24, 43, 53, 54] (also known as device passthrough) to enable the virtual machine to access the underlying I/O device. This approach suffers from two important limitations. First, existing implementations of direct device assignment mainly support PCI devices common in x86 workstations, but not I/O devices of mobile systems. Second, running a hardware-based virtual machine within commodity mobile systems is impossible. While many mobile systems today incorporate ARM processors with hardware virtualization support, the hypervisor mode is disabled on these devices to prevent its use by rootkits. This leaves us with the option of software-based virtualization, which suffers from poor performance.

#### Charm’s Approach

We present Charm, a system solution to facilitate the dynamic analysis of device drivers of mobile systems. Charm decouples the execution of the device driver from the mobile system hardware, enabling the device driver to run in a virtual machine on a different physical machine, i.e., a workstation.

As mentioned earlier, a device driver needs access to its I/O device for correct execution. Our key idea in Charm is to reuse the physical I/O devices through remote device driver execution. We connect the physical mobile system directly to the workstation with a USB cable. The device driver executes fully in the workstation, and only infrequent low-level I/O operations are forwarded and executed on the physical mobile system.

In Charm, the latency of remoting low-level I/O operations to the mobile system is critical. High latency would result in various timeout problems in the device driver or I/O device. Device drivers often wait for a bounded period for a response from the I/O device. If the response comes later than expected, the device driver triggers a timeout error. Additionally, the I/O device might require timely reads and writes to registers. For example, after the device triggers an interrupt, it might require the driver to clear the interrupt (by writing to a register) in a short period. If not, the device might re-trigger the interrupt, potentially repeatedly.

In Charm, we leverage an x86 virtual machine in the workstation to execute the device driver. Given that mobile systems use ARM processors, one might wonder why we do not use an ARM virtual machine. Indeed, in our first prototype of Charm, we used a QEMU ARM virtual machine with ARM-to-x86 instruction interpretation on our x86-based workstation and implemented Charm fully in QEMU. Unfortunately, the overhead of instruction interpretation slowed the execution, causing various timeout errors. This made us realize that native execution is needed to meet the device driver’s latency requirements, and hence we used a hardware-virtualized x86 virtual machine and reimplemented Charm in KVM.

Note that it is possible to use an ARM workstation to have native ARM execution for the Charm’s virtual machine. However, while x86 workstations are easily available, ARM workstations are not yet commonplace. Therefore, we did not adopt this approach since we want Charm to be available to security analysts immediately.

#### Potential Concerns

There are two potential concerns with Charm’s design. Fortunately, as we will report in our evaluation, we have managed to show that Charm overcomes both concerns.

The first concern is potentially poor performance. Remoting I/O operations can significantly slow down the execution of the device driver, leading to incorrect behavior due to timeouts. Even if there are no timeouts, it can slow down the dynamic analysis, e.g., fuzzing time. In this paper, we show that by leveraging native execution of an x86 processor and a customized low-latency USB channel, we can not only eliminate timeouts but also achieve performance on par with the execution of the analysis running directly on the mobile system.

The second concern is that the disparity between the ARM Instruction Set Architecture (ISA) used in mobile systems and the x86 ISA used in the virtual machine may result in incorrect device driver behavior, affecting the analysis, e.g., false positives in bugs detected by a fuzzer. Fortunately, as we will show, this is not the case. For example, we have not encountered a confirmed false positive bug detected by Charm. Moreover, we have verified that several Proof-of-Concept codes (PoCs) publicly reported for a device driver are also effective in Charm. The reason behind this is that device drivers are written almost entirely in C and suffer from bugs in the source code, which are effective regardless of the ISA they are compiled to. We do, however, note that "compiler bugs," e.g., undefined behavior bugs [70], can show different behavior in the mobile system vs. Charm. This is because a compiler bug present in a C x86 compiler might not be present in a C ARM compiler, and vice versa. Therefore, Charm might result in false compiler bug reports (although we have not yet come across one). However, note that bugs due to undefined behavior are not necessarily false positives since they happen due to the driver code wrongly relying on an undefined behavior of the language. Finally, Charm might result in false negatives for ARM compiler bugs as well.

### Remote Device Driver Execution

The key enabling technique in Charm is the remote execution of mobile I/O device drivers. In this technique, we run the device driver in a virtual machine in the workstation. We then intercept the low-level interactions of the driver with the hardware interface of the I/O device and route them to the actual mobile system through a USB channel. Similarly, interrupts from the I/O device in the mobile system are routed to the device driver in the virtual machine. Figure 2 illustrates this technique. We will next elaborate on the solution’s details.

#### Device and Device Driver Interactions

The remote device driver technique requires us to execute the device driver in a different physical machine from the one hosting the I/O device. At first glance, this sounds like an impossible task. The device driver interacts very closely with the underlying hardware in the mobile system. Therefore, this raises the question: is remote execution of a device driver even possible? We answer this question positively in this paper. To achieve this, a stub module in the workstation’s hypervisor communicates with a stub module in the mobile system to support the device driver’s interactions with its hardware. These interactions are three-fold: accesses to the registers of the I/O device, interrupts, and Direct Memory Access (DMA). Charm currently supports the first two. We will demonstrate that these two are enough to port and execute many device drivers remotely. In §8, we will discuss how we plan to support DMA in the future.

**Register accesses.** Using the hypervisor in the workstation, we intercept the accesses of the device driver to its registers. Upon a register write, we forward the value to be written to the stub in the mobile system. Upon a register read, we send a read request to the stub module, receive the response, and return it to the device driver in the virtual machine.

**Interrupts.** The stub module in the mobile system registers an interrupt handler on behalf of the remote driver. Whenever the corresponding I/O device in the mobile system triggers an interrupt, the mobile stub forwards the interrupt to the stub in the workstation, which then injects it into the virtual machine for the device driver to handle.

#### Device Driver Initialization

For the device driver to get initialized in the kernel of the virtual machine, the kernel must detect the corresponding I/O device in the system. Therefore, for a remote device driver to get initialized in the virtual machine, we must enable the kernel of the virtual machine to "detect" the corresponding I/O device as being connected to the virtual machine. ARM and x86 machines use different approaches for I/O device detection. In an ARM machine, a device tree is used, which is a software manifest containing the list of hardware components in the system. In this machine, the kernel parses the device tree at boot time and initializes the corresponding device drivers. In an x86 machine, hardware detection is mainly used through the Advanced Configuration and Power Interface (ACPI). In an x86 virtual machine, the ACPI interface is emulated by the hypervisor.

The first solution we considered was to add a remote I/O device to the hypervisor’s ACPI emulation layer so that the virtual machine kernel can detect it. However, this solution would require significant engineering effort to translate the device tree entries into ACPI devices. Therefore, we take a different approach. We allow the x86 kernel to parse and use device trees as well. That is, we first allow the kernel to finish its ACPI-based device detection. After that, the kernel parses the device tree to detect the remote I/O devices. This significantly reduces the engineering effort. To support the initialization of a new device driver, we only need to copy the device tree entries corresponding to the I/O device of interest from the device tree of the mobile system to that of the virtual machine.

#### Low-Latency USB Channel

We use USB for connecting the mobile system to the workstation, as USB is the most commonly used connection for mobile systems. USB provides adequate bandwidth for our use cases. For example, the USB 3.0 standard (used in modern mobile systems) can handle up to 5 Gbps.

In Charm, in addition to bandwidth, the latency of the channel between the workstation and the mobile system is of utmost importance. High latency can result in timeout problems in both the I/O device and the device driver. In our initial prototypes of Charm, we experienced various timeout problems in the device driver and I/O device due to high latency of our initial channel implementation. In this prototype, we used a TCP-based socket over the ADB interface. However, our measurements showed that this connection introduces a large delay (about one to two milliseconds for a round trip). This latency is due to several user space/kernel crossings both in the virtual machine and mobile system. To address this problem, we implement a low-level and customized USB channel for Charm. In this channel, we create a USB gadget interface [13] for Charm and attach five endpoints to this interface. Two endpoints are used for bidirectional communication for register accesses. Two endpoints are used for bidirectional communication for RPC calls (explained in §4.4). And the last endpoint is used for unidirectional communication for interrupts (from the mobile system to the workstation). Both in the mobile system and in the workstation, our stub modules read and write to these endpoints directly in the kernel (the host operating system kernel in the case of the workstation), thus avoiding costly user/kernel crossings. Therefore, this channel eliminates all user space/kernel crossings, significantly reducing the latency.

To further minimize the latency of communication over this channel, we perform an optimization: write batching. That is, we batch consecutive register writes by simply sending the write request over the USB channel and receiving the acknowledgment asynchronously.