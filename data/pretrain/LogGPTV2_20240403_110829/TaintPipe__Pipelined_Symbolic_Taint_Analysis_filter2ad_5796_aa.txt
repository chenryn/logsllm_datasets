title:TaintPipe: Pipelined Symbolic Taint Analysis
author:Jiang Ming and
Dinghao Wu and
Gaoyao Xiao and
Jun Wang and
Peng Liu
TaintPipe: Pipelined Symbolic Taint Analysis
Jiang Ming, Dinghao Wu, Gaoyao Xiao, Jun Wang, and Peng Liu,  
The Pennsylvania State University
https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/ming
This paper is included in the Proceedings of the 24th USENIX Security SymposiumAugust 12–14, 2015 • Washington, D.C.ISBN 978-1-939133-11-3Open access to the Proceedings of  the 24th USENIX Security Symposium is sponsored by USENIXTaintPipe: Pipelined Symbolic Taint Analysis
Jiang Ming, Dinghao Wu, Gaoyao Xiao, Jun Wang, and Peng Liu
College of Information Sciences and Technology
The Pennsylvania State University
{jum310, dwu, gzx102, jow5222, pliu}@ist.psu.edu
Abstract
Taint analysis has a wide variety of compelling applica-
tions in security tasks, from software attack detection to
data lifetime analysis. Static taint analysis propagates
taint values following all possible paths with no need
for concrete execution, but is generally less accurate than
dynamic analysis. Unfortunately, the high performance
penalty incurred by dynamic taint analyses makes its de-
ployment impractical in production systems. To amelio-
rate this performance bottleneck, recent research efforts
aim to decouple data ﬂow tracking logic from program
execution. We continue this line of research in this paper
and propose pipelined symbolic taint analysis, a novel
technique for parallelizing and pipelining taint analy-
sis to take advantage of ubiquitous multi-core platforms.
We have developed a prototype system called TaintPipe.
TaintPipe performs very lightweight runtime logging to
produce compact control ﬂow proﬁles, and spawns mul-
tiple threads as different stages of a pipeline to carry
out symbolic taint analysis in parallel. Our experiments
show that TaintPipe imposes low overhead on applica-
tion runtime performance and accelerates taint analysis
signiﬁcantly. Compared to a state-of-the-art inlined dy-
namic data ﬂow tracking tool, TaintPipe achieves 2.38
times speedup for taint analysis on SPEC 2006 and 2.43
times for a set of common utilities, respectively. In ad-
dition, we demonstrate the strength of TaintPipe such as
natural support of multi-tag taint analysis with several
security applications.
1
Introduction
Taint analysis is a kind of program analysis that tracks
some selected data of interest (taint seeds), e.g., data
originated from untrusted sources, propagates them
along program execution paths according to a cus-
tomized policy (taint propagation policy), and then
checks the taint status at certain critical location (taint
sinks).
It has been shown to be effective in dealing
with a wide range of security problems, including soft-
ware attack prevention [25, 40], information ﬂow control
[45, 34], data leak detection [49], and malware analy-
sis [43], to name a few.
Static taint analysis [1, 36, 28] (STA) is performed
prior to execution and therefore it has no impact on run-
time performance. STA has the advantage of consider-
ing multiple execution paths, but at the cost of poten-
tial imprecision. For example, STA may result in either
under-tainting or over-tainting [32] when merging results
at control ﬂow conﬂuence points. Dynamic taint analysis
(DTA) [25, 13, 27], in contrast, propagates taint as a pro-
gram executes, which is more accurate than static taint
analysis since it only considers the actual path taken at
run time. However, the high runtime overhead imposed
by dynamic taint propagation has severely limited its
adoption in production systems. The slowdown incurred
by conventional dynamic taint analysis tools [25, 13] can
easily go beyond 30X times. Even with the state-of-the-
art DTA tool based on Pin [20], typically it still intro-
duces more than 6X slowdown.
The crux of the performance penalty comes from
the strict coupling of program execution and data ﬂow
tracking logic. The original program instructions min-
gle with the taint tracking instructions, and usually it
takes 6–8 extra instructions to propagate a taint tag in
shadow memory [11].
In addition, the frequent “con-
text switches” between the original program execution
and its corresponding taint propagation lead to register
spilling and data cache pollution, which add further pres-
sure to runtime performance. The proliferation of multi-
core systems has inspired researchers to decouple taint
tracking logic onto spare cores in order to improve per-
formance [24, 31, 26, 15, 17, 9]. Previous work can
be classiﬁed into two categories. The ﬁrst category is
hardware-assisted approaches. For example, Speck [26]
needs OS level support for speculative execution and
rollback. Ruwase et al. [31] employ a customized hard-
USENIX Association  
24th USENIX Security Symposium  65
ware for logging a program trace and delivering it to
other idle cores for inspection. Nagarajan et al. [24] uti-
lize a hardware ﬁrst-in ﬁrst-out buffer to speed up com-
munication between cores. Although they can achieve an
appealing performance, the requirement of special hard-
ware prevents them from being adopted using commod-
ity hardware.
The second category is software-only methods that
work with binary executables on commodity multi-core
hardware [15, 17, 9]. These software-only solutions rely
on dynamic binary instrumentation (DBI) to decouple
dynamic taint analysis from program execution. The pro-
gram execution and parallelized taint analysis have to
be properly synchronized to transfer the runtime values
that are necessary for taint analysis. Although these ap-
proaches look promising, they fail to achieve expected
performance gains due to the large amounts of commu-
nication data and frequent synchronizations between the
original program execution thread (or process) and its
corresponding taint analysis thread (or process). Recent
work ShadowReplica [17] creates a secondary shadow
thread from primary application thread to run DTA in
parallel. ShadowReplica conducts an ofﬂine optimiza-
tion to generate optimized DTA logic code, which re-
duces the amount of information that needs to be com-
municated, and thus dramatically improves the perfor-
mance. However, as we will show later, the performance
improvement achieved by this “primary & secondary”
thread model is ﬁxed and cannot be improved further
when more cores are available. Furthermore, in many se-
curity related tasks (e.g., binary de-obfuscation and mal-
ware analysis), precise static analysis for the ofﬂine opti-
mization needed by ShadowReplica may not be feasible.
In this paper, we exploit another style of parallelism,
namely pipelining. We propose a novel technique, called
TaintPipe, for parallel data ﬂow tracking using pipelined
symbolic taint analysis.
In principle, TaintPipe falls
within the second category of taint decoupling work clas-
siﬁed above. Essentially, in TaintPipe, threads form mul-
tiple pipeline stages, working in parallel. The execution
thread of an instrumented application acts as the source
of pipeline, which records information needed for taint
pipelining, including the control ﬂow data and the con-
crete execution states when the taint seeds are ﬁrst intro-
duced. To further reduce the online logging overhead, we
adopt a compact proﬁle format and an N-way buffering
thread pool. The application thread continues executing
and ﬁlling in free buffers, while multiple worker threads
consume full buffers asynchronously. When each logged
data buffer becomes full, an inlined call-back function
will be invoked to initialize a taint analysis engine, which
conducts taint analysis on a segment of straight-line code
concurrently with other worker threads. Symbolic mem-
ory access addresses are determined by resolving indirect
control transfer targets and approximating the ranges of
the symbolic memory indices.
To overcome the challenge of propagating taint tags
in a segment without knowing the incoming taint state,
TaintPipe performs segmented symbolic taint analysis.
That is, the taint analysis engine assigned to each seg-
ment calculates taint states symbolically. When a con-
crete taint state arrives, TaintPipe then updates the re-
lated taint states by replacing the relevant symbolic taint
tags with their correct values. We call this symbolic
taint state resolution. According to the segment order,
TaintPipe sequentially computes the ﬁnal taint state for
every segment, communicates to the next segment, and
performs the actual taint checks. Optimizations such as
function summary and taint basic block cache offer en-
hanced performance improvements. Moreover, differ-
ent from previous DTA tools, supporting bit-level and
multi-tag taint analysis are straightforward for TaintPipe.
TaintPipe does not require redesign of the structure of
shadow memory; instead, each taint tag can be naturally
represented as a symbolic variable and propagated with
negligible additional overhead.
We have developed a prototype of TaintPipe, a
pipelined taint analysis tool that decouples program ex-
ecution and taint logic, and parallelizes taint analysis on
straight-line code segments. Our implementation is built
on top of Pin [23], for the pipelining framework, and
BAP [5], for symbolic taint analysis. We have evalu-
ated TaintPipe with a variety of applications such as the
SPEC CINT2006 benchmarks, a set of common utilities,
a list of recent real-life software vulnerabilities, malware,
and cryptography functions. The experiments show that
TaintPipe imposes low overhead on application runtime
performance. Compared with a state-of-the-art inlined
dynamic taint analysis tool, TaintPipe achieves overall
2.38 times speedup on SPEC CINT2006, and 2.43 times
on a set of common utility programs, respectively. The
efﬁcacy experiments indicate that TaintPipe is effective
in detecting a wide range of real-life software vulnera-
bilities, analyzing malicious programs, and speeding up
cryptography function detection with multi-tag propa-
gation. Such experimental evidence demonstrates that
TaintPipe has potential to be employed by various appli-
cations in production systems. The contributions of this
paper are summarized as follows:
• We propose a novel approach, TaintPipe, to efﬁ-
ciently decouple conventional inlined dynamic taint
analysis by pipelining symbolic taint analysis on
segments of straight-line code.
• Unlike previous taint decoupling work, which suf-
fers from frequent communication and synchroniza-
tion, we demonstrate that with very lightweight run-
time value logging, TaintPipe rivals conventional in-
lined dynamic taint analysis in precision.
66  24th USENIX Security Symposium 
USENIX Association
• Our approach does not require any speciﬁc hard-
ware support or ofﬂine preprocessing, so TaintPipe
is able to work on commodity hardware instantly.
• TaintPipe is naturally a multi-tag taint analysis
method. We demonstrate this capability by detect-
ing cryptography functions in binary with little ad-
ditional overhead.
The remainder of the paper is organized as fol-
lows. Section 2 provides background information and an
overview of our approach. Section 3 and Section 4 de-
scribe the details of the system design, online logging,
and pipelined segmented symbolic taint analysis. We
present the evaluation and application of our approach
in Section 5. We discuss a few limitations in Section 6.
We then present related work in Section 7 and conclude
our paper in Section 8.
2 Background
In this section, we discuss the background and context
information of the problem that TaintPipe seeks to solve.
We start by comparing TaintPipe with the conventional
inlined taint analysis approaches, and we then present
the differences between the previous “primary & sec-
ondary” taint decoupling model and the pipelined decou-
pling style in TaintPipe.
Inlined Analysis vs. TaintPipe
2.1
Figure 1 (“Inlined DTA”) illustrates a typical dynamic
taint analysis mechanism based on dynamic binary in-
strumentation (DBI), in which the original program code
and taint tracking logic code are tightly coupled. Es-
pecially, when dynamic taint analysis runs on the same
core, they compete for the CPU cycles, registers, and
cache space, leading to signiﬁcant performance slow-
down.
For example, “context switch” happens fre-
quently between the original program instructions and
taint tracking instructions due to the starvation of CPU
registers. This means there will be a couple of instruc-
tions, mostly inserted per program instruction, to save
and restore those register values to and from memory.
At the same time, taint tracking instructions themselves
(e.g., shadow memory mapping) are already complicated
enough. One taint shadow memory lookup operation
normally needs 6–8 extra instructions [11].
Our approach, analogous to the hardware pipelin-
ing, decouples taint logic code to multiple spare cores.
Figure 1 (“TaintPipe”) depicts TaintPipe’s framework,
which consists of two concurrently running parts: 1) the
instrumented application thread performing lightweight
online logging and acting as the source of the pipeline;
2) multiple worker threads as different stages of the
pipeline to perform symbolic taint analysis. Each hor-
izontal bar with gray color indicates a working thread.
We start online logging when the predeﬁned taint seeds
are introduced to the application. The collected proﬁle
is passed to a worker thread. Each worker thread con-
structs a straight-line code segment and then performs
taint analysis in parallel. In principle, fully parallelizing
dynamic taint analysis is challenging because there are
strong serial data dependencies between the taint logic
code and application code [31]. To address this prob-
lem, we propose segmented symbolic taint analysis in-
side each worker thread whenever the explicit taint in-
formation is not available, in which the taint state is sym-
bolically calculated. The symbolic taint state will be up-
dated later when the concrete data arrive. In addition to
the control ﬂow proﬁle, the explicit execution state when
the taint seeds are introduced is recorded as well. The
purpose is to reduce the number of fresh symbolic taint
variables.
We use a motivating example to introduce the idea
of segmented symbolic taint analysis. Figure 2 shows
an example for symbolic taint analysis on a straight-
line code segment, which is a simpliﬁed code snippet of
the libtiff buffer overﬂow vulnerability (CVE-2013-
4231). Assume when a worker thread starts taint anal-
ysis on this code segment (Figure 2(a)), no taint state
for the input data (“size” and “num” in our case) is de-
ﬁned. Instead of waiting for the explicit information, we
treat the unknown values as taint symbols (symbol1 for
“size” and symbol2 for “num”, respectively) and sum-
marize the net effect of taint propagation in the segment.
The symbolic taint states are shown in Figure 2(b). When
the explicit taint states are available, we resolve the sym-
bolic taint states by replacing the taint symbols with their
real taint tags or concrete values (Figure 2(c)). After that,
we continue to perform concrete taint analysis like con-
ventional DTA. Note that here we show pseudo-code for
ease of understanding, while TaintPipe works on binary
code.
Compared with inlined DTA, the application thread
under TaintPipe is mainly instrumented with control ﬂow
proﬁle logging code, which is quite lightweight. There-
fore, TaintPipe results in much lower application runtime
overhead. On the other hand, the execution of taint logic
code is decoupled to multiple pipeline stages running in
parallel. The accumulated effect of TaintPipe’s pipeline
leads to a substantial speedup on taint analysis.
“Primary & Secondary” Model
2.2
Some recent work [15, 17, 9] ofﬂoads taint logic code
from the application (primary) thread to another shadow
(secondary) thread and runs them on separate cores. At
the same time, the primary thread communicates with
USENIX Association  
24th USENIX Security Symposium  67
Inlined DTA
TaintPipe
Taint seeds  & 
 execution state
Threads
Time
Application speedup
Taint speedup
Application
DBI
Control flow 
profiling
Concrete taint 
analysis
Symbolic taint 
analysis
Resolving symbolic 
taint state
Figure 1: Inlined dynamic taint analysis vs. TaintPipe.
Output
Taint state
Output
Taint state
size = getc(infile); 
A = -1;
B = size + 1;
C = (1 << size) - 1;
D = num & C;
A 
B 
C 
D 
0
symbol1 + 1
(1 << symbol1) – 1
symbol2 & ((1 << symbol1) – 1)
A 
B 
C 
D 
0
tag1 + 1
(1 << tag1) – 1
 (1 << tag1) – 1
(a) Code segment
(b) Symbolic taint state
(c) Resolving symbolic taint state
Figure 2: An example of symbolic taint analysis on a code segment: (a) code segment; (b) symbolic taint states, the
input value size and num are labeled as symbol1 and symbol2, respectively; (c) resolving symbolic taint states when
size is tainted as tag1 and num is a constant value (num = 0xffffffff).
the secondary thread to convey the necessary informa-
tion (e.g., the addresses of memory operations and con-
trol transfer targets) for performing taint analysis. How-
ever, this model suffers from frequent communication
between the primary and secondary thread. In principle,
every memory address that is loaded or stored has to be
logged and transferred. Due to the frequent synchroniza-
tion with the primary thread and the extra instructions
to access shadow memory, taint logic execution in the
secondary thread is typically slower than the application
execution. As a result, the delay for each taint operation
could be accumulated, leading to an delay proportional
to the original execution. ShadowReplica [17] partially
addresses this drawback by performing advanced ofﬂine
static optimizations on the taint logic code to reduce the
runtime overhead. However, in many security analysis
scenarios, precise static analysis and optimizations over
taint logic code are not feasible, e.g., reverse engineer-
ing and malware forensics. In such cases, program static
features such as control ﬂow graphs are possibly obfus-
cated.
In TaintPipe, we record compact control ﬂow infor-
mation to reconstruct straight-line code, in which all the
targets of direct and indirect jumps have been resolved.
However, we do not record or transfer the addresses of
memory operations. Our key observation is that most
addresses of memory operations can be inferred from
the straight-line code. For example, if a basic block is
ended with an indirect jump instruction jmp eax, we
can quickly know the value of eax from the straight-line
code. In this way, all the other memory indirect access
calculated through eax (before it is updated) can be de-
termined. For instance, we can infer the memory load
address for the instruction: mov ebx, [4*eax + 16].
Even when the index of a memory lookup is a symbol,
with the taint states and path predicates of the straight-
line code, we can often narrow down the symbolic mem-
ory addresses to a small range in most cases.