variable nodes in Fig. 3(c), updating the beliefs on the val-
ues of the targeted SNPs (in XU) at each iteration, until
convergence. We denote the variable and factor nodes x1
1,
f 3
1 , and g1
The variable nodes generate their messages (µ) and send
(ν)) by
to their neighbors. Variable node i forms µ(ν)
multiplying all information it receives from its neighbors ex-
cluding the familial factor node k.3 Hence, the message from
variable node i to the familial factor node k at the νth iter-
ation is given by
1,2 with the letters i, k, and z, respectively.
i→k(x1
1
µ(ν)
i→k(x1
1
(ν)
) =
1
Z
λ(ν−1)
w→i (x1
1
(ν−1)
β(ν−1)
y→i (x1
1
×(cid:89)
w∈(∼k)
)× (cid:89)
y∈{z,g1
1,3}
(ν−1)
),
(3)
3The message µ(ν)
tor node z is constructed similarly.
i→z(x1
1
(ν)) from the variable node i LD fac-
F(2)C(3)M(1)(c)Set of family members: Mother (M), Father (F) and Child (C). We represent M as 1, F as 2, and C as 3.Set of SNP IDs.Variable node representingthe value of SNP j for individual I, where .Familial factornode, representing the familial relationships and reproduction.LD factor node, representing the LD relationship between the SNPs.(a)(b)1145where Z is a normalization constant, and the notation (∼
k) means all familial factor node neighbors of the variable
node i, except k. This computation is repeated for every
neighbor of each variable node. It is important to note that
the message in (3) is valid if the value of x1
1 is unknown to the
adversary (i.e., x1
1 can also
1 ∈
be observed by the adversary (i.e., x1
1 = ρ (ρ ∈ {0, 1, 2}), then µ(ν)
XK and x1
(ν) = ρ) = 1 and
(ν)) = 0 for other potential values of x1
µ(ν)
i→k(x1
1 (regardless
of the values of the messages received by the variable node
i from its neighbors).
1 ∈ XK). Thus, if x1
i→k(x1
1 ∈ XU). However, the value of x1
1
1
Next, the factor nodes generate their messages. The mes-
sage from the familial factor node k to the variable node i
at the νth iteration is formed using the principles of belief
propagation as
λ(ν)
k→i(x1
1
(ν)
) =
f 3
1 (x1
1, Θ(x1
1),FR(xM
j , xF
j , xC
j ), P)
(cid:88)
(cid:89)
1}
1,x3
{x2
y∈{x2
1}
1,x3
1),FR(xM
µ(ν)
y→k(x1
1
(ν)
).
(4)
j , xC
j , xF
j , xF
1, Θ(x1
1 (x1
j , xC
j ), P) ∝ p(x1
1|Θ(x1
Note that f 3
1),
FR(xM
j ), P), and this probability is computed using
Table 1. Furthermore, if the degree of the familial factor
node is 1 for a particular SNP, then the local function cor-
responding to the familial factor node only depends on the
MAF of the corresponding SNP. For example, the degree of
f 1
1 (in Fig. 3(c)) is 1, hence f 1
j ), P)
∝ p(x1
1). The above computation must be performed for
every neighbor of each familial factor node.
1),FR(xM
1, Θ(x1
j , xF
1|pb
j , xC
1 (x1
Similarly, the message from the LD factor node z to the
variable node i at the νth iteration is formed as
β(ν)
z→i(x1
1
(ν)
) =
g1
1,2(x1
1, x1
2, L1,2)
µ(ν)
y→k(x1
1
(ν)
). (5)
(cid:89)
y∈{x1
2}
(cid:88)
x1
2
As before, this computation is performed for every neighbor
2, L1,2)
1, x1
of each LD factor node. We further note that g1
∝ p(x1
2. The al-
gorithm proceeds to the next iteration in the same way as
the νth iteration.
2), which is derived from L1,2, pb
1,2(x1
1, and pb
1, x1
1
i→k(x1
1 ∈ XU), µ(1)
1 and, (ii) if the value of x1
1 ∈ XK) and x1
The algorithm starts at the variable nodes. Thus, at the
ﬁrst iteration of the algorithm (i.e., ν = 1), the variable node
i sends messages to its neighboring factor nodes based on the
following rules: (i) If the value of x1
1 is unknown to the ad-
(1)) = 1 for all potential values
versary (x1
of x1
1 is known to the adversary
(1) = ρ) = 1
(x1
and µ(1)
1. The
iterations stop when all variables in XU have converged. The
marginal probability of each variable in XU is given by mul-
tiplying all the incoming messages at each variable node.
3.3 Computational Complexity
(1)) = 0 for other potential values of x1
1 = ρ (ρ ∈ {0, 1, 2}), µ(1)
i→k(x1
i→k(x1
1
1
The computational complexity of the proposed inference
attack is proportional to the number of factor nodes. In our
setting, there are nm familial factor nodes and a maximum
of nm(m − 1)/2 LD factor nodes. Hence, the worst-case
computational complexity per iteration is O(cid:0)nm2(cid:1). How-
ever, as each SNP is in LD with a limited number of other
SNPs, the matrix L is sparse and the number of LD factor
nodes grows with m rather than with m(m−1)/2, especially
computational complexity per iteration is O(cid:0)nm(cid:1). Based
if we focus on SNPs in strong LD only. Thus, the average
on our experiments, we can state that the number of itera-
tions before convergence is a small constant, between 10 and
15. Note ﬁnally that this complexity can be further reduced
by using similar techniques developed for message-passing
decoding of LDPC codes (e.g., working in log-domain [20]).
3.4 Privacy Metrics
A crucial step towards protecting kin genomic privacy is to
quantify the privacy loss induced by the release of genomic
information. Through the inference attack, the adversary
infers the targeted SNPs (in XU) belonging to the members
of a targeted family by using his background knowledge and
observed genomic data (of the family members). The in-
ferred information can be expressed as the posterior distri-
bution p(XU|XK,FR(xM
j ), L,GF, P). Moreover, each
posterior marginal probability distribution is represented as
j|XK), for all i ∈ F, j ∈ S. We propose to quantify kin
p(xi
genomic privacy using the following metrics: expected esti-
mation error (incorrectness) and uncertainty.4
j , xF
j , xC
Correctness was already proposed in the context of loca-
tion privacy [45]. In our scenario, correctness quantiﬁes the
adversary’s success in inferring the targeted SNPs. That is,
it quantiﬁes the expected distance between the adversary’s
j ∈ XU) and the true
j (xi
estimate on the value of a SNP, xi
value of the corresponding SNP, ˆxi
j. This distance can be
expressed as the expected estimation error as follows:
p(xi
j|XK)||xi
j − ˆxi
j||.
(6)
(cid:88)
Ei
j =
j∈{0,1,2}
xi
Privacy can also be represented as the adversary’s uncer-
j|XK). This un-
tainty [22, 43], that is the ambiguity of p(xi
certainty is generally considered to be maximum if the pos-
terior distribution is uniform. This deﬁnition of uncertainty
j|XK)
can be quantiﬁed as the (normalized) entropy of p(xi
as follows:
j∈{0,1,2} p(xi
xi
j|XK) log p(xi
j|XK)
log(3)
.
(7)
−(cid:80)
H i
j =
The higher the entropy is, the higher is the uncertainty.
j; XK) = H(xi
Finally, we propose another entropy-based metrics that
quantiﬁes the mutual dependence between the hidden ge-
nomic data that the adversary is trying to reconstruct, and
the observed data. This is quantiﬁed by mutual information
j|XK) [8]. As privacy decreases
I(xi
with mutual information, we propose the following (normal-
ized) privacy metrics:
j = 1 − H(xi
I i
j) − H(xi
j|XK)
H(xi
(8)
=
.
j) − H(xi
H(xi
j)
j|XK)
H(xi
j)
The aforementioned metrics are useful for quantifying the
genomic privacy of individuals. In order to quantify a more
tangible privacy, we must convert these genomic-privacy met-
rics into health-privacy metrics. To quantify an individual’s
health privacy, we focus on his predisposition to diﬀerent
diseases. Let Sd be the set of IDs of the SNPs that are as-
sociated with a disease d. Then, a metrics quantifying the
4These metrics are not speciﬁc to the proposed inference
attack; they can be used to quantify genomic privacy in
general.
1146health privacy for an individual i regarding the disease d can
be deﬁned as follows:
(cid:88)
k∈Sd
ck