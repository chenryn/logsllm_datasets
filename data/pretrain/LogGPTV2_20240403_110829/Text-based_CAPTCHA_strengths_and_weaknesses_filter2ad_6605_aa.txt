title:Text-based CAPTCHA strengths and weaknesses
author:Elie Bursztein and
Matthieu Martin and
John C. Mitchell
Text-based CAPTCHA Strengths and Weaknesses
Elie Bursztein, Matthieu Martin, and John C. Mitchell
Stanford University
PI:EMAIL, PI:EMAIL, PI:EMAIL
ABSTRACT
We carry out a systematic study of existing visual CAPTCHAs based
on distorted characters that are augmented with anti-segmentation
techniques. Applying a systematic evaluation methodology to 15
current CAPTCHA schemes from popular web sites , we ﬁnd that
13 are vulnerable to automated attacks. Based on this evaluation, we
identify a series of recommendations for CAPTCHA designers and
attackers, and possible future directions for producing more reliable
human/computer distinguishers.
Categories and Subject Descriptors
K.6.5 [Computing Milieux]: Management of Computing and In-
formation Systems—Security and Protection
General Terms
Security, Theory
Keywords
CAPTCHA, reverse Turing test, machine learning, vision algorithm,
SVM, KNN classiﬁer.
1.
INTRODUCTION
Many websites use CAPTCHAs [25], or Completely Automated
Public Turing tests to tell Computers and Humans Apart, in an at-
tempt to block automated interactions with their sites. These efforts
may be crucial to the success of these sites in various ways. For
example, Gmail improves its service by blocking access to auto-
mated spammers, eBay improves its marketplace by blocking bots
from ﬂooding the site with scams, and Facebook limits creation
of fraudulent proﬁles used to spam honest users or cheat at games.
The most widely used CAPTCHA 1 schemes use combinations of
distorted characters and obfuscation techniques that humans can
recognize but that may be difﬁcult for automated scripts.
1For readability purpose, we will write the acronym in lowercase.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’11, October 17–21, 2011, Chicago, Illinois, USA.
Copyright 2011 ACM 978-1-4503-0948-6/11/10 ...$10.00.
Figure 1: Wikipedia captcha example
Captchas are sometimes called “reverse Turing tests”: because
they are intended to allow a computer to determine if a remote
client is human or not. In spite of their importance, their extremely
widespread use, and a growing number of research studies [7, 8, 31]
there is currently no systematic methodology for designing or evalu-
ating captchas. In fact, as we substantiate by thorough study, many
popular websites still rely on schemes that are vulnerable to auto-
mated attacks. For example, our automated Decaptcha tool breaks
the Wikipedia scheme, illustrated in ﬁgure 1, approximately 25%
of the time. 13 out of 15 of the most widely used current schemes
are similarly vulnerable to automated attack by our tool. Therefore,
there is a clear need for a comprehensive set of design and testing
principles that will lead to more robust captchas.
While ﬁne previous work [7] suggests that captcha security de-
pends on preventing segmentation, we ﬁnd in our study that relying
on segmentation alone does not provide reliable defense against
automated attacks. For example, it is possible to exploit the fact
that the captcha length is ﬁxed to make an educated guess where to
segment the captcha, even if its anti-segmentation technique can’t
be broken directly. We found that this type of attacks apply to nu-
merous captcha schemes, including eBay and Baidu.
Reﬂecting on techniques described in the literature [10, 32], avail-
able machine-learning techniques [11, 20, 26] available vision al-
gorithms [1, 13, 14], and our own experience with captcha analy-
sis [2, 4, 5], we divide the automated captcha-solving process into
ﬁve generic steps: pre-processing, segmentation, post-segmentation,
recognition, and post-processing. While segmentation, the sepa-
ration of a sequence of characters into individual characters, and
recognition, identifying those characters, are intuitive and generally
understood, there are good reasons for considering the additional
pre-processing and post-processing steps as part of a standard pro-
cess. For example, preprocessing can remove background patterns
or eliminate other additions to the image that could interfere with
segmentation, while post-segmentation steps can “clean up” the seg-
mentation output by normalizing the size of each image or otherwise
performing steps distinct from segmentation.
125After recognition, post-processing can improve accuracy by, for
example, applying spell checking to any captcha that is based on ac-
tual words (such as Slashdot). Based on this generic captcha-solving
architecture, we experimented with various speciﬁc algorithms and
tried them on various popular website captchas. From these corpus,
we identiﬁed a set of techniques that make captchas more difﬁcult
to solve automatically. By varying these techniques, we created a
larger synthetic corpus that allowed us to study the effect of each
of these features in detail and reﬁne our automated attack methods.
Based on our previous study of how solvable captchas are for hu-
mans [3, 5], we focused our attention on a range of techniques that
are within the grasp of human solvers, although we did consider
possible captchas that could be uncomfortably difﬁcult for some
humans.
We tested the efﬁciency of our tool Decaptcha against real captchas
from Authorize, Baidu, Blizzard, Captcha.net, CNN, Digg, eBay,
Google, Megaupload, NIH, Recaptcha, Reddit, Skyrock, Slash-
dot, and Wikipedia. As far as we know none of these captcha
schemes had been reported broken prior to this work. Of these
15 captchas, we had 1%-10% success rate on two (Baidu, Sky-
rock), 10-24% on two (CNN, Digg), 25-49% on four (eBay,
Reddit, Slashdot, Wikipedia), and 50% or greater on ﬁve (Autho-
rize, Blizzard, Captcha.net, Megaupload, NIH). To achieve such a
high success rate we developed the ﬁrst successful attacks against
captcha schemes that use collapsed characters (eBay, Megaupload,
and Baidu). Only Google and Recaptcha resisted to our attack at-
tempts, and we reached some informative understanding of why we
couldn’t break them. Because of Decaptcha genericity we were able
to break 7 of these 15 schemes (Authorize, Baidu, CNN, Megau-
pload, NIH, Reddit, Wikipedia) without writing a new algorithm.
Based on our evaluation of real-world and synthetic captchas,
we extracted several guidelines and suggestions that we believe
will be useful to captcha designers and attackers. For example,
randomizing the captcha length and individual relative character size,
while relatively painless for humans, are important steps for resisting
automated attacks. Similarly, if all characters are the same size,
partial segmentation then gives a good estimate of the number of
characters, again aiding segmentation. Conversely, creating a wave
shape and collapsing or overlayed lines can be effective, relatively
speaking. We also ﬁnd that complex character sets, which can
be confusing for humans, are not particularly effective, and we
comment on the relative importance of anti-recognition techniques,
implementation errors, preparing alternative “backup” schemes in
case vulnerabilities are discovered. The main contributions of this
work include:
• A generic evaluation tool, Decaptcha, designed to evaluate
quickly captcha security.
• A state-of-the-art evaluation of anti-recognition techniques
and anti-segmentation techniques, and captchas used by the
popular websites.
• Successful attacks by a single tool against 13 out of 15 real
captcha schemes from popular websites and the ﬁrst success-
ful attacks on captchas that use collapsed characters (e.g eBay
and Baidu).
• A publicly available synthetic corpus designed to replicate
security features of real-world captchas, in ranges potentially
acceptable to humans, so that designers may test new attack
algorithms on them.
• A defense taxonomy and an evaluation of the impact of anti-
recognition techniques on the learnability of captchas by au-
tomated tools.
2. BACKGROUND
Measuring attack effectiveness. A ﬁrst step to evaluate attack
effectiveness is to measure its accuracy, the fraction of captchas
that were answered correctly by the captcha solver. However, a
particular attacker may choose to respond to some captchas and not
others, depending on the conﬁdence in their guess, as web services
usually limit the number of attempts per IP [2]. Therefore, a more
precise way to evaluate attack effectiveness is through coverage and
precision metrics.
Coverage is the fraction of captchas that the solver attempts to
answer. Precision is the fraction of captchas answered correctly [2].
The captcha design goal is that “automatic scripts should not be
more successful than 1 in 10,000” attempts (i.e. a precision of
0.01%) [18]. However, we believe that this security goal is too
ambitious, random guesses can be sucessful, so we deem a captcha
scheme broken when the attacker is able to reach a precision of at
least 1%.
Another important consideration is how to choose the test set on
which the solver is evaluated. We argue that cross-validation is use-
ful for initial experimentation but is not sufﬁcient to deem a captcha
scheme insecure as it does not reﬂect real-world conditions where
the solver attacking a website is presented with previously unknown
captchas. Instead we adopt the machine learning community’s best
practices. We use a test set that is entirely different from the training
set to evaluate the solver’s effectiveness. We must avoid skewing
the precision evaluation due to a single easy captcha in the test set.
This is especially important when the solver’s precision is close
to 1% mark. Therefore, we advocate to use a large test set, of at
least 1,000 captchas. Now, the solver must solve at least 10 unseen
captchas before reaching the 1% precision mark required to deem a
scheme insecure. Every evaluation performed in this work follows
these best practices.
Attacking captchas. Prior to this work, state of the art automated
solvers used a three-stage approach consisting of preprocessing,
segmentation and classiﬁcation stages [9]. Previous experiments
have established that systems combining custom segmentation with
machine learning greatly outperform off-the-shelf OCR system at
breaking captchas. For example, [2] showed that on the eBay audio
captcha, the accuracy of a state of the art speech recognizer does
not exceed 1%, whereas a custom classiﬁer can exceed 75%. This
three-stage approach works as follow: ﬁrst, the solver pre-processes
the captcha to make it easier to analyze, for instance by remov-
ing colors or by applying noise reduction techniques. Next, the
solver attempts to segment the captcha into chunks that contain
exactly one character, for example by using a clustering algorithm
on the image. Finally, a classiﬁer, such as a support vector machine
(SVM) or a neural network, is used to recognize which character
is contained in each chunk. Accordingly, we will refer to anti-
recognition techniques to describe the image/text manipulations
that aim at preventing the recognition of individual characters and
to anti-segmentation techniques to describe image/text manipula-
tions that aim at preventing the solver from splitting the captcha
into individual characters. We will refer to the core-features to
describe the captcha’s basic design features, including its charset,
font, length, whether this length is random, and so forth.
126Many experiments [7] and attacks [32] have demonstrated that
most captcha schemes are broken if they can be reliably segmented.
Accordingly robust text-based schemes must make it difﬁcult for the
solver to determine where each character is. However, even if anti-
segmentation techniques are essential to captcha security, they are
only effective when the captcha core features and anti-recognition
techniques are properly designed and implemented. Instead of solely
focusing on preventing segmentation, we will show in this evalua-
tion section that secure design principles need to be applied at all
layers to create a secure scheme to avoid “side-channel attacks”. Fi-
nally we introduced in [4] a new metric called Learnability which
evaluates captcha strength based on the number of labeled exam-
ples required to train a classiﬁer to a given precision level. Our
learnability metric provides insight into how to properly choose
anti-recognition techniques and core-features.
3. CORPUS
In this section we present the captcha corpus we used to establish
our design principles and breaking techniques. As a starting point
we collected and annotated 15 real-world schemes used by popular
websites to evaluate Decaptcha performances against top-of-the-line
captchas schemes. Decaptcha was able to break 13 of these 15
schemes. We analyzed these captchas to come up with a set of
relevant security features that we used to create our synthetic corpus
designed to study the effect of each of these features in detail and
reﬁne attacking techniques.
3.1 Popular Real World Captchas
To collect a representative sample of captchas, we consulted the
Alexa list of most used websites2 and identiﬁed the top sites which
presented captchas as part of their account registration process. Ad-
ditionally, we collected captchas from sites which provide captchas
to other sites, e.g. Recaptcha.net and captchas.net. For each website
or captcha scheme presented in ﬁgure 2, we collected directly from
the website, 11,000 captchas that we had labeled by humans via
Amazon crowd-sourcing service Mechanical Turk [5]. Decaptcha is
able to break all of them except Recaptcha and Google.
3.1.1 Real-world Captcha Security Features
As visible in ﬁgure 2, real-world captchas exhibit a lot of varia-
tion in their design. By analyzing how each scheme is constructed
we grouped the security defenses used in these schemes into the
following ten techniques. Following the taxonomy presented in sec-
tion 2, these techniques were assigned into the anti-recognition or
the anti-segmentation category. We assigned to the anti-recognition
category every feature that didn’t directly prevent segmentation.
The anti-recognition techniques considered are: 1. Multi-fonts
Using multiple fonts or font-faces. 2. Charset Which charset the
scheme uses. 3. Font size Using variable font size. 4. Distortion
Distorting the captcha globally using attractor ﬁelds. 5. Blurring
Blurring letters. 6. Tilting Rotating characters with various angles.
7. Waving Rotating the characters in a wave fashion.
The anti-segmentation techniques considered are: 1. Complex
background Try to hide the text in a complex background to "con-
fuse" the solver. 2. Lines Add extra lines to prevent the solver
from knowing what are the real character segments. 3. Collapsing
Remove the space between characters to prevent segmentation.
2http://www.alexa.com/topsites
Scheme
Authorize
Baidu
Blizzard
Ebay
Recaptcha
Range from [5] Generated
95 – 98
90 – 93
89 – 95
93 – 93
72 – 75
92
90
91
94
93
Table 1: Optimistic solving accuracy across schemes, compar-
ing real world captchas to generated versions
Figure 3: Real world captchas and our generated versions (gen-
erated on the left, real on the right) Captcha schemes depicted
1:Authorize, 2:Baidu, 3:eBay, 4:Google, 5:Recaptcha
3.2 Synthetic corpus
To generate our synthetic corpus we created a captcha generator.
Using Mechnical turk we experimentally validated that our captcha
generator is able to replicate real-world captchas. Synthetic captchas
created by our generator have a similar accuracy to real world-