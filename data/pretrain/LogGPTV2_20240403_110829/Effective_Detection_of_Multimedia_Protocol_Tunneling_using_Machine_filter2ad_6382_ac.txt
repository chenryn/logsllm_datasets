ture set regions already reported. However, we verify
that the region including larger packet lengths was sig-
niﬁcantly expanded, including bins representing packets
with a size within the range of 885-1200 bytes.
4.5 Alternative Dataset Evaluation
We have constructed and handled our dataset by follow-
ing the same methodology adopted by previous works
under study. However, this methodology may raise a
few concerns. In particular, the covert streams (positive
class) have been produced using the available legitimate
videos (negative class), which may introduce some form
of correlation among classes. Furthermore, this method-
ology generates a 1:1 ratio of positive to negative classes,
which may be unrealistic if covert streams are a minority
among the trafﬁc found in the wild. Thus, one may won-
der how accurate is our classiﬁer if: i) the positive class is
no longer correlated with the negative class during test-
ing; ii) the positive-to-negative sample ratio is low during
testing. To validate the effectiveness of our approach, we
performed two additional experiments.
First, we performed an experiment which removed the
correlations between the positive and negative classes.
We split our legitimate trafﬁc dataset in half, using only
one half as legitimate samples. Then, for creating our
covert video dataset, we selected those covert videos
which embed modulated data in the legitimate videos
out of our reduced legitimate trafﬁc dataset. We then
used XGBoost to build a model through 10-fold cross-
validation. To prevent the ﬁtting of results to a particular
choice of the initial legitimate samples, we repeated the
process 10 times while randomly choosing such samples.
Second, we performed an experiment where we keep
the positive-to-negative sample ratio low during testing.
We split our data in training / testing sets in a 70 / 30 pro-
portion, and where we kept the training set ratio as 1:1,
and keep the positive to negative ratio of the testing set
to 1:100. To prevent the ﬁtting of results to a particular
split of the data, we randomly choose each set 10 times.
The results of our additional experiments suggest that
possible correlations among training and testing data, as
well as sample ratios, do not limit the accuracy of our
approach. For our ﬁrst experiment, XGBoost obtained an
AUC=0.94 for DeltaShaper h320 × 240, 8 × 8, 6, 1i trafﬁc
(only 0.01 less than the results reported in Section 4.3),
and an AUC=0.99 for trafﬁc pertaining to Facet s=50%
conﬁguration. As for the second experiment, XGBoost
was able to correctly identify 90% of Facet s=50% trafﬁc
with an FPR of only 2%, while it was able to identify
90% of DeltaShaper h320 × 240, 8 × 8, 6, 1i trafﬁc with
an FPR of 18% (only 4% larger).
4.6 Practical Considerations
This section details several practical considerations
which may be useful to an adversary considering the
use of decision tree classiﬁers for the detection of covert
channels. The following results reﬂect processing time in
a VM conﬁguration akin to that described in Section 2.4.
Feature extraction. The extraction of quantized packet
length bins from a 60 second Facet network trace
amounts to an average of 0.33s per sample. Generat-
178    27th USENIX Security Symposium
USENIX Association
System
Feature Set
Memory (kB)
Storage (kB)
System
1s
5s
10s
30s
60s
Facet
DeltaShaper
Summary Statistics (ST)
Packet Lengths (PL)
Summary Statistics (ST)
Packet Lengths (PL)
1.3
2.4
1.3
4.8
1.8
1.0
1.9
2.0
Table 2: Memory and storage requirements for a single
Facet record using different feature sets. We report stor-
age requirements for holding data in raw ASCII text.
System
Classiﬁer
Model Building (s) Prediction (µs)
Facet
Decision Tree
Random Forest
XGBoost
DeltaShaper Decision Tree
Random Forest
XGBoost
0.27
1.45
0.41
0.13
0.86
0.38
40
15000
180
90
16000
350
Table 3: Model building time and time for individual
predictions for Facet s=50% and DeltaShaper h320 ×
240, 8 × 8, 6, 1i trafﬁc, using quantized packet lengths
(PL). Model building time is the average of 10 folds.
ing summary statistics describing the same type of trafﬁc
ﬂow amounts to an average of 0.44s per sample. This
result indicates that an adversary can quickly generate
feature vectors for conducting subsequent classiﬁcation.
Memory and storage requirements. Table 2 depicts the
memory and storage requirements for holding a single
Facet or DeltaShaper sample. In our Python implemen-
tation, a NumPy [47] array storing the quantized packet
lengths describing a Facet sample (300 attributes) occu-
pies 2.4kB of memory per sample.
In comparison, an
array containing the bi-grams required by the χ 2 classi-
ﬁer occupy a total of 45kB per sample. The numbers in
Table 2 suggest that an adversary can efﬁciently store and
process large datasets. As an example, storing 1 million
Facet quantized packet lengths feature vectors in a raw
ASCII text ﬁle would only occupy approximately 1GB
of disk space. Storing summary statistics in raw ASCII
text would occupy nearly twofold the space due to the
characters required to represent ﬂoating-point precision.
Model building and classiﬁcation speed. Table 3 de-
picts the average training time of our classiﬁers, as well
as the average time to output a prediction. Building a De-
cision Tree - PL for identifying Facet trafﬁc takes an av-
erage of 0.27s. For an ensemble composed of 100 trees,
Random Forest - PL and XGBoost – PL models are built
in 1.45s and 0.41s, respectively. Moreover, the average
classiﬁcation time for an individual sample is 180µs for
XGBoost – PL. XGBoost is not only more accurate but
also trains faster and exhibits a faster classiﬁcation speed
than Random Forest. This relation is also present when
classifying DeltaShaper trafﬁc. These results stress the
Facet
DeltaShaper
0.81
0.75
0.92
0.88
0.96
0.93
0.99
0.95
0.99
0.95
Table 4: AUC of XGBoost – PL when classifying Facet
s=50% and DeltaShaper h320× 240, 8× 8, 6, 1i trafﬁc for
varying trafﬁc collection time windows.
fact that an adversary would beneﬁt from using XGBoost
to detect multimedia protocol tunneling covert channels.
Generalization ability of the classiﬁers. A classiﬁer
with good generalization ability is able to perform cor-
rect predictions for previously unseen data. Albeit the
AUC obtained by our decision tree-based classiﬁers sug-
gests that these can generalize well, we further assess
their classiﬁcation performance when training data is
severely limited. We split our data in two 10 / 90 train-
ing and testing sets, and report the mean AUC obtained
by the classiﬁer after repeating this process 10 times
while randomly choosing the samples making part of
each set. In this setting, when classifying Facet s=50%,
XGBoost - PL attains an AUC=0.98, only 0.01 short of
that obtained after 10x cross-validation. For DeltaShaper
h160 × 120, 4 × 4, 6, 1i trafﬁc, XGBoost - PL attains an
AUC 0.1 smaller than their 10x cross-validation counter-
part. These results suggest that an adversary can build ac-
curate decision tree-based classiﬁers for detecting covert
trafﬁc while resorting to a small sample of data.
Impact of network traces collection time. Table 4 de-
picts the AUC obtained by XGBoost – PL when detect-
ing different types of covert trafﬁc for varying time-spans
of trafﬁc ﬂows collection. Results show that capturing
trafﬁc by 30s is enough for attaining the same classiﬁ-
cation performance achieved in our initial experiments,
which admitted 60s trafﬁc captures. The numbers in Ta-
ble 4 also show that classiﬁcation performance decreases
monotonically for trafﬁc collections fewer than 30s, sug-
gesting that the inspection of at least 30s of video trafﬁc
provides the adversary with sufﬁcient data for identifying
covert trafﬁc ﬂows with low false positives.
5 Beyond Supervised Anomaly Detection
While decision tree-based classiﬁers show promising re-
sults for the detection of multimedia protocol tunneling
covert channels, they require the adversary to obtain a la-
beled dataset, including both legitimate and covert traf-
ﬁc. This usually requires the adversary to have a unlim-
ited access to a particular multimedia protocol tunneling
tool with which it may generate covert trafﬁc samples.
However, even if an adversary, for instance a censor,
would have an expedite access to these tools [19], it is
interesting to understand if detection is possible without
USENIX Association
27th USENIX Security Symposium    179
this knowledge. Note that covert channels may also be
used by organized criminals that can succeed in delaying
the dissemination of such tools. Secondly, albeit the ad-
versary is assumed to possess a given tool, it is expected
to spend a non-negligible time in synthesizing covert data
samples for building a model. Overcoming such chal-
lenges opens a timeframe where the covert trafﬁc gener-
ated by a given system would remain undetected.
This section explores alternative approaches at covert
trafﬁc detection in the absence of a fully labeled dataset.
5.1 Selected Anomaly Detection Methods
This section starts by describing several anomaly detec-
tion techniques which could be of interest for an adver-
sary aiming at detecting covert trafﬁc when it is deprived
of labeled anomalies. First, we describe OCSVMs and
autoencoders, two well-known approaches for anomaly
detection, which are based on representational models
of legitimate data and thus disregard the need of labeled
anomaly data [50]. Then, we explore Isolation Forest, a
competitive approach at unsupervised anomaly detection
which does not require labeled data [4, 8, 26].
One-class SVMs [45] deﬁne a decision boundary be-
tween normal samples and anomalies by ﬁtting a func-
tion around normal samples during training. OCSVMs
attempt to ﬁnd the maximal margin hyperplane which
separates the normal data from the origin, which is
treated as the single member of a second class. If data
cannot be easily separated by a linear function, OCSVMs
project the original feature space into a new feature space
through the use of kernel functions, introducing non-
linearity in the model. New data samples falling outside
the decision boundary are considered anomalies.
Autoencoders [32] are a type of artiﬁcial neural
networks which can approximate the identity function
through a compressed representation of its inputs, forc-
ing the algorithm to learn underlying structures in data.
The ability to reconstruct inputs allows us to have a gen-
erative model of the training data. An autoencoder can
be repurposed for anomaly detection by comparing the
reconstruction error of training inputs with normal and
anomalous data, where the latter is assumed to be larger.
Isolation Forest [31] performs outlier detection by
isolating anomalous samples. To isolate a sample, the
algorithm starts by selecting a random feature and se-
lects a split between its minimum and maximum values.
This process continues recursively until the considered
sample is isolated. Recursive partitioning is represented
by a tree, where the number of partitions required to iso-
late a sample corresponds to the length of the path tra-
versed from the root node to a leaf. The Isolation Forest
is built by combining a number of isolation trees split on
different attributes. Anomalies are expected to exhibit a
smaller average path length than that of normal samples.
Hyperparameters. The classiﬁcation performance of
the above algorithms depends upon the choice of hy-
perparameters, i.e., parameters whose value must be set
prior to the execution of the algorithm. The optimal-
ity of such parameters is intrinsically dependent on the
dataset and tipically requires cross-validation with la-
beled anomalous data [56]. However, we are interested
in assessing the average classiﬁcation performance that
an adversary would be able to achieve using such algo-
rithms – albeit the adversary would be unable to ﬁnd the
optimal hyperparameter conﬁguration for an algorithm,
sub-optimal parameterizations may still provide the ad-
versary with accurate trafﬁc classiﬁers. To this end, we
conduct a search over a space of parameters for the above
algorithms and collect the maximum and average AUC
obtained when classifying Facet and DeltaShaper trafﬁc.
For OCSVM, we perform a grid search on the space of
ν and γ. We also build a shallow autoencoder containing
one hidden layer between the input and its compressed
representation, and between the compressed representa-
tion and the output layer. We conduct a grid search over
the number of units populating each of these layers. As
for Isolation Forest, we conduct a search over the number
of trees composing the ensemble, as well as the number
of samples for training each individual tree.
Experimental settings. For OCSVM and autoencoder,