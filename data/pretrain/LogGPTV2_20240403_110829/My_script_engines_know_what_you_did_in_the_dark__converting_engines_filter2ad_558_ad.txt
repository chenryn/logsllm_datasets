1
Log lines
10000+
16
20
Failure rate
0
0.6
0
Table 5: Lines of Code (LOC) of test scripts
Script languages Average LOC
VBA
VBScript
PowerShell
3.8
2.75
2
5.7 Human Effort
To answer RQ6, we conducted an experiment to evaluate the amount
of human effort required to prepare test scripts. We evaluated this
from two viewpoints: lines of code (LOC) of test scripts and required
time to create them.
We gathered ten people (eight graduate students, one technical
staff member, and one visiting researcher) belonging to the com-
puter science department as the participants of this experiment.
We then explained the concept and requirements of the test scripts
described in Section 3.2 to them. We asked them to write valid
test scripts while measuring the required time. Many did not have
experience on writing the script languages of VBA, VBScript, and
PowerShell. Therefore, we asked them to spend some time learning
the language specifications since we assume that test script writers
have knowledge on the target language. Note that we confirmed
all the created test scripts argued below are valid with STAGER.
Table 5 shows the average LOC of the created test scripts for
each language. The LOC of the test scripts for each language are
within the range of 2 to 3.8. This indicates that test scripts that our
method uses are just simple ones.
Figure 8 shows the average time required for creating test scripts
for each language. The average required time per script API was
36.6 seconds for VBScript, 42.6 seconds for VBA, and 42.6 seconds
for PowerShell. The average time for all languages was about 59.5
seconds. These results showed that writing valid test scripts takes
less time for programmers who have knowledge on the target script
language. Therefore, the amount of human effort required for using
STAGER is much less than manual reverse-engineering of script
engines since manual reverse-engineering requires weeks of or
months of analysis time.
6 DISCUSSION
6.1 Limitations
We discuss three cases in which the proposed method cannot detect
hook and tap points. The first is that in which the target script
API does not have arguments to which we can set arbitrary values.
Since tap point detection uses argument matching which is based
on setting unique arguments, detection fails in principal if this
matching is not available.
Figure 8: Required Time for Test Script Preparation
The second is that in which the target script API contains only a
small amount of program code. In this case, hook point detection
by differential execution analysis might not be applicable because
the difference is not well observed. However, since it is difficult for
such simple script APIs to achieve significant functionality, they
would not be interesting targets for malware analysts.
The third is that the script engine is heavily obfuscated for
software protection. For example, when the control flow graph
is flattened to implement the script engine with one function, the
proposed method cannot accurately detect hook points. Neverthe-
less, such obfuscated implementation is rarely seen in recent script
engines, as far as we know.
6.2 Human-assisted Analysis
Although our method introduces automatic detection of hook and
tap points it is also helpful for its analysis to be assisted by human.
In particular, human-assisted analysis is beneficial for the case in
which tap point detection does not work in principal. One such case
is that human assistance can eliminate the first limitation discussed
in the previous section. Our method identifies tap points by match-
ing values in test scripts and functions arguments in script engines
without taking into account any semantics regarding the values.
However, manual analysis can take into account the semantics of
values. Therefore, it is possible to discover tap points using the
semantic information even when value matching is not available.
In addition, since manual analysis by humans can provide better
type information of variables by analyzing how the variables are
used, the exploration for tap point detection becomes more accurate
with human assistance.
Note that the burden of manual analysis with our method is much
less than complete manual analysis. This is because the number of
functions that should be analyzed becomes much less by hook point
detection, as described in Table 3. Without hook point detection, a
reverse-engineer has to analyze thousands of functions to obtain
tap points, whereas only tens of functions should be analyzed when
it is performed with hook point detection.
4757 RELATED WORK
7.1 Script Analysis Tools
There is a large amount of research on constructing script analysis
tools. There are multiple script analysis tools that adopt script-
level monitoring. The tool jAEk [24] hooks JavaScript APIs by
overriding built-in functions. It inserts hooks on open/send meth-
ods of XMLHttpRequest objects and methods regarding HTM-
LElement.prototype to obtain URLs accessed by Ajax communica-
tion. Practical script analysis tools such as Revelo [16], box-js [6],
jsunpack-n [11]k and JSDetox [28] also use script-level monitor-
ing. These tools offer strong script behavior analysis capability
on JavaScript. However, they do not fulfill the requirements men-
tioned in Section 2.1 because they deeply depend on the language
specifications of JavaScript.
There are also script analysis tools based on script engine-level
monitoring. Sulo [14][13] is a instrumentation framework for Ac-
tion Script of Adobe Flash using Intel Pin. It is based on the analy-
sis of the source code of the Actionscript Virtual Machine (AVM).
JSAND [2] hooks built-in methods of JavaScript by implementing a
specific emulator. FlashDetect [30] modifies an open source script
engine of Flash for their hook. These are examples of script engine-
level monitoring. ViperMonkey [18] is an emulator of VBA, which
can output logs of notable script APIs.
For system-level monitoring, many binary analysis tools that can
hook system APIs and/or system calls are available [17][23]. How-
ever, all these tools in this section cannot fulfill the requirements
introduced in Section 2.1.
7.2 Script Engine Enhancement
Chef [5][3] is a symbolic execution engine for script languages. It
uses a real script engine for building a symbolic execution engine.
It achieves symbolic execution of the target scripts by symbolically
executing the script engine binaries with a specific path exploration
strategy. The design is similar to that of STAGER in that it reuses
the target script engine for building a script analysis tool by in-
strumentation. On the other hand, the approaches and goals with
Chef are different from those of STAGER. Its approach was based on
manual source code analysis, whereas we used binary analysis. In
addition, the goal with Chef is building symbolic execution engines,
whereas ours is building script API tracers.
7.3 Mitigation of Semantic Gap
Several methods were developed for mitigating the semantic gap
between the guest and host OSes on the virtual machine monitor
(VMM).
Virtuoso [10] automatically creates VM introspection tools that
can produce the same results as a reference tool executed in a VM
from out-of-VM. Virtuoso first acquires execution traces by exe-
cuting the reference tool in the VM. It then extracts a program
slice which is only required for creating the tool. This method is
similar to ours in that it extracts required information by analyzing
formerly acquired execution traces. It differs from ours in its appli-
cation target as well as the algorithm it uses to extract information
from execution traces.
Tappan Zee (North) Bridge [9], or TZB, discovers tap points
effective for VM introspection. TZB monitors memory access of
software inside a VM with various inputs for learning. It then finds
tap points by identifying the memory location where the input
value appears. It is used to monitor the tap points in real time from
the out-of-VM for achieving effective VM instrospection.
7.4 Reverse Engineering of Virtual Machine
Sharif et al. [26] proposed a method of automatically reverse engi-
neering VMs used by malware for obfuscation. They used data flow
analysis to identify bytecode syntax and semantics as well as the
fundamental characteristics of VMs. Since script engines that our
method analyzes are generally based on such VMs, their goal of
automatically analyzing the VMs is similar to ours. However, their
analysis target is different from ours. Their method analyzes VMs
to identify the information about VMs and bytecode, whereas our
method analyzes to detect the local functions and their arguments
that relate to script APIs.
Coogan et al. [8] proposed an approach to identify the bytecode
instructions responsible for invoking system calls. Since system
calls are strongly relevant to malware behavior, their goal is to
approximate the behavior by the set of the identified bytecode in-
structions regarding the invocation of the system calls. Their goal,
focus, and approach are different from ours. First, their goal is ap-
proximating the behavior of malware obfuscated by VMs, whereas
ours is mitigating semantic gaps between script APIs and system
APIs or system calls. Second, their focus is only the bytecode in-
structions relevant to the invocation of system calls, whereas ours
is all script APIs regardless of the existence of system calls. Last,
their approach strongly relies on the invoked system calls and argu-
ments, whereas ours only on the branch instructions logged with
test scripts.
7.5 Differential Execution Analysis
Carmony et al. [7] proposed a method that uses differential analysis
of multiple execution and memory traces for identifying tap points
of Adobe Acrobat Reader. The traces are logged on condition that
PDFs with JavaScript, Well-Formed PDFs, and Malformed PDFs
are input to the reader. Based on the differential analysis of the
traces, the method identifies tap points that enables the extraction
JavaScript as well as those that represent the termination and error
of input file processing.
Zhu et al. [31] used differential execution analysis to identify
the blocking conditions used by anti-adblockers. They accessed
websites and logged the traces of JavaScript execution with and
without an adblocker. They then analyzed the traces to discover
branch divergences caused by the adblocker and identified the
branch conditions that cause the divergences.
Although they used differential execution analysis, the same as
with our method, their focus (Adobe Acrobat Reader and JavaScript
in websites) was different from ours (i.e., script engines). In addition,
our differentiation algorithm (i.e., the modified Smith-Waterman
algorithm) is different from those used in the above studies because
their target problems to solve were also different from ours (i.e., an
identification of the commonly appeared sequences).
476[17] Yuhei Kawakoya, Makoto Iwamura, Eitaro Shioji, and Takeo Hariu. 2013. API
Chaser: Anti-analysis Resistant Malware Analyzer. In Proceedings of the 16th
International Symposium on Research in Attacks, Intrusions and Defenses (RAID
’13). Springer, 123–143.
[18] Philippe Lagadec. [n. d.]. ViperMonkey. https://github.com/decalage2
/ViperMonkey. (accessed: 2019-09-20).
[19] JongHyup Lee, Thanassis Avgerinos, and David Brumley. 2011. TIE: Principled
Reverse Engineering of Types in Binary Programs. In Proceedings of the 18th
Annual Network and Distributed System Security Symposium (NDSS ’11). Internet
Society, 1–18.
[20] Chi-Keung Luk, Robert Cohn, Robert Muth, Harish Patil, Artur Klauser, Geoff
Lowney, Steven Wallace, Vijay Janapa Reddi, and Kim Hazelwood. 2005. Pin:
building customized program analysis tools with dynamic instrumentation. In
ACM Sigplan Notices, Vol. 40. ACM, 190–200.
[21] Alwin Maier, Hugo Gascon, Christian Wressnegger, and Konrad Rieck. 2019.
TypeMiner: Recovering Types in Binary Programs Using Machine Learning. In
Proceedings of the 16th International Conference on Detection of Intrusions and
Malware, and Vulnerability Assessment (DIMVA ’19). Springer, 288–308.
[22] Microsoft. [n. d.]. Antimalware Scan Interface. https://docs.microsoft.com/
(accessed:
en-us/windows/desktop/amsi/antimalware-scan-interface-portal.
2018-08-16).
[23] Yuto Otsuki, Eiji Takimoto, Shoichi Saito, Eric W Cooper, and Koichi Mouri. 2015.
Identifying system calls invoked by malware using branch trace facilities. In
International MultiConference of Engineers and Computer Scientists 2015, IMECS
2015. Newswood Limited.
[24] Giancarlo Pellegrino, Constantin Tschürtz, Eric Bodden, and Christian Rossow.
2015.
jäk: Using Dynamic Analysis to Crawl and Test Modern Web Applica-
tions. In Proceedings of the 18th International Symposium on Research in Attacks,
Intrusions and Defenses (RAID ’15). Springer, 295–316.
[25] ReactOS Project. [n. d.]. ReactOS. https://www.reactos.org/. (accessed: 2018-08-
[26] Monirul Sharif, Andrea Lanzi, Jonathon Giffin, and Wenke Lee. 2009. Automatic
Reverse Engineering of Malware Emulators. In 2009 30th IEEE Symposium on
Security and Privacy (SP ’09. IEEE, 94–109.
[27] Temple F Smith, Michael S Waterman, et al. 1981. Identification of Common
Molecular Subsequences. Journal of molecular biology 147, 1 (1981), 195–197.
[28] T. Sven. [n. d.]. JSDetox. http://relentless-coding.org/projects/jsdetox/. (accessed:
[29] PowerShell Team. [n. d.]. PowerShell. https://github.com/powershell. (accessed:
2019-09-20).
2018-08-16).
[30] Timon Van Overveldt, Christopher Kruegel, and Giovanni Vigna. 2012. FlashDe-
tect: ActionScript 3 Malware Detection. In Proceedings of the 15th International
Symposium on Research in Attacks, Intrusions and Defenses (RAID ’12). Springer,
274–293.
[31] Shitong Zhu, Xunchao Hu, Zhiyun Qian, Zubair Shafiq, and Heng Yin. 2018.
Measuring and Disrupting Anti-Adblockers Using Differential Execution Anal-
ysis. In Proceedings of the 25th Annual Network and Distributed System Security
Symposium (NDSS ’18). Internet Society.
16).
8 CONCLUSION
In this paper, we focused on the problems of current script dynamic
analysis tools and proposed a method for automatically building
script API tracers by automatically analyzing the binaries of script
engines. The method detects appropriate hook and tap points in
script engines through dynamic analysis using test scripts. Through
the experiments with a prototype system implemented with our
method, we confirmed that the method can properly append script
behavior analysis capability to the script engines for building script
API tracers. In addition, our case studies showed that the gener-
ated script API tracers can analyze malicious scripts in the wild.
Appending more effective script behavior analysis capabilities is
for future work.
ACKNOWLEDGMENTS
The authors would like to thank Tomoya Matsumoto, Yuki Kimura,
and the members of Matsuura Laboratory for their kind support as
the participants in the experiment. We also thank the anonymous
reviewers for their insightful comments. This work was partially
supported by JSPS KAKENHI Grant Number JP17KT0081.
2019-02-15).
REFERENCES
[1] [n. d.]. VirusTotal. https://www.virustotal.com/. (accessed: 2017-03-09).
[2] Pieter Agten, Steven Van Acker, Yoran Brondsema, Phu H Phung, Lieven Desmet,
and Frank Piessens. 2012. JSand: complete client-side sandboxing of third-party
JavaScript without browser modifications. In Proceedings of the 28th Annual
Computer Security Applications Conference (ACSAC ’12). ACM, 1–10.
[3] The Dependable Systems Lab at EPFL in Lausanne. [n. d.]. Chef. https://github.
com/S2E/s2e-old/tree/chef. (accessed: 2018-01-01).
[4] Rohitab Batra. [n. d.]. API Monitor. http://www.rohitab.com/apimonitor. (ac-
cessed: 2019-02-15).
[5] Stefan Bucur, Johannes Kinder, and George Candea. 2014. Prototyping symbolic
execution engines for interpreted languages. In ACM SIGPLAN Notices, Vol. 49.
ACM, 239–254.
[6] CapacitorSet. [n. d.]. box.js. https://github.com/CapacitorSet/box-js. (accessed:
[7] Curtis Carmony, Xunchao Hu, Heng Yin, Abhishek Vasisht Bhaskar, and Mu
Zhang. 2016. Extract Me If You Can: Abusing PDF Parsers in Malware Detec-
tors.. In Proceedings of the 23rd Annual Network and Distributed System Security
Symposium (NDSS ’16). Internet Society, 1–15.
[8] Kevin Coogan, Gen Lu, and Saumya Debray. 2011.
Deobfuscation of
Virtualization-Obfuscated Software: A Semantics-Based Approach. In Proceedings
of the 18th ACM conference on Computer and Communications Security (CCS ’11).
ACM, 275–284.
[9] Brendan Dolan-Gavitt, Tim Leek, Josh Hodosh, and Wenke Lee. 2013. Tappan
Zee (North) Bridge: Mining Memory Accesses for Introspection. In Proceedings
of the 2013 ACM SIGSAC Conference on Computer and Communications Security
(CCS ’13). ACM, 839–850.
[10] Brendan Dolan-Gavitt, Tim Leek, Michael Zhivich, Jonathon Giffin, and Wenke
Lee. 2011. Virtuoso: Narrowing the Semantic Gap in Virtual Machine Introspec-
tion. In Proceedings of the IEEE Symposium on Security and Privacy 2011 (SP ’11).
IEEE, 297–312.
[11] Blake Hartstein. [n. d.].
jsunpack-n. https://github.com/urule99/jsunpack-n.
(accessed: 2019-02-15).
[12] Jingxuan He, Pesho Ivanov, Petar Tsankov, Veselin Raychev, and Martin Vechev.
2018. Debin: Predicting Debug Information in Stripped Binaries. In Proceedings
of the 2018 ACM SIGSAC Conference on Computer and Communications Security
(CCS ’18). ACM, 1667–1680.
[13] Timo Hirvonen. [n. d.]. Sulo. https://github.com/F-Secure/Sulo.
(accessed:
[14] Timo Hirvonen. 2014. Dynamic Flash instrumentation for fun and profit.
Blackhat USA briefings 2014, https://www.blackhat.com/docs/us-14/materials/
us-14-Hirvonen-Dynamic-Flash-Instrumentation-For-Fun-And-Profit.pdf. (ac-
cessed: 2019-02-15).
[15] Ralf Hund. 2016. The beast within - Evading dynamic malware analysis using
Microsoft COM. Blackhat USA briefings 2016.
[16] KahuSecurity. [n. d.]. Revelo Javascript Deobfuscator. http://www.kahusecurity.
com/posts/revelo_javascript_deobfuscator.html. (accessed: 2019-02-15).
2019-02-15).
477