### Profiling and Validation of URL Filtering Products

We utilize the profiling tool, WhatWeb [9], to confirm the presence of specific products installed on a given host. For certain products, such as Netsweeper, WhatWeb already includes pre-existing signatures that we can leverage for validation. In other cases, we create custom signatures based on HTTP headers observed when running WhatWeb on an IP address. Table 2 provides a summary of how we identify various products using WhatWeb.

Additionally, we use geolocation data from MaxMind [15] and whois data from TeamCymru [31] to map the IP addresses matching WhatWeb signatures to their country-level locations and autonomous system (AS) numbers.

### Networks with URL Filtering Installations

Figure 1 summarizes the countries where each product was detected. While the OpenNet Initiative (ONI) typically focuses on installations by national ISPs, our new methodology allows us to uncover URL filtering installations in a broader range of countries and networks. For example, we observed Blue Coat installations in several new regions: South America (Argentina and Chile), Europe (Finland, Sweden), Asia (Philippines, Thailand, and Taiwan), and the Middle East (Israel, Lebanon). Furthermore, for the remaining three products, all the installations we discovered (except for McAfee SmartFilter in Pakistan) were previously unknown.

In the United States, we observed diverse installations, such as Websense in two Texas utilities' networks and Netsweeper in educational networks in West Virginia, Oklahoma, and Missouri. Additionally, we found Netsweeper installations in large ISP networks like Global Crossing, AT&T, Verizon, and Bell South, as well as Blue Coat installations in Comcast and Sprint. Interestingly, we also detected a Blue Coat installation on an IP address registered to the United States Information Systems Command (USAISC). The dual-use of these products for network management and censorship necessitates confirming their usage before drawing conclusions.

### Confirming Use of URL Filters

Many of the identified products play a legitimate role in network management. Therefore, it is crucial to validate whether they are being used for censorship. Vendors may obscure their product identities by removing the headers we identified in Table 2. Our confirmation method is robust to the lack of signatures and does not require the IP address of the URL filter to be externally visible. However, we use the networks identified in Section 3 as a case study for our technique.

#### In-Network Testing

To confirm that a URL filter is being used for censorship, we conduct experiments from within the network under consideration, utilizing our global network of testers. These tests involve accessing a specified list of URLs in the "field" (i.e., the location where censorship is suspected) using a measurement client. The same set of URLs is accessed from a server in our lab at the University of Toronto, which does not censor the tested content. The results from the field and lab are compared to determine if the page was blocked in the field location. For our URL filtering measurements, we test short lists of URLs that are amenable to manual analysis. The products we test often use block pages that explicitly state that content has been censored, thus avoiding ambiguities such as censorship via dropped packets or TCP resets.

#### Methodology

Our methodology aims to answer the question: Is the given URL filtering product used for censorship in the measured ISP? Many URL filters provide a mechanism for users to submit sites that should be blocked. We explored whether this mechanism could be used to confirm the use of a specific URL filter. The basic idea is to test sites (under our control) that are not blocked within the ISP, and then submit a subset of these sites to the appropriate URL filter vendor. After 3-5 days, we retest the sites to observe if the submitted sites are blocked. If they are, it is highly likely that the URL filter is being used for censorship. Table 3 summarizes the case studies that explore the effectiveness of this approach.

#### Case Study: McAfee SmartFilter in UAE and Saudi Arabia

In 2009, the ONI identified McAfee SmartFilter being used in Etisalat (UAE's national ISP) and in a centralized blocking implementation in Saudi Arabia [23, 24]. We used our proposed methodology to confirm whether these technologies were still deployed in these networks in 2012 and 2013.

Previously, the ONI observed Etisalat using SmartFilter to block content related to anonymizing proxies [24]. We created a set of 10 domains providing proxy services to test whether SmartFilter was still in use. These domains had the form of two random (non-profane) words registered with the ".info" top-level domain (e.g., starwasher.info) and contained the Glype proxy script [8] as their index page. We first verified that these 10 domains were accessible in the country. We then submitted five of these domains to SmartFilter for blocking. Within a few days, we observed that the five submitted sites were blocked on Etisalat, confirming that the product was still in use (Table 3).

**Challenge 1: Access to Sites That Will Be Blocked**

Our methodology requires access to websites that are blocked by the studied ISP. Unlike the UAE, we found that websites classified as proxies by SmartFilter were accessible in Saudi Arabia. This suggests that Saudi Arabia is not using the proxy category provided by SmartFilter in their deployment. However, websites classified as pornography by SmartFilter are blocked in Saudi Arabia. We performed a similar experiment, creating 10 domains hosting an adult image found via a Google image search. Using the ISP Bayanat Al-Oula, we verified that the 10 domains were accessible in Saudi Arabia. We then submitted five of the domains to SmartFilter for blocking. After four days, we observed that these five domains were blocked (Table 3). We repeated this methodology on Nournet and Etisalat to confirm that SmartFilter is still used within these ISPs in 2013.

#### Case Study: Netsweeper in Qatar, UAE, and Yemen

Implementation details of censorship platforms can impact our ability to confirm censorship. For example, we have observed Netsweeper queuing websites for categorization once they have been accessed within the country. As a result, once we have validated that our set of URLs is accessible, they may be queued for categorization by Netsweeper and eventually blocked. Thus, it is not possible to validate that our sites are accessible prior to submission. We operate on the assumption that none of our sites will be blocked prior to submission.

Previous studies by the ONI identified the use of Netsweeper in YemenNet (Yemen), Du (UAE), and Ooredoo (Qatar) to block content related to anonymizing proxies [25, 24, 21]. We used these ISPs to test our proposed methodology. We created a list of 12 domains providing proxy services and submitted six of them to Netsweeper’s “test-a-site” service for classification [20]. We then accessed these 12 domains in YemenNet, Du, and Ooredoo, and observed whether the six submitted sites were blocked. In all three ISPs, the methodology was successful, with five of the six sites blocked in Du and all six blocked in YemenNet and Ooredoo (Table 3).

**Challenge 2: Inconsistent Blocking**

Validating censorship in Yemen was complicated by inconsistent blocking. We observed cases where the blocking technology appeared to be temporarily offline. For example, some proxy URLs were accessible on runs where others were blocked, and the reverse was true in later runs. Prior work by the ONI observed a Yemeni ISP using Websense with a limited number of concurrent user licenses. When the number of users exceeded the number of licenses, no content was filtered [25].

Inconsistent blocking means that we need to repeat the tests numerous times and require a larger set of domains for testing. This inconsistency limits the scalability of our approach for validating Netsweeper installations in Yemen.

However, we identified another way to validate that Netsweeper is being used for censorship. Netsweeper provides a website for operators to validate that censorship is working within their network by querying a set of 66 category-specific URLs (e.g., denypagetests.netsweeper.com/category/catno/23 for pornography). A manual test of this tool in YemenNet in January 2013 indicated that five categories were blocked: adult images, phishing, pornography, proxy anonymizers, and search keywords.

### Summary of URL Filter Case Studies

Table 3 summarizes the case studies of URL filter usage. The table includes the product, country, ISP, date, number of sites submitted, category, number of sites blocked, and whether the usage was confirmed.

### Summary of Web Content Blocked by URL Filtering Products

Table 4 provides a summary of the types of web content blocked by different URL filtering products, including media freedom, human rights, political reform, LGBT, religious criticism, and minority groups and religions.