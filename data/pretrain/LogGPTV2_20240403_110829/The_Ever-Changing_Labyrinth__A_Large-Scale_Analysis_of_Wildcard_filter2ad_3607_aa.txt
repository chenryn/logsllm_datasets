title:The Ever-Changing Labyrinth: A Large-Scale Analysis of Wildcard
DNS Powered Blackhat SEO
author:Kun Du and
Hao Yang and
Zhou Li and
Hai-Xin Duan and
Kehuan Zhang
The Ever-Changing Labyrinth: A Large-Scale 
Analysis of Wildcard DNS Powered Blackhat SEO
Kun Du and Hao Yang, Tsinghua University; Zhou Li, IEEE Member; Haixin Duan,  
Tsinghua University; Kehuan Zhang, The Chinese University of Hong Kong
 https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/du
This paper is included in the Proceedings of the 25th USENIX Security SymposiumAugust 10–12, 2016 • Austin, TXISBN 978-1-931971-32-4Open access to the Proceedings of the 25th USENIX Security Symposium is sponsored by USENIX The Ever-changing Labyrinth: A Large-scale Analysis of Wildcard DNS
Powered Blackhat SEO
Kun Du
Tsinghua University
PI:EMAIL
Haixin Duan
Hao Yang
Tsinghua University
PI:EMAIL
Zhou Li
IEEE Member
PI:EMAIL
Tsinghua University
PI:EMAIL
Kehuan Zhang
The Chinese University of Hong Kong
PI:EMAIL
Abstract
1
Introduction
Blackhat Search Engine Optimization (SEO) has been
widely used to promote spam or malicious web sites.
Traditional blackhat SEO campaigns often target hot
keywords and establish link networks by spamming pop-
ular forums or compromising vulnerable sites. However,
such SEO campaigns are actively disrupted by search en-
gines providers, making the operational cost much higher
in recent years.
In this paper, we reveal a new type
of blackhat SEO infrastructure (called “spider pool”)
which seeks a different operational model. The owners
of spider pools use cheap domains with low PR (PageR-
ank) values to construct link networks and poison long-
tail keywords. To get better rankings of their promoted
content, the owners have to reduce the indexing laten-
cies by search engines. To this end, they abuse wildcard
DNS to create virtually inﬁnite sites and construct com-
plicated loop structure to force search-engine crawlers to
visit them relentlessly.
We carried out a comprehensive study to understand
this emerging threat. As a starting point, we inﬁltrated
a spider pool service and built a detection system to ex-
plore all the recruited SEO domains to learn how they
were orchestrated. Exploiting the unique features of the
spider pool, we developed a scanner which examined
over 13 million domains under 22 TLDs/SLDs and dis-
covered over 458K SEO domains. Finally, we measured
the spider-pool ecosystem on top of these domains and
analyzed the crawling results from 21 spider pools. The
measurement result reveals their infrastructure features,
customer categories and impact on search engines. We
hope our study could inspire new mitigation methods and
improve the ranking or indexing metrics from search en-
gines.
To most people, search engine is the entrance to all sorts
of web sites on internet. The trafﬁc volume generated
through search engines is huge: the number one search
engine Google receives 3.5 billion search queries per
day [46] and the subsequent visits referred by the search
results can account for more than 60% of the incoming
trafﬁc of a website [55]. Improving sites’ search rank-
ings and attracting crawlers to visit them frequently are
very important to their owners.
Site owners and researchers have done extensive stud-
ies and come up with a set of “golden rules” on how to
improve one site’s performance in search results, which
are also called Search Engine Optimization (SEO) tech-
niques. Some SEO techniques aim to improve the site
structure (e.g., providing navigation in HTML pages)
and search afﬁnity (e.g., adding descriptive keywords
to titles and metadata). They are termed “whitehat
SEO” techniques and are encouraged by search engine
providers. However, applying these techniques usually
requires great effort from site owners and the effects are
not always immediate. As a shortcut, “blackhat SEO”
techniques are developed, which exploit the blind side of
search-engine algorithms and gain a site big advantage
in search results at low cost.
Traditional blackhat SEO practices recommend stuff-
ing keywords and injecting inbound links into reputable
sites. While the ﬁrst method can be achieved just by
manipulating the site’s content, the second one is much
more difﬁcult because it requires changing content on
other reputable sites which are not under SEOer’s con-
trol. Common approaches towards this goal include post-
ing spam links in forums [43], compromising sites to
inject links [24, 51], buying links from link exchange
services [54], and constructing link network using ex-
USENIX Association  
25th USENIX Security Symposium  245
pired domains with high PR (PageRank) value [15, 16].
These techniques, nevertheless, require big investment
(e.g., buying links and expired domains) and could result
in severe penalties from search engines (e.g., when the
SEOer is found to use compromised sites).
New blackhat SEO techniques.
Instead of contest-
ing high rankings of trending keywords which are of-
ten dominated by top-brand sites, SEOers start to tar-
get the search queries containing long-tail keywords and
tunnel the trafﬁc to their sites [32]. Long-tail keywords
are usually overlooked by big sites because the trafﬁc to-
wards each keyword is quite limited. However, the traf-
ﬁc combined from many such keywords can be substan-
tial, which motivates SEOers to launch campaigns target-
ing them. The sites competing long-tail keywords usu-
ally have low PR value, leading to infrequent visits from
search-engine crawlers and long waiting time before be-
ing indexed (i.e., site is shown in search results) [18].
To increase the chance of being crawled, new blackhat
SEO strategy is proposed to feed inﬁnite hyperlinks to
crawlers which all point to the sites under SEOer’s con-
trol. When a crawler enters SEOer’s network, it will be
trapped and keep crawling the content fed by the SEOer.
To escape from such network, a crawler can check if it
keeps visiting a ﬁxed set of sites and exit when this hap-
pens. This is actually enforced by many search engines.
As a countermeasure, SEOers can create a massive num-
ber of fresh sites for the crawlers to foil the check, and
it turns out wildcard DNS perfectly serves this purpose.
A site with wildcard DNS toggled on can redirect vis-
its landing on its subdomains (e.g., aaaa.example.com)
to itself (e.g., example.com). Leveraging this tech-
nique, SEOers can create unlimited number of virtual
sites under only one valid domain name. This new attack
clearly harms search engines, as the crawling resources
are wasted and search results are manipulated.
This novel approach quickly gains popularity in the
blackhat SEO community, especially in China. The in-
frastructure built upon wildcard DNS domains is called
spider pool in China (“∎V” in Kanji) 1 and has been
broadly discussed in underground forums. In this study,
we aim to provide the ﬁrst comprehensive study of this
new threat in hopes of inspiring new methods for mitiga-
tion.
Our study. In order to understand the spider-pool infras-
tructure, we reached out to an owner of a spider pool in
operation and purchased SEO service to promote a site
created by us. Playing as a customer enabled us to in-
ﬁltrate the spider pool and discover unique features re-
garding its infrastructure. In particular, we found wild-
card DNS was extensively used on each site and dynamic
1Such infrastructure may be named differently in SEO communities
of other countries. We use spider pool to represent all variations for
brevity.
content generation was fully automated. We also discov-
ered a new promotion technique which has never been
reported by previous research. The adversaries are able
to advertise their messages through very popular sites,
like amazon.com, without compromising or even spam-
ming them.
Exploiting the DNS and content features of spider
pool, we developed a scanner based on DNS probing and
differential analysis. We used this scanner to examine
13.5 million domains under 22 TLDs and SLDs. The
result is quite alarming: we identiﬁed 458K spider pool
domains distributed among 19 TLDs/SLDs. In addition,
we discovered a trend of misusing new gTLD domains
for this type of SEO and also policy holes for domain
registration process of .ac.cn SLD. We measured these
domains in different aspects and show statistics regard-
ing their hosted IPs, domain registrars and registrants.
We found that though the domains are spread over 28K
IPs, they are rather centralized on a small set of ASNs,
registrars and controlled by a small group of SEOers.
Finally, we extended our study and crawled 20 new
spider pools using seed domains detected by our scan-
ner, to study their business model and impact on search
engines. As a result, we identiﬁed 15.8K SEO do-
mains, 1.4K customer domains and 7.2M URLs embed-
ding customer messages. The study on the business
model revealed new categories of customer’s business
that are never reported before. Our results also suggest
that spider pool is clearly effective in attracting search
crawlers and manipulating search results under long-tail
keywords. Baidu, the top search engine vendor in China,
has acknowledged our ﬁndings and we are now collab-
orating with Baidu to deploy detection system to purify
search results and capture spider pool services.
2 Background
In this section, we ﬁrst overview the factors affecting
search rankings and indexing delay of a website. Then,
we survey widely used blackhat SEO techniques and
their infrastructures which aim to promote a website’s
ranking unethically.
2.1 Search Engine Optimization
The goal of search engine is to provide a user with
a list of web pages that are relevant to search key-
words and ranked by their importance. Although rank-
ing algorithm is considered as the topmost secret by
search engine providers and is never released, guide-
lines and techniques called Search Engine Optimization
(SEO) are developed from white-papers published by
the providers, extensive experiments and reverse engi-
neering [17, 20, 44]. Whitehat SEO advocates improv-
ing the structure of a site to make it more friendly to
search crawlers. Advices include adding targeted key-
246  25th USENIX Security Symposium 
USENIX Association
2
words to webpage (document body, title, meta tags and
page URLs), creating navigation page (e.g., a sitemap
ﬁle) to guide crawler, avoiding repeated page content,
and frequent content update. Improving the site’s quality
also increases the chance of being referred by other web
sites, which in turn increases its PR (PageRank) value.
In addition to gaining high rankings in relevant search
results, it is also important to reduce the indexing delay
of a page. The more frequently a web site is visited by
search crawler, the faster its pages will be indexed (i.e.,
shown in search results). The visit frequency is mainly
determined by the PR value [18], meaning that a new
web site might have to wait for a long time to be indexed
and displayed under search terms it targets.
While most of the web sites attempt to get good rank-
ings under hot keywords, the cost is always high. Instead,
targeting long-tail keywords might help the site harvest a
large volume of trafﬁc without big spending [32]. As
an example, to get top ranking under the search results
of “socks” is challenging, but achieving so for “socks
with dogs on them” or “socks that knock my socks off”
is much easier. In fact, the trafﬁc querying long-tail key-
words can account for 70% of all trafﬁc to a search en-
gine [10]. So, long-tail keywords are also important for
web sites.
2.2 Blackhat SEO Techniques
Tuning the factors that improve site’s quality is allowed
by search engine companies. However, unethical adver-
saries also develop techniques (i.e., Blackhat SEO) to
gain advantages in search results at low cost by gaming
ranking algorithms. We describe known techniques as
follows:
Content spam. Since the number of keywords con-
tained in a web page and URLs play an important role
in computing the ranking score, an adversary can either
repeat the same keywords to increase the relevance to
search terms of the same category, or include a spectrum
of trending keywords to associate the site with many
search terms of different categories (also named search
poisoning [31]). Recently, Google starts to penalize web
pages with excessively repeated contents, which forces
the SEOers to use a new technique called spinning to
generate spam texts with similar meaning but different
appearances [57]. A set of SEO toolkit is developed to
automate this process, like XRumer [6].
Link farm. To accumulate a large number of incom-
ing links to a web site, an adversary can set up link
farm [8, 53] which exploits the vulnerabilities of other
reputable sites to inject link. We show more details about
this blackhat SEO infrastructure in Section 2.3.
Cloaking. Blackhat SEO is becoming one popular chan-
nel for malware and scam delivery. Cloaking technique
is leveraged to serve benign content to search engines
while malicious content to normal visitors, in order to
avoid being detected [50]. User agent, referrer ﬁeld in
HTTP header, and IP address are inspected to determine
if the request is from a real browser or a search engine
crawler.
2.3 Blackhat SEO Infrastructures
The number and quality of incoming links are key factors
for the effectiveness of a SEO campaign. The adversary
needs to have a large number of incoming links at dis-
posal to elevate the site’s popularity. Different blackhat
SEO infrastructures on organizing the links have been
discovered and they are described below.
Forum spam. Web forum accepts and displays posts
contributed by web users, and the posts are also crawled
by search engines. A forum with high reputation is prone
to be abused by attackers who post links to promote their
sites [37]. Moreover, blog sites allowing comments are
also likely to be spammed by the similar techniques. As
a mitigation strategy, a site can set the rel attribute of
external links as nofollow to stop disseminating repu-
tation score to spam links [20], or request CAPTCHA
solving before comments are posted.
SEO botnet. The adversary has limited privileges in
posting spams to forum/blog. To overcome such restric-
tions, attackers could choose to compromise vulnerable
sites, turn them into botnet, and make them refer to the
sites to be promoted. Later, when search engines visit
the compromised sites and compute rank value, the pro-
moted web site will get an unusual high ranking [24,51].
Some SEO kits are developed to manage thousands of
sites simultaneously, reducing attackers’ workload [2].
Knowing the existence of such infrastructure, search en-
gine vendors are actively detecting compromised sites
and removing sites promoted in this fashion. The com-
promised sites are also alarmed in search results to avoid
being clicked by victim visitors [49].
Link exchange platform. There are also online fo-
rums and platforms helping website administrators to
exchange incoming links and improve their sites’ rank
mutually [54]. Examples include sape.ru [39] and
warriorforum.com [52]. Link exchange through SEO
forum and platform is explicitly forbidden by search en-
gine companies like Google, which for example penal-
izes buyers of sape.ru [40]. This approach is also ex-
pensive for adversaries, because they have to buy links to
maintain their faked popularity.
Private Blog Network (PBN). This is a new type of
black SEO infrastructure. The adversaries ﬁrst buy and
set up many blog sites on a set of expired domains with
high PR values, then construct link network carefully un-
der their control, and ﬁnally inject outgoing links point-
ing to sites to be promoted [15, 16]. Expired domains
USENIX Association  
25th USENIX Security Symposium  247
3
with high PR values are usually sold at high prices, so
a large-scale and successful PBN could cost consider-
ably [11].
3 Dissecting a Spider Pool Campaign
Since search engine vendors upgrade their ranking al-
gorithm frequently (e.g., Google updates its algorithm
500-600 times per year [42]) and demote sites engaged
in blackhat SEO actively or even seize the back-end
servers [49], attackers are forced to invent new ways to
keep their business effective and proﬁtable. In this sec-
tion, we elaborate our study on “spider pool”, a new type
of blackhat SEO infrastructure unreported by previous
research.
3.1 Overview
All known blackhat SEO techniques ask for massive in-
coming links from reputable sites to increase the impor-
tance score of the promoted site under hot keywords,
which are always competed by numerous sites.
In-
evitably, these techniques are very expensive. To reduce
the cost, SEOers start to operationalize their campaigns
under long-tail keywords, for which the competition is
more relaxing. Though the search trafﬁc ﬂowing to an
individual long-tail keyword is nominal, the volume ac-
cumulated for a large set is considerable.
Furthermore, new or expiring domains which are
much cheaper are recruited to set up this SEO infrastruc-
ture. However, since the PR values of these domains are
usually negligible, they cannot be directly used to boost
the score of the customer sites they point to. This causes
a big issue in indexing latency, as search engines prefer
to crawl and index a page faster if it comes from sites
with high PR value.
Instead of sitting and waiting for the search crawler
to knock on the door, spider pool actively traps search
crawlers.
In other words, it keeps the crawlers visit-
ing sites (sites of both SEOer and customers) within the
border of attacker’s network.
How to trap a crawler. One intuitional approach to trap
crawler is through link loop, but search engines have al-
ready adopted some algorithms to detect loops that are
constructed intentionally. To evade detection, spider pool
applies techniques including creation of massive subdo-
mains and generation of dynamic contents. By adding a
wildcard DNS record (as shown in Figure 1) to the au-
thoritative DNS server, an adversary can conﬁgure the
web server to feed the crawler whatever subdomain she
wants to be visited (e.g., a.example.com). The web
page fed into the crawler is stuffed with spam links,
which instruct the crawler to visit other subdomains (e.g.,
b.example.com). In case the crawler skips the pages
with the same content, the site could render page dynami-
cally and provide distinctive content for each visit. Since
Figure 1: An example of wildcard DNS record.
the crawler always gets a “valid” page from a “valid”
website, it will follow the spam links and keep visiting
sites under adversaries’ control.
Effects. The major beneﬁt through using spider pool
is the boost of visiting frequency from search crawler,
given that there are always new pages fed into them. It
can also improve the importance score of the customers’
sites, as the incoming links from spider pool are mas-
sive.
In addition, the number of indexed pages under
customers’ sites can be increased as well.
Comparison with other SEO infrastructures. The
price of buying new or expiring domain is much cheaper
nowadays. As shown in domcomp.com, a web site list-
ing domain prices, one can purchase a domain for only
$0.99 at some registrars [13]. This is a big advantage
over PBN asking for expensive expired domains with
high PR value, and over link exchange service for expen-
sive links. In the meantime, attackers can easily change
the underlying link structure, which outperforms forum
spam in ﬂexibility. Moreover, since the sites in spider
pool are not compromised, they are less likely to be de-
tected and alarmed compared to sites recruited by SEO
botnet, as shown in Section 5.2.
Terms. For simplicity, throughout this paper, we use do-
main to refer to the domain name purchased by the adver-
sary, which is different from hostname or FQDN that can
be created randomly at her will through wildcard DNS.
We call domains controlled by the spider pool owner
SEO domains and pages with spam links SEO pages. The
parties who use spider pool to promote their sites or mes-
sages (explained at the end of this section) are called cus-
tomers.
3.2
To better understand the business model, features and op-
erational details of a spider pool, we inﬁltrated one popu-
lar spider pool service provider called super spider pool2.
In this paper we use SSP to refer to this service. Differ-
ent from dedicated spider pool which is built for a single
customer, this is a shared spider pool which sells SEO
service to customers publicly. It adds the URL provided
by customers to its SEO pages after payment.
Purchasing spider pool service. We bought a domain 3
and set up a web site with fake contents generated from
template downloaded from tttuangou.net 4. The web
Inﬁltration of a Spider Pool
2http://www.zhizhuche.com
3his-and-hers.xyz, bought on Oct 30th, 2015 from Goddady.
4http://tttuangou.net/download.html
248  25th USENIX Security Symposium 
USENIX Association
4
Spider Pool 
Customers’ Sites 
tonty.27sb.cn 
jaozi.27sb.cn 
jftxy.27sb.cn 
Crawling 
*.27sb.cn 
otlxo.bkiwd.top 
Gambling 
Drugs 
Prostitution 
99859.isdrs.pw 
*.bkiwd.top 
*.isdrs.pw 
iujic.bkiwd.top 
Crawling 
7834115.isdrs.pw 
hzcbz.bkiwd.top 
565632296.isdrs.pw 
Customers’ Messages 
Visit from Search Results 
Figure 2: The infrastructure of a spider pool. The spider pool consists of new or expiring domains (e.g., 27sb.cn) which leverage
wildcard DNS to breed unlimited numbers of subdomains (e.g., jftxy.27sb.cn). Subdomains under different domains are inter-
connected and the links are dynamically generated. When a search crawler approaches one subdomain, it will be trapped in the
spider pool until being released to customers’ sites or URLs bearing customers’ messages.
Cute Group Purchase
Business Scope of Chess and Card Room
24sb.cn is a wildcard domain
Add Lock for Glove Box in Car
nraogh.com.cn is a wildcard domain
Real Estate for YaHao in BeiJing
kpkuny.com.cn is a wildcard domain
Fasion Wedding Photo in NewYork
nkjwap.com.cn is a wildcard domain
Figure 3: The returned search results from Google (top 5 only)
when querying using the homepage URL of our site. Except the