11
0 0.2 0.4 0.6 0.8 1 0 5 10 15 20 25utilizationβhonRRADPRASRAFIG. 6—Mean utilization of DPRA with 1M rounds as we vary the
bounds (βhon) and the security parameter (λ) for a resource of capacity
k = 10. Here, g(λ) = λ and h(λ) = 3λ. The number of processes
requesting service (|P|) is fixed to 100.
(a) DPRA with ε = 0.20 and δ = 0.030
can guarantee privacy in the presence of an unbounded number
of malicious processes.
To measure utilization (Definition 4), we have processes
request resources following a Poisson distribution with a rate
of 50 requests/round; this determines the value of |P|, which
we truncate at βP. We then depict the mean utilization over
1M rounds as we vary βhon (which impacts the value of βP as
explained above) in Figure 5.
Results. SRA achieves low utilization across the board since
it is inversely proportional to βM and does not depend on βhon
(the utilization is much lower at βhon = 1 only because of the
truncation of |P| to ≤ 10). RRA, on the other hand, achieves
perfect utilization when βhon is small. This is simply because
|P| = βP with high probability (again, due to the way we are
setting and truncating |P|); in such case RRA adds no dummy
processes. For larger values of βhon, the difference between βP
and |P| increases, leading to a reduction in utilization.
As we expect, DPRA’s utilization is inversely proportional
to βhon. What is somewhat surprising about this experiment is
that DPRA achieves worse utilization than RRA, even though
it provides weaker guarantees. However, this is explained by
DPRA making a weaker assumption. One could view this
difference as the cost of working in a “permissionless” setting.
(b) DPRA with ε = 0.10 and δ = 0.027
(c) DPRA with ε = ln(2) and δ = 10−4
C. Utilization versus privacy for DPRA
(d) RRA
In the previous section we compare the utilization of DPRA
to other allocators for a particular value of ε, δ, and βhon.
Here we examine how λ can impact utilization for a variety of
bounds by conducting the same experiment but varying λ and
βhon. We arbitrarily set g(λ) = λ and h(λ) = 3λ, which yields
ε = 1/λ and δ = 1
λ ). The results are in Figure 6.
2 exp( 1−3λ
We find that for high values of λ, the utilization is well below
10% regardless of βhon, which is too high a price to stomach—
especially since RRA leaks no information and achieves better
utilization. As a result, DPRA appears useful only in cases
where moderate leakage is acceptable (high values of ε and
δ), or when there is no other choice (when there are sybils, or
when the application is new and a bound cannot be predicted).
To answer whether a given ε and δ are a good choice in terms
of privacy and utilization, we can reason about it analytically
using the expressions in the last row of Figure 3. However, it
is also useful to visualize how DPRA works. To do this, we
FIG. 7—Histogram of malicious processes allocated by DPRA for
different values of ε and δ (Figures a–c) and RRA (Figure d) after
100K iterations. In b = 0, the allocators are called with Pmal; in
b = 1, the allocators are given Pmal ∪ Phon. Differences between
the two lines represents the leakage. Here βhon = 10, βP = 100,
k = 10, |Phon| ∈R [0, 10], and |Pmal| = 100 − |Phon|. The parameters
in Figure (c) are those used by Vuvuzela [81] and Alpenhorn [57].
To achieve ϵ = ln(2) and δ = 10−4, we set g(λ) = λ/10 ln(2) and
h(λ) = 1.328λ for λ = 10.
run 100K iterations of the security game (§III) and measure
how the resulting allocations differ based on the challenger’s
choice of b and the value of ε and δ. We also conduct this
experiment with RRA (with βP = 100) for comparison. The
results are depicted in Figure 7.
If an allocator has negligible leakage, the two lines (b = 0
and b = 1) should be roughly equivalent (this is indeed the
12
0 0.2 0.4 0.6 0.8 1 1 10 100 1000 10000utilizationλβhon = 5βhon = 10βhon = 15βhon = 200 10000 20000 30000 0 2 4 6 8 10frequencymalicious processes allocated (tmal)b = 0b = 10 10000 20000 30000 0 2 4 6 8 10frequencymalicious processes allocated (tmal)b = 0b = 10 10000 20000 30000 0 2 4 6 8 10frequencymalicious processes allocated (tmal)b = 0b = 10 20000 40000 60000 80000 0 2 4 6 8 10frequencymalicious processes allocated (tmal)b = 0b = 1FIG. 8—Average number of rounds required to establish a session in
Alpenhorn when the recipient is using a PRA with a varying number
of incoming channels (“in” in the terminology of Section VI-B).
βP = 100, βhon = 10, ε = ln(2), δ = 10−4.
FIG. 9—Average number of rounds required to establish a session in
Alpenhorn when the recipient is using a weighted PRA (§VI-C) and
the caller has a priority 5× higher than all other users. βP = 100,
βhon = 10, ε = ln(2), and δ = 10−4.
case with RRA). Since DPRA is leaky, there are observable
differences, even to the naked eye (e.g., Figure a and c). We
also observe a few trends. If we fix g(λ) = λ and h(λ) = 3λ
in DPRA (Figure 7a and b), as λ doubles (from Figure a to b),
the frequency of values concentrates more around the mean,
and the mean shifts closer to 0. Indeed, for λ = 1000 (not
depicted), the majority of the mass is clustered around 0 and
1. RRA is heavily concentrated around tmal = 10 because our
setting of |P| = βP guarantees perfect utilization (cf. §VII-B),
and roughly 90% of the chosen processes are malicious (so
they count towards tmal). For other values of βP, the lines would
concentrate around k|Pmal|
D. Conversation start latency in Alpenhorn
βP
.
To evaluate our modified version of Alpenhorn, we choose
privacy parameters that are at least as good as those in the
original Alpenhorn evaluation [57] (ε = ln(2) and δ = 10−4,
see Figure 7 for details on the polynomial functions that
we use), and pick bounds based on a previous study of
Facebook’s social graph [79]4. We set the maximum number
of friends (βM) to 5,000, the maximum number of concurrent
dialing friends (βP) to 100, and the maximum number of
concurrent honest dialing friends (βhon) to 20. We think these
numbers are reasonable for MPMs: if dialing rounds are on
the order of a minute, the likelihood of a user receiving a call
from 21 different uncompromised friends while the adversary
simultaneously compromises at least 80 of the users’ friends is
relatively low. Of course, the adversary could exploit software
or hardware vulnerabilities in clients’ end devices to invalidate
this assumption, but crucially, MPM systems are at least not
vulnerable to sybils (dialing requires a pre-shared secret).
We quantify the disruption of PRAs in Alpenhorn by
measuring how many dialing rounds it takes a particular
caller to establish a session with a friend as a function of
the allocator’s capacity (in). The baseline for comparison is
the original Alpenhorn system which uses the FIFO allocator
described in Section III-B. Our experiment first samples a
number of concurrent callers following a Poisson distribution
with an average rate of in processes/round. We set the average
4While Facebook is different from a messaging app, Facebook Messenger
relies on users’ Facebook contacts and has over 1.3 billion monthly users [23].
13
rate to in because we expect that as the system becomes
more popular and users start demanding more concurrent
conversations, the default per-round capacity of the system
will be increased. We emphasize that this choice only helps
the baseline: the number of callers (|P|) has no impact on the
probability of a particular process being chosen in SRA or RRA,
and has only a bounded impact in DPRA. In contrast, the value
of |P| has a significant impact on when a process (e.g., the
last process) is chosen in the FIFO allocator (lower is better).
We then label one caller c ∈ P at random as a distinguished
caller, and have all callers dial the callee; whenever a caller’s
call is picked up, we remove that caller from P. Finally, we
measure how many rounds it takes for c’s call to be answered
and repeat this experiment 100 times. The results for the
baseline, RRA, and DPRA are given in Figure 8. We do not
depict SRA since it requires over 10× more rounds.
When there is a single incoming channel available (in = 1),
it takes c on average 102 rounds to establish a connection with
RRA and 271 rounds for DPRA; it takes the baseline roughly
1.5 rounds since the number of processes is very small. For
in = 5, which is reasonable in a setting in which rounds are
infrequent, c must wait for about 20 and 52 rounds, for RRA
and DPRA respectively.
Given this high delay, we ask whether prioritization (§VI-C)
can provide some relief. We perform the same experiment
but assume that the caller c is classified as a high priority
friend (5× higher weight). Indeed, prioritization cuts down the
average session start proportional to the caller’s weight. For
in = 5, the average session start is 4.4 rounds in RRA versus
1.2 rounds in the baseline (a 3.6× latency hit).
Alternate tradeoffs. It takes callers in our modified Alpenhorn
16× longer than the baseline to establish a connection with
their friends (when in = 5 and there is no prioritization). If
rounds are long (minutes or tens of minutes), this dramatically
hinders usability. An alternative is to trade other resources for
latency: clients can increase the number of conversations they
can handle by 16× (paying a corresponding network cost due
to dummy messages) to regain the lower latency. Equivalently,
the system can decrease the dialing round duration (again, at a
CPU and network cost increase for all clients and the service).
0 20 40 60 80 100 0 5 10 15 20 25session start delay (rounds)incoming channels (in)RRADPRABaseline0 5 10 15 20 0 5 10 15 20 25session start delay (rounds)incoming channels (in)RRA (weighted)DPRA (weighted)BaselineVIII. RELATED WORK
Several prior works study privacy in resource allocation
mechanisms, including matchings and auctions [11, 13, 17, 40,
63, 65, 75, 85], but the definition of privacy, the setting, and
the guarantees are different from those studied in this work;
the proposed solutions would not prevent allocation-based side
channels. Beaude et al. [13] allow clients to jointly compute
an allocation without revealing their demands to each other
via secure multiparty computation. Zhang and Li [85] design
a type of searchable encryption that allows an IoT gateway to
forward tasks coming from IoT devices (e.g., smart fridges) to
the appropriate fog or cloud computing node without learning
anything about the tasks. Similarly, other works [17, 40, 63,
65, 75] study how to compute auctions while hiding clients’
bids. Unlike PRAs, the goal of all of these works is to hide
the inputs from the allocator or some auditor (or to replace
the allocator with a multi-party protocol), and not to hide the
existence of clients.
The work of Hsu et al. [41] is related to DPRA (§IV-C). They
show how to compute matchings and allocations that guarantee
joint-differential privacy [46] and hide the preferences of an
agent from other agents. However, their setting, techniques,
and assumptions are different. We highlight a few of these
differences: (1) their mechanism has a notion of price, and
converges when agents stop bidding for additional resources
because the price is too high for them to derive utility. In
our setting, processes do not have a budget and there is no
notion of prices. (2) Their scheme assumes that the allocator’s
capacity is at least logarithmic in the number of agents. (3)
Their setting does not distinguish between honest or malicious
agents, so the sensitivity is based on all agents’ demands. In
the presence of sybils (which as we show in Section VII is
the only setting that makes sense for DPRA), assumption (2)
cannot be met, and (3) leads to unbounded sensitivity.
IX. DISCUSSION AND FUTURE WORK
We introduce private resource allocators (PRA) to deal with
allocation-based side-channel attacks, and evaluate them on
an existing metadata-private messenger. While PRAs might be
useful in other contexts, we emphasize that their guarantees
are limited to hiding which processes received resources from
the allocation itself. Processes could learn this information
through other means (this is not an issue in MPM systems
since by design they hide all other metadata). For example,
even if one uses a PRA to allocate threads to a fixed set of
CPUs, the allocated threads could learn whether other CPUs
were allocated by observing cache contention, changes to the
filesystem state, etc.
Other applications in which allocation-based side channels
could play a role are those in which processes ask for
permission to consume a resource before doing so. One example
is FastPass [67], which is a low-latency data center architecture
in which VMs first ask a centralized arbiter for permission and
instructions on how to send a packet to ensure that their packets
will not contribute to queue build up in the network. Similarly,
Pulsar [7] works in two phases: cloud hypervisors ask for
resources (network, storage, middleboxes) for their VMs to a
centralized controller via a small dedicated channel before the
VMs can use the shared data center resources. While the use
of the shared resources is vulnerable to consumption-based
side channels, the request for resources and the corresponding
allocation might be vulnerable to allocation-based side channels.
Indeed, we believe that systems that make a distinction between
the data plane and control plane are good targets to study for
potential allocation-based side channels.
Enhancements to PRAs. Note that PRAs naturally use re-
sources to compute allocations: they execute CPU instructions,
sample randomness, access memory, etc. As a result, even
though the allocation itself might reveal no information, the
way in which PRAs compute that allocation is subject to
standard consumption-based side-channel attacks (e.g., timing
attacks). For example, a process might infer how many other
processes there are based on how long it took the PRA to
compute the allocation. It is therefore desirable to ensure that
PRA implementations are constant time and take into account
the details of the hardware on which they run. To illustrate
how critical this is, observe that DPRA (§IV-C) samples
noise from the Laplace distribution assuming infinite precision.
However, real hardware has finite precision and rounding effects
for floating point numbers that violates differential privacy
unless additional safeguards are used [28, 62]. Beyond these
enhancements, we consider two other future directions.
Private multi-resource allocators. In some settings there is
a need to allocate multiple types of resources to clients with
heterogeneous demands. For example, suppose there are three
resources R1, R2, R3 (each with its own capacity). Client c1
wants two units of R1 and one unit of R2, and client c2 wants
one unit of R1 and three units of R3. How can we allocate
resources to clients without leaking information and ensuring
different definitions of fairness [14, 29, 37, 39, 45, 64]? A naive
approach of using a PRA for each resource independently is
neither fair (for any of the proposed fairness definitions) nor
optimal in terms of utilization.
Private distributed resource allocators. Many allocators
operate in a distributed setting. For example, the transmission
control protocol (TCP) allocates network capacity fairly on a
per-flow basis without a central allocator. Can we distribute
the logic of our PRAs while still guaranteeing privacy and
liveness with minimal or no coordination?
ACKNOWLEDGMENTS
We thank the anonymous reviewers for their thoughtful
feedback, which significantly improved this paper. We also
thank Aaron Roth for pointing us to related work, and Andrew
Beams for his comments on an earlier draft of this paper.
DISCLAIMER
This document does not contain technology or technical data
controlled under either the U.S. International Traffic in Arms
Regulations or the U.S. Export Administration Regulations.
14
[7] S. Angel, H. Ballani, T. Karagiannis, G. O’Shea, and
[22] D. Cole. We kill people based on metadata.
REFERENCES
[1] Apache Hadoop. https://hadoop.apache.org.
[2] Alpenhorn: Bootstrapping secure communication without
leaking metadata. https://github.com/vuvuzela/alpenhorn,
Nov. 2018. commit 3284950.
[3] Criterion: Statistics-driven microbenchmarking in Rust.
https://github.com/japaric/criterion.rs, Apr. 2019.
[4] D. Agrawal, B. Archambeault, J. R. Rao, and P. Rohatgi.
The EM side-channel(s). In Proceedings of the
Workshop on Cryptographic Hardware and Embedded
Systems (CHES), Aug. 2002.
[5] D. Agrawal and D. Kesdogan. Measuring anonymity:
The disclosure attack. IEEE Security & Privacy, 1(6),
Nov. 2003.
[6] N. Alexopoulos, A. Kiayias, R. Talviste, and
T. Zacharias. MCMix: Anonymous messaging via secure
multiparty computation. In Proceedings of the USENIX
Security Symposium, Aug. 2017.
E. Thereska. End-to-end performance isolation through
virtual datacenters. In Proceedings of the USENIX
Symposium on Operating Systems Design and
Implementation (OSDI), Oct. 2014.
[8] S. Angel, H. Chen, K. Laine, and S. Setty. PIR with
compressed queries and amortized query processing. In
Proceedings of the IEEE Symposium on Security and
Privacy (S&P), May 2018.
[9] S. Angel, D. Lazar, and I. Tzialla. What’s a little leakage
between friends? In Proceedings of the ACM Workshop
on Privacy in the Electronic Society (WPES), Oct. 2018.
[10] S. Angel and S. Setty. Unobservable communication
over fully untrusted infrastructure. In Proceedings of the