### Accuracy and Top-n Accuracy Measures

In the context of multiclass classification, accuracy is defined as the fraction of correctly classified samples over all samples. Top-n accuracy is a similar measure, where a sample is considered correctly classified if it is among the top n predictions made by the classifier.

### Key Classification Using Logistic Regression

For key classification, we employed a Logistic Regression (LR) classifier, which outperformed other classifiers such as Linear Discriminant Analysis (LDA), Support Vector Machines (SVM), Random Forest (RF), and k-nearest neighbors. This was demonstrated in an experiment where each classifier was used to classify a dataset of 10 samples for each of the 26 keys corresponding to the letters of the English alphabet, using a 10-fold cross-validation scheme. Mel-frequency cepstral coefficients (MFCCs) were used as features, and hyperparameters were optimized via an extensive grid search.

The results, shown in Figure 4, indicate that LR and SVM are the best-performing classifiers, especially when making a small number of predictions (between 1 and 5). Both LR and SVM achieved around 90% top-1 accuracy and over 98.9% top-5 accuracy. However, LR slightly outperformed SVM until top-4.

**Figure 4: Average top-n accuracy of single key classification, as a function of the number of guesses, for each classifier.**

| Number of Guesses | 0% | 20% | 40% | 60% | 80% | 100% |
|-------------------|----|-----|-----|-----|-----|------|
| 0                 |    |     |     |     |     |      |
| 2                 |    |     |     |     |     |      |
| 4                 |    |     |     |     |     |      |
| 6                 |    |     |     |     |     |      |
| 8                 |    |     |     |     |     |      |
| 10                |    |     |     |     |     |      |

### Evaluation of S&T Attack Feasibility

To evaluate the feasibility of the S&T attack, we conducted a series of experiments covering all previously described scenarios, using Skype as the underlying VoIP software. The reasons for choosing Skype include its popularity, the use of its codecs in the IETF standard Opus, and its representation of mono audio. Preliminary results suggest that similar outcomes can be achieved with other VoIP software, such as Google Hangouts.

#### Data Collection

Data was collected from five distinct users, each tasked with pressing the keys corresponding to the English alphabet sequentially from "A" to "Z" and repeating the sequence ten times. Users first used the right index finger (Hunt and Peck typing, or HP) and then used all fingers of both hands (Touch typing). We believe this method does not introduce bias, as typing the English alphabet in order is similar to typing random text, which is the target of the S&T attack.

To test this assumption, a preliminary experiment was conducted:
- A single user typed the English alphabet sequentially on a Macbook Pro laptop.
- Waveforms of the letters were extracted at different intervals (3ms, 10ms, 20ms, ..., 100ms).
- MFCCs were extracted, and the S&T attack was tested in a 10-fold cross-validation scheme.

Results, shown in Figure 5, indicate minimal accuracy loss even with very short 20ms samples, suggesting that adjacent letters do not influence each other due to the low likelihood of sound overlapping.

**Figure 5: Top-5 accuracy of single key classification for different sample lengths.**

| Sample Length (ms) | 0% | 20% | 40% | 60% | 80% | 100% |
|--------------------|----|-----|-----|-----|-----|------|
| 0                  |    |     |     |     |     |      |
| 20                 |    |     |     |     |     |      |
| 40                 |    |     |     |     |     |      |
| 60                 |    |     |     |     |     |      |
| 80                 |    |     |     |     |     |      |
| 100                |    |     |     |     |     |      |

Data was collected on six laptops: two Apple Macbooks Pro 13” mid 2014, two Lenovo Thinkpads E540, and two Toshiba Tecras M2. Acoustic emanations were recorded using the laptop's microphone and Audacity software v2.0.0, with a sampling frequency of 44.1kHz and saved in WAV format (32-bit PCM signed).

The recorded data was then filtered through Skype and recorded on a different computer. Two Linux machines with Skype v4.3.0.37 were used, connected to a high-speed network, with no significant data loss during the calls.

#### S&T Attack Evaluation

We evaluated the S&T attack in various scenarios, focusing on the Complete Profiling scenario. Performance was analyzed separately for each laptop model, typing style, and VoIP filtered and unfiltered data. The most realistic combination—Touch typing and Skype-filtered data—was given particular attention.

**Complete Profiling Scenario**

To evaluate the scenario where the victim disclosed labeled data, we used a stratified 10-fold cross-validation scheme. For each fold, feature selection was performed using a Recursive Feature Elimination algorithm, and the classifier's accuracy was calculated.

Results, shown in Figure 6, indicate that the S&T attack achieves its lowest performance on Lenovo laptops, with a top-1 accuracy of 59.8% and a top-5 accuracy of 83.5%. On Macbook Pro and Toshiba, the top-1 accuracy was 83.23% and 73.3%, respectively, and the top-5 accuracy was 97.1% and 94.5%, respectively. These differences are likely due to variations in manufacturing quality.

**Figure 6: S&T attack performance – Complete Profiling scenario, Touch typing, Skype-filtered data, average accuracy.**

| Number of Guesses | 0% | 20% | 40% | 60% | 80% | 100% |
|-------------------|----|-----|-----|-----|-----|------|
| 0                 |    |     |     |     |     |      |
| 2                 |    |     |     |     |     |      |
| 4                 |    |     |     |     |     |      |
| 6                 |    |     |     |     |     |      |
| 8                 |    |     |     |     |     |      |
| 10                |    |     |     |     |     |      |

**More Realistic Small Training Set**

To simulate a more realistic scenario, we trained the classifier with a subset of training data that conforms to the letter frequency of the English language. The subset contained 105 samples, reflecting a typical short chat message or brief email. Results, shown in Figure 7, indicate a 30% accuracy loss, but the classifier still performs well with this small training set.

**Figure 7: S&T attack performance – Complete Profiling scenario, average accuracy, on a small subset of 105 samples that respects the letter frequency of the English language.**

| Number of Guesses | 0% | 20% | 40% | 60% | 80% | 100% |
|-------------------|----|-----|-----|-----|-----|------|
| 0                 |    |     |     |     |     |      |
| 2                 |    |     |     |     |     |      |
| 4                 |    |     |     |     |     |      |
| 6                 |    |     |     |     |     |      |
| 8                 |    |     |     |     |     |      |
| 10                |    |     |     |     |     |      |

**User Profiling Scenario**

In this scenario, the attacker profiles the victim on a laptop of the same model as the target device. The dataset of a particular user on one of the six laptops was used as the training set, and the dataset of the same user on another laptop of the same type was used to model the target device. If the target device is not in the database, the difference between the mean and the most-voted labels can be used to assess this. Consistently lower values (e.g., 0.21 vs 0.45) indicate an unknown laptop, prompting the attacker to obtain further information.