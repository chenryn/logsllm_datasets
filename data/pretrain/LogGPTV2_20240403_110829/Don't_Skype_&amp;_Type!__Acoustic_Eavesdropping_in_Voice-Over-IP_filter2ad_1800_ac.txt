accuracy and top-n accuracy measures. Given true values
of k, accuracy is deﬁned in the multiclass classiﬁcation case
as the fraction of correctly classiﬁed samples over all sam-
ples. Top-n accuracy is deﬁned similarly. The sample is
correctly classiﬁed if it is present among the top n guesses
of the classiﬁer.
To perform key classiﬁcation, we use a Logistic Regression
(LR) classiﬁer, since it outperformed all others, including:
Linear Discriminant Analysis (LDA), Support Vector Ma-
chines (SVM), Random Forest (RF), and k-nearest neigh-
bors. We show this in an experiment which uses each can-
didate to classify a dataset of 10 samples, for each of the
26 keys corresponding to the letters of the English alpha-
bet, in a 10-fold cross-validation scenario. We use MFCC
as features, and, for each classiﬁer, we optimize the hyper-
parameters with an extensive grid search.
Results are shown in Figure 4 which demonstrates that
the best performing classiﬁers are LR and SVM. This is
especially the case if the classiﬁer is allowed to make a small
number of predictions (between 1 and 5), which is more
realistic in an eavesdropping setting.
In particular, both
LR and SVM exhibit around 90% top-1 accuracy, and over
98.9% top-5 accuracy. However, LR slightly outperforms
SVM until top-4.
Figure 4: Average top-n accuracy of single key clas-
siﬁcation, as a function of the number of guesses, for
each classiﬁer.
0246810Numberofguesses0%20%40%60%80%100%AccuracyLRLDASVMRFk-NN7075. EVALUATION
To assess feasibility of S&T attack we conducted a set of
experiments that cover all previously described scenarios.
We chose Skype as the underlying VoIP software. There
are three reasons for this choice: (i) Skype is one of the
most popular VoIP tools [20, 1, 22]; (ii) its codecs are used
in Opus, an IETF standard [26], employed in many other
VoIP applications, such as Google Hangouts and Teams-
peak [21]; (iii) it reﬂects our general assumption about mono
audio. Therefore, we believe Skype is representative of a
wide range of VoIP software packages and its world-wide
popularity makes it appealing for attackers. Even though
our S&T evaluation is focused on Skype, preliminary results
show that we could obtain similar results with other VoIP
software, such as Google Hangouts.
We ﬁrst describe experimental data collection in Section 5.1.
Then, we discuss experimental results in Section 5.2. Next,
Section 5.3) considers several issues in using VoIP and Skype
to perform S&T attack, e.g., impact of bandwidth reduction
on audio quality, and the likelihood of keystroke sounds over-
lapping with the victim’s voice. Finally, in Section 5.4, we
report on S&T attack results in the context of two practi-
cal scenarios: understanding English words, and improving
brute-force cracking of random passwords.
5.1 Data Collection
We collected data from ﬁve distinct users. For each user,
the task was to press the keys corresponding to the English
alphabet, sequentially from “A” to “Z”, and to repeat the
sequence ten times, ﬁrst by only using the right index ﬁnger
(this is known as Hunt and Peck typing, referred to as HP
from here on), and then by using all ﬁngers of both hands
(Touch typing) [12]. We believe that typing letters in the or-
der of the English alphabet rather than, for example, typing
English words, did not introduce bias. Typing the English
alphabet in order is similar to typing random text, that S&T
attack targets. Moreover, a fast touch typist usually takes
around 80ms to type consecutive letters [7], and S&T attack
works without any accuracy loss with samples shorter than
this interval. In order to test correctness of this assumption,
we ran a preliminary experiment as follows:
We recorded keystroke audio of a single user on
a Macbook Pro laptop typing the English alpha-
bet sequentially from “A” to “Z” via Touch typ-
ing. We then extracted the waveforms of the let-
ters, as described in Section 4.1. However, in-
stead of extracting 100ms of the waveform, we
extracted 3ms [3], and from 10ms to 100ms at in-
tervals of 10ms for each step. We then extracted
MFCC and tested S&T attack in a 10-fold cross-
validation scheme. Figure 5 shows top-5 accu-
racy of this preliminary experiment, for diﬀerent
lengths of the sound sample that we extracted.
We observe that, even with very short 20ms samples, S&T
attack suﬀers minimal accuracy loss. Therefore, we believe
that adjacent letters do not inﬂuence each other, since sound
overlapping is very unlikely to occur.
Note that collecting only the sounds corresponding to let-
ter keys, instead of those for the entire keyboard, does not af-
fect our experiment. The “acoustic ﬁngerprint” of every key
is related to its position on the keyboard plate [3]. There-
fore, all keys behave, and are detectable, in the same way [3].
Figure 5: Top-5 accuracy of single key classiﬁcation
for diﬀerent sample lengths.
Due to this property, we believe that considering only let-
ters is suﬃcient to prove our point. Moreover, because of
this property, it would be trivial to extend our approach to
various keyboard layouts, by associating the keystroke sound
with the position of the key, rather than the symbol of the
key, and then mapping the positions to diﬀerent keyboard
layouts.
Every user ran the experiment on six laptops: (1) two Ap-
ple Macbooks Pro 13” mid 2014, (2) two Lenovo Thinkpads
E540, and (3) two Toshiba Tecras M2. We selected these as
being representative of many common modern laptop mod-
els: Macbook Pro is a very popular aluminium-case high-end
laptop, Lenovo Thinkpad E540 is a 15” mid-priced laptop,
and Toshiba Tecra M2 is an older laptop model, manufac-
tured in 2004. All acoustic emanations of the laptop key-
boards were recorded by the microphone of the laptop in
use, with Audacity software v2.0.0. We recorded all data
with a sampling frequency of 44.1kHz, and then saved it in
WAV format, 32-bit PCM signed.
We then ﬁltered the results by routing the recorded em-
anations through the Skype software, and recording the re-
ceived emanations on a diﬀerent computer (i.e., on the at-
tacker’s side). To do so, we used two machines running
Linux, with Skype v4.3.0.37, connected to a high-speed net-
work. During the calls, there was no sensible data loss. We
analyzed bandwidth requirements needed for data loss to oc-
cur, and the impact of bandwidth reduction, in Section 5.3.1.
At the end of data collection and processing phases, we
obtained datasets for all the ﬁve users on all six laptops,
with both the HP and Touch-typing styles. All datasets are
both unﬁltered, i.e., raw recordings from the laptop’s mi-
crophone, and ﬁltered through Skype and recorded on the
attacker’s machine. Each dataset consists of 260 samples,
10 for each of the 26 letters of the English alphabet. The
number of users and of laptops we considered often exceeds
related work on the topic [3, 11, 12, 19], where only a max-
imum of 3 keyboards were tested, and a single test user.
5.2 S&T Attack Evaluation
We evaluated S&T attack with all scenarios described in
Section 3.2. We evaluated Complete Proﬁling scenario in
detail, by analyzing performance of S&T attack separately
for all three laptop models, two diﬀerent typing styles, and
VoIP ﬁltered and unﬁltered data. We consider this to be
a favorable scenario for showing the accuracy of S&T at-
tack. In particular, we evaluated performance by consider-
ing VoIP transformation, and various combinations of lap-
31020304050607080100SampleLenght(ms)020406080100Top-5Accuracy708tops and typing styles. We then analyzed only the realistic
combination of Touch typing data, ﬁltered with Skype.
We evaluated S&T attack accuracy in recognizing single
characters, according to the top-n accuracy, deﬁned in [6],
as mentioned in Section 4.2.2. As a baseline, we considered
a random guess with accuracy x
l , where x is the number
of guesses, and l is the size of the alphabet. Therefore, in
our experimental setup, accuracy of the random guess is
x
26 , since we considered 26 letters of the English alphabet.
Because of the need to eavesdrop on random text, we can
not use “smarter” random guesses that, for example, take
into account letter frequencies in a given language.
5.2.1 Complete Proﬁling Scenario
To evaluate the scenario where the victim disclosed some
labeled data to the attacker, we proceeded as follows. We
considered all datasets, one at a time, each consisting of 260
samples (10 for every letter), in a stratiﬁed 10-fold cross-
validation scheme5. For every fold, we performed feature
selection on training data using a Recursive Feature Elimi-
nation algorithm [10]. We calculated the classiﬁer’s accuracy
over each fold, and then computed the mean and standard
deviation of accuracy values.
Figure 6 depicts results of the experiment on the realistic
Touch typing, Skype-ﬁltered data combination. We observe
that S&T attack achieves its lowest performance on Lenovo
laptops with top-1 accuracy of 59.8%, and a top-5 accuracy
83.5%. On Macbook Pro and Toshiba, we obtained a very
high top-1 accuracy, 83.23% and 73.3% respectively, and a
top-5 accuracy of 97.1% and 94.5%, respectively. We believe
that these diﬀerences are due to variable quality of manu-
facturing, e.g., the keyboard of our particular Lenovo laptop
model is made of cheap plastic materials.
in accuracy is a surprising 0.33%. This clearly shows that
Skype does not reduce accuracy of S&T attack.
We also ran a smaller set of these experiments over Google
Hangouts and observed the same tendency. This means that
the keyboard acoustic eavesdropping attack is applicable to
other VoIP software, not only Skype.
It also makes this
attack more credible as a real threat. We report these results
in more detail in Appendix A.
From now on, we only focus on the most realistic combi-
nation – Touch typing and Skype ﬁltered data. We consider
this combination to be the most realistic, because S&T at-
tack is conducted over Skype, and it is more common for
users to type with the Touch typing style, rather than the
HP typing style. We limit ourself to this combination to
further understand real-world performance of S&T attack.
5.2.2 A More Realistic Small Training Set
As discussed in Section 3.2, one way to mount S&T at-
tack in the Complete Proﬁling scenario is by exploiting data
accidentally disclosed by the victim, e.g., via Skype instant-
messaging with the attacker during the call. However, each
dataset we collected includes 10 repetitions of every letter,
from “A” to “Z”, 260 total. Though this is a reasonably low
amount, it has unrealistic letter frequencies. We therefore
trained the classiﬁer with a small subset of training data that
conforms to the letter frequency of the English language. To
do this, we retained 10 samples of the most frequent letters
according to the Oxford Dictionary [23]. Then, we randomly
excluded samples of less frequent letters until only one sam-
ple for the least frequent letters was available. Ultimately,
the subset contained 105 samples, that might correspond to
a typical short chat message or a brief email. We then eval-
uated performance of the classiﬁer trained with this subset,
on a 10-fold cross-validation scheme. This random exclu-
sion scheme was repeated 20 times for every fold. Results
on Touch typing Skype ﬁltered data are shown in Figure 7.
Figure 6: S&T attack performance – Complete Pro-
ﬁling scenario, Touch typing, Skype-ﬁltered data,
average accuracy.
Interestingly, we found that there is little diﬀerence be-
tween this data combination (that we consider the most un-
favorable) and the others. In particular, we compared aver-
age accuracy of S&T attack on HP and Touch typing data,
and found that the average diﬀerence in accuracy is 0.80%.
Moreover, we compared the results of unﬁltered data with
Skype ﬁltered data, and found that the average diﬀerence
5In a stratiﬁed k-fold cross-validation scheme, the dataset
is split in k sub-samples of equal size, each having the
same percentage of samples for every class as the complete
dataset. One sub-sample is used as testing data, and the
other (k − 1) – as training data. The process is repeated k
times, using each of the sub-samples as testing data.
Figure 7: S&T attack performance – Complete Pro-
ﬁling scenario, average accuracy, on a small subset
of 105 samples that respects the letter frequency of
the English language.
We incurred an accuracy loss of around 30% on every lap-
top, mainly because the (less frequent) letters for which we
have only a few examples in the training set are harder to
classify. However, performance of the classiﬁer is still good
enough, even with such a very small training set, composed
of 105 samples with realistic letter frequency. This further
motivates the Complete Proﬁling scenario: the attacker can
exploit even a few acoustic emanations that the victim dis-
closes via a short message during a Skype call.
0246810Numberofguesses0%20%40%60%80%100%AccuracyRandomguessMacbookProToshibaLenovo0246810Numberofguesses0%20%40%60%80%100%AccuracyRandomguessMacbookProLenovoToshiba7095.2.3 User Proﬁling Scenario
In this case, the attacker proﬁles the victim on a laptop of
the same model of target-device. We selected the dataset of a
particular user on one of the six laptops, and used it as our
training set. Recall that it includes 260 samples, 10 for every
letter. This training set modeled data that the attacker
acquired, e.g., via social engineering techniques. We used
the dataset of the same user on the other laptop of the same
type, to model target-device. We conducted this experiment
for all six laptops.
We now consider the case when the model of target-device is
not in the database. The attacker must ﬁrst determine that
this is indeed so. This can be done using the conﬁdence of
the classiﬁer. If target-device is in the database, most samples
are classiﬁed correctly, i.e., they “vote”correctly. However,
when target-device is not in the database, predicted labels for
the samples are spread among known models. One way to
assess whether this is the case is to calculate the diﬀerence
between the mean and the most-voted labels. We observed
that trying to classify an unknown laptop consistently leads
to a lower value of this metric: 0.21 vs 0.45. The attacker can
use such observations, and then attempt to obtain further in-