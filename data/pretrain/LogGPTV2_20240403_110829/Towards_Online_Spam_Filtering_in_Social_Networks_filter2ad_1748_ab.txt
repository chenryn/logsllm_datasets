atic to use them to detect OSN spam, because the under-
lying assumption is violated. The assumption is that spam
emails are sent out using SMTP servers running on large
number of infected ordinary end hosts, whereas legitimate
emails originate from a set of dedicated SMTP servers. As a
result, the spam senders’ IP neighborhood will be crowded
due to the botnet infection, but the IP addresses of legitimate
SMTP servers are far apart. Also because of the infection
pattern of botnet, spamming hosts tend to aggregate into
a small number of ASes, which makes sender AS number
a promising feature. At last, the spamming bots may not
listen to other service ports, but legitimate SMTP servers
will do so. Unfortunately, in OSNs both spam and legit-
imate messages are sent from ordinary end hosts. Given
the large number of OSN users, the sender’s IP neighbor-
hood is expected to be dense for both spam and legitimate
messages. In addition, there would be no difference in the
status of sender’s service ports for the two cases. At last,
spam senders may still be aggregated into a small number of
ASes. However, legitimate message senders will be mixed
e
g
a
s
s
e
M
f
o
%
 20
 15
 10
 5
 0
Spam Message
Legitimate Message
e
g
a
s
s
e
M
f
o
%
 30
 25
 20
 15
 10
 5
 0
Spam Message
Legitimate Message
e
g
a
s
s
e
M
f
o
%
 0
 200
 400
 600
 800
 1000
 0
 40
 80
 120
 160
 200
Message Size (Bytes)
# of Words
 40
 30
 20
 10
 0
 0
Spam Message
Legitimate Message
 10
 20
 30
 40
Average Word Length (Bytes)
Figure 2: Distribution of spam and legit-
imate message size, respectively. Each
bin is 20 bytes.
Figure 3: Distribution of spam and legit-
imate message word count, respectively.
Each bin is 5 words.
Figure 4: Distribution of average word
length of spam and legitimate messages,
respectively. Each bin is 1 byte.
into the same ASes and the effectiveness of sender AS num-
ber as a feature would be seriously degraded.
3.2 OSN Speciﬁc Features
OSN users form a huge social graph, where each node
represents an individual user. In Facebook-like OSNs, a so-
cial link would connect two nodes if the two corresponding
users have mutually agreed to establish a social connection.
Two users without a social link between them cannot di-
rectly interact with each other. Twitter-like OSNs impose
looser restrictions, where a user can “follow” anyone to
establish a directed social link, so that he can receive all
the updates. Similarly, the interaction history among users
forms an interaction graph.
Sender Social Degree Recent studies suggest that the ma-
jority of spamming accounts in OSNs are compromised ac-
counts [9, 10]. Meanwhile, research on modeling epidemics
in topological networks indicates that the more edges a node
has, with a higher probability it will be infected quickly by
an epidemic [6, 36]. On the other hand, the accounts created
by spammers also have an incentive to make large num-
ber of friends to open up communication channels. Con-
sequently, we hypothesize that spamming accounts have
higher degree in the social graph than legitimate accounts.
In Twitter-like OSNs, we deﬁne the social degree of one
node as the number of other nodes it “follows”, since this
number is controlled by the account itself. In Facebook-like
OSNs, there is no ambiguity as edges are not directed.
Figure 5 shows that our intuition is roughly correct. The
average social degree of spamming accounts is 59.2. It is
about 50% higher than that of legitimate accounts, which
is 40.8. Given such an observation, it is tempting to use
the message sender’s social degree as one feature. Un-
fortunately, the compromised spamming account will send
a mixture of spam and legitimate messages. Hence in
many cases spam and legitimate messages share the same
sender and will naturally have exactly the same value of the
sender’s social degree. However, after being organized into
 100
 80
 60
 40
 20
)
F
D
C
(
s
r
e
s
U
f
o
%
 0
 0
Spamming Account
Legitimate Account
 150
 300
 450
 600
Social Degree
Figure 5: Cumulative distribution of the social degree of
spamming and legitimate accounts, respectively.
clusters, the average senders’ social degree of the clusters
becomes an effective feature. The main reason is that all
senders in spam clusters are spamming accounts, while this
is very unlikely to be true for legitimate clusters. As a re-
sult, spam clusters are expected to exhibit higher average
senders’ social degree. Figure 6 conﬁrms this expectation.
It does not depict the clusters whose senders’ social degree
is not available in the dataset. Despite some overlapping
in the lower left region, the solid curve representing spam
clusters is to the right of the dashed curve representing le-
gitimate clusters. About 80% of legitimate clusters have an
average senders’ social degree of less than 400. In contrast,
this value is larger than 400 for about 50% of spam clusters.
Interaction History Although one account may establish
a large number of social links in the social graph, it only
interacts with a small subset of its friends [29]. However,
its behavior is expected to deviate from this pattern once the
account is compromised and under the control of spammers,
since the spammers desire to push spam messages to as
many recipients as possible. Consequently, a sudden burst
that the accounts start to interact with the friends that they
do not, or rarely, interact with before becomes a strong sig-
nal indicating spamming activities. Note that this intuition
 100
 80
 60
 40
 20
)
F
D
C
(
s
r
e
t
s
u
C
l
f
o
%
 0
 0
)
F
D
C
(
s
r
e
t
s
u
C
l
f
o
%
 100
 80
 60
 40
 20
 0
Spam Clusters
Legitimate Clusters
Spam Clusters
Legitimate Clusters
 300
 600
 900
 1200
 1500
 0
 1000
 2000
 3000
 4000
 5000
Average Social Degree
Cluster Size
Figure 6: Cumulative distribution of average senders’ social
degree of spam and legitimate clusters, respectively.
)
F
D
C
(
s
r
e
t
s
u
C
l
f
o
%
 100
 80
 60
 40
 20
 0
10-1
100
Spam Clusters
Legitimate Clusters
101
102
103
104
105
Interaction History Score
Figure 7: Cumulative distribution of interaction history
score of spam and legitimate clusters, respectively.
applies speciﬁcally to Facebook-like OSNs, since messages
are always broadcast to all followers in Twitter-like OSNs.
We use the notion of “interaction history score” to quan-
tify this intuition. The kth interaction between a user pair
is weighted 1/k, so that messages sent between user pairs
that rarely interact are given heavier weight values. As k in-
creases, the message weight between frequently interacting
user pairs decreases. We deﬁne the interaction history score
of a cluster as the sum of the message weight within the
cluster. Naturally, the spam clusters are expected to have
higher score because larger number of less frequently in-
teracting user pairs is contained. Figure 7 plots the CDFs
of this score for spam and legitimate clusters, respectively.
For the 20% clusters with the lowest scores, the expectation
is not always true. However, spam clusters indeed exhibit
higher score for the rest of the cases. Note that the x-axis
is in log scale. The score of spam clusters is usually several
times higher.
Figure 8: Cumulative distribution of spam and legitimate
cluster size, respectively.
3.3 General Features
We ﬁnd four additional features effective to discriminate
between spam and legitimate clusters. These features do not
need the social graph or the interaction graph to compute,
and could also apply to spam detection problems outside
OSNs. They are denoted as the general features.
Cluster Size Although each spamming account might not
generate large number of spam messages, the spam cam-
paign as a whole must contain large number of spam mes-
sages in order to be prosperous. Figure 8 plots the CDFs
of the size, measured as the number of message contained,
for spam and legitimate clusters, respectively. We observe
that about 50% of spam clusters’ size is less than 10, which
causes the overlapping part of the two curves. On the other
hand, large spam clusters exhibit a big difference in size
comparing with legitimate clusters. The overlapping of size
of small clusters does not make this feature invalid. The rea-
son is that small spam clusters only have minor impact on
the system’s detection performance. Instead, the big clus-
ters are those that matter. As an extreme example, it is still
acceptable even if the system correctly identiﬁes 10% of
spam clusters of size 1,000 while missing the remaining
90% of spam clusters of size 10.
Average Time Interval Known as the “bursty” property,
most spam campaigns involve coordinated action by many
accounts within short periods of time [30]. The effect is that
messages from the same campaign are densely populated in
the time period when the campaign is active. Consequently,
if we compute the intervals between the generation time of
consecutive messages in each cluster, the spam clusters are
expected have shorter intervals than the legitimate clusters.
From a statistical prospective, the median interval would
nicely quantify the “bursty” property, and is robust to out-
lier values. However, it is expensive to maintain during run-
time, as the complete list of intervals must be recorded and
 100
 80
 60
 40
 20
)
F
D
C
(
s
r
e
t
s
u
C
l
f
o
%
 0
100
101
 100
 80
 60
 40
 20
)
F
D
C
(
s
r