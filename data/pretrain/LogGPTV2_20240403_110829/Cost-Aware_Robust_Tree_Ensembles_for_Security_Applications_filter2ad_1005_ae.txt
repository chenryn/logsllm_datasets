models found by Kantchelian et al.’s MILP attack [29] is
on average 3.52⇥ and 1.7⇥ larger than regular training and
Chen’s method. On the other hand, there is only a 1.35% aver-
age drop of test accuracy and under 3% increase of false posi-
tive rate for the robust models compared to Chen’s method.
Accuracy under attack. Figure 8 shows the accuracy of mod-
els under different L• evasion distances of the MILP attack.
Our models maintain higher accuracy under attack than those
trained by Chen’s method for all datasets. In addition, our
models maintain higher accuracy under attack than regular
training, for all datasets except a small region for the breast-
cancer dataset (L• > 0.5).
Model quality evaluation. Figure 9 shows the ROC curves
and the Area Under the Curve (AUC) for random forest mod-
els trained with natural, Chen’s, and our training methods. For
three datasets (breast-cancer, cod-rna, and binary MNIST),
the ROC curve of our models are very close to the baseline
models, with at most 0.018 drop in AUC than Chen’s method.
However, our random forest model for the ijcnn1 dataset has
very low AUC (0.74853). The model has 92% test accuracy,
and the majority class of the test set is 90% negative class.
Note that the false positive rate for the model is only 0.08%
because the model does not predict the positive class very
often, and therefore it generates very few false positives. We
acknowledge the limitation of applying our algorithm in the
L• norm cost model for the ijcnn1 dataset. This also moti-
vates the need for cost models other than the L• norm. In
Section 4.3.4, we demonstrate that we can balance robustness
and accuracy using a cost model consistent with the semantics
of the features for Twitter spam detection, even though using
the L• cost model signiﬁcantly degrades the model quality.
4.2.4 Beneﬁts of our robust algorithm over existing
heuristics
According to Equation (8), our robust algorithm is designed
to maximize some impurity measure for each potential feature
split during the training process. The higher the score is ob-
tained by the algorithm, the stronger capability of the attacker
is used for training, which guides the model to learn stronger
robustness. Therefore, how well the algorithm can solve the
maximization problem directly determines the eventual ro-
bustness the models can learn. To that end, we measure how
our robust algorithm performs in solving the maximization
problem compared to the heuristics used in state-of-the-art
Chen and Zhang’s [11] to illustrate its effectiveness.
On the four benchmark datasets, we measure the percent-
age of the cases where our robust algorithms can better solve
2302    30th USENIX Security Symposium
USENIX Association
Dataset
breast-cancer
cod-rna
ijcnn1
0.26
4.66
1.11
6.33
99.74
94.13
90.31
87.98
Total
Better (%) Equal (%) Worse (%)
3,047
0
1.21
35,597
8.58 424,825
MNIST 2 vs. 6
5.69 796,264
Table 5: The percentage of the cases where our robust algo-
rithm performs better, equally well, or worse than the heuris-
tics used in the state-of-the-art Chen and Zhang et al.’s robust
training algorithms [11] in solving the maximization problem
(Equation 8). The total number of cases represent the total
number of splits evaluated during robust optimization.
the maximization problem than the heuristics used in [11]
and summarize the results in Table 5. The results show that
our robust algorithm can provide a better solution than heuris-
tics used in Chen and Zhang et al.’s method [11] for at least
87.98% cases during the whole training process. On small
datasets like breast-cancer and cod-rna, our algorithm per-
forms equally or better for 100% and 98.79% cases respec-
tively. Such signiﬁcant improvements in solving the max-
imizaation problem greatly beneﬁt the robustness of our
trained models. The results provide insights on why our ro-
bust training algorithm can obtain more robust tree ensembles
than existing training methods.
4.3 Twitter Spam Detection Application
In this section, we apply our robust tree ensemble training
method to a classic security application, spam URL detec-
tion on Twitter [35]. As a case study, we want to answer the
following questions in the evaluation:
• Cost-driven constraint: How to specify the cost-driven
constraint based on security domain knowledge? What
is the advantage of training cost-driven constraint com-
pared to L•-norm robustness?
• Accuracy vs robustness tradeoffs: How much does ro-
bustness affect accuracy? Do different ways of specify-
ing the cost-driven constraint change that tradeoffs?
• Adaptive attack cost: Against the strongest whitebox
attack [29], does the robust model increase the adaptive
attack cost for successful evasion?
• Other mathematical distances: Can we increase ro-
bustness against L1 and L2 based attacks?
4.3.1 Dataset
We obtain the public dataset used in Kwon et al.’s work [35]
to detect spam URLs posted on Twitter. Spammers spread
harmful URLs on social networks such as Twitter to distribute
malware, scam, or phishing content. These URLs go through
a series of redirections, and eventually reach a landing page
containing harmful content. The existing detectors proposed
in prior works often make decisions based on content-based
features that are strong in predictive power but easy to be
changed, e.g., different words used in the spam tweet. Kwon
et al. propose to use more robust features that incur monetary
or management cost to be changed under adversarial settings.
They extract these robust features from the URL redirection
chains (RC) and the corresponding connected components
(CC) formed by the chains.
Dataset
Malicious
Benign
Total
Training
130,794
165,076
295,870
Testing
55,732
71,070
126,802
Table 6: The size of Twitter spam dataset [35].
Feature Name
Description
Shared Resources-driven Features
EntryURLid
AvgURLid
ChainWeight
CCsize
CCdensity
MinRCLen
AvgLdURLDom
In degree of the largest redirector
Average in degree of
URL nodes in the RC
Total frequency of edges in the RC
# of nodes in the CC
Edge density of the CC
Min length of the RCs in the CC
Average domain # of
landing URL IPs in the CC
Average domain # for
the IPs in the RC
Cost
"
#
M N
M N
N
L
N
L
N
L
L
N
H
N
M N
L
L
L
L
L
L
L
N
N
N
N
N
N
H
H
N
M N
M N
N
L
L
N
N
L
Total geo distance (km)
traversed by the RC
# of unique continents in the RC
# of unique countries in the RC
# of unique IPs in the RC
# of unique domains in the RC
# of unique TLDs in the RC
Length of the RC
Distance from the initial URL
to the largest redirector
# of initial URLs in the CC
Total domain name #
in the initial URLs
# of ﬁnal landing URLs in the RC
Average IP # per URL in the RC
Average IP # per
landing URL in the CC
AvgURLDom
Heterogeneity-driven Features
GeoDist
CntContinent
CntCountry
CntIP
CntDomain
CntTLD
Flexibility Features
ChainLen
EntryURLDist
CntInitURL
CntInitURLDom
CntLdURL
AvgIPperURL
AvgIPperLdURL
User Account Features
Mention Count
Hashtag Count
Tweet Count
URL Percent
⇤ CC: connected component. RC: redirection chain.
BPH: bulletproof hosting. N: Negligible. L: Low. M: Medium. H: High.
Table 7: We reimplement 25 features used in [35] to detect
Twitter spam, among which three features have high cost to
decrease or increase. To maintain the same level of spam activ-
ities, the attacker needs to purchase more bulletproof hosting
servers to host the different landing pages if AvgLdURLDom
feature is decreased or AvgIPperLdURL feature is increased.
In addition, it is very hard for the attacker to decrease the
GeoDist feature.
# of ‘@’ count to mention other users
# of hashtags
# of tweets made by the user account
Percentage of user posts
that contain a URL
L
N
L
N
N M
N
L
USENIX Association
30th USENIX Security Symposium    2303
Feature extraction. We reimplemented and extracted 25
features from the dataset in the original paper, as shown in
Table 7. There are four families of features: shared resources-
driven, heterogeneity-driven, ﬂexibility-driven, and user ac-
count and post level features. The key intuitions behind the
features are as follows. 1) Attackers reuse underlying host-
ing infrastructure to reduce the economic cost of renting and
maintaining servers. 2) Attackers use machines hosted on bul-
letproof hosting services or compromised machines to operate
the spam campaigns. These machines are located around the
world, which tend to spread over larger geographical distances
than benign hosting infrastructure, and it is hard for attackers
to control the geographic location distribution of their infras-
tructure. 3) Attackers want to maximize the ﬂexibility of the
spam campaign, so they use many different initial URLs to
make the posts look distinct, and different domains in the long
redirection chains to be agile against takedowns. 4) Twitter
spammers utilize speciﬁc characters to spread harmful con-
tent, such as hashtags and ‘@’ mentions. We removed some
highly correlated features from the original paper. For exam-
ple, for a feature where the authors use both maximum and
average numbers, we use the average number only.
Kwon et al. labeled the dataset by crawling suspended users,
identifying benign users, and manually annotating tweets and
URLs. In total, there are 186,526 distinct malicious tweets
with spam URLs, and 236,146 benign ones. We randomly
split the labeled dataset into 70% training set and 30% testing
set as shown in Table 6. We extract the aforementioned 25
features from each data point and normalize the values to be
between 0 and 1 for training and testing.
4.3.2 Attack Cost Analysis
In order to obtain the cost-driven constraint for robust train-
ing, we ﬁrst analyze the cost of changing the features and the
direction of the changes, then we specify a box contraint for
the cost accordingly.
Feature Analysis We categorize the features into negligi-
ble (N), low (L), medium (M), and high (H) cost to change,
as shown in Table 7. We analyze the cost based on feature
families as follows.
• Shared resources: All features cost more to be decreased
than to be increased. If the attacker decreases the reused
redirectors in the chain, the attacker needs to set up addi-
tional redirector servers to maintain the same level of spam
activities (EntryURLid and AvgURLid features). It costs
even more to set up more servers for the landing pages,
since the landing URLs contain actual malicious content,
which are usually hosted on bulletproof hosting (BPH) ser-
vices. Feature AvgLdURLDom captures how the attacker
is reusing the malicious content hosting infrastructure. If
the value is decreased, the attacker will need to set up more
BPH severs, which has the highest cost in the category.
• Heterogeneity: The total geographical distance traversed
by the URL nodes in the redirection chain has the highest
cost to change in general (GeoDist). If the attacker uses all
the available machines as resources for malicious activities,
it is hard to control the location of the machines and the
distance between them. Overall, it is harder to decrease
GeoDist to what looks more like benign value than to in-
crease it. Since GeoDist values for benign URL redirection
chains are very concentrated in one or two countries, the
attacker would need to purchase more expensive resources
located close by to mimic benign URL. The other four
features that count number of continents, countries, IPs,
domains, and top-level domains incur cost for decreased
ﬂexibility and increased maintainence cost if the features
are decreased.
• Flexibility: All features in this family except the last one
have relatively low cost to decrease, because that decreases
the ﬂexibility of the attack. The high cost feature AvgIP-
perLdURL counts the number of IP addresses that host the
malicious landing page URL. If the attacker wants more
ﬂexibility of hosting the landing page on more BPH servers,
the cost will be increased signiﬁcantly.
• User account: Increasing features in this family generally
increases suspiciousness of the user account. Among them,
increasing the tweet count is the most suspicious of all,
since a tweet is capped by 140 characters which limits
the number of mentions and hashtags, and percentage of
posts containing URLs is also capped. If a user account
sends too many tweets that puts the account to the top
suspicious percentile, it can be easily detected by simple
ﬁltering mechanism and compromise the account.
Overall, three features have the highest cost to be perturbed:
AvgLdURLDom, GeoDist3, and AvgIPperLdURL. Decreas-
ing AvgLdURLDom and increasing AvgIPperLdURL incurs
cost to obtain more bulletproof hosting servers for the landing
page URL, and manipulating GeoDist is generally outside the
control of the attacker. Other types of actions can also achieve
the changes in AvgLdURLDom and AvgIPperLdURL, but it
will generally decrease the proﬁt of the malicious operation.
To decrease AvgLdURLDom, if the attacker does not rent
more BPH servers but only reduces the number of malicious
landing pages, that reduces the proﬁt. If the attacker increases
the AvgIPperLdURL by using cheap servers, their malicious
content could be taken down more often that interrupts the
malicious operation.
4.3.3 Box Constraint Speciﬁcation
We specify box constraint according to Section 3.1.3 with
19 different cost models as shown in Table 8, from M1 to
M19. We want to allow more perturbations for lower cost
3GeoDist, CntContinent and CntCountry have similar intuition, but we
choose GeoDist since it has ﬁner granularity in feature values.
4https://tinyurl.com/2b5egv49.
2304    30th USENIX Security Symposium
USENIX Association
Classiﬁer
Model
Natural
C1 e = 0.03
C2 e = 0.05
C3 e = 0.1
M1
M2
M3
M4
M5
M6