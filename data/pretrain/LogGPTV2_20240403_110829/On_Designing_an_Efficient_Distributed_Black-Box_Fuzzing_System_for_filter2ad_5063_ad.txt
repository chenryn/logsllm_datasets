GIF, JPEG, PNG, MP3 and MP4 video. The fuzzing ex-
periments were run for 2 weeks and the crashes are analysed
by CACE. As we are still investigating several crashes to
discover the vulnerabilities and to prevent attackers from
exploiting them, we have anonymised the device identities.
SFAT Metrics
For every stage of the vulnerability discovery pipeline, we
deﬁne groups of metrics for our experimental ﬁndings cate-
gorised below:
3.2.1
We evaluated all fuzzed results across all devices based on
fuzzes created from 2 diﬀerent mpeg-4 seed ﬁles across all de-
vices. One mp4 ﬁle has lower ﬁeld scores, ﬁeld occurance scores
and occurancedistributionscores compared to the second mp4
ﬁle. The number of unique crashes and total number of
crashes identiﬁed for each seed ﬁle to evaluate the eﬀective-
ness of SFAT.
3.2.2 FEET Metrics
We ran some GIF fuzzing experiments without FEET on
several devices running Android 4.0.4 and compared the re-
38FEET
Without FEET
With FEET
Job ID #Crashes #Unique Bugs
1
2
3
4
5
6
7
8
9
1
2
3
4
5
6
7
8
9
1
0
0
0
0
0
0
0
0
0
0
3
3
6
0
0
0
2
1
0
0
0
0
0
0
0
0
0
0
1
1
1
0
0
0
1
Table 3: Fuzzing on Android 4.0.4 Device 1 with and
without FEET
sults with FEET to ascertain its eﬀectiveness. A total of
9 jobs with 10000 ﬁles each were tested. The job IDs are
fuzzed in order - i.e., ID 1 is fuzzed ﬁrst and 9 last. We
derived the following metrics to measure the eﬀectiveness:
(a) Uniqueness
FEET tests the uniqueness of fuzz ﬁles produced by
each fuzz conﬁguration.A job in this experiment con-
sisted of 10,000 fuzzed ﬁles. The more uniqueness a
job has, the more diverse the individual test ﬁles in it.
We of course prefer to maximise the uniqueness per-
centage as this means we are fuzzing more variety of
ﬁles which in turn promises more chances of striking a
crash.
3.3.1 FEET Results
(a) Uniqueness
Table 2 shows the percentage uniqueness of jobs dis-
tributed to clients. From the Table 2, we see that
out of the 100,000 ﬁles in this experiment (10 jobs *
10,000 ﬁles per job), using FEET provides an average
uniqueness factor of 96.67% compared to an average
uniqueness factor of 85.11% without FEET.
For illustration purposes, let us consider that testing
one JPG image on an iPhone takes 1 second (in real-
ity, the time taken is much lesser). Let us have two
iPhones side by side - one fuzzing inputs processed by
FEET, and the other fuzzing inputs without FEET.
Given 100,000 seconds, the ﬁrst iPhone would have
processed 96,670 unique images whereas the second
iPhone would have processed 85,100 unique images.
We can say the ﬁrst iPhone “wasted” 3330 seconds out
of 100,000 (a ratio of 0.033) whereas the second iPhone
“wasted” 14,900 seconds (a ratio of 0.149) or around 4.5
times as much wastage. This gap only widens when we
fuzz for longer durations.
(b) Crash Arrival Rate Comparison In Table 3, it can
be seen that without using FEET, the device encoun-
tered the ﬁrst crash in its ﬁrst fuzzing job. However,
that is the only crash found; hence this crash could
be a one-oﬀ incident. Remaining jobs do not yield
any crashes. This is in contrast with the utilisation
of FEET to ﬁrst determine uniformity and uniqueness
of resulting conﬁgurations before generating patches.
Crashes come only from the 3rd job onwards.
(c) Number of Crashes
There are 14 crashes discovered on the Android 4.0.4
device using FEET selected fuzzing conﬁgurations.
(b) Crash Arrival Rate
(d) Variety of Bugs
We ﬁrst compare the crash arrival rate, i.e. how fast
can a crash be obtained using FEET selected fuzzing
conﬁgurations against randomly selected fuzzing con-
ﬁgurations.
(c) Number of Crashes
We also compare the number of crashes obtained us-
ing FEET selected fuzzing conﬁgurations against ran-
domly selected fuzzing conﬁgurations.
(d) Variety of bugs
How many unique bugs are discovered using FEET se-
lected fuzzing conﬁgurations against randomly selected
fuzzing conﬁgurations.
STAMP Metrics
3.2.3
We analyse the speedup using distributed fuzzing 10,000
ﬁles against a ﬁxed number of fuzzes.
3.3 Experimental Results
Please note that we have anonymised the device identities
because we are still investigating several crashes to discover
vulnerabilities.
For the GIF ﬁle format, there is only one bug discov-
ered by both FEET selected and randomly selected
conﬁgurations.
Device
Version
File
Format
Device 1
Device 1
Device 2
Device 3
Device 4
Device 5
Device 6
Device 7
Device 8
Device 9
Device 10
Android 2.3.x GIF
Android 2.3.x MP4
Android 4.0.x GIF
Android 4.0.x GIF
Android 4.1.x PNG
Android 4.2.x MP3
Android 4.3.x MP3
iOS 6.x
iOS 6.x
iOS 6.x
iOS 6.1.x
JPEG
MP3
JPEG
JPEG
Crash
Count
825
9
253
708
19
27
13
25
1
12
9
#Unique
bugs
1
2
1
1
1
2
2
1
0
1
1
Table 5: Table of top 10 devices with maximum
crashes found using STAMP.
39Seed File
1.mp4
2.mp4
I
367.4
234.8
Field Occurance Score Mean/StdDeviation
77.64
33.2
0.2
0.66
Size (KB) #Unique Bugs #Total Crashes
162
296
2
1
8
1
Table 4: Field score and occurance score for 2 mp4 ﬁles. Lesser score is better (See Section 2.1.2)
SFAT results
3.3.2
As the result shows in Table 4, the 1st ﬁle with higher
ﬁeld and occurance scores generally yield an overall better
number of unique crashes and total crashes. We can con-
clude that SFAT’s scoring mechanism is eﬀective for ﬁnding
a good seed ﬁle. The additional crashes are due to a loca-
tion of the ﬂag change corresponding to the size value of an
TBPM (beats per minute) which is not present in 2.mp4.
3.3.3 STAMP results
Within the span of 2 weeks, STAMP conducted close to 5
million test cases and uncovered close to 1900 unique crash-
ing inputs in both Android and iOS devices aﬀecting GIF,
JPEG, PNG, MP3 and MP4 video ﬁles. The speedup ob-
tained (as shown in Table 6) from distributed parallel fuzzing
of 4 devices of the same model achieves a better than ex-
pected 5.27. This is likely due to less (or no) crashes hap-
pening on some devices in parallel. Network latency may
also play a part.
Overall, fuzzing speed depends on the ﬁle-type fuzzed.
Video and audio ﬁles are signiﬁcantly slower as they have to
be played back even though the duration of all seed ﬁles are
1 second.
#GIF ﬁles
fuzzed
10000
#Devices
4
1
Time
Taken
55 min
290 min
Table 6: Speedup obtained with distributed fuzzing
Times include downloading, patching and fuzzing.
3.3.4 CACE - Variety of bugs
CACE triaged all discovered crashes discovered into 7 dif-
ferent bugs. They are detailed in Table 5. CACE traced
the 1786 GIF crashes to a single bug in the LZW compres-
sion algorithm located in the Android 2D graphics library.
That crash is an invalid read access and is not likely to be
exploitable. On the other hand CACE deduced that the 19
PNG crashes are due to a potentially exploitable write to an
invalid memory location also in the same Android 2D graph-
ics library. The MP3 crash indicates an invalid address or
address of corrupt block passed to dlfree to release mem-
ory. Further up the stack,it is actually discovered that the
real error happened in the utilities library, where Android
was actually trying to free a shared StringBuffer. This
appears to be a use-after-free vulnerability. However, when
libc is examined with IDA Pro, r3 points to the address
0xdeadbaad [25] intentionally to cause a segment violation
and forcibly abort the playback. This is a countermeasure
to address a possible heap corruption while rendering the
ﬁle. The crash for MP3 is due to the TBPM ﬂag set, a tag
that is not always used in MP3 ﬁles; indicating the impor-
tance of fuzzing with a high coverage seed ﬁle. The single
discovered JPEG crash for iOS is a memory leak bug where
an extraordinarily large image dimensions are provided in
a much smaller JPEG ﬁle. All bugs are reported to their
respective manufacturers thus the anonymisation of the vul-
nerability information. We do not yet know if the bugs have