The ﬁrst distance met-
ric involves locating the common subsequences of vary-
ing lengths between two clickstreams. We formalize
a clickstream as a sequence S = (s1s2...si...sn), where
is the ith element in the sequence. We then de-
si
ﬁne Tk as the set of all possible k-grams (k consecu-
246  22nd USENIX Security Symposium 
USENIX Association
tive elements) in sequence S: Tk (S) = {k-gram|k-gram =
(sisi+1...si+k−1),i ∈ [1,n + 1 − k]}. Simply put, each k-
gram in Tk (S) is a subsequence of S. Finally, the distance
between two sequences can then be computed based on
the number of common subsequences shared by the two
sequences. Inspired by the Jaccard Coefﬁcient [19], we
deﬁne the distance between sequences S1 and S2 as:
Dk(S1,S2) = 1 −
|Tk (S1) ∩Tk(S2)|
|Tk (S1) ∪Tk(S2)|
(1)
We will discuss the choice of k in Section 4.2.2.
Common Subsequences With Counts.
The com-
mon subsequence metric deﬁned above only measures
distinct common subsequences, i.e. it does not consider
the frequency of common subsequences. We propose a
second distance metric that rectiﬁes this by taking the
count of common subsequences into consideration. For
sequences S1, S2 and a chosen k, we ﬁrst compute the
set of all possible subsequences from both sequences as
T = Tk(S1) ∪ Tk(S2). Next, we count the frequency of
each subsequence within each sequence i (i = 1,2) as ar-
ray [ci1,ci2, ...,cin] where n = |T |. Finally, the distance
between S1 and S2 can be computed as the normalized
Euclidean Distance between the two arrays:
(2)
(c1j −c2j)2
D(S1,S2) = 1√2(cid:31) n
∑
j=1
Distribution-based Method.
Unfortunately, the
prior metrics cannot be applied to sequences of contin-
uous values (i.e. the Time-based Model).
Instead, for
continuous value sequences S1 and S2, we compute the
distance by comparing their value distribution using a
two-sample KolmogorovSmirnov test (K-S test). A two-
sample K-S test is a general nonparametric method for
comparing two empirical samples. It is sensitive to dif-
ferences in location and shape of the empirical Cumu-
lative Distribution Functions (CDF) of the two samples.
We deﬁne the distance function using K-S statistics:
D(S1,S2) = supt |Fn,1(t ) −Fn′,2(t )|
(3)
where Fn,i(t ) is the CDF of values in sequence Si.
4.2.2 Applying Distances Functions to Clickstreams
Having deﬁned three distance functions for computing
sequence similarity, we now apply these metrics to our
three clickstream models. Table 4 summarizes the dis-
tance metrics we apply to each of our models. The Time-
based Model is the simplest case, because it only has one
corresponding distance metric (K-S Test). For the Click
Sequence and Hybrid Models, we use several different
parameterizations of our distance metrics.
Model
Click Sequence Model
Time-based Model
Hybrid Model
Distance Metrics
unigram, unigram+count,
10gram, 10gram+count
K-S test
5gram, 5gram+count
Table 4: Summary of distance functions.
Click Sequence Model. We use the common subse-
quence and common subsequence with counts metrics to
compute distances in the CS model. However, these two
metrics require that we choose k, the length of k-gram
subsequences to consider. We choose two values for k: 1
and 10, which we refer to as unigram and 10gram. Un-
igram represents the trivial case of comparing common
click events in two clickstreams, while ignoring the or-
dering of clicks. 10gramincludes all unigrams, as well as
bigrams, trigrams, etc. As shown in Table 4, we also in-
stantiate unigram+count and 10gram+count, which in-
clude the frequency counts of each unique subsequence.
Although values of k > 10 are possible, we limit our
experiments to k = 10 for two reasons. First, when k = n
(where n is the length of a clickstream), the computa-
tional complexity becomes O(n2). This overhead is sig-
niﬁcant when you consider that O(n2) subsequences will
be computed for every user in a clickstream dataset. Sec-
ond, long subsequenceshave diminishing utility, because
they are likely to be unique for a particular user. In our
tests, we found k = 10 to be a good limit on computa-
tional overhead and subsequence over-speciﬁcity.
Hybrid Model.
Like the Click Sequence Model, dis-
tances between sequences in the Hybrid Model can also
be computed using the common subsequence and com-
mon subsequence plus count metrics. The only change
between the Click Sequence and Hybrid Models is that
we must discretize the inter-arrival times between clicks
so they can be encoded into the sequence. We do this
by placing inter-arrival times into log-scale buckets (in
seconds):
[0,1], [1,10], [10,100], [100,1000], [1000,∞].
Based on Figure 6, the inter-arrival time distribution is
highly skewed, so log-scale buckets are better suited than
linear buckets to evenly encode the times.
After we discretize the inter-arrival times and insert
them into the clickstream, we use k = 5 as the parameter
for conﬁguringthe two distance metrics. Further increas-
ing k offers little improvement in the model but intro-
duces extra computation overhead. As shown in Table 4,
we refer to these metrics as 5gram and 5gram+count.
Thus, each 5gram contains three consecutive click events
along with two tokens representing inter-arrival time
gaps between them.
USENIX Association  
22nd USENIX Security Symposium  247
)
%
(
e
t
a
R
r
o
r
r
E
 10
 8
 6
 4
 2
 0
False Positive
False Negative
(Activities)
(Categories)
CS Hybrid CS Hybrid
Models
Time
)
%
(
e
t
a
R
r
o
r
r
E
 7
 6
 5
 4
 3
 2
 1
 0
False Positive
False Negative
(CS Model)
(Hybrid Model)
unigram
10gram
unigram-c
10gram-c
Distance Functions
5gram
5gram-c
)
%
(
e
t
a
R
r
o
r
r
E
 6
 5
 4
 3
 2
 1
 0
False Positive
False Negative
10 20 30 40 50 60 70 80 90 100
# of Clusters (Hybrid Model)
Figure 8: Error rate of three models.
Figure 9: Error rate using different
distance functions.
Figure 10: Impact of number of clus-
ters (K).
4.3 Sequence Clustering
At this point we have deﬁned models of clickstreams
as well as metrics for computing the distance between
them. Our next step is to cluster users with similar click-
streams together. As shown in Section 3, Sybil and nor-
mal users exhibit very different behaviors, and should
naturally form distinctive clusters.
To achieve our goal, we build and then partition a
sequence similarity graph. Each user’s clickstream is
represented by a single node. The sequence similarity
graph is complete, i.e. every pair of nodes is connected
by a weighted edge, where the weight is the similarity
distance between the sequences. Partitioning this graph
means producing the desired clusters while minimizing
the total weight of cut edges: users with similar activi-
ties (high weights between them) will be placed in the
same cluster, while users with dissimilar activities will
be placed in different clusters. Thus the clustering pro-
cess separates Sybil and normal users. Note that not all
Sybils and normal users exhibit homogeneous behavior;
thus, we expect there to be multiple, distinct clusters of
Sybils and normal users.
Graph Clustering.
To cluster sequence similarity
graphs, we use METIS [18], a widely used multilevel k-
way partitioning algorithm. The objective of METIS is
to minimize the weight of edges that cross partitions. In
the sequence similarity graph, longer distances (i.e. dis-
similar sequences) have lower weights. Thus, METIS
is likely to place dissimilar sequences in different parti-
tions. METIS requires a parameter K that speciﬁes the
number of partitions desired. We will assess the impact
of K on our system performance in Section 4.4.
Cluster Quality.
A key question when evaluat-
ing our methodology is assessing the quality of clus-
ters produced by METIS. In Section 4.4, we leverage
our ground-truth data to evaluate false positives and
negatives after clustering the sequence similarity graph.
We label each cluster as “Sybil” or “normal” based on
whether the majority of nodes in the cluster are Sybils
or normal users. Normal users that get placed into Sybil
clusters are false positives, while Sybils placed in normal
clusters are false negatives. We use these criteria to eval-
uate different clickstream models and distance functions.
4.4 Model Evaluation
We now evaluate our clickstream models and distance
functions to determine which can best distinguish Sybil
activity patterns from those of normal users. We examine
four different variables: 1) choice of clickstream model,
2) choice of distance function for each model, 3) what
representation of clicks to use (speciﬁc activities or cat-
egories), and 4) K, the number of desired partitions for
METIS.
Experiment Setup.
The experimental dataset con-
sists of 4000 normal users and 4000 Sybils randomly se-
lected from our dataset. In each scenario, we build click
sequences for each user (based on a given clickstream
model and click representation), compute all distances
between each pair of sequences, and then cluster the re-
sulting sequence similarity graph for a given value of K.
Finally, each experimental run is evaluated based on the
false positive and negative error rates.
Model Analysis.
First, we examine the error rates
of different clickstream models and click representations
in Figure 8. For the CS and Hybrid models, we en-
code clicks based on activities as well as categories.
In the Time model, all clicks are encoded as inter-
arrival times. In this experiment, we use 10gram+count,
5gram+count, and K-S as the distance function for CS,
Hybrid, and Time, respectively. We ﬁx K = 100. We in-
vestigate the impact of distance functions and K in sub-
sequent experiments.
Two conclusions can be drawn from Figure 8. First,
the CS and Hybrid models signiﬁcantly outperform the
Time-based model, especially in false negatives. This
demonstrates that click inter-arrival times alone are in-
sufﬁcient to disambiguate Sybils from normal users.
Manual inspection of false negative Sybils from the Time
experimentreveals that these Sybils click at the same rate
as normal users. Thus these Sybils are either operated by
real people, or the software that controls them has been
intentionally rate limited.
248  22nd USENIX Security Symposium 
USENIX Association
The second conclusion from Figure 8 is that encod-
ing clicks based on category outperforms encoding by
activity. This result conﬁrms ﬁndings from the existing
literatures on web usage mining [3]: representing clicks
using high-level categories (or concepts) instead of raw
click types better exposes the browsing patterns of users.
A possible explanation is that high-level categories have
better tolerance for noise in the clickstream log. In the
rest of our paper, we use categories to encode clicks.
Next, we examine the error rate of different distance
functions for the CS and Hybrid models. As shown in
Figure 9, we evaluate the CS model using the unigram
and 10gram functions, as well as counting versions of
those functions. We evaluate the Hybrid model using the
5gram and 5gram+count functions.
Several conclusions can be drawn from Figure 9. First,
the unigram functions have the highest false negative
rates. This indicates that looking at clicks in isolation
(i.e. without click transitions) is insufﬁcient to discover
many Sybils. Second, the counting versions of all three
distance functions produce low false positive rates. This
demonstrates that the repeat frequency of sequences is
important for identifying normal users. Finally, we ob-
serve that CS 10gram+countand Hybrid have similar ac-
curacy. This shows that click inter-arrival times are not
necessary to achieve low error rates.
Finally, we examine the impact of the number of clus-
ters K on detection accuracy. Figure 10 shows the error
rate of Hybrid 5gram+count as we vary K. The overall
trend is that larger K produces lower error rates. This
is because larger K grants METIS more opportunities to
partition weakly connected sequences. This observation
is somewhat trivial: if K = N, where N is the number
of sequences in the graph, then the error rate would be
zero given our evaluation methodology. In Section 6, we
discuss practical reasons why K must be kept ≈100.
Summary.
Our evaluation shows that the Click
Sequence and Hybrid models perform best at disam-
biguating Sybils and normal users. 10gram+count and
5gram+count are the best distance functions for each
model, respectively. We ﬁnd that accuracy is highest
when clicks are encoded based on categories, and when
the number of partitions K is large. In the following sec-
tions, we will use these parameters when building our
Sybil detection system.
5 Incremental Sybil Detection
Our results in Section 4 showed that our models can ef-
fectively distinguish between Sybil clickstreams and nor-
mal user clickstreams. In this section, we leverage this
methodology to build a real-time, incremental Sybil de-
tector. This system works in two phases: ﬁrst, we cre-
ate clusters of Sybil and normal users based on ground-
truth data, as we did in Section 4. Second, we compute
the position of unclassiﬁed clickstreams in our sequence
similarity graph. If an unclassiﬁed clickstream falls into
a cluster representing clickstreams from ground-truth
Sybils, we conclude the new clickstream is a Sybil. Oth-
erwise, it is benign.
5.1 Incremental Detection
To classify a new clickstream given an existing clustered
sequence similarity graph, we must determine how to
“re-cluster” new sequences into the existing graph. We
investigate three algorithms.
The ﬁrst is K Nearest Neighbor (KNN). For a given
unclassiﬁed sequence, we ﬁnd the top-K nearest se-
quences in the ground-truth data. If the majority of these
sequences are located in Sybil clusters, then the new se-
quence is classiﬁed as a Sybil sequence.
The second algorithm is Nearest Cluster (NC). We
compute the average distance from an unclassiﬁed se-
quence to all sequences in each cluster. The unclassiﬁed
sequence is then added to the cluster with the closest av-
erage distance. The new sequence is classiﬁed as Sybil
or normal based on the cluster it is placed in.
The third algorithm is a less computationally-intensive
version of Nearest Cluster that we refer to as Nearest
Cluster-Center (NCC). NC and KNN require comput-
ing the distance from an unclassiﬁed sequence to all se-
quences in the ground-truth clusters. We can streamline
NC’s classiﬁcation process by precomputing centers for
each cluster. In NCC, we only need to compute the dis-
tance from an unclassiﬁed sequence to the center of each
existing cluster.
For each existing cluster, the center is chosen by close-
ness centrality. Intuitively, the center sequence is the one
that has the shortest distance to all the other sequences
in the same cluster. To be more robust, we precompute
three centers for each cluster, that is, the three sequences
with highest closeness centrality.
5.2 System Evaluation
In this section, we evaluate our incremental Sybil detec-
tion system using our ground-truth clickstream dataset.
We start by evaluating the basic accuracy of the system at
classifying unknown sequences. Next, we evaluate how
quickly the system can identify Sybils, in terms of num-
ber of clicks in their clickstream. Finally, we explore
how long the system can remain effective before it needs
to be retrained using updated ground-truth data.
Detection Accuracy. We start with a basic evaluation
of system accuracy using our ground-truth dataset. We
split the dataset into training data and testing data. Both
datasets include 3000 Sybils and 3000 normal users. We
build sequence similarity graphs from the training data
USENIX Association  
22nd USENIX Security Symposium  249
)
%
(
e
t
a
R
r
o
r
r
E
 5