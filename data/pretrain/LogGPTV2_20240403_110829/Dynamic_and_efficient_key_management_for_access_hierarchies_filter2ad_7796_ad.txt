a single node, but when the tree size becomes ≤ √n. This
means that there are at most √n successive centroids that
are aﬀected by the “prematurely terminated” decomposition
(as opposed to n of them for the standard decomposition).
We call these centroids, as well as the root of T , the spe-
cial nodes. Note that, by construction, removing the special
nodes from T leaves connected components of size at most
√n each; we call these connected components (which are
trees) the “residual” trees and denote them by T1, . . . , Tk.
We also use the notion of a “reduced tree” ˆT . The tree
ˆT consists of the O(√n) special nodes and of edges that
satisfy the following condition: There is an edge from node
x to node y in ˆT iﬀ (i) x is an ancestor of y in T , and (ii)
there is no other node of ˆT on the x-to-y path in T .
Now we are ready to describe the overall recursive proce-
dure for adding shortcuts. In what follows, |T| denotes the
number of vertices in T .
AddShortcuts(T ):
1. If |T| ≤ 4 then return an empty set of shortcuts. Oth-
erwise continue with the next step.
2. Compute the special nodes of T in linear time. Initial-
ize the set of shortcuts S to be empty.
3. Create, from T , the reduced tree ˆT and add to S a
shortcut edge between every ancestor-descendant pair
in ˆT (unless the ancestor is a parent of the descen-
dant, in which case there is already such an edge in
T ). Because ˆT has O(p|T|) vertices, the size of S is
O(|T|).
size of S by no more than Pk
4. For every residual tree Ti in turn (i = 1, . . . , k), add to
S a shortcut edge from the root of Ti to every node in
Ti that is not a child of that root. This increases the
i=1 |Ti|, which is ≤ |T|.
5. For every residual tree Ti in turn (i = 1, . . . , k), recur-
sively call AddShortcuts(Ti) and, if we let Si be the
set of shortcuts returned by that recursive call, then
we update S by doing S = S ∪ Si.
6. Return S.
The number f (|T|) of shortcut edges added by the above
recursive procedure obeys the recurrence
f (|T|) = 8 4
f (|Ti|)
where every |Ti| is ≤ √n, and c1 is a constant. A straight-
forward induction proves that this recurrence implies that
f (|T|) = O(|T| log log |T|). Therefore the space for the pub-
lic data is O(n log log n), due to the creation of the f (n)
shortcut edges.
We now turn our attention to showing that, for every
ancestor-descendant pair x and y in T , there is now, due to
the shortcuts, an x-to-y path of length O(log log |T|). The
recursive procedure for ﬁnding such a path is given next,
and mimics the recursion of AddShortcuts() (uses same
ˆT , same Ti’s, etc.). In it, we use Length(n) to denote the
worst-case length of a shortest ancestor-to-descendant path
that can avail itself of the shortcuts generated in the above
AddShortcuts().
FindPath(x, y, T ):
1. If T| ≤ 4 then trace a path from x to y along T and
return that path. If |T| > 4 continue with the next
step.
2. If x and y are both special in T (i.e., both are nodes
of ˆT ) then return the edge (x, y). (Note that such an
edge exists because of Step 3 in AddShortcuts().) If
x and/or y is not special, then proceed to the next
step.
3. Let Ti be the residual tree containing x, and let Tj
be the residual tree containing y.
If i = j then we
recursively call FindPath(x, y, Ti), which returns a
path in Ti that is of length ≤ Length(|Ti|), which is
≤ Length(p|T|). We return that path. If i 6= j (i.e.,
x and y are in diﬀerent residual trees) then we proceed
as follows:
(a) We recursively call FindPath(x, z, Ti) where z is
the node of Ti that is nearest to y in T (hence
z is a leaf of Ti, and one of its children z0 in T
is a special node that is ancestor of y in T ). The
length of this x-to-z path is ≤ Length(|Ti|), which
is at most Length(p|T|). This path is the initial
portion of the path P that will be returned by the
recursive call (P will be further built in the steps
that follow).
(b) Follow the edge in T from z to the special node z0
that is ancestor of y in T , and append that edge
(z, z0) to P.
(c) Follow (and append to P) the edge in ˆT from
special node z0 to the special node (call it u) that
is the special ancestor of y that is nearest to y
(hence u is parent of the root of the residual tree
Tj that contains y). Note that such an edge exists
because of Step 3 in AddShortcuts(). If u = y
then return P, otherwise continue with the next
step.
(d) Follow (and append to P) the edge in T from u
to the root of Tj .
(e) Follow (and append to P) the edge from the root
of Tj to y; such an edge exists because of Step 4
in AddShortcuts().
(f) Return P.
The recurrence for Length implied by the above recursive
procedure is:
Length(|T|) = Length(|T|) ≤ c2
if |T| ≤ 4
Length(|T|) ≤ c3 + Length(p|T|) if |T| > 4
where every |Ti| is ≤ √n, and the ci’s are constants. A
straightforward induction proves that this recurrence implies
that Length(|T|) = O(log log |T|). Therefore the worst-case
time for key derivation is O(log log n).
The next section deals with decreasing the space complex-
ity of the public information to O(n).
6.3 Improving the Space Complexity
We begin with a pre-processing step of T that consists of
carrying out “prematurely terminated centroid decomposi-
tion” similar to the one used in the previous section, except
that we stop the recursion not when the tree becomes of
size ≤ √n, but when the tree size becomes ≤ log log n. This
means that there are at most O(n/ log log n) successive cen-
troids that are aﬀected by this new form of “prematurely
terminated” decomposition. We call these O(n/ log log n)
nodes, as well as the root of T , the distinguished nodes (these
will be treated diﬀerently from the “special” nodes deﬁned
in the previous section). Note that, by construction, remov-
ing the distinguished nodes from T leaves connected compo-
nents of size at most log log n each; we call these connected
components (which are trees) the “tiny trees”.
of a T 0 as a “beltway” that connects the subtrees in which
x and y reside.
6.4 A Time/Space Tradeoff
In this section we introduce schemes with constant time
complexity. Our ﬁrst scheme has space complexity O(n log log n)
and requires at most 3 hops to reach any node. Like the
scheme outlined in Section 6.2, we start with prematurely
terminated centroid decomposition that stops when the tree
size is ≤ √n. We also use the reduced tree ˆT . The approach
is as follows.
The next thing that we use is the notion of a “reduced
tree” T 0 that is conceptually similar to the ˆT of the previous
section: The nodes of T 0 are the distinguished nodes plus the
root – hence there are O(n/ log log n) nodes in T 0 (whereas
there were O(√n) nodes in ˆT ). The edges of T 0 satisfy the
following condition: There is an edge from node x to node
y in T 0 if and only if (i) x is an ancestor of y in T , and (ii)
there is no other node of T 0 on the x-to-y path in T .
Now we are ready to put the pieces together:
1. Compute the distinguished nodes of T in linear time.
2. Create the tree T 0.
3. Use the method of Section 6.2 on the tree T 0. Any
edge of T 0 that was not in T must be considered a new
(i.e., a shortcut) edge. Note that the public space this
takes is O(n) because |T 0| = O(n/ log log n). It allows
computing an ancestor-to-descendant path of length
at most log log n − log log log n between any ancestor-
descendant pair of distinguished nodes in T 0.
4. To ﬁnd an ancestor-to-descendant path from x to y
when x and/or y is not distinguished, do the following:
(a) First trace a path in T from x to the nearest dis-
tinguished node (call it z) that is ancestor of y.
The length of this path is at most log log n be-
cause the “prematurely terminated centroid de-
composition” that we described above stops at
tiny trees of size ≤ log log n.
If there does not
exist such a distinguished node z that is both a
descendant of x and ancestor of y, then x and
y are in the same O(log log n) sized tiny tree of
nondistinguished nodes. In this case we can di-
rectly go along edges of T from x to y and stop.
(b) Next, trace a path in T 0 from z to the distin-
guished node (call it u) that is the nearest distin-
guished ancestor of y. As stated above, the length
of this path is at most log log n − log log log n. If
u = y then stop, otherwise continue with the next
step.
(c) Trace a path in T from u to y. Because that
path does not go through any distinguished node
(other than u), it stays in one of the tiny trees
and thus has length at most log log n.
The above implies that the concatenation of the paths
from x to z, z to u, u to y, has length O(log log n).
The space is clearly linear.
Although the above method uses a diﬀerent partitioning
scheme from Section 6.2 (and in fact uses the scheme of
that section as a subroutine), its spirit is the same: The use
AddShortcuts(T ):
1–4. The same as in the AddShortcuts() algorithm of Sec-
tion 6.2.
5. For every residual tree Ti in turn (i = 1, . . . , k), add
to S a shortcut edge from each node N in Ti (other
than the root) to all nodes in ˆT that are both: (i)
descendants of N and (ii) children of the root of Ti
in ˆT . This adds at most O(|T|) edges to the shortcut
set: For each node SN in ˆT , all of the new edges that
point to SN come from at most one tree (as SN has
at most one parent in ˆT ). Furthermore, since each
tree has at most O(p|T|) nodes, there are at most
O(p|T|) edges pointing to SN that are added during
this step. Finally, there are only O(p|T|) nodes in ˆT ,
and so there are at most O(|T|) edges added during
this step.
6. For every residual tree Ti in turn (i = 1, . . . , k), recur-
sively call AddShortcuts(Ti) and, if we let Si be the
set of shortcuts returned by that call, then we update
S by doing S = S ∪ Si.
7. Return S.
The number of edges added to the shortcut set in the above
scheme follows a recurrence similar to the scheme in section
6.2; thus this scheme adds only O(n log log n) edges. Fur-
thermore, the Algorithm FindPath(x, y, T ) is very similar
to the section 6.2 algorithm. To avoid unnecessarily repeat-
ing the above mentioned techniques, we describe only the
case of the FindPath() algorithm that diﬀers from its pre-
vious version. It corresponds to the situations where x and
y are not in the same residual tree and neither of them are
“special nodes”. In this case, it takes at most one hop to get
to a “special node” (call it s1) that is an ancestor of y (by
Step 5 of AddShortcuts()). Once we are at a special node,
we can get to the special node of the residual tree containing
y in a single hop (call this node s2) by Step 3. From there
we can reach y with a single hop by Step 4. The path from
x to y is thus x, s1, s2, y which is 3 hops.
The above scheme requires only three hops to reach a spe-
ciﬁc node. It is trivial to show that a one-hop solution must
add O(n2) edges, but a two-hop solution exists with only
O(n1.5) public space, which we brieﬂy sketch here. First,
we compute the special nodes of T as in the above scheme
and add two kinds of edges to this tree. The ﬁrst kind of
edge that we add to S connects every ancestor-descendant
pair in Ti for each Ti (unless the ancestor is a parent of the
descendant, in which case there is already such an edge in
T ). Since each Ti has O(√n) nodes, this step adds at most
O(n) edges to each Ti. There are O(√n) such trees, and so
the space required by this step is O(n1.5). After this step
all nodes in the same subtree can reach each other with a
single hop. The second type of edge is from each node N in
T to all special nodes that are descendants of N . As there
are O(√n) special nodes and each node adds at most O(√n)
such edges, there are at most O(n1.5) such edges in total.
If x and y are in diﬀerent trees, then x can get to the root
of y’s subtree in one hop (by the second type of edge) and
then to y with one hop (by the ﬁrst type of edge), thus any
two nodes are no more than 2 hops away from each other.
6.5 Dynamic Behavior
This section examines the cost of maintaining the shortcut
edges as the tree changes dynamically as a result of edge and
node insertions and deletions. In the uniform-distribution
random model for such dynamic updates, nothing else needs
to be done: The structure retains its claimed properties (to
within a constant factor) essentially for the same reason that
an initially balanced tree data structure tends to remain bal-
anced (to within a constant factor) as random insertions and
deletions are carried out. If, on the other hand, the updates
are not uniformly distributed, then the initial set of short-
cuts may, over time, deviate from the properties we claimed.
We can, however, show that the extra cost introduced by the
need to maintain our shortcuts in the face of insertion and
deletion operations, is O(1) per operation in an amortized
sense: After a sequence of σ such operations, if tσ is the
additional time (compared to without shortcuts) taken to
maintain shortcut edges, then tσ/σ = O(1). The rest of this
section proves this.
One possible strategy is the following: When the non-
uniform updates have caused deviations from the desired
performance bounds by more than a constant multiplicative
factor d (e.g., instead of the shortcuts providing an upper
bound of b log log n, they now provide an upper bound of
worse than db log log n), we discard all the shortcuts and re-
place them with new ones that reﬂect the new situation.
Note that this does not aﬀect the tree itself, only the short-
cuts, so there is no need for re-keying any node. Note also
that (i) this takes no more than linear time in the size of
the new tree (because it is a re-computation of the short-
cuts), and (ii) it suﬃces to know the current n and the
above-mentioned “ﬂexibility factor” d in order to determine
when to initiate such a re-computation. The latter does not
require us to detect and report every case when the path
exceeds db log log n, but instead the shortcuts can be recom-
puted periodically every αn insertions/deletions. The cost is
small and is only O(1) per operation because the O(n) time
it takes for one shortcut recomputation is amortized over the
αn operations that occurred before the restructuring took
place.