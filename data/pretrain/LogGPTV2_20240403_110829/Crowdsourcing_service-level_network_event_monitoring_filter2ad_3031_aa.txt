title:Crowdsourcing service-level network event monitoring
author:David R. Choffnes and
Fabi&apos;an E. Bustamante and
Zihui Ge
Crowdsourcing Service-Level Network Event Monitoring
David R. Choffnes†, Fabián E. Bustamante†, Zihui Ge‡
†Northwestern University, ‡AT&T Labs - Research
{drchoffnes,fabianb}@eecs.northwestern.edu, PI:EMAIL
ABSTRACT
The user experience for networked applications is becoming a key
benchmark for customers and network providers. Perceived user
experience is largely determined by the frequency, duration and
severity of network events that impact a service. While today’s net-
works implement sophisticated infrastructure that issues alarms for
most failures, there remains a class of silent outages (e.g., caused by
conﬁguration errors) that are not detected. Further, existing alarms
provide little information to help operators understand the impact
of network events on services. Attempts to address this through
infrastructure that monitors end-to-end performance for customers
have been hampered by the cost of deployment and by the volume
of data generated by these solutions.
We present an alternative approach that pushes monitoring to
applications on end systems and uses their collective view to
detect network events and their impact on services - an approach
we call Crowdsourcing Event Monitoring (CEM). This paper
presents a general framework for CEM systems and demonstrates
its effectiveness for a P2P application using a large dataset gathered
from BitTorrent users and conﬁrmed network events from two
ISPs. We discuss how we designed and deployed a prototype
CEM implementation as an extension to BitTorrent. This system
performs online service-level network event detection through
passive monitoring and correlation of performance in end-users’
applications.
Categories and Subject Descriptors
C.2.3 [Network Operations]: Network monitoring
C.2.4 Distributed Systems Distributed Applications
General Terms
Measurement, Performance, Reliability
Keywords
Service-Level Network Events, Crowdsourcing, Anomaly Detection, P2P
1.
INTRODUCTION
The Internet is increasingly used as a platform for diverse
distributed services including online multiplayer gaming, content
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
SIGCOMM’10, August 30–September 3, 2010, New Delhi, India.
Copyright 2010 ACM 978-1-4503-0201-2/10/08 ...$10.00.
distribution and IPTV. Given the popularity and potential for
revenue from these services, their user experience has become an
important benchmark for service providers, network providers and
end users [17].
Perceived user experience is in large part determined by the
frequency, duration and severity of network events (e.g., outages,
route changes or misconﬁgurations) that impact a service. There
is thus a clear need to detect, isolate and determine the root causes
of these service-level network events so that operators can address
them in a timely manner, minimizing their impact on revenue
and reputation.
In this work, we develop a practical monitoring
approach enables online detection (within seconds or minutes) of
network events impacting the user experience for services at the
network edge.
While today’s networks generally implement sophisticated in-
frastructure that detects and issues alarms when core network
elements fail, there remains a class of events that often go un-
detected – the so-called silent failures. Conﬁguration errors (e.g,
incorrect ACL settings), routing anomalies (e.g., routing loops),
and router bugs (simply because routers are incapable of detecting
their own internal failures) are common causes for silent failures
that can impact performance for services. Beyond these issues,
in-network alarms fail to provide information to help operators
understand the impact of network events, nor do they assist in
detecting events caused by external ISPs. Despite efforts to use
infrastructure to monitor end-to-end performance [16, 17, 36], the
cost of deployment, the number of services to monitor and the
volume of data generated by these solutions hampers their network
visibility and limits their scalability and effectiveness.
This paper presents an alternative approach to detecting, iso-
lating and reporting service-level network events – we call this
approach CEM, for Crowdsourcing Event Monitoring. The key
idea behind CEM is to push service-level event monitoring to
the end systems where the services are used. Building on end
systems has a number of clear advantages. First, the approach
provides ﬂexibility in the types of monitoring software that can
be installed inside or alongside services, facilitating immediate
and incremental deployments. Second, by leveraging the unique
perspective of participating end systems, it offers the potential
for broad network visibility into an increasingly opaque Internet.
Finally, its collaborative model enables a highly robust and more
scalable system by drawing from every node’s resources and
avoiding any centralized components.
Detecting events from the network edge also poses a number
of interesting challenges.
First, any practical approach must
address scalability constraints imposed by managing information
from potentially millions of end systems. Second, to assist oper-
ators in addressing problems promptly, events should be detected
387quickly (i.e., within minutes), isolated to speciﬁc networks (e.g.,
BGP preﬁxes) and this information should be available to ISPs
for troubleshooting and problem mitigation. Last, the approach
must facilitate a broad (Internet-scale) deployment of edge-system
monitors that ensures user privacy and provides trustworthy event
detection. We show how our approach addresses these challenges
and present the Network Early Warning System (NEWS), a proof-
of-concept implementation for online event detection in BitTorrent.
In Sec. 2, we describe the challenges faced by end-system
monitoring in more detail and discuss potential solutions. Sec. 3 ad-
dresses the general problem of how to detect network performance
events from the edge. Speciﬁcally, we develop a framework for our
CEM approach in which each end system performs a signiﬁcant
portion of event detection locally, then uses a distributed approach
to corroborate their ﬁndings.
Demonstrating the effectiveness of any edge-based approach is
challenging due to the lack of representative testbeds and the sheer
scale and diversity of networks worldwide. In Sec. 4, we address
this issue using a large dataset of diagnostic information from edge
systems, gathered from users running the Ono plugin [8] for the
Vuze BitTorrent client. We use our ﬁndings to motivate the design
and implementation of the Network Early Warning System.
We present results of our evaluation in Sec. 5.
In addition
to comparing NEWS-detected events with conﬁrmed ones, we
demonstrate that our crowdsourcing approach detects network
events worldwide, including events spanning multiple networks.
Our approach is robust to various parameter settings and incurs
reasonably low overhead.
NEWS has already been installed 45,000 times, demonstrating
not only the feasibility of our approach for a real application, but
also that there are appropriate incentives for widespread adoption
(Sec. 6). We are currently investigating other potential hosting
applications and services for our CEM approach. Last, to assist
with quickly resolving problems causing detected network events,
we have implemented NEWSight1 – a system that accesses live
event information gathered by NEWS and publishes its results. We
are currently beta-testing NEWSight interface with ISPs.
2. CROWDSOURCING MONITORING
Monitoring service-level events – issues that impact end-to-end
performance and the user experience – is important for users,
service providers and network operators. While most networks are
instrumented with systems that detect and raise alarms for failures
in network elements, their visibility is restricted to a single network
and aggregate ﬂows that make it difﬁcult to extract user-perceived
performance. Infrastructure-based distributed monitoring can de-
tect events across multiple networks, but this approach is limited by
both the fraction of the Internet that remain invisible to traditional
measurement techniques and the large number of Internet locations
that need to be monitored [5]. Motivated by these limitations, we
propose online detection of service-level events through monitoring
software that runs inside or alongside applications on the end
systems where they are used.
There are a number of important issues that must be addressed
in this new context. An edge-based monitoring system must be
able to detect sufﬁciently ﬁne-grained events that impact service
performance, while scaling effectively to large numbers of users.
Also, any viable deployment model must protect privacy, provide
trustworthy results and ensure widespread adoption.
Scalability. As one moves toward the edge of the network,
1
http://aqualab.cs.northwestern.edu/projects/news/
newsight.html
the number of network elements – and thus the opportunities for
failures – rapidly increases. With more than 1 billion Internet users
worldwide, an edge monitoring system that includes even a small
fraction of the population must support millions of hosts. As such,
collecting and processing raw performance data using a centralized
infrastructure is neither scalable nor practical.
We propose a decentralized approach to event detection in which
each host uses its own passively gathered performance information
to detect local problems as potential network events. By processing
performance data at each monitoring host, CEM facilitates an
immediately deployable, scalable monitoring system.
Granularity. Any online network monitoring system should
quickly identify network events and determine the affected network
region. The time to detect a problem is largely dependent on
how frequently a system can sample performance information. For
instance, in an end-system monitoring approach like Hubble [16],
the number of networks to monitor and the overhead for active
measurements limits its resolution to 15 minutes. By passively
gathering and processing this information locally at each end
system, CEM can enable event detection with ﬁne granularity
(on the order of seconds) and relatively low CPU and memory
overhead. To isolate the scope of network events, CEM correlates
multiple locally detected events from the same network region.
These regions can be drawn from publicly available BGP preﬁxes
and AS numbers, or richer information such as AS relationships
and topologies for cross-network problems.
Privacy. Any implementation of an edge-based network moni-
toring service is subject to privacy concerns. In previous work that
used control-layer information (e.g., BGP updates), network probes
(e.g., traceroutes) or aggregate ﬂows to identify network events,
privacy is ensured because no personally identiﬁable information
(PII) is exchanged. However, in an edge-based approach that relies
on corroboration among multiple vantage points to conﬁrm and
isolate events, users must share information about their network
views. We demonstrate how edge-based monitoring can remain
effective without publishing any PII.
Trust. Most existing network event detection approaches are
implemented as closed systems, where third parties are unable
or highly unlikely to affect the accuracy or validity of detected
problems.
In the context of edge-based detection, an open,
decentralized approach is vulnerable to attack. For example, one
ISP may wish to “poison” the system by introducing false reports of
events detected by users in a competitor’s ISP. We propose several
ways to harden an implementation against such attacks.
Deployment model. Any network event detection approach is
limited by the coverage of its deployment. As an application-layer
approach CEM is essentially free to deploy and there are practically
no limitations as to where participating hosts can be located. The
main challenge for CEM is thus gaining widespread adoption.
There are a number of ways in which this can be addressed, such as
incorporating the software into an OS, providing it as a background
service, and/or distributing it as part of networked applications.
In deployments where users must install new software, an appro-
priate incentive model is essential. Existing approaches to network
monitoring have used incentives such as micropayments [27],
altruism [31] and mutual beneﬁt [8]. Based on the success of
Ono [8], we propose using a mutual beneﬁt model where providers
and customers both gain from participation.
In this instance,
customers (i.e., those running the monitoring software) beneﬁt
from immediate notiﬁcation and logging of network performance
problems while network providers receive a more detailed view
of their network for improving the quality of their service. This
388determine when there may be a problem.
In this section, we
discuss the types of available performance signals and techniques
for detecting local performance events in CEM.
3.1.1 Performance Signals
By pushing detection to end systems located at the edge of the
network, CEM can use a wide variety of service-level information
to diagnose local performance problems (Table 2). Examples of
these performance signals available to any monitored application
include ﬂow and path-quality information such as throughput,
loss and latencies. Our approach can also incorporate service-
speciﬁc information to distinguish normal performance changes
from potential network events. For instance, P2P ﬁle-sharing
systems can provide information about whether a transfer has
completed and a VoIP application can indicate when there is
silence. Our approach can also use system-level information for
local event detection. For example,
the operating system can
provide information about throughput consumed by all running
applications, allowing CEM to account for the performance impact
of concurrent applications. Because these types of information can
be gathered passively, they can be sampled frequently so that events
are detected as soon as they occur.
Finally, to assist with diagnosing network problems, our ap-
proach can incorporate limited active measurements such as tracer-
outes, pings and available bandwidth probes.
3.1.2 Event Detection
CEM uses signals described in the previous section to detect
local performance events. The goal of local detection is to provide
sufﬁcient information for determining the scope of a problem,
i.e., whether the problem is local (isolated to a single ESM) or
network-related. To this end, the output of local detection is a
summary of each event describing its type (e.g., throughput drop,
lost video frame), the time of detection, where in the network it was
discovered and how it was detected.
The types of events that can be detected and the appropriate
technique to detect
them are dependent on the service being
monitored. For instance, when monitoring end-to-end throughput
for a host (e.g., for video streaming), we show that moving
averages can identify drops in transfer rates potentially caused by a
network issue like congestion. In the domain of IPTV [23], video
quality (among other factors) may indicate network problems.
Alternatively, a VoIP application may experience sudden jitter that
impacts call quality. Our approach is agnostic to how these events
are detected, so long as they correspond to service-level problems.
Correlating local events. Performance changes for monitored
services do not necessarily indicate widespread problems.
In a
P2P application like BitTorrent, for example, download rates often
drop to zero abruptly. While this may appear at ﬁrst to be a
network problem, it can be explained by the fact that downloading
stops when the transfer is complete. Additionally, information
gathered at the operating system level can assist in evaluating
whether changes in performance are caused by interactions among
concurrent applications (e.g., VoIP and P2P ﬁle sharing) instead of
the network.
As we remove these confounding factors from our analysis, we
improve our conﬁdence that a detected problem is independent
of the monitored service. Similarly, concurrent events occurring
in multiple performance signals for a service (e.g., download and
upload rates), further increases our conﬁdence that the event is
independent of the service.
Publishing local events. After detecting a local event, CEM
determines whether other hosts in the same network are seeing the
Figure 1: Schematic view of our edge detection approach.
has been sufﬁcient for a prototype implementation of CEM already
installed over 45,000 times.
3. CEM FRAMEWORK
The previous paragraphs discussed many of the issues faced by
any edge-based monitoring system.
In this section we describe
how we address these challenges in CEM. Fig. 1 depicts the CEM
architecture as a collection of cooperating edge system monitors
(ESMs). We assume that each ESM has access to one or more
sources of performance information that it can use to identify a
problem (e.g., transfer rates, latency jitter and dropped packets).
Further, each ESM can connect to a distributed storage system to
share information about detected events.
As previously mentioned,
it is infeasible for edge systems
to publish detailed performance data for scalability and privacy
reasons. To address this issue, our approach detects events affecting
each ESM using only locally available performance data, gathered
mostly through passive monitoring (step (1) of the ﬁgure). We
describe the CEM approach to local detection in Sec. 3.1.
Local event detection presents new design challenges for de-
termining the scope and severity of events. CEM addresses this
through a decentralized approach to disseminating information
about detected events and the network(s) they impact. In particular,
each edge system publishes its locally detected events to distributed
storage (step 2), allowing any other participating host to examine
these aggregate events. When multiple hosts detect the same
problem at the same time in the same network, our approach
determines the relative likelihood of the detected problem being
caused by the monitored network (as opposed to coincidence, for
example). We discusses how CEM determines the likelihood that a
set of these locally detected problems corresponds to a widespread
event in Sec. 3.2.
In our architecture, the scope of detected events can be deter-
mined by ESMs or via third-party analysis. Each participating host
can use the distributed store to capture events corresponding to its
network (step 3), then determine whether these local events indicate
a network event. Additionally, a third-party system (e.g., run by an
ISP) could use the distributed store to perform this analysis (step
4). Thus network customers can monitor the level of service they
receive and operators can be informed about events as they occur,
expediting root-cause analysis and resolution.
3.1 Local Detection
The ﬁrst step in CEM is to analyze local performance infor-
mation to determine whether the monitored host is experiencing
a problem. In general, network event detection consists of mon-
itoring a number of signals and using a detection algorithm to
389same problem – this requires hosts to share local event detection
results (but no local performance data). To ensure scalability,
distributed storage (e.g., a DHT) is an appropriate medium for
sharing these events.
3.2 Group Detection
Locally detected events may indicate a network problem, but
each local view alone is insufﬁcient to determine if this is the
case. We now formulate a technique for using multiple hosts’
perspectives to conﬁdently identify when a network problem is the
likely source.
3.2.1 Corroboration or Coincidence?
To identify events impacting a particular network, CEM ﬁrst
gathers a list of events reported by monitors in that network. This
can be done periodically or on demand (e.g., in response to events
detected by an ESM). If multiple events occur concurrently in the
same network, our approach must determine if these events are
likely to be due to the network.
There are a number of reasons why multiple hosts can detect
events concurrently in the same network. For example, problems
can be isolated to one or more related physical networks due to a
router malfunction or congestion. The problem can also be caused
by the service driving network activity, e.g., performance from a
Web server or from a swarm of P2P users. Finally, simultaneous
events can occur simply by chance, e.g., with multiple users
experiencing interference on separate wireless routers.
Below, we discuss how CEM accounts for service-speciﬁc
dependencies and correlated events that occur by coincidence.
After accounting for service dependencies, our approach tests the