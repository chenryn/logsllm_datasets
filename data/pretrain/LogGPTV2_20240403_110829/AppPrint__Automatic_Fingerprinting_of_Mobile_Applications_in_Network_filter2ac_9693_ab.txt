of app identiﬁcation. In the illustrated example, ﬂow f i
x would suggest its app
identity to all tokens in the group, i.e., its own tokens and the tokens of other
ﬂows in g(f i
MAP repository: The MAP repository is a knowledge base that reveals tokens
suitable for ﬁngerprints of each app. The repository is formed as a matrix in
which each row corresponds to a token t, and each column corresponds to a
suggested app x. The matrix element t, x, denoted as M APt,x, stores the number
of instances in which token t was suggestively associated with app x.
x).
Table 1 shows a snapshot of the MAP repository. Note the additional col-
umn in the repository which contains the total count of each token’s suggested
associations to any apps (denoted as column ∗ in Table 1). In the illustrated
example, the repository indicates that tokens angrybirds and rovio are by far
most frequently associated to Angry Birds app, which qualiﬁes them for Angry
Birds ﬁngerprints. On the other hand, tokens such as google and mobile have
dispersed associations across numerous apps, thus not being suitable for any app
ﬁngerprints.
3.4 SCORE: Probabilistic App Identiﬁcation
SCORE algorithm determines the most likely app identities in the observed traf-
ﬁc. The algorithm measures similarity between the tokens found in the traﬃc
and all token-to-app associations suggested by the MAP repository, thus identi-
fying the most likely corresponding app. The decisions span ﬂow sets and each
decision is referred to as app identiﬁcation instance.
SCORE ﬂow sets: Flow sets are the units of SCORE’s decision making. They
are formed by bundling traﬃc in a diﬀerent manner than MAP’s ﬂow grouping.
AppPrint: Automatic Fingerprinting of Mobile Applications
63
Table 1. MAP repository example.
tokens/apps *
Angry Birds Piggies Google Maps ...
angrybirds
500 450
rovio
mobile
google
...
700 600
3000
2000
50
60
...
...
0
50
30
40
...
Ts
f 1
f 2
f 3
Ts
f 4
...
...
...
...
...
0
0
100
200
...
Ts
f 5
f 6 f 7
f 8
flow set 
flow set 
flow set 
Fig. 3. SCORE grouping of ﬂow sets.
This enables MAP and SCORE to operate independently and if needed simulta-
neously. The diﬀerence stems from the fact that SCORE does not need any ﬂows
with explicit app identiﬁers, because app identity can be readily suggested by
the MAP repository. This is one of the key advantages of AppPrint: The system
is capable of identifying apps even when none of the ﬂows (in a ﬂow set) can be
a priori characterized individually.
For ﬂow sets, a simple time slotting mechanism suﬃces: Flows that originate
from the same source (i.e., source IP address) and have starting times that ﬁt
the same time slot constitute a ﬂow set instance. The duration of each time slot
TS is a conﬁgurable parameter. A ﬂow set example is illustrated in Fig. 3.
SCORE and eccentricity metrics: To identify the most likely app for a
given ﬂow set, we develop a pair of metrics that leverage indications of the MAP
repository. Let ST be a set of tokens in a ﬂow set F and SA be the set of all
apps in MAP repository. The similarity between the ﬂow set F and an app x is
evaluated as:
SCORE(x) =
(cid:2)
t∈ST
(cid:3)
M APt,x
M APt,∗
a∈SA δ(t, a) ,
(1)
where M APt,x is the value of the t, x element in the MAP repository, M APt,∗
is the total number of token t’s suggested associations to any apps, δ(t, a) is an
indicator of t being associated to an app a in the repository, i.e., δ(t, a) = 1 if
M APt,a (cid:3)= 0.
The intuition behind the SCORE metric is the following: If tokens in the
ﬂow set ST mostly associate with an app x, the app should score high as pro-
vided by the ratio of M APt,x and M APt,∗. Moreover, the token set should
a∈SA δ(t, a).
not have many other suggested app associations, as accounted by
(cid:3)
64
S. Miskovic et al.
The combination of these two criteria results in a high conﬁdence that a decision
about app identity for a ﬂow set can be made unambiguously.
Once the SCORE metric for the ﬂow set F is calculated against all candi-
date apps in the MAP repository, AppPrint decides whether the ﬂow set can be
attributed to the highest scoring app. This decision is based on the eccentricity
metric. The metric requires that the score of the highest ranking app is signif-
icantly diﬀerent from any other potential apps. Given the top ranked app x1st
and the second-best app x2nd, the eccentricity φ is a relative diﬀerence in their
scores:
φSCORE = SCORE(x1st) − SCORE(x2nd)
SCORE(x1st)
(2)
The ﬁnal result positively associates app x1st to the ﬂow set if and only
if the SCORE and eccentricity metrics are higher than Θ and Φ thresholds,
respectively.
4 Evaluation
In this section, we evaluate the proposed MAP-SCORE algorithm (MS) against
two state-of-the-art approaches for discovery of app identities: (i) one based on
the content of HTTP User-Agent ﬁelds (UA), and (ii) another based on explicit
app identiﬁers found in any HTTP header ﬁelds (HH ). Both of these reference
approaches rely solely on explicit app identiﬁers, which makes them perfectly
accurate (although on a limited set of ﬂows).
In preparation, we conducted exhaustive sensitivity testing of the three key
MAP-SCORE parameters: (1) ﬂow (set) grouping interval T , (2) threshold Θ of
the SCORE metric, (3) threshold Φ of the SCORE eccentricity. We found that
app classiﬁcation is largely consistent over various parameter settings whenever
T is around 10 s, Θ is between 0.1 and 0.2 and Φ is around 0.3. The parameters
set for our experiments are T = 10s, Θ = 0.1 and Φ = 0.3.
4.1 Datasets
Lab Trace: To evaluate AppPrint, we partly use lab traﬃc generated by running
individual apps in order to establish a ground truth. To this end, we downloaded
40K Android apps from Google’s Play Store and collected their traﬃc. Each
app was run on multiple versions of Android emulators provided by the Android
SDK. We use the Android monkey tool [12] to emulate user interaction with the
apps. Similarly, we collected 7K popular apps from Apple’s iTunes App Store.
Given that Apple does not provide any emulators for iOS devices, we developed
one and enabled it to automatically install and execute apps, as well as collect
app traﬃc.
Real Trace: We also evaluate AppPrint on a large anonymized dataset from a
major US cellular provider. The dataset contains 7 days of traﬃc from about
200K anonymous and mostly Android users. This dataset faithfully represents
AppPrint: Automatic Fingerprinting of Mobile Applications
65
s
e
c
n
a
t
s
n
i
p
p
a
f
o
#
105106
102103104
100101
105106
102103104
100101
s
e
c
n
a
t
s
n
i
p
p
a
f
o
#
HH
UA
MS
Fig. 4. Number of identiﬁed app instances.
actual human usage of mobile apps. However, it does not provide any a priori
information of apps behind the traﬃc, except for a small portion of ﬂows (less
than 1 %) whose apps can be determined via User-Agent (UA) or header data
(HH) approaches.
4.2 App Identiﬁcation
We ﬁrst evaluate the traﬃc coverage characterized by MAP-SCORE (MS) in
the real trace. Due to the lack of comprehensive ground truth in this trace, it
is impossible to fully evaluate correctness of MAP-SCORE’s results. Thus, we
later conduct precision analysis on the lab trace in order to provide a holistic
view in AppPrint’s capabilities.
Our experiments use the ﬁrst 6 days of the real trace to provide training
for the MAP repository. Our evaluation is based on running SCORE against the
ﬂow sets in the 7th day of data. The same evaluation methodology is used for the
other two approaches, user agents (UA) and header data (HH), i.e., we evaluate
their characterization capabilities only on the 7th day of data.
Coverage of the real traﬃc: The number of identiﬁed app instances is used as
a coverage comparison metric. For MAP-SCORE, an app-instance identiﬁcation
corresponds to SCORE positively associating an app ﬁngerprint to a ﬂow set.
By design, there can be at most one such app identiﬁcation per ﬂow set. For HH
and UA, we count the total number of distinct app identiﬁcations in each ﬂow
set - i.e., depending on the number of diﬀerent explicit app identiﬁers found in
the ﬂow set, there may be more than one app identiﬁed per ﬂow set.
As plotted in Fig. 4, MAP-SCORE (MS) identiﬁes 1, 729K app instances,
while UA identiﬁes close to 13K app instances and HH about 86K app instances.
Coverage-wise, MAP-SCORE performs an order of magnitude better. We also
note that UA is not as eﬀective as described in [14]. This is due to the fact
that “our” cellular provider mainly supports Android, the platform that doesn’t
force developers to code explicit app identiﬁes in User-Agents. In contrast, the
trace studied in [14] included a signiﬁcant portion of the traﬃc from iOS devices,
whose apps predominantly include app-identifying information in User-Agents.
Among 1, 729K positive ﬁngerprint matches of MAP-SCORE, we found that
84K are consistent with the indications of UA or HH approaches. This can be
66
S. Miskovic et al.
used as a hint of MAP-SCORE’s accuracy. Further accuracy analysis could not
be conducted on the real trace because it does not contain the ground truth for
the remaining 1645K = 1729K − 84K MAP-SCORE app identiﬁcations.
Precision evaluation: In order to further assess accuracy of MAP-SCORE
results, we use the lab trace which does contain the ground truth of ﬂow-to-
app associations. We built the trace by combining lab-generated traﬃc of 1000+
apps which appeared in the MAP repository (i.e., the repository trained on the
ﬁrst 6 days of the real trace). Then, SCORE was run against such traﬃc. To
evaluate app-identiﬁcation precision and coverage, we use the standard ratios
of true positive and false positive detections. Our results indicate that MAP-
SCORE achieves 81 % ﬂow-set coverage with 93.7 % precision. This supports
our claim that AppPrint can identify the most likely apps with a wide ﬂow-set
coverage and with a high conﬁdence.
Further, this result supports our assumption about the noise canceling prop-
erties of MAP-SCORE ﬁngerprints (stated in Sect. 3.3). Speciﬁcally, even though
MAP was trained on the noisy real traﬃc, ﬁngerprint indications were still highly
precise when applied on the ground truth of the lab traﬃc. Thus, the app ﬁn-
gerprinting noise largely dispersed over time and large user population as we
expected.
4.3 Eﬀectiveness of Grouping Flows
Next, we evaluate the importance of ﬂow grouping, i.e., the importance of using
tokens from multiple ﬂows towards building app ﬁngerprints. We take an extreme
s
w
o
l
f
f
o