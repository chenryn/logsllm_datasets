tions, could reduce the incentive to attack Civitas by raising
the cost of mounting an attack.
Requiring trusted voter clients compromises our goal of
a remote voting system. Even if voters download a client
from a trusted organization, the software stack on a voter’s
machine might not be trustworthy. Thus voters might need
to travel to a location where an organization they trust has
provided a client application running on a trustworthy hard-
ware and software platform.
Trust Assumption 4. The channels on which voters cast
their votes are anonymous.
Without this assumption, the adversary could observe
network trafﬁc and learn which voters have voted, trivially
violating coercion resistance—although the adversary still
could not learn the voter’s choice or credential.
Our prototype of Civitas does not implement its own
anonymous channel because the construction of trustworthy
anonymous channels is an orthogonal research problem. It
seems likely that existing anonymizing networks, such as
Tor [26], would sufﬁce if made sufﬁciently reliable.17
Trust Assumption 5. At least one of the ballot boxes to
which a voter submits his vote is correct.
A correct ballot box returns all the votes that it accepted
to all the tabulation tellers. This is weaker than the standard
assumption (less than a third of the ballot boxes fail) made
for Byzantine fault tolerance [10] and multi-party computa-
tion [33], which both require more expensive protocols.
Trust Assumption 6. There exists at least one honest tabu-
lation teller.
If all the tellers were corrupted, then the adversary could
trivially violate coercion resistance by decrypting creden-
tials and votes. This assumption is not needed for veriﬁa-
bility, even if all the tellers collude or are corrupted—the
proofs posted by tellers during tabulation will reveal any at-
tempt to cheat. Fault tolerance techniques [14, 30] would
increase the difﬁculty of corrupting all the tellers.
Attacks on election authorities. Trust Assumptions 2, 5,
and 6 allow all but one election authority of each kind to be
corrupted. But certain attacks might still be mounted:
• A corrupt registration teller might fail to issue a valid
credential share to a voter. The voter can detect this,
but coercion resistance requires that the voter cannot
prove that a share is valid or invalid to a third party. De-
fending against this could involve the voter and another
election authority, perhaps an external auditor, jointly
attempting to re-register the voter. The auditor could
then attest to the misbehavior of a registration teller.
• The bulletin board might attempt to alter messages. But
this is detectable since messages are signed. A bulletin
board might also delete messages. This is an attack on
availability, which is addressed in Section 10.
• A corrupt registrar might add ﬁctitious voters or re-
move legitimate voters from the electoral roll. Each
tabulation teller can defend against this by refusing to
tabulate unless the electoral roll is correct according to
some external policy.
• A corrupt supervisor might post an incorrect ballot de-
sign, stop an election early, or even attempt to simulate
an election with only one real voter. Voters and tabu-
lation tellers should cease to participate in the election
once the supervisor exhibits such behavior.
16Another example is the use of paper as one of the components. How-
ever, this is incompatible with remote electronic voting.
17A vote typically ﬁts into just three packets, so scalability and timing
attacks seem unlikely to present problems.
359
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:14:20 UTC from IEEE Xplore.  Restrictions apply. 
All election authorities might be simultaneously cor-
rupted if they all run the same software. For example, an
insider working at the software supplier might hide mali-
cious code in the tabulation teller software. As discussed in
Trust Assumption 6, this attack could violate coercion resis-
tance, but it could not violate veriﬁability. To defend against
insider attacks, election authorities should use diverse im-
plementations of the Civitas protocols.
Trust Assumption 7. The Decision Difﬁe-Hellman (DDH)
and RSA assumptions hold, and SHA-256 implements a ran-
dom oracle.
DDH and RSA are standard cryptographic assumptions.
The more fundamental assumption for Civitas is DDH, as
the JCJ security proof is a reduction from it.
5. Cryptographic Components
Civitas uses many cryptographic components. This section
gives an overview of these; the accompanying technical re-
port [18] contains a detailed speciﬁcation of the protocols.
Many components require posting messages to the bulletin
board. These messages must be signed by the poster. Also,
a variety of zero-knowledge proofs are used to enforce the
honest execution of protocols. These proofs are made non-
interactive via the Fiat-Shamir heuristic [29], so their secu-
rity is in the random oracle model [5]. Civitas implements a
random oracle with SHA-256.
Security proof. The security of Civitas follows from the
JCJ security proof [45] and the individual security proofs
of each component, cited below. We give a security proof
for the registration protocol in the accompanying technical
report [18].
5.1. Setup phase
Keys. The supervisor posts RSA public keys representing
the election authorities. These keys are used for authenti-
cation of agents and messages. The choice of RSA is for
convenience, since many real-world organizations already
have RSA keys, but could be replaced by another cryptosys-
tem. The tabulation tellers also generate a distributed El Ga-
mal public key, described below. The registrar posts each
voter’s registration public key (RSA, again for convenience)
and designation public key (El Gamal).
Encryption scheme. Civitas implements a distributed El
Gamal scheme similar to Brandt’s [7]. The supervisor posts
a message (p, q, g) describing the cryptosystem parameters:
a prime p = 2kq + 1, where q is also prime, and a generator
g of the order q subgroup of Z∗
p. This subgroup, denoted
M, is the message space of the cryptosystem. The tabula-
tion tellers generate an El Gamal public key KTT for which
each teller holds a share of the corresponding private key.
Encryption of message m under key K with randomness r
is denoted Enc(m; r; K). We omit r or K from this nota-
tion when they are unimportant or clear from context. De-
cryption of a ciphertext c that was encrypted under key KTT,
denoted Dec(c), requires all tabulation tellers.
El Gamal encryption is homomorphic with respect to
multiplication. That is, Enc(m) · Enc(n) = Enc(m · n).
El Gamal permits a probabilistic reencryption operation, de-
noted Reenc(c) for a ciphertext c, which produces a new
encryption of the same plaintext. Encryption can be made
non-malleable, preventing the use of homomorphisms and
reencryption, by the use of Schnorr signatures [68]. Civi-
tas uses non-malleable encryption until the tabulation phase,
where malleability is required.
Civitas uses two zero-knowledge proofs to ensure the
honesty of tellers during key generation and during decryp-
tion. The ﬁrst is a proof of knowledge of a discrete logarithm
due to Schnorr [67]. The second is a proof of equality of dis-
crete logarithms due to Chaum and Pedersen [13].
Credential generation. Civitas uses a novel construction
for credentials, based on ideas found in earlier work [20,
37, 45]. The security of this construction is proved in the
accompanying technical report [18].
For each voter, each registration teller i individually gen-
erates a random element of M as private credential share
si. The corresponding public share Si is Enc(si; KTT). The
registration teller posts Si on the bulletin board and stores si
for release during registration. After all tellers have posted a
share, the voter’s public credential S is publicly computable
i Enc(si; KTT), which by the homomorphic property is
as(cid:81)
equal to Enc((cid:81)
i si; KTT).
i, D), where r is random, S(cid:48)
5.2. Voting phase
Registration. To acquire a private credential, a voter con-
tacts each registration teller. The voter authenticates us-
ing his registration key, then establishes a shared AES ses-
sion key using the Needham-Schroeder-Lowe [51] proto-
col. The voter requests registration teller i’s share si of
the private credential. The registration teller responds with
(si, r, S(cid:48)
i = Enc(si; r; KTT) and
D is a designated-veriﬁer reencryption proof (DVRP) due
to Hirt and Sako [37]. The proof shows that S(cid:48)
i is a reen-
cryption of Si, the public credential share. Construction of
this proof requires the voter’s public designation key. The
voter veriﬁes that S(cid:48)
i was computed correctly from si and
r, then veriﬁes the DVRP. These veriﬁcations convince the
voter, and only the voter, that the private share is correct with
respect to the public share posted on the bulletin board—i.e.,
that Si is an encryption of si. After retrieving all the shares,
the voter constructs private credential s, where s =(cid:81)
i si.
Voting. To cast a vote, a voter posts an unsigned mes-
sage (cid:104)Enc(s; KTT), Enc(v; KTT), Pw, Pk(cid:105) to some or all of
360
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:14:20 UTC from IEEE Xplore.  Restrictions apply. 
the ballot boxes, where s is the voter’s private credential, v
is the voter’s choice, and Pw and Pk are zero-knowledge
proofs. Pw, implemented with a 1-out-of-L reencryption
proof due to Hirt and Sako [37], shows that the vote is
well-formed with respect to the ballot design of the elec-
tion. Given C = {ci | 1 ≤ i ≤ L} and c, this reencryp-
tion proof shows there exists an i such that ci = Reenc(c).
Pk, implemented by adapting a proof due to Camenisch and
Stadler [9], shows that the submitter simultaneously knows
s and v. This defends against an adversary who attempts to
post functions of previously cast votes.
Resisting coercion. To construct a fake credential, a voter
chooses at least one registration teller and substitutes a ran-
i ∈ M for the share si that registration
dom group element s(cid:48)
teller sent to the voter. The voter can construct a DVRP that
causes this fake share to appear real to the adversary, unless
the adversary has corrupted the registration teller the voter
chose (in which case the adversary already knows the real
share), or unless the adversary observed the channel used by
the registration teller and voter during registration (in which
case the adversary has seen the real proof). By Trust As-
sumption 2, there exist some teller and channel that the ad-
versary does not control, so it is always possible for voters
fake credentials.
5.3. Tabulation phase
Ballot boxes. Recall from Section 3 that ballot boxes are
instances of an insert-only log service. Ballot boxes have
one additional function, reporting their contents at the end
of an election. When the supervisor closes the election, each
ballot box posts a commitment to its contents on the bulletin
board. The supervisor then posts his own signature on all
these commitments, deﬁning the set of votes to be tabulated.
Thus, if a voter posts a vote to at least one correct ballot
box, the vote will be tabulated.18 Note that ballot boxes do
not check validity of votes.
Since ballot boxes operate independently, never contact-
ing other ballot boxes, this ballot box construction scales
easily. Moreover, this construction ensures that all votes
are available for tabulation—a requirement of universal
veriﬁability—without expensive fault tolerance protocols.
Mix network. A mix network is used to anonymize sub-
mitted votes and authorized credentials. Civitas implements
a reencryption mix network made veriﬁable by randomized
partial checking [40], in which each teller in the network
performs two permutations.19
18A malicious supervisor could violate this by excluding a correct bal-
lot box. This trust in the supervisor could be eliminated by using a more
expensive agreement protocol.
19Randomized partial checking reveals some small amount of informa-
tion about these permutations. In the worst case, when all but one teller is
corrupted, the size of the set within which a vote or credential is anonymous
Duplicate and invalid credential elimination.
It would
be easy to eliminate votes containing duplicate or invalid
credentials if credentials could be decrypted. However, this
would fail to be coercion-resistant, because voters’ private
credentials would be revealed.
Instead, a zero-knowledge
protocol called a plaintext equivalence test (PET) is used to
compare ciphertexts. Given c and c(cid:48), a PET reveals whether
Dec(c) = Dec(c(cid:48)), but nothing more about the plaintexts of
c and c(cid:48). Civitas implements a PET protocol due to Jakob-
sson and Juels [39]. For duplicate elimination, a PET must
be performed on each pair of submitted credentials. Sim-
ilarly, to eliminate invalid credentials, PETs must be per-
formed to compare each submitted credential with every au-
thorized credential.20 These pairwise tests cause credential
elimination to take quadratic time.
6. Scalability
There are two main challenges for scalability in Civitas.
First, elimination of duplicate and invalid credentials takes
quadratic time. Second, tabulation requires each teller to
perform computation for each vote.
Our solution to both challenges is to group voters
into blocks, which are virtual precincts. Like real-world
precincts, the tally for each block can be computed indepen-
dently, block results are public, and voters are anonymous
within their block. Unlike real-world precincts, the assign-
ment into blocks need not be based on physical location. For
example, voters might be assigned to blocks in a way that is
veriﬁably pseudorandom, reducing the risk of reprisal by the
adversary against an entire block of voters. Blocking also
enables the production of early returns, in which a fraction
of blocks are tabulated to predict the outcome of the election.
Implementing blocking is straightforward. The registrar
publicly assigns each voter to a block. Each submitted vote
identiﬁes, in plaintext, the block in which its credential (sup-
posedly) resides. Vote proof Pk is extended to make this
identiﬁer non-malleable.
Without blocking, duplicate elimination requires O(N 2)
PETs, where N is the number of all submitted votes. With