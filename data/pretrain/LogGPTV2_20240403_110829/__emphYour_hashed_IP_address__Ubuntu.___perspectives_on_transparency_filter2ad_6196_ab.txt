a company, aside from being compliant with legal requirements.
Therefore, we analyze the privacy policies of the 22 companies
regarding three criteria: (C1) Does the policy use plain and clear
language, (C2) Is the purpose of data collection explained, and
(C3) Is the way how data is collected explained?. Thus, criteria C2
and C3 focus on the requirements for technical descriptions, not
compliance in general.
To assess the readability of the privacy policies (C1), we used the
Flesch-Kincaid Grade Level (FKG). This grading assesses how many
years of school education one needs to understand a text (e. g., FKG
= 12 means 12 years of education—senior-level high school student
in the US). There is no consistent usage of readability scores in the
literature, but Fabian et al. [23] found that the FKG, among other
scores such as SMOG, RIX, or LIX, produces comparable results
between each other (i. e., the correlation coefficients are almost 1).
Previous work often does not report how they actually calculate
the score (e. g., [23, 30, 31]) and we found that different available
tools compute different FKG scores for the same text because they
compute sentence endings or syllables differently. We computed
the FKG score using the koRpus R package [39].
Regarding criteria C2 and C3, the privacy policies of the compa-
nies were independently analyzed by two researchers with experi-
ence in the area to check whether the required explanations were
given. All researchers have a strong background in data protection,
a strong understanding of the online ad ecosystem, and experience
in the field. One is also a certified data protection officer with legal
704expertise. We told these researchers that a technical description,
although it might not be understandable by most users, is sufficient.
While this favors the companies, we assume that if users are inter-
ested in how or why data is collected, they could check what these
technologies are and how they work. While it would be favorable,
it is—from our point of view—not the purpose of a privacy policy
to explain technical details of the used technologies.
Industry Self-Regulation. The OBA industry associations have
developed transparency guidelines for their members on how and
which kind of information and choices they should provide to
consumers (e. g., the DAA and IAB [16, 21]). As noted earlier, we
analyzed the guidelines of the three most prominent alliances, the
Interactive Advertising Bureau (IAB), the Network Advertising Initia-
tive (NAI), and the Digital Advertising Alliance (DAA). All guidelines
urge companies to take steps to increase transparency to their users
and every company we analyzed is a member of at least one of the
alliances. However, we found that the guidelines are quite vague
and not easy to validate on the users’ end. For example, companies
are asked to place a special icon (which provides a link to an opt-out
tool and further explanations why the ad is displayed) on the ad if
it is based on a behavioral profile. If the ad banner does not contain
such an icon, this could mean that the company either provides an
ad not based on a profile (e. g., depending on the website’s content)
or that it does not adhere to the self-imposed rules. By manual
inspection of several websites, we found the same ad twice once
labeled with the icon and the other without the label. It is possible
that this observation was coincidental and that one ad was con-
textual and the other was profile-based, but this illustrates that it
is nearly impossible to decide if the guidelines were followed or
not. Due to this inconsistency and previous work highlighting the
ineffectiveness of such icons [43], we did not further investigate
this transparency mechanism.
Besides the guidelines, the DAA, NAI, and IAB provide and main-
tain websites for consumers to learn more about online advertising
and control privacy related settings (e. g., mechanisms to opt-out
of OBA for several ad companies at once). The DAA provides the
“YourAdChoices” [17] and the EDAA the “Your Online Choices” [22]
tool. At the time of this study, none of the guidelines contained
rules or advice how users can obtain access to their personal data.
3.2 Results
Table 1 lists the results of our analysis of transparency tools in
alphabetic order. Ten companies provided data online only, eight
companies provided data offline only, and five companies provided
data in both ways. In general, online data can be seen as more us-
able since it is pre-processed, while most (n = 6) of the offline data
is comma-separated, which needs a more technical background to
interpret. The table lists how users can access their data (Access),
which data is provided (Expect.), which data is provided in the com-
pany’s privacy policy (Privacy P.), and further information that help
users to understand the company’s usage of personal data (Misc.).
The category Misc lists if the company provides insights with whom
personal data was shared (Sharing) and whether the used technolo-
gies to track users are explained. Some profiles contained inconclu-
sive information (e. g., Segment: companyB_Usersync_Global or
Table 1: Results of transparency tools analysis. Access de-
scribes the format how users get access to their data. Expect
shows whether the provided data contains information to
our defined categories. Privacy P. lists whether privacy poli-
cies are useful to users. Misc. lists additionally provided data
of interest. (cid:35): Does not apply. (cid:32): Applies according to the
privacy policy and data is provided.(cid:72)(cid:35): Applies according to
the privacy policy but no data is provided. †: Google and Face-
book only shows tracking data on their own platforms. Twit-
ter’s way to provide sharing data did not work for us. Sovrn
only shared pseudonyms of partners. (cid:18): Our analyzed pro-
file did not include this data but could include it. (cid:51): These
companies only shared their syncing partners.
Access
Expect.
Privacy P. Misc.
Company
e
n
i
l
n
O
e
n
i
ffl
O
Adform
Amobee
AppNexus
ComScore
Conversant
Criteo
Facebook
Google
Leiki
Lotame
MediaMath
Oracle
Quantcast
Rubicon Project
ShareThrough(cid:51)
Sizmek
Sojern(cid:51)
Sovrn(cid:51)
SpotXchange
The Trade Desk
TripleLift
Twitter
✗ ✓
✓ ✗
✓ ✗
✓ ✗
✓ ✓
✗ ✓
✓ ✓
✓ ✓
✓ ✗
✓ ✗
✗ ✓
✓ ✗
✗ ✓
✓ ✗
✗ ✓
✓ ✓
✗ ✓
✗ ✓
✓ ✗
✓ ✗
✓ ✗
✓ ✓
s
t
n
e
m
g
e
S
s
c
i
h
p
a
r
g
o
m
e
D
g
n
i
k
c
a
r
T
G
K
F
y
h
w
n
t
a
h
w
n
i
a
l
p
x
e
i
a
l
p
x
e
g
n
i
r
a
h
S
.
h
c
e
t
n
i
a
l
p
x
e
14.19 ✓ ✓
13.37 ✓ ✓
9.96 ✗ ✗
(cid:32)(cid:72)(cid:35)(cid:32) 13.40 ✓ ✓
(cid:32)(cid:72)(cid:35)(cid:18)(cid:72)(cid:35) 13.05 ✓ ✗
(cid:32)(cid:32)(cid:72)(cid:35) 11.96 ✓ ✓
(cid:72)(cid:35)(cid:32)(cid:32) 10.63 ✓ ✓
(cid:32)(cid:72)(cid:35)(cid:18)(cid:32) 13.43 ✗ ✗
(cid:72)(cid:35)(cid:72)(cid:35)(cid:32) 12.00 ✓ ✓
†
(cid:35)(cid:32)(cid:72)(cid:35)
†
(cid:32)(cid:32)(cid:72)(cid:35)
(cid:32)(cid:35)(cid:32)
(cid:32)(cid:32)(cid:72)(cid:35) 12.72 ✓ ✓
(cid:32)(cid:32)(cid:72)(cid:35) 12.69 ✓ ✓
(cid:32)(cid:32)(cid:72)(cid:35) 11.92 ✓ ✗
(cid:32)(cid:32)(cid:32) 12.10 ✓ ✓
(cid:35)(cid:35)(cid:32) 12.77 ✓ ✓
(cid:72)(cid:35)(cid:72)(cid:35)(cid:72)(cid:35) 12.07 ✓ ✓
(cid:72)(cid:35)(cid:32)(cid:72)(cid:35) 14.81 ✗ ✓
(cid:72)(cid:35)(cid:72)(cid:35)(cid:72)(cid:35) 13.96 ✓ ✓
(cid:72)(cid:35)(cid:72)(cid:35)(cid:72)(cid:35) 14.24 ✓ ✗
(cid:35)(cid:32)(cid:72)(cid:35) 12.15 ✗ ✗
(cid:32)(cid:72)(cid:35)(cid:18)(cid:72)(cid:35) 10.29 ✓ ✓
(cid:32)(cid:72)(cid:35)(cid:18)(cid:72)(cid:35) 12.19 ✓ ✓
(cid:32)(cid:32)(cid:35) 12.16 ✗ ✓
✗ ✓
✗ ✗
✓ ✓
✗ ✗
✓ ✗
✓ ✗
✗ ✓
✗ ✓
✗ ✗
✗ ✓
✗ ✓
✗ ✗
✗ ✓
✓ ✓
✓ ✗
✗ ✗
✗ ✓
✓†✓
✓ ✓
✓ ✗
✓ ✗
✗† ✓
Your hashed IP address: Ubuntu). If we could see (or guess) the
meaning of such information, we ruled in favor of the companies.
User Expectations. We checked if the transparency tools provide
data on three levels, as described above. These categories contain
information the ad companies inferred/collected about the user
regarding (1) interest segments, (2) demographics, and (3) tracking.
We inspected the data provided by the tools, checked if the data
can be grouped into any of these groups, and also reviewed if the
privacy policy stated if such data was collected/inferred.
We identified three different cases: (1) a company states that they
collect data in one of the categories and provides this data ((cid:32)), (2) a
705company states that they collect data on one of these categories but
not state that they collect data in one category and also does not
does not provide such information ((cid:72)(cid:35)), and (3) the company does
provide any information ((cid:35)). We did not observe the case that a
company did not state that they would collect data on a category but
provided such information. In some cases, the 22 analyzed profiles
did not contain interest segment or demographic data. However,
the profiles might contain such data for other profiles because the
shared data is not a full set of all categories, but only the data they
assigned to one user. Meaning, that a company might try to infer for
example the user’s age but could not do so based on the collected
Table 1).
data. We found four cases where this applies (marked with (cid:18) in