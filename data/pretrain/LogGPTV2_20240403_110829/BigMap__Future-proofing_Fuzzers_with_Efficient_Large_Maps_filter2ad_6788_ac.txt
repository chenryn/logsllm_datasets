Corresponding locations in the coverage bitmap is also
updated. After the execution is ﬁnished, the hit counts are
bucketed and compared with the global coverage maps. If
the test case is deemed interesting by the fuzzer, additional
bitmap operations such as hashing, rank update, etc., may be
performed. These steps read/modify only the used portion of
the coverage bitmap as well.
A few things to note here. The index bitmap is touched
only during the update phase. It is not accessed at any other
phase, including reset. Therefore, the same edge will point
to the same coverage bitmap location for all the test cases.
Also, the update phase is the only stage where AFL’s data
structure is more efﬁcient. AFL’s structure does one data
access per edge compared to two accesses of BigMap’s
structure. Fortunately, the extra access shows good cache
locality, as will be discussed in the next section.
C. Access Patterns of the Bitmap Operations
1) AFL’s Data Structure: Table I(a) summarizes the
access patterns for AFL’s data structure. The bitmap update
does sparse access over the coverage bitmap. These accesses
correspond to the IDs of the encountered edges. It has a
high temporal locality because the same edges are likely to
be traversed again within the same program execution (e.g.,
edges inside loops or common functions). The same edges
are also likely to be traversed across different executions due
to the overlap of execution paths.
The rest of the bitmap operations iterates the full map.
Most of these locations do not contain any useful informa-
tion, therefore causes heavy cache pollution. In turn, the
cache pollution may trigger the eviction of useful data to
slower cache levels or memory. For example, pollution may
Table I: Access Patterns of the Bitmap Operations
(a) AFL’s Data Structure
Map
Operation
Bitmap
Access to
Temporal
locality
Spatial
locality
Cache
pollution
Update
Others1
Coverage Used map2
Coverage
Full map
High
Low
Low
High
Low
High
(b) BigMap’s Data Structure
Map
Operation
Update
Others1
Bitmap
Access to
Index
Used map2
Coverage Used map2
Index
None
Coverage Used map2
Temporal
locality
Spatial
locality
Cache
pollution
High
High
–
High
Low
High
–
High
Low
None
None
None
1Bitmap reset, compare, classify, hash etc.
2Corresponds to the highlighted cells in the example of Figure 5.
535
Authorized licensed use limited to: Tsinghua University. Downloaded on October 11,2021 at 09:23:42 UTC from IEEE Xplore.  Restrictions apply. 
run test
execution path:
A → B → A → B → C
EAB = 7
EBA = 1
EBC = 9
run next test
(a) Trace
initialize
reset
A → B
B → A
A → B
B → C
classify
compare
reset
[0] [1] [2] [3] [4] [5] [6] [7] [8] [9]
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 1 0 0
0 1 0 0 0 0 0 1 0 0
0 1 0 0 0 0 0 2 0 0
0 1 0 0 0 0 0 2 0 1
0 1 0 0 0 0 0 2 0 1
0 1 0 0 0 0 0 2 0 1
0 0 0 0 0 0 0 0 0 0
initialize
reset
A → B
B → A
A → B
B → C
classify
compare
reset
[0] [1] [2] [3] [4] [5] [6] [7] [8] [9]
-1 -1 -1 -1 -1 -1 -1 -1 -1 -1
-1 -1 -1 -1 -1 -1 -1 -1 -1 -1
-1 -1 -1 -1 -1 -1 -1 0 -1 -1
-1 1 -1 -1 -1 -1 -1 0 -1 -1
-1 1 -1 -1 -1 -1 -1 0 -1 -1
-1 1 -1 -1 -1 -1 -1 0 -1 2
-1 1 -1 -1 -1 -1 -1 0 -1 2
-1 1 -1 -1 -1 -1 -1 0 -1 2
-1 1 -1 -1 -1 -1 -1 0 -1 2
[0] [1] [2] [3] [4] [5] [6] [7] [8] [9]
0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
1 0 0 0 0 0 0 0 0 0
1 1 0 0 0 0 0 0 0 0
2 1 0 0 0 0 0 0 0 0
2 1 1 0 0 0 0 0 0 0
2 1 1 0 0 0 0 0 0 0
2 1 1 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0
coverage_bitmap
(b) AFL’s data structure
index_bitmap
coverage_bitmap
(c) BigMap’s data structure
used
key (n)
0
0
1
2
2
3
3
3
3
Figure 5: An illustrative example of bitmap operations on AFL’s and BigMap’s data structures. Value on top is the index
of the bitmaps. Locations accessed at each step are highlighted in bold. (a) Execution trace and the assigned edge IDs
(random). (b) AFL’s data structure. Reset, classify, compare, etc., operations need to access the full bitmap. (c) BigMap’s
data structure. The full map is accessed only during initialization. Afterward, reset, classify, compare, etc., accesses only
the used region of the coverage bitmap. Index bitmap is only accessed during the hit count update.
prevent keeping common edge locations in L1/L2 cache
across consecutive executions.
2) BigMap’s Data Structure: Table I(b) shows the access
patterns for BigMap’s data structure. During the update
operation, BigMap’s structure makes two accesses per edge,
ﬁrst to the index bitmap and then to the coverage bitmap.
Access to the index bitmap is scattered and is identical to
the pattern of AFL’s data structure. On the other hand, access
to the coverage bitmap has a high spatial and temporal
locality. The spatial locality stems from the fact that the
edge hit counts are now residing in close vicinity. The rest
of the bitmap operations do sequential access to the cov-
erage bitmap, exhibiting high spatial and temporal locality.
We infer high temporal locality for BigMap’s structure and
not for AFL’s structure. This is because AFL’s structure
has a high reuse distance as it accesses the full map.
Overall, BigMap’s structure demonstrates vastly improved
cache locality behaviors compared to AFL.
D. Implementation Details
The BigMap approach requires minor modiﬁcations of
AFL’s instrumentation to support the two-level bitmap up-
date. The new instrumentation is shown in Listing 2.
i f
1 BX , BY = random % MAP SIZE 
2 EXY = (BX >> 1) ⊕ BY
3
4
5 KXY = i n d e x b i t m a p [ EXY ]
6
( i n d e x b i t m a p [ EXY ] == −1)
i n d e x b i t m a p [ EXY ] = used key ++
c o v e r a g e b i t m a p [ KXY ]++
Listing 2: BigMap instrumentation for map update.
Here, lines 1, 2, and 6 are identical to AFL’s instrumen-
tation scheme (Listing 1). Lines 3-5 are added to query
and modify the index bitmap. Since these instructions are
executed for every edge, overhead can be a big concern.
Given the rarity of new edge discovery, most of the time,
the overhead will consist of one branch condition check (at
line 3) and one extra access to the index bitmap (at line 5).
The branch condition outcome is highly skewed towards not-
taken and will be predicted correctly by the branch predictor
almost always. Furthermore, the access to the index bitmap
is amenable to hit the L1 or L2 cache, making the access
time negligible. The index bitmap update (at line 4) will be
invoked only when a new edge is discovered for the ﬁrst
time. Interestingly, while the index bitmap is indexed by
the edge ID, it does not necessarily have to be the case. In
fact, any coverage metric can be used in edge ID’s place,
trivializing the integration process.
The modiﬁcation in the instrumentation takes care of the
bitmap update operation. Further adjustments are required
to support the rest of the bitmap operations. It primarily
involves changing the iteration count from the full map size
to used key. Bitmap hash operation is an exception to this
rule. AFL uses CRC32 for calculating bitmap hash. If we
always calculate hash in the [0..used key) range, it might
lead to wrong hash values. Consider the following example
with three test case executions:
Execution Path
P1: A → B → C
P2: A → B → C → D
P3: A → B → C
used key coverage bitmap Bitmap Hash
crc32({1,1})
crc32({1,1,1})
crc32({1,1,0})
{1,1,0,0,...}
{1,1,1,0,...}
{1,1,0,0,...}
2
3
3
The hash of ﬁrst case is crc32(P 1) = crc32({1, 1}).
Here, {1, 1} are the hit counts up to the used key. While
executing the second case, the used key will be incremented
to 3. Therefore, the hash of third case will be calculated as
crc32(P 3) = crc32({1, 1, 0}). The ﬁrst and third paths are
essentially the same. However, the calculated hash values
Authorized licensed use limited to: Tsinghua University. Downloaded on October 11,2021 at 09:23:42 UTC from IEEE Xplore.  Restrictions apply. 
536
do not match because crc32({1, 1}) (cid:3)= crc32({1, 1, 0}). To
avoid such discrepancy, BigMap calculates the hash up to
the last non zero value in the coverage bitmap.
E. Additional Optimizations
We carried out a few additional optimizations to make our
implementation faster. These optimizations are orthogonal
to the two-level bitmap scheme and can be adopted by any
AFL based fuzzers. First, we merged the bitmap classify and
compare steps. The bitmap compare operation almost always
follows the classify operation. Because these operations are
carried out in the same region of the bitmap, they can be
easily merged. This merging allows more efﬁcient use of
cache and cuts the cost of (compare + classify) to half. The
second optimization is to replace normal reset operation with
a non-temporal version. The reset operation happens just
before the execution and can pollute cache with regions of
the bitmap that are never used. Using non-temporal stores
prevents this pollution. This optimization is only beneﬁcial
to the vanilla AFL because BigMap already limits the map
operations to the used region. Our ﬁnal optimization is
to allocate the index and coverage bitmap using the OS-
provided facility for huge pages. There are limited numbers
of slots on L1/L2 DTLB, and a large bitmap can consume
many of them, resulting in frequent page-walks caused
by DTLB misses. Allocating the bitmaps on a huge page
reduces these overheads.
V. EVALUATION
We evaluated our proposed approach in three steps. First,
we demonstrated that BigMap could support larger maps
without sacriﬁcing test generation throughput, unlike stan-
dard AFL. Second, we investigated BigMap’s ability to
support coverage metric compositions and whether that leads
to practical beneﬁts in terms of improved code coverage.
This step also acts as a justiﬁcation for using large coverage
maps. Finally, we evaluated the scalability of both fuzzers
with respect to the number of concurrent fuzzing instances.
A. Experimental Setup
1) System Conﬁguration: The experiments were con-
ducted on a system with two Intel Xeon E5645 CPUs (to-
taling 12 physical cores) clocked at 2.40GHz. Each fuzzing
instance was pinned to a separate physical core with a
private 32kB L1 data cache, 256kB uniﬁed L2 cache, and
a shared 12MB L3 cache. Fuzzers were run for 24 hours.
Because the run time is relatively short, the deterministic
fuzzing step is skipped, and the fuzzers were conﬁgured
to run in persistent mode. Persistent mode enables feeding
multiple inputs in a loop and does not have any fork() call
or initialization overheads, thus signiﬁcantly boosts the test
execution rate. This setup is adopted from FuzzBench [10].
As for the instrumentation mode, we used the aﬂ-clang-
fast that leverages an LLVM compiler pass to inject the
Table II: Benchmark Characteristics
Static
edges3 Version
v1.2.11
v1.6.35
v245
v2.0.4
v2.21.0
v6.3.1
v2.6.4
v2.9.10
v1.0.2u
875
2,987
53,453
9,542
10,942
7,830
10,021
50,327
45,989
89,658
62,523
123,767
45,136
v1.0
v7.68.0
v7.4.3
v3.31.1
v10.0.1
977,899
Benchmark
Number
of seeds
Discovered
edges1
Collision
rate2 (%)
zlib
libpng
systemd
libjpeg
mbedtls
proj4
harfbuzz
libxml2
openssl
bloaty
curl
php
sqlite3
77
1
6
1
1
43
58
1
2,241
94
31
2,782
1,256
722
1,218
2,314
2,928
5,377
6,379
8,930
9,422
10,297
10,536
12,728
20,260
40,948
0.55
0.92
1.74
2.20
3.99
4.71
6.51
6.86
7.46
7.62
9.11