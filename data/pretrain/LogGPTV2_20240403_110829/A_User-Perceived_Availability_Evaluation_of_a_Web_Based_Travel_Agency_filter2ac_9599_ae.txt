### Web Service Unavailability Analysis

The following data represents the unavailability of a web service in different scenarios, with varying failure and request arrival rates. The figures illustrate how the number of web servers (Nw) impacts the unavailability of the web service under both perfect and imperfect coverage conditions.

#### Data Points
- 1 e+0
- 1 e-1
- 1 e-2
- 1 e-3
- 1 e-4
- 1 e-5
- 1 e-6
- 1 e-7
- 1 e-8
- 1 e-9
- 1 e-10

#### Parameters
- \(\lambda = 150/\text{sec}\)
- \(\lambda = 100/\text{sec}\)
- \(\lambda = 50/\text{sec}\)
- \(\mu = 1e-2/\text{h}\)
- \(\mu = 1e-3/\text{h}\)
- \(\mu = 1e-4/\text{h}\)

#### Figures
- **Figure 11: Web Service Unavailability (Perfect Coverage)**
- **Figure 12: Web Service Unavailability (Imperfect Coverage)**

Both figures show that increasing the number of web servers (Nw) from 1 to 2, 3, or 4 (depending on the failure and request arrival rates) reduces the web service unavailability. However, when the coverage is imperfect, the trend reverses for Nw values higher than 4 (Figure 12). This is because, with imperfect coverage, increasing the number of servers also increases the probability of the system being in states where the web service is unavailable, requiring manual reconfiguration. The probability of a request being rejected due to a full buffer plays a significant role until a certain value of Nw. When the number of servers exceeds this threshold, the total service rate and buffer capacity are sufficient to handle the flow of arrivals without rejecting requests. In such cases, the unavailability of the web service mainly results from hardware and software failures leading to a down state.

Compared to the imperfect coverage model, the model with perfect coverage is more sensitive to variations in Nw. The unavailability decreases exponentially as Nw increases, and the trend does not reverse for values higher than 4. Additionally, the web server failure rate significantly impacts availability only when the system load (\(\lambda / \mu\)) is lower than 1.

#### Design Decisions
Based on these results, design decisions can be made:
- Determine the number of servers needed to achieve a given availability requirement.
- Evaluate the maximum availability that can be obtained with a set number of servers.

For example, with the model of imperfect coverage:
- To achieve an unavailability lower than \(5 \text{ min/year} \) (unavailability < \(10^{-3} \text{ per hour}\)), at least 2 servers are needed if the request arrival rate is 50 per second, and 4 servers if the request arrival rate is 100 per second.
- With a failure rate of \(10^{-2} \text{ per hour}\), the same requirement can be met, but it cannot be satisfied with a failure rate of \(10^{-5} \text{ per hour}\).

Similar sensitivity analyses can be conducted to study the level of availability achievable with a given number of web servers. For instance, using three servers, the unavailability would be lower than 1 hour per year if the failure rate varies from \(10^{-2} \text{ to } 10^{-4} \text{ per hour}\) and the system load is less than 1.

### User-Level Availability Results

Using Equation (10), we evaluate the availability as perceived by user classes A and B. The parameters involved in this equation are provided in Table 7, and the probabilities characterizing user execution scenarios for classes A and B are presented in Table 1. It is assumed that the web service is implemented on four servers with imperfect coverage (Nw=4, c=0.98, \(\lambda = 100/\text{sec}\), \(\mu = 10^{-4}/\text{hour}\)).

#### Model Parameters
- \(A_{net} = A_{LAN} = 0.9966\)
- \(A(CAS) = A(CDS) = 0.996\)
- \(A(Disk) = 0.9\)
- \(APS = AFi = AHi = ACi = 0.9\)
- \(q_{23} = 0.2\)
- \(A(WS) = 0.999995587\)
- \(q_{24} = 0.8\)
- \(q_{45} = 0.4\)
- \(q_{47} = 0.6\)

#### User Perceived Availability
Table 8 presents the user-perceived availability for user classes A and B, considering different numbers of flight, car, and hotel reservation systems (NF, NH, NC) interacting with the travel agency system. The same number is assumed for NF, NH, and NC.

The results show that for a given user class, the user-perceived availability increases significantly when the number of reservation systems increases from 1 to 4, and then stabilizes. The availability variation rate is directly related to the availability assigned to each reservation system. Comparing the results for class A and B users, different operational profiles lead to significant differences in the availability perceived by the users. For instance, with NF = NH = NC = 5, the user-perceived unavailability is about 173 hours per year for class A users and 190 hours for class B users, accounting for all possible user scenarios.

#### User Scenarios
User scenarios can be grouped into four categories (SC1, SC2, SC3, SC4) to analyze the contribution of each category to the perceived availability:
- **SC1**: Scenarios leading to the execution of "Home" or "Browse" functions without invoking other functions (scenarios 1-3).
- **SC2**: Scenarios including the "Search" function without going through the "Book" or "Pay" functions (scenarios 4-6).
- **SC3**: Scenarios including the "Book" function (scenarios 7-9).
- **SC4**: Scenarios reaching the "Pay" function (scenarios 10-12).

Figure 13 illustrates the unavailability caused by each scenario category for class A and B users, assuming the web service is implemented on four servers with imperfect coverage.

- **Class A Users**:
  - UA(A users): Total unavailability
  - UA(SC1): Contribution of SC1
  - UA(SC2): Contribution of SC2
  - UA(SC3): Contribution of SC3
  - UA(SC4): Contribution of SC4

- **Class B Users**:
  - UA(B users): Total unavailability
  - UA(SC1): Contribution of SC1
  - UA(SC2): Contribution of SC2
  - UA(SC3): Contribution of SC3
  - UA(SC4): Contribution of SC4

The unavailability caused by scenarios ending with a trip payment (SC4) is higher for class B users compared to class A users (43 hours downtime per year for class B users vs. 16 hours for class A users). This results in a higher impact in terms of revenue loss for the travel agency provider. Assuming a transaction rate of 100 per second, the total number of transactions lost is 5.7 million for class A users and 15.5 million for class B users. If the average revenue generated by each transaction is $100, the revenue loss amounts to $570 million and $1.55 billion, respectively.

This result underscores the importance of accurately estimating the user operational profile to obtain realistic predictions of the economic and business impact of failures.

### Conclusion

In this paper, we have illustrated the main concepts of our hierarchical modeling framework for evaluating the dependability of internet-based applications using a travel agency example. Our objectives were to show how to apply our framework by decomposing the target system into four levels (user, function, service, and resource) and to present typical dependability analysis and evaluation results to help e-business providers make informed design decisions.

For illustration, we considered simplified yet realistic assumptions concerning the user operational profile and the travel agency architecture, and analyzed their impact on the user-perceived availability. The availability measure takes into account the impact of performance-related failures as well as traditional software and hardware failures. The sensitivity analyses clearly demonstrate the appropriateness of this measure. We have shown that the proposed hierarchical framework provides a systematic and pragmatic modeling approach necessary to evaluate the dependability characteristics of the target application at different levels of abstraction.

Future work will focus on extending the framework to handle more complex assumptions and models, including failures that occur when the response time exceeds an acceptable threshold.

### References
[1] Bakos Y., "The Emerging Role of Electronic Marketplaces on the Internet," Communications of the ACM, 41 (8), pp.35-42, 1998.
[2] Menascé D. A. and Almeida V. A. F., Capacity Planning for Web Services: Metrics, Models, and Methods, Prentice Hall PTR, Upper Saddle River, NJ, USA, 2002.
[3] Shim S. S. Y., Pendyala V. S., Sundaram M., and Gao J. Z., "Business-to-Business E-Commerce Frameworks," Computer (October), pp.40-47, 2000.
[4] Purba S., Architectures for E-Business Systems: Building the Foundation for Tomorrow's Success, Best Practices Series, AUERBACH Publications - CRC Press LLC, Boca Raton, FL, USA, 2002.
[5] Goodyear M., Enterprise System Architectures: Building Client/Server and Web-based Systems, AUERBACH Publications - CRC Press LLC, Boca Raton, FL, USA, 2000.
[6] Long D., Muir A., and Golding R., "A Longitudinal Survey of Internet Host Reliability," in Proc. 14th Symposium on Reliable Distributed Systems (SRDS-95), pp.2-9, Bad Neuenahr, Germany, September 1995.
[7] Kalyanakrishnam M., Iyer R. K., and Patel J. U., "Reliability of Internet Hosts: a Case Study from the End User's Perspective," Computer Networks, 31, pp.47-57, 1999.
[8] Machiraju V., Dekhil M., Griss M., and Wurster K., E-services Management Requirements, HP Laboratories Palo Alto, CA, USA, N°HPL-2000-60, May 2000.
[9] Paxson V., Mahdavi J., Adams A., and Mathis M., "An Architecture for Large-Scale Internet Measurement," IEEE Communications Magazine (August), pp.48-54, 1998.
[10] Xie W., Sun H., Cao Y., and Trivedi K. S., "Modeling of Online Service Availability Perceived by Web Users," in IEEE Global Telecommunications Conference (GLOBECOM 2002), IEEE Computer Society, Taipei, Taiwan, November 2002.
[11] Kaâniche K., Kanoun K., and Rabah M., A Preliminary Framework for SoS Dependability Modelling and Evaluation, DSoS Project, IST-1999-11585, LAAS Report N°01157, April 2001.
[12] Kaâniche K., Kanoun K., and Rabah M., "A Framework for Modeling the Availability of e-Business Systems," in 10th International Conference on Computer Communications and Networks, pp.40-45, IEEE CS, Scottsdale, AZ, USA, 15-17 October 2001.
[13] Menascé D. A. and Almeida V. A. F., Scaling for E-Business: Technologies, Models, Performance, and Capacity Planning, Prentice Hall PTR, Upper Saddle River, NJ, USA, 2000.
[14] van Moorsel A., "Metrics for the Internet Age: Quality of Experience and Quality of Business," in Fifth International Workshop on Performability Modeling of Computer and Communication Systems, pp.26-31, Universität Erlangen-Nürnberg, Institut für Informatik, Germany, September 2001.
[15] Menascé D. A., Almeida V. A. F., Fonseca R. C., and Mendes M. A., "Business-oriented Resource Management Policies for E-commerce Servers," Performance Evaluation, 42 (2-3), pp.223-239, 2000.
[16] Hariri S. and Mutlu H. B., "A Hierarchical Modeling of Availability in Distributed Systems," in 11th International Conference on Distributed Computing Systems, pp.190-197, IEEE Computer Society, Arlington, TX, USA, 1991.
[17] Kanoun K. and Powell D., "Dependability Evaluation of Fault-tolerant Communication Topologies for the Delta-4 Distributed Architecture," in 10th IEEE Symposium on Reliable Distributed Systems (SRDS-10), pp.130-141, IEEE Computer Society, Pisa, Italy, 1991.
[18] Meyer J. F., "On Evaluating the Performability of Degradable Computer Systems," IEEE Transactions on Computers, C-29 (8), pp.720-731, 1980.
[19] Meyer J. F., "Closed-form Solutions of Performability," IEEE Transactions on Computers, C-31 (7), pp.648-657, 1982.
[20] Allen A. O., Probability, Statistics, and Queuing Theory — With Computer Science Applications, Computer Science and Applied Mathematics, Academic Press, 1978.