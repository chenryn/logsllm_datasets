cious and intentional. The Shutterﬂy app that extracts geolo-
cation information from EXIF metadata may not be doing
this to learn location information about the user or may not be
using this data later for any purpose. On the other hand, cases
where an app contains both code to access the data through
the permission system and code that implements an evasion
do not easily admit an innocent explanation. Even less so for
those containing code to legitimately access the data and then
store it for others to access. This is particularly bad because
covert channels can be exploited by any app that knows the
protocol, not just ones sharing the same SDK. The fact that
Baidu writes user’s IMEI to publicly accessible storage al-
lows any app to access it without permission—not just other
Baidu-containing apps.
6.1 Privacy Expectations
In the U.S., privacy practices are governed by the “notice and
consent” framework: companies can give notice to consumers
about their privacy practices (often in the form of a privacy
policy), and consumers can consent to those practices by us-
ing the company’s services. While website privacy policies
are canonical examples of this framework in action, the per-
missions system in Android (or in any other platform) is an-
other example of the notice and consent framework, because
it fulﬁlls two purposes: (i) providing transparency into the
sensitive resources to which apps request access (notice), and
(ii) requiring explicit user consent before an app can access,
collect, and share sensitive resources and data (consent). That
apps can and do circumvent the notice and consent framework
is further evidence of the framework’s failure. In practical
terms, though, these app behaviours may directly lead to pri-
vacy violations because they are likely to defy consumers’
expectations.
Nissenbaum’s “Privacy as Contextual Integrity” framework
deﬁnes privacy violations as data ﬂows that defy contextual
information norms [55]. In Nissenbaum’s framework, data
ﬂows are modeled by senders, recipients, data subjects, data
614    28th USENIX Security Symposium
USENIX Association
types, and transmission principles in speciﬁc contexts (e.g.,
providing app functionality, advertising, etc.). By circumvent-
ing the permissions system, apps are able to exﬁltrate data
to their own servers and even third parties in ways that are
likely to defy users’ expectations (and societal norms), par-
ticularly if it occurs after having just denied an app’s explicit
permission request. That is, regardless of context, were a user
to explicitly be asked about granting an app access to per-
sonal information and then explicitly declining, it would be
reasonable to expect that the data then would not be accessi-
ble to the app. Thus, the behaviours that we document in this
paper constitute clear privacy violations. From a legal and
policy perspective, these practices are likely to be considered
deceptive or otherwise unlawful.
Both a recent CNIL decision (France’s data protection au-
thority), with respect to GDPR’s notice and consent require-
ments, and various FTC cases, with respect to unfair and de-
ceptive practices under U.S. federal law—both described in
the next section—emphasize the notice function of the An-
droid permissions system from a consumer expectations per-
spective. Moreover, these issues are also at the heart of a re-
cent complaint brought by the Los Angeles County Attorney
(LACA) under the California State Unfair Competition Law.
The LACA complaint was brought against a popular mobile
weather app on related grounds. The case further focuses on
the permissions system’s notice function, while noting that,
“users have no reason to seek [geolocation data collection]
information by combing through the app’s lengthy [privacy
policy], buried within which are opaque discussions of [the de-
veloper’s] potential transmission of geolocation data to third
parties and use for additional commercial purposes. Indeed,
on information and belief, the vast majority of users do not
read those sections at all” [76].
6.2 Legal and Policy Issues
The practices that we highlight in this paper also highlight
several legal and policy issues. In the United States, for ex-
ample, they may run afoul of the FTC’s prohibitions against
deceptive practices and/or state laws governing unfair busi-
ness practices. In the European Union, they may constitute
violations of the General Data Protection Regulation (GDPR).
The Federal Trade Commission (FTC), which is charged
with protecting consumer interests, has brought a number
of cases under Section 5 of the Federal Trade Commission
(FTC) Act [79] in this context. The underlying complaints
have stated that circumvention of Android permissions and
collection of information absent users’ consent or in a man-
ner that is misleading is an unfair and deceptive act [84]. One
case suggested that apps requesting permissions beyond what
users expect or what are needed to operate the service were
found to be “unreasonable” under the FTC Act. In another
case, the FTC pursued a complaint under Section 5 alleging
that a mobile device manufacturer, HTC, allowed developers
to collect information without obtaining users’ permission via
the Android permission system, and failed to protect users
from potential third-party exploitation of a related security
ﬂaw [81]. Finally, the FTC has pursued cases involving con-
sumer misrepresentations with respect to opt-out mechanisms
from tailored advertising in mobile apps more generally [83].
Also in the United States, state-level Unfair and Deceptive
Acts and Practices (UDAP) statutes may also apply. These
typically reﬂect and complement the corresponding federal
law. Finally, with growing regulatory and public attention
to issues pertaining to data privacy and security, data collec-
tion that undermines users’ expectations and their informed
consent may also be in violation of various general privacy
regulations, such as the Children’s Online Privacy Protection
Act (COPPA) [80], the recent California Privacy Protection
Act (CCPA), and potentially data breach notiﬁcation laws that
focus on unauthorized collection, depending on the type of
personal information collected.
In Europe, these practices may be in violation of GDPR.
In a recent landmark ruling, the French data regulator, CNIL,
levied a 50 million Euro ﬁne for a breach of GDPR’s trans-
parency requirements, underscoring informed consent require-
ments concerning data collection for personalized ads [25].
This ruling also suggests that—in the context of GDPR’s con-
sent and transparency provisions—permission requests serve
a key function of both informing users of data collection prac-
tices and as a mechanism for providing informed consent [81].
Our analysis brings to light novel permission circumven-
tion methods in actual use by otherwise legitimate Android
apps. These circumventions enable the collection of informa-
tion either without asking for consent or after the user has ex-
plicitly refused to provide consent, likely undermining users’
expectations and potentially violating key privacy and data
protection requirements on a state, federal, and even global
level. By uncovering these practices and making our data
public,5 we hope to provide sufﬁcient data and tools for regu-
lators to bring enforcement actions, industry to identify and
ﬁx problems before releasing apps, and allow consumers to
make informed decisions about the apps that they use.
7 Limitations and Future Work
During the course of performing this research, we made cer-
tain design decisions that may impact the comprehensiveness
and generalizability of this work. That is, all of the ﬁndings
in this paper represent lower bounds on the number of covert
and side channels that may exist in the wild.
Our study considers a subset of the permissions labeled by
Google as dangerous: those that control access to user iden-
tiﬁers and geolocation information. According to Android’s
documentation, this is indeed the most concerning and pri-
vacy intrusive set of permissions. However, there may be
5https://search.appcensus.io/
USENIX Association
28th USENIX Security Symposium    615
other permissions that, while not labeled as dangerous, can
still give access to sensitive user data. One example is the
BLUETOOTH permission; it allows apps to discover nearby
Bluetooth-enabled devices, which may be useful for consumer
proﬁling, as well as physical and cross-device tracking. Addi-
tionally, we did not examine all of the dangerous permissions,
speciﬁcally data guarded by content providers, such as ad-
dress book contacts and SMS messages.
Our methods rely on observations of network transmissions
that suggest the existence of such channels, rather than search-
ing for them directly through static analysis. Because many
apps and third-party libraries use obfuscation techniques to
disguise their transmissions, there may be transmissions that
our instrumentation does not ﬂag as containing permission-
protected information. Additionally, there may be channels
that are exploited, but during our testing the apps did not
transmit the accessed personal data. Furthermore, apps could
be exposing channels, but never abuse them during our tests.
Even though we would not report such behavior, this is still
an unexpected breach of Android’s security model.
Many popular apps also use certiﬁcate pinning [28, 61],
which results in them rejecting the custom certiﬁcate used by
our man-in-the-middle proxy; our system then allows apps
to continue without interference. Certiﬁcate pinning is rea-
sonable behaviour from a security standpoint; it is possible,
however, that it is being used to thwart attempts to analyse
and study the network trafﬁc of a user’s mobile phone.
Our dynamic analysis uses the Android Exerciser Monkey
as a UI fuzzer to generate random UI events to interact with
the apps. While in our prior work we found that the Monkey
explored similar code branches as a human for 60% of the
apps tested [66], it is likely that it still fails to explore some
code branches that may exploit covert and side channels. For
example, the Monkey fails to interact with apps that require
users to interact with login screens or, more generally, require
speciﬁc inputs to proceed. Such apps are consequently not
as comprehensively tested as apps amenable to automated
exploration. Future work should compare our approaches to
more sophisticated tools for automated exploration, such as
Moran et al.’s Crashscope [53], which generates inputs to an
app designed to trigger crash events.
Ultimately, these limitations only result in the possibility
that there are side and covert channels that we have not yet
discovered (i.e., false negatives). It has no impact on the va-
lidity of the channels that we did uncover (i.e., there are no
false positives) and improvements on our methodology can
only result in the discovery of more of these channels.
Moving forward, there has to be a collective effort coming
from all stakeholders to prevent apps from circumventing the
permissions system. Google, to their credit, have announced
that they are addressing many of the issues that we reported to
them [33]. However, these ﬁxes will only be available to users
able to upgrade to Android Q—those with the means to own a
newer smartphone. This, of course, positions privacy as a lux-
ury good, which is in conﬂict with Google’s public pronounce-
ments [58]. Instead, they should treat privacy vulnerabilities
with the same seriousness that they treat security vulnerabili-
ties and issue hotﬁxes to all supported Android versions.
Regulators and platform providers need better tools to mon-
itor app behaviour and hold app developers accountable by
ensuring apps comply with applicable laws, namely by pro-
tecting users’ privacy and respecting their data collection
choices. Society should support more mechanisms, techni-
cal and other, that empower users’ informed decision-making
with greater transparency into what apps are doing on their
devices. To this end, we have made the list of all apps that
exploit or contain code to exploit the side and covert channels
we discovered available online [8].
Acknowledgments
This work was supported by the U.S. National Security
Agency’s Science of Security program (contract H98230-18-
D-0006), the Department of Homeland Security (contract
FA8750-18-2-0096), the National Science Foundation (grants
CNS-1817248 and grant CNS-1564329), the Rose Founda-
tion, the European Union’s Horizon 2020 Innovation Action
program (grant Agreement No. 786741, SMOOTH Project),
the Data Transparency Lab, and the Center for Long-Term Cy-
bersecurity at U.C. Berkeley. The authors would like to thank
John Aycock, Irwin Reyes, Greg Hagen, René Mayrhofer,
Giles Hogben, and Refjohürs Lykkewe.
References
[1] IDA: About. Ida pro.
https://www.hex-rays.com/products/ida/.
[2] J. P. Achara, M. Cunche, V. Roca, and A. Francillon.
WiﬁLeaks: Underestimated privacy implications of the
access wiﬁ state Android permission. Technical Report
EURECOM+4302, Eurecom, 05 2014.
[3] A. Al-Haiqi, M. Ismail, and R. Nordin. A new
sensors-based covert channel on android. The Scientiﬁc
World Journal, 2014, 2014.
[4] D. Amalﬁtano, A. R. Fasolino, P. Tramontana, B. D. Ta,
and A. M. Memon. MobiGUITAR: Automated
model-based testing of mobile apps. IEEE Software,
32(5):53–59, 2015.
[5] Android Documentation. App Manifest Overview.
https://developer.android.com/guide/topics/
manifest/manifest-intro, 2019. Accessed:
February 12, 2019.
[6] Android Studio. UI/Application Exerciser Monkey.
https://developer.android.com/studio/test/
monkey.html, 2017. Accessed: October 12, 2017.
616    28th USENIX Security Symposium
USENIX Association
[7] Apktool. Apktool: A tool for reverse engineering
android apk ﬁles.
https://ibotpeaches.github.io/Apktool/.
[18] S. Cabuk, C. E. Brodley, and C. Shields. IP covert
channel detection. ACM Transactions on Information
and System Security (TISSEC), 12(4):22, 2009.
[8] AppCensus Inc. Apps using Side and Covert Channels.
https://blog.appcensus.mobi/2019/06/01/
apps-using-side-and-covert-channels/, 2019.
[9] S. Arzt, S. Rasthofer, C. Fritz, E. Bodden, A. Bartel,
J. Klein, Y. Le Traon, D. Octeau, and P. McDaniel.
FlowDroid: Precise Context, Flow, Field,
Object-sensitive and Lifecycle-aware Taint Analysis for
Android Apps. In Proc. of PLDI, pages 259–269, 2014.
[10] K. W. Y. Au, Y. F. Zhou, Z. Huang, and D. Lie. Pscout:
analyzing the android permission speciﬁcation. In
Proceedings of the 2012 ACM conference on Computer
and communications security, pages 217–228. ACM,
2012.
[11] V. Avdiienko, K. Kuznetsov, A. Gorla, A. Zeller,
S. Arzt, S. Rasthofer, and E. Bodden. Mining apps for
abnormal usage of sensitive data. In Proceedings of the
37th International Conference on Software Engineering-
Volume 1, pages 426–436. IEEE Press, 2015.
[12] G. S. Babil, O. Mehani, R. Boreli, and M. A. Kaafar. On
the effectiveness of dynamic taint analysis for protecting
against private information leaks on android-based
devices. In 2013 International Conference on Security
and Cryptography (SECRYPT), pages 1–8, July 2013.
[13] Baidu. Baidu Geocoding API. https://geocoder.
readthedocs.io/providers/Baidu.html, 2019.
Accessed: February 12, 2019.
[14] Baidu. Baidu Maps SDK. http://lbsyun.baidu.
com/index.php?title=androidsdk, 2019.
Accessed: February 12, 2019.
[15] Bauer, A. and Hebeisen, C. Igexin advertising network
put user privacy at risk. https:
//blog.lookout.com/igexin-malicious-sdk,
2019. Accessed: February 12, 2019.
[16] R. Bhoraskar, S. Han, J. Jeon, T. Azim, S. Chen,
J. Jung, S. Nath, R. Wang, and D. Wetherall.
Brahmastra: Driving Apps to Test the Security of
Third-Party Components. In 23rd USENIX Security
Symposium (USENIX Security 14), pages 1021–1036,
San Diego, CA, 2014. USENIX Association.
[19] Y. Cao, Y. Fratantonio, A. Bianchi, M. Egele, C. Kruegel,
G. Vigna, and Y. Chen. EdgeMiner: Automatically
Detecting Implicit Control Flow Transitions through
the Android Framework. In Proc. of NDSS, 2015.
[20] B. Chess and G. McGraw. Static analysis for security.
IEEE Security & Privacy, 2(6):76–79, 2004.
[21] M. Christodorescu and S. Jha. Static analysis of
executables to detect malicious patterns. Technical
report, Wisconsin Univ-Madison Dept of Computer
Sciences, 2006.
[22] M. Christodorescu, S. Jha, S. A Seshia, D. Song, and
R. E. Bryant. Semantics-aware malware detection. In
Security and Privacy, 2005 IEEE Symposium on, pages
32–46. IEEE, 2005.
[23] A. Continella, Y. Fratantonio, M. Lindorfer, A. Puccetti,
A. Zand, C. Kruegel, and G. Vigna.
Obfuscation-resilient privacy leak detection for mobile
apps through differential analysis. In Proceedings of
the ISOC Network and Distributed System Security
Symposium (NDSS), pages 1–16, 2017.
[24] Commission Nationale de l’Informatique et des
Libertés (CNIL). Data Protection Around the World.
https://www.cnil.fr/en/
data-protection-around-the-world, 2018.
Accessed: September 23, 2018.
[25] Commission Nationale de l’Informatique et des
Libertés (CNIL). The CNIL’s restricted committee
imposes a ﬁnancial penalty of 50 Million euros against