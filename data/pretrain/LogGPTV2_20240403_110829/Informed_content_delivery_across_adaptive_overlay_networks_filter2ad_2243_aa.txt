title:Informed content delivery across adaptive overlay networks
author:John W. Byers and
Jeffrey Considine and
Michael Mitzenmacher and
Stanislav Rost
Informed Content Delivery Across Adaptive Overlay
Networks ∗
John Byers
PI:EMAIL
Jeffrey Considine
PI:EMAIL
Michael Mitzenmacher
Stanislav Rost
PI:EMAIL
PI:EMAIL
Dept. of Computer Science
Boston University
Boston, Massachusetts
EECS
Harvard University
MIT Laboratory for
Computer Science
Cambridge, Massachusetts
Cambridge, Massachusetts
Abstract
Overlay networks have emerged as a powerful and highly ﬂexible
method for delivering content. We study how to optimize through-
put of large transfers across richly connected, adaptive overlay net-
works, focusing on the potential of collaborative transfers between
peers to supplement ongoing downloads. First, we make the case
for an erasure-resilient encoding of the content. Using the digital
fountain encoding approach, end-hosts can efﬁciently reconstruct
the original content of size n from a subset of any n symbols drawn
from a large universe of encoded symbols. Such an approach af-
fords reliability and a substantial degree of application-level ﬂex-
ibility, as it seamlessly accommodates connection migration and
parallel transfers while providing resilience to packet loss. How-
ever, since the sets of encoded symbols acquired by peers during
downloads may overlap substantially, care must be taken to enable
them to collaborate effectively. Our main contribution is a collec-
tion of useful algorithmic tools for efﬁcient estimation, summariza-
tion, and approximate reconciliation of sets of symbols between
pairs of collaborating peers, all of which keep message complexity
and computation to a minimum. Through simulations and experi-
ments on a prototype implementation, we demonstrate the perfor-
mance beneﬁts of our informed content delivery mechanisms and
how they complement existing overlay network architectures.
∗
John Byers, Jeffrey Considine and Stanislav Rost were sup-
ported in part by NSF grants ANI-0093296 and ANI-9986397.
Michael Mitzenmacher was supported in part by NSF grants
CCR-9983832, CCR-0118701, CCR-0121154, and an Alfred P.
Sloan Research Fellowship.
Permission to make digital or hard copies of all or part of
this work for personal or classroom use is granted without fee
provided that copies are not made or distributed for proﬁt or
commercial advantage and that copies bear this notice and the
full citation on the ﬁrst page. To copy otherwise, to republish, to
post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
SIGCOMM’02, August 19-23, 2002, Pittsburgh, Pennsylvania,
USA.
Copyright 2002 ACM 1-58113-570-X/02/0008...$5.00
Categories and Subject Descriptors
Organization]:
C.2
Communication Networks
[Computer
Systems
Computer-
General Terms
Algorithms, Measurement, Performance
Keywords
Overlay, peer-to-peer, content delivery, digital fountain, erasure
correcting code, min-wise summary, Bloom ﬁlter, reconciliation,
collaboration.
1 Introduction
Consider the problem of distributing a large new ﬁle across a
content delivery network of several thousand geographically dis-
tributed machines. Transferring the ﬁle with individual point-to-
point connections from a single source incurs two performance lim-
itations. First, the bandwidth consumption of such an approach is
wasteful. Second, the rate of each individual transfer is limited by
the characteristics of the end-to-end path between the source and
that destination. The problem of excessive bandwidth consumption
can be solved by a reliable multicast-based approach. With multi-
cast, only a single copy of each packet payload transmitted by the
server traverses each link in the multicast tree en route to the set
of clients. Providing reliability poses additional challenges, but one
elegant and scalable solution is the digital fountain approach [8],
whereby the content is ﬁrst encoded via an erasure-resilient encod-
ing [18, 24, 17], then transmitted to clients. In addition to providing
resilience to packet loss, this approach also accommodates asyn-
chronous client arrivals and, if layered multicast is also employed,
heterogeneous client transfer rates.
Although multicast-based dissemination offers near-optimal scal-
ing properties in bandwidth and server load, IP multicast suffers
from limited deployment. This lack of deployment has led to the de-
velopment of end-system approaches [10, 13, 9], along with a wide
variety of related schemes relevant to peer-to-peer content delivery
architectures [25, 27, 29, 30, 32]. Many of these architectures over-
come the deployment hurdle faced by IP multicast by requiring no
changes to routers nor additional router functionality. Instead, these
architectures construct overlay topologies, comprising collections
of unicast connections between end-systems, in which each edge
1
47S
S
F
S
A
B
A
A
A
B
B
B
A
B
C D
E
C D
DC
DC
E
E
E
C
D
E
B A,C
A B,E
C B,D,E
D,E
C
S C
S D,E
(a) Initial delivery tree.
(b) Parallel downloads.
(c) Collaborative transfers.
(d)
Figure 1: Possibilities for content delivery. Shaded content within a node in the topology represents the working set of that node. Connections
in (b) supplement (a); connections in (c) supplement (a)+(b). Source S and peer F have the content in its entirety. A, B each have different,
but overlapping halves of the full content. C, D, E each have 25% of the content.
(or connection) in the overlay is mapped onto a path in the under-
lying physical network by IP routing.
End-system multicast differs from IP multicast in a number of fun-
damental aspects. First, overlay-based approaches do not use a mul-
ticast tree; indeed, they may map multiple virtual connections onto
the same network links. Second, unlike IP multicast trees, overlay
topologies may ﬂexibly adapt to changing network conditions. For
example, applications using overlay networks may reroute around
congested or unstable areas of the Internet [2, 28]. Finally, end-
systems are now explicitly required to cooperate. This last point
is crucial and forms the essence of the motivation for our work:
given that end-systems are required to collaborate in overlays, does
it necessarily follow that they should operate like routers, and sim-
ply forward packets? We argue that this is not the case, and that
end-systems in overlays have the opportunity to improve perfor-
mance provided they have the ability to actively collaborate, in an
informed manner.
We now return to the second limitation with traditional service
models based on tree topologies: the transfer rate to a client in
such a topology is bounded by the available bandwidth of the bot-
tleneck link on the path from the server. In contrast, overlay net-
works can overcome this limitation. In systems with ample band-
width, transfer rates across overlay networks can substantially ben-
eﬁt from additional cross-connections between end-systems, if the
end-systems collaborate appropriately. Assuming that a given pair
of end-systems has not received exactly the same content, this ex-
tra bandwidth can be used to ﬁll in, or reconcile, the differences in
received content, thus reducing the total transfer time.
Our approach to addressing these limitations is illustrated in the
content delivery scenario of Figure 1. In the initial scenario de-
picted in Figure 1(a), S is the source and all other nodes in the
tree (nodes A through E) represent end-systems downloading a
large ﬁle via end-system multicast. Each node has a working set of
packets, the subset of packets it has received (for simplicity, we as-
sume the content is not encoded in this example). Even if the over-
lay management of the end-system multicast architecture ensured
the best possible embedding of the virtual graph onto the network
graph (for some appropriate deﬁnition of best), there is still consid-
erable room for improvement. A ﬁrst improvement can be obtained
by harnessing the power of parallel downloads [7], i.e. establishing
concurrent connections to multiple servers or peers with complete
copies of the ﬁle (Figure 1(b)). More generally, additional signif-
icant performance beneﬁts may be obtained by taking advantage
of “perpendicular” connections between nodes whose working sets
are complementary, as pictured in Figure 1(c). Beneﬁts of estab-
lishing concurrent connections to multiple peers have been demon-
strated by popular peer-to-peer ﬁle sharing systems such as Kazaa,
Grokster and Morpheus. The improvements in transfer rates that
these programs obtain provide preliminary, informal evidence of
availability of bandwidth for opportunistic downloads between col-
laborating peers. The legend of 1(d) depicts the portions of content
which can be beneﬁcially exchanged via opportunistic transfers be-
tween pairs of end-systems in this scenario.
As discussed earlier, the tree and directed acyclic graph topologies
of Figures 1(a) and 1(b) impede the full ﬂow of content to down-
stream receivers, as the rate of ﬂow monotonically decreases along
each end-system hop on paths away from the source. In contrast,
the opportunistic connections of the graph of Figure 1(c) allow for
higher transfer rates, but simultaneously demand a more careful
level of orchestration between end-systems to achieve those rates.
In particular, any pair of end-systems in a peer-to-peer relationship
must be able to determine which packets lie in the set difference of
their working sets, and subsequently make an informed transfer of
those packets, i.e. they must reconcile the two working sets.
When working sets are limited to small groups of contiguous blocks
of sequentially indexed packets, reconciliation is simple, since each
block can be succinctly speciﬁed by an index and a size. How-
ever, restricting working sets to such simple patterns greatly limits
ﬂexibility to the frequent changes which arise in adaptive overlay
networks, as we argue in Section 2. In that section, we also elab-
orate the numerous beneﬁts of using encoded content. The main
drawback of the added ﬂexibility provided by the use of erasure-
resilient content is that reconciliation becomes a more challenging
problem. To address this challenge, in Sections 3, 4 and 5, we pro-
vide a set of tools for estimating, summarizing, and approximately
2
48reconciling working sets of connected clients, all of which keep
message complexity and computation to a minimum. In Section 6,
we demonstrate through simulations and experiments on a proto-
type implementation that these tools, coupled with the encoding
approach, form a highly effective delivery method which can sub-
stantially reduce transfer times over existing methods. We provide
a recap of our results and draw conclusions in Section 7.
2 Content Delivery Across Overlay Networks
We motivate our approach ﬁrst by sketching fundamental chal-
lenges that must be addressed by any content delivery architecture
and outlining the set of opportunities that an overlay approach af-
fords. Next, we argue the pros and cons of encoded content, the
cons primarily being a small amount of added complexity and the
pros being greatly improved ﬂexibility and scalability. We outline
the encoding building blocks we use and enumerate the beneﬁts
they provide and the costs they incur.
2.1 Challenges and Opportunities
When operating in the context of the ﬂuid environment of the In-
ternet, there are a number of fundamental problems that a content
delivery infrastructure must cope with, including:
leave and rejoin the infrastructure at arbitrary times.
• Asynchrony: Receivers may open and close connections or
• Heterogeneity: Connections vary in speed and loss rates.
• Transience: Routers, links and end-systems may fail and
• Scalability: The service must scale to large receiver popula-
their performance may ﬂuctuate over time.
tions and large content.
Overlay networks should tolerate asynchrony and heterogeneity
and should adapt to transient behavior, all in a scalable manner. For
example, a robust overlay network should have the ability to adap-
tively detect and avoid congested or temporarily unstable [15, 2]
areas of the network. Continuous reconﬁguration of virtual topol-
ogy by overlay management strives to establish paths with the most
desirable end-to-end characteristics. While optimal paths may be
difﬁcult to identify, an overlay node can often identify paths that
are better than default Internet paths [2, 28]. Such reactive behavior
of the virtual topology may frequently force the nodes to reconnect
to better-suited peers. But of course this adaptive behavior then ex-
acerbates the fundamental problems enumerated above.
Another consequence of the ﬂuidity of the environment is that
content is likely to be disseminated non-uniformly across peers.
For example, discrepancies between working sets may arise due
to uncorrelated losses, bandwidth differences, asynchronous joins,
and topology reconﬁgurations. More speciﬁcally, receivers with
higher transfer rates and receivers who initiate the download ear-
lier will simply have more content than their peers. As the transfers
progress, and different end-systems peer with one another, working
sets will become further divergent and fragmented. By carefully or-
chestrating connections, one may be able to manage the level of
fragmentation, but only at the expense of restricting potential peer-
ing arrangements, thereby limiting throughput.
Finally, we also want to take advantage of a signiﬁcant opportunity
presented by overlay networks discussed in the introduction: the
3
ability to download content across multiple connections in parallel.
Or more generally, we wish to make beneﬁcial use of any available
connection present in an adaptive overlay, including ephemeral con-
nections which may be short-lived, may be preempted, or whose
performance may ﬂuctuate over time. This opportunity raises the
further challenge of delivering content which is not only useful, but
which is useful even when other connections are being employed
in parallel, and doing so with a minimum of set-up overhead and
message complexity.
2.2 Limitations of Stateful Solutions
Solutions to the problems and concerns of the preceding subsection
cannot be scalably achieved with techniques that require state to be
stored at connection endpoints. For example, while issues of con-
nection migration, heterogeneity, and asynchrony are tractable, so-
lutions to each problem generally require signiﬁcant per-connection
state. The retained state makes such approaches highly unscalable.
Moreover, bulky per-connection state can have signiﬁcant impact
on performance, since this state must be maintained in the face of
reconﬁguration and reconnection.
Parallel downloading using stateful approaches is also problematic,
as discussed in [7]. The natural approach is to divide the range of
the missing packets into disjoint sets in order to download different
ranges from different sources. With heterogeneous bandwidth and
transient network conditions, effectively predicting the correct dis-
tribution of ranges among sources is difﬁcult, and hence frequent
renegotiation may be required. Also, there is a natural bottleneck
that arises from the need to obtain “the last few packets.” If an end-
system has negotiated with multiple sources to obtain certain packet
ranges, and one source is slow in sending the last necessary packets,
the end-system must either wait or pursue a ﬁne-grained renegoti-
ation with other sources. Both of these problems are alleviated by
the use of encoded content, as we describe below. While we do not
argue that parallel downloading with unencoded content is impos-
sible (for example, see [26]), the use of encoding facilitates simpler
and more effective parallel downloading.
One other complication is that in order to maximize the advantage
of obtaining useful content from multiple peers, it is actually ben-
eﬁcial to have partially downloaded content distributed unevenly
across participating end-systems, so that there is considerable dis-
crepancy between working sets. As noted earlier, discrepancies in
working sets will naturally arise due to factors such as uncorre-
lated losses, bandwidth differences, asynchronous joins, and topol-
ogy reconﬁgurations. But stateful approaches in which end-systems
attempt to download contiguous blocks of unencoded packets work
against this goal, since end-systems effectively strive to reduce the
discrepancies between the packets they obtain. Again, in schemes
using encoded content, this problem is not a consideration.
2.3 Beneﬁts of Encoded Content
An alternative to using stateful solutions as described above is the
use of the digital fountain paradigm [8] running over an unreliable
transport protocol. The digital fountain approach was originally de-
signed for point-to-multipoint transmission of large ﬁles over lossy
channels. In this application, scalability and resilience to packet loss
is achieved by using an erasure correcting code [17, 18, 24] to pro-
duce an unbounded stream of encoding symbols derived from the
49source ﬁle. The encoding stream has the guarantee that a receiver is
virtually certain to be able to recover the original source ﬁle from
any subset of distinct symbols in the encoding stream equal to the
size of the original ﬁle. In practice, this strong decoding guarantee
is relaxed in order to provide efﬁcient encoding and decoding times.
Some implementations are capable of efﬁciently reconstructing the
ﬁle having received only a few percent more than the number of
symbols in the original ﬁle [17, 16, 8], and we assume such an im-
plementation is used. A digital fountain approach provides a num-
ber of important beneﬁts which are useful in a number of content
delivery scenarios [8, 7, 16].
• Continuous Encoding: Senders with a complete copy of a
ﬁle may continuously produce encoded symbols from the con-
tent.
• Time-Invariance: New encoding symbols are produced in-
dependently from symbols produced in the past.
• Tolerance: Digital fountain streams are useful to all receivers
regardless of the times of their connections or disconnections
and their rates of sampling the stream.
• Additivity: Fountain ﬂows generated by senders with differ-
ent sources of randomness are uncorrelated, so parallel down-
loads from multiple servers with complete copies of the con-
tent require no orchestration.
While the full beneﬁts of encoded content described above apply
primarily to a source with a copy of the entire ﬁle, some beneﬁts can
be achieved by end-systems with partial content, by re-encoding the
content as described in Section 5.4. The ﬂexibility provided by the
use of encoding frees the receiver from receiving all of a set of dis-
tinct symbols and enables fully stateless connection migrations, in
which no state need be transferred among hosts and no dangling re-
quests for retransmission need be resolved. It also allows the nodes
of the overlay topology to connect to as many senders as necessary
and obtain distinct encoding symbols from each, provided these
senders are in possession of the entire ﬁle.
There is one signiﬁcant disadvantage from using encoded content,
aside from the small overhead associated with encoding and decod-