# Network-Aware Service Placement in a Distributed Cloud Environment

## Authors
Moritz Steiner, Bob Gaglianello, Vijay K. Gurbani, Volker Hilt, W. D. Roome, Michael Scharf, and Thomas Voith  
Bell Labs, Alcatel-Lucent  
{first.last}@alcatel-lucent.com

## Abstract
This paper addresses the challenge of distributing compute and storage resources across multiple geographically dispersed locations in a wide-area network. By strategically placing these resources, we aim to reduce latency, lower bandwidth costs, and enhance service availability. Our work introduces efficient algorithms for the optimal placement of services with varying characteristics—ranging from highly latency-sensitive applications to those requiring extensive storage or computational power. These algorithms require real-time data on the status of network, compute, and data resources, which are then matched to specific application requirements.

The demonstration showcases a network-aware cloud system that integrates computation, storage, and network connectivity in distributed cloud environments. Our dynamic service placement algorithm continuously monitors these resources and uses this information to place or migrate services, thereby optimizing user experience.

## Categories and Subject Descriptors
C.2.1 [Computer-Communication Networks]: Network Architecture and Design—Network operating systems

## Keywords
Cloud, service placement

## 1. Introduction
Cloud computing has experienced significant growth in recent years, and analysts predict this trend will continue [3]. Currently, public cloud providers operate a few large data centers, offering compute and storage resources. However, they do not own or manage the networks connecting their data centers to the public Internet or customer sites. Conversely, network operators manage the network but lack awareness of the cloud services using it. We argue that integrating data center and network operations, and adding compute and storage resources at multiple network locations, can create new opportunities.

One such opportunity is to run services closer to users, enabling parallel execution at multiple locations. This approach enhances the performance of latency-sensitive services, potentially matching or surpassing the quality users receive from local computers. Examples include remote storage, virtual desktops, and action games. Integrated network and cloud providers can offer high-quality services to end users by controlling all involved resources. Additionally, running services in data centers close to users can reduce bandwidth costs.

## 2. Research Challenges
To maximize the benefits of a distributed cloud system, we need efficient service placement algorithms that can balance multiple, sometimes conflicting, objectives [1]. For instance, a service provider may aim to minimize communication, compute, and storage costs while maximizing link and data-center utilization and ensuring a high quality of experience for users. This is a complex, multi-dimensional optimization problem.

The placement and resource allocation algorithms require input from both the data centers and the network, including available resources and a normalized measure of the cost of accessing these resources. A key challenge is to summarize and abstract this data to a level that is meaningful for solving the optimization problem without revealing too much detail about the network and data centers. Additionally, the algorithms must consider the application's profile, such as its latency sensitivity, storage requirements, communication patterns, and legal constraints.

Another challenge is to provide an environment that enables rapid deployment of new, distributed, elastic, and resilient services. This requires a management system optimized for distributed clouds.

## 3. Demonstration
We have developed a solution for network-aware service placement in a distributed cloud, which will be demonstrated. The solution consists of several components:

1. **Cloud Management System**: We use CloudStack [2], an open-source cloud management system, to show that our solution is not dependent on proprietary protocols.
2. **Web-based Dashboard**: We implemented a web-based frontend "dashboard" that communicates with other components and provides a central interface for monitoring and configuring the system.
3. **ALTO Protocol**: We use the ALTO protocol [4], developed within the IETF, to obtain information about the communications network. We developed an ALTO server that collects network topology data and provides an abstract view of the topology and associated costs.

The overall function of the system is as follows: The cloud dashboard queries the ALTO server for network metrics and the cloud management system for data center load. Using this input and the user's location, the dashboard runs a placement decision algorithm, which computes a score for each data center and recommends the best one.

The demonstration setup includes four laptops and an Ethernet switch to simulate multiple data centers connected to and controlled by a cloud management system. Three laptops form mini data centers, while the fourth hosts the cloud management software, dashboard, measurement logic, and ALTO server. An additional laptop runs the remote desktop client, and another device (laptop or tablet) displays the network topology and cloud operations center dashboard.

## 4. Scenarios
Our demonstration uses a virtual desktop as a sample application. Access to a remote desktop is a promising use case for outsourcing enterprise infrastructure, using the standard RDP protocol [5] to connect the user to the host of the virtual desktop. The virtual desktop is highly latency-sensitive, making it an ideal example to highlight the benefits of distributed data centers.

### Scenario 1: High-Definition Video Playback
- **Initial Setup**: A high-definition video is played on the client laptop. The virtual desktop, running in a remote data center, renders the video and sends screen updates to the client via RDP. Initially, the video plays smoothly with synchronized audio.
- **Degraded Experience**: Latency and loss are introduced between the client and the data center, causing the video to become choppy and out of sync with the audio.
- **Solution**: The dashboard displays the network topology and live measurements of link and data center load. The placement algorithm calculates scores for each data center and suggests a better one. The virtual desktop is migrated to the new data center, restoring the video quality.

### Scenario 2: Powerpoint Presentation
- **Initial Setup**: A user works on a Powerpoint presentation with the virtual desktop, which responds smoothly to edits.
- **Degraded Experience**: As network latency increases, the user finds it increasingly difficult to work effectively.
- **Solution**: The dashboard and network monitoring tools are used to select a better data center and migrate the virtual desktop, restoring the user's productivity.

In summary, our demonstration highlights the tight integration of the network with a distributed cloud solution, showcasing how migrating services to different data centers can mitigate performance issues.

## 5. References
[1] M. Alicherry and T. V. Lakshman. Network Aware Resource Allocation in Distributed Clouds. In INFOCOM, 2012.  
[2] CloudStack - Open Source Cloud Computing. http://www.cloudstack.org/  
[3] Gartner Cloud Market Prediction. http://tiny.cc/x696bw  
[4] IETF ALTO Working Group. http://datatracker.ietf.org/wg/alto/  
[5] Windows Remote Desktop Services. http://tiny.cc/zt05bw