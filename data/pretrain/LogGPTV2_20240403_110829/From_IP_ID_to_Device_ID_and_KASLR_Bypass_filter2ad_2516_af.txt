(cid:1) f δL+10
For false positives, we also assume that a burst contains
the average number of false pairs and true pairs A =
(L
M (cid:99). We note that the probability for
(cid:98) f δL+10
2)
f ∆t
M )k(1 −
M )A−k. The probability of |W|− 1 false keys to generate at
1
least one false positive key is therefore:
a single false key to match exactly k pairs is(cid:0)A
(cid:1)( 1
M )A−i(cid:17)|W|−1
Prob(FP) ≈ 1−(cid:16) ν−1
M )i(1− 1
(cid:18)A
(cid:19)
∑
1
(
i
k
i=0
Assuming |W| = 248 (worst case – Android), we enumerated
over all ν values for each L in {200,250, . . . ,500} to ﬁnd the
optimal ν (per L). We found that L = 400 (with ν = 11) is the
minimal “round” L satisfying Prob(FP)+Prob(FN)≤ 10−6
at its optimal ν.
6.10 A More Accurate Treatment for L = 400
Using a computer simulation, we approximated the distribu-
tions of all collisions pA(n) (using 108 simulation runs), and
of true collisions pT (n) (using 109 simulation runs). The
simulations took into account 1% packet loss. With these,
we can calculate more accurate approximations:
n
1
i=0
pT (i)
pA(n)
Prob(FN) ≈ ν−1
∑
(cid:19)
(cid:18)n
M )n−i(cid:17)|W|−1
(cid:16) ν−1
Prob(FP) ≈ 1−∑
∑
(cid:1) = 0 where k > n.) We enumer-
(We use the convention(cid:0)n
M )i(1− 1
ated over values 1 ≤ ν ≤ 20 for L = 400 and |W| = 248 (worst
case – Android.) The minimal Prob(FP) + Prob(FN) is at
ν = 11, where Prob(FP) = 6.2 × 10−10 and Prob(FN) =
4.2× 10−8. We get the same optimal ν value for L = 400 as
we got in Section 6.9, which means that the approximation
steps we took there are reasonable.
i=0
(
i
k
6.11 Practical Considerations
Controlling packets from the browser As explained in
Section 6.3, it is possible to emit UDP trafﬁc to arbitrary
hosts and ports using WebRTC. The packet payload is not
controlled. The tracker can use the UDP destination port in
order to associate STUN trafﬁc to the same measurement.
Synchronization and packet transmission/arrival order
Unlike the Windows technique, in the Linux/Android track-
ing technique there is no need to know the exact transmission
order of the packets within a single burst.
False positives and false negatives Using a computer sim-
ulation with L = 400 destination IP addresses, a burst length
of δL = 0.6 seconds, and packet loss rate of 0.01, we cal-
culated an approximation of for the false negative rate of
4.2 × 10−8 for ν = 11, and an approximation for the false
positive rate of 6.2 × 10−10. These approximations were
computed assuming |W| = 248 (worst case – Android). See
Section 6.10 for more details.
Device ID collisions The expected number of pairs of de-
vices with colliding IDs, due to the birthday paradox, and
given R devices and a key space of size |W|, is (R
2)/|W|. For
Algorithms A1 and A2 the key space size is |W| = 232, and
will cause device ID collisions once there are several tens of
thousands of devices. For R = 106 this will affect 0.00023 of
the population (2 out of every 10,000 devices). For Alg. A3,
the key space size (with KASLR) is ≥ 241, so collisions start
showing up with R in the millions. Even for R = 128· 106,
collisions affect only 0.00006 of the population.
1076    28th USENIX Security Symposium
USENIX Association
Dwell time
In order to record B5, the snippet page needs to
be loaded in the browser for 8-9 seconds. Navigating away
from the page will immediately terminate the STUN trafﬁc.
Environment factors All the UDP-related topics in Sec-
tion 4.8 are applicable as environment factors on the
Linux/Android tracking technique.
Longevity The device ID remains valid as long as the de-
vice is not shutdown or restarted. Mobile devices are rarely
shut down, and are typically restarted only on updates, which
happen once every several months, or even less frequently.
Scalability The attack is scalable. Device ID collisions
are rare even with many millions of devices (see above).
False positives and false negatives are also rare (less than
4.3× 10−8 combined). From a resource perspective, the at-
tack uses a ﬁxed number of IPs and servers, and a ﬁxed-size
RAM/disk. The required CPU power is proportional to the
number of devices measured per time unit. Network con-
sumption per test is negligible – approx. 13.5KB/s (at the IP
level) during measurement.
√
c.
6.12 Possible Countermeasures
Increasing M Changing the algorithm to use a larger num-
ber M of counters, will reduce the likelihood of pairs of IP
addresses using the same counter.
In response to such a
change the tracker can increase the number L of IP addresses
that is uses. The expected number of collisions is (L
2)/M, and
therefore increasing M by a factor of c requires the attacker
to increase L by only a factor of
On the other hand, δL also grows (probably linearly in L),
and when f δL ≥ 216 no information is practically revealed to
the tracker. It is probably safe to assume that the tracker can
handle an increase of L by a factor of ×10, which means that
in order to stop the attacker the IP ID generation algorithm
must increase M by more than ×100, making it too memory
expensive to be practical.
Increasing the key size (W) This can be an effective
counter-measure for the exhaustive search phase, though the
pair collection phase is unaffected by it. Yet some choices of
the hash function h might still allow fast cryptanalysis.
Strengthening h Our analysis does not rely on any prop-
erty of the hash function h, except that it is more-or-less uni-
form. Thus, changing h will not affect our results.
Replacing the algorithm See the last item in Section 4.9.
7 Experiment – Attacking Linux and Android
Devices in the Lab
In order to verify that we can extract the key used by Linux
and Android devices, we need to control hundreds of IP ad-
dresses. Controlling such a magnitude of Internet-routable
IP addresses was logistically out of scope for this research.
Therefore we had to settle for an in-the-lab setup, which nat-
urally limited the number of devices we could test.
7.1 Setup
We connected the tested devices to our own WiFi ac-
cess point, which advertised our laptop as a network gate-
way. Then we launched a Chrome-like browser inside the
Linux/Android device, and navigated to a page containing
a tracking snippet. The tracking snippet used WebRTC to
force UDP trafﬁc to a list of L = 400 hosts, and this trafﬁc
passed through our laptop (as a gateway) and was recorded.
We then ran the collision collection logic (Phase 1), and
fed its output (IP pairs whose IP IDs collide) to the exhaus-
tive key search logic (Phase 2). For KASLR-enabled de-
vices, we also provided the algorithm with the offset (relative
to the kernel image) of init_net, which we extracted from
the kernel image ﬁle given the build ID (can be inferred e.g.
from the User-Agent HTTP request header). We expected
that the algorithm will output a single key, which will match
a large part of the collisions.
7.2 Results
We tested 2 Linux laptops and 6 Android devices, together
covering the vast majority of operating system and hardware
parameters that regulate the IP ID generation. The results
from all tests were positive - our technique extracted a sin-
gle key and a kernel address of init_net where applicable
(which was identical to the address in /proc/kallsyms).
Note that due to hardware availability constraints, for the
Pixel 2XL case (|W| = 248), we provided the algorithm with
the correct 16 bit kernel displacement to reduce the key
search to 232. Table 2 provides information about the com-
mon kernel versions, their parameter combinations and the
tested devices.
The Attack time column is the extrapolated attack time in
seconds with 10,000 Azure B1s machines, based on E(Pf )
the average attack time is r ·|W|· E(Pf )
from Table 1, i.e.
where r is the time it takes a single B1s machine to test a sin-
gle key with a single pair, divided by 10,000. The standard
deviation of the attack time for a given f is r ·|W|· σ (Pf ),
which is σ (Pf )/E(Pf ) in Table 1 times the average attack run
time in Table 2. From a calibration run (single B1s machine,
10 pairs, 232 keys, 294.83 seconds run time) we calculated
r = 6.8645× 10−13, and populated the Attack Time column
in Table 1 with r·|W|· E(Pf ).
Applicability in-the-wild While our tests were carried out
in the lab, we argue that the results are representative of an
in-the-wild experiment with the same devices. We list the
following potential differences between in-the-lab and in-
the-wild experiment, and for each difference, we note why
our experiment can be projected to an in-the-wild scenario.
• Packet loss: our technique is not sensitive to packet
loss. We ran false positive/negative computer simula-
tions (assuming 1% packet loss) supporting this fact.
USENIX Association
28th USENIX Security Symposium    1077
Table 2: Common Linux/Android Kernels and Their Parameter Combinations
O/S
Kernel
Version
Linux (x64)
4.19+
Linux (x64)
4.8-4.18.x
Android
(ARM64)
Android
(ARM64)
Android
(ARM64)
4.4.56+,
4.9, 4.14
3.18.17+
3.4.109+
3.18.0-3.18.6
3.10.53+
3.4.103-3.4.108
Alg.
f [Hz] KASLR NET_NS
A3
A3
A3
A2
A1
250
250
300/
100
100
Yes
Yes
Yes
No
100
No
Yes
Yes
Yes
No
No
ρ
12
6
6/7
Don’t
care
Don’t
care
48
32
41
41
log2|W| Tested System
Dell Latitude
E7450 laptop
Dell Latitude
E7450 laptop
Pixel 2XL (ρ = 6)
Redmi Note 4
Xiaomi Mi4
Samsung J7 prime
Samsung S7
Meizu M2 Note
32
Attack
Time [s]
99
99
13,612/
9,775
0.15
0.15
• Network latency: our technique is not sensitive to net-
work latency (which is just a constant time-shift, from
our perspective).
• UDP jitter: this only affects correctly splitting the trafﬁc
into bursts. Our technique uses the “late” bursts, thus
assuring that the bursts are well separated time-wise and
that a jitter of σ = 0.1s does not affect tracking.
• Network interference (IPID modiﬁcation):
this issue
was already evaluated in-the-wild in the Windows ex-
periment, and the Windows results can be applied to
the Linux/Android use case.
• Packet reordering (within a burst): Our technique does
not rely on packet order within a burst.
Thus we conclude that our results (and henceforth, the prac-