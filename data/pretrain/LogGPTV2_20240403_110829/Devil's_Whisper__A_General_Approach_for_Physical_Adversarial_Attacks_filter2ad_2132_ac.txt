cal substitute model approximation approach still does not
succeed in generating the AE for the target command, we go
back to Line 2 to restart the whole algorithm. The E pochMax
parameter can restrain the number of total alternations. For
Line 16~17, we will not break the “AEGENERATION” func-
tion even if the Line 16 returns “True” and an effective AE is
crafted towards the target ASR API service. This is because
the successful sample to attack the target ASR API service
does not necessarily indicate the success towards IVC devices.
Therefore, instead of breaking the function, once a successful
AE is found, we save it towards the target ASR API service.
Finally, we can return a set X∗, where we preserve all potential
effective AEs towards target IVC devices.
Efﬁcient query of the black-box API. Intuitively, we can
query the black-box server after a few iterations, instead of
every iteration. We compare the decoded transcript of the
current sample from the black-box model with the desired
transcript, and use it as a reference to determine when the next
sample should be sent to the black-box server. Suppose we
set the number of iterations between two queries to the target
black-box model as Tinterval, and there are s words from the
decoded transcript of AE that match the desired commands
(e.g., s = 2 if “the door” is decoded from the current iteration
for the desired command “open the door”). Then T∗
interval
should be updated by Eq. 3.
interval = (cid:98)Tinterval × 1
T∗
s + 1
(cid:99)
(3)
Actually when examining the word match, we check the
phonetic similarity of the words, rather than character-by-
character match, since the language model of the speech recog-
nition systems will reﬁne the phonetic-similar words based on
semantics. Hence, we applied SoundEx [35], a tool to encode
homophones with the same representation even though they
have minor differences in spelling. Thus, s will be updated
by comparing the SoundEx code of the decoded command
and the target command. For example, “inter” is encoded
by SoundEx as “I536” and “pay Internet fee” is encoded as
“P000 I536 F000”. We consider one match (the code “I536”)
when comparing such decoded output and desired command,
so s will be set as 1 in this case.
4.2.3 Understanding the Attack
Although our approach works effectively in a black-box at-
tack, which will be demonstrated in our experiments (Sec-
tion 6.2), theoretic analysis of the technique are nontrivial,
just like the attempt to interpret adversarial learning in gen-
eral. Following we provide high-level intuition behind our
approach through an example.
At a high level, our approach is based upon the observa-
tion that different ASR systems have some similarity in their
classiﬁcation models, which allows us to utilize a white-box,
well-trained base model to move an instance towards the tar-
get model’s decision boundary, though it is likely different
from that of the white-box model. This difference is further
addressed using the substitute that ﬁne-tunes the instance
based upon the features of the target, including those related
to its decision boundary. In this way, we can utilize both
the information learnt from the target by the substitute and
that shared between the base model and the target to build a
successful AE.
For example, consider an attack on the Alexa Transcribe
API using the approach proposed in Section 4.2. The target
command is “clear notiﬁcation”. According to the experimen-
tal results, we found that the generation process (the base
model->substitute model->base model) helped ﬁnd the re-
sults that came closer to the target (recognized as “I don’t”
by Alexa Transcribe API). These results were then further
adjusted by the substitute model towards the target. They
became “notiﬁcation” in the 10th~30th iterations, and were
recognized as “clear notiﬁcation” in the 48th~60th iterations.
We believe that the transformation from “I don’t” to “clear no-
tiﬁcation” is attributed to the fact that the substitute is trained
to simulate the behavior of the Alexa Transcribe API on “clear
notiﬁcation”.
Implementation
5
5.1 Target IVC Devices and ASR Systems
Since we are developing a general approach generating AEs
against commercial black-box IVC devices, we plan to ex-
amine the AEs on most of the popular IVC devices currently
available on the market. In particular, we consider the speech
recognition devices/systems from Google, Microsoft, Ama-
zon, Apple, and IBM into the following three categories. First,
USENIX Association
29th USENIX Security Symposium    2673
we can ﬁnd the ASR API services associated with the cor-
responding IVC devices, e.g.,Google Assistant and Google
Cloud Speech-to-Text API8 (Category 1). Second, IVC device
is available, but ASR API is not, e.g., Apple Siri (Category 2).
Last, ASR API is available, but IVC device is not, e.g., IBM
Speech to Text API (Category 3).
Regarding Category 2, since there does not exist online
ASR API service required by local model approximation,
we attack such IVC devices mainly via transferability as in
Section 4.1. As for Category 3, since we cannot ﬁnd the IVC
device of IBM, we simulate such scenario by playing the AE,
recording it and then using the ASR API service to decode the
recorded audio as in Section 6.3. All the available ASR API
services return the decoded transcripts and the corresponding
conﬁdence level for the decoding.
5.2 Phrase Selection
Since the aim of our approach is to attack the commercial
IVC devices like Google Home, we only focused on the spe-
ciﬁc commands frequently used on these devices, e.g., “turn
off the light”, “navigate to my home”, “call my wife”, “open
YouTube”, “turn on the WeMo Insight”, etc. For each target
model, we selected 10 such commands and further appended
the default wake-up words for different systems (Google
Home, Amazon Echo and Microsoft Cortana) before each
of them. For the IBM Speech to Text API without commercial
IVC devices available, we utilized daily conversation sen-
tences. The full list of the phrases used on the target platforms
are presented by Table 10 and Table 11 in Appendix G.
5.3 Local Model Approximation
Model selection. In our experiment, we chose the Mini Lib-
rispeech model9 as the substitute model to approximate the
target models. Speciﬁcally, we used the default architecture
and hyper-parameters of Mini Librispeech to train all four
substitute models in our paper. These models were found to
be highly effective in our study (Section 6.2). On the other
hand, we acknowledge that even better performance could
be achieved by tuning model parameters, a mostly manual
and time-consuming procedure. So, our attack should only
be viewed as a lower bound for the security threats these
commercial systems are facing.
Corpus preparation. To enrich our corpus, we use 5 TTS
(Text-to-Speech) services to synthesize the desired command
audio clips, i.e., Google TTS [11], Alexa TTS [3], Bing
8There are four models in Google Cloud Speech-to-Text API, e.g.,
“phone_call model”, “video model”, “command_and_search model” and “de-
fault model”. In detail, “phone_call model” is used to translate the recorded
audio from phone call; “command_and_search model” is used for voice
command and short speech searching; “video model” is used for the video;
“default model” is not designed for a speciﬁc scenario. We use the com-
mand_and_search model to label our corpus since our corpus are more suit-
able for voice command and search application.
9Both Mini Librispeech and Kaldi ASpIRE (used as the base model) use
chain model, and Mini Librispeech is easy to implement.
TTS [6], IBM TTS [13] and an unnamed TTS [9], with 14
speakers in total including 6 males and 8 females. After using
the above TTS services to generate the desired command au-
dio clips, we enrich it by adding background noise or twisting
the audio. For the former, we add white noise to the original
audio, and set the amplitude of the added white noise to be
α. For the latter, we twist the original audio by changing its
speech rate either slower or faster. We deﬁne the twist-rate as
β (β = original_audio_duration/twisted_audio_duration).
Finally, we use the target black-box model to recognize the
tuned audio and ﬁlter it based on the correctness and the con-
ﬁdence level of the decoded results. The values of α, β and
the size of the corpus after ﬁltering are shown in Table 5 in
Appendix A.
We constructed the training corpus by combining the tuned
TTS audio clips (generated from the queries on the target
model) and the supplemental corpus from Mini Librispeech.
This is because the tuned TTS audio clips alone would cause
the substitute model to overﬁt to the set of commands used
in the queries (in the tuned TTS audio clips). As a result,
the AEs found from the less generalized substitute model
can be less effective at attacking the target models. On the
other hand, solely relying on the supplemental corpus is not
effective either, since the substitute trained without the in-
formation from the target will behave very differently from
the target, as conﬁrmed by our experiment (alternate models
based generation without approximation) in Section 6.4.
Furthermore, we evaluate the impact of different sizes of
supplemental corpus on Microsoft Bing Speech Service API
in Appendix B, and the results show that 3~40 hours size of
the supplemental corpora are all effective for our approach,
while with 1 hour supplemental data cannot generate AEs for
all of the target commands. For the four substitute models
of the target black-box platforms, we use the default Mini
LibriSpeech corpus (7.35 hours) as the supplemental corpus.
Training the substitute model. To train the substitute model,
we need to label the audio clips in the training corpus. Also,
as mentioned in Section 4.2, retrieving the pdf-id sequence
of the target commands is critical in our attack. However, we
found that some words (such as Cortana, WiFi, Bluetooth,
YouTube, WeMo, TV, etc.) are not included in the dictionaries
of the Mini Librispeech model and the ASpIRE Chain model,
so we cannot directly label these words and get the pdf-id
sequences of the corresponding commands. Simply extend-
ing the vocabulary of the language models [15] requires the
entire language models be retrained. To address this prob-
lem, we leveraged some linguistically similar phrases, based
upon the prior research [29, 42], to label those undocumented
ones10, which allows us to identify the pdf-id sequences of
their commands and further generate their AEs.
10The phrases like “Cort tana”, “why ﬁ”, “blue tooth”, “you too boo”,
“we mow” and “T V” are used to replace “Cortana”, “WiFi”, “Bluetooth”,
“YouTube”, “WeMo” and “TV”, respectively.
2674    29th USENIX Security Symposium
USENIX Association
6 Evaluation
6.1 Experiment Setup
Hardware. We conduct the experiment on the sever equipped
with four Nvidia Tesla K40m GPUs and 2 x 10 core Intel
Xeon E5-2650 2.30GHz processors, with 131 Gigabytes of
RAM and 1 Terabyte Hard Drive. We use a laptop (Lenovo
W541/Dell XPS 15/ASUS P453U) and a phone (iPhone
SE/iPhone 8) connected to a speaker (JBL clip 2/3 portable
speaker) to play out AEs. The target IVC devices are Google
Home Mini, Amazon Echo 1st Gen and voice assistants on
phones (Google Assistant App on Samsung C7100/iPhone
SE and Microsoft Cortana App on Samsung C7100/iPhone
8)11. The transferability of the AEs on Apple Siri is tested on
iPhone 8 and iPhone XR. The AEs on IBM WAA tests are
recorded by Huawei P30.
The original audio. Similar to CommanderSong, our attack
utilizes songs as the carrier for the AE produced. Speciﬁ-
cally, we used the dataset released by the CommanderSong
project [8], which contains 5 songs in each of the soft, popular,
rock and rap categories. Among them, we selected the songs
in the soft and popular categories, which are less noisy, al-
lowing the integrated perturbations more likely to overwhelm
the background music and be decoded correctly by the target
IVC devices. To further evaluate the 10 songs, we utilized two
commands “Okay Google, navigate to my home” and “Hey
Cortana, turn off the bedroom light”, and ran our approach
to embed the commands into the songs, against the speech
recognition APIs provided by Google and Microsoft Bing.
The results show that all the 10 songs can serve as carriers
for the commands to ensure their recognition by the APIs.
However, when listening to these AEs, we found that four
instances using soft songs and one using a popular song were
less stealthy than the other 5 manipulated songs and therefore
selected the latter for all follow-up experiments. Our exper-
imental results show that for each target command of each
target platform, there are at least 2 music clips across these 5
songs that can be crafted as effective and stealthy AEs. Fur-
ther we studied the songs more likely to be good candidates
for covering different commands (Section 7.1).
Besides the songs, we also tried other types of sounds as our
carriers for malicious commands in the experiments, e.g., am-
bulance siren sound, train passing sound, etc. We found songs
perform best in both effectiveness and stealthiness among
those sounds. Therefore, we choose the songs as our carrier.
6.2 Effectiveness
We evaluate the effectiveness of AEs generated by trans-
ferability based approach (TBA) and those generated by
alternate models generation approach (AGA) on the com-
mercial Speech API services and IVC devices. The target
commands for every black-box platform are listed in Ta-
ble 10 and Table 11 in Appendix G. Similar to the existing
11In Table 11, we elaborate the hardware used for each test.
works [20, 34, 40], we use SNR12 to measure the distortion of
AE to the original song.
Speech-to-Text API services attack. We feed our adversar-
ial examples (AEs) directly into the corresponding API ser-
vices, and observe the results. For the four models of Google
Cloud Speech-to-Text API (Section 5), we show the results
of “phone_call model” and “command_and_search model”,
since according to our tests the former is similar to “video
model” and the latter is similar to “default model”.
When attacking Speech-to-Text API, since we do not need
to wake up the IVC devices, we consider the AE successfully
attacks the target if the returned transcript matches the desired
command. The results are shown in Table 1, with the SNR
being the average of all commands on each black-box plat-
form (The result of each individual command can be found
in Table 10 in Appendix G). Speciﬁcally, the effectiveness of
our approach is evaluated using the success rate of command
(SRoC), that is, the number of successful commands vs. the
total number of the commands evaluated on a target service.
Here a successful command is the one for which we can gener-
ate at least one workable AE using our approach. The results
show that the AEs produced by TBA work well on Google
phone_call model with 100% SRoC, but fail on Google com-
mand_and_search model and Amazon Transcribe. Also the
AEs generated by AGA achieve an SRoC of 100% for all
Speech-to-Text API Services except Amazon Transcribe.
Table 1: The overall SRoC results on API services.
Google
Black
-box
Phone Command
TBA
10/10
AGA 10/10
SNR
(dB)
0/10
10/10
11.97
9.39
Micros-
oft Bing
Amazon
Transcribe
2/10
10/10
13.36
1/10
4/10
11.21
IBM
STT
3/10
10/10
10.06
Note: (1) “Phone” and “Command” represent the “phone_call model”, “com-
mand_and_search model” of Google Cloud Speech-to-Text API, respectively.
(2) “Microsoft Bing” represents the Microsoft Bing Speech Service API. (3)
“IBM STT” represents the IBM Speech to Text API. (4) The results were all
based on the tests conducted in October 2019.
As for Amazon Transcribe API service, we only crafted
successful AEs on 4 out of 10 target commands using AGA
method (details in Table 10 in Appendix G). We then per-
formed more tests on Amazon Transcribe API and found that
the API service cannot even recognize some plain TTS audio
clips for the target commands correctly. In contrast, these com-
mands can always be recognized by Amazon Echo. There can
be reasons for such difference. First, different models could
be used by Amazon Transcribe API and Echo device. Second,
the developers of Amazon Echo may set lower threshold to
identify voice commands, thus it is more sensitive to the voice
12SNR, deﬁned as the ratio of the original signal power to the noise power,
can be expressed as follows: SNR(dB) = 10 log10 (Px(t)/Pδ(t)), where Px(t)
represents the average power of the original signal and Pδ(t) represents the
average power of the distortion. It can be seen that a larger SNR value
indicates a smaller perturbation.
USENIX Association
29th USENIX Security Symposium    2675
commands when used physically.
IVC devices attack. We selected the AEs that can success-
fully attack the API service with high conﬁdence score (≥ 0.6)
to attack the IVC devices. Speciﬁcally, since the AEs work-
ing poorly on Amazon Transcribe API are not necessarily
working poorly on Amazon Echo as we identiﬁed before, we
decide to test the AEs on Amazon Echo directly, even if they
failed on Amazon Transcribe API. In our experiment, if the
devices respond to the played AE in the same way as the
regular voice command from human being, we consider the
AE for this command successful.
As shown in Table 2, the average SRoC of TBA is 26%. In
contrast, the average SRoC of AGA over all IVC devices can
be improved to 98%, which shows the proposed approach is
very effective in attacking real-world IVC devices. Based on
our evaluation, we ﬁnd that for most of the black-box models,
we can always ﬁnd the AEs that can successfully attack their
corresponding IVC devices from the ones that have fooled
the ASR API services. However, Amazon Transcribe API
and Amazon Echo are the exception. We ﬁnd that although
attacking Amazon Transcribe API is difﬁcult, we can always
generate AEs with 100% SRoC for the 10 target commands to
attack Amazon Echo. The full list of successful commands on