title:Pretzel: Email encryption and provider-supplied functions are compatible
author:Trinabh Gupta and
Henrique Fingler and
Lorenzo Alvisi and
Michael Walfish
Pretzel: Email encryption and provider-supplied functions are compatible
Trinabh Gupta∗† Henrique Fingler∗ Lorenzo Alvisi∗‡ Michael Walfish†
∗UT Austin
†NYU
‡Cornell
ABSTRACT
Emails today are often encrypted, but only between mail servers—
the vast majority of emails are exposed in plaintext to the mail
servers that handle them. While better than no encryption, this
arrangement leaves open the possibility of attacks, privacy viola-
tions, and other disclosures. Publicly, email providers have stated
that default end-to-end encryption would conflict with essential
functions (spam filtering, etc.), because the latter requires analyzing
email text. The goal of this paper is to demonstrate that there is
no conflict. We do so by designing, implementing, and evaluating
Pretzel. Starting from a cryptographic protocol that enables two
parties to jointly perform a classification task without revealing
their inputs to each other, Pretzel refines and adapts this protocol
to the email context. Our experimental evaluation of a prototype
demonstrates that email can be encrypted end-to-end and providers
can compute over it, at tolerable cost: clients must devote some
storage and processing, and provider overhead is roughly 5× versus
the status quo.
CCS CONCEPTS
• Information systems → Email; • Security and privacy →
Cryptography; Privacy-preserving protocols;
KEYWORDS
encrypted email, secure two-party computation, linear classifiers
ACM Reference format:
Trinabh Gupta, Henrique Fingler, Lorenzo Alvisi, and Michael Walfish. 2017.
Pretzel: Email encryption and provider-supplied functions are compatible.
In Proceedings of SIGCOMM ’17, Los Angeles, CA, USA, August 21-25, 2017,
14 pages. https://doi.org/10.1145/3098822.3098835
1 INTRODUCTION
Email is ubiquitous and fundamental. For many, it is the principal
communication medium, even with intimates. For these reasons,
and others that we outline below, our animating ideal in this paper
is that email should be end-to-end private by default.
How far are we from this ideal? On the plus side, hop-by-hop
encryption has brought encouraging progress in protecting email
privacy against a range of network-level attacks. Specifically, many
emails now travel between servers over encrypted channels (TLS [47,
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
SIGCOMM ’17, August 21-25, 2017, Los Angeles, CA, USA
© 2017 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-4653-5/17/08...$15.00
https://doi.org/10.1145/3098822.3098835
56]). And network connections between the user and the provider
are often encrypted, for example using HTTPS (in the case of web-
mail providers) or VPNs (in the case of enterprise email accounts).
However, emails are not by default encrypted end-to-end be-
tween the two clients: intermediate hops, such as the sender’s and
receiver’s provider, handle emails in plaintext. Since these providers
are typically well-run services with a reputation to protect, many
users are willing to just trust them. This trust however, appears to
stem more from shifting social norms than from the fundamental
technical safety of the arrangement, which instead seems to call
for greater caution.
Reputable organizations have been known to unwittingly harbor
rogue employees bent on gaining access to user email accounts and
other private user information [27, 103, 140]. If you were developing
your latest startup idea over email, would you be willing to bet its
viability on the assumption that each employee within the provider
acts properly? And well-run organizations are not immune from
hacks [127, 128]—nor from the law. Just in the first half of 2013,
Google [64], Microsoft [97] and Yahoo! [131] collectively received
over 29,000 requests for email data from law enforcement, and in
the vast majority of cases responded with some customer data [96].
End-to-end email encryption can shield email contents from
prying eyes and reduce privacy loss when email providers are
hacked; and, while authorities would still be able to acquire private
email by serving subpoenas to account owners, they would not gain
unfettered access to someone’s private correspondence without that
party’s knowledge.
Why then are emails not encrypted end-to-end by default? After
all, there has long been software that implements this function-
ality, notably PGP [144]; moreover, the large webmail providers
offer it as an option [63, 130] (see also [23, 113, 115, 126]). A crucial
reason—at least the one that is often cited [41, 42, 55, 65, 112]—
is that encryption appears to be incompatible with value-added
functions (such as spam filtering, email search, and predictive per-
sonal assistance [28, 39, 49, 102]) and with the functions by which
“free” webmail providers monetize user data (for example, topic
extraction) [67]. These functions are proprietary; for example, the
provider might have invested in training a spam filtering model,
and does not want to publicize it (even if a dedicated party can infer
it [117]). So it follows that the functions must execute on providers’
servers with access to plaintext emails.
But does that truly follow? Our objective in this paper is to
refute these claims of incompatibility, and thus move a step closer
to the animating ideal that we stated at the outset, by building an
alternative, called Pretzel.
In Pretzel, senders encrypt email using an end-to-end encryp-
tion scheme, and the intended recipients decrypt and obtain email
contents. Then, the email provider and each recipient engage in a se-
cure two-party computation (2PC); the term refers to cryptographic
SIGCOMM ’17, August 21-25, 2017, Los Angeles, CA, USA
T. Gupta et al.
protocols that enable one or both parties to learn the output of an
agreed-upon function, without revealing the inputs to each other.
For example, a provider supplies its spam filter, a user supplies
an email, and both parties learn whether the email is spam while
protecting the details of the filter and the content of the email.
by its design, both user and provider have to agree on the algorithm,
with only the inputs being private. Most fundamentally, Pretzel
cannot achieve the ideal of perfect privacy; it seems inherent in
the problem setup that one party gains information that would
ideally be hidden. However, these leaks are generally bounded, and
concerned users can opt out, possibly at some dollar cost (§4.4, §7).
The biggest limitation, though, is that Pretzel cannot change the
world on its own. As we discuss later (§7), there are other obstacles
en route to the ultimate goal: general deployment difficulties, key
management, usability, and even politics. However, we hope that
the exercise of working through the technical details to produce
an existence proof (and a rough cost estimate) will at least shape
discourse about the viability of default end-to-end email encryption.
2 ARCHITECTURE AND OVERVIEW
2.1 Design ethos: (non)requirements
Pretzel would ideally (a) enable rich computation over email, (b) hide
the inputs and implementations of those computations, and (c) im-
pose little overhead. But these three ideals are in tension. Below
we describe the compromises that form Pretzel’s design ethos.
• Functionality. We will not insist that Pretzel replicate exactly the
computations that providers such as Google perform over email;
in fact, we don’t actually know in detail what they do. Rather, we
aim to approximate the value-added functions that they provide.
• Provider privacy. Related to the prior point, Pretzel will not sup-
port proprietary algorithms; instead, Pretzel will protect the in-
puts to the algorithms. For example, all users of Pretzel will know
the spam filtering model (both its structure and its features), but
the parameters to the model will be proprietary.
• User privacy. Pretzel will not try to enshroud users’ email in
complete secrecy; indeed, it seems unavoidable that computing
over emails would reveal some information about them. How-
ever, Pretzel will be designed to reveal only the outputs of the
computation, and these outputs will be short (in bits).
• Threat model and maliciousness. Pretzel will not build in protec-
tion against actions that subvert the protocol’s semantics (for
example, a provider who follows the protocol to the letter but who
designs the topic extraction model to recover a precise email); we
will deal with this issue by relying on context, a point we elabo-
rate on later (§4.4, §7). Pretzel will, however, build in defenses
against adversaries that deviate from the protocol’s mechanics;
these defenses will not assume particular misbehaviors, only that
adversaries are subject to normal cryptographic hardness.
• Performance and price. Whereas the status quo imposes little
overhead on email clients, Pretzel will incur network, storage,
and computation overhead at clients. However, Pretzel will aim to
limit the network overhead to small multiples of the overhead in
the status quo, the storage cost to several hundred megabytes, and
the cpu cost to a few hundred milliseconds of time per processed
email. For the provider, Pretzel’s aim is to limit overheads to
small multiples of the costs in the status quo.
• Deployability and usability. Certain computations, such as encryp-
tion, will have to run on the client. However, web applications
The challenge in Pretzel comes from the 2PC component. There
is a tension between expressive power (the best 2PC schemes can
handle any function and even hide it from one of the two parties)
and cost (those schemes remain exorbitant, despite progress in low-
ering the costs; §3.2). Therefore, in designing Pretzel, we decided
to make certain compromises to gain even the possibility of plau-
sible performance: baking in specific algorithms, requiring both
the algorithms’ logic and the model features to be exposed (model
parameters are hidden), and incurring per-function design work.
The paper’s central example is classification, which Pretzel ap-
plies to both spam filtering and topic extraction (Pretzel also imple-
ments elementary keyword search). Pretzel’s first step is to compose
(a) a relatively efficient 2PC protocol (§3.2) geared to computations
that consist mostly of linear operations [19, 30, 75, 100, 106], (b) lin-
ear classifiers from machine learning (Naive Bayes, SVMs, logistic
regression), which fit this form and have good accuracy (§3.1),
and (c) mechanisms that protect against adversarial parties. Al-
though the precise protocol (§3.3) has not appeared before, we
don’t claim it as a contribution, as its elements are well-understood.
This combination is simply the jumping-off point for Pretzel.
The work of Pretzel is adapting and incorporating this baseline
into a system for end-to-end encrypted email. In this context, the
costs of the baseline would be, if not quite outlandish, nevertheless
too high. Pretzel responds, first, with lower-level protocol refine-
ments: revisiting the cryptosystem (§4.1) and conserving calls into
it by applying a packing technique [59] (§4.2). Second, for topic
extraction, Pretzel rearranges the setup, by decomposing classifica-
tion into a non-private step, performed by the client, which prunes
the set of topics; and a private step that further refines this can-
didate set to a single topic. Making this work requires a modified
protocol that, roughly speaking, selects a candidate maximum from
a particular subset, while hiding that subset (§4.3). Third, Pretzel
applies well-known ideas (feature selection to reduce costs, various
mechanisms to guard against misuses of the protocol); here, the
work is demonstrating that these are suitable in the present context.
We freely admit that not all elements of Pretzel are individually
remarkable. However, taken together, they produce the first (to our
knowledge) demonstration that classification can be done privately,
at tolerable cost, in the email setting.
Indeed, evaluation (§6) of our implementation (§5) indicates
that Pretzel’s cost, versus a legacy non-private implementation, is
estimated to be up to 5.4×, with additional client-side requirements
of several hundred megabytes of storage and per-email cpu cost
of several hundred milliseconds. These costs represent reductions
versus the starting point (§3.3) of between 1.8× and 100× (§6).
Our work here has clear limitations (§7). Reflecting its proto-
type status, our implementation handles only the three functions
mentioned (ideally, it would handle predictive personal assistance,
virus scanning, and more); also, Pretzel does not hide metadata,
and it focuses on applying classifiers, not training or retraining
them. More fundamentally, Pretzel compromises on functionality;
Pretzel: Email encryption and provider-supplied functions are compatible
SIGCOMM ’17, August 21-25, 2017, Los Angeles, CA, USA
Figure 1: Pretzel’s architecture. e denotes plaintext email; e′ denotes
encrypted email. The sender’s provider is not depicted.
are permitted to consume client-side resources, including stor-
age [40]. Furthermore, Pretzel will aim to be configuration-free.
Also, Pretzel must be backwards compatible with existing email
delivery infrastructure (SMTP, IMAP, etc.).
2.2 Architecture
Figure 1 shows Pretzel’s architecture. Pretzel comprises an e2e mod-
ule and function modules. The e2e module implements an end-to-end
encryption scheme; a function module implements a computation
over the email content (spam filtering, etc.). The e2e module is
client-side only, while a function module has a component at the
client and another at the provider.
At a high level, Pretzel works as follows. An email sender uses
its e2e module to encrypt and sign an email for an email recipient
(step ➀). The recipient uses its e2e module to authenticate and