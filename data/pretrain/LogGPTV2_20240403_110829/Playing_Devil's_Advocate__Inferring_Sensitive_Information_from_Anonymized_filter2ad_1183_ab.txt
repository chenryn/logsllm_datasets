tially, of probability > tP ) values from the distribution
and recomputing the normalized entropy until the distribu-
tion becomes sufﬁciently uniform, bringing the normalized
entropy above a given threshold, tH. Finding the ‘heavy-
hitters’ this way allows us to focus our later deanonymiza-
tion efforts on the most prevalent hosts in the network trace.
Algorithm 1 Find-Heavy-Hitters(Connections C, thresh-
olds tH and tP )
HeavyHitters ← ∅
// Examine both source IP address (C1) and destination IP address (C2)
for i = 1, 2 do
k ← 0
C(cid:48) ← C
while H(C(cid:48)
i)  2−ktP then
HeavyHitters ← HeavyHitters ∪ {ci}
C(cid:48) ← C(cid:48) \ {c}
k ← k + 1
return HeavyHitters
Dominant State Analysis Xu et al. also propose a novel
approach for determining the most characteristic behaviors
for a given host, known as Dominant State Analysis [33].
We apply this technique to the network trafﬁc associated
with the heavy-hitters found as described above to develop
4
a behavioral proﬁle, or set of recurring network activities
that best characterize these hosts. These behavioral proﬁles
can then be used as a means of ﬁngerprinting various hosts
based on their behaviors. The concept of proﬁling behaviors
has been examined by others, including Karagiannis et al.
and Aiello et al., and has been found to be a practical mech-
anism for classifying hosts into logical groupings based on
the characterization of their trafﬁc [16, 17].
To ﬁnd these behaviors, for each ‘heavy-hitter’ address
x, we begin with a simple behavioral proﬁle: src address =
x. Recall that c1 is the source IP address of connection c.
Then, denoting the set of connections with c1 = x as C x,
i ) ≤
we reorder the remaining features i such that H(C x
i+1). Then, for each feature in the set of connec-
H(C x
i=2..4, we look for values of ci whose conditional
tions, C x
probability with the current proﬁle exceeds our threshold
t, and append that value to the proﬁle vector for further
consideration. The algorithm extends these proﬁles in an
iterative fashion until no value meeting our threshold can
be found, or all features have been examined. The output
of this Dominant State Analysis (Algorithm 2) for each
‘heavy-hitter’ IP address is a set of feature vectors describ-
ing its behavioral proﬁles. After performing the Dominant
State Analysis on the source IP addresses, we repeat the
same process using the destination IP addresses.
Subnet Clustering The subnets associated with the IP ad-
dresses found in the network data are not always made avail-
able, and thus we must consider alternate methods of deter-
mining this information. The determination of the subnets
found in the anonymized data is an important step in the
creation of network topology maps and the deanonymiza-
tion of hosts, as it allows us to distinguish the distinct areas
of the network where the data was collected. Subnets can
be inferred from the set of IP addresses present within the
network data using an application of the k-means cluster-
ing algorithm. Note that this process does not deanonymize
the addresses in the trace, but it does take advantage of
the preﬁx-preserving anonymization to extract information
about the underlying network topology.
A na¨ıve solution for discovering subnets within the data
is to simply look for groupings of contiguous addresses sep-
arated by large gaps. Of course, an arbitrary cutoff would
have to be determined to specify the required gap between
the groupings. This gap size would necessarily relate to
a predetermined subnet size, which may not be uniform
across all subnets. It is therefore likely that such a scheme
would improperly group addresses if a variety of subnet
sizes were present. Our approach, on the other hand, is able
to choose the proper sizes for a variety of subnets without
the use of a priori information on the subnets sizes being
grouped. To achieve that, we automatically determine the
best subnets based on the observed data and an initial ap-
Algorithm 2 Dominant State Analysis for Heavy-Hitter x
FinishedProﬁles ← ∅
CurrentProﬁles ← {(cid:104)x(cid:105)}
i ← 2
// examine each feature, in order of increasing normalized entropy
while i ≤ 4 do
NewProﬁles ← ∅
for all proﬁle ∈ CurrentProﬁles do
ExtendedProﬁles ← ∅
for all c ∈ Cx do
if PCx (Cx
i = ci|proﬁle) > t then
ExtendedProﬁles ← ExtendedProﬁles ∪ {proﬁle||(cid:104)ci(cid:105)} // where || indicates vector concatenation
if ExtendedProﬁles = ∅ then
else
FinishedProﬁles ← FinishedProﬁles ∪ {proﬁle}
NewProﬁles ← NewProﬁles ∪ ExtendedProﬁles
CurrentProﬁles ← NewProﬁles
i ← i + 1
FinishedProﬁles ← FinishedProﬁles ∪ CurrentProﬁles
return FinishedProﬁles
proximation of the density of addresses within the subnet
through the use of unsupervised learning techniques, in our
case, the k-means algorithm.
Speciﬁcally, we treat IP addresses as 4-dimensional vec-
tors, where each element of the vector corresponds to one
octet of the IP address as written in dotted decimal nota-
tion. To determine cluster membership, we use a modi-
ﬁed Euclidean distance with bitwise exclusive-OR instead
of subtraction as our distance metric. The dimensions corre-
sponding to the octets are exponentially weighted such that
the left-most octet carries the most weight. This weight-
ing ensures that the hierarchical nature of the subnetting is
preserved in the clustering algorithm 1.
We note that k-means clustering requires that the number
of clusters be speciﬁed a priori; however, since we have no
way of inferring the number of expected subnets, nor their
density within the 4-dimensional space, we ﬁrst evenly di-
vide each of the octet dimensions into m blocks. In doing
so, we make an approximate guess about the length of the
subnet preﬁx. The initial centroids are placed at the bound-
aries of these partitions. Therefore, we create k = md ini-
tial centroids where m is the number of partitions and d is
the number of dimensions to which the partitioning was ap-
plied. Notice that as we increase m, we allow for greater
density of subnets by decreasing the spacing among initial
centroids 2. Also, by including or excluding dimensions
from the initial partitioning scheme, we can control how
many octets participate in the creation of initial clusters.
After this initial step, we iteratively recompute the cen-
troid and the corresponding cluster membership. This pro-
1For example,
using this weighted metric we compute the
distance between the IP addresses 192.168.1.2 and 10.0.0.10 as
G((192 ⊕ 10) ∗ 23)2 + ((168 ⊕ 0) ∗ 22)2 + ((1 ⊕ 0) ∗ 21)2 + ((2 ⊕ 10) ∗ 20)2.
2In practice, the parameter m can be tuned based on the observed be-
havior of the Subnet Clustering output to ensure it properly accommodates
the density of addresses present in the given data.
cess continues until the membership of the clusters reaches
a steady state. This iterative reﬁnement of the clusters
makes it possible to accommodate for variable length sub-
nets. In particular, at the beginning of the reﬁnement pro-
cess, the clusters start in an unoptimized state where some
addresses that reside within the same subnet appear in dif-
ferent clusters due to the inaccuracy of our initial approx-
imation. However, as the reﬁnement continues, new clus-
ter centroids are created that better represent the addresses
within each cluster, and the process eventually converges to-
ward a set of stable centroids for the observed subnets in the
data. This ensures that the addresses within a given cluster
all reside in the same subnet without requiring exact initial
centroid placement.
Upon completion, each nonempty cluster represents a
subnet in the underlying network, and for each cluster we
calculate its subnet address as the longest common preﬁx
shared by all IP addresses in the given cluster. As with
any application of the k-means algorithm, the results must
be empirically evaluated to ensure proper selection of ini-
tial clusters to approximate the anonymized address space.
In our evaluation, the Subnet Clustering technique achieves
> 96% accuracy across all datasets used within this paper
without signiﬁcant tuning of the initial cluster centroids.
We reiterate that
the primitives do not actually
deanonymize anything by themselves; the application of the
Dominant State Analysis algorithm can reveal typical be-
haviors for each anonymized IP address in the trace, and the
Subnet Clustering technique can derive a list of anonymized
subnet addresses, but more work is required to infer a map
of the network and to deanonymize hosts.
5
4 Information Leakage
In what follows, we show that not only can a map of
the network be recovered from anonymized network data,
but we are also able to deanonymize hosts in the trace
through the use of behavioral proﬁling. Such successful
deanonymization provides for a new method of passive net-
work reconnaissance and undermines the stated goals of ex-
isting approaches to anonymization. We note that the infor-
mation required to mount these attacks follows the require-
ments on the anonymized dataset laid out in Section 2.
4.1 Recovering network topology
Network topology can be inferred by ﬁrst determining
the locations within the network where each of the traces
were captured (i.e, the observation points), then identifying
the routers at each location, and ﬁnally examining the trafﬁc
to infer the connectivity between them.
To associate traces with observation points, we ﬁrst iden-
tify the network subnets which are present on the local area
network where the trace was recorded. We then regard two
traces as coming from the same observation point if they
have one or more subnets in common. If the anonymized
trace data contains Address Resolution Protocol (ARP) traf-
ﬁc, we can ﬁnd the local subnets by performing subnet clus-
tering (see Section 3) on the IP addresses in the ARP re-
quests and replies. When given only IP trafﬁc, subnets sur-
rounding the trace’s observation point can be inferred by
performing subnet clustering on all IP addresses found in
the trace and taking the n most frequently occurring subnets
in the results as the observation point’s subnets. The pa-
rameter n can be chosen to represent a best estimate of the
number of subnets for the observation point.3
Next, routing devices can be identiﬁed by the hardware
address used in the link layer headers. For each subnet at
each observation point, we examine TCP and UDP trafﬁc
sent from local hosts to out-of-subnet hosts and record the
destination hardware address found in the link layer header
as the gateway for that subnet. Similarly, routers can be
found by recording the hardware addresses that appear to
have multiple network addresses associated with them over
some time period δ. To avoid also ﬂagging hosts that use the
Dynamic Host Conﬁguration Protocol (DHCP) as routers,
this time period should be shorter than a typical DHCP
lease. In practice, this has not been an issue in any of the
traces we have examined, and we typically set δ to be on the
order of several seconds.
3For example, with an initial guess of n = 5 for the Johns Hopkins
University trace in the example below, we ﬁnd the top two subnets share
a common preﬁx and both occur twice as often as the third most frequent
subnet. The similarity of the preﬁxes and the substantial difference in num-
ber of occurrences suggest that we should instead set n = 2.
Inferring the routes taken by observed trafﬁc can be
useful in understanding the interconnection of observation
points at the network layer. To characterize the routes han-
dled by the discovered routing devices, the subnet cluster-
ing technique is applied to the source and destination IP ad-
dresses of TCP and UDP trafﬁc that transit the devices. The
unique pairs of source and destination subnets, as well as
the hardware addresses of the other routers to which trafﬁc
is sent, can be used to better understand the routing topol-
ogy of the network in question.
Lastly, the network layer topology can be reconstructed
by examining the routers and gateways for each observation
point, and the hardware addresses with which they commu-
nicate. Formally, the network can be represented as a graph
G consisting of nodes V and edges E ⊆ V × V . Then if the
hardware address for router s is associated with some other
discovered routing device t, we add an edge e = (s, t) to
E in the graph. Once the topology map is created via this
matching process, the routes can be superimposed using the
hardware addresses to characterize the actual routes taken
by network layer trafﬁc. This inference can also occur for
link layer topology if the network traces provide ARP traf-
ﬁc.
In this case, one may logically assume that only the
IP addresses observed in the ARP packets are members of
the local link layer network. Therefore, any trafﬁc that is
present at an observation point not destined to or sent from a
local host must be transiting that observation point. Speciﬁ-
cally, the path taken from hosts in a given observation point
to their gateway router can provide an approximation of the
topology, including the presence of switches and bridging
devices.
Note that to perform this topology inference, the pro-
vided data must at least meet the header and transport pro-
tocol requirements discussed in Section 2. The header re-
quirement is necessary to retrieve the anonymized hardware
addresses of the routing devices within the topology, and
therefore datasets that do not meet this requirement, such
as NetFlow data, are not vulnerable to the topology infer-
ence attack. The transport protocol requirement provides
the minimum network trafﬁc from which the inference of
network topology information is made.
4.2 Inferring Host Behavior
While the inference of network topology information
is certainly disconcerting, the anonymization of host ad-
dresses should make it difﬁcult to accurately map this topol-
ogy to real-world addresses. If, however, the behaviors of
the anonymized hosts can be uniquely mapped to the behav-
iors of their real-world counterparts, the attacker can begin
deanonymizing portions of the topology.
To infer the host behavior, the unique, recurring trafﬁc to
and from a particular host is characterized as a behavioral
6
Host
web server
SSH server
web client
Src IP Address
128.220.231.207
128.220.231.147
128.220.231.17
Src Port
Dst IP Address
Dst Port H(Src Port) H(Dst IP) H(Dst Port)
80
22
*
17.138.176.51
*
*
*
*
80
0.0
0.0
1.0
0.93
0.0
0.85
1.0
1.0
0.17
Table 2. Example behavioral proﬁles observed in the departmental network
proﬁle. To create these proﬁles, we take as input a list of
k-dimensional feature vectors c = (cid:104)c1, . . . , ck(cid:105) describing
a set of connections C. The set of signiﬁcant source and
destination addresses, or ‘heavy-hitters’, is obtained from
the connections in C via Algorithm 1. Next, Dominant
State Analysis is applied to the connections c ∈ C con-
taining each of these signiﬁcant addresses to determine the
set of dominant behaviors that comprise the given host’s
behavioral proﬁle. Upon termination, the set of behav-
ioral proﬁles for each signiﬁcant address is returned (see
Algorithm 2).
Like the topology inference attack, our inference of host
behavior requires that the transport protocol requirement be
met, as well as the pseudonym consistency requirement and
port number assumption. In particular, the pseudonym con-
sistency requirement allows us to accurately build proﬁles
for the hosts in the data, which would otherwise be difﬁcult
if their identities in the dataset changed. The port number
assumption simply allows us to easily determine what ser-
vices a given host offers when building our proﬁles. Un-
like the topology attack, these requirements can be met re-
gardless of the form that the network data takes. There-
fore, while the use of NetFlow data hampers the topology
inference attack due to its lack of header information, it still
meets all requirements for our behavioral inference attacks
and remains vulnerable to deanonymization via behavioral
proﬁling.
4.3 An Example
For concreteness, we illustrate the application of the
aforementioned techniques on an anonymized trace from
the Johns Hopkins University (JHU) network. In general,
deanonymization begins by ﬁrst identifying an interesting
service, and ﬁnding an appropriate host offering that service
to deanonymize. The goal is to create a behavioral proﬁle
query based on public information regarding services being
run on the target host, the perceived popularity of the host,
and its possible locations within the network topology. De-
veloping this proﬁle often requires the use of public infor-
mation sources, such as DNS or web search engine queries,
to specify unique information about the host. Beyond that, it
is simply a matter of matching hosts within the trace dataset
that best match the derived criterion.
The trace in question contains TCP trafﬁc from a sin-
gle observation point between a departmental network and
Anonymized
address