函数的缓存。
下一个Get的实现，调用Get的goroutine会两次获取锁：查找阶段获取一次，如果查找没有返
回任何内容，那么进入更新阶段会再次获取。在这两次获取锁的中间阶段，其它goroutine可
以随意使用cache。
gopl.io/ch9/memo3
func (memo *Memo) Get(key string) (value interface{}, err error) {
memo.mu.Lock()
res, ok := memo.cache[key]
memo.mu.Unlock()
if !ok {
res.value, res.err = memo.f(key)
// Between the two critical sections, several goroutines
// may race to compute f(key) and update the map.
memo.mu.Lock()
memo.cache[key] = res
memo.mu.Unlock()
}
return res.value, res.err
}
这些修改使性能再次得到了提升，但有一些URL被获取了两次。这种情况在两个以上的
goroutine同一时刻调用Get来请求同样的URL时会发生。多个goroutine一起查询cache，发现
没有值，然后一起调用f这个慢不拉叽的函数。在得到结果后，也都会去更新map。其中一个
示例: 并发的非阻塞缓存 362
gopl
获得的结果会覆盖掉另一个的结果。
理想情况下是应该避免掉多余的工作的。而这种“避免”工作一般被称为duplicate
suppression(重复抑制/避免)。下面版本的Memo每一个map元素都是指向一个条目的指针。
每一个条目包含对函数f调用结果的内容缓存。与之前不同的是这次entry还包含了一个叫
ready的channel。在条目的结果被设置之后，这个channel就会被关闭，以向其它goroutine广
播(§8.9)去读取该条目内的结果是安全的了。
gopl.io/ch9/memo4
type entry struct {
res result
ready chan struct{} // closed when res is ready
}
func New(f Func) *Memo {
return &Memo{f: f, cache: make(map[string]*entry)}
}
type Memo struct {
f Func
mu sync.Mutex // guards cache
cache map[string]*entry
}
func (memo *Memo) Get(key string) (value interface{}, err error) {
memo.mu.Lock()
e := memo.cache[key]
if e == nil {
// This is the first request for this key.
// This goroutine becomes responsible for computing
// the value and broadcasting the ready condition.
e = &entry{ready: make(chan struct{})}
memo.cache[key] = e
memo.mu.Unlock()
e.res.value, e.res.err = memo.f(key)
close(e.ready) // broadcast ready condition
} else {
// This is a repeat request for this key.
memo.mu.Unlock()
<-e.ready // wait for ready condition
}
return e.res.value, e.res.err
}
示例: 并发的非阻塞缓存 363
gopl
现在Get函数包括下面这些步骤了：获取互斥锁来保护共享变量cache map，查询map中是否
存在指定条目，如果没有找到那么分配空间插入一个新条目，释放互斥锁。如果存在条目的
话且其值没有写入完成(也就是有其它的goroutine在调用f这个慢函数)时，goroutine必须等待
值ready之后才能读到条目的结果。而想知道是否ready的话，可以直接从ready channel中读
取，由于这个读取操作在channel关闭之前一直是阻塞。
如果没有条目的话，需要向map中插入一个没有准备好的条目，当前正在调用的goroutine就
需要负责调用慢函数、更新条目以及向其它所有goroutine广播条目已经ready可读的消息了。
条目中的e.res.value和e.res.err变量是在多个goroutine之间共享的。创建条目的goroutine同
时也会设置条目的值，其它goroutine在收到"ready"的广播消息之后立刻会去读取条目的值。
尽管会被多个goroutine同时访问，但却并不需要互斥锁。ready channel的关闭一定会发生在
其它goroutine接收到广播事件之前，因此第一个goroutine对这些变量的写操作是一定发生在
这些读操作之前的。不会发生数据竞争。
这样并发、不重复、无阻塞的cache就完成了。
上面这样Memo的实现使用了一个互斥量来保护多个goroutine调用Get时的共享map变量。不
妨把这种设计和前面提到的把map变量限制在一个单独的monitor goroutine的方案做一些对
比，后者在调用Get时需要发消息。
Func、result和entry的声明和之前保持一致：
// Func is the type of the function to memoize.
type Func func(key string) (interface{}, error)
// A result is the result of calling a Func.
type result struct {
value interface{}
err error
}
type entry struct {
res result
ready chan struct{} // closed when res is ready
}
然而Memo类型现在包含了一个叫做requests的channel，Get的调用方用这个channel来和
monitor goroutine来通信。requests channel中的元素类型是request。Get的调用方会把这个
结构中的两组key都填充好，实际上用这两个变量来对函数进行缓存的。另一个叫response的
channel会被拿来发送响应结果。这个channel只会传回一个单独的值。
gopl.io/ch9/memo5
示例: 并发的非阻塞缓存 364
gopl
// A request is a message requesting that the Func be applied to key.
type request struct {
key string
response chan<- result // the client wants a single result
}
type Memo struct{ requests chan request }
// New returns a memoization of f. Clients must subsequently call Close.
func New(f Func) *Memo {
memo := &Memo{requests: make(chan request)}
go memo.server(f)
return memo
}
func (memo *Memo) Get(key string) (interface{}, error) {
response := make(chan result)
memo.requests <- request{key, response}
res := <-response
return res.value, res.err
}
func (memo *Memo) Close() { close(memo.requests) }
上面的Get方法，会创建一个response channel，把它放进request结构中，然后发送给
monitor goroutine，然后马上又会接收它。
cache变量被限制在了monitor goroutine `(*Memo).server 中，下面会看到。monitor会在循环
中一直读取请求，直到request channel被Close方法关闭。每一个请求都会去查询cache，如
果没有找到条目的话，那么就会创建/插入一个新的条目。
示例: 并发的非阻塞缓存 365
gopl
func (memo *Memo) server(f Func) {
cache := make(map[string]*entry)
for req := range memo.requests {
e := cache[req.key]
if e == nil {
// This is the first request for this key.
e = &entry{ready: make(chan struct{})}
cache[req.key] = e
go e.call(f, req.key) // call f(key)
}
go e.deliver(req.response)
}
}
func (e *entry) call(f Func, key string) {
// Evaluate the function.
e.res.value, e.res.err = f(key)
// Broadcast the ready condition.
close(e.ready)
}
func (e *entry) deliver(response chan<- result) {
// Wait for the ready condition.
<-e.ready
// Send the result to the client.
response <- e.res
}
和基于互斥量的版本类似，第一个对某个key的请求需要负责去调用函数f并传入这个key，将
结果存在条目里，并关闭ready channel来广播条目的ready消息。使用 来完成
(*entry).call
上述工作。
紧接着对同一个key的请求会发现map中已经有了存在的条目，然后会等待结果变为ready，
并将结果从response发送给客户端的goroutien。上述工作是用 来完成的。
(*entry).deliver
对call和deliver方法的调用必须让它们在自己的goroutine中进行以确保monitor goroutines不会
因此而被阻塞住而没法处理新的请求。
这个例子说明我们无论用上锁，还是通信来建立并发程序都是可行的。
上面的两种方案并不好说特定情境下哪种更好，不过了解他们还是有价值的。有时候从一种
方式切换到另一种可以使你的代码更为简洁。(译注：不是说好的golang推崇通信并发么)
练习 9.3： 扩展Func类型和 方法，支持调用方提供一个可选的done channel，
(*Memo).Get
使其具备通过该channel来取消整个操作的能力(§8.9)。一个被取消了的Func的调用结果不应
该被缓存。
示例: 并发的非阻塞缓存 366
gopl
示例: 并发的非阻塞缓存 367
gopl
9.8. Goroutines和线程
在上一章中我们说goroutine和操作系统的线程区别可以先忽略。尽管两者的区别实际上只是
一个量的区别，但量变会引起质变的道理同样适用于goroutine和线程。现在正是我们来区分
开两者的最佳时机。
9.8.1. 动态栈
每一个OS线程都有一个固定大小的内存块(一般会是2MB)来做栈，这个栈会用来存储当前正
在被调用或挂起(指在调用其它函数时)的函数的内部变量。这个固定大小的栈同时很大又很
小。因为2MB的栈对于一个小小的goroutine来说是很大的内存浪费，比如对于我们用到的，
一个只是用来WaitGroup之后关闭channel的goroutine来说。而对于go程序来说，同时创建成
百上千个goroutine是非常普遍的，如果每一个goroutine都需要这么大的栈的话，那这么多的
goroutine就不太可能了。除去大小的问题之外，固定大小的栈对于更复杂或者更深层次的递
归函数调用来说显然是不够的。修改固定的大小可以提升空间的利用率允许创建更多的线
程，并且可以允许更深的递归调用，不过这两者是没法同时兼备的。
相反，一个goroutine会以一个很小的栈开始其生命周期，一般只需要2KB。一个goroutine的
栈，和操作系统线程一样，会保存其活跃或挂起的函数调用的本地变量，但是和OS线程不太
一样的是一个goroutine的栈大小并不是固定的；栈的大小会根据需要动态地伸缩。而
goroutine的栈的最大值有1GB，比传统的固定大小的线程栈要大得多，尽管一般情况下，大
多goroutine都不需要这么大的栈。
练习 9.4: 创建一个流水线程序，支持用channel连接任意数量的goroutine，在跑爆内存之
前，可以创建多少流水线阶段？一个变量通过整个流水线需要用多久？(这个练习题翻译不是
很确定。。)
9.8.2. Goroutine调度
OS线程会被操作系统内核调度。每几毫秒，一个硬件计时器会中断处理器，这会调用一个叫
作scheduler的内核函数。这个函数会挂起当前执行的线程并保存内存中它的寄存器内容，检
查线程列表并决定下一次哪个线程可以被运行，并从内存中恢复该线程的寄存器信息，然后
恢复执行该线程的现场并开始执行线程。因为操作系统线程是被内核所调度，所以从一个线
程向另一个“移动”需要完整的上下文切换，也就是说，保存一个用户线程的状态到内存，恢复
另一个线程的到寄存器，然后更新调度器的数据结构。这几步操作很慢，因为其局部性很差
需要几次内存访问，并且会增加运行的cpu周期。
Go的运行时包含了其自己的调度器，这个调度器使用了一些技术手段，比如m:n调度，因为
其会在n个操作系统线程上多工(调度)m个goroutine。Go调度器的工作和内核的调度是相似
的，但是这个调度器只关注单独的Go程序中的goroutine(译注：按程序独立)。
Goroutines和线程 368
gopl
和操作系统的线程调度不同的是，Go调度器并不是用一个硬件定时器而是被Go语言"建筑"本
身进行调度的。例如当一个goroutine调用了time.Sleep或者被channel调用或者mutex操作阻
塞时，调度器会使其进入休眠并开始执行另一个goroutine直到时机到了再去唤醒第一个
goroutine。因为这种调度方式不需要进入内核的上下文，所以重新调度一个goroutine比调度
一个线程代价要低得多。
练习 9.5: 写一个有两个goroutine的程序，两个goroutine会向两个无buffer channel反复地发送
ping-pong消息。这样的程序每秒可以支持多少次通信？
9.8.3. GOMAXPROCS
Go的调度器使用了一个叫做GOMAXPROCS的变量来决定会有多少个操作系统的线程同时执
行Go的代码。其默认的值是运行机器上的CPU的核心数，所以在一个有8个核心的机器上
时，调度器一次会在8个OS线程上去调度GO代码。(GOMAXPROCS是前面说的m:n调度中的
n)。在休眠中的或者在通信中被阻塞的goroutine是不需要一个对应的线程来做调度的。在I/O
中或系统调用中或调用非Go语言函数时，是需要一个对应的操作系统线程的，但是
GOMAXPROCS并不需要将这几种情况计算在内。
你可以用GOMAXPROCS的环境变量来显式地控制这个参数，或者也可以在运行时用
runtime.GOMAXPROCS函数来修改它。我们在下面的小程序中会看到GOMAXPROCS的效
果，这个程序会无限打印0和1。
for {
go fmt.Print(0)
fmt.Print(1)
}
$ GOMAXPROCS=1 go run hacker-cliché.go
111111111111111111110000000000000000000011111...
$ GOMAXPROCS=2 go run hacker-cliché.go
010101010101010101011001100101011010010100110...
在第一次执行时，最多同时只能有一个goroutine被执行。初始情况下只有main goroutine被执
行，所以会打印很多1。过了一段时间后，GO调度器会将其置为休眠，并唤醒另一个
goroutine，这时候就开始打印很多0了，在打印的时候，goroutine是被调度到操作系统线程上
的。在第二次执行时，我们使用了两个操作系统线程，所以两个goroutine可以一起被执行，
以同样的频率交替打印0和1。我们必须强调的是goroutine的调度是受很多因子影响的，而
runtime也是在不断地发展演进的，所以这里的你实际得到的结果可能会因为版本的不同而与
我们运行的结果有所不同。
练习9.6: 测试一下计算密集型的并发程序(练习8.5那样的)会被GOMAXPROCS怎样影响到。