Figure 2: A simple Markov model for counting convergence
opportunities
two honest hits that are less than ∆ rounds, and let Q denote the
same for quiet periods longer than ∆.
To arrive at their consistency proof, the consistency lemma [17,
Lemma 6.11] derives a lower bound of 2Q − L on the number of
convergence opportunities. Specifically, they show that except with
probability 1− e−Ω(βt ), there are at least (1− δ′′′)(1− 2α (∆ + 1))αt
convergence opportunities between any two rounds r and r + t,
and moreover, an adversary only mined at most (1 + w′′)(t + 1)β
blocks, for arbitrary small constants δ′′′, w′′ ≥ 0.
Using a simple Markov chain, we show below that the above
lower bound is not accurate; it may underestimate the true count
of convergence opportunities.
Figure 2 presents a Markov model which precisely captures the
count from Pass et al. It has 2 states: S0 represents a “messy” state
where honest mined blocks occur in less than ∆ rounds from one
another, while S1 is the state where quiet periods between honest
mined blocks is at least ∆ rounds. As long as quiet periods are
shorter than ∆ rounds the system stays in S0; otherwise we move to
state S1. Once in S1, the system stays in S1 as long as quiet periods
between honest mined blocks are at least ∆ rounds, otherwise the
state changes to S0. Let eij represent the edge from state Si to state
Sj. Below are the events that happen when each edge is traversed:
e00 = one quiet period of less than ∆ rounds followed by a
single honest mined block
e01 = one quiet period that is at least ∆ rounds
e11 = a single honest mined block followed by a quiet period
of at least ∆ rounds
e10 = an honest mined block followed by one quiet period
of less than ∆ rounds followed by an honest mined block.
Consider a random walk on this Markov chain. We can compute
the number of honest mined blocks by counting one block every
time e00 or e11 is traversed, and 2 every time e10 is traversed. To
calculate Q, we count the number of times e01 is traversed plus the
number of times e11 is traversed. Letting Eij represent the expected
number of times eij is traversed, we have:
2Q − L = 2(E01 + E11) − (E00 + E11 + 2E10)
= 2E01 + E11 − 2E10 − E00
Our analysis plan is to compare the expected fraction of events
that are convergence opportunities with the expected fraction of
events that are blocks mined by the adversary, and then invoke
concentration bounds from Theorem 3.1. To calculate the expecta-
tions, we solve for the probability of crossing each edge, and the
stationary probabilities. Let P∆ = (1 − µp)∆ be the probability of ∆
Session 4C: Blockchain 1CCS’18, October 15-19, 2018, Toronto, ON, Canada734silent rounds.
Pr[e00] = Pr[e10] = 1 − P∆
Pr[e01] = Pr[e11] = P∆
π0 = Pr[S0] = (1 − P∆)π0 + (1 − P∆)π1
π1 = Pr[S1] = P∆π1 + P∆π0
, we get:
Since π0 + π1 = 1 we get that π0 = 1 − P∆ and π1 = P∆.
To calculate the expected number of times we hit each edge eij,
we divide πipij by the total weighted time spent on all edges, which
in turn requires the expected time spent on each edge lij. Letting
pi |≤∆ = Pr[hit at time i| silence lasted ≤ ∆] = pi
∆(cid:88)
p≤∆
∆(cid:88)
The total weighted time spent on all edges is(cid:80)
i =1
i, j Pr[eij]πilij. Thus
2Q −L is equal to 2(e01π0 +e11π1)− (e00π0 +e11π1 +2e01π0) divided
by the total weighted time spent on all edges. We simplify this to
∆(cid:80)
(1 − µp)i−1
j=1(1 − µp)j−1
+ ∆;
l01 = ∆;
pi |≤∆ =
l10 =
+
µp
;
µp
l00 =
ipi |≤∆
i =1
ipi |≤∆
l11 =
1
µp
1
µp
2(e01π0 + e11π1) − (e00π0 + e11π1 + 2e01π0)
= 2 · (P∆ (1 − P∆) + P
− ((1 − P∆)
2
2 + P
∆
∆ − (1 − P∆)
2
2
= P
2
∆)
+ 2 ∗ P∆ (1 − P∆))
We then calculate the total weighted time spent on the edges and
plot the bound for convergence opportunities as
(cid:80)
P
− (1 − P∆)
2
2
∆
i, j Pr[eij]πilij
in Figure 1 as (
). Note this bound is slightly stronger than the
same count from [17] because we use a more accurate probability
for µ (while Pass et al. use a conservative approximation); these two
calculations are equivalent when we use the same approximation.
In order to establish a concentration bound for the convergence
opportunities count, we show the following. For each state v, the
number of visits to v in T rounds is concentrated around the ex-
pected number of visits in T rounds with high probability; for each
edge e, the number of visits to e as well as the time spent on e
are concentrated around their respective expectations with high
probability. Since the count we are measuring is a linear combina-
tion of the number of visits, we obtain the desired high probability
concentration bound. We obtain these concentration bounds by an
application of Theorem 3.1. Before we can apply the theorem, we
transform the Markov chain to another equivalent Markov chain,
presented in Figure 3, in which traversing each edge takes one step
of the chain. Now, the number of visits to a vertex v in T rounds
can be captured by the random variable X by setting fi (v) to be 1,
and fi (u) to be 0 for all u (cid:44) v, for all i. Theorem 3.1 immediately
yields a bound that the number of visits to v in T rounds is within
(1 ± δ ) of its expectation with probability 1 − e−Ω(T ), where the
hidden constant depends on ∆ and p, factors that determine the
mixing time of the transformed Markov chain.
N
H
S0
∆ − 1
N
N
H
H
N
N
N
∆ − 1
N
N
N
H
S1
N
Figure 3: Markov chain equivalent to that in Figure 2. The
label H (resp., N) on an edge marks event that a block (resp.,
no block) was mined by an honest player in the round. The
edge labeled H from the two rectangular blocks of states rep-
resents an edge from each state in the blocks.
Problems with this counting. The analysis of Pass et al. lower
bounded the number of convergence opportunities by counting
the number of (honest) hits and by counting the number of “quiet”
periods that were longer than ∆, and comparing this with an upper
bound on the expected number of blocks the adversary can mine.
We now show when this analysis underestimates the number of
convergence opportunities, even getting a negative count.
Consider the following sequence of events where, slightly abus-
ing notation, H represents a round with a “hit”, Q represents at least
∆ rounds with no mined blocks, and q represents a quiet period of
fewer than ∆ rounds,
H , q, H , Q, H , Q, H , q, H , q, H , q, . . . ,
the Pass et al. method underestimates the number of convergence
opportunities as−2, when there should be 1. We see that when c  0 such that
≥ (1 + δ )β
(1)
∆(cid:80)
P
2
i, j
Pi, j πili, j
4.4 Nakamoto Consensus Attack
Pass et al. [17] introduce the delay attack on the consistency of
Nakamoto’s protocol in which the adversary simply delays all hon-
est blocks the maximum amount allowed by the model. Through
this delay, the adversary is able to thwart the growth rate of the
honest chain, while mining efficiently their own private chain of
length at least the size of the honest chain. Figure 7 (1-chain) shows
a simple Markov model which captures this attack, where once
an honest block is mined, any honest blocks mined in the ∆ steps
after are wasted work since those honest players don’t know about
the initial block. Figure 1 ‘example attack’, taken from [17] and
recalculated using our Markov model, shows the minimum fraction
of mining power the adversary needs for each c in order for the
attack to succeed with high probability.
We now present the Markov model of Figure 4 for this attack,
and calculate the probability the adversary can generate a private
chain of length k, for each µ, ∆ and c. The states are as follows:
• Sx : the state where the attack fails
• S−1: state where the honest chain is ahead by one block
• S0: state with honest and attacker’s chains of equal length
• Si for i ≥ 1: state where the adversary chain is longer than
the honest chain by i blocks
For this analysis we introduce the following variables:
′ = µ (1 − (1 − ρp)∆)
′ = µ (1 − ρp)∆ ρ
µ
′′ = 1 − (1 − ρp)∆ + (1 − ρp)∆ρ
ρ
Let Pi (k ) be the probability that starting from state Si, we visit
ρ, ρ′, or ρ′′ edges ≥ k times before hiting state Sx . We calculate:
′′
i ≥ 0
P0 (k − 1)
Pi (0) = 1
P−1 (k ) = ρ
P0 (k ) = ρP1 (k − 1) + µP−1 (k )
Pi (k ) = ρPi +1 (k − 1) + ρ
′
Using generating functions, we show how to derive closed form
expressions for Pi (k ) for fixed i and k. For all k ≥ 0, define
′
Pi−1 (k )
i > 0
Pi (k − 1) + µ
(cid:88)
Pi (k )xi .
i ≥0
fk (x ) =
We show that fk (x ) satisfies the following equation.
fk (x ) =
ρ
x
′
µ
( fk−1 (x ) − fk−1 (0)) + ρ
x fk (x ) + µρ
′′
(2)
To establish Equation 2, we show that for every i ≥ 0, the coefficient
of xi in the right-hand side equals Pi (k ). For i = 0, we observe that
fk−1 (0)
′
( fk−1 (x ) − fk−1 (0))
S0
ρ′′
µ
ρ
µ′
S−1
ρ′
S1
∆ + µ
ρ′
S2
ρ
µ′
Sx
ρ
µ′
ρ′
S3
ρ
µ′
Figure 4: Our Markov chain model which we use to capture
the probability that the delay attack lasts for some k blocks.
the constant term in the right-hand side is the sum of two terms:
the constant term in (ρ/x ) fk−1 (x ) and µρ′′ fk−1 (0). This equals
ρP1 (k − 1) + µρ
′′
P0(k − 1) = P0(k ),
as desired. For i > 0, the term xi appears in the right-hand side
of Equation 2 in three summands: (ρ/x ) fk−1 (x ), ρ′ fk−1 (x ), and
µ′x fk (x ). Adding these up, we obtain
Pi (k − 1) + µ
ρPi +1 (k − 1) + ρ
Pi−1 (k ) = Pi (k ).
′
′
1
1 − x
x (1 − µ′x )
We now express the generating function fk (x ) of Equation 2 as the
following recurrence in k.
f0 (x ) = 1 + x + x
2 + . . . =
(ρ + ρ′x )( fk−1 (x ) − fk−1(0)) + µρ′′x fk−1(0)
, k > 0.
fk (x ) =
Note that P0 (k ) is fk (0); so by unravelling the above recurrence,
we can derive a closed form expression for P0(k ) for any given k.
In Figure 5 we plot P0(k ) for c = 1, 4 and 60 for a 49% and 25%
adversary. We see that for the Bitcoin hardness parameter (c = 60),
forks of length 6 (the suggested confirmation time) are possible
with roughly 5% probability for an adversary controlling 25% of the
mining power and are even more than 1% for length 9. For Ethereum
whose c parameter is set to less than 4, waiting 15 confirmations
corresponds to roughly 1% probability, which perhaps justifies the
aggressive choice of c.
5 CLIQUECHAIN ANALYSIS
Informally, Nakamoto consensus relies on a simple “longest chain”
rule to pick between different forks when the network is not in
agreement. Sompolinsky and Zohar and later Sompolinsky, Lewen-
berg and Zohar began to study a more general class of rules for
picking between forks that apply to directed acyclic graphs. The
first idea in this framework was the GHOST [20] protocol which
considered trees of blocks instead of linear chains, they provide
an analysis which we extend in the next section. They extended
this idea to general DAG protocols where blocks can point to more
than one parent block, they call these inclusive protocols [13]. In-
clusive protocols have a voting mechanism for which transactions
to accept, but inherit security from GHOST or any other tree-based
selection policy underlying it. In subsequent ongoing work, they
consider ideas of how blocks can reference multiple parent blocks