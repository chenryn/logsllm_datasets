increase. This is captures by the “All Above & All Below” category.
Finally, the “X Shape” category captures the setting where the query
answers are not all the same and some increase and others decrease
when evaluated on one database compared to an adjacent database.
These categories were chosen from our desire to allow coun-
terexamples to be easily understood by mechanism designers (and
to make it easier for them to manually trace the code to understand
4For queries with larger sensitivity, the extension is obvious. For example D1 =
[1, 1, 1, 1, 1] and D2 = [1 + ∆q, 1 + ∆q, . . . , 1 + ∆q]
CCS ’18, October 15–19, 2018, Toronto, ON, Canada
Zeyu Ding, Yuxin Wang, Guanhong Wang, Danfeng Zhang, and Daniel Kifer
the problems). Thus the samples are short and simple. We consider
inputs of length 5 (as in Table 1) and also versions of length 10.
4.4.2 Argument Generation. Some differentially-private algorithms
require extra parameters beyond the database. For example, the
sparse vector technique [19], shown in Algorithm 11, takes as inputs
a threshold T and a bound N . It tries to output numerical queries
that are larger than T . However, for privacy reasons, it will stop
after it returns N noisy queries whose values are greater than T .
These two arguments are specific to the algorithm and their proper
values depend on the desired privacy level as well as algorithm
precision.
To find values of auxiliary parameters (such as N and T in Sparse
Vector), we build argument generator based on Symbolic Execution
[26], which is typically used for bug finding: it generates concrete
inputs that violate assertions in a program. In general, a symbolic
executor assigns symbolic values, rather than concrete values as
normal execution would do, for inputs. As the execution goes, the
executor maintains a symbolic program state at each assertion and
generates constraints that will violate the assertion. When those
constraints are satisfiable, concrete inputs (i.e., a solution of the
constraints) are generated.
Compared with standard symbolic execution, a major difference
in our argument generation is that we are interested in algorithm
arguments that will likely maximize the privacy cost of an algorithm.
In other words, there is no obvious assertion to be checked in our
argument generation. To proceed, we use two heuristics that likely
will cause large privacy cost of an algorithm:
• The first heuristic applies to parameters that affect noise gener-
ation. For example in Sparse Vector, the algorithm adds Lap(2 ·
N · ∆q/ϵ0) noise. For such a variable, we use the value that
results in small amount of noise (i.e., N = 1). Small amount of
noise is favorable since it reduces the variance in the hypothesis
testing (Section 4.2).
• The second heuristic (for variables that do not affect noise)
prefers arguments that make two program executions using
two different databases (as described in Section 4.4.1) to take
as many diverging branches as possible. The reason is that
diverging branches will likely use more privacy budget.
Next, we give a more detailed overview of our customized sym-
bolic executor. The symbolic executor takes a pair of concrete databases
as inputs (as described in Section 4.4.1) and uses symbolic values
for other input parameters. Random samples in the program (e.g., a
sample from Laplace distribution) are set to value 0 in the symbolic
execution. Then, the symbolic executor tracks symbolic program
states along program execution in the standard way [26]. For ex-
ample, the executor will generate a constraint5
x = y + 1 after an
assignment (x ← y+1), assuming that variable y has a symbolic
value y before the assignment. Also, the executor will unroll loops
in the source code, which is standard in most symbolic executors.
Unlike standard symbolic executors, the executor conceptually
tracks a pair of symbolic program states along program execution
(one on concrete database D1, and one on concrete database D2).
Moreover, it also generate extra constraints, according to the two
heuristics above, in the hope of maximizing the privacy cost of an
5For simplicity, we use a simple representation for constraints; Z3 has an internal
format and a user can either use Z3’s APIs or SMT2 [34] format to represent constraints.
algorithm. In particular, it handles two kinds of statements in the
following way:
• Sampling. The executor generates two constraints for a sam-
pling statement: a constraint that eliminates randomness in
symbolic execution by assigning sample to value 0, and a con-
straint that ensures a small amount of noise. Consider a state-
ment (η ← Lap(e)). The executor generates two constraints:
η = 0 as well as a constraint that minimizes expression e.
• Branch. The executor generates a constraint that makes the
two executions diverge on branches. Consider a branch state-
ment (if e then · · · ). Assume that the executor has symbolic
values e1 and e2 for the value of expression e on databases D1
and D2 respectively; it will generates a constraint (e1 ∧ ¬e2) ∨
(¬e1 ∧ e2) to make the executions diverge. Note that unlike
other constraints, a diverging constraint might be unsatisfiable
(e.g., if the query answers under D1 and D2 are the same). How-
ever, our goal is to maximize the number of satisfiable diverging
constraints, which can be achieved by a MaxSMT solver.
The executor then uses an external MaxSMT solver such as Z3
[13] on all generated constraints to find arguments that maximizes
the number of diverged branches.
For example, the correct version of the Sparse Vector algorithm
(see the complete algorithm in Algorithm 11) has the parameter T
(a threshold). It has a branch that tests whether the noisy query
answer is above the threshold T :
q + η2 ≥ ˆT
Here, η2 is a noise variable, q is one query answer (i.e. one of the
components of the input D1 of the algorithm) and ˆT is a noisy
threshold ( ˆT = T + η1). Suppose we start from a database candidate
([1, 1, 1, 1, 1], [2, 2, 2, 2, 2]). The symbolic executor assigns symbolic
values to the parameters T and unrolls the loop in the algorithm,
where each iteration handles one noisy query. Along the execution,
it updates program states. For example, statement ˆT ← T + η1
results in ˆT = T + η1. For the first execution of the branch of
interest, the executor tracks the following symbolic program state:
q1 = 1 ∧ q2 = 2 ∧ η1 = 0 ∧ η2 = 0 ∧ ˆT1 = T + η1 ∧ ˆT2 = T + η2
as well as the following constraint for diverging branches:
(q1 + η1 ≥ ˆT1 ∧ q2 + η2 < ˆT2) ∨ (q1 + η1 < ˆT1 ∧ q2 + η2 ≥ ˆT2)
Similarly, the executor generates constraints from other itera-
tions. In this example, the MaxSMT solver returns a value in be-
tween of 1 and 2 so that constraints from all iterations are satisfied.
This value of T is used as arg in the candidate tuple (D1, D2, arд).
5 EXPERIMENTS
We implemented our counterexample detection framework with
all components, including hypothesis test, event selector and input
generator. The implementation is publicly available6. The tool takes
in an algorithm implementation and the desired privacy bound ϵ0,
and generates counterexamples if the algorithm does not satisfy
ϵ0-differential privacy.
6 https://github.com/cmla-psu/statdp.
Detecting Violations of Differential Privacy
CCS ’18, October 15–19, 2018, Toronto, ON, Canada
In this section we evaluate our detection framework on some of
the popular privacy mechanisms and their variations. We demon-
strate the power of our tool: for mechanisms that falsely claim to be
differentially private, our tool produces convincing evidence that
this is not the case in just a few seconds.
5.1 Noisy Max
Report Noisy Max reports which one among a list of counting queries
has the largest value. It adds Lap(2/ϵ0) noise to each answer and
returns the index of the query with the largest noisy answer. The
correct versions have been proven to satisfy ϵ0-differential privacy
[19] no matter how long the input list is. A naive proof would show
that it satisfies (ϵ0 · |Q|/2)-differential privacy (where |Q| is the
length of the input query list), but a clever proof shows that it
actually satisfies ϵ0-differential privacy.
Algorithm 5: Correct Noisy Max with Laplace noise
1 function NoisyMax(Q, ϵ0):
input:Q: queries to the database, ϵ0: privacy budget.
NoisyVector ← [ ]
for i = 1 . . . len(Q) do
NoisyVector[i] ← Q[i] + Lap(2/ϵ0)
end
return arдmax(NoisyVector)
5.1.1 Adding Laplace Noise. The correct Noisy Max algorithm (Al-
gorithm 5) adds independent Lap(2/ϵ0) noise to each query answer
and returns the index of the maximum value. As Figure 2a shows,
we test this algorithm for different privacy budget ϵ0 at 0.2, 0.7, 1.5.
All lines rise when the test ϵ is slightly less than the claimed privacy
level ϵ0 of the algorithm. This demonstrates the precision of our
tool: before ϵ0, there is almost 0 chance to falsely claim that this
algorithm is not private; after ϵ0, the p-value is too large to conclude
that the algorithm is incorrect. We note that the test result is very
close to the ideal cases, illustrated by the vertical dashed lines.
Algorithm 6: Correct Noisy Max with Exponential noise
1 function NoisyMax(Q, ϵ0):
input:Q: queries to the database, ϵ0: privacy budget.
NoisyVector ← [ ]
for i = 1 . . . len(Q) do
NoisyVector[i] ← Q[i] + Exponential(2/ϵ0)
end
return arдmax(NoisyVector)
2
3
4
5
6
2
3
4
5
6
Algorithm 7: Incorrect Noisy Max with Laplace noise, return-
ing the maximum value
1 function NoisyMax(Q, ϵ0):
input:Q: queries to the database, ϵ0: privacy budget.
NoisyVector ← [ ]
for i = 1 . . . len(Q) do
NoisyVector[i] ← Q[i] + Laplace(2/ϵ0)
end
// returns maximum value instead of index
return max(NoisyVector)
Algorithm 8: Incorrect Noisy Max with Exponential noise,
returning the maximum value
1 function NoisyMax(Q, ϵ0):
input:Q: queries to the database, ϵ0: privacy budget.
NoisyVector ← [ ]
for i = 1 . . . len(Q) do
NoisyVector[i] ← Q[i] + Exponential(2/ϵ0)
end
// returns maximum value instead of index
return max(NoisyVector)
Algorithm 9: Histogram
1 function Histogram(Q, ϵ0):
input:Q:queries to the database, ϵ0: privacy budget.
NoisyVector ← [ ]
for i = 1 . . . len(Q) do
NoisyVector[i] ← Q[i] + Lap(1/ϵ0)
end
return NoisyVector
Algorithm 10: Histogram with wrong scale
1 function Histogram(Q, ϵ0):
input:Q: queries to the database, ϵ0: privacy budget.
NoisyVector ← [ ]
for i = 1 . . . len(Q) do
// wrong scale of noise is added
NoisyVector[i] ← Q[i] + Lap(ϵ0)
end
return NoisyVector
2
3
4
5
6
7
2
3
4
5
6
7
2
3
4
5
6
2
3
4
5
6
5.1.2 Adding Exponential Noise. One correct variant of Noisy Max
adds Exponential(2/ϵ0) noise, rather than Laplace noise, to each
query answer(Algorithm 6). This mechanism has also been proven
to be ϵ0-differential private[19]. Figure 2b shows the corresponding
test result, which is similar to that of Figure 2a. The result indicates
that this correct variant likely satisfies ϵ0-differential privacy for
the claimed privacy budget.
Incorrect Variants of Exponential Noise. An incorrect variant
5.1.3
of NoisyMax has the same setup but instead of returning the index
of maximum value, it directly returns the maximum value. We
evaluate on two variants that report the maximum value instead of
the index (Algorithm 7 and 8) and show the test result in Figure 2c
and 2d.
For the variant using Laplace noise (Figure 2c), we can see that
for ϵ0 = 0.2, the line rises at around test ϵ of 0.4, indicating that
this algorithm is incorrect for the claimed privacy budget of 0.2.
CCS ’18, October 15–19, 2018, Toronto, ON, Canada
Zeyu Ding, Yuxin Wang, Guanhong Wang, Danfeng Zhang, and Daniel Kifer
(a) Correct Noisy Max with Laplace noise.
(b) Correct Noisy Max with Exponential noise.
(c) Incorrect variant with Laplace noise. It returns the
maximum value instead of the index.
(d) Incorrect variant with Exponential noise. It returns the
maximum value instead of the index.
Figure 2: Results of Noisy Max algorithm and its variants.
The same pattern happens when we set privacy budget to be 0.7
and 1.5: all lines rise much later than their claimed privacy budget.
In this incorrect version, returning the maximum value (instead
of its index) causes the algorithm to actually satisfy ϵ0 · |Q|/2 dif-
ferential privacy instead of ϵ0-differential privacy. For the variant
using Exponential noise (Figure 2d), the lines rise much later than
the claimed privacy budgets, indicating strong evidence that this
variant is indeed incorrect. Also, we can hardly see the lines for
privacy budgets 0.7 and 1.5, since their p-values remain 0 for all
the test ϵ ranging from 0 to 2.2 in the experiment.
5.2 Histogram
The Histogram algorithm [14] is a very simple algorithm for publish-
ing an approximate histogram of the data. The input is a histogram
and the output is a noisy histogram with the same dimensions. The