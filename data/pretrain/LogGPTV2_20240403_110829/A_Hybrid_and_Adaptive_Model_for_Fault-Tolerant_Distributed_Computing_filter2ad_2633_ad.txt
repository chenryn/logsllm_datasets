### 10. Optimality and Adaptability of the Proposed Protocol

It has been established that \( f < \frac{n}{2} \) is a necessary condition for such a model [5]. In this context, the proposed protocol is optimal. 

The second "extreme" instance of the model is defined by \( \forall i, t: \text{uncertain}_i = \emptyset \), which encompasses the classic synchronous distributed system model. This instance also includes other "less synchronous" computation models. As before, the protocol in Figure 1 can be simplified for this particular model. Specifically, the set \(\text{suspected}_i\) and item (2) on line 8 can be omitted. This results in an early-deciding protocol that works for any number of process failures, i.e., for \( f < n \).

In synchronous systems, it is natural to omit the sets \(\text{suspected}_i\) because 3S is only needed to handle the combined effects of asynchrony and failures.

A key feature of the protocol is its generality: the same protocol can be easily adapted to fully synchronous or fully asynchronous systems. However, these adaptations have different requirements for the value of \( f \). A significant characteristic of the protocol is its suitability for distributed systems that are neither fully synchronous nor fully asynchronous. The trade-off is the need to equip the system with a failure detector of class 3S. The benefit is that the constraint on \( f \) can be relaxed from \( f < \frac{n}{2} \).

### 4. QoS-Based Implementation of the Model

Implementing our hybrid system model requires basic facilities such as the provision and monitoring of QoS communications with both bounded and unbounded delivery times, and a failure awareness mechanism [6] to adapt the system when timely bounds can no longer be guaranteed.

Our system model leverages facilities typically found in QoS architectures, such as Omega, QoS-A [2], Quartz [12], and Differentiated Services [1]. We assume that the underlying system can provide timely communication channels (similar to services like QoS hard [2], deterministic [12], and Express Forward [1]). Similarly, we assume the existence of best-effort channels where messages are transmitted without guaranteed bounded time delays, which we call untimely.

QoS monitoring and failure awareness are implemented by the QoS Provider, failure, and state detectors. It was a design decision to build our system model on top of a QoS-based system. However, we could also have implemented our model using facilities found in existing hybrid architectures. For example, timely channels could be implemented using RTD channels with high deadline and reliability probabilities, and untimely channels could be implemented with a basic channel without guarantees [9]. The timing failure detection service of TCB [3] could then complement the required functionality.

#### 4.1. The System Model Implementation

Implementing our system model involves providing mechanisms to maintain the sets live, uncertain, and down, as defined by rules R0-R5. Two mechanisms have been developed for this purpose:
1. A state detector responsible for maintaining the sets live and uncertain based on information from the QoS Provider.
2. A failure detector that uses information from the QoS Provider, state detector, and heartbeat messages to detect crashes and update the down sets accordingly.

Each process \( p_i \) is associated with a module of the state detector, a module of the failure detector, a representation of the DS(Π, Γ) graph, and three sets: live\(_i\), uncertain\(_i\), and down\(_i\).

The DS(Π, Γ) graph is constructed using the QoS Provider functions createChannel() and DefineQoS(), according to the QoS required and resources available in the system. During the initialization phase, down\(_i\) is set to empty, and live\(_i\) and uncertain\(_i\) are initialized such that the identity of a process \( p_j \) is placed into live\(_i\) if and only if there is a timely channel linking \( p_j \) to another process (i.e., \( \exists p_x \in \Pi \) such that QoS\((p_j, p_x) = \text{timely}\)). Otherwise, the identity of \( p_j \) is placed in uncertain\(_i\).

#### 4.2. A LINUX/JAVA Prototype

The failure detector, state detector, consensus algorithm, and QoS provider have been implemented as JAVA classes and tested on a set of networked LINUX workstations. We used RED HAT LINUX 9 (kernel 2.4.20), which includes the iproute2 package for configuring kernel routing tables and executing traffic control disciplines (such as those needed for DiffServ functions [1]). We configured the LINUX kernel with CBQ (Class Based Queue) forwarding characteristics to create DiffServ classes of service (Express Forwarding for timely channels and Best Effort for untimely channels), and we used the u32 and tcindex filters to identify packets and associate them with classes of service.

We conducted experiments to assess the prototype's performance under various execution scenarios. The experimental environment consisted of a network of three LINUX Pentium III computers (800 MHz, 128 MB RAM) connected through a 100 megabits network. One computer served as a router connecting the other two. Processes were distributed across the three computers to ensure that a decision quorum would never be formed on a single machine.

An initial evaluation of the experiments is presented below, where we measured the time to reach consensus among Π processes (where uncertain = Π and live = empty set). In each experiment, we fixed the number of processes (from 3 to 6) and ran the consensus 100 times. The figures in Table 3 represent the mean time and standard deviation (in milliseconds) taken for the process that initiated the consensus to decide (i.e., the time elapsed from the execution of the primitive propose until decide is returned). As shown in the figures, the mean time increased with the number of processes, which is expected due to the inherent scalability of consensus and the communication bottleneck represented by the router in our experimental topology.

| Number of Processes | Mean Time (ms) | Standard Deviation (ms) |
|---------------------|-----------------|-------------------------|
| 3                   | 13.17           | 11.30                   |
| 4                   | 15.79           | 9.60                    |
| 5                   | 18.01           | 10.64                   |
| 6                   | 22.86           | 11.66                   |

Although the initially collected data allowed us to validate some of the main ideas behind our prototype, further performance analysis is necessary to thoroughly evaluate its performability, which we will address in future work.

### 5. Conclusion

This paper proposes and develops an adaptive model for fault-tolerant distributed computing that encompasses both synchronous (with time bounds on processing speed and message delay) and asynchronous (without time bounds) models. The fundamental characteristic of our model is that processes perceive each other’s states by accessing the contents of three local, non-intersecting sets: uncertain, live, and down. To illustrate the adaptiveness of our model, we developed a consensus algorithm that makes progress despite distinct views of the corresponding local sets and can tolerate more faults, the more processes are in the live set.

This new model is particularly relevant for applications requiring runtime adaptiveness, such as distributed multimedia systems, where previously negotiated QoS cannot always be delivered between processes. We presented an implementation of the model on top of a QoS infrastructure. To specify the underlying functionality needed to implement it, we developed a mechanism called the QoS provider. Thanks to this modular approach, porting the model implementation to a given environment requires only implementing the QoS Provider functions. The proposed system has been implemented in JAVA and tested on a set of networked LINUX workstations equipped with QoS capabilities.

### References

[1] Blake S., Black D., Carlson M., Davies E., Wang Z. and Weiss W., An Architecture for Differentiated Services, RFC 2475, 1998.

[2] Campbell, A., Coulson, G. and Hutchison, D., A Quality of Service Architecture, ACM Computer Communications Review, 24(2):6-27, 1994.

[3] Casimiro A. and Veríssimo P., Using the Timely Computing Base for Dependable QoS Adaptation Proc. 20th IEEE Symp. on Reliable Distributed Systems, New Orleans, 2001.

[4] Chandra T.D., Hadzilacos V. and Toueg S., The Weakest Failure Detector for Solving Consensus. Journal of the ACM, 43(4):685-722, 1996.

[5] Chandra T.D. and Toueg S., Unreliable Failure Detectors for Reliable Distributed Systems. Journal of the ACM, 43(2):225-267, 1996.

[6] Cristian F. and Fetzer C., The Timed Asynchronous Distributed System Model. IEEE TPDS, 10(6):642-657, 1999.

[7] Fischer M.J., Lynch N. and Paterson M.S., Impossibility of Distributed Consensus with One Faulty Process. Journal of the ACM, 32(2):374-382, 1985.

[8] Gorender S., Macdo R. and Raynal M., A QoS-Based Adaptive Model for Fault-Tolerant Distributed Computing. IRISA Tech Report 1668, 2004. http://www.irisa.fr/bibli/publi/pi/2004/1668/1668.html.

[9] Hiltunen M., Schlichting R., Han X., Cardozo M., and Das R., Real-Time Dependable Channels: Customizing QoS Attributes for Distributed Systems, IEEE TPDS, 10(6):600-612, 1999.

[10] Mostefaoui A. and Raynal M., Solving Consensus Using Chandra-Toueg’s Unreliable Failure Detectors: a General Quorum-Based Approach. Proc. 13th Symp. on Distributed Computing (DISC’99), Springer Verlag LNCS #1693, pp. 49-63, 1999.

[11] Ren Y., Cukier M. and Sanders W.H., An Adaptive Algorithm for Tolerating Values Faults and Crash Failures. IEEE TPDS, 12(2):173-192, 2001.

[12] Siqueira F. and Cahill, V., Quartz: A QoS Architecture for Open Systems, Proc. 18th Brazilian Symposium on Computer Networks, pp. 553-568, 2000.

[13] van Renesse R., Birman K., Hayden M., Vaysburd A. and Karr D., Building Adaptive Systems Using Ensemble. Software Practice and Experience, 28(9):963-979, 1998.

[14] Veríssimo P. and Casimiro A., The Timely Computing Base Model and Architecture. IEEE Transactions on Computers, Special Issue on Asynchronous Real-Time Systems, 51(8):916-930, 2002.