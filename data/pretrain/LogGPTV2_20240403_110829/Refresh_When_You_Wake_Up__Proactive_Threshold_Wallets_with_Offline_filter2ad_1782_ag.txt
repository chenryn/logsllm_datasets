The provided text appears to be a section of a technical paper, specifically focusing on the impossibility of certain secure multi-party computation protocols. The text contains references and a detailed proof. Below is an optimized version that aims to improve clarity, coherence, and professionalism:

---

### References

[43] D. Kravitz, "Digital signature algorithm," July 1993, US Patent 5,231,668.

[44] Y. Lindell, "Fast secure two-party ECDSA signing," in CRYPTO 2017.

[45] G. Castagnos, D. Catalano, F. Laguillaumie, F. Savasta, and I. Tucker, "Two-party ECDSA from hash proof systems and efficient instantiations," in CRYPTO 2019, 2019.

[46] D. Boneh, B. Lynn, and H. Shacham, "Short signatures from the Weil pairing," J. Cryptology, vol. 17, no. 4, pp. 297–319, 2004.

[47] J. Doerner, Y. Kondi, E. Lee, and A. Shelat, "Secure two-party threshold ECDSA from ECDSA assumptions," in IEEE S&P, 2018.

[48] M. Keller, E. Orsini, and P. Scholl, "Actively secure OT extension with optimal overhead," in CRYPTO, 2015.

[49] Y. Ishai, J. Kilian, K. Nissim, and E. Petrank, "Extending oblivious transfers efficiently," in CRYPTO '03, 2003, pp. 145–161.

[50] O. Goldreich, S. Micali, and A. Wigderson, "Proofs that yield nothing but their validity or all languages in NP have zero-knowledge proof systems," J. ACM, vol. 38, no. 3, pp. 690–728, July 1991.

[51] M. Stadler, "Publicly verifiable secret sharing," in EUROCRYPT '96, 1996.

[52] R. Canetti, Y. Lindell, R. Ostrovsky, and A. Sahai, "Universally composable two-party and multi-party secure computation," in ACM STOC, 2002.

### Appendix A: Full Proof of Multi-Party Impossibility

#### Intuitive Argument

Before presenting the formal theorem and proof, we build intuition by examining a (3,4) case. Specifically, we argue that it is impossible for only three online parties to proactively secure the system while tolerating two mobile corruptions. Assume \(P_0\), \(P_1\), and \(P_2\) are online, and \(P_{off}\) is offline. Since the system is resilient to two corruptions (say \(P_1\) and \(P_2\)), we cannot rely on any private communication from \(P_1\) and \(P_2\) to \(P_{off}\). Therefore, all information required by \(P_{off}\) must be contained in \(P_0\)'s view. This includes information that \(P_0\) may not be able to interpret, such as ciphertexts encrypted under a key \(P_0\) does not possess.

An adversary who continuously corrupts \(P_0\) but only corrupts \(P_{off}\) for a single epoch can derive \(P_{off}\)'s private state even in subsequent epochs. The adversary can then corrupt \(P_1\) in a later epoch (after un-corrupting \(P_{off}\)) and use the obtained private states of \(P_0\) and \(P_1\) in conjunction with \(P_{off}\)'s derived private state to completely retrieve the signing key. This is feasible because any three parties should be able to sign a message.

#### Formal Proof

Translating this intuition into a formal proof involves several subtle issues. For instance, we cannot unconditionally prove that it is impossible to realize \(F^{n,t}_{ECDSA}\) with offline refresh for \(t > 2\). To see why, consider a 'signature scheme' where the verification algorithm \(Vrfy\) outputs 1 on all inputs. Clearly, realizing a threshold version of this 'scheme' is trivial; all parties simply output "0" when instructed to sign a message, and there is no private state to refresh. Therefore, we formulate our theorem more carefully: we prove that if it is possible to offline-refresh a given threshold signature scheme (\(t > 2\)) with a dishonest online majority, then the given signature scheme itself is susceptible to forgery.

We state our theorem in the \((GLedger, FRO)\) model:
- \(GLedger\) represents that this barrier cannot be circumvented even with a consensus primitive as strong as an ideal ledger.
- \(FRO\) gives the power to compute any efficiently computable function [52] and represents the ability to produce arbitrary correlated randomness during the preprocessing phase (i.e., during key generation) and also during the refresh protocol itself.

**Theorem A.1.** Let \(\text{Sig} = (\text{KeyGen}, \text{Sign}, \text{Vrfy})\) be a triple of algorithms that satisfies the completeness definition of signature schemes. If there exists a protocol \(\pi(t,n)^{\rho-\text{sign}}\) in the \((GLedger, FRO)\)-hybrid model that UC-realizes \(F^{n,t}_{\text{Sign}}\) with \(n > t\rho \geq t > 2\) in the presence of a mobile adversary actively corrupting \(t-1\) parties, where \(t\rho \geq t \geq 2\) and \(t\rho > \lfloor t\rho/2 \rfloor + 1\), then the adversary may corrupt more than \(h\) parties. For ease of exposition, assume \(2h+1 = t\rho\).

Consider the same experiment \(\text{EXEC}_{\pi(t,n)^{\rho-\text{sign}}, Z^*}\) run with an alternative environment \(Z^*\) that corrupts each \(P_i\) for \(i \in [h+1, 2h+1]\) and issues the same commands as \(Z\), with the caveat that corrupt parties do not transmit anything on their private channels to \(P_{off}\), i.e., \((\tau_{i,off} = \bot)_{i \in [h+1, 2h+1]}\).

Observe that the view of the honest parties \(P_1, \ldots, P_h\) is distributed identically in both executions. This is because the private channel between each corrupt \(P_i\) for \(i \in [h+1, 2h+1]\) to \(P_{off}\) is hidden by definition, and \(P_{off}\) itself does not send any messages in this experiment. This fact has the following implications:
- The transcript of honest parties' private channels to \(P_{off}\), i.e., \((\tau_{i,off})_{i \in [h]}\), is distributed identically in both executions.
- The collection of private states of honest parties at the end of the experiment, i.e., \((\text{state}'_i)_{i \in [h]}\), is distributed the same in both experiments. In particular, at the end of both experiments, parties \(P_1, \ldots, P_h\) successfully advance to the next epoch. As all honest parties must agree on the epoch when activated, it holds that \(P_{off}\) advances to the next epoch in both experiments. In particular, for any \(I \subset [n] \setminus \{off\}\) such that \(|I| = t-1\), it must hold that implementing the instruction \((\text{sign}, m, I \cup \{off\})\) via \(\pi(t,n)^{\rho-\text{sign}}\) produces a valid signature \(\sigma\) of \(m\) under \(pk\).

Since we have argued that \(P_{off}\) must successfully advance to the next epoch in both experiments, we are ready to define \(\text{Ext}\) and \(\text{Sign}^*\) as follows:
- \(\text{Ext}\) implements the wake instruction for \(P_{off}\) via \(\pi(t,n)^{\rho-\text{sign}}\), using as input the entire view of \(P_{off}\), characterized by \((\tau_{i,off})_{i \in [h]}\) and \(\text{state}_{off}\), and outputs the private state of \(P_{off}\) for the next epoch, \(\text{state}'_{off}\).
- \(\text{Sign}^*\) implements the \((\text{sign}, m, I \cup \{off\})\) instruction via \(\pi(t,n)^{\rho-\text{sign}}\), using as input the private states of all these parties \((\text{state}'_i)_{i \in I \cup \{off\}}\).

By completeness and unanimous erasure of the protocol \(\pi(t,n)^{\rho-\text{sign}}\), both the above algorithms succeed with overwhelming probability. This completes the proof of this lemma.

We now construct the environment that will actually be used by the forger. Consider an instantiation with the same parameters as earlier, \(n > t\rho \geq t \geq 2\) such that \(t > \lfloor t\rho/2 \rfloor + 1\), i.e., less than half the parties in the refresh protocol are guaranteed to be honest, and define \(off = t\rho + 1\) and \(h = t\rho - t + 1\) as earlier. Define the environment \(Z^*\) controlling adversary \(A\) as follows:
1. Instruct \(A\) to corrupt \(P_1, P_2, \ldots, P_h\) and \(P_{off}\).
2. Send \(\text{init}\) to all parties.
3. Instruct \(A\) to uncorrupt \(P_{off}\).
4. Send \((\text{refresh}, [1, t\rho])\) to each party \(P_i\) where \(i \in [1, t\rho]\).
5. Send \((\text{wake})\) to all parties.
6. Instruct \(A\) to corrupt \(P_{h+1}\).
7. The adversary \(A\) outputs its entire view.
8. \(Z^*\) outputs whatever \(A\) outputs.

Note that unlike the usual specification for the real/ideal process in UC [14] in which the environment only outputs a bit, the output of \(Z^*\) here is a more complex string. This is done for ease of exposition as the output of \(Z^*\) will be used by the forger (\(Z^*\) acts as a passthrough for the output of \(A\)), and there is no meaningful advantage in the real/ideal distinguishing game.

When the instructions of \(Z^*\) are implemented with the protocol \(\pi(t,n)^{\rho-\text{sign}}\), we denote the output of the resulting experiment as \(\text{REAL}_{\pi(t,n)^{\rho-\text{sign}}, A, Z^*}\). Since \(\pi(t,n)^{\rho-\text{sign}}\) UC-realizes \(F^{n,t}_{\text{Sign}}\), there must exist a simulator \(S_{\text{Sign}}\) which interacts with \(Z^*\) in place of \(A\), and queries \(F^{n,t}_{\text{Sign}}\) instead of interacting with honest parties, with the output of the resulting experiment denoted \(\text{IDEAL}_{F^{n,t}_{\text{Sign}}, S_{\text{Sign}}, Z^*}\). We make use of this fact when constructing the forger, i.e., the forger will run the simulator \(S_{\text{Sign}}\) with the adversary to sample from \(\text{IDEAL}_{F^{n,t}_{\text{Sign}}, S_{\text{Sign}}, Z^*}\), as it cannot sample from \(\text{REAL}_{\pi(t,n)^{\rho-\text{sign}}, A, Z^*}\) without instantiating honest parties in \(\pi(t,n)^{\rho-\text{sign}}\), for which their secret states (and hence the secret key) must be known. Additionally, the challenger's public key \(pk\) can be embedded in the ideal computation using \(F^{n,t}_{\text{Sign}}\).

We are finally ready to construct the forger for the signature scheme, which forges a signature on a given message \(m\) under a public key \(pk\) received from the challenger.

**Forge(\(1^\kappa, pk, m\)):**
1. Sample \((\tau_{i,off}, \text{state}_i, \text{state}'_i)_{i \in [h]}, \text{state}_{off}, \text{state}'_{h+1} \leftarrow \text{IDEAL}_{F^{n,t}_{\text{Sign}}, S_{\text{Sign}}, Z^*}\) with the caveat that \(F^{n,t}_{\text{Sign}}\) is programmed to output \(pk\) as the public key when \(\text{init}\) is queried by \(S_{\text{Sign}}\). The ideal oracle \(GLedger\), if used, is implemented as per its specification.
2. Compute \(\text{state}'_{off} \leftarrow \text{Ext}((\tau_{i,off})_{i \in [h]}, \text{state}_{off})\).
3. Compute \(\sigma \leftarrow \text{Sign}^*(m, \text{state}'_{off}, (\text{state}'_i)_{i \in [h+1]})\).
4. Output \(\sigma\).

**Lemma A.3.** For all \(m \in \{0, 1\}^*\), the following probability is overwhelming in \(\kappa\):

\[
\Pr\left[Vrfy(pk, \sigma, m) = 1 : (sk, pk) \leftarrow \text{KeyGen}(1^\kappa), \sigma \leftarrow \text{Forge}(pk, m)\right]
\]

**Proof.** We have previously shown in Lemma A.2 that it is possible to forge a message under a public key \(pk\) by running the real protocol \(\pi(t,n)^{\rho-\text{sign}}\). We now show how to translate this ability to forge a message under a public key \(pk\) received from an external challenger (i.e., the signature experiment) using \(S_{\text{Sign}}\) to replace honest parties from \(\pi(t,n)^{\rho-\text{sign}}\) as well as program \(pk\) into the view of the adversary. We prove this lemma via a sequence of hybrid experiments.

**Hybrid H1.** In this hybrid experiment, \(\text{Forge}\) is run as specified, except that Step 1 is implemented using \(\text{REAL}_{\pi(t,n)^{\rho-\text{sign}}, A, Z^*}\). Let the public key produced by running \(\pi(t,n)^{\rho-\text{sign}}\) be denoted as \(pk\).

---

This optimized version maintains the technical content while improving readability and structure.