it would destroy graph utility (e.g. community structures). On
the other hand, LinkMirage applies perturbations selectively to
communities; thus it is possible to use a very high privacy pa-
rameter in the perturbation process, while preserving structural
properties such as community structures.
Fig. 3. Dynamic Facebook interaction dataset topology, for t = 3, 4, 5. On the left, we can see that LinkMirage has superior utility than the baseline approach
(Mittal et al.), especially for larger values of k (due to dynamic clustering). On the right, we show the overlapped edges (black) and the changed edges (yellow)
between consecutive graphs: t=(3, 4) and t=(4, 5). We can see that in LinkMirage, the perturbation of unchanged communities is correlated across time (selective
perturbation), minimizing information leakage and enhancing privacy.
D. Scalable Implementation
is the number of edges in graph Gt,
Our algorithm relies on two key graph theoretical tech-
niques: community detection (serves as a foundation for the
dynamic clustering step in LinkMirage) and random walk
(serves as a foundation for the selective perturbation step in
LinkMirage). The computational complexity for both commu-
nity detection and random walk is O(|Et|) [3], [27] where
|Et|
therefore the
overall computational complexity of our approach is O(|Et|).
Furthermore, our algorithms are parallelizable. We adopt the
GraphChi parallel framework in [22] to implement our algo-
rithm efﬁciently using a commodity workstation (3.6 GHz,
24GB RAM). Our parallel implementation scales to very large
social networks; for example, the running time of LinkMirage
is less than 100 seconds for the large scale Google+ dataset
(940 million links) (will be described in Section V-A) using
our commodity workstation.
E. Visual Depiction
For our experiments, we consider a real world Facebook
social network dataset [40] among New Orleans regional
network, spanning from September 2006 to January 2009.
Here, we utilize the wall post interaction data which represents
stronger trust relationships and comprises of 46,952 nodes
(users) connected by 876,993 edges. We partitioned the dataset
using three month intervals to construct a total of 9 graph
instances as shown in Table I. Fig. 3 depicts the outcome of
our perturbation algorithm on the partitioned Facebook graph
sequence with timestamp t = 3, 4, 5 (out of 9 snapshots),
for varying perturbation parameter k (perturbation parameter
for each community). For comparative analysis, we consider
a baseline approach [27] that applies static perturbation for
each timestamp independently. In the dynamic clustering step
of our experiments, we free the two-hop neighborhoods of the
changed nodes, i.e. m = 2.
The maximum-modularity clustering method yields two
communities for G3,
three communities for G4, and four
communities for G5. For the perturbed graphs, we use the
same color for the vertices as in the original graph and
we can see that ﬁne-grained structures (related to utility)
are preserved for both algorithms under small perturbation
parameter k, even though links are randomized. Even for high
values of k, LinkMirage can preserve the macro-level (such
as community-level) structural characteristics of the graph. On
the other hand, for high values of k, the static perturbation
algorithm results in the loss of structure properties, and appears
to resemble a random graph. Thus, our approach of ﬁrst
isolating communities and applying perturbation at the level
of communities has beneﬁts even in a static context.
Fig. 3 also shows the privacy beneﬁts of our perturbation
algorithm for timestamps t = 4, 5. We can see that LinkMirage
reuses perturbed links (shown as black unchanged links) in
the unchanged communities (one unchanged community for
t = 4 and two unchanged communities for t = 5). Therefore,
LinkMirage preserves the privacy of users’ social relationships
by considering correlations among the graph sequence, and this
beneﬁt does not come at the cost of utility. In the following
sections, we will formally quantify the privacy and utility
properties of LinkMirage.
V. PRIVACY ANALYSIS
We now address the question of understanding link pri-
vacy of LinkMirage. We propose three privacy metrics: anti-
inference privacy,
indistinguishability, anti-aggregation pri-
vacy to evaluate the link privacy provided by LinkMirage.
Both theoretical analysis and experimental results with a Face-
book dataset (870K links) and a large-scale Google+ dataset
(940M links) show the beneﬁts of LinkMirage over previous
approaches. We also illustrate the relationship between our
privacy metric and differential privacy.
A. Experimental Datasets
To illustrate how the temporal information degrades privacy,
we consider two social network datasets. The ﬁrst one is a
large-scale Google+ dataset [14]. whose temporal statistics are
illustrated in Table II. To the best of our knowledge, this is the
largest temporal dataset of social networks in public domain.
The Google+ dataset is crawled from July 2011 to October
2011 which has 28,942,911 nodes and 947,776,172 edges.
The dataset only considers link additions, i.e. all the edges in
the previous graphs exist in the current graph. We partitioned
the dataset into 84 timestamps. The second one is the 9-
timestamp Facebook wall posts dataset [40] as we stated in
Section IV-E. with temporal characteristics shown in Table I. It
is worth noting that the wall-posts data experiences tremendous
churn with only 45% overlap for consecutive graphs. Since our
dynamic perturbation method relies on the correlation between
consecutive graphs, the evaluation of our dynamic method on
the Facebook wall posts data is conservative. To show the
improvement in performance of our algorithm for graphs that
evolve at a slower rate, we also consider a sampled graph
sequence extracted from the Facebook wall posts data with
80% overlap for consecutive graphs.
6
t=3t=4Mittaletal.(k=5)Mittaletal.(k=20)t=5LinkMirage(k=5)LinkMirage(k=20)OriginalgraphsMittaletal.(k=20)LinkMirage(k=20)LinkMirage(k=5)Mittaletal.(k=5)OriginalgraphsTime
# of nodes
# of edges
Average degree
TABLE II. Temporal Statistics of the Google+ Dataset.
Aug.8
Aug.28
Aug.18
Sep.7
Sep.17
Jul.29
Sep.27
Oct.7
16,165,781
28,942,911
505,527,124 560,576,194 575,345,552 654,523,658 686,709,660 759,226,300 886,082,314 947,776,172
19,954,197
24,235,387
17,483,936
17,850,948
19,406,327
28,035,472
31.2714
32.0624
32.2305
33.7273
34.4143
31.3272
31.6058
32.7464
Fig. 4. (a),(b) represent the link probability distributions for the whole Facebook interaction dataset and the sampled Facebook interaction dataset with 80%
overlap. We can see that the posterior probability of LinkMirage is more similar to the prior probability than the baseline approach.
B. Anti-Inference Privacy
First, we consider adversaries that aim to infer link in-
formation by leveraging Bayesian inference. We deﬁne the
privacy of a link Lt (or a subgraph) in the t-th graph instance,
as the difference between the posterior probability and the
prior probability of the existence of the link (or a subgraph),
computed by the adversary using its prior information W ,
and the knowledge of the perturbed graph sequence {G(cid:48)
i}t
i=0.
Utilizing Bayesian inference, we have
Deﬁnition 1: For link Lt in the original graph sequence
G0,··· , Gt and the adversary’s prior information W , the anti-
inference privacy Privacyai for the perturbed graph sequence
0,··· , G(cid:48)
G(cid:48)
t is evaluated by the similarity between the poste-
rior probability P (Lt|{G(cid:48)
i}t
i=0, W ) and the prior probability
P (Lt|W ), where the posterior probability is
i=0|Lt, W ) × P (Lt|W )
i}t
P ({G(cid:48)
P (Lt|{G(cid:48)
i}t
i}t
P ({G(cid:48)
i=0|W )
i=0, W ) =
(1)
Higher similarity implies better anti-inference privacy.
The difference between the posterior probability and the prior
probability represents the information leaked by the perturba-
tion mechanism. Similar intuition has been mentioned in [23].
Therefore, the posterior probability should not differ much
from the prior probability.
In the above expression, P (Lt|W ) is the prior probability
of the link, which can be computed based on the known
structural properties of social networks, for example, by using
i}t
link prediction algorithms [24]. Note that P ({G(cid:48)
i=0|W ) is a
normalization constant that can be analyzed by sampling tech-
niques. The key challenge is to compute P ({G(cid:48)
i}t
i=0|Lt, W )3.
For evaluation, we consider a special case where the adver-
sary’s prior is the entire time series of original graphs except
the link Lt (which is the link we want to quantify privacy for,
and Lt = 1 denotes the existence of this link while Lt = 0
denotes the non-existence of this link). Such prior information
can be extracted from personal public information, Facebook
related information or other application-related information as
3The detailed process for computing the posterior probability can be found
in [27].
7
Fig. 5. Link probability distribution for the Google+ dataset under the
adversary’s prior information extracted from the social-attribute network model
in [14].
i=0)
i=0)
Denoting {(cid:101)Gi(Lt)}t
stated in [6]. Note that this is a very strong adversarial prior,
which would lead to the worst-case analysis of link privacy.
i=0 as the prior which contains all the
information except Lt, we have the posterior probability of
link Lt under the worst case is
i=0)
i=0,{(cid:101)Gi(Lt)}t
i=0|, Lt,{(cid:101)Gi(Lt)}t
i=0|{(cid:101)Gi(Lt)}t
i}t
P ({G(cid:48)
i=0) × P (Lt|{(cid:101)Gi(Lt)}t
P (Lt|{G
i}t
(cid:48)
i}t
P ({G(cid:48)
=
i=0).
(cid:48)
i=0) = P (G
t|G
(cid:48)
(cid:48)
where
P ({G
i}t
(cid:48)
1|G
(cid:48)
(cid:48)
P (G
0|(cid:101)G0(Lt))×
t−1, (cid:101)Gt−1(Lt), (cid:101)Gt(Lt))
i=0) close to P (Lt|{(cid:101)Gi(Lt)}t
i=0|Lt,{(cid:101)Gi(Lt)}t
0, (cid:101)G0(Lt), (cid:101)G1(Lt))··· P (G
i=0,{(cid:101)Gi(Lt)}t
Therefore, the objective of perturbation algorithms is to make
P (Lt|{G(cid:48)
i}t
Comparison with previous work: Fig. 4 shows the pos-
terior probability distribution for the whole Facebook graph
sequence and the sampled Facebook graph sequence with
80% overlapping ratio, respectively. We computed the prior
probability using the link prediction method in [24]. We can
see that the posterior probability corresponding to LinkMirage
is closer to the prior probability than that of the method of
Mittal et al. [27]. In Fig. 4(b), taking the point where the
link probability equals 0.1, the distance between the posterior
CDF and the prior CDF for the static approach is a factor of 3
larger than LinkMirage (k = 20). Larger perturbation degree
k improves privacy and leads to smaller difference with the
prior probability. Finally, by comparing Fig. 4(a) and (b), we
can see that larger overlap in the graph sequence improves the
10−310−210−110000.20.40.60.81(a) Inference ProbabilityCumulative distribution function  Prior probabilityk=5, Mittal et al.k=5, LinkMiragek=20, Mittal et al.k=20, LinkMirage10−310−210−110000.20.40.60.81(b) Inference probabilityCumulative distribution function  Prior probabilityk=5, Mittal et al.k=5, LinkMiragek=20, Mittal et al.k=20, LinkMirage10−310−210−110000.10.20.30.40.50.60.70.80.91Inference ProbabilityCumulative distribution function  Prior Probabilityk=5, Mittal et al.k=5, LinkMiragek=20, Mittal et al.k=20, LinkMirageFig. 6. (a),(b) represent the temporal indistinguishability for the whole Facebook interaction dataset and the sampled Facebook interaction dataset with 80%
overlap. Over time, the adversary has more information, resulting in decreased indistinguishability. We can also see that LinkMirage has higher indistinguishability
than the static method and the Hay’s method in [16], although it still suffers from some information leakage.
privacy beneﬁts of LinkMirage. We also compare with the
work of Hay et al. in [16], which randomizes the graph with
r real links deleted and another r fake links introduced. The
probability for a real link to be preserved in the perturbed graph
is 1 − r/m, which should not be small otherwise the utility
would not be preserved. Even considering r/m = 0.5 (which
would substantially hurt utility [16]), the posterior probability
for a link using the method of Hay et al. would be 0.5,
even without prior information. In contrast, our analysis for
LinkMirage considers a worst-case prior, and shows that the
posterior probability is smaller than 0.5 for more than 50% of
the links when k = 20 in Fig. 4. Therefore, our LinkMirage
provides signiﬁcantly higher privacy than the work of Hay et
al.
Adversaries with structural and contextual information:
Note that our analysis so far focuses on quantifying link-
privacy under an adversary with prior information about the
original network structure (including link prediction capabil-
ities). In addition, some adversaries may also have access to
contextual information about users in the social network, such
as user attributes, which can also be used to predict network
links (e.g., social-attribute network prediction model in [14]).
We further computed the prior probability using such social-
attribute network prediction model in [14] and showed the link
probability for the Google+ dataset in Fig. 5. The posterior
probability of our LinkMirage is closer to the prior probability
and thus LinkMirage achieves better privacy performance than
previous work.
C. Indistinguishability
i=0,{(cid:101)Gi(Lt)}t
Based on the posterior probability of a link under the worst
i}t
case P (Lt|{G(cid:48)
i=0), we need to qualify the pri-
vacy metric for adversaries who aim to distinguish the posterior
i=0 and the prior knowledge {(cid:101)Gi(Lt)}t
probability with the prior probability. Since our goal is to
reduce the information leakage of Lt based on the perturbed
graphs {G(cid:48)
i}t
i=0, we
consider the metric of indistinguishability to quantify privacy,
which can be evaluated by the conditional entropy of a private
message given the observed variables [7]. The objective for
an obfuscation scheme is to maximize the indistinguishability
of the unknown input I given the observables O, i.e. H(I|O)
(where H denotes entropy of a variable [7]). Here, we deﬁne
our metric for link privacy as
Deﬁnition 2: The indistinguishability for a link Lt
the original graph Gt
that
from the perturbed graph G(cid:48)
information {(cid:101)Gi(Lt)}t
i=0
the
in
adversary can infer
t under the adversary’s prior
is deﬁned as Privacyid =