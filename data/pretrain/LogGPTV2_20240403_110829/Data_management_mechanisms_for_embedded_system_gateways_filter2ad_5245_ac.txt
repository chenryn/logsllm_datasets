### Dropped Message Counts for Various Queue Lengths (5000 Trials, Drop Oldest Overflow Policy)

**Figure 6: Summary of the total number of dropped messages from each trial for experiments with queues of various lengths.**

- **Number of Dropped Messages:** 0, 100, 200, 300, 400
- **Queue Length:** 1, 3, 6, 10, 20, 30, 40, 50, 60

### Average Delay for Various Queue Lengths (5000 Trials, Drop Oldest Overflow Policy)

**Figure 7: Summary of the average queue delay for queues of various lengths.**

- **Average Delay (s):** 0, 10, 20, 30, 40, 50
- **Queue Length:** 1, 10, 20, 30, 40, 50, 60

For queues of length 40 or longer, the median value of the average delay begins to level off, although the upper bound on delay continues to grow. Longer queues are less likely to overflow and are also less likely to be full, which means that as queue bounds become larger, the median delay is governed less by the length of the queue and more by the timing of the arrival messages (recall that each experiment uses the same set of arrival sequences).

Based on the results in Figures 6 and 7, we observe a trade-off between the number of dropped messages and the average queue delay.

### Mean Value Error for Various Queue Lengths

**Figure 8: Boxplot summary of mean value error for various queue lengths.**

- **Mean Value Error (km/h):** 0, 5, 10, 15, 20, 25
- **Queue Length:** 1, 20, 50, Unbounded

Shorter queue lengths have a slightly lower median value error. The boxplots in Figure 8 compare the mean value error for experiments run with bounded queues of length 1, 20, and 50, and an unbounded queue. For the bounded queues, the "Drop Oldest" overflow policy was used.

We might expect that reducing queue delay would also decrease the mean value error in the output. Indeed, the results in Figure 8 show that the median error does go down slightly as the queue length is reduced. However, we also observe that the 5th percentile of the error actually increases for short queues. Although we have reduced the delay by reducing the queue size, shorter queues drop more messages, and these dropped messages also contribute to the mean value error. Therefore, while the queue length parameter can be used to choose a point in the trade-off space between dropped messages and average delay, it has very little effect on the mean value error.

### Comparison of Experiments Using a Length 50 Bounded Queue with Various Overflow Policies

**Figure 9: Boxplot summary of mean value error for queues employing various overflow policies.**

- **Mean Value Error (km/h):** 0, 5, 10, 15, 20, 25
- **Overflow Policy:** Drop Oldest, Drop Newest, Drop Random, Drop All

The performance of the "Drop Newest," "Drop Oldest," and "Drop Random" policies is almost the same because when an overflow condition occurs, each policy drops a single value. Although each policy selects a different message to drop, the number of dropped messages, and thus the overall effect, is relatively small. The only policy that exhibits different behavior is the "Drop All" policy. The performance of this policy is worse because the flushing of the queue results in a large number of dropped messages.

The insight gained from these experiments is that neither queue length nor overflow policy can significantly improve the mean value error performance of the gateway.

### Analysis

As the results in Section 6 show, the delay introduced by the queue can increase the error in the values output by the gateway. A detailed examination of the queue in operation can offer insight into how queue delay arises, which in turn offers insight into how to mitigate delay.

It turns out that queue underflow is the root cause of message delivery delay. In the example we consider, the average input and output rates of the gateway are the same, so in the steady state, there should be no accumulation of messages in the queue. However, the experimental results show that this is not the case.

**Figure 10: Comparison of Queues and Filters with bursty inputs.**

- **Part (a):** Ideal case where each incoming message arrives in time for its timeslot in the output stream.
- **Part (b):** Bursty traffic arrivals, causing queue underflow and delayed message delivery.
- **Part (c):** Proposed solution using a filter mechanism to estimate missing data.

In part (b) of the figure, when the first three messages arrive in a burst, they are queued and delivered in their appropriate timeslots. Because of the long quiescent period between the bursts, the fourth message has not arrived when the fourth timeslot comes up at the output, so the third message is sent again (per the mailbox policy). When the fourth message does arrive, it is sent in the timeslot where the fifth message should go, and the fifth message is delivered in the sixth slot, and so on. The timeslot missed by the fourth message cannot be recovered, and the steady-state size of the queue has increased by one, adding one message period delay to each delivered message.

This process can happen repeatedly, causing the queue to grow longer and longer as a result of either normal timing variations or a malicious attacker purposely clumping message arrival times.

The proposed solution to the problem of queue underflow is shown in part (c) of the figure. When underflow occurs and the fourth message is not available in the fourth timeslot, the data management mechanism produces an estimate of the missing data. When the fourth value arrives, it is not delivered in the fifth timeslot. In fact, it is not delivered at all. This eliminates the delay caused by the missed timeslot.

### Filter Mechanisms

A mechanism that implements the behavior shown in part (c) of Figure 10 can be thought of as a queue with a special policy that drops an incoming message for every duplicate message that has been sent. This policy is not an overflow policy because the messages are not dropped based on the length of the queue. If this special queue mechanism uses the mailbox policy for underflow, then the estimate for the missing message will be the last sent message. This queue mechanism can intelligently drop messages in order to reduce delay, but since the queue mechanism can only process messages based on their arrival order and timing, the estimates for the missed message values cannot be more sophisticated than those generated by the mailbox policy.

We propose to generalize the idea of using previous data values to estimate missing output values. We call a mechanism that looks at message values as well as message timing and arrival order a filter. Additionally, filter mechanisms may aggregate or modify message values. One consequence of this definition is that a queue may only deliver a message value that it has received in the incoming message stream, but filters could potentially deliver a message with a value that has never been seen at the input of the gateway, although this new value may be a function of previous input values.

A wide variety of models can be applied to the data to generate an estimate. For example, the model could predict a missing value by taking the average of the three previous values or by performing regression analysis on the previous data and extrapolating to compute the new value. The data model should be chosen to fit the data that is being filtered.

Although there is a very large design space for data models that can be used in these filters, our purpose here is simply to demonstrate that filters can be more effective than queues in the enterprise-to-embedded scenario. Therefore, we have chosen the mechanism described in part (c) of Figure 10. This mechanism uses a simple data model which approximates missing values by zero-order (constant) approximation. In other words, the missing value is approximated by the last value that was received at the gateway input.

As we have noted, this mechanism is on the boundary between queues and filters and could be classified as either one. The comparison in Section 9 below shows that this mechanism exhibits significantly better data value error performance. We believe that further improvement could be obtained by using more sophisticated data models, and for this reason, we choose to classify this mechanism as a filter mechanism.

### Comparing Filters and Queues

To compare the filter and queue mechanisms, we evaluate them using the mean value error metric. Recall from the results in Section 6 that the queue length and overflow policy parameters had little impact on the mean value error metric.

**Figure 11: Mean value error summary comparing the filter mechanism to length 1 and 50 bounded queues and an unbounded queue.**

- **Mean Value Error (km/h):** 0, 5, 10, 15, 20, 25
- **Mechanism:** Filter, Queue (1), Queue (50), Unbounded Queue

The bounded queues used the "Drop Oldest" overflow policy. Per the results in Figure 9, other overflow policies would yield similar results. Although the 95th percentile of the mean value error is only slightly lower, the filter mechanism shows a significant bias toward lower mean value errors.

**Figure 12: Cumulative distribution functions of the mean value error for the filter and queue mechanisms.**

- **Mean Value Error (km/h):** 0, 5, 10, 15, 20, 25
- **Cumulative Probability:** 0.0, 0.2, 0.4, 0.6, 0.8, 1.0
- **Mechanism:** Queue (1), Queue (50), Unbounded Queue, Filter

These results are not meant to imply that queue mechanisms have no place in embedded system gateways. There may be other scenarios with different requirements that are more suited to their characteristics. These results do demonstrate that a further exploration of filter mechanisms is warranted.

### Conclusions and Future Work

As it becomes more common to network and inter-network embedded systems, there is a need to develop mechanisms and policies for embedded system gateways and to develop guidance on how these mechanisms and policies can be used. We have begun this work by evaluating queue mechanisms and by proposing instead using a filter mechanism. Although queues are used successfully in Internet routers to manage bandwidth and optimize throughput, we have shown that queue mechanisms are not well-suited to at least some embedded system gateway applications, which require timely delivery of data.

An important insight is that queue delay is a result of queue underflow. Our evaluation has demonstrated the inherent trade-off between dropped messages and delay, and we have shown how both delay and dropped messages can introduce error in periodic, continuous-valued state variable data streams. We have also demonstrated that a simple filter mechanism can mitigate the shortcomings of the queue mechanism and improve gateway performance over queue mechanisms.

One assumption in our approach to data handling in the gateway is that the minimum sampling speed for the application can be met by the gateway mechanisms. If timing differences in the networks result in too many messages being dropped, then using that network topology may be infeasible. It is possible that mechanisms which include estimation (such as more advanced versions of the filters proposed here) can mitigate this shortcoming, but it depends on the character of the data and the application requirements.

We believe that, in contrast to Internet routers, successful embedded system gateway designs are going to require some application knowledge, or at the very least, knowledge of the requirements for a particular data stream. If there are multiple data streams in the gateway, some method (such as a priori configuration) must be in place to enumerate these streams, to select a data management mechanism for each stream, and to define parameters (such as queue length for a queue mechanism or data model type for a filter mechanism).

By enumerating various mechanisms and the types of scenarios they are suited for, we can provide a toolkit of data management mechanisms that can be used at design time to develop gateway implementations with a fixed set of mechanisms for specific applications and data types. Given sufficient understanding of the impact different mechanisms have on various types of data streams, applications themselves could communicate with the gateway at runtime and request a particular mechanism for a particular data stream via an API, similar to the plug-and-play (uPnP) protocol employed in many commodity home routers. In this way, the embedded system gateway can move toward becoming a generic device that can be used with many systems and applications.

As we continue to study the design and implementation of embedded system gateways, there are several avenues that remain to be explored. The simple filter introduced in this paper is just the beginning of the design space for filter mechanisms. We plan to examine various estimation and regression methods and evaluate their effectiveness as data models for various types of state variable data. We will also continue to identify and evaluate new data management mechanisms. For example, one mechanism that is likely to be needed is a mechanism to aggregate data. Such a mechanism could be used when connecting a high-bandwidth network to a low-bandwidth network. We also plan to evaluate the mechanisms we have already identified under other scenarios, such as the embedded-to-enterprise and embedded-to-embedded scenarios. Just as the evaluation presented here gave insight into the design of the filter mechanism, we expect these other scenarios to yield similar insights and possibly new mechanisms as well.

### Acknowledgment

This research was funded by General Motors through the GM-Carnegie Mellon Vehicular Information Technology Collaborative Research Lab.

### References

1. W.C. Feng, K. Shin, D. Kandlur, and D. Saha. The BLUE active queue management algorithms. Networking, IEEE/ACM Transactions on, 10(4):513–528, Aug 2002.
2. FlexRay-Consortium. FlexRay communications system, protocol specification, version 2.0. Request online: <http://www.flexray.com/specification_request.php>.
3. S. Floyd and V. Jacobson. Random early detection gateways for congestion avoidance. Networking, IEEE/ACM Transactions on, 1(4):397–413, Aug 1993.
4. Q. Huang, J.S. Smith, and T. Li. Web-based distributed embedded gateway system design. In WI’06: Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence, pages 905–908, Washington, DC, USA, 2006. IEEE Computer Society.
5. H. Jiang and C. Dovrolis. Why is the internet traffic bursty in short timescales? In SIGMETRICS’05: Proceedings of the 2005 ACM SIGMETRICS international conference on Measurement and modeling of computer systems, pages 241–252, New York, NY, USA, 2005. ACM Press.
6. P. Koopman, J. Morris, and T. Maxino. Position paper: Deeply embedded survivability. ARO Planning Workshop on Embedded Systems and Network Security, Raleigh NC, Feb 22-23 2007.
7. T. Lakshman, A. Neidhardt, and T. Ott. The drop from front strategy in TCP and in TCP over ATM. INFOCOM’96. Fifteenth Annual Joint Conference of the IEEE Computer Societies. Networking the Next Generation. Proceedings IEEE, 3:1242–1250 vol.3, Mar 1996.
8. A. Mankin. Random drop congestion control. SIGCOMM Comput. Commun. Rev., 20(4):1–7, 1990.
9. J. Nilsson. Real-Time Control Systems with Delays. PhD thesis, Lund Institute of Technology, 1998.
10. Robert Bosch, GmbH. CAN specification, version 2.0, 1991.
11. J. Samuel. Emission related diagnostic services. IEEE Communication Standards for European On-Board-Diagnostics Seminar (Ref. No. 1998/294), pages 10/1–10/6, Feb 1998.
12. H. Sirisena, A. Haider, and K. Pawlikowski. Auto-tuning RED for accurate queue control. Global Telecommunications Conference, 2002. GLOBECOM’02. IEEE, 2:2010–2015 vol.2, Nov. 2002.
13. TTA-Group. Time-triggered protocol TTP/C, high-level specification document, protocol version 1.1. Request online: <http://www.ttagroup.org/technology/specification.htm>, 2003.