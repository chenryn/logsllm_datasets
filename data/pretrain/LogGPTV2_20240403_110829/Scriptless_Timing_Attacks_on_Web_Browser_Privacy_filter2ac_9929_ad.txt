# Browser Compatibility and Security Analysis

## Table of Browser Versions
| Browser                   | Version  |
|---------------------------|----------|
| Internet Explorer         | 10.0.9   |
| Firefox                   | 19.0     |
| Chrome                    | 26.0     |
| Safari                    | 5.1.4    |
| Android Built-in Browser  | 4.2      |
| Dolphin                   | 9.1.0    |

## Experimental Results
| Metric | IE 10.0.9 | Firefox 19.0 | Chrome 26.0 | Safari 5.1.4 | Android 4.2 | Dolphin 9.1.0 |
|--------|-----------|--------------|-------------|--------------|-------------|---------------|
| Requests | 200 | 200 | 200 | 200 | 20 | 20 |
| Successes | 200 | 200 | 200 | 200 | 20 | 20 |
| Failures | 1 | 0 | 0 | 1 | 0 | 0 |
| Caching Hits | 200 | 200 | 200 | 200 | 20 | 20 |
| Caching Misses | 198 | 200 | 199 | 20 | 2 | 0 |

## V. Countermeasures

The most straightforward countermeasure against cache-based attacks is to disable caching entirely. This would prevent the attacks but would also lead to an unacceptable performance penalty, as nearly 60% of HTTP queries are for cacheable resources [30]. Disabling caching is therefore not a practical solution.

Alternatively, Jackson et al. developed a Firefox extension called SafeCache, which prevents timing attacks by enforcing a same-origin policy on the browser cache [19]. This extension modifies the default caching service so that the browser cache is partitioned and isolated for different domains. SafeCache effectively defends against both traditional and scriptless timing attacks. However, it has not been adopted by browser vendors and is not available for more recent versions of Firefox. We recommend that browser vendors integrate this technique as a built-in security feature, despite the potential storage overhead.

Our method leverages CSS features instead of executing scripts. By removing support for these features in browsers, the attack can be prevented. However, completely abandoning such features may be unacceptable for web application developers and users. A possible compromise is to limit the capabilities of these features. For example, for CSS scrollbar customization, a same-origin policy could be implemented to block suspicious requests. Specifically, requests should only be allowed if they are sent to the same domain as the embedded content. In the case of the attack pages discussed in Section III, if the requests triggered by the increment track pieces were limited to the original website (e.g., www.nsf.gov), no information would be leaked to attackers. Unfortunately, this defense is ineffective against attacks using CSS media queries, as there is no direct relationship between the media queries used to send requests and the target resource. It is challenging, if not impossible, to identify suspicious requests. The core of this attack relies on the fact that browsers load non-cached resources in a specific order. If we could randomize the loading order of non-cached resources, the false negative rate of comparison-based attacks might increase significantly. We believe a feasible mitigation technique with low overhead could be developed based on this approach.

## VI. Discussion

A natural concern is whether image searches on engines like Google can introduce false positives. If the target image appears in the search results, it may be stored in the cache. However, in our method, queries against search engines rarely introduce false positives. Typically, the images displayed in search results are thumbnails generated by the search engine and stored on their servers. If a user does not view the original image, it will not be cached by the browser. Additionally, attackers can choose images that are unlikely to be found by search engines, such as background images of web pages, which have a weak semantic relationship with the page content.

Older history-sniffing attacks that exploited browser bugs could probe tens of thousands of sites within a few minutes, but these bugs have since been fixed. As a timing attack, our method takes longer to probe a target site. However, in many cases, attackers may only need to know if the victim has visited a limited number of sites. For example, a site might want to check if users have visited several competitors' sites. Our experiments show that our approach can probe dozens of URLs within a few minutes, making it efficient for such scenarios.

It should also be noted that other browser features may be exploitable for inspecting resource loading and rendering. With the increasing number of dynamic and interactive features in modern browsers, we expect more exploitable features to emerge.

## VII. Related Work

History-sniffing attacks have received significant attention recently due to the potential damage they can cause [20, 31]. The most widespread technique is the CSS-based attack, which uses CSS markups to determine which websites a user has visited [14]. These attacks have proven effective and efficient, as demonstrated by Janc et al. [21], who showed that this technique can detect browser history on a large scale. CSS-based history sniffing is documented as a bug in many browsers, such as Bug 57351 in Mozilla Firefox [27]. To address this, Baron of Mozilla Corporation proposed a solution [10] that blocks CSS-based attacks by making the computed style APIs pretend that all links are unvisited. All major browsers, including Firefox, Chrome, Safari, and Internet Explorer, have adopted this solution, rendering this type of history sniffing ineffective in the latest versions.

Another general technique for history sniffing falls under the umbrella of side-channel attacks, which can leak private information while bypassing system security policies. These attacks are difficult to find and often cannot be eliminated without compromising other desirable characteristics of the system [16].

Among side-channel attacks, timing attacks, as proposed by Felten and Schneider [15], are well-known. These attacks rely on the fact that the load time of a resource can indicate whether it is in the browser cache. Bortz and Boneh [11] and Michal [26] have demonstrated how to use timing attacks to expose private information from web applications. Brewster [12] showed another approach where, for sites where users remain logged in for extended periods (e.g., Facebook), an attacker can attempt to load certain resources and use JavaScript's `onerror` event to get error information, revealing whether the user is logged in.

In addition to page caching, some researchers have conducted history sniffing using DNS caching [17, 23] or cached cookies [15]. For example, the prefetch DNS technique in popular browsers like Firefox and Chrome can reveal search entries made by users [23]. Weinberg et al. [29] discovered that attackers can use webcams to sniff browsing histories, although this is difficult to exploit in practice.

To our knowledge, all recent attacks on users' browsing histories, including CSS-based and timing attacks, are script-based. Due to the serious threats posed by client-side scripts, many defense techniques have been proposed to block the execution of suspicious scripts [1, 4, 5, 7, 24, 28]. Heiderich et al. [18] introduced a new attack technique called "scriptless attacks," and Zalewski [32] presented alternatives to direct script injection. Our research is inspired by these studies, but we use CSS features differently and for different purposes. In our work, CSS features are employed as a timing measure tool, not a page content extractor. We demonstrate that CSS features can be leveraged to sense out-of-page sensitive information rather than just within-page content.

## VIII. Conclusion

In this paper, we presented a new timing attack method for sniffing users' browsing histories. Unlike existing methods, our approach does not rely on the execution of client-side scripts and is applicable to modern browsers. We found that three CSS features—CSS animation, scrollbar customization, and media queries—can be exploited to monitor the rendering process of a resource, providing an indirect but effective way to determine whether a resource exists in the browser cache. Combining these CSS features with selected standard browser features, we developed three practical attack vectors. We evaluated their effectiveness on six popular browsers, including Internet Explorer, Firefox, and four WebKit-based browsers. The results show that the three attack vectors can effectively sniff users' browsing histories, especially when using media queries, with very low false positive and false negative rates. Our research demonstrates that browsers are still vulnerable to browsing history leakage, even when protected by script-blocking tools.

In the future, we plan to investigate additional exploitable browser mechanisms. With the increasing number of dynamic and interactive features in modern browsers, we expect more exploitable features to emerge, requiring prompt identification and subsequent defense approaches.

## Acknowledgment

The authors would like to thank the anonymous reviewers for their insightful comments. This work is supported by the National Natural Science Foundation of China (NSFC) under grants 61170240 and 61070192, and the National Science and Technology Major Project of China under grant 2012ZX01039-004.

## References

[1] “Content Security Policy,” http://www.w3.org/TR/2011/WD-CSP-20111129/.

[2] “CSS,” http://www.w3.org/Style/CSS/.

[3] “CSS3,” http://www.w3.org/Style/CSS/current-work.en.html.

[4] “HTML5 IFrame Sandbox,” http://www.w3.org/TR/2011/WD-html5-20110525/the-IFrame-element.html#attr-IFrame-sandbox.

[5] “JavaScript Blocker for Safari,” http://javascript-blocker.toggleable.com/.

[6] “McDonald’s, CBS, & Microsoft Mine Data from Web Ads, Class Claims,” http://www.courthousenews.com/2010/12/27/32877.htm.

[7] “NotScripts for Chrome,” https://chrome.google.com/webstore/detail/notscripts/odjhifogjcknibkahlpidmdajjpkkcfn.

[8] “Statement by FTC Bureau of Consumer Protection Director David Vladeck Regarding Judge’s Approval of Google Safari Settlement,” http://www.ftc.gov/opa/2012/11/google.shtm.

[9] “YouPorn Sued for Sniffing Browser History,” http://news.cnet.com/8301-30685_3-20024696-264.html.

[10] D. Baron, “Preventing attacks on a user’s history through CSS :visited selectors,” http://dbaron.org/mozilla/visited-privacy.

[11] A. Bortz and D. Boneh, “Exposing private information by timing web applications,” in WWW, 2007, pp. 621–628.

[12] K. Brewster, “Patching privacy leaks,” http://kentbrewster.com/patching-privacy-leaks/.

[13] S. Chen, R. Wang, X. Wang, and K. Zhang, “Side-channel leaks in web applications: A reality today, a challenge tomorrow,” in IEEE Symposium on Security and Privacy, 2010, pp. 191–206.

[14] A. Clover, “CSS visited pages disclosure,” http://seclists.org/bugtraq/2002/Feb/271.

[15] E. W. Felten and M. A. Schneider, “Timing attacks on web privacy,” in ACM Conference on Computer and Communications Security, 2000, pp. 25–32.

[16] V. Gligor, “A guide to understanding covert channel analysis of trusted systems,” National Computer Security Center, Tech. Rep., 1993.

[17] L. Grangeia, “DNS cache snooping or snooping the cache for fun and profit,” SideStep Seguranca Digitial, Tech. Rep., 2004.

[18] M. Heiderich, M. Niemietz, F. Schuster, T. Holz, and J. Schwenk, “Scriptless attacks: stealing the pie without touching the sill,” in ACM Conference on Computer and Communications Security, 2012, pp. 760–771.

[19] C. Jackson, A. Bortz, D. Boneh, and J. C. Mitchell, “Protecting browser state from web privacy attacks,” in WWW, 2006, pp. 737–744.

[20] M. Jakobsson and S. Stamm, “Invasive browser sniffing and countermeasures,” in WWW, 2006, pp. 523–532.

[21] A. Janc and L. Olejnik, “Feasibility and real-world implications of web browser history detection,” in Web 2.0 Security and Privacy Conference, 2010.

[22] D. Jang, R. Jhala, S. Lerner, and H. Shacham, “An empirical study of privacy-violating information flows in JavaScript web applications,” in ACM Conference on Computer and Communications Security, 2010, pp. 270–283.

[23] S. Krishnan and F. Monrose, “DNS prefetching and its privacy implications: when good things go bad,” in USENIX Conference on Large-scale Exploits and Emergent Threats, 2010.

[24] G. Maone, “NoScript for Mozilla Firefox,” https://addons.mozilla.org/de/firefox/addon/722/.

[25] J. R. Mayer and J. C. Mitchell, “Third-party web tracking: Policy and technology,” in IEEE Symposium on Security and Privacy, 2012, pp. 413–427.

[26] Michal, “Rapid history extraction through non-destructive cache timing,” http://lcamtuf.coredump.cx/cachetime/.

[27] J. Ruderman, “CSS on a:visited can load an image and/or reveal if visitor been to a site,” https://bugzilla.mozilla.org/57351.

[28] S. Stamm, B. Sterne, and G. Markham, “Reining in the web with content security policy,” in WWW, 2010, pp. 921–930.

[29] Z. Weinberg, E. Y. Chen, P. R. Jayaraman, and C. Jackson, “I still know what you visited last summer: Leaking browsing history via user interaction and side channel attacks,” in IEEE Symposium on Security and Privacy, 2011, pp. 147–161.

[30] A. Wolman, G. M. Voelker, N. Sharma, N. Cardwell, M. Brown, T. Landray, D. Pinnel, A. R. Karlin, and H. M. Levy, “Organization-based analysis of web-object sharing and caching,” in USENIX Symposium on Internet Technologies and Systems, 1999.

[31] G. Wondracek, T. Holz, E. Kirda, and C. Kruegel, “A practical attack to de-anonymize social network users,” in IEEE Symposium on Security and Privacy, 2010, pp. 223–238.

[32] M. Zalewski, “Postcards from the Post-XSS World,” http://lcamtuf.coredump.cx/postxss/.