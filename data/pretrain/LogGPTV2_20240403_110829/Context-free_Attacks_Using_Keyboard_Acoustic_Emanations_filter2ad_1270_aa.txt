title:Context-free Attacks Using Keyboard Acoustic Emanations
author:Tong Zhu and
Qiang Ma and
Shanfeng Zhang and
Yunhao Liu
Keyboard Acoustic Emanations
Dmitri Asonov
Rakesh Agrawal
IBM Almaden Research Center
650 Harry Road, San Jose, CA 95120, USA
{dasonov,ragrawal}@us.ibm.com
Abstract
on these devices can also be compromised using an attack
based on the sounds produced by clicks.
We show that PC keyboards, notebook keyboards, tele-
phone and ATM pads are vulnerable to attacks based on
differentiating the sound emanated by different keys. Our
attack employs a neural network to recognize the key be-
ing pressed. We also investigate why different keys produce
different sounds and provide hints for the design of homo-
phonic keyboards that would be resistant to this type of at-
tack.
1. Introduction
Emanations produced by electronic devices have long
been a source for attacks on the security of computer sys-
tems. Past attacks have exploited electromagnetic emana-
tions [6] as well as optical emanations [10, 13]. Acous-
tic emanations have also been explored. For example, it is
shown in [7] that the acoustic emanations of matrix print-
ers can carry substantial information about the text being
printed.
We investigate acoustic emanations of a PC keyboard,
the clicks, to eavesdrop upon what is being typed. This at-
tack is based on the hypothesis that the sound of clicks can
differ slightly from key to key, although the clicks of differ-
ent keys sound very similar to the human ear. Our experi-
ments show that a neural network can be trained to differ-
entiate the keys to successfully carry out this attack.
This attack is inexpensive and non-invasive. It is inex-
pensive because in addition to a computer, the only other
hardware required is a parabolic microphone. It is non-
invasive because it does not require physical intrusion into
the system; the sound can be recorded from a substantial
distance. We, therefore, also investigate what can be done
to thwart this attack.
In addition to the PC keyboards, we also study attacks
on notebook computers, touchtone telephones, and ATM
keypads. Our experiments suggest that what is being typed
1.1. Paper Layout
Section 2 presents the details of the attack. We explain
how we extract features from the raw acoustic signal pro-
duced by the click of a key on the PC keyboard. These fea-
tures are then used to train the neural network for differen-
tiating the keys. We ﬁrst show the effectiveness of the at-
tack in distinguishing two keys and then extend the attack
to cover multiple keys.
We show that the differences in typing style have little
impact on the ability of the network to recognize the keys.
This means that the network can be trained on one person
and then used to eavesdrop on another person typing on the
same keyboard. We also show that it is possible to train the
network on one keyboard and then use it to attack another
keyboard of the same type, albeit there is a reduction in the
quality of recognition.
In Section 3, we examine the physical characteristics of
a keyboard that cause the attack to succeed. Speciﬁcally,
we determine why different keys produce different sounds.
These insights provide clues for the design of homophonic
keyboards that would be resistant to this type of attack.
In Section 4, we study the vulnerability of different types
of push button input devices to the proposed attack. We dis-
cuss related work in Section 5 and conclude with a sum-
mary in Section 6.
2. The Attack
The proposed attack is based on the hypothesis that the
sound of clicks might differ slightly from key to key, al-
though the clicks of different keys sound similar to the hu-
man ear. We employ a neural network to classify clicks.
We chose to use neural networks for this task as they have
been successfully used in solving related problems, such as
speaker identiﬁcation [18].
2.1. Experimental Set-up
We ﬁrst specify the equipment and the software used in
our study.
Keyboards. We used several
types of keyboards. Most
of PC keyboard experiments were performed with an
IBM keyboard S/N 0953260, P/N 32P5100. Experi-
ments with multiple keyboards were performed with three
GE Power keyboards HO97798. For experiments with tele-
phones, Siemens RP240 phones (M/N 62001) were used.
Microphones. We used a simple PC microphone for short
distances up to 1 meter and a parabolic microphone for
eavesdropping from a distance.
Computer omnidirection microphone: serial number 33 −
3026 manufactured by RadioShack; frequency response:
30 Hz–15 kHz; impedance: 1000 ohms ±30%; sensitivity:
−68 dB ±3 dB; operating voltage: 1.0 to 10 VDC.
Parabolic microphone: ‘Bionic Booster’ manufactured by
Silver Creek Industries; frequency response 100 Hz–10 kHz
(−3 dB response); gain amp. cut off at 90 dB; overall sys-
tem gain: 40 dB; sensitivity: −46 dB (0 dB = 1 V/Pa).
ADC and FFT. The input was digitized using a standard
PC sound card with 44.1 kHz sampling rate. Sigview soft-
ware v.1.81 was used for recording the sound as well as
for calculating time-FFT on 2 ms windows, with the Han-
ning windowing function applied. Window overlap was not
available.
Neural Network. We used the JavaNNS neural network
simulator [23] to build a backpropagation neural network.
The number of input nodes equaled the size of the feature.
For example, one value per 20 Hz in the FFT requires 200
input nodes for 0–4 kHz interval. There were 6–10 hidden
nodes, depending on the size of the feature and the num-
ber of keys. The number of output nodes equaled the num-
ber of keys in the experiments with multiple keys. One out-
put node was used in the experiments with two keys.
2.2. Training the Neural Network
The raw sound produced by key clicks is not a good in-
put for training a neural network. Neural networks are rec-
ommended to be trained with an input consisting of several
dozens to several hundreds of numeric values between 0 and
1 [19], which corresponds to approximately up to 1 kB in-
put. On the other hand, the size of the acoustic signal corre-
sponding to a keyboard click is about 10 kB. We, therefore,
extract relevant features from the raw sound.
3000
2000
1000
0
-1000
-2000
-3000
-4000
1.46
signal
1.5
1.54
sec
1.58
Figure 1. The acoustic signal of one click.
e
d
u
t
i
n
g
a
M
35
30
25
20
15
10
5
0
(push peak) t=1.49
(silence) t=1.54
(release peak) t=1.58
2000
4000
6000
8000
Hz
Figure 2. Frequency spectrums correspond-
ing to the push peak, a silence interval, and
the release peak.
Figure 3. Time FFT of the signal in Figure 1.
from
ADC
recorded 
signal
Fourier
transform
time
FFT
extract
push 
peaks
FFT @
push peak
normalize
normalized
FFT 
Figure 4. Feature extraction.
kHz
ADCS
0–9 .3–3.4 0–3 1–4 2–5 3–6 4–7 5–8 6–9
1.65 2.70 2.76 3.45 4.36 3.94 5.05 5.94 7.70
Table 1. ADCS value for [0:9] kHz, radio band,
and shifting 3 kHz intervals.
We want the features that enable the neural network to
differentiate between perceptually similar sound samples.
The direct frequency spectrum is known to have signiﬁcant
variation for perceptually similar sounds [8], which makes
it particularly attractive for our application. Interestingly, it
is this same property of the direct frequency spectrum that
causes it not to be used as a feature in the conventional
sound classiﬁcation [8].
We also need to carefully choose the time at which the
spectrum is calculated. For this purpose, an understanding
of how the signal of a click looks like is instructive. As
shown in Figures 1, 2 and 3, the click lasts for approx-
imately 100 ms, and the acoustic signal has two distinct
peaks corresponding to pushing the key and releasing the
key. There is relative silence between the push and release
peaks.
The frequency distribution is best exposed at the peaks.
We calculate the frequency distribution at the time of the
press peak because the release peak is considerably lower.
After calculating the frequency distribution at the press
peak, we normalize the vector so that the values in the spec-
trum fall in the range [0,1] required for a neural network.
Initially, we used the FFT [19] extracted from the 8–
10 ms window of the push peak to serve as the feature. Fur-
ther experimentation, however, led to a reﬁnement. When
zoomed, the push peak can be observed to consist of two
distinct active intervals at the beginning and the end of the
10 ms interval, with relative silence in the middle. These ac-
tive intervals correspond to a ﬁnger touching the key (the
touch peak) and then a ﬁnger and the key hitting the key-
board supporting plate (the hit peak). The keyboard plate
vibrates in both cases. If the FFT is extracted from a 2–3 ms
window corresponding to either of the two active intervals,
the recognition improves by several percentage points. The
reason is that the noise in the middle of the 10 ms inter-
val and on the edges of touch and hit peaks spoil the fea-
ture. The touch peak was expressed much better than the hit
peak in many of the clicks. We, therefore, use touch peaks
to extract features.
Additional details about feature extraction pertain to
frequency intervals that go into the feature. We experi-
mented with features extracted from different intervals. We
recorded the training and the test set for 30 keys on a single
PC keyboard. For each ﬁltered frequency interval, we ex-
tracted the features, retrained the network, ran the network
over the test set, and observed the recognition rate. Table 1
shows ADCS1 for different intervals. We ﬁnd that the best
recognition rate is achieved by including the entire active in-
terval in the feature extraction, whereas relatively short in-
tervals produced poorer results.
Another observation that can be made from the exper-
iments is that higher frequencies are generally less infor-
mative. Of particular interest is the 300–3400 Hz interval –
telephone audio band. The relatively good ADCS for this
interval in our experiments suggests that eavesdropping on
the clicks over the phone, an attack setting proposed in [12],
is potentially possible.
Figure 4 summarizes the sequence of transformations ap-
plied to the raw sound of the click for feature extraction.
It is conceivable to use alternative feature extraction al-
gorithms. For example, one may use cepstrum instead of
raw FFT [19]. As a matter of fact, one can even experiment
with a different type of classiﬁer, such as a support vector
machine or a decision tree [14]. As we will see, the current
setup was adequate to demonstrate the vulnerability of key-
board and push button devices to attacks based on sound
produced from key clicks. It is an interesting topic of future
research to explore if these alternatives can enhance further
the effectiveness of this attack.
2.3. Distinguishing two keys
Before applying the neural network to the task of distin-
guishing two PC keyboard keys based on the clicks pro-
duced by them, we tried to visualize the difference be-
tween the features extracted from the sound produced by
the clicks. We applied various aggregations to the features
produced from the 10 ms window of a push peak for the
two keys, but did not observe signiﬁcant difference visu-
ally. However, features extracted from the 2–3 ms window
of a touch peak are visually distinguishable, even if no ag-
gregation is applied (see Figure 5). Note that the visual dif-
ference between the touch peak spectrums of different keys
differs for different keys.
We next report the neural network results. We chose keys
k and l on a standard QWERTY keyboard for this experi-
ment. This and most of the further experiments included the
following steps:
1. Preparing the {key, feature} pairs for training the neu-
ral network. This step involved recording 100 clicks
of each key and extracting the features. Unless noted
1
The average depth of correct symbol (ADCS) is deﬁned in [11]. This
measure gives the average position of the correct symbol in the or-
dered set returned by the network. ADCS parameter can be inter-
preted as follows. ADCS=1 means a recognition with no errors at all.
ADCS=15 (half of the number of the keys in the experiment) means
there was no information gain and the recognition was completely un-
successful.
1
0.8
0.6
0.4
0.2
e
d
u
t
i
n
g
a
M
0
474
avg. "q"
avg. "w"
1766 3058 4350 5642 6934 8226
frequency (Hz)
Figure 5. Comparison of the normalized aver-
age spectrums (extracted from touch peaks
of the clicks).
s
k
c
i
l
c
f
o
r
e
b
m
u
n
10
8
6
4
2
0
false
correct
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
output of NN
Figure 6. Results of recognizing ten k and ten
l clicks each.
otherwise, the clicks were recorded from a distance of
about 0.5 meter.
2. Training the neural network with the pairs {key, fea-
ture}.
3. Preparing features to test the trained neural network.
This step involved recording a set of test clicks (10
clicks per key) and extracting the features.
4. Testing the neural network. In this step, the neural net-
work was provided with a test feature and the output
of the network was compared with the identity of the
key that was actually pressed.
Figure 6 shows a sample experiment of applying
a trained neural network to recognize 10 clicks pro-
duced by each of the keys k and l. The network recognizes
key pressed
recognized
key pressed
recognized
key pressed
recognized
key pressed
recognized
key pressed
recognized
Keyboard A, ADCS: 1.99
r
w
q