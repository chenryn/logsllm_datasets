title:Cost-Optimization of the IPv4 Zeroconf Protocol
author:Henrik C. Bohnenkamp and
Peter van der Stok and
Holger Hermanns and
Frits W. Vaandrager
Cost-Optimization of the IPv4 Zeroconf Protocol
†
∗
, Peter van der Stok
Henrik Bohnenkamp
, Holger Hermanns
‡,∗
§
, Frits Vaandrager
Dept. of Computer Science, University of Twente, Enschede, The Netherlands. Email: PI:EMAIL
Philips Research Laboratories, Eindhoven, The Netherlands. Email: PI:EMAIL
Dept. of Computer Science, Saarland University, Saarbr¨ucken, Germany. Email: PI:EMAIL
∗
†
‡
§
Nijmeegs Inst. v. Informatica en Informatiekunde, University of Nijmegen, The Netherlands. Email: PI:EMAIL
Abstract
This paper investigates the tradeoff between reliability
and effectiveness for the IPv4 Zeroconf protocol, proposed
by Cheshire/Adoba/Guttman in 2002, dedicated to the self-
conﬁguration of IP network interfaces. We develop a sim-
ple stochastic cost model of the protocol, where reliability
is measured in terms of the probability to avoid an address
collision after conﬁguration, while effectiveness is viewed
as the average penalty perceived by a user. We derive an
analytical expression for the user penalty which we use to
derive optimal conﬁguration parameters of the network, re-
stricting to those parameters which are under the control
of a consumer electronics manufacturer. In particular we
show that minimal cost and maximal reliability are quali-
ties that cannot be achieved at the same time.
1
Introduction
Future generations of consumer electronic products such
as DVD players, microwaves, TV-sets etc., are envisioned
to be connected via a home local network, based on the In-
ternet Protocol (IP) suite. Hand-held devices, laptops and
wearable computers are additionally supposed to be able
to form and communicate over so-called ad-hoc networks.
To enable communication among appliances, each will be
equipped with an IP network interface, making it possible
to connect them as nodes to a network.
A prime requirement for the economical success of these
types of networking is that their initialization and mainte-
nance must rely on at most a minimal degree of user inter-
vention. They must be self-conﬁguring. When integrating a
new appliance into an existing network, the requirement to
be self conﬁgurable is of particular importance. Prior to be-
ing usable inside the network, the interface must be conﬁg-
ured with a unique IP address. One solution to achieve this
assumes a running (usually manually conﬁgured) DHCP
server, which is responsible for attributing IP addresses dy-
namically. This is suboptimal for home networks, due to
the need for manual intervention, and because this solution
is not robust in case of a failure or unplugging of the DHCP
server. In ad-hoc networks, a DHCP server is generally not
even available. The ideal solution is a distributed “plug-and-
play” solution, where the selection of a unique IP number
is taken care of solely by the embedded control software of
the individual appliance to be connected to the net.
In this paper, we study a simple protocol which has
been proposed in the Internet-Draft [2] to perform the above
“plug-and-play” task. This algorithm uses randomization to
automatically conﬁgure an interface with an IPv4 address in
the currently unassigned spectrum of addresses of the net-
work. In the following, we address this protocol as the ze-
roconf protocol.
The major criterion for the assignment of IP numbers
to interfaces is that the chosen IP number must be unique
within a given network context. For ad-hoc networks and
most home networks the network context can be consid-
ered to be link-local, i.e., no routers are present within
the network.1 The Internet Assigned Number Authority
(IANA) has allocated 65024 IP addresses for the purpose
of communication between nodes (called hosts in the se-
quel) on a single link: spanned by the addresses 169.254.1.0
to 169.254.254.255. These IP-numbers are supposed to be
used in a local network only, therefore they are never al-
lowed to be routed.
The basic idea of the zeroconf protocol is easy to explain.
A host that wants to conﬁgure a new IP link-local address
randomly selects an IP address U out of the 65024 available
names. It then broadcasts a message to the network “Who is
using the address U?” We call such a message a probe. If a
probe is received by a host that is already using address U,
it will broadcast a reply indicating that U is in use. Upon
receipt of this reply, the new host will start from scratch:
it randomly selects a new address, broadcasts a new probe,
etc. It may occur that a probe does not arrive due to message
1The link-local network can be connected to other IP nets via one or
more routers, but link-local IP-addresses are not passed over these routers.
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
loss or a busy host, or that a reply gets lost. Therefore, to
increase reliability, a host is required to send n probes, each
time followed by a listening period of a certain length r.
Only when during the total period of n · r seconds no reply
message has been received, a host may start to use its new IP
address. It is important to realize that when a host decides to
use a new link-local IP address after sending four requests,
it may still be possible that some other host in the network
is using the same address, for instance, because all probes
got lost. Such a situation, which is called address collision,
may, in the worst case, force a host to kill active TCP/IP
connections. This is highly undesirable.
The draft [2] suggests to set the length of the listening
period to r = 2 seconds for unreliable (wireless) networks,
and r = 0.2 seconds for reliable ones, but no precise ar-
gument justifying these values is given. The suggestion is
based on assumptions of round-trip delays of the underlying
physical network. Likewise, the number of probe transmis-
sions is set to n = 4, but the inﬂuence of a variation of this
number is not treated.
From a user perspective, it is desirable that the self-
conﬁguration of a device takes a minimal amount of time.
For a hand-held device user, for instance, a conﬁguration
time of 8 seconds may seem barely acceptable, in particu-
lar if in combination with a perceived high risk of breaking
existing connections, caused by address collisions.
On the other hand, decreasing the duration r of the lis-
tening periods may increase the probability of an address
collision, and so does a decrease in the number n of probe
transmissions: while sending less probes takes less time, it
decreases the chance that a host will discover that an IP ad-
dress is already in use. Thus, a trade-off has to be made by
the manufacturer between the goal of reliably assigning a
(locally) unique IP address, and the goal of not disturbing
the user too much. This is the principal issue addressed
in this paper, and we do so by addressing the following
questions: “Is it actually needed to send n = 4 probes?”;
“Are there variations of the protocol which behave equiva-
lently except that conﬁguration takes less time?”; “What is
the probability that an address collision occurs in the initial-
ization phase for a given variation of n and r?”; and “What
is the optimal number of probes for a given scenario?”
The answers to these questions depend on the cost of
having to wait versus the cost of address collisions. As
a particularity of our approach, we treat costs as abstract,
dimension-less entities which provide a common quantita-
tive scale for very different aspects of user (dis)satisfaction
such as experiencing waiting time as well as experiencing
the consequences of an address collision (i.e., broken con-
nections). We model the initialization phase of the protocol
as a stochastic cost model, namely a family of discrete-time
Markov reward models. We provide an analytical evalua-
tion of the model and address the above question based on
our analytical insight. Our model abstracts away from many
details, but allows us to exhibit the trade-off in the protocol
design very clearly. The core of this approach is to ﬁnd (i)
the number of probes n that have maximally to be sent and
(ii) the optimal length r of the waiting period such that the
overall (mean) cost of the protocol is minimal. The model
sets all important parameters and costs in relation to each
other.
The beneﬁts of our approach are the following: ﬁrst, we
can gain insight into the interplay between the different con-
ﬁguration parameters. Moreover, we can derive conﬁgura-
tion parameters for the protocol, depending on the reliabil-
ity of the underlying network technology and the cost of an
address collision. Finally, we are able to assess the sensitiv-
ity of the measures of interest of our model to variations in
the input parameters.
Related Work. In [7], a more detailed model of the zeroconf
protocol is described and analyzed using the model checker
Uppaal [1, 4]. In this work, the emphasis is on what hap-
pens in a setting in which multiple hosts simultaneously re-
quest an IP address. The analysis takes place in a setting of
timed automata and does not take probabilistic aspects into
account.
The rest of the paper is organized as follows. In Sec-
tion 2, we describe the zeroconf protocol in greater detail.
Section 3 introduces the model of the initialization mech-
anism of the protocol, while Section 4 derives an analytic
cost function and evaluates it for speciﬁc scenarios. In Sec-
tion 5 we discuss how the address collision probability can
be obtained from the model. In Section 6 we give a ﬁnal as-
sessment of the protocol parameters chosen for the zeroconf
protocol. Section 7 concludes the paper.
2 The IPv4 zeroconf protocol
This section describes the details of the zeroconf proto-
col as proposed in [2]. The core of the protocol comprises
two parts. The ﬁrst deals with the collision-avoiding as-
signment of an IP address to an interface during initializa-
tion, while the second part deals with the collision detection
and address defense mechanisms during normal operation,
which is a network maintenance task. Since the focus of this
paper is on the initialization phase of the zeroconf protocol,
we will describe only the ﬁrst part.
We consider a fresh host h intending to connect to an ex-
isting IP network. First, the host h selects an IP address U
randomly out of the reserved address space 169.254.1.0 to
169.254.254.255. Before h can use the address to conﬁg-
ure its interface, it must achieve certainty that the address
is not already in use by another host on the same link-local
network. To ﬁnd this out, host h uses the address resolu-
tion protocol (ARP), which is part of the IP suite [5]. The
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
ARP is used to ﬁnd the hardware address of an interface
connected to the link-local network that has been conﬁg-
ured with a given IP address. When an arbitrary host on
the network wants to determine the hardware address of a
given IP address X, it sends out an ARP packet (which is
broadcasted to every interface connected to the local link)
containing X. This ARP packet is, ﬁguratively speaking,
the question “What is the hardware address that belongs to
IP number X?”, addressed to all other hosts on the link.
The host with the interface conﬁgured with address X then
sends a message to the querying host which contains the
hardware address of the interface. If no host is conﬁgured
with address X, there will be no answer.
The ARP mechanism is utilized by the zeroconf proto-
col to determine whether the chosen address U is already in
use. Host h sends out so-called ARP probes. ARP probes
are specially crafted ARP packets containing the randomly
chosen IP number U. The question broadcasted on the net
is then “What is the hardware address that belongs to IP
number U?”. Then, if some host h(cid:1)
has an interface con-
ﬁgured with address U, it broadcasts the hardware address
of its interface. In this case, however, the hardware address
is not of interest, but only the fact that an answer has been
sent. This is a clear indication for h that U is already in use
and should not be used by the newcomer h. Then h must
choose another address randomly and start anew. If, on the
other hand, no answer has been received for U, this indi-
cates that U is not yet in use. The protocol requires that n
ARP probes have to be sent out by h, unless a response to
at least one of them has been received. After each probe, r
seconds have to elapse before the next probe is allowed to
be sent. Consequently, before host h can conﬁgure its inter-
face with an unused IP address, at least n · r seconds have
to pass. [2] sets n = 4 and ﬁxes r ∈ {2, 0.2}.
3 Modeling the zeroconf protocol
3.1 A family of discrete-time Markov reward
models
The model of the zeroconf protocol is expressed in
terms of a family of discrete-time Markov reward models
(DRMs). A Markov reward model is basically a Markov
chain equipped with a reward structure, the latter assigning
rewards, bonuses, or dually costs, to the states and/or transi-
tions of the chain. We consider the cost interpretation here.
We deal with a family of DRMs, since we consider differ-
ent Markov chains for different values of n ∈ {1, 2, 3, . . .},
where n is the number of ARP probes needed to be sent
before a decision of acceptance of the chosen IP address is
made.
In our modeling efforts we focus on a model of a sin-
gle representative host, which is assumed to be freshly con-
nected to the local link. The link itself and all other hosts on
the link are described in an abstract way: by probabilities.
We assume that there are m hosts already connected to the
network, and that, during the process of self-conﬁguration
of the host, other devices are neither added nor removed
from the network, nor trying to acquire a new IP address.
The DRM family we consider is parametric in n, and
its common structure is depicted in Figure 1. Costs are as-
sociated with transitions (given in parentheses in Figure 1;
whenever no costs are indicated they are set to zero). We
will now describe the model and the purpose of the costs in
detail. Common to all of DRM are the states start, er-
“Address unused”
ok
1 − q
“Address erroneously accepted”
(n(r + c))
start
q (r + c)
p2 (r + c)
2nd
p3 (r + c)
3rd
pn (E)
nth
error
p1 (r + c)
1st
1 − p1
1 − p2
1 − p3
1 − pn
Figure 1. Structure of the DRM family
ror, and ok. Moreover, there are states 1st, 2nd, 3rd,
. . . , nth. In the initial state, start, the host randomly se-
lects an IP address from the provided address range. There
are now two possibilities, which we model by two transi-
tions outgoing from start. Either the IP address is already
in use (represented by a transition to state 1st), or the IP
address is not in use yet (represented by a transition to state
ok). The transition to 1st has probability q, the one to ok
1− q. The probability q depends on the number m of IP ad-
dresses in use by other hosts on the net. Assuming that each
host possesses a single IP address we have q = m/65024.
State ok models the case that the chosen address is not
in use yet. The host will then send n ARP probes, as speci-
ﬁed by the protocol. Due to our assumption about the static
nature of the network during the protocol run no host will
send an ARP reply in response to these probes, so after n· r
seconds the host may start using the new IP address. Send-
ing an ARP probe and receiving a reply incurs some cost,
for two reasons. (i) The network is a limited resource and its
use should be accounted for. Therefore, for each ARP probe