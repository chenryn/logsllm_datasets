this happens, recall the microbenchmark trace in §7, in particular
Fig. 10(d). As we can see, if the initial position is off by a fairly
large amount, while the shape of the reconstructed word is rec-
ognizable, the end of the trajectory is enlarged. Intuitively, this is
due to the fact that we end up tracking a wrong grating lobe fur-
ther away from the correct one, whose motion has the same trend
as the correct one yet leads to a larger distortion in the shape as
the RFID moves more. Indeed, in many cases where we observe
244e
t
a
R
s
s
e
c
c
u
S
r
e
t
c
a
r
a
h
C
100%
80%
60%
40%
20%
0%
98.0%
97.6%
97.3%
RF‐IDraw
Antenna 
Arrays
4.2%
3.7%
0.4%
2m
3m
5m
Distance from User to Reader Antennas
Figure 14—Character Recognition Success Rate: RF-IDraw’s
reconstructed trajectories for letters can be correctly recognized in
97.5% of the cases by the handwriting recognition Android app,
whereas the character trajectories reproduced by the antenna array
based system can only be recognized in less than 4% of the cases,
equivalent to a random guess.
a high median trajectory error, it is due to the enlarging of the
shape towards the end of the trace.
9. VIRTUAL TOUCH SCREEN APPLICATION
We use our prototype of RF-IDraw to demonstrate the feasibil-
ity of an RF-based virtual touch screen, which allows a user to
input her commands to a desired computing device (e.g., an An-
droid phone) by writing in the air. In particular, we feed each recon-
structed trajectory as a set of instructions to an Android phone and
the instructions emulate a sequence of touch screen events. Then
we let the handwriting recognition function in the MyScript Stylus
app [36] interpret it as text. We evaluate success rates for recog-
nizing the character and word trajectories as reconstructed by RF-
IDraw and the antenna array based system respectively.
9.1 Character Recognition Success Rates
The average width of a user’s handwritten character is around
10 cm. Fig. 14 shows the success rate of correctly recognizing the
character, as a function of the distance from the user to the reader
antennas. As we can see, the character error rate almost remains the
same at around 97%-98% when the user is 2 m, 3 m, and 5 m away
from the reader antennas. The overall character recognition success
rate for RF-IDraw’s reconstructed trajectory is 97.5%, while the
success rate for the antenna array based scheme is less than 4%.
The following points are worth noting:
• One may be wondering, with the 3–4 cm median trajectory ac-
curacy as shown in Fig. 11(a) and Fig. 11(b), how can the trajec-
tories reconstructed by RF-IDraw be successfully recognized for
characters each of only a few centimeters wide. This is because
the errors on the trajectory are not random errors from point to
point. Instead, they are mostly due to the transform/distortion
(e.g., stretching and squeezing) in the shape of the trajectory,
as opposed to independent positioning errors. For example, the
blue reconstructed trajectory (after removing initial position off-
set) in Fig. 10(e) deviates from the ground truth in the lower part
of letter "c", resulting in trajectory error of a few centimeters. Yet
because it is only a slight distortion instead of random errors, it
does not affect the character recognition. In fact, different users
write the same letter differently, and hence such type of distortion
is naturally taken care of by the handwriting recognition app.
• The errors on the antenna array based scheme’s reconstructed
trajectory are random and incohesive. As a result, they lead to
signiﬁcant errors in recognizing the letters. In fact, even in the
very rare cases where the trajectory is interpreted as the correct
letter, the decision is more like a random guess by the software,
because even a human could not recognize the letter.
100%
95%
94%
91%
90%
88%
RF‐IDraw
80%
60%
40%
20%
e
t
a
R
s
s
e
c
c
u
S
d
r
o
W
0%
Antenna 
Arrays
0%
0%
0%
0%
0%
≥6
2
Number of Characters in the Word
3
4
5
Figure 15—Word Recognition Success Rate: RF-IDraw’s recon-
structed trajectories for words can be correctly recognized in 92%
of the cases by the Android app, enabling an effective virtual touch
screen interface, far exceeding the capability of existing RF-based
positioning system using the same number of antennas. None of the
word trajectories reproduced by the antenna array based scheme is
correctly recognized.
2
1.5
1
)
m
(
z
2
1.5
1
)
m
(
z
0.5
0.5
1
x (m)
1.5
2
0.5
0.5
1
x (m)
1.5
2
(a) RF-IDraw
(b) Antenna Array Based
Scheme
Figure 16—Reconstructed Trajectories of "play" Written 5 m
Away: RF-IDraw’s reconstructed trajectory reproduces all the de-
tails in the user’s writing. The antenna array based scheme’s recon-
structed trajectory is scattered all over the place, due to the antenna
arrays’ low-resolution beams and their high sensitivity to noise.
• Finally, the character recognition success rate of RF-IDraw’s re-
constructed trajectories holds similar for different distances. The
reason for this is that the trajectory error at larger distances in
many cases is due to the enlarging of certain part of the trajec-
tory, which has fairly little effect on the recognition of a letter,
and thus does not affect the recognition success rate.
9.2 Word Recognition Success Rates
Next, we study the success rate of recognizing the reconstructed
trajectories for words. Overall, 92% of the word trajectories recon-
structed by RF-IDraw were correctly recognized by the handwriting
recognition app.
• Fig. 15 shows the word recognition success rate as a function
of the number of characters in the word. It is expected that as
the word gets longer, it is more difﬁcult to recognize it correctly.
Yet the word recognition success rate for RF-IDraw holds above
88% even for words consisting of 6 letters or more. Note that,
the simple Android app that we use has only a basic handwriting
recognition function suitable for a mobile phone. To enable a
larger, full-ﬂedged virtual touch screen, one could use advanced
techniques in natural language processing to improve the success
rate, especially for longer words, the dictionary of which is more
conﬁned and can be leveraged for better inference [40].
• None of the word trajectories reconstructed by the antenna array
based scheme can be recognized correctly, i.e., 0% success rate.
This is not surprising given its low character success rate above.
• Fig. 16 shows the trajectories for the same word "play" written
by a user 5 m away from the reader antennas, as reconstructed by
RF-IDraw and by the antenna array based system respectively.
245While RF-IDraw is able to reconstruct the whole word, the an-
tenna array based scheme’s output fails to form any meaningful
shape, because of its wide beams’ low resolution and high sensi-
tivity to noise.
In summary, using RF-IDraw’s prototype, we enable a ﬁrst-of-
its-kind RF-based virtual touch screen in the air with 97.5% char-
acter recognition success rate and 92% word recognition success
rate, far exceeding the capability of antenna array based technique
with the same number of antennas.
9.3 Discussion
Finally, a few points are worth elaborating on, regarding the ap-
plication of RF-IDraw:
• One could distinguish between two classes of in-the-air user
interfaces. One class is based on a priori deﬁning a few ges-
tures like forward/backward motion [27], then using a machine
learning approach to learn patterns and classify gestures into the
learned categories. The alternative is an interface that is similar
to having a pen for tablets. This interface does not require train-
ing or learning different user’s motions. Yet it can trace a much
richer set of gestures: one can create any command by drawing
or writing, e.g., people can annotate slides in a meeting, draw
icons/signs which would be interpreted by different computing
devices, etc. While classiﬁcation of a limited set of simple ges-
tures may be sufﬁcient for certain applications, we believe many
emerging applications will beneﬁt from an interface that can in-
terpret a rich set of commands and does not rely on training,
which is the approach we adopt in RF-IDraw.
• For applications that require selecting and manipulating items on
a display, one can use RF-IDraw in a manner similar to operat-
ing a mouse to control a cursor on the screen. The user sees the
cursor’s position in real time and will naturally adjust her motion
to reach the desired position based on the visual feedback.
• A limitation of our current implementation of RF-IDraw’s virtual
touch screen is that we manually segment the user’s writing into
words. We believe this can be addressed by using standard seg-
mentation methods [26] in natural language processing, which
would allow us to build a full-ﬂedged virtual touch screen that
can automatically process continuous streams of input.
• Finally, we note that the key idea of using grating lobes in RF-
IDraw is transferable to other RF systems beyond RFID, such
as WiFi and bluetooth. For example, one can potentially imple-
ment RF-IDraw on WiFi access points to trace the trajectories
of nearby cellphones, which is one of our ongoing efforts. We
acknowledge that the operating assumptions, constraints, and re-
quirements of WiFi and bluetooth systems propose new chal-
lenges for applying RF-IDraw, which we plan to explore and ad-
dress in future work.
10. CONCLUSION
This paper presents RF-IDraw, an accurate RFID-based trajec-
tory tracing system that can transform any plane or surface into a
virtual touch screen, allowing a user to interact with a desired com-
puting device by writing her commands in the air. We believe RF-
IDraw opens up a whole new class of applications in gaming and
user interaction interface.
Acknowledgments: We thank Haitham Hassanieh, Fadel Adib, Zach Ka-
belac, the reviewers and our shepherd, Brad Karp for their insightful com-
ments. This research is funded by Lincoln Laboratory and the U.S. Air
Force. We thank the members of the MIT Center for Wireless Networks
and Mobile Computing, including Amazon.com, Cisco, Google, Intel, Me-
diaTek, Microsoft, ST Microelectronics, and Telefonica, for their interest
and support.
11. REFERENCES
[1] AN-900LH 900MHz antenna. rf-links.com/newsite/pdf/an900lh.pdf.
[2] Atacama Large Millimeter/submillimeter Array(ALMA).
alma.mtk.nao.ac.jp/e/aboutalma/.
[3] Google Acquires Indoor/Outdoor Wireless Location Patents.
[4] MonkeyRunner API.
developer.android.com/tools/help/MonkeyRunner.html.
[5] Omni-id exo 800. http://www.omni-id.com/products/.
[6] The corpus of contemporary american english.
www.wordfrequency.info/.
[7] Ubi interactive. www.ubi-interactive.com.
[8] Vicon t-series. www.vicon.com/products/documents/Tseries.pdf.
[9] F. Adib, Z. Kabelac, D. Katabi, and R. C. Miller. 3d tracking via body
radio reﬂections. NSDI, 2014.
[10] F. Adib and D. Katabi. See through walls with WiFi! SIGCOMM’13.
[11] Alien Technology Inc. ALN-9640 Squiggle Inlay.
www.alientechnology.com.
[12] S. Azzouzi et al. New measurement results for the localization of uhf
rﬁd transponders using an angle of arrival (aoa) approach. In IEEE
RFID 2011.
[13] K. Chintalapudi, A. Padmanabha Iyer, and V. N. Padmanabhan.
Indoor localization without the pain. MobiCom ’10.
[14] Cisco. Cisco Announces Acquisition of ThinkSmart.
[15] EPCglobal Inc. EPCglobal Class 1 Generation 2.
[16] Forbes. Microsoft, Motorola, Nokia And RIM To Battle Google Over
Indoor Location Market.
[17] Frost and Sullivan. Breakthrough Innovations in Indoor GPS, 2013.
[18] M. Hawes and W. Liu. Robust sparse antenna array design via
compressive sensing.
[19] K. Joshi, S. Hong, and S. Katti. Pinpoint: Localizing interfering
radios. NSDI, 2013.
[20] C. U. Keller. Interferometers. ATI 2010.
[21] R. Miesen et al. Holographic localization of passive uhf rﬁd
transponders. In IEEE RFID 2011.
[22] P. Nikitin et al. Phase based spatial identiﬁcation of uhf rﬁd tags. In
IEEE RFID 2010.
[23] NOKIA. Accurate Mobile Indoor Positioning Industry Alliance,
called In-Location, to promote deployment of location-based indoor
services and solutions.
[24] S. J. Orfanidis. Electromagnetic Waves and Antennas. Macmillan
Publishing Co., New York, 2010.
[25] P. Pal and P. Vaidyanathan. Coprime sampling and the music
algorithm. 2011.
[26] R. Plamondon and S. N. Srihari. On-line and off-line handwriting
recognition: A comprehensive survey. IEEE Trans. Pattern Anal.
Mach. Intell., 2000.
[27] Q. Pu, S. Gupta, S. Gollakota, and S. Patel. Whole-home gesture
recognition using wireless signals. MobiCom, 2013.
[28] A. Rai, K. K. Chintalapudi, V. N. Padmanabhan, and R. Sen. Zee:
zero-effort crowdsourcing for indoor localization. Mobicom ’12.
[29] M. T. Review. The Indoor Positioning System Era.
[30] SlashGear. Qualcomm Gimbal takes on Apple iBeacon for
Micro-Location.
[31] Z. Tan, Y. Eldar, and A. Nehorai. Direction of arrival estimation using
co-prime arrays: A super resolution viewpoint. 2013.
[32] TED. Free or cheap wii remote hacks.
[33] ThingMagic. Mercury6e rﬁd reader module.
www.thingmagic.com/embedded-rﬁd-readers.
[34] A. R. Thompson, J. M. Moran, and G. W. Swenson. Interferometry
and Synthesis in Radio Astronomy. Wiley-Interscience, 2001.
[35] D. Tse and P. Vishwanath. Fundamentals of Wireless
Communications. Cambridge University Press, 2005.
[36] VisionObjects. Myscript stylus.
www.visionobjects.com/en/myscript/.
[37] J. Wang, F. Adib, R. Knepper, D. Katabi, and D. Rus. Rf-compass:
Robot object manipulation using rﬁds. MobiCom, 2013.
[38] J. Wang, H. Hassanieh, D. Katabi, and P. Indyk. Efﬁcient and reliable
low-power backscatter networks. SIGCOMM, 2012.
[39] J. Wang and D. Katabi. Dude, where’s my card?: Rﬁd positioning
that works with multipath and non-line of sight. SIGCOMM, 2013.
[40] W. Wang, A. Brakensiek, and G. Rigoll. Combination of multiple
classiﬁers for handwritten word recognition. ICFHR’02.
[41] J. Xiong and K. Jamieson. Arraytrack: A ﬁne-grained indoor location
system. NSDI ’13, 2013.
246