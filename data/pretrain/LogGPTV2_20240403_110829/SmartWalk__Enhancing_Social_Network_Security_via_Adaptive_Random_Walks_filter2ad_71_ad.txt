misclassiﬁed as Sybils). In SybilLimit, only random walks
of ﬁxed length are performed, i.e., W = w for all walks,
and the value of w is usually chosen to be the graph mixing
time to ensure a low false postive rate [51], which is unnec-
essarily large for most nodes and only severely degrades the
security performance. Hence, we are interested in apply-
ing adaptive random walks when generating random routes
in SybilLimit. We compare the security/false positive rate
trade-oﬀ when generating random routes based on three dif-
ferent random walks, i.e., ﬁxed-length random walks (nor-
mal random walks), node-adapative random walks and path-
adaptive random walks. We show that among these three
usage models, our node-adaptive and path-adaptive random
walks guarantee stronger system security by decreasing false
negatives for any desired false positive rate.
Evaluation. We use the Facebook wall post dataset in
[34] (with 29,060 nodes and 169,752 edges) and the Twitter
dataset in Table 1 (with 81,306 nodes and 1,342,296 edges).
8 Using two adaptive random walk models, Fig. 6a and Fig.
8The Facebook wall post dataset is an interaction network
Local mixing time0102030405060CDF00.10.20.30.40.50.60.70.80.91ǫ=0.75ǫ=0.5ǫ=0.25Local mixing time050100150200CDF00.10.20.30.40.50.60.70.80.91ǫ=0.75ǫ=0.5ǫ=0.25(a) Facebook wall post
(b) Twitter
(c) Facebook wall post
(d) Twitter
Figure 6: (a) - (b) false negatives per attack edge as a function of ; (c) - (d) false positive rate as a function
of false negatives per attack edge.
6b depict the false negatives per attack edge as a function of
 for the Facebook wall post graph and the Twitter graph,
respectively. Thus, false negatives are tunable by setting
the variation distance parameter  to various values from
0 to 1 (from strong to weak convergence). Also note that
to achieve a certain distance , adaptive models result in a
signiﬁcantly smaller false negatives per attack edge than the
mixing time w = T () used by ﬁxed-length systems. For
instance, in Fig. 6a, at  = 0.25, the false negatives (≈ 15)
are reduced by a factor of 3.7 compared to the mixing time
(≈ 56) in Fig. 5a.
Fig. 6c and Fig. 6d illustrate the false positive rate versus
false negatives per attack edge (E[W ]) using three random
walk models for the Facebook wall post graph and the Twit-
ter graph, respectively. It can be seen that the path-adaptive
random walks achieve the best security/false positive rate
trade-oﬀ among the three, while the node-adaptive random
walks come to be the second best. Speciﬁcally, for the Face-
book wall post graph (Fig. 6c), the false positive rate after
the adoption of path-adaptive walks shows a decline from
1.3% to 0.2% at E[w] = 6 and from 0.2% to 0.015% at
E[W ] = 8,
i.e., the false positive rate is reduced by an
order of magnitude compared to the classical ﬁxed-length
walks (y-axis is in log-scale). In other words, the accuracy
of classifying benign users is considerably improved. For the
Twitter graph, we observe that the false positive rate can be
reduced by up to two orders of magnitude (at false negatives
= 30) using the path-adaptive walks.
We conclude that both path-adaptive and node-adaptive
random walk models outperform the classical ﬁxed-length
model. This is because our adaptive walk algorithms re-
duce the walk length of most nodes to a large extent while
still ensuring that their distance to stationarity is suﬃciently
close. The path-adaptive walk model works better than the
node-adaptive one since it leverages the information of nodes
along the path to further decrease the number of unneces-
sary hops. As discussed above, the path-adaptive random
walk model results in signiﬁcant improvements in accuracy
and security trade-oﬀs (by up to two orders of magnitude).
6.2 Anonymous systems
Anonymous communication systems preserve users’ pri-
vacy by hiding the communication link between the user and
the remote communicating entity. Nagaraja et al. and oth-
and thus implies stronger social ties than the Facebook link
dataset. For the Twitter dataset, we only preserve a link
between two users if they follow each other such that a link
indicates a close relationship between the two users.
ers [37, 34, 12, 15] proposed several anonymous system de-
signs that enhance the security properties by leveraging trust
relationships to select proxies which are more likely to be
honest. The Pisces protocol [34] is a low-latency anonymity
system that leverages social links. Similar to the Tor proto-
col, users in Pisces rely on proxy servers and onion routing
for anonymous communication. Speciﬁcally, the relays in-
volved in the onion routing path are chosen by performing a
random walk on a trusted social network topology. In [34],
the anonymity performance is evaluated based on the Shan-
non entropy, which considers the probability distribution of
nodes being possible initiators as computed by the attackers.
Anonymity/latency trade-oﬀ. Both shannon entropy
and latency are signiﬁcantly inﬂuenced by the length of ran-
dom walks l. Given a node i, as the random walk gets longer,
the node’s entropy increases and eventually converges to
some value (indicating stronger system anonymity), mean-
while the latency gets larger. Since latency is roughly pro-
portional to the walk length, we use the expected random
walk length as the latency metric. In prior works, all ran-
dom walks have the same length. Speciﬁcally, in [34], the
random walk length l is set to a ﬁxed value such that the
expected entropy of a random sample of 5% nodes is above a
threshold. We ﬁrst show that nodes with greater local mix-
ing time usually require a longer random walk to achieve
the same level of anonymity as other nodes. As a result, us-
ing Jain’s fairness index [21], we show that the ﬁxed length
method used in [34] has poor fairness of anonymity due
to its ignorance of a minority of nodes that needs larger l.
Then we demonstrate that using an adaptive length method
instead enhances the fairness for any given expected random
walk length.
Evaluation. We use the Facebook wall post dataset in
[34], along with the Facebook link (Facebook1) and Twit-
ter datasets in Table 1. We rank the nodes according to
their local mixing time in a descending order, and compare
the anonymity (entropy) averaged over the top 5% nodes
(hard nodes), the last 5% nodes (easy nodes) and random
5% nodes, as illustrated in Fig. 7.
It can be seen that
the convergence rate of easy nodes’ anonymity to the upper
bound is much faster than that of hard nodes. However, in a
normal random walk scheme, l is set to be identical for every
node. Note that in social graphs, a majority of nodes are
easy nodes while hard nodes take only a small portion (see
Fig. 5a and Fig. 5b). Consequently, as illustrated in Fig. 7,
the expected anonymity/entropy for a random sample only
reﬂects the behaviour of most easy nodes rather than that
of hard nodes. In Fig. 7a, if we set the threshold as 14, we
0.20.40.60.81ǫ4681012141618false negatives per attack edgenode-adaptive walkpath-adaptive walk0.20.40.60.81ǫ01020304050false negatives per attack edgenode-adaptive walkpath-adaptive walk4681012false negatives per attack edge10-210-1100101102% false positive ratenormal walknode-adaptive walkpath-adaptive walk204060false negatives per attack edge10-210-1100101102% false positive ratenormal walknode-adaptive walkpath-adaptive walk(a) Facebook wall post
(b) Facebook link
(c) Twitter
Figure 7: Anonymity as a function of random walk length.
(a) Facebook wall post
(b) Facebook link
(c) Twitter
Figure 8: CDF of anonymity for the hard nodes.
will choose l = 10 for all nodes, which is in fact insuﬃcient
for over 5% of the nodes (i.e., hard nodes) that need l to
be at least 13. The approach for determining a ﬁxed walk
length based on average anonymity can lead to a more se-
vere anonymity loss for hard nodes in larger social graphs,
as indicated in Fig. 7b and Fig. 7c.
To illustrate the anonymity loss of hard nodes, Fig. 8
depicts the CDF of anonymity over the hard nodes, using
diﬀerent random walk schemes. For the Facebook wall post
graph, in the case of normal random walks, we choose l = 10
based on Fig. 7a so that the expected anonymity reaches 14.
Then about 90% of hard nodes fail to reach 13.5, and their
minimum anonymity even drops to 6. To ensure that more
than 99% nodes meet the threshold requirement, we have
to assign an unnecessarily large value to l (around 20 in
this case), which incurs long latency. For adaptive random
walks 9, we are able to adaptively perform short random
walks for the majority of nodes and relatively long walks
for the rest. Using the prediction algorithm, we can de-
tect the existence of hard nodes. In the Facebook wall post
graph, the necessary walk length is predicted for a set of
diﬀerent ’s. We choose  = 0.65, which produces an av-
erage walk length that is close to the ﬁxed length used in
normal walks, i.e., 10. From Fig. 8a, we can see that af-
ter the adaptive walk model is applied, the percentage of
hard nodes with anonymity greater than 13.5 rises to 90%,
whereas the expected length E[l] is still small (≈ 10). Our
adaptive random walk algorithm also results in a signiﬁcant
increase of the minimum anonymity from 6 to 13. Note
that the entropy metric characterizes the anonymity using a
logarithmic scale; thus an increase of entropy from 6 to 13
results in 2 orders of magnitude larger anonymity set size.
To quantify the fairness of anonymity among nodes, we in-
troduce the Jain’s fairness index [21] given by F(x1, x2, ..., xn) =
9We mainly consider applying node-adaptive random walks
to the anonymous communication systems.
((cid:80)n
n·(cid:80)n
i=1 xi)2
i=1 xi)(xi)2 , which measures the fairness of a set of values
where there are n users with each assigned with the through-
put xi. The fairness metric ranges from 1
n (the worst case)
to 1 (the best case), with the maximum value obtained at the
uniform allocation over all users. In the scenario of anony-
mous communications, we take xi as the anonymity set of
each node vi. Fig. 9 illustrates the fairness versus the aver-
age walk length in two random walk models. We conclude
that the adaptive walk scheme signiﬁcantly strengthens the
anonymity of hard nodes and thus enhances the fairness.
6.3 Link Privacy
Extensive research has been carried out to protect the
privacy of trust relationships between any pair of users (link
privacy) [19, 20, 50, 54, 33, 27]. The challenge of preserving
link privacy lies in causing no signiﬁcant losses on the utility
of applications that leverage the social trust relationships.
Speciﬁcally, link privacy is preserved by adding extra noise
to the local structure of a social network. At the same time,
global structural characteristics are maintained to ensure
that the utility of the social network is not severely reduced.
This can be implemented by replacing a real link between
two users with a fake link generated by a random walk[33].
in [33]
considered that the length of random walks for all nodes
has a ﬁxed value. As the length increases (more noise), the
perturbed social graph converges to a random graph and its
utility declines drastically. Our key insight is that instead of
adding identical amount of noise to all users, perturbation
can be unevenly distributed according to the local mixing
time such that privacy can be protected with less pertur-
bation on average. In other words, we can perform node-
adaptive random walks rather than random walks with a
ﬁxed length for every user when generating fake links.
Link privacy/utility trade-oﬀ. Mittal et al.
To evaluate diﬀerent perturbation algorithms, we use the
deﬁnitions of utility and link privacy in [33], which are based
5101520l (random walk length)051015Anonymityrandom nodeseasy nodeshard nodes5101520l (random walk length)051015Anonymityrandom nodeseasy nodeshard nodes01020304050l (random walk length)051015Anonymityrandom nodeseasy nodeshard nodes51015Anonymity00.20.40.60.81CDFnormal walk, l=10adaptive walk, E[l]≈ 1046810121416Anonymity00.20.40.60.81CDFnormal walk, l=10adaptive walk, E[l]≈ 106810121416Anonymity00.20.40.60.81CDFnormal walk, l=20adaptive walk, E[l]≈ 20(a) Facebook wall post
(b) Facebook link
(c) Twitter
Figure 9: Fairness versus average random walk length.
(a) Link privacy
(b) Mean utility
(c) Max utility
Figure 10: (a) CDF of link privacy; (b) Mean utility and (c) max utility of the perturbed graph G(cid:48) versus
transient random walk length.
on the transition matrices and the Bayesian inference, re-
spectively.
Definition 2. The overall mean utility of a perturbed
(cid:80)
graph G(cid:48) with respect to the original graph G and an ap-
plication parameter l is deﬁned as the mean utility for all
i∈V |πi(0)(P l(G)−
nodes in G, i.e., Umean(G, G(cid:48), l) = 1|V |
P l(G(cid:48)))|1. Similarly, the maximum utility (worst case) of a
perturbed graph G(cid:48) is deﬁned by computing the maximum
of the utility over all nodes in G, i.e., Umax(G, G(cid:48), l) =
maxi∈V {|πi(0)(P l(G) − P l(G(cid:48)))|1}.
Definition 3. The link privacy of a link L is deﬁned as
the probability of the existence of the link in the original
graph G under the assumption that the adversary has ac-
cess to the perturbed graph G(cid:48) and prior information H, i.e.,
LP (L, G(cid:48), H) = Pr[L = 1|G(cid:48), H].
Note that smaller distances indicate higher utility perfor-
mance, and smaller probabilities provide higher privacy pro-
tection. We consider the worst-case link privacy by assuming
that the adversary has the information of the entire original
graph without the link L, i.e., H = G − L.
Evaluation. We use the Facebook link graph. Fig. 10a
illustrates the CDF of link privacy Pr[L|G(cid:48), H] under the
worst case prior H = G− L. From Fig. 10a, we can see that
as the perturbation t gets larger, the percentage of links with
lower link privacy increases, indicating higher privacy. By
making t adaptive to diﬀerent nodes (ranging from 5 to 36
with E(t) ≈ 8), a larger portion of nodes have low probabil-
ities compared to the ﬁxed perturbation algorithm at t = 8,
which indicates that privacy is better preserved. This is be-
cause we make every node get its minimum required pertur-
bation using our adaptive random walk models, which oﬀer
a higher level of privacy for a given expected walk length.
Fig. 10b and Fig. 10c illustrate the mean utility and the
max utility of the perturbed graph G(cid:48) versus the transient
random walk length, respectively. We can see that by mak-
ing t adaptive to diﬀerent nodes (ranging from 5 to 36) with
the average value around 8, the utility degradation is min-
imal compared to t = 8. Combining Fig. 10a, Fig. 10b
and Fig. 10c, our adaptive perturbation algorithms improve
the privacy performance at the cost of slight degradation in
utility.
7. FURTHER DISCUSSION
We leverage supervised machine learning techniques to
predict the local mixing time of a given node, which requires
the knowledge of k-hop neighborhood features. In central-
ized systems where the graph is globally known, features
can be directly computed and the total computation time