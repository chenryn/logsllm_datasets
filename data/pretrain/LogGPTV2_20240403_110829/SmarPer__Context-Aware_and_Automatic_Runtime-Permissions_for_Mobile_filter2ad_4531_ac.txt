permission decisions [8], [30]. Other data sets include runtime
decisions but were collected in non-realistic scenarios
[2],
[10]. Initially, we considered using the data set from Wije-
sekera et al.
[2], as it seemed to match our requirements.
But, we determined it was not appropriate for our goals, as
participants’ decisions were collected ofﬂine during an exit
interview (i.e., the context at request time is different from
the one at decision time), and the number of decisions per
participant is limited (i.e., 10-15 decisions per participant)
for training a machine learning model per participant. Hence,
we decided to conduct a data-collection campaign using our
partial SmarPer implementation and build our own data set.
Besides the technical requirements, a key challenge for our
data-collection was to gather, in a limited period of time,
enough data for our machine learning analysis without over-
whelming users with prompts or causing prompt habituation.
Moreover, the data collected can be very sparse [8], given
the great variety of apps, permissions, and contextual infor-
mation available. Hence, besides the mechanisms described in
Section IV, we also decided to collect decisions from only
a subset of apps and data types. We chose a set of popular
apps from the US Google Play Store that belong to different
categories and make requests for at least one of the following
data types: location, contacts, and storage. By using popular
apps, we increased the chance of (1) collecting more decision-
data from each app during the study (i.e., popular apps are
used more often), and (2) having more than one participant
SmarPer permission prompt. The Weather Channel app
Fig. 2.
requests access to the user’s location. Clicking on the question mark
shows information about the effect of the different decision types.
Below that, we can see the semantic location and decision buttons.
important contextual features. In Section VI, we show a subset
of the most relevant features across all participants.
In
total, we
selected
32
raw features
for
our
machine learning analysis (Section VI):
• App information (6): UID, GID, package name, name,
version, and Google Play Store category.
• Foreground app information (3): package name, name,
and activity.
• Request
information (4): XPrivacy category, method
name, parameters, whether it is dangerous (i.e., denying
it may break the app).
• Decision information (4): type, current time, time to make
the decision, and whether the decision has been modiﬁed
by the user.
• Device status (14): screen in interactive mode, screen
locked, ringer state, headphones plugged, headphone
type, headphones with a mic, battery percent, charging
state, charger type, network connection type, dock state,
latitude, longitude, and location provider.
• Semantic location (1): users are asked to choose a la-
bel for their current geographical location. For usability
purposes, only four labels are used (see Figure 2).
D. Data Collection Considerations
The purpose of our current SmarPer implementation is to
collect at runtime users’ permission decisions (Section V).
We want to collect as many users’ decisions as possible but
not to overwhelm users or cause habituation to the prompts
(Figure 2). Otherwise, we could end up with noisy and unre-
liable data. To address these issues, we added the following
mechanisms to SmarPer:
Prompt rate-limiting: As previous work [2] and our eval-
uation shows, most apps make a large number of requests for
users’ data. Hence, it is not practical to prompt users each
time an app makes a request. To address this problem, we
implemented the following rate-limiting policy for the apps
and data types targeted in our study (Section V). If the user is
using the app (i.e., foreground app), SmarPer does not limit
the number of prompts associated with this app. If the user is
1064
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:19:06 UTC from IEEE Xplore.  Restrictions apply. 
using each app (to facilitate comparisons). This resulted in a
total of 29 apps: Accuweather, Amazon, Candy Crush Soda
Saga, Clash of Clans, Dropbox, Evernote, Facebook, Fitbit,
iHeartRadio, Instagram, Kik, Lyft, Runtastic, Shazam, Skype,
Snapchat, Soundcloud, Star Wars: Galaxy of Heroes, Subway
Surfers, The Weather Channel, TripAdvisor, Twitter, Uber,
Viber, Walmart, Waze, WhatsApp, Wish, and Yelp.
A. Methodology
Here, we describe the steps in our data-collection campaign.
It is important to note that the data collected contains
no personally identiﬁable information of the participants
and that our study was approved by our institution’s IRB
(i.e., ethical committee). In addition, all the data collected
is securely stored and can only be accessed by authorized
researchers from our institution.
1) Recruitment: We recruited remote and local participants
through posts on online forums and ﬂyers on our campus.
Participants were required to be at least 18 years old, be regular
Android users, be regular users of at least two of the apps
selected for our study, and have reliable cellular and WiFi
Internet connectivity. We offered a $50 gift card as a reward.
2) Setup, Training, and Entry Survey: Both local and
remote participants had access to SmarPer’s training material
(e.g., written instructions and video tutorials) hosted in our
server. Before starting the study, participants had to agree
to our consent form and complete an entry survey. In this
survey, we asked participants some demographic questions
and some questions to estimate their general level of privacy
concerns. We made use of the IUIPC scale [43], as well
as some questions of our own design, adapted to the smart-
phone environment. Remote participants used their personal,
SmarPer-compatible smartphones (i.e., rooted Android 4.0.3-
5.x devices). Local participants had the option of using their
personal devices or using a smartphone provided by us,
notably Motorola Moto G 2nd or 3rd generation devices with
Android 4.4.5. In the latter case, to guarantee normal use
patterns, local participants met with one of our researchers
to set up the loaned device: transfer the participant’s SIM
card and data, and install the participant’s apps. We also asked
participants to treat the loaned smartphones as their personal
devices. This step is thus similar to the one followed by
Wijesekera et al. [2]. In total, we loaned smartphones to 29
participants. We also explained to participants the functioning
of SmarPer, in particular, the effect that the three decision
types have on the targeted data types and their purpose, i.e.,
data minimization.
It is possible that our SmarPer training inﬂuenced partici-
pants towards a more privacy-preserving behavior. Such bias
is difﬁcult to avoid when evaluating a privacy mechanism
with real users. We cannot properly evaluate SmarPer without
ﬁrst explaining concepts such as permission prompts and data
obfuscation. Nevertheless, such bias is unlikely to affect our
analysis, as our goal is not to estimate if SmarPer makes
participants more privacy-conscious. Instead, our goal is to
model participants’ unique privacy preferences when prompted
for permissions in different contexts (even if there is a bias)
and their attitudes towards obfuscation. Our scenario is similar
to the one of runtime permission-prompts in Android 6+ and
iOS, where users are explained ﬁrst how permission prompts
work and their purpose.
3) Data-collection: Participants agreed to run SmarPer on
their personal or loaned smartphones for at least 10 days. Dur-
ing that period, SmarPer prompted participants for permission
decisions (Figure 2) associated with our selected apps and
data types. The goal was to collect at least 75 decisions per
participant and the contextual information associated with each
decision. If this targeted number of decisions was not reached
after 10 days, participants were encouraged to continue the
study for some additional time until it was reached (to avoid
bias, we did not explicitly ask participants for more decisions).
Every day, the decision data was automatically uploaded to
our server over an encrypted connection. Hence, we were also
able to monitor for problems with SmarPer or if users were not
actively using the smartphone. In the latter case, we contacted
the participants to remind them about the rules.
4) Static Policies and Exit Surveys: At
the end of the
data-collection, all participants were required to complete
two additional surveys. In the static policy survey, for each
app monitored during the study, we asked the participant to
deﬁne what static decision (i.e., allow, obfuscate, deny) they
would grant to access each of the monitored data types (i.e.,
location, contacts, storage). The purpose of this survey is
to capture how participants would conﬁgure permissions on
their personal smartphones by using the interface provided by
current permission systems (e.g., Android 6+). The data from
this survey was used as a baseline in our analysis (Section VI).
In the exit survey, we asked participants about their experi-
ence with SmarPer and their aptitudes towards using automatic
decisions, data obfuscation, and contextual
information in
mobile permissions. We conducted supplementary interviews
with selected participants to better understand the reasons
for their decisions during the study. After completing both
surveys and passing the data consistency check (described
next), participants were rewarded with a gift card.
5) Data Quality: We performed different checks to validate
the quality of the data submitted by participants. First, we
checked that participants did not respond to prompts too
rapidly, i.e., at least two seconds elapsed before they chose
their response. The fact that participants had to touch the
screen twice per prompt (Figure 2) reduced the chances of
quick random decisions. Second, we checked the consistency
of the semantic locations reported by the participants, by
comparing the semantic labels with the actual coordinates
recorded at decision time. For example, if a participant re-
ported “home” in two or more geographical locations, it is
likely that the participant provided false information. No users
violated the above conditions signiﬁcantly enough to warrant
being removed from the study. Third, for each participant, we
removed the ﬁrst and last ﬁve decisions from the data set, as
they were made during the familiarization with SmarPer and
when participants returned the loaned devices, i.e., noisy data.
1065
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:19:06 UTC from IEEE Xplore.  Restrictions apply. 
s
n
o
i
s
i
c
e
d
f
o
r
e
b
m
u
N
 600
 550
 500
 450
 400
 350
 300
 250
 200
 150
 100
 50
 0
Allow
Obfuscate
Deny
D C C 
A3F 
A68 
F6B 
221 
08C 
A EE 
FE7 
B D1 
393 
232 
263 
A87 
37F 
0D2 
68C 
B35 
573 
B62 
354 
84B 
6D0 
FD1 
D69 
39E 
023 
0C6 
82B 
66A 
A72 
E14 
20A 
4B0 
004 
B D A 
D42 
FFF 
710 
Participant identifier
E8C 
31B 
020 
Fig. 3. Total number of decisions per participant, including the distribution of the decision types. The difference in the number of decisions
is mostly due to the participant’s behavior, number and type of apps used, and days in the study.
6) Data Preprocessing: We converted some of the raw con-
textual features (Section IV-C) before our machine learning
analysis (Section VI). First, categorical features (e.g., app
name and category) were converted into dummy features [44],
because techniques, such as linear regression, do not work
directly with categorical features. These dummy variables
take the value 0 or 1 to indicate the absence or presence of
some categorical effect. Second, we computed ﬁve additional
features based on the raw features collected: whether an app
is in the foreground, day of week, part of day (i.e., morning,
afternoon, evening, night), battery charge percentage, and
day/month/year. We ended up with a total of 37 features.
B. Data Set Details
A total of 47 participants joined our data-collection cam-
paign; 41 completed it successfully. Overall, we collected
around 4.82 million apps’ requests for private information. Of
these, we prompted participants for 8,521 manual permission
decisions. The rest corresponds to requests associated with
apps and data types outside the scope of our study.
1) Demographics: From the 41 participants that completed
the study: 17 (41%) were female; 29 (71%) were in the 18–25
range and 12 (29%) were in the 26–50 range; 12 (29.3%) were
undergraduate students, 23 (56.1%) were graduate students,
3 (7.3%) worked in scientiﬁc services, 1 (2.4%) worked in
education, 1 was unemployed, and 1 did not disclose their
occupation. Participants reported being active smartphones
users (1-3 hours/day) and long-term Android users (2-5 years).
In the entry survey, participants scored high on a 5-
point IUIPC scale for control, awareness, and collection of
private information. These results indicate that most of our
participants have a high level of privacy concern. Participants
reported high concern regarding apps accessing their contacts,
camera, or storage. Surprisingly, participants were less con-
cerned about apps accessing their location.
2) Exploratory Analysis: In our ﬁnal data set, allow, obfus-
cate, and deny account for 42%, 27%, and 31% of the total
number of decisions, respectively, thus showing a balanced
distribution of decision types. Figure 3 shows the total number
of permission decisions per user, including the distribution
of decision types. Participants chose for contacts: 65% allow,
24% obfuscate, and 11% deny; for location: 25% allow, 27%
obfuscate, and 48% deny, and for storage: 35% allow, 31%
obfuscate and 34% deny. We conclude that participants are
more likely to allow contacts and deny location requests. These
results contradict the concern levels reported by participants
in the entry survey (Section V-B1), where they stated to be
more concerned about apps accessing their contacts than their
location (i.e., “privacy paradox” [45]).
In Figure 3 we also notice that some participants were
signiﬁcantly more active than others. This difference is due
mainly to the participant’s individual behavior, the number and
type of apps used, and the number of days in the study (66%
of the participants completed the data collection in less than
15 days). Participants were prompted a median of 17.3 times
per day and each prompt was completed in a few seconds.
These numbers show the effectiveness of our rate-limiting
mechanisms (Section IV-D). For comparison, participants in
[10] were prompted at least 10 times a day and each prompt
required 2-5 minutes to complete. We observe that the distribu-
tion of decision types varies considerably across participants,
indicating the unique privacy preferences of each user and
hinting at the difﬁculty of predicting permission decisions.
Figure 4 shows this difference more clearly by depicting the
initial, middle, and last 12 decisions of a subset of participants.
We observe that the distributions are reasonably stable over
time per participant, especially after some initial period where
some participants changed their preferences. Participants are
vertically grouped according to their privacy proﬁle: utility-
concerned (top), somewhat-privacy-concerned (middle), and
privacy-concerned (bottom).
1066
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:19:06 UTC from IEEE Xplore.  Restrictions apply. 
Allow
Obfuscate
Deny