)
It
is
reasonable
) (cid:1) Pr(pw
] (cid:1) Pr(pwjpw
′
generality, assume Ak is a type-2 PII. First,
Pr(pw; pw
; Ak) = Pr(pw; Akjpw
′
= Pr[(Akjpw)jpw
Pr(Akjpw). Consequently, we have:
′
Pr(pwjpw
)
Pr(pw; Ak; pw
Pr(pw′; Ak)
Pr[(Akjpw)jpw
] (cid:1) Pr(pwjpw
′
Pr(pw′; Ak)
; Ak) =
to
′
′
(1)
′
′
′
′
′
′
′
;
)
; pw).
)= Pr(pw
; Ak) on the probability of event (pw
=
(cid:25) Pr(pwjpw
′
) is called the “prior” in Bayesian theory, the
; Ak) represents the impact
) (cid:1) Pr(Akjpw) (cid:1) Pr(pw
Pr(pw′; Ak)
′
; Ak) can be fully computed:
′
) can be computed using TarGuess-II; (2) Pr(pw
where Pr(pwjpw
factor Pr(Akjpw) (cid:1) Pr(pw
of (pw
As a result, Pr(pwjpw
(1)
Pr(pwjpw
; Ak)
= c1 is a constant, because the event (pw
; Ak) is a known and
ﬁxed fact when we attack U, and the ordering of guesses do not
need the exact value of c1; (3) Pr(pw
)=c2 is, similarly, a constant
is a known and ﬁxed fact when we attack U;
since the event pw
and (4) Pr(Akjpw) can be computed by counting the training
set—the password pw is selected by what fraction of users that are
with an attribute Ak. When the training data is sufﬁciently large
(e.g., >106), Pr(Akjpw) can be obtained by direct counting.
Otherwise, smoothing techniques (e.g., Laplace and Good-Turing)
shall be used to overcome the sparsity issue to assure accuracy.
We note that some PII attributes are inherently dependent be-
tween each other (e.g., birthday vs. age, and ﬁrst name vs. gender).
Fortunately, since the majority of PII attributes (see Table 1) are
mutually independent, the practicality of Theorem 1 will not be
′
′
′
affected much. This is especially true when many attributes are
simultaneously exploited. We observe that, even if TarGuess-III
only employs birthday and TarGuess-IV employs one more PII
(i.e., age), TarGuess-IV still performs better than TarGuess-III by
now only adjusting the non-birthday-involved guesses using Eq. 1.
As shown in Fig. 12, by exploiting an additional PII (i.e., gen-
der), TarGuess-IV can achieve improvements over TarGuess-III
by 4.38%(cid:24)18.19% within 10(cid:24)103 guesses, reaching a success
rate of 24.51% with 102 guesses and 30.66% with 103 guesses,
respectively. This indicates that type-2 PII, which, as far as we
know, has never been considered in the literature of password
cracking, is indeed valuable for A.
4.5 Dealing with other attacking scenarios
As mentioned in Table 2, seven scenarios can be resulted from
the various combinations of the 3 types of personal info that we
focus in this work. This means that, beyond the four most represen-
tative scenarios #1(cid:24)#4 that we have considered above, three other
ones remain: #5 (type-2 PII), #6 (type-1 PII + type-2 PII) and #7 (1
sister PW + type-2 PII). Besides, there are scenarios involving 2+
sister PWs: #8 (2+sister PWs) and #9 (2+sister PWs+some PII).
When Ak is a type-2 PII, it is natural to derive from Eq. 1 that:
(2)
where Pr(Ak) = c3 is a constant, and both Pr(pw) and
Pr(Akjpw) can be obtained by counting the training set, as
discussed in Sec. 4.4. Eq. 2 well addresses Scenarios #5.
Pr(pwjAk) (cid:25) Pr(pw) (cid:1) Pr(Ak|pw)
Pr(Ak)
;
To tackle Scenario #6, we need to develop a new formulation.
∏
i=1 Pr(pw|Ai)
Pr(pw)n−1
n
From Theorem 1, we can derive that
;
Pr(pwjA1; A2;(cid:1)(cid:1)(cid:1) ; An) =
(3)
where Pr(pwjAi) can be obtained by using TarGuess-I when Ai is
a type-1 PII, or be obtained by using Eq. 2 when Ai is a type-2 PII.
This addresses Scenario #6.
As our Theorem 1 is suitable for both type-1 and type-2 PII,
Scenario #7 can be readily tackled by ﬁrst using TarGuess-II to
generate a list of guesses and then adjusting the probabilities of the
guesses according to Eq. 1.
Scenarios #8 and #9 cannot be readily addressed using the mod-
els proposed above. A simple approach to tackle them is to employ
our TarGuess in a repeated manner, yet this is not optimal and we
leave these two scenarios for future work. Still, as we have shown
in Sec. 2, only a marginal fraction of users have leaked two or more
passwords, and thus these two scenarios are far less common than
the seven targeted guessing scenarios we have addressed.
Summary. We have designed a series of sound probabilistic mod-
els for targeted online guessing, with each characterizing one of the
seven types of attacking scenarios. Our TarGuess-I and II signiﬁ-
cantly outperform the related algorithms [12, 20], while TarGuess-
III and IV, for the ﬁrst time, tackle the realistic issues of combining
users’ leaked passwords and PII to facilitate online guessing. Based
on TarGuess-I(cid:24)IV, we further show how to address the three re-
maining scenarios. Extensive experiments in the following section
further demonstrate the effectiveness of our TarGuess-I(cid:24)IV.
5. EXPERIMENTS
evaluate TarGuess-I(cid:24)IV with ﬁve leading algorithms.
5.1 Experiment setup
We now describe our experimental setups and comparatively
Among the nine algorithms to be evaluated, three (i.e., Markov
[21], PCFG [35] and Trawling optimal [6]) only need some training
passwords, four (i.e., Das et al.’s algorithm [12], TarGuess-II(cid:24)IV)
work on password pairs of the same user, and four (i.e., Personal-
PCFG [20], TarGuess-I, III and IV) involve various types of user
PII-12306
Training set(s), with policy and language consistent with the test set
Table 11: Training and test settings for each attacking scenario under 9 algorithms(Tra. opt.=Trawling optimal)†
∗
Tra. opt. Personal-PCFG TarGuess-I
Dodo
PII-12306
8+PII-Dodo
CSDN 8+PII-Dodo
8+PII-Dodo
CSDN 8+PII-Dodo
PII-Dodo
CSDN PII-Dodo
PII-Dodo
PII-Dodo
12306
Dodo
PII-12306
PII-12306
PII-Rootkit
PII-Rootkit
Yahoo
Experimental
scenario
(size; service)
PCFG
#1: 12306!Dodo
49,775; Dodo
126
#2: 12306!CSDN
8+Dodo
12,635; CSDN
#3: Dodo!CSDN
8+Dodo
5,997; CSDN
#4: Dodo!12306
49,775; 12306
Dodo
#5: CSDN!12306
12,635; 12306
Dodo
#6: CSDN!Dodo
5,997; Dodo
126
#7: Rootkit!Yahoo
214; Yahoo
Rockyou
#8: Rootkit!000web L+D Rockyou L+D Rockyou 000web L+D PII-Rootkit L+D PII-Rootkit L+D Rockyou Rootkit, L+D Xato Rootkit, L+D PII-Xato 2,949; 000web
#9: 000web!Rootkit Rockyou
2,949; Rootkit
#10: Yahoo!Rootkit Rockyou
214; Rootkit
Dodo=Dodonew; 000web=000webhost; 8+=len(cid:21)8; PII-X=the PII-associated list X; L+D=Passwords with both letters and digits.
†
A ! B means that: (1) for the four password-reuse-based algorithms (i.e., Das et al.’s algorithm [12], TarGuess-II(cid:24)IV), a user U’s password at service A can be used by A to
∗
help attack U’s account at service B; and (2) for the other ﬁve algorithms, U’s password at A is not involved, and only U’s password at B is used as the target. Note that, every
user’s passwords in both A and B now have been associated with PII (see Tables 12 and 13) to facilitate the four PII-based algorithms.
zWhen training TarGuess-II(cid:24)IV, U’s one sister password comes from the 1st dataset, and A uses it to guess U’s password from the 2nd dataset.
TarGuess-III, IV
12306, PII-126
12306, 8+PII-Dodo
Dodo, 8+PII-12306
PII-Dodo, 126
CSDN, PII-Dodo
CSDN, PII-126
Rootkit, PII-Xato
‡
TarGuess-II
12306, 126
12306, 8+Dodo
Dodo, 8+126
Dodo, 126
CSDN, Dodo
CSDN, 126
Rootkit, Xato
Das et al.
126
8+Dodo
8+Dodo
Dodo
Dodo
126
Rockyou
Markov
126
8+Dodo
8+Dodo
Dodo
Dodo
126
Rockyou
Rootkit PII-Xato
Rootkit PII-Xato
000web, PII-Xato
Yahoo, PII-Xato
000web, Xato
Yahoo, Xato
Rockyou
Rockyou
Rockyou
Rockyou
PII-Xato
PII-Xato
Test set
‡
personal info. However, only two of our original datasets (i.e.,
12306 and Rootkit) are associated with PII (see Table 3). Thus,
as mentioned in Sec. 3.4, we build PII-Dodonew with size 161,510
by matching Dodonew with 51job and 12306 using email address,
and PII-000webhost with size 2,950 by matching 000webhost with
Rootkit. Matching by email ensures that all our PII-associated En-
glish passwords are created by Rootkit hackers, who well represent
security-savvy users. Since Rockyou does not contain email or user
name, we further match Xato with Rootkit to obtain 15,304 PII-
associated Xato passwords to supplement Rockyou.
As shown in Table 12, we further build three lists of password
pairs for Chinese users by matching Dodonew and CSDN with the
two PII-associated Chinese password lists using email address. For
instance, the list Dodonew$12306 has a total of 49,775 password
pairs, of which 14,380 pairs are with non-identical passwords. Sim-
ilarly, we build three lists of password pairs for English users (see
Table 13), but eliminate one of them (i.e., Yahoo$000webhost)
because the limited size of test set (i.e., 96) would make it impossi-
ble to reﬂect the true nature of an algorithm. These ﬁve pair-wised
lists lead to ten experimental scenarios in Table 11.
Table 12: Basic information of the matched Chinese datasets
PII-12306(129,303)
Original
dataset
Total Non-identical(%)
Dodonew 49,775 14,380 (28.89%)
CSDN
5,538 (43.83%)
12,635