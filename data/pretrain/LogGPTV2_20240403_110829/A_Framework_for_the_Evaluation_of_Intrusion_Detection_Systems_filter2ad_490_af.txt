Note that in this case, p is bounded in such a way that
the equilibrium of the game is achieved via a pure strat-
egy. In fact, the optimal strategy of the intruder is to attack
with frequency ˆp + δu (and of course, generate missed de-
tections with probability β and false alarms with probability
α) whereas the optimal strategy of DM is to ﬁnd the point
in ROCα,β that minimizes the expected cost by assuming
that the base-rate is ˆp + δu.
The optimal point for the ROCα,β curve corresponds
to the one with threshold 799, having an expected cost
Eδ,α,β[C(I, A)] = 5.19 × 10
−2. Finally, by using the opti-
mal point for ROCα,β, as opposed to the original one, we
get during operation an expected cost of Eoperation[C(I, A)] =
2.73× 10
−2. Therefore in this case, not only we have main-
−2 − security of the evalu-
tained our expected 5.19 × 10
ation, but in addition the new optimal point actually per-
formed better than the original one.
Notice that the evaluation of Figure 10 relates exactly to
the problem we presented in the introduction, because it can
be thought of as the evaluation of two IDSs. One IDS hav-
ing a buffer threshold of length 399 and another IDS having
a buffer threshold of length 773. Under ideal conditions we
choose the IDS of buffer threshold length of 399 since it has
a lower expected cost. However after evaluating the worst
possible behavior of the IDSs we decide to select the one
with buffer threshold length of 773.
An alternative view can be achieved by the use of IDOC
curves. In Figure 11(a) we see the original IDOC curve dur-
ing the evaluation period. These curves give a false sense of
conﬁdence in the IDS. Therefore we study the IDOC curves
based on ROCα,β in Figure 11(b). In Figure 11(c) we can
see how the IDOC of the actual operating environment fol-
lows more closely the IDOC based on ROCα,β than the orig-
inal one.
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:52:29 UTC from IEEE Xplore.  Restrictions apply. 
1
0.9
0.8
0.7
0.6
D
P
0.5
0.4
0.3
0.2
0.1
0
0
Evaluation
p=1×10−4
p=1×10−3
p=1×10−6
p=1×10−5
p=1×10−2
0.2
0.4
0.6
Pr[I=1|A=1]
0.8
1
(a) Original IDOC obtained during the evaluation
period
Intruder
α,β
During operation
1
0.9
0.8
0.7
0.6
D
P
0.5
0.4
0.3
0.2
0.1
0
0
p=1×10−5
p=1×10−6
p=1×10−4
p=1×10−3
p=1×10−2
0.2
0.4
0.6
Pr[I=1|A=1]
0.8
1
(b) IDOC obtained from ROCα,β
1
0.9
0.8
0.7
0.6
D
P
0.5
p=1×10−5
p=1×10−3
p=1×10−2
p=1×10−4
0.4
0.3
0.2
0.1
0
0
p=1×10−6
0.2
0.4
0.6
Pr[I=1|A=1]
0.8
1
(c) IDOC during operation time
Figure 11. Robust IDOC evaluation
6. Conclusions and Future Work
There are two main problems that any empirical test of
an IDS will face. The ﬁrst problem relates to the inferences
that once can make about any IDS system based on experi-
ments alone. An example is the low conﬁdence on the esti-
mate for the probability of detection in the ROC. A typical
way to improve this estimate in other classiﬁcation tasks is
through the use of error bars in the ROC. However, since
tests of IDSs include very few attacks and their variations,
there is not enough data to provide an accurate signiﬁcance
level for the bars. Furthermore, the use of error bars and any
other cross-validation technique gives the average perfor-
mance of the classiﬁer. However, this brings us to the sec-
ond problem, and it is the fact that since the IDSs are subject
to an adversarial environment, evaluating an IDS based on
its average performance is not enough. Our intruder model
tries to address these two problems, since it provides a prin-
cipled approach to give us the worst case performance of a
detector.
The extent by which the analysis with a (δ,α,β) −
intruder will follow the real operation of the IDS will de-
pend on how accurately the person doing the evaluation of
the IDS understands the IDS and its environment, for ex-
ample, to what extent can the IDS be evaded, how well
the signatures are written (e.g. how likely is it that normal
events ﬁre alarms) etc. However, by assuming robust pa-
rameters we are actually assuming a pessimistic setting, and
if this pessimistic scenario never happens, we might be op-
erating at a suboptimal point (i.e. we might have been too
pessimistic in the evaluation).
Finally we note that IDOC curves are a general method
not only applicable to IDSs but to any classiﬁcation algo-
rithm whose classes are heavily imbalanced (very small or
very large p). We plan to propose their use in other ﬁelds as
a general alternative to ROCs for these type of classiﬁcation
problems. In particular, we point out that another choice
for the x-axis on an IDOC curve is to select 1 − Pr[I =
1|A = 1] = Pr[I = 0|A = 1], instead of Pr[I = 1|A = 1].
This can be done in order to mimic the ROC evaluation,
since Pr[I = 0|A = 1] intuitively represents the Bayesian
false alarm rate. That is, the x-axis would then represent
the probability that the IDS operator will not ﬁnd an in-
trusion when he investigates an alarm report (informally, it
would represent the waste of time for the operator of the
IDS). The ﬁnal decision on which x-axis to use will depend
on the personal interpretation of the user.
References
[1] The MIT lincoln labs evaluation data set, DARPA
at
intrusion
http://www.ll.mit.edu/IST/ideval/index.html.
Available
detection
evaluation.
[2] Software for empirical evaluation of IDSs. Available at
http://www.cshcn.umd.edu/research/IDSanalyzer.
[3] S. Axelsson. The base-rate fallacy and its implications for
the difﬁculty of intrusion detection. In Proceedings of the
6th ACM Conference on Computer and Communications Se-
curity (CCS ’99), pages 1–7, November 1999.
[4] S. Buchegger and J.-Y. Le Boudec. Nodes bearing grudges:
Towards routing security, fairness, and robustness in mo-
bile ad hoc networks.
In Proceedings of Tenth Euromicro
PDP (Parallel, Distributed and Network-based Processing),
pages 403 – 410, Gran Canaria, January 2002.
[5] T. M. Cover and J. A. Thomas. Elements of Information
Theory. John Wiley & Sons, Inc, 1991.
[6] G. Di Crescenzo, A. Ghosh, and R. Talpade. Towards a the-
ory of intrusion detection. In ESORICS 2005, 10th European
Symposium on Research in Computer Security, pages 267–
286, Milan, Italy, September 12-14 2005. Lecture Notes in
Computer Science 3679 Springer.
[7] E. Eskin, A. Arnold, M. Prerau, L. Portnoy, and S. Stolfo. A
geometric framework for unsupervised anomaly detection:
Detecting intrusions in unlabeled data.
In D. Barbara and
S. Jajodia, editors, Data Mining for Security Applications.
Kluwer, 2002.
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:52:29 UTC from IEEE Xplore.  Restrictions apply. 
[8] S. Forrest, S. Hofmeyr, A. Somayaji, and T. A. Longstaff. A
sense of self for unix processes. In Proceedigns of the 1996
IEEE Symposium on Security & Privacy, pages 120–12,
Oakland, CA, USA, 1996. IEEE Computer Society Press.
[9] J. E. Gaffney and J. W. Ulvila. Evaluation of intrusion de-
tectors: A decision theory approach. In Proceedings of the
2001 IEEE Symposium on Security and Privacy, pages 50–
61, Oakland, CA, USA, 2001.
[10] G. Gu, P. Fogla, D. Dagon, W. Lee, and B. Skoric. Measur-
ing intrusion detection capability: An information-theoretic
approach.
In Proceedings of ACM Symposium on Infor-
mAtion, Computer and Communications Security (ASIACCS
’06), Taipei, Taiwan, March 2006.
[11] H. Handley, C. Kreibich, and V. Paxson. Network intru-
sion detection: Evasion, trafﬁc normalization, and end-to-
end protocol semantics. In 10th USENIX Security Sympo-
sium, 2001.
[12] J. Jung, V. Paxson, A. Berger, and H. Balakrishnan. Fast
portscan detection using sequential hypothesis testing.
In
IEEE Symposium on Security & Privacy, pages 211–225,
Oakland, CA, USA, 2004.
[13] C. Kruegel, E. Kirda, D. Mutz, W. Robertson, and G. Vi-
gna. Automating mimicry attacks using static binary anal-
ysis. In Proceedings of the 2005 USENIX Security Sympo-
sium, pages 161–176, Baltimore, MD, August 2005.
[14] C. Kruegel, D. Mutz, W. Robertson, and F. Valeur. Bayesian
event classiﬁcation for intrusion detection. In Proceedings of
the 19th Annual Computer Security Applications Conference
(ACSAC), pages 14–24, December 2003.
[15] C. Kruegel, D. Mutz, W. Robertson, G. Vigna, and R. Kem-
merer. Reverse Engineering of Network Signatures. In Pro-
ceedings of the AusCERT Asia Paciﬁc Information Technol-
ogy Security Conference, Gold Coast, Australia, May 2005.
[16] W. Lee and S. J. Stolfo. Data mining approaches for intru-
sion detection. In Proceedings of the 7th USENIX Security
Symposium, 1998.
[17] W. Lee, S. J. Stolfo, and K. Mok. A data mining framework
for building intrusion detection models. In Proceedings of
the IEEE Symposium on Security & Privacy, pages 120–132,
Oakland, CA, USA, 1999.
[18] R. P. Lippmann, D. J. Fried,
I. Graf, J. W. Haines,
K. R. Kendall, D. McClung, D. Weber, S. E. Webster,
D. Wyschogrod, R. K. Cunningham, and M. A. Zissman.
Evaluating intrusion detection systems: The 1998 DARPA
off-line intrusion detection evaluation.
In DARPA Infor-
mation Survivability Conference and Exposition, volume 2,
pages 12–26, January 2000.
[19] D. J. Marchette. A statistical method for proﬁling network
In USENIX Workshop on Intrusion Detection and
trafﬁc.
Network Monitoring, pages 119–128, 1999.
[20] S. Marti, T. J. Giuli, K. Lai, and M. Baker. Mitigating rout-
ing misbehavior in mobile ad hoc networks. In Proceedings
of the 6th annual international conference on Mobile com-
puting and networking, pages 255–265. ACM Press, 2000.
[21] A. Martin, G. Doddington, T. Kamm, M. Ordowski, and
M. Przybocki. The DET curve in assessment of detec-
tion task performance. In Proceedings of the 5th European
Conference on Speech Communication and Technology (Eu-
rospeech’97), pages 1895–1898, Rhodes, Greece, 1997.
[22] J. McHugh. Testing intrusion detection systems: A critique
of the 1998 and 1999 DARPA intrusion detection system
evaluations as performed by the Lincoln laboratory. ACM
Transactions on Information and System Security (TISSEC),
3(4):262–294, November 2000.
[23] H. V. Poor. An Introduction to Signal Detection and Estima-
tion. Springer-Verlag, 2nd edition edition, 1988.
[24] F. Provost and T. Fawcett. Robust classiﬁcation for im-
precise environments. Machine Learning, 42(3):203–231,
March 2001.
[25] T. H. Ptacek and T. N. Newsham. Insertion, evasion and de-
nial of service: Eluding network intrusion detection. Tech-
nical report, Secure Networks, Inc., January 1998.
[26] M. Schonlau, W. DuMouchel, W.-H. Ju, A. F. Karr,
M. Theus, and Y. Vardi. Computer intrusion: Detecting mas-
querades. Technical Report 95, National Institute of Statis-
tical Sciences, 1999.
[27] U. Shankar and V. Paxson. Active mapping: Resisting NIDS
evasion without altering trafﬁc. In Proceedings of the 2003
IEEE Symposium on Security & Privacy, pages 44–61, Oak-
land, CA, USA, 2003.
[28] S. Stolfo, W. Fan, W. Lee, A. Prodromidis, and P. Chan.
Cost-based modeling for fraud and intrusion detection: Re-
sults from the JAM project.
In Proceedings of the 2000
DARPA Information Survivability Conference and Exposi-
tion, pages 130–144, January 2000.
[29] K. Tan, K. Killourchy, and R. Maxion. Undermining an
anomaly-based intrusion detection system using common
exploits.
In Proceeedings of the 5th International Sym-
posium on Recent Advances in Intrusion Detection (RAID
2002), pages 54–73, Zurich, Switzerland, October 2002.
[30] K. Tan, J. McHugh, and K. Killourhy. Hiding intrusions:
From the abnormal to the normal and beyond. In Informa-
tion Hiding: 5th International Workshop, pages 1–17, No-
ordwijkerhout, The Netherlands, October 2002.
[31] H. L. Van Trees. Detection, Estimation and Modulation The-
ory, Part I. Wiley, New York, 1968.
[32] G. Vigna, S. Gwalani, K. Srinivasan, E. Belding-Royer, and
R. Kemmerer. An Intrusion Detection Tool for AODV-based
Ad Hoc Wireless Networks.
In Proceedings of the An-
nual Computer Security Applications Conference (ACSAC),
pages 16–27, Tucson, AZ, December 2004.
[33] G. Vigna, W. Robertson, and D. Balzarotti.
Testing
Network-based Intrusion Detection Signatures Using Mu-
tant Exploits.
In Proceedings of the ACM Conference on
Computer and Communication Security (ACM CCS), pages
21–30, Washington, DC, October 2004.
[34] D. Wagner and P. Soto. Mimicry attacks on host-based intru-
sion detection systems. In Proceedings of the 9th ACM Con-
ference on Computer and Communications Security (CCS),
pages 255–264, Washington D.C., USA, 2002.
[35] C. Warrender, S. Forrest, and B. Pearlmutter. Detecting in-
trusions using system calls: Alternative data models. In Pro-
ceedings of the 1999 IEEE Symposium on Security & Pri-
vacy, pages 133–145, Oakland, CA, USA, May 1999.
[36] Y. Zhang, W. Lee, and Y. Huang. Intrusion detection tech-
niques for mobile wireless networks. ACM/Kluwer Mo-
bile Networks and Applications (MONET), 9(5):545–556,
September 2003.
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:52:29 UTC from IEEE Xplore.  Restrictions apply.