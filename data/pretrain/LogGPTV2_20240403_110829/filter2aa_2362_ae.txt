are announced, let’s take a close look at the nature of vulnerabilities in software.
Vulnerabilities have many interesting aspects that could be studied, such as the level
of exploitability and the mode of exploitability. But one categorization is the most
important—the accessibility of the vulnerability. Software vulnerabilities have secu-
6
Introduction
4Vulnerability disclosure publications and discussion tracking, maintained by University of Oulu
since 2001. Available at www.ee.oulu.fi/research/ouspg/sage/disclosure-tracking
rity implications only when they are accessible through external interfaces, as well
as when triggers can be identified and are repeatable.
Fuzzing enables software testers, developers, and researchers to easily find vul-
nerabilities that can be triggered by malformed or malicious inputs via standard
interfaces. This means that fuzzing is able to cover the most exposed and critical
attack surfaces in a system relatively well. Attack surface has several meanings,
depending on what is analyzed. To some, attack surface means the source code fin-
gerprint that can be accessed through externally accessible interfaces. This is where
either remote or local users interact with applications, like loading a document into
a word processor, or checking email from a remote mail server. From a system test-
ing standpoint, the total attack surface of a system can comprise all of the individ-
ual external interfaces it provides. It can consist of various network components,
various operating systems and platforms running on those devices, and finally, all
client applications and services.
Interfaces where privilege changes occur are of particular interest. For example,
network data is unprivileged, but the code that parses the network traffic on a server
always runs with some privilege on its host computer. If an attack is possible through
that network-enabled interface—for example, due to a vulnerability in message pars-
ing code—an unprivileged remote user could gain access to the computer doing the
parsing. As a result, the attacker will elevate its privileges into those of the compro-
mised process. Privilege elevation can also happen from lower privileges into higher
privileges on the same host without involving any network interfaces.
An example of fuzzing remote network-enabled attack surfaces would be to
send malformed web requests to a web server, or to create malformed video files for
viewing in a media player application. Currently, dozens of commercial and free
fuzz testing frameworks and fuzz-data generators of highly varying testing capabil-
ity exist. Some are oriented toward testing only one or a few interfaces with a spe-
cialized and predefined rule set, while some are open frameworks for creating fuzz
tests for any structured data. The quality of tests can vary depending on the com-
plexity of the interface and the fuzzing algorithms used. Simple tools can prove very
good at testing simple interfaces, for which complex tools could be too time-
consuming or expensive. On the other hand, a complex interface can only be tested
thoroughly with a more capable fuzzing system.
The various routes into a system, whether they are remote or local, are called
attack vectors. A local vector means that an attacker already has access to the sys-
tem to be able to launch the attack. For instance, the attacker may possess a user-
name and password, with which he or she can log into the system locally or
remotely. Another option is to have access to the local user interface of the system.
Note that some user interfaces are realized over the network, meaning that they are
not local. The attacker can also have access to a physical device interface such as a
USB port or floppy drive. As an example, a local attack vector can consist of any of
the following:
1. Graphical User Interface (GUI);
2. Command Line User Interface (CLI);
3. Programming Interfaces (API);
4. Files;
1.1
Software Security
7
5. Local network loops (RPC, Unix sockets or pipes, etc.);
6. Physical hardware access.
Much more interesting interfaces are those that are accessible remotely. Those
are what fuzzing has traditionally focused on. Note that many local interfaces can
also be accessed remotely through active content (ActiveX, JavaScript, Flash) and
by fooling people into activating malicious content (media files, executables).
Most common categories of remote interfaces that fuzzers test are displayed in
Figure 1.2.
1. Web applications: Web forms are still the most common attack vector.
Almost 50% of all publicly reported vulnerabilities are related to various
packaged or tailored web applications. Almost all of those vulnerabilities
have been discovered using various forms of fuzzing.
2. Digital media: File formats are transferred as payloads over the network,
e.g., downloaded over the web or sent via email. There are both open source
and commercial fuzzers available for almost any imaginable file format.
Many fuzzers include simple web servers or other tools to automatically
send the malicious payloads over the network, whereas other file fuzzers
are completely local. Interesting targets for file fuzzers are various media
gateways that cache, proxy, and/or convert various media formats, anti-
virus software that has to be able to separate valid file contents from mal-
ware, and, of course, various widely used operating system components
such as graphics libraries or metadata indexing services.
3. Network protocols: Standardization organizations such as IETF and 3GPP
have specified hundreds of communication protocols that are used every-
where in the world. A network protocol fuzzer can be made to test both
client- and server-side implementations of the protocol. A simple router on
the network can depend on dozens of publicly open protocol interfaces, all
of which are extremely security critical due to the requirement of the router
being available for any remote requests or responses.
4. Wireless infrastructure: All wireless networks are always open. Fuzzing has
been used to discover critical flaws in Bluetooth and 802.11 WLAN (WiFi)
implementations, for example, with these discoveries later emerging as
sophisticated attack tools capable of exploiting wireless devices several
miles away. Wireless devices are almost always embedded, and a flaw
found in a wireless device has the potential of resulting in a total corrup-
8
Introduction
Figure 1.2
Categories of remote attack vectors in most network-enabled systems.
tion of the device. For example, a flaw in an embedded device such as a
Bluetooth-enabled phone can totally corrupt the memory of the device
with no means of recovery.
Fuzzers are already available for well over one hundred different attack vectors,
and more are emerging constantly. The hottest trends in fuzzing seem to be related
to communication interfaces that have just recently been developed. One reason for
that could be that those technologies are most immature, and therefore security
flaws are easy to find in them. Some very interesting technologies for fuzzers include
• Next Generation Networks (Triple-Play) such as VoIP and IPTV;
• IPv6 and related protocols;
• Wireless technologies such as WiFi, WiMAX, Bluetooth, and RFID;
• Industrial networks (SCADA);
• Vehicle Area Networks such as CAN and MOST.
We will not list all the various protocols related to these technologies here, but
if you are interested in finding out which protocols are the most critical ones for
you, we recommend running a port scanner5 against your systems, and using net-
work analyzers6 to monitor the actual data being sent between various devices in
your network.
1.1.4
Reasons Behind Security Mistakes
Clearly, having security vulnerabilities in software is a “bad thing.” If we can
define the attack surface and places where privilege can be elevated, why can’t we
simply make the code secure? The core reason is that the fast evolution of com-
munications technologies has made software overwhelmingly complex. Even the
developers of the software may not understand all of the dependencies in the com-
munication infrastructure. Integration into off-the-shelf platforms and operating
systems brings along with it unnecessary network services that should be shut
down or secured before deploying the products and services. Past experience has
shown that all complex communication software is vulnerable to security inci-
dents: The more complex a device is, the more vulnerable it usually proves in prac-
tice. For example, some security solutions are brought in to increase security, but
they may instead enable new vulnerabilities due to their complexity. If a thousand
lines of code have on average between two to ten critical defects, a product with
millions of lines of code can easily contain thousands of flaws just waiting to be
found. For secure solutions, look for simple solutions over complex ones, and min-
imize the feature sets instead of adding anything unnecessary. Everything that is
not used by majority of the users can probably be removed completely or shut
down by default. If you cannot do that or do not want to do that, you have to test
(fuzz) that particular feature very thoroughly.
1.1
Software Security
9
5One good free port scanner is NMAP. Available at http://insecure.org/nmap
6A popular network analyzer is Wireshark. Available at www.wireshark.org
Standardization and harmonization of communications have their benefits, but
there is also a downside to them. A standardized homogeneous infrastructure can
be secure if all possible best practices are in place. But when security deployment is
lacking in any way, such an environment can be disrupted with one single flaw in
one single standard communication interface. Viruses and worms often target
widely deployed homogeneous infrastructures. Examples of such environments
include e-mail, web, and VoIP. A unified infrastructure is good from a security
point of view only if it is deployed and maintained correctly. Most people never
update the software in their mobile phones. Think about it! Some people do not
even know if they can update the software on their VoIP phones. If you do not want
to update all those devices every week, it might be beneficial to try to fuzz them,
and maybe fix several flaws in one fell swoop.
Open, interconnected wireless networks pose new opportunities for vulnerabil-
ities. In a wireless environment, anyone can attack anyone or anything. Wireless is
by definition always open, no matter what authentication and encryption mecha-
nisms are in place. For most flaws that are found with fuzzing in the wireless
domain, authentication is only done after the attack has already succeeded. This is
because in order to attempt authentication or encryption, input from an untrusted
source must be processed. In most cases the first message being sent or received in
wireless communications is completely anonymous and unauthenticated. If you do
not need wireless, do not use it. If you need to have it open, review the real opera-
tion of that wireless device and at minimum test the handling of pre-authentication
messages using fuzzing.
Mobility will increase the probability of vulnerabilities, but also will make it eas-
ier to attack those devices. Mobile devices with complex communication software
are everywhere, and they often exist in an untrusted environment. Mobility will also
enable anonymity of users and devices. Persons behind security attacks cannot be
tracked reliably. If you have a critical service, it might be safer to ask everyone to
authenticate himself or herself in a secure fashion. At minimum, anything that can
be accessed anonymously has to be thoroughly tested for vulnerabilities.
1.1.5
Proactive Security
For an enterprise user, there are typically two different measures available for pro-
tecting against security incidents: reactive and proactive. The main difference
between reactive security measures and proactive security measures is who is in
control of the process. In reactive measures, you react to external events and keep
running around putting fires out. In proactive security measures, you take a step
back and start looking at the system through the eyes of a hacker. Again, a hacker
in this sense is not necessarily a criminal. A hacker is a person who, upon hearing
about a new technology or a product, will start having doubts on the marketing
terms and specifications and will automatically take a proactive mindset into ana-
lyzing various technologies. Why? How? What if? These are just some of the ques-
tions someone with this mindset will start to pose to the system.
Let us take a look at the marketing terms for proactive security from various
commercial fuzzer companies:
10
Introduction
XXX enables companies to preemptively mitigate unknown and published threats
in products and services prior to release or deployment—before systems are
exposed, outages occur, and zero-day attacks strike.
By using YYY, both product developers and end users can proactively verify secu-
rity readiness before products are purchased, upgraded, and certainly before they
are deployed into production environments.
In short, proactive, pre-deployment, or pre-emptive software security equals to
catching vulnerabilities earlier in the software development life cycle (SDLC), and
catching also those flaws that have not been disclosed publicly, which traditional
reactive security measures cannot detect. Most traditional security solutions
attempt to detect and block attacks, as opposed to discovering the underlying vul-
nerabilities that these attacks target (Figure 1.3).
A post-deployment, reactive solution depends on other people to ask the ques-
tions critical for security. An example of a reactive solution is a signature based
anti-virus system. After a new virus emerges, researchers at the security vendor start
poking at it, trying to figure out what makes it tick. After they have analyzed the new
virus, they will make protective measures, trying to detect and eliminate the virus
in the network or at a host computer. Another example of a reactive solution is an
Intrusion Detection System (IDS) or an Intrusion Prevention System (IPS). These
systems look for known exploits and block them. They do not attempt to identify
which systems are vulnerable or what vulnerabilities exist in software. One could
argue that even a firewall is reactive solution, although the pace of development is
much slower. A firewall protects against known attacks by filtering communica-
tion attempts at the perimeter. The common thread with most post-deployment
security solutions is that they all target “attacks,” and not “vulnerabilities.” They
are doomed to fail because of that significant difference. Every time there is a
unique vulnerability discovered, there will be hundreds, if not thousands of attack
variants trying to exploit that worm-sized hole. Each time a new attack emerges, the
retroactive security vendors will rush to analyze it and deploy new fingerprints to
their detection engines. But based on studies, unfortunately they only detect less
than 70% of attacks, and are often between 30 and 60 days late.7
1.1
Software Security
11
Figure 1.3
Reactive post-deployment versus proactive pre-deployment security measures.
7“Anti-Virus Is Dead; Long Live Anti-Malware.” Published by Yankee Group. Jan. 17, 2007.
www.marketresearch.com/map/prod/1424773.html
One could argue that security scanners (or vulnerability scanners) are also
proactive security tools. However, security scanners are still mostly based on
known attacks and exhibit the same problems as other reactive security solutions.
A security scanner cannot find a specific vulnerability unless the vulnerability is
publicly known. And when a vulnerability becomes known, attacks usually already
exist in the wild exploiting it. That does not sound very proactive, does it? You
still depend on someone else making the decisions for you, and in their analyzing
and protecting your assets. Security scanners also look for known issues in stan-
dard operating systems and widely used hosts, as data on known vulnerabilities is
only available for those platforms. Most tests in security scanners are based on
passive probing and fingerprinting, although they can contain active hostile tests
(real exploits) for selected known issues. Security scanners cannot find any un-
known issues, and they need regular updating of threats. Security scanners also
rarely support scanning anything but very popular operating systems and selected
network equipment.
An additional recent problem that is becoming more and more challenging for
reactive security solutions that depend on public disclosure is that they do not know
the problems (vulnerabilities) anymore. This is because the “public disclosure
movement” has finally died down. However, raising awareness about security mis-
takes can only be a good thing. Public disclosure is fading because very few people
actually benefit from it. Manufacturers and software developers do not want to pub-
lish the details of vulnerabilities, and therefore today we may not know if they have
fixed the problems or not. Hackers do not want to publish the details, as they can
sell them for profit. Corporate enterprise customers definitely do not want to pub-
lish any vulnerability details, as they are the ones who will get damaged by any
attacks leading to compromises. The only ones who publish details are security
companies trying to make you believe they actually have something valuable to
offer. Usually, this is just bad and irresponsible marketing, because they are getting
mostly second-hand, used vulnerabilities that have already been discovered by var-
ious other parties and exploited in the wild.
A proactive solution will look for vulnerabilities and try to resolve them before
anyone else learns of them and before any attacks take place. As we said, many
enterprise security measures fail because they are focused on known attacks. A truly
proactive approach should focus on fixing the actual flaws (unknown zero-day vul-
nerabilities) that enable these attacks. An attack will not work if there is no under-
lying vulnerability to exploit. Vulnerability databases indicate that programming
errors cause 80% of vulnerabilities, so the main focus of security solutions should
probably be in that category of flaws. Based on research conducted at the PROTOS
project and also according to our experience at commercial fuzzing companies, 80%
of software will crash when tested via fuzzing. That means we can find and eliminate
many of those flaws with fuzzing, if we spend the effort in deploying fuzzing.
1.1.6
Security Requirements
We have discussed fuzzing and its uses, but the truth is not all software is security-
critical, and not all software needs fuzzing. Just as is the case with all security meas-
ures, introducing fuzzing into development or deployment processes needs to be
12
Introduction
based on the requirement set for the system. Unfortunately, traditional security
requirements are feature-driven and do not really strike a chord with fuzzing.
Typical and perhaps the most common subset of security requirements or secu-
rity goals consists of the following: confidentiality, integrity, and availability.
Fuzzing directly focuses on only one of these, namely availability, although many
vulnerabilities found using fuzzing can also compromise confidentiality and integrity
by allowing an attacker to execute malicious code on the system. Furthermore, the
tests used in fuzzing can result in corrupted databases, or even in parts of the mem-
ory being sent back to the fuzzer, which also constitute attacks against confidential-
ity and integrity.
Fuzzing is much closer to the practices seen in quality assurance than those
related to traditional security requirements. This may have been one of the main
reasons why fuzzing has not been widely adopted so far in software engineering
processes: Security people have mostly driven its deployment. Without solid
requirements to fulfill, you only end up with a new tool with no apparent need for
it. The result is that your expensive fuzzer equipment ends up just collecting dust in
some far-away test lab.
1.2
Software Quality
Thrill to the excitement of the chase! Stalk bugs with care, methodology, and rea-
son. Build traps for them. . . . Testers! Break that software (as you must) and drive
it to the ultimate—but don’t enjoy the programmer’s pain.
Boris Beizer8
People who are not familiar with testing processes might think that the purpose of
testing is to find flaws. And the more flaws found, the better the testing process is.
Maybe this was the case a long time ago, but today things are different. Modern
testing is mostly focused on two things: verification and validation (V&V).
Although both terms are used ambiguously, there is an intended difference.
Verification attempts to answer the question: “Did we build the product right?”
Verification is more focused on the methods (and in the existence of these methods),
such as checklists, general process guidelines, industry best practices, and regula-
tions. Techniques in verification ensure that the development, and especially the qual-
ity assurance process, is correct and will result in reduction of common mistakes.
Validation, on the other hand, asks: “Did we build the right product?” The
focus is on ensuring and documenting the essential requirements for the product
and in building the tests that will check those requirements. For any successful val-
idation testing, one needs to proactively define and document clear pass/fail crite-
ria for all functionality so that eventually when the tests are done, the test verdicts
can be issued based on something that has been agreed upon beforehand.
Unfortunately, fuzzing does not fit well into this V&V model, as we will see
here, and later in more detail in Chapter 3.
1.2
Software Quality
13
8Quote is from Software Testing Techniques, 2nd ed., Boris Beizer, International Thomson Com-
puter Press. 1990. Abbreviated for brevity.
Testing is a time-consuming process that has been optimized over time at the
same time that software has become more complex. With increasing complexity,
devising a completely thorough set of tests has become practically impossible. Soft-
ware development with a typical waterfall model and its variants—such as the iter-
ative development process—proceed in phases from initial requirements through
specification, design, and implementation, finally reaching the testing and post-
deployment phases. These phases are rarely completely sequential in real-life devel-
opment, but run in parallel and can revisit earlier steps. They can also run in cycles,
such as in the spiral model. Due to this, the requirements that drive testing are
drafted very early in the development process and change constantly. This is
extremely true for various agile processes, where test requirements may be only
rarely written down due to the fast change process.
If we look at fuzzing from a quality assurance perspective, fuzzing is a branch
of testing; testing is a branch of quality control; quality control is a branch of qual-
ity assurance. Fuzzing differs from other testing methods in that it