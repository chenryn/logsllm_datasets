title:Extract Me If You Can: Abusing PDF Parsers in Malware Detectors
author:Curtis Carmony and
Xunchao Hu and
Heng Yin and
Abhishek Vasisht Bhaskar and
Mu Zhang
Extract Me If You Can:
Abusing PDF Parsers in Malware Detectors
Curtis Carmony
Syracuse University
PI:EMAIL
PI:EMAIL
PI:EMAIL
NEC Laboratories America
Syracuse University
Mu Zhang
Xunchao Hu
Abhishek Vasisht Bhaskar
Heng Yin
Syracuse University
PI:EMAIL
Syracuse University
PI:EMAIL
Abstract—Owing to the popularity of the PDF format and the
continued exploitation of Adobe Reader, the detection of malicious
PDFs remains a concern. All existing detection techniques rely
on the PDF parser to a certain extent, while the complexity of
the PDF format leaves an abundant space for parser confusion.
To quantify the difference between these parsers and Adobe
Reader, we create a reference JavaScript extractor by directly
tapping into Adobe Reader at locations identiﬁed through a
mostly automatic binary analysis technique. By comparing the
output of this reference extractor against that of several open-
source JavaScript extractors on a large data set obtained from
VirusTotal, we are able to identify hundreds of samples which
existing extractors fail to extract JavaScript from. By analyzing
these samples we are able to identify several weaknesses in each
of these extractors. Based on these lessons, we apply several
obfuscations on a malicious PDF sample, which can successfully
evade all the malware detectors tested. We call this evasion
technique a PDF parser confusion attack. Lastly, we demonstrate
that the reference JavaScript extractor improves the accuracy of
existing JavaScript-based classiﬁers and how it can be used to
mitigate these parser limitations in a real-world setting.
I.
INTRODUCTION
Even though Adobe’s Acrobat Reader, more commonly
known as Adobe Reader, has become increasingly secure
through the addition of advanced security mechanisms such as
a sandbox [5], new exploits continue to be found with 44 CVEs
published in 2014 [1] and 128 published in 2015 at the time of
writing [2]. Due to the continued exploitation of Adobe Reader
along with the ubiquity of the PDF format,
the detection
of malicious PDF ﬁles remains a concern, with Kaspersky
reporting that Adobe Reader was the third most exploited target
in 2014 and attracted 5% of the overall attacks [18].
Malicious PDF detection in commercial anti-virus products
relies heavily on signature detection and is insufﬁcient to detect
PDFs containing zero-day exploits or advanced persistent
threats. To address this limitation, two classes of systems have
been proposed to detect malicious PDF ﬁles speciﬁcally: 1)
structure and metadata based detectors [29], [32], [38] and 2)
JavaScript-based classiﬁers [23], [25], [37], [26].
Permission to freely reproduce all or part of this paper for noncommercial
purposes is granted provided that copies bear this notice and the full citation
on the ﬁrst page. Reproduction for commercial purposes is strictly prohibited
without the prior written consent of the Internet Society, the ﬁrst-named author
(for reproduction of an entire paper only), and the author’s employer if the
paper was prepared within the scope of employment.
NDSS ’16, 21-24 February 2016, San Diego, CA, USA
Copyright 2016 Internet Society, ISBN 1-891562-41-X
http://dx.doi.org/10.14722/ndss.2016.23483
Structure and metadata based detection methods distinguish
benign and malicious PDFs by determining which structural
features and metadata are most associated with each class.
However, the essential malice of PDF exploits does not orig-
inate in ﬁle structures but rather in embedded payloads (e.g.,
JavaScript code) that bear malicious intent. Therefore, these
detectors can be easily evaded by the mimicry attack [39],
[38] and the reverse mimicry attack [28], which hide harmful
code in PDF ﬁles that exhibit structural features and metadata
associated with benign ﬁles.
To fundamentally address PDF exploits, it is necessary to
analyze the contents of documents and search for malicious
payloads. Prior work [23] reveals that JavaScript is the most
common malicious content in PDF exploits for two major
reasons: 1) the implementation of the Adobe JavaScript APIs
exposes vulnerabilities and 2) JavaScript code is used to en-
able advanced exploitation techniques, such as heap spraying.
Almost all of the malicious PDF documents in our sample set
collected from VirusTotal contain JavaScript, indicating that
the extraction and analysis of embedded JavaScript is essential
to malicious PDF detection.
To this end, prior JavaScript-based classiﬁers [23], [25],
[37] have attempted to parse PDF documents, extract
JavaScript from them, and then analyze this JavaScript to
classify it as benign or malicious. These works all depend
on their ability to accurately extract JavaScript from PDFs.
With the exception of MPScan[26], which uses a modiﬁed
version of Adobe Reader similar to the one presented in this
work, each of these works rely either on open-source parsers
or their own home-grown parsers. Because all of these parsers
are incomplete and have oversimpliﬁed assumptions in regards
to where JavaScript can be embedded, these detection methods
are not accurate or robust.
In this paper, we aim to conduct a systematic study on
a new evasion technique called the PDF parser confusion
attack, which aims to confuse the PDF parsers in malware
detectors in order to evade detection. In essence, this evasion
attack exempliﬁes the chameleon and werewolf attacks that
deliberately abuse ﬁle processing in malware detectors [22].
However, compared to other ﬁle types (e.g., ZIP, ELF and
PE) that have been investigated in this previous work, the
combination of the complexity of the PDF format and Adobe
Reader’s leniency in parsing these ﬁles potentially offers a
much larger attack space. Unfortunately, this attack space has
not been studied sufﬁciently in the security community.
To enable a systematic study we have developed a reference
JavaScript extractor by directly tapping into Adobe Reader,
which is arguably the most popular and most targeted PDF
viewer [19]. To develop this reference extractor, we present a
mostly automatic dynamic binary analysis technique that can
quickly identify a small number of candidate tap points, which
can be further reﬁned by simple manual analysis. We then
perform a differential analysis on this reference extractor and
several popular extractors, using over 160,000 PDFs collected
from VirusTotal. For each extractor we identify hundreds of
samples which it cannot correctly process, but that contain
JavaScript according to the reference extractor.
By delving into these discrepancies between the reference
extractor and the existing extractors we have identiﬁed several
new obfuscations, and further quantiﬁed their impact when
used in parser-confusion attacks on JavaScript extractors and
malware detectors. By combining several of these obfusca-
tions, we demonstrate that a malicious PDF can successfully
evade all the malware detectors evaluated, including signature-
based, structure/metadata-based, and JavaScript-based detec-
tors.
These ﬁndings suggest that the key to effective countermea-
sures is a high-ﬁdelity parser that closely mimics the parsing
logic of Adobe Reader. One possible solution is to directly
deploy our reference JavaScript extractor for JavaScript-based
detectors. Our experiment shows that this deployment scheme
not only incurs acceptable runtime overhead, but also produces
much higher detection accuracy. Our experiments show that
after replacing the original parser with our reference extractor,
the detection rate of PJScan [23] increases from 68% to 96%
for a speciﬁc version of Adobe Reader, based on a fairly
rudimentary classiﬁer.
Paper Contributions. In summary,
following contributions:
this paper makes the
• We propose a mostly-automatic, platform independent
tap point identiﬁcation technique to correctly identify
tap points related to JavaScript parsing and execution
in Adobe Reader which are used to develop a reference
JavaScript extractor.
•
Using our reference extractor we systematically evalu-
ate the shortcomings of existing JavaScript extraction
tools. We have identiﬁed hundreds of PDF samples
(both benign and malicious), which existing extractors
failed to extract JavaScript from. We manually inves-
tigate many of them, and identify their root causes.
• We construct several PDF parser confusion attacks by
combining several of the obfuscations identiﬁed in our
analysis. These evasions have proved to be effective
in successfully evading all of the malware detectors
we tested.
• We discuss several mitigation techniques. In particular,
we demonstrate that with our reference JavaScript
extractor, the detection rate of an existing classiﬁer
increases signiﬁcantly from 68% to 96% on our sam-
ple set, and present a possible deployment scenario
for the reference extractor.
We plan to release the complete data set and also launch
a public service for our reference JavaScript extractor, to help
security researchers conduct further research on this problem.
A list of MD5 hash values are available for part of the data
set and can be found at https://goo.gl/qtbuOC.
II. BACKGROUND
A. Metadata and Structural Features Based Detection
Since signature-based malicious PDF detectors [31] are
susceptible to various conventional malware polymorphism
techniques [16], [17], [34], efforts have been made to ﬁnd
more robust malicious PDF detection methods. Based off of the
observation that malicious ﬁles usually have little or no content
aside from their payloads, and that benign ﬁles usually have
an extensive set of diverse contents, several systems have been
presented to quantify these structural differences to facilitate
malicious PDF detection and classiﬁcation.
PDF Malware Slayer [29] uses the PDF keywords identiﬁed
in a sample by the popular PDFiD tool [35] as a feature set
which they use to train a random forests PDF classiﬁer. The
primary limitation of this system lies in its use of the PFDiD
tool which merely performs simple string matching to identify
the existence of a subset of PDF keywords, and therefore
cannot recognize strings encoded by a ﬁlter or differentiate the
strings in the document structure from those in its contents.
PDFrate [32] similarly uses a random forests classiﬁer, but
utilizes a much more descriptive feature set. It parses PDF ﬁles
to retrieve 202 different structural aspects of a sample such as
the number and types of objects in the ﬁle, their size, aspects
of their contents, pages in the document, and the size of the
ﬁle. Again, this work is largely limited by its parser, a program
developed by the authors which utilizes regular expressions to
extract these features which cannot decode encoded streams in
the ﬁle or parse their contents.
Taking a similar approach ˇSrndi´c and Laskov [38] devel-
oped a system which extracts the tree-like structure of the
objects within a PDF as a feature set for classiﬁcation. Despite
its accuracy in an ofﬂine experiment, the use of this system
in an operational test demonstrates this system cannot always
correctly identify new threats.
While metadata and structure based malicious PDF de-
tection systems have been shown to be both efﬁcient and
effective, they are fundamentally susceptible to evasion. Prior
studies [38], [39] have demonstrated, either anecdotally or
in a systematic study of PDFrate [9], that these classiﬁers
are subject
to so-called mimicry attacks. In these attacks,
the structural features of a malicious sample are modiﬁed to
resemble that of a PDF document already classiﬁed as benign.
Because the malicious behaviors exercised by PDF malware
do not necessarily depend upon speciﬁc structural features,
this technique can evade these classiﬁers while preserving the
efﬁcacy of the original exploits.
A second type of attack, the reverse mimicry attack, has
also been presented [28]. Whereas a mimicry attack adds be-
nign attributes to malicious samples, the reverse mimicry attack
takes a sample classiﬁed as benign and makes it malicious.
The launch of such attacks is even easier because it does not
2
TABLE I: Existing PDF Classiﬁers
Parser
Detectors
Detection
Capability
Varies
Requirement
Low - Medium Malware Polymorphism [16], [17], [34]
Techniques
Evasion
Technique
Signature-based
Metadata & Structure -based
JavaScript-based
AV Scanners
Shaﬁq et al. [31]
PDF Malware Slayer [29]
PDFrate [32]
ˇSrndi´c and Laskov [38]
Liu et al. [25]
MDScan [37]
PJScan [23]
Medium
Medium
Mimicry Attack [39], [38]
Reverse Mimicry Attack [28]
Varies
High
require knowledge of the targeted classiﬁcation system, which
mimicry attacks largely depend on.
B. JavaScript Based Detection
The evasions of these systems demonstrate that malicious
PDF detection techniques that rely only upon structural and
metadata similarities are insufﬁcient. Given that most mali-
cious PDFs use JavaScript to either trigger or set up exploits,
prior classiﬁers focus on the extraction and analysis of embed-
ded JavaScript instead. Since these detection methods depend
on JavaScript analysis for classiﬁcation, an accurate parser is
essential to correctly interpret the entire PDF ﬁle and precisely
locate JavaScript.
Liu et al. [25] attempt to identify and instrument automat-
ically executing JavaScript in a document, so as to attribute
suspicious behavior exhibited by Adobe Reader at runtime
to the executing JavaScript. The runtime observations along
with other heuristics are then used to compute a score for
classiﬁcation. This system is limited by its overly simplistic
JavaScript extraction, only associating JavaScript with two
keywords, and assuming that they must always appear in plain-
text. In fact JavaScript can be embedded in multiple layers,
using extensions to the format (e.g., XFA), and can be encoded
by using diverse PDF features, such as object streams and
ﬁlters.
Realizing that malicious JavaScript often utilizes the Adobe
JavaScript API to read the contents of objects in a PDF,
MDScan [37] parses a PDF not only to extract embedded
JavaScript, but to load the internal structure of the document
as well. The extracted JavaScript is then run in a modiﬁed
JavaScript engine, augmented to support certain elements of
the Adobe JavaScript API which the authors reverse engi-
neered, so that calls to these supported API functions mimic
the behavior of Adobe Reader. While this system provides
a more complete platform for dynamically analyzing this
JavaScript, it is inherently incomplete due to partial API sup-
port, which is non-trivial, error-prone, and considerably time-
consuming to improve. This work realizes that JavaScript can
be encoded in various ways, but it only associates JavaScript
with one keyword, which is a severe limitation.
PJScan [23] extracts JavaScript and uses the tokenized
JavaScript as the feature set used to train a One-Class Support
Vector Machine. This system falls short of accuracy primarily
due to its PDF parser libpdfjs, which is built upon a third-
party parser, Poppler [10]. While Poppler claims to implement
the entire PDF ISO 32000-1 speciﬁcation [24], it does not
claim to address the discrepancies between the speciﬁcation
and the closed-source implementation of Adobe Reader, all of
the addendums to the speciﬁcation, or all of the speciﬁcations
extensions such as XFA.
Without considering the shortcomings speciﬁc to each de-
tector, these JavaScript-based PDF classiﬁers are all limited by
their JavaScript extraction capabilities. Not only must PDFs be
parsed correctly, but these detectors have to statically identify
all of JavaScript components embedded in the document. Be-
cause JavaScript can be embedded in many different ways, or
even using extensions to the speciﬁcation which these detectors
do not implement, they are unlikely to always produce all of
the JavaScript in a document, especially those which have been
obfuscated.
To resolve these parsing issues, Lu et al introduced MPScan
which hooks Adobe Reader’s JavaScript engine to produce
the JavaScript executed by Adobe Reader when opening a
document, which is then classiﬁed as malicious or benign using