title:Aaron: An adaptable execution environment
author:Marc Brunink and
Andr&apos;e Schmitt and
Thomas Knauth and
Martin S&quot;ußkraut and
Ute Schiffel and
Stephan Creutz and
Christof Fetzer
Aaron: An Adaptable Execution Environment
Marc Br¨unink, Andr´e Schmitt, Thomas Knauth, Martin S¨ußkraut, Ute Schiffel, Stephan Creutz, Christof Fetzer
Technische Universit¨at Dresden
Department of Computer Science; 01062 Dresden; Germany
{marc, andre, thomas, suesskraut, ute, stephan, christof}@se.inf.tu-dresden.de
Abstract—Software bugs and hardware errors are the largest
contributors to downtime [1], and can be permanent (e.g.
deterministic memory violations, broken memory modules)
or transient (e.g. race conditions, bitﬂips). Although a large
variety of dependability mechanisms exist, only few are used
in practice. The existing techniques do not prevail for several
reasons: (1) the introduced performance overhead is often not
negligible, (2) the gained coverage is not sufﬁcient, and (3)
users cannot control and adapt the mechanism.
Aaron tackles these challenges by detecting hardware and
software errors using automatically diversiﬁed software compo-
nents. It uses these software variants only if CPU spare cycles
are present in the system. In this way, Aaron increases fault
coverage without incurring a perceivable performance penalty.
Our evaluation shows that Aaron provides the same throughput
as an execution of the original application while checking a
large percentage of requests — whenever load permits.
Keywords-Fault detection; Fault tolerance; Diversity meth-
ods; Adaptive algorithm; Compiler transformation
I. INTRODUCTION
More and more, our daily life depends upon computing
systems. The proliferation of those systems is accompanied
by a demand for security, safety, and availability. To satisfy
these demands a large variety of dependability mechanism
have been developed, both using either hardware or software
solutions.
Hardware solutions to dependability issues are costly to
develop and deploy; they are a good choice for techniques
that are mature. One example is the NX bit used by WˆX
page protection (every memory page is either writable or
executable per default). For dependability mechanisms that
might be modiﬁed, most hardware solutions lack adaptivity.
Techniques that are useful for only a minority of users are
unlikely to be integrated into COTS hardware. Building spe-
cialized hardware incorporating these techniques can result
in a prohibitively high cost-performance ratio compared to
COTS components. Thus, dependability mechanism should
be implemented in software until they have matured and
have been proven to be useful in a majority of application
scenarios.
In contrast to COTS hardware, software solutions are
highly adaptable. Furthermore, many different software solu-
tions that cope with dependability issues are available. Those
include, but are not limited to: out-of-bounds checker [2],
redundant execution [3, 4], software encoded processing [5],
and recovery blocks [6]. Each of these different approaches
target a speciﬁc set of failures; however, none covers all
failures observable in deployed systems. Although coverage
can be increased by multiplexing dependability mechanisms,
the overheads of different mechanisms add up. Even worse,
interactions between them can lead to overheads larger than
linear. In addition, multiplexing might have a negative effect
on the coverage of the individual mechanisms.
Some of the existing dependability mechanisms only solve
problems in speciﬁc execution environments or program-
ming languages. Naturally, the question arises, why one
should apply a dependability mechanism instead of changing
the underlying setup. For example, instead of deploying an
out-of-bounds checker, a software engineer could simply
use a programming language that is safe in respect to out-
of-bounds accesses. Similar arguments can be applied to
dangling references (garbage collected languages) and bit
ﬂips (redundant hardware). However, changing the program-
ming language or execution environment in these ways only
shifts dependability mechanisms to lower levels. Although
shifting might enable stronger optimization or more efﬁcient
implementation, it also decreases adaptability. Adaptability
is favorable because it can lead to higher efﬁciency in the
long run: As more mature software is deployed, less errors
are present in the software; but, the cost of checking is
constant. As a result the cost-beneﬁt ratio gets worse. Using
a traditional deployment it is not possible to downscale
checking. For example, once an application is developed in
a safe language, it is hard to loose the incurred constraints
during runtime in order to increase performance.
Aaron tackles these challenges by scheduling different
runtime checks dynamically depending on the load of the
system and the maturity of the software. Maturity is not a
monotonically increasing property but ﬂuctuates especially
at major releases. To this extent Aaron has to adapt, and,
potentially, take hints from a system administrator.
The different software diversity mechanisms we used to
increase safety and security are discussed in Section II-B.
Aaron uses CPU spare cycles to schedule software variants
dynamically, which is detailed in Section II-D. In Section III
we evaluate the system and show that it adapts to changes
in system load instantaneously.
The resulting system can: (1) use dependability mecha-
nisms that exhibit a high overhead; (2) adapt failure cov-
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:46:53 UTC from IEEE Xplore.  Restrictions apply. 
978-1-4244-9233-6/11/$26.00 ©2011 IEEE411erage at runtime; (3) incorporate hints given by a system
administrator.
II. THE AARON APPROACH
In many environments, availability and costs are ulti-
mately more important than security and safety. With the ex-
ception of highly critical systems, we often take the potential
risk of a security or safety violation with the goal to increase
availability or to decrease costs. For example, triple modular
redundancy or byzantine fault tolerant systems are often not
used because the costs outweigh the beneﬁts. Aaron targets
these environments in which safety and security are not
the prime objectives but are desired nevertheless. In the
following, we enumerate the design goals of Aaron and
explain how they are fulﬁlled:
1) Goal: Hardware and software errors are detected with-
out additional hardware and without increasing costs
of software development.
Approach: Aaron uses software diversity to detect and,
if possible,
tolerate errors in deployed systems. It
generates software variants automatically without user
intervention. Aaron does not need special hardware. It
runs on COTS hardware making it especially useful
in scenarios in which high fault coverage is desired
but without additional cost due to special purpose
hardware.
2) Goal: The cost of processing is increased at most
moderately.
Approach: Aaron exploits spare cycles present in the
system. No additional hardware has to be deployed to
cope with increased load caused by error detection.
Furthermore, using spare cycles for error detection
increases power costs only moderately since common
computers consume a signiﬁcant amount of power
even while being idle.
3) Goal: Error detection does not
inﬂuence system
throughput.
Approach: The runtime overhead of Aaron itself is
negligible. Aaron adapts extremely fast to the current
load situation. Error detection is performed on a best-
effort basis; if in doubt, Aaron opts for throughput
instead of error detection.
To build a solid foundation for further discussion, we
continue with a general overview of the architecture of
Aaron. Subsequently, we examine speciﬁc details of Aaron
to gain insights into its inner workings. We use the obtained
knowledge to discuss Aaron’s limitations at the end of the
section.
A. Architectural Overview
Aaron augments an application with software dependabil-
ity mechanisms. The software developer embeds Aaron into
the application using a very slim interface. To this end, three
Figure 1.
automatically diversiﬁed software.
Aaron augments the existing applications by scheduling
parts of the application have to be isolated: input streams,
tasks, and worker threads.
The developer has to re-route the input streams of tasks to
Aaron; in our experience a very straightforward endeavor. A
task is a small unit of work the application should perform.
It subsumes multiple different concepts including, but not
limited to, jobs, events, kernels, and requests. Especially ap-
plications that distribute computation across multiple nodes
show the necessary structure. After reading the task from an
input channel (cf. Figure 1, step 1), the application passes it
to Aaron using a simple function call. The function call is
added by the software developer. Optionally, the application
might perform minor pre-processing before a task is passed
to Aaron, e.g. tasks might be prioritized.
Next, Aaron inspects current system conditions. Depend-
ing upon system load, Aaron chooses a software variant
from a variant pool (step 2). A variant is a version of the
application that was diversiﬁed at compile time and protects
the execution of the task against a speciﬁc set of errors. We
present more details in the next section. Aaron forwards the
task and a function pointer reﬂecting the chosen variant to
a worker thread (step 3). The thread processes the request
using the determined variant. Output is sent via an arbitrary
application-speciﬁc channel, which is not depicted in the
Figure.
B. Automatic Diversity
Diversiﬁcation is a common practice to detect and mask
errors in deployed systems, for example in avionics. How-
ever, manual diversiﬁcation, e.g. design diversity, is costly
in general and only justiﬁable in highly critical areas. Aaron
uses automatic software diversiﬁcation to achieve high fault
coverage without increasing development costs.
A large number of software diversiﬁcations methods are
available (e.g. [7, 4, 8, 9, 10, 11, 12]). In principle, Aaron
can use any of those. We implemented multiple software
diversiﬁcation methods (Table I). The goal is neither to
present new diversiﬁcation methods nor to extend knowledge
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:46:53 UTC from IEEE Xplore.  Restrictions apply. 
T(3)(1) AaronCCCTTTTTCClientTThreadTaskVariant(2)(    ,   )(    ,   )Pre-processing412DIVERSIFICATION METHODS PRESENT IN AARON.
Table I
Name
Native
Assertion
OverAllocate
NullWrite
NullRead
NullDeref
SWIFT
SWIFTCFC
Function
An unchanged version of the application.
However assertions do not trigger an abort.
Instead, violated assertions are logged and
ignored.
Violated assertions cause an abort of the
application.
Pads stack and heap allocations to tolerate
present buffer overﬂows. Stack allocations
are padded on a per object basis, so each
stack variable is padded.
Ignores writes to address 0x0.
Return 0 if address 0x0 is loaded.
Combines NullWrite and NullRead.
SWIFT duplicates all instructions and regis-
ters apart from memory accesses and control
ﬂow instructions to detect transient hardware
errors. Since the original implementation of
SWIFT was not available, we reimplemented
SWIFT.
SWIFT alone does not detect control ﬂow er-
rors. SWIFTCFC adds control ﬂow checking
to SWIFT.
Ref.
[8, 9]
[14]
[14]
[15]
[4]
about existing methods. Instead, we use them to prove the
applicability and the overall soundness of Aaron. Aaron
can be easily extended with new diversiﬁcation methods if
desired.
The diversiﬁcation itself is achieved using the LLVM
compiler infrastructure [13]. LLVM translates the source
code of the application into an intermediate representation
(IR). For each diversiﬁcation method, the intermediate rep-
resentation is copied and augmented with runtime checks
(Figure 2). All functions are renamed and calls and refer-
ences are adjusted accordingly. Global variables are shared
among variants. Finally, all variants and the global variables
are linked into a single ﬁle. Thus, we gain multiple versions,
i.e. variants, of the application. Each variant protects against
a speciﬁc set of errors. All variants together form the
diversiﬁed application.
C. Power Consumption
Computers consume a signiﬁcant amount of power even
while being idle or only lightly loaded. Figure 3 shows the
power consumption of one of our Dell Precision R5400
machines, measured with the help of a Raritan Dominion
PX-5528 power distribution unit.
If the node is not loaded at all, it already consumes 133
watts. Power consumption increases linearly and peaks at
190W. At a load of 50%, power consumption is already
88% of consumption under full load (167 watts). Only a
small increase of about 14% has to be paid in order to use
the remaining 50% of CPU power.
To handle sudden load surges, cluster deployments are of-
ten oversized [16]. Aaron uses those spare cycles present in
deployed systems to schedule different diversiﬁed software
Figure 2.
Aaron diversiﬁes software during compilation. To improve
readability, we present only the NullRead diversiﬁcation together with the
Native version and show C source code instead of LLVM intermediate
representation.
Figure 3. Power consumption of a Dell Precision R5400 machine based
on CPU utilization. The x-axis reﬂects the load put on each core.
variants to detect and tolerate runtime failures. Since Aaron
uses spare cycles, we expect only a small increase in total
power consumption.
D. Scheduling Software Variants
To be able to exploit spare cycles in deployed systems
without generating any user-perceivable runtime penalty,
Aaron has to adapt to varying workloads extremely fast.
Aaron currently relies on an important fact of applications
running in cluster environments: cluster applications process
workload in parallel. As a result the workload is divided into
different tasks by the application developer. For example,
in web and database servers, batch and event processing
systems one can discover the concept of a task. Aaron
exploits this task orientation: it decides whether to apply
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:46:53 UTC from IEEE Xplore.  Restrictions apply. 
extern int counter;char get_Native    (char *array, int i) {        ++counter;        return array[i];}Nativeextern int counter;char get_NULLRead     (char *array, int i) {        ++counter;        if (array + i == NULL)                 return 0;        return array[i];}NullReadint counter = 0;Global variablesstatic int counter = 0;char get (char *array, int i) {        ++counter;        return array[i];}Original application static int counter = 0;char get_Native (..) {..}char get_NULLRead (..) {..}Diversiﬁed application 0102030405060708090100CPU utilization [%]020406080100120140160180Energy consumption [watts]413checking on a task by task basis. Aaron targets task-oriented
applications, which are prevailing in cluster environments.
1) Load Estimation: The scheduler’s job is to decide
which variant to use. This decision is based on the current
load of the system. Since CPU utilization is a local attribute,
calculation of system load is performed locally on each
cluster node.
The load calculation has to be precise and accurate. We
implemented several calculation methods.
The ﬁrst approach estimated system load by inspecting
the actual CPU load of the node. Although it is straight-
forward and seems to be the natural approach, CPU load is
not precise enough: In our experience the scattering of values
renders ﬁne-grained, accurate variant selection impossible.
In the second approach we simply inspect the task queue
and use the number of pending tasks to estimate system
load. This mode proved to be highly efﬁcient and accurate.
It is best suited for applications in which clients issue tasks
in an asynchronous manner. Asynchrony ensures that tasks
are not queued at the client but at the server, and the work
queue of the server reﬂects the actual system load.
As a third option we calculate system load using the ratio
of pending IO sockets per active client. This is best suited
for applications that use synchronous tasks.
An application developer can use one of the load estima-
tors provided by Aaron or build a custom estimator.
2) Best-effort Detection: In contrast to existing methods,
Aaron uses a best-effort approach to error detection: Aaron
does not guarantee a speciﬁc error coverage. Instead, it
observes error behavior and maximizes coverage using spare
cycles present in the system.
Before a task is processed by the system, Aaron gathers