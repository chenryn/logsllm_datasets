### Further Analysis of ai.lock as a δ-LSIM Function

We further demonstrate that ai.lock is also a δ-LSIM function when its hash value is a single bit. We set δ = τ, where τ is the error tolerance threshold derived from the ai.lock training process (refer to Table 3) for different values of λ. Table 7 presents the P1 and P2 values achieved by the basic ai.lock over the holdout dataset. We conducted a one-sided Mann-Whitney test with the alternative hypothesis P1 > P2. Based on the observed p-value = 0.00 (α = 0.05), we conclude that the alternative hypothesis is true for different values of λ, thus confirming that ai.lock is a δ-LSIM function over the holdout dataset.

| λ | DI2E module (Inception v.1) | DI2E module (Inception v.3) | PCA + LSH module |
|---|---------------------------|---------------------------|--------------------|
| 150 | 0.7, 1.9, 0.044 | 0.7, 1.9, 0.049 | 0.7, 1.9, 0.051 |
| 250 | 0.7, 1.9, 0.049 | 0.7, 1.9, 0.051 | 0.7, 1.9, 0.066 |
| 350 | 0.7, 1.9, 0.051 | 0.7, 19, 0.066 | 0.7, 1.9, 0.066 |
| 500 | 0.7, 1.9, 0.066 | 0.7, 1.9, 0.066 | 0.7, 1.9, 0.066 |

**Table 8: Processing time (in seconds) of SLSS ai.lock modules for different values of λ. When using Inception.h5, the overall ai.lock speed is below 0.8s.**

### Entropy of Imageprints

We used the entropy evaluation dataset (see § 6.2) to empirically calculate the entropy of the imageprints generated by the ai.lock variants. The empirical entropy of an authentication solution is proportional to the size of the keyspace that an attacker needs to search to find a match for the authentication secret. For biometric information, estimating this size is challenging. In such cases, the entropy can be estimated as \(-\log_2(\text{FAR})\) [46]. We performed this study for different values of λ and the best parameter choice of ai.lock (see § 7.1), using the entropy evaluation dataset.

On the 2 billion image pairs in the entropy evaluation dataset, the FAR of the SLSS ai.lock variant is 0.020% and 0.035% when λ is 50 and 500, respectively, resulting in an entropy of 12.28 bits and 11.48 bits. We visually inspected several hundred image pairs that resulted in false accepts and observed that a significant proportion were due to images containing the same object type, e.g., ribbons, helmets, etc. This result is not unexpected: the SLSS variant uses only the last hidden layer of the Inception.v3 network. Since Inception.v3 is trained for image classification, it is expected to have similar activations on the last hidden layer for images of the same object type. We anticipate that requiring the match between activations of multiple inception layers (multi-layer variant) will eliminate this issue.

The FAR of the MLMS ai.lock variant on the entropy evaluation dataset, for λ values of 500 and 150, is 0.0007% and 0.0004%, respectively. Therefore, the estimated entropy of ai.lock imageprints is 17.14 and 18.02 bits, respectively.

### ai.lock Speed

We implemented ai.lock using Android 7.1.1 and TensorFlow 0.12.1 and evaluated its speed using 1,000 images from the Nexus dataset on a Nexus 6P smartphone (Qualcomm Snapdragon 810 CPU and 3GB RAM). Table 8 shows the average processing time of the three main ai.lock modules for different values of λ. Independent of the value for λ, the DI2E module takes 1.9s to compute the activations of all the layers of Inception.v3. When using Inception.h5 [63] (a smaller network), the DI2E module takes 0.7s. The combined PCA and LSH speed increases with the value of λ but remains below 70ms for λ = 500. The processing overhead of ai.lock is below 2s and 1s using Inception.v3 and Inception.h5, respectively. To minimize its impact on user experience on a Nexus 6P, ai.lock should use Inception.h5. The most significant processing overhead of ai.lock is in computing the activation of the DNN, which directly depends on the size of the network. Note that compressing the network using the DNN distillation approach [25] can alleviate this overhead. Future device and Inception improvements are likely to enhance ai.lock's performance and accuracy.

### Discussion and Limitations

#### Default Authentication, Revocation, and Recovery
If the image-based authentication fails multiple times or the ai.lock secret is unavailable, the system falls back to the default authentication mechanism, such as text passwords.

#### Strong Passwords
ai.lock benefits from users choosing strong, high-entropy, and unique objects for authentication. ai.lock can use datasets of images of frequently occurring, low-entropy objects and learn to reject similar objects during their registration by the user. Additionally, the image classification task can be adapted to detect images belonging to classes of weak, low-entropy authentication objects. Similar to text passwords, users could be encouraged to pick an ordered combination of personal objects for authentication.

#### Usability
Although usability is not the primary focus of this paper, we expect ai.lock to share several limitations with face-based authentication mechanisms due to their similarities in form factor. These include susceptibility to inappropriate lighting conditions [9]. While the FAR of ai.lock remains small under illumination changes, its FRR increases, affecting usability. However, DNNs are capable of learning representations invariant to input changes, such as lighting and translation. Thus, the DI2E module of ai.lock can be fine-tuned to be more resistant to illumination changes. We leave the investigation of such improvements for future work.

In [6], we evaluated the usability aspects of an image-based authentication approach and found that:
1. User entry time was significantly shorter compared to text passwords on a mobile device.
2. Participants were able to remember their authentication objects 2 and 7 days after registering them.
3. Participants perceived object-based authentication to be easier to use than text passwords and were willing to adopt it.

Further studies are required to understand:
1. The user choice of secret objects or scenes and whether it impacts the secret key space.
2. The ability of ai.lock to filter out common or low-entropy images.
3. The scenarios where users are willing to adopt ai.lock authentication.
4. Other limitations associated with ai.lock authentication.

#### Shoulder Surfing
Similar to face-based authentication, ai.lock is vulnerable to shoulder surfing attacks where the adversary captures images of the objects or scenes used by victims. However, ai.lock eliminates remote attacks, moves the target away from sensitive body features, and enables users to trivially change their image-passwords. Similar to biometrics, ai.lock can benefit from liveness verification techniques [55] to ensure that the adversary has physical access to the authentication object or scene, preventing sophisticated image replay attacks. In addition, in Appendix B, we show that knowledge of the authentication object type does not provide the adversary with a significant advantage when launching a brute force attack.

#### Multi-factor Authentication
ai.lock can be used in conjunction with other authentication solutions. For instance, the image password set and authentication steps described in § 4.1 can take advantage of a secondary secret (e.g., password, PIN), increasing the number of authentication factors to improve security. To this end, let \( r \) be a random salt. We modify \( x \) in the fuzzy biometric protection solution outlined in § 4.1 to be the randomized hash of the secondary secret computed using salt \( r \). Randomized hashing ensures the required formatting and bit length for \( x \) can be achieved using a key derivation function (e.g., HKDF [36]). The random salt \( r \) needs to be stored along with the other authentication credentials, i.e., SS(R, x).

#### Compromised Device
Our model assumes an adversary who physically captures a victim's device and thus has black-box access to the authentication function. ai.lock is not resilient to an adversary who installs malware on the victim's device. Such malware may leverage PlaceRaider [66] to construct three-dimensional models of the environment surrounding the victim, including the authentication object.

Trusted hardware can secure ai.lock and even obviate the need for secure sketches. However, it would reduce the number of devices where ai.lock can be applied. Techniques similar to AuDroid [50] could be employed to ensure that unauthorized processes or external parties cannot access and misuse the device camera, but they may still leave ai.lock vulnerable to cache attacks [38].

### Conclusions

In this paper, we introduced ai.lock, the first secure and efficient image-based authentication system. We presented a suite of practical yet powerful image-based attacks and built large-scale attack datasets. We demonstrated that even under our powerful attacks, ai.lock achieves better entropy than state-of-the-art biometric authentication solutions.

### Acknowledgments

We thank the shepherd and reviewers for their excellent feedback. This research was supported in part by grants from the NSF (CNS-1526494, CNS-1527153, and SES-1450619) and the Florida Center for Cybersecurity.

### References

[References listed as provided in the original document]

This optimized version of the text aims to be more coherent, clear, and professional, with improved readability and structure.