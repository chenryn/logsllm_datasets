pages are in successive order as well. Presumably this is done
for performance reasons to optimally distribute the data over the
caches and increase the effectiveness of the hardware prefetcher.
As our experiments have shown, even on Sandybrige CPUs one
virtually consecutive memory buffer with a size twice as large
as the L3 cache is sufﬁcient to completely ﬂush it.
During our experiments we tried to locate certain system
service handler functions within win32k.sys. To avoid cache
pollution and obtain the best measuring results, we chose the
system service bInitRedirDev, since it only executes 4
bytes of code before returning. As a side effect, we also
located the System Service Dispatch/Parameter Tables (SSDT
and SSPT) within that module, since these tables are accessed
internally on each service call.
In our implementation we ﬁrst allocated a 16 MB eviction
buffer and ﬁlled it with RET instructions. Then for each page
p of the complete kernel space memory (or a set of selected
candidate regions), we performed three steps:
1) Flush all (address translation-, code- and uniﬁed) caches by
calling into each cacheline (each 64th byte) of the eviction
buffer.
2) Perform sysenter to preload address translation caches.
3) Call into some arbitrary address of page p and measure
time until page fault handler returns.
300
250
200
s
k
c
o
l
c
150
100
50
0
0x9624e3c0
0x962c84e0
0x96342600
0x963bc720
0x96436840
virtual address
Figure 7. Extract of cache preloading measurements
1) Evaluation Results: The steps described above have to
be repeated several times to diminish the effects of noise and
measuring inaccuracies. It turned out that the necessary amount
of iterations strongly depends on the underlying hardware.
Empirically we determined that around 100 iterations are needed
on Nehalem, 60 on AMD, and only 30 on Sandybridge to
reliably produce precise results. Inside the virtual machine, we
had to further increase the number of iterations due to the noise
that was generated by the virtual machine monitor. Nevertheless,
by increasing it to 100 (the VM operated on the Sandybridge
processor) this timing technique also worked successfully inside
a virtualized environment.
We learned that the noise could be additionally reduced by
taking different addresses randomly from each probed page for
each iteration. In addition, we found out that using relative
time differences was less error-prone than using absolute values.
Therefore, we enhanced our testing procedure by performing
the measuring twice for each page: the ﬁrst time like shown
above and the second time without performing the syscall in
between. By calculating the relative time difference between
both timing values, we were able to measure the speedup of
address translation caches for our particular scenario. Figure 7
shows an extract of our measuring results for the Intel i7-950
(Lynnﬁeld) CPU. The x-axis displays the probed virtual address,
while the y-axis displays the relative time difference in clock
cycles. The two vertical lines indicate those locations where the
searched system service handler function resp. the SSDT/SSPT
were located. As one can easily see those memory regions have
much higher timing difference values than the others. Though
there was a lot of noise within the data, our algorithms were
able to locate those regions correctly on all of our testing
environments.
While this method only reveals the memory page of the
searched kernel module, it is still possible to reconstruct its
201
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:55:20 UTC from IEEE Xplore.  Restrictions apply. 
full virtual address. This can be achieved by obtaining the
relative address offset of the probed code/data by inspecting the
image ﬁle of the module. As the measuring operates on a page
granularity, it is best suited to locate kernel modules that reside
in regular pages. Nevertheless, with the described difference
technique, also large page memory regions can be identiﬁed
that contain certain code or data. Obviously, the exact byte
locations within such regions cannot be resolved and, therefore,
we have used it to locate win32k.sys in our experiments.
Due to its size, this module is sufﬁcient to perform arbitrary
ROP attacks [35], [36].
2) Discussion: Our third proposed method has no remarkable
limitations. However, depending on the size of the probed
memory range and the amount of necessary test iterations, it
may take some time to complete. The probing of a 3 MB region
(this is the size of win32k.sys) for one iteration takes around
27 seconds. Therefore, if an attacker has employed the double
page fault method to identify an appropriate candidate region
and then performs 30 iterations on a Sandybridge processor, it
takes 13 minutes to perform the complete attack. However, since
the relative offset of the searched kernel function can previously
be obtained from the image ﬁle, the probed memory region can
be reduced drastically, enabling to perform the test in a minute
or less. If the location of candidate regions is not possible, our
attack will still work but take longer time. Furthermore, the
technique operates on page granularity. Hence, drivers residing
in large pages can be located, but their exact byte offset cannot
be identiﬁed without additional techniques.
V. MITIGATION APPROACHES
Since the methods presented in the previous section can
be used to break current ASLR implementations, mitigation
strategies against our attacks are necessary. To that end, there
are several options for CPU designers and OS vendors.
The root cause of our attacks is the concurrent usage of the
same caching facilities by privileged and non-privileged code
and data, i.e., the memory hierarchy is a shared resource. One
solution to overcome this problem would be to split all caches
and maintain isolated parts for user and kernel mode, respec-
tively. Obviously, this imposes several performance drawbacks
since additional checks had to be performed in several places
and the maximum cache size would be cut in half for both
separate caches (or the costs increase).
A related mitigation attempt is to forbid user mode code
to resolve kernel mode addresses. One way to achieve this is
to modify the global descriptor table (GDT), setting a limit
value such that
the segments used in non-privileged mode
only span the user space. However, doing so would render
some CPU optimization techniques useless that apply when
the ﬂat memory model is used (in which all segments span
the complete memory). Furthermore, the complete disabling
of segmentation on 64-bit architectures makes this mitigation
impossible. Another option would be to suppress the creation
of TLB entries on successful address translation if an access
violation happens, like it is done with the tested AMD CPU.
Nevertheless,
loading of kernel code, data, or
address mappings through system calls still cannot be avoided
with this method.
the indirect
Current ASLR implementations (at least under Windows) do
not fully randomize the address space, but randomly choose
from 64 different memory slots. By utilizing the complete mem-
ory range and distributing all loaded modules to different places,
it would be much harder to perform our attacks. Especially
when dealing with a 64-bit memory layout, the time needed
for measuring is several magnitudes higher and would increase
the time needed to perform some of our attacks. Nevertheless,
scattering allocated memory over the full address range would
signiﬁcantly degrade system performance since much more
paging structures would be needed and spatial locality would
be destroyed to a large extent. Furthermore, we expect that our
double page fault attack even then remains practical. Due to the
huge discrepancy between the 64-bit address space and the used
physical memory, the page tables are very sparse (especially
those one higher levels). Since page faults can be used to
measure the depth of the valid page tables for a particular
memory address, only a very small part of the complete address
space actually has to be probed.
We have proposed a method to identify mapped kernel
modules by comparing their memory allocation patterns to a
set of known signatures. This is possible because parts of these
modules are marked pageable or discardable. If no code or data
could be paged-out (or even deallocated) after loading a driver, it
would be impossible to detect them with our signature approach.
Again, applying this protection would decrease the performance,
because unpageable memory is a scarce and critical system
resource.
One effective mitigation technique is to modify the execution
time of the page fault handler: if there is no correlation between
the current allocation state of a faulting memory address and the
observable time for handling that, the timing side channel for
address translation vanishes. This would hinder our attacks from
Sections IV-B and IV-C. We have implemented one possible
implementation for this method and veriﬁed that our measuring
no longer works. To that end, we have hooked the page fault
handler and normalized its execution time if unprivileged code
raises a memory access violation on kernel memory. In that case
we enforce the execution to always return back to user mode
after a constant amount of clock cycles. For that purpose we
perform a bunch of timing tests in advance to measure the timing
differences for memory accesses to unallocated and allocated
(for both regular and large) pages. Inside the hooked page fault
handler we delay execution for the appropriate amount of time,
depending on the type of memory that caused the exception.
Since this happens only for software errors – or due to active
probing – there is no general impact on system performance.
Note that modifying the page fault handler renders our attack
infeasible, but there might be other side channels an attacker can
exploit to learn more about the memory layout of the kernel.
202
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:55:20 UTC from IEEE Xplore.  Restrictions apply. 
Even with normalizing the page fault handling time, our cache
probing attack remains feasible. However, cache probing has
one fundamental shortcoming: it only reveals information about
physical addresses. If the kernel space randomization is only
applied to virtual addresses, then knowing physical addresses
does not help in defeating ASLR.
The kernel (or an underlying hypervisor) may also try to
detect suspicious access patterns from usermode to kernelspace,
for example by limiting the amount of usermode page faults
for kernel space addresses. Such accesses are necessary for
two of the previously described methods. While our current
implementations of these attacks could be detected without
much effort that way, we can introduce artiﬁcial sleep times
and random access patterns to mimicry benign behavior. In the
end, this would lead to an increased runtime of the exploits.
In case the attacks are mounted from within a VMM, the hy-
pervisor might also provide the VM with incorrect information
on the true CPU model and features, for example by modifying
the cpuid return values. However, this might have undesirable
side-effects on the guest operating system which also needs
this information for optimizing cache usage. Furthermore, the
architectural parameters of the cache (such as size, associativity,
use of slice-hashing, etc.) can be easily determined from within
the VM using speciﬁc tests.
Finally, the most intuitive solution would be to completely
disable the rdtsc instruction for usermode code, since then
no CPU timing values could be obtained at all. However, many
usermode applications actually rely on this operation and, hence,
its disabling would cause signiﬁcant compatibility issues.
VI. RELATED WORK
Timing and side channel attacks are well-know concepts in
computer security and have been used to attack many kinds
of systems, among others cryptographic implementations [41]–
[43], OpenSSL [44], [45], SSH sessions [46], web applica-
tions [47], [48], encrypted VoIP streams [49], [50], and virtual
machine environments [51]–[53].
Closely related to our work is a speciﬁc kind of these attacks
called cache games [24], [25], [54], [55]. In these attacks, an ad-
versary analyzes the cache access of a given system and deduces
information about current operations taking place. The typi-
cal target of these attacks are cryptographic implementations:
while the CPU performs encryption or decryption operations,
an adversary infers memory accesses and uses the obtained
information to derive the key or related information. In a recent
work, Gullasch et al. showed for example how an AES key can
be recovered from the OpenSSL 0.9.8n implementation [24]
and Zhang et al.
introduced similar attacks in a cross-VM
context [53].
We apply the basic principle behind cache attacks in our work
and introduce different ways how this general approach can
be leveraged to obtain information about the memory layout
of a given system. Previous work focused on attacks against
the instruction/data caches and not on the address translation
cache, which is conceptually different. We developed novel
approaches to attack this speciﬁc aspect of a computer system.
Furthermore, all documented cache attacks were implemented
either for embedded processors or for older processors such
as Intel Pentium M (released in March 2003) [24], Pentium 4E
(released in February 2004) [25], or Intel Core Duo (released in
January 2006) [23]. In contrast, we focus on the latest processor
architectures and need to solve many obstacles related to modern
performance optimizations in current CPUs [22]. To the best
of our knowledge, we are the ﬁrst to present timing attacks
against ASLR implementations and to discuss limitations of
kernel space ASLR against a local attacker.
VII. CONCLUSION AND FUTURE WORK
In this paper, we have discussed a generic, timing-based
side channel attack against kernel space ASLR. Such side
channels emerge from intricacies of the underlying hardware
and the fact that parts of the hardware (such as caches and
physical memory) are shared between both privileged and non-
privileged mode. We have presented three different instances
of this methodology that utilize timing measures to precisely
infer the address locations of mapped kernel modules. We
successfully tested our implementation on four different CPUs
and within a virtual machine and conclude that these attacks are
feasible in practice. As a result, a local, restricted attacker can
infer valuable information about the kernel memory layout and
bypass kernel space ASLR.
As part of our future work, we plan to apply our methods to
other operating systems such as Mac OS X and more kinds of
virtualization software. We expect that they will work without
many adoptions since the root cause behind the attacks lies in
the underlying hardware and not in the operating system. We
further plan to test our methods on other processor architectures
(e.g., on ARM CPUs to attack ASLR on Android [11]). Again,
we expect that timing side channel attacks are viable since the
memory hierarchy is a shared resource on these architectures as
well.
Another topic for future work is the identiﬁcation of methods
to obtain the physical address of a certain memory location from
user mode. One promising method would be to identify certain
data structures that are always mapped to the same physical
memory and use the technique of cache probing with them. First
experiments have shown that certain parts of mapped system
modules are constant for a given system (e.g., the physical base
address of ntdll.dll). Another possibility is to instrument
the characteristics of the Sandybridge hash function to locate
colliding memory locations and infer the bits of their physical
address.
VIII. ACKNOWLEDGEMENTS
This work has been supported by the Ministry of Economic
Affairs and Energy of the State of North Rhine-Westphalia
(Grant IV.5-43-02/2-005-WFBO-009) and the German Federal
Ministry of Education and Research (BMBF grant 16BY1207B
– iTES).
203
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:55:20 UTC from IEEE Xplore.  Restrictions apply. 
REFERENCES
[1] Aleph One, “Smashing the Stack for Fun and Proﬁt,” Phrack
Magazine, vol. 49, no. 14, 1996.
[2] blexim, “Basic Integer Overﬂows,” Phrack Magazine, vol. 60,
no. 10, 2002.
[3] M. Conover, “w00w00 on Heap Overﬂows,” 1999.
[4] C. Cowan, C. Pu, D. Maier, H. Hintony, J. Walpole, P. Bakke,
S. Beattie, A. Grier, P. Wagle, and Q. Zhang, “StackGuard:
Automatic Adaptive Detection and Prevention of Buffer-Overﬂow
Attacks,” in USENIX Security Symposium, 1998.
[5] Microsoft, “Data Execution Prevention (DEP),” http://support.
microsoft.com/kb/875352/EN-US/, 2006.
[6] S. Bhatkar, D. C. DuVarney, and R. Sekar, “Address Obfuscation:
An Efﬁcient Approach to Combat a Broad Range of Memory
Error Exploits,” in USENIX Security Symposium, 2003.
[7] PaX Team, “Address Space Layout Randomization (ASLR),”
http://pax.grsecurity.net/docs/aslr.txt.
[8] J. Xu, Z. Kalbarczyk, and R. K. Iyer, “Transparent Runtime Ran-
domization for Security,” in Symposium on Reliable Distributed
Systems (SRDS), 2003.
[9] Solar Designer, “”return-to-libc” attack,” Bugtraq, 1997.
[10] H. Shacham, “The Geometry of Innocent Flesh on the Bone: