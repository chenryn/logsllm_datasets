Intuitive ideas. Based on the third guideline, an IRC should use an 
unlimited  number  of  different  types  of  objects.  This  can  be  easily 
achieved  by  crawling  images  in  the  Internet.  But  how  do  we 
generate  challenges?  In  general,  computers  do  not  understand  the 
semantics  of  an  image,  but  we  want  to  avoid  labeling  images  in 
generating  challenges.  Computers  do  a  poor  job  in  segmenting  an 
image  into  semantically  meaningful  objects.  Objects  that  are 
automatically  segmented  by  computers  were  considered  not 
suitable for an IRC. Instead, semantically  meaningful objects were 
considered  necessary  in  generating  IRC  challenges  in  order  for 
human  users  to  produce  consistent  answers.  This  explains  why 
many  existing  IRCs  require  manual  labor  such  as  labeling  or 
selecting images. It is a dilemma seemingly hard to solve.  
Our  insight  is  that  although  an  object  that  is  segmented  by  a 
computer might be poor cognitively, but if the object is surrounded 
by  its  original  context  in  the  image,  then  the  object  is  readily 
recognizable  by  humans.  By  exploiting  the  context,  objects 
segmented  by  computer  can  be  used  in  an  IRC.  The  magic  of 
context  solves  the  dilemma,  and  an  IRC  can  be  designed  without 
labeling any image.  
To  use  context  for  humans  to  recognize  a  computer-segmented 
object, we can crop the object and detach it from its original image, 
and then ask a user to use the image as a context cue to identify the 
detached  object  from  a  set  of  decoy  objects.  The  hole  left  by 
cropping  in  the  original  image  must  be  filled.  Otherwise  the 
detached object can be easily deduced by comparing the contour of 
a candidate object with the shape of the hole. The filling should not 
allow  bots  to  locate  the  cropped  region  but  should  leave  some 
semantic  hints  such  as  unnaturalness  to  enable  humans  to  quickly 
locate the region. Image inpainting [27], which is to incrementally 
fill  a  hole  with  the  best  matching  blocks,  can  be  modified  to 
achieve the goal.  
These intuitive ideas led to the development of Cortcha. In Cortcha, 
a  user  is  asked  to  identify,  among  a  set  of  candidate  objects,  an 
object detached from an image, and then place it back to its original 
position in the image. 
Advantages.  The  major  innovation  in  Cortcha  is  to  exploit  the 
surrounding  context  to  recognize  an  inaccurately  segmented  and 
thus  often  semantically  meaningless  object.  Compared  with 
existing IRCs, Cortcha has the following advantages: 
•  No  need  to  manually  label  any  image.  Context-based  object 
semantically 
it  possible 
recognition  makes 
meaningless  objects 
in  our  design.  Therefore  object 
segmentation  can  be  done  by  computers  and  the  whole 
challenge generation process can be fully automated. 
to  use 
•  An  unlimited  number  of  types  of  objects  can  be  used  in 
Cortcha. This can effectively disable the learning process in 
machine learning attacks.  
•  Cortcha  is  scalable.  In  Cortcha,  the  tasks  of  source  image 
collection  and  challenge  generation  can  both  be  automated. 
By  crawling  the  Internet,  a  large  number  of  images  can  be 
quickly and continuously added to Cortcha's image database. 
Cortcha  can  therefore  meet  the  demanding  requirement  of  a 
large scale application such as Hotmail. 
6.1  Detailed Description 
Cortcha consists of the following stages: collecting images into the 
database, generating challenges, displaying challenges, and grading 
responses.  
6.1.1  Image Database  
Cortcha relies on a secret database of images. The huge number of 
images in the Internet combined with the fact that the content-based 
image  retrieval  at  the  Internet  scale  is  still  in  its  infancy  makes  it 
feasible  to  convert  these  public  images  into  Cortcha’s  secret 
database. It is highly unlikely for adversaries to find out the original 
Internet  image  used  in  a  Cortcha  challenge  before  the  current 
CAPTCHA session expires.  
Not  all  images  are  suitable  for  Cortcha.  We  discard  small-sized 
images  as  well  as  noisy  ones  which  have  a  large  ratio  of  high 
frequency  energy  to  low  frequency  energy.  We  also  discard 
monotonic  images,  whose  absolute  gradient  values  are  on  average 
small  or  whose  histogram  entropy  is  small.  However,  instead  of 
discarding large images, we crop them into suitable sizes.  
6.1.2  Image Segmentation and Object Selection  
An image is first processed to identify its salient objects. We apply 
the  JSEG  [28]  method  to  segment  the  image  into  objects.  The 
195 
boundary of each object is refined to align with the gradient edges. 
Small-sized objects are  merged with their best matched neighbors.   
We  then  assign  each  object  a  perceptual  significance  value,  which 
is calculated with the saliency detection scheme proposed in [29].  
Not all the resulting objects are suitable as the object to be cropped 
from  the  image  for  generating  a  challenge.  We  have  observed 
improved  usability  when  both  the  object  to  be  cropped  and  its 
surrounding  context  in  the  image  are  semantically  meaningful. 
Humans  can  correlate  the  semantics  of  an  object  with  that  of  the 
surrounding  context 
in  solving  a  challenge.  Such  semantic 
correlation  cannot  be  exploited  by  computers.  This  observation 
leads us to discard objects with a small significance value and those 
that  are  thin,  monotonic,  or  overly  large-sized.  An  object’s 
thickness  is  measured  by  the  maximum  value  of  its  distance 
transform. A thin or monotonic object tends to carry little semantic 
information. A large object tends to make its surrounding context of 
little semantic meaning.  
We also discard objects which share local or global similarity with 
the remaining image. Such similarity may be exploited by attackers 
to  deduce  a  correct  answer  to  a  challenge.  Local  similarity  is 
calculated  by  comparing  the  local  color  histogram  and  texture  on 
both sides of the object’s boundary.  Global similarity is calculated 
by  using  SIFT  [30]  to  extract  scale-invariant  local  features.  The 
features  from  the  objects  are  compared  with  those  from  the 
remaining  image  to  detect  any  similar  object  in  the  remaining 
image.  
in 
terms  of  cognition,  carrying 
If there exists any survived object at the end of the above process, 
the  image,  along  with  the  survived  objects,  is  inserted  into 
Cortcha’s  database  for  future  use.  With  all  the  measures  adopted 
above,  it  is  still  possible  that  a  survived  object  is  segmented 
incorrectly 
little  semantic 
information.  Cortcha  allows  such  a  case  since  the  context  in  the 
inpainted  image  can  be  leveraged  by  humans  in  recognizing  the 
object.  This  is  a  key  advantage  over  other  IRCs  such  as  Pix  [21], 
Chew  and  Tygar  [11],  Asirra  [15],  and the orientation  CPATCHA 
[16],  which  all  require  semantically  meaningful  objects,  and  thus 
have to involve human labors to label or select suitable images. On 
the  contrary,  the  image  segmentation  and  object  selection  process 
in Cortcha can be fully automated. 
6.1.3  Image Inpainting 
To  generate  a  challenge,  an  image  is  randomly  selected  from  the 
database.  Then,  an  object  is  randomly  selected  from  the  objects 
stored along with the image. The image and its objects are then all 
deleted from the database. A buffer region of n-pixels surrounding 
the object is created in the image. The object and the buffer region 
are  then  cropped  from  the  image.  The  buffer  region  is  used  to 
remove  possible  traces  of  local  similarity  between  the  object  and 
the  remaining  image.  The  cropped  region  is  then  filled  with  an 
inpainting algorithm modified from [27], as described next. 
We  first  locate  a  region  surrounding  the  cropped  region  and 
calculate its color histogram. The database is then searched to find 
an image that matches the color histogram best. The found image is 
used  as  the  primary  source  while  the  remaining  image  as  the 
secondary source in inpainting. The hole to be filled is divided into 
blocks.  These  blocks  are  filled  sequentially.  In  filling  a  block,  a 
matching  block  from  the  source  is  needed.  The  primary  source  is 
searched first for a matching block. If no matching block is found, 
the  secondary  source  is  searched  to  find  a  set  of  matching  blocks. 
We then randomly select a block from the set as the source block. It 
is possible to use several images from the database as the primary 
source for the inpainting process.  
Two  scheduling  schemes  are  used  to  determine  which  block  to  be 
filled  next.  The  first  scheme  places  a  block  with  a  large  curvature 
and a shorter distance to the cropped boundary at a higher priority. 
The  second  scheme  treats  a  block  with  structured  neighboring 
blocks at higher priority. The first schedule is applied to boundary 
blocks  of  the  cropped  region  while  the  second  schedule  is  applied 
to  internal  blocks.  For  the  blocks  lying  between  the  two  types  of 
blocks,  either  schedule  can  be  applied,  depending  on  a  random 
selection  process.  The  first  schedule  ensures  smooth  transition  at 
the boundary while the second schedule maintains structured filling. 
Sharp changes at the boundary might be correlated with the contour 
of  the  detached  object.  Lack  of  structures  may  indicate  a  filling 
region. They both can help an attacker solve a challenge.   
If any part of the detached object’s boundary lies in the boundary of 
the image, that part may indicate the block’s location in the image. 
This leaking information exploitable by attackers can be effectively 
removed  by  applying  outpainting,  an  inpainting  process  for  the 
reversal  direction,  to  grow  the  object  beyond  its  boundary  at  the 
part that lies in the image’s boundary. As described later in Section 
6.2, the extra pixels “filled” by the outpainting process are invisible 
when  the  detached  object  is  aligned  correctly  with  the  inpainted 
image in solving a Cortcha challenge.  
6.1.4  Generating a Challenge 
The  detached  object,  outpainted if  necessary,  is  used  to  search  the 
database to find the best matched L-1 objects in the image database. 
These objects are from distinct images. The search is based on the 
color  histogram  and  the  complexity,  measured  as  the  averaged 
absolute  values  of 
the  object’s  gradient.  More  advanced 
technologies  such  as  SIFT  [30]  can  also  be  applied.  These  L-1 
objects are optionally further processed by warping, rotating, or, if 
lacking of structures, randomly embedding with a similarly colored 
visual object. The resulting objects are used as decoy objects. These 
optional distortions make a decoy object look odd to humans so that 
the  authentic  object  can  be  easily  identified  by  human  eyes.  If  the 
detached object can be detected by a computer, e.g., a human or a 
cat face, similar computer-detectable objects are retrieved from the 
database  as  decoy  objects.  None  of  the  optional  distortions  is 
applied  in  this  case.  The  reason  to  treat  generic  objects  and 
computer-detectable  objects  differently  is  to  prevent  attacks  from 
“recognizing” an object or detecting the distortion applied to decoy 
objects to solve a challenge. 
The  detached  object  and  its  L-1  decoys  form  L  candidate  objects. 
They, as well as the inpainted image, are scaled in size by a factor 
that  is  empirically  chosen.  We  use  the  bicubic  interpolation  for 
image  scaling.  A  random  noise  is  then  added  to  the  scaled  image 
and  candidate  objects.  The  purpose  of  both  image  scaling  and 
random noise is to remove any quantization or other patterns in an 
image  that  can  be  exploited  to  deduce  the  inpainted  region  or  the 
detached object.   
6.2  Solving Cortcha Challenges 
A  Cortcha  challenge  displays  an  inpainted  image  along  with  L 
candidate  objects.  Figure  7  shows  an  actual  challenge  from  our 
current implementation, in which eight candidate objects were used. 
A  user  selects  a  candidate  object,  and  drags  it  to  move  around  or 
drop to a position of the inpainted image. Wherever the object is on 
top of the inpainted image, surrounding the object, a buffer region 
(of the same width as we use in the challenge generation process) is 
196 
created.  The  buffer  region  is  cropped  and  then  filled  by  an  image 
smoothing  method.  Effectively,  a  composite  image  is  created  by 
combining the inpainted image and the candidate object on the spot. 
The resulting composite image is presented to the user, but only the 
pixels within the inpainted image’s boundary are visible. As a result, 
when  the  detached  object  is  corrected  aligned  with  the  inpainted 
image,  the  outpainted  portion,  if  exists,  is  invisible.  At  each  trial 
location,  if  the  composite  image  looks  natural  and  semantically 
meaningful, the detached object and its due position are found. The 
challenge  is  thus  solved.  Figure  8  shows  the  result  when  the 
detached object is correctly placed back. 
Figure 7: A Cortcha challenge with 8 candidate objects on  
the left and the inpainted image on the right. 
Figure 8. A successfully solved Cortcha challenge: the right 
panel shows the composite image when the detached  
object was placed at the correct position. 
6.3  Usability 
6.3.1  Experimental Settings 
Our  database  included  30,000  images  that  we  crawled  from  the 
Internet.  The  longest  side  of  each  image  was  500  pixels.  350 
Cortcha challenges were then generated from this database. All the 
thresholds  needed  in  generating  these  challenges  were  empirically 
determined  from  a  small  set  of  representative  samples,  and  then 
applied  to  all  the  images.  The  average  time  for  generating  a 
challenge (following the whole process as described in Section 6.1) 
was  122s  on  a  PC  with  3.2GHz  Intel  P4  and  2GB  memory.  Note 
that many steps in this process can be performed offline. Therefore, 
offline  preprocessing  will  significantly  reduce  the  average  time 
required for online generation of challenges.  
A  website  was  used  in  our  usability  study.  A  participant  browsed 
the  website  to  start  a  test.  Each  test  consisted  of  20  randomly 
selected  Cortcha  challenges  presented  sequentially.  The  responses 
and solving times were recorded by our web server. After the test, 
each  participant  was  asked  to  answer  a  questionnaire  as  an  exit 
survey.  We  invited  a  group  of  interns  who  had  never  exposed  to 
Cortcha  to  participate  in  our  study.  Most  of  them  were  graduate 
students in their twenties. 84 volunteers participated and completed 
the  study.  In  our  experiment,  the  position  tolerance  for  a  response 
was set to be 10.0% of the inpainted image’s height and width. The 
buffer region was set to have a width of n=3 pixels. 
6.3.2  Results 
We  examine  Cortcha  based  on  the  following  three  components, 
partially quoted from [31]: 
1.  Learnability. Figure 9 shows the average solving time for each 
of the 20 sequentially presented challenges. Note that different 