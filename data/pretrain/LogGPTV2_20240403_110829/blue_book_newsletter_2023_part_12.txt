    If the dataset has snapshots you need to rename them too. They must be renamed within the same pool and dataset from which they were created though. For example:
    ```bash
    zfs rename tank/home/cindys@083006 tank/home/cindys@today
    ```
    In addition, the following shortcut syntax is equivalent to the preceding syntax:
    ```bash
    zfs rename tank/home/cindys@083006 today
    ```
    The following snapshot rename operation is not supported because the target pool and file system name are different from the pool and file system where the snapshot was created:
    ```bash
    $: zfs rename tank/home/cindys@today pool/home/cindys@saturday
    cannot rename to 'pool/home/cindys@today': snapshots must be part of same
    dataset
    ```
    You can recursively rename snapshots by using the `zfs rename -r` command. For example:
    ```bash
    $: zfs list
    NAME                         USED  AVAIL  REFER  MOUNTPOINT
    users                        270K  16.5G    22K  /users
    users/home                    76K  16.5G    22K  /users/home
    users/home@yesterday            0      -    22K  -
    users/home/markm              18K  16.5G    18K  /users/home/markm
    users/home/markm@yesterday      0      -    18K  -
    users/home/marks              18K  16.5G    18K  /users/home/marks
    users/home/marks@yesterday      0      -    18K  -
    users/home/neil               18K  16.5G    18K  /users/home/neil
    users/home/neil@yesterday       0      -    18K  -
    $: zfs rename -r users/home@yesterday @2daysago
    $: zfs list -r users/home
    NAME                        USED  AVAIL  REFER  MOUNTPOINT
    users/home                   76K  16.5G    22K  /users/home
    users/home@2daysago            0      -    22K  -
    users/home/markm             18K  16.5G    18K  /users/home/markm
    users/home/markm@2daysago      0      -    18K  -
    users/home/marks             18K  16.5G    18K  /users/home/marks
    users/home/marks@2daysago      0      -    18K  -
    users/home/neil              18K  16.5G    18K  /users/home/neil
    users/home/neil@2daysago       0      -    18K  -
    ```
* New: [See the differences between two backups.](zfs.md#see-the-differences-between-two-backups)
    To identify the differences between two snapshots, use syntax similar to the following:
    ```bash
    $ zfs diff tank/home/tim@snap1 tank/home/tim@snap2
    M       /tank/home/tim/
    +       /tank/home/tim/fileB
    ```
    The following table summarizes the file or directory changes that are identified by the `zfs diff` command.
    | File or Directory Change | Identifier |
    | --- | --- |
    | File or directory has been modified or file or directory link has changed | M |
    | File or directory is present in the older snapshot but not in the more recent snapshot | — |
    | File or directory is present in the more recent snapshot but not in the older snapshot | + |
    | File or directory has been renamed | R |
* New: [Create a cold backup of a series of datasets.](zfs.md#create-a-cold-backup-of-a-series-of-datasets)
    If you've used the `-o keyformat=raw -o keylocation=file:///etc/zfs/keys/home.key` arguments to encrypt your datasets you can't use a `keyformat=passphase` encryption on the cold storage device. You need to copy those keys on the disk. One way of doing it is to:
    - Create a 100M LUKS partition protected with a passphrase where you store the keys.
    - The rest of the space is left for a partition for the zpool.
* New: [Clear a permanent ZFS error in a healthy pool.](zfs.md#clear-a-permanent-zfs-error-in-a-healthy-pool)
    Sometimes when you do a `zpool status` you may see that the pool is healthy but that there are "Permanent errors" that may point to files themselves or directly to memory locations.
    You can read [this long discussion](https://github.com/openzfs/zfs/discussions/9705) on what does these permanent errors mean, but what solved the issue for me was to run a new scrub
    `zpool scrub my_pool`
    It takes a long time to run, so be patient.
* New: [ZFS pool is in suspended mode.](zfs.md#zfs-pool-is-in-suspended-mode)
    Probably because you've unplugged a device without unmounting it.
    If you want to remount the device [you can follow these steps](https://github.com/openzfsonosx/zfs/issues/104#issuecomment-30344347) to symlink the new devfs entries to where zfs thinks the vdev is. That way you can regain access to the pool without a reboot.
    So if zpool status says the vdev is /dev/disk2s1, but the reattached drive is at disk4, then do the following:
    ```bash
    cd /dev
    sudo rm -f disk2s1
    sudo ln -s disk4s1 disk2s1
    sudo zpool clear -F WD_1TB
    sudo zpool export WD_1TB
    sudo rm disk2s1
    sudo zpool import WD_1TB
    ```
    If you don't care about the zpool anymore, sadly your only solution is to [reboot the server](https://github.com/openzfs/zfs/issues/5242). Real ugly, so be careful when you umount zpools.
* New: [Prune snapshots.](sanoid.md#prune-snapshots)
    If you want to manually prune the snapshots after you tweaked `sanoid.conf` you can run:
    ```bash
    sanoid --prune-snapshots
    ```
* New: [Send encrypted backups to a encrypted dataset.](sanoid.md#send-encrypted-backups-to-a-encrypted-dataset)
    `syncoid`'s default behaviour is to create the destination dataset without encryption so the snapshots are transferred and can be read without encryption. You can check this with the `zfs get encryption,keylocation,keyformat` command both on source and destination.
    To prevent this from happening you have to [pass the `--sendoptions='w'](https://github.com/jimsalterjrs/sanoid/issues/548) to `syncoid` so that it tells zfs to send a raw stream. If you do so, you also need to [transfer the key file](https://github.com/jimsalterjrs/sanoid/issues/648) to the destination server so that it can do a `zfs loadkey` and then mount the dataset. For example:
    ```bash
    server-host:$ sudo zfs list -t filesystem
    NAME                    USED  AVAIL     REFER  MOUNTPOINT
    server_data             232M  38.1G      230M  /var/server_data
    server_data/log         111K  38.1G      111K  /var/server_data/log
    server_data/mail        111K  38.1G      111K  /var/server_data/mail
    server_data/nextcloud   111K  38.1G      111K  /var/server_data/nextcloud
    server_data/postgres    111K  38.1G      111K  /var/server_data/postgres
    server-host:$ sudo zfs get keylocation server_data/nextcloud
    NAME                   PROPERTY     VALUE                                    SOURCE
    server_data/nextcloud  keylocation  file:///root/zfs_dataset_nextcloud_pass  local
    server-host:$ sudo syncoid --recursive --skip-parent --sendoptions=w server_data PI:EMAIL:backup_pool
    INFO: Sending oldest full snapshot server_data/log@autosnap_2021-06-18_18:33:42_yearly (~ 49 KB) to new target filesystem:
    17.0KiB 0:00:00 [1.79MiB/s] [=================================================>                                                                                                  ] 34%
    INFO: Updating new target filesystem with incremental server_data/log@autosnap_2021-06-18_18:33:42_yearly ... syncoid_caedrium.com_2021-06-22:10:12:55 (~ 15 KB):
    41.2KiB 0:00:00 [78.4KiB/s] [===================================================================================================================================================] 270%
    INFO: Sending oldest full snapshot server_data/mail@autosnap_2021-06-18_18:33:42_yearly (~ 49 KB) to new target filesystem:
    17.0KiB 0:00:00 [ 921KiB/s] [=================================================>                                                                                                  ] 34%
    INFO: Updating new target filesystem with incremental server_data/mail@autosnap_2021-06-18_18:33:42_yearly ... syncoid_caedrium.com_2021-06-22:10:13:14 (~ 15 KB):
    41.2KiB 0:00:00 [49.4KiB/s] [===================================================================================================================================================] 270%
    INFO: Sending oldest full snapshot server_data/nextcloud@autosnap_2021-06-18_18:33:42_yearly (~ 49 KB) to new target filesystem:
    17.0KiB 0:00:00 [ 870KiB/s] [=================================================>                                                                                                  ] 34%
    INFO: Updating new target filesystem with incremental server_data/nextcloud@autosnap_2021-06-18_18:33:42_yearly ... syncoid_caedrium.com_2021-06-22:10:13:42 (~ 15 KB):
    41.2KiB 0:00:00 [50.4KiB/s] [===================================================================================================================================================] 270%
    INFO: Sending oldest full snapshot server_data/postgres@autosnap_2021-06-18_18:33:42_yearly (~ 50 KB) to new target filesystem:
    17.0KiB 0:00:00 [1.36MiB/s] [===============================================>                                                                                                    ] 33%
    INFO: Updating new target filesystem with incremental server_data/postgres@autosnap_2021-06-18_18:33:42_yearly ... syncoid_caedrium.com_2021-06-22:10:14:11 (~ 15 KB):
    41.2KiB 0:00:00 [48.9KiB/s] [===================================================================================================================================================] 270%
    server-host:$ sudo scp /root/zfs_dataset_nextcloud_pass 192.168.122.94:
    ```
    ```bash
    backup-host:$ sudo zfs set keylocation=file:///root/zfs_dataset_nextcloud_pass  backup_pool/nextcloud
    backup-host:$ sudo zfs load-key backup_pool/nextcloud
    backup-host:$ sudo zfs mount backup_pool/nextcloud
    ```
    If you also want to keep the `encryptionroot` you need to [let zfs take care of the recursion instead of syncoid](https://github.com/jimsalterjrs/sanoid/issues/614). In this case you can't use syncoid's stuff like `--exclude` from the manpage of zfs:
    ```
    -R, --replicate
       Generate a replication stream package, which will replicate the specified file system, and all descendent file systems, up to the named snapshot.  When received, all properties, snap‐
       shots, descendent file systems, and clones are preserved.
       If the -i or -I flags are used in conjunction with the -R flag, an incremental replication stream is generated.  The current values of properties, and current snapshot and file system
       names are set when the stream is received.  If the -F flag is specified when this stream is received, snapshots and file systems that do not exist on the sending side are destroyed.
       If the -R flag is used to send encrypted datasets, then -w must also be specified.
    ```
    In this case this should work:
    ```bash
    /sbin/syncoid --recursive --force-delete --sendoptions="Rw" zpool/backups PI:EMAIL:zpool/backups
    ```
* New: [Repair a DEGRADED pool.](zfs.md#repair-a-degraded-pool)
    First let’s offline the device we are going to replace:
    ```bash
    zpool offline tank0 ata-WDC_WD2003FZEX-00SRLA0_WD-xxxxxxxxxxxx
    ```
    Now let us have a look at the pool status.
    ```bash
    zpool status
    NAME                                            STATE     READ WRITE CKSUM
    tank0                                           DEGRADED     0     0     0
      raidz2-1                                      DEGRADED     0     0     0
        ata-TOSHIBA_HDWN180_xxxxxxxxxxxx            ONLINE       0     0     0
        ata-TOSHIBA_HDWN180_xxxxxxxxxxxx            ONLINE       0     0     0
        ata-TOSHIBA_HDWN180_xxxxxxxxxxxx            ONLINE       0     0     0
        ata-WDC_WD80EFZX-68UW8N0_xxxxxxxx           ONLINE       0     0     0
        ata-TOSHIBA_HDWG180_xxxxxxxxxxxx            ONLINE       0     0     0
        ata-TOSHIBA_HDWG180_xxxxxxxxxxxx            ONLINE       0     0     0
        ata-WDC_WD2003FZEX-00SRLA0_WD-xxxxxxxxxxxx  OFFLINE      0     0     0
        ata-ST4000VX007-2DT166_xxxxxxxx             ONLINE       0     0     0
    ```
    Sweet, the device is offline (last time it didn't show as offline for me, but the offline command returned a status code of 0).
    Time to shut the server down and physically replace the disk.
    ```bash
    shutdown -h now
    ```
    When you start again the server, it’s time to instruct ZFS to replace the removed device with the disk we just installed.
    ```bash
    zpool replace tank0 \
        ata-WDC_WD2003FZEX-00SRLA0_WD-xxxxxxxxxxxx \
        /dev/disk/by-id/ata-TOSHIBA_HDWG180_xxxxxxxxxxxx
    ```
    ```bash
    zpool status tank0
    pool: main
    state: DEGRADED
    status: One or more devices is currently being resilvered.  The pool will
            continue to function, possibly in a degraded state.
    action: Wait for the resilver to complete.
      scan: resilver in progress since Fri Sep 22 12:40:28 2023
            4.00T scanned at 6.85G/s, 222G issued at 380M/s, 24.3T total
            54.7G resilvered, 0.89% done, 18:28:03 to go
    NAME                                              STATE     READ WRITE CKSUM
    tank0                                             DEGRADED     0     0     0
      raidz2-1                                        DEGRADED     0     0     0
        ata-TOSHIBA_HDWN180_xxxxxxxxxxxx              ONLINE       0     0     0
        ata-TOSHIBA_HDWN180_xxxxxxxxxxxx              ONLINE       0     0     0
        ata-TOSHIBA_HDWN180_xxxxxxxxxxxx              ONLINE       0     0     0
        ata-WDC_WD80EFZX-68UW8N0_xxxxxxxx             ONLINE       0     0     0
        ata-TOSHIBA_HDWG180_xxxxxxxxxxxx              ONLINE       0     0     0
        ata-TOSHIBA_HDWG180_xxxxxxxxxxxx              ONLINE       0     0     0
        replacing-6                                   DEGRADED     0     0     0
          ata-WDC_WD2003FZEX-00SRLA0_WD-xxxxxxxxxxxx  OFFLINE      0     0     0
          ata-TOSHIBA_HDWG180_xxxxxxxxxxxx            ONLINE       0     0     0  (resilvering)
        ata-ST4000VX007-2DT166_xxxxxxxx               ONLINE       0     0     0
    ```
    The disk is replaced and getting resilvered (which may take a long time to run (18 hours in a 8TB disk in my case).
    Once the resilvering is done; this is what the pool looks like.
    ```bash
    zpool list
    NAME      SIZE  ALLOC   FREE  EXPANDSZ   FRAG    CAP  DEDUP  HEALTH  ALTROOT
    tank0    43.5T  33.0T  10.5T     14.5T     7%    75%  1.00x  ONLINE  -
    ```
    If you want to read other blogs that have covered the same topic check out [1](https://madaboutbrighton.net/articles/replace-disk-in-zfs-pool).
* New: Stop a ZFS scrub.
    ```bash
    zpool scrub -s my_pool
    ```
* New: [Mount a dataset that is encrypted.](zfs.md#mount-a-dataset-that-is-encrypted)
    If your dataset is encrypted using a key file you need to:
    - Mount the device that has your keys
    - Import the pool without loading the key because you want to override the keylocation attribute with zfs load-key. Without the -l option, any encrypted datasets won't be mounted, which is what you want.
    - Load the key(s) for the dataset(s)
    - Mount the dataset(s).
    ```bash
    zpool import rpool    # without the `-l` option!
    zfs load-key -L file:///path/to/keyfile rpool
    zfs mount rpool
    ```
* New: [Umount a pool.](zfs.md#umount-a-pool)
    ```bash
    zpool export pool-name
    ```
* Correction: [Improve the Repair a DEGRADED pool instructions.](zfs.md#repair-a-degraded-pool)
    First you need to make sure that it is in fact a problem of the disk. Check the `dmesg` to see if there are any traces of reading errors, or SATA cable errors.
    A friend suggested to mark the disk as healthy and do a resilver on the same disk. If the error is reproduced in the next days, then replace the disk. A safer approach is to resilver on a new disk, analyze the disk when it's not connected to the pool, and if you feel it's safe then save it as a cold spare.
* New: [Remove all snapshots of a dataset.](zfs.md#remove-all-snapshots-of-a-dataset)
    ```bash
    zfs list -t snapshot -o name path/to/dataset | tail -n+2 | tac | xargs -n 1 zfs destroy -r
    ```
### [ZFS Prometheus exporter](zfs_exporter.md)
* New: Introduce the ZFS exporter.
    You can use a [zfs exporter](https://github.com/pdf/zfs_exporter) to create alerts on your ZFS pools, filesystems, snapshots and volumes.
    It's not easy to match the exporter metrics with the output of `zfs list -o space`. Here is a correlation table:
    - USED: `zfs_dataset_used_bytes{type="filesystem"}`
    - AVAIL: `zfs_dataset_available_bytes{type="filesystem"}`
    - LUSED: `zfs_dataset_logical_used_bytes{type="filesystem"}`
    - USEDDS: `zfs_dataset_used_by_dataset_bytes="filesystem"}`
    - USEDSNAP: Currently there [is no published metric](https://github.com/pdf/zfs_exporter/issues/32) to get this data. You can either use `zfs_dataset_used_bytes - zfs_dataset_used_by_dataset_bytes` which will show wrong data if the dataset has children or try to do `sum by (hostname,filesystem) (zfs_dataset_used_bytes{type='snapshot'})` which returns smaller sizes than expected.
    It also covers the [installation](zfs_exporter.md#installation) as well
    as some nice [alerts](zfs_exporter.md#configure-the-alerts).
* Correction: Improve alerts.
* Correction: Update the alerts to the more curated version.
* New: [Useful inhibits.](zfs_exporter.md#useful-inhibits)
    Some you may want to inhibit some of these rules for some of your datasets. These subsections should be added to the `alertmanager.yml` file under the `inhibit_rules` field.
    Ignore snapshots on some datasets: Sometimes you don't want to do snapshots on a dataset
    ```yaml
    - target_matchers:
        - alertname = ZfsDatasetWithNoSnapshotsError
        - hostname = my_server_1
        - filesystem = tmp
    ```
    Ignore snapshots growth: Sometimes you don't mind if the size of the data saved in the filesystems doesn't change too much between snapshots doesn't change much specially in the most frequent backups because you prefer to keep the backup cadence. It's interesting to have the alert though so that you can get notified of the datasets that don't change that much so you can tweak your backup policy (even if zfs snapshots are almost free).
    ```yaml
      - target_matchers:
        - alertname =~ "ZfsSnapshotType(Frequently|Hourly)SizeError"
        - filesystem =~ "(media/(docs|music))"
    ```
## Monitoring
### [Loki](loki.md)
* New: Introduce loki.
    [Loki](https://grafana.com/docs/loki/latest/) is a set of components that can be composed into a fully featured logging stack.
    Unlike other logging systems, Loki is built around the idea of only indexing metadata about your logs: labels (just like Prometheus labels). Log data itself is then compressed and stored in chunks in object stores such as Amazon Simple Storage Service (S3) or Google Cloud Storage (GCS), or even locally on the filesystem.
    A small index and highly compressed chunks simplifies the operation and significantly lowers the cost of Loki.
* New: [How to install loki.](loki.md#installation)