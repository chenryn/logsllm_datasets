   如果没有与其他人和机器的互动，SRE的工作就无法完成。所有这些参与者（人类和机器）都起着所谓认知主体的作用。不可能孤立地描述任何一方的工作。它们的互动是基于彼此的能力、意图和对情况的理解。他们协调，合作和推理他人的意图。他们一起形成了一个联合认知系统，简称JCS（Hollnagel和Woods，2006）。故障中的SRE工作时需要完成有关自动化的推理。自动化实现了什么功能？接下来会怎么做？它如何了解情况？如果我们告诉它这样做或那个会发生什么？通常，自动化是强大、无声的，很难指引（Woods，1997）。要想使自动化成为更有用的认知“伙伴”，主要的努力侧重于关键系统的保障，如飞机驾驶舱（1996年由Billings提出）或医疗设备（2005年由Nemeth等人提出）。面向互联网的业务系统日益重要，这加大了这一领域自动化的风险。SRE的生涯种充满了与自动化相关的故障案例。任何在计划对测试系统进行更新时意外更新到生产系统的人都肯定亲身体验过这一点！具有讽刺意味的是，人们如此习惯于臃肿的、笨拙的自动化系统，也习惯了对系统进行修修补补，以至于他们认为这是正常的。有个关于西装的笑话很好地说明了这一点。一个男人去买一套西装。试了一下后，他注意到手臂太长了。“没问题，”售货员说，“只要肘部弯一下，然后把胳膊抱在胸前就好了”。他确实如此做了，但后来又注意到衣服后面有点长。“只需要弯一点腰，”售货员说。然后他又注意到右裤腿太短，而左腿太长。“只要你扭一点点屁股就好了，”销售员说。“对了，现在你看起来完美。”于是，男人买了西装，走在街上，走过两个坐在长凳上的老太太。“哦，”一个老太太说，“看看那个可怜的人，他的姿势怎么那么别扭，时因为他很难过吗？”“是的，他可能是很难过吧，”另一个老太太回答到，”但他的西装肯定不合身!“有时候自动化系统表现不如人意，这时候人类认知主体必须做额外的认知工作来弥补它的不足。如果已经是系统繁忙的时候需要对自动化系统进行指导，会让人感觉到“臃肿”（Cook等人，1991年）。目前部署在故障期间使用的大部分自动化有这种问题。
尽管我们知道如何与自动化系统和平共处（Klein等人，2004年），但因为所需的努力和技术都在快速变化，因此往往只有面对最严重的问题时才能达到最佳配合。然而，很明显，JCS整体表现水平的提高在于使所有认知主体都成为更好的团队成员（Klein等人，2004年）。  
知识校准问题
   SRE的工作取决于对事物如何运作、如何失效，可用干预措施以及这些干预措施的（可能）后果的了解。这将包括一般知识（例如特定操作系统的功能）、特定知识（例如特定系统的Redis是如何配置的）以及相当多样化的知识（例如明天安排的代码“冻结”将可能导致许多发布提前进行，所以今天可能比平时更具挑战性）。人们如何知道这些知识是最新的还是陈旧的？是什么触发了重新评估？在一个快速变化、复杂的世界里，没有人能有完整而详细的理解。某人如何知道他们当前的知识足以满足他们当前所执行的工作？在获取知识方面有哪些投资是值得的？
心理模型
研究人员经常使用心理模型这个术语来描述所收集的关于系统如何工作的知识（Gentner和Stevens，1983的讨论，见Cook，2018）。虽然一般知识的陈旧速度缓慢，但快速的变化往往导致更专业的知识快速陈旧。工程师知道这一点并更新他们的心智模型。所以他们会将对组件、子系统、网络和应用程序如何连接和交互等的知识与众多渠道的证据进行比较。
但是这提出了一个重要的问题：工程师如何知道他们的心理模型何时显著过时了，现代系统在不断变化。新代码的部署；新用户以新的方式强调系统；外部服务停止按预期工作......微妙的因素结合在一起，以产生新的交互。任何个人都不可能跟上所有这些变化——事实上，敏捷模型反映了这一点。鉴于发生了如此多的变化，而且许多变化都发生在人们视线外，工程师何时应该决定花费时间和精力来更新他们的心理模型，工程师应该如何将注意力集中在何处？这是知识校准问题。伍兹定理指出：“随着系统复杂性的增加，任何单一主体自己对该系统模型的准确性都迅速降低。”任何努力都不足以使整个系统的心理模型准确无误。甚至一个“足够好”的部分系统模型也会随着系统的变化而过时。个人能做的最好的事情就是试图维持一个足够准确和足够精确的心理模型，以满足当下的需求。
每个人都有独特的心理模型，往往与其他人的模型大相径庭。这既是资产，也成了问题。它是一种资产，因为组织中存在的许多不同的心理模型（比单个模型）反应了系统的更多方面。这也是一个问题，因为不同模型重叠的地方很可能不一致。个别心理模型很有可能出现不同意见，这反过来又需要识别和解决心理模型的差异。这种情况在#schematic_drawing_of_a_system_including_e中以图形展现（参见伍兹2018，第2.3节）。值得注意的是，所有与计算技术的交互都是通过图中的方框或圆框来展示的。这些共同构成了一种技术“接口”，显明了技术的用途。我们无法直接感知技术本身（计算机、程序、API和网络等）。因此，技术由屏幕上显示的文本和图像表示。人们使用键盘，鼠标等对基础技术采取行动，并通过表示评估其影响。他们通过心理模型解释反应，从这些相互作用中推断出基础技术的组成和功能。
整体上看，这里展示的人类工作在“在水平线之上”，而他们所使用的技术则是“在水平线之下”。
系统的架构图，包括展示线上方和下方的元素。（©2016由理查德·库克创作，许可使用）
事件触发个人重新校准事件触发个人重新校准
  当一个人遇到异常行为并开始探索其来源和后果时，事件就会开始。事件首先是以异常方式呈现的。预期和观察到的内容之间的差异是接下来发生的事情的驱动因素。这种差异是观察者的心理模型与系统的某部分无法校准的信号。心理模型可以是粗略的或高度精确的，但异常是证明它不准确的证据。
事件响应在一大意义上是重新校准观察者对系统某一部分的心理模型的过程。搜索异常的“目的”在于对心理模型的更新，用于避免问题再次出现。特别要注意这里强调了系统的某一部分。复杂性和变化将挫败任何在广泛的心理模型更新的尝试。观察者对心理模型的重新校准受事件限制，以调查过程为中心。
我们假设专家拥有他们所理解的系统特定部分的细粒度、准确的心理模型，这些模型是关键的或可能失败的。他们可以利用这些心理模型快速解决问题，并在解决问题时，为满足他们将来需求而更新他们的心理模型。即使新手和不太专业的从业者从更粗糙、不太准确的心理模型开始，但事件的经验可以让他们增强他们某一部分系统的心理模型。事件还可以作为拓展专业知识的平台。重大事件响应很少由单人进行相应。新手参与事件应对似乎促进了专业知识的拓展。观察异常情况的修复，这为新手提供了与专家一起完善其心理模型的机会。事件处理具有尖锐的重点，并呈现出现实世界的复杂性，其方式很难与更正式的培训活动相匹配。
事件是集体重新校准的机会
   个体面临的问题在较大的组织中是同样存在的：组织如何知道其对复杂系统的集体理解何时需要更新？鉴于可用的资源有限，组织应该如何投入时间和资源，保持人们对系统真正运作方式的洞察：知道它的漏洞是什么，以及未来会发生什么？
我们也可以利用事件来集中注意力。事件是来自底层系统有关故障所在位置的消息。更广泛地研究这些事件可以提供有关系统真正工作原理的有用见解，使相关人员能够更新其心理模型。事件指向系统中发生故障的部分。它们是这个系统中某一部分最相关的指标。事件可能对组织具有广泛帮助的想法并不新鲜。事故研究长期以来一直强调事故作为指针的价值（参见Woods等人的著作，2010年），质量理论鼓励将事故和窗户用于过程和问题（参见 Deming，1982年）。使用故障报告（Allspaw，2012）可以提供对系统及其操作的独特洞见。
这里的关键思想是：复杂性和持续的变化，这使得在“理解”现有系统方面做出的大范围的、一般性的努力相对低效。作为对比，事件指向需要重新校准系统的心理模型的特定位置。事件提供了及时的、高度相关的关于问题分布位置的信息。
我们承认，这种观点与通常用来管理事件的方法截然相反。在许多组织中，事件被收集、简化为数据库条目，并很快被遗忘。“数字化”管理要求快速解决事件，并将事件发生频率减少到某个级别。这样做的效果是忽略（或至少降低）了事件的价值，破坏了更深入、更彻底调查问题的起点。具有讽刺意味的是，如此昂贵的“数字化”数据很快就被抛弃了。这一切意味着什么？
事件非常频繁。对于许多系统，组织确认的事件速率是每天一两次。我们知道有些地方的频率要高得多。在许多公司中，应对事件被当成是时间和资源的消耗。显然，如果这种情况将继续下去，随着系统的复杂性和重要性的增加，事件的后果可能会倍增。由于系统和环境在不断变化，因此事件的影响、性质和影响都会发生变化。然而，同样真实的是，事件是有价值的信息来源，可以在适当的条件下和努力地获得。
事件将继续
  这种情况不会好转。相反，问题可能会变得更加困难。随着越来越多的业务功能嵌入到系统中，并且日常业务操作变得更加依赖于系统操作，系统操作的风险会不断上升。这些系统的复杂性不断增加。试图驯服这种复杂性有时会改变人类操作员的注意力，但却没有也不会消除操作员理解正在发生的事情的必要性。
与其他行业一样，技术进步似乎同时减少了重大事故的数量，同时也增强了其后果。结果是，重大事件的发生频率较低，但一些事件确实发生，其影响比过去更大。现代系统的连通性和响应性使得干扰传播比过去更快、更广泛。我们注意到，许多正在开发大型系统的机构都会含蓄地假定：未来的系统将理论上“无事故”。这是一个危险的技术幻想，可以说是一个魔咒。各种系统的历史，特别是信息技术的历史，都与这个想法相反。事件将继续发生，威胁始终存在，并要求我们关注。未能建立具有适合事件管理的系统的系统（技术和组织）可以说是失职的。
事件将导致代价
  事故的成本难以衡量，但肯定可能很大。周详的计算表明，一家主要航空公司的一天宕机可能造成超过2亿美元的损失。实际上无法计算已有事件造成的代价，例如 2012 年 Knight Capital 的崩溃。
事故的直接代价包括对收入的直接影响、响应成本等。#some_direct_costs_of_incidents列出了其中的一些。
事件的一些直接代价
| 事件 | 导致代价 |
|---|---|
| 宕机时间 |收入损失 服务条款对应的罚金 恢复工作的成本 || 宕机时间 |收入损失 服务条款对应的罚金 恢复工作的成本 |
| 响应 |应对事故的工作人员的薪酬 将员工的注意力转移到事件的可能代价 实施事后应对步骤的代价 |
| 组织开销 |维护事件跟踪系统 |
| 监管 |合规性报告 经济处罚 开发/运营中的法规干预 |