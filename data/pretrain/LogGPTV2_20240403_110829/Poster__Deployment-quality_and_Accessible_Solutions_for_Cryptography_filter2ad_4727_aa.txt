title:Poster: Deployment-quality and Accessible Solutions for Cryptography
Code Development
author:Sazzadur Rahaman and
Ya Xiao and
Sharmin Afrose and
Ke Tian and
Miles Frantz and
Na Meng and
Barton P. Miller and
Fahad Shaon and
Murat Kantarcioglu and
Danfeng (Daphne) Yao
POSTER: Deployment-quality and Accessible Solutions for
Cryptography Code Development
Sazzadur Rahaman1, Ya Xiao1, Sharmin Afrose1, Ke Tian1, Miles Frantz1, Na Meng1,
Barton P. Miller2, Fahad Shaon3, Murat Kantarcioglu3, Danfeng (Daphne) Yao1
1Computer Science, Virginia Tech, Blacksburg, VA
2 Computer Science, University of Wisconsin-Madison, Madison, WI
3 Computer Science, University of Texas at Dallas, Dallas, TX
{sazzad14,yax99,sharminafrose,ketian,frantzme,nm8247,danfeng}@vt.edu,
PI:EMAIL,{fahad.shaon,muratk}@utdallas.edu
ABSTRACT
Cryptographic API misuses seriously threaten software security.
Automatic screening of cryptographic misuse vulnerabilities has
been a popular and important line of research over the years. How-
ever, the vision of producing a scalable detection tool that devel-
opers can routinely use to screen millions of line of code has not
been achieved yet.
Our main technical goal is to attain a high precision and high
throughput approach based on specialized program analysis. Specifi-
cally, we design inter-procedural program slicing on top of a new on-
demand flow-, context- and field- sensitive data flow analysis. Our
current prototype named CryptoGuard can detect a wide range of
Java cryptographic API misuses with a precision of 98.61%, when
evaluated on 46 complex Apache Software Foundation projects
(including, Spark, Ranger, and Ofbiz). Our evaluation on 6,181 An-
droid apps also generated many security insights. We created a
comprehensive benchmark named CryptoApi-Bench with 40-unit
basic cases and 131-unit advanced cases for in-depth comparison
with leading solutions (e.g., SpotBugs, CrySL, Coverity). To make
CryptoGuard widely accessible, we are in the process of inte-
grating CryptoGuard with the Software Assurance Marketplace
(SWAMP). SWAMP is a popular no-cost service for continuous soft-
ware assurance and static code analysis.
CCS CONCEPTS
• Security and privacy → Software and application security.
INTRODUCTION
KEYWORDS
Accuracy; Cryptographic API Misuses; Static Program Analysis;
False Positive; False Negative; Benchmark; Java;
1 
Cryptography offers provable security guarantees in the presence
of adversaries. Various software libraries and frameworks provide
Permission to make digital or hard copies of part or all of this work for personal or 
classroom use is granted without fee provided that copies are not made or distributed 
for profit or commercial advantage and that copies bear this notice and the full citation 
on  the  first  page.  Copyrights  for  third-party  components  of  this  work  must  be 
honored. For all other uses, contact the Owner/Author.
CCS '19, November 11–15, 2019, London, United Kingdom
© 2019 Copyright is held by the owner/author(s).
ACM ISBN 978-1-4503-6747-9/19/11.
https://doi.org/10.1145/3319535.3363252
a variety of cryptographic APIs to support secure coding. Crypto-
graphic API misuses, such as exposed secrets, predictable random
numbers, and vulnerable certificate verification, have critical impact
on software security [7–9, 12].
Figure 1: Reduction of false positives with refinement in-
sights in 46 Apache projects and 6,181 Android apps. Top 6
rules with maximum reductions are shown [13].
The research solution that we aim in this project addresses the
pervasive problem of cryptographic coding vulnerabilities in real-
world software. Specifically, our ongoing goals are to produce high
quality code screening tools and make them accessible to the devel-
opers in various convenient form, including, standalone, IDE plugin
(e.g., Eclipse, IntelliJ IDEA), build tool plugin (e.g., Gradle, Maven),
code screening as a service (e.g., Software Assurance Marketplace
aka, SWAMP).
We have made substantial progress toward building a high ac-
curacy and low runtime static analysis solution for detecting 16
types of cryptographic and SSL/TLS API misuse vulnerabilities. The
main technical enabler is the use of highly optimized forward and
backward program slicing algorithms, which are built on top of on-
demand flow-, context- and field-sensitive data-flow analysis [13].
Threat model. Our prototype CryptoGuard [13]1 aims to de-
tect 16 types of Cryptographic and SSL/TLS API misuses. It de-
tects three types of predictable secrets (i.e., symmetric keys and
passwords), four types of SSL/TLS MitM attacks, two types of pre-
dictability of PRNGs, three types of chosen-ciphertext attacks (i.e.,
static salts and IVs, ECB mode of symmetric ciphers) and 4 types
1Available at https://github.com/CryptoGuardOSS/cryptoguard
[1,2] Predictable Keys [3] Hardcoded  KeyStore Pass[10] Predictable Salts[12]Predictable  IVs[13]<1000 PBE Iterations102103104105Number of Alerts (Log Scale)w/o RI (Apache)w/ RI (Apache)w/o RI (Android)w/ RI (Android)PosterCCS ’19, November 11–15, 2019, London, United Kingdom2545(a)
(b)
(c)
Figure 2: The impact of the orthogonal exploration depth on F1 scores and the number of discovered constants in (a), runtime
in (b), and analysis properties in (c) for 8 rules.
of brute-force attacks (i.e., less than 1000 password-based encryp-
tion (PBE) iterations, insecure symmetric, asymmetric, and crypto-
graphic hashes). We also categorize their severity into high, medium,
and low, based on i) attacker’s gain and ii) attack difficulty. Vul-
nerabilities from predictable secrets, SSL/TLS MitM, and insecure
Hash are immediately exploitable, hence are classified as high risks.
Vulnerabilities from predictability and CPA provide substantial ad-
vantages to attackers by significantly reducing attack efforts [14].
They are at medium-level risks. Brute-forcing ciphers, requiring
non-trivial effort, is low risk.
Detection accuracy. Most of the cryptographic vulnerabilities in
our threat model require finding constants. To improve detection
accuracy, our inter-procedural data-flow analysis adopts a set of
refinement insights that systematically discard false alerts. These
refinement insights (RI) are deduced by observing common pro-
gramming idioms and language restrictions to remove irrelevant
elements, i.e., resource identifiers, arguments about states of op-
erations, constants on infeasible paths, and bookkeeping values.
For eight of our rules, these refinement algorithms reduce the total
number of alerts by 76% in Apache and 80% in Android (Figure 1).
Our manual analysis shows that CryptoGuard has a precision of
98.61% on Apache [13].
Our analysis shows that the adoption of these refinement insights
is often more useful to clip orthogonal exploration in order to
achieve better performance.
We measure the impact of the orthogonal exploration, we con-
ducted an experiment with 30 Apache root-subprojects and varied
the clipping of the exploration from depth 1 to 10 (Figure 2) [13].
The total number of discovered constants across all projects in-
creases slightly with the depth (Figure 2(a) right Y-axis). However,
our manual analysis revealed that none of the new constants is a
true positive. Thus, the increase of the orthogonal exploration depth
does not improve the recall in this specific experiment, causing a
decrease in the F1 score (Figure 2(a) left Y-axis). Interestingly, the
runtime does not increase with the increasing depth (Figure 2(b)).
Figure 2(c) shows that the number of inter-procedural slices and
their average sizes are drastically reduced when the depth increases
from 1 to 2. The reason is that when the analysis explores inside a
method, influences on an argument the method’s specific invoca-
tion might become irrelevant. Given these observations, we set the
orthogonal exploration depth to 1 for the rest of our experiments,
as it returns the fewest number of irrelevant constants.
Runtime overhead and coverage. Existing flow-, context- and
field-sensitive analysis techniques build a super control-flow graph
of the entire program, which has a significant impact on runtime. In
contrast, our on-demand slicing algorithms run much faster, which
start from the slicing criteria and only propagate to the methods
that have the potential to impact security. Hence, a large portion
of the code base is not touched. For Apache projects, the average
runtime was 3.3 minutes with a median of around 1 minute. For
Android apps, we terminated unfinished analysis after 10 minutes.
The average runtime was 3.2 minutes with a median of 2.85 min-
utes [13].
Comparison with other tools. We construct CryptoApi-
Bench [6]2, a comprehensive benchmark with 171 cases for com-
paring the quality of cryptographic vulnerability detection tools.
CryptoApi-Bench covers 16 types of cryptographic misuses. In
CryptoApi-Bench, there are 40 basic test cases and 131 advanced
test cases. Experimental evaluation in Table 1 shows that Crypto-
Guard outperforms the state-of-the-art open source and commer-
cial solutions in this space, including CrySL [11], SpotBugs [2], and
the free online version of Coverity [1], in terms of precision and re-
call [13]. For runtime comparison, we ran CrySL and CryptoGuard
on 10 randomly selected Apache projects. Unfortunately, CrySL
crashed and exit prematurely for 7 of them. For the 3 completed
projects, CrySL is slower, but comparable on 2 projects (5 vs. 3 sec-
onds, 25 vs. 19 seconds). However, it is 3 orders of magnitude slower
than CryptoGuard on kerbaros-codec [13]. During our experi-
ments, we use CrySL 2.0 (commit id 5f531d1), SpotBugs 3.1.0 (from
SWAMP) and the results from Coverity was obtained before Mar
29, 2019. CrySL is an actively maintained project and got benefited