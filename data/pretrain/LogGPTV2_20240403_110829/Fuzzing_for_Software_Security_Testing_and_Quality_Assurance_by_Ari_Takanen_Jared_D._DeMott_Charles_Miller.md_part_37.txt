project at the University of Oulu developed several protocol-specific pregenerated
test suites for selected protocols many years ago. The PROTOS SNMP test-suite
was the tool used to discover the ASN.1 bugs mentioned in the sidebar.
8.3.8 What is Missing
This study excluded some well-known open-source fuzzers including SPIKE, Sulley,
and Peach. This is because these are fuzzing frameworks and not really ready-made
protocol specific fuzzers. They allow a user to generate fuzzed inputs based on a
specification file. If you attempted to test one of these fuzzers using the strategies
outlined in the chapter, you’d really be testing that particular format specification,
and not the actual framework itself. For this reason, and the fact it can take weeks
to produce a through specification file, these fuzzers were excluded. At the time of
the analysis, Sulley already contained sophisticated monitoring and analysis tools,
and SPIKE had layer 2 support.
8.4 The Targets
Three protocols were chosen for testing: FTP, SNMP, and DNS. They are extremely
common, for the most part they are relatively simple, and between them, they rep-
resent both ASCII-based and binary protocols. Additionally, while FTP and SNMP
servers were tested, a DNS client was examined. In each case, in an effort to avoid
finding real bugs, a well-established and hopefully robust open source implementa-
tion was selected.
The FTP server selected was ProFTPD. This well-established server was con-
figured mostly by its default settings. Some options were modified to ensure that
the fuzzer could run very quickly against the server without the server denying
6 https://www.ee.oulu.fi/roles/ouspg/Protos.
6760 Book.indb 257 12/22/17 10:50 AM
258 Fuzzer Comparison
connections. Other changes included ensuring an anonymous login was available,
including the ability to download and upload documents.
For SNMP, we tested the Net-SNMP server. The server was configured to accept
version 2 SNMP when presented with a suitable community string and version 3
SNMP when presented with a valid username (requiring no authentication). This
user was given read and write access. It is important to note that these configura-
tion options may have significant effect on the outcome because some fuzzers may
only be able to handle certain SNMP versions in addition to the way the code cov-
erage will obviously be affected. Of course, in the interest of fairness, the various
configurations were set before any fuzzer was examined.
Finally, for a DNS client we chose the dig utility from the BIND open-source
DNS library.
8.5 The Bugs
For each program implementation, 17 bugs were added to the applications. Of these
vulnerabilities, approximately half were buffer overflows and a fourth were format
string vulnerabilities. The remaining bugs were from other categories, such as com-
mand injection, double free, and wild pointer writes. Some of these bugs were made
easy to find and others were hidden deeper within the application. All bugs were
tested to ensure they were remotely accessible. None were detectable using the stan-
dard server or client (they weren’t THAT obvious). Each vulnerability was prefaced
with code that would log when they had been detected. Note that this means credit
may be given to a fuzzer for finding a bug even if it is likely that the fuzzer would
not have found this bug in real life. An example of this is if a fuzzer overflowed
a buffer by only one byte, the logging function would indicate the vulnerability
had been found when in reality this would be very difficult to detect (without the
monitoring described in Chapter 6, at least). On the positive side, having this log-
ging code eliminates any dependency on the type of monitoring used (custom or
that which comes with the fuzzer) and is completely accurate.
Below are several of the bugs for illustration.
8.5.1 FTp Bug 0
MODRET xfer_type(cmd_rec *cmd) {
...
if (strstr(get_full_cmd(cmd), “%”)!=NULL){
BUGREPORT(0);
}
char tempbuf[32];
snprintf(tempbuf, 32, “%s not understood”, get_full_cmd(cmd));
pr_response_add_err(R_500, tempbuf);
Here, we see the logging code trying to detect the use of the format identifier
‘%’. This bug occurs because the function pr_response_add_err is a function that
expects a format string for its second argument. In this case, the processing of the
XFER command contains a straightforward format string vulnerability.
6760 Book.indb 258 12/22/17 10:50 AM
8.6 Results 259
8.5.2 FTp Bugs 2, 16
MODRET xfer_stru(cmd_rec *cmd) {
...
cmd->argv[1][0] = toupper(cmd->argv[1][0]);
switch ((int) cmd->argv[1][0]) {
...
case ‘R’:
case ‘P’:
{
char tempbuf[64];
if(strlen(get_full_cmd(cmd)) > 34){
BUGREPORT(16);
}
if(strstr(get_full_cmd(cmd), “%”)!=NULL){
BUGREPORT(2);
}
sprintf(tempbuf, “’%s’ unsupported structure type.”,
get_full_cmd(cmd));
pr_response_add_err(R_504, tempbuf);
return ERROR(cmd);
}
Here, a buffer overflow and a format string issue exist in the processing of the
STRU FTP command. However, it is only possible to find this if the first character
of the string is ‘R’ or ‘P.’ These two bugs proved difficult for the fuzzers to find—
more on this later in Section 8.7.1.
These code snippets illustrate some example bugs that were added to the appli-
cations. As will be seen in the next section, some of these bugs were easier to find
than others for the fuzzers. After each comparison, some of the bugs that proved
decisive will be examined closer.
8.6 results
After all this setup about the bugs and the fuzzers, it remains to be seen how the
fuzzers did in this testing. Below we list which bugs each fuzzer found and how
much code coverage they obtained. The following abbreviations will be used in
the results:
• Random. This is purely random data fed into the interface. For fuzzing serv-
ers, this data was obtained with the “-R” option of GPF. For fuzzing clients, a
custom server that sent random data was used. This is mostly included for code
coverage comparison as it would not be expected to find any vulnerabilities.
• GPF Partial. This is GPF used with only a partial packet capture. For FTP
fuzzing, we used two initial inputs to GPF and TAOF. The first was a packet
capture consisting of most common FTP operations, including login, pass-
word, directory changing, and uploading and downloading files. GPF Partial
refers to this packet capture for the initial input.
6760 Book.indb 259 12/22/17 10:50 AM
260 Fuzzer Comparison
• GPF Full. This is GPF as described above except the packet capture used
contained every FTP command that ProFTPD accepted, according to its help
message. This is a more full and complete initial input. In both cases, GPF
was used with the ASCII tokAid.
• SuperGPF. This refers to SuperGPF using the full packet capture described
above along with a text file containing all valid FTP commands.
• TAOF Partial. TAOF with the partial packet capture described above.
• TAOF Full. TAOF with the full packet capture described above.
• ProxyFuzz Partial. ProxyFuzz with the partial packet capture available
for modification
• ProxyFuzz Full. ProxyFuzz with the full packet capture available.
• GPF Generic. GPF used with a generic binary tokAid.
• GPF SNMP. GPF used with a custom written SNMP tokAid.
Throughout all the testing, generation-based fuzzers were allowed to run through
all their test cases. Mutation-based fuzzers were allowed to run for 25,000 test cases
or seven hours, whichever came first. While this time period is somewhat arbitrary,
it was consistent with the amount of time required by most generation-based fuzzers.
8.6.1 FTp
Table 8.1 summarizes the bugs found while fuzzing the FTP server.
Figure 8.1 shows the percentage of bugs found as well as the total percentage of
code coverage obtained by each of the fuzzers. For this particular application, the
code coverage represents the percentage of source code lines executed after authen-
tication. This explains why the random fuzzer received 0% code coverage, since
it never successfully authenticated. For the other applications, the code coverage
statistics include the authentication code.
Detailed analysis of these numbers will follow the presentation of the results
for the three applications.
Table 8.1 Results of Fuzzing the FTP Server
Bug 0 1 3 4 5 9 11 12 13 14 15 16
GPF Random
GPF Partial X X X
GPF Full X X X X X
Super GPF X X X X X X
TAOF Partial
TAOF Full X X X
ProxyFuzz Partial
ProxyFuzz Full X X X
Mu-4000 X X X X X
FTPfuzz X X X X
Codenomicon X X X X X X
6760 Book.indb 260 12/22/17 10:50 AM
8.6 Results 261
Figure 8.1 The steps in a fuzzing life cycle.
8.6.2 SNMp
Table 8.2 displays the results of the fuzzing against the SNMP server. Note that
SuperGPF could not be used since it only works on ASCII protocols.
These results, as well as the amount of code coverage obtained, are summarized
in the Figure 8.2:
Table 8.2 Results of Fuzzing the SNMP Server
Bug 0 1 2 3 4 5 6 9 10 11 12 13 14 15 16
GPFRandom
GPF Generic X X X X X X X
GPF SNMP X X X X X X X X X
ProxyFuzz X X X X X X
Mu-4000 X X X X X X X X X X X X
PROTOS X X X X X X X
Codenomicon X X X X X X X X X X X X
beSTORM X X X X X X
Figure 8.2 Percentage of bugs found and code coverage obtained by fuzzers on FTP server.
6760 Book.indb 261 12/22/17 10:50 AM
262 Fuzzer Comparison
8.6.3 DNS
Table 8.3 again lists which bugs were found by which fuzzers.
Note that the Mu-4000 fuzzer does not fuzz client-side applications and so
is excluded from this testing. Figure 8.3 summarizes the results and lists the code
coverage obtained by each fuzzer.
8.7 A Closer Look at the results
Some of the results of the testing are surprising, and some aren’t so surprising. First,
let’s look at which bugs were found by which fuzzers. Quite a few bugs were found
by all the fuzzers; there were also bugs that were found by only one fuzzer. We’ll
take a closer look at why various bugs were found or missed in a bit. First, let’s try
to draw some general conclusions from the data.
Table 8.3 Results of Fuzzing the DNS Client
Bug 0 1 2 3 4 5 7 8 11 12 13 14 15
GPF Random
GPF Generic X X X X
ProxyFuzz X X X X X X X X X
Codenomicon X X X X X X X X X X
beSTORM X
Figure 8.3 Percentage of bugs found and code coverage obtained by fuzzers against the SNMP
server.
6760 Book.indb 262 12/22/17 10:50 AM
8.7 A Closer Look at the Results 263
8.7.1 FTp
Let’s take a look at some of the more prominent anomalies in the data. The first
appears in the testing of FTP. Here are some bugs of interest.
• Bugs 9, 12, and 13 were found by GPF but no other fuzzers.
• Bugs 14 and 16 were found by TAOF and ProxyFuzz but no other fuzzers.
• Bugs 4, 5, and 15 were found by the generational-based fuzzers, but not the
mutation-based ones.
Let’s take a closer look at some of these bugs. Bug 9 is a format string vulnerabil-
ity in the SIZE FTP verb (remember that pr_response_add_err() acts as a printf
like function).
MODRET core_size(cmd_rec *cmd) {
...
if (!path || !dir_check(cmd->tmp_pool, cmd->argv[0],
cmd->group,
path, NULL) || pr_fsio_stat(path, &sbuf) == -1) {
char tempbuf[64];
if(strstr(cmd->arg, “%”)){
BUGREPORT(9);
}
strncpy(tempbuf, cmd->arg, 64);
strncat(tempbuf, “: “, 64);
strncat(tempbuf, strerror(errno), 64);
pr_response_add_err(R_550, tempbuf);
None of the generational-based fuzzers ever execute the size verb, probably because
it is not in the protocol specification (RFC 959). Since TAOF and ProxyFuzz were
working off the same packet capture, they should have also found this bug. It is
likely that ProxyFuzz just wasn’t run long enough to find it. Likewise, bugs 12 and
13 are in the EPSV command, which again is not in the RFC.
Next, we examine bug 16, which TAOF and ProxyFuzz managed to find, but none
of the other fuzzers did. This bug was a format string bug in the EPRT command,
MODRET core_eprt(cmd_rec *cmd) {
char delim = ‘\0’, *argstr = pstrdup(cmd->tmp_pool,
cmd->argv[1]);
...
/* Format is protoip addressport (ASCII in
network order),
* where  is an arbitrary delimiter character.
*/
delim = *argstr++;
...
while (isdigit((unsigned char) *argstr))
argstr++;
...
6760 Book.indb 263 12/22/17 10:50 AM
264 Fuzzer Comparison
if (*argstr == delim)
argstr++;
...
if ((tmp = strchr(argstr, delim)) == NULL) {
pr_log_debug(DEBUG3, “badly formatted EPRT argument: ‘%s’”,
cmd>argv[1]);
char tempbuf[64];
if(strstr(cmd->argv[1], “%”)!=NULL){
BUGREPORT(16);
}
snprintf(tempbuf, 64, “badly formatted EPRT argument: ‘%s’”,
cmd->argv[1]);
pr_response_add_err(R_501, tempbuf);
return ERROR(cmd);
}
To activate this bug, you need to have an argument to EPRT without enough delim-
iters, and the portion of the argument after the second delimiter needs to contain a
format string specifier. Again, the generational-based fuzzers did not run the EPRT
command at all. Looking at why GPF missed the bug, the code coverage reveals
that it always included the right number of delimiters, in other words, it wasn’t
random enough!
This code is taken from the lcov code coverage tool (based on gcov). The num-
ber to the left of the colon indicates the number of times the instrumented (i.e.,
real) code was executed. Executed code is highlighted lightly, missed code darkly.
Here we see that GPF never got into the error-checking clause for a badly formatted
EPRT argument and thus missed the bug. The same phenomenon occurs for bug 14.
Finally, we examine bug 4, which was only found by the generational-based fuzzers:
char *dir_canonical_path(pool *p, const char *path) {
char buf[PR_TUNABLE_PATH_MAX + 1] = {‘\0’};
char work[256 + 1] = {‘\0’};
6760 Book.indb 264 12/22/17 10:50 AM
8.7 A Closer Look at the Results 265
if (*path == ‘~’) {
if(strlen(path) > 256 + 1){
BUGREPORT(4);
}
if (pr_fs_interpolate(path, work, strlen(path)) != 1) {
if (pr_fs_dircat(work, sizeof(work), pr_fs_getcwd(), path) <
0)
return NULL;
}
This bug is only activated when a long path is used that starts with the tilde char-