title:Detecting and resolving privacy conflicts for collaborative data sharing
in online social networks
author:Hongxin Hu and
Gail-Joon Ahn and
Jan Jorgensen
Detecting and Resolving Privacy Conﬂicts for
Collaborative Data Sharing in Online Social Networks
Hongxin Hu, Gail-Joon Ahn and Jan Jorgensen
Arizona State University
Tempe, AZ 85287, USA
{hxhu,gahn,jan.jorgensen}@asu.edu
ABSTRACT
We have seen tremendous growth in online social networks (OSNs)
in recent years. These OSNs not only offer attractive means for
virtual social interactions and information sharing, but also raise
a number of security and privacy issues. Although OSNs allow a
single user to govern access to her/his data, they currently do not
provide any mechanism to enforce privacy concerns over data asso-
ciated with multiple users, remaining privacy violations largely un-
resolved and leading to the potential disclosure of information that
at least one user intended to keep private. In this paper, we propose
an approach to enable collaborative privacy management of shared
data in OSNs. In particular, we provide a systematic mechanism
to identify and resolve privacy conﬂicts for collaborative data shar-
ing. Our conﬂict resolution indicates a tradeoff between privacy
protection and data sharing by quantifying privacy risk and sharing
loss. We also discuss a proof-of-concept prototype implementation
of our approach as part of an application in Facebook and provide
system evaluation and usability study of our methodology.
Categories and Subject Descriptors
D.4.6 [Security and Protection]: Access controls; H.2.7 [Information
Systems]: Security, integrity, and protection
General Terms
Security, Management
Keywords
Social Networks, Collaborative, Data Sharing, Privacy Conﬂict,
Access Control
1.
INTRODUCTION
Online social networks (OSNs), such as Facebook, Twitter, and
Google+, have become a de facto portal for hundreds of millions
of Internet users. For example, Facebook, one of representative so-
cial network provider, claims that it has more than 800 million ac-
tive users [3]. With the help of these OSNs, people share personal
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ACSAC ’11 Dec. 5-9, 2011, Orlando, Florida USA
Copyright 2011 ACM 978-1-4503-0672-0/11/12 ...$10.00.
and public information and make social connections with friends,
coworkers, colleagues, family and even with strangers. As a result,
OSNs store a huge amount of possibly sensitive and private infor-
mation on users and their interactions. To protect that information,
privacy control has been treated as a central feature of OSNs [2, 4].
OSNs provide built-in mechanisms enabling users to communi-
cate and share information with other members. A typical OSN
offers each user with a virtual space containing proﬁle information,
a list of the user’s friends, and web pages, such as wall in Facebook,
where the user and friends can post content and leave messages. A
user proﬁle usually includes information with respect to the user’s
birthday, gender, interests, education and work history, and contact
information. In addition, users can not only upload a content into
their own or others’ spaces but also tag other users who appear in
the content. Each tag is an explicit reference that links to a user’s
space. For the protection of user data, current OSNs indirectly re-
quire users to be system and policy administrators for regulating
their data, where users can restrict data sharing to a speciﬁc set of
trusted users. OSNs often use user relationship and group member-
ship to distinguish between trusted and untrusted users. For exam-
ple, in Facebook, users can allow friends, friends of friends, speciﬁc
groups or everyone to access their data, relying on their personal
privacy requirements.
Despite the fact that OSNs currently provide privacy control mech-
anisms allowing users to regulate access to information contained
in their own spaces, users, unfortunately, have no control over data
residing outside their spaces [7, 15, 21, 22, 24]. For instance, if a
user posts a comment in a friend’s space, s/he cannot specify which
users can view the comment. In another case, when a user uploads a
photo and tags friends who appear in the photo, the tagged friends
cannot restrict who can see this photo. Since multiple associated
users may have different privacy concerns over the shared data,
privacy conﬂicts occur and the lack of collaborative privacy con-
trol increases the potential risk in leaking sensitive information by
friends to the public.
In this paper, we seek an effective and ﬂexible mechanism to sup-
port privacy control of shared data in OSNs. We begin by giving
an analysis of data sharing associated with multiple users in OSNs,
and articulate several typical scenarios of privacy conﬂicts for un-
derstanding the risks posed by those conﬂicts. To mitigate such
risks caused by privacy conﬂicts, we develop a collaborative data
sharing mechanism to support the speciﬁcation and enforcement of
multiparty privacy concerns, which have not been accommodated
by existing access control approaches for OSNs (e.g., [10, 12, 13]).
In the meanwhile, a systematic conﬂict detection and resolution
mechanism is addressed to cope with privacy conﬂicts occurring in
collaborative management of data sharing in OSNs. Our conﬂict
resolution approach balances the need for privacy protection and
the users’ desire for information sharing by quantitative analysis
of privacy risk and sharing loss. Besides, we implement a proof-
of-concept prototype of our approach in the context of Facebook.
Our experimental results based on comprehensive system evalua-
tion and usability study demonstrate the feasibility and practicality
of our solution.
The rest of the paper is organized as follows. In Section 2, we
analyze several conﬂict scenarios for privacy control in OSNs. In
Section 3, we address our proposed mechanism for detecting and
resolving privacy conﬂicts in collaborative data sharing. The de-
tails on our prototype implementation and experimental results are
described in Section 4. Section 5 gives a brief overview of related
work. Section 6 concludes this paper and discusses our future di-
rections.
2. PRIVACY CONFLICTS IN ONLINE
SOCIAL NETWORKS
Users in OSNs can post statuses and notes, upload photos and
videos in their own spaces, tag others to their content, and share
the content with their friends. On the other hand, users can also
post content in their friends’ spaces. The shared content may be
connected with multiple users. Consider an example where a pho-
tograph contains three users, Alice, Bob and Carol. If Alice uploads
it to her own space and tags both Bob and Carol in the photo, we
called Alice the owner of the photo, and Bob and Carol stakehold-
ers of the photo. All of them may be desired to specify privacy
policies to control over who can see this photo. In another case,
when Alice posts a note stating “I will attend a party on Friday
night with @Carol” to Bob’s space, we call Alice the contributor
of the note and she may want to make the control over her notes.
In addition, since Carol is explicitly identiﬁed by @-mention (at-
mention) in this note, she is considered as a stakeholder of the note
and may also want to control the exposure of this note. Since each
associated user may have different privacy concerns over the shared
content, privacy conﬂicts can occur among the multiple users.
the content, and then a disseminator views and shares the content.
All privacy conﬂicts among the disseminator and the original con-
trollers (the owner, the contributor and the stakeholders) should be
taken into account for regulating access to content in disseminator’s
space.
In addition to privacy conﬂicts in content sharing, conﬂicts may
also occur in two other situations, proﬁle sharing and friendship
sharing, where multiple parties may have different privacy require-
ments in sharing their proﬁles and friendship lists with others or
social applications in OSNs.
3. OUR APPROACH
Current online social networks, such as Facebook, only allow the
data owner to fully control the shared data, but lack a mechanism
to specify and enforce the privacy concerns from other associated
users, leading to privacy conﬂicts being largely unresolved and sen-
sitive information being potentially disclosed to the public. In this
section, we address a collaborative privacy management mecha-
nism for the protection of shared data with respect to multiple con-
trollers in OSNs. A privacy policy scheme is ﬁrst introduced for
the speciﬁcation and enforcement of multiparty privacy concerns.
Then, we articulate our systematic method for identifying and re-
solving privacy conﬂicts derived from multiple privacy concerns
for collaborative data sharing in OSNs.
3.1 Collaborative Control for Data Sharing in
OSNs
3.1.1 OSN Representation
An OSN can be represented by a friendship network, a set of user
groups and a collection of user data. The friendship network of an
OSN is a graph, where each node denotes a user and each edge rep-
resents a friendship link between two users. Besides, OSNs include
an important feature that allows users to be organized in groups [25,
26], where each group has a unique name. This feature enables
users of an OSN to easily ﬁnd other users with whom they might
share speciﬁc interests (e.g., same hobbies), demographic groups
(e.g., studying at the same schools), political orientation, and so
on. Users can join in groups without any approval from other group
members. Furthermore, OSNs provide each member a web space
where users can store and manage their personal data including pro-
ﬁle information, friend list and content. We now provide an abstract
representation of an OSN with the core components upon which to
build our solution:
Figure 1: Privacy Conﬂicts in OSNs.
OSNs also enable users to share others’ content. For example,
when Alice views a photo in Bob’s space and decides to share this
photo with her friends, the photo will be in turn posted to her space
and she can authorize her friends to see this photo. In this case, Al-
ice is a disseminator of the photo. Since Alice may adopt a weaker
control saying the photo is visible to everyone, the initial privacy
concerns of this photo may be violated, resulting in the leakage
of sensitive information during the procedure of data dissemina-
tion. Figure 1 shows a comprehensive conﬂict scenario in content
sharing where the sharing starts with a contributor who uploads
a unique identiﬁer;
Each group also has a unique identiﬁer;
• U is a set of users of the OSN, {u1; : : : ; un}. Each user has
• G is a set of groups to which the users can belong, {g1; : : : ; gm}.
• U U ⊆ U × U is a binary user-to-user friendship relation;
• U G ⊆ U ×G is a binary user-to-group membership relation;
• P is a collection of user proﬁle sets, {p1; : : : ; po}, where
pi = {pi1; : : : ; pip} is the proﬁle of a user i ∈ U. Each
proﬁle entry is a  pair, pij =, where attrj is an attribute identiﬁer and
pvaluej is the attribute value;
• F is a collection of user friend sets, {f1; : : : ; fq}, where
fi = {u1; : : : ; ur} is the friend list of a user i ∈ U;
• C is a collection of user content sets, {c1; : : : ; cs}, where
ci = {ci1; : : : ; cit} is a set of content of a user i ∈ U, where
cij is a content identiﬁer; and
• D is a collection of data sets, {d1; : : : ; du} , where di =
pi ∪ fi ∪ ci is a set of data of a user i ∈ U.
3.1.2 Privacy Policy Speciﬁcation
To enable a collaborative management of data sharing in OSNs,
it is essential for privacy policies to be in place to regulate access
over shared data, representing privacy requirements from multiple
associated users. Recently, several access control schemes (e.g., [9,
12]) have been proposed to support ﬁne-grained privacy speciﬁ-
cations for OSNs. Unfortunately, these schemes can only allow
a single user to specify her/his privacy concern.
Indeed, a ﬂex-
ible privacy control mechanism in a multi-user environment like
OSNs should allow multiple controllers, who are associated with
the shared data, to specify privacy policies.
Controller Speciﬁcation: As we discussed previously in the pri-
vacy conﬂict scenarios (Section 2), in addition to the owner of data,
other controllers, including the contributor, stakeholder and dis-
seminator of data, also need to regulate the access of the shared
data. We deﬁne these controllers as follows:
DEFINITION 1. (Owner). Let e ∈ du be a data item in the
space of a user u ∈ U in the social network. The user u is called
the owner of e, denoted as OW u
e .
DEFINITION 2. (Contributor). Let e ∈ du
′ be a data item pub-
′ ∈ U in the
lished by a user u ∈ U in the space of another user u
social network. The user u is called the contributor of e, denoted
as CBu
e .
DEFINITION 3. (Stakeholder). Let e ∈ du
′ be a data item in
′ ∈ U in the social network. Let G be the
the space of a user u
set of tagged users associated with e. A user u ∈ U is called a
stakeholder of e, denoted as ST u
e , if u ∈ G.
DEFINITION 4. (Disseminator). Let e ∈ du
′ be a data item
′ ∈ U to
shared by a user u ∈ U from the space of another user u
her/his space in the social network. The user u is called a dissemi-
nator of e, denoted as DSu
e .
Then, we can formally deﬁne the controller speciﬁcation as fol-
lows:
DEFINITION 5. (Controller Speciﬁcation). Let cn ∈ U be a
user who can regulate the access of data. And let ct ∈ CT be
the type of the cn, where CT = {OW; CB; ST; DS} is a set of
controller types, indicating Owner, Contributor, Stakeholder and
Disseminator, respectively. The controller speciﬁcation is deﬁned
as a tuple .
Accessor Speciﬁcation: Accessors are a set of users to whom the
authorization is granted. Accessors can be represented with a set
of user names, the friendship or a set of group names in OSNs. To
facilitate collaborative privacy management, we further introduce
trust levels, which are assigned to accessors when deﬁning the pri-
vacy policies. Golbeck [14] discussed how trust could be used in
OSNs, focusing on OSNs for collaborative rating. We believe that
such considerations can also apply to our privacy management sce-
nario. As addressed in Section 3.2.2, trust is one of the factors in
our approach for resolving privacy conﬂicts. Clearly, in our sce-
nario, trust has a different meaning from the one used in [14]. The
notation of trust in our work mainly convey information about how
much conﬁdence a controller put on her/his friends who would not
disclose the sensitive information to untrusted users. Also, trust
levels can be changed in different situations. The notion of acces-
sor speciﬁcation is formally deﬁned as follows:
DEFINITION 6. (Accessor Speciﬁcation). Let ac be a user u ∈