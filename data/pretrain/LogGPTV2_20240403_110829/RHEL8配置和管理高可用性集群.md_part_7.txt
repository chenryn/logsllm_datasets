|                    | 5404-5412 非常重要，这样来自任何节点的         |
|                    | `corosync`{.literal}                           |
|                    | 都可以与群集中的所有节点（包括自身）进行通信。 |
+--------------------+------------------------------------------------+
| TCP 21064          | 如果群集包含任何需要 DLM 的资源（如            |
|                    | `GFS                                           |
|                    | 2`{.literal}），则在所有节点上都需要这个端口。 |
+--------------------+------------------------------------------------+
| TCP 9929, UDP 9929 | 需要在所有集群节点上打开，并在使用 Booth       |
|                    | ticket                                         |
|                    | 管理器建                                       |
|                    | 立多站点集群时引导节点从这些相同节点进行连接。 |
+--------------------+------------------------------------------------+
:::
:::
:::
:::
[]{#assembly_configuring-active-passive-http-server-in-a-cluster-configuring-and-managing-high-availability-clusters.html}
::: chapter
::: titlepage
# []{#assembly_configuring-active-passive-http-server-in-a-cluster-configuring-and-managing-high-availability-clusters.html#assembly_configuring-active-passive-http-server-in-a-cluster-configuring-and-managing-high-availability-clusters}第 5 章 在红帽高可用性集群中配置主动/被动 Apache HTTP 服务器 {.title}
:::
此流程使用 `pcs`{.literal} 命令行界面配置双节点 Red Hat Enterprise Linux
High Availability 附加组件中的主动/被动 Apache HTTP
服务器来配置群集资源。在这种情况下，客户端通过浮动 IP 地址访问 Apache
HTTP 服务器。Web 服务器在集群的两个节点之一中运行。如果运行 web
服务器的节点出现问题，则 web
服务器会在集群的第二个节点上再次启动，以实现服务中断的最小化。
下图显示了集群的高级概述，其中集群是一个双节点红帽高可用性集群，它配置有网络电源交换机和共享存储。集群节点连接到公用网络，以便客户端通过虚拟
IP 访问 Apache HTTP 服务器。Apache 服务器在 Node 1 或 Node 2
中运行，每个节点都可访问保存 Apache 数据的存储。本图例中，网页服务器在
Node 1 上运行，如果 Node 1 停止工作， Node 2 可以运行服务器。
::: figure
[]{#assembly_configuring-active-passive-http-server-in-a-cluster-configuring-and-managing-high-availability-clusters.html#idm140696038466464}
**图 5.1. Red Hat High Availability 双节点集群中的 Apache**
::: figure-contents
::: mediaobject
![Red Hat High Availability 双节点集群中的
Apache](images/291627-haserver_cluster4.png)
:::
:::
:::
这个用例需要您的系统包括以下组件：
::: itemizedlist
-   一个双节点 Red Hat High Availability
    集群，为每个节点配置了电源隔离功能。我们建议使用专用网络，但这不是必须的。此流程使用了[创建带有
    Pacemaker 的 Red Hat High-Availability
    集群](#assembly_creating-high-availability-cluster-configuring-and-managing-high-availability-clusters.html "第 4 章 使用 Pacemaker 创建红帽高可用性集群"){.link}中提供的集群示例。
-   Apache 需要的公共虚拟 IP 地址。
-   集群中节点的共享存储，使用 iSCSI、光纤或其他共享网络块设备。
:::
集群被配置为带有 Apache 资源组，其中包含 web 服务器所需的集群组件：LVM
资源、文件系统资源、IP 地址资源以及 web
服务器资源。这个资源组可以从集群的一个节点切换到另外一个节点，允许其中两个节点运行
web 服务器。在为集群创建资源组前，您将执行以下步骤：
::: orderedlist
1.  在逻辑卷 `my_lv`{.literal} 上配置 `ext4`{.literal} 文件系统。
2.  配置 web 服务器。
:::
执行这些步骤后，您要创建资源组及其包含的资源。
::: section
::: titlepage
# []{#assembly_configuring-active-passive-http-server-in-a-cluster-configuring-and-managing-high-availability-clusters.html#proc_configuring-lvm-volume-with-ext4-file-system-configuring-ha-http}在 Pacemaker 集群中使用 ext4 文件系统配置 LVM 卷 {.title}
:::
这个过程在集群节点之间共享的存储中创建 LVM 逻辑卷。
::: {.note style="margin-left: 0.5in; margin-right: 0.5in;"}
### 注意 {.title}
LVM 卷以及集群节点使用的对应分区和设备必须只能连接到集群节点。
:::
下面的过程创建了 LVM 逻辑卷，然后在该卷上创建一个 ext4 文件系统供
Pacemaker 集群使用。在这个示例中，使用共享分区 `/dev/sdb1`{.literal}
来存储从中创建 LVM 逻辑卷的 LVM 物理卷。
::: orderedlist
**流程**
1.  在集群的两个节点上，执行以下步骤将 LVM 系统 ID 的值设置为系统的
    `uname`{.literal} 标识符值。LVM 系统 ID
    将用于确保只有集群可以激活卷组。
    ::: orderedlist
    1.  将 `/etc/lvm/lvm.conf`{.literal} 配置文件中的
        `system_id_source`{.literal} 配置选项设置为 `uname`{.literal}。
        ``` literallayout
        # Configuration option global/system_id_source.
        system_id_source = "uname"
        ```
    2.  验证节点上的 LVM 系统 ID 是否与节点的 `uname`{.literal} 匹配。
        ``` literallayout
        # lvm systemid
          system ID: z1.example.com
        # uname -n
          z1.example.com
        ```
    :::
2.  创建 LVM 卷并在那个卷中创建 ext4 文件系统。由于
    `/dev/sdb1`{.literal}
    分区是共享的存储，因此您仅在一个节点上执行这一部分的步骤。
    ::: orderedlist
    1.  在分区 `/dev/sdb1`{.literal} 上创建一个 LVM 物理卷。
        ``` literallayout
        # pvcreate /dev/sdb1
          Physical volume "/dev/sdb1" successfully created
        ```
    2.  创建由物理卷 `/dev/sdb1`{.literal} 组成的卷组
        `my_vg`{.literal}。
        对于 RHEL 8.5 及之后的版本，指定
        `--setautoactivation n`{.literal} 标志来确保集群中由 Pacemaker
        管理的卷组在启动时不会自动激活。如果您要为要创建的 LVM
        卷使用现有卷组，您可以使用
        `vgchange --setautoactivation n`{.literal}
        命令为卷组重置此标记。
        ``` literallayout
        # vgcreate --setautoactivation n my_vg /dev/sdb1
          Volume group "my_vg" successfully created
        ```
        对于 RHEL 8.4 及更早版本，使用以下命令创建卷组：
        ``` literallayout
        # vgcreate my_vg /dev/sdb1
          Volume group "my_vg" successfully created
        ```
        有关确保集群中 Pacemaker 管理的卷组在 RHEL 8.4
        [及更早版本启动时不会自动激活，请参阅确保不会在多个群集节点上激活卷组](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/configuring_and_managing_high_availability_clusters/assembly_configuring-active-passive-http-server-in-a-cluster-configuring-and-managing-high-availability-clusters#proc_ensuring-cluster-volume-not-multiply-activated-configuring-ha-http){.link}。
    3.  确认新卷组带有您要运行的节点的系统 ID，并从这个节点中创建卷组。
        ``` literallayout
        # vgs -o+systemid
          VG    #PV #LV #SN Attr   VSize  VFree  System ID
          my_vg   1   0   0 wz--n- 
# []{#assembly_configuring-active-passive-http-server-in-a-cluster-configuring-and-managing-high-availability-clusters.html#proc_ensuring-cluster-volume-not-multiply-activated-configuring-ha-http}确保没有在多个集群节点中激活卷组（RHEL 8.4 及更早版本） {.title}
:::
此流程确保启动时不会自动激活集群中由 Pacemaker
管理的卷组。如果某个卷组在启动时自动激活，而不是由 Pacemaker
激活，则卷组可能会同时在多个节点上激活，这可能会破坏卷组的元数据。
::: {.note style="margin-left: 0.5in; margin-right: 0.5in;"}
### 注意 {.title}
对于 RHEL 8.5 及更高版本，您可以在创建卷组时为卷组禁用自动激活，方法是为
`vgcreate`{.literal} 命令指定 `--setautoactivation n`{.literal} 标志，如
[Pacemaker 集群中使用 ext4 文件系统配置 LVM
卷](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/configuring_and_managing_high_availability_clusters/assembly_configuring-active-passive-http-server-in-a-cluster-configuring-and-managing-high-availability-clusters#proc_configuring-lvm-volume-with-ext4-file-system-configuring-ha-http){.link}
所述。
:::
此流程修改 `/etc/lvm/lvm.conf`{.literal} 配置文件中的
`auto_activation_volume_list`{.literal}
条目。`auto_activation_volume_list`{.literal}
条目用于将自动激活限制为特定的逻辑卷。将
`auto_activation_volume_list`{.literal} 设置为空列表可完全禁用自动激活。
任何未被共享且不由 Pacemaker 管理的本地卷都应包含在
`auto_activation_volume_list`{.literal}
条目中，包括与节点本地根和主目录相关的卷组。由群集管理器管理的所有卷组都必须从
`auto_activation_volume_list`{.literal} 条目中排除。
::: title
**流程**
:::
在集群的每个节点中执行以下步骤。
::: orderedlist
1.  使用以下命令，确定您的本地存储上当前已配置哪些卷组。这将输出当前配置的卷组的列表。如果您在单独的卷组中为
    root
    和此节点上的主目录分配了空间，您会在输出中看到这些卷，如下例所示。
    ``` literallayout
    # vgs --noheadings -o vg_name
      my_vg
      rhel_home
      rhel_root
    ```
2.  将 `my_vg`{.literal}
    之外的卷组（您刚刚为群集定义的卷组）作为条目添加到
    `/etc/lvm/lvm.conf`{.literal} 配置文件中的
    `auto_activation_volume_list`{.literal}。
    例如，如果您在单独的卷组中为 root 和主目录分配了空间，您可以取消注释
    `lvm.conf`{.literal} 文件的 `auto_activation_volume_list`{.literal}
    行，并将这些卷组作为条目添加到
    `auto_activation_volume_list`{.literal}，如下所示：请注意，您刚才为群集定义的卷组（`本例中为 my_vg`{.literal}
    ）不在此列表中。
    ``` literallayout
    auto_activation_volume_list = [ "rhel_root", "rhel_home" ]
    ```
    ::: {.note style="margin-left: 0.5in; margin-right: 0.5in;"}
    ### 注意 {.title}
    如果节点上没有要在群集管理器外激活的本地卷组，您仍需要将
    `auto_activation_volume_list`{.literal} 条目初始化为
    `auto_activation_volume_list = []`{.literal}。
    :::
3.  重建 `initramfs`{.literal}
    引导映像，以确保引导映像不会尝试激活由群集控制的卷组。使用以下命令更新
    `initramfs`{.literal} 设备：此命令最多可能需要一分钟完成。
    ``` literallayout
    # dracut -H -f /boot/initramfs-$(uname -r).img $(uname -r)
    ```
4.  重新引导节点。
    ::: {.note style="margin-left: 0.5in; margin-right: 0.5in;"}
    ### 注意 {.title}
    如果您自引导引导镜像后安装了一个新的 Linux 内核，则新
    `initrd`{.literal}
    镜像将适用于您在创建引导镜像时运行的内核，而不是重新引导该节点时运行的新内核。您可以通过在重启前后运行
    `uname -r`{.literal} 命令来确保使用正确的 `initrd`{.literal}
    设备，以确定正在运行的内核版本。如果发行版不同，请在使用新内核重启后更新
    `initrd`{.literal} 文件，然后重新引导节点。
    :::
5.  节点重新引导后，通过在该节点上执行 `pcs cluster status`{.literal}
    命令，检查群集服务是否已在该节点上再次启动。如果这会产生
    `Error: cluster 当前没有在此节点上运行的信息`{.literal}，请输入以下命令。
    ``` literallayout
    # pcs cluster start
    ```
    另外，您可以等待直到您重新引导集群中的每个节点，并使用以下命令在集群中的所有节点上启动集群服务。
    ``` literallayout
    # pcs cluster start --all
    ```
:::
:::
::: section
::: titlepage
# []{#assembly_configuring-active-passive-http-server-in-a-cluster-configuring-and-managing-high-availability-clusters.html#proc_configuring-apache-http-web-server-configuring-ha-http}配置 Apache HTTP 服务器 {.title}
:::
此流程配置 Apache HTTP 服务器。