To filter all such responses, we used TextStat,8 a Python library to
calculate statistics from the text. We used it to count the number of
7https://github.com/ReDASers/ASIACCS2020-ScamAugmentation
8https://pypi.org/project/textstat/
Session 5: Usable Security & Privacy ASIA CCS '20, October 5–9, 2020, Taipei, Taiwan240Table 2: Number of participants who correctly labeled N of-
fers (N ranges from 0 to 4). ACL: average confidence level
over all offers. Tukey’s Comparison: ANOVA Comparisons
of ACL. We do not report p-values bigger than 0.05 (empty
cells).
#of Correct
Detections
4
3
2
1
0
# of
participants
487 (26%)
640 (35%)
546 (29%)
156 (9%)
23 (1%)
Mean
3.69
3.50
3.55
3.35
3.34
StdDev
0.66
0.67
0.81
0.72
0.71
ACL
Tukey’s Comparison
3
<.001
2
<.05
1
<.001
<0.05
Table 3: Performance of participants in each group. LCR - Le-
gitimate Choosing Rate. N - number of participants in each
group. LCRL - LCR for Legitimate offers. LCRF - LCR for Fake
offers.
Variable
LinkedIn
N
232
241 Gmail
224 Human
220 NLG
228
246 Receiver
232
229 None
Sender
Send+Rec.
LCRL
0.53
0.46
0.48
N/A
0.74
0.76
0.77
0.65
LCRF Avg. LCR Avg. Conf.
0.26
0.23
0.22
0.28
0.22
0.16
0.26
0.19
0.39
0.35
0.34
N/A
0.48
0.46
0.51
0.42
3.43
3.51
3.49
3.67
3.53
3.60
3.57
3.59
as legitimate divided by the total number of offers regardless of
their actual label. Equation 1 shows the relation of LCR.

(cid:26)1
0
LCR =
LC =
all_of f ers LC
|all_o f f ers|
,
i f predictedlabel = leдit
otherwise
(1)
We calculated the LCR for each group and reported the average
in Table 3. It shows LCR for fake and legitimate offers separately as
well as overall LCR. LCRL of 1 and LCRF of zero show perfect detec-
tion of all legitimate and fake offers respectively. In NLG group (row
number four), we did not calculate LCR (N/A) for legitimate offers
and average LCR since we only used NLG to generate fraudulent
emails (legitimate offers used in NLG group are written by human).
6.2 LinkedIn vs. Gmail (H1)
We compare the LCR for legitimate and fake offers in GL,H,E and
GG,H,E to test our LinkedIn hypothesis. Using the two-sample z
proportions test, we found a significant difference between partici-
pants’ tendency in choosing legitimate label for offers delivered by
Gmail and LinkedIn (z=2.15, p<0.05). This means users trust mes-
sages delivered by LinkedIn more than those delivered by Gmail.
To test our first hypothesis, we need to analyze the LinkedIn
effect on legitimate and fake offers separately. The effect might be
significant only for legitimate offers and not for fake ones. For legit-
imate offers, the two-sample z proportions test shows a significant
Figure 1: Average detection rate of job scam and legitimate
emails for different groups. DR: Detection Rate
words and removed all responses with less than two words. This
filtered out 382 responses.
6 RESULTS
After applying the above filters, we got 1,852 responses, 58% fe-
male and 42% male. The average age of participants is 26 years old
with a minimum of 16 and a maximum of 83 (median is 22). Stu-
dents comprise 81% of the participants and the rest are faculty/staff.
Among the students, 76% are undergraduates and 22% are graduate
students. The participants were from 83 different majors with Psy-
chology, Biology, and Computer Science as the most frequent (eight,
seven, and five percent respectively). Each experimental group had
between 239 to 270 responses (mean: 251).
Figure 1 shows the average detection rate of participants in each
group for phishing and legitimate offers. notice that the last four
groups are almost 20% better than the first four in detecting le-
gitimate offers. Our participants found the legitimate offers used
in groups one, two, three and four more suspicious than the rest.
This difference is not an issue for our analysis since they are on
different groups which are not compared with each other. But we
further investigated this issue and checked the offers and partic-
ipants’ reasoning to see if there is anything wrong (any obvious
clue that was missed). The only difference that we noticed was their
length. The offers that were labeled as legitimate more frequently
by the participants were longer (but not significantly) and had more
description of the job. As mentioned, this difference does not affect
our study.
Table 2 shows the number of participants who were able to label
zero to four offers correctly as well as their confidence level. Only
26% of the participants were able to correctly detect all four offers.
We also observe a higher average confidence level among partici-
pants who performed better. An analysis of variance (ANOVA) on
their confidence level yielded significant variation among condi-
tions (F(4, 1847)=8.73, p<.001). The results of the Tukey’s post-hoc
test are shown in the last three columns of Table 2 (empty cells
mean no significant difference at 95% confidence level).
6.1 Overall Performance
Since our hypotheses affect legitimate and fraudulent detection rate
differently (reducing one while increasing the other), we need a
metric that reflects participants’ tendency in choosing legitimate
label as their response (regardless of the actual label of the offer).
Thus, we introduce a new variable called Legitimate Choosing Rate
(LCR) to test our hypotheses. It measures the ratio of offers labeled
LinkedInGmailHumanNLGSenderReceiverSend+Rec.None0.00.20.40.60.81.0Legit DRPhish DRSession 5: Usable Security & Privacy ASIA CCS '20, October 5–9, 2020, Taipei, Taiwan241Table 4: p-value of pairwise comparison of LCR for legiti-
mate offers on GG,H,S , GG,H,R, GG,H,SR and GG,H,E.
Group
None
Receiver
Sender
Both
<0.001
None
Receiver
0.12 <0.001
<0.05 <0.001 <0.01
Table 5: p-value of pairwise comparison of LCR for fake of-
fers on GG,H,S , GG,H,R, GG,H,SR and GG,H,E.
Both
Group
<0.05
None
Receiver <0.05
Sender
0.11
None Receiver
0.91
0.91
0.69
difference (z=2.14, p<0.05) which means people trust legitimate
offers delivered by LinkedIn (0.53) more than those delivered by
Gmail (0.46). However, we did not find any significant difference in
fake offers (z=0.94, p=.34). It rejects our hypothesis that LinkedIn
can be used by attackers to increase their success rate.
6.3 Customization (H2)
The proportions test shows a significant difference between the four
variations of sender and receiver information on both legitimate
and fake offers (fraudulent: z =3.72, df=3, p<0.001, legitimate:
z =6.38, df=3, p<.0001). Tables 4 and 5 show the pairwise compar-
isons of proportions for LCR on legitimate and fake offers (Holm-
Bonferroni method used for p-values adjustment). As expected, not
having any of sender and receiver information makes the email less
credible for both types of offers (legitimate and fake) compared to
having both elements.
Between sender and receiver information, the results show a
significant difference in LCR for legitimate offers but not significant
for fake offers. On the other hand, having both sender and receiver
information at the same time does not necessarily make the email
more credible compared to only having one of them. For fake offers,
we only see a significant difference between using both of the
information and only using receiver information.
6.4 Human Fake vs. NLG Fake (H3)
We only used NLG to generate fake offers, so here we only com-
pare them with fake offers written by human. Comparing the re-
sults of participants’ performance on fake offers written by hu-
mans or NLG ones showed a significant difference between them
(z=2.25, p<0.05). Surprisingly, participants performed worse on
NLG-generated emails (LCR: 0.28 for NLG vs. 0.22 for Human). This
could have happened due to some other variables, which we did
not control like the length of emails. We compared these offers and
found human-written ones longer and more descriptive, which is
in favor of legitimacy (opposite of what we observed). We looked
at participants reasoning and found that the second-highest men-
tioned reason among people who marked human-generated emails
as fraudulent was “too good to be true.” It shows that participants
performed differently due to the nature of the (phishing) emails
Figure 2: Participants’ confidence in their responses. 1 is the
lowest confidence and 5 is the highest.
and not whether it is human or synthetic. None of the participants
mentioned anything about writing or coherency issues in their
reasoning.
6.5 Participants’ Confidence
For each question in the survey, we had a 5-point Likert scale to
measure participants’ confidence in their responses. Figure 2 shows
the percentage of participants with a specific confidence level in
each experimental group. Between 42% and 68% of participants,
across the groups, chose 4 and 5 (highest) for their confidence,
generally reflecting high confidence in their answers.
Participants may express different confidence when they cor-
rectly classify an offer compared to the cases that they are wrong.
To analyze participants’ metacognition ability [14], we calculated
two confidence levels for each participant: 1) average confidence
for correctly classified offers (true negative and true positive) 2)
average confidence for incorrectly classified offers (false negative
and false positive). Our results show that participants were more
confident when they correctly classified the offers (median: 3.66 vs.
3). Mann-Whitney U Test shows a significant difference between
them (U=1500000, p<0.001). Our result confirms the findings of
researchers in [14] that users have reasonable calibration (i.e., they
know how much confidence to place in their own performance).
The fact that participants have a high calibration even though
they do not perform well in the detection task (26% labeled all
messages correctly) suggests that they have basic knowledge on
phishing emails. Giving them the correct awareness/education,
e.g., through a warning scheme, should lead to better performance.
Further studies are required to support this hypothesis.
6.6 Personality and Cognitive Ability
Previous studies have shown relationships between people’s per-
sonality and their vulnerability to cyber-attacks [15, 30, 31]. They
showed that agreeableness, neuroticism, and conscientiousness signif-
icantly increase susceptibility to phishing attacks. Table 6 presents
Participants' Confidence Per Group and QuestionRow Count TotalsQ4Q3Q2Q1229229229229None220220220220NLGQ4Q3Q2Q1232232232232Both224224224224HumanQ4Q3Q2Q1246246246246Receiver241241241241GmailQ4Q3Q2Q1020228228228228Sender232232232232LinkedIn125 Confidence Level34Percent020PercentSession 5: Usable Security & Privacy ASIA CCS '20, October 5–9, 2020, Taipei, Taiwan242puter?
• Have you ever used browsers bookmarks?
• Have you ever installed computer software on your com-
• Have you ever used internet calling software? e.g., Skype,
• Have you ever used online systems for banking or shopping?
• Have you seen any specific information in the last year that
• Do you use any spam filter (stand-alone or part of Antivirus)
helps you detect email scams?
Hangout, etc.
The technology background is a variable between zero and six based
on participants responses to the following questions (by counting
the number of yes):
to filter emails in your personal account?
Figure 3: Correlation between personality traits and detec-