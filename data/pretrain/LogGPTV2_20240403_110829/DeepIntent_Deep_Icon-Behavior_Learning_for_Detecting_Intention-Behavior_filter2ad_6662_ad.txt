text_only
concatenate
add
co-attention
IconIntent
icon_only
text_only
concatenate
add
co-attention
0.9054
0.9478
0.9775
0.9665
0.9617
0.9674
0.7488
0.987
0.9807
0.9841
0.9858
0.9883
0.8197
0.967
0.9791
0.9752
0.9736
0.9777
0.3702
0.7006
0.8505
0.8684
0.8588
0.8675
0.7897
0.6021
0.8784
0.8426
0.8549
0.8325
0.5041
0.6476
0.8642
0.8553
0.8568
0.8496
0.2644
0.7725
0.8489
0.8809
0.8528
0.9073
0.5576
0.5326
0.7926
0.7177
0.7532
0.7705
0.3587
0.6305
0.8198
0.791
0.7999
0.8333
NETWORK LOCATION MICROPHONE
CAMERA CALL STORAGE CONTACTS
0.2334
0.7447
0.8515
0.7827
0.8117
0.8531
0.6985
0.4355
0.7473
0.5839
0.5606
0.6487
0.3499
0.5496
0.796
0.6688
0.6632
0.737
SMS
0.3221
0.7817
0.8651
0.8747
0.9076
0.9389
0.6825
0.5209
0.7874
0.72
0.6605
0.7763
0.4377
0.6252
0.8244
0.7898
0.7646
0.8499
0.2917
0.7793
0.8763
0.8955
0.9378
0.9322
0.6885
0.5558
0.7512
0.7258
0.7214
0.7274
0.4098
0.6488
0.8089
0.8018
0.8155
0.8172
0.2264
0.9138
0.8028
1.000
1.000
1.000
0.7059
0.6306
0.7315
0.6134
0.65
0.6111
0.3429
0.7462
0.7655
0.7604
0.7879
0.7586
0.1286
0.8273
0.7971
0.8526
0.8915
0.9137
0.5454
0.4548
0.6802
0.4054
0.468
0.5554
0.2081
0.5869
0.734
0.5495
0.6138
0.6909
Table 3: Evaluation results for icon-permission prediction. Our co-attention mechanism in DeepIntent generally performs
the best, especially in four permission groups that are relatively difficult to predict.
set, and the malicious test set, respectively. In the two test sets, we
have manually found 432 and 865 intention-behavior discrepancies.
7.2 Implementation
DeepIntent contains three key steps: icon-behavior association,
icon-behavior modeling, and outlier detection. For icon-behavior
association, we implement it upon Gator [64] and Soot [74] for
static analysis. We decode apps using ApkTool [73] and map API
methods to permissions using PScout [6]. We use Pillow [12] to
process icons and Google Tesseract OCR [60] to extract embedded
texts from icons. We followed the standard steps as the previous
work [80] including tuning image colors and rotating images to fit
the text angles before extracting embedded texts from icons. For the
icon-behavior model, we implement it using Keras [11]. We embed
each word with the dimension of 100, and set feature dimension d
to 100. The model is trained using stochastic gradient descent with
the Adam optimizer. We also adopt dropout [21] with the dropout
rate being 0.5. For outlier detection, we set the hidden dimensions
of AutoEncoder to [64, 32, 64], where the first two dimensions are to
compress and the last two are to reconstruct. The neighborhood size
for the distance-based aggregation method is set to 5 (i.e., T = 5).
7.3 Evaluation Results
7.3.1 RQ1: Effectiveness of joint feature learning. To demonstrate
the effectiveness of the co-attention mechanism that jointly mod-
els icons and texts in icon-behavior learning, we first compare
DeepIntent with IconIntent [80], the state-of-the-art sensitive
UI widget identification approach that adapts computer vision tech-
niques (SIFT [46] and FAST [62]) to predict sensitive categories of
UI widgets. As IconIntent is designed to predict each single per-
mission group while DeepIntent targets at a multi-label prediction
problem, for fair comparison, we run IconIntent multiple times
over each permission group to obtain the predicted labels. Next, to
demonstrate the improvement brought by modeling both icons and
texts, we compare with two variants of DeepIntent: ‘icon_only’
and ‘text_only’, which consider either only image features or only
text features. Finally, we further compare the co-attention mecha-
nism used in DeepIntent with two variants: ‘add’ and ‘concatenate’,
which adds or concatenates the image and text features to substitute
our feature combination in Figure 8 (c).
We measure the prediction accuracy of DeepIntent and the
compared approaches. The test set of this experiment is a subset
of the benign test set with icons marked as intention-behavior
discrepancies deleted. Since we model the permission prediction as
a multi-label prediction problem, we adopt the average precision,
recall, and F1-score over each icon as evaluation metrics. The results
are shown in Table 3.
We have several major observations. First, all the three Deep-
Intent variants significantly outperform IconIntent in terms of
precision and F1-score. For example, DeepIntent achieves at least
19.3% relative improvement in different permission groups. IconIn-
tent yields higher recall values. The reason is that the extracted
features from IconIntent are less accurate, and it tends to predict
a larger number of permissions for each icon, resulting in higher
recall and lower precision. This result indicates the superior per-
formance of the used deep learning techniques clearly over the
computer vision techniques in IconIntent for large-scale datasets.
Second, compared to ‘text_only’ and ‘icon_only’, DeepIntent
performs the best in most cases on the F1-score metric. The only ex-
ception is from the Network group when comparing with ‘text_only’.
The possible reason is as follows. Compared to the other permis-
sions, various icons with more different appearances may use the
Network permission; therefore, adding icon features may mislead
the predictions when there are insufficient similar icons in the
training data. Moreover, we can observe that ‘text_only’ generally
performs better than ‘icon_only’. The reasons are three-fold: 1) text
Type
benign
(a) The distributions of icon permissions. Directly using mani-
fest files introduces many unused permissions.
SMS
NETWORK
LOCATION
MICROPHONE
Permission Precision/Recall AUC
0.8638
0.746
0.8221
0.7841
0.7851
0.9382
0.9722
0.787
0.8712
0.756
0.693
0.7857
0.7613
0.7685
0.7647
0.8697
0.8571
0.7849
0.7568
0.856
CONTACTS
CAMERA
CALL
NETWORK
LOCATION
STORAGE
malicious
MICROPHONE
SMS
CAMERA
CALL
STORAGE
CONTACTS
-
-
0.939
0.9167
0.9231
0.9412
-
-
0.8034
0.8472
0.8462
0.8412
Table 4: Detection accuracy results over permission groups.
AUC = 0.5 means random guess. DeepIntent can accurately
detect the intention-behavior discrepancies.
(b) The precision/recall results for the icon-behavior model.
Training with permissions in manifest files performs poorly
in precision.
Figure 11: The necessity of icon-behavior association.
descriptions are intuitively discriminative in our prediction task, 2)
we extract text not only in apps’ UIs but also from the layout and
resource names, and 3) icon images are relatively noisy and require
more data for training.
Third, the co-attention mechanism in DeepIntent performs
especially well in 4 out of 8 permission groups (the bold cases in the
table). One common place in these 4 cases is that the accuracy of all
the feature combination methods is relatively low. This means that
our co-attention mechanism helps improve the learned model for
the permission groups that are relatively more difficult to predict.
Overall, this experiment shows the effectiveness of our co-attention
mechanism for learning the icon-behavior model, which performs
especially well in four out of eight permission groups that are relatively
difficult to predict.
7.3.2 RQ2: Effectiveness of Icon-Behavior Association. To demon-
strate the necessity of icon-behavior association in icon-behavior
learning, we compare DeepIntent with an approach Mani f est that
uses the permissions defined in an app’s manifest file for all the icon
widgets in this app. Obviously, the permission set from the manifest
file for each icon widget is a super set of that from our icon-behavior
association module. We then use these permissions for each icon
as the training set, and evaluate Mani f est’s performance on the
benign test set without icons marked as intention-behavior discrep-
ancies. The resulting permission distributions and the prediction
accuracy results are shown in Figure 11.