Pr{a, σ|o} =
Pr{o|a, σ} Pr{σ|a} Pr {a}
Pr{o}
(22)
The denominator is a normalizing factor that
is hard
to compute, but it does not depend on a. The algorithm
allows us to sample from the distribution Pr{a, σ|o} without
computing the denominator Pr{o}. However, the numerator
needs to be easy to compute, which is true in our case: We
compute the probability Pr{o|a, σ} using (1); the probability
Pr{σ|a} is constant and equal to 1
N ! , as we use random per-
mutation as the anonymization function; and the probability
Pr {a} is computed from the users’ proﬁles.
At a high level, the MH algorithm performs a random
walk on the space of possible values for (a, σ). The tran-
sition probabilities of the random walk are chosen so that
its stationary distribution is the distribution from which we
want to sample.
First of all, we need to ﬁnd a feasible initial point for the
walk (i.e., a point that does not violate the mobility proﬁle
of any user; it is not a trivial matter to ﬁnd such a point). We
use the output of the maximum likelihood tracking attack.
We then need to deﬁne a neighborhood for each point
(a, σ). We deﬁne two points (a, σ) and (a′, σ′) to be
neighbors if and only if exactly one of the three following
conditions holds:
• The components σ and σ′ differ in exactly two places.
That is, N − 2 out of the N traces are assigned to
the same users in both σ and σ′, and the assignment
of the remaining two traces to users is switched. The
components a and a′ are identical.
• The components a and a′ differ in exactly one place.
That is, the location of exactly one user at exactly one
timeslot is different. All other locations are unchanged.
The components σ and σ′ are identical.
• Points (a, σ) and (a′, σ′) are identical. That is, a point
is assumed to be included in its own neighborhood.
We ﬁnally deﬁne a proposal density function that deter-
mines the candidate neighbor to move to at the next step;
this function also inﬂuences the convergence speed of the
algorithm. For simplicity, we use a uniform proposal density,
so the candidate is selected randomly among all neighbors.
the cur-
is
accepted with probability
Pr{o|a,σ} Pr{a} , 1}. If (a′, σ′) is rejected, then we
is
rent point
(a′, σ′). Then,
min{ Pr{o|a′,σ′} Pr{a′}
To perform the random walk, suppose that
selected candidate
and the
(a, σ)
(a′, σ′)
is
repeat the procedure of selecting and probabilistically ac-
cepting a neighbor. If it is accepted, it is logged as a step in
the random walk. However, it is not an independent sample,
as it is correlated with (a, σ). Only after making enough
steps to overcome the inherent correlation among successive
steps is a step stored as an independent sample. After storing
enough independent samples, the algorithm stops.
How many independent samples are enough? The attacker
collects as many samples as needed to satisfy his accuracy
requirements. The conﬁdence interval for the chosen conﬁ-
dence level must be shorter than the desired length. Suppose
the attacker needs to collect n independent samples.
How many steps of the random walk must be taken
between each pair of successive samples to ensure the inde-
pendence of these n samples? There are standard statistical
tests of independence; our choice is the Turning Point test.
The basic idea of this test is that, among three successive
independent and identically distributed samples, all 3! = 6
possible orderings are equiprobable. Given three numerical
values xi−1, xi, xi+1, a turning point exists at i if and only if
xi is either larger than both xi−1, xi+1 or smaller than both
xi−1, xi+1. If the three numerical values are independent
and identically distributed, then the probability of a turning
point is 2
3 . Then, given a large enough number of values, n
in our case, the number of turning points is approximately
Gaussian with mean 2n−4
and variance 16n−29
.
3
90
So, we test if the number of turning points in our sequence
of n MH samples can be claimed to be Gaussian with this
mean and variance. If so, we stop. Otherwise, we make more
steps in the random walk and skip more and more of the
logged intermediate steps before storing each sample.
It should be emphasized that the Distribution Tracking
attack can answer all kinds of U-R-T questions. The
attacker can specify a very wide range of objectives as
functions of a sample of the MH algorithm. Then,
the
attacker computes this function on each independent sample,
and the sample average of the computed values is the
estimate of the attacker’s objective. In this case, the accuracy
and certainty metrics would be computed on the values that
the function returns, rather than directly on the MH samples.
Despite its generality, the Distribution Tracking attack is
computationally intensive. So, it might make sense to use
heuristics to ﬁnd the distribution of traces for each user.
An important heuristic is to consider, as we have al-
ready seen, only the most likely deanonymization. Then
we ﬁnd the posterior distribution of nonobfuscated traces
separately for each user-to-obfuscated-trace assignment that
the deanonymization produced. Formally, the objective is to
ﬁnd the pdf
max
σ
Pr(σ, a|O).
(23)
The implementation of this heuristic is simply to ﬁnd the
MWA, as explained in the Maximum Likelihood Tracking
attack, and then run Metropolis-Hastings for each user-trace
256
pair separately. That is, MH would run on each space Au
separately for each u, and of course the neighborhood of a
point would be restricted to single location changes, as there
can be no changes in the username part.
D. Localization Attacks
In localization attacks, a typical question is to ﬁnd the
location of a user u at some time t. The most general answer
to such a question is to compute
Pr{au(t) = r|ou, P u}
(24)
for each r ∈ R. The output for the attacker is a distribution
on the possible regions, from which he can select the most
probable, or form an average, etc. For this attack, the attacker
needs to know or estimate the observed trace that user u
created, perhaps by using the Maximum Weight Assignment,
which is what we have implemented.
Of course, he can perform the attack for each of the
observed traces, as it is not very computationally intensive.
In particular, these probabilities can be easily computed
with the Forward-Backward algorithm. In the section on
the Maximum Likelihood Tracking attack, we described the
computation of the forward variables
αt(r) = Pr{ox(1), ox(2), . . . , ox(t), ax(t) = r|P u}.
(25)
The backward variables are deﬁned to be
βt(r) = Pr{ox(t + 1), ox(t + 2), . . . , ox(T )|ax(t) = r, P u},
(26)
that is, βt(r) is the probability of the partial trace from time
t + 1 to the end, given that the region at time t is r and
given that user u created the trace.
Again, we can recursively compute the backward variables
using the fact that
βt(r) =
rMXρ=r1
P u
rρfρ(ox(t + 1))βt+1(ρ),
t = T − 1, T − 2, . . . , 1, r ∈ R.
(27)
Notice that the computation takes place backwards in
time. The initialization (at time T ) of the backward variables
is arbitrary:
βT (r) = 1, r ∈ R.
(28)
Having computed the backward variables, the probability
Pr{au(t) = r|ou} is then equal to
Pr{au(t) = r|ou, P u} =
αt(r)βt(r)
Pr(ou|P u)
.
(29)
The variable αt(r) accounts for the observations up to
time t and region r at time t, and βt(r) accounts for the
remainder of the observed trace, given that the region at t
is r. The term Pr(ou|P u) is a normalization factor that was
αT (r). An alternative way of
αt(r)βt(r), which more directly
earlier computed as PrM
computing it is as PrM
shows its role as a normalization factor.
r=r1
r=r1
E. Meeting Disclosure Attacks
In a meeting disclosure attack, a typical objective speciﬁes
a pair of users u and v, a region r, and a time t, and then
it asks whether this pair of users have met at that place
and time. The probability of this event is computed as the
product Pr{au(t) = r|ou, P u} Pr{av(t) = r|ov , P v} by
using the results of the localization attack. A more general
attack would specify only a pair of users and ask for the
expected number of time instants that they have met in
any region. Such questions can be answered by using the
results of the localization attack for each user ui as will
be explained in Section IV. Yet another question would not
specify any usernames, but only a region and a time. The
objective would be the expected number of present users
in the region at that time. Again, a localization attack for
each user would be the ﬁrst step as will be explained in
Section IV.
IV. USING THE TOOL: EVALUATION OF LPPMS
In this Section, we pursue two main goals:
• We show a few examples of using the Location-Privacy
Meter to quantify the effectiveness of LPPMs against
various attacks.
• We evaluate the appropriateness of two popular met-
rics, namely, k-anonymity and entropy, for quantifying
location privacy.
In order to use the Location-Privacy Meter, we ﬁrst
need to provide and specify (i) the location traces that we
obfuscate/anonymize, (ii) the LPPMs that we implement,
and (iii) the attacks that we perform.
The location traces that we use belong to N = 20 ran-
domly chosen mobile users (vehicles) from the epﬂ/mobility
dataset at CRAWDAD [17]. Each trace contains the location
of a user every 5min for 8hours (i.e., T = 96). The area
within which users move (the San Francisco bay area) is
divided into M = 40 regions forming a 5 × 8 grid.
We use two location-privacy preserving mechanisms that
are explained in Section III-A: precision reducing with
parameters µx, µy (the number of dropped low-order bits
from the x, y coordinate of a region, respectively), and
location hiding with parameter λh (the probability of hiding
a region). Let LPPM(µx, µy, λh) denote an LPPM with
these speciﬁc parameters. The traces are also anonymized
using a random permutation function (i.e., each user is
assigned a unique pseudonym from 1 to N ).
In order to consider the strongest adversary, we feed
the knowledge constructor (KC) module with the users’
actual traces. We run the inference mechanisms explained in
Sections III-C and III-D and obtain results for the following
U-R-T attack scenarios:
• LO-ATT: Localization Attack: For a given user u and
time t, what is the location of u at t? (Since the location
257
is a random variable, the answer is the probability
distribution over the regions).
• MD-ATT: Meeting Disclosure Attack: For a given pair
of users u and v, what is the expected number of
meetings between u and v? Put differently, at how many
time instants in T the two users are in the same region.
• AP-ATT: Aggregated Presence Attack: For a given
region r and time t, what is the expected number of
users present in r at t?
The metric to evaluate location privacy of users in all three
attacks is the failure of the adversary in ﬁnding the correct
answer: his incorrectness. For LO-ATT, according to (5), the
privacy of user u at time t is computed as
LPLO-ATT (u, t) =Xr∈R
ˆpu,t(r)kr − au(t)k
(30)
and v is
Z t
where au(t) is the actual location of u at time t, and the
distance kr − au(t)k is equal to 0 if r = au(t) (i.e., correct
estimation by the adversary), and it is equal to 1 otherwise.
Section III-D.
For MD-ATT, let Z t
Moreover, ˆpu,t(r) =cPr{au(t) = r|ou, P u} as described in
u,v = 1au(t)=av (t) be the random
variable that indicates whether u and v meet at time t. The
adversary estimates their expected number of meetings over
all time instants
Z t
ˆpu,t(r)ˆpv,t(r)
1au(t)=av (t)k, (31)
For AP-ATT, let Y u
whose values range from 0 and T .
u,v) −Xt
The actual number of meetings between u and v is
u,v = 1) =Xt Xr
u,v) =Xt cPr(Z t
r,t = 1au(t)=r be the random variable
that indicates whether u is in r at t. The adversary estimates
bE(Xt
Pt 1au(t)=av (t). Hence, according to (5), the privacy of u
LPMD-ATT (u, v) = kbE(Xt
the expected value ofPu Y u
r,t) =Xu cPr(Y u
bE(Xu
The actual number of users in region r at t isPu 1au(t)=r.
LPAP-ATT (r, t) = kbE(Xu
Hence, according to (5), the privacy of users at time t for
region r is
r,t = 1) =Xu
r,t) −Xu
and its values range from 0 to N .
Y u
1au(t)=rk,
(32)
Y u
ˆpu,t(r)
r,t which is
y
c
a
v
i
r
P
n
o
i
t
a
c
o
L
r
e
s
u
a
f
o
n
o
i
t
a
z
i
l
a
c
o
l
f
o
s
s
e
n
t
c
e
r
r
o
c
N
I
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
25
20
s
r
e
s
u
f
o
r
i
a
p
a
n
e
e