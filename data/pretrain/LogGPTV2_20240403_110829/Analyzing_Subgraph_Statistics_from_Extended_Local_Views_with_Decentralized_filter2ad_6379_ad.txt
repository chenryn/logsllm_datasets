(9)
as a probabilistic upper bound of d(vi). We can then set τ =
maxvi ∈G d⊤(vi) as a probabilistic upper bound of LSG (Γ△).
The advantage of this approach is that only a small amount of
noise is needed in {d∗(v1), . . . , d∗(vi)}. In particular, since adding
or removing an edge in G only changes the degrees of two nodes,
each by 1, the sensitivity of D = {d(v1), . . . , d(vi)} equals 2. Hence,
injecting Laplace noise Lap(2/ϵ) into Dд achieves ϵ-DDP. The dis-
advantage, however, is that d(vi) could be a rather loose upper
bound of c(vi), due to which setting τ = maxvi ∈G d⊤(vi) could
still lead to excessive noise in Phase 2. This motivates us to develop
a hybrid approach that combines both c⊤(vi) and d⊤(vi).
In the proposed hybrid approach, different nodes report different
information to the analyst, i.e., Mi varies depending on vi. The main
idea is as follows. First, we obtain a probabilistic degree upper bound
d⊤(vi) for every user vi, and we identify the set S of nodes whose
(cid:18) 1
(cid:19)
Algorithm 1: Optimized Two-Phase Approach
Input
:Privacy budget for phase 1 ϵ1, privacy budget for phase 2 ϵ2,
invalidation probability δ, a large number h′;
Output :Scale λ;
1 λd = 2
;
0.5ϵ1
2 δ′ = δ2h′+2 ;
3 for each vi do
4
Report d⊤(vi) to server;
d⊤(vi) = d(vi) + Lap(λd) + λd · log(cid:16) 1
i0.5ϵ1 · log(cid:16) 1
(cid:17) ≥ d⊤(v[i +2]) then
// Client
6 Sort {vi } into {v[1], v[2], . . . , v[n]} by d⊤(vi) in descending order;
7 for i = 1 to h′ do
8
// Server
// Client
// Server
// Server
// Server
// Server
(cid:17);
2δ′
if
2δ′
5
// Server
// Server
// Server
// Server
// Client
// Client
// Client
// Server
// Server
break;
9
10 h = ⌈i/2⌉;
11 S = {v[i]|2 ≤ i ≤ h + 1};
12 λc = h0.5ϵ1
13 for each vi ∈ S do
c⊤(vi) = c(vi) + Lap(λc) + λc · log(cid:16) 1
14
;
2δ′
(cid:17)
c†(vi) = min{c⊤(vi), d⊤(vi)}
Report c†(vi) to server;
ϵ2 d⊤(v[h′+2]),
1
ϵ2
15
16
17 λ = 3 max{ 1
18 return λ
maxvi ∈S c†(vi)};
degree upper bounds are the largest. Intuitively, for any v ∈ S,
using d⊤(v) as an upper bound of c(v) is likely to be ineffective,
since c(v) could be much smaller than d⊤(v). Therefore, for each
v ∈ S, we derive c⊤(v) as an alternative upper bound of c(v), instead
of relying solely on d⊤(v). Note that in this case, the amount of
Laplace noise injected into c⊤(v) is O(|S|) instead of O(n), since
we do not only request c⊤(v) for any v (cid:60) S. Finally, we combine
d⊤(v1), . . . , d⊤(vn) and c⊤(v) (v ∈ S) to compute an improved
upper bound of LSG (Γ△). We will explain later how to select the
set of nodes S used in this step later
Algorithm 1 shows the pseudo-code of the proposed solution for
Phase 1 of the framework. The algorithm involves two rounds of
reporting; all nodes participate in the first round, and only a selected
few participate in the second round. Specifically, the algorithm
starts by splitting budget λd and δ′ in Lines 1-2. This is done by
the server. Here we divide the budget ϵ1 into two halves for the
two-round reporting. We also divide the probability δ into 2h′ + 2
parts, where h′ is a user-specified number indicating the maximum
number of clients to do the second round of reporting. The specific
value of h′ slightly affects the accuracy of the estimation result, but
not the correctness of the algorithm. In our experiments, we found
that h′ = 100 usually leads to good results.
After that, the server sends these parameters to all the clients, i.e.,
nodes in the social network. Lines 4-5 are executed by each client,
which calculate the probabilistic upper bound of the actual degree
d(vi) and report it to the server, i.e., the data collector. Then, in
Lines 6-11, the server uses a heuristic to decide h ≤ h′, the number
of clients who do the second-round reporting, and obtains the set S
of h nodes. The intuition of the heuristic will be explained shortly.
In Line 12, the server spends another half of ϵ in the second-
round reporting. After getting λc, as shown in Lines 14-16, all the
clients in S calculate c⊤(vi) as their probabilistic upper bound of
common neighbor counts, then get their final upper bound c†(vi)
in Line 15 and report it to the server.
Finally, in Lines 17-18, the server computes the final upper bound
of each client, and selects the maximum one. However, it is possi-
ble that the client vi with maximum c(vi) is not in S, and hence,
maxvi ∈S c†(vi) is unable to cover the sensitivity. In such case, the
client is hiding in {v[h′+2], . . . , v[n]}, and it has to be covered by
d⊤(v[h′+2]). That is reason that we derive the final λ by getting the
maximum value in Line 17. Finally, since every addition/removal
of a triangle is always observed by 3 clients, we multiply the result
by 3.
Lemma 4.2. Algorithm 1 satisfies ϵ1-DDP and, with at least 1 − δ
probability, returns λ ≥ 1
ϵ2 LSG (Γ△).
As mentioned above, Lines 6-10 in Algorithm 1 are a heuristic
to choose h, the size of the set of nodes S who report further their
c⊤ to deduce a final upper bound λ. Clearly, if h is too small, the
final upper bound would be close to the second largest d⊤, which
is likely to be much larger than the maximum c(v) among all nodes.
If h is too large, each node v in S would end up adding too much
noise to c(v), again resulting in a much larger final upper bound.
To find an appropriate h, we have the following intuition. Suppose
that h = i. Observe that for each node v in S, besides the Laplace
noise, it also needs to add an additional noise
c(v). If this noise is already bigger than d⊤(v[h+2]), then any bigger
i would not result in smaller final upper bounds. Meanwhile, since
c⊤(v) also includes c(v), the i we have now is likely to be more than
enough to ensure c⊤(v) > d⊤. Therefore, we set h = i2 to derive
the final upper bound. In Section 5, we experimentally evaluate the
quality of this heuristic in choosing h.
i0.5ϵ1 · loд
(cid:17) to
(cid:16) 1
2δ′
4.2 Three-Hop Paths
Baseline: Pessimistic Laplace mechanism. A three-hop path
refers to a set of three edges that form a simple path. Suppose that
we let each user vi report the number γ⊔(vi) of three-hop paths
in which she is one of the two nodes in the middle (referred to
as the internal nodes). In that case, the Pessimistic Laplace mech-
anism (explained in Section 3.1) lets each vi inject Laplace noise
Lap (6(n − 2)(n − 3)/ϵ) into γ⊔(vi) before reporting it. To explain,
observe that for any two nodes u and v, there can be at most
6(n − 2)(n − 3) three-hop paths in which ⟨u, v⟩ is one of the edges.
Accordingly, the sensitivity of Γ⊔ = {γ⊔(v1), . . . , γ⊔(vn)} equals
6(n − 2)(n − 3), since (i) adding or removing an edge ⟨u, v⟩ in G af-
fects at most 3(n− 2)(n− 3) three-hop paths, and (ii) each three-hop
path is reported by two users.
Two-phase solution. Next we apply the proposed two-phase
framework, for which the key is to develop an (ϵ1, δ)-differentially
private algorithm for computing a probabilistic upper bound of
LSG (Γ⊔). Observe that
LSG (Γ⊔) ≤
max
(d (vℓ) − 1)
2(cid:16)
d (vi) · d(cid:0)vj(cid:1) + 
(d (vℓ) − 1)(cid:17)
+ 
,
(10)
vi,vj ∈G,i(cid:44)j
vℓ ∈N(vi)
vℓ ∈N(vj)
Phase 1: Derive d⊤(vi) with Lap
Phase 2: Derive Γ⊔ based on d⊤(vi) and ψ⊤(vi)
(a) Two-phase solution.
ϵ1a
(cid:16) 2
(cid:17) and ψ⊤(vi) with Lap
(cid:17)
(cid:16) 8(n−2)
ϵ1b
Phase 1:
(cid:16) 2
Sub-Phase 1: Derive d⊤(vi) with Lap
ϵ1a
Sub-Phase 2: Derive ψ⊤(vi) based on Lap
(cid:17)
(cid:32) 4(cid:16)
d⊤
(1)+d⊤
(2)
ϵ1b
(cid:33)
(cid:17)
Phase 2: Derive Γ⊔ based on d⊤(vi) and ψ⊤(vi)
(b) Proposed three-phase solution.
Figure 3: Comparison of two-phase and three-phase solutions for counting three-hop paths under DDP.
at most
Let ψ(vi) =
where d(v) denotes the degree of v and N(v) denotes the set of
neighbors of v. This is because there can be (i) at most d(vi) · d(vj)
three-hop paths in which vi and vj are the two internal nodes, (ii)
vℓ ∈N(vj) (d (vℓ) − 1) three-hop
paths in which ⟨vi , vj⟩ is an edge and either vi or vj is an end point.
vℓ ∈N(vi) 2(d (vℓ) − 1) and Ψ = {ψ(v1), . . . ,ψ(vn)}.
By Eq. (10), if we can derive probabilistic upper bounds d⊤(vi)
and ψ⊤(vi) for d(vi) and ψ(vi), respectively, then we can use
maxvi,vj ∈G,i(cid:44)j
bound of LSG (Γ⊔).
Note that d⊤(vi) can be computed based on Eq. (9). To derive
ψ⊤(vi), we may utilize Lemma 4.1 as follows. First, we let each user
vi inject Laplace noise Lap
ψ∗(vi), and then setting
vℓ ∈N(vi) (d (vℓ) − 1) +
(cid:0)2d⊤(vi) · d⊤(vj) + ψ⊤(vi) + ψ⊤(vj)(cid:1) as an upper
(cid:17) into ψ(vi), to obtain a noisy value
(cid:16)
λψ
⊤(vi) = ψ
∗(vi) + λψ · log
ψ
,
(11)
(cid:33)
(cid:32) 1
2δψ
LSG (Ψ) ≤
4(cid:0)d(vi) + d(vj)(cid:1) .
for some δψ . This approach, however, offers inferior accuracy, as it
requires λψ ≥ 8(n − 2)/ϵ to achieve ϵ-DDP, because the sensitivity
of Ψ equals 8(n−2). To understand this, observe that when all nodes
in G are connected to each other, we have ψ(vi) = 2(n − 1)(n − 2)
for every user vi. If we remove the edge ⟨v1, v2⟩, then we have
ψ(v1) = ψ(v2) = 2(n − 2)2, and ψ(vj) = 2(n − 1)(n − 2)− 4 for j ≥ 3.
This worst-case scenario leads to a total change of 8(n − 2) in Ψ,
which explains the sensitivity of Ψ.
Proposed three-phase solution. Next we present the proposed
solution, which recursively applies the two-phase framework to
the estimation of Ψ. Observe that although Ψ has a large sensitivity,
its local sensitivity LSG (Ψ) can be much smaller:
max
vi,vj ∈G∧i(cid:44)j
(12)
In particular, when one edge ⟨vi , vj⟩ is added or removed in G,
(i) ψ(vi) changes by at most 2d(vj), (ii) ψ(vj) changes by at most
2d(vi), and (iii) {ψℓ | ℓ (cid:44) i, j} changes by at most 2d(vi) + 2d(vj).
The fact that LSG (Ψ) is relatively small motivates the recurisve
application of the two-phase framework on the estimation of Ψ, i.e.,
we first compute a probabilistic upper bound of LSG(Ψ), and then
inject noise into Ψ accordingly. After that, we derive a probabilistic
upper bound ψ⊤(vi) for each user vi, and ask them to report their
square counts injected with Laplace noise Lap
.
Figure 3 illustrates the differences between the proposed three-
phase solution and the aforementioned two-phase solution, which
suffers from the large sensitivity of Ψ.
We now explain how we derive a probabilistic upper bound
ψ⊤(vi) of each ψ(vi). First, we compute a probabilistic degree upper
bound d⊤(vi) for each vi, based on Eq. (9). Let d⊤
(2) be
(cid:18) maxvi ∈Gψ ⊤(vi)
(1) and d⊤
(cid:19)
ϵ2
// Client
6 Sort {vi } into {v[1], v[2], . . . , v[n]} by d⊤(vi) in descending order;
// Server
// Server
// Client
(cid:17);
// Server
// Server
// Client
// Client
// Server
// Server
:Privacy budget for phase 1 ϵ1, privacy budget for phase 2 ϵ2,
invalidation probability δ, a large number h′
;
Algorithm 2: Optimized Three-Phase Approach
Input
1 λd = 2
0.5ϵ1
2 δ1 = δ;
3 for each vi do
4
d⊤(vi) = d(vi) + Lap(λd) + λd · log(cid:16) 1
Report d⊤(vi) to server;
d⊤(v[1])+d⊤(v[2])(cid:17)
4(cid:16)
ψ ⊤(vi) = ψ(vi) + Lap(λψ ) + λψ · log(cid:16) 1
7 λψ =
8 δ2 = δ;
9 for each vi do
10
// Server
0.5ϵ1
2δ1
5
;
2δ2
(cid:17);
Report ψ ⊤(vi) to server;
11
12 λ = 1
ϵ2
13 return λ
maxvi ∈G ψ ⊤(vi);