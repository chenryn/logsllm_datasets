title:ILAB: An Interactive Labelling Strategy for Intrusion Detection
author:Ana&quot;el Beaugnon and
Pierre Chifflier and
Francis R. Bach
ILAB: An Interactive Labelling Strategy
for Intrusion Detection
Ana¨el Beaugnon1,2(B), Pierre Chiﬄier1, and Francis Bach2
1 French Network Security Agency (ANSSI), Paris, France
{anael.beaugnon,pierre.chifflier}@ssi.gouv.fr
2 INRIA, ´Ecole Normale Sup´erieure, Paris, France
PI:EMAIL
Abstract. Acquiring a representative labelled dataset is a hurdle that
has to be overcome to learn a supervised detection model. Labelling a
dataset is particularly expensive in computer security as expert knowl-
edge is required to perform the annotations. In this paper, we introduce
ILAB, a novel interactive labelling strategy that helps experts label large
datasets for intrusion detection with a reduced workload. First, we com-
pare ILAB with two state-of-the-art labelling strategies on public labelled
datasets and demonstrate it is both an eﬀective and a scalable solution.
Second, we show ILAB is workable with a real-world annotation project
carried out on a large unlabelled NetFlow dataset originating from a
production environment. We provide an open source implementation
(https://github.com/ANSSI-FR/SecuML/) to allow security experts to
label their own datasets and researchers to compare labelling strategies.
Keywords: Intrusion detection · Active learning · Rare category
detection
1 Introduction
Supervised learning is adapted to intrusion detection and has been success-
fully applied to various detection problems: Android applications [11], PDF
ﬁles [7,35], botnets [2,5], Windows audit logs [4], portable executable ﬁles [19].
However, supervised detection models must be trained on representative labelled
datasets which are particularly expensive to build in computer security. Expert
knowledge is required to annotate and data are often conﬁdential. As a result,
crowd-sourcing [37] cannot be applied as in computer vision or natural lan-
guage processing to acquire labelled datasets at low cost. Some labelled datasets
related to computer security are public (Malicia project [22], KDD99 [41],
kyoto2006 [39], etc.) but they are quickly outdated and they often do not account
for the idiosyncrasies of each deployment context.
Electronic supplementary material The online version of this chapter (doi:10.
1007/978-3-319-66332-6 6) contains supplementary material, which is available to
authorized users.
c(cid:2) Springer International Publishing AG 2017
M. Dacier et al. (Eds.): RAID 2017, LNCS 10453, pp. 120–140, 2017.
DOI: 10.1007/978-3-319-66332-6 6
ILAB: An Interactive Labelling Strategy for Intrusion Detection
121
Experts are essential for annotating but they are an expensive resource, that
is why the labelling process must use expert time eﬃciently. Active learning
methods have been proposed to reduce the labelling cost by asking the expert
to annotate only the most informative examples [32]. However, classical active
learning methods often suﬀer from sampling bias [29,34]: a family (a group of
similar malicious or benign examples) may be completely overlooked by the
annotation queries as the expert is asked to annotate only the most informative
examples. Sampling bias is a signiﬁcant issue in intrusion detection: it may lead
to missing a malicious family during the labelling process, and being unable to
detect it thereafter. Moreover, the labelling strategy must scale to large datasets
to be workable on real-world annotation projects.
Finally, active learning is an interactive process which must ensure a good
expert-model interaction, i.e. a good interaction between the expert who anno-
tates and the detection model [33,43]. The expert annotations improve not only
the detection model but also the relevance of the following annotation queries.
A low execution time is thus required to allow frequent updates of the detec-
tion model with the expert feedback. A labelling strategy with a high execution
time would alter the expert-model interaction and is unlikely to be accepted by
experts.
In this paper, we introduce ILAB, a novel interactive labelling strategy that
helps an expert acquire a representative labelled dataset with a reduced work-
load. ILAB relies on a new hierarchical active learning method with binary labels
(malicious vs. benign) and user-deﬁned malicious and benign families. It avoids
the sampling bias issue encountered by classical active learning as it is designed
to discover the diﬀerent malicious and benign families. Moreover, the scalable
algorithms used in ILAB make it workable on large datasets and guarantee a
low expert waiting time for a good expert-model interaction.
Our paper makes the following contributions:
– We present a novel active learning method called ILAB designed to avoid
sampling bias. It has a low computation cost to ensure a good expert-model
interaction, and it is scalable to large datasets.
– We compare ILAB with two state-of-the-art active learning methods for intru-
sion detection [14,40] on two detection problems. We demonstrate that ILAB
improves the scalability without reducing the eﬀectiveness. Up to our knowl-
edge, [14,40] have never been compared. We provide an open source imple-
mentation of ILAB and of these two labelling strategies to foster comparison
in future research works.
– We show that ILAB is a workable labelling strategy that scales to large real-
world datasets with an annotation project on NetFlow data originating from
a production environment. We provide an open source implementation of the
graphical user interface deployed during the annotation project to allow secu-
rity experts to label their own datasets.
The rest of the paper is organized as follows. Section 2 presents the sampling
bias issue in active learning and related works. The problem being addressed and
the notations are detailed in Sect. 3. Section 4 explains ILAB labelling strategy.
122
A. Beaugnon et al.
Finally, Sect. 5 compares ILAB with state-of-the-art labelling strategies through
simulations run on public fully labelled datasets, and Sect. 6 presents a real-
world annotation project carried out with ILAB on a large unlabelled NetFlow
dataset.
2 Background and Related Work
Active Learning. Active learning [32] methods have been developed in the
machine learning community to reduce the labelling cost. A labelling strategy
asks the expert to annotate only the most informative instances, i.e. the ones
that lead to the best detection model. Active learning methods rely on an inter-
active process where the expert is asked to annotate some instances from a large
unlabelled pool to improve the current detection model and the relevance of the
future annotation queries (see Fig. 1). However, annotating only the most infor-
mative instances may cause a family of observations to be completely missed
by the labelling process (see [8,29] for theoretical examples) and, therefore, may
have a negative impact on the performance of the detection model.
Train a model
Detection Model
Labelled Dataset
Unlabelled Pool
Expert
New labelled instances
Annotation queries
Fig. 1. Active learning: an interactive process
B1
45%
M1
1%
M3
10%
Decision Boundary
Sampling Bias. Figure 2 provides an example of
sampling bias in one dimension with uncertainty
sampling [20] which queries the closest instances
to the decision boundary. Each block represents
a malicious or a benign family. With this data
distribution, instances from the family M1 are
Fig. 2. Sampling bias example
unlikely to be part of the initial training dataset,
and so the initial decision boundary is likely to lie between the families B2 and
M3. As active learning proceeds, the classiﬁer will gradually converge to the
decision boundary between the families B2 and M2 and will only ask the expert
to annotate instances from these two families to reﬁne the decision boundary. The
malicious family M1 on the left is completely overlooked by the query algorithm
Missed cluster
B2
40%
M2
4%
ILAB: An Interactive Labelling Strategy for Intrusion Detection
123
as the classiﬁer is mistakenly conﬁdent that the entire family is benign. As the
malicious family M1 is on the wrong side of the decision boundary, the classiﬁer
will not be able to detect this malicious family thereafter.
Sampling bias is a signiﬁcant problem for intrusion detection that may lead to
malicious families remaining completely undetected. Besides, the risk of sampling
bias is even higher for intrusion detection than for other application domains
because the initial labels are not uniformly distributed. Uniform random sam-
pling cannot be used to acquire the initial labelled instances as the malicious
class is too under-represented. The signatures widely deployed in detection sys-
tems can provide initial labels but they likely all belong to the same family or
to a small number of families.
Related Work. Online active learning [21,30,31,44,45] is well-suited to follow the
evolution of the threats: experts perform annotations over time to update the
detection model that is already deployed. In this setting, the detection model in
production has been initially trained on a labelled dataset representative of the
deployment environment. In our case, such a representative labelled dataset is
unavailable and the objective is to acquire it oﬄine to train the initial detection
model.
Some works focus on oﬄine active learning to build a labelled dataset for
intrusion detection. First, Almgren et al. [1] have applied plain uncertainty sam-
pling [20] to intrusion detection before the sampling bias issue has been dis-
covered. Then, Aladin [40] and G¨ornitz et al. [14] have proposed new labelling
strategies for intrusion detection that intend to discover the diﬀerent malicious
families. Aladin applies rare category detection [26] on top of active learning to
foster the discovery of the diﬀerent families, and G¨ornitz et al. use a k-nearest
neighbour approach to detect yet unknown malicious families. However, both
[14,40] deal with sampling bias at the expense of the expert-model interaction.
These labelling strategies require heavy computations to generate the annotation
queries that cause long waiting-periods that cannot be exploited by the expert.
ILAB relies on rare category detection to avoid sampling bias, as Aladin, but
with a divide and conquer approach to ensure a good expert-model interaction.
Aladin [40] and G¨ornitz et al. [14] labelling strategies have never been compared
to our knowledge. We compare ILAB with these two labelling strategies in the
simulations presented in Sect. 5 and we provide open source implementations in
order to foster comparison in future research works.
Finally, active learning is an interactive process where a user interface is
required for the expert to annotate. Almgren et al. and G¨ornitz et al. have
only run simulations on fully labelled datasets with an oracle answering the
annotation queries and they have not mentioned any user interface. Aladin has
a corresponding graphical user interface, but [40] provides no detail about it.
As an ergonomic user interface can deﬁnitely reduce the expert eﬀort [9,33],
ILAB comes up with an open source graphical user interface brieﬂy described in
Sect. 6.
124
A. Beaugnon et al.
3 Problem Statement
m}
Our goal is to acquire a representative labelled dataset from a pool of unlabelled
instances with a reduced human eﬀort. Both the number of annotations asked
from the expert and the computation time for generating the annotation queries
must be minimized to reduce the workload and ensure a good expert-model
interaction. We assume that there is no adversary attempting to mislead the
labelling strategy as it is performed oﬄine before the detection model is deployed
in production.
Notations. Let D = {xi ∈ R
1≤i≤N be the dataset we want to label partially
to learn a supervised detection model M. It contains N instances described by
m real-valued features. For example, each instance xi could represent a PDF ﬁle,
an Android application, the traﬃc of an IP address, or the activity of a user.
Such unlabelled data are usually easy to acquire from the environment where the
detection system is deployed (ﬁles, network traﬃc captures, or logs for example).
To represent an instance with real-valued features the expert must extract
discriminating features and transform them into real values. Many research
works focus on feature extraction for given detection problems: Android applica-
tions [11], PDF ﬁles [7,35], Windows audit logs [4], portable executable ﬁles [19].
In this paper, we do not address feature extraction and we focus on reducing the
cost of building a representative labelled dataset with an eﬀective labelling strat-
egy. Instances are represented by real-valued features regardless of the detection
problem thanks to feature extraction. As a result, labelling strategies are generic
regarding the detection problems.
Let L = {Malicious, Benign} be the set of labels and Fy be the set contain-
ing the user-deﬁned families of the label y ∈ L. For example, malicious instances
belonging to the same family may exploit the same vulnerability, they may be
polymorphic variants of the same malware, or they may be emails coming from
the same spam campaign.
maximizing the accuracy of the detection model M trained on DL. DL associates
a label y ∈ L and a family z ∈ Fy to each instance x ∈ D. The labelled
dataset DL is built with an iterative active learning strategy. At each iteration,
a security expert is asked to annotate, with a label and a family, b ∈ N instances
selected from the pool of remaining unlabelled instances denoted by DU . During
the annotation process, the expert cannot annotate more instances than the
annotation budget B ∈ N.
Objective. The objective of the labelling strategy is to build DL maximizing the
accuracy of the detection model M while asking the expert to annotate at most
B instances. In other words, the labelling strategy aims to ask the expert to
annotate the B instances that maximize the performance of the detection model
M. Besides, the labelling strategy must be scalable to work on large datasets
while keeping a low expert waiting time.
Our aim is to create a labelled dataset
DL ⊆ {(x, y, z) | x ∈ D, y ∈ L, z ∈ Fy}
ILAB: An Interactive Labelling Strategy for Intrusion Detection
125
4 ILAB Labelling Strategy
ILAB is an iterative annotation process based on active learning [32] and rare
category detection [26]. At each iteration, the expert is asked to annotate b
instances to improve the current detection model and to discover yet unknown
families. Active learning improves the binary classiﬁcation model raising the
alerts while rare category detection fosters the discovery of new families to avoid
sampling bias. First, we describe how we initialize the active learning process
and then we explain the labelling strategy, i.e. which instances are selected from
the unlabelled pool to be annotated by the expert.
L
DMalicious
DBenign
DMalicious
DBenign
U
L
U
M3
Decision
Boundary
M2
M1
B1
Annotation Queries
Uncertainty sampling (1)
Low likelihood (2)
High likelihood (3)
B2
Fig. 3. ILAB labelling strategy
Initial Supervision. The active learning process needs some initial labelled exam-
ples to learn the ﬁrst supervised detection model. This initial supervision can be
diﬃcult to acquire for detection problems. The Malicious class is usually too
under-represented for uniform random sampling to be eﬀective at collecting a
representative labelled dataset.
If a public labelled dataset is available for the detection problem considered, it
can be used for the initial supervision. Otherwise, the signatures widely deployed