incremental online learning [63] for model updation.
VIII. RELATED WORK
Bot Detection. Bot detection is a well-studied area, and key
related works have been summarized in Section II. Compared
to most existing works on application-speciﬁc bots (e.g., social
network bots, game bots) [64], [21], [20], [29], [19], [65],
[66], [67], we explicitly prioritize the model generalizability
by avoiding any application or account speciﬁc features. Our
main novelty is to explore the use of data synthesis for bot
detection with limited data. We also show data synthesis helps
to slow down the model decaying over time. One recent
work [12] studied “concept drift” to determine when to re-
train a classiﬁer (for malware detection). Our work looks into
a complementary direction by exploring ways to effectively
retrain the classiﬁer with limited data.
Anomaly Detection.
Anomaly detection aims to detect
anomalous data samples compared to known data distribu-
tion [68], [69], [70], [71], [72]. Researchers have applied
anomaly detection methods to detect bots and other fraudulent
activities [73], [60]. These works share a similar assumption
with ODDS, that is, the normal/benign data should be (rela-
tively) representative and stable. In our work, we use anomaly
detection methods as our baselines, and show the beneﬁt of
synthesizing new data based on both the normal samples and
the limited abnormal samples.
Data Augmentation using GANs.
To generate more data
for training, various transformations can be applied to existing
training data. In the domain of computer vision and natural
language processing, researchers have proposed various data
augmentation methods including GAN to improve the perfor-
mance of one-shot learning [74], image segmentation [75],
image rendering [76], and emotion classiﬁcation [77]. The
most related work to ours is OCAN [60], which uses GAN
to synthesize malicious samples for fraud detection. We have
compared our system with OCAN in our evaluation, and
demonstrated the beneﬁts of using two generators to handle
outliers and clustered data differently.
Recent works have explored introducing multiple generators
to GAN [78], [79], [80], [81]. But their goals are to make
the synthesized data (e.g., synthesized images) closer to the
target distribution. On the contrary, we are not interested in
generating data that resemble the known bots, but to synthesize
data for unknown bots. This calls for entirely different designs
(e.g., using different generators for outliers and clustered data).
IX. CONCLUSION
In this paper, we propose a stream-based bot detection
model and augment it with a novel data synthesis method
called ODDS. We evaluate our system on three different real-
world online services. We show that ODDS makes it possible
to train a good model with only 1% of the labeled data, and
helps the model to sustain over a long period of time with
low-cost retraining. We also explore the relationship between
data synthesis and adversarial re-training, and demonstrate the
different beneﬁts from both approaches.
ACKNOWLEDGEMENT
We thank our shepherd Suman Jana and anonymous review-
ers for their constructive feedback. We also thank Harisankar
Haridas for discussions on bot behavior. This work was
supported by NSF grants CNS-1750101 and CNS-1717028.
REFERENCES
[1] V. Dave, S. Guha, and Y. Zhang, “ViceROI: Catching click-spam in
search ad networks,” in Proc. of CCS, 2013.
[2] Y. Mirsky, T. Doitshman, Y. Elovici, and A. Shabtai, “Kitsune: An
ensemble of autoencoders for online network intrusion detection,” in
Proc. of NDSS, 2018.
[3] K. Bartos, M. Sofka, and V. Franc, “Optimized invariant representation
of network trafﬁc for detecting unseen malware variants,” in Proc. of
USENIX Security, 2016.
[4] G. Stringhini, C. Kruegel, and G. Vigna, “Shady paths: Leveraging
surﬁng crowds to detect malicious web pages,” in Proc. of CCS, 2013.
[5] K. Tian, S. T. K. Jan, H. Hu, D. Yao, and G. Wang, “Needle in a
haystack: Tracking down elite phishing domains in the wild,” in Proc.
of IMC, 2018.
[6] H. Li, X. Xu, C. Liu, T. Ren, K. Wu, X. Cao, W. Zhang, Y. Yu, and
D. Song, “A machine learning approach to prevent malicious calls over
telephony networks,” in Proc. of IEEE S&P, 2018.
[7] D. Arp, M. Spreitzenbarth, M. Hubner, H. Gascon, and K. Rieck,
“DREBIN: Effective and explainable detection of android malware in
your pocket,” in Proc. of NDSS, 2014.
[8] G. Dahl, J. Stokes, L. Deng, and D. Yu, “Large-scale malware clas-
siﬁcation using random projections and neural networks,” in Proc. of
ICASSP, 2013.
[9] N. Srndic and P. Laskov, “Detection of malicious PDF ﬁles based on
hierarchical document structure,” in Proc. of NDSS, 2013.
[10] S. E. Coull and C. Gardner, “Activation analysis of a byte-based deep
neural network for malware classiﬁcation,” in Proc. of DLS workshop,
2019.
[11] P. Gao, X. Xiao, D. Li, Z. Li, K. Jee, Z. Wu, C. H. Kim, S. R.
Kulkarni, and P. Mittal, “SAQL: A stream-based query system for real-
time abnormal system behavior detection,” in Proc. of USENIX Security,
2018.
[12] R. Jordaney, K. Sharad, S. K. Dash, Z. Wang, D. Papini, I. Nouretdinov,
in malware
and L. Cavallaro, “Transcend: Detecting concept drift
classiﬁcation models,” in Proc. of USENIX Security, 2017.
[13] T. Lokot and N. Diakopoulos, “News bots: Automating news and
information dissemination on Twitter,” Digital Journalism, vol. 4, pp.
682–699, 8 2016.
[14] S. Savage, A. Monroy-Hernandez, and T. Höllerer, “Botivist: Calling
volunteers to action using online bots,” in Proc. of CSCW, 2016.
[15] C. A. Davis, O. Varol, E. Ferrara, A. Flammini, and F. Menczer,
“BotOrNot: A system to evaluate social bots,” in Proc. of WWW, 2016.
[16] K. Chiang and L. Lloyd, “A case study of the rustock rootkit and spam
bot,” HotBots, vol. 7, no. 10-10, p. 7, 2007.
[17] G. Gu, R. Perdisci, J. Zhang, and W. Lee, “BotMiner: Clustering
analysis of network trafﬁc for protocol- and structure-independent botnet
detection,” in Proc. of NDSS, 2008.
[18] V. Dave, S. Guha, and Y. Zhang, “Measuring and ﬁngerprinting click-
spam in Ad networks,” in Proc. of SIGCOMM, 2012.
[19] G. Wang, T. Konolige, C. Wilson, X. Wang, H. Zheng, and B. Y. Zhao,
“You are how you click: Clickstream analysis for sybil detection,” in
Proc. of USENIX Security, 2013.
[20] K. Thomas, D. McCoy, C. Grier, A. Kolcz, and V. Paxson, “Trafﬁcking
fraudulent accounts: The role of the underground market in Twitter spam
and abuse,” in Proc. of USENIX Security, 2013.
[21] K. Thomas, C. Grier, D. Song, and V. Paxson, “Suspended accounts in
retrospect: An analysis of Twitter spam,” in Proc. of IMC, 2011.
[22] E. De Cristofaro, N. Kourtellis, I. Leontiadis, G. Stringhini, and S. Zhou,
“LOBO: Evaluation of generalization deﬁciencies in Twitter bot classi-
ﬁers,” in Proc. of ACSAC, 2018.
[23] L. Von Ahn, M. Blum, N. J. Hopper, and J. Langford, “CAPTCHA:
Using hard AI problems for security,” in Proc. of EUROCRYPT, 2003.
[24] R. Sommer and V. Paxson, “Enhancing byte-level network intrusion
detection signatures with context,” in Proc. of CCS, 2003.
[25] S. Kudugunta and E. Ferrara, “Deep neural networks for bot detection,”
Information Sciences, vol. 467, pp. 312–322, 2018.
[26] D. Damopoulos, S. A. Menesidou, G. Kambourakis, M. Papadaki,
N. Clarke, and S. Gritzalis, “Evaluation of anomaly-based IDS for
mobile devices using machine learning classiﬁers,” Security and Com-
munication Networks, vol. 5, no. 1, pp. 3–14, 2012.
[27] S. Ranjan, J. Robinson, and F. Chen, “Machine learning based botnet
detection using real-time connectivity graph based trafﬁc features,” 2014,
uS Patent 8,762,298.
[28] A. Javaid, Q. Niyaz, W. Sun, and M. Alam, “A deep learning approach
for network intrusion detection system,” in Proc. of BICT, 2016.
[29] D. Freeman, S. Jain, M. Dürmuth, B. Biggio, and G. Giacinto, “Who
are you? A statistical approach to measuring user authenticity.” in Proc.
of NDSS, 2016.
[30] L. Akoglu, H. Tong, and D. Koutra, “Graph based anomaly detection and
description: A survey,” Data mining and knowledge discovery, vol. 29,
no. 3, pp. 626–688, 2015.
[31] L. Invernizzi, P. M. Comparetti, S. Benvenuti, C. Kruegel, M. Cova,
and G. Vigna, “EVILSEED: A guided approach to ﬁnding malicious
web pages,” in Proc. of IEEE S&P, 2012.
[32] E. Manzoor, S. M. Milajerdi, and L. Akoglu, “Fast memory-efﬁcient
anomaly detection in streaming heterogeneous graphs,” in Proc. of KDD,
2016.
[33] K. Bock, D. Patel, G. Hughey, and D. Levin, “unCaptcha: A low-
resource defeat of reCaptcha’s audio challenge,” in Proc. of WOOT,
2017.
[34] G. Ye, Z. Tang, D. Fang, Z. Zhu, Y. Feng, P. Xu, X. Chen, and Z. Wang,
“Yet another text CAPTCHA solver: A generative adversarial network
based approach,” in Proc. of CCS, 2018.
[35] W. Aiken and H. Kim, “POSTER: DeepCRACk: Using deep learning
to automatically crack audio CAPTCHAs,” in Proc. of ASIACCS, 2018.
[36] M. Mohamed, N. Sachdeva, M. Georgescu, S. Gao, N. Saxena, C. Zhang,
P. Kumaraguru, P. C. van Oorschot, and W.-B. Chen, “A three-way
investigation of a game-CAPTCHA: Automated attacks, relay attacks
and usability,” in Proc. of ASIACCS, 2014.
[37] C. Shi, X. Xu, S. Ji, K. Bu, J. Chen, R. Beyah, and T. Wang, “Adversarial
CAPTCHAs,” CoRR abs/1901.01107, 2019.
[51] Y. Qin, N. Carlini, I. Goodfellow, G. Cottrell, and C. Raffel, “Imper-
ceptible, robust, and targeted adversarial examples for automatic speech
recognition,” in Proc. of ICML, 2019.
[52] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley,
S. Ozair, A. Courville, and Y. Bengio, “Generative adversarial nets,” in
Proc. of NeurIPS, 2014.
[53] H. Zenati, C. S. Foo, B. Lecouat, G. Manek, and V. R. Chandrasekhar,
“Efﬁcient GAN-based anomaly detection,” in Proc. of ICLR Workshop,
2018.
[38] M. Motoyama, K. Levchenko, C. Kanich, D. McCoy, G. M. Voelker,
and S. Savage, “Re: CAPTCHAs: Understanding CAPTCHA-solving
services in an economic context,” in Proc. of USENIX Security, 2010.
[39] K. M. Tan and R. A. Maxion, “Why 6? Deﬁning the operational limits
of stide, an anomaly-based intrusion detector,” in Proc. of IEEE S&P,
2002.
[40] A. Pathak, F. Qian, Y. Hu, Z. Mao, and S. Ranjan, “Botnet spam
campaigns can be long lasting: Evidence, implications, and analysis,”
in Proc. of SIGMETRICS, 2009.
[41] S. Nilizadeh, H. Aghakhani, E. Gustafson, C. Kruegel, and G. Vigna,
“Think outside the dataset: Finding fraudulent reviews using cross-
dataset analysis,” in Proc. of WWW, 2019.
[42] B. Stone-Gross, T. Holz, G. Stringhini, and G. Vigna, “The underground
economy of spam: A botmaster’s perspective of coordinating large-scale
spam campaigns,” in Proc. of LEET, 2011.
[43] T. Mikolov, I. Sutskever, K. Chen, G. Corrado, and J. Dean, “Distributed
representations of words and phrases and their compositionality,” in
Proc. of NeurIPS, 2013.
[44] S. Wang, C. Liu, X. Guo, H. Qu, and W. Xu, “Session-based fraud
detection in online E-commerce transactions using recurrent neural
networks,” in Proc. of ECML-PKDD, 2017.
[45] R. ˇReh˚uˇrek and P. Sojka, “Software framework for topic modelling with
large corpora,” in Proc. of LREC Workshop on New Challenges for NLP
Frameworks, 2010.
[46] T. Mikolov, M. Karaﬁát, L. Burget, J. ˇCernock`y, and S. Khudanpur,
“Recurrent neural network based language model,” in Proc. of INTER-
SPEECH, 2010.
[47] S. Hochreiter and J. Schmidhuber, “Long short-term memory,” Neural
Comput., vol. 9, no. 8, pp. 1735–1780, 1997.
[48] H.-T. Cheng, L. Koc, J. Harmsen, T. Shaked, T. Chandra, H. Aradhye,
G. Anderson, G. Corrado, W. Chai, M. Ispir et al., “Wide & deep
learning for recommender systems,” in Proc. of DLRS, 2016.
[49] F. Pendlebury, F. Pierazzi, R. Jordaney, J. Kinder, and L. Cavallaro,
“TESSERACT: Eliminating experimental bias in malware classiﬁcation
across space and time,” in Proc. of USENIX Security, 2019.
[50] N. Carlini and D. Wagner, “Towards evaluating the robustness of neural
networks,” in Proc. of IEEE S&P, 2017.
[58] A. Niculescu-Mizil and R. Caruana, “Predicting good probabilities with
supervised learning,” in Proc. of ICML, 2005.
[59] L. Breiman, “Random forests,” Mach. Learn., vol. 45, no. 1, pp. 5–32,
2001. [Online]. Available: https://doi.org/10.1023/A:1010933404324
[60] P. Zheng, S. Yuan, X. Wu, J. Li, and A. Lu, “One-class adversarial nets
for fraud detection,” in Proc. of AAAI, 2019.
[61] N. Papernot, P. D. McDaniel, and I. J. Goodfellow, “Transferability
in machine learning: From phenomena to black-box attacks using
adversarial samples,” CoRR abs/1605.07277, 2016.
[62] O. Suciu, R. Marginean, Y. Kaya, H. D. III, and T. Dumitras, “When
does machine learning FAIL? Generalized transferability for evasion and
poisoning attacks,” in Proc. of USENIX Security, 2018.
[63] M. Du, Z. Chen, C. Liu, R. Oak, and D. Song, “Lifelong anomaly
detection through unlearning,” in Proc. of CCS, 2019.
[64] D. M. Freeman, “Can you spot the fakes? On the limitations of user
feedback in online social networks,” in Proc. of WWW, 2017.
[65] G. Wang, T. Wang, H. Zheng, and B. Y. Zhao, “Man vs. Machine:
Practical adversarial detection of malicious crowdsourcing workers,” in
Proc. of USENIX Security, 2014.
[66] H. Zheng, M. Xue, H. Lu, S. Hao, H. Zhu, X. Liang, and K. W. Ross,
“Smoke screener or straight shooter: Detecting elite sybil attacks in user-
review social networks,” in Proc. of NDSS, 2018.
[67] E. Lee, J. Woo, H. Kim, A. Mohaisen, and H. K. Kim, “You are a
game bot! Uncovering game bots in MMORPGs via self-similarity in
the wild,” in Proc. of NDSS, 2016.
[68] C. Zhou and R. C. Paffenroth, “Anomaly detection with robust deep
autoencoders,” in Proc. of KDD, 2017.
[54] M. Ester, H.-P. Kriegel, J. Sander, and X. Xu, “A density-based algo-
rithm for discovering clusters a density-based algorithm for discovering
clusters in large spatial databases with noise,” in Proc. of KDD, 1996.
[55] E. Schubert, J. Sander, M. Ester, H. P. Kriegel, and X. Xu, “DBSCAN
revisited, revisited: Why and how you should (still) use DBSCAN,”
ACM Trans. Database Syst., vol. 42, no. 3, 2017.
[56] Z. Dai, Z. Yang, F. Yang, W. W. Cohen, and R. Salakhutdinov, “Good
semi-supervised learning that requires a bad GAN,” in Proc. of NeurIPS,
2017.
[57] J. Zhao, M. Mathieu, and Y. LeCun, “Energy-based generative adver-
sarial network,” in Proc. of ICLR, 2017.
[69] B. Zong, Q. Song, M. R. Min, W. Cheng, C. Lumezanu, D. Cho, and
H. Chen, “Deep autoencoding gaussian mixture model for unsupervised
anomaly detection,” in Proc. of ICLR, 2018.
[70] M. Amer, M. Goldstein, and S. Abdennadher, “Enhancing one-class
support vector machines for unsupervised anomaly detection,” in Proc.
of KDD Workshop, 2013.
[71] S. C. Tan, K. M. Ting, and T. F. Liu, “Fast anomaly detection for
streaming data,” in Proc. of IJCAI, 2011.
[72] W. Robertson, G. Vigna, C. KrÃijgel, and R. Kemmerer, “Using gener-
alization and characterization techniques in the anomaly-based detection
of web attacks.” in Proc. of NDSS, 2006.
[73] G. Jacob, E. Kirda, C. Kruegel, and G. Vigna, “PUBCRAWL: Protecting
users and businesses from crawlers,” in Proc. of USENIX Security, 2012.
[74] A. Antoniou, A. Storkey, and H. Edwards, “Data augmentation genera-
tive adversarial networks,” CoRR abs/1711.04340, 2017.
[75] C. Bowles, L. Chen, R. Guerrero, P. Bentley, R. Gunn, A. Hammers,
D. A. Dickie, M. V. Hernández, J. Wardlaw, and D. Rueckert, “GAN
augmentation: Augmenting training data using generative adversarial
networks,” CoRR abs/1810.10863, 2018.
[76] L. Sixt, B. Wild, and T. Landgraf, “RenderGAN: Generating realistic
labeled data,” Frontiers in Robotics and AI, vol. 5, p. 66, 2018.
[77] X. Zhu, Y. Liu, Z. Qin, and J. Li, “Emotion classiﬁcation with data aug-
mentation using generative adversarial networks,” in Proc. of PAKDD,
2018.
[78] Z. Yi, H. Zhang, P. Tan, and M. Gong, “DualGAN: Unsupervised dual
learning for image-to-image translation,” in Proc. of ICCV, 2017.
[79] H. Tang, D. Xu, W. Wang, Y. Yan, and N. Sebe, “Dual generator genera-
tive adversarial networks for multi-domain image-to-image translation,”
in Proc. of ACCV, 2018.
[80] S. Arora, R. Ge, Y. Liang, T. Ma, and Y. Zhang, “Generalization and
equilibrium in generative adversarial nets (GANs),” in Proc. of ICML,
2017.
[81] Q. Hoang, T. D. Nguyen, T. Le, and D. Phung, “MGAN: Training
generative adversarial nets with multiple generators,” in Proc. of ICLR,
2018.
[82] L. M. Manevitz and M. Yousef, “One-class SVMs for document classi-
ﬁcation,” Journal of Machine Learning Research, 2002.
APPENDIX A: LSTM VS. CNN
To justify our choice of Long-Short-Term-Memory (LSTM)
model [44], we show the comparison results with Convolu-
tional Neural Network (CNN) using the same feature encoding
methods on the same dataset. The architecture of the CNN
model is a stack of two convolutional layers (with 64 ﬁlters
and 32 ﬁlters), followed by one fully connected layer with a
sigmoid activation function. We experiment with 1% as well as
100% of the data from Website B in August 2018 for training.
As shown in Table XIV, the performance of CNN is not as
high as LSTM under 1% training data. The performance is
comparable under 100% of the training data. As we mentioned,
our main contribution is the feature encoding method rather
than the choice of deep neural networks. Our result shows that
LSTM has a small advantage over CNN.
TABLE XIV: We use August-18 dataset from Website B; Models are
trained with 1% of the training dataset.
% of Data
Precision
LSTM
CNN
1%
100%
1%
100%
0.60
0.89
0.62
0.85
Recall
0.36
0.88
0.29
0.93
F1
0.45
0.88
0.37
0.89