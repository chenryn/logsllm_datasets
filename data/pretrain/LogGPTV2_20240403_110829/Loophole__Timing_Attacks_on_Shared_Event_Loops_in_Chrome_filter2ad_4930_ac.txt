the different versions.
4.1 Page identiﬁcation
We describe how the event-delay trace obtained from
spying on event loops can be used for identifying web-
pages loaded in other tabs. We begin by explaining
our data selection and harvesting process and the cho-
sen analysis methods, then we describe our experimental
setup and the results we obtain.
854    26th USENIX Security Symposium
USENIX Association
4.1.1 Sample Selection
We start with the list of Alexa Top 1000 sites, from
which we remove duplicates. Here, duplicates are sites
that share the subdomain but not the top-level domains
(e.g., “google.br” and “google.com”) and that are likely
to have similar event-delay traces. From the remaining
list, we randomly select 500 sites as our sample set. This
reduction facilitates a rigorous exploration of the data
and the parameter space.
4.1.2 Data Harvesting
We visit each page in the sample set 30 times for both the
renderer and the host process, to record traces of event-
delays during the loading phase.
The event-delay traces for the renderer process con-
sist of 200.000 data items each. On our testing machine,
the measurement resolution (i.e. the delay between two
subsequent measurement events on an otherwise empty
loop) lies at approximately 25 µs. That is, each trace
captures around 5 seconds (200.000·25 µs = 5 s) of the
loading process of a page in the sample set.
The event-delay traces for the host process consist of
100.000 data items each. The measurement resolution
lies in the range of 80− 100 µs, i.e. each trace captures
around 9s of the loading process of a page.
We automate the harvesting procedure for the renderer
process as follows:
1. Open a new tab via
target = window.open(URL, ’_blank’); 2
2. Monitor the event loop until the trace buffer is full
3. Close the tab
4. Send the trace to the server
5. Wait 5 seconds and go to 1 with next URL
The harvesting procedure for the host process differs
only in that we use the rel="noopener" attribute in or-
der to spawn a new renderer.
We conducted measurements on the following three
machines:
1. Debian 8.6 with kernel 3.16.0-4-amd64, running on
an Intel i5 @ 3.30GHz x 4 with 4 GB of RAM, and
Chromium v53;
2. Debian 8.7 with kernel 3.16.0-4-amd64, running on
an Intel i5-6500 @ 3.20GHz x 4 with 16 GB of
RAM, and Chromium v57; and
3. OSX running on a Macbook Pro 5.5 with In-
tel Core 2 Duo @ 2.53GHz with 4 GB of RAM,
and Chrome v54.
2Note that this requires disabling Chrome’s popup blocker from
“chrome://settings/content”.
We measure the timing on a Chrome instance with two
tabs, one for the spy process and the other for the target
page. For the renderer process, we gather data on all
machines; for the host process on (2) and (3). Overall,
we thus obtain ﬁve corpora of 15.000 traces each.
4.1.3 Classiﬁcation
Event Delay Histograms. Our ﬁrst approach is to
cluster the observed event delays around k centers, and
to transform each trace into a histogram that represents
the number of events that fall into each of the k classes.
We then use the Euclidean distance as a similarity mea-
sure on the k-dimensional signatures.
This approach is inspired by the notion of memprints
in [21]. It appears to be suitable for classifying event-
delay traces obtained from event loops because, for ex-
ample, static pages with few external resources are more
likely to produce long events at the beginning and stabi-
lize soon, whereas pages with Javascript resources and
animations are likely to lead to more irregular patterns
and produce a larger number of long delays. Unfortu-
nately, our experimental results were discouraging, with
less than a 15% of recognition rate in small datasets.
Dynamic Time Warping. Our second approach is
to maintain temporal information about the observed
events. However, the exact moments at which events
occur are prone to environmental noise. For example,
network delays will inﬂuence the duration of network
requests and therefore the arrival of events to the event
loop. Instead, we focus on the relative ordering of events
as a more robust feature for page identiﬁcation.
This motivates the use of dynamic time warping
(DTW) [7] as a similarity measure on event-delay traces.
DTW is widely used for classifying time series, i.e. se-
quences of data points taken at successive and equally
spaced points in time. DTW represents a notion of dis-
tance that considers as “close” time-dependent data of
similar shape but different speed, i.e. DTW is robust to
horizontal compressions and stretches. This is useful,
for example, when one is willing to assign a low distance
score to the time series “abc“ and “abbbbc‘, insensitive
to the prolonged duration of “b“. Formally, DTW com-
pares two time series: a query, X = (x1, ...,xn), and a ref-
erence, Y = (y1, ...,ym). For that we use a non-negative
distance function f (xi,yi) deﬁned between any pair of el-
ements xi and y j. The goal of DTW is to ﬁnd a matching
of points in X with points in Y , such that (1) every point
is matched, (2) the relative ordering of points in each se-
quence is preserved (monotonicity), (3) and the cummu-
lative distance (i.e. the sum of the values of f ) over all
matching points is minimized. This matching is called a
USENIX Association
26th USENIX Security Symposium    855
warping path, and the corresponding distance is the time
warping distance d(X,Y ).
Figure 4: The path in the upper right square represents
the optimal alignment between points in the time se-
ries corresponding to ’google.com’ (horizontal axis) with
points in the time series of ’youtube.com’ (vertical axis).
Figure 4 visualizes a warping path between the
time series corresponding to event-delay traces observed
while loading different webpages.
4.1.4 Speed-up Techniques
Unfortunately, the time required for computing d(X,Y )
is quadratic in the length of the input sequences and does
not scale up to the raw data obtained in our measure-
ments. We rely on two kinds of speed-up techniques,
one at the level of the data and the other at the level of
the algorithm:
At the level of data, we reduce the dimension of our
data by applying a basic sampling algorithm: We split
the raw trace into groups of measurements corresponding
to time intervals of duration P, and replace each of those
groups by one representative. This representative can be
computed by summing over the group, or by taking its
average, maximum or minimum. The sum function gen-
erally yields the best results among different sampling
functions and is the one that we use onwards. Sampling
reduces the size of the traces by a factor of P/t, where t
is the average duration of an event delay. Figure 5 shows
two plots with the raw data taken from a renderer’s main
thread loop, and its corresponding time series obtained
after sampling.
At the algorithmic level, we use two sets of tech-
niques for pruning the search for the optimal warping
path, namely windowing and step patterns [15].
Figure 5: The top ﬁgure represents a raw trace of 200.000
time measurements from the renderer’s main thread ex-
tracted while loading “google.com”. The bottom ﬁgure
displays the same data after being converted into a time
series with P = 20 ms, i.e. using only 250 data points.
The difference in the height of the peaks is due to the ac-
cumulation of small events in the raw data, which are not
perceptible in the top ﬁgure.
• Windowing is a heuristic that enforces a global con-
straint on the envelope of the warping path.
It speeds
up DTW but will not ﬁnd optimal warping paths that lie
outside of the envelope. Two well-established constraint
regions are the Sakoe-Chiba band and the Itakura paral-
lelogram, see Figure 6.
Figure 6: A global window constraint deﬁnes an enve-
lope limiting the search space for optimal warping paths:
(a) Itakura parallelogram, and (b) Sakoe-Chiba band.
• Step patterns are a heuristic that puts a local con-
straint on the search for a warping path, in terms of re-
strictions on its slope.
In particular, we rely on three
well-known step patterns available in R. Intuitively, the
symmetric1 pattern favors progress close to the diagonal,
the symmetric2 pattern allows for arbitrary compressions
and expansions, and the asymmetric forces each point in
the reference to be used only once.
856    26th USENIX Security Symposium
USENIX Association
(a)(b)Figure 7: Web page identiﬁcation performance after tuning with traces from the renderer on Linux machine (1). Effect
of P, traceDuration, and windowSize, with three combinations of stepPattern and windowType.
4.1.5 Parameter tuning
The possible conﬁgurations of the techniques presented
in Section 4.1.4 create a large parameter space, see Ta-
ble 1 for a summary.
Parameter
traceDuration
P
windowType
windowSize
stepPattern
Values
1000,2000,4000
5,10,20,50
itakura, sakoechiba
1,5,10,30,50,100
symmetric1, symmetric2,
asymmetric
Description
Trace duration (ms)
Sampling interval (ms)
Window constraint
Window size
Step pattern
Table 1: List of parameters tuned for optimizing web
page identiﬁcation
We systematically identify the optimal parameter con-
ﬁguration for each event loop on each machine. To avoid
overﬁtting, we divide our dataset of 30 traces (per page,
loop, and machine) into 15 traces for tuning and 15 for
cross-validation. For each parameter conﬁguration we
perform a lightweight version (with 3 rounds) of the eval-
uation phase described in Section 4.1.6. Figure 7 visual-
izes an extract of the results we obtain for the renderer
process of the Linux (1) machine. The tuning phase
yields the following insights:
• The optimal parameters depend on the loop but ap-
pear to be stable across machines.
• Measuring the loading phase during 2 seconds is
sufﬁcient for recognition of a webpage; the gain in recog-
nition from using longer traces is negligible.
• P and windowSize are the parameters with the
biggest impact on the recognition rate. However, they
also have the biggest impact on the computational cost
(the optimal choice being most expensive one).
• The combination of stepPattern = symmetric1 and
windowType = sakoechiba generally yields the best re-
sults.
4.1.6 Experimental Results
cesses on each individual machine, as well as through the
renderer process across two different machines.
To this end, we select the top conﬁguration for each
corpus from the tuning phase and carry out a 10-fold
cross-validation. In each of the 10 rounds, we partition
the validation set into a training set that contains one
trace of each page, and a testing set that contains three
different (out of the 14 available) traces of each page.
For each of the traces in the testing set, we compute the
set of k closest matches in the training set according to
the time warping distance.
We measure performance in terms of the k-match
rate, which is the percentage of pages in the testing set
for which the true match is within the set of k closest
matches. We abbreviate the 1-match rate by recognition
rate, i.e. the percentage of pages where the best match is
the correct one. The result of the cross-validation is the
average k-match rate over all 10 rounds.
Table 2 summarizes our experiments. We highlight the
following results:
1
k
3
5
10
76.7 % 86.7 % 88.8 % 91.1 %
sym1,sakoe,P = 5,windowSize = 100
58.2 % 68.6 % 71.8 % 75.1 %
sym1,sakoe,P = 5,windowSize = 100
16.2 % 23.2 % 27.9 % 36.1 %
sym1,sakoe,P = 20,windowSize = 30
61.8 % 74.5 % 78.4 % 83.1 %
sym1,sakoe,P = 5,windowSize = 100
23.48 % 32.9 % 38.1 % 46.6 %
sym1,sakoe,P = 20,windowSize = 30
) Renderer
1
(
)
2
(
)
3
(
Renderer
I/O host
Renderer
I/O host
Table 2: 10-fold cross-validation results on different ma-
chines and different event loops, with the best conﬁg-
uration after tuning. Machines (1) and (2) refer to the
Linux desktops, (3) to the OSX laptop, as described in
Section 4.1.2.
We evaluate the performance of page identiﬁcation
through the shared event loops of host and renderer pro-
• We can correctly identify a page by spying on the
renderer from (1) in up to 76.7% of the cases, and cor-
USENIX Association
26th USENIX Security Symposium    857
0%25%50%75%100%15103050100WindowSizeSakoechiba - symmetric10%25%50%75%100%15103050100WindowSizeSakoechiba - asymmetric0%25%50%75%100%1WindowSizeItakura - symmetric151020504s2s1sPTraceDurationrectly narrow down to a set of 10 candidates in up to
91.1% of the cases.
• We can correctly identify a page though the host
process from (3) in up to 23.48% of the cases, and nar-
row down to a set of 10 candidates in up to 46.6% of the
cases.
• We stress that these recognition rates are obtained
using a single trace for training.
• Recognition is easier through the renderer than
through the host. This is explained by the difference
in noise and measurement resolution, see Section 3.2.3.
Furthermore, most operations on the host only block the
I/O thread while signaling their start and completion,
whereas the renderer is blocked during the entire exe-
cution of each Javascript task.
• We observe different recognition rates on different
machines. However the homogeneity in hardware and
software of Macbooks facilitate reuse of training data
across machines, which may make remote page identi-
ﬁcation more feasible.
• We obtain recognition rates below 5% for recog-
nition across machines (1) and (3). A reason for this