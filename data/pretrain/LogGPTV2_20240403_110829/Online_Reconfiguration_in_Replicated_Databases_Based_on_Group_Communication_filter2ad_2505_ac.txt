date it,  it  is  easy  to determine  the  objects that  have  been 
changed since  Tgldmazs,.  The data transfer  phase  of  the 
protocol of Section 4.3 can be modified as follows: 
I.  Data  Transfer Phase:  Whenever a  lock  on  object X  is 
granted, check whether the version is labeled with a trans- 
action T for which g i d ( T )  > gidmaxs,.  If this is the case, 
transfer X  as in the previous section, otherwise ignore X 
and release the lock immediately. 
4.5. Restricting the Set of Objects to Check 
The optimization  of  the  previous  section  still  needs  to 
scan the entire database, which may involve a considerable 
overhead.  Moreover,  an object is  locked from the  start of 
D T  until it is either transferred or considered non-relevant. 
Thus, transaction processing on S, can be delayed for quite 
some  time.  Finally,  not  all  replica  control  protocols  tag 
objects with  version numbers as required  by  the protocol. 
In this  section, we present  an  alternative that avoids these 
problems:  (1) it does not rely on the use of version numbers 
as object tags, thus it  can  be  applied to  any database  sys- 
tem; (ii) it does not require scanning all  the objects in  the 
database; and (iii) it unlocks non-relevant objects sooner. 
We propose to maintain a reconstruction table RecTable 
at  each  site  keeping  information  about  recently  changed 
data.  That is, a record  of RecTable consists of  an  object 
identifier i d ( X )  and a global  identifier gid indicating  that 
Tgid was the last transaction to update X .  RecTable should 
hold a record for each object X  updated by transaction T if 
there is at least one site S that might not have yet executed T 
(e.g., S is not in the primary  view when T commits).  Only 
in the case of a data transfer RecTable must be completely 
up-to-date (see below).  Otherwise, it can be maintained by 
a background process whenever the system is idle: 
Registration of  updates: Let object X  be last updated by 
committed transaction T .  If RecTable has already a record 
for  X ,  then set the transaction identifier of  this record to 
g i d ( T ) ,  otherwise insert a new record ( i d ( X ) ,  g i d ( T ) ) .  
Deleting  records:  Let  g i d m a x s   be  the  global identifier 
of  the  cover  transaction for  site  S.  Let  gidma.x,i,,  be 
the  minimum of  all  g i d m a z s .   Sites  maintain a  conser- 
vative estimate of  gidmax,i, 
through  regular exchange 
of g i d m a x  values (in particular, by using for site S  not in 
the primary view the last gidmazs announced by S  while 
in the primary view).  When a site increases its estimate 
of gidmuxmin, it deletes from RecTable  each record with 
g i d ( T )  such that g i d ( T )  5 gidmax,,,. 
Based on RecTable, the data transfer protocol of section 
4.3 can be modified by changing the lock phase as follows: 
I.  Lock Phase and Determining the Data Transfer Set: Upon 
delivery of v c h g ( w ) ,  create transaction D T ,  request a sin- 
gle read lock on the entire database and wait until all trans- 
actions  delivered  before vchg(W) have terminated  and 
their updates are registered in RecTable. 
Let D I D   = { i d ( X ) l ( i d ( X ) , g i d )  E  RecTable  and gid  > 
gidmax.7,).  Request  read  locks  on  objects  X ,  with 
i d ( X )  E  D I D  and release the lock on the database.  At 
this point, proceed with the data transfer phase as usual 
for the objects whose identifiers are in D I D .  
In  contrast  to  the  previous  protocols  we  now  set  only 
a  single  lock  on  the  entire  database.  Once  the  data  set 
to  be  transferred  is  determined,  which  can  be done easily 
with RecTable, this lock is replaced by the fine granularity 
locks on the individual objects. Hence, non-relevant data is 
locked for only a very short time. 
RecTable  may  be  implemented  as  a  traditional  table 
In  this  case,  D I D  can 
in  a  relational  database  system. 
be  constructed  with  the  simple  SQL  statement  “SELECT 
i d ( X )  from RecTable  where gid > gidmaxsp”. Fast re- 
sponse to this query may be obtained by having an index on 
RecTable  with  the global  identifier being  the search  key. 
In  the same way, an index on the object identifier will fas- 
ten  the  registration  of  new  updates  to  RecTable.  Notice 
that maintenance of RecTable is mostly  asynchronous and 
changes to RecTable do not need to be forced to disk; thus 
we  believe  that  its  impact  during  normal transaction  pro- 
cessing be small.  Finally, notice that gidmax,i, 
can only 
increase and that when  all  sites are up and in  the primary 
view  records  that  are  no  longer  needed  are  continuously 
deleted.  In  the case of relational databases we estimate the 
maximum additional space overhead to be the same as for 
two additional indices for each relation in the database. 
4.6. Filtering the Log 
So far,  S, has  had  to set read  locks to  synchronize the 
data transfer  with  concurrent  transaction  processing.  Al- 
though  the  previous  optimizations,  amongst  other  things, 
shortened the time such locks are set on non-relevant data, 
locks on relevant data are still long. 
We can avoid setting locks on the current database if the 
database system maintains multiple object versions.  In this 
122 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:01:57 UTC from IEEE Xplore.  Restrictions apply. 
case, transactions can update the objects of the database un- 
hindered  while  S,  will  simply transfer the versions  of  the 
objects that were current when vchg(W) was delivered. No 
data  transfer  transaction  needs  to  be  created  and  transac- 
tions  at S,  can  access the  current database objects unhin- 
dered.  Multiple versions are given, for instance, if the log 
maintained for single site recovery stores for each update of 
object X  the entire physical after-image of X .  The details 
of such a protocol can be found in [8]. 
4.7. Lazy Data Transfer 
All the previous solutions use the view change as a syn- 
chronization point in that Sj enqueues all transaction mes- 
sages delivered after vchg(W) and eventually applies them 
to its local (up-to-date) copy of the database. While this is a 
simple and intuitive approach, it has several disadvantages. 
First, the peer node S,  has to delay transaction processing 
on data that must be  transferred  (unless there  exist multi- 
ple object versions).  Second,  if  the workload  is  high  and 
the data transfer takes a long time, then the joining site Sj 
might not  be  able  to  store all transaction  messages deliv- 
ered during the data transfer, or it might not be able to apply 
these transactions fast enough to catch up with the rest of the 
system. Finally, a failure of S, requires Sj to leave and re- 
join the system and to restart the data transfer from scratch: 
since the  sites that could  take  over after S,’s  failure have 
continued transaction processing, they might not be able to 
provide Sj  with  the  state of  the database that  was  current 
upon  the  delivery  of  wchg(W). These drawbacks can  be 
avoided if  we decouple the synchronization point from the 
delivery of vchg(W) [ 7 ] :  
0  Sj initially discards transaction  messages delivered  in 
W  and  S,  starts  a  data  transfer  as  described  below. 
When  the transfer  is nearly completed, S,  and Sj  will 
determine a specific delimiter transaction T d ,  delivered 
in  W .  S,  transfers  all changes performed by  transac- 
tions  with gid  5  d.  Sj starts enqueueing transaction 
messages with  gad  such that  g i d   > d  and  will  apply 
these transactions once the data transfer is completed. 
0  S, transfers the data in several rounds. Only in the last 
round (when Td  is determined), the transfer is synchro- 
nized with concurrent processing by  setting appropriate 
locks. The idea is to send in each round the objects that 
were updated during the data transfer of the last round. 
The last round is started either when the number of ob- 
jects  that  are  left  to  be  transferred  does  not  exceed  a 
or a maximum number R,,,  > 1 
given threshold k,,, 
of rounds has been reached. 
Before discussing this solution in more detail, we high- 
light its advantages.  First, S,  has a better control of  when 
to perform the data transfer and at which speed. Second, Sj 
has to enqueue and apply  far  less transactions.  Third,  the 
approach allows for much better concurrency as transaction 
processing  at  S,  is  delayed  only  in  the  last  round  which 
we expect to be  fast, since it  will  only  transfer little data. 
Finally,  failures of S,  before reconfiguration  is  completed 
can be handled more efficiently.  As we shall see below, in 
each round i, the updates up to a certain  transaction  Tgid; 
are transferred. Sj  only has to inform the new peer site Sb 
up to which Tgidi it received  the  updates from S,,  and SA 
can continue the data transfer starting from that transaction. 
The actions at S, are as follows: 
Round i, 1 5 i 5 (n - 1) 
1.  Determine the delimiter transaction TYtdi of this round: If 
i  = 1 then  let gidi  be the identifier of  the  last transac- 
tion delivered before v c h g ( W ) .  Otherwise, let gidi be the 
identifier of the last transaction that was delivered before 
the  round started.  Wait  until all updates of  transactions 
with gid 5 gidi are included in RecTable (i.e., at least the 
updates of all transactions up to Tyidi will be transferred). 
2.  Determine the data  to be  transferred:  If i  =  1 then  let 
gid,t  = g i d m a x s j ,  otherwise gadst = gidi-1.  Let D I D  = 
{ i d ( X ) l ( i d ( X ) ,  gid) E  RecTable and gid > gidSt} 
3.  Data  transfer:  For each i d ( X )  E  D I D  acquire a short 
read lock on X ,  read X ,  release the lock and then trans- 
fer X  to S,  (the short read lock is only used to guarantee 
that  only committed data is read).  Furthermore, inform 
S,  about gid, (for fail-over). 
4.  Termin. Check I: If i = R,,,  - 1 then go to Round n. 
5.  Termin. Check I/: Let D I D n e z t  = { i d ( X ) l ( i d ( X ) ,  gid) E 
then go 
RecTable and gid > gid,}. If  # D I D n e x t  5 k,,, 
to Round n. Otherwise, increase i and repeat. 
Round n: 
1.  Determine  the  delimiter transaction Td: Inform S,  that 
this is the last round, and wait for a response (upon re- 
ception of  this  message, S,  starts enqueueing transac- 
tions and responds with the identifier gidpropose of  the 
first  enqueued transaction).  Upon reception of  the  re- 
sponse, let gid,  be the identifier of  the  last transaction 
delivered  at  S,  that  already  requested  its  write  locks: 
d  = maa:(gid,,gidpropose  - 1). 
2.  Final data transfer: The data transfer of the last round is 
performed by a transaction DT  ordered as follows:  DT 
transfers all changes of transactions with gid  5 d  but no 
changes from transactions with gid > d (they will be ap- 
plied by Sj). DT  now follows any of  the  protocols de- 
scribed in the previous sections. For instance: 
a.  Lock Phase and Determining the Data Transfer Set:  If 
d  = gid,,  request immediately a read lock on the en- 
tire database.  Otherwise, wait until Tgldpropose- 
has 
requested its  write  locks  and  then  request the  read 
lock on the entire database. Wait until all transactions 
with gid  5  d  are included in RecTable.  Let D I D  = 
{ i d ( X ) l ( i d ( X ) ,  gid) E  RecTable and gid > gid;}. Re- 
quest a read lock for each object X with i d ( X - )  E  D I D  
and release the lock on the database. 
b.  Data Transfer: As in section 4.3. 
123 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:01:57 UTC from IEEE Xplore.  Restrictions apply. 
mw  @ 
RdS2 
vo 
s3 
v2 
s3 
s3 
v4 
SI 
s2 
s3 
s4 
s2 
s3 
s4 
s3 
s4 
Figure 1. Example of virtual synchrony 
if  the data transfer is done as part of the view change proto- 
col or if  the application is able to perform the data transfer 
very  quickly, the  application-dependent  notion  of  “up-to- 
date  member”  is  essentially  the  same  as  “member  of  the 
primary  view”.  However,  as  previously  pointed  out, such 
forms of data transfer are unsuitable for database systems. 
The next sections outline an extension of the traditional 
group communication abstraction, called enriched view syn- 
chrony  (EVS) [4],  and  its  possible  use  in  the  context  of 
database applications [7].  EVS will allow us to easily han- 
dle the failure scenarios described in this section. 
Note that the set DIDnezt constructed within the termi- 
nation check I1 is an estimate of the D I D  that will be con- 
structed in the next round, because transaction processing is 
not  suspended.  We  suggest that in the  first round data are 
transferred per data partition (e.g., per relation).  In case of 
failures during this round, the new peer site does not need to 
restart but  simply continue the transfer for those partitions 
that Sj has not yet received. 
5. Cascading Reconfigurations 
A  key  problem  for all  solutions presented  so far is  that 
further  view  changes may  occur  before  reconfiguration  is 
completed.  The problem is  that  reconfiguration is  not  an 
atomic  step but  may  take  a  long  time.  The possibility  of 
view  changes during reconfiguration  may  greatly  compli- 
cate the  details.  As an example, consider  Figure  1  (ovals 
indicate views;  grey-shaded ovals indicate primary  views; 
consecutive views are connected by an arrow). Suppose that 
So acts as peer site when S3 joins the primary view V 3  and 
suppose that So  leaves the primary view (V6) before recon- 
figuration  has  completed.  Only  S3  and So know  that  re- 
configuration has not yet completed. It follows that SI and 
Sa  in V6 do not know whether S3 is able to process transac- 
tions or whether one of them has to resume the data transfer. 
Similarly, S4  does not know which of the other sites can act 
as a peer site for its reconfiguration.  In fact, S4 cannot even 
tell that there will indeed be an up-to-date peer site: from its 
point of view, it might be the case that no predecessor of this 
primary  view  was primary.  The following example shows 
a  further complication:  SI and S2 start reconfiguration  in 
view V6 for S3  and S4.  ‘Then, a partition excludes SI, lead- 