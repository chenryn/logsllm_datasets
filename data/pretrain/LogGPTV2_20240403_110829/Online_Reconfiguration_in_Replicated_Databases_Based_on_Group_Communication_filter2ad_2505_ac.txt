### Date and Versioning for Data Transfer Optimization

To determine the objects that have been changed since a specific time, the data transfer phase of the protocol in Section 4.3 can be modified as follows:

**Data Transfer Phase:**
1. **Lock and Version Check:** Whenever a lock on object X is granted, check if the version is labeled with a transaction T where `gid(T) > gidmaxs`. If this condition is met, transfer X as described in the previous section. Otherwise, ignore X and release the lock immediately.

### Restricting the Set of Objects to Check

The optimization in the previous section still requires scanning the entire database, which can be computationally expensive. Additionally, an object is locked from the start of the Data Transfer (DT) until it is either transferred or deemed non-relevant, potentially delaying transaction processing. Furthermore, not all replica control protocols use version numbers as required by the protocol. This section presents an alternative approach that addresses these issues:
1. It does not rely on version numbers, making it applicable to any database system.
2. It avoids scanning all objects in the database.
3. It unlocks non-relevant objects more quickly.

We propose maintaining a reconstruction table, `RecTable`, at each site to keep track of recently changed data. Each record in `RecTable` consists of an object identifier `id(X)` and a global identifier `gid` indicating that `Tgid` was the last transaction to update X. `RecTable` should include a record for each object X updated by transaction T if there is at least one site S that might not have executed T yet (e.g., S is not in the primary view when T commits). `RecTable` must be up-to-date during data transfers but can be maintained by a background process when the system is idle.

**Maintenance of RecTable:**
- **Registration of Updates:** If object X was last updated by committed transaction T, set the transaction identifier of the record to `gid(T)`. If no record exists for X, insert a new record `(id(X), gid(T))`.
- **Deleting Records:** Let `gidmaxs` be the global identifier of the cover transaction for site S, and `gidmaxmin` be the minimum of all `gidmaxs`. Sites maintain a conservative estimate of `gidmaxmin` through regular exchanges of `gidmax` values. When a site increases its estimate of `gidmaxmin`, delete records from `RecTable` where `gid(T) ≤ gidmaxmin`.

**Modified Data Transfer Protocol:**
1. **Lock Phase and Determining the Data Transfer Set:**
   - Upon delivery of `vchg(W)`, create transaction DT, request a single read lock on the entire database, and wait until all transactions delivered before `vchg(W)` have terminated and their updates are registered in `RecTable`.
   - Define `DID = {id(X) | (id(X), gid) ∈ RecTable and gid > gidmaxsj}`. Request read locks on objects X with `id(X) ∈ DID` and release the lock on the database.
   - Proceed with the data transfer phase for the objects whose identifiers are in `DID`.

In contrast to previous protocols, we now set only a single lock on the entire database. Once the data set to be transferred is determined using `RecTable`, this lock is replaced by fine-grained locks on individual objects, minimizing the time non-relevant data is locked.

**Implementation of RecTable:**
- `RecTable` can be implemented as a traditional table in a relational database system. The set `DID` can be constructed with the SQL statement: `SELECT id(X) FROM RecTable WHERE gid > gidmaxsp`.
- Fast response to this query can be achieved by indexing `RecTable` with the global identifier as the search key. An index on the object identifier will speed up the registration of new updates.
- Maintenance of `RecTable` is mostly asynchronous, and changes do not need to be forced to disk, minimizing its impact on normal transaction processing.
- `gidmaxmin` can only increase, and records no longer needed are continuously deleted when all sites are up and in the primary view. For relational databases, the maximum additional space overhead is estimated to be the same as two additional indices for each relation in the database.

### Filtering the Log

So far, site Sj has had to set read locks to synchronize data transfer with concurrent transaction processing. Although previous optimizations have reduced the time such locks are set on non-relevant data, locks on relevant data remain long.

If the database system maintains multiple object versions, locks on the current database can be avoided. Transactions can update the objects unhindered while Sj transfers the versions of the objects that were current when `vchg(W)` was delivered. No data transfer transaction needs to be created, and transactions at Sj can access the current database objects without interruption. Multiple versions are provided if the log maintained for single-site recovery stores the entire physical after-image of each updated object X. Details of such a protocol can be found in [8].

### Lazy Data Transfer

All previous solutions use the view change as a synchronization point, where Sj enqueues all transaction messages delivered after `vchg(W)` and eventually applies them to its local (up-to-date) copy of the database. While this approach is simple and intuitive, it has several disadvantages:
1. Sj must delay transaction processing on data that must be transferred (unless multiple object versions exist).
2. If the workload is high and the data transfer takes a long time, Sj might not be able to store all transaction messages delivered during the data transfer or apply these transactions fast enough to catch up with the rest of the system.
3. A failure of Sj requires it to leave and rejoin the system, restarting the data transfer from scratch. Since other sites continue transaction processing, they might not be able to provide Sj with the state of the database that was current upon the delivery of `vchg(W)`.

These drawbacks can be avoided by decoupling the synchronization point from the delivery of `vchg(W)` [7]:
- **Initial Discard and Data Transfer:**
  - Sj initially discards transaction messages delivered in W, and S starts a data transfer as described below. When the transfer is nearly completed, S and Sj determine a specific delimiter transaction `Td` delivered in W. S transfers all changes performed by transactions with `gid ≤ d`, and Sj starts enqueuing transaction messages with `gid > d` and will apply these transactions once the data transfer is completed.
- **Rounds of Data Transfer:**
  - S transfers the data in several rounds. Only in the last round (when `Td` is determined), the transfer is synchronized with concurrent processing by setting appropriate locks. The idea is to send in each round the objects that were updated during the data transfer of the last round. The last round is started either when the number of objects left to be transferred does not exceed a given threshold `kmax` or a maximum number of rounds `Rmax > 1` has been reached.

**Advantages:**
1. S has better control over when to perform the data transfer and at what speed.
2. Sj has to enqueue and apply fewer transactions.
3. The approach allows for much better concurrency as transaction processing at S is delayed only in the last round, which is expected to be fast.
4. Failures of S before reconfiguration is completed can be handled more efficiently. In each round i, the updates up to a certain transaction `Tgidi` are transferred. Sj only needs to inform the new peer site Sb up to which `Tgidi` it received the updates from S, and Sb can continue the data transfer starting from that transaction.

**Actions at S:**
- **Round i, 1 ≤ i ≤ (n - 1):**
  1. **Determine Delimiter Transaction:** If `i = 1`, let `gidi` be the identifier of the last transaction delivered before `vchg(W)`. Otherwise, let `gidi` be the identifier of the last transaction delivered before the round started. Wait until all updates of transactions with `gid ≤ gidi` are included in `RecTable`.
  2. **Determine Data to Transfer:** If `i = 1`, let `gidst = gidmaxsj`; otherwise, `gidst = gidi-1`. Define `DID = {id(X) | (id(X), gid) ∈ RecTable and gid > gidSt}`.
  3. **Data Transfer:** For each `id(X) ∈ DID`, acquire a short read lock on X, read X, release the lock, and then transfer X to S (the short read lock ensures that only committed data is read). Inform S about `gidi` (for fail-over).
  4. **Termination Check I:** If `i = Rmax - 1`, go to Round n.
  5. **Termination Check II:** Define `DIDnext = {id(X) | (id(X), gid) ∈ RecTable and gid > gidi}`. If `#DIDnext ≤ kmax`, go to Round n. Otherwise, increase i and repeat.

- **Round n:**
  1. **Determine Delimiter Transaction Td:** Inform S that this is the last round and wait for a response. Upon reception of the message, S starts enqueuing transactions and responds with the identifier `gidpropose` of the first enqueued transaction. Let `gidn` be the identifier of the last transaction delivered at S that already requested its write locks: `d = max(gidn, gidpropose - 1)`.
  2. **Final Data Transfer:** The data transfer of the last round is performed by a transaction DT ordered as follows:
     - **Lock Phase and Determining the Data Transfer Set:** If `d = gidn`, request immediately a read lock on the entire database. Otherwise, wait until `Tgidpropose-1` has requested its write locks and then request the read lock on the entire database. Wait until all transactions with `gid ≤ d` are included in `RecTable`. Define `DID = {id(X) | (id(X), gid) ∈ RecTable and gid > gid;}`. Request a read lock for each object X with `id(X) ∈ DID` and release the lock on the database.
     - **Data Transfer:** As in Section 4.3.

### Cascading Reconfigurations

A key problem for all solutions presented so far is that further view changes may occur before reconfiguration is completed. Reconfiguration is not an atomic step and can take a long time, complicating the details. For example, consider Figure 1 (ovals indicate views; grey-shaded ovals indicate primary views; consecutive views are connected by an arrow). Suppose So acts as the peer site when S3 joins the primary view V3, and So leaves the primary view (V6) before reconfiguration is completed. Only S3 and So know that reconfiguration is incomplete. Consequently, SI and Sa in V6 do not know whether S3 can process transactions or if one of them must resume the data transfer. Similarly, S4 does not know which site can act as a peer site for its reconfiguration. In fact, S4 cannot even determine if there will be an up-to-date peer site.

**Example of Further Complication:**
- SI and S2 start reconfiguration in view V6 for S3 and S4. Then, a partition excludes SI, leading to further complications.

The next sections outline an extension of the traditional group communication abstraction, called Enriched View Synchrony (EVS) [4], and its possible use in the context of database applications [7]. EVS will allow us to handle the failure scenarios described in this section more effectively.