uniform with the weights on call edges, we still give two weight
functions for a data-flow edge e: fflow(e) is the amount of informa-
tion flow on the edge and bflow(e) is always zero.
Third, for a read edge e from global д to function f , we use af(e)
for the frequency of f reading from д during profiling; similarly,
for a write edge e from function f to global д, af(e) is the frequency
of f writing to д during profiling. Lastly, for a data-flow edge e
that connects a function f to a global д, plevel(e) represents the
complexity of д’s type signature. This is because, if the function and
the global are in separate domains, the function has to read/write
the global through an RPC to a getter or a setter function. Therefore,
the type complexity of the global is used to represent the complexity
of implementing the RPC.
With these adjustments, the definitions of sensitive code percent-
age, sensitive information flow, context-switch overhead, pointer
Session 5A: Software SecurityCCS ’19, November 11–15, 2019, London, United Kingdom1037complexity, and optimal partitioning are exactly the same as the
case for call graphs and are not repeated.
B ENCODING OPTIMAL PARTITIONING AS
IP
Solution variables and objective. We first declare two binary
vairables αv and βv for each vertex v in the PDG. Recall that a
vertex represents either a function or a global variable. αv is 1 iff v
is in the sensitive partition S but not replicated; βv is 1 iff v is in
the insensitive partition T but not replicated. That is, they satisfy
v ∈ S − R ⇔ αv = 1 and v ∈ T − R ⇔ βv = 1. As a result, v ∈ R
(v is replicated) iff αv = 0 ∧ βv = 0. We term the two kinds of
variables as solution variables.
For the objective function, we use the goal of minimizing sensi-
tive code percentage as an example; other objective functions can
be modeled in a similar way. Since the total code size of the input
program is a constant, minimizing the sensitive code percentage
can be converted to minimizing the code size in S, which is the same
as maximizing the code size in T − R, where R = S ∩ T . Therefore,
we can use the following objective function:

max
sz(i) · βi .
i ∈V
Intermediate variables and constraints. The following con-
straints model that (1) the special sensitive function or the special
sensitive global variable s must be in S − R only, and (2) every
function or global variable i cannot stay in both S − R and T − R:
αs = 1 ∧ βs = 0 ∧ ∀i, αi + βi ≤ 1.
When αi + βi = 0, it means that the function or global variable i
represents is replicated (that is, it is in R).
Since the direction of an edge matters when measuring sensitive
information flow, we further declare two intermediate variables xi j
and yi j to represent if the edge is a forward boundary edge or a
backward boundary edge. Specifically, xi j = 1 ⇔ ei j ∈ FB; and
yi j = 1 ⇔ ei j ∈ BB.
With the input budgets bc , bf , bs , and bx , we can construct the
following constraints for all measurements based on Def 5.2:

sz(i) · (1 − βi ))/totalSize ≤ bc ;
(

i ∈V
fflow(ei j ) · xi j + bflow(ei j ) · yi j ≤ bf ;
i, j ∈V


i, j ∈V
af(ei j ) · (xi j + yi j ) ≤ bs ;
plevel(ei j ) · (xi j + yi j ) ≤ bx .
i, j ∈V
The first constraint limits the sensitive code percentage, assuming
totalSize is the total code size. The second limits the total of sensitive
information flow. The third limits the RPC context-switch frequency
during runtime. And the fourth limits the pointer complexity.
The next step is to constrain variables xi j and yi j with their
related four solution variables αi , αj , βi , and βj . In our problem
formalization, we have three different boundary edge sets for three
types of edges. Therefore, constraints are introduced differently
for different types of edges. We first discuss what logical formulas
need to be encoded for each type of edges and then present how
those logical formulas can be encoded by IP inequality constraints.
For an edge ei j from vertex i to vertex j in the graph,
1) if ei j is a call edge,
xi j = 1 ⇔ ei j ∈ FBC ⇔ βi = 0 ∧ βj = 1 ⇔ ¬βi ∧ βj ;
yi j = 1 ⇔ ei j ∈ BBC ⇔ αi = 0 ∧ αj = 1 ⇔ ¬αi ∧ αj ;
2) if ei j is a read edge,
xi j = 1 ⇔ ei j ∈ FBR ⇔ αi = 1 ∧ αj = 0 ⇔ αi ∧ ¬αj ;
yi j = 1 ⇔ ei j ∈ BBR ⇔ βi = 1 ∧ βj = 0 ⇔ βi ∧ ¬βj ;
3) if ei j is a write edge,
xi j = 1 ⇔ ei j ∈ FBW ⇔ βi = 0 ∧ βj = 1 ⇔ ¬βi ∧ βj ;
yi j = 1 ⇔ ei j ∈ BBW ⇔ αi = 0 ∧ αj = 1 ⇔ ¬αi ∧ αj .
To transform the above logical formulas into linear inequations,
we use two classic IP techniques: (1) ¬x is equivalent to 1 − x; and
(2) the relation y = 1 ⇔ x1 ∧ x2 ∧ · · · ∧ xn can be linearly modeled
as
y ≤ xi , ∀i = 1, 2, . . . , n
y ≥ x1 + x2 + · · · + xn − (n − 1).
For brevity, we only show how xi j and yi j are constrained when
ei j is a call-edge:
xi j ≤ 1 − βi ,
xi j ≤ βj ,
xi j ≥ βj − βi ,
yi j ≤ 1 − αi ,
yi j ≤ αj ,
yi j ≥ αj − αi .
So far, we have declared 2|V | + 2|E | binary variables and con-
structed |V | + 6|E | + 5 constraints.
C MEASURING INFORMATION FLOW
In Flowcheck users specify what file opened by the program or
what buffer used by the program is sensitive. Flowcheck’s dynamic
analysis then constructs a flow graph during program execution.
For a relevant operation during execution, a graph structure is
generated to represent the sensitive information flow happened
in the operation. Edges in the graph represent how sensitive data
is processed in the program and are annotated with the amount
of sensitive data being processed; that is, edges represent explicit
information flows. For instance, a comparison between a 32-bit
secret with a constant would produce (1) a 32-bit edge from the
node for the secret to a new node for the comparison, and (2) a 1-bit
edge from the comparison node to a new node for the comparison
result. Implicit flows are also reported at the instruction level. If
Flowcheck encounters a conditional jump and the processor flag
that the jump depends on has 1-bit sensitive information (because of
an earlier instruction that sets the flag using sensitive information),
then Flowcheck reports that the jump has one bit of implicit flow.
The flow graph constructed by Flowcheck, however, does not
directly report inter-procedural information flow PM is interested in.
Next we discuss how this is calculated in PM on top of information
Session 5A: Software SecurityCCS ’19, November 11–15, 2019, London, United Kingdom1038provided by Flowcheck. This is presented in several steps: we first
discuss how explicit flows through arguments, return values, and
global variables are quantified and an optimization method for
improving precision; we then discuss how implicit flows are treated;
finally, we briefly discuss how PM aggregates flow quantities across
multiple calls and multiple runs.
Explicit flows. When a function gets called with some arguments,
PM needs to know how much sensitive information is stored in the
arguments and how much in the function’s return value. The flow
graph constructed by Flowcheck, however, does not directly give
such information, as explained below.
First, Flowcheck generates a graph structure for an operation
only when sensitive information is involved in the operation. Func-
tion calls/returns, on the other hand, do not directly manipulate
sensitive information. Take the following code as an example. For
clarity, this example and other examples use a pseudo-code syntax,
instead of the x86 assembly code syntax; in particular, we use “:=”
for an assignment.
eax := ebx xor ecx
...
ret
In the default x86 calling convention, register eax contains the
return value at the end of the function. Thus PM needs to know
how much sensitive information is in eax when ret is executed.
However, since ret itself does not manipulate eax, Flowcheck does
not generate a graph structure related to eax. It instead would gen-
erate a graph structure when eax was assigned earlier in “eax :=
ebx xor ecx”, assuming ebx or ecx contains sensitive information.
Consequently, PM would have to trace back from ret to the earlier
assignment and use the assignment’s graph structure to know the
amount of information in eax at the time of the return.
Second, Flowcheck uses an optimization to avoid generating a
huge flow graph; it generates graph structures for operations that
combine different pieces of data or transform data, but not when
data is moved around completely unchanged. Take the following
as an example:
edx := ebx xor ecx
...
eax := edx
...
ret
A graph structure is generated for “edx := ebx xor ecx”, as-
suming ebx or ecx contains sensitive information; however, no
graph structure is generated for “eax := edx” since it only moves
sensitive information around without changing it. This example
shows that, to calculate the amount of sensitive information in eax
at the place of a return, one could perform dependence analysis to
identify the last operation that affected eax and for which some
graph structure was generated.
PM adopts an easier solution, which performs assembly-level
rewriting to force Flowcheck to generate graph structures for func-
tion arguments and return values at the places of function calls and
returns. Source code is first compiled to assembly code by using
the x86 cdecl calling convention. At the assembly code level, a
sequence of “eax := not eax; eax := not eax” is inserted
before a return. This sequence was chosen because (1) the net ef-
fect of the sequence is a no-op: no registers or flags are affected;7
(2) if eax contains sensitive information, the not operations force
Flowcheck to generate graph structures immediately before the
return instruction, making it easy for PM to identify the amount of
sensitive information in eax at the time of the return.
Similar rewriting is performed for function arguments and global
variables so that PM can identify the amount of sensitive informa-
tion in arguments and global variables during runtime. For function
arguments, in the default x86 calling convention, arguments are
passed on the stack. Before a function call, move instructions are
used to move arguments from registers to the stack. Therefore,
before such a move instruction, a sequence of “r := not r; r
:= not r” is inserted, assuming r is the register used in the move.
Reads from or writes to global variables are also realized through
move instructions. These move instructions are identified with the
help of symbol tables, which tell where global variables are stored
and a similar sequence of “r := not r; r := not r” is inserted
before such a move.
We note that the rewriting is performed purely for measuring
sensitive information flow. After the measurement, the rewritten
program is discarded and PM’s partitioning is performed on the
original program.
Mincut for better precision. After getting the amount of sensi-
tive information in function arguments, return values, and global
variables, one could directly add those numbers as weights to the
PDG. For instance, if at a function call there are two arguments and
each is measured to have 32-bit sensitive information, we could
say that there are 64 bits of flow for the function call. However, the
problem is that the two arguments’ information may overlap and
the actual amount of sensitive information may be less than 64 bits.
To improve precision, PM performs a refinement. We discuss the
case for function arguments; the cases for return values and global
variables are similar. For a function call’s arguments, the refinement
(1) starts from the nodes for the arguments, (2) performs backward
reachability on the flow graph to find a subgraph of nodes that
can reach the starting nodes, up to k nodes, and (3) then performs
the mincut algorithm on the subgraph to find the max capacity of
sensitive information in the starting nodes.
As a toy example, suppose there is a 32-bit secret, and a function
call passes two arguments; the first argument is a copy of the secret,
and the second is the result of one’s complement of the secret. The
following figure shows the relevant graph structure generated by
Flowcheck for this example.
7 The “not” instruction in x86 is like C’s one’s complement (~) operation, but not C’s
logical not (!) operation.
Session 5A: Software SecurityCCS ’19, November 11–15, 2019, London, United Kingdom1039information flow in д reported by Flowcheck since no manipulation
of secret information is performed in д.
However, after partitioning, a function call is turned into an RPC,
during which PM performs deep copying on pointers. For the same
example above, if f and д are in separate partitions, the call from f
to д is turned into an RPC, whose deep copying not only copies the
pointer but also the secret data the pointer points to. As a result, the
partition where д resides has the potential of reading the secret data
through the pointer, if the partition is taken over by an attacker. In
other words, even if д itself does not perform dereferencing, if the
partition where д is taken over, the attacker may have the ability
of inducing arbitrary computation within д’s partition and get the
secret. To measure the potential information flow, PM marks the
pointer that points to sensitive data and performs static tainting to
locate function invocations that pass tainted pointers (i.e., pointers
to sensitive data). For example, if f1 calls f2 with a pointer to a
secret encryption key of size 1K, then the amount of potential flow
is 1K, since f2 has the potential of dereferencing the pointer to get
the secret key.
Aggregation over multiple calls and runs. Flowcheck is a dy-
namic analysis tool; therefore, during the execution of a program,
a function f1 may call f2 multiple times. The steps discussed so far
produce a flow quantity for each call and a flow quantity for each
return. Since PM produces a static PDG in which there is only one
edge from f1 to f2, it aggregates flow quantities associated with
multiple calls. In particular, forward information flow fflow(e) is
the sum of forward flow quantities in multiple dynamic calls that
correspond to the same call edge e; the same goes for bflow(e). A
similar aggregation process happens when a function reads from
or writes to some global variable multiple times.
Dynamic analysis also suffers from the problem of code coverage.
To alleviate the issue, in experiments we designed an extensive
suite of test cases for each benchmark and ran the benchmark
multiple times with different tests; PM then aggregates the flow
quantities over multiple runs. In particular, for a call edge (or a
data-flow edge), PM takes the max quantity over multiple runs.
The hypothesis is that there is a single number that represents the
maximum amount of information a single run of the program could
ever produce; then the maximum from the individual tests is the
best under-approximation of that ideal measurement. Another way
of aggregation is to add flow amounts over multiple runs and is
a conservative way of counting the amount of information flow
through the whole test suite.
The mincut algorithm tells us that the amount of information in
the two arguments is just 32 bits, since both are derived from the
same 32-bit secret. In our implementation, the threshold k for the
subgraph size is 10. We note that any k would affect only precision,
not soundness.
Implicit flows. When executing a conditional jump instruction
that depends on sensitive information, Flowcheck would report
that there is an implicit flow. However, the implicit flow is not
propagated further by Flowcheck. For instance, if there is a subse-
quent operation that assigns a constant to eax, no graph structure
is generated for the assignment even though eax contains sensi-
tive information because the assignment is dependent upon the
conditional jump.
To alleviate this, PM propagates implicit flows interprocedurally
and aggregate them with explicit flows. As an example, suppose f1
calls f2 and there is a 1-bit implicit flow in f2 because it contains a
secret-dependent conditional jump; and its return value contains
2-bit secret information because of explicit flows. Then in the PDG
constructed by PM, the backward flow for the edge from f1 to f2
(i.e., bflow(e)) is annotated with 3 bits (by adding the quantities of
implicit and explicit flows). Furthermore, the 1-bit implicit flow from
f2 to f1 is propagated in the PDG following both data dependence
and control dependence. For instance, if the call from f1 to f2 is
caused by a call from h to f1 and f2’s return value has 1-bit implicit
flow, then f1’s return value is also considered to have a 1-bit implicit
flow when it returns to h.
In an unpartitioned program, passing a pointer
Potential flows.
that points to a secret between functions does not necessarily cause
the secret information to flow into the callee function, because the
pointer itself is not sensitive. For example, suppose function f calls
д with a pointer that points to the secret, and д passes the pointer
to h but does not deference the pointer. Then there is no explicit
Session 5A: Software SecurityCCS ’19, November 11–15, 2019, London, United Kingdom1040