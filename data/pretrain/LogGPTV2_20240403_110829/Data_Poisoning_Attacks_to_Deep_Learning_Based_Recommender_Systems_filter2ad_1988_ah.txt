### References

1. **Management, Education and Information (MEICI 2018).**
   - Atlantis Press, 2018.

2. **B. Sarwar, G. Karypis, J. Konstan, and J. Riedl.**
   - "Item-based collaborative filtering recommendation algorithms."
   - In *Proceedings of the 10th International Conference on World Wide Web*, 2001, pp. 285–295.

3. **J. Steinhardt, P. W. W. Koh, and P. S. Liang.**
   - "Certified defenses for data poisoning attacks."
   - In *Proceedings of the 31st International Conference on Neural Information Processing Systems*, 2017, pp. 3517–3529.

4. **B. Wang, X. Cao, J. Jia, and N. Z. Gong.**
   - "On certifying robustness against backdoor attacks via randomized smoothing."
   - In *CVPR 2020 Workshop on Adversarial Machine Learning in Computer Vision*, 2020.

5. **B. Wang, N. Z. Gong, and H. Fu.**
   - "GANG: Detecting fraudulent users in online social networks via guilt-by-association on directed graphs."
   - In *ICDM*, 2017.

6. **B. Wang, J. Jia, and N. Z. Gong.**
   - "Graph-based security and privacy analytics via collective classification with joint weight learning and propagation."
   - In *NDSS*, 2019.

7. **B. Wang, L. Zhang, and N. Z. Gong.**
   - "SybilScar: Sybil detection in online social networks via local rule-based propagation."
   - In *INFOCOM*, 2017.

8. **G. Wang, T. Konolige, C. Wilson, X. Wang, H. Zheng, and B. Y. Zhao.**
   - "You are how you click: Clickstream analysis for Sybil detection."
   - In *USENIX Security*, 2013.

9. **X. Xing, W. Meng, D. Doozan, A. C. Snoeren, N. Feamster, and W. Lee.**
   - "Take this personally: Pollution attacks on personalized services."
   - In *the 22nd USENIX Security Symposium* (USENIX Security 13), 2013, pp. 671–686.

10. **G. Yang, N. Z. Gong, and Y. Cai.**
    - "Fake co-visitation injection attacks to recommender systems."
    - In *NDSS*, 2017.

11. **H. Yu, H. Yu, M. Kaminsky, P. B. Gibbons, and A. Flaxman.**
    - "SybilGuard: Defending against Sybil attacks via social networks."
    - In *SIGCOMM*, 2006.

12. **D. Yuan, Y. Miao, N. Z. Gong, Z. Yang, Q. Li, D. Song, Q. Wang, and X. Liang.**
    - "Detecting fake accounts in online social networks at the time of registrations."
    - In *CCS*, 2019.

13. **W. Zeller and E. W. Felten.**
    - "Cross-site request forgeries: Exploitation and prevention."
    - *The New York Times*, pp. 1–13, 2008.

14. **S. Zhang, L. Yao, A. Sun, and Y. Tay.**
    - "Deep learning based recommender system: A survey and new perspectives."
    - *ACM Computing Surveys (CSUR)*, vol. 52, no. 1, p. 5, 2019.

15. **W. Zhou, J. Wen, Q. Xiong, M. Gao, and J. Zeng.**
    - "SVM-TIA: A shilling attack detection method based on SVM and target item analysis in recommender systems."
    - *Neurocomputing*, vol. 210, pp. 197–205, 2016.

### Appendix

#### A. Standard Deviations of Experimental Results

In this section, we provide the standard deviations of the experimental results (see Table I in Section V-B), which correspond to those in Table X. Some interesting findings can be observed from Tables I and X:

1. The increase in standard deviations is slower than that of the average hit ratios. For example, on the ML-100K dataset, the average hit ratio for random target items is 0.0025 for the "None" setting, while the standard deviation of the hit ratios for these target items is 0.0033, which is even larger than the former.
2. For all attack methods, after injecting 5% fake users into the target recommender system, all average hit ratios for random target items are larger than the standard deviations for hit ratios of these target items, indicating that all attack methods can promote target items.
3. Our attack has the highest standard deviations in most cases. This is because our attack promotes target items most significantly among all attacks, and the hit ratios for some target items tend to increase faster than others.

**Table X: Standard deviations for different attacks with different attack sizes.**

| Attack Size | Dataset       | Attack        | Random Target Items | Unpopular Target Items |
|-------------|---------------|---------------|---------------------|------------------------|
| 0.5%        | ML-100K       | None          | 0.0033              | 0                      |
|             |               | Random        | 0.0036              | 0.0002                 |
|             |               | Bandwagon     | 0.0038              | 0.0002                 |
|             |               | MF            | 0.0038              | 0.0002                 |
|             |               | Our attack    | 0.0038              | 0.0008                 |
| 1%          | ML-100K       | None          | 0.0033              | 0                      |
|             |               | Random        | 0.0041              | 0.0003                 |
|             |               | Bandwagon     | 0.0039              | 0.0003                 |
|             |               | MF            | 0.0045              | 0.0003                 |
|             |               | Our attack    | 0.0043              | 0.0021                 |
| 3%          | ML-100K       | None          | 0.0033              | 0                      |
|             |               | Random        | 0.0054              | 0.0009                 |
|             |               | Bandwagon     | 0.0056              | 0.0020                 |
|             |               | MF            | 0.0070              | 0.0060                 |
|             |               | Our attack    | 0.0090              | 0.0060                 |
| 5%          | ML-100K       | None          | 0.0033              | 0                      |
|             |               | Random        | 0.0074              | 0.0016                 |
|             |               | Bandwagon     | 0.0075              | 0.0015                 |
|             |               | MF            | 0.0089              | 0.0032                 |
|             |               | Our attack    | 0.0122              | 0.0101                 |

#### B. Hit Ratio per Target Item

In this section, we show the change in the hit ratio for each target item under different attacks and attack sizes. We count the number of target items whose hit ratio has been promoted compared to the original value. The results are shown in Table XI. We find that not all target items can be promoted when a limited number of fake users are injected, which often happens when the attack size is very small. As the attack size increases, more target items get promoted, and eventually, all target items obtain an increased hit ratio in all attack methods when 5% fake users are injected. More importantly, we observe that our attack increases the hit ratios of most selected target items, especially when the attack size is small, e.g., 0.5%. All these results demonstrate the effectiveness of our attack in promoting target items in poisoned deep learning-based recommender systems.

**Table XI: The number of promoted target items for different attacks with different attack sizes.**

| Attack Size | Dataset       | Attack        | None | Random | Bandwagon | MF | Our attack |
|-------------|---------------|---------------|------|--------|-----------|----|------------|
| 0.5%        | ML-100K       | None          | 0    | 4      | 6         | 7  | 9          |
|             | Music         | None          | 0    | 9      | 8         | 10 | 9          |
| 1%          | ML-100K       | None          | 0    | 8      | 8         | 8  | 9          |
|             | Music         | None          | 0    | 10     | 10        | 10 | 10         |
| 3%          | ML-100K       | None          | 0    | 6      | 6         | 5  | 9          |
|             | Music         | None          | 0    | 7      | 8         | 8  | 9          |
| 5%          | ML-100K       | None          | 0    | 10     | 10        | 10 | 10         |
|             | Music         | None          | 0    | 10     | 10        | 10 | 10         |