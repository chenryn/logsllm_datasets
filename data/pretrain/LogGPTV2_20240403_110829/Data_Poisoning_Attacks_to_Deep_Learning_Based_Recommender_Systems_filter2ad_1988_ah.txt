Management, Education and Information (MEICI 2018).
Atlantis
Press, 2018.
[38] B. Sarwar, G. Karypis, J. Konstan, and J. Riedl, “Item-based collabo-
rative ﬁltering recommendation algorithms,” in Proceedings of the 10th
international conference on World Wide Web, 2001, pp. 285–295.
J. Steinhardt, P. W. W. Koh, and P. S. Liang, “Certiﬁed defenses for data
poisoning attacks,” in Proceedings of the 31st International Conference
on Neural Information Processing Systems, 2017, pp. 3517–3529.
[39]
[40] B. Wang, X. Cao, J. Jia, and N. Z. Gong, “On certifying robustness
against backdoor attacks via randomized smoothing,” in CVPR 2020
Workshop on Adversarial Machine Learning in Computer Vision, 2020.
[41] B. Wang, N. Z. Gong, and H. Fu, “Gang: Detecting fraudulent users in
online social networks via guilt-by-association on directed graphs,” in
ICDM, 2017.
[42] B. Wang, J. Jia, and N. Z. Gong, “Graph-based security and privacy
analytics via collective classiﬁcation with joint weight learning and
propagation,” in NDSS, 2019.
[43] B. Wang, L. Zhang, and N. Z. Gong, “Sybilscar: Sybil detection in
online social networks via local rule based propagation,” in INFOCOM,
2017.
16
[44] G. Wang, T. Konolige, C. Wilson, X. Wang, H. Zheng, and B. Y. Zhao,
“You are how you click: Clickstream analysis for sybil detection,” in
USENIX Security, 2013.
[45] X. Xing, W. Meng, D. Doozan, A. C. Snoeren, N. Feamster, and W. Lee,
“Take this personally: Pollution attacks on personalized services,”
the 22nd {USENIX} Security Symposium
in Presented as part of
({USENIX} Security 13), 2013, pp. 671–686.
[46] G. Yang, N. Z. Gong, and Y. Cai, “Fake co-visitation injection attacks
to recommender systems.” in NDSS, 2017.
[47] H. Yu, H. Yu, M. Kaminsky, P. B. Gibbons, and A. Flaxman,
“Sybilguard: defending against sybil attacks via social networks,” in
SIGCOMM, 2006.
[48] D. Yuan, Y. Miao, N. Z. Gong, Z. Yang, Q. Li, D. Song, Q. Wang,
and X. Liang, “Detecting fake accounts in online social networks at the
time of registrations,” in CCS, 2019.
[49] W. Zeller and E. W. Felten, “Cross-site request forgeries: Exploitation
and prevention,” The New York Times, pp. 1–13, 2008.
[50] S. Zhang, L. Yao, A. Sun, and Y. Tay, “Deep learning based rec-
ommender system: A survey and new perspectives,” ACM Computing
Surveys (CSUR), vol. 52, no. 1, p. 5, 2019.
[51] W. Zhou, J. Wen, Q. Xiong, M. Gao, and J. Zeng, “Svm-tia a shilling
attack detection method based on svm and target item analysis in
recommender systems,” Neurocomputing, vol. 210, pp. 197–205, 2016.
APPENDIX
A. Standard Deviations of Experimental Results
In this section, we provide the standard deviations of
experimental results (see Table I in Section V-B), which is
corresponding to that
in Table X. We can observe some
interesting ﬁndings in Table I and Table X. First, the increase
of standard deviations is slower than that of the average hit
ratios. For example, on the ML-100K dataset, the average
hit ratio for random target items is 0.0025 for the “None”
setting, while the standard deviation of the hit ratios for these
target items is 0.0033, even larger than the former. As for all
attack methods, after injecting 5% fake users into the target
recommender system, all average hit ratios for random target
items are larger than the standard deviations for hit ratios
of these target items, which indicates that all attack methods
can promote target items. Second, our attack have the highest
standard deviations in most cases. The reason is that our attack
promotes target items most signiﬁcantly among all attacks and
the hit ratios for some target items tend to increase faster than
others.
B. Hit Ratio per Target Item
In this section, we show the change of the hit ratio for
each target item in different attacks with different attack sizes.
We count the number of target items whose hit ratio has
been promoted compared to the original value. The results
are shown in Table XI. We ﬁnd that not all target items can
get promoted when injecting limited number of fake users,
which often happens when the attack size is very small. As
the attack size increases, more target
items get promoted
and ﬁnally all target items obtain an increased hit ratio in
all attack methods when 5% fake users are injected. More
importantly, we observe that our attack increases the hit ratios
of most selected target items, especially when the attack size
is small, e.g., 0.5%. All these results demonstrate our attack is
effective to promote target items in poison deep learning based
recommender systems.
TABLE X: Standard deviations for different attacks with different attack sizes.
Attack size
Dataset
Attack
Random target items
Unpopular target items
None
Random
ML-100K
Bandwagon
MF
Our attack
None
Random
Music
Bandwagon
MF
Our attack
0.5%
0.0033
0.0036
0.0038
0.0038
0.0038
0.0038
0.0044
0.0044
0.0043
0.0055
1%
0.0033
0.0041
0.0039
0.0045
0.0043
0.0038
0.0049
0.0049
0.0052
0.0066
3%
0.0033
0.0054
0.0056
0.0070
0.0090
0.0038
0.0063
0.0068
0.0073
0.0079
5%
0.0033
0.0074
0.0075
0.0089
0.0122
0.0038
0.0098
0.0076
0.0084
0.0109
0.5%
0
0.0002
0.0002
0.0002
0.0008
0.0005
0.0008
0.0006
0.0005
0.0015
1%
0
0.0003
0.0003
0.0003
0.0021
0.0005
0.0015
0.0014
0.0018
0.0025
3%
0
0.0009
0.0009
0.0020
0.0060
0.0005
0.0041
0.0029
0.0045
0.0063
5%
0
0.0016
0.0015
0.0032
0.0101
0.0005
0.0064
0.0061
0.0062
0.0100
TABLE XI: The number of promoted target items for different attacks with different attack sizes.
Attack size
Dataset
Attack
None
Random
ML-100K
Bandwagon
MF
Our attack
None
Random
Music
Bandwagon
MF
Our attack
0
4
6
7
9
0
9
8
10
9
0
8
8
8
9
0
10
10
10
10
0
6
6
5
9
0
7
8
8
9
Random target items
Unpopular target items
0.5% 1% 3% 5% 0.5% 1% 3% 5%
0
10
10
10
10
0
10
10
10
10
0
9
10
10
10
0
10
10
10
10
0
10
10
10
10
0
10
10
10
10
0
9
10
8
10
0
9
9
9
10
0
10
10
10
10
0
10
10
10
10
17