tion process. While understanding the pathogen’s addi-
tional functionality is in principle impossible—since it
requires solving the Halting Problem—it is important to
keep in mind that the Halting Problem applies to ana-
lyzing arbitrary programs: on the other hand, there are
classes of programs that are fully analyzable, as revealed
by extensive past research in proving programmatic cor-
rectness.
The question is then to what degree can worm authors
write programs that are intractable to analyze. Certainly
it is quite possible to take steps to make programs dif-
ﬁcult to understand; indeed, there is a yearly contest
built around just this theme [NCSB01], and our own un-
funded research in this regard has demonstrated to us the
relative ease of transforming a non-trivial program into
an incomprehensible mess [Pa92].
CDC Task: procure and develop state-of-the-art pro-
gram analysis tools, to assist an on-call group of experts.
These tools would need to go beyond simple disassem-
bly, with facilities for recognizing variants from a library
of different algorithms and components from a variety of
development toolkits, and also components from previ-
ous worms, which would be archived in detail by a CDC
staff librarian.
The tools would also need to support rapid, distributed
program annotation and simulation. Furthermore, the
team would need access to a laboratory stocked with vir-
tual machines capable of running or emulating widely-
used operating systems with support for detailed execu-
tion monitoring. (Less widely-used systems do not pose
much of a threat in regards to Internet-scale worms.) In
addition, code coverage analysis tools coupled with sam-
ple execution of the pathogen could help identify unex-
ecuted portions of the code, which in turn might reﬂect
the pathogen’s additional functionality, and thus merit
detailed analysis. (Or such unused regions could simply
reﬂect “chaff” added by the worm author to slow down
the analysis; an “arms race” seems inevitable here.)
Admittedly, any analysis involving humans might be too
slow to match the pace of a rapidly-propagating worm.
But clearly it will always prove beneﬁcial to know ex-
actly how a worm spread and what it did, even after the
fact; and for a large-scale cyberwarfare situation, speed
will remain of the essence, especially as the “fog of war”
may well retard the attacker’s full use of the worm. This
is especially true if the worm is designed to accept up-
dates, for although the worm’s spread may be extremely
fast, the threat may continue as long as there are a sig-
niﬁcant number of infected machines remaining on the
Internet. Furthermore, for contagion worms, there may
be signiﬁcantly more time available for analysis, if the
worm is detected sufﬁciently early.
7.3 Fighting infections
Naturally, we would want the CDC to help as much as
possible in retarding the progress or subsequent applica-
tion of the worm.
CDC Task: establish mechanisms with which to prop-
agate signatures describing how worms and their trafﬁc
can be detected and terminated or isolated, and deploy
an accompanying body of agents that can then apply the
mechanisms.11
It is difﬁcult to see how such a set of agents can be ef-
fective without either extremely broad deployment, or
pervasive backbone deployment. Both approaches carry
with them major research challenges in terms of co-
ordination, authentication, and resilience in the pres-
ence of targeted attack. As with sensors, the policy is-
sues regarding the actual deployment of such agents are
daunting—who controls the agents, who is required to
host them, who is liable for collateral damage the agents
induce, who maintains the agents and ensures their se-
curity and integrity?
7.4 Anticipating new vectors
We would want the CDC to not only be reactive, but also
proactive: to identify incipient threats.
11Such techniques should also be applied to the numerous strains of
zombies present on the Internet, as they too are a signiﬁcant resource
for an attacker.
CDC Task: track the use of different applications in the
Internet, to detect when previously unknown ones begin
to appear in widespread use. Unfortunately, Internet ap-
plications sometimes can “explode” onto the scene, very
rapidly growing from no use to comprising major trafﬁc
contributors [Pa94]. Accordingly, tracking their onset
is not a simple matter, but will require diligent analysis
of network trafﬁc statistics from a variety of sources, as
well as monitoring fora in which various new applica-
tions are discussed (since some of them may have trafﬁc
patterns that are difﬁcult to discern using conventional
trafﬁc monitoring variables such as TCP/UDP port num-
bers).
CDC Task: analyze the threat potential of new appli-
cations. How widely spread might their use become?
How homogeneous are the clients and servers? What are
likely exploit strategies for subverting the implementa-
tions? What are the application’s native communication
patterns?
7.5 Proactively devising detectors
Once a new potential disease vector has been identiﬁed,
we would then want to deploy analyzers that understand
how the protocol functions, to have some hope of detect-
ing contagion worms as they propagate.
For example, to our knowledge there is no KaZaA mod-
ule (one speciﬁc to how KaZaA functions) available for
network intrusion detection systems in use today. With-
out such a module, it would be exceedingly difﬁcult to
detect when KaZaA is being exploited to propagate a
contagion worm.
CDC Task: foster the development of application anal-
ysis modules suitable for integration with the intru-
sion detection systems in use by the CDC’s outbreak-
identiﬁcation elements.
7.6 Resisting future threats
Devising the means to live with an Internet periodically
ravaged by ﬂash or contagion worms is at best an uneasy
equilibrium. The longer-term requirement is to shift the
makeup of Internet applications such that they become
much less amenable to abuse. For example, this may
entail broader notions of sandboxing, type safety, and
inherent limitations on the rate of creating connections
and the volume of trafﬁc transmitted over them.
CDC Task:
foster research into resilient application
design paradigms and infrastructure modiﬁcations that
(somehow) remain viable for adaptation by the commer-
cial software industry, perhaps assisted by legislation or
government policy.
CDC Task: vet applications as conforming to a certain
standard of resilience to exploitation, particularly self-
propagating forms of exploitation.
7.7 How open?
A ﬁnal basic issue regarding the CDC is to what degree
should it operate in an open fashion. For example, dur-
ing an outbreak the CDC could maintain a web site for
use by the research community. Such an approach would
allow many different people to contribute to the analy-
sis of the outbreak and of the pathogen, perhaps adding
invaluable insight and empirical data. This sort of coor-
dination happens informally today, in part; but it is also
the case that currently a variety of anti-viral and secu-
rity companies analyze outbreaks independently, essen-
tially competing to come out with a complete analysis
ﬁrst. This makes for potentially very inefﬁcient use of
a scarce resource, namely the highly specialized skill of
analyzing pathogens.
A key question then is the cost of operating in an open
fashion. First, doing so brings with it its own set of secu-
rity issues, regarding authenticating purported informa-
tion uploaded into the analysis database, and preventing
an attacker from crippling the analysis effort by launch-
ing a side-attack targeting the system. Second, the at-
tacker could monitor the progress made in understand-
ing the worm, and perhaps gain insight into how it has
spread beyond what they could directly gather for them-
selves, allowing them to better hone their attack. Third,
some sources of potentially highly valuable empirical
data might refuse to make their data available if doing
so is to release it to the public at large.
Given these concerns,
it seems likely that the CDC
would pursue a “partially open” approach, in which
subsets of information are made publicly available,
and publicly-attained information is integrated into the
CDC’s internal analysis, but the information ﬂow is scru-
tinized in both directions. Unfortunately, such scrutiny
would surely involve manual assessment, and could
greatly slow the collection of vital information.
A related question is how international in scope such a
facility should be. A national facility is likely to have
a simpler mission and clearer management and account-
ability. However, there are real beneﬁts to an interna-
tional approach to this problem; one’s allies are awake
and working while one sleeps. A worm released in the
middle of the night in the US would be far more likely
to receive intense early research and attention in Europe
or Asia than in the US itself. Thus, at a minimum, na-
tional level CDCs are likely to need to maintain strong
linkages with one another.
8 Conclusion
In this paper we have examined the spread of several re-
cent worms that infected hundreds of thousands of hosts
within hours. We showed that some of these worms re-
main endemic on the Internet. We explained that better-
engineered worms could spread in minutes or even tens
of seconds rather than hours, and could be controlled,
modiﬁed, and maintained indeﬁnitely, posing an ongo-
ing threat of use in attack on a variety of sites and infras-
tructures. Thus, worms represent an extremely serious
threat to the safety of the Internet. We ﬁnished with a
discussion of the urgent need for stronger societal in-
stitutions and technical measures to control worms, and
sketched what these might look like.
9 Acknowledgments
Many thanks to Jim Ausman, Michael Constant, Ken
Eichmann, Anja Feldmann, Gary Grim, Mark Handley,
Roelof Jonkman, Dick Karp, John Kuroda, Cathy Mc-
Collum, Mike Skroch, Robin Sommer, Laura Tinnel,
Dan Upper, David Wagner, and Brian Witten for very
helpful discussions, analysis, and measurement data.
References
[Bd02] Brilliant Digital Media. “Altnet—a vision
for the future,” Apr. 2, 2002. http://www.
brilliantdigital.com/content.asp?ID=779
[Br+00] Andrei Broder et al, “Graph structure in
the web,” Proc. 9th International World
Wide Web Conference, pp. 309–320, 2000.
http://www9.org/w9cdrom/160/160.html
[CSA00] Neal Cardwell, Stefan Savage, and Thomas
Anderson, “Modeling TCP Latency,” Proc.
INFOCOM, 2000.
[CDC02] Centers for Disease Control and Prevention,
Jan. 2002. http://www.cdc.org
[CE01] CERT, “Code Red II: Another Worm Ex-
ploiting Buffer Overﬂow In IIS Indexing Ser-
vice DLL,” Incident Note IN-2001-09, Aug. 6,
2001. http://www.cert.org/incident notes/IN-
2001-09.html
[CE02] CERT, “CERT Incident Note IN-2001-15,
W32/Goner Worm,”
IN-
2001-15, Dec. 4, 2001. http://www.cert.org/
incident notes/IN-2001-15.html
Incident Note
[CE03] CERT, “CERT Incident Note IN-2001-11,
sadmind/IIS Worm,”
IN-
2001-11, May 8, 2001. http://www.cert.org/
incident notes/IN-2001-11.html
Incident Note
[CV01] Common Vulnerabilities
and Exposures,
“CVE-2001-0500,” Buffer overﬂow in ISAPI
extension (idq.dll), Mar. 9, 2002. http://
cve.mitre.org/cgi-bin/cvename.cgi?name=
CVE-2001-0500
[DA01] Das Bistro Project,
2001.
http://www.
dasbistro.com/default.ida
[Di99] David Dittrich, “The ‘stacheldraht’ distributed
denial of service attack tool”, Dec. 31, 1999.
http://staff.washington.edu/dittrich/misc/
stacheldraht.analysis
[EDS01a] Eeye Digital Security, “.ida ‘Code Red’
Jul. 17,
http://www.eeye.com/html/Research/
Worm,” Advisory AL20010717,
2001.
Advisories/AL20010717.html
[EDS01b] Eeye Digital Security, “Code Red Dis-
assembly,” 2001. http://www.eeye.com/html/
advisories/codered.zip
[EDS01c] Eeye Digital Security, “All versions of Mi-
crosoft
Information Services Re-
mote buffer overﬂow,” AdvisoryAD20010618,
Jun. 18, 2001. http://www.eeye.com/html/
Research/Advisories/AD20010618.html
Internet
[ER89] Mark Eichin and Jon A. Rochlis, “With Mi-
croscope and Tweezers: An Analysis of the
Internet Virus of November 1988,” Proc. 1989
IEEE Computer Society Symposium on Secu-
rity and Privacy.
[Tw02] Tripwire Inc., “Tripwire for Servers,” 2002.
http://www.tripwire.com/products/servers/
index.cfm?
[We02] Nicholas Weaver,
“Reﬂections on Bril-
liant Digital: Single Points of 0wnership”,
2002. http://www.cs.berkeley.edu/∼nweaver/
0wn2.html
[Fa01]
FastTrack — P2P Technology. KaZaA Media
Desktop, Jan. 2002. http://www.fasttrack.nu/
[Ka01] KaZaA Media Desktop, Jan. 2002. http://
www.kazaa.com/en/index.htm
[MSVS02] David Moore, Colleen Shannon, Geof-
frey M. Voelker, and Stefan Savage, “Inter-
net Quarantine: Limits on Blocking Self-
Propagating Code,” work in progress, 2002.
[Mu01] Morpheus, Jan. 2002. http://www.musiccity.
com/
[Ne02] Netcraft,
“Netcraft Web Server Survey,”
Jan. 2002. http://www.netcraft.com/survey/
[NCSB01] Landon Curt Noll, Simon Cooper, Peter
Seebach, and Leonid Broukhis, The Interna-
tional Obfuscated C Code Contest, Jan. 2002.
http://www.ioccc.org/
[OR93]
J. Oikarinen and D. Reed, RFC 1459, Internet
Relay Chat Protocol, May 1993.
[Op01] The
OpenSSL
Project,
http://www.
openssl.org/
[PV01] Romualdo Pastor-Satorras and Alessandro
Vespignani, “Epidemic spreading in scale-free
networks,” Physical Review Letters, 86(14),
pp. 3200–3203, April 2, 2001.
[Pa92] Vern Paxson, 1992. http://www.ioccc.org/
1992/vern.c
[Pa94] Vern Paxson, “Growth trends in wide-area
TCP connections,” IEEE Network, 8(4), pp.
8–17, July 1994.
[Re02]
The Register, “Old Morpheus still works
for unhacked users,” http://www.theregister.
co.uk/content/4/24445.html, Mar. 15, 2002.
[SA01] SANS, “Code Red (II),” August 7, 2001.
http://www.incidents.org/react/code redII.php
[Sp89]
[Sy00]
Eugene Spafford, “An Analysis of the Inter-
net Worm,” Proc. European Software Engi-
neering Conference, pp. 446–468, Sep. 1989.
Lecture Notes in Computer Science #387,
Springer-Verlag.
“Symantic
Re-
Symantic,
sponse: W32.Sonic.Worm,” Oct. 9, 2000.
http://www.sarc.com/avcenter/venc/data/
w32.sonic.worm.html
Security