ior of Microsoft’s browsers based on the domain being visited. We
first became aware of this list while reviewing an alert raised by an
internal traffic quality monitor that was built to identify anomalies
within the distribution of user agents.
The compatibility view list is updated monthly. Its contents
includes a wide variety of publishers, government web sites, and
financial companies. As of this writing, the current XML file for
Edge4 includes about 1600 domains.
For example, the current Internet Explorer list5 shows that when
visiting the financial site, chase.com, the browser should use the
Firefox 22 token, which is represented in the file as:
Mozilla/5.0 ($PLATFORM; Trident/7.0; rv:11.0)\
like Gecko/20100101 Firefox/22.0
This UA contains the Microsoft-specific token Trident but also
contains an out-dated version of Firefox.
The second anomalous instance concerns a dramatic shift within
the UA space that occurred during 2015. In April of that year, the
daily volume of the following Android UAs suddenly increased
from O(10) records per day to O(100M) records per day:
Mozilla/5.0 (Android; U; Android 2.1; en-us;)\
AppleWebKit/525.10 (KHTML,like Gecko)
In other words, prior to April, the volume of this UA was backscatter.
By July 2015, this UA was among the top 100 worldwide. This event
was discovered during a routine manual review of data quality.
Figure 5: The daily volume of the Android User Agent anom-
aly of summer 2015.
This User Agent belongs to a device running Android version
2.1. As documented elsewhere6, this version of Android was most
prevalent during 2010–2011. To summarize, the data showed a sud-
den large shift within the mobile space towards a browser version
that was four years out of date. Figure 5 documents the total daily
volume of this event.
This event was visible from the perspectives of publisher, brand
and ad network. Additionally, no single publisher, ad campaign or
other entity appeared to be a target of this traffic. Since comScore
also collects browser cookie information, we were able to follow
4http://cvlist.ie.microsoft.com/edge/desktop/1432152749/edgecompatviewlist.xml
5http://cvlist.ie.microsoft.com/IE11/1426178821/iecompatviewlist.xml
6https://en.wikipedia.org/wiki/Android_version_history
IMC ’17, November 1–3, 2017, London, United Kingdom
Jeff Kline, Aaron Cahn, Paul Barford, and Joel Sommers
Length
Edit User agent
Dist
Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36
Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.79 Safari/537.36\
Edge/14.14393
109
128
68
110
137
0
31
58
3
65
Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko
Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36
Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_1 like Mac OS X) AppleWebKit/603.1.30 (KHTML, like Gecko) \
Version/10.0 Mobile/14E304 Safari/602.1
Table 1: The five most prevalent user agents seen on May 3 2017. The string length reports character count. The edit distance
reports the Levenshtein distance from the top-ranked User Agent. The top-ranked user agent from a month prior (April 5)
ranked 74th on May 3 and is not displayed.
the evolution of several cookies as they transitioned from a current
browser to the anomalous one and back again. This allowed for a
partial diagnosis of the the cause: the event appeared to be mostly
related to the Facebook app running on Samsung devices. Based
on this, we conjecture that a software misconfiguration released
in April 2015 by one of Samsung, Google or Facebook was the
underlying cause. A more precise diagnosis was not attempted since
the event, despite its large scale and obvious inaccuracy, appeared
benign.
5 RELATED WORK
The HTTP User-Agent string has been used in a number of prior
studies to estimate browser version populations, operating sys-
tem version prevalence, and device populations, particularly mo-
bile handheld devices, e.g., [13, 15, 19, 24]. These prior studies
have noted that their population estimates have appeared to be in
line with industry estimates, e.g., provided by such companies as
netmarketshare.com. Third party services such as udger.com and
deviceatlas.com provide UA string parsing libraries and device
catalogs to help companies track various subpopulations of visitors
to their websites. Maier et al. have also used the combination of UA
string and client IP address to identify multiple devices residing be-
hind NAT devices [19]. We believe that our results can help inform
these string parsing libraries and device catalogs.
The UA string has been commonly used by servers to deliver
appropriately-sized content to mobile devices and other devices
with constrained screen sizes. This is so common that many web
application frameworks contain built-in capabilities for providing
different content variants, e.g., [1]. Some researchers have relied
on this behavior by spoofing the UA request header in order to
analyze differences in content delivered to mobile versus desktop
devices [21, 26].
RFC7231 recommends that a client should not use a UA string
with “needlessly fine-grained detail” [22] to avoid host fingerprint-
ing, and prior studies have evaluated the potential for the UA string
to be used to identify users [7, 11, 27]. Yen et al. found that 60–70%
of users could be identified through the UA string [27], similar to
findings by Eckersley [11]. Our results complement and enhance
those of [27] in the following ways: (1) the long tail in observed UAs
that we see suggests users may be identified through the UA as the
earlier work showed, but (2) our analysis of the time-varying nature
of observed UAs suggests that anonymity sets evolve rapidly over
hours of the day and days of the week due to user behavior (shifting
from one device to another), software updates (e.g., rollout of a new
Chrome version), and browser behavior (e.g., Edge target-specific
behaviors).
Other studies have evaluated UA strings to detect the presence of
malware by using anomalies such as misspellings and inconsistent
information in HTTP headers (e.g., iOS and Flash) [14, 16, 23]. Kotov
and Massacci studied the source code of several exploit kits and
found that server-side malware used the UA string presented by
clients as a way to detect potentially vulnerable operating systems
and devices [17]; the exploit code would mimic an “innocent” site
if the UA indicated a non-vulnerable host.
6 SUMMARY AND CONCLUSIONS
Analysis of User Agent strings transferred during web transactions
offers a compelling perspective on understanding client systems in
the Internet. In this paper, we describe our study of UAs, which is
based on a corpus of over 1B UA strings collected over a period of
2 years by comScore. To conduct this study, we constructed a UA
parsing and analysis infrastructure that is robust to the wide variety
of strings in our data set. Our analysis of the general characteristics
of UA strings reveals that the most prevalent strings comprise
about 26% of all UAs and are composed of the expected instances of
popular platforms such as Google, Microsoft and Apple. We also find
that the rank-frequency distribution of strings is consistent with a
power law. Our analysis of the UAs observed at multiple time scales
indicates dynamic characteristics that can be explained by day-to-
day user behavior and by periodic updates to hardware and software
platforms. Finally, we examine UA strings that have been identified
as anomalous or pertaining to unwanted or malicious activity. These
UA strings reveal that there are instances of unexpected anomalies.
In on-going work, we continue to expand and drill down in our
analyses. We expect this will reveal a variety of characteristics—
especially in the long tail of the data—that will improve analysis,
test and content negotiation capabilities.
ACKNOWLEDGMENTS
We thank the anonymous reviewers and our shepherd Theophilus
Benson for their feedback. This material is based upon work sup-
ported by DHS grant BAA 11-01 and AFRL grant FA8750-12-2-0328.
Any opinions, findings, and conclusions or recommendations ex-
pressed in this material are those of the authors and do not neces-
sarily reflect the views of the DHS or AFRL.
On the Structure and Characteristics of User Agent String
IMC ’17, November 1–3, 2017, London, United Kingdom
REFERENCES
[1] [n. d.]. Action Pack Variants (Ruby on Rails 4.1 Release Notes). http://edgeguides.
rubyonrails.org/4_1_release_notes.html#action-pack-variants. ([n. d.]). Accessed
August 2017.
[2] [n. d.]. Panopticlick. ([n. d.]). https://panopticlick.eff.org/
[3] [n. d.]. Udger. ([n. d.]). https://udger.com/resources/ua-list
[4] [n. d.]. Understanding the compatibility view list. https://msdn.microsoft.com/
en-us/library/gg622935(v=vs.85).aspx. ([n. d.]). Accessed August 2017.
[5] [n. d.]. UserAgentString.
([n. d.]). http://www.useragentstring.com/pages/
useragentstring.php
[6] [n. d.]. WhatIsMyBrowser.com. ([n. d.]). https://www.whatismybrowser.com/
developers/tools/user-agent-parser/browse
[7] Károly Boda, Ádám Máté Földes, Gábor György Gulyás, and Sándor Imre. 2011.
User tracking on the web via cross-browser fingerprinting. In Nordic Conference
on Secure IT Systems. 31–46.
[8] Aaron Cahn, Scott Alfeld, Paul Barford, and S. Muthukrishnan. 2016. An Empirical
Study of Web Cookies. In Proceedings of the 25th International Conference on World
Wide Web (WWW ’16). International World Wide Web Conferences Steering
Committee, Republic and Canton of Geneva, Switzerland, 891–901. https://doi.
org/10.1145/2872427.2882991
[9] Shauvik Roy Choudhary, Husayn Versee, and Alessandro Orso. 2010. Webdiff:
Automated identification of cross-browser issues in web applications. In IEEE
International Conference on Software Maintenance (ICSM). 1–10.
[10] Media Ratings Council. [n. d.]. Invalid Traffic Detection and Filtration Guidelines
Addendum. ([n. d.]). http://mediaratingcouncil.org/101515_IVT%20Addendum%
20FINAL%20(Version%201.0).pdf
[11] Peter Eckersley. 2010. How unique is your web browser?. In International Sym-
posium on Privacy Enhancing Technologies Symposium. 1–18.
[12] EF Foundation. [n. d.]. Panopticlick. ([n. d.]). https://panopticlick.eff.org/
[13] Aaron Gember, Ashok Anand, and Aditya Akella. 2011. A comparative study of
handheld and non-handheld traffic in campus Wi-Fi networks. In International
Conference on Passive and Active Network Measurement. 173–183.
[14] Martin Grill and Martin Rehák. 2014. Malware detection using HTTP user-agent
discrepancy identification. In Information Forensics and Security (WIFS), 2014 IEEE
International Workshop on. 221–226.
[15] Sunghwan Ihm and Vivek S Pai. 2011. Towards understanding modern web traffic.
In Proceedings of the 2011 ACM SIGCOMM conference on Internet measurement
conference. 295–312.
[16] Nizar Kheir. 2013. Analyzing HTTP user agent anomalies for malware detection.
In Data Privacy Management and Autonomous Spontaneous Security. 187–200.
[17] Vadim Kotov and Fabio Massacci. 2013. Anatomy of exploit kits. In International
Symposium on Engineering Secure Software and Systems. 181–196.
[18] Balachander Krishnamurthy. 2001. Web protocols and practice: HTTP/1.1, Network-
ing protocols, caching, and traffic measurement. Addison-Wesley Professional.
[19] Gregor Maier, Fabian Schneider, and Anja Feldmann. 2010. A first look at mobile
hand-held device traffic. In International Conference on Passive and Active Network
Measurement. 161–170.
[20] Ali Mesbah and Mukul R Prasad. 2011. Automated cross-browser compatibility
testing. In Proceedings of the 33rd International Conference on Software Engineering.
561–570.
[21] Jitu Padhye and Henrik Frystyk Nielsen. 2012. A comparison of SPDY and HTTP
performance. Technical Report MSR-TR-2012-102.
[22] J. Reschke and R. Fielding. 2014. RFC 7231: Hypertext Transfer Protocol
(HTTP/1.1): Semantics and Content. http://tools.ietf.org/html/rfc7231. (June
2014).
[23] Christian Rossow, Christian J Dietrich, Herbert Bos, Lorenzo Cavallaro, Maarten
Van Steen, Felix C Freiling, and Norbert Pohlmann. 2011. Sandnet: Network
traffic analysis of malicious software. In Proceedings of the First Workshop on
Building Analysis Datasets and Gathering Experience Returns for Security. 78–88.
[24] Fabian Schneider, Bernhard Ager, Gregor Maier, Anja Feldmann, and Steve Uh-
lig. 2012. Pitfalls in HTTP traffic measurements and analysis. In International
Conference on Passive and Active Network Measurement. 242–251.
[25] Kevin Springborn and Paul Barford. 2013. Impression Fraud in On-line Advertis-
ing via Pay-Per-View Networks. In USENIX Security. 211–226.
[26] Paul J Timmins, Sean McCormick, Emmanuel Agu, and Craig E Wills. 2006. Char-
acteristics of mobile web content. In Hot Topics in Web Systems and Technologies,
2006. HOTWEB’06. 1st IEEE Workshop on. 1–10.
[27] Ting-Fang Yen, Yinglian Xie, Fang Yu, Roger Peng Yu, and Martin Abadi. 2012.
Host Fingerprinting and Tracking on the Web: Privacy and Security Implications.
In NDSS.