provides an example, but also describes the weaker Data
Encryption Standard (DES) as cryptographically secure. The
documentation warns against weak exclusive-or (XOR) en-
cryption. However, the documentation does not warn against
using the default Electronic Code Book (ECB) mode, or the
default empty IV, neither of which is secure.
M2Crypto. M2Crypto [43] is a binding to the well-known
OpenSSL library that is more complete than alternative bind-
ings such as pyOpenSSL. Although development on M2Crypto
has largely ceased, the library is still widely used, and there
is ample documentation and online usage examples, so we
included it. M2Crypto supports all of the tasks we tested,
including X.509 certiﬁcate handling. Developers are required
to choose algorithms, modes of operation, and initialization
vectors. M2Crypto comes with automatically generated doc-
umentation that includes no code examples or comments on
the security of cryptographic algorithms and modes.
cryptography.io. cryptography.io has a stated goal of pro-
viding more usable security than other libraries by emphasiz-
ing secure algorithms, high-level methods, safe defaults, and
good documentation [8]. It supports symmetric and asymmet-
ric encryption as well as X.509 certiﬁcate handling. The docu-
mentation includes code examples that include secure options,
with context for how they should be used. cryptography.io pro-
vides a high-level interface for some cryptographic tasks (such
158
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:21:34 UTC from IEEE Xplore.  Restrictions apply. 
Fig. 1. An example of the study’s task interface.
as symmetric key generation and encryption); this interface
does not require developers to choose any security-sensitive
parameters. The library also includes a lower-level interface,
necessary for some asymmetric tasks and for encrypted key
storage; this low-level interface does require developers to
specify parameters such as algorithm and salt.
Keyczar. The library aims to make it easier to safely use
cryptography, so that developers do not accidentally expose
key material, use weak key lengths or deprecated algorithms,
or improperly use cryptographic modes [40]. The documen-
tation consists of an 11-page technical report that includes
a few paragraphs regarding the program’s design and a few
abbreviated examples. Keyczar does not easily support X.509
certiﬁcate handling, encrypted key ﬁles, or password-based
key derivation, but it does support digital signatures. There is
no public API for key generation, but developers can generate
keys by using an internal interface or by calling a provided
command-line tool programmatically. Developers do not have
to specify cryptographic algorithms, key sizes, or modes of
operation.
PyNaCl. PyNaCl is a Python interface to libsodium [62],
a cryptographic library designed with a focus on usability.
The detailed documentation includes code examples with
159
context for how to use them. PyNaCl supports both secure
symmetric and asymmetric APIs without requiring the devel-
oper to choose cryptographic details, although the developer
must provide a nonce. PyNaCl neither supports encrypted key
storage nor password-based key derivation. X.509 certiﬁcate
handling is also not supported directly; however, verifying
digital signatures is supported.
G. Exit survey
Once all
tasks had been completed or abandoned,
the
participant was directed to a short exit survey. We asked for
their opinions about the tasks they had completed and the
library they used, including the standard System Usability
Scale (SUS) [63] score for the library. We also collected their
demographics and programming experience. The participant’s
code for each task was displayed (imported from our database)
for their reference with each question about that task.
We were speciﬁcally interested in the participants’ opinions
about the usability of the API. To this end, we collected the
SUS score, but we wanted to also investigate in more depth.
Prior work on API usability has suggested several concrete
factors that affect an API’s usability. We combined the cog-
nitive dimensions framework [24] with usability suggestions
from Nielsen and from Smith and Green [23], [27], and pulled
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:21:34 UTC from IEEE Xplore.  Restrictions apply. 
out the factors that could most easily be evaluated via self-
reporting from developers using the API. We transformed these
factors into an 11-question scale (given in Appendix A) that
focuses on the learnability of the API, the helpfulness of its
documentation, the clarity of observed error messages, and
other features. Our scale can be used to produce an overall
score, as well as to target speciﬁc characteristics that impede
the usability of each API. For this work, we treat this scale
as exploratory; we correlate it with SUS and investigate its
internal reliability in Section IV-F.
H. Evaluating participant solutions
We used the code submitted by our participants for each
task, henceforth called a solution, as the basis for our analysis.
We evaluated each participant’s solution to each task for
both functional correctness and security. Every task was inde-
pendently reviewed by two coders, using a codebook prepared
ahead of time based on the capabilities of the libraries we eval-
uated. Differences between the two coders were adjudicated
by a third coder, who updated the codebook accordingly. We
brieﬂy describe the codebook below.
Functionality. For each programming task, we assigned a
participant a functionality score of 1 if the code ran without
errors, passed the tests and completed the assigned task, or 0
if not.
Security. We assigned security scores only to those solu-
tions which were graded as functional. To determine a security
score, we considered several different security parameters.
A participant’s solution was marked secure (1) only if their
solution was acceptable for every parameter; an error in any
parameter resulted in a security score of 0.
Not all security parameters applied to all libraries, as some
libraries do not allow users to make certain potentially insecure
choices. Details of how the different security parameters
applied to each library can be found in Table III. Whenever a
given library requires a developer to make a secure choice for
a given parameter, we assign a full circle; if that parameter
is not applicable in that library, we assign an empty circle.
For example, for symmetric encryption, PyCrypto participants
had to specify an encryption algorithm, mode of operation and
an initialization vector (three full circles). However, PyNaCl
participants did not have to care about these cryptographic
details (three empty circles).
For key generation, we checked key size and proper source
of randomness for the key material. We selected an appro-
priate key size for a particular algorithm (e.g., for RSA we
required at least 2 048-bit keys [64]). For key storage we
checked if encryption keys were actually encrypted and if
a proper encryption key was derived from the password we
provided. Depending on the library and task type, encrypt-
ing cryptographic key material requires the application of a
key derivation function such as PBDKF2 [65]. For libraries
in which developers had to pick parameters for PBKDF2
manually (cf. Table III), we scored use of a static or empty
salt, HMAC-SHA1 or below as the pseudorandom function,
and less than 10 000 iterations as insecure [66]. For some
160
libraries, participants had to select encryption parameters for
one or more tasks; in these cases, we also scored the security
of the chosen encryption algorithm, mode of operation, and
initialization vector. For symmetric encryption, we scored
ARC2, ARC4, Blowﬁsh, (3)DES, and XOR as insecure, and
AES as secure. We scored the ECB as an insecure mode of
operation and scored Cipher Block Chaining (CBC), Counter
Mode (CTR) and Cipher Feedback (CFB) as secure. Static,
zero or empty initialization vectors were scored insecure. For
asymmetric encryption we scored the use of OAEP/PKCS1
for padding as secure.
I. Limitations
As with any user study, our results should be interpreted
in context. We chose an online study because it is difﬁcult to
recruit “real” developers (rather than students) for an in-person
lab study at a reasonable cost. Choosing to conduct an online
study allowed us less control over the study environment;
however, it allowed us to recruit a geographically diverse
sample. Because we targeted developers, we could not easily
take advantage of services like Amazon’s Mechanical Turk
or survey sampling ﬁrms. Managing online study payments
outside such infrastructures is very challenging; as a result, we
did not offer compensation and instead asked participants to
generously donate their time. As might be expected, the com-
bination of unsolicited recruitment emails and no compensa-
tion led to a strong self-selection effect, and we expect that our
results represent developers who are interested and motivated
enough to participate. Comparing the full invited sample to
the valid participants (see Section IV-A) suggests that indeed,
more active GitHub users were more likely to participate. That
said, these limitations apply across conditions, suggesting that
comparisons between conditions are valid. Further, we found
almost no results (Section IV-G) correlated with self-reported
Python experience.
In any online study, some participants may not provide full
effort, or may answer haphazardly. In this case, the lack of
compensation reduces the motivation to answer in a manner
that is not constructive; those who are not motivated will
typically not participate. We attempt to remove any obviously
low-quality data (e.g., responses that are entirely invective)
before analysis, but cannot discriminate perfectly. Again, this
limitation should apply across conditions without affecting
condition comparisons.
Our study examines how developers use different crypto-
graphic libraries. Developers who reach this point already
recognize that they need encryption and have chosen to use
an existing library rather than trying to develop their own
mechanism; these are important obstacles to secure code that
cannot be addressed by better library design. Nonetheless, we
believe that evaluating and improving cryptographic libraries
is a valuable step toward more secure development.
Finally, we are comparing libraries overall: this includes
their API design and implementation as well as their docu-
mentation. The quality of both varies signiﬁcantly across the
libraries. Our results provide insight into the contributions
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:21:34 UTC from IEEE Xplore.  Restrictions apply. 
Key Generation
Size
Plain/
Encrypted
Key Storage
Key Derivation
Encryption
Algorithm Mode
IV
Salt
PRF
Iterations
Algorithm Mode
IV
*
*
*
*
*
*
Key Generation
Type
Size
Plain/
Encrypted
Key Storage
Encryption
Algorithm Mode
IV
Padding
Nonce
Signature
Veriﬁcation
Certiﬁcate Validation
CA
Check
Hostname
Check
Date
Check
*
*
*
*
*
*
TABLE III
Symmetric
PyCrypto
M2Crypto
cryptography.io
Keyczar
PyNaCl
Asymmetric
PyCrypto
M2Crypto
cryptography.io
Keyczar
PyNaCl
indicates no such
Security choices required by various libraries, as deﬁned in our codebook.
choice is required. Libraries that do not include a key derivation function, requiring the developer to fall back to Python’s hashlib API, are indicated with *.
indicates the developer is required to make a secure choice,
made by documentation and by API design to a library’s
overall success or failure, but future work is needed to further
explore how the two operate independently.
IV. STUDY RESULTS
Study participants experienced very different rates of task
completion, functional success, and security success as a
function of which library they were assigned and whether they
were assigned the symmetric or asymmetric tasks. Overall, we
ﬁnd that completion rate, functional success, and self-reported
usability satisfaction showed similar results: cryptography.io,
PyCrypto and (to some extent) PyNaCl performed best on
these metrics. The security results, however, were somewhat
different. PyCrypto and M2Crypto were worst, while Keyczar
performed best. PyNaCl also had strong security results;
cryptography.io exhibited strong security for the symmetric
tasks but poor security for asymmetric tasks. These results
suggest that the relationship between “usable” design, devel-
oper satisfaction, and security outcomes is a complex one.
A. Participants
In total, we sent 52 448 email invitations. Of these, 5 918
(11.3%) bounced, and another 698 (1.3%) requested to be
removed from our list, a request we honored.
A total of 1 571 people agreed to our consent form; 660
(42.0%) dropped out without taking any action, most likely
because the initial task seemed too difﬁcult or time-consuming.
The other 911 proceeded through at least one task; of these,
337 proceeded to the exit survey, and 282 completed it with
valid responses.1 Of these, 26 were excluded for failing to
use their assigned library. Unless otherwise noted, we report
results for the remaining 256 participants, who proceeded
through all tasks, used their assigned library, and completed
the exit survey with valid responses.
1We deﬁne invalid responses as providing straight-line answers to all
questions or writing off-topic or abusive comments in free-text responses.
An additional 61 participants attempted to reach the study
but encountered technical errors in our infrastructure, mainly
due to occasional AWS pool exhaustion during times of high
demand.
Our 256 participants reported ages between 18 and 63 (mean
29.4, sd 7.9), and the vast majority of them reported being
male (238, 93.0%).
We successfully reached the professional developer de-
mographic we targeted. Almost all (247, 96.5%) had been
programming in general for more than two years, and 81.2%
(208) had been programming in Python for more than two
years. Most participants (196, 76.6%) reported programming
as (part of) their primary job; of those, 147 (75.0%) used
Python in their primary job. Most participants (195, 76.2%)
said they had no IT-security background.
While the developers we invited represent a random sample
from GitHub, our valid participants are a small, self-selected
subset. Table IV and Figure 2 detail available GitHub demo-
graphics for both groups. Our participants appear to be slightly
more active on GitHub than average: owning more public
repositories, having more followers, having older accounts,
and being more likely to provide optional proﬁle information.
This may correspond to their self-reported high levels of
programming experience and professional status.
B. Regression models
In the following subsections, we apply regression models to
analyze our results in detail. To analyze binary outcomes (e.g.,
secure vs. insecure), we use logistic regression; to analyze
numeric outcomes (e.g., SUS score), we use linear regression.
When we consider results on a per-task rather than a per-
participant basis (for security and functionality results, as well
as perceived security), we use a mixed model that adds a
random intercept to account for multiple tasks from the same
participant.
161
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:21:34 UTC from IEEE Xplore.  Restrictions apply. 
Hireable
Company listed
URL to Blog
Biography added
Location provided
Public gists (median)
Public repositories (median)
Following (users, median)
Followers (users, median)
GitHub proﬁle creation (days ago, median)
GitHub proﬁle last update (days ago, median)
Valid
Invited
19.5% 37.9%
28.0% 42.2%
34.7% 55.6%
8.1% 16.3%
49.9% 75.8%
1
20
2
7
1 589
38
0
12
1
3
1 415
50
GitHub demographics for the 50 000 invited users and for our 256 valid
TABLE IV
participants.
Fig. 2. Boxplots comparing our invited participants (a random sample from
GitHub) with those who provided valid participation. The center line indicates
the median; the boxes indicate the ﬁrst and third quartiles. The whiskers extend
to ±1.5 times the interquartile range. Outliers greater than 150 were truncated
for space.
For each regression analysis, we consider a set of candi-
date models and select the model with the lowest Akaike
Information Criterion (AIC) [67]. The included factors are
described in Table V. We consider candidate models consisting
of the required factors library and encryption mode, as well
as (where applicable) the participant random intercept, plus
every possible combination of the optional variables.
We report the outcome of our regressions in tables. Each
row measures change in the analyzed outcome related to
changing from the baseline value for a given factor to a
different value for that factor (e.g., changing from asymmet-
ric to symmetric encryption). Logistic regressions produce
an odds ratio (O.R.) that measures change in likelihood of
the targeted outcome; baseline factors by construction have
O.R.=1. For example, Table VII indicates that M2Crypto
participants were 0.55× as likely to complete all tasks as
participants in the baseline PyCrypto condition. In constrast,
linear regressions measure change in the absolute value of the
outcome; baseline factors by construction have coef=0. In each
row, we also provide a 95% conﬁdence interval (C.I.) and a
p-value indicating statistical signiﬁcance.
For each regression, we set the library PyCrypto as the
baseline, as it has the most download counts of all libraries we
included in our study, and can therefore be considered as the
most common “default” crypto library for Python. In addition,
we used the set of symmetric tasks as the baseline, as these
correspond to the simpler and more basic form of encryption.
All baseline values are given in Table V.
C. Dropouts
We ﬁrst examine how library and encryption mode affected
participants’ dropout rates, as we believe that dropping out of
the survey is a ﬁrst (if crude and oversimpliﬁed) measure of
how much effort was required to solve the assigned tasks with
the assigned library. Table VI details how many participants
in each condition reached each stage of the study.
We test whether library and encryption mode affect dropout
rate using a logistic regression model (see Section IV-B)
examining whether each participant who consented proceeded
through all tasks and started the exit survey. (We use the
start of the survey here because dropping out at the survey
stage seems orthogonal to library type.) For this model, we
include only the library-encryption mode interactions as an
optional factor, because we do not have experience or security
background data for the participants who dropped out.
The ﬁnal model (see Table VII) indicates that asymmetric-
encryption participants were only about half as likely to
proceed through all tasks as participants assigned to symmetric
encryption, which was statistically signiﬁcant. Compared to
the “default” choice of PyCrypto, participants assigned to
M2Crypto and Keyczar were about half as likely to proceed
through all
tasks, which was also statistically signiﬁcant.
PyNaCl exhibits a higher dropout rate than PyCrypto; how-
ever, this trend was not signiﬁcant. cryptography.io matches
PyCrypto’s dropout rate. Although the two-way interactions
are included in the ﬁnal model, none exhibits a signiﬁcant
result.
Overall, these results suggest that PyCrypto (approximate
default) and cryptography.io (designed for usability, with rela-
tively complete documentation) were least likely to drive par-
ticipants away. Keyczar, also designed for usability, performed
worst on this metric.
D. Functionality results
We next discuss the extent to which participants were able to
produce functional solutions—that is, solutions that produced
a key or encrypted and decrypted some content without
generating an exception.2 We observed a wide variance in
functional results across libraries and encryption types, ranging
from asymmetric Keyczar (13.7% functional) to symmetric
cryptography.io and symmetric PyNaCl (89.5% and 87.9%