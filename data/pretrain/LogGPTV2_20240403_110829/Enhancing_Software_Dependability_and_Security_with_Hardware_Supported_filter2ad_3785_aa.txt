title:Enhancing Software Dependability and Security with Hardware Supported
Instruction Address Space Randomization
author:Seung-Hun Kim and
Lei Xu and
Ziyi Liu and
Zhiqiang Lin and
Won Woo Ro and
Weidong Shi
2015 45th Annual IEEE/IFIP International Conference on Dependable Systems and Networks
2015 45th Annual IEEE/IFIP International Conference on Dependable Systems and Networks
Enhancing Software Dependability and Security with
Hardware Supported Instruction Address Space
Randomization
Seung Hun Kim∗, Lei Xu†, Ziyi Liu†, Zhiqiang Lin‡, Won Woo Ro∗, and Weidong Shi†
∗School of Electrical and Electronic Engineering, Yonsei University, Seoul, Republic of Korea.
Email: PI:EMAIL, PI:EMAIL
†Department of Computer Science, University of Houston, Houston, TX, USA.
Email: PI:EMAIL, PI:EMAIL, PI:EMAIL
‡Department of Computer Science, The University of Texas at Dallas, Dallas, TX, USA.
Email: PI:EMAIL
Abstract—We present a micro-architecture based lightweight
framework to enhance dependability and security of software
against code reuse attack. Different from the prior hardware
based approaches for mitigating code reuse attacks, our solution
is based on software diversity and instruction level control ﬂow
randomization. Generally, software based instruction location
randomization (ILR) using binary emulator as a mediation layer
has been shown to be effective for thwarting code reuse attacks
like return oriented programming (ROP). However, our in-depth
studies show that straightforward and naive implementation of
ILR at the micro-architecture level will incur major performance
deﬁciencies in terms of instruction fetch and cache utilization.
For example, straightforward implementation of ILR increases
the ﬁrst level instruction cache miss rates on average by more
than 9 times for a set of SPEC CPU2006 benchmarks. To address
these issues, we present a novel micro-architecture design that can
support native execution of control ﬂow randomized software
binary while at the same time preserve the performance of
instruction fetch and efﬁcient use of on-chip caches. The proposed
design is evaluated by extending cycle based x86 architecture
simulator, XIOSim with validated power simulation. Performance
evaluation on SPEC CPU2006 benchmarks shows an average
speedup of 1.63 times compared to the hardware implementation
of ILR. Using the proposed approach, direct execution of ILR
software incurs only 2.1% IPC performance slowdown with a
very small hardware overhead.
Keywords—Instruction
location
randomization,
micro-
architecture, code reuse attack, software security
I.
INTRODUCTION
Code reuse attacks allow the adversary to make malicious
results by exploiting control ﬂow in the existing program with-
out any additional code injection [1], [2], [3]. Return oriented
programming (ROP) attack is an representative example. Using
ROP, the attacker can link small pieces of code which is
known as gadgets, that already exist in the binary image of
a vulnerable application. In fact, the ROP gadgets are short
sequences of code, typically ending with a return or indirect
control transfer instruction. Instead of injecting binary code
into the memory space of an application, the attacker can use
a sequence of gadget in the stack or other memory areas of the
program. Each gadget ends with an indirect control transfer
instruction, which transfers the control
to the next gadget
according to the injected gadget sequence. During the attack,
978-1-4799-8629-3/15 $31.00 © 2015 IEEE
978-1-4799-8629-3/15 $31.00 © 2015 IEEE
DOI 10.1109/DSN.2015.48
DOI 10.1109/DSN.2015.48
251
251
the adversary can circumvent many defenses such as read-only
memory [4], non-executable memory [5], kernel code integrity
protections [6] since the injected part is only data (rather than
code). In addition, access to ROP exploits is not difﬁcult since
they are provided in the publicly available packs [7].
Most existing defense mechanisms, such as instruction set
randomization [8] or simple address space layout random-
ization (ASLR) cannot prevent code reuse attacks. For this
reason, many solutions have been proposed to mitigate the
risks of code reuse attack [9], [10]. Recently, approaches
at micro-architecture level are also presented for detecting
control ﬂow violations or monitoring control ﬂows at runtime
using hardware support [11], [12], [13]. Among the previously
proposed concept, instruction location randomization (ILR) is
widely used due to the effectiveness of the method [14].
Pappas et al. described an in-place code randomization
approach to mitigate ROP exploits by applying ILR within
basic blocks [10]. The binary transformations include re-
ordering instructions within the basic block boundaries without
changing execution results. On the other hand, Hiser et al. pre-
sented complete ILR [9]. The solution completely randomizes
the location of every instruction in a program. Consequently, it
can thwart an attacker’s ability to re-use the existing program
gadgets (e.g., ROP based exploits, arc-injection attacks). In-
place code randomization and complete ILR are software based
approaches for mitigating gadget based exploits. ILR and other
similar approaches often rely on heavy-weight runtime instru-
mentations or exotic binary emulation frameworks that can in-
cur signiﬁcant overhead. For minimizing such overheads, most
software based approaches support either partial ILR (e.g.,
randomization within basic block boundary) or randomization
with reduced scope to achieve acceptable performance. As
more variations and less predictable control ﬂow will increase
resilience to remote attacks. In fact, Snow et al. pointed out
that 32 bit address space is hard to provide enough entropy
to protect systems from just-in-time code reuse attack [15]. In
this case, applying a 64 bit address space can be a solution by
increasing the entropy of the randomization [14]. However,
partial randomization approach cannot
take full advantage
of increased address space while the complete randomiza-
tion does. Consequently, complete ILR provides higher level
security beneﬁts by maximizing resilience with completely
randomized control ﬂows.
Besides performance and efﬁciency reasons, another major
beneﬁt of supporting ﬁne grained instruction layout or control
ﬂow randomization at micro-architecture level is reduced at-
tacking surfaces by removing the binary emulation layer. In
fact, software based approach is less secure because malicious
attackers can target the software emulation or interpretation
layer. Similar to how out-of-order execution is hidden from
the OS and compiler, our micro-architecture based approach
hides the actual instruction space and minimizes the interface
exposed to the hackers (attacking surface).
According to our studies, straightforward implementation
of complete ILR at hardware level has major performance
issues with some of the established design principles of
modern micro-processor. When compared with the baseline
architecture with identical cache organizations, straightforward
implementation of ILR will increase the ﬁrst level instruction
cache miss rates since the instructions are widely spread among
the memory space. That is, if ILR is to be integrated with
native execution support, one has to come up with a new
approach that can meet both the goals of maximizing ran-
domness of instruction layout and efﬁcient software execution.
Last but not the least, it is a fact that software based approach
suffers from lack of adoption by the end users as many
companies and web services don’t use the most secure software
(sometimes due to cost and lack of knowledge/incentive) or
apply security patches. When attack resilience is built into
the micro-architecture, it can eliminate the adoption barrier by
providing default attack resilience integrated with the hardware
itself. To achieve all these goals and beneﬁts, we propose
micro-architecture based solution for complete ILR in this
paper. Speciﬁcally, we make the following contributions:
•
•
•
•
Introducing the performance problem of instruction
fetch caused by native support of randomized instruc-
tion layout and the need for new solutions that can
support software diversity with minimal impact on
performance;
Presenting the novel architecture design of one such
solution that can support native execution of control
ﬂow randomized software binary and at
the same
time preserve the performance of instruction fetch and
efﬁcient use of on-chip caches;
Proposing a novel control ﬂow randomization concept
that uses a lightweight mediation layer to create ran-
domized view of instruction space without destroying
instruction locality at memory hierarchy; and
Demonstrating the effectiveness of the proposed ap-
proach using cycle based architectural model and
SPEC benchmarks.
II. THREAT MODEL OF GADGET BASED EXPLOITS
Our threat model is deﬁned as the following. An attacker
is attempting to subvert a remote system via gadget and ROP1
exploits. Software applications are distributed to the end user
in binary format, and then randomized. The binary application
1In this paper, we decide to use ROP as a representative code reuse attack
method. Details are explained in Section V.
Fig. 1.
Instruction space and control ﬂow randomization of ILR. The
mechanism provides control ﬂow randomization for reducing the attack surface
of gadget based exploits. Existing software based ILR uses instruction level
emulator to support execution of randomized instructions.
has been tested, but not guaranteed to be vulnerability free.
The program may contain weakness that can be exploited by
ROP based attacks. However, the application is assumed to
be free from back doors or trojans. Furthermore, we assume
that there is no insider attack and the system is managed
by trusted administrators. The attacker does not know/see the
executable version of the binary code after randomization is
applied. As such,
the attacker can only launch a kind of
random attack because the attacker can neither see (due to the
lack of privilege) nor run the randomized code (because the
attacker does not have physical access to the system controlled
by the system administrator). Moreover, the attacker cannot
observe the instruction-by-instruction state change from the
operating system. Our threat model mainly focuses on attacks
where applications are subverted by processing malicious data
submitted by the attacker. The data may contain ROP exploits.
The threat model covers a wide range of exploits, such as
attacks to client-server based program, exploits to document
viewers, browsers, network clients, etc. According to the previ-
ous research in the literature, randomization/diversiﬁcation can
effectively mitigate a wide range of security attacks because
of reduced attack surface. Though this paper focuses more on
the security risks associated with ROP, the proposed micro-
architecture facilitated complete ILR increases a computing
system’s resilience against many exploits beyond ROP.
III. MOTIVATION AND APPROACH OVERVIEW
Native support of ﬁne grained ILR has many advantages
than the existing software based approaches. One main beneﬁt
of integrating ILR with micro-architecture is improved perfor-
mance by maintaining the efﬁciency of on-chip cache access.
To execute binary programs randomized by ILR such as
the one shown in Figure 12, a special virtual machine that
decodes the randomized instruction sequences at runtime is
required. Figure 2 shows that when ILR is implemented on an
2In this example ﬁgure, we assume that all instructions are 32 bit and the
memory address is 16 bit. For the simplicity, we apply same assumption for
the rest of the ﬁgures which show instructions and memory space.
252252
 movl  -12(%rbp), %eax . . . L5:   movl  -12(%rbp), %eax   andl  $1, %eax   testl %eax, %eax   jne   L3   addl  $1, -8(%rbp)   jmp   L4 L4:   addl  $1, -12(%rbp) . . . 0100  andl  $1, %eax 0104  testl %eax, %eax 0108  jne   0130 010c  addl  $1, -8(%rbp) 0110  jmp   0118 0114  addl  $1, -12(%rbp) 0118  jmp   0118 0100  andl  $1, %eax 0104 0108  jne   0130 010c  addl  $1, -12(%rbp) 0110 0114  testl %eax, %eax 0118  addl  $1, -8(%rbp) 011c 0120  movl  -12(%rbp), %eax 0124 ... 0128 Sequential arrangement  on memory  Randomizing 0128 0108 011c 0110 0120 0104 0104 0118 010c 011c 0100 0110 Address Mapping Direct or indirect execution by hardware or instruction level emulator  ...  ... ... Fig. 2. Performance of implementing instruction level randomization using an
instruction level machine emulator. Y-axis shows the amount of performance
decrease against native execution on bare metal. The execution time increases
by over hundred of times.
instruction level emulator, applications suffer from the hun-
dreds of times slower than native executions on the bare metal
CPU hardware. Although a certain optimization technique can
be applied to improve performance of emulation based ILR
approaches, the emulation layer without hardware support is
bound to incur signiﬁcant performance penalty. It should be
pointed out that some software based implementation reduces
the overheads by supporting ILR with limited scope. It will
be not fair if one compares more efﬁcient micro-architecture
based approach with these schemes because they don’t support
complete randomization and de-randomization of instruction
space at per instruction execution level. Our apples-to-apples
comparison shows that, since randomized binary cannot be
executed natively, a run-time interpreter that de-randomizes the
instruction space at per instruction level will certainly incur
much higher overhead and signiﬁcantly reduce instruction
fetch efﬁciency. For the studied benchmark applications, ILR
can increase instruction L1 cache miss rate by more than ﬁve
times on average.
A. Randomization vs. Efﬁcient Instruction Fetch
One possible approach is to integrate the capability for
direct execution of ILR randomized programs with native
micro-architecture support. A simple implementation is to
remove the runtime emulation layer and push its functionality
into the processor. However, our in-depth studies reveal that
such solution has major performance issues with the design
principles of modern micro-processor. When compared with
the baseline architecture with identical cache organizations, a
naive implementation of ILR increases the L1 instruction cache
miss rates on average by 9.4 times for 11 applications from
SPEC CPU2006 benchmark suite, see Figure 3. In addition,
instruction level address space randomization signiﬁcantly im-
pedes the efﬁciency of hardware based instruction pre-fetcher
as shown by the results in Figure 3. The pre-fetch miss
rates of L1 instruction cache (IL1) increase by on average
28% for the tested SPEC CPU2006 benchmarks. The reduced
L1 cache efﬁciency is propagated to the next level cache by
adding workload pressures. As shown in the ﬁgure, the uniﬁed
L2 cache experience 36% of average increased loads for the
tested SPEC CPU2006 applications; the amount of pressure is
measured by the number of read operation from L1 cache to
L2 cache.
Combining all the effects, the overall CPU performance
decreases dramatically. The average IPC reduces to 61% of
the baseline IPC with identical architecture settings, as shown
in Figure 4. The naive implementation assumes that CPU
can resolve address mapping with zero cost. Therefore, the
performance penalty is entirely due to the randomization of
instruction space.
Fig. 3. The impact of naive approach on the L1 and L2 cache. In this mode,
a processor directly executes a binary program with randomized layout. The
program is randomized using the complete ILR approach which is described in
Hiser et al.’s work [9]. CPU setting: 32KB IL1 and 512KB L2, XIOSim [16]
and Zesto [17].
Fig. 4.
Performance of straightforward implementation of ILR at micro-