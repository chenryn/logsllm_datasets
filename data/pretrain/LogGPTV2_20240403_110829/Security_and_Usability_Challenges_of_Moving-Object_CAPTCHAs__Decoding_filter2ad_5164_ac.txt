is non-trivial to do so without masking out too much of
the other characters. We solve this problem as follows.
In order to block a character, we try to match it with
templates of each character that can be gained by learn-
ing. One way to do that is to match scale-invariant fea-
ture transforms (SIFT) between the patch and a reference
template. While SIFT features can deal with scaling, ro-
tation and translation of characters, there are times when
some frames have insufﬁcient SIFT features. Our solu-
tion is to ﬁnd a frame with enough features to apply SIFT,
and then warp the template to mask the target character
in that frame. Once found, this frame is used as the ini-
tial position in an incremental alignment approach based
on KLT tracking. Essentially, we combine the beneﬁts
of SIFT and KLT to provide a video sequence where the
character we are most conﬁdent about is omitted. At that
point, we rerun our attack, but with one fewer character.
This process is repeated until we have no characters left
to decode. This process is illustrated in Figure 9.
Runtime: Our implementation is based on a collection
of modules written in a mix of C++ and Matlab code.
We make extensive use of the Open Source Computer
Vision library (OpenCV). Our un-optimized code takes
approximately 30s to decode the three characters in a
MIOR captcha when the feedback loop optimization (in
stage ) is disabled. With feedback enabled, processing
time increases to 250s. The bottleneck is in the incre-
mental alignment procedure (written in Matlab).
5 Evaluation
We now discuss the results of experiments we performed
on MIOR captchas. Speciﬁcally, the ﬁrst set of experi-
ments are based on video sequences downloaded off the
demo page of NuCaptcha’s website. On each visit to the
demo page, a captcha with a random 3-character code-
word is displayed for 6 seconds before the video loops.
The displayed captchas were saved locally using a Fire-
fox plugin called NetVideoHunter. We downloaded 4500
captchas during November and December of 2011.
The collected videos contain captchas with all 19
backgrounds in use by NuCaptcha as of December 2011.
In each of these videos, the backgrounds are of moving
scenes (e.g., waves on a beach, kids playing baseball,
etc.) and the text in the foreground either moves across
the ﬁeld of view or in-place. We painstakingly labeled
each of the videos by hand to obtain the ground truth.
We note that while NuCaptcha provides an API for ob-
taining captchas, we opted not to use that service as we
did not want to interfere with their service in any way. In
addition, our second set of experiments examine several
countermeasures against our attacks, and so for ethical
reasons, we opted to perform such experiments in a con-
trolled manner rather than with any in-the-wild experi-
mentation. These countermeasures are also evaluated in
our user study (§6).
5.1 Results
The naïve attack was analyzed on 4000 captchas. Due
to time constraints, the extended attack (with and with-
out the feedback optimization) were each analyzed on a
random sample of 500 captchas. To determine an appro-
priate training set size, we varied the number of videos as
well as the number of extracted frames and examined the
recognition rate. The results (not shown) show that while
accuracy steadily increased with more training videos
(e.g., 50 versus 100 videos), we only observed marginal
improvement when the number of training patches taken
from each video exceeded 1500. In the subsequent anal-
yses, we use 300 video sequences for training (i.e., 900
codeword characters) and for each detected character, we
select 2 frames containing that character (yielding 1800
training patches in total). We use dense SIFT descrip-
tors [44] as the features for each patch (i.e., a SIFT de-
scriptor is extracted for each pixel in the patch, and con-
catenated to form a feature vector). The feature vectors
are used to train the neural network. For testing, we
choose a different set of 200 captchas, almost evenly dis-
tributed among the 19 backgrounds. The accuracy of the
attacks (in §4) are given in Table 1.
The result indicate that the robustness of these MIOR
In par-
captchas are far weaker than one would hope.
ticular, our automated attacks can completely decode the
captchas more than three quarters of the time. In fact,
our success rates are even higher than some of the OCR-
based attacks on CR-still captchas [7, 19, 32, 47]. There
are, however, some obvious countermeasures that de-
signers of MIOR captchas might employ.
5.2 Mitigation
To highlight some of the tensions that exists between
the security and usability of MIOR captchas, we explore
a series of possible mitigations to our attacks.
In or-
der to do so, we generate video captchas that closely
mimic those from NuCaptcha.
In particular, we built
a framework for generating videos with characters that
move across a background scene with constant velocity
in the horizontal direction, and move up and down har-
monically. Similar to NuCaptcha, the characters of the
codeword also rotate. Our framework is tunable, and all
the parameters are set to the defaults calculated from the
original videos from NuCaptcha (denoted Standard). We
refer the interested reader to Appendix A for more details
on how we set the parameters. Given this framework, we
explore the following defenses:
• Extended: the codeword consists of m > 3 random
characters moving across a dynamic scene.
• Overlapping: same as the Standard case (i.e., m =
3), except characters are more closely overlapped.
identical to the Standard case,
• Semi-Transparent:
except that the characters are semi-transparent.
• Emerging objects: a different MIOR captcha where
the codewords are 3 characters but created using an
“Emerging Images” [31] concept (see below).
Figure 10: Extended case. Top: scrolling; bottom: in-place.
Increasing the number of random characters shown in
the captcha would be a natural way to mitigate our attack.
Hence, the Extended characters case is meant to investi-
gate the point at which the success rate of our attacks fall
Attack
Strategy
Naïve
Enhanced (no feedback)
Enhanced (with feedback)
Single Character
Accuracy
68.5% (8216/12000)
90.0% (540/600)
90.3% (542/600)
3-Character
Accuracy
36.3% (1450/4000)
75.5% (151/200)
77.0% (154/200)
Table 1: Reconstruction accuracy for various attacks.
below a predeﬁned threshold. An example is shown in
Figure 10. Similarly, we initially thought that increas-
ing the overlap between consecutive characters (i.e., the
Overlapping defense, Fig. 11) might be a viable alterna-
tive. We estimate the degree that two characters overlap
by the ratio of the horizontal distance of their centers and
their average width. That is, suppose that one character
is 20 pixels wide, and the other is 30 pixels wide. If the
horizontal distance of their centers is 20, then their over-
lap ratio is computed as 20/ 20+30
2 = 0.8. The smaller
this overlap ratio, the more the characters overlap. A ra-
tio of 0.5 means that the middle character is completely
overlapped in the horizontal direction. In both the origi-
nal captchas from NuCaptcha and our Standard case, the
overlap ratio is 0.95 for any two adjacent characters.
Figure 11: Overlapping characters (with ratio = 0.49).
The Semi-Transparent defense is an attempt to break
the assumption that the foreground is of constant color.
In this case, foreground extraction (stage ) will be dif-
ﬁcult. To mimic this defense strategy, we adjust the
background-to-foreground pixel ratio. An example is
shown in ﬁgure 12.
Figure 12: Semi-transparent: 80% background to 20% fore-
ground pixel ratio. (Best viewed in color.)
The ﬁnal countermeasure is based on the notion of
Emerging Images proposed by Mitra et al. [31]. Emer-
gence refers to “the unique human ability to aggregate
information from seemingly meaningless pieces, and to
perceive a whole that is meaningful” [31].2 The con-
cept has been exploited in Computer Graphics to prevent
automated tracking by computers, while simultaneously
allowing for high recognition rates in humans because of
our remarkable visual system. We apply the concepts
outlined by Mitra et al. [31] to generate captchas that
are resilient to our attacks. The key differences between
our implementation and the original paper is that our in-
put is 2D characters instead of 3D objects, and we do
not have the luxury of incorporating shadow information.
Our Emerging captchas are constructed as follows:
Figure 13: Emerging captcha.
(a) Top: noisy background
frame. Middle: derivative of foreground image. Bottom: single
frame for an Emerging captcha. (b) Successive frames.
1. We build a noisy frame Ibg by creating an image
with each pixel following a Gaussian distribution.
We blur the image such that the value of each pixel
is related to nearby pixels. We also include time cor-
respondence by ﬁltering in the time domain. That is,
each frame is a mixture of a new noisy image and
the last frame.
2. We generate an image If g similar to that in Nu-
Captcha. We then ﬁnd the edges in the image by
calculating the norm of derivatives of the image.
3. We combine Ibg and If g by creating a new im-
age I where each pixel in I is deﬁned as I(x,y) :=
Ibg(x,y)∗ exp(
If g
const ), where exp(x) is the exponen-
tial function. In this way, the pixels near the bound-
ary of characters in I are made more noisy than
other pixels.
4. We deﬁne a constant threshold t < 0. All pixel val-
ues in I that are larger than t are made white. All
frame iframe i+1frame i+2creation of a frame(a)(b)the other pixels in I are made black.
The above procedure results in a series of frames
where no single frame contains the codeword in a way
that is easy to segment. The pixels near the boundaries
of the characters are also more likely to be blacker than
other pixels, which the human visual system somehow
uses to identify the structure from motion. This feat re-
mains challenging for computers since the points near the
boundaries change color randomly, making it difﬁcult, if
not impossible, to track, using existing techniques. An
illustration is shown in Figure 13. To the best of our
knowledge, we provide the ﬁrst concrete instantiation of
the notion of Emerging Images applied to captchas, as
well as a corresponding lab-based usability study (§6).
We refer interested readers to http://www.cs.
unc.edu/videocaptcha/ for examples of the mit-
igation strategies we explored.
5.2.1 Results
We now report on the results of running attacks on
captchas employing the aforementioned defenses. Fig-
ure 14 depicts the results for the Extended defense strat-
egy.
In these experiments, we generated 100 random
captchas for each m ∈ [3,23]. Our results clearly show
that simply increasing the codeword length is not neces-
sarily a viable defense. In fact, even at 23 characters, our
success rate is still 5%, on average.
Figure 14: Attack success as a function of codeword length.
Figure 15 shows the results for the Overlapping de-
fense strategy. As before, the results are averaged over
100 sequences per point. The graph shows that the suc-
cess rate drops steadily as the overlap ratio decreases (de-
noted as “sensitivity” level in that plot).
Interestingly,
NuCaptcha mentions that this defense strategy is in fact
one of the security features enabled by its behavioral
analysis engine. The images provided on their website
for the “very secure” mode, however, have an overlap ra-
tio of 0.78, which our attacks would still be able to break
more than 50% of the time.3 Our success rate is still rel-
atively high (at 5%) even when the overlap ratio is as low
as 0.49. Recall that, at that point, the middle character is
100% overlapped, and others are 51% overlapped.
Figure 15 also shows the results for
the Semi-
Transparent experiment.
In that case, we varied the
transparency of the foreground pixel from 100% down
to 20%. Even when the codewords are barely visible (to
the human eye), we are still able to break the captchas
5% of the time. An example of one such captcha (with a
background to foreground ratio of 80 to 20 percent) was
shown earlier in Figure 12.
Figure 15: Attack success rate against Overlapping and Semi-
Transparent defenses. Sensitivity refers to the overlap ratio
(circles) or the background-to-foreground ratio (squares).
Lastly, we generated 100 captchas based on our imple-
mentation of the Emerging Images concept. It comes as
no surprise that the attacks in this paper were not able to
decode a single one of these challenges — precisely be-
cause these captchas were speciﬁcally designed to make
optical ﬂow tracking and object segmentation difﬁcult.
From a security perspective, these MIOR captchas are
more robust than the other defenses we examined. We
return to that discussion in §7.
5.2.2 Discussion
The question remains, however, whether for any of the
defenses, parameters could be tuned to increase the ro-
bustness and still retain usablility. We explore precisely
that question next. That said, the forthcoming analysis
raises interesting questions, especially as it relates to the
robustness of captchas. In particular, there is presently
no consensus on the required adversarial effort a captcha
should present, or the security threshold in terms of suc-
cess rate that adversaries should be held below. For ex-
ample, Chellapilla et al. [8] state: “automated attacks
should not be more than 0.01% successful but the human
success rate should be at least 90%”. Others argue that
“if it is at least as expensive for an attacker to break the
challenge by machine than it would be to pay a human to
take the captcha, the test can be considered secure” [22].
Zhu et al. [53] use the metric that the bot success rate
should not exceed 0.6%.
In the course of our pilot studies, it became clear
that if the parameters for the Extended, Overlapping,
and Semi-Transparent countermeasures are set too strin-
gently (e.g., to defeat automated attacks 99% of the
time), then the resulting MIOR captchas would be ex-