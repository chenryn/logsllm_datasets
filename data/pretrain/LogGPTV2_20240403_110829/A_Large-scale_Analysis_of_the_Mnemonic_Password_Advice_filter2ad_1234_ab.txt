and ﬁltered such sentences by removing re-occurrences within
1 000 extracted sentences. Further excluding spam pages [8]
could not improve the method. We also tried the standard
Boilerpipe ArticleSentenceExtractor [24], but found that
it
performed worse in our tests.
The ﬁnal Webis-Sentences-17 corpus contains 3.4 billion
sentences. From these, we generate on average 1.4 billion
passwords of length 8 to 20 per generation rule. We chose
this range based on length limits in popular web pages [18].
Table IV gives a few examples from this corpus.
3www.uni-weimar.de/en/media/chairs/webis/corpora/webis-sentences-17
4Tested for the lowercase letter word initials password generation rule
5Source: github.com/webis-de/aitools4-aq-web-page-content-extraction
6Rendering by Jericho HTML: jericho.htmlparser.net v. 3.2
7Tokenization by ICU4J: site.icu-project.org/home v. 53.1
Figure 3.
Distribution and ﬁtted model of syllable counts per word for
the Webis-Mnemonics-17 corpus (top) and per sentence of length 12 in the
Webis-Sentences-17 corpus (bottom)
C. The Webis-Simple-Sentences-17 Corpus
As the Webis-Sentences-17 corpus intuitively contains
more complex sentences than can be expected for mnemonics,
we created the Webis-Simple-Sentences-17 sub-corpus with a
sentence complexity like in the Webis-Mnemonics-17 corpus.3
For measuring sentence complexity, we use the standard Flesch
reading ease test [11] (higher F means more readable):
F = 206.835 − 84.6 · #syllables
#words
− 1.015 ·
#sentences
#words
.
(1)
For the Webis-Simple-Sentences-17 corpus, we sample
sentences from the Webis-Sentences-17 corpus such that, for
each sentence length, the syllable distribution of the sampled
sentences matches the syllable distribution in the Webis-
Mnemonics-17 corpus. Since this requires only to compare
Flesch values for single sentences of the same length, Equa-
tion 1 essentially reduces to the number of syllables, where less
syllables correspond to simpler sentences. For the sampling
probabilities, we ﬁt negative binomial models—which are
usual for syllable counts of English sentences [17]—to the ob-
served syllable counts of the Webis-Mnemonics-17 and Webis-
Sentences-17 corpora.8 Figure 3 shows these models. When
sampling sentences, the appropriate sampling probability for
each sentence length and syllable count follows directly from
these models. Also, the Figure shows that the web sentences
are indeed signiﬁcantly more complex than human-chosen
mnemonics. Hence,
the Webis-Simple-Sentences-17 corpus
is more similar to mnemonics than the Webis-Sentences-17
corpus. The ﬁnal corpus consists of 0.5 billion sentences. From
these sentences, we generate on average 0.23 billion passwords
of length 8 to 20 per generation rule. Table V gives a few
examples from this corpus.
8As the negative binomial distribution is a discrete distribution, the model
for the Webis-Mnemonics-17 syllable counts is ﬁrst ﬁt to a transformed value
of (syllables-per-word − 1) · 100 and then transformed inversely
4
Density1.01.52.02.53.00.00.51.01.52.02.53.0Syllables per word, averaged by sentenceObserved distributionNegative binomial model0.000.050.100.150.200.25DensitySyllableslllllllllllllllllllllllll1218243036lllllllllllllllllllllllllllllllllllllllllllllllllllllObserved distributionNegative binomial modelModel from Webis−Mnemonics−17Table II.
CHARACTER-WISE CROSS ENTROPY ESTIMATES FOR
PASSWORDS FROM THE WEBIS-MNEMONICS-17 CORPUS OF LENGTH 12.
MODEL CORPORA: WEBIS-MNEMONICS-17 (WM),
WEBIS-SENTENCES-17 (WS), WEBIS-SIMPLE-SENTENCES-17 (WSS).
Character set Model corpus
ASCII
Lowercase
letters
WS
WSS
WM
WS
WSS
WM
Model order
4
3
2
1
0
5
4.95 4.64 4.58 4.56 4.62 4.75
4.94 4.63 4.56 4.55 4.62 4.76
4.59 4.51
4.54 4.55 4.55 4.55
4.17 4.11 4.08 4.06 4.07 4.14
4.16 4.09 4.06 4.04 4.06 4.14
4.14 4.10 4.18 4.20 4.20 4.20
Table III.
EXAMPLE SENTENCES DRAWN RANDOMLY FROM THE
WEBIS-MNEMONICS-17 CORPUS FOR EACH OF THE TOPIC SUGGESTIONS
FROM THE USER STUDY (CF. SECTION III-C).
the password that I use.
No suggestion
• What was the color of your car when you were twenty years old?
• The order of my favorite colors followed by my cousin’s pets is
• The ﬁve green ships docked at the west yellow arrow pointing
• i have an upside down kayak that ﬂoats on air without wings
• Three birds are sitting on a hibiscus tree driving their cars fast
• my very eager mother just served us pickles, never eat shredded
• My parents are driving here from Michigan to visit for a week.
south.
wheat
D. Web Sentence and Mnemonic Similarity
We will now argue why password strength estimates will
be approximately the same for passwords from mnemonics
and from web sentences. (a) Strength estimates for password
distributions depend on the distribution of password proba-
bilities and not on the literal passwords (cf. Section IV-C).
(b) Password probabilities can be estimated well from a sample
using language models, as successfully exploited for password
cracking [9], [27], [30], [34]. (c) Language models estimate
password probabilities using only the conditional probabilities
of the characters given their preceding characters [7].
Hence, given passwords from two different password sources
in which these conditional character probabilities follow ap-
proximately the same distributions, the password probabilities
of these two sources will also follow approximately the same
distribution (from b+c), and the strength estimates will there-
fore be approximately the same for both password sources
(from a). It is important to note that the above reasoning does
not require that both sources contain the same passwords.
Moreover, algorithmic successes suggest that these conditional
character probabilities from mnemonics and web sentences
follow approximately the same distributions: (1) Automatic
language identiﬁcation based on related conditional charac-
ter probabilities works robustly on short texts from various
sources [15]; (2) Human-chosen password phrases—a similar
setting to that of mnemonics—can be cracked using language
models from a few million web sentences [34].
In order to provide further evidence for the similarity,
we show that, while complete passwords from mnemonics
and web sentences are likely different, they are composed
from a very similar set of common substrings. This suggests
that the difference between mnemonics and web sentences is
more of a topical than a linguistic kind, and has therefore
not much impact on the strength estimates. To show that
both kind of sentences are composed from a very similar
set of common substrings, we compare the cross-entropy—
a standard similarity measure of distributions—of different
sentence corpora to the Webis-Mnemonics-17 corpus using
language models with speciﬁc model orders (cf. Section IV-A
for details). A model of order o only considers substrings up
to o + 1 characters. As Table II shows, the cross entropy from
the web sentences corpora to the mnemonic corpus gets about
as low as the cross entropy between different subsets of the
mnemonic corpus. Therefore, the substrings up to length 4 or 5
in passwords from the web sentences corpora are very similar
to those in human-chosen mnemonics.
5
vault.
that also pray
Your sentence should be related to mail
• beautiful mails require a touch of golden heart and brave minds
• Savings under the ﬂoorboards are safer than inside a big bank
• Boy, you must be Fedex because you look like a hot mail.
• Is it all junk today, or is there anything worthwhile for a change?
• I like talking with my friends about current events and things that
• i can remember very well what i try to keep as a secret
• I pick up the mail at noon from the mailbox in the lobby of the
• I want to become a successful teacher as well as a lovable mother
will happen in the near time coming.
building
up in shinny paper.
Your sentence should be related to shopping
• While shopping i usually purchase meaningless items that i wrap
• when I don’t have money I want it, if I have money I want more.
• the cat liked to shop for cookies and bananas at the store in france
• I go shopping in the spring only when it’s raining in Paris.
• There is a little girl shopping for a blue dress for her sister.
• When I go shopping, I always buy at least two bunches of bananas.
• Warehouse savings can multiply with money deposited into my
• My three sons bought the faith of the king with a robe.
account every day.
day he died.
Your sentence should be related to money
• Cash is king of the hill and worth every penny and cent.
• The crisp green bill did not leave the frugal boy’s pocket until the
• The community i was born and raised in until I turned legal age.
• I like to bathe in a vat of crisp tens and twenties.
• Just like my inventory in Dragon Age Origins I am hella loaded
• My wife and I are often worried we will have enough money.
• She will get a new apron on her 3rd birthday next year.
• i have huge amount of money and have kept all of my money in
savings banks
proper hygine.
Your sentence should be related to talking with friends
• How do you know that carrots are good for the eye sight?
• I told my friend a secret and told her not to tell anyone
• Hey tell me what friends usually talk when they meet or call?
• it is important to wash your hands through out the day to keep
• I like chat with friends because they are so funny and I am happy
• My dear friend how are you and do you know the secret about
• Talking to friends can be fun and sometimes we learn new things.
• My friends make me feel conﬁdent about myself and my work
our teacher mallika
I have them.
skills
Table IV.
EXAMPLE SENTENCES DRAWN RANDOMLY FROM THE
WEBIS-SENTENCES-17 CORPUS (CF. SECTION III-B).
• There are also other retail outparcel developments on the other
side of the interchange as well as some industrial development
in the immediate area, so the center promises to have a strong
regional draw.
• The ADA recommends that the costs associated with postexposure
prophylaxis and exposure sequelae be a beneﬁt of Workers’
Compensation insurance coverage.
• Your agents will come away with the knowledge of how service
level and quality go hand-in-hand and how that affects the entire
contact center.
• This distance, the ’local loop’, helps determine which of the
providers in Manhattan will be the best options to provide service
to your location.
• The arena act was the product of gate keeping & was only ever
• And when it comes to painting, throw out your color charts
because rural Pennsylvanians use an array of hues not found in
nature or in any hardware stores looking to remain on the right
side of the Better Business Bureau.
• Nominations are called for Vice-president and two Director posi-
tions on the Board of Directors of ALIA, as incorporated under
Corporations Law.
• The lack of initiative in this case seemed puzzling due to nearly
all Americans’ faith at the time in the strength and reliability of
the constitutional machinery of due process.
important from a commercial standpoint.
• It will be better for you if you renounce meat & masalas.
IV. PASSWORD STRENGTH ESTIMATION
Password strength is measured on the password distribu-
tion, which is unknown for mnemonic passwords but which
can be estimated from huge password samples using lan-
guage models. Language models are detailed in general in
Section IV-A and optimized for mnemonic passwords in Sec-
tion IV-B. After this, Section IV-C details the common strength
measures we use in our analysis.
For a formal discussion, this section uses the following
notations. X is a random variable distributed over a set of
n passwords {x1, . . . , xn} according to the password distribu-
tion X . We use pi = Pr[X = xi] to denote the probability that
a password X drawn from X is equal to xi. We enumerate
passwords in descending order of their associated probability
i ··· x(cid:96)i
in X , that means p1 ≥ . . . ≥ pn. Furthermore, x1
i
denotes the (cid:96)i characters of password xi and X j denotes the
random variable of the j-th character of a password. Finally,
L denotes a random variable distributed according to the
password lengths in X .
A. Language Models
Even password corpora several orders of magnitude larger
than the Webis-Sentences-17 corpus would not sufﬁce to cal-
culate reliable maximum-likelihood estimates for the probabil-
ities of very rare passwords. The maximum-likelihood estimate
of a password probability is the number of its occurrences di-
vided by the size of the entire password sample. However, even
in the Webis-Sentences-17 corpus, the often-used Good-Turing
method9 [12] estimates that about 75% of the probability mass
9The estimate is calculated as the number of passwords occurring only once
divided by the number of different passwords in the corpus
6
Table V.
EXAMPLE SENTENCES DRAWN RANDOMLY FROM THE
WEBIS-SIMPLE-SENTENCES-17 CORPUS (CF. SECTION III-C).
ﬁnished with it.
received the item.
happens with all saves.
in most but not all benchmarks.
school, college and graduate studies.
you can drop the kids off there while you work out.
• Please do not ask to return an item after 7 days of when you
• This guide has a lot of nuggets, and I could only stop when I was
• She acted as a student leader during her primary school, high
• As mentioned, some gyms also have a daycare program so that
• How much you lose depends on the compression level, but it
• So far it looks to top the current king of the hill (Radeon 4870X2)
• Your dog will be well behaved and all your friends will want to
• And if that is what we want, then talking about "attraction" and
• The ramps vary in size and height and you will want to look
• That’s blatant right there, you should have seen how wroth Bela
• Some of the more commonly known herbs to avoid during
• Additional cost and energy savings are realized by reducing or
eliminating the need for hot water, detergent, labor costs, and
capital costs.
around to ﬁnd the best one for your ATV needs.
"bonding" is a good place to begin.
• You can structure it and then restructure it as per your needs.
Karolyi was about that.
know how you did it.
pregnancy include:
corresponds to passwords that occur not a single time in the
corpus. Therefore, using the maximum-likelihood estimate for
each password is unsuitable.
The most widespread language models for passwords, often
referred to as Markov chains or n-gram models, employ the
chain-rule of probability to describe a password probability by
its length and character probabilities.10 Let the probability of
password xi be
pi = Pr[L = (cid:96)i] · (cid:96)i(cid:89)
(cid:104)
pi,j = Pr
X j = xj
i
pi,j , where
(cid:12)(cid:12)(cid:12)X 1 ··· X j−1 = x1 ··· xj−1
j=1
i
, L = (cid:96)i
(cid:105)
.
(2)
i
xj−o
··· xt
i = xt−o
Instead of the exact probabilities in Equation 2, language
models approximate the character probabilities by conditioning
on only the o preceding characters [7], and thus require much
less passwords. Therefore, they reduce the model complexity
by assuming that
··· xj
(3)
which leads to robust models used successfully in various
natural language tasks [7]. Applying Equation 3 to Equation 2,
pi,j ≈ Pr
where a special start-of-password symbol is used to cope with
characters preceding x1
i :
(cid:12)(cid:12)(cid:12)X j−o···X j−1 = xj−o
Pr(cid:2)X j = start-of-password symbol(cid:3) =
k → pi,j = pk,t ,
(cid:26) 1
··· xj−1
X j = xj
i
, L = (cid:96)i
(cid:104)
(cid:105)
k
,
i
i
if j ≤ 0
if j > 0
0
10An alternative method introduces an end-of-password symbol
is
treated like a normal character by the language model [7]. However, the effect
of this choice is usually negligible [27].
that
Figure 4. Effect of the sample size and model order in model training on estimated cross entropy for passwords of length 12 using the ASCII (triangles) and
lowercase letters (circles) character sets. The left and center plots show the effect of the sample size for different model settings and optimal order. The right
plot shows the effect of the model order for the selected sample size.
B. Empirical Language Model Optimization
Language models have several parameter, which are com-
monly optimized for a given task using the cross entropy on