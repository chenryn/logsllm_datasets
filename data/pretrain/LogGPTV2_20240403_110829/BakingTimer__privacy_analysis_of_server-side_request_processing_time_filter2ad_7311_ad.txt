are maintained in the browser. In this two specific cases, we first
classified the websites following the same three-state schema as
in previous cases. Then, we logged out of the service and checked
if this state would be classified as logged or accessed. Our results
show that in both cases, the comparison phases classified this state
as logged. This indicates that even if the user logged out, if the
websites does not correctly delete all related cookies, it would be
possible to detect a previous logged state.
7 DISCUSSION
Even if a user trusts all the websites she visits, many websites
include a large number of third-party services and resources to
improve their usage or to monetize their traffic. All these scripts
loaded on the website, including simple advertisement banners, can
track users and perform many different attacks, including the one
we presented in this paper.
7.1 Result Interpretation
In order to obtain the most reliable results, it is important to per-
form the experiments against multiple real-world websites. In fact,
synthetic websites or small sample sets may not correctly capture
all the implementation patterns encountered in the wild. Our tests
show that more than half of the websites we analyzed are vulnera-
ble to our attack. This means two important things. First, that there
is a measurable, statistically significant difference between the time
the server spend processing the two classes of requests (with, and
without the access cookies). Second, that either the website does
not set cookies on cross-origin requests, or that those cookies are
different from the one created on a regular access.
7.2 Comparison with Similar Techniques
Table 2 shows the different state-of-the-art timing methods and
their different characteristics, both in terms of adopted technique
and on the type and size of the experiments performed to validate.
The majority of previous works allowed an attacker to detect the
login status of a victim in other websites. Only one [16], apart form
ours, allows also to detect the access state (but this same technique
is unable to detect the login status). The only technique able to
detect both access and login state is the one presented in this paper.
Most of existing attacks, including our own, do not rely on any
other browser resource than the cookies. This makes the technique
resilient to generic browsing history cleaning processes, as browsers
explicitly discourages user to delete cookies in their settings (see
Section 2). Two techniques are instead based on different types of
browser caching that, on the contrary of cookies, are even deleted
by default, and therefore users can easily and without any major
consequence delete them when needed.
Regarding the number of websites analyzed, as nearly all the
techniques are only able to detect the login status, the manual
effort needed to perform a big scale analysis made large scale exper-
iments unfeasible. We also presented a similar set of experiments
in Section 6, but we also performed an automatic analysis of over
10k websites divided in different categories to provide a general
overview of how effective this attack can be in the wild.
7.3 Countermeasures
There are two possible timing countermeasures that could be im-
plemented to avoid different types of server-side attacks such as
the one presented in this paper [32, 37]. One consists in including
a random delay in the response time of the servers. However, this
would just increase the noise and a larger number of comparisons
may compensate for small random changes in the processing time.
The other method would be to change the web application to have
fixed response times for sensitive requests. On top of being very
difficult to be properly implemented, this solution would also have
a large performance impact — considerably reducing the number of
requests per second a web site can sustain. Moreover, as the fixed
time would need to be exactly the same for all the sensitive request,
they should be as slow as the slowest response the server can make.
For all these reasons, we believe none of these mitigations are
practical and feasible to implement in a real-world deployment. Like
other time-based network fingerprinting solutions, BakingTimer
is therefore very difficult to mitigate.
ACSAC ’19, December 9–13, 2019, San Juan, PR, USA
Iskander Sanchez-Rola, Davide Balzarotti, and Igor Santos
Another possible solution to the problem, would be related to
the creation of the cookies themselves. Some browsers are going to
start supporting the SameSite attribute [20, 31], thanks to which,
websites can specifically indicate that they do not want a cookie
to be send in third-party requests. This option is a very interesting
approach, and can stop attacks similar to ours. However, in order
to completely protect from the technique presented in this paper,
all cookies must set this attribute. As long as one of the cookies
involved does not indicate it, the attack would still work. On the
other hand, these changes could impact the state detection of the
attack differently. For instance, due to the sensitive nature of login
cookies, they could be more prone to use this option. Nevertheless,
its important to remark that some sites could lose part of their core
functionalities as a result of using SameSite cookies. Many types
of websites, such as social networks or cashback services, rely on
cookies to be added in third-party requests, in consequence, its
global applicability could be limited in some situations.
Two recent studies show that these attacks are far from being
solved. Van Goethem et al. [44] proposed new timing techniques
based on estimating the size of cross-origin resources. Since the
measurement starts after the resources are downloaded, it does not
suffer from unfavorable network conditions. The study also shows
that these attacks could be used in various platforms, increasing
the attack surface and the number of potential victims. The specific
size of the resource can leak the current state of the user in the
website. Lee et al. [28] demonstrated that using HTML5’s AppCache
functionality (to enable offline access), an attacker can correctly
identify the status of a target URL. This information can later be
used to check if a user is logged or not in certain website.
However, these timing techniques can generally only determine
if the user is logged on a specific website or some isolated data,
but not if she has just previously accessed it. Moreover, some of
them use resources easily cleanable by the user, like different cache
options, as they do not imply any visible consequence to the user.
8 RELATED WORK
History sniffing attacks are a widely explored topic with differ-
ent techniques and solutions presented over the years. Clover [12]
found that it was possible to identify previously visited websites
just checking the CSS:visited style of a specially crafted link
though the getComputedStyle method in JavaScript. Many other
similar attacks appeared using different CSS-based techniques [22,
23, 40, 46]. Kotcher et al. [25] discovered that besides from the above
mentioned attacks, the usage of CSS filters allows the involuntary
revelation of sensitive data, such as text tokens, exploiting time
differences to render various DOM trees. Weinber et al. [45] fol-
lowed another direction, using interactive techniques to get the
information. While these attacks are much slower, the protection
methods are in principle more difficult to implement.
With a different approach, and leaving CSS aside, Felten and
Schneider [16] introduced web timing attacks as a tool to compro-
mise users private data and, specifically, their web-browsing history.
Particularly, they proposed a method based on leveraging the dif-
ferent forms of web browser cache to obtain user specific browsing
information. By measuring the time needed to access certain data
from a third-party website, the attacker could determine if that
specific data was cached or not, indicating a previous access. Some
years later, Jia et al. [24] analyzed the possibility of identifying
the geo-location of a given visitor using to the customization of
services performed by websites. As this location-sensitive content
is also cached, it is possible to determine the location by checking
this concrete data and without relying in any other technique.
Bortz et al. [7] organized JavaScript web timing attacks in two
different types of attacks: (i) direct timing, based on measuring
the difference in time of diverse HTTP requests and (ii) cross-site
timing, that allows to retrieve private client-side data. The first type
could expose data that may be used to prove the validity of specific
user information in certain secure website, such as the username.
The second attack type follows the same line of previous work by
Felten and Schneider. They also performed some experiments that
suggested that these timing vulnerabilities were more common
than initially expected.
9 CONCLUSIONS
Many different threats against the users security and privacy can
benefit from a list of websites previously accessed by the user and
a list of services where the user is logged in or ever logged in.
In this paper, we show that simply using cookies of third-party
websites, is possible the detect the specific state (e.g., accessed and
logged) of a user in certain website, which outperforms previous
techniques that are only able to detect one single state. In particular,
we present a novel timing side-channel attack against server-side
request processing schema. This technique is capable of detect-
ing execution paths with more than 5 milliseconds of difference
between each other.
We also analyzed real-world servers to detect the percentage
of websites vulnerable to the presented attack. All previous work
analyzed less than 10 websites (manually), as they generally only
detect the logged status. We performed this same analysis, and
additionally, we performed an automated check of 10k websites
from different categories and number of users. Results show that
more than half of the websites are vulnerable to our technique.
ACKNOWLEDGMENTS
This work is partially supported by the Basque Government under
a pre-doctoral grant given to Iskander Sanchez-Rola.
REFERENCES
[1] Acar, G., Juarez, M., Nikiforakis, N., Diaz, C., Gürses, S., Piessens, F., and
Preneel, B. FPDetective: dusting the web for fingerprinters. In Proceedings of
the ACM SIGSAC Conference on Computer and Communications Security (CCS)
(2013).
[2] Akkus, I. E., Chen, R., Hardt, M., Francis, P., and Gehrke, J. Non-tracking
web analytics. In Proceedings of the ACM SIGSAC Conference on Computer and
Communications Security (CSS) (2012).
[3] Amazon Web Services. Alexa top sites. https://aws.amazon.com/es/alexa-
top-sites/, 2018.
[4] Backes, M., Kate, A., Maffei, M., and Pecina, K. Obliviad: Provably secure and
practical online behavioral advertising. In Proceedings of the IEEE Symposium on
Security and Privacy (Oakland) (2012).
[5] Bilenko, M., Richardson, M., and Tsai, J. Targeted, not tracked: Client-side
solutions for privacy-friendly behavioral advertising. In Proceedings of the Privacy
Enhancing Technologies (PETS) (2011).
[6] Blocksi. Web content filtering. http://www.blocksi.net/, 2018.
BakingTimer: Privacy Analysis of Server-Side Request Processing Time
ACSAC ’19, December 9–13, 2019, San Juan, PR, USA
[7] Bortz, A., and Boneh, D. Exposing private information by timing web applica-
tions. In Proceedings of the International conference on World Wide Web (WWW)
(2007).
[8] Cao, Y., Li, S., and Wijmans, E.
(Cross-)browser fingerprinting via os and
hardware level features. In Proceedings of the Network and Distributed System
Symposium (NDSS) (2017).
[9] ChromeDevTools.
DevTools Protocol API.
ChromeDevTools/debugger-protocol-viewer, 2019.
https://github.com/
[10] Cisco Adaptive Security Appliance. CVE-2019-1713. https://cve.mitre.
org/cgi-bin/cvename.cgi?name=CVE-2019-1713, 2019.
[11] Cloudacl. Web security service. http://www.cloudacl.com/, 2018.
[12] Clover, A. Css visited pages disclosure. BUGTRAQ mailing list posting (2002).
[13] Englehardt, S., and Narayanan, A. Online tracking: A 1-million-site measure-
ment and analysis. In Proceedings of the ACM SIGSAC Conference on Computer
and Communications Security (CCS) (2016).
[14] Directive 2009/136/EC of the European Parliament and of the Council of 25
November 2009. Official Journal of the European Union (2009).
[15] Regulation (EU) 2016/679 of the European Parliament and of the Council of 27
April 2016 on the protection of natural persons with regard to the processing of
personal data and on the free movement of such data, and repealing Directive
95/46/EC (General Data Protection Regulation). Official Journal of the European
Union (2016).
[16] Felten, E. W., and Schneider, M. A. Timing attacks on web privacy.
In
Proceedings of the ACM SIGSAC Conference on Computer and Communications
Security (CCS) (2000).
[17] Fortinet. Fortiguard web filtering. http://www.fortiguard.com/, 2018.
[18] Fredrikson, M., and Livshits, B. Repriv: Re-imagining content personalization
and in-browser privacy. In Proceedings of the IEEE Symposium on Security and
Privacy (Oakland) (2011).
[19] Google. Leak of visited status of page in blink. https://chromereleases.
googleblog.com/2018/05/stable-channel-update-for-desktop_58.
html, 2018.
[20] Google. Improving privacy and security on the web. https://blog.chromium.
org/2019/05/improving-privacy-and-security-on-web.html, 2019.
[21] Guha, S., Cheng, B., and Francis, P. Privad: practical privacy in online adver-
tising. In Proceedings of the USENIX conference on Networked Systems Design and
Implementation (NDSI) (2011).
[22] Heiderich, M., Niemietz, M., Schuster, F., Holz, T., and Schwenk, J. Scriptless
attacks: stealing the pie without touching the sill. In Proceedings of the ACM
SIGSAC Conference on Computer and Communications Security (CSS) (2012).
[23] Janc, A., and Olejnik, L. Web browser history detection as a real-world privacy
threat. In Proceedings of the European Symposium on Research in Computer Security
(ESORICS) (2010).
[24] Jia, Y., Dong, X., Liang, Z., and Saxena, P. I know where you’ve been: Geo-
inference attacks via the browser cache. IEEE Internet Computing 19 (2015).
[25] Kotcher, R., Pei, Y., Jumde, P., and Jackson, C. Cross-origin pixel stealing:
timing attacks using css filters. In Proceedings of the ACM SIGSAC Conference on
Computer and Communications Security (CCS) (2013).
[26] Laperdrix, P., Rudametkin, W., and Baudry, B. Beauty and the beast: Diverting
modern web browsers to build unique browser fingerprints. In Proceedings of the
IEEE Symposium on Security and Privacy (Oakland) (2016).
[27] Lapowsky, I. California unanimously passes historic privacy bill. Wired, 06 2018.
timing/, 2018.
[28] Lee, S., Kim, H., and Kim, J. Identifying cross-origin resource status using appli-
cation cache. In Proceedings of the Network and Distributed System Symposium
(NDSS) (2015).
[29] Mowery, K., and Shacham, H. Pixel perfect: Fingerprinting canvas in HTML5.
In Proceedings of the Web 2.0 Workshop on Security and Privacy (W2SP) (2012).
[30] Mozilla. Privacy and the :visited selector. https://developer.mozilla.org/
en-US/docs/Web/CSS/Privacy_and_the_:visited_selector, 2018.
[31] Mozilla. Supporting same-site cookies in firefox 60. https://blog.mozilla.
org/security/2018/04/24/same-site-cookies-in-firefox-60/, 2019.
[32] Nagami, Y., Miyamoto, D., Hazeyama, H., and Kadobayashi, Y. An independent
evaluation of web timing attack and its countermeasure. In Proceedings of the
International Conference on Availability, Reliability and Security (ARES) (2008),
IEEE, pp. 1319–1324.
[33] Nikiforakis, N., Kapravelos, A., Joosen, W., Kruegel, C., Piessens, F., and
Vigna, G. Cookieless monster: Exploring the ecosystem of web-based device fin-
gerprinting. In Proceedings of IEEE Symposium on Security and Privacy (Oakland)
(2013).
[34] phpMyAdmin. CVE-2019-12616. http://cve.mitre.org/cgi-bin/cvename.
cgi?name=CVE-2019-12616, 2019.
[35] Sanchez-Rola, I., and Santos, I. Knockin’ on trackers’ door: Large-scale au-
tomatic analysis of web tracking. In Proceedings of the International Conference
on Detection of Intrusions and Malware, and Vulnerability Assessment (DIMVA)
(2018).
[36] Sanchez-Rola, I., Santos, I., and Balzarotti, D. Clock Around the Clock:
Time-Based Device Fingerprinting. In Proceedings of the ACM SIGSAC Conference
on Computer and Communications Security (CCS) (2018).
[37] Schinzel, S. An efficient mitigation method for timing side channels on the
web. In Proceedings of the International Workshop on Constructive Side-Channel
Analysis and Secure Design (COSADE) (2011).
[38] Schwartz, J. Giving the web a memory cost its users privacy. http://www.
nytimes.com/2001/09/04/technology/04COOK.html, 2001.
say “don’t
track? advertisers
Do not
[39] Singer, N.
tread on us”.
http://www.nytimes.com/2012/10/14/technology/do-not-track-
movement-is-drawing-advertisers-fire.html, 2012.
[40] Smith, M., Disselkoen, C., Narayan, S., Brown, F., and Stefan, D. Browser his-
tory re: visited. In Proceedings of the USENIX Workshop on Offensive Technologies
(WOOT) (2018).
[41] Sutton, M. A wolf in sheep’s clothing, the dangers of persistent web browser
storage. Black Hat DC Briefings (BHDC) (2009).
[42] Swartz, A. Web.py web framework. http://webpy.org/, 2018.
[43] Toubiana, V., Narayanan, A., Boneh, D., Nissenbaum, H., and Barocas, S.
Adnostic: Privacy preserving targeted advertising. In Proceedings of the Network
and Distributed System Symposium (NDSS) (2010).
[44] Van Goethem, T., Joosen, W., and Nikiforakis, N. The clock is still ticking:
Timing attacks in the modern web. In Proceedings of the ACM SIGSAC Conference
on Computer and Communications Security (CCS) (2015).
[45] Weinber, Z., Chen, E., Jayaraman, P., and Jackson, C. I still know what you
visited last summer. In Proceedings of the IEEE Symposium on Security and Privacy
(Oakland) (2011).
[46] Wondracek, G., Holz, T., Kirda, E., and Kruegel, C. A practical attack to
de-anonymize social network users. In Proceedings of the IEEE Symposium on
Security and Privacy (Oakland) (2010).
[47] World Wide Web Consortium. User timing. https://www.w3.org/TR/user-