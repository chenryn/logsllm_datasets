### 4. Experimental Results

In our experiments, we first classified the websites using the same three-state schema as in previous cases. After logging out of the service, we checked whether this state would be classified as "logged" or "accessed." Our results show that in both cases, the comparison phases classified the state as "logged." This indicates that even if a user logs out, if the website does not correctly delete all related cookies, it is possible to detect a previous logged-in state.

### 7. Discussion

Even if a user trusts all the websites they visit, many websites include a large number of third-party services and resources to improve functionality or monetize traffic. These scripts, including simple advertisement banners, can track users and perform various attacks, such as the one described in this paper.

#### 7.1 Result Interpretation

To obtain the most reliable results, it is crucial to conduct experiments on multiple real-world websites. Synthetic websites or small sample sets may not accurately capture all the implementation patterns encountered in the wild. Our tests show that more than half of the analyzed websites are vulnerable to our attack. This implies two key points: First, there is a statistically significant difference in the time the server spends processing requests with and without access cookies. Second, either the website does not set cookies on cross-origin requests, or those cookies differ from the ones created during a regular access.

#### 7.2 Comparison with Similar Techniques

Table 2 summarizes the different state-of-the-art timing methods and their characteristics, both in terms of the adopted technique and the type and scale of experiments performed for validation. Most previous works allowed attackers to detect the login status of a victim on other websites. Only one [16], besides ours, can also detect the access state (though it cannot detect the login status). The only technique capable of detecting both access and login states is the one presented in this paper.

Most existing attacks, including ours, do not rely on any browser resource other than cookies. This makes the technique resilient to generic browsing history cleaning processes, as browsers explicitly discourage users from deleting cookies in their settings (see Section 2). Two techniques, however, are based on different types of browser caching, which are typically deleted by default, making them easier for users to remove without significant consequences.

Regarding the number of websites analyzed, since most techniques can only detect the login status, the manual effort required for large-scale analysis has made extensive experiments unfeasible. In Section 6, we presented a similar set of experiments, but we also performed an automatic analysis of over 10,000 websites across different categories to provide a general overview of the attack's effectiveness in the wild.

#### 7.3 Countermeasures

There are two potential timing countermeasures that could be implemented to prevent server-side attacks like the one presented in this paper [32, 37]. One involves introducing a random delay in the server's response time. However, this would merely increase the noise, and a larger number of comparisons might compensate for small random changes in processing time. The other method is to modify the web application to have fixed response times for sensitive requests. While this solution is very difficult to implement properly, it would also significantly reduce the number of requests per second a website can handle. Moreover, the fixed time must be the same for all sensitive requests, making them as slow as the slowest response the server can generate.

For these reasons, we believe neither of these mitigations is practical or feasible for real-world deployment. Like other time-based network fingerprinting solutions, BakingTimer is very difficult to mitigate.

Another possible solution is related to the creation of cookies themselves. Some browsers are starting to support the SameSite attribute [20, 31], which allows websites to specify that cookies should not be sent in third-party requests. This approach is promising and can stop attacks similar to ours. However, to fully protect against the technique presented in this paper, all cookies must set this attribute. If even one cookie involved does not use this option, the attack would still work. Additionally, these changes could impact the state detection of the attack differently. For instance, due to the sensitive nature of login cookies, they might be more likely to use this option. However, some sites could lose core functionalities as a result of using SameSite cookies. Many types of websites, such as social networks or cashback services, rely on cookies being included in third-party requests, limiting the global applicability of this solution in some situations.

Two recent studies highlight that these attacks are far from being solved. Van Goethem et al. [44] proposed new timing techniques based on estimating the size of cross-origin resources. Since the measurement starts after the resources are downloaded, it is not affected by unfavorable network conditions. The study also shows that these attacks can be used on various platforms, increasing the attack surface and the number of potential victims. The specific size of the resource can leak the current state of the user on the website. Lee et al. [28] demonstrated that using HTML5’s AppCache functionality (to enable offline access), an attacker can correctly identify the status of a target URL, which can later be used to check if a user is logged into a specific website.

However, these timing techniques generally can only determine if the user is logged into a specific website or has accessed some isolated data, but not if they have previously accessed it. Moreover, some of these techniques use resources that are easily cleanable by the user, such as different cache options, without any visible consequence.

### 8. Related Work

History sniffing attacks have been extensively studied, with various techniques and solutions presented over the years. Clover [12] found that it was possible to identify previously visited websites by checking the CSS:visited style of a specially crafted link through the getComputedStyle method in JavaScript. Many other similar attacks have used different CSS-based techniques [22, 23, 40, 46]. Kotcher et al. [25] discovered that the usage of CSS filters allows the involuntary revelation of sensitive data, such as text tokens, by exploiting time differences to render various DOM trees. Weinberg et al. [45] explored interactive techniques to obtain information, although these attacks are much slower and the protection methods are more challenging to implement.

Felten and Schneider [16] introduced web timing attacks as a tool to compromise users' private data, specifically their web-browsing history. They proposed a method based on leveraging different forms of web browser cache to obtain user-specific browsing information. By measuring the time needed to access certain data from a third-party website, the attacker could determine if that specific data was cached, indicating a previous access. Jia et al. [24] analyzed the possibility of identifying the geo-location of a given visitor using the customization of services performed by websites. As this location-sensitive content is also cached, it is possible to determine the location by checking this concrete data without relying on any other technique.

Bortz et al. [7] categorized JavaScript web timing attacks into two types: (i) direct timing, based on measuring the difference in time of diverse HTTP requests, and (ii) cross-site timing, which allows the retrieval of private client-side data. The first type could expose data that may be used to prove the validity of specific user information on secure websites, such as the username. The second attack type follows the same line as previous work by Felten and Schneider. They also performed experiments suggesting that these timing vulnerabilities were more common than initially expected.

### 9. Conclusions

Many threats to user security and privacy can benefit from a list of websites previously accessed by the user and a list of services where the user is logged in or has ever logged in. In this paper, we show that using third-party website cookies, it is possible to detect the specific state (e.g., accessed and logged) of a user on a particular website, outperforming previous techniques that could only detect one single state. Specifically, we present a novel timing side-channel attack against server-side request processing schemas. This technique can detect execution paths with more than 5 milliseconds of difference between each other.

We also analyzed real-world servers to determine the percentage of websites vulnerable to our attack. All previous work analyzed fewer than 10 websites (manually), as they generally only detected the logged status. We performed the same analysis and additionally conducted an automated check of 10,000 websites from different categories and with varying numbers of users. Our results show that more than half of the websites are vulnerable to our technique.

### Acknowledgments

This work is partially supported by the Basque Government under a pre-doctoral grant given to Iskander Sanchez-Rola.

### References

[1] Acar, G., Juarez, M., Nikiforakis, N., Diaz, C., Gürses, S., Piessens, F., and Preneel, B. FPDetective: dusting the web for fingerprinters. In Proceedings of the ACM SIGSAC Conference on Computer and Communications Security (CCS) (2013).

[2] Akkus, I. E., Chen, R., Hardt, M., Francis, P., and Gehrke, J. Non-tracking web analytics. In Proceedings of the ACM SIGSAC Conference on Computer and Communications Security (CSS) (2012).

[3] Amazon Web Services. Alexa top sites. https://aws.amazon.com/es/alexa-top-sites/, 2018.

[4] Backes, M., Kate, A., Maffei, M., and Pecina, K. Obliviad: Provably secure and practical online behavioral advertising. In Proceedings of the IEEE Symposium on Security and Privacy (Oakland) (2012).

[5] Bilenko, M., Richardson, M., and Tsai, J. Targeted, not tracked: Client-side solutions for privacy-friendly behavioral advertising. In Proceedings of the Privacy Enhancing Technologies (PETS) (2011).

[6] Blocksi. Web content filtering. http://www.blocksi.net/, 2018.

[7] Bortz, A., and Boneh, D. Exposing private information by timing web applications. In Proceedings of the International conference on World Wide Web (WWW) (2007).

[8] Cao, Y., Li, S., and Wijmans, E. (Cross-)browser fingerprinting via OS and hardware level features. In Proceedings of the Network and Distributed System Symposium (NDSS) (2017).

[9] ChromeDevTools. DevTools Protocol API. https://github.com/ChromeDevTools/debugger-protocol-viewer, 2019.

[10] Cisco Adaptive Security Appliance. CVE-2019-1713. https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-1713, 2019.

[11] Cloudacl. Web security service. http://www.cloudacl.com/, 2018.

[12] Clover, A. CSS visited pages disclosure. BUGTRAQ mailing list posting (2002).

[13] Englehardt, S., and Narayanan, A. Online tracking: A 1-million-site measurement and analysis. In Proceedings of the ACM SIGSAC Conference on Computer and Communications Security (CCS) (2016).

[14] Directive 2009/136/EC of the European Parliament and of the Council of 25 November 2009. Official Journal of the European Union (2009).

[15] Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation). Official Journal of the European Union (2016).

[16] Felten, E. W., and Schneider, M. A. Timing attacks on web privacy. In Proceedings of the ACM SIGSAC Conference on Computer and Communications Security (CCS) (2000).

[17] Fortinet. Fortiguard web filtering. http://www.fortiguard.com/, 2018.

[18] Fredrikson, M., and Livshits, B. Repriv: Re-imagining content personalization and in-browser privacy. In Proceedings of the IEEE Symposium on Security and Privacy (Oakland) (2011).

[19] Google. Leak of visited status of page in Blink. https://chromereleases.googleblog.com/2018/05/stable-channel-update-for-desktop_58.html, 2018.

[20] Google. Improving privacy and security on the web. https://blog.chromium.org/2019/05/improving-privacy-and-security-on-web.html, 2019.

[21] Guha, S., Cheng, B., and Francis, P. Privad: Practical privacy in online advertising. In Proceedings of the USENIX conference on Networked Systems Design and Implementation (NSDI) (2011).

[22] Heiderich, M., Niemietz, M., Schuster, F., Holz, T., and Schwenk, J. Scriptless attacks: Stealing the pie without touching the sill. In Proceedings of the ACM SIGSAC Conference on Computer and Communications Security (CSS) (2012).

[23] Janc, A., and Olejnik, L. Web browser history detection as a real-world privacy threat. In Proceedings of the European Symposium on Research in Computer Security (ESORICS) (2010).

[24] Jia, Y., Dong, X., Liang, Z., and Saxena, P. I know where you’ve been: Geo-inference attacks via the browser cache. IEEE Internet Computing 19 (2015).

[25] Kotcher, R., Pei, Y., Jumde, P., and Jackson, C. Cross-origin pixel stealing: Timing attacks using CSS filters. In Proceedings of the ACM SIGSAC Conference on Computer and Communications Security (CCS) (2013).

[26] Laperdrix, P., Rudametkin, W., and Baudry, B. Beauty and the beast: Diverting modern web browsers to build unique browser fingerprints. In Proceedings of the IEEE Symposium on Security and Privacy (Oakland) (2016).

[27] Lapowsky, I. California unanimously passes historic privacy bill. Wired, June 2018. https://www.wired.com/story/california-unanimously-passes-historic-privacy-bill/, 2018.

[28] Lee, S., Kim, H., and Kim, J. Identifying cross-origin resource status using application cache. In Proceedings of the Network and Distributed System Symposium (NDSS) (2015).

[29] Mowery, K., and Shacham, H. Pixel perfect: Fingerprinting canvas in HTML5. In Proceedings of the Web 2.0 Workshop on Security and Privacy (W2SP) (2012).

[30] Mozilla. Privacy and the :visited selector. https://developer.mozilla.org/en-US/docs/Web/CSS/Privacy_and_the_:visited_selector, 2018.

[31] Mozilla. Supporting same-site cookies in Firefox 60. https://blog.mozilla.org/security/2018/04/24/same-site-cookies-in-firefox-60/, 2019.

[32] Nagami, Y., Miyamoto, D., Hazeyama, H., and Kadobayashi, Y. An independent evaluation of web timing attack and its countermeasure. In Proceedings of the International Conference on Availability, Reliability and Security (ARES) (2008), IEEE, pp. 1319–1324.

[33] Nikiforakis, N., Kapravelos, A., Joosen, W., Kruegel, C., Piessens, F., and Vigna, G. Cookieless monster: Exploring the ecosystem of web-based device fingerprinting. In Proceedings of IEEE Symposium on Security and Privacy (Oakland) (2013).

[34] phpMyAdmin. CVE-2019-12616. http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-12616, 2019.

[35] Sanchez-Rola, I., and Santos, I. Knockin’ on trackers’ door: Large-scale automatic analysis of web tracking. In Proceedings of the International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment (DIMVA) (2018).

[36] Sanchez-Rola, I., Santos, I., and Balzarotti, D. Clock Around the Clock: Time-Based Device Fingerprinting. In Proceedings of the ACM SIGSAC Conference on Computer and Communications Security (CCS) (2018).

[37] Schinzel, S. An efficient mitigation method for timing side channels on the web. In Proceedings of the International Workshop on Constructive Side-Channel Analysis and Secure Design (COSADE) (2011).

[38] Schwartz, J. Giving the web a memory cost its users privacy. http://www.nytimes.com/2001/09/04/technology/04COOK.html, 2001.

[39] Singer, N. “Do not tread on us.” http://www.nytimes.com/2012/10/14/technology/do-not-track-movement-is-drawing-advertisers-fire.html, 2012.

[40] Smith, M., Disselkoen, C., Narayan, S., Brown, F., and Stefan, D. Browser history re: visited. In Proceedings of the USENIX Workshop on Offensive Technologies (WOOT) (2018).

[41] Sutton, M. A wolf in sheep’s clothing, the dangers of persistent web browser storage. Black Hat DC Briefings (BHDC) (2009).

[42] Swartz, A. Web.py web framework. http://webpy.org/, 2018.

[43] Toubiana, V., Narayanan, A., Boneh, D., Nissenbaum, H., and Barocas, S. Adnostic: Privacy preserving targeted advertising. In Proceedings of the Network and Distributed System Symposium (NDSS) (2010).

[44] Van Goethem, T., Joosen, W., and Nikiforakis, N. The clock is still ticking: Timing attacks in the modern web. In Proceedings of the ACM SIGSAC Conference on Computer and Communications Security (CCS) (2015).

[45] Weinberg, Z., Chen, E., Jayaraman, P., and Jackson, C. I still know what you visited last summer. In Proceedings of the IEEE Symposium on Security and Privacy (Oakland) (2011).

[46] Wondracek, G., Holz, T., Kirda, E., and Kruegel, C. A practical attack to de-anonymize social network users. In Proceedings of the IEEE Symposium on Security and Privacy (Oakland) (2010).

[47] World Wide Web Consortium. User timing. https://www.w3.org/TR/user-timing/