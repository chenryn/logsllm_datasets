2
886
889
890
887
891
891
893
889
122
154
122
152
123
152
122
151
138
125
139
123
136
126
139
123
0
0
1
0
0
2
0
1
480
482
482
485
482
482
485
485
73
104
71
107
70
105
73
101
134
127
129
136
135
140
138
142
0
0
0
0
0
0
0
1
On average, 753.1 addresses out of 65,536 were
mapped for each scan range. The ranges we tested were
all potential ranges for safe stacks. 138.5 times a signa-
ture was hit, meaning we hit an address being part of a
safe stack (S-hits). 0.4 times a signature was hit which
did not belong to a safe stack. That means we hit a false
positive (false S-hits). These false hits occur due to the
signature being written by the program to non-stack re-
gions which reside in potential stack ranges.
Choosing the three least signiﬁcant bytes as a ﬁxed
value has the advantage of greatly reducing the search
space: instead of probing in 2MB steps—which would
be necessary to sweep the potential stack locations with-
out a chance of missing a stack—we exploit the obser-
vation that the distance between allocated pages varies.
Taking this into account leads to the conclusion that
stacks are distributed in a way that gives any value of
these ranges a roughly equal chance of being part of
one stack. While it is not guaranteed to get a hit with
this scanning approach, we cover a bigger area in less
time. Additionally, in case the ﬁrst run did not turn up
any stack, we are free to retry the scan using a different
range. With an increasing number of retries we get close
to a full coverage of the scan region, but at the same time
we spend less time probing a region without any stacks.
4.3.3 Locating non-adjacent stacks
With our modiﬁcations to stack ASLR the methods pre-
sented so far have a high chance of missing a stack, be-
cause they probe a memory region several times larger
than a single stack. Therefore we need to assume no re-
lation between stack locations and are forced to scan for
memory of the size of a single stack. With the random-
ization applied we split the memory into C = 247/221 =
226 chunks, each representing a possible 2MB stack lo-
cation. We ignore the fact that some locations are already
occupied by modules and heaps, as we are able to distin-
guish this data from stack data. Also building a complete
memory map and then skipping these regions, if possi-
ble at all, would take more time than checking for a false
stack hit. Without thread spraying we would be forced to
locate a single stack, which would mean we would on av-
erage need 225 probes. Even with a high scanning speed
this would not be feasible. However by spawning more
threads we can reduce the number of probes in practice
signiﬁcantly.
We tested two strategies for locating these stacks. In
theory every location in the address space has an equal
chance of containing a stack, so scanning with a linear
sweep with a step size of one stack seems like a valid
approach that allows for locating all stacks eventually.
However we noticed that the amount of probes required
to locate any stack signiﬁcantly differed from the ex-
pected amount. This can be explained by big modules
being loaded at addresses our sweep reaches before any
stacks. Due to this mechanic we risk sampling the same
module multiple times instead of moving on to a possible
stack location. As such we employed a different strategy
based on a purely random selection of addresses to probe.
In total we performed nine measurements and were able
to locate a stack with 33,462 probes on average.
4.3.4 Crash-Resistant Memory Scanning
To verify that an attacker can indeed locate CPI’s SafeS-
tack when conducting a memory corruption exploit
against Firefox, we combined thread and stack spraying
with a crash-resistant primitive introduced by recent re-
search [18]. Crash-resistant primitives rely on probing
memory while surviving or not causing at all application
crashes. Using a crash-resistant primitive, it is possible
to probe entire memory regions for mapped pages from
within JavaScript and either receive the bytes located at
the speciﬁed address or a value indicating that the ac-
cess failed.
In case an access violation happens, then
the event is handled by an exception handler provided
by the application, which eventually survives the crash.
An equivalent approach is probing memory using system
calls that return an error without crashing when touching
unmapped memory. Equipped with crash-resistant prim-
itives, we are free to use any strategy to locate the safe
stack without the risk of causing an application crash.
112  25th USENIX Security Symposium 
USENIX Association
8
We choose to scan potential ranges which may include
safe stacks and hence we choose one of the ranges shown
in Table 1. To counteract false positives, we employ a
heuristic based on the observation that thread and stack
spraying yield stacks of a predetermined size, each of
which contains a large number of addresses with our sig-
nature. Determining the stack size is easily done after
any address inside a stack candidate is found, because
we are free to probe higher and lower addresses to locate
the border between the stack’s memory and neighboring
unmapped memory. Once these boundaries are known,
it is possible to use memory disclosures to apply the sec-
ond part of our heuristic. This heuristic is implemented
in asm.js as an optimization. As our code is nearly di-
rectly compiled to native code it is very fast to execute.
Additionally, we mainly need to index an array, with its
start address set to the lower boundary, which is a heavily
optimized operation in asm.js. If the number of entries in
this array matching our sprayed values is above a certain
threshold, we conclude that the memory region is indeed
a stack. A further optimization we chose was to scan
from higher addresses to lower addresses: we observed
that stacks are usually the memory regions with the high-
est address in a process, which means we most likely hit
a stack ﬁrst when scanning from the top.
With the overhead caused by the thread and stack
spraying, we are not able to use the full speed offered
by the probing primitive [18]. This results in an aver-
age probing time of 46s to locate a safe stack (includ-
ing the time for thread and stack spraying). The speed
decrease is mainly due to the fact that we need to keep
the threads and stack frames alive. Our attack achieved
this by simply entering an endless loop at the end, which
leads to degraded performance. However as web work-
ers are designed to handle computational intensive tasks
in the background, the browser stays responsive, but the
scanning speed is affected.
Tagging safe stacks with user controlled data is not
the only option for locating a safe stack. As most free
stack space is zeroed out, a simple heuristic can be used
to scan for zeros instead of scanning for placed markers.
The advantage is that shadow stacks which separate re-
turn addresses and data are still locatable. Another pos-
sibility is to scan for known return addresses near the
base of the stack: as coarse-grained ASLR randomizes
shared libraries on a per-module basis and libraries are
page aligned, the last twelve bits of return addresses stay
the same across program runs and remain recognizable.
Without the overhead caused by the thread and stack
spraying, our scanning speed is increased to 16,500
probes per second. As our approximated scanning
method requires 65,536 scans per run, we are able to
ﬁnish one sweep in less than 4 seconds. However, this
is only the worst case estimation when not hitting any
stack. As mentioned before, we are then free to retry us-
ing a different value. On average, we are able to locate a
safe stack in 2.3 seconds during our empirical evaluation.
4.4 Discussion:
Guard
Implications for ASLR-
In the following, we discuss the potential of a similar at-
tack against ASLR-Guard [26]. While this defense pro-
vides strong security guarantees, it might be vulnerable
to a similar attack as the one demonstrated above: as the
native stack is used for the AG-stack, we can locate it
using our scanning method. If the randomization of AG-
stack locations is left to the default ASLR implementa-
tion (i.e., the stacks receive the same amount of entropy
and potential base addresses), we can use our existing ap-
proach and only need to adjust for the size of the stacks
(if different) in addition to a different scanning heuris-
tic. This results in a longer scanning time, but if recur-
sion can again be forced by attacker-supplied code, the
resulting AG-stack will also increase in size. Combined
with the thread spraying attack, we are able to generate
a large number of sizable stacks. The major difference
is that we are not able to spray a chosen value on the
AG-stack. Further research into dynamic code genera-
tion might allow for spraying speciﬁc byte sequences as
return addresses, if code of the appropriate size can be
generated. While we can not evaluate the security of
ASLR-Guard since we do not have access to an imple-
mentation, it seems possible to locate the AG-stack and
thus disclose unencrypted code addresses.
Besides the AG-stack, there are two additional mem-
ory regions that must be hidden from an attacker. First,
the code regions of executable modules are moved to a
random location, but they are still potentially readable.
As the mmap-wrapper is used, they receive an entropy
of 28 bits. Since the stacks also receive the same amount
of entropy, a similar attack is possible. Scanning can
be done in bigger steps if a large executable module is
targeted. Second, a safe area called safe vault is used
for the translation of encoded pointers and it needs to be
protected. If either of those structures is located, an ad-
versary is able to launch a code-reuse attack. However,
she would be limited to attack types that do not require
access to the stack (e.g., COOP [32]). As stated in the
paper, an attacker has a chance of 1 in 214 to hit any
of these regions with a random memory probe. This re-
sults in the possibility of exhausting the search space in
roughly one second with the memory probing primitive
discussed earlier. Additional steps need to be taken in
order to determine the speciﬁc region hit, though. This
can include signatures for code sections or heuristics to
identify the safe vault.
USENIX Association  
25th USENIX Security Symposium  113
9
5 Reducing the Odds for Attackers
We developed a mechanism called Authenticating Page
Mapper (APM), which hinders attacks probing for the
safe areas. Our mechanism is based on a user-level page
fault handler authenticating accesses to inactive pages in
the safe area and, when possible, also artiﬁcially inﬂating
the virtual memory region backing the safe area.
The ﬁrst strategy seeks to limit the attack surface to
active safe area pages in the working set of the appli-
cation. Since the working set is normally much smaller
than the virtual memory size (especially for modern de-
fenses relying on safe areas with sparse virtual memory
layouts [13,24]), this approach signiﬁcantly increases the
entropy for the attacker. Also, since a working set is nor-
mally stable for real applications [38], the steady-state
performance of APM is negligible.
The second strategy ensures an increase in the number
of inactive pages not in use by the application, serving
as a large trip hazard surface to detect safe area prob-
ing attacks with very high probability. In addition, since
we randomize the concrete placement of the safe area
within the larger inﬂated virtual memory space, this miti-
gates the impact of implementation bugs that allow an at-
tacker to disclose the virtual (but not the physical) mem-
ory space assigned to the inﬂated area. Finally, this en-
sures that, even an attacker attempting to stress-test an
application and saturate the working set of a safe area is
still exposed to a very large detection surface.
Notice that deterministic isolation, and not hiding, can
secure any safe area if properly applied. However, isola-
tion in 64-bit systems has not, yet, been broadly adopted,
while CPI’s SafeStack is already available in the ofﬁcial
LLVM tool-chain [2] and there are discussions for port-
ing it to GCC [3], as well. We therefore seek for a system
that rather hardens IH, than fully protects it. To that end,
APM stands as a solution until a proper replacement of
IH is adopted by current defenses.
5.1 Authenticating Accesses
To authenticate accesses, APM needs to interpose on all
the page faults in the safe area. Page faults are nor-
mally handled by the OS, but due to the proliferation
of virtualization and the need for live migration of vir-
tual machines, new features that enable reliable page
fault handling in user space have been incorporated in
the Linux kernel [6]. We rely on such features to gain
control when an instruction accesses one of the safe ar-
eas to authenticate it. To authenticate the access, we
rely on unforgeable execution capabilities, such as the
faulting instruction pointer and stack pointer, exported
by the kernel to our page fault handler and thus trusted
in our threat model (arbitrary memory read/write primi-
tives in userland). Our design draws inspiration from re-
cent hardware solutions based on instruction pointer ca-
pabilities [37], but generalizes such solutions to generic
execution capabilities and enforces them in software (in
a probabilistic but efﬁcient fashion) to harden IH-based
solutions. An alternative option is to use SIGSEGV han-
dlers, but this introduces compatibility problems, since
applications may have their own SIGSEGV handler,
faults can happen inside the kernel, etc. On the other
hand, userfaultfd [6] is a fully integrated technique
for reliable page fault handling in user space for Linux.
APM is implemented as a shared library on Linux
and can be incorporated in programs protected by CPI,
ASLR-Guard, or any other IH-based solution by preload-
ing it at startup (e.g., through the LD_PRELOAD environ-
ment variable). Upon load, we notify the kernel that we
wish to register a user-level page-fault handler for each of
the process’s safe areas (i.e., using the userfaultfd
and ioctl system calls).
When any of the safe area pages are ﬁrst accessed
through a read or write operation, the kernel invokes
the corresponding handler we previously registered. The
handler obtains the current instruction pointer (RIP on
x86-64), the stack pointer, the stack base, and the fault-
ing memory address from the kernel, and uses this in-
formation to authenticate the access. Authentication is
performed according to defense-speciﬁc authentication
rules. If the memory access fails authentication, the pro-
cess is terminated. In the other cases, the handler signals
the kernel to successfully map a new zero page into the
virtual memory address which caused the page fault.
To support CPI and SafeStack in our current im-
plementation, we interpose on calls to mmap() and
pthread_create(). In particular, we intercept calls
to mmap() to learn CPI’s safe area. This is easily ac-
complished because the safe area is 4TB and it is the
only such mapping that will be made. Furthermore, we
intercept pthread_create(), which is used to ini-
tialize thread-related structures and start a thread, to ob-
tain the address and size of the safe stack allocated for the
new thread. In the following subsections, we detail how
we implement authentication rules for CPI and SafeStack
using our execution capabilities.
5.2 CPI’s Authentication Rules
To access a safe area without storing its addresses in
data memory, CPI (and other IH-based solutions) store
its base address in a CPU register not in use by the appli-
cation. However, as the number of CPU registers is lim-
ited, CPI relies on the segmentation register gs available
on x86-64 architectures to store the base address. The
CPI instrumentation simply accesses the safe area via an
offset from that register. Listing 1 shows an example of
a safe area-accessing instruction generated by CPI.
114  25th USENIX Security Symposium 
USENIX Association
10
mov
%gs:0x10(%rax),%rcx
Listing 1: x86-64 code generated by CPI to read a value
from the safe area.
Since gs is not used for any other purpose (it was se-
lected for this reason) and the instrumentation is assumed
to be trusted, APM authenticates accesses to the CPI safe
area by verifying that the instruction pointer points to an
instruction using the gs register. Therefore, since the at-
tacker needs to access the safe area before actually gain-
ing control of the vulnerable program, only legitimate in-
structions part of the instrumentation can be successfully
authenticated by APM.
5.3 SafeStack’s Authentication Rules
Similar to CPI’s safe area, SafeStack’s primary stack
(safe stack) is also accessed through a dedicated register
(RSP on x86-64 architectures) which originally points
to the top of the stack. When new values need to be
pushed to it, e.g., due to a function call, the program al-
locates space by subtracting the number of bytes needed
from RSP. This occurs explicitly or implicitly through
the call instruction. Hence, to authenticate safe stack
accesses, APM relies on the stack pointer (RSP) to verify
the faulting instruction accesses only the allocated part
of the stack. The latter extends from the current value of
RSP to the base of the safe stack of each thread. We also
need to allow accesses the red zone on x86-64.
Inﬂating the Safe Area