title:Timely Rerandomization for Mitigating Memory Disclosures
author:David Bigelow and
Thomas Hobson and
Robert Rudd and
William W. Streilein and
Hamed Okhravi
Timely Rerandomization for Mitigating Memory
Disclosures∗
David Bigelow
MIT Lincoln Laboratory
PI:EMAIL
Thomas Hobson
MIT Lincoln Laboratory
Robert Rudd
MIT Lincoln Laboratory
PI:EMAIL
PI:EMAIL
William Streilein
MIT Lincoln Laboratory
PI:EMAIL
Hamed Okhravi
MIT Lincoln Laboratory
PI:EMAIL
Abstract
Address Space Layout Randomization (ASLR) can increase
the cost of exploiting memory corruption vulnerabilities.
One major weakness of ASLR is that it assumes the secrecy
of memory addresses and is thus ineﬀective in the face of
memory disclosure vulnerabilities. Even ﬁne-grained vari-
ants of ASLR are shown to be ineﬀective against memory
disclosures. In this paper we present an approach that syn-
chronizes randomization with potential runtime disclosure.
By applying rerandomization to the memory layout of a pro-
cess every time it generates an output, our approach renders
disclosures stale by the time they can be used by attackers
to hijack control ﬂow. We have developed a fully function-
ing prototype for x86 64 C programs by extending the Linux
kernel, GCC, and the libc dynamic linker. The prototype
operates on C source code and recompiles programs with a
set of augmented information required to track pointer lo-
cations and support runtime rerandomization. Using this
augmented information we dynamically relocate code seg-
ments and update code pointer values during runtime. Our
evaluation on the SPEC CPU2006 benchmark, along with
other applications, show that our technique incurs a very
low performance overhead (2.1% on average).
1.
INTRODUCTION
Memory corruption attacks have been one of the most
prevalent types of attack for decades [5], and they continue
to pose a threat to modern systems. These attacks have
evolved from simple stack-based buﬀer overﬂows [33] to a
more sophisticated type that reuses existing code in a pro-
cess’s memory space [40]. Known as code reuse attacks, or
return-oriented programming (ROP), these attacks bypass
traditional defenses such as marking memory pages writable
∗This work is sponsored by the Department of Defense un-
der Air Force Contract #FA8721-05-C-0002. Opinions, in-
terpretations, conclusions and recommendations are those of
the author and are not necessarily endorsed by the United
States Government.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are not
made or distributed for proﬁt or commercial advantage and that copies bear
this notice and the full citation on the ﬁrst page. Copyrights for components
of this work owned by others than ACM must be honored. Abstracting with
credit is permitted. To copy otherwise, or republish, to post on servers or to
redistribute to lists, requires prior speciﬁc permission and/or a fee. Request
permissions from Permissions@acm.org.
CCS’15, October 12–16, 2015, Denver, Colorado, USA.
c(cid:13) 2015 ACM. ISBN 978-1-4503-3832-5/15/10 ...$15.00.
DOI: http://dx.doi.org/10.1145/2810103.2813691.
or executable but not both (W⊕X), or defenses that check
the integrity of code before execution [34]. Although in
many cases these attacks may be mitigated through the use
of a memory safe language, protecting against such attacks
remains challenging due to enormous volumes of existing
code combined with modern programs that continue to be
developed in C/C++ [44] for reasons of practicality, perfor-
mance, and developer familiarity.
Because memory safe languages are not always a reason-
able option, numerous defenses have been proposed over
the years to mitigate memory corruption attacks in non-
memory safe languages. These defenses can be broadly cat-
egorized into enforcement-based and randomization-based
defenses. In the enforcement-based category, certain checks
are performed on the code to prevent memory corruption
attacks. Complete memory safety techniques such as Soft-
Bound and its CETS extension [31, 32] are an example of
such defenses; however, they incur a high overhead, up to
4x slowdowns in some cases. Other enforcement-based tech-
niques include control-ﬂow integrity (CFI) [3], along with
its coarse-grained enforcement variants [47, 48], that try to
stop control-hijacking attacks by verifying the target of any
control transfer. Unfortunately, ideal CFI has not proven
practical to date, and coarse-grained enforcement of CFI
has been shown to be ineﬀective [18].
In the randomization-based category, the process’s instruc-
tions [26, 8] or memory layout [35] are randomized to thwart
memory corruption attacks. A widely deployed memory
randomization technique is Address Space Layout Random-
ization (ASLR), implemented in most modern desktop and
mobile operating systems, that randomizes the location of
the stack, heap, linked libraries, and main program [35]. A
major assumption of randomization-based defenses is that
the memory layout remains secret. Unfortunately, this as-
sumption has been shown to be incorrect. Memory data
can be leaked to a potential attacker either directly using
memory disclosure vulnerabilities [43], or indirectly using
remote timing or fault analysis attacks [38, 9]. In response
to such weaknesses, one trend in the research community
has been to make randomization techniques ﬁner-grained.
Techniques such as Binary Stirring [46], medium- and ﬁne-
grained ASLR [27, 17], or in-place code rewriting [20] try to
make randomization of memory layout more granular than
traditional memory segments. However, as shown by recent
oﬀensive techniques such as just-in-time ROP [42] or side-
channel attacks [38], even ﬁne-grained randomization can
be bypassed with an extensive-enough leakage of memory
content.
268In this work, we take a diﬀerent approach to mitigate
memory leakage attacks. We observe that the weaknesses
of existing traditional and ﬁne-grained randomization tech-
niques arise from the fact that randomization happens a
single time at program load and never again, while leaks
may happen many times at runtime. As a result, the infor-
mation leaked to an attacker remains valid as long as the
process is running. We therefore rerandomize a process’s
memory layout at runtime in order to mitigate the impact
of information leakage.
An important question is when to rerandomize the mem-
ory layout. Overly frequent rerandomization can incur an
unacceptably high overhead, while insuﬃciently frequent re-
randomization can weaken or eliminate security guarantees
because an attacker may have the opportunity to leak mem-
ory layout information and execute the main attack before
the process is rerandomized. A key insight in our technique
is the need to tie rerandomization to the actions of a poten-
tial attacker. Therefore, we rerandomize the process mem-
ory layout whenever there is an output from the process; that
is, a socket write, a ﬁle write, a console write, etc. More pre-
cisely, we rerandomize the memory layout after many out-
put system calls and before processing an input system call.
This mitigates the impact of memory disclosure attacks be-
cause any information about the layout of memory that an
attacker obtains at output time is stale by the time there
is an opportunity to use that information to hijack control
ﬂow (i.e. at input time).
In this paper, we describe the design, implementation, and
evaluation of our technique, Timely Address Space Random-
ization (TASR1), which rerandomizes the memory layout
during runtime before the attacker can take advantage of
any stolen knowledge (hence, the timely aspect). TASR is
conceptually simple, but its realization required a substan-
tial design and implementation eﬀort, most notably in track-
ing the locations of all code pointers in a live process. TASR
consists of three major components. First, the compile-time
component annotates source code written in C with infor-
mation needed to support its relocation at runtime. This
information is added as a new section into the compiled bi-
nary (ELF) ﬁle of the application which is used in a TASR-
enabled system and ignored otherwise. Second, the kernel
component of TASR uses this information to manage the re-
randomization whenever the appropriate input/output sys-
tem call pairings occur, and third, an injected process ele-
ment performs the actual pointer updating each time it is
required.
TASR was designed with the intent of achieving source
code compatibility [44] with complex, production-level ap-
plication while having low performance overhead, which has
been shown to be critical for widespread adoption of defen-
sive techniques.
Pointer analysis similar to what is needed for TASR has
been studied before in other contexts including control-ﬂow
integrity techniques [3] or garbage collection for C [36]; how-
ever, those analyses are not suﬃcient for our prototype be-
cause the pointer analysis must be exact and complete in
order for TASR to work properly. Imprecise pointer track-
ing can be tolerated in previous work where correctness is
not at stake (e.g. a garbage collector simply fails to collect
an unused region of memory which does not break function-
1Pronounced “taser”
ality), but can cause crashes or worse in a TASR-enabled
process. Therefore, we have also improved pointer tracking
for compiler-generated temporary variables so as to achieve
greater precision. We additionally use techniques from re-
lated work [36] to handle other hard cases, such as disam-
biguation of unions and other dynamically allocated objects.
TASR is practical and lightweight. We have implemented
a complete TASR prototype which includes the improved
compile-time pointer analyzer and a runtime rerandomizer
on x86 64 Linux systems. We also evaluate the performance
characteristics, compatibility, and security of TASR. We
have evaluated TASR against the SPEC 2006 benchmark
and show that it oﬀers signiﬁcant protection with low per-
formance overhead. The average runtime overhead incurred
by TASR on SPEC 2006 is 2.1% with a maximum overhead
of 10.1%. Thus, TASR’s overhead is well within the com-
monly recommended threshold of 10% overhead for practical
memory corruption defenses [44].
TASR is subject to certain limitations. First, it is designed
to protect precompiled binary applications rather than inter-
preted code, and as such, attacks such as JIT-ROP [42] that
apply to scripting engines are not in scope. Second, TASR
cannot automatically handle code that is not compliant with
the C Standard in certain ways. Speciﬁcally, upcasting any
other pointer type into a function pointer prevents necessary
code annotations during the compilation process. Third, use
of a custom memory allocator requires the manual addition
of the allocator signature into the compilation process in or-
der to properly convey necessary information between com-
pilation stages. Related to this, memory allocations must
make use of the sizeof() operator when allocating mem-
ory that includes function pointers. Fourth, TASR does not
protect against data-only attacks or attacks that use relative
addressing, and as such, partial pointer overwrite attacks re-
main possible without the incorporation of additional ﬁne-
grained ASLR techniques. These limitations are described
in more detail in Sections 3 and 4.
Our contributions are summarized as follows:
• We design a complete prototype that continuously ran-
domizes memory layout in a manner that is synchro-
nized with attacker interactions in order to thwart
memory disclosure attacks (direct or indirect) that are
commonly used to bypass existing defensive techniques.
• We implement a prototype for applications written in
C on x86 64 Linux systems. We modify GCC and
the dynamic linker to support rerandomization, and
develop a kernel component and userspace module to
control and perform it.
• We evaluate TASR using the SPEC 2006 benchmark
and show that it incurs a low performance overhead.
We illustrate that by tying output system calls to re-
randomization events, we can minimize the overhead of
TASR while providing the desired security guarantees.
We begin in Section 2 by reviewing existing defenses and
their weaknesses with respect to memory disclosures. Sec-
tion 3 details the threat model under which TASR operates.
The design and implementation of our prototype make up
Section 4. We evaluate the performance and security of our
prototype in Section 5. Finally, we conclude in Section 6.
2692. BACKGROUND AND RELATED WORK
2.1 Randomization-Based Defenses
In 2001, the PaX team released Address Space Layout
Randomization which took the form of a Linux kernel patch
[35]. It applies a one-time randomization to various memory
components of a process at load time. With the advent of
sophisticated exploitation techniques such as ROP in which
small code snippets are chained together to achieve a mali-
cious purpose, ﬁner-grained forms of ASLR have been pro-
posed in the literature. For example, ASLP [27] randomizes
the location of functions within libraries (a.k.a. medium-
grained ASLR), and Binary Stirring [46] applies randomiza-
tion at the basic block level (a.k.a. ﬁne-grained ASLR). Oxy-
moron [7] is another technique that facilitates ﬁne-grained
randomization while allowing code sharing among processes.
Randomization can also be applied to the content of mem-
ory. For example, the multicompiler technique [24] diversi-
ﬁes the content of memory by adding random no-operation
(NOP) instructions into the code at compile-time, among
other protections. ILR [21] is another example that imple-
ment in-place code rewriting of binaries. Techniques such
as multicompiler and ILR can achieve suﬃciently high en-
tropy to make traditional brute-force attacks [41] hard to
implement without unacceptably high numbers of crashes.
The challenge in these techniques, however, arises in the
frequency of randomization. Multicompiler randomizes the
code at compile-time, and ASLR, ASLP, Binary Stirring,
Oxymoron, and ILR randomize the code at load-time. Al-
though the latter case ensures that the code or layout will
be diﬀerent every time that the process is run, the code and
layout will then stay the same during the entire execution
of the process which can be days, weeks, months, or longer
in the case of some server programs.
2.2 Enforcement-Based Defenses
Numerous enforcement-based memory defenses have also
been proposed in the literature. Complete memory safety
techniques such as the SoftBound technique with its CETS
extension [31] incur large runtime overhead (up to 4x slow-
down). “Fat pointer” techniques such Cyclone [25] have also
been proposed to provide spatial pointer safety, but are not
compatible with existing C codebases. Other eﬀorts such as
Cling [4] and AddressSanitizer [39] only provide temporal
pointer safety to prevent use-after-free attacks.
Control ﬂow integrity (CFI) [3] techniques are another
class of enforcement-based defenses. They enforce a compile-
time extracted control ﬂow graph (CFG) at runtime to pre-
vent control hijacking attacks. Unfortunately, precise CFI
enforcement has not yet shown itself to be practical [3]. As
a result, weaker forms of CFI have been implemented in CC-
FIR [47] and bin-CFI [48], but have also been shown to be
vulnerable to carefully crafted control hijacking attacks [18].
Other, ﬁner-grained forms of CFI have also been proposed
recently among which are: Opaque CFI [29] and Forward-
Edge CFI [45].
2.3 Memory Disclosure
A major assumption in the existing layout and code ran-
domization techniques is that the layout of memory remains
unknown to the attacker. As many attacks have illustrated,
however, memory content can leak directly or indirectly [22].
In the direct form, memory content is sent as an output of
the process because of a memory disclosure vulnerability.
For example, a buﬀer overread vulnerability can be used to
leak memory content [43]. Moreover, the same vulnerabil-
ity may be used repeatedly to leak large parts of memory,
a technique that has been used to successfully bypass ﬁne-
grained ASLR [13] and Oxymoron [13]. In the indirect form,
timing or fault analysis attacks are used to remotely leak
the contents of memory. These attacks have been shown
to be eﬀective in bypassing one-time randomization tech-
niques [38], and are eﬀective even against unknown binaries
[9]. In its indirect form, the attack can cover large regions
of memory, and is not limited to areas adjacent to an over-
ﬂowed buﬀer. Moreover, these attacks do not require a sep-
arate memory leakage vulnerability; that is, a single buﬀer
overﬂow vulnerability can be used for the dual purposes of
leaking the content of memory and then hijacking control
[38]. The indirect information leakage attack [16] was also
used to bypass an enforcement-based memory corruption de-
fense known as code pointer integrity [28], and even recent
generalized techniques such as Counterfeit Object-Oriented
Programming [37] make use of information leakage to carry
out an otherwise low-requirement attack. A promising new
defense, Readactor [11], combines execute-only permissions
with a randomized indirection layer to resist memory disclo-
sure attacks. It provides much greater resistance to memory
disclosure attacks than previous defenses, but maintains a
one-time only randomization strategy.
TASR solves these memory disclosure problems by reran-
domizing the layout of memory at every opportunity that