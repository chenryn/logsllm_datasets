that is lower than a specified cutoff threshold, c.
As mentioned above, the scenario pruning algorithm (see Fig. 5
for illustration) uses a tree to represent all the different failure
scenarios. The root node is the scenario where no failure event
occurs [0, 0, . . . , 0], and every child node differs from its parent by
flipping a single bit from 0 to 1. The tree is constructed such that
each flipped bit must be to the right of the previously flipped bit
to prevent revisiting previously visited states. We assume (1) SRG
failures are independent (and so failure events are independent in
our model), and (2) that the probability of each failure event z is
no higher than 0.5, i.e., that every SRG is more likely to not fail
than to fail. Observe that, given these assumptions, the probability
of a scenario decreases as the distance from the root increases.
We traverse the tree in depth-first search (DFS) order until the
condition pq < c is met, at which point no further scenarios down
that path need to be visited. It is important to efficiently calculate
the scenario probabilities while traversing the tree. Consider a
child scenario qc and a parent scenario q which differ in the bit
representing event scenario z. We update the probability of qc as
[1,1,1][1,1,0][1,0,1][1,0,0][0,1,0][0,0,0][0,1,1][0,0,1]SIGCOMM ’19, August 19–23, 2019, Beijing, China
Bogle et al.
(a) Empirical data from MWAN
(b) Weibull distribution
Figure 6: CDF of failure probabilities used in our experi-
ments. The exact value of m in (a) is not shown for confiden-
tiality reasons. The shape and scale parameters in (b) are 0.8
and 10−4, respectively.
Our empirical data from the MWAN network consist of the fol-
lowing: the capacity of all links (in Gbps) and the traffic matrices
(source, destination, amount of data in Mbps) over four months at
a resolution of one sample per hour. For data on failure events, we
collected the up/down state of each link at 15-minute granularity
over the course of a year, as well as a list of possible shared risk
groups. For the ATT, B4, and IBM topologies we obtained a set of
at least 24 demand matrices and link capacities, but per-link failure
probabilities are missing in these datasets. Hence, we use a Weibull
distribution derived from MWAN measurements for these topolo-
gies. In all experiments, including the MWAN network, we use a
range of scaling factors for this distribution to model networks
under different failure rates.
Tunnel selection. TE schemes [27, 30, 35, 43] often use link-disjoint
tunnels for each source-destination pair. However, recent work
shows performance improves with the use of oblivious tunnels
(interchangeably also referred to as oblivious paths) [38]. Because
TeaVaR’s optimization framework is orthogonal to tunnel selec-
tion, we run simulations with a variety of tunnel-selection schemes,
including oblivious paths, link-disjoint paths, and k-shortest paths.
As we show later in the section, TeaVaR achieves higher through-
put regardless of the tunnel selection algorithm. We also study the
impact of tunnel selection on TeaVaR and find that combining
TeaVaR with the tunnel selection of oblivious-routing [38] leads to
better performance (§5.2).
Deriving failure probability distributions. For each link e, we
examine historical data and track whether e was up or down in a
measured time epoch. Each epoch is a 15-minute period. We ob-
tain a sequence of the form (ψ1,ψ2, . . .) such that‘ each ψt specifies
whether the link was up (ψt = 1) or down (ψt = 0) during the
tth measured time epoch. From this sequence, another sequence
(δ1, δ2, . . . , δM) is derived such that δj is the number of consecutive
time epochs the link was up prior to the jth time it failed. For exam-
ple, from the sequence(ψ1,ψ2, . . . ,ψ12) = (1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0)
we derive the sequence (δ1, δ2, δ3) = (2, 3, 1) (the link was up for
2 time epochs before the first failure, 3 before the second failure,
and 1 before the last failure). An unbiased estimator of the mean
ΣM
j =1δj
uptime is given by U =
M . We make a simplified assumption
that the link up-time is drawn from a geometric distribution (i.e.,
the failure probability is fixed and consistent across time epochs).
Then, the failure probability pe of link e is simply the inverse of the
mean uptime; that is, pe = 1
U . We note that we can use this exact
analysis for other shared-risk groups, such as switches.
Figure 6(a) plots the cumulative distribution function (CDF) for
the failure probability across the network links, derived by applying
the above methodology to the empirical availability traces of the
MWAN network. The x-axis on the plot represents the failure prob-
ability, parametrized by m. The exact value of m is not disclosed for
confidentiality reasons. Nonetheless, the important takeaway from
this figure is that failure probabilities of different links might differ
by orders of magnitude. To accommodate the reproducibility of
results, we obtain a Weibull probability distribution which fits the
shape of our empirical data. The Weibull distribution, which has
been used in prior study of failures in large backbones [46], is used
here to model failures over time for topologies for which we do not
have empirical failure data. We denote the Weibull distribution with
shape parameter λ and scale parameter k by W (λ, k). In Fig. 6(b), we
plot the Weibull distribution used in our evaluation, as well as the
parameters needed to generate it. Throughout our experiments, we
change the shape and scale parameters of our Weibull distribution
and study the impact of probability distribution on performance.
Optimization. Our optimization framework uses the Gurobi LP
solver [26] and is implemented using the Julia optimization lan-
guage [10].
5.2 Throughput vs. Availability
We examine the performance of different TE schemes with respect
to both throughput and availability.
Setup. We benchmark TeaVaR against several approaches: SMORE [38],
FFC [43], MaxMin (in particular, the algorithm used in B4 [16, 29]),
and ECMP [20]. SMORE minimizes the maximum link utilization
without explicit guarantees on availability, FFC maximizes the
throughput while explicitly considering failures, MaxMin maxi-
mizes minimum bandwidth per user [16], and TeaVaR minimizes
the CVaR for an input probability. When link failures occur, traf-
fic is redistributed across tunnels according to the proportional
assignment mechanism (see §4.2) without re-optimizing weights.
In our evaluations, we care about both the granted bandwidth and
the probabilistic availability guarantee it comes with. In TeaVaR,
the probability is explicit (controlled by the β parameter in the
formulation as shown in Eq. 4). In FFC, the per-user bandwidth is
granted with 100% availability for scenarios with up to k-link fail-
ures. In our experiments, FFC1 and FFC2 refer to FFC’s formulation
with k = 1 and k = 2, respectively. To fairly compare the ability of
the FFC algorithm to accommodate scaled-up demands, we let it
send the entire demand at the expense of potential degradation in
availability, unless otherwise stated.
Availability vs. demand scaling. We first analyze the availability
achieved by various TE schemes as demand is scaled up. Given
that current networks are designed with traditional worst-case
assumptions about failures, all topologies are over-provisioned.
Hence, we begin with the input demands, compute the availability
achieved when satisfying them for different schemes, and then scale
up the demands by introducing a (uniform) demand scale-up factor
s ≥ 1 by which each entry in the demand matrix is multiplied, a
technique also used in prior work [38, 43].
Availability is calculated by running a post-processing simulation
in which we induce failure scenarios according to their probabil-
ity of occurrence and attempt to send the entirety of the demand
 0 0.2 0.4 0.6 0.8 110-(m+3)10-(m+2)10-(m+1)10-mCDFFailure Probability 0 0.2 0.4 0.6 0.8 110-610-510-410-30.010.1CDFFailure ProbabilityStriking the Right Utilization-Availability Balance in WANs
SIGCOMM ’19, August 19–23, 2019, Beijing, China
(a) IBM topology
(b) MWAN topology
(c) B4 topology
(d) ATT topology
Figure 7: Comparison of TeaVaR to various TE schemes under different tunnel selection algorithms. All schemes in (a) use
oblivious paths, in (b) use k-shortest paths (k = 8), and all schemes in (c) and (d) use edge disjoint paths. The term availability
refers to the percentage of scenarios that meet the 100% demand-satisfaction requirement.
through the network. For each scenario we record the amount of
unsatisfied demand (loss) for each flow, as well as the probability
associated with that scenario. The sum of the probabilities for sce-
narios where demand is fully satisfied reflects the availability in that
experiment. For example, if a TE scheme’s bandwidth allocation
is unable to fully satisfy demand in 0.1% of scenarios, it has an
availability of 99.9%. We then scale the demand matrix and repeat
the above analysis for at least 24 demand matrices per topology.
In Fig. 7, we summarize the results by depicting the demand scale
vs. the corresponding availability.
The results show a consistent trend: TeaVaR can support higher
demand for a given availability level. In particular, for any target
availability level, TeaVaR can support up to twice the demand sup-
ported by other approaches. Notably, in the MWAN topology with
oblivious paths, TeaVaR is able to scale up the demand by a factor
of 3.4, whereas MaxMin achieves a factor of 2.6. The remaining
approaches cannot scale beyond 1.4× the original demand. In cer-
tain networks, like B4, we see less of an improvement over existing
approaches. We believe that this is due to the specific structure of
the network topology and its bottleneck links.
Impact of failure probabilities on availability and demand
scaling. Fig. 7 illustrates TeaVaR’s ability to scale up the demand
matrix while maintaining high availability. To examine the gains
in high-availability regions (99% and higher), we experiment with
lower failure probabilities. Figure 8 shows that TeaVaR is able to
scale the demand up by a factor of 3.7 even when availability is as
high as 99.99%.
Achieved throughput and tunable β. We next demonstrate the
tradeoff between a target availability threshold and the achieved
throughput without scaling the demand. In the previous set of
experiments, availability is measured as the probability mass of
scenarios in which demand is fully satisfied (“all-or-nothing” re-
quirement). In contrast, in this set of experiments we measure the
fraction of the total demand that can be guaranteed for a given
availability target. This fraction is optimized explicitly in TeaVaR
for a given value of β. For other TE schemes, we obtain the fraction
of demand through a similar post-processing method as before: for
each failure scenario, we simulate the outcome of sending the entire
demand through the network, sort the scenarios according to loss
values, and report the demand fraction at the β-percentile (i.e., the
throughput is greater than or equal to that value for β percent of
the scenarios). The range of availability values is chosen according
to typical availability targets [28].
Fig. 9 plots the average throughput for ATT, B4, and IBM topolo-
gies. For each TE scheme, we report the results under the tunnel
selection algorithm which has performed the best (SMORE, TeaVaR,
and MaxMin with oblivious paths and FFC with link-disjoint paths).
The results demonstrate that TeaVaR is able to achieve higher
Figure 8: Comparison of TeaVaR to other TE schemes for
MWAN network in the high-availability region.
Figure 9: Averaged throughput guarantees for different β
values on ATT, B4, and IBM topologies. TeaVaR is the only
scheme that can explicitly optimize for a given β. For all the
other schemes, the value on the x-axis is computed based on
their achieved throughput.
 98 99 100 1 1.4 1.8 2.2 2.6 3Availability (%)Demand Scale 98 99 100 1 1.4 1.8 2.2 2.6 3 3.4Availability (%)Demand Scale 98 99 100 1 1.4 1.8 2.2 2.6 3Availability (%)Demand Scale 98 99 100 1 1.4 1.8 2.2 2.6Availability (%)Demand Scale 0 1 2 3 4 5 6 799%99.9%99.99%Demand ScaleAvailabilityTeaVarSMOREECMPFFC1FFC2MaxMin 70 75 80 85 90 95 10099%99.5%99.9%99.99%Throughput (%)AvailabilityTEAVARSMOREECMPFFC1MaxMinSIGCOMM ’19, August 19–23, 2019, Beijing, China
Bogle et al.
Figure 10: The admissible bandwidth of TeaVaR and FFC av-
eraged across two topologies (IBM and B4), 10 demand matri-
ces, and 10 different probabilities samples. TeaVaR is able to
tune availability and bandwidth, while FFC’s ability to bal-
ance the two is much more coarse-grained.
throughput for each of the target availability values because it
can optimize throughput for an explicit availability target within a
probabilistic model of failures.
The advantage of optimization with respect to an explicit
availability threshold. We next illustrate the advantage over FFC
of TeaVaR’s explicit optimization of the admissible bandwidth for
flows with respect to a target availability threshold (as in Eq. 7).
Recall that FFC influences availability indirectly by requiring that
the admissible bandwidth be supported even with up to k simul-
taneous link failures, for some predetermined value k. We show
below that this approach is too coarse grained to strike desired
utilization-availability tradeoffs. Figure 10 compares the average
admissible bandwidth between FFC and TeaVaR across two topolo-
gies (B4 and IBM), 10 demand matrices, and 10 different probability
samples. Note that in FFC1 (where k = 1) the admissible bandwidth
is nearly 80% with 99.9% availability (FFC1 only provides guarantee
with respect to a single failure, and the total probability of all failure
events in which at most a single link fails is 99.9%). What if, how-
ever, the network operator is interested in achieving availability of
99.99%? Because of the limited expressiveness of FFC, achieving
higher availability than FFC1 translates to setting k = 2. However,
while FFC2 does indeed improve availability to 99.999% (the total
probability of all failure events in which at most two links fail), as
seen in the figure, this huge increase in availability comes at a dire
price: the total admissible bandwidth drops to 27%. As seen in the
figure, by optimizing for an explicit availability level, TeaVaR can
find a sweet spot on the availability-bandwidth arc according to
the operator’s availability target.
FFC maximizes the admissible bandwidth, while TeaVaR’s op-
timization also strives to achieve fairness across flows. Thus, FFC
favors more bandwidth over fairness. Indeed, in the FFC1 and FFC2
outcomes plotted in Figure 10, some of the flows do not send traf-
fic at all while others send their entire demands, making these
extremely unfair. Yet, as the results in Figure 10 show, TeaVaR’s
fairness does not stand in the way of attaining admissible bandwidth
comparable to FFC1 and FFC2 for the corresponding availability
levels (99.9% and 99.999%, respectively).
Figure 11: The effect of tunnel selection scheme on TeaVaR’s
performance, quantified by the resulting CV aRβ (or loss) for
different values of β. TeaVaR using oblivious paths has better
performance (lower loss).
Impact of tunnel selection. So far, TeaVaR has been simulated
with either link-disjoint or oblivious tunnels [38] schemes. We now
analyze other tunnel selections. We demonstrate that while path
selection is an important aspect of any TE scheme, no specific choice
is needed for TeaVaR’s success. In Fig. 11, we plot the obtained
CV aRβ as a function of β for k-shortest paths with 3 and 4 paths,
FFC’s link-disjoint paths, and SMORE’s oblivious routing. TeaVaR
performs comparably well regardless of the tunnel selection scheme.
However, the figure shows that oblivious paths are still superior.
For example, the obtained CV aRβ value is at least 20% better for
β = 0.99 than any other tunnel selection scheme. These results
indicate that an oblivious routing tunnel selection is a good choice
to complement TeaVaR. Oblivious routing is intended to avoid
link over-utilization through diverse and low-stretch path selection,
whereas k-shortest paths routing often yields many overlapping
paths. Intuitively, these path properties are useful for TeaVaR,
providing our optimization framework with a set of tunnels that, if
utilized appropriately, can provide high availability.
5.3 Robustness of Probability Estimates
TeaVaR uses a probabilistic model of network failures. Probabilities
of failure events in our experiments are estimated by analyzing