### PhotoProof: Transparent Handling of Algorithms and Keys

PhotoProof can seamlessly manage its algorithms and keys, allowing users to focus solely on image editing. This process is akin to using any standard image editing software, while the plugin keeps track of all permissible transformations applied. Once the editing is complete, the plugin calls the prover with the correct parameters the required number of times and outputs the proof.

### Copyright Message and Metadata Protection

Metadata, often as crucial as the image content, can be easily edited or forged. In our prototype, we demonstrated metadata protection by including a protected timestamp (see Section V-A). Similarly, it is possible to protect GPS location tags, the camera owner's name, or any other automatically added information.

We also enable the protection of fields manually added by the user after the image has been signed, such as captions, copyright messages, and face tags. This is achieved by allowing certain fields to be edited only with access to the original image, which can be verified by the compliance predicate. The original image can then be destroyed, ensuring that no one can edit these fields without invalidating the proof.

### Image Provenance Tracking

For some applications, it may be necessary to track (and possibly limit) the list of transformations an image undergoes and their order. This can be accomplished using a provenance metadata field. The original (signed) image is generated with an empty list, and permissible transformations will append themselves to this field. Note that the length of this field is limited due to the overall image size constraint. Alternatively, tracking only the length of the provenance can mitigate the risk of numerous small permissible changes accumulating into an impermissible overall change.

### Conclusions and Future Directions

We have presented IA schemes, a cryptographic primitive for image authentication, and constructed PhotoProof, an IA scheme based on Proof-Carrying Data and digital signatures. We also implemented a working prototype with a collection of supported permissible transformations. Our implementation is the first proof-of-concept of an IA scheme.

Further improvements are needed to make the technology usable for real-world applications. This includes reducing generation and proving times, extending the set of supported transformations, and increasing the image size limit. These goals can be achieved through faster SNARK technology, better circuit designs for image transformations, and accelerated implementations using GPGPU, FPGA, or ASIC.

Another approach is to implement a variant of PhotoProof using a PCD-like mechanism based on trusted hardware with attestation capabilities, such as TPM or Intel’s SGX. In this implementation, every editing step would attest to the correct execution of the computation that verified the previous step’s attestation and performed a permissible transformation. This would provide succinctness and zero-knowledge comparable to PhotoProof, with higher performance, but based on trusted hardware and careful platform configuration instead of cryptographic proofs.

Increased image size and decreased proof size will enable practical methods to embed the proof inside the image in an invisible way. PhotoProof demonstrates the power of PCD in tracking and enforcing authenticity and provenance for digital images while still offering the editing flexibility required by applications. Similar needs for authenticity and provenance arise for other document types, such as text, audio, databases, and other structured data. We challenge the community to identify and implement specific applications in these domains.

### Acknowledgments

This work was supported by the Broadcom Foundation and Tel Aviv University Authentication Initiative; the Check Point Institute for Information Security; the Israeli Ministry of Science and Technology; the Israeli Centers of Research Excellence I-CORE program (center 4/11); and the Leona M. & Harry B. Helmsley Charitable Trust.

### References

[1] M. Ajtai, “Generating hard instances of lattice problems,” in ACM Symposium on the Theory of Computing (STOC) 1996, 1996, pp. 99–108.
...
[60] Y. Zhao, S. Wang, X. Zhang, and H. Yao, “Robust hashing for image authentication using Zernike moments and local features,” IEEE Transactions on Information Forensics and Security, vol. 8, no. 1, pp. 55–63, 2013.

### Secure Camera: Caveats

Most existing image authentication solutions rely on a secure camera as a root of trust. However, like any secure device, cameras can be vulnerable to attacks from software and hardware vulnerabilities, side channel and fault injection attacks, and reverse engineering.

One example is Canon’s Original Decision Data (ODD), which digitally signs images inside the camera. Unfortunately, their implementation was insecure [50], [15]. Nikon’s analogous Image Authentication system [36] faced similar issues.

Even when ignoring implementation bugs and hardware flaws, several attack vectors exist at the camera level. One possible attack is image injection, where an attacker exploits the insecure link between the camera’s sensor and its Image Signal Processor (ISP). This can be mitigated by encrypting the sensor-to-ISP channel, programming the ISP to sign only signals with a unique analog fingerprint, or using accelerometers to verify the video feed.

Another attack is 2D scene staging, where an attacker fabricates an image, prints or projects it, and photographs it with a secure camera. Solutions include adding data to determine if the image content matches the physical surroundings, such as focus distance or range from target. Another possibility is to take a 3D picture and use image processing algorithms to distinguish between 2D and 3D objects. However, a sufficiently dedicated attacker might fabricate a 3D scene, making it appear authentic.

---

This revised version aims to enhance clarity, coherence, and professionalism while maintaining the original content and intent.