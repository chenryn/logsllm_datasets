reuse attacks such as counterfeit-object oriented programming
(COOP) [46] and return-into-libc (RILC) [37].
The memory leakage resilience of LR2 is similar to that of
Readactor. Unlike the approaches by Crane et al. [14, 15], we
do not require a CPU with hardware support for virtualization
and a hypervisor;
in fact, our approach does not rely on
virtual memory at all and therefore applies to MMU-less chips
commonly used in build embedded and real-time systems.
Another way to defend against information disclosure is
“live re-randomization”, where the program is periodically re-
randomized to invalidate any current code pointers, thereby
preventing the attacker from exploiting any knowledge they
gain of the program. Giuffrida et al. [23] describe the ﬁrst
implementation of this idea. However, even with very short
randomization periods, the attacker may still have enough time
for an attack [4, 20]. Bigelow et al. [6] propose an improved
approach, TASR, which only re-randomize programs when
they perform input or output. Both approaches require that
all code pointers are updated post-randomization, and rely on
a modiﬁed C compiler to provide their locations. However,
ﬁnding all code pointers in a C program is not always possible
in the general case. Bigelow et al. describe a set of heuristics
and assumptions they rely on to ﬁnd the pointers, but real-
world C code does not strictly comply with C’s standard rules
and often violates common sense assumptions about pointer
use and safety [10].
Figure 7 maps key regions of the in-memory program
representation to related work in leakage-resilient diversity.
While many defenses focus on enforcing XoM or preventing
indirect leakage through code pointers, only Readactor and
LR2 provide both to stop all variants of JIT-ROP. As described
in Section VII-D, the vtable and procedure linkage table (PLT)
randomization techniques are fully compatible with software-
XoM and would increase resilience against COOP and RILC
attacks.
13
HeapStacksVtables OxymoronXnR, HideM, Readactor, TASR, LRPointGuard, Readactor, ASLRGuard, LR       Readactor++StackGuard,StackArmorPLTIsomeron22CodePagepointer to codeprotected against leakageDataCoded) Software-Fault Isolation: SFI isolates untrusted code
so it cannot access memory outside the sandbox or escape
conﬁnement. SFI policies are typically enforced by inserting
inline reference monitors [45, 53].
Since reads are far more frequent than writes, some SFI
implementations only sandbox writes and indirect branches.
Google’s NaCl implementation for ARM [47] eschewed load-
isolation initially but support was later added [36] to prevent
untrusted plug-ins from stealing sensitive information such as
credit card and bank account numbers. Like LR2, NaCl for
ARM uses a customized compiler and masks out the high
bits of addresses. Unlike LR2, NaCl also constrains writes
and indirect branches. ARMor [54] is another SFI approach
for ARM. It uses link time binary rewriting to instrument
untrusted code. This makes ARMor less efﬁcient than compile-
time solutions and the authors report overheads ranging from
5-240%.
Several hardware-based fault isolation approaches appeared
recently. Zhou et al. [55] present ARMlock which uses the
memory domain support in ARM processors to create sand-
boxes that constrain the reads and writes, and branches of code
running inside them with no loss of efﬁciency. While ARMlock
prevents code from reading the contents of other sandboxes,
it cannot support our use-case of preventing read accesses
to code inside the sandbox. Santos et al. [44] use the ARM
TrustZone feature to build a trusted language runtime (TLR);
while this greatly reduces the TCB of an open source .NET
implementations the performance cost is high. Unlike LR2,
these approaches rely on features that limit their applicability
to certain hardware platforms.
One may consider the load-masks we insert as a type
of SFI inline reference monitor. However, as explained in
Section IV-B, we place masking instructions differently from
SFI techniques due to the different threat model; using the
same instrumentation for SFI would not be secure. Further,
LR2 does not need to constrain writes or indirect branches as
the adversary must disclose the code layout before mounting
a code-reuse attack.
Software that is vulnerable to memory corruption remains
exposed to sophisticated code-reuse exploits. The problem of
code reuse is not speciﬁc to x86 systems but threatens RISC-
based mobile and embedded systems too. Code randomization
can greatly improve resilience to code reuse as long as the
code layout is not disclosed ex post facto. The combination
of execute-only memory and code-pointer hiding provides
comprehensive resilience against leakage of code layout infor-
mation. Unfortunately, the implementation of these techniques
has so far relied on x86-speciﬁc features or has increased
resource requirements beyond reasonable limits for mobile and
embedded devices.
Unlike previous solutions, our leakage-resilient layout ran-
domization approach—LR2—only requires that the host sys-
tem enforces a W⊕X policy. Our software enforcement of
execute-only memory is inspired by prior work on software-
fault isolation. However, since our threat model is fundamen-
tally different from SFI (we protect trusted code whereas SFI
isolates untrusted code), we are able to insert fewer load-
masking operations than comparable SFI implementations.
This signiﬁcantly reduces overheads.
14
We reuse existing techniques to protect forward pointers
but present a new optimized XOR pointer encryption scheme
relying on XoM and function permutation to protect return
addresses. Since LR2 does not require any special hardware
support, it can protect applications running on a broad range of
non-x86 devices, including MMU-less micro-controllers. Even
though LR2 prevents memory disclosure purely in software,
its performance is similar to defenses offering comparable
security.
ACKNOWLEDGMENTS
The authors thank Nikhil Gupta for helping with logistics
and benchmarking.
This material is based upon work partially supported by
the Defense Advanced Research Projects Agency (DARPA)
under contracts FA8750-15-C-0124, FA8750-15-C-0085, and
FA8750-10-C-0237, by the National Science Foundation under
award numbers CNS-1513837 and IIP-1520552 as well as gifts
from Mozilla, Oracle, and Qualcomm.
Any opinions, ﬁndings, and conclusions or recommenda-
tions expressed in this material are those of the authors and
do not necessarily reﬂect the views of the Defense Advanced
Research Projects Agency (DARPA), its Contracting Agents,
the National Science Foundation, or any other agency of the
U.S. Government.
This work has been co-funded by the German Science
Foundation as part of project S2 within the CRC 1119
CROSSING and the European Union’s Seventh Framework
Programme under grant agreement No. 609611, PRACTICE
project.
REFERENCES
[1] M. Abadi, M. Budiu, Ú. Erlingsson, and J. Ligatti. Control-ﬂow integrity
principles, implementations, and applications. ACM Transactions on
Information System Security, 13, 2009.
[2] ARM Ltd. ARM Compiler Software Development Guide v5.04, 2013.
http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.dui0471k/
chr1368698593511.html.
[3] M. Backes and S. Nürnberger. Oxymoron: Making ﬁne-grained memory
In 23rd USENIX
randomization practical by allowing code sharing.
Security Symposium, USENIX Sec, 2014.
[4] M. Backes, T. Holz, B. Kollenda, P. Koppe, S. Nürnberger, and J. Pewny.
You can run but you can’t read: Preventing disclosure exploits in
In ACM SIGSAC Conference on Computer and
executable code.
Communications Security, CCS, 2014.
[5] S. Bhatkar and R. Sekar. Data space randomization.
In Detection of
Intrusions and Malware, and Vulnerability Assessment, DIMVA, 2008.
[6] D. Bigelow, T. Hobson, R. Rudd, W. Streilein, and H. Okhravi. Timely
In ACM SIGSAC
rerandomization for mitigating memory disclosures.
Conference on Computer and Communications Security, CCS, 2015.
[7] A. Bittau, A. Belay, A. J. Mashtizadeh, D. Mazières, and D. Boneh.
Hacking blind. In 35th IEEE Symposium on Security and Privacy, S&P,
2014.
[8] H. Bojinov, D. Boneh, R. Cannings, and I. Malchev. Address space
In ACM Conference on Wireless
randomization for mobile devices.
Network Security, WiSec, 2011.
[9] C. Cadar, P. Akritidis, M. Costa, J.-P. Martin, and M. Castro. Data ran-
domization. Technical Report MSR-TR-2008-120, Microsoft Research,
September 2008. URL http://research.microsoft.com/apps/pubs/default.
aspx?id=70626.
[10] D. Chisnall, C. Rothwell, R. N. M. Watson, J. Woodruff, M. Vadera,
S. W. Moore, M. Roe, B. Davis, and P. G. Neumann. Beyond the PDP-
11: Architectural support for a memory-safe C abstract machine. In 20th
International Conference on Architectural Support
for Programming
Languages and Operating Systems, ASPLOS, 2015.
[11] M. Conti, S. Crane, L. Davi, M. Franz, P. Larsen, C. Liebchen, M. Negro,
M. Qunaibit, and A.-R. Sadeghi. Losing control: On the effectiveness of
control-ﬂow integrity under stack attacks. In ACM SIGSAC Conference
on Computer and Communications Security, CCS, 2015.
[12] F. J. Corbató and V. A. Vyssotsky.
Introduction and overview of the
MULTICS system. In Joint Computer Conference, AFIPS, 1965.
[13] C. Cowan, S. Beattie, J. Johansen, and P. Wagle. Pointguard: protecting
pointers from buffer overﬂow vulnerabilities. In 12th USENIX Security
Symposium, USENIX Sec, 2003.
[14] S. Crane, C. Liebchen, A. Homescu, L. Davi, P. Larsen, A.-R. Sadeghi,
S. Brunthaler, and M. Franz. Readactor: Practical code randomization
In 36th IEEE Symposium on Security
resilient to memory disclosure.
and Privacy, S&P, 2015.
[15] S. Crane, S. Volkaert, F. Schuster, C. Liebchen, P. Larsen, L. Davi, A.-
R. Sadeghi, T. Holz, B. D. Sutter, and M. Franz. It’s a TRAP: Table
In ACM
randomization and protection against function reuse attacks.
SIGSAC Conference on Computer and Communications Security, CCS,
2015.
[16] R. Cytron, J. Ferrante, B. K. Rosen, M. N. Wegman, and F. K. Zadeck.
An Efﬁcient Method of Computing Static Single Assignment Form. In
16th ACM SIGPLAN-SIGACT Symposium on Principles of Programming
Languages, POPL, 1989.
[17] L. Davi, A. Dmitrienko, M. Egele, T. Fischer, T. Holz, R. Hund,
S. Nürnberger, and A.-R. Sadeghi. MoCFI: A framework to mitigate
In 19th Annual Network and
control-ﬂow attacks on smartphones.
Distributed System Security Symposium, NDSS, 2012.
[18] L. Davi, A. Dmitrienko, S. Nürnberger, and A. Sadeghi. Gadge me if
you can: secure and efﬁcient ad-hoc instruction-level randomization for
x86 and ARM. In 8th ACM Symposium on Information, Computer and
Communications Security, ASIACCS, 2013.
[19] L. Davi, A. Sadeghi, D. Lehmann, and F. Monrose. Stitching the gadgets:
On the ineffectiveness of coarse-grained control-ﬂow integrity protection.
In 23rd USENIX Security Symposium, USENIX Sec, 2014.
[20] L. Davi, C. Liebchen, A.-R. Sadeghi, K. Z. Snow, and F. Monrose.
Isomeron: Code randomization resilient to (Just-In-Time) return-oriented
programming. In 22nd Annual Network and Distributed System Security
Symposium, NDSS, 2015.
[21] J. Drake. Stagefright: scary code in the heart of Android. https://www.
blackhat.com/us-15/brieﬁngs.html#stagefright-scary-code-in-the-heart-
of-android, 2015.
[22] J. Gionta, W. Enck, and P. Ning. HideM: Protecting the contents of
userspace memory in the face of disclosure vulnerabilities. In 5th ACM
Conference on Data and Application Security and Privacy, CODASPY,
2015.
[23] C. Giuffrida, A. Kuijsten, and A. S. Tanenbaum. Enhanced operating
system security through efﬁcient and ﬁne-grained address space random-
ization. In 21st USENIX Security Symposium, USENIX Sec, 2012.
[24] E. Göktas, E. Athanasopoulos, H. Bos, and G. Portokalidis. Out of
control: Overcoming control-ﬂow integrity. In 35th IEEE Symposium on
Security and Privacy, S&P, 2014.
[25] A. Homescu, S. Brunthaler, P. Larsen, and M. Franz.
Librando:
In ACM
transparent code randomization for just-in-time compilers.
SIGSAC Conference on Computer and Communications Security, CCS,
2013.
[26] R. Hundt, E. Raman, M. Thuresson, and N. Vachharajani. MAO –
an extensible micro-architectural optimizer. In 9th Annual IEEE/ACM
International Symposium on Code Generation and Optimization, CGO,
2011.
[27] C. Kil, J. Jun, C. Bookholt, J. Xu, and P. Ning. Address space layout
permutation (ASLP): towards ﬁne-grained randomization of commodity
software. In 22nd Annual Computer Security Applications Conference,
ACSAC, 2006.
[28] V. Kuznetsov, L. Szekeres, M. Payer, G. Candea, R. Sekar, and D. Song.
In 11th USENIX Symposium on Operating
Code-pointer integrity.
Systems Design and Implementation, OSDI, 2014.
[29] P. Larsen, A. Homescu, S. Brunthaler, and M. Franz. SoK: Automated
software diversity. In 35th IEEE Symposium on Security and Privacy,
S&P, 2014.
[30] B. Lee, L. Lu, T. Wang, T. Kim, and W. Lee. From zygote to morula:
Fortifying weakened aslr on android. In IEEE Symposium on Security
and Privacy, S&P, 2014.
[31] K. Lu, C. Song, B. Lee, S. P. Chung, T. Kim, and W. Lee. ASLR-Guard:
Stopping address space leakage for code reuse attacks. In ACM SIGSAC
Conference on Computer and Communications Security, CCS, 2015.
[32] S. Maleki, Y. Gao, M. J. Garzarán, T. Wong, and D. A. Padua. An
evaluation of vectorizing compilers. In 2011 International Conference
on Parallel Architectures and Compilation Techniques, PACT, 2011.
15
[38] K. Onarlioglu, L. Bilge, A. Lanzi, D. Balzarotti, and E. Kirda. G-Free:
Defeating return-oriented programming through gadget-less binaries. In
26th Annual Computer Security Applications Conference, ACSAC, 2010.
[39] V. Pappas, M. Polychronakis, and A. D. Keromytis. Smashing the
gadgets: Hindering return-oriented programming using in-place code
randomization. In 33rd IEEE Symposium on Security and Privacy, S&P,
2012.
[40] O. Peles and R. Hay. One class to rule them all: 0-day deserialization
In Workshop on Offensive Technologies,
vulnerabilities in android.
WOOT, 2015.
[41] J. Pewny and T. Holz. Control-ﬂow restrictor: Compiler-based CFI
In 29th Annual Computer Security Applications Conference,
for iOS.
ACSAC, 2013.
[42] S. Quirem, F. Ahmed, and B. K. Lee. Cuda acceleration of p7viterbi al-
gorithm in hmmer 3.0. In Performance Computing and Communications
Conference, IPCCC, 2011.
[43] R. Roemer, E. Buchanan, H. Shacham, and S. Savage. Return-oriented
programming: Systems, languages, and applications. ACM Transactions
on Information System Security, 15, 2012.
[44] N. Santos, H. Raj, S. Saroiu, and A. Wolman. Using ARM TrustZone to
build a trusted language runtime for mobile applications. In Architectural
Support for Programming Languages and Operating Systems, ASPLOS,
2014.
[45] F. B. Schneider. Enforceable security policies. ACM Trans. Inf. Syst.
Secur., 3, 2000.
[33] A. J. Mashtizadeh, A. Bittau, D. Boneh, and D. Mazières. CCFI:
In ACM SIGSAC
cryptographically enforced control ﬂow integrity.
Conference on Computer and Communications Security, CCS, 2015.
[34] M. Meissner. Tricks of a Spec master.
https : / / gcc . gnu . org / wiki / summit2010 ? action = AttachFile&do =
get&target=meissner2.pdf.
[35] V. Mohan, P. Larsen, S. Brunthaler, K. Hamlen, and M. Franz. Opaque
control-ﬂow integrity. In 22nd Annual Network and Distributed System
Security Symposium, NDSS, 2015.
[36] NaCL. Implementation and safety of nacl sﬁ for x86-64, 2015. https:
//groups.google.com/forum/#!topic/native-client-discuss/C-wXFdR2lf8.
[37] Nergal. The advanced return-into-lib(c) exploits: PaX case study. Phrack
Magazine, 11, 2001.
[46] F. Schuster, T. Tendyck, C. Liebchen, L. Davi, A.-R. Sadeghi, and
T. Holz. Counterfeit object-oriented programming: On the difﬁculty
In 36th IEEE
of preventing code reuse attacks in C++ applications.
Symposium on Security and Privacy, S&P, 2015.
[47] D. Sehr, R. Muth, C. Bifﬂe, V. Khimenko, E. Pasko, K. Schimpf, B. Yee,
and B. Chen. Adapting software fault isolation to contemporary cpu
architectures. In 18th USENIX Security Symposium, USENIX Sec, 2010.
Information leaks without
memory disclosures: Remote side channel attacks on diversiﬁed code. In
ACM SIGSAC Conference on Computer and Communications Security,
CCS, 2014.
[48] J. Seibert, H. Okhravi, and E. Söderström.
[49] H. Shacham, M. Page, B. Pfaff, E. Goh, N. Modadugu, and D. Boneh.
On the effectiveness of address-space randomization. In ACM SIGSAC
Conference on Computer and Communications Security, CCS, 2004.
[50] K. Z. Snow, F. Monrose, L. Davi, A. Dmitrienko, C. Liebchen, and
A. Sadeghi.
Just-in-time code reuse: On the effectiveness of ﬁne-
grained address space layout randomization. In 34th IEEE Symposium
on Security and Privacy, S&P, 2013.
[51] C. Song, C. Zhang, T. Wang, W. Lee, and D. Melski. Exploiting and
In 22nd Annual Network and
protecting dynamic code generation.
Distributed System Security Symposium, NDSS, 2015.
[52] R. Strackx, Y. Younan, P. Philippaerts, F. Piessens, S. Lachmund, and
T. Walter. Breaking the memory secrecy assumption. In 2nd European
Workshop on System Security, EUROSEC, 2009.
[53] R. Wahbe, S. Lucco, T. E. Anderson, and S. L. Graham. Efﬁcient
software-based fault isolation. In 14th ACM Symposium on Operating
System Principles, SOSP, 1993.
[54] L. Zhao, G. Li, B. De Sutter, and J. Regehr. Armor: Fully veriﬁed
In 9th ACM International Conference on
isolation.
software fault
Embedded Software, EMSOFT, 2011.
[55] Y. Zhou, X. Wang, Y. Chen, and Z. Wang. Armlock: Hardware-based
fault isolation for arm. In ACM SIGSAC Conference on Computer and
Communications Security, CCS, 2014.