the other sub-ORAMs as well to ensure consistency. This is
challenging because the sub-ORAMs are initialized with their
own random seeds, and hence the location of a particular block
Further, in the presence of a stateless or limited-storage
client, the position maps associating logical to physical ad-
dresses in each of the sub-ORAM trees must also be stored
obliviously on the server. This is a well-known problem with
tree-based ORAMs like Path ORAM. Locating and updating
a block in all
the sub-ORAMs using their corresponding
position maps will unfortunately result in O(log3 N ) seeks
and communication overhead.
To tackle this, rORAM introduces a new distributed position
map. First, each block in each sub-ORAM stores additional
information allowing rORAM to immediately look up the
physical location of that same block in the other ORAMs,
not unlike the case of pointer-based oblivious data structures
[44]. Second, note that if a client accesses a range using the ith
sub-ORAM, the positions of the blocks in the accessed range
need to be updated only in the ith sub-ORAM. The range needs
to be evicted to the other trees as well, but there is no need
to refresh the positions in the other sub-ORAMs since they
are still hidden and look random to the adversary – the range
has not been read from those trees, and the (deterministic)
eviction schedule is independent of the positions.
As a result, rORAM needs only O(log2 N ) seeks for the
position map accesses and updates per operation, matching
the asymptotic cost of the data access itself.
Simplicity of construction & evaluation. A key advantage of
rORAM is the simplicity of implementation and deployment.
Prior solutions [9] are amortized and use complex building
blocks (such as locality-friendly oblivious sort etc.)
rORAM mechanisms can be implemented with simple yet
effective modiﬁcations to existing tree-based ORAM designs.
rORAM is evaluated in detail for real workloads, and com-
pared against standard ORAMs. rORAM is 30-50x times faster
than Path ORAM for similar range query workloads on local
HDDs, 30x faster for local SSDs, and 10x faster for network
block devices. Further, the rORAM locality-aware physical
layout can be deployed independently to speed-up standard
Path ORAM by a factor of 2x. Finally, application benchmarks
demonstrate that rORAM is up to 5x faster running a ﬁle server
and up to 11x faster running a range-query intensive video
server workloads compared to Path ORAM.
C. Summary
Based on the construction presented herein, rORAM makes
the following contributions:
1) A new oblivious range ORAM construction that opti-
mizes data locality and is faster by a factor of O(log N )
over previous results [9] (Table I).
3
2) A new locality-preserving sub-ORAM design based on
bit-reversed lexicographic ordering that achieves: i) a
highly-optimized physical disk layout
for efﬁciently
batching evictions, and ii) an efﬁcient tree paths mapping
mechanism for ensuring data locality in range queries.
3) A new distributed position map construction for efﬁ-
ciently locating block replicas in multiple ORAMs.
4) An open-source implementation of rORAM. To the best
of our knowledge, rORAM is the ﬁrst implementation of
a Range ORAM construction.
5) Micro-benchmarks showing signiﬁcant performance in-
crease for range-query workloads compared to standard
ORAMs. For example, rORAM is 30-50x faster than Path
ORAM for range queries of size ≥ 210 blocks on local
HDDs, 30x faster for local SSDs, and 10x faster for
network block devices.
6) Application benchmarks showing suitability for
real
world applications: rORAM is up to 5x faster running
a ﬁle server and up to 11x faster running a range-query
intensive video server across several platforms.
II. PRIOR WORK
Oblivious RAM (ORAM) and applications. ORAM protects
the access pattern so that it is infeasible to guess which oper-
ation is occurring and on which item. Since the seminal work
by Goldreich and Ostrovsky [27], many works have focused
on improving ORAM efﬁciency (e.g., [10, 34, 38, 42, 45]).
ORAM plays as an important tool to achieve secure cloud
storage [31, 39] and secure multi-party computation [22, 30,
42] and secure processors [24, 29]. There also have been works
to hide the access pattern of protocols accessing individual
data structures, e.g., maps, priority queues, stacks, and queues
and graph algorithms on the cloud server [35, 44].
Locality in searchable encryption. Data locality has been a
useful metric for evaluating searchable symmetric encryption
[8, 14, 19]. In these models,
the client stores their data
remotely and encrypted, but the server can perform searches
upon the data (e.g., a keyword search) without revealing the
plain text. While related, searchable symmetric encryption
does not protect against access patterns, e.g., revealing whether
the same data item has been accessed multiple times.
ORAMs with locality.
In the closest related work to this
one, Asharov et al. [9] ﬁrst introduced the weaker security
model for range ORAMs by which the size of the range is
leaked to provide data locality. Their construction, built on
top of a hierarchical ORAM construction [27], also makes use
O(log N ) series of ORAMs by which each ORAM forms the
layer in the tree. Locality is achieved by storing the ranges on
each level as increasingly larger blocks of size 2i. They show
that the number of seeks per access is O(log3 N·(log log N )2).
Further, [9] proposes a more relaxed deﬁnition for File
ORAMs where the sizes of individual ﬁles are revealed per
access. This results in better asymptotic performance at the
cost of less access ﬂexibility. First, File ORAMs do not
provide any opportunity for padding accesses in contrast to the
variable-length padding options available for range ORAMs –
access to individual ﬁles/metadata of different sizes are always
distinguishable and multiple accesses to the same ﬁle can be
linked using the ﬁle size. Second, File ORAMs cannot support
efﬁcient arbitrary-sized reads/edits to portions of large ﬁles –
ﬁles are always accessed in their entirety. In this work, we
adapt the security setting and ﬂexibility of range ORAMs but
with a more efﬁcient construction. We primarily compare our
work against the range ORAM construction in [9].
Data locality has been used previously as a performance
metric in the setting of write-only ORAMs. In this security
model, reads are assumed to be unobservable by an attacker,
but writes to data can be observed and must be obfuscated.
First introduced by Blass et al. [11] in the context of protecting
hidden volumes, a randomized procedure was used to achieve
obliviousness. Later, Roche et al. [36] showed that write-
obliviousness can be achieved with deterministic, sequential
writing patterns. However, the data locality of reads was not
evaluated, and depends largely on the write pattern itself.
Improvements for the position map have been produced by
using temporal locality. FreeCursive [24] employs a PosMap
Lookaside Buffer (PLB) to reduce the overhead of using
a position map. While leveraging temporal locality in the
position map, this work does not provide spatial data locality.
ORAMs have also been used to expand searchable encryp-
tion with locality. Work by Demertzis et al. [21] proposed a
hierarchical square-root ORAM [27] to support searchable en-
cryption. This scheme makes use of locality-preserving version
of Melbourne Shufﬂe [33] to achieve O(1) seeks, but requires
O(N 1/3 log2 N ) communication and local storage with higher
server storage. It also does not support range queries naturally,
which adds a multiplicative cost to communications and seeks.
III. BACKGROUND & SECURITY DEFINITIONS
ORAM. An Oblivious RAM (ORAM) protocol allows a client
to store and manipulate an array of N blocks on an untrusted,
honest-but-curious server without revealing the data or access
patterns to the server. Speciﬁcally, the logical array of N
blocks is indirectly stored into a specialized back-end data
structure on the server, and an ORAM scheme speciﬁes an
access protocol that implements each logical access with a
sequence of physical accesses to that back-end structure. An
ORAM scheme is secure if for any two sequences of logical
accesses of the same length, the physical accesses produced
by the protocol are computationally indistinguishable.
More formally, let ~y = (y1, y2, . . .) denote a sequence of
operations, where each yi is a Read(ai) or a Write(ai, di);
here, ai ∈ [0, N ) denotes the logical address of the block
being read or written, and di denotes a block of data being
written. For an ORAM scheme Π, let AccessΠ(~y) denote the
physical access pattern that its access protocol produces for
the logical access sequence ~y. We say the scheme Π is secure
if for any two sequences of operations ~x and ~y of the same
length, it holds
AccessΠ(~x) ≈c AccessΠ(~y),
where ≈c denotes computational indistinguishability (with
respect to the security parameter λ).
4
A. Range ORAM and Locality
Let
In this work, we study ORAMs speciﬁcally suited for
accessing sequential ranges of data. This requires a slightly
different security deﬁnition to capture the fact
that range
ORAMs access ranges of blocks instead of just single blocks.
let ~y = (y1, y2, . . .) denote a sequence of opera-
tions, where each yi represents an access to a range of
sequential blocks. Let yi be either ReadRange(ai, ℓi) or
WriteRange(ai, ℓi, d1, . . . , dℓi). Here, ai refers to a logical
block as before, but additionally ℓi indicates the number of
sequential blocks to access starting with ai. d1, . . . , dℓi are
the blocks of data to be written to the logical addresses
ai, ai + 1, . . . , ai + ℓi.
Let len(yi) signify the length ℓi for of the range access yi.
A Range ORAM scheme Π is secure if for any two sequences
of operations ~x and ~y of the same length, subject to the
following constraint:
∀i : ⌈log2(len(yi))⌉ = ⌈log2(len(xi))⌉
it holds that
AccessΠ(~x) ≈c AccessΠ(~y),
where ≈c denotes computational
respect to the security parameter λ).
indistinguishability (with
Informally, this means that a Range ORAM can leak the
rough size of the ranges that are being accessed by each
operation. That is, the length of two accesses only needs
to be within (2k, 2k+1] for some k in order for them to be
indistinguishable. In other words, O(log ℓi) bits are leaked per
access, which is the order of magnitude of the range.
Locality and seeks. Locality of an algorithm is well deﬁned
in prior works [9, 19]. Informally, this is the number of seeks
required on the storage medium during the execution of that
algorithm. If an ORAM algorithm performs accesses to the
physical storage at the addresses ~z = (z1, z2, . . .), in that order,
then a seek is deﬁned as an index i such that zi+1 6= zi+1. The
total number of seeks across ~z is the locality of the algorithm.
B. Path ORAM
One of the most efﬁcient ORAM constructions currently
known is Path ORAM, presented in the seminal work of
Stefanov et al. [41]. Path ORAM works by storing data blocks
in a complete binary tree with N leaf nodes (or buckets).
Each bucket in the tree has space for a small constant number
of blocks, denoted Z. During initialization, leaf buckets are
numbered 0 to N − 1 and blocks are each given random tags
(or positions) from the range [0, N ). In addition, there is a
single small stash area which holds some blocks temporarily.
The tree maintains an invariant that if a block has tag p, it will
exist either in the stash or somewhere along the path from the
root of the tree to the pth leaf node.
Data access and eviction.
In order to retrieve a block, the
client must ﬁrst determine the path position tag t for the block.
This is done by maintaining a map, called the position map,
that relates logical block addresses to their random positions.
Once the tag t has been found, the client retrieves the entire
path from root to the tth leaf node and stores the buckets
on this path locally. The requested logical block is accessed
by scanning the retrieved buckets. The chosen block is then
assigned to a new random leaf node (i.e. a tag), and its tag
is updated accordingly and stored back in the position map.
Finally the updated block itself is appended to the stash area.
Note that this occurs invariably as the tag is reassigned for
every access in order to hide the access pattern.
Because the stash has a ﬁxed size, eventually it is necessary
to evict blocks from the stash back to the tree buckets.
In the simplest setting, every data access (which involves
appending one new block to stash) is followed immediately
by rewriting, or evicting, along a single path in the tree. In
this step, the client picks a path in the tree (either randomly
or deterministically using bit-reversed ordering [26, 41]) and
retrieves the buckets for that path from the storage device. The
existing blocks in that path are then re-ordered, along with the
blocks in stash, so that every block is stored as far down in
the path as it can go, subject to the invariant and the size of
the buckets. Any block which still does not ﬁt in the path is
stored back to the stash area.
Bucket and stash size. Because each bucket has a ﬁxed
size, as does the stash area, it is possible for the scheme
to “break” by running out of room in the stash, a situation
referred to as stash overﬂow. The original Path ORAM used
a random eviction strategy and showed that if the bucket
size is at least Z ≥ 5, the probability of stash overﬂow
decreases exponentially in the stash size [41]. The Ring
ORAM construction improved this further, demonstrating that
Z ≥ 3 is sufﬁcient with a deterministic eviction strategy [34].
Position map. The map storing each block’s tag can be quite
large; it is N log2 N bits long. If the client is not capable of
storing the map locally, it can be stored recursively in a series
of O(log N ) smaller ORAMs on the server. Alternatively,
one can use an oblivious data structure (more speciﬁcally, an
oblivious trie [36, 41]) to store the position map. In either
solution, the total communication overhead for a single access
with Path ORAM is O(log2 N ).
Access Complexity. ORAMs are typically evaluated in
terms of bandwidth – the number of data blocks that are
downloaded/uploaded in order to complete one logical request.
Path ORAM features an overall bandwidth of O(log N ) data
blocks, where N is the total number of blocks in the ORAM.
This asymptotic bound holds only under the large block size
assumption when the data blocks size is Ω(log2 N ) bits.
rORAM has the same large block size assumption and all
access complexities reported in this paper indicate the number
of physical blocks that are accessed overall for fulﬁlling a
particular logical request.
Seeks. If Path ORAM is used as a Range ORAM to retrieve
a sequential range of blocks, each block is stored along a
random path, and it would require O(r · log N ) seeks to fetch
data blocks, where r is the number of blocks in the range. If
the position map is stored server-side recursively, the position
map access will additionally require O(r · log2 N ) seeks. A
locality-friendly ORAM, as we achieve here, should require a
number of seeks independent of the range size r.
5
IV. RORAM CONSTRUCTION OVERVIEW
In this section, we describe the basic, core construction
details for rORAM. We start with multiple Path ORAM trees
as building blocks, designating each ORAM for range queries
of a speciﬁc size. This allows us to design and optimize a
particular sub-ORAM for range queries of a given size.
To this end, we show how to achieve data locality for both
queries and evictions for each of the sub-ORAMs. This is
the result of two key insights – i) using a locality-aware disk
layout that dramatically reduces the number of seeks required
for performing multiple evictions in batches, and ii) a novel
locality-sensitive block mapping mechanism which reduces
seeks when querying for blocks in a range.
Finally, we describe a novel distributed position map scheme
for efﬁcient query and update of the multiple sub-ORAMs.
A. Core Construction
Multiple ORAMs each covering a subset of ranges. We use
multiple sub-ORAMs to store ranges of a speciﬁc length, as
with the prior work [9]. Let N be the total number of blocks
stored in the rORAM, and L ≤ N be a parameter indicating
the maximum range size that will be supported. Then the
rORAM construction makes use of ℓ + 1 Path ORAMs, where
ℓ = ⌈log2 L⌉;
these individual Path ORAMs are labeled