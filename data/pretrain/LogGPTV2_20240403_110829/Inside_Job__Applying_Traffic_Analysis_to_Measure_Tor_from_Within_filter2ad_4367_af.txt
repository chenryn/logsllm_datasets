Rendezvous / End
Rendezvous Client / Exit + Rendezvous Client
Rendezvous Service / Exit + Rendezvous Service
Purpose is Rendezvous / Total
SNS Popularity (as % of onion circuits)
Rend. Service to SNS ASN / Rend. Service
Site is SNS / Total
Direct
Direct
Direct
Direct
Classiﬁed
Direct
Classiﬁed
1.34%
1.45%
1.20%
1.20%
4.48%
0.52%
0.02%
rate was 3.4%, and the true positive and false negative rates for
the SNS classiﬁer were 60% and 40%, respectively. With these
results, we are optimistic that our classiﬁers are functioning as
intended. We assert that an adversary who is not concerned
with privacy (and does not add noise) would be able to make
much more precise measurements than we describe here.
3) Popularity: We estimate the popularity of the onion
service protocol by computing the fraction of middle relay
circuits that are rendezvous circuits. Middle relays that do not
serve as the rendezvous point on a circuit cannot determine
with certainty whether or not the circuit is a rendezvous circuit,
but they can predict it by running our circuit purpose classiﬁer.
As previously discussed, we also measure the popularity of the
onion service protocol independently and directly when our
relays do serve as rendezvous points, since in that case our
relays can distinguish client-side and server-side rendezvous
circuits from others.
Our popularity estimates are shown in Table IX. The entries
in the table show several ways one could estimate popularity,
with our classiﬁcation-based estimates at the bottom of each
section. The direct measurement approaches indicate that onion
service popularity is between 1% and 1.5% based on circuit
counts; for comparison, 0.9% of Tor trafﬁc by volume (i.e.,
bytes) is onion service trafﬁc (900 Mbit/s onion13 of 100
Gbit/s total14) according to Tor metrics. Our classiﬁcation-
based estimate is a bit higher at 4.48%, but we note this result
includes noise and an unknown number of false positives.
Similarly, our direct measurement of accesses to the SNS onion
site front-page is 0.52% of rendezvous service circuits whereas
our classiﬁcation-based estimate is 0.02%.
F. Discussion
Our laboratory results from the previous sections show that
WF at the middle relay position is just as effective w.r.t. recall
and precision as has been shown from the guard position in
previous works—both for closed- and open-world scenarios.
On the other hand, our real-world results indicate that the base-
rate of the site we chose (i.e., the SNS) was too low for our
classiﬁer to provide high conﬁdence for its counter. However,
what we can learn with high conﬁdence is that the popularity
of the SNS as an onion service is almost negligible when
comparing SNS onion service circuits to all other onion service
circuits. This result was unexpected: our intuition for picking
this particular SNS was that it is known to be one of the most
popular websites in the world. Our results show that a much
lower FPR—up to two orders of magnitude lower—is neces-
sary for WF to be useful in measuring individual onion sites.
13https://metrics.torproject.org/hidserv-rend-relayed-cells.html
14https://metrics.torproject.org/bandwidth.html
13
IX. CONCLUSION
VIII. RELATED WORK
Although there are many studies that explore the extent to
which trafﬁc analysis can leak information on Tor [12], [23],
[24], here we focus on website and onion site ﬁngerprinting.
A. Tor Website Fingerprinting Attacks
The ﬁrst WF attack on Tor was proposed and evaluated
by Herrmann et al. and only achieved 3% success rate [15].
This research area has since seen great activity and the latest
WF studies achieve more than 90% accuracy under speciﬁc
conditions and scenarios [4], [14], [26], [28], [29], [30].
Recent work attempted to address WF on non-onion web-
sites in an open world model and increases the scalability of
evaluation approaches [26], but the closed world model has
been considered realistic for the evaluation of WF on onion
services [6] due to their limited number. It has been shown
that a local and passive adversary can effectively detect onion
service visits using circuit ﬁngerprinting, and then apply web-
site ﬁngerprinting methods to infer to which website they be-
long [22]. Errors when classifying onion service websites have
been explored in order to further improve WF techniques [25],
but the practicality of monitoring a realistic number of sites
even in the smaller onion service world is still in question [27].
To the best of our knowledge, we are the ﬁrst to apply
circuit, position, and WF techniques from middle relays, and
we are the ﬁrst to use our classiﬁcation techniques on trafﬁc
initiated from real Tor users. While we apply our techniques
for measurement purposes, recent work has shown how our
techniques can be used to further target speciﬁc users [17].
B. Tor Website Fingerprinting Defenses
Several defenses have been designed to mitigate WF at-
tacks. Most of these defenses are based on link padding [10],
[21], [29], that is, adding dummy messages that are indistin-
guishable from real ones in order to make the features that
WF exploit ineffective. Prior work assumes that the middle
collaborates in the defense and removes the padding, in which
case our techniques would not be affected. End-to-end padding
that does not depend on collaborating Tor infrastructure [6]
could disrupt the trafﬁc analysis techniques we leverage, but
would come at a prohibitively-high performance cost.
Restricted routing—e.g., if middles were chosen and used
long term as is currently the case with guards—would limit the
number of users from which a middle could observe circuits.
In that case, middles could lose much of the advantage over
guards as preferential observation points.
C. Onion Site Enumeration
Existing HSDir lookup protocols have been shown to be
vulnerable to attack by an adversary running low-bandwidth
relays [3]. By exploiting the lookup protocols, an adversary
running an HSDir can directly measure the popularity of the
onion services whose addresses are assigned to it. Previous
work has used this approach to better understand the popularity
of content in the onion service ecosystem [2]. These attacks
can be mitigated by changes in the HSDir protocol.
Tor is currently deploying next-generation onion services
in order to limit the effectiveness of onion service enumeration
attacks, but the planned defenses will not signiﬁcantly change
the ﬂow of cells through a circuit (like padding does) and
therefore we believe that they will not signiﬁcantly affect the
accuracy of our techniques.
14
We have shown that a signiﬁcant amount of information is
leaked to middle relay positions, although the extent of this
threat is often overlooked. We describe how the design of Tor
admits to middle relays a wider visibility over all users of
the network because clients pick new middle relays for every
circuit that they build. We have shown through extensive data
collection and experimentation that trafﬁc analysis techniques
are as effective from internal middle positions as they are from
ingress and egress (guard and exit) positions. In particular, we
have built a trafﬁc analysis pipeline that can detect a relay’s
position in a circuit, the purpose of the circuit, and identiﬁes
the onion service being accessed through a circuit. We have
then put the pipeline into practice to measure the popularity of
a well-known social network onion service: we are the ﬁrst to
apply these trafﬁc analysis techniques on real Tor user trafﬁc to
the best of our knowledge. Although our measurement results
are constrained in scale and accuracy due to resource and
ethical concerns (constraints not shared by malicious actors),
our framework provides the means to study effective mitigation
to potential threats and to gather additional measurements.
A. Lessons Learned
It is clear that more progress needs to be made and this
present work provides positive ﬁrst steps in that direction.
We anticipate that classiﬁcation techniques at middle relay
positions will not deteriorate and point out some of the
challenges to deploying them in the real-world. First, our
pipeline was created in order to reduce the number of circuits
that need to be processed by the WF classiﬁer; we ﬁlter out real
user circuits for training and non-onion service circuits with
the circuit classiﬁer during testing. This greatly reduced the
overhead both in training and testing and improved our results.
Therefore, careful ﬁltering and data pre-processing are keys to
successful real-world deployments. Second, our measurement
was done in real-time: everything was kept in RAM, and we
used a low circuit sampling rate of 0.12 due to computational
and memory limitations. We found that real-world scale may
overwhelm available resources and pragmatic compromises
may need to be made. Third, we were very concerned with
user safety in our real-world measurements and hence our
results are noisy. Depending on the use-case (e.g., a malicious
actor), noise may not be necessary; removing this requirement
would reduce the operational overhead of running the privacy-
preserving apparatus and may allow higher sampling rates.
B. Future Work
Using our current WF classiﬁcation pipeline, an adversary
could target the guards that originate connections to websites
of interest (e.g., the SNS). We have shown that there are a
small number of SNS circuits, and therefore the set of guards
used to access the SNS would also be small. An adversary
could reduce the time and cost of a targeting attack by focusing
on only these guards rather than, e.g., compromising guards
at random and waiting until it is used to access a website
of interest. Some related target attacks that depend on our
techniques have recently been explored [17].
An alternative to compromising guards that route interest-
ing connections is locating the originating client or destination
onion service using middle relay network latency measure-
ments. Hopper et al. [16] show the effectiveness of such
attacks from malicious websites. Mapping latency between
an adversarial middle and all Tor relays (or at
the
least
most popular) [5] would assist in narrowing the network and
geographic location of circuit originators (e.g., to a region or
possibly a country).
An adversary could ﬁngerprint protocols instead of web-
sites to target a broader base of users. For example, a censoring
regime may ﬁngerprint Tor’s pluggable transports (PT) from
the middle relay positions. Fingerprinting PTs from the client-
side—which is the current state-of-the-art—has a high FPR
since PTs are designed to be confused with other protocols that
the censor is reluctant to block. In contrast, ﬁngerprinting PTs
at a middle does not provide this same confusion since only Tor
trafﬁc is present in the Tor network and the protocols that the
censor is reluctant to block (e.g., HTTPS) are not present. As-
suming that the censor already has the ability to identify users
on the client-side, the censor could greatly reduce the incidence
of false positives in detecting PT circuits. Furthermore, using
timing correlations between client-side observations could also
identify PT users, and an adversary could use our ﬁngerprinting
techniques to identify which websites PT users visit.
ACKNOWLEDGMENTS
We thank the anonymous reviewers for their helpful feed-
back. We thank Roger Dingledine from the Tor Research
Safety Board for providing feedback that helped to make
our measurement safer and more transparent. We thank Tim
Wilson-Brown for the suggestion to directly measure the SNS,
for implementing much of the Tor and PrivCount code that we
used during our measurement, and for the helpful suggestions
and feedback on our approach. We thank Tim Wilson-Brown
and Matt Traudt for operating Tor relays and PrivCount nodes
as part of our PrivCount deployment.
This work has been partially supported by the Defense
Advanced Research Project Agency (DARPA) and the National
Science Foundation (NSF) under grant number CNS-1527401.
This material is based upon work supported by the European
Commission through KU Leuven BOF OT/13/070, H2020-DS-
2014-653497 PANORAMIX, and H2020-ICT-2014-644371
WITDOM. Juarez is supported by a PhD fellowship of the
Fund for Scientiﬁc Research - Flanders (FWO), and Elahi
is supported by NSERC through a Postdoctoral Fellowship
Award, the Research Council KU Leuven: C16/15/058. The
views expressed in this work are strictly those of the authors
and do not necessarily reﬂect the ofﬁcial policy or position of
any employer or funding agency.
REFERENCES
[1]
“TC: A Tor control protocol (Version 1),” https://gitweb.torproject.org/
torspec.git/tree/control-spec.txt.
[2] A. Biryukov, I. Pustogarov, F. Thill, and R.-P. Weinmann, “Content and
popularity analysis of Tor hidden services,” in International Conference
on Distributed Computing Systems Workshops, 2014.
[3] A. Biryukov, I. Pustogarov, and R.-P. Weinmann, “Trawling for Tor
Hidden Services: Detection, Measurement, Deanonymization,” in Sym-
posium on Security and Privacy, 2013.
[4] X. Cai, X. C. Zhang, B. Joshi, and R. Johnson, “Touching from a
Distance: Website Fingerprinting Attacks and Defenses,” in Conference
on Computer and Communications Security, 2012.
[5] F. Cangialosi, D. Levin, and N. Spring, “Ting: Measuring and exploiting
latencies between all tor nodes,” in Internet Measurement Conference,
2015.
[6] G. Cherubin, J. Hayes, and M. Juarez, “Website Fingerprinting De-
fenses at the Application Layer,” in Proceedings on Privacy Enhancing
Technologies, 2017.
[7] R. Dingledine, N. Hopper, G. Kadianakis, and N. Mathewson, “One fast
guard for life (or 9 months),” in Workshop on Hot Topics in Privacy
Enhancing Technologies, 2014.
[8] R. Dingledine, N. Mathewson, and P. Syverson, “Tor: The Second-
Generation Onion Router,” in USENIX Security Symposium, 2004.
[9] C. Dwork, “Differential privacy,” in International Colloquium on Au-
tomata, Languages and Programming, 2006.
[10] K. Dyer, S. Coull, T. Ristenpart, and T. Shrimpton, “Peek-a-Boo, I
Still See You: Why Efﬁcient Trafﬁc Analysis Countermeasures Fail,”
in Symposium on Security and Privacy, 2012.
[11] T. Elahi, G. Danezis, and I. Goldberg, “Privex: Private collection of traf-
ﬁc statistics for anonymous communication networks,” in Conference
on Computer and Communications Security, 2014.
[12] N. S. Evans, R. Dingledine, and C. Grothoff, “A practical congestion
attack on tor using long paths.” in USENIX Security Symposium, 2009.
[13] D. Goulet, A. Johnson, G. Kadianakis, and K. Loesing, “Hidden-service
[14]
statistics reported by relays,” Tor Project, Tech. Rep., April 2015.
J. Hayes and G. Danezis, “k-ﬁngerprinting: a Robust Scalable Website
Fingerprinting Technique,” in USENIX Security Symposium, 2016.
[15] D. Herrmann, R. Wendolsky, and H. Federrath, “Website Fingerprinting:
Attacking Popular Privacy Enhancing Technologies with the Multi-
nomial Na¨ıve-Bayes Classiﬁer,” in Workshop on Cloud Computing
Security, 2009.
[16] N. Hopper, E. Y. Vasserman, and E. Chan-Tin, “How much anonymity
does network latency leak?” Transactions on Information and System
Security, vol. 13, no. 2, 2010.
[17] A. D. Jaggard and P. Syverson, “Onions in the Crosshairs: When The
Man really is out to get you,” in Workshop on Privacy in the Electronic
Society, 2017.
[18] R. Jansen and N. Hopper, “Shadow: Running Tor in a box for accurate
and efﬁcient experimentation,” in Network and Distributed System
Security Symposium, 2012.
[19] R. Jansen and A. Johnson, “Safely Measuring Tor,” in Conference on
Computer and Communications Security, 2016.
[20] M. Juarez, S. Afroz, G. Acar, C. Diaz, and R. Greenstadt, “A Critical
Analysis of Website Fingerprinting Attacks,” in Conference on Com-
puter and Communications Security, 2014.
[21] M. Juarez, M. Imani, M. Perry, C. Diaz, and M. Wright, “Toward an
efﬁcient website ﬁngerprinting defense,” in European Symposium on
Research in Computer Security, 2016.
[22] A. Kwon, M. AlSabah, D. Lazar, M. Dacier, and S. Devadas, “Circuit
ﬁngerprinting attacks: passive deanonymization of tor hidden services,”
in USENIX Security Symposium, 2015.
[23] P. Mittal, A. Khurshid,
Juen, M. Caesar, and N. Borisov,
“Stealthy trafﬁc analysis of low-latency anonymous communication
using throughput ﬁngerprinting,” in Conference on Computer and
Communications Security, 2011.
J.
[24] S. J. Murdoch and G. Danezis, “Low-cost trafﬁc analysis of tor,” in
Symposium on Security and Privacy, 2005.
[25] R. Overdorf, M. Juarez, G. Acar, R. Greenstadt, and C. Diaz, “How
Unique is Your. onion? An Analysis of the Fingerprintability of Tor
Onion Services,” in Conference on Computer and Communications
Security, 2017.
[26] A. Panchenko, F. Lanze, A. Zinnen, M. Henze, J. Pennekamp,
K. Wehrle, and T. Engel, “Website Fingerprinting at Internet Scale,”
in Network and Distributed System Security Symposium, 2016.
[27] A. Panchenko, A. Mitseva, M. Henze, F. Lanze, K. Wehrle, and T. En-
gel, “Analysis of Fingerprinting Techniques for Tor Hidden Services,”
in Workshop on Privacy in the Electronic Society, 2017.
[28] A. Panchenko, L. Niessen, A. Zinnen, and T. Engel, “Website Fin-
gerprinting in Onion Routing Based Anonymization Networks,” in
Workshop on Privacy in the Electronic Society, 2011.
[29] T. Wang, X. Cai, R. Nithyanand, R. Johnson, and I. Goldberg, “Effective
Attacks and Provable Defenses for Website Fingerprinting,” in USENIX
Security Symposium, 2014.
[30] T. Wang and I. Goldberg, “Improved Website Fingerprinting on Tor,”
in Workshop on Privacy in the Electronic Society, 2013.
[31] ——, “On Realistically Attacking Tor with Website Fingerprinting,” in
Proceedings on Privacy Enhancing Technologies, 2016.
15