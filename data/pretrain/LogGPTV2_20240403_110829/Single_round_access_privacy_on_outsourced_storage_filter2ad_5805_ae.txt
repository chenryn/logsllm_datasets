 20
 40
 60
 80
 100
 120
 140
Network round trip (milliseconds)
 7
 6.5
 6
 5.5
 5
 4.5
 4
 3.5
 3
 2.5
 0
Figure 7: Comparison of amortized (online plus
oﬄine) cost of SR-ORAM to the ideal interactive
storage-free ORAM, assuming the hardware conﬁg-
uration of Figure 5. Left: query cost plotted as the
database size grows on a logarithmic X axis. Right:
comparison vs. latency for a ﬁxed database size.
key part from disk, server-side decryption, and transmit-
ting the results back to the client. The oﬄine performance
cost encompasses the disk, encryption, and network costs of
shuﬄing the items using a 4-pass random shell sort, and con-
structing the Bloom ﬁlter. The step shape results from the
additional level shuﬄed and queried every time the database
size doubles. While this no longer adds an additional round
trip, it does increase the query object size, require reading
an extra set of (e.g. 50) Bloom ﬁlter positions (key compo-
nents) from disk, and require additional construction time.
Discussion. Oﬄine shuﬄing in both the ideal storage-free
ORAM and SR-ORAM takes somewhat longer than that
described in [19] (who achieve over 1 query per second on a
1TB database) because we are eliminating their assumption
√
of client storage.
Instead of using a storage-based merge
scramble that requires log log n passes to sort n items, we
use a randomized shell sort, that requires ≈ 24 log n passes.
This is not a result of our technique—storage can be ap-
plied to speed up our result equivalently—but a result of
the diﬀerent model here, under which we do not provide
O(
n log n) client storage.
Online vs. oﬄine cost.
In the preceeding analysis we
consider the “online” cost to be the cost of performing an
individual query, and the “oﬄine” cost to be the cost of con-
structing the associated levels. However, the top level needs
to be rebuilt in between each query. That could perhaps
more appropriately be considered part of the online cost
rather than the oﬄine cost, resulting in a total of 1.5 round
trips. This is because the client must write back the new
version of the top level after each query. In the single-client
usage model considered in this paper, however, this write-
back can be included with the next item request, returning
our online cost to only a single round trip per query.
The rest of the level constructions can also be performed in
a small number of round trips, constant in the level size. De-
amortization techniques are compatible with this ORAM,
and eliminate the waiting during level shuﬄe. We recom-
mend an appropriate de-amortization technique be applied
to any implementation, but discussion is out of scope for
this paper.
7.1 Dealing with Reality
Although it is convenient to model disk data transfer costs
based only on the average disk throughput, this is not a
complete model, not even for solid state disks. In the solid
state disks we consider above, the disk sector size must be
considered: it speciﬁes the minimum size of a read or write
we can perform. That is, reads or writes of smaller amounts
cost the same as reading/writing the entire sector. This is
problematic for one piece of the SR-ORAM cost analysis:
the random shell sort of segments during the Bloom ﬁlter
construction. The Bloom ﬁlter segments (e.g., 32 bytes)
are potentially much smaller than a disk sector (e.g., 4096
bytes), and are accessed in a random pattern during the
random shell sort.
We now describe implementation details that avoid the
expense resulting from short disk reads. First, leading to a
simple but expensive potential solution, recall that the disk
costs are all server-side costs. This makes it plausible to
solve this cost discrepancy with additional hardware. For
example, a large amount of server RAM (e.g., 48 GB for
a 1TB database) would make it possible to cache the en-
tire Bloom ﬁlter during construction, requiring only a single
contiguous write at the end. A key point is that the Bloom
ﬁlter is smaller during these sort procedures than the ﬁnal
resulting Bloom ﬁlter will eventually be. For example, it is
blown up by about a factor of 4 when converting the bits
(with their, e.g., 64-bit positions) into (e.g., 256-bit) keys
at the end. This conversion process requires only a single,
sequential scan and write. This amount of RAM would re-
sult in a sort faster than the estimates used above (pushing
the bottleneck to client crypto speeds instead of disk I/O
speeds), which assume that disk transfer is required for each
of the ≈ 24 log2 n passes across the data in the random shell
sort. This is not necessarily an unreasonable scenario, as
the RAM is only used for the duration of the sort, making
it feasible to “pool” resources across many clients.
302A second option is to assume enough client memory to
build the Bloom ﬁlter locally. For a 1 TB database consist-
ing of 10KB blocks, and taking the acceptable failure rate to
−128, and 50 hash functions, the total number of Bloom
be 2
ﬁlter positions to set can be under 16 billion bits. This ﬁts in
2GB of client memory. Moreover, as this construction is now
done in private client memory, the oblivious Bloom ﬁlter sort
can be avoided, speeding up the Bloom ﬁlter construction
signiﬁcantly. This process now requires only the network
transfer, and sequential disk write of the key-storing Bloom
ﬁlter (.5TB). However, the client memory requirement for
that (cost-optimal) Bloom ﬁlter construction process is lin-
ear in the total database size, a trait we desire avoiding.
Fortunately, such a workaround is not necessary. We now
illustrate how the randomized shell sort can be performed
without incurring the overhead resulting from the minimum
sector size.
In exchange, we require extra server-side se-
quential scans of the data. Observe that a randomized shell
sort consists of dividing the array to be sorted (sized s) into
equal sized regions, and swapping items between the two re-
gions (called the “compareRegions” operation). The region
sizes start at s/2 and decrease all the way down to 1. In
any compareRegions operation, one region is read sequen-
tially, while the other region is read randomly. Likewise,
the regions are written back in the order they are read.
Two properties are key to eliminating disk seek and par-
tial sector read costs. First, observe that for regions that
ﬁt entirely in the server available cache sized M , the disk
seek / minimum sector cost can be avoided altogether with
an aggressive read-ahead page cache. This is because any
one region can be read and cached in its entirety, and small
regions are accessed contiguously.
Second, when the regions are too big to ﬁt in the server
page cache, the access pattern is still predictable by the
server. This means it can sort data according to the future
√
access pattern. Moreover, this sort can be performed in only
logM n passes. This is 2 passes whenever the server has
n
blocks of RAM, which we believe to be a more than rea-
sonable assumption. The idea is, in one pass, sort data in
groups sized M . In the second pass, merge these n/M re-
gions together, reading contiguous chunks from each region
into the page cache (the default behavior of a read-ahead
page cache). This way, during the shell sort, the items be-
ing read can be accessed contiguously.
For simplicity, the data is sorted back into its start loca-
tion after being written. The result is a sort that performs
eﬃciently, even when the sort item size is much smaller than
the disk sector size. The penalty is that now data is scanned
from the disk up to four times in each sort pass (but this is
more than made up for by the savings of not having to read
an entire disk sector for every access of a 32-byte element).
This cost is reﬂected in the graphs above.
A similar argument comes into play when modeling the
encryption/decryption throughput; our model considers the
sustained throughput over large blocks of data, while when
sorting the Bloom ﬁlter positions, many of the decryptions
and encryptions are on short (e.g.
64-bit) blocks. For-
tunately, the encryption block size (e.g., 256-bit) is much
closer to the encryption size, resulting in the actual crypto
throughput staying within a factor of 1/4 of the modeled
crypto throughput. This analysis is also reﬂected in our
graphs, which measure the entire cost of decrypting a ci-
pher block even when the amount of data to be decrypted
in a single operation is smaller than the block.
8. CONCLUSION
We introduced a new single-round-trip ORAM. We ana-
lyzed its security guarantees and demonstrated its utility.
While non-interactivity is of signiﬁcant theoretic interest in
itself, we also showed this to be the most eﬃcient Oblivious
RAM to date for a storage-free client over today’s Internet-
scale network latencies.
9. ACKNOWLEDGEMENTS
This work was supported in part by the NSF under awards
1161541, 0937833, 0845192, 0803197, 0708025. The authors
would also like to thank the anonymous reviewers for their
excellent feedback.
10. REFERENCES
[1] M. Ajtai, J. Komlos, and E. Szemeredi. An O(n log n)
sorting network. In Proceedings of the 25th ACM
Symposium on Theory of Computing, pages 1–9, 1983.
[2] Dimitri Asonov. Querying Databases Privately: A New
Approach to Private Information Retrieval. Springer
Verlag, 2004.
[3] B. H. Bloom. Space/time trade-oﬀs in hash coding
with allowable errors. Commun. ACM, 13(7):422–426,
1970.
[4] Dan Boneh, David Mazi´eres, and Raluca Ada Popa.
Remote oblivious storage: Making Oblivious RAM
practical. Technical report, MIT, 2011.
MIT-CSAIL-TR-2011-018 March 30, 2011.
[5] Ivan Damg˚ard, Sigurd Meldgaard, and Jesper Nielsen.
Perfectly secure Oblivious RAM without random
oracles. In Theory of Cryptography, volume 6597 of
Lecture Notes in Computer Science, pages 144–163.
2011.
[6] Oded Goldreich and Rafail Ostrovsky. Software
protection and simulation on Oblivious RAMs.
Journal of the ACM, 45:431–473, May 1996.
[7] Michael Goodrich and Michael Mitzenmacher.
Mapreduce parallel cuckoo hashing and Oblivious
RAM simulations. In 38th International Colloquium
on Automata, Languages and Programming (ICALP),
2011.
[8] Michael Goodrich, Michael Mitzenmacher, Olga
Ohrimenko, and Roberto Tamassia. Oblivious RAM
simulation with eﬃcient worst-case access overhead. In
ACM Cloud Computing Security Workshop at CCS
(CCSW), 2011.
[9] Michael T. Goodrich. Randomized shellsort: A simple
oblivious sorting algorithm. In Proceedings 21st
ACM-SIAM Symposium on Discrete Algorithms
(SODA), 2010.
[10] Michael T. Goodrich, Michael Mitzenmacher, Olga
Ohrimenko, and Roberto Tamassia. Practical oblivious
storage. In Proceedings of the second ACM conference
on Data and Application Security and Privacy,
CODASPY ’12, pages 13–24, New York, NY, USA,
2012. ACM.
[11] IBM. IBM 4764 PCI-X Cryptographic Coprocessor
(PCIXCC). Online at http://www-03.ibm.com/
303security/cryptocards/pcixcc/overview.shtml,
2006.
[12] A. Iliev and S.W. Smith. Private information storage
with logarithmic-space secure hardware. In
Proceedings of i-NetSec 04: 3rd Working Conference
on Privacy and Anonymity in Networked and
Distributed Systems, pages 201–216, 2004.
[13] Eyal Kushilevitz, Steve Lu, and Rafail Ostrovsky. On
the (in)security of hash-based oblivious RAM and a
new balancing scheme. In Proceedings of the
Twenty-Third Annual ACM-SIAM Symposium on
Discrete Algorithms, SODA ’12, pages 143–156. SIAM,
2012.
[14] Benny Pinkas and Tzachy Reinman. Oblivious RAM
revisited. In CRYPTO, pages 502–519, 2010.
[15] Sean W. Smith and David Saﬀord. Practical server
privacy with secure coprocessors. IBM Systems
Journal, 40(3):683–695, 2001.
[16] Emil Stefanov, Elaine Shi, and Dawn Song. Towards
Practical Oblivious RAM. In Proceedings of the
Network and Distributed System Security Symposium
(NDSS), 2012.
[17] Shuhong Wang, Xuhua Ding, Robert H. Deng, and
Feng Bao. Private information retrieval using trusted
hardware. In Proceedings of the European Symposium
on Research in Computer Security ESORICS, pages
49–64, 2006.
[18] Peter Williams and Radu Sion. SR-ORAM: Single
round-trip Oblivious RAM. In Industrial Track of
ACNS, 2012.
[19] Peter Williams, Radu Sion, and Bogdan Carbunar.
Building castles out of mud: practical access pattern
privacy and correctness on untrusted storage. In ACM
Conference on Computer and Communications
Security (CCS), pages 139–148, 2008.
304