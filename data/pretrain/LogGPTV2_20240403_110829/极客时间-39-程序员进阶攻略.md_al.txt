## 非规律性没有规律性的 Bug，才是让人抓狂的。曾经我接手过一个系统，是一个典型的生产者、消费者模型系统。系统接过来就发现一个比较明显的性能瓶颈问题，生产者的数据源来自数据库，生产者按规则提取数据，经过系统产生一系列的转换渲染后发送到多个外部系统。这里的瓶颈就在数据库上，生产能力不足，从而导致消费者饥饿。问题比较明显，我们先优化SQL，但效果不佳，遂改造设计实现，在数据库和系统之间增加一个内存缓冲区从而缓解了数据库的负载压力。缓冲区的效果，类似大河之上的堤坝，旱时积水，涝时泄洪。引入缓冲区后，生产者的生产能力得到了有效保障，生产能力高效且稳定。本以为至此解决了该系统的瓶颈问题，但在生产环境运行了一段时间后，系统表现为速度时快时慢，这时真正的Bug 才显形了。这个系统有个特点，就是 I/O 密集型。消费者要与多达 30个外部系统并发通信，所以猜测极有可能导致系统性能不稳定的 Bug就在此，于是我把目光锁定在了消费者与外部系统的 I/O通信上。既然锁定了怀疑区域，接下来就该用证据来证明，并给出合理的解释原因了。一开始假设在某些情况下触碰到了阈值极限，当达到临界点时程序性能则急剧下降，不过这还停留在怀疑假设阶段，接下来必须量化验证这个推测。那时的生产环境不太方便直接验证测试，我便在测试环境模拟。用一台主机模拟外部系统，一台主机模拟消费者。模拟主机上的线程池配置等参数完全保持和生产环境一致，以模仿一致的并发数。通过不断改变通信数据包的大小，发现在数据包接近100k 大小时，两台主机之间直连的千兆网络 I/O 达到满负载。于是，再回头去观察生产环境的运行状况，当一出现性能突然急剧下降的情况时，立刻分析了生产者的数据来源。其中果然有不少大报文数据，有些甚至高达200k，至此基本确定了与外部系统的 I/O通信瓶颈。解决办法是增加了数据压缩功能，以牺牲 CPU 换取 I/O。增加了压缩功能重新上线后，问题却依然存在，系统性能仍然时不时地急剧降低，而且这个时不时很没有时间规律，但关联上了一个"嫌疑犯"：它的出现和大报文数据有关，这样复现起来就容易多了。I/O瓶颈的怀疑被证伪后，只好对程序执行路径增加了大量跟踪调试诊断代码，包含了每个步骤的时间度量。在完整的程序执行路径中，每个步骤的代码块的执行时间独立求和结果仅有几十毫秒，最高也就在一百毫秒左右，但多线程执行该路径的汇总平均时间达到了4.5秒，这比我预期值整整高了两个量级。通过这两个时间度量的巨大差异，我意识到线程执行该代码路径的时间其实并不长，但花在等待CPU 调度的时间似乎很长。那么是 CPU 达到了瓶颈么？通过观察服务器的 CPU消耗，平均负载却不高。只好再次分析代码实现机制，终于在数据转换渲染子程序中找到了一段可疑的代码实现。为了验证疑点，再次做了一下实验测试：用150k 的线上数据报文作为该程序输入，单线程运行了下，发现耗时居然接近 50毫秒，我意识到这可能是整个代码路径中最耗时的一个代码片段。由于这个子程序来自上上代程序员的遗留代码，包含一些稀奇古怪且复杂的渲染逻辑判断和业务规则，很久没人动过了。仔细分析了其中实现，基本就是大量的文本匹配和替换，还包含一些加密、Hash操作，这明显是一个 CPU密集型的函数啊。那么在多线程环境下，运行这个函数大概平均每个线程需要多少时间呢？先从理论上来分析下，我们的服务器是 4 核，设置了 64个线程，那么理想情况下同一时间可以运行 4个线程，而每个线程执行该函数约为 50 毫秒。这里我们假设 CPU 50毫秒才进行线程上下文切换，那么这个调度模型就被简化了。第一组 4个线程会立刻执行，第二组 4 个线程会等待 50 毫秒，第三组会等待 100毫秒，依此类推，第 16 组线程执行时会等待 750毫秒。平均下来，每组线程执行前的平均等待时间应该是在 300 到 350毫秒之间。这只是一个理论值，实际运行测试结果，平均每个线程花费了 2.6秒左右。实际值比理论值慢一个量级，这是为什么呢？因为上面理论的调度模型简化了 CPU的调度机制，在线程执行过程的 50 毫秒中，CPU将发生非常多次的线程上下文切换。50 毫秒对于 CPU的时间分片来说，实在是太长了，因为线程上下文的多次切换和 CPU争夺带来了额外的开销，导致在生产环境上，实际的监测值达到了 4.5秒，因为整个代码路径中除了这个非常耗时的子程序函数，还有额外的线程同步、通知和I/O 等操作。分析清楚后，通过简单优化该子程序的渲染算法，从近 50 毫秒降低到 3、4毫秒后，整个代码路径的线程平均执行时间下降到 100毫秒左右。收益是明显的，该子程序函数性能得到了 10倍的提高，而整体执行时间从 4.5 秒降低为 100 毫秒，性能提高了 45 倍。至此，这个非规律性的 Bug 得到了解决。虽然案例中最终解决了Bug，但用的方法却非正道，更多依靠的是一些经验性的怀疑与猜测，再去反过来求证。这样的方法局限性非常明显，完全依赖程序员的经验，然后就是运气了。如今再来反思，一方面由于是刚接手的项目，所以我对整体代码库掌握还不够熟悉；另一方面也说明当时对程序性能的分析工具了解有限。而更好的办法就应该是采用工具，直接引入代码 Profiler等性能剖析工具，就可以准确地找到有性能问题的代码段，从而避免了看似有理却无效的猜测。面对非规律性的Bug，最困难的是不知道它的出现时机，但一旦找到它重现的条件，解决起来也没那么困难了。
## 神出鬼没能称得上神出鬼没的 Bug 只有一种：**海森堡 Bug（Heisenbug）**。这个 Bug 的名字来自量子物理学的"海森堡不确定性原理"，其认为观测者观测粒子的行为会最终影响观测结果。所以，我们借用这个效应来指代那些无法进行观测的Bug，也就是在生产环境下不经意出现，费尽心力却无法重现的 Bug。海森堡 Bug的出现场景通常都是和分布式的并发编程有关。我曾经在写一个网络服务端程序时就碰到过一次海森堡Bug。这个程序在稳定性负载测试时，连续跑了十多个小时才出现了一次异常，然后在之后的数天内就再也不出现了。第一次出现时捕捉到的现场信息太少，然后增加了更多诊断日志后，怎么测都不出现了。最后是怎么定位到的？还好那个程序的代码量不大，就天天反复盯着那些代码，好几天过去还真就灵光一现发现了一个逻辑漏洞，而且从逻辑推导，这个漏洞如果出现的话，其场景和当时测试发现的情况是吻合的。究其根源，该 Bug复现的场景与网络协议包的线程执行时序有关。所以，一方面比较难复现，另一方面通过常用的调试和诊断手段，诸如插入日志语句或是挂接调试器，往往会修改程序代码，或是更改变量的内存地址，或是改变其执行时序。这都影响了程序的行为，如果正好影响到了Bug，就可能诞生了一个海森堡 Bug。关于海森堡Bug，一方面很少有机会碰到，另一方面随着你编程经验的增加，掌握了很多编码的优化实践方法，也会大大降低撞上海森堡Bug 的几率。综上所述，每一个 Bug 都是具体的，每一个具体的 Bug 都有具体的解法。但所有Bug 的解决之道只有两类：事后和事前。事后，就是指 Bug 出现后容易捕捉现场并定位解决的，比如第一类周期特点的Bug。但对于没有明显重现规律，甚至神出鬼没的海森堡Bug，靠抓现场重现的事后方法就比较困难了。针对这类Bug，更通用和有效的方法就是在事前预防与埋伏。之前在讲编程时说过一类代码：运维代码，它们提供的一种能力就像人体血液中的白细胞，可以帮助发现、诊断、甚至抵御Bug 的 "入侵"。而为了得到一个更健康、更健壮的程序，运维类代码需要写到何种程度，这又是编程的"智慧" 领域了，充满了权衡选择。程序员不断地和 Bug 对抗，正如医生不断和病菌对抗。不过 Bug的存在意味着这是一段活着的、有价值的代码，而死掉的代码也就无所谓 Bug了。在你的程序员职业生涯中，有碰到过哪些有意思的 Bug呢？欢迎你给我留言分享讨论。![](Images/a1e61bd5d0a80da9fdfd53ba1e12f2e4.png){savepage-src="https://static001.geekbang.org/resource/image/45/b8/456def9c2e16edaec6543cfa03376cb8.jpg"}
# 14 \| Bug的反复出现：重蹈覆辙与吸取教训Bug除了时间和空间两种属性，还有一个特点是和程序员直接相关的。在编程的路上，想必你也曾犯过一些形态各异、但本质重复的错误，导致一些Bug总是以不同的形态反复出现。在你捶胸顿足懊恼之时，不妨试着反思一下：为什么你总会写出有Bug 的程序，而且有些同类型的 Bug 还会反复出现？
## 1. 重蹈覆辙重蹈覆辙的错误，老实说曾经我经历过不止一次。也许每次具体的形态可能有些差异，但仔细究其本质却是类似的。想要写出没有Bug的程序是不可能的，因为所有的程序员都受到自身能力水平的局限。而我所经历的重蹈覆辙型错误，总结下来大概都可以归为以下三类原因。
### 1.1 粗心大意人人都会犯粗心大意的错误，因为这就是 "人"这个系统的普遍固有缺陷（Bug）之一。所以，作为人的程序员一定会犯一些非常低级的、因为粗心大意而导致的Bug。这就好比写文章、写书都会有错别字，即使经历过三审三校后正式出版的书籍，都无法完全避免错别字的存在。而程序中也有这类 "错别字" 类型的低级错误，比如：条件`if`后面没有大括号导致的语义变化，`==`、`=` 和 `===` 的数量差别，`++` 或`--`的位置，甚至`;`的有无在某些编程语言中带来的语义差别。即使通过反复检查也可能有遗漏，而自己检查自己的代码会更难发现这些缺陷，这和自己不容易发现自己的错别字是一个道理。``{=html}心理学家汤姆·斯塔福德（TomStafford）曾在英国谢菲尔德大学研究拼写错误，他说："当你在书写的时候，你试图传达想法，这是非常高级的任务。而在做高级任务时，大脑将简单、零碎的部分（拼词和造句）概化，这样就可以更专注于更复杂的任务，比如将句子变成复杂的观点。"而在阅读时，他解释说："我们不会抓住每个细节，相反，我们吸收感官信息，将感觉和期望融合，并且从中提炼意思。"这样，如果我们读的是他人的作品，就能帮助我们用更少的脑力更快地理解含义。但当我们验证自己的文章时，我们知道想表达的东西是什么。因为我们预期这些含义都存在，所以很容易忽略掉某些感官（视觉）表达上的缺失。我们眼睛看到的，在与我们脑子里的印象交战。这，便是我们对自己的错误视而不见的原因。写程序时，我们是在进行一项高级的复杂任务：将复杂的需求或产品逻辑翻译为程序逻辑，并且还要补充上程序固有的非业务类控制逻辑。因而，一旦我们完成了程序，再来复审写好的代码，这时我们预期的逻辑含义都预先存在于脑中，同样也就容易忽略掉某些视觉感官表达上的问题。从进化角度看，粗心写错别字，还看不出来，不是因为我们太笨，而恰恰还是进化上的权衡优化选择。
### 1.2 认知偏差认知偏差，是重蹈覆辙类错误的最大来源。曾经，我就对 Java 类库中的线程 API产生过认知偏差，导致反复出现问题。Java自带线程池有三个重要参数：核心线程数（core）、最大线程数（max）和队列长度（queues）。我曾想当然地以为当核心线程数（core）不够了，就会继续创建线程达到最大线程数（max），此时如果还有任务需要处理但已经没有线程了就会放进队列等待。但实际却不是这样工作的，类库的实现是核心线程（core）满了就会进队列（queues）等待，直到队列也满了再创建新线程直至达到最大线程数（max）的限制。这类认知偏差曾带来线上系统的偶然性异常故障，然后还怎么都找不到原因。因为这进入了我的认知盲区，我以为的和真正的现象之间的差异一度让我困惑不解。还有一个来自生活中的小例子，虽然不是关于程序的，但本质是一个性质。有时互联网上，朋友圈中小道消息满天飞，与此类现象有关的一个成语叫"空穴来风"，现在很多媒体文章有好多是像下面这样用这个成语的：> 他俩要离婚了？看来空穴来风，事出有因啊！\> 物价上涨的传闻恐怕不是空穴来风。第一句是用的成语原意：指有根据、有来由，"空"发三声读 kǒng，意同"孔"。第二句是表达：没有根据和由来，"空"发一声读kōnɡ。第二种的新意很多名作者和普通大众沿用已久，约定俗成，所以又有辞书与时俱进增加了这个新的义项，允许这两种完全相反的解释并存，自然发展，这在语义学史上也不多见。而关于程序上有些 API 的定义和实现也犯过 "空穴来风" 的问题，一个 API可以表达两种完全相反的含义和行为。不过这样的 API就很容易引发认知偏差导致的 Bug，所以在设计和实现 API时我们就要避免这种情况的出现，而是要提供单一原子化的设计。