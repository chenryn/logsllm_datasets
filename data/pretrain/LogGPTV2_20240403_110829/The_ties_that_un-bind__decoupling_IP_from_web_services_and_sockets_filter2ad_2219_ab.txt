key enablers for our architecture.
Name-based virtual hosting CDNs used to assign unique IP
addresses to each website. This has diminished over time with the
adoption of name-based virtual hosting. The Host header in HTTP
enables a single application to provide independent yet identical
services. Similarly, the Server Name Indication (SNI) field in
TLS allows a server to host multiple HTTPS certificates on the
same IP+port. This effort was once stymied by slow adoption from
clients1, but client adoption has since changed dramatically. As of
2017, over 99% of TLS connections to major CDNs use the SNI
extension [49]. As a result, servers can now safely assume support
for SNI. In fact, some services mandate it: many Google services
are inaccessible by clients that do not support SNI [32, 60].
IP-based virtual hosting Recent advancements built atop equal-
cost multipath routing (ECMP) allow multiple instances of a sin-
gle service to sit behind a single public-facing IP, on multiple
servers [22]. Though often referred to as a virtual IP (VIP), this
model adheres to the IP’s original design allowing a single address
to interface with different network architectures [52]. It also has
the perhaps unintended effect of decoupling addresses from net-
work interfaces, so that the mapping between them is flexible and
dynamic.
On the client side, advancements in networking stacks and APIs
also encourage applications to move away from IP addresses and
towards names. Apple’s Network Framework APIs [4], for example,
support “connect-by-name” as the primary mechanism for establish-
ing UDP, TCP, and TLS connections. Similar APIs can be found in
standard libraries for modern programming languages such as Go.
1For years, Akamai limited its use of SNI to remains backwards-compatible with old
versions of Windows (e.g., Windows XP) that did not support it.
(a) Conventional DNS uses name to lookup addresses.
(b) Our architecture matches policy without name; a random bit-
string is appended to a prefix representing the policy.
Figure 3: Policy-first DNS architecture shifts from matching
names to instead matching on attributes that represent a policy;
address pools are assigned to policies.
3 HOW DO WE GET OUT OF HERE?
Our overarching goal is to relax the bindings between IP addresses,
hostnames, and sockets. In later sections, we show that doing so
enables greater flexibility and innovation for network engineering
and services. To that end, in this section, we present two comple-
mentary designs that, together, completely decouple IP bindings.
First, we describe a modification to DNS that separate DNS records
from the addresses that populate them. This has the effect of creating
independent control and data channels for DNS.
Second, to escape from the rigidity of IP-to-socket bindings
we design a scalable and flexible programmable socket architec-
ture, sk_lookup. The sk_lookup design enables dynamic mapping
IP+port pairs in any or all combinations – an otherwise decades-long
constraint – to sockets. The implementation with BPF [28] was re-
cently accepted into the mainline Linux kernel [43, 44]. In a spirit
similar to the DNS changes, sk_lookup has the effect of separating
sockets into control and data channels.
3.1 DNS to Decouple IP–name bindings
We assume, for the purpose of presentation, that a service provider
originates an IP prefix announcement, and that the IP range is orders
of magnitude smaller than the set of hostnames associated with the
service. How then do we map or move hostnames to IP addresses?
The fan-out properties of L4 ECMP and consistent hashing
load-balancers ( [22, 45]) may appear suitable. However, L4 load-
balancers are themselves constrained by (virtual) addressing. Alter-
natively, QUIC anticipates a desire to accept a connection on one IP
address, and receive a reply from another [34]. While novel, tangible
435
Query arrivesH: Addr-1, Addr-2, …, Addr-kDNS Process12Lookup Table34Lookup: HAdditional logic (geo, load-balance).Construct and return A/AAAA.Query arrivesFor: - PoP location - account type Use: a.b.c.d/xx1Policy Configuration:     Generate bitstring and       append to prefix     2Randomization function:DNS Process3Construct and return record.SIGCOMM ’21, August 23–28, 2021, Virtual Event, USA
Fayed, et al.
progress has yet to be made and use cases are restricted to QUIC,
rather than generalized across transport services.
Instead, IP addresses should be mapped where the binding to
hostnames occurs – that place is authoritative DNS. From the per-
spectives of the client, and the connection, the binding between
destination hostnames and IP addresses is due solely to DNS. Name-
to-IP mappings in DNS are generally static in nature, stored in some
form of a record or lookup table.
However, despite the existence of static lookup tables, the binding
is only known ‘on-query’. In other words the address is returned in
response to a DNS query—the last possible moment in the lifetime
of a request where a hostname can be bound to an IP address. Fig-
ure 3a shows conventional DNS, in which names may be mapped
to possibly multiple addresses for the purposes of path redundancy,
proximity selection, or load-balancing [9]. For all practical uses of
that mapping, the address(es)-to-name binding occurs at the moment
that DNS generates and returns the response.
This leads to the observation that addresses are bound to names at
the moment the response is returned, rather than within any record.
The separation is subtle, but important: DNS responses in today’s
architectures use a name to identify a set of of addresses, from which
a subset is selected based on some policy logic. We instead invert
this relationship, as represented in Figure 3b. Instead of IP addresses
pre-assigned to a name, our architecture begins with a policy that
may (or in our case, not) include a name. For example, a policy may
be represented by attributes such as location and account type (as in
our deployment described in §4). The attributes identify a pool of
addresses that represent the policy. The pool itself may be isolated
to that policy or have elements shared with other pools and policies.
Note that in this model, all addresses in the pool are equivalent.
Any address may be returned without inspecting the DNS query
name. Instead, IP addresses are computed and assigned at runtime or
query-time. The lifetime of the name-to-IP binding is upper-bounded
in time by the larger of connection lifetime and TTL in downstream
caches. The binding itself is otherwise ephemeral and can be changed
without regard to previous bindings, resolvers, clients, or purpose.
3.2 From Policy to Practice
The address pool can consist of any set addresses. In our design the
set of policy attributes is associated with an address pool described
by a prefix, w.x.y.z/b. From within the pool our design defaults
to random selection, as instantiated in §4. We note that IP random-
ization in and of itself is far from new [9] and is implemented by
CDNs, albeit limited to a few addresses [2, 13]. Alongside, domains
are increasingly co-hosted; recent studies show 20% of observed
domains are co-hosted with more than 1K other domains onto a sin-
gle IP address, up from 6% in 2007[31]. We view our architecture,
which foregoes all notions of fixed IP-to-name ratios, as the next
logical step change in this evolution.
The DNS architecture is described by Figure 3b and takes the
following approach:
(1) A query arrives for an A or AAAA record.
(2) Any processing, validation, or logging (e.g., for accounting
or debugging), remains unchanged.
(3) Attributes match to a policy (specific examples §4, §5, and
§6) that identifies a prefix.
(4) Given a prefix of length 𝑏, generate a random bitstring of
32 − 𝑏 (for IPv4) or 128 − 𝑏 (for IPv6).
(5) Respond with the address that is the concatenation of the
prefix with the random bitstring.
This approach makes no assumptions about query patterns or
contents. For example, consider three hostnames ℎ𝑖, ℎ 𝑗 , ℎ𝑘. The
randomly generated addresses returned for any of (ℎ𝑖, ℎ 𝑗 , ℎ𝑘) and
(ℎ𝑖, ℎ𝑖, ℎ𝑖) are equivalent: IP addresses are 𝑖.𝑖.𝑑 irrespective of order-
ing or frequency. As a result, all hostnames will appear on all of the
addresses in the pool given a sufficient window of time.
We place no bounds on the number of hostnames that may be
mapped onto the IP pool since this mapping is carried by SNI and
HTTP Host (see §2.3). Nor do we put limits on the prefix length.
CDNs and hosting services already bind multiple hostnames to indi-
vidual IP addresses. SNI enables hostnames to exceed IP addresses
by orders of magnitude. Our own evaluations later will show this
works at a ratio of 20+ million hostnames to 1 single address.
The flexibility generated by a policy- rather than name-based
DNS architecture is instantiated by later sections. However, the
inflexibility of sockets is a barrier to a complete decoupling of IP
addresses that must first be resolved.
3.3 From listen to lookup: Re-engineering the
sockets stack for scale
The inflexibility of standard BSD-style socket implementations is
both known and the subject of research [66]. Perhaps less well known
is that sockets increasingly are barriers to services at scale. Briefly
stated, it is exceptionally challenging to set up network services to
listen on hundreds of IP addresses without causing the network stack
to buckle, and even break.
Broadly speaking, the way that sockets are bound to IP+port pairs
has three limitations: (i) Each new socket consumes memory, and in-
creases the search time to find the right socket for an arriving packet;
(ii) any IP+port pair selection artificially restricts other IP+port pair
selections; (iii) once bound, sockets are unchangeable and inexorably
tie the software interface to the IP+port.
We propose a new design: programmable socket lookups. Our
implementation, BPF sk_lookup, is open-source and was recently
accepted into the mainline Linux kernel [43, 44]. A brief overview
is helpful to understand socket limitations.
Standard sockets primer and problems The default association
between an IP+port and a service is one-to-one. The service appli-
cation, itself, must open one socket for each transport protocol (be
it TCP or UDP) it wants to support. For example, an authoritative
DNS service would open up two sockets (a.b.c.d:53/tcp and
a.b.c.d:53/udp). Each socket is given its own file descriptor.
The 1:1 mapping means that CDN services must have at least one
listen socket for each IP address in use, as depicted in Figure 4a.
For example, 4096 sockets are needed to listen on any single port
(e.g., 80) for each IP address in an advertised /20—before doubling
in number to accommodate both TCP and UDP.2 The associated
memory and look-up performance penalties do not go unnoticed.
2Admittedly this approach, while naïve, has an isolation advantage: a UDP flood attack
on any IP in the range has no impact on the receive queues of sockets bound to the
remaining IP addresses in the range.
436
The Ties that un-Bind: Decoupling IP from web services and sockets. . .
SIGCOMM ’21, August 23–28, 2021, Virtual Event, USA
(a) The standard socket model scales
linearly in memory and incurs perfor-
mance penalties with large numbers.
(b) The bind-to-any INADDR_ANY catch-all ad-
dress is inflexible and a security hazard.
(c) An sk_lookup example: Packets arriving on
192.0.2.0/24:53 to socket sk:2, while traffic on
203.0.113.1 to any port number lands in socket sk:4.
Figure 4: Sockets are unscalable, inflexible, and static. sk_lookup solves this by decoupling IP+port pairs from listening sockets.
Alternatively, the sockets API comes with an ‘any’ facility as
INADDR_ANY or the 0.0.0.0 wildcard address. A socket created
with the ‘any’ facility will respond on all addresses assigned to the
server, but specified to one port number. As shown in Figure 4b, com-
pared to the naïve “one address, one socket” model, INADDR_ANY
provides a single catch-all listening socket for the whole IP range
on which connections are accepted. It works by being the last in a
chain of lookups for more specific sockets, as shown in Figure 5a.
The INADDR_ANY facility deserves closer inspection in a CDN
context. One advantage of binding to 0.0.0.0 is that applications
become address-agnostic, allowing for addresses to be added or
removed after socket binding without need for an application re-
configuration or restart. Conversely, this catch-all creates a security
vulnerability: Listening on more addresses than needed may other-
wise expose an internal-only service to external traffic that has no
firewall or socket filter in place. Furthermore, one socket has one
receive queue, so an attack on any IP address will cause legitimate
packets on other IP addresses to be dropped3.
Perhaps the greatest downside, however, is loss of flexibility in
services. In particular, what should happen if another service is later
bound to a specific address and port pair? In Linux, for example, a
service that listens on the wildcard INADDR_ANY address claims the
port number exclusively for itself. Attempts to listen on a specific IP
and a port bound to the wildcard-listening socket will fail.4
Unfortunately the sockets API does not allow us to express a
setup in which two services share a port and accept requests on
disjoint IP ranges. Nor does it offer a facility to listen on all ports
simultaneously for any IP address or range. Nor does it allow for a
socket’s IP+port bindings to be altered.
On appearance these may seem like corner cases that can be
resolved with a new socket option, but at scale cases such as these
are common. Consider, for example, services that share the same
port number but otherwise respond to requests on non-overlapping
IP ranges. One prominent instance occurs when a recursive DNS
resolver runs side-by-side with the authoritative DNS service.
sk_lookup: Programmable socket lookup The inflexibility of
sockets at scale motivates us to re-evaluate and re-engineer socket
bindings. In lieu of 1-to-1 or all-to-1 address to socket bindings,
the ideal is a programmable and flexible facility that matches an
incoming packet with a listening socket, ignoring the file descriptor
3The Linux kernel offers protections in the TCP stack, but UDP requires special care.
4See https://man7.org/linux/man-pages/man2/listen.2.html#ERRORS.
(a) Programmable sk_lookup is injected on the standard socket
lookup path after connected sockets are matched, but prioritized
ahead of IP+port listeners.
(b) sk_lookup program is a set of matches and actions.
Figure 5: BPF sk_lookup in the kernel.
to which the socket may have been bound. Our design is captured