REFERENCES
[1] Martín Abadi. 2006. Access Control in a Core Calculus of Dependency. In 11th
ACM SIGPLAN Int’l Conf. on Functional Programming. ACM, New York, NY, USA,
263–273.
[2] Martín Abadi. 2008. Variations in Access Control Logic.
In Deontic Logic in
Computer Science, Ron van der Meyden and Leendert van der Torre (Eds.). Lecture
Notes in Computer Science, Vol. 5076. Springer Berlin Heidelberg, 96–109.
[3] Martín Abadi, Anindya Banerjee, Nevin Heintze, and Jon Riecke. 1999. A Core
Calculus of Dependency. In 26th ACM Symp. on Principles of Programming Lan-
guages (POPL). 147–160.
[4] Owen Arden, Jed Liu, and Andrew C. Myers. 2015. Flow-Limited Authorization.
In 28th IEEE Symp. on Computer Security Foundations (CSF). 569–583.
[5] Owen Arden and Andrew C. Myers. 2016. A Calculus for Flow-Limited Autho-
rization. In 29th IEEE Symp. on Computer Security Foundations (CSF). 135–147.
[6] Aslan Askarov and Andrew C. Myers. 2011. Attacker Control and Impact for
Confidentiality and Integrity. Logical Methods in Computer Science 7, 3 (Sept.
2011).
[7] K. J. Biba. 1977. Integrity Considerations for Secure Computer Systems. Technical
Report ESD-TR-76-372. USAF Electronic Systems Division, Bedford, MA. (Also
available through National Technical Information Service, Springfield Va., NTIS
AD-A039324.).
[8] Niklas Broberg and David Sands. 2010. Paralocks—Role-Based Information Flow
Control and Beyond. In 37th ACM Symp. on Principles of Programming Languages
(POPL).
[9] Pablo Buiras, Dimitrios Vytiniotis, and Alejandro Russo. 2015. HLIO: Mixing
Static and Dynamic Typing for Information-Flow Control in Haskell. In 20th
ACM SIGPLAN Int’l Conf. on Functional Programming. ACM, 289–301.
[10] Ethan Cecchetti, Andrew C. Myers, and Owen Arden. 2017. Nonmalleable In-
formation Flow Control: Technical Report. Technical Report. Cornell University
Computing and Information Science. https://arxiv.org/abs/1708.08596.
[11] Stephen Chong and Andrew C. Myers. 2006. Decentralized Robustness. In 19th
IEEE Computer Security Foundations Workshop (CSFW). 242–253.
[12] Stephen Chong and Andrew C. Myers. 2008. End-to-End Enforcement of Erasure
and Declassification. In IEEE Symp. on Computer Security Foundations (CSF). 98–
111.
[13] Michael R. Clarkson and Fred B. Schneider. 2008. Hyperproperties. In IEEE
Symp. on Computer Security Foundations (CSF). 51–65.
[14] Dorothy E. Denning. 1976. A Lattice Model of Secure Information Flow. Comm. of
the ACM 19, 5 (1976), 236–243.
SIAM Rev. 45, 4 (2003), 727–784.
[15] Danny Dolev, Cynthia Dwork, and Moni Naor. 2003. Nonmalleable Cryptography.
[16] Petros Efstathopoulos, Maxwell Krohn, Steve VanDeBogart, Cliff Frey, David
Ziegler, Eddie Kohler, David Mazières, Frans Kaashoek, and Robert Morris. 2005.
Labels and Event Processes in the Asbestos Operating System. In 20th ACM
Symp. on Operating System Principles (SOSP).
[17] Michael D. Ernst, René Just, Suzanne Millstein, Werner Dietl, Stuart Pernsteiner,
Franziska Roesner, Karl Koscher, Paulo Barros, Ravi Bhoraskar, Seungyeop Han,
Paul Vines, and Edward X. Wu. 2014. Collaborative Verification of Informa-
tion Flow for a High-Assurance App Store. In 21st ACM Conf. on Computer and
Communications Security (CCS). 1092–1104.
[18] David Ferraiolo and Richard Kuhn. 1992. Role-Based Access Controls. In 15th
National Computer Security Conference.
[19] Joseph A. Goguen and Jose Meseguer. 1982. Security Policies and Security Models.
In IEEE Symp. on Security and Privacy. 11–20.
[20] Limin Jia, Jeffrey A. Vaughan, Karl Mazurak, Jianzhou Zhao, Luke Zarko, Joseph
Schorr, and Steve Zdancewic. 2008. Aura: A Programming Language for Autho-
rization and Audit. In 13th ACM SIGPLAN Int’l Conf. on Functional Programming.
[21] krdlab. 2014. Haskell Servant Example. https://github.com/krdlab/examples.
(Dec. 2014).
[22] Maxwell Krohn, Alexander Yip, Micah Brodsky, Natan Cliffer, M. Frans Kaashoek,
Eddie Kohler, and Robert Morris. 2007. Information Flow Control for Standard
OS Abstractions. In 21st ACM Symp. on Operating System Principles (SOSP).
[23] Peng Li and Steve Zdancewic. 2006. Encoding information flow in Haskell. In
19th IEEE Computer Security Foundations Workshop (CSFW).
[24] Benoît Montagu, Benjamin C. Pierce, and Randy Pollack. 2013. A Theory of
Information-Flow Labels. In 26th IEEE Symp. on Computer Security Foundations
(CSF). 3–17.
[25] Andrew C. Myers. 1999. JFlow: Practical Mostly-Static Information Flow Control.
In 26th ACM Symp. on Principles of Programming Languages (POPL). 228–241.
[26] Andrew C. Myers and Barbara Liskov. 2000. Protecting Privacy using the Decen-
tralized Label Model. ACM Transactions on Software Engineering and Methodol-
ogy 9, 4 (Oct. 2000), 410–442.
[27] Andrew C. Myers, Andrei Sabelfeld, and Steve Zdancewic. 2006. Enforcing Robust
Declassification and Qualified Robustness. Journal of Computer Security 14, 2
(2006), 157–196.
[28] Aleksandar Nanevski, Anindya Banerjee, and Deepak Garg. 2011. Verification of
Information Flow and Access Control Policies with Dependent Types. In IEEE
Symp. on Security and Privacy. 165–179.
[29] Sylvan Pinsky. 1995. Absorbing Covers and Intransitive Non-Interference. In
IEEE Symp. on Security and Privacy. 102–113.
[30] François Pottier and Sylvain Conchon. 2000. Information Flow Inference for Free.
In 5th ACM SIGPLAN Int’l Conf. on Functional Programming (ICFP ’00). 46–57.
[31] François Pottier and Vincent Simonet. 2003. Information Flow Inference for ML.
ACM Trans. on Programming Languages and Systems 25, 1 (Jan. 2003).
[32] A. W. Roscoe and M. H. Goldsmith. 1999. What is Intransitive Noninterference?.
In 12th IEEE Computer Security Foundations Workshop (CSFW). 228–238.
[33] Indrajit Roy, Donald E. Porter, Michael D. Bond, Kathryn S. McKinley, and Em-
mett Witchel. 2009. Laminar: Practical Fine-Grained Decentralized Information
Flow Control. In ACM SIGPLAN Conf. on Programming Language Design and
Implementation (PLDI).
[34] John Rushby. 1992. Noninterference, transitivity and channel-control security poli-
cies. Technical Report CSL-92-02. SRI.
[35] Andrei Sabelfeld and Andrew C. Myers. 2003. Language-Based Information-Flow
IEEE Journal on Selected Areas in Communications 21, 1 (Jan. 2003),
Security.
5–19.
[36] Andrei Sabelfeld and David Sands. 2005. Dimensions and Principles of Declassifi-
cation. In 18th IEEE Computer Security Foundations Workshop (CSFW). 255–269.
http://
Servant – A Type-Level Web DSL.
[37] Servant Contributors. 2016.
haskell-servant.readthedocs.io/. (2016).
[38] Marcelo Sousa and Isil Dillig. 2016. Cartesian Hoare logic for verifying k-safety
properties. In SIGPLAN Notices, Vol. 51. ACM, 57–69.
[39] Deian Stefan, Amit Levy, Alejandro Russo, and David Mazières. 2014. Building
Secure Systems with LIO. In Haskell Symposium. ACM SIGPLAN.
[40] Nikhil Swamy, Michael Hicks, Stephen Tse, and Steve Zdancewic. 2006. Managing
Policy Updates in Security-Typed Languages. In 19th IEEE Computer Security
Foundations Workshop (CSFW). 202–216.
[41] The Glasgow Haskell Compiler 2016. The Glasgow Haskell Compiler. (2016).
https://www.haskell.org/ghc/.
[42] Ron van der Meyden. 2007. What, Indeed, Is Intransitive Noninterference?. In
12th European Symposium on Research in Computer Security (ESORICS). 235–250.
[43] Lucas Waye, Pablo Buiras, Dan King, Stephen Chong, and Alejandro Russo. 2015.
It’s My Privilege: Controlling Downgrading in DC-Labels. In Proceedings of the
11th International Workshop on Security and Trust Management.
[44] J. Todd Wittbold and Dale M. Johnson. 1990. Information Flow in Nondetermin-
istic Systems. In IEEE Symp. on Security and Privacy. 144–161.
[45] Andrew K. Wright and Matthias Felleisen. 1994. A Syntactic Approach to Type
Soundness. Information and Computation 115, 1 (1994), 38–94.
[46] Steve Zdancewic and Andrew C. Myers. 2001. Robust Declassification. In 14th
IEEE Computer Security Foundations Workshop (CSFW). 15–23.
[47] Steve Zdancewic, Lantian Zheng, Nathaniel Nystrom, and Andrew C. Myers.
2002. Secure Program Partitioning. ACM Trans. on Computer Systems 20, 3 (Aug.
2002), 283–328.
[48] Nickolai Zeldovich, Silas Boyd-Wickizer, Eddie Kohler, and David Mazières. 2006.
Making Information Flow Explicit in HiStar. In 7th USENIX Symp. on Operating
Systems Design and Implementation (OSDI). 263–278.
[49] Lantian Zheng and Andrew C. Myers. 2007. Dynamic Security Labels and Static
Information Flow Control. International Journal of Information Security 6, 2–3
(March 2007).
A FULL NMIFC
We present the full syntax, semantics, and typing rules for NMIFC
in Figures 17, 18, and 20, respectively. This is a straightforward
extension of the core language presented in Section 5. We note that
polymorphic terms specify a pc just as λ terms. This is because they
contain arbitrary expressions which could produce arbitrary effects,
so we must constrain the context that can execute those effects.
Figure 21 presents the full set of derivation rules for the acts-for
(delegation) relation p ≽ q.
A.1 Label tracking with brackets
In order to simply proofs of hyperproperties requiring 2 and 4
traces, we introduce a new bracket syntax to track secret and un-
trusted data. These brackets are inspired by those used by Pottier
and Simonet [31] to prove their FlowCaml type system enforced
noninterference. Their brackets served two purposes simultane-
ously. First they allow a single execution of a bracketed program
to faithfully model two executions of a non-bracketed program.
n ∈ N (atomic principals)
x ∈ V (variable names)
(cid:12)(cid:12)(cid:12) p ⊔ p
(cid:12)(cid:12)(cid:12) p ⊓ p
p, ℓ, pc
τ
v
e
::= n
::= unit
pc−−→ τ
τ
::=
::= x
(cid:12)(cid:12)(cid:12) p ∨ p
(cid:12)(cid:12)(cid:12) ⊤ (cid:12)(cid:12)(cid:12) ⊥ (cid:12)(cid:12)(cid:12) p π (cid:12)(cid:12)(cid:12) p ∧ p
(cid:12)(cid:12)(cid:12) (τ × τ )
(cid:12)(cid:12)(cid:12) X
(cid:12)(cid:12)(cid:12) (τ + τ )
(cid:12)(cid:12)(cid:12) ∀X [pc]. τ
(cid:12)(cid:12)(cid:12) ℓ says τ
(cid:12)(cid:12)(cid:12) inji v
(cid:12)(cid:12)(cid:12) ⟨v, v⟩ (cid:12)(cid:12)(cid:12) (η ℓ v )
(cid:12)(cid:12)(cid:12) ΛX [pc]. e
(cid:12)(cid:12)(cid:12) ⟨e, e⟩ (cid:12)(cid:12)(cid:12) (ηℓ e )
(cid:12)(cid:12)(cid:12) e e
(cid:12)(cid:12)(cid:12) e τ
(cid:12)(cid:12)(cid:12) v
(cid:12)(cid:12)(cid:12) inji e
(cid:12)(cid:12)(cid:12) bind x = e in e
(cid:12)(cid:12)(cid:12) endorse e to ℓ
proji e
case e of inj1 (x ).e | inj2 (x ).e
decl e to ℓ
Figure 17: Full NMIFC syntax.
()
λ(x :τ )[pc]. e
(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)(cid:12)
[TLam]
[TApp]
[Pair]
[Inj]
(cid:69)
[Case]
[UnitM]
[BindM]
[Decl]
[Endorse]
p ≽ q
e −→ e′
[E-App]
[E-TApp]
[E-UnPair]
(λ(x :τ )[pc]. e ) v −→ e[x (cid:55)→ v]
(ΛX [pc]. e ) τ −→ e[X (cid:55)→ τ ]
proji ⟨v1, v2⟩ −→ vi
[E-Case]
(case (inji v ) of inj1 (x ).e1 | inj2 (x ).e2) −→ ei [x (cid:55)→ v]
[E-BindM]
⟨e, t⟩ −→→ (cid:10)e′
, t′(cid:11)
bind x = (η ℓ v ) in e −→ e[x (cid:55)→ v]
[E-Step]
[E-UnitM]
[E-Decl]
[E-Endorse]
[E-Eval]
(cid:68)
(cid:68)
Evaluation context
::= [·]
E
decl (η ℓ′ v ) to ℓ, t
endorse (η ℓ′ v ) to ℓ, t
(cid:69)
(cid:69)
ℓ′, η ℓ v )
e −→ e′
, t;•(cid:11)
⟨e, t⟩ −→→ (cid:10)e′
(cid:10)(ηℓ v ), t(cid:11) −→→ (cid:68)
(cid:69) −→→ (cid:68)
(η ℓ v ), t; (η ℓ v )
(η ℓ v ), t; (↓→
(cid:69) −→→ (cid:68)
(η ℓ v ), t; (↓←
⟨e, t⟩ −→→ (cid:10)e′
, t′(cid:11)
⟨E[e], t⟩ −→→ (cid:10)E[e′], t′(cid:11)
(cid:12)(cid:12)(cid:12) v E
(cid:12)(cid:12)(cid:12) E τ
(cid:12)(cid:12)(cid:12) ⟨E, e⟩ (cid:12)(cid:12)(cid:12) ⟨v, E⟩ (cid:12)(cid:12)(cid:12) (ηℓ E )
(cid:12)(cid:12)(cid:12) inji E
(cid:12)(cid:12)(cid:12) bind x = E in e
(cid:12)(cid:12)(cid:12) endorse E to ℓ
proji E
case E of inj1 (x ).e | inj2 (x ).e
decl E to ℓ
(cid:12)(cid:12)(cid:12) E e
ℓ′, η ℓ v )
(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)(cid:12)
Figure 18: Full NMIFC operational semantics.
⊢ ℓ ⊑ unit
[P-Lbl]
′ ⊑ ℓ
ℓ
′ ⊑ ℓ says τ
⊢ ℓ
⊢ ℓ ⊑ τ1
⊢ ℓ ⊑ τ2
⊢ ℓ ⊑ (τ1 × τ2)
H ∈ H
⊢ H ⊑ τ
⊢ τ prot H
H is upward closed
⊢ ℓ ⊑ τ
[P-Unit]
[P-Pair]
⊢ τ ⊑ H
[P-Set]
Figure 19: Type protection levels.
Second, the brackets track secret/untrusted information through
execution of the program, thereby making it easy to verify that it
did not interfere with public/trusted information simply by prov-
ing that brackets could not be syntactically present in such values.
Since noninterference only requires examining pairs of traces, these
purposes complement each other well; if the two executions vary
only on high inputs, then low outputs cannot contain brackets.
While this technique is very effective to prove noninterference,
nonmalleable information flow provides security guarantees even
in the presence of both declassification and endorsement. As a re-
sult, we need to track secret/untrusted information even through
Γ; pc ⊢ e : τ
[Var]
Γ, x :τ , Γ
′; pc ⊢ x : τ
[Unit]
[Lam]
Γ, x :τ1; pc′ ⊢ e : τ2
Γ; pc ⊢ λ(x :τ1)[pc′]. e : τ1
[App]
pc′−−→ τ2
Γ, X ; pc′ ⊢ e : τ
Γ; pc ⊢ ΛX [pc′]. e : ∀X [pc′]. τ
Γ; pc ⊢ () : unit
Γ; pc ⊢ e1 : τ ′ pc′−−→ τ
Γ; pc ⊢ e2 : τ ′
Γ; pc ⊢ e1 e2 : τ
pc ⊑ pc′
Γ; pc ⊢ e : ∀X [pc′]. τ
pc ⊑ pc′
) : τ [X (cid:55)→ τ ′] τ ′ is well-formed in Γ
Γ; pc ⊢ (e τ ′
Γ; pc ⊢ e1 : τ1
Γ; pc ⊢ e2 : τ2
Γ; pc ⊢ ⟨e1, e2⟩ : (τ1 × τ2)
[UnPair]
Γ; pc ⊢ e : (τ1 × τ2)
Γ; pc ⊢ proji e : τi