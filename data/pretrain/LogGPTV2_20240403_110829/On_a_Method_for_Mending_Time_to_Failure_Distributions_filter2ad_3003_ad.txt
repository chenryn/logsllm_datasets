clude both ﬁnite failures category models like the Jelinski-
Moranda model [10] and inﬁnite failures category models
like Moranda’s geometric model [16]. Due to the time-
homogeneity, all these models share the common property
that all transition rates are constant over time. As a conse-
quence, for each failure that can occur at all equation (2)
does not hold, and the TTF distribution is non-defective.
The italicized qualiﬁcation in the last sentence is required in
order to allow for the fact that homogeneous CTMC models
of the ﬁnite failures category necessarily feature an absorb-
ing state at which the Markov chain terminates. As seen in
the discussion of the Littlewood model, for the time out of
this state the entire probability mass is allocated to inﬁnity.
6. A speciﬁc all-stages truncated model
The derivation of the all-stages truncated models in Sec-
tion 4.2 is valid for any (non-defective) coverage function
G(t). Therefore, G(t) and consequently the initial NHPP-I
model have not been speciﬁed so far. In this section, we ap-
ply our approach to the well-known Goel-Okumoto model
[5] and show how to estimate the parameters of the result-
ing all-stages truncated model. We then employ this model
for ﬁtting and predicting a classic failure data set, and we
compare its performance to the one of the original Goel-
Okumoto model and the Musa-Okumoto model.
6.1. The truncated Goel-Okumoto model
The mean value function and the failure intensity of the
NHPP-I model introduced by Goel and Okumoto [5] are
µ(t) = ν(1−exp(−φt)) and λ(t) = νφ exp(−φt), (25)
respectively, implying the non-defective coverage function
(7). Plugging equation (7) into equation (24), we obtain
the mean value function of the all-stages truncated Goel-
Okumoto model (in the following referred to as the “trun-
cated Goel-Okumoto model” for brevity):
exp(ν) − 1
(cid:183)
(cid:184)
µ(t) = ln
exp[ν exp(−φt)] − 1
.
(26)
Its derivative with respect to time is the failure intensity
λ(t) =
νφ exp(−φt)
1 − exp[−ν exp(−φt)] .
(27)
From equations (4) and (26), the reliability in the interval
(ti−1, ti−1 + x] is derived as
R(x | ti−1, M(ti−1) = i − 1)
=
exp(ν exp(−φ(ti−1 + x))) − 1
exp(ν exp(−φti−1)) − 1
,
which approaches zero for x → ∞. Thus, all TTF distribu-
tions are non-defective. Moreover, it can be shown that all
mean times to failure are ﬁnite: The mean time to the ith
failure implied by the truncated Goel-Okumoto model is
(cid:90) ∞
E(Xi) =
R(x | ti−1, M(ti−1) = i − 1) dx
0
=
1
φ[exp(ν exp(−φti−1)) − 1]
∞(cid:88)
j=1
(28)
(ν exp(−φti−1))j
j · j!
for all i. The sum in the equation converges to a ﬁnite value,
as can be seen by comparing it to the Taylor series expan-
sion of the exponential function. This means that for each
failure i = 1, 2, ... the mean time to failure is ﬁnite. Since
the summands vanish rather quickly, the mean time to fail-
ure can easily be calculated based on equation (28).
Maximum likelihood estimation (MLE) can be em-
ployed for calculating point estimates of the two model
parameters ν and φ. Based on the me failure times
t1, t2, ..., tme collected while testing the software from time
0 to te (where te may be identical to or larger than tme), for
NHPP models the log-likelihood function to be maximized
with respect to the parameter vector δ takes the general form
[17, p. 324]
lnL(δ; t1, ..., tme, te) =
ln(λ(ti)) − µ(te).
(29)
i=1
With equations (26) and (27) the log-likelihood of the trun-
cated Goel-Okumoto model becomes
me(cid:88)
lnL(ν, φ; t1, ..., tme , te)
= me ln(νφ) − φ
ln [1 − exp(−ν exp(−φti))]
ti − me(cid:88)
+ ln[exp(ν exp(−φte)) − 1] − ln[exp(ν) − 1].
i=1
i=1
me(cid:88)
In Proc. International Conference on Dependable Systems and Networks 2005, Los Alamitos, 2005, pp. 560–569 c(cid:176) IEEE
567
6.2. Numerical example
For illustrating the application of the truncated Goel-
Okumoto model we use one of the data sets collected by
Musa and available at the web site of the Data & Analy-
sis Center for Software [3]. The data are from the 1970s,
but careful control had been applied during their collection
in order to ensure their high quality. Moreover, they have
been used before for validating new models and are there-
fore well-studied. The “System 40” data set consists of the
wall-clock times of 101 failures experienced during the sys-
tem test phase of a military application containing about
180,000 delivered object code instructions.
Estimation of the parameters of the truncated Goel-
Okumoto model is carried out according to the procedure
described in the last section. We also employ MLE for
ﬁtting the Goel-Okumoto model and the Musa-Okumoto
model to the data set. This is done by maximizing the
log-likelihood derived from combining equations (25), (29)
and (13), (29), respectively. Figure 6 shows the develop-
ment of the cumulative number of failure occurrences over
time for System 40 as well as the mean value functions of
the three models, with parameters estimated based on the
complete data set. Obviously, the truncated Goel-Okumoto
model does the best job in ﬁtting the actual data. This is cor-
roborated by the log-likelihood values attained by the three
models. The maximum log-likelihood value achieved by
a model during MLE can be viewed as a measure for the
possibility that the data were generated by the respective
model.
Since adding parameters to a model cannot worsen its
ﬁt, selecting the “best” model based on the log-likelihood
value would in general favor overtly complex models.
Indeed, Akaike’s [1] information criterion derived from
the Kullback-Leibler distance essentially adjusts the log-
likelihood value by penalizing for the number of model pa-
rameters. However, since all three models considered here
contain two parameters, we can simply compare the log-
likelihood values. For the Goel-Okumoto model, the trun-
cated Goel-Okumoto model and the Musa-Okumoto model,
these values are −1282.362, −1239.508 and −1251.290,
respectively. The model ranking implied by these num-
bers coincides with the visual impression given by Figure 6:
The truncated Goel-Okumoto model attains the largest log-
likelihood value and is therefore most capable in explain-
ing the collected failure data; it is followed by the Musa-
Okumoto model and the original Goel-Okumoto model.
As shown in the last section, in the truncated Goel-
Okumoto model all mean times to failure are ﬁnite. For this
data set this is also the case for the Musa-Okumoto model,
because the estimate of the parameter θ is smaller than one.
We can therefore contrast the predicted mean times to fail-
ure according to both models with the failure data. For each
model, we start out with the ﬁrst ﬁve data points, estimate
the model parameters and predict the time to the sixth fail-
ure based on the parameter estimates and the ﬁfth failure
time, using equations (14) and (28). This procedure is re-
peated, each time adding one data point, until the end of the
data set is reached. The predicted mean times to next failure
and the actual times to failure are depicted in Figure 7.
Figure 6. (Expected) Cumulative number of
failure occurrences
Figure 7. Observed times to failure and pre-
dicted mean times to failure
In Proc. International Conference on Dependable Systems and Networks 2005, Los Alamitos, 2005, pp. 560–569 c(cid:176) IEEE
568
0100020003000400050006000020406080100Time [h](Expected) Cumulative number of failure occurrencesFailure dataGoel−Okumoto modelMusa−Okumoto modeltruncated Goel−Okumoto model0204060801000200400600800Failure iObserved TTF and predicted MTTF [h]Failure dataMusa−Okumoto modeltruncated Goel−Okumoto modelThe development in the predicted E(Xi) values is quite
similar for the two models. While the mean time to fail-
ure predictions of the truncated Goel-Okumoto model are
slightly more optimistic, they seem to be less volatile than
the ones of the Musa-Okumoto model. Moreover, the for-
mer model does not only respond to the long inter-failure
times experienced by increasing the mean times to failure
predictions (as the Musa-Okumoto model does), but it al-
ready predicts this increasing trend before the ﬁrst TTF ex-
ceeding 100 hours is observed.
7. Conclusions
Defective time to failure distributions are often unreal-
istic, and they entail inﬁnite mean times to failure, mak-
ing this metric useless.
In the course of our investiga-
tions, we have been able to answer the questions listed in
the abstract: The ith time to failure distribution is defec-
tive if the transition rate into state i decreases so quickly in
time that the area below it is ﬁnite. While this can never
happen for homogeneous CTMC models, it is possible for
non-homogeneous ones. NHPP models are a special case
of the latter, and due to the equality of all transition rates
and the failure intensity, the areas below the transition rates
are related to the mean value function. If this function is
bounded as t approaches inﬁnity, i.e., for NHPP-I models,
all time to failure distributions are defective. However, there
is a generic approach with which an NHPP-I model can be
transformed into an NHPP-II model. Its application to the
Goel-Okumoto model has turned out to be both feasible and
worthwhile, since it led us to a new SRGM with desirable
properties, including all mean times to failure being ﬁnite.
References
[1] H. Akaike. Information theory and an extension of the maxi-
mum likelihood principle. In S. Kotz and N. L. Johnson, ed-
itors, Breakthroughs in Statistics - Volume I, pages 611–624.
Springer, New York, 1992.
(Reprint of the original 1973
paper).
[2] Y. Chen and N. D. Singpurwalla. Uniﬁcation of software
reliability models by self-exciting point processes. Advances
in Applied Probability, 29:337–352, 1997.
[3] Data & Analysis Center for Software. The software reliabil-
ity dataset. Available at http://www.dacs.dtic.mil/databases/
sled/swrel.shtml. (Link veriﬁed on 2004-11-16).
[4] O. Gaudoin. Outils statistiques pour l’´evaluation de la ﬁa-
bilit´e des logiciels. Th`ese de doctorat, Universit´e de Joseph
Fourier - Grenoble 1, Grenoble, 1990.
[5] A. Goel and K. Okumoto. Time-dependent error-detection
rate model for software reliability and other performance
measures. IEEE Trans. Reliability, 28:206–211, 1979.
[6] S. S. Gokhale and K. S. Trivedi. A time/structure based
software reliability model. Annals of Software Engineering,
8:85–121, 1999.
[7] M. Grottke. Prognose von Softwarezuverl¨assigkeit, Soft-
wareversagensf¨allen und Softwarefehlern.
In P. Mertens
and S. R¨assler, editors, Prognoserechnung, pages 459–487.
Physica, Heidelberg, 6th edition, 2005.
[8] C.-Y. Huang and S.-Y. Kuo. Analysis of incorporating logis-
tic testing-effort function into software reliability modeling.
IEEE Trans. Software Engineering, 51:261–270, 2002.
[9] C.-Y. Huang, S.-Y. Kuo, and I.-Y. Chen. Analysis of a
software reliability growth model with logistic testing-effort
function. In Proc. Eighth International Symposium on Soft-
ware Reliability Engineering, pages 378–388, 1997.
[10] Z. Jelinski and P. Moranda. Software reliability research.
In W. Freiberger, editor, Statistical Computer Performance
Evaluation, pages 465–484. Academic Press, New York,
1972.
[11] S. Kotz, N. L. Johnson, and C. B. Read.
Improper distri-
butions. In S. Kotz, N. L. Johnson, and C. B. Read, editors,
Encyclopedia of Statistics, volume 4, pages 25–26. John Wi-
ley & Sons, New York, 1983.
[12] L. Kuo and T. Y. Yang. Bayesian computation for nonhomo-
geneous Poisson processes in software reliability. Journal of
the American Statistical Association, 91:763–773, 1996.
[13] J. Ledoux. Software reliability modeling. In H. Pham, ed-
itor, Handbook of Reliability Engineering, pages 213–234.
Springer, London, 2003.
[14] B. Littlewood. Stochastic reliability growth: A model for
fault-removal in computer-programs and hardware-design.
IEEE Trans. Reliability, 30:313–320, 1981.
[15] D. R. Miller. Exponential order statistic models for soft-
ware reliability growth. IEEE Trans. Software Engineering,
12:12–24, 1986.
[16] P. B. Moranda. Event-altered reliability rate models for gen-
IEEE Trans. Reliability, 28:376–
eral reliability analysis.
381, 1979.
[17] J. D. Musa, A. Iannino, and K. Okumoto. Software Reliabil-
ity - Measurement, Prediction, Application. McGraw-Hill,
New York, 1987.
[18] J. D. Musa and K. Okumoto. A logarithmic Poisson exe-
cution time model for software reliability measurement. In
Proc. Seventh International Conference on Software Engi-
neering, pages 230–238, 1984.
[19] H. Pham and X. Zhang. Software release policies with gain
in reliability justifying the costs. Annals of Software Engi-
neering, 8:147–166, 1999.
[20] N. D. Singpurwalla and S. P. Wilson. Statistical Methods in
Software Engineering - Reliability and Risk. Springer Series
in Statistics. Springer, New York, 1999.
[21] K. S. Trivedi. Probability and Statistics with Reliability,
Queuing, and Computer Science Applications. John Wiley
& Sons, New York, 2001.
[22] S. Yamada, J. Hishitani, and S. Osaki. Software-reliability
growth with a Weibull test-effort. IEEE Trans. Reliability,
42:100–106, 1993.
[23] S. Yamada, H. Ohtera, and H. Narihisa. Software reliability
growth models with testing-effort. IEEE Trans. Reliability,
35:19–23, 1986.
In Proc. International Conference on Dependable Systems and Networks 2005, Los Alamitos, 2005, pp. 560–569 c(cid:176) IEEE
569