is a strict hierarchy like a tree, s = O(n), thus k = O(n).
But if there is no hierarchy at all (e.g. a clique), k = O(n2)
because all the O(n2) paths are linearly independent. Tang-
munarunkit et al. found that the power-law degree Internet
topology has moderate hierarchy [22]. It is our conjecture
that k = O(n log n).
In this section, we will show through linear regression on
both synthetic and real topologies that k is indeed bounded
by O(n log n) for reasonably large n (e.g, 100). We explain
it based on the power-law degree distribution of the Internet
topology and the AS (Autonomous System) hierarchy.
We experiment with three types of BRITE [24] router-
level topologies - Barabasi-Albert, Waxman and hierarchi-
cal models - as well as with a real router topology with
284,805 nodes [25]. For hierarchical topologies, BRITE ﬁrst
generates an autonomous system (AS) level topology with a
Barabasi-Albert model or a Waxman model. Then for each
AS, BRITE generates the router-level topologies with an-
other Barabasi-Albert model or Waxman model. So there
are four types of possible topologies. We show one of them
as an example because they all have similar trends (see [2]
for complete results).
We randomly select end hosts which have the least degree
(i.e., leaf nodes) to form an overlay network. We test by lin-
ear regression of k on O(n), O(n log n), O(n1.25), O(n1.5),
and O(n1.75). As shown in Fig. 4, results for each type of
topology are averaged over three runs with diﬀerent topolo-
gies for synthetic ones and with diﬀerent random sets of end
hosts for the real one. We ﬁnd that for Barabasi-Albert,
Waxman and real topologies, O(n) regression has the least
residual errors - actually k even grows slower than O(n).
The hierarchical models have higher k, and most of them
have O(n log n) as the best ﬁt. Conservatively speaking, we
have k = O(n log n).
Note that such trend still holds when the end hosts are
sparsely distributed in the Internet, e.g., when each end host
is in a diﬀerent access network. One extreme case is the
“star” topology - each end host is connected to the same
center router via its own access network. In such a topology,
there are only n links. Thus k = O(n). Only topologies with
very dense connectivity, like a full clique, have k = O(n2).
Those topologies have little link sharing among the end-to-
end paths.
The key observation is that when n is suﬃciently large,
such dense connectivity is very unlikely to exist in the In-
ternet because of the power-law degree distribution. Tang-
munarunkit et al.
found that link usage, as measured by
the set of node pairs (source-destination pairs) whose traf-
ﬁc traverses the link, also follows a power-law distribution,
i.e., there is a very small number of links that are on the
shortest paths of the majority of node pairs. So there is sig-
niﬁcant amount of link sharing among the paths, especially
for backbone links, customer links, and peering links.
Such link sharing can easily lead to rank deﬁciency of the
path matrix for overlay networks. As an example, consider
an overlay within a single AS. The AS with the largest num-
ber of links (exclusive of customer and peering links) in [26]
original measurement
regression on n
regression on nlogn
regression on n1.25
regression on n1.5
regression on n1.75
14000
12000
10000
8000
6000
4000
2000
)
k
(
e
c
a
p
s
h
t
a
p
f
o
k
n
a
R
original measurement
regression on n
regression on nlogn
regression on n1.25
regression on n1.5
regression on n1.75
12000
10000
8000
6000
4000
2000
)
k
(
e
c
a
p
s
h
t
a
p
f
o
k
n
a
R
0
100
200
300
400
700
Number of end hosts on the overlay (n)
500
600
800
900
1000
0
100
200
300
400
700
Number of end hosts on the overlay (n)
500
600
800
900
1000
Barabasi-Albert model of 20K nodes
Waxman model of 10K nodes
original measurement
regression on n
regression on nlogn
regression on n1.25
regression on n1.5
regression on n1.75
9000
8000
7000
6000
5000
4000
3000
2000
1000
)
k
(
e
c
a
p
s
h
t
a
p
f
o
k
n
a
R
original measurement
regression on n
regression on nlogn
regression on n1.25
regression on n1.5
regression on n1.75
x 104
7
6
5
4
3
2
1
)
k
(
e
c
a
p
s
h
t
a
p
f
o
k
n
a
R
0
100
200
300
400
700
Number of end hosts on the overlay (n)
500
600
800
900
1000
Hierarchical model of 20K nodes
0
100
200
300
700
400
Number of end hosts on the overlay (n)
500
600
800
900
1000
(AS-level: Barabasi-Albert and router level: Waxman)
A real topology of 284,805 routers
Figure 4: Regression of k in various functions of n under diﬀerent router-level topologies.
has 5,300 links. Even considering the coverage factor (55.6%
as in Table 2 of [26]), there are at most 9,600 links. Since
there are n(n − 1) paths among n nodes, link sharing must
occur before n = 100; in fact, substantial link sharing is
likely to occur for even smaller n.
Now consider an overlay network that spans two ASes
connected by y customer/peering links, with n/2 nodes in
one AS and n/2 nodes in the other. The n2/2 cross-AS
paths can be modelled as linear combination of 2y × n + 2y
virtual links - bi-directional links from each end host to its y
peering link routers, and y bi-directional peering links. Thus
given y is normally much less than n and can be viewed as
a constant, only O(n) paths need to be measured for the
O(n2) cross-AS paths.
Now consider an overlay on multiple ASes. According
to [27], there are only 20 ASes (tier-1 providers) which form
the dense core of the Internet. These ASes are connected
almost as a clique, while the rest of the ASes have far less
dense peering connectivity. So when the size of an overlay
is reasonably big (e.g., n > 100), the number of customer
and peering links that cross-AS paths traverse tends to grow
much slower than O(n2). For example, a joining end host
may only add one customer link to the overlay topology,
and share the peering links that have been used by other
end hosts. Meanwhile, only a few nodes are needed in a
single AS before link sharing occurs in paths within an AS.
We believe this heavy sharing accounts for our empirical
observation that k = O(n) in a real router-level topology,
and k grows at worst like O(n log n) in several generated
topologies. Note that the real 284,805-router topology repre-
sents a fairly complete transit portion of the Internet [25]. In
our analysis, we conservatively assume that there is only one
end host connecting to each edge router to reduce the possi-
ble path sharing, but we still ﬁnd k = O(n) when n > 100.
5. DYNAMIC ALGORITHMS FOR
TOPOLOGY CHANGES
During normal operation, new links may appear or dis-
appear, routing paths between end hosts may change, and
hosts may enter or exit the overlay network. These changes
may cause rows or columns to be added to or removed from
G, or entries in G may change. In this section, we design
eﬃcient algorithms to incrementally adapt to these changes.
5.1 Path Additions and Deletions
The basic building blocks for topology updates are path
additions and deletions. We have already handled path ad-
ditions in Algorithm 1; adding a path v during an update
is no diﬀerent than adding a path v during the initial scan
of G. In both cases, we decide whether to add v to ¯G and
update R.
To delete a path that is not in ¯G is trivial; we just remove
it from G. But to remove a path from ¯G is more compli-
cated. We need to update R; this can be done in O(k2)
time by standard algorithms (see e.g. Algorithm 3.4 in [28,
p.338]). In general, we may then need to replace the deleted
path with another measurement path. Finding a replace-
ment path, or deciding that no such path is needed, can
be done by re-scanning the rows of G as in Algorithm 1;
however, this would take time O(rk2).
procedure DeletePath(v, G, ¯G, R)
1 if deleted path v is measured then
2
3
j = index of v in ¯G
y = ¯GT R−1R−T ej
Remove v from G and ¯G
Update R (Algorithm 3.4 in [28, p.338])
r = Gy
if ∃ i such that ri (cid:10)= 0 then
4
5
6
7
8
Add the ith path from G to ¯G (Algorithm 1,
steps 2-6)
end
end
9 else Remove v from G
Algorithm 2: Path deletion algorithm
We now describe Algorithm 2 to delete a path v more ef-
ﬁciently. Suppose v corresponds to the ith row in ¯G and the
jth row in G, we deﬁne ¯G(cid:3) ∈ R
(k−1)×s as the measurement
path matrix after deleting the ith row, and G(cid:3) ∈ R
(r−1)×s
as the path matrix after removing the jth row. By deleting
v from ¯G, we reduce the dimension of ¯G from k to k − 1.
Intuitively, our algorithm works in the following two steps.
1. Find a vector y that only describes the direction re-
moved by deleting the ith row of ¯G.
2. Test if the path space of G(cid:3)
is orthogonal to that direc-
tion, i.e., ﬁnd whether there is any path p ∈ G(cid:3)
that
has a non-zero component on that direction. If not, no
replacement path is needed. Otherwise, replace v with
any of such path p, and update the QR decomposition.
Next, we describe how each step is implemented. To ﬁnd
y which is in the path space of ¯G but not of ¯G(cid:3)
, we solve
the linear system ¯Gy = ei, where ei is the vector of all
zeros except for a one in entry i. This system is similar to
the linear system we solved to ﬁnd xG, and one solution is
y = ¯GT R−1R−T ei.
Once we have computed y, we compute r = G(cid:3)y, where
G(cid:3)
is the updated G matrix. Because we chose y to make
¯G(cid:3)y = 0, all the elements of r corresponding to selected
rows are zero. Paths such that rj (cid:10)= 0 are guaranteed to
be independent of ¯G(cid:3)
, since if row j of G could be written
as wT ¯G(cid:3)
for some w, then rj would be wT ¯G(cid:3)y = 0. If all
elements of r are zero, then y is a null vector for all of G(cid:3)
;
is k− 1,
in this case, the dimension k(cid:3)
and we do not need to replace the deleted measurement
path. Otherwise, we can ﬁnd any j such that rj (cid:10)= 0 and
add the jth path to ¯G(cid:3)
of the row space of G(cid:3)
to replace the deleted path.
Take the overlay network in Fig. 3 for example, suppose ¯G
is composed of the paths AB and BC, i.e., ¯G = (cid:20)1 1 0
1 1 1(cid:21).
Then we delete path BC, ¯G(cid:3) = [1 1 0]T and G(cid:3)
= (cid:20)1 1 0
0 0 1(cid:21).
Applying Algorithm 2, we have y = [0 0 1]T and r =
[0 1]T . Thus the second path in G(cid:3)
, AC, should be added
to ¯G(cid:3)
. If we visualize such path deletion in reference to the
geometry of the linear system, the path space of G(cid:3)
remains
as a plane in Fig. 3, but ¯G(cid:3)
only has one dimension of the
path space left, so we need to add AC to ¯G(cid:3).
When deleting a path used in ¯G, the factor R can be up-
dated in O(k2) time. To ﬁnd a replacement row, we need to
compute a sparse matrix-vector product involving G, which
takes O(n2 × (average path length)) operations. Since most
routing paths are short, the dominant cost will typically be
the update of R. Therefore, the complexity of Algorithm 2
is O(k2).
5.2 End Hosts Join/Leave the Overlay
To add an end host h, we use Algorithm 1 to scan all
the new paths from h, for a cost of O(nk2). However, it is
ineﬃcient to delete an end host h by directly using Algo-
rithm 2 to delete all aﬀected paths. If Algorithm 2 is used
to delete a path that starts/ends at h, often another path
that starts/ends at h is chosen as a replacement – and soon
deleted in turn. To avoid this behavior, we remove all these
paths from G ﬁrst, then use the updated G in Algorithm 2 to
select replacements as needed during the removal of paths
that start/end at h. Each path in ¯G can be removed in
O(k2) time; the worst-case total cost of end host deletion is
then O(nk2).
5.3 Routing Changes
In the network, routing changes or link failures can af-
fect multiple paths in G. Previous studies have shown that
end-to-end Internet paths generally tend to be stable for sig-
niﬁcant lengths of time, e.g., for at least a day [29, 30]. So we
can incrementally measure the topology to detect changes.
Each end host measures the paths to all other end hosts
daily, and for each end host, such measurement load can be
evenly distributed throughout the day. In addition to the
periodic route measurement, if any path is found to have
large loss rate changes, we will check its route instantly.
For each link, we keep a list of the paths that traverse
it. If any path is reported as changed for certain link(s), we
will examine all other paths that go through those link(s)
because it is highly likely that those paths can change their
routes as well. We use Algorithms 1 and 2 to incrementally
incorporate each path change.
Unlike O(n2) approaches (e.g., RON), we need some extra
traceroute measurement. However, the key point is that the
end-to-end routing remains much more stable than its loss
rate, thus requires far less frequent measurement. So the
savings on loss rate probing dwarf the traceroute overhead.
6. LOAD BALANCING AND TOPOLOGY
ERROR HANDLING
To further improve the scalability and accuracy, we need
to have good load balancing and handle topology measure-
ment errors, as discussed in this section.
6.1 Measurement Load Balancing
To avoid overloading any single node or its access link, we
evenly distribute the measurements among the end hosts.
We randomly reorder the paths in G before scanning them
for selection in Algorithm 1. Since each path has equal prob-
ability of being selected for monitoring, the measurement
load on each end host is similar. Note any basis set gen-
erated from Algorithm 1 is suﬃcient to describe all paths
G. Thus the load balancing has no eﬀect on the loss rate
estimation accuracy.
6.2 Handling Topology Measurement Errors
As our goal is to estimate the end-to-end path loss rate
instead of any interior link loss rate, we can tolerate cer-
tain topology measurement inaccuracies, such as incomplete
routing information and poor router alias resolution.
For completely untraceable paths, we add a direct link
between the source and the destination.
In our system,
these paths will become selected paths for monitoring. For
paths with incomplete routing information, we add links
from where the normal route becomes unavailable (e.g., self
loops or displaying “* * *” in traceroute), to where the nor-
mal route resumes or to the destination if such anomalies
persist until the end. For instance, if the measured route is
(src, ip1, “* * *”, ip2, dest), the path is composed of three
links: (src ip1), (ip1, ip2), and (ip2, dest). By treating the
untraceable path (segment) as a normal link, the resulting
topology is equivalent to the one with complete routing in-
formation for calculating the path loss rates.
For topologies with router aliases presenting one physi-
cal link as several links, we have little need to resolve these
aliases. At worst, our failure to recognize the links as the
same will result in a few more path measurements because
the rank of G will be higher. For these links, their cor-
responding entries in xG will be assigned similar values be-
cause they are actually a single link. Thus the path loss rate
estimation accuracy is not aﬀected, as veriﬁed by Internet
experiments in Sec. 8. In addition, our system is robust to
measurement node failures and node changes by providing
bounds on the estimated loss rates.
7. EVALUATION
In this section, we present our evaluation metrics, simu-
lation methodology and simulation results.
7.1 Metrics
The metrics include path loss rate estimation accuracy,
variation of measurement loads among the end hosts, and
speed of setup, update, and topology change adaptation.
To compare the inferred loss rate ˆp with real loss rate p, we
analyze both absolute error and error factor. The absolute
error is |p − ˆp|. We adopt the error factor Fε(p, ˆp) deﬁned
in [9] as follows:
Fε(p, ˆp) = max(cid:26) p(ε)
ˆp(ε)
, ˆp(ε)
p(ε)(cid:27)
(7)
where p(ε) = max(ε, p) and ˆp(ε) = max(ε, ˆp). Thus, p and
ˆp are treated as no less than ε, and then the error factor is
the maximum ratio, upwards or downwards, by which they
diﬀer. We use the default value ε = 0.001 as in [9]. If the
estimation is perfect, the error factor is one.
Furthermore, we classify a path to be lossy if its loss rate
exceeds 5%, which is the threshold between “tolerable loss”
and “serious loss” as deﬁned in [20]. We report the true
number of lossy paths, the percentage of real lossy paths
identiﬁed (coverage) and the false positive rate, all averaged
over ﬁve runs of experiment for each conﬁguration.
There are two types of measurement load: 1) sending
probes, and 2) receiving probes and computing loss rates.
The load reﬂects the CPU and uplink/downlink bandwidth
consumption. For each end host h, its measurement load is
linearly proportional to, and thus denoted by the number of
monitored paths with h as sender/receiver. Then we com-
pute its variation across end hosts in terms of the coeﬃcient
of variation (CV) and the maximum vs. mean ratio (MMR),
for sending load and receiving load separately. The CV of
a distribution x, deﬁned as below, is a standard metric for
measuring inequality of x, while the MMR checks if there is
any single node whose load is signiﬁcantly higher than the
average load.
CV (x) =
standard deviation(x)
mean(x)
(8)
The simulations only consider undirected links, so for each
monitored path, we randomly select one end host as sender
and the other as receiver. This is applied to all simulations
with or without load balancing.
7.2 Simulation Methodology
We consider the following dimensions for simulation.
• Topology type: three types of synthetic topologies from
BRITE (see Sec. 7.3) and a real router-level topology
from [25]. All the hierarchical models have similar re-
sults, we just use Barabasi-Albert at the AS level and
Waxman at the router level as the representative.
• Topology size: the number of nodes ranges from 1000
to 20000 2. Note that the node count includes both
internal nodes (i.e., routers) and end hosts.
• Fraction of end hosts on the overlay network: we de-
ﬁne end hosts to be the nodes with the least degree.
Then we randomly choose from 10% to 50% of end
hosts to be on the overlay network. This gives us
pessimistic results because other distributions of end
hosts will probably have more sharing of the routing
paths among them. We prune the graphs to remove
the nodes and links that are not referenced by any path
on the overlay network.
• Link loss rate distribution: 90% of the links are classi-
ﬁed as “good” and the rest as “bad”. We use two dif-
ferent models for assigning loss rate to links as in [10].
In the ﬁrst model (LLRD1), the loss rate for good links
is selected uniformly at random in the 0-1% range and
that for bad links is chosen in the 5-10% range.
In
the second model (LLRD2), the loss rate ranges for
good and bad links are 0-1% and 1-100% respectively.
Given space limitations, most results are under model
LLRD1 except for Sec. 7.4.
• Loss model: After assigning each link a loss rate, we
use either a Bernoulli or a Gilbert model to simulate
the loss processes at each link. For a Bernoulli model,
each packet traversing a link is dropped at indepen-