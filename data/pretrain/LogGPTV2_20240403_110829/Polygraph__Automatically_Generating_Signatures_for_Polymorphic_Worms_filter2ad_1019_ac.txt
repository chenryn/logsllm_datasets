payload as a worm, we state that the signature set causes a
false negative for that network ﬂow.
3.3. Design Goals
Polygraph7 must meet several design goals to work ef-
fectively:
Signature quality. Our end-to-end goal in Polygraph, as
has been the case in prior worm signature generation sys-
tems, is to generate signatures that offer low false positives
for innocuous trafﬁc and low false negatives for worm in-
stances, including polymorphic worm instances.
Efﬁcient signature generation. The signature types pro-
posed in Section 2.5 are more complex than the single sub-
string signatures generated automatically by today’s signa-
ture generation systems. To the extent possible, we seek to
minimize the computational cost of signature generation in
the size of the suspicious ﬂow pool. Thus, we seek efﬁcient
algorithms for signature generation.
Efﬁcient signature matching. Each signature type also in-
curs a different computational cost during matching against
network trafﬁc. We characterize these matching costs for
each signature type, to argue for the tractability of ﬁltering
using these more complex signatures.
Generation of small signature sets. Some constraint must
be made on the number of signatures Polygraph generates
to match a suspicious ﬂow pool. In the extreme case, Poly-
graph might generate one signature for each polymorphic
payload. Clearly, such behavior does not qualify as gen-
erating a signature that matches a polymorphic worm. We
seek to minimize the number of signatures Polygraph gen-
erates for a suspicious ﬂow pool, without sacriﬁcing signa-
ture quality (causing false positives). Such sets of signatures
cost less bandwidth to disseminate, and cost less to match
at trafﬁc ﬁltering time.
7For the remainder of the paper, we refer to the Polygraph signature
generator as Polygraph, in the interest of brevity.
Robustness against noise and multiple worms. A suc-
cessful signature generator must generate high-quality sig-
natures on workloads that contain noise or a mixture of
different worms on the same destination port. If the sys-
tem cannot ﬁnd a fully general signature that matches all
worms in the pool and does not cause false positives, it
should instead generate multiple signatures, each of which
matches some subset of ﬂows in the suspicious ﬂow pool
(most likely a subset that employ the same exploit), and
such that the set of signatures together exhibits low false
positives and low false negatives.
Robustness against evasion and subversion. An adver-
sary who knows the design of Polygraph may attempt to
evade or subvert the system. Several well known attacks
against IDS systems may be mounted against Polygraph,
but there are novel attacks speciﬁc to Polygraph as well.
An adversary may, for example, evolve a worm’s payload
over time, in an effort to cause signatures previously gener-
ated by Polygraph to cease matching the worm. We con-
sider several evasion and subversion strategies an adver-
sary might adopt in Section 6, and describe defenses against
them.
4. Signature Generation Algorithms
In this section, we will describe our algorithms for auto-
matically generating signatures of different classes includ-
ing conjunction signatures, token subsequence signatures,
and Bayes signatures. For ease of explanation, we ﬁrst con-
sider the problem of generating one signature that matches
every sample (or most of the samples) in the suspicious ﬂow
pool. However, when the suspicious ﬂow pool has noise or
contains a mix of different worms (or a worm with different
attack vectors), generating one signature that matches every
ﬂow is not always possible or will result in low-quality sig-
natures. In Section 4.3, we will show how these algorithms
can be adapted to handle the cases when there is noise and
when there are multiple worms in the suspicious pool, by
generating a set of signatures where each signature in the set
only matches part of the suspicious pool and the set of sig-
natures together match the samples in the suspicious pool.
Many of the algorithms described in this section are
based on algorithms found in [11].
4.1. Preprocessing: Token Extraction
We deﬁne a token to be a contiguous byte sequence.
Each signature in the signature classes that we consider is
made up of one or more such tokens. Here we discuss al-
gorithms for extracting and analyzing tokens, which will be
used in our algorithms for creating signatures.
As a preprocessing step before signature generation, we
extract all of the distinct substrings of a minimum length
Proceedings of the 2005 IEEE Symposium on Security and Privacy (S&P’05) 
1081-6011/05 $ 20.00 IEEE
that occur in at least K out of the total n samples in the
suspicious pool. By distinct, we mean that we do not want
to use a token that is a substring of another token, unless it
occurs in at least K out of n samples not as a substring of
that token. For example, suppose one of the substrings oc-
curring in at least K out of the n samples is “HTTP”. “TTP”
is not a distinct substring unless it occurs in at least K of the
n samples, not as a substring of “HTTP”.
There is a well-known algorithm to ﬁnd the longest sub-
string that occurs in at least K of n samples [12], in time lin-
ear in the total length of the samples. That algorithm can be
trivially modiﬁed to return a set of substrings that includes
all of the distinct substrings that occur in at least K out of
n samples, but also includes some of the non-distinct sub-
strings, in the same time bound. We can then prune out the
non-distinct substrings and ﬁnally output the set of tokens
for use in signature generation.
Token extraction can be viewed as a ﬁrst step toward
eliminating the irrelevant parts of suspicious ﬂows. After
the token extraction, we can simply represent each suspi-
cious ﬂow as a sequence of tokens, and remove the rest of
the payload.
4.2. Generating Single Signatures
We next describe our algorithms that automatically gen-
erate a single signature that matches all (or most of) the
suspicious ﬂow pool. Note that this approach of forcing all
(or most of) the suspicious ﬂow pool to be matched using
a single signature is not resilient against noise or when the
suspicious ﬂow pool contains a mixture of different worms.
We present our full algorithms to address these issues in
Section 4.3.
4.2.1. Generating Conjunction Signatures
A conjunction signature consists of an unordered set of to-
kens, where a sample matches the signature if and only if
it contains every token in the signature. To generate one
conjunction signature matching every sample in the pool,
we can simply use the token extraction algorithm described
above to ﬁnd all the distinct tokens that appear in every sam-
ple of the suspicious pool. The signature is then this set of
tokens. The running time of the algorithm is linear in the
total byte length of the suspicious pool.
4.2.2. Generating Token-Subsequence Signatures
A token-subsequence signature is an ordered list of tokens.
A sample matches a token-subsequence signature if and
only if the subsequence of tokens is in the sample. To gen-
erate a token-subsequence signature, we want to ﬁnd an or-
dered sequence of tokens that is present in every sample in
the suspicious pool. We begin by showing how to ﬁnd the
signature from two samples, and then show how we can use
that algorithm to ﬁnd a token-subsequence signature for any
number of samples.
For example,
A subsequence of two strings is a sequence of bytes
that occur in the same order in both strings, though not
necessarily consecutively.
in the strings
“xxonexxxtwox” and “oneyyyyytwoyy”, the longest com-
mon subsequence is “onetwo”. The problem of ﬁnding the
longest common subsequence of two strings can be framed
as a string alignment problem. That is, given two strings,
we wish to align them in such a way as to maximize the
number of characters aligned with a matching character.
The alignment that gives the longest subsequence in the pre-
vious examples is:
x x o n e x x x - - t w o x -
- - o n e y y y y y t w o y y
This alignment can be described by the regular expression
“.*one.*two.*”.
Note that the longest subsequence does not maximize
consecutive matches, only the total number of matches. For
example, consider the strings “oxnxexzxtwox” and “ytwoy-
oynyeyz”. The alignment corresponding to the longest sub-
sequence is:
- - - - - o x n x e x z x t w o x
y t w o y o y n y e y z - - - - -
This results in the signature “.*o.*n.*e.*z.*”. However,
in this case we would prefer to generate the signature
“.*two.*”, which corresponds to the alignment:
o x n x e x z x t w o x - - - - - - -
- - - - - - - y t w o y o y n y e y z
Although the second alignment produces a shorter subse-
quence, the fact that all the bytes are contiguous produces
a much better signature. (We can use the technique in Ap-
pendix A to show that the ﬁrst signature has a 54.8% chance
of matching a random 1000-byte string, while the second
signature has only a .0000595% chance). Thus, we need to
use a string alignment algorithm that prefers subsequences
with contiguous substrings.
We use an adaptation of the Smith-Waterman [23] al-
gorithm to ﬁnd such an alignment. An alignment is as-
signed a score by adding 1 for each character that is aligned
with a matching character, and subtracting a gap penalty Wg
for each maximal sequence of spaces and/or non-matching
characters.8 That is, there is a gap for every “.*” in the re-
sulting signature. However, we do not count the ﬁrst and
the last “.*”, which are always present. In our experiments,
we set Wg to 0.8 (We used the technique in Appendix A to
help choose this value, based on minimizing the chance of
the resulting signature matching unrelated strings). Using
these parameters, the score for the alignment producing the
signature “.*o.*n.*e.*z.*” has a value of 4 − 3 .8 = 1.6,
8This differs from the common deﬁnition of a gap, which is a maximal
sequence of spaces.
Proceedings of the 2005 IEEE Symposium on Security and Privacy (S&P’05) 
1081-6011/05 $ 20.00 IEEE
while the score for the alignment producing the signature
“.*two.*” has a value of 3 − 0 .8 = 3. Hence, the latter sig-
nature would be preferred. The Smith-Waterman algorithm
ﬁnds the highest-scoring alignment between two strings in
O(nm)time and space, where n and m are the lengths of the
strings.9
We generate a signature that matches every sample in the
suspicious pool by ﬁnding a subsequence of tokens that is
present in each sample. We ﬁnd this by iteratively applying
the string-alignment algorithm just described. After each
step, we replace any gaps in the output with a special gap
character
, and ﬁnd the best alignment between it and the
next sample. Note that this algorithm is greedy, and could
reach a local minimum. To help reduce this risk, we ﬁrst use
the token extraction algorithm to ﬁnd the tokens present in
every sample, and then convert each sample to a sequence
of tokens separated by . This helps prevent an early align-
ment from aligning byte sequences that are not present in
other samples. It also has the added beneﬁt of reducing the
lengths of the strings, and hence the running time of the
Smith-Waterman pairwise comparisons.
If the suspicious pool consists of s samples, each n bytes
long, the running time is O(n)to perform the token extrac-
tion, plus O(sn2)to perform the alignments.
4.2.3. Generating Bayes Signatures
The conjunction and token-subsequence classes of signa-
tures assume that the distinction between worms and in-
nocuous ﬂows involves an exact pattern of a set of tokens.
However, the distinction between worms and innocuous
ﬂows may instead be a difference in the probability dis-
tributions over sets of tokens that may be present. Thus,
given two different distributions over sets of tokens (e.g.,
for worms and innocuous ﬂows), we could classify a ﬂow
by the distribution from which its token set is more likely
to have been generated. This type of signature allows for
probabilistic matching and classiﬁcation, rather than for ex-
act matches, and may be more resilient to noise and changes
in the trafﬁc.
We study the na¨ıve Bayes classiﬁer as a ﬁrst step toward
exploring this class of signatures. This model is character-
ized by the following independence assumption: the prob-
ability of a token being present in a string, when the string
is known to be a worm or an innocuous string, is indepen-
dent of the presence of other tokens in the string. This as-
sumption often holds approximately in many practical sce-
narios, and is simple enough to allow us to focus on the
important question, i.e., how such a probabilistic matching
scheme compares to the exact matching schemes. In addi-
tion, a na¨ıve Bayes classiﬁer needs far fewer examples to
9Hirchberg’s algorithm can reduce the space bound to O(m), where m
is the length of the longer string.
Proceedings of the 2005 IEEE Symposium on Security and Privacy (S&P’05) 
1081-6011/05 $ 20.00 IEEE
approach its asymptotic error, in comparison to many other
models; thus, it will yield very good results when it is used
with an extremely large number of dimensions (i.e. tokens,
in our case) and a moderately sized suspicious pool. In fu-
ture work, we can easily relax this independence assump-
tion and extend the na¨ıve Bayes model to other more com-
plex Bayesian models to allow more complex dependencies
in the presence of sets of tokens.
As in the conjunction and subsequence signature gen-
eration, the ﬁrst step in generating a Bayes signature is to
choose the set of tokens to use as features, as described
in Section 4.1. Assume that we have a set of n tokens,
{Ti}1 i n, from the preprocessing step. Thus, a ﬂow x could
be denoted with a vector (x1,...,xn) in {0,1}n, where the
ith bit xi is set to 1 if and only if the ith token Ti is present
somewhere in the string.
We then calculate the empirical probability of a token
occurring in a sample given the classiﬁcation of the sample
(a worm or not a worm), i.e., for each token Ti, we compute
the probability that the token Ti is present in a worm ﬂow,
denoted as ti, and the probability that the token Ti is present
in an innocuous ﬂow, denoted as si. We calculate ti sim-
ply as the fraction of samples in the suspicious ﬂow pool
that the token Ti occurs in. We estimate si, the probability
of a token occurring in innocuous trafﬁc, by measuring the
fraction of samples it appears in the innocuous pool, and by
calculating it using the technique described in Appendix A.
We use whichever value is greater, in an effort to minimize
the risk of false positives.
Given a sample x, let L(x) denote the true label of x,
i.e., L(x)= worm denotes x is a worm, and L(x)= worm
denotes x is not a worm. Thus, to classify a sample x =
(x1,...,xn), we wish to compute Pr[L(x)= worm|x]and
Pr[L(x)= worm|x].
To calculate Pr[L(x)= worm|x], we use Bayes law.
Pr[L(x)= worm|x]
Pr[x|L(x)= worm]
=
Pr[x]
Pr[L(x)= worm]
From the independence assumption of the na¨ıve Bayes
model, we can compute this as follows:
=
Pr[L(x)= worm]
Pr[x]
1 i n
Pr[xi = 1|L(x)= worm].
We only need to estimate the quantity Pr[L(x)= worm|x]
Pr[L(x)= worm|x]
(i.e., if this is greater than 1, then the x is more likely to have
been generated by a worm, and vice-versa).
Pr[L(x)= worm|x]
Pr[L(x)= worm|x]
=
Pr[L(x)= worm]· 1 i n Pr[xi = 1|L(x)= worm]
Pr[L(x)= worm]· 1 i n Pr[xi = 1|L(x)= worm]
To calculate the result, we need to ﬁnd a value to use
for Pr[L(x)= worm], i.e., the probability that any partic-
ular ﬂow is a worm. This value is difﬁcult to determine,
and changes over time. We simply set Pr[L(x)= worm]=
Pr[L(x)= worm]= .5. Since false positives are often con-
sidered more harmful than false negatives, we set a thresh-
old so that the classiﬁer reports positive only if it is suf-
ﬁciently far away from the decision boundary. Given a de-
sired maximum false positive rate, the value of the threshold
to use is automatically set by running the classiﬁer on the
innocuous trafﬁc pool and the suspicious trafﬁc pool, and
selecting a threshold that minimizes the “negative” classi-
ﬁcations in the suspicious trafﬁc pool while achieving no
more than the maximum false positive rate in the innocuous
trafﬁc pool.
In practice, we transform the formula above such that
each token is assigned a score based on the log of its term in
the formula. To classify a sample, the scores of the tokens
it contains are added together.
If a token is present in a
sample multiple times, it is counted only once. If the total
score is greater than the threshold, the sample is classiﬁed
as a worm. This transformation allows the signatures to
be more human-understandable than if we were to use the
probability calculations directly.
4.3. Generating multiple signatures