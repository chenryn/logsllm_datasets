son. If time and budget allows, organize a team summit so that all members of the
team can interact in person. A summit also provides a great opportunity to hash out
designs and goals. For situations where neutrality is important, it’s advantageous to
hold team summits at a neutral location so that no individual site has the “home
advantage.”
Finally, use the project management style that suits the project in its current state.
Even projects with ambitious goals will start out small, so the overhead should be
correspondingly low. As the project grows, it’s appropriate to adapt and change how
the project is managed. Given sufficient growth, full project management will be
necessary.
Collaboration Outside SRE
As we suggested, and Chapter 32 discusses, collaboration between the product devel‐
opment organization and SRE is really at its best when it occurs early on in the design
phase, ideally before any line of code has been committed. SREs are best placed to
make recommendations about architecture and software behavior that can be quite
difficult (if not impossible) to retrofit. Having that voice present in the room when a
new system is being designed goes better for everyone. Broadly speaking, we use the
Objectives & Key Results (OKR) process [Kla12] to track such work. For some service
teams, such collaboration is the mainstay of what they do—tracking new designs,
making recommendations, helping to implement them, and seeing those through to
production.
Case Study: Migrating DFP to F1
Large migration projects of existing services are quite common at Google. Typical
examples include porting service components to a new technology or updating com‐
ponents to support a new data format. With the recent introduction of database tech‐
nologies that can scale to a global level such as Spanner [Cor12] and F1 [Shu13],
Google has undertaken a number of large-scale migration projects involving databa‐
ses. One such project was the migration of the main database of DoubleClick for Pub‐
lishers (DFP)5 from MySQL to F1. In particular, some of this chapter’s authors were
in charge of a portion of the serving system (shown in Figure 31-1) that continually
extracts and processes data from the database, in order to generate a set of indexed
files that are then loaded and served around the world. This system was distributed
over several datacenters and used about 1,000 CPUs and 8 TB of RAM to index 100
TB of data every day.
5 DoubleClick for Publishers is a tool for publishers to manage ads served on their websites and in their apps.
Collaboration Outside SRE | 437
Figure 31-1. A generic ads serving system
The migration was nontrivial: in addition to migrating to a new technology, the data‐
base schema was significantly refactored and simplified thanks to the ability of F1 to
store and index protocol buffer data in table columns. The goal was to migrate the
processing system so that it could produce an output perfectly identical to the exist‐
ing system. This allowed us to leave the serving system untouched and to perform,
from the user’s perspective, a seamless migration. As an added restriction, the prod‐
uct required that we complete a live migration without any disruption of the service
to our users at any time. In order to achieve this, the product development team and
the SRE team started working closely, from the very beginning, to develop the new
indexing service.
As its main developers, product development teams are typically more familiar with
the Business Logic (BL) of the software, and are also in closer contact with the Prod‐
uct Managers and the actual “business need” component of products. On the other
hand, SRE teams usually have more expertise pertaining to the infrastructure compo‐
nents of the software (e.g., libraries to talk to distributed storage systems or databa‐
ses), because SREs often reuse the same building blocks across different services,
learning the many caveats and nuances that allow the software to run scalably and
reliably over time.
From the start of the migration project, product development and SRE knew they
would have to collaborate even more closely, conducting weekly meetings to sync on
the project’s progress. In this particular case the BL changes were partially dependent
upon infrastructure changes. For this reason the project started with the design of the
new infrastructure; the SREs, who had extensive knowledge about the domain of
438 | Chapter 31: Communication and Collaboration in SRE
extracting and processing data at scale, drove the design of the infrastructure
changes. This involved designing how to extract the various tables from F1, how to
filter and join the data, how to extract only the data that changed (as opposed to the
entire database), how to sustain the loss of some of the machines without impacting
the service, how to ensure that the resource usage grows linearly with the amount of
extracted data, the capacity planning, and many other similar aspects. The new pro‐
posed infrastructure was similar to other services that were already extracting and
processing data from F1. Therefore, we could be sure of the soundness of the solution
and reuse parts of the monitoring and tooling.
Before proceeding with the development of this new infrastructure, two SREs pro‐
duced a detailed design document. Then, both the product development and SRE
teams thoroughly reviewed the document, tweaking the solution to handle some edge
cases, and eventually agreed on a design plan. Such a plan clearly identified what kind
of changes the new infrastructure would bring to the BL. For example, we designed
the new infrastructure to extract only changed data, instead of repeatedly extracting
the entire database; the BL had to take into account this new approach. Early on, we
defined the new interfaces between infrastructure and BL, and doing so allowed the
product development team to work independently on the BL changes. Similarly, the
product development team kept SRE informed of BL changes. Where they interacted
(e.g., BL changes dependent on infrastructure), this coordination structure allowed us
to know changes were happening, and to handle them quickly and correctly.
In later phases of the project, SREs began deploying the new service in a testing envi‐
ronment that resembled the project’s eventual finished production environment. This
step was essential to measure the expected behavior of the service—in particular, per‐
formance and resource utilization—while the development of BL was still underway.
The product development team used this testing environment to perform validation
of the new service: the index of the ads produced by the old service (running in pro‐
duction) had to match perfectly the index produced by the new service (running in
the testing environment). As suspected, the validation process highlighted discrepan‐
cies between the old and new services (due to some edge cases in the new data for‐
mat), which the product development team was able to resolve iteratively: for each ad
they debugged the cause of the difference and fixed the BL that produced the bad out‐
put. In the meantime, the SRE team began preparing the production environment:
allocating the necessary resources in a different datacenter, setting up processes and
monitoring rules, and training the engineers designated to be on-call for the service.
The SRE team also set up a basic release process that included validation, a task usu‐
ally completed by the product development team or by Release Engineers but in this
specific case was completed by SREs to speed up the migration.
When the service was ready the SREs prepared a rollout plan in collaboration with
the product development team and launched the new service. The launch was very
successful and proceeded smoothly, without any visible user impact.
Case Study: Migrating DFP to F1 | 439
Conclusion
Given the globally distributed nature of SRE teams, effective communication has
always been a high priority in SRE. This chapter has discussed the tools and techni‐
ques that SRE teams use to maintain effective relationships among their team and
with their various partner teams.
Collaboration between SRE teams has its challenges, but potentially great rewards,
including common approaches to platforms for solving problems, letting us focus on
solving more difficult problems.
440 | Chapter 31: Communication and Collaboration in SRE
CHAPTER 32
The Evolving SRE Engagement Model
Written by Acacio Cruz and Ashish Bhambhani
Edited by Betsy Beyer and Tim Harvey
SRE Engagement: What, How, and Why
We’ve discussed in most of the rest of this book what happens when SRE is already in
charge of a service. Few services begin their lifecycle enjoying SRE support, so there
needs to be a process for evaluating a service, making sure that it merits SRE support,
negotiating how to improve any deficits that bar SRE support, and actually instituting
SRE support. We call this process onboarding. If you are in an environment where
you are surrounded by a lot of existing services in varying states of perfection, your
SRE team will probably be running through a prioritized queue of onboardings for
quite a while until the team has finished taking on the highest-value targets.
Although this is very common, and a completely reasonable way of dealing with a fait
accompli environment, there are actually at least two better ways of bringing the wis‐
dom of production, and SRE support, to services old and new alike.
In the first case, just as in software engineering—where the earlier the bug is found,
the cheaper it is to fix—the earlier an SRE team consultation happens, the better the
service will be and the quicker it will feel the benefit. When SRE is engaged during
the earliest stages of design, the time to onboard is lowered and the service is more
reliable “out of the gate,” usually because we don’t have to spend the time unwinding
suboptimal design or implementation.
Another way, perhaps the best, is to short-circuit the process by which specially cre‐
ated systems with lots of individual variations end up “arriving” at SRE’s door. Pro‐
vide product development with a platform of SRE-validated infrastructure, upon
which they can build their systems. This platform will have the double benefit of
being both reliable and scalable. This avoids certain classes of cognitive load prob‐
441
lems entirely, and by addressing common infrastructure practices, allows product
development teams to focus on innovation at the application layer, where it mostly
belongs.
In the following sections, we’ll spend some time looking at each of these models in
turn, beginning with the “classic” one, the PRR-driven model.
The PRR Model
The most typical initial step of SRE engagement is the Production Readiness Review
(PRR), a process that identifies the reliability needs of a service based on its specific
details. Through a PRR, SREs seek to apply what they’ve learned and experienced to
ensure the reliability of a service operating in production. A PRR is considered a pre‐
requisite for an SRE team to accept responsibility for managing the production
aspects of a service.
Figure 32-1 illustrates the lifecycle of a typical service. The Production Readiness
Review can be started at any point of the service lifecycle, but the stages at which SRE
engagement is applied have expanded over time. This chapter describes the Simple
PRR Model, then discusses how its modification into the Extended Engagement
Model and the Frameworks and SRE Platform structure allowed SRE to scale their
engagement process and impact.
Figure 32-1. A typical service lifecycle
442 | Chapter 32: The Evolving SRE Engagement Model
The SRE Engagement Model
SRE seeks production responsibility for important services for which it can make
concrete contributions to reliability. SRE is concerned with several aspects of a ser‐
vice, which are collectively referred to as production. These aspects include the
following:
• System architecture and interservice dependencies
• Instrumentation, metrics, and monitoring
• Emergency response
• Capacity planning
• Change management
• Performance: availability, latency, and efficiency
When SREs engage with a service, we aim to improve it along all of these axes, which
makes managing production for the service easier.
Alternative Support
Not all Google services receive close SRE engagement. A couple of factors are at play
here:
• Many services don’t need high reliability and availability, so support can be pro‐
vided by other means.
• By design, the number of development teams that request SRE support exceeds
the available bandwidth of SRE teams (see Chapter 1).
When SRE can’t provide full-fledged support, it provides other options for making
improvements to production, such as documentation and consultation.
Documentation
Development guides are available for internal technologies and clients of widely used
systems. Google’s Production Guide documents production best practices for serv‐
ices, as determined by the experiences of SRE and development teams alike. Develop‐
ers can implement the solutions and recommendations in such documentation to
improve their services.
The SRE Engagement Model | 443
Consultation
Developers may also seek SRE consulting to discuss specific services or problem
areas. The Launch Coordination Engineering (LCE) team (see Chapter 27) spends a
majority of its time consulting with development teams. SRE teams that aren’t specifi‐
cally dedicated to launch consultations also engage in consultation with development
teams.
When a new service or a new feature has been implemented, developers usually con‐
sult with SRE for advice about preparing for the Launch phase. Launch consultation
usually involves one or two SREs spending a few hours studying the design and
implementation at a high level. The SRE consultants then meet with the development
team to provide advice on risky areas that need attention and to discuss well-known
patterns or solutions that can be incorporated to improve the service in production.
Some of this advice may come from the Production Guide mentioned earlier.
Consultation sessions are necessarily broad in scope because it’s not possible to gain a
deep understanding of a given system in the limited time available. For some devel‐
opment teams, consultation is not sufficient:
• Services that have grown by orders of magnitude since they launched, which now
require more time to understand than is feasible through documentation and
consultation.
• Services upon which many other services have subsequently come to rely upon,
which now host significantly more traffic from many different clients.
These types of services may have grown to the point at which they begin to encounter
significant difficulties in production while simultaneously becoming important to
users. In such cases, long-term SRE engagement becomes necessary to ensure that
they are properly maintained in production as they grow.
Production Readiness Reviews: Simple PRR Model
When a development team requests that SRE take over production management of a
service, SRE gauges both the importance of the service and the availability of SRE
teams. If the service merits SRE support, and the SRE team and development organi‐
zation agree on staffing levels to facilitate this support, SRE initiates a Production
Readiness Review with the development team.
The objectives of the Production Readiness Review are as follows:
• Verify that a service meets accepted standards of production setup and opera‐
tional readiness, and that service owners are prepared to work with SRE and take
advantage of SRE expertise.
444 | Chapter 32: The Evolving SRE Engagement Model
• Improve the reliability of the service in production, and minimize the number
and severity of incidents that might be expected. A PRR targets all aspects of pro‐
duction that SRE cares about.
After sufficient improvements are made and the service is deemed ready for SRE sup‐
port, an SRE team assumes its production responsibilities.
This brings us to the Production Readiness Review process itself. There are three dif‐
ferent but related engagement models (Simple PRR Model, Early Engagement Model,
and Frameworks and SRE Platform), which will be discussed in turn.
We will first describe the Simple PRR Model, which is usually targeted at a service
that is already launched and will be taken over by an SRE team. A PRR follows several
phases, much like a development lifecycle, although it may proceed independently in
parallel with the development lifecycle.
Engagement
SRE leadership first decides which SRE team is a good fit for taking over the service.
Usually one to three SREs are selected or self-nominated to conduct the PRR process.
This small group then initiates discussion with the development team. The discussion
covers matters such as:
• Establishing an SLO/SLA for the service
• Planning for potentially disruptive design changes required to improve reliability
• Planning and training schedules
The goal is to arrive at a common agreement about the process, end goals, and out‐
comes that are necessary for the SRE team to engage with the development team and
their service.
Analysis
Analysis is the first large segment of work. During this phase, the SRE reviewers learn
about the service and begin analyzing it for production shortcomings. They aim to
gauge the maturity of the service along the various axes of concern to SRE. They also
examine the service’s design and implementation to check if it follows production
best practices. Usually, the SRE team establishes and maintains a PRR checklist
explicitly for the Analysis phase. The checklist is specific to the service and is gener‐
ally based on domain expertise, experience with related or similar systems, and best
practices from the Production Guide. The SRE team may also consult other teams
that have more experience with certain components or dependencies of the service.
Production Readiness Reviews: Simple PRR Model | 445
A few examples of checklist items include:
• Do updates to the service impact an unreasonably large percentage of the system
at once?
• Does the service connect to the appropriate serving instance of its dependencies?
For example, end-user requests to a service should not depend on a system that is
designed for a batch-processing use case.
• Does the service request a sufficiently high network quality-of-service when talk‐
ing to a critical remote service?
• Does the service report errors to central logging systems for analysis? Does it
report all exceptional conditions that result in degraded responses or failures to
the end users?
• Are all user-visible request failures well instrumented and monitored, with suit‐