### Browsing Mode
The term "browsing mode" can vary in meaning across different web browsers, but the common goal is to prevent websites from accessing persistent data, such as cookies, during a particular session. Various browser add-ons and modifications, like TrackMeNot [15], Torbutton, SafeCache [30], SafeHistory [30], and IE8’s InPrivate browsing, have been developed to enhance user anonymity on the web. While a truly anonymous browsing mode has not yet been successfully implemented [1], and it remains unclear if such a mode is technically feasible [7], we argue that REPRIV facilitates end-user privacy by incentivizing content providers to use privacy-sensitive personalization techniques instead of relying on invasive tracking mechanisms. In this way, REPRIV complements private browsing modes by enabling personalized content without the need for current tracking methods, which are incompatible with anonymous browsing.

### Profile Management
REPRIV currently maintains behavior profiles entirely within the browser, with each profile being distinct per user and per browser. However, there is potential for additional profile management schemes. One possibility is to store the primary copy of the profile on a cloud server, encrypted using a symmetric key. Since the cloud does not need direct access to the profile data, key distribution is straightforward: the user manually loads the symmetric key into each browser that updates or consumes the profile. This is practical if the user is physically present at each browser instance. Local updates to the profile are synced periodically with the cloud server. The main advantage of this scheme is that the behavior profile is no longer limited to a single browser, allowing the user to transfer the same profile between multiple instances via the cloud.

### Attacks Against REPRIV
Several types of attacks could compromise the principles of REPRIV. First, since REPRIV does not prevent remote parties from tracking the user, an adversary could collect additional data through unwanted tracking. This can be mitigated by using REPRIV in conjunction with private browsing modes or various browser extensions [15]. We consider this an orthogonal issue; as better private browsing modes are developed, they can be integrated with REPRIV.

A group of colluding sites could share information provided through REPRIV to learn more about a user than explicitly consented to at each individual site. This attack can also be addressed by private browsing modes, which thwart the ability of third parties to track the user. If colluding adversaries cannot link the data provided to each site to a single user, the impact on the user is minimal.

Another possible attack is a denial-of-service scenario where an attacker inundates the user with meaningless REPRIV prompts, attempting to coerce the user into giving full permissions to personal data. To mitigate this, the number of prompts should be limited, perhaps consolidating all prompts into a single dialog when the site is first rendered. Interface design can help prevent tricking or coercing the user into agreeing to permissions against their interest [20].

Lastly, users may provide untruthful preferences, substituting random or false values for their actual interests. Applying remote attestation and software verification techniques to the browser stack can help address some of these issues. Additionally, users have an incentive to provide honest preferences, as they benefit from higher-quality personalized content.

### Related Work
#### Privacy and Web Applications
In response to decreasing privacy on the web, many researchers have explored techniques to restore privacy while still allowing rich web applications. The P3P Project [4], sponsored by the W3C Consortium, aims to formalize and mechanize the specification and distribution of privacy policies on the web. However, it lacks provisions for providing personal information to content providers, making personalized functionality challenging.

Jakobsson et al. [17] addressed the problem of third-party sites mining users' navigation history by developing a system that allows third parties to learn aggregate information rather than detailed listings. The privacy assurances of this system come from its auditable nature, which discourages cheating.

Becker and Chen [2] found that specific personal characteristics can be deduced from a list of friends on a social network, and defending against such inferences is difficult. Narayanan and Shmatikov [27] studied the privacy implications of social network participation, developing a re-identification algorithm that can identify users with high accuracy, even from scrubbed data.

McSherry and Mironov [24] aimed to restore privacy to collaborative recommendation algorithms by building a differential privacy framework to preserve the privacy of individual ratings. Their solution performs comparably to the original Netﬂix recommendation algorithm.

#### Privacy in Advertising
Targeted advertising without violating user privacy is a significant challenge. Freudiger et al. [10] proposed a browser extension for managing third-party cookies, but it does not offer fine-grained control over the type of information shared with third parties. Other systems [14, 19, 34] store sensitive personal data on the client and match ads locally, avoiding the need to leak data to ad networks. These systems differ from REPRIV, which provides content providers with small amounts of selected personal data in return for full application generality.

#### Managing Private Browser State
Researchers have studied ways to identify users and preferences from browser interactions. Wondracek et al. [36] found that a subtlety in the W3C specification allows browser history to be inferred, leading to de-anonymization. Jackson et al. [16] attributed this to the lack of an origin policy for browser history. Mozilla has taken steps to prevent history sniffing [33], though it breaks some parts of the W3C specification. Eckersley [7] introduced browser fingerprinting, combining publicly-visible attributes to create a unique identifier.

Howe and Nissenbaum [15] created TrackMeNot, a Firefox extension that anonymizes search behavior. McKinley [23] examined the privacy modes of popular browsers and found that while some clear private state, none perform as advertised, leaving persistent state that can be retrieved in different sessions.

#### Web Personalization and Mining
Web personalization varies across applications, falling into four broad categories: memorizing information, guiding users to relevant information, customizing content, and supporting task completion. REPRIV primarily supports the second and third points but can be used for all types of personalization.

Browser add-ons like the Alexa Toolbar collect comprehensive browsing data for analytics, including traffic statistics and audience demographics. Bing [3], Google [12], and Yahoo [38] offer similar toolbars, varying in the amount of data mining and personalization they perform.

### Conclusions
This paper introduces REPRIV, an in-browser approach that aims to perform personalization without sacrificing user privacy. REPRIV achieves this by requiring explicit user consent for any transfer of sensitive information. We demonstrated how efficient and effective behavior mining can be added to a web browser to infer information needed for personalized web applications, evaluated this mechanism on real-world data, and showed how third-party code can be incorporated with static software verification. Two case studies highlight REPRIV's capabilities. By focusing on client-side operations, REPRIV ensures that personalized content and privacy can coexist.

### References
[1] G. Aggarwal, E. Bursztein, C. Jackson, and D. Boneh. An analysis of private browsing modes in modern browsers. In Proceedings of the Usenix Security Symposium, Jul. 2010.
[2] J. Becker and H. Chen. Measuring privacy risk in online social networks. In Proceedings of the Workshop on Web 2.0 Security and Privacy, May 2009.
[3] The Bing Toolbar. http://www.discoverbing.com/toolbar.
[4] W. Consortium. Platform for Privacy Preferences (P3P) Project. http://www.w3.org/P3P.
[5] Spam database lookup. http://www.dnsbl.info.
[6] C. Dwork. Differential privacy: a survey of results. In Proceedings of the International Conference on Theory and Applications of Models of Computation, May 2008.
[7] P. Eckersley. How Unique Is Your Web Browser? Technical report, Electronic Frontier Foundation, Mar. 2009.
[8] The Electronic Freedom Foundation. http://www.eff.org.
[9] M. Fredrikson and B. Livshits. RePriv: Re-imagining in-browser privacy. Technical Report MSR-TR-2010-116, Microsoft Research, Aug. 2010.
[10] J. Freudiger, N. Vratonjic, and J.-P. Hubaux. Towards Privacy-Friendly Online Advertising. In Proceedings of the Workshop on Web 2.0 Security and Privacy, May 2009.
[11] Google AdSense privacy information. http://www.google.com/privacy_ads.html#toc-faq.
[12] The Google Toolbar. http://toolbar.google.com.
[13] A. Guha, M. Fredrikson, B. Livshits, and N. Swamy. Verified security for browser extensions. In Proceedings of the IEEE Symposium on Security and Privacy, May 2011.
[14] S. Guha, A. Reznichenko, K. Tang, H. Haddadi, and P. Francis. Serving Ads from localhost for Performance, Privacy, and Profit. In Proceedings of Hot Topics in Networking, Nov. 2009.
[15] D. C. Howe and H. Nissenbaum. TrackMeNot: Resisting surveillance in web search. In I. Kerr, V. Steeves, and C. Lucock, editors, Lessons from the Identity Trail: Anonymity, Privacy, and Identity in a Networked Society, chapter 23. 2009.
[16] C. Jackson, A. Bortz, D. Boneh, and J. C. Mitchell. Protecting browser state from web privacy attacks. In Proceedings of the International Conference on World Wide Web, May 2006.
[17] M. Jakobsson, A. Juels, and J. Ratkiewicz. Privacy-Preserving History Mining for Web Browsers. In Proceedings of the Workshop on Web 2.0 Security and Privacy, May 2010.
[18] W. S. Journal. What they know. http://blogs.wsj.com/wtk/, 2011.
[19] A. Juels. Targeted advertising ... and privacy too. In Proceedings of the Conference on Topics in Cryptology, Apr. 2001.
[20] P. G. Kelley, L. Cesca, J. Bresee, and L. F. Cranor. Standardizing the International Conference on Human Factors in Computing Systems, Apr. 2010.
[21] B. Lerner, H. Venter, B. Burg, and W. Schulte. An experimental extensible, reconfigurable platform for HTML-based applications, Oct. 2010.
[22] McAfee Inc. Spyware information. http://www.mcafee.com/us/security_wordbook/spyware.html.
[23] K. McKinley. Cleaning Up After Cookies Version 1.0. Technical report, ISEC Partners, Dec. 2010.
[24] F. McSherry and I. Mironov. Differentially private recommender systems: building privacy into the net. In Proceedings of the International Conference on Knowledge Discovery and Data Mining, Jun. 2009.
[25] Amazon Mechanical Turk. https://www.mturk.com/mturk/welcome.
[26] A. Narayanan and V. Shmatikov. Robust de-anonymization of large sparse datasets. In Proceedings of the IEEE Symposium on Security and Privacy, May 2008.
[27] A. Narayanan and V. Shmatikov. De-anonymizing social networks. IEEE Symposium on Security and Privacy, May 2009.
[28] The Open Directory Project. http://dmoz.org.
[29] D. Pierrakos, G. Paliouras, C. Papatheodorou, and C. D. Spyropoulos. Web usage mining as a tool for personalization: A survey. User Modeling and User-Adapted Interaction, 13(4), 2003.
[30] Same origin policy: Protecting browser state from web privacy attacks. http://crypto.stanford.edu/safecache/.
[31] N. Swamy, J. Chen, and R. Chugh. Enforcing stateful authorization and information flow policies in fine. In Proceedings of the European Symposium on Programming, Mar. 2010.
[32] TargetAPI. http://www.targetapi.com.
[33] The Mozilla Team. Plugging the CSS History Leak. http://blog.mozilla.com/security/2010/03/31/plugging-the-css-history-leak, 2010.
[34] V. Toubiana, A. Narayanan, D. Boneh, H. Nissenbaum, and S. Barocas. Adnostic: Privacy preserving targeted advertising. In Proceedings of the Network and Distributed System Security Symposium, Feb. 2010.
[35] WebMii: A person search engine. http://www.webmii.com.
[36] G. Wondracek, T. Holz, E. Kirda, and C. Kruegel. A practical attack to de-anonymize social network users. In IEEE Symposium on Security and Privacy, May 2010.
[37] Yahoo! BOSS API. http://developer.yahoo.com/search/boss/.
[38] The Yahoo Toolbar. http://toolbar.yahoo.com.