# Graph Neural Networks (GNNs) and Adversarial Machine Learning

## Authors and Affiliations
- **Yang Zhang** and his research group: CISPA Helmholtz Center for Information Security
- **Yun Shen**: Spot by NetApp
- **Azzedine Benameur**: Spot by NetApp

## Introduction
*All attacks discussed in this talk are simulated in a lab environment.*

### The Age of Machine Learning
Machine learning has revolutionized various fields, from image and text processing to audio and video analysis. Graphs, which are combinatorial structures with arbitrary sizes and multi-modal information, are ubiquitous in many applications.

#### Image Sources
- [AlphaFold](https://github.com/deepmind/alphafold)
- [OpenAI GPT-3](https://emergetech.org/openai-gpt3-good-at-almost-everything/)
- [GitHub Copilot](https://github.com/features/copilot/signup)
- [Google Imagen](https://imagen.research.google/)

### Graphs Are Everywhere
- **Social Networks**
- **Knowledge Graphs**
- **Molecules**
- **User-Item Graphs**

#### Image Sources
- [AB Testing in Social Networks](https://towardsdatascience.com/ab-testing-challenges-in-social-networks-e67611c92916)
- [Molecule Definition](https://biologydictionary.net/molecule/)
- [Introduction to Knowledge Graphs](https://yashuseth.blog/2019/10/08/introduction-question-answering-knowledge-graphs-kgqa/)

### Applications of Graphs
- **Link Prediction**: "Do you (Alice) know Bob?"
- **Toxicity Prediction**
- **Knowledge Mining**
- **Recommendation Systems**: "We found an item you may be interested in!"
- **Demographic Inference**: "Age group of Bob"

## Graph Neural Networks (GNNs)
- **Traditional Neural Networks**: Designed for grids (e.g., images) or sequences (e.g., text).
  - **CNNs** for images
  - **RNNs** for sequences
- **GNNs**:
  - **Graph Convolution Network (GCN)**
  - **Graph Sample and Aggregate (GraphSAGE)**
  - **Graph Isomorphism Network (GIN)**
  - **Graph Attention Network (GAT)**

## Adversarial Attacks on GNNs
### Overview
- **Security**
- **Privacy**
- **Graphs**
- **GNNs**

### Types of Attacks
- **Model Extraction Attack**
- **Property Inference Attack**
- **Link Re-identification Attack**
- **Subgraph Inference Attack**

### Link Re-identification Attack
- **Scenario**: Identify if two nodes are connected in the training data.
- **Attacker’s Capability**:
  1. Posterior scores of nodes obtained from the target model.
- **GNN Model**: Node classification.
- **Posterior Scores**: 
  - Example: `panda dog cat` with scores `0 35 70`.
- **Private Information**: Revealed through posterior similarity.

### Property Inference Attack
- **Scenario**: Infer properties of the graph.
- **Attacker’s Capability**:
  1. Embeddings of graphs obtained from the target model.
  2. Can query the GNN model.
- **GNN Model**: Graph classification.
- **Graph Embeddings**: 
  - Example: `This is a graph with ~4 nodes`.
- **Attack Model**: Cross-entropy loss.
- **Auxiliary Graphs**: Used for local and remote access.

### Subgraph Inference Attack
- **Scenario**: Infer subgraphs within the graph.
- **Attacker’s Capability**:
  1. Embeddings of graphs obtained from the target model.
  2. Can query the GNN model.
- **GNN Model**: Graph classification.
- **Subgraph Embeddings**: 
  - Example: `This graph contains at least one`.
- **Positive and Negative Pairs**: Used for attack model.
- **AUC Analysis**: Evaluate the attack performance.

### Model Stealing Attack
- **Scenario**: Faithfully replicate the GNN functionality.
- **Attacker’s Capability**:
  1. Can query the GNN model via a publicly accessible API.
- **GNN Model**: Node classification.
- **IDGL Framework**: Used for learning discrete graph structure.
- **Surrogate Model**: Learned to replicate the target model.
- **t-SNE Projection**: 2-dimensional projection as a new attack surface.

## Takeaways
1. Secure your infrastructure.
2. Audit your GNN-based machine learning pipeline.
3. Monitor your model logs for anomalies.
4. Evaluate the security and privacy posture of your GNN models.

## Code Repositories
- **Link Re-identification Attack**: [GitHub](https://github.com/xinleihe/link_stealing_attack)
- **Property/Subgraph Inference Attack**: [GitHub](https://github.com/Zhangzhk0819/GNN-Embedding-Leaks)
- **Model Stealing Attack**: [GitHub](https://github.com/xinleihe/GNNStealing)

## Contact Information
- **Yang Zhang**: [Email](PI:EMAIL)
- **Azzedine Benameur and Yun Shen**: `{Azzedine.Benameur, Yun.Shen}@netapp.com`

Thank you for your attention!