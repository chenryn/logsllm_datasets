preﬁxes. The remaining IP addresses must be stored as individual IP
addresses.
With hop-count-based clustering, we never aggregate IP addresses
that do not share the same hop-count. Hence, we can eliminate false
positives when all clients of a server are known as in Figure 9. HCF
will be free of false positives as long as the table is updated with the
correct hop-counts when client hop-counts change. Furthermore, un-
der hop-count clustering, we observe no noticeable increase in false
negatives compared to the approach of 32-bit Strict Filtering. Thus,
one cannot see the difference in Figure 9 due to their having similar
numbers of false positives and negatives. Compared to the 24-bit
aggregation, the clustering approach is more accurate but consumes
more memory. Figure 11 shows the number of table entries for all
web servers used in our experiments. The x-axis is the ID of the web
server ranked by the number of client IP addresses, and the y-axis is
the number of table entries. In the case of 32-bit Strict Filtering, the
number of table entries for each server is the same as the number of
client IP addresses. We observe that the hop-count-based clustering
increases the size of HCF table, by no more than 20% in all but one
case (36%).
5.2 Pollution-Proof Initialization and Update
To populate the HCF table initially, an Internet server should col-
lect traces of its clients that contain both IP addresses and the corre-
sponding TTL values. The initial collection period should be com-
mensurate with the amount of trafﬁc the server is receiving. For a
very busy site, a collection period of a few days could be sufﬁcient,
while for a lightly-loaded site, a few weeks might be more appropri-
ate.
Keeping the IP2HC mapping up-to-date is necessary for our ﬁlter
to work in the Internet where hop-counts may change. The hop-
s
e
i
r
t
n
E
T
F
H
45000
40000
35000
30000
25000
20000
15000
10000
0
5
10
32-bit Strict Filtering
24-bit Strict Filtering
24-bit Clustering Strict Filtering
20
15
30
Traceroute Gateway Rank
25
35
40
45
Figure 11: Sizes of various HCF tables.
count, or distance from a client to a server can change as a result
of relocation of networks, routing instability, or temporary network
failures. Some of these events are transient, but changes in hop-count
due to permanent events need to be captured.
While adding new IP2HC entries or capturing legitimate hop-count
changes, we must foil attackers’ attempt to slowly pollute HCF ta-
bles by dropping spoofed packets. One way to ensure that only le-
gitimate packets are used during initialization and dynamic update
is through TCP connection establishment, an HCF table should be
updated only by those TCP connections in the established state
[44]. The three-way TCP handshake for connection setup requires
the active-open party to send an ACK (the last packet in the three-
way handshake) to acknowledge the passive party’s initial sequence
number. The host that sends the SYN packet with a spoofed IP ad-
dress will not receive the server’s SYN/ACK packet and thus cannot
complete the three-way handshake. Using packets from established
TCP connections ensures that an attacker cannot slowly pollute an
HCF table by spooﬁng source IP addresses. While the HCF mecha-
nism works for all types of IP trafﬁc, the update procedure uses only
TCP trafﬁc.
While our dynamic update provides safety, it may be too expen-
sive to inspect and update an HCF table with each newly-established
TCP connection, since our update function is on the critical path of
TCP processing. We provide a user-conﬁgurable parameter to adjust
the frequency of update. The simplest solution would be to maintain
a counter p that records the number of established TCP connections
since the last reset of p. We will update the HCF table using packets
belonging to every k-th TCP connection and reset p to zero after the
update. p can also be a function of system load and hence, updates
are made more frequently when the system is lightly-loaded.
We note that mapping updates may require re-clustering which
may break up a node or merge two adjacent nodes on a 24-bit tree.
Re-clustering is a local activity, which conﬁnes itself to a single 24-
bit tree. Moreover, since hop-count changes are not a frequent event
in the network as reported in [32] and conﬁrmed by our own obser-
vations, the overhead incurred by re-clustering is negligible.
6. RUNNING STATES OF HCF
Since HCF causes delay in the critical path of packet processing, it
should not be active at all time. We therefore introduce two running
states inside HCF: the alert state to detect the presence of spoofed
packets and the action state to discard spoofed packets. By default,
HCF stays in alert state and monitors the trend of hop-count changes
without discarding packets. Upon detection of a ﬂux of spoofed
In alert state:
for each sampled packet p:
spoo f = IP2HC Inspect(p);
t = Average(spoo f );
if ( spoo f )
if ( t > T1 )
Switch Action();
Accept(p);
for the k-th TCP control block tcb:
Update Table(tcb);
In action state:
for each packet p:
spoo f = IP2HC Inspect(p);
t = Average(spoo f );
if ( spoo f )
Drop(p);
else Accept(p);
if ( t ≤ T2 )
Switch Alert();
Figure 12: Operations in two HCF states.
packets, HCF switches to action state to examine each packet and
discards spoofed IP packets. In this section, we discuss the details of
each state and show that having two states can better protect servers
against different forms of DDoS attacks.
6.1 Tasks in Two States
Figure 6.1 lists the tasks performed by each state.
In the alert
state, HCF performs the following tasks: sample incoming pack-
ets for hop-count inspection, calculate the spoofed packet counter,
and update the IP2HC mapping table in case of legitimate hop-count
changes. Packets are sampled at exponentially-distributed intervals
with mean m in either time or the number of packets. The exponen-
tial distribution can be precomputed and made into a lookup table
for fast on-line access. For each sampled packet, IP2HC Inspect()
returns a binary number spoo f , depending on whether the packet is
judged as spoofed or not. This is then used by Average() to compute
an average spoof counter t per unit time. When t is greater than a
threshold T1, HCF enters the action state. HCF in alert state will
also update the HCF table using the TCP control block of every k-th
established TCP connection.
HCF in action state performs per-packet hop-count inspection and
discards spoofed packets, if any. HCF in action state performs a
similar set of tasks as in alert state. The main differences are that
HCF must examine every packet (instead of sampling only a subset
of packets) and discards spoofed packets. HCF stays in action state
as long as spoofed IP packets are detected. When the ongoing spoof-
ing ceases, HCF switches back to alert state. This is accomplished
by checking the spoof counter t against another threshold T2, which
should be smaller than T1 for better stability. HCF should not al-
ternate between alert and action states when t ﬂuctuates around T1.
Making the second threshold T2 < T1 avoids this instability.
To minimize the overhead of hop-count inspection and dynamic
update in alert state, their execution frequencies are adaptively cho-
sen to be inversely proportional to the server’s workload. We mea-
sure a server’s workload by the number of established TCP connec-
tions. If the server is lightly-loaded, HCF calls for IP2HC inspection
and dynamic update more frequently by reducing user-conﬁgurable
parameters, k and x. In contrast, for a heavily-loaded server, both
k and x are decreased. The two thresholds T1 and T2, used for de-
tecting spoofed packets, should also be adjusted based on load. The
general guideline for setting execution rates and thresholds with the
dynamics of server’s workload is given as follows:
Load (cid:7) ⇒ Rates (cid:9) ⇒ T hreshold (cid:9)
Currently, however, we only recommend these parameters to be user-
conﬁgurable. Their speciﬁc values depend on the requirement of
individual networks in balancing security and performance.
6.2 Staying “Alert” to DRDoS Attacks
Introduction of the alert state not only lowers the overhead of
HCF, but also makes it possible to stop other forms of DoS attacks.
In DRDoS attacks, an attacker forges IP packets that contain legit-
imate requests, such as DNS queries, by setting the source IP ad-
dresses of these spoofed packets to the actual victim’s IP address.
The attacker then sends these spoofed packets to a large number of
reﬂectors. Each reﬂector only receives a moderate ﬂux of spoofed
IP packets so that it may easily sustain the availability of its normal
service, thus not causing any alert. The usual intrusion detection
methods based on the ongoing trafﬁc volume or access patterns may
not be sensitive enough to detect the presence of such spoofed traf-
ﬁc. In contrast, HCF speciﬁcally looks for IP spooﬁng, so it will
be able to detect attempts to fool servers into acting as reﬂectors.
Although HCF is not perfect and some spoofed packets may still
slip through the ﬁlter, HCF can detect and intercept enough of the
spoofed packets to thwart DRDoS attacks. We would like to point
out that an attacker may evade detection if he knows the hop-count
mapping from reﬂectors to a victim as discussed in Section 3.3.
6.3 Blocking Bandwidth Attacks
To protect server resources such as CPU and memory, HCF can be
installed at a server itself or at any network device near the servers,
i.e., inside the ‘last-mile’ region, such as the ﬁrewall of an organi-
zation. However, this scheme will not be effective against DDoS at-
tacks that target the bandwidth of a network to/from the server. The
task of protecting the access link of an entire stub network is more
complicated and difﬁcult because the ﬁltering has to be applied at
the upstream router of the access link, which must involve the stub
network’s ISP.
The difﬁculty in protecting against bandwidth ﬂooding is that packet
ﬁltering must be separated from detection of spoofed packets as the
ﬁltering has to be done at the ISP’s edge router. One or more ma-
chines inside the stub network must run HCF and actively watch
for traces of IP spooﬁng by always staying in the alert state. For
complete protection, the access router should also run HCF in case
attacking trafﬁc terminates at the access router. This can be accom-
plished by substituting a regular end-host conﬁgured as a router. In
addition, at least one machine inside the stub network needs to main-
tain an updated HCF table since only end-hosts can see established
TCP connections. Under an attack, this machine should notify the
network administrator who then coordinates with the ISP to install a
packet ﬁlter based on the HCF table on the ISP’s edge router.
Our two running-state design makes it natural to separate these
two functions — detection and ﬁltering of spoofed packets. Figure
13 shows a hypothetical stub network that hosts a web server that
runs HCF. The stub network is connected to its upstream ISP via
an access router and the ISP’s edge router. Under normal network
condition, the web server monitors its trafﬁc and builds the HCF ta-
ble. When attack trafﬁc arrives at the stub network, HCF at the web
server will notice this sudden rise of spoofed trafﬁc and inform the
Hop-Count
  Table
ISP Router
Access Router
Server
Install
Admin
Notify
Figure 13: Packet ﬁltering at a router to protect bandwidth.
network administrator via an authenticated channel. The administra-
tor can have the ISP install a packet ﬁlter in the ISP’s edge router,
based on the HCF table. Note that one cannot directly use the HCF
table since the hop-counts from client IP addresses to the web server
are different from those to the router. Thus, all hop-counts need to
be decremented by a proper offset equal to the hop-count between
the router and the web server. Once the HCF table is enabled at
the ISP’s edge router, most spoofed packets will be intercepted, and
only a very small percentage of the spoofed packets that slip through
HCF, will consume bandwidth. In this case, having two separable
states is crucial since routers usually cannot observe established TCP
connections and use the safe update procedure.
7. RESOURCE SAVINGS
This section details the implementation of a proof-of-concept HCF
inside the Linux kernel and presents its evaluation on a real testbed.
The two concerns we addressed are the per-packet overhead of HCF
and the amount of resource savings when HCF is active. Our mea-
surements show that HCF only consumes a small amount of CPU
time, and indeed makes signiﬁcant resource savings.
7.1 Building the Hop-Count Filter
To validate the efﬁcacy of HCF in a real system, we implement
a test module inside the Linux kernel. The test module resides in
the IP packet receive function, ip rcv. To minimize the CPU cy-
cles consumed by spoofed IP packets, we insert the ﬁltering function
before the code segment that performs the expensive checksum ver-
iﬁcation. Our test module has the basic data structures and functions
to support search and update operations to the hop-count mapping.
The hop-count mapping is organized as a 4096-bucket hash table
with chaining to resolve collisions. Each entry in the hash table rep-
resents a 24-bit address preﬁx. A binary tree is used to cluster hosts
within each 24-bit address preﬁx. Searching for the hop-count of an
IP address consists of locating the entry for its 24-bit address preﬁx
in the hash table, and then ﬁnding the proper cluster that the IP ad-
dress belongs to on the tree. Given an IP address, HCF computes the
hash key by XORing the upper and lower 12-bits of the ﬁrst 24 bits
of the source IP address. Since 4096 is relatively small compared to
the set of possible 24-bit address preﬁxes, collisions are likely to oc-
cur. To estimate the average size of a chained list, we hash the client
IP addresses from [11] into the 4096-bucket hash table to ﬁnd that,
on average, there are 11 entries on a chain, with the maximum being
25. We build the clustering tree by choosing a minimum clustering
unit of four IP addresses so the tree has a depth of six (26 = 64).
This tree can then be implemented as a linear array of 127 elements.
Each element in the array stores the hop-count value of a particular
clustering. We set the array element to be the hop-count if clustering
is possible, and zero otherwise.
TCP open+close
scenarios
TCP SYN
ping 64B
ping 1500B
ping ﬂood
TCP bulk
UDP bulk
with HCF
avg min
240
388
456
264
240
396
124
298
256
358
168
443
490
184
without HCF
min
avg
3664
7507
18002
3700
3604
20194
2436
35925
3616
20139
3700
6538
6524
3628
Table 2: CPU overhead of HCF and normal IP processing.
To implement the HCF-table update, we insert the function call
into the kernel TCP code past the point where the three-way hand-
shake of TCP connection is completed. For every k-th established
TCP connection, the update function takes the argument of the source
IP address and the ﬁnal TTL value of the ACK packet that completes
the handshake. Then, the function searches the HCF table for an en-
try that corresponds to this source IP address, and will either over-
write the existing entry or create a new entry for a ﬁrst-time visitor.
7.2 Experimental Evaluation
For HCF to be useful, the per-packet overhead must be much
lower than the normal processing of an IP packet. We examine the
per-packet overhead of HCF by instrumenting the Linux kernel to
time the ﬁltering function as well as the critical path in processing IP
packets. We use the built-in Linux macro rdtscl to record the ex-
ecution time in CPU cycles. While we cannot generalize our exper-