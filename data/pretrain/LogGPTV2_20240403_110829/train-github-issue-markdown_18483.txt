I'm doing some work in filtering and having a bit of a rough time. I went
looking for some examples and I found this:
http://azitech.wordpress.com/2011/03/15/designing-a-butterworth-low-pass-
filter-with-scipy/
It looks to me like a perfectly valid set of examples, and he's even generated
some example output. It looks reasonable.
So I download the code and try running it on my machine. I see this error:  
/usr/lib/python2.7/dist-packages/scipy/signal/filter_design.py:288:
BadCoefficients: Badly conditioned filter coefficients (numerator): the
results may be meaningless  
"results may be meaningless", BadCoefficients)  
b=[ 1.50249921e-18], a=[ 1. -9.78671066 43.10310124 -112.50164481 192.7084543  
-226.36430741 184.66074807 -103.30140929 37.92528936 -8.25143211  
0.80791132]
And then the graph looks substantially different:  
![output](https://camo.githubusercontent.com/e5d68ccb67641b636b0981590803add906e215f04c7d285efb791c653118f4eb/68747470733a2f2f662e636c6f75642e6769746875622e636f6d2f6173736574732f3130343532302f313331383437352f30316630383735322d333262642d313165332d383333362d6361636463306362616334302e706e67)
The thing that strikes me is that in the filter passbands are HUGELY
different. The example output he shows has a passband gain of 1. My passband
gain is 10^-5 so it's all attenuation.
I found this ticket #2140 and it mentioned problems with the "small enough to
zero out" number. I'm running a newer version of scipy which already has the
1e-14 threshold so that doesn't seem to be the problem.
This is really puzzling me.