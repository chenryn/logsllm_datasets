ticipant can violate privacy of others’ inputs and integrity
of others’ ﬁnal outputs, often completely undetectably. So
while 1-out-of-3 active security has some limitations, it is a
signiﬁcantly stronger guarantee than 1-out-of-3 semi-honest
security.
2.2 Garbling Scheme
We employ the abstraction of garbling schemes [BHR12b]
introduced by Bellare et al. Below is a summary of garbling
scheme syntax and security:
A garbling scheme is a four-tuple of algorithms G =
(Gb, En, De, Ev) where: Gb is a randomized garbling algo-
rithm that transforms function f into a triplet (F, e, d), where
F is the garbled circuit, e is encoding information, and d
is decoding information. En is an encoding algorithm that
maps input x into garbled input via X = En(e, x). De is
a decoding algorithm that maps the garbled output Y into
plaintext output y = De(d, Y ). Ev is the algorithm that on
garbled input X and garbled circuit F , produces garbled
output Y = Ev(F, X).
The correctness property of a garbling scheme is that,
for all (F, e, d) in the support of Gb(1k, f ) and all inputs x,
we have De(d, Ev(F, En(e, x))) = f (x), where k denotes the
security parameter.
We require a projective scheme, meaning that e is an
n × 2 matrix of wire labels, and the encoding algorithm En
has the structure En(e, x) = (e[1, x1], e[2, x2], . . . , e[n, xn]).
A scheme satisﬁes privacy if there exists a simulator S
for which following two processes induce indistinguishable
output distributions:
M1(1k, f, x):
(F, e, d) ← Gb(1k, f )
X ← En(e, x)
return (F, X, d)
M2(1k, f, x):
(F, X, d) ← S(1k, f, f (x))
return (F, X, d)
In other words, the tuple (F, X, d) contains no information
beyond f (x).
593Our protocol requires an additional “soft decoding” func-
ing information d. The soft-decoding function must satisfy
A scheme satisﬁes authenticity if the following property
holds. Given (F, X) as in the output of M1 above, it is with
only negligible probability that a poly-time adversary can
generate ˜Y (cid:54)= Ev(F, X) such that De(d, ˜Y ) (cid:54)= ⊥. In other
words, without d, it is not possible to give a valid garbled
output other than Y obtained from Ev.
tion (cid:102)De that can decode garbled outputs without the decod-
(cid:102)De(Ev(F, En(e, x))) = f (x) for all (F, e, d) in the support of
Gb(1k, f ). Note that both (cid:102)De and De can decode garbled
with respect to De — that is, (cid:102)De can in principle be “fooled”
erated, the output of (cid:102)De will be correct. In our protocol,
using (cid:102)De, while the generators of the garbled circuit will use
when given maliciously crafted garbled outputs. However,
if the garbled circuit and garbled input are honestly gen-
outputs, but the authenticity security property holds only
we will let the evaluator of the garbled circuit obtain input
De (to protect against a corrupt party who tries to falsify the
garbled outputs). In practice, we can achieve soft decoding
in typical garbling schemes by simply appending the truth
value to each output wire label. The true decoding func-
tion De will still verify the entire wire labels to guarantee
authenticity.
2.3 Non-Interactive Commitment
We require a non-interactive commitment scheme (in the
common random string model). Let crs denote the common
random string and let (Comcrs, Chkcrs) be a non-interactive
commitment scheme for n-bit messages. The Comcrs algo-
rithm takes an n-bit message x and random coins r as input,
and outputs a commitment C and the corresponding open-
ing σ. We write Comcrs(x) as shorthand for the distribution
Comcrs(x; r) induced by uniform choice of r. We require the
following properties of the scheme:
• Correctness: for all crs, if (C, σ) ← Comcrs(x) then
Chkcrs(C, σ) = x.
• Binding: For all poly-time adversaries A, it is with
negligible probability (over uniform choice of crs) that
A(crs) outputs (C, σ, σ(cid:48)) such that Chkcrs(C, σ) (cid:54)=
Chkcrs(C, σ(cid:48)) and ⊥ (cid:54)∈ {Chkcrs(C, σ), Chkcrs(C, σ(cid:48))}.
• Hiding: For all poly-time adversaries A, all crs, and
all x, x(cid:48) ∈ {0, 1}n, the following diﬀerence is negligible:
Pr
(C,σ)←Comcrs(x)
[A(C) = 1]−
Pr
(C,σ)←Comcrs(x(cid:48))
[A(C) = 1]
(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)(cid:12).
Since we quantify over all crs and A together (not just
a random crs), it is not necessary to give crs to A in
this deﬁnition. The deﬁnition also implies that the crs
can be used for many commitments.
Instantations.
In the random oracle model, commitment is simple via
(C, σ) = (H(x(cid:107)r), x(cid:107)r) = Comcrs(x; r). The crs can in fact
be empty.
In the standard model, we can use a multi-bit variant of
Naor’s commitment [Nao91]. For n-bit strings, we need a
crs ∈ {0, 1}4n. Let G : {0, 1}n → {0, 1}4n be a pseudo-
random generator, and let pad : {0, 1}n → {0, 1}4n be the
function that prepends 3n zeroes to its argument. Then the
commitment scheme is:
• Comcrs(x; r): set C = G(r) + crs · pad(x), with arith-
metic in GF (24n); set σ = (r, x).
• Chkcrs(C, σ = (r, x)): return x if C = G(r) + crs ·
pad(x); otherwise return ⊥.
Security of this construction closely follows the original proof
of Naor’s construction, but is provided for completeness in
Appendix A.
3. OUR PROTOCOL
In this section we present a new and eﬃcient 3PC protocol
that is secure against 1 malicious corruption. Its complexity
is essentially the same as that of (semi-honest-secure) two-
party Yao’s protocol.
3.1 High Level Overview
Our starting point is Yao’s protocol based on garbled cir-
cuits. In that protocol, one party generates a garbled circuit
and the other evaluates it. The two parties use oblivious
transfer to allow the evaluator to receive the garbled encod-
ing of his input.
Yao’s protocol is secure against a malicious evaluator, but
secure against only a semi-honest garbler. Our 3-party pro-
tocol can be thought of as splitting the role of the garbler
between two parties (while keeping the evaluator a single
party). When only one party is corrupt, then at least one of
the garbling parties is honest, and we can leverage that fact
to protect against one malicious garbler.
In more detail, we let P1 and P2 agree on a random tape r
and run Yao’s protocol as garbler with P3 as evaluator, with
both instances using random tape r. By using the same
random tape in Yao’s protocol, P1 and P2 are expected to
send identical messages to P3 in every step, and P3 can abort
if this is not the case. Then, security against a malicious P3
follows from the security of Yao’s protocol — it is really P3
attacking a single instance of 2-party Yao’s protocol in this
case. Security against a malicious P1 or P2 follows from the
fact that Yao’s protocol is secure against a garbler who runs
the protocol honestly (even on adversarially chosen random
tape). In our protocol, the only options for malicious P1 or
P2 are to run Yao’s 2-party protocol honestly or else cause
P3 to abort (by disagreeing with the honest garbler).
Obtaining Garbled Inputs.
This overview captures the main intuition, but it does not
address the issue of garbled inputs. Indeed, P1 and P2 have
their own private inputs and so must at some point send
diﬀerent messages in order to aﬀect the ﬁnal output. To ad-
dress this, we have P1 and P2 commit to all of the input wire
labels for the circuit. For each wire, the two commitments
are randomly permuted. P1 and P2 will generate these com-
mitments using the same randomness, so their correctness
is guaranteed using the same reasoning as above. Then P1
and P2 can simply open the appropriate commitments cor-
responding to their input bits (note that the position of the
commitments does not leak their inputs).
P3’s garbled input is handled using an oblivious transfer
in Yao’s protocol, but we are able to avoid OT altogether in
our 3-party setting. We garble the circuit f(cid:48)(x1, x2, x3, x4) =
f (x1, x2, x3 ⊕ x4), so that x3, x4 are an additive secret shar-
ing of P3’s logical input. We have P3 send x3 to P1 and x4
to P2, so that P1/P2 can open the corresponding commit-
ments to garbled inputs. Since at most one of {P1, P2} is
594corrupt, an adversary can learn nothing about P3’s logical
input. To ensure that P1/P2 open the correct commitments
in this step (i.e., they do not ﬂip bits in P3’s input), we
have them both reveal the random ordering of the relevant
commitments (which can be checked against each other by
P3).
Other Optimizations.
To make the commitment non-interactive, we can either
assume a random oracle commitment scheme, or else a com-
mon random string (CRS). In the latter case, P3 can choose
the CRS himself (we use a commitment scheme that is hid-
ing for all CRS values, not just for a uniformly chosen one).
Both P1 and P2 use a common random tape r to run Yao’s
protocol as garbler. We can actually have P1 choose r him-
self; surprisingly there is no problem in a corrupt P1 choos-
ing r arbitrarily. In the case that P1 is corrupt, the security
proof needs to apply the binding security of the commitment
scheme and correctness property of garbled circuits. Bind-
ing holds with respect to malicious senders (in particular,
senders who choose r arbitrarily and use PRF(r,·) to derive
randomness to run the Comcrs(·) algorithm). Correctness of
garbled circuits holds with probability 1, i.e., for all (F, e, d)
in the support of Gb(1k, f(cid:48)). The fact that P2 must be hon-
est if P1 is corrupt guarantees that the (F, e, d) used in the
protocol is indeed in the support of Gb, so we can apply the
correctness of the garbling scheme.
3.2 Detailed Protocol Description
We denote the three parties in the protocol by P1, P2 and
3. Their goal
3). For
P3, and their respective inputs by x1, x2, and x∗
is to securely compute the function y = f (x1, x2, x∗
convenience we deﬁne the related function
(cid:48)
(x1, x2, x3, x4) = f (x1, x2, x3 ⊕ x4).
f
For simplicity we assume that |xi| = |y| = m. The proto-
col is as follows. All communication between parties is on
private point-to-point channels.
In what follows we assume that all parties learn the same
output y, but it is easy to modify the protocol such that
each party learns a diﬀerent output (i.e., a 3-output func-
tion).
In particular, P3 can return to each of P1 and P2
the garbled values for the portion of the output wires cor-
responding to their own output, while the “soft-decoding”
procedure is constrained to work only for P3’s output wires
(concretely, the cleartext truth values are appended only to
the output wires for P3’s outputs).1
1. P3 samples a random crs for the commitment scheme
3 = x3 ⊕
and randomly secret-shares his input x∗
x4. He sends x3 to P1 and x4 to P2 and broadcasts crs
to both parties.
3 as x∗
2. P1 chooses random PRF seed r ← {0, 1}k and sends it
to P2 (see the discussion in the previous section).
3. Both P1 and P2 do the following, independently, and
obtaining all required randomness via P RF (r,·):
(a) Garble the circuit f(cid:48) via Gb(1λ, f(cid:48)) → (F, e, d).
1The resulting protocol will achieve a slightly weaker notion
of security, since a corrupt P3 can choose to make only one
of {P1, P2} abort. This notion is known as security with
selective abort. [GL05]
(b) Commit to all 4m input wire labels in the fol-
lowing way. Sample b ← {0, 1}4m. Then for all
j ∈ [4m] and a ∈ {0, 1}, generate the following
commitment:
(C a
j , σa
j ) ← Comcrs(e[j, b[j] ⊕ a])
Both P1 and P2 send the following values to P3:2
(b[2m + 1··· 4m], F,{C a
j }j,a).
P3 will abort if P1 and P2 report diﬀerent values for
these items.
4. P1 and P2 additionally reveal garbled inputs to P3 in
the following way (now P1 and P2 are sending diﬀerent
messages). For j ∈ [m]:
(a) P1 sends decommitment σx1[j]⊕b[j]
(b) P2 sends decommitment σx2[j]⊕b[m+j]
(c) P1 sends decommitment σx3[j]⊕b[2m+j]
(d) P2 sends decommitment σx4[j]⊕b[3m+j]
to P3.
to P3.
to P3.
to P3.
2m+j
3m+j
j
m+j
5. P3 assembles the garbled input as follows. For j ∈
[4m], P3 computes X[j] = Chkcrs(C o[j]
), for the
appropriate o[j]. If any call to Chk returns ⊥, then P3
aborts. Similarly, P3 knows the values b[2m+1··· 4m],
and aborts if P1 or P2 did not open the “expected”
and C x4[j]⊕b[3m+j]
commitments C x3[j]⊕b[2m+j]
corre-
sponding to the garbled encodings of x3 and x4.
P3 runs Y ← Ev(F, X) and broadcasts Y to all parties.
, σo[j]
2m+j
3m+j
j
j
6. At this point, P1 and P2 can compute y = De(d, Y ). If
y (cid:54)= ⊥, then they output y, otherwise they abort. Also,
P3 can compute and output y = (cid:102)De(Y ), where (cid:102)De is
the “soft decoding” function described in Section 2.2.
3.3 Security Proof
Theorem 1. The protocol in Section 3.2 securely realizes
the Ff functionality against adversaries who actively corrupt
at most one of the parties.
Proof. First consider the case where P1 is corrupted (the
case of P2 is essentially symmetric). We show that the real
and ideal interactions are indistinguishable to all environ-
ments, in a sequence of hybrid interactions. The required
simulator is built up implicitly in the hybrid sequence be-
low. Recall that the environment’s view consists of messages
sent from honest parties to the adversary in the protocol, as
well as the ﬁnal outputs of the honest parties.
H0: This hybrid is identical to the real interaction, except
that we repackage the various components of the inter-
action. A simulator plays the role of honest P2 and P3,
receiving their inputs x2 and x∗
3 from the environment
and running the protocol on their behalf.
2Since b[2m + 1··· 4m] are given to P3, we can actually take
them to be all zeroes and eliminate them altogether. Still,
to keep the treatment of all garbled inputs consistent in the
notation, we continue with b ∈ {0, 1}4m.
595j
H1: In the previous hybrid, the simulator runs the protocol
on behalf of P2 and hence knows the value b chosen in
step (3b). Assuming P3 does not abort in step (5),
then P1 must have succesfully opened commitments
for some string o ∈ {0, 1}m. At this point in
C o[j]
H1 we have the simulator compute x1 = o⊕ b[1··· m].
The simulator also simulates an instance of the Ff
3 to the simulated Ff
functionality. It sends x1, x2, x∗
(recall that at this point in the sequence of hybrids
the simulator is receiving the other parties’ inputs x2
and x∗
3). As the simulator does nothing with anything
computed by Ff , there is no diﬀerence in the environ-
ment’s view. Note that the simulator is still using x2
and x∗
3 at this point to run the protocol on behalf of
P2 and P3.
j commitments.
H2: In the previous hybrid, the simulator runs the protocol
on behalf of P2 and hence knows what was committed
in all of the C a
We modify the simulator to abort if the simulated P3
accepts the opening of any commitment (in step 5)