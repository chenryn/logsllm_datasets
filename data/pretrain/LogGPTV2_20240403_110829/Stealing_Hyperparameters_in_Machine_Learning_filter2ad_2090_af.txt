1
g
o
l
(
r
o
r
r
e
n
o
i
t
a
m
i
t
s
e
e
v
i
t
a
l
e
R
0
−2
−4
−6
−8
−10
)
0
1
g
o
l
(
r
o
r
r
e
C
C
A
e
v
i
t
a
l
e
R
L2-LR
L1-LR
L2-KLR
L1-KLR
0
−2
−4
−6
−8
−10
2
1
5
Number of decimals
3
4
)
0
1
g
o
l
(
r
o
r
r
e
n
o
i
t
a
m
i
t
s
e
e
v
i
t
a
l
e
R
0
−2
−4
−6
−8
−10
L2-LR
L1-LR
L2-KLR
L1-KLR
2
1
5
Number of decimals
3
4
2
1
5
Number of decimals
3
4
2
1
5
Number of decimals
3
4
(a) Iris
(b) Madelon
(c) Bank
Fig. 12: Defense results of the rounding technique for logistic regression classiﬁcation algorithms.
0
−2
−4
−6
−8
−10
2
5
1
Number of decimals
3
4
)
0
1
g
o
l
(
r
o
r
r
e
n
o
i
t
a
m
i
t
s
e
e
v
i
t
a
l
e
R
0
−2
−4
−6
−8
SVM-RHL
SVM-SHL
KSVM-RHL
KSVM-SHL
−10
1
5
Number of decimals
2
3
4
)
0
1
g
o
l
(
r
o
r
r
e
C
C
A
e
v
i
t
a
l
e
R
0
−2
−4
−6
−8
−10
2
5
1
Number of decimals
3
4
)
0
1
g
o
l
(
r
o
r
r
e
n
o
i
t
a
m
i
t
s
e
e
v
i
t
a
l
e
R
0
−2
−4
−6
−8
SVM-RHL
SVM-SHL
KSVM-RHL
KSVM-SHL
−10
1
5
Number of decimals
2
3
4
)
0
1
g
o
l
(
r
o
r
r
e
C
C
A
e
v
i
t
a
l
e
R
0
−2
−4
−6
−8
−10
2
5
1
Number of decimals
3
4
)
0
1
g
o
l
(
r
o
r
r
e
n
o
i
t
a
m
i
t
s
e
e
v
i
t
a
l
e
R
0
−2
−4
−6
−8
SVM-RHL
SVM-SHL
KSVM-RHL
KSVM-SHL
−10
1
5
Number of decimals
3
4
2
(a) Iris
(b) Madelon
(c) Bank
Fig. 13: Defense results of the rounding technique for SVM classiﬁcation algorithms.
)
0
1
g
o
l
(
r
o
r
r
e
E
S
M
e
v
i
t
a
l
e
R
)
0
1
g
o
l
(
r
o
r
r
e
C
C
A
e
v
i
t
a
l
e
R
)
0
1
g
o
l
(
r
o
r
r
e
C
C
A
e
v
i
t
a
l
e
R
0
−2
−4
−6
−8
errors of an algorithm with L2 regularization increase more
than those with L1 regularization.
Comparing loss functions: cross entropy and square hinge
loss can more effectively defend against our attacks than
regular hinge loss: We also compare defense effectiveness
of different loss functions. Since all regression algorithms we
studied have the same loss function, we use classiﬁcation
algorithms to compare loss functions. Speciﬁcally, we use
two triples: (L2-LR, SVM-SHL, SVM-RHL) and (L2-KLR,
KSVM-SHL, KSVM-RHL). The three algorithms in each
triple use cross entropy loss, square hinge loss, and regular
hinge loss, respectively, while all using L2 regularization.
We ﬁnd that cross entropy and square hinge loss have
similar defense effectiveness against our attacks, while they
can more effectively defend against our attacks than regular
)
0
1
g
o
l
(
r
o
r
r
e
E
S
M
e
v
i
t
a
l
e
R
Diabetes
GeoOrig
UJIIndoor
)
0
1
g
o
l
(
r
o
r
r
e
n
o
i
t
a
m
i
t
s
e
e
v
i
t
a
l
e
R
2
0
−2
−4
−6
Iris
Madelon
Bank