its operations and data are beyond other apps’ reach. To use
protected global resources, such as audio, video, GPS, etc.,
each app needs to request permissions from the user or the
OS before its installation. Such permissions are categorized
into different protection levels [21], among which normal ones
are automatically granted to the apps when asked, dangerous
permissions are given based upon the user’s consent, and system
or signature permissions are saved for system apps. With a
proper permission, an app can call relevant APIs to operate on
those global resources, e.g., recording audio, taking pictures,
connecting to Bluetooth accessories, etc.
This security model is known to have a few issues, which
are becoming prominent in the presence of increasingly diverse
Android applications. First, the permission-based access control
turns out to be too coarse-grained: any app granted a permission
is allowed to use it
to access any resources, under any
circumstances. For example, a voice recorder can tape any
phone conversation without restriction; a game app with the
Bluetooth permission for connecting to its playpad can also
download patient data from a Bluetooth glucose meter. Further,
the model does not protect an app’s runtime statistics and
other resources the OS considers to be public. An example
is its network-data usage. Under some circumstances, such
information could actually be linked to the app’s program states,
allowing the adversary to ﬁgure out the content of its data [1].
As a consequence of these design limitations, even a carefully-
implemented app often unwittingly discloses its conﬁdential
data through the way it uses resources (CPU, memory, network
data, etc.) during its execution or through shared communication
channels (audio, Bluetooth, etc.) when it is sending or receiving
the data. This subjects the app to all kinds of RIG attacks in
which the adversary is continuously monitoring its operations
and collecting its runtime information.
Data stealing. Speciﬁcally, unauthorized voice recording has
long been known to be a serious security issue. Prior study
shows that malware recording phone conversations can masquer-
ade as an app with a legitimate need for the related permission,
such as a voice dialer or a voice memo application [3]. Once
installed, it can be made to intelligently choose the data of
a high value (e.g., credit card number, password) to steal,
leveraging context information such as a bank’s interactive
voice response system. In such an attack, the malware operates
when the system phone app runs in the foreground to command
Android’s MediaRecorder service to collect the voice data
exchanged during a phone call.
More recently, research has found that Android Bluetooth
accessories are also vulnerable to such runtime data stealing [6].
The ofﬁcial app of a Bluetooth medical device, such as
blood-glucose meter and pulse oximeter, can be monitored
by a malicious app with the Bluetooth permission. Once the
legitimate app starts running in the foreground, the malware
tries to connect to its accessory before the app does or right after
it ﬁnishes its communication but before the device is turned
off. This RIG attempt was found to be often successful, letting
the unauthorized app download a patient’s clinic data. Another
example is the attack on programmatic screenshot apps [20],
which typically run a local socket connection to command a
916917
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:04:07 UTC from IEEE Xplore.  Restrictions apply. 
process invoked through Android Debug Bridge (ADB), so
as to get ADB’s signature permission for screenshot taking.
The problem is that this local socket channel has not been
properly regulated and as a result, any app with the Network
permission can ask the process to snap an picture of the screen.
The research shows that using this technique, a RIG attack can
continuously take screenshots when the user types into an app,
extracting the sensitive information (e.g., password) she enters.
In all those attacks, a malicious app abuses permissions it
gets to directly collect sensitive user data from the target app
running in the foreground. Following we show that even in
the absence of such permissions, RIG attacks can still happen
through a variety of side channels on Android.
Side-channel inference. Android is designed for thin devices,
on which the level of concurrency is limited: typically, the
foreground process controls most resources while those running
in the background are often inactive and considered to be
disposable. Also, most apps are just the user interfaces of web
applications, and characterized by simple designs and intensive
interactions with their web services during their operations.
These features make an Android app’s behavior conspicuous to
the party continuously monitoring its CPU, memory, network-
data usages and other side channels and vulnerable to the
inference attacks that link the information collected to the
content of its data such as the user’s inputs.
Speciﬁcally, prior research studied the RIG attacks through
the side channels on both the Linux layer and Android’s
application framework layer. Linux-level channels are mostly
related to the public process ﬁlesystem, which includes public
statistics about a process’s use of memory, CPU, network data
and others. For example, the dynamics of the browser’s memory
usages (observed from /proc//statm) during its
rendering of web content are found to be useful for identifying
the web page the user visits [5]. In this attack, a malicious app
continuously samples the browser’s data resident sizes (called
memory footprint) when it is loading a page and compares
the set of the footprints with the proﬁles of web sites. A
more recent study looked into Android’s network data usages
(/proc/uid_stat/tcp_snd and tcp_rcv), and shows
that the increments observed from these two indicators are
in line with the payload sizes of the TCP packets sent or
received by the app under the surveillance. Such increments
were used to ﬁngerprint the app’s activities, such as sending
a tweet. This allows the adversary to query the Twitter server
using the timestamps of such operations, for determining the
individual who tweets at all these times. Also such usage
increments were found to be sufﬁcient for identifying the
content
the user clicks on when using the most popular
healthcare app WebMD [22] and high-proﬁle investment app
Yahoo! Finance [23]. As a result, by simply examining the
increment sequences gathered from these apps’ runtime, a
malicious app without any permission can ﬁgure out the disease
and stock a user is interested in.
On the framework layer, what have been extensively
investigated include keystroke identiﬁcation using motion
sensors such as accelerometer. The idea is to monitor the
movement and gesture changes when the user types through
the touch screen to infer the content she enters into a running
app. Such an inference was found to be completely feasible [4].
Another side channel exploited on the framework layer is the
public API function. Particularly, prior research shows that an
Android user’s driving route could be determined by looking
at sequences of the duration for the voice guidance produced
by Google Navigator. Such a duration is identiﬁed from the
speaker’s status (“on” or “off”), which can be found out through
a public API isMusicActive. A collection of the duration
sequences turns out to be sufﬁciently informative for tracking
the path the user drives down [1].
B. Preliminary Study on Android IoT
Given the unique features of Android (i.e., simple user-
interface programs, little noise in their running environments),
we strongly believe that what have been discovered is just a tip
of the iceberg. As a baby step towards a better understanding
of the RIG threat to Android, we looked into two popular
IoT systems, the Belkin NetCam Wi-Fi camera with Night
Vision [13] and Nest Protect [9]. Both systems are among
the front runners of the current trend of Android-based home
security and safety IoTs [24]. The NetCam camera is designed
for home surveillance and motion detection, which can identify
the stranger who gets into the house and allows the house owner
to check what has happened remotely, through her smartphone.
Nest Protect is an intelligent ﬁre alarm system. It monitors the
ﬁre situation in the user’s home and alerts her through phone.
Both systems are considered to be high-end IoTs, with at least
hundreds of thousands of users [14]. Here we describe how
they work and our analysis that reveals their RIG weaknesses.
The IoT systems. The way the NetCam system works is illus-
trated in Figure 1, which is also typical for other smartphone-
based IoT systems, including Nest Protect. Speciﬁcally, such
a system deploys a single or multiple sensors in the user’s
house. Each sensor is connected to a home Wi-Fi router for
communicating with other sensors and a server operated by
the party providing the service (home security or ﬁre alarm).
Whenever a situation is found, the sensor reports to the server,
which takes measures to respond to the event, including pushing
a message through Google-Cloud Messaging (GCM) to the
user’s phone. This message is picked up by the GCM process
on the phone, which forwards it to the IoT’s ofﬁcial app through
an Intent. The app further posts a notiﬁcation, producing an
alert sound to arouse the user’s attention. The ofﬁcial app also
enables the user to remotely control the sensors and check the
data (e.g., looking at a live video) they collect.
1HW&DP6HUYHU
,
Q
W
H
U
Q
H
W
*&0
,QWHUQHW
,QWHUQHW
2QO\ZKHQSKRQH
LVLQUDQJH
1HW&DP$SS
,QWHUQHW
Fig. 1: NetCam system
For the NetCam system, whenever the user is leaving home,
she can turn on the camera’s motion detector by clicking on the
ofﬁcial app’s “save clips” switch. Once the status of this switch
changes, the app communicates with the server to conﬁgure
the camera to automatically identify the motion likely related
917918
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:04:07 UTC from IEEE Xplore.  Restrictions apply. 
to human activities (which is not supposed to happen, given
that the house is empty), and reports to the user through the
GCM channel. Similarly, Nest Protect sensors capture a ﬁre
situation and sends an alarm to the user’s phone.
Analysis and ﬁndings. In our research, we ran both systems
while monitoring their operations through an unprivileged
attack app on the user’s Android phone. The app utilizes
getRunningTasks to ﬁnd out whether its target starts
running, and continuously collects the target’s side-channel
information, particularly its network data usage (tcp_snd
and tcp_rcv) and CPU usage (/proc//stat), for
inferring the events related to the target. With such information,
the app can also actively interfere with the system’s operation,
to prevent the user from being properly notiﬁed.
We found that for NetCam, the status of the “save clips”
switch is actually observable from the ofﬁcial app’s network
data usage. This is important because when the switch is on
(means that the camera reports any human-related motions
detected), we know exactly that no one is at home. Speciﬁcally,
whenever the status changes, the ofﬁcial app always sends out a
single packet with a payload of 368 + 2k bytes, where k is the
length of one’s username, which is typically around 10 bytes.
This packet causes the app’s tcp_snd to rise by its payload
size while a response package may add to tcp_rcv, and
then remains unchanged, together with tcp_snd in at least
1 seconds. These features make the switch-setting operations
(turning it on or off) stand out, as no other activities involve a
single packet with that length (above 300 bytes). Also, when
we take a close look at the packets that change the switch status
(from “off” to “on” or vice versa), the former is always one byte
below the latter, even when usernames vary in length. To detect
the former, our attack app ﬁrst identiﬁes a few switch operations
based on their unique features (changes of tcp_snd and
tcp_rcv), and then compares the exact tcp_snd increments
they cause to ﬁnd out the one that sets the switch on (one byte
less than those deactivating the detector). Such information
was accurately collected in our experiment when our app read
from the proc ﬁle at 10 times per second. In this way, the app
was able to determine exactly when the user’s house is empty.
Further, our research shows that the message the GCM
process delivers to the ofﬁcial NetCam app can also be
ﬁngerprinted. This is important because now the attack app
can ﬁnd out whether the camera indeed gets something and
respond to such an event, for example, by muting the speaker
temporarily to make the event less likely to come to the user’s
immediate attention. Speciﬁcally, we found that the GCM
message for such an alarm (sent by the NetCam server) ranges
from 266 bytes to more than 300, depending on the length
of the username and other variables. Again, this can be seen
from the increment of tcp_rcv (for the GCM process). This
length is rare for messages processed by GCM but might not be
unique, given that any app can use this channel to get messages.
Therefore, our attack app further veriﬁes the recipient of the
message by looking at whether the ofﬁcial app of NetCam is
invoked or its background process starts using CPU resources
(/proc//schedstat) right after the arrival of the
message (in 150 milliseconds). If so, it is evident that the alarm
has come. In response to it, the attack app immediately turns
off sound and vibration, and restores the original settings after
10 seconds. To make the attack succeed, the app needs to check
the GCM’s proc ﬁles at 20 times per second.
Another trick we can play is to ﬁnd out whether the user is
looking at the live video streamed from the camera. A unique
feature for this operation was found to be the arrival of 6
consecutive packets, each with at least 2,500 bytes. This can be
observed from the increments of the NetCam app’s tcp_rcv
when the attack app collects the data 5 times per second. Putting
things together, we conclude that even though the IoT system
is for home security, its side-channel weaknesses can actually
be taken advantage of for committing a robbery. Speciﬁcally,
the robber running an app on the victim’s phone knows when
the house is empty by inferring the switch status, whether the
camera detects his break-in and the user is looking at the video.
He can be further protected by muting the alarm sent to the
user. A video demo of the attack is posted online [15].
It turns out that Nest Protect is equally vulnerable to the RIG
attacks, though the system was carefully built to avoid common
security ﬂaws1. Speciﬁcally, the ﬁre alarm sent through GCM
always increases its tcp_rcv by 305 to 318 bytes, which can
be reliably identiﬁed by the attack app when it is sampling
the indicator 20 times per second. The event can be conﬁrmed
by checking the CPU usage of the Nest app. In our research,
we performed the same muting attack to disable sound once
an alarm is arrived, which worked as effectively as that on
NetCam. As a result, the attack app could make the alarm
temporarily go unnoticeable.
III. APP GUARDIAN
As demonstrated by the prior research and our preliminary
study, Android is not designed to withstand the RIG threat. Its
fundamental limitations, such as shared channels and public
resources, subject it to various forms of runtime information
collection, which often causes the exposure of sensitive user
information. This problem is realistic, pervasive and serious,
and can only be addressed by new techniques that are effective
and also easy to deploy across nearly one billion Android
systems customized by various parties. In this section, we
elaborate the design and implementation of such a technique,
which protects the app carrying private user information at the
application level.
A. Overview
Before delving into details, here we ﬁrst present the idea
behind our technique, a 1000-foot view of its design and the
assumptions made in our research.
Idea and high-level design. Critical to the success of any RIG
attack is a malicious app’s capability to run side-by-side with
the target app, collecting the information exposed during its
operation. To defeat such an attack, therefore, it is important
to stop such information-gathering activities. For this purpose,
our approach suspends suspicious apps’ executions throughout
the target app’s runtime and resumes them after the target
completes its task. During this period (called the Ward mode
or simply Ward in our research), we further ensure that no
suspicious app is invoked, and the Guardian app can protect