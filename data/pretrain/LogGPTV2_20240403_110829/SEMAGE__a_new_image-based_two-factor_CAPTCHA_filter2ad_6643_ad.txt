Semage
11.64
Asirra
17.35
recaptcha
11.05
Table 1: Average Time taken per challenge for each of the systems
(in seconds)
The distribution plots in Figures 9 show that most of the users
of SEMAGE ﬁnished each challenge in about 11.647 seconds or
less, whereas this number is comparatively higher for Asirra with
most of the users taking around 17.355 seconds. Consistency and
uniformity in majority of the data points of the plots show that the
timing average was not largely affected by some isolated outlier
cases and it represents the general behavior of the users.
We notice that the average time taken by the users to solve a chal-
lenge from SEMAGE is almost the same as that of reCAPTCHA.
This is actually surprising. We expected that solving a SEMAGE
challenge is much slower than solving a reCAPTCHA challenge
because text-based CAPTCHAs have been widely in use for a long
time and users have gotten used to them whereas users were seeing
our system for the very ﬁrst time. This encouraging fact suggests
that SEMAGE is pretty user-friendly and easy to use.
We concede that an Assira challenge consists of more images
than a SEMAGE challenge leading to more time spent in complet-
ing each challenge. However, Assira needs more images in each
challenge set to be secure because of the limited set of differenti-
ating classes of objects (two to be precise, cats and dogs) whereas
there can be theoretically thousands of differentiating classes in our
SEMAGE implementation. Moreover, presence of just two differ-
entiating given classes should have made the challenge easier for
humans as they simply need to place each image in one of the two
categories. SEMAGE on the other hand requires the user to relate
two or more images, making it potentially more time consuming.
However the timing data clearly shows that taking SEMAGE chal-
lenges is easier than it seems because of the natural cognitive ability
of humans.
5.5 Accuracy Statistics
Simply speaking, the total number of correct attempts for SEMAGE
is higher than Asirra, indicating that users are able to correctly solve
more challenges of SEMAGE. Figure 10(a) shows a graphical rep-
resentation of the difference in correct attempts between Assira and
SEMAGE. We had also asked the users to rate their familiarity and
comfort level with CAPTCHAs on the scale of 1 to 5 (with 5 being
very comfortable) in the initial questionnaire. As we see in Fig-
ure 10(b), the participants who voluntarily identiﬁed themselves
as ‘less comfortable’ (rated 3 or less) with CAPTCHA systems in
general also show high accuracy with SEMAGE and reCAPTCHA
than with Asirra.
(a) Total correct attempts out of 815 attempts
(b) Total correct attempts from 132 users who rated
themselves as less comfortable with CAPTCHA
Figure 10: Accuracy achieved on individual systems
In order for the system to be deployed in the real world, it should
have a high ‘Correct Attempts ratio’ for humans. The ‘Correct At-
tempts ratio’ (C.A.R) is simply the number of correct attempts di-
(a) SEMAGE Timing
(b) Assira Timing
(c) reCAPTCHA Timing
Figure 9: Timing Distribution of each system for all users
vided by the total attempts. It signiﬁes how many times a human
passes the challenge. The closer the ratio is to 1, the better the
system is in terms of usability.
The user study data shows that our system has a higher C.A.R
(0.94) than Asirra (0.91). Users had been familiar with text-based
CAPTCHA systems, so we expected them to do very well in the
reCAPCTHA system. But again, the difference between SEMAGE
and the traditional text-based system is almost negligible. This
along with the timing data shows that our system likely has a higher
usability factor than the current state-of-the-art image-based system
(Asirra).
5.6 Fun Factor and Ease of Use
After the completion of challenges from the three systems, the
users were then asked to compare and rate SEMAGE and Assira on
the criterion of Fun and Easiness. There were two separate ques-
tions: one for Fun factor and the other for Easiness, which asked
them to choose a rating as follows:
• 1, if they found Assira to be way more fun or easy
• 3, if they found Assira and SEMAGE to be equal on the Fun
or Easiness factors
• 5, if they found SEMAGE to be way more fun or easy
• 2 or 4, if they were slightly inclined towards Assira or SEMAGE,
respectively.
These factors gave us a more subjective indicator of usability.
We can clearly see from Figure 11(a) that majority of the users
(58.92 %) choose rating 4 and 5 indicating a high fun factor with
SEMAGE. Only 16.07% choose rating 1 and 2 indicating Assira
was better while the rest considered them to be equally fun. This
clearly supports that more users found SEMAGE to be a system
that was more fun to solve than Assira.
Figure 11(b) shows the rating distribution for the easiness factor.
72.61% of the users rated 4 and 5 indicating SEMAGE to be easier
than Assira. Only 10.72% of the users rated 1 and 2 indicating
Assira to be easier while 16.66% of the users rated 3 indicating
they considered both systems to be equally easy.
These metrics as well as the timing and accuracy results shown
previously clearly demonstrate that SEMAGE is a highly user-friendly
CAPTCHA system.
6. LIMITATIONS AND FUTURE WORK
Generating a vast and correct database is always a challenge for
image-based CAPTCHA systems. In our simple SEMAGE imple-
mentation we crawl the web to automatically gather and label im-
ages. However not all images returned by the crawler were relevant,
some were even objectionable. We then manually weeded out the
irrelevant images. Such manual labor is time consuming and would
pose a big problem when the database content is regularly updated.
(a) Users rating the Fun factor
(b) Users rating the Easiness
Figure 11: We asked users to comparatively rate SEMAGE and As-
sira on the metrics of fun and easiness. Rating 1,2 indicate Assira
to be more fun and easy, rating 3 indicate both systems are equal
and rating 4,5 indicate SEMAGE to be more fun and easy.
There can also be legal issues in directly using the crawled images.
SEMAGE by the virtue of its design though, does not require
the database to be built in such a way. Websites like e-commerce
services, movie rental services can easily use the available image
database with a suitable “semantic relationship”. However, further
work is required to create a large, correct database automatically to
allow widespread deployment in real world.
In this paper we introduced the concept and technique of creating
CAPTCHAs using “semantic relationships” between objects and
then implemented a simple system for demonstration. Our naive
implementation does not reach the full potential of SEMAGE and
we plan to build a more robust, high semantic correlation based
SEMAGE system as future work.
7. CONCLUSION
In this paper, we present SEMAGE (semantically matching im-
ages). The design of this CAPTCHA presents a set of candidate
images and asks users to choose a set of images that ﬁt a certain
relation. The challenge is layered in that both knowledge about se-
mantic meaning of images and relationship between the subjects of
images is required. The challenge comes naturally to humans as it
incorporates light-weight visual and cognitive task. However, the
layering scheme provides double protection against bot attacks. It
is easy to understand and the interaction interface is simple and ef-
ﬁcient. CAPTCHA systems constantly seek an optimum trade-off
point on security and usability. SEMAGE provides great room for
customization by the website administrators. They can customize
the number of candidate images and semantically similar images in
the challenges to adjust the usability and security level according
to the need of particular websites. Moreover SEMAGE can be tar-
geted towards touch-based smart-phones and devices where typing
to solve a text-based CAPCTHA is difﬁcult. Website administra-
tors can also determine the content of the image database and cater
towards their promotional needs. The database can be populated
especially for SEMAGE, or adapted from existing database. E-
commerce is one area where SEMAGE database can be easily built
and SEMAGE can be utilized for both security and advertisement
purposes.
8. REFERENCES
[1] Audio and visual captcha.
http://www.nswardh.com/shout/.
[2] Breaking text captcha. http://www.blackhat-seo.com/
2008/how-to-break-captchas/.
[3] Esp-pix. http://server251.theory.cs.cmu.edu/
cgi-bin/esp-pix/esp-pix.
[4] Gimpy project.
http://www.captcha.net/captchas/gimpy/.
[5] Imagemagick.
http://www.imagemagick.org/script/index.php.
[6] recaptcha ofﬁcial site. reCaptchaOfficialSite:http:
//www.google.com/reCAPTCHA.
[7] Sq-pix. http:
//server251.theory.cs.cmu.edu/cgi-bin/sq-pix.
[8] L. v. Ahn. Human Computation. Ph. d. dissertation, Carnegie Mellon
University, 2005.
[9] H. S. Baird and K. Popat. Human interactive proofs and document
image analysis. In Proceedings of the 5th International Workshop on
Document Analysis Systems V, DAS ’02, pages 507–518, London,
UK, 2002. Springer-Verlag.
[10] J. P. Bigham and A. C. Cavender. Evaluating existing audio captchas
and an interface optimized for non-visual use. In Proceedings of the
27th international conference on Human factors in computing
systems, CHI ’09, pages 1829–1838, New York, NY, USA, 2009.
ACM.
[11] E. Bursztein, R. Bauxis, H. Paskov, D. Perito, C. Fabry, and J. C.
Mitchell. The failure of noise-based non-continuous audio captchas.
In Proceedings of 2011 IEEE Symposium on Security and Privacy
(Oakland’11), 2011.
[12] E. Bursztein, R. Beauxis, H. S. Paskov, D. Perito, C. Fabry, and J. C.
Mitchell. The failure of noise-based non-continuous audio captchas.
In Proceedings of the 2011 IEEE Symposium on Security and
Privacy. IEEE Computer Society, 2011.
[13] E. Bursztein, S. Bethard, C. Fabry, D. Jurafsky, and J. C. Mitchell.
How good are humans at solving captchas? a large scale evaluation.
In Proceedings of 2010 IEEE Symposium on Security and Privacy
(Oakland’10), 2010.
[14] T.-Y. Chan. Using a text-to-speech synthesizer to generate a reverse
turing test. Tools with Artiﬁcial Intelligence, IEEE International
Conference on, 0:226, 2003.
[15] K. Chellapilla, K. Larson, P. Simard, and M. Czerwinski. Designing
human friendly human interaction proofs (hips). In Proceedings of
the SIGCHI conference on Human factors in computing systems, CHI
’05, pages 711–720, New York, NY, USA, 2005. ACM.
[16] K. Chellapilla and P. Simard. Using machine learning to break visual
human interaction proofs (hips). In In Advances in Neural
Information Processing Systems, pages 265–272, 2005.
[17] M. Chew and J. D. Tygar. Image recognition captchas. In In
Proceedings of the 7th International Information Security
Conference (ISC), pages 268–279, 2004.
[18] R. Datta, J. Li, and J. Z. Wang. Imagination: a robust image-based
captcha generation system. In Proceedings of the 13th annual ACM
international conference on Multimedia, MULTIMEDIA ’05, pages
331–334, New York, NY, USA, 2005. ACM.
[19] A. S. El Ahmad, J. Yan, and L. Marshall. The robustness of a new
captcha. In Proceedings of the Third European Workshop on System
Security, EUROSEC ’10, pages 36–41, New York, NY, USA, 2010.
ACM.
[20] J. Elson, J. R. Doucerur, J. Howell, and J. Saul. Asirra: A captcha
that exploits interest-aligned manual image categorization. In
Proceedings of the 14th ACM conference on Computer and
communications security, CCS ’07, pages 366–374, New York, NY,
USA, 2007. ACM.
[21] H. Gao, H. Liu, D. Yao, X. Liu, and U. Aickelin. An audio captcha to
distinguish humans from computers. In Proceedings of the 2010
Third International Symposium on Electronic Commerce and
Security, ISECS ’10, pages 265–269, Washington, DC, USA, 2010.
IEEE Computer Society.
[22] P. Golle. Machine learning attacks against the asirra captcha. In
Proceedings of the 15th ACM conference on Computer and
communications security, CCS ’08, pages 535–542, New York, NY,
USA, 2008. ACM.
[23] R. Gossweiler, M. Kamvar, and S. Baluja. What’s up captcha?: a
captcha based on image orientation. In Proceedings of the 18th
international conference on World wide web, WWW ’09, pages
841–850, New York, NY, USA, 2009. ACM.
[24] R. Guha, R. McCool, and E. Miller. Semantic search. In Proceedings
of the 12th international conference on World Wide Web, WWW ’03,
pages 700–709, New York, NY, USA, 2003. ACM.
[25] P. Matthews and C. C. Zou. Scene tagging: image-based captcha
using image composition and object relationships. In Proceedings of
the 5th ACM Symposium on Information, Computer and
Communications Security, ASIACCS ’10, pages 345–350, New
York, NY, USA, 2010. ACM.
[26] G. Mori and J. Malik. Recognizing objects in adversarial
clutter—breaking a visual captcha. In In Proceedings of the
Conference on Computer Vision and Pattern Recognition, 2003.
[27] Y. Rui and Z. Liu. Excuse but are you human? In Proceedings of the
eleventh ACM international conference on Multimedia,
MULTIMEDIA ’03, pages 462–463, New York, NY, USA, 2003.
ACM.
[28] L. von Ahn, M. Blum, N. J. Hopper, and J. Langford. Captcha: Using
hard ai problems for security. In In In Proceedings of Eurocrypt, Vol.
2656, pages 294–311, 2003.
[29] L. von Ahn, M. Blum, and J. Langford. Telling humans and
computers apart automatically. Commun. ACM, 47:56–60, February
2004.
[30] J. Yan and A. S. El Ahmad. A low-cost attack on a microsoft captcha.
In Proceedings of the 15th ACM conference on Computer and
communications security, CCS ’08, pages 543–554, New York, NY,
USA, 2008. ACM.
[31] J. Yan and A. S. El Ahmad. Usability of captchas or usability issues
in captcha design. In Proceedings of the 4th symposium on Usable
privacy and security, SOUPS ’08, pages 44–52, New York, NY,
USA, 2008. ACM.
[32] B. B. Zhu, J. Yan, Q. Li, C. Yang, J. Liu, N. Xu, M. Yi, and K. Cai.
Attacks and design of image recognition captchas. In Proceedings of
the 17th ACM conference on Computer and communications security,
CCS ’10, pages 187–200, New York, NY, USA, 2010. ACM.