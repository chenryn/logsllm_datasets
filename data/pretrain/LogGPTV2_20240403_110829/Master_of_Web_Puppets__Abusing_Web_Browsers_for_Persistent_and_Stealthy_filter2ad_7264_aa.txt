title:Master of Web Puppets: Abusing Web Browsers for Persistent and Stealthy
Computation
author:Panagiotis Papadopoulos and
Panagiotis Ilia and
Michalis Polychronakis and
Evangelos P. Markatos and
Sotiris Ioannidis and
Giorgos Vasiliadis
Master of Web Puppets: Abusing Web Browsers
for Persistent and Stealthy Computation
Panagiotis Papadopoulos,∗ Panagiotis Ilia,∗ Michalis Polychronakis,† Evangelos P. Markatos,∗
Sotiris Ioannidis,∗ Giorgos Vasiliadis∗
∗FORTH, Greece, {panpap, pilia, markatos, sotiris, gvasil}@ics.forth.gr
†Stony Brook University, USA, PI:EMAIL
Abstract—The proliferation of web applications has essentially
transformed modern browsers into small but powerful operating
systems. Upon visiting a website, user devices run implicitly
trusted script code, the execution of which is conﬁned within
the browser to prevent any interference with the user’s system.
Recent JavaScript APIs, however, provide advanced capabilities
that not only enable feature-rich web applications, but also allow
attackers to perform malicious operations despite the conﬁned
nature of JavaScript code execution.
In this paper, we demonstrate the powerful capabilities
that modern browser APIs provide to attackers by presenting
MarioNet: a framework that allows a remote malicious entity to
control a visitor’s browser and abuse its resources for unwanted
computation or harmful operations, such as cryptocurrency
mining, password-cracking, and DDoS. MarioNet relies solely on
already available HTML5 APIs, without requiring the installation
of any additional software. In contrast to previous browser-
based botnets, the persistence and stealthiness characteristics of
MarioNet allow the malicious computations to continue in the
background of the browser even after the user closes the window
or tab of the initially visited malicious website. We present the
design, implementation, and evaluation of our prototype system,
which is compatible with all major browsers, and discuss potential
defense strategies to counter the threat of such persistent in-
browser attacks. Our main goal is to raise awareness about this
new class of attacks, and inform the design of future browser
APIs so that they provide a more secure client-side environment
for web applications.
I.
INTRODUCTION
Our increasing reliance on the web has resulted in sophisti-
cated browsing software that essentially behaves as an integrated
operating system for web applications. Indeed, contemporary
browsers provide an abundance of APIs and sensors (e.g.,
gyroscope, location, battery status) that can be easily used
by web applications through locally-running JavaScript code.
The constantly expanding JavaScript interfaces available in
modern browsers enable users to receive timely updates, render
interactive maps and 3D graphics, or even directly connect to
other browsers for peer-to-peer audio or video communication
(e.g., through WebRTC).
In the era of edge computing, the capabilities offered by the
available APIs have pushed a signiﬁcant part of web application
Network and Distributed Systems Security (NDSS) Symposium 2019
24-27 February 2019, San Diego, CA, USA
ISBN 1-891562-55-X
https://dx.doi.org/10.14722/ndss.2019.23070
www.ndss-symposium.org
logic to the endpoints. Web publishers transfer parts of the
critical computations on the user side, thus minimizing latency,
providing satisfactory user experience and usability, while at
the same time increasing the scalability of the service. Despite
all these advancements, the web largely works in the very same
way since its initial inception: whenever a user visits a website,
the browser requests from the remote web server (and typically
from other third-party servers) all the necessary components
(e.g., HTML, CCS, JavaScript and image ﬁles), executes any
script code received, and renders the website locally. That is,
whenever a user visits a website, the browser blindly executes
any received JavaScript code on the user’s machine.
From a security perspective, a fundamental problem of web
applications is that by default their publisher is considered as
trusted, and thus allowed to run JavaScript code (even from
third parties) on the user side without any restrictions (as long
as it is allowed by the website’s content security policy, if
any). More importantly, users remain oblivious about the actual
operations performed by this code. This problem has became
evident lately with the widespread surreptitious deployment
of cryptocurrency mining scripts in thousands of websites,
exploiting the visitors’ browsers without their consent [18],
[66]. Although there are some blacklist-based extensions and
tools that can protect users to some extent, such as Google’s
safe browsing, these do not offer complete protection.
On the other hand, disabling entirely the execution of
JavaScript code often breaks intended legitimate functionality
and affects the overall user experience. In general, the highly
dynamic nature of JavaScript, the lack of mechanisms for
informing users about the implemented functionality, and the
instant execution of script code, which does not leave room
for extensive security checks before invocation, are facilitators
for malicious or unwanted in-browser code execution.
On the positive side, unwanted JavaScript execution so far
has been constrained chronologically to the lifetime of the
browser window or tab that rendered the compromised or ma-
licious website. Consequently, cryptocurrency mining or other
malicious JavaScript code can affect users only temporarily,
typically for just a few minutes [53], depending on the time a
user spends on a given website. Unfortunately, however, some
recently introduced web technologies—already supported by
the most popular browsers—can severely exacerbate the threat
of unwanted JavaScript computation in terms of stealthiness,
persistence, and scale, and the support of such capabilities has
already started raising concerns of the community [29].
In this paper, we present MarioNet: a system that enables
a remote attacker to control users’ browsers and hijack device
resources. Upon visiting a website that employs MarioNet, the
user’s browser joins a centrally orchestrated swarm that exploits
user machines for unwanted computation, and launching a
wide variety of distributed network attacks. By leveraging
the technologies offered by HTML5, MarioNet goes beyond
existing approaches and demonstrates how malicious publishers
can launch persistent and stealthy attacks. This is possible by
allowing malicious actors to continue having control of the
victim’s browser even after the user browses away from a
malicious or infected website, and by bypassing most of the
existing in-browser detection mechanisms.
MarioNet consists of two main parts: (a) an in-browser
component, and (b) a remote command and control system.
Although MarioNet enables the attacker to perform attacks
similar to those carried out by typical botnets [32], there are
some fundamental differences. First and foremost, MarioNet
does not exploit any implementation ﬂaw on the victim’s
system and does not require the installation of any software.
In contrast, MarioNet, leverages the provided capabilities of
JavaScript and relies on some already available HTML5 APIs.
Consequently, MarioNet is compatible with the vast majority
of both desktop and mobile browsers. In contrast to previous
approaches for browser hijacking (e.g., Puppetnets [4]), a key
feature of MarioNet is that it remains operational even after
the user browses away from the malicious webpage.
In particular, our system fulﬁlls three important objectives:
(i) isolation from the visited website, allowing ﬁne-grained
control of the utilized resources; (ii) persistence, by continuing
its operation uninterruptedly on the background even after
closing the parent tab; and (iii) evasiveness, avoiding detection
by browser extensions that try to monitor the webpage’s activity
or outgoing communication. Besides malicious computation
some of the attacks the infected browsers can perform include
DDoS, darknet creation, and malicious ﬁle hosting and sharing.
Overall, in this paper, we make the following contributions:
1) Present MarioNet: a novel multi-attack framework to allow
persistent and stealthy bot operation through web browsers.
MarioNet is based on an in-browser execution environment
that provides isolated execution, totally independent from
any open browsing session (i.e., browser tab). Therefore,
it is able to withstand any tab crashes and shutdowns,
signiﬁcantly increasing the attacker’s ﬁrepower by more
than an order of magnitude.
2) Demonstrate and assess the feasibility of our approach with
a proof of concept implementation of MarioNet for the
most common web browsers (i.e., Chrome, Firefox, Opera,
and Safari). To measure its effectiveness, we thoroughly
evaluate MarioNet for various attack scenarios.
3) Discuss in detail various defense mechanisms that can be
applied as countermeasures against MarioNet-like attacks.
The main goal of this work is to raise awareness about the
powerful capabilities that modern browser APIs provide to
attackers, so that a more secure client-side environment can be
provided for web applications in the future.
II. BACKGROUND
In this section, we discuss several features that have been
recently introduced as part of HTML5 and inﬂuence our design.
2
We also discuss the capabilities of web browser extensions,
especially with regards to these HTML5 features, and ﬁnally,
for each feature, we analyze its security aspects, access policies,
permissions, and threat vectors that may open.
A. HTML5 features
1) Web Workers: Browsers typically have one thread that
is shared for both the execution of JavaScript and for page
rendering processing. As a result, page updates are blocked
while the JavaScript interpreter executes code, and vice versa.
In such cases browsers typically ask the user whether to kill
the unresponsive page or wait until the execution of such long-
running scripts is over. HTML5 solves this limitation with the
Web Workers API [46], which enables web applications to
spawn background workers for executing processing-intensive
code in separate threads from the browser window’s UI thread.
Since web workers run as separate threads, isolated from the
page’s window, they do not have access to the Dynamic Object
Model (DOM) of the webpage, global variables, and the parent
object variables and functions. More speciﬁcally, neither the
web worker can access its parent object, nor the parent object
can access the web worker. Instead, web workers communicate
with each other and with their parent object via message passing.
Web workers continue to listen for messages until the parent
object terminates them, or until the user navigates away from
the main webpage. Furthermore, there are two types of web
workers: dedicated and shared workers. Dedicated web workers
are alive as long as the parent webpage is alive, while shared
web workers can communicate with multiple webpages, and
they cease to exist only when all the connections to these
webpages are closed.
Typically, web workers are suitable for tasks that require
computationally intensive processing in an asynchronous and
parallel fashion, such as parsing large volumes of data and
performing computations on arrays, processing images and
video, data compression, encryption etc. Indeed, during the
recent outbreak of web-based cryptocurrency mining, we have
observed that typically these scripts utilize web workers for
mining, and that they deploy multiple such workers to utilize
all available CPU cores of the user’s system.
2) Service Workers: Service workers are non-blocking
(i.e., fully asynchronous) modules that reside in the user’s
browser, in between of the webpage and the publisher’s web
server. Unlike web workers, a service worker, once registered
and activated, can live and run in the background, without
requiring the user to continue browsing through the publisher’s
website—service workers run in a separate thread and their
lifecycle is completely independent from the parent page’s
lifecycle. The characteristics of service workers enable the
provision of functionality that cannot be implemented using
web workers, such as push notiﬁcations and background syncing
with the publisher. Furthermore, another core feature of service
workers is their ability to intercept and handle network requests,
including programmatically managing the caching of responses.
This allows developers to use service workers as programmable
network proxies, thus enriching the ofﬂine user experience by
controlling how network requests from a webpage are handled.
A service worker can be registered only over HTTPS via
the serviceWorkerContainer.register() function,
which takes as argument the URL of the remote JavaScript
ﬁle that contains the worker’s script. This URL is passed to
the internal browser’s engine and is fetched from there. For
security purposes, this JavaScript ﬁle can be fetched only from
the ﬁrst-party domain (i.e., cannot be hosted in a CDN or
other third-party servers). Also, no iframe or third-party script
can register its own service worker. Importantly, no browser
extension or any in-browser entity can have access either in the
browser’s C++ implementation that handles the retrieval and
registration of the service worker or in the ﬁrst-party domain.
When the user browses away from a website, the service
worker of that website is typically paused by the browser;
it is then restarted and reactivated once the parent domain
is visited again. However, it is possible for the publisher of
a website to keep its service worker alive by implementing
periodic synchronization. It should be noted though that the
registration of a service worker is entirely non transparent to the
user, as the website does not require the user’s permission to
register and maintain a service worker. Furthermore, similarly to
web workers, service workers cannot access the DOM directly.
Instead, they communicate with their parent webpages by
responding to messages sent via the postMessage interface.
3) WebRTC: Popular web-based communication applica-
tions (such as Web Skype, Google Meet, Google Hangouts,
Amazon Chime, Facebook Messenger) nowadays are based on
Web Real-Time Communication (WebRTC) API [23], which
enables the establishment of peer-to-peer connections between
browsers. The WebRTC technology enables browsers to perform
real-time audio and video communication and exchange data
between peers, without the need of any intermediary.
As in every peer-to-peer protocol, a challenge of WebRTC
is to locate and establish bidirectional network connections
with remote peers residing behind a NAT. To address this,
WebRTC uses STUN (Session Traversal Utilities for NAT)
and TURN (Traversal Using Relays around NAT) servers
for resolving the network address of the remote peer and
reliably establishing a connection. There are several such servers
publicly available [21], maintained either by organizations (e.g.,
Universities) or companies (e.g., Google).
4) Cross-Origin Resource Sharing: Before HTML5, sending
AJAX requests to external domains was impossible due to the
restrictions imposed by the same-origin policy, which restricts
scripts running as part of a page in accessing only the DOM
and resources of the same domain. This means that a web
application using AJAX APIs (i.e., XMLHttpRequest and
the Fetch API) can only request resources from the same
domain it was loaded.
However, the Cross-Origin Resource Sharing (CORS) [43]
capabilities introduced in HTML5, allow scripts to make cross-
origin AJAX requests to other domains. To enable this feature,
CORS uses extra HTTP headers to permit a user agent to access
selected resources from a server on a different domain (origin)
than the parent sits. Additionally, for HTTP request methods
that can cause side-effects on server-side data (in particular,
for HTTP methods other than GET, or for POST usage with
certain MIME types), the speciﬁcation mandates browsers to
“preﬂight” the request, soliciting supported methods from the
server with an HTTP OPTIONS request method, to determine
whether the actual request is safe to send.
B. Web Extensions