one is interested in measuring the aggregate effect that a single
element has, given the actions of subsets.
A revenue division should ideally satisfy certain desiderata.
Formally, we wish to ﬁnd a function φ(N, v), whose input
is N and v : 2N → R, and whose output is a vector in
n, such that φi(N, v) measures some quantity describing
R
the overall contribution of the i-th player. Research on fair
revenue division in cooperative games traditionally follows an
axiomatic approach: deﬁne a set of properties that a revenue
division should satisfy, derive a function that outputs a value
for each player, and argue that it is the unique function that
satisﬁes these properties.
Several canonical fair cooperative solution concepts rely
on the fundamental notion of marginal contribution. given a
player i and a set S ⊆ N \ {i}, the marginal contribution of
i to S is denoted mi(S, v) = v(S ∪ {i}) − v(S) (we simply
write mi(S) when v is clear from the context). Marginal QII,
as deﬁned above, can be viewed as an instance of a measure of
marginal contribution. Given a permutation π ∈ Π(N ) of the
elements in N, we deﬁne Pi(σ) = {j ∈ N | σ(j)  0, with probability ≥ 1 − δ, we output a value φ∗
i such
that |φ∗
i − φi| < ε.
ε , log 1δ.
More generally, [23] observe that
the number of i.i.d.
samples needed in order to approximate the Shapley value and
Banzhaf index is parametrized in Δ(v) = maxS⊆N v(S) −
minS⊆N v(S). Thus, if Δ(v) is a bounded value, then an ε-
δ approximation exists. In our setting, coalitional values are
always within the interval [0, 1], which immediately implies
the following theorem.
Theorem 10. There exists an ε-δ approximation scheme for
the Banzhaf and Shapley values in the QII setting.
B. Estimating Q
Since we do not have access to the prior generating the
data, we simply estimate it by observing the dataset itself.
Recall that X is the set of all possible user proﬁles; in this
605605
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:16:24 UTC from IEEE Xplore.  Restrictions apply. 
(cid:10)
(cid:10)
case, a dataset is simply a multiset (i.e. possibly containing
multiple copies of user proﬁles) contained in X . Let D be a
ﬁnite multiset of X , the input space. We estimate probabilities
by computing sums over D. For example, for a classiﬁer c,
the probability of c(X) = 1.
x∈D 1(c(x) = 1)
ˆED(c(X) = 1) =
(10)
Given a set of features S ⊆ N, let D|S denote the elements
of D truncated to only the features in S. Then, the intervened
probability can be estimated as follows:
|D|
.
(cid:10)
uS∈D|S
(cid:10)
x∈D 1(c(x|N\SuS) = 1)
|D|2
.
ˆED(c(X−S) = 1) =
(11)
Similarly, the intervened probability on individual outcomes
can be estimated as follows:
ˆED(c(X−S) = 1|X = x) =
uS∈DS
1(c(x|N\SuS) = 1)
|D|
.
Finally, let us observe group disparity:
(cid:12)(cid:12)(cid:12)ˆED(c(X−S) = 1 | X ∈ Y) − ˆED(c(X−S) = 1 | X /∈ Y)
(cid:12)(cid:12)(cid:12)
(12)
The term ˆED(c(X−S) = 1 | X ∈ Y) equals
(13)
Thus group disparity can be written as:
(cid:3)
uS∈DS
x∈Y
1|Y|
(cid:3)
(cid:3)
(cid:12)(cid:12) 1|Y|
(cid:3)
− 1|D \ Y|
We write ˆQY
x∈D\Y
x∈Y
uS∈DS
1(c(x|N\SuS) = 1),
(cid:3)
(cid:3)
1(c(x|N\SuS) = 1)
(cid:12)(cid:12).
1(c(x|N\SuS) = 1)
uS∈DS
disp(S) to denote (13).
If D is large, these sums cannot be computed efﬁciently.
Therefore, we approximate the sums by sampling from the
dataset D. It is possible to show using the According to the
Hoeffding bound [24], partial sums of n random variables
Xi, within a bound Δ, can be well-approximated with the
following probabilistic bound:
(cid:8)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) 1
n
n(cid:3)
i=1
Pr