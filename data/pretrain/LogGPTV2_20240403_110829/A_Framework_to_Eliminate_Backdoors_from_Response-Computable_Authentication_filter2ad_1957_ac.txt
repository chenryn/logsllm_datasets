In this section, we deﬁne response-computable au-
thentication (RCA) and usable RCA backdoors. We
then analyze the existence and usability of backdoors in
our framework. Finally, we discuss the countermeasure
against possible backdoors.
A. RCA backdoors deﬁnition
Deﬁnition 1 (Response-Computable Authentication).
A two-party (e.g. client and server) authentication is
called a response-computable authentication (RCA) if
all the following statements hold:
• The client computes (or chooses) a response and
then sends to the server.
• The server has a computation component that com-
putes an expected response independently.
• Whether the authentication passes or not depends
on whether the user response equals to the expected
response.
In brief, an RCA is an authentication with a compute-
the server and the
then-compare logic. Speciﬁcally,
client compute the response separately. The server com-
pares the two values to decide whether to authenticate
the user.
The server’s computation component of an RCA can
be modeled as a computation function f. We present
the details in the following deﬁnition.
9
Deﬁnition 2 (Computation Function). A computation
function is a binary function, which reads in two argu-
ments that cannot be controlled by attackers, i.e., a ran-
domly generated challenge cha and a secret password
pw from the password database, and then outputs an
expected response Response(cid:2) for further comparison.
In our framework, the computation component re-
sides in the sandbox NaPu, and thus the computation
function f is a pure function,
i.e. given the same
arguments cha and pw, f returns the same result and
does not cause any side effects.
Deﬁnition 3 (Usable RCA Backdoor). Given an RCA
whose computation function is f, a RCA backdoor
exists in this RCA if and only if, there is a hidden
client-side response generation schema S such that
the attacker can login successfully with a probability
Pbackdoor. This backdoor is called a (S, Pbackdoor)-
backdoor. If Pbackdoor is higher than a predeﬁned
threshold Pthreshold, it is called usable.
More speciﬁcally, the attacker can choose a special
(or any) id and waits for a special (or any) cha, and
then sends the response S(id, cha) to server, and ﬁnally
logins successfully with a probability
Pbackdoor = P (S(id, cha)==f (pw, cha)) ,
such that,
Pbackdoor ≥ Pthreshold,
where the pw is the corresponding secret password of
id.
The attacker is also the developer of the computation
function f, and he/she has some knowledge about f,
such as f’s algorithm or a hidden vulnerability in f’s
implementation or a rarely executed execution path.
These knowledge can be combined into the attack
schema S. As a result, even though the attacker does
not know id’s corresponding pw, he/she can login
successfully with a probability (i.e. Pbackdoor) greater
than the probability (denoted as P id
guess) of guessing
the right password. Even worse, if the attacker can try
several login attempts in a short time, he/she can login
successfully much faster.
Deduction 1 (Probability of Successful Attacks in a
Login Session). In a classical login session, the user
is allowed to try several login attempts before he/she
is forbidden to login. Suppose the count of permitted
attempts in a login session is NL and the attacker can
login successfully with a probability Pbackdoor in each
attempt, the probability with which the attacker can
login successfully in the whole login session is
Ptotal = 1−(1 − Pbackdoor)NL
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:49:58 UTC from IEEE Xplore.  Restrictions apply. 
According to the Bernoulli inequality, we can in-
fer that: Ptotal ≤ Pbackdoor × NL. Especially, when
Pbackdoor (cid:5) 1, the statement Ptotal ≈ Pbackdoor × NL
holds. As a result, if Pbackdoor and NL are big enough,
the attacker can easily login into the target system.
On the other hand, a practical secure login system
should make sure that Pbackdoor in each attempt is small
enough and the count of permitted attempts in a certain
time period is small.
B. Security analysis of our framework
1) Effectiveness on different types of backdoors:
(1) Type T1 backdoors: For T1 type back-
doors, the compute-then-compare logic is violated, e.g.,
through vulnerability exploiting. In our framework, the
login module is decomposed into several components,
e.g., the computation and comparison components. Be-
sides, the computation component is protected by the
sandbox NaPu which is robust against vulnerabilities,
and thus the control ﬂow cannot be controlled by
attacker. Meanwhile, the comparison component is quite
simple (i.e. a compare statement) and can be enforced
easily. With this explicit comparison enforcing mecha-
nism, the compute-then-compare logic cannot be violat-
ed if the control ﬂow reaches the computation module.
Moreover, other control-ﬂow-integrity techniques can
be applied to ensure the computation module not be
bypassed. As a result, there are no T1 type backdoors
in our framework.
(2) Type T2a backdoors For T2a type backdoors, given
a certain input pw and cha, the output f (pw, cha) is
not deterministic, e.g. f outputs a predeﬁned response
when a speciﬁc trigger condition (e.g. a speciﬁc date)
meets and outputs a normal response otherwise. In our
framework, f resides in a sandbox NaPu, and we use
global state isolation and internal state resetting to make
sure f is a pure function and thus deterministic. So,
there are no T2a type backdoors.
(3) Type T2b backdoors. However, in our framework,
even though the compute-then-compare logic is en-
forced and the computation function is deterministic,
backdoors of type T2b can still be active.
In this framework, attackers only know id, cha and
f’s algorithm. Besides, f is a pure function, and its
result is used in an enforced comparison to make a
decision. In order to login successfully, attackers have
to provide a valid response matches the deterministic
expected response. More speciﬁcally, they must choose
a special (or any) id0 and wait for a special (or any)
cha0, and then send a response S(id0, cha0) to the
server to match the expected response f (pw, cha0)
generated by the server.
Fortunately, attackers know nothing about pw al-
though pw is determined by id chosen by attackers.
Ideally, if the outputs of f (pw, cha0) are completely
different for all pws (i.e. f’s value space is uniform
distributed), the attacker-supplied response S(id0, cha0)
matches f (pw, cha0) only with a low probability of
1/M (let M be the count of possible passwords),
i.e. attackers can login successfully with a probability
of 1/M which equals to the negligible probability of
guessing id’s password.
However, the outputs of f (pw, cha0) may be same
for some different pws. In an extreme case, all outputs
are the same for all different pws. And then the attacker
can choose any password, and behaves like a legal user
to generate a response, and logins successfully. In other
words, there may be backdoors if f’s value space is not
uniform distributed.
Unfortunately, the attacker knows f’s algorithm, and
thus knows the image (i.e. the value space) of f. As
a result, S(id0, cha0) may match f (pw, cha0) with a
high probability and thus an usable backdoor exists. For
example, for a certain cha0, if half of the pws lead to a
same output f (pw, cha0) (denoted as res0, known by
attackers), the attacker can randomly choose an id and
waits for the special cha0 sent from the server, then
he/she sends res0 back to the server, and ﬁnally logins
successfully with a probability equals to 1/2. Obviously,
this is an usable backdoor.
But these backdoors’ usability can be measured and
controlled as following, so they can hardly be used
practically.
2) Usability of backdoors in our framework:
Premise 1. Before discussing the usability of backdoors
in our framework, we declared some premises which are
enforced by the framework or usually acceptable.
• The attacker knows every possible valid id.
• For any id, the attacker knows nothing about its
corresponding pw, i.e. the pw is random.
• The attacker knows f’s algorithm.
• The computation function f is pure, and thus its
output is deterministic when given inputs pw and
cha.
• The computation-then-compare logic cannot be vi-
olated.
• From the cha, ﬁguring out the pw is impossible
(i.e. they are independent).
Deﬁnition 4 (Collision probability of a computation
function). Given a pure response computation function
f (pw, cha), suppose there are M possible passwords.
• For a certain cha0, let {res1, res2, ..., resk} be
the image of f (pw, cha0). Besides,
there are
Mi passwords which may cause f (pw, cha0) =
resi, where i = 1, 2, ..., k and M1 + M2 +
... + Mk = M. Then we deﬁne P cha0
=
max{M1, M2, ..., Mk}/M.
col
10
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:49:58 UTC from IEEE Xplore.  Restrictions apply. 
• For all possible cha0, we denote the maximum
P cha0
. This probability is called the
collision probability of the computation function
f.
as P max
col
col
Theorem 1 (Usability of backdoors in our frame-
work). Given any RCA implemented in our framework,
suppose its computation function is f whose collision
probability is P max
, then any T2b-backdoor attacker-
s can only login successfully with a probability not
greater than the collision probability, i.e. Pbackdoor ≤
col
col
The proof to Theorem 1 is listed in the appendix A.
P max
.
C. Countermeasures against T2b backdoors
As discussed earlier, only T2b type backdoors may
exist in our framework. More speciﬁcally, if and only
if the computation function f’s value space is not uni-
formly distributed, backdoors exist in our framework.
According to the Theorem 1, T2b backdoor attackers
can only login successfully in our framework with a
maximum probability of P max
. For any computation
function f, if the corresponding P max
is assured to
be smaller than the threshold Pthreshold, then we can
conclude there is no usable backdoors in our framework.
In our framework, a collision testing is made to
evaluate the computation function’s collision probability
P max
. If this probability is too high, i.e. higher than the
threshold, a backdoor alert is triggered.
col
col
col
However, ﬁguring out the exact collision probability
of a computation function is computationally hard.
According to the Deﬁnition 4, in order to compute the
collision probability, P cha
should be computed for all
col
cha. Further, for a given cha0, all possible pw should
be traversed to compute P cha0
. Notice that the counts
of cha and pw are both huge, and thus it is hard to
compute the exact collision probability of a computation
function.
col
Alternately, we sample parts of chas and parts of
pws and then compute a similar collision probability
to emulate the exact collision probability. More specif-
ically, some random challenges {cha1, cha2, ..., chac}
are chosen ﬁrst. And then for any chosen chai, some
random pws are selected to test f, and thus P chai
is
computed. Then the collision probability is computed,
}. If the
i.e. P max
sampled collision probability is larger than the backdoor
threshold, the computation function is regarded vulner-
able and should be eliminated before being deployed.
Although this sampling and testing scheme cannot
deduce the exact collision probability of a computation
function, it can exactly model attackers’ capabilities. In
other words, if attackers ﬁnd a usable backdoor in the
= max{P cha1
, ..., P chac
, P cha2
col
col
col
col
col
col
computation function, security testers in our framework
is likely to get a P max
higher than the threshold.
Notice that passwords in the real database only cover
a small part of all possible passwords. Besides, pass-
words are random. And thus, even though the attacker
knows f’s algorithm, he/she does not know the exact
distribution of f’s value space for passwords in the real
database. For example, if the outputs of f are same
(denoted as res0) for half of all possible passwords,
but all passwords in the database are not in this half,
then the attacker can never login successfully if he/she
still chooses res0 as the response. So, attackers can not
predicate which response are more likely to be correct
because the password database is small and random.
On the other hand, the security testers in our frame-
work randomly choose some passwords to evaluate
P max
the real
password databases.
. This randomly sampling can model
col
As a result, the attackers have no advantage over the
testers. And thus, with the help of our thorough and
random collision testing, computation functions with a
high collision probability can be ﬁltered out or no usable
backdoors exist.
V. IMPLEMENTATION
In this section, we present the implementation of
our approach, with focuses on NaPu — the Native
Pure-function enforcing sandbox. We build NaPu based
on Google’s Native Client (NaCl) [37]. NaPu provides
vulnerability isolation inherited from NaCl.
Vulnerability isolation. NaCl consists of two layers
of sandbox. The inner sandbox makes a secure subdo-
main in the native process. Besides applying software
isolation [37] and disabling the unsafe machine instruc-
tions, it also enforces structural rules and alignment to
make disassembling reliable, and constrains references
in both instruction and data memory by segmenting.
The outer sandbox uses secure interfaces to control
interactions between modules and the system.
Even though there were vulnerabilities in the code in
the sandbox, the effect will be contained in the sandbox
and cannot be used to exploit the system.
Pure function enforcing. To ensure that the response
computing function f running in NaPu is pure, we
need to eliminate the non-deterministic source of f by
isolating the global states, resetting the internal states,
and making sure it has no side effects. Meanwhile, all
the instructions allowed in NaPu are deterministic.
Global state isolation. NaCl provides a white-list
mechanism to conﬁne the native code’s accesses to
system calls. Those trusted system calls include ﬁle
operations, timers, socket calls, threading operations,
debug mode calls and sound/graphic interfaces. Those
system calls can access global states and use them as
11
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:49:58 UTC from IEEE Xplore.  Restrictions apply. 
the trigger to generate a special response, which are not
necessary for normal response computing. Therefore,
they are all prohibited in NaPu, except
the system
calls related to memory allocation. Speciﬁcally, NaPu
only provides pure function interfaces and disallows the
native code to invoke the following system calls:
• The system calls that can perform ﬁle operations
(e.g., open , read, write).
• The system calls that can obtain system timers
(e.g., gettimeofday, clock, nanosleep).
• The system calls that can make network accesses
(e.g., accept, connect, recvmsg).
• The system calls that can obtain system informa-
tion (e.g., sysconf, getpid).
• Others (threading related, sound/graphic related,
debug related).
In addition, NaPu disables the following x86 instruc-
tions in the native code of f through the instruction
validator, so that NaPu makes sure that all the allowed
instructions are deterministic.
• Instructions that can obtain hardware identiﬁcation
conﬁguration (e.g., CPUID) ;
• Instructions that can obtain hardware performance
information (e.g., RDPMC, RDTSC, and RDTSCP);
(e.g.,
that can access
I/O ports
• Instructions
IN/OUT).
Internal state reset. The backdoor may use a local
variable as the trigger, such as the example shown in
Figure 2. NaPu uses the memory wiper to resets the
internal states each time to call f, to make sure there
is no variable recording internal states.
Even though there are only memory allocation system
calls left in NaPu, the allocated memory or the memory
address can be used as triggers when there is no
special handling. For instance, an attacker may initiate
a number of login requests in a short time, since each
login authentication will be performed in one sandbox,
the memory address for each sandbox will be different
for each login request. Thus, the attacker can break the
pure function requirement. To deal with such situations,
NaPu uses the deterministic memory allocator. The
allocator ﬁlls all new allocated memory buffers with