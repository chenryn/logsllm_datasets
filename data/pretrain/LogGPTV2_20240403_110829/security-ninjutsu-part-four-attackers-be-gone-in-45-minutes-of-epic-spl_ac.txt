Here we have a search with a few fields that we want 	to use for drilldown, but don’t want to actually show 	to the analyst. controls what is shown. (json format..) Specifically, we are not showing the drilldown field
Now we can use the   to define the actual search. This can be weird if you’re not familiar with URL Encoding - it’s easiest to just google it. But here we are opening in the search app, search view, 	and passing the query (q=). Then we URL Encode 	the actual fields we want to put in there.© 2017 SPLUNK INC.
Technique: Formatting a Table Or just use our out of the box tools..
▶ … or just use ES with 
it’s built-in tables and 
built-in drilldown 
searches… which is 
way way easier
Technique: Formatting a Table
Working Example
▶ From conf2016 Security Ninjutsu Part Three, a large customer shared a search that looks for scenarios where svchost.exe wasn’t owned by services.exe. Cool search, yeah? Those MD5s are known legit svchost.exe versions in their environment. But this is going to the SOC, so what did they end with? A table.sourcetype=Win*Security EventID=4688 BaseFileName="svchost.exe" NOT CreatorProcessName="services" 
NOT (MD5="54A47F6B5E09A77E61649109C6A08866" OR […])
| sort 0 -_time
| table _time, Computer, SubjectDomainName, SubjectUserName, BaseFileName, CommandLine, CompanyName, CreatorProcessName, NewProcessName, FileDescription, FileVersion, MD5
Technique: Multi-Scenario Alerts
Background and ChallengesBackground and Challenges
▶ "There are six different reasons why I might want this to alert, but I don’t want to 	have six different searches!"
▶ "I have too many searches looking at the exact same dataset!"
▶ When we help people consolidate alerts from legacy SIEMs, there are generally two different types of consolidations. One is data sources, where our CIM allows us to avoid duplicating rules for different data types. The other is that we can consolidate rules.▶ As an example, I looked at one SIEM dataset that had 54 different auth rules, where there were 7 different data sources and 8 different logic pieces. Those fit easily into just two Splunk searches. 
Technique: Multi-Scenario Alerts Actual SPL
▶ If you have something you want to tell analysts, tell them. You can put it in the 	playbook if you know they will always look at the playbook.. Otherwise embed it.index=risk earliest=-30d 
| stats values(source) as search_names 
	sum(risk_score) as thirty_day_risk 
	sum(eval(if(_time > relative_time(now(), 
	"-1d"),risk_score,0))) as one_day_risk 
	by risk_object 
| eval threshold_1day = 500, threshold_30day = 1200 | eventstats avg(thirty_day_risk) as avg_thirty_day_risk stdev(thirty_day_risk) as stdev_thirty_day_risk 
| where one_day_risk>threshold_1day OR| where one_day_risk>threshold_1day OR 
	thirty_day_risk>threshold_30day OR 
	thirty_day_risk>
This examples uses the ES Risk Framework
Using stats + eval, we can pull out many different 	metrics here. Slicing and dicing by data type or 	particular field value, all very easy.
Here we are using a mix of static thresholds, and behavioral thresholds calculated via eventstats. Eventstats is also helpful for augmenting analysis, just make sure not to exceed its memory limits, as it will silently fail.Finally we can trigger on multiple different conditions 	with ease.
(avg_thirty_day_risk + 3 * stdev_thirty_day_risk) 
If you use multi-scenario alerts, make sure you have inline comments that explain the logic. See the next section!
Technique: Multi-Scenario Alerts
How complex is too complex?▶ A word of warning here: I love multi-scenario alerts, because I am an SPL nerd. Most seasoned PS folks will probably tell you to avoid them, because often each alert ties to a different playbook an analyst would have to pursue. Or worse, an analyst would look at the alert and not really know what it means (emphasis: inline comments is the next section). Or even, it can allow you to create hundreds of effective rules, which we know often leads to bad security practices.▶ There’s fairly broad agreement on the risk example, because it is functionally doing something pretty straightforward (looking at risk indicators) and just tries to account for quick bursts, but also slow and low activity. 
▶ Just be wary when creating these that you don’t allow your newfound power to 	create an unhappy SOC. 
Technique: Inline Comments
Background and ChallengesBackground and Challenges
▶ It’s very easy to build advanced logic in correlation searches that are difficult for an analyst to quickly ascertain the meaning of. This results in comments like "I don’t know what to do with this" or "this is not actionable."
▶ Scenario One:
• It’s very easy in Splunk to combine many different searches into one, but then analysts don’t 	know why it’s actually alerting.• For example, in analyzing the risk framework, we can alert on slow and low, or short term burst activity, or do behavioral detections all in one search. But you need to tell the analyst what to look at.
▶ Scenario Two:
• There can be some information that you would expect to be there, but maybe it’s just not. Tell 	the analyst so they don’t boggle.
Technique: In Line Comments Simple Comments▶ If you have something you want to tell analysts, tell them. You can put it in the 	playbook if you know they will always look at the playbook.. Otherwise embed it. 
[... base search here …] 
| eval "Remote Source Address"="It would sure be nice if the F5 told us where connections were coming from" 
| rename dest_ip as "Local Destination Address" 	user as User 
| table _time "* Address" Sourcetype| table _time "* Address" Sourcetype
Start with whatever base search you want
Clue Analysts into what’s going on here, so they 	know what to look for, if you cannot provide it.
*Note* -- the ES Adaptive Response can help here, 	by adding related search results to your ticket.
BTW - rename your fields so that they make sense 	to the analysts. Try to be consistent across your 	searches, but don’t make people divine what you 	mean by "outgoing_ip"Yeah, of course we finish with a table
Technique: In Line Comments Advanced Logic begets Advanced Comments
index=risk earliest=-30d | stats values(source) as search_names sum(risk_score) as thirty_day_risk sum(eval(if(_time > 
relative_time(now(), "-1d"),risk_score,0))) as one_day_risk by risk_object | eval threshold_1day = 500, threshold_30day = 1200 | eventstats avg(thirty_day_risk) as avg_thirty_day_riskstdev(thirty_day_risk) as stdev_thirty_day_risk
| where one_day_risk>threshold_1day OR 
thirty_day_risk>threshold_30day OR 
thirty_day_risk>(avg_thirty_day_risk + 3 * stdev_thirty_day_risk) 
| eval risk_score_reason = case(one_day_risk>threshold_1day, "One Day Risk Score above " . threshold_1day,thirty_day_risk>threshold_30day . " on " . strftime(now(), "%m-%d-%Y"), "Thirty Day Risk Score above " . threshold_30day, 1=1, "Thirty Day Risk Score more than three standard deviations above normal (>" . round((avg_thirty_day_risk + 3 * stdev_thirty_day_risk),2) . ")") | fields - avg* stdev*
| table risk_object risk_score one_day_risk thirty_day_risk risk_score_reason▶ If you’re going to put in advanced logic, make sure you have advanced comments and explanations
We have three potential reasons why this alert would fire - one day risk, 30 day risk, or a behavioral risk. 
(Note: I think this behavioral risk is pretty weak..)
We had three conditions in the where, so we have 3 
conditions to cover in the comment. Note that the 
conditionals are the same in the case statements.Fun fact: when combining searches with this method, 
the comment block will usually be way way longer.. 
Yeah, of course we finish with a table
	Technique: In Line Comments 
Wait, *you* are telling me to keep my comments short? Have you looked at the 	deck you’re writing right now? I have a mirror for you! 
▶ You’re familiar with tl;dr, right? Hard learned lessons:▶ If your comment is more than a few words, people aren’t going to read it. 
▶ If you have 3 different potential comments, make them visually very different (e.g., don’t start each with "This alerts because") so that people will notice the unfamiliar format at a glance.
Technique: Tuning 
Background and ChallengesBackground and Challenges
▶ "I like this correlation search but it generates too much noise"▶ "I like that you tuned this correlation search, but wow is it ever long!"▶ "I like that you tuned this correlation search, but you missed XYZ"
▶ Tuning searches is inevitable for correlation searches. Let’s look at techniques for 	doing this scalably.
Technique: Tuning 
Just toss that inline!Just toss that inline!
▶ By far, the easiest way to do tuning is to add the items inline. But beware, you 	can end up with super, super long searches. 
sourcetype=Win*Security EventID=4688 
BaseFileName="svchost.exe" NOT 
CreatorProcessName="services"
NOT (MD5="54A47F6B5E09A77E61649109C6A08866" 
OR […])
| sort 0 -_time 	That’s Tuning!
| table _time, Computer, SubjectDomainName,SubjectUserName, BaseFileName, CommandLine, 
CompanyName, CreatorProcessName, 
NewProcessName, FileDescription, FileVersion, MD5
That’s *also* Tuning!
Technique: Tuning 
Make a Macro
▶ One place to look, can be applied to multiple different searches, and makes for 	short non-scary searches!
In macro config (macros.conf, or Web UI):
[standard_host_exclusions][standard_host_exclusions] 
NOT (host=vuln-scan*.mycompany.local OR host=*.old-env.mycompany.local OR {…} )
In Correlation Search: 
index=authentication `standard_host_exclusions` | rest of your correlation search
Define your exclusions in macros.conf or in 	Settings -> Advanced Search -> Macros
Add your macro into the correlation search
Technique: Tuning 
Build a Lookup Table that the SOC can access▶ Define a lookup table with the fields you care about, then bring it into the search. 	The SOC can then access that lookup table and update it. 
Create a lookup field with whatever field you care 
about, e.g., standard_host_exclusions.csv:
host 
vuln-scan*.mycompany.local *.old-env.mycompany.local
This is just a simple CSV. You can even allow the SOC to update this via the lookup editor app (or the built in capability in Enterprise Security)!Then bring that into your correlation search: 
tag=authentication 
	[.  | inputlookup standard_host_exclusions.csv 	| stats values(host) as search 
	| eval search="NOT (host=" . mvjoin(host, " OR host=") . ")" 
	] This allows you to take those hosts, and then craft a NOT (…) string like in the macro example that is generated the moment that you click "search" with almost no performance impact.P.S. You can put that in a Macro too!
Did you know that a subsearch that returns just the field "search" is interpreted literally as a search 
string? Check out more details in the Subsearch
   technique    
Technique: stats + eval
Background and Challenges
▶ If you remember only one thing in this entire presentation, remember this.
Stats + Eval is the most powerful tool for Splunk Correlation SearchesStats + Eval = BEAST MODE
▶ "I want to alert if we see a set of events across 7 different sourcetypes in a 	particular order"
▶ "I want to alert if we see a particular error coming from the web server right after 	a user submits a particular request."
▶ "I want to run a search that tracks multiple different thresholds based on different 
time windows to find slow and low activity while also finding bursts oh and I alsowant to implement a specific piece of custom logic."
	Technique: stats + eval
▶ You can input a lookup, then output a lookup, and then continue on your search. 
Run this search every day/hour, and take advantage of a 90 day baseline!
tag=authentication 
| stats count(eval(action="success")) as successes 	count(eval(action="failure")) as failures 
values(eval(if(action="success",user,null))) as 	"Successful Users"count(eval(if(searchmatch("example of log 	message"), 1, null))) as "example hits"
	count(eval(if(match(email, 
	"\@buttercupgames\.com"),1,null))) as 	buttercup_emails 
by user
Start with whatever base search you want
Using stats + eval allows you to create columns 	based on individual items.
You can even use if statements, and use null for 	items you don’t want to include.Searchmatch even allows you to execute a raw 	search within the eval!
I’m also fond of regex matching inside of stats, 	‘cause you can just do that!