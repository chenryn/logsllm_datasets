phone number and transmits that information to Avazu servers
(api.c.avazunativeads.com).
Similar to the previous cases, we look for policy statements
that describe the data ﬂow at any semantic granularity, but
with both positive and negative sentiment. For these data
ﬂows, we do not ﬁnd any policy statements that match both
data type and entity.
This example application demonstrates the need for consid-
ering both the data type and entity. If we only considered the
data type, we would identify the following policy statement:
“When you access our Services, we automatically record and
upload information from your device including, but not lim-
ited to attributes such as the operating system, hardware
version, device settings, battery and signal strength, device
identiﬁers...” This policy statement indicates application itself
is collecting device identiﬁers. However, it does not disclose
a data ﬂow to the advertiser. Therefore, the Android identi-
ﬁer, IMEI, and phone number data ﬂows to the advertiser lack
ﬂow-to-policy consistency. Prior works [29,32,38] that do not
consider entities when reasoning over privacy policies would
have incorrectly identiﬁed these data ﬂows as consistent.
Incorrect Disclosure
2.4
A data ﬂow has an incorrect disclosure if a policy statement
indicates that the ﬂow will not occur (i.e., a negative senti-
ment sharing or collection statement) and there is not a con-
tradicting positive sentiment statement. However, we must
be careful when determining if a positive sentiment policy
statement contradicts the negative sentiment statement. Poli-
cyLint [4] identiﬁed a class of narrowing deﬁnitions (labeled
N1 to N4 in Table 1) that use a negative sentiment when refer-
ring to a more speciﬁc data type or entity. A human reading
these policy statements would not view them as contradict-
ing; rather, the negative sentiment statement would be viewed
as providing an exception to a broad sharing or collection
practice. Therefore, we still classify a data ﬂow as an incor-
rect disclosure if there is a corresponding positive sentiment
statement that matches the narrowing deﬁnitions relationship.
For example, consider the “Furby BOOM!” (com.hasbr-
o.FurbyBoom) game application, which has over 10 million
downloads on Google Play. This application is built on top
of the Unity third-party game engine. To provide statistics
to Unity for optimization purposes of their game platform,
the application obtains and sends the device’s IMEI to Unity
(stats.unity3d.com).
Similar to the above cases, we ﬁnd all relevant policy state-
ments that describe the data ﬂow at any semantic granularity.
In this case, we only ﬁnd one policy statement, “Our Apps do
not send the device ID or IP address to us or to any third-party,
and our App does not make further use of this information.”
As the device’s IMEI is a type of device identiﬁer and Unity
is a third-party, the application is inconsistent with its own
policy, as it is stating that the data ﬂow should not exist. Note
that prior works [29,32] would have incorrectly identiﬁed this
data ﬂow as consistent with the policy, as they do not handle
negative sentiment statements.
2.5 Ambiguous Disclosure
A data ﬂow has an ambiguous disclosure if the ﬂow matches
two or more contradictory policy statements where it is not
clear if the ﬂow will or will not occur. As mentioned above,
PolicyLint [4] identiﬁed different types of relationships be-
tween positive and negative sharing statements. We classify
a data ﬂow as having an ambiguous disclosure if there exist
two policy statements that have a logical contradiction rela-
tionship (C1 to C5 in Table 1), but not a narrowing deﬁnition
relationship (N1 to N4 in Table 1), as described above. Further-
more, we introduce a new set of conﬂicting policy statements
called ﬂow-sensitive contradiction relationships (C6 to C12 in
Table 1), which Section 3 explains in more detail. Data ﬂows
matching two or more policy statements with a ﬂow-sensitive
contradiction relationship are also classiﬁed as ambiguous
disclosures.
For example, consider the “Flip Diving” (com.motionvol-
t.flipdiving) game application, which has over 50 million
downloads on Google Play. This application uses the Ad-
Colony advertising provider to serve advertisements for mon-
etization purposes. When requesting advertisements from Ad-
Colony, the application obtains the user’s Android advertising
identiﬁer and transmits it to androidads23.adcolony.com.
Similar to the above cases, we ﬁnd all relevant policy state-
ments that describe the data ﬂow at any semantic granularity.
In this case, we only ﬁnd two relevant policy statements, “On
988    29th USENIX Security Symposium
USENIX Association
our apps, these third party advertising companies will collect
and use your data to provide you with targeted advertising
that is relevant to you and your preferences with your con-
sent.” and “We don’t give or sell your data to third parties
for them to market to you.” As their policy states that they
both do and do not give your data to third-parties for advertis-
ing/marketing, the policy is ambiguous. Prior works [29, 32]
would have falsely identiﬁed this data ﬂow as consistent, as
they do not capture negative sentiment sharing or collection
statements, nor do they identify conﬂicting statements.
3 Consistency Model
In this section, we provide the core logic model for our deﬁni-
tion of ﬂow-to-policy consistency, as motivated in Section 2.
We begin with a formal speciﬁcation of data ﬂows and pri-
vacy policy statements. We then introduce four ontological
operations required for reasoning over data ﬂows. Finally,
we formalize the two types of ﬂow-to-policy consistencies
(clear disclosures and vague disclosures) and the three types
of inconsistencies (omitted disclosures, incorrect disclosures,
and ambiguous disclosures).
3.1 Data Flow and Policy Statements
We model an application a as a tuple, a = (F,P), where F is
a set of data ﬂows observed for the application and P is a set
of sharing and collection policy statements extracted from the
application’s privacy policy. Let D represent the total set of
data types and E represent the total set of entities. Then, a
data ﬂow is represented by the following deﬁnition.
Deﬁnition 3.1 (Data Flow). A data ﬂow f ∈ F is a tuple
f = (e,d) where d ∈ D is the data type that is sent to an entity
e ∈ E.
For example, an application that sends the device’s adver-
tising identiﬁer to AdMob can be concisely represented by
the data ﬂow tuple (AdMob, advertising identiﬁer).
Similar to PolicyLint [4], we represent a sharing and col-
lection policy statement as a tuple (actor, action, data type,
entity) where the actor performs an action on a data type, and
an entity receives a data object of that type. We consider four
actions: share, not share, collect, and not collect. For example,
the statement, “We will share your personal information with
advertisers” is represented as (we, share, personal informa-
tion, advertisers). As our analysis can only observe client-side
behaviors, we adopt PolicyLint’s simpliﬁed policy statement
form, which transforms the 4-tuple into a more compact 3-
tuple. Intuitively, these transformation rules remove the actor
and sharing actions and only considers the entities who may
possibly receive (i.e., collect) the data type based on the pol-
icy statement (e.g., sharing data implies the actor also collects
it). Therefore, we represent a policy statement as follows.
Deﬁnition 3.2 (Policy Statement). A policy statement p ∈
P is a tuple, p = (e,c,d), where data type d ∈ D is either
collected or not collected, c ∈ {collect,not_collect}, by an
entity e ∈ E.
For example, the above 4-tuple (we, share, personal infor-
mation, advertisers) is represented as two 3-tuples: (we, col-
lect, personal information) and (advertisers, collect, personal
information).
3.2 Ontological Operations
Privacy policies may disclose data ﬂows using terms with a
different semantic granularity than the actual data ﬂow. For
example, a privacy policy may specify (advertiser, collect, de-
vice identiﬁer) to disclose the data ﬂow (AdMob, advertising
identiﬁer). To match the policy statement to the data ﬂow,
an analysis tool must know that AdMob is an advertiser and
an advertising identiﬁer is a type of device identiﬁer. These
relationships are commonly referred to as subsumptive rela-
tionships, where a more speciﬁc term is subsumed under a
more general term (e.g., AdMob is subsumed under adver-
tisers, and advertising identiﬁer is subsumed under device
identiﬁer). Such relationships are often encoded into an on-
tology, which is a rooted directed acyclic graph where terms
are nodes and edges are labeled with the relationship between
those terms.
Our analysis uses two ontologies: data type and entity.
While ontologies can represent several different types of re-
lationships, our ontologies are limited to subsumptive and
synonym relationships. We use the following notation to de-
scribe binary relationships between terms in a given ontology,
which expands on the operators deﬁned by PolicyLint. The
operators are parameterized with an ontology o, which repre-
sents either the data type (δ) or entity (ε) ontologies.
Deﬁnition 3.3 (Semantic Equivalence). Let x and y be terms
partially ordered by an ontology o. x ≡o y is true if x and y
are synonyms, deﬁned with respect to an ontology o.
Deﬁnition 3.4 (Subsumptive Relationship). Let x and y be
terms partially ordered by “is-a” relationships in an ontology
o. x (cid:64)o y is true if term x is subsumed under the term y and
x (cid:54)≡o y (e.g., “x is-a y” or “x is-a . . . is-a y”). Similarly, x (cid:118)o
y ⇔ x (cid:64)o y ∨ x ≡o y.
In addition to these two ontological operators, we iden-
tify a third type of ontological operator that impacts ﬂow-to-
policy consistency analysis. We deﬁne a semantic approxima-
tion operator that identiﬁes terms that have common descen-
dants in the ontology, but are not direct descendants of one
other. For example, consider we have the data ﬂow (Flurry,
advertising identiﬁer) and the policy statements: (advertiser,
not_collect, identiﬁers) and (analytic provider, collect, iden-
tiﬁer). As Flurry is both an advertiser and analytics provider
(common descendant), the policy becomes ambiguous when
USENIX Association
29th USENIX Security Symposium    989
considering whether the data ﬂow is disclosed by the policy.
We deﬁne semantic approximation as follows.
Deﬁnition 3.5 (Semantic Approximation). Let x and y be
terms partially ordered by “is-a” relationships in an ontology
o. x ≈o y is true if ∃z such that z (cid:64)o x ∧ z (cid:64)o y ∧ x (cid:54)(cid:118)o y ∧
y (cid:54)(cid:118)o x.
Finally, when discussing vague disclosures, it is useful to
characterize the vagueness using a metric. To help deﬁne this
metric, we deﬁne the following two operations to determine a
distance between two terms in a given ontology.
Deﬁnition 3.6 (Ontological Distance). Let x and y be terms
partially ordered by “is-a” relationships in an ontology o, and
x (cid:118)o y. The ontological distance ∆o(x,y) is the shortest path
between x and y.
Deﬁnition 3.7 (Normalized Ontological Distance). Let x and
y be terms partially ordered by “is-a” relationships in an on-
tology o, and x (cid:118)o y. The normalized ontological distance
ˆ∆o(x,y) is the length of the shortest path between x and y
divided by the length of the shortest path between x and
the root node ((cid:62)) that goes through y. More speciﬁcally,
ˆ∆o(x,y) =
∆o(x,y)
∆o(x,y)+∆o(y,(cid:62)).
3.3 Consistency
Section 2 informally deﬁned ﬁve types of disclosures used to
describe ﬂow-to-policy consistency and inconsistency. This
section formally deﬁnes a consistency model via the logical
relationships between terms in data ﬂows and policy state-
ments. A key part of the informal deﬁnitions in Section 2 is
the interpretation of situations with conﬂicting policy state-
ments, that is, contradictions and narrowing deﬁnitions. The
existence of such policy statement conﬂicts requires ﬂow-to-
policy consistency analysis to consider the policy as a whole,
rather than looking for the existence of any sharing or collec-
tion statement, as done in prior work [29, 32, 38].
PolicyLint [4] introduced ﬁve types of logical contradic-
tions (C1 to C5) and four types of narrowing deﬁnitions (N1
to N4) as shown in Table 1. Logical contradictions are a pair
of policy statements that are either exact contradictions (C1)
or those that discuss not collecting broad types of data, but
also discuss collecting exact or more speciﬁc types (C2 to C5).
Narrowing deﬁnitions are a pair of policy statements where
broad data types are stated to be collected, and speciﬁc data
types are stated to not be collected (N1 to N4).
We introduce a third pairing of conﬂicting policy state-
ments called ﬂow-sensitive contradictions (C6 to C12 in Ta-
ble 1). Flow-sensitive contradictions are a pair of policy state-
ments with opposing sentiment, such that at least one of the
data types or entities are semantically approximate to the
other. Similar to logical contradictions, ﬂow-sensitive con-
tradictions result in an ambiguous policy when reasoning
N2
N3
N4
C3
C4
C1
C2
Table 1: Types of conﬂicting policy statements in a privacy
policy: narrowing deﬁnitions (N1−4) and logical contradic-
tions from PolicyLint [4], and ﬂow-sensitive contradictions
(C6−12). C1−12 may lead to ambiguous policies.
Rule
N1
Logic
ei ≡ε e j ∧ dk (cid:65)δ dl
ei (cid:64)ε e j ∧ dk (cid:65)δ dl
ei (cid:65)ε e j ∧ dk ≡δ dl
ei (cid:65)ε e j ∧ dk (cid:65)δ dl
ei ≡ε e j ∧ dk ≡δ dl
ei ≡ε e j ∧ dk (cid:64)δ dl
ei (cid:64)ε e j ∧ dk ≡δ dl
ei (cid:64)ε e j ∧ dk (cid:64)δ dl
Example∗
(Flurry, collect, Dev Info)
(Flurry, not_collect, IMEI)
(Flurry, collect, Dev Info)
(Advertiser, not_collect, IMEI)
(Advertiser, collect, IMEI)
(Flurry, not_collect, IMEI)
(Advertiser, collect, Dev Info)
(Flurry, not_collect, IMEI)
(Flurry, collect, IMEI)
(Flurry, not_collect, IMEI)
(Flurry, collect, IMEI)
(Flurry, not_collect, Dev Info)
(Flurry, collect, IMEI)
(Advertiser, not_collect, IMEI)
(Flurry, collect, IMEI)
(Advertiser, not_collect, Dev
Info)
(Advertiser, collect, IMEI)
(Flurry, not_collect, Dev Info)
(Flurry, collect, Dev Info)
(Flurry, not_collect, Track Info)
(Flurry, collect, Dev Info)
(Advertiser, not_collect, Track
Info)
(Advertiser, collect, Dev Info)
(Flurry, not_collect, Track Info)
(Analytic, collect, IMEI)
(Advertiser, not_collect, IMEI)
(Analytic, collect, IMEI)
(Advertiser, not_collect, Dev
Info)
(Analytic, collect, Dev Info)
(Advertiser, not_collect, IMEI)
(Analytic, collect, Dev Info)
(Advertiser, not_collect, Track
Info)
∗P = {(ei,collect,dk), (e j,not_collect,dl)}, f = (Flurry,IMEI)
ei (cid:65)ε e j ∧ dk (cid:64)δ dl
ei ≡ε e j ∧ dk ≈δ dl
ei (cid:64)ε e j ∧ dk ≈δ dl
ei (cid:65)ε e j ∧ dk ≈δ dl
ei ≈ε e j ∧ dk ≡δ dl
ei ≈ε e j ∧ dk (cid:64)δ dl
ei ≈ε e j ∧ dk (cid:65)δ dl
ei ≈ε e j ∧ dk ≈δ dl
C6
C7
C8
C9
C5
C10