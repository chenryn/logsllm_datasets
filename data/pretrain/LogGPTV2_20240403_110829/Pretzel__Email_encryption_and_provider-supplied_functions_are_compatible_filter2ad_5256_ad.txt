case). Then, the output of a dot product computation—assuming a
sum of L products, each formed from a bin-bit element and a fin-bit
element—has b = log L + bin + fin bits (in our context, L would be
the number of features extracted from an email). This means that
there is “room” to pack p = ⌊G/b⌋ elements into a single ciphertext.
Cost savings. Here we give rough estimates of the effect of the re-
finements in this subsection and the previous; a more detailed eval-
uation is in Section 6. For the spam filtering module, the provider’s
cpu drops by 5× and the client-side storage drops by 7×, relative to
the baseline (§3.3). However, cpu at the client increases by 10× (ow-
ing to the cyclic shifts), and the network overhead increases by 5.4×;
despite these increases, both costs are not exorbitant in absolute
terms, and we view them as tolerable (§6.1, §6.2). The provider-side
costs for spam filtering are comparable to an arrangement where
the provider classifies plaintext emails non-privately.
For the topic extraction module, the cost improvements relative
to the baseline (§3.3) are smaller: provider cpu drops by 1.37×,
client cpu drops by 3.25×, storage goes up by a factor of 2, and
the network cost goes up slightly. Beyond that, the non-private
version of this function is vastly cheaper than for spam, to the point
that the private version is (depending on the resource) up to two
orders of magnitude worse than the non-private version. The next
subsection addresses this.
4.3 Pruning in topic extraction
Decomposed classification. So far, many of the costs are propor-
tional to B: cpu and network cost of Yao (Figure 2, step 4), and
storage (Figure 2, “setup phase”). For spam filtering, this is not a
problem (B = 2) but for topic extraction, B can be in the thousands.
Pretzel’s response is a technique that we call decomposed classifi-
cation. To explain the idea, we regard topic extraction as abstractly
mapping an email, together with a set S of cardinality B (all possible
topics), down to a set S∗ of cardinality 1 (the chosen topic), using a
model with proprietary parameters. Pretzel decomposes this map
into two:
(i) Map the email, together with the set S, to a set S′ of cardinality
B′ (for example, B′ = 20); S′ comprises candidate topics. The
client does this by itself.
(ii) Map the email, together with S′, down to a set S′′ of cardinality
1; ideally S′′ is the same as S∗ (otherwise, accuracy is sacrificed).
pv1v2vpp< pv(B-1)vBSIGCOMM ’17, August 21-25, 2017, Los Angeles, CA, USA
T. Gupta et al.
Pretzel’s protocol for proprietary topic extraction, based on candidate topics
• The protocol has two parties. Party X begins with a matrix ⃗v1, . . . , ⃗vB. Party Y begins with a vector ⃗x = (x1, . . . , xN ) and a list S′ of B′ < B
column indexes, where each index is between 1 and B; S′ indicates a subset of the columns of matrix ⃗v. The protocol constructs a vector
from the product of ⃗x and the submatrix of ⃗v given by S′, and outputs the column index (in ⃗v) that corresponds to the maximum element in
the vector-submatrix product; neither party’s input is revealed to the other.
• The protocol has two phases: setup and computation. The setup phase is as described in Figure 2 but with the addition of packing from §4.2.
(3) Party Y does the following:
Computation phase
(a) (compute dot products) As described in Figure 2, step 2a, and §4.2. At the end of the dot product computations, it gets a vector
of packed ciphertexts ⃗pcts = (Enc(pk, d1∥ . . . ∥dp), . . . , Enc(pk, . . . ∥dB∥ . . .)), where di is the dot product of ⃗x and the i-th matrix
column ⃗vi, and p is the number of b-bit positions in a packed ciphertext (§4.2).
(b) (separate out dot products for the columns in S′ from the rest) For each entry in S′, i.e., S′[j], makes a copy of the packed ciphertext
containing dS′[j], and shifts dS′[j] to the left-most b-bit position in that ciphertext. Because each ciphertext holds p elements,
the separation works by using the quotient and remainder of S′[j], when divided by p, to identify, respectively, the relevant
packed ciphertext and position within it. That is, for 1 ≤ j ≤ B′, computes ciphertext Enc(pk, dS′[j]∥ . . .) = ⃗pcts[Qj] · 2b·Rj, where
Qj = ⌈S′[j]/p⌉ − 1, and Rj = (S′[j]− 1) mod p. The shifting relies on the multiply-by-constant homomorphic operation (see Figure 2
and §4.2).
(c) (blinding) Blinds dS′[j] using the technique described in Figure 2, step 2b, but extended to packed ciphertexts. Sends the B′ ciphertexts
(4) Party X applies Dec on the B′ ciphertexts, followed by bitwise right shift on the resulting plaintexts, to get dS′[1] + n1, . . . , dS′[B′] + nB′.
(5) The two parties engage in Yao’s 2PC. Party Y supplies S′ and {nj} for 1 ≤ j ≤ B′; Party X supplies {(dS′[j] + nj )} for 1 ≤ j ≤ B′; and, the
(Enc(pk, dS′[1] + n1∥ . . .), . . . , Enc(pk, dS′[B′] + nB′∥ . . .)) to Party X. Here, nj is the added noise.
parties use a function f that subtracts nj from dS′[j] + nj, and computes and returns S′[argmaxj dS′[j]] to Party X.
Figure 5: Protocol for proprietary topic extraction, based on candidate topics (this instantiates step (ii) in Section 4.3). The provider is Party
X; the client is Party Y. This protocol builds on the protocol presented in §3.3–§4.2.
4.4 Robustness to misbehaving parties
Pretzel aims to provide the following guarantees, even when parties
deviate from the protocol:
(1) The client and provider cannot (directly) observe each other’s
inputs nor any intermediate state in the computation.
(2) The client learns at most 1 bit of output each time spam classifi-
cation is invoked.
(3) The provider learns at most log B bits of output per email. This
comes from topic extraction.
Guarantee (1) follows from the baseline protocol, which includes
mechanisms that thwart the attempted subversion of the proto-
col (§3.3). Guarantee (2) follows from Guarantee (1) and the fact
that the client is the party who gets the spam classification output.
Guarantee (3) follows similarly, provided that the client feeds each
email into the protocol at most once; we discuss this requirement
shortly.
Before continuing, we note that the two applications are asym-
metric. In spam classification, the client, who gets the output, could
conceivably try to learn the provider’s model; however, the provider
does not directly learn anything about the client’s email. With topic
extraction, the roles are reversed. Because the output is obtained by
the provider, what is potentially at risk is the privacy of the email
of the client, who instead has no access to the provider’s model.
Leakage. Despite its guarantees about the number of output bits,
Pretzel has nothing to say about the meaning of those bits. For ex-
ample, in topic extraction, an adversarial provider could construct
a tailored “model” to attack an email (or the emails of a particular
user), in which case the log B bits could yield important informa-
tion about the email. A client who is concerned about this issue
has several options, including opting out of topic extraction (and
presumably compensating the provider for service, since a key pur-
pose of topic extraction is ad display, which generates revenue). We
describe a more mischievous response below (in “Integrity”).
In the spam application, an adversarial client could construct
emails to try to infer model parameters, and then leak the model.
Such leakage would not only undermine the proprietary nature
of the model but also make it easier for spammers to bypass the
spam filter [29, 125]. A possible defense would be for the provider
to periodically revise the model (and maintain different versions).
Repetition and replay. An adversarial provider could conceiv-
ably replay a given email to a client k different times, each time
with a unique topic model. The provider would then get k log B
bits from the email, rather than log B. Our defense is simply for the
client to regard email transmission from each sender’s device as a
separate asynchronous—and lossy and duplicating—transmission
channel. Solutions to detecting duplicates over such channels are
well-understood: counters, windows, etc. Something to note is that,
for this defense to work, emails have to be signed, otherwise an
adversary can deny service by pretending to be a sender and spuri-
ously exhausting counters.
Integrity. Pretzel does not offer any guarantees about which func-
tion Yao actually computes. For topic extraction, the client could,
Pretzel: Email encryption and provider-supplied functions are compatible
SIGCOMM ’17, August 21-25, 2017, Los Angeles, CA, USA
rather than garbling argmax (§3.2), instead garble an arbitrary func-
tion. Similarly, a client could input bogus candidate topics in step
(ii) of decomposed classification (§4.3). In such cases, the afore-
mentioned guarantees continue to hold (no inputs are disclosed,
etc.), though of course this misbehavior interferes with the ultimate
functionality. Pretzel does not defend against this case, and in fact,
it could be considered a feature—it gives the client a passive way to
“opt out”, with plausible deniability (for example, the client could
garble a function that produces an arbitrary choice of index).
The analogous attack, for spam, is for the provider to garble a
function other than threshold comparison. This would undermine
the spam/nospam classification and would presumably be disincen-
tivized by the same forces incentivizing providers to supply spam
filtering as a service in the first place.
5 IMPLEMENTATION
Our prototype fully implements the design described in Section 4. In
addition, it includes an elementary keyword search module in which
the client maintains and queries a client-side search index. The mod-
ules, written in 5,300 lines of C++ and 160 lines of Python, glue the
code we borrow from existing libraries: GPGME [9] for OpenPGP
encryption, Obliv-C [137] for Yao’s 2PC protocol,5 XPIR [20] for
the xpir-bv AHE scheme, liblinear [24, 57] to train LR and SVM
classifiers, and SQLite FTS4 [10] for the search index.
6 EVALUATION
Our evaluation answers the following questions:
(1) What are the provider- and client-side overheads of Pretzel?
For what configurations (model size, email size, etc.) are they
low?
(2) How much do Pretzel’s optimizations (§4) help in reducing
the overheads?
(3) How accurate are Pretzel’s functions: how accurately can they
filter spam emails or extract topics of emails?
A summary of evaluation results is as follows:
• Pretzel’s provider-side cpu consumption for spam filtering and
topic extraction is, respectively, 0.65 and 1.03–1.78× of a non-
private arrangement, and, respectively, 0.17× and 0.01–0.02× of
its baseline (§3.3). (One of the reasons that provider-side cpu
consumption is low—and sometimes lower than in a non-private
arrangement—is that the protocols shift work to the client.)
• Network transfers in Pretzel are 2.7–5.4× of a non-private ar-
rangement, and 0.024–0.048× of its baseline (§3.3).
• Pretzel’s client-side cpu consumption is less than 1s per email,
and storage space use is a few hundred MBs. These are a few
factors lower than in the baseline (§3.3).
• For topic extraction, the potential coarsening effects of Pretzel’s
classifiers (§4.3) are a drop in accuracy of between 1–3%.
Method and setup. We consider spam filtering, topic extraction,
and keyword search separately.
5Another choice would have been TinyGarble [114]. We found the performance of
Obliv-C and TinyGarble to be comparable for the functions we compute inside Yao in
Pretzel; we choose the former because it is easier to integrate with Pretzel’s C++ code.
For spam filtering and topic extraction, we compare Pretzel to its
starting baseline, which we call Baseline (this baseline is described
in detail in Section 3.3 and Figure 2), and NoPriv, which models
the status quo, in which the provider locally runs classification
on plaintext email contents. For the keyword search function, we
consider only the basic client-side search index based scheme (§5).
We vary the following parameters: number of features (N) and
categories (B) in the classification models, number of features in
an email (L), and the number of candidate topics (B′) in topic ex-
traction. For the classification models, we use synthetic datasets
for measuring resource overheads, and real-world datasets for mea-
suring accuracies. To generate synthetic emails, we use random
words (between 4 to 12 letters each), and consider each word as one
feature. For real-world data, we use the Ling-spam [22] (481 spam
and 2,411 non-spam emails), Enron [11] (17,148 spam and 16,555
non-spam emails of about 150 Enron employees), and Gmail (355
spam and 600 non-spam emails received by one of the authors over
a period of one month) datasets for spam filtering evaluation, and
the 20 Newsgroup [12] (18,846 Usenet posts on 20 topics), Reuters-
21578 [13] (12,603 newswire stories on 90 topics), and RCV1 [85]
(806,778 newswire stories from 296 regions) datasets for topic ex-
traction evaluation. To extract features from the documents in
real-world datasets, we use the feature extraction algorithms from
SpamBayes [4] and scikit-learn [6].
We measure resource overheads in terms of provider- and client-
side cpu times to process an email, network transfers between
provider and client, and the storage space used at a client. The
resource overheads are independent of the classification algorithm
(NB, LR, SVM), so we present them once; the accuracies depend
on the classification algorithm, so we present them for each algo-
rithm. To measure accuracies for spam classification, we use 10-fold
cross validation experiments [35]; for topic extraction, we train a
model on the training part of the datasets, and then apply it to the
documents in the testing part.
Our testbed is Amazon EC2. We use one m3.2xlarge machine for
the provider and one machine of the same type for a client. At the
provider, we use an independent cpu for each function module (§2.2).
Similarly, the client uses a single cpu.
Microbenchmarks. Figure 6 shows the cpu and network costs
for the common operations (Figure 3) in Pretzel and the baselines.
We will use these microbenchmarks to explain the performance
evaluation in the next subsections.
6.1 Spam filtering
This subsection reports the resource overheads (provider- and client-
side cpu time, network transfers, and client-side storage space use)
and accuracy of spam filtering in Pretzel.
We set three different values for the number of features in the
spam classification model: N = {200K, 1M, 5M}. These values corre-
spond to the typical number of features in various deployments of
Bayesian spam filtering software [15–17]. We also vary the number
of features in an email (L = {200, 1000, 5000}); these values are
chosen based on the Ling-spam dataset (average of 377 and a max-
imum of 3638 features per email) and the Gmail dataset (average
of 692 and a maximum of 5215 features per email). The number of
categories B is two: spam and non-spam.
SIGCOMM ’17, August 21-25, 2017, Los Angeles, CA, USA
encryption
1.7 ms
2.5 ms
103 µs
decryption
1.3 ms
0.7 ms
31 µs
addition