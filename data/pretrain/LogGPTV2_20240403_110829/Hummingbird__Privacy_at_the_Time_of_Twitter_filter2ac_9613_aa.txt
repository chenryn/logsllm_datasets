title:Hummingbird: Privacy at the Time of Twitter
author:Emiliano De Cristofaro and
Claudio Soriente and
Gene Tsudik and
Andrew Williams
2012 IEEE Symposium on Security and Privacy
Hummingbird: Privacy at the time of Twitter
Emiliano De Cristofaro∗
PARC
PI:EMAIL
Claudio Soriente†
ETH Zurich
Gene Tsudik
UC Irvine
Andrew Williams‡
UC Irvine
PI:EMAIL
PI:EMAIL
PI:EMAIL
Abstract—In the last several years, micro-blogging Online
Social Networks (OSNs), such as Twitter, have taken the world
by storm, now boasting over 100 million subscribers. As an
unparalleled stage for an enormous audience, they offer fast
and reliable centralized diffusion of pithy tweets to great mul-
titudes of information-hungry and always-connected followers.
At the same time, this information gathering and dissemination
paradigm prompts some important privacy concerns about
relationships between tweeters, followers and interests of the
latter. In this paper, we assess privacy in today’s Twitter-like
OSNs and describe an architecture and a trial implementation
of a privacy-preserving service called Hummingbird. It is
essentially a variant of Twitter that protects tweet contents,
hashtags and follower interests from the (potentially) prying
eyes of the centralized server. We argue that, although in-
herently limited by Twitter’s mission of scalable information-
sharing, this degree of privacy is valuable. We demonstrate, via
a working prototype, that Hummingbird’s additional costs are
tolerably low. We also sketch out some viable enhancements
that might offer better privacy in the long term.
I. INTRODUCTION
Online Social Networks (OSNs) offer multitudes of peo-
ple a means to communicate, share interests, and update
others about their current activities. Social networking ser-
vices are progressively replacing more “traditional” one-
to-one communication systems, such as email and instant
messaging. Alas, as their proliferation increases, so do
privacy concerns with regard to the amount and sensitivity
of disseminated information.
Popular OSNs, such as Facebook, Twitter, Google+, pro-
vide users with customizable “privacy settings”, i.e., users
can specify other users (or groups) that can access their
content. Information is often classiﬁed by categories, e.g.,
personal, text post, photo or video. For each category, the
account owner can deﬁne a coarse-grained access control list
(ACL). This strategy relies on the trustworthiness of OSN
providers and on users appropriately controlling access to
their data. Therefore, users need to trust the service not
only to enforce their ACLs, but also to store and manage
all accumulated content.
∗Work done in part at UC Irvine.
†Work done in part at Universidad Polit´ecnica de Madrid, with funding
from Spanish Research Council (MICCIN) under project TIN2010-19077,
Madrid Research Foundation (CAM) under project S2009/TIC-1692 (co-
funded by ERDF & ESF), Juan de la Cierva Fellowship ref. JCI-2010-
06161, and European Commission under project MASSIF (FP7-257475).
‡Supported by NSF Scholarship-for-Service (SFS) grant DUE-0723955.
OSN providers are generally incentivized to safeguard
users’ content, since doing otherwise might tarnish their
reputation and/or result
in legal actions. However, user
agreements often include clauses that let providers mine
user content, e.g., deliver targeted advertising [36] or re-sell
information to third-party services. For instance, Facebook’s
terms of use classify all user contents as “public” by default,
raising privacy concerns in the U.S. Federal Trade Commis-
sion [25]. Furthermore, content stored at an OSN provider
is subject to potential break-ins [24], insider attacks [37], or
subpoenas by law enforcement agencies [30] (e.g., during
the WikiLeaks investigation [39]). Moreover, privacy risks
are exacerbated by the common practice of caching content
and storing it off-line (e.g., on tape backups), even after users
explicitly delete it. Thus, the threat to user privacy becomes
permanent.
Therefore, it appears that a more effective (or at least
an alternative) way of addressing privacy in OSNs is by
delegating control over content to its owners, i.e., the end-
users. Towards this goal, the security research community
has already proposed several approaches [8, 31, 38] that
allow users to explicitly authorize “friends” to access their
data, while hiding content from the provider and other
unauthorized entities.
it
However, the meaning of relationship, or afﬁnity, among
users differs across OSNs. In some,
is not based on
any real-life trust. For example, micro-blogging OSNs, such
as Twitter and Tumblr, are based on (short) information
exchanges among users who might have no common history,
no mutual friends and possibly do not trust each other. In
such settings, a user publishes content labeled with some
“tags” that help others search and retrieve content of interest.
Furthermore, privacy in micro-blogging OSNs is not lim-
ited to content. It also applies to potentially sensitive infor-
mation that users (subscribers or followers) disclose through
searches and interests. Speciﬁcally, tags used to label and
retrieve content might leak personal habits, political views,
or even health conditions. This is particularly worrisome
considering that authorities are increasingly monitoring and
subpoenaing social network content [20]. We therefore claim
that privacy mechanisms for micro-blogging OSNs, such
as Twitter, should be designed differently from personal
afﬁnity-based OSNs, such as Facebook.
© 2012, Emiliano De Cristofaro. Under license to IEEE.
DOI 10.1109/SP.2012.26
285
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:50:17 UTC from IEEE Xplore.  Restrictions apply. 
A. Motivation
Twitter is clearly the most popular micro-blogging OSN
today. It lets users share short messages (tweets) with their
“followers” and enables enhanced content search based on
keywords (referred to as hashtags) embedded in tweets.
Over time, Twitter has become more than just a popular
micro-blogging service. Its pervasiveness makes it a per-
fect means of reaching large numbers of people through
their always-on mobile devices. Twitter is also the primary
source of information for untold millions who obtain their
news, favorite blog posts or security announcements via
140-character tweets. Twitter is used by entities as varied
as individuals, news media outlets, government agencies,
NGOs, politicians, political parties/movements as well as
commercial organizations of all shapes and sizes. As such,
it is an appealing all-around source for information-addicted
and attention-deﬁcit-afﬂicted segment of the population.
including:
Users implicitly trust Twitter to store and manage their
content,
tweets, searches, and interests. Thus,
Twitter is in possession of complex and valuable infor-
mation, such as tweeter-follower relationships and hashtag
frequencies. As mentioned above, this prompts privacy con-
cerns. User interests and trends expressed by the “Follow”
button represent sensitive information. For example, looking
for tweets with a hashtag #TeaParty, (rather than, say,
#BeerParty), might expose one’s political views. A search
for #HIVcure might reveal one’s medical condition and
could be correlated with the same user’s other activity, e.g.,
repeated appearances (obtained from a geolocation service,
such as Google Latitude) of the user’s smartphone next to a
hospital.
Based on its enormous popularity, Twitter has clearly
succeeded in its main goal of providing a ubiquitous real-
time push-based information sharing platform. However, we
believe that it is time to re-examine whether it is reasonable
to trust Twitter to store and manage content (tweets) or
search criteria, as well as enforce user ACLs.
B. Contributions
This paper proposes Hummingbird: a privacy-enhanced
variant of Twitter. Hummingbird retains key features of
Twitter while adding several privacy-sensitive ingredients.
Its goal is two-fold:
1) Private ﬁne-grained authorization of
followers: a
tweeter encrypts a tweet and chooses who can access
it, e.g., by deﬁning an ACL based on tweet content.
2) Privacy for followers: they subscribe to arbitrary hash-
tags without leaking their interests to any entity. That
is, Alice can follow all #OccupyWS tweets from the
New York Times (NYT) such that neither Twitter nor
NYT learns her interests.
Hummingbird can be viewed as a system composed of
several cryptographic protocols that allow users to tweet
286
and follow others’ tweets with privacy. We acknowledge,
from the outset, that privacy features advocated in this paper
would affect today’s business model of a micro-blogging
OSN. Since, in Hummingbird, the provider does not learn
tweet contents, current revenue strategies (e.g.,
targeted
advertising) would become difﬁcult to realize. Consequently,
it would be both useful and interesting to explore economical
incentives of providing privacy-friendly services (not just
in the context of micro-blogging OSNs) over the Internet.
However, this topic is beyond the scope of this paper.
To demonstrate Hummingbird’s practicality (ease of use
and performance overhead), we implemented it as a web
site on the server side. On the user side, a Firefox extension
is employed to access the server, by making cryptographic
operations transparent to the user. Hummingbird imposes
minimal overhead on users and virtually no extra overhead
on the server; the latter simply matches tweets to corre-
sponding followers.
Organization: The rest of this paper is structured as fol-
lows: Section II overviews Twitter and a few cryptographic
building blocks used to construct Hummingbird. Section
III describes our privacy model, while Section IV details
Hummingbird architecture and its protocols. Prototype im-
plementation is described in Section VI. Next, Section VII
discusses privacy features of Hummingbird and considers
several extensions. Finally, Section VIII surveys related work
and the paper concludes in Section IX.
II. PRELIMINARIES
This section provides Twitter background and describes
some cryptographic building blocks.
A. Twitter
As the most popular micro-blogging OSN, Twitter (http:
//www.twitter.com) boasts 100 million active users world-
wide, including: reporters, artists, public ﬁgures, government
agencies, NGOs and commercial entities [46]. Its users com-
municate via 140-character messages, called tweets, using a
simple web interface. Posting messages is called tweeting.
Users may subscribe to other users’ tweets; this practice is
known as following. Basic Twitter terminology includes:
• A user who posts a tweet is a tweeter.
• A user who follows others’ tweets is a follower.
• The centralized entity that maintains proﬁles and
matches tweets to followers is simply Twitter.
Tweets are labeled and retrieved (searched) using hashtags,
i.e., strings preﬁxed by a “#” sign. For example, a tweet:
“I don’t care about #privacy on #Twitter” would match
any search for hashtags “#privacy” or “#Twitter”. An “@”
followed by a user-name is utilized for mentioning, or
replying to, other users. Finally, a tweet can be re-published
by other users, and shared with one’s own followers, via the
so-called re-tweet feature.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:50:17 UTC from IEEE Xplore.  Restrictions apply. 
Tweets are public by default: any registered user can see
(and search) others’ public tweets. These are also indexed by
third party services – such as Google – and can be accessed
by application developers through a dedicated streaming
API. All public tweets are also posted on a public website
(http://twitter.com/public timeline), that keeps the tweeting
“timeline” and shows twenty most recent messages.
Tweeters can restrict availability of their tweets by making
them “private” – accessible only to authorized followers
[4]. Tweeters can also revoke such authorizations, using
(and trusting) Twitter’s block feature. Nonetheless, whether
a tweet is public or private, Twitter collects all of them
and forwards them to intended recipients. Thus, Twitter
has access to all information within the system, including:
tweets, hashtags, searches, and relationships between tweet-
ers and their followers. Although this practice facilitates
dissemination, availability, and mining of tweets, it also
intensiﬁes privacy concerns stemming from exposure of
information.
B. Cryptography Background
We now overview some cryptographic concepts and tools
used in the rest of the paper. For ease of exposition, we omit
basic notions and refer to [27, 42] for details on various
cryptographic primitives, such as hash functions, number-
theoretic assumptions as well as encryption and signature
schemes.
Basic Notation. A function F(τ) is negligible in the
security parameter τ if, for every polynomial p, F(τ) <
1/|p(t)| for large enough t. Throughout the paper, we use
semantically secure symmetric encryption and assume the
key space to be τ1-bit strings, where τ1 is a (polynomial)
function of the security parameter τ. Enck(·) and Deck(·)
denote symmetric-key encryption and decryption under key
k, respectively. Finally, a ←R A means that variable a is
chosen uniformly, at random from set A.
Oblivious PseudoRandom Functions (OPRFs). Infor-
mally, a pseudorandom function (PRF) family is a collection
of efﬁciently computable functions such that no efﬁcient
algorithm, under some computational assumption, can dis-
tinguish, with non-negligible advantage, between a function
chosen randomly from this family and one with truly random
outputs. A PRF f is a function that takes two inputs: a
variable x and a secret function index s, and outputs fs(x).
An Oblivious PRF (OPRF) is a two-party protocol, between
sender and receiver, that securely computes fs(x) on secret
index s contributed by sender and input x – by the receiver,
such that the former learns nothing from the interaction, and
the latter only learns fs(x). OPRFs have been introduced by
Freedman, et al. [26], based on Naor-Reingold PRF [44].
Several OPRF constructions have been suggested since,
e.g., [9, 34] based on Boneh-Boyen PRF [12].
Blind RSA Signatures. A blind signature scheme allows
one to sign a message such that its content is disguised
(blinded) before being signed. The resulting signature can
be publicly veriﬁed against the original blinded message.
Knowledge of the blinding factor allows one to unblind a
blind signature and obtain a (message, signature) pair that
cannot be correlated to its original (blinded) counterpart.
There have been many interesting research results in the
context of blind signatures involving various constructions,
security models, assumptions, and computational settings.
(See [47] for more details.) In this paper, we focus on RSA
Blind Signatures introduced in [16]. Blind RSA Signature
Scheme (Blind-RSA) involves a signer (S), a receiver, (R)
and the following algorithms:
• Key-Gen(1τ ): On input of the security parameter τ,
S generates a safe RSA modulus N = pq, where p
and q are random distinct τ2-bit primes, (with τ2 as
a polynomial function of τ), such that p = 2p(cid:3) + 1
and q = 2q(cid:3) + 1 for distinct primes p(cid:3), q(cid:3). Next, a
random positive integer e < φ(N) is selected such
that gcd(e, φ(N)) = 1. Also, d is generated such that
ed = 1 modφ(N ). Finally, a Full Domain Hash (FDH)
function H : {0, 1}∗ → ZN is selected. The output
consists of the RSA public/private keypair ((N, e), d)
as well as H(·).
• Blind-Sign(d, x): Given public input (H(·), N, e), S
and R interact on private input d and x, respectively.
is as follows: R sends μ = H(x) ·
The protocol
re mod N (for r ←R ZN ) to S,
that sends back
μ(cid:3) = μd mod N. Finally, R obtains σ = μ(cid:3)/r mod N.
is easy to see that σ is a valid RSA signature
It
on message x under private key d: σ = μd/r =
H(x)dredr−1 = H(x)d mod N.
• Verify(σ, x): Signature σ is publicly veriﬁed, by check-
ing that σe = H(x) mod N.
Blind-RSA based OPRFs. Blind RSA signatures can
be used, in the Random Oracle Model (ROM), to realize
an OPRF. The actual function is deﬁned as fd(x) =
H(cid:3)(H(x)d), where H(·) and H(cid:3)(·) are modeled as random
oracles. The OPRF protocol is simply the Blind-RSA proto-
col presented above, with d contributed by sender, and x –
by receiver. Using this protocol, the function remains a PRF
under the One-More-RSA assumption [10], even if receiver
is malicious, as recently shown in [18].
Blind-DH based OPRFs. In ROM, OPRFs can also be
instantiated using a Blind Difﬁe-Hellman protocol. This con-
struction, presented in [35], relies on the function fs(x) =
H(cid:3)(H(x)s) where H(x) maps onto a group where the
Computational Difﬁe-Hellman problem is assumed to be
hard, and both H(·), H(cid:3)(·) are modeled as random oracles.
The protocol is similar to Blind-RSA, but is secure under
the One-More-DH assumption [10]. It runs on public input
287
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:50:17 UTC from IEEE Xplore.  Restrictions apply. 
of two primes p, q (with q|p − 1). Receiver blinds its
input by sending μ = H(x)r mod p, with r ←R Zq.
Sender replies with μ(cid:3) = μs mod p and receiver obtains
fs(x) = H(cid:3)(H(x)s) by computing H(cid:3)((μ(cid:3))1/r mod p).
Blind-DH vs Blind-RSA. There are a few differences
between Blind-DH and Blind-RSA OPRFs. First, sender’s
computation in Blind-RSA is veriﬁable, as opposed to Blind-