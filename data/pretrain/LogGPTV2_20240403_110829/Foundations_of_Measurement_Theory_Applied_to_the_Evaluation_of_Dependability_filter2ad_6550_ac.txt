logical properties addressed in the previous sections. The
observations are based on an objective analysis of the con-
sidered works, and no attempt to numerically quantify mea-
surement properties on these works is done. We do not want
to question the results presented in the literature, but just
to show that underestimating or neglecting factors such as
uncertainty, intrusiveness, resolution and repeatability can
easily reduce the trust in the achieved measures or in the
developed measurement systems.
In the left part of Table 3 (columns Tool, Exp and Sys-
tem classiﬁcation) the works taken into consideration are
classiﬁed according to the criteria introduced in Section 3
related to the dimensions of systems. Note that the columns
tool and experiments are marked depending on whether the
main focus was the tool or the experiments performed (in
some cases, both).
The considered works cover some very different situa-
tions in which dependability measures have been collected.
Such difference stems either from the type of analysis per-
formed or from the kind of system under study. We analyze
fault-injection tools (e.g. [8], [13]) and experiments (e.g.
[20]), general prototyping frameworks (e.g. [15]), an exper-
iment in which a new total ordering protocol [24] has been
tested and, ﬁnally, an experiment in which a fail-aware sys-
tem is analyzed [23]. Such experiences cover a spectrum of
eight different systems typologies. Note that some works
belong to more than just one category of systems.
Let us now consider right part of Table 3 (columns Rel-
evant Properties and Awareness). In the column Relevant
Properties, the most relevant metrological properties that
should have been addressed, are singled out for each paper.
The Awareness part of the table reports marks related to the
measurement properties for which some concern (often with
quite good observations) has been shown. Due to the very
different, non-uniform, and often partial (or missing) ap-
proaches we have observed (even the name of the four mea-
surement properties are different from a work to another),
it has been actually difﬁcult to identify these elements in
the surveyed works. Therefore, in some cases the ticks in
the table are the result of our own interpretation and under-
standing. This does not necessarily mean that measurement
properties have been ignored by the related authors when
designing tools and experiments, but we just note that these
properties have often not been given the adequate emphasis.
Let us start analyzing uncertainty. Although a full con-
sciousness of all measurement properties is not achieved in
the surveyed tools, it is important to highlight that a quite
exhaustive analysis of measurement parameters is, in some
cases, performed. For example, in the software fault injec-
tion tool Loki ([13], [14]), a post-runtime analysis, using
off-line clock synchronization, is used to place injections
on a single global timeline and to determine whether the
intended faults were properly injected:
there is a signiﬁ-
cant attempt to evaluate the uncertainty of the time instant
at which faults were injected, even though it is not referred
to as uncertainty. Such a deep analysis is performed only
for timestamping fault injection. Although the approach to
uncertainty is quite informal, far from uncertainty as dealt
with by the GUM [5], this example denotes a signiﬁcant and
remarkable interest in quantitatively evaluating the disper-
sion of the values that can be reasonably attributed to the
measurand.
the shelf
(COTS) components.
Regarding experiment papers, uncertainty issues are
taken into account only in the experiments related to the
testing/development of FORTRESS ([23]). FORTRESS is
a support system for designing and implementing fault-
tolerant distributed real-time systems that use commer-
cial off
In the test
case performed, when measuring the one-way delay, the
FORTRESS fail-aware datagram service computes an up-
per bound ub(m) on the transmission delay td(m) of each
delivered message (obviously ub(m) > td(m)). Due to the
incapability of precisely estimating td(m), an upper bound
on the error ub(m)−td(m) is estimated as the difference be-
tween the computed upper bound and a known lower bound
for the message transmission delay δmin (the error is set to
ub(m) − δmin).
For the sake of completeness, it has to be highlighted that
for some time measurements, uncertainty can be not (very)
relevant. This can happen when the objective is to measure a
(sufﬁciently) long time interval. A few examples of such sit-
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 05:37:28 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007Table 3. Surveyed work classiﬁcation and metrological properties
DI
¬RT
CR
DI
RT
¬CR
DI
RT
CR
Relevant Properties
Awareness
Unc
Surveyed Work
XCEPTION [7]
GOOFI [8]
MAFALDA [9]
MAFALDA-RT [10]
MESSALINE [11]
FTAPE [12]
Loki [13] [14]
Neko/NekoStat [15] [16]
ORCHESTRA [17]
PFI Tool [18]
OS dependability
benchmark [19]
Impact Analysis
on Real-Time Sys [20]
Evaluating COTS [21]
Fault-Tolerant
Commercial Systems [22]
FORTRESS [23]
PLATO [24]
Tool
Exp
√
√
√ √
√ √
√ √
√ √
√ √
√ √
√ √
√ √
√
√
√
√
√
√
CE
¬RT
CR
√
√
√
CE
¬RT
√
¬CR
√
√
System classiﬁcation
DI
¬RT
¬CR
CE
RT
CR
CE
RT
¬CR
√ √
√ √
√
√
√
√
√
√
√
√
√
√
Res
Rep
√
√ √
Int
√
√
√
√
√
√
√
√ √ √
√
Unc
Int
Res
Rep
√ √ √
√ √ √ √
√ √ √ √
√ √ √ √
√ √ √ √
√ √
√ √
√ √
√ √ √
√ √
√ √ √
√ √ √ √
√ √ √ √
√ √
√ √
√
√ √ √ √ √ √
√
√
√
√
uations can be found in FTAPE [12] and in the experiment
presented in [19]. In the case study presented in FTAPE, a
fault injection tool, the execution time with/without faults is
measured. Such a time interval is greater than one thousand
seconds. In [19], a dependability benchmark for operating
systems is developed and tested on Windows 2000 OS. The
restart time of the operating system is measured.
It is a
quite long interval (dozen of seconds). Relative uncertainty
here is very small, and in cases like these the absence of
assumptions or concerns about uncertainty can therefore be
justiﬁed.
Regarding intrusiveness, we have observed that a large
subset of the surveyed tools show great consciousness of
how important it is to design a non-intrusive measuring in-
strument (Loki [13], ORCHESTRA [17], XCEPTION [7],
MAFALDA [9], MAFALDA-RT [10], FTAPE [12], GOOFI
[8] and PFI Tool [18]).
In Loki, awareness about intrusiveness is clear, and to be
as non-intrusive to the system as possible, the runtime does
not block the system while notiﬁcations about the system
state are in transit. A post-runtime check is made to cor-
rect possible problems due to non-compatible views of the
system state.
In ORCHESTRA, a fault injection tool for distributed
real-time systems, a deep analysis about intrusiveness is
performed. ORCHESTRA deals with real-time systems
with strict time requirements.
It is designed to explicitly
address the intrusiveness of fault injection on a target dis-
tributed system. This operation is performed by exploiting
operating system support to quantitatively assess the intru-
siveness of a fault injection experiment on the timing behav-
ior of the target system and to compensate for it whenever
possible.
In XCEPTION, a tool for software fault injection, an im-
portant attempt to evaluate tools characteristics using sys-
tem performance monitoring facilities is made.
In MAFALDA, a fault injection tool for safety critical
systems, the used fault injection technique is chosen with
awareness of problem of intrusiveness of the tool.
In MAFALDA-RT, a tool for fault-injection in real-time
systems (it is a completely new version of MAFALDA), the
authors focus on the problems of temporal intrusiveness.
The authors identify the main causes of intrusiveness in:
i) the time related to the injection of faults, and ii) the time
related to the observation of the system behavior.
In FTAPE, the authors recognize the problem of intru-
siveness of the fault injection component and of the work-
load monitoring component, and they try to estimate the
time overhead comparing the time the workload requires to
execute with and without the fault injection and monitoring
components.
In the fault injection Java tool GOOFI, it is recog-
thus
nized that logging is a time-consuming operation,
GOOFI makes available two different logging modes: a
detailed (time-consuming) mode and a normal (less time-
consuming) mode.
In [18], the fault injection tool PFI Tool (Probe/Fault In-
jection Tool) is presented. The authors recognize that their
approach can be more intrusive than others, but, despite
this awareness, a metrological characterization of the tool
is missing.
In the experiments we have been considering, the intru-
siveness of the measurement tool used is considered only
in [22]. In this experiment a dependability benchmark for
commercial systems is proposed and studied on TMR-based
prototype machines (using the FTAPE tool). The time over-
head of the fault injection tool used is accounted, even if
intrusiveness is not looked closely as in [12]. In most cases,
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 05:37:28 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007missing observations about intrusiveness of the measure-