User: How to write a simple web crawler program in Python? Please provide code skeleton and necessary libraries.
Assistant: In order to write a simple web crawler, you can use Python's Requests library and BeautifulSoup library. The following is a basic code framework that will use these libraries to extract all links of a website: ```python import requests from bs4 import BeautifulSoup #Define the website url to crawl = "http://example.com" # Send a request and get the page content response = requests.get(url) html = response.content # Parse the page content and get all the links soup = BeautifulSoup(html, "html.parser") links = [] for link in soup.find_all ("a"): link_url = link.get("href") if link_url is not None: links.append(link_url) # save the link to the file with open("links.txt", "w") as f: for link in links: f.write(link + "\n") ``` In this example, we first send a GET request to the website using the Requests library. We then use the BeautifulSoup library to parse the page content and extract all links from it. Finally, we save all links to a file for further analysis. Note that this is just a basic framework, and you can extend it to perform more complex tasks, such as crawling specific types of web content, or filtering links by specific rules.