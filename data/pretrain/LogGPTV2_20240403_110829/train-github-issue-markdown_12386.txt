I am seeing frequent deadlocks when running tasks simplified to the below. (I
purged out all the logging and a few database interactions to keep things
clear.) Calling the task that calls everything else usually runs ',api_context=context),rr.s()).delay()
    tasks.register(RefreshRecords)
    class ApiCall(BaseTask):
        def run(self, mode, **kwargs):
            self.api_context.key = API_KEY
            modeDict = {}
            try:
                url = modeDict[mode]
            except KeyError:
                logger.info("Keyerrors!")
            URL = url + '?' + urlencode(self.api_context.toUrlDict(mode))
            # Exception handling for the URL opening.
            try:
                pageaccess = urllib2.urlopen(URL, timeout=5)
            except urllib2.HTTPError, err:
                if err.code in [104, 111, 401, 403, 404, 500, 503]:
                    self.retry(mode=mode)
                else:
                    self.retry(mode=mode)
            except (BadStatusLine, urllib2.URLError, ssl.SSLError, socket.timeout) as err:
                self.retry(mode=mode)
            data = json.loads(pageaccess.read())
            data['api_context'] = self.api_context
            return data
    tasks.register(ApiCall)
    class RetrieveRecords(ApiFollower):
        """This is tricky.  The API lets you take slices of data, but you only know the indices to use in the call from the previously taken slices.  Further, to get actual information for the records in a slice, you need another API call.  Here we see if the previous call worked, spawn the detail calls as needed, and either hit the API again or finish up, depending on whether we wanted any more records."""
        def run(self, urldata):
            try:
                if self.result['status'] == 1:
                    self.spawnDetailCalls()
                    if self.moreResultsLeft():
                        self.rebound()
                    #Successful closeout
                    else:
                        logger.info("Cleaning up")
                        self.cleanup()
                    return True
                else:
                    logger.error("Unhandled status: "+str(self.result['status']))
                    return True
            except Exception, err:
                logger.error("ERROR!:{0}".format(err))
                return False
        def rebound(self):
            self.api_context.start_at_record_id = self.result['information'][-1]['id']
            ac = ApiCall()
            rr = RetrieveRecords()
            pass_context = deepcopy(self.api_context)
            chain(ac.s(mode='',api_context=pass_context), rr.s()).delay()
        def cleanup(self):
        def spawnDetailCalls(self):
            for result in self.result['information']:
                ac = ApiCall()
                ud = UploadData()
                self.api_context.record_id=result['record_id']
                self.api_context.processed+=1
                pass_context = deepcopy(self.api_context)
                chain(ac.s(mode='',api_context=pass_context), ud.s()).delay()
        def moreResultsLeft(self):
            if self.result['results_remaining'] == 0:
                return False
            elif self.api_context.processed >= self.api_context.records_desired:
                return False
            else:
                if self.api_context.deepcopy is False:
                    return self.api_context.last_scrape_time < self.result['information'][-1]['start_time']
                else:
                    return True
    tasks.register(RetrieveRecords)