简化操作是Envoy一个非常重要的设计目标。除了强大的统计和本地管理接口，Envoy还
本地服务到远端服务的出口 listener。该类型listener 会监听在某个指定的端口上，所有内部
上图展示了最简单的 Envoy 部署方式。在这种部署方式中 Envoy 承担的是SOA服务内部
这一块是大家关注的重点，也就是应用程序如何与 Envoy 结合来使用的、请求是如何转
应用出去的请求都重定向到该端口上，由该listener 处理并转发到目的服务集群节点。
--drain-time-s 配置项用来配置等待平滑退出的时间。如果平滑退出花费的时间超过了这
ServiceMesh数据面板Envoy简介－微服务
，Envoy有不同的部署方式。
初
---
## Page 42
的连接最终都会复用已经与数据中心完成连接建立的HTTP/2 连接。
TLS 握手时间，更快的TCP 拥塞窗口调整，更少的丢包等等）。这些在双代理上卸载TLS后
双代理模式
Service to service, front proxy, and double proxy
景
这种方式和 service to service 方式相比多出了 前端七层代理的部分。可以适配更多的使用场
该部署模式有以下特点：
上图展示了在 service to service 模式前增加 Envoy 集群作为7层反向代理的部署模式。
Service to service plus front proxy
·前端的 Envoy 代理集群使用标准的 ingress 端口与后端的 service to service 集群通信。对
·TLS 卸载
● Discovery service integration
● Optional external service egress listeners 
· Service to service ingress listener 
双代理模式的设计理念是：更加高效地卸载 TLS、更快速的与client 端建立连接（更短的
于后端服务集群节点使用服务发现方式获取。前端的 Envoy 集群节点是完全对等的提供服务
完整的 HTTP 7层路由支持
同时支持 HTTP/1.1 和 HTTP/2
集成外部服务发现组件来提供服务到服务的发现功能。
moDB。我们建议为所有外部服务使用本地端口路由，
有时，
听端口。根据需要，本地的Envoy会进行一些缓存、断路检查等处理。
例如：http://ocalhost:9211。
本地服务到远端服务的入口 listener。该 listener 提供远端 Envoy 调用本地 Envoy 的端口
路
本地 Services 只需要知道本地的Envoy，无需关心它们自己所处的网络拓扑及环境。
过程中会进行服务发现、负载均衡、
neader,
例如：http://ocalhost:9001 或tcp:/localhost:9001 。
没有任何差异。
持host header的重写来支持标准的HTTP反向代理行为。
需要访问外部的服务，
此时需要提供一
进入本地 Envoy的请求都被路由/重定向到本地 service 的监
限速等处理。
微服务－ServiceMesh数据面板Envoy简介
一个端口提供访问。因为，有些外部服务SDK不
，而不是使用主机路由和专用本地端口
HTTP 和 gRPC 类型请求使用 host
在数据流经Envoy
37
---
## Page 43
本文链接：https://opsdev.cn/post/envoy.html
语言的限制，从网络层面解决了这一难题，使得工具或者框架更通用。
Q：Envoy的价值体现在哪里呢？
熟，我们打算引入该技术。
A：目前Envoy我们还没有使用，当前正是出于调研阶段。后面，随着容器化平台的完善和微服务框架的成
Q：Envoy你们已经开始使用了吗？
面对面：
基本的Envoy 介绍这些，更深入的了解Envoy工作原理需要阅读其源码。
38ServiceMesh数据面板Envoy简介－微服务
口
扫查看文章详情
5
口
告
---
## Page 44
全身。
负责一个服务，快速迭代与滚动更新上线。而不像单体应用，一般上线与迭代总是牵一发而动
个项目的接入。同时就提高了该项目的容错性。整体项目的开发进度都能以服务为维度，各自
态的根据流量扩容和缩容。
的rpc多服务运维经验，那就可以拆微服务，拆完之后，服务的水平扩展一般是线性的，可以动
开发者都对微服务有一定的经验，并且底层rpc，连接池等初始化库都有积累，然后有比较丰富
务拆成四五个微服务，然后增加自己的运维成本和实现成本。
来就是个没有并发的对内系统，那就完全没必要拆成微服务，就写个单体的，把接入层，数据
为了人多每人分点活，而故意拆成微服务。总之不能为了微服务而微服务。
项目的运维敏感度，项目的紧急程度，开发人员的技术熟练程度，微服务架构的基础储备程度
我的理解
单体项目的优缺点。
谓的微服务，再结合以前的一些单体项目的开发经验，这里主要探讨一下我所理解的微服务和
■微服务拆分那点事
等等。
背景
最近参与了两个项目的开发，两个项目都有多组件，各自服务功能清晰等特点，也就是所
其实所谓这些服务的拆分与否都是与很多因素有关系，比如：该项目的开发人员数目，该
| Mar. 19th 2018 BY 王保平 
底层其他非接入层的服务，
如果该项目是多人协作的，有一定的并发度，对用户接入比较敏感，不能随便重启，并且
比如该项目总工就一个人开发，然后该项目你重启一下服务，对用户接入没啥敏感性，本
因为我们的最终目的是将项目快速完整的实现好，而不是为了显得逼格高而微服务，不是
比如数据处理服务，Session服务的重启与上线都不会影响整
fig1 Microservice Architecture
微服务－微服务拆分那点事
39
---
## Page 45
别的用户系统和boss系统等等。
备上报的信息计算分配换算成工作量，然后按工作量百分比分配相应的积分。
项目背景
两天刚做的一个共享积分项目。
我怎么拆分
我的对比
40
该项目主要工作两部分，
接下来根据一个具体的项目实例，看看如何将一个单体项目，拆分成微服务。该项目是前
所以整体从以下几个维度，我来对比一下优缺点。
微服务拆分那点事－微服务
积分设备
boss系统
用户系统
美誉度
适合业务场景
运维复杂度
组件重启
水平扩展
功能职责
开发进度
技术复杂度
开发人数
http
上报
center组件
一部分，积分设备上报信息给服务端。第二部分：服务端根据设
听着高大上
高并发，大流量
较高
不影响其他组件 
很方便，直接改配置堆机器
组件拆分明确 
分工协作较快，单组件快速迭代
较高
较多
微服务
fig2 Project Architecture
rpci清求
pci请求
finance组件
collector组件
没啥波动
没并发，对内系统居多
简单
牵一发动全身
不支持
较模糊
一般，互相等待
一般
较少
单体
事务性
同时该项目对接
大量
Mongo
Redis
Mysol
---
## Page 46
些不同。rpc等连接池代码基本都是能复用的，其他的公共库，直接拖到新项目里就能开搞。
期我们会先把这些公共库的初始化工作都做了，比如DB的一些连接池初始化不同项目稍微有一
用户自己基于go自带的rpc的二次封装等。还有trace等用于追踪请求方便日志查询的基本库。
redis，mongo，mysql等db的连接池初始化，还有rpc的连接池初始化，这里或者用grpc或者
第二步：公共库的初始化
处理所有的APl请求。所以单独起一个center组件。
统。职责也很明确。
币额度。这其实是一个类似经济系统的职责，
个职责就很明确了。
集数据，这里抽象了各种数据来源，比如把矿机和其他业务数据接口都统一到collect模块。这
额
是一样的。比如该项目，矿机在不断地上报数据，然后我们通过上报的带宽给矿机分配虚拟币
第一步：根据服务职责拆分
是非常高的。
是依赖公共库。互相之间的调用都是通过rpc，
测试。
如果拆成微服务，三人都有相关经验，一个礼拜肯定就可以保质保量的完成相应组件的开发与
个API目录处理接入请求就行了。外加一些util的公共组件。
目录：Src下，
发周期。
页度。这个其实细分其中的职责，我们可以看到我们需要一个收集上报数据的模块，只负责收
这些基础库是我们做微服务的必备，通常开始一个新项目，在前期需求讨论完后，编码前
我们把公共的库都放在common里面，这里面包括了log，config，errors等基础库，还有
这两个模块对外暴露各种API接口。这个可以抽出来，单独一个接入组件，负责对外统一
这个项目相对功能不复杂，所以拆分完，也就三个组件，职责已经比较明确了。
同时这些数据收集上来以后得集中运算，算完之后得通过内部分配算法，给矿机分配虚拟
其实微服务的拆分最根本是一些代码职责的拆分和抽象，这一步和我们模块化的时候思路
所以现在我们开始简单将这个单体应用拆成微服务。
因为微服务的每个组件其实都是一个独立的单体应用。组件之间的开发是没有关联的，都
但是前面也说了，单体应用有诸多的弊端。并且主要还剩两人，你一个人用两周的时间，
然后一个人开发就行了。两周的时间应该能调通。
一开始该项目其实因为复杂度不是太高，其实完全可以做成一个单体应用就行。
该项目总共三人：三人都参与过微服务的开发，有基础库的储备。
一个collector目录收集矿机上报，一个finance目录处理一些金融数据。再来一
，该系统只负责处理金融信息，是个finance经济系
，所以开发是可以并行开发。互不干扰。效率肯定
微服务－微服务拆分那点事
时间比较紧，一周的开
，比如项目
41
---
## Page 47
载等。单独抽出来都是挺有研究意义的。
的地方，比如公共库中一些db的连接池初始化和rpc的连接池初始化，配置的集中管理，动态加
本文也主要是聊聊拆分的时候一些我理解的原则，具体实现细节，其实微服务还有很多有意思
微服务的时候一些基本工程流程。如果项目比较复杂，可能拆分出来的组件数目就相对较多。
总结
基本的测试。然后等联调即可。
初始化完毕，然后开发就是完全并行了。编写完之后，自己的组件可以依靠单元测试，做一些
第四步：开始分工写自己的组件了
体的pb编写参考文档即可。
件，定义完接口以后，让自动生成pb.go即可，最后代码交互都是走的pb.go里面的结构体。具
系统需要从collect系统获取数据去统一运算。所以collect系统还需要给finance系统暴露rpc接
口
rpc 转到相应组件做单独处理。collect 系统和 finance 系统之间，是单向的数据流动，finance
求逻辑优先级，第一同机器，第二同机房，第三跨机房。
关。这里不做描述。接入层可以做很轻量的数据处理，不宜过重。不做有状态的数据存储。是
们三个组件 center，collector，finance三个组件
第三步：组件之间接口的定义
个无状态服务，最终的数据处理通过rpc传给后端相应的组件，基本是一个纯转发的组件。
42微服务拆分那点事－微服务
collect 和 finance组件都对center暴露了 grpc pb 接口，因为请求从center进来，会通过 
在配置文件中已经配好了，相应的组件的rpc地址，rpc公共库中我们二次封装了基本的请
 center是接入层，这里统一处理所以的APl请求。http或者https，具体APl接口是业务相
在初始化完公共库之后，我们先不着急写代码，先把组件之间的接口定义好。这里比如我
以上只是一个相对比较简单的项目拆分。这里也主要说的是一个拆分的思路，和具体实现
到此开始编写代码了。每个人都是相对独立的开发，因为接口定义好了，公共库也都已经
具体的 grpc pb 接口有自己的定义语言，比较简单容易上手，在相应的目录下新建proto文
---
## Page 48
本文链接：https:/lopsdev.cn/post/mymicroservices.html
gokeeper等，都是类似的。
同步配置，建立新连接和断掉旧连接。
机房机器，最后才选择跨机房等。并且在修改了rpc地址配置之后，不需要重启组件，底层rpc框架可以自适应
景中会很大程度上减少服务器压力。并且我们为了保证rpc连接的耗时，第一优先连接同宿主机，第二优先同
据业务请求并发提前初始化一个量级的连接池，保证后端db的读写压力。
发的项目有一点不同，比如平常项目的一些db操作都是读取数据的时候才建立连接，而微服务的一般都是根
A：本文是我在开发了两个微服务架构后的一些理解。因为项目本身有一些并发，所以项目的初始化和没有并
Q：你后面提到的一些有意思的研究点可否提前分享下？
补充一点不要为了拆分而拆分，要综合人力，时间，开发成本，业务场景，运维成本等多维度综合考虑。
A：文中提到，拆分还是应该关注服务职责足够明确，至于微服务的优缺点文章已经提过了，不在赘述，这里
Q：你认为微服务拆分最应该关注是么？
面对面：
微服务的配置一般都是集中管理，动态加载，这种我们部门内部的qconf，或者我们当前项目自己写的
同时rpc的也是同样连接池的概念，这样就少了很多的rpc建立连接和释放连接的网络消耗，这在高并发场
以上这些点可能在后续会有更进一步分享，敬请关注。
微服务－微服务拆分那点事43