0.79
0.75
2.90
1.12
1.67
1.45
3.06
2.28
5.10
1.34
5.33
Table 4: Comparison of PIKADROID and MaMaDroid [31] in accuracy, f-score, precision, recall, and false positive rating when being used at the same
time period. The training and testing data are from the same time periods. The cases where PIKADROID outperforms MaMaDroid are in bold.
6.1 Effectiveness
Our first goal is to evaluate how well PIKADROID can correctly
classify malware during the time periods when it was most preva-
lent. Our evaluation includes four datasets. Three datasets contain
benign and malware samples from the same time-periods: 2010-
2012, 2013-2015, 2016-2018. The first three datasets verify that
lightweight circumstantial awareness can accurately distinguish be-
tween samples that were popular in relatively the same time periods.
The final dataset, 2010-2018, contains malware that spans over eight
years. This dataset is used to verify that PIKADROID is capable of
learning a diverse set of malware samples. This is necessary because
the Android OS is heavily fragmented [46], and malware developers
may still use old malware samples to attack outdated devices.
The accuracy, precision, f-score, recall, and false positive rating
for each experiment are summarized in Table 4. We see that for each
dataset, PIKADROID is able to maintain a low false positive rate of
under 1.76% for all cases. For malware in the 2013-2015 dataset,
PIKADROID is able to maintain a false-positive rate of 0.44%. Main-
taining a low false positive rate (FPR) is very important for Android
malware detection systems because high FPRs result in more benign
samples being misclassified as malware samples. For each misclassi-
fied benign sample, a intensive manual process is required to verify
the legitimacy of the app. We see that PIKADROID is able to detect
97.02% of the samples in the 2010-2012 dataset. We also evaluated
PIKADROID on the larger dataset which contained samples from all
three time periods. We found that PIKADROID was able to detect
malware with an accuracy of 98.00% when trained with malicious
samples from different time periods.
6.2 Comparison with Prior Work
6.2.1 With AppContext. For modeling, AppContext [52] cre-
ates a contextual model of an app based on a variety of factors:
environmental-, activation-, and constraint-dependencies. We use
Ridge Regression [23] to rank the contextual factors by importance.
Performance wise, we find that the use of multiple types of contex-
tual information as AppContext does brings two challenges. First, the
capturing of these contextual behaviors is unlikely to scale to a real-
world environment. For example, we originally intended to classify
all 23,631 applications in our dataset using AppContext. However, it
imposes a size cap of 5 MB on the analyzed applications, with larger
apps requiring significant manual efforts to extract the contextual fea-
tures. In addition, we find that in many cases the analysis takes over
4 hours and consumes over 256 GB of physical memory. In compari-
son, PIKADROID’s static analysis is lightweight, and on average it
finishes the analysis in one minute per app (refer to §6.5 for detailed
performance evaluation). Unfortunately the lack of scalability related
to AppContext’s method prevented a side-by-side comparison. To
provide a comparison of PIKADROID and AppContext an extension
of the case study in §2.2 is provided. In the case-study provided in
§2.2, the entrypoints, activity, broadcastReceiver, service, and
UI, were among the highest ranked categories. The second highest
ranked category is behaviors related to NETWORK dependencies. We
summarize the comparison results in Table 1. Therefore, based on
this comparison, the model of PIKADROID using entrypoints pro-
vides a lightweight and scalable approach to malware detection by
avoiding non-informative contextual factors, which limits AppCon-
text’s scalability.
6.2.2 With MaMaDroid. Another current, state-of-the-art An-
droid Malware detection system is MamaDroid [31]. This system fo-
cuses on abstracting sequences of method and API calls found in an
app to build a Markov chain model which represents the probabilities
of transitioning between method/API calls. In an effort to minimize
features unique to a malware family or single app, MamaDroid ab-
stracts each method/APIs signature to its containing package name
and creates the transition model from the resulting set. For example,
android.view.KeyEvent would become android.view. This abstrac-
tion process is used to be resilient to the frequent changes in the
Android Platform and to prevent feature explosion. For comparison,
we use the open-sourced part of MaMaDroid [1] for its abstraction
and modeling, then implemented the classification portion, which is
not provided in its source code using a RandomForest Classifier [29],
as described in the original paper. We evaluate both systems on each
of our partitioned datasets as well as the combined dataset covering
eight years. A detailed comparison of PIKADROID and MaMaDroid
in terms of accuracy, precision, f-score, recall, and false positive
rating is given in Table 4. When comparing the results of the clas-
sification of malware and benign samples in the same time-period,
we verify that both PIKADROID and MaMaDroid are effective at
detecting Android malware. Overall, PIKADROID outperforms Ma-
MaDroid in every experiment in terms of f-scores. Even though, Ma-
MaDroid maintained lower false positive rate in 3/10 experiments,
PIKADROID maintained a slightly better detection rate in these tests.
These tests show that context-based, Android malware detection
systems can achieve the same high performance as abstraction-based
216ACSAC ’18, December 3-7, 2018, San Juan, PR, USA
Dataset
2010-2012
2013-2015
2016-2018
2010-2018
FP Ratio
FN Ratio
1.45x
3.02x
2.035x
2.36x
1.38x
1.24x
1.02x
1.29x
Table 5: The ratio of false positive and false-negatives of APIMiner
to PIKADROID. Column one shows the ratio of false-positives of
APIMiner to PIKADROID. Column two shows the ratio of false-
negatives of APIMiner to PIKADROID.
methods, and in some cases achieve higher detection rates while
still maintaining low false positive rates. We believe this shows that
both abstraction-based and lightweight circumstantial awareness ap-
proaches for malware detection can accurately detect malware when
the testing and training data are from the same time periods.
The starkest difference in these comparison tests is the classifica-
tion of grayware. Grayware creates new challenges for classification
because its behavior blurs the line between what is malicious and
what is benign. For the 2010-2015 dataset, PIKADROID detects
91.54% of grayware, but MaMaDroid only detects 79.97% of the
samples. We find that the discrepancy is due to MaMaDroid abstract-
ing method signatures to package names. This difference comes from
grayware’s reliance on inappropriate UI-driven event-handlers to
trigger advertising displays. For example, grayware samples would
register android.view.KeyEvent callbacks that display ads and ac-
cess sensitive device information. Since MaMaDroid relies on only
using the package name (android.view) instead of the full API
signature, it loses the necessary context, since it cannot see what
callback is used.
6.2.3 With DroidAPIMiner. To evaluate how meaningful the
contextual information obtained from conditioning the target API
call on its corresponding entrypoint is for malware detection, we
compare PIKADROID to prior works by implementing a frequency-
based approach like DroidAPIMiner [2], which we call APIMiner
for the remainder of the paper. Unlike PIKADROID, these systems do
not take into consideration the circumstances in which the sensitive
API are invoked. To evaluate how much improvement is obtained
from using our contextual awareness, we evaluated APIMiner on
each dataset discussed in §5. We provide a detailed report of the false
positive ratio and false negative ratio of APIMiner to PIKADROID
in Table 5. We see that by not leveraging the entrypoint, it can lead
to 3.02x times more false-positives.
In Table 5, we show the reduction of false-positives and false-
negatives PIKADROID receives when using the pairs of (entrypoint,
targetMethod) compared to using only the sensitive APIs alone.
For the 2010-2018 time period, PIKADROID reduces the false posi-
tives by 2.36x and the false negatives by 1.29x. This suggests that
PIKADROID’s lightweight circumstance-aware approach leads to a
significant reduction in false positives and false negatives.
6.2.4 Reducing False-positives. We provide an additional
case study that shows how lightweight circumstantial awareness al-
lows PIKADROID to detect behaviors that have malicious intent
that is undetectable when the APIs are considered alone. When
PIKADROID is configured to only use sensitive APIs, the malicious
Entrypoint (E)
Service.onStart
Service.onStart
BroadcastReceiver.
onReceive
Service.onCreate
Targeted API (T)
FileWriter.write
DataOutputStream.
writeBytes
Cursor.getString
TelephonyManager.
getDeviceID
J. Allen et. al
Risk Score (E,T) Risk Score (T)
3.06
18.71
2.59
11.05
1.20
0.256
1.46
0.401
Table 6: Comparison of risk scores using (entrypoint, targetMethod), or
(E,T) of PIKADROID and target-API-based system APIMiner for the
sample “e2caa60b08ea474f0812fabac0985a19”, which belongs to the
DroidKungfu [54] malware family. By having an outstanding risk score
using (E,T), PIKADROID detects this sample while APIMiner does not.
Time Period
Obfuscations
2010-2012
string encryption, package obfuscation,
class obfuscation, identifier mangling,
resource injection, permission injection,
bytecode transformations, method obfuscation
TPR%
92.5 %
Table 7: The obfuscations applied to bypass PIKADROID using AV-
Pass [27]. The first column represents the time period when the mali-
cious apps are found; the second column lists the obfuscations, and the
third column provides the True Positive Rating (TPR%).
sample with the md5sum “e2caa60b08ea474f0812fabac0985a19”,
from the DroidKungfu [54] malware family is not detected as mal-
ware. In Table 6, we show a subset of (entrypoint, targetMethod)
pairs that are present in this sample. The column Risk Score (T)
shows the risk-score of the sensitive targeted API, T , when the
targeted API is considered without being conditioned on the en-
trypoint. The risk score is a comparison of the number of benign
samples that use this particular API versus the number of malicious
samples which use this targeted API. For example, the sensitive
API DataOutputStream.writeBytes had a risk-score of 0.256. This
means it was only found in 0.256 of the malicious apps. Prior ap-
proaches like DroidAPIMiner would find this behavior uncommon
in malicious apps, and the sensitive API would be considered noise
and be filtered from the feature space [2]. Unfortunately, this ap-
proach leads to significant context loss which decreases detection
accuracy.
PIKADROID leverages lightweight circumstantial awareness to
create a risk score based on the sensitive API and a lightweight
representation of the contextual factors involved in the invocation
of this security sensitive method. The column Risk Score (E, T)
shows the risk-score of the sensitive, targeted API, T , when it was
invoked using the entrypoint E. For example, when the targeted
API DataOutputStream.writeBytes is invoked from the entrypoint
Service.onStart, it is 18.71x more likely to be from a malicious
app.
6.2.5 Drifting Scenarios. To test how resilient PIKADROID is
to concept drift [25], we created two drifting scenarios and compared
the results of PIKADROID, MaMaDroid [31], and APIMiner [2] in
each. In the first drifting scenario, each system was trained using
the 2013-2015 dataset, and then classified the samples from the
2016-2018 time period. Figure 3(a) shows the results in terms of
f-score for PIKADROID, MaMaDroid, and APIMiner. PIKADROID
217Improving Accuracy of Android Malware Detection with Lightweight Contextual Awareness
ACSAC ’18, December 3-7, 2018, San Juan, PR, USA
Figure 3: The results of both drifting scenarios is provided in terms of f
score. PIKADROID (blue), MaMaDroid (purple), and APIMiner (green).
The left (a) shows scenario 1, which used the 2013-2015 samples as for
training PIKADROID. The right (b) shows scenario 2, which used the
2010-2012 samples for training.
was able to maintain an f-score of 94.3%. In contrast, MaMaDroid
and APIMiner had a f-score 89.89% and 65.92% respectively. We
believe this scenario shows that lightweight contextual systems, like
PIKADROID, can be extremely effective at generalizing the feature
space. This is because PIKADROID aims to learn only the most infor-
mative behaviors that form the core of the malware. In scenario two,
each system was trained using the 2010-2012 datasets, and then clas-
sified samples from 2013-2018. The results are shown in Figure 3(b).
Similar to scenario one, PIKADROID and MaMaDroid were able
to accurately detect samples 1-5 years older than the training set.
However, all three systems performed poorly at detecting apps 6-
8 year older. Unlike scenario 1, APIMiner performed suprisingly
well, and actually marginally performed better than PIKADROID
and MaMaDroid. This leads us to believe that properly evaluating
concept-drift is extremely difficult because the evaluation is ex-
tremely susceptible to undersampling. This is because evaluating
concept-drift requires a diverse dataset over a large time period.
Therefore, we believe this evaluation technique may not be the most
effective approach at measuring concept drift. However, since it
is similar to prior approaches [31], we believe the results contains
useful information. However, we believe, a more formal approach,
such as Transcend [25] is necessary. Finally, we also believe these
two scenarios show that both abstraction-based and contextual-based
systems can improve a model’s lifetime by creating more general-
izable feature spaces. Both MaMaDroid and PIKADROID perform
well in both scenarios when the testing samples are 1-5 years older
than the training samples.
6.3 Robustness
In this section, we discuss experiments used to extensively eval-
uate PIKADROID’s features against state-of-the-art obfuscations
tools. We also discuss obfuscations that could potentially hinder
PIKADROID’s feature set.
Obfuscated Malware. In order to evade anti-virus scanners and
learning-based systems, malware authors leverage obfuscation tech-
niques to make analysis and reverse engineering more difficult [27,
28, 40, 43]. To identify how robust PIKADROID is to obfuscation,
Figure 4: The f-scores of K-Nearest Neighbor (KNN) (k = 3, 5), Ran-
dom Forest (200 estimators), and a Multi Layer Perceptron with one
hidden layer of size 100.
we leverage AVPass [27], an open-source obfuscation platform that
is capable of rule and feature inference. This allows malicious devel-
opers to tailor combinations of obfuscations techniques to bypass
learning-based malware detection systems including PIKADROID.
We first train PIKADROID on Android applications in the 2010-2012
dataset. Next, we use AVPass to create unknown obfuscated variants
of samples found in the same time period. After the obfuscation pro-
cess is completed for all apps, we use PIKADROID’s trained model
to classify them as benign or malicious. We find that PIKADROID
accurately detects malicious applications, even when deep-semantic
obfuscated apps are used for testing. The results of our experiments
are given in Table 7. Eight obfuscations are applied by AVPass,
including bytecode transformation, identifier mangling, and class
obfuscation. However, despite these obfuscations PIKADROID is
able to still detect the unknown variants with a true positive rating
92.5%. We attribute PIKADROID’s ability to be robust to its reliance
on semantic-based features instead of application syntax like prior
approaches [15, 16]
Limitations. We see two possible limitations related to the feature
space used by PIKADROID. The first limitation is entrypoint obfusca-
tion. Yang et. al. showed possible attacks against context-based sys-
tems using phylogenetic analysis [8]. This attack launches an inter-
component transplantation attack [50], which transplants the mali-
cious behavior into a different application component. Unfortunately,
this attack requires an isolated component (broadcastReceiver),
which could be easily detected because malicious applications of-
ten invoke sensitive APIs from broadcast receivers. PIKADROID is
subject to a second limitation such that its contextual factors may be
more susceptible to Java reflection and dynamic code loading com-
pared to prior context-based systems [52, 53]. This is because these
systems tailor the contextual factors to specific malware families,
which allows them to identify inappropriate uses of Java reflection
and dynamic code loading. For example, AppContext [52] accurately
detects the misuse of Java Reflection and Dynamic Code loading by
attaching activation-, control-, and system- dependencies to the invo-