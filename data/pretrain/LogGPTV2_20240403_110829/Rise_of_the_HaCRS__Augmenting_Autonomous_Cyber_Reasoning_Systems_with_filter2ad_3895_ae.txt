### Vulnerability Detection Case Study: Game Board Hiding

A null pointer dereference bug can be triggered in the game by playing at least one round and then typing "START OVER" to initiate a new game from the menu. Other options, such as "PLAY AGAIN," do not immediately cause a crash. During gameplay, the binary provides clear instructions on the expected input format. Our assistants adhered to this format, winning the first round quickly, and then selected "PLAY AGAIN" to start a new game. HaCRS then mutated one of the round-winning inputs, replacing "PLAY AGAIN" with "START OVER," which immediately triggered the crash. In contrast, neither AFL nor Driller could win a single round or generate input that met the format requirements, thus failing to crash the binary.

### Vulnerability Detection Case Study: KPRCA_00028

This binary implements a command-line interpreter for expressions in an imaginary programming language called SLUR. Built-in functions include `quote`, `cons`, `equal`, `lambda`, and others, which can be used within SLUR expressions. A typical SLUR expression might look like `(quote e)` or `((lambda (v1 v2) e) e1 e2)`. A null pointer dereference vulnerability exists in the `lambda` function.

Although the program does not provide explicit guidance on the available built-in functions or the required input format, our assistants were able to capture function names from the symbolic tokens provided by HaCRS. They also correctly determined the legitimate format of SLUR expressions and manually constructed expressions using various built-in functions accepted by the binary. With the help of these inputs, HaCRS was able to build several long SLUR expressions, including one or more `lambda` sub-expressions, which triggered the crash. We examined the input generated by AFL (without human assistance) and found that it failed to produce a correctly formatted expression, explaining why it did not crash the binary.

### 7. Discussion

#### 7.1 Human Obsolescence

As with many human-dependent techniques, we expect that the "intuition" provided by human assistants will eventually be replaced by automated methods. However, it is unclear what form such an analysis would take. While performing the tasks requested by HaCRS, humans do not necessarily reason about code coverage but rather explore the abstract state space of the program in ways that current automated techniques do not consider. When automated techniques can reproduce this aspect of human intuition, humans may become redundant, similar to the automation of assembly lines. For now, human involvement remains crucial, even in the simplified Cyber Grand Challenge dataset.

#### 7.2 Assistant Skill Levels

Interestingly, more technically-minded assistants tended to get frustrated and quit faster when they encountered technical issues, possibly due to our attempts to simplify the assistant instructions. This, combined with the relatively unimpressive performance of semi-experts, suggests that more research is needed to present the correct abstraction for different skill levels. The non-expert interface may not scale well for expert users. Software testing specialists, despite being "semi-experts" in program analysis, excel at identifying corner cases. Our future direction is to reintroduce expertise into the process with appropriate interface support, to better understand the impact of expertise-independent human "intuition" and human experience.

Given a pool of non-experts, semi-experts, and a limited number of experts, HaCRS could strategically distribute different tasks with varying difficulty levels. There are open questions about the best way to facilitate this interaction. Should experts inject inputs like non-experts, or should they work at a lower level of program paths and symbolic constraints? Once variable levels of assistance are supported, HaCRS will need to reason about a budget in terms of available human talent, time, and money. This requires integrating complex game theory and approach planning algorithms, which are currently underexplored in Cyber Reasoning Systems.

#### 7.3 Incentive Structures

Amazon Mechanical Turk is designed for quick tasks with instant payoffs, so we settled on an incentive model that pays assistants for triggering a pre-set amount of transitions in the program. However, this ignores the downstream effects of human contributions on automated analysis. Not all transitions are equally valuable, and some lead to more interesting mutations than others. An improved incentive structure could reward assistants based on the code coverage achieved by test cases derived from their solutions, not just the coverage of the solutions themselves. This would allow assistants to budget their time more effectively across different programs.

These improved incentive structures, where humans and automation assist each other, could bring the two sides closer to creating a hybrid "centaur" system.

#### 7.4 Other Tasklets

We have integrated human assistance into the test case creation pipeline of the Mechanical Phish. However, the HaCRS concept can be applied to other aspects of a CRS:

- **Test Case Selection**: Automated techniques like AFLFast have been developed to help with test case selection, but human assistance could still be beneficial.
- **Exploitation**: Even though the Mechanical Phish exploited more challenges during the Cyber Grand Challenge, it had an 80% failure rate in converting crashes to exploits. Crashing test cases that the CRS fails to exploit could be sent to expert human assistants for "post-processing."
- **Patching**: The Mechanical Phish cannot create precise patches due to a lack of root cause analysis. Integrating human effort into the patch evaluation process could significantly improve this component.
- **High-Level Planning**: Human assistance can be leveraged in the planning process, such as deciding whether to patch a vulnerability.

We plan to explore these applications in our future work.

### 8. Conclusion

The use of principled human assistance in Cyber Reasoning Systems represents a paradigm shift in binary analysis. Instead of the dichotomy between human-led, semi-automated systems (HCH) and fully automated systems (CCC), we propose a C(H|C)C system where computers make organizational calls and humans assist when needed. This system can utilize the insight of non-expert humans, who are more abundant and scalable. In the absence of humans, these systems can operate autonomously, albeit at a lower effectiveness.

In this paper, we explored how non-experts impact the automated vulnerability discovery pipeline. The results are significant: humans with no security training were able to significantly improve the bug detection rate of a state-of-the-art vulnerability analysis engine. Further exploration is warranted, as humans can confirm or repudiate static analysis results, combine behavior observed in different test cases, and help verify automatically-generated patches.

### Acknowledgments

We thank the Shellphish CTF and CGC team for their support and brilliance over the years. We also thank our workers on Amazon Mechanical Turk and our semi-expert volunteers: Xingcheng Chen, Tao Du, Tao Zhan, and two anonymous graduate students.

This material is based on research sponsored by the National Science Foundation, DARPA, and the Office of Naval Research. The views and conclusions contained herein are those of the authors and should not be interpreted as representing the official policies or endorsements of the U.S. Government.

### References

[References listed here, following the same format as in the original text.]

### Binary List

- CADET_00001
- CADET_00003
- CROMU_00001
- CROMU_00003
- CROMU_00005
- CROMU_00017
- CROMU_00019
- CROMU_00029
- CROMU_00031
- CROMU_00037
- CROMU_00040
- CROMU_00041
- CROMU_00044