title:Mobile Network Performance from User Devices: A Longitudinal, Multidimensional
Analysis
author:Ashkan Nikravesh and
David R. Choffnes and
Ethan Katz-Bassett and
Zhuoqing Morley Mao and
Matt Welsh
Mobile Network Performance from User Devices:
A Longitudinal, Multidimensional Analysis
Ashkan Nikravesh1, David R. Choffnes2, Ethan Katz-Bassett3,
Z. Morley Mao1, and Matt Welsh4
1 University of Michigan
2 Northeastern University
3 University of Southern California
4 Google Inc.
Abstract. In the cellular environment, operators, researchers and end users have
poor visibility into network performance for devices. Improving visibility is chal-
lenging because this performance depends factors that include carrier, access
technology, signal strength, geographic location and time. Addressing this re-
quires longitudinal, continuous and large-scale measurements from a diverse set
of mobile devices and networks.
This paper takes a ﬁrst look at cellular network performance from this per-
spective, using 17 months of data collected from devices located throughout the
world. We show that (i) there is signiﬁcant variance in key performance metrics
both within and across carriers; (ii) this variance is at best only partially explained
by regional and time-of-day patterns; (iii) the stability of network performance
varies substantially among carriers. Further, we use the dataset to diagnose the
causes behind observed performance problems and identify additional measure-
ments that will improve our ability to reason about mobile network behavior.
1 Introduction
Cellular networks are the fastest growing, most popular and least understood Internet
systems. A particularly difﬁcult challenge in this environment is capturing a view of
network performance that is representative of conditions at end user devices. A num-
ber of factors frustrate our ability to capture this view. For instance, carriers enforce
different policies depending on the trafﬁc types or geographic/social characteristics of
different locations such as population [1, 2], causing user perceived performance to dif-
fer from advertised performance for access technologies. Other environmental factors
have a signiﬁcant impact on performance, including device model [3], mobility [4],
network load [2], packet size [5, 6] and MAC-layer scheduling [4].
To account for various factors impacting Internet performance in mobile networks,
we need pervasive network monitoring that samples a variety of devices across carriers,
access technologies, locations and over time. This work takes a ﬁrst look at such a view
using data collected from controlled measurement experiments in 144 carriers during
17 months, comprising 11 cellular network technologies. We use this data to identify
the patterns, trends, anomalies, and evolution of cellular networks’ performance.
This study demonstrates that characterizing and understanding the performance in
today’s cellular networks is far from trivial. We ﬁnd that all carriers exhibit signiﬁcant
M. Faloutsos and A. Kuzmanovic (Eds.): PAM 2014, LNCS 8362, pp. 12–22, 2014.
c(cid:2) Springer International Publishing Switzerland 2014
Mobile Network Performance from User Devices
13
variance in end-to-end performance in terms of latency and throughput. To explain this
variance, we investigate geographic and temporal properties of network performance.
While we ﬁnd that these properties account for some differences in performance, impor-
tantly we observe that performance is inherently unstable, with some carriers providing
relatively more or less predictable performance. Last, we identify alternative sources
of variance in performance that include routing and signal strength. An important open
question is how to design a measurement platform that allows us to understand reasons
behind most observed performance differences.
This paper differs from previous related work in that our study is longitudinal, con-
tinuous, pervasive and gathered from mobile devices using controlled experiments. In
contrast, some related work [7–9] passively collected network trafﬁc from cellular net-
work infrastructure, using one month of data or less. These studies tend to be limited to
a single carrier, hampering our ability to conduct meaningful comparisons across carri-
ers. Other work collected network performance data at mobile devices [10, 1, 11], but
did not use controlled experiments to capture a continuous view of performance.
Roadmap. We describe our methodology and dataset in §2, then present our ﬁndings
regarding network performance across different network technologies, carriers, loca-
tions, and times in §3.1, §3.2, and §3.3 respectively. Then we study the root causes for
performance degradation in §3.4. We discuss related work in §4 and conclude in §5.
2 Methodology and Dataset
This paper studies cellular network performance using a broad longitudinal view of net-
work behavior impacting user-perceived performance. To this end, we consider HTTP
GET throughput, round trip time latency from ping, and DNS lookup time as end-to-end
performance metrics. In addition to gathering raw performance data, we annotate our
measurements with path information gathered from traceroute, the identify of the de-
vice’s carrier, its cellular network technology, signal strength, location and timestamp.
We focus on performance from mobile devices to Google, a large, popular content
provider. We argue that Google is an ideal target for network measurements because it is
highly available and well provisioned, making it easier to isolate network performance
to cell networks vs. Google’s network. Focusing on these measurements, we identify the
performance impact of carrier, network technology, location and time. To reason about
the root cause behind performance changes, we use path information, DNS mappings
and signal strength readings.
Our data is collected by two Android apps using a nearly identical codebase,
Speedometer and Mobiperf.1 Speedometer is an internal Android app developed by
Google and deployed on hundreds of volunteer devices, mainly owned by Google em-
ployees. As such, the bulk of our dataset2 is biased toward locations where Google
employees live and work. Speedometer collected the following measurements from
2011-10 to 2013-2 (17 months): 6.6M ping RTTs to www.google.com (each sam-
ple consists of 10 consecutive probes), 1.7M HTTP GETs to measure TCP throughput
1 http://www.mobiperf.com/
2 This dataset is publicly available at
https://storage.cloud.google.com/speedometer
14
A. Nikravesh et al.
Table 1. Number of Measurement and Carriers for the Network Technologies
HSPA HSDPA UMTS EDGE GPRS LTE EVDO eHRPD 1xRTT
# of Measurements 439K 2326K 563K 506K 58K 1460K 2183K 301K
# of Carriers
50
111
96
85
48
7
8
2
68K
3
using a 224KB ﬁle hosted on a Google server, 0.4M UDP burst samples for measuring
packet loss rate, 0.8M DNS resolutions of google.com, and 0.8M traceroute (without
hop RTTs) from 144 carriers and 9 network technologies. The dataset includes ≈ 4-5
measurements per minute. Each measurement is annotated with device model, coarse-
grained location information (k-anonymized latitude and longitude), timestamp, car-
rier, and network type.3 All users consented to participate in the measurement study;
the anonymization process is explained in the dataset’s README ﬁle. Because of
anonymization, the number of users who participated in data collection is unknown.
We augment the Speedometer dataset with 11 months of data collected by Mobiperf.
Mobiperf conducts a superset of measurements in Speedometer, and notably adds signal
strength information. The number of measurements collected by Mobiperf for each
task ranges from 17K (HTTP GET) to 58K (ping RTT test) from 71 carriers. We use
Mobiperf data to study the impact of signal strength on measurement results. Table 1
shows the number of measurements collected from the most frequently seen 9 network
technologies (ordered by peak speed) for both GSM and CDMA technologies in the
combined datasets.
3 Data Analysis
3.1 Performance across Carriers
This section investigates the performance of ﬁve access technologies for each of several
carriers. Our goal is to understand how observed performance matches with expecta-
tions across access technologies, and how variable this performance is across carriers.
In Fig. 1, we plot percentile distributions (P5, P25, median, P75, and P95) of the latency
and throughput of 9 carriers from Asia, America, Europe, and Australia. We select these
carriers based on their geographic locations and relatively large data sample sizes. One
of the key observations is that performance varies signiﬁcantly across carriers and ac-
cess technologies; further, the range of values is also relatively large.
For carriers that have high latency, we use traceroute data to investigate if the cause
is inefﬁcient routes to Google [12]. However, approximately half of the carriers such as
SFR (French Carrier) and Swisscom have direct peering points with Google, making
this unlikely to be the cause for high latency.
For carriers such as AT&T, T-Mobile US, and Airtel (India), we observe high vari-
ability in latency. In the following subsections, we investigate whether this is explained
by regional differences, time-of-day effects and/or other factors.
Surprisingly, we do not observe signiﬁcant latency differences across access tech-
nologies for some carriers. For example, the latency of UMTS, HSDPA, and HSPA
3 https://github.com/Mobiperf/Speedometer
 1000
)
s
m
(
T
T
R
g
n
P
i
 100
T
-
M
A
T
&
T
o
bile
Mobile Network Performance from User Devices
15
GPRS
EDGE
UMTS
HSDPA
HSPA
 1000
)
s
p
b
K
(
t
u
p
h
g
u
o
r
h
T
P
T
T
H
 100
Y
S
V
N
S
S
E
 10
e
s
O
w
is
s
ptu
s
c
o
m
o
d
afo
T
T
D
n
e
(I
o
C
o
F
R
K
T
m
o
ele
bile
c
o
E
)
M
o
m
T
-
M
o
bile
A
T
&
T
GPRS
EDGE
UMTS
HSDPA
HSPA
Y
S
V
N
S
S
E
e
s
O
w
is
s
ptu
s
c
o
m
o
d
T
F
R
K
T
m
o
afo
T
D
n
e
(I
o
C
o
ele
bile
c
o
E
)
M
o
m
(a) Ping RTT
(b) HTTP GET throughput for downloading a
224KB ﬁle
Fig. 1. Throughput and latency across access technology and carriers
in Emobile (Ireland), SK Telecom (Korea), and Swisscom are almost equal. Users in
these networks may not see noticeable differences in performance for delay-sensitive
applications when upgrading to newer technologies.
In Fig. 1b, we plot HTTP throughput for downloading a 224KB ﬁle from a Google
domain. Compared to ping RTT, the difference between the throughput of carriers is
relatively smaller, indicating that the high variability in ping RTTs is often amortized
over the duration of a transfer.
Note that the throughput for UMTS, HSDPA, and HSPA are almost identical. This
occurs because the ﬂow size is not sufﬁciently large to saturate the link for high-capacity
technologies. This indicates a need for better low-cost techniques to estimate available
capacity in such networks [13]. However, the ﬁgure shows signiﬁcant performance dif-
ference between GPRS/EDGE and other access technologies.
We observe that lower latency is generally correlated with higher HTTP GET
throughput, but this depends on the carrier. We quantify this using the correlation coef-
ﬁcient between HTTP throughput and ping RTT for speciﬁc carrier and network type.
The strongest correlation coefﬁcient observed was for Verizon LTE users with −0.53
and lowest was −0.01 for T-Mobile HSDPA users, using one-hour buckets.
Having observed signiﬁcant differences in performance within and between carriers,
we now investigate some of the potential factors behind this variability.
3.2 Performance across different Locations
We now investigate the impact of geography on network performance. We focus on