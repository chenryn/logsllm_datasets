two pebbles perform the same operation. These redundant
operations can be avoided if one pebble waits while the other
performs the operations common to both pebbles. Then in-
stead of copying the value of the originally intended pebble
the waiting pebble can copy the value from the other pebble,
eliminating redundant work.
When two pebbles would ordinarily move upward to the
same pebble, the question arises of which to move ﬁrst and
which to delay. When considering a simple case with two
pebbles, two algorithms naturally emerge which are built
into two transition algorithms – the Lazy Pebble and Trav-
eling Pebble algorithms. The small example in Figure 4 illus-
trates the basic principles of these algorithms. The strategy
taken by the Lazy Pebble algorithm is to move the pebble
with the smaller ID ﬁrst. Once this pebble reaches its des-
tination, the larger pebble can copy the value of the smaller
and begin hashing to step downward from there. The other
algorithm, Traveling Pebble, moves the larger pebble ﬁrst.
With this method, the smaller pebble does not perform any
hash operations at all. As the larger pebble steps past the
smaller pebble’s destination, the smaller pebble copies the
1277Table 1: Retrieval bounds are given for the best
and worst cases of targeting when skipping δ values.
Cit(δ) denotes the cost δ iterations of iterative FHT.
2 ρ(δ, 3)) + 2ρ(δ,1) − 4 : (cid:100)log2(δ)(cid:101) > 3
: Otherwise
2 (ρ(δ, 1)) − 2ρ(δ,0) + 2
(cid:40)
Case
Worst
Best
Bound
Cit(δ) − δ
Cit(δ)
Cit(δ) − δ
Figure 4: A simple example is pictured in which
the two pebbles, with IDs 2 and 4, both intend to
copy the value from the same higher pebble (shown
darkened). To avoid redundant work, one pebble
moves before the other. The two paths demonstrate
diﬀerent principles on which to base transition algo-
rithms.
value from the larger pebble. The larger pebble then contin-
ues on to its ﬁnal destination. The remainder of this paper
will focus on the Traveling Pebble approach. This algorithm
is more intuitive, and preliminary tests indicated no measur-
able performance diﬀerence between the two.
For the purpose of explanation, the targeting algorithm
has been divided into two stages: state calculation and state
transition. The state calculation determines new destina-
tions for all pebbles that need to move. The Traveling Pebble
algorithm implements the state transition and can be thought
of as a sweep which hashes values across the whole range into
which pebbles will move. During this sweep, pebbles move
to their intended destinations. To make this process align
better with the style of FHT pebble movements, the job of
performing the hash sweep is given to the various moving
pebbles. In the Traveling Pebble algorithm, not all pebbles
are required to participate in the hash sweep, but those that
do are responsible for the range of values that lie above their
new destination and below the next higher pebble.
The targeting algorithm descriptions pertain to pebbles
whose destinations are still within the chain. The other case,
where pebbles move past the end of the chain, is ignored for
simplicity. These pebbles are unnecessary for the remainder
of the traversal and can be safely retired by removal from
the pebble list.
3.2 Theoretical Performance
Overall performance of the targeting algorithm can be
measured in terms of storage and computation, with compu-
tation cost split into hash operations and overhead incurred
from rearranging the pebble list. Storage complexity is ex-
actly the same as FHT, which is bounded by O(log2(n))
where n is the chain length. Computational costs require
further analysis.
Overhead of both state calculation and state transition
is bounded by O(log2(δ)) list operations, where δ repre-
sents the distance between successive retrieval targets. The
number of pebbles in a range of length δ is bounded by
log2(δ) + 1. In both Algorithms 1 or 2, no loop processes
more than log2(δ) + 1 pebbles. The ﬁrst loop in both algo-
rithms searches for a pebble above the target, with an ID
larger than any pebble below the target. This pebble is ﬁrst
guessed by knowing the minimum number of pebbles below
the target as well as the smallest possible ID for the largest
of these pebbles. From this guess, at most one iteration is
needed before reaching pebbles above the target. Finding
a pebble with an ID larger than all the pebbles below the
target is clearly bounded by log2(δ) + 1, the number of peb-
bles that will move2. The second loop in each algorithm
iterates over moving pebbles, which is already known to be
O(log2(δ)).
Performance in terms of hash operations is characterized
by upper and lower bounds on the number of operations
saved, S(δ), in comparison to the iterative method. For a
retrieval distance δ, iterative FHT requires O(δ × log2(n))
hash operations. Savings gained by targeting are examined
on a case by case basis to establish the lower and upper
bounds.
Bounds are found by estimating the number of pebbles
capable of savings and the number of operations saved by
each pebble. To simplify notation, let ρ(δ, α) represent the
number of pebbles that cause savings:
ρ(δ, α) = max((cid:100)log2(δ)(cid:101) − α, 0)
(1)
An interval of size δ contains at most (cid:100)log2(δ)(cid:101) pebbles, how-
ever, this overestimates the number of pebbles which achieve
savings by a small number α. To form best and worst case
calculations, α is adjusted accordingly. In the worst case, at
most three pebbles will be large enough to step above the
target without achieving savings3. With 0 ≤ α ≤ 3, note
that:
ρ(δ, α) ∈ Θ(log2(δ))
(2)
A lower savings bound can be estimated from the case
where the only savings derive from pebbles that avoid extra
moves below the target. This case is unlikely, but theoret-
ically possible. A key observation about the iterative algo-
rithm is that while each pebble hashes small ranges through-
out the chain, these ranges add up to hashing about half of
the entire chain. While skipping a region of length δ, each
pebble can save up to δ
2 operations, with adjustments neces-
sary for losses at the edges of the region. For an individual
pebble pi, the savings loss at each edge is at most 2i+1. Thus
2 (δ−2×2i+1).
for each pi, the minimum individual savings is 1
2This number is actually bounded by a constant, however,
the explanation is lengthy and unnecessary to show the
O(log2(δ)) bounds on the targeting algorithm.
3Finding an example region containing three pebbles with
no potential savings is straightforward. However, adding a
fourth pebble requires an interval large enough to allow the
smallest of the original three to achieve some savings. This
logic applies inductively.
1278Bounds predictions assume diﬀerent values of δ occur over
the course of a traversal. In TV-OTS, all keys have equal
probability of being retrieved. Consequently, the distance
δ between retrievals follows a geometric distribution. The
bounds in Figure 5 were calculated by summing over the
geometrically weighted savings for diﬀerent δ’s. Results are
plotted over E(δ), the expected δ of the distribution which
varies with the key retrieval probability of the protocol.
3.3 State Calculation
The correct state after any retrieval can be determined
by a small set of rules. The state calculator given by Algo-
rithm 1 uses these rules to determine ﬁnal pebble positions
that match those produced by an iterative FHT traversal.
The primary property used in determining new positions is
that each moving pebble must create an interval below a
larger pebble that matches the moving pebble’s ID. The
larger pebbles that assist in ﬁnding new destinations for
moving pebbles are referred to as reference pebbles. The
reference pebbles limit the possible destinations of the mov-
ing pebbles, some of which will lie above the target and some
below. Those below are disregarded as they lie in a region of
skipped values. Of the remaining possibilities, the lowest is
chosen for the moving pebble’s new destination. The choice
of lowest position reﬂects that pebbles moved iteratively will
stop as soon as they move past the target. The availabil-
ity of the correct reference location is ensured by deciding
the destinations for larger pebbles before smaller ones. By
knowing the destinations for all larger pebbles, the correct
destination is certain to be found for each moving pebble.
Because state calculation always chooses the lowest pos-
sible position, only one pebble needs to be considered as a
reference. Anticipating pebble movements, there are only
two pebbles that serve as possible references. These are the
two closest in position to the retrieval target. Of these two,
the lower will be chosen assuming the moving pebble, when
positioned below this lower reference, will still be above the
target. If this is not the case, the other reference is chosen.
In this second case, the two potential reference pebbles bor-
der the interval for the moving pebble to split. Since this
division is even, placing the moving pebble at an interval be-
low the higher of the two references is equivalent to placing
the moving pebble above the lower reference. Because this
process is only responsible for ﬁnding destinations and not
for moving pebbles, knowing the position of only this lower
reference is suﬃcient to ﬁnd the proper destination.
With these guiding principles in place, state calculation
can be described as an iterative algorithm for calculating
individual pebble destinations. Setup requires ﬁnding the
location, β, of a pebble to use as the initial reference. Specif-
ically, β is the position of the pebble whose ID is the smallest
from a certain set of pebbles. This set is comprised of all the
pebbles whose IDs are larger than the IDs of all the pebbles
below the target5. The number of pebbles below the target
is a function of the interval length between retrieved val-
ues. Once the number of pebbles to move is known, ﬁnding
a pebble to use for β requires checking pebbles above the
target until one satisﬁes the criterion just mentioned. Once
β is determined, iteration can start with the pebble of the
next lower ID.
5Note that this set is not equivalent to all the pebbles above
the target: a pebble below the target could have an ID larger
than that of a pebble above the target.
Figure 5: A bounds prediction for TV-OTS, calcu-
lated by subtracting the calculated expected savings
from a baseline expectation for iterative FHT.
Summing over the ρ(δ, 3) pebbles that cause savings gives:
δ−2i+2
ρ(δ,3)(cid:88)
(cid:40) δ
2 ρ(δ, 3)) − 2ρ(δ,1) + 4 : (cid:100)log2(δ)(cid:101) > 3
i=1
2
0
: Otherwise
Smin(δ) =
=
(3)
An upper bound is achieved from slightly overestimating
the savings below the target and adding the maximum ad-
ditional savings from moving pebbles above the target. In
the best case, all the moving pebbles except the largest can
be moved for free. This is at most ρ(δ, 1) = (cid:100)log2(δ)(cid:101) − 1
pebbles. The savings below the target are also adjusted,
counting ρ(δ, 1) pebbles potentially saving up to δ
2 opera-
tions each:
Smax(δ) =
+
ρ(δ,1)(cid:88)
ρ(δ,1)(cid:88)
2 ρ(δ, 1) + 2ρ(δ,0) − 2
δ
2
2i
i=1
i=1
= δ
(4)
From Smin(δ) ∈ Ω(δ log2(δ)) and Smax(δ) ∈ O(δ log2(δ)),
and the relationship Smin ≤ S ≤ Smax, a tight bound can
be placed on S(δ):
S(δ) ∈ Θ(δ log2(δ))
(5)
Table 3.2 summarizes the diﬀerences between the iterative
method, and targeting in the best and worst case.
3.2.1 Bounds Prediction for TV-OTS
The theoretical bounds help predict the performance of
TV-OTS using targeting. Figure 5 shows expected bounds
calculated per traversal, estimated by subtracting calculated
savings from a baseline TV-OTS approximation. The esti-
mated requirement of a TV-OTS traversal is n
2 log2(n) hash
operations, recalling that over an entire traversal each peb-
bles hashes about half the chain, or n
2 operations4.
4The cost of FHT is reported as 2 log2(n) + 1 operations per
retrieval, but this is an upper bound and does not necessarily
imply that a sequence of n retrievals requires n×(2 log2(n)+
1) operations.
1279Algorithm 1: State Calculation
Data: A list of pebbles L of length n
Input: A target position t
Result: L is modiﬁed
/* initialize iteration control variables
idx ← (cid:98) log2(t − L.getPebbleByIndex(0).pos + 1)(cid:99)
nxtId ← 2idx
p ← L.getPebbleByIndex(idx)
while p.dest < t or p.id ≤ nxtId do
*/
*/
*/
*/
*/
est.
In this way, larger pebbles begin their moves before
smaller ones. When a pebble pt is found to move, a looka-
head operation is performed to determine the destination
of the next smaller pebble, ps. The destination of ps deter-
mines whether pt may complete its move, or whether it must
begin its move but pause when it reaches ps’s destination,
allowing ps to copy the value at pt’s position. If this is in-
deed the case, this procedure is followed and then repeated
for a new ps, performing lookahead operations for smaller
pebbles until one is found whose destination lies below that
of pt. At this point, no more smaller pebbles will need to
move above pt and pt completes its move.