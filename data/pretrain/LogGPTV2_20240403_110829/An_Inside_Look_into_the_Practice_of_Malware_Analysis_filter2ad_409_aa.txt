title:An Inside Look into the Practice of Malware Analysis
author:Miuyin Yong Wong and
Matthew Landen and
Manos Antonakakis and
Douglas M. Blough and
Elissa M. Redmiles and
Mustaque Ahamad
An Inside Look into the Practice of Malware Analysis
Miuyin Yong Wong†, Matthew Landen†, Manos Antonakakis†, Douglas M. Blough†,
Elissa M. Redmiles‡, Mustaque Ahamad†
Georgia Institute of Technology†
Max Planck Institute for Software Systems‡
United States
Germany
ABSTRACT
Malware analysis aims to understand how malicious software car-
ries out actions necessary for a successful attack and identify the
possible impacts of the attack. While there has been substantial
research focused on malware analysis and it is an important tool
for practitioners in industry, the overall malware analysis process
used by practitioners has not been studied. As a result, an under-
standing of common malware analysis workflows and their goals
is lacking. A better understanding of these workflows could help
identify new research directions that are impactful in practice. In
order to better understand malware analysis processes, we present
the results of a user study with 21 professional malware analysts
with diverse backgrounds who work at 18 different companies. The
study focuses on answering three research questions: (1) What are
the different objectives of malware analysts in practice?, (2) What
comprises a typical professional malware analyst workflow?, and
(3) When analysts decide to conduct dynamic analysis, what factors
do they consider when setting up a dynamic analysis system?
Based on participant responses, we propose a taxonomy of mal-
ware analysts and identify five common analysis workflows. We
also identify challenges that analysts face during the different stages
of their workflow. From the results of the study, we propose two
potential directions for future research, informed by challenges
described by the participants. Finally, we recommend guidelines
for developers of malware analysis tools to consider in order to
improve the usability of such tools.
CCS CONCEPTS
• Security and privacy → Usability in security and privacy.
KEYWORDS
Malware Analysis;Usable Security
ACM Reference Format:
Miuyin Yong Wong†, Matthew Landen†, Manos Antonakakis†, Douglas
M. Blough†,, Elissa M. Redmiles‡, Mustaque Ahamad† . 2021. An Inside
Look into the Practice of Malware Analysis. In Proceedings of the 2021 ACM
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea
© 2021 Association for Computing Machinery.
ACM ISBN 978-1-4503-8454-4/21/11...$15.00
https://doi.org/10.1145/3460120.3484759
SIGSAC Conference on Computer and Communications Security (CCS ’21),
November 15–19, 2021, Virtual Event, Republic of Korea. ACM, New York, NY,
USA, 17 pages. https://doi.org/10.1145/3460120.3484759
1 INTRODUCTION
The growing volume and sophistication of cyber attacks relies on
the ability of malicious actors to take control of victim comput-
ers, often by running malicious software on them. Such malicious
software, or malware, can be used to exfiltrate sensitive data (e.g.,
data breaches) or to demand ransom as seen in numerous recent at-
tacks [6, 16]. To combat such attacks, we must understand how they
were conducted. To do so, professional malware analysts typically
analyze malware samples to understand what a certain malware
instance does and how it carries out the actions required for a
successful attack.
There has been considerable research in the area of malware
analysis that aims to understand malware and develop defenses
against it [28, 29, 33, 35–37, 39, 42, 45, 47, 51, 52, 54–56, 61, 66–
68, 73, 78, 82]. Such analysis may range from limited static analysis,
such as collecting hashes or extracting strings, to a detailed analysis
that can help understand the specific tactics used by malware to
achieve its goals [24, 64]. There are two main categories of malware
analysis; dynamic and static. Dynamic analysis consists of execut-
ing a potentially malicious program in a controlled setting and
monitoring its actions. In contrast, static analysis techniques are
performed without actually executing the sample, but rather focus
on analyzing the malicious code. There are also hybrid approaches
that leverage both dynamic and static analysis to analyze malware.
Although a significant body of research is devoted to developing
new malware analysis techniques [24, 25, 31, 36, 42, 50, 52, 67,
69, 79, 80], and these techniques are used widely, there is limited
research on understanding how they are used in practice. Prior
work has examined the workflows of software testers and white
hat hackers [75] as well as the workflows of reverse engineers [76].
Recently, Votipka et al. presented an analysis of the workflow of
reverse engineers by conducting an observational study [76]. The
study found that reverse engineers mostly rely on static analysis
and utilize some dynamic analysis in later stages of their workflow.
As discussed in prior research, malware analysis spans a broad
space of techniques, leveraging a combination of dynamic and static
analysis. Since reverse engineering primarily relies on static analy-
sis, the overall process of malware analysis, including important
steps associated with dynamic analysis, were not explored in detail
in past research studies. To fill this gap, we focus on understanding
the process of malware analysis broadly, including how analysis
Session 11C: Software Development and Analysis CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea3053goals and different methods of analysis (i.e., static and dynamic) im-
pact this process. To do so, we conduct a semi-structured interview
study with a diverse group of 21 professional malware analysts from
18 different companies, including Mandiant, Cisco, IBM, and a large
financial institution. Although the analysts cannot disclose their
company’s proprietary information, we gain insights from their
personal workflows, which have been shaped by the knowledge
that they have accumulated while working in the security industry.
Our work seeks to answer the following research questions:
RQ1. What are the different objectives of malware analysts in
practice?
RQ2. What comprises a typical professional malware analyst work-
flow?
RQ3. When analysts conduct dynamic analysis, what factors do
they consider when setting up a dynamic analysis system?
Our contributions are divided into three main areas. First, we
propose a taxonomy that classifies malware analysts based on the
indicators of compromise 1 (IOCs) that the analysts extract in or-
der to achieve their objectives. Second, we identify five common
malware analysis workflows. Third, we identify six key decisions
that malware analysis practitioners make when setting up their
dynamic analysis systems: We detail participants’ choices of imple-
mentation, virtual analysis platform, environment setup, network
communication, execution time, and techniques used to overcome
evasive tactics deployed by some malware.
From the workflows, we find that the participant’s main ob-
jective significantly alters the methodology used to analyze the
malware sample. We also observe that as the complexity of a mal-
ware sample increases, the likelihood that analysts will require a
hybrid approach also increases. The majority of the participants
begin with either dynamic analysis or limited static analysis. Later,
some participants switch to more in-depth static analysis; either to
derive additional information to reconfigure their dynamic analysis
systems or to manually reverse engineer the sample. Additionally,
this user study allowed us to observe open challenges faced by
professional malware analysts. We discuss potential opportunities
for translating previous research into practical solutions for practi-
tioners as well as future research directions that could help address
the identified challenges.
This paper is structured as follows. Section 2 describes the method-
ology of our study and section 3 provides details of the participants.
Next, we present our taxonomy used to categorize participants in
section 4. Section 5 describes the different analysis workflows that
we identified and section 6 discusses the configuration decisions
made by analysts. Lastly, we present challenges faced by the par-
ticipants, offer potential ways to help address them, and provide
usability recommendations in section 7, and conclude in section 9.
2 METHODOLOGY
In order to answer our research questions, we conducted 21 semi-
structured interviews with professional malware analysts. This
section describes the recruitment, interview, and data analysis pro-
cedures, as well as the limitations of our work. This study was
approved by our university’s Institutional Review Board.
1IOCs are artifacts that indicate potentially malicious activities that analysts seek by
analyzing a malware sample [13].
2.1 Recruitment
Three sources were used to recruit professional malware analysts:
a curated panel of security professionals who made themselves
available for surveys, mailing lists of security organizations, and
personal contacts of the co-authors of this paper. In April 2020,
an email requesting participation was sent to all three sources
containing a description of the study and an explanation of the
steps that the participants would have to take to participate.
Participant Selection. Although we only shared the study with
people in the cybersecurity field, we needed to ensure that we
specifically selected malware analysts for this user study. As such,
potential participants completed a 20 question survey (see Ap-
pendix A) that collected basic demographic information as well
as information regarding participants’ area of expertise, technical
skills, and job tasks. Among those who fit the purpose of the study,
we selected participants who captured a broad range of skill levels,
job titles, and job tasks within malware analysis.
2.2 Interview Protocol
We conducted hour-long, semi-structured interviews with each
participant via online video conference from May through June 2020.
All interviews were conducted by the first author for consistency.
The interviewer followed the questions found in Appendix B with
the option to ask follow-up questions and skip previously answered
questions. The interviews were divided into the following sections.
Introduction and Experience. The interview began by asking
the participants to expand on their daily job tasks and experience
described in the screening survey. Their responses allowed us to
personalize questions during the rest of the interview.
Malware Sources. Next, to better understand our participants’
day-to-day work experiences, we asked them questions about the
malware samples they analyze. Specifically, we asked how they
receive their malware samples, what data is included when they
get a sample, and how many samples they receive per day. We also
asked how the participants prioritized the samples they analyze
and how they detect whether a sample is a variant of a previously
known malware.
Analysis Workflow. In this next section, we asked participants
to walk us through the steps they take and tools they use to analyze
a malware sample. With these questions, we wanted to understand
the process that participants use to achieve their analysis objec-
tives. More generally, we wanted to understand the output of their
analysis process. Also, we wanted to identify common challenges
that malware analysts face during their analysis workflow.
Dynamic Analysis System Configuration. Dynamic analysis
is a common process used by a majority of malware analysts. For
this reason, we wanted to understand how the participants config-
ure their dynamic analysis system. We asked participants whether
they prefer bare metal or virtualized environments2, commercial or
open-source sandboxes3, and their reasoning behind such prefer-
ences. We also asked what operating system (OS) they select when
configuring their sandbox, how they configure their network, and
2Bare metal refers to physical computer whereas a virtualized environment uses
software to simulate a physical computer.
3sandboxes are tools that execute and monitor malware samples safely.
Session 11C: Software Development and Analysis CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea3054whether they configure the user space with specific locations, lan-
guages, and/or applications. Our questions aimed to identify any
critical settings that our participants consider when setting up their
dynamic analysis systems to get malware to reveal its malicious
behavior.
After understanding participants’ configuration process, we in-
vestigated the dynamic analysis process they follow. Specifically,
we asked questions regarding the execution of the malware samples.
For example: How long and how many times do they run a sample?
If they run samples multiple times, do they modify anything in the
setup between runs? What data does the execution produce? Lastly,
we wanted to identify the challenging and time-consuming tasks
that the participants face when performing this setup.
Malware Analysis Evolution. Finally, we asked each participant
to describe how their malware analysis approach has evolved over
time.
2.3 Data Collection and Analysis
The interviews were recorded and then manually transcribed by the
interviewer and analyzed using an iterative open coding methodol-
ogy [72]. The interviewer, along with another co-author, developed
a codebook (Appendix D) based on an independent review of four
interviews. Subsequently, the two co-authors independently coded
each interview using this codebook. The coders achieved "excellent"
Krippendorff’s alpha intercoder reliability of 0.823 [57]. Reliability
was used to ensure consistency in the interpretation of conceptual
themes and workflows across the research team.
2.4 Follow-up Survey
The last step of our methodology was a follow-up survey, sent
in September 2020, consisting of three multiple choice questions,
shown in Appendix C. The purpose of this survey was to clar-
ify whether the participants configure specific dynamic analysis
settings. Further clarification was needed because some partici-
pants provided high-level responses in the initial interview. When
presenting results about the dynamic analysis environment setup
process, we only include findings from participants who responded
to the follow-up survey in order to ensure the results are complete.
2.5 Limitations
Our study has limitations common in exploratory, qualitative re-
search. First, participants may not recall all of the steps of their
personal analysis and configuration processes. This limitation is
common with studies involving expert tasks [43]. We aimed to mit-
igate this limitation by asking participants to walk us through their
analysis process, per best practice for qualitative interviews [46].
The second limitation is participants’ inability to respond to cer-
tain questions due to non-disclosure agreements they have with
their companies. To mitigate this issue, we asked participants to
describe their personal analysis process instead of describing the
confidential processes of their companies. Finally, it is possible
that our participant group, as a whole, may not cover all of the
types of analysts in practice. To partially mitigate this limitation,
we recruited participants through several sources to have a diverse
group of participants and increase the likelihood that relevant ideas
would be stated by more than one participant.
Educ
Ph.D.
-
B.S.
B.S.
Ph.D.
M.S.
Yrs
5
14.5
4
2
5
5
Assoc.
10
ID
P1
P2
P3
P4
P5
P6
P7
P8
P9
3
7
2
6
1
-
4
B.S.
B.S.
P10 M.S.
P11 M.S.
P12 M.S.
P13 M.S.
P14
B.S.
P15 College
P16
B.S.
P17 M.S.
P18
B.S.
P19 M.S.
P20 M.S.
P21
B.S.
Title
Director of Research
Project Manager - Security So-
lution Architect
Security Engineer
Senior Reverse Engineer
Head of Laboratory
Senior Analyst
Principal Threat Researcher /
Reverse Engineer
Senior Security Engineer
Manager, Digital Forensics and