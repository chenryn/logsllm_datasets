Attack Results. Our attack results on Bob Spear align with prior
work, with an average AS of 93.1% for Spear’s UBM-GMM method
and 97.1% for Spear’s ISV method (see Table 2). Our synthesized
samples have an average Mel-Cepstral Distortion (MCD) of 4.79 dB,
compared to the average MCD of 5.59 dB reported in [57] (lower
is better).
However, the Festvox attack fails on current SR systems, includ-
ing Resemblyzer and Azure. Out of the 38 speakers tested, only 8
have one or more attack samples accepted (21%). Moreover, Festvox
requires a signiﬁcant amount (around 6-8 minutes) of content-speciﬁc
speech from both the victim and attacker to synthesize fake speech,
making the attack impractical. Modern voice conversion systems
like SV2TTS are text-independent and need much fewer victim
speech samples to successfully synthesize speech.
8.2 The Rainbow Passage
Participants in our user study of §4.2 were asked to record the Rain-
bow Passage. The Rainbow Passage is commonly used in linguistic
studies, since it contains nearly all the phonemes combinations of
the English language. The full text of the Rainbow Passage is be-
low:
When sunlight strikes raindrops in the air, they act
like a prism and form a rainbow. The rainbow is a di-
vision of white light into many beautiful colors. These
take the shape of a long round arch, with its path high
above, and its two ends apparently beyond the hori-
zon. There is, according to legend, a boiling pot of
gold at one end. People look but no one ever ﬁnds it.
When a man looks for something beyond his reach,
his friends say he is looking for the pot of gold at the
end of the rainbow. Throughout the centuries men
have explained the rainbow in various ways. Some
have accepted it as a miracle without physical ex-
planation. To the Hebrews it was a token that there
would be no more universal ﬂoods. The Greeks used
to imagine that it was a sign from the gods to fore-
tell war or heavy rain. The Norsemen considered the
rainbow as a bridge over which the gods passed from
the earth to their home in the sky. Other men have
tried to explain the phenomenon physically. Aristotle
thought that the rainbow was caused by reﬂection of
the sun’s rays by the rain. Since then physicists have
found that it is not the reﬂection, but refraction by
the raindrops which causes the rainbow. Many com-
plicated ideas about the rainbow have been formed.
The diﬀerence in the rainbow depends considerably
upon the size of the water drops, and the width of
the colored band increases as the size of the drops in-
creases. The actual primary rainbow observed is said
to be the eﬀect of superposition of a number of bows.
If the red of the second bow falls upon the green of
the ﬁrst, the result is to give a bow with an abnor-
mally wide yellow band, since red and green light
when mixed form yellow. This is a very common type
of bow, one showing mainly red and yellow, with lit-
tle or no green or blue.
8.3 Phrases for Synthesis
Table 10 lists the phrases used for synthetic speech generation with
SV2TTS and AutoVC.
Phrases used for SV2TTS Speech Synthesis
We control complexity by establishing new languages for describing a design,
each of which emphasizes particular aspects of the design and deemphasizes others.
An interpreter raises the machine to the level of the user program.
Everything should be made as simple as possible, and no simpler.
The great dividing line between success and failure
can be expressed in ﬁve words: "I did not have time."
When your enemy is making a very serious mistake,
don’t be impolite and disturb him.
A charlatan makes obscure what is clear;
a thinker makes clear what is obscure.
There are two ways of constructing a software design;
one way is to make it so simple that there are obviously no deﬁciencies,
and the other way is to make it so complicated that there are no obvious deﬁciencies.
The three chief virtues of a programmer are: Laziness, Impatience and Hubris.
All non-trivial abstractions, to some degree, are leaky.
XML wasn’t designed to be edited by humans on a regular basis.
Table 10: Phrases used for SV2TTS speech synthesis attacks
in §4.2 and 4.3.
8.4 Phoneme Similarity Experiments from §4.2
We use phoneme error rate (PER) to determine the similarity be-
tween a target sample’s content and a synthesized output’s content.
Session 1D: Authentication and Click Fraud CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea250Metric
Detection Success
Replay
Source
ϵ = 0.01
ϵ = 0.05
ϵ = 0.10
SVM LightCNN
91.3%
93.0%
90.8%
94.1%
94.6%
80.1%
Custom
DNN
90.2%
91.4%
84.4%
SVM
4.8%
3.9%
6.2%
EER
Light
CNN
3.1%
4.4%
19.1%
Custom
DNN
9.8%
8.3%
17.9%
Table 13: Void detection success rates and EER for com-
bined defenses. Speech is ﬁrst synthesized from Attack-VC
defended samples (diﬀerent ϵ levels indicated by row), re-
played using the UE Boom loudspeaker, then run through
the Void models.
PER
0.0
0.25
0.5
0.75
1.0
Text
wind had come up and was driving puﬀy white clouds across the sky
wind had shove pup tuned wess priming puﬀy weir cloudy across the ski
wind had kerl yum econocom gestate erring puﬀy lett clouds close aja sky
vine hyde tonne edmundson airships stennis orville gaﬀes sues lader kross the sky
vine tass klumb muhs caftans prognosticater mendiola morphogenesis clips hilder kross though ski
Table 11: Changes to a reference text (top line) as phoneme
error rate (PER) increases. Changes are generated by ran-
domly selecting phrases from CMUDict [93] which match
the speciﬁed PER.
µ
σ
LibriSpeech
0.25
0.75
1.0
0.0
0.25
VCTK
0.5
0.75
1.0
Azure
Resemblyzer
0.0
100% 100%
0%
18%
0.5
100% 100% 100%
0%
0%
19.5% 16%
22.2% 15.5% 13.0% 15.0% 20.0%
6.4%
8.1%
0%
4%
15.5% 15.5% 18.5%
13.5% 12%
Table 12: Resemblyzer, Azure results for phoneme experi-
ments. Results on Resemblyzer reported as average, stan-
dard deviation of 10 trials.
6.8%
15%
0%
19%
5.5%
PER is the Levenshtein distance between a predicted and reference
pronunciation’s phonemes and is a common measure of phonetic
similarity between two text samples [24].
To control the phonetic distance between sample and output, we
implement a custom phoneme conversion system, which takes in
a transcript of the target speech sample and produces output text
with a speciﬁc phoneme error rate (PER) from the input. Output
text was generated for PERs normalized by phoneme length rang-
ing from 0.0 to 1.0. Using SV2TTS, we synthesize speech from the
output text.
Table 11 demonstrates how diﬀerent phoneme error rates aﬀects
the output text. To achieve a particular phoneme error rate, a ran-
dom distribution of PER per word, given the total PER for the ref-
erence text, was generated. Words satisfying this distance criteria
from the original text were then randomly selected from CMUDict
to generate the output text [93]. Using 1 speech sample, we ﬁnd
that the PER between the target sample content and synthesized
sample content does not impact attack success (see Table 12).
8.5 Post-Deception Interview Procedure from
§5.3
Here, we describe the script and format of our post-deception in-
terview from §5.3.
Script. The following questions were asked during the post-deception
interview:
• How familiar were you with  voice before
this study (on a scale of 1-5, 5 being most familiar)?
• How familiar were you with  voice before
this study (on a scale of 1-5, 5 being most familiar)?
• Did anything throughout the interview cause you to think that
 wasn’t using a real voice?
• Were you at any point suspicious of the interview setup?
• If you were, at what point did you become suspicious?
• What, if anything, would have made you suspicious of ?
• Do you have any additional comments about your experience?
Following best practices for
Qualitative Analysis Procedure.
analysis of open-ended questions, as described in [72], the inter-
viewers made notes during and/or immediately following the post-
deception portion of the interview. After the conclusion of all inter-
views, each interviewer independently reviewed their notes and/or
rewatched the interviews as needed. For some questions, i.e., level
of familiarity with interviewers, the responses already had discrete
categories. For open-ended questions, using a bottom-up approach,
the notes were used to categorize responses into general themes re-
garding the interviewees level of suspicion, and reasons why. Upon
completing independent coding of all interviews, the researchers
met to consolidate the code books into a single code book with con-
sistent categories, and resolve any discrepancies. In the end, each
coding category represents sentiments expressed by 3 or more par-
ticipants, unless otherwise noted in §5.3.
8.6 Results on Combined Defenses from §6
We also tested if Void can detect speech synthesized from AttackVC-
protected samples. We ﬁrst generated protected samples using ϵ =
0.01, 0.05, 0.1 for AttackVC (as in §6.1), then recorded them using
the UE-Boom loudspeaker for playback as before. When tested, all
three Void models (SVM/LightCNN/CustomDNN) show high de-
tection rates (91-94%) on protected samples at ϵ = 0.01, 0.05 levels
but slightly lower detection rates at ϵ = 0.1. Detection rates for
protected samples with ϵ < 0.1 are higher than those for unpro-
tected samples (see Table 9).
8.7 DNN Architecture from §6.2
Table 14 lists the architecture used for our custom DNN trained for
Void in §6.2.
# of
Channels
Filter
Size
Activation
Connected
to
Layer
Index
1
2
3
4
5
Layer
Layer
Type
Name
Conv1D
conv_1
conv_2
Conv1D
max_1 MaxPool
FC
FC
fc_1
fc_2
conv_1
conv_2
max_1
fc_1
Table 14: Custom DNN architecture used to evaluate the Void
defense in §6.2.
ReLU
ReLU
-
ReLU
Softmax
32
64
64
128
2
3
3
2
-
-
Session 1D: Authentication and Click Fraud CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea251