would execute as slowly as the ﬁrst time. This shows that not
only the cache has a very high impact on execution time but
also that the cached information is evicted relatively quickly.
F. Summary
In this section, we empirically analysed the gas cost and
resource consumption of different instructions. To summarise:
• We see that even for simple instructions,
the gas
cost
is not always consistent with resource usage.
Indeed, even for instruction with very predictable
speed, such as arithmetic operations, we observe that
some instructions have a throughput 5 times slower
than others.
•
• We notice that while most instructions have a rela-
tively consistent execution speed, other instructions
have large variations in the time it takes to execute.
We ﬁnd that these instructions involve some sort of
IO operation.
Finally, we demonstrate the effect that the page cache
has on the execution speed of smart contracts and then
show the typical number of blocks for which the page
cache still provides speed up.
Overall, we see that beyond some pricing issue, the
metering scheme used by EVM does not allow to
express the complexity inherent to IO operations.
•
IV. ATTACKING THE METERING MODEL OF EVM
In light of the results we obtained in the previous sections,
we hypothesise that it is possible to construct contracts which
use a low amount of gas compared to the resources they use.
A. Constructing Resource Exhaustion Attacks
In particular, as we showed in Section III, the gas consump-
tion is dominated by the storage allocated but is not as much
affected by other resources such as the clock time. Therefore,
we decide to use the clock time as a target resource and look
for contracts which minimise the throughput in terms of gas
per second. We can formulate this as a search problem.
Problem formulation. We want to ﬁnd a program which
has the minimum possible throughput, where we deﬁne the
throughput to be the amount of gas processed per second. Let
I be the set of EVM instructions and P be the set of EVM
programs. A program p ∈ P is a sequence of instructions
I1,··· , In where all Ii ∈ I. Let t : P → R be a function
7
which takes a program as an input and outputs its execution
time and g : P → N be a function which takes a program
as input and outputs its gas cost. We deﬁne our function to
minimise f : P → R, f (p) = g(p)/t(p). Our goal is to ﬁnd
the program pslowest such that
pslowest = arg min
p∈P
(f (p))
(1)
The search space for a program of size n is |I|n. Given
|I| ≈ 100, the search space is clearly too large to be explored
entirely for any non-trivial program. Therefore, we cannot
simply go over the space of possible programs and instead
need to approximate the solution.
Although our problem resembles other program synthesis
tasks [33], there is a notable difference. Program synthesis usu-
ally focuses on generating “meaningful” programs, either from
speciﬁcations or examples. These tasks often do not have well-
deﬁned metrics allowing optimisation techniques (the genetic
algorithm in our work). The task we solve is different because
we need to deﬁne “valid” but not “meaningful” programs and
optimise for a well-deﬁned metric: gas throughput.
Search strategy. With the problem formulated as a search
problem, we now present our search strategy. We decide to
design the search as a genetic algorithm [56]. The reasons for
this choice are as follow:
•
•
•
•
we have a well-deﬁned ﬁtness function f
we have promising initialisation values, which we will
discuss below
programs being a sequence of instructions, cross-over
and mutations can be designed efﬁciently
generated programs need to be syntactically correct
but do not need to be semantically meaningful, making
the cross-over and mutations more straightforward to
design
We will now discuss in detail how we design the initialisation,
cross-over and mutations of our genetic algorithm.
Program construction. Although our programs do not need
to be semantically meaningful, they need to be executed suc-
cessfully on the EVM, which means that they must fulﬁl some
conditions. First, an instruction should never try to consume
more values than the current number of elements on the stack.
Second, instructions should not try to access random parts of
the EVM memory, otherwise the program could run out of
gas straight away. Indeed, when an instruction reads or writes
to a place in memory, the memory is “allocated” up to this
position and a fee is taken for each allocated memory word.
This means that if MLOAD would be called with 2100 as an
argument, it would result in the cost of allocating 2100 words
in memory, which would result in an out of gas exception.
Another potential issue would be to run into an inﬁnite
loop. However, we decide to explicitly exclude loops out of our
program generation algorithm for the following reason: adding
loops is unlikely to make the generated programs slower.
Indeed, if a piece of code is slow enough, our genetic algorithm
will tend to repeat it. The loop version could be faster if a value
is already cached but have no reason to be slower.
We design the program construction so that all created
programs will never fail because of either of the previous
reasons. We ﬁrst want to ensure that there are always enough
elements on the stack to be able to execute an instruction.
The instructions requiring the least number of elements on the
stack are instructions such as PUSH or BALANCE which do
not require any element, and the element requiring the most
number of elements on the stack is SWAP16 which requires 17
elements to be on the stack. We deﬁne the functions function
a : I → N which returns the number of arguments consumed
from the stack and r : I → N which returns the number
of elements returned on the stack for an instruction I. We
generate 18 sets of instructions using Equation 2.
∀n ∈ [0, 17], In = {I | I ∈ I ∧ a(I) ≤ n}
(2)
For example, the set I3 is composed of all the instructions
which require 3 or less items on the stack. We will use
these sets in Algorithm 1 to construct the initial programs
but before, we need to deﬁne the functions we use to control
memory access. For this purpose, we deﬁne two functions to
handle these. First, uses_memory : I → {0, 1} returns 1
only if the given instruction accesses memory in some way.
Then, prepare_stack : P × I → P takes a program and an
instruction and ensures that all the arguments of the instruction
which inﬂuence which part of memory is accessed are below
a relatively low value, that we arbitrarily set to 255. To ensure
this, prepare_stack adds POP instruction for all arguments
of I and add the exact same number of PUSH1 instructions
with a random value below the desired value. For example, in
the case of MLOAD, a POP followed by a PUSH1 would be
generated.
Using the sets In, the uses_memory and prepare_stack
functions, we use Algorithm 1 to generate the program. We
assume that the biased_sample function returns a random
element from the given set and will discuss how we instantiate
it in the next section.
Algorithm 1 Initial program construction
function GENERATEPROGRAM(size)
(cid:46) Initial empty program
(cid:46) Stack size
P ← ( )
s ← 0
for 1 to size do
I ← biased_sample(Is)
if uses_memory(I) then
P ← prepare_stack(P, I)
end if
P ← P · ( I )
s ← s + (r(I) − a(I))
(cid:46) Append I to P
end for
return P
end function
Initialisation. As the search space is very large, it is important
to start with good initial values so that the genetic algorithm
can search for promising solutions. For this purpose, we use the
result of the results we presented in Section III, in particular,
8
we use the throughput measured for each instruction. We deﬁne
a function throughput : I → R which returns the measured
throughput of a single instruction. When randomly choosing
the instructions with biased_sample, we want to have a higher
probability of picking an instruction with a low throughput but
want to keep a high enough probability of picking a higher
throughput instruction to make sure that these are not all
discarded before the search begins. We deﬁne the weight of
each instruction and then its probability with equations 3 and 4.
(cid:18)
(cid:80)
W (I ∈ I) = log
1 +
1
throughput(I)
P (I ∈ In) =
W (I)
W (I(cid:48))
I(cid:48)∈In
(cid:19)
(3)
(4)
Given that the throughput can have order-of-magnitude dif-
ferences among instructions, the log in Equation 3 is used to
avoid assigning a probability to close to 0 to an instruction.
Cross-over. We now want to deﬁne a cross-over function over
our search-space, a function which takes as input two programs
and returns two programs, i.e. cross_over : P × P → P ×
P, where the output programs are combined from the input
programs. To avoid enlarging the search space with invalid
programs, we want to perform cross-over such that the two
output programs are valid by construction. As during program
creation, we must ensure that each instruction of the output
program will always have enough elements on the stack and
that it will not try to read or write at random memory locations.
For the memory issue, we simply avoid modifying the
program before an instruction manipulating memory or one of
the POP or PUSH1 added in the program construction phase.
For the second issue, we make sure to always split the two
programs at positions where they have the same number of
elements on the stack.
We show how we perform the cross-over in Algorithm 2. In
the CREATESTACKSIZEINDEX function, we create a mapping
from a stack size to a set of program counters where the stack
has this size. In the CROSSOVER function, we ﬁrst create this
mapping for both programs and randomly choose a stack size
to split the program. We then randomly choose a location from
each program with the selected stack size. Note that here,
sample assigns the same probability to all elements in the set.
Finally, we split each program in two at the chosen position,
and cross the programs together.
Mutation. We use a straightforward mutation operator. We
randomly choose an instruction I in the program, where I is
not one of the POP or PUSH1 instructions added to handle
memory issues previously discussed. We generate a set MI of
replacement candidate instructions deﬁned as follow.
MI = {I(cid:48) | I(cid:48) ∈ Ia(I) ∧ r(I(cid:48)) = r(I)}
(5)
In other words, the replacement must require at most the
same number of elements on the stack and put back the
same number as the replaced instruction. Then, we replace
the instruction I by I(cid:48), which we randomly sample from MI.
If I had POP or PUSH1 associated with it to control memory,
we remove them from the program. Finally, if I(cid:48) uses memory,
we add the necessary instructions before it.
Algorithm 2 Cross-over function
function CREATESTACKSIZEMAPPING(P )
S ← empty mapping
pc ← 0
s ← 0
for I in P do
if s /∈ S then
S[s] ← {}
end if
S[s] ← S[s] ∪ {pc}
s ← s + (r(I) − a(I))
pc ← pc + 1
end for
return S
end function
function CROSSOVER(P1, P2)
S1 ← CREATESTACKSIZEMAPPING(P1)
S2 ← CREATESTACKSIZEMAPPING(P2)
S ← S1 ∩ S2
s ← sample(S)
i1 ← sample(S1[s])
i2 ← sample(S2[s])
P11, P12 ← split_at(P1, i1)
P21, P22 ← split_at(P2, i2)
1 ← P11 · P22
P (cid:48)
2 ← P21 · P12
P (cid:48)
return P (cid:48)
1, P (cid:48)
end function
2
(cid:46) Intersection on keys
(cid:46) Concatenate
Fig. 11: Execution time as a function of amount of gas used by contracts
within a block.
algorithm.
Clear the page cache;
1)
2) Warm up caches by generating and executing
randomly-generated contracts
Generate the initial set of program;
Run the genetic algorithm for n generation.
3)
4)
B. Effectiveness of Attacks with Synthetic Contracts
We want to measure the effectiveness of our approach to
produce Resource Exhaustion Attacks. To do so, we want to
generate contracts and benchmark them while mimicking the
behaviour of a regular full validating node as much as possible.
To do so, we execute all the programs produced within every
generation of our genetic algorithm, as if they were part of a
single block. We use the following steps to run our genetic
Fig. 10: Evolution of the average contract throughput as a function of the
number of generations.
9
An important point here is that when running the genetic
algorithm, we only want
to execute each program once,
otherwise every IO access will already be cached and it will
invalidate the results, as this is not what would happen when
a regular validating node executes contracts. However, we of
course do want to execute the measurements multiple times to
be able to measure the execution time standard deviation. To
work around these two requirements, we save all the programs
generated while we run the experiment. Once the experiment
has ﬁnished, we re-run all the programs in the exact same
order. We combine these results to compute the mean and
standard deviation of the execution time.
We note that generating a new generation takes on average
less than 1 second but the time-consuming part of our algo-
rithm is to compute the throughput of the generated programs.
Indeed, we need to wait for the EVM to run the program,
which can, as we show see in this section, take more than 90
seconds for a single generation. Furthermore, parallelising this
task could bias our measurements, which forces the algorithm
to perform the evaluation serially.
Generated bytecode. Before discussing the results further, we
show a small snippet of bytecode generated by our genetic
algorithm in Figure 12. We highlight the instructions which
involve IO operations in bold and show the instructions whose
sole purpose is to keep the stack consistent
in a smaller
font. We can see that there is a large number of IO related
instructions, in particular BLOCKHASH and BALANCE show up
multiple times. Although the fee of BALANCE has been revised
from 20 to 400 in EIP-150, this suggests that the instruction
is still under-priced. In the snippet, we also see that
the
stack is cleared and replaced with small values before calling
CALLDATACOPY. This corresponds to the prepare_stack
050100150200250Generation number0.00.51.01.52.02.53.0Throughput (Mgas/s)0246810Gas used (Mgas)020406080Execution time (s)PUSH9 0x57c2b11309b96b4c59
BLOCKHASH
SLOAD
CALLDATALOAD
PUSH7 0x25dfb360fa775a
BALANCE
MSTORE8
PUSH10 0x49f8c33edeea6ac2fe8a
PUSH14 0x1d18e6ece8b0cdbea6eb485ab61a
BALANCE
POP
POP
POP
PUSH1 0xf7
PUSH1 0xf7
PUSH1 0xf7
CALLDATACOPY
PUSH7 0x421437ba67fe0e
ADDRESS
BLOCKHASH
; prepare call to CALLDATACOPY