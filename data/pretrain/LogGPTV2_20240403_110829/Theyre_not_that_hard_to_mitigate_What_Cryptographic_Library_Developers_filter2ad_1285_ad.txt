codebook is
available
at https://crocs.fi.muni.cz/public/papers/
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:37:33 UTC from IEEE Xplore.  Restrictions apply. 
637
1. Participant backgroundExplores participants' background in developingcryptographic code.2. Library / Primitive properties and decisionsExplores properties of participants's library and theirrelationship.3. Tool awarenessExplores participants' knowledge of tools for testing andverifying the constant-time property.4. Tool useExplores participants' experience with using the tools.5. Hypothetical tool use5a. Dynamic instrumentation5b. Statistical runtime tests5c. Formal analysisRandomizedorderExplores participants' likeliness of using the toolsin hypothetical scenarios.6. MiscellaneousAsks for participant feedback and general comments.E. Limitations
A. Survey Participants
Like all surveys, our research suffers from multiple biases,
including opt-in bias and self-reporting bias. However, we
were pleasantly surprised that for 27 out of the 36 libraries
we selected, we received at least one valid response. Partici-
pants may over-report desirable traits (like caring about side-
channel attacks or protecting against them), and underplaying
negative traits (like making decisions ad-hoc). However, their
reporting generally tracked with official documents and our a
priori knowledge about the libraries. The projects represent
a selection, and are not representative of all cryptographic
libraries. However, we took great care in inviting participants
corresponding to a variety of prominent, widely used libraries
as well as smaller but popular libraries and primitives, as
assessed by multiple authors who work in this space.
F. Data cleaning & Presentation
We emailed 201 4 listed as most active contributors to 36
libraries/primitives, finding alternate emails for those emails
that bounced. 2 emailed us to tell us that they did not think
they could meaningfully contribute. In total, 71 started the
survey. We removed all 25 incomplete responses. We removed
two participants because they gave responses about a project
of their own, instead of the library we asked them about.
From here, we report results only for the 44 valid participants.
For statistical testing and figures for hypothetical tool use, we
report results for the 36 participants who gave answers for all
three tool groups. We merged answers of participants talking
about using a ctgrind-like approach but without the use of
ctgrind itself (as it is no longer necessary as Valgrind can
directly do this) into the ctgrind tool answers.
Participants spent an average of 32 minutes on the survey,
and left rich free text comments. We generally received
positive feedback and high interest in our work, and 35 asked
to be sent our results, with 33 agreeing to be contacted for
follow-up questions. Whenever we report results at the library
level, we merge qualitative answers given by all participants
corresponding to that library. Whenever the answers are addi-
tive, we add them together without reporting a conflict (e.g.
when one developer tests a library in one way while another
one tests it a different way, we report both). When the answers
are claims of a level (e.g. resistance to timing attacks) we
report the highest claimed. Otherwise, whenever we encounter
conflicting opinions, we report on this conflict.
IV. RESULTS
In this section, we answer our research questions based
on the results of our survey. Between full awareness and
low levels of protection against timing attacks, we identify
reasons for (not) choosing to develop and verify constant-time
code, including a lack of (easy-to-use) tooling, tradeoffs with
competing tasks, understandable concerns and misconceptions
about current
tooling. We identify that participants would
generally like the guarantees offered by tools, but fear negative
experiences, code annotations and problems with scalability.
4From now on, we use the
symbol to denote the participants.
Library developers: We successfully recruit experienced
cryptographic library developers, including the most active
contributors and decision-makers. We ended up with 44
recruited via direct invitation. Of our participants, 4 were the
only developer in their project, 9 were project leads, 11 were
core developers, 19 were maintainers, 11 were committers,
3 were contributors without commit rights. These classes are
non-exclusive self-reports. 40 said they were involved in the
library decision processes, while only 4 were not involved.
Participants had strong backgrounds in cryptographic de-
velopment, reporting a median of 10 years of experience
(sd = 7.75), and qualitatively reporting strong engagement
with various projects, for example reporting involvement in
security certifications: “I’ve worked on open source and closed
source cryptography libraries, dealt with various Common
Criteria EAL4+ products” (P1). As for the participants’ con-
crete background in cryptography, 17 reported an academic
background, 15
took some classes on cryptography, 32
had on the job experience, 6 teach cryptography, for 15
cryptography is (also) a hobby, 27 have industry experience
in cryptography.
Libraries: We ended up with participants from 27 promi-
nent libraries, such as OpenSSL, BoringSSL, mbedTLS or
libgcrypt. Participants gave or linked to descriptions of a broad
range of use cases for cryptographic libraries. As intended
platforms, 23 gave servers, 22 desktop, 14 embedded device
(with OS, 32 bit), 4 mobile, and 1 micro-controller (no OS,
8/16 bit). For targets, 7 stated TLS, 12 protocols, 2 services,
1 cloud, 2 operating systems, 1 crypto-currency, and 2 corpo-
rate internal purposes. Libraries had varying decision-making
processes: 9 made decisions by discussion, 2 by voting, 3 by
consensus, and for 11, decisions were made by the project
leads who had a final say.
B. Answering Research Questions
1) Threat models (RQ1a): Here, we answer the research
question whether timing attacks are part of library developers’
threat models (RQ1a). We found that all participants were
aware of timing attacks. Generally, when a threat model is
defined for a cryptographic library, it mostly includes timing
attacks. However, strict and absolute adherence to constant-
time code is most often not required. In practice, developers
tend to distinguish vulnerabilities that are “easy” to exploit
(e.g. remote timing attacks) from the others (e.g. locally ex-
ploitable attacks). When asked specifically about the library’s
threat models with respect to side-channel attacks, 20 libraries
claimed remote attackers are in their threat model, 16 included
local attackers, 1 included speculative execution attacks, 2
included physical attacks and 2 included fault attacks. Some
libraries expressed that they consider some classes of attacks
in their threat model if they are easy to mitigate, 2 would do
so for local attacks and 1 for physical attacks. The general
attitude towards side-channel attacks varied, 2 said that all
side-channel attacks are outside their threat model and 10
said that their protections against side-channel attacks are best
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:37:33 UTC from IEEE Xplore.  Restrictions apply. 
638
effort. For example, one participant said: “Best-effort constant-
time implementations. CPU additions and multiplications are
assumed to be constant-time (platforms such as Cortex M3
are not officially supported).” (P2) Another one implied a
progressive widening of their threat model regarding timing
attack in their statement: “Protections against remote attacks,
and slow movement to address local side channels, though the
surface is wide.” (P3)
In a follow up question, 23 libraries agreed that timing
attacks were considered a relevant threat for the intended use
of the library and its threat model, while this was not true for
2 libraries. We did not get this information for 2 libraries.
Reasons for considering timing attacks as relevant for their
threat model were given as the ease of doing so (2), the threats
of key-recovery in asymmetric cryptography (3), user demands
(1), fear of reputation loss (1), use in a hostile environment
(6), that attacks get smarter (1), the (rising) relevance of timing
attacks (9), personal expectations (5), a connected environment
(2), or the large scope of the library/of timing attacks (3).
Reasons for not considering timing attacks as part of their
threat model were stated as this not being a goal of the library
(2) or that they only consider more “practical” attacks.
2) Resistance against
timing attacks (RQ1b): Here, we
answer the research question whether libraries claim resis-
tance against timing attacks (RQ1b). Many libraries do not
have a systematic approach to address timing attacks; they
only consider fixing “serious” vulnerabilities that could be
exploited in practice. This might result in vulnerable code
that can be exploited later with better techniques of recovering
leaking information. We also encountered differing answers of
different participants regarding suitedness of random delays
as a mitigation. Out of the 27 total libraries, 13 claimed
resistance against timing attacks. An additional 10 claimed
partial resistance, 3 claimed no resistance, and for 1, we
obtained no information.
We also asked how the development team decided to protect
against timing attacks. For 4 libraries, participants reported
that one person made this decision, for 12 it was a team
decision, for 2 it was a corporate decision (where high-level
management makes a decision or the team decided locally
based on a corporate mission statement), for 14 libraries,
participants reported that a priority trade-off caused their
decision (e.g., lack of time to fully enact the decision) and
5 inherited the decision from previous projects or developers.
For 6 it was obvious that they needed to protect against
timing attacks. For example, one participant stated: “There
was no decision, not even a discussion. It was totally obvious
for everybody right
that protection against
timing attacks is necessary.” (P4) Another one said: “It’s just
how you write cryptographic code, every other way is the
wrong approach (unless in very specific circumstances or if
no constant-time algorithm is known).” (P5) Another stated
from the start
“It became clear that these attacks transition from being
an "academic interest" to a “real world problem” on a
schedule of their own development. If something is noticed
we now tend to favor elimination on first sight without
waiting for news of a practical attack.” (P6)
Contrarily, another said:
“Basically a tradeoff of criticality of the algorithm vs
practicality of countermeasures. Something very widely
used (eg RSA, AES, ECDSA) is worth substantial efforts
to protect. Something fairly niche (eg Camellia or SEED
block ciphers) is more best-effort” (P7)
This reasoning of waiting for attacks to justify expending
the effort was also reported by another participant: “For many
cases there aren’t enough real world attacks to justify spending
time on preventing timing leaks.” (P8)
3) Timing attack protections (RQ2a): Here, we answer the
research question how developers choose to protect against
timing attacks (RQ2a). Developers address timing attacks in
various ways, for example by implementing constant-time
hacks (e.g. constant selecting), implementing constant-time
algorithms of cryptographic primitives, using special hardware
instructions (CMOV, AES-NI), scatter-gathering for data ac-
cess, blinding secret inputs, and slicing. Many are interested
and willing to invest effort into this - to various degrees, as
P9 puts it: “[T]hey’re not that hard to mitigate, at least with
the compilers I’m using right now” (P9). Others are deterred
by the lack of (easy-to-use) tooling.
We asked developers of the 23 libraries who considered
timing attacks at least partially if and how their library protects
against timing attacks.
For 2 libraries, participants reported that they use hardware
features (instead of leak-prone algorithms) that protect from
timing attacks such as AES-NI. For example, P7 said: “AES
uses either hardware support, Mike Hamburg’s vector permute
trick, or else a bytesliced version.” (P7)
For 21 libraries, participants said that they use constant-
time code practices, which should in theory mean that code
is constant-time by construction, but may be vulnerable to
timing attacks after compilation. For example, P2 explained
that: “Conditional branches and lookups are avoided on
secrets. Assembly code and common tricks are used to prevent
compiler optimizations.” (P2)
For 9 libraries, participants explained that
they choose
known-to-be constant-time algorithms, but may suffer from
miscompilation issues and end up non-constant-time. As an
example, P7 said: “If I know of a "natively" const
time
algorithm I use it (eg DJB’s safegcd for gcd).” (P7)
For 7 libraries, participants said they use “blinding”, which
means using randomization to “blind” inputs on which com-
putation is performed, thereby destroying the usefulness of the
leak. As P7 said: “If blinding is possible [...] it is used, even
if the algorithm is otherwise believed constant-time. ” (P7)
For 2 libraries, participants said that they protect through
bitslicing, i.e., the implementation uses parallelization on parts
of the secrets, hiding leaks. As one participant described: “For
instance, the constant-time portable AES implementations use
bitslicing.” (P11)
For 2 libraries, participants reported protecting by “assem-
bly”, i.e., they have a specialized low-level implementation for
protecting against compilers doing non-constant-time trans-
formations. One participant noted the prohibitive cost of this
practice, explaining:
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:37:33 UTC from IEEE Xplore.  Restrictions apply. 
639
“We do not write all constant-time code in assembly
because of
is
possible that the compiler may break the constant-time
property. We spot-check that using Valgrind.” (P12)
the cost of carrying assembly code. It
For 1 library, timing leaks are made harder to detect by
adding random delays.
they only protect a choice of modules:
Most developers focus on asymmetric crypto. Some do not
consider old primitives, such as DES, which is still used in
payment systems as Triple-DES. For 5 libraries, participants
stated that
those
libraries have multiple implementations, of which only some
might be constant-time, maybe even insecure by default.
“Legacy algorithms like RC4 and DES are out of scope.
If you use the  "BIGNUM" APIs to build
custom constructions, it’s probably leaky, since bignum
width management is complex.” (P13)
also mentions bignum libraries being specifically hard to
secure. This claim is supported by academic literature as well:
“lazy resizing of Bignumbers in OpenSSL and LibreSSL yields
a highly accurate and easily exploitable side channel” [77].
For 1 library, protection against timing attacks was reported
to be still in progress, e.g., they try to use constant-time coding
practices throughout the library, but this is still in development
due to large legacy code base.
“All decisions in a side project are limited by the available
resources. There’s a report about a new attack which
proposes a new counter-measure: Does someone have the
time to implement it? Yes - cool, let’s do it. No - fine, let’s
put it on the ToDo list.” (P15)
and “Very early on in its development these guarantees were
much weaker, and in a few cases, approaches were used that
turned out to be known to be imperfect.” (P16) were two
answers from participants of libraries being in very different
phases of solving this problem.
4) Testing of
timing attack resistance (RQ2b, RQ2c):
In Software Engineering, testing code for the properties it
should achieve is commonplace and generally considered best
practice [78]. We therefore were interested in the practice of
testing and verification for constant-time also. Here, we answer
the research questions whether, how, and how often libraries
test for/verify resistance against timing attacks (RQ2b, RQ2c).
For 21 libraries, at least some type of testing was done, of
which 14 were fully, and 7 were partially tested. 6 were not
tested including the 2 libraries which claimed timing attacks
are not relevant. 24 personally tested their libraries.
Of those, 12 stated they have tested manually, and 11 stated
they tested automatically. Those two answers are not exclusive,
since 7 libraries which test code automatically have also been
tested manually. For manual testing, 6 libraries analyzed (parts
of) their source code, 4 libraries analyzed (parts of) their
binary, 5 did manual statistical runtime testing for leakage,
and 1 ran the code and looked at execution paths, debugging
as it ran. “Originally, me, a glass of bourbon, and gdb were a
good trio. But that got old pretty quick. (The manual analysis
part – not the whiskey.)” (P17) conveys the experience quite
graphically.
For those who did automated testing, 9 libraries used a
Valgrind-based approach, 2 used ctgrind, 1 used Memsan, 1
used TriggerFlow, 1 used DATA, and 1 reported automated
statistical testing without specifying further.
For the participants who did at least partial testing for
resistance to timing attacks, we asked for testing frequency.
For 1, the testing was only done once. For 11, participants
reported manual or occasional testing. For 4, participants re-
ported testing on release. For 6 libraries, participants reported
that testing for resistance to timing attacks was part of their
continuous integration. For 11 libraries, we did not obtain
information on testing or testing frequency. These varying
answers suggest that despite a common awareness of timing
attacks, cryptographic developers never came to a consensus
on the best way to address timing attacks in practice.
5) Tool awareness (RQ3a):
In order to effectively test,
developers should be able to leverage existing tooling created
for the purpose of testing and/or verifying that source code,
or compiled code, runs in constant time. Here, we answer the
research question whether participants are aware of the exis-
tence of such tooling (RQ3a). We asked participants whether
they are aware of tools that can test or verify resistance
against timing attacks, also showing them a list of tools from
Table I. We asked them whether they had heard about any of
those tools with regards to verifying resistance against timing
attacks. Table III shows the results with 33 being aware of
at least one tool and 11 being unaware of any tool. ctgrind
was most popular (27 heard of it; 17 had tried to use it),
followed by ct-verif (17 heard of it; only 3 tried to use it)
and MemSan (8 heard of it; 4
tried to use it). DATA had
been used by 2 , all others by no more than 1 . Individual