oriented fuzzers as well. We have seen that ParmeSan can be
between 37% to 876% faster at triggering bugs than other
state-of-the-art fuzzer.
In two cases, ParmeSan could ﬁnd
bugs that none of the other fuzzers could ﬁnd.
9 Related work
In the software engineering community, search-based test
data generation has been common for a number of years [24,
30, 31].
In a security context this approach is known as
fuzzing.
Greybox Fuzzing Greybox fuzzing has been successfully
applied to fuzzing a large number of programs [17,47]. Fair-
Fuzz [26] augments AFL to prioritize seeds that exercise un-
common branches to improve branch coverage. Steelix [28]
uses instrumentation to record comparison progress, allow-
ing it to solve so-called “magic bytes” that need to be ﬁxed
not to quit the program at an early stage.
VUzzer [36] ﬁrst suggested using dynamic data-ﬂow anal-
ysis (DFA) in a greybox fuzzing strategy, allowing the in-
put mutation to focus on the bytes that affect branches.
ParmeSan shows DFA can also be used to accurately aug-
ment the control-ﬂow graph for direct fuzzing purposes.
REDQUEEN uses a lightweight input-to-state correspon-
dence mechanisms as an alternative to data-ﬂow analysis [3].
Angora [9] uses a gradient descent-based strategy to solve
branch constraints in an efﬁcient manner. NEUZZ [40] uses
neural networks to approximate the discrete branching be-
havior of a target application and uses this information to im-
plement a similar gradient-guided optimization as Angora.
Similarly to Matryoshka [10], ParmeSan relies on control-
ﬂow and data-ﬂow analysis to augment the fuzzing process.
However, ParmeSan relies on such information to augment
the CFG and ﬁxing indirect calls, rather than using it to solve
constraints.
Directed Greybox Fuzzing Böhme & al.
introduce di-
rected greybox fuzzing [4] with AFLGo. AFLGo takes a set
of predetermined targets and tries to guide the fuzzing pro-
cess in that direction. Unlike ParmeSan, AFLGo cannot op-
erate as a drop-in replacement for coverage-guided fuzzing,
as it includes no generic target acquisition analysis. Hawk-
eye [8] improves upon the ideas in AFLGo by supporting in-
direct calls using static alias analysis. While Hawkeye sup-
ports reaching targets via indirect calls, unlike ParmeSan’s
dynamic CFG distance calculation, the static call-target anal-
ysis incurs overapproximations and does not take the input
seed into account for distance calculation.
Driller [43] introduces hybrid fuzzing. By only using sym-
bolic execution selectively for a smaller compartments of the
total program, it is able to avoid path explosion common
to prior symbolic execution approaches, and is thus able to
scale to larger programs. KATCH utilizes static analysis and
symbolic execution to generate inputs for increasing patch
test coverage [29]. QSYM [46] introduces a new symbolic
execution engine tailored to hybrid fuzzing, which is able to
scale to larger programs than previous attempts at symbolic
execution. TaintScope [45] uses tainting and symbolic exe-
cution to avoid the target program exiting an an early stage
due to invalid checksums in the input. A similar approach is
taken by T-Fuzz [34], which transforms the target program
by removing hard-to-solve checks to more easily reach pos-
sible bugs in the program. After a possible bug is found,
T-Fuzz tries to reconstruct the input with symbolic execution
such that the input passes the checks and triggers the deep
bug.
Another use case for sanitizers in fuzzing that builds on
similar ideas is the concurrent work presented by Chen et
al. in SAVIOR [11], which suggests using the UBSan san-
itizer to improve hybrid fuzzing.
It solves constraints for
UBSan checks to direct the fuzzing process towards actual
bugs, avoiding costly concolic execution for many branches
that are less prone to bugs. Note that this approach is not
directly applicable to sanitizers, such as ASAN, that use in-
ternal datastructures (e.g., shadow memory).
In contrast,
ParmeSan’s generic dynamic taint tracking strategy makes
it sanitizer-agnostic. This allows ParmeSan to use all avail-
able LLVM sanitizers for more ﬁne-grained targeting of bug
classes as shown in Section 8.3.
In a similar manner to ParmeSan, Hercules [35] uses dy-
namic CFG reconstruction techniques to reach bugs. While
Hercules focuses on bug reproducibility (i.e., generating a
crashing input given a target application and a crash report),
ParmeSan focuses on ﬁnding bugs without the knowledge
that a certain crash exists (i.e., generating a crash given a tar-
get application). Hercules augments the CFG with indirect
calls and tainting information to satisfy conditions for reach-
USENIX Association
29th USENIX Security Symposium    2301
ing a target crash site. ParmeSan uses similar information,
but instead uses it to improve distance calculations with bet-
ter estimation of indirect call targets, given the input bytes
that the fuzzer is mutating.
10 Conclusion
We presented ParmeSan, a sanitizer-guided greybox fuzzing
pipeline. ParmeSan leverages off-the-shelf sanitizers, not
only for detecting vulnerabilities as commonly used by prior
fuzzers, but to actively guides the fuzzing process towards
triggering the sanitizer checks. We identiﬁed a number of
challenges in sanitizer-guided fuzzing, and discussed how
ParmeSan addresses them. ParmeSan shows that off-the-
shelf sanitizers are useful not only for bug detection, but
also for ﬁnding interesting fuzzing targets that match real-
world bugs. ParmeSan trivially retargets the fuzzing strat-
egy to different classes of bugs by switching to a different
sanitizer, all in an automated and blackbox fashion. Our ex-
perimental results show that ParmeSan ﬁnds many classes of
bugs with signiﬁcantly lower time-to-exposure (TTE) than
state-of-the-art fuzzers. ParmeSan is 37% faster than ex-
isting state-of-the-art coverage-based fuzzers (Angora) and
288% faster than directed fuzzers (AFLGo) when covering
the same set of bugs. Techniques used by ParmeSan, such as
taint-enhanced input mutation and dynamic CFG construc-
tion can further beneﬁt other fuzzers. To foster further re-
search and encourage reproducibility, we will open-source
ParmeSan upon acceptance of the paper.
11 Acknowledgments
We thank our shepherd, Aurélien Francillon, and the anony-
mous reviewers for their feedback. This work was sup-
ported by the EU’s Horizon 2020 research and innovation
programme under grant agreement No. 786669 (ReAct), by
the Netherlands Organisation for Scientic Research through
grants 639.023.309 VICI “Dowsing” and 639.021.753 VENI
“PantaRhei”, by the United States Ofﬁce of Naval Research
(ONR) under contract N00014-17-1-2782, and by Cisco Sys-
tems, Inc. through grant #1138109. Any opinions, ﬁndings,
and conclusions or recommendations expressed in this pa-
per are those of the authors and do not necessarily reﬂect the
views of any of the sponsors or any of their afﬁliates.
References
[1] DataFlowSanitizer.
docs/DataFlowSanitizer.html
30-March-2019.
https://clang.llvm.org/
. Online; accessed
[2] UndeﬁnedBehaviorSanitizer. https://clang.llvm.
.
org/docs/UndefinedBehaviorSanitizer.html
Online; accessed 30-March-2019.
[3] Cornelius Aschermann,
Sergej Schumilo, Tim
Blazytko, Robert Gawlik,
and Thorsten Holz.
Redqueen: Fuzzing with input-to-state correspon-
In Network and Distributed System Security
dence.
Symposium (NDSS 2019), 2019.
[4] Marcel Böhme, Van-Thuan Pham, Manh-Dung
Nguyen, and Abhik Roychoudhury. Directed greybox
In Proceedings of the 2017 ACM SIGSAC
fuzzing.
Conference
and Communications
Security, pages 2329–2344. ACM, 2017.
on Computer
[5] Marcel Böhme, Van-Thuan Pham, and Abhik Roy-
choudhury.
Coverage-based greybox fuzzing as
In Proceedings of the 2016 ACM
markov chain.
SIGSAC Conference on Computer and Communica-
tions Security, CCS ’16, pages 1032–1043, New York,
NY, USA, 2016. ACM.
[6] Cristian Cadar, Daniel Dunbar, Dawson R Engler, et al.
KLEE: Unassisted and Automatic Generation of High-
Coverage Tests for Complex Systems Programs.
In
Symposium on Operating Systems Design and Imple-
mentation (OSDI), volume 8, pages 209–224, 2008.
[7] Hongxu Chen, Yuekang Li, Bihuan Chen, Yinxing
Xue, and Yang Liu. Fot: a versatile, conﬁgurable, ex-
tensible fuzzing framework. In Proceedings of the 2018
26th ACM Joint Meeting on European Software En-
gineering Conference and Symposium on the Founda-
tions of Software Engineering, pages 867–870. ACM,
2018.
[8] Hongxu Chen, Yinxing Xue, Yuekang Li, Bihuan
Chen, Xiaofei Xie, Xiuheng Wu, and Yang Liu. Hawk-
eye:
In
Proceedings of the 2018 ACM SIGSAC Conference on
Computer and Communications Security, pages 2095–
2108. ACM, 2018.
towards a desired directed grey-box fuzzer.
[9] Peng Chen and Hao Chen. Angora: Efﬁcient fuzzing
by principled search. In IEEE Symposium on Security
and Privacy (SP), pages 711–725. IEEE, 2018.
[10] Peng Chen, Jianzhong Liu, and Hao Chen. Ma-
In ACM
tryoshka: fuzzing deeply nested branches.
Conference on Computer and Communications Secu-
rity (CCS), London, UK.
[11] Yaohui Chen, Peng Li, Jun Xu, Shengjian Guo, Run-
dong Zhou, Yulong Zhang, Long Lu, et al. SAVIOR:
Towards Bug-Driven Hybrid Testing. In IEEE Sympo-
sium on Security and Privacy (SP), 2020.
[12] Yuanliang Chen, Yu Jiang, Fuchen Ma, Jie Liang,
Mingzhe Wang, Chijin Zhou, Xun Jiao, and Zhuo
Su. Enfuzz: Ensemble fuzzing with seed synchroniza-
tion among diverse fuzzers. In 28th USENIX Security
2302    29th USENIX Security Symposium
USENIX Association
Symposium (USENIX Security 19), pages 1967–1983,
Santa Clara, CA, August 2019. USENIX Association.
[13] Maria Christakis, Peter Müller, and Valentin Wüstholz.
Guiding dynamic symbolic execution toward unveri-
In Proceedings of the 38th
ﬁed program executions.
International Conference on Software Engineering,
pages 144–155. ACM, 2016.
[14] LLVM Developers.
TySan: A type sanitizer.
https://lists.llvm.org/pipermail/llvm-dev/
2017-April/111766.html
19-March-2019.
, 2017. Online; accessed
[15] Brendan Dolan-Gavitt, Patrick Hulin, Engin Kirda,
Tim Leek, Andrea Mambretti, Wil Robertson, Freder-
ick Ulrich, and Ryan Whelan. Lava: Large-scale au-
In IEEE Symposium
tomated vulnerability addition.
on Security and Privacy (SP), pages 110–121. IEEE,
2016.
[16] Xiaoning Du, Bihuan Chen, Yuekang Li, Jianmin Guo,
Yaqin Zhou, Yang Liu, and Yu Jiang. Leopard: Iden-
tifying vulnerable code for vulnerability assessment
through program metrics. In Proceedings of the 41st In-
ternational Conference on Software Engineering, ICSE
’19, pages 60–71, Piscataway, NJ, USA, 2019. IEEE
Press.
[17] Shuitao Gan, Chao Zhang, Xiaojun Qin, Xuwen Tu,
Kang Li, Zhongyu Pei, and Zuoning Chen. Collaﬂ:
Path sensitive fuzzing. In IEEE Symposium on Security
and Privacy (SP), pages 679–696. IEEE, 2018.
[18] Vijay Ganesh, Tim Leek, and Martin Rinard. Taint-
based directed whitebox fuzzing. In Proceedings of the
31st International Conference on Software Engineer-
ing, pages 474–484. IEEE Computer Society, 2009.
[19] Xi Ge, Kunal Taneja, Tao Xie, and Nikolai Tillmann.
DyTa: Dynamic Symbolic Execution Guided with
Static Veriﬁcation Results. pages 992–994, 05 2011.
[20] Patrice Godefroid, Nils Klarlund, and Koushik Sen.
DART: Directed Automated Random Testing. In Pro-
ceedings of the 2005 ACM SIGPLAN Conference on
Programming Language Design and Implementation,
PLDI ’05, pages 213–223, New York, NY, USA, 2005.
ACM.
[21] Patrice Godefroid, Michael Y Levin, and David Mol-
SAGE: whitebox fuzzing for security testing.
nar.
Queue, 10(1):20, 2012.
[22] Inc. Google.
fuzzer-test-suite.
com/google/fuzzer-test-suite
cessed 30-March-2019.
https://github.
, 2018. Online; ac-
[23] Istvan
Haller,
Asia
Slowinska,
Matthias
Neugschwandtner, and Herbert Bos. Dowsing for
Overﬂows: A Guided Fuzzer to Find Buffer Boundary
Violations. In Presented as part of the 22nd USENIX
Security Symposium (USENIX Security 13), pages
49–64, Washington, D.C., 2013. USENIX.
[24] Mark Harman. Automated test data generation using
search based software engineering. In Proceedings of
the Second International Workshop on Automation of
Software Test, page 2. IEEE Computer Society, 2007.
[25] Chris Lattner and Vikram Adve. LLVM: A compilation
framework for lifelong program analysis & transforma-
tion. In Proceedings of the international symposium on
Code generation and optimization: feedback-directed
and runtime optimization, page 75. IEEE Computer So-
ciety, 2004.
[26] Caroline Lemieux and Koushik Sen. Fairfuzz: Tar-
geting rare branches to rapidly increase greybox
In Proceedings of the 33rd
fuzz testing coverage.
ACM/IEEE International Conference on Automated
Software Engineer-ing, 2018.
[27] Yiwen Li, Brendan Dolan-Gavitt, Sam Weber, and
Justin Cappos. Lock-in-pop: Securing privileged oper-
ating system kernels by keeping on the beaten path. In
2017 USENIX Annual Technical Conference (USENIX
ATC 17), pages 1–13, Santa Clara, CA, July 2017.
USENIX Association.
[28] Yuekang Li, Bihuan Chen, Mahinthan Chandramohan,
Shang-Wei Lin, Yang Liu, and Alwen Tiu. Steelix:
program-state based binary fuzzing. In Proceedings of
the 2017 11th Joint Meeting on Foundations of Soft-
ware Engineering, pages 627–637. ACM, 2017.
[29] Paul Dan Marinescu and Cristian Cadar. KATCH: high-
coverage testing of software patches. In Proceedings of
the 2013 9th Joint Meeting on Foundations of Software
Engineering, pages 235–245. ACM, 2013.
[30] Phil McMinn. Search-based software test data gener-
ation: A survey: Research articles. Softw. Test. Verif.
Reliab., 14(2):105–156, June 2004.
[31] Phil McMinn. Search-based software testing: Past,
present and future. In 2011 IEEE Fourth International
Conference on Software Testing, Veriﬁcation and Vali-
dation Workshops, pages 153–163. IEEE, 2011.
[32] Trail of Bits.
ProtoFuzz: A Protobuf Fuzzer.
https://blog.trailofbits.com/2016/05/18/
protofuzz-a-protobuf-fuzzer/
accessed 31-January-2019.
, 2016. Online;
USENIX Association
29th USENIX Security Symposium    2303
[33] Mathias Payer, Antonio Barresi, and Thomas R
Gross. Fine-grained control-ﬂow integrity through bi-
In International Conference on De-
nary hardening.
tection of Intrusions and Malware, and Vulnerability
Assessment, pages 144–164. Springer, 2015.
[34] Hui Peng, Yan Shoshitaishvili, and Mathias Payer. T-
In IEEE
Fuzz: fuzzing by program transformation.
Symposium on Security and Privacy (SP), pages 697–
710. IEEE, 2018.
[44] Jonas Wagner, Volodymyr Kuznetsov, George Candea,
and Johannes Kinder. High system-code security with
low overhead. In IEEE Symposium on Security and Pri-
vacy (SP), pages 866–879. IEEE, 2015.
[45] Tielei Wang, Tao Wei, Guofei Gu, and Wei Zou.
TaintScope: A checksum-aware directed fuzzing tool
for automatic software vulnerability detection. In IEEE
Symposium on Security and Privacy (SP), pages 497–
512. IEEE, 2010.
[35] V. Pham, W. B. Ng, K. Rubinov, and A. Roychoudhury.
Hercules: Reproducing crashes in real-world applica-
tion binaries. In 2015 IEEE/ACM 37th IEEE Interna-
tional Conference on Software Engineering, volume 1,
pages 891–901, May 2015.
[46] Insu Yun, Sangho Lee, Meng Xu, Yeongjin Jang, and
Taesoo Kim. QSYM: A practical concolic execution
In 27th USENIX
engine tailored for hybrid fuzzing.
Security Symposium (USENIX Security 18), pages 745–
761, 2018.
[36] Sanjay Rawat, Vivek Jain, Ashish Kumar, Lucian Co-
jocar, Cristiano Giuffrida, and Herbert Bos. VUzzer:
Application-aware Evolutionary Fuzzing. In Network
and Distributed System Security Symposium (NDSS),
February 2017.
[37] Konstantin Serebryany, Derek Bruening, Alexander
Potapenko, and Dmitriy Vyukov. AddressSanitizer: A
fast address sanity checker. 2012.
[38] Kostya Serebryany. Sanitize, fuzz, and harden your
C++ code. In USENIX Enigma, 2016.
[39] Kostya Serebryany.
Oss-fuzz-google’s continuous
fuzzing service for open source software. 2017.
[40] Dongdong She, Kexin Pei, Dave Epstein, Junfeng
Yang, Baishakhi Ray, and Suman Jana. NEUZZ: Efﬁ-
cient fuzzing with neural program smoothing. In IEEE
Symposium on Security and Privacy (SP), 2019.
[41] Stelios Sidiroglou-Douskos, Eric Lahtinen, Nathan Rit-
tenhouse, Paolo Piselli, Fan Long, Deokhwan Kim, and
Martin Rinard. Targeted automatic integer overﬂow
discovery using goal-directed conditional branch en-
forcement. In ACM Sigplan Notices, volume 50, pages
473–486. ACM, 2015.
[42] Dokyung Song, Julian Lettner, Prabhu Rajasekaran,
Yeoul Na, Stijn Volckaert, Per Larsen, and Michael
Franz. SoK: sanitizing for security. arXiv preprint
arXiv:1806.04355, 2018.
[43] Nick Stephens, John Grosen, Christopher Salls, An-
drew Dutcher, Ruoyu Wang, Jacopo Corbetta, Yan
Shoshitaishvili, Christopher Kruegel, and Giovanni Vi-
gna. Driller: Augmenting fuzzing through selective
symbolic execution. In NDSS, volume 16, pages 1–16,
2016.
[47] Michal Zalewski. American Fuzzy Lop: a security-
oriented fuzzer.
afl/ , 2010. Online; accessed 31-January-2019.
http://lcamtuf.coredump.cx/
[48] Mingwei Zhang, Rui Qiao, Niranjan Hasabnis, and
R Sekar. A platform for secure static binary instrumen-
tation. In ACM SIGPLAN Notices, volume 49, pages
129–140. ACM, 2014.
A Additional results
In this appendix, we include some additional results of our
evaluation of different components of ParmeSan, as well as
an evaluation of our target pruning strategy.
Impact of different components
A.1
In Table 7, we present the results on the Google fuzzer-
test-suite, where we individually disable each of the three
core components: lazy sanitizer optimization (lazysan), tar-
get pruning, and the dynamic CFG dyncfg. Overall, our re-
sults show that each component has a signiﬁcant impact on
fuzzing performance. Note that the lazysan optimization re-
quires the dyncfg component.
When disabling the lazysan component, we see a degra-
dation in TTE in almost every single case. The outliers are
the bugs in libssh and the memory leak in openssl , where
the performance improves when disabling lazysan. As dis-
cussed previously, this degradation in performance is due to
the fact that the sanitizer is disabled when triggering the bug.
Note that ParmeSan will still catch the bug, but triggering the
sanitizer might be delayed until the exploitation phase.
Overall, we see that the different individual components
each contribute signiﬁcantly to the total performance of
ParmeSan. For example, disabling the lazysan optimization,
increases the TTE by 25%. Likewise, our target pruning ac-
counts for 28% of the improvement. Without target pruning,
2304    29th USENIX Security Symposium
USENIX Association
Type Runs ParmeSan
Prog
UAF 10
1850
boringssl
200
10
BO
c-ares
49320
IO
5
freetype2
8761
UAF 10
pcre2
540
10
BO
lcms
BO
10
4123
libarchive
123
10
ML
libssh
2701
10