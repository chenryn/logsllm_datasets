263
226
复以及RPC对象。内存耗尽可能导致如下情况的发生。
就算没有其他副作用，同时处理的请求数量升高也会消耗更多的内存用于存放请求、回
内存
CPU缓存效率下降
RPC超时
CPU死锁或者请求卡住
线程卡住
队列过长
正在处理的（in-flight）请求数量上升
任务崩溃
因为处理请求需要较长的时间，同一时间服务器必须同时处理更多的请求（上升到
例如，
本地缓存的失效，进而降低CPU处理的效率。
CPU使用得越多，任务被分配到多个CPU核心上的几率越大，从而导致CPU核心
成更严重的过载。
这会导致服务器对请求实际进行的处理都被浪费了，而客户端可能会重试RPC，造
服务器过载时，对客户端RPC的回复会变慢，最终会超过客户端所设置的超时时间。
请求队列排队，这些请求无法被及时处理，而触发看门狗机制杀掉进程。
件服务器最终由于CPU资源不够而崩溃。如果看门狗机制是远端触发的，但是由于
理健康检查请求（Borg系统会将这种情况视为服务器已经失败，从而杀掉它）。
如果一个线程由于等待某个锁而无法处理请求，可能服务器无法在合理的时间内处
应对策略见本章后面“队列管理”小节。
这意味着延迟上升（因为所有请求都要排队一段时间），同时队列会使用更多的内存。
如果没有足够的资源以稳定的速度处理所有请求，服务器会逐渐将请求队列填满。
资源的耗尽可能会带来其他连锁问题）。
程数（在每个请求一个线程的编程模型下）、文件描述符，和后端服务器的资源（该
一定数量可能会开始进入队列排队）。这会影响其他所有的资源，包括内存、活跃线
件
成
已经失败
某种特定请求会定时发送给该服务器，
了任何工作。
第22章
，某任务可能会因为超过资源限制而被容器管理器驱逐（VM或者其他的），或
处理连锁故障
一有可能是软件服务器自己，或者发送请求的组件，或者是中间连接的网络。
如果没有完成任何工作，
）常常以一个定期唤醒的线程实现，
---
## Page 269
在上述这个复杂情景下，发生故障时可能没有时间仔细分析因果关系。尤其是在前端和
注意，很多资源的耗尽都会导致其他资源出现问题一
文件描述符（filedescriptor）不足可能会导致无法建立网络连接，进而导致健康检查失败。
的进程ID 数是有限的)。
线程可能会占用更多内存。在极端情况下，线程不足可能会导致进程ID数不足（Linux
线程不足可能会导致错误或者导致健康检查失败。
缓存命中率下降
Java垃圾回收（GC）速率加快，从而导致CPU使用率上升
假设如下场景：
次级现象看起来很像根本问题，这会使定位问题更困难。
资源之间的相互依赖
文件描述符
线程
9.CPU不足导致健康检查失败，从而触发了连锁故障。
8.后端服务器CPU或者线程不足。
1.某Java前端服务器GC参数没有被调优。
可能会导致后端任务过载。
可用内存的减少可能会导致应用层缓存的命中率降低，导致向后端发送更多的RPC，
螺旋”
导致GC触发次数增多，导致CPU资源的进一步减少。我们将此称之为“GC死亡
一个糟糕透顶的场景：由于CPU资源减少，请求处理速度变慢，内存使用率上升，
者程序自身逻辑会触发崩溃。
缓存命中率下降导致更多的请求被发往后端进行处理。
缓存数量降低意味着缓存中键值数量下降，从而导致命中率下降。
内存压力上升，同时由于固定内存分配比例的原因，用于缓存的内存数量减少。
同时处理的请求增多导致内存使用上升。
CPU不足导致请求处理变慢。
在高负载（但是在期待范围内）情况下，前端由于GC问题导致CPU不足。
连锁故障产生的原因和如何从设计上避免
，如果服务器为此增加更多线程，这些
一某个服务过载经常会出现一系列
1227
264
---
## Page 270
265
228
提供降级结果
使用负载压力测试得出服务器的极限，同时测试过载情况下的失败模式
下面描述了避免过载的几种策略，大致以优先级排序。
防止软件服务器过载
载上升，从而再次触发滚雪球效应。
务产生了错误，会导致负载均衡器不再向它们发送请求，进而使得其余软件服务器的负
会自动避免产生错误的软件服务器的负载均衡策略会将这个问题加剧一
件服务器越来越少。
务器都在很短的一段时间内接受了大量请求而进入不健康状态，导致能够处理请求的软
软件服务器崩溃很类似，越来越多的软件服务器呈现不健康状态，每个仍健康的软件服
可用容量的降低：软件服务器可能进入跛脚鸭状态或者无法处理健康检查。这种情况和
同样的，这些软件服务器可能对负载均衡层来说是处于不健康状态，从而导致负载均衡
那么请求速率必须降低到1,000QPS才能使整个系统恢复稳定。
任务能够承受过载请求的时间。在这个例子里，如果10%的任务目前可以正常处理请求
服务器数量通常取决于：系统重启任务的速度，该任务进入正常工作的时间和新启动的
容量不足的状态；通常仅仅只有一小部分的软件服务器可以正常处理请求。正常的软件
例如，如果某个服务在10,000QPS的水平下正常服务，但是当11,000QPS的时候进入
轰炸，几乎立即再次崩溃。
这种场景经常很难恢复，因为一旦某个软件服务器恢复正常，它就会接收到大量请求的
崩溃。这种问题经常如同滚雪球一样越来越严重，不多久全部服务器就会进入崩溃循环。
旦几个软件服务器由于过载而崩溃，其他软件服务器的负载可能会上升，从而使它们也
资源耗尽可能导致软件服务器崩溃。例如，这些服务器可能会由于内存超标而崩溃。一
服务不可用
后端由不同团队运维时，判断后端崩溃是由于前端缓存命中率下降可能非常困难。
连锁故障模式，降低负载到9.000QPS通常也无法恢复。这是因为这时该服务仍然处于
细节见本章后面的“流量抛弃和优雅降级”一节。
给用户返回低质量的，但是更容易计算的结果。这里的策略取决于每个服务自己，
源会耗尽，以及资源耗尽产生的效果。细节请见本章后面的“连锁故障的测试”一节。
为了避免过载，这一步是最重要的。除非在真实环境下测试，否则很难预测哪种资
第22章
处理连锁故障
一某几个后端任
---
## Page 271
注3通常由于地理分布因素，这并不是一个很好的假设。见第2章“任务和数据的组织方式”小节。
求才会进入队列，这种情况会导致线程池和队列的同时饱和。
量是固定的。在这个理想化的情景下，只有在请求速率超过单个请求的处理速率时，请
如果请求速率和单个请求处理耗时是固定的，那么排队就没有必要：同时运行的线程数
通常情况下，当队列排满时，服务器会拒绝新的请求。
接收到的请求将会进入队列，线程池中的某线程会将请求从队列中取出，进行实际处理。
队列管理
以根据需要动态增加容量，这可能防止过载发生，但是适当地进行容量规划还是必要的。
题、网络分区事件，或者突发性流量增长，都会创造意料之外的负载问题。有些系统可
者计划外的事件导致大部分集群容量同时下线时，连锁反应是不可避免的。负载均衡问
进行容量规划只能减少触发连锁反应的可能性，但是并不能完全避免。当一个计划内或
进行容量规划
上层系统应该主动拒绝请求
在过载情况下主动拒绝请求
好的容量规划可以降低连锁反应发生的可能性。容量规划应该伴随着性能测试进行，
注意，由于速率限制实现中一般不会考虑服务整体健康程度的因素，它可能并不能
软件服务器应该保护自己不进入过载崩溃状态。当前端或者后端进入过载模式时，
来以N+2模式运行该服务。
服务负载平均分布，注3而该服务的峰值负载是19,000QPS，我们则需要大约6个集群
以确定可能导致服务失败的负载程度。例如，如果每个集群的临界点是5,000QPS，
·在每个任务自身，避免负载均衡层的随机扰动导致软件服务器过载。
·在反向代理层，通过针对请求的某种特性进行数量限制（如IP地址），来缓解和
浪费。速率限制可以具体在以下位置实现：
阻止一个已经发生了的连锁故障。简单的速率限制实现很有可能会导致一些容量的
应尽早尽快地将该请求标记为失败。细节见本章后面的“负载抛弃和优雅降级”一节。
在负载均衡器层，在服务进入全局过载时主动丢弃请求。取决于该服务的实现和
避免拒绝服务攻击，避免攻击性客户端的影响。
步请求，但是保留用户交互型请求）。
是有选择性的（丢弃非最近用户发来的请求，或者丢弃低优先级请求，如背景同
复杂度，这种丢弃可能是针对所有请求的（丢弃超过XQPS的所有请求），或者
防止软件服务器过载
229
266
---
## Page 272
230
的算法来进行结果排序。
而不是搜索全部存在硬盘上的数据。该服务或者可以采用一种不那么精确（但是更快）
算时间的。例如，一个搜索类型的应用可能在过载情况下仅仅搜索保存在内存中的数据，
在某些应用程序中，是可以通过降低回复的质量来大幅减少所需的计算量或者所需的计
优雅降级（gracefuldegradation）可在流量抛弃的基础上进一步减少服务器的工作量。
其他更复杂的手段包括通过精确识别客户端的方式来更有选择地丢弃部分任务，或者将
迟和截止时间”
层向下传递RPC截止时间的策略结合起来，工作得十分好，可参见本章后面的“请求延
可控延迟算法（CodDel）（参见文献[Nic12]），或者类似的方式更进一步地避免处理那些
时处理的请求超过一定量时，开始直接针对新请求返回HTTP503（服务不可用）。
限制队列长度的详细讨论请参见上一小节“队列管理”。例如，一个有效的办法是当同
成的现象。也就是使软件服务器在负载极限时，尽可能地再多做一些有用的工作。
标是避免该软件服务器出现内存超限，健康检查失败，延迟大幅升高，或者其他过载造
流量抛弃（load shedding）是指在软件服务器临近过载时，主动抛弃一定量的负载。
流量抛弃和优雅降级
时间和突发性流量的频率和大小来计算队列长度。
发性”负载的系统，或者请求模式经常变动的软件服务器通常基于线程数量、请求处理
用无队列软件服务器，在线程满的时候转移负载到其他服务器上。而另外一些经常有“突
当服务处理速度无法跟上请求到达速率时，尽早拒绝请求会更好。例如，Gmail通常使
对一个流量基本稳定的服务来说，队列长度比线程池大小更小会更好（如50%或更小）。
才能处理完成，大部分时间都消耗在排队过程中。
而单个线程处理单个请求的耗时是100ms。如果队列处于满载状态，每个请求都需要1.1s
在队列中的排队请求消耗内存，同时使延迟升高。例如，如果队列大小是线程数量的10倍，
请求按优先级排序，按优先级处理等。这些策略更适用于一些基础的共享服务采用。
请求：这时回复第一个RPC请求已经没有任何意义，因为它已经没用了！这个策略和层
因素已经等待了10s，很有可能该用户已经放弃了，已经刷新了浏览器又发送了一个新
不值得处理的请求（参见文献[Mau15]）。如果某个用户的Web搜索请求由于RPC排队
另外的做法包括将标准的先入先出（FIFO）队列模式改成后入先出（LIFO），以及使用
一种简单的流量抛弃实现方式是根据CPU使用量、内存使用量及队列长度等进行节流。
第22章处理连锁故障
一节。
目
---
## Page 273