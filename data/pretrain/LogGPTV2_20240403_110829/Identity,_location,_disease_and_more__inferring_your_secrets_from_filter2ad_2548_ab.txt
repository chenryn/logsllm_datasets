user and also minimize its impact on a smartphone’s performance.
On the other hand, the adversary has the resources to analyze the
data gathered by the app using publicly available background in-
formation, for example, through crawling the public information
released by social networks, searching Google Maps, etc. Such
activities can be performed by ordinary Internet users.
What the adversary can do. In addition to collecting and analyzing
the information gathered from the victim’s device, a zero-permission
malicious app needs a set of capabilities to pose a credible privacy
threat. Particularly, it needs to send data across the Internet without
the INTERNET permission. Also, it should stay aware of the sys-
tem’s situation, i.e., which apps are currently running. This enables
the malicious app to keep a low proﬁle, start data collection only
when its target app is being executed. Here we show how these
capabilities can be obtained by the app without any permission.
• Networking. Leviathan’s blog describes a zero-permission tech-
nique to smuggle out data across the Internet [16]. The idea is to
let the sender app use the URI ACTION_VIEW Intent to open a
browser and sneak the payload it wants to deliver to the parameters
of an HTTP GET from the receiver website. We re-implemented this
technique in our research and further made it stealthy. Leviathan’s
approach does not work when the screen is off because the browser
is paused when the screen is off. We improved this method to
smuggle data right before the screen is off or the screen is being un-
locked. Speciﬁcally, our app continuously monitors /lcd_power
(/sys/class/lcd/panel/lcd_power on Galaxy Nexus),
an LCD status indicator released under the sysfs. Note that this
indicator can be located under other directory on other devices, for
example, sys/class/backlight/s6e8aa0 on Nexus Prime.
When the indicator becomes zero, the phone screen dims out, which
allows our app to send out data through the browser without being
noticed by the user. After the data transmission is done, our app can
redirect the browser to Google and also set the phone to its home
screen to cover this operation.
• Situation awareness.
Our zero permission app deﬁnes
location
a list of target applications such as stock, health,
applications and monitors their activities.
It ﬁrst checks
whether those packages are installed on the victim’s system
(getInstalledApplications()) and then periodically calls
ps to get a list of active apps and their PIDs. Once a target is
found to be active, our app will start a thread that closely moni-
tors the /proc/uid_stats/[uid] and the /proc/[pid]/
of the target.
3. GETTING YOUR IDENTITY, HEALTH
AND INVESTMENT INFORMATION
In this section, we report our study on information leaks from
public data usage statics.
3.1 Usage Monitoring and Analysis
Mobile-data usage statistics. Mobile data usages of Android are
made public under /proc/uid_stat/ (per app) and
1019Analysis methodology. The monitor cannot always produce deter-
ministic outcomes: when sampling the same packet sequence twice,
it may observe two different sequences of increments from the usage
statistics. To obtain a reliable trafﬁc ﬁngerprint of a target app’s
activity we designed a methodology to bridge the gap between the
real sequence and what the monitor sees.
Our approach ﬁrst uses Shark for Root to analyze a target app’s
behavior (e.g., click on a button) ofﬂine - i.e in a controlled con-
text - and generate a payload-sequence signature for the behav-
ior. Once our monitor collects a sequence of usage increments
from the app’s runtime on the victim’s Android phone, we com-
pare this usage sequence with the signature as follows. Consider
a signature (··· , si, si+1,··· , si+n,··· ), where si,··· ,i+n are the
payload lengths of the TCP packets with the same direction (in-
bound/outbound), and a sequence (··· , mj,··· ), where mj is an
increment on a usage statistic (tcp_rcv or tcp_snd) of the di-
rection of si, as observed by our monitor. Suppose that all the
elements before mj match the elements in the signature (those prior
to si). We say that mj also matches the signature elements if either
mj = si or mj = si + ··· + si+k with 1 < k ≤ n. The whole
sequence is considered to match the signature if all of its elements
match the signature elements.
For example, consider that the signature for requesting the in-
formation about a disease condition ABSCESS by WebMD is
(458, 478, 492 →), where “→” indicates outbound trafﬁc. Us-
age sequences matching the signature can be (458, 478, 492 →),
(936, 492 →) or (1428 →).
The payload-sequence signature can vary across different mobile
devices, due to the difference in the User-Agent ﬁeld on the HTTP
packets produced by these devices. This information can be acquired
by a zero-permission app through the android.os.Build API,
which we elaborate in Appendix A.
3.2 Identity Inference
A person’s identity, such as name, email address, etc., is always
considered to be highly sensitive [35, 19, 15, 29] and should not be
released to an untrusted party. For a smartphone user, unauthorized
disclosure of her identity can immediately reveal a lot of private
information about her (e.g., disease, sex orientation, etc.) simply
from the apps on her phone. Here we show how one’s identity can
be easily inferred using the shared resources and rich background
information from Twitter.
Twitter is one of the most popular social networks with about
500 million users worldwide. It is common for Twitter users to use
their mobile phones to tweet extensively and from diverse locations.
Many Twitter users disclose there identity information which in-
cludes their real names, cities and sometimes homepage or blog
URL and even pictures. Such information can be used to discover
one’s accounts on other social networks, revealing even more in-
formation about the victim according to prior research [26]. We
also performed a small range survey on the identity information
directly disclosed from public Twitter accounts to help us better
understand what kind of information users disclose and at which
extend. By manually analyzing randomly selected 3908 accounts
(obvious bot accounts excluded), we discovered that 78.63% of
them apparently have users’ ﬁrst and last names there, 32.31% set
the users’ locations, 20.60% include bio descriptions and 12.71%
provide URLs. This indicates that the attack we describe below
poses a realistic threat to Android users’ identity.
The idea. In our attack, a zero-permission app monitors the mobile-
data usage count tcp_snd of the Twitter 3.6.0 app when it is
running. When the user send tweets to the Twitter server, the app
detects this event and send its timestamp to the malicious server
Figure 1: Monitor tool precision
Table 1: Performance overhead of the monitor tool: there the baseline is
measured by AnTuTu [8]
Baseline
Monitor Tool
Overhead
I/O
Total
595
3776
585
3554
5.8% 0.3% 11.6% -0.1% 1.7%
RAM
588
589
GPU
1816
1606
CPU
777
774
/sys/class/net/[interface] /statistics/ (per in-
terface). The former is newly introduced by Android to keep track
of individual apps. These directories can be read by any app directly
or through TrafficStats, a public API class. Of particular in-
terest here are two ﬁles /proc/uid_stat/[uid]/tcp_rcv
and /proc/uid_stat/[uid]/tcp_snd, which record the to-
tal numbers of bytes received and sent by a speciﬁc app respectively.
We found that these two statistics are actually aggregated from
TCP packet payloads: for every TCP packet received or sent by an
app, Android adds the length of its payload onto the correspond-
ing statistics. These statistics are extensively used for mobile data
consumption monitoring [5]. However, our research shows that
their updates can also be leveraged to ﬁngerprint an app’s network
operations, such as sending HTTP POST or GET messages.
Stealthy and realtime monitoring. To catch the updates of those
statistics in real time, we built a data-usage monitor that continu-
ously reads from tcp_rcv and tcp_snd of a target app to record
increments in their values. Such an increment is essentially the
length of the payload delivered by a single or multiple TCP pack-
ets the app receives and sends, depending on how fast the monitor
samples from those statistics. Our current implementation has a
sampling rate of 10 times per second. This is found to be sufﬁcient
for picking up individual packets most of the time, as illustrated in
Figure 1, in which we compare the packet payloads observed by
Shark for Root (a network trafﬁc sniffer for 3G and WiFi), when the
user is using Yahoo! Finance, with the cumulative outbound data
usage detected by our usage monitor.
From the ﬁgure we can see that most of the time, our monitor
can separate different packets from each other. However, there are
situations in which only the cumulative length of multiple packets is
identiﬁed (see the markers in the ﬁgure). This requires an analysis
that can tolerate such non-determinism, which we discuss later.
In terms of performance, our monitor has a very small memory
footprint, only 28 MB, even below that of the default Android key-
board app. When it is running at its peak speed, it takes about 7%
of a core’s cycles on a Google Nexus S phone. Since all the new
phones released today are armed with multi-core CPUs, the moni-
tor’s operations will not have noticeable impacts on the performance
of the app running in the foreground as demonstrated by a test de-
scribed in Table 1 measured using AnTuTu [8] with a sampling rate
of 10Hz for network usage and 50Hz for audio logging (Section
5). To make this data collection stealthier, we adopted a strategy
that samples intensively only when the target app is being executed,
which is identiﬁed through ps (Section 2.2).
010203040500500010000cumulative tcp.len in bytespacket sequencetcp_sndshark for rootthe total length of two packets1020stealthily. This gives us a vector of timestamps for the user’s tweets,
which we then use to search the tweet history through public Twitter
APIs for the account whose activities are consistent with the vector:
that is, the account’s owner posts her tweets at the moments recorded
by these timestamps. Given a few of timestamps, we can uniquely
identify that user. An extension of this idea could also be applied to
other public social media and their apps, and leverage other informa-
tion as vector elements for this identity inference: for example, the
malicious app could be designed to ﬁgure out not only the timing of
a blogging activity, but also the number of characters typed into the
blog through monitoring the CPU usage of the keyboard app, which
can then be correlated to a published post.
To make this idea work, we need to address a few technical
challenges. Particularly, searching across all 340 million tweets
daily is impossible. Our solution is using less protected data, the
coarse location (e.g, city) of the person who tweets, to narrow down
the search range (see Section 4).
Fingerprinting tweeting event. To ﬁngerprint the tweeting event
from the Twitter app, we use the aforementioned methodology to
ﬁrst analyze the app ofﬂine to generate a signature for the event.
This signature is then compared with the data usage increments
our zero-permission app collects online from the victim’s phone to
identify the moment she tweets.
Speciﬁcally, during the ofﬂine analysis, we observed the fol-
lowing TCP payload sequence produced by the Twitter app:
(420|150, 314, 580–720). The ﬁrst element here is the payload
length of a TLS Client Hello. This message normally has 420 bytes
but can become 150 when the parameters of a recent TLS session
are reused. What follow are a 314-byte payload for Client Key
Exchange and then that of an encrypted HTTP request, either a GET
(download tweets) or a POST (tweet). The encrypted GET has a
relatively stable payload size, between 541 and 544 bytes. When
the user tweets, the encrypted POST ranges from 580 to 720 bytes,
due to the tweet’s 140-character limit. So, the length sequence can
be used as a signature to determine when a tweet is sent.
As discussed before, what we want to do here is to use the signa-
ture to ﬁnd out the timestamp when the user tweets. The problem
here is that our usage monitor running on the victim’s phone does
not see those packets and can only observe the increments in the
data-usage statistics. Our ofﬂine analysis shows that the payload for
Client Hello can be reliably detected by the monitor. However, the
time interval between the Key-Exchange message and POST turns
out to be so short that it can easily fall through the cracks. There-
fore, we have to resort to the aforementioned analysis methodology
(Section 3.1) to compare the data-usage sequence collected by our
app with the payload signature: a tweet is considered to be sent
when the increment sequence is either (420|150, 314, 580–720) or
(420|150, 894–1034).
Identity discovery. From the tweeting events detected, we obtain a
sequence of timestamps T = [t1, t2,··· , tn] that describe when the
phone user tweets. This sequence is then used to ﬁnd out the user’s
Twitter ID from the public index of tweets. Such an index can be
accessed through the Twitter Search API [4]: one can call the API
to search the tweets from a certain geo-location within 6 to 8 days.
Each query returns 1500 most recent tweets or those published in
the prior days (1500 per day). An unauthorized user can query 150
times every hour.
To collect relevant tweets, we need to get the phone’s geo-location,
which is speciﬁed by a triplet (latitude, longitude, radius) in the
twitter search API. Here all we need is a coarse location (at city
level) to set these parameters. Android has permissions to control
the access to both coarse and ﬁne locations of a phone. However,
we found that the user’s ﬁne location could be inferred once she
connects her phone to a Wi-Fi hotspot (see Section 4). Getting her
coarse location in this case is much easier: our zero-permission app
can invoke the mobile browser to visit a malicious website, which
can then search her IP in public IP-to-location databases [11] to ﬁnd
her city. This allows us to set the query parameters using Google
Maps. Note that smartphone users tend to use Wi-Fi whenever
possible to conserve their mobile data (see Section 4), which gives
our app chances to get their coarse locations. Please note that we
do not require the user to geo-tag each tweet. The twitter search
results include the tweets in a area as long as the user speciﬁed her
geo-location in her proﬁle.
As discussed before, our app can only sneak out the timestamps it
collects from the Twitter app when the phone screen dims out. This
could happen minutes away from the moment a user tweets. For
each timestamp ti ∈ T , we use the twitter API to search for the set
of users ui who tweet in that area in ti ± 60s (due to the time skew
between mobile phone and the twitter server). The target user is in
the set U = ∩ui. When U contains only one twitter ID, the user is
identiﬁed. For a small city, oftentimes 1500 tweets returned by a
query are more than enough to cover the delay including both the
ti ± 60s period and the duration between the tweet event and the
moment the screen dims out. For a big city with a large population
of Twitter users, however, we need to continuously query the Twitter
server to dump the tweets to a local database, so when our app report
a timestamp, we can search it in the database to ﬁnd those who tweet
at that moment.
Table 2: City information and Twitter identity exploitation
Location
Population City size
Urbana
Bloomington
Chicago
41,518
81,381
2,707,120
11.58 mi2
19.9 mi2
234 mi2
times-
Time
interval
covered (radius)
243 min (3 mi)
87 min (3 mi)
141 sec (3 mi)
# of
tamps
3
5
9
Attack evaluation. We evaluated the effectiveness of this attack at
three cities, Urbana, Bloomington and Chicago. Table 2 describes
these cities’ information.
We ﬁrst studied the lengths of the time intervals the 1500 tweets
returned by a Twitter query can cover in these individual cities. To
this end, we examined the difference between the ﬁrst and the last