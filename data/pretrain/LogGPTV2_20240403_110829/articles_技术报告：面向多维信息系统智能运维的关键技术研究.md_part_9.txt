但是自编码器（AE）有很明显的缺陷，就是网络复现的能力有限，以及容易陷入过拟合之中，缺乏对稍稍变化的正常数据的适应能力。因此有了改进的变分自编码器，VAE假设隐变量符合高斯分布，encoder训练出的其实是隐变量的均值和方差，从高斯分布里抽样再输入decoder，这样就保证了输出的一般性和隐变量的连续性。VAE将decoder输出的变量也假设符合高斯分布，即得到均值和协方差矩阵（对角阵），在实践中我们只关注窗口最后一点的均值和方差，可以由其得到3sigma的置信区间，用以判断原数据的窗口最后一点是否符合网络学习到的正常模式。VAE模型可以通过新数据不断地更新自己的网络参数，可以设置定期更新，保持模型的时效性。
变分自编码器（VAE）可以很理想地解决数据模式学习的问题，但是其对于数据模式自身之外的业务模式或更复杂的数据模式缺乏学习能力。比如有的业务指标，在每天中有白天和夜晚的峰值变化，在一周中还有工作日和休息日的峰值变化，那么在工作日出现休息日的模式就是错误的。而变分自编码器是无法学习到这种复杂的内在模式的。因此再次改进引入了条件变分自编码器，通过在隐藏层加入外界条件（例如星期、时间等）来使解码器网络对不同复杂模式下的数据有不同的反映结果。对于复杂模式和存在数据外模式的指标具有良好的适配性。
优点：
-   可以处理绝大多数的周期类指标，对于各类模式异常都有良好的适应性；
-   可以在一定程度上学习到更复杂的业务模式和复杂时间模式（需借助condition）；
-   单从周期数据的模式识别上，效果优于大多数的其他算法。
缺点：
-   对数据中的波动程度比较敏感，如果数据经常大起大落，漏报和误报会增多；
-   神经网络的机器学习算法，训练速度和检测速度都较慢；
-   对训练数据的数据量有一定的要求。
### 4.3.2 多指标异常检测 
在异常检测和根因分析等流程中，考虑多个指标数据，往往可以获得更多有效的信息来定位异常和发现指标之间潜在关系。
单指标异常检测根据一个单独的指标识别异常模式，或给出动态阈值。例如，当磁盘储存空间不足时，磁盘压力超出阈值，一个单指标异常检测模型可能会对此产生一个告警。作为对比，多指标异常检测会根据一系列相关的，或在一个场景下的指标同时进行检测，并共同决策异常。例如，一个多指标异常检测模型会同时检测一台机器的磁盘压力、内存压力、CPU压力、网络波动等，当仅仅是磁盘压力过大时，机器仍然可以正常运转，其他指标依然正常，在这种情况下，告警可能不会被触发。只有当高磁盘压力和高内存消耗同时发生时，模型才会告警。这只是一个简单的例子，运维人员完全可以通过制定告警策略来实现这种共同决策。然而真实情况要复杂的多，哪些指标发生异常的影响更大，哪些异常模式的严重性更高，仅通过规则是无法给出精确合理的描述的。多指标异常检测模型借助神经网络或一些其他机器学习模型，挖掘出指标间更深层次的关系，利用这些信息做出更精确的异常告警决策。
多指标异常检测的应用场景通常是一个可以通过多个特征指标描述的实体（entity），例如一台服务器、一个集群、一个航天器系统等等。实体下的每一个特征指标，都会对整个实体的运行状况作出一部分贡献。当然，每个指标的影响度是不同的，其中有两类指标是比较重要的：
一、对其他指标影响较大的指标，它的变化往往可以导致其他很多的指标都跟随它一起变化，从而导致整个实体进入异常状态，这种指标一般都处于依赖拓扑图的较低层，例如机器空闲内存等基础指标。
二、对整个实体的可用性产生较大影响的指标，当这种指标发生异常时，可能不会导致其他指标的变化，但是对整个实体的可用性，或者某些业务逻辑十分关注的时效性等，引起较严重的后果，例如宇航器中的通信模块等必要指标。
在进行多指标异常检测时，第一步就是去筛选可以代表实体运行情况的重要指标。要尽可能地涵盖上述两种指标，并排除一些不重要的指标，例如有信息冗余的指标或者业务上并不关注的指标。其实这些很类似于模型的特征选择过程，甚至某些参数的学习过程。然而利用一些人类的先验知识去做一些简单的预处理，能够帮助模型收敛更快，效果更好，让机器学习的能力有的放矢，这也是所有智能运维方法所推荐的。
从算法的角度，在建模多指标异常检测模型时，输入 X
即为实体某一时刻的状态，它可以被表示为一个 N 维向量，代表实体的 N
个特征指标，输出则是一个 0 或 1
的异常状态。异常检测中，常用的两种判定异常的方式是预测和重构。预测是指，使用预测值和真实值的误差作为异常评分；重构是指，使用真实值的重构和真实值的误差作为异常评分。多指标场景下，预测值和重构值都应该是多维的向量，那么异常评分的计算需要采取一种策略将多维向量转化为一个标量评分，当然这个策略也是可以通过学习得到的。对于输入向量，一个
N
维向量能够涵盖每个特征指标的信息，但是它不能涵盖时序上的信息。指标的本质是一个连续时间序列，大部分能够挖掘到的信息其实是储存在时序关系里的，多指标异常检测同样需要充分考虑到时序信息才能有更好的效果。
提到时序信息自然而然就想到循环神经网络，LSTM
是一个很典型的解决方案，它可以学习到每个特征的历史模式，在预测时基于前一段时间的记忆给出合理的预测。
另外一个解决方案是，类似于单指标异常检测，使用滑动窗口扩展每一个特征指标的维度，如果窗口的长度是
W，此时模型的输入将会从一个 N 维的向量变成一个 N \* W
维的矩阵，显然模型更复杂了，但是因为引入了时序信息，这种复杂性也是在所难免的。在实际应用中，一个实体的特征指标可能多达100个，甚至1000个。这样大批量模式的异常本身就已经很难从人类经验的角度去判断了，算法的优势此时就体现了出来。另一方面，多指标异常的真实数据也极为重要，由于它的高复杂度，开发人员很难模拟出接近真实情况的数据，所以只有依靠经过实践检验的真实数据，才能得到理想的效果。
上述场景是结合了单指标异常检测和多指标异常检测的应用模式，对于一些强相关的指标，因此往往也可以借助这种强相关关系，仅使用多指标异常检测来识别异常。例如，部署在一个集群上的某个服务，使用负载均衡的方式分配请求流量，那么可以认为这个集群内的每台机器的
QPS （Queries Per Second）指标是强相关的。此时对异常的定义是：某台机器的
QPS
趋势偏离了整体趋势，因为强相关的指标的趋势一定是相似的。这里的"强相关"，在大多数情况下是线性相关。根据负载均衡的策略的不同，也不排除有非线性相关的指标集存在，但是非线性相关的指标是很难定义异常模式的，仅仅在运维人员十分了解指标间关系的情况下，才会去使用非线性的模型适应这种场景，而过多的人工干预本身是智能运维所不推荐的，所以这里只讨论多指标之间线性相关的情形。
-   相关性计算
线性相关模型是否适用是根据指标间的相关程度决定的。统计学中有很多计算相关性的方式，例如皮尔森系数，回归中的
R-squared
系数等。在使用模型之前，推荐使用这些方式对模型相对指标的适用性做一个估计，以便得出更好的效果。异常检测的模型可以使用最简单的多元线性回归模型，例如，对于某一集群中的指标
A
来说，集群中的其他指标可作为因变量，使用训练数据拟合出一个多元线性回归方程。在检测过程中，每当收到
A
指标的一个新数据点，模型会给出一个预测值，当真实值与预测值的偏差过大时，即可以认为
A
指标背离了这种线性关系，继而判定为异常。常规的线性回归模型假设了噪音的分布符合高斯分布，因此我们可以用数值偏离的方差倍数来设定异常阈值。在实际情况中，各种回归模型都有一定的适用范围，所以通常会选择在测试集中表现最好的回归模型作为最终的模型。线性回归模型的优势是简单高效，训练速度快，可以适用于百分之九十以上的情形；缺点是当指标数过多时，由于不能保证所有指标都两两强相关，训练出的线性回归模型可能会在某些维度上学习到一些无效的信息，从而影响泛化能力。
-   降维
另一个常用的多指标利用相关性来检测异常的方式是降维。同之前所述，非线性降维往往不会挖掘出更多有效的信息，所以降维通常指的就是线性的降维。以
PCA（Principal Components Analysis） 为例，PCA
将线性相关的多维数据降维至很少的几个维度上，同时保留了大部分的原始信息，这几个维度被称为主成分。在正常情况下，主成分可以稳定的描述多个指标，当异常发生时，由于一个或多个指标背离了线性关系，原先的几个主成分已经无法描述大部分的原始信息，这时就需要更多的主成分去描述，在这种情况下，模型即将之识别为异常。更方便的，我们也可以根据主成分去尝试重建数据，使用真实数据和重建数据的误差的大小来判定是否是异常，使用误差的方向来判定是哪个指标发生了异常。这种降维后再重建的方式是很多异常检测模型的基本思路。
多指标异常检测相对于单指标异常检测来说其实是一种高维延拓，提升维度可以挖掘到更多的信息，所以一些简单的单指标检测模型也可以在多指标中使用。受大环境限制，指标检测缺少高质量的带标签数据，因此大多数单指标检测模型都是无监督模型。而在单指标异常检测中通常通过滑动窗口的方式来扩充维度，在多指标中，结合高维的数据和滑动窗口，一些单指标无监督模型同样适用于多指标中，并对多指标的整体，例如一个机器、一个集群、一个多机部署的服务，能够给出更好的描述。同时，多指标模型也必然会带来更高的复杂度，更长的训练时间，以及更高的调参难度。这些也是需要智能运维的开发人员和使用产品的运维人员共同考虑的因素。
### 4.3.3 选用方案
通过对主要机器学习算法进行研究，主要选用以下三类常见算法：
1.  变分自动编码器(Variational Auto-Encoder,VAE)
变分自动编码器是一种有方向的图形生成模型，已经取得了很好的效果，是目前生成模型的最先进方法之一。它假设数据是由一些随机过程，涉及一个未被注意的连续随机变量z假设生成的z是先验分布Pθ(z)和条件生成数据分布Pθ(X
\| z),其中X表示这些数据。z有时被称为数据X的隐藏表示。
VAE的最大特点是模仿自动编码机的学习预测机制，在可测函数之间进行编码、解码。同GAN类似，其最重要的idea是基于一个令人惊叹的数学事实：对于一个目标概率分布，给定任何一种概率分布，总存在一个可微的可测函数，将其映射到另一种概率分布，使得这种概率分布与目标的概率分布任意的接近。
![](media/image21.png){width="5.930555555555555in"
height="5.118055555555555in"}
图 10 VAE原理示意图
VAR在图像重构、聚类、机器翻译等方面有着广泛的应用,自动编码机的一个非常好的应用是降维，也可用于特征提取、文档检索、分类和异常检测，特别是应用与周期性较强的指标趋势。
![](media/image22.png){width="5.305508530183727in"
height="2.833390201224847in"}
从上图可以看出VAE算法非常适合周期性强指标分析，比如业务量、交易额等都是周期性特征比较明显的指标。
2.  IsolationFotest/ MovingAverage（随机森林/移动平均）
随机森林就是通过集成学习的思想将多棵树集成的一种算法，它的基本单元是决策树，而它的本质属于机器学习的一大分支------集成学习（Ensemble
Learning）方法。随机森林的名称中有两个关键词，一个是"随机"，一个就是"森林"。"森林"我们很好理解，一棵叫做树，那么成百上千棵就可以叫做森林了，这样的比喻还是很贴切的，其实这也是随机森林的主要思想\--集成思想的体现。。
从直观角度来解释，每棵决策树都是一个分类器（假设现在针对的是分类问题），那么对于一个输入样本，N棵树会有N个分类结果。而随机森林集成了所有的分类投票结果，将投票次数最多的类别指定为最终的输出，这就是一种最简单的
Bagging 思想。
![http://file.elecfans.com/web1/M00/48/4D/o4YBAFqo2VWAOPp8AAB7G8e5pbc524.png](media/image23.png){width="5.684027777777778in"
height="3.189583333333333in"}
典型的适合由随机森林来训练分析的数学模型:
![](media/image24.png){width="5.4175087489063865in"
height="2.995298556430446in"}
IsolationFotest随机森林/和MovingAverage移动平均算法比较适合较离散的数据，包括CPU、内存等性能数据，变化趋势一般没有规律。
3.  KDE（核密度估计）
由给定样本集合求解随机变量的分布密度函数问题是概率统计学的基本问题之一。解决这一问题的方法包括参数估计和非参数估计。参数估计又可分为参数回归分析和参数判别分析。在参数回归分析中，人们假定数据分布符合某种特定的性态，如线性、可化线性或指数性态等，然后在目标函数族中寻找特定的解，即确定回归模型中的未知参数。在参数判别分析中，人们需要假定作为判别依据的、随机取值的数据样本在各个可能的类别中都服从特定的分布。经验和理论说明，参数模型的这种基本假定与实际的物理模型之间常常存在较大的差距，这些方法并非总能取得令人满意的结果。
而核密度估计方法不利用有关数据分布的先验知识，对数据分布不附加任何假定，是一种从数据样本本身出发研究数据分布特征的方法，因而，在统计学理论和应用领域均受到高度的重视。适用数据类型：
![https://img-blog.csdn.net/20180316090129264](media/image25.png){width="2.5555555555555554in"
height="2.31875in"}![https://img-blog.csdn.net/20180316090139420](media/image26.png){width="2.623611111111111in"
height="2.3604166666666666in"}
KDE算法比较适合有停止事件的指标，如跑批处理、启停处理干扰的指标情况。
![](media/image27.png){width="5.262706692913386in"
height="2.7714818460192476in"}
综合所有主要算法研究来看，业务类指标首先从业务日志中进行提取分析，包括交易量、交易耗时、成功率等关键业务指标。业务指标属于强周期型的指标趋势，需选择VAE算法进行训练效果会最佳。
结合以上三部分技术，同时考虑电网使用场景，我们新提出两种不同的算法上的创新方案：
1.  基于无监督学习技术的单指标异常检测技术
对于异常检测技术，可采用无监督自学习异常检测方案。因为随着各种监控以及web应用程序的拓展，这些具有各种模式和数据质量的季节性KPI异常检测一直是一个巨大的挑战，尤其是在没有标签的情况下。所以设计出一种基于VAE的无监督异常检测算法。
变分自编码器是一种深度贝叶斯网络，通过SGVB最大化证据下界（ELBO）近似后验和生成模型联合训练。具体公式如下图所示：
![](media/image28.jpeg){width="3.904166666666667in"
height="1.4743055555555555in"}
基于此的优化算法的结构如下：
![](media/image29.jpeg){width="3.852777777777778in"
height="2.1993055555555556in"}
优化算法性能会大大超过了现有的监督集成方法和基线VAE方法，采用的新的优化算法重构KDE解释方法，使其成为第一个具有较强的理论解释力的基于VAE的异常检测算法。
2.  海量机器指标智能异常定位技术;
我们的智能异常定位技术主要由三个关键技术组成：异常相关波动检测，相似机器聚类，以及智能严重度评估排序。
采用核密度估计和极值理论结合的方式来估算相关波动严重度，基本流程如下图所示：
聚类方面我们采用了皮尔森相关系数来对两台机器的异常度进行度量，并使用DBSCAN算法来进行聚类。其中利用皮尔森系数来估算相似度的公式如下：
![](media/image30.png){width="2.1118055555555557in"
height="0.8611111111111112in"}
最后在排序阶段，我们使用了Learning-to-Rank算法中的PointWise排序法，利用监督学习和逻辑回归配合，辅助历史事件的人工结果，自动训练合适的排序模型。最终排序时采用的关键特性包括有：
-   集群的最大异常值