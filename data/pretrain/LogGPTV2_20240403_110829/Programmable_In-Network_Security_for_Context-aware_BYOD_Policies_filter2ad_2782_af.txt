[55] Y. Fratantonio, C. Qian, P. Chung, and W. Lee. Cloak and
dagger: From two permissions to complete control of the UI
feedback loop. In Proc. IEEE S&P, 2017.
[56] C. K. Georgiadis, I. Mavridis, G. Pangalos, and R. K. Thomas.
Flexible team-based access control using contexts. In Proc.
SACMAT, 2001.
[57] D. Harkins. Simultaneous authentication of equals: A secure,
password-based key exchange for mesh networks. In Proc.
SensorComm, 2008.
[58] S. Hong, R. Baykov, L. Xu, S. Nadimpalli, and G. Gu. To-
wards SDN-deﬁned programmable BYOD (bring your own
device) security. In Proc. NDSS, 2016.
[59] S. Hong, L. Xu, H. Wang, and G. Gu. Poisoning network
visibility in software-deﬁned networks: New attacks and coun-
termeasures. In Proc. NDSS, 2015.
[60] Y. J. Jia, Q. A. Chen, S. Wang, A. Rahmati, E. Fernandes,
Z. M. Mao, and A. Prakash. ContexIoT: Towards providing
contextual integrity to appiﬁed IoT platforms. In Proc. NDSS,
2016.
[61] X. Jin, X. Li, H. Zhang, N. Foster, J. Lee, R. Soule, C. Kim,
and I. Stoica. NetChain: Scale-free sub-RTT coordination. In
Proc. NSDI, 2018.
[62] X. Jin, X. Li, H. Zhang, R. Soulé, J. Lee, N. Foster, C. Kim,
and I. Stoica. NetCache: Balancing key-value stores with fast
in-network caching. In Proc. SOSP, 2017.
[63] M. T. Jones.
Invoking user-space applications from the
kernel. https://www.ibm.com/developerworks/libra
ry/l-user-space-apps/index.html, 2018.
[64] L. Jose, L. Yan, G. Varghese, and N. McKeown. Compiling
packet programs to reconﬁgurable switches. In Proc. NSDI,
2015.
[65] N. Katta, M. Hira, C. Kim, A. Sivaraman, and J. Rexford.
HULA: Scalable load balancing using programmable data
planes. In Proc. SOSR, 2016.
[66] M. Liu, L. Luo, J. Nelson, L. Ceze, A. Krishnamurthy, and
K. Atreya. IncBricks: Toward in-network computation with
an in-network cache. In Proc. ASPLOS, 2017.
[67] N. McKeown, T. Anderson, H. Balakrishnan, G. Parulkar,
L. Peterson, J. Rexford, S. Shenker, and J. Turner. OpenFlow:
Enabling innovation in campus networks. ACM SIGCOMM
Computer Communication Review, 38(2):69–74, 2008.
[68] C. Monsanto, N. Foster, R. Harrison, and D. Walker. A
compiler and run-time system for network programming lan-
guages. In Proc. POPL, 2012.
[69] C. Monsanto, J. Reich, N. Foster, J. Rexford, and D. Walker.
Composing software-deﬁned networks. In Proc. NDSI, 2013.
[70] A. Morrison, L. Xue, A. Chen, and X. Luo. Enforcing context-
In Proc.
aware BYOD policies with in-network security.
HotCloud, July 2018.
[71] D. M’Raihi, S. Machani, M. Pei, and J. Rydell. Time-based
one-time password algorithm. RFC 6238.
[72] A. Nadkarni and W. Enck. ASM: A programmable interface
for extending Android security. In Proc. USENIX Security,
2014.
[73] S. Narayana, A. Sivaraman, V. Nathan, P. Goyal, V. Arun,
M. Alizadeh, V. Jeyakumar, and C. Kim. Language-directed
hardware design for network performance monitoring. In
Proc. SIGCOMM, 2017.
[74] M. Nauman, S. Khan, X. Zhang, and J.-P. Seifert. Beyond
kernel-level integrity measurement: Enabling remote attesta-
tion for the Android platform. In Proc. TRUST, 2010.
[75] T. OConnor, W. Enck, W. M. Petullo, and A. Verma. Pivot-
Wall: SDN-based information ﬂow control. In Proc. SOSR,
2018.
[76] B. Parducci. eXtensible Access Control Markup Language
(XACML) speciﬁcation. 2005.
[77] P. Porras, S. Shin, V. Yegneswaran, M. Fong, M. Tyson, and
G. Gu. A security enforcement kernel for OpenFlow networks.
In Proc. HotSDN, 2012.
[78] M. Reitblatt, M. Canini, A. Guha, and N. Foster. Fattire:
Declarative fault tolerance for software-deﬁned networks. In
Proc. HotSDN, 2013.
[79] C. Schlesinger, M. Greenberg, and D. Walker. Concurrent
NetCore: From policies to pipelines. In Proc. ICFP, 2014.
[80] S. Shin and G. Gu. Cloudwatcher: Network security moni-
toring using OpenFlow in dynamic cloud networks. In Proc.
ICNP, 2012.
[81] S. Shin, P. Porras, V. Yegneswaran, M. Fong, G. Gu, and
M. Tyson. Fresco: Modular composable security services for
software-deﬁned networks. In Proc. NDSS, 2013.
[82] S. Shin, V. Yegneswaran, P. Porras, and G. Gu. AVANT-
GUARD: Scalable and vigilant switch ﬂow management in
software-deﬁned networks. In Proc. CCS, 2013.
[83] R. Skowyra, L. Xu, G. Gu, T. Hobson, V. Dedhia, J. Landry,
and H. Okhravi. Effective topology tampering attacks and
defenses in software-deﬁned networks. In Proc. DSN, 2018.
[84] J. Sonchack, A. Aviv, E. Keller, and J. Smith. Enabling prac-
tical software-deﬁned networking security applications with
OFX. In Proc. NDSS, 2016.
[85] H. Song. Protocol-oblivious forwarding: Unleash the power
of SDN through a future-proof forwarding plane. In Proc.
HotSDN, 2013.
[86] Sophos. Synchronized security: Best-of-breed defense that’s
more coordinated than attacks. https://www.sophos.com
/en-us/medialibrary/gated-assets/white-papers/
sophos-security-heartbeat-wpna.pdf.
USENIX Association
29th USENIX Security Symposium    609
[87] W. Tolone, G.-J. Ahn, and T. Pai. Access control in collabo-
rative systems. ACM Computing Surveys, 37:29–41, 2005.
[88] N. Ulltveit-Moe and V. Oleshchuk. Enforcing mobile security
with location-aware role-based access control. Security and
Communication Networks, 9:429–439, 2016.
[89] VMware. Next generation security with VMware NSX and
Palo Alto Networks VM-series. In White Paper, 2013.
[90] A. Voellmy, A. Agarwal, P. Hudak, N. Feamster, S. Burnett,
and J. Launchbury. Don’t conﬁgure the network, program
it! Domain-speciﬁc programming languages for network sys-
tems. Technical report, Yale University, 2010.
[91] X. Wang, K. Sun, Y. Wang, and J. Jing. Deepdroid: Dynami-
cally enforcing enterprise policy on Android devices. In Proc.
NDSS, 2015.
[92] X. Wang, T. Yu, O. Mengshoel, and P. Tague. Towards con-
tinuous and passive authentication across mobile devices: an
empirical study. In Proc. WiSec, 2017.
[93] Z. Wang, Z. Qian, Q. Xu, Z. M. Mao, and M. Zhang. An
untold story of middleboxes in cellular networks. In Proc.
SIGCOMM, 2011.
[94] R. Ward and B. Beyer. BeyondCorp: A new approach to
enterprise security. USENIX ;login:, 39:6–11, 2014.
[95] Wi-Fi Alliance introduces Wi-Fi Certiﬁed WPA3 security.
https://www.wi-fi.org/news-events/newsroom/wi-
fi-alliance-introduces-wi-fi-certified-wpa3-se
curity.
[96] L. Xu, J. Huang, S. Hong, J. Zhang, and G. Gu. Attacking
the brain: Races in the SDN control plane. In Proc. USENIX
Security, 2017.
[97] R. Ye. Android System Programming: Porting, customizing,
and debugging Android HAL. Packt Publishing, 2017.
[98] T. Yu, S. K. Fayaz, M. Collins, V. Sekar, and S. Seshan. PSI:
Precise security instrumentation for enterprise networks. In
Proc. NDSS, 2017.
[99] T. Yu, V. Sekar, S. Seshan, Y. Agarwal, and C. Xu. Handling
a trillion (unﬁxable) ﬂaws on a billion devices: Rethinking
network security for the Internet-of-Things. In Proc. HotNets,
2016.
[100] Y. Yuan, D. Lin, R. Alur, and B. T. Loo. Scenario-based
programming for SDN policies. In Proc. CoNEXT, 2015.
[101] N. Zahadat, P. Blessner, T. Blackburn, and B. Olson. BYOD
security engineering: A framework and its analysis. Comput-
ers & Security, 55:81–99, 2015.
A Appendix
In this appendix, we include more discussions and results.
A.1 Poise protocol format
In this subsection, we extend the discussion in §4.3 and de-
scribe the Poise protocol format in more detail. The Poise
client module periodically sends context packets for each ac-
tive connection. Context packets have the same ﬂow tuples
(source IP, destination IP, source port, destination port) with
data packets from the same TCP/UDP ﬂows. The only differ-
ences are that a) context packets have a special IP protocol
number (IPProto=143 for TCP, IPProto=144 for UDP; both
are unassigned protocol numbers [21]), b) context headers
come after the transport-layer (TCP/UDP) header, and c) con-
text packets do not have payload. Poise never propagates
context packets to external networks but rather drops them
at the switch, and it does not modify data packets. Figure 13
shows the format for TCP ﬂows.
Data packet
Ethernet
IP (proto=6)
TCP
Payload
Context packet
Ethernet
IP (proto=143)
TCP
Context
Figure 13: Context packets have a special IP protocol number.
Data packets from Poise clients have unchanged headers.
A.2 Compiler optimizations
This subsection extends §4.3 and describes in more detail the
compiler optimizations.
Table deduplication. Suppose that we would like to compose
two policies that perform checks on the same context type.
A naïve compiler would simply compile each check into a
separate match/action table. With this approach, the number of
policies that can be supported would be limited by the number
of match/action tables in a switch. Depending on the switch
model, this number is on the order of O(10), which is quite
small. Our compiler can recognize that policies share the same
context type, and it merges checks on the same context type
by creating one table for each unique context across policies.
Then, it compiles each check into a match/action table entry
instead of a separate table. This optimization allows Poise
to scale the number of context types to the number of table
entries a switch can support, not the number of unique tables.
This number is on the order of O(1M).
Policy collapsing. Consider now a policy that checks many
context ﬁelds one by one, and only arrives at the ﬁnal decision
afterwards. The key challenge for handling such a policy is
that these checks create “dependent tables”, which due to P4
constraints must reside in separate stages. In essence, such a
policy would result in a long chain of tables, which might ex-
ceed the number of available stages (O(1-10)) in a switch. Our
optimization collapses a chain of tables of length k into multi-
ple shorter chains k1, k2, .., kt , each of which stays within the
number of available stages. Due to another P4 constraint—a
packet can only match against a single table per stage, match-
ing against all subchains k1, k2, .., kt would require recircu-
lating the packet t times, each for a subchain. Recirculation
of context packets would cause additional latency, as such
packets now need to traverse the switch multiple times before
ﬁnishing processing, and also additional recirculation trafﬁc
in a dedicated switch pipeline.
A.3 Scalability
This subsection includes more results for §8.5. Figure 14
shows the scalability of Poise for monitor policies, in terms
of a) the number of monitors, and the number of checks per
610    29th USENIX Security Symposium
USENIX Association
(a) Num. of monitors vs. num. of checks
(b) Num. of monitors vs. latency
(c) Num. of monitors vs. trafﬁc overhead
Figure 14: The scalability of Poise with monitor policies. The high-level takeaways are similar as those for regular, non-monitor
policies (Figure 11 in §8.5). The only difference is that a monitor uses two tables, whereas a regular context uses one table.
monitor (Figure 14a), b) the latency of context and data pack-
ets (Figure 14b), and c) the throughput of recirculated context
trafﬁc and data trafﬁc (Figure 14c).
Policies could also use a mix of monitor and regular context
types. At a high level, a monitor is just another type of context,
except that it uses two tables instead of one. Figures 17, 18,
19, and 20 present the scalability results assuming 1, 2, 5, and
10 monitors in the policies; the rest of the available tables are
used for regular contexts.
A.4 Client overhead
This subsection includes the full results for §8.6 on the client
overhead due to the extra PoiseDroid module.
(a) CPU overhead
(b) Trafﬁc overhead
Figure 15: CPU and trafﬁc overheads of PoiseDroid under
different frequencies of context packets. Baseline: Android.
Table 1: The battery overhead of PoiseDroid (lower is better).
Attribute
Overall Browsing Video Writing
Photo
Android
PoiseDroid
5493
5591
4278
4303
5458
5597
4530
4660
11432
11746
Data
4136
4145
Overhead
1.02%
0.06%
2.55% 2.87% 2.75% 0.22%
CPU and trafﬁc overheads. Figures 15a and 15b show the
CPU and trafﬁc overheads at different frequencies of con-
text packets. For each data point, we uploaded a video ﬁle
of 1.73 GB to a remote FTP server using the mobile app
AndFTP [1], and measured the CPU overhead as collected
from the /proc/loadavg ﬁle. As we can see, if Poise were
to tag each data packet with context information, then the CPU
and trafﬁc overheads are prohibitive (∼10%). Because the in-
network primitive is stateful, it can remember past decisions
for each connection; this enables an optimized design where
client modules can send out context packets periodically. The
Poise primitive can look up its stateful data structure and
apply access control decisions accordingly. For instance, at
the frequency of one context packet per second, the CPU and
trafﬁc overheads are both low enough to be practical.
Battery overhead. Table 1 shows the battery overhead of the
PoiseDroid client, as measured by PCMark [35]. PCMark
tests capture a wide variety of activities, such as browsing,
video playback, photo editing, writing, and data manipulation.
In the beginning of the experiment, the phone was charged
with full capacity (100%), and the tests ran until the battery
dropped to less than 20%. We can see that, the highest over-
head across all scenarios is only 2.87%.
Overall benchmark. Figure 16 shows the results obtained
by CF-Bench, a comprehensive benchmark tool for testing
multicore mobile devices. PoiseDroid introduces 5%, 4%, and
5% additional overheads for the native code, Java code, and
overall scores, compared to the baseline system of a vanilla
Android system without PoiseDroid installed.
Figure 16: The overall overhead of PoiseDroid, as measured
using the CF-bench benchmark tool (higher is better).
USENIX Association
29th USENIX Security Symposium    611
1001k10k100k1M1251020Checks per monitorNumber of monitorsExactRange 0 1 2 3 4 5 6 71251020Latency (us)Number of monitorsContext packetData packet00.5901001251020Throughput (Gbps)Number of monitorsData traffcRecirculation0510151102030allCPU overhead (%)Frequency10-410-310-210-11001011102030allTraffc overhead (%)Frequency 0 10000 20000 30000 40000 50000NativeJavaOverallScoreAndroidPoiseDroid(a) Num. of contexts vs. num. of checks
(b) Num. of contexts vs. latency
(c) Num. of contexts vs. trafﬁc overhead
Figure 17: Scalability results for policies with one monitor and 1–38 regular contexts. The number of (exact or range) checks
Poise can perform is the same for a regular or monitor context. Similarly for all ﬁgures below.
(a) Num. of contexts vs. num. of checks
(b) Num. of contexts vs. latency
(c) Num. of contexts vs. trafﬁc overhead
Figure 18: Scalability results for policies with two monitors and 1–36 regular contexts.
(a) Num. of contexts vs. num. of checks
(b) Num. of contexts vs. latency
(c) Num. of contexts vs. trafﬁc overhead
Figure 19: Scalability results for policies with ﬁve monitors and 1–30 regular contexts.
(a) Num. of contexts vs. num. of checks
(b) Num. of contexts vs. latency
(c) Num. of contexts vs. trafﬁc overhead
Figure 20: Scalability results for policies with ten monitors and 1–20 regular contexts.
612    29th USENIX Security Symposium
USENIX Association
1001k10k100k1M125102038Number of checksNumber of regular contextsExactRange 0 1 2 3 4 5 6 7125102038Latency (us)Number of regular contextsContext packetData packet00.590100125102038Throughput (Gbps)Number of regular contextsData traffcRecirculation1001k10k100k1M125102036Number of checksNumber of regular contextsExactRange 0 1 2 3 4 5 6 7125102036Latency (us)Number of regular contextsContext packetData packet00.590100125102036Throughput (Gbps)Number of regular contextsData traffcRecirculation1001k10k100k1M125102030Number of checksNumber of regular contextsExactRange 0 1 2 3 4 5 6 7125102030Latency (us)Number of regular contextsContext packetData packet00.590100125102030Throughput (Gbps)Number of regular contextsData traffcRecirculation1001k10k100k1M125101520Number of checksNumber of regular contextsExactRange 0 1 2 3 4 5 6 7125101520Latency (us)Number of regular contextsContext packetData packet00.590100125101520Throughput (Gbps)Number of regular contextsData traffcRecirculation