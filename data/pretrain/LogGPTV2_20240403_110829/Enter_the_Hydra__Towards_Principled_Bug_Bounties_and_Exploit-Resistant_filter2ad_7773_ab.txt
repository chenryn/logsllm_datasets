gap for a distribution D over inputs sequences X if
PrX∈D(cid:2)X ∈(cid:83)N
i=1 E( fi,I)(cid:3)
gap :=
PrX∈D [X ∈ E( f ∗,I)]
> 1 .
(1)
The exploit gap is empirically measurable and its mag-
nitude reﬂects the likelihood that an input sequence that
is an exploit for some fi does not affect f ∗.
A transformed program f ∗ that always returns ⊥ in-
duces a large exploit gap, yet has no utility. We therefore
also require the following notion of availability.
Deﬁnition 2 (Availability Preservation). Let F( f ) be the
set of inputs with fallbacks, i.e. X ∈ F( f ) iff run( f ,X) ∈
Y⊥. Then a program transformation T is availability-
preserving iff F( f ∗) ⊆(cid:83)N
i=1 (E( fi,I)∪ F( fi))
USENIX Association
27th USENIX Security Symposium    1337
To be availability-preserving and yield an exploit gap,
a program transformation may trade availability for cor-
rectness. That is, a transformed program may fallback on
inputs that are exploits for some of the original programs.
Given a transformation T that induces an exploit gap,
a natural bug bounty for a deployed program f ∗ rewards
bugs in the original programs fi. Such a bug bounty
scheme satisﬁes three important properties:
1. The bugs are efﬁciently veriﬁable, via differential test-
ing: If run( fi,X) (cid:54)= run( f ∗,X), then the input X is an
exploit against fi or f ∗ or both.
2. A claimable bug need not be an exploit on f ∗. If the
exploit gap is large (gap (cid:29) 1), then a discovered bug
likely affects one of the programs fi but not f ∗.
3. The bugs are valuable. If gap > 1, ﬁxing bugs in the
fi eventually reduces the probability of exploits in f ∗.
Achieving an exploit gap. Generically, dynamic run-
time checks (e.g., stack canaries, under- or overﬂow de-
tection) can yield an availability-preserving exploit-gap:
the checks result in a fallback output (e.g., a runtime ex-
ception), where the original program had an exploit.
A broadly applicable method for achieving an exploit-
gap is via redundancy and fault-tolerance, e.g., Recov-
ery Blocks [46] or N-version programming [17]. These
transformations operate on N > 1 programs and aim at
full availability (i.e., no fallback outputs), a natural re-
quirement in mission-critical systems.
We focus on N-version (or multiversion) program-
ming, which we build upon in Section 3. This software
paradigm consists in three steps [17, 6]:
1. A speciﬁcation is written for the program’s function-
ality, API, and error handling. It further deﬁnes how
to combine outputs of different versions (see Step 3).
2. N versions of the program speciﬁcation are devel-
oped. Independence among versions is promoted via
isolation (i.e., minimal interactions between devel-
opers) and diversity (i.e., different programming lan-
guages, or technical backgrounds of developers).
3. The N versions are run in parallel and their outputs
combined via some voting scheme. N-version pro-
gramming traditionally uses majority voting between
programs to induce an exploit gap [17, 6].
3 N-of-N-version Programming
N-version programming assumes that heterogeneous
implementations have weakly correlated failures [17].
Many experiments have challenged this view [33, 21],
questioning the cost-beneﬁt trade-off of the paradigm.
Our thesis is that smart-contract ecosystems present a
number of key properties that render multiversion pro-
gramming and derived bug-bounty schemes attractive.
The main differentiator between the traditional set-
ting of N-version programming, and ours, is the role of
availability. Prior works consider mission-critical sys-
tems and thus favor availability over safety in the face
of partial failures. For instance, Eckhardt et al. [21] ex-
plicitly ignore the “error-detection capabilities” of N-
version programming. This setup is not suitable for
smart-contracts: As in centralized ﬁnancial institutions
(e.g., stock-markets [48]), the cost of a fault typically
trumps that of a temporary loss of resource availability.
Ethereum’s community exempliﬁed its preference for
safety in this trade-off, when attackers found an exploit
in the Parity Multisig Wallet [11] and stole user funds. A
consortium of “white-hat hackers” used the same bug to
move user’s funds to a safe account. Despite funds being
unavailable for weeks, and reimbursement depending on
the consortium’s good will, the action was acclaimed by
the community and affected users. The simple escape
hatch in this scenario (i.e., move funds to a safe account)
was deemed a successful alternative to an actual exploit.
We propose trading availability for safety in N-version
programming, by replacing the goal of fault-tolerance by
one of error detection and safe termination. Suppose
that programs f1, . . . , fN have no fallback outputs (i.e.,
F( fi) = /0). Then majority voting yields a program f ∗
that also satisﬁes F( f ∗) = /0, but the exploit gap may be
small. At the other end of the spectrum, we propose N-of-
N-version programming (NNVP), wherein f ∗ aborts un-
less all of the N versions agree. NNVP is an availability-
preserving transformation that induces a much larger ex-
ploit gap ( f ∗ only fails if all the fi fail simultaneously).
Table 1 lists prominent Ethereum smart contract fail-
ures. We discuss these in more detail in the extended
version of this paper [13], and argue that a majority could
have been abated with NNVP.
3.1 Revisiting N-version Programming
We revisit experiments on the cost-effectiveness of N-
version programming, in light of our NNVP alternative.
Knight and Leveson [34] ﬁrst showed that the null-
hypothesis of statistical independence between program
failures should be rejected. Yet, such correlated failures
only invalidate the N-version paradigm if increased de-
velopment costs outweigh failure rate improvements.
Unfortunately, in an experiment at NASA, Eckhardt
et al. [21] found that the correlation between individual
versions’ faults could be too high to be considered cost-
effective, with a majority vote between three programs
reducing the probability of some fault classes by only a
small factor (as we show in Appendix A, some of the
workloads in [21] yield an exploit gap of gap ≈ 5 using
majority voting between three programs).
Fortunately, NNVP provides a better cost-beneﬁt
1338    27th USENIX Security Symposium
USENIX Association
Contract name
Parity Multisig 2 [50]
Parity Multisig 1 [11]
The DAO* [18]
Proof of Weak Hands [7]
SmartBillions [49]
HackerGold (HKG)* [40]
MakerDAO* [47]
Rubixi [16]
Governmental [16]
Exploit value (USD)
Root cause
300M Delegate call+exposed self-destruct
180M Delegate call+unspeciﬁed modiﬁer
150M Re-entrancy
1M Arithmetic overﬂow
500K
400K
85K
Bug in caching mechanism
Typo in code
Re-entrancy
<20K Wrong constructor name
10K
Exceeds gas limit
Independence source
programmer/language?
programmer/language?
language
programmer+language
programmer
programmer+language
language
programmer+language
None?
Exploit gap
/
/







Table 1: Selected smart contract failures and potential exploit gaps. The list is extended from [27]. For each incident, we
report the value of affected funds (data from [1]), the cause of the exploited vulnerability, as well as the (hypothetical) potential for
fault independence between multiple contract versions. Green lines indicate settings in which a Hydra contract would have likely
induced a large exploit gap and prevented the exploit. Yellow and red lines indicate incidents that Hydra addresses only partially or
not at all. Asterisks indicate ERC20 compatible contracts, like our bounty described in Section 6. More details are in the extended
version of this paper [13].
trade-off. In the experiment of Eckhardt et al. [21], three
programs failed simultaneously with probability at least
75× lower than a single program (see Appendix A). The
actual exploit gap is probably much larger, as Eckhardt et
al. did not consider whether program failures were iden-
tical or not. In NNVP, a failure only occurs if all N ver-
sions produce the same incorrect output.
In any other
failure scenario, NNVP aborts. Thus, if loss of availabil-
ity can be tolerated, NNVP can signiﬁcantly boost the
error detection capabilities of N-version programming.
3.2 Smart Contracts are NNVP-Friendly
In addition to favoring safety over availability, other
properties of smart contract ecosystems (and Ethereum
in particular) render NNVP bug bounties attractive:
• High risk for small applications. Smart contracts store
large ﬁnancial values in small applications with an ex-
ceptionally high “price per line of code” (some token
contracts hold over 1M USD per line [1]). Contract
code is stored on a public blockchain and exploits often
directly extract or destroy stored funds. Yet developing
multiple versions is typically cheap in absolute terms.
• Principled bounty pricing. A contract’s balance is of-
ten a direct measure of an exploit’s market value. This
facilitates our analysis of principled bounty pricing that
incentivizes early disclosure of bugs (see Section 4).
• Bounty automation. Smart contracts enable automa-
tion of the full bounty program, from bug detection
(with differential testing) to rollback to bounty pay-
ments. Bounties administered by smart contracts can
satisfy fair exchange of bounties for bugs and guaran-
teed payment for disclosure of valid bugs [53]. Boun-
ties are also transparent (i.e., the bounty is publicly
visible on the blockchain) and may be dynamically ad-
justed to reﬂect a contract’s changing exploit value.
The result is a stable, decentralized bounty market.
• Programming language diversity. Many exploits in
Ethereum arose due to speciﬁc language idiosyn-
crasies.
The multiple interoperable languages for
Ethereum enable potentially diverse implementations.
3.3 The Hydra Contract
Hydra consists of two program transformations. The
ﬁrst, TNNVP, uses the NNVP paradigm to yield an
availability-preserving exploit gap. TNNVP combines N
smart contracts (or heads) f1, . . . , fN into a contract f ∗,
which delegates incoming calls to each head. If all out-
puts match, f ∗ returns the output; otherwise, f ∗ reverts
all state changes and returns ⊥.
The idea is depicted in Figure 2. The heads are indi-
vidually deployed and instrumented such that they only
interact with the Hydra meta-contract (MC). The MC
is the logical embodiment of the contract functionality
(i.e., the MC holds all assets, and interfaces with external
contracts and clients). To maintain consistency while in-
teracting with external contracts, the MC checks that all
heads agree on which external interaction to perform, ex-
ecutes the interaction once, and distributes the obtained
response (if any). Our design and implementation of
the TNNVP transformation for Ethereum smart contracts
is described in Section 6.
The second transformation TBounty is responsible for
paying out a bounty and providing escape-hatch func-
tionality. It transforms a program f ∗ into a program ˆf
which forwards any input to f ∗ and then returns f ∗’s out-
put, unless f ∗ returns ⊥. In the latter case, ˆf will pay out
a bug bounty to its caller and enter an escape hatch mode.
Escape hatches.
Ideally, bugs could be patched online.
This is hard in Ethereum as smart contract code cannot
be updated after deployment [41]. Best practices [23]
suggest enhancing smart contracts with an escape hatch
USENIX Association
27th USENIX Security Symposium    1339
party ﬁnds an exploit against the full Hydra contract (x is
an exploit for each head), the party can use this exploit
to steal the entirety of the contract’s balance, $balance.
We model bug ﬁnding as a Poisson process with rate
λi, which captures a party’s work rate towards ﬁnding
bugs. We assume that parties sample inputs x from a
common distribution of potential exploits D. We then
recover our exploit gap notion (Deﬁnition 1) by consider-
ing the difference in arrival times of two random events:
(1) a party discovers a ﬂaw in one of the heads; (2) a party
ﬁnds a full exploit. The waiting times for both events are
exponentially distributed with respective rates λi and
λi · Pr
x∈D
i=1E( fi,I)(cid:3)
(cid:2)x ∈ E( f ∗,I) | x ∈(cid:83)N
i=1 E( fi,I)(cid:3)
= λi · Prx∈D(cid:2)x ∈ E( f ∗,I) ∧ x ∈(cid:83)N
i=1 E( fi,I)(cid:3)
Prx∈D(cid:2)x ∈(cid:83)N
i=1 E( fi,I)(cid:3) = λi · gap
Prx∈D(cid:2)x ∈(cid:83)N
Prx∈D [x ∈ E( f ∗,I)]
= λi ·
−1 .
(2)
Let us ﬁrst consider the strong assumption of indepen-
dent program failures. For a head fi, let p be the proba-
bility that an input x ∈ D is an exploit for fi. We get
1− (1− p)N
Prx∈D[x∈(cid:83)N
i=1 E( fi,I)]
Prx∈D[x∈E( f ∗,I)] =
gap =
pN
which grows exponentially in N, for p ∈ (0,1).
(3)
,
The gap can be empirically estimated using Equa-
tion (1). For the test suites considered in the experiments
of Eckhardt et al. [21], the average gap for three program
variants is 4400 (see Appendix A for details).
4.2 Analyzing Economic Incentives
We assume a set of honest parties with combined work
rate λH. These bounty hunters only try to exchange bugs