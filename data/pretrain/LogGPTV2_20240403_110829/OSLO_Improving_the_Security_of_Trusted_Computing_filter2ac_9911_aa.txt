title:OSLO: Improving the Security of Trusted Computing
author:Bernhard Kauer
OSLO: Improving the security of Trusted Computing
Bernhard Kauer
Technische Universität Dresden
Department of Computer Science
01062 Dresden, Germany
PI:EMAIL
Abstract
• How to ensure that only a particular software stack
can access a stored secret? (Sealed Memory)
In this paper we describe bugs and ways to attack
trusted computing systems based on a static root of trust
such as Microsoft’s Bitlocker. We propose to use the dy-
namic root of trust feature of newer x86 processors as
this shortens the trust chain, can minimize the Trusted
Computing Base of applications and is less vulnerable
to TPM and BIOS attacks. To support our claim we
implemented the Open Secure LOader (OSLO), the ﬁrst
publicly available bootloader based on AMDs skinit
instruction.
1
Introduction
An increasing number of Computing Platforms with
a Trusted Platform Module (TPM) [33] are deployed.
Applications using these chips are not widely used yet
[5, 37]. This will change rapidly with the distribution
of Microsoft’s Bitlocker [2], a disk encryption utility
which is part of Windows Vista Ultimate. As the trusted
computing technology behind these applications is quite
new, there is not much experience concerning the secu-
rity of trusted computing systems.
In this context we
analyzed the security of TPMs, BIOSes and bootloaders
that consitute the basic building blocks of trusted com-
puting implementations. Furthermore, we propose a de-
sign that can improve the security of such implementa-
tions.
1.1 Trusted Computing
Trusted Computing [9,23,25,33] is a technology that
tries two answer two questions:
• Which software is running on a remote computer?
(Remote Attestation)
Different scenarios can be built on top of trusted com-
puting, for example, multi-factor authentication [37],
hard disk encryption [2,5] or the widely disputed Digital
Rights Management. All of these applications are based
on a small chip: the Trusted Platform Module (TPM).
1.2 Technical Background
As deﬁned by the Trusted Computing Group (TCG),
a TPM is a smartcard-like low performance crypto-
It is soldered1 on various moth-
graphic coprocessor.
erboards. In addition to cryptographic operations such
as signing and hashing, a TPM can store hashes of the
boot sequence in a set of Platform Conﬁguration Regis-
ters (PCRs).
A PCR is a 160 bit wide register that can hold an
SHA-1 hash. It cannot be directly written. Instead, it
can only be modiﬁed using the extend(x) operation.
This operation calculates the new value of a PCR as an
SHA-1 hash of the concatenation of the old value and x.
The extend operation is used to store a hash of a chain
of loaded software in PCRs. The chain starts with the
BIOS and includes Option ROMs2, Bootloader, OS and
applications.
Using a challenge-response protocol, this trust chain
can attest to a remote entity which software is running
on the platform (remote attestation). Similarly it can be
used to seal some data to a particular, not necessarily the
currently running, software conﬁguration. Unsealing the
data is then only possible when this conﬁguration was
started. Figure 1 shows such a trust chain based on a
Static Root of Trust for Measurement (SRTM), namely
the BIOS.
USENIX Association
16th USENIX Security Symposium
229
T PM
BootLoader
3 BIOS
3 OS
3 OptionROMs
3 Application
Figure 1. Typical trust chain in a TC system
1.3 Chain of Hashes
Three conditions must be met, to make a chain of
hashes trustworthy:
1. The ﬁrst code running and extending PCRs after
a platform reset (called SRTM) is trustworthy and
cannot be replaced.
2. The PCRs are not resetable, without passing con-
trol to trusted code.
3. The chain is contiguous. There is no code in-
between that is executed but not hashed.
The reasons behind these conditions are the follow-
ing: If the initial code is not trustworthy or can be re-
placed by untrustworthy code, it cannot be guaranteed
that any hash value is correct. This code can in fact mod-
ify any later running software to prevent the undesirable
hashing. The second condition is quite similar and can
be seen as a generalization of the ﬁrst one. If PCRs are
reset and untrustworthy code is running then any chain
of hashes can be fabricated. The ﬁrst two points de-
scribe the beginning of the trust chain. The third point
is needed to form a contiguous chain by recursion. It
forces the condition that every program occupying the
machine must be hashed, before it is executed. Other-
wise, the trust chain is interrupted and unmeasured code
can be running. Every program using sealed memory
has to trust the code running before it to not open a hole
in the chain. Similarly, a remote entity needs to ﬁnd out
during an attestation whether the trust chain presented
by a trusted computing platform contains any hole in
which untrusted code could be run. We will see later
how current implementations do not meet the three con-
ditions.
Organization
This paper is structured as follows. We describe bugs
and ways to attack trusted computing systems based on
SRTM in the next section. After that we present the de-
sign and describe the implementation of OSLO. A sec-
tion evaluating the security achievements follows. The
last section proposes future work and concludes.
2 Security Analysis
2.1 Bootloader Bugs
We look at the three publicly available TPM-enabled
bootloaders and analyze whether they violate the third
condition of a trust chain, executing code that is not
hashed.
The very ﬁrst publicly available trusted bootloader
was part of the Bear project from Dartmouth College
[19, 20]. They enhanced Linux with a security module
called Enforcer. This module checks for modiﬁcation
of ﬁles and uses the TPM to seal a secret key of an en-
crypted ﬁlesystem. To boot the system they used a mod-
iﬁed version of LILO [7]. They extend LILO in two
ways: the Master Boot Record hashes the rest of LILO
and the loaded Linux kernel image is also hashed. Only
the last part of the image, containing the kernel itself, is
hashed here. But the ﬁrst part of the image, containing
the real-mode setup code, is executed. Hence, this vio-
lates the third condition. A ﬁx for this bug would be to
hash every sector which gets loaded.
A second trusted bootloader is a patched GRUB
v0.97 from IBM Japan [21, 36]. This bootloader is used
in IBMs Integrity Measurement Architecture [28]. It has
the same security ﬂaw as our own experiments with a
TCG enabled GRUB [16]: it loads ﬁles twice, ﬁrst for
extraction and later for hashing into a PCR. A cause for
this bug lies certainly in the structure of GRUB. GRUB
loads and extracts a kernel image at the same time in-
stead of loading them completely into memory and ex-
tracting them afterwards. This leads to the situation
that measuring the ﬁle independently from loading is
the easiest way for a programmer to add TCG support
to GRUB. Such an implementation is unfortunately in-
correct. As program code is loaded twice from disk or
from a remote host over the network, an attacker who
has physical access either to the disk or to the network
can send different data at the second time. This violates
again the third condition, as hashed and executed code
may differ.
Another GRUB based trusted bootloader called
TrustedGRUB [35] solves this issue in a recent version
by moving the hash code to a lower level. Hashing is
simply done on each read() call that loads data from
disk or network, before the actual data is returned to the
caller. The hash is then used after loading a kernel to
extend a PCR.
The current version 1.0-rc5 of TrustedGRUB (August
2006) contains at least two other bugs. The hashing of
its own code when starting from hard disk is broken. The
corresponding PCR is never extended and always zero.
Furthermore TrustedGRUB never contained any code to
230
16th USENIX Security Symposium
USENIX Association
+
+
+
3
+
+
use it securely from a CD. Nevertheless, it is used on a
couple of LiveCDs [6].
All publicly available TPM-enabled bootloaders vio-
late the third assumption, which makes systems booted
by them unable to prove their trustworthiness. To an-
alyze this it was not necessary to look at more sophis-
ticated attack points such as missing range checks or
buffer overﬂows. Both of these will become more in-
teresting if the aforementioned bugs are ﬁxed.
2.2 TPM Reset
In July 2004 we discovered that setting the reset bit
in a control register of a v1.1 TPM3 resets the chip
without resetting the whole platform. This violates the
second condition. As it results in default PCR values,
this breaks the remote attestation and sealing features of
those chips: Any PCR value can be reproduced without
the opportunity for a remote entity to see the difference
via remote attestation. Unsealing protected secrets of
a security critical program is possible after resetting as
well. The reset feature was added for maintenance rea-
sons but does not have broad security consequences, be-
cause sealing and remote attestation are not used in any
product application with v1.1 chips. Instead the chips
are solely used as smartcard for signing and key man-
agement.
This case demonstrates the security risk of a reset-
table TPM. As other chips have different interfaces and
can therefore not be reset in the same way, we exper-
imented with a simple hardware attack. The Low Pin
Count (LPC) bus was the point of attack. Most TPMs
are connected to the southbridge through it and the bus
has a separate reset line. We used different TPMs on
external daughterboards for this experiment.
By physically connecting the LRESET# pin to
ground we were able to perform a reset of the chip
itself. We separated the pin from the bus as other-
wise the PS/2 keyboard controller received such a re-
set signal, too. We had to reinitialize the chip which
we did by reloading the driver and then sending a
TPMStartup(TPM_CLEAR) to the chip. This pro-
cess gave us an activated and enabled TPM in a state
normally only visible to the BIOS: As expected all PCRs
were in their default state. We presume that this attack
could be mounted against any TPM in a similar way.
The simplicity of the reset makes this hardware at-
tack a threat to trusted computing systems. In particular
in use cases where physical access, for example, through
theft, can not be excluded. This attack also affects an-
other use case of trusted computing, the widely disputed
Digital Rights Management scenario where the owner
of a device is untrusted and can use the system unin-
tendedly.
We have to admit that the TCG does not claim to
protect against hardware attacks. But scenarios using
trusted computing technology have to be aware of these
restrictions.
2.3 BIOS Attack
We have shown that bootloader and TPM implemen-
tations have some weaknesses. Now we look at the en-
tity in-between them: the BIOS.
The BIOS contains the Core Root of Trust for Mea-
surement (CRTM), a piece of code that extends PCR 0
initially. A CRTM has only to be exchanged with vendor
signed code. Currently, the CRTM of many machines is
freely patchable. It is stored in ﬂash and no signature
checking is performed on updates. This violates the ﬁrst
condition needed by a trust chain.
We used a HP nx6325, a recent business notebook
with a TPM v1.2, for this experiment. The fact that the
BIOS is ﬂashed from a raw image eased an attack. Other
vendors are checking a hash before ﬂashing the image to
avoid transmission errors, a feature that is missing here.
Checking a hash is irrelevant from a security point of
view but it would make the following steps slightly more
complicated, as we would have to recalculate the correct
hash value.
The part of the BIOS we choose to patch is the TPM
driver. This has the advantage that all commands to the
TPM, whether they come from the CRTM or from a
bootloader through the INT 1Ah interface, can be in-
tercepted. Our BIOS has only a memory-present TPM
driver. These drivers need access to main memory for
execution and can therefore only run after the BIOS has
initialized the RAM. The interface of the TPM drivers
are deﬁned in the TCG PC client speciﬁcation for con-
ventional BIOS [34]. The function that we want to
disable is MPTPMTransmit() which transmits com-
mands to the TPM. We found the TPM driver in the
BIOS binary quite easily. Strings like ’TPM’ and the
magic number of the code block as well as character-
istic mnemonics (e.g., in and out) in the disassembly
point to it.
Figure 2 shows the start of the BIOS TPM driver. It
starts with a magic number and entry point, both as de-
ﬁned in the speciﬁcation. The code itself starts at ad-
dress 0x28. We now search for an instruction that al-
lows us to disable MPTPMTransmit(). The ﬁrst in-
structions of the driver are quite uninteresting. They
just save some registers to the stack and calculate the
drivers starting address in register edi in order to make
the code position independent. The ﬁrst interesting in-
struction is the comparison at address 0x3a. By look-
USENIX Association
16th USENIX Security Symposium
231
0:
4:
28:
29:
2a:
2b:
2d: