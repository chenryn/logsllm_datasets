# 1RMA: Re-envisioning Remote Memory Access for Multi-tenant Datacenters

**Authors:**
- Arjun Singhvi†‡
- Aditya Akella†‡
- Dan Gibson‡
- Thomas F. Wenisch‡
- Monica Wong-Chan‡
- Sean Clark‡
- Milo M. K. Martin‡
- Moray McLaren‡
- Prashant Chandra‡
- Rob Cauble‡
- Hassan M. G. Wassel‡
- Behnam Montazeri‡
- Simon L. Sabato∗
- Joel Scherpelz◦
- Amin Vahdat‡

**Affiliations:**
- ‡ Google Inc.
- † University of Wisconsin - Madison
- ∗ Lilac Cloud
- ◦ Unaffiliated

## Abstract

Remote Direct Memory Access (RDMA) is crucial for high-performance datacenter applications. However, existing RDMA technologies are not well-suited for multi-tenant datacenters, where applications run at massive scales, require isolation and security, and the workload mix changes over time. Our experiences in operationalizing RDMA at scale indicate that these issues stem from the fundamental design attributes of standard RDMA, such as its connection-oriented nature and complex hardware policies.

We introduce a new approach to remote memory access, called One-Shot RMA (1RMA), tailored for multi-tenant datacenter environments. The 1RMA Network Interface Card (NIC) is connection-free and fixed-function, treating each RMA operation independently and providing fine-grained delay measurements and fast failure notifications. 1RMA software handles operation pacing, congestion control, failure recovery, and inter-operation ordering when needed. Deployed in our production datacenters, the 1RMA NIC supports line-rate encryption (100Gbps and 100M ops/sec) with minimal performance and availability disruption during encryption key rotation.

**CCS Concepts:**
- Networks → Network design principles; Data center networks.

**Keywords:**
- Remote Memory Access
- Connection Free
- Congestion Control

**ACM Reference Format:**
Arjun Singhvi, Aditya Akella, Dan Gibson, Thomas F. Wenisch, Monica Wong-Chan, Sean Clark, Milo M. K. Martin, Moray McLaren, Prashant Chandra, Rob Cauble, Hassan M. G. Wassel, Behnam Montazeri, Simon L. Sabato, Joel Scherpelz, Amin Vahdat. 2020. 1RMA: Re-envisioning Remote Memory Access for Multi-tenant Datacenters. In Proceedings of the ACM SIGCOMM 2020 Conference, August 10–14, 2020, Virtual Event, NY, USA. ACM, New York, NY, USA, 14 pages. https://doi.org/10.1145/3387514.3405897

## Introduction

Modern datacenter applications, such as search, ad serving, video transcoding, and machine learning, demand networks that support high bandwidth and operation rates while achieving low tail latencies. Remote Direct Memory Access (RDMA) is an attractive option for such distributed systems due to the latency and op-rate benefits provided by one-sided reads and writes, which involve no remote CPU and thus offer performance limited only by hardware.

However, industry-standard RDMA, evolved from supercomputer environments, has been challenging to deploy in commercial datacenters. RDMA assumes low-latency, reliable, ordered networks, and supercomputing fabrics deliver on these expectations via switch-enforced lossless link-level flow control. These fabrics are typically single-tenant or statically partitioned, and RDMA solutions for authorization, access control, fault recovery, and privacy reflect single-tenant expectations.

In contrast, modern hyperscale datacenters are characterized by multi-tenancy, where uncoordinated large-scale distributed applications share common infrastructure. A diverse, time-varying application mix induces rapidly changing network traffic patterns, necessitating strong privacy and authentication. These requirements create tension with standard RDMA’s design choices:

- **Connection-Oriented Design:** Standard RDMA offers connections in hardware, an abstraction that aligned well with early RDMA applications but limits at-scale isolation, performance, and fault tolerance. With modern serving and storage systems operating beyond ten-thousand-server scale, per-connection hardware resources are easily exhausted. Workarounds, such as connection sharing, lead to broken isolation, further exacerbated under failures.
- **Congestion Control:** Congestion control algorithms need constant iteration in response to deployment and application considerations. Standard RNICs and switches bake significant portions of congestion response into hardware, leaving little opportunity to adapt post-deployment.
- **Security and Privacy:** As applications and infrastructure are mutually untrusting, multi-tenancy calls for line-rate encryption and application support to manage the provenance of encryption keys. Although modern RNICs provide encryption, practical challenges arise: encryption is intrinsically tied to the notion of connections, applications must trust lower levels of the stack to manage keys, and there is no support for security-related management operations, such as encryption key rotation.

## Division of Responsibilities

Table 1 highlights the division of responsibilities between standard RDMA and 1RMA. By moving a subset of functionality to software, we simplify hardware and enable more flexibility and rapid iteration.

| Responsibility | RDMA | 1RMA |
|----------------|------|------|
| Inter-op Ordering | NIC | Software |
| Failure Recovery | NIC | Software |
| Flow and Congestion Control | NIC and Fabric | NIC and Software |
| Security Operations (e.g., Rekey) | None | NIC |

## 1RMA Design

We take a new approach to remote memory access (RMA) to better match the constraints of consolidated, multi-tenant datacenters. Our approach delivers the performance advantages of standard one-sided RDMA—high bandwidth, high op rate, and low latency—while also providing predictable tail performance, scalability, fault tolerance, isolation, security features, and amenability to rapid post-deployment iteration.

### Key Design Idioms

1. **No Connections:** 1RMA is connection-free. Hardware state does not grow with the number of endpoint pairs. Freed from connection semantics, the NIC can treat each operation independently, leaving software to handle inter-operation ordering when needed. 1RMA assigns to software the duties of per-operation retry and fault recovery, and instead provides simpler fail-fast behavior: 1RMA hardware ensures timely completions (10× slowdown). 1RMA’s congestion control converges to fair bandwidth shares in the presence of competing applications almost immediately (25μs); separately reacting to local congestion improves convergence speed by 20×. First-class support for security reduces the unavailability period during encryption key rotations to <1μs. These gains come at a minimal cost of 0.5 cores to drive 100 Gbps line-rate, as 1RMA chunks large operations into 4KB operations and implements congestion control and operation management in software.

## Background and Motivation

Standard RDMA offers three different transport types, each supporting a different subset of operations (Table 2). The prevalent transport is RC, or "reliable connected".

### Queue Pairs (QPs) and Connections

An application establishes connected queue pairs (QPs) between application-pairs via out-of-band exchange of tokens (e.g., via RPC or librdmacm). The server-side QP is configured with the client's address and other parameters, and the client-side QP is similarly configured. Once established, QPs provide a reliable, ordered, and connection-oriented communication channel.