(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:2)(cid:6)(cid:7)(cid:8)(cid:6)(cid:2)(cid:9)
(cid:10)(cid:2)(cid:11)(cid:12)(cid:13)(cid:19)
(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:2)(cid:6)(cid:7)(cid:8)(cid:6)(cid:2)(cid:9)
(cid:10)(cid:2)(cid:11)(cid:12)(cid:13)(cid:19)(cid:16)(cid:17)
Figure 3: Control ﬂow between data-ﬂow nodes
after the sensitive sink can, because the potentially harmful
instruction will already have been executed. Note that this
assumption may not hold in face of parallel execution or
precautions taken by the operating system.
We divide security mechanisms into security checks and
sanitizations. For our purposes, a security check has the
following properties:
1. It occurs in the control ﬂow between user-controlled
source and sensitive sink.
2. It uses data derived from the sensitive data ending up
in the sensitive sink.
3. Its result inﬂuences the control ﬂow to stop this data
ﬂow to the sensitive sink.
This captures both direct and indirect examples:
f r e a d ( ( v o i d ∗)& l e n , 4 , 1 ,
i f ( l e n = 2 5 6 ;
i f ( i s t o o l a r g e ) e x i t ( 1 ) ;
To ﬁnd security checks, we simply follow the path between
source and sink, while tracing which data is inﬂuenced by the
sensitive data. Then, we use this information to determine
if it causes a control-ﬂow divergence.
For sanitization, the constructs to search for are highly
speciﬁc for the sensitive sink: data which ends in a shell-
command (e.g., system() has to be sanitized in a diﬀerent
way than data for an SQL query. One cannot, however,
assume in general that every change to the data is actu-
ally a sanitization. As of now, our prototype does recognize
some sanitizations, like inserting 0x00-bytes into strings to
restrict their length, but our instrumentations do not cover
manipulating such sanitizations, yet.
220
3.7
Instrumentations
The instrumentations, i.e., our code transformations that
actually disable security mechanisms, happen in three steps:
1. Bugdoorability: Decide, if our models “understand”
the security mechanism.
2. Applicable instrumentations: Enumerate the pos-
sible instrumentations for this security mechanism.
3. Apply random instrumentation: Choose a possi-
ble instrumentation at random and apply it.
The ﬁrst and second steps are somewhat intermingled and
rather straightforward, as we simply compare the type of
mechanisms a speciﬁc instrumentation can disable against
the security mechanism. For our prototype, we mainly fo-
cus on disabling security checks, which means constructs like
if(length > 256) {. . .} and thus implemented the follow-
ing instrumentations classes:
false (resp. true), to never (resp. always) execute
• Remove security mechanism
• Surround by if with constraints always evaluating to
• Arithmetically inﬂuence decision logic
• Move security mechanism into an unrelated path
• Swap the security mechanism and sensitive sink
• Use security anti-patterns for integer overﬂow checks
Note that an instrumentation class can cover many in-
strumentations. For example, we can transform a statement
such as (length > 256) to diﬀerent representations:
• (length > 512)
• (length/2 > 256)
• (length > 256*2)
• ((char)length > 256)
Thus, we do not think that there is a fair way to count
the number of actual instrumentations to introduce a bug,
as instrumentation subclasses could be deﬁned almost arbi-
trarily and syntactic changes introduced by an instrumen-
tation class are virtually unlimited. Thus, we refrain from
reporting the number of possible instrumentations during
the evaluation of our prototype.
4. EVALUATION
In the following, we evaluate our prototype for automatic
bug insertion called EvilCoder with respect to its perfor-
Table 1: Results of automatic bug insertion
Lines of code
User-controlled sources (UCS)
Sensitive sinks (Si)
Unique UCS-Si combinations
UCS-to-Si data-ﬂow paths
libpng vsftpd wget busybox
265,887
40,044
9
152
573
98
30
158
22,516
2,905
20,046 137,234
21
453
22
1,882
3
13
22
786
Table 2: Runtime in minutes:seconds for diﬀerent phases of
processing open-source projects
Runtime for phase
Importing with Joern
libpng
vsftpd wget
busybox
00:32
00:24
00:58
03:49
Analyzing intraprocedural behaviour
00:35
00:12
01:33
03:42
mance, the quantity of security-critical bugs it can intro-
duce, and the exploitability of said introduced bugs.
To this end, we tried to introduce vulnerabilities into
open-source projects, namely libpng, wget, busybox, and
vsftpd. We found between 22 and 158 unique source-sink
pairs for each tested project, which translates to hundreds of
security-critical data paths. This in turn implies hundreds of
diﬀerent security-critical bug variations we could introduce.
Our rationale regarding the exploitability is as follows: By
deﬁnition, the vulnerabilities we study have a data ﬂow from
a user-controlled source to a sensitive sink. If only insuﬃ-
cient security mechanisms are found on this data-ﬂow path,
we have a taint-style vulnerability. Assuming that the path
was not vulnerable to begin with, the security mechanisms
on the path are the reason as to why the path is not vul-
nerable. Consequently, this means that relaxing the security
mechanisms makes the path vulnerable.
Naturally, the sheer volume of generated bugs, combined
with the lack of practical automatic exploit generation, means
that we cannot verify that every single introduced bug is ac-
tually exploitable. However, we chose to justify our claim
of introducing exploitable bugs by taking a patched ap-
plication, which had real-world exploitable CVEs, and re-
introducing a security-critical bug into the path in question.
4.1 Setup
All experiments were conducted in a virtual Debian 8
“Jessie” machine, with an Intel Core i7-2640M @ 2.8GHz,
8GB DDR3-RAM @ 1600MHz and an SSD.
4.2 Bugdooring Open-Source Projects
For this experiment, we tried to insert bugs into four open-
source projects. We chose libpng, the oﬃcial reference li-
brary for the popular image format PNG, because it suﬀered
from a well-studied CVE which we wanted to use as a case
study in a following experiment (see Section 4.4). Further-
more, we chose the two popular standalone programs wget
v1.16 and busybox v1.24.1. The FTP server vsftpd was
implemented with security in mind, which is why it performs
all buﬀer-related operations through a set of wrapper func-
tions to shield the actual application code from the sanity
checks necessary to prevent buﬀer overﬂows or overreads.
As one can see in Table 1, our tool is able to ﬁnd a sub-
stantial number of sensitive data paths for each application.
The library libpng has a lot of such paths compared to its
code size, which was expected since the PNG ﬁle format in-
corporates several context sensitive length ﬁelds. For this
library, the number of user-controlled sources is rather low,
since most data ﬂow actually traces back to one of a few
ﬁle reading operations. Compared to that, the number of
user-controlled sources in wget and busybox is rather high,
given that they exchange data not only via ﬁles. Considering
that we mostly searched for user-controlled length ﬁelds, the
number of found potentially vulnerable paths was expected.
As mentioned before, vsftpd performs all buﬀer-related op-
erations through a set of wrapper functions.
Indeed, the
Augmenting code property graph for interprocedural analysis
35:28
00:22
03:40
01:18
Finding UCS-to-Si paths
Total:
...per 10,000 LOC:
01:56
04:21
01:05
00:49
01:47
00:53
02:14
08:25
00:37
7:05
50:04
01:56
number of both user-controlled sources and sensitive sinks
is very low, and all the potentially vulnerable paths our cur-
rent implementation found traverse the security checks of
these wrapper functions.
The value for unique user-controlled source (UCS) and
sensitive sink (Si) combinations refers to the number of user-
controlled source for which we found data-ﬂow from a single
sensitive sink, summed over all sensitive sinks:
)s∈Si
#{u ∈ U CS, where s connects to u}
In contrast, the number of UCS-to-Si data-ﬂow paths refers
to the sum over all data-ﬂow paths that connect the found
user-controlled sources and sensitive sinks. Since Joern
sometimes includes transitive data-ﬂow edges, the reported
numbers may be higher than the data ﬂows occurring when
executing the program. Thus, they can be seen as an upper
bound, while the unique UCS-Si combinations can serve as
a lower bound, which means that the actual number of data
ﬂows can be estimated to be between those two. Since the
number of control-ﬂow nodes connecting to data-ﬂow nodes
suﬀers from the same problem, we do not report them here.
As mentioned before, there is no fair way to estimate the
number of applicable instrumentations for a given UCS-to-
Si path, but given that multiple instrumentation classes are
applicable to each found path, it is safe to say that we can
introduce at least a hundred bugs into each tested project.
4.3 Performance
Table 2 shows that transforming the source code into code
property graphs using Joern is fast, although it does not
behave linearly in the size of code base. The next step (i.e.,
analyzing which functions set which parameters) is slower,
but seems to increase linearly with the size of the code base.
Naturally, some functions take longer to analyze than others,
depending on the number of their parameters, the number
of subfunctions they invoke and their general size, but we
observed this to average out over the full code base. The
time for augmenting the code property graph to facilitate
interprocedural analysis, as expected, grows for larger code
bases, but the size of the code base is not the only relevant
factor: we observed that intertwined programs, where a lot
of function are called in a lot of places, result in increased
runtime. Similarly, the time for ﬁnding potentially vulnera-
ble paths depends not only on the size of the code base, but
especially on the fan-out of potential continuations of the
data ﬂow. Function pointers in particular are problematic
in this context. Since a speciﬁc data-ﬂow path only has to
be traversed once per variable to know whether it ends up
221
in a user-controlled source, tracing the data ﬂow for a spe-
ciﬁc sensitive sink tends to get faster towards the end of the
algorithm when more nodes have already been visited.
Given the nature of C code, transforming it into property
graphs is most likely best performed in one step. Intrapro-
cedural analysis to facilitate the augmentation of the code
property graphs for interprocedural analysis, however, could
be performed in an ad-hoc fashion, depending on the neces-
sities of the source-to-sink data-ﬂow analysis. This would
allow us to analyze a smaller subset of the program and
increase performance.
4.4 Case Study: Libpng CVE-2004-0597
Libpng had multiple buﬀer overﬂow vulnerabilities de-
scribed in CVE-2004-0597. Here, we will discuss the auto-
matic removal of the introduced security guards. We chose
this example for two reasons: First, it is well studied, as its
exploitation is a training example in an undergrad course [23].
Second, it highlights some of our tool’s features, namely in-
terprocedural analysis, function pointers, data-ﬂow through
struct members, and removal of multiple guards.
In particular this CVE describes a stack buﬀer overﬂow
due to a malformed palette-index. A stack buﬀer of ﬁxed
size (256 bytes) is allocated to hold a color palette index.
However, the length of the palette is read from a png ﬁle and
libpng only checked whether this value exceeded the size of
the main color palette. This did not prohibit the attacker
from claiming an index palette size of more than 256 bytes
in the png ﬁle, which lead to a stack buﬀer overﬂow. Thus,
a patch was issued to additionally check, whether the length
exceeded 256 bytes, the maximum size for an index palette.
Sensitive Sink and User-Controlled Source
4.4.1
The length for the palette-index is passed through four
functions in three diﬀerent ﬁles, until the buﬀer is ﬁlled at
the sensitive sink: a call to fread(). Since fread() is user-
controlled, the attacker controls the stackbuﬀer’s contents,
which makes this vulnerability likely to be exploitable.
The way to the user-controlled source for the length-ﬁeld
is a little more complex. Over the course of ten functions
in ﬁve ﬁles, it changed its name eight times and its type
once. One had to track data ﬂow through three diﬀerent
struct members, the data was copied, passed as parameters,
returned and ﬁlled via memcpy() from an internal buﬀer,
which in turn was ﬁnally set via fread().
Instrumentations
4.4.2
There are 22 nodes in the data-ﬂow path from the user-
controlled source to the sensitive sink, but the shortest of
the 144 connecting control-ﬂows is already 114 nodes long
and includes 37 checks. Only ﬁve of those are overarched
by the respective variable connecting two nodes in the data
ﬂow. Three of them check internal relations between buﬀer
sizes and another one checks for an out-of-range integer. The
ﬁnal one is the check which was issued with the patch.
The conditions of the ﬁrst three checks have to be ful-
ﬁlled to continue execution, but their alternative path does
not immediately abort the program and thus our approach
deems them not to be security critical. The out-of-range
check, however, would abort execution, which is why our ap-
proach would instrument it to never evaluate to true. While
this introduces a bug, it does not hinder execution on well-
formed input. As for the last check, our tool automatically
determines that it must never evaluate to true and can de-
termine which of our instrumentation classes apply. Then,
it applies one of those instrumentations and thereby intro-
duces a bug. Because we know that an exploit for the pro-
gram lacking this very check exists, we can conclude that
our tool successfully inserted an exploitable vulnerability.
General Obstacles.
We found that libpng uses the C preprocessor directive
#define png_memcpy memcpy and only uses png_memcpy()
throughout its code. We found this pattern of using macros
for simple wrapper functionality to occur frequently. Since
this alias does not stem from C code, it cannot be detected
with C-analysis alone. Thus, source code analysis for C
either has to be aware of preprocessor macros or utilize the
preprocessor, like we do.
5. LIMITATIONS AND FUTURE WORK