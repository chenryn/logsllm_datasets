Aylin Caliskan
      @aylin_cim
Assistant Professor
George Washington University
Rachel Greenstadt
      @ragreens
Associate Professor
Drexel University
De-anonymizing Programmers from Source Code and Binaries
August 10, 2018
1
Stylometry
Natural language
English
English as a second language
Translated text
Underground forum text
Artificial language
Programming languages
Python
C/C++
Source code
Binary executables
August 10, 2018
2
Stylometry
Natural language
FBI
Expert witnesses
European high-tech crime units
Artificial language
Expert witnesses
DARPA
US Army Research Laboratory
August 10, 2018
3
August 10, 2018
Why de-anonymize programmers?
4
Iran confirms death sentence for 'porn site' web programmer.
No technical difference between 
security-enhancing and privacy-infringing
Source code stylometry
August 10, 2018
5
Source code stylometry
 Application
Learner 
Setting
Software forensics
Multiclass 
Open world
Stylometric plagiarism detection
Multiclass 
Closed world
Copyright investigation
Two-class
Closed world
Authorship verification
Two-class/One-class
One-class open world
A machine learning classification task
August 10, 2018
6
Random Forest Classifier
 A           B            C           D
De-anonymizing Programmers
Fuzzy Parsing
Identifying 
Programmer Fingerprints
Language 
Processing
Supervised 
Machine Learning
Privacy and Security 
Implications
Source Code
August 10, 2018
7
De-anonymizing programmers
 Application
Classes
Instances
Accuracy
Stylometric plagiarism detection
250 class
  2,250
  98%
Large scale de-anonymization
1,600 class
14,400
  94%
Copyright investigation
Two-class
     540
100%
Authorship verification
Two-class/One-class
  2,240
  91%
Open world problem
Multi-class
     420
  96%
Principled method & robust syntactic feature set
August 10, 2018
8
Source code stylometry
preprocessing
extract features
majority vote
 A            B             C             D
random forest
fuzzy AST parser
1,600 contestants – C++
De-anonymized Programmers
August 10, 2018
9
Features
     Source code                                             Abstract syntax tree
August 10, 2018
10
Case 1: Authorship attribution
•Who is this anonymous programmer?
•Who is Satoshi?
August 10, 2018
11
Case 1: Authorship attribution
•If only we had a suspect set for Satoshi…
Train on the suspect set
to de-anonymize the
initial Bitcoin author
train
test
Satoshi = git contributor
August 10, 2018
12
Case 1: Authorship attribution
•94% accuracy in identifying 1,600 authors of 14,400 anonymous 
program files.
Train on 1,600 authors 
to identify the
authors of 14,400 files 
train
test
94% accuracy
August 10, 2018
13
Case 2: C++ Obfuscation - STUNNIX
August 10, 2018
14
Case 2: C++ Obfuscation - STUNNIX
Same set of 25 authors
with 225 program files
Classification 
Accuracy
Original source code
97%
STUNNIX-Obfuscated source code
97%
August 10, 2018
15
Case 2: C Obfuscation - TIGRESS
August 10, 2018
16
Case 2: C Obfuscation - TIGRESS
August 10, 2018
17
Case 2: C Obfuscation - TIGRESS
August 10, 2018
Same set of 20 authors
with 180 program files
Classification 
Accuracy
Original C source code
96%
TIGRESS-Obfuscated source code
67%
18
Case 3: Authorship verification
•Is this source code really written by this programmer?
Test on 6 files that belong to Mallory
and 6 files that belong to 6 random authors.
Mallory M M M M M M M
A
B C
D
E
F
G
H
M M M M M M
X1 X2 X3 X4 X5 X6
93% accuracy in 80 sets of experiments
Train on 8 files from Mallory and one file 
from authors A, B, C, D, E, F, G, and H.
August 10, 2018
19
What about executable binaries?
Compiled code looks cryptic
 00100000 00000000 00001000 00000000 00101000 00000000   
 00000000 00000000 00110100 00000000 00000000 00000000  
 00000100 00001000 00000000 00000001 00000000 00000000  
 00000000 00000001 00000000 00000000 00000101 00000000  
 00000000 00000000 00000100 00000000 00000000 00000000  
 00000011 00000000 00000000 00000000 00110100 00000001  
 00000000 00000000 00110100 10000001 00000100 00001000  
 00000000 00000000 00010011 00000000 00000000 00000000  
 00000100 00000000 00000000 00000000 00000001 00000000  
 00000000 00000000 00000001 00000000 00000000 00000000  
 00000000 00000000 00000000 00000000 00000000 10000000  
 00000100 00001000 00000000 10000000 00000100 00001000  
 11001000 00010111 00000000 00000000 11001000 00010111  
 00000000 00000000 00000101 00000000 00000000 00000000  
Source Code
#include 
#include 
using namespace std;
#define For(i,a,b) for(int i = a; i = a; i--)
double nextDouble() {
double x;
scanf("%lf", &x);
return x;}
int nextInt() {
int x;
scanf("%d", &x);
return x; }
int n;
double a1[1001], a2[1001];
int main() {
freopen("D-small-attempt0.in", "r", stdin);
freopen("D-small.out", "w", stdout);
int tt = nextInt();
For(t,1,tt+1) {
int n = nextInt();        
. . .
. . .
August 10, 2018
20
August 10, 2018
21
August 10, 2018
22
Features: Assembly
August 10, 2018
      Disassembly                    Assembly Features
Assembly unigrams
Assembly bigrams
Assembly trigrams    
Two consecutive assembly lines
23
Features: Syntactic
August 10, 2018
24
Features: Control flow
August 10, 2018
25
Dimensionality Reduction
• Information gain criterion
• Keep features that reduce entropy – see (a) 
• Reduce dimension from ~700,000 to ~2,000
August 10, 2018
26
Dimensionality Reduction
• Information gain criterion
• Keep features that reduce entropy – see (a) 
• Reduce dimension from ~700,000 to ~2,000
August 10, 2018
•Correlation based feature selection
•Keep features with low inter-class correlation
•Reduce dimension from ~2,000 to 53
27
Predictive features
August 10, 2018
28
Optimizations and stripping symbols
August 10, 2018
Number of 
programmers
Number of training 
samples
Compiler 
optimization level
Accuracy
100
8
None
96%
100
8
1
93%
100
8
2
89%
100
8
3
89%
100
8
Stripped symbols
72%
29
Obfuscation
1. Bogus control flow insertion               2. Instruction substitution 
August 10, 2018
3. Control flow flattening
30
Obfuscation
1. Bogus control flow insertion               2. Instruction substitution 
August 10, 2018
3. Control flow Flattening
Open-LLVM obfuscations reduce
de-anonymization accuracy of
100 programmers from 96% to 88%.
31
Large scale programmer de-anonymization
August 10, 2018
32
GitHub and Nulled.IO
•De-anonymizing 50 GitHub programmers 
• with 65% accuracy.
•De-anonymizing 6 malicious programmers
• Nulled.IO hackers and malware authors
• with 100% accuracy.
August 10, 2018
33
Programmer De-anonymization on GitHub
✓
Single authored GitHub repositories
✓
The repository has at least 500 lines of code
Compile 
repositories
August 10, 2018
3,438
161
439
2 - 8
2 - 344
50
542
450
50
65%
97%
34
Collaborative Code
35
August 10, 2018
Segment and Account Attribution
● Sometimes we only care who wrote a small piece of code
● Sometimes we want to deanonymize a pseudonymous account
○ Without whole files belonging to it, only small pieces
● In these cases, we can only attribute small segments, or “snippets” 
● Using the manual feature set 
○ Large, sparse features (3,407 nonzero out of 369,097 total)
36
August 10, 2018
Segment attribution results
73% accuracy 
(average sample 4.9 lines of code)
37
August 10, 2018
Accuracy vs LOC
38
August 10, 2018
Attribute accounts not individual commits?
Works much much better! 
- close to 100% after 4 snippets
39
August 10, 2018
Deep Learning AST Representations
Using AST features allowed us to get good results. 
 But….
A Tree is not a 
feature!
40
August 10, 2018
We manually chose features of the ASTs
41
August 10, 2018
Can a deep neural net do better?
● Embedding Layer
○ Map AST nodes to feature vectors
● Subtree Layers
○ Learn the structure of the AST
■
Subtree LSTM
■
Subtree BiLSTM (bidirectional)
● Softmax Layer
○ Generate a probability distribution of 
the programmers
42
August 10, 2018
Long Short-Term Memory Networks
Recurrent neural networks (RNNs)
● Handle sequential input
● Add feedback loops to remember 
information
LSTMs add memory cells
● Sequential long-term dependencies
● Use gates to control flow of 
information
What should I remember?
What should I ignore?
What should I forget?
43
August 10, 2018
Results
Using only AST features (No lexical or layout features)
Python 
(25 programmers)
Python
 (70 programmers)
C++ 
(10 programmers)
Random Forest
86.00
72.90
75.90
Linear SVM
77.20
61.28
73.50
LSTM
92.00
86.36
80.00
BiLSTM
96.00
88.86
85.00
44
August 10, 2018
So what?
● Learn better AST representations without feature engineering
● Language independent - any programming language that supports 
ASTs
Future work
● Combine with Random Forests and fuller feature sets
○ Better results or just overlap with other features?
45
August 10, 2018
What about other languages?
Porting requires AST parser and lexical/layout features
Similar accuracies so far (on GCJ dataset)
Results with just AST vary
46
August 10, 2018
Train on one language test on another?
● This is something we’d like to try
● Need either universal intermediate 
AST representation or pairwise
● Babblefish project (doesn’t appear 
to be ready yet)
47
August 10, 2018
Interesting Software 
Engineering Insights
48
August 10, 2018
What about attributing groups?
Looked at                            team programming competition
Teams compete on sets of problems
Preliminary results:
118 Codeforces teams, at least 20 submissions each
● 10-fold cross-validation: 67.2% accuracy
● 20-fold cross-validation: 67.8% accuracy
Difficult because they are likely splitting up the problems completely
Future work: code repositories
49
August 10, 2018
Difficult vs. Easy Tasks
Implementing harder functionality makes programming 
style more unique.Same set of 62 authors
Classification Accura
Same set of 62 programmers Classification Accuracy
Solving 7 Easy Problems
90%
Solving 7 Harder Problems
95%
50
August 10, 2018
Effect of Programming Skill?
Programmers who got further in the GCJ Contest were 
easier to attribute.Same set of 62 authors
Classification Accura
Same set of 62 programmers Classification Accuracy
Less Advanced Coders
80%
More Advanced Coders
95%
51
August 10, 2018
How does coding style change over time?
● 92% accuracy, train and test on 2012
● 88% accuracy, train on 2012, test on 2014
52
August 10, 2018
Coding style by country?
GCJ files (in javascript) written by programmers in Canada and China
● 84 files
● 91.9% classification accuracy
53
August 10, 2018
Future Applications
● Find malicious code authors
○ anonymous contributors
● Write better obfuscators
○ target AST directly
● Find authors who write vulnerable code
○ open source code
● Find who to recruit directly
○ from git commits
54
August 10, 2018
Thanks to collaborators
Bander Alsulami, Edwin Dauber, Richard Harang, Andrew Liu, Spiros 
Mancoridis, Arvind Narayanan, Frederica Nelson, Mosfiqur Rahman, 
Dennis Rollke, Konrad Rieck, Gregory G. Shearer, Clare Voss, Michael J. 
Weisman, Fabian Yamaguchi
55
August 10, 2018
Aylin Caliskan
@aylin_cim
PI:EMAIL
Contact information       and         Q & A
Source code authorship attribution:  https://github.com/calaylin/bda 
Javascript authorship attribution: 
https://github.com/dns43/CodeStylometry/tree/master/SCAA/src 
Binary authorship attribution:  https://github.com/calaylin/bda 
Rachel Greenstadt
@ragreens
PI:EMAIL
56
August 10, 2018
Comparison to related work
Related
Work
Author
Size
Instances
Average
LOC
Language