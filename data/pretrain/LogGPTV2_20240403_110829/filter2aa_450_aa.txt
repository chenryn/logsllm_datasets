# De-anonymizing Programmers from Source Code and Binaries

**Presented by:**
- **Aylin Caliskan**  
  Assistant Professor, George Washington University  
  [@aylin_cim](https://twitter.com/aylin_cim)
- **Rachel Greenstadt**  
  Associate Professor, Drexel University  
  [@ragreens](https://twitter.com/ragreens)

**Date:** August 10, 2018

## 1. Introduction to Stylometry
Stylometry is the study of linguistic style in written text. It can be applied to both natural and artificial languages, including:
- **Natural Languages:**
  - English
  - English as a second language
  - Translated text
  - Underground forum text
- **Artificial Languages:**
  - Programming languages (e.g., Python, C/C++)
  - Source code
  - Binary executables

## 2. Applications of Stylometry
Stylometry has been used by various organizations for different purposes:
- **Law Enforcement:**
  - FBI
  - Expert witnesses
  - European high-tech crime units
- **Research and Development:**
  - DARPA
  - US Army Research Laboratory
  - Expert witnesses

## 3. Motivation for De-anonymizing Programmers
- **Ethical and Legal Implications:**
  - Iran confirms death sentence for a 'porn site' web programmer.
  - There is no technical difference between security-enhancing and privacy-infringing uses of source code stylometry.

## 4. Source Code Stylometry Applications
- **Software Forensics:**
  - Multiclass, open world
- **Stylometric Plagiarism Detection:**
  - Multiclass, closed world
- **Copyright Investigation:**
  - Two-class, closed world
- **Authorship Verification:**
  - Two-class/One-class, one-class open world
- **Machine Learning Classification Task:**
  - Random Forest Classifier

## 5. Methodology
- **Fuzzy Parsing:**
  - Identifying programmer fingerprints
- **Language Processing:**
  - Supervised machine learning
- **Privacy and Security Implications:**
  - Source code analysis

## 6. Experimental Results
- **De-anonymizing Programmers:**
  - **Stylometric Plagiarism Detection:**
    - 250 classes, 2,250 instances, 98% accuracy
  - **Large Scale De-anonymization:**
    - 1,600 classes, 14,400 instances, 94% accuracy
  - **Copyright Investigation:**
    - Two-class, 540 instances, 100% accuracy
  - **Authorship Verification:**
    - Two-class/One-class, 2,240 instances, 91% accuracy
  - **Open World Problem:**
    - Multi-class, 420 instances, 96% accuracy

## 7. Case Studies
- **Case 1: Authorship Attribution**
  - **Satoshi Nakamoto (Bitcoin Creator):**
    - 94% accuracy in identifying 1,600 authors of 14,400 anonymous program files.
- **Case 2: C++ Obfuscation - STUNNIX**
  - **Classification Accuracy:**
    - Original source code: 97%
    - STUNNIX-obfuscated source code: 97%
- **Case 3: C Obfuscation - TIGRESS**
  - **Classification Accuracy:**
    - Original C source code: 96%
    - TIGRESS-obfuscated source code: 67%

- **Case 4: Authorship Verification**
  - **Verification Accuracy:**
    - 93% accuracy in 80 sets of experiments

## 8. Executable Binaries
- **Challenges:**
  - Compiled code looks cryptic
- **Features:**
  - Assembly unigrams, bigrams, trigrams
  - Syntactic features
  - Control flow features

## 9. Dimensionality Reduction
- **Information Gain Criterion:**
  - Reduce dimension from ~700,000 to ~2,000
- **Correlation-Based Feature Selection:**
  - Reduce dimension from ~2,000 to 53

## 10. Optimizations and Stripping Symbols
- **Compiler Optimization Levels:**
  - None: 96% accuracy
  - Level 1: 93% accuracy
  - Level 2: 89% accuracy
  - Level 3: 89% accuracy
  - Stripped symbols: 72% accuracy

## 11. Obfuscation Techniques
- **Bogus Control Flow Insertion:**
- **Instruction Substitution:**
- **Control Flow Flattening:**
  - Open-LLVM obfuscations reduce de-anonymization accuracy from 96% to 88%.

## 12. Large-Scale Programmer De-anonymization
- **GitHub and Nulled.IO:**
  - De-anonymizing 50 GitHub programmers with 65% accuracy.
  - De-anonymizing 6 malicious programmers (Nulled.IO hackers and malware authors) with 100% accuracy.

## 13. Collaborative Code and Segment Attribution
- **Segment Attribution:**
  - 73% accuracy (average sample: 4.9 lines of code)
- **Account Attribution:**
  - Close to 100% after 4 snippets

## 14. Deep Learning AST Representations
- **AST Features:**
  - Embedding Layer
  - Subtree Layers (LSTM, BiLSTM)
  - Softmax Layer
- **Results:**
  - Python (25 programmers): 92% accuracy (LSTM), 96% accuracy (BiLSTM)
  - Python (70 programmers): 86.36% accuracy (LSTM), 88.86% accuracy (BiLSTM)
  - C++ (10 programmers): 80% accuracy (LSTM), 85% accuracy (BiLSTM)

## 15. Future Work
- **Porting to Other Languages:**
  - Similar accuracies on GCJ dataset
- **Cross-Language Training:**
  - Universal intermediate AST representation or pairwise training
- **Team Programming Competition:**
  - 118 Codeforces teams, 67.2% accuracy (10-fold cross-validation), 67.8% accuracy (20-fold cross-validation)
- **Effect of Task Difficulty and Skill:**
  - Harder tasks and more advanced coders have higher classification accuracy
- **Coding Style Over Time:**
  - 92% accuracy (train and test on 2012), 88% accuracy (train on 2012, test on 2014)
- **Coding Style by Country:**
  - 84 JavaScript files, 91.9% classification accuracy (Canada and China)

## 16. Future Applications
- **Finding Malicious Code Authors:**
- **Writing Better Obfuscators:**
- **Identifying Vulnerable Code Authors:**
- **Recruitment from Git Commits:**

## 17. Acknowledgments
- **Collaborators:**
  - Bander Alsulami, Edwin Dauber, Richard Harang, Andrew Liu, Spiros Mancoridis, Arvind Narayanan, Frederica Nelson, Mosfiqur Rahman, Dennis Rollke, Konrad Rieck, Gregory G. Shearer, Clare Voss, Michael J. Weisman, Fabian Yamaguchi

## 18. Contact Information and Q&A
- **Aylin Caliskan:**
  - [Email](mailto:PI@EMAIL)
  - [Source Code Authorship Attribution](https://github.com/calaylin/bda)
  - [JavaScript Authorship Attribution](https://github.com/dns43/CodeStylometry/tree/master/SCAA/src)
  - [Binary Authorship Attribution](https://github.com/calaylin/bda)
- **Rachel Greenstadt:**
  - [Email](mailto:PI@EMAIL)

## 19. Comparison to Related Work
- **Related Work:**
  - Author, Size, Instances, Average LOC, Language

---

This optimized version provides a clear, professional, and structured overview of the research and findings presented by Aylin Caliskan and Rachel Greenstadt.