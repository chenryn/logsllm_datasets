prove the security only for the components of our best performing
solution, composed by Circuit DORAM and ABWT based oblivious
substring search algorithm; similar proofs can be constructed for
Path and Ring DORAMs and for the ODSBWT algorithm.
As customary in the context of privacy-preserving protocols, our
security definitions are based on the simulation paradigm, which
mandates to prove the security guarantees of the protocol by show-
ing that its actual execution can be simulated by a simulator S
which knows only the information L leaked to the adversary in the
actual execution of the protocol. The leakage L must be defined
beforehand, and it is specific for each protocol; the existence of
the simulator S allows to prove that the adversary learns no more
information than L throughout the execution of the protocol.
A.1 DORAM Security
We assume that the DORAM stores a dataset D split in n blocks,
each of size B bits. In our security definition, besides the Access pro-
cedure already described throughout the manuscript, we consider
also an Init procedure, which is employed to build the DORAM
tree and insert the n blocks of D in the DORAM: specifically, for
each block, the algorithm obliviously adds to the stash the block at
hand and then evicts the stash to the DORAM tree following the
eviction strategy of the DORAM. In order to properly construct
the DORAM tree, the Init procedure employs several parameters
specified by the user: the recursive factor C to build the recursive
position map, the maximum number of real blocks per bucket Z,
the stash size S, the number of dummy blocks per buckets D and
the eviction period A. The security guarantees of DORAM are not
weakened if the adversary knows these values, since they depend
only on the number of blocks of the DORAM; thus, to simplify
our security analysis we assume that the Init procedure always
employs the same values for these parameters. Since our DORAMs
employs an integrity-check mechanism based on Merkle-trees, both
the Init and Access procedures may return the special value abort
in case they detect data tampering on the DORAM.
To outline the security definition for the DORAM primitive, we
need to introduce two further concepts: the trace T and the leakage
L for the adversary. The former represents the information directly
observed by the adversary while interacting with the DORAM:
Definition 1 (Trace of DORAM). Given a DORAM whose client
runs inside an SGX enclave and the DORAM tree is stored in the unpro-
tected memory, the trace of the DORAM is T = {CodeAP , DataAP ,
DataSrv}, with CodeAP and DataAP denoting the code and data
access patterns of the DORAM client, respectively, while DataSrv de-
notes the information sent by the DORAM client outside the enclave.
In our security definition, we split the trace in two components
TInit and TAcc, which refer to the trace of the Init and the Access
procedures, respectively. The leakage L denotes the information
about the dataset and the accessed blocks which is inferred by the
adversary from the trace T . We split the leakage L in two compo-
nents LInit and LAcc that represent the information inferred by
the adversary from TInit and TAcc, respectively.
Definition 2 (DORAM Security). Given a security parameter λ,
a DORAM ρ with trace T as in Def. 1, leakage L = {LInit , LAcc}
and an integer d≥1, consider the two interactive experiments Realρ,A
and Idealρ,A,S, outlined in Fig. 4, between a challenger and an
adversary A consisting of d+1 probabilistic polynomial time algo-
rithms, i.e., A={AInit , AAcc,1, . . . , AAcc,d}. Throughout the ex-
periments, the challenger may invoke the DORAM ρ and a simu-
lator S consisting of d+1 probabilistic polynomial time algorithms,
i.e., S={SInit ,SAcc,1, . . . ,SAcc,d}; the adversary A can tamper
with data and computation of the DORAM as described in our threat
model. Denoting as D a probabilistic polynomial time algorithm that,
given the output o of an experiment determines if o refers to Realρ,A
(D(o) = 0) or Idealρ,A,S (D(o) = 1) experiment, the DORAM ρ,
with leakage L and trace T , is secure against malicious probabilistic
polynomial time adversaries A if, for every possible A, there exists a
simulator S such that for every D:
Pr(D(o)=1|o←Realρ,A)−Pr(D(o)=1|o←Idealρ,A,S)≤ϵ(λ)
where ϵ(·) is a negligible function.
In the experiments outlined in Fig. 4, both the adversary and
the simulator are stateful, that is they have a state stA (resp. stS)
employed to store any information learned throughout the exper-
iment. In short, our security definition is satisfied if the outputs
of the two experiments outlined in Fig. 4 are computationally in-
distinguishable. This property is sufficient to guarantee that the
ACSAC 2020, December 7–11, 2020, Austin, USA
N. Mainardi, D. Sampietro, A. Barenghi, G. Pelosi
DORAM protocol leaks to any malicious adversary no more infor-
mation than the leakage L. Indeed, the information available to
the adversary at the end of the Idealρ,A,S experiment, namely
the trace of the DORAM T and the state stA of the adversary,
depends on the fake input data {DS,[bidS
i ]d
i =1} constructed by the
simulator S. Since Sconstructs the fake input data by knowing only
the leakage L provided by the challenger, no more information
than L about the actual data can be inferred by the adversary from
the operations observed over fake data. Since this experiment is
computationally indistinguishable from the Realρ,A one, then the
information available to the adversary in the Realρ,A experiment
cannot reveal more information than L about the actual data.
Furthermore, since the results of the d+1 operations must be
indistinguishable between the two experiments, our definition guar-
antees also that a malicious adversary cannot affect the result of the
computation without being detected by the DORAM client. Indeed,
in the Idealρ,A,S experiment, the challenger ensures that the result
of the computation is always the correct one, unless the DORAM
ρ has detected a misbehavior of the adversary. Thus, in case there
exists a misbehavior of the adversary affecting the correctness of
the result that is not detected by the DORAM, the result would be
correct in the Idealρ,A,S experiment but wrong in the Realρ,A
one, hence making them distinguishable.
Theorem 1. Our DORAMs meet the security guarantees of Def. 2
against a malicious adversary with leakage L = {LInit , LAcc,1,
. . . , LAcc,d}, where LInit = {n, B} and LAcc,i = ∅, i = 1, . . . , d.
Proof. To prove this statement, we show the construction of a
simulator S that makes the transcript of the Idealρ,A,S experiment
computationally indistinguishable from the Realρ,A one.
Simulator SInit . This algorithm, given LInit as input, randomly
samples n blocks DS
of B bits, and then it invokes the Init proce-
i
dure of the DORAM to instantiate the DORAM with these n blocks.
The traces TInit observed by the adversary in the two experiments
are indistinguishable: indeed, the DORAM is constructed with sim-
ilar parameters, and the Init procedure accesses the same blocks
in both the experiments (as path for evictions are chosen accord-
ing to a deterministic schedule). Since the blocks inserted in the
DORAM are encrypted with a semantically secure cipher, it is not
possible to distinguish the blocks with random data employed in
the Idealρ,A,S experiment from the blocks with actual data of the
Realρ,A one. The result res0 of the Init procedure is the same in
both experiments, as the tampering of the tree is detected inde-
pendently from the data stored inside the DORAM. Furthermore,
except for such tampering, there are no other adversarial behav-
iors that may alter the result of the computation, since it entirely
involves code and data stored inside the SGX enclave.
Simulator SAcc,i, i ∈ {1, . . . , d}. This simulator simply chooses at
random the block id bidS
to be accessed by the DORAM. We now
i
show that the traces TAcc,i of our Circuit DORAM observed by the
adversary in both the experiments are computationally indistin-
guishable. We start by proving the following claim about the code
and data access patterns of the client algorithm in Circuit DORAM:
Theorem 2. The code and data access patterns (CodeAP and
DataAP ) of our Circuit DORAM client in the Access procedure are
independent from the block id bid given as input to the procedure
Proof. The Access procedure of the DORAM has two main
phases: the former retrieves from the position map the leaf id lid
corresponding to block bid, replacing lid with a new random leaf
id lid′ in the corresponding entry of the position map; the latter
employs the FindBlock and Eviction procedures to retrieve the
block with id bid from the DORAM. We first prove our claim for
these two procedures; then, we prove it also for the first phase in
the case the position map is recursively stored in several DORAMs.
FindBlock. The DORAM client executes the FindBlock proce-
dure reported in Alg. 2. Both the control flow and the memory
locations accessed by this procedure are clearly independent from
the block id bid: indeed, the former depends only on parameters of
the DORAM known to the adversary, while all conditionally depen-
dent memory accesses are performed through oblivious operations.
Eviction. This procedure, reported in Alg. 5, is executed over two
paths, chosen by the client with a deterministic schedule known to
the adversary and independent from bid; furthermore, as the control
flow of this procedure depends only on parameters of the DORAM
known to the adversary and all the conditionally dependent mem-
ory accesses are performed through oblivious operations, both code
and data access patterns of this procedure are independent from
the block id bid.
Recursive Position Map. We recall that the position map of the
DORAM is stored in O(logC(n)) DORAMs of increasing size, and
the client stores only the position map of the smallest among these
DORAMs. The algorithm to retrieve the leaf id corresponding to
block bid has O(loдC(n)) iterations; in each of them, the algorithm
accesses one of the DORAMs storing the position map, hinging
upon FindBlock and Eviction procedures: as we have just shown,
their operations are independent from bid. The algorithm, after
retrieving a block from these DORAMs, performs a linear sweep
over such block; this block is a small array with O(C) entries, and
each of them is obliviously swapped with a target memory location
through OblSwap operation. Therefore, the sweep over the block
does not depend on bid. No other operations are performed in each
iteration of the algorithm, thus making the retrieval of the leaf id lid
corresponding to the block with id bid independent from bid. □
The claim in Thm. 2 implies that there is no difference on the
access patterns observed by the adversary in the Realρ,A and
Idealρ,A,S experiments. Regarding Datasrv, that is the informa-
tion sent outside the enclave from the DORAM client, we observe
that this is limited to the leaf ids of the paths being fetched or
evicted, and the blocks of these paths written back to the DORAM
tree. The paths to be fetched in our DORAMs are chosen in the
same way as in the corresponding ORAM; thus, the leaf ids of these
paths are distributed as in the corresponding ORAM. Since leaf
ids of fetched paths in Circuit ORAM are uniformly distributed,
independently from the accessed blocks, then the distribution of
the leaf ids fetched by our DORAM is uniform in both the Realρ,A
and Idealρ,A,S experiments. Regarding the paths being evicted,
in all our DORAMs they are chosen according to a deterministic
schedule that depends only on the eviction period A, which is the
same in both experiments; thus, the ids of the evicted paths cannot
be employed to distinguish the traces between the two experiments.
Finally, since the blocks are encrypted with a semantically secure
Efficient Oblivious Substring Search via Architectural Support
ACSAC 2020, December 7–11, 2020, Austin, USA
Experiment out ← RealP,A(λ):
(D, stA) ← A0(1λ)
I ← P.Setup(D)
res0 ← P.Load(I)
∀i ∈ {1, . . . , d}:
dis(qi , occi , stA)← Ai(stA, D,[qj]i−1
disagi [LQuery, j]i−1
dis resi ← P.Query(qi , occi)
i =0,[TQuery,i]d
out ← {[resi]d
j=1,[occj]i−1
j=1, LSetup , LLoad , dis(qi , occi , stA)← Ai(stA, D,[qj]i−1
j=1, TSetup , TLoad ,[TQuery, j]i−1
j=1)
i =1, TSetup , TLoad , stA}
j=1,[occj]i−1
j=1, LSetup , LLoad ,
j=1, TSetup , TLoad ,[TQuery, j]i−1
j=1)
j=1)
Experiment out ← IdealP,A,S(λ):
(D, stA) ← A0(1λ)