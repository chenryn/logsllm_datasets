ducted a hand-off in which we discussed our results with the
referring professional. For 12 of these, the professional was
onsite and hand-off occurred immediately. For the other 13,
we followed up with the professional via email and/or a phone
call. Although many clients did not resolve discovered prob-
lems immediately because of the need to safety plan, they
said that it was helpful and empowering to at least know how
the abuser was plausibly obtaining information about them.
Eleven cases required further research after the consulta-
tion. Six of these were client requests for information about
speciﬁc apps we were unfamiliar with (e.g., can app X track
my location?). For the remaining ﬁve we found something
during the consultation that needed further analysis to assess
its danger. In 10 cases, the consultant researched the issue at
length and provided a comprehensive answer to the referring
professional within a few days of the consultation. In the
remaining case, we could not provide a satisfactory explana-
tion for what the client was describing even after signiﬁcant
research, which we explained to the referring professional.
8 Discussion
Although the results from our ﬁeld study are preliminary, they
suggest that our consultation protocol is already valuable to
clients in dangerous situations. Encouragingly, the ENDGBV
have asked our team to schedule more consultations with
clients at the FJCs. This in turn raises new open questions
about how to sustain and scale our clinical computer security
approach. In this section we discuss: (1) limitations of our
current study; (2) open questions that it raises about how to
realize the vision of clinical computer security for IPV victims
more generally; and (3) open questions that our work raises
about clinical approaches to computer security beyond IPV.
Limitations. This ﬁrst study on clinical computer security
interventions has several limitations that we acknowledge.
First, our study was restricted to a single municipality and
our participants were not representative of all people who
suffer IPV. Although New York City has a large and diverse
population, and our sample does include socioeconomic and
cultural diversity, all but one of our participants were women,
all but one were no longer living with their abuser, and the
majority had been in heterosexual relationships. As a result,
our study may fail to capture some of the nuances associated
with abusive relationships for LGBTQIA+ people or those
who may still live with their abuser.
Another limitation is our sample size. Although 44 clients
may be sufﬁcient to verify the utility of our consultations, it
certainly does not yield statistically signiﬁcant estimates of,
for example, likelihood of spyware or other harms being seen
in practice. Further, our study context purposefully biases our
sample towards victims that are speciﬁcally worried about
tech problems. Still, our results provide guidance on what a
tech clinic is likely to see, and our experiences are consistent
with prior work on tech attacks in IPV [20, 27].
Our consultations may not catch all issues, either due to
consultant error (e.g., forgetting to ask a TAQ question) or
technical error (e.g., ISDi mislabeling an app). Indeed, one
of the fundamental challenges faced in this area is dealing
with complex, multifaceted attacks, and it is not possible to
be perfect. That said, our new approach vastly improves
over the current status quo in practice, which is essentially
nothing. Moving forward, future research will need to assess
if, and how, our protocol and instruments impact client lives
in the longer term, determining, for example, whether our
interventions measurably decrease illicit account accesses.
Should a client change their behavior as a result of our
consultations, abusers may change behavior, retaliate against
the victim, or otherwise escalate abuse. We designed our
protocols to try to minimize the potential for this, but no
procedures can eliminate such risks entirely. That said, we
are in active communication with FJC leadership and have
not received any indication that a client has faced retribution
as a consequence of participating in a consultation.
Clinical computer security for IPV. Our work focused on
client consultations, which are a fundamental component of
realizing our vision of clinical computer security. Given the
success of our initial ﬁeld study, we are faced with a range
of open questions. The most obvious is that our design and
evaluation so far did not perform in-depth investigation of
issues related to scalability and sustainability.
116    28th USENIX Security Symposium
USENIX Association
A sustainable computer security clinic will likely need a
supporting organization, outside the scope of a research study,
to handle recruitment, screening, and training of sufﬁciently
many volunteer consultants (or paid professionals, should
there be funding to pay them). Although the assessments and
materials we developed in this work will help with training
future tech consultants, they do not yet speak to challenges
that are outside the context of the consultation. In a referral
model like the one we used, just scheduling consultations took
many hours per week and, more broadly, how best to organize
delivery of clinical computer security for IPV victims raises a
host of questions for future research.
As a ﬁnancially sustainable recruitment strategy, we might
draw on existing models like pro-bono legal services [30], and
initial conversations with tech professionals and companies
suggest that some may be willing to offer their time free of
charge. (This model is used by the TECC clinic [2].) Another
approach is student-run clinics, similar to law school legal
clinics [12] or medical school free clinics [37]. In any such
model, it will be essential to develop strong protocols for
screening consultant applicants, particularly to ensure that
abusers are prevented from enrolling as consultants. Advo-
cacy groups have protocols for screening applicants, and one
could start by adopting these. In parallel, future research
will be needed to localize clinical techniques to geographic
locations with different support organizations and laws.
Another pressing issue is maintenance of instruments.
ISDi’s coverage currently relies on labor-intensive updating of
blacklists, based on web crawling and manual analysis. Like
malware detection in other contexts, maintaining accuracy
over time and staying ahead of emerging threats is an immense
challenge [40]. It is also important to consider the longer-
term implications of making ISDi’s existence and methods
public. While current spyware does not infer ISDi was used,
if it becomes widespread enough to become a target, spyware
developers might turn to more sophisticated methods that
monitor USB-related system processes. Similarly, spyware
vendors may start attempting to avoid detection. As such, we
keep ISDi’s blacklist private, allowing access via legitimate
requests from those working to help victims.
Our other instruments will also require updating at various
time intervals. By design, the TAQ should maintain relevance
for quite a while to come, requiring updating only when tech-
nology changes suggest new, broad classes of threats we must
consider. But our manual investigation guides for checking
security or privacy settings may need to be updated more
frequently as companies change their products. Future work
might evaluate the right balance between generalizability and
actionability of such guides (c.f., [19]), or infrastructure for
maintaining them (e.g., expert crowdsourcing [29]).
Clinical computer security beyond IPV.
IPV is not the
only context in which victims suffer targeted, persistent, and
personalized attacks. Some examples include the dissidents,
activists, and NGO employees targeted by nation-state hack-
ing campaigns [7, 23, 25, 26], or the gamers [9], journal-
ists [10], politicians [6], and researchers [21] who are at
high-risk of being harassed online [18, 33]. As in IPV, in all
these cases the attacker wants to harm their particular target.
There is also an asymmetry between the victim and attacker,
with the latter having more resources, time, and/or technolog-
ical sophistication. Indeed, in some cases the adversary in
these other contexts has signiﬁcant technical prowess.
Clinical approaches to computer security may be of util-
ity in these other contexts. In the near term, adapting our
techniques to other communities of victims similar to IPV —
such as victims of elder, parental, or child abuse, or victims
of sex trafﬁcking (which are also served by FJCs) — could
constitute important research directions. Despite the similari-
ties, research will be needed to understand how the nuances
emanating from particular circumstances or demographics
change best practices for clinical interventions.
Further aﬁeld are contexts that are less similar to IPV. For
example, those targeted by government agencies as mentioned
above might beneﬁt from systematized clinical approaches.
One could perhaps start with the work done by the Citizen-
Lab [13] and Citizen Clinic [1], and determine to what extent,
if any, our methodologies for stakeholder-driven design could
help improve clinical interventions.
9 Conclusion
This paper lays out a vision for clinical computer security
and explores it in the context of IPV. Through an iterative,
stakeholder-driven process, we designed a protocol for con-
ducting face-to-face tech consultations with victims of IPV
to understand their tech issues, investigate their digital assets
programmatically and by hand to discover vulnerabilities, and
advise on how they might proceed. Our preliminary study
with 44 IPV victims surfaced vulnerabilities for roughly half
our participants, including account compromise, potential
spyware, and misconﬁguration of family sharing plans. Our
consultations also provided advice and information to vic-
tims and professionals on ways to document such discoveries
and improve computer security moving forward. Our clinical
approach provides immediate value, while also laying a foun-
dation for future research on evidence-based reﬁnements to
clinical tech interventions in IPV and, potentially, beyond.
Acknowledgments
We would like to sincerely thank all our study participants,
the Family Justice Centers, and the NYC ENDGBV. This
work was funded by the NSF through grants CNS-1717062
and CNS-1558500, and by gifts from Comcast and Google.
USENIX Association
28th USENIX Security Symposium    117
References
[1] Citizen clinic.
citizen-clinic/.
https://cltc.berkeley.edu/
[2] Technology-enabled coercive control working group,
Seattle, WA, USA. https://tecc.tech/.
[3] iOS jailbreak detection (OWASP). https://git.io/
fj4te, 2017.
[4] Libimobiledevice: a cross-platform software protocol
library and tools to communicate with iOS devices
natively.
https://www.libimobiledevice.org/,
2017.
[5] Android debug bridge (adb).
https://developer.
android.com/studio/command-line/adb, 2019.
[6] Maggie Astor.
For female candidates, harass-
https:
ment and threats come every day.
//www.nytimes.com/2018/08/24/us/politics/
women-harassment-elections.html, 2018.
[7] S. Le Blond, A. Cuevas, J. Ramón Troncoso-Pastoriza,
P. Jovanovic, B. Ford, and J. Hubaux. On enforcing the
digital immunity of a large humanitarian organization.
In 2018 IEEE Symposium on Security and Privacy (SP),
volume 00, pages 302–318.
[8] Rahul Chatterjee, Periwinkle Doerﬂer, Hadas Orgad,
Sam Havron, Jackeline Palmer, Diana Freed, Karen
Levy, Nicola Dell, Damon McCoy, and Thomas Risten-
part. The spyware used in intimate partner violence. In
2018 IEEE Symposium on Security and Privacy (SP),
pages 441–458. IEEE, 2018.
[9] Despoina Chatzakou, Nicolas Kourtellis, Jeremy Black-
burn, Emiliano De Cristofaro, Gianluca Stringhini, and
Athena Vakali. Hate is not binary: Studying abusive
behavior of #gamergate on twitter. In Proceedings of
the 28th ACM Conference on Hypertext and Social Me-
dia, HT ’17, pages 65–74, New York, NY, USA, 2017.
ACM.
[10] Gina Masullo Chen, Paromita Pain, Victoria Y Chen,
Madlin Mekelburg, Nina Springer, and Franziska Troger.
“you really have to have a thick skin”: A cross-cultural
perspective on how online harassment inﬂuences female
journalists. Journalism, 2018.
[11] Robyn Clay-Williams and Lacey Colligan. Back to
basics: checklists in aviation and healthcare. BMJ Qual
Saf, 24(7):428–431, 2015.
[12] Robert J. Condlin. "tastes great, less ﬁlling": The law
school clinic and political critique. Journal of Legal
Education, 36(1):45–78, 1986.
[13] Ronald J. Deibert.
//citizenlab.ca/.
The Citizen Lab.
https:
[14] Jill P Dimond, Casey Fiesler, and Amy S Bruckman. Do-
mestic violence and information communication tech-
nologies. Interacting with Computers, 23(5):413–421,
2011.
[15] John W Ely, Mark L Graber, and Pat Croskerry. Check-
lists to reduce diagnostic errors. Academic Medicine,
86(3):307–313, 2011.
[16] NYC ENDGBV. NYC mayor’s ofﬁce to combat domes-
tic and gender-based violence. https://www1.nyc.
gov/site/ocdv/about/about-endgbv.page, 2019.
[17] NYC FJCs.
NYC family justice centers.
https://www1.nyc.gov/site/ocdv/programs/
family-justice-centers.page, 2019.
[18] Antigoni-Maria Founta, Constantinos Djouvas, De-
spoina Chatzakou, Ilias Leontiadis, Jeremy Blackburn,
Gianluca Stringhini, Athena Vakali, Michael Sirivianos,
and Nicolas Kourtellis. Large scale crowdsourcing and
characterization of twitter abusive behavior. CoRR,
abs/1802.00393, 2018.
[19] Diana Freed, Jackeline Palmer, Diana Minchala, Karen
Levy, Thomas Ristenpart, and Nicola Dell. Digital tech-
nologies and intimate partner violence: A qualitative
analysis with multiple stakeholders. PACM: Human-
Computer Interaction: Computer-Supported Coopera-
tive Work and Social Computing (CSCW), Vol. 1(No.
2):Article 46, 2017.
[20] Diana Freed, Jackeline Palmer, Diana Minchala, Karen
Levy, Thomas Ristenpart, and Nicola Dell. “A Stalker’s
Paradise”: How intimate partner abusers exploit tech-
nology. In Proceedings of the 2018 CHI Conference on
Human Factors in Computing Systems. ACM, 2018.
[21] Virginia Gewin. Real-life stories of online harassment
— and how scientists got through it.
https://
www.nature.com/articles/d41586-018-07046-0,
2018.
[22] Philip J Guerin and Eileen G Pendagast. Evaluation of
family system and genogram. Family therapy: Theory
and practice, pages 450–464, 1976.
[23] Seth Hardy, Masashi Crete-Nishihata, Katharine
Kleemola, Adam Senft, Byron Sonne, Greg Wise-
man, Phillipa Gill, and Ronald J Deibert. Targeted
threat index: Characterizing and quantifying politically-
motivated targeted malware. In USENIX Security Sym-
posium, pages 527–541, 2014.
[24] Leigh Honeywell. Personal communication, 2019.
118    28th USENIX Security Symposium
USENIX Association
[36] Geek Squad. Geek Squad services. https://www.
geeksquad.com, 2019.
[37] Lindsey Stephens, Nicole Bouvier, David Thomas, and
Yasmin Meah. Voluntary participation in a medical
student-organized clinic for uninsured patients signiﬁ-
cantly augments the formal curriculum in teaching un-
derrepresented core competencies. Journal of Student-
Run Clinics, 1(1), Jun. 2015.
[38] San-Tsai Sun, Andrea Cuadros, and Konstantin
Beznosov. Android rooting: Methods, detection, and
evasion. In Proceedings of the 5th Annual ACM CCS
Workshop on Security and Privacy in Smartphones and