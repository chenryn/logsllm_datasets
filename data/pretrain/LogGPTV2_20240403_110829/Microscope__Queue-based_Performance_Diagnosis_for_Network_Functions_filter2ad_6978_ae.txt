Why pattern aggregation helps. Usually it is difficult to iden-
tify the bug-triggering flows because they are mixed with other
normal flows. But pattern aggregation is effective because it collec-
tively analyzes packets in all queuing period when the processing
rate is low. During these queuing periods, packets from the bug-
triggering flows appear from frequently than a random flow, so the
bug-triggering flows stand out in the pattern aggregation.
6.5 Running in the Wild
We now study how Microscope diagnose performance problems of
NFs without any injected bugs. We run a one-minute CAIDA traffic
at a high load (1.6Mpps, 64-byte packet size), and use Microscope
to diagnose the 99.9-th percentile latency (a total of 80K victim
packets). We find that diverse types of problems emerge at the high
load. We now present some interesting findings.
Culprit
Traffic sources
Victim NAT
5.51%
10.46%
NAT
Firewall
Monitor
VPN
0%
0%
0%
Firewall Monitor
0.64%
1.43%
0.812%
1.84%
27.27%
2.49%
19.00%
0%
0%
0%
VPN
3.56%
0.64%
3.85%
0.89%
21.60%
Table 2: Breakdown of problem frequencies based on culprits
and victims. Rows represent culprit NFs and columns represent
victim NFs. Numbers show the percentage of problems for each
[culprit→victim] pair. Bold numbers represents problems that
propagate across different NFs.
The victims caused by propagation is considerable. As shown
in Table 2, 21.7% of all victim packets are caused by propagation, and
10.9% are caused by at least two-hop propagation4. This emphasizes
the importance of locating the right culprit location, which can
prevent blame game across operation teams managing different
421.7% is the sum of all cells in Table 2 that represent propagation. 10.9% is the sum of
cells that represents at least two-hop propagation.
399
 0.16 0.18 0.2 0.22 0.24 0.26 0.28 0.3 0.32 0.34 0.36151050100Correct RateTime Window SizeMicroscope: Queue-based Performance Diagnosis for Network Functions
SIGCOMM ’20, August 10–14, 2020, Virtual Event, NY, USA
Culprit
NAT1
NAT2
NAT3
NAT4
Victim NAT Firewall Monitor VPN
0.26%
0.05%
0.29%
0.04%
3.29%
2.06%
2.92%
2.18%
0.68%
0.25%
0.66%
0.25%
0.35%
0.12%
0.24%
0.10%
Table 3: Frequency differences for problems caused by different
NAT instances
Limitation of Microscope. Microscope can diagnose problems
from NFs that keep the IPID of the packet, since Microscope uses
IPID to identify the packet. Even if the IPID changes, there are
other ways to generate a unique ID per packet [22]. For those NFs
within which there is no one-to-one mapping for packets before
and after the processing of the NF (e.g., compression proxies, TLS
terminations), Microscope then cannot diagnose those NFs, but we
can still diagnose the NF chain before such NFs and that after such
NFs. Those NFs fundamentally require a white-box approach to
diagnose, which we cannot help for now.
Non-DPDK NFs and other network components. Note that
our implementation can collect data from all DPDK-supported NFs.
All other network components, including switches and NICs, are
treated as one component in our topology. If we also want to di-
agnose the problems in switches and NICs, we can treat them as
different components in the same way as NFs, and thus we also need
the data from queues in switches and NICs. When running NFs in
different machines, we need to align the timestamp of data from
different machines. This needs clock synchronization (microsecond
level), which is already supported in PTP and Huygens [5, 28].
Problems not caused by long queues. Long latencies or packet
drops could be caused by the long queue or the misbehaviors of
the NF. We only focus on long queues in our paper. For the case
of misbehaviors of NFs, the problem could be easily detected by
our trace: we can know the delay within the NF by checking the
timestamp difference of the packet in the input queue and the
output queue, and report that those packets with large in-NF delay
are caused by misbehaviors of NFs.
What if the queue is not empty in most cases? In our descrip-
tion of the algorithm, the start of a queuing period is when the
queue length exceeds zero, but this is not required. In fact, we can
also use a non-zero queue length threshold to define the start of
a queuing period, to handle the case when the NF queues may be
non-zero for a long time.
To implement Microscope with non-zero threshold, we just need
to read the queue length from the NIC and compare it with the
threshold. Unfortunately our NIC cannot report queue length, so
as a workaround, we use the batch sizes to infer whether the queue
is empty or not, which can only evaluate the threshold of zero. We
leave the evaluation of non-zero threshold to future work.
8 RELATED WORK
In this section, we discuss works related to Microscope. Given
the nature of network function virtualization, we discuss existing
solutions for performance diagnostics in the domain of networks
Figure 15: The CDF of the time gap between the culprit and the
victim of each causal relation.
NFs in the real world. Without Microscope, it is difficult to find the
right location.
Even though a large fraction of the culprits are local, Microscope
also provides very insightful diagnostic information for them, such
as the flow patterns (see § 6.4) and the timing.
The time gap between a culprit and its victim is highly vari-
able. Figure 15 shows the CDF of the time gap, which varies from
0 to 91 ms. While half of them are under 1.5 ms, the other half
spread almost evenly from 1.5 to 50 ms, with a long tail reaching
91 ms. This means for time-based correlation, it is very hard to find
the appropriate time window: a small window may miss the real
causal relations, while a large window includes lots of irrelevant
signals that mislead the correlation (both are observed when us-
ing NetMedic in § 6.2). This highlights the benefit of Microscope’s
queue-based diagnosis.
NFs of the same type can cause different levels of impacts.
As shown in Table 3, NAT1 and NAT3 cause more problems, at all
layers of NFs (we also observe such an uneven impact phenomenon
in other types of NFs). However, the traffic is evenly distributed
across different NATs. This suggests that many problems stem from
factors that exhibit temporal unevenness, such as interrupts and
temporal distribution of traffic.
Microscope is very helpful in diagnosing these problems, because
it provides and analyzes the queuing, which is the consequence of
temporal unevenness.
Some flows are more likely to cause problems. We perform
pattern aggregation, and find that the traffic bursts are comprised
of certain flow aggregates. Initially we suspected that the skew
was due to the skew in traffic: i.e., larger flow aggregates in the
traffic were more likely to appear in the bursts. However, when we
compared the flow aggregates in the bursts and the flow aggregates
over all traffic, we saw a significant difference. This means some
flows are more likely to form bursts and lead to problems.
Microscope provides very useful insights for diagnosing such
problems, such as the packet information in the queuing period.
Without them, it is very hard to diagnose.
7 DISCUSSION
Microscope could fail. In practice, Microscope cannot always get
the correct answer. Microscope could fail in the following cases: 1)
The expected rate ri of NFs is not measured correctly. 2) Microscope
fails to identify the path of packets by only using the IPID. 3) The
queuing period is not measured accurately due to the inaccuracy
of timestamps.
400
 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 10 20 30 40 50 60 70 80 90 100CDFGap (ms)SIGCOMM ’20, August 10–14, 2020, Virtual Event, NY, USA
Gong, et al.
and distributed systems5. But before going into direct comparisons
we’ll first discuss a few of the recent works on NFV performance
optimization and then discuss how Microscope is different from
existing works based on its ability to diagnose problems at fine-
grained timescales and across functions in service function chains.
Performance optimization: There has been a great effort on
performance optimization for NFV systems and distributed systems
in multi-tenant environments.
Performance optimization for distributed systems: Retro [44], Ernest
[52], and HUG [20] are some of the first efforts in this regard. These
systems are mainly focused on resource allocation optimization in
a distributed system.
NF service chain optimization: NFP [51] and Parabox [56] try to
reduce end-to-end latency by expliting parallelism in NFV chain.
NFVNice [42] proposes a service chain management framework.
It monitors loads of network functions to provide fair, efficient,
and dynamic resource scheduling. Metron [38] and Slick [14] do re-
source optimization while implementing an NF chain inside server
and network respectively by reducing inter-node communications
within each server.
NF performance optimization: NF performance optimization dis-
cussed here can be divided into three lines of work based on main
packet processing units, i.e., CPUs, GPUs, and FPGAs. Packet-
Shader [31], SSLShader [33], Kargus [32], NBA [39], APUNet [29],
and G-NET [55] leverage GPU to accelerate packet processing.
ClickNP [43], SwitchBlade [15] offload packet processing logic to
the FPGAs. RouteBricks [21], NetBricks [49] and E2 [48] propose
packet processing optimization techniques to improve performance
on CPUs. Besides leveraging accelerators, there has been some
work optimizing state management. OpenBox [18] decouples NFV
control plane and data plane, and Stateless Network Functions [34]
decouple stateless processing logic and data store.
For all the NF optimization works on CPUs, GPUs, and FPGAs,
clock cycles matter. With Microscope we provide a mechanism to
diagnose performance issues of deployed network functions in a
DAG at the granularity of hundreds/thousands of clock cycles. Now
we’ll discuss performance diagnostics works in NF and distributed
systems domain.
Performance diagnosis in networked systems: We divide the
diagnosis of networked systems into performance diagnosis for
VNFs and for traditional network systems.
For VNFs, PerfSight[53] and Probius[47] diagnose persistent
problems, like persistent high packet drop rate and long-term low
throughput, on software dataplane. Whereas Microscope can di-
agnose transient (microseconds scale) service function chain per-
formance problems. Perfsight uses packet drops and throughput
numbers as indicators of bottleneck network elements. Although
this is effective in identifying persistent bottleneck, it cannot diag-
nose problems at the tail (e.g., long tail latency, transient drops),
which is a big headache to operators. There is no way to identify
long latency in PerfSight, while transient drops themselves are
insufficient for PerfSight to give the detailed causal diagnosis as
provided by Microscope.
For traditional network systems, SCORE [41] focuses on identi-
fying root causes of network faults across different vertical layers
(e.g., across IP layer and optical link layer), but it cannot figure
out how faults propagate their impact across different network
elements, horizontally. Sherlock [16] builds a graph to model the
causal relationship between network components (e.g., routers,
hosts, links) and services, and use history monitoring data and
time-based correlation to predict probabilities of the causal rela-
tionship. But Microscope identifies transient performance issues at
smaller time granularity then Sherlock [16].
Performance diagnosis in distributed systems: There are sev-
eral distributed system diagnostic tools that use statistical correla-
tion of the logs [19, 46]. They face the same problem as NetMedic [36]
faces to perform diagnosis at low granularity. Similarly, Retro [44]
monitors and attributes the queuing delay to different users to quan-