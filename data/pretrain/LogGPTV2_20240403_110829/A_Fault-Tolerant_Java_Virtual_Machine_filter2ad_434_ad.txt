marks, only Mtrt actually requires them for multi-threading.
We implemented replicated lock acquisition for both
the green threads library supporting user-level threads on
uniprocessors and the native threads library supporting
multi-threading on an SMP. We only implemented thread
scheduling for green threads. We found the overheads ex-
hibited by the two implementations of replicated lock ac-
quisitions to be qualitatively similar. We thus only report
results from our implementation using green threads. All
experiments are performed on lightly loaded machines run-
ning in multi-user mode; experiments were repeated until
95% conﬁdence intervals were within 1% of the mean.
Figure 2 shows the overall execution times of the bench-
mark applications using each of our replication approaches
normalized to the corresponding times without any repli-
cation. The primary columns are the execution times of
the primary logging events to the backup, while the backup
columns give the times for the backup to replay events from
the log. Although our implementation was not tuned ag-
gressively (we only optimized some in the replicated thread
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 06:58:33 UTC from IEEE Xplore.  Restrictions apply. 
)
d
e
z
i
l
a
m
r
o
n
(
e
m
T
n
o
i
t
u
c
e
x
E
i
5
4
3
2
1
0
Pessimistic Overhead
Misc. Overhead
Lock Acquire Overhead
Communication Overhead
Original JVM
jess
jack
compress
db
mpegaudio
mtrt
Figure 3: Normalized overhead for replicated lock acquisi-
tion implementation using green threads library.
)
d
e
z
i
l
a
m
r
o
n
(
e
m
T
n
o
i
t
u
c
e
x
E
i
5
4
3
2
1
0
Pessimistic Overhead
Misc. Overhead
Rescheduling Overhead
Communication Overhead
Original JVM
jess
jack
compress
db
mpegaudio
mtrt
Figure 4: Normalized overhead for
scheduling implementation using green threads library.
replicated thread
scheduler), we observed under 100% overhead for most
applications. Replicating lock acquisitions has an average
of 140% overhead (skewed by Db) for green threads, well
above the replicated thread scheduling’s 60% average.
The overhead for replicated lock acquisitions (Figure 3)
ranges from 5% (Mpegaudio) to 375% (Db). The large over-
head in Db is a result of processing its more than 53 million
lock acquisitions. In Figure 3, Communication Overhead
represents the time spent sending messages to the backup,
and Lock Acquire Overhead measures the time spent stor-
ing information on lock acquire. Pessimistic Overhead rep-
resents the time spent waiting for acknowledgments from
the backup on output commit events.
In our implementation lock acquisition messages are
very small (36 bytes). The primary buffers such messages
and sends them to the backup either periodically or on an
output commit; in the latter case, the primary sends the
buffered messages and waits for an acknowledgment. Sim-
ilarly, the backup only sends an acknowledgment message
after processing a burst of incoming logging messages.
The sources of overhead for
the replicated thread
scheduling implementation are detailed in Figure 4. Com-
munication Overhead and Pessimistic Overhead are as in
Figure 3, while Rescheduling Overhead measures time
spent updating counters and storing scheduling decisions.
The overhead varies from 100% (Jack) to 15% (Compress).
Replicating thread scheduling yields a lower communi-
cation overhead than replicating lock acquisition: only Mtrt
logs any thread schedule records to the backup. Further, to
reduce the number of records created, a record is sent only
when a new thread is scheduled. All other benchmarks are
single-threaded; hence, they do not involve transmission of
any records. The replicated lock acquisition implementa-
tion does not take advantage of this single-threaded case,
sending many unnecessary messages.
For such applications, we expect replicated thread
scheduling to incur smaller overhead than replicated lock
acquisition.
In practice, however, we observe that this is
not always the case (see Figure 2), because storing thread
progress incurs signiﬁcant overhead. As seen in Figure 4,
the overhead of replicated thread scheduling is dominated
by the Misc. Overhead, which captures the overhead result-
ing from extra bookkeeping. In an earlier version of our im-
plementation, the bookkeeping overhead for the replicated
thread scheduler overwhelmed any communication advan-
tages. To reduce these costs, we were forced to add about
12 instructions that update counters and keep track of the
virtual machine’s PC to the hand-written optimized assem-
bly loop that executes bytecodes at the heart of the JVM. We
believe signiﬁcant additional reductions could be achieved
by optimizing the code further. Also, using a deterministic
scheduler as in the Jikes RVM [9, 10] or Jalape˜no [11] might
result in lower overhead substantially because the progress
indicators would be simpliﬁed.
The two approaches to handling multi-threading present
different tradeoffs. Replicating lock acquisitions may be
less effective if a thread acquires or releases objects several
times before being rescheduled. Further, replicating thread
scheduling handles automatically the single-threaded case
as no extra messages are sent. Nonetheless, replicating lock
acquisitions is still a compelling approach because it works
on multiprocessor systems, and may provide better perfor-
mance, as in the case of Mtrt.
As communication overhead is the dominant source of
overhead in our experiments, the amount of communication
for a given application created by each technique is an ef-
fective predictor of their performance.
6. Related Work
Replica coordination[1, 2] can be implemented at any
level of a system’s architecture,
from the application
level [12]all the way down to the hardware [13]. Systems
that implement replica coordination at intermediate levels
include TFT [14] (at the interface above the operating sys-
tem) and [3], in which replica coordination is implemented
above a virtual machine that exports the same instruction
set architecture as HP’s PA-RISC.
We ﬁrst reported on our fault-tolerant JVM in [15]. Since
then, we have become aware of other concurrent and in-
dependent effort that address some of the same issues dis-
cussed in this paper. Basile and others report on replicating
multi-threaded applications in [16]. They develop a leader-
follower replicated lock acquisition algorithm that assumes
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 06:58:33 UTC from IEEE Xplore.  Restrictions apply. 
R4A and a Byzantine failure model for a webserver applica-
tion. Their algorithm for replicated lock acquisition is sim-
ilar to ours; however, they do not explore scenarios where
R4A doesn’t hold.
Recently, Friedman and Kama have also explored the
idea of modifying the JVM (in their case,
the Jikes
RVM [9]) to achieve transparent fault-tolerance [10] using
semi-active replication. Although we share the same goals,
our approaches differ in three fundamental ways. First, their
approach only applies to systems where R4A holds, while
we explore multiple ways to handle the non-determinism
introduced by multi-threading. Second, they do not address
applications with non-deterministic native methods, though
they do address I/O within the JRE. Finally, they report
experiments using JIT, while all our experiments are per-
formed in interpreted mode because we require access to
the source code for JIT.
Earlier work on debugging multi-threaded applications
addressed non-determinism. LeBlanc and Mellor-Crummey
ﬁrst introduced recording lock synchronization and shared
memory accesses for debugging replay [17]. More recently,
Choi and Srinivasan apply this approach to Java in the De-
jaVu tool for debugging assuming R4A in [18] and R4B
in [11]. DejaVu records logical thread intervals wherein
a thread performs non-deterministic events such as moni-
tor entry/exit and shared variable accesses. The intervals
include thread schedules for the underlying deterministic
thread scheduler of the Jalpe˜no JVM.
As our focus is fault-tolerance, our implementation dif-
fers in several ways. First, we include a general approach to
handling application-provided native methods. Second, De-
jaVu does not address output to the environment. Third, the
Jalape˜no scheduler reschedules at deterministic yield points,
simplifying thread execution progress tracking.
Their trace sizes are much smaller than ours by clever
use of intervals, but the overhead incurred is still 40%-80%,
comparable to ours without pessimism. Our implementa-
tion could beneﬁt from the use of intervals. For the multi-
threaded Mtrt application there would only be 56 intervals
instead of 700258 lock acquisitions—four orders of magni-
tude fewer events, resulting in a signiﬁcant saving in space
and probably also time.
To the best of our knowledge, replicating lock acqui-
sitions for handling multi-threading was ﬁrst proposed by
Goldberg, et al., for Mach applications in [19]. When repli-
cating lock acquisitions, correctness depends on the absence
of data races. By augmenting the type system, Boyapati
and Rinard developed race-free Java programs which meet
R4A [20]. Data race detection mechanisms [21, 6] could
also be used to verify R4A holds for a given program.
Our implementation of replicated thread scheduling is
based on Slye and Elnozahy [7]. They record thread
progress during normal execution using a count of control
ﬂow changes (branches, jumps, function calls). Our solu-
tion differs in two ways: 1) the JVM cannot track all control
ﬂow changes (e.g., while executing a native method) and 2)
we do not recover all threads (e.g., the garbage collector).
7. Conclusions
We build a fault-tolerant JVM using the state machine
approach. We implement and evaluate two techniques
for eliminating the non-determinism introduced by multi-
threading. The ﬁrst technique allows the threads at the
backup to reproduce the exact sequence of monitor acqui-
sitions performed by the threads at the primary. The sec-
ond technique replicates at the backup the thread schedul-
ing decisions performed at the primary. Our results suggest
that this is a viable solution for providing transparent fault-
tolerance to Java applications.
References
[1] L. Lamport, “Time, clocks, and the ordering of events in
distributed systems,” Communications of the ACM, vol. 21,
no. 7, pp. 558–565, July 1978.
[2] F. B. Schneider, “Implementing fault-tolerant services using
the state machine approach: A tutorial,” ACM Computing
Surveys, vol. 22, no. 4, pp. 299–319, Dec 1990.
[3] T. C. Bressoud and F. B. Schneider, “Hypervisor-based fault
tolerance,” in Proceedings of SOSP 15, Dec 1995.
[4] T. Lindholm and F. Yellin, The JavaTM Virtual Machine Spec-
iﬁcation, 2nd Ed. Addison-Wesley, April 1999.
[5] S. Liang, The JavaTM Native Interface: Programmer’s Guide
and Speciﬁcation. Addison-Wesley, June 1999.
[6] S. Savage et al., “Eraser: A dynamic race detector for multi-
threaded programs,” ACM TOCS, vol. 15, no. 4, pp. 391–411,
October 1997.
[7] J. H. Slye and E. Elnozahy, “Support for sotware interrupts
in log-based rollback recovery,” IEEE TOCS, vol. 47, no. 10,
pp. 1113–1123, October 1998.
[8] P. Chan, R. Lee, and D. Kramer, The Java Class Libraries:
2nd Ed, Vol 1 Supplement for the JavaTM 2 Platform, Std Ed,
v1.2. Addison-Wesley, June 1999.
[9] IBM,
“Jikes
RVM,”
2002.
[Online]. Available:
http://www.ibm.com/developerworks/oss/jikesrvm/
[10] R. Friedman and A. Kama, “Transparent fault-tolerant JVM,”
Department of Computer Science, The Technion, Tech. Rep.
CS-2002-19, Dec 2002.
[11] J.-D. Choi, B. Alpern, T. Ngo, M. Sridharan, and J. Vlissides,
“A perturbation-free replay platform for cross-optimized
multithreaded application,” in Proceedings of IPDPS, 2001.
[12] K. P. Birman, “The process group approach to reliable dis-
tributed computing,” Communications of the ACM, vol. 36,
no. 12, pp. 37–53, 1993.
[13] J. Bartlett, J. Gray, and B. Horst, “Fault tolerance in tandem
computer systems,” in The Evolution of Fault-Tolerant Sys-
tems, A. Avizienis, H. Kopetz, and J.-C. Laprie, Eds. Vi-
enna, Austria: Springer-Verlag, 1987, pp. 55–76.
[14] T. C. Bressoud, “TFT: A Software System for Application-
Transparent Fault Tolerance,” in Proceedings of FTCS 28,
June 1998, pp. 128–137.
[15] J. Napper, L. Alvisi, and H. Vin, “A fault-tolerant java virtual
machine,” University of Texas, Dept. of Computer Sciences,
Tech. Rep. TR02-56, May 2002.
[16] C. Basile, Z. Kalbarczyk, K. Whisnant, and R. Iyer, “Active
replication of multithreaded applications, Tech. Rep. UILU-
ENG-02-2201, March 2002.
[17] T. J. LeBlanc and J. M. Mellor-Crummey, “Debugging par-
allel programs with instant replay,” IEEE Transactions on
Computers, vol. C-36, no. 4, pp. 471–482, April 1987.
[18] J. Choi and H. Srinivasa, “Deterministic replay of java multi-
threaded applications,” in SIGMETRICS Symposium on Par-
allel and Distributed Tools, August 1998, pp. 48–59.
[19] A. Goldberg, A. Gopal, K. Li, R. Strom, and D. F. Bacon,
“Transparent Recovery of Mach Applications,” in Usenix
Mach Workshop, 1990, pp. 169–183.
[20] C. Boyapati and M. Rinard, “A parameterized type system
for race-free Java programs,” in Proceedings of OOPSLA,
Tampa Bay, FL, October 2001.
[21] G.-I. Cheng et al., “Detecting data races in cilk programs that
use locks,” in Proceedings of ACM SPAA, 1998.
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 06:58:33 UTC from IEEE Xplore.  Restrictions apply.