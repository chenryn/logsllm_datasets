Receive Money” page, the attacker is able to perform a variety
of severe and persistent CSRF attacks because this page
contains multiple critical session arguments and URLs that
allow the attack to send forged requests. For example, in
Figure 9, the source code exposes the session arguments and
URLs for requests to update recipients, add recipients, and
manage contacts. The attack can expose critical information
to manipulate the user’s recipient and contact lists. Worse,
attackers can transfer money to their own accounts because the
page also provides a link to transfer money. In Figure 10, the
attacker sends a post request to wellsfargo.com which contains
the stolen session arguments and URLs to transfer money to
his account. Note that these attacks no longer work on Google
Chrome [7] and Mozilla Firefox [16] since these browsers do
39
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:01:26 UTC from IEEE Xplore.  Restrictions apply. 
Fig. 10. The attacker can create a post request to send money with the stolen
arguments during screen sharing.
the sites the user has visited before.
We summarize how the attackers applying the four methods to
collect data from the three categories in Figure 11. In the next
few sections, we display the results from these attacks.
1) Autocomplete History Snifﬁng: Autocomplete is a
browser feature designed to save the user’s effort from typing
the same input repeatedly. User-supplied form values for text
ﬁelds are shared across different websites by the “name”
attribute. Take the Gmail login form for example. As shown in
Figure 12(a), the username entered into the Gmail login page
will automatically populate the autocomplete history for all
subsequent input ﬁelds bearing the same name as that on the
Gmail login page, which is “Email”.
The browser shares the same autocomplete database across
all websites. The only exception to this rule is that the browser
does not populate the input ﬁeld if the type is set to “password”.
More speciﬁcally, the browser provides the password history
only to the page where the user had manually entered his/her
password initially. This prevents malicious websites from
stealing the saved passwords for other websites. Generally, the
user enters the same information for ﬁelds such as email, phone
numbers and address because this information that identiﬁes
the user does not depend upon the website.
Though the browser saves the autocomplete history, the
browser prevents websites from directly accessing the auto-
complete history. For example, there is no DOM element
associated with the autocomplete history, which could be
accessed programmatically using JavaScript. However, Jeremiah
Grossman has discovered multiple vulnerabilities which can
allow a malicious website to steal the autocomplete history
by manipulating the autocomplete functionality [11]. Browsers
have patched the vulnerabilities that allow stealing personal
data [12].
Since the browsers have patched these issues, a malicious
website cannot access the autocomplete history programmati-
cally. Firefox resolved this issue by restricting the web pages
to programmatically send input to the text ﬁelds [13]. Google
Chrome 30, however, still allows passing inputs programmat-
ically to the text ﬁelds using JavaScript. This vulnerability
combined with the screen sharing feature enables the attacker
to brute force the autocomplete history for text-ﬁelds with
common “name” attributes such as name, email, address, and
age.
To prove this, we use the proof-of-concept from ha.ckers.org,
Fig. 8. Secret session arguments can be retrieved from the source code by the
attacker during a screen sharing session, and these arguments can be applied
to mount further attacks.
not display page source using view-source links inside iframes.
C. Attacks on Conﬁdentiality
Conﬁdentiality of web sites guards users’ sensitive
information,
such as email addresses and credit card
numbers, from being disclosed to third parties. To guarantee
conﬁdentiality, many websites adopt encrypted communication
channels such as HTTPS to transmit data between servers
and clients. However, with the screen sharing functionality,
a malicious screen sharing website can collect cross-domain
content from victim websites by displaying target websites on
the screen. Therefore, HTTPS defense is entirely broken when
the screen sharing API is involved.
In the following discussion, we illustrate four attack methods
that can disrupt the conﬁdentiality of trusted websites using
the screen sharing API: auto-complete history snifﬁng, framing
target websites, opening target websites in a new window and
browsing history snifﬁng. For auto-complete history snifﬁng,
attackers utilize the auto-complete feature of the browser to
collect history with characters invisible to the user. For framing
target websites, attackers navigate iframes to websites which
contain sensitive information and do not have X-Frame-Options
enabled. For websites which have X-Frame-Options turned on,
attackers open them in new windows. For browsing history
snifﬁng, attackers embed URLs to test if users have visited
certain websites. Through these approaches, attackers collect
information in three categories: personal information, account
activity, browsing history. Personal information includes the
user’s account name, password, email, address, and bank
account number. Account activities are the records of user
behaviors for one account, including purchase history, search
history, and transaction history. Browsing history is formed by
40
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:01:26 UTC from IEEE Xplore.  Restrictions apply. 
Fig. 9. Multiple session arguments are exposed in the source code. Therefore, the screen sharing attacker can collect these arguments and use them to generate
CSRF attack packets.
Attack Approaches 
Auto-complete 
History  
Sniffing  
Frame to  
Target  
Website 
Open Target 
Website in  
New Window 
Browsing  
History 
 Sniffing 
Personal  
Information 
Account    
Activity  
Browsing   
History 
Target Information 
Fig. 11. The attacker can apply the four methods to collect data from the
three categories.
which was used to demonstrate the autocomplete history steal-
ing attack on Safari [17]. This JavaScript code programmatically
supplies all possible characters as single character inputs to
the input text ﬁelds for each of the common text ﬁeld attribute
names such as name, company, city, and email. The browser
automatically populates the autocomplete history, if it exists,
for the combination of the starting letter and the text ﬁeld
attribute name. The sample result is shown in Figure 12(b).
Using this technique, the attacker forces the browser to
display the autocomplete history on the victim’s own page.
2) Browsing History Snifﬁng: Browsing history refers to
a list of web pages where a user has visited. Although the
information is secured by the user’s browser, the information
can be stolen in the context of screen sharing.
41
One attacking approach is to embed target links in the
attacker’s website that provides screen sharing services. The
attacker can infer the browsing history from the colors of
links rendered on the screen. Although vendors hide the render
differences between visited and unvisited links from JavaScript
in order to prevent history snifﬁng, they still expose the
differences to users for usability reasons; therefore, the screen
sharing attacker can display the links in a way users cannot
easily notice and capture the color of the links to infer the
browsing history of the user.
3) Framing Target Website: For websites that do not enable
X-Frame-Options, attacks can still succeed if attackers frame
pages that expose sensitive information. We demonstrate how
the attackersteal personal information in the following sections.
Account Activity Snifﬁng. Many websites provide users with
the option of seeing their account activity. For example, on
an e-commerce site, the user can see his transaction history.
Similarly, on a search engine site, the user can check his search
history. The URL of the page that stores the user’s activity
information is often static. Thus, the attacker can attempt to
open these URLs in a new window on the victim’s browser,
and if the victim is logged into these services, the pages will
expose the user’s account history.
Below, we illustrate two popular services that record the
account history at a static URL.
•
Amazon:
1)
2)
http://www.amazon.com/%20gp/history?ie=
UTF8&ref =ya browsing history
https://www.amazon.com/gp/css/
order-history/ref=ya orders css.
These two pages store a user’s browsing and purchase
history. For example, Figure 13 shows the browsing
history of an Amazon account. Since the two pages are
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:01:26 UTC from IEEE Xplore.  Restrictions apply. 
(a) The browser automatically shows the strings from autocomplete history
that start with the letter(s) entered in the text ﬁeld. For example, the ﬁgure
shows what the browser displays on entering the letter “j”.
Fig. 12. Auto-complete History Snifﬁng
(b) The attacker’s page enters “j” in the input text ﬁeld to see the autocomplete
history related to the element that had the name attribute set to “Email”.
Fig. 13. The attacker can collect the browsing history of Amazon by displaying
the history page.
not protected by X-Frame-Options, the attacker can
load them inside an iframe on their website.
Bing:
•
http://www.bing.com/proﬁle/history. Bing stores a
user’s search history locally, irrespective of whether
the user is currently logged in or not. As illustrated
in Figure 14, the Bing history page keeps the search
history, organizing the terms searched by users in blue
blocks with respect to time. By opening the URL, an
attacker can retrieve the user’s search history from the
screen.
As for Google Search, users are asked to enter their
passwords before they can see their search history. Since our
threat model assumes that the user does not have to enter any
sensitive information on the screen while his screen is being
shared, Google Search history cannot be stolen using this
technique.
Personal Information Theft. These attacks are similar to
account history snifﬁng expect for the information at risk. The
attacker can get sensitive information from a user if the user
is logged in their account. The attacker can steal information
stored at static URLs with the help of screen sharing by opening
Fig. 14.
sharing.
The attacker can steal the search history of Bing during screen
such pages inside the user’s browser. For example, some of
the popular services that store sensitive account information at
static URLs are shown below.
•
•
ebay:
http://my.ebay.com/ws/eBayISAPI.dll?
MyeBay&CurrentPage=MyeBayPersonalInfo&gbh=
1&ssPageName=STRK:ME:LNLK. This URL reveals
sensitive user information such as the user’s address
email, ID and payment methods.
Amazon:
To purchase goods and deliver them to a user’s address,
the user inputs payment and address information into
their Amazon account page. The attacker can embed
the page that records payment information in the
screen sharing page. Figure 15 is a screenshot for the
information that would be collected by the attacker.
42
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:01:26 UTC from IEEE Xplore.  Restrictions apply. 
history&nav=0%2e3. Paypal keeps track of transaction
history for users, including email address of senders
and receivers, as well as other detailed information of
the transactions (see Figure 16).
Personal Information Theft
We experimented with popular websites and found that
attackers can steal information from many websites by opening
the target websites in a new window. This is not an exhaustive
list of static URLs that host sensitive content. The aim of this
section is only to demonstrate that it is easy for an attacker to
launch such attacks.
•
•
•
Google:
Google hosts a variety of services, such as Gmail,
Google Contacts, and Google Calendar. Since these
web pages contain plenty of sensitive information, an
attacker can exploit pop-up windows to open these web
pages. For example, the attacker can steal the user’s
Gmail and Google Doc by opening the following links
during the screen sharing session:
1)
2)
https://mail.google.com/mail/#inbox
https://drive.google.com/?tab=mo&authuser=
0#my-drive
PayPal:
PayPal maintains personal
information, such as a
user’s SSN, email, phone number and address, in
the proﬁle page ( https://www.paypal.com/webapps/
customerproﬁle/summary.view?nav=0%2e6). The at-
tacker can collect the user’s information by opening
the proﬁle page using a popup window (see Figure
17).
Facebook:
For Facebook, the attacker can pop out a window and
navigate to https://www.facebook.com/messages/ and
https://www.facebook.com/friends?ft ref=mni to steal
Facebook messages and other sensitive information.
V. ANALYSIS AND DISCUSSION
With the visual channel created by screen sharing API, the
assumption that websites cannot access the cross-origin content
directly is broken. Therefore, current defenses which are based
on the assumption can be bypassed by the attacks using screen
sharing API. In this section, we ﬁrst present our analysis about
the practical relevance of the attack, and then demonstrate how
the attacks bypass the current defenses. Finally, we discuss
some potential solutions of the problem for browser vendors,
websites and users and compare their security and usability.
A. Feasibility of Screen Sharing Attacks
The screen sharing attacks are feasible and imperceptible
to users owing to the following reasons. First, the screen
sharing attack becomes more workable when it is combined
with orthogonal attacks such as phishing attacks and social
engineering. The user might be tricked to click on a malicious
website for screen sharing. Even when the user is in the process
Fig. 15. The attacker can collect payment and address information from
Amazon.
Fig. 16. The attacker displays activity history of Paypal.
4) Open Target Sites in New Browser Windows: Even if
the websites are protected from being loaded inside an iframe,