mov    %r15,%rdx
mov    $0x3c,%esi
mov    %rbp,%rdi
sub    %rbp,%rdx
movl   $0x0,0xbc(%rsp)
movl   $0x0,0xbc(%rsp)
callq
4044d0 
int
struct
(cid:7)(cid:2)(cid:1)(cid:4)(cid:14)(cid:17)(cid:16)(cid:18)(cid:20)(cid:7)(cid:15)(cid:9)(cid:10)(cid:1)(cid:6)(cid:12)(cid:19)(cid:21)(cid:7)(cid:13)(cid:12)(cid:22)(cid:7)(cid:20)(cid:12)(cid:16)(cid:15)
0.30% 0.64% 1.32% 2.12% 2.62% 3.38% 4.10% 5.20% 6.54%
0.64% 1.38% 1.80% 2.70% 3.18% 3.84% 4.78% 5.82% 7.54%
0.22% 0.68% 1.28% 2.00% 2.56% 3.26% 3.82% 5.18% 6.58%
0.32% 0.74% 1.28% 1.86% 2.82% 3.22% 4.34% 5.44% 7.20%
0.94% 1.32% 1.92% 2.60% 3.22% 3.90% 4.82% 5.84% 7.62%
0.58% 1.46% 2.04% 2.66% 3.10% 3.54% 4.32% 5.46% 7.30%
0.40% 0.90% 1.46% 2.32% 3.12% 3.70% 4.40% 5.28% 7.70%
0.88% 1.52% 2.36% 2.98% 3.60% 4.62% 5.88% 6.80% 8.46%
0.84% 1.62% 2.42% 3.46% 4.50% 5.14% 5.80% 7.08% 8.44%
0.74% 1.70% 2.24% 3.00% 3.42% 4.14% 4.68% 6.06% 7.50%
6.02% 8.58% 11.66% 14.04% 16.82% 19.72% 23.60% 27.82% 35.46%
1.24% 1.74% 2.70% 3.46% 4.12% 4.98% 5.80% 7.06% 9.34%
0.20% 0.82% 1.40% 1.88% 2.46% 3.18% 3.88% 5.34% 7.20%
0.58% 1.40% 1.86% 2.64% 3.58% 4.54% 5.34% 6.78% 8.38%
0.54% 1.14% 1.80% 2.58% 3.30% 3.88% 5.14% 6.16% 7.76%
0.64% 1.46% 1.80% 2.30% 2.84% 3.58% 4.50% 5.60% 7.08%
0.66% 1.58% 2.06% 2.66% 3.58% 4.42% 5.54% 6.64% 8.66%
0.74% 1.72% 2.18% 2.80% 3.40% 4.28% 4.88% 5.94% 7.08%
0.74% 1.08% 1.68% 2.48% 3.40% 4.10% 4.76% 5.78% 7.52%
0.78% 1.42% 2.70% 3.16% 4.06% 4.62% 5.50% 6.06% 7.72%
0.54% 1.08% 1.80% 2.16% 2.88% 3.70% 4.48% 5.34% 6.82%
(cid:8)(cid:2)(cid:1)(cid:4)(cid:14)(cid:17)(cid:16)(cid:18)(cid:20)(cid:7)(cid:15)(cid:9)(cid:10)(cid:1)(cid:3)(cid:12)(cid:19)(cid:20)(cid:18)(cid:12)(cid:8)(cid:21)(cid:20)(cid:12)(cid:16)(cid:15)(cid:1)(cid:16)(cid:11)(cid:1)(cid:5)(cid:10)(cid:19)(cid:20)(cid:1)(cid:3)(cid:7)(cid:20)(cid:7)
Importance visualization and distribution of example case.
Fig. 6.
instruction. k is an index ranged in (0, +∞) to measure the
importance of kth instruction. A smaller value of k indicates
more signiﬁcance of the instruction.
As shown in Figure 6 a), the left side is the result of 
of each instruction. It is obvious that the variable instructions
with the same variable type play a more important role in
type inference. However, the instruction in column 3 operates
a variable with type char, which seems to take the lead of
prediction with a small . The reasonable explanation of this
situation is that the representation of column 3 is the same
as the central instruction (column 11). It is easy to guess
that the model regards these two instructions as the same
variable’s operation. As shown in Figure 6 b), the heat map
reﬂects the statistical result of  for each instruction among
our test data. Each row represents the location of instructions
in VUCs, and each column represent the rate of instructions
whose  is ranged in (0,1), (0.1,1), ..., (0.8,1), (0.9,1). Take
the percentage in column 11, row 5 as an example, it denotes
that 16.82% of central instructions have  ranged in (0.5,1).
The tendency of the heat map indicates that the model is
able to pay attention to the central instruction which operates
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:25:44 UTC from IEEE Xplore.  Restrictions apply. 
(cid:26)(cid:23)
the target variable, and the closer instructions have a more
positive inﬂuence on the prediction result. To contrast, we ﬁnd
the next-door neighboring instructions already vary a lot from
the central instruction in all rows, not to speak of the rest of
the instructions. The distribution indicates that the method of
feature extraction brings in noises in some aspects.
At
last, we further investigate the signiﬁcance of VUC
to infer variable types, and we do the following additional
experiments here.
Training and Inference Speed. It takes about two hours to
train the classiﬁcation models based on CNN for six stages,
and it takes about three hours to train the Word2Vec model.
The extracting phase for test data lasts about 24 minutes,
and prediction time (including inference and voting) is about
5 minutes. Each binary takes about 6 seconds on extraction
and prediction. Fortunately, the speed of CATI is acceptable,
because the system is based on static analysis for binaries. It
would be possible bringing in some dynamic analysis in our
future work to increase the accuracy of CATI.
VIII. DISCUSSION
We mainly work on the binaries compiled from GCC
because it is more widely used and previous works are all
based on GCC. After the thorough experiment on the data set
generated from GCC to infer the variable type from stripped
binaries, we still need to conﬁrm that our prototype can work
on other mainstream compilers, like Clang.
In this work, we concern about the method of locating
variables and inferring the types of them from stripped bi-
naries, but we are not sure whether the method is compiler
sensitive. We want to deeply investigate whether the behavior
of variables in source code compiled to a low-level represen-
tation (e.g., binary code) is highly correlated to its compiler.
To validate our hypothesis that our method is transferable,
we ﬁnish the following experiments. Except for the compiler
which we substitute with Clang, the rest of the experimental
setups are the same as the settings in section VII. We train new
models with the binaries compiled from Clang and test the
model with the same applications as before. The performance
of 6 classiﬁers is shown in Table VIII.
Precision
Stage
Stage1
Stage2-1
Stage2-2
Stage3-1
Stage3-2
Stage3-3
Recall
0.95
0.87
0.95
0.88
0.99
0.87
0.95
0.86
0.94
0.88
0.99
0.86
TABLE VII
F1-score
0.95
0.86
0.94
0.88
0.99
0.86
EVALUATION RESULT OF APPLICATIONS COMPILED FROM CLANG.
According to the table, we can see that all 6 classiﬁers
achieve a good result in 3 stages. The total accuracy of all
variables in our test applications is 82.14%, which means that
most of these variables compiled from Clang can be correctly
classiﬁed in all stages. The transformed model can well solve
the type inference problem in the ﬁeld of Clang. Hence, we
can conclude that the design of the prototype is transferable.
What’s more, to make the system more complete, we try
to set up a classiﬁer before our tree-based variable type
classiﬁers to identify the scatter binaries from which compiler.
For different register usages between GCC and Clang, we
successfully train a model with 100% accuracy which is just
used VUCs exactly from previous experiments.
Here, the results indicate that the prototype is transferable
between different compilers, even though we still need to
identify the source compiler of stripped binaries. We also
ﬁnd different compiler options may inﬂuence inferring types,
which will lead us to our future work.
IX. RELATED WORK
In this part, we introduce some works closed to us.
Existing Works. Some previous works focus on variable
recoveries, such as DIVINE [25]. But we leverage the tech-
nique from Hex-Rays to avoid this problem and concentrate
more on type inference. For type inference, REWARDS [16]
and TIE [13] really perform well in the rule-based method and
get a considerable result. ELKAVYA [30] leverages machine
learning to identify 7 types of functions. In recent years, some
works try to distinguish variable types by machine learning
methods. Xu [18] and Maier [22] have successfully identiﬁed
the part of variable types. The former employs Support Vector
Machine (SVM), and the latter employs N-grams. DEBIN [1]
accomplished the mission of variable recovery, type recovery,
and name recovery at the same time with the help of Con-
ditional Random Field. To the best of our knowledge, CATI
is the ﬁrst system that takes the problem of type inference
as text classiﬁcation with the help of instruction context and
overcomes the challenge of uncertain samples.
Approaches for Binary Analysis. There is always a trade-
off between static analysis and dynamic analysis in the ﬁeld
of binary analysis. Under the situation of our work, some
researchers employ static analysis [2], [15], [31], [32] to
pursue the code coverage, while others utilizing dynamic
analysis [16], [33], [34] to trace the target on the execution
time. Intuitively, some works propose hybrid approaches to
make the best of both static and dynamic methods. However,
traditional approaches seem to reach the end, and machine
learning approaches are well adapted to the security ﬁeld in
time. Especially, the strong mapping ability of machine learn-
ing helps experts to solve many problems in binary analysis.
With the help of deep learning, we can ﬁnd some connections
between binaries and source code, which is usually invisible
to the human. It is natural that with the development of large
amounts of code, some tasks achieve a satisfying result, such
as malware classiﬁcation [35]–[37] and function identiﬁcation
[19], [30], [38].
Our work does not directly mix new approaches to reach
better performance, but we utilize the advantage of machine
learning to overcome the partial weakness of static analysis.
We employ static analysis for the reason of its efﬁciency
and code coverage, and we try our best to bring in extra
information which may assist to do the prediction.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:25:44 UTC from IEEE Xplore.  Restrictions apply. 
(cid:26)(cid:24)
X. CONCLUSION
We present a novel approach for inferring the variable type
from stripped binaries. To solve the problem of orphan vari-
ables and uncertain samples, we leverage a new feature called
VUC to transform the representation of variables which is
inspired by our discovery – same type clustering phenomenon.
To validate our hypothesis, we collect a comprehensive data
set
is trained by
convolutional neural networks (CNN).
to establish a multi-stage classiﬁer that
Our system, called CATI, uses CNN models and a voting
mechanism to infer variable types from unseen stripped bina-
ries. The experiment of CATI shows that the system is more
accurate than previous works in different aspects. As a new
feature, VUC really plays a crucial part in our work to improve
the classiﬁcation result.
ACKNOWLEDGMENT
We would like to thank our shepherd Nuno Neves and
the anonymous reviewers for their helpful feedback. We are
grateful for Yifei Huang’s contribution on polishing the paper.
This work was supported in part by grants from the Chinese
National Natural Science Foundation (NSFC 61272078).
REFERENCES
[1] J. He, P. Ivanov, P. Tsankov, V. Raychev, and M. Vechev, “Debin:
Predicting debug information in stripped binaries,” in Proceedings of
the 2018 ACM SIGSAC Conference on Computer and Communications
Security. ACM, 2018, pp. 1667–1680.
[2] A. Prakash, X. Hu, and H. Yin, “vfguard: Strict protection for virtual
function calls in cots c++ binaries.” in NDSS, 2015.
[3] C. Zhang, T. Wei, Z. Chen, L. Duan, L. Szekeres, S. McCamant,
D. Song, and W. Zou, “Practical control ﬂow integrity and randomization
for binary executables,” in 2013 IEEE Symposium on Security and
Privacy.
[4] M. Zhang and R. Sekar, “Control ﬂow integrity for {COTS} binaries,”
the 22nd {USENIX} Security Symposium
IEEE, 2013, pp. 559–573.
in Presented as part of
({USENIX} Security 13), 2013, pp. 337–352.
[5] S. Eschweiler, K. Yakdan, and E. Gerhards-Padilla, “discovre: Efﬁcient
cross-architecture identiﬁcation of bugs in binary code.” in NDSS, 2016.
[6] J. Pewny, F. Schuster, L. Bernhard, T. Holz, and C. Rossow, “Leveraging
semantic signatures for bug search in binary programs,” in Proceedings
of the 30th Annual Computer Security Applications Conference. ACM,
2014, pp. 406–415.
[7] U. Alon, S. Brody, O. Levy, and E. Yahav, “code2seq: Generating
sequences from structured representations of code,” arXiv preprint
arXiv:1808.01400, 2018.
[8] N. D. Bui, L. Jiang, and Y. Yu, “Cross-language learning for program
classiﬁcation using bilateral tree-based convolutional neural networks,”
in Workshops at
the Thirty-Second AAAI Conference on Artiﬁcial
Intelligence, 2018.
[9] S. H. Ding, B. C. Fung, and P. Charland, “Asm2vec: Boosting static rep-
resentation robustness for binary clone search against code obfuscation
and compiler optimization,” in Asm2Vec: Boosting Static Representation
Robustness for Binary Clone Search against Code Obfuscation and
Compiler Optimization.
IEEE, 2019, p. 0.
[10] B. Liu, W. Huo, C. Zhang, W. Li, F. Li, A. Piao, and W. Zou, “αdiff:
cross-version binary code similarity detection with dnn,” in Proceedings
of the 33rd ACM/IEEE International Conference on Automated Software
Engineering. ACM, 2018, pp. 667–678.
[11] V. Jain, S. Rawat, C. Giuffrida, and H. Bos, “Tiff: Using input type
inference to improve fuzzing,” in Proceedings of
the 34th Annual
Computer Security Applications Conference. ACM, 2018, pp. 505–
517.
[12] “IDA Pro,” https://www.hex-rays.com/.
[13] J. Lee, T. Avgerinos, and D. Brumley, “Tie: Principled reverse engineer-
ing of types in binary programs.” in NDSS, 2011.
[14] K. ElWazeer, K. Anand, A. Kotha, M. Smithson, and R. Barua, “Scalable
variable and data type detection in a binary rewriter,” ACM SIGPLAN
Notices, vol. 48, no. 6, pp. 51–60, 2013.
[15] C. Zhang, C. Song, K. Z. Chen, Z. Chen, and D. Song, “Vtint: Protecting
virtual function tables’ integrity.” in NDSS, 2015.
[16] Z. Lin, X. Zhang, and D. Xu, “Automatic reverse engineering of data
structures from binary execution,” in Proceedings of the 11th Annual
Information Security Symposium. CERIAS-Purdue University, 2010,
p. 5.
[17] I. Haller, A. Slowinska, and H. Bos, “Mempick: High-level data structure
detection in c/c++ binaries,” in 2013 20th Working Conference on
Reverse Engineering (WCRE).
IEEE, 2013, pp. 32–41.
[18] Z. Xu, C. Wen, and S. Qin, “Learning types for binaries,” in Interna-
Springer, 2017,
tional Conference on Formal Engineering Methods.
pp. 430–446.
and D. Brumley,
“{BYTEWEIGHT}: Learning to recognize functions in binary code,”
in 23rd {USENIX} Security Symposium ({USENIX} Security 14), 2014,
pp. 845–860.
J. Burket, M. Woo, R. Turner,
[19] T. Bao,
[20] D. Brumley, I. Jager, T. Avgerinos, and E. J. Schwartz, “Bap: A binary
analysis platform,” in International Conference on Computer Aided
Veriﬁcation. Springer, 2011, pp. 463–469.
[21] J. Lafferty, A. McCallum, and F. C. Pereira, “Conditional random ﬁelds:
Probabilistic models for segmenting and labeling sequence data,” 2001.
[22] A. Maier, H. Gascon, C. Wressnegger, and K. Rieck, “Typeminer:
Recovering types in binary programs using machine learning,” in In-
ternational Conference on Detection of Intrusions and Malware, and
Vulnerability Assessment. Springer, 2019, pp. 288–308.
[23] D. Zeng and G. Tan, “From debugging-information based binary-level
type inference to cfg generation,” in Proceedings of the Eighth ACM
Conference on Data and Application Security and Privacy.
ACM,
2018, pp. 366–376.
[24] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean,
“Distributed representations of words and phrases and their composi-
tionality,” in Advances in neural information processing systems, 2013,
pp. 3111–3119.
[25] G. Balakrishnan and T. Reps, “Divine: Discovering variables in executa-
bles,” in International Workshop on Veriﬁcation, Model Checking, and
Abstract Interpretation. Springer, 2007, pp. 1–28.
[26] “The DWARF Debugging Standard.” http://dwarfstd.org/.
[27] “gensim,” https://radimrehurek.com/gensim/.
[28] “Keras,” https://www.tensorﬂow.org/guide/keras.
[29] “scikit-learn,” https://scikit-learn.org/.
[30] Z. L. Chua, S. Shen, P. Saxena, and Z. Liang, “Neural nets can
learn function type signatures from binaries,” in 26th USENIX Security
Symposium, 2017, pp. 99–116.
[31] D. Dewey and J. T. Gifﬁn, “Static detection of c++ vtable escape
vulnerabilities in binary code.” in NDSS, 2012.
[32] M. Noonan, A. Loginov, and D. Cok, “Polymorphic type inference for
machine code,” in ACM SIGPLAN Notices, vol. 51, no. 6. ACM, 2016,
pp. 27–41.
[33] A. Pawlowski, M. Contag, V. van der Veen, C. Ouwehand, T. Holz,
H. Bos, E. Athanasopoulos, and C. Giuffrida, “Marx: Uncovering class
hierarchies in c++ programs.” in NDSS, 2017.
[34] T. Rupprecht, X. Chen, D. H. White, J. H. Boockmann, G. L¨uttgen, and
H. Bos, “Dsibin: identifying dynamic data structures in c/c++ binaries,”
in Proceedings of the 32nd IEEE/ACM International Conference on
Automated Software Engineering.
IEEE Press, 2017, pp. 331–341.
[35] J. Z. Kolter and M. A. Maloof, “Learning to detect malicious executables
in the wild,” in Proceedings of the tenth ACM SIGKDD international
conference on Knowledge discovery and data mining. ACM, 2004, pp.
470–478.
[36] R. Moskovitch, C. Feher, N. Tzachar, E. Berger, M. Gitelman, S. Dolev,
and Y. Elovici, “Unknown malcode detection using opcode representa-
tion,” in European conference on intelligence and security informatics.
Springer, 2008, pp. 204–215.
[37] M. G. Schultz, E. Eskin, F. Zadok, and S. J. Stolfo, “Data mining
methods for detection of new malicious executables,” in Proceedings
2001 IEEE Symposium on Security and Privacy. S&P 2001.
IEEE,
2000, pp. 38–49.
[38] E. C. R. Shin, D. Song, and R. Moazzezi, “Recognizing functions in
binaries with neural networks,” in 24th {USENIX} Security Symposium
({USENIX} Security 15), 2015, pp. 611–626.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:25:44 UTC from IEEE Xplore.  Restrictions apply. 
(cid:26)(cid:25)