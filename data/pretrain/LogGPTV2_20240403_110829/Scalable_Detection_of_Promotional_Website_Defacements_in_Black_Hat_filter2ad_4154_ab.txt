Section 2.1, defacers hack into popular websites and perform
tiny modiﬁcation to insert their promotional content, hoping
that the stealthy defacement can evade detection and indexed
by search engines. When consumers search the jargons and
ﬁnd the defaced website among the search results, there are
usually two ways for the consumer to reach the soliciting web-
site. Firstly, marked as "Path A" in the ﬁgure, the consumer
can infer the illicit content information based on the hints
left by the defacer, e.g., website URL or contact information.
Secondly, the consumer can click on the search results and
visit the defaced web page, as illustrated by "Path B".
2.5 Other Defacement/ Black Hat SEO Tech-
niques
Below we discuss other existing defacement/ black hat SEO
techniques:
• Keyword stufﬁng. The number of keywords contained
in a web page is important for the page rank score. Defac-
ers can thereby include a spectrum of trending keywords
to associate the illicit website with many hot words.
• Link farm [23]. To accumulate a large number of in-
coming links pointed to the illicit websites, defacers can
compromise high page-ranking sites to inject referring
hyperlinks.
• Cloaking [43]. To evade detection, cloaking techniques
are widely used to serve different content to different
Figure 2: System Overview of DMOS
visitors or search engines dynamically. User-Agent, Ref-
erer header, IP address, etc., are inspected to present the
illicit content only to the target customers.
Since illicit solicitations are being vigorously censored by
search engines, defacers have been forced to evolve their tech-
niques. For example, there is a phase-out of old techniques
like keyword stufﬁng as it involves extensive modiﬁcations
of the web page and thus can be easily detected by search
engines. In contrast, modern defacers mostly perform stealthy
defacements and use obfuscated jargons, which tend to be
more elusive yet effective. Nevertheless, whatever techniques
defacers use, they are limited to promote products to their cus-
tomers via search engines. Based on this observation, DMOS
can detect defacements generally and robustly.
3 Design of DMOS
Figure 2 depicts the overall design of DMOS. At a high level,
the workﬂow of DMOS consists of 3 phases. In the Web Page
Acquisition phase, we apply the search engine dork query [15],
which uses advanced search operators (e.g., site:, inurl:, etc.),
to ﬁnd suspicious web pages under a given domain. We then
pre-process and normalize the obfuscated jargons in the Web
Page Pre-processing phase so that we can leverage NLP tech-
niques to detect defacements in the third phase. Due to the
target market of our collaborating industrial partner, we focus
on defacement detection for Chinese websites in this section.
Note however that, our approach is general: in Section 4.4,
we will demonstrate how DMOS can be extended to detect
defacements of web pages in other languages.
3.1 Web Page Acquisition for Training
It is a complex, labor-intensive process to collect and label
a large dataset of web pages to cover a wide range of de-
facement techniques. Below, we ﬁrst discuss how to collect
representative defaced and legitimate web pages. We then
present our efﬁcient data annotating techniques for training
DMOS.
3706    30th USENIX Security Symposium
USENIX Association
Web Page AcquisitionDefacement DetectionWebsite Crawlers(Section 3.1.2)Search Engine Dork Query(Section 3.1.1)Web Page Pre-processing(title,s1)(a, s2)(p, sM)...HTML Parser    M4RK SIX（六台彩）=>MARK SIX （六合彩）Tag-aware Machine- learning ModelsJargon Normalization3.1.1 Collecting Defaced Dataset
To avoid detection by the authorities, defacers have evolved
their techniques, making it more challenging to collect de-
faced web pages. We note that defacers’ primary goal is to
make illicit products rank high in relevant search results so
that they can be readily accessible. Based on this observation,
we leverage the web-crawling capabilities of search engines
and use advanced search engine queries to efﬁciently retrieve
the most suspicious web pages. Speciﬁcally, we search a list
of illicit keywords (like "MARK 6", "M4RK SIX") on search
engines. Since these illicit keywords1 are often meaningless
and irrelevant to outsiders due to their obfuscation (e.g., homo-
phonic/ homomorphic jargons in Section 3.2.2), it is therefore
reasonable to believe that the pages indexed under jargons
are more likely to be defaced web pages. We then use Sele-
nium [11], a web browser automation tool, to follow the links
in the search results and crawl the corresponding web pages.
Jargon-mining algorithm. The next issue is to collect a
large number of illicit keywords to cover different deface-
ment scenarios. Sole reliance on manual keyword crafting is
not viable due to its labor-intensive nature and limited/ un-
certain coverage. To overcome this challenge, we leverage
the “related search” function offered by all major search en-
gines [35, 45] to expand our illicit keyword list based on a
small set of seed jargons. The procedure is detailed as follows:
• We ﬁrst manually collect a small list of seed jargons
through manual crafting or keyword extraction from il-
licit websites (e.g., adult-content website). We also ex-
tract jargons from cybercrime marketplaces (e.g., Silk
Road, a breeding ground for illegal drug business [47])
• We input seed jargons as search terms on mainstream
search engines such as Google, Baidu, 360 Search, etc.
• By collecting the "related search" keywords, we form a
candidate list of keywords that are likely to be illicit.
• We then manually review the keywords in the candidate
list to ﬁlter out those not related to defacements.
While the above process may still miss some illicit keywords,
thanks to the built-in generalization power of its Jargon Nor-
malization module, DMOS can still achieve high detection
performance in our large-scale empirical studies. Refer to
Section 6.1 for more detailed discussions on this issue.
3.1.2 Collecting Legitimate Dataset
Collecting legitimate data, e.g. legitimate web pages that have
not been compromised/ defaced, is relatively straightforward:
We ﬁrst crawl those top-ranked websites across multiple cate-
gories in the China Webmaster list [8]. Since these websites
are expected to be less susceptible, we then ﬁlter and label
these web pages using a light-weight scheme to be described
in Section 3.1.3.
1For the ease of presentation, we use the terms illicit keywords and
jargons interchangeably.
(a) Defaced Dataset Categories (b) Legitimate Dataset Categories
Figure 3: Topic Distribution in Defaced/Legitimate Web
Pages
Upon further examination, we observe that web pages from
the same website are more similar to each other. If we di-
rectly feed all the crawled web pages as training data for our
machine-learning model, it will lead to overﬁtting, which in
turn will result in poor identiﬁcation/ detection performance
for never-before-seen data. To ensure the diversity within
the dataset, we use ssdeep [4], a fuzzy hashing algorithm,
to compute the fuzzy hash value. The hash distance is then
used to measure web pages’ similarity, and only the Top-1000
dissimilar web pages per website are used for training.
3.1.3 Data Annotation
The training of DMOS requires labeled data, which is very
time consuming and resource-intensive.
Label defaced dataset. We manually examine and label
the suspicious pages collected from search engines. If, in the
collected dataset, there is only one suspicious page under a
domain, we manually examine the page by looking for illicit
keywords and checking their context. If there are multiple
suspicious pages under a domain, we randomly sample 10%
pages under this domain for manual veriﬁcation. We observe
that defacements are often conducted in batch for all web
pages from a website with similar jargons. Therefore, if all the
sampled web pages are defaced, we assume all the collected
web pages under the same domain are defaced. Otherwise,
we manually check the remaining suspicious pages under this
domain. For defaced web pages, we also label the categories
of the promoted illicit products.
Label legitimate dataset. While our legitimate dataset
was crawled from ﬁrst-tier websites, we were surprised to
ﬁnd defacements in some of the web pages. For example, we
found 163.com, ranked Top-140 worldwide by Alexa, was
injected with gambling materials in March 2019. To ensure
the correctness of labels, we need to design a light-weight
scheme to remove any defaced web pages from the legitimate
dataset. Speciﬁcally, we ﬁrst develop a list of alarming key-
words, which are broad enough so that any defaced web page
should contain at least one alarming keyword with a very high
probability. In other words, it is difﬁcult for defacers to craft
a defaced web page without any alarming keywords. Then,
USENIX Association
30th USENIX Security Symposium    3707
gamble57.21%porn28.11%game5.76%sales8.92%travel4.55%entertainment8.07%sports5.30%health6.24%government17.15%education15.24%news1.67%life12.16%others7.83%technology8.16%business10.63%shopping3.00%we use the Aho-Corasick string-searching algorithm [6] to
search for alarming keywords among web pages. By admit-
ting the vast majority (95%) of the legitimate web pages with
this pre-screening step, we can afford to check the remaining
ones manually to ensure they have not been compromised.
To generate the list of alarming keywords, we compare the
frequency difference of a keyword in the legitimate dataset
and defaced dataset, respectively. More details can be found
in Appendix A.
3.1.4 Details of Our Final Dataset
Figure 4: The Procedure for Jargon Normalization
Based on 439 seed jargons, we collected 216,708 illicit key-
words, where keywords related to gambling, adult content
(porn), and sales comprise the majority of the data. Given
these illicit keywords, we collected 294,393 suspicious web
pages from 4,931 websites in total. After verifying and la-
beling the web pages as discussed in Section 3.1.3, we ﬁlter
out web pages of incorrect labels to yield 147,754 of defaced
web pages across 2,103 websites. The dataset covers com-
mon defacement categories, whose proportion is shown in
Figure 3a. Note that the category of sales includes different
illicit goods and services such as fake credentials/ certiﬁcates,
counterfeits, surrogacy, and unlicensed drugs, etc.
For the legitimate dataset, we collected 389,438 web pages
from 5,121 websites in total, covering most website cate-
gories (e.g., government, sports, health, etc.). Their statistics
are depicted in Figure 3b. We randomly split 70% of the legit-
imate and defaced datasets for training and use the remaining
30% for ofﬂine testing (see Section 4.1).
3.2 Web Page Preprocessing
As mentioned earlier, modern defacement campaigns often
obfuscate jargons (also called "illicit keywords” in this pa-
per) using similar shape or pronunciation to bypass detection.
Existing NLP techniques cannot adequately learn or under-
stand these jargons for two reasons. Firstly, the vocabulary of
jargons is constantly evolving and differs signiﬁcantly from
the standard vocabulary. Secondly, many illicit keywords are
created in ungrammatical and obfuscated forms (e.g., letter
"l" can be replaced by digit "1") while the NLP techniques are
geared towards the properly-written text. To leverage the tech-
nical advances of NLP for detecting defaced web pages, we
need to recover transformed jargons to their base forms. Be-
low, we ﬁrst introduce how to parse HTML and then discuss
how to identify and recover these jargons.
3.2.1 Parsing HTML into Tag-Sentence Pairs
Web pages are parsed to extract tag-sentence pairs. In particu-
lar, there exist special HTML tags which can contain text not
only in the body but also in speciﬁc attributes, e.g., keywords
of meta tag and alt of image tag, etc. One example snippet is
presented in Listing 1, for which the parsed result is [(‘a.title’,
‘MARK SIX’), (‘a’,‘benign content’)].
Listing 1: An Example of Special HTML Tags
1
2
 benign content 
For a formal deﬁnition, suppose page is a web page, its
parsed result is page = [(tag1,s1), (tag2,s2),··· , (tagM,sM)],
where M indicates the maximum length of page. Let N be
the maximum length of a sentence si. When the length of a
sentence exceeds this parameter N, we split this sentence into
sub-sentences, and add these tag-sub-sentence pairs to page.
3.2.2
Jargon Normalization
Recovering obfuscated jargons is of great importance for
machine-learning models to understand the semantics of the
jargons and thus can precisely recognize defaced web pages.
Since the obfuscated jargons should be easily understood by
human subjects, these jargons often share similar pronun-
ciations (i.e., homophonic jargons) or similar shapes (i.e.,
homomorphic jargons) with their original forms.
• Homophonic jargon. There is a system called Pinyin
to notate the pronunciation of Chinese characters. The
Pinyin-to-character mapping is a one-to-N mapping.
Therefore, homophonic characters are common and have
been widely abused by defacers. For example, instead of
directly using MARK SIX (i.e., 六合彩), defacers may
use MARC SIX (i.e., 六和彩), a transformed jargon with
the same Pinyin “LiuHeCai".
• Homomorphic jargon. Some Chinese characters have
similar shapes. These homomorphic characters are also
commonly used to obfuscate jargons. For example, de-
facers can use M4RK SIX (i.e., 六台彩), as shown in
Figure 1, to replace the blocked keyword of MARK SIX
(i.e., 六合彩) based on their similar appearance.
To identify the obfuscated keywords, we develop the follow-
ing jargon normalization procedure, as illustrated in Figure 4:
1. Language Modeling (LM) is a classical task for assign-
ing probabilities to sentences drawn from a corpus. It
3708    30th USENIX Security Symposium
USENIX Association
Language Modeltag-sentence pairsnon-fluent sentences        Homophonic/Homomorphic  Jargon RecoveryLanguage Modelseed jargons(title, s1’)(a, s2’)(p, sM’)recoveredsentences jargoncandidates is often used to measure the smoothness/ idiomaticness
of sentences. Since sentences with obfuscated jargons
should not be smooth, we can use LM to ﬁlter out smooth
sentences, which should not contain any jargons. For ef-
ﬁciency considerations, we adopt the unigram LM [10]
approach. We then build the model using a corpus con-
sisting of the Chinese wiki [9], the legitimate dataset we
collected (see Section 3.1.2), and illicit web pages2, but
not the defaced victim pages.
2. We use unigram LM to assign a probability for each
sentence. High-probability sentences are believed to be
similar to the corpus. In contrast, the minority of low-
probability sentences are assumed to be non-ﬂuent and
thus can contain obfuscated jargon candidates.
3. We identify the homophonic/ homomorphic jargons from
these non-ﬂuent sentences and transform them back to
their base forms (i.e., jargon candidates), on which we
expand later.
4. For jargon candidates, we use LM to measure the ﬂu-
entness again. Only high-probability sentences are used
and recovered, while the others are abandoned since they
have never been seen in our large corpus.
Homophonic Jargon Recovery. To identify and recover ho-
mophonic jargons from non-ﬂuent sentences, we take the
following steps:
• We collect a list of seed jargons (e.g., MARK SIX). As
described in Section 3.1.1, this is a relatively straight-
forward process of extracting keywords from illicit web-
sites, etc.
• We use a sliding window to traverse non-ﬂuent sentences
and convert Chinese characters within the window to
their Pinyin representations.
• We then calculate the editing distance (e.g., Levenshtein
distance [49]) of Pinyin between the characters in the
window and seed jargons.
• If the distance is under a threshold, it means the char-
acters in the window and the seed jargons are similar.
Therefore, we replace the characters with the matched
seed jargon. The latter is treated as jargon candidates.
Homomorphic Jargon Recovery. We need an encoding sys-
tem, similar to Pinyin, but can encode Chinese characters
according to their shapes instead of pronunciations. Fortu-
nately, we ﬁnd the Four-Corner System [1] that can suit this
requirement. It can be seen as a perceptual hashing algorithm
that can embed the shape information of Chinese characters.
With this encoding, the distance between homomorphic jar-
gons should be small.
The Jargon Normalization Algorithm (JNA) has achieved
an outstanding accuracy. We manually check the results of
the ofﬂine testing data. JNA identiﬁes 50,855 obfuscated
jargons, out of which only 5 are false positives. More details
are given in Section 5.2. Due to the high cost of manual false
2To crawl illicit web pages, we can visit illegal websites directly or follow
the links of defaced pages. They should not contain obfuscated jargons.
negative checking, we can only afford to sample around 50
defaced web pages without detected obfuscated jargon. When