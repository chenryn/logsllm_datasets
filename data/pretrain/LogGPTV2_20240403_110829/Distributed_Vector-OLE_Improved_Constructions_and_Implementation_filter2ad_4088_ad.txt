1
Sender
Receiver
Figure 1: Example of the GGM tree generated by the sender and partially learnt by the receiver. Here, 𝑘 = 2, 𝑛 = 8, and 𝑖 = 3.
Thus, the path not learnt by the receiver is (010). For each level, the parties run an OT where the receiver learns an XOR of
either the left children or the right children of that level. Using previously expanded sub-trees, this information allows the
receiver to learn a new seed (nodes filled in blue) which can be expanded by repeatedly calling 𝐺 (the nodes resulting from
such expansions are filled in black).
can then appropriately set the 𝑖th entry of r2 so that 𝑟1
𝑖 = 𝛽.
Note that, as long as P2 obtains 𝑅𝛽 in the key generation phase, the
corrections can be applied during expansion. Our construction is
presented in Protocol 3 in terms of the key generation and expansion
procedures for (𝑛 − 1)-out-of-𝑛-ROT from the previous section,
which encompasses the steps from above.
𝑖 + 𝑟2
Lemma 4.1. Protocol 3 securely implements Known-Index SPFSS
over a domain of size 𝑛 in the (𝑛 − 1)-out-of-𝑛-ROT hybrid model.
With (𝑛 − 1)-out-of-𝑛-ROT instantiated by the construction of Pro-
tocol 2, Protocol 3 requires 𝑂(𝜆 log 𝑛) communication and 𝑂(𝜆𝑛)
computation per party where 𝜆 is the security parameter of the ROT.
Proof Sketch. The main argument in the security proof is that
𝑅𝛽 is a one-time pad that masks 𝛽1, given the property of (𝑛 −
1)-out-of-𝑛-ROT that the output of P1 is a random vector. A detailed
proof is given in Appendix A.2.
5 KNOWN-INDICES MPFSS VIA CUCKOO
HASHING
In this section we present a reduction from known-index multi-
point FSS to known index single point FSS. The multi-point setting
is analogous to the SPFSS functionality of Protocol 3, but extended
to functions that fix the value of 𝑡 ≥ 1 points. We formalize our
Known-Indices MPFSS variant in Definition A.7 in the appendix. A
naive reduction executes 𝑡 independent instances of known-index
SPFSS on the original database. However, as observed by Boyle
et al. [9], this requires evaluating all 𝑡 SPFSS instances on the whole
domain, which results in an Ω(𝑡𝑛) computational overhead.
Protocol 3: Distributed Known-Index Single Point FSS
Params and Building Blocks: (𝑛 − 1)-out-of-𝑛-ROT;
Point function 𝑓 : [𝑛] → G, 𝑓 (𝑖) = 𝛽, 𝑓 ( 𝑗) = 0 ∀ 𝑗 ≠ 𝑖
Random shares 𝛽1, 𝛽2 : 𝛽1 + 𝛽2 = 𝛽; 𝑏 ∈ {0, 1}
Parties: P1, P2
Inputs: P1 : 𝛽1, P2 : 𝛽2, 𝑖
Key Generation (SPFSS.Gen(1𝜆, 𝑓𝑖,𝛽)):
(1) The parties run a secure ROT.Gen(1𝜆, 𝑛, 𝑖) protocol to
(2) The parties execute locally ROT.Expand, from which P1
obtain keys 𝐾ROT1
gets 𝑛 random values {𝑟𝑖}𝑗 ∈[𝑛], and P2 obtains
{𝑟𝑖}𝑗 ∈[𝑛],𝑗≠𝑖.
and 𝐾ROT2
.
(3) Let 𝑅 =𝑗 ∈[𝑛] 𝑟𝑖. P1 sends to P2 the value 𝑅𝛽 = 𝑅 − 𝛽1.
(4) P2 computes ˜𝑟 = 𝛽2 − 𝑅𝛽 +𝑗 ∈[𝑛]\{𝑖} 𝑟𝑖.
• If 𝑏 = 2, parse 𝐾2 as(cid:0)𝐾ROT2
compute v2 ← ROT.Expand(cid:0)2, 𝐾ROT2
(5) P1 outputs 𝐾1 ← 𝐾ROT1
(6) P2 outputs 𝐾2 ← (𝐾ROT2
Expansion (SPFSS.Eval(𝑏, 𝐾𝑏, 𝑥)):
• If 𝑏 = 1, compute v1 ← ROT.Expand(1, 𝐾1) and output 𝑣1
𝑥.
, ˜𝑟(cid:1). If 𝑥 = 𝑖, output ˜𝑟. Otherwise,
(cid:1) and output −𝑣2
, ˜𝑟).
𝑥.
A general idea to improve on this baseline is to rely on batching
schemes that split the domain of size 𝑛 into 𝑚 small parts in a way
that allows to distribute the 𝑡 SPFSS instances across the 𝑚 smaller
parts. One can instantiate this general idea using a combinatorial
object called batch codes (see Ishai et al. [36] for an introduction).
7
𝑚 Buckets
Hash Table 𝑇
𝑡 Indices
ℎ1
ℎ2
ℎ3
𝑖
𝑖
𝑖
𝑖1
.
.
.
𝑖 𝑗
.
.
.
𝑖𝑡
ℎ3
𝑖 𝑗
1
2
...
𝑖
...
𝑛
Public
𝑃2
Figure 2: The domain of the MP function is hashed 𝜅 times
into 𝑚 Buckets using 𝜅 different hash functions (this ar-
rangement is public). P2 privately builds a cuckoo hash ta-
ble of the indices of the MP function. Then, an instance of
known-index SPFSS is executed for each bucket.
A batch code with parameters 𝑛, 𝑡, 𝑘, 𝑚 gives a partition of a data-
base of size 𝑛 into 𝑚 parts such that any 𝑡 indices from [𝑛] can
be recovered by reading at most 𝑘 entries in each of the 𝑚 parts.
Although batch codes are attractive in that they offer very strong
provable guarantees, they can be hard to instantiate in practice.
This issue arises in the construction proposed by Boyle et al. [9],
who explore Combinatorial Batch Codes (CBCs) for batching mul-
tiple FSS instances to obtain MPFSS. Since explicit constructions
of the expander graphs required for instantiating a CBC do not
satisfy their efficiency requirements, Boyle et al. propose a heuris-
tic construction of a CBC. This leads to a small failure probability,
which asymptotically depends on 𝑡 and the expansion factor of the
batch code. However, concrete parameters for the heuristic CBC
construction are not given by Boyle et al., and in their running time
estimates, the authors assume 𝑡 SPFSS instances on disjoint subsets
of [𝑛] instead of full MPFSS.
A second approach to baching is given by Angel et al. [1], who
introduce a relaxed notion of Probabilistic Batch Codes (PBCs).
Unlike the heuristic CBC construction of Boyle et al. [9], batching
here may fail on each insertion of 𝑡 indices with a certain probability
(which can be made arbitrarily small). The PBC construction of
Angel et al. [1] is inspired by many works in the PSI literature [15,
21, 26, 49], where cuckoo hashing [47] is commonly used to reduce
PSI to private set membership queries. We follow this line of work,
and base our MPFSS construction on probabilistic batching.
5.1 Batching Known-Index SPFSS
5.1.1 Cuckoo hashing as a PBC. Our approach to build MPFSS from
single point FSS is to use Cuckoo hashing [47] and simple hashing
in a similar manner as in PSI and PIR protocols [1, 15, 21, 26, 49].
Cuckoo hashing [47] is a multi-choice hashing scheme with eviction
parameterized by 𝜅 universal hash functions ℎ1, . . . , ℎ𝜅. Cuckoo
hashing achieves the goal of distributing 𝑡 items in a table 𝑇 of size
𝑚 in a manner that guarantees that each location in 𝑇 is occupied
8
by at most one item. The insertion algorithm puts the item to be
inserted 𝑥 at 𝑇 [ℎ1(𝑥)] and, if this position is occupied, evicts the
item in that position and relocates it using ℎ2, which may cause
yet another eviction resolved using ℎ3, and so on. This insertion
algorithm may fail when a cycle of evictions is found, and thus
cuckoo hashing has a failure probability that depends on parameters
𝜅, 𝑛, 𝑡 and 𝑚. Several works [15, 21, 49] that use cuckoo hashing
in secure computation protocols have empirically studied such
parameters and how they relate to the failure probability. In our
work we use the estimates of Demmler et al. [21], which leads to the
same parameter choices used by Angel et al. [1] and Chen et al. [15].
While we present our concrete parameter choices in Section 8.2,
we keep these symbolic in the protocol description for presentation
purposes. We therefore introduce a statistical security parameter
𝜂, meaning that the probability of failing at hashing 𝑡 items is
bounded by 2−𝜂. More specifically, we denote by ParamGen(𝑛, 𝑡, 𝜂)
the function that generates cuckoo hashing parameters, i.e., number
of hash functions 𝜅 and cuckoo table size 𝑚, that guarantee this
statistical bound on the insertion failure probability. Note that in
the case of such an insertion failure, P1 learns of it in Step (1) of the
protocol and thus can handle this case in several ways in practice.
For example, it could simply abort the protocol, or it could sample
new hash functions until the hashing step succeeds or a maximum
number of trials is reached. In these cases, hashing failures result
in leakage, as the adversary can infer information about the indices
from the fact that they failed (or did not fail) to hash. A second
option is to sacrifice correctness instead, and simply ignore indices
that failed to hash. This way, no information is leaked from the
generated MPFSS keys, but the multi-point function changes with a
small probability. As discussed in [1, 15], the strategy for handling
hashing failures depends a lot on the exact use case. In the case of
vector OLE, we choose to drop indices that fail to hash (cf. Section 6).
This is also the approach suggested by Boyle et al. [9] for their
heuristic batch code construction. Our protocol therefore achieves
the same type of security guarantee, while at the same time being
concretely efficient.
5.1.2 Our protocol. Our construction is shown in Protocol 4. We
use a cuckoo hashing scheme with capacity 𝑡 instantiated with 𝜅
hash functions mapping [𝑛] to [𝑚], where (𝑚, 𝜅) = ParamGen(𝑛, 𝑡, 𝜂)
as described above. In step (1), the party holding the 𝑡 non-zero
evaluation points of the multi-point function computes a cuckoo
hash table 𝑇 of size 𝑚 that contains them. In step (2), the two parties
use all of the 𝜅 hash functions to simple-hash the whole domain [𝑛].
This results in 𝑚 buckets 𝐼1, . . . , 𝐼𝑚, with 𝜅 copies of each integer
in [𝑛] distributed across them uniformly at random. An important
point is that this arrangement is public (see left side of Figure 2).
The parties also fix an order within each bucket 𝐼𝑙, and compute
the reverse mapping pos𝑙 from items to positions.
After having assigned indices to buckets, our protocol securely
runs an SPFSS key generation for each bucket 𝐼𝑙. First, in step (3),
the parties obtain shares of the vector v of values to be fixed in each
of the SPFSS instances (the value 𝛽 in Protocol 3). This needs to be
done in a secure computation because both parties share all 𝛽𝑖’s,
while only P2 knows which 𝛽𝑖 maps to which bucket. The secure
computation can be implemented using permutation networks [53]
in a garbled circuit, or using additive homomorphic encryption.
Protocol 4: Distributed Known-Indices MPFSS
Public Params: Input domain [𝑛], number of points 𝑡,
statistical security parameter 𝜂,
Cuckoo hash parameters: table size 𝑚, and number of hash
functions 𝜅, (𝑚, 𝜅) = ParamGen(𝑛, 𝑡, 𝜂)
Point function 𝑓i,𝜷 : [𝑛] → F, 𝑓i,𝜷 (𝑖 𝑗) = 𝛽1
𝑗 ∈ [𝑡], 𝑓i,𝜷 ( 𝑗′) = 0 for all other inputs.
Parties: P1, P2
Inputs: P1: 𝑥, 𝛽1
𝑡 ; P2: 𝑖1, . . . 𝑖𝑡, 𝛽2
Key Generation (MPFSS.Gen(1𝜆, 𝑓i,𝜷)):
(1) P2 randomly chooses 𝜅 hash functions (ℎ 𝑗)𝑗 ∈[𝜅], with
1, . . . , 𝛽1
1, . . . , 𝛽2
𝑗 for all
𝑗 + 𝛽2
𝑡
ℎ 𝑗 : [𝑛] → [𝑚]. P2 inserts 𝑖1, . . . 𝑖𝑡 into a Cuckoo hash table
𝑇 of size 𝑚 using ℎ1, . . . , ℎ𝜅, and it sends the 𝜅 hash
functions to P1. Let empty bins in 𝑇 be denoted by ⊥.
(2) P1 and P2 do simple hashing with all 𝑘1, . . . , ℎ𝜅 on the
domain [𝑛], to independently build 𝑚 buckets 𝐼1, . . . , 𝐼𝑚, i.e.
𝐼𝑙 = (𝑥 ∈ [𝑛] | ∃𝑝 ∈ [𝜅] : ℎ𝑝(𝑥) = 𝑙), for 𝑙 ∈ [𝑚], each
sorted in some canonical order. The parties compute
functions pos𝑙 : 𝐼𝑙 → [|𝐼𝑙|] that map values to their
position in the 𝑙-th bucket.
𝑗 + 𝛽2
𝑗 ∈[𝑡], where 𝑙 𝑗 is the location of 𝑖 𝑗 in
𝑇 . The parties run a secure 2PC protocol to obtain random
shares v1, v2 of the vector v ∈ F𝑚 defined as
(3) Let u =(cid:0)(𝛽1
𝑗 , 𝑙 𝑗)(cid:1)
(cid:26) 𝑎
v𝑗 =
0
if (𝑎, 𝑗) ∈ u,
otherwise.
(4) For all 𝑙 ∈ [𝑚], P1 and P2 run 𝑆𝑃𝐹𝑆𝑆.𝐺𝑒𝑛(1𝜆, 𝑔𝑙)
(Protocol 3) to obtain seeds (𝐾𝑙