main reason for contacting him was that we wanted to have a completely independ-
ent comparison of various fuzzer technologies, and did not want to write that our-
selves as both of us had strong opinions in various, conflicting, directions. I, for
instance, have always been a strong believer in syntax testing-based negative testing
(some call this model-based fuzzing), with no random component to the tests. Jared
on the other hand was working on evolutionary fuzzers. Charlie accepted to write a
chapter, but later actually got more deeply involved in the project and ended up writ-
ing almost one third of the book (Charlie should definitely do more traveling, as he
claims he wrote all that in an airplane).
Our goal was to write something that would be used as a course book at uni-
versities, but also as a useful reference for both quality assurance engineers and
security specialists. And I think we succeeded quite well. The problem with other
available books was that they were targeted to either security people, or to quality
assurance, or on very rare occasions to the management level. But fuzzing is not
only about security, as fuzzers are used in many closed environments where there
are no security threats. It is also not only about software quality. Fuzzing is a con-
vergence of security practices into quality assurance practices, or sometimes the
other way around. In all 100+ global customers of Codenomicon fuzzing tools (in
late 2007), from all possible industry verticals, the same logic is always apparent
in deploying fuzzers: Fuzzing is a team effort between security people and quality
assurance people.
There are many things that were left out of this edition of the book, but hopefully
that will motivate you to buy enough books so that the publisher will give us an
opportunity to improve. This book will never be complete. For example in 2007
and early 2008 there were a number of completely new techniques launched around
fuzzing. One example is the recent release of the PROTOS Genome. Also, commer-
cial companies constantly continue to develop their offerings, such as the rumors of
the Wurldtech “Achilles Inside” (whatever that will be), and the launch of the “fifth
generation” Codenomicon Defensics 3.0 fuzzing framework, both of which were not
covered in this book. Academics and security experts have also released new frame-
works and tools. One example that you definitely should check out is the FuzzGuru,
available through OWASP. I am also expecting to see something completely different
from the number of academics working with fuzzing, such as the techniques devel-
oped by the Madynes team in France.
We promise to track those projects now and in the future, and update not only
this book, but also our web site dedicated to fuzzing-related topics (www.fuzz-test
.com.) For that, please contact us with your comments, whether they are positive or
negative, and together we will make this a resource that will take software develop-
ment a giant leap forward, into an era where software is reliable and dependable.
Ari, Jared, and Charlie
xx
Preface
Acknowledgments
From Ari Takanen
There have been several people who have paved the way toward the writing of this
book. First of all, I want to give big hugs and thanks to my home team. My family
has been supportive in this project even if it has meant 24-hour workdays away from
family activities. Combining a couple of book projects with running a security com-
pany, traveling 50% of the year around the globe attending various conferences,
and meeting with global customers can take a bit of time from the family. I keep
making promises about dedicating more time for the family, but always fail those
promises.
I am forever grateful to both Marko Laakso and Prof. Juha Röning from Univer-
sity of Oulu for showing me how everything is broken in communication technolo-
gies. Everything. And showing that there is no silver bullet to fix that. That was really
eye-opening. To me, my years as a researcher in the OUSPG enabled me to learn
everything there was to learn about communications security.
Enormous thanks to all my colleagues at Codenomicon, for taking the OUSPG
work even further through commercializing the research results, and for making it
possible for me to write this book although it took time from my CTO tasks. Special
thanks to Heikki and Rauli. Thank you to everyone who has used either the Code-
nomicon robustness testing tools, or the PROTOS test-suites, and especially to every-
one who came back to us and told us of their experiences with our tools and
performing security testing with them. Although you might not want to say it out
loud, you certainly know how broken everything is. Special thanks to Sven Weizeneg-
ger who provided valuable insight into how fuzzers are used and deployed in real-
life penetration testing assignments.
I would like to thank everyone involved at Artech House, and all the other peo-
ple who patiently helped with all the editing and reviewing, and impatiently reminded
about all the missed deadlines during the process. Special thanks to Dr. Boris Beizer
for the useful dialog on how syntax testing (and fuzzing) was done in the early 70s,
and to Michael Howard for the review comments.
Finally, thanks Jared and Charlie for joining me in this project. Although it was
slow and painful at times, it certainly was more fun than anything else.
From Jared DeMott
Jared would like to thank God and those he’s known. The Lord formed me from dust
and my family, friends, co-workers, classmates, and students have shaped me from
there. Special thanks to Ari, Charlie, and Artech for working hard to keep the book
project on track. Thanks to my beautiful wife and two energetic boys for supporting
xxi
all of my career endeavors, and thanks to our parents for giving us much needed
breaks and support.
Our goal is that readers of this book will receive a well-rounded view of comput-
ing, security, software development, and of course an in-depth knowledge of the art
and science of this evolving branch of dynamic software testing known as fuzzing.
From Charlie Miller
I’d like to thank my family for their love and support. They make everything worth
while. I’d also like to thank JRN, RS, JT, OB, and EC for teaching me this stuff.
Finally, thanks to Michael Howard for his insightful comments while editing.
xxii
Acknowledgments
C H A P T E R  1
Introduction
Welcome to the world of fuzzing! In a nutshell, the purpose of fuzzing is to send
anomalous data to a system in order to crash it, therefore revealing reliability prob-
lems. Fuzzing is widely used by both security and by quality assurance (QA)
experts, although some people still suffer from misconceptions regarding its capa-
bilities, effectiveness, and practical implementation. Fuzzing can be defined as
A highly automated testing technique that covers numerous boundary cases using
invalid data (from files, network protocols, API calls, and other targets) as applica-
tion input to better ensure the absence of exploitable vulnerabilities. The name
comes from modem applications’ tendency to fail due to random input caused by
line noise on “fuzzy” telephone lines.1
But before you explore fuzzing further, we ask you to try to understand why
you are interested in fuzzing. If you are reading this, one thing is clear: You would
like to find bugs in software, preferably bugs that have security implications. Why
do you want to find those flaws? Generally, there are three different purposes for
looking for these types of defects:
1. Quality Assurance (QA): Testing and securing your internally developed
software.
2. System Administration (SA): Testing and securing software that you depend
on in your own usage environment.
3. Vulnerability Assessment (VA): Testing and trying to break into someone
else’s software or system.
We have seen a number of books about fuzzing that are written by security
experts for security experts. There are also a handful of books that cover topics rel-
evant to fuzzing, written by quality assurance engineers for other quality assurance
engineers. Another set of books consists of “hacking cookbooks,” which teach you
to use a set of tools without providing much original content about the topic at
hand. In real life, testing practices are not that different from security assessment
practices, or from hacking. All three require some theoretical knowledge, and some
information on the available tools, as it is not efficient to continuously reinvent the
wheel and develop our own tools for every task that arises.
1
1Peter Oehlert, “Violating Assumptions with Fuzzing,” IEEE Security & Privacy (March/April
2005): 58–62.
In this book, we will look at fuzzing from all of these perspectives. No matter
what your purpose and motivation for fuzzing, this is the book for you. We will
view fuzzing from a developer’s perspective, as well as through the eyes of an enter-
prise end user. We will also consider the requirements of a third-party assessment
team, whether that is a testing consultant or a black-hat hacker. One goal of this
book is to level the playing field between software companies (testers) and vulner-
ability analysts (hackers). Software testers can learn from the talents of hackers,
and vice versa. Also, as end users of software, we should all have access to the same
bug-hunting knowledge and experience through easy-to-use tools.
Why did we choose fuzzing as the topic for this book? We think that fuzzing is
the most powerful test automation tool for discovering security-critical problems in
software. One could argue that code auditing tools find more flaws in code, but
after comparing the findings from a test using intelligent fuzzing and a thorough
code audit, the result is clear. Most findings from code auditing tools are false pos-
itives, alerts that have no security implications. Fuzzing has no such problem. There
are no false positives. A crash is a crash. A bug is a bug. And almost every bug
found with fuzzing is exploitable at some level, at minimum resulting in denial of
service. As fuzzing is generally black-box testing, every flaw is, by definition,
remotely exploitable, depending, of course, on the interface you are fuzzing and to
some extent on your definition of exploitation. Fuzzing is especially useful in ana-
lyzing closed-source, off-the-shelf software and proprietary systems, because in
most cases it does not require any access to source code. Doesn’t that sound almost
too good to be true?
In this chapter we will present an overview of fuzzing and related technologies.
We will look at why security mistakes happen and why current security measures
fail to protect us from security compromises that exploit these mistakes. We will
explore how fuzzing can help by introducing proactive tools that anyone can use to
find and eliminate security holes. We will go on to look where fuzzing is currently
used, and why. Finally, we will get a bit more technical and review the history of
fuzzing, with focus on understanding how various techniques in fuzzing came into
existence. Still, remember that the purpose of this chapter is only to provide an
overview that will prepare you for what is coming later in the book. Subsequent
chapters will provide more details on each of these topics.
1.1
Software Security
As stated before, fuzzing is a great technique for finding security-critical flaws in
any software rapidly and cost effectively. Unfortunately, fuzzing is not always used
where it should be used, and therefore many systems we depend on are immature
from a security perspective. One fact has emerged from the security field: Software
will always have security problems. Almost all software can be hacked easily. But
if you become familiar with the topic of software security and the related tech-
niques, you might be able to make a difference on how many of those parasitic
security mistakes eventually remain in the software. This is what software security
is about.
2
Introduction
Very few people today know what software security really is, even if they are
so-called “security experts.” Like the maps in ancient history used to warn, the dan-
gerous area just outside the map is sometimes best left alone. The uncharted territory
just read, “Here be dragons,” meaning that you should not venture there. It is too
scary or too challenging. Fortunately for software security, the age of darkness is
over because the first explorers risked their souls and delved into the mystic lands of
hacking, trying to explain security to ordinary software developers. First, they were
feared for their new skills, and later they were blamed for many of the dangerous
findings they encountered. Even today they are thought to possess some secret arts
that make them special. But what they found was not that complex after all.
Well, in our defense we have to say that we have explored the wilderness for
more than ten years; so one could say that we are familiar with the things beyond the
normal scope of software engineering and that we know the field well. We have
looked at software security from an academic and commercial fuzzer developer per-
spective, but also through the eyes of a security consultant, a contract hacker, and an
independent analyst. Grab a book on secure programming, or one of the few good
books on security, and you will be amazed how simple it is to improve software secu-
rity through secure programming practices. Software security is a highly desirable
topic to learn. The only thing you need is motivation and a will to learn. Young chil-
dren could master those skills (and they continue to do so). Anyone can find a unique
new vulnerability in almost any piece of commercial software and write an exploit
for it. Anyone can even write worms or viruses with some focus on the topic. If you
do not know what a vulnerability is, or what an exploit is, or even how to use one,
you might be better off reading some other security-related book first. Don’t have
patience for that? Well, we will do our best to explain along the way.
But first, let us look at what solutions are available out there. Software security
can be introduced at various phases and places, starting from research and devel-
opment (R&D), then entering the test-lab environment, and finally in the opera-
tions phase (Figure 1.1).
In R&D, fuzzing can be used both in the early prototyping phase and in the
implementation phase, where the majority of programming takes place. In fact,
immediately when the first operational prototype is ready, it can be fuzzed. But a
1.1
Software Security
3
Figure 1.1
Phases in the software life cycle, and the resulting places for using fuzzing.
more natural tool for software security in this phase is a source code auditing tool,
which we will discuss later. One thing common in R&D environments is that devel-
opers themselves use the tools at this stage.
Testing as an activity takes place throughout all phases of the software life
cycle. Although most programmers conduct the first unit tests as part of R&D, a
dedicated team typically performs most of the remaining testing efforts.2 A test lab
environment can be quite different from an R&D environment. In a test lab, a sys-
tem can be tested with any available tools, and the test results can be analyzed with
all possible metrics selected for use. A test lab may contain expensive, dedicated
tools for load and performance testing, as well as fuzzing. Indeed, some commer-
cial fuzzers have been implemented as fixed test appliances for traditional test lab
environments.
In operations, various post-deployment techniques are used to increase soft-
ware security. Vulnerability scanners or security scanners such as Nessus3 are most
commonly used in a live environment. An important criterion for test tools in an
operational environment is that they should not disrupt the operation of critical
services. Still, penetration testing services are often conducted against live systems,
as they need to validate the real environment from real threats. This is because not
all problems can be caught in the controlled confines of a test lab. Similarly, fuzzing
should be carefully considered for operational environments. It may be able to find
more flaws than when compared to a test lab, but it will most probably also disrupt
critical services.
Never forget that there is no silver bullet solution for security: Not even fuzzing
can guarantee that there are no flaws left in the software. The fast-paced world of
technology is changing, growing, and constantly evolving, for better or worse. This
is good news for testers: People will be writing new software for the foreseeable
future. And new software inevitably brings new bugs with it. Your future careers are
secured. Software is becoming more complex, and the number of bugs is thought to
be directly proportional to lines of code. The security testing tools you have will
also improve, and as you will see, fuzzing tools certainly have evolved during the
past 20 years.
1.1.1
Security Incident
The main motivation for software security is to avoid security incidents: events
where someone can compromise the security of a system through active attacks, but
also events where data can be disclosed or destroyed through mistakes made by
people, or due to natural disasters such as floods or tornadoes. Active compromises
are the more significant factor for discussions related to fuzzing. “Accidental” inci-
dents may arise when software is misconfigured or a single bit among massive
4
Introduction
2The exact proportion of testing intermixed with actual development and testing performed by
dedicated testers depends on the software development methodology used and the organizational
structure of the development team.
3Nessus Security scanner is provided by Tenable Security and is available at www.nessus.org
amounts of data flips due to the infamous alpha-particles, cosmic rays, or other
mysterious reasons and result in the crash of a critical service. Accidental incidents
are still quite rare events, and probably only concernservice providers handling mas-
sive amounts of data such as telecommunication. The related threat is minimal, as
the probability of such an incident is insignificant. The threat related to active
attacks is much more severe.
Software security boasts a mixture of terms related to security incidents. Threats
are typically related to risks of loss for an asset (money, data, reputation). In a secu-
rity compromise, this threat becomes realized. The means of conducting the com-
promise is typically done through an attack, a script or malicious code that misuses
the system, causing the failure, or potentially even resulting in the attacker’s taking
control of the system. An attack is used to exploit a weakness in the system. These
weaknesses are called software vulnerabilities, defects, or flaws in the system.
Example threats to assets include
• Availability of critical infrastructure components;
• Data theft using various technical means.
Example attacks are the actual exploitation tools or means:
• Viruses and worms that exploit zero-day flaws;
• Distributed Denial of Service (DDoS) attacks.
Vulnerabilities can be, for example,
• Openness of wireless networks;
• Processing of untrusted data received over the network;
• Mishandling of malicious content received over the network.
Even the casual security hackers are typically one step ahead of the system
administrators who try to defend their critical networks. One reason for that is the
easy availability of vulnerability details and attack tools. You do not need to keep
track of all available hacking tools if you know where you can find them when you
need them. However, now that computer crime has gone professional, all tools
might not be available to the good guys anymore. Securing assets is becoming more
challenging, as white-hat hacking is becoming more difficult.
1.1.2
Disclosure Processes
There are hundreds of software flaws just waiting to be found, and given enough
time they will be found. It is just a matter of who finds them and what they do with
the findings. In the worst case, each found security issue could result in a “patch
and penetrate” race: A malicious user tries to infiltrate the security of the services
before the administrators can close the gaping holes, or a security researcher keeps
reporting issues to a product vendor one by one over the course of many months or
years, forcing the vendor to undergo a resource-intensive patch testing, potential
recertification, and worldwide rollout process for each new reported issue.
1.1
Software Security
5
Three different models are commonly used in vulnerability disclosure processes:
1. No disclosure: No details of the vulnerability, nor even the existence of the
vulnerability, are disclosed publicly. This is often the case when vulnerabil-
ities are found internally, and they can be fixed with adequate time and
prioritization. The same can also happen if the disclosing organization is a
trusted customer or a security expert who is not interested in gaining fame
for the findings. People who do not like the no-disclosure model often
argue that it is difficult for the end users to prioritize the deployment of
updates if they do not know whether they are security-related and that
companies may not bother to fix even critical issues quickly unless there is
direct pressure from customers to do so.
2. Partial disclosure: This is the most common means of disclosure in the
industry. The vendor can disclose the nature of the correction and even a
workaround when a proper correction is not yet available. The problem
with partial disclosure is that hackers can reverse-engineer the corrections
even when limited information is given. Most partial disclosures end up
becoming fully known by those who are interested in the details and have
the expertise to understand them.
3. Full disclosure: All details of the vulnerability, including possible exploita-
tion techniques, are disclosed publicly. In this model, each reader with
enough skill can analyze the problem and prioritize it accordingly. Some-
times users decide to deploy the vendor-provided patches, but they can also
build other means of protecting against attacks targeting the vulnerability,
including deploying IDS/IPS systems or firewalls.
From an end-user perspective, there are several worrying questions: Will an
update from the vendor appear on time, before attackers start exploiting a reported
vulnerability? Can we deploy that update immediately when it becomes available?
Will the update break some other functionality? What is the total cost of the repair
process for our organization?
As a person conducting fuzzing, you may discover a lot of critical vulnerabili-
ties that can affect both vendors and end users. You may want to consider the con-
sequences before deciding what to do with the vulnerabilities you find. Before
blowing the whistle, we suggest you familiarize yourself with the works done on
vulnerability disclosure at Oulu University Secure Programming Group (OUSPG).4
1.1.3
Attack Surfaces and Attack Vectors
Now that we have explained how software vulnerabilities affect us and how they