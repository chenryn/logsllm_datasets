other streaming-oriented approaches [49, 88, 115] are either
domain speciﬁc (e.g., bibliographic networks have a different
structure than provenance graphs) or applicable primarily to
homogeneous graphs.
In the realm of malware classiﬁcation and intrusion detec-
tion, Classy [72] clusters streams of call graphs to facilitate
malware analysis based on graph edit distance (GED) [41]
of pairs of graphs using a modiﬁed version of simulated
annealing. Although its runtime complexity is suitable for
graph streams, the empirical evaluation was limited to graphs
with no more than 3,000 vertices; real system execution yields
graphs orders of magnitude larger [101].
StreamSpot
[83] analyzes streaming information ﬂow
graphs to detect anomalous activity. However, StreamSpot’s
graph features are locally constrained while UNICORN’s em-
body execution context. We show in § VI that contextualized
graph analysis has great impact on detection performance.
Furthermore, StreamSpot models only a single snapshot of
every training graph, dynamically maintaining its clusters
during test time. However, it results in a signiﬁcant number
of false alarms, which creates an opportune time window for
the attacker. We also consider such an approach inappropriate
in APT scenarios, where persistent attackers can manipulate
the model to gradually and slowly change system behavior to
avoid detection. UNICORN takes full advantage of its ability
to continuously summarize the evolving graph, modeling the
corresponding evolution of the system execution it monitors.
FRAPpuccino [53] is another attempt at graph-based intrusion
detection. It uses a windowing approach to allow for efﬁcient
graph analysis. Naturally, segmenting provenance graphs in
this way produces a more limited view of system execution,
unsuitable for long-term detection that spans windows.
Provenance-based Security Analysis A variety of security-
related applications leverage provenance, mostly notably for
forensic analysis and attack attribution [8]. BackTracker [69]
analyzes intrusions using a provenance graph to identify the
entry point of the intrusion, while PriorTracker [79] optimizes
this process and enables a forward tracking capability for
timely attack causality analysis. HERCULE [102] analyzes
intrusions by discovering attack communities embedded within
provenance graphs. Winnower [56] expedites system intrusion
investigation through grammatical inference over provenance
graphs, and simultaneously reduces storage and network over-
head without compromising the quality of provenance data.
NoDoze [55] performs attack triage within provenance graphs
to identify anomalous paths. Bates et al. [16] were the ﬁrst to
use provenance for data loss prevention, and Park et al. [99]
formalized the notion of provenance-based access control
(PBAC). Ma et al. [80] designed a lightweight provenance
tracing system ProTracer to mitigate the dependence explosion
problem and reduce space and runtime overhead, facilitating
practical provenance-based attack investigation. Pasquier et
al. [101] introduced a generic framework, called CamQuery,
that enables inline, realtime provenance analysis, demonstrat-
ing great potential for future provenance-based security appli-
cations.
Recently, as APT attacks become increasingly prominent,
a number of systems leverage data provenance for APT attack
analysis. Holmes [87] and Sleuth [58] focus primarily on attack
reconstruction using information ﬂow provided by data prove-
nance. Their approach is similar to an architecture proposed
by Tariq et al. [118] that correlates anomalous activity in grid
applications using data provenance. The anomaly detection
module itself uses a simple, pre-deﬁned model that relies on
expert knowledge of the existing APT kill-chain to match
an a priori speciﬁcation of possible exploits to localized
components in the graph. Poirot [86] produces another form of
attack reconstruction. It correlates a collection of compromise
indicators (found by other systems) to identify APTs. Relying
on expert knowledge from existing cyber threat intelligence
reports and compromise descriptions to construct attack query
graphs, Poirot performs ofﬂine graph pattern matching on
provenance graphs to uncover potential APTs. For example, it
uses the red team’s attack descriptions to manually craft query
graphs to correlate anomalies in the DARPA datasets used in
§ VI-B. This is a critical limitation given that composing a
sufﬁciently detailed description of a new class of APT takes
signiﬁcant forensic effort [15].
UNICORN differs from these rule-based systems in that
it is an anomaly-based system that requires no prior expert
knowledge of APT attack patterns and behaviors. Although
rule-based approaches are closely aligned with commercial
practices today (i.e.,
they are essentially provenance-based
versions of the Endpoint Detection and Response (EDR) tools
offered by enterprise security vendors), prior research shows
that rule-based EDR systems are the chief contributor to the
“threat fatigue problem” [2]. Recent work on provenance
analysis (e.g., NoDoze [55]) demonstrated that historical con-
text is crucial for mitigating this problem; UNICORN instead
investigates how to incorporate context as a ﬁrst class citizen
in HID systems, rather than as a secondary triage tool.
Gao et al. [40] leveraged complex event processing plat-
forms and designed a domain-speciﬁc query language, SAQL
to analyze large-scale, streaming provenance data. The system
combines various anomaly models (e.g., rule-based anomalies)
and aggregates data streams across multiple hosts, but
it
ultimately requires expert domain knowledge to identify ele-
ments/patterns to match against queries. We also note that our
provenance graph analyses are able to incorporate implicitly
(without domain knowledge) most of their anomaly models
(e.g., invariant-based, time-series, and outlier-based). Barre et
al. [15] mine data provenance to detect anomalies. The goal
of their work is mainly to identify important process features
that are likely to be relevant to APT attacks (e.g., a process’
lifetime and path information). Using a random forest model
with hand-picked process features,
their system delivers a
detection rate of only around 50%. Such low performance
suggests that simple feature engineering on provenance graphs
without considering graph topology is insufﬁcient in detecting
stealthy APT attacks. Berrada et al. [19] proposes score ag-
gregation techniques to combine anomaly scores from different
anomaly detectors to improve detection performance. Although
their work targets provenance graphs for APT detection, it
is orthogonal to UNICORN (or any other detectors) in that it
functions only as an aggregator for existing anomaly detection
systems.
IX. CONCLUSION
We present UNICORN, a realtime anomaly detection sys-
tem that leverages whole-system data provenance to detect
14
advanced persistent threats that are deemed difﬁcult for tra-
ditional detection systems. UNICORN models system behavior
via structured provenance graphs that expose causality relation-
ships between system objects, taking into account the entirety
of the graph by efﬁciently summarizing it as it streams into its
analytic pipeline. Our evaluation shows that the resulting evo-
lutionary models can successfully detect various APT attacks
captured from different audit systems, including real-life APT
campaigns, with high accuracy and low false alarm rates.
ACKNOWLEDGEMENT
We thank Dr. Robert N. W. Watson and his team at the Uni-
versity of Cambridge on the DARPA Transparent Computing
Program. We also thank the anonymous reviewers and our
shepherd Prof. Brendan Saltaformaggio who helped improve
the paper. We acknowledge the support of the Natural Sciences
and Engineering Research Council of Canada (NSERC). Cette
recherche a ´et´e ﬁnanc´ee par le Conseil de recherches en
sciences naturelles et en g´enie du Canada (CRSNG). This
research was supported by the US National Science Foundation
under grants NSF 14-50277, 16-57534, and 17-50024. This
research was also supported with promotional credits from
the AWS Cloud Credits for Research program. The views,
opinions, and/or ﬁndings contained in this paper are those of
the authors and should not be interpreted as representing the
ofﬁcial views or policies, either expressed or implied, of the
Department of Defense or the U.S. Government.
REFERENCES
[1] “Causal, Adaptive, Distributed,
and Efﬁcient Tracing System
(CADETS),” Accessed 21st January 2020, https://www.cl.cam.ac.uk/
research/security/cadets/.
[2] “How Many Alerts
Too Many
2020,
to Handle?” Ac-
https://www2.ﬁreeye.com/
cessed
StopTheNoise-IDC-Numbers-Game-Special-Report.html.
21st
is
January
[3] “Transparent Computing,” Accessed 21st January 2020, https://people.
[4] “University of New Mexico System Call Dataset,” accessed 21st Jan-
csail.mit.edu/rinard/research/ComputerSecurity/.
uary 2020, https://www.cs.unm.edu/∼immsec/systemcalls.html.
[5] C. C. Aggarwal and P. S. Yu, “On classiﬁcation of high-cardinality data
streams,” in International Conference on Data Mining. SIAM, 2010,
pp. 802–813.
[6] C. C. Aggarwal, Y. Zhao, and S. Y. Philip, “Outlier detection in graph
streams,” in International Conference on Data Engineering (ICDE).
IEEE, 2011.
[7] K. J. Ahn, S. Guha, and A. McGregor, “Graph sketches: sparsiﬁcation,
spanners, and subgraphs,” in Proceedings of the 31st ACM SIGMOD-
SIGACT-SIGAI symposium on Principles of Database Systems. ACM,
2012, pp. 5–14.
[8] L. Akoglu, H. Tong, and D. Koutra, “Graph based anomaly detection
and description: a survey,” Data mining and knowledge discovery,
vol. 29, no. 3, pp. 626–688, 2015.
[9] A. Alshamrani, S. Myneni, A. Chowdhary, and D. Huang, “A survey
on advanced persistent threats: Techniques, solutions, challenges, and
research opportunities,” IEEE Communications Surveys & Tutorials,
vol. 21, no. 2, pp. 1851–1877, 2019.
[10] J. P. Anderson, “Computer Security Technology Planning Study,” Air
Force Electronic Systems Division, Tech. Rep. ESD-TR-73-51, 1972.
[11] J. Ansel, S. Kamil, K. Veeramachaneni, J. Ragan-Kelley, J. Bosboom,
U.-M. O’Reilly, and S. Amarasinghe, “Opentuner: An extensible frame-
work for program autotuning,” in Proceedings of the 23rd international
conference on Parallel architectures and compilation. ACM, 2014, pp.
303–316.
[12] Y. Bachrach, E. Porat, and J. S. Rosenschein, “Sketching techniques
for collaborative ﬁltering.” in IJCAI, 2009, pp. 2016–2021.
[13] L. D. Baker and A. K. McCallum, “Distributional clustering of words
for text classiﬁcation,” in Conference on Research and Development in
Information Retrieval. ACM, 1998, pp. 96–103.
15
[14] M. Baquiran
and D. Wren,
-
Performance Testing,” PassMark Software, Tech. Rep., 2017,
https://www.symantec.com/content/dam/symantec/docs/reviews/
endpoint-protection-2017-performance-testing-enterprise-Win10.pdf.
“Endpoint Protection
2017
[15] M. Barre, A. Gehani, and V. Yegneswaran, “Mining data provenance
to detect advanced persistent threats,” in 11th International Workshop
on Theory and Practice of Provenance (TaPP), 2019.
[16] A. M. Bates, D. Tian, K. R. Butler, and T. Moyer, “Trustworthy
whole-system provenance for the linux kernel.” in USENIX Security
Symposium, 2015, pp. 319–334.
[17] M. Berlingerio, D. Koutra, T. Eliassi-Rad, and C. Faloutsos, “Netsimile:
A scalable approach to size-independent network similarity,” arXiv
preprint arXiv:1209.2684, 2012.
[18] D. Bernstein, “Containers and cloud: From lxc to docker to kubernetes,”
IEEE Cloud Computing, no. 3, pp. 81–84, 2014.
[19] G. Berrada and J. Cheney, “Aggregating unsupervised provenance
anomaly detectors,” in 11th International Workshop on Theory and
Practice of Provenance (TaPP), 2019.
[20] L. Bilge and T. Dumitras, “Before we knew it: an empirical study of
zero-day attacks in the real world,” in Conference on Computer and
Communications Security. ACM, 2012, pp. 833–844.
[21] L. Carata, S. Akoush, N. Balakrishnan, T. Bytheway, R. Sohan,
M. Seltzer, and A. Hopper, “A primer on provenance,” ACM Queue,
vol. 12, no. 3, p. 10, 2014.
[22] E. P. I. Center, “Equifax Data Breach,” available at https://www.epic.
org/privacy/data-breach/equifax/.
[23] V. Chandola, A. Banerjee, and V. Kumar, “Anomaly detection: A
survey,” ACM computing surveys (CSUR), vol. 41, no. 3, p. 15, 2009.
[24] O. Chapelle, P. Haffner, and V. N. Vapnik, “Support vector machines
for histogram-based image classiﬁcation,” IEEE transactions on Neural
Networks, vol. 10, no. 5, pp. 1055–1064, 1999.
[25] M. S. Charikar, “Similarity estimation techniques from rounding algo-
rithms,” in Proceedings of the thiry-fourth annual ACM symposium on
Theory of computing. ACM, 2002, pp. 380–388.
[26] Q. Chen, R. Luley, Q. Wu, M. Bishop, R. W. Linderman, and Q. Qiu,
“Anrad: A neuromorphic anomaly detection framework for massive
concurrent data streams,” IEEE transactions on neural networks and
learning systems, vol. 29, no. 5, pp. 1622–1636, 2018.
[27] O. Chum, J. Philbin, A. Zisserman et al., “Near duplicate image
detection: min-hash and tf-idf weighting.” in BMVC, vol. 810, 2008,
pp. 812–815.
[28] G. Creech and J. Hu, “Generation of a new ids test dataset: Time
to retire the kdd collection,” in IEEE Wireless Communications and
Networking Conference (WCNC).
IEEE, 2013, pp. 4487–4492.
[29] H. Debar, M. Dacier, M. Nassehi, and A. Wespi, “Fixed vs. variable-
length patterns for detecting suspicious process behavior,” in European
Symposium on Research in Computer Security.
Springer, 1998, pp.
1–15.
[30] Q. Ding, N. Katenka, P. Barford, E. Kolaczyk, and M. Crovella, “Intru-
sion as (anti) social communication: characterization and detection,” in
International Conference on Knowledge Discovery and Data Mining.
ACM, 2012, pp. 886–894.
[31] C. Doersch, “Tutorial on variational autoencoders,” arXiv preprint
arXiv:1606.05908, 2016.
[32] J. Drew, T. Moore, and M. Hahsler, “Polymorphic malware detection
using sequence classiﬁcation methods,” in Security and Privacy Work-
shops (SPW).
IEEE, 2016, pp. 81–87.
[33] J. Fairbanks, D. Ediger, R. McColl, D. A. Bader, and E. Gilbert, “A
statistical framework for streaming graph analysis,” in Proceedings of
the International Conference on Advances in Social Networks Analysis
and Mining. ACM, 2013, pp. 341–347.
[34] U. M. Fayyad, G. Piatetsky-Shapiro, P. Smyth, and R. Uthurusamy,
“Advances in knowledge discovery and data mining,” 1996.
[35] M. Fazzini, “Tagging and Tracking of Multi-level Host Events for
Transparent Computing,” Accessed 21st January 2020, https://smartech.
gatech.edu/handle/1853/56510.
[36] H. H. Feng, O. M. Kolesnikov, P. Fogla, W. Lee, and W. Gong,
“Anomaly detection using call stack information,” in Symposium on
Security and Privacy.
IEEE, 2003, pp. 62–75.
[37] S. Forrest, S. A. Hofmeyr, A. Somayaji, and T. A. Longstaff, “A sense
of self for unix processes,” in Symposium on Security and Privacy.
IEEE, 1996, pp. 120–128.
[38] J. H. Friedman, “On bias, variance,
loss, and the curse-of-
dimensionality,” Data mining and knowledge discovery, vol. 1, no. 1,
pp. 55–77, 1997.
[39] J. Gao, F. Liang, W. Fan, C. Wang, Y. Sun, and J. Han, “On community
outliers and their efﬁcient detection in information networks,” in
International Conference on Knowledge Discovery and Data Mining.
ACM, 2010, pp. 813–822.
[40] P. Gao, X. Xiao, D. Li, Z. Li, K. Jee, Z. Wu, C. H. Kim, S. R.
Kulkarni, and P. Mittal, “Saql: A stream-based query system for real-
time abnormal system behavior detection,” in 27th USENIX Security
Symposium (USENIX Security 18), 2018, pp. 639–656.
[41] X. Gao, B. Xiao, D. Tao, and X. Li, “A survey of graph edit distance,”
Pattern Analysis and applications, vol. 13, no. 1, pp. 113–129, 2010.
[42] M. R. Garey, “A guide to the theory of np-completeness,” Computers
and intractability, 1979.
[43] T. Garﬁnkel et al., “Traps and pitfalls: Practical problems in system call
interposition based security tools.” in NDSS, vol. 3, 2003, pp. 163–176.
[44] A. Gehani and D. Tariq, “Spade: support for provenance auditing
ACM/I-
in distributed environments,” in Middleware Conference.
FIP/USENIX, 2012, pp. 101–120.
[45] L. Georget, M. Jaume, F. Tronel, G. Piolle, and V. V. T. Tong, “Veri-
fying the reliability of operating system-level information ﬂow control
systems in linux,” in International Workshop on Formal Methods in
Software Engineering.
IEEE/ACM, 2017, pp. 10–16.
[46] I. Goldberg, D. Wagner, R. Thomas, E. A. Brewer et al., “A secure
environment for untrusted helper applications: Conﬁning the wily
hacker,” in USENIX Security Symposium, vol. 6, 1996, pp. 1–1.
[47] D. Golunski, “Gnu wget 1.18 - arbitrary ﬁle upload / remote code
execution,” 2016, https://www.exploit-db.com/exploits/40064/.
[48] A. GReAT, “Operation shadowhammer,” 2019, https://securelist.com/
operation-shadowhammer/89992/.
[49] M. Gupta, C. C. Aggarwal, J. Han, and Y. Sun, “Evolutionary clustering
and analysis of bibliographic networks,” in Conference on Advances in
Social Networks Analysis and Mining.
IEEE, 2011, pp. 63–70.
[50] W. Haider, G. Creech, Y. Xie, and J. Hu, “Windows based data sets for
evaluation of robustness of host based intrusion detection systems (ids)
to zero-day and stealth attacks,” Future Internet, vol. 8, no. 3, p. 29,
2016.
[51] W. Haider, J. Hu, J. Slay, B. P. Turnbull, and Y. Xie, “Generating
realistic intrusion detection system dataset based on fuzzy qualitative
modeling,” Journal of Network and Computer Applications, vol. 87,
pp. 185–192, 2017.
[52] W. Hamilton, Z. Ying, and J. Leskovec, “Inductive representation learn-
ing on large graphs,” in Advances in Neural Information Processing
Systems, 2017, pp. 1024–1034.
[53] X. Han, T. Pasquier, T. Ranjan, M. Goldstein, and M. Seltzer, “Frap-
puccino: fault-detection through runtime analysis of provenance,” in
Workshop on Hot Topics in Cloud Computing (HotCloud’17). USENIX
Association, 2017.
[54] D. J. Hand, “Principles of data mining,” Drug safety, vol. 30, no. 7,
pp. 621–622, 2007.
[55] W. U. Hassan, S. Guo, D. Li, Z. Chen, K. Jee, Z. Li, and A. Bates,
“Nodoze: Combatting threat alert fatigue with automated provenance
triage.” in NDSS, 2019.
[56] W. U. Hassan, M. Lemay, N. Aguse, A. Bates, and T. Moyer, “Towards
scalable cluster auditing through grammatical inference over prove-
nance graphs,” in Network and Distributed System Security Symposium,
NDSS, 2018.
[57] M. A. Hearst, S. T. Dumais, E. Osuna, J. Platt, and B. Scholkopf, “Sup-
port vector machines,” IEEE Intelligent Systems and their applications,
vol. 13, no. 4, pp. 18–28, 1998.
[58] M. N. Hossain, S. M. Milajerdi, J. Wang, B. Eshete, R. Gjomemo,
R. Sekar, S. D. Stoller, and V. Venkatakrishnan, “Sleuth: Real-time at-
tack scenario reconstruction from cots audit data,” in USENIX Security
Symposium, 2017, pp. 487–504.
[59] P. Indyk and R. Motwani, “Approximate nearest neighbors: towards
removing the curse of dimensionality,” in Symposium on Theory of
Computing. ACM, 1998, pp. 604–613.
[60] B. Jacob, P. Larson, B. Leitao, and S. Da Silva, “Systemtap: instru-
menting the linux kernel for analyzing performance and functional
problems,” IBM Redbook, vol. 116, 2008.
[61] T. Jaeger, A. Edwards, and X. Zhang, “Consistency analysis of au-
thorization hook placement in the linux security modules framework,”
ACM Transactions on Information and System Security (TISSEC),
vol. 7, no. 2, pp. 175–205, 2004.
[62] J. H. Jafarian, A. Abbasi, and S. S. Sheikhabadi, “A gray-box dpda-
based intrusion detection technique using system-call monitoring,” in
Annual Collaboration, Electronic messaging, Anti-Abuse and Spam
Conference. ACM, 2011, pp. 1–12.
[63] K. Jain and R. Sekar, “User-level infrastructure for system call interpo-
sition: A platform for intrusion detection and conﬁnement.” in NDSS,
2000.
[64] J. Ji, J. Li, S. Yan, Q. Tian, and B. Zhang, “Min-max hash for jaccard
IEEE, 2013,
similarity,” in International Conference on Data Mining.
pp. 301–309.
[65] L. Kaufman and P. J. Rousseeuw, Finding groups in data: an introduc-
tion to cluster analysis.
John Wiley & Sons, 2009, vol. 344.
[66] A. D. Keromytis, “Transparent computing engagement 3 data re-