title:Reactive noninterference
author:Aaron Bohannon and
Benjamin C. Pierce and
Vilhelm Sj&quot;oberg and
Stephanie Weirich and
Steve Zdancewic
Reactive Noninterference
Aaron Bohannon
University of Pennsylvania
Benjamin C. Pierce
University of Pennsylvania
Vilhelm Sjöberg
University of Pennsylvania
Stephanie Weirich
University of Pennsylvania
Steve Zdancewic
University of Pennsylvania
ABSTRACT
Many programs operate reactively—patiently waiting for
user input, running for a while producing output, and even-
tually returning to a state where they are ready to accept
another input (or occasionally diverging). When a reactive
program communicates with multiple parties, we would like
to be sure that it can be given secret information by one
without leaking it to others.
Motivated by web browsers and client-side web applica-
tions, we explore deﬁnitions of noninterference for reactive
programs and identify two of special interest—one corre-
sponding to termination-insensitive noninterference for a sim-
ple sequential language, the other to termination-sensitive
noninterference. We focus on the former and develop a proof
technique for showing that program behaviors are secure ac-
cording to this deﬁnition. To demonstrate the viability of
the approach, we deﬁne a simple reactive language with an
information-ﬂow type system and apply our proof technique
to show that well-typed programs are secure.
Categories and Subject Descriptors
F.1.2 [Modes of Computation]: Interactive and reactive
computation
General Terms
Languages, Security, Theory
Keywords
Noninterference,
web browsers, web applications
information ﬂow, reactive programming,
INTRODUCTION
1.
Reactive programs, which repeatedly perform single-
threaded computations in response to events generated by
external agents (GUI button clicks, commands issued at a
terminal, receipt of network packets, timer events, etc.), are
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’09, November 9–13, 2009, Chicago, Illinois, USA.
Copyright 2009 ACM 978-1-60558-352-5/09/11 ...$10.00.
ubiquitous. When a single reactive program may interact
with multiple agents, questions of security and privacy im-
mediately arise.
Web browsers and the client-side web applications they
run are an obvious case in point, because they interact with
both a local user and mutually untrusting, remote agents
(e.g., web servers). Web client security has attracted sig-
niﬁcant interest [18, 15, 10, 11]. However, we still lack the
theoretical tools to answer the question “What does it mean
for a browser, running a web application, to be secure?”
A web client may receive data and programs from many
diﬀerent servers, and each program may attempt to read
any browser data and communicate with any remote server.
Most browsers adhere to the “same-origin policy” [20], which
is intended to enforce isolation among programs and data
from diﬀerent servers. However, the same-origin policy is
a policy in name only: in fact, it is a set of rather complex
and subtle rules, with no high-level statement of the security
property they are intended jointly to enforce. Moreover, it
has several practical problems: First, it prevents the client
from calling useful third-party web services. Second, it pre-
vents client-side data integration or collaborative behavior,
even when the data being handled is guaranteed never to
leave the user’s machine. Third, its rules involving subdo-
main relationships are complex and ambiguous [11]. And
ﬁnally, because of its rigid restrictions, the same-origin pol-
icy is not applied to browser extensions or plug-ins.
Our goal in this paper is to oﬀer a more principled ap-
proach to the sort of attack scenario that is addressed by
the same-origin policy and to lay a foundation for more ﬂex-
ible enforcement mechanisms. In this scenario, the attacker
is positioned at a remote host and can only communicate
with the user’s client over HTTP. However, the attacker may
have written some or all of the event handlers running on
the client. The goal of the attacker is to retrieve some pri-
vate piece of information that the user would not knowingly
authorize the attacker to have.1
When compared with models of execution that have been
previously studied in the information ﬂow literature, reac-
tive programs possess a novel combination of features:
in-
teractivity with buﬀered, asynchronous communication; in-
cremental output; the requirement that the system respond
in some way to arbitrary inputs; and the possibility of non-
termination in handlers. Web client programs illustrate all
1The same-origin policy also addresses scenarios in which
the attacker wants to corrupt data from other web servers
or to interfere with the functionality of other web pages in
the browser; we are focusing only on conﬁdentiality here.
79of these features. They have handlers that wait idly for user
input or responses to HTTP requests. After an event has
occurred, the appropriate event handler runs from start to
completion, possibly sending one or more messages to re-
mote hosts or to the user. (To streamline the model, we can
consider all updates to the browser display as “messages” to
the user.) Outgoing messages are sent as execution proceeds,
so a script need not terminate to produce visible output.
When the browser is idle, any event can be processed (this
feature has been called input-totality [14, 4, 22]), although
it will typically result in a no-op if no handler exists. How-
ever, when the browser is running a script, additional events
cannot be immediately processed because there is no notion
of preemptive multitasking. Instead, additional events must
be buﬀered and processed when and if the current script
terminates.
Our aim is to ﬁnd a natural deﬁnition of information-ﬂow
security for this execution model and to design a language-
based enforcement technique for reactive programming lan-
guages that execute under this model. Before coming to the
details of our development, though, we brieﬂy summarize its
connections to the most closely related prior work.
Goguen and Meseguer [5, 6] gave one of the ﬁrst formal
accounts of noninterference, and they did so in a setting of
machines that accept inputs and produce outputs. Their
“MLS property” [6]—informally, “the low-visible outputs of
a system remain unchanged after dropping the high-level
inputs”—oﬀers an attractive template for the sort of suc-
cinct, high-level speciﬁcation we are looking for here. How-
ever, their model does not apply to nonterminating behav-
iors (they rely on a total function that immediately moves
the system to a new state after each input); adapting the
same intuition to our model involves an entirely new math-
ematical development.
By contrast, some information-ﬂow research [4, 22] has
addressed execution models of concurrent systems with in-
put and output that are somewhat more general than our
reactive model. In stating the security properties for these
systems, the observable behaviors of a system are usually
characterized by a set of traces, each trace being a ﬁnite
preﬁx of some, possibly inﬁnite, sequence of transitions that
might occur. This is a convenient tool for handling nonde-
terministic behavior, and it naturally encompasses nonter-
minating behavior as well. However, sets of traces are too
abstract to capture some distinctions that we would like to
make:
in the standard trace representation, a system with
the sole behavior of repeatedly outputting a single message
forever is represented by the same set of traces as a sys-
tem that repeatedly outputs that message until it nondeter-
ministically decides to halt. We address this issue by using
streams rather than sets of traces to represent inﬁnite be-
haviors, leading to a notion of security that is fundamentally
not expressible as a “security property” in the sense of Za-
kinthinos and Lee [22].
Besides articulating a natural information-ﬂow property
for reactive systems, we want to be able to enforce it using
a security type system. There is a large body of research
on such type systems (see Sabelfeld and Myers [19] for an
overview).
In particular, Volpano, Smith, and Irvine [21]
develop a basic information-ﬂow type system for sequen-
tial while-programs and prove that it guarantees a high-
level noninterference property. Notably, their noninterfer-
ence property is termination-insensitive, which means that
a program may diverge on some high inputs and terminate
on others. Since this allows the possibility of a covert termi-
nation channel in a program, it is technically less secure than
a termination-sensitive property, but it is more practical for
language-based enforcement because ruling out these termi-
nation channels either requires the elimination of too many
useful, secure programs, or else requires the use of static
termination checking. Thus, a question of particular inter-
est to us is whether there exists a termination-insensitive
deﬁnition of security for reactive systems.
While most work on language-based security has ignored
the issue of incremental inputs and outputs, it has been ad-
dressed by some recent work on “interactive programs” [16,
9, 2]. In contrast with our execution model, the execution
model of these interactive programs is based on synchronous
communication that is not input-total: the languages have
explicit input operations that block, waiting for designated
principals to respond. In stating its security properties, this
line of work must tackle some of the same issues that we
do; for instance, Hunt and Sands [9] make use of inﬁnite
streams. However, all of their deﬁnitions are termination-
sensitive, and in order to pursue a termination-insensitive
notion of noninterference, we have found it necessary to set
up a more general framework for deﬁning information secu-
rity in the presence of inputs and outputs.
We oﬀer the following contributions. First, we deﬁne an
abstract model of execution that is applicable to web client
behavior (and any form of reactive computation that does
not rely on preemptive multitasking). Second, by appealing
to a stream-based semantics of these abstract systems, we
give a generic deﬁnition of security for our execution model
that is high-level in the manner of Goguen and Meseguer’s
MLS property; then we show that this generic deﬁnition has
speciﬁc instantiations corresponding to both termination-
sensitive and to termination-insensitive deﬁnitions of non-
interference. Third, we oﬀer an “unwinding lemma” [6] for
our termination-insensitive version of security, which gives
rise to a lower-level, transition-based deﬁnition of security.
Finally, we use this unwinding lemma to demonstrate how
a security type system can be used to enforce security in a
simple language with a reactive semantics.
2. REACTIVE COMPUTATION
We use a constrained labeled transition system with input
and output actions to capture our execution model. Al-
though it bears similarity to labeled transition systems in
the information-ﬂow literature [14, 7, 4], the constraints are
notably diﬀerent.
2.1 Deﬁnition: A reactive system is a tuple
(ConsumerState , ProducerState , Input, Output ,→)
where → is a labeled transition system whose states are
State = ConsumerState ∪ ProducerState and whose labels
are Act = Input ∪ Output , subject to the following con-
straints:
• for all C ∈ ConsumerState , if C a→ Q, then a ∈ Input
and Q ∈ ProducerState ,
• for all P ∈ ProducerState , if P a→ Q, then a ∈ Output ,
• for all C ∈ ConsumerState and i ∈ Input , there exists
a P ∈ ProducerState such that C i→ P , and
80• for all P ∈ ProducerState , there exists an o ∈ Output
and Q ∈ State such that P o→ Q.
2.2 Deﬁnition: Coinductively deﬁne Q(I) ⇒ O (Q trans-
lates the input stream I to the output stream O) with the
following rules:
In words, a reactive system is one that takes the next avail-
able input, produces one or more outputs in response, and
repeats the process.
Of course, a reactive system is inert unless it exists in an
environment that can supply and receive messages. We may
view an environment as comprising multiple agents commu-
nicating with the system over diﬀerent channels by assuming
that all inputs i and outputs o are tagged with some channel
name c. In this scenario, the environment performs the ser-
vice of multiplexing multiple streams of messages into a sin-
gle, buﬀered stream. In modeling a web application, channel
names for inputs would be used to represent both the ad-
dresses of remote servers (e.g., domain names) and unique
references to the input controls available to the user of the
web client; channel names for outputs would be used to
model server addresses and references to updateable browser
display components.
It is useful to make a few more observations about how
our formal deﬁnition relates to the real systems we are try-
ing to model. First, the deﬁnition implies that the system
can always make some kind of progress unless it is block-
ing on input, but we note that this does not mean that it
must always return to an input-accepting state: it can get
into a loop producing outputs forever and never try to con-
sume another input. Second, the deﬁnition requires every
small step to produce an output. This is a technical device
that does have any practical implications in our particular
setting because, when we talk about security, we will as-
sume that diﬀerent outputs (and inputs) may be invisible
to diﬀerent observers, so we can easily model the act of a
machine taking a silent, internal step using a system tran-
sition whose requisite output is invisible to all observers.
This assumption conveniently allows us to assume, in our
theoretical development, that all programs that diverge are
continuously producing output, instead of having to make
a special case for programs that diverge silently. We also
force the system to go to a producer state after every input.
Similarly, this does no harm in a setting where the system
can simply produce a single invisible output in response to
an input; however, it is a technical device that greatly sim-
pliﬁes our proofs because it entails that an inﬁnite stream
of inputs will always generate an inﬁnite stream of outputs.
Now that we have a machine-like notion of reactive sys-
tems, we need a higher-level representation of their behavior
to achieve a high-level deﬁnition of security. As mentioned
earlier, we choose a stream-based interpretation instead of a
trace-based interpretation. Formally, we deﬁne a stream as
the coinductive2 interpretation of the grammar
S ::= [] | s :: S
where s ranges over stream elements. That is, a stream is
a ﬁnite or inﬁnite list of elements. We use metavariables
I and O to range over streams of inputs i and outputs o,
respectively. Now we can view the behavior of a reactive
system in a state Q as a relation between input streams and
output streams.
2See Appendix A for technical background on this way of
presenting coinductive deﬁnitions.
C([]) ⇒ []
C i→ P
P (I) ⇒ O
C(i :: I) ⇒ O
P o→ Q
Q(I) ⇒ O
P (I) ⇒ o :: O
We observe that this deﬁnition associates at least one output
stream with every input stream, given the constraints on our
transition systems.
In order to illustrate how a reactive system might be pro-
grammed, we now introduce the syntax of the simple lan-
guage RIMP—a reactive version of the IMP language of ba-
sic while-programs. The full semantics are given in Sec-
tion 5; here we rely on an intuitive explanation of RIMP’s
operational model.
Input messages in RIMP are natural
numbers tagged with their channels, where we let n range
over the set of natural numbers, and ch range over a set of
channels. Outputs are either a natural number sent over a
channel or a “tick” (which will be the default output on an
internal step).