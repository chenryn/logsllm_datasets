### Introduction
Our research builds upon previous findings that indicate a higher frequency of bug introductions on Fridays. However, our work extends these results in several significant ways. We conduct a more extensive statistical analysis on a much larger dataset, which serves as the foundation for our system. Based on the results, we train a Support Vector Machine (SVM) and develop an adaptable system to predict vulnerability-inducing commits.

### Key Contributions
Our approach goes beyond existing methods in several respects:
1. **Comprehensive Analysis**: We perform a more extensive statistical analysis on a larger dataset.
2. **Feature Integration**: We combine both code metrics and metadata in our analysis.
3. **Machine Learning Approach**: We use machine learning to extract and combine relevant features, and to create a classification engine that predicts which commits are more likely to be vulnerable.
4. **Scalability**: Unlike previous studies that focused on single projects, our method is automated and can be applied to a large set of projects.

### Related Work
Several authors have proposed machine learning and data mining techniques for identifying vulnerabilities. For example:
- Scandariato et al. [31] trained a classifier on textual features extracted from source code to determine vulnerable software components.
- Yamaguchi et al. [36] introduced a method to expose missing checks in C source code by combining static tainting and anomaly detection techniques.
- Chang et al. [13] presented a data mining approach to reveal neglected conditions and discover implicit conditional rules and their violations.

However, these approaches focus solely on features extracted from source code. In contrast, we demonstrate that additional metadata, such as developer experience, can significantly improve detection performance.

### Methodology

#### 3.1 Vulnerability-Contributing Commits
To analyze the common features of commits that introduce vulnerabilities, we first needed to identify which commits actually introduced these vulnerabilities. To the best of our knowledge, no large-scale database exists that maps vulnerabilities reported by Common Vulnerabilities and Exposures (CVEs) to specific commits. Previous works by Meneely et al. and Shin et al. [25, 23, 24] manually created such mappings for specific projects like Mozilla Firefox, Apache HTTP Server, and parts of the RHEL Linux kernel. Unfortunately, this data was not available for our use at the time.

To address this, we developed a method to automatically map CVEs to vulnerability-contributing commits (VCCs). Our approach involved two data sources:
1. **CVE Links**: We selected all CVEs containing a link to a commit fixing a vulnerability.
2. **Commit Messages**: We created a crawler to search commit messages of the 66 projects for mentions of CVE IDs.

We manually checked a random sample of 10% of the mapped CVEs and found no incorrectly mapped entries. This process resulted in a list of 718 CVEs, which, while potentially incomplete, provided a sufficiently large sample for training our classifier.

Next, we developed a heuristic to identify the VCCs from the fixing commits:
1. **Ignore Documentation Changes**: Exclude changes in documentation such as release notes or change logs.
2. **Blame Deleted Lines**: For each deletion, blame the line that was deleted.
3. **Blame Inserted Blocks**: For every continuous block of code inserted in the fixing commit, blame the lines before and after the block.
4. **Mark Most Blamed Commit**: Finally, mark the commit blamed most in the steps above. If two commits were blamed equally, mark both.

Our heuristic mapped 718 CVEs to 640 VCCs. A 15% random sample of the flagged VCCs (96 VCCs) was manually checked, revealing only three cases (3.1%) where the heuristic blamed the wrong commit. These errors occurred in very large commits. Despite this, the error rate is acceptable for our purposes, though improving the heuristic remains a future research direction.

#### 3.2 Feature Extraction
We extracted a list of characteristics hypothesized to distinguish VCCs from other commits. Our central hypothesis is that combining code metrics with GitHub metadata features enhances the detection of VCCs. We tested each feature separately using statistical analysis to measure whether the distribution of the feature within VCCs was statistically different from that within unclassified commits.

**Hypotheses:**
- New committers are more likely to introduce security bugs than frequent contributors.
- Longer commits may be more suspicious than shorter ones, following Git Best Practices.
- Code that has been frequently iterated over, possibly by many different authors, is more suspicious than code that doesn't change often.

**Table 1: Overview of Features and Statistical Analysis**

| Feature | Scope | Mean (VCCs) | Mean (Others) | U Effect Size |
|---------|-------|-------------|---------------|---------------|
| Number of commits | Repository | 282 | 171.39 | 32143126* |
| Number of unique contributors | Repository | 524.99 | 103 | 30528184* |
| Contributions in project | Author | 31263040* | 71.54 | - |
| Additions | Commit | 37.46 | 385.53 | 42983290* |
| Deletions | Commit | 396.63 | 22.70 | 40715632* |
| Past changes | Commit | 51.44 | 9.88 | 36261346* |
| Future changes | Commit | - | - | - |
| Past different authors | Commit | - | - | - |
| Future different authors | Commit | - | - | - |
| Hunk count | Commit | 17.68 | 1.07 | 28724694* |
| Commit message | Commit | - | - | - |
| Commit patch | Commit | - | - | - |
| Keywords | Commit | - | - | - |
| Added functions | Function | 6.51 | 1.03 | 50084674* |
| Deleted functions | Function | 6.79 | 0.49 | 41446509* |
| Modified functions | Function | - | - | - |

**Note:** Mannâ€“Whitney U test significant (*) if p < 0.00059.

**Project-Specific Features:**
- **Programming Language**: The primary language of the project, determined by GitHub's linguist library. We focused on C and C++ projects.
- **Star Count**: The number of stars the project has received on GitHub.
- **Fork Count**: The number of times the project has been forked on GitHub.
- **Number of Commits**: The total number of commits in the project.

**Author-Specific Features:**
- **Contributions (Percentage)**: The percentage of commits made by the author in the project.

**Commit-Specific Features:**
- **Number of Hunks**: The number of continuous blocks of changes in the commit.
- **Patch (Text)**: All changes made by the commit, represented as a bag of words.

By integrating these features and applying machine learning, we aim to enhance the detection of vulnerability-inducing commits in open-source projects.