efforts, HAL, hierarchical scheduling, and secure I/O. For both
the scheduling and secure I/O, there are both design/compile
time components and run-time components. Due to space
limitations,
the implementation of HAL can be found in
Appendix B.
Hierarchical Scheduler: To support real-time scheduling, we
implemented a customizable hierarchical scheduler on top of
the RT-TEE HAL. The basic components in a scheduling
system include management of tasks and prioritization. On the
task management side, since the current OP-TEE does not sup-
port secure scheduling natively, we implemented our own con-
text switching and task structure on top of the current OP-TEE
thread pool architecture using the Linux scheduling subsystem
as a reference architecture. From the prioritization side, our
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:11:09 UTC from IEEE Xplore.  Restrictions apply. 
8359
 I/O Reference MonitorDriver Debloatinginstrumentationdynamic analysisSandboxReference Monitor TrappingDriver SplitinstrumentationSched. AnalysisCARTSSandboxed Feature Rich DriverWorld SchedulerSecure OS SchedulerReplayerTrusted Debloated DriversI/O Transaction TemplatesEvent-driven Hierarchical SchedulingHALSchedulingAlgorithm(RM)compile timerun timeScheduling Paramstemplate generationTimer, IRQ, DMA, MMIO, TEE ConﬁgurationIMU,GPS,PWM,Baro.Implemented driversscheduler framework is fully modularized. It provides the basic
API to developers for building different real-time algorithms,
such as world budget update and world prio recalc. Besides
the infrastructure, we also implemented several concrete prior-
itization and budget replenishment algorithms. Our prototype
uses partitioned Rate-Monotonic (RM) with deferrable server
for the world scheduler and RM scheduler for the secure OS.
Debloated Driver: To record all the sensor operations, we in-
strumented the lowest level kernel functions, writel and readl,
then exercised the sensor operations from the user space device
driver. The recording contains a list of tuples [r/w, MMIO
address, content]. This list forms the basis of interaction
template. For many sensor reads, this list is ﬁxed because the
driver is repeatedly asking the sensor for the last readings. For
other interactions, such as motor speed, the value is constantly
changing; however, the format remains the same. For polling-
based drivers,
this list of MMIO reads/writes is enough.
The replay simply reads the tuple from memory, and writes
to the MMIO addresses using the hardcoded data or reads
from the registers. To support DMA on the template driver,
we also statically allocated memory and harcoded both the
structures and addresses into the template. Besides read/write,
our recording also records use of IRQ by instrumenting the
wait for completion function. For these types of interactions,
the template needs to be paused until IRQ is received, upon
which the replay can continue. We implemented the template
driver for all the sensors (5) and actuators (1) on Navio2.
Sandboxed Driver Implementation: There are two main
efforts, the process of splitting the driver into secure and non-
secure halves, and the process of instrumenting the secure
split to enable CFI, memory read/write sandbox, and MMIO
read/write trapping. We implemented one split driver for the
SPI bus controller since it is one of the most complex drivers
that is used by a majority of sensors and actuators on our
drone prototype. The ArduPilot program, containing millions
of SLOCs, also provides user space sensor drivers, such as
the AP InertialSensor Invensense.cpp, that interact with the
kernel using the IOCTL interface. Decoupling the existing
drivers from the non-secure OS and completely moving it
to secure environment is impractical and does not beneﬁt
security, but having only hardware interaction (i.e., MMIO
reads/writes) in the secure world is also not a good solution
since it
introduces a signiﬁcant amount of overhead. To
minimize the performance penalty, we started with the main
transfer data function bcm2835 spi transfer one and moved
all its dependencies to the secure world but manually kept
all the linux kernel structures away. In the future, this can
be an automatic process. Once the driver was splitted, we
also replaced all the calls to readl/writel with traps to the
I/O reference monitor. To provide forward edge CFI, we also
unrolled all the indirect targets. The backward edge CFI is
implemented using a shadow stack by instrumenting function
entry and exit. Lastly, we also instrumented all the memory
reads/writes to sandbox the secure driver by masking.
I/O Reference Monitor Implementation: The RT-TEE I/O
reference monitor has two main components,
the spatial
reference monitor and the temporal reference monitor. The
spatial I/O reference is highly policy dependent. In our im-
plementation, we implemented chip select checking for bus
communication and range checking for motors. To ensure I/O
requests are processed in real-time, all requests are processed
based on the priority of the process. There are multiple queues
for different ranges of priority levels and the corresponding
I/O tasks that handle requests in this queue. Therefore, it is
conﬁgurable from one queue per priority to one queue in the
entire system. In our prototype, we use a single queue and
assign all secure requests to the top half of the priority and
non-secure requests to the other half. Besides prioritization,
another key aspect is in bounding the priority inversion time.
To do so, we measure the runtime statistics of the peripheral
interactions and use the scheduler to enforce a time limit on
each I/O operation.
VI. EVALUATION
Our evaluation of the system focused on understanding
the added overhead of security on real-time systems. The
microbenchmarks measure the overhead of individual com-
ponents of RT-TEE, while the macrobenchmarks examine the
overall system performance under both synthetic workload and
real-world CPS applications. We have two evaluation plat-
forms, one for each ARMv8 architecture. For ARMv8-A, we
evaluated on a self-built quadcopter with Raspberry Pi 3 Model
B powered by ARM Cortex-A53 and with Navio2 board as the
controller. For ARMv8-M, we performed the evaluation on the
LPC55S69 micro-controller. For real-world CPS applications,
we chose ArduPilot [51], one of the most widely used open-
source autonomous vehicle controllers. Since hardware-in-the-
loop (HITL) is not supported in ArduPilot, we had to resort to
software-in-the-loop (SITL) for evaluating platforms that we
don’t have hardware for. To minimize the impact of simulation
on control performance, we ensured the platform resource
utilization was below capacity and that no tasks were missing
deadlines. We also added delays to the SITL to simulate actual
sensor/actuator response. Lastly, we built a drone using RPI3
as the ﬂight controller to demonstrate feasibility.
Fig. 7: Experiment Platform
A. Microbenchmark on Scheduling
The microbenchmark, shown in Table I, measures the over-
heads introduced by the system. All the measurements are an
average of 100 runs. Task invocation delay measures the delay
between scheduler deciding which tasks to run and the actual
start of the task execution. The conventional non-secure-based
scheduling mechanism in OP-TEE takes around 53 µs and
111 µs to invoke a secure kernel space function and a secure
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:11:09 UTC from IEEE Xplore.  Restrictions apply. 
9360
TABLE I: RT-TEE Scheduling Overhead
Runtime Overhead
S EL0 Task Invoc. Delay
S EL1 Task Invoc. Delay
World Scheduling Delay
Workload Dis: 50%(NS) 50%(S) Total Workload: 70% (Run Time16.91s)
16751(N)
617.95 ms
2713(W)/2155(S)/4156(NS)
158.24 ms
Total Scheduling Event
Total Scheduling Overhead
RT-TEE
89.35 us
16.51 us
0.94 us
OP-TEE
111.00 us
53.00 us
N/A
user space function, respectively. It takes around 16.51 µs
and 89.35 µs under RT-TEE. The performance gain is mainly
due to signiﬁcant reduction in context switch overhead for
invoking secure world functions. The difference between user
task and kernel task is primarily due to the user process setup.
We also measured the task invocation time on the LPC55S69
micro-controller. The invocation delay is 0.35 µs with RT-
TEE and 0.31 µs without RT-TEE. The invocation delay is
shorter due to a much simpler context switch. To measure
the efﬁciency of the event-driven scheduler adopted by RT-
TEE, we instrumented RT-TEE hierarchical scheduler and
non-secure OS scheduler in Linux to record the scheduling
event count and the total overhead over the execution of a set
of real-time tasks executing in both S and NS environment
over 16.91s. As shown in Table.I, event-driven scheduler has
46.13% fewer scheduling events and 74.40% less scheduling
runtime overhead than conventional time-based scheduler.
B. Micro-benchmark on I/O
I/O – Debloated Driver: To ﬁnd the number of sensor
operations, we instrumented all the IOCTL in ArduPilot. We
found that during drone operation, there are six sensor/actuator
operations. To demonstrate driver ﬂexibility, we implemented
and evaluated the debloated/template-based drivers for all the
sensor and actuator operations needed to operate the drone.
Each operation has its own individual template, as shown in
Table. II. These drivers encompass 2 buses (SPI and I2C) and
three mechanisms of message delivery (DMA, IRQ, and Poll).
However, driver interaction with peripherals always follows a
similar protocol, which allows us to turn them into templates.
During the experiments, we attempted to speed up the I/O
operations in the template but failed due to the bus speed. As
a result, we decided to adhere to the existing delays in the
template. To compare with the native driver, we use the same
user space driver, but instead invoked the template version.
The runtime overheads of our debloated drivers are shown in
Table II. The latency is comparable to the original drivers. We
believe this is due to the fact that the debloated drivers save
complex conﬁguration and simply replay data; however, they
suffer from world switches as well as I/O queue processing.
TABLE II: Debloated Driver Statistics
Sensors/Bus
MPU9250/SPI
AK8963/SPI
LSM9DS1/SPI
UbloxM8N/SPI
Motors/SPI
MS5611/I2C
Operation
Semantics
R Inertial
R Compass
R Compass
R GPS
W Motors
R Temp/Pres
Tpl.
Size
117
126
126
124
4374
225
Transfer
Mech.
DMA
Poll
Poll
DMA
IRQ
IRQ
Native
Avg(us)
157
41
37
227
782
77
Debloated
Avg(us)
165
46
43
235
792
84
I/O – Sandboxed Driver Overhead: We split
the SPI
controller driver for RPI3 as a feasibility study. To identify
the best split between the secure and non-secure parts, we
dynamically analyzed the driver to identify the function in
the execution trace that will have the least amount of Linux
structure dependency and the largest group of I/O operations.
Currently, this is a manual process. Once the function was
identiﬁed, we proceeded to extract all the dependencies of the
function along with the structures they refer to and ﬂatten
them. Using the self-contained driver, we then sandboxed it
using the GCC pass. The non-secure split was also modiﬁed
to call secure world split upon entry of the function. The
average overhead was 6.86% for runtime and 13.75% for code
size. The overhead was within our expectation since average
masking overhead is around 5%, and there is only a single
invocation to the secure world.
C. Macro-benchmark with Synthetic Tasks
Using the synthetic tasks, we answered the question of
whether hierarchical scheduling has better real-time perfor-
mance than idle scheduling at different system loads. The per-
formance is measured by how few tasks miss their deadlines.
Particularly, we wanted to see heirachical scheduler deliver
on the promise of not missing secure task deadlines even if
non-secure environment is prioritized. All experiments were
conducted using ten synthetic tasks. The actual execution was
randomly generated from 1ms to 20ms, with ﬁve as secure
tasks and ﬁve as nonsecure tasks. Given the real-time task
speciﬁcation, we used CARTS [43] to calculate budgets for
each world, which ensures the schedulability of tasks.
(a) Prioritizing Secure
(b) Prioritizing Non-Secure
Fig. 8: Tasks Miss Rate Compared with Idle Scheduling on ARMv8-A
Idle Scheduling Performance Comparison: Fig. 8 shows
real-time performance comparison between idle scheduling
and hierarchical scheduling. We can make the following
observations. 1) Hierarchical scheduling has better real-time
performance when secure world is prioritized in hierarchical
scheduling since task miss rate is always lower with hierarchi-
cal scheduling, as shown in Fig. 8a. 2) Hierarchical scheduling
always outperforms idle scheduling when system load is below
80%, as shown in Fig. 8b. In other words, our scheduling struc-
ture allows better responsiveness of non-secure tasks without
impacting secure workloads as long as the system is designed
to be below 80% utilization, which is a reasonable assumption
since many CPS systems are not schedulable when the system
utilization is high (69% for rate monotonic systems [37]). In
other words, when the real-time task set is schedulable, it is
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:11:09 UTC from IEEE Xplore.  Restrictions apply. 
10361
4550556065707580859095100Workload (%) - NS/S Dist (75%/25%)0255075100Tasks Miss Rate (%)NS Miss Rate with Idle SchedulerNS Miss Rate with Hierarchical SchedulerS Miss Rate with Idle SchedulerS Miss Rate with Hierarchical Scheduler4550556065707580859095100Workload (%) - NS/S Dist (75%/25%)0255075100Tasks Miss Rate (%)(a) Velocity deviation
(b) Acceleration deviation
Fig. 9: Control Performance with RT-TEE and Baseline w/o TEE on Copter
always better to leverage hierarchical scheduling to provide
better non-secure task responsiveness.
D. Macro-benchmark with Real-world CPS in Simulation
While synthetic tasks are informative and allow us to
explore the various conditions the system can face from the
computation perspective, we are also interested in seeing how
the system can be used to protect real-world CPS applica-
tions. Therefore, we used RT-TEE to protect three real-world
applications to show the feasibility and potential limitations.
Particularly, we used RT-TEE to protect fail-safe controller and
attitude controller on the quadcopter and fail-safe controller on
the plane and rover platforms. Fail-safe controller was selected
because it can be used to detect unsafe physical condition of
the autonomous system, while attitude controller was selected
for its ability to act as an enforcer for mission trajectory.
We used CMAC-copter-circuit, CMAC-circuit, and CMAC-
bigloop of ArduPilot autotest as missions for quadcopter,
plane, and rover, respectively.
RT-TEE Impact on Control Performance: To understand
the impact of RT-TEE on the control, we recorded the actual
position, velocity, and acceleration of the autonomous vehi-