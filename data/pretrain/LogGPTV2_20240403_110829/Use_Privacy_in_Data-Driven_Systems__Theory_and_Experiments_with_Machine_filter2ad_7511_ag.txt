otherwise
We denote q as ‘positional indicator’. Specifically, q has the syntax
of the following.
⟨q⟩ ::= ϵ | i⟨q⟩ | {i1, . . . , ik}
We then define the term obtained by substituting s in e at position
q, written e[s]q, to be the term where e[s]q|q = s, and e[s]q|q′ = eq′
for all q′ that are not prefixed by q. For a sequence of positions
q1, . . . , qn and terms s1, . . . , sn, we write e[s1, . . . , sn]q1, ...,qn
to
denote the sequential replacement obtained in order from 1 to n.
Given a program p = λ(cid:174)x .e, we will often write p|q or p[s]q for
brevity to refer to e|q and e[s]q, respectively. The set of decomposi-
tions of a program p is then defined by the set of positions q such
that p|q (cid:44)⊥. Given position q, the corresponding decomposition is
simply (λ(cid:174)x .p|q , u, λ(cid:174)x, u.p[u]q).
Example B.1. Consider a simple model,
p = λx, y.ite(x + y ≤ 0, 1, 0)
= λx, y.ite(≤ (+(x, y), 0), 1, 0)
There are eight positions in the body expression, namely {ϵ, 1, 2, 3,
11, 12, 111, 112}. The subexpression at position 112 is y, and p[u]11 =
ite(u ≤ 0, 1, 0). This corresponds to the decomposition:
(λx, y.x + y, u, λx, y, u.ite(u ≤ 0, 1, 0))
With this notation in place, we can formally describe the detec-
tion algorithm in Algorithm 4.
B.2 Translation
This section describes the translation of machine learning models
used in our implementation to the term language.
B.2.1 Decision trees and Rule lists. Decision trees can be written
in this language as nested ite terms, as shown in Figure 7. The
Boolean expression in each term corresponds to a guard, and the
arithmetic expressions to either a proper subtree or a leaf. Bayesian
x1
≤ 1
2
0
≤ 0
0
1
2
>
x2
≤ 1
x3
> 0
1
> 1
0
ite(x1≤ 1
2 ,
0
ite (x2 ≤ 1,
ite(x3 ≤ 0, 0, 1),
0)))
Figure 7: Decision tree and corresponding expression pro-
gram.
rule lists are a special kinds of decision trees, where the left subtree
is always a leaf.
B.2.2
Linear models. Linear regression models are expressed by
direct translation into an arithmetic term, and linear classification
models (e.g., logistic regression, linear support vector machines,
Naive Bayes) are expressed as a single ite term, i.e.,
sgn((cid:174)w · (cid:174)x + b) becomes λ(cid:174)x.ite((cid:174)w · (cid:174)x + b ≥ 0, 1, 0)
Importantly, the language supports n-ary operations when they
are associative, and allows for rearranging operands according
to associative and distributive equivalences. In other words, the
language computes on terms modulo an equational theory. Without
allowing such rearrangement, when a linear model is expressed
using binary operators, such as ((((w1×x1) +(w2×x2)) +(w3×x3)),
then the algorithm cannot select the decomposition:
p1 = λ(cid:174)x.(w1 × x1) + (w3 × x3)
p2 = λ(cid:174)x, u.u + (w2 × x2)
B.2.3 Decision Forests. Decision forests are linear models where
each linear term is a decision tree. We combine the two translations
described above to obtain the term language representation for
decision forests.
B.3 Validity Testing
We use mutual information to determine the strength of the statis-
tical association between(cid:74)p1(cid:75)(X) and Z. Each test of this metric
hypothesis which assumes that d((cid:74)p1(cid:75)(X), Z) 
we need to find an optimal constant to replace the subtree rooted
2 ∧ x2 ≤ 1, so we select (cid:174)Xϕ = {(cid:174)x ∈
1
at x3. In this case, ϕ
(cid:174)X|x1 >
2 ∧ x2 ≤ 1} and take the mode of the empirical sample
1
[p((cid:174)x)](cid:174)x ∈ (cid:174)Xϕ
D OTHER EXPERIMENTS
D.1 Details of Case Studies
Targeted contraception advertising We consider a scenario in
which a data processor wishes to show targeted advertisements
for contraceptives to females. To support this goal, the proces-
sor collects a dataset from a randomly-sampled female population
containing age, level of education, number of children, current
employment status, income, level of media exposure, information
about the partner’s education and occupation, and the type of con-
traception used by the individual (if any). This dataset is used to
train a model that predicts whether an individual uses no contra-
ception, short-term contraception, or long-term contraception. This
model is then used to determine who to display advertisements to,
under the assumption that individuals who already use short-term
contraception are more likely to be receptive to the advertisements.
Because certain religions ban the use of contraception, users
belonging to such a religion are on the whole less likely to purchase
contraceptives after seeing such an advertisement. The ad-targeting
model does not explicitly use a feature corresponding to religion,
as this information is not available to the system when ads are
displayed. Furthermore, some users may view the use of this infor-
mation for advertising purposes as a violation of their privacy, so
the data processor would like to ensure that the targeting model
has not inferred a proxy for this information that is influential in
determining whether to show an advertisement.
We evaluated this scenario using data collected for the 1987
National Indonesia Contraceptive Survey [1], which contains the
features mentioned above, as well as a feature indicating whether
the individual’s religious beliefs were Islam. To simulate the data
processor, we trained a decision tree classifier to predict contracep-
tive use over all available features except the one corresponding to
religion. We then used our detection algorithm to look for a proxy
use of religion, using the available data as ground truth to evaluate
the effectiveness of our approach.
Although this data is representative of a single country, it il-
lustrates an interesting case of potential use privacy. Our detec-
tion algorithm identified the following intermediate computation,
which was one of the most influential in the entire model, and the
one most closely associated with the religion variable: ite(educ <
4∧ nchild ≤ 3∧ age < 31, no, yes). This term predicts that women
younger than 31, with below-average education background and
fewer than four children will not use contraception. Given that the
dataset is comprised entirely of females, closer examination in fact
reveals that just the “guard” term educ < 4 alone is even more
closely associated with religion, and its influence on the model’s
output is nearly as high. This reveals that the model is using the vari-
able for education background as a proxy for religion, which may
be concerning given that this application is focused on advertising.
Student assistance A current trend in education is the use of
predictive analytics to identify students who are likely to benefit
from certain types of interventions to ensure on-time graduation
and other benchmark goals [31, 39]. We look at a scenario where
a data processor builds a model to predict whether a secondary
school student’s grades are likely to suffer in the near future, based
on a range of demographic features (such as age, gender, and family
characteristics), social information (such as involvement in extracur-
ricular activities, amount of reported free time after school), and
academic information (e.g., number of reported absences, use of
paid tutoring services, intention to continue on to higher education).
Based on the outcome of this prediction, the student’s academic
advisor can decide whether to pursue additional interventions.
Because of the wide-ranging nature of the model’s input fea-
tures, and sensitivity towards the privacy rights of minors, the data
processor would like to ensure that the model does not base its
decision on inferred facts about certain types of activities that the
student might be involved with. For example, alcohol consumption
may be correlated with several of the features used by the model,
and it may not be seen as appropriate to impose an intervention
on a student because their profile suggests that they may have
engaged in this activity. Depending on the context in which such
Figure 8: The association with marital_status and influence of the sub-expressions of three similarly-sized models trained
on the UCI Adult dataset (normalized): random forest (×), decision tree (+), and logistic regression (⋆). The arrows denote the
sub-expression relationship among the expressions. Pointed out are several significant expressions that use the relationship
feature. Note that in the random forest, the same associated expression appears in all three of the trees in that model.
an inference were made, the processor would view this as a privacy
violation, and attempt to remove it from the model.