caches recently used mappings of virtual page numbers
to physical page frames. On every virtual memory ac-
cess, all entries in a TLB are checked to see whether any
of them contain the correct virtual page number. If an
entry is found for the virtual page number, a TLB hit has
occurred, and the corresponding physical page frame is
immediately accessed. Otherwise, we have a TLB miss,
and the appropriate page tables are consulted in the fash-
ion discussed previously. The mapping so determined is
then added to the TLB by replacing the mapping that
was least recently used. Figure 4 illustrates what hap-
pens on a TLB hit.
Virtual Address
Directory Offset
Map Offset
Table Offset
Page Offset
TLB Translation Mechanism
Physical Address
Physical Frame
Page Offset
Figure 4. Address Translation using a TLB
Because of the principal of locality, TLB translation
works very well in practise. System designers have no-
ticed, however, that code and data exhibit different pat-
terns of locality. To prevent interference between these
patterns, caches of code and data are often separated; for
similar reasons, most modern CPUs have separate code
and data TLBs. CPU caches mark referenced memory
as code or data depending upon whether it is sent to an
instruction decoder. Whenever an instruction is fetched
from memory, the instruction pointer is translated via the
instruction TLB into a physical address. When data is
fetched or stored, the processor uses a separate data TLB
for the translation. Using different TLB units for code
and data allows the processor to maintain a more accu-
rate representation of recently used memory. Separate
TLB’s also protect against frequent random accesses of
code (data) overwhelming both TLB’s. Because most
code and data references exhibit high degrees of locality,
a combination of small amounts of fast storage (e.g. on-
chip memory caches) and more plentiful slower storage
(DRAM memory) can together approximate the perfor-
mance of a larger amount of fast storage.
Page Swapping. Because the memory management
unit presents a virtual address space to the application
running, the application need not be aware of the phys-
ical sections of memory which it actively uses. Thus
even though the virtual address space of a program is
contiguous, the physical regions of memory it uses may
not be. This presents a great opportunity for the operat-
ing system. Not only does it allow multiple applications
to be run on the system (each with its own unique virtual
address space, mapping to different physical pages), but
it allows the operating system to only keep in physical
memory those parts of each application required at the
current time. Since not all pages of virtual memory may
map to a physical page, there must be some way for the
processor to inform the OS when a virtual address does
not have a physical mapping. The processor does this
through the use of a page fault interrupt. The proces-
sor will store the virtual address which caused the page
fault in a register, and then signal the operating system
through an interrupt handler. The operating system up-
dates the mapping of virtual to physical addresses, so
that the requested virtual address can be mapped to a
physical address. This may mean bringing the section
of the program into physical memory from disk or some
other external storage. The OS then signals the proces-
sor to retry the instruction by returning from the inter-
rupt. The OS also has the choice of aborting execution
of the application if it determines that the virtual address
if the virtual address refers to memory
is invalid, e.g.
Proceedings of the 2005 IEEE Symposium on Security and Privacy (S&P’05) 
1081-6011/05 $ 20.00 IEEE
that has not been allocated.
Access Controls on Memory. Along with the trans-
lation of a virtual to physical address, the processor may
implement access protection on memory regions. Since
the virtual memory subsystem already splits physical
memory into small areas (frames), it makes sense that
the same memory management unit would also imple-
ment access control on a per-frame basis. The most im-
portant protection is that only pages that an application
is allowed to access are mapped into its page table. To
prevent an application from manually mapping a page
into its address space, the page directory base pointer is
stored in a read-only register, and the frames containing
a process’s page table are themselves not accessible by
the process.
In addition,
there are protection mechanisms for
pages which are in a process’s address space. Each
mapped page is restricted in the types of operations that
may be performed on its contents: read, write, and in-
struction fetch (also called execute). Permitted oper-
ations are speciﬁed using control bits associated with
each page table entry. Read and write are common oper-
ations on data pages, while executing code is commonly
associated with a page containing executable code.
Modern operating systems take advantage of the pro-
tection mechanisms implemented by the processor to
distinguish various types of memory usage. As men-
tioned in Section 4, the ability to set no-execute permis-
sion on a per-page basis produces the restriction that
many programs are conﬁned to executing code from
their code segment, unless they take speciﬁc action to
make their data executable. Although such changes
can interfere with systems that generate machine code
at runtime (e.g. modern Java Virtual Machines), many
types of code injection attacks can be defeated by non-
executable data pages. While not currently supported on
all processors, we expect this technology to appear in an
increasing number of new processors.
Table 1. Separation of access control priv-
ileges for different page types
Permissions
Segment
Code
Data
Executable Data
Stack
Read Write Execute
(cid:1)
(cid:1)
(cid:1)
(cid:1)
X
(cid:1)
(cid:1)
(cid:1)
(cid:1)
X
(cid:1)
X
privileges is currently assumed in executable ﬁle for-
mats. All processors implementing page level access
controls must check for disallowed operations and signal
the operating system appropriately. Most often, the op-
erating system is signalled through the page fault inter-
rupt, which indicates the memory reference that caused
the invalid operation.
4. Hardware-assisted Circumvention of In-
tegrity Self-Checking
Although the code and data separation performed by
modern processors yields many positive results, it turns
out that these same mechanisms can sometimes be used
to circumvent checksumming-based self-checking tam-
per resistance mechanisms.
In the subsections below,
we report our ﬁndings for the UltraSparc, Alpha, x86,
PowerPC, AMD64, and ARM processor architectures.
We consider an attack involving the following steps.
1. The attacker makes a copy of the original program
code (e.g. cp program).
2. The attacker modiﬁes the original program code as
desired.
3. The attacker modiﬁes the kernel on the machine,
installing a kernel module or patch designed to im-
plement our attack.1
4. The attacker runs the modiﬁed code under the mod-
iﬁed kernel. During the attack, the attack code in
the kernel will redirect data reads (including those
by the checksumming code) to the corresponding
information in the un-modiﬁed application.
Operating systems are capable of detecting the dif-
ference between a data and instruction read because of
the processor functionality exposed. If enough control
is presented to the operating system (as demonstrated in
Section 4.1 and 4.2), the attack is possible. How the
attack code in the kernel is informed about the desired
redirections in the program under attack can vary. For
our proof of concept implementation, a wrapper pro-
gram (as explained in Section 4.1) was used to notify
the kernel.
Table 1 shows the ideal separation of privileges for
different sections of an application. This separation of
1This of course assumes an attacker has, or has gained, very sig-
niﬁcant privileges on the host machine. However, this is precisely the
standard threat model for software tamper resistance (see Section 2).
Proceedings of the 2005 IEEE Symposium on Security and Privacy (S&P’05) 
1081-6011/05 $ 20.00 IEEE
4.1. Defeating Self-Checking on the UltraSparc
Virtual Address
In this section we focus on the UltraSparc and brieﬂy
Instruction Fetch
Instruction TLB
Physical Memory
Modified Program Code
Original Program Code
discuss the Alpha processor.
The UltraSparc processor implements a software load
TLB mechanism (see Section 3). When the running ap-
plication requires a translation from a virtual page to a
physical page that cannot be done with the current TLB
state, the processor signals the OS to perform a TLB up-
date, which installs the virtual to physical mapping for
the translation. The processor notiﬁes the kernel through
two exceptions, fast instruction access MMU miss or
fast data access MMU miss [30]. Knowing this, we
crafted a tamper resistance attack to take advantage of
the information given by the processor to the operating
system on a TLB miss. Depending on whether a data or
instruction fetch (i.e. D(x) or I(x)) caused the fault, our
modiﬁed kernel updates the corresponding TLB differ-
ently. At a high level, the attack results in the separation
of the physical page containing an instruction for ad-
dress x from the physical page containing readable data
for x. Instruction fetches were automatically directed by
the modiﬁed TLB to page p while reads by the program
code into the code section were directed to the physical
page p + 1 (see Figure 5). For an actual attack, the at-
tacker arranges that page p + 1 contains an unmodiﬁed
copy of the original code, and that the modiﬁed code is
on page p. A read from the virtual address in question
results in the expected value of the unmodiﬁed (original)
program code on physical page p + 1, even though the
actual instruction which is executed from that same vir-
tual address is a different instruction on physical page
p. In this discussion and for our proof of concept im-
plementation, an offset of 1 physical page was chosen
for simplicity; other page offsets are equally possible.
This mechanism thus defeats the protection provided by
self-integrity checksumming mechanisms (e.g. includ-
ing [4, 12], also [14]), on the UltraSparc processor.
Our implementation was done using version 2.6.8.1
of the Linux kernel [19]. A separate wrapper program
was also developed to set up the kernel level structures
and then run the target program. The wrapper program
notiﬁes the kernel of the associated data pages for spe-
ciﬁc virtual addresses which are to have split processing
of data and instruction reads. The wrapper program re-
places itself (using execve) with the application binary
when it has ﬁnished initialization.
Like many other processors, the UltraSparc proces-
sor’s page table entries do not use all the available bits.
Those bits which are unused by the processor are avail-
able for use by the operating system. We used one of
Proceedings of the 2005 IEEE Symposium on Security and Privacy (S&P’05) 
1081-6011/05 $ 20.00 IEEE
Data Fetch
Data TLB
Figure 5. Separation of virtual addresses
for instruction and data fetch
these bits while modifying the kernel to implement our
attack. This bit (which we refer to as isSplit) was used to
identify which pages had split instruction and data phys-
ical pages. When a fast data access MMU miss excep-
tion was triggered by the processor, the proof of con-
cept exception handler checks the bit and increments the
physical page number for the corresponding page table
entry before loading it into the data TLB. This extra pro-
cessing required only 6 additional assembly instructions.
The kernel side of our proof-of-concept attack code
implemented the split instruction and data pages. As
mentioned earlier, two adjacent pages in physical mem-
ory were allocated, with page p holding the modiﬁed
(attacked) and p + 1 holding the un-modiﬁed applica-
tion code. The page table entry for each page that im-
plemented the split had the isSplit bit set. The value of
the isSplit bit is determined by examining information
provided by the wrapper program. For pages contain-
ing application code which has been tampered with, the
wrapper program will provide the original unmodiﬁed
code page to the modiﬁed kernel. When the application
which is to be attacked is subsequently loaded, the page
table map is initialized by the modiﬁed kernel and the
isSplit bit is set for those pages speciﬁed by the wrap-
per. Page swapping was not considered in the proof of
concept implementation (but we would not expect this
to introduce any complication).
The end result of our proof of concept is that the
data TLB was always loaded with address mappings
that mapped a virtual address onto the physical address
containing the un-modiﬁed application code for the ap-
plication being attacked. The instruction TLB was al-
ways loaded with translations which mapped to physi-
cal pages containing the modiﬁed application code. Our
proof of concept implementation was tested with a pro-
gram employing checksumming of the code section. We
were able to easily change program ﬂow of the origi-
nal program without being detected by a representative
checksumming tamper resistance algorithm.
Alpha Processor. The Alpha processor has the abil-
ity to execute PALcode (Privileged Architecture Li-
brary) [8]. PALcode is similar to microcode except that
it is stored in main memory and modiﬁable by the oper-
ating system. By modifying the PALcode which is run
by the processor on a TLB miss, one can directly inﬂu-
ence the state of both the data and instruction TLB. The
operating system has the ability to modify the PALcode,
or replace it with a version speciﬁc to the operating sys-
tem should it wish. By replacing the PALcode for the
TLB miss scenario, we expect that an attack similar to
that above can be implemented on the Alpha processor.