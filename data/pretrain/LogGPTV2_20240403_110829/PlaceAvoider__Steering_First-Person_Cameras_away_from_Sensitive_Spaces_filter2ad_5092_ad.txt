### 优化后的文本

#### 性能比较
以下是不同特征分类器在各个数据集上的性能对比：

- **SIFT 特征**：
  - 数据集1: 82.7%, 41.6%, 71.9%
  - 数据集2: 78.7%, 52.8%, 64.8%
  - 数据集3: 66.2%, 51.9%, 65.5%
  - 数据集4: 88.8%, 76.2%, 85.1%
  - 数据集5: 83.2%, 67.5%, 72.2%
  - 数据集6: 79.9%, 58.0%, 71.9%

- **全局密集 SIFT 袋**：
  - 数据集1: 81.4%
  - 数据集2: 78.8%
  - 数据集3: 68.9%
  - 数据集4: 93.9%
  - 数据集5: 83.1%
  - 数据集6: 81.2%

- **RGB 直方图**：
  - 数据集1: 57.4%
  - 数据集2: 47.9%
  - 数据集3: 57.4%
  - 数据集4: 79.8%
  - 数据集5: 55.0%
  - 数据集6: 59.5%

平均而言，分类器的性能比多数基线分类器高出近2.5倍。HMM（隐马尔可夫模型）进一步显著提高了准确性，将局部特征的平均准确率从64.7%提高到81.9%，将全局特征的平均准确率从64.3%提高到74.8%。结合两种特征与HMM，可以达到最佳性能，平均准确率为89.8%，是基线的3.1倍以上。

#### 图像示例
图5展示了来自House 2流的一些样本图像，包括正确和错误分类的图像。我们可以推测一些误分类的原因。当通过窗户或门拍摄图像时，如果捕获的注册空间很少，分类器的信心会降低（见图5中的误分类示例面板1、4和7）。同样，图像中高度遮挡也会阻碍分类尝试（误分类示例面板3展示了这一点）。

#### 人类交互
我们的概率方法的一个优势是可以自然地结合额外的证据。例如，生活日志应用程序或设备操作系统可以要求用户帮助标记模糊的图像。我们通过让HMM识别其估计标签中最不自信的图像（即具有最低最大边缘概率的图像），然后强制该图像采用真实标签，修改P(li|I)使其对正确标签为1，对错误标签为0，并重新进行推理。我们重复此过程10次，模拟PlaceAvoider请求用户标记10张图像。表IV的最后一列展示了结果，显示了相对于完全自动算法的进一步性能提升，在四个数据集中实现了超过90%的准确率，在三个数据集中实现了95-100%的准确率。进一步的增强可以通过这些新标记的图像更新视觉模型本身，但这留待未来工作。

#### 在线推理
请注意，我们的HMM假设整个照片流都是可用的——即在标记给定图像时，分类器可以看到未来的图像以及过去的图像。这种场景适用于照片共享、生活日志和其他容许延迟的应用程序。对于需要在线实时决策的应用程序，HMM可以被修改为仅查看过去（通过仅运行前向-后向算法的前向传递），但准确率会有所下降：在这种情况下，五个数据集的平均HMM性能从89.8%降至82.6%。

#### 场景遮挡的影响
第一人称相机捕捉到的动态场景中经常有移动的对象和人物，这通常会导致照片中的大部分场景被前景对象遮挡。这些遮挡增加了室内位置识别的难度，但我们预计它们是常见的——实际上，潜在的遮挡可能是隐私政策中定义敏感房间的基础。为了测量更频繁的遮挡对分类器准确率的影响，我们生成了一个包含模拟遮挡的数据集，将一个人体轮廓（遮挡约30%的图像）叠加在不同比例的图像上。图6展示了我们的模拟图像示例，表V展示了这些图像在Workspace 2数据集上的准确率。我们观察到，随着更多图像被遮挡，局部特征性能下降，而全局特征和HMM的准确率相对稳定，下降不到一个百分点。我们将在未来的工作中进行更多关于真实物体和人员遮挡的广泛研究。

#### 检索私密图像
到目前为止的实验将问题视为图像分类问题：给定一张已知在一个n个房间之一拍摄的图像，识别正确的房间。然而，PlaceAvoider的主要目标并不一定是识别确切的房间，而是过滤出可能在某些私密房间拍摄的图像。这是一个图像检索问题：给定一系列图像，我们希望检索出私密图像，以便将其过滤掉。由于我们的分类算法并不完美，用户可以提供置信度阈值来选择一个非常保守或非常选择性的过滤器，具体取决于他们的偏好和空间的敏感程度。

图7的顶部行展示了从我们的五个数据集中检索私密图像的精度-召回曲线。我们为每个数据集进行了五次检索任务，每次针对一个房间，然后将得到的P-R曲线取平均值。对于局部和全局特征，我们使用PL(li|I)和PG(li|I)的最大值（跨类别）作为自由参数（置信度），而对于HMM，我们使用由前向-后向算法计算的P(li|I1, ..., Im)的最大边缘值（跨类别）。我们看到，对于House 1、House 3和Workspace 2，可以在大于70%的精度下实现100%的召回率，这意味着所有私密图像都可以被识别，同时只移除30%的无害图像。对于Workspace 1，可以实现大约90%的精度和召回率，而对于非常困难的House 2，大约可以在90%的召回率下实现40%的精度。

上述结果反映了封闭场景，其中假设用户已经注册了所有可能的房间。作为对开放场景的初步评估，我们创建了合成流，在其中插入了其他数据集的随机片段，使得这些噪声流中约20%的图像是“其他类别”。这可以解释为用户在已注册的空间中收集了80%的图像，这是合理的。实际应用中，时间分配可能会因个体而异。图7的底部行展示了这种情况下的精度-召回曲线。尽管与原始流相比，检索准确率有所下降，但在三个数据集（House 3和两个Workspaces）中，我们仍然观察到在大于80%的精度下接近100%的召回率。我们认为，对于大量生活日志应用中的照片，这样的精度值是合理的，因为它们仍然留下了大量无害的图像用于分享。被阻止的照片可以手动审查以识别错误分类。虽然这些结果很有希望，但需要更大规模、更真实的头戴式数据集来评估现实世界开放场景中的性能。

#### 计算性能
目前版本的PlaceAvoider是一个概念验证，实现在通用工作站上，使用未优化的C++、Matlab、Python和R代码混合编写。该代码在2.6GHz Xeon服务器上处理每张图像平均需要18.421秒。这种性能可能适合于离线计算的云应用，但不适合实时使用。我们怀疑通过简单的优化（如将所有代码重写为C++），可以显著改善运行时间。我们现在讨论算法改进，以提高PlaceAvoider在移动设备上的可用性。

#### 减少局部特征匹配时间
我们的局部特征分类器的一个缺点是Equation (1)中的最小化可能计算量很大，每张图像需要几秒钟。然而，由于我们的注册数据集由多轮照片采集组成，并且图像之间存在空间重叠，因此不可避免地存在冗余。我们开发了四种技术来减少分类算法的运行时间和空间需求，试图消除这些房间模型中的冗余：

- **K-means聚类**：对房间模型中的SIFT特征进行K-means聚类，简单地将房间表示为聚类中心集合。
- **局部敏感哈希（LSH）**：一种降维技术，试图保留哈希和未哈希点之间的空间关系。我们运行LSH并将每个哈希桶中的多个点合并成单个描述符。
- **近似最近邻（ANN）**：扫描描述符集，迭代地将最接近的两个描述符合并，直到达到指定的目标描述符数量。使用ANN使这一过程高效。

#### 单张图像分类时间
表VI展示了House 3注册图像的平均单张图像分类时间，包括特征提取和分类：

- **全局密集SIFT袋**：68.9%，14.325秒
- **局部SIFT**：95.7%，2.517秒
- **全局HOG袋**：66.2%，1.110秒
- **全局LBP**：51.9%，1.107秒
- **局部SIFT（10%黑名单）**：55.2%，0.996秒
- **全局SIFT袋**：89.4%，0.469秒
- **全局GIST**：65.5%，0.247秒
- **全局RGB直方图**：57.4%，0.063秒

通过这些优化，我们可以显著提高PlaceAvoider在移动设备上的性能和实用性。