82.7% 41.6% 71.9%
78.7% 52.8% 64.8%
66.2% 51.9% 65.5%
88.8% 76.2% 85.1%
83.2% 67.5% 72.2%
79.9% 58.0% 71.9%
of SIFT
81.4%
78.8%
68.9%
93.9%
83.1%
81.2%
RGB
histogram
57.4%
47.9%
57.4%
79.8%
55.0%
59.5%
percentage points. On average, the classiﬁers outperform a
majority baseline classiﬁer by almost 2.5 times. The HMM
provides a further and relatively dramatic accuracy improve-
ment, improving average accuracy from 64.7% to 81.9% for
local features, and from 64.3% to 74.8% for global features.
Combining the two types of features together with the HMM
yields the best performance with an average accuracy of
89.8%, or over 3.1 times the baseline.
Figure 5 shows some sample images from the House 2
stream, including a random assortment of correctly and incor-
rectly classiﬁed images. We can speculate on the cause of some
of the misclassiﬁcations. When images are collected looking
through windows or doors such that little of an enrolled space
is captured in the image, the classiﬁer conﬁdence is intuitively
reduced (see panels 1, 4, and 7 of the misclassiﬁed examples in
Figure 5). Similarly, high degrees of occlusion in images will
frustrate classiﬁcation attempts (panel 3 of the misclassiﬁed
examples demonstrates this).
Human interaction. An advantage of our probabilistic ap-
proach is that it can naturally incorporate additional evidence,
if available. For instance, a lifelogging application or the
device operating system could ask the user to help label
ambiguous images. We simulated a simple version of this
approach by having the HMM identify the least conﬁdent of
its estimated labels (i.e., the image with the lowest maximum
marginal probability). We then forced that image to take on
the true label by modifying P (li|I) in Equation (2) to be 1
for the correct label and 0 for the incorrect labels, and re-
ran inference. We repeated this process 10 times, simulating
PlaceAvoider asking the user to label 10 images. The last
column of Table IV presents the results, showing a further
increase in performance over the fully automatic algorithm,
achieving over 90% accuracy for four of the datasets, and 95–
100% accuracy for three of them. An additional enhancement
would be to update the visual models themselves based on
these new labeled images, but we leave this for future work.
Online inference. Note that our HMM assumes that the entire
photo stream is available — i.e., in labeling a given image, the
classiﬁer can see images in the future as well as in the past.
This scenario is reasonable for photo-sharing, lifelogging, and
other applications that are tolerant to delay. For applications
that require online, real-time decisions,
the HMM can be
modiﬁed to look only at the past (by running only the forward
pass of the Forward-Backward Algorithm), but at a reduced
accuracy: average HMM performance across the ﬁve datasets
falls from 89.8% to 82.6% in this case.
Impact of scene occlusion. First-person cameras capture
dynamic scenes with moving objects and people, and this
often causes large portions of a scene to be occluded by
foreground subjects in the photos. These occlusions increase
the difﬁculty of indoor place recognition, but we expect them
to be commonplace — in fact, potential occlusions may be the
basis for deﬁning a room as sensitive in a privacy policy. (For
8
TABLE IV.
CLASSIFICATION OF TEST STREAMS BY THE SINGLE IMAGE CLASSIFIERS AND VARIATIONS OF THE HMM.
Global
Local
features
features
89.2% 64.0%
56.4%
55.0%
97.4%
86.9%
89.2%
75.5%
81.2%
92.3%
81.9%
74.8%
features
89.2%
74.6%
98.7%
87.7%
98.7%
89.8%
Joint stream classiﬁer
Local+global
Local+global+
human interaction
95.0%
76.8%
99.8%
91.0%
100.0%
92.5%
Baseline
accuracy
29.8%
31.0%
20.9%
32.1%
28.9%
28.5%
Single image classiﬁer
Local
features
52.9%
41.8%
81.5%
75.9%
71.6%
64.7%
Global
features
48.3%
49.1%
80.0%
74.6%
69.4%
64.3%
Dataset
House 1
House 2
House 3
Workplace 1
Workplace 2
Average
t
c
e
r
r
o
C
t
c
e
r
r
o
c
n
I
Fig. 5. Some sample classiﬁcation results from the House 2 stream, showing correctly classiﬁed (top) and incorrectly classiﬁed (bottom) images.
TABLE V.
EFFECT OF IMAGE OCCLUSION ON CLASSIFICATION
ACCURACY, ON OUR SYNTHETIC DATASET BASED ON WORKSPACE 2.
% of occluded
images
0
10
20
30
100
Photo streams
Single image
Local
Local+ Local+global+
Global
global
classiﬁer classiﬁer
71.6% 69.4% 98.7%
67.6% 68.7% 98.9%
67.2% 68.3% 99.6%
64.6% 69.8% 99.8%
68.0% 69.8% 98.5%
interaction
100.0%
100.0%
100.0%
100.0%
100.0%
instance, empty bathrooms are usually innocuous but photos
of people in the bathroom may cause concern.)
While our streams include some incidental occlusions, we
wanted to measure the effect that more frequent occlusions
would have on classiﬁer accuracy. To do this, we generated
a dataset with simulated occlusions, superimposing a human
silhouette (which blocked about 30% of the image) on varying
fractions of the images. Figure 6 shows examples of our
simulated images, and Table V presents accuracies on these
images on the Workspace 2 dataset. (We chose this dataset
because it had relatively high performance with both types
of individual features and the stream classiﬁer.) We observe
that local feature performance declines as more images are
occluded, while the accuracies of the global features and HMM
are relatively stable, decreasing by less than a percentage point.
We save more extensive investigations of occlusion by real
objects and people for future work.
Fig. 6. Sample images from our dataset with synthetic occlusions.
D. Retrieving private images
The experiments so far have cast our problem as one of
image classiﬁcation: given an image known to have been taken
in one of n rooms, identify the correct room. The main goal
of PlaceAvoider, however, is not necessarily to identify the
exact room, but to ﬁlter out images taken from some subset of
potentially private rooms. This is an image retrieval problem:
given a stream of images, we wish to retrieve the private
ones, so that they can be ﬁltered out. Since our classiﬁcation
algorithms are imperfect, the user could provide conﬁdence
thresholds to select between a highly conservative or a highly
selective ﬁlter, depending on their preferences and the degree
of sensitivity of the spaces.
The top row of Figure 7 shows precision-recall curves
for retrieving private images from each of our ﬁve datasets.
9
To generate these, we conducted ﬁve retrieval tasks for each
dataset, one for each room, and then averaged the resulting
P-R curves together. For the local and global features we
used the maximum value (across classes) of PL(li|I) and
PG(li|I), respectively, as the free parameter (conﬁdence), and
for the HMM we used the maximum marginal (across classes)
of P (li|I1, ..., Im) computed by the Forward-Backward algo-
rithm. We see that for House 1, House 3, and Workspace 2
we can achieve 100% recall at greater than 70% precision,
meaning that all private images could be identiﬁed while
removing only 30% of the harmless images. For Workspace 1
we can achieve about 90% precision and recall, whereas for
the very difﬁcult House 2, about 40% precision is possible at
90% recall.
The above results reﬂect the closed scenario, where we
assume that the user has enrolled all possible rooms in the
space. As a preliminary evaluation of the open locale scenario,
we created synthetic streams in which we inserted randomly
chosen segments of streams from other datasets, such that
about 20% of the images in these noisy streams were in
the ‘other class’ category. This can be interpreted as a user
collecting 80% of their images in spaces that are enrolled,
which is arguably reasonable. In practice, the distribution of
time spent amongst spaces in a building will likely be an
individual function. The bottom row of Figure 7 shows the
precision-recall curves in this case. While retrieval accuracy
degrades somewhat compared to the original streams, in three
of the datasets (House 3 and the two Workspaces) we still
observe nearly 100% recall at greater than 80% precision. We
posit that for the vast amounts of photos obtained in lifelogging
applications, such precision values are reasonable as they still
leave a large fraction of harmless images for sharing. The
blocked photos can always be reviewed manually to identify
such false classiﬁcations. While these results are promising,
evaluation on larger-scale, realistic ﬁrst-person datasets will be
needed to characterize performance in real-world open locale
scenarios.
E. Computational performance
Our current version of PlaceAvoider is a proof of concept,
implemented on general purpose workstations with a mixture
of unoptimized C++, Matlab, Python, and R code. This code
takes on average 18.421 seconds to process an image on a
2.6GHz Xeon server. This performance may be reasonable
for cloud-based applications with ofﬂine computation, but ill-
suited for realtime use. We suspect that this running time
could be improved signiﬁcantly through simple optimizations
(like re-writing all code in C++). We now discuss algorithmic
reﬁnements to improve the usability of PlaceAvoider with
mobile devices.
Decreasing local feature matching time. A disadvantage of
our local feature classiﬁer is that the minimizations in Equa-
tion (1) can be computationally intensive, requiring several
seconds per image. However, there is inevitable redundancy
between enrollment images, because each of our enrollment
datasets consists of several rounds of photo collection and
there is spatial overlap between images. We developed four
techniques for reducing the runtime and space requirements
of the classiﬁcation algorithm by attempting to remove the
redundancy from these room models:
TABLE VI.
AVERAGE SINGLE IMAGE CLASSIFICATION TIMES,
INCLUDING BOTH FEATURE EXTRACTION AND CLASSIFICATION FOR
HOUSE 3 ENROLLMENT IMAGES.
Classiﬁer
Global dense bags of SIFT
Local SIFT
Global bags of HOG
Global LBP
Local SIFT (10% blacklists)
Global bags of SIFT
Global GIST
Global RGB histogram
Time (s) Accuracy
68.9%
14.325
95.7%
2.517
66.2%
1.110
1.107
51.9%
55.2%
0.996
89.4%
0.469
65.5%
0.247
0.063
57.4%
•
•
•
•
sensitive hashing is
K-means performs k-means clustering on the set of
SIFT features in a room model, representing the room
simply as the set of cluster centroids;
Locality
a dimensionality-
reduction technique that attempts to preserve spa-
tial relationships between the hashed and unhashed
points [21]. We run LSH and then collapse each hash
bin having multiple points into a single descriptor;
Approximate Nearest Neighbors scans through the set
of descriptors, iteratively collapsing together the two
closest descriptors until a speciﬁed number of target
descriptors is reached. ANN [2] is used to make this
process efﬁcient;