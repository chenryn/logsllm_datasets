a network attack) takes time to affect the physical processes,
our feature vectors are pairs of sensor readings taken at ﬁxed
time intervals. While feature vectors can be extracted from the
normal traces immediately, some pre-processing is required
before they can be extracted from the abnormal ones: the
mutations in some mutant PLC programs may never have
been executed, or only executed after a certain number of
system cycles,
leading to traces either totally or partially
indistinguishable from positive ones. To overcome this, we
compare abnormal traces with normal ones obtained from
the same initial states, discarding wholly indistinguishable
traces, and then extracting pairs of sensor readings only when
discrepancies are detected. With the feature vectors collected,
we apply a supervised ML algorithm, e.g. Support Vector
Machines (SVM), to learn a classiﬁer.
In the third step, we must validate that the classiﬁer is
actually an invariant of the CPS. After applying standard ML
cross-validation to minimise generalisation error, we apply
statistical model checking (SMC) [8] to establish whether or
not there is statistical evidence that the model is an invariant.
In SMC, additional normal traces of the CPS are observed, and
statistical estimation or hypothesis testing (e.g. the sequential
probability ratio test (SPRT) [14]) is used to estimate the
probability of the classiﬁer’s correctness. If the probability
is high (i.e. above some predetermined threshold), we take
that classiﬁer as our invariant. Otherwise, we repeat the whole
process with different randomly sampled data.
With a CPS invariant
learnt, a supervisory system can
monitor live data from the system and query it against the
invariant, raising an alarm when it is not satisﬁed. This has
at least two applications in defending against attacks. First, it
can be used to detect standard network attacks, where packets
have been manipulated and actuators are shifted into states
that are inappropriate for the current physical environment.
Second, it can be seen as a form of code attestation: if the
actual behaviour of a CPS does not satisfy our mathematical
model of it (i.e. the invariant), then it is possible that the cyber
part has been compromised and that ill-intended manipulations
are occurring. This form of attestation is known as physical
attestation [9, 15], and while weaker than typical software- and
hardware-based attestation schemes (e.g. [16–19]), it is much
more lightweight as neither the ﬁrmware nor the hardware of
the PLCs need to be modiﬁed.
III. IMPLEMENTING OUR APPROACH
In this section, we describe in detail the main steps of our
approach: (1) generating mutants and data traces; (2) collecting
positive and negative feature vectors for learning a classiﬁer;
and (3) validating the classiﬁer.
We illustrate each of the steps in turn by applying them
to the SWaT simulator. We remark that our choice to use the
SWaT simulator (rather than the testbed) has some important
advantages for this paper. It allows us to automate each step
in an experimental framework, with which we can easily
investigate the effects of different parameters on the accuracy
of learnt models. Furthermore, mutations can be applied and
attacks can be simulated without the risk of damage, and
the usefulness of learnt invariants can be assessed without
wasting resources (e.g. water, chemicals) or navigating the
policy restrictions of the testbed. Obtaining an invariant for
the testbed can be achieved by re-running the trace collection
phase on SWaT with optimised parameters for learning (see
Section IV), or improving the accuracy of the physical model
in the simulator to the extent that learnt classiﬁers can be
validated as invariants of both the simulator and the testbed.
A. First Step: Generating Mutants and Traces
The ﬁrst step of our approach is collecting the traces of
raw sensor data that will subsequently be used for learning a
CPS invariant. It consists of the following sub-steps: (i) ﬁxing
a set of initial physical conﬁgurations and a time interval
for taking sensor readings; (ii) generating data traces that
represent normal system behaviour; (iii) applying mutations
and generating the (possibly) abnormal traces they produce.
Sub-step (i): Initial Conﬁgurations.
In order to collect a set
of data that captures the CPS’ behaviour across a variety of
physical contexts, a set of initial conﬁgurations should be
chosen that covers the extremities of the sensors’ ranges, as
well as randomly selected combinations of values within them.
A time interval for logging sensor readings (e.g. the historian’s
default) should also be chosen, as well as a length of time to
run the CPS from each initial conﬁguration.
Applied to SWaT. In the case of the SWaT simulator, since
it only models physical processes concerning water ﬂow, we
collect traces of data from sensors recording the water levels
in the ﬁve tanks. In particular, physical conﬁgurations are
expressed in terms of the water levels recorded by these
ﬁve sensors. The set of initial conﬁgurations we use in
our experiments (see Section IV) therefore includes different
combinations of water tank levels, including extreme values
(i.e. tanks being full or empty). We choose to log the sensor
values every 5ms, corresponding to the default time interval
at which the simulator logs data. We ﬁx 30 minutes as the
length of time to run the simulator from each conﬁguration,
as previous experimentation has shown that the simulator’s
physical model remains accurate for at least this length of
time.
Sub-step (ii): Normal Traces. To generate normal traces,
we simply launch the CPS under normal operating conditions
from each initial physical conﬁguration, using the run length
and time interval ﬁxed in sub-step (i). The traces of sensor
data should be extracted from the historian for processing in
a later step.
Applied to SWaT. For our case study, we built a frame-
work [13] around the SWaT simulator that can automatically
launch and run the software on each of the initial conﬁgura-
tions chosen earlier. Each run uses the original (i.e. unaltered)
PLC programs, lasts for 30 minutes, and logs the simulated
water tank levels every 5ms. These logs are stored as raw text
ﬁles from which feature vectors are extracted in a later step.
Sub-step (iii): Mutants and Abnormal Traces. Next, we
need to generate data traces representing abnormal system
behaviour. In order to learn a classiﬁer that is as close to
the boundary of normal and abnormal behaviour as possible,
we generate these traces after subjecting the control soft-
ware to small syntactic code changes (i.e. mutations). These
code changes are the result of applying simple mutation
operators, which randomly replace some Boolean operator,
logical connector, arithmetic function symbol, constant, or
variable. To ensure a diverse enough training set, we generate
abnormal traces from multiple versions of the control software
representing a variety of different mutations.
Our approach for generating mutant PLC programs is
summarised in Algorithm 2. Given a set of co-operating
PLC programs, the algorithm makes a copy of all of them,
and applies an applicable mutation operator to a single PLC
program in the set.
Applied to SWaT. In the case of the SWaT simulator, our
framework can automatically and randomly generate multiple
mutant simulators. Note that each mutant simulator, built up
of six PLC programs, consists of one mutation only in a
PLC program chosen at random. Since the PLC programs are
syntactically simple, we need only six mutation operators (Ta-
ble I). Evidence suggests that additional mutation operators are
unlikely to increase coverage [20], so our mutant simulators
should be sufﬁciently varied.
To illustrate, consider the code in Listing 1, a small extract
from the PLC program controlling ultraﬁltration in SWaT. If
the guard conditions are met, line 5 will change the state of
the PLC to “19”. This number identiﬁes a branch in a case
statement (not listed) that triggers the signals that should be
sent to actuators. Now consider Listing 2: this PLC program
SNIPPET OF UNMODIFIED CONTROL CODE FROM PLC #3
Listing 1
A POSSIBLE MUTANT OBTAINED FROM LISTING 1
Listing 2
1 if Sec P :
2
MI. Cy P3 . CIP CLEANING SEC =HMI. Cy P3 .
1 if Sec P :
2
MI. Cy P3 . CIP CLEANING SEC =HMI. Cy P3 .
CIP CLEANING SEC +1
if HMI. Cy P3 . CIP CLEANING SEC>HMI.
Cy P3 . CIP CLEANING SEC SP or self
. Mid NEXT :
self. Mid NEXT =0
HMI.P3.State =19
break
3
4
5
6
3
4
5
6
CIP CLEANING SEC +1
if HMI. Cy P3 . CIP CLEANING SEC>HMI.
Cy P3 . CIP CLEANING SEC SP or self
. Mid NEXT :
self. Mid NEXT =0
HMI.P3.State =14
break
Algorithm 2: Generating Mutant PLC Code
Input: A set of PLC programs S
Output: A mutant set of PLC programs SM
1 Let Ops be the set of mutation operators;
2 Make a copy SM of the PLC programs S;
3 applied := f alse;
4 while ¬applied do
5
6
7
8
9
Apply an applicable operator to line i;
applied := true;
Randomly choose a PLC P from SM ;
Randomly choose a line number i from P ;
if some operator in Ops is applicable to line i then
10 return SM ;
TABLE I
MUTATION OPERATORS
Mutation Operator
Scalar Variable Replacement
Arithmetic Operator Replacement
Relational Operator Replacement
Guard Valuation Replacement
Logical Connector Replacement
Assignment Operator Replacement
Example
x = a (cid:32) x = b
a + b (cid:32) a − b
a > b (cid:32) a ≥ b
if(c) (cid:32) if(false)
a and b (cid:32) a or b
x = a (cid:32) x + = a
is identical to Listing 1, except for the result of a scalar
mutation on line 5 that means the PLC would be set to state
“14” instead. If executed, different signals will be sent to the
actuators, potentially causing abnormal effects on the physical
state—as might be the goal of an attacker.
Once we have our mutant simulators, we discard any that
cannot be compiled. Of the mutants remaining, we run them
with respect to each initial state for 30 minutes, logging the
levels of all the water tanks every 5ms.
The current implementation of our mutant simulator gener-
ator for SWaT is available online [13], consisting of just over
200 lines of Python code. It applies mutations to the PLC
programs by reading them as text ﬁles, randomly choosing
a line, and then randomly applying an applicable mutation
operator (Table I) by matching and substituting. This takes a
negligible amount of time, so hundreds of mutant simulators
can be generated very quickly (i.e. in seconds).
B. Second Step: Collecting Feature Vectors, Learning
At this point, we have a collection of raw data traces gener-
ated by normal PLC programs as well as by multiple mutant
PLC programs. The second step is to extract positive and
negative feature vectors from this data to perform supervised
learning. It consists of the following sub-steps: (i) ﬁxing a
feature vector type; (ii) collecting feature vectors from the
data, undersampling the abnormal data to maintain balance;
(iii) applying a supervised learning algorithm.
Sub-step (i): Feature Vector Type. A feature vector type must
be deﬁned that appropriately represents objects of the data. For
traces of sensor data, a simple feature vector would consist of
the sensor values at any given time point. For typical CPS
however, such a feature vector is far too simple, since it does
not encapsulate any information about how the values evolve
over the time series—an intrinsic part of the physical model.
A more useful feature vector would record the values at ﬁxed
time intervals, making it possible to learn patterns about how
the levels of tanks change over the time series.
Applied to SWaT. In the case of the SWaT simulator, we
deﬁne our feature vectors to be of the form (π, π(cid:48)), where π
denotes the water tank levels at a certain time and π(cid:48) denotes
the values of the same tanks after d time units, where d is
some ﬁxed time interval that is a multiple of the interval
at which data is logged (we compare the effects of different
values of d in Section IV-B). Our feature vectors are based on
the sliding window method that is commonly used for time
series data [21].
Sub-step (ii): Collecting Feature Vectors. Next,
the raw
normal and abnormal data traces must be organised into
positive and negative feature vectors of the type chosen in sub-
step (i). Extracting positive feature vectors from the normal
data is straightforward, but for negative feature vectors, we
have the additional difﬁculty that mutants are not guaranteed
to be effective, i.e. able to produce data traces distinguishable
from normal ones. Furthermore, even effective mutants may
Algorithm 3: Collecting Feature Vectors
Input: Set of normal traces TN and abnormal traces TA,
each trace of uniform size N
Output: Set of positive feature vectors P o; set of
negative feature vectors N e
1 Let S be the unmodiﬁed simulator;
2 Let t be the time interval for logging data in traces;
3 Let d be the time interval for feature vectors;
4 x := 0; P o := ∅; N e := ∅;
5 foreach T r ∈ TN do
while x + (d/t) < N do
11 x := 0;
12 foreach T r ∈ TA do
while x + (d/t) < N do
6
7
8
9
10
13
14
15
16
17
18
19
20
π := (cid:104)s0, s1, . . .(cid:105) for all sensor values si at row
x of T r;
π(cid:48) := (cid:104)s(cid:48)
0, s(cid:48)
x + (d/t) of T r;
P o := P o ∪ {(π, π(cid:48))}
x := x + 1;
1, . . .(cid:105) for all sensor values s(cid:48)
i at row
1, . . .(cid:105) for all sensor values s(cid:48)
π := (cid:104)s0, s1, . . .(cid:105) for all sensor values si at row
x of T r;
π(cid:48) := (cid:104)s(cid:48)