We extract the information of co-located IXP and co-located private peering
facilities from IXP data.
Model Design. Predicting route decisions is to choose the best route among
several candidate routes. This problem can be formulated as a ranking problem,
i.e., ranking candidate routes according to the preferences set by decision AS and
selecting the most preferred route as the best route. Learning to rank (in short,
LTR) [28] is a class of machine learning algorithms for solving real-world ranking
problems. To achieve this goal, we use a state-of-the-art pairwise LTR algorithm,
LambdaMART [29] to learn the route behaviors from observed routing data and
predict route decisions of stranger ASes.
2 In machine learning, one hot encoding is a method of converting categorical values
into binary vectors.
RouteInfer: Inferring Interdomain Paths
229
Fig. 9. Framework of the route decision model based on LambdaMART
We begin by reviewing the LambdaMART algorithm. LambdaMART is a
pairwise learning to rank algorithm which is approximated by a classiﬁcation
problem, i.e., learning a binary classiﬁer that can tell which route is preferred in
a given pair of candidate routes.
The structure of LambdaMART is based on the multiple additive regres-
sion tree (MART) which is also called gradient boosting decision tree (GBDT).
MART combines many weak learners (which are decision trees here) to come up
with one strong learner. All the trees are connected in series and each tree tries
to minimize the error of the previous tree. The ﬁnal model aggregates the result
of each tree and thus a strong learner is achieved. Figure 9 shows the framework
of our route decision model. Each input instance includes the features of two
candidate routes. The sum of each output of trees can be used to predict the
preference between two candidate routes.
LambdaMART deﬁnes the gradient λ as follows:
| ΔN DCG |
(1)
−σ
λij =
1 + eσ(si−sj )
σ is the parameter that determines the shape of the sigmoid. si and sj are the
predicted preference of candidate route r1 and candidate route r2. Normalized
discounted cumulative gain (NDCG) is a traditional measure of goodness induced
for improving the eﬀectiveness of the model.
LambdaMART uses the Newton-Raphson step to compute the leaf value of
the decision tree. For a function g(γ), a Newton-Raphson towards the extremum
of g is
γn+1 = γn − g
(cid:3)(γn)
g(cid:3)(cid:3)(γn)
(2)
We use the following steps to get our route decision model. After we infer the
policies from public routing data, we simulate route announcements and route
decisions in our AS-routing map for each preﬁx. For the ASes which we know
its best route towards destination preﬁx, we query the AS’s adj-rib-in database
which contains all candidate routes of the AS. Therefore, we can get millions of
230
T. Wu et al.
triplets (decision AS, best route, candidate route) for training our route decision
model. We extract features introduced above from those triples as the input of
the LambdaMART model. The model is initialized as a constant value. Then
the model creates N trees iteratively. In each iteration, we assign leaf values by
the newton step and update the model. The pseudocode of our route decision
model is shown in Appendix D.
In conclusion, we infer interdomain paths in the following steps. Suppose we
want to infer the routes towards preﬁx p. First, the route is announced from
the original AS which hosts the preﬁx p. Then, we simulate the process of route
announcements and route decisions of each AS. When an AS a received a route
from a neighbor AS, it will ﬁrst query its 3-layer policies. AS a will search for
the policy which is set for the route. It will ﬁrst consider preﬁx policies, then
destAS policies, then neighbor policies. If there are even no neighbor policies for
it to make the route decision, AS a will use our route decision model to predict
the best route. After that, AS a will announce the best route to neighbor ASes
according to the export policies we set for AS a. After routing convergence, we
can get the best paths between all ASes to the destination preﬁx p. Those paths
are the inference results of our RouteInfer algorithm.
5 Evaluation and Analysis
In this section, we evaluate our inference algorithm RouteInfer. We evaluate the
overall accuracy of RouteInfer against state-of-the-art interdomain path infer-
ence algorithms. Besides, we evaluate the improvement of two key components
(i.e., 3-layer policy model and route decision model) respectively. Furthermore,
we analyze inferred routing behaviors of ASes and try to ﬁnd reasons for the
discrepancy between standard policies in theory and routing behaviors in real-
ity. We demonstrate that RouteInfer can achieve high accuracy in path inference
and help us better understand routing behaviors in the following ﬁve aspects:
Overall Accuracy (Sect. 5.2). RouteInfer achieves higher accuracy compared
with ﬁve state-of-the-art interdomain path inference algorithms with about
81.64% accuracy on average.
Improvement of 3-Layer Policy Model (Sect. 5.3). Our 3-layer policy
model performs up to 133% better than single-kind policy models. Besides, the
3-layer policy model can achieve high accuracy and good generalization ability
at the same time.
Improvement of Route Decision Model (Sect. 5.4). Our route decision
model based on learning to rank performs up to 313% better than default policies
used in prior works. Besides, our model is explainable and can tell us which
features are important for route decisions.
Analysis of 3-Layer Policies (Sect. 5.5). We further analyze the 3-layer poli-
cies we get. We ﬁnd that ASes in high-tiers tend to set ﬁne-grained policies and
ASes in low-tiers tend to set coarse-grained policies. Besides, we ﬁnd most of
ASes set preﬁx policies for the preﬁxes belonging to CDN ASes.
RouteInfer: Inferring Interdomain Paths
231
Analysis of Route Decision Model (Sect. 5.6). We investigate feature
importance of our explainable model. We ﬁnd that the tier of next-hop AS is
the most important feature. Besides, we ﬁnd that many ASes prefer the routes
received from providers to the routes received from peers, and it does not follow
the standard preference rule. We also ﬁnd those violations are related to p2p
links in European IXPs.
5.1 Datasets
BGP Routing Data. We use BGP routing data from RouteViews [30], RIPE
RIS [31] and Isolario [32] as the input data of RouteInfer. Snapshots of BGP
routing tables are on the ﬁrst day of January 2020, which are collected from
around 747 vantage points (VPs) by 50 route collectors. We preprocess the raw
dataset by ﬁltering mistakes or noises that impact the path inference. We remove
duplicated ASes that result from path prepending and ﬁlter paths with AS loops
or reserve AS numbers. IXPs typically have their own AS number and should
not add their ASN in the BGP path in best practices [33]. But sometimes it
may happen due to debugging. Thus we remove IXP AS numbers from the BGP
paths. Please notice that the Internet topology constructed from BGP routing
data is incomplete, i.e., there are many invisible links [34]. We do not try to
improve the completeness of the topology and it is a limitation of our work.
IRR Data. IRR data is mainly used to investigate the challenge mentioned in
Sect. 3. We get IRR data from RADb [25] which provides the largest routing
registry mirror site in the Internet on August 1, 2021. IRR data is recorded by
Routing Policy Speciﬁcation Language (RPSL) [35]. Thus we need to parse the
IRR data according to the semantic of RPSL.
BGP Community Data. BGP community is a transitive BGP attribute used
to attach metadata on BGP paths. This dataset is used to investigate the chal-
lenge mentioned in Sect. 3 and to validate the accuracy of inferred policies in
Sect. 5.3. BGP community value is extracted from BGP routing data mentioned
before (snapshots on January 1, 2020). The semantics of BGP communities is not
standardized, many ASes publicly document the meaning of their BGP commu-
nities on their websites [36,37], one step [38], and IRR database [25], enabling
us to assemble a dictionary that records how the ASes set import policies by
BGP communities. Finally, we know the meanings of BGP community values of
56 diﬀerent ASes.
IXP Data. IXP data is used to identify the co-located IXPs and co-located
facilities used in the feature extraction of our route decision model and also used
in the analysis in Sect. 5.6. IXP data can be used to identify where p2p links are
located. We get IXP data from PeeringDB [39], the Euro-IX IXP Service Matrix
[40], and Packet Clearing House [41] on January 1, 2020.
232
T. Wu et al.
5.2 Overall Accuracy
Evaluation Methodology. To evaluate the accuracy of inferred paths, we split
BGP routing data into a training set and a test set. We use the training set as the
input of RouteInfer and use the test set to evaluate the accuracy of the inferred
paths. This evaluation methodology is widely used in prior path inference works
[4,15–17].
We give a brief
introduction of
ﬁve state-of-the-art path inference
algorithms. SIGCOMM06 [15] is the
ﬁrst work to use the preﬁx policy
model to infer policies. It initializes
import policies by choosing the short-
est path and initializes export poli-
cies by announcing all routes to all
neighbors. It infers the preﬁx poli-
cies of ASes by iterative simulation.
KnownPath [16] also uses preﬁx pol-
icy model to infer AS paths. It infers
paths based on known paths observed
from the BGP routing table and uses
standard policies to infer unknown
paths of ASes. iPlane Nano [4] is the
ﬁrst work to use the neighbor policy model to infer policies. It infers the export
policies of ASes by extracting the three consecutive ASes in AS paths and infers
import policies by comparing observed paths and alternative routes. Routing
Tree [18] algorithm infers paths using standard policies. It uses a three-stage
breadth-ﬁrst search to quickly compute paths from all source ASes to a desti-
nation AS. PredictRoute [17] uses preﬁx policy model to infer policies. It trains
Markov chains towards each preﬁx to predict paths. For the ASes which is not
in the Markov chain, PredictRoute will use standard policies to infer paths.
Fig. 10. Overall accuracy against other
algorithms
We randomly select 90% (672) VPs and use the routing data observed from
those VPs as the training set and the routing data observed from the remaining
10% (75) VPs as the test set. We conduct a classic 10-fold cross-validation,
repeated 10 times.
Figure 10 depicts the overall inference accuracy for RouteInfer and the other
ﬁve state-of-the-art algorithms. We can see that, compared with the ﬁve algo-
rithms, RouteInfer is always more accurate and stable, with accuracy between
79.63% and 83.39%. RouteInfer improves the average accuracy 182.3% than that
of Routing Tree, 87% than that of iPlane Nano, 55.9% than that of PredictRoute,
50.79% than that of SIGCOMM06, and 30.04% than that of KnownPath.
5.3
Improvement of 3-Layer Policy Model
Next, we evaluate the improvement of the two key components of RouteInfer,
the 3-layer policy model and the route decision model respectively. First, we
evaluate the improvement of the 3-layer policy model.
RouteInfer: Inferring Interdomain Paths
233
Comparison with Single-Kind Policy Model. We compare the accuracy
of the 3-layer policy model with single-kind policy models, including preﬁx pol-
icy model, destAS policy model, neighbor policy model, and standard policies.
Please notice that, for some single-kind policy models, we cannot infer the poli-
cies of all ASes. We ﬁrst investigate in our test set, how many routes for which
we have corresponding policies to infer the path and how many routes with
inferred policies can be inferred correctly. For a given route, if we have inferred
policies of each AS in the route, we say this route is covered by our inferred poli-
cies. We deﬁne coverage that is the proportion of routes which we have inferred
policies. We deﬁne accuracy which is the proportion of covered routes that are
inferred correctly. Figure 11(a) shows the coverage and accuracy of diﬀerent pol-
icy models. We can see that the preﬁx policy model can achieve 100% accuracy
for covered routes but has limited coverage. As the example shown in Fig. 5(a),
if we infer a route and we do not have the preﬁx policy which is set for the des-
tination preﬁx of that route, then we can only use the default policy to infer the
routes. On the contrary, if using standard policies, we can infer any end-to-end
route in the Internet. However, it can not achieve high accuracy for those routes.
Therefore, single-kind policy models do not have good generalization ability. Our
3-layer policy model consists of three kinds of policies. Coarse-grained policies
ensure that our policy model can achieve extensive coverage. Fine-grained poli-
cies ensure that our policy model can achieve high accuracy in path inference.
Thus, the 3-layer policy model has good generalization ability, with high accu-
racy and extensive coverage at the same time.
Fig. 11. Improvement of 3-layer policy model
Then we set default policies for the ASes without policies and investigate
the accuracy of each policy model, If there are some ASes we cannot infer their
policies, the import policies of those ASes will be set to choosing the shortest
valley-free path. Figure 11(b) depicts the accuracy of the 3-layer policy model
and single-kind policy model. We can see that the 3-layer policy model achieves
higher accuracy than single-kind policy models, with accuracy between 66.82%
and 72.98%. 3-layer policy model improves the average accuracy of 52.38% than
234
T. Wu et al.
that of preﬁx policy model, 47.61% than that of destAS policy model, 133.7%
than that of business relationship model (standard policies), and 114.9% than
that of neighbor policy model.
Validation of 3-Layer Policies by BGP Communities. We try to use the
BGP community data to validate our inferred policies. Please notice that we
can not guarantee the quality of BGP community data. But we can use the
consistency between our results and the BGP community data to judge whether
our results are reliable. As mentioned in Sect. 3, we know the semantics of BGP
community values of 56 ASes and only 17 ASes community values can be found in
BGP routing data. For example, we ﬁnd AS1273 uses community value 1273: 70
to the route received from neighbor AS2129, and it means setting preference 70.
AS1273 uses community value 1273: 90 to the route received from neighbor
AS12969, and it means setting preference 90. Thus, we can know the policy
that AS1273 prefers AS12969 to AS2129. We extract 13492 policies of those 17
ASes from their BGP community data. 12643 policies can be used to validate
our inferred policies (other policies cannot be inferred due to incomplete routing
data). In those 12643 policies, about 79.46% policies are consistent with our
inferred policies. We can see that our inferred policies are highly consistent with
BGP community data.
5.4
Improvement of Route Decision Model
In this subsection, we evaluate the improvement of the route decision model
based on learning to rank.
Fig. 12. Performance of three models
Model Selection. Typically, LTR approaches can be categorized into three
groups: pointwise, pairwise, and listwise approaches. Pointwise approaches aim
to predict the preference of a single route. Pairwise approaches aim to predict
the preference between a pair of routes. Listwise approaches aim to predict the