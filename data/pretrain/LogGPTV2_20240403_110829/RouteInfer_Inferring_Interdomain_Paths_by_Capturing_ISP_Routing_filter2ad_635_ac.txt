### Information Extraction and Model Design

We extract information on co-located Internet Exchange Points (IXPs) and co-located private peering facilities from IXP data. Our model is designed to predict route decisions by selecting the best route among several candidate routes, which can be formulated as a ranking problem. The goal is to rank the candidate routes according to the preferences set by the decision-making Autonomous System (AS) and select the most preferred route. To achieve this, we employ a state-of-the-art pairwise Learning to Rank (LTR) algorithm, LambdaMART [29], to learn route behaviors from observed routing data and predict route decisions for unfamiliar ASes.

### One-Hot Encoding in Machine Learning

In machine learning, one-hot encoding is a method of converting categorical values into binary vectors.

### RouteInfer: Inferring Interdomain Paths

#### Framework of the Route Decision Model Based on LambdaMART

We begin by reviewing the LambdaMART algorithm. LambdaMART is a pairwise LTR algorithm that approximates the ranking problem as a classification problem, where a binary classifier is learned to determine the preferred route in a given pair of candidate routes.

The structure of LambdaMART is based on Multiple Additive Regression Trees (MART), also known as Gradient Boosting Decision Trees (GBDT). MART combines multiple weak learners (decision trees) to form a strong learner. Each tree in the series aims to minimize the error of the previous tree. The final model aggregates the results from each tree, resulting in a robust learner. Figure 9 illustrates the framework of our route decision model, where each input instance includes features of two candidate routes, and the sum of the outputs from the trees is used to predict the preference between the two routes.

LambdaMART defines the gradient \(\lambda\) as follows:
\[
\lambda_{ij} = \frac{|\Delta NDCG|}{1 + e^{\sigma(s_i - s_j)}}
\]
where \(\sigma\) is a parameter that determines the shape of the sigmoid function, \(s_i\) and \(s_j\) are the predicted preferences of candidate routes \(r_1\) and \(r_2\), and Normalized Discounted Cumulative Gain (NDCG) is a traditional measure of model effectiveness.

LambdaMART uses the Newton-Raphson step to compute the leaf value of the decision tree. For a function \(g(\gamma)\), the Newton-Raphson step towards the extremum of \(g\) is:
\[
\gamma_{n+1} = \gamma_n - \frac{g'(\gamma_n)}{g''(\gamma_n)}
\]

To build our route decision model, we first infer policies from public routing data and then simulate route announcements and decisions in our AS-routing map for each prefix. For ASes with known best routes to destination prefixes, we query the AS's adj-rib-in database, which contains all candidate routes. This process yields millions of triplets (decision AS, best route, candidate route) for training the model. We extract features from these triplets as inputs for the LambdaMART model, which is initialized with a constant value. The model iteratively creates \(N\) trees, assigning leaf values using the Newton step and updating the model in each iteration. The pseudocode for our route decision model is provided in Appendix D.

### Inference Process

To infer interdomain paths, we follow these steps. Suppose we want to infer routes towards prefix \(p\):
1. The route is announced from the original AS hosting prefix \(p\).
2. We simulate the route announcement and decision process for each AS.
3. When an AS \(a\) receives a route from a neighbor AS, it queries its three-layer policies: prefix policies, destAS policies, and neighbor policies.
4. If no neighbor policies are available, AS \(a\) uses our route decision model to predict the best route.
5. AS \(a\) then announces the best route to its neighbors according to the export policies we set.
6. After routing convergence, we obtain the best paths between all ASes to the destination prefix \(p\).

### Evaluation and Analysis

#### Overall Accuracy

We evaluate the overall accuracy of RouteInfer against five state-of-the-art interdomain path inference algorithms. RouteInfer achieves an average accuracy of 81.64%, outperforming the other algorithms by significant margins.

#### Improvement of 3-Layer Policy Model

Our 3-layer policy model, which includes prefix, destAS, and neighbor policies, performs up to 133% better than single-kind policy models. It achieves high accuracy and good generalization, balancing both coverage and precision.

#### Improvement of Route Decision Model

Our route decision model, based on learning to rank, performs up to 313% better than default policies used in prior works. Additionally, the model is explainable, allowing us to identify important features for route decisions.

#### Analysis of 3-Layer Policies

We find that high-tier ASes tend to set fine-grained policies, while low-tier ASes set coarse-grained policies. Most ASes set prefix policies for prefixes belonging to Content Delivery Network (CDN) ASes.

#### Analysis of Route Decision Model

Feature importance analysis reveals that the tier of the next-hop AS is the most critical feature. Many ASes prefer routes received from providers over peers, contrary to standard preference rules. These violations are often related to peer-to-peer links in European IXPs.

### Datasets

#### BGP Routing Data

We use BGP routing data from RouteViews [30], RIPE RIS [31], and Isolario [32] collected on January 1, 2020, from approximately 747 vantage points (VPs) by 50 route collectors. We preprocess the data to remove duplicates, loops, and reserved AS numbers, and exclude IXP AS numbers from BGP paths.

#### IRR Data

IRR data from RADb [25] (collected on August 1, 2021) is used to parse and investigate routing policies recorded in RPSL.

#### BGP Community Data

BGP community data, extracted from BGP routing data, is used to validate inferred policies. We have assembled a dictionary of BGP community values for 56 different ASes.

#### IXP Data

IXP data from PeeringDB [39], Euro-IX IXP Service Matrix [40], and Packet Clearing House [41] (collected on January 1, 2020) is used for feature extraction and analysis.

### Evaluation Methodology

We split the BGP routing data into a training set (90% VPs) and a test set (10% VPs) and perform 10-fold cross-validation repeated 10 times. RouteInfer consistently outperforms other algorithms, achieving an accuracy range of 79.63% to 83.39%.

### Improvement of 3-Layer Policy Model

#### Comparison with Single-Kind Policy Models

The 3-layer policy model achieves higher accuracy and coverage compared to single-kind policy models. It improves the average accuracy by 52.38% over the prefix policy model, 47.61% over the destAS policy model, 133.7% over the business relationship model, and 114.9% over the neighbor policy model.

#### Validation by BGP Communities

Using BGP community data, we validate our inferred policies, finding that about 79.46% of the 12,643 policies are consistent with our inferred policies.

### Improvement of Route Decision Model

#### Model Selection

LTR approaches can be categorized into pointwise, pairwise, and listwise methods. Pairwise approaches, like LambdaMART, aim to predict the preference between a pair of routes. Our model outperforms other methods, demonstrating significant improvements in route decision accuracy.