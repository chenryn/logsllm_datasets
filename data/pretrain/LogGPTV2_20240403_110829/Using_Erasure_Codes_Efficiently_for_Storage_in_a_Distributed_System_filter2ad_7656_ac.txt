which restores full recoverability of the system. This mechanism even
works if the threshold tp of client failures was exceeded, as long as
no storage nodes have crashed.
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
if recover not yet running locally then fork recover()
Code for client p:
Global variables: data[i] for i = 1, . . . , n
procedure start recovery()
1
procedure recover()
2
3
4
5
6
r[j] ← Sj .trylock(L1)
if r[j].status = ⊥ then
for j ← 1 . . . n do
pfor each (cid:2) ≤ j such that r[(cid:2)].status = OK do S(cid:1).setlock(r[(cid:2)].oldlmode)
return
// phase 2 starts: now we are running solo
for j ← 1 . . . n do data[j] ← Sj .get state()
if for some h, data[h].opmode = RECONS then
cset ← data[h].recons set−{j : data[j].opmode = INIT}
7
8
9
10 else
11
12
13
14
15
16
17
18
19
20
cset ← ﬁ nd consistent()
slack ← td − |{j : data[j].opmode = INIT}|
while |cset| < k + slack do
pfor j ← k + 1 . . . n do Sj .setlock(L0)
while |cset| < k + slack do
pfor j ← k + 1 . . . n do data[j] ← Sj .get state()
cset ← ﬁ nd consistent()
slack ← td − |{j : data[j].opmode = INIT}|
pfor j ← k + 1 . . . n do list[j] ← Sj .getrecent(L1)
cset ← cset − {j : list[j] (cid:1)= data[j].recentlist}
21 blocks ← erasure decode(data[∗].block, cset)
22 pfor j ← 1 . . . n do epoch[j] ← Sj .reconstruct(cset, blocks[j])
23 pfor j ← 1 . . . n do Sj .ﬁ nalize(maxa{epoch[a]} + 1)
function ﬁ nd consistent()
24 return a maximal set S such that
(1) ∀i ∈ S : data[i].opmode = NORM,
(2) ∀ redundant blocks r, s ∈ S : ˆfS (r) = ˆfS (s), and
(3) ∀ redundant blocks r ∈ S, ∀ data blocks j ∈ S : ˆHS (r, j) = ˆfS (j)
where ˆHS(i, j) = {x ∈ ˆfS (i) such that x = (cid:4)∗, j, ∗(cid:5) },
ˆfS(i) := tids(data[i].recentlist) − ˆGS,
ˆGS := ∪i∈Stids(data[i].oldlist),
tids(list) is the set of tids of items in list.
// if/then executed atomically
// phase 1 starts: try to lock all blocks
// somebody else locked
// release lock
// read state from all storage nodes
// another client previously crashed during recovery?
// yes, pick up their recovery
// ﬁnd consistent set of blocks
// td is the max number of storage node failures (cf Section 4)
// while consistent set not large enough
// partially release locks to allow add operations
// while consistent set not large enough
// get new state
// ﬁnd consistent blocks
// try to lock blocks before new adds occur
// decode blocks to retrieve data
// write recovered data
// bump epoch, release locks, change to normal opmode
// ﬁnds a set of blocks consistent with erasure code
// only non-crashed blocks
// tids in ˆfS (i) originated by j
// tids in Si’s recentlist minus ˆGS
// tids in some oldlist
// phase 3 starts: now nodes have lmode = L1 and opmode = RECONS, and data[j].block has data for all nodes j ∈ cset
Code for storage node Si:
Global variables: lid, initially ⊥, after fail-remap ⊥
recons set ∈ set of integers
(cid:4)lmode, lid(cid:5) ← (cid:4)lm, caller(cid:5)
if opmode = NORM then blk ← block else blk ← ⊥
if lmode ∈ {L0, L1} then return (cid:4)status : ⊥, lmode(cid:5)
operation trylock(lm)
25
26 oldlmode ← lmode; (cid:4)lmode, lid(cid:5) ← (cid:4)lm, caller(cid:5); return (cid:4)status : OK, oldlmode(cid:5)
operation setlock(lm)
operation get state()
27
28 return (cid:4)opmode, recons set, oldlist, recentlist, blk(cid:5)
operation getrecent(lm)
operation reconstruct(set, blk)
29
30 block ← blk; return epoch
operation ﬁ nalize(ep)
31 epoch ← ep; (cid:4)recentlist, oldlist(cid:5) ← (cid:4)∅, ∅(cid:5)
32
33
upon failure of lid when lmode ∈ {L0, L1} do
34
if opmode = RECONS then opmode ← NORM
lmode ← UNL
(cid:4)lmode, lid(cid:5) ← (cid:4)lm, caller(cid:5); return recentlist
(cid:4)opmode, recons set(cid:5) ← (cid:4)RECONS, set(cid:5)
lmode ← EXP
// identity of client locking block
// saved set of consistent blocks for recovery
// try to lock if not locked yet
// already locked
// update lock mode and return old mode
// set lock mode
// get node’s state for recovery
// if opmode (cid:1)= NORM then block has garbage
return state for recovery
// change lock mode and return recentlist
// recover block
// remember set of blocks used for reconstruction
// write block
// ﬁnish recovery
// advance epoch and clean lists of tids
// back to normal mode
// and unlock storage node
// lid is the client locking block
// expire lock
Fig. 6. Algorithm for recovery.
3.11. Optimizations for sequential I/O and throughput
To optimize sequential I/O, consecutive blocks are mapped to
different storage nodes and different stripes, and the redundant blocks
rotate with each stripe, thus avoiding bottlenecks. In this way, clients
can pipeline sequential I/O and get great bandwidth. As sequential
writes occur, a redundant block R of a storage node is updated
multiple times. When using disks to store data, the storage node
can postpone writing R to disk until after the node knows that the
sequential writes will no longer affect R. This can be determined
when the node sees a write for large enough logical block C. For
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
repeat periodically while not executing WRITE or READ
Code for client p:
task collect garbage
1
2
3
4
5
6
7
8
pfor j ← 1 . . . n do
repeat r[j] ← Sj .gc old(old[j])
until r[j] = OK
pfor j ← 1 . . . n do
repeat r[j] ← Sj .gc recent(gc[j])
until r[j] = OK
old[j] ← gc[j]; gc[j] ← ∅
Code for storage node Si:
operation gc old(list)
if opmode (cid:1)= NORM or lmode (cid:1)= UNL then return ⊥
remove entries in oldlist with tid in list
return OK
operation gc recent(list)
if opmode (cid:1)= NORM or lmode (cid:1)= UNL then return ⊥
for each t ∈ list do
if exists entry in recentlist with tid t then
move entry from recentlist to oldlist
return OK
Fig. 7. Algorithm for garbage collection.
extra performance, R can be laid out on disk so that it is close to C.
Another optimization when writing is to use broadcast to send add
to update the redundant blocks, thus saving client bandwidth. For this
to work, the storage nodes, not the client, must do the multiplication
by αji in line 10 of Fig. 5; clients simply broadcast the new content
subtracted by old content—the same data for all storage nodes.
4. Correctness and Maximum Number of Failures
For correctness, we assume that k ≥ 2 (more than one storage
node), and n − k ≤ k (redundant blocks do not outnumber data
blocks). Let tp and td be the maximum number of client and storage
node failures.
Theorem 1: The algorithms of Section 3 are correct
if td ≤
dSERIAL = (cid:7) n−k
tp+1
− tp
2
(cid:8).
The algorithm in Figure 5 updates to redundant blocks in series (for
loop in lines 10–11). For better performance, we can parallelize the
update by replacing for with a parallel-for (pfor). Then, a common-
case WRITE takes only one swap and one batch of parallel adds. The
tradeoff is reduced fault resiliency, as stated below:
Theorem 2: With parallel adds, the algorithms of Section 3 are
correct if td ≤ dPARALLEL = (cid:7) n−k
2tp
− tp
2
(cid:8).
Corollary 1: To tolerate tp client failures and td storage node
failures, we need δ redundant storage nodes where:
δ = 1 + (tp + 1)(td + tp/2 − 1)
δ = 1 + 2tp (td + tp/2 − 1)
The latency ρ for common WRITES is ρ = 1 + δ (original algorithm)
or ρ = 2 (parallel adds).
(original algorithm), or
(parallel adds).
Due to space limitations, proofs are omitted. They are given in [9].
A hybrid scheme. By corollary 1, the parallel scheme has smaller
latency for common WRITES but much lower tolerance for client
or storage node failures. As a compromise, we can deﬁne a hybrid
parallel-serial scheme, where we partition the set of redundant storage
nodes into s groups G1, . . . , Gs, of size at most r = (cid:7) n−k
(cid:8), where
adds within a group are in parallel, but groups are updated in series.
That is, we replace the for in line 10 in Fig. 5 with
s
for h ← 1 . . . s do
pfor each j ∈ Gh ∩ M do
r[j] ← Sj .add(αji.(v−blk), ntid, otid, epoch)
Theorem 3: With parallel-serial updates, the algorithms of Sec-
tion 3 are correct if td ≤ dSERIAL and r ≤ dSERIAL.
For the parallel-serial scheme to tolerate tp client failures and td
storage node failures, we need the same δ = 1 + (tp + 1)(td +
tp/2 − 1) storage nodes as in the serial update case, but the latency
ρ for common WRITES is ρ = 1 + (cid:7)δ/dSERIAL(cid:8), potentially much
lower for small values of tp (when tp = 0, dSERIAL = δ and ρ = 2).
Resetting the number of failures. After recovery completes, if
no additional processes or storage nodes fail during the recovery then
the system is in a “clean” state, where it can tolerate additional tp
process crashes and td storage node failures.
5. Validation
For validation, we have implemented our protocol and instantiated
a small system with 8 hosts, where we varied the role of a host per
experiment between client and storage node. We also used simulation
to study the behavior of larger systems.
5.1. Implementation
We implemented our protocol in C using RPC in user mode running
over TCP. Storage and clients nodes are multi-threaded. The number
of threads at the server limit the number of RPC calls that are served
simultaneously; at the client, it limits the number of outstanding calls.
We implemented Reed-Solomon codes using hand optimized code for
ﬁeld arithmetic.
We instantiated our implementation in a system with 8 nodes for
varying number of clients and nodes, and various levels of redundancy.
Nodes were 2.4GHz-2.8GHz Pentium 3 or 4 machines with 256MB-
1024MB of memory and a low-end gigabit ethernet card (no jumbo-
frame support). Inter-node latency is 50 µs as reported by ping, and
inter-node network bandwidth is 500Mbits/s as reported by Netperf.
To separate disk performance from our results, we used RAM
memory as the storage medium for data in all experiments. Our results
for latency and throughput correspond to a system with disks in cases
where data is cached or the I/O is sequential with prefetching.
5.2. Simulation
We study larger systems through simulation. In the simulation,
nodes have limited bandwidth and computing power, and the network
also has limited bandwidth. Each client has multiple threads, one for
each outstanding RPC call; there is a processor to serve all threads.
In each thread, each phase of the protocol allocates the processor
and the node’s network adapter for some time for an RPC call,
thus causing latency and consuming node bandwidth. Once an RPC
message is placed on the network, the message incurs latency and
consumes network bandwidth. When an RPC call arrives at the storage
nodes, it allocates the receiving node’s network adapter for some time,
incurring extra latency and consuming node bandwidth. To serve an
RPC call, the storage node incurs some variable latency that depends
on the RPC call. Returning from an RPC is similar to issuing an
RPC. The simulator reports per-node and aggregate throughput for
reads and writes.
We tuned our simulator using the real system to determine values
for the delays to encode and decode blocks for the erasure code,
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
latencies for various operations on the storage node, network latency,
and bandwidth of each node.
6. Results
Our goal is to answer the following questions: (1) Are k-of-n Reed-
Solomon erasure codes fast enough for storage, including with large
k and n? (2) What are the latency and throughput numbers for our
system, and how do they vary with n, k, and the number of clients?
(3) What is the impact of failures on the system? (4) How complicated
are storage nodes, and how much memory does our protocol use?
6.1. Erasure code choice and performance
Fig. 8(a) shows the k-of-n Reed-Solomon codes that we chose for
real (non-simulated) runs with 4-7 storage nodes, together with their
failure resiliency and computation time. Failure resiliency indicates
the maximum tolerated number of client and storage node failures,
e.g., “1c1s, 0c2s” means it tolerates either 1 client crash and 1 storage
crash or 0 client and 2 storage crashes. For computation time, Delta
is the time for ﬁnite-ﬁeld subtraction followed by multiplication of
a 1KB block (at the client node), and Add is the time for ﬁnite-
ﬁeld addition of a 1KB block (at the storage node). Full encode and
full decode are the time to encode and decode a full stripe, used in
recovery. All times are very small, as we wrote carefully optimized
erasure code functions that runs 10-20 times faster than textbook
implementations.
Fig. 8(b) shows the computation time for erasure codes with larger
n and k used in our simulations for a 1KB block. The full-encoding
and -decoding times are close, so the graph only shows encoding.
Times for Delta and Add are combined. With large k,
the full
de/encoding time becomes signiﬁcant, but in the common executions
our scheme only uses Deltas and Add computations, whose times
remain approximately constant even for large k.
Fig. 8(c) shows how many client and storage node crashes we can
tolerate with the k-of-n erasure codes used in our simulations; it
depends only on n − k, not on n or k individually.
6.2. Throughput
Fig. 9(a) shows aggregate write throughput as we vary the number
of outstanding requests of size 1KB each, with 2 clients. Note that (1)
the curves start to ﬂatten after 64 simultaneous requests per client, and
(2) increasing the number k of data storage nodes does not improve
performance much. This is because the client network bandwidth
saturates. The numbers for read throughput (not shown) are typically
4-5 times higher than write throughput, but are otherwise similar.
Fig. 9(b) shows how write aggregate throughput increases with
number of clients; read throughput is similar and thus omitted. The
graph does not have all combinations of erasure code and clients
because we are limited by 8 nodes. The slope of the curves decreases
after 3 clients as the storage nodes’ bandwidth starts to saturate. For
k-of-n erasure codes with larger k, the sloper is higher because there
is more aggregate storage node bandwidth.
Fig. 9(c) shows how write throughput decreases with the redun-
dancy of the erasure code (n−k). The decrease happens because more
redundancy means more data for a client to send, which consumes its
bandwidth faster. The decrease is gentler when k is larger—which is
consistent with our goal to support high-efﬁcient erasure codes with
large n and k, and small n − k.
Fig. 9(d) shows an experiment where two clients are reading and
writing random blocks using a 3-of-5 erasure code. After 28 minutes,
one of the storage nodes crashes, causing throughput to drop to 1/3
for both clients. As clients access unavailable blocks, they recover
those blocks and throughput gradually increases until all blocks are
recovered. In another experiment (not depicted), three clients are
recovering the blocks of a crashed storage node sequentially. The
aggregate recovery throughput is around 17 MB/s, and latency is
around 22ms for a request with 16 blocks.
6.3. Latency
Computation, including ﬁnite-ﬁeld arithmetic for the erasure codes,
contributed to less than 5% of the latency for writes or reads; 95%
of latency is due to communication delays, including network delays,
and TCP and RPC overheads. The total latency for a 4-block write
was less than 3ms for a 3-of-5 code. Note that the storage medium
is memory, and so there is no disk latency. Had we been using disks
with a latency of 10ms, it would dominate.
6.4. Protocol complexity
The implementation has around 5,500 lines of C code: 1,200 for the
erasure code library, 2,000 for clients, 2,000 for storage nodes, and
250 for common thread control. The storage node’s code consists
of independent remote procedures invoked by the client, which we
consider simple because there is little code interdependency.
6.5. Space overhead at storage nodes
The memory used by our protocol at the storage nodes is 10 bytes
per block—a 1% overhead for 1KB blocks. We could reduce this to 6
bytes per block; by increasing the block size to 16KB, it would result
in a 0.04% overhead. Thus, the space overhead beyond the erasure
code redundancy is very small.
6.6. Results from simulation
We used simulation to study throughput for systems with more
hosts than we have. We checked accuracy by simulating our real
system, and found an error of at most 20%.
We considered many combinations of erasure codes with n =
4 . . . 32 and k = 2 . . . 16, and had 1 . . . 64 clients executing opera-
tions simultaneously. Figs. 10(a) and 10(b) show aggregate write and
read throughput respectively as the number of clients varies. For write
throughput, the slope of the curve decreases with higher redundancy
n−k, and the maximum decreases as n decreases and n−k decreases,
as also shown in Fig. 10(c). For reads, the throughput does not depend
on k, only on n, because reads do not involve the redundant nodes.
Fig. 10(d) shows (on a log-scale) the write performance of a
modiﬁed protocol that uses broadcast optimization to update each
redundant block, as described in Section 3.11. With this optimization,
the throughput of 1 client running alone does not decrease as n − k
increases. With 64 clients running simultaneously,
the aggregate
throughput decreases with n − k as the storage nodes’ bandwidth
saturates.
6.7. Evaluation summary
Our approach performs fairly well and offers many performance
and resiliency modes. Failures disrupt a running system, but not
to an extreme. Without broadcasts, a client’s bandwidth becomes a
bottleneck for write throughput if n − k is large. Storage nodes are
simple and keep little control data.
7. Conclusion
Erasure codes are powerful alternatives to replication for storage, as
they provide better space efﬁciency and ﬁner control over the redun-
dancy level. However, they create complications due to complexity
and cohesion of data, especially with concurrent updates and failures.
Here, we propose a new protocol to address these complications. The
protocol has features to make it broadly applicable, and its efﬁciency
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 