/sys/block/sdX/queue 可可调调参参数数
add_random
在某些情况下，熵池中用于 /dev/random 的 I/O 事件成本是可以测量的。在某些情况下要求将其
设定为 0。
max_sectors_kb
默认将发送到磁盘的最大请求设定为 512 KB。这个可调参数可用来增大或者减小该值。最小值为
逻辑块大小；最大值由 max_hw_sectors_kb 设定。有些 SSD 会在 I/O 大小超过内部删除块大小
时性能下降。在此类情况下建议将 max_hw_sectors_kb 降低到删除块大小。您可以使用类似
iozone 或者 aio-stress 的 I/O 生成程序对此进行测试，记录大小可从 512 字节到 1 MB 不等。
50
第 6 章 输入/输出
nomerges
这个可调参数主要用于故障排除。大多数负载都可从请求合并中获益（即使类似 SSD 的告诉存储
也是如此）。但在有些情况下要求禁用合并，比如当您要查看存储后端可处理多少 IOPS 而无需禁
用预读或者执行随机 I/O 时。
nr_requests
每个请求队列都有可为每个读和写 I/O 分配的请求描述符总数限制。这个数的默认值为 128，即在
将某个进程转入睡眠模式时可将 128 个读和 128 个写放入队列。转入睡眠模式的进程是下一个要
分配请求的进程，不一定是已分配所有可用请求的进程。
如果您一个对延迟敏感的程序，则应考虑在您的请求队列中降低 nr_requests 值，并将存储中的
命令队列深度降低到较低的数值（甚至可以降低为 1），这样写回 I/O 就无法分配所有可用请求描
述符，并使用写入 I/O 设备队列填满该设备。分配 nr_requests 后，所有其他尝试执行 I/O 的进
程都会转入睡眠模式等待请求可用。这样更为公平，因为这样会以轮循模式分配请求（而不是让一
个进程很快消耗完所有资源）。注：只有在使用最后期限或者 noop 调度程序时才会有此问题，因
为默认 CFQ 配置可防止出现此类情况。
optimal_io_size
在有些情况下，底层存储会报告最佳 I/O 大小。这在硬件和软件 RAID 中很常见，其中最佳 I/O 大
小是条大小。如果报告该值，则程序应该发出以及最佳 I/O 大小相当会长成倍数的大小的 I/O。
read_ahead_kb
操作系统可探测到程序何时从文件或者磁盘中连续读取数据。在这种情况下，它可执行智能预读算
法，因此用户可能会要求从磁盘中读取更多数据。因此当用户下一步尝试读取数据块时，它已经在
操作系统的页缓存中了。可能的缺点是操作系统可能从磁盘中读取过多数据，这样就会占用页缓存
直到高内存压力将其清除。如果有多个进程执行错误预读就会增加这种情况下的内存压力。
对于设备映射器设备，一般应该增大 read_ahead_kb 值，比如 8192。理由是设备映射器设备通
常有多个基础设备组成。将其设定为默认的值（128 KB）然后乘以要映射的设备数是个好的调整
起点。
rotational
传统硬盘一般都采用轮换模式（比如转盘）。但 SSD 不是。大多数 SSD 会以适当的方式进行宣
传。但如果您遇到设备没有说明有此功能，则可能需要手动将轮换模式设定为 0；禁用轮换模式
后，I/O 提升程序就不使用要减少查询的逻辑，因为在非轮换介质中会有少量查询操作罚分。
rq_affinity
可在与发出 I/O 不同的 CPU 中处理 I/O。将 rq_affinity 设定为 1 可让内核向发出 I/O 的 CPU
传递完成信息。这样可以改进 CPU 数据缓存效果。
51
红帽企业版 Linux 6 性能调节指南
第第 7 章章 文文件件系系统统
阅读本章对支持使用红帽企业版 Linux 的文件系统有一个大致了解，并了解如何优化其性能。
7.1. 为为文文件件系系统统调调整整注注意意事事项项
在所有文件系统有一些通用的注意事项：文件系统中选择的格式化和挂载选项，程序可使用的提高其在所在
系统中性能的动作。
7.1.1. 格格式式化化选选项项
文文件件系系统统块块大大小小
可在执行 mkfs 时选择块大小。不同的系统其有效范围各有不同：上限为主机系统的最大页大小，下限取决
于所使用的文件系统。默认块大小适用于大多数情况。
如果您希望创建大量小于默认块大小的块，您可以设定较小的块大小以尽量减少磁盘空间浪费。注：但设定
较小的块大小可能会限制该文件系统中的最大块，并可以造成额外运行费用，特别是对那些比所选块大小更
大的块。
文文件件系系统统几几何何学学
如果您的系统使用带状存储，比如 RAID5，您可以通过在执行 mkfs 时将数据和元数据与基础存储几何对其
提高其性能。对于软件 RAID（LVM 或者 MD）以及有些企业级存储，可查询并自动设置这些信息，但在很
多情况下必须由管理员在命令行中使用 mkfs 手动设定。
有关创建和维护这些文件系统的信息请参考《存储管理指南》。
外外部部日日志志
需要大量使用元数据的负载意味着日志文件系统（比如 ext4 和 XFS）的 log 部分会非常频繁地更新。要尽
量减少文件系统查询日志的时间，您可以将日志放在专用存储中。注：如果将日志放在速度比主文件系统慢
外部存储中可抵消所有可能的与使用外部存储有关的优势。
警警告告
确定您的外部日志是可靠的。丢失任何外部日志文件都可能造成文件系统死机。
外部日志在运行 mkfs 时创建，并要在挂载时指定日志设备。有关详情请参考
mke2fs(8)、mkfs.xfs(8) 和 mount(8) man page。
7.1.2. 挂挂载载选选项项
Barriers
写入 barrier 是保证在永久存储中正确写入并排列文件系统元数据的内核机制，即使在存储设备会经常断电
的情况也不例外。启用了写入 barrier 的文件系统还可以保证在断电时保存使用 fsync() 进行的所有数据传
输。红帽企业版 Linux 默认在所有支持此功能的硬件上启用 barrier。
但启用写入 barrier 可显著延缓一些程序的速度，特别是使用很多 fsync() 的程序，或者延缓创建和删除大
量小文件的速度。对于没有不稳定写入缓存的存储，或者罕见的文件系统不一致的情况以及断电后出现可以
承受的数据丢失，可使用 nobarrier 挂载选项禁用 barrier。有关详情请参考《存储管理指南》。
52
第 7 章 文件系统
访访问问时时间间（（noatime））
以前在读取文件时，对那个文件的访问时间（atime）必须在内节点元数据中更新，这样就造成额外的 I/O
写入操作。如果不需要准确的 atime 元数据，则请使用 noatime 选项挂载该文件系统以便消除这些元数据
更新。但在大多数情况下，鉴于红帽企业版 Linux 6内核的默认相对 atime（或者 relatime）行为，atime
不是一个大的消耗。relatime 行为只在原有 atime 比修改时间（mtime）或者状态更改时间（ctime）旧
时更新 atime）。
注注意意
启用 noatime 选项还可以启用 nodiratime 行为。但不需要同时设置 noatime 和 nodiratime。
增增加加的的预预读读支支持持
预读可通过预先附加数据并将其载入页面缓存以便提前在内存中而不是磁盘中可用，籍此提高文件访问速
度。有些负载，比如那些涉及连续 I/O 大量流操作的负载可得益于高的预读值。
tuned 工具以及使用 LVM 条带功能可提高预读值，但对有些负载还是不够的。另外，红帽企业版 Linux 不
总是可以根据它可以探测到的您的文件系统设定恰当的预读值。例如：如果一个强大的存储阵列在红帽企业
版 Linux 中只作为单一强大 LUN 出现，则操作系统会将其视为强大的 LUN 阵列，并因此默认不会充分利用
该存储可以使用的预读优势。
请使用 blockdev 命令查看并编辑预读值。要查看某个块设备的当前预读值，请运行：
# blockdev -getra device
要修改那个块设备的预读值，请运行以下命令。N 代表 512 字节扇区中的数值。
# blockdev -setra N device
注：使用 blockdev 命令选择的值重启后不会保留。我们建议创建一个运行等级 init.d 脚本在引导时设
定这个值。
7.1.3. 文文件件系系统统维维护护
放放弃弃不不使使用用的的块块
批丢弃和在线丢弃操作是根据文件系统的功能，可丢弃那些文件系统没有使用的块。这些操作在固态硬盘和
精简配置存储中很有帮助。
批忽略操作由用户明确使用 fstrim命令运行。这个命令忽略文件系统中所有与该用户标准匹配到未使用
块。在还没企业版 Linux 6.2 以及之后 OS 到 XFS 和 ext4 文件系统中支持这两种操作类型，条件是文件系
统到基础块设备支持物理忽略操作。只要 /sys/block/device/queue/discard_max_bytes 不为零就
支持物理忽略操作。
在线忽略操作是在挂载时使用 -o discard 选项指定（可以是在 /etc/fstab 中或者使用 mount 命
令），并实时运行而无需任何用户互动。在线忽略操作只忽略那些从已使用转换到可用状态的块。红帽企业
版 Linux 6.2 以及之后到版本中的 ext4 文件系统以及还没企业版 Linux 6.4 以及之后版本中的 XFS 文件系统
支持在线忽略操作。
红帽建议使用批忽略操作除非系统负载不可使用此类批忽略，或者需要使用在线忽略操作保持其性能。
53
红帽企业版 Linux 6 性能调节指南
7.1.4. 应应用用程程序序注注意意事事项项
预预分分配配
ext4、XFS 和 GFS2 文件系统支持使用 fallocate(2) glibc 调用有效预分配空间。在由于写入模式造成
到大量碎片的文件中可导致读取性能极差。预写入可将磁盘空间标记为已分配给某个文件而无需在那个空间
中写入任何数据。最将实际数据写入预写入到块中钱，读取操作将返回 0。
7.2. 文文件件系系统统性性能能侧侧写写
tuned-adm 工具可让用户轻松地在已设计成为具体使用案例提高性的大量侧写间切换。特别用来提高存储
性能的侧写为：
latency-performance
用于典型延迟性能调整的服务器侧写。它可禁用 tuned 和 ktune 节能机制。cpuspeed 模块改为
performance。每个设备的 I/O 提升程序改为 deadline。cpu_dma_latency 参数使用数值
0（最小延迟）注册管理电源服务质量以便尽可能减小延迟。
throughput-performance
用于典型吞吐性能调整的服务器侧写。如果系统没有企业级存储则建议使用这个侧写。它与
latency-performance 相同，只是：
将 kernel.sched_min_granularity_ns（调度程序最小优先占用时间间隔）设定为 10 毫
秒，
将kernel.sched_wakeup_granularity_ns（调度程序唤醒间隔时间）设定为 15 毫秒。
将 vm.dirty_ratio（虚拟机脏数据比例）设定为 40%，并
启用够名超大页面。
enterprise-storage
建议最企业级服务器配置中使用这个侧写，其中包括电池备份控制程序缓存保护以及管理磁盘缓
存。它与 吞吞吐吐量量性性能能类似，只是：
将 readahead 值设定为 4x，同时
不使用 barrier=0 重新挂载的 root/boot 文件系统。