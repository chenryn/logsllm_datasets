to Snew. The controller ﬁrst gets notiﬁed about the host
movement. It then installs new routing rules in the author-
ity switch, and also installs a rule in Sold redirecting packets
to Snew. If an ingress switch A receives a packet whose des-
tination is H, A may still send the packet to the old egress
point Sold if the cache rule has not expired. Sold then redi-
rects packets to Snew. After the cache rule expires in switch
A, A directs the packets to the authority switch for the cor-
rect egress point Snew and caches the new routing rule.
5. HANDLING WILDCARD RULES
Most ﬂow-management systems simply use microﬂow rules [3]
or transform overlapping wildcard rules into a set of non-
overlapping wildcard rules. However these methods signiﬁ-
cantly increase the number of rules in switches, as shown in
our evaluation in Section 7. To the best of our knowledge,
there is no systematic and eﬃcient solution for handling
overlapping wildcard rules in network-wide ﬂow-management
systems. In this section, we ﬁrst propose a simple and ef-
7In some enterprises, a host changes its identiﬁer when it
moves. The rules also change correspondingly. We can use
the techniques in Section 4.1 to handle the rule changes.
Rule
R1
R2
R3
R4
F1
4
0-7
6-7
14-15
F2 Action
0-15 Accept
5-6
Drop
0-15 Accept
0-15 Accept
(a) Wildcard rules listed in the decreasing
order of priority. (R1 > R2 > R3 > R4)
F1
F2
R2
B1
Cut B
B2
R1
R3
R4
A1
A2
Cut A
(b) Graphical view and two partition solutions.
Figure 4: An illustration of wildcard rules.
ﬁcient solution for multiple authority switches to indepen-
dently insert cache rules in ingress switches. We then discuss
the key ideas of partitioning overlapping wildcard rules, de-
ferring the description of our algorithm to the Appendix.
5.1 Caching Wildcard Rules
Wildcard rules complicate dynamic caching at ingress switches.
In the context of access control, for example in Figure 4,
the packet (F1 = 7, F2 = 0) matches an “accept” rule R3
that overlaps with “deny” rule R2 which has higher priority.
Simply caching R3 is not safe. If we just cache R3 in the
ingress switch, another packet (F1 = 7, F2 = 5) could incor-
rectly pass the cached rule R3, because the ingress switch is
not aware of the rule R2. Thus, because rules can overlap
with each other, the authority switch cannot solely cache
the rule that a packet matches. This problem exists in all
the ﬂow management systems that cache wildcard rules and
therefore it is not trivial to extend Ethane controllers [3] to
support wildcards.
To address this problem, DIFANE constructs one or more
new wildcard rules that cover the largest ﬂow range (i.e., a
hypercube in a ﬂow space) in which all packets take the same
action. We use Figure 4 to illustrate the solution. Although
the rules overlap, which means a packet may match multiple
rules, the packet only takes the action of the rule with the
highest priority. That is, each point in the ﬂow space has
a unique action (which is denoted by the shading in each
spot in Figure 4(b)). As long as we cache a rule that cov-
ers packets with the same action (i.e., spots with the same
shading), we ensure that the caching preserves semantic cor-
rectness. For example, we cannot cache rule R3 because the
spots it covers have diﬀerent shading. In contrast, we can
safely cache R1 because all the spots it covers has the same
shading. For the packet (F1 = 7, F2 = 0), we construct and
cache a new rule: F1 = [6..7], F2 = [0..3].
The problem of constructing new wildcard rules for caching
at a single switch was studied in [17]. Our contribution lies
in extending this approach to multiple authority switches,
each of which can independently install cache rules at ingress
356switches. Given such a setting, we must prevent authority
switches from installing conﬂicting cache rules. To guaran-
tee this, DIFANE ensures that the caching rules installed by
diﬀerent authority switches do not overlap. This is achieved
by allocating non-overlapping ﬂow ranges to the authority
switches, and only allowing the authority switch to install
caching rules in its own ﬂow range. We later evaluate our
caching scheme in Section 7.
5.2 Partitioning Wildcard Rules
Overlapping wildcard rules also introduce challenges in
partitioning. We ﬁrst formulate the partition problem: The
controller needs to partition rules into M parts to minimize
the total number of TCAM entries across all M author-
ity switches with the constraint that the rules should not
take more TCAM entries than are available in the switches.
There are three key ideas in the partition algorithm:
Allocating non-overlapping ﬂow ranges to authority
switches: As discussed in the caching solution, we must
ensure that the ﬂow ranges of authority switches do not
overlap with each other. To achieve this goal, DIFANE ﬁrst
partitions the entire ﬂow space into M ﬂow ranges and then
stores rules in each ﬂow range in an authority switch. For
example, the “Cut A” shown in Figure 4(b) partitions the
ﬂow space on ﬁeld F1 into two equal ﬂow ranges A1 and
A2. We then assign R1, R2 and R3 in A1 to one authority
switch, and R4 to another.
DIFANE splits the rules so that each rule only be-
longs to one authority switch. With the above par-
titioning approach, one rule may span multiple partitions.
For example, “Cut B” partitions the ﬂow space on ﬁeld F2,
which results in the rules R1, R3, and R4 spanning the two
ﬂow ranges B1 and B2. We split each rule into two indepen-
dent rules by intersecting it with the two ﬂow ranges. For
example, the two new rules generated from rule R4 are F1 =
[14..15], F2 = [0..7] → Accept and F1 = [14..15], F2 = [8..15]
→ Accept. These two independent rules can then be stored
in diﬀerent authority switches. Splitting rules thus avoids
the overlapping of rules among authority switches, but at
the cost of increased TCAM usage.
To reduce TCAM usage, we prefer the cuts to align
with rule boundaries. For example, “Cut A” is better
than “Cut B” because “Cut A” does not break any rules. We
also observe that cut on ﬁeld F1 is better than F2 since we
have more rule boundaries to choose. Based on these obser-
vations, we design a decision-tree based partition algorithm
which is described in [16].
In summary, DIFANE partitions the entire rule space into
M independent portions, and thus each authority switch is
assigned a non-overlapping portion. However, within the
portion managed by a single authority switch, DIFANE al-
lows overlapping or nested rules. This substantially reduces
the TCAM usage of authority switches (see Section 7).
Duplicating authority rules to reduce stretch: We
can duplicate the rules in each partition on multiple au-
thority switches to reduce stretch and to react quickly to
authority switch failures. Due to host mobility, we cannot
pre-locate authority switches to minimize stretch. Instead,
we assume traﬃc that is related to one rule may come from
any ingress switches and place replicated authority switches
to reduce the average stretch. One simple method is to ran-
TCAM in a switch
In 
pkts
Access 
control
rules
Measure-
ment rules
Routing
rules
Out 
pkts
Switch
connect
rules
Figure 5: Rules for various management modules.
domly place the replicated switches to reduce stretch. Alter-
natively, by leveraging an approximation algorithm for the
“k-median problem” [18], we can place the replicated author-
ity switches so that they have minimal average stretch to any
pair of switches. Both schemes are evaluated in Section 7.
6. DESIGN AND IMPLEMENTATION
In this section, we present our design and implementation
of DIFANE. First, we describe how our prototype handles
multiple sets of rules from diﬀerent kinds of high-level poli-
cies for diﬀerent management functions. Second, we describe
the prototype architecture, which just add a few control-
plane functions for authority switches to today’s ﬂow-based
switches.
6.1 Managing Multiple Sets of Rules
Diﬀerent management functions such as access control,
measurement and routing may have totally diﬀerent kinds
of policies. To make our prototype eﬃcient and easy to
implement, we generate diﬀerent sets of rules for diﬀerent
policies, partition them using a single partition algorithm,
and process them sequentially in the switch.
Generate multiple sets of low-level rules: Translat-
ing and combining diﬀerent kinds of high-level policies into
one set of rules is complicated and signiﬁcantly increases
TCAM usage. For example, if the policies are to monitor
web traﬃc, and perform destination based routing, we have
to provide rules for (dst, port 80) and (dst, other ports) for
each destination dst. If the administrator changes the policy
of monitoring port 21 rather than port 80, we must change
the rules for every destination. In contrast, if we have dif-
ferent sets of rules, we only need one routing rule for each
destination and a single measurement rule for port 80 traﬃc
which is easy to change.
To distribute multiple sets of rules, the controller ﬁrst par-
titions the ﬂow space to minimize the total TCAM usage. It
then assigns all the rules (of diﬀerent management modules)
in one ﬂow range to one authority switch. We choose to use
the same partition for diﬀerent sets of low-level rules so that
packets only need to be redirected to one authority switch
to match all sets of authority rules.8
Processing packets through multiple sets of rules in
switches:
In switches we have one set of rules for each
management module.9 We process the ﬂow rules sequen-
tially through the rules for diﬀerent modules as shown in
Figure 5. We put access control rules ﬁrst to block mali-
cious traﬃc. Routing rules are placed later to identify the
egress switch for the packets. Finally, the link-state rout-
8One can also choose to provide a diﬀerent partition of the
ﬂow space for diﬀerent sets of low-level rules, but packets
may be redirected to multiple authority switches to match
the authority rules of diﬀerent management modules.
9To make the rule processing simple, we duplicate the same
set of partition rules in the management modules.
357Data packets
Control msgs
Controller
Recv cache
updates 
Send cache
updates
Control 
Plane 
Cache
manager
Data 
Plane
(Click)
Trigger  
cache
manager
Install auth. 
and partition 
rules
Link-state 
Protocol 
(XORP)
Forwarding  
updates
Routing 
updates
with other  
switches
rules cached, otherwise it would forward the packets directly
rather than sending them to the authority switch.10
Data plane: We run Click-based OpenFlow switch [11]
in the kernel as the data plane of DIFANE. Click manages
the rules for diﬀerent management modules and encapsu-
lates and forwards packets based on the switch connection
rules. We implement the packet encapsulation function to
enable tunneling in the Click OpenFlow element. We also
modify the Click OpenFlow element to support the ﬂow rule
action “trigger the cache manager”. If a packet matches the
authority rules, Click generates a message to the cache man-
ager through the kernel-level socket “netlink”. Today’s ﬂow-
based switches already support actions of sending messages
to a local controller in order to communicate with the cen-
tralized controller [4]. We just add a new message type of
“matching authority rules”. In addition, today’s ﬂow-based
switches already have interfaces for the centralized controller
to install new rules. The cache manager then just lever-
ages the same interfaces to install cache rules in the ingress
switches.
7. EVALUATION
Ideally we would like to evaluate DIFANE based on poli-
cies, topology data, and user-mobility traces from real net-
works. Unfortunately, most networks today are still con-
ﬁgured with rules that are tightly bound to their network
conﬁgurations (e.g., IP address assignment, routing, and
VLANs). Therefore, we evaluated DIFANE’s approach against
the topology and access-control rules of a variety of diﬀer-
ent networks toexplore DIFANE’s beneﬁt across various set-
tings. We also perform latency, throughput, and scalability
micro-benchmarks of our DIFANE prototype and a trace-
driven evaluation of our partition and caching algorithms.
To verify the design decisions in Section 2, we evaluate two
central questions in this section: (1) How eﬃcient and scal-
able is DIFANE? (2) How well do our partition and caching
algorithms work in handling large sets of wildcard rules?
7.1 Performance of the DIFANE Prototype
We implemented the DIFANE prototype using a kernel-
level Click-based OpenFlow switch and compared the delay
and throughput of DIFANE with NOX [4], which is a cen-
tralized solution for ﬂow management. For a fair compar-
ison, we ﬁrst evaluated DIFANE using only one authority
switch. Then we evaluated the throughput of DIFANE with
multiple authority switches. Finally we investigated how
fast DIFANE reacts to the authority switch failures.
In the experiments, each sender sends the packets to a
receiver through a single ingress switch, which is connected
directly to either NOX or a DIFANE authority switch as
shown in Figure 7. (In this way, the network delay from the
ingress switch to NOX and the DIFANE authority switch is
minimized. We evaluate the extra delay caused by redirect-
ing through authority switches in Section 7.2.) With NOX,
when a packet does not match a cached rule, the packet
10For UDP ﬂows, they may be a few packets sent to the
authority switch. The authority switch sends one feedback
for each UDP ﬂow, because it takes very low overhead to
send a cache update message (just one UDP packet).
In
addition, we do not need to store the existing cached ﬂow
rules in the authority switch or fetch them from the ingress
switch.
Cache 
rules
Auth.
rules
Partition 
rules
In
pkts.
Switch
connect
rules
Pkt.
Encap.
Out
pkts.
Figure 6: DIFANE prototype implementation. (Cache
manager and authority rules (shaded boxes) only exist
in authority switches.)
ing constructs a set of switch connection rules to direct the
packets to their egress switches.
To implement sequential processing in the switch where
all the rules share the same TCAM, the controller sets a
“module identiﬁer” in the rules to indicate the module they
belong to. The switch ﬁrst initializes a module identiﬁer in
the packet. It then matches the packet with the rules that
have the same module identiﬁer. Next, the switch incre-
ments the module identiﬁer in the packet and matches to
the next set of rules. By processing the packet several times
through the memory, the switch matches the packet to the
rules for diﬀerent modules sequentially. The administrator
speciﬁes the order of the modules by giving diﬀerent module
identiﬁers for the high-level policies in the controller.
A packet may be redirected to the authority switch when
it is in the middle of the sequential processing (e.g., while
being processed in the measurement module). After redi-
rection, the packet will be processed through the following
modules in the authority switch based the module identiﬁer
in the packet.
6.2 DIFANE Switch Prototype
Figure 6 shows both the control and data plane of our
DIFANE switch prototype.
Control plane: We use XORP [19] to run the link-state
routing protocol to maintain the switch-level connectivity,
and keep track of topology changes. XORP also sends up-