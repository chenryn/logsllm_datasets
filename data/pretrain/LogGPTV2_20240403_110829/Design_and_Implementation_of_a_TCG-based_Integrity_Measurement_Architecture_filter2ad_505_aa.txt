title:Design and Implementation of a TCG-based Integrity Measurement Architecture
author:Reiner Sailer and
Xiaolan Zhang and
Trent Jaeger and
Leendert van Doorn
USENIX Association
Proceedings of the
13th USENIX Security Symposium
San Diego, CA, USA
August 9–13, 2004
© 2004 by The USENIX Association
Phone: 1 510 528 8649
All Rights Reserved
FAX: 1 510 548 5738
Rights to individual papers remain with the author or the author's employer.
Email: PI:EMAIL
For more information about the USENIX Association:
WWW: http://www.usenix.org
 Permission is granted for noncommercial reproduction of the work for educational or research purposes.
This copyright notice must be included in the reproduced paper. USENIX acknowledges all trademarks herein.
Design and Implementation of a TCG-based
Integrity Measurement Architecture
Reiner Sailer and Xiaolan Zhang and Trent Jaeger and Leendert van Doorn
IBM T. J. Watson Research Center
19 Skyline Drive, Hawthorne, NY 10532
{sailer,cxzhang,jaegert,leendert}@watson.ibm.com
Abstract
We present the design and implementation of a secure in-
tegrity measurement system for Linux. All executable con-
tent that is loaded onto the Linux system is measured be-
fore execution and these measurements are protected by the
Trusted Platform Module (TPM) that is part of the Trusted
Computing Group (TCG) standards. Our system is the ﬁrst
to extend the TCG trust measurement concepts to dynamic
executable content from the BIOS all the way up into the ap-
plication layer. In effect, we show that many of the Microsoft
NGSCB guarantees can be obtained on today’s hardware and
today’s software and that these guarantees do not require a
new CPU mode or operating system but merely depend on
the availability of an independent trusted entity, a TPM for
example. We apply our trust measurement architecture to a
web server application where we show how our system can
detect undesirable invocations, such as rootkit programs, and
that our measurement architecture is practical in terms of the
number of measurements taken and the performance impact
of making them.
1 Introduction
With the introduction of autonomic computing, grid comput-
ing and on demand computing there is an increasing need to
be able to securely identify the software stack that is running
on remote systems. For autonomic computing, you want to
determine that the correct patches have been installed on a
given system. For grid computing, you are concerned that
the services advertised really exist and that the system is not
compromised. For on demand computing, you may be con-
cerned that your outsourcing partner is providing the software
facilities and performance that have been stipulated in the ser-
vice level agreement. Yet another scenario is where you are
interacting with your home banking or bookselling webser-
vices application and you want to make sure it has not been
tampered with.
The problem with the scenarios above is, who do you trust
to give you that answer? It cannot be the program itself be-
cause is could be modiﬁed to give you wrong answers. For
the same reason we cannot trust the kernel or the BIOS on
which these programs are running since they may be tam-
pered with too. Instead we need to go back to an immutable
root to provide that answer. This is essentially the secure boot
problem [1], although for our scenarios we are interested in
an integrity statement of the software stack rather than ensur-
ing compliance with respect to a digital signature.
The Trusted Computing Group (TCG) has deﬁned a set
of standards [2] that describe how to take integrity measure-
ments of a system and store the result in a separate trusted
coprocessor (Trusted Platform Module) whose state cannot
be compromised by a potentially malicious host system. This
mechanism is called trusted boot. Unlike secure boot, this
system only takes measurements and leaves it up to the re-
mote party to determine the system’s trustworthiness. The
way this works is that when the system is powered on it trans-
fers control to an immutable base. This base will measure the
next part of BIOS by computing a SHA1 secure hash over its
contents and protect the result by using the TPM. This pro-
cedure is then applied recursively to the next portion of code
until the OS has been bootstrapped.
The TCG trusted boot process is composed of a set of or-
dered sequential steps and is only deﬁned up to the bootstrap
loader. Conceptually, we would like to maintain the chain of
trust measurements up to the application layer, but unlike the
bootstrap process, an operating system handles a large vari-
ety of executable content (kernel, kernel modules, binaries.
shared libraries, scripts, plugins, etc.) and the order in which
the content is loaded is seemingly random. Furthermore, an
operating system almost continuously loads executable con-
tent and measuring the content at each load time incurs a con-
siderable performance overhead.
The system that we describe in this paper addresses these
concerns. We have modiﬁed the Linux kernel and the runtime
system to take integrity measurements as soon as executable
content is loaded into the system, but before it is executed.
We keep an ordered list of measurements inside the kernel.
We change the role of the TPM slightly and use it to pro-
tect the integrity of the in-kernel list rather than holding mea-
surements directly. To prove to a remote party what software
stack is loaded, the system needs to present the TPM state us-
ing the TCG attestation mechanisms and this ordered list. The
remote party can then determine whether the ordered list has
been tampered with and, once the list is validated, what kind
of trust it associates with the measurements. To minimize
the performance overhead, we cache the measurement results
and eliminate future measurement computations as long as
the executable content has not been altered. The amount of
modiﬁcations we made to the Linux system were minimal,
about 4000 lines of code.
Our enhancement keeps track of all the software compo-
nents that are executed by a system. The number of unique
components is surprisingly small and the system quickly set-
tles into a steady state. For example, the workstation used by
this author which runs RedHat 9 and whose workload con-
sists of writing this paper, compiling programs, and browsing
the web does not accumulate more than 500 measurement en-
tries. On a typical web server the accumulated measurements
are about 250. Thus, the notion of completely ﬁngerprinting
the running software stack is surprisingly tractable.
Contributions: This paper makes the following contribu-
tions:
• A non-intrusive and veriﬁable remote software stack
attestation mechanism that uses standard (commodity)
hardware.
• An efﬁcient measurement system for dynamic exe-
cutable content.
• A tractable software stack attestation mechanism that
does not require new CPU modes or a new operating
system.
Outline: Next, we introduce the structure of a typical
run-time system, for which we will establish an integrity-
measurement architecture throughout this paper. In Section 3,
we present related work in the area of integrity protecting sys-
tems and attestation.
In Sections 4 and 5, we describe the
design of our approach and its implementation in a standard
Linux operating environment. Section 6 describes experi-
ments that highlight how integrity breaches are made visible
by our solution when validating measurement-lists.
It also
summarizes run-time overhead. Finally, Section 7 sketches
enhancements to our architecture that are being implemented
or planned. Our results show and validate that our architec-
ture is efﬁcient, scales with regard to the number of elements,
successfully recognizes integrity breaches, and offers a valu-
able platform for extensions and future experiments.
2 Problem Statement
To provide integrity veriﬁcation services, we ﬁrst examine the
meaning of system integrity, in general. We then describe a
web server example system to identify the types of problems
that must be solved to prove integrity to a remote system with
a high degree of conﬁdence. We show that the operating sys-
tem lacks the context to provide the level of integrity mea-
surement necessary, but with a hardware root of trust, the op-
erating system can be a foundation of integrity measurement.
Currently, we surmise that it is more appropriate for ﬁnding
integrity bugs than full veriﬁcation, but we aim to deﬁne an
architecture that can eventually be extended to meet our mea-
surement requirements.
2.1
Integrity Background
Our goal is to enable a remote system (the challenger) to
prove that a program on another system (the attesting sys-
tem owned by the attestor) is of sufﬁcient integrity to use.
The integrity of a program is a binary property that indicates
whether the program and/or its environment have been mod-
iﬁed in an unauthorized manner. Such an unauthorized mod-
iﬁcation may result in incorrect or malicious behavior by the
program, such that it would be unwise for a challenger to rely
on it.
While integrity is a binary property, integrity is a relative
property that depends on the veriﬁer’s view of the ability of a
program to protect itself. Biba deﬁnes that integrity is com-
promised when a program depends on (i.e., reads or executes)
low integrity data [3]. In practice, programs often process low
integrity data without being compromised (but not all pro-
grams, all the time), so this deﬁnition is too restricted. Clark-
Wilson deﬁne a model in which integrity veriﬁcation proce-
dures verify integrity at system startup and high integrity data
is only modiﬁed by transformation procedures that are certi-
ﬁed to maintain integrity even when their inputs include low
integrity data [4]. Unfortunately, the certiﬁcation of applica-
tions is too expensive to be practical.
More recent efforts focus on measuring code and associ-
ating integrity semantics with the code. The IBM 4758 ex-
plicitly deﬁnes that the integrity of a program is determined
by the code of the program and its ancestors [5].
In prac-
tice, this assumption is practical because the program and its
conﬁguration are installed in a trusted manner, it is isolated
from using ﬁles that can be modiﬁed by other programs, and
it is assumed to be capable of handling low integrity requests
from the external system. To make this guarantee plausible,
the IBM 4758 environment is restricted to a single program
with a well-deﬁned input state and the integrity is enforced
with secure boot. However, even these assumptions have not
been sufﬁcient to prevent compromise of applications running
on the 4758 which cannot handle low integrity inputs prop-
erly [6]. Thus, further measurement of low integrity inputs
and their impact appear to be likely.
The key differences in this paper are that: (1) we endeavor
to deﬁne practical integrity for a ﬂexible, traditional sys-
tems environment under the control of a potentially untrusted
party and (2) the only special hardware that we leverage is
the root of trust provided by the Trusted Computing Group’s
Trusted Platform Module (TCG/TPM). In the ﬁrst case, we
may not assume that all programs are loaded correctly simply
by examining the hash because the untrusted party may try
to change the input data that the program uses. For example,
many programs enable conﬁguration ﬁles to be speciﬁed in
the command line. Ultimately, applications deﬁne the seman-
tics of the inputs that they use, so it is difﬁcult for an oper-
ating system to detect whether all inputs have been used in
an appropriate manner by an application if its environment is
controlled by an untrusted party. However, a number of vul-
nerabilities can be found by the operating system alone, and
it is fundamental that the operating system collect and protect
measurements.
Second, the specialized hardware environment of the IBM
4758 enables secure boot and memory lockdown, but such
features are either not available or not practical for current
PC systems. Secure boot is not practical because integrity
requirements are not ﬁxed, but deﬁned by the remote chal-
lengers.
If remote parties could determine the secure boot
properties of a system, systems would be vulnerable to a sig-
niﬁcant denial-of-service threat. Instead the TCG/TPM sup-
ports trusted boot, where the attesting system is measured and
the measurements are used by the challengers to verify their
integrity requirements. Since trusted boot does not terminate
a boot when a low integrity process is loaded, all data could
be subject to attack during the “untrusted” boot. Since multi-
ple applications can run in a discretionary access control en-
vironment concurrently, it is difﬁcult to determine whether
the dynamic data of a system (e.g., a database) is still ac-
ceptable. Discretionary integrity mechanisms, such as sealed
storage [7], do not solve this problem in general.
2.2 Example
We use as an example a server machine running an Apache
Webserver and Tomcat Web Containers that serve static and
dynamic content to sell books to clients running on remote
systems. The system is running a RedHat 9.0 Linux environ-
ment. Figure 1 illustrates the runtime environment that affects
the Web server.
The system is initiated by booting the operating system.
The boot process is determined by the BIOS, grub bootloader,
and kernel conﬁguration ﬁle (/boot/grub.conf). The
ﬁrst two can alter the system in arbitrary ways, so they must
be measured. An interesting point is that measurement of
conﬁguration ﬁles, such as grub.conf, is not necessary
as long as they do not: (1) modify code already loaded and
(2) all subsequent ﬁle loads can be seen by the measurement
infrastructure. Since the BIOS and grub bootloader are un-
affected, we only need to ensure that the kernel and other
programs whose loads are triggered by the conﬁguration are
measured.
Figure 1: Runtime System Components
The boot process results in a particular kernel being run.
There are a variety of different types of kernels, kernel ver-
sions, and kernel conﬁgurations that determine the actual
system being booted. For example, we load Linux 2.6.5-
tcg from /boot/vmlinuz-2.6.5-tcg which includes a
TPM driver and our measurement hooks. Further, the kernel
may be extended by loadable kernel modules. The measure-
ment infrastructure must be able to measure the kernel and
any modules that are loaded. The challenger must be able
to determine whether this speciﬁc kernel booted and the dy-
namically loaded modules meet the desired integrity require-
ments.
Once the kernel is booted, then user-level services and ap-
plications may be run. In Linux, a program execution starts
by loading an appropriate interpreter (i.e., a dynamic loader,
such as ld.so) based on the format of the executable ﬁle.
Loads of the target executable’s code and supporting libraries