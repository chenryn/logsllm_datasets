title:Reliable group rekeying: a performance analysis
author:Yang Richard Yang and
Xiaozhou (Steve) Li and
X. Brian Zhang and
Simon S. Lam
Reliable Group Rekeying: A Performance Analysis ∗
Yang Richard Yang, X. Steve Li, X. Brian Zhang, Simon S. Lam
Department of Computer Sciences
The University of Texas at Austin
{yangyang,xli,zxc,lam}@cs.utexas.edu
ABSTRACT
In secure group communications, users of a group share a common
group key. A key server sends the group key to authorized new
users as well as performs group rekeying for group users whenever
the key changes. In this paper, we investigate scalability issues of
reliable group rekeying, and provide a performance analysis of our
group key management system (called keygem) based upon the use
of key trees. Instead of rekeying after each join or leave, we use
periodic batch rekeying to improve scalability and alleviate out-of-
sync problems among rekey messages as well as between rekey and
data messages. Our analyses show that batch rekeying can achieve
large performance gains. We then investigate reliable multicast of
rekey messages using proactive FEC. We observe that rekey trans-
port has an eventual reliability and a soft real-time requirement,
and that the rekey workload has a sparseness property, that is, each
group user only needs to receive a small fraction of the packets that
carry a rekey message sent by the key server. We also investigate
tradeoffs between server and receiver bandwidth requirements ver-
sus group rekey interval, and show how to determine the maximum
number of group users a key server can support.
1.
INTRODUCTION
Many emerging network applications, such as pay-per-view dis-
tribution of digital media, restricted teleconferences, and pay-per-
use multi-party games, are based upon a secure group communica-
tions model [7]. In this model, to protect the privacy of group com-
munications, a symmetric group key known only to group users
and the key server is used for encrypting data trafﬁc between group
users. Access to the group key is controlled by a group key manage-
ment system, which sends the group key to authorized new users as
well as performs group rekeying whenever the group key changes.
Speciﬁcally, a group key management system can implement two
types of access control: backward access control and forward ac-
cess control. If the system changes the group key after a new user
∗
Research sponsored in part by NSF grant no. ANI-9977267 and
NSA INFOSEC University Research Program grant no. MDA904-
98-C-A901. Experiments were performed on equipment procured
with NSF grant no. CDA-9624082.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
SIGCOMM’01, August 27-31, 2001, San Diego, California, USA..
Copyright 2001 ACM 1-58113-411-8/01/0008 ...$5.00.
joins, the new user will not be able to decrypt past group commu-
nications; this is called backward access control. Similarly, if the
system rekeys after a current user leaves, or is expelled from the
system, the departed user will not be able to access future group
communications; this is called forward access control.
Implementing access control may have large performance over-
heads which limit system scalability. Backward access control can
be implemented efﬁciently because a new group key can be dis-
tributed by encrypting it with the existing group key for existing
group users. Forward access control is harder to implement. To
send a new group key to all remaining group users after a user
has departed, one approach is to encrypt the new group key with
each remaining user’s individual key, which is shared only between
the user and the key management system. This straightforward ap-
proach, however, is not scalable because it requires the key man-
agement system to encrypt and send the new group key N − 1
times, where N is group size before the departure.
In the past few years, several approaches [20, 21, 2, 4, 5] have
been proposed to implement scalable forward access control. For
example, the key tree approach, which uses a hierarchy of keys
to facilitate group rekeying, reduces group rekeying complexity to
O(log N ) [20, 21], where N is group size.
individual key
Registration
join
leave
 Rekey encoding
rekey message
Rekey transport
Figure 1: Functional components of a key management service
Figure 1 shows the functional components of an architecture for
group key management system. The registration component au-
thenticates users and distributes to each user its individual key. Au-
thenticated users send their join and leave requests to the rekey en-
coding component. The rekey encoding component, which man-
ages the keys in the system, validates the requests by checking
whether they are encrypted by individual keys, and generates rekey
messages, which are sent to the rekey transport component for de-
livery. Previous studies have focused primarily on the rekey en-
coding component, particularly the processing time required by the
rekey encoding component in a key server [20, 21]; the problem of
reliable transport of group rekey messages has not been addressed
in the literature. To make a group key management system scal-
able, however, the design of each of the three components needs to
be scalable. Therefore, the objective of our study is to investigate
scalability issues of all three components, including the evaluation
of batch rekeying algorithms to improve scalability for a large and
dynamic group, the characterization of rekey transport workload,
the design of a reliable rekey transport protocol, and an overall per-
formance analysis of our system, called keygem.
First, consider the registration component. For a group key man-
agement system to grant or deny a join or leave request, the iden-
tity of the user sending the request needs to be authenticated. Thus,
each user needs to ﬁrst register with the system by authenticating
itself to the system and receive its individual key. Registration us-
ing an authentication protocol, however, can have large overheads,
and a key server becomes a bottleneck when user registration rate
is high. To improve the scalability of the registration component,
the key server in keygem can ofﬂoad its its registration workload
to trusted registrars [7, 23]. Machines running registrars can be
added or removed dynamically. Moreover, different registrars can
use different authentication protocols to authenticate different sets
of users. Since we can ofﬂoad the registration workload to reg-
istrars, we do not consider this workload in this paper. For the
detailed operations to register a new user, please see a description
of the keystone system [23].
Second, consider the rekey encoding component. We show that
rekeying after each join or leave (called individual rekeying) for the
key tree approach has two problems: inefﬁciency and out-of-sync
problems among rekey messages as well as between rekey and data
messages (see Section 2). Furthermore, when user join/leave rate is
high, the delay needed to reliably multicast a rekey message may be
too large to implement individual rekeying. In keygem, we improve
rekey encoding efﬁciency and alleviate the out-of-sync problems by
rekeying periodically for a batch of join/leave requests. The idea of
batch rekeying has been proposed before [4, 12, 17, 21]. However,
for batch rekeying based on a key tree, no explicit algorithm has
been presented and its performance has not been analyzed. In this
paper, we present the speciﬁcation of a batch rekeying algorithm,
analyze its performance, and evaluate the beneﬁts of batch rekey-
ing. Our evaluation shows that batch rekeying not only can reduce
the number of expensive signing operations, it also can reduce sub-
stantially bandwidth requirements at server and receivers. In other
words, batch processing can improve system scalability for a highly
dynamic group.
Third, consider the rekey transport component. Reliable trans-
port of rekey messages has not received much attention in previous
work. Although the idea of using FEC to improve the reliability
of rekey transport has been discussed in the SMuG community [7]
and in our keystone system, there is no protocol detail and its per-
formance is not analyzed. The common assumption is that one of
the reliable multicast protocols [6] can be used for rekey transport,
and that prior analyses [10, 13, 19, 8, 14] of these reliable multicast
protocols still apply. In this paper, we observe that rekey transport
has its own special properties. First, we observe that rekey trans-
port has an eventual reliability and a soft real-time requirement be-
cause of the inter-dependencies among rekey messages as well as
between rekey and data messages. Second, we observe that rekey
transport workload has a sparseness property, that is, while a key
server sends a rekey message as a large block of packets, each re-
ceiver only needs to receive a small fraction of the packets. For our
rekey transport protocol, which is based upon the use of proactive
FEC [9, 16], we show that reliable rekey multicast can be analyzed
by converting it to conventional reliable multicast, which does not
have the sparseness property. Using this approach, we have investi-
gated key server bandwidth overhead, number of rounds needed to
transport the workload of a rekey operation, and how to determine
the proactivity factor for FEC.
Fourth, consider the rekey encoding and the rekey transport com-
ponents together. Based on a simple membership model, we show
that group rekeying interval serves as a design parameter that al-
lows tradeoffs between rekeying overheads, group access delay,
and the degree of forward access control vulnerability. Considering
four system constraints, we investigate how to choose an appropri-
ate rekey interval and determine the maximum number of users that
a key server can support.
The balance of the paper is organized as follows. In Section 2,
we investigate scalability issues of the rekey encoding component
and evaluate periodic batch rekeying.
In Section 3, we address
the issues of reliable rekey transport, including rekey workload
characterization and performance analysis of rekey transport.
In
Section 4, we integrate the results of Section 2 and Section 3 to
consider overall system performance and study tradeoffs between
bandwidth overhead and rekey interval. Our conclusion is in Sec-
tion 5.
2.
IMPROVING
REKEY ENCODING SCALABILITY
Having been authenticated by a registrar, a user can then send a
join request to the key server. The key server will also receive leave
requests from existing users. The rekey encoding component pro-
cesses these requests to prepare rekey messages. Before discussing
the issues of individual rekeying, we ﬁrst brieﬂy review the key tree
idea [20, 21].
2.1 Key tree
A key tree is a directed tree in which each node represents a
key. The root of the key tree is the group key, which is shared
by all users, and a leaf node is a user’s individual key, which is
shared only between the user and the key server. Since each node
represents a key, we call a node in the key tree a key node. For
key nodes representing the individual keys of users, we also refer
to them as user nodes. A trusted key server manages the key tree,
and a user u is given key k if and only if there is a directed path
from its individual key to key k in the key tree. Consider a group
with 9 users. An example key tree is shown in Figure 2. In this
group, user u9 is given three keys: k9, k789, and k1−9. Key k9 is
the user’s individual key, key k1−9 is the group key, and k789 is an
auxiliary key shared by u7, u8, and u9.
group key
k1−9
(change to k1−8)
auxiliary
keys
k123
(change to k78)
k456
k789
individual
keys
(user nodes)
users
k1
u1
k2
u2
k3
u3
k4
u4
k5
u5
k6
u6
k7
u7
k8
u8
Figure 2: An example key tree
k9
u9
leave
Suppose u9 leaves the group. The key server will then need to
change the keys that u9 knows: change k1−9 to k1−8, and change
k789 to k78. To distribute the changed keys to the remaining users
using group-oriented rekeying strategy [21], the key server con-
structs the following rekey message by traversing the key tree bottom-
up: ( {k78}k7 , {k78}k8 , {k1−8}k123 , {k1−8}k456 , {k1−8}k78 ).
Here {k(cid:2)}k denotes key k(cid:2)
encrypted by key k, and is referred to as
an encrypted key or an encryption. Upon receiving this message, a
user extracts the encrypted keys that it needs. For example, u7 only
needs {k1−8}k78 and {k78}k7 .
2.2 Issues of individual rekeying
Although individual rekeying introduces no extra delay to pro-
cess user requests, it has two issues.
First, if we rekey after each join or leave, it is hard to control the
synchronization that will arise because of the inter-dependencies
among rekey messages as well as between rekey and data mes-
sages. When synchronization is not achieved, we will have out-of-
sync problems. Consider an encryption {k}k(cid:1) in a rekey message.
A user must receive k(cid:2)
in order to decrypt the encryption. How-
ever, k(cid:2)
may be distributed in a previous rekey message, and if the
previous rekey message has not arrived, the user will not be able
to recover the new key. Also, consider a group key distributed in a
rekey message to a user. If data messages are encrypted using the
group key and the group key has not arrived, the user will not be
able to decrypt the data messages. As a result of these out-of-sync
problems, if rekey message delivery delay is high and join/leave
requests happen frequently, a user may need to keep all of the old
group keys, and buffer a large amount of rekey and data messages
that it cannot decrypt yet.
Second, individual rekeying can be inefﬁcient. For authentica-
tion purpose, each rekey message needs to be digitally signed to
prove that it originates from the key server, and we know that sign-
ing operation can have large computation or bandwidth overheads.
Moreover, as Snoeyink, Suri and Varghese observed in [18], which
we have also independently derived at the same time using a differ-
ent proof [24], we know that when a key server rekeys after each
request and when forward access control is required, Ω(log N ) is a
lower bound on the amortized number of encrypted keys. Thus, the
key tree approach has already achieved the complexity of this lower
bound, and we cannot further improve the performance of rekey en-
coding if we rekey after each request. To overcome this limit and
reduce the number of signing operations, we need to consider batch
rekeying.
2.3 Periodic batch rekeying
Periodic batch rekeying, which collects requests during a rekey
interval and rekeys them in a batch, can alleviate the out-of-sync
problems and improve efﬁciency. To alleviate the out-of-sync prob-
lems, periodic batch rekeying delays the usage of a new group key
until the next rekey interval, and rekey transport can guarantee with
a high probability that the rekey message has been delivered before
the next interval (see Section 4). As for performance, an obvious
performance gain of batch processing J join and L leave requests
is that it reduces the number of signing operations from J + L
to 1. Moreover, the number of encrypted keys generated by batch
rekeying can be less than the sum of those generated by individual
rekeying. Consider Figure 2. Suppose both u8 and u9 send leave
requests. If the key server rekeys individually, it will need to update
the group key twice, and at each time, the new group key needs to
be encrypted by k123. However, if the two requests are rekeyed in
a batch, the key server only needs to update the group key once.
Periodic batch rekeying improves performance at the expense of
delayed group access control, because a new user has to wait longer
to be accepted by the group and a departed (or expelled) user can
stay within the group longer. Thus, we observe that group rekeying
interval serves as a design parameter that allows tradeoffs between
rekeying overheads, group access delay, and the degree of forward
access control vulnerability.
To accommodate different application requirements and make
tradeoffs between performance and group access control, keygem
can operate in three batch modes: 1) periodic batch rekeying, in
which the key server processes both join and leave requests period-
ically in a batch; 2) periodic batch leave rekeying, in which the key
server processes each join request immediately to reduce the de-
lay for a new user to access group communications, but processes
leave requests in a batch; and 3) periodic batch join rekeying, in
which the key server processes each leave request immediately to
reduce the exposure to users who have departed, but processes join
requests in a batch. We will investigate the tradeoffs further in Sec-
tion 4.
2.4 Batch rekeying algorithms
In periodic batch rekeying mode, the key server maintains a key
tree that is slightly different from the key tree described in Sec-
tion 2.1 to facilitate a key identiﬁcation strategy that we proposed
in [26]. In particular, we add null nodes that represent empty key
nodes to a key tree so that the key server can always maintain a
complete and balanced key tree. To identify each node in the key
tree, the key server assigns integer IDs to tree nodes in breadth ﬁrst
search order, with the ID of the tree root as 0.
At the end of each rekey interval, the key server collects J join
and L leave requests and executes the following marking algorithm
to update the key tree and generate a rekey subtree. The objectives
of the marking algorithm are to 1) reduce the number of encrypted
keys; 2) maintain the balance of the updated key tree; and 3) make
it efﬁcient for users to identify the encrypted keys that they need.
becomes
becomes
becomes
leaves
3 leaves
2 joins
j1 j2
u1
leave
1 leave
3 joins
d=2
new new
u1
j1
u1
j3
j1
j2
J > L (Strategy 1)
J < L
Figure 3: Example of marking algorithm for J (cid:5)= L.
The marking algorithm ﬁrst updates the key tree. If J ≤ L, the
key server replaces J of the departed users that have the smallest
IDs with the J newly joined users. By replacing departed users
with newly joined users, the algorithm reduces the number of en-
crypted keys [11]. When J < L, we notice that some of the de-