stances per action (5 sessions x 10 task sets). In total, we have 1650
instances (50 instances x 33 users) per action from all 33 participants
in the single app experiment. We then extracted features from these
instances using the methodology discussed in §5 and labeled the
feature vectors with the following four actions as classes:
• Camera for the task of taking photo action,
• Video for the task of taking video action,
• Gallery for the task of choosing a photo from gallery, and
• Cancel for canceling the pop-up.
Global Model. In this model, we consider dataset of all the users
with all the sessions. We have total 6600 (1650 instances x 4 actions)
ERP events for this model. The experiment results of this model are
shown in Table 3. As shown in the table, the weighted average of
Precision is 70.70%. This implies that our IAC can correctly detect
human intention for 70.70% of time, which is not very good for
automated authorization. The reason behind this relatively low
accuracy is that even for the same task, dierent people are likely
to have dierent ERPs patterns, which actually has been used to
build authentication systems [5, 63]. For this reason, we would like
to know how the classier performs when only consider actions
belong to the same participant.
Table 3: Classication result of global model.
Precision
70.70%
Metrics
Recall
70.70%
F − Measure
70.70%
Figure 6: Boxplot of Precision, Recall, and F − measure of indi-
vidual model. The red line indicates the median value and +
symbol indicates the outliers.
Individual Model. In the individual model, we train and test the
model with data from a single user across all sessions of single app
experiment. The results for the individual model are reported in Fig-
ure 6. Overall, the results were much better than when considering
all segments across all participants (i.e., the global model). From
the boxblot, we observed that the median of weighted average of
Precision and Recall are 99.50% and 99.50%, respectively. The me-
dian of weighted average F − measure is 99.50% also. These results
imply that IAC correctly detect human intent for 99.50% of the time.
The results also indicate that IAC works well when the ML model
is trained and tested with a single user and a single app.
6.2 Cross-app Portability Analysis
Through the single app experiment, we partially veried that it
is possible to infer users’ high-level intents based on their brain
signals. In terms of app context, this implies that our classier can
distinguish dierent app contexts. However, since it only involves
one app, the remaining questions is: can the learned model work
across dierent apps? That is, in terms of app context, we want
to know whether our classier can identify similar context from
dierent apps (i.e., cross-app portability).
We answer this question using the multiple real-world apps
experiment where 8 participants interacted with 8 real world apps
with a duration of 21 minutes on average. However, we had to
discard 3 participants data due to the device error caused data loss.
So we only consider those 5 participants whose data is sucient.
On average, the 5 participants performed 22 actions for video, 47
actions for camera, and 27 actions for gallery. In total, we have 484
ERPs from 5 users.
Because these 5 participants have not participated in the sin-
gle app experiment, this experiment resembles a more practical
scenario. With this setup, we have two options to bootstrap the
IAC: On the Feasibility of Utilizing Neural Signals for
Access Control
Figure 7: How classication metrics varies with the number of
seen intents? The rst bar represents the Pr ecision, Recall, and
F − measur e without adding any new intents from multiple real
world apps experiment to the global model from single app experi-
ment. The second bar represents results with adding new intents to
the global model, The third bar represents the results after adding
two intents to the global model, and so on and so forth. We observed
the upward trends of Pr ecision, Recall, and F − measur e with the
addition of more new intents to the global model.
individual model: (1) we can start with an empty model can com-
pletely rely on the feedback loop (in Figure 2) to collect training
data; or (2) we start with a half-baked model and use the feedback
loop to improve it. In this experiment, we chose the second option
as it requires less training and the global model we tested in §6.1
still showed reasonable accuracy.
With Initial Model. We used the global model learned from all
participants in the single app experiment as the initial model (i.e.,
train the model with all data in the single app experiment) and
tested it with all data collected from the multiple app experiments.
The classication results of Precision, Recall, and F − measure of
the initial model are presented in the rst bar diagram in Figure 7.
From this gure, we can observe that we can only correctly infer
the user intention with the precision of 43.16%.
Adding Feedback Loop. When we gradually add new training
intents collected from the user when he/she is using real world
apps, the improvement on Precision, Recall, and F − measure are
shown in Figure 7. All newly added intents were from the multiple
app experiment and we have to stop at 5 so we can have enough
data for the testing phase. As we can see, after adding 5 intents
from real world apps, the weighted average Precision improved
from 43.16% to 88.34%, the weighted average Recall improved from
39.82% to 86.52%, and the weighted average F − measure improved
from 38.94% to 86.92%. The results imply that in real world context,
IAC can correctly infer the user intention 86.92% of time by adding
only 5 intents to re-train the ML model. Again, the precision is
expected to continue improving and the only reason we stop at 5 is
due to lack of data.
6.3 Results Analysis
Based on the classication results from above experiments, we
decided to accept our hypothesis. That is, it is possible to identify
ACSAC’18, December 3–7,2018, San Juan, PR, USA
high-level intents based on neural signals using a machine learning
algorithm. In terms of app context, our classier can both distin-
guish dierent contexts from the same app and identify similar
contexts from dierent apps. Hence, the answer to Q1 is positive.
6.4 Authorization Accuracy
In the above analysis, we have shown that it is possible to identify
user’s high-level intent through the brain-computer interface. How-
ever, whether the classication result can be used for automated
access authorization for user-owned sensitive sensors and resources
still faces the question: is it accurate enough (Q2). In this subsection,
we analyze the classication results to answer this question. From
the analysis of multiple app experiment data, we observed that our
classier can achieve a weighted average of Precision 88.34% with
the weighted average of F − measure 86.92% for the completely
unknown scenarios. Based on this, we think the answer to Q2 is
positive.
7 DISCUSSION
IAC and Contextual Integrity. Access control system is a mecha-
nism to protect user’s privacy. Modern OS, including Android (M+),
iOS, and Windows (8+) uses an ask-on-rst-use permission system
to guard access to sensitive data and sensors. This approach pro-
vides some context cues but only at the rst time when the permis-
sion is requested. Researchers have argued that permission should
be requested under the context that matches user’s expectations,
i.e., contextual integrity [46]. IAC enforces contextual integrity in
the way that user would only have an intent in her mind when the
context is relevant to the intent. In other word, if an app violates
contextual integrity, then the user will not express the intent and
IAC will block the access.
Learning Strategy. As demonstrated in §6, the classication accu-
racy can vary based on the learning strategy. Overall, since dierent
people may exhibit dierent brain signals even when thinking about
the same thing (which has been used for neural-signal-based au-
thentication); it is preferable to use individual models. However,
bootstrapping such a model require users to go through a calibra-
tion phase. An alternative approach, as used in [66] and our own
experiment, is to use a half-baked model (e.g., the generalized model
learned from all participants in the single app experiment), then per-
sonalized it by adding feedbacks from explicit prompts, especially
for newly installed apps. Once the model has seen enough feedback,
we can start using it to make real authorization decisions. Our mul-
tiple app experiment has partially validated the eectiveness of this
strategy.
Limitations. Similar to other previous studies on BCI [40, 45], our
study also has several limitations. First, the study was conducted
in the controlled environment so whether unwanted artifacts like
EOG and EMG can be reliably removed in an uncontrolled environ-
ment is still unclear. However, since this is a common problem for
BCI, we believe future techniques will be able to address it. Second,
despite that our sample set is relatively larger (41 participants) than
previous studies (e.g., 5 participants [5, 49], 9 participants [39], 16
participants [7]) and have diverse demography background, it is
still much smaller than data set in other machine learning appli-
cations, such as computer vision, voice recognition, and natural
ACSAC’18, December 3–7,2018, San Juan, PR, USA
M. Rahman et al.
language processing. Third, we used only popular apps for testing
our feasibility and the number of apps is only 8. This could be a
bias scenario as participants are more familiar with popular apps.
Finally, our classier is likely to be vulnerable to phishing-style
attacks. That is, similar to following our instructions to perform
actions that would allow an app to access protected resources, a
phishing-style attack might also be able to trick users into willing
to perform operations that would compromise the security and
privacy of their data.
Future Work. There are many unexplored areas along this re-
search direction. First, we would like to explore other machine
learning algorithms like deep neural network (DNN) to see if it can
help improve the classication accuracy. Second, we would like to
see if the classier can scale to support more types of tasks and
how the accuracy would look like. Third, we would also like to
explore if it is possible to improve the classier by including other
behavioral information, such as eye gazing information. Moreover,
although our current design might be vulnerable to phishing-style
attacks, previous study [45] has shown that even though at con-
scious level, users may not realize the dierence between phishing
and non-phishing websites, their neural signals still diers. Based
on this observation, we would like to explore the possibility of de-
fending against phishing-style attacks at brain signal level. Finally,
recent research has shown machine-learning-based classiers may
be subject to adversarial examples [28], so might be our classier.
However, it is unclear that under our threat model, how attackers
can tamper with the collected EEG data to inject their malicious
perturbations. So we would also like to explore this direction.
8 RELATED WORK
In this section, we briey discuss related work on neural signals
and permission model.
BCI-based security studies. Neural signals have used for user
authentication [17, 34, 43, 63] and identication [52, 68]. Ashby et
al. [5] proposed an EEG-based authentication system using a con-
sumer grade 14-sensor Emotiv Epoc headset. Abdullah et al. [2]
discussed the possibility of the EEG-based biometric system using 4
or fewer electrodes. Chuang et al. [17] developed a user authentica-
tion model using one single-sensor Neurosky headset. Campbell et
al. [14] developed a neurophone which is based upon ERP of brain
signal. They implemented a brain-controlled address book dialing
app, which shows a sequence of photos of contacts from address
book to users. Thorpe et al. [63] suggested pass-thoughts to au-
thenticate users. In their study, they used EEG signal to replace
password typing. The EEG-based authentication system overcomes
the weakness of current authentication protocol which suers from
several types of attacks including dictionary attack, password guess-
ing, etc. However, there are some drawbacks to this approach like
non-pervasiveness of EEG equipment and lack of feedback to the
users during the authentication process.
Exposing user’s neural signals to third-party apps via the brain
computer interfaces introduced new security and privacy issues
[11, 25, 40, 44]. Martinovic et al. [40] introduced a side-channel at-
tack which they referred to as ”brain spyware” using commercially
available headset Emotiv EPOC. The authors extracted private infor-
mation like familiar banks, ATMs, PIN digits, and month of birth us-
ing only brain signal. Their work is similar to Guilty-KnowledgeTest
(GKT) [18] where familiar items evoked a dierent response than
unfamiliar items. In their experiment, users are shown images of
banks, digits, known people images. The users’ ERP responses will
be dierent for their very known banks as that information stored
their memory beforehand. However, their attack is intrusive and
can be easily detectable as the users may notice the abnormality in
the application when it displays some of their familiar information
sequentially. Frank et al. [25] proposed a subliminal attack in which
attacker can learn relevant private information from the victim at
the levels below his cognitive perception. Bonaci et al. [11] showed
how non-invasive BCI platforms used in games or web navigation,
can be misused to extract user’s private information. Neupane et
al. [44] showed the feasibility of stealing users’ PIN from their brain
signals.
Runtime Permission Models. Requesting access to sensitive
resources at runtime—the moment they will be used provide more
context information thus can help users better understanding the
nature of these requests and make more optimal decisions [23]. The
challenge is how to avoid habituation caused by high frequency of
resource access [65].
User-driven access control. The rst approach to reduce the num-
ber of prompts is to automatically authorize the requests based on
users’ intent. Existing user-driven access control systems [33, 38,
41, 48, 51, 55, 57] all utilize the same way to infer the intent—by
capturing authentic user interaction with trusted GUI gadgets (i.e.,
access control gadgets), e.g., the “camera” button. Our approach
also tries to infer the intent of an user. However, as we directly infer
the intent from the neural signals, our system is not vulnerable to
GUI attacks [30, 51] thus do not require additional protection for
GUI gadgets. Please note that although we only used user-initiated
actions in our experiment, unlike existing user-driven access con-