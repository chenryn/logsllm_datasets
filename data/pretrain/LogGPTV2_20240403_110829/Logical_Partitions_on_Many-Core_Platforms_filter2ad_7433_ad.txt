on them. However, the main ideas underlying our design
(NoC-based address space isolation and factoring of hyper-
visors into critical and non-critical services) are generic and
likely applicable also to future many-core systems.
7. RELATED WORK
Centralized Hypervisors. Previous work on the design
and implementation of centralized hypervisors such as No-
Hype [39], OSV [15] and MultiHype [36] are closely related
to the solution that we present in this paper. NoHype relies
on CPU and memory virtualization extensions and is based
on the Xen hypervisor (above 100K LOC). OSV (8K LOC)
uses a centralized hypervisor design to enable bare-metal ex-
ecution of VMs, rather than isolation. It also relies on virtu-
alization extensions during VM boot up and simply assumes
that VMs do not misbehave at runtime. Finally, MultiHype
relies on memory controller enhancements to realize logi-
cal partitions based on a centralized hypervisor design, but
MultiHype is not disengaged (e.g., it manages I/O devices
even if they are virtualization-capable) and its complexity
is not publicly available. Unlike all these above proposals,
our solution leverages simpler hardware support on an AMP
processor (Intel SCC) to realize a small (3.4K LOC) and
completely disengaged hypervisor.
Traditional Hypervisors. Traditional hypervisors for
x86-systems leverage hardware virtualization extensions to
achieve a small TCB. Examples include NOVA (20K LOC)
[38] that uses a micro-kernel design to reduce the amount
of privileged code and HypeBIOS (4K LOC) [46] that elim-
inates redundant code for the same purpose. Furthermore,
formally veriﬁed kernels such as Muen [13] (complexity not
publicly available) and seL4 [26] (8.7K LOC) as well as
security-certiﬁed commercial hypervisors (e.g., Integrity Mul-
tivisor [2]) that rely on similar hardware virtualization ex-
tensions also exist. IBM and Hitachi today incorporate sim-
ilar hypervisors into the ﬁrmware of their servers to achieve
logical partitions [1, 19]. All of the above solutions are de-
signed for SMP processors and it is unclear if similar designs
would scale for use in future many-core systems.
Distributed Hypervisors. Similar to the architecture
of future many-core processors, uncertainties exist regarding
whether current hypervisor and more generally OS designs
would scale for future processors. On the one hand, there
is evidence that by changing existing operating systems, it
is possible to enable their use on large-scale processors [12].
On the other hand, there is a trend towards pursuing alter-
nate hypervisor and OS designs to achieve the same goal.
This includes designing operating systems and hypervisors
as distributed kernels whose components run on all or a sub-
set of the cores [10, 32] and re-structuring them as services
on separate cores that allow interaction via message passing
rather than through traditional traps or exceptions that are
handled on the same core [9,11]. An alternative approach for
asymmetric processors is to run a set of distributed kernels
that can provide shared virtual memory, i.e., a consistent
view of memory across all cores like an SMP system [14,37].
All these distributed solutions aim to optimize the eﬃ-
ciency of the operating systems or the hypervisors, but not
to achieve simplicity or disengagement.
In fact, it is not
possible to realize disengagement in a distributed solution,
as discussed in Section 2.
8. CONCLUSION
We explored the problem of realizing logical partitions
using small and disengaged hypervisors on many-core plat-
forms. In contrast to current disengaged hypervisors that
need full-ﬂedged hardware virtualization extensions, our so-
lution relies on a simple address-space isolation mechanism.
We demonstrated this through a case study on the Intel SCC
and showed that with lightweight modiﬁcations, it is possi-
ble realize logical partitions on many-core processors. We
also designed and implemented a cloud architecture based
on the security-enhanced Intel SCC. In this architecture, the
hypervisor is completely disengaged, i.e., it is involved only
in the startup and shutdown of VMs and the VMs run di-
rectly on the hardware without any virtualization overhead.
The size of our prototype hypervisor is 3.4K LOC which is
comparable to the smallest hypervisors known today.
Previously, many-core systems have been primarily used
for parallel computing where eﬃcient data sharing is needed.
This work demonstrates that many-core processors can also
be used in IaaS cloud deployments where secure isolation is
a mandatory requirement.
9. ACKNOWLEDGEMENTS
We thank our shepherd Dr. Kurt Thomas for the very
useful comments. We are also grateful to Dr. Devendra Rai
and Dr. Stefan Lankes for access and help with the Intel
SCC. This work was partially supported by the Zurich In-
formation Security and Privacy Center.
It represents the
views of the authors. This work was also partly supported
by the TREDISEC project (G.A. no 644412), funded by
the European Union (EU) under the Information and Com-
munication Technologies (ICT) theme of the Horizon 2020
(H2020) research and innovation programme.
10. REFERENCES
[1] Hitachi Embedded Virtualization Technology.
http://www.hitachi-america.us/supportingdocs/forbus/
ssg/pdfs/Hitachi Datasheet Virtage 3D 10-30-08.pdf.
[2] INTEGRITY Multivisor. http://www.ghs.com/products/
rtos/integrity virtualization.html.
[3] Linux Kernel Vulnerability Statistics.
http://www.cvedetails.com/product/47/
Linux-Linux-Kernel.html?vendor id=33.
[4] LPARBOX. http://lparbox.com/.
[5] Microsoft Windows 8 Vulnerability Statistics.
http://www.cvedetails.com/product/22318/
Microsoft-Windows-8.html?vendor id=26.
[6] SSL Library PolarSSL. https://polarssl.org.
[7] Adapteva. Ephiphany Multicore IP. www.adapteva.com/
products/epiphany-ip/epiphany-architecture-ip/.
[8] T. W. Arnold and L. P. Van Doorn. The IBM PCIXCC: A
new cryptographic coprocessor for the IBM eServer. IBM
Journal of Research and Development, 2004.
[9] Ballesteros, F. J., Evans, N., Forsyth, C., Guardiola, G.,
McKie, J., Minnich, R. and Soriano-Salvador, E. NIX: A
Case for a Manycore System for Cloud Computing.
Technical report, Bell Labs Tech. J., 2012.
[10] A. Baumann, P. Barham, P.-E. Dagand, T. Harris,
R. Isaacs, S. Peter, T. Roscoe, A. Sch¨upbach, and
A. Singhania. The Multikernel: A New OS Architecture for
Scalable Multicore Systems. In Symposium on Operating
Systems Principles, SOSP’09, 2009.
[11] S. Boyd-Wickizer, H. Chen, R. Chen, Y. Mao, F. Kaashoek,
R. Morris, A. Pesterev, L. Stein, M. Wu, Y. Dai, Y. Zhang,
and Z. Zhang. Corey: An Operating System for Many
Cores. In Operating Systems Design and Implementation,
OSDI’08, 2008.
[12] S. Boyd-Wickizer, A. T. Clements, Y. Mao, A. Pesterev,
M. F. Kaashoek, R. Morris, and N. Zeldovich. An Analysis
of Linux Scalability to Many Cores. In Operating Systems
Design and Implementation, OSDI’10, 2010.
[13] R. Buerki and A.-K. Rueegsegger. Muen-an x86/64
separation kernel for high assurance.
http://muen.codelabs.ch/muen-report.pdf, 2013.
[14] M. Chapman and G. Heiser. vNUMA: A Virtual
Shared-memory Multiprocessor. In USENIX Annual
Technical Conference, USENIX’09, 2009.
[15] Y. Dai, Y. Qi, J. Ren, Y. Shi, X. Wang, and X. Yu. A
Lightweight VMM on Many Core for High Performance
Computing. SIGPLAN Not., 2013.
[16] Y. Dong, X. Yang, X. Li, J. Li, K. Tian, and H. Guan. High
performance network virtualization with sr-iov. In High
Performance Computer Architecture, HPCA ’10, 2010.
[17] L. Fiorin, G. Palermo, S. Lukovic, V. Catalano, and
C. Silvano. Secure Memory Accesses on Networks-on-Chip.
IEEE Transactions on Computers, 2008.
[18] A. Gavrilovska, S. Kumar, H. Raj, K. Schwan, V. Gupta,
R. Nathuji, R. Niranjan, A. Ranadive, and P. Saraiya.
High-performance Hypervisor Architectures: Virtualization
in HPC Systems. In System-level Virtualization for High
Performance Computing, 2007.
[19] N. Harris, D. Barrick, I. Cai, P. G. Croes, A. Johndro,
B. Klingelhoets, S. Mann, N. Perera, and R. Taylor. LPAR
Conﬁguration and Management Working with IBM eServer
iSeries Logical Partitions. IBM Redbooks, 2002.
[20] Intel Corporation. Getting Xen working for Intel(R) Xeon
Phi(tm) Coprocessor. https://software.intel.com/en-us/
videos/knights-landing-the-next-manycore-architecture.
[21] Intel Corporation. Intel Xeon Phi 7100 Series Speciﬁcation.
http://ark.intel.com/products/75800/
Intel-Xeon-Phi-Coprocessor-7120X-16GB-1
238-GHz-61-core.
View. In International Conference for High Performance
Computing, Networking, Storage and Analysis, SC ’10,
2010.
[30] F. McKeen, I. Alexandrovich, A. Berenzon, C. V. Rozas,
H. Shaﬁ, V. Shanbhogue, and U. R. Savagaonkar.
Innovative Instructions and Software Model for Isolated
Execution. In Hardware and Architectural Support for
Security and Privacy, HASP’13, 2013.
[31] A. Milenkoski, B. Payne, N. Antunes, M. Vieira, and
S. Kounev. Experience Report: An Analysis of Hypercall
Handler Vulnerabilities. In Software Reliability Engineering
(ISSRE), 2014.
[32] E. B. Nightingale, O. Hodson, R. McIlroy, C. Hawblitzel,
and G. Hunt. Helios: Heterogeneous Multiprocessing with
Satellite Kernels. In Symposium on Operating Systems
Principles, SOSP ’09, 2009.
[33] Partheymuller, Markus and Stecklina, Julian and D¨obel,
Bj¨orn. Fiasco.OC on the SCC. http://os.inf.tu-dresden.de/
papers ps/intelmarc2011-ﬁascoonscc.pdf, 2011.
[34] J. Porquet, A. Greiner, and C. Schwarz. NoC-MPU: A
Secure Architecture for Flexible Co-hosting on Shared
Memory MPSoCs. In Design, Automation Test in Europe
Conference Exhibition, DATE’11, 2011.
[35] T. Ristenpart, E. Tromer, H. Shacham, and S. Savage. Hey,
You, Get oﬀ of My Cloud: Exploring Information Leakage
in Third-party Compute Clouds. In Computer and
Communications Security, CCS’09, 2009.
[36] W. Shi, J. Lee, T. Suh, D. H. Woo, and X. Zhang.
Architectural Support of Multiple Hypervisors over Single
Platform for Enhancing Cloud Computing Security. In
Computing Frontiers, CF ’12, 2012.
[37] X. Song, H. Chen, R. Chen, Y. Wang, and B. Zang. A Case
for Scaling Applications to Many-core with OS Clustering.
In European Conference on Computer Systems, EuroSys
’11, 2011.
[38] U. Steinberg and B. Kauer. NOVA: A Microhypervisor-
based Secure Virtualization Architecture. In European
Conference on Computer systems, EuroSys ’10, 2010.
[39] J. Szefer, E. Keller, R. B. Lee, and J. Rexford. Eliminating
the Hypervisor Attack Surface for a More Secure Cloud. In
Computer and Communications Security, CCS’11, 2011.
[40] J. Szefer and R. B. Lee. Architectural support for
hypervisor-secure virtualization. SIGARCH Comput.
Archit. News, 2012.
[41] Tilera Corporation. TILE-GX Family.
http://www.tilera.com/products/?ezchip=585&spage=618.
[42] TU Dresden. L4linux.
[22] Intel Corporation. SCC External Architecture Speciﬁcation.
http://os.inf.tu-dresden.de/L4/LinuxOnL4/.
https://communities.intel.com/docs/DOC-5044/version.
[43] D. Wentzlaﬀ and A. Agarwal. Factored Operating Systems
[23] Intel Corporation. PCI-SIG SR-IOV Primer.
http://www.intel.com/content/dam/doc/application-note/
pci-sig-sr-iov-primer-sr-iov-technology-paper.pdf, 2011.
[24] Intel Corporation. Intel Virtualization Technology for
Directed I/O.
http://www.intel.com/content/www/us/en/embedded/
technology/virtualization/vt-directed-io-spec.html, 2014.
[25] G. Irazoqui, M. Inci, T. Eisenbarth, and B. Sunar. Wait a
Minute! A Fast, Cross-VM Attack on AES. In Research in
Attacks, Intrusions and Defenses (RAID), 2014.
[26] G. Klein, K. Elphinstone, G. Heiser, J. Andronick, D. Cock,
P. Derrin, D. Elkaduwe, K. Engelhardt, R. Kolanski,
M. Norrish, T. Sewell, H. Tuch, and S. Winwood. seL4:
Formal Veriﬁcation of an OS Kernel. In Symposium on
Operating Systems Principles, SOSP ’09, 2009.
[27] P. Li, D. Gao, and M. Reiter. Mitigating Access-driven
Timing Channels in Clouds Using StopWatch. In
Dependable Systems and Networks (DSN), June 2013.
(Fos): The Case for a Scalable Operating System for
Multicores. SIGOPS Oper. Syst. Rev., 2009.
[44] Y. Yarom and K. Falkner. FLUSH+RELOAD: A High
Resolution, Low Noise, L3 Cache Side-Channel Attack. In
USENIX Security Symposium, Aug. 2014.
[45] Y. Zhang, A. Juels, M. K. Reiter, and T. Ristenpart.
Cross-VM Side Channels and Their Use to Extract Private
Keys. In Computer and Communications Security, CCS’12,
2012.
[46] Y. Zhang, W. Pan, Q. Wang, K. Bai, and M. Yu.
HypeBIOS: Enforcing VM Isolation with Minimized and
Decomposed Cloud TCB. http:
//www.people.vcu.edu/˜myu/s-lab/my-publications.html,
2012.
[47] Y. Zhang and M. K. Reiter. Duppel: Retroﬁtting
Commodity Operating Systems to Mitigate Cache Side
Channels in the Cloud. In Computer and Communications
Security, CCS’13, 2013.
[28] M. M. K. Martin, M. D. Hill, and D. J. Sorin. Why On-chip
[48] M. Ziwisky and D. Brylow. BareMichael: A Minimalistic
Cache Coherence is Here to Stay. Commun. ACM, 2012.
[29] T. G. Mattson, M. Riepen, T. Lehnig, P. Brett, W. Haas,
P. Kennedy, J. Howard, S. Vangal, N. Borkar, G. Ruhl, and
S. Dighe. The 48-core SCC Processor: The Programmer’s
Bare-metal Framework for the Intel SCC. In Many-core
Applications Research Community Symposium, MARC’12,
2012.