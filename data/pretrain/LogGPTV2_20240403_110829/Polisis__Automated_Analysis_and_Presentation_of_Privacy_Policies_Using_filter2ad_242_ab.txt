corpus of 130K privacy policies collected from apps on
the Google Play Store. These policies typically describe
the overall data practices of the apps’ companies.
We crawled the metadata of more than 1.4 million An-
droid apps available via the PlayDrone project [27] to
ﬁnd the links to 199,186 privacy policies. We crawled
the web pages for these policies, retrieving 130,326 poli-
cies which returned an HTTP status code of 200. Then,
we extracted the textual content from their HTML us-
ing the policy crawler described in Sec. 3. We will refer
to this corpus as the Policies Corpus. Using this corpus,
we trained a word-embeddings model using fastText [28].
We henceforth call this model the Policies Embeddings.
A major advantage of using fastText is that it allows train-
ing vectors for subwords (or character n-grams of sizes 3
to 6) in addition to words. Hence, even if we have words
outside our corpus, we can assign them vectors by com-
bining the vectors of their constituent subwords. This is
very useful in accounting for spelling mistakes that occur
in applications that involve free-form user queries.
4.2 Classiﬁcation Dataset
Our Policies Embeddings provides a solid starting
point to build robust classiﬁers. However, training the
classiﬁers to detect ﬁne-grained labels of privacy poli-
cies’ segments requires a labeled dataset. For that pur-
pose, we leverage the Online Privacy Policies (OPP-
115) dataset, introduced by Wilson et al. [11]. This
dataset contains 115 privacy policies manually annotated
by skilled annotators (law school students). In total, the
dataset has 23K annotated data practices. The anno-
tations were at two levels. First, paragraph-sized seg-
ments were annotated according to one or more of the
10 high-level categories in Fig. 3 (e.g., First Party Col-
lection, Data Retention). Then, annotators selected parts
of the segment and annotated them using attribute–value
pairs, e.g., information type: location, purpose: adver-
tising, etc. In total, there were 20 distinct attributes and
138 distinct values across all attributes. Of these, 122
values had more than 20 labels. In Fig. 3, we only show
the mandatory attributes that should be present in all seg-
ments. Due to space limitation, we only show samples of
the values for selected attributes in Fig. 3.
4.3 Hierarchical Multi-label Classiﬁcation
To account for the multiple granularity levels in the
policies’ text, we build a hierarchy of classiﬁers that
are individually trained on handling speciﬁc parts of the
problem.
At the top level, a classiﬁer predicts one or more high-
level categories of the input segment x (categories are the
top-level, shaded boxes of Fig. 3). We train a multi-label
classiﬁer that provides us with the probability p(ci|x) of
the occurrence of each high-level category ci, taken from
the set of all categories C . In addition to allowing mul-
tiple categories per segment, using a multi-label classi-
534    27th USENIX Security Symposium
USENIX Association
Information Type
• financial
• health
• contact
• location
• …
Purpose
• advertising 
• marketing
• analytics
• legal requirement
• …
Information 
Type
Information 
Type
Access 
Rights
Retention 
Purpose
Purpose
Purpose
Information 
Type
Retention Period
• stated period
• limited
• indefinitely
• unspecified
• other
1st Party 
Collection
3rd Party 
Collection
Collection 
Mode
Action
Access, 
Edit,
Delete
Access 
Scope
Data 
Retention
Data 
Security
Specific 
Audiences
Do Not 
Track
Policy 
Change
Other
Choice,
Control
Retention 
Period
Security 
Measure
Audience 
group
Do Not 
Track 
Policy
Choice Type
• opt-in 
• opt-out
• opt-out-link
• …
Change 
Type
User 
Choice
Introductory
Choice Type
Contact 
Information
Choice Scope
Notification 
Type
Practice not 
covered
Fig. 3: The privacy taxonomy of Wilson et al. [11]. The top level of the hierarchy (shaded blocks) deﬁnes high-level privacy
categories. The lower level deﬁnes a set of privacy attributes, each assuming a set of values. We show examples of values for
some of the attributes.
ﬁer makes it possible to determine whether a category is
present in a segment by simply comparing its classiﬁca-
tion probability to a threshold of 0.5.
At the lower level, a set of classiﬁers predicts one
or more values for each privacy attribute (the leaves
in the taxonomy of Fig. 3). We train a set of multi-
label classiﬁers on the attribute-level. Each classiﬁer
produces the probabilities p(v j|x) for the values v j ∈
V (b) of a single attribute b. For example, given the
attribute b=information type,
the corresponding clas-
siﬁer outputs the probabilities for elements in V (b):
{ﬁnancial, location, user proﬁle, health, demographics,
cookies, contact information, generic personal informa-
tion, unspeciﬁed, . . . }.
An important consequence of this hierarchy is that in-
terpreting the output of the attribute-level classiﬁer de-
pends on the categories’ probabilities. For example, the
values’ probabilities of the attribute “retention period”
are irrelevant when the dominant high-level category is
“policy change.” Hence, for a category ci, one would
only consider the attributes descending from it in the hi-
erarchy. We denote these attributes as A (ci) and the set
of all values across these attributes as V (ci).
We use Convolutional Neural Networks (CNNs) in-
ternally within all the classiﬁers for two main reasons,
which are also common in similar classiﬁcation tasks.
First, CNNs enable us to integrate pre-trained word em-
beddings that provide the classiﬁers with better gener-
alization capabilities. Second, CNNs recognize when a
certain set of tokens are a good indicator of the class, in
a way that is invariant to their position within the input
segment.
We use a similar CNN architecture for classiﬁers on
both levels as shown in Fig. 4. Segments are split into to-
kens, using PENN Treebank tokenization in NLTK [29].
The embeddings layer outputs the word vectors of these
tokens. We froze that layer, preventing its weights from
being updated, in order to preserve the learnt seman-
tic similarity between all the words present in our Poli-
cies Embeddings. Next, the word vectors pass through a
Convolutional layer, whose main role is applying a non-
linear function (a Rectiﬁed Linear Unit (ReLU)) over
t w1
n
e
w2
m
g
…
e
S
Embeddings
Layer
CNN
+
ReLU
+
Max-
Pooling
Sigmoid
Dense 1
+
ReLU
Dense 2
Classes
Probs
Fig. 4: Components of the CNN-based classiﬁer used.
windows of k words. Then, a max-pooling layer com-
bines the vectors resulting from the different windows
into a single vector. This vector then passes through the
ﬁrst dense (i.e., fully-connected) layer with a ReLU ac-
tivation function, and ﬁnally through the second dense
layer. A sigmoid operation is applied to the output of
the last layer to obtain the probabilities for the possible
output classes. We used multi-label cross-entropy loss
as the classiﬁer’s objective function. We refer interested
readers to [30] for further elaborations on how CNNs are
used in such contexts.
Models’ Training. In total, we trained 20 classiﬁers at
the attribute level (including the optional attributes). We
also trained two classiﬁers at the category level: one for
classifying segments and the other for classifying free-
form queries. For the former, we include all the classes
in Fig. 3. For the latter, we ignore the “Other” cate-
gory as it is mainly for introductory sentences or uncov-
ered practices [11], which are not applicable to users’
queries. For training the classiﬁers, we used the data
from 65 policies in the OPP-115 dataset, and we kept
50 policies as a testing set. The hyper-parameters for
each classiﬁer were obtained by running a randomized
grid-search. In Table 1, we present the evaluation met-
rics on the testing set for the category classiﬁer intended
for free-form queries.
In addition to the precision, re-
call and F1 scores (macro-averaged per label3), we also
show the top-1 precision metric, representing the fraction
of segments where the top predicted category label oc-
3A successful multilabel classiﬁer should not only predict the pres-
ence of a label, but also its absence. Otherwise, a model that predicts
that all labels are present would have 100% precision and recall. For
that, the precision in the table represents the macro-average of the pre-
cision in predicting the presence of each label and predicting its ab-
sence (similarly for recall and F1 metrics).
USENIX Association
27th USENIX Security Symposium    535
Table 1: Classiﬁcation results for user queries at the category
level. Hyperparameters: Embeddings size: 300, Number of
ﬁlters: 200, Filter Size: 3, Dense Layer Size: 100, Batch Size:
40
Category
Prec.
Recall
F1
Top-1
Prec.
Support
1st Party Collection
3rd Party Sharing
User Choice/Control
Data Security
Speciﬁc Audiences
Access, Edit, Delete
Policy Change
Data Retention
Do Not Track
Average
0.80
0.81
0.76
0.87
0.95
0.94
0.96
0.79
0.97
0.87
0.80
0.81
0.73
0.86
0.94
0.75
0.89
0.67
0.97
0.83
0.80
0.81
0.75
0.87
0.95
0.82
0.92
0.71
0.97
0.84
0.80
0.86
0.81
0.77
0.91
0.97
0.93
0.60
0.94
0.84
1267
963
455
202
156
134
120
93
16
curs in the annotators’ ground-truth labels. As evident in
the table, our classiﬁers can predict the top-level privacy
category with high accuracy. Although we consider the
problem in the multi-label setting, these metrics are sig-
niﬁcantly higher than the models presented in the origi-
nal OPP-115 paper [11]. The full results for the rest of
classiﬁers are presented in the Appendix. The efﬁcacy
of these classiﬁers is further highlighted through queries
that directly leverage their output in the applications de-
scribed next.
5 Application Layer
Leveraging the power of the ML Layer’s classiﬁers,
Polisis supports both structured and free-from queries
about a privacy policy’s content. A structured query
is a combination of ﬁrst-order logic predicates over
the predicted privacy classes and the policy segments,
such as: ∃s (s ∈ policy ∧ information type(s)=location ∧
purpose(s) = marketing ∧ user choice(s)=opt-out). On
the other hand, a free-form query is simply a natural lan-
guage question posed directly by the users, such as “do
you share my location with third parties?”. The response
to a query is the set of segments satisfying the predicates
in the case of a structured query or matching the user’s
question in the case of a free-form query. The Appli-
cation Layer builds on these query types to enable an ar-
ray of applications for different privacy stakeholders. We
take an exempliﬁcation approach to give the reader a bet-
ter intuition on these applications, before delving deeper
into two of them in the next sections.
Users: Polisis can automatically populate several of the
previously-proposed short notices for privacy policies,
such as nutrition tables and privacy icons [3, 18, 31, 32].
This task can be achieved by mapping the notices to
a set of structured queries (cf. Sec. 6). Another pos-
sible application is privacy-centered comparative shop-
ping [33]. A user can build on Polisis’ output to auto-
matically quantify the privacy utility of a certain policy.
For example, such a privacy metric could be a combi-
nation of positive scores describing privacy-protecting
features (e.g., policy containing a segment with the la-
bel: retention period: stated period ) and negative scores
describing privacy-infringing features (e.g., policy con-
taining a segment with the label: retention period: un-
limited ). A major advantage of automatically generat-
ing short notices is that they can be seamlessly refreshed
when policies are updated or when the rules to generate
these notices are modiﬁed. Otherwise, discrepancies be-
tween policies and notices might arise over time, which
deters companies from adopting the short notices in the
ﬁrst place.
By answering free-form queries with relevant policy
segments, Polisis can remove the interface barrier be-
tween the policy and the users, especially in conver-
sational interfaces (e.g., voice assistants and chatbots).
Taking a step further, Polisis’ output can be potentially
used to automatically rephrase the answer segments to a
simpler language. A rule engine can generate text based
on the combination of predicted classes of an answer seg-
ment (e.g., “We share data with third parties. This con-
cerns our users’ information, like your online activities. We
need this to respond to requests from legal authorities”).
Researchers: The difﬁcultly of analyzing the data-
collection claims by companies at scale has often been
cited as a limitation in ecosystem studies (e.g., [34]).
Polisis can provide the means to overcome that. For in-
stance, researchers interested in analyzing apps that ad-
mit collecting health data [35, 36] could utilize Polisis to
query a dataset of app policies. One example query can
be formed by joining the label information type: health
with the category of First Party Collection or Third Party
Sharing.