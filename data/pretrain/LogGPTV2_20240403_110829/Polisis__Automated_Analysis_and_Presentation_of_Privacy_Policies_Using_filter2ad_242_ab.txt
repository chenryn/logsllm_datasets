### Corpus of Privacy Policies

We collected a corpus of 130,000 privacy policies from apps available on the Google Play Store. These policies generally outline the overall data practices of the respective app companies. Using the metadata from over 1.4 million Android apps, sourced via the PlayDrone project [27], we identified links to 199,186 privacy policies. We successfully crawled and retrieved 130,326 policies that returned an HTTP status code of 200. The textual content was then extracted from the HTML using the policy crawler described in Section 3. This corpus is referred to as the "Policies Corpus."

Using this corpus, we trained a word-embeddings model with fastText [28], which we will refer to as the "Policies Embeddings." A significant advantage of fastText is its ability to train vectors for subwords (character n-grams of sizes 3 to 6) in addition to whole words. This feature is particularly useful for handling out-of-vocabulary words and spelling mistakes, which are common in free-form user queries.

### Classification Dataset

The Policies Embeddings provide a robust foundation for building classifiers. However, to detect fine-grained labels in privacy policy segments, a labeled dataset is essential. For this purpose, we utilized the Online Privacy Policies (OPP-115) dataset, introduced by Wilson et al. [11]. This dataset contains 115 privacy policies manually annotated by skilled annotators, primarily law school students. In total, the dataset includes 23,000 annotated data practices.

The annotations were conducted at two levels:
1. **Paragraph-sized segments** were labeled according to one or more of the 10 high-level categories (e.g., First Party Collection, Data Retention).
2. **Attribute-value pairs** were used to annotate specific parts of each segment. There are 20 distinct attributes and 138 distinct values across all attributes. Of these, 122 values had more than 20 labels. Figure 3 illustrates the mandatory attributes that should be present in all segments, along with sample values for selected attributes.

### Hierarchical Multi-label Classification

To handle the multiple granularity levels in the policies' text, we constructed a hierarchy of classifiers, each trained to address specific parts of the problem.

#### Top-Level Classifier
At the top level, a multi-label classifier predicts one or more high-level categories for an input segment. The set of all categories is denoted as \( C \). The classifier provides the probability \( p(c_i|x) \) of each high-level category \( c_i \) occurring in the segment. This approach allows for the presence of multiple categories per segment and simplifies the determination of whether a category is present by comparing its classification probability to a threshold of 0.5.

#### Lower-Level Classifiers
At the lower level, a set of classifiers predicts one or more values for each privacy attribute (the leaves in the taxonomy of Figure 3). Each classifier produces the probabilities \( p(v_j|x) \) for the values \( v_j \in V(b) \) of a single attribute \( b \). For example, given the attribute \( b = \text{information type} \), the corresponding classifier outputs the probabilities for elements in \( V(b) \): {financial, location, user profile, health, demographics, cookies, contact information, generic personal information, unspecified, ...}.

An important aspect of this hierarchy is that the output of the attribute-level classifier depends on the categories' probabilities. For instance, the probabilities of the "retention period" attribute are irrelevant if the dominant high-level category is "policy change." Therefore, for a category \( c_i \), only the attributes descending from it in the hierarchy, denoted as \( A(c_i) \), and their values \( V(c_i) \) are considered.

### CNN-Based Classifier Architecture

We use Convolutional Neural Networks (CNNs) within all classifiers for two main reasons:
1. **Integration of Pre-trained Word Embeddings**: This provides better generalization capabilities.
2. **Position-Invariant Token Recognition**: CNNs can recognize when a certain set of tokens are good indicators of a class, regardless of their position within the input segment.

The architecture of the CNN-based classifier is shown in Figure 4. Segments are tokenized using the PENN Treebank tokenizer in NLTK [29]. The embeddings layer outputs the word vectors of these tokens, and this layer is frozen to preserve the learned semantic similarity between words in our Policies Embeddings. The word vectors then pass through a convolutional layer with a ReLU activation function, followed by a max-pooling layer. The resulting vector passes through two dense layers, and a sigmoid operation is applied to the final output to obtain the probabilities for the possible classes. We used multi-label cross-entropy loss as the objective function. For further details on the use of CNNs in this context, see [30].

### Modelsâ€™ Training

In total, we trained 20 classifiers at the attribute level, including optional attributes, and two classifiers at the category level: one for segment classification and another for free-form queries. For segment classification, we included all the classes in Figure 3. For free-form queries, we excluded the "Other" category, as it is mainly for introductory sentences or uncovered practices [11], which are not applicable to user queries. We used data from 65 policies in the OPP-115 dataset for training and kept 50 policies for testing. Hyperparameters were obtained through a randomized grid search. Table 1 presents the evaluation metrics on the testing set for the category classifier intended for free-form queries.

In addition to precision, recall, and F1 scores (macro-averaged per label), we also show the top-1 precision metric, representing the fraction of segments where the top predicted category label matches the ground-truth labels. Our classifiers achieve high accuracy in predicting the top-level privacy category, with significantly higher metrics compared to the models presented in the original OPP-115 paper [11]. Full results for the rest of the classifiers are provided in the Appendix.

### Application Layer

Leveraging the power of the ML Layer's classifiers, Polisis supports both structured and free-form queries about a privacy policy's content. 

- **Structured Query**: A combination of first-order logic predicates over the predicted privacy classes and policy segments, such as: \( \exists s (s \in \text{policy} \land \text{information type}(s)=\text{location} \land \text{purpose}(s) = \text{marketing} \land \text{user choice}(s)=\text{opt-out}) \).
- **Free-Form Query**: A natural language question posed directly by users, such as "Do you share my location with third parties?"

The response to a query is the set of segments satisfying the predicates for structured queries or matching the user's question for free-form queries. The Application Layer builds on these query types to enable various applications for different privacy stakeholders.

#### Users
Polisis can automatically generate short notices for privacy policies, such as nutrition tables and privacy icons [3, 18, 31, 32], by mapping the notices to a set of structured queries. Another application is privacy-centered comparative shopping [33], where Polisis' output can be used to quantify the privacy utility of a policy. For example, a privacy metric could combine positive scores for privacy-protecting features (e.g., "retention period: stated period") and negative scores for privacy-infringing features (e.g., "retention period: unlimited"). Automatically generating short notices ensures they remain up-to-date with policy changes, reducing discrepancies over time.

By answering free-form queries with relevant policy segments, Polisis removes the interface barrier between the policy and the users, especially in conversational interfaces (e.g., voice assistants and chatbots). Additionally, Polisis' output can be used to rephrase answer segments into simpler language, enhancing user understanding.

#### Researchers
Polisis can facilitate large-scale analysis of data-collection claims by companies, overcoming a common limitation in ecosystem studies [34]. For example, researchers interested in analyzing apps that collect health data [35, 36] can use Polisis to query a dataset of app policies. A sample query might combine the label "information type: health" with the categories "First Party Collection" or "Third Party Sharing."

This comprehensive approach leverages advanced machine learning techniques to provide a robust and versatile tool for understanding and interacting with privacy policies.