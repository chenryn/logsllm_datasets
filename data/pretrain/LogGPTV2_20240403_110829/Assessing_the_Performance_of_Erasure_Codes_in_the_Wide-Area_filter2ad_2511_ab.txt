20.0 - 24.9 Mbps
15.0 - 19.9 Mbps
10.0 - 14.9 Mbps
1
2
3
4
5
6
7
8
Data Blocks per Set (N)
Figure 2. Best overall performance given n and m over the Slow Regional Distribution
parameters when n and m are the given values. The trends proposed in section 5.3 emerge in several ways,
but the different distributions of the blocks appear to strengthen and weaken different trends.
The slow regional distribution shown in Figure 2 produces a very regular pattern with diagonal bands
of performance across the grid. The two trends that dominate are that performance improves as m increases
and n remains ﬁxed, and that performance degrades as n increases and m remains ﬁxed. Furthermore, both
trends seem to have equal weight. Performance improves whenever the rate of encoding decreases, but
does not show signiﬁcant changes when the set size increases and the encoding rate stays the same - more
speciﬁcally, increased set size does not signiﬁcantly harm performance in smaller sets, nor does it improve
performance due to a more advantageous block distribution.
The only difference between the regional distribution and the slow regional distribution is that all of the
blocks in the regional distribution are nearby, and none of the blocks in the slow regional distribution are
nearby. As such, the performance per block of the regional network ﬁle is quite good, and the only trend
that emerges in Figure 3 is that performance degrades as n, and thus the decoding time per set, increases.
(Note that Figures 2, 3 and 4 have different scales for the shading blocks, so that relative trends rather than
absolute trends may emerge).
The hodgepodge distribution exhibits more interesting behavior in Figure 4 than either of other distri-
butions. In general, performance improves as m increases and n remains ﬁxed; the columns where n = 5
8
)
M
(
t
e
S
r
e
p
s
k
c
o
l
B
k
c
e
h
C
9
8
7
6
5
4
3
2
1
1
2
80.0 - 81.9 Mbps
78.0 - 79.9 Mbps
76.0 - 77.9 Mbps
74.0 - 75.9 Mbps
72.0 - 73.9 Mbps
70.0 - 71.9 Mbps
68.0 - 69.9 Mbps
66.0 - 67.9 Mbps
8
9
4
3
7
Data Blocks per Set (N)
5
6
Figure 3. Best overall performance given n and m over the Regional Distribution
)
M
(
t
e
S
r
e
p
s
k
c
o
l
B
k
c
e
h
C
9
8
7
6
5
4
3
2
1
1
2
60.0 - 64.9 Mbps
55.0 - 59.9 Mbps
50.0 - 54.9 Mbps
45.0 - 49.9 Mbps
40.0 - 44.9 Mbps
35.0 - 39.9 Mbps
8
9
4
3
7
Data Blocks per Set (N)
5
6
Figure 4. Best overall performance given n and m over the Hodgepodge Distribution
9
Table 2. Summary of Reed-Solomon and LDPC Coding
Primary Operation
Quality of Encoding
Decoding Complexity
Overhead Factor
Reed-Solomon
Galois-Field Dot Products
Optimal
O(n3)
1
LDPC
XOR
Suboptimal
O(n ln(1=(cid:15))), where (cid:15) 2 R [11]
Roughly 1.15
and 6 are good examples of this behavior. Performance also diminishes as n increases; observe for example,
the rows where m = 5 and 8. These are the same trends that turned up in the slow regional distribution;
however, the upper right quadrant of the grid has better performance relative to the rest of the grid than the
upper right quadrant of the slow regional grid. There are two possible reasons for this: ﬁrst, the performance
is improving due to distribution advantages that arise in larger sets, and second, the trend that performance
improves as m increases is stronger than the trend that performance declines as n increases. (these observa-
tions are entirely focused with “small” sets; as n increases beyond a point, decoding will take much longer
than downloading, regardless of set size or distribution) The hodgepodge distribution spreads the blocks
across 50 servers that are not related to each other in any way, while the regional and slow regional distribu-
tions spread the blocks across only 4 regions that typically contain less that 50 servers. Thus, it is likely that
the loads of servers in the same region interfere with each other, and the hodgepodge distribution may have
performance advantages because of this that are not visible in the regional and slow regional network ﬁles.
6 Reed-Solomon vs. LDPC
Table 2 summarizes some of the key differences between Reed-Solomon and LDPC coding. When
comparing the two types of coding, the properties of key importance are the encoding and decoding times,
and the average number of blocks that are necessary to reconstruct a set. LDPC codes have a great advantage
in terms of encoding and decoding time over Reed-Solomon codes; in addition, Reed-Solomon decoding
requires n blocks from a set before decoding can begin, while LDPC decoding can take place on-the-ﬂy.
However, for small n, the extra blocks that LDPC codes can require for decoding can cause substantial
performance degradation. Moreover, for systems where the network connection is slow, Reed-Solomon
codes can sometimes outperform LDPC codes despite the increased decoding penalty [16].
Table 3 shows the parameter space explored in the next set of experiments, which compare Reed-
Solomon coding to LDPC coding. Since LDPC coding may fare poorly in very small sets, sets up to
10
Table 3. LDPC vs. Reed-Solomon Experiment Space
Parameter
Simultaneous Downloads
Range of Parameters
T 2 [20; 30]
Work Replication and Failover Strategy
fR; P g 2 [f1; 1g; f2; (30=n)g], static timeouts
Server Selection
Block Selection
Coding
Fastest0, Fastest1
Db-ﬁrst, Dont-care
fn; mg 2 [f5; 5g; f10; 10g; f20; 20g; f50; 50g; f100; 100g]
size 200 were tested. The experiments test the same values for T , R, P , and server selection algorithm that
were used in the Reed-Solomon experiments. In addition, a new block selection criteria based on the type
of block is introduced, and will be detailed in section 6.1. The actual codes used are listed in the Appendix.
They were derived as a part of the exploration in [16], and therefore are not provably optimal.
6.1 Subtleties of LDPC Implementation
The implementation of LDPC coding involves several subtleties that are not present in that of Reed-
Solomon coding. First, the fact that LDPC coding sometimes requires more than n blocks affects not only
how many blocks must be retrieved, but also limits which blocks the client application can choose. A wide
range of block scheduling strategies may be applied to an LDPC coding set. At one extreme, blocks are
downloaded randomly, until enough blocks have been retrieved to decode the set. It is likely that some of the
coding blocks will become useless by the time they are retrieved, and that some data blocks may be decoded
before they are retrieved. Both of these possibilities increase the number of blocks that are needlessly
downloaded. At the other extreme, a download may be simulated in order to determine an “optimal” set of
blocks that can be used to decode the set. Note that it is possible every time to choose a set of exactly n
blocks that can be used for decoding. The difﬁculty here is that it must be determined up front which blocks
are coming from the fastest servers. In our previous experiments we tested a number of different server
selection algorithms that judged servers based on speed and on load. The speed of servers remains ﬁxed in
most of the server scheduling algorithms, but the load is always dynamic, and any optimal schedule would
have to approximate the load of servers not only throughout the download of a given set, but between the
downloads of different sets in the ﬁle, since they often overlap. Moreover, such a scheduling algorithm is
somewhat complicated to implement and may not offer signiﬁcant performance enhancements once its own
computation time is factored into performance. The following experiments use a compromise between the
two extreme scheduling options: when selecting a block to download, the downloading algorithm will skip
11
Distribution 1
Distribution 2
Region 1 (fast)
Region 2 (slow)
Region 1 (fast)
Region 2 (slow)
1
3
2
4
1
2
3
4
1
2
3
4
Data 
Blocks
Check 
Blocks
Fastest−0
Lightest−Load
Figure 5. Distribution Woes. The performance of different server scheduling algorithms can vary
greatly depending on the distribution of a ﬁle with LDPC coding. In distribution 1, the Lightest-load
algorithm performs best, while in distribution 2, the Fastest0 algorithm performs best.
over check blocks that can no longer contribute to decoding and data blocks that are already decoded. The
algorithm also allows one of two block preferences to be speciﬁed:
(cid:15) Data blocks ﬁrst (db-ﬁrst): data blocks are always preferred over check blocks.
(cid:15) Don’t care (dont-care): the type of blocks is ignored, and blocks are chosen solely based on the speed
and load of the servers on which they reside.
In the previous experiments over only Reed-Solomon codes, only the dont-care algorithm was used.
The second major subtlety in the implementation of LDPC coding is that the distribution of the ﬁle
can have a great impact on the performance of different server scheduling algorithms. Consider the example
depicted in Figure 5, where n = 2, and m = 2, and there are two server regions. Figure 5 shows two possible
distributions of the blocks, and which blocks would be chosen from each distribution by the Fastest0 and
Lightest-load server scheduling algorithms [6], where the Lightest-load algorithm always chooses the
server with the lightest load. Depending on the distribution, one of the algorithms results in two blocks
that can be used to reconstruct the entire set, and the other does not. The unfortunate consequence of this
characteristic is that the performance can vary greatly between different server scheduling algorithms not
because of the algorithms themselves, but because of the ﬁle’s distribution. The following experiments use
the Fastest0, and Fastest1 server scheduling algorithms, and the same distributions described in section 5,
which do not address the distribution subtleties of LDPC coding – it is a subject of further work to address