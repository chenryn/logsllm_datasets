title:Measurement and evaluation of a real world deployment of a challenge-response
spam filter
author:Jelena Isacenkova and
Davide Balzarotti
Measurement and Evaluation of a Real World Deployment
of a Challenge-Response Spam Filter
Jelena Isacenkova, Davide Balzarotti
Eurecom, Sophia Antipolis, France
{isachenk,balzarotti}@eurecom.fr
ABSTRACT
Despite the number of existing solutions, spam still accounts
for a large percentage of the email traﬃc on the Internet.
Both the eﬀectiveness and the impact of many common anti-
spam techniques have already been largely studied and eval-
uated against multiple datasets. However, some of the less
known solutions still lack a proper experimental validation.
For example, Challenge-Response (CR) systems have been
largely discussed, and often criticized, because they shift the
eﬀort to protect the user’s mailbox from the recipient to the
sender of the messages. In addition, these systems are be-
lieved to produce a lot of backscattered emails that further
deteriorate the global Internet situation.
In this paper we present the ﬁrst comprehensive measure-
ment study of a real anti-spam system based on a challenge-
response technique. In our work we analyze a large amount
of data, collected for a period of six months from over forty
companies protected by a commercial challenge-response prod-
uct. We designed our experiments from three diﬀerent point
of views: the end user, the system administrator, and the
entire Internet community. Our results cover many diﬀer-
ent aspects such as the amount of challenges sent, the delay
on the message delivery, and the likelihood of getting the
challenge server blacklisted.
Our aim is neither to attack nor to defend CR-based so-
lutions. Instead, we hope that our ﬁndings will shed some
light on some of the myths about these kind of systems,
and will help both users and companies to take an informed
decision on the topic.
Categories and Subject Descriptors
C.4 [Performance of Systems]: Measurement techniques,
Performance attributes
General Terms
Experimentation, Measurement
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
IMC’11, November 2–4, 2011, Berlin, Germany.
Copyright 2011 ACM 978-1-4503-1013-0/11/11 ...$10.00.
Keywords
Spam, whitelist, challenge-response, blacklisting
1.
INTRODUCTION
Despite the considerable eﬀort and the large amount of
proposed solutions to detect and ﬁlter unsolicited emails,
according to the MessageLabs Intelligence Annual Security
Report [35] published by Symantec, in 2010 spam still ac-
counted for 89.1% of the emails on the Internet. Even worse,
according to the same Symantec’s report, in 2010 the spam
volume increased by 1.4% compared with the previous year.
Traditional anti-spam solutions are based on two common
techniques: ﬁltering emails based on their content, or ﬁlter-
ing them based on their senders. The ﬁrst category includes
content-based text classiﬁcation techniques [15, 19, 32, 33]
that aim at ﬁnding (often using supervised learning) the to-
kens commonly associated to spam messages. The second
category includes instead detection methods based on some
properties of the sender [24, 30, 31], of his reputation [11,
36], or of the domain from which the email is delivered [18,
22, 36].
Even though these two categories cover most of the widely
adopted techniques, a number of other solutions have also
been proposed to ﬁght spam. One notable example is repre-
sented by Challenge-Response (CR) ﬁlters [21, 29], a solu-
tion based on the observation that the large majority of good
emails are delivered from senders that are already known
to, and trusted by, the recipient. The name of the approach
comes from the fact that, whenever the sender of an email
is unknown (i.e., not yet in the user’s personal whitelist),
the system temporarily quarantines the email and automat-
ically sends back a message to the sender, asking him to
solve a simple challenge to verify his legitimacy. This tech-
nique somehow changes the traditional approach of treating
incoming emails, shifting the delivery responsibility from the
recipient to the sender of the message.
Since their ﬁrst introduction, CR-based techniques have
been considered an extremely controversial solution [13, 2].
On the one hand, they seem to be able to completely block
any unsolicited email, but, on the other hand, they also
have a number of side-eﬀects that can seriously hamper their
adoption on a large scale.
In particular, it is possible to group the main criticisms
against CR systems around three main points. First, the so-
cial and usability issues that, on one side, are related to the
eﬀorts required from the user to maintain a proper white-
list, and, on the other, to the annoyance for the sender that
has to invest time to solve a challenge in order to have his
413message delivered. Previous studies, in particular Erickson
et al. [21], have already studied the usability of CR systems
in controlled experiments. Their study concludes that such
systems are very eﬀective when accompanied with already
existing anti-spooﬁng techniques. The authors also measure
that CR solutions outperform traditional systems like Spa-
mAssassin, generating on average 1% of false positives with
zero false negatives.
The second point against CR systems concerns the fact
that they can introduce a (possibly conspicuous) delay in
the emails delivery due to the quarantine period applied to
previously unknown senders. Finally, the last (and one of
the main) critique against CR systems is due to the chal-
lenge emails sent in response to spam messages. Since un-
solicited emails often contain spoofed sender addresses, the
challenges are often delivered to non-existing recipients or to
innocent users. These misdirected messages (often referred
as “backscattered” spam) pollute the Internet with unneces-
sary traﬃc and damage other users that may receive chal-
lenges for emails they never sent. From this point of view,
CR antispam ﬁlters seem to literally bounce the spam back
towards other innocent users. However, supporters of the
CR approach often rebut by saying that well-designed sys-
tems only send back a challenge to a few percents of the
spam messages they receive. Therefore, considering the fact
that real forged addresses are not too common, normal users
are very unlikely to often receive misdirected challenges. Un-
fortunately, since both sides lack real data to support their
own hypothesis, it is hard for users and companies to tell
which is the truth and take a conscious decision.
To the best of our knowledge, this paper presents the ﬁrst
study on both the eﬀectiveness and the impact of a real-
world deployment of a challenge-based antispam solution.
In our work we measure and analyze a large amount of data
collected for a period of six months from 47 companies pro-
tected by a commercial CR-based antispam product.
In particular, we conduct our measurements to analyze the
behavior of CR systems from three diﬀerent perspectives:
1. From the end user point of view, to measure how this
technique aﬀects the delivery of both spam and normal
messages to the end user’s mailbox;
2. From the server’s administrator point of view, focusing
on some of the problems of maintaining a CR installa-
tion in a real company;
3. From the Internet point of view, to measure the amount
and the impact of backscattered messages and misdi-
rected challenges.
It is important to stress the fact that the purpose of this
study is neither to attack nor to defend CR-based solutions.
Instead, our goal is to provide real-world ﬁgures and statis-
tics that can help both users and companies to take an in-
formed decision based on our study. Our results can also
help to shed some light on some of the myths related to CR
antispam techniques.
The rest of the paper is organized as follows.
In Sec-
tion 2 we introduce our data collection methodology and
the dataset we used in our measurements. Section 3 presents
a study of the amount of challenges sent by a CR system.
Section 4 describes the eﬀectiveness of CR systems in dis-
tinguishing spam from legitimate messages. Section 5 in-
troduces some of the problems related to maintaining this
type of antispam ﬁlter. Then, we summarize our ﬁndings in
Section 6, present a survey of related work in Section 7, and
ﬁnally conclude the paper in Section 8.
2. DATA COLLECTION
In this section, we describe the dataset we used in our
experiments and we provide a short overview of our data
collection methodology.
System Overview
Our study has been carried out within a company providing
an anti-spam solution based on a challenge-response tech-
nique. Figure 1 presents the overall system architecture and
a “weighted” lifecycle of the incoming emails. The CR ﬁlter
consists of two main components: a message dispatcher and
a set of additional spam ﬁlters.
The dispatcher receives the incoming messages from the
company’s Incoming Mail Transfer Agent (MTA-IN) server.
Some of the email servers were conﬁgured to work as open
relays, serving emails also for a restricted number of do-
mains that are diﬀerent from the ones in which the systems
are installed. This conﬁguration allows the server to accept
messages not targeting to, or originating from, known users
in the system.
The MTA-IN server ﬁrst checks if the email address is well
formed (according to RFC822 [17]) and then if it is able to
resolve the incoming email domain. In addition, if the server
is not conﬁgured as an open relay, it also veriﬁes that the
recipient exists in the system.
Our study shows that this ﬁrst layer of simple checks is
responsible to drop more than 75% of the incoming messages
(see Figure 2), while open-relay systems pass most of the
messages to the next layer. These results are perfectly in
line with similar values reported by the other analysis of
spam delivery rate [34, 26]. The reasons behind the dropped
messages are summarized in the following table:
Dropped Percentage Reason
0.06% Malformed email
4.19% Unable to resolve the domain
2.27% No relay
0.03% Sender rejected
62.36% Unknown Recipient
The second check point for the incoming emails is at the
internal email dispatcher. This component is the core of the
CR infrastructure and it is the one responsible for deciding
to which category the email belongs to: white, black or gray.
The white and black spools are controlled by the user’s
whitelist and blacklist. Emails in the black category are
dropped immediately, while emails from senders in the white-
list are delivered to the user’s INBOX. Emails matching none
of the previous lists fall in the gray category. These messages
are then ﬁltered with additional antispam techniques (e.g.,
virus scan, reverse DNS and IP blacklisting).
If an email
passes the ﬁlters, then dispatcher sends a challenge-response
message to the original sender containing a request to solve
a CAPTCHA. Otherwise, the email is considered spam and
it is dropped.
Figure 1 also reports the average number of messages for
each spool, assuming that 1,000 emails are received by the
MTA-IN. The ﬁgures are computed by aggregating the data
of all the monitored servers not conﬁgured as open relay.
414Figure 1: Lifecycle and distribution of incoming emails
Figure 3 shows that the other spam ﬁlters included in the
CR engine drop on average 54% of the gray emails. Chal-
lenge messages are instead generated for 28% of emails. In
the open relay cases, the engine ﬁlters have a lower perfor-
mance rate, and the number of challenges sent increases by
an extra 9%. This shows that, in an open relay conﬁgura-
tion, the CR system receives more junk messages and it is
more likely to reply with a challenge to illegitimate emails.
Whitelisting process
The process of email whitelisting involves both parties: the
sender and the recipient. There exist several alternative
ways for the email address to get added to a user’s white-
list. In particular, the system we tested in our experiments
supported the following mechanisms:
• The sender solves a challenge sent by the CR system
as a response to one of his messages;
• The user authorizes the sender from the daily message
digest;
• The address is manually added to the whitelist by the
user;
• The user previously sent an email to that address.
In the general scenario, suppose that Alice sends an email
to Bob, a user protected by a challenge-response system. If
this is the ﬁrst communication between Alice and Bob, the
system temporarily stores the email in a “gray” spool and
sends back a message to Alice. The message includes a link
to a webpage that contains a CAPTCHA (the challenge)
that Alice has to solve to get her email delivered and her
address added to Bob’s whitelist. After this simple authen-
tication step, Alice’s address is considered trustworthy, and
the CR system will not interfere in any future communica-
tion between the two users, promptly delivering to Bob any
further message coming from Alice.
If Alice does not solve the challenge, the email stays in
the gray spool for a period of 30 days, after which it is
dropped by the system. Bob also receives a daily digest
that summarizes the quarantined messages, so that he can
manually authorize them or delete them from the list.
Figure 2: MTA-IN email treatment
Figure 3: Message category at the internal email
processing engine
General Statistics
In our experiment we collected statistical data about a com-
mercial system deployed in 47 companies of diﬀerent sizes.
The monitoring period lasted for 6 months, between July
and December 2010. For some of the servers we had access
to the data for the entire time frame, while for other com-
panies our collection was limited to a shorter period of time
(with a minimum of 2 months).
In total we collected statics for 90 millions of incoming
emails. All the results were sanitized to protect both the end
users and the companies privacy. In particular, we never got
access to the message bodies and we stored only aggregated
ﬁgures obtained from the automated analysis of the email
headers.
The data collection was performed on a daily basis by ana-
lyzing the logs of the MTAs and of the challenge-response en-
gines. In addition, information about the solved CAPTCHAs