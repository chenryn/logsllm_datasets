howmanyindividualsensorreadingsshouldbesomehowsegmentedorclustered
to classify an activity is the subject of many recent works [11]. Recently, there
have a been a number of authors who have concentrated their efforts applying
on-line segmentation of sensors readings using fixed or dynamic windows com-
bined with ensemble-based learning [10,22]. These state-of-the-art approaches
have attempted to address the aforementioned challenges but to various degrees
ofsuccess.
As the basis of our work we focus on how the frequency of sensor activations
contributetoactivityrecognition.AlthoughJureketal.[15]appliedthismethod
in their Cluster-Based Ensemble-Classifier (CBCE) framework, our approach is
to consider the frequency information quite differently by transforming it into a
TermFrequency-InverseDocumentFrequency(TF-IDF)representationinspired
by [13].
Ourcontributionsarethatweextendboththeseideasintoanewframework
wellsuitedtolearningcompactrepresentationsofdatastreamsisemployedcre-
ating a model with less complexity than prior solutions but still achieves com-
parableaccuracy.Asopposedto[15]wealsoincorporatediscriminatingbetween
up to two residents’ interleaving activities and adopt more sensors than those
reported in [13] in an attempt to improve classifier performance.
The rest of the paper is organized as follows. In Sect.2, we briefly review
relevant prior work in techniques for classification of smart home sensor data in
smart homes. Section3 briefly describes our proposed methodology. The details
of the methodology and experiments applying our framework are described in
Sect.4. The results and discussion of the experiments are presented in Sect.5.
Finally, in Sect.6 we revisit our key objectives in the context of the results we
obtained leading to areas of improvement in future work.
IR-Based Approach for Smart Home Activity Recognition 585
2 Background
The specific motivation for our work has been driven by the increased attention
to smart homes in healthcare [1]. Amiribesheli et al. [2] surveyed the state of
these technologies, which when combined, form the infrastructure to model and
recognize activities to support the elderly in their independent living especially
for those individuals who have chronic conditions (e.g. dementia). Moreover,
detecting these activities may also help to identify anomalous behaviors to aid
such individuals to maintain their independence.
To identify activities requires that sensor activations somehow be combined
to form an instance of an activity. Because the duration of the activity is not
known in advance work conducted by [4] investigated how a sliding fixed win-
dow coupled with a knowledge-based approach could be used to segment sensor
readings into activities. [21] extended this approach proposing a dynamically
sized window that could shrink and expand to better accommodate the correct
number of sensors readings contributing to an instance of an activity. Similarly,
[19] adopted this same approach but also past contextual information e.g. that
a'Enter_Home'activitywouldnormallyhappenaftera'Leave_Home'activity.
Howeverthereareweaknessesinthispriorworksuchastheunduecomplexityof
thewindowingalgorithmsandtheinabilitytohandlesignificantclassimbalance.
As opposed to the conventional techniques for analyzing this type of data
on-line which are largely based on processing the readings at the individual
sensor-level,[14]describesanoff-linemethodemployedtolearnmultiplemodels
for each activity using a novel context-aware hierarchical clustering algorithm
which retains information about the sequences of activities that a residents’
regular behavior is composed of.
[15]performedsimilarworkwherethefrequencyofsensoractivationsforeach
activity are computed and fed into a clustering-based ensemble learning model.
Although this method addresses the class imbalance issue, it loses the sequence
inwhichthesensorswereactivated.Inaddition,thetworepresentationsofsensor
activations used were based on simple frequency-based information; either how
manytimesasensoractivatedduringanactivityorwhetherornotthatasensor
was active during an activity.
However, we argue that such frequency-based information could be of use
if it provided more insight into which sensor(s) contributed more to classifying
an instance of an activity. Furthermore, by doing so such a method could still
produce prototypical configurations of various activities and these prototypes
can then be analysed clustered, compared, and classified.
3 Methodology
Our proposed framework consists of three distinct parts:
1. A data pre-processing step which constructs sensor activation sequences into
prototype activities.
586 B. J. Woodford and A. Ghandour
2. Transformation of these prototype activities into a TF-IDF representation.
3. Use the TF-IDF representation as input to four different supervised learning
algorithms.
4 Framework Implementation
4.1 Data Preprocessing
As mentioned beforehand, in this article we adopted a different approach com-
paredwith previous work. Insteadof generating variable-length windows of sen-
sor sequences as proposed by [21], we create a vector representing the duration
and frequency information of each sensor for an activity similar to the work of
[14,15]. In this way each vector can be investigated and compared with each
other as they have the same length. This “chunking” or meta-representation
alsolendsitselftoasimplerandmoreappropriaterepresentationforsubsequent
TF-IDF transformation. An additional advantage of this approach is that the
representation can be built up independent of the number of residents living in
the home.
To elaborate, each instance of the original data set is a six-dimensional vec-
tor where each instance consists of a mandatory date, time, sensor number, a
corresponding sensor status, and an optional activity type and activity status.
Algorithm 1 presents a version of the method used to transform these individ-
ual sensor readings into a generic representation suitable for any supervised or
unsupervised learning algorithm. Algorithm 1 assumes that for each identified
activitythereisacorresponding'end'activitystatusforeach'begin'activity
status.
All generated activity prototypes are represented using six features,
{f ,f ,...,f }. f is the date and start time of the activity, f is the elapsed
1 2 6 1 2
time in seconds for an activity, f is the sensor that activated at the start of the
3
activity, f is the sensor that activated at the end of the activity, f is a vector
4 5
containing the frequency information for each sensor that activated during the
occurrence of the activity, and finally f is the activity type itself.
6
For example, presented in Fig.1 is a section from the Aruba data set [6].
After Algorithm1 is runover this section, a single activity vector is constructed
as presented in Table1.
With a significantly reduced number of prototypes compared with the num-
berofinstancesintheoriginaldatasetasshowninTable3,trainingofasuitable
classifier should take less time as there are fewer examples to learn. This is an
advantage of the representation for these prototypes but the real strength of it
is this representation affords a wider range of data analysis techniques to be
appliedsincewearenownotrestrictedtoonlyon-linedatastreamclassification
methods.
IR-Based Approach for Smart Home Activity Recognition 587
4.2 Generating the TF-IDF Representation
Our assumption is that some sensors would be more important than others to
aid activity recognition process. In order to determine these critical sensors, we
ALGORITHM 1: Activity Feature Selection
Input:
S: A data set of sensor readings.
activityTypes: A vector of activity type labels.
sensorTypes: A vector of sensor labels.
Output:
SEFMatrix: A set of activity prototypes each labelled with a corresponding
activity type.
1 resStorage← Size(activityTypes);
2 FVMatrix← Size(sensorTypes);
3 actInd←1;
4 for i←1 to Size (S) do
5 SR← instance of data set S i;
6 Identify activity type, AT from SR;
7 Determine activity status AS from AT;
8 if AS status is 'begin' then
9 Set resInd to the index in activityTypes where AT was found;
10 Set resStorage[resInd].startTime to the start timestamp of the
activity;
11 Set resStorage[resInd].startSensor to the activated sensor in SR;
12 resStorage[resInd].activityTypes←AT;
13 else if AS status is 'end' then
14 Set resInd to the index in activityTypes where AT was found;
15 Set resStorage[resInd].endSensor to the activated sensor in SR;
16 Set activityDuration to the number of seconds elapsed between the
start and end times of the activity;
17 SEFMatrix[actInd,1]= resStorage[resIndex].startTime;
18 SEFMatrix[actInd,2]=activityDuration;
19 SEFMatrix[actInd,3]=startSensor;
20 SEFMatrix[actInd,4]=endSensor;
21 SEFMatrix[actInd,5]= resStorage[resInd].FVMatrix;
22 SEFMatrix[actInd,6]=AT;
23 resStorage[resIndex]=activityInstance;
24 actInd+=1;
25 else if resIndex> 0 then
26 Set theIndex to the location in sensorTypes where the activated sensor
in SR was found;
27 resStorage[resInd].FVMatrix(theIndex)+=1;
28 end
29 end
588 B. J. Woodford and A. Ghandour
...
2010-11-04 05:40:51.303739 M004 ON Bed_to_Toilet begin
2010-11-04 05:40:52.342105 M005 OFF
2010-11-04 05:40:57.176409 M007 OFF
2010-11-04 05:40:57.941486 M004 OFF
2010-11-04 05:43:24.021475 M004 ON
2010-11-04 05:43:26.273181 M004 OFF
2010-11-04 05:43:26.345503 M007 ON
2010-11-04 05:43:26.793102 M004 ON
2010-11-04 05:43:27.195347 M007 OFF
2010-11-04 05:43:27.787437 M007 ON
2010-11-04 05:43:29.711796 M005 ON
2010-11-04 05:43:30.279021 M004 OFF Bed_to_Toilet end
...
Fig.1. Extract of sensor data from the Aruba data set [6].
Table 1. Breakdown of an activity prototype
Feature Description Value
f 1 Start timestamp '2010-11-04 05:40:51.303739'
f 2 Activity duration 158.9753
f 3 First sensor 'M004'
f 4 Last sensor 'M004'
f 5 Sensor activations 0,0,0,6,2,0,4,0,0,0,0,0,0
0,0,0,0,0,0,0,0,0,0,0,0,0
0,0,0,0,0,0,0,0,0,0,0,0,0
0,0,0,0,0,0,0,0,0,0,0,0,0
f 6 Activity label 'Bed_to_Toilet'
adopt the TF-IDF measure from the field of Information Retrieval (IR) [18] to
evaluate sensor importance.
Consider a set of terms T = {t 1,t 2,...,t m} and a set of documents D =
{d 1,d 2,...,d n}.ThecommonuseofTF-IDFistoevaluatehowimportantaterm,
t∈T,istoadocument,d∈D.Moreformally,TF-IDFisdefinedinEq.1as
TF-IDF(t,d)=TF(t,d)×IDF(d,t,D) (1)
TF(t,d)=times(t,d)/(times(t 1,d)+times(t 2,d)+...+times(t m,d)) where
times(t,d)ishowmanytimestheterm,t,appearsinthedocumentd.IDF(t,d,D)
= log(|D|/(1+|{d|d∈D and times(t,d)>0|})).
We can adapt this equation to determine how important a sensor is to an
activity instance. So, instead of a set of terms, T, we have a set of sensors,
S = {s 1,s 2,...,s m}. Similarly instead of the set of documents, D, we have
a set of activity instances AI = {ai 1,ai 2,...,ai n}. TF-IDF(s,ai) is therefore
IR-Based Approach for Smart Home Activity Recognition 589
defined as TF-IDF(s,ai) = TF(s,ai) × IDF(ai,s,AI). By applying TF-IDF in
this way, sensors that occur often in a specific activity instance but not in all
activity instances will have higher weights assigned to them. To this end we can
transform SEFMatrix by Eq.1 into a TF-IDF representation.
Finally, as therangeofvaluesproducedbyTF-IDFsometimes couldbeout-
sidetheboundariesofacceptablevaluesforinputtoalearner,theTF-IDFvalues
are both normalized using both Eq.2 and Eq.3 as defined by [13]. Performing
these transformations on the original (Raw) SEFMatrix produces three addi-
tional data sets 1) TF-IDF, 2) LogSig(TF-IDF), and 3) TanSig(TF-IDF). Our
assumption in having the original SEFMatrix and its three aforementioned
variants of each smart home data set is that the Raw representation would pro-
vide a baseline performance for the classifier it was trained and tested on. A
similar classifier would then exhibit improved performance when trained and
testedoneachofthethreevariants.Bydemonstratingthisimprovementinper-
formance would help to justify the utility of these IR-based representations of
smart home sensor data.
1
LogSig(TF-IDF(s,ai))= (2)
1+e(TF-IDF(s,ai))
eTF-IDF(s,ai)−e−(TF-IDF(s,ai))
TanSig(TF-IDF(s,ai))= (3)
eTF-IDF(s,ai)+e−(TF-IDF(s,ai))
Toevaluateourmethodprototypesfromtwosmarthomedatasets,Aruba[6]and
Kyoto[7],wereusedforallexperimentsreportedinthiswork.AfeatureofAlgo-
rithm 1 describedin Sect.4 is that it has been designed to discriminate between
interleavingactivitiesofuptotworesidentswhichisthecasewiththeKyotodata
set.ThenumberandtypeofsensorsforeachsmarthomeissummarizedinTable2.
Ascanbeseen,theconfigurationofthesensorsinthetwosmarthomeswerevaried
but this was a feature of these smart homes as we wanted to test our framework
onasmanydiversesmarthomedatasetsaspossible.
Table 2. Set-up of each smart home and number of sensors.
Data set Sensor type
Motion Door Temperature Pressure Other
Aruba 31 3 5 N/A 3
Kyoto 51 15 5 1 16
Table 3. Breakdown for the number of instances of the two data sets.
Data set Individual sensor readings Prototypes created
Aruba 1719559 6477
Kyoto 2804813 3744
590 B. J. Woodford and A. Ghandour
Table 4. Breakdown of the number of prototypes for each activity class.
Aruba Kyoto
Activity class No. Instances Activity class No. Instances
Meal preparation 1606 R1 Bathing 31
Relax 2919 R1 Bed toilet transition 24
Eating 257 R1 Eating 26
Work 171 R1 Enter home 85
Sleeping 401 R1 Housekeeping 1
Wash dishes 65 R1 Leave home 147
Bed to toilet 157 R1 Meal preparation 131
Enter home 431 R1 Personal hygiene 550
Leave home 431 R1 Sleep 274
Housekeeping 33 R1 Sleeping not in bed 4
Resperate 6 R1 Wandering in room 15
R1 Watch TV 110
R1 Work 504
R2 Bathing 55
R2 Bed toilet transition 6