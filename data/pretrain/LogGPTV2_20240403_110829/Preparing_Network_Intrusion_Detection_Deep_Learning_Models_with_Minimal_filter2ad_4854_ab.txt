Figure 4: Principal component analysis (PCA) transforma-
tion. The first graph plots two features, f1 and f2, and the
second graph plots the two principal components pc1 and
pc2 after applying PCA transformation. The lines below the
graphs show the features and principal components plotted
individually to demonstrate variability. Source: [40]
from the respective GANs share the weights in the first few layers
and learn to generate synthetic images in the source and target
distributions simultaneously from input noise [29]. The adversar-
ial discriminative DA (ADDA) approach completely uncouples the
source and target G weights while keeping a single D [48], whereas
domain-adversarial training of neural networks (DANN) approach
uses a single feature extractor and two classifiers - one for label
prediction and one for domain prediction [13]. The goal is to mini-
mize the combined loss, i.e. the domain prediction loss and the class
prediction loss, while learning a domain-invariant feature extractor
for both the source and the target domains. All these approaches
use convolutional neural networks (CNNs) as the underlying mod-
els for G which might not be suitable in case of non-image data. In
addition to this, most of the DA approaches mentioned above are
unsupervised (no labeled data in target domain) and thus, do not
achieve a high enough accuracy on the target data. In this paper,
we assume that we only have a small amount of labeled samples in
the target domain. We instantiate a hybrid version of the DANN
and ADDA architectures to cater to our specific scenario.
2.5 Principal component analysis (PCA)
When trying to predict a certain dependent variable using ML, there
might be a plethora of independent variables (features) to consider.
For example, when trying to predict the likelihood of a certain dis-
ease in a person, one might collect features like age, height, weight,
gender, ethnicity, allergy information, medical history, hereditary
predisposition to the disease, genetic information, etc. Training on
a large number of inter-related features is likely to increase the
complexity of the ML model and cause over-fitting, resulting in
degradation of performance on unseen data. Various dimensionality
reduction techniques have been proposed to reduce the number of
features considered for training an ML model. These techniques
mainly belong to one of two categories: feature selection and feature
extraction. Feature selection refers to reducing the feature space
by removing the features that do not have a significant correlation
with the dependent variable and keep only the top k features on
the basis of correlation to the output. This can be done manually or
programmatically. However, feature selection results in loss of any
information contained in the removed features. Feature extraction
on the other hand allows one to convert a high-dimensional feature
space into a low-dimensional representation without a significant
loss of information.
PCA [39] is a feature extraction technique that performs a linear
mapping from a high-dimensional feature space to a low-dimensional
one. PCA takes a dataset consisting of n features and converts them
into new linearly uncorrelated features, also known as principal
components. One then selects the top k principal components (where
k≤n) in descending order of variance to account for most of the
variability in the input dataset in order to remove the least impor-
tant principal components. These k selected principal components
serve as the new features for the dataset. For brevity, we omit the
mathematical explanation of PCA from this paper and refer the
readers to the paper by Wold et al. [52].
Fig. 4 shows an example of the PCA transformation. Suppose we
have two features f1 and f2 in a dataset. Both f1 and f2 represent
almost equal variance in the dataset as seen from the individual plots
of f1 and f2. PCA converts these into two principal components pc1
and pc2, where pc1 represents most of the variance in the dataset
and pc2 represents very little variance. Thus, pc2 can be dropped
allowing us to transform the dataset containing two features f1 and
f2 into another dataset with just one feature pc1 and still account
for most of the variance in the dataset. Similarly, we can use PCA
to transform datasets with a much larger number of features and
reduce the number of dimensions of the dataset while preserving
the information represented by the dataset.
3 RELATED WORK
Previous approaches have been proposed that use NN models for
both misuse-based NID [6, 18, 36] and for anomaly-based NID [24,
47]. However, these approaches assume the availability of enough
labeled data for training their respective NN models and do not
explore the problem of lack of training data.
Singla et al. evaluate the quality of DL models for NIDS trained
using very low amounts of training data [43]. They propose to first
train the DNN model on a source domain (similar to the target do-
main) with adequate training data and then use transfer learning to
fine-tuning the model on the target data. Their technique, however,
can only be applied to scenarios where the source and the target
datasets have the same feature space.
Zhao et al. propose the CeHTL [55] and HeTL [54] transfer learn-
ing frameworks for training NID models with no labeled training
data in the target domain, for both homogeneous and heteroge-
neous DA cases but they do not achieve a high accuracy on the
target dataset. Both these approaches are unsupervised DA tech-
niques (applicable only on unlabeled training data is the target
domain) and do not look at supervised DA cases where a little
amount of labeled training data is available.
Session 3: Network Security ASIA CCS '20, October 5–9, 2020, Taipei, Taiwan130Tzeng et al. [49] and Ganin et al. [13] propose the adversarial
DA frameworks ADDA and DANN for unsupervised DA. However,
both these approaches are primarily applicable to unsupervised
DA cases. Moreover, these approaches are only evaluated on image
classification tasks using convolutional neural networks (CNN) and
not on domains with non-image data.
To the best of our knowledge, our approach is the first to use
adversarial DA for training DL models for NID when training data
is limited, both for the homogeneous and heterogeneous DA cases.
4 ADVERSARIAL DA METHODOLOGY
Our methodology consists of two steps. We first clean and transform
the source and target datasets to be prepared for DA. We then use
our adversarial DA framework to map the source and target datasets
into a common latent subspace and consequently generate a NID
classification model that can accurately categorize the benign and
attack samples in the target dataset. In what follows we describe
those steps in detail.
4.1 Data pre-processing
We first pre-processes both the source and target datasets to deal
with missing entries from the datasets. We then transform the
features depending on whether they are categorical or continuous
and finally apply PCA for dimensionality reduction.
• Handling missing values: A real-world dataset might have a
lot of values missing for several features, which can cause
problems while training ML models, as a lot of ML libraries
do not have provisions for handling missing data. There are
three common techniques to deal with missing values. The
first is remove all data records that have missing values. The
second is to initialize the missing values by 0, but 0 might
have some other meaning in the case of numerical or binary
variables. For example, a binary variable like is_logged_in
is represented by values 0 and 1 and setting the missing val-
ues as 0 might be misleading. The third is to set the missing
values to the mean of all the values of that variable in the
dataset; however, the application of this technique may also
lead to misleading data. In our approach, we simply drop the
dataset records that contain any missing values.
• Transforming categorical features: Categorical features are
the features that have discrete values instead of continuous
values. For example, protocol_type is a categorical fea-
ture since it can have only three possible values in our NID
dataset i.e. TCP, UDP and ICMP. We need to convert these
string values to integers as ML models cannot train on non-
numeric data. However, simply converting these features to
integer values can cause unexpected behavior from the ML
models, since there is no ordinal relationship between them.
To transform categorical features, we use one-hot encod-
ing which converts categorical features to multiple binary
features with values 0 or 1. Using one-hot encoding on our
example, the feature protocol_type is replaced by three
features: [protocol_type_TCP, protocol_type_UDP and
protocol_type_ICMP]. The values of TCP, UDP and ICMP
will be represented as [1, 0, 0], [0, 1, 0] and [0, 0, 1] respec-
tively, in terms of the new features.
• Processing continuous features: Continuous features can as-
sume an infinite number of values, for example: duration
and packet_count. These features might have different scales
for values like hours, metres, pounds etc. and can range over
thousands of units. This can cause poor performance for
the ML models and cause the weight values of the model
variables to change drastically during training making the
model unstable. Thus, we need to standardize the continuous
variables to convert them to a common scale and map the
input values in a certain small range. Standardization trans-
forms the continuous features so that the resulting feature
distribution has a mean of 0 and a standard deviation of 1.
To standardize a feature, we first calculate the mean and
standard deviation of all the numeric entries of the feature
in the dataset. We then subtract the mean of the feature
from each entry and divide this value by its standard devia-
tion. x′ = x − x
where, x is the mean and σ is the standard
deviation of the feature.
• PCA: We apply PCA transformation on the source and tar-
get datasets to reduce their dimensions to some common
value d, where d ≤ dim(source) and d ≤ dim(tarдet). Here,
dim(source) and dim(tarдet) refer to the original dimensions
of the source and target datasets respectively. PCA essentially
converts the problem of heterogeneous DA to homogeneous
DA by allowing our adversarial DA technique to be applied
to the any DA problem regardless of the dimensions. PCA
also converts the possibly correlated features of the datasets
into completely uncorrelated features, which is a require-
ment for some ML algorithms. The common dimension d is
chosen carefully so that the transformed dataset still explains
most of the variance in the original dataset.
σ
4.2 Adversarial domain adaptation
In this section, we describe the GAN architecture and loss functions
we use for adversarial DA.
GAN architecture: Our DA GAN architecture consists of a gen-
erator and discriminator that are DNNs with the same layer con-
figuration (see Fig 5). They both consist of 9 layers with 3 sets of
fully connected layers, a batch normalization layer, and a reLU
activation layer stacked on top of each other. The fully connected
layers have 64, 32, 16 neurons in that order. The last layer of the
generator serves as input to the discriminator as well as feeds into
a soft-max layer to predict the class of the data sample. Similarly,
the final layer of the discriminator feeds into a soft-max layer to
predict the domain the sample belongs to.
GAN training: Our GAN implementation’s main objective is to
learn a NID classifier that can accurately predict whether the data
samples in the target domain belong to the attack or benign class.
It does this by trying to learn a mapping between source and target
domains, so that they can be transformed into a common latent
subspace. This allows us to overcome the lack of labeled data in the
target domain by using the mapped data from the source domain
for training. The goal of the generator in our GAN architecture
is to take samples from the source and target data distributions
and convert them into a domain-invariant representation to fool
Session 3: Network Security ASIA CCS '20, October 5–9, 2020, Taipei, Taiwan131Figure 5: Our GAN architecture for adversarial DA. We train the GAN to minimize the class prediction and domain prediction
loss. The adversarial DA process outputs the generator as a classifier for the target dataset.
Algorithm 1: Algorithm for adversarial domain adaptation using our GAN architecture.
input : Adam optimizer has learning rate l and decay rates β1 and β2
output: The generator G as a classifier
for n training iterations do
Select d samples from the source dataset;
Select d samples from the target dataset;
Decrease the discriminator gradient using Adam optimiser using loss:
Decrease the generator gradient using Adam optimiser using loss:
(i)
s ))] + [log(1 − D(G(x
(i)
t ))]
2d
d
i=1 y(i)[log(G(x(i))] + (1 − y(i))[log(1 − G(x(i))]
i=1[log(D(G(x
(i)
t ))]
d
1
− 1
d
i=1[log D(G(x
2[Lclass + Ldomain]
where, Lclass = − 1
and, Ldomain = − 1
2d
d
end
the discriminator into misclassifying the generated representations.
The discriminator’s goal is to identify whether the representation
provided by the generator belongs to the source or the target data
distribution. The generator also has the additional objective of
being able to distinguish between the attack and benign classes
on the source and target data distributions. The generator and
the discriminator are trained simultaneously to get better at their
respective tasks.
The formal algorithm for our adversarial DA technique is pro-
vided in Algorithm 1. The algorithm iterates over the source and
target dataset. In each iteration, the algorithm selects a batch of
data samples from the source and the target data distributions equal
to a predefined batch size d. The generator updates its weights to
maximize the domain loss (i.e. error produced by the domain pre-
dictor) and minimize the classification loss (i.e. error produced by
the class predictor) on this batch. The discriminator weights remain
frozen during this step. Simultaneously, the discriminator updates
its weights to minimize the domain loss on the current batch. The
generator weights remain frozen during this step. After n iterations,
the algorithm outputs the generator as a NID classification model.
Loss functions: We define the various loss functions for training
our GAN architecture in this section. We first define two loss func-
tions, domain loss Ldomain and classification loss Lclass in equations
1 and 2 below. The domain loss function measures the difference
between real values and the predicted values of the domain gen-
erated by our discriminator. Here, domain prediction refers to the
probability of the data sample belonging to the source or the target
data distribution. Similarly, the classification loss function measures
the difference between the real and the predicted values of the class
predictions by our generator. Here, class prediction refers to the
probability values of the data sample belonging to the attack or
benign category.
The domain loss is calculated as:
Ldomain (G, D) = −Exs[log D(G(xs))] − Ext[log(1 − D(G(xt))]
(1)
where Exs and Ext are the expected values of the source domain
samples and the target domain samples respectively, D(G(xs)) is
Domain	PredictionDiscriminatorFully	Connected	Layer	(64	neurons)	Batch	Normalization	LayerActivation	Layer	(ReLU)Fully	Connected	Layer	(32	neurons)	Batch	Normalization	LayerActivation	Layer	(ReLU)Fully	Connected	Layer	(16	neurons)	Batch	Normalization	LayerActivation	Layer	(ReLU)GeneratorFully	Connected	Layer	(64	neurons)	Batch	Normalization	LayerActivation	Layer	(ReLU)Fully	Connected	Layer	(32	neurons)	Batch	Normalization	LayerActivation	Layer	(ReLU)Fully	Connected	Layer	(16	neurons)	Batch	Normalization	LayerActivation	Layer	(ReLU)Class	PredictionSourceDataTargetDataSession 3: Network Security ASIA CCS '20, October 5–9, 2020, Taipei, Taiwan132the probability of the discriminator predicting a source domain
sample as belonging to source, and D(G(xt)) is the probability of
the discriminator predicting a target domain sample as belonging
to source.
The classification loss is calculated as:
Lclass (G) = − Exattack[log(G(x))] − Exbenign[log(1 − G(x))]
(2)
where Exattack and Exbenign are the expected values of attack and
benign samples respectively over the combined source and target
true data distributions, G(x) is the probability of the generator
classifying a sample as attack, and 1 − G(x) is the probability of the
generator classifying a sample as benign.
The domain loss described in equation 1 can be split into two
minimization objectives for the generator and discriminator if we in-
vert the domain labels while training the generator (see equations 3
and 4) [16]. Our algorithms train the generator and discrimina-
tor simultaneously according to the following three minimization
objectives:
min
D
Ldomain (G) = −Exs[log D(G(xs))] − Ext[log(1 − D(G(xt))]
(3)
(4)
Ldomain (D) = −Ext[log(D(G(xt))]
min
G
min
G
Lclass
(5)
5 EXPERIMENT DETAILS
We now provide the details of the datasets used for our experiments,
details of the experiments, the metrics collected, and the system
setup.
5.1 Selecting the source and target datasets
There are several public datasets available for NIDS evaluation.
KDD-CUP99 [27] has been the most popular NIDS bench-marking
dataset for many years and was created by MIT Lincoln Labs using
a U.S. Air Force LAN simulation. However, it suffers from various
discrepancies such as redundant records and different probability
distributions for the training and testing datasets [30, 32]. NSL-
KDD [1] was created by addressing the discrepancies of the KDD-
CUP99 dataset.
The 10% NSL-KDD dataset contains 125,973 records in the train-
ing dataset and 22,544 records in the testing dataset. It contains 41
features categorized as: ❶ basic features of individual connections
(e.g. duration, protocol type, service), ❷ content features suggested
by domain knowledge (e.g. number of failed login attempts, number
of shell prompts) and ❸ traffic features computed using a 2 seconds
window (e.g. number of connections to the same host, percent of
connections that have SYN errors). The NSL-KDD dataset catego-
rizes records into five major attack categories: normal, denial of
service (e.g. syn flood attack, neptune, teardrop), probing (e.g. port
scanning, satan), remote-to-local (e.g. guessing password, warez-
client, warezmaster), and user-to-root (e.g. buffer overflow, rootkit)
(see Table 1).
The UNSW-NB15 dataset [34] is a NIDS evaluation dataset con-
taining more recent attack types and distributions than the NSL-
KDD dataset. This dataset was created using the IXIA PerfectStorm
security testing platform [22] that can generate simulated traffic
Percentage Number of records
Table 1: Distribution of attack categories (NSL-KDD training
dataset).
Percentage Number of records
Category
Normal
DoS
Probing
Remote-to-local
User-to-root
Category