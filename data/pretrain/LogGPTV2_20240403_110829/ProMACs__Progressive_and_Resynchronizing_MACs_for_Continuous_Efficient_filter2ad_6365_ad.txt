𝑡𝑖+1. To this end, the two PRFs: 𝐹
𝑘′′ . are used, respectively.
Below we assume that the sampled key 𝑘 has the form 𝑘 = (𝑘′, 𝑘′′)
3The inspiration for the name is that the sliding ”Area of Dependency” resembles the
moving ”wave” when cracking a whip.
4In the following, we consider the case where 𝑢 is finite. At the end, we shortly discuss
the case of 𝑢 = ∞.
and 𝐹
upd
𝑘′
and that these two parts have been used to initialize the two PRFs.
upd
takes as input the counter, the initial substate, and the packet
𝐹
𝑘′
and outputs the next substate:
upd
𝑘′
𝐹
: {0, 1}𝛾 × {0, 1}𝜎 × {0, 1}𝜇 → {0, 1}𝜎
(8)
(9)
This defines the next state 𝑠𝑖+1 = (𝑖 + 1, ˜𝑠0, ˜𝑠[𝑖+1,𝑢]) which is used
to compute the corresponding tag with the help of 𝐹
(𝑖, ˜𝑠0, 𝑚𝑖+1)
sig
𝑘′′ :
: {0, 1}𝛾 × {0, 1}𝜎 × {0, 1}𝑢·𝜎 → {0, 1}𝜏
↦→ ˜𝑠𝑖+1
(10)
(11)
The core idea of the proposed instantiation is shown in Fig.3. We
now discuss the algorithms that are part of the model, per Definition
4.1:
(𝑖 + 1, ˜𝑠0, ˜𝑠[𝑖,𝑢])
↦→ 𝑡𝑖
sig
𝑘′′
𝐹
Key Generation Gen. The probabilistic key-generation algorithm
Gen samples a secret key 𝑘 ∈ K. Below we assume that sender and
receiver share a common secret key 𝑘 ∈ {0, 1}𝜅 and write 𝐹𝑘(. . .)
instead of 𝐹(𝑘, . . .).
Initialization Init. The probabilistic initialization algorithm Init
samples an initial substate ˜𝑠0 ∈ {0, 1}𝜎 and sets5
𝑠0 = (0, ˜𝑠0, ˜𝑠[0,𝑢]).
Also, it samples a key 𝑘 = (𝑘′, 𝑘′′) ∈ K to initialize the PRFs 𝐹
and 𝐹
sig
𝑘′′ .
Update Upd and Tag Generation Sig. Both procedures: state up-
date and next tag computation, are accomplished by a call to one
PRF. 6 More precisely, let 𝑠𝑖−1 denote the current internal state
(with 𝑠0 being the initial state) and let 𝑚𝑖 be the current packet.
Then, Whips updates the internal state by computing:
˜𝑠𝑖 := 𝐹
upd
𝑘′
(𝑖 − 1, ˜𝑠0, 𝑚𝑖)
(13)
5The first 𝑢 − 1 states contain multiple copies of ˜𝑠0 to be compatible with the overall
formal of all states.
sig
6In fact, one could replace the second PRF 𝐹
𝑘′′ by a classical MAC. We chose to rely
on one type of cryptographic primitive, since it may be more efficient in practice to
implement it only once and use it with different keys, e.g., hash functions.
(12)
upd
𝑘′
where 𝑢 = ad(Upd) is the Area of Dependency. This defines 𝑠𝑖 =
(𝑖, ˜𝑠0, ˜𝑠[𝑖,𝑢]). Given this, Whips computes the tag 𝑡𝑖 for 𝑚𝑖 by
sig
𝑘′′ (𝑠𝑖).
𝑡𝑖 := 𝐹
(14)
Verification. The verification algorithm Vrfy𝑘 computes on input
𝑠𝑖, 𝑚𝑖, ˜𝑡𝑖 first the tag 𝑡𝑖 and then compares it to the given ˜𝑡𝑖. If both
are equal, the output is true; otherwise it is false.
The Case of Infinite 𝑢. If 𝑢 = ∞, i.e., the equivalent of duplex-
based chaining, it is no longer necessary to store the last 𝑢 substates
to ”cancel” these out later. Instead, more compact solutions are
possible, e.g., setting 𝑠𝑖 = (𝑖, ˜𝑠0, ˜𝑠𝑖) and choosing an appropriate PRF
𝐹. Here, we can take advantage of the fact that ˜𝑠𝑖 anyhow depends
on all previous states. For security reasons, it is necessary to choose
a higher value for 𝜎.
5.2 Design Rationale
Before proving security of our construction, we briefly discuss why
𝑠𝑖 contains the counter, the initial state, and the recent substates.
Let us assume that the state did not contain a counter. Recall that
one goal of our construction is to realize an Area of Dependency to
support resynchronization. This means that, in a scenario where
the packet stream consists of the repetition of the same packet, i.e.,
𝑚0 = 𝑚1 = . . ., the tags would all be the same, which would allow
for a simple forgery attack. The counter ensures freshness of the
state, even if the packets repeat.
Next, we assume that the state would not contain the initial state
value 𝑠0. Then, an attacker who can figure out the internal state
𝑠𝑖 for 𝑖 > 0 could produce a forgery by using 𝑠𝑖 as “initial state”.
Hence, the initial state, which is beyond attacker’s control, acts as
anchor for the trust chain. In addition, it prevents replay attacks in
the sense that tags observed for one initial state are re-used for a
different initial state.
Finally, to facilitate removal of “outdated” substates from the cur-
rent state calculation (to ensure an Area of Dependency of length 𝑢),
the current state is mainly composed from most recent 𝑢 substates.
5.3 Proof of Security
Below, we prove security of our construction. Recall that the mo-
tivation of ProMACs is an attacker who aims to forge a certain
tag also has to forge upcoming tags. Consequently, the number of
tags to be forged needs to be a part of the security claim. In the
context of the security definition, this is equivalent to the number
of fresh forgery sequences Δ (see the definition in Section 4.3.3).
The security claim is as follows:
Theorem 5.1. Consider an instantiation of Whips with two (𝑞,𝑇 , 𝜀/2)-
pseudorandom functions 𝐹 upd and 𝐹 sig, with substate length of 𝜎, tag
length of 𝜏 ≥ 2, and counter length of at least 𝛾 ≥ log2(𝑞). Then,
for any attacker A who runs in time at most 𝑇 , makes at most 𝑞
Sig-queries and produces Δ fresh forgery sequences, the probability
of success is upper-bounded by:
𝑃𝑟 [A wins] ≤ 𝜀 + 𝑞2 + 2𝑞
2𝜎
+
.
(15)
(cid:19) Δ
(cid:18) 1
2𝜏
In the parameter choices, we suggest keeping 𝜏 small (since it
impacts bandwidth overhead), while 𝜎 can be large (since states
is only stored internally). Thus, 1
term of the sum.
2𝜏 can be seen as the dominating
We note that (15) also describes the increasing security level
of the proposed scheme. Since the attacker’s advantage decreases
with every subsequent successful verification, i.e. with increasing
Δ, guaranteed security level for the respective packet is increasing
with each of these packets. For each verified packet, the security
level increases by transmitted tag bits with an upper bound of the
key length. Fig. 1 (bottom) depicts such an increasing security level,
while Fig. 4 demonstrates resynchronization properties of Whips
and the increasing security level.
Figure 4: Achieved security level for the respective incom-
ing packet, assuming a 64-bit tag size and 256-bit key size,
ad(Upd) = 4 and an error at packet #8.
Finally, we note that the proof is independent of 𝑢, i.e., the given
bound holds for both finite and infinite 𝑢.
Proof of Theorem 5.1. We show the security claim (15) by us-
ing a sequence of games 𝐺0-𝐺3. Since 𝛾 ≥ log2(𝑞), we exclude the
case of counter overflow, i.e., that the counter repeats after up to 𝑞
queries.
Game 𝐺0. Let 𝐺0 denote the original security game as described
in Section 4.3. We are interested in showing an upper bound for
𝑃𝑟 [A wins in 𝐺0].
Game 𝐺1. 𝐺1 is defined as 𝐺0 with the only difference that, when-
upd
ever the attacker makes a Sig-query, it learns the full output of 𝐹
.
𝑘′
Since the attacker now has more information, the probability of
success is at least as high as before:
𝑃𝑟 [A wins in 𝐺0] ≤ 𝑃𝑟 [A wins in 𝐺1] .
(16)
Game 𝐺2. 𝐺2 is based on 𝐺1 with the difference that the PRFs
are replaced by a randomly chosen functions. Because each PRF
is (𝑞, 𝑡, 𝜀/2)-pseudorandom and that A runs in time at most 𝑡 and
makes at most 𝑞 queries, it holds that:
𝑃𝑟 [A wins in 𝐺1] ≤ 𝑃𝑟 [A wins in 𝐺2] + 𝜀.
(17)
Game 𝐺3. 𝐺3 is defined as 𝐺2 with the difference that the game
is aborted if during the Sig-queries, a collision in the states occurs.
An obvious upper bound is given by considering a collision on the
next substate only. Since 𝐹𝑘 is replaced by a random function, it
follows that:
𝑃𝑟 [A wins in 𝐺2] ≤ 𝑃𝑟 [A wins in 𝐺3] + 𝑞2/2𝜎 .
(18)
It remains to upper bound 𝑃𝑟 [A wins in 𝐺3].
We assume that Δ = 1. Then, an attacker wins if: (i) either it can
produce a state collision or, (ii) a tag collision. That is, we have:
2𝜎 +(cid:16)1 − 𝑞
𝑞
2𝜎
(cid:17) · 1
2𝜏 .
(19)
𝑃𝑟 [A wins in 𝐺3|Δ = 1] =
:= 𝑞+𝑖
Below we use 𝑐𝑖
rephrase the equation as:
2𝜎 where 𝑐 stands for ”collision”. We can
𝑃𝑟 [A wins in 𝐺3|Δ = 1] = 𝑐0 + 1 − 𝑐0
2𝜏
(20)
Next, we consider the case of Δ = 2. For the first fresh sequence,
there are two possibilities: (i) a state collision, or (ii) a tag collision.
In the former, it follows that the second fresh sequence comes ”for
free”. In the latter, we again have the same possibilities for the
second fresh sequence. This yields:
.
𝑃𝑟 [A wins in 𝐺3|Δ = 2] = 𝑐0 + 1 − 𝑐0
2𝜏
(21)
By induction and using the fact that 1 − 𝑐𝑖 ≤ 1 for all 𝑖 ≥ 0, we
can show that probability of winning 𝐺3 with Δ fresh sequences is
upper bounded by:
·
.
(cid:20)
𝑐1 + 1 − 𝑐1
2𝜏
(cid:21)
Δ−1
𝑖=0
(cid:19) Δ
(cid:18) 1
2𝜏
. (22)
𝑐0 + 𝑐1
2𝜏 + 𝑐2
22𝜏 + . . . + 𝑐Δ−1
2(Δ−1)·𝜏 + 1
2Δ·𝜏 =
𝑐𝑖
2(𝑖)·𝜏 +
(cid:18)
Note that, for the sum, it holds that for increasing Δ, the number of
terms in the sum increases, while their values decrease. Thus, we
aim to find an upper bound for the sum. Let 𝑖 ≥ 0 be arbitrary. For
the ratio of two successive, it holds that:
𝑞 + 𝑖 + 1
· 1
𝑞 + 𝑖
2𝜏 =
=
2𝜏 ≤ 1
≤ 2 · 1
2 .
/(cid:16) 𝑐𝑖
1 + 1
𝑞 + 𝑖
2(𝑖+1)·(𝜏+1)
· 1
2𝜏
𝑐𝑖+1
2𝑖·𝜏
(cid:19)
(cid:18)
(cid:19)
(cid:17)
In other words, each term in the sum is at most half the size of
the previous term. This allows us to to derive the following upper
bound:
𝑖=0
𝑐𝑖
2𝑖·𝜏
≤ 𝑐0 + 𝑐0
2Δ−1 < 2 · 𝑐0 =
2𝑞
2𝜎 . (23)
Thus, it follows from equations (22) and (23), that attacker’s proba-
bility of success in game 𝐺3 with Δ fresh sequences can be upper-
bounded by:
2 + 𝑐0
22 + . . . + 𝑐0
(cid:18) 1
(cid:19) Δ
(24)
2𝑞
2𝜎 +