TOR denotes the time taken for constraint generation, while TAINT
denotes the time taken for taint analysis. The constraints produced
can be resolved in one of two ways; the rows LPSOLVE and HIER-
SOLVE report the time taken by the IIS detection based approach
CODESURFER
GENERATOR
TAINT
LPSOLVE
HIERSOLVE
TOTAL (LP./HIER.)
wu-ftpd-2.6.2
12.54 sec
74.88 sec
9.32 sec
3.81 sec
10.08 sec
100.55/106.82 sec
sendmail-8.7.6
30.09 sec
266.39 sec
28.66 sec
13.10 sec
25.82 sec
338.24/350.96 sec
PRE-TAINT
POST-TAINT
Number of Constraints Generated
22008
14972
104162
24343
Table 1: Performance of the tool
and the hierarchical solves approach respectively (Section 4). The
number of constraints output by the constraint generator is reported
in the row PRE-TAINT, while POST-TAINT denotes the number of
constraints after taint-analysis.
As noted earlier, the IIS detection based approach is more efﬁ-
cient, but is not mathematically precise, whereas the hierarchical
solver is mathematically precise. We however found that the solu-
tion produced by the IIS detection based approach is a good approx-
imation to the solution obtained by the hierarchical solver. In case
of wu-ftpd-2.6.2 fewer than 5% of the constraint variables, and
in the case of sendmail-8.7.6 fewer than 2.25% of the constraint
variables obtained imprecise values when we used the IIS detection
based approach. We also found that this imprecision did not signiﬁ-
cantly affect the number of warnings – in case of wu-ftpd-2.6.2
and sendmail-8.7.6 the IIS based approach resulted in 1 and
2 more warnings respectively (these warnings were false alarms),
which shows that in practice we can use the faster IIS detection
based approach with little loss of precision.
6.4 Adding Context Sensitivity
We report here our experience with using context-sensitive anal-
ysis on wuftpd-2.6.2 using both the constraint inlining approach
and the summary constraints approach. Note that adding context
sensitivity will not ﬁnd new overruns. Adding context sensitivity
changes the constraints generated so that they precisely reﬂect the
call-return semantics of functions. As a result, we can expect more
precise values from the constraint solvers. To measure the effec-
tiveness of each approach, we will count the number of range vari-
ables that were reﬁned in comparison to the corresponding ranges
obtained in a context-insensitive analysis. Recall that the value of
a range variable var is given by the corresponding constraint vari-
ables var!min and var!max as [var!min..var!max]. We chose
this metric since, as explained in Section 3.5, the detector uses the
values of the ranges to produce diagnostic information, and more
precise ranges will more precise diagnostic information.
The context-insensitive analysis on wuftpd-2.6.2 yields val-
ues for 7310 range variables. Using the summary constraints ap-
proach, we found that 72 of these range variables obtained more
precise values. Note that in this approach the number of constraint
variables (and hence the number of range variables) is the same as
in the context-insensitive analysis. However, the number of con-
straints may change, and we observed a 1% increase in the num-
ber of constraints. This change can be attributed to the fact that
summarization introduces a some constraints (the summaries), and
removes some constraints (the old call-site assignment constraints).
The constraint inlining approach, on the other hand, leads to a
5.8× increase in the number of constraints, and a 8.7× increase
in the number of constraint variables (and hence the number of
range variables). This can be attributed to the fact that the inlining
based approach specializes the set of constraints at each callsite.
In particular, we observed that the 7310 range variables from the
context-insensitive analysis were specialized to 63704 range vari-
ables based on calling context. We can count the number of range
variables that obtained more precise values in two possible ways:
• Out of 63704 specialized range variables, 7497 range variables
obtained more precise values than the corresponding unspecialized
range variables.
• Out of 7310 unspecialized range variables, 406 range variables
had obtained more precise values in at least one calling context.
As noted earlier, the constraint inlining approach returns more
precise information than the summary constraints based approach.
To take a concrete example, we consider the program variable ms-
gcode (an integer), which is the formal parameter of a function
pr mesg in the ﬁle access.c in wu-ftpd-2.6.2. The function
pr mesg is called from several places in the code with different val-
ues for the parameter msgcode. The summary constraints approach
results in the value [530..550] for the range variable corresponding
to msgcode. Constraint inlining reﬁnes these ranges – for instance,
it is able to infer that pr mesg is always called with the value 530
from the function pass in the ﬁle ftpd.c.
6.5 Effects of Pointer Analysis
As observed in Section 3, we were able to reduce false negatives
through the use of pointer analysis. The tool is capable of han-
dling arbitrary levels of dereferencing. For instance, if p points to
a pointer to a structure s, the pointer analysis algorithms correctly
infer this fact. Similarly, if p and q are of type char** (i.e., they
point-to pointers to buffers), the constraints for a statement such
as strcpy(*p, *q) would be correctly modeled in terms of the
points-to sets of p and q (recall that we generated constraints in
terms of pointers to buffers rather than buffers themselves).
To observe the beneﬁts of pointer analysis we generated con-
straints with the pointer analysis algorithms turned off. Since fewer
constraints will be generated, we can expect to see fewer warnings;
in the absence of these warnings, false negatives may result. We
observed a concrete case of this in the case of sendmail-8.7.6.
When we generated constraints without including the results of the
pointer analysis algorithms, the tool output 251 warnings (as op-
posed to 295 warnings). However, this method resulted in the warn-
ing on the array dfname being suppressed, so the tool missed the
off-by-one bug that we described earlier. A closer look at the pro-
cedure queuename revealed that in the absence of points-to facts,
the tool failed to generate constraints for a statement:
snprintf(buf, sizeof buf, "%cf%s", type, e− >e id)
in the body of queuename since points to facts for the variable e,
which is a pointer to a structure, were not generated.
We note that BOON [30] identiﬁed this off-by-one bug because
of a simple assumption made to model the effect of pointers, i.e.,
BOON assumes that any pointer to a structure of type T can point
to all structures of type T. While this technique can be effective at
discovering bugs, the lack of precise points-to information will lead
to a larger number of false alarms.
6.6 Shortcomings
While we found the prototype implementation a useful tool to
audit several real world applications, we also noted several short-
comings and are working towards overcoming these limitations.
First, the ﬂow insensitivity of the analysis meant that we would
have several false alarms. Through the use of slicing we were able
to weed out the false alarms, nevertheless it was a manual and often
painstaking procedure. Moreover, the beneﬁts observed by adding
context-sensitivity were somewhat limited because of the ﬂow in-
sensitivity of the analysis. By transitioning to a Static Single As-
signment (SSA) representation [15] of the program, we can add a
limited form of ﬂow sensitivity to the program. However, the SSA
representation will result in a large number of constraint variables.
Fortunately, we have observed that the solvers readily scale to large
linear programs with several thousand variables.
Second, by modeling constraints in terms of pointers to buffers
rather than buffers, we can miss overruns, thus leading to false neg-
atives [30]. However, the reason we did so was because the pointer
analysis algorithms themselves were ﬂow- and context-insensitive,
and generating constraints in terms of buffers would have resulted
in a large number of constraints and consequently a large number
of false alarms. By transitioning to “better” pointer analysis algo-
rithms we can model constraints in terms of buffers themselves,
thus eliminating the false negatives.
7. CONCLUSIONS
We have demonstrated a light-weight technique to analyze C
source code to detect buffer overrun vulnerabilities. We have shown
the efﬁcacy of the technique by applying it to real world examples
and identifying new vulnerabilities in a popular security critical
package. Our techniques use novel ideas from the linear program-
ming literature, and provide a way to enhance context sensitivity.
The output of our tool, coupled with other program understanding
features of CodeSurfer, such as static slicing, aid the user to com-
prehend and eliminate bugs from source code.
Acknowledgments. We would like to thank the members of the
Wisconsin Safety Analyzer research group, Michael Ferris, Aditya
Rao and the anonymous reviewers for their suggestions.
8. REFERENCES
[1] bugtraq. www.securityfocus.com.
[2] CERT/CC advisories. www.cert.org/advisories.
[3] The twenty most critical internet security vulnerabilities.
www.sans.org/top20.
[4] Aleph-one. Smashing the stack for fun and proﬁt. Nov 1996.
Phrack Magazine.
[5] Technical analysis of remote sendmail vulnerability.
www.securityfocus.com/archive/1/313757.
[6] L. O. Andersen. Program Analysis and Specialization for the
C Programming Language. PhD thesis, DIKU, Univ. of
Copenhagen, 1994. (DIKU report 94/19).
[7] E. D. Anderson and K. D. Anderson. Presolving in linear
programming. Mathematical Prog., 71(2):221–245, 1995.
[8] R. Bodik, R. Gupta, and V. Sarkar. ABCD: Eliminating
array-bounds checks on demand. In ACM Conf. on Prog.
Lang. Design and Impl. (PLDI), 2000.
[9] J. W. Chinnek and E. W. Dravinieks. Locating minimal
infeasible constraint sets in linear programs. ORSA Journal
on Computing, 3(2):157–168, 1991.
[10] T-C. Chiueh and F-H. Hsu. RAD: A compile-time solution to
buffer overﬂow attacks. In 21st Intl. Conf. on Distributed
Computing Systems (ICDCS), 2001.
[11] J. Condit, M. Harren, S. McPeak, G. C. Necula, and
W. Weimer. CCured in the Real World. In ACM Conf. on
Prog. Lang. Design and Impl. (PLDI), 2003.
[12] T. H. Cormen, C. E. Lieserson, R. L. Rivest, and C. Stein.
Introduction to Algorithms. MIT Press, 2001.
[13] C. Cowan, S. Beattie, R-F Day., C. Pu, P. Wagle, and
E. Walthinsen. Automatic detection and prevention of buffer
overﬂow attacks. In 7th USENIX Sec. Symp., 1998.
[14] C. Cowan, S. Beattie, J. Johansen, and P. Wagle.
PointGuardT M : Protecting pointers from buffer overﬂow
vulnerabilities. In 12th USENIX Sec. Symp., 2003.
[15] R. Cytron, J. Ferrante, B. K. Rosen, M. N. Wegman, and
F. K. Zadeck. Efﬁciently computing static single assignment
form and the control dependence graph. ACM Trans. on
Prog. Lang. and Systems (TOPLAS), 13(4):452–490, 1991.
[16] G. B. Dantzig and B. Curtis Eaves. Fourier-Motzkin
elimination and its dual. Journal of Combinatorial Theory
(A), 14:288–297, 1973.
[17] N. Dor, M. Rodeh, and M. Sagiv. CSSV: Towards a realistic
tool for statically detecting all buffer overﬂows in C. In ACM
Conf. on Prog. Lang. Design and Impl. (PLDI), 2003.
[18] H. Etoh and K. Yoda. Protecting from stack-smashing
attacks. 2000. www.trl.ibm.com/projects/security/ssp/main.html.
[19] V. Ganapathy, S. Jha, D. Chandler, D. Melski, and D. Vitek.
Buffer overrun detection using linear programming and static
analysis. 2003. UW-Madison Comp. Sci. Tech. Report 1488.
ftp://ftp.cs.wisc.edu/pub/tech-reports/reports/2003/tr1488.ps.Z
[20] S. Horwitz, T. Reps, and D. Binkley. Interprocedural slicing
using dependence graphs. ACM Transactions on Prog.
Lang.s and Systems (TOPLAS), 12(1):26–60, 1990.
[21] S. Horwitz, T. Reps, M. Sagiv, and G. Rosay. Speeding up
slicing. In 2nd ACM Symp. on Foundations of Soft. Engg.
(FSE), pages 11–20, New York, 1994.
[22] D. Larochelle and D. Evans. Statically detecting likely buffer
overﬂow vulnerabilities. In 10th USENIX Sec. Symp., 2001.
[23] E. Larson and T. Austin. High coverage detection of input
related security faults. In 12th USENIX Sec. Symp., 2003.
[24] G. C. Necula, S. McPeak, and W. Weimer. CCured: type-safe
retroﬁtting of legacy code. In ACM Conf. on the Principles of
Prog. Lang. (POPL), 2002.
[25] CPLEX Optimizer. www.cplex.com/.
[26] R. Rugina and M. C. Rinard. Symbolic bounds analysis of
pointers, array indices and accessed memory regions. In
ACM Conf. on Prog. Lang. Design and Impl. (PLDI), 2000.
[27] A. Schrijver. Theory of Linear and Integer Programming.
Wiley, N.Y., 1986.
[28] M. Sharir and A. Pnueli. Two Approaches to Interprocedural
Dataﬂow Analysis. Prentice Hall Inc., 1981.
[29] D. Wagner. Static Analysis and Computer Security: New
techniques for software assurance. PhD thesis, UC Berkeley,
Dec 2000.
[30] D. Wagner, J. S. Foster, E. A. Brewer, and A. Aiken. A ﬁrst
step towards automated detection of buffer overrun
vulnerabilities. In Network and Distributed System Security
(NDSS), 2000.
[31] S. J. Wright. Primal-Dual Interior-Point Methods. SIAM
Philadelphia, 1997.
[32] R. Wunderling. Paralleler und Objektorientierter
Simplex-Algorithmus. PhD thesis, Konrad-Zuse-Zentrum fur
Informationstechnik Berlin, TR 1996-09.
www.zib.de/PaperWeb/abstracts/TR-96-09/.
[33] Y. Xie, A. Chou, and D. Engler. ARCHER: Using symbolic,
path-sensitive analysis to detect memory access errors. In 9th
European Soft. Engg. Conf. and 11th ACM Symp. on
Foundation of Soft. Engg. (ESEC/FSE), 2003.
[34] S. Yong, S. Horwitz, and T. Reps. Pointer analysis for
programs with structures and casting. In ACM Conf. on Prog.
Lang. Design and Impl. (PLDI), 1999.