title:2MA: Verifying Voice Commands via Two Microphone Authentication
author:Logan Blue and
Hadi Abdullah and
Luis Vargas and
Patrick Traynor
2MA: Verifying Voice Commands via
Two Microphone Authentication
Logan Blue
University of Florida
Gainesville, Florida
PI:EMAIL
Luis Vargas
University of Florida
Gainesville, Florida
PI:EMAIL
Hadi Abdullah
University of Florida
Gainesville, Florida
PI:EMAIL
Patrick Traynor
University of Florida
Gainesville, Florida
PI:EMAIL
ABSTRACT
Voice controlled interfaces have vastly improved the usability of
many devices (e.g., headless IoT systems). Unfortunately, the lack
of authentication for these interfaces has also introduced command
injection vulnerabilities - whether via compromised IoT devices,
television ads or simply malicious nearby neighbors, causing such
devices to perform unauthenticated sensitive commands is rela-
tively easy. We address these weaknesses with Two Microphone
Authentication (2MA), which takes advantage of the presence of
multiple ambient and personal devices operating in the same area.
We develop an embodiment of 2MA that combines approximate
localization through Direction of Arrival (DOA) techniques with
Robust Audio Hashes (RSHs). Our results show that our 2MA sys-
tem can localize a source to within a narrow physical cone (< 30◦)
with zero false positives, eliminate replay attacks and prevent the
injection of inaudible/hidden commands. As such, we dramatically
increase the difficulty for an adversary to carry out such attacks
and demonstrate that 2MA is an effective means of authenticating
and localizing voice commands.
CCS CONCEPTS
• Security and privacy → Multi-factor authentication; Access
control;
KEYWORDS
Internet of Things, authentication
ACM Reference Format:
Logan Blue, Hadi Abdullah, Luis Vargas, and Patrick Traynor. 2018. 2MA:
Verifying Voice Commands via Two Microphone Authentication. In ASIA
CCS ’18: 2018 ACM Asia Conference on Computer and Communications Secu-
rity, June 4–8, 2018, Incheon, Republic of Korea. ACM, New York, NY, USA,
12 pages. https://doi.org/10.1145/3196494.3196545
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
ASIA CCS ’18, June 4–8, 2018, Incheon, Republic of Korea
© 2018 Association for Computing Machinery.
ACM ISBN 978-1-4503-5576-6/18/06...$15.00
https://doi.org/10.1145/3196494.3196545
1 INTRODUCTION
One of the many promises of the Internet of Things (IoT) is conve-
nience. From devices that automatically close curtains at sundown
to connected door locks, IoT sensors, actuators and systems are
expected to be deployed in virtually every environment in the com-
ing decade. Because such devices often have extremely limited or
simply lack traditional user interfaces, an increasing number are
opting to integrate voice commands as their primary user interface.
Voice interfaces are also widely lauded as a means of making com-
puting inclusive by allowing young, those with disabilities, and the
elderly alike to successfully interact with enabled systems [35].
Unfortunately, voice interfaces suffer from a number of security
problems. First, most systems rely on ensuring that adversaries can
not be within physical proximity of devices implementing such
interfaces. Such devices need not be compromised by an attacker;
recent news provides examples of nearby televisions and radios
used to activate home assistant devices [3, 9]. This assumption
renders systems vulnerable to any malicious neighbor (e.g., closely
situated people in adjacent apartments, compromised IoT stereo,
television playing commercials) and is unrealistic given the number
of vulnerable IoT devices expected to be deployed in homes and
business in the coming years. Second, multiple researchers have
recently demonstrated that adversaries can inject commands with-
out nearby users hearing them [20, 44, 45], thereby circumventing
their ability to cancel such requests. Finally, even those systems
that attempt to use biometrics do little to prevent replay attacks.
Given the ease with which previously played audio can be sub-
tly modified [36, 41], adversaries can easily generate previously
unplayed commands in the absence of the user. Given that voice
commands can cause the execution of sensitive operations (e.g.,
the purchase of goods; the actuation of physical systems including
heating/air conditioning, door locks and window shades; perform
online banking), these systems require stronger protections.
In this paper, we present Two Microphone Authentication (2MA).
2MA systems take advantage of the fact that multiple (at least two)
microphones are likely to be present in settings where users deploy
systems with voice interfaces. We aim to retain the utility of such
systems while explicitly eliminating attacks from nearby sources,
replayed legitimate requests, and hidden commands. We make the
following specific contributions to achieve these goals:
Session 3: AuthenticationASIACCS’18, June 4–8, 2018, Incheon, Republic of Korea89ASIA CCS ’18, June 4–8, 2018, Incheon, Republic of Korea
Logan Blue, Hadi Abdullah, Luis Vargas, and Patrick Traynor
• Develop Two Microphone Authentication: Applications
ranging from reducing ambient noise to identifying the tra-
jectory of bullets use unified arrays of microphones. To our
knowledge, ours is the first work to propose the use of mul-
tiple microphones located on potentially mutually disinter-
ested devices throughout an area (e.g., an apartment) to pro-
vide a stronger means of authenticating voice commands.
• Design and Implement First Instance of 2MA: 2MA sys-
tems can take many forms. We design a two-channel protocol
(audio and network) and then implement a system using mi-
crophones located on an Amazon Echo/Google Home-like
device and a mobile phone held by an authorized user. We
demonstrate the ability to eliminate voice commands made
when the user is not present and those injected from places
outside of a narrow audio cone (< 30◦) with zero false posi-
tives.
• Defend Against Inaudible Attacks: We customize mech-
anisms including the Robust Sound Hash (RSH) and perform
extensive tests to ensure that the recent collection of inaudi-
ble attacks [20, 44, 45]1 fail to inject sensitive commands
without detection.
We spend significant time talking about our specific embodiment
of a 2MA system; however, readers should see the idea of 2MA as a
generic framework and by itself a contribution. It is our hope that
readers build applications appropriate for other specific contexts
(as we have done) in the future.
The remainder of the paper is organized as follows: Section 2
discusses related work; Section 3 provides background information
on our underlying mechanisms; Section 4 specifies our security
model and adversarial capabilities; Section 5 defines our 2MA pro-
tocol; Section 6 details the architecture of our system; Section 7
shows our experimental performance of our 2MA system, including
against adversarial audio; Section 8 offers discussion on a number
of important considerations; and Section 9 provides concluding
remarks.
2 RELATED WORK
In recent years, speech has become a common command interface
for many devices [6, 7, 10–12]. While convenient, this interface
does not provide any means of authenticating an arbitrary speaker.
This allows anyone within the device’s audible proximity to issue
commands. In April of 2017, this lack of authentication allowed
Burger King to release a television advertisement that triggered
nearby Google assistant enabled devices to read a promotional
message posted online [9]. Similarly, a TV host in the UK caused
Amazon Echo devices to purchase a children’s dollhouse simply by
reading text on the news [3]. The effects of these specific instances
were eventually reversed, but only after millions of devices initi-
ated sensitive operations. Using a similar attack, a malicious entity
can unlock doors [8], make purchases [6, 13], or transfer money
thousands of times before being stopped [15, 25]. This problem is
compounded by the increasing number of IoT devices. A comprised
device with a built-in speaker can be used by an adversary to play
1We thank the authors of these three papers for generously providing us with malicious
samples against which we test our system. Their willingness to share these files not
only makes our results valid, but also allowed us to independently validate their results
(thereby furthering their science).
malicious audio commands. This is a realistic scenario given the
recent discovery of the Mirai Botnet [32], which comprised mil-
lions of IoT devices. Audio commands can also be concealed so that
they are imperceptible even if the victim is in the vicinity. These
morphing techniques exploit weaknesses in speech recognition
models employed by voice operated devices. The audio commands
can be modified to sound like nonsensical audio [20, 44] or can be
made completely inaudible [45] to the unsuspecting victim, while
simultaneously being registered as legitimate commands by the
voice operated device.
Many researchers have looked to incorporate speaker recogni-
tion into voice operated devices. This approach might ensure that
such devices only accept commands from the their real owners.
However, this approach has several limitations. First, the entropy in
the human voice prevents speaker recognition systems from being
used for large scale identification [17]. Second, researchers have
shown it is possible to synthesize audio to effectively imitate the vic-
tim’s voice, thereby defeating speaker recognition models [36, 41].
Tools making such attacks possible are widely available [5, 14].
The research community has spent significant effort in devel-
oping proximity based authentication systems. One of the best
known, Zero-Interaction Authentication (ZIA), involves the use of
an authentication token on a device (e.g., smart watch or phone)
in the user’s possession. The device monitors the user’s proxim-
ity [21] or activity [33] and then performs a wireless handshake
(e.g., via Bluetooth, WiFi) with the terminal device (e.g., a laptop)
using the token. Once the handshake is successfully completed,
the user is granted access to the terminal device. This approach
has some limitations, most important of which are replay [27] and
relay attacks [23, 26, 31, 43]. Similarly, zero-effort Two-factor au-
thentication can leverage surrounding audio to establish proximity
between the terminal and the user’s mobile device [30], although
some argue that this approach may be susceptible to adversarially
injected noise [42]. However, none of these techniques tightly lo-
calize a device user located arbitrarily within the same room as the
verifying device.
The use of the audio channel to perform these commands makes
the weaknesses described above more acute. As such, none of the
above solutions are appropriate to address the challenge identified
in this paper. Our goal in developing an embodiment of a 2MA
system is to overcome the limitations of these proposed systems in
an ecosystem in which voice commands are increasingly common.
3 BACKGROUND
3.1 Direction of Arrival
Direction of Arrival (DOA) is a technique used to determine the
direction a source (S) is located with respect to an array consisting
of at least 2 receivers, R1 and R2. DOA assumes S, R1, and R2 are
points on a 2D plane. The plane is defined such that R1 and R2 both
lie on the x-axis, with R1 at the origin. S transmits a signal (e.g.,
sound) which is subsequently registered by R1 and R2 at slightly
different times. R1 and R2 are assumed to share a global time frame
since they are apart of the same receiver array and both record the
time when the signal arrived at them. The difference between when
the signal arrives at both devices is used to compute the angle of
incidence as follows:
Session 3: AuthenticationASIACCS’18, June 4–8, 2018, Incheon, Republic of Korea902MA: Verifying Voice Commands via
Two Microphone Authentication
ASIA CCS ’18, June 4–8, 2018, Incheon, Republic of Korea
Figure 2: Robust Sound Hash steps: 1) The audio is split into
intervals. 2) The interval and a random number are passed
into a digest function. 3) The digest function generates a 512-
bit audio digest.
(a) Same content, different speakers (BER: 0.299)
(b) Different content, same speaker (BER: 0.499)
Figure 3: RSH helps identify similar content in two audio
streams, independent of the speaker. Cryptographic hashes
can not perform this task because noise, timbre, and differ-
ences in microphones produce varying analog streams. Fig-
ure 3a shows waveforms for two different speakers from the
TIMIT corpus saying the same content with a BER of 0.299.
Figure 3b shows the same speaker saying two different sen-
tences with a significantly higher average BER (0.499).
TT = Ty + TN
(3)
3.3 Robust Sound Hash
Once an audio command is given, 2MA needs a mechanism to de-
termine if the commands heard on the mobile device and the voice
operated device are the same. Intuitively, we could use a crypto-
graphic hash function, compute the hash of each audio sample and
then compare to see if there is a collision. However, cryptographic
hash function are sensitive to minor variance in the input. In the
Figure 1: Direction of Arrival helps determine the direction
of a sound source S relative to two receivers (R1 and R2).
θ = cos−1
(
)
vsτ
d
(1)
where vs is the speed of sound, d is the distance between R1
and R2, and τ is the difference between the arrival times. Figure 1
provides a visual description of this technique and shows both the
angle θ and its corresponding line L1.
A single microphone array provides a direction of the source
(with bounded uncertainty). However, the presence of a second
microphone (or set of microphones) can assist in identifying the
location of a source along (or nearby) L1. Another 2MA system
provides this second estimation. Unlike before, these microphones
are not located on the same physical array, so achieving clock
synchronization is necessary.
3.2 Clock Synchronization
Clock synchronization is the process whereby multiple independent
clocks are made to adhere to a single time domain. Even if the clocks
are initially set to the same time, their time values will gradually
drift apart; a phenomenon known as clock skew. A large amount of
research has been conducted in this area, especially with relation to
distributed systems [22, 24]. The Network Time Protocol (NTP) has
been shown to be accurate to tens of microseconds [4], more than
sufficient for our system. NTP works on a client server architecture,
where the client device sends a message contain the device’s time
when the first message is sent (Ta). The server records the “true”
time (Tx ) of when the first message is received and then it sends
its response message. The response message contains Ta, Tx , and
the “true” time when the server’s response is sent, Ty. Finally, the
client records their local time when the last message was received
(Tb). Using the four recorded times, the client can now estimate the
one way network latency (TN ) and the “true” (TT ) time using the
following equations.
Tb − Ta − (Ty − Tx )
2
TN =
(2)
SR1R2✓Receiver ArrayL1Session 3: AuthenticationASIACCS’18, June 4–8, 2018, Incheon, Republic of Korea91ASIA CCS ’18, June 4–8, 2018, Incheon, Republic of Korea