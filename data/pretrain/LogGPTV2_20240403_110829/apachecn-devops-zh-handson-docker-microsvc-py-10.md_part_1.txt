# 十、监控日志和指标
在实际操作中，快速检测和调试问题的能力至关重要。在本章中，我们将讨论两个最重要的工具，我们可以使用它们来发现在处理大量请求的生产集群中发生了什么。第一个工具是日志，它帮助我们了解单个请求中发生了什么，而另一个工具是度量，它对系统的聚合性能进行分类。
本章将涵盖以下主题:
*   实时系统的可观测性
*   设置日志
*   通过日志检测问题
*   设置指标
*   积极主动
到本章结束时，您将知道如何添加日志，以便它们可用于检测问题，以及如何添加和绘制指标，并了解两者之间的差异。
# 技术要求
我们将使用本章的示例系统，并对其进行调整，以包括集中式日志记录和度量。本章的代码可以在本书的 GitHub 资源库中找到:[https://GitHub . com/PacktPublishing/动手 Docker-for-micro service-with-Python/tree/master/chapter 10](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter10)。
要安装集群，您需要构建每个单独的微服务:
```
$ cd Chapter10/microservices/
$ cd frontend
$ docker-compose build
...
$ cd thoughts_backend
$ docker-compose build
...
$ cd users_backend
$ docker-compose build
...
```
The microservices in this chapter are the same ones that we introduced previously, but they add extra log and metrics configuration.
现在，我们需要创建示例名称空间，并使用`Chapter10/kubernetes`子目录中的`find`配置启动 Kubernetes 集群:
```
$ cd Chapter10/kubernetes
$ kubectl create namespace example
$ kubectl apply --recursive -f .
...
```
为了能够访问不同的服务，您需要更新您的`/etc/hosts`文件，使其包含以下代码行:
```
127.0.0.1 thoughts.example.local
127.0.0.1 users.example.local
127.0.0.1 frontend.example.local
127.0.0.1 syslog.example.local
127.0.0.1 prometheus.example.local
127.0.0.1 grafana.example.local
```
这样，您将能够访问本章的日志和指标。
# 实时系统的可观测性
可观察性是了解实时系统中正在发生什么的能力。我们可以处理低可观测性系统，在那里我们无法知道发生了什么，或者高可观测性系统，在那里我们可以通过工具从外部推断事件和内部状态。
可观测性是系统本身的特性。通常，监控是获取有关系统当前或过去状态的信息的操作。这有点像命名的争论，但是你要监控系统来收集它的可观察部分。
在很大程度上，监控很容易。有很多很棒的工具可以帮助我们捕捉和分析信息，并以各种方式呈现出来。但是，系统需要公开相关信息，以便收集。
暴露正确的信息量是困难的。过多的信息会产生大量的噪声，从而隐藏相关的信号。太少的信息不足以发现问题。在本章中，我们将研究不同的策略来解决这个问题，但是每个系统都必须自己探索和发现这个问题。期待在自己的系统中进行实验和改变！
分布式系统，如遵循微服务架构的系统，也存在问题，因为系统的复杂性会使其难以理解内部状态。在某些情况下，行为也是不可预测的。这种大规模的系统本质上永远不会完全健康；这里那里总会有小问题。您需要开发一个优先级系统来确定哪些问题需要立即采取行动，哪些问题可以在稍后阶段解决。
微服务可观测性的主要工具是**日志**和**度量**。它们被社区很好地理解和使用，并且有很多工具可以极大地简化它们的使用，既可以作为可在本地安装的包，也可以作为有助于数据保留和降低维护成本的云服务。
Using cloud services for monitoring will save you from maintenance costs. We will talk about this later in the *Setting up logs* and *Setting up metrics* sections.
Another alternative when it comes to observability is services such as Data Dog ([https://www.datadoghq.com/](https://www.datadoghq.com/)) and New Relic ([https://newrelic.com/](https://newrelic.com/)). They receive events – normally logs – and are able to derive metrics from there.
集群状态最重要的细节可以通过`kubectl`查看，正如我们在前面章节中看到的。这将包括诸如已部署的版本、重新启动、提取映像等详细信息。
For production environments, it may be good to deploy a web-based tool to display this kind of information. Check out Weave Scope, an open source tool that shows data in a web page similar to the one that can be obtained with `kubectl`, but in a nicer and more graphical way. You can find out more about this tool here: [https://www.weave.works/oss/scope/](https://www.weave.works/oss/scope/).
日志和度量有不同的目标，两者都可能是错综复杂的。我们将在这本书里看看它们的一些常见用法。
# 理解日志
日志跟踪系统中发生的独特事件。每个日志存储一条消息，该消息是在执行代码的特定部分时产生的。日志可以是完全通用的(*函数 X 称为*)也可以是包含具体细节的(*函数 X 用参数 A* 调用)。
日志最常见的格式是以普通字符串的形式生成。这非常灵活，通常与日志相关的工具可以处理文本搜索。
每个日志都包括一些元数据，这些元数据涉及谁生成了日志，日志是在什么时间创建的，等等。这通常也编码为文本，位于日志的开头。标准格式有助于排序和过滤。
日志还包括严重性级别。这允许进行分类，以便我们能够捕捉消息的重要性。严重性级别可以按重要性顺序为`DEBUG`、`INFO`、`WARNING`或`ERROR`。这种严重性允许我们过滤掉不重要的日志，并确定我们应该采取的措施。记录工具可以被配置为设置阈值；不太严重的日志将被忽略。
There are many severity levels, and you can define custom intermediate levels if you wish. However, this isn't very useful except in very specific situations. Later in this chapter, in the *Detecting problems through logs* section, we will describe how to set a strategy per level; too many levels can add confusion.
在 web 服务环境中，大多数日志将作为 web 请求响应的一部分生成。这意味着请求将到达系统，被处理，并返回一个值。沿途会生成几个日志。请记住，在负载下的系统中，多个请求将同时发生，因此来自多个请求的日志也将同时生成。例如，请注意第二个日志如何来自不同的 IP:
```
Aug 15 00:15:15.100 10.1.0.90 INFO app: REQUEST GET /endpoint
Aug 15 00:15:15.153 10.1.0.92 INFO api: REQUEST GET /api/endpoint
Aug 15 00:15:15.175 10.1.0.90 INFO app: RESPONSE TIME 4 ms
Aug 15 00:15:15.210 10.1.0.90 INFO app: RESPONSE STATUS 200
```
可以添加一个通用请求标识，将为单个请求生成的所有相关日志分组。我们将在本章后面看到如何做到这一点。
每个单独的日志可能相对较大，并且总体上占用大量磁盘空间。在负载下，系统中的日志可能会很快变得不成比例。不同的日志系统允许我们调整它们的保留时间，这意味着我们只保留它们一定的时间。在保留日志以查看过去发生的事情和使用合理的空间之间找到平衡很重要。
Be sure to check the retention policies when enabling any new log service, whether it be local or cloud-based. You won't be able to analyze what happened before the time window. Double-check that the progress rate is as expected – you don't want to find out that you went unexpectedly over quota while you were tracking a bug.
一些工具允许我们使用原始日志来生成聚合结果。他们可以统计特定日志出现的次数，并生成每分钟的平均次数或其他统计数据。但是这很昂贵，因为每个日志都占用空间。要观察这种聚集行为，最好使用特定的度量系统。
# 理解指标
度量处理聚合信息。它们显示的信息与一个事件无关，而是一组事件。这使我们能够以比使用日志更好的方式检查集群的一般状态。
We will use typical examples related to web services, mainly dealing with requests metrics, but don't feel restricted by them. You can generate your own metrics that are specific to your service!
当日志保存关于每个单独事件的信息时，度量会将信息减少到事件发生的次数，或者将它们减少到一个值，然后以某种方式对该值进行平均或聚合。
这使得度量比日志更轻量级，并允许我们根据时间绘制它们。度量提供了诸如每分钟请求数、一分钟内请求的平均时间、排队请求数、每分钟错误数等信息。
The resolution of the metrics may depend on the tool that was used to aggregate them. Keep in mind that a higher resolution will require more resources. A typical resolution is 1 minute, which is small enough to present detailed information unless you have a very active system that receives 10 or more requests per second.
捕获和分析与性能相关的信息，如平均请求时间，使我们能够检测到可能的瓶颈并迅速采取行动，以提高系统的性能。平均来说，这更容易处理，因为单个请求可能无法捕获足够的信息来让我们看到全局。它还帮助我们预测未来的瓶颈。
根据所使用的工具，有许多不同类型的度量标准。最常见的支持如下:
*   **计数器**:每次发生事情都会产生一个触发器。这将被计算和汇总。这方面的一个例子是请求的数量和错误的数量。
*   **仪表**:唯一的单个数字。它可以上升或下降，但最后一个值会覆盖前一个值。这方面的一个例子是队列中请求的数量和可用工作人员的数量。
*   **测量**:有数字关联的事件。这些数字可以通过某种方式进行平均、求和或汇总。与仪表相比，不同之处在于以前的测量仍然是独立的；例如，当我们以毫秒为单位请求时间，以字节为单位请求大小时。度量也可以作为计数器，因为它们的数量可能很重要；例如，跟踪请求时间也会计算请求的数量。
衡量标准主要有两种工作方式:
*   每发生一件事，一个事件就会被推向度量收集器。
*   每个系统维护自己的度量，然后定期从度量系统中*提取*。
每种方式都有其利弊。推送事件会产生更高的流量，因为每个事件都需要发送；这会导致瓶颈和延迟。提取事件只会对信息进行采样，并错过采样之间发生的事情，但它本质上更具可扩展性。
While both approaches are used, the trend is moving toward pulling systems for metrics. They reduce the maintenance that's required for pushing systems and are much more easier to scale.
我们将建立普罗米修斯，它使用第二种方法。第一种方法最常用的指数是石墨。
度量还可以组合生成其他度量；例如，我们可以将返回错误的请求数除以生成错误请求的请求总数。这种派生的度量可以帮助我们以有意义的方式呈现信息。
仪表板中可以显示多个指标，这样我们就可以了解服务或集群的状态。一眼看去，这些图形工具允许我们检测系统的一般状态。我们将设置 Grafana，使其显示图形信息:
![](img/1d334374-d1df-4f9f-a7ac-07ccd296c87a.png)
与日志相比，度量占用的空间要少得多，而且它们可以捕获更长的时间窗口。甚至有可能保留系统寿命的指标。这与日志不同，日志永远不会存储那么长时间。
# 设置日志
我们将把系统生成的所有日志集中到一个 pod 中。在本地开发中，这个 pod 将通过 web 界面公开所有接收到的日志。
日志将通过`syslog`协议发送，这是最标准的传输方式。Python 中对`syslog`有本地支持，实际上任何处理日志记录并支持 Unix 的系统也是如此。
Using a single container makes it easy to aggregate logs. In production, this system should be replaced with a container that relays the received logs to a cloud service such as Loggly or Splunk.
有多个`syslog`服务器能够接收日志并聚合日志；`syslog-ng`([https://www.syslog-ng.com/](https://www.syslog-ng.com/))和`rsyslog`([https://www.rsyslog.com/](https://www.rsyslog.com/))是最常见的。最简单的方法是接收日志并将它们存储在文件中。让我们用`rsyslog`服务器启动一个容器，它将存储接收到的日志。
# 设置 rsyslog 容器
在本节中，我们将创建自己的`rsyslog`服务器。这是一个非常简单的容器，您可以在 GitHub 上查看`docker-compose`和`Dockerfile`以获得更多关于日志的信息。
We will set up logs using the UDP protocol. This is the standard protocol for `syslog`, but it's less common than the usual HTTP over TCP that's used for web development.
The main difference is that UDP is connectionless, so the log is sent and no confirmation that it has been delivered is received. This makes UDP lighter and faster, but also less reliable. If there's a problem in the network, some logs may disappear without warning.
This is normally an adequate trade-off since the number of logs is high and the implications of losing a few isn't big. `syslog` can also work over TCP, thus increasing reliability but also reducing the performance of the system.
Dockerfile 安装`rsyslog`并复制其配置文件:
```
FROM alpine:3.9
RUN apk add --update rsyslog
COPY rsyslog.conf /etc/rsyslog.d/rsyslog.conf
```
配置文件主要在端口`5140`启动服务器，并将接收到的文件存储在`/var/log/syslog`中:
```
# Start a UDP listen port at 5140
module(load="imudp")
input(type="imudp" port="5140")
...
# Store the received files in /var/log/syslog, and enable rotation
$outchannel log_rotation,/var/log/syslog, 5000000,/bin/rm /var/log/syslog
```
使用日志旋转，我们在`/var/log/syslog`文件的一侧设置了一个限制，这样它就不会无限制地增长。
我们可以用通常的`docker-compose`命令来构建容器:
```
$ docker-compose build
Building rsyslog
...
Successfully built 560bf048c48a
Successfully tagged rsyslog:latest
```
这将创建一个 pod、一个服务和一个入口的组合，就像我们对其他微服务所做的那样，以收集日志并允许从浏览器进行外部访问。
# 定义系统日志窗格
`syslog`舱将包含`rsyslog`容器和另一个显示日志的容器。
为了显示日志，我们将使用 front rail，一个将日志文件流式传输到 web 服务器的应用。我们需要在同一个容器中跨两个容器共享文件，最简单的方法是通过一个卷。