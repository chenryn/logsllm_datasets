3.8
0
-
3.6
0
-
7.8
5.9
20.9
22.5
47.5
-
-
-
47.6
0.5
372.2
15.8
0.5
791
12.9
8.0
657.5
501
70.0
Table 12: CIFAR-10 Benchmark
Framework
A MiniONN
Gazelle
Runtime (s)
Communication (MB)
Ofﬂine Online Total Ofﬂine Online Total
9272
1236
3046
940
6226
296
472
9.34
72
3.56
544
12.9
Networks A and B use only the square activation
function allowing us to use a much simpler AHE base inter-
active protocol, thus avoiding any use of GC’s. As such we
only need to transmit short ciphertexts in the online phase.
Similarly our use of the AHE based FC and Conv layers
as opposed to multiplications triples results in 5-6× lower
latency compared to [29] and [30] for network A. The com-
parison with [18] is even more the stark. The use of AHE
with interaction acting as an implicit bootstraping stage
allows for aggressive parameter selection for the lattice
based scheme. This results in over 3 orders of magnitude
savings in both the latency and the network bandwidth.
Networks C and D use ReLU and MaxPool functions
which we implement using GC. However even for these
the network our efﬁcient FC and Conv implementation
allows us roughly 30× and 17× lower runtime when
compared with [32] and [29] respectively. Furthermore
we note that unlike [32] our solution does not rely on a
trusted third party.
The CIFAR-10 Dataset. The CIFAR-10 task is a
second commonly used image classiﬁcation benchmark
that is substantially more complicated than the MNIST
classiﬁcation task. The task consists of classifying
32×32 color with 3 color channels into 10 classes such
as automobiles, birds, cats, etc. For this task we replicate
the network topology from [29] to offer a fair comparison.
We use a 10bit wpt and a 8bit wrelin.
We note that the complexity of this network when
measured by the number of multiplications is 500× that
used in the MNIST network from [36], [32]. By avoiding
the need for multiplication triples Gazelle offers a 50×
faster ofﬂine phase and a 20× lower latency per inference
showing that our results from the smaller MNIST networks
scale to larger networks.
9 Conclusions and Future Work
In conclusion, this work presents Gazelle, a low-latency
framework for secure neural network inference. Gazelle
uses a judicious combination of packed additively
homomorphic encryption (PAHE) and garbled circuit
based two-party computation (2PC) to obtain 20− 30×
lower latency and 2.5−88× lower online bandwidth when
compared with multiple recent 2PC-based state-of-art
secure network inference solutions [29, 30, 32, 36], and
more than 3 orders of magnitude lower latency and 2 orders
of magnitude lower bandwidth than purely homomorphic
approaches [18]. We brieﬂy recap the key contributions
of our work that enable this improved performance:
1. Selection of prime moduli that simultaneously allow
SIMD operations, low noise growth and division-free
and lazy modular reduction.
2. Avoidance of ciphertext-ciphertext multiplications to
reduce noise growth.
3. Use of secret-sharing and interaction to emulate a
lightweight bootstrapping procedure allowing us to
evaluate deep networks composed of many layers.
4. Homomorphic linear algebra kernels that make
efﬁcient use of the automorphism structure enabled by
a power-of-two slot-size.
5. Sparing use of garbled circuits limited to ReLU and
MaxPool functions with linear-size Boolean circuits.
6. A compact garbled circuit-based transformation gadget
that allows us to securely compose the PAHE-based
and garbled circuit based layers.
There are a large number of natural avenues to build on
our work including handling neural networks with larger
input sizes and building a framework to automatically
compile neural networks into secure inference protocols.
Acknowledgments
We thank Kurt Rohloff, Yuriy Polyakov and the
PALISADE team for providing us with access to the
PALISADE library. We thank Shaﬁ Goldwasser, Rina
Shainski and Alon Kaufman for delightful discussions. We
thank our sponsors, the Qualcomm Innovation Fellowship
and Delta Electronics for supporting this work.
References
[1] ALBRECHT, M. R., PLAYER, R., AND SCOTT, S. On
the concrete hardness of learning with errors. Journal of
Mathematical Cryptology 9, 3 (2015), 169–203.
[2] ANGELINI, E., DI TOLLO, G., AND ROLI, A. A neural
network approach for credit risk evaluation. The Quarterly
Review of Economics and Finance 48, 4 (2008), 733 – 755.
[3] BELLARE, M., HOANG, V. T., KEELVEEDHI, S., AND RO-
GAWAY, P. Efﬁcient garbling from a ﬁxed-key blockcipher.
1666    27th USENIX Security Symposium
USENIX Association
In 2013 IEEE Symposium on Security and Privacy, SP 2013,
Berkeley, CA, USA, May 19-22, 2013 (2013), pp. 478–492.
[4] BRAKERSKI, Z. Fully homomorphic encryption without
modulus switching from classical gapsvp. In Advances
in Cryptology - CRYPTO 2012 - 32nd Annual Cryptology
Conference, Santa Barbara, CA, USA, August 19-23, 2012.
Proceedings (2012), pp. 868–886.
[5] BRAKERSKI, Z., GENTRY, C., AND VAIKUNTANATHAN,
V. (leveled) fully homomorphic encryption without boot-
strapping. In ITCS (2012).
[6] BRAKERSKI, Z., AND VAIKUNTANATHAN, V. Efﬁcient
In
fully homomorphic encryption from (standard) lwe.
FOCS (2011).
[7] CHILLOTTI, I., GAMA, N., GEORGIEVA, M., AND IZ-
ABACH `ENE, M. Faster fully homomorphic encryption:
In Advances in
Bootstrapping in less than 0.1 seconds.
Cryptology - ASIACRYPT 2016 - 22nd International Con-
ference on the Theory and Application of Cryptology and
Information Security, Hanoi, Vietnam, December 4-8, 2016,
Proceedings, Part I (2016), pp. 3–33.
[8] CHILLOTTI, I., GAMA, N., GEORGIEVA, M., AND IZ-
ABACHENE, M. Tfhe: Fast fully homomorphic encryption
over the torus, 2017. https://tfhe.github.io/
tfhe/.
[9] DAMGARD,
I., PASTRO, V., SMART, N., AND
ZACHARIAS, S.
The spdz and mascot secure com-
putation protocols, 2016. https://github.com/
bristolcrypto/SPDZ-2.
[10] DEMMLER, D., SCHNEIDER, T., AND ZOHNER, M. ABY
- A framework for efﬁcient mixed-protocol secure two-party
computation. In 22nd Annual Network and Distributed
System Security Symposium, NDSS 2015, San Diego, Cal-
ifornia, USA, February 8-11, 2015 (2015), The Internet
Society.
[11] DUCAS, L., AND STEHL ´E, D. Sanitization of FHE cipher-
texts. In Advances in Cryptology - EUROCRYPT 2016 -
35th Annual International Conference on the Theory and
Applications of Cryptographic Techniques, Vienna, Austria,
May 8-12, 2016, Proceedings, Part I (2016), pp. 294–310.
[12] EJGENBERG, Y., FARBSTEIN, M., LEVY, M., AND LIN-
DELL, Y. Scapi: Secure computation api, 2014. https:
//github.com/cryptobiu/scapi.
[13] ESTEVA, A., KUPREL, B., NOVOA, R. A., KO, J., SWET-
TER, S. M., BLAU, H. M., AND THRUN, S. Dermatologist-
level classiﬁcation of skin cancer with deep neural networks.
Nature 542, 7639 (2017), 115–118.
[14] FAN, J., AND VERCAUTEREN, F. Somewhat practical
fully homomorphic encryption. IACR Cryptology ePrint
Archive 2012 (2012), 144.
[15] GENTRY, C. A fully homomorphic encryption scheme.
PhD Thesis, Stanford University, 2009.
[16] GENTRY, C., HALEVI, S., AND SMART, N. P. Fully
homomorphic encryption with polylog overhead. In Ad-
vances in Cryptology - EUROCRYPT 2012 - 31st Annual
International Conference on the Theory and Applications
of Cryptographic Techniques, Cambridge, UK, April 15-19,
2012. Proceedings (2012), pp. 465–482.
[17] GENTRY, C., HALEVI, S., AND VAIKUNTANATHAN, V.
A simple BGN-type cryptosystem from LWE. In EURO-
CRYPT (2010).
[18] GILAD-BACHRACH, R., DOWLIN, N., LAINE, K.,
LAUTER, K. E., NAEHRIG, M., AND WERNSING, J. Cryp-
tonets: Applying neural networks to encrypted data with
high throughput and accuracy. In Proceedings of the 33nd In-
ternational Conference on Machine Learning, ICML 2016,
New York City, NY, USA, June 19-24, 2016 (2016), pp. 201–
210.
[19] GOLDREICH, O., MICALI, S., AND WIGDERSON, A.
How to play any mental game or a completeness theorem
for protocols with honest majority. In STOC (1987).
[20] GOLDWASSER, S., MICALI, S., AND RACKOFF, C. The
knowledge complexity of interactive proof systems. SIAM
J. Comput. 18, 1 (1989), 186–208.
[21] HALEVI, S., AND SHOUP, V. An implementation of ho-
momorphic encryption, 2013. https://github.com/
shaih/HElib.
[22] HALEVI, S., AND SHOUP, V. Algorithms in HElib. In
Advances in Cryptology - CRYPTO 2014 - 34th Annual
Cryptology Conference, Santa Barbara, CA, USA, August
17-21, 2014, Proceedings, Part I (2014), pp. 554–571.
[23] HALEVI, S., AND SHOUP, V., 2017. Presentation at the
Homomorphic Encryption Standardization Workshop, Red-
mond, WA, July 2017.
[24] HE, K., ZHANG, X., REN, S., AND SUN, J. Deep residual
learning for image recognition. CoRR abs/1512.03385
(2015).
[25] HENECKA, W., SADEGHI, A.-R., SCHNEIDER, T.,
WEHRENBERG, I., ET AL. Tasty: tool for automating
secure two-party computations. In Proceedings of the 17th
ACM conference on Computer and communications security
(2010), ACM, pp. 451–462.
[26] INDYK, P., AND WOODRUFF, D. P. Polylogarithmic pri-
vate approximations and efﬁcient matching. In Theory of
Cryptography, Third Theory of Cryptography Conference,
TCC 2006, New York, NY, USA, March 4-7, 2006, Proceed-
ings (2006), pp. 245–264.
[27] ISHAI, Y., KILIAN, J., NISSIM, K., AND PETRANK, E.
Extending oblivious transfers efﬁciently. In Advances in
Cryptology - CRYPTO 2003, 23rd Annual International
Cryptology Conference, Santa Barbara, California, USA,
August 17-21, 2003, Proceedings (2003), pp. 145–161.
[28] KRIZHEVSKY, A., SUTSKEVER, I., AND HINTON, G. E.
Imagenet classiﬁcation with deep convolutional neural net-
works. In Advances in Neural Information Processing Sys-
tems 25: 26th Annual Conference on Neural Information
Processing Systems 2012. Proceedings of a meeting held
December 3-6, 2012, Lake Tahoe, Nevada, United States.
(2012), pp. 1106–1114.
[29] LIU, J., JUUTI, M., LU, Y., AND ASOKAN, N. Oblivious
neural network predictions via minionn transformations.
In Proceedings of the 2017 ACM SIGSAC Conference on
Computer and Communications Security, CCS 2017, Dallas,
TX, USA, October 30 - November 03, 2017 (2017), pp. 619–
631.
[30] MOHASSEL, P., AND ZHANG, Y. Secureml: A system
for scalable privacy-preserving machine learning. In 2017
USENIX Association
27th USENIX Security Symposium    1667
IEEE Symposium on Security and Privacy, SP 2017, San
Jose, CA, USA, May 22-26, 2017 (2017), pp. 19–38.
[31] PAILLIER, P. Public-key cryptosystems based on compos-
ite degree residuosity classes. In Advances in Cryptology –
EUROCRYPT ’99 (1999), pp. 223–238.
[32] RIAZI, M. S., WEINERT, C., TKACHENKO, O.,
SONGHORI, E. M., SCHNEIDER, T., AND KOUSHAN-
FAR, F. Chameleon: A hybrid secure computation frame-
work for machine learning applications. Cryptology ePrint
Archive, Report 2017/1164, 2017. https://eprint.
iacr.org/2017/1164.
[33] RINDAL, P. Fast and portable oblivious transfer exten-
sion, 2016. https://github.com/osu-crypto/
libOTe.
[34] RIVEST, R. L., ADLEMAN, L., AND DERTOUZOS, M. L.
On data banks and privacy homomorphisms. Foundations
of Secure Computation (1978).
[35] ROHLOFF, K., AND POLYAKOV, Y. The PALISADE Lattice
Cryptography Library, 1.0 ed., 2017. Library available at
https://git.njit.edu/palisade/PALISADE.
[36] ROUHANI, B. D., RIAZI, M. S., AND KOUSHANFAR, F.
Deepsecure: Scalable provably-secure deep learning. CoRR
abs/1705.08963 (2017).
[37] SADEGHI, A., SCHNEIDER, T., AND WEHRENBERG, I.
Efﬁcient privacy-preserving face recognition. In Informa-
tion, Security and Cryptology - ICISC 2009, 12th Inter-
national Conference, Seoul, Korea, December 2-4, 2009,
Revised Selected Papers (2009), pp. 229–244.
[38] SCHROFF, F., KALENICHENKO, D., AND PHILBIN, J.
Facenet: A uniﬁed embedding for face recognition and
clustering. In IEEE Conference on Computer Vision and
Pattern Recognition, CVPR 2015, Boston, MA, USA, June
7-12, 2015 (2015), pp. 815–823.
[39] SIMONYAN, K., AND ZISSERMAN, A. Very deep convo-
lutional networks for large-scale image recognition. CoRR
abs/1409.1556 (2014).
[40] SZE, V., CHEN, Y., YANG, T., AND EMER, J. S. Efﬁcient
processing of deep neural networks: A tutorial and survey.
CoRR abs/1703.09039 (2017).
[41] SZEGEDY, C., LIU, W., JIA, Y., SERMANET, P., REED,
S., ANGUELOV, D., ERHAN, D., VANHOUCKE, V., AND
RABINOVICH, A. Going deeper with convolutions. In
Computer Vision and Pattern Recognition (CVPR) (2015).
[42] TRAM `ER, F., ZHANG, F., JUELS, A., REITER, M. K.,
AND RISTENPART, T. Stealing machine learning models
via prediction apis. In 25th USENIX Security Symposium,
USENIX Security 16, Austin, TX, USA, August 10-12, 2016.
(2016), pp. 601–618.
[43] V, G., L, P., M, C., AND ET AL. Development and valida-
tion of a deep learning algorithm for detection of diabetic
retinopathy in retinal fundus photographs. JAMA 316, 22
(2016), 2402–2410.
[44] YAO, A. C. How to generate and exchange secrets (ex-
tended abstract). In FOCS (1986).
[45] ZAHUR, S., ROSULEK, M., AND EVANS, D. Two halves
make a whole - reducing data transfer in garbled circuits
using half gates. In Advances in Cryptology - EUROCRYPT
2015 - 34th Annual International Conference on the The-
ory and Applications of Cryptographic Techniques, Soﬁa,
Bulgaria, April 26-30, 2015, Proceedings, Part II (2015),
pp. 220–250.
A The Halevi-Shoup Hoisting Optimization
The hoisting optimization reduces the cost of the ciphertext
rotation when the same ciphertext must be rotated by
multiple shift amounts. The idea, roughly speaking, is to
“look inside” the ciphertext rotation operation, and hoist
out the part of the computation that would be common to
these rotations and then compute it only once thus amor-
tizing it over many rotations. It turns out that this common
computation involves computing the NTT−1 (taking the ci-
phertext to the coefﬁcient domain), followed by a wrelin-bit
decomposition that splits the ciphertext (cid:100)(log2q)/wrelin(cid:101)
ciphertexts and ﬁnally takes these ciphertexts back to the
evaluation domain using separate applications of NTT.
The parameter wrelin is called the relinearization window
and represents a tradeoff between the speed and noise
growth of the Perm operation. This computation, which
we denote as PermDecomp, has Θ (nlogn) complexity
because of the number theoretic transforms. In contrast,
the independent computation in each rotation, denoted by
PermAuto, is a simple Θ(n) multiply and accumulate op-
eration. As such, hoisting can provide substantial savings
in contrast with direct applications of the Perm operation
and this is also borne out by the benchmarks in Table 7.
B Circuit Privacy
We next provide some details on our light-weight circuit
privacy solution. At a high level BFV ciphertexts look
like a tuple of ring elements (a, b) where a is chosen
uniformly at random and b encapsulates the plaintext and
the ciphertext noise. Both a and the ciphertext noise are
modiﬁed in a circuit dependent fashion during the process
of homomorphic computation and thus may violate
circuit privacy. We address the former by simply adding
a fresh public-key encryption of zero to the ciphertext to
re-randomize a. Information leakage through the noise is
handled through interactive decryption. The BFV decryp-
tion circuit is given by (cid:100)(a·s+b)/∆(cid:99) where s is the secret
key and ∆ =(cid:98)(p/q)(cid:99). Our approach splits the interactive
computation of this circuit into 2 phases. First we send
the re-randomized a back to the client who multiplies it
with s to a· s. We then use a garbled circuit to add this
to b. We leverage the fact that ∆ is public to avoid an
expensive division inside the garbled circuit. In particular
both parties can compute the quotients and remainders
modulo ∆ of their respective inputs and then interactively
evaluate a garbled circuit whose size is Ω(n·q). Note that
in contrast the naive decryption circuit is Ω(n2·q) sized
even without accounting for the division by ∆.
1668    27th USENIX Security Symposium
USENIX Association