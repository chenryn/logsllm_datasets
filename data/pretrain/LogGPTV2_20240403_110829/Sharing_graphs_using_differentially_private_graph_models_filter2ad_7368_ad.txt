 1e+06
 100000
 10000
 1000
 100
 10
 1
 0.1
 1
 10
 100
 10
 100
Epsilon
(b) Russia
Epsilon
(c) WWW
Figure 4: Euclidean distances of the dK-2-series of different -Differential Privacy strategies on three real graphs.
only leveraging m∗ independent Laplace random variables, with
parameter λ = (
 ), it is possible to generate sufﬁcient noise per
Sβi
cluster to satisfy the privacy requirement.
Conquering -privacy into ∪i bβi.
Our next task is to leverage
the proved -differential privacy of each independent bβi to guar-
antee privacy on the entire perturbed bβ-series= ∪i bβi. In order to
achieve this goal a further step is required, shown in the following
corollary.
COROLLARY 1. The amount of information an attacker can learn
on bβi by observing any bβj with i )= j is null.
This proof considers only two sub-series for simplicity. Given
Lemma 3, this proof can be extended to any number of clusters.
PROOF. Let A and B be two sub-series built out of our partition
strategy and let bA and bB be their -differentially private projection
as proved in Theorem 2. Finally, let a and b be events on bA and
bB, respectively. Through the Shannon Entropy Theory we quantify
the information a sub-series could exploit on another sub-series. In
particular, the Mutual Information
I(bA; bB) = X
p(a, b)
p(a)p(b)
p(a, b) log
a,b
is the amount of information an attacker can infer on bA by ob-
serving bB. By construction the sensitivity of the sub-series A is
independent from the sensitivity of the sub-series B, as proved
in Lemma 3. This means that the sub-series A is perturbed by
a Laplace random process with parameter λA that is independent
from the Laplace random process acting on B, as consequence of
Lemma 2. Thus, this independence property directly implies that
the Mutual Information I( bA, bB) = 0, that is, an attacker gains no
information on bA by observing bB, which concludes the proof.
The properties derived on the different βis are sufﬁcient to begin
the conquer phase of our DRC approach. The goal of the con-
quer phase is to unify the bβis such that the union set inherits the
-privacy guarantees from the individual sub-series.
THEOREM 3. Given em different sub-series bβi with i = 1, ..., em,
the result of the DRC conquer strategy ∪iβi satisﬁes the -differential
privacy property.
PROOF. The DRC strategy produces em -differentially private
sub-series bβi, as proved in Theorem 2. Each βi satisﬁes Lemma 2
and Lemma 3, and any combination of bβis satisﬁes Corollary 1.
The privacy independence property, from Corollary 1, implies that
∪i bβi satisﬁes the -Differential Privacy property.
Thus, we have proven that our perturbed dK-2, ∪i bβi, satisﬁes
the -differential privacy requirement. DRC achieves a tighter bound
on noise than dk-PA due to the properties from Lemmas 2 and 3.
Error Analysis. We now quantify the error introduced to dK-
2 via our DRC strategy. Error analysis on DRC is complicated
because our algorithm does not specify the number of clusters to
generate during partitioning.
Instead, our clustering approach is
general, and covers any possible set of cuts on the β-series such
that the resulting sub-series differ in cardinality and sensitivity from
each other, so long as they respect Lemmas 2 and 3. Therefore, in
order to provide an error analysis that covers any possible cluster-
ing of the β-series we have to study both the lower and the upper
bound of the error injected into those series.
DEFINITION 4. The error estimation of the union of the bβis un-
der the ∂ ordering on dK-2 of a graph G can be computed as the
expected randomization in generating bβ = ∪i bβi.
The expected randomization in bβ is quantiﬁed as
E0
@X
j
(bβi[j] − βi[j])21
A =
emX
i=1
emX
i=1
|βi|E[Lap(
Sβi

)2]
The lower bound is found when each Sβi have the same mini-
mum value, which is 1, and thus
i=1
Sβi

)2] ≥ d2
|βi|E[Lap(
maxV ar(Lap(
emX
Note that the considered minimum, i.e. 1, happens only when a
graph of nodes with zero degree is considered, and after adding an
edge Sβ is 1. The upper bound is found when each Sβi have the
maximum value that, as proved in Lemma 2, is O(dmax), and thus
d2
max
2
)) = Ω(
1

)
i=1
dmax
)) = O(
Sβi

)2] ≤ d2
|βi|E[Lap(
maxV ar(Lap(
emX
The worst-case error level of DRC is equal to that of dK-PA.
However, depending on graph structure, the error level can decrease
down to Ω( d2
). As we demonstrate in the next section, real
graphs exhibit error rates towards the lower bound. Thus, in prac-
tice, DRC performs much better than dK-PA.
d4
max
2
max
2
)

88)
%
(
F
D
C
 100
 90
 80
 70
 60
 50
 40
 30
 20
 1
Russia
dK w/o Noise
ε=100
ε=10
ε=5
)
%
(
F
D
C
 100
 1000
 10
Degree
(a) Russia
 100
 90
 80
 70
 60
 50
 40
 30
 20
 1
ε=100
WWW
ε=10
ε=5
dK w/o Noise
 100
 1000
 10
Degree
(b) WWW
)
%
(
F
D
C
 100
 90
 80
 70
 60
 50
 40
 30
 20
 1
 10
Degree
(c) AS
ε=100
AS
dK w/o Noise
ε=10
ε=5
 100
 1000
Figure 5: Degree distribution of three real measured graphs, i.e. Russia, WWW and AS, each compared to the dK-synthetic graph
without noise and Pygmalion synthetic graphs with different  values.
Russia
dK w/o Noise
ε=100
ε=10
ε=5
y
t
i
v
i
t
a
t
r
o
s
s
A
 0.5
 0.4
 0.3
 0.2
 0.1
 0
(a) Russia
 0
-0.02
-0.04
-0.06
-0.08
-0.1
-0.12
-0.14
y
t
i
v
i
t
a
t
r
o
s
s
A
WWW
dK w/o Noise
ε=100
ε=10
ε=5
(b) WWW
y
t
i
v
i
t
a
t
r
o
s
s
A
 0
-0.05
-0.1
-0.15
-0.2
-0.25
-0.3
AS
dK w/o Noise
ε=100
ε=10
ε=5
(c) AS
Figure 6: Assortativity of three real measured graphs, i.e. Russia, WWW and AS, each compared to the dK-synthetic graph without
noise and Pygmalion synthetic graphs with different  values.
4.3 Evaluating and Optimizing DRC
To quantify the improvement DRC achieves over the dK-PA
strategy, we compare the results of applying each algorithm on our
graphs. As before in Section 3.3, we quantify error using the Eu-
clidean distances between each of their dK-2-series and the dK-2-
series of the original graph. As seen in Figure 4, DRC reduces the
Euclidean distance by one order of magnitude for different graphs
and a range of  values. As is the case for dK-PA, error introduced
by DRC decreases exponentially as the value of  increases, which
is clear from the linear correlation in the log-log scale plot of Fig-
ure 4.
Further Optimization with LDRC.
Despite its improvement
over dK-PA, DRC is still quite far from the idealized function in
terms of error (see Figure 4). We apply a prior result from [25]
that proves how to use isotonic regression [6], i.e. evenly “smooth”
out the introduced noise across tuples, without breaking differential
privacy properties. This technique enables a reduction of the error
introduced in the dK-2-series by another constant factor.
Formally, given a vector p of length p∗, the goal is to determine
a new vector p! of the same length which minimizes the L2 norm,
i.e. ||p − p!||2. The minimization problem has the following con-
straints: p![i] ≤ p![i+1] for 1 ≤ i . Let deﬁne M[i, j] as
the mean of this sub-vector, i.e. M[i, j] = Pj
k=i p[k]/(j − i + 1).
THEOREM 4. [6] The minimum L2 vector, p!, is unique and is
equal to p![k] = gMk, with:
We apply this technique on the set of all tuples produced by
DRC. We refer to it as the L2 minimization Divide Randomize and
Conquer algorithm, or LDRC. We include LDRC in our compari-
son of algorithms in Figure 4, and see that LDRC provides roughly
another 50% reduction in error over the DRC algorithm. Since it
consistently outperforms our other algorithms, we use LDRC as the
algorithm inside the Pygmalion graph model.
Implications.
Finally, we note that our DRC partition tech-
nique is general, and has potential implications in other contexts
where it is desirable to achieve differential privacy with lower lev-
els of injected noise. More speciﬁcally, it can serve to reduce the
amount of perturbation necessary when the required perturbation is
a function of a parameter that varies signiﬁcantly across values in
the dataset.
5. END-TO-END GRAPH SIMILARITY
We have already quantiﬁed the level of similarity between real
and synthetic graphs by computing the Euclidean distances be-
tween their respective dK-series datasets. These values represent
the distortion in the statistical representation of a graph, i.e.
the
dK-series, but do not capture the ultimate impact of the added
noise on graph structure.
In this section, we evaluate how well
Pygmalion preserves a graph’s structural properties by comparing
Pygmalion’s differentially private synthetic graphs against the orig-
inals in terms of both graph metrics and outcomes in application-
level tests. Strong structural similarity in these results would es-
tablish the feasibility of using these differentially private synthetic
graphs in real research analysis and experiments.
gMk = minj∈[k,p∗]maxi∈[1,j]M[i, j]
89t
t
h
g
n
e
L