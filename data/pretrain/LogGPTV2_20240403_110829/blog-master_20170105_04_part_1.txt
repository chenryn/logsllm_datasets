## PostgreSQL 流式数据处理(聚合、过滤、转换...)系列 - 4        
### 作者                                                               
digoal                                                                
### 日期                                                               
2017-01-05                                                                    
### 标签                                                              
PostgreSQL , 流式 , 函数 , 流式处理 , 异步统计 , count , group , agg , 触发器 , xid , 事务隔离 , 异步气泡 , gap , function , 串行处理
----                                                              
## 背景           
2013年帮朋友做的方案。写了一些列文档来解决当时某个大数据BI平台的异步流式数据处理的功能。        
逐步优化，化繁为简。           
在业务层面，统计，数据的过滤，数据的清洗，数据的事件触发等。是比较常见的需求。            
比如以COUNT就是一个很典型的例子。        
在9.2以前全表的count只能通过扫描全表来得到, 即使有pk也必须扫描全表.        
9.2版本增加了index only scan的功能, count(*)可以通过仅仅扫描pk就可以得到.        
但是如果是一个比较大的表, pk也是很大的, 扫描pk也是个不小的开销.        
到了9.6，开始支持并行查询，通过并行，一张1亿的表，COUNT可能只需要几百毫秒。这是一个质的飞跃。（但是还有很多时候用并行并不是最好的）        
另外社区也除了一个流式处理的数据库，pipelineDB，但是它的社区版本限制了一个DATABASE只能使用1024个流视图，在编码的地方使用了1BYTE存储CV。        
那么回到postgresql数据库本身，有没有办法来优化count全表的操作呢, 如果你的场景真的有必要频繁的count全表, 那么可以尝试一下使用以下方法来优化你的场景.        
## 正文        
前面三篇blog针对PostgreSQL的coung(*)如何优化做了比较详细的分析和测试, 如下 :   
http://blog.163.com/digoal@126/blog/static/163877040201331252945440/  
http://blog.163.com/digoal@126/blog/static/16387704020133151402415/  
http://blog.163.com/digoal@126/blog/static/16387704020133155179877/  
但是都是实时的方式进行的优化, 特别是第三篇, 对于按列进行统计分析的场景, 因为统计维度较多, 实时的更新count(*)会带来较大的插入性能瓶颈. 例如有8个维度表的时候, 单步插入的性能会下降到insert = 6500 qps左右.  
这个时候, 你可能需要非实时批量统计. 也就是异步的更新维度表的统计数据.   
例如每100条数据更新一次, 或者每1秒更新一次. 来减少维度表的更新频率. 降低数据库, 但是统计数据是非实时的, 这点必须清楚.   
如果需要查询实时的count还需要查询未计入统计表的明细表数据.  
## 异步处理会遇到以下问题  
1\. 气泡问题, (有解决方法，不要使用界限，使用order by limit，或者直接使用limit).  
例如这样，是不是很帅呢（本文未涉及）？  (with tmp as (delete from tbl limit 10000 returning *) insert into xxx select x from tmp group by x; )    
自增长字段作为分段统计的分隔字段安全吗?   
如果明细表的插入是当线程的, 回答是安全的. 但是如果明细表是并行插入的, 那么就不安全了.  
举个例子(这里以时间为分隔字段) :   
```  
t1:2013-03-01 11:01:00 SESSION A :   
begin;  
insert into log(id,info,crt_time) values (1,'test1',clock_timestamp());  -- 假设clock_timestamp()='2013-03-01 11:01:00'  
t2:2013-03-01 11:01:02 SESSION B :   
begin;  
insert into log(id,info,crt_time) values (2,'test2',clock_timestamp());  -- 假设clock_timestamp()='2013-03-01 11:01:02'  
commit;  
t3:2013-03-01 11:01:03 统计操作1 : (由于此时a未提交,所以取不到a的数据)  
select * from log where crt_time >='2013-03-01 11:01:00' and crt_time='2013-03-01 11:01:02' and crt_time=log_read_last_txid;  
-- 处理 select * from log_del where txid =log_read_last_txid;  
-- 处理 select * from log where txid in log_xip and not in v_xip;  
-- 处理 select * from log_del where txid in log_xip and not in v_xip;  
-- 记录处理截止点log_read_last_txid;  
-- 更新log_xip  
end;  
```  
本例将采用方法二的解决办法.  
2\. 并行处理的问题, 如何保证并行安全, 高效.   
本例不涉及并行处理, 所以等下一篇BLOG再来解决这个问题. 感兴趣的朋友可以关注一下.  
3\. 如何减少取数次数(扫描次数).   
多个统计维度使用同一份数据. 这个本例已经解决.  
4\. 明细表delete带来的问题. 可能造成被删除的数据无法被统计.  
## 异步处理的解决办法  
1\. 加一个字段用来标识(记录是否删除). 应用程序查询数据是需要过滤删除数据.  
2\. 增加del明细表.  
本例已经解决.  
## 详细的实施过程  
测试表 :   
```  
create table log   
(  
  id serial primary key,   
  xid int8 default txid_current() not null,   
  isdel boolean default false not null,   
  c1 int not null,   
  c2 int not null,   
  c3 int not null,   
  c4 text not null,   
  crt_time timestamp default now()  
);  
create index idx_log_1 on log(xid);  
```  
存放count(*)的表, 假设经常需要按log.c1以及log.crt_time分天, 周, 月, 年进行count(*)  
```  
create table log_c1_cnt_day (c1 int, cnt int8, stat_time text, primary key(c1,stat_time));  
create table log_c1_cnt_week (c1 int, cnt int8, stat_time text, primary key(c1,stat_time));  
create table log_c1_cnt_month (c1 int, cnt int8, stat_time text, primary key(c1,stat_time));  
create table log_c1_cnt_year (c1 int, cnt int8, stat_time text, primary key(c1,stat_time));  
```  
存放count(*)的表, 假设经常需要按log.c2, log.c3以及log.crt_time分天, 周, 月, 年进行count(*)  
```  
create table log_c2_c3_cnt_day (c2 int, c3 int, cnt int8, stat_time text, primary key(c2,c3,stat_time));  
create table log_c2_c3_cnt_week (c2 int, c3 int, cnt int8, stat_time text, primary key(c2,c3,stat_time));  
create table log_c2_c3_cnt_month (c2 int, c3 int, cnt int8, stat_time text, primary key(c2,c3,stat_time));  
create table log_c2_c3_cnt_year (c2 int, c3 int, cnt int8, stat_time text, primary key(c2,c3,stat_time));  
```  
存放删除记录的表,   
```  
create table log_del (xid int8 default txid_current() not null, log_rec log not null);  
create index idx_log_del_1 on log_del(xid);  
```  
创建删除触发器函数, 更新log.isdel标记, 不删除log表. 同时插入log_del.  
```  
create or replace function tg_log_del() returns trigger as $$  
declare  
begin  
  -- 避免重复删除  
  if not OLD.isdel then  
    update log set isdel=true where id=OLD.id;  
    insert into log_del(log_rec) values (OLD);  
    return null;  
  else  
    -- 如果已经删除, 则直接返回空, 不处理.  
    return null;  
  end if;  
end;  
$$ language plpgsql;  
```  
在log上创建before删除触发器, 注意是before. 必须的.  
```  
create trigger tg1 before delete on log for each row execute procedure tg_log_del();  
```  
插入测试数据  
```  
insert into log (c1,c2,c3,c4) values (1,1,1,1);  
insert into log (c1,c2,c3,c4) values (2,2,2,2);  
```  
验证  
```  
digoal=# select * from log;  
 id |    xid    | isdel | c1 | c2 | c3 | c4 |          crt_time            
----+-----------+-------+----+----+----+----+----------------------------  
  2 | 444403112 | f     |  2 |  2 |  2 | 2  | 2013-04-19 11:47:17.140624  
  1 | 444403111 | f     |  1 |  1 |  1 | 1  | 2013-04-19 11:47:16.778672  
(2 rows)  
```  
删除验证  
```  