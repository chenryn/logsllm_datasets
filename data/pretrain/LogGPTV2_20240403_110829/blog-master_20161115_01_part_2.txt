postgres=> select to_tsvector('english', 'hello world') @@ to_tsquery($$'world' & 'hello'$$);
 ?column? 
----------
 t
(1 row)
两个词组字段的包含关系
'cat'::tsquery @> 'cat & rat'::tsquery
  return
false
'cat'::tsquery  'rat'
querytree(query tsquery)|	text|	get indexable part of a tsquery|	querytree('foo & ! bar'::tsquery)|	'foo'
setweight(vector tsvector, weight "char")|	tsvector|	assign weight to each element of vector|	setweight('fat:2,4 cat:3 rat:5B'::tsvector, 'A')|	'cat':3A 'fat':2A,4A 'rat':5A
setweight(vector tsvector, weight "char", lexemes text[])|	tsvector|	assign weight to elements of vector that are listed in lexemes|	setweight('fat:2,4 cat:3 rat:5B'::tsvector, 'A', '{cat,rat}')|	'cat':3A 'fat':2,4 'rat':5A
strip(tsvector)|	tsvector|	remove positions and weights from tsvector|	strip('fat:2,4 cat:3 rat:5A'::tsvector)|	'cat' 'fat' 'rat'
to_tsquery([ config regconfig , ] query text)|	tsquery|	normalize words and convert to tsquery|	to_tsquery('english', 'The & Fat & Rats')|	'fat' & 'rat'
to_tsvector([ config regconfig , ] document text)|	tsvector|	reduce document text to tsvector|	to_tsvector('english', 'The Fat Rats')|	'fat':2 'rat':3
ts_delete(vector tsvector, lexeme text)|	tsvector|	remove given lexeme from vector|	ts_delete('fat:2,4 cat:3 rat:5A'::tsvector, 'fat')|	'cat':3 'rat':5A
ts_delete(vector tsvector, lexemes text[])|	tsvector|	remove any occurrence of lexemes in lexemes from vector|	ts_delete('fat:2,4 cat:3 rat:5A'::tsvector, ARRAY['fat','rat'])|	'cat':3
ts_filter(vector tsvector, weights "char"[])|	tsvector|	select only elements with given weights from vector|	ts_filter('fat:2,4 cat:3b rat:5A'::tsvector, '{a,b}')|	'cat':3B 'rat':5A
ts_headline([ config regconfig, ] document text, query tsquery [, options text ])|	text|	display a query match|	ts_headline('x y z', 'z'::tsquery)|	```x y z```
ts_rank([ weights float4[], ] vector tsvector, query tsquery [, normalization integer ])|	float4|	rank document for query|	ts_rank(textsearch, query)|	0.818
ts_rank_cd([ weights float4[], ] vector tsvector, query tsquery [, normalization integer ])|	float4|	rank document for query using cover density|	ts_rank_cd('{0.1, 0.2, 0.4, 1.0}', textsearch, query)|	2.01317
ts_rewrite(query tsquery, target tsquery, substitute tsquery)|	tsquery|	replace target with substitute within query|	ts_rewrite('a & b'::tsquery, 'a'::tsquery, 'foo&#124;bar'::tsquery)|	'b' & ( 'foo' &#124; 'bar' )
ts_rewrite(query tsquery, select text)|	tsquery|	replace using targets and substitutes from a SELECT command|	SELECT ts_rewrite('a & b'::tsquery, 'SELECT t,s FROM aliases')|	'b' & ( 'foo' &#124; 'bar' )
tsquery_phrase(query1 tsquery, query2 tsquery)|	tsquery|	make query that searches for query1 followed by query2 (same as  operator)|	tsquery_phrase(to_tsquery('fat'), to_tsquery('cat'))|	'fat'  'cat'
tsquery_phrase(query1 tsquery, query2 tsquery, distance integer)|	tsquery|	make query that searches for query1 followed by query2 at maximum distance distance|	tsquery_phrase(to_tsquery('fat'), to_tsquery('cat'), 10)|	'fat'  'cat'
tsvector_to_array(tsvector)|	text[]|	convert tsvector to array of lexemes|	tsvector_to_array('fat:2,4 cat:3 rat:5A'::tsvector)|	{cat,fat,rat}
tsvector_update_trigger()|	trigger|	trigger function for automatic tsvector column update|	CREATE TRIGGER ... tsvector_update_trigger(tsvcol, 'pg_catalog.swedish', title, body)|	
tsvector_update_trigger_column()|	trigger|	trigger function for automatic tsvector column update|	CREATE TRIGGER ... tsvector_update_trigger_column(tsvcol, configcol, title, body)|	
unnest(tsvector, OUT lexeme text, OUT positions smallint[], OUT weights text)|	setof record|	expand a tsvector to a set of rows|	unnest('fat:2,4 cat:3 rat:5A'::tsvector)|	(cat,{3},{D})...
一些重要的例子  
1\. 这里重点将一下PG9.6加入的phrase转换功能，支持相邻度啦。   
例如你要搜索“中国道教文化”，分词后变成了中国  道教  文化，他们必须相邻才能匹配。  否则不匹配。   
如"中国人口普查，道教占比xx，文化程度xx"，这个分词是不匹配的。  如果你要匹配则可以使用原始的方法使用 中国 & 道教 & 文化 即可。  是不是非常灵活非常赞呢。      
```
postgres=# select phraseto_tsquery('hello digoal');
   phraseto_tsquery   
----------------------
 'hello'  'digoal'
(1 row)
postgres=# select phraseto_tsquery('hello digoal zhou');
        phraseto_tsquery         
---------------------------------
 'hello'  'digoal'  'zhou'
(1 row)
postgres=# select plainto_tsquery('hello digoal zhou');
       plainto_tsquery       
-----------------------------
 'hello' & 'digoal' & 'zhou'
(1 row)
postgres=# select plainto_tsquery('hello digoal zhou, this is china');
            plainto_tsquery            
---------------------------------------
 'hello' & 'digoal' & 'zhou' & 'china'
(1 row)
postgres=# select phraseto_tsquery('hello digoal zhou, this is china');
              phraseto_tsquery               
---------------------------------------------
 'hello'  'digoal'  'zhou'  'china'
(1 row)
```
2\. 查询词组哪些支持索引搜索    
```
querytree('foo & ! bar'::tsquery)  
foo支持索引  
!bar不支持索引  
```
3\. 添加或消除tsvector的weight（即ABCD）    
```
setweight('fat:2,4 cat:3 rat:5B'::tsvector, 'A')  -- 所有lexeme都添加A权重
'cat':3A 'fat':2,4 'rat':5A
setweight('fat:2,4 cat:3 rat:5B'::tsvector, 'A', '{cat,rat}')  -- cat,rat添加A权重
'cat':3A 'fat':2,4 'rat':5A
strip('fat:2,4 cat:3 rat:5A'::tsvector)  --  消除权重
'cat' 'fat' 'rat'
```
4\. 删除tsvector中指定的lexeme ， 例如 我们知道这些词是没有意义的，可以清除出去。    
```
ts_delete('fat:2,4 cat:3 rat:5A'::tsvector, 'fat')	返回	'cat':3 'rat':5A
ts_delete('fat:2,4 cat:3 rat:5A'::tsvector, ARRAY['fat','rat'])	返回	'cat':3
```
5\. 根据权重过滤分词，例如 我只看标题和副标题是否匹配（假设标题和副标题的权重为A,B）。     
```
ts_filter('fat:2,4 cat:3b rat:5A'::tsvector, '{a,b}')	返回	'cat':3B 'rat':5A
```
6\. 黑体表示匹配的词组，这个忒有用了，特别是在展示时。  
例如我经常为一些BLOG平台敏感词过滤苦恼，他们也不告诉我哪些敏感词触犯规则了，有了这个，可以很快速的定位到匹配的词。  
```
	ts_headline('x y z', 'z'::tsquery)	返回	x y z
```
7\. 匹配百分比，应用场景更多，例如，按匹配程度排序，匹配度越高的，排的越前面。  
```
ts_rank(textsearch, query)	0.818
select *, ts_rank(fts,to_tsquery('supernovae & x-ray')) as rank 
from apod
where fts  @@ to_tsquery('supernovae & x-ray') 
order by rank desc limit 5;
或者直接使用操作符
select *
from apod
where fts  @@ to_tsquery('supernovae & x-ray') 
order by fts  to_tsquery('supernovae & x-ray') desc limit 5;
```
由于分词有标题，副标题，正文，段落（即权重）之分，所以它还支持为不同的权重，设置不同的系数，例如    
根据你设置的权重，计算匹配度，是不是很有意思呢。    
```
设置A,B,C,D的系数为{0.1, 0.2, 0.4, 1.0}
ts_rank_cd('{0.1, 0.2, 0.4, 1.0}', textsearch, query)	返回	2.01317
```
8\. 查询词组重写功能，就像SQL REWRITE一样，或者像文本替换功能一样。  
```
将a替换为foo|bar    
ts_rewrite('a & b'::tsquery, 'a'::tsquery, 'foo|bar'::tsquery)	返回	'b' & ( 'foo' | 'bar' )
支持批量替换，例如使用QUERY，替换目标为s字段，替换为t。   
SELECT ts_rewrite('a & b'::tsquery, 'SELECT t,s FROM aliases')	返回	'b' & ( 'foo' | 'bar' )
```
9\. 计算phrase，转换为tsquery，这里包含了lexeme之间的距离信息。  
```
tsquery_phrase(to_tsquery('fat'), to_tsquery('cat'))	返回	'fat'  'cat'    --  制造fat和cat相邻的phrase  
tsquery_phrase(to_tsquery('fat'), to_tsquery('cat'), 10)	返回	'fat'  'cat'   --  制造fat和cat相距10个token(包括被过滤的token)的phrase   
```
10\. 将tsvector转换为数组，数组没有位置信息。  
```
tsvector_to_array('fat:2,4 cat:3 rat:5A'::tsvector)	返回	{cat,fat,rat}
```
11\. 自动更新分词字段，这个太重要了，例如用户更新了文本字段，如何自动更新对应的分词字段呢？    
```
两个内置的触发器搞定  
CREATE TRIGGER ... tsvector_update_trigger(tsvcol, 'pg_catalog.swedish', title, body)  
CREATE TRIGGER ... tsvector_update_trigger_column(tsvcol, configcol, title, body)
```
12\. 展开tsvector，转换为多条记录.    
```
unnest('fat:2,4 cat:3 rat:5A'::tsvector)	(cat,{3},{D}) ...  
```
## 全文检索类型调试函数
例如你添加了字典，添加了分词配置，或者修改了分词的配置，先给看看修改后的分词结果。  
因为分词有几个步骤，如将字符串按照字典拆分成tokens，包括位置信息，权重等；然后根据token的属性，以及ts config配置，过滤不必要token；返回tsvector。  
使用调试函数可以看到最原始的拆分信息。  
https://www.postgresql.org/docs/9.6/static/functions-textsearch.html    
例子    
Table 9-41. Text Search Debugging Functions  
Function|	Return| Type|	Description|	Example	Result
---|---|---|---|---
ts_debug([ config regconfig, ] document text, OUT alias text, OUT description text, OUT token text, OUT dictionaries regdictionary[], OUT dictionary regdictionary, OUT lexemes text[])|	setof record|	test a configuration|	ts_debug('english', 'The Brightest supernovaes')|	(asciiword,"Word, all ASCII",The,{english_stem},english_stem,{}) ...
ts_lexize(dict regdictionary, token text)|	text[]|	test a dictionary|	ts_lexize('english_stem', 'stars')|	{star}
ts_parse(parser_name text, document text, OUT tokid integer, OUT token text)|	setof record|	test a parser|	ts_parse('default', 'foo - bar')|	(1,foo) ...
ts_parse(parser_oid oid, document text, OUT tokid integer, OUT token text)|	setof record|	test a parser|	ts_parse(3722, 'foo - bar')|	(1,foo) ...