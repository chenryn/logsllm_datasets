terminal multiplication where one of the inputs can be large, by
outputting the result of the pairing operation without executing
the final conversion step. This simple observation has interesting
applications: it allows to design RMS programs in which a large
secret key will be revealed if and only if some predicate is satisfied.
More specifically, it allows to evaluate programs with outputs of
the form K F (x1,··· ,xn ) where K is a large input, and (x1,· · · , xn )
are short input: the key K will be revealed if and only if F evaluates
to 1 on (x1,· · · , xn ).
Reduced Failure Probability in Terminal Multiplications. Consider ter-
minal multiplications in the evaluation of an RMS program where
the output is computed modulo β. If a party detects a risk of failure,
he must return a flag ⊥. However, observe that such a failure occurs
when the two parties end up on different distinguished points in
a conversion step; but if the distance between the two possible
distinguished points happens to be a multiple of β in a terminal
multiplication, then the reduction modulo β of the result will can-
cel this failure. In this case, the party can simply ignore the risk
of failure. For the most commonly used special case of computa-
tion modulo 2, this observation reduces the number of failures in
terminal multiplication by a factor 2.
4.5.2 Evaluating Branching Programs and Formulas. As pointed
out in [11], a branching program can be evaluated using two RMS
multiplications for each node. A simple observation shows that in
fact, a single RMS multiplication per node is sufficient. Each node N
is computed as x · N0 +y · N1, where (N0, N1) are values on the two
parent nodes, and (x, y) are multipliers on the edges (N0, N ) and
(N1, N ). Observe that the two edges leaving N0 carry the values x
and ¯x, and that given (N0, x · N0), the value ¯x · N0 can be computed
as N0 − x · N0 at no cost. Therefore, the two RMS multiplications
used to compute N can be reused in the computation of two other
nodes, saving a factor two on average compared to the simulation
of a branching program by an RMS program given in Claim A.2
of [11].
Session J1:  OutsourcingCCS’17, October 30-November 3, 2017, Dallas, TX, USA2114As boolean formulas can be efficiently simulated by branching
programs, a fan-in-2 boolean formula with n internal AND and OR
gates can be evaluated using exactly n RMS multiplication in the
setting of secret-key HSS. In the setting of public-key HSS, where
the encryption of the inputs must be converted to level 2 shares,
and additional RMS multiplication per input is required. In both
cases, NOT gates incur no additional cost.
4.5.3 Evaluating Threshold Formulas. Threshold functions (that
return 1 if at least some number n of inputs, out of N , are equal to 1)
are useful in many applications. An n-out-of-N threshold function
can be evaluated using (N − n + 1) · n non-terminal RMS multiplica-
tions, and 1 terminal RMS multiplication (for example, the majority
/4 − 1 RMS multiplications),
function requires essentially (N + 1)
using their natural branching program representation. Applying an
n-out-of-N threshold function to the N outputs of N size-k boolean
formulas requires k (N −n +1)·n non-terminal RMS multiplications.
This class of functions captures a large number of interesting appli-
cations, such as evaluating policies on encrypted data, or searching
for fuzzy matches with encrypted queries.
2
5 APPLICATIONS
In this section, we outline a number of natural scenarios in which
group-based HSS seems particularly attractive, and describe how
our the optimizations from the previous section apply in these sce-
narios. The efficiency estimates given in this section are based on
the running time of our implementation, described Section 6 (see
Remark 6.1), using a single thread of an Intel Core i7 CPU. Our
implementation could perform roughly 5×109 conversion steps per
second on average, and 6.4×105 modular multiplications per second,
on a conversion-friendly group with a pseudo-Mersenne modulus
p = 21536 − 11510609, which is estimated to provide roughly 80 bits
of security. We summarize in Table 1 the optimizations of Section 4
that apply to each application described in this section. Some of
the subsections of Section 4 refer to several distinct possible opti-
mizations; a ✓ mark indicates that at least one of the optimizations
apply to the application. Note also that leakage-absorbing pads
(Section 4.4.1) and ciphertext compression (Section 4.3) cannot be
used simultaneously; for applications where both optimizations
possibly apply, only one of the two optimizations can be used in a
given instantiation. Finally, for some applications, there are opti-
mizations that are not relevant in general, but could be applied in
some specific scenario; those optimizations are still marked with a
✗ for simplicity.
5.1 Secure MPC with Minimal Interaction
Suppose that a set of clients wish to outsource some simple MPC
computation to two servers, with a simple interaction pattern that
involves a message from each input client to each server and a
message from each server to each output client. Security should
hold as long as the two servers do not collude, and should hold even
if when an arbitrary set of clients colludes with one server. HSS
provides a natural solution in this scenario. Before the set of clients
or their inputs are known, the two servers Sb obtain a common
public key pk and local secret evaluation keys ekb. This (reusable)
setup can be implemented via a trusted dealer or via an interactive
protocol between the servers or another set of parties. (When the
(5.2)
(5.2)
(5.2)
MPC File System RSS Feed PIR Correl.
(5.1)
(5.3)
Share Conversion (4.1) ✓
Rand. Conversion (4.1) ✓
Key Generation (4.2)
✓
Compression (4.3)
✓
Leakage (4.4)
✓
Terminal Mult. (4.5)
✓
Large Inputs (4.5)
✓
✓
✓
✗
✓
✓
✓
✓
✓
✓
✗
✗
✗
✓
✗
✓
✓
✗
✗
✓
✓
✗
✓
✓
✓
✗
✗
✓
✗
Table 1: Summary of the optimizations of Section 4 that ap-
ply to the applications of Section 5.
setup is implemented using external parties, the servers do not ever
need to interact or know each other’s identity.) The clients, who
do not need to know which or how many other clients participate
in the protocol, can compute a program P on their inputs xi in the
following way.
• Upload inputs. Each client Ci with input xi computes cti ←
Enc(pk, xi ) and sends cti to both servers. (Alternatively, the
encrypted inputs cti can be posted in a public repository and
downloaded by the servers.)
• Local evaluation. Each server Sb, given encrypted inputs
(ct1,· · · , ctn ) and a program P, locally computes zb ←
Eval(b, ekb , (ct1,· · · , ctn ), P, δ ), where δ is a given failure
probability bound.
• Download output. Each server Sb sends zb to each output
client. (Alternatively, zb can be made public if the output is
public.) The output P (x1, . . . , xn ) is recovered, except with
δ failure probability, by computing z ← z0 ⊕ z1.
A simple example for this kind of secure computation can be
a small-scale vote: multiple clients encrypt their vote and upload
them on a public repository. The two servers retrieve the encrypted
votes and evaluate the voting function (say, majority, conjunction,
or another threshold function), without having to interact. The
local nature of this computation mitigates risks of collusions and
reduces latency. Shares of the result of the vote are then sent to
the clients, who can reconstruct the result by performing a simple
XOR. In case of a failure, the vote can be recomputed using the
same encrypted inputs.
Managing the Leakage. Note that the event of a failure in our group-
based HSS constructions is correlated with both the private inputs of
the clients and the secret evaluation keys. In some cases, this might
not be an issue: the private inputs are compromised only when a
leakage occurs while a server is corrupted. In scenarios where a
server has a low probability of being corrupted, this conjunction of
events can be acceptably rare.
To further mitigate the risk associated with such leakage, the
parties can use the techniques described in Section 4.4.1 to reduce
the dependency between a failure event and a leakage event. The
key randomization techniques can be used to ensure that the same
setup can be used for many computations without compromising
the secret key. Moreover, leakage-absorbing pads can be generated
as part of the distributed key setup to protect inputs encrypted
Session J1:  OutsourcingCCS’17, October 30-November 3, 2017, Dallas, TX, USA2115Using leakage pads
no leakage pads
6.5
6
5.5
5
4.5
4
3.5
3
2.5
2
1.5
1
0.5
0
s
d
n
o
c
e
s
n
i
e
m
T
i
5
15
10
Number of inputs n
20
25
Figure 3: Time to compute majority of n inputs with 10−4
leakage probability, with and without leakage-absorbing
pads, on a single thread of an Intel Core i7 CPU. See Re-
mark 6.1 for further implementation details.
2
with this setup, where Eval is replaced by the MaskedEval algo-
rithm. To minimize the number of pads, the same pad can be used
in each computation until one of the servers detects possible failure;
when this happens, the compromised pad is replaced by a new pad
in subsequent computations. This makes the leakage probability
quadratically smaller than the failure probability. Note that while
communication between the servers may still be occasionally re-
quired for generating new leakage pads, such an interaction will
typically be very infrequent and has a small amortized cost.
Efficiency Estimations. Consider for example the case of n clients
who want to compute the majority of their private inputs. The
majority function can be implemented using an RMS program with
/4 − 1 non-terminal multiplications. Each client sends one
(n + 1)
ciphertext encrypting his input, with basis B = 2 if using leakage-
absorbing pads (for XOR-masking), and B = 16 otherwise. Figure 3
shows the time required to compute the majority function on n
inputs, using either Eval directly, or using leakage-absorbing pads
and MaskedEval. Without leakage-absorbing pads, a ciphertext is
of size 10.6kB. With leakage-absorbing pads, a ciphertext is of size
35.9kB. The parameters are chosen to ensure a 10−4 leakage proba-
bility, and allow for the evaluation of about 104 functions before
refreshing the key. In the setting with leakage-absorbing pads, this
requires generating a number N = 100 of pads during the setup.
Note that the failure probability corresponding to a 10−4 leakage
probability is 1% with leakage pads, and 0.01% without leakage pads.
However, one can easily mitigate this issue by setting the leakage
probability of the pad-based protocol to 10−4
/2 and re-running it
when a failure occurs, which allows to maintain a 10−4 leakage
probability while making the failure probability comparable to that
of the protocol without pads, at essentially no cost in efficiency (as
the protocol is re-run only when a failure actually occurs).
Advantage over alternative approaches. This HSS-based approach
has the advantage of being particularly efficient for the clients,
without requiring interaction between the servers (or requiring
infrequent interaction for refreshing secret key or leakage absorb-
ing pads). Standard alternative techniques for performing secure
computation in this setting break down if a client colludes with one
of the servers. For instance, this applies to solutions where one of
the servers generates a garbled circuit, or to solutions that employ
a standard FHE scheme whose secret key is known to all clients.
5.2 Secure Data Access
In this section, we discuss three natural applications of HSS to
secure data access: policy-based file systems, private RSS feeds, and
private information retrieval.
5.2.1 Policy-Based File Systems. Consider the following sce-
nario: a data owner wants to maintain a file system where users,
identified by a set of attributes, can access encrypted files according
to some policy. Let us outline a brief intuition of an HSS-based
solution: the data owner D generates the keys of a secret-key Las
Vegas HSS and sends them to two servers (S0, S1), together with
some encrypted vectors that indicates how permissions to access
the files should be granted given the vector of attributes of some
client. A public repository contains encrypted files EK (m), where
the key K is derived from a large value r encrypted by the data
owner. An RMS program P determines whether access should be
granted to a client. We use the enhanced semantic of section 4.5.1
to allow the program P to handle the large input r in a terminal
multiplication. We discuss this application in more details in the
full version.
5.2.2 Private RSS Feed. Consider the following scenario: a client
has subscribed to a (potentially large) number of RSS feeds, and
would like to receive regular updates on whether new data might
interest him. Typical examples could be getting newspapers relevant
to his center of interest, or job offers corresponding to his abilities.
Each data is categorized by a set of tags, and the client wishes
to retrieve data containing specific tags (one can also envision