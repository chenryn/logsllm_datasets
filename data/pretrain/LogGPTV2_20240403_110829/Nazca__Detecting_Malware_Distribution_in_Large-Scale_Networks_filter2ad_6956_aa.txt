title:Nazca: Detecting Malware Distribution in Large-Scale Networks
author:Luca Invernizzi and
Stanislav Miskovic and
Ruben Torres and
Christopher Kruegel and
Sabyasachi Saha and
Giovanni Vigna and
Sung-Ju Lee and
Marco Mellia
Nazca: Detecting Malware Distribution
in Large-Scale Networks
Luca Invernizzi
UC Santa Barbara
PI:EMAIL
Sung-Ju Lee
Narus, Inc.
PI:EMAIL
Stanislav Miskovic
Narus, Inc.
PI:EMAIL
Marco Mellia
Politecnico di Torino
PI:EMAIL
Abstract—Malware remains one of the most signiﬁcant secu-
rity threats on the Internet. Antivirus solutions and blacklists,
the main weapons of defense against these attacks, have only
been (partially) successful. One reason is that cyber-criminals
take active steps to bypass defenses, for example, by distribut-
ing constantly changing (obfuscated) variants of their malware
programs, and by quickly churning through domains and IP
addresses that are used for distributing exploit code and botnet
commands.
We analyze one of the core tasks that malware authors have to
achieve to be successful: They must distribute and install malware
programs onto as many victim machines as possible. A main vec-
tor to accomplish this is through drive-by download attacks where
victims are lured onto web pages that launch exploits against the
users’ web browsers and their components. Once an exploit is
successful, the injected shellcode automatically downloads and
launches the malware program. While a signiﬁcant amount of
previous work has focused on detecting the drive-by exploit
step and the subsequent network trafﬁc produced by malware
programs, little attention has been paid to the intermediate step
where the malware binary is downloaded.
In this paper, we study how clients in real-world networks
download and install malware, and present Nazca, a system
that detects infections in large scale networks. Nazca does not
operate on individual connections, nor looks at properties of the
downloaded programs or the reputation of the servers hosting
them. Instead,
it looks at the telltale signs of the malicious
network infrastructures that orchestrate these malware installa-
tion that become apparent when looking at the collective trafﬁc
produced and becomes apparent when looking at the collective
trafﬁc produced by many users in a large network. Being content
agnostic, Nazca does not suffer from coverage gaps in reputation
databases (blacklists), and is not susceptible to code obfuscation.
We have run Nazca on seven days of trafﬁc from a large
Internet Service Provider, where it has detected previously-unseen
malware with very low false positive rates.
Permission(cid:1) to(cid:1) freely(cid:1) reproduce(cid:1) all(cid:1) or(cid:1) part(cid:1) of(cid:1) this(cid:1) paper(cid:1) for(cid:1) noncommercial(cid:1)
purposes(cid:1)is(cid:1)granted(cid:1)provided(cid:1)that(cid:1)copies(cid:1)bear(cid:1)this(cid:1)notice(cid:1)and(cid:1)the(cid:1)full(cid:1)citation(cid:1)
on(cid:1)the(cid:1)ﬁrst(cid:1)page.(cid:1)Reproduction(cid:1)for(cid:1)commercial(cid:1)purposes(cid:1)is(cid:1)strictly(cid:1)prohibited(cid:1)
without(cid:1)the(cid:1)prior(cid:1)written(cid:1)consent(cid:1)of(cid:1)the(cid:1)Internet(cid:1)Society,(cid:1)the(cid:1)ﬁrst-named(cid:1)author(cid:1)
(for(cid:1) reproduction(cid:1) of(cid:1) an(cid:1) entire(cid:1) paper(cid:1) only),(cid:1) and(cid:1) the(cid:1) author’s(cid:1) employer(cid:1) if(cid:1) the(cid:1)
paper(cid:1)was(cid:1)prepared(cid:1)within(cid:1)the(cid:1)scope(cid:1)of(cid:1)employment.
NDSS(cid:1)’14,(cid:1)23-26(cid:1)February(cid:1)2014,(cid:1)San(cid:1)Diego,(cid:1)CA,(cid:1)USA
Copyright(cid:1)2014(cid:1)Internet(cid:1)Society,(cid:1)ISBN(cid:1)1-891562-35-5
http://dx.doi.org/(cid:18)(cid:17)(cid:15)(cid:18)(cid:21)(cid:24)(cid:19)(cid:19)(cid:16)(cid:79)(cid:69)(cid:84)(cid:84)(cid:15)(cid:19)(cid:17)(cid:18)(cid:21)(cid:15)(cid:19)(cid:20)(cid:19)(cid:23)(cid:26)
Ruben Torres
Narus, Inc.
PI:EMAIL
Sabyasachi Saha
Narus, Inc.
PI:EMAIL
Christopher Kruegel
UC Santa Barbara
PI:EMAIL
Giovanni Vigna
UC Santa Barbara
PI:EMAIL
I.
INTRODUCTION
Malware is one of the most severe security threats on the
Internet. Once infected with malicious code, victim machines
become platforms to send email spam messages, launch denial-
of-service attacks, and steal sensitive user data.
A key challenge for attackers is to install their malware
programs on as many victim machines as possible. One ap-
proach is to rely on social engineering: for example, attackers
might send email messages that entice users to install attached
malware programs. While this technique works, it requires the
cooperation of victim users, and hence is often ineffective. An
alternative, and more effective, approach is to lure users onto
web pages that launch exploits against vulnerabilities in web
browsers (or their components, such as the PDF reader or the
Flash player). In this case, no user interactions are required,
and the malware is surreptitiously installed and launched on
the victim’s machine. The effectiveness and stealthiness of
drive-by downloads have made them the preferred vehicle for
attackers to spread their malware, and they are the focus of
the work presented in this paper.
The infection process in a drive-by download attack can be
divided into three phases. During the ﬁrst phase (the exploita-
tion phase), the goal of the attacker is to run a small snippet of
code (shellcode) on the victim’s host. To this end, the attacker
ﬁrst prepares a website with drive-by download exploit code.
When a victim visits a malicious page, the browser fetches
and executes the drive-by code. When the exploit is successful,
it forces the browser to execute the injected shellcode. In the
subsequent second phase (the installation phase), the shellcode
downloads the actual malware binary and launches it. Once
the malware program is running, during the third phase (the
control phase), it unfolds its malicious activity. Typically, the
malware connects back to a remote command and control
(C&C) server. This connection is used by attackers to issue
commands, to “drop” new executables onto the infected host
to enhance the malware’s functionality, and receive stolen data.
Most current techniques protecting users against malware
focus on the ﬁrst and the third phases. A large body of
work targets the initial exploitation phase, trying to detect
pages that contain drive-by download exploits and prevent
browsers from visiting a malicious page in the ﬁrst place. For
example, honeyclients crawl the web to quickly ﬁnd pages
with exploit code, and turn these ﬁndings into domain and
URL blacklists. Attackers have responded by quickly rotating
through malicious domains, making blacklists perpetually out-
of-date. Also, attackers have started to aggressively ﬁngerprint
honeyclients and obfuscate their code to avoid detection [1].
Another large body of work focuses on the control phase,
attempting to identify the execution of malicious code on the
end host. Antivirus (AV) programs are probably the main line
of defense that is employed by most users. AV software relies
mostly on signatures to detect malicious programs when they
are stored to disk or executed. Unfortunately, these programs
are seeing diminishing returns in successful detections [2], as
malware writers modify their programs to avoid detection [3].
Researchers have also developed solutions that use signatures
or reputation-based systems to identify and block the directives
that the malware distributor issues to the infected hosts after
a successful infection. Attackers have reacted by encrypting
their communication channels and even using steganographic
techniques to make their command and control (C&C) trafﬁc
appear legitimate.
So far, little attention has been paid to the installation
phase. At ﬁrst glance, this makes sense as in the installation
phase, the shellcode typically issues an HTTP request that
fetches a program from a remote server, and then installs
and executes the malware locally. Often, this request is done
by simply invoking available functions in the user’s browser.
From the network point of view, such connections are hardly
suspicious, and look essentially identical to legitimate requests
performed by users who download benign programs (e.g.,
updates or shareware programs).
However, the situation changes signiﬁcantly when “zoom-
ing out” and leaving the myopic view of individual malware
downloads. Instead, when considering many malware down-
loads together – performed by different hosts, but related
to a single campaign – a malware distribution infrastructure
becomes visible. In some sense,
this malware distribution
infrastructure acts like a content distribution network. How-
ever, there are also differences, and these differences can be
leveraged to identify cases where malicious content (malware
programs) are distributed.
We present Nazca, a system that aims to detect web
requests that are used to download malware binaries. Similar to
the drawings in the Nazca desert, the malware downloads (and
the supporting distribution infrastructure) becomes more appar-
ent when observing a larger part of the picture/network. Our
system detects these large-scale traits of malware distribution
networks. Thus, it is designed to operate in large-scale net-
works, such as Internet Service Providers (ISPs), large enter-
prise networks, and universities. Moreover, our system focuses
on malware downloaded through HTTP requests. This design
choice is driven by the observation that an overwhelming
majority of drive-by exploits use the web to download malware
binaries. Finally, Nazca does not perform any analysis of the
content of web downloads, except for extracting their MIME
type. That is, we do not apply any signatures to the network
payload, do not look at features of the downloaded programs,
and do not consider the reputation of the programs’ sources.
This allows us to identify the downloads of previously-unseen
malicious software, enabling zero-day malware detection.
Our system monitors web trafﬁc between a set of hosts
(typically, machines in the protected network) and the Internet.
The goal is to identify the connections that are related to
malware downloads. To this end, Nazca operates in three
steps: In the ﬁrst step, the system identiﬁes HTTP requests
and extracts metadata for subsequent analysis. This metadata
includes information on the connection endpoints, the URIs,
and whether an executable program is being downloaded.
In the second step, Nazca identiﬁes suspicious web con-
nections whose HTTP requests download an executable ﬁle.
There are certain properties associated with the connection
that make it appear different from legitimate downloads. These
properties are designed to capture techniques employed by
malware authors to hide their operations from traditional
defense systems. Such evasive techniques include domain
ﬂuxing, malware repackaging, and the use of malware droppers
for multi-step installations. An interesting and favorable trait
of our approach is that it complements well to the existing
detection mechanisms. That is, when malware authors employ
techniques to evade traditional approaches (such as malware
signatures or IP/domain reputation systems), their downloads
are easier to recognize for Nazca.
In the third step, Nazca aggregates the previously-identiﬁed
suspicious connections (candidates). The goal is to ﬁnd related,
malicious activity so as to reduce potential false positives and
focus the attention on the most signiﬁcant infection events.
Here, we build a graph of the malicious activities that Nazca
detected. This enables the reconstruction and observation of
entire malware distribution networks.
We have evaluated Nazca’s effectiveness on a one-week
trafﬁc dataset from a commercial ISP. Our results show that
Nazca is effective in detecting malicious web downloads in
large-scale, real-world networks.
The main contributions of this paper are as follows:
• We present a novel approach to identify web requests
related to malware downloads and installations. Our
system operates in large networks, and identiﬁes traits
of orchestrated malware distribution networks. Since
our approach does not analyze the downloaded pro-
grams, Nazca can identify unseen-before malware, and
is not defeated by content obfuscation.
• We introduce a three-step process to detect malware
downloads. First, we extract a short summary of
HTTP requests metadata. We then identify suspicious
candidate connections that exhibit features that are
anomalous for benign downloads. These features cap-
ture evasive attempts of malware authors to avoid
detection by traditional defense systems. Last, we
combine candidates to identify clusters of malicious
activity.
Using seven days of trafﬁc from a commercial ISP, we
evaluate the effectiveness of our system to detect mal-
ware downloads, and we compare this effectiveness to
popular blacklists.
•
II. APPROACH
Nazca aims at identifying HTTP connections downloading
malicious software. Our system is designed to operate in large-
2
scale networks, such as ISPs, large enterprise networks, and
universities. That is, we assume that our system is positioned
at a vantage point where it can observe the trafﬁc between a
large set of hosts and the Internet. In Section VII-D, we explore
in more detail how many hosts Nazca needs to observe to be
effective.
The ability to monitor the web trafﬁc from larger number
of machines provides the key advantage that our system can
see – and correlate – multiple malware downloads related to a
speciﬁc campaign. This is crucial, since we do not analyze the
downloaded binaries or take into account the reputation of the
source of the download. Attackers have signiﬁcant freedom in
crafting their malware programs, and have long used packers
and code obfuscation to limit the utility of traditional AV
signatures. Malware authors can also use different IPs and
domains to serve their software. As a result, blacklists and
domain reputation systems naturally lag behind and suffer
from limited coverage. By ignoring features that attackers
can easily change, and instead focusing on properties of the
malware distribution infrastructure, Nazca has the ability to
detect previously-unseen, malicious code.
Nazca inspects only IP and TCP packets headers, HTTP
headers, and a small portion of HTTP responses. We limit
Nazca’s analysis to HTTP trafﬁc because we observed that it
is the protocol of choice for the vast majority of malware in
current circulations (see Section VII-A for details). One reason
for distributing malware via HTTP is that it is typically allowed
through corporate ﬁrewalls. When attackers implement custom
protocols to download their binaries, the risk is higher that
application-aware ﬁrewalls would simply drop the trafﬁc (and
hence, block the infection).
The payload analysis of an HTTP response is limited to
detecting the MIME type of the content that the web server
returns and calculating a hash of (the beginning of) it. We
need to determine the MIME type of the server response to
distinguish between program (binary) downloads and other,
irrelevant content (such as web pages,
images, etc.). We
compute the hash over the ﬁrst portion of a program download
to determine whether two programs are (likely) identical or
different. Since we do not
inspect properties of the code
that is being downloaded, but instead focus solely on the
malware distribution infrastructure, Nazca has the ability to
detect previously-unseen (zero-day) malware programs.
The following sections discuss the main steps of Nazca in
more detail.
III. EXTRACTION
During the extraction step, Nazca analyzes network trafﬁc
by recording live packets on the wire or reading the PCAP
ﬁles. The goal of this step is to extract a metadata record for
each connection of interest. Nazca extracts a record for each
HTTP connection that initiates a download of a ﬁle whose
MIME type is not in our whitelist (MIME types of popular
formats for images, videos, audio, and other innocuous ﬁles).
More speciﬁcally, Nazca reassembles packets and aggre-
gates them into streams. For performance reasons, we do not
reassemble the complete stream, but just enough to perform
protocol detection. We discard any stream that does not contain
HTTP requests or responses. Whenever we ﬁnd an HTTP
request, we analyze the corresponding answer from the server.
In particular, we are interested in determining the MIME type
of the object that the server returns. To this end, we do not
trust the server HTTP Content-Type header, as we have
found it to be often misleading. Instead, we perform a quick
Content-Type snifﬁng with libmagick (the library that
powers the file command in GNU/Linux). We also attempt
to decompress payloads zipped with popular protocols (such
as zip, gzip, bzip2, etc.).
Whenever our analysis recognizes that a downloaded ﬁle’s
MIME type is not whitelisted, we record the following in-
formation: source (client) and destination (server) IP address
and port, URI that the client requests (everything, including
parameters), the value of the User-Agent HTTP header
ﬁeld, and a content hash of the uncompressed ﬁrst k bytes at
the beginning of the ﬁle. k is a conﬁgurable value that should
be large enough to minimize collisions, without sacriﬁcing
performance (see [4]). In this paper, we use the ﬁrst kilobyte.
The records that correspond to interesting connections can
be recorded in real-time, as soon as the information is avail-
able. In a typical network, the amount of data that is collected
in this fashion is very small (compared to the data volume
on the wire). Hence, we do not expect any scalability issues,
even for very large networks. For example, in Section VII-E,
we show that we need to store only 286 KB of metadata per
client per day. Since our default time window is typically less
than a day, old data can be discarded.
IV. CANDIDATE SELECTION
Nazca works by correlating information from multiple
connections. In the candidate selection step, Nazca considers
the set of all metadata records that are captured during a
certain time period T . One can run the candidate selection
step periodically, analyzing the connections in chunks of T .
Alternatively, one could keep a sliding window of length T .
The goal of this step is to produce a candidate set that contains
suspicious connections. These candidates are connections that
exhibit behavior that is typically associated with malicious