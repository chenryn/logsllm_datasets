---
author: Lorenzo Fontana
category: 容器与云
comments_data:
- date: '2017-01-22 15:29:56'
  message: 您好，现在我们已经做到开始收集容器及应用日志，因为日志量过大现在还没有一个方案，您那边这两个日志收集是怎么做的
  postip: 121.69.29.10
  username: 来自北京的 Chrome 54.0|Mac 10.11 用户
count:
  commentnum: 1
  favtimes: 1
  likes: 0
  sharetimes: 0
  viewnum: 10648
date: '2016-10-06 08:05:00'
editorchoice: false
excerpt: 如果你正在运行 Swarm 模式的集群，或者只运行单台 Docker，你都会有下面的疑问：我如何才能监控到它们都在干些什么？
fromurl: https://blog.codeship.com/monitoring-docker-containers-with-elasticsearch-and-cadvisor/
id: 7834
islctt: true
largepic: /data/attachment/album/201610/05/211233tabbmh8bjt5jjpw5.png
permalink: /article-7834-1.html
pic: /data/attachment/album/201610/05/211233tabbmh8bjt5jjpw5.png.thumb.jpg
related: []
reviewer: ''
selector: ''
summary: 如果你正在运行 Swarm 模式的集群，或者只运行单台 Docker，你都会有下面的疑问：我如何才能监控到它们都在干些什么？
tags:
- Docker
- 容器
- 监控
thumb: false
title: 使用 Elasticsearch 和 cAdvisor 监控 Docker 容器
titlepic: true
translator: bazz2
updated: '2016-10-06 08:05:00'
---
如果你正在运行 Swarm 模式的集群，或者只运行单台 Docker，你都会有下面的疑问：
> 
> 我如何才能监控到它们都在干些什么？
> 
> 
> 
这个问题的答案是“很不容易”。
![](/data/attachment/album/201610/05/211233tabbmh8bjt5jjpw5.png)
你需要监控下面的参数：
1. 容器的数量和状态。
2. 一台容器是否已经移到另一个节点了，如果是，那是在什么时候，移动到哪个节点？
3. 给定节点上运行着的容器数量。
4. 一段时间内的通信峰值。
5. 孤儿卷和网络（LCTT 译注：孤儿卷就是当你删除容器时忘记删除它的卷，这个卷就不会再被使用，但会一直占用资源）。
6. 可用磁盘空间、可用 inode 数。
7. 容器数量与连接在 `docker0` 和 `docker_gwbridge` 上的虚拟网卡数量不一致（LCTT 译注：当 docker 启动时，它会在宿主机器上创建一个名为 docker0 的虚拟网络接口）。
8. 开启和关闭 Swarm 节点。
9. 收集并集中处理日志。
本文的目标是介绍 [Elasticsearch](https://github.com/elastic/elasticsearch) + [Kibana](https://github.com/elastic/kibana) + [cAdvisor](https://github.com/google/cadvisor) 的用法，使用它们来收集 Docker 容器的参数，分析数据并产生可视化报表。
阅读本文后你可以发现有一个监控仪表盘能够部分解决上述列出的问题。但如果只是使用 cAdvisor，有些参数就无法显示出来，比如 Swarm 模式的节点。
如果你有一些 cAdvisor 或其他工具无法解决的特殊需求，我建议你开发自己的数据收集器和数据处理器（比如 [Beats](https://github.com/elastic/beats)），请注意我不会演示如何使用 Elasticsearch 来集中收集 Docker 容器的日志。
> 
> [“你要如何才能监控到 Swarm 模式集群里面发生了什么事情？要做到这点很不容易。” —— @fntlnz](https://twitter.com/share?text=%22How+do+you+keep+track+of+all+that%27s+happening+in+a+Swarm+Mode+cluster%3F+Not+easily.%22+via+%40fntlnz&url=https://blog.codeship.com/monitoring-docker-containers-with-elasticsearch-and-cadvisor/)
> 
> 
> 
### 我们为什么要监控容器？
想象一下这个经典场景：你在管理一台或多台虚拟机，你把 tmux 工具用得很溜，用各种 session 事先设定好了所有基础的东西，包括监控。然后生产环境出问题了，你使用 `top`、`htop`、`iotop`、`jnettop` 各种 top 来排查，然后你准备好修复故障。
现在重新想象一下你有 3 个节点，包含 50 台容器，你需要在一个地方查看整洁的历史数据，这样你知道问题出在哪个地方，而不是把你的生命浪费在那些字符界面来赌你可以找到问题点。
### 什么是 Elastic Stack ？
Elastic Stack 就一个工具集，包括以下工具：
* Elasticsearch
* Kibana
* Logstash
* Beats
我们会使用其中一部分工具，比如使用 Elasticsearch 来分析基于 JSON 格式的文本，以及使用 Kibana 来可视化数据并产生报表。
另一个重要的工具是 [Beats](https://github.com/elastic/beats)，但在本文中我们还是把精力放在容器上，官方的 Beats 工具不支持 Docker，所以我们选择原生兼容 Elasticsearch 的 cAdvisor。
[cAdvisor](https://github.com/google/cadvisor) 工具负责收集、整合正在运行的容器数据，并导出报表。在本文中，这些报表被到入到 Elasticsearch 中。
cAdvisor 有两个比较酷的特性：
* 它不只局限于 Docker 容器。
* 它有自己的 Web 服务器，可以简单地显示当前节点的可视化报表。
### 设置测试集群，或搭建自己的基础架构
和我[以前的文章](https://blog.codeship.com/nginx-reverse-proxy-docker-swarm-clusters/)一样，我习惯提供一个简单的脚本，让读者不用花很多时间就能部署好和我一样的测试环境。你可以使用以下（非生产环境使用的）脚本来搭建一个 Swarm 模式的集群，其中一个容器运行着 Elasticsearch。
> 
> 如果你有充足的时间和经验，你可以 搭建自己的基础架构   （    Bring Your Own Infrastructure，BYOI    ） 。
> 
> 
> 
如果要继续阅读本文，你需要：
* 运行 Docker 进程的一个或多个节点（docker 版本号大于等于 1.12）。
* 至少有一个独立运行的 Elasticsearch 节点（版本号 2.4.X）。
重申一下，此 Elasticsearch 集群环境不能放在生产环境中使用。生产环境也不推荐使用单节点集群，所以如果你计划安装一个生产环境，请参考 [Elastic 指南](https://www.elastic.co/guide/en/elasticsearch/guide/2.x/deploy.html)。
### 对喜欢尝鲜的用户的友情提示
我就是一个喜欢尝鲜的人（当然我也已经在生产环境中使用了最新的 alpha 版本），但是在本文中，我不会使用最新的 Elasticsearch 5.0.0 alpha 版本，我还不是很清楚这个版本的功能，所以我不想成为那个引导你们出错的关键。
所以本文中涉及的 Elasticsearch 版本为最新稳定版 2.4.0。
### 测试集群部署脚本
前面已经说过，我提供这个脚本给你们，让你们不必费神去部署 Swarm 集群和 Elasticsearch，当然你也可以跳过这一步，用你自己的 Swarm 模式引擎和你自己的 Elasticserch 节点。
执行这段脚本之前，你需要：
* [Docker Machine](https://docs.docker.com/machine/install-machine/) – 最终版：在 DigitalOcean 中提供 Docker 引擎。
* [DigitalOcean API Token](https://cloud.digitalocean.com/settings/api/tokens/new): 让 docker 机器按照你的意思来启动节点。
![](/data/attachment/album/201610/05/211255f31k8ir3t81p4w3n.png)
### 创建集群的脚本
现在万事俱备，你可以把下面的代码拷到 create-cluster.sh 文件中：
```
#!/usr/bin/env bash
#
# Create a Swarm Mode cluster with a single master and a configurable number of workers
workers=${WORKERS:-"worker1 worker2"}
#######################################
# Creates a machine on Digital Ocean
# Globals:
#   DO_ACCESS_TOKEN The token needed to access DigitalOcean's API
# Arguments:
#   $1 the actual name to give to the machine
#######################################
create_machine() {
  docker-machine create \
    -d digitalocean \
    --digitalocean-access-token=$DO_ACCESS_TOKEN \
    --digitalocean-size 2gb \
    $1
}
#######################################
# Executes a command on the specified machine
# Arguments:
#   $1     The machine on which to run the command
#   $2..$n The command to execute on that machine
#######################################
machine_do() {
  docker-machine ssh $@
}
main() {
  if [ -z "$DO_ACCESS_TOKEN" ]; then
    echo "Please export a DigitalOcean Access token: https://cloud.digitalocean.com/settings/api/tokens/new"
    echo "export DO_ACCESS_TOKEN="
    exit 1
  fi
  if [ -z "$WORKERS" ]; then
    echo "You haven't provided your workers by setting the \$WORKERS environment variable, using the default ones: $workers"
  fi
  # Create the first and only master
  echo "Creating the master"
  create_machine master1
  master_ip=$(docker-machine ip master1)
  # Initialize the swarm mode on it
  echo "Initializing the swarm mode"
  machine_do master1 docker swarm init --advertise-addr $master_ip
  # Obtain the token to allow workers to join
  worker_tkn=$(machine_do master1 docker swarm join-token -q worker)
  echo "Worker token: ${worker_tkn}"
  # Create and join the workers
  for worker in $workers; do
    echo "Creating worker ${worker}"
    create_machine $worker
    machine_do $worker docker swarm join --token $worker_tkn $master_ip:2377
  done
}
main $@
```
赋予它可执行权限：
```
chmod +x create-cluster.sh
```
### 创建集群
如文件名所示，我们可以用它来创建集群。默认情况下这个脚本会创建一个 master 和两个 worker，如果你想修改 worker 个数，可以设置环境变量 WORKERS。
现在就来创建集群吧。
```
./create-cluster.sh
```
你可以出去喝杯咖啡，因为这需要花点时间。
最后集群部署好了。
![](/data/attachment/album/201610/05/211258k1j9q19nj6p5u716.png)
现在为了验证 Swarm 模式集群已经正常运行，我们可以通过 ssh 登录进 master：
```
docker-machine ssh master1
```
然后列出集群的节点：
```
docker node ls
```
```
ID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS
26fi3wiqr8lsidkjy69k031w2 *  master1   Ready   Active        Leader
dyluxpq8sztj7kmwlzs51u4id    worker2   Ready   Active
epglndegvixag0jztarn2lte8    worker1   Ready   Active
```
### 安装 Elasticsearch 和 Kibana
> 
> 注意，从现在开始所有的命令都运行在主节点 master1 上。
> 
> 
> 
在生产环境中，你可能会把 Elasticsearch 和 Kibana 安装在一个单独的、[大小合适](https://www.elastic.co/blog/found-sizing-elasticsearch)的实例集合中。但是在我们的实验中，我们还是把它们和 Swarm 模式集群安装在一起。