able alerting configured?
The checklist may also include operational standards and best practices followed by a
specific SRE team. For example, a perfectly functional service configuration that
doesn’t follow an SRE team’s “gold standard” might be refactored to work better with
SRE tools for scalably managing configurations. SREs also look at recent incidents
and postmortems for the service, as well as follow-up tasks for the incidents. This
evaluation gauges the demands of emergency response for the service and the availa‐
bility of well-established operational controls.
Improvements and Refactoring
The Analysis phase leads to the identification of recommended improvements for the
service. This next phase proceeds as follows:
1. Improvements are prioritized based upon importance for service reliability.
2. The priorities are discussed and negotiated with the development team, and a
plan of execution is agreed upon.
3. Both SRE and product development teams participate and assist each other in
refactoring parts of the service or implementing additional features.
This phase typically varies the most in duration and amount of effort. How much
time and effort this phase will involve depends upon the availability of engineering
time for refactoring, the maturity and complexity of the service at the start of the
review, and myriad other factors.
446 | Chapter 32: The Evolving SRE Engagement Model
Training
Responsibility for managing a service in production is generally assumed by an entire
SRE team. To ensure that the team is prepared, the SRE reviewers who led the PRR
take ownership of training the team, which includes the documentation necessary to
support the service. Typically with the help and participation of the development
team, these engineers organize a series of training sessions and exercises. Instruction
can include:
• Design overviews
• Deep dives on various request flows in the system
• A description of the production setup
• Hands-on exercises for various aspects of system operations
When the training is concluded, the SRE team should be prepared to manage the ser‐
vice.
Onboarding
The Training phase unblocks onboarding of the service by the SRE team. It involves a
progressive transfer of responsibilities and ownership of various production aspects
of the service, including parts of operations, the change management process, access
rights, and so forth. The SRE team continues to focus on the various areas of produc‐
tion mentioned earlier. To complete the transition, the development team must be
available to back up and advise the SRE team for a period of time as it settles in man‐
aging production for the service. This relationship becomes the basis for the ongoing
work between the teams.
Continuous Improvement
Active services continuously change in response to new demands and conditions,
including user requests for new features, evolving system dependencies, and technol‐
ogy upgrades, in addition to other factors. The SRE team must maintain service relia‐
bility standards in the face of these changes by driving continuous improvement. The
responsible SRE team naturally learns more about the service in the course of operat‐
ing the service, reviewing new changes, responding to incidents, and especially when
conducting postmortems/root cause analyses. This expertise is shared with the devel‐
opment team as suggestions and proposals for changes to the service whenever new
features, components, and dependencies may be added to the service. Lessons from
managing the service are also contributed to best practices, which are documented in
the Production Guide and elsewhere.
Production Readiness Reviews: Simple PRR Model | 447
Engaging with Shakespeare
Initially, the developers of the Shakespeare service were responsible for the product,
including carrying the pager for emergency response. However, with growing use of
the service and the growth of the revenue coming from the service, SRE support
became desirable. The product has already been launched, so SRE conducted a Pro‐
duction Readiness Review. One of the things they found was that the dashboards were
not completely covering some of the metrics defined in the SLO, so that needed to be
fixed. After all the issues that had been filed had been fixed, SRE took over the pager
for the service, though two developers were in the on-call rotation as well. The devel‐
opers are participating in the weekly on-call meeting discussing last week’s problems
and how to handle upcoming large-scale maintenance or cluster turndowns. Also
future plans for the service are now discussed with the SREs to make sure that new
launches will go flawlessly (though Murphy’s law is always looking for opportunities
to spoil that).
Evolving the Simple PRR Model: Early Engagement
Thus far, we’ve discussed the Production Readiness Review as it’s used in the Simple
PRR Model, which is limited to services that have already entered the Launch phase.
There are several limitations and costs associated with this model. For example:
• Additional communication between teams can increase some process overhead
for the development team, and cognitive burden for the SRE reviewers.
• The right SRE reviewers must be available, and capable of managing their time
and priorities with regards to their existing engagements.
• Work done by SREs must be highly visible and sufficiently reviewed by the devel‐
opment team to ensure effective knowledge sharing. SREs should essentially
work as a part of the development team, rather than an external unit.
However, the main limitations of the PRR Model stem from the fact that the service is
launched and serving at scale, and the SRE engagement starts very late in the devel‐
opment lifecycle. If the PRR occurred earlier in the service lifecycle, SRE’s opportu‐
nity to remedy potential issues in the service would be markedly increased. As a
result, the success of the SRE engagement and the future success of the service itself
would likely improve. The resulting drawbacks can pose a significant challenge to the
success of the SRE engagement and the future success of the service itself.
448 | Chapter 32: The Evolving SRE Engagement Model
Candidates for Early Engagement
The Early Engagement Model introduces SRE earlier in the development lifecycle in
order to achieve significant additional advantages. Applying the Early Engagement
Model requires identifying the importance and/or business value of a service early in
the development lifecycle, and determining if the service will have sufficient scale or
complexity to benefit from SRE expertise. Applicable services often have the follow‐
ing characteristics:
• The service implements significant new functionality and will be part of an exist‐
ing system already managed by SRE.
• The service is a significant rewrite or alternative to an existing system, targeting
the same use cases.
• The development team sought SRE advice or approached SRE for takeover upon
launch.
The Early Engagement Model essentially immerses SREs in the development process.
SRE’s focus remains the same, though the means to achieve a better production ser‐
vice are different. SRE participates in Design and later phases, eventually taking over
the service any time during or after the Build phase. This model is based on active
collaboration between the development and SRE teams.
Benefits of the Early Engagement Model
While the Early Engagement Model does entail certain risks and challenges discussed
previously, additional SRE expertise and collaboration during the entire lifecycle of
the product creates significant benefits compared to an engagement initiated later in
the service lifecycle.
Design phase
SRE collaboration during the Design phase can prevent a variety of problems or inci‐
dents from occurring later in production. While design decisions can be reversed or
rectified later in the development lifecycle, such changes come at a high cost in terms
of effort and complexity. The best production incidents are those that never happen!
Occasionally, difficult trade-offs lead to the selection of a less-than-ideal design. Par‐
ticipation in the Design phase means that SREs are aware up front of the trade-offs
and are part of the decision to pick a less-than-ideal option. Early SRE involvement
aims to minimize future disputes over design choices once the service is in produc‐
tion.
Evolving the Simple PRR Model: Early Engagement | 449
Build and implementation
The Build phase addresses production aspects such as instrumentation and metrics,
operational and emergency controls, resource usage, and efficiency. During this
phase, SRE can influence and improve the implementation by recommending specific
existing libraries and components, or helping build certain controls into the system.
SRE participation at this stage helps enable ease of operations in the future and allows
SRE to gain operational experience in advance of the launch.
Launch
SRE can also help implement widely used launch patterns and controls. For example,
SRE might help implement a “dark launch” setup, in which part of the traffic from
existing users is sent to the new service in addition to being sent to the live produc‐
tion service. The responses from the new service are “dark” since they are thrown
away and not actually shown to users. Practices such as dark launches allow the team
to gain operational insight, resolve issues without impacting existing users, and
reduce the risk of encountering issues after launch. A smooth launch is immensely
helpful in keeping the operational burden low and maintaining the development
momentum after the launch. Disruptions around launch can easily result in emer‐
gency changes to source code and production, and disrupt the development team’s
work on future features.
Post-launch
Having a stable system at launch time generally leads to fewer conflicting priorities
for the development team in terms of choosing between improving service reliability
versus adding new features. In later phases of the service, the lessons from earlier
phases can better inform refactoring or redesign.
With extended involvement, the SRE team can be ready to take over the new service
much sooner than is possible with the Simple PRR Model. The longer and closer
engagement between the SRE and development teams also creates a collaborative
relationship that can be sustained long term. A positive cross-team relationship fos‐
ters a mutual feeling of solidarity, and helps SRE establish ownership of the produc‐
tion responsibility.
Disengaging from a service
Sometimes a service doesn’t warrant full-fledged SRE team management—this deter‐
mination might be made post-launch, or SRE might engage with a service but never
officially take it over. This is a positive outcome, because the service has been engi‐
neered to be reliable and low maintenance, and can therefore remain with the devel‐
opment team.
450 | Chapter 32: The Evolving SRE Engagement Model
It is also possible that SRE engages early with a service that fails to meet the levels of
usage projected. In such cases, the SRE effort spent is simply part of the overall busi‐
ness risk that comes with new projects, and a small cost relative to the success of
projects that meet expected scale. The SRE team can be reassigned, and lessons
learned can be incorporated into the engagement process.
Evolving Services Development: Frameworks and SRE
Platform
The Early Engagement Model made strides in evolving SRE engagement beyond the
Simple PRR Model, which applied only to services that had already launched. How‐
ever, there was still progress to be made in scaling SRE engagement to the next level
by designing for reliability.
Lessons Learned
Over time, the SRE engagement model described thus far produced several distinct
patterns:
• Onboarding each service required two or three SREs and typically lasted two or
three quarters. The lead times for a PRR were relatively high (quarters away). The
effort level required was proportional to the number of services under review,
and was constrained by the insufficient number of SREs available to conduct
PRRs. These conditions led to serialization of service takeovers and strict service
prioritization.
• Due to differing software practices across services, each production feature was
implemented differently. To meet PRR-driven standards, features usually had to
be reimplemented specifically for each service or, at best, once for each small sub‐
set of services sharing code. These reimplementations were a waste of engineer‐
ing effort. One canonical example is the implementation of functionally similar
logging frameworks repeatedly in the same language because different services
didn’t implement the same coding structure.
• A review of common service issues and outages revealed certain patterns, but
there was no way to easily replicate fixes and improvements across services. Typi‐
cal examples included service overload situations and data hot-spotting.
• SRE software engineering contributions were often local to the service. Thus,
building generic solutions to be reused was difficult. As a consequence, there was
no easy way to implement new lessons individual SRE teams learned and best
practices across services that had already been onboarded.
Evolving Services Development: Frameworks and SRE Platform | 451
External Factors Affecting SRE
External factors have traditionally pressured the SRE organization and its resources
in several ways.
Google is increasingly following the industry trend of moving toward microservices.1
As a result, both the number of requests for SRE support and the cardinality of serv‐
ices to support have increased. Because each service has a base fixed operational cost,
even simple services demand more staffing. Microservices also imply an expectation
of lower lead time for deployment, which was not possible with the previous PRR
model (which had a lead time of months).
Hiring experienced, qualified SREs is difficult and costly. Despite enormous effort
from the recruiting organization, there are never enough SREs to support all the serv‐
ices that need their expertise. Once SREs are hired, their training is also a lengthier
process than is typical for development engineers.
Finally, the SRE organization is responsible for serving the needs of the large and
growing number of development teams that do not already enjoy direct SRE support.
This mandate calls for extending the SRE support model far beyond the original con‐
cept and engagement model.
Toward a Structural Solution: Frameworks
To effectively respond to these conditions, it became necessary to develop a model
that allowed for the following principles:
Codified best practices
The ability to commit what works well in production to code, so services can
simply use this code and become “production ready” by design.
Reusable solutions
Common and easily shareable implementations of techniques used to mitigate
scalability and reliability issues.
A common production platform with a common control surface
Uniform sets of interfaces to production facilities, uniform sets of operational
controls, and uniform monitoring, logging, and configuration for all services.
Easier automation and smarter systems
A common control surface that enables automation and smart systems at a level
not possible before. For example, SREs can readily receive a single view of
1 See the Wikipedia page on microservices at http://en.wikipedia.org/wiki/Microservices.
452 | Chapter 32: The Evolving SRE Engagement Model
relevant information for an outage, rather than hand collecting and analyzing
mostly raw data from disparate sources (logs, monitoring data, and so on).
Based upon these principles, a set of SRE-supported platform and service frameworks
were created, one for each environment we support (Java, C++, Go). Services built
using these frameworks share implementations that are designed to work with the
SRE-supported platform, and are maintained by both SRE and development teams.
The main shift brought about by frameworks was to enable product development
teams to design applications using the framework solution that was built and blessed
by SRE, as opposed to either retrofitting the application to SRE specifications after
the fact, or retrofitting more SREs to support a service that was markedly different
than other Google services.
An application typically comprises some business logic, which in turn depends on
various infrastructure components. SRE production concerns are largely focused on
the infrastructure-related parts of a service. The service frameworks implement infra‐
structure code in a standardized fashion and address various production concerns.
Each concern is encapsulated in one or more framework modules, each of which pro‐
vides a cohesive solution for a problem domain or infrastructure dependency. Frame‐
work modules address the various SRE concerns enumerated earlier, such as:
• Instrumentation and metrics
• Request logging
• Control systems involving traffic and load management
SRE builds framework modules to implement canonical solutions for the concerned
production area. As a result, development teams can focus on the business logic,
because the framework already takes care of correct infrastructure use.
A framework essentially is a prescriptive implementation for using a set of software
components and a canonical way of combining these components. The framework
can also expose features that control various components in a cohesive manner. For
example, a framework might provide the following:
• Business logic organized as well-defined semantic components that can be refer‐
enced using standard terms
• Standard dimensions for monitoring instrumentation
• A standard format for request debugging logs
• A standard configuration format for managing load shedding
• Capacity of a single server and determination of “overload” that can both use a
semantically consistent measure for feedback to various control systems
Evolving Services Development: Frameworks and SRE Platform | 453
Frameworks provide multiple upfront gains in consistency and efficiency. They free
developers from having to glue together and configure individual components in an
ad hoc service-specific manner, in ever-so-slightly incompatible ways, that then have
to be manually reviewed by SREs. They drive a single reusable solution for produc‐
tion concerns across services, which means that framework users end up with the
same common implementation and minimal configuration differences.
Google supports several major languages for application development, and frame‐
works are implemented across all of these languages. While different implementa‐