tripping over cables, replacing the wrong cable or transceiver, or
accidentally powering off equipment).
In CorrOpt, we seek to improve the accuracy of repair by leverag-
ing our observations of the most likely symptoms of corruption root
causes (§4) in terms of optical power levels and the link’s history.
Our strategy is listed in Algorithm 1. It first uses packet corruption
rate on neighboring links to identify shared component failures.
Then it uses TxPower on the opposite side to detect decaying trans-
mitters. CorrOpt uses RxPower to separate optical and non-optical
issues. With non-optical issues, the only solution is to try reseating
the transceiver, and then to replace it.
CorrOpt uses PowerT hr eshRx (PowerT hr eshT x ) per optical tech-
nology as the minimal RxPower (TxPower) threshold. When both
ends of a link have RxPower below PowerT hr eshRx , this suggests
bent or damaged fiber. Connector contamination tends to cause
RxPower to be low in one direction. Cleaning connectors with fiber
cleaning kits can often fix corruption.
CorrOpt’s recommendation engine has been deployed in our
DCNs since October 2016. §7.2 evaluates its effectiveness. In our
experience, machine learning techniques can produce similar repair
accuracy. We choose our approach because it is more intuitive.
6 IMPLEMENTATION
Figure 13 shows the workflow and system components of CorrOpt.
When a switch detects packet corruption, it reports to the CorrOpt
controller. The controller uses the fast checker logic to quickly de-
termine if the link can be safely disabled. If the link is disabled, the
recommendation engine (§5.2) generates a ticket with a suggested
repair procedure, based off the monitoring data (collected by an-
other system). When a link is activated, CorrOpt uses the optimizer
logic to check if any active corrupting links can be disabled.
We prototyped fast checker and optimizer with around 500 lines
of python code. We integrated CorrOpt’s recommendation engine
into the cloud provider’s infrastructure with around 50 lines of C#
code.
Figure 12: An example of unsuccessful repair actions on a
link. (a) A healthy state with corruption loss rate below 10−8.
(b) Starts corrupting packets. (c) Disabled for repair. (d) En-
abled after the repair but starts corrupting packets again. (e)
Disabled again. (f) Enabled after but the repair failed again.
(g) Disabled again for repair, and the repair is finally success-
ful.
optimizer runs in less than one minute on a 1.3 GHz computer with
2 cores.
5.2 Corruption Repair
Simply stated, repairing corruption in today’s DCNs is cumber-
some. Unlike switch configuration errors or congestion, corruption
cannot be remedied via a software-based reaction. For example, as
mentioned in §4, dirt on connectors can cause corruption, and the
only repair is to manually clean the connections. If the root cause
of the corruption is not correctly diagnosed, on-site technicians
must rely on guesswork when deciding what action to take.
Network technicians currently use manual diagnosis. When as-
signed to a ticket, they manually inspect the transceiver and the
fiber to find tight bends or damage. If equipment is not connected
firmly, they reconnect it. If tight bends or damage are found on
the fiber, the technicians replace the fiber. If they cannot find any
problem visually, they may choose to clean the connector with an
optical cleaning kit [30].
If the repair does not address the actual cause of packet corrup-
tion, the link will continue to corrupt packets as soon as the link is
enabled. Figures 7 and 9 show examples of successful repair. In con-
trast, Figure 12 shows a series of two unsuccessful repair attempts.
Both include cleaning the fiber and reseating the transceiver. Fi-
nally, on the third try, the technician replaces the fiber and fixes
the corruption.
This whole process takes several days. In between repair at-
tempts, the link is enabled and a new ticket is generated when it is
disabled again. Generated tickets are placed in a FIFO queue; thus,
the exact time needed for a fix depends on the number of tickets in
the queue. Our analysis of 3400 tickets shows that, on average, it
takes two days for technicians to resolve a ticket; this means, each
failed repair attempt adds two more days during which the link
must be disabled.
Unsuccessful repairs also increase the likelihood of collateral
damage because technicians need to enter the facility more often.
Each entry poses a risk of them affecting something unrelated (e.g.,
(a)(b)(d)(c)(f)(g)(e)SIGCOMM ’17, August 21–25, 2017, Los Angeles, CA, USA
D. Zhuo et al.
Figure 13: CorrOpt’s system components and workflow.
7 EVALUATION
We now evaluate CorrOpt for i) its ability to protect applications
by safely disabling corrupting links, while meeting capacity con-
straints; and ii) its ability to speed repairs by correctly identifying
the root cause. The first evaluation uses simulations based on data
from our DCNs, and the second uses our deployment of CorrOpt’s
repair recommendation engine for three months. We study these
two factors individually in §7.1 and §7.2, and we quantify their
combined impact in §7.3.
7.1 Disabling Links
We simulate the impact of CorrOpt using the topologies and link
corruption traces from two production DCNs, a large DCN with
O(35K) links and a medium-sized DCN with O(15K) links. The trace
period is from Oct to Dec 2016.
We quantify the effectiveness of CorrOpt at disabling links using
is(cid:80)
“total penalty.” Each corrupting link l with corruption rate fl incurs
a penalty of I ( fl ) per second (§5), and the total penalty per second
l ∈links (1 − dl ) × I ( fl ), where dl is 1 if the link is disabled and 0
otherwise. For simplicity, results in this paper use I ( fl ) = fl . Thus,
the total penalty is proportional to corruption losses (assuming
equal utilization on all links).
We compare CorrOpt with “switch-local,” the link disabling tech-
nique used today. As we discussed earlier, for this method to guaran-
√
tee a capacity constraint of c, it should be configured with sc =
c
for three-stage DCNs (which is what we study).
To isolate the impact of link disabling strategy, we couple both
methods with the same repair effectiveness (as CorrOpt’s). When a
link is disabled, it is put into a queue of links that are waiting to
be fixed. Links stay in that queue for two days, the average service
time in our DCNs (§5.2). Based on our observed repair accuracy
(§7.2), 80% of the links are repaired correctly after this time. The
remaining take two rounds of fix, so the overall it takes them four
days to be enabled again.
Figure 14 shows the performance of both methods for the two
DCNs, when the capacity constraint is c=75% for every ToR. The
x-axis is time, and the y-axis is total penalty per second. We see that
the penalty of the switch-local checker is much higher, because of its
sub-optimality that we illustrated earlier. It is flat for switch-local
approach because there is a set of corrupting links switch-level
(a) Medium DCN
(b) Large DCN
Figure 14: Total penalty per second of switch-local and Cor-
rOpt when the capacity constraint is 75% for every ToR.
(a) Medium DCN
(b) Large DCN
Figure 15: Fraction of available paths to the spine for the
worst ToRs when the capacity constraint is 75%.
(a) Medium DCN
(b) Large DCN
Figure 16: Fraction of available paths to the spine for the
worst ToRs when the capacity constraint is 50%.
approach is not able to disable and in our model, they corrupt
packets at constant rates. In contrast, CorrOpt can disable the vast
majority of the corrupting links, leading to a much lower penalty.
The penalty varies with time based on the number and relative
locations of corrupting links in the data.
The inability of the switch-local checker to disable links is visi-
ble in Figures 15 and 16, which show the worst ToR’s fraction of
available paths to the spine when the capacity constraint is 75%
and 50%. When lines overlap, it means for some period of time,
performance of CorrOpt is the same of switch-local check. Over-
all, we see that CorrOpt can hit the capacity limit as needed, but
Understanding and Mitigating Packet Corruption in DCNs
SIGCOMM ’17, August 21–25, 2017, Los Angeles, CA, USA
and estimate the total penalty incurred using fast checker alone
and with the full CorrOpt logic. Figure 18a shows the total penalty
ratio of using CorrOpt versus using fast checker only for a month-
long period. We see most of the time, optimizer does not reduce
penalty. However, during certain periods, it can significantly reduce
corruption losses compared to using fast checker alone. Figure 18b
shows CDF of the average ratio of penalty of CorrOpt over that
with using fast checker alone. Optimizer does not lower the ratio
for 90% of the time. For 7% of the time, optimizer can reduce the
total penalty per second by at least one order of magnitude.
7.2 Accuracy of Repair Recommendations
CorrOpt’s repair recommendation engine has been deployed across
70 DCNs of different sizes since Oct 2016. Because of certain limita-
tions of the current infrastructure, the deployed version is simpler
than the version outlined in §5.2. It uses a single RxPower threshold
rather than customizing it to the links’ optical technology (infor-
mation about which was not readily available), and it does not
consider historical repairs or space locality. As a result of these
simplifications, the results below underestimate the efficacy of our
repair recommendations.
To evaluate CorrOpt, we analyze tickets generated between Oct
22 and Dec 31 2016. In this period, it generated close to two thou-
sand tickets with a repair recommendation. Not all generated tickets
have a repair recommendation because we cannot get optical power
information from all types of switches. We deem repair successful
if we do not see another ticket for the same link within a week.
Because corruption faults are infrequent, if a link experiences cor-
ruption soon after a repaired, it is likely that the repair was not
successful.
Based on this analysis, the success rate of repair was 58.0%, which
is much lower than our expectation. To investigate, we read diaries
of 322 tickets. We found that 30% of the time, technicians were
ignoring the recommendations! Since CorrOpt is newly-deployed,
not all operators have been informed or trained to leverage the
information it provides.
When the technicians followed our recommendation, the success
rate was 80%. In contrast, our analysis of tickets before CorrOpt’s
deployment revealed that the previous repair success rate was 50%.
The higher success rate of CorrOpt implies the links can be put
back into service sooner; at the same time, it reduces the risk of
collateral damage that occurs with each manual intervention.
CorrOpt’s higher accuracy of repair also lowers corruption losses
because that leads to more healthy links in the DCN, which allows
more corrupting links to be disabled while meeting capacity con-
straints. To quantify this effect, we ran simulations similar to those
in the previous section and considered two different repair pro-
cesses. With CorrOpt, 80% the links are repaired in two days and
the rest in four days (i.e., requiring two attempts). Without CorrOpt,
50% of the links are repaired in two days and the rest in four days.
In both cases, CorrOpt’s algorithm was used to disable links.
Figure 19 shows the results for different capacity constraint for
both medium and large DCNs. The penalty is normalized to that
of the setting without CorrOpt. We see that, in addition to their
other benefits, CorrOpt repair recommendations reduce corruption
losses by 30% when the capacity constraint is 75%.
(a) Medium DCN
(b) Large DCN
Figure 17: Total penalty of CorrOpt divided by switch-local
for different capacity constraints.
(a) Penalty Ratio over Time
(b) Penalty Ratio CDF
Figure 18: Gain of optimizer over using fast checker alone in
the large DCN. (a) The ratio of total penalty of CorrOpt (fast
checker + optimizer) divided by using fast checker alone. (b)
The CDF of this ratio over the entire simulation period.
switch-local does not disable enough links even though it is not
limited by the capacity constraint.
Impact of the capacity constraint. The advantage of CorrOpt over
today’s switch-local checks depends on the capacity constraint. If
the constraint is lax, both methods are expected to perform similarly,
as both can turn off almost all corrupting links. However, when the
constraint is more demanding, the intelligent decision making of
CorrOpt begins to shine. For different capacity constraints, Figure 17
shows the total penalty, integrated over time, of CorrOpt divided
by that of the switch-local checker. Since our penalty function is
linear in corruption losses, this ratio represents the reduction in
the amount of corruption losses.
We see that when the capacity constraint is lax (c=25%), as ex-
pected, there is no difference between the two methods. However,
when the capacity constraint is 50% or higher, a more realistic
regime, CorrOpt outperforms the switch-local checker. On the
medium size data center, with a capacity constraint of 50%, CorrOpt
can eliminate almost all corruption while the switch-local check
keeps some corrupting links active. Thus, the total penalty ratio
drops to 0. When the capacity constraint is 75%, CorrOpt’s total
penalty is three to six orders of magnitude lower.
Fast checker vs. optimizer. To isolate the performance gain of
fast checker and optimizer, we simulate the large DCN using fast
checker alone, which is run both when new corrupting links appear
and disabled links are activated. We bin time into one-hour chunks
SIGCOMM ’17, August 21–25, 2017, Los Angeles, CA, USA
D. Zhuo et al.
(a) Medium DCN
(b) Large DCN
Figure 19: CorrOpt’s repair recommendations also help
lower corruption loss. The graph plots the ratio of total
penalty with and without CorrOpt’s recommendation en-
gine.
Figure 20: Example of topology segmentation. The corrupt-
ing links to D affect ToRs G,H, and the leftmost link affects
G, resulting in Segment 1. The corrupting link from A to F
affects ToRs I,J, with the uplinks of I,J only affecting them-
selves respectively, resulting in Seg 2. We can thus optimize
Seg 1 and Seg 2 independently. Pruning shrinks Seg 1,2 fur-
ther, depending on capacity constraints.
7.3 Combined Impact
We conclude by evaluating the combined impact of CorrOpt’s strat-
egy of disabling links and repair recommendations. (Previous sec-
tions studied their impact individually.) We compare it to the current
practice of using switch-local checks to disable links and 50% repair
accuracy.
In terms of reducing packet losses, the results are similar to those
in Figure 17. That is because most of the gain stem from its strategy
for disabling links, though its higher repair accuracy has other
benefits noted above. Overall, in the realistic capacity constraint
regime of 75%, CorrOpt reduces corruption losses by three to six
orders of magnitude.
Finally, we also find that the massive reduction in corruption
losses with CorrOpt does not come at the expense of significantly
reduced network capacity. We measure the average fraction of paths
to the spine available for each ToR when the capacity constraint
is 75%. We find that, compared to the current practice, CorrOpt
reduces this average by at most 0.2% across all one-second time
intervals.
Speeding optimizer with topology segmentation. Our opti-
mizer suffices for today’s DCNs, but it may need to be extended
for larger DCNs or for those with more corrupting links. We can
do so by dividing corrupting links into non-overlapping segments
such that the decision of disabling them is independent of other
segments. Figure 20 shows an example. Such segmentation signifi-
cantly reduces the search space.
Load balancing. CorrOpt disables corrupting links and thus
makes the network topology asymmetric. Advanced network load
balancing is needed when utilization is high or a significant sub-
set of links are off. Standard load balancing techniques [1] work
seamlessly atop CorrOpt. Links taking offline by CorrOpt can be
seen as link failures which is a standard input into load balancing
schemes. Flows on corrupting links have to be re-routed before