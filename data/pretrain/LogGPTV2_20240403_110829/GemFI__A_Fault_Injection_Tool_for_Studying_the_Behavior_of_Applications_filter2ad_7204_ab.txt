thread has activated fault injection, in order to properly set
the core’s pointer to the thread’s ThreadEnabledFault object.
Monitoring context switches allows GemFI to eliminate the
overhead of checking the fault injection status of the executing
thread in the hash table on each simulated clock tick.
Faults are described in the input ﬁle provided by the user at
GemFI command line. The ﬁle is parsed at startup and each
fault is inserted to one of ﬁve internal queues. Each queue
corresponds to a different pipeline stage.
On each simulation tick, GemFI checks if fault injection
has been enabled for the running thread. In such a case,
it prefetches the corresponding ThreadEnabledFault objects.
Then and for each instruction served at a pipeline stage,
GemFI updates the thread’s data and scans the corresponding
queue for faults targeting the executing thread at the speciﬁc
simulation point. Queue entries are sorted according to the
tions from that point on. As a result, the cumulative execution
time of the simulation campaign is signiﬁcantly reduced, as
we demonstrate in Sec. V.
E. Simulation Campaigns on a Network Of Workstations
GemFI is accompanied by a set of shell scripts which
facilitate launching simulation campaigns on a network of
workstations (NoW). The workstations need to share a network
ﬁle-system, in order to store the fault description ﬁles of the
experiments, the simulation checkpoints and the output of each
simulation. The main steps for parallel execution of simulation
campaigns on a NoW are the following:
1) The conﬁguration ﬁles for all experiments are stored on
a network share.
2) A simulation is executed up to the point fault injection is
activated and the simulator process is checkpointed. The
checkpoint is stored to the share.
3) Each workstation gets a local copy of the checkpoint.
4) Each workstation checks the share for experiments to be
executed. It selects one of the remaining experiments and
executes it locally, starting from the checkpointed state.
5) Simulation results are moved from the workstation back
to the network share.
6) Steps 4-6 are repeated until there are no experiments left.
IV. VALIDATION
In order to validate the functional correctness of GemFI,
we conducted an experimental study using a set of benchmark
applications. Our simulator system was set
to simulate a
single core ALPHA CPU coupled with a tournament branch
predictor, a L1 instruction cache and a L1 data cache and as
a L2 cache we used a uniﬁed L2 cache.
DCT,
is a kernel of JPEG image compression and de-
compression [4]. We applied each kernel on a gray-scale
512X512 image. Jacobi is applied on a diagonally dominant
64X64 matrix. Monte Carlo PI estimates the value of PI
by randomly selecting 105 points within a unit square and
evaluating whether they fall into the inscribed into a circle with
radius one. Knapsack is a solution of the zero one knapsack
combinational problem using a genetic algorithm. We use an
input of 24 items and a weight limit of 500. The Deblocking
ﬁlter is a kernel of the AVS video decoding process [5]. We
apply it on a 720X240 pixel image. Canneal is a benchmark
of the PARSEC Benchmark Suite [6]. Canneal employs an
annealing (SA) algorithm to minimize the routing cost of a
chip design by randomly swapping netlist elements. It was
applied on 100 nets, allowing up to 100 swaps in each step.
The number of executions of each application for every
experiment varied from 2501 to 2504 and has been calculated
using the method presented in [7], setting 99% as a target
conﬁdence level and 1% as the error margin.
A. Experimental Validation in the Absense of Faults
The execution of each application was simulated both with
our tool and the original Gem5 simulator. When simulating
using GemFI we did not inject any faults. We then compared
625
Fig. 3: Simple checkpoint-restore mechanism to speedup sim-
ulation campaigns.
timing of each fault. If such a fault is found, the value of the
targeted location is corrupted according to fault’s behavior.
D. Simulation Checkpointing
Checkpointing allows saving the state of a process or a
system at a speciﬁc time snapshot and reverting to that later, to
restart the execution from that point if needed. Checkpointing
is necessary in order to avoid losing simulations in case of
unexpected failures. It is particularly useful when simulation
campaigns are executed to non-dedicated networks of work-
stations, a feature supported by GemFI.
Gem5 provides checkpointing, however with limitations.
One method is to switch the simulation from O3 to atomic
simple mode, create the checkpoint, and revert back to O3
mode to continue the simulation. This requires a pipeline ﬂush,
presenting a potential realism loss hazard. The second method
requires simulating the MOESI hammer cache coherency pro-
tocol, which however dramatically increases simulation time.
We used DMTCP (Distributed MultiThreaded Checkpoint-
ing) [3] to checkpoint the state of the Linux process running
the simulator, instead of checkpointing the internal state of
the simulator. A feature of DMTCP is its ability to take
checkpoints either by programmatically invoking checkpoint-
ing from within the process to be checkpointed, or asyn-
chronously, by setting environment variables. The ability to
invoke DMTCP from within the simulator allows us to ex-
ploit the front-end checkpointing mechanism of Gem5, while
altering the checkpointing back-end to use the DMTCP API.
Apart from protecting against unexpected problems in sim-
ulation campaigns, checkpointing can be used to speed-up
simulations. Before starting simulation campaigns, the user
executes one simulation up to the point when fault injection
is activated (including booting of the operating system and
application initialization). Using GemFI’s API the user can
checkpoint the simulation at this point. The saved state is then
used as a starting point for all experiments in the campaign
(Fig. 3). Upon restoring a checkpoint GemFI parses again the
faults conﬁguration ﬁle. Therefore, this strategy allows fast-
forwarding of the execution to the checkpoint and spawning of
multiple experiments, with different fault injection conﬁgura-
Fig. 4: Different categories of results for the DCT benchmark.
a) A strict correct result b) Relaxed correct result c) SDC d)
The difference between (a),(b) (loss of quality)
the application output from the two experiments, as well as the
statistical results provided by the simulator. For all benchmarks
the results were identical. This indicates that GemFI does not
corrupt the simulation process.
B. Experimental Validation in the Presence of Faults
1) Methodology: As a next step, we launched simulation
campaigns in which applications are injected with faults.
We use a single event upset fault model. Each experiment
injects a ﬂip-bit fault, using a uniform distribution for the
Location, Time and Behavior. Although this methodology does
not necessarily represent the way faults affect systems, it is
ample for the evaluation of the simulator. As mentioned earlier,
GemFI can support any user-provided realistic fault model.
We initially checkpoint after the system boot-up and the
initialization phase of the application under investigation.
For each experiment
in a campaign, we restore from the
checkpoint, start simulating in O3 mode and inject the fault.
The simulation continues until the affected instruction commits
or squashes (for example, due to a branch misprediction). At
that point we switch to atomic simulation and after application
termination (normal or crash) we evaluate the quality of the
end-result. When injecting a fault we print information on
the affected assembly instruction. This information is used
postmortem to correlate, either analytically or statistically, the
fault with the simulation result.
The outcome of each experiment can be classiﬁed in the fol-
lowing categories: crashed, non propagated, strictly correct re-
sult, correct result and SDC (Silent Data Corruption). Crashed
are experiments which fail
to successfully terminate. Non
propagated are experiments in which faults did not manifest
as errors (for example they were inserted in registers, however
the corrupted register was either not used during the execution
of the application or overwritten before the erroneous value
was used). Strictly correct experiments produce results which
are bit-wise identical to those produced by the corresponding
Fig. 5: Application behavior when fault injecting different
architectural components.
error-less execution. Correct experiments produce results that
are within acceptable quality margins, although not bit-wise
identical to those of the error-less execution. The degree of
tolerance is application dependent. For DCT we compare the
produced compressed image with the uncompressed one used
as input. Images with PSNR higher than 30 are regarded
as correct, since typical PSNR values in lossy image and
video compression range between 30 and 50 dB [8]. For the
deblocking ﬁlter, outputs with PSNR higher than 80 dB, when
compared with the error-free execution, are characterized as
correct [8]. For PI estimation we accept experiments that have
computed the ﬁrst two decimal points correctly, since this the
accuracy expected by the error-free execution for the 105 test
points. Since the tolerance on Jacobi is highly dependent on
the application domain, we characterize as correct solutions
that result to the same (bit-exact) output as the golden model,
converging after a potentially different number of iterations.
Correct Canneal executions are those that reduce the total
cost of routing and produce a correct chip. Finally, SDCs are
executions that terminate normally, yet they produce results
outside the acceptable range compared to the results of the
error-free execution. Fig. 4 depicts an example of the different
classes of results.
2) Experimental Results: Fig. 5 depicts the results of the
fault injection campaigns, correlating the Location of the fault
with application behavior. The last column of each chart
summarizes the results for the speciﬁc application.
All applications demonstrate their highest resiliency to faults
626
31
30
29
28
Opcode
Opcode
Opcode
Opcode
Opcode
Opcode
27
26
25
24
22
21
20
19
18
Rb
Rb
Rb
23
Ra
Ra
Ra
Ra
Ra
17
16
15
Literal
14
Unused
13
12
0
1
11
10
Function
7
6
5
4
3
8
9
Function
Function
Displacement
Function
Displacement
1
0
2
Rc
Rc
Rc
Type
Integer Operate
Integer Operate,Literal
Floating Point Operate
Memory Format
Branch Format
CALL PAL Format
TABLE I: Alpha instruction formats
targeting ﬂoating point registers. Most applications use a small
subset of these registers, hence there is a low probability
for a fault to affect a live register. Moreover, ﬂoating point
registers are typically used to store data and not system
state information or control ﬂow information. Deblocking, a
benchmark with no ﬂoating point operations, behaves exactly
as expected, demonstrating 100% strict correctness.
On the other hand, faults on the integer register ﬁle result
to higher crash rates. The compiler uses integer registers for
storing important information (global pointer, stack pointer,
frame pointer, return address register). Moreover compiler uses
integer registers for control ﬂow information (loop iterators,
base addresses for memory translation). The integrity of these
registers is crucial. Integer resisters tend to be live during large
spans of the application life. Therefore, any fault affecting
them has a high probability to cause a crash. For example
DCT and Jacobi which are characterized by many memory
accesses and use multi-level loop nests exhibit almost twice
the crash rate compared with other applications.
injection at
In order to validate fault
the fetch stage,
we correlated the affected bit location and the instruction
type with the end result of the application. The analysis is