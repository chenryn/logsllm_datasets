database as well as the results returned to the application. As queries are submit-
ted to the database and result tuples are returned, QStatProﬁler simultaneously
computes query statistics and the S-vectors for the queries. QStatProﬁler is ﬂex-
ible and can accommodate a variety of machine learning/clustering algorithms.
We shall elaborate on diﬀerent algorithms and anomaly detection goals later.
Query Filtering: The ﬁrst task of QStatProﬁler is proﬁling users or roles. It is
thus necessary to ignore queries that are are common for all users. For example,
the application may issue a query to the database to obtain the currently active
list of users, or the time-line for a particular activity, and so on. These queries
may sometimes be generated as part of application startup. This set queries is
well-known a priori, since they may be embedded in the application code and can
be ignored while proﬁling. In our case, we maintain a list of url tags that indicate
common application queries, called Framework Queries by QStatProﬁler.
Query Parsing and Unfolding: This component is concerned with obtaining
the mapping between the schema of the result set and the overall schema of the
database. The syntax of a user query may not refer directly to elements of the
base database schema (i.e., base relations and their attributes). References may
be made to views that might refer to other views; the use of aliases and in-line
subquery deﬁnitions can complicate the task of schema mapping. QStatProﬁler
uses a query parsing component that is tailored to the Postgresql SQL syntax.
Query parse trees are constructed and analyzed to determine the subset of the
database relations and attributes that are present in the result tuples. The output
of this phase is thus a set of relations and attributes that describe the result
tuples, from which S-vectors are constructed.
6.2 Approximating S-vectors
As alluded to earlier, having to execute a query before classifying it as anomalous
is a legitimate performance concern, which is addressed in this section.
First, we argue that the approach does not impose signiﬁcant additional bur-
den to the database server. In most application environments (e.g., web database
applications), execution of database queries is part of typical application func-
tion. For example, a user might submit queries through a web form; the queries
are executed at a remote database server and the results are made available to
the application. Our system operates as a passive component between the appli-
cation and the database server, observing queries and the corresponding results
without disrupting normal functioning. The database does not experience any
additional load due to the anomaly detection system; the computational cost
of calculating result statistics falls on a diﬀerent host that runs the ID system
(QStatProﬁler).
Second, the data-centric approach needs to see some data, necessitating some
performance penalty if we compare it to the syntax-centric approach on a mali-
cious query that the syntax-centric approach is able to detect (a true positive!).
However, as we shall see, the execution of one pinelined round in the RDBMS is
suﬃcient for the data-centric engine to perform well. The extra burden put on
the server is minimal, and is only marginally worse than the syntax-centric ap-
proach when that approach produces a true positive while ours produces a false
negative (type-3b queries, e.g., which are diﬃcult for attackers to construct).
This marginal penalty is more than oﬀset by queries which our approach pro-
duces a true positive while the syntax-based approach gives a false negative
(type-2b queries, e.g., which are easy for attackers to construct).
We propose to utilize only k tuples from the result set to build the corre-
sponding S-vector. We tested two ways to choose k tuples from a result set.
Initial-k tuples: Only the initial k tuples in the result set are used to ap-
proximate the entire result set. Statistics computed from these tuples are used
to generate the S-Vector representation of the query. As soon as the S-Vector is
classiﬁed as anomalous, we can stop the rest of the pipelined rounds from the
database, avoiding extra execution overheads.
Random–k tuples: k tuples are chosen at random from the complete result
set the S-vector of these k tuples are computed to represent the result set. This
approach is expected to produce better accuracy as compared to the inital-k
approach as it is not likely to be sensitive to speciﬁc orderings of the result
tuples by the database (this is especially important if the SQL query contains
‘ORDER BY’ clauses). Fortunately, we show that our choice of the distance
function seems to be insensitive to result set ordering, as long as the set is not
too small.
6.3 Detecting Type 1 and 2a Anomalies, and Masquerade Attacks
This section will show that the data-centric approach works slightly better than
the syntax-centric approach for type 1 and type 2a anomalies. The fact that
Table 3. Detection Performance – Type 1 Anomalies (Role Masquerade)
Syntax-Centric
Data-Centric
Roles Algorithm C
M
F
quip.
S-V S-V S-V
I(10) R(10) I(5)
S-V
R(5)
Chair N-Bayes
vs. Dec. Tree
quip. quip.
81.67% 85.33% 75%
88% 87.67% 87.67% 96.33% 88.3% 88.3 % 89% 88.67% 88.67% 88.67%
74.33%
83.3% 81%
92.67% 92.33% 94% 94% 92.67% 93.33%
Clustering 73.3% 72%
87.67% 82.33% 74.67% 77%
65.67% 92%
82.67% 78.33% 77% 81.67% 90%
71.33% 75.67% 68%
Faculty SVM
S-V
(all)
85%
S-V
S-V
I(20) R(20)
85%
Chair N-Bayes
vs. Dec. Tree
Staﬀ SVM
58% 93.5% 95.5% 60.5% 59%
75% 88% 96% 95.5% 92.5% 96% 96% 93% 95%
51.5% 84.5% 96% 80%
60.5% 62% 57.5% 62.5% 60.5%
92.5%
85.5% 78.5% 81.5% 85.5% 82%
Clustering 88.5% 85.5% 90.5% 91.5% 99% 96% 98.5% 95% 100% 96%
60%
58.67% 61.3% 60.3% 60.3% 59.3% 63%
84.33% 90.67% 93%
90% 93.67% 95.67% 89.3% 92.3% 91.67% 92% 93.67% 91.33% 91.67%
87% 93%
95.67% 69.67% 71.67% 71%
69.33% 72% 68.67% 72%
84%
vs. Dec. Tree
Staﬀ SVM
Faculty N-Bayes
Clustering 78.7% 73.3% 78%
99% 100% 99.6% 99.3% 99.3% 100% 99.3%
both approaches work well is to be expected by deﬁnition, because both the
syntax and the query results are statistically diﬀerent in type 1 and type 2a
anomalies. The syntax-centric scheme in [14] has been shown to perform well in
detecting role-based anomalies. Because the results are similar and due to space
limitation, we will present only the type-1 anomaly results. Our experiments
are also aimed to evaluate the accuracy of both approaches in detecting role
masquerade attacks. Recall that each query for GradVote comes with a user role,
and the execution of a typical query in one role by a user with a diﬀerent role
constitutes an anomaly.
Syntax-Centric Features: For the sake of completeness, we brieﬂy summarize
the syntax-centric data formats of [14]. Three representations are considered:
Crude (C-quiplet), Medium (M-quiplet), and Fine (F-quiplet). C-quiplet is a
coarse-grained representation consisting of the SQL-command, counts of pro-
jected relations, projected attributes, selected relations, and selected attributes.
M-quiplet is a medium-grained format recording the SQL command, a binary
vector of relations included in the projection clause, an integer vector denoting
the number of projected attributes from each relation, a binary vector of rela-
tions included in the selection clause, and an integer vector counting the number
of selected attributes from each relation. F-quiplet is ﬁne-grained, diﬀering from
the M-quiplet in that instead of a count of attributes in each relation for the
selection and projection clauses, a binary value is used to explicitly indicate the
presence or absence of each attribute in a relation in the corresponding clauses.
Test Setup: The available dataset of queries is labeled by the roles Staﬀ, Fac-
ulty, and Chair, in addition to Framework, for the common application-generated
queries. The query set is randomized and separated into Train and Test sets of
1000 and 300 queries, respectively. Four query data representations are tested:
our S-Vector (dimensionality 1638) and the syntax-centric C-quiplet (dimen-
Table 4. Detection Performance – Type 2b Anomalies (Data Harvesting Attacks)
Syntax-Centric
Data-Centric
Algorithm
C
S-V
quiplet quiplet quiplet (all)
M
F
S-V S-V S-V S-V S-V S-V
I(20) R(20) I(10) R(10) I(5) R(5)
Cluster Detection 23.5% 26.4% 17.64% 83.87% 12% 67.7% 6.4% 45.1% 6.4% 35.4%
Outlier False
Positive
14.47% 11.84% 15.8% 10.5% 3.9% 6.5% 3.9% 5.2% 2.6% 6.6%
Attrib Detection 0%
17.64% 2.9%
87% 87% 87% 87% 87% 12.9% 64.5%
Deviation False
Positive
0%
4.8%
4.8%
22.6% 26% 15% 23.8% 15.8% 23.8% 20.4%
sionality 5), M-quiplet (dimensionality 73), and F-quiplet (dimensionality 1187).
Four supervised learning algorithms are tested with each of these feature sets:
Naive Bayes, Decision Tree Classiﬁer, Support Vector Machines, and Euclidean
k-means clustering (see, e.g., [29]).
The results for the binary classiﬁers for masquerade detection are shown in
Table 3 (the best performance for each format with respect to separating user
roles is shown in boldface). In the table, I(k) and R(k) denote the Initial-k and
Random-k S-Vector approximations. There are two main results. First, the per-
formance of the S-Vector based detection using k-mean clustering is virtually
uniformly better than the syntax-based schemes. In many cases, the detection
rates are aproaching 100%. Note also that, the false positive rates is the com-
plement of the entries in the table, as there are only two classes. Second, the
Inital-k and Random-k S-Vector approximations perform very well. This result
is important because the Initial-k representation is the most practical one, as
alluded to earlier.
It is also noteworthy that the performance of syntax-based schemes is rela-
tively poor using the clustering outlier algorithm. There is one abnormal entry
which is the clutering performance of S-V (all) in the “Chair vs. Staﬀ” case,
which most likely is due to overﬁtting.
6.4 Detecting Type 2b Anomalies and Data Harvesting Attacks
The focus here is on detecting syntactically similar queries, but diﬀer in output
data (data-values, output volume, or both). This is a signiﬁcant query anomaly
since, in a typical attack, a minor variation of a legitimate query can output a
large volume of data to the attacker. This may go undetected and may be ex-
ploited for the purpose of data-harvesting. In other attack variations, the volume
of the output may be typical, but the data values may be sensitive. These kinds
of attacks fall into Type 2b in Table 2.
Test Setup: Since type-2b anomalous queries are not available from the
real query set, we generate type-2b queries by slightly modifying the normal
queries (i.e. queries normally executed by GradVote users). Thus, this gen-
erated “anomaly set” has approximately the same distribution as the normal
queries. Anomalous queries are generated by varying arithmetic and logical op-
erators and constants. As an example, consider the query
SELECT *
FROM vApplicants
WHERE reviewStatusID = ’a’
AND reviewStatusID = ’b’;
can be slightly modiﬁed to become
SELECT *
FROM vApplicants
WHERE reviewStatusID = ’a’
OR reviewStatusID = ’b’;
which yields a vastly diﬀerent result set.
It must be noted that the queries considered here are diﬀerent from mas-
querade attacks (since they are not representative of any authorized user of the
system) and are thus not available for training QStatProﬁler. Hence, supervised
learning is not suitable here. We devise two detection techniques based on a sin-
gle class of normal queries: Cluster-Based Outlier Detection based on Euclidean-
distance clustering, and Attrib-Deviation which is a variation of clustering using
the L∞-norm as the distance function.
Cluster-based Outlier Detection: The set of queries encountered during the
training phase are viewed as points in an m-dimensional Euclidean vector space,
where m is the dimensionality of the S-vectors. For each user cluster, we select
a point in the Euclidean space that is representative of the entire cluster, called
the cluster centroid, which minimizes the sum of the squared Euclidean distances
of the cluster points. For a test vector, the Euclidean distance from the cluster
centroid is computed. The query is ﬂagged as an outlier if the vector distance
is greater than a speciﬁed threshold from any user. In our case, the threshold is
chosen to be 3 times the standard deviation.
Attrib-Deviation: Consider, for example, that a user issues an anomalous
query with a diﬀerent statistic for the same attribute in the result schema as
a normal query. In our representation, this diﬀerence shows up in one or more
(depending on whether the attribute is categoric or numeric) dimensions of the
S-Vector. Hence, monitoring for anomalies on per-dimension basis is a promis-
ing approach. Further, if a query generates unusual output for more than one