—
32,796
98,098
CDN
1. Cloudﬂare
2. App Engine
3. Cloudfront
4. Incapsula
5. Akamai
In two of the above
No CDN
Total
Domains
44,615
89
80
48
12
47
53,301
98,098
Table III: Top ﬁve TLDs and CDNs for domains in the
blocklist—.com and .ru are the most popular TLDs. (cid:5)
For the 324,695 unique IPs in the list, we examined their
geolocation using the MaxMind Geolite2 [46] database. 324,038
(99.8%) IPs were found in the database. We saw that over 200k
IPs (>61%) were located in the US. Somewhat surprisingly,
Russia was only the sixth most popular country in which IPs
were located as shown in Table II. These IPs spanned over 2,112
Autonomous Systems (ASes) based on RouteViews lookup.
The blocklist also contains 39 subnets, ranging from /16s
to /24s. 31 out of 39 of these subnets contain at least one
IP reachable to one of our controls. The remaining eight
unreachable subnets geolocated to Moscow.
B. Domains
For the 132,798 domains in the list, over 49,583 (37.3%)
are .com domains and 15,259 (11.5%) are .ru domains. As
discussed in Section III, 34,404 (25.9%) domains on the
blocklist are not responsive, so for the analysis that follows
we only focus on the 98,098 responsive domains. .com and
.ru still dominate responsive domains as shown in Table III.
Inspired by McDonald et al. [47], we looked at what CDNs
the sites in the blocklist were hosted in, if any. We were able
to identify the CDN for 44,797 (45.7%) domains following
their methodology. As shown in Table III, an overwhelming
majority of domains which were served by a CDN (99.6%)
were hosted on Cloudﬂare, which provides some of its services
for free with little vetting of the sites. 47 domains had signs
that they used more than one CDN service. In these cases, we
counted them as customers of both.
We initially experimented with using the Fortiguard doc-
ument classiﬁcation service [25] to categorize domains and
ascertain what types of websites are in the blocklist. Unfortu-
nately, the Fortiguard classiﬁcation was not effective for Russian
language domains. Also, a large number of domains—27,858
(28.4%)—were classiﬁed into the “Business” category, which
9
did not reveal much information about the services hosted on
those domains. Therefore, we developed our topic modeling
algorithm designed after the technique introduced in Weinberg
et al. [81]. Our topic modeling algorithm processes the text
received from control measurements, and uses Latent Dirichlet
Allocation (LDA) clustering [6] to identify pages with the same
topic. To accomplish this, we adopt the following steps:
• Text Extraction—From the control measurements, we ob-
tained the HTML responses for all the 98,098 domains. We
ﬁrst ﬁlter out all the responses that returned an empty HTML
body, have an error code in the status line, or have encoding
issues in the server response. This reduced the number of
classiﬁable domains to 70,390 (71.8% of the original list).
We then use Python’s Beautiful Soup library [5] to extract
useful text and remove boilerplate text.
• Language Identiﬁcation—The LDA algorithm requires input
documents to be in the same language; as described in [81],
it detects semantic relationships between words based on the
probability of them occurring together within a document.
We used Python’s langdetect library [41] to identify
the primary language for each document. Out of 70,390
classiﬁable documents, 44,270 (62.9%) primarily contained
Russian or related Cyrillic text, and 19,530 (27.7%) contained
primarily English text. We choose to focus on this portion of
the classiﬁable pages as the other 9.4% contained documents
in 42 different languages. We thus reduce our manual effort
in labeling topics by only using LDA only twice, once for
Russian pages and once for English pages.
• Stemming—Before applying the LDA algorithm, we reduce
all words to stems using Snowball [71]. We then apply
term frequency-inverse document frequency (tf-idf ) [65]
to select terms that occur frequently. We preserved terms
whose combined tf-idf constitutes at least 90% of the total
document.
• LDA analysis—We then use LDA for Russian and English
documents separately. We used Python’s gensim [28] and
nltk [52] libraries for our implementation, and we used all
documents for training. We found N=20 topics to be optimal,
and α is determined optimally by the library based on the
training data.
Using LDA, we obtain 20 topic word vectors from the
English documents and 20 topic word vectors from the Russian
documents. Two researchers independently labeled the topics
by reviewing the top words in each topic. Disagreements were
resolved through discussion between the researchers. Many
topics were given the same label; as discussed in [81], this
is one of known limitations of LDA analysis. We manually
merge these topics into 9 categories. Additionally, we manually
selected a random subset of documents within each topic cluster
and ensured that all the documents belonged to the category
they were assigned.
The number of English and Russian documents classi-
ﬁed into each category is shown in Table IV. The major-
ity of domains (67.6%) fall into the “Gambling” category,
indicating the stringent crackdown of Russian authorities
against gambling websites. Our analysis suggests the high
number of gambling websites to be an effect of websites
quickly cloning to an alternate mirror domain when added
to the blocklist. This can be seen by many of the gam-
bling website domains on the blocklist having slight vari-
Category
Gambling
Pornography
Error Page
News and Political
Drug Sale
Circumvention
Multimedia
Parking Page
Conﬁguration Page
Categorized Total
Other Language Pages
No HTML or Error
Total
Num. Russian
Num. English
33,097
5,576
134
1,883
1,811
1,769
No clusters
No clusters
No clusters
44,270
—
—
10,144
2,821
3,923
No clusters
No clusters
No clusters
1,610
601
431
19,530
—
—
Total
43,241
8,397
4,057
1,883
1,811
1,769
1,610
601
431
63,980
10,464
23,654
98,098
Table IV: Categories of responsive domains obtained using
topic modeling—The second column shows the number of
documents in primarily Russian or related Cyrillic languages
classiﬁed into each category, and the third column shows the
same for primarily English language documents. Gambling and
pornography websites dominate the blocklist. (cid:5)
ations in their names, for example 02012019azino777.ru,
01122018azino777.ru, 01042019azino777.ru, and so on.
This also suggests that the blocklist is not actively maintained.
Unsurprisingly, pornography websites also feature prominently
in the blocklist.
RUBLdom contains news, political, and circumvention
websites that feature exclusively Russian-language media
(chechenews.com, graniru.org) and activist websites such
as antikor.com.ua, which is a self-proclaimed national anti-
corruption portal. Some of the pages were also categorized into
error pages, parking pages and conﬁguration pages, indicating
that these domain owners have moved since being added to
the blocklist. These pages are primarily in English because
they use templates from popular web server error pages (e.g.
Apache, Nginx etc.)
There are a few caveats to our topic modelling algorithm.
First, the documents we determine as Russian and English
may contain text in other languages, but we only choose those
documents that are predominantly in either Russian or English.
Nevertheless, a signiﬁcant amount of other language text may
lead to miscategorization of some websites. Second, our labeling
is primarily based on the top words in each word vector. This
may also lead to some pages being categorized incorrectly, but
our manual veriﬁcation did not ﬁnd any false positives.
VI. RESULTS
We divide this section into four parts: ﬁrst, we begin with
an analysis of the Zapret repository and present data about
how it has evolved over time. Then we present results from
RUBLdom, RUBLip, and ﬁnally, RUBLsub measurements.
A. Historical Analysis of Russian Blocklist
We analyze the Russian blocklist’s evolution over a seven-
year time period, from November 19, 2012, to April 24, 2019
at a daily granularity. Since it may be updated multiple times
a day, we utilize only the latest version, which is most often
published close to midnight. Any activity of smaller granularity,
such as the occasion of an addition or removal of an IP address
in a time span of less than 24 hours, is not considered. IP
Figure 2: Evolution of the blocklist over 7 years—The
blocklist has grown rapidly for much of its existence, across
all categories of contents. (cid:5)
subnets are not included in this analysis, which amount to an
approximately additional 26,000 addresses beginning in the
middle of 2017 and 16 million addresses beginning in April
2018 due to the banning of Telegram. These addresses are
omitted because their inclusion obscures graph clarity due to
their signiﬁcantly greater scale.
As shown by Figure 2, the size of the blocklist appears
to have grown rapidly since its conception in 2012. The plot
shows three size metrics: number of entries, raw number of
both IPs and domains, and number of unique IPs and domains.
Each of these metrics is cumulative and the drops in the number
are due to “removal” of entries, IPs, or domains. Since an entry
may contain multiple IPs and domains, the number of IPs and
domains far exceeds the number of entries.
An unexpected ﬁnding is how the raw number of IPs signif-
icantly exceeds the number of unique IPs. This discrepancy can
be attributed to potentially unintentional duplication—one IP
added to the blocklist because it hosts one domain name may
later be entered again for a different domain. Multiple domains
may share IPs because of the prevalence of sites hosted on
CDNs in the blocklist (as discussed in Section V-B). More
details on this analysis can be found in Appendix B.
One important observation is the sharp increase in the
number of raw IPs, unique IPs, and a moderate increase in
the number of unique domains in the past year. This suggests
that there is a deliberate effort to increase the accuracy of the
list. This is further punctuated by a number of drops in all the
metrics in the past year, which suggests that there has been
conscious effort put into making the list more meaningful and
to avoid repetitions.
B. Characterizing Censorship of RUBLdom
As described in Section III, we have six VPSes in data
centers and 14 residential probes. Figure 3 shows the type of
censorship observed at each vantage point. We divide the rest
of this section by vantage point type, in order to highlight the
complementary nature of the results from each of them.
1) VPSes in data centers: We observed some amount of
censorship at all of our VPSes in data centers. The number
10
Figure 3: Testing RUBLdom from all vantage points—The kind of blocking varies between vantage points. VPSes in Data
Centers see varying levels of blocking. Residential Probes experience a larger amount of domains blocking, and they also typically
receive explicit blockpages. (cid:5)
of domains blocked per vantage point is shown in Figure 3.
Four out of six VPSes show that more than 90% of RUBLdom
is blocked, with the highest blocking 96.8% of all RUBLdom
domains.
The censorship method varies between each VPS, conﬁrm-
ing our hypothesis that the lack of prescription of censorship
mechanism enables data center network providers to employ
any method of censorship. While most VPSes observe multiple
kinds of blocking, one method of blocking typically dominates
at each vantage point. For example, VPS 5 and VPS 6 mostly
observed blockpages, while VPS 2 and VPS 3 observed
more connection timeouts. In VPS 4, we observed that TCP
connections were reset when domains in RUBLdom were
requested. We suspect that VPSes observe more than one
type of blocking due to content being blocked at different
locations along the path to the server, such as at transit ISPs.
Content restriction at transit ISPs would cause most content to
be blocked across the country, even if ISPs closer to the user
do not censor all content in RUBL.
2) Residential Probes: Figure 3 shows that residential
probes show higher amounts of blocking overall, suggesting
that ISPs closer to the user block almost all the domains more
uniformly. Nine out of 14 residential probes observe more than
90% of the domains blocked and all of the probes observe at
least 49% of the domains blocked.
While VPSes saw high occurrences of timeouts and resets,
most residential probes observed a blockpage. We believe this
is in part due to the fact that residential ISPs are encouraged
by Roskomnadzor’s guidelines [67] to cite the law and/or
Roskomnadzor’s registry and provide explicit
information
regarding blocking to users. As for the other methods of
blocking, we found that Probe 6 predominantly observed a
large amount of connection resets and Probe 12 observed a
large number of timeouts.
the method of blocking is not clear. In an effort
As mentioned earlier, a blockpage is shown to the user
when the blocking method is either “Keyword Based” or
“DNS/Keyword Based”. In the latter the trigger is the hostname
but
to
distinguish between the two methods of blocking, we compare
the IPs from domain resolution in the residential probes with
the IPs received in domain resolution from all control vantage
points and with the answers that were determined as “Not
Figure 4: Answers from DNS resolutions that do not match
answers from any control DNS resolutions or Satellite
resolutions—Three vantage points VPS-6, Probe-9 and Probe-
14) show signs of DNS manipulation. (cid:5)
manipulated” in Satellite. The percentage of IPs from each
vantage point that does not match any control IP or any resolved
IP in Satellite is shown in Figure 4. VPS 6, Probe 9 and Probe
14 observe a large percentage of resolved IPs that do not
match any of the control responses. This lends credence to
the hypothesis that these three vantage points may be subject
to DNS manipulation rather than keyword based blocking. To
corroborate this, we investigate all instances of “DNS/Keyword
Based” blocking and found that each of the three vantage points
observed a single poisoned IP respectively. We looked at the
content hosted at these three IPs and found a blockpage being
returned which can be seen in Figure 10 in the Appendix.
We observe blockpages in that was categorized as “Other”
speciﬁcally in Probes 12, 13, and 14, meaning we could not
exactly determine the method of blocking. Upon investigation,
we saw that Probe 14 received a blockpage when queried with
the domain but was unable to retrieve the page when queried