## 沉浸式学习PostgreSQL|PolarDB 16: 植入通义千问大模型+文本向量化模型, 让数据库具备AI能力   
### 作者        
digoal        
### 日期        
2023-09-14         
### 标签        
PostgreSQL , PolarDB , 数据库 , 教学        
----        
## 背景        
欢迎数据库应用开发者参与贡献场景, 在此[issue](https://github.com/digoal/blog/issues/121)回复即可, 共同建设《沉浸式数据库学习教学素材库》, 帮助开发者用好数据库, 提升开发者职业竞争力, 同时为企业降本提效.        
- 系列课程的核心目标是教大家怎么用好数据库, 而不是怎么运维管理数据库、怎么开发数据库内核. 所以面向的对象是数据库的用户、应用开发者、应用架构师、数据库厂商的产品经理、售前售后专家等角色.        
本文的实验可以使用永久免费的阿里云[云起实验室](https://developer.aliyun.com/adc/scenario/f55dbfac77c0467a9d3cd95ff6697a31)来完成.        
如果你本地有docker环境也可以把镜像拉到本地来做实验:        
x86_64机器使用以下docker image:        
- [《amd64 image》](../202307/20230710_03.md)        
ARM机器使用以下docker image:        
- [《arm64 image》](../202308/20230814_02.md)        
## 业务场景1 介绍: 植入通义千问大模型+文本向量化模型, 让数据库具备AI能力     
开源的大模型非常多, 但是都需要大的算力才能高效的发挥大模型的能力, 以及训练各领域专业的大模型. 普通个人甚至企业很难独自构建及训练大模型.    
为了让大模型可以更加普惠企业及大众的需求, 阿里云推出了DashScope灵积. 可以理解为模型集市, 每个模型都有其独有的特点, 而且每一种模型都提供了API接口, 使得任何人都可以调用大模型的算力.  
什么和大模型结合将发挥重大的价值? 毫无疑问是数据. 例如:  
- 1、通过数据来训练大模型. 
- 2、通过大模型分析数据, 帮助企业进行决策. 
- 3、通过大模型理解数据, 例如帮助企业解决客户和伙伴提出的问题, 提升产品体验.   
这个实验将带领大家来体验一下如何将“千问大模型+文本向量化模型”植入到PG|PolarDB中, 让数据库具备AI能力.  
通用大模型是使用大量高质量素材训练而成的AI大脑, 训练过程非常耗费硬件资源, 时间也非常漫长. AI的能力取决于训练素材(文本、视频、音频等), 虽然训练素材非常庞大, 可以说可以囊括目前已知的人类知识的巅峰. 但是模型是由“某家公司/某个社区”训练的, 它能触达的素材总有边界, 总有一些知识素材是无法被训练的, 例如私有(机密)素材. 因此通用大模型存在一些问题, 以chatGPT为例: 
- 在达模型训练完成后, 新发现的知识. 大模型不具备这些知识, 它的回答可能产生幻觉(胡编乱造)   
- 大模型没有训练过的私有知识. 大模型不具备这些知识, 它的回答可能产生幻觉(胡编乱造)   
由于训练过程耗费大量资源且时间漫长, 为了解决幻觉问题, 不可能实时用未知知识去训练大模型, 向量数据库应运而生.   
基本原理如下
- 1、将新知识(在达模型训练完成后, 新发现的知识 + 大模型没有训练过的私有知识)分段
- 2、将分段内容向量化, 生成对应的向量(浮点数组)
- 3、将向量(浮点数组), 以及对应的分段内容(文本)存储在向量数据库中
- 4、创建向量索引, 这是向量数据库的核心, 有了向量索引可以加速相似搜索. 例如: 1000万条向量中召回100条相似内容, 毫秒级别.   
- 5、当用户提问时, 将用户问题向量化, 生成对应的向量(浮点数组)
- 6、到向量数据库中根据向量距离(向量相似性)进行搜索, 找到与用户问题相似度高于某个阈值的文本分段内容 
- 7、将找到的文本分段内容+用户问题发送给大模型
- 8、大模型有了与用户提问问题相关新知识(分段文本内容)的加持, 可以更好的回答用户问题
### 实现和对照     
1、模型服务灵积总览  
DashScope灵积，旨在通过灵活、易用的模型API服务，让业界各个模态的模型能力，能方便触达AI开发者。  
通过灵积API，丰富多样化的模型不仅能通过推理接口被集成，也能通过训练微调接口实现模型定制化，让AI应用开发更灵活，更简单！  
https://dashscope.console.aliyun.com/overview  
2、可以先在web界面体验各种模型  
https://dashscope.aliyun.com/  
3、进入控制台, 开通通义千问大模型+文本向量化模型  
https://dashscope.console.aliyun.com/overview  
4、创建API-KEY, 调用api需要用到key. 调用非常便宜, 一次调用不到1分钱, 学习几乎是0投入.   
https://dashscope.console.aliyun.com/apiKey  
5、因为灵积是个模型集市, 我们可以看到这个集市当前支持的所有模型:   
https://dashscope.console.aliyun.com/model  
支持大部分开源模型, 以及通义自有的模型. 分为三类: aigc, embeddings, audio.  
5\.1、aigc 模型  
通义千问:  
- 通义千问是一个专门响应人类指令的大模型，是一个灵活多变的全能型选手，能够写邮件、周报、提纲，创作诗歌、小说、剧本、coding、制表、甚至角色扮演。  
Llama2大语言模型:  
- Llama2系列是来自Meta开发并公开发布的的大型语言模型（LLMs）。该系列模型提供了多种参数大小（7B、13B和70B等），并同时提供了预训练和针对对话场景的微调版本。  
百川开源大语言模型:  
- 百川开源大语言模型来自百川智能，基于Transformer结构，在大约1.2万亿tokens上训练的70亿参数模型，支持中英双语。  
通义万相系列:  
- 通义万相是基于自研的Composer组合生成框架的AI绘画创作大模型，提供了一系列的图像生成能力。支持根据用户输入的文字内容，生成符合语义描述的不同风格的图像，或者根据用户输入的图像，生成不同用途的图像结果。通过知识重组与可变维度扩散模型，加速收敛并提升最终生成图片的效果。图像结果贴合语义，构图自然、细节丰富。支持中英文双语输入。当前包括通义万相-文生图，和通义万相-人像风格重绘模型。  
StableDiffusion文生图模型:  
- StableDiffusion文生图模型将开源社区stable-diffusion-v1.5版本进行了服务化支持。该模型通过clip模型能够将文本的embedding和图片embedding映射到相同空间，从而通过输入文本并结合unet的稳定扩散预测噪声的能力，生成图片。  
ChatGLM开源双语对话语言模型:  
- ChatGLM开源双语对话语言模型来自智谱AI，在数理逻辑、知识推理、长文档理解上均有支持。  
智海三乐教育大模型:  
- 智海三乐教育大模型由浙江大学联合高等教育出版社、阿里云和华院计算等单位共同研制。该模型是以阿里云通义千问70亿参数与训练模型为基座，通过继续预训练和微调等技术手段，利用核心教材、领域论文和学位论文等教科书级高质量语料，结合专业指令数据集，训练出的一款专注于人工智能专业领域教育的大模型，实现了教育领域的知识强化和教育场景中的能力升级。  
姜子牙通用大模型:  
- 姜子牙通用大模型由IDEA研究院认知计算与自然语言研究中心主导开源，具备翻译、编程、文本分类、信息抽取、摘要、文案生成、常识问答和数学计算等能力。  
Dolly开源大语言模型:  
- Dolly开源大语言模型来自Databricks，支持脑暴、分类、问答、生成、信息提取、总结等能力。  
BELLE开源中文对话大模型:  
- BELLE是一个基于LLaMA二次预训练和调优的中文大语言模型，由链家开发。  
MOSS开源对话语言模型:  
- MOSS开源对话语言模型来自复旦大学OpenLMLab项目，具有指令遵循能力、多轮对话能力、规避有害请求能力。  
元语功能型对话大模型V2:  
- 元语功能型对话大模型V2是一个支持中英双语的功能型对话语言大模型,由元语智能提供。V2版本使用了和V1版本相同的技术方案，在微调数据、人类反馈强化学习、思维链等方面进行了优化。  
BiLLa开源推理能力增强模型:  
- BiLLa是一种改良的开源LLaMA模型，特色在于增强中文推理能力。  
5\.2、embeddings,   
通用文本向量:  
- 基于LLM底座的统一向量化模型，面向全球多个主流语种，提供高水准的向量服务，帮助用户将文本数据快速转换为高质量的向量数据。  
ONE-PEACE多模态向量表征:  
- ONE-PEACE是一个通用的图文音多模态向量表征模型，支持将图像，语音等多模态数据高效转换成Embedding向量。在语义分割、音文检索、音频分类和视觉定位几个任务都达到了新SOTA表现，在视频分类、图像分类图文检索、以及多模态经典benchmark也都取得了比较领先的结果。  
5\.3、audio,  
Sambert语音合成:  
- 提供SAMBERT+NSFGAN深度神经网络算法与传统领域知识深度结合的文字转语音服务，兼具读音准确，韵律自然，声音还原度高，表现力强的特点。  
Paraformer语音识别;  
- 达摩院新一代非自回归端到端语音识别框架，可支持音频文件、实时音频流的识别，具有高精度和高效率的优势，可用于客服通话、会议记录、直播字幕等场景。  
6、通义千问模型的API:  
https://help.aliyun.com/zh/dashscope/developer-reference/api-details   
调用举例:  
6\.1、通过curl调用api. 请把以下API-KEY代替成你申请的api-key.    
```  
curl --location 'https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation' --header 'Authorization: Bearer API-KEY' --header 'Content-Type: application/json' --data '{  
    "model": "qwen-turbo",  
    "input":{  
        "messages":[        
            {  
                "role": "system",  
                "content": "你是达摩院的生活助手机器人。"  
            },  
            {  
                "role": "user",  
                "content": "请将这句话翻译成英文: 你好，哪个公园距离我最近？"  
            }  
        ]  
    },  
    "parameters": {  
    }  
}'  
```  