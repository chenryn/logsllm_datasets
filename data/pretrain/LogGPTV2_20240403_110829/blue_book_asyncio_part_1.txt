---
title: Asyncio
date: 20210817
author: Lyz
---
[asyncio](https://docs.python.org/3/library/asyncio.html) is a library to write
concurrent code using the async/await syntax.
asyncio is used as a foundation for multiple Python asynchronous frameworks that
provide high-performance network and web-servers, database connection libraries,
distributed task queues, etc.
asyncio is often a perfect fit for IO-bound and high-level structured network
code.
!!! note
        "[Asyncer](https://asyncer.tiangolo.com/tutorial/) looks very useful"
# Basic concepts
## [Concurrency](https://realpython.com/async-io-python/#async-io-explained)
Concurrency is best explained by an example stolen from [Miguel Grinberg](https://youtu.be/iG6fr81xHKA?t=4m29s).
Chess master Judit Polgár hosts a chess exhibition in which she plays multiple amateur players. She has two ways of conducting the exhibition: synchronously and asynchronously.
Assumptions:
- 24 opponents
- Judit makes each chess move in 5 seconds
- Opponents each take 55 seconds to make a move
- Games average 30 pair-moves (60 moves total)
Synchronous version: Judit plays one game at a time, never two at the same time, until the game is complete. Each game takes (55 + 5) * 30 == 1800 seconds, or 30 minutes. The entire exhibition takes 24 * 30 == 720 minutes, or 12 hours.
Asynchronous version: Judit moves from table to table, making one move at each table. She leaves the table and lets the opponent make their next move during the wait time. One move on all 24 games takes Judit 24 * 5 == 120 seconds, or 2 minutes. The entire exhibition is now cut down to 120 * 30 == 3600 seconds, or just 1 hour.
Async IO takes long waiting periods in which functions would otherwise be blocking and allows other functions to run during that downtime. (A function that blocks effectively forbids others from running from the time that it starts until the time that it returns.)
## [AsyncIO is not easy](https://realpython.com/async-io-python/#async-io-is-not-easy)
You may have heard the phrase “Use async IO when you can; use threading when you must.” The truth is that building durable multithreaded code can be hard and error-prone. Async IO avoids some of the potential speedbumps that you might otherwise encounter with a threaded design.
But that’s not to say that async IO in Python is easy. Be warned: when you venture a bit below the surface level, async programming can be difficult too! Python’s async model is built around concepts such as callbacks, events, transports, protocols, and futures—just the terminology can be intimidating. The fact that its API has been changing continually makes it no easier.
Luckily, asyncio has matured to a point where most of its features are no longer provisional, while its documentation has received a huge overhaul and some quality resources on the subject are starting to emerge as well.
## [The async/await Syntax and Native Coroutines](https://realpython.com/async-io-python/#the-asyncawait-syntax-and-native-coroutines)
At the heart of async IO are coroutines. A coroutine is a specialized version of a Python generator function. A coroutine is a function that can suspend its execution before reaching return, and it can indirectly pass control to another coroutine for some time. For example look at this Hello World async IO example:
```python
#!/usr/bin/env python3
# countasync.py
import asyncio
async def count():
    print("One")
    await asyncio.sleep(1)
    print("Two")
async def main():
    await asyncio.gather(count(), count(), count())
if __name__ == "__main__":
    import time
    s = time.perf_counter()
    asyncio.run(main())
    elapsed = time.perf_counter() - s
    print(f"{__file__} executed in {elapsed:0.2f} seconds.")
```
When you execute this file, take note of what looks different than if you were to define the functions with just `def` and `time.sleep()`:
```bash
$ python3 countasync.py
One
One
One
Two
Two
Two
countasync.py executed in 1.01 seconds.
```
The order of this output is the heart of async IO. Talking to each of the calls to `count()` is a single event loop, or coordinator. When each task reaches `await asyncio.sleep(1)`, the function talks to the event loop and gives control back to it saying, “I’m going to be sleeping for 1 second. Go ahead and let something else meaningful be done in the meantime.”
Contrast this to the synchronous version:
```python
#!/usr/bin/env python3
# countsync.py
import time
def count():
    print("One")
    time.sleep(1)
    print("Two")
def main():
    for _ in range(3):
        count()
if __name__ == "__main__":
    s = time.perf_counter()
    main()
    elapsed = time.perf_counter() - s
    print(f"{__file__} executed in {elapsed:0.2f} seconds.")
```
When executed, there is a slight but critical change in order and execution time:
```bash
$ python3 countsync.py
One
Two
One
Two
One
Two
countsync.py executed in 3.01 seconds.
```
Here `time.sleep()` can represent any time-consuming blocking function call, while `asyncio.sleep()` is used to stand in for a non-blocking time-consuming call.
Summing up the benefit of awaiting something, including `asyncio.sleep()`, is that the surrounding function can temporarily cede control to another function that’s more readily able to do something immediately. In contrast, `time.sleep()` or any other blocking call is incompatible with asynchronous Python code, because it will stop everything in its tracks for the duration of the sleep time.
## [The Rules of Async IO](https://realpython.com/async-io-python/#the-rules-of-async-io)
There are a strict set of rules around when and how you can and cannot use `async`/`await`:
- A function that you introduce with `async def` is a coroutine. It may use `await`, `return`, or `yield`, but all of these are optional.
    - Using `await` and/or `return` creates a coroutine function. To call a coroutine function, you must `await` it to get its results.
    - Using `yield` in an `async def` block creates an asynchronous generator, which you iterate over with `async for`. 
    - Anything defined with `async def` may not use `yield from`, which will raise a `SyntaxError`. (Remember that `yield from x()` is just syntactic sugar to replace for `i in x(): yield i`)
- The keyword `await` passes function control back to the event loop. (It suspends the execution of the surrounding coroutine.) If Python encounters an `await f()` expression in the scope of `g()`, this is how `await` tells the event loop, “Suspend execution of g() until whatever I’m waiting on—the result of f()—is returned. In the meantime, go let something else run.”. In pseudo code this would be:
    ```python
    async def g():
        r = await f() # Pause here and come back to g() when f() is ready
        return r
    ```
- You can't use `await` outside of an `async def` coroutine.
- When you use await `f()`, it’s required that `f()` be an object that is awaitable. An awaitable object is either another coroutine or an object defining an `.__await__()` method that returns an iterator. 
Here are some examples that summarize the above rules:
```python
async def f(x):
    y = await z(x)  # OK - `await` and `return` allowed in coroutines
    return y
async def g(x):
    yield x  # OK - this is an async generator
async def m(x):
    yield from gen(x)  # No - SyntaxError
def m(x):
    y = await z(x)  # No - SyntaxError (no `async def` here)
    return y
```
## [Async IO Design Patterns](https://realpython.com/async-io-python/#async-io-design-patterns)
Async IO comes with its own set of possible script designs.
### [Chaining Coroutines](https://realpython.com/async-io-python/#chaining-coroutines)
This allows you to break programs into smaller, manageable, recyclable coroutines:
```python
#!/usr/bin/env python3
# chained.py
import asyncio
import random
import time
async def part1(n: int) -> str:
    i = random.randint(0, 10)
    print(f"part1({n}) sleeping for {i} seconds.")
    await asyncio.sleep(i)
    result = f"result{n}-1"
    print(f"Returning part1({n}) == {result}.")
    return result
async def part2(n: int, arg: str) -> str:
    i = random.randint(0, 10)
    print(f"part2{n, arg} sleeping for {i} seconds.")
    await asyncio.sleep(i)
    result = f"result{n}-2 derived from {arg}"
    print(f"Returning part2{n, arg} == {result}.")
    return result
async def chain(n: int) -> None:
    start = time.perf_counter()
    p1 = await part1(n)
    p2 = await part2(n, p1)
    end = time.perf_counter() - start
    print(f"-->Chained result{n} => {p2} (took {end:0.2f} seconds).")
async def main(*args):
    await asyncio.gather(*(chain(n) for n in args))
if __name__ == "__main__":
    import sys
    random.seed(444)
    args = [1, 2, 3] if len(sys.argv) == 1 else map(int, sys.argv[1:])
    start = time.perf_counter()
    asyncio.run(main(*args))
    end = time.perf_counter() - start
    print(f"Program finished in {end:0.2f} seconds.")
```
Pay careful attention to the output, where `part1()` sleeps for a variable amount of time, and `part2()` begins working with the results as they become available:
```shell
$ python3 chained.py 9 6 3
part1(9) sleeping for 4 seconds.
part1(6) sleeping for 4 seconds.
part1(3) sleeping for 0 seconds.
Returning part1(3) == result3-1.
part2(3, 'result3-1') sleeping for 4 seconds.
Returning part1(9) == result9-1.
part2(9, 'result9-1') sleeping for 7 seconds.
Returning part1(6) == result6-1.
part2(6, 'result6-1') sleeping for 4 seconds.
Returning part2(3, 'result3-1') == result3-2 derived from result3-1.
-->Chained result3 => result3-2 derived from result3-1 (took 4.00 seconds).
Returning part2(6, 'result6-1') == result6-2 derived from result6-1.
-->Chained result6 => result6-2 derived from result6-1 (took 8.01 seconds).
Returning part2(9, 'result9-1') == result9-2 derived from result9-1.
-->Chained result9 => result9-2 derived from result9-1 (took 11.01 seconds).
Program finished in 11.01 seconds.
```
In this setup, the runtime of `main()` will be equal to the maximum runtime of the tasks that it gathers together and schedules.
### [Using a Queue](https://realpython.com/async-io-python/#using-a-queue)
The `asyncio` package provides [queue classes](https://docs.python.org/3/library/asyncio-queue.html) that are designed to be similar to classes of the [`queue`](https://docs.python.org/3/library/queue.html#module-queue) module.
There is an alternative structure that can also work with async IO: a number of producers, which are not associated with each other, add items to a queue. Each producer may add multiple items to the queue at staggered, random, unannounced times. A group of consumers pull items from the queue as they show up, greedily and without waiting for any other signal.
In this design, there is no chaining of any individual consumer to a producer. The consumers don’t know the number of producers, or even the cumulative number of items that will be added to the queue, in advance.
It takes an individual producer or consumer a variable amount of time to put and extract items from the queue, respectively. The queue serves as a throughput that can communicate with the producers and consumers without them talking to each other directly.
One use-case for queues is for the queue to act as a transmitter for producers and consumers that aren’t otherwise directly chained or associated with each other.
For example:
```python
#!/usr/bin/env python3
# asyncq.py
import asyncio
import itertools 
import os
import random
import time
async def makeitem(size: int = 5) -> str:
    return os.urandom(size).hex()
async def randsleep(caller=None) -> None:
    i = random.randint(0, 10)
    if caller:
        print(f"{caller} sleeping for {i} seconds.")
    await asyncio.sleep(i)
async def produce(name: int, q: asyncio.Queue) -> None:
    n = random.randint(0, 10)
    for _ in itertools.repeat(None, n):  # Synchronous loop for each single producer
        await randsleep(caller=f"Producer {name}")
        i = await makeitem()
        t = time.perf_counter()
        await q.put((i, t))
        print(f"Producer {name} added  to queue.")
async def consume(name: int, q: asyncio.Queue) -> None:
    while True:
        await randsleep(caller=f"Consumer {name}")
        i, t = await q.get()
        now = time.perf_counter()
        print(f"Consumer {name} got element "
              f" in {now-t:0.5f} seconds.")
        q.task_done()
async def main(nprod: int, ncon: int):
    q = asyncio.Queue()
    producers = [asyncio.create_task(produce(n, q)) for n in range(nprod)]
    consumers = [asyncio.create_task(consume(n, q)) for n in range(ncon)]
    await asyncio.gather(*producers)
    await q.join()  # Implicitly awaits consumers, too
    for c in consumers:
        c.cancel()
if __name__ == "__main__":