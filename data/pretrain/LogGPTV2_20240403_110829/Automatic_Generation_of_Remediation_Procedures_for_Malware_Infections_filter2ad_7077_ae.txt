Infected Resources: Remediating infected resources
is more challenging than newly-created resources.
In
general, it is not possible to know the contents of a ﬁle
before infection takes place, so it is not possible to re-
store their contents to a clean state. The exception to this
fact is with operating system ﬁles, which are common
to all systems and can thus be known to the remediation
procedure a priori.
to
approach
A naive
remediating
high-level
FileInfection(name, region, data)
behaviors
would be to replace the entire ﬁle with the corresponding
ﬁle in the bare operating system. However, uninfected
regions of data may be removed by this technique, which
could result in the loss of important system data, or
leave the system in an inconsistent state. To avoid this
circumstance, high-level behavior traces keep track of
uninfected regions regions in addition to ﬁle name ﬁle
and infected data data. We update the Smut component
of R to account for a FileInfection behavior only
if there is an actual ﬁle in the clean operating system
state whose name matches the ﬁle. In this case, Smut is
updated with the contents of ﬁle in the bare operating
system state, modiﬁed by preserving the portions listed
in regions and overwriting the rest with data. As indi-
cated in Algorithm 3, when the remediation procedure
ﬁnds ﬁle, it replaces the infected regions with a pristine
copy from the bare operating system.
a
high-level
RegistryInfection((key, value), data)
behavior
is encountered, and it is determined that a counterpart of
(key, value) exists in the bare operating system, Smut is
modiﬁed by adding the key/value pair together with the
Similarly,
when
modiﬁed data to the list of infected resources. As with
infected ﬁles, Algorithm 3 remediates these resources
by locating a pristine copy of (key, value) in the bare
operating system and replacing the infected resource
with it.
Deleted Resources: Currently, most malware is writ-
ten with the intent of leveraging infected systems to per-
petrate proﬁtable, albeit illicit, activities. Therefore, it
is very rare to see malware removing system resources,
as doing so would render the system useless for money-
making activities. For this reason, our remediation pro-
cedures do not handle deleted resources.
5 Evaluation
We applied our remediation procedure generation algo-
rithm to over two hundred malware samples collected in
the wild. We evaluated the quality of the generated pro-
cedures with respect to two metrics: false positives and
false negatives. A false positive occurs when a resource
is mistakenly identiﬁed as being part of a malware in-
fection and subsequently remediated. A false negative
occurs when a resource that was actually involved in an
infection is not identiﬁed and left untouched by the re-
mediation procedure. The results of our evaluation tes-
tify to the effectiveness of our technique: we observed a
low false negative rate, with more than 98% of the ma-
licious resources successfully remediated, and only one
false positive was encountered. Finally, we compare our
results to the remediation capabilities of the three com-
mercial products that performed best in previous experi-
ments [15].
5.1 Experimental Setup
Our experiments were performed over a corpus of 200
malicious programs, obtained through our own honey-
pot, and a web crawler that crawls known malicious do-
mains for executable ﬁles. Several traces for each sam-
ple were collected by executing it in multiple distinct en-
vironments. To extract a wide range of behaviors from
each sample, we modiﬁed the environments along a va-
riety of dimensions, including locale, timezone, and the
set of installed applications. Speciﬁcally, for each sam-
ple we performed the following steps:
1. Execute the sample three times in ﬁve different en-
vironments, collecting a system call trace for each
execution. Apply the algorithm described in Sec-
tion 4.2 to generate a remediation procedure from
the collected data.
2. Infect twenty-ﬁve test environments, all of them dis-
tinct from those used to collect traces, with the sam-
ple.
3. Execute the generated remediation procedure in
each test environment.
4. Compare the remediated state to the original (clean)
state. Tally the false positives and false negatives.
Although we do not attempt to extract all possible exe-
cution paths from the malware, this strategy allows us to
observe a reasonable range of malware behavior in vari-
ous settings.
5.2 False Negatives
Figure 7 compares the false negative rate of our
automatically-generated remediation procedures with
the three top-rated commercial malware detectors eval-
uated in [15]: Nod32 Anti-Virus 3.0, Panda Anti-Virus
9.0.5, and Kaspersky Anti-Virus 2009. The graph depicts
the average number of malicious resources that were re-
mediated over the entire malware corpus. Resources are
divided into three categories: ﬁles, registry keys, and
processes. Each of these classes is further divided into
two subcategories: primary and ancillary. Primary re-
sources are composed of executable ﬁles, registry keys
that activate process creation, and processes that arise
from ﬁles dropped or infected by the malware sample.
Roughly, we argue that all other resources are not as crit-
ical to the security of the system, and are thus considered
ancillary.
For the majority of these categories and subcategories,
our remediation procedures are more complete than com-
mercial anti-malware products. For example, our proce-
dures were able to remediate more than 99% of the pri-
mary ﬁle resources, whereas the best commercial prod-
uct we tested reached only 82% in this subcategory. Sim-
ilarly, our procedures remediated 99% of primary reg-
istry activities, while commercial products did not ex-
ceed 86%. Furthermore, while ancillary objects are of-
ten ignored by commercial remediation procedures, our
procedures remediated 95% of ancilliary ﬁles and 98%
of ancilliary registry activities. The portion of ﬁle and
registry resources that were not remediated by our proce-
dures correspond to behaviors that were never observed
while collecting traces. This illustrates the primary limi-
tation of our dynamic analysis-based approach and high-
lights a clear avenue for improvement in future work. Fi-
nally, our procedures remediated 100% of primary pro-
cess resources. However, the performance on ancillary
processes is signiﬁcantly lower. This is a result of the fact
that our processes do not have access to enough informa-
tion to discern a benign process from a process spawned
by the malware using a pre-existing benign ﬁle.
13
Figure 7: Comparison of the completeness of our automatically generated remediation procedures with the complete-
ness of the procedures employed in three top-rated commercial malware detectors.
5.3 False Positives
To quantify false positives, we compared the set of re-
sources affected by each malware sample in each test en-
vironment with the set of resources our procedures re-
mediated in each test environment. Any remediated re-
source not affected by the corresponding malware sam-
ple in at least one trace is considered a false positive.
We found that only one of our procedures produced any
false positives. The cause of this false positive, not sur-
prisingly, was a high-level behavior argument speciﬁed
by a very general regular expression. This implies that
the nondeterminism demonstrated by the corresponding
malware sample was too complex to be easily described
by a regular language. Thus, one area for future work
is utilizing more expressive language classes, such as
context-free grammars, for generalizing argument val-
ues.
6 Discussion
We are aware of some limitations of our system. Some of
these limitations could be exploited by attackers to cause
the system to produce remediation procedures that are of
limited value. In this section, we discuss these limita-
tions and present some solutions that we will investigate
in the future to address the limitations.
We constructed the models that we use to detect high-
level behaviors by leveraging years of experience in mal-
ware analysis, and we carefully tested all models to en-
sure that they cannot be evaded. However, since we can-
not prove that these models are perfect, we must take into
account the possibility that attackers could ﬁnd new ways
to perform some high-level malicious activities without
being detected. Moreover, in our proof-of-concept im-
plementation, multiple execution traces are obtained by
executing the same malware in several different operat-
ing system conﬁgurations. If attackers introduced dan-
gerous behaviors to their malicious programs that are not
triggered in our monitoring environment, then the result-
ing procedure would not be able to remediate such be-
haviors. Clearly, one area for future work is in expanding
the coverage of the dynamic behavioral analysis. While
our approach covers some of the potential behavior of the
sample, more sophisticated techniques [12, 21] can be
applied to increase the likelihood that all relevant paths
through the malware are explored.
The high-level behaviors observed in multiple execu-
tion traces are clustered to identify the instances of the
same behavior.
If the clusters we generate did not in-
clude all the instances of the same behavior, or if they
included instances of different behaviors, then the reme-
diation procedures constructed by generalizing the be-
haviors associated to each cluster would be too speciﬁc
or too generic. An attacker could write malicious pro-
grams that manifest certain behaviors to break the clus-
tering. Similarly, the regular expressions used by our re-
mediation procedures to identify affected resources are
14
 0 20 40 60 80 100Files(primary)Files(ancillary)Reg. keys(primary)Reg. keys(ancillary)Processes(primary)Processes(ancillary)% activities revertedOur approachNod32PandaKasperskygeneralized heuristically. Attackers could develop mali-
cious programs that affect resources in a way that induces
us to perform very aggressive generalization (e.g. create
ﬁles with random names anywhere in the ﬁle system) and
thus to generate remediation procedures that remove be-
nign ﬁles. We plan to address these problems in the fu-
ture. One approach is to introduce a feedback loop while
clustering behaviors and generating regular expressions
to validate the quality of the results. This feedback loop
would repeat the process until no further progress can be
made. Finally, we assert that it is not possible to cause
our algorithm to generate a procedure that modiﬁes ex-
isting ﬁles in a harmful way. This follows from the fact
that system ﬁles are only ever restored to their original
state by the procedure, not modiﬁed.
We currently generate a remediation procedure for
each malware sample we analyze. We plan to extend
our system to generate remediation procedures that cover
more than one malware sample. For example, it would be
useful to generate remediation procedures that are capa-
ble of operating on all samples for a given malware fam-
ily. Because the generated procedures will likely have
to account for a much higher degree of nondeterminism
than those that target only a single sample, additional
care must be taken to ensure that the high-level behav-
iors models are not too general, thus resulting in false
positives.
7 Conclusion
In this paper, we have presented a technique for auto-
matically generating malware remediation procedures.
Given a malware binary, our system produces executable
code that removes the harmful effects of executing that
malware on a system. We use dynamic analysis and be-
havior generalization to account for the difﬁculties posed
by real malware, thus allowing our procedures to effec-
tively remediate many possible executions of the mal-
ware without witnessing the actual infection take place.
This contribution represents a major break with previ-
ous automatic remediation techniques, which required
detailed information about the particular infection being
targeted. We implemented our technique and evaluated
its effectiveness on more than 200 malware binaries. The
performance of our prototype is quite good: on average,
98% of the harmful effects are remediated, and we en-
countered only a single false positive. In the future, we
plan to build on this work by extending it to work on
entire families, as well as exploring more precise tech-
niques for generalizing observed malware behaviors.
References
[1] U. Bayer, C. Kruegel, and E. Kirda. TTAnalyze: A
tool for analyzing malware. In 15th European Insti-
tute for Computer Antivirus Research (EICAR) An-
nual Conference, Hamburg, Germany, Apr. 2006.
[2] U. Bayer, P. Milani, C. Hlauschek, C. Kruegel, and
E. Kirda. Scalable, behavior-based malware clus-
tering.
In 16th Annual Network and Distributed
System Security Symposium (NDSS), 2009.
[3] F. Bellard. QEMU, a fast and portable dynamic
http://fabrice.bellard.
translator.
free.fr/qemu/.
[4] M. Christodorescu, C. Kruegel, and S. Jha. Min-
ing speciﬁcations of malicious behavior.
In 6th
Joint Meeting of the European Software Engineer-
ing Conference and the ACM SIGSOFT Symposium
on the Foundations of Software Engineering (ES-
EC/FSE), Dubrovnik, Croatia, 2007.
[5] M. Costa, M. Castro, L. Zhou, L. Zhang, and
M. Peinado. Bouncer: Securing software by block-
ing bad input. In 21st ACM Symposium on Operat-
ing Systems Principles (SOSP), 2007.
[6] P. Foggia. The vﬂib graph matching library, ver-
sion 2.0. http://amalfi.dis.unina.it/
graph/db/vflib-2.0/.
[7] F. Hsu, H. Chen, T. Ristenpart, J. Li, and Z. Su.
Back to the future: A framework for automatic mal-
ware removal and system repair.
In 22nd Annual
Computer Security Applications Conference (AC-
SAC), 2006.
[8] C. Kolbitsch, P. M. Comparetti, C. Kruegel,
E. Kirda, X. Zhou, and X. Wang. Effective and efﬁ-
cient malware detection at the end host. In USENIX
Security Symposium, 2009.
[9] Z. Li, M. Sanghi, Y. Chen, M.-Y. Kao, and
B. Chavez. Hamsa: Fast signature generation for
zero-day polymorphic worms with provable attack
resilience. In IEEE Symposium on Security and Pri-
vacy, Oakland, California, 2006.
[10] Z. Liang, V. N. Venkatakrishnan, and R. Sekar. Iso-
lated program execution: An application transpar-
ent approach for executing untrusted programs. In
19th Annual Computer Security Applications Con-
ference (ACSAC), 2003.
15
[11] L. Martignoni, E. Stinson, M. Fredrikson, S. Jha,
and J. C. Mitchell. A layered architecture for de-
tecting malicious behaviors. In International Sym-
posium on Recent Advances in Intrusion Detection
(RAID), Sept. 2008.
[12] A. Moser, C. Kruegel, and E. Kirda. Exploring mul-
tiple execution paths for malware analysis. In IEEE
Symposium on Security and Privacy, Oakland, Cal-
ifornia, 2007.
[13] A. Moser, C. Kruegel, and E. Kirda. Limits of static
analysis for malware detection.
In 23rd Annual
Computer Security Applications Conference (AC-
SAC), 2007.
[14] J. Newsome, B. Karp, and D. Song. Polygraph:
Automatically generating signatures for polymor-
phic worms. In IEEE Symposium on Security and
Privacy, Oakland, California, 2005.
[15] E. Passerini, R. Paleari, and L. Martignoni. How
good are malware detectors at remediating infected
systems?
In 6th Conference on Detection of In-
trusions and Malware & Vulnerability Assessment
(DIMVA), Como, Italy, July 2009.
[16] M. D. Preda, M. Christodorescu, S. Jha, and S. De-
bray. A semantics-based approach to malware de-
tection. ACM Transactions on Programming Lan-
guages and Systems, 30(5):25.1–25.54, Aug. 2008.
[17] A. Raman, P. Andreae, and J. Patrick. A beam
search algorithm for PFSA inference. Pattern Anal-
ysis and Applications, 1(2):121–129, 1998.
[18] K. Rieck, T. Holz, C. Willems, P. D¨ussel, and
P. Laskov. Learning and classiﬁcation of malware
behavior.
In 5th Conference on Detection of In-
trusions and Malware & Vulnerability Assessment
(DIMVA), 2008.
[19] W. Sun, Z. Liang, R. Sekar, and V. N. Venkatakrish-
nan. One-way isolation: An effective approach for
realizing safe execution environments. In 12th Sym-
posium on Network and Distributed Systems Secu-
rity (NDSS), 2005.
[20] V. Yegneswaran, J. T. Gifﬁn, P. Barford, and S. Jha.
An architecture for generating semantics-aware sig-
natures. In 14th USENIX Security Symposium, Bal-
timore, MD, 2005.
[21] H. Yin, D. Song, M. Egele, E. Kirda, and
C. Kruegel. Panorama: Capturing system-wide in-
formation ﬂow for malware detection and analysis.
In 14th ACM Conference on Computer and Com-
munications Security (CCS), Alexandria, VA, 2007.
16