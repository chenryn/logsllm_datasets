Our AKDE may model a discrete feature as if it’s continuous.
The reason is that the domain of the feature ¯f could be very large
and requires much more samples than we can collect in order to
accurately estimate in discrete. Take total packet count of Face-
book.com as an example. We observe 238 diﬀerent values from our
600 samples in the range of 576 and 1865. If the feature is processed
as discrete, the estimated probability for observed values would be
inaccurate, and the missed values would be considered impossible
in the inappropriate way. Our solution is to consider such a dis-
crete feature to be continuous, so that the kernels would smooth
the probability distribution estimation and assign an appropriate
probability to the missed values, making our measurement more
accurate.
Our AKDE is able to distinguish a continuous-like discrete fea-
ture. Take the feature of transmission time as an example. This
feature is used to be continuous, but when defenses such as Tama-
raw [6] are applied, the feature would become discrete. Our AKDE
is able to recognize by two approaches. The ﬁrst approach is about
using a threshold β. If the same traﬃc instances are observed more
than β times in our dataset, these instances are distinguished as
discrete cases, and our AKDE would consider their features to be
discrete. The second approach is template matching used in BuFLO
case. We precompute a pattern of traﬃc believed to be discrete, and
we consider the instances matching the pattern as discrete as well.
In case of BuFLO, the pattern is the resulted traﬃc instance with
transmission time τ .
Moreover, our AKDE can handle a feature which is partly con-
tinuous and partly discrete (or in other words, a mixture of con-
tinuous and discrete random variables). Such features exist in a
WF defense such as BuFLO [11] which always sends at least T sec-
onds. These features would be discrete if the genuine traﬃc can be
completed within time T , otherwise, the features would be continu-
ous. Thanks to AKDE which allows diﬀerent observations to have
their separate bandwidths, we compute the bandwidths separately
for discrete and continuous feature values. According to [14, 15],
AKDE is able to model a feature with mixed nature by selecting
adaptive bandwidths for its observations.
We start by how WeFDE applies AKDE to estimate a single fea-
D INFORMATION LEAKAGE IN TWO
ture’s probability distribution:
WORLDS
ˆp(
¯f |cj ) =
1
n
mc =1
1
hc
K (
¯f − pc
hc
)
(8)
This section describes how to apply mutual information to quan-
tify the information leakage in the closed-world setting and the
open-world setting.
where
hc is the bandwidth in AKDE,
K (· ) is the kernel function of a Gaussian, and
p1 , p2 , · · · , pm are the observations for ¯f in visiting cj
Choosing proper bandwidths is important for AKDE to make
an accurate estimate. If a feature is continuous, WeFDE adopts
plug-in estimator[43]. In case of failure, we use the rule-of-thumb
Closed-world Setting. Suppose C is a random variable denot-
ing possible websites that a user may visit. Then the information
leakage I (F ; C) in the closed-world scenario is:
I (C; F ) = H (C) − H (C |F )
H (C) = − ci ∈C
H (C |F ) =ÞΦ
p(x)H (C |x)dx
Pr(ci ) log2 Pr(ci )
(9)
where
Pr (ci ) is the probability that the visited website is ci ,
Φ is the domain for the feature F , and
p(x) is the probability density function for variable x.
Open-world Setting. The information leakage I (F ; O) in the
open-world scenario is:
I (F ; O) = H (O) − H (O |F )
(10)
Pr(ci ) log2 Pr(ci )
log2 { c j ∈N
Pr(cj )}
p(f )H (O | f )d f
Pr(ci | f ) log2(Pr(ci | f ))
H (O) = − ci ∈M
−
Pr(cj )
c j ∈N
H (O |F ) = ÞF
H (O | f ) = − ci ∈M
c j ∈N
Pr(cj | f )
−
(11)
(12)
(13)
log2 { c j ∈N
Pr(cj | f )}
where O is a random variable denoting the visited website be-
longs to the monitored or the non-monitored, and if it is moni-
tored, which one. M denotes the monitored set of websites, and N
denotes the non-monitored set of websites. F denotes the domain
for feature F .
E FEATURE SET
The following lists the 14 categories of features which are included
in the state-of-art attacks.
1. Packet count. Counting the number of packets is found help-
ful for an attacker. Speciﬁcally, we include the following features
based on packet count: (a) the total packet count, (b) the count of
outgoing packets, (c) the count of incoming packets, (d) the ratio
between the incoming packet count and that of the total, and (e)
the ratio between the outgoing packet count and that of the total.
2. Time Statistics. Firstly, we look at the packet inter-arrival time
for the total, incoming, and outgoing streams, individually. We ex-
tract the following statistics and add them into our feature set: (a)
maximum, (b) mean, (c) standard deviation, and (d) the third quar-
tile. Secondly, we embrace the features based on transmission time.
We add the ﬁrst, second, third quartile and total transmission time
into our feature set.
Let’s take 2-gram as an example. Suppose the traﬃc sequence is
h(l1, t1), (l2, t2), (l3, t3), (l4, t4)i, then the 2-grams are (l1, l2), (l2, l3)
and (l3, l4). We consider the frequencies of each grams as features
and we measure bigram, trigram, 4-gram, 5-gram, and 6-gram for
comparison.
In addition, the number of packets transmitted before each suc-
cessive incoming or outgoing packets also captures the ordering
of the packets. We record such features by scanning the ﬁrst 300
packets of the incoming and those of the outgoing respectively.
5–7 and 9. Intervals and Bursts. We ﬁrstly adopt interval-based
features to capture the traﬃc bursts. An interval is deﬁned as a
traﬃc window between a packet and the previous packet with the
same direction.
We use two approaches for interval-based features: Interval-I [46]
also apply grouping [36] on V to obtain extra features: 5
8
i =6 V(i), and13
records the ﬁrst 300 intervals of incoming packets and those of the
outgoing, Interval-II [40] uses a vector V in which V(i) records the
number of intervals with the packet number i. We use two vec-
tors to count the incoming and outgoing intervals separately, and
we ﬁx the vectors’ dimension to be 300 (An interval having more
than 300 packets is counted as a interval with 300 packets). We
i =3 V(i),
i =9 V(i). We name this approach to be Interval-III.
We also adopt [46]’s approach of counting the bursts for outgo-
ing packets. A burst of outgoing packets is deﬁned as a sequence
of outgoing packets, in which there are no two adjacent incoming
packets. We extract the packet number in each burst and use the
maximum and the average as features. We also add the total burst
number, as well as the number of bursts with more than 5 packets,
10 packets, and 20 packets, respectively.
8. Packet Distribution. We divide the packet sequence into non-
overlapping chunks of 30 packets and count the number of outgo-
ing packets in ﬁrst 200 chunks as features. We ignore the chunks
after the 200 chunks if any, and pad 0s to have 200 features in case
of having less than 200 chunks[46].
We also apply the approaches in [22] to have additional features:
(a) calculate the standard deviation, mean, median, and maximum
of the 200 features, and (b) split them into 20 evenly sized subsets
and sum each subset to be new features.
10–12. First 30 and Last 30 Packets. We explore the information
leakage from the ﬁrst and last 30 packets. Particularly, we include
ﬁrst 20 packets as features, and we extract the packet count fea-
tures (incoming packet count and outgoing packet count) from the
ﬁrst and last 30 packets, respectively.
13. Packet count Per Second. We count the packet number in ev-
ery second. To make the feature number ﬁxed, we count the ﬁrst
100 seconds and pad 0s if the transmission time is less than 100 sec-
onds. The standard deviation, mean, median, minimum, and maxi-
mum of these features are also included.
We also include the alternative count of packets per second features[22].
We split the packet count per second features into 20 evenly sized
subsets and sum each subset to obtain the alternative features.
3–4. Packet Ordering. we explore the n-gram features which are
widely adopted features extracting packet ordering. A n-gram is a
contiguous sequence of n packet lengths from a traﬃc sequence.
14. CUMUL Features. Panchenko et al. [34] introduce the CU-
MUL features. A cumulative representation is extracted from the
packet trace, and n features are derived by sampling the piecewise
linear interpolant of the representation at n equidistant points. We
adopt such features with n = 100.
It’s worth noting that “packet” here refers to a Tor cell packet.
We extract our features based on the cell packet traces. In addition,
in 2011 [36] includes a feature named HTML marker, which counts
the total size of incoming packets from the ﬁrst outgoing packet
and the next outgoing packet. Such summation was considered to
be the size of the HTML document and therefore is informative. We
ﬁnd such claim is not accurate anymore, and we ﬁnd no updated
details of how to reproduce such a feature. As a result, we do not
include this feature in our measurement.
F WORLD SIZE AND INFORMATION
LEAKAGE
In this section, we discuss the impact of the world size on our in-
formation leakage measurement.
We start with the closed-world setting. We observe that with
the increase of the world size, the information leakage for most
categories and the total increases as well, while the individual in-
formation leakage of features is little impacted (particularly when
the world size increases from 1000 to 2000). To explain the conﬂict-
ing observations, we highlight the notion of maximum possible in-
formation leakage of a setting. A feature (or a set of features) leaks
no more information than the information that the setting has. For
example, in our closed-world setting with 100 websites, the total
information leakage is 6.63 bits. But if we let the world size be 2,
the total leakage is no more than 1 bit, no matter how distinguish-
able the ﬁngerprint is. Therefore we argue that the increased infor-
mation leakage with larger world size for most categories and the
total is because the website ﬁngerprint has the ability to leak more
information than the information that our closed-world settings
have. This phenomenon leads to an interesting question: what is
the maximum information leakage the website ﬁngerprint is able
to leak in a suﬃciently larger world size, which we include in our
future work.
For the features’ individual information leakage, we observe that
the leakage in each setting is much less than the information that
these setting have, and that the world size has little impact on the
measurement. We explain the reason for the little impact of the
world size by the following theorem:
Theorem 2. Let’s consider x closed-world settings with equal
world size n. Suppose a feature F = ¯f has valid information leak-
age of I1 , I2 , · · · , Ix in each closed-world setting. In the combined
closed-world setting with nx world size, the information leakage
of F = ¯f would be I1+I2+···+Ix
.
x
Proof: let’s denote the information leakage in each closed-world
setting to be:
Il = lo❕2(n) + l ∈{1, ··· ,n }
ql (i)lo❕2(ql (i))
(14)
, where ql (i) is the probability of visiting the ith website in the lth
closed-world setting conditioned on F = ¯f .
12
11
10
9
8
7
6
5
4
3
)
t
i
b
(
e
g
a
k
a
e
L
n
o
i
t
a
m
r
o
f
n
I
l
a
t
o
T
2
400
600
800
Tamaraw (L=100)
Tamaraw (L=500)
Tamaraw (L=1000)
BuFLO (t =20)
BuFLO (t =60)
BuFLO (t =120)
Upper Bound
1000
1200
1400
1600
1800
2000
the Closed−world Size
Figure 14: Defenses with Diﬀerent World Size.
In the combined closed-world setting, the information leakage
of F = ¯f is
lo❕2(nx) + l ∈{1, ··· , x }
{ i ∈{1, ··· ,n }
x l ∈{1, ··· , x } i ∈{1, ··· ,n }
1
x
= lo❕2(n) +
ql (i)
lo❕2(
ql (i)
x
)}
ql (i)lo❕2(ql (i))
(15)
=
I1 + I2 + · · · + Ix
x
This theorem reveals the relation between world size and in-
formation leakage. With each closed-world setting including suf-
ﬁcient websites, the combined larger world size would have little
impact on the information leakage.
We also evaluate world size impact on defenses in closed-world
setting. Figure 14 shows that in Tamaraw, world size has little im-
pact on information leakage. No matter how large the world size
is, the information leakage for Tamaraw is around 3.3, 2.72, 2.45
bits for L = 100, 500, 1000. BuFLO with τ = 120 is not impacted
by world size, but BuFLO with τ = 20, 60 see the increase of in-
formation leakage. The diﬀerent impact from world size roots in
BuFLO’s mixed nature.
We discuss the world size impact on the open-world setting.
Here the world size refers to the size of the non-monitored web-
sites. We ﬁnd that with a larger world size, the maximum informa-
tion leakage decreases. In addition, as is shown in Section 9, world
size also has little impact on the measure.
G MONTE CARLO INTEGRAL EVALUATION
We use the Monte Carlo method [17] to evaluate the integral when
measuring H (C | ¯f ). Monte Carlo picks random points in the do-
main and uses these points to numerically approximate the deﬁnite
integral:
H (C | ¯f ) ≃
1
k
ki =1
H (C | ¯f (i ))
(16)
where
¯f (1)
k is the size of the sample.
, · · · ,
¯f (2)
,
¯f (k) are the random samples, and
Note that we apply importance sampling here, in which random
samples are drawn from the distribution having probability density
function p( ¯f ). The sampling process is:
• Step 1: decide sampling size. To accurately evaluate the inte-
gral by Monte Carlo method, suﬃcent samples are needed.
In this paper, the total number of samples is set to be k =
5000. For each condition cj , j ∈ {1, · · · , n}, the number of
samples is k · Pr(cj ).
• Step 2: sampling for diﬀerent conditons. For each condition
cj , draw k · Pr(cj ) samples from the distribution with condi-
tional PDF p( ¯f |cj ).
We use this method to draw k samples from the generic PDF p( ¯f ).
We choose importance sampling over uniform domain sampling
(which would require a diﬀerent estimation than Equation 16) since
it includes more samples for feature values that are more likely to
happen. The beneﬁt is that the “important” values in the integra-
tion are emphasized for higher precision.