operation is used at the end to yield the 32 bit hash
40
12th USENIX Security Symposium 
USENIX Association
value. This construction supports inputs of length
up to 224 bytes.
(A maximum length is declared
by the programmer when a hashing context is al-
located, causing the ﬁxed vector to be initialized by
AES in counter mode, keyed from /dev/random.
Hash inputs longer than this are rejected.)
Our initial tests showed that UHASH signiﬁcantly
outperformed the Carter-Wegman construction for
long inputs, but Carter-Wegman worked well for
short inputs. Since many software applications of
hash functions know, apriori, that their inputs are
small and of ﬁxed length (e.g., in-kernel network
stacks that hash portions of IP headers), we wished
to provide carefully tuned functions to make such
hashing faster. By ﬁxing the length of the input, we
could fully unroll the internal loop and avoid any
function calls. GCC inlines our hand-tuned func-
tion. Furthermore, the Carter-Wegman construc-
tion can be implemented with a smaller accumu-
lator. Without changing the mathematics of Carter-
Wegman, we can multiply 8 bit values with 20 bit
entries in the ﬁxed vector and use a 32 bit accumu-
lator. For inputs less than 16-bytes, the accumulator
will not overﬂow, and we get a 20 bit hash value as
a result. The inputs are passed as separate formal
arguments, rather than in an array. This gives the
compiler ample opportunity for inlining and spe-
cializing the function.
5.2.2 Universal hash microbenchmarks
We performed our microbenchmarking on a Pen-
tium 2, 450MHz computer. Because hash tables
tend to use a large amount of data, but only read
it once, working set size and its resultant impact
on cache miss rates cannot be ignored. Our mi-
crobenchmark is designed to let us measure the ef-
fects of hitting or missing in the cache. We pick
an array size, then ﬁll it with random data. We then
hash a random sub-range of it. Depending on the ar-
ray size chosen and whether it ﬁts in the L1 cache,
L2 cache, or not, the performance can vary signiﬁ-
cantly.
In our tests, the we microbenchmarked two con-
ventional algorithms, four universal hashing al-
gorithms, and one cryptographic hash algorithm:
Perl
MD5
UHASH
CW
Perl 5.8.0 hash function
cryptographic hash function
UMAC universal hash function
Carter-Wegman, one byte process-
ing, variable-length input, 64 bit
accumulator, 32 bit output
Carter-Wegman, two byte process-
ing, 12-byte ﬁxed input, 64 bit ac-
cumulator, 32 bit output
CW12
CW12-20 Carter-Wegman, one byte process-
ing, 12-byte ﬁxed input, 32 bit ac-
cumulator, 20 bit output
four byte processing, 12-byte ﬁxed
input, 32 bit output
XOR12
In addition to Perl, MD5, UHASH, and three vari-
ants of the Carter-Wegman construction, we also
include a specialized function that simply XORs
its input together, four bytes at a time. This sim-
ulates the sort of hash function used by many
performance-paranoid systems.
Figure 7 shows the effects of changing the work-
ing set size on hash performance. All the hash
functions are shown hashing 12-byte inputs, cho-
sen from an array whose sizes have been chosen to
ﬁt within the L1 cache, within the L2 cache, and to
miss both caches. The largest size simulates the ef-
fect that will be seen when the data being hashed is
freshly read from a network buffer or has otherwise
not yet been processed. We believe this most ac-
curately represents the caching throughput that will
be observed in practice, as hash values are typically
only computed once, and then written into an ob-
ject’s internal ﬁeld, somewhere, for later compari-
son.
As one would expect, the simplistic XOR12 hash
function radically outperforms its rivals, but the ra-
tio shrinks as the working set size increases. With
a 6MB working set, XOR12’s throughput is 50
MB/sec, whereas CW12-20 is 33 MB/sec. This rel-
atively modest difference says that universal hash-
ing, with its strong security guarantees, can ap-
proach the performance of even the weakest hash
USENIX Association
12th USENIX Security Symposium 
41
)
c
e
s
/
e
t
y
b
M
(
t
u
p
h
g
u
o
r
h
T
 180
 160
 140
 120
 100
 80
 60
 40
 20
 0
12KByte
240KByte
6MByte
391
Perl
MD5
UHASH
CW
CW12
CW12-20
XOR12
Figure 7: Effect of working set on hash performance on 12-byte inputs.
functions. We can also see that universal hashing is
competitive with Perl’s hash function and radically
outperforms MD5.
As the cache hit rate increases with a smaller work-
ing set, XOR12 radically outperforms its competi-
tion. We argue that this case is unlikely to occur
in practice, as the data being hashed is likely to
incur cache misses while it’s being read from the
network hardware into main memory and then the
CPU. Secondly, we are microbenchmarking hash
function performance, a hash function is only a per-
centage of overall hash table runtime which is only
a percentage of application runtime. Of course, in-
dividual application designers will need to try uni-
versal hashing out to see how it impacts their own
systems.
Some applications hash longer strings and require
general-purpose hash functions. Figure 8 uses the
6MB working set and varies the length of the input
to be hashed. We can no longer use the special-
ized 12-byte functions, but the other functions are
shown. (We did not implement a generalization of
our XOR12 hash function, although such a function
would be expected to beat the other hash functions
in the graph.) With short strings, we see the Perl
hash function outperforms its peers. However, with
strings longer than around 44-bytes, UHASH dom-
inates all the other hash functions, due in no small
part to its extensive performance tuning and hand-
coded assembly routines.
)
c
e
s
/
e
t
y
B
M
(
t
u
p
h
g
u
o
r
h
T
 140
 120
 100
 80
 60
 40
 20
 0
Perl
MD5
UHASH
CW
 1
 4
 16
 64
Input length
 256
 1024
Figure 8: Effect of input length on hash perfor-
mance with a 6MB working set.
We have some preliminary benchmarks with in-
tegrating universal hashing into Perl. We bench-
marked the change with two perl scripts, both of
which do little other than hash table operations. The
ﬁrst script is a histogramming program, the second
just inserts text into a hash table. Our results in-
dicate that the application performance difference
between UHASH and Perl’s default hash function
is plus or minus 10%.
We conclude that our customized Carter-Wegman
construction, for short ﬁxed-length strings, and
UHASH, for arbitrary strings, are sufﬁciently high
performance that there is no excuse for them not to
be used, or at least benchmarked, in production sys-
tems. Our code is available online with a BSD-style
42
12th USENIX Security Symposium 
USENIX Association
license2.
6 Conclusions and future work
We have presented algorithmic complexity attacks,
a new class of low-bandwidth denial of service
attacks. Where traditional DoS attacks focus on
small implementation bugs, such as buffer over-
ﬂows, these attacks focus on inefﬁciencies in the
worst-case performance of algorithms used in many
mainstream applications. We have analyzed a va-
riety of common applications, ﬁnding weaknesses
which vary from increasing an applications work-
load by a small constant factor to causing the appli-
cation to completely collapse under the load cause
by its algorithm’s unexpectedly bad behavior.
Algorithmic complexity attacks against hash table,
in particular, count on the attacker having sufﬁ-
cient freedom over the space of possible inputs to
ﬁnd a sufﬁcient number of hash collisions to in-
duce worst-case behavior in an application’s hash
table. When the targeted system is processing net-
work packets, the limited address space of IPv4 of-
fers some limited protection against these attacks,
but future IPv6 systems will greatly expand an at-
tacker’s ability to ﬁnd collisions. As such, we
strongly recommend that network packet process-
ing code be audited for these vulnerabilities.
Common applications often choose algorithms
based on their common-case behavior, expecting
the worst-case to never occur in practice. This pa-
per shows that such design choices introduce vul-
nerabilities that can and should be patched by using
more robust algorithms. We showed how univer-
sal hashing demonstrates impressive performance,
suitable for use in virtually any application.
While this paper has focused on a handful of soft-
ware systems, an interesting area for future research
will be to study the algorithms used by embed-
ded systems, such as routers, ﬁrewalls, and other
networking devices. For example, many “stateful”
2http://www.cs.rice.edu/˜scrosby/hash/
ﬁrewalls likely use simple data structures to store
this state. Anyone who can learn the ﬁrewall’s al-
gorithms may be able to mount DoS attacks against
those systems.
Acknowledgements
The authors gratefully thank John Garvin for his
help in the analysis of the Squid web proxy and
Algis Rudys and David Rawlings for their careful
reading and comments. We also thank David Wag-
ner and Dan Boneh for helpful discussions on uni-
versal hashing.
This work is supported by NSF Grant CCR-
9985332 and Texas ATP grant #03604-0053-2001
and by gifts from Microsoft and Schlumberger.
References
[1] G. M. Adel’son-Vel’skii and Y. M. Landis. An al-
gorithm for the organization of information. Soviet
Mathematics Doklady, 3:1259–1262, 1962.
[2] Aleph1.
Smashing the stack for
fun and
proﬁt. Phrack #49, Nov. 1996. http://www.
phrack.org/show.php?p=49&a=14.
[3] D. J. Bernstein.
Floating-point arithmetic and
message authentication. http://cr.yp.to/
papers/hash127.ps, March 2000.
[4] J. Black, S. Halevi, H. Krawczyk, T. Krovetz,
UMAC: Fast and secure
and P. Rogaway.
message authentication.
In Advances in Cryp-
tology – CRYPTO 99, pages 215–233, 99.
see also, http://www.cs.ucdavis.edu/
˜rogagay/umac/.
[5] J. L. Carter and M. N. Wegman. Universal classes
of hash functions. Journal of Computer and System
Sciences (JCSS), 18(2):143–154, Apr. 1979.
[6] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.
Introduction to Algorithms. MIT Electrical Engi-
neering and Computer Science Series. MIT Press,
1990.
[7] P. B. Danzig, R. S. Hall, and M. F. Schwartz. A
case for caching ﬁle objects inside internetworks.
USENIX Association
12th USENIX Security Symposium 
43
In Proceedings of the ACM SIGCOMM ’93 Con-
ference on Communication Architectures, Proto-
cols, and Applications, pages 239–248, San Fran-
cisco, CA, Sept. 1993.
[19] D.-E. C. Smorgrav. YA Apache DoS attack.
http:
Bugtraq mailing list, August 1998.
//lists.nas.nasa.gov/archives/
ext/bugtraq/1998/08/msg00060.html.
[20] F. Weimer. Private communication, Apr. 2003.
[21] D. Wessels and K. Claffey. Application of Internet
Cache Protocol (ICP), version 2. Technical Re-
port RFC-2187, Internet Engineering Task Force,
Sept. 1997. ftp://ftp.rfc-editor.org/
in-notes/rfc2187.txt.
[8] D. Dean and A. Stubbleﬁeld. Using client puz-
zles to protect TLS.
In Proceedings of the 10th
USENIX Security Symposium, Washington, D.C.,
Aug. 2001.
[9] C. Dwork and M. Naor. Pricing via processing
or combatting junk mail. Advances in Cryptology
CRYPTO ’92, 740:139–147, August 1992.
[10] S. Garﬁnkel. Script for a king. HotWired Packet,
Nov. 1996. http://hotwired.lycos.com/
packet/garfinkel/96/45/geek.html,
and see http://simson.vineyard.net/
table.html for the table attack.
[11] L. J. Guibas and R. Sedgewick. A dichromatic
framework for balanced trees.
In Proceedings of
19th Foundations of Computer Science, pages 8–
21, 1978.
[12] H. Krawczyk, M. Bellare, and R. Canetti. HMAC:
Keyed-hashing for message authentication. Tech-
nical Report RFC-2104, Internet Engineering Task
Force, Feb. 1997. ftp://ftp.rfc-editor.
org/in-notes/rfc2104.txt.
[13] S. McCanne and V. Jacobson. The BSD packet ﬁl-
ter: A new architecture for user-level packet cap-
ture.
In USENIX Annual Technical Conference,
pages 259–270, San Diego, California, Jan. 1993.
[14] National Laboratory for Applied Network Re-
search. The Squid Internet object cache. http:
//www.squid-cache.org.
[15] V. Paxson. Bro: a system for detecting network
intruders in real-time. Computer Networks, 31(23–
24):2435–2463, 1999.
[16] X. Qie, R. Pang, and L. Peterson. Defensive Pro-
gramming: Using an Annotation Toolkit to Build
Dos-Resistant Software.
In Proceedings of the
Fifth Symposium on Operating Systems Design
and Implementation, Boston, MA USA, December
2002.
[17] R. Seidel and C. R. Aragon. Randomized search
trees. Algorithmica, 16(4/5):464–497, 1996.
[18] D. D. Sleator and R. E. Tarjan. Self-adjusting bi-
nary search trees. Journal of the ACM (JACM),
32(3):652–686, 1985.
44
12th USENIX Security Symposium 
USENIX Association