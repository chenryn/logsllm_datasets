# Probabilistic Inference on Integrity for Access Behavior-Based Malware Detection

## Authors:
- Weixuan Mao
- Zhongmin Cai
- Don Towsley
- Xiaohong Guan

### Abstract
Integrity protection is a proven method for malware detection and defense. Determining the integrity of subjects (programs) and objects (files and registries) is fundamental to this approach. However, the large number of subjects and objects, along with their complex behaviors, makes it challenging to manually or rule-based determine their integrity. In this paper, we propose a probabilistic model of integrity in modern operating systems. Our model is based on two primary security policies: "no read down" and "no write up," which establish connections between observed access behaviors and the inherent integrity ordering between pairs of subjects and objects. We use a message-passing-based inference to determine the integrity of subjects and objects under a probabilistic graphical model. Additionally, by leveraging a statistical classifier, we build an integrity-based access behavior model for malware detection. Extensive experimental results on a real-world dataset demonstrate that our model can detect 7,257 malware samples from 2,840 benign processes with a 99.88% true positive rate and a 0.1% false positive rate, indicating the feasibility of our probabilistic integrity model.

**Keywords:** Probabilistic graphical model, Integrity protection, Malware detection

## 1. Introduction
Despite significant efforts by security researchers and engineers, attackers continue to develop new malicious code (malware). A recent Symantec security threat report states that over 317 million new pieces of malware were created in 2014, a 26% increase from 2013 [27]. Given the ever-growing and increasingly sophisticated nature of malware, it is crucial to develop more effective defenses from essential security perspectives [28].

Integrity protection has been shown to be an effective method for malware detection and defense [4, 7, 23, 28]. Determining the integrity of subjects and objects is fundamental to this approach [26]. The integrity of a subject or object refers to the trustworthiness of its contents, typically divided into levels such as trusted and untrusted, high and low. Integrity protection aims to prevent trusted objects from being accessed inappropriately, e.g., forbidding an untrusted program from writing to a trusted file. Previous work often defines the number of integrity levels manually and assigns them either manually or by rules. For example, previous studies usually define two integrity levels [4, 7, 26]. Sun et al. treat media players and games as having low integrity [26], while LOMAC treats system files as having high integrity and uses a rule to assign a subject a low integrity if it reads an object with low integrity [7]. Windows Vista treats Internet Explorer as having low integrity and Vista files as having high integrity [11].

Manually defining integrity levels is feasible when the number of subjects and objects is small and their behaviors are simple. However, in a modern operating system with hundreds of thousands of subjects and objects, manual assignment is challenging and error-prone. Moreover, the intricate behaviors of subjects make it inflexible and non-adaptive to assign integrity levels by rules.

This paper aims to determine integrity levels for all system subjects (programs) and system objects (files and registries) based on the access behaviors of benign programs. Our method builds on two primary security policies: "no read down" and "no write up." These policies, first proposed by Biba [4], form the basis of integrity protections in modern operating systems [7, 12, 26]. Unlike earlier work, our method does not assume a fixed number of integrity levels and does not require knowledge from previous attacks.

The integrity level of system subjects and objects may change in different executions and contexts. We model integrity levels as random variables to capture these uncertainties. Each observation of access behavior, involving a pair of system subject and object, implies an ordering of their integrity levels according to the "no read down" and "no write up" security policies. This ordering defines a joint integrity level (joint distribution) of the subject-object pair. We build a probabilistic generative model to capture these connections and derive the joint distribution of the integrity levels of each pair based on observations of access behaviors of benign programs. To obtain the integrity levels of each subject and object, we aggregate the joint integrity level of each pair to build a pairwise Markov network. We then employ message-passing-based inference, specifically loopy belief propagation, to determine the integrity levels of all subjects and objects.

Furthermore, we use a statistical classifier to build an integrity-based access behavior model for malware detection. Our experiments on a real-world dataset consisting of 27,840 executions of 534 benign programs and 7,257 executions of malicious programs demonstrate the effectiveness of our model. Our results show a 99.88% true positive rate at a 0.1% false positive rate, indicating the feasibility and capability of our model.

The contributions of this paper are:
- **Modeling integrity levels**: We propose a probabilistic generative model to capture the connection between the joint integrity level of each pair of system subjects and objects, and observations of access behaviors of benign programs, corresponding to "no read down" and "no write up" security policies.
- **Probabilistic graphical model**: We build a probabilistic graphical model, a pairwise Markov network, to characterize joint integrity levels of all pairs and use message-passing-based inference to further characterize the integrity levels of all subjects and objects.
- **Integrity-based access behavior model**: We employ a statistical classifier, random forest, to build an access behavior model for malware detection based on the integrity levels of accessed objects of programs.
- **Experimental results**: Extensive experimental results on a real-world dataset demonstrate the feasibility and capability of our model. On a dataset consisting of 27,840 executions of 534 benign programs and 7,257 executions of malicious programs, our experimental results exhibit a 99.88% true positive rate at a 0.1% false positive rate.

The rest of the paper is organized as follows. Section 2 introduces the background and related work. Section 3 explains our probabilistic integrity model and inference, and our model of malware detection. Section 4 presents our experimental results, and Section 5 concludes our work and discusses future directions.

## 2. Background and Related Work
### 2.1. Integrity Protection
Integrity protection has been demonstrated to be an effective way of protecting modern operating systems [7, 12, 23, 26]. It determines when information flows are allowed based on the integrity levels of subjects and objects. One of the most fundamental and well-known integrity protection models is the Biba model [4], which defines the following policies:
- **No Read Down (NRD)**: A subject is allowed to read an object only if its integrity is lower than or equal to that of the object.
- **No Write Up (NWU)**: A subject is allowed to write an object only if its integrity is higher than or equal to that of the object.

The Biba model provides security policies for integrity protection and was initially proposed as a mandatory access control (MAC) model in military and government systems. However, the Biba model is too restrictive for modern operating systems [21]. Follow-up research aimed to build a more applicable model from two perspectives:
1. Determine the integrity level of subjects and objects.
2. Devise policies for these integrity levels.

Prior work assigns integrity levels to subjects and objects and devises policies under integrity levels either manually or by rules [7, 23, 26]. LOMAC, a Linux extension of the Biba model, defines two integrity levels, high and low. System files are assigned high integrity levels, and the network is assigned a low integrity level. LOMAC changes the integrity level of subjects and objects according to the low water mark principle, i.e., if a subject with high integrity reads an object with low integrity, the integrity of the subject is assigned to low [7]. This provides a mechanism for capturing changes in the integrity levels of subjects and objects dynamically. However, its way of determining static integrity levels relies on limited rules.

Sun et al. devise elaborate rules to assign integrity levels, either high or low, to subjects and objects and define policies based on their experiences with benign and malicious information flow [26]. In their later work, they apply integrity protection with similar policies to software installation and propose a Secure Software Installer to prevent untrusted software from modifying files used by trusted software [25]. Their rules require a large number of examples of both attacks and defenses. Although these rules may provide effective protection, it is expensive to devise such rules and difficult to make them flexible enough to deal with newly emerging attacks and benign programs.

Hsu et al. provide a framework for recovering from malicious programs and their effects based on integrity. They focus on the NRD policy because they do not aim to prevent malware but only to recover from intrusions [12]. Mao et al. leverage graph centrality to measure the importance of system subjects and objects, which is treated as a proxy for integrity [20]. However, there is still a gap between the importance of graph structure and integrity in operating systems. Besides these efforts by security researchers, one commercial example is the Mandatory Integrity Control (MIC) in Windows Vista. It labels the integrity levels of file objects as Low, Medium, High, or System. By default, critical Vista files are labeled System, other objects are labeled Medium, and Internet Explorer is labeled Low. MIC designs policies to enforce security with the help of user account control (UAC) [1, 11, 19]. However, it heavily relies on user judgment, making it unusable for ordinary users [3].

Previous integrity protection models suffer from two shortcomings:
1. **Determining integrity levels**: It is difficult to determine the integrity levels of all subjects and objects, given the large number and complex behaviors between them. Prior work usually manually assigns integrity levels to a small subset of subjects and objects based on their experiences with attacks and then uses a rule-based approach to determine others [7, 11, 25, 26]. Unlike prior work, which predefines the number of possible integrity levels, we make no assumption about the number of integrity levels in operating systems but determine it from access behaviors of benign programs.
2. **Mandatory control policies and manually devised rules**: These cannot accommodate real-world operations very well without numerous exceptions in the face of crafty attackers and diverse benign programs. We employ a statistical classifier to extract policies for benign and malicious programs with respect to their access behaviors under our integrity levels.

### 2.2. Behavior-Based Malware Detection
Prior work on behavior-based malware detection typically employs heuristic, rule-based, or statistical learning algorithms to construct behavior models or specifications for programs [2, 6, 8, 16, 17]. While successful in trading off false positives against false negatives, it relies solely on statistical discriminations between benign and malicious programs and neglects the essence of malware from a security perspective, i.e., violations of security policies. Our method leverages the integrity level of objects involved in access behaviors, paying more attention to violations of security policies of programs. Under the integrity level derived from our model, we observe discriminations not only in statistics but also from a security perspective in our experimental results.

## 3. Methodology
### 3.1. Overview
In this section, we present our method for deriving integrity levels of system subjects and objects and for malware detection. Our method consists of two components:
1. **Probabilistic integrity model and inference**.
2. **Malware detection utilizing the integrity levels**.

Figure 1 illustrates the framework of our method.

#### Figure 1. Framework of our method for deriving integrity levels and malware detection
```
Access Behaviors
of Benign Programs
I(s)
I(o)
P(I(s), I(o))
s1
...
sn
Probabilistic Generative Model
P(I(s1), I(oi))
...
P(Isn), I(om))
pMN
o1
...
om
loopy BP
Integrity Levels
Access Behaviors
of Malicious Programs
Malware Detection
Feature Vectors
Statistical Classifier
Access Behavior
Model
```

Since the integrity levels of system subjects (programs) and objects (files or registries) may change in different executions and contexts, we represent the integrity levels as random variables to capture their uncertainties in real operating systems. The first component of our method, the probabilistic integrity model and inference, consists of two steps:
1. **Infer the joint integrity level (joint distribution) of each subject-object pair**: Given all observed access behaviors, we infer the joint integrity level (joint distribution) of each subject-object pair under a proposed probabilistic generative model for access behaviors. Depending on which of the two primary security policies (NRD and NWU) applies, each observed access behavior implies an ordering of the integrity levels of a subject-object pair. The possible orderings include <, =, and >. The orderings within a subject-object pair imply its joint integrity level (joint distribution).
2. **Construct a pairwise Markov network (pMN)**: We aggregate the joint distributions of integrity levels for all pairs of subjects and objects to construct a pMN that provides a joint distribution of integrity levels for all subjects and objects. Our goal is to characterize the distribution of the integrity levels of each subject and object from the pMN. We employ loopy belief propagation (loopy BP), a message-passing approximate inference algorithm, to infer the marginal distributions of the integrity levels for subjects and objects.

Once we characterize the integrity levels, we extract feature vectors to describe the access behaviors of programs. Using a statistical classifier, we build a model of malware detection that accounts for the security meanings of access behaviors. In this paper, we focus on system subjects and objects, i.e., programs, files, and registries.

### 3.2. Probabilistic Integrity Model
**Probabilistic Integrity and Pairwise Relationship**: Determining the exact integrity level of subjects and objects is challenging. For example, due to varying behaviors and intents, a program may exhibit different integrity levels in different executions and contexts. Meanwhile, the integrity level of a file or registry, accessed by these programs, may change according to security policies, such as the low/high water mark principle [7]. We capture these uncertainties by modeling the integrity level of subjects and objects as random variables and make two primary assumptions in this paper:
1. **Random Variable Assumption**: We assume the integrity level of each subject or object \(i\) is a random variable \(I(i) \in \{L, H\}\), where \(L\) and \(H\) indicate low and high integrity levels.
2. **Security Policy Compliance**: We assume observed access behaviors of benign programs obey the security policies NRD and NWU to ensure a secure operating system.

For each subject-object pair \((s, o)\), we denote their joint integrity level as a random variable \(JI(s, o)\), where \(P(JI(s, o) = (x, y)) = P(I(s) = x, I(o) = y)\), and \(x, y \in \{L, H\}\). Given a pair of integrity levels \((x, y)\), we say that \(x < y\), \(x = y\), or \(x > y\). Note that the integrity level of \(s\) may be higher than that of \(o\) in one execution but lower in another. Therefore, we represent the order between \(s\) and \(o\) as a random variable \(EI(s, o)\) with three possible values, i.e., \(EI(s, o) \in \{I(s) < I(o), I(s) = I(o), I(s) > I(o)\}\).

Thus, we obtain \(P(JI|EI)\) by \(P(JI|EI) = P(EI|JI)P(JI) / P(EI)\) as follows:
- **If \(EI\) is \(I(s) < I(o)\)**, then:
  \[
  P(JI = (L, H)|EI) = 1; \text{ otherwise, } 0.
  \]
- **If \(EI\) is \(I(s) = I(o)\)**, then:
  \[
  P(JI = (L, L)|EI) = P(LL), \quad P(JI = (H, H)|EI) = P(HH); \text{ otherwise, } 0,
  \]
  where \(P(LL) = \frac{P(JI = (L, L))}{P(JI = (L, L)) + P(JI = (H, H))}\) and \(P(HH) = \frac{P(JI = (H, H))}{P(JI = (L, L)) + P(JI = (H, H))}\).

## 4. Experimental Results
We conduct a set of experiments to evaluate our model by comparing it with baseline models on a dataset consisting of 27,840 executions of 534 benign programs and 7,257 executions of malicious programs. Our encouraging results demonstrate the usefulness of our access behavior model for malware detection based on determined integrity levels and the feasibility of our model in determining integrity levels for system subjects and objects.

Our experimental results show a 99.88% true positive rate at a 0.1% false positive rate, indicating the effectiveness of our model in detecting malware.

## 5. Conclusion and Future Work
In this paper, we propose a probabilistic model of integrity in modern operating systems. Our model is based on two primary security policies: "no read down" and "no write up," which establish connections between observed access behaviors and the inherent integrity ordering between pairs of subjects and objects. We use a message-passing-based inference to determine the integrity of subjects and objects under a probabilistic graphical model. Additionally, we build an integrity-based access behavior model for malware detection using a statistical classifier.

Extensive experimental results on a real-world dataset demonstrate the feasibility and capability of our model. Our results show a 99.88% true positive rate at a 0.1% false positive rate, indicating the effectiveness of our model in detecting malware.

Future work will focus on extending our model to handle more complex and dynamic environments, incorporating additional security policies, and improving the scalability of our approach.