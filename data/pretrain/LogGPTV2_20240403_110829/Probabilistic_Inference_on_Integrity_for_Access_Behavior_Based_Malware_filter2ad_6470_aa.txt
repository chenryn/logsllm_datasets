title:Probabilistic Inference on Integrity for Access Behavior Based Malware
Detection
author:Weixuan Mao and
Zhongmin Cai and
Don Towsley and
Xiaohong Guan
Probabilistic Inference on Integrity
for Access Behavior Based Malware Detection
Weixuan Mao1, Zhongmin Cai1(B), Don Towsley2, and Xiaohong Guan1
1 MOE KLINNS Lab, Xi’an Jiaotong University, Xi’an, Shaanxi, China
{wxmao,zmcai,xhguan}@sei.xjtu.edu.cn
2 School of Computer Science, University of Massachusetts, Amherst, MA, USA
PI:EMAIL
Abstract. Integrity protection has proven an eﬀective way of malware
detection and defense. Determining the integrity of subjects (programs)
and objects (ﬁles and registries) plays a fundamental role in integrity
protection. However, the large numbers of subjects and objects, and
intricate behaviors place burdens on revealing their integrities either
manually or by a set of rules. In this paper, we propose a probabilis-
tic model of integrity in modern operating system. Our model builds on
two primary security policies, “no read down” and “no write up”, which
make connections between observed access behaviors and the inherent
integrity ordering between pairs of subjects and objects. We employ a
message passing based inference to determine the integrity of subjects
and objects under a probabilistic graphical model. Furthermore, by lever-
aging a statistical classiﬁer, we build an integrity based access behavior
model for malware detection. Extensive experimental results on a real-
world dataset demonstrate that our model is capable of detecting 7,257
malware samples from 27,840 benign processes at 99.88 % true positive
rate under 0.1 % false positive rate. These results indicate the feasibility
of our probabilistic integrity model.
Keywords: Probabilistic graphical model · Integrity protection ·
Malware
1 Introduction
In spite of considerate eﬀort by security researchers and engineers, attackers
continue to craft malicious code (malware). A recent security threat report by
Symantec states that there were more than 317 million new pieces of malware
created in 2014, which is 26 % more than in 2013 [27]. Being faced with ever-
growing and increasingly sophisticated malware, it is important to develop more
eﬀective defenses from essential perspectives of security [28].
Integrity protection has proven an eﬀective way of malware detection and
defense [4,7,23,28]. Determining the integrity of subjects and objects is funda-
mental to integrity protection [26]. The integrity of a subject or an object refers
to the trustworthiness of its contents. Integrity is typically divided into levels,
c(cid:2) Springer International Publishing Switzerland 2015
H. Bos et al. (Eds.): RAID 2015, LNCS 9404, pp. 155–176, 2015.
DOI: 10.1007/978-3-319-26362-5 8
156
W. Mao et al.
e.g., trusted and untrusted, high and low, etc. Integrity protection aims at pre-
venting trusted objects from being accessed inappropriately, e.g., it forbids an
untrusted program from writing a trusted ﬁle. Prior work manually deﬁnes the
number of integrity levels, and assigns integrity levels to subjects and objects
either manually or by rules. For example, previous work usually deﬁnes two
integrity levels [4,7,26]. Learning from previous attacks, Sun et al. treat Media
players and games as having low integrity [26], LOMAC treats system ﬁles as
having high integrity, and builds on a rule that assigns a subject a low integrity,
if it read an object with low integrity [7]. Windows Vista treats Internet Explorer
as having low integrity, and Vista ﬁles as having high integrity [11]. It is feasible
to deﬁne integrity levels either manually or by rules, when the number of subjects
and objects is small, and the behaviors of subjects are simple. However, given
hundreds of thousands subjects and objects in a modern operating system, it
is challenging and error-prone to assign integrity levels to all of them manually.
And, given the intricate behaviors of subjects, it is neither ﬂexible nor adaptive
to assign integrity levels to them by rules.
This paper aims to determine integrity levels for all system subjects, i.e., pro-
grams, and system objects, i.e., ﬁles and registries, based on access behaviors of
benign programs. Our method builds on two primary security policies, “no read
down” and “no write up”. These two policies, ﬁrst proposed by Biba [4], have
become the basis of integrity protections in modern operating systems [7,12,26].
These policies make connections between integrity levels and access behaviors.
Our method determines the integrity levels of subjects and objects based on these
connections. Unlike earlier work, it makes no assumption of the total number of
integrity levels and needs no knowledge obtained from previous attacks.
The integrity level of system subjects and objects may change in diﬀerent exe-
cutions and contexts. We model integrity levels as random variables to capture
their uncertainties. Meanwhile, each observation of access behavior, involving a
pair of system subject and object, implies an ordering of their integrity levels
between them, according to “no read down” and “no write up” security policies.
This ordering of integrity level deﬁnes a joint integrity level (joint distribution)
of the subject-object pair. Thus, we build a probabilistic generative model to
capture these connections, and derive the joint distribution of the integrity lev-
els of each pair, based on observations of access behaviors of benign programs.
To obtain the integrity levels of each subject and object, we aggregate the joint
integrity level of each pair to build a pairwise Markov network. We then employ
message passing based inference on this pairwise Markov network, i.e., loopy
belief propagation, to obtain integrity levels of all subjects and objects.
Furthermore, we employ a statistical classiﬁer to build an integrity based
access behavior model for malware detection. We conduct a set of experiments
to evaluate our model by comparing with baseline models, on a data set con-
sisting of 27,840 executions of 534 benign programs and 7,257 executions of
malicious programs. Our encouraging results demonstrate the usefulness of our
access behavior model for malware detection based on determined integrity
Probabilistic Inference on Integrity for Access Behavior
157
levels, and the feasibility of our model on determining integrity levels for system
subjects and objects.
The contributions of this paper are summarized as follows:
– Modeling integrity level of system subjects and objects under two primary
security policies. We propose a probabilistic generative model to capture the
connection between the joint integrity level of each pair of system subjects
and objects, and observations of access behaviors of benign programs, corre-
sponding to “no read down”and “no write up” security policies.
– Probabilistic graphical model on joint integrity levels of all subject-object
pairs. We build a probabilistic graphical model, pairwise Markov network, to
characterize joint integrity levels of all pairs, and leverage a message passing
based inference to further characterize integrity levels of all subjects and
objects.
– An integrity based access behavior model for malware detection. We employ
a statistical classiﬁer, random forest, to build an access behavior model for
malware detection, based on integrity levels of accessed objects of programs.
– Extensive experimental results on a real data set demonstrate the feasibility
and capability of our model. On a data set consisting of 27,840 executions
of 534 benign programs and 7,257 executions of malicious programs, our
experimental results of malware detection exhibit a 99.88 % true positive
rate at 0.1 % false positive rate.
The paper is organized as follows. We ﬁrst introduce the background and
related work in Sect. 2. We then explain our probabilistic integrity model and
inference, and our model of malware detection in Sect. 3. After demonstrating
our experimental results in Sect. 4, Sect. 5 concludes our work and states future
work.
2 Background and Related Work
2.1 Integrity Protection
Integrity protection has been demonstrated to be an eﬀective way of protecting
modern operating systems [7,12,23,26]. It determines when information ﬂows are
allowed based on the integrity levels of subjects and objects. One of the most
fundamental and well-known integrity protection models is the Biba model [4],
which deﬁnes policies as follows.
– A subject is allowed to read an object only if its integrity is lower than or
equal to that of the object (no read down).
– A subject is allowed to write an object only if its integrity is higher than or
equal to that of the object (no write up).
The Biba model provides security policies for integrity protection, and was
initially proposed as a mandatory access control (MAC) model in military, gov-
ernment systems. We refer to “no read down” as NRD, and “no write up” as
158
W. Mao et al.
NWU in the following paper. However, Biba is too restrictive for modern oper-
ating systems [21]. Follow-up research aimed to build a more applicable model
from two perspectives: (1) Determine the integrity level of subjects and objects.
(2) Devise policies for these integrity levels.
Prior work assigns integrity levels to subjects and objects, and devises policies
under integrity levels either manually or by rules [7,23,26]. LOMAC is a Linux
extension of Biba model. It deﬁnes two integrity levels, high and low. System
ﬁles are assigned high integrity levels and the network is assigned a low integrity
level. LOMAC changes the integrity level of subjects and objects according to
the low water mark principle, i.e., if a subject with high integrity reads an object
with low integrity, the integrity of the subject is assigned to low [7]. This pro-
vides a mechanism of capturing changes of integrity levels of subjects and objects
dynamically. However, its way of determining static integrity levels of subjects
and objects relies on limited rules. Sun et al. devise elaborate rules to assign
integrity levels, either high or low, to subjects and objects, and deﬁne policies
based on their experiences on benign and malicious information ﬂow [26]. In
their later work, they apply integrity protection with similar policies into soft-
ware installation, and propose a Secure Software Installer to prevent untrusted
software from modifying ﬁles used by trusted software [25]. Their rules require
a large number of examples of both attacks and defenses. Although these rules
may provide an eﬀective protection, it is expensive to devise such rules, and
diﬃcult to make them ﬂexible enough to deal with newly emerging attacks and
benign programs. Hsu et al. provide a framework for recovering from malicious
programs and their eﬀects based on integrity. They focus on the NRD policy,
because they do not aim to prevent malware but only to recover from intru-
sions [12]. Mao et al. leverage graph centrality to measure the importance of
systems subjects and objects, which is treated as a proxy for integrity [20]. How-
ever, there is still a gap between the importance of graph structure and integrity
in operating systems. Beside these eﬀorts by security researchers, one commercial
example is the Mandatory Integrity Control (MIC) in Windows Vista. It labels
the integrity levels of ﬁle objects as either Low, Medium, High, or System. As a
default, critical Vista ﬁles are labeled System, other objects are labeled Medium,
and Internet Explorer is labeled Low. MIC designs policies to enforce security
with the help of user account control (UAC) [1,11,19]. However, it highly relies
on judgment of users, which makes it unusable for ordinary users [3].
Previous integrity protection model suﬀer from two shortcomings. Firstly, it
is diﬃcult to determine the integrity levels of all subjects and objects, as there are
hundreds of thousands and intricate behaviors between them. Prior work usually
manually assigns integrity levels to a small subset of subjects and objects based
on their experiences in attacks, and then uses a rule-based approach to determine
others [7,11,25,26]. Unlike prior work, which predeﬁnes the number of possible
integrity levels, we make no assumption about the number of integrity levels in
operating systems, but determine it from access behaviors of benign programs.
We aim to determine the integrity level for each subject and object, relying on
knowledge of benign programs, but not malicious programs. Secondly, manda-
Probabilistic Inference on Integrity for Access Behavior
159
tory control policies and manually devised rules cannot accommodate real-world
operation very well without the introduction of numerous exceptions in the face
of crafty attackers and diverse benign programs. We employ a statistical classi-
ﬁer to extract policies for benign and malicious programs with respect to their
access behaviors under our integrity levels.
2.2 Behavior Based Malware Detection
Prior work on behavior based malware detection usually employs heuristic, rule-
based or statistical learning algorithms to construct behavior models or speciﬁca-
tions for programs [2,6,8,16,17]. It successfully trades false positives oﬀ against
false negatives. However, it relies on statistical discriminations between benign
and malicious programs only, and neglects the essence of malware from a secu-
rity perspective, i.e., violations of security policies. Our method leverages the
integrity level of objects involved in access behaviors, which pays more attention
to violations of security policies of programs. Under the integrity level derived
from our model, we observe discriminations not only in statistics, but also from
a security perspective in our experimental results.
3 Methodology
3.1 Overview
In this section, we present our method for deriving integrity levels of system
subjects and objects, and malware detection. It consists of two components:
(1) Probabilistic integrity model and inference. (2) Malware detection utilizing
the integrity levels. Figure 1 illustrates the framework of our method in this
paper.
Probabilistic Integrity Model and Inference
Access Behaviors
of Benign Programs
I(s)
I(o)
P(I(s), I(o))
s1
·
·
·
sn
Probabilistic Generative Model
P(I(s 1
P(I(s
·
·
·
1),
I(
o
i))
oi
P(I(sn),I(oi))
·
·
·
P(I(s
n),
I(
o
m))
om
pMN
))
),I(o 1
Probabilistic Graphical Model
o1
loopy BP
Integrity Levels
Access Behaviors
of Malicious Programs
Malware Detection
Feature Vectors
Statistical Classiﬁer
Access Behavior
Model
Fig. 1. Framework of our method for deriving integrity levels and malware detection
Since the integrity levels of system subjects (programs) and objects (ﬁles
or registries) may change in diﬀerent executions and contexts, we represent the
160
W. Mao et al.
integrity levels as random variables to capture their uncertainties in real oper-
ating systems. The ﬁrst component of our method, probabilistic integrity model
and inference, consists of two steps: (i) Given all observed access behaviors,
we infer the joint integrity level (joint distribution) of each subject-object pair,
under proposed a probabilistic generative model for access behaviors. Depend-
ing on which of the two primary security policies NRD and NWU applies, each
observed access behavior implies an ordering of the integrity levels of a subject-
object pair. The possible orderings include . Moreover, the orderings
within a subject-object pair implies its joint integrity level (joint distribution).
(ii) We aggregate the joint distributions of integrity levels for all pairs of subjects
and objects to construct a pairwise Markov network (pMN) that provides a joint
distribution of integrity levels for all subjects and objects. Our goal is to charac-
terize the distribution of the integrity levels of each subject and object from the
pMN. Furthermore, we employ loopy belief propagation (loopy BP), a message
passing approximate inference algorithm, to infer the marginal distributions of
the integrity levels for subjects and objects.
Once we characterize the integrity levels, we extract feature vectors to describe
access behaviors of programs. Resorting to a statistical classiﬁer, we build a model
of malware detection, that accounts for the security meanings of access behaviors.
In this paper, we focus on system subjects and objects, i.e., programs, ﬁles and
registries.
3.2 Probabilistic Integrity Model
Probabilistic Integrity and Pairwise Relationship. It is not easy to deter-
mine the exact integrity level of subjects and objects. For example, due to the
varying behaviors and intents, a program may exhibit diﬀerent integrity levels in
diﬀerent executions and contexts. Meanwhile, accessed by these programs, the
integrity level of a ﬁle or registry may be changed according to security policies,
e.g., low/high water mark principle [7], etc. We capture these uncertainties by
modeling the integrity level of subjects and objects as random variables, and
make two primary assumptions in this paper.
Primary assumptions: (1) We assume the integrity level of each subject or
object i is a random variable I(i) ∈ {L, H}, where L and H indicate low and high
integrity levels. (2) We assume observed access behaviors of benign programs
obey security policies NRD and NWU to ensure a secure operating system.
For each subject-object pair (s, o), we denote their joint integrity level as a
random variable JI(s, o), where P (JI(s, o) = (x, y)) = P (I(s) = x, I(o) = y),
x, y ∈ {L, H}. Meanwhile, given a pair of integrity levels (x, y), we say that
x  I(o). Note that, the integrity level of s may be higher than that of o
in one execution, but lower than that of o in another execution. Therefore, we
represent the order between s and o as a random variable EI(s, o) with three
possible values, i.e., EI(s, o) ∈ {I(s)  I(o)}. Thus, we
obtain P (JI|EI) by P (JI|EI) = P (EI|JI )P (JI )
∝ P (EI|JI)P (JI) as follows.
P (EI )
Probabilistic Inference on Integrity for Access Behavior
161
(1) If EI is I(s) < I(o), then,
P (JI = (L, H)|EI) = 1; otherwise, 0.
(1)
(2) If EI is I(s) = I(o), then,
P (JI = (L, L)|EI) = P (LL), P (JI = (H, H)|EI) = P (HH); otherwise, 0,
(2)
where P (LL) =
P (JI =(L,L))+P (JI =(H,H)), P (HH) =
P (JI =(L,L))
P (JI =(H,H))