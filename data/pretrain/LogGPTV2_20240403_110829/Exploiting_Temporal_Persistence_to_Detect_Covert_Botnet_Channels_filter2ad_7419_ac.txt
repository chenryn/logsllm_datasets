1
8
4
1
9
19672
min - max
0-5.7
0-6.8
0.2-2.1
0-9.2
0-10
0-1.
0-1.3
0-2.1 8
3.8-4.6
0-0.1
0-1
0-30
of non-IRC communications, and in some cases examining histograms of pay-
load size to extract unusual patterns (i.e. very high chance of small packet sizes
consistent across a subset of connections). As an interesting example, consider
Trojan.AimBot-5. First we constructed histograms of traﬃc to various destina-
tions and on various ports. In this particular case, the communication involved
a few destinations. By zooming in on these individual connections and recon-
structing the associated TCP streams we obtained a “conversation” between the
zombie and the signiﬁcant destination. We were able to identify IRC protocol
commands being tunneled over HTTP to particular destinations. Further analy-
sis revealed that the destination being contacted was hosting a squid proxy, and
the IRC commands were being tunneled through. In case of the Storm botnet
trace, we were able to pick out the p2p traﬃc from the packet size distribu-
tions (the UDP traﬃc used to communicate with the p2p network had a very
diﬀerent characteristic from the other, presumably attack, traﬃc). The second
column in Table 2 describes the ports and protocols associated with the C&C
channel. The third column is a count of the distinct destination atoms seen in
the (isolated) C&C traﬃc. Column 4 shows the range (min to max) of C&C
traﬃc in connections/minute. This conﬁrms our belief that the communication
volume associated with the C&C traﬃc is light and thus volume based detectors
would not be able to easily expose this traﬃc.
5 Evaluation
In this section we present results from overlaying the botnet malware traces on
top of each user trace, and then emulating our detection algorithm to evaluate
the performance of our detector. The two notable results which we discuss further
in this section are: (i) our persistence metric based detector can indeed pick out
the C&C destination atoms in the botnet traces with a very low false positive
rate, (ii) the whitelists we construct can signiﬁcantly boost the detection rates,
and improve detection times, of well established volume anomaly detectors.
Exploiting Temporal Persistence to Detect Covert Botnet Channels
337
5.1 System Properties
As mentioned earlier, for our system to work well, the whitelists should have two
properties. First, they should be stable, i.e., they need to be updated infrequently
(so that bot C&C will stand out and user annoyance is kept small). Second, it is
desirable that they be small, as this speeds up the searching activity (matching
outgoing traﬃc against whitelist contents). Our whitelists will be stable if the
rate at which new persistent destination atoms are added to the whitelist is
low; and this will be true when much of the user communication is transient. To
examine this for our set of users, we compute all the destination atoms for a given
user and the persistence value for each atom. The cumulative distribution of these
across all users is plotted in Figure 2. We see that less than 20% of the destination
atoms have a persistence value greater than 0.2; this validates our intuition that
transient destinations form the bulk of endpoints a host communicates with. Very
few destination atoms exhibit a persistence greater than 70%. The observation
that any user typically has few persistent destination atoms conﬁrms that a
whitelist consisting of these atoms is unlikely to be updated often. Recall that
our method uses a parameter p∗, that is used both to construct the whitelists
in the training stage, and as an alert threshold when monitoring for new C&C
destination during detection (testing phase). This plot of user data suggests that
selecting a value of p∗ anywhere in the range of 50 to 80% will result in a small
whitelist, that is likely to require few updates. We select the value of p∗ = 0.6
because it is in the ﬂat portion of the curve. Note that the number of destination
atoms in the whitelist is not very sensitive to the value of p∗ (as long as it is above
roughly 0.5) suggesting that this parameter is fairly robust in the sense that it
need not necessarily be ﬁne tuned. In ﬁgure 3, we plot the histogram of whitelist
sizes across all the 157 users. The whitelists for almost all the hosts contain
60-140 destination atoms, which is a very manageable size and thus limits any
overhead involved in searching whitelists when ﬁltering. Thus our user traﬃc
traces conﬁrms that whitelists constructed of persistent destination atoms will
have the two desirable properties which will enable our detection method to be
eﬀective.
Fig. 2. CDF of destination atom persis-
tence across all atoms seen in training
data
Fig. 3. Distribution of per host whitelist
size (using p∗
= 0.6)
338
F. Giroire et al.
Ideally, we would have liked to verify these properties over a much longer
period. However collecting user traces, particularly over an extended period and
a sizeable population is extremely challenging. Nor are there public repositories
of such data that can be used. While we cannot prove this conclusively, there are
certain observations to be made from the traces we use which lead us to believe
that the properties are likely to hold over a longer period. One of these is that
we see few false positives in the C&C detection (§˜refsec:sec:ccdetection), which
essentially determines how the whitelist sizes will grow over time.
5.2 C&C Detection
To assess the ability of our algorithm to identify C&C traﬃc when it is mixed in
with regular user traﬃc, we overlaid each botnet trace on each of our 157 user
traces and ran this traﬃc through our detector (12 botnets × 157 users = 1884
traces). The detector was conﬁgured to use 5 distinct timescales (as discussed in
Section 3). The timescales used were with measurement window s taking values
s = (1, 4, 8, 16, 20, 24), and the observation window W was always W = 10s,
i.e. we used (1,10), (4,40), etc. In each of these 1884 instances, our detector
was able to correctly identify the C&C traﬃc. This was validated against the
labels determined earlier (from having isolated the portion of the bot traﬃc
corresponding to the C&C channel). This success illustrates the eﬀectiveness of
our persistence metric in detecting botnet C&C activity.
In Table 3 we list various properties of the detected botnets. Column 2 in-
dicates the persistence of a destination atom from a particular bot. Column 3
indicates the timescale that triggered the alert, and the 4th column enumerates
the speciﬁc number of destination atoms that were associated with (persistence
and timescale) listed in the same row. For example, we see IRCBot-776 listed
twice (ﬁrst two rows of this table) because it used one destination atom that had
a persistence of 1 and was detected at a timescale of (10,1), and it had 2 other
destination atoms with a persistence of 0.8 that were detected at a timescale
of (200,20). This example illustrates that a single zombie might used multiple
time scales (in terms of how regularly they contact their botmasters) on diﬀerent
C&C servers. Looking down column 3, we see that the smallest timescale (10,1)
was suﬃcient to detect at least one of the atoms in all instances except in the
case of IRC.Zapchast-11 and Mybot-8926. However, we cannot know ahead of
time as to what timescale is appropriate for a particular botnet; thus it is critical
to have enough timescales in play to cover a wide range of behaviors. For the
STORM bot, we have marked ”> 1” in the last column because there a great
many of them. The success of our method in uncovering the STORM bot C&C
traﬃc brings up an interesting point: even though our method works best to
uncover botnets that tend to have a high degree of centralization, we are able to
detect the p2p based infrastructure used by the Storm botnet. Thus, our method
is likely to be eﬀective at also uncovering non-centralized infrastructures as long
as there is a certain repetitiveness in contacting some of the destination atoms
involved (out of the thousands, in the case of Storm).
Exploiting Temporal Persistence to Detect Covert Botnet Channels
339
Table 3. C&C Detection Performance
Botnet
IRCBot-776
IRCBot-776
Aimbot-5
Aimbot-5
Aimbot-5
MyBot-8926
IRC.Zapchast-11
Spybot-248
IRC-Script-50
VB-666
Codbot-14
Gobot.T
Wootbot-247
IRC.Zapchast-11
Aimbot-25
Peed-69 [Storm]
Persistence Timescale # dest. atoms
1.0
0.8
1.0
1.0
1.0
0.6
1.0
1.0
1.0
0.7
1.0
1.0
1.0
1.0
1.0
1.0
(10,1)
(200,20)
(10,1)
(40,4)
(160,16)
(160,16)
(40,4)
(10,1)
(10,1)
(10,1)
(10,1)
(10,1)
(10,1)
(10,1)
(10,1)
(10,1)
1
2
1
1
1
1
3
2
7
1
1
1
3
6
1
> 1
The bot IRC.Zapchast-11 presents a compelling illustration on how tracking
for persistence can be eﬀective even when the connection volume is extremely
stealthy. Recall from Table 2 that IRC.Zapchast-11 generates very little traﬃc
overall - about 1.4 connections per binning interval on average. By all accounts,
this is a minuscule amount of additional traﬃc, that has no chance to stand
out in traﬃc volume against the normal traﬃc of an end-host, and thus will
go undetected by a volume based anomaly detector. However by tracking the
persistence of its associated destination atom, we were able to make the anomaly
visible. This illustrates the utility of persistence, even in the face of extremely
stealthy bots.
Using our two data sets, we can also compute the false positive and detection
rate (1 - false negative rate) tradeoﬀ. We computed a traditional ROC curve, by
sweeping through a range of values for p∗. The detection rate is computed as the
fraction of the tested botnets, across users, for which an alarm is raised. It should
be clear that the detection rate is independent of user traﬃc (the persistence
value of an atom does not depend on other atoms). The y-axis denotes an average
number of false positives per day. Here, a false positive is simply a destination in
the user traﬃc (assumed clean) which raised an alarm. The values are averaged
across all users and over the last two weeks of user traﬃc data. This ROC curve
is shown in Fig. 4. In an earlier section, we had selected a value for p∗ based upon
properties of the user generated whitelists; we can now determine the optimum
value from the ROC curve. if we set p∗ ≤ 0.6, we are guaranteed to raise an
alarm, for at least one of the atoms, in every botnet trace that we evaluated
against. This brings the detection rate to 1.0. In general, lowering p∗ acts to
increase the detection rate (more botnet atoms cross the persistence bar) but
also increases the false positive rate (more begign atoms also meet the standard).
Selecting p∗ = 0.6 seems balance the tension between these two points. At this
operating point, we are able to detect every botnet and keep the false positives
down to less than 1 a day on average. However, it is also important to study
how this number varies across the user population.
340
F. Giroire et al.
1
0.95
0.9
0.85
e
t
a
R
n
o
i
t
c
e
t
e
D
0.6
0.5
0.3
0.4
0.2
0.1