1.754
2.275
ˆHA
2.515
2.852
3.112
ˆHR
1.999
2.000
1.926
ˆHA
2.209
2.238
2.022
SalaDP ( = 100)
SalaDP ( = 50)
SalaDP ( = 10)
Note that differential privacy guarantees are theoretically
not violated since differential privacy is, by deﬁnition, closed
under post-processing [11]. However, despite these formal
semantic guarantees are still valid, we demonstrate that our
recovery attack can, without additional knowledge about the
data, reduce the magnitude of the actual noise put in place
to perturb the original graph by exploiting the graph structure.
This demonstrates that, by simply looking at the sanitized data,
we can concretely jeopardize the anonymity of the graph.
Graph De-anonymization: We also compare the performance
of the graph de-anonymization attack designed by Narayanan
and Shmatikov [32], referred to as the NS-attack, on both
anonymized and recovered social graphs. Our experiments
show that, contrary to what one might initially expect, graph
recovery does not improve the performance of the graph de-
anonymization signiﬁcantly. Our explanation is that the NS-
attack assumes a much stronger adversary model, such as an
auxiliary graph with seed nodes already de-anonymized (see
Section VI). Moreover, Ji et al. show that, in many cases, the
NS-attack even performs better on the anonymized graph than
on the original graph [18].
VI. ENHANCING GRAPH ANONYMIZATION
In this section, we take the ﬁrst step towards enhancing
the existing graph anonymization mechanisms. We start by
presenting our methodology, then evaluate the performance of
fake edge detection as well as graph utility with the enhanced
mechanisms. In the end, we study our new anonymized graphs’
resistance to graph de-anonymization.
A. Methodology
To improve the graph anonymization mechanisms, intu-
itively, we should add fake edges that are more similar to
edges in the original graph G. Figure 7 depicts the edge
plausibility distributions for the original NO dataset under two
different vector dimensions.6 We observe that both empirical
6We map all users in G into vectors and compute all edges’ plausibility in
G following the same procedure as for GA (Section III).
(a) d = 128
(b) d = 512
Fig. 7: Edge plausibility in the original NO dataset follows a
Gaussian distribution. We choose two vector dimensions for
edge plausibility: (a) d = 128 and (b) d = 512, following the
evaluation results in Section IV.
distributions follow a Gaussian distribution. If we are able to
modify the current graph anonymization mechanisms such that
the plausibility of the added fake edges is more likely to come
from the same Gaussian distribution, it should be harder to
discover these fake edges.
The general procedure for our enhanced anonymization
mechanisms is as follows. We ﬁrst apply maximum likelihood
estimation to learn the Gaussian distribution of edge plausibil-
ity in G, denoted by N (s(u, u(cid:48))|µ,σ), where s(u, u(cid:48)) represents
{u, u(cid:48)
}’s plausibility in G. Then, we conduct the same process
as in k-DA and SalaDP. A loop is performed through all the
users and, in each iteration, if a user u needs m fake edges, we
construct a candidate set γ(u) which includes all the potential
users that could share a fake edge with u (following the
original anonymization mechanisms’ design). Different from
the original approaches of k-DA and SalaDP for choosing m
users out of γ(u), we compute the plausibility between users in
γ(u) and u,7 represented as a set λ(u) = {s(u, v)|v ∈ γ(u)}.
Then, for each plausibility s(u, v) in λ(u), we calculate its
density using the previously learned N (s(u, u(cid:48))|µ,σ), and treat
the density as the weight of the user v in γ(u). Next, we
perform a weighted sampling to choose m users out of γ(u)
and add edges between these users and u. In the end, we
obtain our new anonymized graph GF under the enhanced
mechanisms.
Note that, as presented in Section II, for a user u, SalaDP
chooses m users from γ(u) in a random manner, while k-DA
picks the users with the highest residual degrees. However, the
reason for k-DA to take this approach is to efﬁciently construct
the anonymized graph. Through experiments, we discover that
our enhanced k-DA can also build the anonymized graph in a
similar time.
We emphasize that our enhanced mechanisms do not affect
the privacy criteria of k-DA and SalaDP as they do not modify
the privacy realization process of the original mechanisms. We
will make the source code for the aforementioned enhanced
versions of k-DA and SalaDP publicly available.
7The plausibility is computed over users’ vectors learned from G.
10
−0.20.00.20.40.60.81.0Edgeplausibility012345678Numberofedges×104−0.20.00.20.40.60.81.0Edgeplausibility0.00.20.40.60.81.0Numberofedges×105(a) Enhanced k-DA (k = 50)
(b) Enhanced k-DA (k = 75)
(c) Enhanced SalaDP ( = 100)
(d) Enhanced SalaDP ( = 50)
(e) Enhanced SalaDP ( = 10)
Fig. 8: Plausibility distributions of fake and original edges in the NO dataset anonymized with our enhanced mechanisms. The
result for k-DA (k = 100) is depicted in Figure 1b.
TABLE VII: [Higher is better] AUC scores for detecting fake
edges for both enhanced k-DA and SalaDP on three different
datasets.
TABLE VIII: [Higher is better] F1 scores for detecting fake
edges using GMM and MAP estimate for both enhanced k-DA
and SalaDP on three different datasets.
k-DA (k = 50)
k-DA (k = 75)
k-DA (k = 100)
SalaDP ( = 100)
SalaDP ( = 50)
SalaDP ( = 10)
Enron
0.677
0.728
0.753
0.806
0.794
0.724
NO
0.628
0.676
0.702
0.890
0.895
0.853
SNAP
0.939
0.927
0.896
0.719
0.723
0.723
k-DA (k = 50)
k-DA (k = 75)
k-DA (k = 100)
SalaDP ( = 100)
SalaDP ( = 50)
SalaDP ( = 10)
Enron
0.531
0.428
0.510
0.422
0.390
0.439
NO
0.391
0.433
0.501
0.370
0.411
0.527
SNAP
0.632
0.609
0.597
0.515
0.522
0.490
B. Evaluation
Fake Edge Detection: After obtaining GF , we perform the
same process as in Section III to compute the plausibility of all
edges in GF . Then, we calculate the AUC values when using
plausibility to differentiate between fake and original edges in
GF . The results are presented in Table VII.
First of all, the AUC values drop in all cases compared to
the results in Figure 3. Especially for the k-DA-anonymized
NO dataset (k = 50), AUC drops by 35% to 0.628. This can be
also observed from the histograms in Figure 1b and Figure 8:
By plausibility, fake edges are hidden quite well among the
original edges (compared to Figure 1a and Figure 6). When
applying our enhanced k-DA mechanism on SNAP, the AUC
values drop, but less than for NO. This may be due to the
dataset’s small size (4,039 users) and the large k value, which
leads to a large number of fake edges. On the other hand,
the performance decrease for SalaDP-anonymized datasets is
smaller, but still signiﬁcant.
Moreover, we discover from Figure 1b and Figure 8 that the
11
−0.20.00.20.40.60.81.0Edgeplausibility012345678Numberofedges×104OriginaledgesFakeedges−0.20.00.20.40.60.81.0Edgeplausibility01234567Numberofedges×104−0.20.00.20.40.60.81.0Edgeplausibility0.00.20.40.60.81.0Numberofedges×105−0.20.00.20.40.60.81.0Edgeplausibility0.00.20.40.60.81.0Numberofedges×105−0.20.00.20.40.60.81.0Edgeplausibility0.00.51.01.52.0Numberofedges×105TABLE IX: De-anonymization prevention of our enhanced
mechanism (GF ) and the original mechanism (GA). [Lower
is better] Number of nodes the NS-attack can correctly de-
anonymize. Best scores are in bold.
Enron
GA GF
289
307
270
309
256
302
k-DA (k = 50)
k-DA (k = 75)
k-DA (k = 100)
SalaDP ( = 100)
SalaDP ( = 50)
SalaDP ( = 10)
265
243
236
255
225
207
NO
GA GF
532
759
508
689
491
580
396
277
208
470
291
233
SNAP
GA GF
303
328
234
294
208
274
378
370
376
342
290
267
similarity between GF and G for all graph properties, i.e., GF
preserves high utility. For instance, the cosine similarity for
triangle count is above 0.86 in most of the cases. Meanwhile,
the lowest cosine similarity (degree distribution) is still ap-
proaching 0.7 when applying enhanced k-DA (k = 100) to
SNAP.
More importantly, we observe that GF preserves better
graph utility than GA (almost all points in Figure 9 are
above the diagonal). For instance, the eigencentrality’s cosine
similarity between GF and G is 0.985 while the similarity
between GA and G is only 0.836 for the k-DA-anonymized
NO dataset (k = 50). This is because the fake edges added by
our enhanced mechanisms are more structurally similar to the
original edges, thus preserving better utility.
Graph De-anonymization: Next, we investigate the perfor-
mance of graph de-anonymization on graphs generated by our
enhanced mechanisms. We concentrate on the NS-attack [32]
due to its superior performance over others [18]. The NS-
attack assumes that the adversary knows an auxiliary graph
with all nodes’ identities. Her goal is to map each node in the
auxiliary graph to the node representing the same user in an
anonymized target graph. Correctly matched nodes are thus
successfully de-anonymized in the target graph. To ease this
matching, the NS-attack assumes that the adversary has prior
knowledge of some correctly matched nodes, namely the seed
nodes. The attack then starts from these seeds to de-anonymize
more nodes by propagating throughout the whole anonymized
graph.
We use GA and GF as the target graphs, respectively,
and sample a subgraph from the original graph G containing
all edges among 25% randomly selected nodes in G as the
auxiliary graph. Moreover, we choose the 200 nodes with
the highest degrees from the auxiliary graph as our seeds.8
For evaluation, we concentrate on correctly and wrongly de-
anonymized users.
Table IX shows the results. First of all, the number of
correctly de-anonymized nodes by the NS-attack is reduced
in all cases thanks to our enhanced mechanisms. Figure 10
further depicts the anonymity gain, i.e., the performance drop
with respect to the correctly de-anonymized nodes. We see
that the NS-attack de-anonymizes almost 30% fewer nodes on
the enhanced k-DA-anonymized (k=50) NO dataset. We also
8We tried other sampling approaches for seed nodes, but did not observe
signiﬁcant performance differences.
Fig. 9: Comparing the utility of our enhanced mechanism
(GF ) to the original mechanism (GA) for different datasets and
metrics. Any point above the diagonal indicates better utility
of our anonymized graph. The x-axis is the cosine similarity
of GA to the original graph G, and the y-axis analogue for GF .
two Gaussian distributions of GF for k-DA and SalaDP largely
overlap (see Figure 1a and Figure 6 for comparison). This
indicates that the Gaussian mixture model approach described
in Section IV cannot perform effective fake edge detection.
For instance, our experiments with the GMM approach only
achieve around 0.37 F1 score for SalaDP ( = 100) on
the NO dataset, which represents a 50% performance drop
(see Table VIII).
It is worth noting that all the edges added by our en-
hanced anonymization mechanisms still have relatively smaller
plausibility than the original edges. Given that our weighted
sampling follows the original edges’ plausibility distribution in
G, this implies that not many potential fake edges are normal
with respect to plausibility. We conclude that it is non-trivial to
create fake edges totally indistinguishable from original edges.
Graph Utility: The main motivation for OSNs to share their
graph data is to allow third parties to conduct research or build
commercial applications. Therefore, a graph anonymization
mechanism needs to take into account graph utility, i.e., how
well the anonymized graph preserves the structural properties
of the original graph. To show that our enhanced mechanisms
outperform the current anonymization mechanisms, we also
evaluate GF ’s utility.
There exist many graph properties that can be used to
evaluate graph utility [12], [24], [18]. For the sake of concise-