x
a
M
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0
  RND
  RFR
  IMP
  SIN
  WLD
C
C
P
x
a
M
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0
  RND
  RFR
  IMP
  SIN
  WLD
 0
 250
 500
 750
 1000
 1250
 1500
 1750
 2000
 2250
 2500
 0
 250
 500
 750
 1000
 1250
 1500
 1750
 2000
 2250
 2500
 0
 250
 500
 750
 1000
 1250
 1500
 1750
 2000
 2250
 2500
T
T
T
(d) Effect of T for the Idle wld.
(e) Effect of T for the Internet wld.
(f) Effect of T for the Office wld.
Fig. 3. The eﬀect of the parameters and the workload on the maximum PCC measured
with regular system processes.
As shown in the graphs, the maximum PCC value decreases exponentially as
N increases. This conﬁrms the intuition that for small N, the PCC may yield
unstable and inaccurate results, possibly assigning very high correlation values
to regular system processes. For example, using input patterns of length N  30, its value is constantly below 0.35. As far as the
pattern generation algorithms are concerned, they all behave very similarly. No-
tably, RFR yields the most stable PCC distribution. This is especially evident
for the Oﬃce workload. In addition, our workload-aware algorithm WLD does
not perform signiﬁcantly better than any other workload-agnostic pattern gen-
eration algorithm. This strongly suggests that, independently of the value of
214
S. Ortolani, C. Giuﬀrida, and B. Crispo
N, the output pattern of a process at any given time is not in general a good
predictor of the output pattern that will be monitored next. This observation
generally reﬂects the low level of predictability in the I/O behavior of a process.
From Figures 3(d), 3(e), 3(f) we can observe the eﬀect of the parameter T on
input patterns generated by the IMP algorithm. The experiments shown here
have been conducted by ﬁxing the pattern length to an arbitrary stable value
of N = 50. For small values of T , IMP constantly outperforms all the other
algorithms by producing extremely anomalous I/O patterns for the given T in
any workload scenario. As T increases, the irregularity becomes less evident and
IMP matches more closely the behavior of the other algorithms.
In general, for reasonable values of T , all the pattern generation algorithms
reveal a similar and constant distribution of the PCC. This conﬁrms the property
of self-similarity of the I/O traﬃc. As expected, the PCC measured is generally
independent of the interval T . Notably, RFR and WLD reveal a more steady
distribution of the PCC. This is probably due to the use of a ﬁxed range of
values in both algorithms. This also conﬁrms the intuition that more variability
in the input pattern leads to more accurate and stable results.
For very small values of T , we also note that WLD performs signiﬁcantly bet-
ter than the average. This is a hint that predicting the I/O behavior of a generic
process in a fairly accurate way is only realistic for small windows of observa-
tion. In all the other cases, we believe that the complexity of implementing a
workload-aware algorithm largely outweighs its beneﬁts. For small values of T ,
we also found the SIN algorithm to be more prone to generation of false posi-
tives. In our analysis, we found that similar PCC distributions can be obtained
with very diﬀerent types of workload. This suggests that it is possible to select
the same threshold for many diﬀerent settings. For reasonable values of N and
T , we found that a threshold of 0.5− 0.6 is usually suﬃcient to rule out the pos-
sibility of false positives, while being able to detect most keyloggers eﬀectively.
In addition, the use of a stable pattern generation algorithm like RFR could also
help minimize the level of unpredictability across many diﬀerent settings.
5 Evasion Techniques
Despite we were able to detect all the existing keyloggers, there are some eva-
sion techniques that keyloggers may employ to make detection more diﬃcult.
For instance, a keylogger may rely on some kind of aggressive buﬀering, namely
ﬂushing its buﬀer every 12 hours. In this case, since we would need 12 hours to
collect a single sample, increasing the amount of samples is not desired solution.
We point out that the model underlying our detection technique is not account-
able for this limitation. In fact, monitoring the memory accesses of the running
processes would promptly make the detection process immune to such behav-
ior. However, since monitoring the memory accesses is not available by means
of unprivileged APIs, we reckon that such beneﬁts are mitigated by the need
of running the OS in a virtualized environment. A more complex behavior is a
keylogger actively performing I/O activities. Although this class of keylogger is
Bait Your Hook: A Novel Detection Technique for Keyloggers
215
hypothetical, our model can easily be augmented to handle this type of keylog-
gers. The solution is to inject rates of keystrokes higher than the I/O generated
by the disguisement activities. In this scenario the component able to inject most
of the keystrokes would make its pattern to emerge. Further research is advised
to assess the viability of such a countermeasure against this evasion technique.
6 Related Work
Despite our approach is the ﬁrst and only technique to solely rely on unprivi-
leged execution environments, several works recently dealt with the detection of
privacy-breaching malware.
The technique of detecting malware by means of modeling their behavior has
been previously proposed by Kirda et al. [12]. Their approach is tailored to
detect malware running as Internet Explorer loadable modules. Modules both
monitoring the user’s activity and disclosing such data to other processes are
ﬂagged as malware. Their analysis in fact deﬁnes a malware behavior in terms
of API calls invoked in response to browser events. However, as we previously
discussed, the API calls a keylogger leverages are commonly used by legitimate
components. Their approach is therefore prone to false positives that only a
continuously updated white-list may be able to counter.
Slightly more sophisticated approaches are the ones detecting when known APIs
are exploited. Since user-space keyloggers are known to target a little set of APIs,
this approach perfectly ﬁts our case. Aslam et al. [3] adopt the approach to disas-
semble executable in order to look for the mentioned API calls. Unfortunately, all
these calls are commonly used by legitimate applications; detecting keyloggers by
such means would produce a remarkable amount of false positives. Xu et al. [20]
push this technique a little further. They interpose a function between the API
and any program calling it; this function denies the delivering of the keystroke to
the keylogger by means of altering its type (from WM KEYDOWN to WM CHAR). How-
ever, since they rely on the ability to interpose the function before the keylogger,
a malware aware of this countermeasure can easily elude it.
A step a little closer to our approach is discussed by AlHammadi et al. in [1].
Their approach deﬁnes a malware behavior in terms of the invoked API functions.
To be more precise, they collect the frequency of API calls invoked to (i) intercept
keystrokes, (ii) writing to a ﬁle, and (iii) sending bytes over the network. A
malware is then ﬂagged as such whether two frequencies are found to be highly
correlated. Since no bogus events are sent to the system (no injection of crafted
input), the correlation may be not be as strong as expected. The correlation value
would be even more impaired in case of any delay introduced by the malware.
Moreover, since the whole analysis is focused on a speciﬁc bot, it lacks a proper
discussion on both false positive and false negatives of their quantitative analysis.
In our approach we focus on the actual written bytes and consequently adopt a
diﬀerent correlation metric, i.e. PCC, that instead is linear. Due to its linearity,
any data transformation (such as encryption) would not help the malware in
evading our detection. Our approach is also immune to malware reasonably
216
S. Ortolani, C. Giuﬀrida, and B. Crispo
buﬀering the collected data: as long as the minimum rate of injected keystrokes
ﬂushes the buﬀer in question, our approach preserves its eﬀectiveness. In case
such a requirement can not be met, our technique can be easily extended by
means of aggregating consecutive samples as we explain in Sec. 5.
A similar technique comprising of both quantitative analysis and injection
routine is sketched by Han et al. in [10]. However, besides being a privileged
approach like [1] and [6], it merely relies on the amount of API calls triggered
in response to a certain amount of keystrokes. However, the assumption that a
certain amount of keystrokes implies a ﬁxed amount of API calls is not always
true. It is how a program is implemented that determines in how many chunks
a stream of data is written to disk. In our approach we rely on more precise
measurements that are also available by means of unprivileged APIs, namely
the amount of bytes a process writes.
In conclusion, notable approaches recently attempted to generalize the be-
havior deemed malicious. In particular, in [16,7] the authors attempt to identify
trigger-based behavior by means of mixing concrete and symbolic execution. In
such a way they aim to explore all the possible execution paths that a mal-
ware may reproduce during execution. As the authors in [16] admit, however,
automating the detection of trigger-based behavior is an extremely challenging
task requiring advanced privileged tools. The problem is also undecidable in the
general case.
7 Conclusions
In this paper we presented an unprivileged black-box approach for accurate de-
tection of the most common keyloggers, i.e. user-space keyloggers. We modeled
the behavior of a keylogger by means of correlating the input, i.e. the keystrokes,
to the I/O pattern produced by the keylogger. Moreover, since the input to the
system was known, we augmented our model by introducing the ability to ar-
tiﬁcially inject keystrokes. We then discussed the problem of choosing the best
input pattern to improve our detection rate. Subsequently we implemented our
architecture on the operating system most vulnerable to the threat of keyloggers,
i.e. Windows. We also gave implementation details to accommodate diﬀerent op-
erating systems, thus obtaining an OS independent architecture. We then tested
the prototype against a real case scenario; the results met our expectations:
given a proper threshold, we were able to detect 100% of the most common free
keyloggers [15] completely avoiding any false positive.
As future works, we will investigate the tradeoﬀ of giving up the constraint of
an unprivileged execution environment; accessing privileged APIs would allow
our detector to monitor memory accesses of running processes.
References
1. Al-Hammadi, Y., Aickelin, U.: Detecting bots based on keylogging activities. In:
Proceedings of the Third International Conference on Availability, Reliability and
Security, pp. 896–902 (2008)
Bait Your Hook: A Novel Detection Technique for Keyloggers
217
2. Aldrich, J.: Correlations genuine and spurious in pearson and yule. Statistical
Science 10(4), 364–376 (1995)
3. Aslam, M., Idrees, R., Baig, M., Arshad, M.: Anti-Hook Shield against the Soft-
ware Key Loggers. In: Proceedings of the 2004 National Conference on Emerging
Technologies, p. 189 (2004)
4. BAPCO: SYSmark 2004 SE (2004),
http://www.bapco.com/products/sysmark2004se/
5. Benesty, J., Chen, J., Huang, Y.: On the importance of the pearson correlation
coeﬃcient in noise reduction. IEEE Transactions on Audio, Speech, and Language
Processing 16(4), 757–765 (2008)
6. Borders, K., Zhao, X., Prakash, A.: Siren: Catching evasive malware (short paper).
In: Proceedings of the IEEE Symposium on Security and Privacy, pp. 76–85 (2006)
7. Brumley, D., Hartwig, C., Liang, Z., Newsome, J., Song, D., Yin, H.: Automati-
cally identifying trigger-based behavior in malware. Advances in Information Se-
curity 36, 65–88 (2008)
8. Goodwin, L., Leech, N.: Understanding correlation: Factors that aﬀect the size of
r. The Journal of Experimental Education 74(3), 249–266 (2006)
9. Grebennikov, N.: Keyloggers: How they work and how to detect them,
http://www.viruslist.com/en/analysis?pubid=204791931
10. Han, J., Kwon, J., Lee, H.: Honeyid: Unveiling hidden spywares by generating
bogus events. In: Proceedings of The Iﬁp Tc 11 23rd International Information
Security Conference, pp. 669–673 (2008)
11. Hsu, W., Smith, A.: Characteristics of I/O traﬃc in personal computer and server
workloads. IBM System Journal 42(2), 347–372 (2003)
12. Kirda, E., Kruegel, C., Banks, G., Vigna, G., Kemmerer, R.: Behavior-based
spyware detection. In: Proceedings of the 15th USENIX Security Symposium
(USENIX Security 2006) (2006)
13. Kochenberger, G., Glover, F., Alidaee, B.: An eﬀective approach for solving the bi-
nary assignment problem with side constraints. Internation Journal of Information
Technology and Decision Making 1, 121–129 (2002)
14. Kuhn, H.W.: The hungarian method for the assignment problem. Naval Research
Logistics Quarterly 2, 83–97 (1955)
15. Security Technology Ltd.: Testing and reviews of keyloggers, monitoring products
and spy software (spyware) (2009),
http://www.keylogger.org/monitoring-free-software-review/
16. Moser, A., Kruegel, C., Kirda, E.: Exploring multiple execution paths for malware
analysis. In: Proceeding of the 28th IEEE Symposium on Security and Privacy (SP
2007), pp. 231–245 (May 2007)
17. San Jose Mercury News: Kinkois spyware case highlights risk of public internet
terminals (2009),
http://www.siliconvalley.com/mld/siliconvalley/news/6359407.htm
18. Rodgers, J.L., Nicewander, W.A.: Thirteen ways to look at the correlation coeﬃ-
cient. The American Statistician 42(1), 59–66 (1988)
19. Strahija, N.: Student charged after college computers hacked (2003),
http://www.xatrix.org/article2641.html
20. Xu, M., Salami, B., Obimbo, C.: How to protect personal information against
keyloggers. In: Proceedings of the 9th International Conference on Internet and
Multimedia Systems and Applications, IASTED 2005 (2005)
Generating Client Workloads and High-Fidelity
Network Traﬃc for Controllable, Repeatable
Experiments in Computer Security(cid:2)
Charles V. Wright, Christopher Connelly, Timothy Braje,
Jesse C. Rabek(cid:3)(cid:3), Lee M. Rossey, and Robert K. Cunningham
Information Systems Technology Group
MIT Lincoln Laboratory
{cvwright,connelly,tbraje,lee,rkc}@ll.mit.edu, PI:EMAIL
Lexington, MA 02420
Abstract. Rigorous scientiﬁc experimentation in system and network
security remains an elusive goal. Recent work has outlined three basic
requirements for experiments, namely that hypotheses must be falsiﬁ-
able, experiments must be controllable, and experiments must be repeat-
able and reproducible. Despite their simplicity, these goals are diﬃcult
to achieve, especially when dealing with client-side threats and defenses,
where often user input is required as part of the experiment. In this
paper, we present techniques for making experiments involving security
and client-side desktop applications like web browsers, PDF readers, or
host-based ﬁrewalls or intrusion detection systems more controllable and
more easily repeatable. First, we present techniques for using statistical
models of user behavior to drive real, binary, GUI-enabled application
programs in place of a human user. Second, we present techniques based
on adaptive replay of application dialog that allow us to quickly and ef-
ﬁciently reproduce reasonable mock-ups of remotely-hosted applications
to give the illusion of Internet connectedness on an isolated testbed. We
demonstrate the utility of these techniques in an example experiment
comparing the system resource consumption of a Windows machine run-
ning anti-virus protection versus an unprotected system.
Keywords: Network Testbeds, Assessment and Benchmarking, Traﬃc
Generation.
1 Introduction
The goal of conducting disciplined, reproducible, “bench style” laboratory re-
search in system and network security has been widely acknowledged [1,2], but
remains diﬃcult to achieve. In particular, Peisert and Bishop [2] outline three
(cid:2) This work was supported by the US Air Force under Air Force contract FA8721-05-
C-0002. The opinions, interpretations, conclusions, and recommendations are those
of the authors and are not necessarily endorsed by the United States Government.
(cid:2)(cid:2) Work performed as a student at MIT. The author is now with Palm, Inc.
S. Jha, R. Sommer, and C. Kreibich (Eds.): RAID 2010, LNCS 6307, pp. 218–237, 2010.
c(cid:2) Springer-Verlag Berlin Heidelberg 2010
Generating Client Workloads and High-Fidelity Network Traﬃc
219
basic requirements for performing good experiments in security: (i) Hypotheses
must be falsiﬁable—that is, it must be possible to design an experiment to ei-
ther support or refute the hypothesis. Therefore, the hypothesis must pertain
to properties that are both observable and measurable. (ii) Experiments must
be controllable; the experimenter should be able to change only one variable at
a time and measure the change in results. (iii) Finally, experiments should be
both repeatable, meaning that the researcher can perform them several times
and get similar results, and reproducible, meaning that others can recreate the
experiment and obtain similar results.
Unfortunately, designing an experiment in system or network security that
meets these requirements remains challenging. Current practices for measur-
ing security properties have recently been described as “ad-hoc,” “subjective,”
or “procedural” [3]. Experiments that deal primarily with hardware and soft-
ware may be extremely controllable, and recent work [4,5,6,7,8] has explored
techniques for deploying and conﬁguring entire networks of servers, PCs, and
networking equipment on isolated testbeds, disconnected from the Internet or
other networks, where malicious code may safely be allowed to run with low risk
of infecting the rest of the world. However, the recent shift in attacks from the
server side to the client side [9,10,11,12] means that an experiment involving any
one of many current threats, such as drive-by downloads [13] cross-site scripting,