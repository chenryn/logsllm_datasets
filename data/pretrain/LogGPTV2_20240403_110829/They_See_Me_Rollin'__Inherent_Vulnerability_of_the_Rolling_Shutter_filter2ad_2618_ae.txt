Koltun. 2017. CARLA: An Open Urban Driving Simulator. In Proceedings of the
1st Annual Conference on Robot Learning. 1–16.
[12] Daniel Durini. 2019. High performance silicon imaging: Fundamentals and appli-
cations of CMOS and CCD sensors. https://doi.org/10.1016/C2017-0-01564-1
[13] EVERGUARD.ai. 2020. sentri360. https://everguard.ai/sentri360.php.
[14] Kevin Eykholt, Ivan Evtimov, Earlence Fernandes, Bo Li, Amir Rahmati, Florian
Tramer, Atul Prakash, Tadayoshi Kohno, and Dawn Song. 2018. Physical ad-
versarial examples for object detectors. In 12th USENIX Workshop on Offensive
Technologies (WOOT 18).
[15] Ilias Giechaskiel and Kasper Rasmussen. 2019. Taxonomy and challenges of
out-of-band signal injection attacks and defenses. IEEE Communications Surveys
& Tutorials 22, 1 (2019), 645–670.
[16] Ionel Gog, Sukrit Kalra, Peter Schafhalter, Matthew A Wright, Joseph E Gonzalez,
and Ion Stoica. 2021. Pylot: A Modular Platform for Exploring Latency-Accuracy
Tradeoffs in Autonomous Vehicles. arXiv preprint arXiv:2104.07830 (2021).
[17] Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. 2014. Explaining and
harnessing adversarial examples. arXiv preprint arXiv:1412.6572 (2014).
[18] Google Nest. 2020. Nest Cam. https://store.google.com/us/product/nest_cam_
outdoor?hl=en-US.
[19] Kaiming He, Georgia Gkioxari, Piotr Dollár, and Ross Girshick. 2017. Mask r-cnn.
In Proceedings of the IEEE international conference on computer vision. 2961–2969.
[20] T Kinugasa, M Noda, T Imaide, I Aizawa, Y Todaka, and M Ozawa. 1987. An
Electronic Variable-Shutter System in Video Camera Use. IEEE Transactions on
Consumer Electronics CE-33, 3 (1987), 249–255.
[21] Eric D Knapp and Joel Thomas Langill. 2014. Industrial Network Security: Securing
critical infrastructure networks for smart grid, SCADA, and other Industrial Control
Systems. Syngress.
[22] Takao Kuroda. 2017. Essential principles of image sensors. https://doi.org/10.
1201/b17411
[23] Haoliang Li, Yufei Wang, Xiaofei Xie, Yang Liu, Shiqi Wang, Renjie Wan, Lap-Pui
Chau, and Alex C Kot. 2020. Light Can Hack Your Face! Black-box Backdoor
Attack on Face Recognition Systems. arXiv preprint arXiv:2009.06996 (2020).
[24] Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed,
Cheng-Yang Fu, and Alexander C Berg. 2016. Ssd: Single shot multibox detector.
In European conference on computer vision. Springer, 21–37.
[25] Giulio Lovisotto, Henry Turner, Ivo Sluganovic, Martin Strohmeier, and Ivan
Martinovic. 2021. SLAP: Improving Physical Adversarial Examples with Short-
Lived Adversarial Perturbations. In 30th USENIX Security Symposium (USENIX
Security 21).
[26] Yanmao Man, Ming Li, and Ryan Gerdes. 2020. GhostImage: Remote Percep-
tion Attacks against Camera-based Image Classification Systems. In 23rd In-
ternational Symposium on Research in Attacks, Intrusions and Defenses (RAID
2020). USENIX Association, San Sebastian, 317–332. https://www.usenix.org/
conference/raid2020/presentation/man
[27] Junichi Nakamura. 2006.
Image sensors and signal processing for digital still
cameras. 1–336 pages. https://doi.org/10.1201/9781420026856
[28] Ben Nassi, Dudi Nassi, Raz Ben-Netanel, Yisroel Mirsky, Oleg Drokin, and Yuval
Elovici. 2020. Phantom of the ADAS: Phantom Attacks on Driver-Assistance
Systems.
[29] Dudi Nassi, Raz Ben-Netanel, Yuval Elovici, and Ben Nassi. 2019. MobilBye:
Attacking ADAS with Camera Spoofing. arXiv preprint arXiv:1906.09765 (2019).
[30] Sangmin Oh, Anthony Hoogs, Amitha Perera, Naresh Cuntoor, Chia-Chih Chen,
Jong Taek Lee, Saurajit Mukherjee, JK Aggarwal, Hyungtae Lee, Larry Davis,
et al. 2011. A large-scale benchmark dataset for event recognition in surveillance
video. In CVPR 2011. IEEE, 3153–3160.
[31] BBC Online. 2020. Met Police to deploy facial recognition cameras.
https:
//www.bbc.co.uk/news/uk-51237665.
[32] Youngseok Park, Yunmok Son, Hocheol Shin, Dohyun Kim, and Yongdae Kim.
2016. This ain’t your dose: Sensor spoofing attack on medical infusion pump. In
10th USENIX Workshop on Offensive Technologies (WOOT 16).
[33] Jonathan Petit, Bas Stottelaar, Michael Feiri, and Frank Kargl. 2015. Remote
attacks on automated vehicles sensors: Experiments on camera and lidar. Black
Hat Europe 11 (2015), 2015.
[34] QImaging. 2014.
Rolling Shutter vs. Global Shutter.
tecnicaenlaboratorios.com/Qimaging/brochures/RollingvsGlobalShutter.pdf.
[35] Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. 2015. Faster r-cnn:
Towards real-time object detection with region proposal networks. In Advances
in neural information processing systems. 91–99.
[36] Ring. 2020. Ring Camera. https://ring.com.
[37] Athena Sayles, Ashish Hooda, Mohit Gupta, Rahul Chatterjee, and Earlence Fer-
nandes. 2021. Invisible Perturbations: Physical Adversarial Examples Exploiting
the Rolling Shutter Effect. In Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition. 14666–14675.
[38] Blue Iris Security. 2020. Video Security. https://blueirissoftware.com/.
[39] Mahmood Sharif, Lujo Bauer, and Michael K Reiter. 2018. On the suitability
of lp-norms for creating and preventing adversarial examples. In Proceedings
of the IEEE Conference on Computer Vision and Pattern Recognition Workshops.
http://www.
409ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Sebastian Köhler, Giulio Lovisotto, Simon Birnbach, Richard Baker, and Ivan Martinovic
1605–1613.
using rectification attacks. In Proceedings of the 2019 ACM SIGSAC Conference on
Computer and Communications Security. 2301–2315.
[50] Haohan Wang, Xindi Wu, Zeyi Huang, and Eric P Xing. 2020. High-frequency
Component Helps Explain the Generalization of Convolutional Neural Networks.
In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recog-
nition. 8684–8694.
[51] Martin Wany and Georg P Israel. 2003. CMOS image sensor with NMOS-only
global shutter and enhanced responsivity. IEEE Transactions on electron devices
50, 1 (2003), 57–62.
[52] Bing Xu, Naiyan Wang, Tianqi Chen, and Mu Li. 2015. Empirical evaluation of
rectified activations in convolutional network. arXiv preprint arXiv:1505.00853
(2015).
[53] Wenyuan Xu, Chen Yan, Weibin Jia, Xiaoyu Ji, and Jianhao Liu. 2018. Analyzing
and enhancing the security of ultrasonic sensors for autonomous vehicles. IEEE
Internet of Things Journal 5, 6 (2018), 5015–5029.
[54] Chen Yan, Wenyuan Xu, and Jianhao Liu. 2016. Can you trust autonomous
vehicles: Contactless attacks against sensors of self-driving vehicle. DEF CON
24, 8 (2016), 109.
[55] Fisher Yu, Haofeng Chen, Xin Wang, Wenqi Xian, Yingying Chen, Fangchen
Liu, Vashisht Madhavan, and Trevor Darrell. 2020. BDD100K: A diverse driving
dataset for heterogeneous multitask learning. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition. 2636–2645.
[56] Guoming Zhang, Chen Yan, Xiaoyu Ji, Tianchen Zhang, Taimin Zhang, and
Wenyuan Xu. 2017. Dolphinattack: Inaudible voice commands. In Proceedings
of the 2017 ACM SIGSAC Conference on Computer and Communications Security.
103–117.
[57] Zhimin Zhou, Bedabrata Pain, and Eric R. Fossum. 1997. Frame-transfer CMOS
IEEE Transactions on Electron Devices
active pixel sensor with pixel binning.
(1997). https://doi.org/10.1109/16.628834
[58] Zhe Zhou, Di Tang, Xiaofeng Wang, Weili Han, Xiangyu Liu, and Kehuan Zhang.
2018. Invisible mask: Practical attacks on face recognition with infrared. arXiv
preprint arXiv:1803.04683 (2018).
[40] Sam Shead. 2019. Chinese residents worry about rise of facial recognition.
https://www.bbc.co.uk/news/technology-50674909.
[41] Hocheol Shin, Dohyun Kim, Yujin Kwon, and Yongdae Kim. 2017. Illusion and
dazzle: Adversarial optical channel exploits against lidars for automotive appli-
cations. In International Conference on Cryptographic Hardware and Embedded
Systems. Springer, 445–467.
[42] Dawn Song, Kevin Eykholt, Ivan Evtimov, Earlence Fernandes, Bo Li, Amir
Rahmati, Florian Tramèr, Atul Prakash, and Tadayoshi Kohno. 2018. Physical
Adversarial Examples for Object Detectors. In 12th USENIX Workshop on Offensive
Technologies (WOOT 18). USENIX Association, Baltimore, MD. https://www.
usenix.org/conference/woot18/presentation/eykholt
[43] Nick Statt. 2020. Amazon is expanding its cashierless Go model into a full-
blown grocery store. https://www.theverge.com/2020/2/25/21151021/amazon-
go-grocery-store-expansion-open-seattle-cashier-less.
[44] Takeshi Sugawara, Benjamin Cyr, Sara Rampazzi, Daniel Genkin, and Kevin Fu.
2020. Light commands: laser-based audio injection attacks on voice-controllable
systems. In 29th USENIX Security Symposium (USENIX Security 20). 2631–2648.
[45] Jiachen Sun, Yulong Cao, Qi Alfred Chen, and Z Morley Mao. 2020. Towards
robust lidar-based perception in autonomous driving: General black-box adver-
sarial sensor attack and countermeasures. In 29th USENIX Security Symposium
(USENIX Security 20). 877–894.
[46] Synology. 2020. Synology Surveillance Station.
https://synology.com/en-
us/surveillance.
[47] Bosch Security Systems. 2016. FW 6.30 Tamper Detection. https://resources-
boschsecurity-cdn.azureedge.net/public/documents/TN_VCA_tamper_detect_
WhitePaper_enUS_22996235531.pdf.
[48] Timothy Trippel, Ofir Weisse, Wenyuan Xu, Peter Honeyman, and Kevin Fu.
2017. WALNUT: Waging doubt on the integrity of MEMS accelerometers with
acoustic injection attacks. In 2017 IEEE European Symposium on Security and
Privacy (EuroS&P). IEEE, 3–18.
[49] Yazhou Tu, Sara Rampazzi, Bin Hao, Angel Rodriguez, Kevin Fu, and Xiali Hei.
2019. Trick or heat? Manipulating critical temperature-based control systems
410They See Me Rollin’: Inherent Vulnerability of the Rolling Shutter in CMOS Image Sensors
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Table 4: Results of the cross-correlation between the color
channel histograms of the frames captured with auto-
exposure, manual exposure setting and manual exposure
setting with an offset of 60µs.
Color Channel Manual Manual + Offset
0.9858
0.9865
0.9545
Red
Green
Blue
0.9961
0.9986
0.9939
A ESTIMATING texp
On the basis of the Axis M3045-V, we demonstrate how the adver-
sary can estimate the exposure time texp. Moreover, we show that
the method leads to very accurate results, by comparing frames
captured with auto-exposure and manually set exposure.
Method. In the first step, we extracted Hv = 0.25lx from the
datasheet. We then collected multiple frames with the auto-exposure
mechanism. Subsequently, we deactivated the auto-exposure mech-
anism, measured the current ambient light level Ev with a lux meter
and used Equation 7 to estimate texp. We repeated the frame collec-
tion for different lighting conditions, such as at sunset, on a cloudy
day and a sunny day.
Accuracy of Estimation. On a first glance, there was no optical
difference between the frames collected with auto-exposure and
the ones collected with manual settings. To analyze the accuracy,
we calculated histograms for each color channel (R, G and B) of the
collected frames. We then calculated the cross-correlation between
the color histograms of the frames captured with auto-exposure
and the ones with manually set exposure. The results in Table 4
show that there is only a small difference between the frames cap-
tured with auto-exposure and the ones with manual exposure. To
make the results more comparable, we also collected frames with
an exposure of texp + 60µs. We picked an offset of 60µs, because
this was the first value where we noticed considerable changes in
brightness. As can be seen in Table 4, an offset of 60 also led to
a noticeable difference in the cross-correlation of all three color
channels. This suggests that the estimation of texp is accurate.
B INCORRECT texp - ADDITIONAL RESULTS
As reported in Section 6.2, incorrect estimates of the exposure time
can lead to distortion sizes that diverge from the expected size.
Here we report the best and worst divergence observed for the
parameters used in our data collection, which depends on ton. In
fact, larger ton will lead to smaller variation, and vice-versa. The
shortest ton is reported in Figure 12, the longest ton is reported in
Figure 13. The figures show that for larger ton (which also generally
produce better attack success in our evaluation, Section 7), incorrect
estimates tend to lead to diminishing divergence in expected versus
actual distortion size. For Logitech we get a worst-case distortion
size increase of 1.6 (down from 6 in the shortest ton setting), while
the same increase for Axis goes from a factor of 11 (in the shortest
ton setting) down to a factor of 3.
Figure 12: As in Figure 7, increment in the expected dis-
tortion size ˆNo and actual size No as the adversary’s expo-
sure time estimate texp diverges from the true exposure time
value ˆtexp. Shortest ton used in the data collection of Sec-
tion 6.
Figure 13: As in Figure 7, increment in the expected dis-
tortion size ˆNo and actual size No as the adversary’s expo-
sure time estimate texp diverges from the true exposure time
value ˆtexp. Longest ton used in the data collection of Sec-
tion 6.
C EFFECT ON AUTONOMOUS DRIVING
We used the open-source simulator CARLA [11], in combination
with the self-driving car platform Pylot [16] to illustrate the effects
of the rolling shutter attack on an autonomous system. By default,
the Pylot agent is equipped with four sensors: (i) a wide-angle
RGB camera for lane detection and object detection/tracking, (ii) a
telephoto camera for traffic light detection, (iii) a LiDAR sensor for
localization, and (iv) GPS for route planning. We uniquely targeted
the wide-angle RGB camera with our attack, to measure how the
system as a whole is affected.
CARLA Setup. We utilized two predefined scenarios from the
CARLA scenario runner, where an entity is crossing the road in
front of the car: Scenario 1 involves a pedestrian and Scenario 2
involves a cyclist. We collected the baseline performance of Pylot by
simulating each scenario 50 times. We then repeated the simulation
under the presence of the rolling shutter attack. We intercepted the
frames captured by the wide-angle camera as they were forwarded
to Pylot and overlayed the rolling shutter pattern, as described in
Section 7.1.1. The attack parameters were as follows: f = 750Hz,
texp = 200µs and ton = 0.53ms. In line with the previous evaluation,
we again used two object detectors, FRCNN and SSD, which are
among the pre-implemented options in Pylot.
texp010002000ˆtexp010002000×2×4×6×8×10×12No=59,ˆNo=10Logitech(ton=320µs)texp05001000ˆtexp05001000DistortionSizeIncrease(NoˆNo)×2×4×6×8×10×12No=57,ˆNo=5Axis(ton=50µs)texp010002000ˆtexp010002000×2×4×6No=398,ˆNo=349Logitech(ton=16000µs)texp05001000ˆtexp05001000DistortionSizeIncrease(NoˆNo)×2×4×6No=76,ˆNo=24Axis(ton=400µs)411ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Sebastian Köhler, Giulio Lovisotto, Simon Birnbach, Richard Baker, and Ivan Martinovic
Results. Most of the key findings from Section 7 can be trans-
ferred to the CARLA simulations. In particular, the performance
difference between SSD and FRCNN stands out. While for Scenario
1 during normal operation for both object detectors the probability
of a collision was equal (5%), under the rolling shutter attack, SSD
showed a 67% probability of a collision compared to 47% for FRCNN.
Similar behavior can be observed for the baseline of Scenario 2. FR-
CNN showed a 0% probability of a collision, while using SSD led to
an increase to 15%. However, interestingly, under attack, FRCNN
experienced a strong performance drop and fell behind SSD. The
probability of a safety infraction increased to 97% compared to 65%
for SSD.
In Figure 14, the velocity curve of the autonomous vehicle for the
two scenarios and object detectors is presented. The figure shows
that in the baseline, the car immediately reduces speed as soon as
the non-player character starts moving. In contrast, as the braking
gap shows, during the attack, a noticeable delay in braking can be
observed.
Figure 14: Velocity curve of the agent during normal oper-
ation (baseline) and during the rolling shutter attack. The
grey area shows the time when the pedestrian/cyclist crosses
the road. The dashed line marks the time when the agent col-
lides with the non-player character.
02468FRCNNVelocity(m/s)SimulationTime(s)collisionScenario1collisionScenario2BaselineRollingShutterAttackCrossingBrakingGap0123402468SSDcollision01234collision412They See Me Rollin’: Inherent Vulnerability of the Rolling Shutter in CMOS Image Sensors
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
(a) Logitech C922
(b) Logitech C922
(c) Axis M3045-V
(d) Axis M3045-V
(e) YI Home Camera 1080p
(f) YI Home Camera 1080p
(g) V380 Camera 720p
(h) V380 Camera 720p
(i) Netgear Arlo
(j) Netgear Arlo
(k) Apple iPhone 7
(l) Apple iPhone 7
Figure 15: Physical evaluation of the attack. These images were collected during a physical experiment where we printed
images, placed them in front of the camera, and carried out the attack with the laser (see Figure 5). The first column reports
the object detection results on FRCNN, the second column on SSD.
413