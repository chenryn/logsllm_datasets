### Linear Relationship with the Number of Cameras

As shown in Figure 13a, the relationship between the number of cameras and the cost reduction is linear. We tested this by using ten video feeds, all covering the same daytime hour, and incrementally adding one camera at a time. Chameleon automatically groups these cameras into a single group (as described in ยง5.3) and achieves a linear reduction in cost with only a small reduction in accuracy. In contrast, during hours when the cameras are less similar, we expect a smaller reduction in profiling cost because only a subset of cameras can share the profiling cost. This is evident in Figure 13b, where Chameleon groups the cameras into two or sometimes three groups, resulting in lower cost savings compared to Figure 13a.

### Accuracy and Grouping

As more cameras are grouped together, the accuracy drops, although by less than 10%. This drop is due to the varying characteristics of cameras within the same group, which means that sharing the same configuration leads to lower accuracy than customizing the configuration for each camera. Additionally, the simple camera-grouping algorithm (ยง5.3) bounds the maximum discrepancy between the accuracy of a randomly chosen configuration on different video feeds within the same group. A more sophisticated grouping algorithm could potentially maintain higher inference accuracy.

### Impact of Reduced Configuration Space

The final key technique in Chameleon is reducing the cost of a single profiling of the configuration space by profiling each knob separately. The reduction in profiling cost is significant, but the impact on accuracy and inference cost of the selected configuration is less clear. Figure 14 compares the configurations found by Algorithm 3 (which assumes knobs are independent) to an exhaustive search, across three metrics: accuracy (Figure 14a), inference cost (Figure 14b), and profiling cost (Figure 14c). The configurations picked by Algorithm 3 are nearly as good as those from an exhaustive search, while achieving a substantial reduction in profiling cost. Note that the "exhaustive" method is not optimal, as it only profiles the first second of each segment, not every second.

### Contribution of Each Component

To investigate the contribution of individual techniques in Chameleon, we incrementally added one technique at a time (temporal incremental update, spatial cross-camera inference, and leveraging knob independence). Figure 15 shows the performance of the full Chameleon solution and some intermediate design points for the two pipelines studied. In both pipelines, each step significantly reduces cost with a relatively small drop in accuracy. Temporal incremental updates reduce profiling cost by about 50%, cross-camera inference by an additional 30-60%, and knob independence by another 40-60%.

### Related Work

#### Video Processing Optimization

Several previous papers have considered optimizing video processing pipelines by adjusting configuration knobs or training specialized neural network models. For example, VideoStorm [32] first profiles each video query running in a cluster and then adjusts its configuration to balance accuracy, processing delay, and resource demand. NoScope [24], MCDNN [16], and Focus [22] process streaming or offline video using various neural networks to detect objects and recognize people and text. A core technique in these papers is training specialized neural networks based on objects that typically appear in a specific video stream. While each paper reports significant improvements in accuracy and/or resource consumption, they only profile and optimize the video queries once at the beginning of the video stream and do not handle changes in video content over time. An exception is [29], which retrains the neural network model to detect popular objects as they change over time. Chameleon's core contributions include demonstrating that optimal configurations change over time and providing an efficient technique for continuous adaptation.

#### Finding Optimal Configurations

Chameleon periodically searches an exponentially large configuration space to find the optimal neural network configuration for a video query. This is done at least for the leader of each spatially-related group of videos. Several recent systems have also faced an exponentially large configuration search space in their problem domains [12, 19, 31, 34]. Ernest [31] uses optimal experimental design [28] to optimize VM configuration, while Cherrypick [12] uses Bayesian optimization [27] to find an optimal cloud configuration for general applications. Hill et al. [19] use Thompson sampling [11] to optimize the layout of a multi-component web page, using greedy hill climbing to select the next layout, similar to Chameleon. However, Chameleon exploits more independence structure and monotonicity. These works bound the cost of their configuration search, but these are still one-time or daily costs. Some bandit algorithms address non-stationary settings (e.g., [26]), but these are currently too inefficient.

Chameleon differs from these systems in two major ways. First, the optimal configuration for a video is non-stationary, requiring frequent (every few seconds) re-profiling to keep up with real-time video feeds, putting tremendous pressure on keeping the profiling cost low. Second, Chameleon reuses optimal configurations across related video feeds. These differences lead to our greedy hill climbing approach, which avoids computationally expensive modeling.

### Discussion and Future Work

#### Network Bandwidth

In addition to computational cost, network bandwidth is an important resource in video analytics. With the increasing trend of running analytics across smart cameras [1, 5, 13] and the cloud, network resources will become scarce. The choice of configuration for a video analytics pipeline has implications for network usage; for example, streaming video at a low frame rate or resolution can save bandwidth if it maintains high inference accuracy. While Chameleon optimizes computational cost, its techniques addressing dynamic variations in the profile using spatial and temporal cross-camera correlations will likely carry over to network considerations. However, this will be a problem of multiple resources and will require techniques for joint consideration.

#### Profiling on the Edge

Chameleon's design relies on a separate cluster for periodic profiling to avoid disruptions to the live video analytics pipeline. As we move towards edge camera analytics [13], such separation will be difficult to achieve. The limited compute resources of edge cameras may be insufficient to accommodate the demand for periodic and quick profiling. Periodically recording and shipping video clips to the cloud for profiling may also overload the network. Designing an appropriate solution for edge camera analytics will be an important future challenge.

#### Triggering Profiling

An unstudied aspect of resource-accuracy profiles is the periodicity with which their values change. While our solution relies on a pre-fixed time interval for profiling, we can further reduce profiling costs by predicting the need to re-profile. Vision techniques like scene understanding could trigger fresh profiling. This requires work at the intersection of systems, machine learning, and computer vision.

### Conclusion

In this paper, we argue that video processing pipelines must be adapted over time to maintain high accuracy. A naive re-profiling is prohibitively expensive. Instead, we present Chameleon, a system that uses several techniques to dramatically reduce profiling cost and improve accuracy.

### Acknowledgements

We appreciate the feedback from the anonymous SIGCOMM reviewers and our shepherd, Romit Roy Choudhury. Ion Stoica is supported by the NSF CISE Expeditions Award CCF-1730628, and in part by DHS Award HSHQDC-16-3-00083, and gifts from Alibaba, Amazon Web Services, Ant Financial, Arm, CapitalOne, Ericsson, Facebook, Google, Huawei, Intel, Microsoft, Scotiabank, Splunk, and VMware.