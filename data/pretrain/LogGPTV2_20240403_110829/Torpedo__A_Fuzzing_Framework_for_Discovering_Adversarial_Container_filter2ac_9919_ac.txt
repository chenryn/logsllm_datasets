6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
(cid:4) resources allocated in containers
(cid:4) record i
∗ that exposes new
if VIOLATE(R, oracle) then
∗} (cid:4) record i
∗ that violates an
onto the host and passes logs from the fuzzer back for analysis
(i.e., between the fuzzer and executors).
TORPEDO contains an observer, which is a thread of
execution responsible for delegating workloads to executors
and examining the results of each execution. It collects a wide
spectrum of system information, including various resources
consumed by a container, the utilization of system/kernel
processes, and the resource consumed by containerization
components. For guiding adversarial program generation to
identify out-of-band workload, TORPEDO leverage an extra
library, Oracle(s), that contains the necessary logic for the
task with respect
to a particular resource. With Oracles,
TORPEDO combines both code coverage information and
resource utilization to guide the fuzzing process.
Algorithm 1 speciﬁes the testing workﬂow. Overall, our
approach depicts a fuzz testing procedure. We start by taking
a set of container instances deployed on the same host as
the testing target. We also require users to provide a set of
initial inputs I as the fuzz testing seeds (see Sec. V on the
construction of I in our research). Containers C are conﬁgured
w.r.t. the particular resource R and yields the corresponding
testing oracle set O (line 3). We then iterate the fuzz testing
process for MAX ITER times and collect all the ﬁndings. For
each iteration, n inputs are fetched from the input queue (line
5), and we mutate the fetched input set i. Then, the mutated
∗ will be used to generate a set of workload W over each
i
container instance (Sec. IV-A). Each container coni will be
executed with its assigned workload wi for a reasonable amount
of time (Sec. IV-B), and we collect the targeted resource
computation during this phase (line 9; Sec. IV-C). In case
the collected computing resource consumption reveals certain
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:18:21 UTC from IEEE Xplore.  Restrictions apply. 
405
unknown patterns (e.g., a larger δ in Equation 3; see Sec. IV-D
∗ is considered interesting
for elaboration), the mutated input i
and will be kept in the input queue for further usage (line 12).
More importantly, once the provoked resource usage violates
any testing oracle for the checked property (line 14), we keep
this input as “discrepant input”. The entire set of discrepant
inputs will be returned to users (e.g., container developers) for
conﬁrmation and bug ﬁx of container runtime systems.
Our testing campaign subsumes several layers hidden within
the container “runtime” (see the three layers in the “Physical
Machine” box of Figure 1). In addition, it is worth noting that
while we primarily detect resource violation vulnerabilities (out-
of-band workloads), crashes hidden in the container runtime
systems and libraries could also be exposed, since the proposed
approach forms a typical fuzz testing toward the container
infrastructure. Existing research has (manually) identiﬁed
vulnerabilities of this category [18], [42], and our evaluation
successfully reveals several crashes in the Docker runtime
system (see Sec. VI). In the rest of this section, we elaborate
on each step in detail.
A. Generating Workload
SYZKALLER does not natively support the direct ingestion
of seed ﬁles for use in corpus construction. Instead, it prefers
to generate programs using a nondeterministic process that may
draw on a corpus of coverage information, if one is available.
For more efﬁcient testing (especially reproducing existing
exploits), we envision that TORPEDO is capable of ingesting
seed ﬁles directly from an operator and using these to populate
∗, TORPEDO prepares a set
an initial corpus. Given an input set i
of workload W that will be used by each container instance. It
then passes through a serialized execution request to a prepared
container, and distributes many heterogeneous workloads in
parallel. Since the majority of generated programs are short
(10 ms or less) and may not ﬁnish at the same time, TORPEDO
repeatedly runs those workloads and deploys a synchronization
mechanism (discussed in Section IV-C) to ensure an efﬁcient
fuzzing process.
B. Interacting with the Container Runtime
In the native SYZKALLER design, workloads are executed
via a virtual machine that shields the syz-manager binary
(which serves as an entrypoint for the fuzzer and a central
collection point for the program corpus and execution statistics)
from kernel crashes. While TORPEDO would also beneﬁt from
such a strategy, we also note that VMs impose a nontrivial
performance overhead and may obscure otherwise relevant
observations. When speciﬁcally considering sandboxed and
virtualized runtimes, which need to be analyzed closely for
adversarial utilization on the host, adding an additional layer
of VM translation will complicate detangling measurements
and slow down the entire fuzzing process. Thus, we choose to
execute all TORPEDO processes on the same host.
We further
identify and package the smallest set of
SYZKALLER components into a container to maintain the
existing program execution workﬂow. Particularly, we package
the syz-executor process (a C++ binary that reads in a serialized
program and executes it while collecting coverage information
about each call) and a simple entrypoint binary to maintain API
compatibility and allow for connection debugging. Additional
features of this entrypoint will be discussed in Section IV-C.
These two applications, when combined, form a container
image for fuzzing adversarial workloads.
C. Collecting Provisioned Computing Resources
Since the goal of TORPEDO is to identify out-of-band
workloads that will violate existing cgroup limitations, it
must accurately capture resource utilization measurements. To
do so, the ﬁrst step is to observe the state of the system
while the program(s) under examination are running. Ideally,
the observation window would completely overlap with the
window of execution to capture an accurate measurement. This
poses an issue when the programs under testing have different
running times as a result of variations in the algorithmic
complexity of the underlying syscalls or simply becoming
blocked. Furthermore, when multiple containers are running
in parallel, we note that all the programs under test will
collectively contribute to the resource utilization of the host.
Thus, for accurately measuring multiple fuzzing processes in
parallel, we completely synchronize the program execution
window and extend the execution time for each program to
become comparable. We choose to have the container entrypoint
binary be responsible for this synchronization. Basically we
keep running the workloads in a loop until it reaches the
threshold, and report the number of executions and average
execution time (obtained through Unix NS timestamps). This
way, TORPEDO ensures that all parallel executor containers
terminate their execution at or before a speciﬁed timestamp.
Observer. To coordinate workload execution and measurement
taking, we introduce the concept of the observer. The observer
is a thread of execution responsible for delegating workloads to
executors, signaling executors to start, and examining the results
of each execution. These “observations” provide feedback
used to guide program generation and mutation, as well as
identify workloads that are likely adversarial. The observer has
access to all feedback results and can use them to immediately
motivate changes to each program for the following round
(Section IV-D). Additionally, the observer is responsible for
logging this information for later analysis (e.g., identifying
adversarial workloads).
D. Constituting Fuzz Testing Feedback
TORPEDO must consider two feedback mechanisms when
making decisions: code coverage and resource utilization. Code
coverage constitutes a simple “binary feedback” mechanism;
a given measurement either contains some new coverage or
does not. A program that generates more new coverage is
strictly ”better” than one that does not. However, the same
relationship does not necessarily hold for resource utilization:
a fuzzing input that generates more CPU utilization than its
predecessor may not strictly be more adversarial; it could
simply spend less time blocked. For designing TORPEDO,
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:18:21 UTC from IEEE Xplore.  Restrictions apply. 
406
we note that adversarial workloads typically exhibit some
amount of “workload ampliﬁcation”, by which the total
amount of resources consumed by the host is increased some
factor beyond what the adversarial program is consuming
itself. This indicates that observing more overall resource
utilization is potentially indicative of an out-of-band workload,
especially when resource limitations have been placed on the
workloads that should restrict them. The observer thread is
then responsible for collecting and analyzing this information
to guide the generation of adversarial programs.
Furthermore, we split
the process of guiding program
generation into two separate problems. The ﬁrst concerns
ranking workloads with respect to ”how likely” they are to
become adversarial. The second concerns identifying with some
certainty that a workload has become adversarial. The ﬁrst
functionality is necessary to motivate program mutation while
evaluation is ongoing for a particular batch, and the second is
necessary for the ultimate goal of identifying programs that
violate one or more resource oracles. We conceive of an oracle
library that contains the necessary logic for both of these tasks
with respect to a particular resource R. More formally, an
oracle library must support the following operations.
1) Score a workload. A higher score indicates the workload
is more indicative of adversarial behavior.
2) Flag a workload. If the ﬂag is thrown, the oracle believes
the workload violates one or more resource isolation
boundaries.
The question remains of how to combine oracle and code
coverage feedback in a meaningful way. Fundamentally, these
two mechanisms are incompatible. Code coverage is collected
per individual syscall in a program, whereas an oracle score
takes into account the behavior of all programs and the host.
TORPEDO solves this problem by considering both mechanisms
at separate granularity levels. Particularly, code coverage is
incorporated at the individual program level, and resource
utilization at the “set of programs” level. In this way, the current
set of all containerized workloads is considered separately from
the individual workloads that comprise the set.
V. IMPLEMENTATION
A. Instrumenting SYZKALLER
The OS kernel fuzzing framework SYZKALLER [32], [56]
takes a set of system call traces (each set is called a “corpus”)
as its seed inputs for fuzzing. Given a corpus of system call
traces, SYZKALLER perturbs input values of system calls and
also shufﬂes system calls on the trace to interact with the
OS kernel. SYZKALLER can also generate new traces during
the fuzzing campaign. It manifests a standard feedback driven
grey-box fuzzing setting guided by kernel code coverage. A
trace is kept for further mutations if the executing system calls
on the trace induces new coverage of the OS kernel; otherwise,
it is discarded. In TORPEDO, we instrument SYZKALLER and
take the resource consumption difference among container
instances as another feedback to guide fuzzing. The whole
implementation contains 1,500+ Go codes as well as non-trivial
C/C++ modiﬁcations.
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
20:
21:
22:
23:
24:
25:
26:
27:
Replacing Virtual Machines with Containers. We begin by
implementing a VM translation layer that creates processes
on the host and passes logs from the fuzzer back for analysis.
Execution requests are passed to containers via IPC pipes
and results are returned using the same mechanism. We
also introduce a small library to support creating containers
with arbitrary resource restrictions and runtimes. Rather than
directly interacting with the Docker daemon over HTTP,
we implement a wrapper around the Docker command line
interface. This ensures that TORPEDO is capable of capturing
potential vulnerabilities created by the interaction between
the CLI and the Docker Daemon, as well as compatible with
equivalent container engines like “podman”, which use the
same CLI commands. Each container is restricted via cgroup
constraints to a single, unique physical core, which makes it
easier to identify when a containerized workload has “escaped”
to another core (i.e., breaking the cpuset cgroup).
Algorithm 2 Observe Execution. Each round lasts for T
seconds. R represents some computing resource the observer
should monitor.
1: function OBSERVER(T , R)
RoundN um ← 0
W orkloads ← ∅
RoundScore ← 0
INITIALIZEEXECUTORS(E)
for ∞ do
W ← GETPROGRAMS(W, RoundScore, R)
StopT ime ← CurrentT ime + T
for E ∈ Executor do
E.stop ← StopT ime
E.program ← w (w ∈ W)
SIGNAL(E)
WAITFORALLEXECUTORS(E)
SIGNALALLEXECUTORS(E)
RoundScore ← TAKEMEASUREMENT(T , R) (cid:4)
(cid:4) Wait for all
executors to signal they are ready
returns after T seconds
16:
17:
18:
LOGROUNDRESULTS(RoundScore)
RoundN um + +
19: function EXECUTOR(O)