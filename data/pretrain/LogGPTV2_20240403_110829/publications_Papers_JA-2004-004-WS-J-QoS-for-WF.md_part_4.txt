i ) for which 0 represents the failing of a task, and 1 represents its success.
n
For example, in a fault-tolerant system with three parallel tasks (n=3), the values of
the indexes i =1, i =0, and i =1 represent the probabilistic state for which tasks t and t
1 2 3 1 3
succeed and task t fails.
2
n
The term g(∑i −k) is used to indicate if a probabilistic state should be considered
j
j=1
in the reliability computation. A probabilistic state is considered only if the number of
n n
tasks succeeding is greater or equal to k, i.e. ∑i ≥k (or equivalently∑i −k ≥0). In
j j
j=1 j=1
19
n
our previous example, since i =1, i =0, i =1 and ∑i =2, the probabilistic state (i =1,
1 2 3 j 1
j=1
i =0, i =1) will be only considered if k ≤2.
2 3
The reliability of a valid state (i.e., a state for which at least k tasks are executed
successfully) is computed based on the product of the reliability of the tasks that compose
the state. In our previous example, where i =1, i =0, i =1, and with k=2, the reliability of
1 2 3
this state is g(2-2)*((1- i )+(2i -1)R(t ))*((1- i )+(2i -1)R(t ))*((1- i )+(2i -1)R(t )) which
1 1 1 2 2 2 3 3 3
can be reduced to 1*R(t )*(1-R(t ))*R(t ). This corresponds to the product of the
1 2 3
probability of task t to succeed, the probability of task t to fail, and the probability of
1 2
task t to succeed.
3
Reduction of a Network System. A network task represents a sub-workflow (Figure 9).
It can be viewed as a black box encapsulating an unknown workflow realization with a
certain QoS. A network task n , having only one task t, can be replaced by an atomic task
s i
t. This reduction can be applied only when the QoS of task t is known. In this
j i
replacement, the QoS of the atomic task t is set to the workflow QoS of the task t, i.e,
j i
X(t) = X(t), X ∈ {T, C, R}.
j i
n
s
t
j
t
i
(a) (b)
Figure 9 - Network system reduction
The input and output transitions of the network task n are transferred to the atomic
s
task t.
j
7 QoS Model Implementation
In the previous sections, we presented a QoS model and the SWR algorithm to address
non-functional issues of workflows, rather than workflow process operations. The model
and algorithm that we have developed has been implemented for the METEOR workflow
management system.
The METEOR project is represented by both a research system (METEOR 2002), and
a suite of commercial systems that provide an open system based, high-end workflow
management solution, as well as an enterprise application integration infrastructure. The
system has been used in prototyping and deploying workflow applications in various
domains, such as bio-informatics (Hall, Miller et al. 2003), healthcare (Anyanwu, Sheth
et al. 2003), telecommunications (Luo, Sheth et al 2003), defense (Kang, Froscher et al.
1999), and university administration (CAPA 1997).
20
The METEOR system has two enactment engines, ORBWork (Kochut, Sheth et al.
1999) and WEBWork (Miller, Palaniswami et al. 1998). In this section we describe the
components that make up the METEOR system and the components that have been
modified, extended, and created to enable QoS management in the context of the
ORBWork engine.
The work discussed in this paper is part of the research system and is not part of any
commercial product yet. It is necessary to make changes to four main components: the
Enactment, the Manager, the Builder, and the Repository. These components and their
relationship to the overall workflow system are illustrated in Figure 10.
Simulation System
Task QOS Estimator
uses QoS Model
BB
Cost
Application
AA NN11 EE NN22 FF Dimensions
uses
Time System
BBuuiillddeerr Instance Level CC DD Reliability Dimensions
BBB Control Flow Create and Manage
AAA NNN111 EEE NNN222 FFF Data flow Workflow schema workflow instances
QoS metrics DDBBLLoogg
CCC DDD Monitor QoS
Schema Level Load
uses WWWooorrrkkkffflllooowww
WfMS Enactment Workflow TTTaaassskkksss
RReeppoossiittoorryy components Manager Service Monitor Instance TTTrrraaannnsssiiitttiiiooonnnsss uses
QoS Data QQQoooSSS IIInnnssstttaaannnccceeesss
Workflow Level
CORBA server, communications,
OS, Hardware, etc.
Infrastructure Level
Figure 10 – QoS Management Architecture
7.1 Enactment System
The modifications that have been made to the ORBWork enactment system include
alterations to the task schedulers, task managers, tasks, and monitors.
In ORBWork enactment system, task schedulers, and tasks are responsible for
managing runtime QoS metrics. From the implementation point of view, we divide the
management of the QoS dimensions into two classes: the system and the application
class. The dimensions of the system class are managed by system components (e.g. a task
scheduler), while the dimensions of the applications class are managed by components
dynamically created to support a particular workflow application (e.g. a task
implementation). In our system, the system class includes the time and reliability
dimensions, while the application class includes the cost dimension.
Since task schedulers decide the starting time of task execution and are notified of task
completion, they are responsible for managing the dimensions of the system class. Task
21
realizations are the candidate components to manage the cost dimension since they
include the necessary functions to dynamically change initial estimates.
7.2 Managing Time
In section 2 we have described task response time (T) as the time an instance takes to be
processed by a task. Task response time is composed of two major components: delay
time (DT) and process time (PT). Delay time is further broken down into queuing delay
(QD) and setup delay (SD). This makes the response time of a task t represented as
followed:
T(t) = DT(t) + PT(t) = QD(t) + SD(t) + PT(t)
To efficiently manage the time dimension, workflow systems must register values for
each of the functions involved in the calculation of task response time (T). Currently, we
register values for all the functions, except for the setup delay. The time dimension has its
values set according to the task structure illustrated in Figure 11. Each state has been
mapped to one of the functions that compose the time dimension. ORBWork system
follows this task structure to represent workflow task execution behavior (Krishnakumar
and Sheth 1995). To more effectively support QoS management, the original structure
has been extended, with the inclusion of the Pre-Init, as shown in Figure 11.
Done/Commit
Pre-Init Initial Executing
Failed/aborted
Synchronization Queuing Processing
Delay Delay Time
Task Response Time Task Reliability
Figure 11 – Revised task structure (extended from (Krishnakumar and Sheth 1995))
The synchronization delay time is calculated based on the difference between the time
registered when a task leaves the pre-init state and the time registered when it enters the
state. A task t remains in the pre-init state as long as its task scheduler is waiting for
another transition to be enabled in order to place the task into an initial state. This only
happens with synchronization tasks, i.e. and-join tasks (Kochut 1999), since they need to
wait until all their incoming transitions are enabled before continuing to the next state.
For all other types of input and output logic (xor-split, xor-join, and-split) the
synchronization delay time is set to zero.
As for the synchronization delay time, the queuing time is the difference between the
time a task leaves and enters the initial state. A task in the initial state indicates that the
task is in a queue waiting to be scheduled (by its task scheduler). ORBWork task
schedulers treat their queues with a FIFO policy. One interesting queuing policy variation
22
is associated with the scheduling of human-tasks. For a human-task instance, being in the
initial state means that the task has been placed in a worklist for human processing. A
user can select any human-task in a worklist, as long as the user role matches the task
role. In this case, the queuing policy is SIRO (Serve In Random Order). Depending on
the workflow system, other useful queuing policies can be used, such as priority queues.
When a task instance enters a queue a time-stamp is attached to it. When the task is
removed from the queue for scheduling, another time-stamp is attached to it so that the
total queuing time can be calculated later. When a task is ready to be executed it transits
to the executing state. As with the previous calculations, the time a task remains in this
state corresponds to the processing time.
Another important time metric is the synchronization delay (SyncD). This measure
corresponds to the time and-join tasks spend waiting for all the incoming transitions to be
enabled. The SyncD(t) of a task t is the difference of t , the time registered when all the
b
incoming transitions of task t are enabled, and t , the time registered when the first
a
incoming transition was enabled, i.e. t - t . This measure gives valuable information that
b a
can be used to re-engineer business processes to increase their time efficiency.
7.3 Managing Reliability
When a task is ready to execute, a task scheduler activates an associated task manager.
The task manager invokes and oversees the execution of the task itself. Once activated,
the task manager stays active until the task itself completes. When the task has completed
or terminated prematurely with an exception, the task manager notifies its task scheduler.
During a task invocation or realization, a number of undesirable events may occur.
Two distinct types of failure may arise (see section 4.5): system failure and process
failure. A system failure occurs when the task scheduler is not able to create a task
manager or when a task manager is not able to invoke its task. A process failure occurs
when an exception is raised during the realization of the task. An exception is viewed as
an occurrence of some abnormal event that the underlying workflow management system
can detect and react to. If an exception occurs during the realization of a task, it can be
placed in the done or fail state (for non-transactional tasks) and commit or abort (for
transactional tasks). The former state indicates that the task execution was unsuccessful,
while the latter state indicates that a task is executed successfully (Krishnakumar and
Sheth 1995).
In our implementation, it is the responsibility of task schedulers to identify the failures
of a task invocation or execution in order to subsequently set the reliability dimension.
Later this information is used to compute the failure rate, which is the ratio between the
number of times the failed/aborted state is reached and the number of times a task was
invoked for execution plus the ratio between the number of times the task scheduler is not
able to create a task manager or when a task manager is not able to invoke its task and the
number of times a task was scheduled for execution by the workflow system.
23
7.4 Managing the Cost
Task managers are implemented as an object and are classified as transactional or non-
transactional, depending on the task managed. Human tasks do not have an associated
task manager.
The task manager is responsible for creating and initializing a QoS cost data structure
from QoS specifications for the task overseen. When the supervised task starts its
execution, the data structure is transferred to it. If the task is a non-transactional one
(typically performed by a computer program), a set of methods is available to
programmatically manage the initial QoS estimates. No methods are supplied to change
the time and reliability dimensions since the task schedulers are responsible for
controlling these dimensions. For transactional tasks (i.e. a database operation), only the
time and reliability dimensions are dynamically set at runtime. The cost dimension, once
initialized from the QoS specifications, cannot be changed. This is because database
systems do not make available information evaluating the cost of the operations executed.
Once the task completes its execution, the QoS data structure is transferred back to the
task manager, and later from the task manager to the task scheduler. The only
responsibility of the task scheduler will be to incorporate the metrics registered for the
time and reliability dimensions (see section 4.2) into the QoS data structure and send it to
the monitor to be processed (see next section).
In the case of human tasks (performed directly by end-users), the QoS specifications
for the cost dimension is included in interface page(s) (as HTML templates) presented to
the end-user. When executing a human task, the user can directly set the cost dimension
to values reflecting how the task was carried out. As mentioned previously, human-tasks
do not have a task manager associated with them, and therefore a specific task scheduler
is responsible for the task supervision. When the task completes its realization, the task
scheduler parses the interface page(s) and retrieves the new QoS metrics that the user
may have modified.
7.5 Monitor
When workflows are installed and instances are executed, the enactment system
generates information messages (events) describing the activities being carried out. The
monitor is an independent component represented by an object that records all of the
events for all of the workflows being processed by the enactment system.
The DBlog is a suitable interface that the monitor uses to store workflow runtime data
in a database. The runtime data generated from workflow installations and instances
execution is propagated to the DBlog that will be in charge of storing the information into
a specified database.
The data model includes metadata describing workflows and workflow versions, tasks,
instances, transitions, and runtime QoS metrics. In addition to storing runtime QoS, we
also store designer-defined QoS estimates. The data model captures the information
necessary to subsequently run suitable tools to analyze workflow QoS. One of the
primary goals of using a database system loosely coupled with the workflow system is to
enable different tools to be used to analyze QoS, such as project management and
statistical tools.
24
DBlog is populated when workflows are installed and instances executed. The DBlog
schema was designed to store three distinct categories of information, reflecting
workflow systems operations with QoS management. The first category corresponds to
data events generated when workflows are installed. During installation, information
describing workflow structure (which includes tasks and transitions) is stored. The
second category of information to be stored corresponds to the QoS estimates for tasks
and transitions that are specified at the workflow design phase. The third category
corresponds to the information which describes how instances are behaving at runtime.
This includes data indicating the tasks’ processing time, cost, and the enabling of
transitions. The monitoring of transitions is important to build functions which
probabilistically describe their enabled rate. The computation of workflow QoS metrics is
based on this stochastic structure.
Since the database stores real-time runtime information of tasks QoS metrics, we are
also investigating the implementation of mechanisms to automatically notify or alert
operators and supervisors when QoS metrics reach threshold values, so that corrective
actions can be taken immediately.
7.6 Workflow Builder
The workflow builder tool is used to graphically design and specify a workflow. In most
cases, after a workflow design no extra work is necessary and it can be converted
automatically to an application by a code generator. The builder is used to specify
workflow topology, tasks, transitions (control flow and data flow), data objects, task
invocation, roles, and security domains (Kang, Park et al. 2001). During the design phase,
the designer is shielded from the underlying details of the runtime environment and
infrastructure, separating the workflow definition from the enactment system on which it
will be installed and executed. To support workflow QoS management the designer must
be able to set estimates for transition probabilities and QoS estimates for tasks. This
information is later combined with historical data, which plays a larger role as more
instances are executed, to create a runtime QoS model for tasks and a probability model
for transitions.
The workflow model and the task model have been extended to support the
specification of QoS metrics. To support these extensions, the builder has been enhanced
to allow designers to associate probabilities with transitions and to make possible the
specification of initial QoS metrics for tasks (see section 5.1). Previously, the workflow
model only included data flow mappings associated with transitions. The association of
probabilities with transitions transforms a workflow into a stochastic workflow. The
stochastic information indicates the probability of a transition being fired at runtime. The
QoS model specified for each task and transitions probabilities are embedded into the
workflow definition and stored in XML format.
7.6.1 Setting Initial Task QoS Estimates
At design time, each task receives information which includes its type, input and output