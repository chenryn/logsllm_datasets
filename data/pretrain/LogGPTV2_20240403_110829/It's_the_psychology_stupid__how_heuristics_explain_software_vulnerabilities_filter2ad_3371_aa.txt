title:It's the psychology stupid: how heuristics explain software vulnerabilities
and how priming can illuminate developer's blind spots
author:Daniela A. S. de Oliveira and
Marissa Rosenthal and
Nicole Morin and
Kuo-Chuan Yeh and
Justin Cappos and
Yanyan Zhuang
It’s the Psychology Stupid: How Heuristics Explain
Software Vulnerabilities and How Priming Can Illuminate
Developer’s Blind Spots
†
Daniela Oliveira Marissa Rosenthal
Kuo-Chuan Yeh*
Justin Cappos
‡
Nicole Morin
‡
Yanyan Zhuang
†
†
‡
University of Florida Bowdoin College
Pennsylvania State University* NYU
daniela@ece.uﬂ.edu, mrosenth,PI:EMAIL, PI:EMAIL, jcappos,PI:EMAIL
ABSTRACT
Despite the security community’s emphasis on the importance of
building secure software, the number of new vulnerabilities found
in our systems is increasing. In addition, vulnerabilities that have
been studied for years are still commonly reported in vulnerabil-
ity databases. This paper investigates a new hypothesis that soft-
ware vulnerabilities are blind spots in developer’s heuristic-based
decision-making processes. Heuristics are simple computational
models to solve problems without considering all the information
available. They are an adaptive response to our short working mem-
ory because they require less cognitive effort. Our hypothesis is that
as software vulnerabilities represent corner cases that exercise un-
usual information ﬂows, they tend to be left out from the repertoire
of heuristics used by developers during their programming tasks.
To validate this hypothesis we conducted a study with 47 de-
velopers using psychological manipulation. In this study each de-
veloper worked for approximately one hour on six vulnerable pro-
gramming scenarios. The sessions progressed from providing no
information about the possibility of vulnerabilities, to priming de-
velopers about unexpected results, and explicitly mentioning the
existence of vulnerabilities in the code. The results show that (i)
security is not a priority in software development environments, (ii)
security is not part of developer’s mindset while coding, (iii) devel-
opers assume common cases for their code, (iv) security thinking
requires cognitive effort, (v) security education helps, but devel-
opers can have difﬁculties correlating a particular learned vulnera-
bility or security information with their current working task, and
(vi) priming or explicitly cueing about vulnerabilities on-the-spot
is a powerful mechanism to make developers aware about potential
vulnerabilities.
1.
INTRODUCTION
Over the past decades, the security community has spent tremen-
dous effort in emphasizing security awareness and building secure
software. However, the number of new vulnerabilities keeps in-
creasing in today’s software systems. In 2013, the Symantec In-
ternet Security report has announced that 5291 new vulnerabilities
occurred in 2012, 302 more than in 2011 [1]. Despite the fact that
vulnerabilities have been the focus of the security community for
decades, frequently observed vulnerabilities such as buffer over-
ﬂows and SQL injections are still repeatedly reported. With to-
Permission to make digital or hard copies of all or part of this work for per-
sonal or classroom use is granted without fee provided that copies are not
made or distributed for proﬁt or commercial advantage and that copies bear
this notice and the full citation on the ﬁrst page. Copyrights for components
of this work owned by others than the author(s) must be honored. Abstract-
ing with credit is permitted. To copy otherwise, or republish, to post on
servers or to redistribute to lists, requires prior speciﬁc permission and/or a
fee. Request permissions from Permissions@acm.org.
ACSAC’14 December 08 - 12 2014, New Orleans, LA, USA
Copyright 2014 ACM 978-1-4503-3005-3/14/12...$15.00
http://dx.doi.org/10.1145/2664243.2664254.
day’s increasingly diverse software, and a society signiﬁcantly de-
pendent on networked computer systems, the inability to effectively
handle software vulnerabilities will result in more serious security
breaches in the future.
Facing this huge number of security vulnerabilities, the research
community has chosen to criticize the current security education
and developers. As an example, SQL injection has caused issues
that commonly lead to password database disclosures. When refer-
ring to the cause for SQL injection, Bruce K. Marshall stated that
“[T]he popularity of the language has led to the rapid deployment
of PHP sites and PHP-based content management systems by peo-
ple who lack an education in web application security. Even though
the risk of SQL injection in PHP should be fairly well understood,
some organizations still end up deploying code that doesn’t imple-
ment proper security controls” [2]. The frequent condemnation of
security education and criticism on software developers, however,
do not help to reason about the root causes of security vulnerabili-
ties.
We argue that the nature of increasingly insecure software with
well-studied vulnerabilities does not lie in the lack of security ed-
ucation from the developer’s part. We seek to examine the hy-
pothesis that software vulnerabilities are blind spots in developer’s
heuristic-based decision-making processes. Heuristics are compu-
tational models that do not use all information available to reach a
particular decision or course of action. During their everyday pro-
gramming tasks, developers use heuristics, either consciously or
unconsciously, that do not include security or vulnerability infor-
mation. As software vulnerabilities represent uncommon cases not
completely understood by developers and exercise unusual infor-
mation ﬂows, they are usually left out from developer’s heuristics.
In spite of that, decision-making is adaptive. Therefore, another
hypothesis we investigate in this paper is whether priming develop-
ers on the spot about the possibility of vulnerabilities will change
their mindset towards security and make security-thinking part of
their repertoire of heuristics.
Despite the abundant security tips for safe programming [3], de-
velopers may not be considering these security practices when writ-
ing code in their daily tasks. Psychological research documents that
humans often engage in heuristic-based decision-making processes
that are due to the limitations in a human’s working memory ca-
pacity [4, 5]. Heuristics occur when a human is facing complex
problems with a large amount of information, and thus she tends to
make simpliﬁed, sub-optimal decisions regardless of the rich infor-
mation available [6, 7]. Although heuristics is an adaptive tool, they
can lead to software faults and deleterious consequences. Seeking
security-related information while coding is usually not the case
in software development. When programming, developers tend to
focus on their immediate goals that usually involve functional and
performance requirements. As a result, they do not expect the pos-
sibility of an adversary exploiting their code [8].
To validate this hypothesis, we conducted an IRB-approved study
with 47 participants from a variety of backgrounds, including de-
(cid:21)(cid:28)(cid:25)
velopers from the industry, CS undergraduate and graduate stu-
dents, CS faculty, software developer managers, and software testers.
The participants were asked to work on six programming scenar-
ios with software vulnerabilities in a survey session. The session
lasted approximately one hour. Our study leveraged psychological
manipulation [9] where participants did not know in advance that
the study was security-related, and were progressively cued about
possible vulnerabilities. The goal was to validate the hypothesis
that security information is usually not part of developers’ heuris-
tic thinking during their everyday programming; however, security
information can become part of their repertoire of heuristics when
developers are cued about the possibility of vulnerabilities. Analy-
sis of participant’s answers showed that stronger cues have stronger
effect on developers.
In summary, this paper has the following contributions:
1. We present a hypothesis that views software vulnerabilities
as blind spots in developers’ heuristic-based decision-making
processes, and propose a paradigm that advocates security in-
formation and education should reach developers when they
need it, on the spot.
2. We conduct an IRB-approved study with 47 developers to
validate our hypothesis and show that 60% of the developers
thought that when primed about security they become aware
of the security implications of their code, and 83% of the
developers thought that explicitly mentioning the possibility
of vulnerabilities on the spot changed their mindset towards
security.
3. We present a thorough discussion of developers’ interview
answers that are analyzed with techniques widely used in the
social, behavioral and economic sciences. The results show
that (i) security is not a priority in software development en-
vironments, (ii) security is not part of a developer’s mindset
while coding, (iii) developers assume common cases for their
code, (iv) security thinking requires cognitive effort, (v) se-
curity education helps, but developers can have difﬁculties
correlating particular learned vulnerability or security infor-
mation with their working task, and (vi) priming or explicitly
cueing about vulnerabilities on-the-spot is a powerful mech-
anism to make developers aware of the potential vulnerabili-
ties.
This paper is organized as follows. Section 2 describes humans’
heuristic-based decision making processes and how they relate to
software vulnerabilities. Section 3 presents the study method to
validate our hypothesis. In Section 4 we detail the scenarios pre-
sented to the developers during our study, and the use of psycho-
logical manipulation. Section 5 presents the results obtained, and
the Section 6 discusses these results and provides our recommen-
dations for developers. Section 7 gives an overview of related work
and Section 8 concludes.
2. HEURISTICS AND VULNERABILITIES
Psychology research has documented that during evolution, hu-
mans have become hardwired for shortcut and heuristic-based de-
cision making processes [4, 5]. Heuristics are cognitive processes
that humans use to make decisions and perform tasks [10]. They are
simple computational models that allow one to quickly ﬁnd feasible
solutions and that do not necessarily use all information available.
Heuristics rely on core human mental capacities, such as recog-
nition, recall and imitation [11]. They represent an alternative to
optimization models that use all information available and always
compute the best solution.
As psychological processes, heuristics are very useful as they re-
quire less cognitive effort for a particular task. Humans have a short
working memory, which makes cognitive processes difﬁcult when
too much information, possibilities, or choices are available [12].
In such cases, humans employ sub-optimal decision-making pro-
cesses that can lead to mistakes [6, 7]. This argument is reinforced
by Zipf’s principle of least effort [13], which states that humans
use as little effort as necessary to solve a problem. Heuristics are
adaptive responses to human’s short working memory. They have
high predictive accuracy when information is scarce, but can lead
to severe biases and errors in decision making or ensuring the cor-
rectness of tasks [10, 11].
Such heuristic-based decision-making processes also largely af-
fect software security. According to Thorngate, humans tend to
ignore information in heuristics because they do not notice cer-
tain issues of a particular problem, or there are small or infrequent
decrements in reward that result from their ignorance or misuse of
relevant information about the problem in hand [10]. In software
development, this is reﬂected by the fact that functional and per-
formance requirements usually have higher priority. Kieskamp and
Hoffrage [14] also argue that under time pressure, a common situ-
ation in software development, humans are likely to adopt heuris-
tics that are even simpler, and do not require much integration of
information.
In spite of that, a decision-maker is adaptive such
that through proper feedback they can improve their repertoire of
heuristics. However, there also exists a forgetting process where a
particular piece of knowledge or strategy can be gradually wiped
out from the decision-maker’s repertoire of heuristics, if not prop-
erly reinforced.
Our hypothesis is that software vulnerabilities are blind spots
in developer’s heuristic-based decision-making processes. Soft-
ware vulnerabilities are introduced mostly because developers use
heuristics to make decisions in their everyday tasks. When devel-
opers constantly make sub-optimal decisions, consciously or un-
consciously, they are mostly concerned about ﬁnding a solution or
an efﬁcient solution to a particular problem. However, as software
vulnerabilities often lie in the corner cases and unusual information
ﬂows, they tend to be left out from developers’ heuristics. How-
ever, when properly primed about security, on the spot and with
cues correlating with their current programming tasks, developers
can properly develop a security mindset for the task at hand.
3. DEVELOPER’S STUDY METHOD
Forty-seven participants were tested in this study in exchange for
a gift certiﬁcate. Participants were invited via direct e-mail sent to
software development companies, universities and colleges in the
United States and abroad.
3.1 Source Materials
Stimuli consisted of programming scenarios that included soft-
ware vulnerabilities and that tested developer’s understanding on
the issue. The vulnerabilities in each programming scenario were:
buffer overﬂow [15], cross-site scripting (XSS) [16], SQL injec-
tion [17], Python Secure Socket Layer (SSL) [18], time of check
to time of use (TOCTTOU) [19], and brute force password exhaus-
tion vulnerabilities [20]. Each scenario is an exhibit question in
Qualitative Research [21], which sharpens the respondents’ con-
centration by asking them to respond to a speciﬁc statement, story
or artifact. A scenario is a short code snippet with comments that
formulates the underlying vulnerability in an focused way, exer-
cising it, adding all necessary context, and removing unnecessary
noise. Noise was removed in a careful way, as vulnerabilities are
often located in hidden cases and also in unusual information ﬂows.
Example programming scenarios will be given in Section 4.
3.1.1
The scenarios are presented to developers with different informa-
tion conditions: (i) with no information about security or vulnera-
bilities (controlled condition), (ii) with implicit information about
possible unexpected results in code (priming condition), and (iii)
with explicit information about the existence of vulnerabilities in
code (explicit condition). Examples of these information condi-
tions in our study are given in Section 4.
3.1.2 Pilot Study
Before inviting developers and distributing the survey, a pilot
study was performed with undergraduate students from one of the
Information Conditions
(cid:21)(cid:28)(cid:26)
author’s institutions. In this study, students were asked to answer
questions for each scenario and provide feedback in a live follow-
up interview about their experience. Follow-up interviews were
tape-recorded and included a thorough debrief on each vulnerabil-
ity. Based on their feedback, the scenarios were adjusted to max-
imize their clarity. An online survey was then created that con-
sisted of the six ﬁnalized scenarios, followed by open-ended ques-
tions that reﬂected the interview questions in the pretest. Stimulus
presentation and the collection of responses were controlled using
Qualtrics platform for online data collection [22].
3.2 Procedure of Study
Participants were instructed to answer questions in the survey
as accurately and thoroughly as possible, without knowing that the
study was security-related. To ensure that subjects were not suspi-
cious of the aim of our study, the survey employed psychological
manipulation techniques [9] that involved a cover story presented
in a consent form signed by the participants. The cover story ex-
plained that this was a study of how developers think about pro-
gramming in general, so that researchers of this study could build
mental models about typical developers. They were informed that
in the survey, there would be six programming scenarios and gen-
eral questions about snippets of code, and they would be asked to
perform small programming tasks to modify the code.
Subjects were not restricted to a particular time frame to com-
plete the survey. However, they were informed that once they com-
pleted one scenario, they would not be able to return to previous
pages. Following the last scenario, subjects responded to open-
ended questions that addressed the manipulation of information,
the subjects’ personal experience with computer security, and their
familiarity with each of the tested vulnerabilities. The examples
of open-ended questions are given in Section 4. To leverage the
educational purposes of the study, subjects were debriefed on each
security vulnerability.
3.3 Design
Psychological research experiments typically have both depen-
dent and independent variables. In this study, the dependent vari-
ables are the participants’ survey scores and their answers to the
open-ended debrief questions. There are also two independent vari-
ables that are varied and manipulated by the experimenter in this
study. The ﬁrst one was the vulnerability scenario of a code snippet.
The second is the level of information (condition) emphasized by
each question and could be no information, implicit or explicit in-
formation. In a psychology experiment, researchers are interested
in how the changes in an independent variable cause changes in
the dependent variable [9]. Two one-way Analyses of Variance
(ANOVAs) [23] across the three levels of information and six vul-
nerability scenario types were conducted on data accuracy.
Scenarios in the controlled and priming (implicit) conditions con-
tained questions that addressed user input, code execution, and
code modiﬁcation.
In the priming condition, subjects answered
an additional question that asked whether unexpected results could
arise from the presented snippet of code. This question aimed to
prime participants to think about security-related vulnerabilities. In
the explicit condition, subjects were cued to look for the vulnera-
bility and were directly told that the code had a security ﬂaw.
The order of the scenarios was randomized for each participant.
However, because the manipulation intended for subjects to change
their mindset, information conditions, or whether the scenario was
in the controlled, implicit, or explicit condition, were presented to
all participants in a speciﬁc order. The ﬁrst two scenarios provided
no information about the corresponding security ﬂaws (controlled
condition), the second two scenarios provided implicit information
(priming) about the corresponding security ﬂaws, and the last two
scenarios explicitly addressed the fact that the snippets of code had
security ﬂaws (explicit).
if(!isset($userinfo[$_POST[’username’]])) {
// Invalid username
echo "Authentication failed."
}
else {
<? php
session_start();
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.