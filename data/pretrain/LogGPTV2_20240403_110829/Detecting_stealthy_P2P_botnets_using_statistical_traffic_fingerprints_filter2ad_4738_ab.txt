Gnutella&Bittorrent
Table I: P2P Applications
notation
𝑇𝑝2𝑝
𝑁𝑓
No-DNS Peers
𝑁𝑐𝑙𝑢𝑠𝑡
𝑁𝑏𝑔𝑝
ˆ𝑇𝑝2𝑝
Description
the active time of P2P application
the number of failed connections per hour
the percentage of ﬂows associated with no domain names
the number of clusters left by enforcing Θ𝑏𝑔𝑝 and Θ𝑝2𝑝
the largest number of unique bgp preﬁxes in one cluster
the estimated active time for P2P application
Table II: Notations and Descriptions
high-level steps reported below:
nications.
1) Identify the set H of all hosts engaged in P2P commu-
2) Identify the subset P ⊆ H of P2P clients whose active
time is similar to the active time of the underlying
systems.
3) Identify the subset B ⊆ P which exhibit similar P2P
communication patterns, and a signiﬁcant overlap of
the set of contacted peers. We classify the hosts in set
B as P2P bots.
To illustrate the statistical features and motivate the re-
lated thresholds used by our system, we used ﬁve popular
P2P applications (see Table I) for 24 hours to collect
their trafﬁc traces. For the Bittorrent application, we gen-
erated two separate 24-hour traces (T-Bittorrent and
T-Bittorrent-2). In this section we report a number
of measurements on the obtained trafﬁc traces to better
motivate some of our design choices. Table III reports the
feature values measured on the collected trafﬁc traces. The
notation used for our statistical features is summarized in
Table II.
We now describe the components of our detection system
in more details.
A. Trafﬁc Volume Reduction
As a ﬁrst step, we want
to ﬁlter out network trafﬁc
(and their sources) that is unlikely to be related to P2P
communications. This is accomplished in part by passively
analyzing DNS trafﬁc, and identifying network ﬂows whose
destination IP address was previously resolved in a DNS
response. The reason is that P2P clients usually contact their
peers directly, by looking up IPs from a routing table for
the overlay network, rather than resolving a domain name
(a possible exception may be when a peer bootstraps into
a P2P network by looking up domain names that resolve
to stable super-nodes). This observation is supported by
Table III (No-DNS Peers), which illustrates the percentage
of ﬂows whose destination IP was not resolved from a
domain name. It conﬁrms that the vast majority of ﬂows
generated by P2P applications do not have destination IPs
resolved from domain names. The remaining small fraction
of ﬂows are either related to bootstrapping (e.g., in the
Trace
𝑇𝑝2𝑝
𝑁𝑓
No-DNS Peers
𝑁𝑐𝑙𝑢𝑠𝑡
T-Bittorrent
T-Emule
T-Limewire
T-Skype
T-Ares
1602
318
1278
81
489
24hr
24hr
24hr
24hr
24hr
Table III: Measurement of Features
96.85%
99.99%
99.97%
99.93%
99.99%
𝑁𝑏𝑔𝑝
12857
1133
5661
12806
1596
ˆ𝑇𝑝2𝑝
24hr
24hr
24hr
24hr
24hr
17
8
36
12
16
case of bittorrent.com and skype.com) or for downloading
advertisement content from popular websites. Since most
non-P2P applications (e.g., browsers, email clients, etc.)
often connect to a destination address resulting from domain
name resolution,
this simple ﬁlter can eliminate a very
large percentage of non-P2P trafﬁc (see Section IV) while
retaining the vast majority of P2P communications.
B. Identifying P2P Clients
After trafﬁc volume reduction we consider the remaining
trafﬁc, and for each host ℎ within the monitored network
we identify three ﬂow sets (we call “outgoing” those ﬂows
that have been initiated by ℎ):
1) 𝑆𝑡𝑐𝑝(ℎ): ﬂows related to successful outgoing TCP con-
nections.
2) 𝑆𝑢𝑑𝑝(ℎ): ﬂows related to successful outgoing UDP
(virtual) connections.
3) 𝑆𝑜(ℎ): ﬂows related to failed outgoing TCP/UDP con-
nections.
We consider as successful those TCP connections with
a completed SYN, SYN/ACK, ACK handshake, and those
UDP (virtual) connections for which there was at least one
“request” packet and a consequent response packet.
P2P applications act as both clients and servers. A node in
a P2P network can initiate (TCP or UDP virtual) connections
to its peers and accept connections initiated by other peers.
In client-mode, P2P nodes periodically probe their peers
with ping/pong messages to maintain a view of the
overlay network (usually for routing purposes), or search
for content. A consequence of this behavior is the fact that
P2P nodes will often generate a large number of failed
outgoing ﬂows. The reason is that P2P networks are usually
characterized by a signiﬁcant node churn [4], due to previous
nodes that leave the network and new nodes that join it (the
churn is intuitively correlated with users that turn on or off
their P2P applications or machines). Therefore, a node that
sends a ping message to a known peer will often discover
that the peer is not up anymore (no pong is received, thus
causing a failed connection).
At this point, we retain all hosts that generated at least
a successful outgoing TCP or UDP connection, and that
generated more than a predeﬁned number Θ𝑜 of outgoing
failed TCP/UDP connections. Namely, we retain a host ℎ if
∣𝑆𝑡𝑐𝑝(ℎ)∣ + ∣𝑆𝑢𝑑𝑝(ℎ)∣ > 0 AND 𝑆𝑜(ℎ) > Θ𝑜, and discard
all other hosts (it is worth noting that here we are only
considering those ﬂows that passed the DNS-based trafﬁc
volume reduction ﬁlter described in Section III-A). Table III,
reports the number 𝑁𝑓 of failed outgoing connections per
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:47:04 UTC from IEEE Xplore.  Restrictions apply. 
124T−Bittorrent
(1,1,145,319,UDP)
(5,3,346,170,TCP)
1
0.8
0.6
0.4
F
D
C
0.2
1
0.8
0.6
0.4
0.2
0
T−Bittorrent−2
(1,1,145,319,UDP)
(5,3,346,170,TCP)
(1,1,145,310,UDP)
TCP
UDP
0
550
450
Flow Size (Bytesent + Byterecv)
500
(1,1,145,310,UDP)
TCP
UDP
550
450
Flow Size (Bytesent + Byterecv)
500
Figure 2: CDF of Flow Size
hour for different P2P applications. We can see that P2P
applications typically generate a large number (from several
tens up to thousands) of failed connection attempts with
other peers. Therefore, we conservatively set Θ𝑜 = 10.
What we just described is a coarse-grained ﬁlter that
allows us to focus on candidate P2P nodes. We further apply
a more ﬁne-grained analysis to prune away hosts that are
not actual P2P nodes. For example, we want to eliminate
hosts that made it into the list of candidate P2P nodes by
chance (e.g., because of scanning behavior). To this end,
we ﬁrst consider the fact that each node of a P2P network
frequently exchanges a number of control messages (e.g.,
ping/pong messages) with other peers. Also, we notice that
the characteristics of these messages, such as the size and
frequency of the exchanged packets, are similar for nodes
in the same P2P network, and vary depending on the P2P
protocol and network in use. In addition, we notice that a
node will often exchange control messages with a relatively
large number of peers distributed in many different networks,
where each network can be represented by its BGP preﬁx.
Figure 2 describes the distribution of ﬂow sizes for two
Bittorrent traces, where a large number of ﬂows share
similar sizes.
To identify ﬂows corresponding to P2P control mes-
sages, we ﬁrst apply a ﬂow clustering process intended
to group together similar ﬂows for each candidate P2P
node ℎ. Given sets of ﬂows 𝑆𝑡𝑐𝑝(ℎ) and 𝑆𝑢𝑑𝑝(ℎ), we
describe each ﬂow as a vector of statistical features 𝑣(ℎ) =
[𝑃 𝑘𝑡𝑠, 𝑃 𝑘𝑡𝑟, 𝐵𝑦𝑡𝑒𝑠, 𝐵𝑦𝑡𝑒𝑟], in which 𝑃 𝑘𝑡𝑠 and 𝑃 𝑘𝑡𝑟 rep-
resent the number of packets sent and received, and 𝐵𝑦𝑡𝑒𝑠
and 𝐵𝑦𝑡𝑒𝑟 represent
the number of bytes sent and re-
ceived, respectively. We then apply an agglomerative hier-
archical clustering algorithm (described in detailed in the
following paragraphs) to partition the set of vectors (i.e.,
of ﬂows) 𝑉𝑡𝑐𝑝(ℎ) ={𝑣 (ℎ)𝑖}𝑖=1..∣𝑆𝑡𝑐𝑝(ℎ)∣ and 𝑉𝑢𝑑𝑝(ℎ) =
{𝑣(ℎ)𝑖}𝑖=1..∣𝑆𝑢𝑑𝑝(ℎ)∣ into a number of clusters. Each of the
obtained clusters of ﬂows, 𝐶𝑗(ℎ), represents a group of ﬂows
with similar size. For each 𝐶𝑗(ℎ) (notice that each vector
can be mapped back to the ﬂow it describes), we consider
the set of destination IP addresses related to the ﬂows in
the clusters, and for each of these IPs we consider its BGP
preﬁx (using BGP preﬁx announcements). Finally, we count
the number of distinct BGP preﬁxes related to destination
IPs in a cluster 𝑏𝑔𝑝𝑗 = 𝐵𝐺𝑃 (𝐶𝑗(ℎ)), and discard those
clusters of ﬂows for which 𝑏𝑔𝑝𝑗 < Θ𝑏𝑔𝑝.
Host P2P
App
s
y
s
T
P
2
P
T
PING/PONG
Peer Discovery
ˆ
TP 2P = max(T (F C1), T (F C2))
Fingerprint Cluster 1
(FC1)
......
T(FC1)
Clustering
Two-level
(Birch + 
Hierarchical)
......
T(FC2)
Network 
Flows
Fingerprint Cluster 2
(FC2)
Figure 3: Example of Flow Clustering to Identify P2P Hosts
We call ﬁngerprint clusters the remaining cluster of ﬂows.
Therefore, each host ℎ can now be described by a set of
ﬁngerprint clusters 𝐹 𝐶(ℎ) = {𝐹 𝐶1, .., 𝐹 𝐶𝑘}. We label ℎ
as P2P node if 𝐹 𝐶(ℎ) ∕= ∅, namely if ℎ generated at least
one ﬁngerprint cluster.
The clustering algorithm for discovering clusters of sim-
ilar ﬂows may affect the system efﬁciency. For example,
a direct usage of hierarchical clustering algorithm (with
𝑂(𝑛2) time complexity where 𝑛 is the number of ﬂows) will
introduce prohibitive time consumption when processing a
large number of ﬂows generated by a P2P node. Therefore,
we design a two-level clustering scheme to improve its
performance. First, given a pre-deﬁned parameter 𝐶𝑛𝑡𝑏𝑖𝑟𝑐ℎ,
we use BIRCH [23], a streaming clustering algorithm
with time complexity 𝑂(𝑛), to efﬁciently identify at most
𝐶𝑛𝑡𝑏𝑖𝑟𝑐ℎ sub-clusters from the sets of TCP and UDP ﬂows
respectively, where the distance of two ﬂows is deﬁned
as the Euclidean distance of [𝑃 𝑘𝑡𝑠, 𝑃 𝑘𝑡𝑟, 𝐵𝑦𝑡𝑒𝑠, 𝐵𝑦𝑡𝑒𝑟].
Then, for each sub-cluster, we aggregate ﬂows in it and
represent it using a vector, where this vector describes the
average value of each feature [𝑃 𝑘𝑡𝑠, 𝑃 𝑘𝑡𝑟, 𝐵𝑦𝑡𝑒𝑠, 𝐵𝑦𝑡𝑒𝑟]
of ﬂows in this sub-cluster. We further apply hierarchical
clustering with DaviesBouldin validation index [7] on top
of the vectors (sub-clusters), and ﬁnd clusters of vectors,
where each cluster represents a set of similar vectors (sub-
clusters). For all the sub-clusters belonging to a cluster, we
ﬁnally group the ﬂows in these sub-clusters to the same
cluster of ﬂows. For this two-level clustering scheme, the
time complexity to process the ﬂows of one P2P node is
mainly bounded by 𝑂(𝐶𝑛𝑡2
𝑏𝑖𝑟𝑐ℎ). Currently we conﬁgure
𝐶𝑛𝑡𝑏𝑖𝑟𝑐ℎ = 4000 (the evaluation of system performance
over 𝐶𝑛𝑡𝑏𝑖𝑟𝑐ℎ is presented in Section IV-C5).
We applied this two-level clustering algorithm to the
sample traces of 5 P2P clients. 𝑁𝑏𝑔𝑝 in Table III presents
the maximum number of distinct BGP preﬁxes of destination
IPs in a ﬁngerprint cluster. We therefore conservatively set
the threshold Θ𝑏𝑔𝑝 = 50, which is much smaller than the
measured 𝑁𝑏𝑔𝑝.
Figure 3 illustrates an example of the ﬂow clustering pro-
cess for a P2P node. Flows corresponding to ping/pong
and peer-discovery share similar sizes respectively,
and therefore they are grouped into two clusters (𝐹 𝐶1
and 𝐹 𝐶2). Since the number of destination BGP preﬁxes
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:47:04 UTC from IEEE Xplore.  Restrictions apply. 
125involved in each cluster is larger than Θ𝑏𝑔𝑝, we take𝐹 𝐶 1
and 𝐹 𝐶2 as its ﬁngerprint clusters. A ﬁngerprint cluster
summary, (𝑃 𝑘𝑡𝑠, 𝑃 𝑘𝑡𝑟, 𝐵𝑦𝑡𝑒𝑠, 𝐵𝑦𝑡𝑒𝑟, proto), presents the
protocol and the average number of sent/received pack-
ets/bytes for all the ﬂows in this ﬁngerprint cluster. Examples
of ﬁngerprint cluster summaries for two Bittorrent
traces (T-Bittorrent and T-Bittorrent-2) and one
Skype trace, are illustrated in Table IV. “(1 1 145 319,
UDP)” and “(1 1 109 100, UDP)” are shared by both
Bittorrent sample traces. The payload of ﬂows cor-
responding to these two ﬁngerprint clusters are illustrated
in Table V. It reveals that the ﬁngerprint cluster of “(1 1
145 319, UDP)” represents the ﬂows for node discovery,
and that of “(1 1 109 100, UDP)” contains the ﬂows for
ping/pong.
C. Identifying Persistent P2P Clients
As we mentioned at the beginning of Section III, P2P bots
make themselves persistent into the compromised system,
and run for as long as the system is powered on. Based
on this observation, we aim to identify P2P clients that are
active for a time 𝑇𝑃 2𝑃 close to the active time 𝑇𝑠𝑦𝑠 of the
underlying system they are running on. While this behavior
is not unique of P2P bots and may be representative of other
P2P applications (e.g., Skype clients that run for as long as
a machine is on), identifying persistent P2P clients takes us
one step closer to identifying P2P bots.
To estimate 𝑇𝑠𝑦𝑠 we proceed as follows. For each host
ℎ ∈ H that we identiﬁed as P2P clients according to
Section III-B, we consider the timestamp 𝑡𝑠𝑡𝑎𝑟𝑡(ℎ) of the
ﬁrst network ﬂow we observed from ℎ and the timestamp
𝑡𝑒𝑛𝑑(ℎ) related to the last ﬂow we have seen from ℎ. After-
wards, we divide the time 𝑡𝑒𝑛𝑑(ℎ)− 𝑡𝑠𝑡𝑎𝑟𝑡(ℎ) into 𝑤 epochs
(e.g., of one hour each), denoted as 𝑇 = [𝑡1, ..𝑡𝑖, .., 𝑡𝑤].
We further compute a vector 𝐴(ℎ, 𝑇 ) = [𝑎1, ..𝑎𝑖, .., 𝑎𝑤]
where 𝑎𝑖 is equal to 1 if ℎ generated any network trafﬁc
between 𝑡𝑖−1 and 𝑡𝑖. We then estimate the active time of ℎ
as 𝑇𝑠𝑦𝑠 =
∑𝑤
𝑖=1 𝑎𝑖.
The challenge is how to accurately estimate the active time
of a P2P application. Since a P2P application periodically
exchanges network control (e.g., ping/pong) messages with
other peers as long as the P2P application is active, we
can leverage the active time of a ﬁngerprint cluster, which
represents ﬂows of control messages, in order to estimate
the active time of the corresponding P2P application. For
each host ℎ (again, we consider only the hosts in H, which
we previously identiﬁed as P2P clients) we consider the set
of its ﬁngerprint clusters 𝐹 𝐶(ℎ) ={𝐹 𝐶 1, ..𝐹 𝐶𝑗.., 𝐹 𝐶𝑘}
(see Section III), and for each ﬁngerprint cluster 𝐹 𝐶𝑗 we
compute a vector 𝐴(𝐹 𝐶𝑗, 𝑇 ) = [𝑎𝑗
𝑤] where an
element 𝑎𝑗
is equal to 1 if the ﬁngerprint cluster 𝐹 𝐶𝑗
𝑖
contains a ﬂow between 𝑡𝑖−1 and 𝑡𝑖, otherwise 𝑎𝑗
𝑖 =
0. We compute the active time of a ﬁngerprint cluster
𝐹 𝐶𝑗 as 𝑇 (𝐹 𝐶𝑗) =
𝑖 . Finally, we estimate the
𝑖 , .., 𝑎𝑗
∑𝑤
1, ..𝑎𝑗
𝑖=1 𝑎𝑗
Trace
T-Bittorrent