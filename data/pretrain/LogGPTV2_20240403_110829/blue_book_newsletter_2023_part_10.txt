          - .cz.toml
          - '.gitea/workflows/**'
    jobs:
      test:
        name: Test
        runs-on: ubuntu-latest
        steps:
            ...
    ```
    The only downside is that if you set this pipeline as required in the branch protection, the merge button will look yellow instead of green when the pipeline is skipped.
* New: [Molecule doesn't find the `molecule.yaml` file.](molecule.md#molecule-doesn't-find-the-`molecule.yaml`-file)
    This is expected default behavior since Molecule searches for scenarios using the `molecule/*/molecule.yml` glob. But if you would like to change the suffix to yaml, you can do that if you set the `MOLECULE_GLOB` environment variable like this:
    ```bash
    export MOLECULE_GLOB='molecule/*/molecule.yaml'
    ```
* Correction: [Using `paths-filter` custom action to skip job actions.](gitea.md#using-`paths-filter`-custom-action)
    ```
    jobs:
      test:
        if: "!startsWith(github.event.head_commit.message, 'bump:')"
        name: Test
        runs-on: ubuntu-latest
        steps:
          - name: Checkout the codebase
            uses: https://github.com/actions/checkout@v3
          - name: Check if we need to run the molecule tests
            uses: https://github.com/dorny/paths-filter@v2
            id: filter
            with:
              filters: |
                molecule:
                  - 'defaults/**'
                  - 'tasks/**'
                  - 'handlers/**'
                  - 'tasks/**'
                  - 'templates/**'
                  - 'molecule/**'
                  - 'requirements.yaml'
                  - '.github/workflows/tests.yaml'
          - name: Run Molecule tests
            if: steps.filter.outputs.molecule == 'true'
            run: make molecule
    ```
    You can find more examples on how to use `paths-filter` [here](https://github.com/dorny/paths-filter#examples ).
* New: [Get variables from the environment.](molecule.md#get-variables-from-the-environment)
    You can configure your `molecule.yaml` file to read variables from the environment with:
    ```yaml
    provisioner:
      name: ansible
      inventory:
        group_vars:
          all:
            my_secret: ${MY_SECRET}
    ```
    It's useful to have a task that checks if this secret exists:
    ```yaml
    - name: Verify that the secret is set
      fail:
        msg: 'Please export my_secret: export MY_SECRET=$(pass show my_secret)'
      run_once: true
      when: my_secret == None
    ```
    In the CI you can set it as a secret in the repository.
* New: [Run jobs if other jobs failed.](gitea.md#run-jobs-if-other-jobs-failed)
    This is useful to send notifications if any of the jobs failed.
    [Right now](https://github.com/go-gitea/gitea/issues/23725) you can't run a job if other jobs fail, all you can do is add a last step on each workflow to do the notification on failure:
    ```yaml
    - name: Send mail
        if: failure()
        uses: https://github.com/dawidd6/action-send-mail@v3
        with:
            to: ${{ secrets.MAIL_TO }}
            from: Gitea 
            subject: ${{ gitea.repository }} ${{gitea.workflow}} ${{ job.status }}
            priority: high
            convert_markdown: true
            html_body: |
                ### Job ${{ job.status }}
                ${{ github.repository }}: [${{ github.ref }}@${{ github.sha }}](${{ github.server_url }}/${{ github.repository }}/actions)
    ```
### [Helmfile](dotdrop.md)
* New: [Troubleshoot Yaml templates in go templates.](helmfile.md#yaml-templates-in-go-templates)
    If you are using a `values.yaml.gotmpl` file you won't be able to use `{{ whatever }}`. The solution is to extract that part to a yaml file and include it in the go template. For example:
    * `values.yaml.gotmpl`:
      ```gotmpl
      metrics:
      serviceMonitor:
        enabled: true
        annotations:
        additionalLabels:
          release: prometheus-operator
      {{ readFile "prometheus_rules.yaml" }}
      ```
    * `prometheus_rules.yaml`
      ```yaml
      prometheusRule:
        enabled: true
        additionalLabels:
          release: prometheus-operator
        spec:
          - alert: VeleroBackupPartialFailures
            annotations:
              message: Velero backup {{ $labels.schedule }} has {{ $value | humanizePercentage }} partialy failed backups.
            expr: increase(velero_backup_partial_failure_total{schedule!=""}[1h]) > 0
            for: 15m
            labels:
              severity: warning
      ```
* New: Introduce dotdrop.
    The main idea of [Dotdrop](https://deadc0de.re/dotdrop/)is to have the ability
    to store each dotfile only once and deploy them with a different content on
    different hosts/setups. To achieve this, it uses a templating engine that allows
    to specify, during the dotfile installation with dotdrop, based on a selected
    profile, how (with what content) each dotfile will be installed.
    What I like:
    - Popular
    - Actively maintained
    - Written in Python
    - Uses jinja2
    - Has a nice to read config file
    What I don't like:
    - [Updating dotfiles doesn't look as smooth as with chezmoi](https://dotdrop.readthedocs.io/en/latest/usage/#update-dotfiles)
    - Uses `{{@@ @@}}` instead of `{{ }}` :S
    - Doesn't support `pass`.
    - Not easy way to edit the files.
### [Terraform](terraform.md)
* New: How to install it.
    Go to the [releases page](https://github.com/hashicorp/terraform/releases), download the latest release, decompress it and add it to your `$PATH`.
* New: [How to store sensitive information in terraform.](terraform.md#sensitive-information)
    One of the most common questions we get about using Terraform to manage infrastructure as code is how to handle secrets such as passwords, API keys, and other sensitive data.
    In the article you'll find how to store your sensitive data in:
    * [The Terraform state](terraform.md#sensitive-information-in-the-terraform-state): Using the state backend encryption
    * [The Terraform source code](terraform.md#sensitive-information-in-the-terraform-source-code): Using`sops` and `gpg`.
* New: [Create a list of resources based on a list of strings.](terraform.md#create-a-list-of-resources-based-on-a-list-of-strings)
    ```hcl
    variable "subnet_ids" {
      type = list(string)
    }
    resource "aws_instance" "server" {
      # Create one instance for each subnet
      count = length(var.subnet_ids)
      ami           = "ami-a1b2c3d4"
      instance_type = "t2.micro"
      subnet_id     = var.subnet_ids[count.index]
      tags = {
        Name = "Server ${count.index}"
      }
    }
    ```
    If you want to use this generated list on another resource extracting for example the id you can use
    ```hcl
    aws_instance.server.*.id
    ```
### [Dotfiles](dotfiles.md)
* New: Introduce dotfiles.
    [User-specific application configuration is traditionally stored in so called dotfiles](https://wiki.archlinux.org/title/Dotfiles)
    (files whose filename starts with a dot). It is common practice to track
    dotfiles with a version control system such as Git to keep track of changes and
    synchronize dotfiles across various hosts. There are various approaches to
    managing your dotfiles (e.g. directly tracking dotfiles in the home directory
    v.s. storing them in a subdirectory and symlinking/copying/generating files with
    a shell script or a dedicated tool).
    Note: this is not meant to configure files that are outside your home directory,
    use Ansible for that use case.
    You can find different ways to track your dotfiles:
    * [Tracking dotfiles directly with Git](dotfiles.md#tracking-dotfiles-directly-with-git)
    * [Using Ansible to manage the dotfiles](dotfiles.md#using-Ansible-to-manage-the-dotfiles)
    * [Using dotfiles specific tools, and an analysis of the state of the
      art](dotfiles.md#tools)
## Infrastructure Solutions
### [Velero](velero.md)
* New: Introduce velero.
    [Velero](https://velero.io/) is an open source tool to safely backup and restore, perform disaster recovery, and migrate Kubernetes cluster resources and persistent volumes.
    In the article you'll also find how to:
    * [Install the client](velero.md#client-installation)
    * [Configure the server](velero.md#server-configuration)
    * [Monitor it with Prometheus](velero.md#monitorization)
    * [Restore backups](velero.md#restore-backups)
    And an [overview of the whole application
    infrastructure](velero.md#overview-of-velero).
* New: [Create a backup.](velero.md#create-a-backup)
    If you already have schedules select the one you want to use:
    ```bash
    velero schedules get
    ```
    Then create the backup with:
    ```bash
    velero backup create --from-schedule selected-schedule
    ```
    You can see the other options to create backups in `velero backup create --help`
### [AWS Snippets](kubectl_installation.md)
* Correction: Recommend to use distro repos when installing.
    It's available now in debian
* New: [Stop an EC2 instance.](aws.md#stop-an-ec2-instance)
    ```bash
    aws ec2 stop-instances --instance-ids i-xxxxxxxx
    ```
* New: [Get EC2 metadata from within the instance.](aws_snippets.md#get-ec2-metadata-from-within-the-instance)
    The quickest way to fetch or retrieve EC2 instance metadata from within a running EC2 instance is to log in and run the command:
    Fetch metadata from IPv4:
    ```bash
    curl -s http://169.254.169.254/latest/dynamic/instance-identity/document
    ```
    You can also download the `ec2-metadata` tool to get the info:
    ```bash
    wget http://s3.amazonaws.com/ec2metadata/ec2-metadata
    chmod +x ec2-metadata
    ./ec2-metadata --all
    ```
* New: [Remove the lock screen in ubuntu.](aws_snippets.md#invalidate-a-cloudfront-distribution
```bash
aws-cloudfront-create-invalidation---paths-"/pages/about"---distribution-id-my-distribution-id
```
feat(bash_snippets)
    Create the `/usr/share/glib-2.0/schemas/90_ubuntu-settings.gschema.override` file with the next content:
    ```ini
    [org.gnome.desktop.screensaver]
    lock-enabled = false
    [org.gnome.settings-daemon.plugins.power]
    idle-dim = false
    ```
    Then reload the schemas with:
    ```bash
    sudo glib-compile-schemas /usr/share/glib-2.0/schemas/
    ```
### [Kubectl Commands](kubectl_commands.md)
* New: [Show the remaining space of a persistent volume claim.](kubectl_commands.md#show-the-remaining-space-of-a-persistent-volume-claim)
    Either look it in Prometheus or run in the pod that has the PVC mounted:
    ```bash
    kubectl -n  exec  -- df -ah
    ```
    You may need to use `kubectl get pod  -o yaml` to know what volume is mounted where.
* New: [Run a pod in a defined node.](kubectl_commands.md#run-a-pod-in-a-defined-node)
    Get the node hostnames with `kubectl get nodes`, then override the node with:
    ```bash
    kubectl run mypod --image ubuntu:18.04 --overrides='{"apiVersion": "v1", "spec": {"nodeSelector": { "kubernetes.io/hostname": "my-node.internal" }}}' --command -- sleep 100000000000000
    ```
### [Tools](kubernetes_tools.md)
* Correction: [Recommend rke2 over k3s.](kubernetes_tools.md#tried)
    A friend told me that it works better.
## Continuous Integration
### [Mypy](mypy.md)
* New: [Module "typing" has no attribute "Annotated".](mypy.md#module-"typing"-has-no-attribute-"annotated")
    This one happens only because `annotated` is not available in python < 3.9.
    ```