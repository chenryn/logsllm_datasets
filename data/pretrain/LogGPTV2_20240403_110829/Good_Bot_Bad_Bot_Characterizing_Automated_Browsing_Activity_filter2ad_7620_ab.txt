protocol. From each connection, FPTLS gathers ﬁelds such
as TLS version, cipher suites, E-curves, and compression
length. The motivation for collecting TLS ﬁngerprints is that
different TLS libraries have different characteristics that can
allow us to later attribute requests back to the same software
or the same machine. This type of ﬁngerprinting is performed
passively (i.e., the connecting agents already send all details
that FPTLS logs as part of their TLS handshakes) and can be
collected by virtually all clients that request content from our
honeysites. This is particularly important because, for other
types of ﬁngerprinting, such as JavaScript-based ﬁngerprinting,
if a bot does not support JavaScript, then Aristaeus cannot
collect a ﬁngerprint from that unsupported mechanism.
B. Honeysite Implementation
While Aristaeus is web-application agnostic, for this paper,
we deployed ﬁve types of popular web applications, consisting
of three Content Management Systems (CMSs) and two
website-administration tools. On the CMS front, we deployed
instances of WordPress, Joomla, and Drupal, which are
the three most popular CMSs on the web [28]. WordPress
alone is estimated to be powering more than 30% of sites
on the web [29]. In terms of website-administration tools,
Fig. 3: (Top) Daily number of new IP addresses that visited our
honeysites. (Bottom) Daily number of received requests.
we chose Webmin and PHPMyAdmin. Both of these tools
enable administrators to interact with databases and execute
commands on the deployed server.
Next to their popularity (which makes them an attractive
target), these tools have existed for a number of years and have
been susceptible to a large number of critical vulnerabilities,
ranging from 49 vulnerabilities (in the case of Webmin) to
333 vulnerabilities (in the case of Drupal). Note that, for
CMSs, the vulnerabilities in the core code do not include
the thousands of vulnerabilities that third-party plugins have
been vulnerable to. Moreover, all ﬁve web applications allow
users and administrators to log in, making them targets for
general-purpose, credential-stufﬁng bots.
C. Deployment and Log Collection/Aggregation
For the set of experiments described in this paper, we
registered a total of 100 domain names. As described in
Section III-A, we ensure that the registered domains never
existed before (i.e., once registered and left to expire) to avoid
residual-trafﬁc pollution. For each domain, Aristaeus spawns
a honeysite and deploys one of our web application templates
onto the server. We use Let’s Encrypt to obtain valid TLS
certiﬁcates for each domain and AWS virtual machines to host
our honeysites over three different continents: North America,
Europe, and Asia. Overall, we have 42 honeysites in North
America, 39 honeysites in Europe, and 19 in Asia.
A central server is responsible for the periodic collection
and aggregation of logs from all 100 honeysites. As described
in Section III-A, these include web-server access logs, TLS
ﬁngerprints, browser ﬁngerprints, behavior ﬁngerprints, and
logs that record violations of security mechanisms. We
correlate entries from different logs using timestamps and
IP addresses and store the resulting merged entries in an
Elasticsearch cluster for later analysis.
IV. BOT TRAFFIC ANALYSIS
In this and the following sections, we report on our ﬁndings
on the data collected from 100 honeysites deployed across 3
different continents (North America, Europe, and Asia-Paciﬁc)
over a 7-month period (January 24, 2020 to August 24,
2020). Overall, our honeysites captured 26,427,667 requests
from 287,017 unique IP addresses totaling 207GB of data. A
OS/Network Stack         FingerprinTLSApache       Perl              Common Fingerprint CodeWeb applicationFingerprint DesignBrowser FingerprintBehavior AnalysisTLS FingerprintHoneysite Implementation01000200030004000CountNew IP addressesNew IP addresses (Trend)Jan/24Feb/24Mar/24Apr/24May/24Jun/24Jul/24Aug/24Time02500005000007500001000000CountDaily RequestsDaily Requests (Trend)detailed breakdown of our dataset is available in the paper’s
Appendix (Table VI).
From 26.4 million requests captured, each honeysite
received 1,235 requests each day on average, originating
from 14 IP addresses. Given that these domains have never
been registered before or linked to by any other websites,
we consider the incoming trafﬁc to belong solely to bots and
potentially the bots’ operators.
Daily bot trafﬁc. Figure 3 (Top), shows the number of
unique IP addresses that visited our honeysites each day. We
observe that this number initially goes down but averages
at around 1,000 IP addresses during the later stages of our
data collection. Our data demonstrate that our honeysites keep
observing trafﬁc from new IP addresses, even 7 months after
the beginning of our experiment.
Figure 3 (Bottom) shows the number of requests received
over time. Beginning on April 18, we observed an increase in
the volume of incoming requests which is not followed by a
commensurate increase in the number of unique IP addresses.
Upon careful inspection, we attribute this increase in trafﬁc to
campaigns of bots performing brute-force attacks on our Word-
Press honeysites (discussed in more detail in Section VI-A2).
Geographical bot distribution. Although we did not
observe signiﬁcant variation across the honeysites hosted in
different regions, we did observe that bot requests are not
evenly distributed across countries. Overall, we received most
bot requests from the US, followed by China and Brazil.
Figure 4 presents the top 10 countries based on the number
of IP addresses that contacted our honeysites.
Limited coverage of IP blocklists. We collect information
about malicious IP addresses from 9 popular IP blocklists that
mainly focus on malicious clients and web threats, including
AlienVault, BadIPs, Blocklist.de, and BotScout. Out of 76,396
IPs that exhibited malicious behavior against our Aristaeus-
managed infrastructure, only 13% appeared in these blocklists.
To better understand the nature of these malicious bots and
how they relate to the rest of the bots recorded by Aristaeus,
we used the IP2Location lite IP-ASN database [30] to obtain
the type of location of all IP addresses in our dataset. Figure 5
shows this distribution. Contrary to our expectation that most
bots would be located in data centers, most IP addresses
(64.37%) are, in fact, located in residential IP space.
This ﬁnding suggests that most bot requests come from
either infected residential devices, or using residential devices
as a proxy to evade IP-based blocklists [31]. This is also
conﬁrmed by the distribution of the IP addresses in the
third-party IP blocklists that we obtained. As shown in
Figure 5, the vast majority of the hosts labeled as malicious
by these blocklists are also located in residential networks.
Fig. 4: Bot Origin Country Distribution.
Fig. 5: Location of IP addresses.
Lastly, to understand how often the blocklists need to be
updated, we characterize the lifetime of bots in our dataset.
We deﬁne the “lifetime” as the duration between a bot’s ﬁrst
visit of a honeysite and the ﬁnal visit through the same IP
address. We observe 69.8% bot IP addresses have a lifetime
less than a day. These bots are active for a short period of
time and then leave, never to return. In contrast, 0.8% of bots
have a lifetime longer than 200 days, approaching the duration
of our study. This indicates that bots frequently switch to
new IP addresses, which make static IP-based blocklists less
effective against IP-churning behavior.
Our comparison of the malicious bots discovered by Aris-
taeus, with popular blocklists demonstrates both the poor cov-
erage of existing blocklists but also the power of Aristaeus that
can identify tens of thousands of malicious IP addresses that are
currently evading other tools. We provide more details on our
methodology for labeling bots as malicious in Section VI-A.
Honeysite discovery. A bot can discover domain names
using DNS zone ﬁles, certiﬁcate transparency logs, and
passive network monitoring. We observe that, mere minutes
after a honeysite is placed online, Aristaeus already starts
observing requests for resources that are clearly associated
/phpinfo.php,
with exploitation attempts (e.g.
/db pma.php, and /shell.php). In Section VI-A, we provide
more details as to the types of exploitation attempts that we
observed in Aristaeus’s logs.
login.php,
To identify how bots ﬁnd their way onto our honeysites, we
inspect the “Host” header in the bot HTTP requests checking
whether they visit us through the domain name or by the
IP address of each honeysite. Out of the total 287,017 IP
addresses belonging to bots, we ﬁnd that 126,361 (44%) visit
us through our honeysite IP addresses whereas 74,728 (26%)
visit us through the domain names. The remaining 85,928
(30%) IP addresses do not utilize a “Host” header. Moreover,
in HTTPS trafﬁc, we observe that all of 36,266 bot IP
addresses visit us through our domain names since Aristaeus
does not use IP-based HTTPS certiﬁcates.
Given the large volume of requests that reach our honeysites,
one may wonder whether we are receiving trafﬁc because
of domains that were once conﬁgured to resolve to our
AWS-assigned IP addresses and whose administrators forgot
to change them, when they retired their old virtual machines.
This type of “dangling domains” are a source of vulnerabilities
and have been recently investigated by Liu et al. [32] and
USCNBRRUTWIRINDEVNIDBot IP Origin0200004000060000IP Count55,47030.00%26,80814.50%23,83712.89%17,0409.21%14,4027.79%13,7227.42%11,7536.36%7,5954.11%7,1653.87%7,1333.86%CommercialData CenterISP (Residential)OtherIP Usage Type0.00.20.40.60.81.0FractionBlocklist IPAristaeus dataset malicious IPAristaeus dataset all IPBorgolte et al. [33]. Using passive DNS, we discovered
that two misconﬁgured third-party domains pointed to our
infrastructure, during the duration of our experiment. However,
the clients who connected to our honeysites because of these
misconﬁgured domains amount to a mere 0.14% of the total
observed IP addresses.
Similarly, to quantify the likelihood that we are receiving
requests from real users (as opposed to bots) whose browsers
are stumbling upon content linked to via an IP address (instead
of through a domain name) back when the Aristaeus-controlled
IP addresses used to belong to other parties, we performed
the following experiment. We crawled 30 pages for each of
the Alexa top 10K websites, searching for content (i.e. images,
JavaScript ﬁles, links, and CSS) that was linked to via an
IP address. Out of the 3,127,334 discovered links, just 31
(0.0009%) were links that used a hardcoded IP address.
When considered together, these ﬁndings demonstrate that
the vast majority of Aristaeus-recorded visits are not associated
with real users, but with bots (benign and malicious) that are
the subject of our study.
Most targeted URIs. Not all honeysite endpoints receive
the same number of requests. Here, we list the endpoints that
received the most requests from bots and the web applications
to which they belong.
Among the most requested endpoints, we observe those
that are common across multiple web applications, such as
robots.txt, as well as resources that belong to only one of our
web applications, such as wp-login.php, which is the login page
of WordPress. Figure 6 shows the share of requests for each
URI towards different web applications; darker-colored cells
indicate a higher portion of requests going towards that type
of web application. To enable a baseline comparison, Figure 6
also shows the access distribution of document root (/).
Overall, the login endpoints of our honeysites received the
most attention by bots. These requests are brute forcing the
login credentials and target endpoints such as wp-login.php or
/user/login. There are also general requests for the robots.txt
ﬁle. Interestingly, the robots.txt ﬁle was mostly queried on
WordPress and Joomla honeysites and signiﬁcantly less for
Drupal, PHPMyAdmin, and Webmin honeysites.
Certain resources are only requested on one of our web
platforms. For instance, xmlrpc.php and wp-login.php are
only requested on WordPress honeysites. Similarly, the URI
/changelog.txt is requested only from Drupal honeysites for the
purpose of web-application ﬁngerprinting (i.e. determining the
exact version and whether it is vulnerable to known exploits).
Next is session login.cgi ﬁle that hosts the Webmin login
page, and we only observe requests to this resource on Webmin
instances. Finally, document root and /latest/dynamic/instance-
identity/document requests are observed equally among all of
our honeysites. The /latest/dynamic/instance-identity/document
endpoint exists on some of the servers hosted on AWS and
can be used in a Server-Side Request Forgery (SSRF) attack
(we discuss this attack in Section VI-A2).
Overall, the application-speciﬁc attack pattern suggests that
bots will ﬁngerprint the applications and identify the presence
Fig. 6: Heatmap of the most requested URIs and their respective
web applications. Darker cells indicate a larger fraction of requests
towards that type of web application. The icons in each cell indicate
whether the resource is available in that web application.
indicates that the resource exists;
not exist;
to unauthenticated clients.
indicates that the resource does
indicates that the resource exists but is not available
of a speciﬁc vulnerable web application rather than blindly
ﬁring their attack payloads. We discuss the ﬁngerprinting
attempts by bots in more detail in Section VI-A2. Lastly,
Table VII (in the Appendix) lists the most targeted URLs
from the perspective of each web application type.
V. JAVASCRIPT FINGERPRINTS OF BOTS
In this section, we report on our ﬁndings regarding bot
detection through browser ﬁngerprinting.
JavaScript support. We designed several tests to measure
the JavaScript support of bots. From these tests, we discovered
out that only 11,205 (0.63% of the total 1,760,124 sessions)
of bot sessions support JavaScript functionality such as adding
dynamic DOM elements and making AJAX requests.
JavaScript-based browser ﬁngerprinting. When it comes
to the detection of the bots that visited our honeysites, the
effectiveness of JavaScript-based browser ﬁngerprinting is
greatly impacted by the lack of support for JavaScript from the
majority of bots. Across the total of 1,760,124 sessions, only
0.59% of them returned a JavaScript-based browser ﬁngerprint.
Overall, given that the majority of bots that come to our
websites do not support JavaScript,
this type of browser
ﬁngerprinting proves to be less useful for bot identiﬁcation.
By the same token, this also indicates that if websites demand
JavaScript in order to be accessible to users, the vast majority
of bots identiﬁed by Aristaeus will be ﬁltered out.
VI. BOT BEHAVIOR
In this section, we look at different aspects of the behavior
of bots during their visits on our honeysites.
Honoring the robots.txt. Based on our dynamic robots.txt
generation scheme, we did not observe any violations against
Disallow-marked paths. This is an unexpected ﬁnding and
could be because of the popularity of using fake Disallow
entries for identifying reconnaissance attempts [34]–[36].
However, this does not mean that all bots will honor robots.txt,
since only 2.2% of total sessions included a request to this ﬁle.
Enforcing the content security policy (CSP). Less than
1% of the total IP addresses reported CSP violations on
our honeysites. Similarly, less than 1% of bots violated the
xmlrpc.phpwp-login.php/wp-admin//administrator//robots.txtinstance-identity/user/login/CHANGELOG.txt(POST) /index.php/phpmyadmin/index.php/session_login.cgi/(document root)WordpressJoomlaDrupalPHPMyAdminWebmin99.8897.6999.730.6136.9718.370.090.001.000.000.0023.180.050.800.1497.9435.2321.430.100.0030.950.000.0021.440.020.700.100.6212.6420.6199.7499.980.910.000.0020.630.010.570.020.289.2519.170.050.0166.41100.000.0018.220.040.230.010.555.9120.420.010.000.720.00100.0016.53CSP rules by loading resources that we explicitly disallowed.
The majority of CSP violations originated from benign
search-engine bots which were capable of loading embedded
resources (such as, third-party images and JavaScript ﬁles) but
did not support CSP. The vast majority of bots do not load
CSP-prohibited resources, not because they honor CSP, but
because they do not load these types of resources in general.
Shared/distributed crawling. Since Aristaeus encodes the
client’s IP addresses into each URL cache-breaker, clients are
expected to make requests that match their URLs. However,
out of 1,253,590 requests that bore valid cache breakers, we
found that 536,258 (42.8%) “re-used” cache-breakers given
to clients with different IP addresses.
Given the large percentage of mismatched requests, we can
conclude that most are because of distributed crawlers which
identify URLs of interest from one set of IP addresses and then
distribute the task of crawling across a different pool of “work-
ers”. This behavior is widely observed in Googlebots (19.6%
of all cache-breaker re-use) and the “MJ12Bot” operated by the
UK-based Majestic (32.1% cache-breaker reuse). Interestingly,
malicious bots do not engage in this behavior, i.e., any cache-
breakers that we receive from them match their IP address.
A. Bot Intentions
Based on their activity on our honeysites, we categorize
bot sessions into three categories: “Benign”, “Malicious”, and
“Other/Gray”. Benign bots are deﬁned as bots visiting our
honeysites and asking for valid resources similar to a normal
browser, with no apparent intent to attack our honeysites. For
example, benign bots do not send unsolicited POST requests
nor try to exploit a vulnerability. Contrastingly, malicious
bots are those that send unsolicited POST requests towards
authentication endpoints, or send invalid requests trying to
exploit vulnerabilities. Apart from these two categories, there
are certain bots that because of limited interaction with our
honeysites, cannot be clearly labeled as benign or malicious.
We label these bots as “Other/Gray”.
1) Benign bots
Based on their activity, we categorize search-engine bots
and academic/industry scanners as benign bots. In total, we
recorded 347,386 benign requests, which is 1.3% of the total
requests received by Aristaeus.
Search-engine bots. Search-engine bots are responsible
for the majority of requests in the benign bots category, and
contribute to 84.4% of total benign bots. The general way of
identifying search-engine bots is from their User-Agents where
they explicitly introduce themselves. However, it is possible
for bots to masquerade their User-Agents as search-engine
bots in order to hide their malicious activity. Search engines
typically provide mechanisms, such as reverse DNS lookups,
that allow webmasters to verify the origin of each bot that
claims to belong to a given search engine [37]–[40].
In total, we received 317,820 requests from search-engine
bots, with Google bots contributing 80.2% of these requests.
For instance, we observed four different Google-bot-related
TABLE I: Breakdown of requests from search engine bots
Type
Total SEBot Requests
Googlebot
Bingbot
Baidubot
Yandexbot
Total
233,024
77,618
2,284
4,894
317,820
Veriﬁed Requests