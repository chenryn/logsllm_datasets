使⁠使用用 setsockopt 配配置置较较大大的的 SO_RCVBUF 值值
这一参数控制的是以字节为单位的 socket 接收缓冲区的最大值。使用 getsockopt 系统调用来确
定当前缓冲区的值。此参数的更多信息，请见手册页：
$ man 7 socket
6.3.5. 配配置置 RSS
RSS（接收端调整），也叫多队列接收，是通过一些基于硬件的接收队列来分配网络接收进程，从而使入站网
络流量可以由多个 CPU 进行处理。RSS 可以用来缓解接收中断进程中由于单个 CPU 过载而出现的瓶颈，并
减少网络延迟。
要确定您的网络接口卡是否支持 RSS，须查看多个中断请求队列是否在 /proc/interrupts 中有相关的接
口。例如，如果用户对 p1p1 接口有兴趣：
# egrep 'CPU|p1p1' /proc/interrupts
CPU0 CPU1 CPU2 CPU3 CPU4 CPU5
89: 40187 0 0 0 0 0 IR-PCI-MSI-edge
p1p1-0
90: 0 790 0 0 0 0 IR-PCI-MSI-edge
p1p1-1
91: 0 0 959 0 0 0 IR-PCI-MSI-edge
p1p1-2
92: 0 0 0 3310 0 0 IR-PCI-MSI-edge
p1p1-3
93: 0 0 0 0 622 0 IR-PCI-MSI-edge
p1p1-4
94: 0 0 0 0 0 2475 IR-PCI-MSI-edge
p1p1-5
46
第⁠第 6 章章 网网络络
之前的输出显示 NIC 驱动程序为 p1p1 接口创建了 6 个接收队列（p1p1-0 至 p1p1-5）。也显示出每个队
列处理的中断数量以及处理中断的 CPU。在这种情况下，由于有 6 个默认队列，这一特殊的 NIC 驱动程序就
为每个 CPU 创建一个队列，这个系统一共有 6 个 CPU。这是 NIC 驱动程序中很常见的模式。
或者用户可以在网络驱动程序加载后查看 ls -1
/sys/devices/*/*/device_pci_address/msi_irqs 的输出。例如，如果用户对 PCI 地址为
0000:01:00.0 的设备感兴趣，可以通过以下指令来列出该设备中断请求队列：
# ls -1 /sys/devices/*/*/0000:01:00.0/msi_irqs
101
102
103
104
105
106
107
108
109
RSS 是默认启用的。RSS 的队列数（或是需要运行网络活动的 CPU ）会由适当的网络驱动程序来进行配
置。 bnx2x 驱动程序是在 num_queues 中进行配置。sfc 驱动程序是用 rss_cpus 参数进行配置。通
常，这都是在 /sys/class/net/device/queues/rx-queue/ 中进行配置，其中 device 是网络设备的
名称（比如 eth1），rx-queue 是适当的接收队列名称。
配置 RSS 时，红帽推荐限制每一个物理 CPU 内核的队列数量。超线程在分析工具中通常代表独立的内核，
但是所有内核的配置队列，包括如超线程这样的逻辑内核尚未被证实对网络性能有益。
启用时，基于每个队列的 CPU 进程数量，RSS 在 CPU 间平等地分配网络进程。但是，用户可以使用
ethtool --show-rxfh-indir 和 --set-rxfh-indir 参数来更改网络活动的分配方式，并权衡哪种
类型的网络活动更为重要。
irqbalance 后台程序可与 RSS 相结合，以减少跨节点内存及高速缓存行反弹的可能性。这降低了处理网
络数据包的延迟。
6.3.6. 配配置置 RPS
RPS（接收端包控制）与 RSS类似，用于将数据包指派至特定的 CPU 进行处理。但是，RPS 是在软件级别
上执行的，这有助于防止单个网络接口卡的软件队列成为网络流量中的瓶颈。
较之于基于硬件的 RSS ，RPS 有几个优点：
RPS 可以用于任何网络接口卡。
易于添加软件过滤器至 RPS 来处理新的协议。
RPS 不会增加网络设备的硬件中断率。但是会引起内处理器间的中断。
每个网络设备和接收队列都要配置 RPS，在 /sys/class/net/device/queues/rx-
queue/rps_cpus 文件中，device 是网络设备的名称（比如 eth0），rx-queue 是适当的接收队列名称
（例如 rx-0）。
rps_cpus 文件的默认值为 0。这会禁用 RPS，以便处理网络中断的 CPU 也能处理数据包。
要启用 RPS，配置适当的 rps_cpus 文件以及特定网络设备和接收队列中须处理数据包的 CPU 。
rps_cpus 文件使用以逗号隔开的 CPU 位图。因此，要让 CPU 在一个接口为接收队列处理中断，请将它们
在位图里的位置值设为 1。例如，用 CPU 0、1、2 和 3 处理中断，将 rps_cpus 的值设为 00001111
（1+2+4+8），或 f（十六进制的值为 15）。
47
红红帽帽企企业业版版 Linux 7 性性能能调调节节指指南南
对于单一传输队列的网络设备，配置 RPS 以在同一内存区使用 CPU 可获得最佳性能。在非 NUMA 的系统
中，这意味着可以使用所有空闲的 CPU。如果网络中断率极高，排除处理网络中断的 CPU 也可以提高性能。
对于多队列的网络设备，配置 RPS 和 RSS 通常都不会有好处，因为 RSS 配置是默认将 CPU 映射至每个接
收队列。但是，如果硬件队列比 CPU 少，RPS依然有用，并且配置 RPS 是来在同一内存区使用 CPU。
6.3.7. 配配置置 RFS
RFS（接收端流的控制）扩展了 RPS 的性能以增加 CPU 缓存命中率，以此减少网络延迟。RPS 仅基于队列
长度转发数据包，RFS 使用 RPS 后端预测最合适的 CPU，之后会根据应用程序处理数据的位置来转发数据
包。这增加了 CPU 的缓存效率。
RFS 是默认禁用的。要启用 RFS，用户须编辑两个文件：
⁠/proc/sys/net/core/rps_sock_flow_entries
设置此文件至同时活跃连接数的最大预期值。对于中等服务器负载，推荐值为 32768 。所有输入的
值四舍五入至最接近的2的幂。
⁠/sys/class/net/device/queues/rx-queue/rps_flow_cnt
将 device 改为想要配置的网络设备名称（例如，eth0），将 rx-queue 改为想要配置的接收队列名
称（例如，rx-0）。
将此文件的值设为 rps_sock_flow_entries 除以 N，其中 N 是设备中接收队列的数量。例
如，如果 rps_flow_entries 设为 32768，并且有 16 个配置接收队列，那么
rps_flow_cnt 就应设为 2048。对于单一队列的设备，rps_flow_cnt 的值和
rps_sock_flow_entries 的值是一样的。
从单个发送程序接收的数据不会发送至多个 CPU。如果从单个发送程序接收的数据多过单个 CPU 可以处理的
数量，须配置更大的帧数以减少中断数量，并以此减少 CPU 的处理工作量。或是考虑 NIC 卸载选项来获得更
快的 CPU。
考虑使用 numactl 或 taskset 与 RFS 相结合，以将应用程序固定至特定的内核、 socket 或 NUMA 节
点。这可以有助于防止数据处理紊乱。
6.3.8. 配配置置加加速速 RFS
加速 RFS 是通过添加硬件协助来增速的。如同 RFS，数据转发是基于应用程序处理数据包的位置。但不同于
传统 RFS 的是，数据是直接发送至处理数据线程的本地 CPU：即运行应用程序的 CPU，或是对于在缓存层
次结构中的 CPU 来说的一个本地 CPU。
加速 RFS 只有满足以下条件才可以使用：
网络接口卡须支持加速 RFS。加速 RFS 是由输出 ndo_rx_flow_steer() netdevice 功能的接口
卡支持。
ntuple 筛选必须启用。
一旦满足了这些条件，队列映射 CPU 就会基于传统 RFS 配置自动导出。即队列映射 CPU 会基于由每个接收
队列的驱动程序配置的 IRQ 关联而自动导出。从 ＜第 6.3.7 节 “配置 RFS”＞ 中来获取配置传统 RFS 的信
息。
红帽推荐在可以使用 RFS 以及网络接口卡支持硬件加速时使用加速 RFS 。
48
工工具具参参考考
工工具具参参考考
此附录为红帽企业版 Linux 7 中多种工具提供快速参考，这些工具可用于调整性能。 工具完整、最新、详细参
考资料请参见相关手册页。
A.1. irqbalance（（中中断断平平衡衡））
irqbalance 是一个命令行工具，在处理器中分配硬件中断以提高系统性能。默认设置下在后台程序运行，但
只可通过 --oneshot 选项运行一次。
以下参数可用于提高性能。
⁠--powerthresh
CPU 进入节能模式之前，设定可空闲的 CPU 数量。如果有大于阀值数量的 CPU 是大于一个标准
的偏差，该差值低于平均软中断工作负载，以及没有 CPU 是大于一个标准偏差，且该偏差高出平
均，并有多于一个的 irq 分配给它们，一个 CPU 将处于节能模式。在节能模式中，CPU 不是
irqbalance 的一部分，所以它在有必要时才会被唤醒。
⁠--hintpolicy
决定如何解决 irq 内核关联提示。有效值为 exact（总是应用 irq 关联提示）、subset （irq 是平
衡的，但分配的对象是关联提示的子集）、或者 ignore（irq 完全被忽略）。
⁠--policyscript
通过设备路径、当作参数的irq号码以及 irqbalance 预期的零退出代码，定义脚本位置以执行每个
中断请求。定义的脚本能指定零或多键值对来指导管理传递的 irq 中 irqbalance。
下列是为效键值对：
⁠ban
有效值为 true（从平衡中排除传递的 irq）或 false（该 irq 表现平衡）。
⁠balance_level
允许用户重写传递的 irq 平衡度。默认设置下，平衡度基于拥有 irq 设备的 PCI 设备种
类。有效值为 none、package、cache、或 core。
⁠numa_node
允许用户重写视作为本地传送 irq 的 NUMA 节点。如果本地节点的信息没有限定于 ACPI
，则设备被视作与所有节点距离相等。有效值为识别特定 NUMA 节点的整数（从0开始）
和 -1，规定 irq 应被视作与所有节点距离相等。
--banirq
将带有指定中断请求号码的中断添加至禁止中断的列表。
您也可以使用 IRQBALANCE_BANNED_CPUS 环境变量来指定被 irqbalance 忽略的 CPU 掩码。
更多信息，请参见手册页。
$ man irqbalance
A.2. Tuna
49
红红帽帽企企业业版版 Linux 7 性性能能调调节节指指南南
Tuna 使您能够控制处理器和调度关联。此章节包含命令行界面，但是也可使用有相同功能范围的图形界面。
运行命令行 tuna 启动图形工具。
Tuna 接受多种按顺序处理的命令行参数。下列命令将负载分配到四个 socket中。
tuna --socket 0 --isolate \n --thread my_real_time_app --move \n --
irq serial --socket 1 --move \n --irq eth* --socket 2 --spread \n --
show_threads --show_irqs
⁠--gui
打开图形用户界面。
⁠--cpu
取用由 Tuna 控制的 CPU 逗号分隔列表。直到指定新列表前此列表均有效。
⁠--config_file_apply
将配置文件名称应用于系统。
⁠--config_file_list
列出预加载配置文件。
⁠--cgroup
用于连接 --show_threads。如果启用控制组，显示控制组类型，该控制组处理显示带有 --
show_threads 所属于的控制组类型。
⁠--affect_children