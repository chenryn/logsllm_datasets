jimmybear
jimmy1001
jimmyjean
jimmylove
jimmy2004
jimmy1234
jimmybabe
jimmygirl
jimmy1000
C
∗∗jimmy
majimmy
mujimmy
mojimmy
myjimmy
12jimmy
jojimmy
gojimmy
jjjimmy
aajimmy
m0jimmy
D
∗∗mm∗91
summy91
sammy91
tommy91
tammy91
mommy91
jimmy91
gimmy91
iammy91
mimmy91
sommy91
E
∗∗∗∗∗91
1111991
9111991
a111991
jan1991
cao1991
ban1991
5121991
man1991
1811991
jao1991
F
12∗∗∗91
1231991
1211991
1221991
1201991
1271991
1234591
1219991
1205091
1280791
12g1991
G
H
∗∗∗A∗∗∗
A∗∗∗∗∗
RONALDO
Andres
ANDRES MALANIA
MANANA1
Andrea
SALAN11
A10123
RATALIS
Angela
A12123
123A123
Andrey
BRIANA1
ANDREY MALA123
AAIANA1
ABC123
ABERES
BALAND1
I
Ra∗∗∗∗91
Raider91
Rainer91
Rain1991
Raidel91
Ranger91
Rana1991
Raid1991
Raynay91
Rayder91
RaIN1991
L
(∗∗∗1∗∗∗)
(2001999)
(1701939)
(toe1234)
(13@1932)
(gar1k())
(1031123)
(1231234)
(sot123))
(Go)12(7)
(11 199%)
M
∗∗∗#∗∗!!!
123#1!!!!
tom#!!!!!
bom#!!!!!
Bom#1!!!!
Bam#99!!
190#1!!!!
abc#2!!!!
123#11!!!’
Bom##!!!!
123#16!!!
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:27:44 UTC from IEEE Xplore.  Restrictions apply. 
1387
of network inference per step of Gibbs sampling or iterated
conditional modes [20]. Yet, they can handle the generation for
a special case of templates (e.g., Column A and Column B),
where the preﬁx of the template is fully known, and no
observable character appears among the wildcards.
To generate over arbitrary templates, a possible trivial
approach for autoregressive models would be to enumerate
passwords according to the chosen cut-off probability and
then ﬁlter the ones compatible with the chosen bias. However,
this solution has two main drawbacks. First, this operation
is costly, as well as storage-demanding. More signiﬁcantly,
such an approach can easily become intractable for small cut-
off probability values, as the enumeration could require an
exponential-scale cost due to the unpruned visit of the space.
The second and more substantial limitation of this approach
resides in the difﬁculty of generating relative low-probability
the chosen bias results in
guesses. In other words,
candidate passwords having low probabilities (according to
the estimated password distribution), those will be unlikely
generated during the enumeration process, at least, for a
reasonable cut-off probability. In turn, this translates into the
impossibility of enumeration-based approaches to generate the
number of valid guesses required to a sound password guessing
attack.
if
By contrast, conditional password generation can seamlessly
be implemented within our representation-learning-based ap-
proach and its locality property. The password organization
imposed by this locality principle maintains similar passwords
bounded in a precise zone of the latent space. Localizing such
zones using the template inversion technique and sampling
from them allow us to enumerate biased passwords with
minimal effort. We can conditionally produce suitable guesses
for each meaningful bias, even if this yields low probabil-
ity passwords. Algorithm 1 brieﬂy formalizes this approach.
Chosen a template t, we use the encoder network E to obtain
the latent representation zt of t. Then, we sample latent points
from a distribution centered in zt and with scale σ. During the
process, we ﬁlter the guesses coherent with t (if statement at
line 6). The effectiveness of this conditional guesses generation
process will be demonstrated in the next section.
Algorithm 1 Conditional Password Guessing (CPG)
Input: Template: t, Int: n, Real: σ
Output: Passwords set: X
1: X = {}
2: zt = E(t)
3: for i:=1 to n do
4:
5:
6:
7:
8:
9: end for
10: return X
zi ∼ N (zt, σI)
xi = G(zi)
if xi (cid:96) t then
X = X ∪ {xi}
end if
D. Evaluation
1) Biased test-sets creation: To create a suitable scenario
to evaluate our conditional generation technique CPG, we cast
a set of biased password test-sets. In our setup, a bias ti is
a password template; a string ti ∈ {Σ ∪ {∗}}∗ where Σ is
the password alphabet (210 unicode characters in our case)
and ∗ is the wildcard character. Every password template
ti is randomly extracted from a password sampled from a
validation set Xv. We chose the LinkedIn [9] password leak
as the validation-set. From this set, we keep passwords with
length 16 or less, obtaining 6 · 107 unique passwords, which
is ∼ 5 times the RockYou train-set used to train our model.
More precisely, sampled a ground-truth password x from
Xv, we derive ti by substituting (with a certain probability p)
each character in x with a wildcard (e.g., from x=“jimmy1991”
to t=“∗i∗my∗∗∗1”). In our setup, we select p = 0.5. In
this process, we select only those of the produced templates
that contain at least 4 observable characters and at least 5
wildcards. The latter constraint aims at rendering not trivial a
brute-force solution (∼ 3 · 1011).
After obtaining a large enough collection of valid templates,
we create a set of biased password test-sets. This is achieved
by collecting all the passwords matching the templates in Xv
with an exhaustive search. More precisely, for each template,
we collect all the instances x of Xv, such that x satisﬁes the
v = {x|x ∈ Xv ∧ x (cid:96) ti}. Based
template ti; that is, the set X ti
v , we divide those into four
on the cardinality of the various X ti
classes:
1) Tcommon, if |X ti
2) Tuncommon, if |X ti
3) Trare, if |X ti
4) Tsuper-rare, if |X ti
Eventually, each of the 4 classes of templates composes of 30
v ). Samples of these templates
different template sets (i.e., X ti
and respective matching passwords are reported in TABLE F.1
in Appendix F.
v | ∈ [1000, 15000]
v | ∈ [50, 150]
v | ∈ [10, 15]
v | ∈ [1, 5]
In the next section, we will use the created biased password
sets to evaluate the proposed CPG framework with a set of
probabilistic and non-probabilistic state-of-the-art password
guessers. We evaluate the ability of each guesser to match
the passwords contained in every biased set X ti
v .
2) Results: We perform our guessing attack using the
CWAE. This model showed slightly better performance than
the GAN approach in this guessing scenario.7 We report results
for the model trained on passwords with a maximum length
of 16, as no consistently different results have been obtained
with models trained on password lengths 10 and 22.
In our setup, we follow the CPG described in Section III-C.
More precisely, for each biased password set X ti
v , we invert
the template ti using the encoder network. Then we sample
password around the obtained latent vector using standard-
deviation σ = 0.8 (see Algorithm 1). We generate n = 107
valid passwords for each template, and then we compute the
In this section, we evaluate our proposed CPG framework
against the state-of-the-art password guessers.
7This is due to the higher quality of the encoder network included with the
auto-encoder.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:27:44 UTC from IEEE Xplore.  Restrictions apply. 
1388
cardinality of the intersection of the generated guesses with
X ti
v to calculate the number of the guessed passwords.
We compare our CPG with ﬁve state-of-the-art guessers;
namely, OMEN [27] and FLA [42] for the fully-probabilistic,
PCFG [56] for token-based probabilistic, and HashCat [3] for
non-probabilistic class. Additionally, we compare against a
min-auto conﬁguration [53].
As these guessers are not able to perform a natural form
of conditional password generation, we exploit
the naive
approach discussed in Section III-C; that is, we generate a
large number of passwords in default mode and then ﬁlter the
guesses coherently with the requested bias. In particular, we
produced 1010 passwords for each approach. Details on the
speciﬁc setup of these tools follow:
• OMEN: We trained the Markov chain using the same
train-set used for our deep generative model (i.e., 80%
RockYou). After that, we generated 1010 sorted guesses.
• PCFG: Like in the OMEN case, we used the train-set
employed for the training of our deep generative model
to infer the grammar.
• HashCat: We performed a mangling rules-based attack
leveraging the train-set used for the training of our deep
generative model as a dictionary (considering only unique
passwords sorted by frequency), and we use Password-
sPro [6] as the set of rules. We chose the latter based on
a suitable number of rules (i.e., 3120) that allowed us to
produce a suitable number of guesses.
• FLA: We trained the largest model described in [42],
i.e., an RNN composed of three LSTM layers of 1000
cells each and two fully connected layers. The training is
carried out on the same train-set used for our model.
• CMU-PGS: In CMU Password Guessability Service
(PGS) [13], the passwords are guessed according to the
min-auto conﬁguration [53], where guesses of multi-
ple tools (i.e., FLA, Hashcat, John The Ripper, PCFG,
Markov Model) are combined. We query the guess-
numbers via the web interface and consider passwords
requiring fewer than 1010 guesses. Recommended tools
setup and “1class1” have been used.
When we test each of these guessers in the conditional
generation, we transform each template in a regular expression
(i.e., replacing the wildcards with the point operator) and
extract all the guesses matching the template in the 1010
generated passwords. Then, we compute the cardinality of the
intersection of the correct guesses with each X ti
v to explicit
the number of the guessed passwords.
The mean percentage of guessed passwords for each tem-
plates class is reported in TABLE IV. Coherently with the
discussion done in Section III-C, our CPG framework allows
us to produce a large number of biased guesses, and it matched
a large portion of passwords accordingly.
As anticipated, CPG maintains a high match ratio (i.e., >
70%) for each template class independently of the correspond-
ing passwords’ low probabilities. In contrast, other guessers
are not able to produce such a speciﬁc class of passwords.
Therefore, they provide shallow coverage of the rare templates.
AVERAGE MATCHED PASSWORDS (AND RELATIVE STANDARD DEVIATION)
OVER THE BIASED PASSWORDS TEST-SET DIVIDED INTO 4 CLASSES.
TABLE IV
Templates
class
Common
[1000-1500]
Uncommon
[50-150]
Rare
[10-15]
Super-Rare
[1-5]
OMEN
0.4383
(± 0.1835)
0.2744
(± 0.1322)
0.1182
(± 0.1272)
0.0555
(± 0.1448)
HashCat
(PasswordPro)
PCFG
FLA
0.5563
(± 0.1274)
0.3656
(± 0.1897)
0.2007
(± 0.1655)
0.0900
(± 0.1700)
0.7546
(± 0.092)
0.5794
(± 0.1987)
0.4013
(± 0.2514)
0.1527
(± 0.2298)
0.7936
(± 0.0757)
0.6365
(± 0.1137)
0.3983
(± 0.1827)
0.1500
(± 0.2961)
CMU-PGS
(min-auto)
0.8617
(± 0.0517)
0.7208
(± 0.1015)
0.5102
(± 0.2005)
0.2277
(± 0.2763)
Our CPG
(CWAE)
0.8136
(± 0.0641)
0.8606
(± 0.0686)
0.8482
(± 0.1444)
0.7722
(± 0.2910)
This is also true for the min-auto attack, where heterogeneous
guesses from multiple tools are combined. For instance, the
min-auto approach would require three orders of magnitude
more guesses to match the same number of passwords as ours
in the edge-case of the Super-Rare templates. Interestingly,
given the strong bias imposed during the generation, CPG
matches most passwords of other single guessers also under
the common templates case. The second best guesser turns out
to be FLA that matches a comparable number of passwords
as ours in the case of common templates and matches an
acceptable number of passwords in the uncommon and rare
classes (i.e., ≥ 40%). Note that we limited our CPG to
generate 107 guesses per template; however, more biased
passwords can be sampled in a linear cost.
IV. DYNAMIC PASSWORD GUESSING (DPG) AND
PASSWORDS WEAK LOCALITY
In this section, we present our major contribution, i.e., Dy-
namic Password Guessing. In Section IV-A, we outline the