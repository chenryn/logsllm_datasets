at a high level, the generalized predictive mitigation scheme makes
possible the practical application of predictive mitigation to general
services. The simple predictive mitigator deﬁned by Askarov et al.
is manifestly unsuitable to this task, as discussed in Section 3.1.
TYPE/HOSTHOST+URLTYPETYPE/URLOFF0500100015002000Latency (ms)0500100015002000Latency (ms)TYPE/HOSTHOST+URLTYPETYPE/URL01020304050Number of request types01020304050Number of request types 0 1000 2000 3000 4000 5000 6000 0 20 40 60 80 100Leakage bound in bitsNumber of inputs (X1000)TYPE/HOSTHOST+URLTYPETYPE/URLAuthAuth(OFF)LoginLogin(OFF)ListList(OFF)EmailEmail(OFF)05001000Latency (ms)05001000Latency (ms) 0 50 100 150 200 250 300 350 0 20 40 60 80 100Leakage bound in bitsNumber of inputs (X1000)Webmail leakage572Köpf et al. [12, 13] introduced the mechanism of bucketing to
mitigate timing side channels in cryptographic operations, achiev-
ing asymptotically logarithmic bounds on information leakage but
with stronger assumptions than in this work. Their security analy-
ses rely on the timing behavior of the system agreeing with a pre-
viously measured distribution of times; therefore they implicitly
assume that the adversary does not control timing, and that there
is a worst-case execution time. The bucketing approach does not
achieve logarithmic bounds for general computation.
The NRL Pump [26] and its follow-ups, like Network Pump [27],
are also network service handling that handle requests. The Pump
work addresses timing channels arising from message acknowledg-
ments (which correspond to but are less general than outputs in this
work). Acknowledgment timing is stochastically modulated using
a moving average of past activity, and leakage in one window does
not affect later windows. Therefore the NRL/Network Pumps can
enforce only a linear leakage bound.
Much other work has studied timing channels at the network
level, exploring techniques such as adding random delays or pe-
riodic quantization of time (e.g., [24, 20]). For discussion of this
prior work, see [14]. Work on language-based security has also
addressed timing channels, especially for internal timing channels,
and this also is covered in [14].
8. Conclusion
Predictive mitigation as introduced earlier offered the possibility
of mitigating timing channels in general computations, but was im-
practical as a way to build real networked services. In this work, we
have both generalized and reﬁned the original model of predictive
mitigation to apply to interactive systems. The experimental results
from the implementation of this generalized prediction mitigation
scheme suggest that it may be a practical way to mitigate timing
channels in a variety of networked services.
Acknowledgments
We thank Owen Arden for useful discussions about this work, Jed
Liu and the anonymous reviewers for helpful feedback about the
paper.
This work was funded by a grant from the Ofﬁce of Naval Re-
search (ONR N000140910652), and by two grants from the NSF:
0424422 (the TRUST center), and 0964409.
9. References
[1] B. W. Lampson, “A note on the conﬁnement problem,”
Comm. of the ACM, vol. 16, no. 10, pp. 613–615, Oct. 1973.
[2] P. Kocher, “Timing attacks on implementations of
Difﬁe–Hellman, RSA, DSS, and other systems,” in Advances
in Cryptology—CRYPTO’96, Aug. 1996.
[3] D. Brumley and D. Boneh, “Remote timing attacks are
practical,” Computer Networks, Jan. 2005.
[4] D. Osvik, A. Shamir, and E. Tromer, “Cache attacks and
countermeasures: the case of AES,” Topics in
Cryptology–CT-RSA 2006, Jan. 2006. [Online]. Available:
http://www.springerlink.com/index/F52X1H55G1632L17.pdf
[5] A. Bortz and D. Boneh, “Exposing private information by
timing web applications,” in Proc. 16th Int’l World-Wide
Web Conf., May 2007.
[6] G. Shah, A. Molina, and M. Blaze, “Keyboards and covert
channels,” Proc. 15th USENIX Security Symp., Aug. 2006.
[7] H. Meer and M. Slaviero, “It’s all about the timing...” in
Proc. Black Hat USA, 2007.
[8] Y. Liu, D. Ghosal, F. Armknecht, A. Sadeghi, and S. Schulz,
“Hide and seek in time—robust covert timing channels,” in
ESORICS, 2009.
[9] R. G. Gallagher, “Basic limits on protocol information in
data communication networks,” IEEE Transactions on
Information Theory, vol. 22, no. 4, Jul. 1976.
[10] M. Padlipsky, D. Snow, and P. Karger, “Limitations of
end-to-end encryption in secure computer networks,” Mitre
Corp., Tech. Rep. ESD TR-78-158, 1978.
[11] I. S. Moskowitz and M. H. Kang, “Covert channels—here to
stay?” in COMPASS ’94, 1994.
[12] B. Köpf and M. Dürmuth, “A provably secure and efﬁcient
countermeasure against timing attacks,” in 2009 IEEE
Computer Security Foundations, Jul. 2009.
[13] B. Köpf and G. Smith, “Vulnerability bounds and leakage
resilience of blinded cryptography under timing attacks,” in
2010 IEEE Computer Security Foundations, Jul. 2010.
[14] A. Askarov, D. Zhang, and A. C. Myers, “Predictive
black-box mitigation of timing channels,” in ACM Conf. on
Computer and Communications Security (CCS), 2010, pp.
297–307.
[15] A. Sabelfeld and D. Sands, “Probabilistic noninterference for
multi-threaded programs,” in Proc. 13th IEEE Computer
Security Foundations Workshop.
Press, Jul. 2000, pp. 200–214.
IEEE Computer Society
[16] W.-M. Hu, “Reducing timing channels with fuzzy time,” in
IEEE Symposium on Security and Privacy, 1991, pp. 8 – 20.
[17] J. Agat, “Transforming out timing leaks,” in Proc. 27th ACM
Symp. on Principles of Programming Languages (POPL),
Boston, MA, Jan. 2000, pp. 40–53.
[18] S. Zdancewic and A. C. Myers, “Observational determinism
for concurrent program security,” in Proc. 16th IEEE
Computer Security Foundations Workshop, Paciﬁc Grove,
California, Jun. 2003, pp. 29–43.
[19] A. Russo, J. Hughes, D. Naumann, and A. Sabelfeld,
“Closing internal timing channels by transformation,” in
Proc. 11th Annual Asian Computing Science Conference
(ASIAN), 2006.
[20] J. Giles and B. Hajek, “An information-theoretic and
game-theoretic study of timing channels.” IEEE Transactions
on Information Theory, vol. 48, no. 9, pp. 2455–2477, 2002.
[21] D. E. Denning, Cryptography and Data Security. Reading,
Massachusetts: Addison-Wesley, 1982.
[22] J. K. Millen, “Covert channel capacity,” in Proc. IEEE
Symposium on Security and Privacy, Oakland, CA, Apr.
1987.
[23] ——, “Finite-state noiseless covert channels,” in Proc. 2nd
IEEE Computer Security Foundations Workshop, Jun. 1989,
pp. 11–14.
[24] I. S. Moskowitz and A. R. Miller, “The channel capacity of a
certain noisy timing channel,” IEEE Trans. on Information
Theory, vol. 38, no. 4, pp. 1339–1344.
[25] G. Smith, “On the foundations of quantitative information
ﬂow,” Proc. 12th Intl’ Conf. on Foundations of Software
Science and Computation Structures, pp. 388–402, 2010.
[26] M. H. Kang and I. S. Moskowitz, “A pump for rapid, reliable,
secure communication,” in ACM Conf. on Computer and
Communications Security (CCS), Nov. 1993, pp. 119–129.
[27] M. H. Kang, I. S. Moskowitz, and D. C. Lee, “A network
pump,” IEEE Transactions on Software Engineering, vol. 22,
pp. 329–338, 1996.
[28] T. Cover and J. Thomas, Elements of information theory.
Wiley, 2006.
573APPENDIX
Example of shared worker pool
Reusing the settings from the example in Section 3.2.1, we have
four inputs: (2, A), (4, B), (6, A) and (30, B), and prediction
function p(1, A) = 10 and p(1, B) = 100. Suppose we have
two shared workers.
As described above, the worker predictions are both initialized to
be empty: W1 = ∅ and W2 = ∅. For the ﬁrst input, both workers
are available; that is, avail(W1) = avail(W2) = 0 since W1 and
W2 are all empty sets now. We break the tie by selecting the worker
with smaller index, worker 1, and then we set the prediction for
input (2, A) as
S1(1) = max(2, 0) + 10 = 12
Finally, the worker prediction of worker 1 is updated to {(1, 12)}.
For the second input, avail(W1) = 12 and avail(W2) = 0.
Worker 2 is the earliest available worker. Similarly to the ﬁrst input,
the prediction for the second output is S1(2) = max(4, 0)+100 =
104. The worker prediction of worker 2 is updated to {(2, 104)}.
Computation of the predicted worker becomes more interesting
for the third input (6, A). We have
avail(W1) = max{q | (i, q) ∈ {(1, 12)}} = 12
avail(W2) = max{q | (i, q) ∈ {(2, 104)}} = 104
The mitigator picks the worker with earliest availability, worker 1.
The third output is predicted at: S1(3) = max(6, 12) + 10 = 22,
and the prediction for worker 1 is updated to {(1, 12), (3, 22)}.
For the last input (30, B), the mitigator ﬁrst computes the avail-
able times for both workers:
avail(W1) = max{q | (i, q) ∈ {(1, 12), (3, 22)}} = 22
avail(W2) = max{q | (i, q) ∈ {(2, 104)}} = 104
Based on these values, the mitigator picks worker 1 as the predicted
worker for the fourth input. The prediction for corresponding out-
put is S1(4) = max(30, 22) + 100 = 130, and the prediction of
worker 1 becomes {(1, 12), (3, 22),(4, 130)}.
Proof of Lemma 1
Proof. ⇐=: since ~m00 is valid, there is sequence of request types
where all intermediate states satisfy the constraints. Further, we can
construct a sequence of request types from ~m00 to ~m by appending
j to the previous sequence until ~mi = ~m. Since p( ~m0, j) ≤ T and
p is monotonic, all new states corresponding to this sequence still
satisfy the constraints.
=⇒: by deﬁnition, there is a sequence of request types r1, . . . , rn
such that all intermediate states satisfy constraints. Moreover, there
must be a point i in this sequence such that ∀l < i, rl 6= j and
ri = j. Thus, the j-th element of ~mi−1 is 0.
Then, a new sequence of request types p1, . . . , pm exists such
that pl = rl, 0 ≤ l ≤ i − 1. For l ≥ i, if rl = j, skip this type.
Otherwise, add the same type to sequence ~p. By this construction,
two properties of states occurring with ~p are that the j-th element
is always 0, and that there is a corresponding state with sequence ~r
such that they only differ in the j-th element. We denote the ﬁnal
states with request type sequence ~r, ~p as ~mr and ~mp respectively.
Since state ~mr satisﬁes p( ~mr, rl) ≤ T , by monotonicity, corre-
n = ~m00,
sponding state ~mp also satisﬁes this condition. Since mr
~m00 is valid at T .
2
Proof of Lemma 2
Proof. By deﬁnition, there is a sequence of request types j1, . . . , jn
such that all conditions in Deﬁnition 2 are satisﬁed. For any sub-
vector of ~m, say ~m0, we can take a projection of the sequence so
that only the request types nonzero in the subvector are kept.
By monotonicity, it is easy to check that all conditions hold in
the deﬁnition. Moreover, ~mn = ~m0. So ~m0 is valid by deﬁnition.
2
Proof of Lemmas 3 and 4
We can view the outputs O1 and O2 as discrete random variables.
Since the second service and its mitigator do not share secret S, the
conditional distribution of O2 depends only on O1 and is condition-
ally independent of S (in other words, random variables S, O1, O2
form a Markov chain). Denoting the probability mass function of a
discrete random variable X as P (X), the joint distribution of these
three random variables has probability mass function P (s, o1, o2) =
P (s)P (o1|s)P (o2|o1). The marginal distribution P (o2, s) is
P (o2|o1) =
P (s, o1, o2), and for any o1, we haveP
P
o2∈O2
o1∈O1
1.
Proof of Lemma 3.
Proof. The proof follows from the standard data-processing in-
equality [28] and the symmetry of mutual information:
I(S; O2) + I(S; O1|O2) = I(S; O1, O2)
= I(S; O1) + I(S; O2|O1)
Note that S and O2 are conditionally independent given O1, since
the second mitigator produces outputs based on only the output of
the ﬁrst mitigator M, public inputs, and secrets other than S. Thus
I(S; O2|O1) = 0. Replacing this term with zero in the above
equation, we get
I(S; O2) + I(S; O1|O2) = I(S; O1)
Also, we know that I(S; O1|O2) ≥ 0, so we have
I(S; O1) ≥ I(S; O2)
2
Proof of Lemma 4. As discussed in Section 2.3, min-entropy
channel capacity is deﬁned as the maximal value of log V (S|O)
among all distributions on S. So it sufﬁces to show V (S|O1) =
V (S|O2) for any distribution on S.
V (S)
V (S|O2) =
P (s)P (o2|s)
o2∈O2
o1∈O1
P (s, o1, o2)
X
X
max
s∈S
max
s∈S
max
s∈S
X
o2∈O2
=
X
X
X
≤ X
X
X
=
=
o2∈O2
o2∈O2
o1∈O1
max
s∈S
o1∈O1
=
o1∈O1
max
s∈S
= V (S|O1)
P (s)P (o1|s)P (o2|o1)
o1∈O1
P (o2|o1) max
s∈S
(P (s)P (o1|s))
P (s)P (o1|s)
X
o2∈O2
P (s)P (o1|s)
P (o2|o1)
574