0
0
0
0
1/1
7/7
4/5
4/5
1/1
2/2
1/2
1/1
3/5
0
0
0
0
0
1/1
2/2
2/2
6/6
7/7
1/1
1/1
1/1
1/1
3/3
0
0
0
0
0
10/10
3/3
2/2
File
1/1
1/1
0
0
0
0
0
0
1/1
0
0
0
0
0
0
Repetition
Total
1/2
1/2
0
0
0
0
0
1/1
0
0
0
0
0/1
0
0
12/14 (86%)
13/15 (87%)
2/2 (100%)
3/3 (100%)
2/3 (67%)
2/2 (100%)
6/8 (75%)
3/3 (100%)
11/11 (92%)
7/8 (88%)
10/11 (91%)
10/12 (83%)
16/17 (94%)
10/11 (91%)
27/28 (96%)
Table 2. Field detection results: correctly identiﬁed ﬁelds / total ﬁelds in message format.
Server
Detected
Missed
apache
keywords
”GET”, ”HTTP/1.1”, ”Host”, ”Connec-
tion”, ”close”, ”keep-alive”
”:”
”:”
CRLF
”@”
lighttpd
iacd
sendmail
delimiters CRLF, SPACE, ”/”, ”.”
keywords
”HTTP/”,
”GET”,
”User-
Agent”, ”Connection”, ”close”, ”keep-
alive”
”Host”,
delimiters CRLF, SPACE, ”/”, ”.”
keywords
delimiters CRLF, SPACE
keywords
”NICK”, ”USER”
delimiters CRLF, ”.”, ”:”, ”>”
”HELO”, ”QUIT”, ”MAIL”, ”FROM”,
”<”
samba
keywords
delimiters
”DOS
”MICROSOFT NETWORKS 1.03”,
”MICROSOFT NETWORKS 3.0”,
LAN-
”LANMAN1.0”,
MAN2.1”,
”NT
”NT LM 0.12”,
LANMAN 1.0”,
”Samba”, ”0xffSMB”, ”IPC”, ”?????”
”NTLMSSP”
”0x00”, ”0x0000”
”LM1.2X002”,
False
positives
”Accept-”
”Accept”
”Accept”
Unsupported
”Accept-Language”,
”Accept-Encoding”,
”Accept-Charset”, ”User-
Agent”, ”Keep-Alive”
”Accept-Language”,
”Accept-Encoding”,
”Accept-Charset”, ”Keep-
Alive”
”PC NETWORK PRO-
GRAM 1.0”
Table 3. Keyword and delimiter detection results. “Unsupported” keywords are part of the protocol
speciﬁcation but are not supported by the server in the tested conﬁguration.
speciﬁcations that can be directly used to parse messages
of a certain type. Also, the speciﬁcations contain detailed
information about the format of the message and the way
in which the sequence of bytes at the network level are split
into meaningful, application-level ﬁelds.
Hypertext Transfer Protocol (HTTP). For our anal-
ysis of HTTP, we selected the latest stable versions of
apache and the Lighttpd web server (versions 1.3.39
and 1.4.18, respectively). Then, we used clients such as
the Firefox web browser to generate HTTP GET messages
that request different pages stored at the server. These mes-
sages contained the “Host” header (which is mandatory
in HTTP/1.1), as well as a number of additional, optional
header lines.
Results for both servers are presented in Table 2 and
Table 3. The complete grammar that was automatically
derived from analyzing the way in which apache pro-
cessed the GET messages is presented in Appendix A.
When examining this grammar in more detail, one can see
that our system has extracted a quite accurate speciﬁcation
for HTTP GET requests. The message has been split into
lines that are separated by the multi-byte delimiter ‘\r\n’,
and the ﬁrst line (“GETLINE”) is split into three ﬁelds by
the space character. The system has identiﬁed keywords
such as the name of the “GET” operation and of header
ﬁelds such as “Host” and “Connection.” Moreover, thanks
to repetition detection, the name of the requested resource
(“FILENAME”) was recognized as a ﬁle name with an
arbitrary number of directories, followed by an optional
extension. The system also automatically recognized that
“FILENAME” is indeed specifying a resource in the ﬁle
system. Also, the IP address following the “Host” header
was split into four character tokens separated by dots (rep-
resenting the general format of an IP address), and our sys-
tem determined that the values of the connection header
can take one of the two alternatives “keep-alive” or “close”.
Finally, one can see that the speciﬁcation correctly captures
the fact that the ﬁrst two lines (the request line and the
“Host” header) have to be present in a request, while the
additional header lines are all optional. Note that the HTTP
RFC does not specify an optional ﬁle extension in the URL
that is delimited by a dot characters (’.’). However, this is
not an error of analysis but reﬂects the way in which the
server actually processes the input. In fact, apache uses
ﬁle extensions to decide which extension module to use to
process a request. Interestingly, for Lighttpd, the dot
character the ﬁle name is not used (and thus, not recog-
nized) as delimiter.
Of course, our HTTP grammar is not ﬂawless, exposing
some limitations of our system. For example, the tokens
“Accept” and “Accept-” are incorrectly identiﬁed as key-
words1. This is because apache scans for the supported
keyword “Accept-Ranges.” As this keyword is not present
in our HTTP trafﬁc, parsing always fails after processing
1“Accept” is in fact a valid HTTP header name, but it is not supported
in the tested conﬁguration.
the string “Accept-.” Nevertheless, our analysis considers
the sequence of successful comparison operations as indi-
cation that the keyword “Accept-” is part of the protocol
message speciﬁcation.
Another inaccuracy is the fact that our speciﬁcation ac-
cepts header lines with arbitrary content. This can be
seen on the right side of the grammar production for “UN-
USEDHDR”, which includes (TEXT)+. The reason for
this is that apache ignores the “User-Agent” and “Keep-
Alive” headers in its default conﬁguration. Thus, our sys-
tem cannot infer any constraints on the value of these head-
ers, and has to assume that they can hold arbitrary content.
This shows that it is difﬁcult for our approach to derive
information for parts of a message that are not processed
by the server. Similarly, several headers starting with “Ac-
cept” are not further parsed by apache, so the format in-
ferred for those headers is overly permissive. In fact, we
tested apache by sending garbage header lines (with no
’:’), and they were indeed accepted by the server, as long
as they did not start with a supported keyword.
The colon character (’:’) is not recognized as a delim-
iter because the server is only checking for it directly after
it has identiﬁed a keyword. As a result, the server only
checks a single input character for the occurrence of the
delimiter. This is not sufﬁcient for our delimiter analysis,
which requires at least two consecutive input bytes to be
analyzed before considering a character as delimiter (see
Section 3.1). Finally, our system is not capable of general-
izing the request header lines as repeating elements. This is
because our repetition detection technique cannot identify
repetitions of different (non-matching) nodes (as explained
in Section 4).
The grammar extracted from analyzing the 34 GET re-
quests was used as input to our parser. This parser was then
applied to an additional set of 20 different GET requests.
The additional messages could be parsed correctly, demon-
strating that our automatically derived speciﬁcation is suf-
ﬁciently accurate to generate parsing code for this type of
messages.
Internet Relay Chat (IRC). To analyze IRC, we chose
the fully-featured iacd IRC server. As for HTTP, we
recorded a set of messages that clients send to the server
when establishing a connection. Results for the NICK and
USER commands are shown in Tables 2 and 3, and the
grammar for the USER command is in Appendix A. When
examining the speciﬁcations produced for these two types
of messages, it can be seen that the message format is sig-
niﬁcantly simpler than the one for HTTP. Our system has
produced correct format descriptions and recognized the
relevant keywords (such as “NICK” and “USER”). When
using these two speciﬁcations to parse an additional set of
IRC messages, we observed no problems.
Simple Mail Transfer Protocol (SMTP). We analyzed
SMTP by examining the well-known sendmail SMTP
server (version 8.13.8-3).
For our experiments, we
recorded a set of eight SMTP sessions. Our tool pro-
duced grammars for the HELO, QUIT, and MAIL com-
mands (shown in Appendix A) that appear in each of these
sessions.
The QUIT command was identiﬁed correctly. For the
HELO command, the space delimiter was detected as a
constant part of the token that follows the keyword. The
reason is that the server only checks for the space in the
position after the HELO keyword, but our delimiter detec-
tion requires at least two consecutive checks to recognize a
delimiter character.
While our system can correctly identify most of the
keywords and delimited ﬁelds of the MAIL command, it
misses the ’@’ delimiter in the email address. The rea-
son is that the parser is not explicitly scanning the input
data for the ’@’ character, but for any character in a non-
printable range. Also, the ‘\r\n’ sequence at the end of
the message is not classiﬁed as a delimiter, because, again,
the parser is only checking for this sequence once (after
the closing angle bracket). However, the angle brackets
and dot delimited ﬁeld are identiﬁed correctly, as well as
the path repetition in the email address sufﬁx.
Domain Name Service (DNS). For the DNS protocol,
we examined the latest named daemon from the bind dis-
tribution (version 9.4.1). We decided to extract the speci-
ﬁcation for the messages that resolve a DNS name to the
corresponding IP address. To this end, we issued a set of
nine DNS queries, using the Linux host command with
different names and ﬂags. The complete speciﬁcation that
we extracted can be found in Appendix A.
When examining this speciﬁcation, one can observe that
our system correctly recognized length ﬁelds and the cor-
responding target ﬁelds. The protocol splits the DNS name
into the parts (or labels) that are separated by dots. That is,
the name www.example.com is split into the three la-
bels www, example, and com. Each of these labels is
stored in a variable length ﬁeld, with its length directly
stored before. This is reﬂected in the grammar as a rep-
etition of one or more “NAMEPARTS”. Our system also
identiﬁed that the ﬁrst two bytes of the message (which
represent the message ID) are echoed back to the client in
the server response.
Because all queries in our message set contain only a
single DNS query (and no additional resource records), the
corresponding bytes of the message are identiﬁed to have a
ﬁxed content. Thus, using our speciﬁcation, we can parse
any DNS query for an IP address. We veriﬁed this by using
our speciﬁcation for parsing an additional set of messages
created by performing name lookups, and found that the
parsing was successful.
Network File System (NFS). We selected NFS because
it is a complex, binary protocol that is layered over an other
protocol (RPC). For our experiments, we used the NFSv2
daemon (with RPCv2) that ships as the default of the cur-
rent Ubuntu Linux distribution (version 2.2.beta47). To
generate messages, we performed several operations on an
NFS-mounted directory, such as obtaining a directory list-
ing as well as writing to and reading from a ﬁle. Results
for four types of NFS messages are listed in Table 2. The
speciﬁcation extracted for NFS Lookup messages is shown
in Appendix A. This is the message used by NFS to look
up a ﬁle name and obtain a corresponding ﬁle handle.
When examining the resulting speciﬁcation, one can see
that our system correctly recognized a number of com-
plex structures. This includes the ﬁle name,
the ma-
chine name, and the set of additional group identiﬁers
that are all transmitted as variable length ﬁelds. We fur-
ther detect that the ﬁle name is used by the server to ac-
cess ﬁle information, and we detect that the four byte re-
quest ID (XID) is echoed back to the client. The ex-
ample of NFS also shows that we detect variable length
ﬁelds that are nested. The ﬁeld “CREDENTIALS BODY”
is a variable ﬁeld whose length is stored in the preced-
ing ﬁeld “CREDENTIALS LENGTH.” Furthermore, the
“CREDENTIALS BODY” ﬁeld contains a number of ad-
ditional ﬁelds (such as machine name or the list of auxiliary
group identiﬁers) that are themselves of variable length.
Finally, note that our system can also deal with variable
length padding. We identify that the end of the variable
length ﬁeld “MACHINE NAME” is padded so that the