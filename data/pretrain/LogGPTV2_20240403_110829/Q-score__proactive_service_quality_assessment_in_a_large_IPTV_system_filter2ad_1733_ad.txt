the most accurate selection of spatial level of features.
spatial
4.2.4 Feedback Aggregation
To show the effect of user feedback duration being aggregated
together, Figure 6 compares various lengths of γ. We observe that
as γ gets longer, the regression performance gets better. An expla-
nation for this is, as mentioned in Section 3.3, there is a signiﬁcant
delay between the occurrence of a problem and the ﬁling of user
feedback. Due to the elongated delay, time-bins with short γs may
fail to contain feedback correlated with signiﬁcant network indica-
tor values.
2025 days of training
10 days of training
15 days of training
20 days of training
30 days of training
 100
 100
 80
 80
 60
 60
 40
 40
 20
 20
e
t
a
R
e
v
i
t
a
g
e
N
e
s
a
F
l
 0
 0
 0.001
 0.001
 0.01
 0.01
 0.1
 0.1
 1
 1
 10
 10
 100
 100
False Positive Rate
Figure 7: Comparison of accuracy with various training dura-
tions
4.2.5 Sensitivity to Training Duration
Finally, we evaluate the sensitivity of testing accuracy on the
duration of training. In this experiment, we ﬁx the testing duration
and assess how accuracy changes by varying the training duration.
Table 3 shows the dates of training and testing periods used in our
evaluation. Figure 7 shows the accuracy trade-off curves of using
different training durations. We observe that in general, the testing
accuracy improves as we increase the training duration. However,
the gain becomes marginal once the training duration is longer than
15 days. This result suggests that using 15 days as training period
is a good choice.
A closer examination of the curves corresponding to the use of
15 and 20 days of training duration reveals that the accuracy of
using 15 days training duration is marginally better. A possible
reason for this is that in the month of August, there was a network-
wide STB ﬁrmware upgrade. The upgrade that took place between
08/10/2010 and 08/14/2010 could have obstructed measurement of
STB logs (i.e., STB audio and video quality measurement logs,
syslog, reset and crash logs) and caused learning of β to be affected.
Since this kind of glitches occurs in real data, we take small amount
of noise as granted. In all, we observe that 15 days of training is
enough to learn β.
Summary. In this section, we evaluate the accuracy and robustness
of Q-score. Q-score, combined with multi-scale temporal aggrega-
tion and multi-scale spatial aggregation, successfully predicts 60%
of service problems reported by customers with only 0.1% misclas-
siﬁcation (i.e., false positive rate). While an in-depth analysis is in
order, our preliminary test shows that a portion of the remaining
40% of unpredicted issues are either (i) unrelated to any of the net-
work KPIs we measure (e.g., remote controller malfunction, wiring
issues between STB and TV inside home) or (ii) fallacies that our
regression does not capture (e.g., gradual and long term changes
in network KPIs). For (i), as feedback is reported and logged by
humans in plain text, it is difﬁcult to completely rule out trouble
tickets unassociated to our KPIs. Thus, we account a small portion
of misclassiﬁcation to inherent noise of feedback. For (ii), we ad-
dress with our previous works Giza [18] and Mercury [19] as they
are speciﬁcally designed to detect and mitigate recurring and per-
sistent events in application service networks. In a future work, we
plan to conduct an extensive analysis on the false negatives to de-
termine the proportions of the issues in each of the categories and
further improve the success rate.
Testing duration
Training durations
Dates
Duration
15 days 09/01/2010 - 09/15/2010
5 days 08/25/2010 - 08/29/2010
10 days 08/20/2010 - 08/29/2010
15 days 08/15/2010 - 08/29/2010
20 days 08/10/2010 - 08/29/2010
30 days 08/01/2010 - 08/30/2010
Table 3: Training and testing durations
5. APPLICATION
In this section, we demonstrate the utility of Q-score by present-
ing three applications on it. First, we present a set of network KPIs
that are closely related to user-perceived service quality. Second,
we illustrate how much Q-score can predict user calls. Third, we
show the possibility of intelligently dimensioning the call center
workforce. In all applications, we successfully identify interesting
results through online analysis of Q-score.
5.1 Identiﬁcation of Signiﬁcant KPIs
Today’s commercial IPTV services support up to millions of user
devices. If for every single device, few KPIs are monitored contin-
uously, the measurement space can easily reach to the order of bil-
lions. In addition, time-lapse analysis in the diagnosis (as many di-
agnosis schemes employs) is required to be conducted on multiple
data snapshots in short periods of time. Thus, in service assurance
of a large-scale IPTV system, it is infeasible to blindly measure,
collect, and analyze such large volume of diverse KPIs from the
entire network. In this application, we discuss our experience on
identiﬁcation of a small number of signiﬁcant KPIs with respect to
user-perceived quality of experience.
Signiﬁcant KPIs. In the generation of Q-score, we relate the net-
work KPIs and user feedback by means of the factor β. β measures
the relevance of signiﬁcant KPIs by its magnitude. The analysis of
the magnitude of β for different temporal aggregation levels indi-
cates how KPIs correlate with user feedback. Tables 4 and 5 list top
ten signiﬁcant KPIs for relatively long history hours (15-24 hours)
and short history hours (3-9 hours), respectively. Being regressed
with individual users’ feedback, the signiﬁcant KPIs exhibit some
commonality (shown in bold) as well as differences.
From the KPIs relevant to network delivery statistics, we observe
that “tuner ﬁll”, “hole without session packets”, “hole too large”,
“bytes processed per sec” are particularly interesting KPIs. “Tuner
ﬁll” logs the number of packets lost by STBs before they are re-
quested for TCP retransmission. The lost packets are supposed to
be retransmitted by content distribution servers. Tuner ﬁll counts
can be related with video quality in that they indicate the condition
of the delivery network and gives a sense of the average packet loss
that would occur without any packet recovery scheme. A ’hole’
represents a time interval greater than a given threshold (assumed
to affect video quality) in which no video packets have been re-
ceived. ’Hole without session packets’ counts the number of such
holes occurred during a STB’s viewing session (since the user’s last
channel change). And ’hole too large’ error is triggered when the
hole size is larger than the maximum end-to-end delay of 150ms
recommended by [2].
On the audio and video related KPIs, “decoder error” logs are
general types of errors that occurred during the decoding of audio
data. Decoder errors can occur due to various situations including,
but not limited to, out-of-order data packet reception, audio buffer
underrun or overrun, and packet loss. ‘DRM errors’ and ‘crypto
error’ indicates errors caused by the video DRM decoder . This
error can occur when encoder packets containing DRM keys are
203KPI Type
Network delivery RTP payload error
KPI Label
Tuner ﬁll
Hole Too Large
Decoder stall
Bytes processed per sec
Audio decoder errors
Video DRM errors
Video decoder errors
Video frames decoded
Video data throughput
β Coef.
0.68
0.63
0.61
0.42
-0.32
0.84
0.73
0.53
-0.49
-0.49
Audio
Video
Audio
Video
Table 4: Signiﬁcant KPIs for large δ (15-24 hrs)
KPI Type
Network delivery Hole without session packets
KPI Label
Tuner ﬁll
Bytes processed per sec
ECM parse errors
Audio decoder errors
Audio samples dropped
Audio crypto error
Audio data dropped
Audio DRM errors
Video DRM errors
β Coef.
0.60
0.57
-0.34
0.32
1.03
0.84
0.64
0.55
0.34
0.63
Table 5: Signiﬁcant KPIs for small δ (3-9 hrs)
KPI Type
KPI Label
Network delivery Tuner ﬁll
Src unavailable received
Hole without session packets
ECM parse errors
Bytes processed per sec
Audio decoder errors
Audio data dropped
Audio crypto error
Video DRM errors
Video frames dropped
Audio
Video
β Coef.
0.67
0.5
0.52
0.35
-0.33
0.74
0.57
0.44
0.68
0.65
Table 6: Signiﬁcant KPIs for multi-scale temporal aggregation
(0-24 hrs)
lost.
In IPTV, every video program is encoded with DRM, and
inability of decoding DRM blocks viewing of the programs. Thus,
the occurrence of this error blocks TV viewing until new encoder
keys are received regardless of receipt of the data packets. Lastly,
the ‘video frames dropped’ error represents the number of video
frames drops (below the normal frame rate of 29.97 frames per
second) due to packet loss or decoder errors. When large frame
drop occurs, viewers can notice choppy or skippy motions.
Observations. We observe an interesting ﬁnding by comparing
signiﬁcant KPIs of long-term event durations (i.e., large δ) and
short-term event durations (i.e., small δ). The ﬁnding is that the
former tend to have more video related KPIs as the most signiﬁcant
ones, whereas the latter has more KPIs related to audio. This re-
lates with the relevance that audio has with respect to video in the
user experience. Audio data is more susceptible to losses and errors
than the video data. The reason is because the total volume of the
data in audio is much less than that of the video, thus the impact
of lost or delayed audio data is relatively greater than that of video
data. Naturally, the viewers of the programs have less tolerance
to audio issues than to video issues, and report about audio issues
much earlier than video issues. The contrasting ﬁnding between
long and short history hours has uncovered that, depending on the
characteristics of the issues (i.e., whether the issue is about audio
or video), there are differences in urgency.
e
r
o
c
s
-
Q
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0
-0.1
-12
-10
-8
-6
-4
-2
 0
Time (in days)
Figure 8: Growth pattern of Q-score
Another ﬁnding from the KPI analysis is drawn from multi-scale
temporal aggregation. As shown in Table 6, by combining long-
term and short-term event duration δ in regression, we observe both
video and audio related issues appear as the most signiﬁcant KPIs.
This further conﬁrms the effectiveness of letting the regression al-
gorithm to choose important KPIs among multiple temporal aggre-
gations.
Noticing that different KPIs have different degrees of relevancy
to user feedback, we aim to guide monitoring of network KPIs by
enlisting a small number of signiﬁcant KPIs to user-perceived ser-
vice quality. This way, forthcoming ﬁne-grained network diagnosis
can focus on the signiﬁcant KPIs rather than analyzing excessive
amount of KPIs.
5.2 Predicting Bad Quality of Experience
In order for Q-score to be useful for alerting services, it should
have the capability to provide triggers well before users start to call.
Thus, there is a need to study how much into the future we can infer
customer calls using Q-score. To understand the feasible level of
proactiveness in Q-score, we evaluated two characteristics: (i) the
growth pattern of Q-score over time and (ii) stability of Q-score
with a time gap between network events and user feedback.
Growth of Q-score Over Time. Figure 8 shows the growth pattern
of Q-score for individual user IDs who ﬁled trouble tickets. In the
ﬁgure, we align the time by the trouble ticket ﬁling time (time = 0)
and observe how Q-score grows. The solid line represents the av-
erage value of the scores and the upper and lower tips of error bars
represent one standard deviation plus and minus the average. From
the graph, we observe that the increase of average Q-score is close
to linear when it is greater than 0.05. The monotonic and grad-
ual increase of Q-score suggests a possibility of using Q-score as a
proactive trigger for alerting because (i) it keeps increasing once it
becomes non-negligible level and (ii) its growth is not too abrupt.
However, due to great variance among different users’ Q-scores,
we cannot use Q-score of 0.05 as the signiﬁcant value triggering
forthcoming actions. Instead, we seek a more realistic lead time by
conducting a further study on the stability of Q-score.
Feasible Level of Proactiveness. As aforementioned in Section 3.3,
user feedback has indeterminate delay from the occurrences of net-
work events. Here, we test the amount of lead time Q-score can
provide before customer calls by measuring the accuracy loss as
we increase the time gap between the occurrence times of network
204e
t
a
R
e
v
i
t
a
g
e
N
e
s
a
F
l
 100
 100
 80
 80
 60
 60
 40
 40
 20
 20
 0
 0
 0.001
 0.001
0 hrs
0 hrs
3 hrs
3 hrs
9 hrs
9 hrs
15 hrs
15 hrs
18 hrs
18 hrs
24 hrs
24 hrs
36 hrs
36 hrs
 0.01