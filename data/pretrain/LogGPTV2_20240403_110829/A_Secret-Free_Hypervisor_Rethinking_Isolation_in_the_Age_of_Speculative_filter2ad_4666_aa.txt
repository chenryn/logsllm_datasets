# A Secret-Free Hypervisor: Rethinking Isolation in the Age of Speculative Vulnerabilities

**Authors:** Hongyan Xia, David Zhang, Wei Liu, István Haller, Bruce Sherwin, and David Chisnall

**Conference:** 2022 IEEE Symposium on Security and Privacy (SP)

## Abstract
In recent years, the proliferation of speculative side-channel vulnerabilities has significantly increased the difficulty of enforcing domain isolation in virtualized cloud environments. While mitigations exist, the industry's approach is neither long-term nor scalable, as each vulnerability is addressed with specific mitigations that often result in substantial performance penalties. We propose a different approach to secret isolation: ensuring that the hypervisor is Secret-Free (SF).

A Secret-Free design partitions memory into secrets and non-secrets and reconstructs hypervisor isolation. It enforces that all domains have a minimal and secret-free view of the address space. Unlike existing methods, a Secret-Free hypervisor does not identify secrets to be hidden but instead identifies non-secrets that can be shared, using an allow-list approach. SF designs function with existing hardware and do not introduce noticeable performance penalties compared to unmitigated baselines, outperforming state-of-the-art techniques by allowing speculative execution where secrets are invisible.

We implemented SF in Xen (a Type-I hypervisor) to demonstrate its applicability to commercial hypervisors. Our evaluation shows performance comparable to the baseline and up to a 37% improvement in certain hypervisor paths compared to Xen's default mitigations.

Furthermore, we show that the Secret-Free approach is a generic kernel isolation infrastructure applicable to various systems, not limited to Type-I hypervisors. We applied the same model in Hyper-V (Type-I), bhyve (Type-II), and FreeBSD (UNIX kernel) to evaluate its applicability and effectiveness. The successful implementations on these systems confirm the generality of SF and highlight the specific adaptations and optimizations required for each type of kernel.

**Keywords:** security-in-depth, speculative vulnerabilities, hypervisor security, secret-free.

## 1. Introduction
In traditional models of kernel and user-space separation, exploiting user-space server applications has always been an attractive target. These applications often run with administrative privileges and handle data from multiple parties, making them vulnerable to attacks from malicious clients [1]–[5]. However, advancements in static analysis tools, dynamic code instrumentation, new programming languages, randomization, and sandboxing techniques have significantly increased the complexity of such attacks [6]–[9].

As a result, security researchers have shifted their focus to kernel vulnerabilities. The growing code base of operating system kernels, such as the Linux kernel, which has expanded from 6.6 MLOC in version 2.6.11 to 27.8 MLOC in 2020 [10], places immense pressure on code reviews and security audits. Analyzing all the code for security vulnerabilities is extremely challenging, if not impossible, leading to an increasing number of disclosed kernel vulnerabilities, including heap overflows, use-after-free bugs, undefined behavior, race conditions, and insufficient privilege checks [11]–[14].

Recent speculative vulnerabilities, such as Spectre [15] and Meltdown [16], further complicate kernel and VM isolation. Enforcing architectural boundaries is no longer sufficient in the presence of speculative side channels. To prevent the leakage of sensitive content over speculative paths on affected hardware, various mitigations have been deployed, including Kernel Page Table Isolation (KPTI) [17], Indirect Branch Prediction Barriers (IBPB), and Indirect Branch Restricted Speculation (IBRS) [18], fences, cache flushes, core scheduling [19], and retpolines [20]. These mitigations, however, introduce undesirable performance degradation, especially in system-call-heavy workloads. Proposed hardware modifications to limit speculation [21]–[23] are still under development and integration.

Given the inefficiency of existing software mitigations and the time required for hardware changes to reach commercialization, we explore new hypervisor designs that ensure each domain has a minimal surface and visibility. In light of recent speculative execution vulnerabilities, we no longer assume that architectural boundaries are sufficient and must include speculative side channels in the design. In this paper, we present the Secret-Free (SF) hypervisor as a systematic defense-in-depth solution. We categorize system state as either secrets or non-secrets and restrict all domains to the minimum, with no access to secrets. Unlike many existing mitigations, we operate under an allow-list approach, treating states as secrets by default. An address space contains secrets and explicitly identified non-secret data. Unlike KPTI or XPTI (Xen Page Table Isolation), we do not assume full access in the hypervisor. The hypervisor is restricted to the current guest domain upon entry and only creates temporary mappings for secret access when necessary.

Achieving SF guarantees requires several key design components, including direct-map teardown, per-domain and per-vCPU private memory, ephemeral mappings, efficient map caching, and the isolation of vCPU state, guest register frames, and hypervisor stacks. Together, these components ensure the isolation of guest and hypervisor secrets without introducing noticeable performance impact from strict domain isolation. The design and implementation of a secret-free hypervisor do not depend on hardware changes and can be deployed at scale on existing cloud platforms with negligible overhead, making it a generic structure that can be extrapolated to multiple types of kernels.

The contributions of this paper are summarized as follows:
- We propose a design that isolates all domains (including the hypervisor) from secrets. Instead of identifying secrets that need to be hidden, the SF design maintains a minimal address space and identifies non-secrets that can be exposed.
- We extend the isolation to guest registers, vCPU state, and hypervisor stacks using private mappings.
- We implement optimizations to minimize the overhead from the isolation of secrets. We develop an efficient caching mechanism for ephemeral mappings, demonstrating that a full address space is unnecessary for efficiency.
- We implement and evaluate the secret-free design on the open-source Type-I Xen hypervisor. With specific adaptations and optimizations to Xen, we achieve negligible overhead in real-world workloads and superior performance compared to default mitigations. We evaluate its security and demonstrate that it is impervious to several categories of architectural and speculative attacks.
- We implement the Secret-Free design in Hyper-V, bhyve, and the FreeBSD kernel. The implementations show that secret freedom is a generic technique that can be retrofitted into a variety of systems, including traditional UNIX kernels, Type-I, and Type-II hypervisors. We analyze the applicability and effectiveness of the technique on these systems and reveal necessary adaptations for further performance improvement and security hardening.

## 2. Background
In this section, we provide the background for kernel privilege separation and address-space layout, explaining why such a structure is susceptible to a broad category of architectural and speculative side-channel attacks.

### 2.1 Address Space Layout of Modern Kernels and VMMs
Assuming no Page Table Isolation (PTI), most kernels have a similar address space layout under virtual memory protection. The user-space guest address range (typically mapped at low addresses) maps user-accessible memory, which is per-process, while the kernel/hypervisor address range (at high addresses) is mapped into all page tables. As shown in Figure 1, the full address space of a user process includes the global kernel mappings, guarded by permission bits in the Page Table Entry (PTE), which are architecturally accessible only under kernel privileges. This global mapping accelerates system calls, interrupts, and exception handling by requiring only a privilege level change rather than a page table swap, reducing the performance cost from CPU pipeline and TLB flushes.

This layout also applies to hypervisors. Second-level paging or shadow page tables will present a different set of memory to each VM, but the full hypervisor address range is mapped into all address spaces, ensuring fast hypercalls and VM exit handling. The kernel and user address split is so ubiquitous that we have not found a different design in the kernels or hypervisors (Xen, Linux/KVM, FreeBSD/bhyve) studied in this paper.

### 2.2 The Direct Map
By taking advantage of the abundance of virtual address space, modern 64-bit kernels implement a common facility for performance and ease of management: the direct map. This is a large contiguous virtual address range in the kernel that is 1:1 mapped to the entire physical memory (Figure 1). Variations exist that deviate from a flat 1:1 mapping on different platforms. For example, the Xen hypervisor permits "compression" by removing large holes on the direct map, useful for accommodating devices with RAM starting at high addresses or in multiple disjoint ranges. Windows NT maintains multiple paged and non-paged pools, but the concept of a direct map remains a fundamental feature in modern kernels.