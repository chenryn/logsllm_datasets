title:A Secret-Free Hypervisor: Rethinking Isolation in the Age of Speculative
Vulnerabilities
author:Hongyan Xia and
David Zhang and
Wei Liu and
Istv&apos;an Haller and
Bruce Sherwin and
David Chisnall
2022 IEEE Symposium on Security and Privacy (SP)
A Secret-Free Hypervisor: Rethinking Isolation in
the Age of Speculative Vulnerabilities
Hongyan Xia,†∗ David Zhang,† Wei Liu,†‡ Istvan Haller,† Bruce Sherwin,† David Chisnall†
†Microsoft
6
2
7
3
3
8
9
.
2
2
0
2
.
4
1
2
6
4
P
S
/
9
0
1
1
.
0
1
:
I
O
D
|
E
E
E
I
2
2
0
2
©
0
0
.
1
3
$
/
2
2
/
9
-
6
1
3
1
-
4
5
6
6
-
1
-
8
7
9
|
)
P
S
(
y
c
a
v
i
r
P
d
n
a
y
t
i
r
u
c
e
S
n
o
m
u
i
s
o
p
m
y
S
E
E
E
I
2
2
0
2
Abstract—In recent years, the epidemic of speculative side
channels signiﬁcantly increases the difﬁculty in enforcing domain
isolation boundaries in a virtualized cloud environment. Although
mitigations exist, the approach taken by the industry is neither a
long-term nor a scalable solution, as we target each vulnerability
with speciﬁc mitigations that add up to substantial performance
penalties. We propose a different approach to secret isolation:
guaranteeing that the hypervisor is Secret-Free (SF).
A Secret-Free design partitions memory into secrets and non-
secrets and reconstructs hypervisor isolation. It enforces that all
domains have a minimal and secret-free view of the address
space. In contrast to state-of-the-art, a Secret-Free hypervisor
does not identify secrets to be hidden, but instead identiﬁes non-
secrets that can be shared, and only grants access necessary
for the current operation, an allow-list approach. SF designs
function with existing hardware and do not exhibit noticeable
performance penalties in production workloads versus the un-
mitigated baseline, and outperform state-of-the-art techniques
by allowing speculative execution where secrets are invisible. We
implement SF in Xen (a Type-I hypervisor) to demonstrate that
the design applies well to a commercial hypervisor. Evaluation
shows performance comparable to baseline and up to 37%
improvement in certain hypervisor paths compared with Xen
default mitigations.
Further, we demonstrate Secret-Free is a generic kernel
isolation infrastructure for a variety of systems, not limited to
Type-I hypervisors. We apply the same model in Hyper-V (Type-
I), bhyve (Type-II) and FreeBSD (UNIX kernel) to evaluate its
applicability and effectiveness. The successful implementations on
these systems prove the generality of SF, and reveal the speciﬁc
adaptations and optimizations required for each type of kernel.
Index Terms—security-in-depth, speculative vulnerabilities, hy-
pervisor security, secret-free.
I. INTRODUCTION
In the conventional model of kernel and user space sep-
aration, exploiting user space server applications has always
been an attractive target. These applications often run with
administrative privileges and handle data from multiple parties,
which are prone to attacks from malicious clients [1]–[5].
However, sophisticated static analysis tools, dynamic code
instrumentation, new programming languages, randomization
and sandboxing techniques in recent years have signiﬁcantly
increased the complexity of mounting such attacks [6]–[9].
Instead, security researchers have turned to kernel vulnera-
bilities. The ever increasing code base of OS kernels exerts
tremendous amount of pressure on code reviews and security
auditing. For example, the size of the Linux kernel has grown
from 6.6 MLOC back in 2.6.11 to 27.8 MLOC in 2020 [10].
∗Part of the work is done while at Amazon Web Services.
‡Part of the work is done while at Citrix/Xen Project.
Analysing all the code for security vulnerabilities is astro-
nomically difﬁcult, if not outright impossible. The growing
attack surface inevitably leads to an increasing number of
disclosed kernel vulnerabilities, ranging from heap overﬂows,
use-after-free bugs, undeﬁned behaviour to race conditions and
insufﬁcient privilege checks [11]–[14].
In recent years, speculative vulnerabilities such as Spec-
tre [15] and Meltdown [16] further complicate kernel and
VM isolation. Enforcing architectural boundaries is no longer
sufﬁcient in the presence of speculative side channels. To
prevent leaking sensitive content over the speculative paths on
affected hardware, mitigations are deployed including Kernel
Page Table Isolation (KPTI) [17], Indirect Branch Prediction
Barriers (IBPB) and Indirect Branch Restricted Speculation
(IBRS) [18], fences, cache ﬂushes, core scheduling [19],
retpolines [20], and so on. As these mitigations introduce
undesirable performance degradation especially in system-call-
heavy workloads, hardware modiﬁcations have been proposed
to limit the effect of speculation [21]–[23]. Although these
CPU and cache changes are able to block or restrict spec-
ulation at the silicon-level, it remains to be seen how well
they integrate into high-performance server farms and how
long such integration may take before the next vulnerability
is discovered.
As existing software mitigations can be inefﬁcient and hard-
ware modiﬁcations take time to reach commercialization, we
explore new designs of the hypervisor such that each domain
always has a minimal surface and visibility. In the wake
of recent speculative execution vulnerabilities, we no longer
assume that architectural boundaries are sufﬁcient and must
include speculative side channels in the design. In this paper,
we present the Secret-Free (SF) hypervisor as a systematic
defense-in-depth solution. We categorize system state as either
secrets or non-secrets and restrict all domains to the minimum,
having no access to secrets. In contrast
to many existing
mitigations, we operate under an allow-list approach, treating
states as secrets by default. An address space contains secrets
of its own and explicitly identiﬁed non-secret data. Unlike
KPTI or XPTI (Xen Page Table Isolation), we do not assume
full access in the hypervisor. The hypervisor is restricted to the
current guest domain upon entry, and only creates temporary
mappings for secret access when necessary.
Reaching the SF guarantees requires several key design
components, including direct-map teardown, per-domain and
per-vCPU private memory, ephemeral mappings, efﬁcient map
cache as well as the isolation of vCPU state, guest register
© 2022, Hongyan Xia. Under license to IEEE.
DOI 10.1109/SP46214.2022.00115
370
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:11:47 UTC from IEEE Xplore.  Restrictions apply. 
frames and hypervisor stacks. Together, they guarantee the
isolation of guest and hypervisor secrets while not introducing
noticeable performance impact from strict domain isolation.
Overall, the design and implementation of a secret-free hyper-
visor do not depend on hardware changes and can be deployed
at scale on existing cloud platforms with negligible overhead,
and is a generic structure that can be extrapolated to multiple
types of kernels.
The contributions of this paper are summarized below:
• We propose a design that isolates all domains (including
the hypervisor) from secrets. Instead of identifying secrets
that need to be hidden, the SF design maintains a minimal
address space and identiﬁes non-secrets that can be
exposed.
• We extend the isolation to guest registers, vCPU state and
hypervisor stacks using private mappings.
• We implement optimizations to minimize the overhead
from the isolation of secrets. We invent an efﬁcient
caching mechanism for ephemeral mappings, proving that
a full address space is unnecessary for efﬁciency.
• We implement and evaluate the secret-free design on the
open-source Type-I Xen hypervisor. With speciﬁc adap-
tations and optimizations to Xen, we achieve negligible
overhead in real-world workloads and superior perfor-
mance compared with default mitigations. We evaluate its
security and demonstrate that it is impervious to several
categories of architectural and speculative attacks.
• We implement the Secret-Free design in Hyper-V, bhyve
and the FreeBSD kernel. The implementations show se-
cret freedom is a generic technique that can be retroﬁtted
into a variety of systems including traditional UNIX
kernels, Type-I, and Type-II hypervisors. We analyse
the applicability and effectiveness of the technique on
these systems and reveal necessary adaptations for further
performance improvement and security hardening.
II. BACKGROUND
In this section, we provide the background for kernel privi-
lege separation and address-space layout. We explain why such
a structure is susceptible to a broad category of architectural
and speculative side channel attacks.
A. Address space layout of modern kernels and VMMs
Assuming no Page Table Isolation (PTI), most kernels
have a similar address space layout under virtual memory
protection. User space guest address range (typically mapped
at low addresses) maps user accessible memory which is per-
process whereas the kernel / hypervisor address range (at high
addresses) is mapped into all page tables. As is shown in
Fig. 1, the full address space of a user process includes the
global kernel mappings guarded by permission bits in the Page
Table Entry (PTE), which are architecturally accessible only
under kernel privileges. Such a global mapping accelerates
system calls, interrupts and exception handling by requiring
only a privilege level change but not a page table swap,
Fig. 1. Kernel/user split. The dashed square indicates the full address space
of Process 3.
reducing the performance cost from the accompanying CPU
pipeline and TLB ﬂushes.
This layout applies to hypervisors as well. The second-level
paging or shadow page tables will present a different set of
memory to each VM but the full hypervisor address range is
mapped into all address spaces, ensuring fast hypercalls and
VM exit handling. The kernel and user address split is so
ubiquitous that we have not found a different design in the
kernels or hypervisors (Xen, Linux/KVM, FreeBSD/bhyve)
studied in this paper.
B. The direct map
By taking advantage of the abundance of virtual address
space, modern 64-bit kernels implement a common facility for
performance and ease of management: the direct map. This is
a large contiguous virtual address range in kernel that is 1:1
mapped to the entire physical memory (Fig. 1). Variations exist
that deviate from a ﬂat 1:1 mapping on different platforms.
The Xen hypervisor permits “compression” by removing large
holes on the direct map, useful for accommodating devices
with RAM starting at high addresses or in multiple disjoint
ranges. Windows NT maintains multiple paged and non-paged