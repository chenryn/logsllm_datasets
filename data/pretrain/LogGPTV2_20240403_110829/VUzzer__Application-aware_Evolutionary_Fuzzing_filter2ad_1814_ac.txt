generating new inputs than i1. This step eventually generates
a sorted list Lf it of inputs in decreasing order of their ﬁtness
scores.
Genetic operators and new input generation: This is
the ﬁnal and most important functionality in our fuzzing strat-
egy, encompassing the SELECT, RECOMBINE, and MUTATE
steps in Algorithm 1. Together, these substeps are responsible
for generating interesting inputs. In each iteration of the main
loop, we generate a new generation of inputs by combining
main0xFDEFvalidgfile.MAZEexitABCDEHnestedgIFFGsomegtaskI@bugerrorerrorJ1,111,10.50.50.5,210.5,20.50.50.25,40.50.5,2.5,20.50.50.50.50.44,2.30.06,160.13,8and mutating the inputs from SI, all tainted inputs, and the
top n% of Lf it. We refer to this set as the ROOT set.
Speciﬁcally, we generate new inputs via crossover and
mutation. First, we randomly select two inputs (parents) from
ROOT and apply crossover to produce two new inputs (chil-
dren). With a ﬁxed probability, these two inputs further un-
dergo mutation. Mutation uses several sub-operations, such as
deletion, replacement, and insertion of bytes at certain offsets
in the given input. The mutation operator makes use of the
data-ﬂow features to generate new values. For example, when
inserting or replacing bytes, it uses characters from Limm to
generate byte sequences of different lengths. Similarly, various
offsets from current inputs’ parents are selected for mutation.
Hence, if any magic bytes exist, they will be replaced at the
proper offsets in the resulting inputs.
This loop of input generation continues until we meet a
termination condition. Currently, we terminate when we ﬁnd
a crash or when VUzzer reaches a pre-conﬁgured number of
generations.
For easier reference, Table I provides a list of symbols that
we use throughout the paper. In the next section, we elaborate
TABLE I.
GLOBAL SYMBOLS AND THEIR MEANING.
Symbol
DTA
SI
LBB
Limm
Lf it
Oother
Llea
Description
dynamic taint analysis
set of seed inputs (valid inputs).
list of basic block weights, obtained by static analysis of the applica-
tion binary.
list of immediate values from cmp instructions, obtained by static
analysis of the application binary.
Sorted lists (in decreasing order) of ﬁtness scores of inputs, obtained
in the ﬁtness calculation step.
set of all tainted offsets, other than the ones which are placeholder for
magic bytes. This set is obtained by DTA.
set of offsets that taint the index operand of lea instructions.
on the algorithms that we use to derive relevant information
about the input structure by using control-ﬂow and data-ﬂow
features.
IV. DESIGN AND IMPLEMENTATION
In this section, we detail the techniques to calculate several
primitives discussed in the previous section. The section also
presents implementation details of VUzzer.
A. Design Details
1) Dynamic Taint Analysis (DTA): DTA is the core of
VUzzer as it plays a major role in evolving new inputs. This
is also the technique that sets VUzzer apart from existing
fuzzers. DTA is used to monitor the ﬂow of tainted input (e.g.,
network packets, ﬁles, etc.) within the application. DTA can
determine, during program execution, which memory locations
and registers are dependent on tainted input. Based on the
granularity, DTA can trace back the tainted values to individual
offsets in the input. VUzzer uses DTA to trace tainted input
offsets used at cmp and lea instructions. For every executed
cmp instruction cmp op1, op2 (op1 and op2 can either
be register, memory, or immediate operands), DTA determines
if op1 and/or op2 are tainted by a set of offsets. Our DTA im-
plementation is able to track taint at the byte level. For a given
tainted operand op, DTA provides taint information for each
byte of op. Symbolically, if op is denoted as b3, b2, b1, b0, then
DTA provides taint information for each byte bi separately.
We denote the set of offsets that taint the jth byte of the ith
operand of a given cmp instruction as T i
j . We also record the
values of these operands. Symbolically, we represent a tainted
cmp instruction as cmpi = (of f set, value), where of f set
and value are the sets of offsets from tainted input and the
set of values for the untainted operand of the cmp instruction.
For each lea instruction, DTA tracks only the index register.
Llea contains all the offsets that taint such indexes.
2) Magic-byte Detection: Based on our understanding of
ﬁle formats that have magic bytes, we postulate that a magic
byte is a ﬁxed sequence of bytes at a ﬁxed offset in the input
string. We have veriﬁed this assumption on several ﬁle formats
that have magic bytes, for example, jpeg, gif, pdf, elf, and ppm.
As VUzzer assumes the availability of a few valid inputs for
a given application, we use the results of DTA on these inputs
at the beginning of fuzzing. As applications expect the input
to contain magic bytes, DTA’s results on cmp instructions will
contain the corresponding check for magic bytes.
For example, the code from Listing 3 expects a magic byte
0xFDEF in the beginning of the input ﬁle. Hence, DTA will
capture two cmp instructions—cmp reg, 0xFD with reg
tainted by offset 0 and cmp reg, 0xEF with reg tainted by
offset 1. If we have a set of valid inputs for this program, we
can observe these two cmp instructions in all the corresponding
executions. Conversely, if for a set of valid inputs we get
cmpi = (oi, vi) in DTA’s results for all the inputs, vi is a
part of the magic byte at offset oi.
It should be noted that the algorithm we use to detect magic
bytes can incur false positives. This may happen if all the
initial valid inputs share identical values at the same offsets.
Nonetheless, this will still be useful for generating inputs that
go beyond the very initial check for magic bytes with a reduced
probability of exploring different paths. To avoid this situation,
we prefer to start with a diverse but valid set of inputs.
j| > 1, we exclude such offsets (∈ T i
During magic-byte detection, for a given cmpi instruction,
if the corresponding value depends on multiple offsets per
byte, we do not consider such offsets to be magic-byte can-
didates. For example, for a given cmp instruction, if DTA
detects that |T i
j ) from
any further consideration for magic-byte placeholders. Such
a case indicates that the value of the corresponding operand
may be derived from tainted values at those offsets ∈ T i
j .
The dependence on multiple bytes breaks the assumption that
magic bytes are ﬁxed (constant) sequences of bytes. We denote
the set of all such offsets as Oother.
3) Basic Block Weight Calculation: From a coverage-
based fuzzing perspective, every feasible path is important to
traverse. A simple fuzzing strategy is to spend equal efforts
to generate inputs for all feasible paths. However, due to the
presence of control structures, the reachability of some paths
may not be the same as that of other paths. This situation
arises very frequently if we have nested control structures [41].
Therefore, any input that exercises such hard-to-reach code
should be rewarded more compared to other inputs.
We incorporate this reward by assigning higher weights to
basic blocks that are contained within nested control structures.
As enumerating all the paths at the interprocedural level has
trouble scaling, we constrain our analysis at the intraprocedural
6
level, i.e., we calculate weights for each basic block within the
containing function. Later, we gather and add the weights of
all the basic blocks in a path that is executed by a given input.
With this strategy, we simulate the score of an interprocedural
path by stitching several intraprocedural path scores together.
If we consider that the transition of an input at a particular
basic block to the next basic block is dependent on some
probability, we can derive a probabilistic model called Markov
process for the input behavior from the control-ﬂow graph
(CFG). A Markov process is a stochastic process in which
the outcome of a given trial depends only on the current state
of the process [30]. We model the CFG of a function as a
Markov process with each basic block having a probability
based on its connections with other basic blocks.
For a given basic block, we assign equal probability to all
its outgoing edges. Hence, if out(b) denotes the set of all out-
going edges of basic block b, then ∀eb∗ ∈ out(b), prob(eb∗) =
1/|out(b)|. The transition probability (likelihood) of a basic
block b is calculated as follows:
(cid:88)
prob(b) =
c∈pred(b)
prob(c) ∗ prob(ecb)
(1)
where pred(b) is the set of all the predecessors of b. We
employ a ﬁxed-point iteration algorithm to compute the prob-
ability associated with each basic block in the CFG. The root
basic block of the CFG is initialized with a probability of 1.
Loops are handled by assigning a ﬁxed probability of 1 to each
backedge, thereby neglecting the effect of the backedge itself
(i.e., we ﬂatten the loop to speed up ﬁxed point calculation).
From Equation 1, the weight of each basic block b is given
by:
inputs are caught by different error-handing code. Nonetheless,
note that we will never classify a basic block corresponding to
a valid path as an error-handling basic block. More formally,
let
V alidBB = ∪i∈SIBB(i), then
EHB = {b : ∀k ∈ T R, b ∈ BB(k)&b /∈ V alidBB}
where EHB is a set of error-handling basic blocks.
Incremental analysis: We observe that since our error-
handling detection strategy is based on the dynamic behavior
of the application, not all error-handling code may be triggered
during the initial analysis. As inputs evolve,
they explore
more paths and thus encounter new error-handling code. For
this reason, we initiate an incremental analysis during later
iterations of fuzzing. In our experimental setup, we observed
that, as we proceed with more iterations of fuzzing, the number
of new error-handling code instances decreases. This reﬂects
the intuition that software has a ﬁnite number of error-handling
code instances, which are reused in different parts of the
application. Therefore, we run our incremental analysis less
frequently as we execute more iterations.
The intuition behind our incremental analysis is the ob-
the majority of newly
servation that as fuzzing proceeds,
generated inputs will end up triggering some error-handling
code. At a given iteration, let I be the set of inputs generated
in the iteration. Let the majority be quantiﬁed by n% of |I|.
Our (ofﬂine) experiments show that n = 90 is a reasonable
choice. Let BB(I) be the set of all the basic blocks executed
by inputs in I. We classify a basic block b from BB(I) as
an error-handling basic block if it is associated to at least n%
of the inputs from I and it is not in the V alidBB set. More
formally, let P(I) denote the power set of I. Then
wb =
1
prob(b)
(2)
EHB = {b : ∀k ∈ P(I), s.t. |k| > |I| ∗ n/100,
b ∈ BB(k)&b /∈ V alidBB}
4) Error-Handling Code Detection: As noted earlier, dur-
ing fuzzing, the majority of mutated inputs will be executing
a path ending up in some error state. Deprioritizing such
execution paths is a key step towards increasing the chances of
creating interesting inputs faster. Our error-handling detection
heuristic relies on the availability of valid inputs, which is
a prerequisite of VUzzer. As our error-handling detection
depends on the dynamic behavior of the application, it detects
error-handling basic blocks in an incremental manner.
Initial analysis: For each valid input i ∈ SI, we collect
a set BB(i) of basic blocks that are executed by i. Let V alidBB
denote the union of all such sets of executed basic blocks
by all valid inputs. We then create a set of totally random
inputs, denoted as T R. For each input in this set, we collect
its execution trace in terms of basic blocks. A basic block from
such a set of executions is assumed to be a error-handling basic
block (i.e., belonging to error-handling code) if it is present
in each execution of inputs from T R and it is not present in
V alidBB. The intuition is that since SI is a set of valid inputs,
no error-handling code will be triggered. Therefore, V alidBB
will contain only basic blocks that correspond to valid paths.
And since T R is a set of totally random inputs, they will be
very likely caught by error-handling code during the execution.
Ours is a very conservative error-handling basic block
detection strategy as we may miss few basic blocks if certain
7
Weight calculation for error-handling basic blocks:
After detecting error-handling basic blocks (EHBs), we want
to deprioritize paths that contain such blocks. We achieve this
by penalizing the corresponding inputs so that such inputs
have less chances of participating in next generation. For
this purpose, each EHB is given a negative weight, which
impacts the ﬁtness score of the corresponding inputs (see
Section IV-A5). However, this strategy is alone insufﬁcient
since, as EHBs are a small minority when compared to the
total number of basic blocks executed by an input, such a small
quantity will have negligible impact. We solve this problem
by deﬁning an impact coefﬁcient µ (a tunable parameter) that
decides how many (non-error handling) basic blocks may be
nulliﬁed by a single error-handling basic block. Intuitively, this
parameter determines that, once an input enters error-handling
code, the contribution of any of the corresponding basic blocks
when calculating ﬁtness scores must be reduced by a factor µ.
For a given input i, we use the following formula for weight
calculation purposes.
we = −|BB(i)| × µ
|EHB(i)|
(3)
where |BB(i)| is number of all the basic blocks executed by
input i, |EHB(i)| is the number of all the error-handling basic
blocks executed by i, and 0.1 ≤ µ ≤ 1.0.
5) Fitness Calculation: Fitness calculation is one of the
most important components of evolutionary algorithms. This
is crucial to implement the feedback loop, which fuels the next
step of input generation. Once a new input is generated, the
chances of its participation in generating new inputs depend
on its ﬁtness score.
VUzzer assess the ﬁtness of an input in two ways. If the
execution of an input results in discovering a new non-EHB
basic block, the input qualiﬁes for participation in the next
generation. This is similar to AFL (with the additional use
of the EHB set). However, this measure of ﬁtness considers
all newly discovered paths equal, which is problematic, as
explained earlier. The importance (and thus the ﬁtness) of
an input depends on the interestingness of the path that
it executes, which, in turn, depends on the weights of the
corresponding basic blocks. Therefore, we deﬁne ﬁtness fi
of an input i as a function that captures the effect of all the
corresponding basic block weights.
(cid:80)
(cid:80)
b∈BB(i)
b∈BB(i)
fi =
log(Freq(b))Wb
log(li)
log(Freq(b))Wb
BBNum if li > LMAX
otherwise.
(4)
where BB(i) is the set of basic blocks executed by input i,
Freq(b) is the execution frequency of basic block b when
executed by i, Wb is the weight of basic block b (by using
Equation 2), li is the length of input i, and LMAX is a pre-
conﬁgured limit on input length. LMAX is used to address the
phenomenon of input bloating. In the parlance of genetic al-
gorithms, both of the ﬁtness criteria (i.e. ability to discovering
new basic block and a higher fi) correspond to the notion of
exploration and exploitation—discovering a new basic block
indicates a new direction (i.e., exploration) and a higher fi
indicates higher execution frequencies (among other factors)
of basic blocks (i.e., exploitation in the same direction).
6) Input Generation: VUzzer’s input generation consists
of two parts, crossover and mutation, which are not mutually