O(|P| · |R|2), where |P| is the number of prefixes, and |R| is the
number of internal routers in the network. The derivation of this
can be found in App. D.3.
5.3 Soft Specification
There may exist multiple orderings satisfying the hard specifica-
tion, which have varying side-effects, as shown in §2.2. Therefore,
Snowcap also considers a soft specification that guides its search
tactics towards a “good” solution.
The soft specification consists of a cost function f : Sn (cid:55)→ R
that maps a sequence of converged network states to a cost. The
sequence of states is given by applying the configuration commands
of the ordering one-by-one. Currently, Snowcap supports traffic
shifts as a cost function, penalizing changes in the forwarding state.
One can easily add any cost function, as long as it is monotonically
increasing (i.e., f ([s0, . . . , sn−1]) ≤ f ([s0, . . . , sn])). Other examples
include, e.g., minimizing the number of routes maintained in the
routing table or preferring orderings with a faster transition. Snow-
cap uses a greedy approach to find a good reconfiguration ordering
with respect to the provided cost function, see §4.3.
Example: Minimize Traffic Shifts. In the following, we highlight
one example of a cost function that penalizes unnecessary traffic
shifts during migration. First, we look at the costs associated with
applying a single command. Then, we combine them to compute
the costs of an entire command ordering. The cost associated with
applying command with index i can be computed using the for-
warding graph nhi−1 of the previous network state si−1 and the
graph nhi of the current state si as follows:
if nhi−1(r, p) (cid:44) nhi(r, p)
otherwise


r ∈R
p∈P
(cid:26) 1
0
fi =
1
|R| · |P|
Here, R is the set of all internal routers, and P is the set of all
externally advertised prefixes. The function nhi(r, p) represents the
next hop for prefix p ∈ P chosen by the router r ∈ R in the state
si. The final cost, associated with the entire ordering of length n, is
computed by
FC([f1, . . . , fn]) = 
fi
1≤i ≤n
A cost of 0 means, that no router has changed its next hop during
the reconfiguration process, i.e., no traffic shift occurred. If, during
the entire reconfiguration process, the next hop of every prefix on
every router changes exactly once, the cost is 1.
Synthesizing Network-Wide Configuration Updates
SIGCOMM ’21, August 23–28, 2021, Virtual Event, USA
Time [s]
2
1
0
Random permutations
Snowcap = Snowcap−
40
20
80
Number of commands
60
100
Time [s]
40
30
20
10
0
5
Random permutations
Snowcap−
Snowcap
20
Number of dependency groups
10
15
Time [s]
101
10−1
10−3
0 8
39 48
Complexity of ϕ
66
c = 5
c = 9
c = 13
c = 17
c = 21
c = 25
c = 29
(a) Snowcap scales well in problem size,
i.e., number of commands with straight-
forward dependencies.
(b) Snowcap’s divide-and-conquer ap-
proach shines when faced with many
complicated dependency groups.
(c) Specification complexity greatly im-
pacts the shape of the search space, and
hence Snowcap’s runtime.
Figure 7: Runtime of Snowcap with respect to three different aspects; number of commands, number of dependency groups,
and complexity of the hard specification.
6 EVALUATION
We now evaluate Snowcap along three dimensions using a proto-
type implementation by comparing it against multiple baselines.
First, we analyze Snowcap’s performance (§6.1) and show that, even
for large reconfigurations, Snowcap finds a valid ordering within
few seconds, which is orders of magnitude faster than the (random)
baseline. We also show that Snowcap’s runtime depends heavily on
the shape of the search space, and only indirectly on the input size
or the complexity of the reconfiguration scenario. Second, we ana-
lyze Snowcap’s effectiveness (§6.2) at optimizing for soft objectives
and the overhead incurred by the greedy optimization. We show
that, in the vast majority of the networks and scenarios, Snowcap
finds orderings that heavily reduce the number of traffic shifts while
suffering from a predictable and acceptable overhead. Third, we
analyze Snowcap’s accuracy (§6.3) in evaluating properties during
convergence. We show that Snowcap’s analysis is sometimes overly
cautious, but never deems a reconfiguration command safe when it
is unsafe.
Implementation. Our implementation consists of ≈ 40 k lines of
Rust code and currently supports: (i) static routes, link-state IGP
protocols like OSPF, and BGP; (ii) the LTL-based hard specification
language as shown in Fig. 6; and (iii) soft specifications to reduce
traffic shifts. Our implementation can easily be extended to support
additional protocols and specification properties. We run all exper-
iments on a server with 64 cores clocked at 2.25 GHz and 512 GB
of memory. One instance of Snowcap is always assigned a single
thread. In all experiments, we use our own simulator as an oracle,
which is able to verify around 50k states per second on average.
6.1 Scalability of Snowcap
In this section, we look at how Snowcap scales and how its runtime
depends on: (a) the size of the reconfiguration problem, i.e., the
number of reconfiguration commands; (b) the complexity of the
reconfiguration problem, i.e., the number of dependency groups
without immediate effect; and (c) the complexity of the hard speci-
fication ϕ.
Methodology. We compare Snowcap to a random baseline and
Snowcap− which only performs the exploration phase (§4.1) with-
out learning dependencies (§4.2). We run each approach on each
reconfiguration scenario 1 000 times and report the median execu-
tion time.
Reconfiguration size. In the first experiment, we analyze the per-
formance of Snowcap with respect to the reconfiguration size, i.e.,
the number of reconfiguration commands. To this end, we use the
chain gadget (see App. E.1), a variable-size synthetic topology con-
sisting of n routers arranged in a chain, each of which is modified
once during the reconfiguration to change its next hop. There exists
exactly one valid ordering of these n commands, and any mistake
will immediately cause a forwarding loop.
Fig. 7a shows the runtime incurred by the three approaches when
checking for reachability. Snowcap clearly outperforms the random
baseline as only one of the n! orderings is valid. Snowcap− performs
identically to Snowcap, as all dependencies can be resolved using
the exploration algorithm.
Reconfiguration complexity. In the second experiment, we in-
spect Snowcap’s performance with respect to the number of depen-
dency groups, i.e., the complexity of the reconfiguration problem.
We use the Bipartite Gadget (see App. E.2), a synthetic topology
built by replicating a small network. The reconfiguration for each
sub-network involves three reconfiguration commands, forming a
dependency group with no immediate effect. In each group, three
orderings out of the possible 3! = 6 are valid. The problem associ-
ated with each replicated network is independent of the others and
can be solved in isolation.
Fig. 7b shows the runtime incurred by the three approaches when
checking for reachability. Here, Snowcap’s divide-and-conquer ap-
proach shines; by identifying and solving the dependency groups
independently, Snowcap clearly outperforms the other approaches.
While the random baseline takes more than 30 seconds to find a
valid ordering for a problem with 15 dependency groups, Snowcap
solves it in less than one second. Snowcap− quickly reaches its
limits as it has to backtrack frequently while solving the entire
problem at once.
SIGCOMM ’21, August 23–28, 2021, Virtual Event, USA
Tibor Schneider, Rüdiger Birkner, and Laurent Vanbever
)
t
f
i
h
S
c
ffi
a
r
T
(
t
s
o
C
F
D
C
2
1.5
1
0.5
0
100%
≈ 80%
≈ 45%
0%
Baseline: important first
Baseline: important last
Baseline: random
Snowcap
Double IGP weights (IGPx2)
Double local-pref (LPx2)
Network Acquisition (NetAcq)
78
100%
≈ 60%
15%
0%
0
0
0.5
1
CostSnowcap/CostRandom
96%
1
0.5
≈ 1.13
CostSnowcap/CostRandom
55
76
100%
≈ 60%
≈ 30%
0%
0
0.5
1
CostSnowcap/CostRandom
Figure 8: In almost all cases, Snowcap finds an ordering with significantly lower cost (less traffic shifts) than all three baselines,
with higher consistency. The upper plots compare Snowcap with the baselines for different topologies. Below is the CDF of
the median cost ratio between Snowcap and the random baseline.
Specification complexity. In the third experiment, we analyze
the impact of specification complexity on Snowcap’s runtime. We
use the Abilene Network from Topology Zoo with six Forwarding
Equivalence Classes (FECs)7, each of which is advertised by two
different eBGP peers. The network consists of 11 routers, which we
reconfigure from a two-level route reflector topology to a single
level, in addition to modifying several link weights. We start with
a simple hard specification which requires reachability for all 66
flows. We then gradually increase the complexity of the specifica-
tion by mandating an increasing number of flows to immediately
switch from the initial to the final path and “stay there”. We run
the experiment for a varying number of commands c: we always
use the 5 commands required for the BGP migration to which we
add a variable number of link weight changes. For example, c = 29
represents the scenario in which 24 link weights are changed.
Fig. 7c shows the runtime of Snowcap (on a logarithmic scale)
with respect to the number of restricted flows and commands. For
simple cases (c ≤ 17), increasing complexity leads to new depen-
dencies, making it harder to find a solution. Especially condition 39
and 48 add complex dependencies. However, for larger scenarios
(c ≥ 25), increasing complexity might reduce the runtime, as it
significantly restricts the search space. The scenario c = 21 exhibits
both: adding condition 8 reduces the runtime by several orders of
magnitude, but adding condition 48 brings new dependencies.
As it is the case for SAT solvers, Fig. 7c shows that Snowcap’s
runtime depends more on the shape of the search space rather than
the complexity of the reconfiguration scenario.
6.2 Effectiveness of Snowcap
We measure Snowcap’s effectiveness to optimize a soft specifica-
tion by comparing its reconfiguration cost with three baselines and
by analyzing the incurred overhead. We show that Snowcap con-
sistently finds good reconfiguration orderings, outperforming the
7An FEC is a group of prefixes with identical forwarding behavior (cf. [26])
baselines in almost all experiments and we show that the overhead
for the optimization remains bounded.
Methodology. We use a set of 80 topologies from Topology Zoo8
(each containing between 5 and 82 routers, 34 on average) and
consider four reconfiguration scenarios: doubling all IGP weights
(IGPx2), doubling all local-preferences (LPx2), performing a network
acquisition (NetAcq) (cf. §2.2), and moving from a full mesh iBGP
topology to a single route reflector (FM2RR) (cf. §2.1). In all scenar-
ios, we choose the IGP configuration at random. We always select
the router with the most links as route reflector (following best
practices [20]). Both IGPx2 and LPx2, as well as the two merging
networks in NetAcq, are configured to use a single route reflector.
We then compare Snowcap’s reconfiguration plans with random or-
derings, alongside with two importance-based orderings in which
we order the commands according to the number of flows they
affect in increasing or decreasing order.
Reconfiguration Costs. In Fig. 8, we compare the cost (number
of traffic shifts, cf. §5.3) of Snowcap’s reconfiguration ordering to
those of the three baselines by performing 10 000 runs each. We
show two plots for each scenario: First, we compare the median
cost, along with the 25th and 75th percentile on each topology.
Second, we show the CDF of the ratio between the median cost of
Snowcap and the random approach. Intuitively speaking, the green
area represents how often and by how much Snowcap outperforms
the baseline, and the red area the opposite.
As Fig. 8 clearly highlights, Snowcap outperforms the baselines in
terms of reconfiguration cost except for 3 out of the 209 topologies.
Snowcap performs especially well for IGPx2, where in 80% of the
topologies, it finds a solution at least twice as good as the random
baseline. But also for LPx2 and NetAcq, Snowcap outperforms the
8 Not every topology can be used for every scenario, as they have different topological
requirements. The network acquisition scenario could only be evaluated on 55 of the
80 topologies. Also, few topologies could not be used with the other scenarios.
Synthesizing Network-Wide Configuration Updates
SIGCOMM ’21, August 23–28, 2021, Virtual Event, USA
Random permutations
Snowcap (hard spec. only)
Snowcap
s
e
t
a
t
s
d
e
r
o
l
p
x
E
1010