of passwords is similar to other leaks. The data set contains
a number of passwords that may be objectionable to some
people (e.g., many popular passwords are based on profanities
from a wide number of languages). Instead of removing these
passwords, which would bias the study, we used the MTurk
mechanism of indicating that there may be vulgar content
in the HITs. This restricts the HITs to be used only by
adult workers as well as providing a warning to them about
the potential for objectionable content. We also removed all
passwords of length greater than 25, as these are (by manual
inspection) not user-selected passwords.
Amazon allows the HIT creator to specify the required
qualiﬁcation and location of the worker. We allowed workers
with more than 10% acceptance rate2 and that were located in
countries whose ofﬁcial language is English.
None of the data we recorded contains personally identi-
fying information. We nevertheless submitted our experiment
designs to our institutional review board and received an IRB
exemption.
A. Measured Typo Rates
We sampled 100,000 passwords randomly with replacement
according to the empirical probability distribution of RockYou
passwords of length 6 or more. (The length requirement
matches the Dropbox policy for passwords, as discussed in
the next section.) By sampling with replacement, this means
we match the expected distribution of submitted passwords a
web service might see across their entire user base (e.g., the
password “123456” appears frequently). We split the sample
into HITs, ensuring that none of the HITs contain more
than 180 characters in total. (This approximately normalizes
2Acceptance rate in MTurk paradigm means the percentage of HITs, that
the worker has submitted, have been accepted by the requester of the work.
This is an eligibility ﬁlter provided by MTurk.
the amount of typing effort of a single HIT.) Each MTurk
worker is given 300 seconds to type all the passwords in the
HIT. The number of passwords in a HIT ranges between 16
to 22. To ensure a broad pool of users, a worker is only
allowed to submit a maximum of 3 HITs. To impose this
restriction, we used a third-party JavaScript function provided
by a website called Unique Turker [5]. In addition to the
submitted passwords, we collected the user agent string of
the browser from which the worker submitted the job, and all
the key presses (and their timestamps) inside the input boxes
within the HIT.
A total of 4,362 workers participated in our study. Several
passwords were not typed at all (e.g., the worker accidentally
submitted the HIT before typing all the passwords), and some-
times the wrong password was entered (e.g., when prompted
“123456” the user entered “password”).
Sanitization. We sanitize the received data ﬁrst, by removing
the submissions where either no password was typed or typed
passwords have a case-independent edit distance of ﬁve or
more from the prompted password. This excluded 226 of
the password samples. Here and throughout this section edit
distance includes insertions, deletions, and substitutions each
as unit cost.
Preliminary analysis of the remaining data revealed that a
large fraction of errors were caused by accidental pressing
of the caps-lock key. Looking at the data, it was clear that
in many cases workers had caps lock on for a large number
of contiguous entries. We therefore sanitized our data with a
heuristic to ﬁgure out improper propagation of caps-lock errors
across multiple entries. The details are given in Appendix B.
After sanitization, there were in total 4,364 incorrect sub-
missions across 97,632 valid submissions (4.5%). There were
81,595 unique passwords among the sanitized submissions,
and 5.5% of all unique passwords were mistyped at least once.
Because we instrumented all key presses, we could see when
users corrected entries before submission. An additional 8.2%
of submissions were ﬁrst incorrectly typed by the workers, but
corrected before submission. In total, we found that 42% of the
workers made at least one typo across all their submissions,
while 1.6% submitted more than four mistyped passwords in
their submissions.
From now on our analyses are based on the submitted
passwords unless otherwise speciﬁed. We include duplicate
passwords in our analyses because they reﬂect the distribution
of passwords a provider would see.
The data resulting from the MTurk measurements suggest
that there is some correlation between typo likelihood and
password complexity under various measures such as length
and lexical diversity. As this is not our main focus we defer
discussion to Appendix C.
B. The Nature of Typos
We now analyze the nature of typos made by the MTurk
workers. First, we look at typos based on the edit distance
between the mistyped password and the correct password.
802802
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:18:05 UTC from IEEE Xplore.  Restrictions apply. 
For 86% of incorrectly typed passwords, if we normalize the
cases of alphabetic characters, the edit distance between the
submission and the correct password was one. This suggests
most password typos are relatively simple.
To obtain better clarity on the kinds of typos made, we
analyze typographical errors on a representation of strings that
accounts for the keys that must be pressed while entering it.
This allows us in particular to highlight the role of capitaliza-
tion errors due to shift and caps-lock mistakes during password
entry.
The key-press representation of a string is deﬁned as fol-
lows. First, recall that our standard alphabet includes upper-
and lower-case letters, numbers, symbols, and the space char-
acter. We deﬁne a key-press alphabet that includes only the
keys on a standard US keyboard: lower-case letters, numbers,
symbols that can be entered without shift (such as the period),
the caps-lock key denoted by (cid:2)c(cid:3), and either shift key repre-
sented by (cid:2)s(cid:3). Then, we convert each password and submitted
string from the MTurk study to a key-press string by replacing
characters omitted from the key-press alphabet by appropriate
combinations of (cid:2)s(cid:3) or (cid:2)c(cid:3) tokens and tokens for keys in the
key-press alphabet. We heuristically assume any sequence of
3 or more capital letters was entered using caps lock and
singleton or doubles using a shift key. So for example, the
string “Password” would be converted to the string “(cid:2)s(cid:3)-p-a-
s-s-w-o-r-d” over our new alphabet, and likewise “ABC12!@”
would be converted to “(cid:2)c(cid:3)-a-b-c-(cid:2)c(cid:3)-1-2-3-(cid:2)s(cid:3)-1-(cid:2)s(cid:3)-2”. As
seen in this last example, in our conversion we insert a (cid:2)s(cid:3)
token for each character modiﬁed by it (despite the fact that
the user may hold it down for the duration).
To gain insight into what kinds of typos the workers made,
we constructed a confusion matrix in which rows represent the
true keys that should have been pressed, and columns represent
the keys that were actually pressed. We ﬁlled this matrix
in the following way. For each pair of prompted password
and submitted string, we ﬁnd an optimal alignment of the
corresponding key presses that minimizes the total cost of
the edit operations. We can extract an optimal alignment in
the process of computing the minimum edit distance using a
dynamic programming algorithm approach proposed in [40].
We then counted the frequency of c → c(cid:2) pairs, where c is the
key in the given password and c(cid:2) is the key which is typed.
We allowed c to take on a placeholder value [ins] signifying
when c(cid:2) was inserted into a password, and c(cid:2) to take on a
placeholder value [del] to denote that c was deleted from a
password. We omitted the case c = c(cid:2) from our tabulation, as
it represents no typographical error.
For example, consider if the prompted password was the
string “Password”, (or “(cid:2)s(cid:3)-p-a-s-s-w-o-r-d” in key-press rep-
resentation) and the study participant submitted the string
“passw0rd1” (or “p-a-s-s-w-0-r-d-1” in key-press representa-
tion). Our algorithm would increment the counts for (cid:2)s(cid:3) →
[del], o → 0, and [ins] → 1. The corresponding typos are:
forgetting (cid:2)s(cid:3) to capitalize the ﬁrst letter, changing an ‘o’ to
‘0’, and adding a (spurious) ‘1’ at the end.
Keyboard 
  proximity
    errors
Deletion of
characters
Transcription 
errors
Insertion errors
Insertion/ 
deletion
of caps lock 
and shift keys
Fig. 1: Heatmap showing the counts of edits that arose
in computing edit distance from the key-press sequence of
the submitted passwords to the key-press sequence of the
prompted passwords. The color in row c and column c(cid:2)
indicates how often the edit c → c(cid:2) was observed across
all distance calculations. The darker the color the higher
the count. Labels [ins] and [del] denote insertion (character
mistakenly inserted) and deletion (failure to type a character).
, (cid:2)s(cid:3), and (cid:2)c(cid:3) respectively denote the and space-bar,
Tokens
shift, and caps lock.
passwords is shown as a heatmap in Figure 1. Darker colors
signify higher counts. The keys are sorted according to a
standard US keyboard layout.
Several common typographical errors stand out:
• Insertion and deletion of shift and caps-lock keys: In the
right bottom corner appears a dark patch of 3×3 squares.
This reﬂects the frequency of erroneous use or lack of use
of shift and caps lock—equivalently, incorrect insertion
or deletion of the (cid:2)s(cid:3) and (cid:2)c(cid:3) tokens. These typos will
switch the case of the password if it contains English
letters as well as changing the shift status of digits and
symbols (e.g., 4 → $).
• Keyboard proximity errors: The slightly darker cells near
the diagonal represent typos due to mistakenly pressing
a neighboring key to the left or right of the intended
key. We found more generally that there are a signiﬁcant
number of typos for which a key is replaced by an
adjacent one (left, right, above, or below). We collectively
refer to these as proximity errors.
• Number-to-number errors: We see a square cluster of
moderately high-frequency errors in the top left
that
represent digit-to-digit typos. Some of these are proximity
The histogram resulting from doing this for all submitted
803803
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:18:05 UTC from IEEE Xplore.  Restrictions apply. 
•
errors, but many such errors confuse widely separated
numbers, e.g., 3 → 9.
Insertions and deletions: There are throughout a large
number of insertion (third row from the bottom) and
deletion (third column from the right) errors. Deletions
are slightly more common.
• Transcription errors: The heatmap has sporadic dark
cells,
including (l,1), (o,0), (0,o), (l,i). These represent
transcription errors due to a worker confusing similar-
looking characters. We presume that the prevalence of
reading errors are an artifact of the experiment design,
and will be less frequent for entry of memorized pass-
words. Nevertheless, such errors could arise for users that
write down their passwords to remember them.
Our analysis suggests that a large fraction of common typos
fall into a few classes. A subset of these are what we refer to
as “easily correctable,” as we discuss shortly.
C. Touchscreen Keyboards
We performed a smaller, but similar, study in which workers
were required to use touchscreen keyboards. The hypothesis
here is that
the distribution of typos may differ due to
keyboard type. We submitted 24,000 passwords drawn from
RockYou across 1,987 HITs using the same methodology of
approximately normalizing effort by restricting total character
counts to be less than 110. Workers were given 300 seconds
to perform a HIT. We restricted workers to using touch-
screen keyboards by checking the user-agent string of the
worker’s browser.
Unlike the desktop user experiment earlier in this section,
we did not need to adjust for the caps lock propagation error on
touchscreen devices. This was because of the fact that in touch
screen devices the caps lock key is auto reset every time the
focus shifts from one input ﬁeld to the other. We performed an
analysis that was otherwise similar to the analysis used above
for the general MTurk experiment. To calculate proximity
errors, we used the Android keyboard layout, which we believe
is a sufﬁciently good proxy for all touch screen keyboards.
The probability of a typo here was 9.0%, an increase over
the 4.5% for unrestricted workers. We compare the types of
typos across the two data sets quantitatively below.
D. Easily-Correctable Typo Classes and Correctors
Using all the data above we manually enumerate a set
of common typo types, or classes. The resulting classes are
detailed in Figure 2, and shown for both the ﬁrst general
MTurk experiment and the touchscreen-restricted experiment.
The column labeled “Corrector” identiﬁes the function that can
be used to correct the corresponding typos: swc-all switches
the case of all letters in a password, swc-ﬁrst switches the
case of the ﬁrst letter, rm-last removes the last character,
rm-ﬁrst removes the ﬁrst character, and n2s-last changes the
last character to its equivalent character under the shift-key
modiﬁer (e.g., ‘1’ becomes ‘!’, ‘a’ becomes ‘A’, etc.). The
correctors mentioned above are mutually exclusive, that is,
Typo type
Case of all letters ﬂipped
Case of ﬁrst letter ﬂipped
Added extra character to end
Added extra character to front
Missed shift for symbol at end
Proximity errors
Transcription errors
Other errors
Corrector % of typos
Any Mobile
8.3
10.9
4.7
4.5
4.6
0.9
0.5
1.3
0.1
0.2
29.6
21.8
3.3
3.0
53.6
52.7
swc-all
swc-ﬁrst
rm-last
rm-ﬁrst
n2s-last
n/a
n/a
n/a
Fig. 2: The top categories of typos observed in our MTurk
experiments. The “Corrector” column identiﬁes an (easily
applied) function that corrects the typo. The “Any” column
is percentage of typos by category for the initial MTurk
study in which workers could have used any browser. Of
97,632 passwords drawn from RockYou, 4,364 were mistyped.
The “Mobile” column is the same for the 23,098 submitted
passwords collected from devices with mobile browsers. Of
these, 2,075 had a typo.
any two correctors, when applied to an input password of
length larger than one, will produce two different passwords
(assuming at least one of the correctors is applicable).
As can be seen, the distribution of typos is non-uniform. A
few typo classes account for a large proportion of mistakes
made. Caps-lock errors alone represent 9.2% of all mistakes
made in our general MTurk experiments, and proximity errors
for another 21.8% of all mistakes. For mobile, we see a
proportionally larger number of keyboard proximity typos.
If a class of typo has a uniquely determined associated
corrector, we refer to it as easily correctable. The typo that
produces a ﬂipped case in the ﬁrst letter is an example: The
corresponding corrector just ﬂips the case of the ﬁrst letter.
Not all easily correctable typos have involutory correctors (the
typo and corrector are the same function): consider the case of
adding a character to the end of a password which is corrected
by removing a character.
In contrast to easily correctable typos, a proximity error is
hard to correct. Given a password with a proximity error, cor-
rection would require identiﬁcation of the erroneous character
as well as identiﬁcation of the nearby character that was the
original, true one. Thus the space of possible correctors for a
proximity error is generally large. As we shall see later, both
security and performance are adversely impacted by searching
large spaces of correctors.
Our exploration culminates in the following two key results:
(1) Some typos are signiﬁcantly more common than others and
(2) Many common typos are easily correctable. In the next
section, we report on experiments at Dropbox that verify that
common, easily correctable typos arise frequently in practice.
IV. EXPERIMENTS AT DROPBOX
Our Mechanical Turk experiments in the last section show
that there exists a small set of frequently observed typos. Those
experiments, which asked users to type in passwords provided
804804
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:18:05 UTC from IEEE Xplore.  Restrictions apply. 
to them, may not simulate the kinds of typos users make when
using their own passwords. We therefore turn to investigating
typos in the production password authentication environment
used at Dropbox. We will also assess the impact of typos on
user experience. We emphasize that our experiments here did
not change the effective login checks at Dropbox, but only
recorded information about the frequency of typos.
The Dropbox authentication system. Dropbox is a ﬁle
hosting service for consumers and enterprises with hundreds
of millions of users. Each user must select a password during
registration. Dropbox uses zxcvbn [44], a password strength
estimator, to guide the user in choosing a strong password.
The system requires that users choose a password of at least
six characters, but it does not explicitly forbid users from
choosing passwords that are considered to be weak by zx-
cvbn. Passwords are submitted over a standard HTTPS POST
interface when logging in via the website or from within one
of the native Dropbox applications. We call the submission of
a password by a user a password submission. If the password
is accepted by the Dropbox server, we call it a successful
password submission, otherwise it is called a failed password
submission. On a failed password submission, the user may
resubmit his/her password. A login attempt is a sequence of
password submissions by a user that either culminates in a
successful login, in which case the login attempt is considered
successful, or accumulates login failures until the study ends.
If the user does not succeed in logging in during the scope of
our study, we consider her sequence of password submissions
to be a failed login attempt.
Dropbox, like most modern web companies, uses a number
of fraud detection mechanisms in order to ﬁlter out spurious
login attempts even before checking the password. An example
of such fraud detection mechanisms is to refuse login attempts
from IP addresses that appear on a blacklist for known bots.