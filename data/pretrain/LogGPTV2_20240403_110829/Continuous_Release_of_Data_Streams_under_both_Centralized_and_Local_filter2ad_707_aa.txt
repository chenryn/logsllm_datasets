title:Continuous Release of Data Streams under both Centralized and Local
Differential Privacy
author:Tianhao Wang and
Joann Qiongna Chen and
Zhikun Zhang and
Dong Su and
Yueqiang Cheng and
Zhou Li and
Ninghui Li and
Somesh Jha
Continuous Release of Data Streams under both Centralized
and Local Differential Privacy
Joann Qiongna Chen
University of California,
Zhikun Zhang
CISPA
Dong Su
Alibaba Inc.
Tianhao Wang∗
Carnegie Mellon University
& University of Virginia
Yueqiang Cheng
NIO Security Research
Irvine
Zhou Li
Irvine
University of California,
Ninghui Li
Purdue University
Somesh Jha
University of Wisconsin,
Madison
ABSTRACT
We study the problem of publishing a stream of real-valued data
satisfying differential privacy (DP). One major challenge is that the
maximal possible value in the stream can be quite large, leading to
enormous DP noise and bad utility. To reduce the maximal value
and noise, one way is to estimate a threshold so that values above it
can be truncated. The intuition is that, in many scenarios, only a few
values are large; thus truncation does not change the original data
much. We develop such a method that finds a suitable threshold with
DP. Given the threshold, we then propose an online hierarchical
method and several post-processing techniques.
Building on these ideas, we formalize the steps in a framework for
the private publishing of streaming data. Our framework consists
of three components: a threshold optimizer that privately estimates
the threshold, a perturber that adds calibrated noise to the stream,
and a smoother that improves the result using post-processing.
Within our framework, we also design an algorithm satisfying the
more stringent DP setting called local DP. Using four real-world
datasets, we demonstrate that our mechanism outperforms the
state-of-the-art by a factor of 6−10 orders of magnitude in terms of
utility (measured by the mean squared error of the typical scenario
of answering a random range query).
CCS CONCEPTS
• Information systems → Data streams; • Security and pri-
vacy → Privacy-preserving protocols.
KEYWORDS
Differential Privacy; Local Differential Privacy; Continuous Obser-
vation; Data Stream
ACM Reference Format:
Tianhao Wang, Joann Qiongna Chen, Zhikun Zhang, Dong Su, Yueqiang
Cheng, Zhou Li, Ninghui Li, and Somesh Jha. 2021. Continuous Release
∗Tianhao did most of the work while at Purdue University.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea.
© 2021 Association for Computing Machinery.
ACM ISBN 978-1-4503-8454-4/21/11...$15.00
https://doi.org/10.1145/3460120.3484750
of Data Streams under both Centralized and Local Differential Privacy. In
Proceedings of the 2021 ACM SIGSAC Conference on Computer and Commu-
nications Security (CCS ’21), November 15–19, 2021, Virtual Event, Republic of
Korea. ACM, New York, NY, USA, 17 pages. https://doi.org/10.1145/3460120.
3484750
1 INTRODUCTION
Continuous observation over data streams has been utilized in
several real-world applications. For example, security companies
continuously analyze network traffic to detect abnormal Internet be-
haviors [9]. However, analyzing and releasing streams raise privacy
concerns when these data contain sensitive individual information.
Directly publishing raw statistics may reveal individual users’ pri-
vate information. For instance, electricity usage data from smart
meters can reveal whether a user is at home or even what household
appliances are used at some specific time [34].
A promising technique for releasing private statistics is differen-
tial privacy (DP) [17], which has become the gold standard in the
privacy-research community. Informally, any algorithm satisfying
DP has the property that its output distribution on a given database
is close to the output distribution on a similar dataset where any
single record is replaced. The closeness is quantified by a parameter
ϵ, where a smaller ϵ offers a better privacy guarantee.
To publish streams with DP, a widely accepted approach is to
use the hierarchical structure [8, 18]. The idea is to partition the
time series into multiple granularities and then add noise to the
stream to satisfy DP. Because of the additive noise, it is impossible
to accurately publish any single value in the stream. Thus our goal
is to accurately estimate the sum of values over any range of time. One
challenge is that to satisfy DP, the magnitude of the noise should
be proportional to the upper bound of the data, which is typically
large. Perrier et al. [36] (termed PAK in this paper) observed that
data in the stream is often concentrated below a value much smaller
than the upper bound. To exploit this insight, a technique called
contribution limitation is commonly-used [13, 30, 32, 50, 54]. It
truncates the data using a specified threshold θ (i.e., values larger
than θ are replaced by θ). The rationale is to reduce the noise (now
the noise is proportional only to θ) while preserving utility. To find
such a threshold while maintaining DP, PAK developed a method
based on smooth sensitivity [35]. The result can then be applied to
the hierarchical algorithm to publish streams with improved utility.
We find three key limitations in existing work of PAK’s. First, it
tries to privately find the 99.5-th percentile to serve as the threshold
θ. Unfortunately, using the 99.5-th percentile (or any other fixed
percentile) is unlikely to work across all settings of ϵ values and
Session 4D: Differential Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1237data distributions. Second, in order to get an analytical upper bound
of the error caused by truncation (this error is also called bias), the
authors further increase the estimated 99.5-th percentile by first
adding a positive term, and then multiplying a coefficient greater
than 1. As a result, the chosen θ is often unnecessarily large. When
ϵ is small (e.g., ϵ ≤ 0.1), the value of θ is usually larger than the
maximal possible value, running against the original purpose of
choosing the threshold. Third, the method directly utilizes a basic
hierarchical approach to output the stream, and does not fully take
advantage of post-processing optimizations. As a consequence, the
accuracy of the output is far from ideal, and the results are worse
when answering range queries with small selectivity.
In this paper, we propose a new approach by addressing the
above-mentioned three limitations. Instead of using a fixed per-
centile, we design a data-dependent method to find the threshold θ
that considers the overall data distribution. Our goal is to minimize
the overall error due to bias and DP noise simultaneously. Given
θ, we then propose a new hierarchical algorithm to obtain accu-
rate results. One major contribution is a novel online algorithm
to enforce consistency over the noisy estimates (i.e., to make sure
the number on any node equal the sum of its children’s, which is
violated if independently sampled noise is added to the hierarchy)
on the hierarchy to provide better utility. While there exists consis-
tency methods that work on the noisy hierarchies, our observation
is that we can pre-compute all the noise, and then make the noise
consistent first. As the true values are naturally consistent, we can
then add the consistent noise to the true values in an online manner
and thus achieve an online consistency algorithm. We prove the
algorithm achieves minimum squared error and also satisfies DP.
Another contribution is that we further extend the algorithm to
prune the lower-level nodes based on an optimization criterion,
based on the observation that the estimates in the lower levels of
the hierarchy tend to be overwhelmed by the noise, leading to a
low signal-noise ratio. Our new hierarchical algorithm is also able
to handle infinite streams.
Next, we generalize the above-mentioned algorithms into a new
framework for streaming data publication. It consists of three com-
ponents: a Threshold optimizer, a Perturber, and a Smoother. The
threshold optimizer consumes a portion of the input stream, and
finds a threshold θ. It then truncates all incoming values by θ and
sends them to the perturber. The perturber adds noise to each in-
coming element of the stream, and releases noisy counts to the
smoother. Finally, the smoother performs further post-processing
on the noisy counts and outputs the final stream. Together with
the new algorithms described above, we call our solution ToPS.
Finally, based on the framework of ToPS, we design an algo-
rithm to output streams while satisfying local DP (LDP), which
protects privacy under a stronger adversary model than DP. We
call the resulting method ToPL. Under LDP, only the users know
the true values and thus removes the dependence on the trusted
central server. In ToPL, we use state-of-the-art LDP mechanisms
for the Threshold optimizer and the Perturber. While the design
of ToPL relies on the findings in ToPS, we also adapt existing LDP
mechanisms to our setting to get better performance.
We implemented both ToPS and ToPL, and evaluated them using
four real-world datasets, including anonymized DNS queries, taxi
trip records, click streams, and merchant transactions. We use the
Mean Squared Error (MSE) over random range queries as the metric
of performance evaluation. The experimental results demonstrate
that our ToPS significantly outperforms the previous state-of-the-
art algorithms. More specifically, the most significant improvement
comes from our new technique to finding θ. It contributes an im-
provement of 4 − 8 orders of magnitude over PAK. Even given
the same reasonable θ, ToPS can answer range queries 100× more
accurately than PAK. Putting the two together, ToPS improves over
PAK by 6 − 10 orders of magnitude in terms of MSE.
Contributions. To summarize, the main contributions of this
paper are threefold:
• We design ToPS for releasing real-time data streams under differ-
ential privacy. Its contributions include an EM-based algorithm
to find the threshold, an online consistency algorithm, the use of
a smoother to reduce the noise, and the ability to handle infinite
streams.
• We extend ToPS to solve the problem in the more stringent setting
• We evaluate ToPS and ToPL using several real-world datasets.
The experimental results indicate that both can output streams
accurately in their settings. Moreover, ToPS outperforms the
previous state-of-the-art algorithms by a factor of 6 − 10 orders.
Our code is open sourced at https://github.com/dp-cont/dp-cont.
Roadmap. In Section 2, we present the problem definition and
the background of DP and LDP. We present the existing solutions
and our proposed method in Section 3 and 4. Experimental results
are presented in Section 5. Finally, we discuss related work in Sec-
tion Section 6 and provide concluding remarks in Section Section 7.
of LDP and propose a new algorithm called ToPL.
2 PROBLEM DEFINITION AND
PRELIMINARIES
We consider the setting of publishing a stream of real values un-
der differential privacy (DP). The length of the stream could be
unbounded. Due to the constraint of DP, it is unrealistic to make
sure every single reading of the stream is accurate, so the goal is to
ensure the aggregated estimates are accurate.
2.1 Formal Problem Definition
There is a sequence of readings V = ⟨v1, v2, . . .⟩, each being a real
number in the range of [0, B]. We publish a private sequence ˜V of
the same size as V while satisfying DP, with the goal of accurately
answering range queries. Range query is an important tool for
understanding the overall trend of the stream. Specifically, a range
query V(i, j) is defined as the sum of the stream from index i to j,
k =i vk. We want a mechanism that achieves a low
expected squared error of any randomly sampled range queries,
i.e.,
i.e., V(i, j) =j
(cid:20)(cid:16) ˜V(i, j) − V(i, j)(cid:17)2(cid:21)
E
.
(1)
2.2 Differential Privacy
We follow the setting of PAK [36] and adopt the notion of event-level
DP [18], which protects the privacy of any value in the stream.
Session 4D: Differential Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1238Definition 2.1. (Event-level (ϵ, δ)-DP) An algorithm A(·) satisfies
(ϵ, δ)-differential privacy ((ϵ, δ)-DP), if and only if for any two
neighboring sequences V and V ′ and for any possible output set O,
Pr[A(V) ∈ O] ≤ eϵ Pr(cid:2)A(V
′) ∈ O(cid:3) + δ,
where two sequences V = ⟨v1, v2, . . .⟩ and V ′ = ⟨v′
neighbors, denoted by V ≃ V ′, when vi = v′
index.
2, . . .⟩ are
for all i except one
1, v′
i
For brevity, we use (ϵ, δ)-DP to denote Definition 2.1. When
δ = 0, which is the case we consider in this paper, we omit the δ
part and write ϵ-DP instead of (ϵ, 0)-DP.
Justification of Event-Level DP. Although event-level DP only
protects one value, it is a suitable guarantee in many cases. For
example, individuals might be happy to disclose their routine trip to
work while unwilling to share the occasional detour. Note that the
data model is general and V can also come from multiple users. For
example, V consists of the customers’ expenditure from a grocery
store, and we want to protect some unusual transaction. Moreover,
our model is a generalization of the basic model where every value
is binary [8, 21], and can be used in building private algorithms
with trusted hardware [7].
Extension to Event-Level LDP. We also work in the local ver-
sion of DP [28]. Compared to the centralized setting, local DP offers
a stronger trust model, because each value is reported to the server
in a perturbed form. Privacy is protected even if the server is mali-
cious. For each value v in the stream of V , we have the following
guarantee:
Definition 2.2 ((ϵ, δ)-LDP). An algorithm A(·) satisfies (ϵ, δ)-local
differential privacy ((ϵ, δ)-LDP), if and only if for any pair of input
values v, v′, and any set O of possible outputs of A, we have
Pr[A(v) ∈ O] ≤ eϵ Pr(cid:2)A(v
′) ∈ O(cid:3) + δ .
Typically, δ = 0 in LDP [33, 41, 45, 49] (one reason is that many
LDP protocols are built on randomized response [49], which ensures
δ = 0). Thus we simplify the notation and call it ϵ-LDP. The notion
of LDP differs from DP in that each user perturbs the data before
sending it out and thus do not need to trust the server under LDP.
2.3 Mechanisms of Differential Privacy
We first review primitives proposed for satisfying DP. We defer the
descriptions of LDP primitives to Appendix E as our LDP method
mostly uses the LDP primitives as blackboxes.
Laplace Mechanism. The Laplace mechanism computes a func-
tion f on the input V in a differentially private way, by adding to