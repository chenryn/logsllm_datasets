### Detecting Malicious Accounts: Challenges and Solutions

#### Introduction
Detecting malicious accounts in social networks is a critical task, but it often requires a large number of labeled accounts to train the detection model. This process incurs significant delays and high labor costs. Muses, an unsupervised approach, addresses these challenges by not requiring labeled datasets.

#### Structure-Based Methods
Structure-based methods [1, 3–5, 7, 9, 10, 12–14, 16] detect malicious accounts by analyzing the social graph structure. The underlying assumption is that benign users mix quickly with each other, while malicious users struggle to establish relationships with benign ones. Consequently, benign accounts tend to cluster in sub-graphs, while malicious accounts are scattered. However, according to a recent study [35], malicious users (e.g., growing-up accounts) can develop sophisticated strategies to gain trust from benign users, thereby establishing more connections. As a result, these methods are less effective in detecting such growing-up accounts. Muses, on the other hand, can capture these subtle differences between growing-up and benign accounts based on common features used in most online social networks (OSNs).

#### Similarity-Based Methods
Similarity-based methods [6, 29] measure the similarities between accounts based on their behaviors. Since malicious accounts are often controlled by a group of malicious users or scripts, they share similar behavior patterns. These methods process account behaviors as time sequences for detection. For example, Clickstream [29] divides the sequences into grams and measures the similarity between accounts as the proportion of their common grams. SynchroTrap [6] aligns the time sequences of two accounts and measures the proportion of common events as their similarities. These methods use similarities to build an account-account graph and perform community detection. However, they fail to detect growing-up accounts that behave similarly to benign accounts and have a limited number of behaviors.

#### Conclusion
In this work, we present the first systematic study of the growing-up behaviors of malicious accounts based on a real-world dataset. Although growing-up accounts may not participate in malicious campaigns immediately after registration, they pose a chronic threat to privacy-centric mobile social networks (PC-MSNs) as they build large social spheres over time. To effectively detect growing-up accounts, we propose Muses, a novel unsupervised method that automatically extracts subtle yet effective behaviors of growing-up accounts and detects them via a graph-based clustering algorithm. We validate our design using anonymized datasets from WeChat. Experimental results show that Muses detects more than 82% of growing-up accounts with a precision higher than 90%, achieving a 2x recall rate and even better precision compared to existing methods. Moreover, we evaluate the detection performance of Muses under various possible evasion strategies and demonstrate its robustness against evasion attacks.

#### Acknowledgments
This work is supported in part by NSFC under Grant 62132011 and BNRist under Grant BNR2020RC01013. Qi Li is the corresponding author of this paper.

#### References
[1] Lorenzo Alvisi, Allen Clement, Alessandro Epasto, Silvio Lattanzi, and Alessandro Panconesi. 2013. Sok: The evolution of sybil defense via social networks. In IEEE S&P.
[2] Vincent D Blondel, Jean-Loup Guillaume, Renaud Lambiotte, and Etienne Lefebvre. 2008. Fast unfolding of communities in large networks. Journal of statistical mechanics: theory and experiment (2008).
[3] Yazan Boshmaf, Dionysios Logothetis, Georgos Siganos, Jorge Lería, Jose Lorenzo, Matei Ripeanu, and Konstantin Beznosov. 2015. Integro: Leveraging Victim Prediction for Robust Fake Account Detection in OSNs. In NDSS.
[4] Zhuhua Cai and Christopher Jermaine. 2012. The latent community model for detecting sybil attacks in social networks. In NDSS.
[5] Qiang Cao, Michael Sirivianos, Xiaowei Yang, and Tiago Pregueiro. 2012. Aiding the detection of fake accounts in large scale social online services. In NSDI.
[6] Qiang Cao, Xiaowei Yang, Jieqi Yu, and Christopher Palow. 2014. Uncovering large groups of active malicious accounts in online social networks. In ACM CCS.
[7] George Danezis and Prateek Mittal. 2009. Sybilinfer: Detecting sybil nodes using social networks. In NDSS.
[8] Manuel Egele, Gianluca Stringhini, Christopher Kruegel, and Giovanni Vigna. 2015. Towards detecting compromised accounts on social networks. IEEE TDSC (2015).
[9] David Freeman, Sakshi Jain, Markus Dürmuth, Battista Biggio, and Giorgio Giacinto. 2016. Who Are You? A Statistical Approach to Measuring User Authenticity. In NDSS.
[10] Hao Fu, Xing Xie, Yong Rui, Neil Zhenqiang Gong, Guangzhong Sun, and Enhong Chen. 2017. Robust spammer detection in microblogs: Leveraging user carefulness. ACM Transactions on Intelligent Systems and Technology (TIST) 8, 6 (2017).
[11] Hongyu Gao, Jun Hu, Christo Wilson, Zhichun Li, Yan Chen, and Ben Y Zhao. 2010. Detecting and characterizing social spam campaigns. In ACM SIGCOMM.
[12] Peng Gao, Binghui Wang, Neil Zhenqiang Gong, Sanjeev R Kulkarni, Kurt Thomas, and Prateek Mittal. 2018. Sybilfuse: Combining local attributes with global structure to perform robust sybil detection. In IEEE CNS.
[13] Neil Zhenqiang Gong, Mario Frank, and Prateek Mittal. 2014. Sybilbelief: A semi-supervised learning approach for structure-based sybil detection. IEEE TIFS (2014).
[14] Jinyuan Jia, Binghui Wang, and Neil Zhenqiang Gong. 2017. Random walk based fake account detection in online social networks. In IEEE DSN.
[15] Anna Leontjeva, Moises Goldszmidt, Yinglian Xie, Fang Yu, and Martín Abadi. 2013. Early security classification of skype users via machine learning. In ACM AIsec.
[16] Changchang Liu, Peng Gao, Matthew Wright, and Prateek Mittal. 2015. Exploiting temporal dynamics in sybil defenses. In ACM CCS.
[17] Abedelaziz Mohaisen, Nicholas Hopper, and Yongdae Kim. 2011. Keep your friends close: Incorporating trust into social network-based sybil defenses. In IEEE INFOCOM.
[18] Jia-Yu Pan, Hyung-Jeong Yang, Christos Faloutsos, and Pinar Duygulu. 2004. Automatic multimedia cross-modal correlation discovery. In ACM SIGKDD.
[19] Jonghyuk Song, Sangho Lee, and Jong Kim. 2011. Spam filtering in twitter using sender-receiver relationship. In RAID. Springer.
[20] Gianluca Stringhini, Christopher Kruegel, and Giovanni Vigna. 2010. Detecting spammers on social networks. In ACSAC.
[21] Gianluca Stringhini, Pierre Mourlanne, Gregoire Jacob, Manuel Egele, Christopher Kruegel, and Giovanni Vigna. 2015. EVILCOHORT: Detecting Communities of Malicious Accounts on Online Services. In USENIX Security.
[22] Kurt Thomas, Frank Li, Chris Grier, and Vern Paxson. 2014. Consequences of connectivity: Characterizing account hijacking on twitter. In ACM CCS.
[23] Bimal Viswanath, Ansley Post, Krishna P Gummadi, and Alan Mislove. 2010. An analysis of social network-based sybil defenses. In ACM SIGCOMM. ACM.
[24] Alex Hai Wang. 2010. Don’t follow me: Spam detection in twitter. In SECRYPT.
[25] Binghui Wang, Neil Zhenqiang Gong, and Hao Fu. 2017. GANG: Detecting fraudulent users in online social networks via guilt-by-association on directed graphs. In IEEE ICDM.
[26] Binghui Wang, Jinyuan Jia, and Neil Zhenqiang Gong. 2019. Graph-based security and privacy analytics via collective classification with joint weight learning and propagation. In NDSS.
[27] Binghui Wang, Jinyuan Jia, and Neil Zhenqiang Gong. 2021. Semi-Supervised Node Classification on Graphs: Markov Random Fields vs. Graph Neural Networks. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 35. 10093–10101.
[28] Binghui Wang, Le Zhang, and Neil Zhenqiang Gong. 2017. SybilSCAR: Sybil detection in online social networks via local rule based propagation. In IEEE INFOCOM.
[29] Gang Wang, Tristan Konolige, Christo Wilson, Xiao Wang, Haitao Zheng, and Ben Y Zhao. 2013. You are how you click: Clickstream analysis for sybil detection. In USENIX Security.
[30] Zenghua Xia, Chang Liu, Neil Zhenqiang Gong, Qi Li, Yong Cui, and Dawn Song. 2019. Characterizing and Detecting Malicious Accounts in Privacy-Centric Mobile Social Networks: A Case Study. In ACM SIGKDD.
[31] Yinglian Xie, Fang Yu, Qifa Ke, Martin Abadi, Eliot Gillum, Krish Vitaldevaria, Jason Walter, Junxian Huang, and Zhuoqing Morley Mao. 2012. Innocent by association: early recognition of legitimate users. In ACM CCS.
[32] Jilong Xue, Zhi Yang, Xiaoyong Yang, Xiao Wang, Lijiang Chen, and Yafei Dai. 2013. Votetrust: Leveraging friend invitation graph to defend against social network sybils. In IEEE INFOCOM.
[33] Chao Yang, Robert Harkreader, Jialong Zhang, Seungwon Shin, and Guofei Gu. 2012. Analyzing spammers’ social networks for fun and profit: a case study of cyber criminal ecosystem on twitter. In WWW. ACM.
[34] Chao Yang, Robert Chandler Harkreader, and Guofei Gu. 2011. Die free or live hard? empirical evaluation and new design for fighting evolving twitter spammers. In RAID. Springer.
[35] Zhi Yang, Christo Wilson, Xiao Wang, Tingting Gao, Ben Y Zhao, and Yafei Dai. 2014. Uncovering social network sybils in the wild. ACM TKDD (2014).
[36] Haifeng Yu, Phillip B Gibbons, Michael Kaminsky, and Feng Xiao. 2008. Sybillimit: A near-optimal social network defense against sybil attacks. In IEEE S & P. IEEE.
[37] Dong Yuan, Yuanli Miao, Neil Zhenqiang Gong, Zheng Yang, Qi Li, Dawn Song, Qian Wang, and Xiao Liang. 2019. Detecting Fake Accounts in Online Social Networks at the Time of Registrations. In CCS.
[38] Haizhong Zheng, Minhui Xue, Hao Lu, Shuang Hao, Haojin Zhu, Xiaohui Liang, and Keith Ross. 2018. Smoke screener or straight shooter: Detecting elite sybil attacks in user-review social networks. In NDSS.

### Evaluation of Robustness
Detecting malicious accounts is a dynamic process. As detection methods improve, malicious users will also upgrade their strategies. In this section, we discuss potential evasion strategies and demonstrate the robustness of Muses against these attacks. We consider three types of evasion strategies for each behavior: IP address, client version, and action type. Since Muses only takes account-behavior bigraphs as input, evasion strategies essentially change the structures of these bigraphs. We modify the bigraph structure to simulate the evasion process and then input these modified bigraphs into Muses to get the new behavior scores and overall scores (see Figure 9). The results show that even under combined evasion strategies, Muses remains robust, with a minimal drop in AUC value of less than 0.01.

#### A.1 IP Address
We selected 35,000 growing-up accounts clustered in one community, likely operated by the same malicious group. We identified 3,200 malicious IP addresses shared exclusively by these accounts. To evade detection, growing-up users might disperse their IP addresses. This can be achieved by either enlarging the IP pool or proxying to normal public IP addresses. The latter is more cost-effective and was simulated in our experiments. We created a list of benign IP addresses shared by most benign accounts and uniformly proxied the malicious IP addresses to these benign ones. This process involves removing edges from selected growing-up accounts to malicious IP addresses and adding edges to benign IP addresses. Figure 9a shows the distribution of malicious scores for the selected growing-up accounts. The average malicious score drops from 0.83 to 0.69 when the number of manipulated IP addresses increases from 0 to 50, still sufficient for detection. As the number of manipulated IP addresses increases, the average malicious score only slightly decreases, remaining above 0.6. Figure 9d shows the AUC of Muses under the IP address evasion attack, which drops slightly from 0 to 5,000 manipulated IP addresses, with a decrease of less than 0.005, demonstrating the robustness of Muses.

#### A.2 Client Version
Similar to the IP address evasion strategy, we selected 38,000 growing-up accounts from one community and identified 588 malicious version numbers shared by these accounts. We also compiled a list of 1,000 benign version numbers as evasion targets. We tested the detection performance of Muses after the selected accounts transferred to 1, 5, 10, 50, and 100 benign version numbers. The distribution of malicious scores and the AUC of Muses under the client version evasion attack are shown in Figures 9b and 9e, respectively. Unlike IP address evasion, version number evasion does not affect the overall performance linearly. This is because the client version does not inherently express maliciousness, and the overall score is dominated by other behaviors, leading to fluctuations due to the random walk process. The AUC drops by less than 0.01, indicating that Muses is robust against client version evasion.

#### A.3 Action Type
Evasion strategies on action behavior face more restrictions. In WeChat, there are many passive action types, such as being kicked from a chatroom, reported as malicious, or added to blacklists, which are difficult to manipulate. We selected 8 non-passive action types, such as generating QR codes for chatrooms and following official accounts, which are common among growing-up accounts. We then selected 29,000 growing-up accounts from one community to initiate evasion on action count behavior. Assuming growing-up users can modify two kinds of action types simultaneously, we randomly chose ten different combinations of action types and changed their counts to fall within intervals containing the most benign accounts. Figure 9c shows that different combinations of action types have similar effects on final malicious scores, with the range covering 0.4 to 1.0 and the average score remaining steady at around 0.7. Some evasion cases even have higher average scores than those without evasion. We also tested the scenario where growing-up users could modify all 8 action types to any count, resulting in higher average scores, indicating that Muses can extract very subtle connections between accounts. Figure 9f presents the AUC of Muses under different action type combinations, showing a drop of less than 0.002, demonstrating robustness.

#### A.4 Combined Evasion Strategies
Based on the above observations, single-behavior evasion strategies have little impact on Muses's performance. We also tested the impact of combining all three evasion strategies. Figure 10 shows the percentage of growing-up accounts with a certain malicious score. Despite the combined evasion, all growing-up accounts have scores higher than 0.5, with most having scores higher than 0.6, sufficient for detection. The AUC of Muses drops by only 0.001, confirming its robustness even under combined evasion attacks.

**Figure 10: Percentage of growing-up accounts and AUC value before and after combined evasion attack.**

| Malicious Score | Value (No Attack, AUC=0.947) | Value (Combined Attack, AUC=0.946) |
|-----------------|------------------------------|------------------------------------|
| 0.5             | 0.00                         | 0.00                               |
| 0.6             | 0.05                         | 0.05                               |
| 0.7             | 0.10                         | 0.10                               |
| 0.8             | 0.15                         | 0.15                               |
| 0.9             | 0.20                         | 0.20                               |
| 1.0             | 0.25                         | 0.25                               |

### Authors
Zijie Yang1, Binghui Wang2, Haoran Li1, Dong Yuan1, Zhuotao Liu1, Neil Zhenqiang Gong3, Chang Liu4, Qi Li1, Xiao Liang5, Shaofeng Hu5

### Event
ACSAC ’21, December 6–10, 2021, Virtual Event, USA