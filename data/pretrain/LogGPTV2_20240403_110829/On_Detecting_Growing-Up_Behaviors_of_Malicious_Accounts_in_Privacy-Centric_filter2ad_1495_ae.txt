malicious accounts, a large number of labeled accounts are required
to train the model periodically, which incur significant detection
delay and heavy labor costs. Muses is an unsupervised approach
and thus does not require labeled datasets.
Structure-based methods. Structure-based methods [1, 3–5, 7, 9,
10, 12–14, 16] detect malicious accounts by leveraging the social
graph structure. The underlying assumption is that benign users
mix quickly with each other, while malicious users can hardly es-
tablish relationships with benign users. Thus, benign accounts in a
social graph tend to cluster in sub-graphs and malicious accounts
are scattered. However, according to the existing study [35], mali-
cious users (e.g., growing-up accounts) can gain trust from benign
ones by developing sophisticated strategies so that they can estab-
lish more connections with them. Thus, these detection methods
cannot effectively detect such growing-up accounts. Muses can cap-
ture them by measuring subtle differences between growing-up
and benign accounts based on features commonly used in most
OSNs.
Similarity-based methods. Similarity-based methods [6, 29] mea-
sure the similarities between accounts based on their behaviors.
Since malicious accounts are controlled by a group of malicious
users or even scripts, they share similar behavior patterns. The
account behaviors are processed as time sequences for detection.
For example, Clickstream [29] divides the sequences into grams and
measures the similarity between accounts as the proportion of their
common grams. SynchroTrap [6] aligns the time sequences of two
accounts and measures the proportion of common events as their
similarities. These methods use similarities to build an account-
account graph and perform community detection. However, they
fail to detect growing-up accounts that behave quite similarly to
benign accounts and only have a limited number of behaviors.
8 CONCLUSION
In this work, we present the first systematic study of the growing-
up behaviors of malicious accounts based on a real-world dataset.
Although growing-up accounts may not participate in malicious
campaigns upon registration, they form a chronic threat to the
PC-MSN as they build large social spheres over time. To effectively
detect growing-up accounts, we propose Muses, a novel unsuper-
vised method to automatically extract subtle yet effective behaviors
of growing-up accounts, and then detect them via a graph-based
clustering algorithm. We validate our design using anonymized
datasets from WeChat. Experimental results show that Muses de-
tects more than 82% of growing-up accounts with a precision higher
than 90%, achieving 2x recall rate and even better precision com-
pared with existing methods. Moreover, we evaluate the detection
performance of Muses under various possible evasion strategies
and demonstrate its robustness against evasion attacks.
ACKNOWLEDGMENTS
This work is supported in part by NSFC under Grant 62132011,
BNRist under Grant BNR2020RC01013. Qi Li is the corresponding
author of this paper.
307ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Zijie Yang1, Binghui Wang2, Haoran Li1, Dong Yuan1, Zhuotao Liu1, Neil Zhenqiang Gong3
Chang Liu4, Qi Li1, Xiao Liang5, Shaofeng Hu5
[5] Qiang Cao, Michael Sirivianos, Xiaowei Yang, and Tiago Pregueiro. 2012. Aiding
[4] Zhuhua Cai and Christopher Jermaine. 2012. The latent community model for
REFERENCES
[1] Lorenzo Alvisi, Allen Clement, Alessandro Epasto, Silvio Lattanzi, and Alessandro
Panconesi. 2013. Sok: The evolution of sybil defense via social networks. In IEEE
S&P.
[2] Vincent D Blondel, Jean-Loup Guillaume, Renaud Lambiotte, and Etienne Lefeb-
vre. 2008. Fast unfolding of communities in large networks. Journal of statistical
mechanics: theory and experiment (2008).
[3] Yazan Boshmaf, Dionysios Logothetis, Georgos Siganos, Jorge Lería, Jose Lorenzo,
Matei Ripeanu, and Konstantin Beznosov. 2015.
Integro: Leveraging Victim
Prediction for Robust Fake Account Detection in OSNs. In NDSS.
detecting sybil attacks in social networks. In NDSS.
the detection of fake accounts in large scale social online services. In NSDI.
[6] Qiang Cao, Xiaowei Yang, Jieqi Yu, and Christopher Palow. 2014. Uncovering
large groups of active malicious accounts in online social networks. In ACM CCS.
[7] George Danezis and Prateek Mittal. 2009. Sybilinfer: Detecting sybil nodes using
social networks. In NDSS.
[8] Manuel Egele, Gianluca Stringhini, Christopher Kruegel, and Giovanni Vigna.
2015. Towards detecting compromised accounts on social networks. IEEE TDSC
(2015).
[9] David Freeman, Sakshi Jain, Markus Dürmuth, Battista Biggio, and Giorgio Giac-
into. 2016. Who Are You? A Statistical Approach to Measuring User Authenticity.
In NDSS.
[10] Hao Fu, Xing Xie, Yong Rui, Neil Zhenqiang Gong, Guangzhong Sun, and Enhong
Chen. 2017. Robust spammer detection in microblogs: Leveraging user carefulness.
ACM Transactions on Intelligent Systems and Technology (TIST) 8, 6 (2017).
[11] Hongyu Gao, Jun Hu, Christo Wilson, Zhichun Li, Yan Chen, and Ben Y Zhao.
2010. Detecting and characterizing social spam campaigns. In ACM SIGCOMM.
[12] Peng Gao, Binghui Wang, Neil Zhenqiang Gong, Sanjeev R Kulkarni, Kurt
Thomas, and Prateek Mittal. 2018. Sybilfuse: Combining local attributes with
global structure to perform robust sybil detection. In IEEE CNS.
[13] Neil Zhenqiang Gong, Mario Frank, and Prateek Mittal. 2014. Sybilbelief: A
semi-supervised learning approach for structure-based sybil detection. IEEE TIFS
(2014).
[14] Jinyuan Jia, Binghui Wang, and Neil Zhenqiang Gong. 2017. Random walk based
[23] Bimal Viswanath, Ansley Post, Krishna P Gummadi, and Alan Mislove. 2010. An
[20] Gianluca Stringhini, Christopher Kruegel, and Giovanni Vigna. 2010. Detecting
[19] Jonghyuk Song, Sangho Lee, and Jong Kim. 2011. Spam filtering in twitter using
[18] Jia-Yu Pan, Hyung-Jeong Yang, Christos Faloutsos, and Pinar Duygulu. 2004.
fake account detection in online social networks. In IEEE DSN.
[15] Anna Leontjeva, Moises Goldszmidt, Yinglian Xie, Fang Yu, and Martín Abadi.
2013. Early security classification of skype users via machine learning. In ACM
AIsec.
[16] Changchang Liu, Peng Gao, Matthew Wright, and Prateek Mittal. 2015. Exploiting
temporal dynamics in sybil defenses. In ACM CCS.
[17] Abedelaziz Mohaisen, Nicholas Hopper, and Yongdae Kim. 2011. Keep your
friends close: Incorporating trust into social network-based sybil defenses. In
IEEE INFOCOM.
Automatic multimedia cross-modal correlation discovery. In ACM SIGKDD.
sender-receiver relationship. In RAID. Springer.
spammers on social networks. In ACSAC.
[21] Gianluca Stringhini, Pierre Mourlanne, Gregoire Jacob, Manuel Egele, Christopher
Kruegel, and Giovanni Vigna. 2015. {EVILCOHORT}: Detecting Communities
of Malicious Accounts on Online Services. In USENIX Security.
[22] Kurt Thomas, Frank Li, Chris Grier, and Vern Paxson. 2014. Consequences of
connectivity: Characterizing account hijacking on twitter. In ACM CCS.
analysis of social network-based sybil defenses. In ACM SIGCOMM. ACM.
IEEE.
[24] Alex Hai Wang. 2010. Don’t follow me: Spam detection in twitter. In SECRYPT.
[25] Binghui Wang, Neil Zhenqiang Gong, and Hao Fu. 2017. GANG: Detecting
fraudulent users in online social networks via guilt-by-association on directed
graphs. In IEEE ICDM.
[26] Binghui Wang, Jinyuan Jia, and Neil Zhenqiang Gong. 2019. Graph-based security
and privacy analytics via collective classification with joint weight learning and
propagation. In NDSS.
[27] Binghui Wang, Jinyuan Jia, and Neil Zhenqiang Gong. 2021. Semi-Supervised
Node Classification on Graphs: Markov Random Fields vs. Graph Neural Net-
works. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 35.
10093–10101.
[28] Binghui Wang, Le Zhang, and Neil Zhenqiang Gong. 2017. SybilSCAR: Sybil
detection in online social networks via local rule based propagation. In IEEE
INFOCOM.
[29] Gang Wang, Tristan Konolige, Christo Wilson, Xiao Wang, Haitao Zheng, and
Ben Y Zhao. 2013. You are how you click: Clickstream analysis for sybil detection.
In USENIX Security.
[30] Zenghua Xia, Chang Liu, Neil Zhenqiang Gong, Qi Li, Yong Cui, and Dawn
Song. 2019. Characterizing and Detecting Malicious Accounts in Privacy-Centric
Mobile Social Networks: A Case Study. In ACM SIGKDD.
[31] Yinglian Xie, Fang Yu, Qifa Ke, Martin Abadi, Eliot Gillum, Krish Vitaldevaria,
Jason Walter, Junxian Huang, and Zhuoqing Morley Mao. 2012. Innocent by
association: early recognition of legitimate users. In ACM CCS.
[32] Jilong Xue, Zhi Yang, Xiaoyong Yang, Xiao Wang, Lijiang Chen, and Yafei Dai.
2013. Votetrust: Leveraging friend invitation graph to defend against social
network sybils. In IEEE INFOCOM.
[33] Chao Yang, Robert Harkreader, Jialong Zhang, Seungwon Shin, and Guofei Gu.
2012. Analyzing spammers’ social networks for fun and profit: a case study of
cyber criminal ecosystem on twitter. In WWW. ACM.
[34] Chao Yang, Robert Chandler Harkreader, and Guofei Gu. 2011. Die free or
live hard? empirical evaluation and new design for fighting evolving twitter
spammers. In RAID. Springer.
2014. Uncovering social network sybils in the wild. ACM TKDD (2014).
[36] Haifeng Yu, Phillip B Gibbons, Michael Kaminsky, and Feng Xiao. 2008. Sybillimit:
A near-optimal social network defense against sybil attacks. In IEEE S & P. IEEE.
[37] Dong Yuan, Yuanli Miao, Neil Zhenqiang Gong, Zheng Yang, Qi Li, Dawn Song,
Qian Wang, and Xiao Liang. 2019. Detecting Fake Accounts in Online Social
Networks at the Time of Registrations. In CCS.
[38] Haizhong Zheng, Minhui Xue, Hao Lu, Shuang Hao, Haojin Zhu, Xiaohui Liang,
and Keith Ross. 2018. Smoke screener or straight shooter: Detecting elite sybil
attacks in user-review social networks. In NDSS.
[35] Zhi Yang, Christo Wilson, Xiao Wang, Tingting Gao, Ben Y Zhao, and Yafei Dai.
A EVALUATION ON ROBUSTNESS
Detecting malicious accounts has always been a dynamic process.
As the detection methods improve, malicious users will also keep
upgrading their strategies. In this section, we discuss some possible
evasion strategies potentially adopted by malicious users and show
the robustness of Muses against these evasion attacks. We consider
three kinds of evasion strategies for each behavior. Since we only
take account-behavior bigraphs as input, evasion strategies basi-
cally change the structures of the bigraphs. Therefore, we modify
the bigraph structure to simulate the evasion process and then input
these bigraphs into Muses to get the new behavior score and overall
score (see Figure 9). The results show that even under combined
evasion strategy, Muses still shows great robustness with less than
0.01 drop on AUC value.
A.1 IP Address
We select 35k growing-up accounts to initiate the IP address evasion
attack. These accounts are clustered in one community, so it is
very likely that they are operated by the same malicious group.
We find a list of 3.2k malicious IP addresses that are only shared
by the selected growing-up accounts. It is convincing that these
malicious IP addresses play an important part in detecting the
selected growing-up accounts.
To evade being detected by common IP addresses, growing-up
users may disperse the IP addresses. There are two ways to achieve
the goal: enlarge the IP pools or proxy to normal public IP addresses.
However, the first way is costly and ineffective. Even if they man-
age to get some new private IP addresses, these new IP addresses
also contribute to the connection among themselves. Therefore,
growing-up users are very likely to adopt the second method, i.e.,
to proxy their IP addresses using normal public IP addresses, which
is also the way we simulate IP address evasion attacks in our ex-
periments.
Specifically, we make a list of benign IP addresses, which are
shared by most benign accounts, and then proxy the malicious
IP addresses uniformly to these benign IP addresses. This process
refers to the changes in IP behavior bigraph of removing edges from
selected growing-up accounts to malicious IP addresses, and adding
308On Detecting Growing-Up Behaviors of Malicious Accounts in Privacy-Centric Mobile Social Networks
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
(a)
(d)
(b)
(e)
(c)
(f)
Figure 9: Evaluating the robustness of Muses under different evasion strategies. Figure (a), (b), (c) show the score distribution
of growing-up users when they use IP, client version, action type evasion strategy, respectively. Figure (d), (e), (f) show the
AUCs after applying these evasion strategies, respectively.
edges from selected growing-up accounts to benign IP addresses.
We test different numbers of benign IP addresses to proxy to, which
also reflects the increasing cost of the evasion attack. Figure 9a
shows the distribution of malicious scores of the selected growing-
up accounts. We see that the average malicious score drops from
0.83 to 0.69 when the number of manipulated IP addresses increases
from 0 to 50, which is still large enough to be detected. As the
number continuously increases, the average malicious score only
drops slightly, which is still larger than 0.6. Figure 9d shows the
AUC of Muses under the IP address evasion attack. We observe
that the AUC drops slightly when the number of manipulated IP
addresses increases from 0 to 5,000. In particular, the AUC of Muses
decreases by less than 0.005, which demonstrates the robustness of
Muses against the IP address evasion attack.
A.2 Client Version
Similar to the IP address evasion strategy, we select 38k growing-up
accounts from one community. Then we make a list of 588 mali-
cious version numbers shared by these accounts. We also make a
list of 1,000 benign version numbers as the evasion targets. Then we
test the detection performance of Muses after the selected accounts
transfer to 1, 5, 10, 50, 100 benign version numbers. The distribu-
tion of malicious score of the selected growing-up accounts and
the AUC of Muses under client version evasion attack are shown
in Figure 9b and Figure 9e, respectively. Unlike IP address evasion,
version number evasion does not affect the overall performance
in a linear way. This result is consistent with that in Table 3. The
main reason is that the client version does not express obvious
maliciousness on its own and the overall score is therefore domi-
nated by the other two behaviors, which makes the evasion result
fluctuates with the randomness introduced by the random walk
process. Further, as shown in Figure 9e, we can see that the overall
AUC drops by less than 0.01, demonstrating that Muses is robust
against the client version evasion attack.
A.3 Action Type
Unlike physical resources such as IP address and client version, eva-
sion strategy on action behavior has many restrictions. In WeChat,
there are many passive action types, such as being kicked from
a chatroom, being reported by other users as malicious, and be-
ing added to black lists by others. The counts of these passive
action types can hardly be manipulated. Therefore, we select 8 non-
passive action types, such as generating QR code for a chatroom
and following official accounts, which are most behaviors related
to growing-up accounts according to Section 3. We then select 29k
growing-up accounts from one community to initiate evasion on
action count behavior. To enhance the power of growing-up users,
we assume that growing-up users can modify two kinds of action
types at the same time. Specifically, we randomly choose ten dif-
ferent combinations of action types. For action type evasion, we
change its count to fall into intervals that contain the most benign
accounts. Figure 9c shows that different combinations of action
types have similar effects on final malicious scores. The range of
the scores becomes larger covering 0.4∼1.0, while the average score
remains steady(∼0.7). Some evasion cases even have higher average
scores than those without evasion. We also test the evasion result
where growing-up users are capable of modifying all 8 action types
to any count (the rightmost bar in Figure 9c). The result shows that
the average scores using this evasion strategy are higher than any
previous case, indicating that our method is able to extract very
subtle connections between accounts. Figure 9f presents the AUC
of Muses under different action type combinations. We observe that
the AUC drops by less than 0.002, which shows the robustness of
Muses against the action type evasion attack.
05010050010005000#manipulated IP addresses0.00.20.40.60.81.0Malicious Score0151050100#manipulated client versions0.00.20.40.60.81.0Malicious ScoreNone  2 typesAction type combination0.00.20.40.60.81.0Malicious Score05010050010005000#manipulated IP addresses0.9400.9420.9440.9460.9480.950AUC0151050100# manipulated client versions0.9400.9420.9440.9460.9480.950AUCNone  2 typesAction type combination0.9400.9420.9440.9460.9480.950AUC309ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Zijie Yang1, Binghui Wang2, Haoran Li1, Dong Yuan1, Zhuotao Liu1, Neil Zhenqiang Gong3
Chang Liu4, Qi Li1, Xiao Liang5, Shaofeng Hu5
A.4 Combined Evasion Strategies
Based on the above observations, we know that evasion strate-
gies on single behavior have little impact on Muses’s performance.
Moreover, we also test the impact of combining all three evasion
strategies. Figure 10 shows the percentage of growing-up accounts
with a certain malicious score. We can see that although growing-
up accounts have relatively low malicious scores after combined
evasion, all of them have scored higher than 0.5. In particular, most
growing-up accounts have high malicious scores of higher than
0.6, which is still high enough to be detected by Muses. Moreover,
we find that the AUC of Muses only drops by 0.001, showing that
Muses is robust even under combined evasion attacks.
Figure 10: Percentage of growing-up accounts and AUC
value before and after combined evasion attack.
0.50.60.70.80.91.0Malicious Score0.000.050.100.150.200.250.300.35ValueNo attack(AUC=0.947)Combined attack(AUC=0.946)310