Magnus Bråding
Version: 0.7
2008-08-04
52(68)
Again, these two different procedures described above, for creation of inbound and outbound
routing tunnels, are completely identical and symmetrical to any external parties. This holds true
both in regards to any external eavesdropper monitoring all traffic for all the nodes in the entire
routing path except the anonymized node itself and the terminating node, and also even for the
intermediate X-nodes themselves, being the actual nodes constituting the tunnel. Thus, neither of
these parties will be able to conclude any information about what kind of routing tunnel is being
created (i.e. an inbound or outbound tunnel), or on which side of the routing path that the
anonymized node that owns it is located. This is, of course, yet another measure to improve the
anonymity of the end-point nodes.
This concludes the low-level details for the secure establishment of routing tunnels.
White Paper:
Generic, Decentralized, Unstoppable Anonymity: The Phantom Protocol
Author:
Magnus Bråding
Version: 0.7
2008-08-04
53(68)
7.2.4.   
Secure Communication over Routing Tunnels
Once a routing tunnel has been established, the communication over it is extremely simple. Each
intermediate node (X-node) in the routing path has one connection in either direction open for the
tunnel, and a stream encryption key associated with it (the one that was chosen during the tunnel
establishment procedure described above). As soon as any data arrives on either of the two
connections, it will be immediately stream encrypted by the node (or decrypted, depending on the
direction) byte by byte, with the associated encryption key, and the encrypted (or decrypted) byte
is then sent out on the matching opposite connection of the node.
This way, each node only works as a forwarding and encrypting proxy, nothing more. The
anonymized node keeps track of the encryption key and stream encryption state for each of the
intermediate nodes, and can, therefore, easily decrypt and encrypt the bytes that it receives and
sends over the routing path.
The reason for using stream encryption in each node is to eliminate any and all possibilities for
any two non-adjacent nodes in the routing tunnel/path to communicate with each other by means
of any kind of data patterns sent over the routing tunnel. For each encrypted unit of data, the
stream encryption state in each node is updated, which means that it will produce completely
different output even if identical data is sent over the same connection twice.
The reason for individually encrypting each byte in the data stream is that it can never be safely
assumed that enough data will be sent at a time to fill an entire and even crypto block, and data
can of course never be withheld until enough data has arrived in this situation (which might very
well never occur in many situations and with many application level protocols).
White Paper:
Generic, Decentralized, Unstoppable Anonymity: The Phantom Protocol
Author:
Magnus Bråding
Version: 0.7
2008-08-04
54(68)
7.3.  Secure End-to-End Encryption and Authentication
End-to-end security equivalent to that of SSL, i.e. using secure end-to-end encryption and
bidirectional secure asymmetrical authentication, can also be easily be accomplished over the
connections of the anonymous network too. The best way is most likely to simply use a regular
SSL connection inside the TCP-equivalent anonymized connection that has been described. This
way, the common anonymized connection would be the anonymized equivalent of a TCP
connection, while the SSL-secured version would be the anonymized equivalent of an SSL/TCP
connection.
Such SSL security could of course always be applied externally, by the applications themselves
on the application level, but it would be a very good idea for several reasons to build it trans-
parently into the protocol design, for all connections. This would prevent any and all eaves-
dropping attacks by exit nodes, entry nodes and external attackers, and make the protocol much
more secure by default.
The needed certificates could also be easily integrated into the already existing network database
design in an efficient manner. They could be stored in association with each AP address entry,
along with the various certificates and other information already being stored there in the design
having been presented this far.
Due to the inherent problems of using a standard PKI structure with certificate authorities (CA) in
an anonymized network (no certificate authority will obviously be able to positively identify the
owner of any AP address, since this in the foundational concept), other methods of ensuring the
authenticity of end points will have to be used. The classic “web of trust” method can still be used,
where one or several trusted actors (either real identities or other AP addresses) can vouch for
the authenticity of a certain AP address certificate.
Also, a second solution which could be used in parallel with the “web of trust” method is to make
it possible for users to manually store trusted end-point certificates for certain AP addresses
locally in their computers. These will be compared to the certificates presented by the
corresponding AP addresses as soon as they are being connected to, and if a mismatch would
occur, a warning will be presented to the user about this. These trusted certificates would typically
be acquired and stored the first time an AP address is connected to, or even acquired manually
from third party sources, e.g. trusted long-time users of the AP address in question, or from
trusted websites on the normal Internet.
White Paper:
Generic, Decentralized, Unstoppable Anonymity: The Phantom Protocol
Author:
Magnus Bråding
Version: 0.7
2008-08-04
55(68)
7.4.  The Network Database
7.4.1.   
The Simple DHT Abstraction
In order to avoid getting stuck in the more complex low-level details of how any specific DHT
(Distributed Hash Table3) design or algorithm works, we will remove the need for all such things
by creating a simple DHT abstraction that even the most basic forms of DHT designs and
algorithms will be able to meet, and use this abstraction for all further discussions. That way,
practically any kind of DHT algorithm can be selected and used to implement the Phantom
Network Database at a later point, without affecting any of its higher level design or features. It
should be noted, however, that some DTH designs may very well already inherently support
some of the features that will be discussed as being placed on top of the simple DHT abstraction.
In these cases, this will only be regarded as an extra advantage for selecting this particular DHT
algorithm, but not as a requirement for any selected algorithm.
The following is the simple DHT abstraction that will be used, and the terms describing it:
1.  A DHT node is one of the networked users that constitute the DHT.
• 
In the case of the DHT-based Phantom Network Database, all network nodes in the
entire anonymized network will be DHT nodes in the database.
2.  Any DHT node can store data in the DHT, by submitting a DHT key with data attached to it.
• 
The DHT key can be any sequence of bytes (with some defined maximum length).
• 
The data attached to the DHT key can be any sequence of bytes (with some defined
maximum length, normally bigger than the maximum length of the DHT keys).
3.  Data can be retrieved from the DHT by any DHT node, by submitting a query for any of its
existing DHT keys.
4.  The DHT will be able to handle constantly departing and newly joining DHT nodes, without
losing any data (or, at least, with a very low risk of doing so).
• 
This is a standard feature of all DHT designs.
5.  It should be possible to quickly broadcast certain messages to all DHT nodes.
• 
This is a feature which most DHT designs inherently support, as part of their overlay
network structure.
7.4.2.   
The Phantom Network Database
Having just defined the simple DHT abstraction, we can now move on to defining the more
advanced distributed Phantom Network Database abstraction. This database abstraction will be
built completely upon the simple DHT abstraction described above, thus having the sole
requirement of being powered by any DHT design able to live up to that simple DHT abstraction.
Here follows a description of the capabilities of the Phantom Network Database (PND), and its
related terminology:
1.  The database should be resilient to injection of false or unauthentic data.
• 
This can be solved in part by applying voting algorithms for replies, and in part by
digitally signing some of its data, where suitable and possible.
2.  The database should be resilient to “net splits”, i.e. attackers being able to create an isolated
part of the network that they can fully control and monitor, thus being able to trap and track
unsuspecting users in it (remember that the entire security of the protocol is based on
attackers not being able to control a significant percentage of all nodes in the network).
3 http://en.wikipedia.org/wiki/Distributed_hash_table
White Paper:
Generic, Decentralized, Unstoppable Anonymity: The Phantom Protocol
Author:
Magnus Bråding
Version: 0.7
2008-08-04
56(68)
• 
First of all, the designs of most DHT algorithms inherently make such an attack
extremely hard to accomplish on a DHT that’s already up and running. This is due to the
rather extreme level of random interconnection and automatic balancing between nodes
that is constantly occurring.
• 
The most likely method to successfully lure and isolate a certain network node into a
separate network would rather be to do it initially, when the victim node is getting
connected to the network. Several things could be done to make also this kind of attack
much more difficult.
• 
First of all, once a node has been successfully connected to the real network just
once, a large amount of previously known nodes could be used to “prime” each
subsequent reconnection to the network. This would assure that if just one of these
nodes is still legitimate, it will work as an “interconnection” between the real network
and any possible false network, giving access to all the nodes in the real network and
possibly even “melting together” the real network and the false network (by means of
the dynamic balancing and distribution of data throughout all known nodes that is
constantly going on in a DHT), thus neutralizing the false network completely.
• 
As for the very first time that a node connects to the network, it is indeed important to
get an “entry address” into the network (i.e. the address of any random node that is
already connected to the network) from a trusted source. Given the typical
exponential growth rate of a network of this kind, it should not take long until most
people “know someone” who is already in the network though, and up until that point
all users could easily be primed from a central trusted web site or similar. It is
important to note though that such a central server will not be needed anymore as
soon as the network reaches a “critical mass”, which should happen very quickly.
• 
Finally, given the “melting together” scenario mentioned above, no false network
would even be able to survive (at least without detection) if just a single node in that
entire network would know about nodes from the real network too. In order to make
sure that such a thing would always happen quickly, and thus make sure that no
false network could survive for any longer period of time, network nodes could be
designed to recurringly “re-prime” themselves from other personal and locally defined
“trusted nodes”. Such a trusted node will typically be a network node belonging to a
personal friend or similar, and during the re-prime procedure the two nodes that are
performing it together (always in a symmetrical fashion) would share with each other
a significant amount of information (e.g. IP addresses) about the current network in
which they are located, and then merge this data from the other trusted node with
their currently existing knowledge about the network. This way a re-primed node
originally located in a false network would also immediately get access to the entire
real network, and the other nodes in the false network would be reduced to being a
small part of the real network instead, which is a situation that the protocol is able to
handle by design. Thus, the false network will have been neutralized.
3.  The database should support the notion of virtual “tables”, “table fields” and “table records”
for storing data.
• 
This can be easily accomplished by only allowing data of certain formats to be stored in
the database, where each format belongs to a different virtual table. The data of the
different allowed formats could be marked based on its data type, and this will be
interpreted by all network nodes in order to know to which virtual table the data belongs.
• 
The notion of table fields and records can be easily accomplished by including different
fields in all the different allowed kinds of data formats, thus effectively storing tuples of
specific data format in each virtual table.
• 
Each table record can also be submitted with an extra DHT key unique to its parent
table, facilitating the subsequent retrieval of “random” records from any specific table, by
simply querying for this special table key.
White Paper:
Generic, Decentralized, Unstoppable Anonymity: The Phantom Protocol
Author:
Magnus Bråding
Version: 0.7
2008-08-04
57(68)
4.  The database should be able to return random records from a specified table in a secure
fashion (i.e. in a fashion such that no single node can influence more than a maximum of
one record in the returned set).
• 
This can be accomplished by querying multiple nodes for the same kind of data, and
then, at random, picking a maximum of one data item from each contacted node. To
make it even more secure, the same nodes should never, to the extent practically
possible, be queried again for random data of the same kind, or even any kind of data,
depending on how many different nodes are available in the network.
5.  The database should be able to enforce a permission system for certain operations, e.g.
allowing only the “owner” of certain data items (i.e. the entity that first inserted the data into
the database) to update or remove them, but no one else, and to only allow certain queries
altogether.
• 
This can be accomplished by requiring cryptographic authentication for such operations,
e.g. by means of requiring a valid digital signature created with the key belonging to a
cryptographic certificate that is attached to the pre-existing item to be updated (or
deleted).
• 
In the case of allowing only certain specific queries, while disallowing all other queries,
this can be a simple matter of having each node pre-filter all queries arriving to it before
processing them. The rules defining what will be allowed and not allowed can be hard
coded into the application itself, together with the virtual table definitions.
6.  The database should be able to enforce expiry dates for certain kinds of data (e.g. table
records in certain tables), outside the control of the nodes that are submitting the data.
• 
This can be accomplished by including expiry time limits for records in certain tables, and
having each individual node enforcing these limits locally, dropping any stored record as
soon as it has passed its expiry time.
• 
In a little more detail, data added to such a table would have its exact expiry time
calculated locally by each node that stores the data, based on the defined expiry time
limit defined in the table in question, combined with a creation time stamp that comes
with the data item itself. In order to prevent “cheating”, no entries having time stamps
with future times will be accepted into such a table to begin with.
7.  A “command channel”, where centrally authorized commands can be quickly sent to all
nodes participating in the network database, should be supported.
• 
This can be easily accomplished by means of a combination of the DHT broadcast
feature, and commands signed with an asymmetric master key whose public half is hard
coded into all clients.
• 
This way, central network administration, located anywhere on the network, could
perform certain administrative actions in order to manually counter large and
resourceful attacks against the network, e.g. globally banning certain IP addresses or
removing certain entries from the network database.
• 
It is important to note, however, that no such command should ever be able to affect
the computers of the network nodes in any way. Because of this, no one should have
to worry about the central command key being cracked, since it will at most be able
to disrupt the operation of the network, but not any of its clients. And in the unlikely
even that such a central command key would be cracked or otherwise compromised,
it’s as easy as releasing a new version of the client with a new hardcoded key inside
it to completely rectify the situation.
• 
Finally, if such a command feature would still induce too much paranoia among
potential users of the protocol, no matter how benign it really is, it can indeed be
completely left out, at least until any hypothetical large scale attack against the
network actually occurs, which the build in counter measures of the protocol won’t be
White Paper:
Generic, Decentralized, Unstoppable Anonymity: The Phantom Protocol
Author:
Magnus Bråding
Version: 0.7
2008-08-04
58(68)
able to handle automatically. After all, this might not happen at all (especially judging
from the (un)success rate of various attackers trying to disrupt miscellaneous
controversial distributed networks on the Internet to this date).
7.4.3.   