whether their data is used by the target recommender.
Adversaryâ€™s Knowledge. We assume an adversary has only black-
box access to the target recommender. That is, adversary can only
observe the items recommended to a target user (i.e., recommenda-
tions), and the userâ€™s history (i.e., interactions), such as rating and
purchase, instead of posterior probabilities for recommendation
predictions. In that case, the adversary needs to profile users by
their interactions and recommendations. Meanwhile, a shadow rec-
ommender is built to generate labeled data for the attack model,
since ground truth membership is unavailable from the target rec-
ommender.
2.3 Recommender Systems
In this section, the framework of recommender systems is briefly
introduced.
Recommendation algorithms output recommended items based
on the information learnt from input. In the paper, two types of
recommendation algorithms are mainly involved: personalized and
non-personalized recommendation algorithms. For members, items
are recommended according to the preferences of members. Mean-
while, lacking non-membersâ€™ data, non-personalized recommen-
dation algorithms are conducted, and provide most popular items
for non-members. Specifically, Item-Based Collaborative Filtering
(Item) [40], Latent Factor Model (LFM) and Neural Collaborative
Filtering (NCF) [16] are adopted as the personalized recommen-
dation algorithms for members. As for the non-personalized rec-
ommendation algorithm, the most popular items are provided to
non-members, which is also called the popularity recommendation
algorithm in the paper. We briefly introduce the above algorithms
as follows:
the ones which are closed to usersâ€™ likes.
â€¢ Item calculates the similarity between items aiming to find
â€¢ LFM builds a latent space to bridge user preferences and
â€¢ NCF combine the deep learning technology with collabora-
tive filtering to enhance the recommendation performances.
â€¢ Users are provided with the most popular items by the pop-
item attributes.
ularity recommendation algorithm.
In general, a recommender system Ağ‘…ğ‘† learns user preferences
from the interactions, sometimes with the external knowledge (such
as gender and location information) for users. According to the
predicted preferences, the recommender system provides users with
multiple items. This procedure can be formulated as:
Ağ‘…ğ‘† : (Iğ‘…ğ‘†,Kğ‘…ğ‘†) â†’ Rğ‘…ğ‘†,
2.2 Threat Model
Adversaryâ€™s Goal. The adversary aims to infer whether a userâ€™s
data is used by a target recommender. In fact, knowing a certain
userâ€™s data being used by a recommender system directly leaks
where Ağ‘…ğ‘† is a recommender system learning the preferences of
users from their interactions Iğ‘…ğ‘† and the external knowledge Kğ‘…ğ‘†.
And Rğ‘…ğ‘† denotes recommended items to users. In the paper, we
mainly use the interactions of users. Thus, we define a recommender
Session 3C: Inference Attacks CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea866attack consists of three steps to achieve the adversaryâ€™s goal: La-
beled Data Generation, Attack Model Establishment, and Parameter
Optimization.
Labeled Data Generation. Training data is required during the
Ağ‘ğ‘¡ğ‘¡ğ‘ğ‘ğ‘˜ optimization process. However, the adversary cannot ob-
tain membership status directly from the target recommender
Ağ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡. To address this problem, a shadow recommender Ağ‘ â„ğ‘ğ‘‘ğ‘œğ‘¤
is developed to mimic the dataset and recommendation algorithm
of the target recommender.
As mentioned in Section 1.1, only recommended item lists from
target recommender systems can be observed. Inspired by the pre-
vious works [17, 24], matrix factorization is adopted to project users
and items into a shared latent space. Specifically, a ğ‘ Ã— ğ‘ user-item
matrix Mğ‘“ is built using ratings of users to items, where ğ‘ and ğ‘
are the number of users and items respectively. Values in Mğ‘“ are
ratings ranging from 1 to 5, indicating how much users prefer these
items. Then, Mğ‘“ is factorized into two low-dimensional matrices,
namely latent user matrix Mğ‘¢ğ‘ ğ‘’ğ‘Ÿ âˆˆ Rğ‘Ã—ğ‘™ and latent item matrix
Mğ‘–ğ‘¡ğ‘’ğ‘š âˆˆ Rğ‘Ã—ğ‘™, where we denote ğ‘™ as the dimension of the latent fea-
ture space. We apply matrix factorization to find optimized Mğ‘¢ğ‘ ğ‘’ğ‘Ÿ
and Mğ‘–ğ‘¡ğ‘’ğ‘š by minimizing the loss function ğ¿ğ‘€ğ¹ :
(cid:13)(cid:13)(cid:13)Mğ‘“ âˆ’ Ë†Mğ‘“(cid:13)(cid:13)(cid:13)2
ğ¿ğ‘€ğ¹ =
ğ‘¤â„ğ‘’ğ‘Ÿğ‘’
Ë†Mğ‘“ = Mğ‘–ğ‘¡ğ‘’ğ‘š Â· Mğ‘¢ğ‘ ğ‘’ğ‘Ÿ T,
ğ‘ â„ğ‘ğ‘‘ğ‘œğ‘¤
ğ‘ â„ğ‘ğ‘‘ğ‘œğ‘¤
and Dğ‘œğ‘¢ğ‘¡
where Ë†Mğ‘“
is a predicted user-item matrix which contains the
predicted scores of users rating items. Besides, Mğ‘¢ğ‘ ğ‘’ğ‘Ÿ and Mğ‘–ğ‘¡ğ‘’ğ‘š
present the predicted preferences of users and the predicted at-
tributes of items, respectively. Each row of the item matrix Mğ‘–ğ‘¡ğ‘’ğ‘š
represents the feature vector of the corresponding item. Note that,
since Mğ‘¢ğ‘ ğ‘’ğ‘Ÿ may not cover all users in the shadow and target rec-
ommenders, Mğ‘¢ğ‘ ğ‘’ğ‘Ÿ is not used to represent users.
To this end, training data for the attack model can be generated
from Ağ‘ â„ğ‘ğ‘‘ğ‘œğ‘¤. The shadow dataset Dğ‘ â„ğ‘ğ‘‘ğ‘œğ‘¤ are split into two
disjoint sets for members and non-members, which are denoted by
Dğ‘–ğ‘›
, respectively. These datasets are composed
of 3-tuples in the form of (ğ‘¢ğ¼ğ·, ğ‘–ğ¼ğ·, ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’), indicating scores rated
by users to items. For instance, a 3-tuple (2, 3, 4) in datasets means
that the 2ğ‘›ğ‘‘ user rates the 3ğ‘Ÿğ‘‘ item a score of 4. Ratings in Dğ‘–ğ‘›
ğ‘ â„ğ‘ğ‘‘ğ‘œğ‘¤
and Dğ‘œğ‘¢ğ‘¡
can be seen as interactions of users to items, and sets
of interaction lists for members and non-members can be obtained,
denoted as Iğ‘–ğ‘›
, respectively. In that case, each
user has a list of interactions. For example, if a user rates the 2ğ‘›ğ‘‘, 4ğ‘¡â„,
6ğ‘¡â„ and 8ğ‘¡â„ items, the corresponding interaction list is {2, 4, 6, 8}.
Next, Ağ‘ â„ğ‘ğ‘‘ğ‘œğ‘¤ is established to mimic Ağ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡, and provides
users with recommendations according to their preferences. The
sets of recommendation lists for members and non-members are
denoted by Rğ‘–ğ‘›
, respectively. Similar as inter-
actions, each user is associated with a list of recommendations.
However, Rğ‘–ğ‘›
are sets of ordered lists of recom-
mendations. Formally, the recommendation process can be formu-
lated as follows:
and Rğ‘œğ‘¢ğ‘¡
and Rğ‘œğ‘¢ğ‘¡
and Iğ‘œğ‘¢ğ‘¡
ğ‘ â„ğ‘ğ‘‘ğ‘œğ‘¤
ğ‘ â„ğ‘ğ‘‘ğ‘œğ‘¤
ğ‘ â„ğ‘ğ‘‘ğ‘œğ‘¤
ğ‘ â„ğ‘ğ‘‘ğ‘œğ‘¤
ğ‘ â„ğ‘ğ‘‘ğ‘œğ‘¤
ğ‘ â„ğ‘ğ‘‘ğ‘œğ‘¤
ğ‘ â„ğ‘ğ‘‘ğ‘œğ‘¤
Ağ‘ â„ğ‘ğ‘‘ğ‘œğ‘¤ : ğ‘“ğ‘ğ‘’ğ‘Ÿ (Iğ‘–ğ‘›
Ağ‘ â„ğ‘ğ‘‘ğ‘œğ‘¤ : ğ‘“ğ‘ğ‘œğ‘(Iğ‘–ğ‘›
ğ‘ â„ğ‘ğ‘‘ğ‘œğ‘¤) = Rğ‘–ğ‘›
ğ‘ â„ğ‘ğ‘‘ğ‘œğ‘¤) = Rğ‘œğ‘¢ğ‘¡
ğ‘ â„ğ‘ğ‘‘ğ‘œğ‘¤
ğ‘ â„ğ‘ğ‘‘ğ‘œğ‘¤,
where ğ‘“ğ‘ğ‘’ğ‘Ÿ performs a personalized recommendation algorithm
based on the behaviors of members. Meanwhile, since non-membersâ€™
Figure 2: The framework of the membership inference at-
tack against a recommender system.
system as:
Ağ‘…ğ‘† : Iğ‘…ğ‘† â†’ Rğ‘…ğ‘†,
where Iğ‘…ğ‘† is a set of lists of interactions for users and Rğ‘…ğ‘† is a set
of ordered lists of recommendations for users. Concretely, Iğ‘…ğ‘† =
ğ‘›=1 and Rğ‘…ğ‘† = {ğ¿ğ‘›
{ğ¿ğ‘›
ğ‘…}ğ‘ğ‘¢
ğ¼ }ğ‘ğ‘¢
is the list of interactions
ğ‘›=1, where ğ¿ğ‘›
and ğ¿ğ‘›
ğ‘… is the ordered list of recommendations for the ğ‘›ğ‘¡â„ user, and
ğ‘ğ‘¢ is the number of users.
ğ¼
2.4 Attack Overview
In this section, we give an overview of our attack. As Figure 2
demonstrated, the attack process follows three steps: Labeled Data
Generation, Attack Model Establishment, and Parameter Optimiza-
tion.
Labeled Data Generation. To represent items, an item matrix
is derived, by factorizing a user-item rating matrix. Due to the
black-box access to the target recommender for the adversary, a
shadow recommender is built to generate labeled training data for
the attack model. Moreover, we represent interactions and recom-
mendations of users using corresponding feature vectors. After
that, a user is profiled by the difference between two centers of
their interactions and recommendations. And each user is labeled
with 1 or 0, indicating they are a member or non-member.
Inspired by [39], a two-hidden-
Attack Model Establishment.
layer Multi-Layer Perceptron (MLP) is utilized as the attack model
ğ´ğ‘ğ‘¡ğ‘¡ğ‘ğ‘ğ‘˜ to infer membership status. Each hidden layer is followed
by a ReLU activation layer. And a softmax function is used as the
output layer to predict the probability of the membership.
Parameter Optimization. After Labeled Data Generation and
Attack Model Establishment, as shown in Figure 2, the adversary
updates parameters of the attack model. In the inference stage, the
test dataset for target users are established following the same steps
as training data generation. The membership status for target users
is inferred by the trained attack model.
2.5 Membership Inference Attack
In this section, we detail our proposed membership inference attack
against a recommender system. As mentioned before, the whole
TargetRecommenderShadowRecommenderRecommendationsRtargetTrainedAttack ModelAttack Model EstablishmentTrainingLabelsLabeled Data GenerationInferenceParameterOptimizationTrainingSetDtrainUser FeaturesZshadowRecommendationFeaturesVshadowInteractionFeaturesUshadowRecommendationsRshadowInteractionsIshadowIInteractionsItargetInteractionFeaturesUtargetUser FeaturesZtargetTestSetDtestRecommendationFeaturesVtarget533TestLabelsUnobservableFor Attack Model Session 3C: Inference Attacks CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea867data is unavailable to Ağ‘ â„ğ‘ğ‘‘ğ‘œğ‘¤, ğ‘“ğ‘ğ‘œğ‘ performs the popularity rec-
ommendation algorithm (a non-personalized recommendation al-
gorithm) based on the statistical results from Iğ‘–ğ‘›
. Besides,
Iğ‘–ğ‘›
and Rğ‘œğ‘¢ğ‘¡
members and non-members respectively.
is a set of lists of interactions for members, and Rğ‘–ğ‘›
ğ‘ â„ğ‘ğ‘‘ğ‘œğ‘¤
are sets of ordered lists of recommended items for
Using item feature representations, we can vectorize the interac-
ğ‘ â„ğ‘ğ‘‘ğ‘œğ‘¤
ğ‘ â„ğ‘ğ‘‘ğ‘œğ‘¤
ğ‘ â„ğ‘ğ‘‘ğ‘œğ‘¤
tion and recommendation sets as follows:
Iğ‘ â„ğ‘ğ‘‘ğ‘œğ‘¤
Rğ‘ â„ğ‘ğ‘‘ğ‘œğ‘¤
ğ‘£ğ‘’ğ‘âˆ’â†’ Uğ‘ â„ğ‘ğ‘‘ğ‘œğ‘¤
ğ‘£ğ‘’ğ‘âˆ’â†’ Vğ‘ â„ğ‘ğ‘‘ğ‘œğ‘¤,
where Uğ‘ â„ğ‘ğ‘‘ğ‘œğ‘¤ and Vğ‘ â„ğ‘ğ‘‘ğ‘œğ‘¤ are sets of lists of the feature vectors
for the corresponding items in Iğ‘ â„ğ‘ğ‘‘ğ‘œğ‘¤ and Rğ‘ â„ğ‘ğ‘‘ğ‘œğ‘¤.
Given that each user has a list of interactions and is provided
with an ordered list of recommendations, the adversary is able to
represent users by their relevant items. To be specific, for the ğ‘–ğ‘¡â„
user, the representation is generated with the following two steps:
1) Center vectors of the interactionsâ€™ and recommendationsâ€™
feature vectors of the ğ‘–ğ‘¡â„ user are calculated:


ğ‘—
ğ‘—
Uğ‘– =
Vğ‘– =
Uğ‘–,ğ‘—/ğ‘ ğ‘–ğ‘›ğ‘¡
ğ‘–
Vğ‘–,ğ‘—/ğ‘ ğ‘Ÿğ‘’ğ‘
ğ‘–
,
whereUğ‘– andVğ‘– are the center vectors of the feature vectors
for the interactions and recommendations of the ğ‘–ğ‘¡â„ user,
and ğ‘ ğ‘–ğ‘›ğ‘¡
are the corresponding quantities. Besides,
Uğ‘–,ğ‘— and Vğ‘–,ğ‘— are the feature vectors for the ğ‘—ğ‘¡â„ interaction
and recommendation of the ğ‘–ğ‘¡â„ user, respectively.
and ğ‘ ğ‘Ÿğ‘’ğ‘
ğ‘–
ğ‘–
2) The difference between the two center vectors are obtained:
zğ‘– = Uğ‘– âˆ’ Vğ‘– .
In the paper, we employ zğ‘– as the feature vector for the ğ‘–ğ‘¡â„
user, which takes not only the userâ€™s history but also the
predicted preference into consideration.
Meanwhile, each user is assigned a label of 1 or 0, indicating their
membership (i.e., 1 means member and 0 means non-member). The
training dataset Dğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘› = {(ğ‘“ ğ‘’ğ‘ğ‘¡ğ‘¢ğ‘Ÿğ‘’ğ‘–, ğ‘™ğ‘ğ‘ğ‘’ğ‘™ğ‘–)}ğ‘
ğ‘–=1 contains feature
vectors and labels of all users, where the pair (ğ‘“ ğ‘’ğ‘ğ‘¡ğ‘¢ğ‘Ÿğ‘’ğ‘–, ğ‘™ğ‘ğ‘ğ‘’ğ‘™ğ‘–)
denotes the feature vector and label for the ğ‘–ğ‘¡â„ user.
Attack Model Establishment. Inspired by [39], a MLP is estab-
lished as the attack model Ağ‘ğ‘¡ğ‘¡ğ‘ğ‘ğ‘˜. The output of Ağ‘ğ‘¡ğ‘¡ğ‘ğ‘ğ‘˜ is a
2-dimension vector representing probabilities for the membership
status. For the ğ‘–ğ‘¡â„ user, the prediction can be formulated as follows:
h1 = ReLU(W1zi + b1)
h2 = ReLU(W2h1 + b2)
yğ‘– = softmax(h2),
where zğ‘– is the input of Ağ‘ğ‘¡ğ‘¡ğ‘ğ‘ğ‘˜ as well as the ğ‘–ğ‘¡â„ userâ€™s feature
vector in our attack. And W1, W2, b1 and b2 are the parameters
updated in the training process. ReLU(Â·) is an activation function
working on the outputs of two hidden layers, and softmax(Â·) is
used for normalization which is required by the cross-entropy loss.
Besides, h1 and h2 are the results of two hidden layers after ReLU(Â·).
And yğ‘– is the predicted result for the input zğ‘–, which is a 2-dimension
ğ‘–=1
i + (1 âˆ’ yâˆ—
ğ‘ğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘›
i )log(1 âˆ’ yâ€²
i)),
vector indicating the possibilities of zğ‘– belonging to members and
non-members, respectively.
Parameter Optimization. In this section, the parameter optimiza-
tion process for the attack model is described. Stochastic gradient
descent is adopted to update parameters, aiming to minimize the
cross-entropy loss function ğ¿ğ‘€ğ¿ğ‘ƒ:
(yâˆ—
ğ‘– logyâ€²
ğ¿ğ‘€ğ¿ğ‘ƒ = âˆ’
where yâˆ—