# Trace-Driven Analysis of the Long-Term Evolution of Gnutella Peer-to-Peer Traffic

## Authors
William Acosta and Surendar Chandra  
University of Notre Dame, Notre Dame, IN 46556, USA  
{wacosta, surendar}@cse.nd.edu

## Abstract
Peer-to-Peer (P2P) applications, such as Gnutella, have evolved to address performance issues. This paper analyzes Gnutella's behavior in 2003, 2005, and 2006, during which the protocol evolved from version 0.4 to 0.6. The primary goal is to evaluate whether the newer protocols effectively address prior concerns. Our findings indicate that while the new architecture alleviated bandwidth consumption for low-capacity peers, it increased bandwidth usage for high-capacity peers. We observed a decrease in incoming query rates, but highly connected ultra-peers experienced an increase in outgoing query traffic due to maintaining numerous connections. Despite these changes, search performance has not significantly improved, with effective success rates increasing only from 3.5% to 6.9%. Over 90% of queries forwarded by a peer do not result in any hits, leading to significant wasted bandwidth. We propose potential solutions to enhance P2P systems' viability for a broader range of applications.

## 1. Introduction
In recent years, Peer-to-Peer (P2P) systems have become popular platforms for distributed and decentralized applications. Applications like Gnutella, Kazaa, and Overnet/eDonkey are widely used, and their performance and behavior have been extensively studied. Gnutella, despite its popularity, suffers from issues such as free-riding users, high bandwidth utilization, and poor search performance. As the number of users grows and the ultra-peer architecture becomes more dominant, addressing these problems is crucial for the long-term viability of Gnutella and other file-sharing P2P applications.

This paper presents an analysis of Gnutella traffic trends from 2003, 2005, and 2006. We examine large-scale macro behaviors to determine how Gnutella traffic evolves over time. By capturing and comparing traffic data, we analyze message rates, bandwidth utilization, and queuing properties to identify changes in Gnutella's characteristic behavior. We also study localized behaviors, such as the query success rate experienced by forwarding peers. Our results show that earlier protocol changes did not achieve the intended benefits of improving search performance and reducing high bandwidth utilization.

## 2. Gnutella Overview
Gnutella is a popular P2P file-sharing application where users connect to form an overlay network for content sharing. The Gnutella protocol is distributed and decentralized, using a flooding mechanism to propagate requests. Each peer forwards requests to all neighbors until a specified Time-To-Live (TTL) is reached. This mechanism can quickly overwhelm available network bandwidth. We describe two major versions of the Gnutella protocol:

### 2.1 Protocol v0.4
The original Gnutella protocol, v0.4, assumed all peers were equal in capacity and participation. It specified four main messages: Ping, Pong, Query, and QueryHit. Control messages (Ping and Pong) are used for peer discovery, while Query and QueryHit messages are used for content search. When a peer receives a Query, it evaluates the query string and sends back a QueryHit if it has matching content.

### 2.2 Protocol v0.6
As Gnutella grew, the network size and traffic increased, overwhelming many peers with poor Internet connections. To address these performance limitations, the v0.6 protocol introduced the ultra-peer architecture. This reduced the incoming query message rate, lowering bandwidth requirements for processing queries. However, the new architecture shifted the problem to ultra-peers, which must maintain many connections and forward all queries, increasing their outgoing query traffic.

## 3. Related Work
Saroiu et al. [11] and Ripeanu et al. [10] studied various aspects of the Gnutella file-sharing network, identifying that new clients tend to connect to peers with many connections, leading to a power-law node degree distribution. They also found that many users do not share content (free-ride), degrading system utility and performance. Rasti et al. [9] analyzed the evolution of the v0.6 two-tier architecture, showing that modifications to major Gnutella client software helped restore the overlay's desired properties. Our work focuses on the evolution of traffic characteristics and query performance, providing insights into the effects of architectural changes and enabling better modeling and simulation of large-scale P2P networks.

## 4. Results

### 4.1 Methodology
We captured traces for two weeks in May and June 2003, October 2005, and June through September 2006. We modified the source code of Phex, an open-source Gnutella client, to log network traffic. The client logged every incoming and outgoing message, including timestamp, message ID, direction, type, TTL, hops, and size. For queries and responses, additional information was logged. Traces from 2003 were collected with the client running as a regular peer, while 2005 and 2006 traces were captured with the client acting as an ultra-peer. Logs were partitioned into two-hour intervals for ease of processing.

### 4.2 Summary of Data
The average number of messages handled by the client was 2.5M in 2003 and 2.67M in 2006 per two-hour interval. The average file size for a two-hour trace was 292MB in 2003 and 253MB in 2006, representing over 3GB of data per 24 hours. In 2003, the client saw 2,784 different peers, while in 2006, it saw 1,155 peers. This reduction can be attributed to longer session times, with more than 50% of sessions lasting over 60 minutes in 2006 compared to less than 30 minutes in 2003.

### 4.3 Message TTL Analysis
Table 1 shows the mean TTL and hops taken for different message types in a 24-hour period from 2003, 2005, and 2006. In 2003, messages traveled 6.85 hops, requiring 4.46 hops to reach our logging client with a mean TTL left of 2.39. In 2005, messages traveled 6.31 hops, requiring 3.41 hops with a TTL of 2.95. In 2006, messages traveled 3.86 hops, requiring 3.34 hops with a TTL of 0.52. This change is attributed to the v0.6 protocol, which restricts the initial TTL to 4-5 hops to reduce network burden. Control messages in 2003 had a mean of 3.1 hops taken and a TTL of 2.8, while in 2006, they had a mean of 3.4 hops taken and a TTL of 0.37. Query traffic in 2006 is expected to be propagated further, with a stable TTL of 2.36 in 2003 and 2.26 in 2006.

Figures 1 and 2 show the hourly mean TTL and hops taken for control and query traffic, respectively. The TTL and hops remain relatively constant throughout the day, even as bandwidth consumption and the number of nodes fluctuate.

### 4.4 Bandwidth Analysis
[Continued in the next section]

---

This revised text aims to improve clarity, coherence, and professionalism. The structure is organized, and the language is refined to ensure a smooth and logical flow of information.