union{MD5，null}@aliases（["hash"]）nullableHash；
array＜long＞arrayOfLongs；
}
error TestError{
string message；
}
string hello（string greeting）；
TestRecord echo（TestRecordrecord）；
int add（int arg1，int arg2）；
bytes echoBytes（bytes data）；
voiderror（）throws TestError；
void ping（）oneway；
}
16.5 Avro SASL概述
SASL（Simple Authentication and Security Layer，简单验证安全层）是网络协议中提供验证和安全的框架，它将验证机制从用户程序协议中分离出来，使得采用SASL的程序可以使用任何SASL所支持的验证机制，同样也支持代理验证。SASL提供的数据安全层能够提供数据完整性和数据加密服务，支持SASL的用户协议，也支持SASL服务所需的安全传输层协议，其中安全传输层协议是为因特网上通信提供安全性的加密协议。开发者可通过SASL对通用API进行编码，此方法避免了对特定机制的依赖。采用SASL的协议需要定义SASL profile，即如何使用SASL进行验证协商。下面对Avro RPC采用的SASL进行介绍。
SASL协商过程可以看成是客户端和服务器使用特定的SASL机制、在连接的基础上进行一系列消息的交互。客户端通过发送带有初始消息（可能为空）的机制名称（这里是SASL）来协商过程。协商过程一直伴随着消息的交换直到某一方表明协商成功或失败。消息的内容由具体的机制决定，如果协商成功就可以通过连接进行会话，否则将被抛弃。一些机制在协商之后会继续处理会话的数据（如对数据进行加密），而一些机制会指定会话数据传输不需修改。
Avro SASL协商使用4个单字节命令，分别是：
0：START（开始），使用于客户端初始消息中；
1：CONTINUE（继续），使用于协商进行中；
2：FAIL（失败），协商失败；
3：COMPLETE（完成），成功完成协商。
开始消息的格式是：
|0|4字节的机制名称的长度|机制名称|4字节的有效负载的长度|有效负载数据|
继续消息的格式是：
|1|4字节的有效负载的长度|有效负载数据|
失败消息的格式是：
|2|4字节的消息长度|UTF-8的消息|
完成消息的格式是：
|3|4字节的有效负载的长度|有效负载数据|
协商以客户端发送START命令开始，START命令中包含客户端选定的机制名称和指定机制的有效负载数据。然后，服务器和客户端交换一些CONTINUE消息，每个消息包含由安全机制生成的下个消息的有效负载数据。一旦客户端或者服务器发送FAIL消息，协商就会失败，失败消息中包含UTF-8编码的文本。只要接收到或发送了FAIL消息，或者在协商过程中发生了任何错误，基于此次连接的通信就必须结束。如果客户端或服务器发送COMPLETE消息，那么协商将成功完成，会话数据可以通过此次连接进行传输直到一方关闭。
如果SASL QOP（Quality of Protection，品质保证）没有进行协商，则基于此次连接的读/写无需修改，特别是传输的消息使用了Avro框架并采用了下面的形式：
|4字节的框架长度|框架数据|……|4个零字节|
如果SASL QOP协商且成功，则此次连接后的消息传输使用QOP。写数据时使用安全机制对非空的框架进行封装，读取数据时需要解开。完整的框架必须传送到安全机制进行解封装，之后传送到应用程序中。如果在封装、解封装或者框架处理时发生错误，那么此次连接的通信必须结束。
SASL的匿名机制很容易实现，特别之处在于，一个初始的匿名请求可以用以下静态序列作为前缀：
|0|009|ANONYMOUS|0000|
如果服务器使用匿名机制，则它应检查所接收到的请求前缀，即开始消息的机制名称是否为“ANONYMOUS”，然后对带有COMPLETE消息的初始响应前加上前缀：
|3|0000|
如果匿名服务器接收到带有其他机制名称的请求，那么它将发送FAIL消息：
|2|0000|
注意，匿名机制不会在客户端和服务器之间增加多余的往返，START消息附加在初始请求中，而COMPLETE和FAIL消息则附加在初始响应中。
16.6 本章小结
本章内容主要包括：16.1节首先将说明如何声明Avro模式，以及如何对数据进行序列化；然后介绍对象容器文件的具体格式和RPC中Avro的使用方法，包括协议的声明、协议传输的格式等；最后介绍如何解析获取的数据，重点说明如何处理写入模式和读取模式的不同。16.2节介绍了在C和C++中如何使用Avro，主要叙述函数的使用，其中引用关于学生模式的具体例子来详细介绍。16.3节首先介绍Java中使用Avro所需要的一些包，后面给出了上节中学生模式例子的Java实现程序。16.4节主要介绍了GenAvro语言，说明如何用类似高级语言的方法来声明一个Avro模式。16.5节简单介绍了Avro的简单验证安全层，具体说明了通信双方如何进行协商。
Avro作为一个数据序列化系统，为数据密集型动态应用程序提供了数据存储和交换的平台，它的最大特点就是模式和数据在一起，也就是在反序列化时写入的模式和读出的模式都是已知的，这为Avro带来了很多好处，如生成的数据文件很小等。
今后，Avro可能会替换Hadoop现有的RPC, Avro的很多特性是为Hadoop及相关项目准备的：容器文件中的同步器可以使MapReduce快速地分离文件；不需要生成代码，有利于Avro使用于Hive和Pig；对于大规模存储较小的数据文件有利于减少数据量等。Avro数据结构的特性和多语言支持的优势还会帮助Hadoop在跨版本、多语言等方面提高性能。
第17章 Chukwa详解
本章内容
Chukwa简介
Chukwa架构
Chukwa的可靠性
Chukwa集群搭建
Chukwa数据流的处理
Chukwa与其他监控系统比较
本章小结
17.1 Chukwa简介
Hadoop的MapReduce最初的主要用于日志处理。但是使用MapReduce处理日志是一件很烦琐的事情，因为集群中机器的日志在不断地增加，会生成大量小文件，而MapReduce其实只有在处理少量的大文件数据时才会产生最好的效用。
Chukwa作为Hadoop的子项目弥补了这一缺陷。同时它也是一个高可靠性的应用，能通过扩展处理大量的客户端请求，还能汇聚多路客户端的数据流。Chukwa也非常适合商业应用，特别是在云环境上，并且它已经成功地使用在多个场景中。
Chukwa的开发主要面向四类群体：Hadoop使用者、集群运营人员、集群的管理者、Hadoop开发者。
Hadoop使用者：他们一般想了解作业运行的状态，以及还有多少资源可以用于新的作业，因此他们需要得到的是作业日志和作业输出。
集群运营人员：他们需要了解硬件故障、异常状态、资源的消耗情况。
集群的管理者：他们需要了解在什么样的成本下能够提供什么样的服务，这就意味着他们需要一个工具去分析集群系统或单个用户过去的使用状况，并利用分析出的信息预测将来的需求。他们也要了解系统的一些特征值，如一个任务的平均等待时间。Hadoop开发者：Hadoop的开发人员通常需要了解系统的运行情况，Hadoop的运行瓶颈、失效模式等。
Chukwa作为Hadoop软件家族中的一员，依赖于其他Hadoop的子项目使用，比如，以HDFS作为存储层，以MapReduce作为计算模型，以Pig作为高层的数据处理语言。Chukwa系统的最大开销被限制在整个集群系统可用资源的5%以内。
Chukwa是一个分布式系统，它采用的是流水式数据处理方式和模块化结构的收集系统，在每一个模块中有一个简单规范的接口，这有利于将来更新，而不需要打破现行的编码结构。流水式模式就是利用其分布在各个节点客户端的采集器收集各个节点被监控的信息，然后以块的形式通过HTTP Post汇集到收集器，由它处理后转储到HDFS中。之后这些数据由Archiving处理（去除重复数据和合并数据）提纯，再由分离解析器利用MapReduce将这些数据转换成结构化记录，并存储到数据库中，HICC（Hadoop Infrastructure Care Center）通过调用数据库里数据，向用户展示可视化后的系统状态。
图17-1展示了Chukwa流水式数据处理结构。
下面的章节将从Chukwa架构出发，介绍系统中的各个模块，并且讲解Chukwa如何实现系统的可靠性。在对Chukwa整个系统框架及原理有所了解后，大家可以根据“Chukwa集群搭建”一节的介绍，搭建一个自己的Chukwa系统来监控Hadoop集群，这样就可以与其他监控系统有一个比较。希望大家可以结合自己实际使用感受，进一步了解Chukwa监控系统的特点。
图 17-1 Chukwa流水式数据处理结构
17.2 Chukwa架构
Chukwa有三个主要组成部分：客户端（Agent），它运行在每一个被监控的机器上，并且传送源数据到收集器（Collector）中；收集器（Collector）和分离解析器（Demux），收集器接受从Agent传来的数据，并且不断地将其写到HDFS中，而分离解析器则进行数据抽取并将其解析变换成有用的记录；HICC（Hadoop Infrastructure Care Center），其是一个门户样式的网页界面，用于数据的可视化。
图17-2为Chuwa的系统架构图。
图 17-2 Chuwa系统架构图
 17.2.1 客户端及其数据模型
在Chukwa中，Agent的主要目的是：使内部进程通信协议能够兼容处理本地的日志文件。
随着分布式计算处理的开始或结束，分布存放的文件和套接字将会不断增加或减少，这种变化是需要被监控的，因此要在每一台机器上配置Agent。现在绝大多数的监控系统都要求通过特殊的协议传送数据，Chukwa也不例外，所以在Chukwa中，Agent不直接负责接收数据，取而代之的是一个可执行环境：提供可配置的承载数据模块（Adaptor）。这些Adaptor在文件系统或被监控的应用中的功能是读取数据，Adaptor的输出是一个逻辑上的比特流，单个数据流对应单个文件，或者在相应套接字上接收对应的数据包或一系列重复调用的UNIX程序。数据流被存储成序列块，每一个数据块由一些流级别的元数据（Stream-level metadata）加上一个数组比特构成。启动Adaptor可以通过UNIX命令来完成。Adaptor能够扫描目录，追踪新创建的文件。这样Adaptor便能够接收UDP消息，包括系统日志（Syslog），特别是可以不断地追踪日志，将日志更新到文件中。并且Adaptor是可以互相嵌套的，例如，一个Adaptor可以在内存中缓存来自另一个Adaptor的输出。在单个线程内运行所有的Adaptor，可以让管理员在资源受限的商业环境中实施一些必要的资源限制：内存的使用可以通过JVM堆的使用进行控制；CPU的使用可以通过进程优先级（Nice）控制；带宽的限制可以通过Agent进程协调，即设置它在网络中的最大传输速率，只要超过最大可利用的带宽，就在Agent进程中设置固定大小的队列，或者当Collector响应缓慢时，Collector会自动调节进程中Adaptor的工作。
Agent的主要工作是负责开始和停止Adaptors，并且通过网络传输数据。Agent支持行定位控制协议，方便程序对Agent控制。该协议包含的命令有：启动和停止Adaptor，以及查询它们的状态，也允许外部程序在开始读日志时重新配置Chukwa。Agent进程也将会定期查询Adaptor状态，并且存储Adaptor状态在检查点（Checkpoint）文件中，每一个Adaptor负责记录足够的状态以便能够在需要的时候完整地恢复原先的状态，Checkpoint只是包含状态，因此Checkpoint文件是很小的，一般每一个Adaptor的Checkpoint文件只有几百比特。
Agent和Adaptor会自动设置一些元数据，但是其中有两个元数据是需要用户自己定义的：集群名字和数据类型。集群名字被设置在etc/chukwa/chukwa-agent-conf.xml中，是在每一个进程当中的全局变量。数据类型描述了由Adaptor实例收集的数据类型，在启动实例时，它必须已经指定。下面的表17-1列举了块的元数据字段。
Adaptors需要以序列号（Sequence ID）作为参数，以便在崩溃后能重新恢复到之前的状态。在启动Adaptor时，通常会把序列号置为0，但是有时候也会为了其他的目的将序列号置为其他值，例如，只想追踪文件的下半部分。
17.2.2 收集器
现在介绍Chukwa架构中Collector的模型。如果每一个Agent都直接向HDFS中写入数据，那么将会产生许多小文件，所以Chukwa使用Collector技术，由单个Collector线程处理多个来自于Agent的数据，每一个Collector将它接收的数据写到单个输出文件中，这个文件放在数据宿（Data Sink）目录下，这就减少了单个机器或单位时间内Adaptor产生的文件数，同时也减少了整个集群产生的文件数。从某种意义上来讲，Collector的存在减轻了大量的低速率数据源和优化过的少量高速率文件系统间写入的匹配问题，Collector会定期关闭它们的输出文件，同时重新命名该文件来标记其可以被进一步处理，并且开始写另一个新的文件。这个过程被称为文件轮转。一个MapReduce作业定期压缩收集到的日志文件并且将它们合并成一个文件。
Chukwa不同于其他监控系统的地方就是它利用了Collector技术。在Collector中没有实施任何可靠性策略，Chukwa的可靠性是依赖于系统端到端的协议。在Chukwa的可靠路径中，Collector以标准的Hadoop序列文件（sequencefile）格式写数据。这种格式使MapReduce的多路处理更加容易。
Chukwa Agent在分配Collector时也没有实施动态负载均衡方法，而是由Agent随机选择Collector轮询，直到有一个可以工作为止，而后Agent将独占该Collector，直到Agent接受到报错信息，这时才会转移到一个新的Collector上，如图17-3所示。
该方法的好处是在文件系统写数据之前，限定了由于Collector故障受影响的Agent的数量，这也避免了故障扩散，否则会发生每一个Agent都被迫对任意一个Collector所发生的故障做出响应的情况。这种情况会造成Collector间的负载不均衡。但在实际的应用中该问题造成的影响不大，Collector不太会饱和。
为了处理过载的情况，Agent重新询问Collector是有特定方法的。如果Agent向一个Collector中写入数据失败，那么该Collector被标记为“坏的”（bad），并且该Agent将在再次写入之前等待一个系统设置的时间。因此，如果所有Collector过载，一个Agent将会询问每一个Collector，其结果都将会是访问失败，这样Agent会等待几分钟后再次访问Collector。
在Collector端筛选数据有许多优点，如Collector是IO约束型，不是CPU约束型，这意味着CPU资源可以根据作业的状态进行分配，进一步说，也就是Collectors是无状态的，只需在机器间简单增加更多的Collector即可。
图 17-3 Agent的可靠性实施
17.2.3 归档器和分离解析器
Chukwa为我们定制了一系列MapReduce作业，这些作业大体上可以分为两类：归档（Archiving）和分离解析（Demux）。
归档器从HDFS的块（Chunk）中抽取数据作为输入，然后将数据进行排序、分组。在这一过程中归档器并不对数据内容进行分析或修改，它会按照不同的方式将数据进行分组。归档器能去除重复数据，并探查到数据丢失，重复地调用该作业可让数据随时间不断压缩到一个大文件中。Chukwa提供了一些工具搜索归档器产生的文件。
分离解析器的功能是抽取记录并解析，使之变换成可以利用的记录，以减少文件数目和降低分析难度。Demux的实现是通过在数据类型和配置文件中指定的数据来处理类并执行相应的数据分析工作的。一般是把非结构化的数据结构化，抽取其中的数据属性。由于Demux的本质是一个MapReduce作业，所以可以根据需求制定Demux作业来进行各种复杂的逻辑分析。Chukwa提供的Demux interface可以通过Java语言很方便地扩展。在之前没有Demux的版本中，Chukwa引入了Archiving的MapReduce作业，按照集群、日期和数据类型来分类数据。这种存储模型匹配了使用数据的传统作业模式，简化了写作业通过基于数据的时间、来源和类型提纯数据的过程。例如，存储用户日志用14天标记，而存储系统日志则用年标记。
Chukwa支持用正则表达式来查询文件的元数据和数据内容，对于繁重和复杂的任务，用户可以运行特定的MapReduce作业去收集数据。此外，Chukwa完整地整合了Pig（见第14章“Pig详解”），以提供更加强大的搜索功能。
17.2.4 HICC
HICC作为Chukwa的子项目，其重要功能是可视化系统性能指标。HICC能够显示传统系统的度量数据，例如系统资源空闲比率、CPU的负载、磁盘写数据的速度，以及应用层的统计数据（如本地机器内map任务数、Hadoop块迁移数量等）等。HICC也能够显示使用每一个节点日志信息的SALSA作业执行模型状态机和Mochi可视化框架[1，2]。利用Chukwa可视化功能可以清楚看到集群中的作业是否在被均匀传播。HDFS对于读请求有很长的延迟，因此在执行交互查询工作时，反应会比较慢，而HICC抽取数据是使用批插入的方式向SQL数据库中插入通过MapReduce处理收集到的数据。MapReduce作业默认每5分钟执行一次，因此显示数据至少比实时慢5分钟。HICC也可以支持集群性能的调试和Hadoop作业执行的可视化等应用。在这些应用中，延迟并不是问题。目前，HICC不需要Chukwa的可靠性传输，但是它依赖于Chukwa收集数据和MapReduce处理数据。
17.3 Chukwa的可靠性
容错能力是Chukwa设计的一个重要指标。即使在系统崩溃、网络连接中断情况下，也不能丢失数据。Chukwa的方案与其他分布式系统在本质上的不同是其分布式存储日志的方式。该方式会将数据源的相应状态写入数据节点，由Agent管理节点崩溃的情况，Agent通常会为自己的状态设置检查点（Checkpoint）。该Checkpoint描述了每一个当前被监控的数据流，并且清查有多少来自流中的数据已经被提交到DataSink上。在节点崩溃后，Chukwa使用后台管理工具去重启Agent。
在Agent进程恢复后，每一个Adaptor将从最近的Checkpoint状态重启。这意味着Agent将重新发送没有提交的数据，或者重新发送在最后的Checkpoint记录之后所提交的数据。在恢复过程中所产生的重复块将通过Archiving作业滤除掉。跟踪文件状态的Adaptor通过文件的定位固定偏移量来恢复文件内容，并且Adaptor也能够监控临时数据源，如网络的套接字。在这种情况下，Adaptor通过重新发送数据就能很容易恢复丢失的数据，因此丢失数据将不是一个大的麻烦，例如丢失一分钟的系统度量信息。因为在默认提供封装好的库的Adaptor中已经缓存了来自不稳定数据源的数据，所以就可以建立不带容错机制的Collector。Agent将检查Collector对于文件系统的状态，这个状态会起到侦测系统故障并从故障中恢复的作用。恢复则完全由Agent处理，并不需要从失效的Collector中获取信息。然后Agent发送数据到Collector, Collector将写数据存储到HDFS文件中，并且也定位了数据在文件中的位置。这个位置很容易就能确定，因为每一个文件仅是通过一个Collector写的，唯一需要满足的要求就是排列数据和增加其长度。
Collector将不监控已写入的文件，也不存储每一个Agent状态，轮询Collector而不是直接对文件系统访问是为了减少文件系统主节点的负载，把Agent从存储系统的烦琐中解脱出来。在出现故障时，Agent将恢复上一个Checkpoint，并且选择一个新的Collector。
17.4 Chukwa集群搭建
 17.4.1 基本配置要求
Chukwa可以工作在任何POSIX平台上，但是GNU/Linux是唯一的已经被广泛测试的商用平台，不过，几个Chukwa研发团队也在Mac OS X上成功使用了Chuwka。目前将GNU/Linux作为安装Chukwa的平台是比较理想的选择。下面是安装Chukwa的先决条件：
必须安装Java 1.6；
必须安装Hadoop 0.20.205.0或以上版本；
安装HBase 0.90.4或以上版本；
Chukwa集群管理脚本需要安装SSH。SSH功能用户Chkuwa执行集群管理脚本，但是对于Chukuwa的运行并不是必需的。如果不使用SSH用户可以采用其他方法来维护Chukwa集群。
17.4.2 Chukwa的安装
Chukwa项目的运行至少需要如下三部分的支持：
Hadoop集群和HBase集群，Chukwa依赖其来存储并处理数据。
一个Collector进程，将收集到的数据写入HBase中。
一个或多个Agent进程，它发送监控数据到Collector，我们将运行的Agent进程的节点视为被监控点。
另外，可以使用定制的脚本文件来监控集群的健康状态，并使用HICC来图形化显示集群的状态。
下面我们以三台机器为例介绍如何配置Chukwa来监控Hadoop分布式集群，集群中三台机器的主机名分别为：master、slave1和slave2，其中master作为Hadoop的NameNode和Hbase的HMaser。
1.安装Chukwa
首先需要在官网（http：//incubator.apache.org/chukwa/）上下载Chukwa，然后将其解压在合适的目录下。当前Chukwa的最新版本为0.5.0，下面以此版本为例进行介绍。下载并解压Chukwa后，我们设置Chkuwa的环境变量如下所示：
export CHUKWA_HOME=/home/hadoop/hadoop-1.0.1/chukwa-incubating-0.5.0
export CHUKWA_CONF_DIR=$CHUKWA_HOME/etc/chukwa
export PATH=$CHUKWA_HOME/bin：$CHUKWA_HOME/sbin：$CHUKWA_CONF_DIR：$PATH
从上面的配置中可以看出，我们将Chukwa放在Hadoop目录下便于管理。在Chukwa 0.5.0版本中，配置文件并不在根目录下的conf文件中，conf文件已经被删除，取而代之的是Chukwa根目录下的$CHUKWA_HOME/etc/chukwa目录。另外，Chukwa的集群管理脚本也并非全部在bin目录下，而是在bin和sbin两个目录下。故此，我们将$CHUKWA_HOME/bin和$CHUKWA_HOME/sbin同时加入PATH中方便操作。
2.Hadoop和HBase集群的配置
Hadoop和HBase的安装与配置我们已经在前面章节详细讲过，这里不再赘述。这里主要介绍为了安装Chukwa而对Hadoop和HBase集群配置的进一步修改。
首先按照如下命令，将Chukwa文件复制到Hadoop中：
cp$CHUKWA_CONF_DIR/hadoop-log4j.properties$HADOOP_CONF_DIR1/log4j.properties
cp$CHUKWA_HOME/etc/chukwa/hadoop-metrics2.properties$HADOOP_CONF_DIR/hadoop-
metrics2.properties
cp$CHUKWA_HOME/share/chukwa/chukwa-0.5.0-client.jar$HADOOP_HOME/lib
cp$CHUKWA_HOME/share/chukwa/lib/json-simple-1.1.jar$HADOOP_HOME//lib
配置完成后重启Hadoop集群，接着进行HBase的设置。我们需要在HBase中创建数据存储所需要的表，如下所示：
bin/hbase shell＜CHUKWA_HOME/etc/chukwa/hbase.schema
表的模式Chukwa已经定义好，我们只需要通过HBase shell将其导入即可。
3.Collector的配置
首先我们对$CHUKWA_CONF_DIR/chukwa-env.sh进行配置。该文件为Chukwa的环境变量，大部分的脚本都需要从该文件中读取关键的全局Chukwa配置信息。我们需要对以下变量进行设置：
export JAVA_HOME=/usr/lib/jvm/java-6-sun-1.6.0.06
export HBASE_HOME=/home/hadoop/hadoop-1.0.1/hbase-0.92.1
export HBASE_CONF_DIR=$HBASE_HOME/conf
export HADOOP_HOME=/home/hadoop/hadoop-1.0.1
export HADOOP_CONF_DIR=$HADOOP_HOME/conf
注意 如果已经在系统环境变量中（如/etc/profile文件）配置了上述参数，那么这里可以省略。需要格外注意的是，chukuwa-env.sh中参数的优先级要高于/etc/profile文件中相同的参数，一定要保证优先级高的参数设置正确。
另外，当需要运行多台机器作为收集器的时候，要修改$CHUKWA_CONF_DIR/collectors文件，该文件定义了哪台机器运行收集器进程。配置文件格式与Hadoop的$HADOOP_CONF_DIR/slaves文件类似，每行代表一台机器。在默认情况下该文件只包含一行记录：配置localhost运行收集器进程。
另外，$CHUKWA_CONF_DIR/initial_Adaptors文件主要用于设置Chukwa监控哪些日志，以及以什么方式、什么频率来监控等。使用默认配置即可，如下所示：
add sigar.SystemMetrics SystemMetrics 60 0
add SocketAdaptor HadoopMetrics 9095 0
add SocketAdaptor Hadoop 9096 0
add SocketAdaptor ChukwaMetrics 9097 0
add SocketAdaptor JobSummary 9098 0
CHUKWA_CONF_DIR/chukwa-collector-conf. xml维护了Chukwa的基本配置信息。我们需要通过该文件指定HDFS的位置，如下所示：
＜property＞
＜name＞writer.hdfs.filesystem＜/name＞
＜value＞hdfs：//Master：9000/＜/value＞