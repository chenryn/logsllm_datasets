title:NoDoze: Combatting Threat Alert Fatigue with Automated Provenance
Triage
author:Wajih Ul Hassan and
Shengjian Guo and
Ding Li and
Zhengzhang Chen and
Kangkook Jee and
Zhichun Li and
Adam Bates
NODOZE: Combatting Threat Alert Fatigue with
Automated Provenance Triage
Wajih Ul Hassan(cid:5), Shengjian Guo‡, Ding Li∗, Zhengzhang Chen∗, Kangkook Jee∗, Zhichun Li∗, Adam Bates(cid:5)
(cid:5) University of Illinois at Urbana-Champaign
∗ NEC Laboratories America, Inc.
{dingli,zchen,kjee,zhichun}@nec-labs.com
‡ Virginia Tech
PI:EMAIL
{whassan3,batesa}@illinois.edu
Abstract—Large enterprises are increasingly relying on threat
detection softwares (e.g., Intrusion Detection Systems) to allow
them to spot suspicious activities. These softwares generate alerts
which must be investigated by cyber analysts to ﬁgure out if
they are true attacks. Unfortunately, in practice, there are more
alerts than cyber analysts can properly investigate. This leads to
a “threat alert fatigue” or information overload problem where
cyber analysts miss true attack alerts in the noise of false alarms.
In this paper, we present NODOZE to combat this challenge
using contextual and historical information of generated threat
alert. NODOZE ﬁrst generates a causal dependency graph of
an alert event. Then,
it assigns an anomaly score to each
edge in the dependency graph based on the frequency with
which related events have happened before in the enterprise.
NODOZE then propagates those scores along the neighboring
edges of the graph using a novel network diffusion algorithm
and generates an aggregate anomaly score which is used for
triaging. We deployed and evaluated NODOZE at NEC Labs
America. Evaluation on our dataset of 364 threat alerts shows that
NODOZE consistently ranked the true alerts higher than the false
alerts based on aggregate anomaly scores. Further, through the
introduction of a cutoff threshold for anomaly scores, we estimate
that our system decreases the volume of false alarms by 84%,
saving analysts’ more than 90 hours of investigation time per
week. NODOZE generates alert dependency graphs that are two
orders of magnitude smaller than those generated by traditional
tools without sacriﬁcing the vital
information needed for the
investigation. Our system has a low average runtime overhead
and can be deployed with any threat detection software.
I.
INTRODUCTION
Large enterprises are increasingly being targeted by Ad-
vanced Persistent Threats (APTs). To combat these threats,
enterprises are deploying threat detection softwares (TDS)
such as intrusion detection system and security information and
event management (SIEM) tools. These softwares constantly
monitor the enterprise-wide activities and generate a threat
alert if a suspicious activity happens. Cyber analysts then
manually sift through these alerts to ﬁnd a signal that indicates
a true attack.
Network and Distributed Systems Security (NDSS) Symposium 2019
24-27 February 2019, San Diego, CA, USA
ISBN 1-891562-55-X
https://dx.doi.org/10.14722/ndss.2019.23349
www.ndss-symposium.org
Fig. 1: Growth of alerts in an enterprise during a given month.
Unfortunately, these automated systems are notorious for
generating high rates of false alarms [59], [2], [6]. According
to a recent study conducted by FireEye, most organizations
receive 17,000 alerts per week where more than 51% of the
alerts are false positives and only 4% of the alerts get properly
investigated [4]. Due to an enormous number of alerts, cyber
analyst face “threat alert fatigue”1 problem and important alerts
get lost in the noise of unimportant alerts, allowing attacks to
breach the security of the enterprise. One example of this is
Target’s disastrous 2013 data breach [15], when 40 million
card records were stolen. Despite numerous alerts, the staff at
Target did not react to this threat in time because similar alerts
were commonplace and the security team incorrectly classiﬁed
them as false positives. In Fig. 1, we demonstrate the growth
of alerts generated by a commercial TDS [8] at NEC Labs
America comprising 191 hosts.
The threat alert fatigue problem is, at least partially, caused
by the fact that existing academic [43], [29] and commer-
cial [3], [5] TDS use heuristics or approaches based on single
event matching such as an anomalous process execution event
to generate an alert. Unfortunately, in many cases, a false alert
may look very similar to true alert if the investigator only
checks a single event. For example, since both ransomware
and ZIP programs read and write many ﬁles in a short pe-
riod of time, a simple ransomware detector that only checks
the behavior of a single process can easily classify ZIP as
ransomware [40]. Even though contextual alerting has proven
to be most effective in the alert triage process [27], existing
TDS usually do not provide enough contextual information
about alerts (e.g., entry point of invasion) which also increases
investigators’ mean-time-to-know.2
1A phenomenon when cyber analysts do not respond to threat alerts because
they receive so many each day.
2Mean-time-to-know measures how fast cyber analysts can sort true threats
from noise when they get threat alerts.
 10 100 1000 10000 5 10 15 20 25 30No. of Alerts (log scaled)DaysData provenance analysis [41], [26] is one possible remedy
for the threat alert fatigue problem. Data provenance can
provide the contextual information about the generated alert
through reconstructing the chain of events that lead to an alert
event (backward tracing) and the ramiﬁcations of the alert
event (forward tracing). Such knowledge can better separate
a benign system event from a malicious event even though
they may look very similar when viewed in isolation. For
example, by considering the provenance of an alert event, it is
possible to distinguish ransomware from ZIP: the entry point
of ransomware (e.g., email attachment) is different from the
ZIP program.
Although a provenance-based approach sounds promising,
leveraging data provenance for triaging alerts suffers from
two critical limitations: 1) labor intensive – using existing
techniques still require a cyber analyst to manually evaluate
provenance data of each alert in order to eliminate false alarms,
and 2) dependency explosion problem – due to the complexity
of modern system, current provenance tracking techniques will
include false dependencies because an output event is assumed
to be causally dependent on all preceding input events [46].
In our scenario, due to this problem, a dependency graph of a
true attack alert will include dependencies with benign events
which might not be causally related to the attack. This problem
makes the graph very huge (with thousands or even millions of
nodes). Such a huge graph is very hard for security experts to
understand [36], making the diagnosis of attacks prohibitively
difﬁcult.
In this paper, we propose NODOZE, an automatic alert
triage and investigation system based on provenance graph
analysis. NODOZE leverages the historical context to auto-
matically reduce the false alert rate of existing TDS. NODOZE
achieves this by addressing the aforementioned two limitations
of existing provenance analysis techniques: it is fully auto-
mated and can substantially reduce the size of the dependency
graphs while keeping the true attack scenarios. Such concise
dependency graphs enable security experts to better understand
the attacks, discover vulnerabilities quickly, accelerating inci-
dent response.
Our approach is based on the insight that the suspiciousness
of each event in the provenance graph should be adjusted
based on the suspiciousness of neighboring events in the
graph. A process created by another suspicious process is
more suspicious than a process created by a benign process.
To this end, our anomaly score assignment algorithm is an
unsupervised algorithm with no training phase. To assign
anomaly scores to the events, NODOZE builds an Event Fre-
quency Database which stores the frequencies of all the events
that have happened before in the enterprise. After anomaly
score assignment, NODOZE uses a novel network diffusion
algorithm to efﬁciently propagate and aggregate the scores
along the neighboring edges (events) of the alert dependency
graph. Finally, it generates an aggregate anomaly score for the
candidate alert which is used for triaging.
To tackle the dependency explosion problem in the alert
investigation process, we propose the notion of behavioural
execution partitioning. The idea is to partition a program
execution based on normal and anomalous behaviour and
generate most anomalous dependency graph of a true alert.
This allows cyber analyst to focus on most anomalous events
which are causally related to the true alert which accelerates
the alert investigation process.
We implement NODOZE and event frequency database in
9K and 4K lines of Java code respectively. We deployed and
evaluated our system at NEC Labs America. For evaluation we
used 1 billion system events spanning 5 days which generated
364 alerts using an exemplar TDS [8]. These alerts include
10 APT attack cases and 40 recent malware simulation while
all
the other alerts are false alarms. Experimental results
show that NODOZE improves the accuracy of existing TDS
by reducing the false alarms by 84%. Moreover, NODOZE
generates dependency graphs for true alerts that are two orders
of magnitude smaller than those generated by traditional tools.
In summary, this paper makes the following contributions:
• We propose NODOZE, an automated threat alert triage
• We present a novel network diffusion algorithm to prop-
agate anomaly scores in dependency graphs enabling the
calculation of aggregate anomaly scores for threat alerts.
• We introduce the notion of behavioural execution par-
titioning, a new technique for combating dependency
explosion in provenance graph that is applicable to threat
alerts.
• We present a concrete implementation and thorough
evaluation of NODOZE. The results show that NODOZE
consistently ranked the true alerts higher than false alarms
and generates concise dependency graphs for true alerts.
system for enterprise settings.
II. BACKGROUND & MOTIVATION
In this section, we use an attack example to illustrate the
effectiveness and utility of NODOZE as an alert triage system
with two aspects: 1) ﬁltering out false alarms to reduce alert
fatigue, and 2) concise explanation of the true alerts using
dependency graphs to accelerate alert investigation process. We
will use the example of a WannaCry ransomware attack [18] in
an enterprise environment. This attack was simulated as a live
exercise at NEC Labs America; we describe the experimental
setup used for the simulation in §VIII.
A. Motivating Attack Example
WannaCry ransomware is a popular attack that affected
around 0.2 million systems across 150 countries in May
2017 [12]. It is essentially a cryptoworm which targets com-
puters running the Microsoft Windows OS with vulnerable
EternalBlue [14]. It exploits this vulnerability to gain access
to the machines and encrypts data on those machines.
Scenario. Consider a front desk person in an enterprise
who one day visits several websites using Internet Explorer
to search for pdf reader software. After visiting several links,
the front desk person accidentally downloads a malware
(springs.7zip) from a malicious website and then runs the
malware thinking of it as pdf reader software. This malware
opens a backdoor to the attacker’s server and then searches for
EternalBlue vulnerable machines in the front desk’s enterprise
network. Once vulnerable machines are found the attacker
downloads the ﬁle encryptor and starts to encrypt ﬁles on those
vulnerable machines. After some time the front desk person’s
PC starts to run very slow so front desk person calls technical
2
Fig. 2: WannaCry attack scenario described in §II-A. (a) Part of the threat alerts’ dependency graph generated by prior approaches [26], [41].
Some edges have been omitted for clarity. (b) Concise dependency graph generated by NODOZE.
(a)
(b)
support. The technical support person downloads and executes
a diagnostic tool (collect-info.ps1) on front desk person’s
PC from an internal software repository, which runs some
diagnostic commands including Tasklist and Ipconfig. All of
the output is copied to a ﬁle sys-report.txt, which is then
transferred to a remote machine for further investigation. On
the remote machine, the technical support person runs several
bash commands to check the ﬁle contents and ﬁgure out the
issue with the front desk person’s computer.
Alerts Investigation. During the above attack scenario, two
threat alerts were generated by the underlying TDS while
over 100 total threat alerts were generated over the course
of the day. The ﬁrst alert event E1, was generated when
malware made several connections to remote machines in the
enterprise. The second alert event E2 was generated when
technical support diagnostic tool initiated a remote connection
to a secure machine. Note that, at a single event level, both
alert events E1 and E2 look very similar; both processes making
an unusual connection to a remote machine in the network.
To investigate the alerts and prepare a response, the cy-
ber analyst performs a causality analysis. Provenance-based
tools [41], [26] process individual events between system
objects (e.g.,, ﬁles and network sockets) and subjects (e.g.,,
processes) to construct a causal dependency graph. Note that
cyber analysts can use these graphs to understand the context
of the alert by using a backward tracing query which starts
from the given symptom event (alert) and then identiﬁes all the
subjects and objects that the symptom directly and indirectly
depends on. Using a forward tracing query, the analyst can
then identiﬁes all the effects induced by the root cause of the
alert. Fig. 2a shows the simpliﬁed dependency graph generated
by existing tools for alert events E1 and E2. In this graph and
also the rest of the paper, we use diamonds, ovals, boxes, and
dashed arrows to represent sockets, ﬁles, processes, and alert
events respectively.
B. Existing Tools Limitations
Existing provenance trackers when combined with TDS
for alert triage and investigation process suffer from following
limitations:
Alert Explosion & Manual Labor.
Even if the TDS
identiﬁes an anomalous event related to the attack, cyber
analysts are barraged with alerts on a daily basis and face
the problem of ﬁnding a “needle in a haystack”. Existing
automated TDS are notorious for generating a high amount
of false alarms [59], [2], [6], [34], [21]. Cyber analysts are in
short supply, so organizations face a key challenge in managing
the enormous volume of alerts they receive using the limited
time of analysts [4]. Many heuristic- and rule-based static
approaches have been proposed to mitigate this problem [68],
[22], [45], [32]. However, there are still too many threat alerts
for the analysts to manually investigate in sufﬁcient depth
using alerts’ dependency graphs which are also usually very
complex. During the day of the attack, the TDS generated
over 100 threat alerts with an average of 2K vertices in each
alert’s dependency graph; and only 1 threat alert was related
to WannaCry attack while all other were false alarms.
Dependency Explosion. Most existing provenance trackers
suffer from the dependency explosion problem, generating
graphs similar to Fig. 2a. The dependency inaccuracy is mainly
caused by long running processes that interact with many
subjects/objects during their
lifetime. Existing approaches
consider the entire process execution as a single node so
that all input/output interactions become edges to/from the
process node. This results in considerably large and inac-
curate graphs. Consider the Internet Explorer IExplorer.exe
vertex in our example dependency graph which is shown in
Fig. 2a. When cyber analysts try to ﬁnd the ancestry of the
downloaded malware ﬁle (springs.7zip) and diagnostic tool
ﬁle (collect-info.ps1), they will unable to determine which
incoming IP/socket connection vertex is related to the malware
ﬁle and which one belongs to the diagnostic tool ﬁle.