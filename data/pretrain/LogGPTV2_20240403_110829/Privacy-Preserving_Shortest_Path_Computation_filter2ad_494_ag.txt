algorithms. In ICML, 2004.
27
A Security Proofs
In this section, we show that the protocol in Figure 3 securely computes the shortest paths functionality
in the presence of a malicious client, and provides privacy against a malicious server. To simplify our
proofs, we work in the OT-hybrid model where we assume the parties have access to an ideal 1-out-of-n
OT functionality [Kil88]. Speciﬁcally, in the real protocol, we replace every OT invocation with an oracle
call to a trusted party that implements the OT functionality: the sender sends the database of records
(r1, . . . , rn) to the trusted party and the receiver sends an index i ∈ [n] to the trusted party. The trusted
party then gives the receiver the record ri. Security in the standard model then follows by instantiating
the ideal OT functionality with an OT protocol that provides security against malicious clients [HL10] and
privacy against malicious servers, and then invoking the sequential composition theorem of [Can00].
A.1 Proof of Theorem 4.6
At a high level, privacy for the client’s location follows from the fact that the server’s view in the protocol
execution consists only of its view in the OT and PIR protocols. By assumption, both the OT protocols and
the PIR protocols provide privacy for the client’s input, so the claim follows. We now show this formally.
As noted at the beginning of Appendix A, we work in the OT-hybrid model, where we replace each OT
invocation with an oracle call to an ideal OT functionality. First, we state the deﬁnition of privacy as it
applies to the PIR protocol.
Deﬁnition A.1 (Privacy for PIR). Fix a security parameter λ ∈ N, and let π be a PIR protocol. Let
A be a non-uniform PPT server for π. Let viewπ,A(1λ,D, i) denote the view of adversary A in the PIR
protocol on database D ∈ {0, 1}∗ (the server’s input) and index i ∈ {0, 1}∗ (the client’s input). Then, π is
a private PIR protocol if for all non-uniform PPT servers A, databases D ∈ {0, 1}∗, indices i, i(cid:48) ∈ {0, 1}∗
where |i| = |i(cid:48)|, we have that
viewπ,A(1λ,D, i)
c≈ viewπ,A(1λ,D, i(cid:48)).
Let A be a malicious server for the private shortest paths protocol in Figure 3. We construct an
ideal-world simulator S such that the distribution of outputs of A in the real protocol is computationally
indistinguishable from the outputs of S in the ideal world. This suﬃces to prove that the protocol in
Figure 3 provides privacy against a malicious server. The simulator S begins by running A. Below, we
describe how S simulates the view for A in the protocol execution.
Setup.
In the setup phase of the protocol, the simulator does nothing. This is the correct behavior
because in the OT-hybrid model, the adversary A does not receive any messages during the setup phase.
Round. On each round of the protocol, the simulator S plays the role of the client in the PIR protocol
and requests for record 0 in both the source database and in the destination database. Again, since we are
working in the OT-hybrid model, these are the only messages adversary A obtains in the real protocol.
At the end of the protocol execution, adversary A will output some function of its view of the protocol
execution. The simulator S echoes this output to the environment.
Correctness of the simulation. To conclude the proof, it suﬃces to show that the view S simulates for
A is computationally indistinguishable from the view A expects in the real protocol. This condition holds
vacuously in the setup phase of the protocol. Let view(r)A be the adversary’s view on the rth round of the
PIR,A(1λ,Ddst, idst)
protocol. The view view(r)A may be written as view(r)A =
,
PIR,A(1λ,Dsrc, isrc), view(r)
view(r)
(cid:111)
(cid:110)
28
where Dsrc,Ddst are the encoding databases A chooses in the real protocol, and isrc, idst are the indices of
the records the client chooses in the real protocol. By privacy of the PIR (Deﬁnition A.1), it follows that
view(r)
view(r)
PIR,A(1λ,Dsrc, isrc)
PIR,A(1λ,Ddst, idst)
c≈ view(r)
c≈ view(r)
PIR,A(1λ,Dsrc, 0)
PIR,A(1λ,Ddst, 0).
Since the request for the source encodings and for the destination encodings constitute two independent
instances of the PIR protocol, we conclude that the view S simulates for A in each round of the protocol
is computationally indistinguishable from the view A expects in the real protocol. Thus, the output of S
in the ideal-world execution is computationally indistinguishable from that of A in the real world.
A.2 Proof of Theorem 4.5
Before we prove Theorem 4.5, we describe the simulatability requirement we require on the garbled circuit
encodings used in the protocol in Figure 3. Intuitively, we require that the garbled circuit encodings can
be entirely simulated given the output of the computation; that is, the garbled circuit together with one
set of encodings do not reveal any information about the underlying inputs other than what is explicitly
revealed by the output. Bellare et al. formalize this notion in [BHR12]. Here, we give a simpliﬁed deﬁnition
adapted from [GKP+13] and specialized to the case of Yao’s garbling scheme [Yao86, LP09].
Deﬁnition A.2 (Yao Garbling Scheme). A Yao garbling scheme ΠYao for a family of circuits {Cn}n∈N
(where Cn is a set of Boolean circuits on n input bits) consists of three algorithms (Yao.Garble, Yao.Encode,
Yao.Eval) where
(cid:9)
C ∈ Cn for some n and outputs a garbled circuit ˜C along with a secret key sk where sk =(cid:8)L0
(cid:9)
• Yao.Encode(sk, x) is a deterministic algorithm that takes the secret key sk = (cid:8)L0
is a set containing n pairs of encodings L0
• Yao.Garble(1λ, C) is a randomized algorithm that takes as input a security parameter λ and a circuit
i∈[n]
i , L1
i
i ∈ {0, 1}∗.
i , L1
input x = x1 ··· xn ∈ {0, 1}n, and outputs an encoding ˜x = {Lxi
of x is the subset of encodings in sk associated with the bits of x.
i∈[n] and an
i }i∈[n]. Speciﬁcally, the encoding ˜x
i , L1
i
• Yao.Eval( ˜C, ˜x) is a deterministic algorithm that takes a garbled circuit ˜C and a set of encodings
˜x = {Lxi
i }i∈[n] for some x ∈ {0, 1}n and outputs a value z.
Deﬁnition A.3 (Correctness). A Yao garbling scheme ΠYao = (Yao.Garble, Yao.Encode, Yao.Eval) for a
family of circuits {Cn}n∈N is correct if for all n = poly(λ), C ∈ Cn, and x ∈ {0, 1}n, the following holds.
Letting ( ˜C, sk) ← Yao.Garble(1λ, C), then with overwhelming probability in λ, we have
where the probability is taken over the random coins used in Yao.Garble.
Yao.Eval( ˜C, Yao.Encode(sk, x)) = C(x),
Deﬁnition A.4 (Input Privacy). A Yao garbling scheme ΠYao = (Yao.Garble, Yao.Encode, Yao.Eval) for a
family of circuits {Cn}n∈N is input-private if there exists a PPT simulator SYao such that for all n = poly(λ),
C ∈ Cn, x ∈ {0, 1}n, the following holds:
(cid:110)
( ˜C, sk) ← Yao.Garble(1λ, C) ; ( ˜C, Yao.Encode(sk, x))
(cid:111) c≈ SYao(1λ, C, C(x)).
Lemma A.5 ([Yao86, LP09]). Assuming one-way functions exist, there exists a Yao garbling scheme
(Deﬁnition A.2) that is input-private (Deﬁnition A.4).
29
Next, we note that the aﬃne encodings from Section 4, Eq. (4) provide statistical privacy.
Lemma A.6 ([AIK14, Lemma 5.1], adapted). Fix a ﬁnite ﬁeld Fp of prime order p, and take z1, . . . , zd ∈
Fp. Deﬁne the function f : Fd
be the
aﬃne encoding functions from Eq. (6). Then, there exists a PPT simulator Sac such that for all x, y ∈ Fd
and z1, . . . , zd ∈ Fp,
p → Fp where f (x, y) = (cid:104)x, y(cid:105) +(cid:80)
i∈[d] zi. Let Laﬃne
and Laﬃne
p × Fd
x
p
y
(cid:17)(cid:111)
Laﬃne
x
(x; r), Laﬃne
y
(y; r)
.
Sac(f (x, y)) ≡(cid:110)
r←− F3d
p
r
;
(cid:16)
Proof of Theorem 4.5. To show Theorem 4.5, we ﬁrst deﬁne the following hybrid experiments:
• Hybrid Hyb0: This is the real experiment (Deﬁnition 4.1).
• Hybrid Hyb1: Same as Hyb0, except the protocol execution aborts if the client succeeds in making
an “inconsistent” query (described below).
• Hybrid Hyb2: This is the ideal experiment (Deﬁnition 4.2).
Informally speaking, we say that the client succeeds in making an “inconsistent” query if on some round r,
it requests the garbled circuit encodings for values ˆzne and ˆznw that were not the outputs of the arithmetic
circuit, and yet, the client obtains a set of garbled circuit encodings where the garbled circuit evaluation
does not output ⊥. We now specify this property more precisely.
Speciﬁcation of Hybrid Hyb1. Let s, t ∈ [n] be the source and destination nodes the client sends to
the ideal OT functionality in the setup phase of the protocol in Figure 3. Let (s = v0, v1, . . . , vR) be
the shortest path from s to t as deﬁned by the environment’s choice of the next-hop routing matrices
A(ne), B(ne), A(nw), B(nw) in the protocol execution (Deﬁnition 4.1). The protocol execution in Hyb1 pro-
ceeds identically to that in Hyb0, except the protocol execution halts (with output ⊥) if the following bad
event occurs:
On a round 1 ≤ r ≤ R, the client submits ˆzne, ˆznw to the ideal OT functionality where either
ˆzne (cid:54)= αne(cid:104)A(ne)
vr
, B(ne)
t
(cid:105) + βne
or
ˆznw (cid:54)= αnw(cid:104)A(nw)
vr
, B(nw)
t
(cid:105) + βnw,
and Cunblind((ˆzne, γne, δne), (ˆznw, γnw, δnw), k0
ˆzne, ˆznw, vr, and t are the round-speciﬁc values chosen by the server on round r.
nw, k1
ne, k1
ne, k0
ne, vr, t) (cid:54)= ⊥, where all values other than
Figure 5: Abort event in hybrid Hyb1.
Fix a security parameter λ. Let π be a private navigation protocol and let f be the ideal shortest-path
functionality. For a client A, a simulator S and an environment E, we deﬁne the following random variables:
• Hyb0(λ, π,A,E) is the output of experiment Hyb0 with adversary A and environment E. In particular,
Hyb0(λ, π,A,E) = REALπ,A,E (λ) (Deﬁnition 4.1).
• Hyb1(λ, π,A,E) is the output of experiment Hyb1 with adversary A and environment E.
• Hyb2(λ, f,S,E) is the output of experiment Hyb2 with simulator S and environment E. In particular,
Hyb2(λ, f,S,E) = IDEALf,S,E (λ) (Deﬁnition 4.2).
To prove Theorem 4.5, we show the following two claims.
30
Claim A.7. Let λ, µ be the security parameter and statistical security parameter, respectively. Let π be the
protocol in Figure 3 instantiated with secure cryptographic primitives as described in Theorem 4.5. Then,
for all PPT adversaries A, and every polynomial-size circuit family E = {E}λ,
|Pr [Hyb0(λ, π,A,E) = 0] − Pr [Hyb1(λ, π,A,E) = 0]| ≤ negl(λ) + R · 2−µ.
Claim A.8. Let λ, µ be the security parameter and statistical security parameter, respectively. Let π be
the protocol in Figure 3 instantiated with secure cryptographic primitives as described in Theorem 4.5. Let
f be the ideal shortest-paths functionality. Then, for all PPT adversaries A, there exists a PPT adversary
S such that for every polynomial-size circuit family E = {E}λ,
|Pr [Hyb1(λ, π,A,E) = 0] − Pr [Hyb2(λ, f,S,E) = 0]| ≤ negl(λ).
Proof of Claim A.8. We begin by showing Claim A.8. Given a real-world adversary A, we construct an
eﬃcient ideal-world simulator S such that the distribution of outputs of any (possibly malicious) client A
in Hyb1 is computationally indistinguishable from the distribution of outputs of an ideal-world simulator
S in Hyb2. Since the server does not produce any output, this will suﬃce to show that hybrids Hyb1 and
Hyb2 are computationally indistinguishable.
As stated in Section 4.2 and Figure 3, we assume that the topology of the graph G = (V, E), the
number of columns d in the compressed routing matrices, the bound τ on the bit-length of the products of
the compressed matrices, and the total number of rounds R are public and known to both parties in the
protocol execution. Moreover, as described in Figure 3, we assume that p > 2τ +µ+1 where µ ∈ N is the
statistical security parameter. In particular, there exists an element ξ ∈ Fp such that ξ (cid:54)∈ [−2τ , 2τ ].
Speciﬁcation of the simulator. We begin by describing the simulator. We let T denote the trusted
party for the shortest path functionality as deﬁned in the speciﬁcation of the ideal model of execution from
Section 4.2. The simulator starts running adversary A. We describe the behavior of the simulator in the
setup phase of the protocol as well as the behavior on each round of the routing protocol.
Setup.
In the setup phase of the protocol, the simulator S does the following:
1. As in the real protocol, the simulator ﬁrst chooses independent symmetric encryption keys ¯k(1)
src,i, ¯kdst,i
r←−
{0, 1}(cid:96) for all i ∈ [n].
2. When A makes an OT request for an entry s in the source key database, the simulator replies with
src,s. Recall that in the ideal OT functionality, each party just sends its input to the ideal
the key ¯k(1)
functionality, and the ideal functionality sends the requested element to the client.
3. When A makes an OT request for an entry t in the destination key database, the simulator replies
with the key ¯kdst,t to A.
4. Finally, the simulator sends (s, t) to the trusted party T . The trusted party replies to the simulator
with a path (s = v0, . . . , vR).
Round. Next, we describe the behavior of the simulator in each round 1 ≤ r ≤ R of the protocol.
1. The simulator chooses ¯zne, ¯znw
and ¯znw to obtain four sets of encodings ¯Laﬃne
r←− Fp. Then, S invokes the simulator Sac (Lemma A.6) on inputs ¯zne
ne,x , ¯Laﬃne
ne,y , ¯Laﬃne
nw,x , ¯Laﬃne
nw,y .
31
2. Let Cunblind be a circuit computing the neighbor-computation function in Figure 2. As in the real
protocol, the simulator runs Yao’s garbling algorithm on Cunblind to obtain a garbled circuit ¯Cunblind,
along with encoding functions ¯Lunblind
for each of the inputs x to the neighbor-computation function
in Figure 2.
x
3. As in the real protocol, the simulator chooses symmetric encryption keys ¯k(r+1)
src,i
r←− {0, 1}(cid:96) for all
i ∈ [n]. These will be used to encrypt the elements in the source database on the next round of the
protocol.
4. The simulator also chooses four PRF keys ¯k0
ne, ¯k1
ne, ¯k0
nw, ¯k1
nw
r←− {0, 1}ρ, two for each axis ne, nw. As
in the real scheme, the simulator deﬁnes the encryption keys for each direction as follows:
¯kn = F (¯k0
¯ks = F (¯k1
ne, n) ⊕ F (¯k0
ne, s) ⊕ F (¯k1
nw, n)
nw, s)
¯ke = F (¯k0
¯kw = F (¯k1
ne, e) ⊕ F (¯k1
ne, w) ⊕ F (¯k0
nw, e)
nw, w).
5. The simulator prepares the source database Dsrc as follows. Let u = vr−1. If u (cid:54)= ⊥, then the uth
record in Dsrc is an encryption under ¯k(r)
= ( ¯Laﬃne
src,u of the following:
• Arithmetic encodings ¯Laﬃne
• Garbled circuit encodings ¯Lunblind
• Encryptions of the source keys for the neighbors of u in the next round of the protocol under
ne,x , ¯Laﬃne
nw,x ).
(u).
s
s
the direction keys:
Enc(¯kn, ¯k(r+1)