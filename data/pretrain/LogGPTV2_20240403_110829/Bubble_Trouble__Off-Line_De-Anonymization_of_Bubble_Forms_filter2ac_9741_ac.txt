answers questions on behalf of an ofﬁcial test-taker. For
example, a surrogate could perform the entire test, or a
proctor could change answer sheets after the test [11, 17].
The ability to detect when someone other than the autho-
rized test-taker completes some or all of the answers on
a bubble form could help deter this form of cheating.
Depending on the speciﬁc threat and available data,
several uses of our techniques exist. Given past answer
sheets, test registration forms, or other bubbles ostensi-
bly from the same test-takers, we could train a model as
in Section 3.2 and use it to infer whether a surrogate com-
pleted some or all of a test.6 Although the surrogate may
not be in the training set, we may rely on the fact that the
surrogate is less likely to have bubble patterns similar to
the authorized test-taker than to another set of test-takers.
Because our techniques are automated, they could ﬂag
the most anomalous cases—i.e., the cases that would be
rejected even under the least restrictive thresholds—in
large-scale datasets for manual review.
If concern exists that someone changed certain an-
swers after the test (for example, a proctor corrected
the ﬁrst ﬁve answers for all tests), we could search for
questions that are correctly answered at an usually high
rate. Given this information, two possible analysis tech-
niques exists. First, we could train on the less suspicious
questions and use the techniques of Section 3.2 to deter-
mine whether the suspicious ones on a form are from the
same test-taker. Alternatively, we could train on the non-
suspicious answer choices from each form and the sus-
picious answer choices from all forms other than a form
of interest. Given this model, we could apply the tech-
niques of Section 3.1 to see whether suspicious bubbles
on that form more closely match less-suspicious bubbles
on the same form or suspicious bubbles on other forms.
4.2 Elections
Our techniques provide a powerful tool for detecting cer-
tain forms of election fraud but also pose a threat to voter
privacy.
Suppose that concerns exist that certain paper ballots
were fraudulently submitted by someone other than a
valid voter. Although the identity of voters might not
be known for direct comparison to past ballots or other
6Note our assumption that the same unauthorized individual has not
completed both the training bubbles and the current answer sheet.
(a) Person A
(b) Person B
Figure 15: Bubbles from respondents often mistaken for
each other. Both respondents use superﬁcially similar
techniques, leaving unmarked space in similar locations.
guess from 39.0% to 51.1% and the accuracy of the top
ten guesses from 87.2% to 92.4%.
3.4 Discussion
Although our accuracy exceeds 50% for respondent re-
identiﬁcation, the restrictive nature of marking a bubble
limits the distinguishability between users. We brieﬂy
consider a challenging case here.
Figure 15 shows marked bubbles from two respon-
dents that our algorithm often mistakes for one another.
Both individuals appear to use similar techniques to com-
plete a bubble: a circular motion that seldom deviates
from the circle boundary, leaving white-space both in the
center and at similar locations near the border. Unless the
minor differences between these bubbles are consistently
demonstrated by the corresponding respondents, differ-
entiating between these cases could prove quite difﬁcult.
The task of completing a bubble is constrained enough
that close cases are nearly inevitable. In spite of these
challenges, however, re-identiﬁcation and detection of
unauthorized respondents are feasible in practice.
4
Impact
This work has both positive and negative implications de-
pending on the context and application. While we limit
our discussion to standardized tests, elections, surveys,
and authentication, the ability to derive distinctive bub-
ble completion patterns for individuals may have conse-
quences beyond those examined here. In Section 7, we
discuss additional tests that would allow us to better as-
sess the impact in several of these scenarios. In particu-
lar, most of these cases assume that an individual’s dis-
tinguishing features remain relatively stable over time,
and tests on longitudinal data are necessary to evaluate
this assumption.
9
forms, we can compare batches of ballots in one election
to batches from past elections. Accounting for demo-
graphic changes and the fact that voters need not vote
in all elections, the ballots should be somewhat similar
across elections. For example, if 85% of the voters on
the previous election’s sign-in list also voted during this
election, we would expect similarities between 85% of
the old ballots and the new ballots.
To test this, we may train on ballots from the previ-
ous election cycle and attempt to re-identify new ballots
against the old set. We would not expect ballots to per-
fectly match. Nevertheless, if less than approximately
85% of the old “identities” are covered by the new ballots
or many of the new ballots cluster around a small num-
ber of identities, this would raise suspicion that someone
else completed these forms, particularly if the forms are
unusually biased towards certain candidates or issues.
Similarly, analysis could also help uncover fraudulent
absentee ballots. Because absentee ballots do not require
a voter to be physically present, concerns exist about
individuals fraudulently obtaining and submitting these
ballots [19]. By training a model on past ballots, we
could assess whether suspicious absentee ballots fail to
match the diversity expected from the population com-
pleting these forms.7
Unfortunately, because bubble markings can serve as
a biometric, they can also be used in combination with
seemingly innocuous auxiliary data to undermine ballot
secrecy. Some jurisdictions now release scanned images
of ballots following elections with the goal of increasing
transparency (e.g., Humboldt County, California [14],
which releases ballot scans at 300 DPI). If someone has
access to these images or otherwise has the ability to ob-
tain ballot scans, they can attempt to undermine voter pri-
vacy. Although elections may be decided by millions of
voters, an attacker could focus exclusively on ballots cast
in a target’s precinct. New Jersey readjusts larger elec-
tion districts to contain fewer than 750 registered voters
[22]. Assuming 50% turnout, ballots in these districts
would fall in groups of 375 or smaller. In Wisconsin’s
contentious 2011 State Supreme Court race, 71% of re-
ported votes cast fell in the 91% of Wisconsin wards with
1,000 or fewer total votes [28].
Suppose that an interested party, such as a potential
employer, wishes to determine how you voted. Given
the ability to obtain bubble markings known to be from
you (for example, on an employment application), that
party can replicate our experiment in Section 3.1 to iso-
late one or a small subset of potential corresponding bal-
lots. What makes this breach of privacy troubling is that
it occurs without the consent of the voter and requires
no special access to the ballots (unlike paper ﬁngerprint-
7If a state uses bubble form absentee ballot applications, analysis
could even occur on the applications themselves.
ing techniques [4], which require access to the physical
ballot). The voter has not attempted to make an iden-
tifying mark, but the act of voting results in identifying
marks nonetheless. This threat exists not only in tradi-
tional government elections but also in union and other
elections.
Finally, one known threat against voting systems is
pattern voting. For this threat, an attacker coerces a voter
to select a preferred option in a relevant race and an un-
usual combination of choices for the other races. The un-
usual voting pattern will allow the attacker to locate the
ballot later and conﬁrm that the voter selected the cor-
rect choice for the relevant race. One proposed solution
for pattern voting is to cut ballots apart to separate votes
in individual contests [6]. Our work raises the possibil-
ity that physically divided portions of a ballot could be
connected, undermining this mitigation strategy.8
4.3 Surveys
Human subjects research is governed by a variety of re-
strictions and best practices intended to balance research
interests against the subjects’ interests. One factor to be
considered when collecting certain forms of data is the
level of anonymity afforded to subjects. If a dataset con-
tains identifying information, such as subject name, this
may impact the types of data that should be collected and
procedural safeguards imposed to protect subject privacy.
If subjects provide data using bubble forms, these mark-
ings effectively serve as a form of identifying informa-
tion, tying the form to the subject even in the absence of
a name. Re-identiﬁcation of subjects can proceed in the
same manner as re-identiﬁcation of voters, by matching
marks from a known individual against completed sur-
veys (as in Section 3.1).
Regardless of whether ethical or legal questions are
raised by the ability to identify survey respondents, this
ability might affect the honesty of respondents who are
aware of the issue. Dishonesty poses a problem even
for commercial surveys that do not adhere to the typical
practices of human subjects research.
The impact of this work for surveys is not entirely neg-
ative, however. In certain scenarios, the person respon-
sible for administering a survey may complete the forms
herself or modify completed forms, whether to avoid the
work of conducting the survey or to yield a desired out-
come. Should this risk exist, similar analysis to the stan-
dardized test and election cases could help uncover the
issue.
8We thank an anonymous reviewer for suggesting this possibility.
10
4.4 Authentication
Because bubble markings are a biometric, they may be
used alone or in combination with other techniques for
authentication. Using a ﬁnger or a stylus, an individual
could ﬁll in a bubble on a pad or a touchscreen. Be-
cause a computer could monitor user input, various de-
tails such as velocity and pressure could also be collected
and used to increase the accuracy of identiﬁcation, poten-
tially achieving far stronger results than in Section 3.2.
On touchscreen devices, this technique may or may not
be easier for users than entry of numeric codes or pass-
words. Additional testing would be necessary for this ap-
plication, including tests of its performance in the pres-
ence of persistent adversaries.
5 Mitigation
The impact of this paper’s techniques can be both bene-
ﬁcial and detrimental, but the drawbacks may outweigh
the beneﬁts under certain circumstances. In these cases, a
mitigation strategy is desirable, but the appropriate strat-
egy varies. We discuss three classes of mitigation strate-
gies. First, we consider changes to the forms themselves
or how individuals mark the forms. Second, we exam-
ine procedural safeguards that restrict access to forms or
scanned images. Finally, we explore techniques that ob-
scure or remove identifying characteristics from scanned
images. No strategy alone is perfect, but various combi-
nations may be acceptable under different circumstances.
5.1 Changes to Forms or Marking Devices
As explored in Section 3.3, changes to the forms them-
selves such as a gray background can impact the accu-
racy of our tests. The unintentional protection provided
by this particular change was mild and unlikely to be
insurmountable. Nevertheless, more dramatic changes
to either the forms themselves or the ways people mark
them could provide a greater measure of defense.
Changes to the forms themselves should strive to limit
either the space for observable human variation or the
ability of an analyst to perceive these variations. The ad-
dition of a random speckled or striped background in the
same color as the writing instrument could create difﬁ-
culties in cleanly identifying and matching a mark.
If
bubbles had wider borders, respondents would be less
likely to color outside the lines, decreasing this source
of information. Bubbles of different shapes or alternate
marking techniques could encourage less variation be-
tween users. For example, some optical scan ballots re-
quire a voter simply to draw a line to complete an arrow
shape [1], and these lines may provide less identifying
information than a completed bubble.
The marking instruments that individuals use could
also help leak less identifying information. Some Los
Angeles County voters use ink-marking devices, which
stamp a circle of ink for a user [18]. Use of an ink-
stamper would reduce the distinguishability of markings,
and even a wide marker could reduce the space for inad-
vertent variation.
5.2 Procedural Safeguards
Procedural safeguards that restrict access to both forms
themselves and scanned images can be both straightfor-
ward and effective. Collection of data from bubble forms
typically relies on scanning the forms, but a scanner need
not retain image data for any longer than required to pro-
cess a respondent’s choices. If the form and its image
are unavailable to an adversary, our techniques would be
infeasible.
In some cases, instructive practices or alternative tech-
niques already exist. For example, researchers conduct-
ing surveys could treat forms with bubble markings in the
same manner as they would treat other forms containing
identifying information. In the context of elections, some
jurisdictions currently release scanned ballot images fol-
lowing an election to provides a measure of transparency.
This release is not a satisfactory replacement for a sta-
tistically signiﬁcant manual audit of paper ballots (e.g.,
[2, 5]), however, and it is not necessary for such an au-
dit. Because scanned images could be manipulated or
replaced, statistically signiﬁcant manual conﬁrmation of
the reported ballots’ validity remains necessary. Further-
more, releasing the recorded choices from a ballot (e.g.,
Washington selected for President, Lincoln selected for
Senator, etc.) without a scanned ballot image is sufﬁcient
for a manual audit.
Whether the perceived transparency provided by the
release of ballot scans justiﬁes the resulting privacy risk
is outside the scope of this paper. Nevertheless, should
the release of scanned images be desirable, the next sec-
tion describes methods that strive to protect privacy in
the event of a release.
5.3 Scrubbing Scanned Images
In some cases,
the release of scanned bubble forms
themselves might be desirable. In California, Humboldt
County’s release of ballot image scans following the
2008 election uncovered evidence of a software glitch
causing certain ballots to be ignored [13]. Although a
manual audit could have caught this error with high prob-
ability, ballot images provide some protection against un-
intentional errors in the absence of such audits.
The ability to remove identifying information from
scanned forms while retaining some evidence of a re-
11
spondent’s actions is desirable. One straightforward ap-
proach is to cover the respondent’s recorded choices with
solid black circles. Barring any stray marks or mis-
readings, this choice would completely remove all iden-
tifying bubble patterns. Unfortunately, this approach
has several disadvantages. First, a circle could cover
choices that were not selected, hiding certain forms of
errors. Second, suppose that a bubble is marked but not
recorded. While the resulting image would allow review-
ers to uncover the error, such marks retain a respondent’s
identifying details. The threat of a misreading and re-
identiﬁcation could be sufﬁcient to undermine respon-
dent conﬁdence, enabling coercion.
An alternative to the use of black circles is to re-
place the contents of each bubble with its average color,
whether the respondent is or is not believed to have se-
lected the bubble. The rest of the scan could be scrubbed
of stray marks. This would reduce the space for variation
to color and pressure properties alone. Unfortunately, no