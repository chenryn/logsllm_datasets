number of tuples), output size, and processing time of the
computation unit i, and call Ψi = (cid:31)Ii,Oi,Ti(cid:30) the IO-proﬁle
of computation unit i. The proﬁle Ψ of the entire execu-
tion on input I is the sequence of Ψi for all computation
units i ∈ [1, . . . ,n + m] in the execution protocol. If an
adversary (cid:31)A can initiate the above protocol and observe
Ψ, we say that the adversary has access to Ψ.
Now, let us consider the execution of the program on
the same input I = (cid:31)x1,x2, . . . ,x n(cid:30) under a MapReduce
provisioning protocol by an adversary A . A semi-honest
adversary A can obtain information on the value of the
input, output and processing time of every trusted in-
stance, including information on trusted instances other
than the map and reduce computation units. If the adver-
sary is malicious, it can further tamper with the inputs
and invocations of the instances. In the protocol, the ad-
versary controls 6 parameters:
(C1)
(C2)
(C3)
(C4)
(C5)
(C6)
the start time of each computation instance,
the end time of each instance,
the encrypted tuples passed to its inputs,
the number of computation instances,
order of computation units executed,
the total number of map-reduce phases executed.
Since the adversary A can obtain “more” information
and tamper the execution, a question to ask is, can the
adversary A gain more knowledge compared to an ad-
versary (cid:31)A who only has access to Ψ? Using the standard
notions of indistinguishability2 and adversaries [28], we
deﬁne a secure protocol as follows:
Deﬁnition 1 (Privacy modulo-Ψ ). A provisioning pro-
tocol for a program is modulo-Ψ private if, for any ad-
versary A executing the MapReduce protocol, there is a
adversary (cid:31)A with access only to Ψ, such that the output
of A and (cid:31)A are indistinguishable.
The deﬁnition states that the output of the adversaries
can be directly seen as deduction made on the informa-
tion available. The fact that all adversaries have output
indistinguishable from the one which knows Ψ suggests
that no additional information can be gained by any A
beyond that implied by knowledge of Ψ.
Remarks. First, our deﬁnition follows the scenario pro-
posed by Canneti [11], which facilitates universal com-
position. Hence, if a protocol is private module-Ψ for
one map-reduce phase, then an entire sequence of phases
executed is private module-Ψ. Note that our proposed
M2R consists of a sequence of map, shufﬂe, and reduce
phases where each phase starts only after the previous
phase has completed, and the chain of MapReduce jobs
are carried out sequentially. Thus, universal composition
can be applied. Second, we point out that if the developer
restructures the original computation to make the IO-
proﬁle the same for all inputs, then Ψ leaks nothing about
the input. Therefore, the developer can consider using or-
thogonal techniques to mask timing latencies [41], hid-
ing trace paths and IO patterns [34] to achieve ideal pri-
vacy, if the performance considerations permit so.
2.3 Assumptions
In this work, we make speciﬁc assumptions about the
baseline system we build upon. First, we assume that the
underlying hardware sufﬁciently protects each computa-
tion unit from malware and snooping attacks. The range
of threats that are protected against varies based on the
underlying trusted computing hardware. For instance,
2non-negligible advantage in a distinguishing game
450  24th USENIX Security Symposium 
USENIX Association
4
traditional TPMs protect against software-only attacks
but not against physical access to RAM via attacks such
as cold-boot [24]. More recent trusted computing prim-
itives, such as Intel SGX [40], encrypt physical mem-
ory and therefore offer stronger protection against adver-
saries with direct physical access. Therefore, we do not
focus on the speciﬁcs of how to protect each computa-
tion unit, as it is likely to change with varying hardware
platform used in deployment.
In fact, our design can
be implemented in any virtualization-assisted isolation
that protects user-level processes on a malicious guest
OS [12, 52, 57], before Intel SGX becomes available on
the market.
Second, an important assumption we make is that of
information leakage via side-channels (e.g. cache laten-
cies, power) from a computation unit is minimal. Indeed,
it is a valid concern and an area of active research. Both
software and hardware-based solutions are emerging, but
they are orthogonal to our techniques [18, 29].
Finally, to enable arbitrary computation on encrypted
data, decryption keys need to be made made available
to each hardware-isolated computation unit. This pro-
visioning of client’s keys to the cloud requires a set of
trusted administrator interfaces and privileged software.
We assume that such trusted key provisioning exists, as
is shown in recent work [49, 65].
3 Attacks
In this section, we explain why a baseline system that
merely encrypts the output of each computation unit
leaks signiﬁcantly more than a system that achieves pri-
vacy modulo-Ψ. We explain various subtle attack chan-
nels that our solution eliminates, with an example.
Running Example. Let us consider the canonical ex-
ample of the Wordcount job in MapReduce, wherein the
goal is to count the number of occurrences of each word
in a set of input ﬁles. The map operation takes one ﬁle
as input, and for each word w in the ﬁle, outputs the tu-
ple (cid:31)w,1(cid:30). All outputs are encrypted with standard au-
thenticated encryption. Each reduce operation takes as
input all the tuples with the same tuple-key, i.e. the same
word, and aggregates the values. Hence the output of
reduce operations is an encrypted list of tuples (cid:31)w,wc(cid:30),
where wc is the frequency of word w for all input ﬁles.
For simplicity, we assume that the input is a set of ﬁles
F = {F1, . . . ,Fn}, each ﬁle has the same number of words
and is small enough to be processed by a map operation3.
What does Privacy modulo-Ψ Achieve? Here all the
map computation units output same size tuples, and af-
ter grouping, each reduce unit receives tuples grouped
3Files can be processed in ﬁxed size blocks, so this assumption is
without any loss of generality
by words. The size of map outputs and group sizes con-
stitute Ψ, and a private modulo-Ψ execution therefore
leaks some statistical information about the collection of
ﬁles in aggregate, namely the frequency distribution of
words in F. However, it leaks nothing about the con-
tents of words in the individual ﬁles — for instance, the
frequency of words in any given ﬁle, and the common
words between any pair of ﬁles are not leaked. As we
show next, the baseline system permits a lot of inference
attacks as it fails to achieve privacy modulo-Ψ. In fact,
eliminating the remaining leakage in this example may
not be easy, as it may assume apriori knowledge about
the probability distribution of words in F (e.g. using dif-
ferential privacy [48]).
Passive Attacks. Consider a semi-honest adversary that
executes the provisioning protocol, but aims to infer ad-
ditional information. The adversary controls 6 parame-
ters C1-C6 (Section 2.2 ) in the execution protocol. The
number of units (C4) and map-reduce phases executed
(C6) are dependent (and implied) by Ψ in an honest exe-
cution, and do not leak any additional information about
the input. However, parameters C1,C2,C3 and C5 may
directly leak additional information, as explained below.
• Dataﬂow Patterns (Channel C3). Assume that the
encrypted tuples are of the same size, and hence do
not individually leak anything about the underlying
plain text. However, since the adversary constitutes
the data communication channel, it can correlate the
tuples written out by a map unit and read by a spe-
ciﬁc reduce unit.
In the Wordcount example, the
ith map unit processes words in the ﬁle Fi, and then
the intermediate tuples are sorted before being fed
to reduce units. By observing which map outputs
are grouped together to the same reduce unit, the
adversary can learn that the word wi in ﬁle Fi is the
same as a word w j in ﬁle Fj. This is true if they
are received by the same reduce unit as one group.
Thus, data access patterns leak signiﬁcant informa-
tion about overlapping words in ﬁles.
• Order of Execution (Channel C5). A determinis-
tic order of execution of nodes in any step can re-
veal information about the underlying tuples be-
yond what is implied by Ψ. For instance, if the
provisioning protocol always sorts tuple-keys and
assigns them to reduce units in sorted order, then
the adversary learns signiﬁcant information. In the
WordCount example, if the ﬁrst reduce unit always
corresponds to words appearing ﬁrst in the sorted
order, this would leak information about speciﬁc
words processed by the reduce unit. This is not di-
rectly implied by Ψ.
• Time-of-Access (Channel C1,C2) Even if data ac-
cess patterns are eliminated, time-of-access is an-
USENIX Association  
24th USENIX Security Symposium  451
5
452  24th USENIX Security Symposium 
USENIX Association
otherchannelofleakage.Forinstance,anoptimiz-ingschedulermaystarttomovetuplestothere-duceunitsevenbeforethemapstepiscompleted(pipelining)togainefﬁciency.Insuchcases,thead-versarycancorrelatewhichblockswrittenbymapunitsarereadbywhichreduceunits.Ifoutputsofallbuttheithmapunitaredelayed,andthejthre-duceunitcompletes,thentheadversarycandeducethatthereisnodataﬂowfromtheithmapunittojthreduceunit.Ingeneral,ifcomputationunitsinasubsequentstepdonotsynchronizetoobtainout-putsfromallunitsinthepreviousstep,thetimeofstartandcompletionleaksinformation.ActiveAttacks.Whileweallowtheadversarytoabortthecomputationsessionatanytime,weaimtopreventtheadversaryfromusingactiveattackstogainadvantageinbreakingconﬁdentiality.Weremindreadersthatinourbaselinesystem,theadversarycanonlyinvokethepro-gramwithitscompleteinputset,withouttamperingwithanyoriginalinputs.Theoutputtuple-setofeachcompu-tationunitisencryptedwithanauthenticatedencryptionscheme,sotheadversarycannottamperwithindividualtuples.Despitethesepreliminarydefenses,severalchan-nelsforactiveattacksexist:•TupleTampering.Theadversarymayattempttodu-plicateoreliminateanentireoutputtuple-setpro-ducedbyacomputationunit,eventhoughitcannotforgeindividualtuples.Asanattackillustration,supposetheadversarywantstolearnhowmanywordsareuniquetoaninputﬁleFi.Todothis,theadversarycansimplydroptheoutputoftheithmapunit.Ifthenumberoftuplesintheﬁnaloutputre-ducesbyk,thetupleseliminatedcorrespondtokuniquewordsinFi.•MisroutingTuples.Theadversarycanreorderin-termediatetuplesorroutedatablocksintendedforonereduceunittoanother.Theseattackssubvertourconﬁdentialitygoals.Forinstance,theadver-sarycanbypasstheshufﬂeraltogetherandroutetheoutputofithmapunittoareduceunit.TheoutputofthisreduceunitleaksthenumberofuniquewordsinFi.Similarinferenceattackscanbeachievedbyduplicatingoutputsoftuplesinthereduceunitandobservingtheresult.4DesignOurgoalistodesignaMapReduceprovisioningproto-colwhichisprivatemodulo-ΨandaddsasmallamountoftheTCBtotheexistingMapReduceplatform.Weex-plainthedesignchoicesavailableandourobservationsthatleadtoanefﬁcientandcleansecuritydesign.MapTmapperMapTReducergroupingx1x2x3x...xn-1xnMapTMapTMapTMapTReduceTSecure Shufflero1o2o3o...on-1onIn+1In+2In+...In+mOn+1On+2On+...On+mJOBIMixTMixTMixTMixTMixTMixTReduceTReduceTReduceTReduceTReduceTGroupTGroupTGroupTGroupTGroupTGroupTFigure2:ThedataﬂowinM2R.Filledcomponentsaretrusted.Input,intermediateandoutputtuplesareencrypted.Theorig-inalmapandreduceoperationsarereplacedwithmapTandreduceT.NewcomponentsarethemixernodeswhichusemixT,andanothertrustedcomponentcalledgroupT.4.1ArchitectureOverviewThecomputationproceedsinphases,eachconsistingofamapstep,ashufﬂestep,andareducestep.Figure2depictsthe4newtrustedcomponentsourdesignintro-ducesintothedataﬂowpipelineofMapReduce.ThesefournewTCBcomponentsaremapT,reduceT,mixTandgroupT.Twoofthesecorrespondtotheexecutionofmapandreduceunit.Theyensurethatoutputtuplesfromthemapandreduceunitsareencryptedandeachtupleisofthesamesize.Theother2componentsim-plementthecriticalroleofsecureshufﬂing.Weexplainournon-intrusivemechanismforsecureshufﬂinginSec-tion4.2.Further,allintegritycheckstodefeatactiveat-tacksaredesignedtobedistributedrequiringminimalglobalsynchronization.TheshufﬂerintheMapReduceplatformisresponsibleforgroupingtuples,andinvokingreduceunitsondisjointrangesoftuple-keys.Oneachclusternode,thereducerchecksthegroupedorderandtheexpectedrangeoftuplesreceivedusingthetrustedgroupTcomponent.Theoutputsofthereduceunitsarethenfedbackintothenextroundofmap-reducephase.MinimizingTCB.Inourdesign,amajorpartoftheMapReduce’ssoftwarestackdealswithjobschedulingandI/Ooperations,henceitcanbeleftoutsideoftheTCB.Ourdesignmakesnochangetothegroupingandschedulingalgorithms,andtheyareoutsideourTCBasshownintheFigure2.Therefore,thedesignisconcep-tuallysimpleandrequiresnointrusivechangestobeim-plementedoverexistingMapReduceimplementations.Developersneedtomodifytheiroriginalapplicationstopreparethemforexecutioninahardware-protectedpro-6USENIX Association  
24th USENIX Security Symposium  453
cessinourbaselinesystem,asproposedinprevioussys-tems[38,39,49].BeyondthismodiﬁcationmadebythebaselinesystemtotheoriginalMapReduce,M2Rrequiresafewadditionallinesofcodetoinvokethenewprivacy-enhancingTCBcomponents.Thatis,MapReduceappli-cationsneedmodiﬁcationsonlytoinvokecomponentsinourTCB.Next,weexplainhowourarchitectureachievesprivacyandintegrityinaMapReduceexecution,alongwiththedesignofthesefourTCBcomponents.4.2Privacy-PreservingExecutionForanygivenexecution,wewishtoensurethateachcomputationstepinaphaseisprivatemodulo-Ψ.Ifthemapstep,theshufﬂestep,andthereducesteparein-dividuallyprivatemodulo-Ψ,bythepropertyofserialcomposibility,theentirephaseandasequenceofphasescanbeshowntobeprivate.Wediscussthedesignofthesestepsinthissection,assumingahonest-but-curiousadversarylimitedtopassiveattacks.Thecaseofmali-ciousadversariesisdiscussedinSection4.3.4.2.1SecureShufﬂingAsdiscussedintheprevioussection,thekeychallengeisperformingsecureshufﬂing.Considerthenaiveap-proachinwhichwesimplymovetheentireshufﬂerintotheplatformTCBofeachclusternode.Toseewhythisisinsecure,considerthegroupingstepoftheshufﬂer,oftenimplementedasadistributedsortorhash-basedgroup-ingalgorithm.Thegroupingalgorithmcanonlyprocessalimitednumberoftupleslocallyateachmapper,soac-cesstointermediatetuplesmustgotothenetworkduringthegroupingprocess.Here,networkdataaccesspatternsfromtheshufﬂerleakinformation.Forexample,iftheshufﬂerwereimplementedusingastandardmergesortimplementation,themergestepleakstherelativeposi-tionofthepointersinsortedsub-arraysasitfetchespartsofeachsub-arrayfromnetworkincrementally4.OnegenericsolutiontohidedataaccesspatternsistoemployanORAMprotocolwhencommunicatingwiththeuntrustedstoragebackend.Thegroupingstepwillthenaccessdataobliviously,therebyhidingallcorre-lationsbetweengroupedtuples.Thissolutionachievesstrongprivacy,butwithanoverheadofO(logkN)foreachaccesswhenthetotalnumberoftuplesisN[55].AdvancedtechniquescanbeemployedtoreducetheoverheadtoO(logN),i.e.k=1[43].Nevertheless,us-ingasortingalgorithmforgrouping,thetotaloverheadbecomesO(Nlogk+1N),whichtranslatestoafactorof30−100×slowdownwhenprocessinggigabytesofshuf-ﬂeddata.4Thiscanreveal,forinstance,whethertheﬁrstsub-arrayisstrictlylesserthantheﬁrstelementinthesecondsortedsub-array.mappermappermappermixTmixTmixTmixTmixTmixTmixTmixTreducerreducerreducermixermixermixermixerFigure3:Highleveloverviewofthemap-mix-reduceexecutionusinga2-roundmixnetwork.Amoreadvancedsolutionistoperformoblivioussort-ingusingsortingnetworks,forexample,odd-evenorbitonicsortingnetwork[23].Suchanapproachhidesdataaccesspatterns,butadmitsaO(log2N)latency(ad-ditiveonly).However,sortingnetworksareoftende-signedforaﬁxednumberofsmallinputsandhardtoadapttotensofgigabytesofdistributeddata.Wemakeasimpleobservationwhichyieldsanon-intrusivesolution.OurmainobservationisthatinMapReduceandotherdataﬂowframeworks,these-quenceofdataaccesspatternsisﬁxed:itconsistsofcyclesoftuplewritesfollowedbyreads.Thereduceunitsstartreadingandprocessingtheirinputsonlyaf-terthemapunitshaveﬁnished.Inoursolution,were-writeintermediateencryptedtupleswithre-randomizedtuplekeyssuchthatthereisnolinkabilitybetweenthere-randomizedtuplesandtheoriginalencryptedmapoutputtuples.Weobservethatthisstepcanberealizedbyse-curemixnetworks[30].Theprivacyofthecomputa-tionreducesdirectlytotheproblemofsecuremixing.ThetotallatencyaddedbyoursolutionisanadditivetermofO(logN)intheworstcase.SinceMapReduceshufﬂestepisbasedonsortingwhichalreadyadmitsO(NlogN)overhead,ourdesignretainstheasymptoticruntimecomplexityoftheoriginalframework.Ourdesignachievesprivacyusingacascadedmixnet-work(orcascaded-mix)tosecurelyshufﬂetuples[30].Theprocedureconsistsofacascadingofκintermedi-atesteps,asshowninFigure3.Ithasκidenticalsteps(calledmixingsteps)eachemployinganumberoftrustedcomputationunitscalledmixTunits,theexecutionofwhichcanbedistributedovermultiplenodescalledmix-ers.EachmixTtakesaﬁxedamountofTtuplesthatitcanprocessinmemory,andpassesexactlythesamenumberofencryptedtuplestoallmixTunitsinthesub-7sequent step. Therefore, in each step of the cascade, the
mixer utilizes N/T mixT units for mixing N tuples. At
κ = log N
T , the network ensures the strongest possible un-
linkability, that is, the output distribution is statistically
indistinguishable from a random distribution [30].
Each mixT unit decrypts the tuples it receives from
the previous step, randomly permutes them using a
linear-time algorithm and re-encrypts the permuted tu-
ples with fresh randomly chosen symmetric key. These
keys are known only to mixT units, and can be derived
using a secure key-derivation function from a common
secret. The processing time of mixT are padded to a
constant. Note that the re-encryption time has low vari-
ance over different inputs, therefore such padding incurs
low overhead.
Let Ω represents the number of input and output tu-
ples of cascaded-mix with κ steps. Intuitively, when κ is
sufﬁciently large, an semi-honest adversary who has ob-
served the execution does not gain more knowledge than
Ω. The following lemma states that indeed this is the
case. We present the proof in Appendix A.
Lemma 1. Cascaded-mix is private module-Ω under
semi-honest adversary, given that the underlying encryp-
tion scheme is semantically secure.
4.2.2 Secure Grouping
After the mixing step, the shufﬂer can group the random-
ized tuple keys using its original (unmodiﬁed) grouping
algorithm, which is not in the TCB. The output of the
cascaded-mix is thus fed into the existing grouping al-
gorithm of MapReduce, which combines all tuples with
the same tuple-key and forward them to reducers. Read-
ers will notice that if the outputs of the last step of the
cascaded-mix are probabilistically encrypted, this group-
ing step would need to be done in a trusted component.
In our design, we add a last (κ +1)-th step in the cascade
to accommodate the requirement for subsequent group-
ing. The last step in the cascade uses a deterministic
symmetric encryption Fs, with a secret key s, to encrypt
the key-component of the ﬁnal output tuples. Speciﬁ-
cally, the (cid:31)a,b(cid:30) is encrypted to a ciphertext of the form
(cid:31)Fs(a),E(a,b)(cid:30), where E(·) is a probabilistic encryption
scheme. This ensures that the two shufﬂed tuples with
the same tuple-keys have the same ciphertext for the key-
component of the tuple, and hence the subsequent group-
ing algorithm can group them without decrypting the tu-
ples. The secret key s is randomized in each invocation of
the cascaded-mix, thereby randomizing the ciphertexts
across two map-reduce phases or jobs.
What the adversary gains by observing the last step
of mixing is the tuples groups which are permuted using
Fs(·). Thus, if Fs(·) is a pseudorandom function family,
the adversary can only learn about the size of each group,
which is already implied by Ψ. Putting it all together
with the Lemma 1, we have:
Theorem 1. The protocol M2R is modulo-Ψ private (un-
der semi-honest adversary), assuming that the underly-
ing private-key encryption is semantically secure, and
Fs(·) is a pseudorandom function family.
4.3 Execution Integrity
So far, we have considered the privacy of the protocol
against honest-but-curious adversaries. However, a mali-
cious adversary can deviate arbitrarily from the protocol
by mounting active attacks using the 6 parameters un-
der its control. In this section, we explain the techniques