# 利用ELK协助安全性攻击的数据分析
|
##### 译文声明
本文是翻译文章，文章来源：marcolancini.it
原文地址：
译文仅供参考，具体内容表达以及含义原文为准。
你是否曾经进行过网络渗透测试，其范围如此之大，以至于最终会得到包含Nmap扫描结果在内的数十个文件，而每个文件又包含多个主机？
如果答案是肯定的，那你应该会对这篇博文感兴趣。
以下是我最近进行的一个工作，旨在找到一种方法来对渗透测试的结果进行分类，同时实现团队成员之间的并发协作。
我们将会看到，在解析和分析数据时，使用传统的“防御性”工具进行攻击性安全数据分析比传统的grep更具优势。
最后，这个工程的所有源代码大家可以在github上下载，我也希望这能够给后面将和我有一个需求的老哥们有所帮助：.
## 当前所能选择的
如果你还在阅读这篇文章，说明你想要摒弃原来基于grep的方法，但是我们有什么替代品吗？  
我首先浏览了我一直忽略的东西：Nmap HTML报告。
我不知道有多少人知道并实际使用它，但确实可以从Nmap获取XML输出文件并将其传递给XML处理器（如xsltproc），将其转换为HTML文件，如下图所示：
如果对此感兴趣，可以在Nmap网站上找到获取此信息的完整流程。 但是，我认为这种方法有一些缺陷。
首先，除非使用—webxml开关启动Nmap，否则必须抛出每个输出文件以替换XSL样式表引用，以使其指向当前计算机上nmap.xsl文件的确切位置。
其次，更重要的是，这没有扩展。
放弃了HTML的办法后，我想起来我的前同事Vincent Yiu的一篇博客，利用Splunk进行攻击性操作。
这是一个有趣的想法，因为我们越来越多地看到人们也使用所谓的“防御”工具进行攻击。
Splunk绝对不适合我（因为我没有license），但经过一些研究后我终于偶然发现了这篇博客文章：“[Nmap + Logstash to Gain
Insight Into Your Network](https://qbox.io/blog/how-to-index-nmap-port-scan-results-into-elasticsearchUsing)”。
我之前听说过ELK（下面有更多内容介绍ELK），但我从未真正了解过它，可能是因为我把它归类为主要由SOC分析师使用的“防御”工具。
而它引起我注意的是上面的博客文章解释了如何：  
“直接将Nmap扫描结果导入Elasticsearch，然后您可以使用Kibana将其可视化”。
## ELK Stack的介绍
那么，ELK Stack是什么？ “ELK”是三个开源项目的首字母缩写：Elasticsearch，Logstash和Kibana。
Elasticsearch是一个搜索和分析引擎。
Logstash是一个服务器端数据处理管道，它同时从多个源中提取数据，对其进行转换，然后将其发送到像Elasticsearch这样的“存储”。
Kibana允许用户使用Elasticsearch中的图表和图形可视化数据。  
我不会详细解释这个堆栈的不同组件，但对于有兴趣的人我强烈推荐 “[The Complete Guide to the ELK
Stack](https://logz.io/learn/complete-guide-elk-stack/)”，它给出了堆栈及其三个主要组件的非常好的概述（可以跳过“安装ELK”部分，因为我们将采取不同的方法）。
我感兴趣的部分是Elasticsearch如何不仅可以用于检测（防御），还可以用于进攻。
## 安装
以下是一个完整的演示，一直到最后安装成功。对这个不感兴趣的同学可以直接跳到“操作数据”部分。
首先我们将使用由[@deviantony](https://github.com/deviantony
"@deviantony")完成的一个很棒的存储库，这将允许我们在几秒钟内启动完整的ELK堆栈，这要归功于docker-compose：  
克隆存储库后，我们可以从docker-compose.yml文件中看到将启动三个服务。 这是修改后的docker-compose.yml文件，我在其中添加了容器名称（为了清楚起见）和一种Elasticsearch存储数据的方式，即使在删除其容器之后，通过在主机上安装卷来保存数据（./_data/elasticsearch:/USR/共享/
elasticsearch/数据）：
docker-elk ❯ cat docker-compose.yml  
version: ‘2’  
services:
    # -------------------------------------------------------------------    # ELASTICSEARCH
    # -------------------------------------------------------------------      elasticsearch:
          container_name: elk_elasticsearch
        build: elasticsearch/
        volumes:
            - ./elasticsearch/config/elasticsearch.yml:  /usr/share/elasticsearch/config/elasticsearch.yml:ro
            - ./_data/elasticsearch:/usr/share/elasticsearch/data
        ports:
            - "9200:9200"
            - "9300:9300"
        environment:
            ES_JAVA_OPTS: "-Xmx256m -Xms256m"
        networks:
            - elk
    # -------------------------------------------------------------------    # LOGSTASH
    # -------------------------------------------------------------------    logstash:
        container_name: elk_logstash
        build: logstash/
        volumes:
            - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro
            - ./logstash/pipeline:/usr/share/logstash/pipeline:ro
        ports:
            - "5000:5000"
        environment:
            LS_JAVA_OPTS: "-Xmx256m -Xms256m"
        networks:
            - elk
        depends_on:
            - elasticsearch
    # -------------------------------------------------------------------    # KIBANA
    # -------------------------------------------------------------------      kibana:
          container_name: elk_kibana
        build: kibana/
        volumes:
            - ./kibana/config/:/usr/share/kibana/config:ro
        ports:
            - "5601:5601"
        networks:
            - elk
        depends_on:
            - elasticsearch
    networks:
        elk:
        driver: bridge
默认情况下，堆栈开放以下端口：
5000：Logstash TCP输入  
9200：Elasticsearch HTTP  
9300：Elasticsearch TCP传输  
5601：Kibana
用几秒钟时间来安装Kibana，然后在web页面上访问它：.
### 准备Elasticsearch以获取Nmap结果
对于一个完整的ELK新手来说，这是一个挑战，直到我找到以下帖子：“[How to Index NMAP Port Scan Results into
Elasticsearch](https://qbox.io/blog/how-to-index-nmap-port-scan-results-into-elasticsearch)  
”。 这不是一个完整的解决方案，而是一个很好的起点。 让我们从那里开始并以此为基础。
首先，我们需要Logstash Nmap编解码器插件。 Logstash编解码器简单地提供了一种指定原始数据应如何解码的方法，而不管源是什么。
这意味着我们可以使用Nmap编解码器从各种输入中读取Nmap XML。 在将数据传递给Nmap编解码器之前，我们可以从消息队列或通过syslog读取它。
幸运的是，添加它就像修改位于logstash / Dockerfile的Logstash Dockerfile一样简单：  
docker-elk ❯ cat logstash/Dockerfile
     # https://github.com/elastic/logstash-docker
     FROM docker.elastic.co/logstash/logstash-oss:6.3.0
     # Add your logstash plugins setup here
     # Example: RUN logstash-plugin install logstash-filter-json
     RUN logstash-plugin install logstash-codec-nmap
接下来，要将其放入Elasticsearch，我们需要创建一个映射。 可以从Logstash Nmap编解码器的Github存储库获得映射模板。
我们可以下载它并将其放在logstash / pipeline / elasticsearch_nmap_template.json中：
最后，我们需要修改位于logstash / pipeline /
logstash.conf的logstash配置文件，以便为新的Nmap插件添加过滤器和输出选项：
### 准备摄取者服务
我们将使用修改后的VulntoES版本来获取结果并将它们导入Elasticsearch。
为了做到这一点，我创建了一个新的文件夹摄取器，用于实际摄取数据的新服务。
在上面的清单中，文件夹摄取器包含：
• VulntoES，原始脚本的修改版本，修复了一些解析错误  
• 脚本提取将为放置在容器的/ data文件夹中的每个XML文件运行VulntoES.py（更多内容见下文）
• Dockerfile将修改后的VulntoES导入到python：2.7-stretch图像中
我们现在只需要将这个新容器添加到docker-compose.yml文件中：  
请注意我们如何在路径/ data /下的容器中映射本地文件夹./_data/nmap。 我们将使用此“共享”文件夹来传递Nmap结果。
在所有这些修改之后，这就是您的项目文件夹的样子：  
完成后，请确保使用docker-compose build命令重建图像。
###  创建索引
最后一步是创建一个索引，用于将数据索引到：  
1、使用curl创建nmap-vuln-to-es索引：
> curl -XPUT ‘localhost:9200/nmap-vuln-to-es’
2、在浏览器中打开Kibana（http：// localhost：5601），您将看到以下屏幕：  
3、插入nmap *作为索引模式，然后按“下一步”：  
选择“I don’t want to use the Time Filter”, 然后点击 “Create Index Pattern”:
## 操作数据
Elk正确配置完后，我们可以用它来玩玩处理数据了。
### 获取Nmap结果
为了能够获取我们的Nmap扫描，我们必须以XML格式的报告（-oX）输出结果，该报告可以由Elasticsearch解析。
完成扫描后，将报告放在./_data/nmap/文件夹中并运行摄取器：
###  分析数据
现在我们已经导入了一些数据，现在是时候开始研究一下Kibana的功能了。  
“dicover”视图将索引中的所有数据显示为文档表，并允许以交互方式浏览数据：我们可以访问与所选索引模式匹配的每个索引中的每个文档。
你可以提交搜索查询，过滤搜索结果以及查看文档数据。 还可以查看与搜索查询匹配的文档数量并获取字段值统计信息。
通过过滤（例如，通过开放端口或服务）来对目标进行分类是很好的。
相反，“Dashboard”视图显示可视化和搜索的集合。 您可以排版，调整大小和编辑仪表板内容，然后保存仪表板以便共享。 这可用于创建高度自定义的数据概览。
仪表板本身是交互式的：您可以应用过滤器来查看实时更新的可视化以反映查询的内容（在下面的示例中，我按端口22过滤）。
对这个感兴趣的同学，我将我的示例仪表板导出到一个易于重新导入的json文件中：  
• 
## 结论
传统的“防御性”工具可以有效地用于攻击性安全数据分析，帮助您的团队协作并对扫描结果进行分类。  
特别的，Elasticsearch提供了聚合不同数据源的数量的机会，使用统一的接口进行查询，目的是从大量未分类的数据中提取可操作的知识。
审核人：yiwang 编辑：边边