### Optimized Text

As illustrated in Figure 8(b), TACK exhibits the same frequency as TCP’s delayed ACK (denoted by TCP (L=2)) over 802.11b wireless links with a small \( R_{T}T_{\text{min}} \) of 10 ms. However, for 802.11ac links, the frequency of TACK decreases by two orders of magnitude when \( R_{T}T_{\text{min}} = 10 \) ms and by three orders of magnitude when \( R_{T}T_{\text{min}} = 80 \) ms. Figures 8(a) and 9(a) also indicate that goodput improvement is relatively insensitive to the latency between endpoints. This is because TACK’s frequency is already quite low, and reducing ACK frequency by hundreds of Hz has only a slight impact on goodput.

Due to licensing constraints, our current implementation of TCP-TACK is in user space rather than kernel space. All evaluations of TCP-TACK in this paper are based on this commercial implementation.

| Spatial Streams | Link | Modulation Type | Coding Rate | Guard Interval | Channel Width | PHY Capacity | UDP Baseline |
|-----------------|------|-----------------|-------------|----------------|---------------|--------------|--------------|
| 1               | 802.11b | CCK             | -           | 400 ns         | 22 MHz        | 11 Mbps      | 7 Mbps       |
| 1               | 802.11g | 64-QAM          | 3/4         | 400 ns         | 20 MHz        | 54 Mbps      | 26 Mbps      |
| 2               | 802.11n | 64-QAM          | 5/6         | -              | 40 MHz        | 300 Mbps     | 210 Mbps     |
| 2               | 802.11ac| 256-QAM         | 5/6         | -              | 80 MHz        | 866.7 Mbps   | 590 Mbps     |

Figure 9: 
(a) Goodput improvement
(b) Ideal goodput trend

(a) Links with faster PHY rates enhance goodput improvement.
(b) TACK approaches the transport upper bound with minimized ACK frequency (RTT=80 ms, 802.11n).

Figure 10: 
(a) TCP-TACK vs. TCP BBR
(b) Actual goodput trend

(a) TCP-TACK achieves 20% to 28.1% goodput improvement.
(b) Prior ACK thinning mechanisms disrupt TCP transport performance (RTT=80 ms, 802.11n).

### 6.3 Performance in WLAN Scenarios

Before delving into protocol performance, we first address how closely TACK can approach the transport upper bound. We use a UDP-based tool [29] specified in Section 3.2 to estimate the ideal goodput of different ACK thinning techniques. For example, "TCP (L=8)" considers the case where an ACK is sent every 8 full-sized packets. Our simulator continuously sends 1518-byte packets from the sender over 802.11n links, and the receiver counts 8 received packets before sending a 64-byte ACK. "UDP Baseline" serves as the transport upper bound, as its goodput is unaffected by ACKs (see Figure 7). "PHY Capacity" represents the raw bit rate at the PHY layer.

It is well-known that transport performance degrades when the number of ACKs is excessively reduced. Thus, sending fewer ACKs has a "negative effect" on transport performance. However, in wireless scenarios, sending fewer ACKs also has a "positive effect" due to reduced contention. To better estimate this "positive effect," we assume no "negative effect" ideally. Consequently, "Ideal Goodput" refers to the ideal scenario where transport is not disturbed by reducing ACKs, while "Actual Goodput" reflects the real scenario where both "negative" and "positive" effects are present.

Figure 9(a) shows that goodput gain increases over faster wireless links. Figure 9(b) demonstrates that TACK's ideal goodput approaches the transport upper bound with minimized ACK frequency. The gap between UDP baseline and PHY capacity is due to non-ACK factors such as high medium acquisition overhead for data packets. Generating large A-MPDUs (Aggregated MAC Protocol Data Units [12]) may reduce this gap, but this is beyond the scope of this paper.

We then compare the actual goodput of TCP-TACK flows and TCP BBR flows over IEEE 802.11b/g/n/ac wireless links. A Wi-Fi host (Intel Wireless-AC 8260, 2 × 2) is connected to another wired host via a wireless router (TL-WDR7500). All devices are in a public room with over 10 additional APs and over 100 wireless users at peak times. Ping tests show RTTs varying between 4 to 200 ms, with slight burst losses. Single-flow tests are conducted repeatedly over all hours of the day for a full week.

Figure 10(a) shows that TCP-TACK achieves 20% to 28.1% average goodput improvement over TCP BBR. Our data traces also indicate that TCP-TACK sends significantly fewer ACKs than TCP BBR (e.g., over 802.11g wireless links, the number of data packets for TCP-TACK is approximately 1.9%, and for TCP BBR, it is approximately 50%), thereby significantly reducing contention on wireless links.

We also investigate the difference between the actual and ideal goodput of TCP BBR with prior ACK thinning mechanisms. We introduce data packet impairments (\(\rho = 0.1%\)) using a network emulator. Figure 10(b) shows that legacy TCP's actual goodput trend does not match the ideal trend (as illustrated in Figure 9(b)). This is likely due to TCP's control algorithms, such as loss recovery, round-trip timing, and send rate control, being disrupted by reduced ACK frequency. In contrast, TCP-TACK's actual performance approaches the ideal goodput improvement, validating the TACK-based protocol design. Similar results were observed in Wi-Fi Direct [5] links.

### 6.4 Deployment Experience: Miracast

TCP-TACK is deployed in commercial products such as the Huawei Mate20 Series Smartphone (Android 9) [43] and Honor Smart TV [44], providing optimized high-resolution wireless projection using Miracast. Miracast [4] allows users to wirelessly share multimedia, including high-resolution pictures and HD video content, between Wi-Fi devices. A predecessor (Android 8) of Huawei's product used RTP over UDP as the transport protocol, while the current commercial products have modified Miracast to enable TCP-based transmissions, i.e., TCP CUBIC, TCP BBR, and TCP-TACK.

The smartphone screen can be projected to a nearby TV, typically within 10 meters. Data traces are collected from both smartphones and TVs during A/B testing. Figure 11 summarizes the trace-based performance results. We found that TCP-TACK significantly reduces video rebuffering compared to legacy TCP or RTP-based projections. Additionally, TCP-TACK produces fewer macroblocking artifacts than RTP transport. The application-level benefits of TCP-TACK can be attributed to improved goodput due to reduced ACK overhead and effective loss recovery. These experiences demonstrate TACK's significant advantages for high-throughput and reliable wireless transport.

### 6.5 Performance over Combined Links of WLAN and WAN

TACK also performs well on hybrid connections involving both wired and wireless links. Figure 12 illustrates the topology. A wireless client (Intel Wireless-AC 8260, 2 × 2) connects to a wireless router (TL-WDR7500) within 10 meters. WLAN bandwidth is configured by setting different 802.11 standards on the wireless router. For example, the "802.11g only" policy provides a 54 Mbps bandwidth for the WLAN. A hardware network emulator is used to introduce packet impairments and transport latency between the wireless router and a wired server. For instance, setting a 100 ms latency on both ingress and egress ports of the network emulator results in a 200 ms RTT for the WAN. Packet loss rates on the data path (\(\rho\)) and ACK path (\(\rho'\)) can also be set on the ingress and egress ports, respectively.

Figure 13 shows the results when WLAN bandwidth is the bottleneck. Cases 1 and 2 involve a wireless client communicating with a domestic server, while Cases 3 and 4 involve a wireless client communicating with a cross-country server. All cases demonstrate TCP-TACK's advantage over legacy TCP in terms of goodput. This can be attributed to two reasons: (1) Significant reduction in ACK frequency improves WLAN bandwidth utilization, and (2) TCP-TACK's advancements in loss recovery, round-trip timing, and send rate control ensure robust transmission over long-delay and lossy WAN links.

Note that the number of ACKs in Case 1 is nearly 10 times that in Case 3, as the RTT on the WAN link increases to 10 times in Case 3. According to Equation (3), higher RTT results in lower TACK frequency, even though data throughput is substantially higher. Additionally, the number of ACKs in Case 4 is nearly 20 K larger than in Case 3, as TCP-TACK adds more ACKs on the return path when losses occur, primarily driven by loss events.

### 6.6 Experience over Real-World WAN Links

Although TACK-based protocols are designed for WLAN scenarios, we evaluated their performance in WAN scenarios. Specifically, we integrated TCP-TACK into Pantheon [59] and conducted long-term tests under various workloads (single flow or cross traffic). Pantheon is a global-scale community evaluation platform for academic research on TCP variants, with measurement nodes on wired networks and in cloud datacenters across nine countries, including the USA, UK, Japan, and Australia. Links between endpoints have varying bandwidth and latency and are non-dedicated, with wild cross traffic over the Internet.

We investigated the overall performance of TCP-TACK and a curated collection of 10 high-speed protocol variants: TCP Vegas [16], TCP CUBIC, TCP BBR [17], QUIC CUBIC (proto-quic [37]), PCC-Allegro [26], PCC-Vivace [27], Indigo [33], Copa [10], Verus [76], and Sprout [74]. All schemes used their recommended parameters [62].

For quantitative analysis, we summarized the performance of each scheme using a version of Kleinrock’s power metric [49] as the utility function \(\log\left(\frac{\text{Throughput}_{\text{avg}}}{\text{OWD}_{95th}}\right)\), where \(\text{Throughput}_{\text{avg}}\) denotes the mean throughput, and \(\text{OWD}_{95th}\) denotes the mean 95th percentile one-way delay (with clock synchronization [59]). Figure 14 illustrates the ranking of each scheme over 200 days [63]. For each test, the highest-power scheme has the smallest ranking value according to the utility metric. Figure 14 reveals that TCP-TACK achieves acceptable performance in WAN scenarios. This indicates that the proposed TACK-based protocol design overcomes the challenges of reducing ACK frequency. Note that due to less contention between data packets and ACKs in WAN, TACK achieves less performance gain in WAN than in WLAN.

### 7. Discussion, Limitations, and Future Work

**Buffer Requirement**: Sending fewer ACKs increases the bottleneck buffer requirement. Ideally, buffer requirement is determined by the minimum send window (\(W_{\text{min}}\)), i.e., \(W_{\text{min}} - bdp\). Given by [50], we have \(W_{\text{min}} = \beta^{-1} \cdot bdp\), \(\beta \geq 2\). By default, TCP-TACK (\(\beta = 4\)) requires a bottleneck buffer of 0.33 bdp. However, in practice, buffer requirements might increase if the send rate control does not behave properly under network dynamics. Pacing can help alleviate problems associated with increased buffer requirements [2, 50]. Our experiment results in WAN scenarios (Figure 14) reveal that TCP-TACK's buffer requirement (based on OWD estimate) can be bounded in practice. However, more substantial measurements are needed to deeply understand the buffer requirements of TACK-based protocols in the future.

**Handling Reordering**: Load balancing often splits traffic across multiple paths at a fine granularity [48]. By handling the prevalent small degree of reordering on the transport layer [52], we help the network layer achieve fine partition granularity, enabling the load balancer to consider less about reordering avoidance in traffic engineering. Thus, we define the IACK delay as an allowance for settling time ([14] and [21] recommend \(\frac{R_{T}T_{\text{min}}}{4}\)) before marking a packet lost. Generally, the IACK delay depends on the service's tolerance of retransmission redundancy and can be dynamically adjusted based on whether unnecessary retransmissions occur, which is left for future work.

**Congestion Controller**: TACK impacts the implementation of congestion controllers. For example, to work with TACK, it is necessary to change sender-based control to receiver-based control. This paper adopted a TACK-based congestion controller co-designed with BBR in a receiver-based manner. Figure 15 shows that the co-designed BBR has similar TCP friendliness to the standard BBR. In other words, as an ACK mechanism, TACK enhances the performance of the congestion controller without compromising fairness.