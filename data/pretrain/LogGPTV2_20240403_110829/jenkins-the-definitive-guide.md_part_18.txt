classes in a separated directory, so that they don’t get bundled up and deployed to production by accident:
¶
•
‚
„
¶ We can only instrument the application classes once they have been compiled.
• Remove any coverage data generated by previous builds.
‚ Remove any previously instrumented classes.
„ Instrument the application classes (but not the test classes) and place them in the
${instrumented.dir} directory.
At this stage, the ${instrumented.dir} directory contains an instrumented version of our application
classes. Now all we need to do to generate some useful code coverage data is to run our unit tests against
the classes in this directory:
150
¶
•
¶ Run the JUnit tests against the instrumented application classes.
• The instrumented classes use Cobertura classes, so the Cobertura libraries also need to be on the
classpath.
This will produce the raw test coverage data we need to produce the XML test coverage reports that
Jenkins can use. To actually produce these reports, we need to invoke another task, as shown here:
Finally, don’t forget to tidy up after your done: the clean target should delete not only the generated
classes, but also the generated instrumented classes, the Cobertura coverage data, and the Cobertura
reports:
Once this is done, you are ready to integrate your coverage reports into Jenkins.
6.6.1.3. Installing the Cobertura code coverage plugin
Once code coverage data is being generated as part of your build process, you can configure Jenkins
to report on it. This involves installing the Jenkins Cobertura plugin. We went through this process
in Section 2.8, “Adding Code Coverage and Other Metrics”, but we’ll run through it again to refresh
your memory. Go to the Manage Jenkins screen, and click on Manage Plugins. This will take you to
151
the Plugin Manager screen. If Cobertura has not been installed, you will find the Cobertura Plugin in
the Available tab, in the Build Reports section (see Figure 6.11, “Installing the Cobertura plugin”). To
install it, just tick the checkbox and press enter (or scroll down to the bottom of the screen and click
on the “Install” button). Jenkins will download and install the plugin for you. Once the downloading is
done, you will need to restart your Jenkins server.
Figure 6.11. Installing the Cobertura plugin
6.6.1.4. Reporting on code coverage in your build
Once you have installed the plugin, you can set up code coverage reporting in your build jobs. Since
code coverage can be slow and memory-hungry, you would typically create a separate build job for
this and other code quality metrics, to be run after the normal unit and integration tests. For very large
projects, you may even want to set this up as a build that only runs on a nightly basis. Indeed, feedback
on code coverage and other such metrics is usually not as time-critical as feedback on test results, and
this will leave build executors free for build jobs that can benefit from snappy feedback.
As we mentioned earlier, Jenkins does not do any code coverage analysis itself—you need to configure
your build to produce the Cobertura coverage.xml file (or files) before you can generate any nice
graphs or reports, typically using one of the techniques we discussed previously (see Figure 6.12, “Your
code coverage metrics build needs to generate the coverage data”).
Figure 6.12. Your code coverage metrics build needs to generate the coverage data
Once you have configured your build to produce some code coverage data, you can configure Cobertura
in the “Post-build Actions” section of your build job. When you tick the “Publish Cobertura Coverage
152
Report” checkbox, you should see something like Figure 6.13, “Configuring the test coverage metrics
in Jenkins”.
Figure 6.13. Configuring the test coverage metrics in Jenkins
The first and most important field here is the path to the Cobertura XML data that we generated. Your
project may include a single coverage.xml file, or several. If you have a multimodule Maven project,
for example, the Maven Cobertura plugin will generate a separate coverage.xml file for each module.
The path accepts Ant-style wildcards, so it is easy to include code coverage data from several files. For
any Maven project, a path like **/target/site/cobertura/coverage.xml will include all of the
code coverage metrics for all of the modules in the project.
There are actually several types of code coverage, and it can sometimes be useful to distinguish between
them. The most intuitive is Line Coverage, which counts the number of times any given line is executed
during the automated tests. “Conditional Coverage” (also referred to as “Branch Coverage”) takes into
account whether the boolean expressions in if statements and the like are tested in a way that checks all
the possible outcomes of the conditional expression. For example, consider the following code snippet:
if (price > 10000) {
managerApprovalRequired = true;
}
To obtain full Conditional Coverage for this code, you would need to execute it twice: once with a value
that is more than 10,000, and one with a value of 10,000 or less.
Other more basic code coverage metrics include methods (how many methods in the application were
exercised by the tests), classes and packages.
153
Jenkins lets you define which of these metrics you want to track. By default, the Cobertura plugin will
record Conditional, Line, and Method coverage, which is usually plenty. However it is easy to add other
coverage metrics if you think this might be useful for your team.
Jenkins code quality metrics are not simply a passive reporting process—Jenkins lets you define how
these metrics affect the build outcome. You can define threshold values for the coverage metrics that
affect both the build outcome and the weather reports on the Jenkins dashboard (see Figure 6.14, “Test
coverage results contribute to the project status on the dashboard”). Each coverage metric that you track
takes three threshold values.
Figure 6.14. Test coverage results contribute to the project status on the dashboard
The first (the one with the sunny icon) is the minimum value necessary for the build to have a sunny
weather icon. The second indicates the value below which the build will be attributed a stormy weather
icon. Jenkins will extrapolate between these values for the other more nuanced weather icons.
The last threshold value is simply the value below which a build will be marked as “unstable”—the
yellow ball. While not quite as bad as the red ball (for a broken build), a yellow ball will still result in
a notification message and will look bad on the dashboard.
This feature is far from simply a cosmetic detail—it provides a valuable way of setting objective code
quality goals for your projects. Although it cannot be interpreted alone, falling code coverage is generally
not a good sign in a project. So if you are serious about code coverage, use these threshold values to
provide some hard feedback about when things are not up to scratch.
6.6.1.5. Interpreting code coverage metrics
Jenkins displays your code coverage reports on the build job home page. The first time it runs, it produces
a simple bar chart (see Figure 2.30, “Jenkins displays code coverage metrics on the build home page”).
From the second build onwards, a graph is shown, indicating the various types of coverage that you are
tracking over time (see Figure 6.15, “Configuring the test coverage metrics in Jenkins”). In both cases,
the graph will also show the code coverage metrics for the latest build.
154
Figure 6.15. Configuring the test coverage metrics in Jenkins
Jenkins also does a great job letting you drill down into the coverage metrics, displaying coverage
breakdowns for packages, classes within a package, and lines of code within a class (see Figure 6.16,
“Displaying code coverage metrics”). No matter what level of detail you are viewing, Jenkins will
display a graph at the top of the page showing the code coverage trend over time. Further down, you
will find the breakdown by package or class.
Figure 6.16. Displaying code coverage metrics
Once you get to the class details level, Jenkins will also display the source code of the class, with the lines
color-coded according to their level of coverage. Lines that have been completely executed during the
tests are green, and lines that were never executed are marked in red. A number in the margin indicates
155
the number of times a given line was executed. Finally, yellow shading in the margin is used to indicate
insufficient conditional coverage (for example, an if statement that was only tested with one outcome).
6.6.2. Measuring Code Coverage with Clover
Clover is an excellent commercial code coverage tool from Atlassian4. Clover works well for projects
using Ant, Maven, and even Grails. The configuration and use of Clover is well documented on the
Atlassian website, so we won’t describe these aspects in detail. However, to give some context, here is
what a typically Maven 2 configuration of Clover for use with Jenkins would look like:
...
...
com.atlassian.maven.plugins
maven-clover2-plugin
3.0.4
false
true
...
This will generate both an HTML and XML coverage report, including aggregated data if the Maven
project contains multiple modules.
To integrate Clover into Jenkins, you need to install the Jenkins Clover plugin in the usual manner using
the Plugin Manager screen. Once you have restarted Jenkins, you will be able to integrate Clover code
coverage into your builds.
Running Clover on your project is a multistep project: you instrument your application code, run your
tests, aggregate the test data (for multimodule Maven projects) and generate the HTML and XML
reports. Since this can be a fairly slow operation, you typically run it as part of a separate build job, and
not with your normal tests. You can do this as follows:
$ clover2:setup test clover2:aggregate clover2:clover
Next, you need to set up the Clover reporting in Jenkins. Tick the Publish Clover Coverage Report
checkbox to set this up. The configuration is similar to that of Cobertura—you need to provide the path
to the Clover HTML report directory, and to the XML report file, and you can also define threshold
values for sunny and stormy weather, and for unstable builds (see Figure 6.17, “Configuring Clover
reporting in Jenkins”).
4 http://www.atlassian.com/software/clover
156
Figure 6.17. Configuring Clover reporting in Jenkins
Once you have done this, Jenkins will display the current level of code coverage, as well as a graph
of the code coverage over time, on your project build job home page (see Figure 6.18, “Clover code
coverage trends”).
Figure 6.18. Clover code coverage trends
6.7. Automated Acceptance Tests
Automated acceptance tests play an important part in many agile projects, both for verification and
for communication. As a verification tool, acceptance tests perform a similar role to integration tests,
and aim to demonstrate that the application effectively does what is expected of it. But this is almost
a secondary aspect of automated Acceptance Tests. The primary focus is actually on communication
—demonstrating to nondevelopers (business owners, business analysts, testers, and so forth) precisely
where the project is at.
Acceptance tests should not be mixed with developer-focused tests, as both their aim and their audience
is very different. Acceptance tests should be working examples of how the system works, with an
emphasis on demonstration rather than exhaustive proof. The exhaustive tests should be done at the
unit-testing level.
157
Acceptance Tests can be automated using conventional tools such as JUnit, but there is a growing
tendency to use Behavior-Driven Development (BDD) frameworks for this purpose, as they tend to be a
better fit for the public-facing nature of Acceptance Tests. Behavior-driven development tools used for
automated Acceptance Tests typically generate HTML reports with a specific layout that is well-suited
to nondevelopers. They often also produce JUnit-compatible reports that can be understood directly by
Jenkins.
Behavior-Driven Development frameworks also have the notion of “Pending tests,” tests that are
automated, but have not yet been implemented by the development team. This distinction plays an
important role in communication with other non-developer stakeholders: if you can automated these tests
early on in the process, they can give an excellent indicator of which features have been implemented,
which work, and which have not been started yet.
As a rule, your Acceptance Tests should be displayed separately from the other more conventional
automated tests. If they use the same testing framework as your normal tests (e.g., JUnit), make sure
they are executed in a dedicated build job, so that non-developers can view them and concentrate on
the business-focused tests without being distracted by low-level or technical ones. It can also help to
adopt business-focused and behavioural naming conventions for your tests and test classes, to make
them more accessible to non-developers (see Figure 6.19, “Using business-focused, behavior-driven
naming conventions for JUnit tests”). The way you name your tests and test classes can make a huge
difference when it comes to reading the test reports and understanding the actual business features and
behavior that is being tested.
Figure 6.19. Using business-focused, behavior-driven naming conventions for JUnit tests
If you are using a tool that generates HTML reports, you can display them in the same build as your
conventional tests, as long as they appear in a separate report. Jenkins provides a very convenient plugin
for this sort of HTML report, called the HTML Publisher plugin (see Figure 6.20, “Installing the HTML
Publisher plugin”). While it is still your job to ensure that your build produces the right reports, Jenkins
can display the reports on your build job page, making them easily accessible to all team members.
158
Figure 6.20. Installing the HTML Publisher plugin
This plugin is easy to configure. Just go to the “Post-build Actions” section and tick the “Publish HTML
reports” checkbox (see Figure 6.21, “Publishing HTML reports”). Next, give Jenkins the directory your
HTML reports were generated to, an index page, and a title for your report. You can also ask Jenkins
to store the reports generated for each build, or only keep the latest one.
Figure 6.21. Publishing HTML reports
Once this is done, Jenkins will display a special icon on your build job home page, with a link to your
HTML report. In Figure 6.22, “Jenkins displays a special link on the build job home page for your
report”, you can see the easyb reports we configured previously in action.
Figure 6.22. Jenkins displays a special link on the build job home page for your report
159
The HTML Publisher plugin works perfectly for HTML reports. If, on the other hand, you want to (also)
publish non-HTML documents, such as text files, PDFs, and so forth, then the DocLinks plugin is for
you. This plugin is similar to the HTML Publisher plugin, but lets you archive both HTML reports as
well as documents in other formats. For example, in Figure 6.23, “The DocLinks plugin lets you archive
both HTML and non-HTML artifacts”, we have configured a build job to archive both a PDF document
and an HTML report. Both these documents will now be listed on the build home page.
Figure 6.23. The DocLinks plugin lets you archive both HTML and non-HTML artifacts
6.8. Automated Performance Tests with JMeter
Application performance is another important area of testing. Performance testing can be used to
verify many things, such as how quickly an application responds to requests with a given number
of simultaneous users, or how well the application copes with an increasing number of users. Many
applications have Service Level Agreements, or SLAs, which define contractually how well they should
perform.
Performance testing is often a one-off, ad-hoc activity, only undertaken right at the end of the project
or when things start to go wrong. Nevertheless, performance issues are like any other sort of bug—the
later on in the process they are detected, the more costly they are to fix. It therefore makes good of sense
to automate these performance and load tests, so that you can spot any areas of degrading performance
before it gets out into the wild.
JMeter5 is a popular open source performance and load testing tool. It works by simulating load on your
application, and measuring the response time as the number of simulated users and requests increase.
It effectively simulates the actions of a browser or client application, sending requests of various sorts
(HTTP, SOAP, JDBC, JMS and so on) to your server. You configure a set of requests to be sent to
5 http://jakarta.apache.org/jmeter/
160
your application, as well as random pauses, conditions and loops, and other variations designed to better
imitate real user actions.
JMeter runs as a Swing application, in which you can configure your test scripts (see Figure 6.24,
“Preparing a performance test script in JMeter”). You can even run JMeter as a proxy, and then