space for Position Map and Stash; Populate is the taken time to
write real blocks to the server storage; Write-back corresponds to
the time taken to write-back to a regular file format.
16M 128M 512M
1G
IPC overhead
368
1322
2298
4235
TABLE IV: Time taken to pass various messages from untrusted
proxy to untrusted service through shared memory channel in chunks
of 4KB for OBLIVIATE (in milli-seconds).
multiple blocks have to be read to access a block, which
naturally results in a higher number of overall page faults
(considering the attacker invalidates all pages). Also, since
the experiment attempts to access the same index, we observe
that each access using OBLIVIATE leaves a different memory
footprint to be observed by the attacker. This is in accordance
with the principles of ORAM which ensure that access patterns
are completely indistinguishable from each other. As a result,
the attacker is blinded as to whether the same file offset was
accessed or a different one.
B. Micro-Benchmarks
We attempt to answer the following questions through this
subsection: (1) How does OBLIVIATE compare in performance
to the other available filesystems?; (2) What is the degree of
improvement observed when using an exitless scheme over
a naive scheme?; (3) What is the performance improvement
achieved by using the non-EPC memory for ORAM server
placement instead of the EPC memory?; (4) What is the
latency added by the communication channel on the overall
performance?; and (5) What is the memory overhead imposed
by OBLIVIATE over other available filesystems?
To this end, we show the results of sequential and random
read/write operations and also discuss OBLIVIATE’s overhead
on open and close operations. We use Iozone [30], which
is an open-source tool, widely used to benchmark filesystem
performance. Iozone provides throughput numbers which are
amortized over different runs. Since it is designed specifically
in order to gauge the performance of a filesystem, we evaluate
OBLIVIATE using Iozone. In order to facilitate the reader, we
present a component-wise breakdown of the numbers.
Open/Close. Table III depicts the performance overhead
(in terms of seconds) imposed in opening and closing the
file by OBLIVIATE. Firstly, OBLIVIATE has to transform the
regular file into an ORAM tree layout, OBLIVARRAY. This
step involves: (a) creating the tree and (b) populating the tree
with data from the original file. OBLIVIATE incurs overheads
ranging from 2-20s to complete these tasks depending on the
file size. This overhead is unavoidable since a regular file cannot
be processed with ORAM-based access protocols. At the time
of finishing the file uses (i.e., exiting an enclave), OBLIVIATE
(a) In-memory FS
(b) Obliviate
Fig. 8: Runtime memory access patterns (page faults) captured by the
SGX driver. As expected, the in-memory FS exhibits the exact same
memory footprint since the same offset is being accessed. OBLIVIATE
conversely shows different memory footprints on each access.
would exhibit a different pattern. An attacker observing the
different pattern on the second run cannot tell whether this was
the same offset or another offset within the file. Furthermore,
with OBLIVIATE, the attacker cannot even tell whether this
was the same file or a different file as OBLIVIATE employs
two-tiered ORAM tree. Therefore, an attacker cannot obtain a
meaningful context by observing the access pattern onto the
ORAM server storage.
As mentioned in §VI-B1, naively deploying ORAM within
an SGX enclave leaves an attack surface to side-channel attacks.
This is true for both the position map and the stash which are
key metadata structures for ORAM. Elaborating further, the
attacker can pinpoint the block being accessed by observing
which index within the position map is accessed. The attacker
can also know which block is real and which is dummy by
observing which block was actually copied onto the provided
buffer. The data oblivious schemes used by OBLIVIATE ensure
that both of the aforementioned transactions always exhibit the
same trace on each run, preventing potential inferences by an
attacker §VI-B1. Since each access will follow the same path,
i.e., from the start to the end of the data structure, an attacker
is again provided with no information that could help him/her.
Experimental Security Evaluation.
In order to show how
OBLIVIATE leaves memory access patterns with its ORAM
implementation, we show observed page faults for OBLIVIATE.
Recall that, when demonstrating our attack case study using
SQLite in §IV, we have also provided OBLIVIATE’s memory
trace for comparison (shown in Figure 4-(b)). In this figure,
while the in-memory FS showed the same access pattern for the
query with the same semantics, OBLIVIATE showed different
access patterns for those due to ORAM based operations. From
attacker’s perspective, this implies that she/he would not be
able to infer query semantics based on the access patterns.
In addition, we also performed another experiment which
attempts to access the same file offset multiple times. Then
we captured the corresponding memory access patterns made
in an enclave, using the SGX driver (which is part of the
untrusted kernel). Figure 8 shows the results on the in-memory
filesystem as well as on OBLIVIATE. We can observe the
following: (a) OBLIVIATE exhibits more page faults than the in-
memory FS and (b) OBLIVIATE’s execution pattern is different
on each access whereas the in-memory filesystem leaves the
same memory footprint. ORAM-based access dictates that
11
TimeMemory AddressTimeMemory Addresswrites back the contents to the regular file, which takes from 3
to 16s. The whole file is written back instead of the modified
parts in order to preserve privacy.
Read/Writes.
Figure 9 shows the read/write throughput
achieved in running iozone. As expected, the native (non-SGX)
FS is the most efficient one. The hybrid FS is slower than the
native FS but is not as slow as the complete in-memory FS or
OBLIVIATE. The reason for this is that the hybrid FS stores the
file buffers in the non-EPC memory region (but within DRAM)
and only copies in-use pages inside the EPC memory. The
in-memory FS is slow since it buffers all file contents within
the EPC memory and therefore competes with the LibOS and
user application for limited EPC pages. This contention of
limited EPC memory result in abundant swap-ins/outs which
incur considerable overhead [32].
OBLIVIATE performs 1.5-2.0× worse than the in-memory
FS for our workloads. The overhead of OBLIVIATE is un-
avoidable since it uses expensive ORAM operations and data
oblivious algorithms to provide complete security. However,
since OBLIVIATE uses the non-EPC memory (with custom
encryption) to store the server storage along with other
optimizations, it is able to compete with the in-memory FS.
It can also be observed that the throughput of both native FS
and hybrid FS increases with the increase in file size whereas
the throughput of in-memory FS ans OBLIVIATE decreases.
For in-memory FS, that is because there is more contention in
the EPC memory region whereas for OBLIVIATE, it is simply
because we have to perform operations on a larger ORAM tree.
As far as the overhead imposed by OBLIVIATE is concerned,
we believe that this is the overhead that any ORAM-based
solution is likely to incur. This is justified since ORAM has
to access multiple (say N where 2N is the height of the tree)
blocks per memory access and has to write-back the same
number of blocks. Therefore, OBLIVIATE has to access a total
of 2N blocks compared to a single block that has to be accessed
by an insecure filesystem.
Optimization Effectiveness: Message Queues and Non-
EPC Server Placement.
In order to show effectiveness
of OBLIVIATE’s optimization techniques, namely message
queues (§VI-A) and non-EPC ORAM server placement
schemes (§VI-B2), we quantize the performance improvements
over the native scheme of each optimization technique. First,
for OBLIVIATE’s message queues, we modified OBLIVIATE
to use ocall mechanism in order to perform message passing
instead of using message queues. Figure 10a shows the results
we obtained while running a simple random read over a range
of data using iozone. As shown, the message queues provide a
performance improvement of 20 − 40% over the naive ocall
scheme. It has been reported previously [7, 32] that enclave exits
are expensive because of context switches and TLB flushes.
To show the effectiveness of using the non-EPC storage
as a medium to store the ORAM server storage, we perform
an experiment where OBLIVIATE uses either EPC or non-EPC
memory region (with our own encryption scheme) in order
to store the ORAM server storage. Figure 10b provides a
comparison of achieved throughput in both scenarios using
Iozone. Since the EPC memory region is small and thus incur-
ring costly swap-in and swap-out, OBLIVIATE’s optimization
schemes show much better throughput. For a 16MB file, the
throughput difference is around 1.25× which reaches to more
than 9× as the file size increases to 1GB.
IPC Overhead.
In Table IV, we compare the overheads of
inter-process communication as we send messages of different
sizes in chunks of 4KB. OBLIVIATE uses shared memory queues
in order to create an IPC channel between the untrusted proxy
and untrusted service (refer §VI-A). As can be observed, the
overhead of shared memory communication increases linearly
to the size of the message. However, there are two things
to consider here. Firstly, this cost (per individual message)
is negligible as compared to the cost of a single ORAM
access. Secondly, OBLIVIATE can be easily adapted to act as a
filesystem which is bundled with the same application, which
will remove the extra latency added by this communication
channel. However, this design choice would have to abandon
the security principle, the principle of separation.
Memory Overhead. OBLIVIATE requires more memory than
a complete in-memory filesystem since it has to create a
multi-tier ORAM tree in-memory. Our evaluations show that
OBLIVIATE’s ORAM-based tree consumes around 6-8× more
memory than the actual file size it tries to map into its tree.
C. Macro-Benchmarks
This subsection evaluates OBLIVIATE and other filesys-
tems in running real-world applications, SQLite [33] and
Lighttpd [22]. We chose these applications since both are
inherently more I/O-intensive than CPU-intensive. To create
a comparison against all SGX-based filesystems, we show
the results from in-memory filesystem, hybrid filesystem, and
OBLIVIATE.
SQLite [33] is a popular open-source database application.
It frequently used to access database files to process SQL
queries which rely on open, read, write, etc. to fetch/update
data. Figure 11a depicts the results in running SQLite. In
this experiment, we run speedtest, a stressed performance
testing script included in SQLite. This inserts 50,000 entries
into the database and attempt to select the 50,000 entries
that we inserted. The results of our experiments show that
OBLIVIATE incurs an overhead of approximately 4× over the
hybrid filesystem and approximately 1.5× over the in-memory
filesystem.
Lighttpd [22] is a popular light-weight web server. It fits
OBLIVIATE’s criteria since it performs heavy I/O intensive jobs
(i.e., reads many files from its memory and transmits them to
the client). Our tests use simple workloads that are observed
as part of web search operations in datacenters [6]. These
workloads show that most of the flows are within a range of
1 KB and 1 MB, and therefore our testing is uniformly within
this range. As shown in Figure 11b, OBLIVIATE is not as fast
as in-memory and hybrid file systems, but its overhead is low.
To be more specific, OBLIVIATE exhibits less than 1.2× the
overhead of the in-memory filesystem and around 2× overhead
over the hybrid filesystem.
In all our evaluations, we see that a baseline ORAM solution
would add a fair amount of overhead to existing filesystem
solutions for SGX. Since OBLIVIATE employs an ORAM based
access mechanism which guarantees security but is expensive
in nature, it is well expected that OBLIVIATE would perform
12
(a) Sequential reads
(b) Sequential writes
(c) Random reads
(d) Random writes
Fig. 9: Iozone benchmark results while varying the file size. X-axis represents a file size, and Y-axis represents the throughput achieved in
KB/s. For each experiments, we read 4KB chunks. The parameters for OBLIVIATE are K = 1, B = 3, and D = 4096. The value of leaf nodes is
calculated based on the value of D and filesize.
is kept local and simply updated to keep the latest copy on
Dropbox. By using OBLIVIATE, the user can securely store and
retrieved his/her data solely on the server since OBLIVIATE
employs ORAM at the server side.
Databases. Cloud-based database services especially storing
personal information merit the use of SGX. As can clearly be
inferred from §IV, database systems running within SGX are
insecure. This security issue can be mitigated using OBLIVIATE.
As we evaluate in §VIII-C, employing OBLIVIATE with a
database system such as SQLite [33] can ensure security with
acceptable overhead (around 2× that of an in-memory FS).
Web Servers. Naive application of webservers (e.g., Ng-
inx [35], Apache [1] etc.) would leak which webpage was
accessed by which user (through correlating with the IP address).
OBLIVIATE protects both file offsets and which file was actually
accessed from being leaked and is therefore a good fit for
security-critical web servers.
B. Other Side-Channel Attacks.
It is difficult to completely prevent side-channel attacks,
especially if the attacking method is not known beforehand.
Although OBLIVIATE’s security guarantees can be also broken
due to new side-channel attack methods in the future, we
still believe the security primitives that OBLIVIATE provides
are general (i.e., exhibiting non-deterministic memory access
patterns in accessing files) and thus OBLIVIATE would be able
to raise the protection bar of against those attacks. For example,
a new side-channel attack against SGX, branch shadowing [23]
attack, was reported recently. The branch shadowing attack
exploits the fact that when an SGX enclave context switches
from the EPC to the non-EPC memory, it leaves its branch
information uncleared. Using such information, the attacker can
gain fine-grained information into the internal workings of the
SGX enclave. However, OBLIVIATE’s ORAM based access is
still secure against such attacks since the underlying assumption
with ORAM is that the attacker can see all the memory accesses
being performed and yet gain no information. Moreover, the
data oblivious access schemes used by OBLIVIATE ensure that,
despite fine-grained observation into the ORAM metadata, the
attacker is able to learn nothing.
X. RELATED WORK
Attacks against Intel SGX. There are three main side-channel
attacks that plague Intel SGX — syscall based, page fault based,
and cache based. Unlike syscall snooping, which is a passive
(a) Exitless Vs OCALL
(b) EPC Vs Non-EPC
Fig. 10: Effectiveness of OBLIVIATE’s optimization techniques. The
figure (a) depicts the the latency (y-axis) while varying the the data
size to be transmitted (x-axis) for exitless scheme [32] and a naive
ocall scheme. The figure (b) shows the throughput (y-axis) to store
the ORAM server storage using either EPC or encrypted non-EPC.