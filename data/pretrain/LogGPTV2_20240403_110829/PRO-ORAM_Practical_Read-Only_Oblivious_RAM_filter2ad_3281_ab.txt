a complex ORAM protocol that is optimized for bandwidth.
It uses a partition-based ORAM [42] where each partition is
itself a hierarchical ORAM [22]. This design takes O(log N)
time to access each block even if the protocol was restricted
to serve read-only requests. Hence, our observations in the
read-only model do not directly provide performance beneﬁts
to ObliviStore’s construction. The key factor in PRO-ORAM is
that — “simple and specialized is better” — a simple ORAM
construction which is non-optimized for the general case, is
better suited for hiding read-only data access patterns.
3 Background
In designing an efﬁcient PRO-ORAM scheme, we select square-
√
root ORAM as our underlying ORAM scheme as it allows
N accesses before the shufﬂing step. To obliviously shuf-
ﬂe the data in parallel with the accesses, we select the Mel-
√
bourne shufﬂe scheme, that allows shufﬂing of data of O(N)
in O(
N) steps. Further, we use Intel SGX-enabled CPU
present to create enclaves with O(
N) private storage. We
provide a brief background on each of these building blocks.
√
3.1 Square-Root ORAM
We select the square-root ORAM scheme as the underlying
√
building block in PRO-ORAM. The square-root ORAM scheme,
as proposed by Goldreich and Ostrovsky [22], uses N +
N
N stash memory, both of them
permuted memory and a
are stored encrypted on the untrusted cloud storage. The per-
muted memory contains N real blocks and
N dummy blocks
arranged according to a pseudo-random permutation π.
√
√
To access a block, the protocol ﬁrst scans the entire stash
deterministically for the block. If the requested block is found
in the stash then the protocol makes a fake access to a dummy
block in the permuted memory. Otherwise, it accesses the
√
real block from the permuted memory. The accessed block
is then written to the stash by re-encrypting the entire
N
stash memory. The key trick here is that all accesses exhibit a
deterministic access order to the adversarial server, namely: a
deterministic scan of the stash elements, followed by an ac-
cess to a real or dummy block in permuted memory, followed
by a ﬁnal re-encrypted write and update to the stash. After ev-
ery
N requests, the protocol updates the permuted memory
with the stash values and obliviously permutes (shufﬂes) it
√
randomly. This shufﬂing step incurs O(N log2 N) overhead, re-
N log2 N) per request.
sulting in an amortized latency of O(
√
Intel SGX
3.2
Recently, Intel proposed support for a trusted hardware primi-
tive called Software Guard Extensions (SGX). With SGX, we
can create isolated memory regions called enclaves which are
200          22nd International Symposium on Research in Attacks, Intrusions and DefensesUSENIX Association(cid:2)(cid:1)
(cid:16)
(cid:17)
(cid:20)(cid:1)
(cid:19)(cid:1)
(cid:5)(cid:12)(cid:20)(cid:11)(cid:11)(cid:14)(cid:10)(cid:1)(cid:4)(cid:7)(cid:18)(cid:18)(cid:1)(cid:2)(cid:1)
(cid:9)(cid:13)(cid:18)(cid:19)(cid:21)(cid:17)(cid:12)(cid:7)(cid:18)(cid:10)(cid:22)(cid:1)
(cid:9)(cid:13)(cid:18)(cid:19)(cid:21)(cid:17)(cid:12)(cid:7)(cid:18)(cid:10)(cid:23)(cid:1)
(cid:8)(cid:14)(cid:10)(cid:7)(cid:16)(cid:20)(cid:17)(cid:21)(cid:17)(cid:12)(cid:7)(cid:18)(cid:10)(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
πtemp 
(cid:6)(cid:1)
(cid:10)(cid:1)
(cid:15)(cid:1)
(cid:17)(cid:1)
(cid:5)(cid:12)(cid:20)(cid:11)(cid:11)(cid:14)(cid:10)(cid:1)(cid:4)(cid:7)(cid:18)(cid:18)(cid:1)(cid:2)(cid:2)(cid:1)
(cid:9)(cid:13)(cid:18)(cid:19)(cid:21)(cid:17)(cid:12)(cid:7)(cid:18)(cid:10)(cid:22)(cid:1)
(cid:9)(cid:13)(cid:18)(cid:19)(cid:21)(cid:17)(cid:12)(cid:7)(cid:18)(cid:10)(cid:23)(cid:1)
(cid:8)(cid:14)(cid:10)(cid:7)(cid:16)(cid:20)(cid:17)(cid:21)(cid:17)(cid:12)(cid:7)(cid:18)(cid:10)(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
π 
(cid:3)
(cid:20)(cid:1)
(cid:19)(cid:1)
(cid:17)
(cid:20)(cid:1)
(cid:19)(cid:1)
Figure 2: Overview of the Melbourne shufﬂe algorithm
inaccessible to the underlying operating system or any other
application. In PRO-ORAM, we use the following two important
features of Intel SGX. PRO-ORAM can be build using any other
trusted hardware that provides these speciﬁc features.
Enclaved Memory. SGX allows the creation of hardware-
isolated private memory region or enclaved memory. For SGX
CPUs, BIOS allocates a certain region for processor reserved
memory (PRM) at the time of boot up. The underlying CPU
reserves a part of this PRM to create enclaves. All the code
and data in the enclaved memory is inaccessible even to the
privileged software such as the OS. Thus, an adversary in our
threat model cannot access this protected memory. It guaran-
tees conﬁdentiality of the private data within enclaves from
the adversary. At present, SGX supports 90 MB of enclaved
memory. This allows us to use a moderate amount of private
storage at the cloud provider. Further, we can create multiple
threads within an enclave [39].
Attestation. Along with enclaved execution, SGX-enabled
CPUs support remote attestation of the software executing
within an enclave. This security features enables a remote
party to verify the integrity of the software executing on an
untrusted platform such as the cloud. Further, it supports
local attestation between two enclaves executing on the same
machine. These enclaves can then establish a secure channel
and communicate with each other. One can perform such
attestation of an enclave program as described in the SGX
manual [1]. Thus, SGX-enabled CPUs at the cloud provider
allows executing trusted code base (TCB) with a small amount
of private storage at the cloud provider.
3.3 Melbourne Shufﬂe
Melbourne shufﬂe is a simple and efﬁcient randomized obliv-
ious shufﬂe algorithm [33]. Using this algorithm, we can
obliviously shufﬂe N data blocks with O(N) external memory.
The data is stored at the server according to a pseudo-random
permutation. The encryption key and the permutation key π
√
require constant storage and are stored in the private memory.
√
N) and
This algorithm uses private storage of the size O(
incurs a communication and message complexity of O(
N).
We use this algorithm in PRO-ORAM to shufﬂe the encrypted
data in parallel to accessing data blocks using enclave mem-
ory as the private storage.
√
N. Further, every 4
The algorithm works in two passes as shown in Figure 2. It
ﬁrst shufﬂes the given input according to a random permuta-
tion πtemp and then shufﬂes the intermediate permutation to
the desired permutation of π. Each pass of the shufﬂe algo-
rithm has three phases, two distribution and a cleanup phase.
√
The algorithm divides each N size array into buckets of size
√
N of these buckets are put together to
form a chunk. Thus, the N array is divided into total
N
chunks. The ﬁrst distribution phase (dist_phase1) simply
puts the data blocks into correct chunks based on the desired
permutation πtemp in the ﬁrst pass and π in the second pass.
The second distribution phase (dist_phase2) is responsible
for placing the data blocks into correct buckets within each
chunk. Finally, the clean up phase (cleanup_phase) arranges
the data blocks in each bucket and places them in their correct
positions based on the permutation key.
4
Choosing appropriate constants in the algorithm guarantees
oblivious shufﬂing of N data blocks for any chosen permu-
tation value π with a very high probability. The important
point is that each of these phases can be implemented to have
a “constant” depth and operate “independently” based only
on the pre-decided πtemp and π values. This allows us to dis-
tribute the overall computation among multiple threads and
parallelize the algorithm. Although the total work done re-
mains the same, our design effectively reduces the overall
execution time to a constant. We refer readers to the original
paper for the detailed algorithm of each of these phases [33].
3.4 Encryption Algorithms
We use standard symmetric key and public key cryptographic
schemes as our building blocks in PRO-ORAM. We assume that
both these schemes guarantee IND-CPA security. The security
guarantees of PRO-ORAM depends on the assumption of using
secure underlying cryptographic schemes. We denote by SE =
(GenSE ,EncSE ,DecSE ) a symmetric key encryption scheme
where GenSE algorithm generates a key which is used by
the EncSE and DecSE algorithms to perform encryption and
decryption respectively. PKE = (GenPKE ,EncPKE ,DecPKE )
denotes a public key encryption scheme where the GenPKE
algorithm generates a public-private key pair (Pb,Pr). The
EncPKE algorithm takes the public key Pb as input and en-
crypts the data whereas the DecPKE takes the private key Pr
as input and decrypts the ciphertext.
4 PRO-ORAM Details
Today’s cloud platforms are equipped with a large amount
of storage and computing units. In PRO-ORAM, we leverage
these resources to achieve practical performance guarantees
for hiding access patterns to read-only data such as photos,
music, videos and so on.
USENIX Association        22nd International Symposium on Research in Attacks, Intrusions and Defenses 201Untrusted Storage 
Next Array 
Active Array 
Encrypted data 
(cid:3)(cid:17)(cid:15)(cid:18)(cid:19)(cid:17)(cid:15)(cid:12)(cid:20)(cid:9)(cid:8)(cid:1)
(cid:5)(cid:17)(cid:10)(cid:21)(cid:24)(cid:6)(cid:19)(cid:9)(cid:1)(cid:5)(cid:21)(cid:6)(cid:7)(cid:13)(cid:1)
(cid:5)(cid:11)(cid:22)(cid:10)(cid:10)(cid:14)(cid:9)(cid:1)(cid:4)(cid:16)(cid:7)(cid:14)(cid:6)(cid:23)(cid:9)(cid:1)
(cid:1)
(cid:2)(cid:7)(cid:7)(cid:9)(cid:20)(cid:20)(cid:1)(cid:4)(cid:16)(cid:7)(cid:14)(cid:6)(cid:23)(cid:9)(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
O(√N) 
threads 
Upload 
(cid:27)
(cid:28)
2  3  4 
(cid:30)(cid:29)
(cid:31)
Read 
(cid:28)
Untrusted 
d 
 Server 
Trusted 
 Client 
Figure 3: PRO-ORAM design overview with access and
shuffle enclaves operating in paralllel on active and next
array.
4.1 Design Overview
Similar to any cloud storage service, we have a setup phase
to establish user identities and upload initial data to the cloud.
We outline the setup phase for users that directly upload their
data to the cloud storage for e.g., Dropbox or Google Drive.
However, it can be modiﬁed to accommodate applications
such NetFlix, Spotify where the initial data is uploaded by
the service providers and not the users themselves.
Initialization. Each user registers with the cloud provider his
identity uid and a public key Pbuid mapped to their identity.
Let the data structure Pub_map store this mapping on the
server. The private key Pruid corresponding to the public
key is retained by the user. Each of these registered users
can upload their data to the server. To upload N data blocks
to the untrusted server, a data owner ﬁrst encrypts the data
blocks with a symmetric key K and then sends them to the
server. The order of these blocks during the initial upload does
not affect the security guarantees of PRO-ORAM. On receiving
the encrypted data, the server instantiates an “access” and a
“shuffle” enclave. Next, the data owner attests the program
running within these enclaves and secretly provisions the
encryption key K to them on successful attestation.
System Overview. Figure 3 shows the overview of PRO-ORAM
design for the read-only model. PRO-ORAM executes two en-
√
claves called access and shuffle in parallel on the untrusted
server. Each access and shuffle enclave has O(
N) pri-
vate storage and corresponds to a set of N data blocks. These
enclaves provide obliviousness guarantees to read from the N
data blocks uploaded on the server. The enclaves locally attest
each other and establish a secure channel between them [13].
They communicate over the secure channel to exchange se-
cret information such as encryption and permutation keys
(explained in detail in Section 4.2). The access enclave ex-
ecutes the square-root ORAM and the shuffle enclave per-
forms the Melbourne shufﬂe algorithm. However, PRO-ORAM
parallelizes the functioning of both these enclaves to achieve
constant latency per read request.
Algorithm 1: Pseudocode for each round of shuffle
enclave
Input: active_array: input data blocks ,
Kprev: previous key,
Knew: new key,
π: desired permutation,
r_num: current round number
Output: next_array: output permuted blocks
1 Let T1, T2, Otemp be temporary arrays;
2 Let πtemp be a random permutation;
3 Let Ktemp be a encryption key;
4 if r_num == 0 then
√
// Add dummy blocks
N do
for j from N to N +
j ← EncSE( Kprev, dummy);
d(cid:4)
active_array = active_array ∪ d(cid:4)
j;
5
6
7
end
8
9 end
// Two pass call to shuffle algorithm
10 mel_shufﬂe(active_array, T1, T2, πtemp, Kprev, Ktemp,
11 mel_shufﬂe(Otemp, T1, T2, π, Ktemp, Knew, next_array);
Otemp);
√
PRO-ORAM algorithm consists of several rounds where each
round is made of total
N requests from the users. In every
round, the access enclave strictly operates on the permuted
array of the uploaded data, which we refer as the active array.
On every request, the access enclave fetches the requested
data block either from the active array or the private stash
(similar to the square-root ORAM), re-encrypts the block and
sends it to the user. Simultaneously, the shuffle enclave
reads data blocks in a deterministic pattern from the active
array, performs the shufﬂe algorithm on them and outputs a
√
new permuted array, which we refer as the next array. The
√
shuffle enclave internally distributes the work using O(
N)
separate threads. By the end of each round, i.e., after
N
requests, the active array is replaced with the next array.
Thus, for serving N data blocks, PRO-ORAM uses O(N) space
on the server to store the active and the next array.
Parallelizing the access and shuffle enclave enables
PRO-ORAM to create a new permuted array while serving re-
quests on the active array. This design is novel to PRO-ORAM
and differs from previous ways of parallelizing access and
shufﬂe operations [23,41]. The algorithms for both the access
and shufﬂe operations execute within SGX enclaves and are
oblivious to the server. We give a detailed proof in Section 5.
4.2 Shufﬂe Enclave
The shuffle enclave starts its execution one round before
the access enclave. We call this as the preparation round
or round 0. The shuffle enclave uses this round to per-
202          22nd International Symposium on Research in Attacks, Intrusions and DefensesUSENIX AssociationAlgorithm 2: Parallel pseudocode for mel_shuffle
function
Input: I: input data blocks ,
T1, T2: Temporary arrays,
Kprev: previous key,
Knew: new key,
π: desired permutation,
Output: O: output permuted blocks
1 Let K1, K2 be encryption keys;
√
// Place the blocks into correct chunks
2 dist_phase1(I, π, Kprev, K1,T1):: O(
N) threads;
√
// Place the blocks in correct buckets
3 dist_phase2(T1, π, K1, K2, T2):: O(
N) threads;
√
// Arrange the blocks in each bucket
4 cleanup_phase(T2, π, K2, Knew):: O(
N) threads;
Active array 
√N blocks 
Temp1 array 
√N buckets 
Temp2 array 
(cid:3)(cid:9)(cid:15)(cid:16)(cid:14)(cid:9)(cid:6)(cid:19)(cid:17)(cid:12)(cid:11)
(cid:3)(cid:9)(cid:15)(cid:16)(cid:14)(cid:9)(cid:6)(cid:19)(cid:17)(cid:12)(cid:11)(cid:1)
(cid:1)(cid:13)(cid:8)(cid:5)(cid:15)(cid:7)(cid:1)(cid:4)(cid:1)
(cid:1)(cid:13)(cid:8)(cid:5)(cid:15)(cid:7)(cid:1)(cid:4)