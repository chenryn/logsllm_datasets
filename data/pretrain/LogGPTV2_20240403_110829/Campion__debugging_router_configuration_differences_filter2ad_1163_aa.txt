title:Campion: debugging router configuration differences
author:Alan Tang and
Siva Kesava Reddy Kakarla and
Ryan Beckett and
Ennan Zhai and
Matt Brown and
Todd D. Millstein and
Yuval Tamir and
George Varghese
Campion: Debugging Router Configuration Differences
Alan Tang
UCLA
PI:EMAIL
Siva Kesava Reddy Kakarla
UCLA
PI:EMAIL
Ryan Beckett
Microsoft
PI:EMAIL
Ennan Zhai
Alibaba
PI:EMAIL
Matt Brown
Intentionet
PI:EMAIL
Todd Millstein
UCLA / Intentionet
PI:EMAIL
Yuval Tamir
UCLA
PI:EMAIL
George Varghese
UCLA
PI:EMAIL
Abstract
We present a new approach for debugging two router configurations
that are intended to be behaviorally equivalent. Existing router ver-
ification techniques cannot identify all differences or localize those
differences to relevant configuration lines. Our approach addresses
these limitations through a modular analysis, which separately an-
alyzes pairs of corresponding configuration components. It handles
all router components that affect routing and forwarding, including
configuration for BGP, OSPF, static routes, route maps and ACLs.
Further, for many configuration components our modular approach
enables simple structural equivalence checks to be used without
additional loss of precision versus modular semantic checks, aid-
ing both efficiency and error localization. We implemented this
approach in the tool Campion and applied it to debugging pairs
of backup routers from different manufacturers and validating re-
placement of critical routers. Campion analyzed 30 proposed router
replacements in a production cloud network and proactively de-
tected four configuration bugs, including a route reflector bug that
could have caused a severe outage. Campion also found multiple
differences between backup routers from different vendors in a
university network. These were undetected for three years, and de-
pended on subtle semantic differences that the operators said they
were "highly unlikely" to detect by "just eyeballing the configs."
CCS Concepts
‚Ä¢ Networks ‚Üí Network reliability; Network manageability.
Keywords
Network Verification, Equivalence Checking, Error Localization,
Modular Reasoning
ACM Reference Format:
Alan Tang, Siva Kesava Reddy Kakarla, Ryan Beckett, Ennan Zhai, Matt
Brown, Todd Millstein, Yuval Tamir, and George Varghese. 2021. Campion:
This work is licensed under a Creative Commons Attribution International 4.0 License.
SIGCOMM ‚Äô21, August 23‚Äì27, 2021, Virtual Event, USA
¬© 2021 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-8383-7/21/08.
https://doi.org/10.1145/3452296.3472925
748
Debugging Router Configuration Differences. In ACM SIGCOMM 2021 Con-
ference (SIGCOMM ‚Äô21), August 23‚Äì27, 2021, Virtual Event, USA. ACM, New
York, NY, USA, 14 pages. https://doi.org/10.1145/3452296.3472925
1 Introduction
Networks today are manually configured through low-level configu-
ration directives at individual routers that enforce complex policies
for access control and routing. Manual programming often intro-
duces subtle configuration errors that induce costly and disruptive
outages [7, 19, 23, 25, 27, 30]. While researchers have developed
many verification tools that can analyze network configurations
to find bugs [1, 3, 4, 12, 13, 17, 18, 21, 24, 29, 32‚Äì34], there has been
less focus on helping operators to understand and fix the identified
bugs.
This paper presents an approach to router configuration debug-
ging in the context of a specific, but common, verification task:
checking behavioral equivalence of two individual router configura-
tions. This task arises often in large networks. First, it is common
for pairs of routers from different manufacturers (to avoid repli-
cating implementation bugs) to serve as backups for one another
in case of failure. Whenever one router in the pair is updated, the
other must be consistently updated, which is non-trivial if they
use different configuration formats. A second important use case
is router replacement. As shown in (¬ß 5), routers are periodically
upgraded from one manufacturer (e.g., Juniper) to one another (e.g.,
Arista) with better features, cost, or performance. Since the Arista
configuration has to be manually translated from the Juniper, the
operation is difficult and perilous. The first use case shows the need
for behavioral equivalence checking in space, while the second is
an example of the need for such checking in time.
Existing tools for network control-plane verification, such as
Minesweeper [3], can be used to verify behavioral equivalence of
two router configurations. However, while these tools can detect
equivalence violations, they provide very little help in debugging
such errors. In particular, existing tools have two key limitations
that our work aims to address. First, they provide only a single coun-
terexample and hence identify only a single behavioral difference
between the two configurations. Second, the provided counterex-
ample consists of a concrete packet whose forwarding exhibits
a behavioral difference in the two configurations, leaving to the
operator the difficult tasks of identifying the set of packets that is
SIGCOMM ‚Äô21, August 23‚Äì27, 2021, Virtual Event, USA
Tang et al.
impacted and the specific configuration lines that caused the differ-
ence. We call the first challenge header localization and the second
text localization.
We present a concrete example of header and text localization in
¬ß2. Figure 1 shows two example configuration snippets from real
configurations for a Cisco and Juniper router, and Table 2 shows the
differences output by our tool. The first few rows of each difference
represent header localization and the last three rows represent text
localization. While the configurations used in Figure 1 are small,
they have subtle behavioral differences. Further, many enterprises
have large route maps and ACLs of thousands of lines (see ¬ß5.1).
Our tool, Campion, performs localization through a novel modu-
lar approach. Rather than representing the behavior of each router
configuration monolithically, for example as a set of SMT con-
straints [3], Campion compares pairs of corresponding components
between the two configurations (route maps, ACLs, OSPF costs,
etc., see Table 1) separately. Performing equivalence checks on a
per-component basis immediately helps: every pair of components
that are not behaviorally equivalent is reported, and each such
violation is by construction localized to the relevant configuration
components.
In the context of modular checking, two configuration compo-
nents ùê∂1 and ùê∂2 are considered equivalent if any configuration
containing ùê∂1 could instead use ùê∂2 without changing the configu-
ration‚Äôs behavior. How should each pair of components be checked
for equivalence? Observe that there are two distinct types of config-
uration components from the point of view of modular checking.
Many configuration components have the property that any
structural difference implies a possible behavioral difference. For ex-
ample, two OSPF link costs are only guaranteed to be behaviorally
equivalent, for all possible configurations, if they are identical. The
same is true for static routes in two configurations. For these con-
figuration components, we compare them with a simple structural
equivalence check that we call StructuralDiff. This check is effi-
cient, reports and localizes all behavioral differences ‚Äî all structural
mismatches ‚Äî and makes it trivial for users to understand the error.
On the other hand, a few configuration components, specifically
ACLs and route maps, encode sophisticated policies, so there are
many possible structures for the same behavior, especially when
considering multiple vendors. For example, Juniper and Cisco route
maps are structured in very different ways. For these configura-
tion components, we compare them with a semantic equivalence
check that we call SemanticDiff. To identify all differences, we
model the two components ùê∂1 and ùê∂2 as functions (e.g., an ACL
is a function from a packet to a boolean). Then, for each path ùëù1
through ùê∂1 and ùëù2 through ùê∂2, we check whether there is some
input that traverses along ùëù1 and ùëù2 through their respective com-
ponents and exhibits a behavioral difference. This algorithm is
conceptually similar to prior approaches to checking equivalence
in C functions [26] and network data planes [9]. To our knowledge
ours is the first approach that can precisely check equivalence of
network control-plane structures, notably route maps.
The SemanticDiff algorithm localizes each behavioral differ-
ence to a specific path through each component. To help users un-
derstand the difference, we also introduce a novel algorithm called
HeaderLocalize that localizes each difference to the relevant space
of inputs. Specifically, SemanticDiff produces the impacted set of
Feature
ACLs
Route Maps (BGP, Route Redistribution)
Static Routes
Connected Routes
Other BGP Properties
OSPF Properties (costs, areas, etc.)
Administrative Distances
Check Used
SemanticDiff
SemanticDiff
StructuralDiff
StructuralDiff
StructuralDiff
StructuralDiff
StructuralDiff
Table 1: Components supported by Campion and the check
used for each.
inputs ùêº as a binary decision diagram (BDD). Given this BDD and
the original configurations, HeaderLocalize produces a represen-
tation of all destination IP addresses in ùêº in terms of the constants
(prefixes or prefix ranges) that appear in the configurations, and
does so in a minimal way.
Perhaps surprisingly, Campion is protocol-free: it does not need
to model or reason about routing protocols like BGP and OSPF.
Our modular approach obviates the need for such reasoning, as
equivalence of each corresponding pair of configuration compo-
nents implies that those protocols will behave identically on the
two routers. We formally prove this theorem, thereby justifying our
approach. A potential downside of our modular approach is that
it can produce false positives: it is possible for two configuration
components to cause a behavioral difference for some configura-
tion, and hence be flagged as erroneous by Campion, but still be
behaviorally equivalent in the context of the two given router con-
figurations. However, our experiments indicate that false positives
are rare. Intuitively this makes sense because configurations are cre-
ated and maintained in a modular fashion, with different aspects of
the configuration responsible for different aspects of the behavior.
We evaluated Campion on the network configurations of a large
cloud provider and a large university campus. We highlight two key
results, with details in ¬ß5. First, the operators of the cloud provider
were in the process of replacing 30 Cisco routers with Juniper
routers due to a corporate policy decision. This required them to
manually translate the original Cisco IOS configurations to JunOS.
They used Campion to proactively check equivalence, identifying
four configuration errors that they fixed before they could cause
service disruption, including one error that would have been a
severe outage. Second, the university network has a pair of core
routers and a pair of border routers from different device vendors
and intended to be backups of one another. Campion identified and
localized configuration errors across these two pairs. These errors
have been present in the configurations for nearly three years, and
the operators said that they were "highly unlikely" to detect them
by "just eyeballing the configs." Campion only takes a few seconds
to compare a pair of routers. Our work does not raise any ethical
issues.
‚Ä¢ A modular approach that identifies all behavioral differences be-
tween two configurations and localizes them to the relevant con-
figuration lines (¬ß3). For each configuration component, we deter-
mine whether a full semantic analysis (SemanticDiff) is needed
or a simple structural equivalence check (StructuralDiff) suf-
fices (see Table 1). We also describe a novel algorithm for local-
izing the relevant inputs (HeaderLocalize).
To summarize, the contributions of this paper are:
749
Campion: Debugging Router Configuration Differences
SIGCOMM ‚Äô21, August 23‚Äì27, 2021, Virtual Event, USA
‚Ä¢ A theorem (¬ß3.4) that shows our modular approach to equiva-
lence checking of configuration components suffices to ensure
router behavioral equivalence, despite not reasoning about the
network protocols.
‚Ä¢ A tool, Campion (¬ß4), that localizes behavioral differences be-
tween router configurations. Campion supports all of the routing
and forwarding components modeled by Minesweeper. Campion
is available as open-source software.1
‚Ä¢ An experimental evaluation of Campion on routers from a large
cloud vendor and a university network. (¬ß5).
2 Campion by Example
This section shows two examples of Campion‚Äôs output that identi-
fied behavioral differences in routers from a large university net-
work. We present one case involving differences between BGP route
maps, which Campion identified and localized using SemanticDiff
and HeaderLocalize, and a second case involving differences in
static routes, which Campion identified and localized using Struc-
turalDiff. In both cases, we also demonstrate the advantages of
Campion by comparing its output to that of Minesweeper [3], a
state-of-the-art network configuration verification tool.
2.1 Route Map Diffs via Semantic Checks
Figure 1 shows simplified versions of route maps from two core
routers in a large university network (see ¬ß 5.2). The two route
maps are intended to be behaviorally identical, with the first writ-
ten for a Cisco router and the second for a Juniper router. Both
configurations define a prefix list NETS to match a specific set of
IP prefixes (lines 1-2 in Figure 1(a) and 1-4 in Figure 1(b)), as well
as a community list COMM to match the community tags 10:10 and
10:11 (4-5 in Figure 1(a) and 5 in Figure 1(b)). The remainder of
each snippet defines a route map POL for each router, which rejects
route advertisements that match prefixes from NETS or are tagged
with communities from COMM and accepts all other advertisements
(7-12 in Figure 1(a) and 6-21 in Figure 1(b)).
Despite the superficial similarity of the two configurations, there
are large behavioral differences. Campion uses SemanticDiff and
HeaderLocalize to find and localize these differences. Table 2
shows Campion‚Äôs output when given the two route maps in Figure 1.
The output has two results, each of which represents a distinct
configuration error. For each error, Campion identifies all the route
advertisement prefixes that are treated differently by the two route
maps, namely route advertisements for prefixes that are in the
set Included Prefixes but not the set Excluded Prefixes. We
call the process of identifying and representing all problematic
inputs header localization. Further, Campion also shows the action
that each route map takes on these advertisements as well as the
configuration lines responsible for that action. We call the process